<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002713">
<title confidence="0.962144">
Grammatical Inference and Computational Linguistics
</title>
<author confidence="0.737872">
Menno van Zaanen
</author>
<affiliation confidence="0.966737333333333">
Tilburg Centre for Creative Computing
Tilburg University
Tilburg, The Netherlands
</affiliation>
<email confidence="0.961486">
mvzaanen@uvt.nl
</email>
<bodyText confidence="0.42945125">
Colin de la Higuera
University of Saint-´Etienne
France
cdlh@univ-st-etienne.fr
</bodyText>
<sectionHeader confidence="0.5911435" genericHeader="method">
1 Grammatical inference and its links to
natural language processing
</sectionHeader>
<bodyText confidence="0.9846499875">
When dealing with language, (machine) learning
can take many different faces, of which the most
important are those concerned with learning lan-
guages and grammars from data. Questions in
this context have been at the intersection of the
fields of inductive inference and computational
linguistics for the past fifty years. To go back
to the pioneering work, Chomsky (1955; 1957)
and Solomonoff (1960; 1964) were interested, for
very different reasons, in systems or programs that
could deduce a language when presented informa-
tion about it.
Gold (1967; 1978) proposed a little later a uni-
fying paradigm called identification in the limit,
and the term of grammatical inference seems to
have appeared in Horning’s PhD thesis (1969).
Out of the scope of linguistics, researchers and
engineers dealing with pattern recognition, under
the impulsion of Fu (1974; 1975), invented algo-
rithms and studied subclasses of languages and
grammars from the point of view of what could
or could not be learned.
Researchers in machine learning tackled related
problems (the most famous being that of infer-
ring a deterministic finite automaton, given ex-
amples and counter-examples of strings). An-
gluin (1978; 1980; 1981; 1982; 1987) introduced
the important setting of active learning, or learn-
ing for queries, whereas Pitt and his colleagues
(1988; 1989; 1993) gave several complexity in-
spired results with which the hardness of the dif-
ferent learning problems was exposed.
Researchers working in more applied areas,
such as computational biology, also deal with
strings. A number of researchers from that
field worked on learning grammars or automata
from string data (Brazma and Cerans, 1994;
Brazma, 1997; Brazma et al., 1998). Simi-
larly, stemming from computational linguistics,
one can point out the work relating language learn-
ing with more complex grammatical formalisms
(Kanazawa, 1998), the more statistical approaches
based on building language models (Goodman,
2001), or the different systems introduced to au-
tomatically build grammars from sentences (van
Zaanen, 2000; Adriaans and Vervoort, 2002). Sur-
veys of related work in specific fields can also
be found (Natarajan, 1991; Kearns and Vazirani,
1994; Sakakibara, 1997; Adriaans and van Zaa-
nen, 2004; de la Higuera, 2005; Wolf, 2006).
2 Meeting points between grammatical
inference and natural language
processing
Grammatical inference scientists belong to a num-
ber of larger communities: machine learning (with
special emphasis on inductive inference), com-
putational linguistics, pattern recognition (within
the structural and syntactic sub-group). There is
a specific conference called ICGI (International
Colloquium on Grammatical Inference) devoted
to the subject. These conferences have been held
at Alicante (Carrasco and Oncina, 1994), Mont-
pellier (Miclet and de la Higuera, 1996), Ames
(Honavar and Slutski, 1998), Lisbon (de Oliveira,
2000), Amsterdam (Adriaans et al., 2002), Athens
(Paliouras and Sakakibara, 2004), Tokyo (Sakak-
ibara et al., 2006) and Saint-Malo (Clark et al.,
2008). In the proceedings of this event it is pos-
sible to find a number of technical papers. Within
this context, there has been a growing trend to-
wards problems of language learning in the field
of computational linguistics.
The formal objects in common between the
two communities are the different types of au-
tomata and grammars. Therefore, another meet-
ing point between these communities has been the
different workshops, conferences and journals that
focus on grammars and automata, for instance,
Proceedings of the EACL 2009 Workshop on Computational Linguistic Aspects of Grammatical Inference, pages 1–4,
Athens, Greece, 30 March 2009. c�2009 Association for Computational Linguistics
</bodyText>
<page confidence="0.937664">
1
</page>
<bodyText confidence="0.898107">
FSMNLP,GRAMMARS, CIAA, .. .
</bodyText>
<sectionHeader confidence="0.98576" genericHeader="method">
3 Goal for the workshop
</sectionHeader>
<bodyText confidence="0.999969428571429">
There has been growing interest over the last few
years in learning grammars from natural language
text (and structured or semi-structured text). The
family of techniques enabling such learning is usu-
ally called “grammatical inference” or “grammar
induction”.
The field of grammatical inference is often sub-
divided into formal grammatical inference, where
researchers aim to proof efficient learnability of
classes of grammars, and empirical grammatical
inference, where the aim is to learn structure from
data. In this case the existence of an underlying
grammar is just regarded as a hypothesis and what
is sought is to better describe the language through
some automatically learned rules.
Both formal and empirical grammatical infer-
ence have been linked with (computational) lin-
guistics. Formal learnability of grammars has
been used in discussions on how people learn lan-
guage. Some people mention proofs of (non-
)learnability of certain classes of grammars as ar-
guments in the empiricist/nativist discussion. On
the more practical side, empirical systems that
learn grammars have been applied to natural lan-
guage. Instead of proving whether classes of
grammars can be learnt, the aim here is to pro-
vide practical learning systems that automatically
introduce structure in language. Example fields
where initial research has been done are syntac-
tic parsing, morphological analysis of words, and
bilingual modelling (or machine translation).
This workshop organized at EACL 2009 aimed
to explore the state-of-the-art in these topics. In
particular, we aimed at bringing formal and empir-
ical grammatical inference researchers closer to-
gether with researchers in the field of computa-
tional linguistics.
The topics put forward were to cover research
on all aspects of grammatical inference in rela-
tion to natural language (such as, syntax, seman-
tics, morphology, phonology, phonetics), includ-
ing, but not limited to
</bodyText>
<listItem confidence="0.998883066666666">
• Automatic grammar engineering, including,
for example,
– parser construction,
– parameter estimation,
– smoothing,...
• Unsupervised parsing
• Language modelling
• Transducers, for instance, for
– morphology,
– text to speech,
– automatic translation,
– transliteration,
– spelling correction, .. .
• Learning syntax with semantics,
• Unsupervised or semi-supervised learning of
linguistic knowledge,
• Learning (classes of) grammars (e.g. sub-
classes of the Chomsky Hierarchy) from lin-
guistic inputs,
• Comparing learning results in different
frameworks (e.g. membership vs. correction
queries),
• Learning linguistic structures (e.g. phonolog-
ical features, lexicon) from the acoustic sig-
nal,
• Grammars and finite state machines in ma-
chine translation,
• Learning setting of Chomskyan parameters,
• Cognitive aspects of grammar acquisition,
covering, among others,
</listItem>
<bodyText confidence="0.610489">
– developmental trajectories as studied by
psycholinguists working with children,
– characteristics of child-directed speech
as they are manifested in corpora such
as CHILDES, .. .
</bodyText>
<listItem confidence="0.9517765">
• (Unsupervised) Computational language ac-
quisition (experimental or observational),
</listItem>
<sectionHeader confidence="0.97664" genericHeader="method">
4 The papers
</sectionHeader>
<bodyText confidence="0.9995418">
The workshop was glad to have as invited speaker
Damir ´Cavar, who presented a talk titled: On boot-
strapping of linguistic features for bootstrapping
grammars.
The papers submitted to the workshop and re-
viewed by at least three reviewers each, covered a
very wide range of problems and techniques. Ar-
ranging them into patterns was not a simple task!
There were three papers focussing on transduc-
ers:
</bodyText>
<page confidence="0.974847">
2
</page>
<listItem confidence="0.957480058823529">
• Jeroen Geertzen shows in his paper Dialogue
Act Prediction Using Stochastic Context-Free
Grammar Induction, how grammar induction
can be used in dialogue act prediction.
• In their paper (Experiments Using OSTIA for
a Language Production Task), Dana Angluin
and Leonor Becerra-Bonache build on previ-
ous work to see the transducer learning algo-
rithm OSTIA as capable of translating syn-
tax to semantics.
• In their paper titled GREAT: a finite-state
machine translation toolkit implementing a
Grammatical Inference Approach for Trans-
ducer Inference (GIATI), Jorge Gonz´alez and
Francisco Casacuberta build on a long his-
tory of GOATI learning and try to eliminate
some of the limitations of previous work.
The learning concerns finite-state transducers
from parallel corpora.
Context-free grammars of different types were
used for very different tasks:
• Alexander Clark, Remi Eyraud and Amaury
Habrard (A note on contextual binary fea-
ture grammars) propose a formal study of
a new formalism called “CBFG”, describe
the relationship of CBFG to other standard
formalisms and its appropriateness for mod-
elling natural language.
• In their work titled Language models for con-
textual error detection and correction, Her-
man Stehouwer and Menno van Zaanen look
at spelling problems as a word prediction
problem. The prediction needs a language
model which is learnt.
• A formal study of French treebanks is made
by Marie-H´el`ene Candito, Benoit Crabb´e and
Djam´e Seddah in their work: On statistical
parsing of French with supervised and semi-
supervised strategies.
• Franco M. Luque and Gabriel Infante-Lopez
study the learnability of NTS grammars with
reference to the Penn treebank in their paper
titled Upper Bounds for Unsupervised Pars-
ing with Unambiguous Non-Terminally Sep-
arated Grammars.
One paper concentrated on morphology :
• In A comparison of several learners for
Boolean partitions: implications for morpho-
logical paradigm, Katya Pertsova compares a
rote learner to three morphological paradigm
learners.
</listItem>
<sectionHeader confidence="0.980901" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.894076744186047">
P. Adriaans and M. van Zaanen. 2004. Computational
grammar induction for linguists. Grammars, 7:57–
68.
P. Adriaans and M. Vervoort. 2002. The EMILE
4.1 grammar induction toolbox. In Adriaans et al.
(Adriaans et al., 2002), pages 293–295.
P. Adriaans, H. Fernau, and M. van Zaannen, editors.
2002. Grammatical Inference: Algorithms and Ap-
plications, Proceedings of ICGI ’02, volume 2484
of LNAI, Berlin, Heidelberg. Springer-Verlag.
D. Angluin. 1978. On the complexity of minimum
inference of regular sets. Information and Control,
39:337–350.
D. Angluin. 1980. Inductive inference of formal lan-
guages from positive data. Information and Control,
45:117–135.
D. Angluin. 1981. A note on the number of queries
needed to identify regular languages. Information
and Control, 51:76–87.
D. Angluin. 1982. Inference of reversible languages.
Journal of the Association for Computing Machin-
ery, 29(3):741–765.
D. Angluin. 1987. Queries and concept learning. Ma-
chine Learning Journal, 2:319–342.
A. Brazma and K. Cerans. 1994. Efficient learning
of regular expressions from good examples. In AII
’94: Proceedings of the 4th International Workshop
on Analogical and Inductive Inference, pages 76–90.
Springer-Verlag.
A. Brazma, I. Jonassen, J. Vilo, and E. Ukkonen. 1998.
Pattern discovery in biosequences. In Honavar and
Slutski (Honavar and Slutski, 1998), pages 257–270.
A. Brazma, 1997. Computational learning theory and
natural learning systems, volume 4, chapter Effi-
cient learning of regular expressions from approxi-
mate examples, pages 351–366. MIT Press.
R. C. Carrasco and J. Oncina, editors. 1994. Gram-
matical Inference and Applications, Proceedings of
ICGI ’94, number 862 in LNAI, Berlin, Heidelberg.
Springer-Verlag.
N. Chomsky. 1955. The logical structure of linguis-
tic theory. Ph.D. thesis, Massachusetts Institute of
Technology.
</reference>
<page confidence="0.990006">
3
</page>
<reference confidence="0.997357586666667">
N. Chomsky. 1957. Syntactic structure. Mouton.
A. Clark, F. Coste, and L. Miclet, editors. 2008.
Grammatical Inference: Algorithms and Applica-
tions, Proceedings of ICGI ’08, volume 5278 of
LNCS. Springer-Verlag.
C. de la Higuera. 2005. A bibliographical study
of grammatical inference. Pattern Recognition,
38:1332–1348.
A. L. de Oliveira, editor. 2000. Grammatical Infer-
ence: Algorithms and Applications, Proceedings of
ICGI ’00, volume 1891 of LNAI, Berlin, Heidelberg.
Springer-Verlag.
K. S. Fu and T. L. Booth. 1975. Grammatical infer-
ence: Introduction and survey. Part I and II. IEEE
Transactions on Syst. Man. and Cybern., 5:59–72
and 409–423.
K. S. Fu. 1974. Syntactic Methods in Pattern Recogni-
tion. Academic Press, New-York.
E. M. Gold. 1967. Language identification in the limit.
Information and Control, 10(5):447–474.
E. M. Gold. 1978. Complexity of automaton identi-
fication from given data. Information and Control,
37:302–320.
J. Goodman. 2001. A bit of progress in language mod-
eling. Technical report, Microsoft Research.
V. Honavar and G. Slutski, editors. 1998. Gram-
maticalInference, Proceedings of ICGI ’98, number
1433 in LNAI, Berlin, Heidelberg. Springer-Verlag.
J. J. Horning. 1969. A study of Grammatical Inference.
Ph.D. thesis, Stanford University.
M. Kanazawa. 1998. Learnable Classes of Categorial
Grammars. CSLI Publications, Stanford, Ca.
M. J. Kearns and U. Vazirani. 1994. An Introduction
to Computational Learning Theory. MIT press.
L. Miclet and C. de la Higuera, editors. 1996. Pro-
ceedings of ICGI ’96, number 1147 in LNAI, Berlin,
Heidelberg. Springer-Verlag.
B. L. Natarajan. 1991. Machine Learning: a Theoret-
ical Approach. Morgan Kauffman Pub., San Mateo,
CA.
G. Paliouras and Y. Sakakibara, editors. 2004. Gram-
matical Inference: Algorithms and Applications,
Proceedings of ICGI ’04, volume 3264 of LNAI,
Berlin, Heidelberg. Springer-Verlag.
L. Pitt and M. Warmuth. 1988. Reductions among
prediction problems: on the difficulty of predicting
automata. In 3rd Conference on Structure in Com-
plexity Theory, pages 60–69.
L. Pitt and M. Warmuth. 1993. The minimum consis-
tent DFA problem cannot be approximated within
any polynomial. Journal of the Association for
Computing Machinery, 40(1):95–142.
L. Pitt. 1989. Inductive inference, DFA’s, and com-
putational complexity. In Analogical and Induc-
tive Inference, number 397 in LNAI, pages 18–44.
Springer-Verlag, Berlin, Heidelberg.
Y. Sakakibara, S. Kobayashi, K. Sato, T. Nishino, and
E. Tomita, editors. 2006. Grammatical Infer-
ence: Algorithms and Applications, Proceedings of
ICGI ’06, volume 4201 of LNAI, Berlin, Heidelberg.
Springer-Verlag.
Y. Sakakibara. 1997. Recent advances of grammatical
inference. Theoretical Computer Science, 185:15–
45.
R. Solomonoff. 1960. A preliminary report on a gen-
eral theory of inductive inference. Technical Report
ZTB-138, Zator Company, Cambridge, Mass.
R. Solomonoff. 1964. A formal theory of inductive
inference. Information and Control, 7(1):1–22 and
224–254.
M. van Zaanen. 2000. ABL: Alignment-based learn-
ing. In Proceedings of COLING 2000, pages 961–
967. Morgan Kaufmann.
G. Wolf. 2006. Unifying computing and cognition.
Cognition research.
</reference>
<page confidence="0.996662">
4
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.009616">
<title confidence="0.96042">Grammatical Inference and Computational Linguistics</title>
<author confidence="0.98549">Menno van</author>
<affiliation confidence="0.7625245">Tilburg Centre for Creative Tilburg</affiliation>
<address confidence="0.854503">Tilburg, The</address>
<email confidence="0.976725">mvzaanen@uvt.nl</email>
<author confidence="0.734106">Colin de_la</author>
<affiliation confidence="0.957498">University of</affiliation>
<abstract confidence="0.984160427927928">cdlh@univ-st-etienne.fr 1 Grammatical inference and its links to natural language processing When dealing with language, (machine) learning can take many different faces, of which the most important are those concerned with learning languages and grammars from data. Questions in this context have been at the intersection of the fields of inductive inference and computational linguistics for the past fifty years. To go back to the pioneering work, Chomsky (1955; 1957) and Solomonoff (1960; 1964) were interested, for very different reasons, in systems or programs that could deduce a language when presented information about it. Gold (1967; 1978) proposed a little later a unifying paradigm called identification in the limit, and the term of grammatical inference seems to have appeared in Horning’s PhD thesis (1969). Out of the scope of linguistics, researchers and engineers dealing with pattern recognition, under the impulsion of Fu (1974; 1975), invented algorithms and studied subclasses of languages and grammars from the point of view of what could or could not be learned. Researchers in machine learning tackled related problems (the most famous being that of inferring a deterministic finite automaton, given examples and counter-examples of strings). Angluin (1978; 1980; 1981; 1982; 1987) introduced the important setting of active learning, or learning for queries, whereas Pitt and his colleagues (1988; 1989; 1993) gave several complexity inspired results with which the hardness of the different learning problems was exposed. Researchers working in more applied areas, such as computational biology, also deal with strings. A number of researchers from that field worked on learning grammars or automata from string data (Brazma and Cerans, 1994; Brazma, 1997; Brazma et al., 1998). Similarly, stemming from computational linguistics, one can point out the work relating language learning with more complex grammatical formalisms (Kanazawa, 1998), the more statistical approaches based on building language models (Goodman, 2001), or the different systems introduced to automatically build grammars from sentences (van Zaanen, 2000; Adriaans and Vervoort, 2002). Surveys of related work in specific fields can also be found (Natarajan, 1991; Kearns and Vazirani, 1994; Sakakibara, 1997; Adriaans and van Zaanen, 2004; de la Higuera, 2005; Wolf, 2006). 2 Meeting points between grammatical inference and natural language processing Grammatical inference scientists belong to a number of larger communities: machine learning (with special emphasis on inductive inference), computational linguistics, pattern recognition (within the structural and syntactic sub-group). There is specific conference called ICGI on Grammatical devoted to the subject. These conferences have been held at Alicante (Carrasco and Oncina, 1994), Montpellier (Miclet and de la Higuera, 1996), Ames (Honavar and Slutski, 1998), Lisbon (de Oliveira, 2000), Amsterdam (Adriaans et al., 2002), Athens (Paliouras and Sakakibara, 2004), Tokyo (Sakakibara et al., 2006) and Saint-Malo (Clark et al., 2008). In the proceedings of this event it is possible to find a number of technical papers. Within this context, there has been a growing trend towards problems of language learning in the field of computational linguistics. The formal objects in common between the two communities are the different types of automata and grammars. Therefore, another meeting point between these communities has been the different workshops, conferences and journals that focus on grammars and automata, for instance, of the EACL 2009 Workshop on Computational Linguistic Aspects of Grammatical pages Greece, 30 March 2009. Association for Computational Linguistics 1 CIAA, .. . 3 Goal for the workshop There has been growing interest over the last few years in learning grammars from natural language text (and structured or semi-structured text). The family of techniques enabling such learning is usually called “grammatical inference” or “grammar induction”. The field of grammatical inference is often subdivided into formal grammatical inference, where researchers aim to proof efficient learnability of classes of grammars, and empirical grammatical inference, where the aim is to learn structure from data. In this case the existence of an underlying grammar is just regarded as a hypothesis and what is sought is to better describe the language through some automatically learned rules. Both formal and empirical grammatical inference have been linked with (computational) linguistics. Formal learnability of grammars has been used in discussions on how people learn language. Some people mention proofs of (non- )learnability of certain classes of grammars as arguments in the empiricist/nativist discussion. On the more practical side, empirical systems that learn grammars have been applied to natural language. Instead of proving whether classes of grammars can be learnt, the aim here is to provide practical learning systems that automatically introduce structure in language. Example fields where initial research has been done are syntactic parsing, morphological analysis of words, and bilingual modelling (or machine translation). This workshop organized at EACL 2009 aimed to explore the state-of-the-art in these topics. In particular, we aimed at bringing formal and empirical grammatical inference researchers closer together with researchers in the field of computational linguistics. The topics put forward were to cover research on all aspects of grammatical inference in relation to natural language (such as, syntax, semantics, morphology, phonology, phonetics), including, but not limited to • Automatic grammar engineering, including, for example, construction, estimation, • Unsupervised parsing • Language modelling • Transducers, for instance, for to speech, translation, correction, .. . • Learning syntax with semantics, • Unsupervised or semi-supervised learning of linguistic knowledge, • Learning (classes of) grammars (e.g. subclasses of the Chomsky Hierarchy) from linguistic inputs, • Comparing learning results in different frameworks (e.g. membership vs. correction queries), • Learning linguistic structures (e.g. phonological features, lexicon) from the acoustic signal, • Grammars and finite state machines in machine translation, • Learning setting of Chomskyan parameters, • Cognitive aspects of grammar acquisition, covering, among others, trajectories as studied by psycholinguists working with children, of child-directed speech as they are manifested in corpora such as CHILDES, .. . • (Unsupervised) Computational language acquisition (experimental or observational), 4 The papers The workshop was glad to have as invited speaker ´Cavar, who presented a talk titled: bootstrapping of linguistic features for bootstrapping The papers submitted to the workshop and reviewed by at least three reviewers each, covered a very wide range of problems and techniques. Arranging them into patterns was not a simple task! There were three papers focussing on transducers: 2 Jeroen Geertzen shows in his paper Act Prediction Using Stochastic Context-Free how grammar induction can be used in dialogue act prediction. In their paper Using OSTIA for Language Production Dana Angluin and Leonor Becerra-Bonache build on previous work to see the transducer learning algorithm OSTIA as capable of translating syntax to semantics. In their paper titled a finite-state machine translation toolkit implementing a Grammatical Inference Approach for Trans- Inference Jorge Gonz´alez and Francisco Casacuberta build on a long hisof and try to eliminate some of the limitations of previous work. The learning concerns finite-state transducers from parallel corpora. Context-free grammars of different types were used for very different tasks: • Alexander Clark, Remi Eyraud and Amaury note on contextual binary feapropose a formal study of a new formalism called “CBFG”, describe the relationship of CBFG to other standard formalisms and its appropriateness for modelling natural language. In their work titled models for conerror detection and Herman Stehouwer and Menno van Zaanen look at spelling problems as a word prediction problem. The prediction needs a language model which is learnt. • A formal study of French treebanks is made by Marie-H´el`ene Candito, Benoit Crabb´e and Seddah in their work: statistical parsing of French with supervised and semi- • Franco M. Luque and Gabriel Infante-Lopez study the learnability of NTS grammars with reference to the Penn treebank in their paper Bounds for Unsupervised Parsing with Unambiguous Non-Terminally Sep- One paper concentrated on morphology : In comparison of several learners for Boolean partitions: implications for morpho- Katya Pertsova compares a rote learner to three morphological paradigm learners.</abstract>
<note confidence="0.9335955">References P. Adriaans and M. van Zaanen. 2004. Computational induction for linguists. 7:57– 68. Adriaans and M. Vervoort. 2002. The 4.1 grammar induction toolbox. In Adriaans et al. (Adriaans et al., 2002), pages 293–295. P. Adriaans, H. Fernau, and M. van Zaannen, editors. Inference: Algorithms and Ap- Proceedings of volume 2484 Berlin, Heidelberg. Springer-Verlag. D. Angluin. 1978. On the complexity of minimum</note>
<abstract confidence="0.912254">of regular sets. and 39:337–350. D. Angluin. 1980. Inductive inference of formal lanfrom positive data. and 45:117–135. D. Angluin. 1981. A note on the number of queries to identify regular languages. 51:76–87. D. Angluin. 1982. Inference of reversible languages.</abstract>
<note confidence="0.977816351351351">Journal of the Association for Computing Machin- 29(3):741–765. Angluin. 1987. Queries and concept learning. Ma- Learning 2:319–342. A. Brazma and K. Cerans. 1994. Efficient learning regular expressions from good examples. In ’94: Proceedings of the 4th International Workshop Analogical and Inductive pages 76–90. Springer-Verlag. A. Brazma, I. Jonassen, J. Vilo, and E. Ukkonen. 1998. Pattern discovery in biosequences. In Honavar and Slutski (Honavar and Slutski, 1998), pages 257–270. Brazma, 1997. learning theory and learning volume 4, chapter Efficient learning of regular expressions from approxiexamples, pages 351–366. C. Carrasco and J. Oncina, editors. 1994. Grammatical Inference and Applications, Proceedings of number 862 in Berlin, Heidelberg. Springer-Verlag. Chomsky. 1955. logical structure of linguis- Ph.D. thesis, Massachusetts Institute of Technology. 3 Chomsky. 1957. Mouton. A. Clark, F. Coste, and L. Miclet, editors. 2008. Grammatical Inference: Algorithms and Applica- Proceedings of volume 5278 of Springer-Verlag. C. de la Higuera. 2005. A bibliographical study grammatical inference. 38:1332–1348. L. de Oliveira, editor. 2000. Inference: Algorithms and Applications, Proceedings of volume 1891 of Berlin, Heidelberg. Springer-Verlag. K. S. Fu and T. L. Booth. 1975. Grammatical infer-</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Adriaans</author>
<author>M van Zaanen</author>
</authors>
<title>Computational grammar induction for linguists.</title>
<date>2004</date>
<journal>Grammars,</journal>
<volume>7</volume>
<pages>68</pages>
<marker>Adriaans, van Zaanen, 2004</marker>
<rawString>P. Adriaans and M. van Zaanen. 2004. Computational grammar induction for linguists. Grammars, 7:57– 68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Adriaans</author>
<author>M Vervoort</author>
</authors>
<title>The EMILE 4.1 grammar induction toolbox.</title>
<date>2002</date>
<booktitle>In Adriaans et al. (Adriaans</booktitle>
<pages>293--295</pages>
<contexts>
<context position="2409" citStr="Adriaans and Vervoort, 2002" startWordPosition="357" endWordPosition="360">hers working in more applied areas, such as computational biology, also deal with strings. A number of researchers from that field worked on learning grammars or automata from string data (Brazma and Cerans, 1994; Brazma, 1997; Brazma et al., 1998). Similarly, stemming from computational linguistics, one can point out the work relating language learning with more complex grammatical formalisms (Kanazawa, 1998), the more statistical approaches based on building language models (Goodman, 2001), or the different systems introduced to automatically build grammars from sentences (van Zaanen, 2000; Adriaans and Vervoort, 2002). Surveys of related work in specific fields can also be found (Natarajan, 1991; Kearns and Vazirani, 1994; Sakakibara, 1997; Adriaans and van Zaanen, 2004; de la Higuera, 2005; Wolf, 2006). 2 Meeting points between grammatical inference and natural language processing Grammatical inference scientists belong to a number of larger communities: machine learning (with special emphasis on inductive inference), computational linguistics, pattern recognition (within the structural and syntactic sub-group). There is a specific conference called ICGI (International Colloquium on Grammatical Inference)</context>
</contexts>
<marker>Adriaans, Vervoort, 2002</marker>
<rawString>P. Adriaans and M. Vervoort. 2002. The EMILE 4.1 grammar induction toolbox. In Adriaans et al. (Adriaans et al., 2002), pages 293–295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Adriaans</author>
<author>H Fernau</author>
<author>M van Zaannen</author>
<author>editors</author>
</authors>
<title>Grammatical Inference: Algorithms and Applications,</title>
<date>2002</date>
<booktitle>Proceedings of ICGI ’02,</booktitle>
<volume>2484</volume>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<marker>Adriaans, Fernau, van Zaannen, editors, 2002</marker>
<rawString>P. Adriaans, H. Fernau, and M. van Zaannen, editors. 2002. Grammatical Inference: Algorithms and Applications, Proceedings of ICGI ’02, volume 2484 of LNAI, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Angluin</author>
</authors>
<title>On the complexity of minimum inference of regular sets.</title>
<date>1978</date>
<journal>Information and Control,</journal>
<pages>39--337</pages>
<contexts>
<context position="1506" citStr="Angluin (1978" startWordPosition="223" endWordPosition="225">later a unifying paradigm called identification in the limit, and the term of grammatical inference seems to have appeared in Horning’s PhD thesis (1969). Out of the scope of linguistics, researchers and engineers dealing with pattern recognition, under the impulsion of Fu (1974; 1975), invented algorithms and studied subclasses of languages and grammars from the point of view of what could or could not be learned. Researchers in machine learning tackled related problems (the most famous being that of inferring a deterministic finite automaton, given examples and counter-examples of strings). Angluin (1978; 1980; 1981; 1982; 1987) introduced the important setting of active learning, or learning for queries, whereas Pitt and his colleagues (1988; 1989; 1993) gave several complexity inspired results with which the hardness of the different learning problems was exposed. Researchers working in more applied areas, such as computational biology, also deal with strings. A number of researchers from that field worked on learning grammars or automata from string data (Brazma and Cerans, 1994; Brazma, 1997; Brazma et al., 1998). Similarly, stemming from computational linguistics, one can point out the w</context>
</contexts>
<marker>Angluin, 1978</marker>
<rawString>D. Angluin. 1978. On the complexity of minimum inference of regular sets. Information and Control, 39:337–350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Angluin</author>
</authors>
<title>Inductive inference of formal languages from positive data. Information and Control,</title>
<date>1980</date>
<pages>45--117</pages>
<marker>Angluin, 1980</marker>
<rawString>D. Angluin. 1980. Inductive inference of formal languages from positive data. Information and Control, 45:117–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Angluin</author>
</authors>
<title>A note on the number of queries needed to identify regular languages. Information and Control,</title>
<date>1981</date>
<pages>51--76</pages>
<marker>Angluin, 1981</marker>
<rawString>D. Angluin. 1981. A note on the number of queries needed to identify regular languages. Information and Control, 51:76–87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Angluin</author>
</authors>
<title>Inference of reversible languages.</title>
<date>1982</date>
<journal>Journal of the Association for Computing Machinery,</journal>
<volume>29</volume>
<issue>3</issue>
<marker>Angluin, 1982</marker>
<rawString>D. Angluin. 1982. Inference of reversible languages. Journal of the Association for Computing Machinery, 29(3):741–765.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Angluin</author>
</authors>
<title>Queries and concept learning.</title>
<date>1987</date>
<journal>Machine Learning Journal,</journal>
<pages>2--319</pages>
<marker>Angluin, 1987</marker>
<rawString>D. Angluin. 1987. Queries and concept learning. Machine Learning Journal, 2:319–342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Brazma</author>
<author>K Cerans</author>
</authors>
<title>Efficient learning of regular expressions from good examples.</title>
<date>1994</date>
<booktitle>In AII ’94: Proceedings of the 4th International Workshop on Analogical and Inductive Inference,</booktitle>
<pages>76--90</pages>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="1993" citStr="Brazma and Cerans, 1994" startWordPosition="298" endWordPosition="301">the most famous being that of inferring a deterministic finite automaton, given examples and counter-examples of strings). Angluin (1978; 1980; 1981; 1982; 1987) introduced the important setting of active learning, or learning for queries, whereas Pitt and his colleagues (1988; 1989; 1993) gave several complexity inspired results with which the hardness of the different learning problems was exposed. Researchers working in more applied areas, such as computational biology, also deal with strings. A number of researchers from that field worked on learning grammars or automata from string data (Brazma and Cerans, 1994; Brazma, 1997; Brazma et al., 1998). Similarly, stemming from computational linguistics, one can point out the work relating language learning with more complex grammatical formalisms (Kanazawa, 1998), the more statistical approaches based on building language models (Goodman, 2001), or the different systems introduced to automatically build grammars from sentences (van Zaanen, 2000; Adriaans and Vervoort, 2002). Surveys of related work in specific fields can also be found (Natarajan, 1991; Kearns and Vazirani, 1994; Sakakibara, 1997; Adriaans and van Zaanen, 2004; de la Higuera, 2005; Wolf, </context>
</contexts>
<marker>Brazma, Cerans, 1994</marker>
<rawString>A. Brazma and K. Cerans. 1994. Efficient learning of regular expressions from good examples. In AII ’94: Proceedings of the 4th International Workshop on Analogical and Inductive Inference, pages 76–90. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Brazma</author>
<author>I Jonassen</author>
<author>J Vilo</author>
<author>E Ukkonen</author>
</authors>
<title>Pattern discovery in biosequences.</title>
<date>1998</date>
<booktitle>In Honavar and Slutski (Honavar and Slutski,</booktitle>
<pages>257--270</pages>
<contexts>
<context position="2029" citStr="Brazma et al., 1998" startWordPosition="304" endWordPosition="307"> a deterministic finite automaton, given examples and counter-examples of strings). Angluin (1978; 1980; 1981; 1982; 1987) introduced the important setting of active learning, or learning for queries, whereas Pitt and his colleagues (1988; 1989; 1993) gave several complexity inspired results with which the hardness of the different learning problems was exposed. Researchers working in more applied areas, such as computational biology, also deal with strings. A number of researchers from that field worked on learning grammars or automata from string data (Brazma and Cerans, 1994; Brazma, 1997; Brazma et al., 1998). Similarly, stemming from computational linguistics, one can point out the work relating language learning with more complex grammatical formalisms (Kanazawa, 1998), the more statistical approaches based on building language models (Goodman, 2001), or the different systems introduced to automatically build grammars from sentences (van Zaanen, 2000; Adriaans and Vervoort, 2002). Surveys of related work in specific fields can also be found (Natarajan, 1991; Kearns and Vazirani, 1994; Sakakibara, 1997; Adriaans and van Zaanen, 2004; de la Higuera, 2005; Wolf, 2006). 2 Meeting points between gram</context>
</contexts>
<marker>Brazma, Jonassen, Vilo, Ukkonen, 1998</marker>
<rawString>A. Brazma, I. Jonassen, J. Vilo, and E. Ukkonen. 1998. Pattern discovery in biosequences. In Honavar and Slutski (Honavar and Slutski, 1998), pages 257–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Brazma</author>
</authors>
<title>Computational learning theory and natural learning systems, volume 4, chapter Efficient learning of regular expressions from approximate examples,</title>
<date>1997</date>
<pages>351--366</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2007" citStr="Brazma, 1997" startWordPosition="302" endWordPosition="303">t of inferring a deterministic finite automaton, given examples and counter-examples of strings). Angluin (1978; 1980; 1981; 1982; 1987) introduced the important setting of active learning, or learning for queries, whereas Pitt and his colleagues (1988; 1989; 1993) gave several complexity inspired results with which the hardness of the different learning problems was exposed. Researchers working in more applied areas, such as computational biology, also deal with strings. A number of researchers from that field worked on learning grammars or automata from string data (Brazma and Cerans, 1994; Brazma, 1997; Brazma et al., 1998). Similarly, stemming from computational linguistics, one can point out the work relating language learning with more complex grammatical formalisms (Kanazawa, 1998), the more statistical approaches based on building language models (Goodman, 2001), or the different systems introduced to automatically build grammars from sentences (van Zaanen, 2000; Adriaans and Vervoort, 2002). Surveys of related work in specific fields can also be found (Natarajan, 1991; Kearns and Vazirani, 1994; Sakakibara, 1997; Adriaans and van Zaanen, 2004; de la Higuera, 2005; Wolf, 2006). 2 Meeti</context>
</contexts>
<marker>Brazma, 1997</marker>
<rawString>A. Brazma, 1997. Computational learning theory and natural learning systems, volume 4, chapter Efficient learning of regular expressions from approximate examples, pages 351–366. MIT Press.</rawString>
</citation>
<citation valid="true">
<title>Grammatical Inference and Applications,</title>
<date>1994</date>
<booktitle>Proceedings of ICGI ’94, number 862 in LNAI,</booktitle>
<editor>R. C. Carrasco and J. Oncina, editors.</editor>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<marker>1994</marker>
<rawString>R. C. Carrasco and J. Oncina, editors. 1994. Grammatical Inference and Applications, Proceedings of ICGI ’94, number 862 in LNAI, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<title>The logical structure of linguistic theory.</title>
<date>1955</date>
<tech>Ph.D. thesis,</tech>
<institution>Massachusetts Institute of Technology.</institution>
<contexts>
<context position="687" citStr="Chomsky (1955" startWordPosition="95" endWordPosition="96">rg Centre for Creative Computing Tilburg University Tilburg, The Netherlands mvzaanen@uvt.nl Colin de la Higuera University of Saint-´Etienne France cdlh@univ-st-etienne.fr 1 Grammatical inference and its links to natural language processing When dealing with language, (machine) learning can take many different faces, of which the most important are those concerned with learning languages and grammars from data. Questions in this context have been at the intersection of the fields of inductive inference and computational linguistics for the past fifty years. To go back to the pioneering work, Chomsky (1955; 1957) and Solomonoff (1960; 1964) were interested, for very different reasons, in systems or programs that could deduce a language when presented information about it. Gold (1967; 1978) proposed a little later a unifying paradigm called identification in the limit, and the term of grammatical inference seems to have appeared in Horning’s PhD thesis (1969). Out of the scope of linguistics, researchers and engineers dealing with pattern recognition, under the impulsion of Fu (1974; 1975), invented algorithms and studied subclasses of languages and grammars from the point of view of what could </context>
</contexts>
<marker>Chomsky, 1955</marker>
<rawString>N. Chomsky. 1955. The logical structure of linguistic theory. Ph.D. thesis, Massachusetts Institute of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<date>1957</date>
<note>Syntactic structure. Mouton.</note>
<marker>Chomsky, 1957</marker>
<rawString>N. Chomsky. 1957. Syntactic structure. Mouton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Clark</author>
<author>F Coste</author>
<author>L Miclet</author>
<author>editors</author>
</authors>
<title>Grammatical Inference: Algorithms and Applications,</title>
<date>2008</date>
<booktitle>Proceedings of ICGI ’08,</booktitle>
<volume>5278</volume>
<editor>of LNCS.</editor>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="3359" citStr="Clark et al., 2008" startWordPosition="495" endWordPosition="498"> communities: machine learning (with special emphasis on inductive inference), computational linguistics, pattern recognition (within the structural and syntactic sub-group). There is a specific conference called ICGI (International Colloquium on Grammatical Inference) devoted to the subject. These conferences have been held at Alicante (Carrasco and Oncina, 1994), Montpellier (Miclet and de la Higuera, 1996), Ames (Honavar and Slutski, 1998), Lisbon (de Oliveira, 2000), Amsterdam (Adriaans et al., 2002), Athens (Paliouras and Sakakibara, 2004), Tokyo (Sakakibara et al., 2006) and Saint-Malo (Clark et al., 2008). In the proceedings of this event it is possible to find a number of technical papers. Within this context, there has been a growing trend towards problems of language learning in the field of computational linguistics. The formal objects in common between the two communities are the different types of automata and grammars. Therefore, another meeting point between these communities has been the different workshops, conferences and journals that focus on grammars and automata, for instance, Proceedings of the EACL 2009 Workshop on Computational Linguistic Aspects of Grammatical Inference, pag</context>
</contexts>
<marker>Clark, Coste, Miclet, editors, 2008</marker>
<rawString>A. Clark, F. Coste, and L. Miclet, editors. 2008. Grammatical Inference: Algorithms and Applications, Proceedings of ICGI ’08, volume 5278 of LNCS. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C de la Higuera</author>
</authors>
<title>A bibliographical study of grammatical inference. Pattern Recognition,</title>
<date>2005</date>
<pages>38--1332</pages>
<contexts>
<context position="2585" citStr="Higuera, 2005" startWordPosition="389" endWordPosition="390">azma and Cerans, 1994; Brazma, 1997; Brazma et al., 1998). Similarly, stemming from computational linguistics, one can point out the work relating language learning with more complex grammatical formalisms (Kanazawa, 1998), the more statistical approaches based on building language models (Goodman, 2001), or the different systems introduced to automatically build grammars from sentences (van Zaanen, 2000; Adriaans and Vervoort, 2002). Surveys of related work in specific fields can also be found (Natarajan, 1991; Kearns and Vazirani, 1994; Sakakibara, 1997; Adriaans and van Zaanen, 2004; de la Higuera, 2005; Wolf, 2006). 2 Meeting points between grammatical inference and natural language processing Grammatical inference scientists belong to a number of larger communities: machine learning (with special emphasis on inductive inference), computational linguistics, pattern recognition (within the structural and syntactic sub-group). There is a specific conference called ICGI (International Colloquium on Grammatical Inference) devoted to the subject. These conferences have been held at Alicante (Carrasco and Oncina, 1994), Montpellier (Miclet and de la Higuera, 1996), Ames (Honavar and Slutski, 1998</context>
</contexts>
<marker>Higuera, 2005</marker>
<rawString>C. de la Higuera. 2005. A bibliographical study of grammatical inference. Pattern Recognition, 38:1332–1348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L de Oliveira</author>
<author>editor</author>
</authors>
<title>Grammatical Inference: Algorithms and Applications,</title>
<date>2000</date>
<booktitle>Proceedings of ICGI ’00,</booktitle>
<volume>1891</volume>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<marker>de Oliveira, editor, 2000</marker>
<rawString>A. L. de Oliveira, editor. 2000. Grammatical Inference: Algorithms and Applications, Proceedings of ICGI ’00, volume 1891 of LNAI, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K S Fu</author>
<author>T L Booth</author>
</authors>
<title>Grammatical inference: Introduction and survey. Part I and II.</title>
<date>1975</date>
<booktitle>IEEE Transactions on Syst. Man. and Cybern.,</booktitle>
<pages>5--59</pages>
<marker>Fu, Booth, 1975</marker>
<rawString>K. S. Fu and T. L. Booth. 1975. Grammatical inference: Introduction and survey. Part I and II. IEEE Transactions on Syst. Man. and Cybern., 5:59–72 and 409–423.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K S Fu</author>
</authors>
<title>Syntactic Methods in Pattern Recognition.</title>
<date>1974</date>
<publisher>Academic Press,</publisher>
<location>New-York.</location>
<contexts>
<context position="1172" citStr="Fu (1974" startWordPosition="171" endWordPosition="172">nductive inference and computational linguistics for the past fifty years. To go back to the pioneering work, Chomsky (1955; 1957) and Solomonoff (1960; 1964) were interested, for very different reasons, in systems or programs that could deduce a language when presented information about it. Gold (1967; 1978) proposed a little later a unifying paradigm called identification in the limit, and the term of grammatical inference seems to have appeared in Horning’s PhD thesis (1969). Out of the scope of linguistics, researchers and engineers dealing with pattern recognition, under the impulsion of Fu (1974; 1975), invented algorithms and studied subclasses of languages and grammars from the point of view of what could or could not be learned. Researchers in machine learning tackled related problems (the most famous being that of inferring a deterministic finite automaton, given examples and counter-examples of strings). Angluin (1978; 1980; 1981; 1982; 1987) introduced the important setting of active learning, or learning for queries, whereas Pitt and his colleagues (1988; 1989; 1993) gave several complexity inspired results with which the hardness of the different learning problems was exposed</context>
</contexts>
<marker>Fu, 1974</marker>
<rawString>K. S. Fu. 1974. Syntactic Methods in Pattern Recognition. Academic Press, New-York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Gold</author>
</authors>
<title>Language identification in the limit.</title>
<date>1967</date>
<journal>Information and Control,</journal>
<volume>10</volume>
<issue>5</issue>
<contexts>
<context position="867" citStr="Gold (1967" startWordPosition="123" endWordPosition="124">cal inference and its links to natural language processing When dealing with language, (machine) learning can take many different faces, of which the most important are those concerned with learning languages and grammars from data. Questions in this context have been at the intersection of the fields of inductive inference and computational linguistics for the past fifty years. To go back to the pioneering work, Chomsky (1955; 1957) and Solomonoff (1960; 1964) were interested, for very different reasons, in systems or programs that could deduce a language when presented information about it. Gold (1967; 1978) proposed a little later a unifying paradigm called identification in the limit, and the term of grammatical inference seems to have appeared in Horning’s PhD thesis (1969). Out of the scope of linguistics, researchers and engineers dealing with pattern recognition, under the impulsion of Fu (1974; 1975), invented algorithms and studied subclasses of languages and grammars from the point of view of what could or could not be learned. Researchers in machine learning tackled related problems (the most famous being that of inferring a deterministic finite automaton, given examples and coun</context>
</contexts>
<marker>Gold, 1967</marker>
<rawString>E. M. Gold. 1967. Language identification in the limit. Information and Control, 10(5):447–474.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Gold</author>
</authors>
<title>Complexity of automaton identification from given data. Information and Control,</title>
<date>1978</date>
<pages>37--302</pages>
<marker>Gold, 1978</marker>
<rawString>E. M. Gold. 1978. Complexity of automaton identification from given data. Information and Control, 37:302–320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Goodman</author>
</authors>
<title>A bit of progress in language modeling.</title>
<date>2001</date>
<tech>Technical report, Microsoft Research.</tech>
<contexts>
<context position="2277" citStr="Goodman, 2001" startWordPosition="340" endWordPosition="341">ve several complexity inspired results with which the hardness of the different learning problems was exposed. Researchers working in more applied areas, such as computational biology, also deal with strings. A number of researchers from that field worked on learning grammars or automata from string data (Brazma and Cerans, 1994; Brazma, 1997; Brazma et al., 1998). Similarly, stemming from computational linguistics, one can point out the work relating language learning with more complex grammatical formalisms (Kanazawa, 1998), the more statistical approaches based on building language models (Goodman, 2001), or the different systems introduced to automatically build grammars from sentences (van Zaanen, 2000; Adriaans and Vervoort, 2002). Surveys of related work in specific fields can also be found (Natarajan, 1991; Kearns and Vazirani, 1994; Sakakibara, 1997; Adriaans and van Zaanen, 2004; de la Higuera, 2005; Wolf, 2006). 2 Meeting points between grammatical inference and natural language processing Grammatical inference scientists belong to a number of larger communities: machine learning (with special emphasis on inductive inference), computational linguistics, pattern recognition (within the</context>
</contexts>
<marker>Goodman, 2001</marker>
<rawString>J. Goodman. 2001. A bit of progress in language modeling. Technical report, Microsoft Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Honavar</author>
<author>G Slutski</author>
<author>editors</author>
</authors>
<date>1998</date>
<booktitle>GrammaticalInference, Proceedings of ICGI ’98, number 1433 in LNAI,</booktitle>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<marker>Honavar, Slutski, editors, 1998</marker>
<rawString>V. Honavar and G. Slutski, editors. 1998. GrammaticalInference, Proceedings of ICGI ’98, number 1433 in LNAI, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Horning</author>
</authors>
<title>A study of Grammatical Inference.</title>
<date>1969</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University.</institution>
<marker>Horning, 1969</marker>
<rawString>J. J. Horning. 1969. A study of Grammatical Inference. Ph.D. thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kanazawa</author>
</authors>
<title>Learnable Classes of Categorial Grammars.</title>
<date>1998</date>
<publisher>CSLI Publications,</publisher>
<location>Stanford, Ca.</location>
<contexts>
<context position="2194" citStr="Kanazawa, 1998" startWordPosition="329" endWordPosition="330">ning, or learning for queries, whereas Pitt and his colleagues (1988; 1989; 1993) gave several complexity inspired results with which the hardness of the different learning problems was exposed. Researchers working in more applied areas, such as computational biology, also deal with strings. A number of researchers from that field worked on learning grammars or automata from string data (Brazma and Cerans, 1994; Brazma, 1997; Brazma et al., 1998). Similarly, stemming from computational linguistics, one can point out the work relating language learning with more complex grammatical formalisms (Kanazawa, 1998), the more statistical approaches based on building language models (Goodman, 2001), or the different systems introduced to automatically build grammars from sentences (van Zaanen, 2000; Adriaans and Vervoort, 2002). Surveys of related work in specific fields can also be found (Natarajan, 1991; Kearns and Vazirani, 1994; Sakakibara, 1997; Adriaans and van Zaanen, 2004; de la Higuera, 2005; Wolf, 2006). 2 Meeting points between grammatical inference and natural language processing Grammatical inference scientists belong to a number of larger communities: machine learning (with special emphasis </context>
</contexts>
<marker>Kanazawa, 1998</marker>
<rawString>M. Kanazawa. 1998. Learnable Classes of Categorial Grammars. CSLI Publications, Stanford, Ca.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Kearns</author>
<author>U Vazirani</author>
</authors>
<title>An Introduction to Computational Learning Theory.</title>
<date>1994</date>
<publisher>MIT press.</publisher>
<contexts>
<context position="2515" citStr="Kearns and Vazirani, 1994" startWordPosition="375" endWordPosition="378">chers from that field worked on learning grammars or automata from string data (Brazma and Cerans, 1994; Brazma, 1997; Brazma et al., 1998). Similarly, stemming from computational linguistics, one can point out the work relating language learning with more complex grammatical formalisms (Kanazawa, 1998), the more statistical approaches based on building language models (Goodman, 2001), or the different systems introduced to automatically build grammars from sentences (van Zaanen, 2000; Adriaans and Vervoort, 2002). Surveys of related work in specific fields can also be found (Natarajan, 1991; Kearns and Vazirani, 1994; Sakakibara, 1997; Adriaans and van Zaanen, 2004; de la Higuera, 2005; Wolf, 2006). 2 Meeting points between grammatical inference and natural language processing Grammatical inference scientists belong to a number of larger communities: machine learning (with special emphasis on inductive inference), computational linguistics, pattern recognition (within the structural and syntactic sub-group). There is a specific conference called ICGI (International Colloquium on Grammatical Inference) devoted to the subject. These conferences have been held at Alicante (Carrasco and Oncina, 1994), Montpel</context>
</contexts>
<marker>Kearns, Vazirani, 1994</marker>
<rawString>M. J. Kearns and U. Vazirani. 1994. An Introduction to Computational Learning Theory. MIT press.</rawString>
</citation>
<citation valid="true">
<date>1996</date>
<booktitle>Proceedings of ICGI ’96, number 1147 in LNAI,</booktitle>
<editor>L. Miclet and C. de la Higuera, editors.</editor>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<marker>1996</marker>
<rawString>L. Miclet and C. de la Higuera, editors. 1996. Proceedings of ICGI ’96, number 1147 in LNAI, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B L Natarajan</author>
</authors>
<title>Machine Learning: a Theoretical Approach. Morgan Kauffman Pub.,</title>
<date>1991</date>
<location>San Mateo, CA.</location>
<contexts>
<context position="2488" citStr="Natarajan, 1991" startWordPosition="373" endWordPosition="374"> number of researchers from that field worked on learning grammars or automata from string data (Brazma and Cerans, 1994; Brazma, 1997; Brazma et al., 1998). Similarly, stemming from computational linguistics, one can point out the work relating language learning with more complex grammatical formalisms (Kanazawa, 1998), the more statistical approaches based on building language models (Goodman, 2001), or the different systems introduced to automatically build grammars from sentences (van Zaanen, 2000; Adriaans and Vervoort, 2002). Surveys of related work in specific fields can also be found (Natarajan, 1991; Kearns and Vazirani, 1994; Sakakibara, 1997; Adriaans and van Zaanen, 2004; de la Higuera, 2005; Wolf, 2006). 2 Meeting points between grammatical inference and natural language processing Grammatical inference scientists belong to a number of larger communities: machine learning (with special emphasis on inductive inference), computational linguistics, pattern recognition (within the structural and syntactic sub-group). There is a specific conference called ICGI (International Colloquium on Grammatical Inference) devoted to the subject. These conferences have been held at Alicante (Carrasco</context>
</contexts>
<marker>Natarajan, 1991</marker>
<rawString>B. L. Natarajan. 1991. Machine Learning: a Theoretical Approach. Morgan Kauffman Pub., San Mateo, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Paliouras</author>
<author>Y Sakakibara</author>
<author>editors</author>
</authors>
<title>Grammatical Inference: Algorithms and Applications,</title>
<date>2004</date>
<booktitle>Proceedings of ICGI ’04,</booktitle>
<volume>3264</volume>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<marker>Paliouras, Sakakibara, editors, 2004</marker>
<rawString>G. Paliouras and Y. Sakakibara, editors. 2004. Grammatical Inference: Algorithms and Applications, Proceedings of ICGI ’04, volume 3264 of LNAI, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Pitt</author>
<author>M Warmuth</author>
</authors>
<title>Reductions among prediction problems: on the difficulty of predicting automata.</title>
<date>1988</date>
<booktitle>In 3rd Conference on Structure in Complexity Theory,</booktitle>
<pages>60--69</pages>
<marker>Pitt, Warmuth, 1988</marker>
<rawString>L. Pitt and M. Warmuth. 1988. Reductions among prediction problems: on the difficulty of predicting automata. In 3rd Conference on Structure in Complexity Theory, pages 60–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Pitt</author>
<author>M Warmuth</author>
</authors>
<title>The minimum consistent DFA problem cannot be approximated within any polynomial.</title>
<date>1993</date>
<journal>Journal of the Association for Computing Machinery,</journal>
<volume>40</volume>
<issue>1</issue>
<marker>Pitt, Warmuth, 1993</marker>
<rawString>L. Pitt and M. Warmuth. 1993. The minimum consistent DFA problem cannot be approximated within any polynomial. Journal of the Association for Computing Machinery, 40(1):95–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Pitt</author>
</authors>
<title>Inductive inference, DFA’s, and computational complexity.</title>
<date>1989</date>
<booktitle>In Analogical and Inductive Inference, number 397 in LNAI,</booktitle>
<pages>18--44</pages>
<publisher>Springer-Verlag,</publisher>
<location>Berlin, Heidelberg.</location>
<marker>Pitt, 1989</marker>
<rawString>L. Pitt. 1989. Inductive inference, DFA’s, and computational complexity. In Analogical and Inductive Inference, number 397 in LNAI, pages 18–44. Springer-Verlag, Berlin, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Sakakibara</author>
<author>S Kobayashi</author>
<author>K Sato</author>
<author>T Nishino</author>
</authors>
<title>Grammatical Inference: Algorithms and Applications,</title>
<date>2006</date>
<booktitle>Proceedings of ICGI ’06,</booktitle>
<volume>4201</volume>
<editor>and E. Tomita, editors.</editor>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="3323" citStr="Sakakibara et al., 2006" startWordPosition="488" endWordPosition="492">e scientists belong to a number of larger communities: machine learning (with special emphasis on inductive inference), computational linguistics, pattern recognition (within the structural and syntactic sub-group). There is a specific conference called ICGI (International Colloquium on Grammatical Inference) devoted to the subject. These conferences have been held at Alicante (Carrasco and Oncina, 1994), Montpellier (Miclet and de la Higuera, 1996), Ames (Honavar and Slutski, 1998), Lisbon (de Oliveira, 2000), Amsterdam (Adriaans et al., 2002), Athens (Paliouras and Sakakibara, 2004), Tokyo (Sakakibara et al., 2006) and Saint-Malo (Clark et al., 2008). In the proceedings of this event it is possible to find a number of technical papers. Within this context, there has been a growing trend towards problems of language learning in the field of computational linguistics. The formal objects in common between the two communities are the different types of automata and grammars. Therefore, another meeting point between these communities has been the different workshops, conferences and journals that focus on grammars and automata, for instance, Proceedings of the EACL 2009 Workshop on Computational Linguistic A</context>
</contexts>
<marker>Sakakibara, Kobayashi, Sato, Nishino, 2006</marker>
<rawString>Y. Sakakibara, S. Kobayashi, K. Sato, T. Nishino, and E. Tomita, editors. 2006. Grammatical Inference: Algorithms and Applications, Proceedings of ICGI ’06, volume 4201 of LNAI, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Sakakibara</author>
</authors>
<title>Recent advances of grammatical inference.</title>
<date>1997</date>
<journal>Theoretical Computer Science,</journal>
<volume>185</volume>
<pages>45</pages>
<contexts>
<context position="2533" citStr="Sakakibara, 1997" startWordPosition="379" endWordPosition="380">d on learning grammars or automata from string data (Brazma and Cerans, 1994; Brazma, 1997; Brazma et al., 1998). Similarly, stemming from computational linguistics, one can point out the work relating language learning with more complex grammatical formalisms (Kanazawa, 1998), the more statistical approaches based on building language models (Goodman, 2001), or the different systems introduced to automatically build grammars from sentences (van Zaanen, 2000; Adriaans and Vervoort, 2002). Surveys of related work in specific fields can also be found (Natarajan, 1991; Kearns and Vazirani, 1994; Sakakibara, 1997; Adriaans and van Zaanen, 2004; de la Higuera, 2005; Wolf, 2006). 2 Meeting points between grammatical inference and natural language processing Grammatical inference scientists belong to a number of larger communities: machine learning (with special emphasis on inductive inference), computational linguistics, pattern recognition (within the structural and syntactic sub-group). There is a specific conference called ICGI (International Colloquium on Grammatical Inference) devoted to the subject. These conferences have been held at Alicante (Carrasco and Oncina, 1994), Montpellier (Miclet and d</context>
</contexts>
<marker>Sakakibara, 1997</marker>
<rawString>Y. Sakakibara. 1997. Recent advances of grammatical inference. Theoretical Computer Science, 185:15– 45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Solomonoff</author>
</authors>
<title>A preliminary report on a general theory of inductive inference.</title>
<date>1960</date>
<tech>Technical Report ZTB-138,</tech>
<institution>Zator Company,</institution>
<location>Cambridge, Mass.</location>
<contexts>
<context position="715" citStr="Solomonoff (1960" startWordPosition="99" endWordPosition="100">mputing Tilburg University Tilburg, The Netherlands mvzaanen@uvt.nl Colin de la Higuera University of Saint-´Etienne France cdlh@univ-st-etienne.fr 1 Grammatical inference and its links to natural language processing When dealing with language, (machine) learning can take many different faces, of which the most important are those concerned with learning languages and grammars from data. Questions in this context have been at the intersection of the fields of inductive inference and computational linguistics for the past fifty years. To go back to the pioneering work, Chomsky (1955; 1957) and Solomonoff (1960; 1964) were interested, for very different reasons, in systems or programs that could deduce a language when presented information about it. Gold (1967; 1978) proposed a little later a unifying paradigm called identification in the limit, and the term of grammatical inference seems to have appeared in Horning’s PhD thesis (1969). Out of the scope of linguistics, researchers and engineers dealing with pattern recognition, under the impulsion of Fu (1974; 1975), invented algorithms and studied subclasses of languages and grammars from the point of view of what could or could not be learned. Res</context>
</contexts>
<marker>Solomonoff, 1960</marker>
<rawString>R. Solomonoff. 1960. A preliminary report on a general theory of inductive inference. Technical Report ZTB-138, Zator Company, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Solomonoff</author>
</authors>
<title>A formal theory of inductive inference.</title>
<date>1964</date>
<journal>Information and Control,</journal>
<volume>7</volume>
<issue>1</issue>
<pages>224--254</pages>
<marker>Solomonoff, 1964</marker>
<rawString>R. Solomonoff. 1964. A formal theory of inductive inference. Information and Control, 7(1):1–22 and 224–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M van Zaanen</author>
</authors>
<title>ABL: Alignment-based learning.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING</booktitle>
<pages>961--967</pages>
<publisher>Morgan Kaufmann.</publisher>
<marker>van Zaanen, 2000</marker>
<rawString>M. van Zaanen. 2000. ABL: Alignment-based learning. In Proceedings of COLING 2000, pages 961– 967. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Wolf</author>
</authors>
<title>Unifying computing and cognition. Cognition research.</title>
<date>2006</date>
<contexts>
<context position="2598" citStr="Wolf, 2006" startWordPosition="391" endWordPosition="392">, 1994; Brazma, 1997; Brazma et al., 1998). Similarly, stemming from computational linguistics, one can point out the work relating language learning with more complex grammatical formalisms (Kanazawa, 1998), the more statistical approaches based on building language models (Goodman, 2001), or the different systems introduced to automatically build grammars from sentences (van Zaanen, 2000; Adriaans and Vervoort, 2002). Surveys of related work in specific fields can also be found (Natarajan, 1991; Kearns and Vazirani, 1994; Sakakibara, 1997; Adriaans and van Zaanen, 2004; de la Higuera, 2005; Wolf, 2006). 2 Meeting points between grammatical inference and natural language processing Grammatical inference scientists belong to a number of larger communities: machine learning (with special emphasis on inductive inference), computational linguistics, pattern recognition (within the structural and syntactic sub-group). There is a specific conference called ICGI (International Colloquium on Grammatical Inference) devoted to the subject. These conferences have been held at Alicante (Carrasco and Oncina, 1994), Montpellier (Miclet and de la Higuera, 1996), Ames (Honavar and Slutski, 1998), Lisbon (de</context>
</contexts>
<marker>Wolf, 2006</marker>
<rawString>G. Wolf. 2006. Unifying computing and cognition. Cognition research.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>