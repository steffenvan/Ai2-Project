<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001378">
<title confidence="0.997072">
Effects of Conversational Agents on Human Communication
in Thought-Evoking Multi-Party Dialogues
</title>
<author confidence="0.758345">
Kohji Dohsaka
</author>
<note confidence="0.454694">
NTT Communication Science Laboratories
NTT Corporation
2-4, Hikaridai, Seika-cho,
Kyoto 619-0237, Japan
</note>
<author confidence="0.92961">
Ryota Asai
</author>
<affiliation confidence="0.901936">
Graduate School of
Information Science and Technology
Osaka University, 1-1 Yamadaoka,
Suita, Osaka 565-0871, Japan
</affiliation>
<author confidence="0.855162">
Ryuichiro Higashinaka and Yasuhiro Minami and Eisaku Maeda
</author>
<affiliation confidence="0.831233">
NTT Communication Science Laboratories, NTT Corporation
</affiliation>
<address confidence="0.968402">
2-4, Hikaridai, Seika-cho, Kyoto 619-0237, Japan
</address>
<email confidence="0.999742">
{dohsaka,rh,minami,maeda}@cslab.kecl.ntt.co.jp
</email>
<sectionHeader confidence="0.997401" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99986448">
This paper presents an experimental
study that analyzes how conversational
agents activate human communication in
thought-evoking multi-party dialogues be-
tween multi-users and multi-agents. A
thought-evoking dialogue, which is a kind
of interaction in which agents act on user
willingness to provoke user thinking, has
the potential to stimulate multi-party in-
teraction. In this paper, we focus on
quiz-style multi-party dialogues between
two users and two agents as an example
of a thought-evoking multi-party dialogue.
The experiment results showed that the
presence of a peer agent significantly im-
proved user satisfaction and increased the
number of user utterances. We also found
that agent empathic expressions signifi-
cantly improved user satisfaction, raised
user ratings of a peer agent, and increased
user utterances. Our findings will be use-
ful for stimulating multi-party communi-
cation in various applications such as ed-
ucational agents and community facilita-
tors.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999932361702128">
Conversational interfaces including dialogue sys-
tems and conversational agents have been typi-
cally used as a single interface to a single user (Zue
et al., 1994; Allen et al., 2001; Cassell et al.,
2000). On the other hand, a new area of re-
search in conversational interfaces is dealing with
multi-party interaction (Traum and Rickel, 2002;
Liu and Chee, 2004; Zheng et al., 2005). Multi-
party conversational interfaces have been applied
to such tasks as training decision-making in team
activities (Traum and Rickel, 2002), collabora-
tive learning (Liu and Chee, 2004), and coordinat-
ing and facilitating interaction in a casual social
group (Zheng et al., 2005).
The advantage of such multi-party dialogues
over two-party cases is that the multi-party case
encourages group interaction and collaboration
among human users. This advantage can be ex-
ploited to foster such human activities as student
learning in more social settings and to build and
maintain social relationships among people. How-
ever, unless users actively engage in the interac-
tion, these multi-party dialogue qualities cannot
be adequately exploited. Our objective is to stim-
ulate human communication in multi-party dia-
logues between multi-users and multi-agents by
raising user willingness to engage in the interac-
tion and increasing the number of user utterances.
As the first step toward this objective, we ex-
ploit a new style of dialogue called thought-
evoking dialogue and experimentally investigate
the impact of a peer agent’s presence and agent
emotional expressions on communication activa-
tion in thought-evoking multi-party dialogues. A
thought-evoking dialogue, an interaction in which
agents act on the willingness of users to provoke
user thinking and encourage involvement in the
dialogue, has the potential to activate interaction
among participants in multi-party dialogues.
Previous work proposed a quiz-style informa-
tion presentation dialogue system (hereafter quiz-
style dialogue system) (Higashinaka et al., 2007a)
that is regarded as a kind of thought-evoking di-
alogue system. This system conveys contents as
biographical facts of famous people through quiz-
style interaction with users by creating a ”Who
is this?” quiz and individually presenting hints.
</bodyText>
<note confidence="0.710018">
Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 217–224,
</note>
<affiliation confidence="0.662522">
Queen Mary University of London, September 2009. c�2009 Association for Computational Linguistics
</affiliation>
<page confidence="0.998329">
217
</page>
<bodyText confidence="0.999981823529412">
The hints are automatically created from the bi-
ographical facts of people and ordered based on
the difficulty naming the people experienced by
the users (Higashinaka et al., 2007b). Since the
user has to consider the hints to come up with rea-
sonable answers, the system stimulates user think-
ing. This previous work reported that, for in-
teraction between a single user and a computer,
a quiz-style dialogue improved user understand-
ing and willingness to engage in the interaction.
In this paper, we focus on a quiz-style informa-
tion presentation multi-party dialogue (hereafter
quiz-style multi-party dialogue) as an example of
a thought-evoking multi-party dialogue.
A peer agent acts as a peer of the users and par-
ticipates in the interactions in the same way that
the users do. We are interested in the peer agent’s
role in quiz-style multi-party dialogues since the
positive effects of a peer agent on users have been
shown in the educational domain (Chou et al.,
2003; Maldonado et al., 2005), which is a promis-
ing application area for quiz-style dialogues. In
the educational domain, a user could benefit not
only from direct communication with a peer agent
but also from overhearing dialogues between a
peer agent and a tutor. Learning by observing oth-
ers who are learning is called vicarious learning
and positively affects user performance (Craig et
al., 2000; Stenning et al., 1999). To the best of our
knowledge, detailed experimental investigations
on the effect of a peer agent on communication
activation have not been reported in multi-party
dialogues between multi-users and multi-agents,
which are our main concern in this paper.
The topic of emotion has gained widespread
attention in human-computer interaction (Bates,
1994; Picard, 1997; Hudlicka, 2003; Prendinger
and Ishizuka, 2004). The impact of an agent’s
emotional behaviors on users has also recently
been studied (Brave et al., 2005; Maldonado et
al., 2005; Prendinger et al., 2005). However, these
previous studies addressed scenario-based interac-
tion in which a user and an agent acted with prede-
termined timing. In this paper, we investigate the
impact of agent emotional expressions on users in
multi-party dialogues in which multiple users and
agents can make utterances with more flexible tim-
ing.
Resembling work by Brave et al. (2005), we
classify agent emotional expressions into em-
pathic and self-oriented ones and investigate their
impact on users in a thought-evoking multi-party
dialogue system. As stated above, Brave et
al. (2005) addressed scenario-based Black-jack in-
teraction, but we deal with multi-party dialogues
that enable more flexible turn-taking. Previous
studies (Bickmore and Picard, 2005; Higashinaka
et al., 2008) showed that agent empathic expres-
sions have a positive psychological impact upon
users, but they only examined two-party cases.
Although Traum et al. (2002) and Gebhard et
al. (2004) exploited the role of agent emotion in
multi-party dialogues, they did not adequately ex-
amine the effects of agent emotion on communi-
cation activation by experiment.
In this work, we deal with disembodied agents
and focus on their linguistic behaviors. We believe
that our results are useful for designing embodied
conversational agents using other modalities.
This paper presents an experimental study that
analyzes how agents stimulate human communi-
cation in quiz-style multi-party dialogues between
two users and two agents. We are especially inter-
ested in how the presence of a peer agent and agent
emotional expressions improve user satisfaction,
enhance user opinions about the peer agent, and
increase the number of user utterances. Our find-
ings will be useful for stimulating human com-
munication in various applications such as educa-
tional agents and community facilitators.
In the following, Section 2 shows an overview
of our quiz-style multi-party dialogue system.
Section 3 explains the experiment design, and Sec-
tion 4 describes the results. Section 5 concludes
the paper.
</bodyText>
<sectionHeader confidence="0.6570805" genericHeader="method">
2 Thought-Evoking Multi-Party
Dialogue System
</sectionHeader>
<bodyText confidence="0.999926714285714">
We implemented a quiz-style multi-party dialogue
system between multi-users and multi-agents. The
system is a Japanese keyboard-based dialogue sys-
tem with a chat-like interface. The users can make
utterances any time they want. A user utterance
is completed and displayed on the chat window
when the Enter key is pressed.
Our experiment dealt with cases where two
users and two agents engaged in a dialogue. The
two agents are a quizmaster and a peer. The quiz-
master agent creates a ”Who is this?” quiz about
a famous person and presents hints one by one to
the users and the peer agent who guess the correct
answer.
</bodyText>
<page confidence="0.990943">
218
</page>
<figure confidence="0.99033025">
1 Whowho Who is this? First hint: Graduated
from the University of Tokyo.
2 Mary I don’t know.
3 Kinoko Yoshida Shigeru.
4 Whowho No, not even close!
5 Jane That’s very difficult.
6 Kinoko Difficult for me, too.
7 Whowho Second hint: Born in Ushigome,
Edo.
...
8 Whowho Third hint: Novelist and scholar of
British literature.
9 Mary Murakami Haruki.
10 Whowho Close!
11 Kinoko You are close. Excellent.
12 Jane Well then, who is it?
13 Whowho Fourth hint: Familiar with Haiku,
Chinese poetry, and calligraphy.
14 Mary Natsume Soseki.
15 Whowho That’s right. Wonderful.
16 Kinoko Mary, excellent. I’m happy for
you.
17 Jane Mary, that’s the right answer. Good
job.
</figure>
<figureCaption confidence="0.999989">
Figure 1: Sample dialogue
</figureCaption>
<bodyText confidence="0.9985595">
Figure 1 shows a sample dialogue. Mary and
Jane are human users. Whowho is the quizmaster
agent, and Kinoko is the peer agent. Quizmaster
agent Whowho presents hints in lines 1, 7, 8, and
13. Users Mary and Jane and peer agent Kinoko
give answers in lines 3, 9, and 14.
The hints were automatically created using
biographical facts (in Japanese) of people in
Wikipedia 1 based on a previously reported
method (Higashinaka et al., 2007b).
</bodyText>
<subsectionHeader confidence="0.996094">
2.1 Dialogue acts
</subsectionHeader>
<bodyText confidence="0.9859174">
The users and the two agents perform several dia-
logue acts based on the dialogue context.
Present-hint: The quizmaster agent presents
hints one by one (lines 1, 7, 8, and 13) in the
sample dialogue shown in Figure 1.
Give-ans: Users and the peer agent give answers
(lines 3, 9, and 14).
Show-difficulty: Users and the peer agent offer
opinions about the quiz difficulty (lines 2, 5,
6, and 12).
</bodyText>
<footnote confidence="0.91019">
1http://ja.wikipedia.org/
</footnote>
<bodyText confidence="0.999804727272727">
Evaluate-ans: When the answer is wrong, the
quizmaster agent evaluates the answer based
on the person-name similarity score (Hi-
gashinaka et al., 2007a) and utters ”very
close!,” ”close!,” ”a little close!,” ”a little far,”
”far,” or ”not even close!” (lines 4 and 10).
Complete-quiz-with-success: When the right
answer is given, the quizmaster agent in-
forms the dialogue participants that the
current quiz is completed (line 15).
Complete-quiz-with-failure: If all hints have
been generated and no right answer is given,
the quizmaster agent gives the right answer,
and the current quiz is completed.
Feedback-on-wrong-ans: Users and the peer
agent give feedback when their own or the
other’s answers are wrong during the current
quiz (line 11).
Feedback-on-success: Users and the peer agent
give feedback when their own or the other’s
answers are right and the current quiz session
is completed (lines 16 and 17).
Feedback-on-failure: Users and the peer agent
give feedback when the current quiz is com-
pleted without the right answer.
Address-hearer: Users and the two agents spec-
ify an intended addressee by uttering the
other’s name (lines 16 and 17).
When a user utterance is input, the system sep-
arates it into word tokens using a Japanese mor-
phological analyzer and converts it into dialogue
acts using hand-crafted grammar. The system can
recognize 120,000 proper names of persons.
</bodyText>
<subsectionHeader confidence="0.999636">
2.2 Utterance generation
</subsectionHeader>
<bodyText confidence="0.999922909090909">
Surface realization forms were prepared for each
dialogue act by the agents. Agent utterances are
generated by randomly selecting one of the forms.
Some agent dialogue acts can be generated
with emotional expressions. Agent emotional ex-
pressions are categorized into empathic and self-
oriented ones (Brave et al., 2005). The agent
self-oriented emotional expressions (self-oriented
expressions) are oriented to their own state, and
the agent empathic expressions are oriented to the
other’s state and are congruent with the other’s
</bodyText>
<page confidence="0.990105">
219
</page>
<table confidence="0.999913714285714">
Dialog act Emotion Expressions
Show- EMP Difficult for me, too.
difficulty
Show- SELF I don’t remember.
difficulty That’s so frustrating.
Show- NONE I don’t know.
difficulty
Feedback- EMP You’re right. I’m
on-success happy for you.
Feedback- SELF I’m really glad I got
on-success the correct answer.
Feedback- NONE You’re right / I’m
on-success right.
Feedback- EMP Too bad you didn’t
on-failure know the right an-
swer.
Feedback- SELF I’m disappointed
on-failure that I didn’t know
the right answer.
Feedback- NONE I/You didn’t know
on-failure the right answer.
</table>
<tableCaption confidence="0.997675">
Table 1: Examples of agent expressions. EMP
</tableCaption>
<bodyText confidence="0.9938251">
shows empathic expressions, SELF shows self-
oriented expressions, and NONE shows neutral
expressions when neither emotion is present.
welfare. As explained in 3.1, we prepared differ-
ent experimental conditions to determine the pres-
ence/absence of agent empathic and self-oriented
expressions. Based on the conditions, we con-
trolled the agent emotional expressions. Table 1
shows examples of agent empathic, self-oriented,
and neutral expressions.
</bodyText>
<subsectionHeader confidence="0.9969">
2.3 Dialogue management
</subsectionHeader>
<bodyText confidence="0.998725181818182">
The system maintains a dialogue state in which
the history of the participant’s dialogue acts is
recorded with the time of each act. We prepared
preconditions of each dialogue act by the agents.
For example, the quizmaster agent’s Evaluate-
ans can be executed after the users or the peer
agent provides a wrong answer. The peer agent’s
Feedback-on-success can be executed after the
quizmaster agent performs Complete-quiz-with-
success. We also used the following turn-taking
rules:
</bodyText>
<footnote confidence="0.520016333333333">
1. Either agent must talk when neither the users
nor the agents make utterances within a given
time (4 sec.).
</footnote>
<table confidence="0.999774">
Condition Peer Empathic Self-
agent oriented
(0) Absent Absent Absent
Present Absent Absent
Present Present Absent
Present Absent Present
Present Present Present
</table>
<tableCaption confidence="0.672346333333333">
Table 2: Experimental conditions based on pres-
ence/absence of peer agent and agent empathic
and self-oriented expressions
</tableCaption>
<listItem confidence="0.827904166666667">
2. Agents must not talk for a given time (0.5
sec.) after the others talk.
3. The quizmaster agent must move to the next
hint when neither the users nor the peer agent
give a correct answer within a given time (30
sec.).
</listItem>
<bodyText confidence="0.999169">
Based on the dialogue state, the preconditions
of the dialogue acts and the turn-taking rules, the
system chooses the next speaker and its dialogue
act.
</bodyText>
<sectionHeader confidence="0.999885" genericHeader="method">
3 Experiment
</sectionHeader>
<subsectionHeader confidence="0.999532">
3.1 Experimental conditions
</subsectionHeader>
<bodyText confidence="0.999760523809524">
To evaluate the effects of the presence of the peer
agent and the agent emotional expressions, we
prepared five systems under different experimen-
tal conditions, (0), (1), (2), (3), and (4), based on
the presence/absence of the peer agent and agent
empathic and self-oriented expressions. They are
shown in Table 2. In condition (0), the peer agent
was absent, and only the quizmaster agent was
present. In other conditions, both the quizmas-
ter and peer agents were present. In conditions
(0) and (1), neither empathic nor self-oriented ex-
pressions were exhibited. In condition (2), only
empathic expressions were exhibited. In condition
(3), only self-oriented expressions were exhibited.
In condition (4), both empathic and self-oriented
expressions were exhibited.
We evaluated the effects of the presence of the
peer agent by comparing conditions (0) and (1).
We evaluated the effects of agent empathic and
self-oriented expressions by comparing conditions
(1), (2), (3), and (4).
</bodyText>
<subsectionHeader confidence="0.992455">
3.2 Measures
</subsectionHeader>
<bodyText confidence="0.9998655">
We used three measures: user satisfaction, user
opinions about the peer agent, and the number of
</bodyText>
<page confidence="0.992601">
220
</page>
<table confidence="0.9985139375">
Questionnaire items
Q1 Did you want to converse with this sys-
tem again? (Willingness to engage in di-
alogue)
Q2 Was the dialogue enjoyable? (Pleasant-
ness of dialogue)
Q3 Did you feel satisfied using the dialogue
system? (Satisfaction of system usage)
Q4 Was the peer agent friendly? (Agent’s
closeness)
Q5 Did you feel that the peer agent cared
about you? (Agent’s caring)
Q6 Was the peer agent likable? (Agent’s lik-
ability)
Q7 Did the peer agent support you?
(Agent’s support)
</table>
<tableCaption confidence="0.995953">
Table 3: Questionnaire items to evaluate user sat-
</tableCaption>
<bodyText confidence="0.98380027027027">
isfaction (Q1, Q2, and Q3) and user opinions
about the peer agent (Q4, Q5, Q6, and Q7)
user utterances. Among these measures, we re-
garded the number of user utterances as an ob-
jective measure to evaluate communication activa-
tion. User satisfaction and opinions about the peer
agent are subjective measures based on the ques-
tionnaires (ten-point Likert scale). Table 3 shows
the questionnaires used in the experiment. We ex-
pected that a high level of user satisfaction and
positive opinions about the peer agent would lead
to a high level of user engagement, which would
promote user utterances.
User satisfaction was evaluated from different
perspectives with three questions: Q1, Q2, and
Q3. Q1 focused on user willingness to engage in
the dialogue; Q2 focused on the user experience
of the dialogue’s pleasantness; Q3 focused on user
satisfaction with the system. We evaluated user
satisfaction with averages of the ratings of Q1, Q2,
and Q3. Using the averaged ratings of Likert ques-
tions allows us to apply such parametric statistical
tests as a multi-factor ANOVA since the summed
or averaged responses to Likert questions tend to
follow a normal distribution.
User opinions about the peer agent were evalu-
ated in terms of how the user perceived the peer
agent’s closeness (Q4), its caring (Q5), its likabil-
ity (Q6), and its support (Q7). We evaluated user
opinions about the peer agent with the averaged
ratings of these items. Previous studies showed
that empathic behaviors exhibited by an agent im-
proved user opinions about the agent in a Black-
jack scenario (Brave et al., 2005) and in a social
dialogue between a single user and an agent (Hi-
gashinaka et al., 2008). We examined these items
in multi-party dialogues with flexible turn-taking.
</bodyText>
<subsectionHeader confidence="0.9982">
3.3 Procedure
</subsectionHeader>
<bodyText confidence="0.999971227272727">
We recruited and paid 64 Japanese adults (32
males and 32 females) for their participation. The
mean ages of the male and female groups were
32.0 and 36.2, respectively (male group: SD=9.2
, min=22, max=59, female group: SD=9.6,
min=20, max=50). The participants were divided
into 32 pairs of the same gender: 16 pairs of males
and 16 pairs of females. The participants in each
pair were unacquainted.
The experiment had a within-participants de-
sign. Each pair of participants successively en-
gaged in dialogues using the five systems under
different experimental conditions. The order of
using the systems was counter-balanced to prevent
order effect.
Before starting the experiment, the participants
were informed that, after completing a dialogue
with each system, they would fill out question-
naires. The questionnaires on user opinions about
the peer agent were used only when it was present
(conditions (1), (2), (3), and (4)). The participants
were also told that the agents were computer pro-
grams and not human participants. During the ex-
periment, each pair of participants was seated in
separate rooms in front of a computer display, a
keyboard, and a mouse, and they could only com-
municate with each other through the system.
In the dialogue with each system, five ”Who
is this?” quizzes about famous people were pre-
sented. The quiz subjects were chosen so that
the difficulty level of the quizzes was approxi-
mately the same in all the systems. For this pur-
pose, we first sorted people in Wikipedia in de-
scending order by their PageRank TM score based
on Wikipedia’s hyper-link structure. We then ex-
tracted the top-50 people and divided them from
the top into five groups of 10. Next we randomly
selected five people from each group to make
five sets of five people of approximately identical
PageRank scores. Each set of five people was used
for quizzes in each system.
On average, a pair of participants took 18 min-
utes to complete a dialogue with each system. The
number of hints that were actually presented in a
</bodyText>
<page confidence="0.997861">
221
</page>
<figureCaption confidence="0.995982">
Figure 2: User satisfaction Figure 3: User ratings of peer agent
</figureCaption>
<bodyText confidence="0.879991">
quiz averaged 7.5.
</bodyText>
<sectionHeader confidence="0.999973" genericHeader="evaluation">
4 Results
</sectionHeader>
<subsectionHeader confidence="0.999725">
4.1 User satisfaction
</subsectionHeader>
<bodyText confidence="0.999919945945946">
For questions Q1, Q2, and Q3, Cronbach’s alpha
was 0.83, which justified combining these items
into a single index. Therefore we evaluated user
satisfaction with averages of the ratings of these
items. Figure 2 shows user satisfaction under each
experimental condition.
To evaluate the effect of the peer agent’s pres-
ence on user satisfaction, we compared conditions
(0) and (1). The F-test results showed that vari-
ances were assumed to be equal across groups
(p &gt; 0.2), and the Kolmogorov-Smirnov test re-
sults showed that the assumption of normality was
satisfied (p &gt; 0.6). By applying the paired t-test
to both the male and female groups, we found that
the peer agent’s presence significantly improved
user satisfaction (male group: t(31) = 4.2,p &lt;
0.001, female group: t(31) = 2.8,p &lt; 0.008).
To evaluate the effect of the empathic and self-
oriented expressions exhibited by the agents on
user satisfaction, we compared conditions (1),
(2), (3), and (4). A three-factor ANOVA was
conducted with two within-participant factors of
empathic and self-oriented expressions and one
between-participant factor of gender. The F-test
for the homogeneity of variances (p &gt; 0.1) and
the Kolmogorov-Smirnov normality test (p &gt; 0.1)
showed that the data met the ANOVA assump-
tions. As a result of the ANOVA, a signifi-
cant main effect was found for empathic expres-
sions with respect to user satisfaction, F(1, 62) =
92.7, p &lt; 0.001. No significant main effects were
found for either self-oriented expressions or gen-
der, and there were no significant interactions.
These results showed that the peer agent’s pres-
ence and the agent empathic expressions signif-
icantly improved user satisfaction in quiz-style
multi-party dialogues.
</bodyText>
<subsectionHeader confidence="0.999326">
4.2 User opinions about the peer agent
</subsectionHeader>
<bodyText confidence="0.999953137931034">
For questions Q4, Q5, Q6, and Q7, Cronbach’s
alpha was 0.92, which justified combining these
items into a single index. Therefore we evaluated
user opinions about the peer agent with the aver-
aged ratings of these items under each experimen-
tal condition. Figure 3 shows the user ratings of
the peer agent under each condition.
To evaluate the effect of agent empathic and
self-oriented expressions on the user ratings of the
peer agent, we compared conditions (1), (2), (3)
and (4). A three-factor ANOVA was conducted
with two within-participant factors of empathic
and self-oriented expressions and one between-
participant factor of gender. The F-test for the
homogeneity of variances (p &gt; 0.3) and the
Kolmogorov-Smirnov normality test (p &gt; 0.2)
showed that the data met the ANOVA assump-
tions. As a result of the ANOVA, a significant
main effect was found for empathic expressions
with respect to the user ratings of the peer agent,
F(1,62) = 77.4,p &lt; 0.001. There was a
moderate main effect for self-oriented expressions
with respect to the user ratings of the peer agent,
F (1, 62) = 4.38, p &lt; 0.04. There were no sig-
nificant main effects for gender, and there were no
significant interactions.
These results showed that agent empathic ex-
pressions significantly improved user ratings of
the peer agent in quiz-style multi-party dialogues.
</bodyText>
<page confidence="0.996373">
222
</page>
<figureCaption confidence="0.996071">
Figure 4: User utterances per quiz hint
</figureCaption>
<subsectionHeader confidence="0.996879">
4.3 Number of user utterances
</subsectionHeader>
<bodyText confidence="0.999801971428572">
Figure 4 shows the number of user utterances per
quiz hint under each condition.
To evaluate the effect of the peer agent’s pres-
ence on the number of user utterances per quiz
hint, we compared conditions (0) and (1). Based
on the F-test and the Kolmogorov-Smirnov test,
the assumptions of variance homogeneity (p &gt;
0.6) and normality (p &gt; 0.5) were met. By apply-
ing the paired t-test to both the male and female
groups, we found that the presence of the peer
agent significantly increased the number of user
utterances per hint (male group: t(31) = 3.1, p &lt;
0.004, female group: t(31) = 5.6,p &lt; 0.001).
To evaluate the effect of empathic and self-
oriented expressions by agents on the number
of user utterances, we compared conditions (1),
(2), (3), and (4). A three-factor ANOVA was
conducted with two within-participant factors of
empathic and self-oriented expressions and one
between-participant factor of gender. The F-test
for the homogeneity of variances (p &gt; 0.05) and
the Kolmogorov-Smirnov normality test (p &gt; 0.6)
showed that the data met the ANOVA assump-
tions. As a result of the ANOVA, a significant
main effect was found for empathic expressions
with respect to the number of user utterances,
F(1, 62) = 18.9,p &lt; 0.001. No significant main
effects were found for either self-oriented expres-
sions or gender, and there were no significant in-
teractions.
These results showed that the peer agent’s pres-
ence and agent empathic expressions increased
the number of user utterances and stimulated hu-
man communication in quiz-style multi-party dia-
logues.
</bodyText>
<sectionHeader confidence="0.998986" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999980166666667">
This paper experimentally analyzed how conver-
sational agents stimulate human communication
in thought-evoking multi-party dialogues between
multi-users and multi-agents. As an example of
such multi-party dialogue, we focused on quiz-
style multi-party dialogues between two users and
two agents. We investigated how a peer agent’s
presence and agent emotional expressions influ-
enced user satisfaction, the user ratings of the peer
agent, and the number of user utterances. The
user ratings of the peer agent included user’s per-
ceived closeness, likability and caring from the
peer agent, and the user’s feeling of being sup-
ported by the peer agent.
The experiment results showed that the peer
agent’s presence significantly improved user sat-
isfaction and increased the number of user utter-
ances. We also found significant effects that agent
empathic expressions improved user satisfaction
and user positive ratings of the peer agent and that
they further increased the number of user utter-
ances. These results indicate that employing a peer
agent and agent empathic behaviors in thought-
evoking multi-party dialogues will stimulate inter-
action among people in computer-mediated com-
munication. Our findings will be useful for a
broader class of applications such as educational
agents and community facilitators.
Many directions for future work remain. First,
we plan to extend our work to deal with various
modalities such as speech, gestures, body posture,
facial expressions, and the direction of eye gazes
to investigate the effects of agent representation
(embodied or disembodied) and other modalities
in thought-evoking multi-party dialogues. Second,
we will analyze how agent behaviors influence
users and dialogues in more detail and develop a
more sophisticated dialogue management method
based on our detailed analysis. Learning optimal
dialogue management strategies in multi-party di-
alogues is a challenging research topic. Third, ex-
amining the relationship between user personality
traits and the impact of agents on users is valuable.
Previous work reported that the effect of embodi-
ment depended on user personalities (Lee et al.,
2006). This direction is important to the stimula-
tion of multi-party interaction for therapeutic and
emotional support.
</bodyText>
<page confidence="0.998287">
223
</page>
<sectionHeader confidence="0.995865" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999862771428571">
James Allen, Donna Byron, Myroslava Dzikovska,
George Ferguson, Lucian Galescu, and Amanda
Stent. 2001. Toward conversational human-
computer interaction. AI Magazine, 22(4):27–37.
Joseph Bates. 1994. The role of emotion in believable
agents. Communications of the ACM, 37(7):122–
125.
Timothy W. Bickmore and Rosalind W. Picard. 2005.
Establishing and maintaining long-term human-
computer relationships. ACM Transactions on
Computer-Human Interaction, 12(2):293–327.
Scott Brave, Clifford Nass, and Kevin Hutchinson.
2005. Computers that care: investigating the effects
of orientation of emotion exhibited by an embodied
computer agent. International Journal of Human-
Computer Studies, 62(2):161–178.
Justine Cassell, Joseph Sullivan, Scott Prevost, and
Elizabeth Churchill, editors. 2000. Embodied Con-
versational Agents. MIT Press, Cambridge, MA.
Chih-Yueh Chou, Tak-Wai Chan, and Chi-Jen Lin.
2003. Redefining the learning companion: the past,
present, and future of educational agents. Comput-
ers &amp; Education, 40(3):255–269.
Scotty D. Craig, Barry Gholson, Matthew Ventura,
Arthur C. Graesser, and the Tutoring Research
Group. 2000. Overhearing dialogues and mono-
logues in virtual tutoring sessions: Effects on ques-
tioning and vicarious learning. International Jour-
nal of Artificial Intelligence in Education, 11:242–
253.
Patrick Gebhard, Martin Klesen, and Thomas Rist.
2004. Coloring multi-character conversations
through the expression of emotions. In Lecture
Notes in Computer Science (Tutorial and Research
Workshop on Affective Dialogue Systems), volume
3068, pages 128–141.
Ryuichiro Higashinaka, Kohji Dohsaka, Shigeaki
Amano, and Hideki Isozaki. 2007a. Effects of quiz-
style information presentation on user understand-
ing. In Proceedings of the 8th Annual Conference
of the International Speech Communication Associ-
ation, pages 2725–2728.
Ryuichiro Higashinaka, Kohji Dohsaka, and Hideki
Isozaki. 2007b. Learning to rank definitions to
generate quizzes for interactive information presen-
tation. In Proceedings of the 45th Annual Meet-
ing of the Association for Computational Linguistics
(Poster Presentation), pages 117–120.
Ryuichiro Higashinaka, Kohji Dohsaka, and Hideki
Isozaki. 2008. Effects of self-disclosure and em-
pathy in human-computer dialogue. In Proceedings
of 2008 IEEE Workshop on Spoken Language Tech-
nology, pages 109–112.
Eva Hudlicka. 2003. To feel or not to feel: The role of
affect in human-computer interaction. International
Journal of Human-Computer Studies, 59(1-2):1–32.
Kwan Min Lee, Younbo Jung, Jaywoo Kim, and
Sang Ryong Kim. 2006. Are physically em-
bodied social agents better than disembodied social
agents?: Effects of embodiment, tactile interaction,
and people’s loneliness in human-robot interaction.
International Journal of Human-Computer Studies,
64(10):962–973.
Yi Liu and Yam San Chee. 2004. Intelligent pedagog-
ical agents with multiparty interaction support. In
Proceedings of International Conference on Intelli-
gent Agent Technology, pages 134–140.
Heidy Maldonado, Jong-Eun Roselyn Lee, Scott
Brave, Cliff Nass, Hiroshi Nakajima, Ryota Ya-
mada, Kimihiko Iwamura, and Yasunori Morishima.
2005. We learn better together: enhancing elearn-
ing with emotional characters. In Proceedings of the
2005 Conference on Computer Support for Collab-
orative Learning, pages 408–417.
Rosalind W. Picard. 1997. Affective Computing. MIT
Press, Cambridge, MA.
Helmut Prendinger and Mitsuru Ishizuka, editors.
2004. Life-Like Characters: Tools, Affective Func-
tions, and Applications. Springer, Berlin.
Helmut Prendinger, Junichiro Mori, and Mitsuru
Ishizuka. 2005. Using human physiology to eval-
uate subtle expressivity of a virtual quizmaster in
a mathematical game. International Journal of
Human-Computer Studies, 62(2):231–245.
Keith Stenning, Jean McKendree, John Lee, Richard
Cox, Finbar Dineen, and Terry Mayes. 1999. Vi-
carious learning from educational dialogue. In Pro-
ceedings of the 1999 Conference on Computer Sup-
port for Collaborative Learning, pages 341–347.
David Traum and Jeff Rickel. 2002. Embodied agents
for multi-party dialogue in immersive virtual worlds.
In Proceedings of the 1st International Joint Confer-
ence on. Autonomous Agents and Multi-Agent Sys-
tems, pages 766–773.
Jun Zheng, Xiang Yuan, and Yam San Chee. 2005.
Designing multiparty interaction support in Elva, an
embodied tour guide. In Proceedings of the 4th In-
ternational Joint Conference on Autonomous Agents
and Multiagent Systems, pages 929–936.
Victor Zue, Stephanie Seneff, Joseph Polifroni,
Michael Phillips, Christine Pao, David Goodine,
David Goddeau, and James Glass. 1994. PEGA-
SUS: a spoken dialogue interface for on-line air
travel planning. Speech Communication, 15:331–
340.
</reference>
<page confidence="0.998706">
224
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.238360">
<title confidence="0.9957225">Effects of Conversational Agents on Human in Thought-Evoking Multi-Party Dialogues</title>
<author confidence="0.93312">Kohji</author>
<affiliation confidence="0.9862425">NTT Communication Science NTT</affiliation>
<address confidence="0.916411">2-4, Hikaridai, Kyoto 619-0237, Japan</address>
<email confidence="0.609913">Ryota</email>
<affiliation confidence="0.877931">Graduate School Information Science and Osaka University, 1-1</affiliation>
<address confidence="0.858379">Suita, Osaka 565-0871, Japan</address>
<author confidence="0.928439">Higashinaka Minami</author>
<affiliation confidence="0.962049">NTT Communication Science Laboratories, NTT</affiliation>
<address confidence="0.904501">2-4, Hikaridai, Seika-cho, Kyoto 619-0237,</address>
<abstract confidence="0.991932384615385">This paper presents an experimental study that analyzes how conversational agents activate human communication in thought-evoking multi-party dialogues between multi-users and multi-agents. A thought-evoking dialogue, which is a kind of interaction in which agents act on user willingness to provoke user thinking, has the potential to stimulate multi-party interaction. In this paper, we focus on quiz-style multi-party dialogues between two users and two agents as an example of a thought-evoking multi-party dialogue. The experiment results showed that the presence of a peer agent significantly improved user satisfaction and increased the number of user utterances. We also found that agent empathic expressions significantly improved user satisfaction, raised user ratings of a peer agent, and increased user utterances. Our findings will be useful for stimulating multi-party communication in various applications such as educational agents and community facilitators.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allen</author>
<author>Donna Byron</author>
<author>Myroslava Dzikovska</author>
<author>George Ferguson</author>
<author>Lucian Galescu</author>
<author>Amanda Stent</author>
</authors>
<title>Toward conversational humancomputer interaction.</title>
<date>2001</date>
<journal>AI Magazine,</journal>
<volume>22</volume>
<issue>4</issue>
<contexts>
<context position="1733" citStr="Allen et al., 2001" startWordPosition="235" endWordPosition="238">at the presence of a peer agent significantly improved user satisfaction and increased the number of user utterances. We also found that agent empathic expressions significantly improved user satisfaction, raised user ratings of a peer agent, and increased user utterances. Our findings will be useful for stimulating multi-party communication in various applications such as educational agents and community facilitators. 1 Introduction Conversational interfaces including dialogue systems and conversational agents have been typically used as a single interface to a single user (Zue et al., 1994; Allen et al., 2001; Cassell et al., 2000). On the other hand, a new area of research in conversational interfaces is dealing with multi-party interaction (Traum and Rickel, 2002; Liu and Chee, 2004; Zheng et al., 2005). Multiparty conversational interfaces have been applied to such tasks as training decision-making in team activities (Traum and Rickel, 2002), collaborative learning (Liu and Chee, 2004), and coordinating and facilitating interaction in a casual social group (Zheng et al., 2005). The advantage of such multi-party dialogues over two-party cases is that the multi-party case encourages group interac</context>
</contexts>
<marker>Allen, Byron, Dzikovska, Ferguson, Galescu, Stent, 2001</marker>
<rawString>James Allen, Donna Byron, Myroslava Dzikovska, George Ferguson, Lucian Galescu, and Amanda Stent. 2001. Toward conversational humancomputer interaction. AI Magazine, 22(4):27–37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Bates</author>
</authors>
<title>The role of emotion in believable agents.</title>
<date>1994</date>
<journal>Communications of the ACM,</journal>
<volume>37</volume>
<issue>7</issue>
<pages>125</pages>
<contexts>
<context position="5762" citStr="Bates, 1994" startWordPosition="858" endWordPosition="859"> communication with a peer agent but also from overhearing dialogues between a peer agent and a tutor. Learning by observing others who are learning is called vicarious learning and positively affects user performance (Craig et al., 2000; Stenning et al., 1999). To the best of our knowledge, detailed experimental investigations on the effect of a peer agent on communication activation have not been reported in multi-party dialogues between multi-users and multi-agents, which are our main concern in this paper. The topic of emotion has gained widespread attention in human-computer interaction (Bates, 1994; Picard, 1997; Hudlicka, 2003; Prendinger and Ishizuka, 2004). The impact of an agent’s emotional behaviors on users has also recently been studied (Brave et al., 2005; Maldonado et al., 2005; Prendinger et al., 2005). However, these previous studies addressed scenario-based interaction in which a user and an agent acted with predetermined timing. In this paper, we investigate the impact of agent emotional expressions on users in multi-party dialogues in which multiple users and agents can make utterances with more flexible timing. Resembling work by Brave et al. (2005), we classify agent emo</context>
</contexts>
<marker>Bates, 1994</marker>
<rawString>Joseph Bates. 1994. The role of emotion in believable agents. Communications of the ACM, 37(7):122– 125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy W Bickmore</author>
<author>Rosalind W Picard</author>
</authors>
<title>Establishing and maintaining long-term humancomputer relationships.</title>
<date>2005</date>
<journal>ACM Transactions on Computer-Human Interaction,</journal>
<volume>12</volume>
<issue>2</issue>
<contexts>
<context position="6713" citStr="Bickmore and Picard, 2005" startWordPosition="999" endWordPosition="1002">th predetermined timing. In this paper, we investigate the impact of agent emotional expressions on users in multi-party dialogues in which multiple users and agents can make utterances with more flexible timing. Resembling work by Brave et al. (2005), we classify agent emotional expressions into empathic and self-oriented ones and investigate their impact on users in a thought-evoking multi-party dialogue system. As stated above, Brave et al. (2005) addressed scenario-based Black-jack interaction, but we deal with multi-party dialogues that enable more flexible turn-taking. Previous studies (Bickmore and Picard, 2005; Higashinaka et al., 2008) showed that agent empathic expressions have a positive psychological impact upon users, but they only examined two-party cases. Although Traum et al. (2002) and Gebhard et al. (2004) exploited the role of agent emotion in multi-party dialogues, they did not adequately examine the effects of agent emotion on communication activation by experiment. In this work, we deal with disembodied agents and focus on their linguistic behaviors. We believe that our results are useful for designing embodied conversational agents using other modalities. This paper presents an exper</context>
</contexts>
<marker>Bickmore, Picard, 2005</marker>
<rawString>Timothy W. Bickmore and Rosalind W. Picard. 2005. Establishing and maintaining long-term humancomputer relationships. ACM Transactions on Computer-Human Interaction, 12(2):293–327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Brave</author>
<author>Clifford Nass</author>
<author>Kevin Hutchinson</author>
</authors>
<title>Computers that care: investigating the effects of orientation of emotion exhibited by an embodied computer agent.</title>
<date>2005</date>
<journal>International Journal of HumanComputer Studies,</journal>
<volume>62</volume>
<issue>2</issue>
<contexts>
<context position="5930" citStr="Brave et al., 2005" startWordPosition="882" endWordPosition="885">carious learning and positively affects user performance (Craig et al., 2000; Stenning et al., 1999). To the best of our knowledge, detailed experimental investigations on the effect of a peer agent on communication activation have not been reported in multi-party dialogues between multi-users and multi-agents, which are our main concern in this paper. The topic of emotion has gained widespread attention in human-computer interaction (Bates, 1994; Picard, 1997; Hudlicka, 2003; Prendinger and Ishizuka, 2004). The impact of an agent’s emotional behaviors on users has also recently been studied (Brave et al., 2005; Maldonado et al., 2005; Prendinger et al., 2005). However, these previous studies addressed scenario-based interaction in which a user and an agent acted with predetermined timing. In this paper, we investigate the impact of agent emotional expressions on users in multi-party dialogues in which multiple users and agents can make utterances with more flexible timing. Resembling work by Brave et al. (2005), we classify agent emotional expressions into empathic and self-oriented ones and investigate their impact on users in a thought-evoking multi-party dialogue system. As stated above, Brave e</context>
<context position="11976" citStr="Brave et al., 2005" startWordPosition="1852" endWordPosition="1855">ering the other’s name (lines 16 and 17). When a user utterance is input, the system separates it into word tokens using a Japanese morphological analyzer and converts it into dialogue acts using hand-crafted grammar. The system can recognize 120,000 proper names of persons. 2.2 Utterance generation Surface realization forms were prepared for each dialogue act by the agents. Agent utterances are generated by randomly selecting one of the forms. Some agent dialogue acts can be generated with emotional expressions. Agent emotional expressions are categorized into empathic and selforiented ones (Brave et al., 2005). The agent self-oriented emotional expressions (self-oriented expressions) are oriented to their own state, and the agent empathic expressions are oriented to the other’s state and are congruent with the other’s 219 Dialog act Emotion Expressions Show- EMP Difficult for me, too. difficulty Show- SELF I don’t remember. difficulty That’s so frustrating. Show- NONE I don’t know. difficulty Feedback- EMP You’re right. I’m on-success happy for you. Feedback- SELF I’m really glad I got on-success the correct answer. Feedback- NONE You’re right / I’m on-success right. Feedback- EMP Too bad you didn’</context>
<context position="17766" citStr="Brave et al., 2005" startWordPosition="2771" endWordPosition="2774">ngs of Likert questions allows us to apply such parametric statistical tests as a multi-factor ANOVA since the summed or averaged responses to Likert questions tend to follow a normal distribution. User opinions about the peer agent were evaluated in terms of how the user perceived the peer agent’s closeness (Q4), its caring (Q5), its likability (Q6), and its support (Q7). We evaluated user opinions about the peer agent with the averaged ratings of these items. Previous studies showed that empathic behaviors exhibited by an agent improved user opinions about the agent in a Blackjack scenario (Brave et al., 2005) and in a social dialogue between a single user and an agent (Higashinaka et al., 2008). We examined these items in multi-party dialogues with flexible turn-taking. 3.3 Procedure We recruited and paid 64 Japanese adults (32 males and 32 females) for their participation. The mean ages of the male and female groups were 32.0 and 36.2, respectively (male group: SD=9.2 , min=22, max=59, female group: SD=9.6, min=20, max=50). The participants were divided into 32 pairs of the same gender: 16 pairs of males and 16 pairs of females. The participants in each pair were unacquainted. The experiment had </context>
</contexts>
<marker>Brave, Nass, Hutchinson, 2005</marker>
<rawString>Scott Brave, Clifford Nass, and Kevin Hutchinson. 2005. Computers that care: investigating the effects of orientation of emotion exhibited by an embodied computer agent. International Journal of HumanComputer Studies, 62(2):161–178.</rawString>
</citation>
<citation valid="true">
<title>Embodied Conversational Agents.</title>
<date>2000</date>
<editor>Justine Cassell, Joseph Sullivan, Scott Prevost, and Elizabeth Churchill, editors.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>2000</marker>
<rawString>Justine Cassell, Joseph Sullivan, Scott Prevost, and Elizabeth Churchill, editors. 2000. Embodied Conversational Agents. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Yueh Chou</author>
<author>Tak-Wai Chan</author>
<author>Chi-Jen Lin</author>
</authors>
<title>Redefining the learning companion: the past, present, and future of educational agents.</title>
<date>2003</date>
<journal>Computers &amp; Education,</journal>
<volume>40</volume>
<issue>3</issue>
<contexts>
<context position="4992" citStr="Chou et al., 2003" startWordPosition="737" endWordPosition="740">a single user and a computer, a quiz-style dialogue improved user understanding and willingness to engage in the interaction. In this paper, we focus on a quiz-style information presentation multi-party dialogue (hereafter quiz-style multi-party dialogue) as an example of a thought-evoking multi-party dialogue. A peer agent acts as a peer of the users and participates in the interactions in the same way that the users do. We are interested in the peer agent’s role in quiz-style multi-party dialogues since the positive effects of a peer agent on users have been shown in the educational domain (Chou et al., 2003; Maldonado et al., 2005), which is a promising application area for quiz-style dialogues. In the educational domain, a user could benefit not only from direct communication with a peer agent but also from overhearing dialogues between a peer agent and a tutor. Learning by observing others who are learning is called vicarious learning and positively affects user performance (Craig et al., 2000; Stenning et al., 1999). To the best of our knowledge, detailed experimental investigations on the effect of a peer agent on communication activation have not been reported in multi-party dialogues betwe</context>
</contexts>
<marker>Chou, Chan, Lin, 2003</marker>
<rawString>Chih-Yueh Chou, Tak-Wai Chan, and Chi-Jen Lin. 2003. Redefining the learning companion: the past, present, and future of educational agents. Computers &amp; Education, 40(3):255–269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scotty D Craig</author>
<author>Barry Gholson</author>
<author>Matthew Ventura</author>
<author>Arthur C Graesser</author>
</authors>
<title>and the Tutoring Research Group.</title>
<date>2000</date>
<journal>International Journal of Artificial Intelligence in Education,</journal>
<volume>11</volume>
<pages>253</pages>
<contexts>
<context position="5388" citStr="Craig et al., 2000" startWordPosition="801" endWordPosition="804">he same way that the users do. We are interested in the peer agent’s role in quiz-style multi-party dialogues since the positive effects of a peer agent on users have been shown in the educational domain (Chou et al., 2003; Maldonado et al., 2005), which is a promising application area for quiz-style dialogues. In the educational domain, a user could benefit not only from direct communication with a peer agent but also from overhearing dialogues between a peer agent and a tutor. Learning by observing others who are learning is called vicarious learning and positively affects user performance (Craig et al., 2000; Stenning et al., 1999). To the best of our knowledge, detailed experimental investigations on the effect of a peer agent on communication activation have not been reported in multi-party dialogues between multi-users and multi-agents, which are our main concern in this paper. The topic of emotion has gained widespread attention in human-computer interaction (Bates, 1994; Picard, 1997; Hudlicka, 2003; Prendinger and Ishizuka, 2004). The impact of an agent’s emotional behaviors on users has also recently been studied (Brave et al., 2005; Maldonado et al., 2005; Prendinger et al., 2005). Howeve</context>
</contexts>
<marker>Craig, Gholson, Ventura, Graesser, 2000</marker>
<rawString>Scotty D. Craig, Barry Gholson, Matthew Ventura, Arthur C. Graesser, and the Tutoring Research Group. 2000. Overhearing dialogues and monologues in virtual tutoring sessions: Effects on questioning and vicarious learning. International Journal of Artificial Intelligence in Education, 11:242– 253.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Gebhard</author>
<author>Martin Klesen</author>
<author>Thomas Rist</author>
</authors>
<title>Coloring multi-character conversations through the expression of emotions.</title>
<date>2004</date>
<booktitle>In Lecture Notes in Computer Science (Tutorial and Research Workshop on Affective Dialogue Systems),</booktitle>
<volume>3068</volume>
<pages>128--141</pages>
<contexts>
<context position="6923" citStr="Gebhard et al. (2004)" startWordPosition="1032" endWordPosition="1035">esembling work by Brave et al. (2005), we classify agent emotional expressions into empathic and self-oriented ones and investigate their impact on users in a thought-evoking multi-party dialogue system. As stated above, Brave et al. (2005) addressed scenario-based Black-jack interaction, but we deal with multi-party dialogues that enable more flexible turn-taking. Previous studies (Bickmore and Picard, 2005; Higashinaka et al., 2008) showed that agent empathic expressions have a positive psychological impact upon users, but they only examined two-party cases. Although Traum et al. (2002) and Gebhard et al. (2004) exploited the role of agent emotion in multi-party dialogues, they did not adequately examine the effects of agent emotion on communication activation by experiment. In this work, we deal with disembodied agents and focus on their linguistic behaviors. We believe that our results are useful for designing embodied conversational agents using other modalities. This paper presents an experimental study that analyzes how agents stimulate human communication in quiz-style multi-party dialogues between two users and two agents. We are especially interested in how the presence of a peer agent and ag</context>
</contexts>
<marker>Gebhard, Klesen, Rist, 2004</marker>
<rawString>Patrick Gebhard, Martin Klesen, and Thomas Rist. 2004. Coloring multi-character conversations through the expression of emotions. In Lecture Notes in Computer Science (Tutorial and Research Workshop on Affective Dialogue Systems), volume 3068, pages 128–141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryuichiro Higashinaka</author>
<author>Kohji Dohsaka</author>
<author>Shigeaki Amano</author>
<author>Hideki Isozaki</author>
</authors>
<title>Effects of quizstyle information presentation on user understanding.</title>
<date>2007</date>
<booktitle>In Proceedings of the 8th Annual Conference of the International Speech Communication Association,</booktitle>
<pages>2725--2728</pages>
<contexts>
<context position="3550" citStr="Higashinaka et al., 2007" startWordPosition="506" endWordPosition="509"> we exploit a new style of dialogue called thoughtevoking dialogue and experimentally investigate the impact of a peer agent’s presence and agent emotional expressions on communication activation in thought-evoking multi-party dialogues. A thought-evoking dialogue, an interaction in which agents act on the willingness of users to provoke user thinking and encourage involvement in the dialogue, has the potential to activate interaction among participants in multi-party dialogues. Previous work proposed a quiz-style information presentation dialogue system (hereafter quizstyle dialogue system) (Higashinaka et al., 2007a) that is regarded as a kind of thought-evoking dialogue system. This system conveys contents as biographical facts of famous people through quizstyle interaction with users by creating a ”Who is this?” quiz and individually presenting hints. Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 217–224, Queen Mary University of London, September 2009. c�2009 Association for Computational Linguistics 217 The hints are automatically created from the biographical facts of people and ordered based on the difficulty naming the people e</context>
<context position="9801" citStr="Higashinaka et al., 2007" startWordPosition="1506" endWordPosition="1509">ligraphy. 14 Mary Natsume Soseki. 15 Whowho That’s right. Wonderful. 16 Kinoko Mary, excellent. I’m happy for you. 17 Jane Mary, that’s the right answer. Good job. Figure 1: Sample dialogue Figure 1 shows a sample dialogue. Mary and Jane are human users. Whowho is the quizmaster agent, and Kinoko is the peer agent. Quizmaster agent Whowho presents hints in lines 1, 7, 8, and 13. Users Mary and Jane and peer agent Kinoko give answers in lines 3, 9, and 14. The hints were automatically created using biographical facts (in Japanese) of people in Wikipedia 1 based on a previously reported method (Higashinaka et al., 2007b). 2.1 Dialogue acts The users and the two agents perform several dialogue acts based on the dialogue context. Present-hint: The quizmaster agent presents hints one by one (lines 1, 7, 8, and 13) in the sample dialogue shown in Figure 1. Give-ans: Users and the peer agent give answers (lines 3, 9, and 14). Show-difficulty: Users and the peer agent offer opinions about the quiz difficulty (lines 2, 5, 6, and 12). 1http://ja.wikipedia.org/ Evaluate-ans: When the answer is wrong, the quizmaster agent evaluates the answer based on the person-name similarity score (Higashinaka et al., 2007a) and u</context>
</contexts>
<marker>Higashinaka, Dohsaka, Amano, Isozaki, 2007</marker>
<rawString>Ryuichiro Higashinaka, Kohji Dohsaka, Shigeaki Amano, and Hideki Isozaki. 2007a. Effects of quizstyle information presentation on user understanding. In Proceedings of the 8th Annual Conference of the International Speech Communication Association, pages 2725–2728.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryuichiro Higashinaka</author>
<author>Kohji Dohsaka</author>
<author>Hideki Isozaki</author>
</authors>
<title>Learning to rank definitions to generate quizzes for interactive information presentation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (Poster Presentation),</booktitle>
<pages>117--120</pages>
<contexts>
<context position="3550" citStr="Higashinaka et al., 2007" startWordPosition="506" endWordPosition="509"> we exploit a new style of dialogue called thoughtevoking dialogue and experimentally investigate the impact of a peer agent’s presence and agent emotional expressions on communication activation in thought-evoking multi-party dialogues. A thought-evoking dialogue, an interaction in which agents act on the willingness of users to provoke user thinking and encourage involvement in the dialogue, has the potential to activate interaction among participants in multi-party dialogues. Previous work proposed a quiz-style information presentation dialogue system (hereafter quizstyle dialogue system) (Higashinaka et al., 2007a) that is regarded as a kind of thought-evoking dialogue system. This system conveys contents as biographical facts of famous people through quizstyle interaction with users by creating a ”Who is this?” quiz and individually presenting hints. Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 217–224, Queen Mary University of London, September 2009. c�2009 Association for Computational Linguistics 217 The hints are automatically created from the biographical facts of people and ordered based on the difficulty naming the people e</context>
<context position="9801" citStr="Higashinaka et al., 2007" startWordPosition="1506" endWordPosition="1509">ligraphy. 14 Mary Natsume Soseki. 15 Whowho That’s right. Wonderful. 16 Kinoko Mary, excellent. I’m happy for you. 17 Jane Mary, that’s the right answer. Good job. Figure 1: Sample dialogue Figure 1 shows a sample dialogue. Mary and Jane are human users. Whowho is the quizmaster agent, and Kinoko is the peer agent. Quizmaster agent Whowho presents hints in lines 1, 7, 8, and 13. Users Mary and Jane and peer agent Kinoko give answers in lines 3, 9, and 14. The hints were automatically created using biographical facts (in Japanese) of people in Wikipedia 1 based on a previously reported method (Higashinaka et al., 2007b). 2.1 Dialogue acts The users and the two agents perform several dialogue acts based on the dialogue context. Present-hint: The quizmaster agent presents hints one by one (lines 1, 7, 8, and 13) in the sample dialogue shown in Figure 1. Give-ans: Users and the peer agent give answers (lines 3, 9, and 14). Show-difficulty: Users and the peer agent offer opinions about the quiz difficulty (lines 2, 5, 6, and 12). 1http://ja.wikipedia.org/ Evaluate-ans: When the answer is wrong, the quizmaster agent evaluates the answer based on the person-name similarity score (Higashinaka et al., 2007a) and u</context>
</contexts>
<marker>Higashinaka, Dohsaka, Isozaki, 2007</marker>
<rawString>Ryuichiro Higashinaka, Kohji Dohsaka, and Hideki Isozaki. 2007b. Learning to rank definitions to generate quizzes for interactive information presentation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (Poster Presentation), pages 117–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryuichiro Higashinaka</author>
<author>Kohji Dohsaka</author>
<author>Hideki Isozaki</author>
</authors>
<title>Effects of self-disclosure and empathy in human-computer dialogue.</title>
<date>2008</date>
<booktitle>In Proceedings of 2008 IEEE Workshop on Spoken Language Technology,</booktitle>
<pages>109--112</pages>
<contexts>
<context position="6740" citStr="Higashinaka et al., 2008" startWordPosition="1003" endWordPosition="1006"> this paper, we investigate the impact of agent emotional expressions on users in multi-party dialogues in which multiple users and agents can make utterances with more flexible timing. Resembling work by Brave et al. (2005), we classify agent emotional expressions into empathic and self-oriented ones and investigate their impact on users in a thought-evoking multi-party dialogue system. As stated above, Brave et al. (2005) addressed scenario-based Black-jack interaction, but we deal with multi-party dialogues that enable more flexible turn-taking. Previous studies (Bickmore and Picard, 2005; Higashinaka et al., 2008) showed that agent empathic expressions have a positive psychological impact upon users, but they only examined two-party cases. Although Traum et al. (2002) and Gebhard et al. (2004) exploited the role of agent emotion in multi-party dialogues, they did not adequately examine the effects of agent emotion on communication activation by experiment. In this work, we deal with disembodied agents and focus on their linguistic behaviors. We believe that our results are useful for designing embodied conversational agents using other modalities. This paper presents an experimental study that analyzes</context>
<context position="17853" citStr="Higashinaka et al., 2008" startWordPosition="2787" endWordPosition="2791"> multi-factor ANOVA since the summed or averaged responses to Likert questions tend to follow a normal distribution. User opinions about the peer agent were evaluated in terms of how the user perceived the peer agent’s closeness (Q4), its caring (Q5), its likability (Q6), and its support (Q7). We evaluated user opinions about the peer agent with the averaged ratings of these items. Previous studies showed that empathic behaviors exhibited by an agent improved user opinions about the agent in a Blackjack scenario (Brave et al., 2005) and in a social dialogue between a single user and an agent (Higashinaka et al., 2008). We examined these items in multi-party dialogues with flexible turn-taking. 3.3 Procedure We recruited and paid 64 Japanese adults (32 males and 32 females) for their participation. The mean ages of the male and female groups were 32.0 and 36.2, respectively (male group: SD=9.2 , min=22, max=59, female group: SD=9.6, min=20, max=50). The participants were divided into 32 pairs of the same gender: 16 pairs of males and 16 pairs of females. The participants in each pair were unacquainted. The experiment had a within-participants design. Each pair of participants successively engaged in dialogu</context>
</contexts>
<marker>Higashinaka, Dohsaka, Isozaki, 2008</marker>
<rawString>Ryuichiro Higashinaka, Kohji Dohsaka, and Hideki Isozaki. 2008. Effects of self-disclosure and empathy in human-computer dialogue. In Proceedings of 2008 IEEE Workshop on Spoken Language Technology, pages 109–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eva Hudlicka</author>
</authors>
<title>To feel or not to feel: The role of affect in human-computer interaction.</title>
<date>2003</date>
<journal>International Journal of Human-Computer Studies,</journal>
<pages>59--1</pages>
<contexts>
<context position="5792" citStr="Hudlicka, 2003" startWordPosition="862" endWordPosition="863">agent but also from overhearing dialogues between a peer agent and a tutor. Learning by observing others who are learning is called vicarious learning and positively affects user performance (Craig et al., 2000; Stenning et al., 1999). To the best of our knowledge, detailed experimental investigations on the effect of a peer agent on communication activation have not been reported in multi-party dialogues between multi-users and multi-agents, which are our main concern in this paper. The topic of emotion has gained widespread attention in human-computer interaction (Bates, 1994; Picard, 1997; Hudlicka, 2003; Prendinger and Ishizuka, 2004). The impact of an agent’s emotional behaviors on users has also recently been studied (Brave et al., 2005; Maldonado et al., 2005; Prendinger et al., 2005). However, these previous studies addressed scenario-based interaction in which a user and an agent acted with predetermined timing. In this paper, we investigate the impact of agent emotional expressions on users in multi-party dialogues in which multiple users and agents can make utterances with more flexible timing. Resembling work by Brave et al. (2005), we classify agent emotional expressions into empath</context>
</contexts>
<marker>Hudlicka, 2003</marker>
<rawString>Eva Hudlicka. 2003. To feel or not to feel: The role of affect in human-computer interaction. International Journal of Human-Computer Studies, 59(1-2):1–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kwan Min Lee</author>
<author>Younbo Jung</author>
<author>Jaywoo Kim</author>
<author>Sang Ryong Kim</author>
</authors>
<title>Are physically embodied social agents better than disembodied social agents?: Effects of embodiment, tactile interaction, and people’s loneliness in human-robot interaction.</title>
<date>2006</date>
<journal>International Journal of Human-Computer Studies,</journal>
<volume>64</volume>
<issue>10</issue>
<marker>Lee, Jung, Kim, Kim, 2006</marker>
<rawString>Kwan Min Lee, Younbo Jung, Jaywoo Kim, and Sang Ryong Kim. 2006. Are physically embodied social agents better than disembodied social agents?: Effects of embodiment, tactile interaction, and people’s loneliness in human-robot interaction. International Journal of Human-Computer Studies, 64(10):962–973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Liu</author>
<author>Yam San Chee</author>
</authors>
<title>Intelligent pedagogical agents with multiparty interaction support.</title>
<date>2004</date>
<booktitle>In Proceedings of International Conference on Intelligent Agent Technology,</booktitle>
<pages>134--140</pages>
<contexts>
<context position="1912" citStr="Liu and Chee, 2004" startWordPosition="265" endWordPosition="268">mproved user satisfaction, raised user ratings of a peer agent, and increased user utterances. Our findings will be useful for stimulating multi-party communication in various applications such as educational agents and community facilitators. 1 Introduction Conversational interfaces including dialogue systems and conversational agents have been typically used as a single interface to a single user (Zue et al., 1994; Allen et al., 2001; Cassell et al., 2000). On the other hand, a new area of research in conversational interfaces is dealing with multi-party interaction (Traum and Rickel, 2002; Liu and Chee, 2004; Zheng et al., 2005). Multiparty conversational interfaces have been applied to such tasks as training decision-making in team activities (Traum and Rickel, 2002), collaborative learning (Liu and Chee, 2004), and coordinating and facilitating interaction in a casual social group (Zheng et al., 2005). The advantage of such multi-party dialogues over two-party cases is that the multi-party case encourages group interaction and collaboration among human users. This advantage can be exploited to foster such human activities as student learning in more social settings and to build and maintain soc</context>
</contexts>
<marker>Liu, Chee, 2004</marker>
<rawString>Yi Liu and Yam San Chee. 2004. Intelligent pedagogical agents with multiparty interaction support. In Proceedings of International Conference on Intelligent Agent Technology, pages 134–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heidy Maldonado</author>
<author>Jong-Eun Roselyn Lee</author>
<author>Scott Brave</author>
<author>Cliff Nass</author>
<author>Hiroshi Nakajima</author>
<author>Ryota Yamada</author>
<author>Kimihiko Iwamura</author>
<author>Yasunori Morishima</author>
</authors>
<title>We learn better together: enhancing elearning with emotional characters.</title>
<date>2005</date>
<booktitle>In Proceedings of the 2005 Conference on Computer Support for Collaborative Learning,</booktitle>
<pages>408--417</pages>
<contexts>
<context position="5017" citStr="Maldonado et al., 2005" startWordPosition="741" endWordPosition="744"> computer, a quiz-style dialogue improved user understanding and willingness to engage in the interaction. In this paper, we focus on a quiz-style information presentation multi-party dialogue (hereafter quiz-style multi-party dialogue) as an example of a thought-evoking multi-party dialogue. A peer agent acts as a peer of the users and participates in the interactions in the same way that the users do. We are interested in the peer agent’s role in quiz-style multi-party dialogues since the positive effects of a peer agent on users have been shown in the educational domain (Chou et al., 2003; Maldonado et al., 2005), which is a promising application area for quiz-style dialogues. In the educational domain, a user could benefit not only from direct communication with a peer agent but also from overhearing dialogues between a peer agent and a tutor. Learning by observing others who are learning is called vicarious learning and positively affects user performance (Craig et al., 2000; Stenning et al., 1999). To the best of our knowledge, detailed experimental investigations on the effect of a peer agent on communication activation have not been reported in multi-party dialogues between multi-users and multi-</context>
</contexts>
<marker>Maldonado, Lee, Brave, Nass, Nakajima, Yamada, Iwamura, Morishima, 2005</marker>
<rawString>Heidy Maldonado, Jong-Eun Roselyn Lee, Scott Brave, Cliff Nass, Hiroshi Nakajima, Ryota Yamada, Kimihiko Iwamura, and Yasunori Morishima. 2005. We learn better together: enhancing elearning with emotional characters. In Proceedings of the 2005 Conference on Computer Support for Collaborative Learning, pages 408–417.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rosalind W Picard</author>
</authors>
<title>Affective Computing.</title>
<date>1997</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="5776" citStr="Picard, 1997" startWordPosition="860" endWordPosition="861">n with a peer agent but also from overhearing dialogues between a peer agent and a tutor. Learning by observing others who are learning is called vicarious learning and positively affects user performance (Craig et al., 2000; Stenning et al., 1999). To the best of our knowledge, detailed experimental investigations on the effect of a peer agent on communication activation have not been reported in multi-party dialogues between multi-users and multi-agents, which are our main concern in this paper. The topic of emotion has gained widespread attention in human-computer interaction (Bates, 1994; Picard, 1997; Hudlicka, 2003; Prendinger and Ishizuka, 2004). The impact of an agent’s emotional behaviors on users has also recently been studied (Brave et al., 2005; Maldonado et al., 2005; Prendinger et al., 2005). However, these previous studies addressed scenario-based interaction in which a user and an agent acted with predetermined timing. In this paper, we investigate the impact of agent emotional expressions on users in multi-party dialogues in which multiple users and agents can make utterances with more flexible timing. Resembling work by Brave et al. (2005), we classify agent emotional express</context>
</contexts>
<marker>Picard, 1997</marker>
<rawString>Rosalind W. Picard. 1997. Affective Computing. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<title>Life-Like Characters: Tools, Affective Functions, and Applications.</title>
<date>2004</date>
<editor>Helmut Prendinger and Mitsuru Ishizuka, editors.</editor>
<publisher>Springer,</publisher>
<location>Berlin.</location>
<contexts>
<context position="6923" citStr="(2004)" startWordPosition="1035" endWordPosition="1035">by Brave et al. (2005), we classify agent emotional expressions into empathic and self-oriented ones and investigate their impact on users in a thought-evoking multi-party dialogue system. As stated above, Brave et al. (2005) addressed scenario-based Black-jack interaction, but we deal with multi-party dialogues that enable more flexible turn-taking. Previous studies (Bickmore and Picard, 2005; Higashinaka et al., 2008) showed that agent empathic expressions have a positive psychological impact upon users, but they only examined two-party cases. Although Traum et al. (2002) and Gebhard et al. (2004) exploited the role of agent emotion in multi-party dialogues, they did not adequately examine the effects of agent emotion on communication activation by experiment. In this work, we deal with disembodied agents and focus on their linguistic behaviors. We believe that our results are useful for designing embodied conversational agents using other modalities. This paper presents an experimental study that analyzes how agents stimulate human communication in quiz-style multi-party dialogues between two users and two agents. We are especially interested in how the presence of a peer agent and ag</context>
</contexts>
<marker>2004</marker>
<rawString>Helmut Prendinger and Mitsuru Ishizuka, editors. 2004. Life-Like Characters: Tools, Affective Functions, and Applications. Springer, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Prendinger</author>
<author>Junichiro Mori</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>Using human physiology to evaluate subtle expressivity of a virtual quizmaster in a mathematical game.</title>
<date>2005</date>
<journal>International Journal of Human-Computer Studies,</journal>
<volume>62</volume>
<issue>2</issue>
<contexts>
<context position="5980" citStr="Prendinger et al., 2005" startWordPosition="890" endWordPosition="893"> performance (Craig et al., 2000; Stenning et al., 1999). To the best of our knowledge, detailed experimental investigations on the effect of a peer agent on communication activation have not been reported in multi-party dialogues between multi-users and multi-agents, which are our main concern in this paper. The topic of emotion has gained widespread attention in human-computer interaction (Bates, 1994; Picard, 1997; Hudlicka, 2003; Prendinger and Ishizuka, 2004). The impact of an agent’s emotional behaviors on users has also recently been studied (Brave et al., 2005; Maldonado et al., 2005; Prendinger et al., 2005). However, these previous studies addressed scenario-based interaction in which a user and an agent acted with predetermined timing. In this paper, we investigate the impact of agent emotional expressions on users in multi-party dialogues in which multiple users and agents can make utterances with more flexible timing. Resembling work by Brave et al. (2005), we classify agent emotional expressions into empathic and self-oriented ones and investigate their impact on users in a thought-evoking multi-party dialogue system. As stated above, Brave et al. (2005) addressed scenario-based Black-jack i</context>
</contexts>
<marker>Prendinger, Mori, Ishizuka, 2005</marker>
<rawString>Helmut Prendinger, Junichiro Mori, and Mitsuru Ishizuka. 2005. Using human physiology to evaluate subtle expressivity of a virtual quizmaster in a mathematical game. International Journal of Human-Computer Studies, 62(2):231–245.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keith Stenning</author>
<author>Jean McKendree</author>
<author>John Lee</author>
<author>Richard Cox</author>
<author>Finbar Dineen</author>
<author>Terry Mayes</author>
</authors>
<title>Vicarious learning from educational dialogue.</title>
<date>1999</date>
<booktitle>In Proceedings of the 1999 Conference on Computer Support for Collaborative Learning,</booktitle>
<pages>341--347</pages>
<contexts>
<context position="5412" citStr="Stenning et al., 1999" startWordPosition="805" endWordPosition="808"> users do. We are interested in the peer agent’s role in quiz-style multi-party dialogues since the positive effects of a peer agent on users have been shown in the educational domain (Chou et al., 2003; Maldonado et al., 2005), which is a promising application area for quiz-style dialogues. In the educational domain, a user could benefit not only from direct communication with a peer agent but also from overhearing dialogues between a peer agent and a tutor. Learning by observing others who are learning is called vicarious learning and positively affects user performance (Craig et al., 2000; Stenning et al., 1999). To the best of our knowledge, detailed experimental investigations on the effect of a peer agent on communication activation have not been reported in multi-party dialogues between multi-users and multi-agents, which are our main concern in this paper. The topic of emotion has gained widespread attention in human-computer interaction (Bates, 1994; Picard, 1997; Hudlicka, 2003; Prendinger and Ishizuka, 2004). The impact of an agent’s emotional behaviors on users has also recently been studied (Brave et al., 2005; Maldonado et al., 2005; Prendinger et al., 2005). However, these previous studie</context>
</contexts>
<marker>Stenning, McKendree, Lee, Cox, Dineen, Mayes, 1999</marker>
<rawString>Keith Stenning, Jean McKendree, John Lee, Richard Cox, Finbar Dineen, and Terry Mayes. 1999. Vicarious learning from educational dialogue. In Proceedings of the 1999 Conference on Computer Support for Collaborative Learning, pages 341–347.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Traum</author>
<author>Jeff Rickel</author>
</authors>
<title>Embodied agents for multi-party dialogue in immersive virtual worlds.</title>
<date>2002</date>
<booktitle>In Proceedings of the 1st International Joint Conference on. Autonomous Agents and Multi-Agent Systems,</booktitle>
<pages>766--773</pages>
<contexts>
<context position="1892" citStr="Traum and Rickel, 2002" startWordPosition="261" endWordPosition="264">ressions significantly improved user satisfaction, raised user ratings of a peer agent, and increased user utterances. Our findings will be useful for stimulating multi-party communication in various applications such as educational agents and community facilitators. 1 Introduction Conversational interfaces including dialogue systems and conversational agents have been typically used as a single interface to a single user (Zue et al., 1994; Allen et al., 2001; Cassell et al., 2000). On the other hand, a new area of research in conversational interfaces is dealing with multi-party interaction (Traum and Rickel, 2002; Liu and Chee, 2004; Zheng et al., 2005). Multiparty conversational interfaces have been applied to such tasks as training decision-making in team activities (Traum and Rickel, 2002), collaborative learning (Liu and Chee, 2004), and coordinating and facilitating interaction in a casual social group (Zheng et al., 2005). The advantage of such multi-party dialogues over two-party cases is that the multi-party case encourages group interaction and collaboration among human users. This advantage can be exploited to foster such human activities as student learning in more social settings and to bu</context>
</contexts>
<marker>Traum, Rickel, 2002</marker>
<rawString>David Traum and Jeff Rickel. 2002. Embodied agents for multi-party dialogue in immersive virtual worlds. In Proceedings of the 1st International Joint Conference on. Autonomous Agents and Multi-Agent Systems, pages 766–773.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Zheng</author>
<author>Xiang Yuan</author>
<author>Yam San Chee</author>
</authors>
<title>Designing multiparty interaction support in Elva, an embodied tour guide.</title>
<date>2005</date>
<booktitle>In Proceedings of the 4th International Joint Conference on Autonomous Agents and Multiagent Systems,</booktitle>
<pages>929--936</pages>
<contexts>
<context position="1933" citStr="Zheng et al., 2005" startWordPosition="269" endWordPosition="272">ction, raised user ratings of a peer agent, and increased user utterances. Our findings will be useful for stimulating multi-party communication in various applications such as educational agents and community facilitators. 1 Introduction Conversational interfaces including dialogue systems and conversational agents have been typically used as a single interface to a single user (Zue et al., 1994; Allen et al., 2001; Cassell et al., 2000). On the other hand, a new area of research in conversational interfaces is dealing with multi-party interaction (Traum and Rickel, 2002; Liu and Chee, 2004; Zheng et al., 2005). Multiparty conversational interfaces have been applied to such tasks as training decision-making in team activities (Traum and Rickel, 2002), collaborative learning (Liu and Chee, 2004), and coordinating and facilitating interaction in a casual social group (Zheng et al., 2005). The advantage of such multi-party dialogues over two-party cases is that the multi-party case encourages group interaction and collaboration among human users. This advantage can be exploited to foster such human activities as student learning in more social settings and to build and maintain social relationships amo</context>
</contexts>
<marker>Zheng, Yuan, Chee, 2005</marker>
<rawString>Jun Zheng, Xiang Yuan, and Yam San Chee. 2005. Designing multiparty interaction support in Elva, an embodied tour guide. In Proceedings of the 4th International Joint Conference on Autonomous Agents and Multiagent Systems, pages 929–936.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Zue</author>
<author>Stephanie Seneff</author>
<author>Joseph Polifroni</author>
<author>Michael Phillips</author>
<author>Christine Pao</author>
<author>David Goodine</author>
<author>David Goddeau</author>
<author>James Glass</author>
</authors>
<title>PEGASUS: a spoken dialogue interface for on-line air travel planning.</title>
<date>1994</date>
<journal>Speech Communication,</journal>
<volume>15</volume>
<pages>340</pages>
<contexts>
<context position="1713" citStr="Zue et al., 1994" startWordPosition="231" endWordPosition="234"> results showed that the presence of a peer agent significantly improved user satisfaction and increased the number of user utterances. We also found that agent empathic expressions significantly improved user satisfaction, raised user ratings of a peer agent, and increased user utterances. Our findings will be useful for stimulating multi-party communication in various applications such as educational agents and community facilitators. 1 Introduction Conversational interfaces including dialogue systems and conversational agents have been typically used as a single interface to a single user (Zue et al., 1994; Allen et al., 2001; Cassell et al., 2000). On the other hand, a new area of research in conversational interfaces is dealing with multi-party interaction (Traum and Rickel, 2002; Liu and Chee, 2004; Zheng et al., 2005). Multiparty conversational interfaces have been applied to such tasks as training decision-making in team activities (Traum and Rickel, 2002), collaborative learning (Liu and Chee, 2004), and coordinating and facilitating interaction in a casual social group (Zheng et al., 2005). The advantage of such multi-party dialogues over two-party cases is that the multi-party case enco</context>
</contexts>
<marker>Zue, Seneff, Polifroni, Phillips, Pao, Goodine, Goddeau, Glass, 1994</marker>
<rawString>Victor Zue, Stephanie Seneff, Joseph Polifroni, Michael Phillips, Christine Pao, David Goodine, David Goddeau, and James Glass. 1994. PEGASUS: a spoken dialogue interface for on-line air travel planning. Speech Communication, 15:331– 340.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>