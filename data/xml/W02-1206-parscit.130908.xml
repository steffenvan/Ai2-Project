<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.916805">
Lexicon-based Orthographic Disambiguation
in CJK Intelligent Information Retrieval
�����������������������
</title>
<author confidence="0.633591">
Jack Halpern(&amp;-A&amp;quot;)jack@cjk.org
The CJK Dictionary Institute(QrPORA1Vf5ftFT)
</author>
<keyword confidence="0.493254">
34-14, 2-chome, Tohoku, Niiza-shi, Saitama 352-0001, Japan
</keyword>
<sectionHeader confidence="0.988545" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999938384615385">
The orthographical complexity of Chinese,
Japanese and Korean (CJK) poses a special
challenge to the developers of computational
linguistic tools, especially in the area of
intelligent information retrieval. These
difficulties are exacerbated by the lack of a
standardized orthography in these languages,
especially the highly irregular Japanese
orthography. This paper focuses on the typology
of CJK orthographic variation, provides a brief
analysis of the linguistic issues, and discusses why
lexical databases should play a central role in the
disambiguation process.
</bodyText>
<sectionHeader confidence="0.99892" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.96451">
Various factors contribute to the difficulties of
CJK information retrieval. To achieve truly
&amp;quot;intelligent&amp;quot; retrieval many challenges must be
overcome. Some of the major issues include:
</bodyText>
<listItem confidence="0.996218647058823">
1. The lack of a standard orthography. To
process the extremely large number of
orthographic variants (especially in Japanese)
and character forms requires support for
advanced IR technologies such as cross-
orthographic searching (Halpern 2000).
2. The accurate conversion between Simplified
Chinese (SC) and Traditional Chinese (TC), a
deceptively simple but in fact extremely
difficult computational task (Halpern and
Kerman 1999).
3. The morphological complexity of Japanese
and Korean poses a formidable challenge to
the development of an accurate
morphological analyzer. This performs such
operations as canonicalization, stemming
(removing inflectional endings) and
</listItem>
<bodyText confidence="0.843814">
conflation (reducing morphological variants
to a single form) on the morphemic level.
4. The difficulty of performing accurate word
segmentation, especially in Chinese and
Japanese which are written without interword
spacing. This involves identifying word
boundaries by breaking a text stream into
meaningful semantic units for dictionary
lookup and indexing purposes. Good progress
in this area is reported in Emerson (2000) and
Yu et al. (2000).
</bodyText>
<listItem confidence="0.942414826086956">
5. Miscellaneous retrieval technologies such as
lexeme-based retrieval (e.g. &apos;take off&apos; +
&apos;jacket&apos; from &apos;took off his jacket&apos;), identifying
syntactic phrases (such as Vf5ft*xa from Vf
5ft�_-Lf:), synonym expansion, and cross-
language information retrieval (CLIR) (Goto
et al. 2001).
6. Miscellaneous technical requirements such as
transcoding between multiple character sets
and encodings, support for Unicode, and
input method editors (IME). Most of these
issues have been satisfactorily resolved, as
reported in Lunde (1999).
7. Proper nouns pose special difficulties for IR
tools, as they are extremely numerous,
difficult to detect without a lexicon, and have
an unstable orthography.
8. Automatic recognition of terms and their
variants, a complex topic beyond the scope
of this paper. It is described in detail for
European languages in Jacquemin (2001),
and we are currently investigating it for
Chinese and Japanese.
</listItem>
<bodyText confidence="0.996749777777778">
Each of the above is a major issue that deserves a
paper in its own right. Here, the focus is on
orthographic disambiguation, which refers to
the detection, normalization and conversion of
CJK orthographic variants. This paper summarizes
the typology of CJK orthographic variation,
briefly analyzes the linguistic issues, and
discusses why lexical databases should play a
central role in the disambiguation process.
</bodyText>
<sectionHeader confidence="0.99051" genericHeader="method">
2 Orthographic Variation in Chinese
</sectionHeader>
<subsectionHeader confidence="0.999663">
2.1 One Language, Two Scripts
</subsectionHeader>
<bodyText confidence="0.989625117647059">
As a result of the postwar language reforms in the
PRC, thousands of character forms underwent
drastic simplifications (Zongbiao 1986). Chinese
written in these simplified forms is called
Simplified Chinese (SC). Taiwan, Hong Kong,
and most overseas Chinese continue to use the old,
complex forms, referred to as Traditional
Chinese (TC).
The complexity of the Chinese writing system is
well known. Some factors contributing to this are
the large number of characters in common use,
their complex forms, the major differences
between TC and SC along various dimensions, the
presence of numerous orthographic variants in TC,
and others. The numerous variants and the
difficulty of converting between SC and TC are of
special importance to Chinese IR applications.
</bodyText>
<subsectionHeader confidence="0.993771">
2.2 Chinese-to-Chinese Conversion
</subsectionHeader>
<bodyText confidence="0.999956333333333">
The process of automatically converting SC
to/from TC, referred to as C2C conversion, is full
of complexities and pitfalls. A detailed description
of the linguistic issues can be found in Halpern
and Kerman (1999), while technical issues related
to encoding and character sets are described in
Lunde (1999). The conversion can be
implemented on three levels in increasing order of
sophistication, briefly described below.
</bodyText>
<subsubsectionHeader confidence="0.620371">
2.2.1 Code Conversion The easiest, but most
</subsubsectionHeader>
<bodyText confidence="0.999309888888889">
unreliable, way to perform C2C conversion is on a
codepoint-to-codepoint basis by looking the
source up in a mapping table, such as the one
shown below. This is referred to as code
conversion or transcoding. Because of the
numerous one-to-many ambiguities (which occur
in both the SC-to-TC and the TC-to-SC
directions), the rate of conversion failure is
unacceptably high.
</bodyText>
<tableCaption confidence="0.949472">
Table 1. Code Conversion
</tableCaption>
<bodyText confidence="0.9412915">
SC TC1 TC2 TC3 TC4 Remarks
one-to-one
one-to-one
one-to-many
one-to-many
one-to-many
</bodyText>
<subsubsectionHeader confidence="0.998411">
2.2.2 Orthographic Conversion The next
</subsubsectionHeader>
<bodyText confidence="0.999764111111111">
level of sophistication in C2C conversion is
referred to as orthographic conversion, because
the items being converted are orthographic units,
rather than codepoints in a character set. That is,
they are meaningful linguistic units, especially
multi-character lexemes. While code conversion is
ambiguous, orthographic conversion gives better
results because the orthographic mapping tables
enable conversion on the word level.
</bodyText>
<tableCaption confidence="0.763362">
Table 2. Orthographic Conversion
</tableCaption>
<bodyText confidence="0.986963714285714">
English SC TC1 TC2 Incorrect Comments
telephone unambiguous
we unambiguous
start-off one-to-many
dry one-to-many
depends on context
As can be seen, the ambiguities inherent in code
conversion are resolved by using an orthographic
mapping table, which avoids false conversions
such as shown in the Incorrect column. Because
of segmentation ambiguities, such conversion
must be done with the aid of a morphological
analyzer that can break the text stream into
meaningful units (Emerson 2000).
</bodyText>
<subsubsectionHeader confidence="0.985196">
2.2.3 Lexemic Conversion A more
</subsubsectionHeader>
<bodyText confidence="0.999365894736842">
sophisticated, and far more challenging, approach
to C2C conversion is called lexemic conversion,
which maps SC and TC lexemes that are
semantically, not orthographically, equivalent.
For example, SC (xìnxī) &apos;information&apos; is
converted to the semantically equivalent TC
(zīxisn). This is similar to the difference between
lorry in British English and truck in American
English.
There are numerous lexemic differences between
SC and TC, especially in technical terms and
proper nouns, as demonstrated by Tsou (2000).
For example, there are more than 10 variants for
&apos;Osama bin Laden.&apos; To complicate matters, the
correct TC is sometimes locale-dependent.
Lexemic conversion is the most difficult aspect of
C2C conversion and can only be done with the
help of mapping tables. Table 3 illustrates various
patterns of cross-locale lexemic variation.
</bodyText>
<tableCaption confidence="0.977683">
Table 3. Lexemic Conversion
</tableCaption>
<figure confidence="0.529830666666667">
English SC Taiwan TC Hong Kong TC Other TC Incorrect TC
(orthographic)
Software
Taxi
Osama bin Laden
Oahu
</figure>
<subsectionHeader confidence="0.992262">
2.3 Traditional Chinese Variants
</subsectionHeader>
<bodyText confidence="0.9998295">
Traditional Chinese does not have a stable
orthography. There are numerous TC variant
forms, and much confusion prevails. To process
TC (and to some extent SC) it is necessary to
disambiguate these variants using mapping tables
(Halpern 2001).
</bodyText>
<subsubsectionHeader confidence="0.496729">
2.3.1 TC Variants in Taiwan and Hong
</subsubsectionHeader>
<bodyText confidence="0.999203">
Kong Traditional Chinese dictionaries often
disagree on the choice of the standard TC form.
TC variants can be classified into various types, as
illustrated in Table 4.
</bodyText>
<tableCaption confidence="0.962482">
Table 4. TC Variants
</tableCaption>
<table confidence="0.8282878">
Var. 1 Var. 2 English Comment
inside 100% interchangeable
teach 100% interchangeable
particle variant 2 not in Big5
for variant 2 not in Big5
</table>
<bodyText confidence="0.916603263157895">
sink; partially
surname interchangeable
leak; partially
divulge interchangeable
There are various reasons for the existence of TC
variants, such as some TC forms are not being
available in the Big Five character set, the
occasional use of SC forms, and others.
2.3.2 Mainland vs. Taiwanese Variants To a
limited extent, the TC forms are used in the PRC
for some classical literature, newspapers for
overseas Chinese, etc., based on a standard that
maps the SC forms (GB 2312-80) to their
corresponding TC forms (GB/T 12345-90).
However, these mappings do not necessarily agree
with those widely used in Taiwan. We will refer to
the former as &amp;quot;Simplified Traditional Chinese&amp;quot;
(STC), and to the latter as &amp;quot;Traditional
Traditional Chinese&amp;quot; (TTC).
</bodyText>
<tableCaption confidence="0.996811">
Table 5. STC vs. TTC Variants
</tableCaption>
<table confidence="0.9035765">
Pinyin SC STC TTC
xiàn
bēng
cè
</table>
<sectionHeader confidence="0.9656895" genericHeader="method">
3 Orthographic Variation in
Japanese
</sectionHeader>
<subsectionHeader confidence="0.999368">
3.1 One Language, Four Scripts
</subsectionHeader>
<bodyText confidence="0.9658095">
The Japanese orthography is highly irregular.
Because of the large number of orthographic
variants and easily confused homophones, the
Japanese writing system is significantly more
complex than any other major language, including
Chinese. A major factor is the complex interaction
of the four scripts used to write Japanese, resulting
in countless words that can be written in a variety
of often unpredictable ways (Halpern 1990, 2000).
Table 6 shows the orthographic variants of 取り扱
い toriatsukai &apos;handling&apos;, illustrating a variety of
variation patterns.
</bodyText>
<tableCaption confidence="0.831088">
Table 6. Variants of toriatsukai
</tableCaption>
<table confidence="0.997808142857143">
Toriatsukai Type of variant
&amp;quot;standard&amp;quot; form
okurigana variant
All kanji
replace kanji with hiragana
replace kanji with hiragana
All hiragana
</table>
<bodyText confidence="0.999426">
An example of how difficult Japanese IR can be is
the proverbial &amp;quot;A hen that lays golden eggs.&amp;quot; The
&amp;quot;standard&amp;quot; orthography would be 金の卵を産む鶏
(Kin no tamago wo umu niwatori). In reality, tamago
&apos;egg&apos; has four variants (卵, 玉子, たまご, タマゴ),
niwatori &apos;chicken&apos; three (鶏, にわとり, ニワトリ)
and umu &apos;to lay&apos; two (産む, 生む), which expands
to 24 permutations like 金の卵を生むニワトリ, 金
の玉子を産む鶏 etc. As can be easily verified by
searching the web, these variants frequently occur
in webpages. Clearly, the user has no hope of
finding them unless the application supports
orthographic disambiguation.
</bodyText>
<subsectionHeader confidence="0.998059">
3.2 Okurigana Variants
</subsectionHeader>
<bodyText confidence="0.999746909090909">
One of the most common types of orthographic
variation in Japanese occurs in kana endings,
called 送り仮名 okurigana, that are attached to a
kanji base or stem. Although it is possible to
generate some okurigana variants algorithmically,
such as nouns (飛出し) derived from verbs (飛出
す), on the whole hard-coded tables are required.
Because usage is often unpredictable and the
variants are numerous, okurigana must play a
major role in Japanese orthographic
disambiguation.
</bodyText>
<tableCaption confidence="0.970706">
Table 7.Okurigana Variants
</tableCaption>
<table confidence="0.99168225">
English Reading Standard Variants
publish kakiarawasu
perform okonau
handling toriatsukai
</table>
<subsectionHeader confidence="0.996674">
3.3 Cross-Script Orthographic Variants
</subsectionHeader>
<bodyText confidence="0.999927">
Japanese is written in a mixture of four scripts
(Halpern 1990): kanji (Chinese characters), two
syllabic scripts called hiragana and katakana,
and romaji (the Latin alphabet). Orthographic
variation across scripts, which should play a major
role in Japanese IR, is extremely common and
mostly unpredictable, so that the same word can
be written in hiragana, katakana or kanji, or even
in a mixture of two scripts. Table 8 shows the
major cross-script variation patterns in Japanese.
</bodyText>
<tableCaption confidence="0.64119375">
Table 8. Cross-Script Variants
Kanji vs. Hiragana
Kanji vs. Katakana
Kanji vs. hiragana vs. katakana
Katakana vs. hybrid
Kanji vs. katakana vs. hybrid
Kanji vs. hybrid
Hiragana vs. katakana
</tableCaption>
<subsectionHeader confidence="0.97938">
3.4 Kana Variants
</subsectionHeader>
<bodyText confidence="0.997892857142857">
Recent years have seen a sharp increase in the use
of katakana, a syllabary used mostly to write
loanwords. A major annoyance in Japanese IR is
that katakana orthography is often irregular; it is
quite common for the same word to be written in
multiple, unpredictable ways which cannot be
generated algorithmically. Hiragana is used
</bodyText>
<equation confidence="0.5637">
Y
</equation>
<bodyText confidence="0.9970974">
mostly to write grammatical elements and some
native Japanese words. Although hiragana
orthography is generally regular, a small number
of irregularities persist. Some of the major types
of kana variation are shown in Table 9.
</bodyText>
<tableCaption confidence="0.968108">
Table 9. Katakana and Hiragana Variants
</tableCaption>
<table confidence="0.99415">
Type English Reading Standard Variants
Macron computer konpyuuta コンピ コンピュ
konpyuutaa ュータ ーター
Long maid meedo メ ー ド メ イ ド
vowels
Multiple team Z hmu u チ ー ム テ ィ ー ム
Traditional big ookii おおきい おうきい
vs. continue tsuzuku つづく つずく
</table>
<bodyText confidence="0.997657166666667">
The above is only a brief introduction to the most
important types of kana variation. There are
various others, including an optional middle dot
(nakaguro) and small katakana variants (クォ vs.
クオ), and the use of traditional (じ vs. ぢ) and
historical (い vs. ゐ) kana.
</bodyText>
<subsectionHeader confidence="0.972479">
3.5 Miscellaneous Variants
</subsectionHeader>
<bodyText confidence="0.999989">
There are various other types of orthographic
variants in Japanese, which are beyond the scope
of this paper. Only a couple of the important ones
are mentioned below. A detailed treatment can be
found in Halpern (2000).
</bodyText>
<subsubsectionHeader confidence="0.860039">
3.5.1 Kanji Variants Though the Japanese
</subsubsectionHeader>
<bodyText confidence="0.999911125">
writing system underwent major reforms in the
postwar period and the character forms have by
now been standardized, there is still a significant
number of variants in common use, such as
abbreviated forms in contemporary Japanese (才
for 歳 and 巾 for 幅) and traditional forms in
proper nouns and classical works (such as 嶋 for
島 and 發 for 発).
</bodyText>
<subsubsectionHeader confidence="0.665382">
3.5.2 Kun Homophones An important factor
</subsubsectionHeader>
<bodyText confidence="0.999372461538462">
that contributes to the complexity of the Japanese
writing system is the existence of a large number
of homophones (words pronounced the same but
written differently) and their variable orthography
(Halpern 2000). Not only can each kanji have
many kun readings, but many kun words can be
written in a bewildering variety of ways. The
majority of kun homophones are often close or
even identical in meaning and thus easily
confused, i.e., noboru means &apos;go up&apos; when written
上 る but &apos;climb&apos; when written 登 る , while
yawarakai ’soft’ is written 柔らかい or 軟らかい
with identical meanings.
</bodyText>
<sectionHeader confidence="0.995945" genericHeader="method">
4 Orthographic Variation in Korean
</sectionHeader>
<subsectionHeader confidence="0.998528">
4.1 Irregular Orthography
</subsectionHeader>
<bodyText confidence="0.999855333333333">
The Korean orthography is not as regular as most
people tend to believe. Though hangul is often
described as &amp;quot;logical,&amp;quot; the fact is that in modern
Korean there is a significant amount of
orthographic variation. This, combined with the
morphological complexity of the language, poses
a challenge to developers of IR tools. The major
types of orthographic variation in Korean are
described below.
</bodyText>
<subsectionHeader confidence="0.996582">
4.2 Hangul Variants
</subsectionHeader>
<bodyText confidence="0.9999638">
The most important type of orthographic variation
in Korean is the use of variant hangul spellings in
the writing of loanwords. Another significant kind
of variation is in the writing of non-Korean
personal names, as shown in Table 10.
</bodyText>
<tableCaption confidence="0.971729">
Table 10. Hangul Variants
</tableCaption>
<table confidence="0.9969618">
cake (keikeu) (keik)
yellow (yelrou) (yelro)
Mao (maojjeottung ) (motaekdong)
Zedong
Clinton (keulrinteon) (keulrinton)
</table>
<subsectionHeader confidence="0.999429">
4.3 Cross-Script Orthographic Variants
</subsectionHeader>
<bodyText confidence="0.999688666666667">
A factor that contributes to the complexity of the
Korean writing system is the use of multiple
scripts. Korean is written in a mixture of three
scripts: an alphabetic syllabary called hangul,
Chinese characters called hanja (their use is
declining) and the Latin alphabet called romaja.
Orthographic variation across scripts is not
uncommon. The major patterns of cross-script
variation are shown Table 11.
</bodyText>
<tableCaption confidence="0.975862">
Table 11. Cross-Script Orthographic Variants
</tableCaption>
<table confidence="0.996491454545455">
Type of English Var. 1 Var. 2 Var.3
Variation
Hanja vs. many (daese) (daese)
hangul people
Hangul vs. shirt (wai- (wai-
hybrid syeacheu) syeacheu)
Hangul vs. one (hansi) (hansi) (hansi)
numeral o&apos;clock
vs. hanja
English sex sex (sekseu )
vs. hangul
</table>
<subsectionHeader confidence="0.994715">
4.4 Miscellaneous Variants
</subsectionHeader>
<bodyText confidence="0.969032625">
4.4.1 North vs. South Korea Another factor
contributing to the irregularity of hangul
orthography is the differences in spelling between
South Korea (S.K.) and North Korea (N.K.). The
major differences are in the writing of loanwords,
a strong preference for native Korean words, and
in the writing of non-Korean proper nouns. The
major types are shown below.
</bodyText>
<listItem confidence="0.9766879">
1. Place names: N.K. (osakka) vs. S.K.
(osaka) for &apos;Osaka&apos;
2. Personal names: N.K. (busyu) vs. S.K.
(busi) for &apos;Bush&apos;
3. Loanwords: N.K. (missail) vs. S.K.
(misail) for &apos;missile&apos;
4. Russian vs. English: N.K. (guruppa)
vs. S.K. (geurup)
5. Morphophonemic: N.K. (ramyong) vs.
S.K. (namyong)
</listItem>
<subsubsectionHeader confidence="0.358601">
4.4.2 New vs. Old Orthography The hangul
</subsubsectionHeader>
<bodyText confidence="0.982296333333333">
script went through several reforms during its
history, the latest one taking place as recently as
1988. Though the new orthography is now well
established, the old orthography is still important
because the affected words are of high frequency
and their number is not insignificant. For example,
the modern &apos;worker&apos; (ilgun) was written
(ilkkun) before 1988, while &apos;color&apos; (bitgal) was
written (bitkkal).
</bodyText>
<subsubsectionHeader confidence="0.87398">
4.4.3 Hanja Variants Although language
</subsubsectionHeader>
<bodyText confidence="0.999588">
reforms in Korea did not include the
simplification of the character forms, the Japanese
occupation of Korea resulted in many simplified
Japanese character forms coming into use, such as
the Japanese form 発 to replace 發 (bal).
</bodyText>
<subsubsectionHeader confidence="0.95135">
4.4.4 Miscellaneous Variants There are
</subsubsectionHeader>
<bodyText confidence="0.999653428571429">
various other types of orthographic variation,
which are beyond the scope of this paper. This
includes the use of abbreviations and acronyms
and variation in interword spacing in multiword
compounds. For example, &apos;Caribbean Sea&apos;
(karibeuhae) may be written solid () or
open ().
</bodyText>
<sectionHeader confidence="0.988218" genericHeader="method">
5 The Role of Lexical Databases
</sectionHeader>
<bodyText confidence="0.965508714285714">
Because of the irregular orthography of CJK
languages, lexeme-based procedures such as
orthographic disambiguation cannot be based on
probabilistic methods (e.g. bigramming) alone.
Many attempts have been made along these lines,
as for example Brill (2001) and Goto et al. (2001),
with some claiming performance equivalent to
lexicon-based methods, while Kwok (1997)
reports good results with only a small lexicon and
simple segmentor.
These methods may be satisfactory for pure IR
(relevant document retrieval), but for orthographic
disambiguation and C2C conversion, Emerson
(2000) and others have shown that a robust
morphological analyzer capable of processing
lexemes, rather than bigrams or n-grams, must be
supported by a large-scale computational lexicon
(even 100,000 entries is much too small).
The CJK Dictionary Institute (CJKI), which
specializes in CJK computational lexicography, is
engaged in an ongoing research and development
effort to compile comprehensive CJK lexical
databases (currently about 5.5 million entries),
with special emphasis on orthographic
disambiguation and proper nouns. Listed below
are the principal components useful for intelligent
IR tools and orthographic disambiguation.
1. Chinese to Chinese conversion. In 1996,
CJKI launched a project to investigate C2C
conversion issues in-depth, and to build
comprehensive mapping tables (now at 1.3
million SC and 1.2 million TC items) whose
goal is to achieve near 100% conversion
accuracy. These include:
a. SC-to/from-TC code-level mapping tables
b. SC-to/from-TC orthographic and lexemic
mapping tables for general vocabulary
c. SC-to/from-TC orthographic mapping
tables for proper nouns
d. Comprehensive SC-to/from-TC
orthographic/lexemic mapping tables for
technical terminology, especially IT terms
</bodyText>
<listItem confidence="0.861954357142857">
2. TC orthographc normalization tables
a. TC normalization mapping tables
b. STC-to/from-TTC character mapping
tables
3. Japanese orthographic variant databases
a. A comprehensive database of Japanese
orthographic variants
b. A database of semantically classified
homophone groups
c. Semantically classified synonym groups
for synonym expansion (Japanese
thesaurus)
d. An English-Japanese lexicon for CLIR
e. Rules for identifying unlisted variants
</listItem>
<sectionHeader confidence="0.627394" genericHeader="conclusions">
Conclusions
</sectionHeader>
<bodyText confidence="0.9998903">
CJK IR tools have become increasingly important
to information retrieval in particular and to
information technology in general. As we have
seen, because of the irregular orthography of the
CJK writing systems, intelligent information
retrieval requires not only sophisticated tools such
as morphological analyzers, but also lexical
databases fine-tuned to the needs of orthographic
disambiguation.
Few if any CJK IR tools perform orthographic
disambiguation. For truly &amp;quot;intelligent&amp;quot; IR to
become a reality, not only must lexicon-based
disambiguation be supported, but such emerging
technologies as CLIR, synonym expansion and
cross-homophone searching should also be
implemented.
We are currently engaged in further developing
the lexical resources required for building
intelligent CJK information retrieval tools and for
supporting accurate segmentation technology.
</bodyText>
<sectionHeader confidence="0.999221" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99867946">
Brill, E. and Kacmarick, G. and Brocket, C. (2001)
Automatically Harvesting Katakana-English Term
Pairs from Search Engine Query Logs. Microsoft
Research, Proc. of the Sixth Natural Language
Processing Pacific Rim Symposium, Tokyo, Japan.
Emerson, T. (2000) Segmenting Chinese in Unicode.
Proc. of the 16th International Unicode Conference,
Amsterdam
Goto, I., Uratani, N. and Ehara T. (2001) Cross-
Language Information Retrieval of Proper Nouns
using Context Information. NHK Science and
Technical Research Laboratories. Proc. of the Sixth
Natural Language Processing Pacific Rim
Symposium, Tokyo, Japan
Jacquemin, C. (2001) Spotting and Discovering Terms
through Natural Language Processing. The MIT
Press, Cambridge, MA
Halpern, J. (1990) Outline Of Japanese Writing System.
In “New Japanese-English Character Dictionary”,
6th printing, Kenkyusha Ltd., Tokyo, Japan
(www.kanji.org/kanji/japanese/writing/outline.htm)
Halpern, J. and Kerman J. (1999) The Pitfalls and
Complexities of Chinese to Chinese Conversion.
Proc. of the Fourteenth International Unicode
Conference in Cambridge, MA.
Halpern, J. (2000) The Challenges of Intelligent
Japanese Searching. Working paper (www.cjk.org/
cjk/joa/joapaper.htm), The CJK Dictionary Institute,
Saitama, Japan.
Halpern, J. (2001) Variation in Traditional Chinese
Orthography. Working paper (www.cjk.org/cjk/
cjk/reference/chinvar.htm), The CJK Dictionary
Institute, Saitama, Japan.
Kwok, K.L. (1997) Lexicon Effects on Chinese
Information Retrieval. Proc. of 2nd Conf. on
Empirical Methods in NLP. ACL. pp.141-8.
Lunde, Ken (1999) CJKV Information Processing.
O’Reilly &amp; Associates, Sebastopol, CA.
Yu, Shiwen, Zhu, Xue-feng and Wang, Hui (2000) New
Progress of the Grammatical Knowledge-base of
Contemporary Chinese. Journal of Chinese
Information Processing, Institute of Computational
Linguistics, Peking University, Vol.15 No.1.
Tsou, B.K., Tsoi, W.F., Lai, T.B.Y. Hu, J., and Chan
S.W.K. (2000) LIVAC, a Chinese synchronous
corpus, and some applications. In &amp;quot;2000
International Conference on Chinese Language
ComputingICCLC2000&amp;quot;, Chicago .
Zongbiao (1986) (Jianhuazi zongbiao)
(Second Edition).
</reference>
<page confidence="0.79836">
,
</page>
<note confidence="0.550419">
, China.
</note>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.451676">
<title confidence="0.9712405">Lexicon-based Orthographic in CJK Intelligent Information Retrieval</title>
<affiliation confidence="0.92024">CJK Dictionary</affiliation>
<address confidence="0.900576">34-14, 2-chome, Tohoku, Niiza-shi, Saitama 352-0001, Japan</address>
<abstract confidence="0.9994155">The orthographical complexity of Chinese, Japanese and Korean (CJK) poses a special challenge to the developers of computational linguistic tools, especially in the area of information These difficulties are exacerbated by the lack of a standardized orthography in these languages, especially the highly irregular Japanese orthography. This paper focuses on the typology of CJK orthographic variation, provides a brief analysis of the linguistic issues, and discusses why lexical databases should play a central role in the disambiguation process.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Brill</author>
<author>G Kacmarick</author>
<author>C Brocket</author>
</authors>
<title>Automatically Harvesting Katakana-English Term Pairs from Search Engine Query Logs.</title>
<date>2001</date>
<booktitle>Microsoft Research, Proc. of the Sixth Natural Language Processing Pacific Rim Symposium,</booktitle>
<location>Tokyo, Japan.</location>
<marker>Brill, Kacmarick, Brocket, 2001</marker>
<rawString>Brill, E. and Kacmarick, G. and Brocket, C. (2001) Automatically Harvesting Katakana-English Term Pairs from Search Engine Query Logs. Microsoft Research, Proc. of the Sixth Natural Language Processing Pacific Rim Symposium, Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Emerson</author>
</authors>
<title>Segmenting Chinese in Unicode.</title>
<date>2000</date>
<booktitle>Proc. of the 16th International Unicode Conference,</booktitle>
<location>Amsterdam</location>
<contexts>
<context position="2120" citStr="Emerson (2000)" startWordPosition="282" endWordPosition="283">rean poses a formidable challenge to the development of an accurate morphological analyzer. This performs such operations as canonicalization, stemming (removing inflectional endings) and conflation (reducing morphological variants to a single form) on the morphemic level. 4. The difficulty of performing accurate word segmentation, especially in Chinese and Japanese which are written without interword spacing. This involves identifying word boundaries by breaking a text stream into meaningful semantic units for dictionary lookup and indexing purposes. Good progress in this area is reported in Emerson (2000) and Yu et al. (2000). 5. Miscellaneous retrieval technologies such as lexeme-based retrieval (e.g. &apos;take off&apos; + &apos;jacket&apos; from &apos;took off his jacket&apos;), identifying syntactic phrases (such as Vf5ft*xa from Vf 5ft�_-Lf:), synonym expansion, and crosslanguage information retrieval (CLIR) (Goto et al. 2001). 6. Miscellaneous technical requirements such as transcoding between multiple character sets and encodings, support for Unicode, and input method editors (IME). Most of these issues have been satisfactorily resolved, as reported in Lunde (1999). 7. Proper nouns pose special difficulties for IR t</context>
<context position="6283" citStr="Emerson 2000" startWordPosition="902" endWordPosition="903">etter results because the orthographic mapping tables enable conversion on the word level. Table 2. Orthographic Conversion English SC TC1 TC2 Incorrect Comments telephone unambiguous we unambiguous start-off one-to-many dry one-to-many depends on context As can be seen, the ambiguities inherent in code conversion are resolved by using an orthographic mapping table, which avoids false conversions such as shown in the Incorrect column. Because of segmentation ambiguities, such conversion must be done with the aid of a morphological analyzer that can break the text stream into meaningful units (Emerson 2000). 2.2.3 Lexemic Conversion A more sophisticated, and far more challenging, approach to C2C conversion is called lexemic conversion, which maps SC and TC lexemes that are semantically, not orthographically, equivalent. For example, SC (xìnxī) &apos;information&apos; is converted to the semantically equivalent TC (zīxisn). This is similar to the difference between lorry in British English and truck in American English. There are numerous lexemic differences between SC and TC, especially in technical terms and proper nouns, as demonstrated by Tsou (2000). For example, there are more than 10 variants for &apos;O</context>
<context position="17713" citStr="Emerson (2000)" startWordPosition="2699" endWordPosition="2700"> The Role of Lexical Databases Because of the irregular orthography of CJK languages, lexeme-based procedures such as orthographic disambiguation cannot be based on probabilistic methods (e.g. bigramming) alone. Many attempts have been made along these lines, as for example Brill (2001) and Goto et al. (2001), with some claiming performance equivalent to lexicon-based methods, while Kwok (1997) reports good results with only a small lexicon and simple segmentor. These methods may be satisfactory for pure IR (relevant document retrieval), but for orthographic disambiguation and C2C conversion, Emerson (2000) and others have shown that a robust morphological analyzer capable of processing lexemes, rather than bigrams or n-grams, must be supported by a large-scale computational lexicon (even 100,000 entries is much too small). The CJK Dictionary Institute (CJKI), which specializes in CJK computational lexicography, is engaged in an ongoing research and development effort to compile comprehensive CJK lexical databases (currently about 5.5 million entries), with special emphasis on orthographic disambiguation and proper nouns. Listed below are the principal components useful for intelligent IR tools </context>
</contexts>
<marker>Emerson, 2000</marker>
<rawString>Emerson, T. (2000) Segmenting Chinese in Unicode. Proc. of the 16th International Unicode Conference, Amsterdam</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Goto</author>
<author>N Uratani</author>
<author>T Ehara</author>
</authors>
<title>CrossLanguage Information Retrieval of Proper Nouns using Context Information.</title>
<date>2001</date>
<booktitle>NHK Science and Technical Research Laboratories. Proc. of the Sixth Natural Language Processing Pacific Rim Symposium,</booktitle>
<location>Tokyo, Japan</location>
<contexts>
<context position="2423" citStr="Goto et al. 2001" startWordPosition="324" endWordPosition="327">rming accurate word segmentation, especially in Chinese and Japanese which are written without interword spacing. This involves identifying word boundaries by breaking a text stream into meaningful semantic units for dictionary lookup and indexing purposes. Good progress in this area is reported in Emerson (2000) and Yu et al. (2000). 5. Miscellaneous retrieval technologies such as lexeme-based retrieval (e.g. &apos;take off&apos; + &apos;jacket&apos; from &apos;took off his jacket&apos;), identifying syntactic phrases (such as Vf5ft*xa from Vf 5ft�_-Lf:), synonym expansion, and crosslanguage information retrieval (CLIR) (Goto et al. 2001). 6. Miscellaneous technical requirements such as transcoding between multiple character sets and encodings, support for Unicode, and input method editors (IME). Most of these issues have been satisfactorily resolved, as reported in Lunde (1999). 7. Proper nouns pose special difficulties for IR tools, as they are extremely numerous, difficult to detect without a lexicon, and have an unstable orthography. 8. Automatic recognition of terms and their variants, a complex topic beyond the scope of this paper. It is described in detail for European languages in Jacquemin (2001), and we are currently</context>
<context position="17409" citStr="Goto et al. (2001)" startWordPosition="2655" endWordPosition="2658">ellaneous Variants There are various other types of orthographic variation, which are beyond the scope of this paper. This includes the use of abbreviations and acronyms and variation in interword spacing in multiword compounds. For example, &apos;Caribbean Sea&apos; (karibeuhae) may be written solid () or open (). 5 The Role of Lexical Databases Because of the irregular orthography of CJK languages, lexeme-based procedures such as orthographic disambiguation cannot be based on probabilistic methods (e.g. bigramming) alone. Many attempts have been made along these lines, as for example Brill (2001) and Goto et al. (2001), with some claiming performance equivalent to lexicon-based methods, while Kwok (1997) reports good results with only a small lexicon and simple segmentor. These methods may be satisfactory for pure IR (relevant document retrieval), but for orthographic disambiguation and C2C conversion, Emerson (2000) and others have shown that a robust morphological analyzer capable of processing lexemes, rather than bigrams or n-grams, must be supported by a large-scale computational lexicon (even 100,000 entries is much too small). The CJK Dictionary Institute (CJKI), which specializes in CJK computationa</context>
</contexts>
<marker>Goto, Uratani, Ehara, 2001</marker>
<rawString>Goto, I., Uratani, N. and Ehara T. (2001) CrossLanguage Information Retrieval of Proper Nouns using Context Information. NHK Science and Technical Research Laboratories. Proc. of the Sixth Natural Language Processing Pacific Rim Symposium, Tokyo, Japan</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Jacquemin</author>
</authors>
<title>Spotting and Discovering Terms through Natural Language Processing.</title>
<date>2001</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA</location>
<contexts>
<context position="3001" citStr="Jacquemin (2001)" startWordPosition="413" endWordPosition="414">on retrieval (CLIR) (Goto et al. 2001). 6. Miscellaneous technical requirements such as transcoding between multiple character sets and encodings, support for Unicode, and input method editors (IME). Most of these issues have been satisfactorily resolved, as reported in Lunde (1999). 7. Proper nouns pose special difficulties for IR tools, as they are extremely numerous, difficult to detect without a lexicon, and have an unstable orthography. 8. Automatic recognition of terms and their variants, a complex topic beyond the scope of this paper. It is described in detail for European languages in Jacquemin (2001), and we are currently investigating it for Chinese and Japanese. Each of the above is a major issue that deserves a paper in its own right. Here, the focus is on orthographic disambiguation, which refers to the detection, normalization and conversion of CJK orthographic variants. This paper summarizes the typology of CJK orthographic variation, briefly analyzes the linguistic issues, and discusses why lexical databases should play a central role in the disambiguation process. 2 Orthographic Variation in Chinese 2.1 One Language, Two Scripts As a result of the postwar language reforms in the P</context>
</contexts>
<marker>Jacquemin, 2001</marker>
<rawString>Jacquemin, C. (2001) Spotting and Discovering Terms through Natural Language Processing. The MIT Press, Cambridge, MA</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Halpern</author>
</authors>
<title>Outline Of Japanese Writing System. In</title>
<date>1990</date>
<booktitle>New Japanese-English Character Dictionary”, 6th printing, Kenkyusha Ltd.,</booktitle>
<location>Tokyo, Japan (www.kanji.org/kanji/japanese/writing/outline.htm)</location>
<contexts>
<context position="9242" citStr="Halpern 1990" startWordPosition="1365" endWordPosition="1366">the latter as &amp;quot;Traditional Traditional Chinese&amp;quot; (TTC). Table 5. STC vs. TTC Variants Pinyin SC STC TTC xiàn bēng cè 3 Orthographic Variation in Japanese 3.1 One Language, Four Scripts The Japanese orthography is highly irregular. Because of the large number of orthographic variants and easily confused homophones, the Japanese writing system is significantly more complex than any other major language, including Chinese. A major factor is the complex interaction of the four scripts used to write Japanese, resulting in countless words that can be written in a variety of often unpredictable ways (Halpern 1990, 2000). Table 6 shows the orthographic variants of 取り扱 い toriatsukai &apos;handling&apos;, illustrating a variety of variation patterns. Table 6. Variants of toriatsukai Toriatsukai Type of variant &amp;quot;standard&amp;quot; form okurigana variant All kanji replace kanji with hiragana replace kanji with hiragana All hiragana An example of how difficult Japanese IR can be is the proverbial &amp;quot;A hen that lays golden eggs.&amp;quot; The &amp;quot;standard&amp;quot; orthography would be 金の卵を産む鶏 (Kin no tamago wo umu niwatori). In reality, tamago &apos;egg&apos; has four variants (卵, 玉子, たまご, タマゴ), niwatori &apos;chicken&apos; three (鶏, にわとり, ニワトリ) and umu &apos;to lay&apos; two (</context>
<context position="10826" citStr="Halpern 1990" startWordPosition="1606" endWordPosition="1607">in kana endings, called 送り仮名 okurigana, that are attached to a kanji base or stem. Although it is possible to generate some okurigana variants algorithmically, such as nouns (飛出し) derived from verbs (飛出 す), on the whole hard-coded tables are required. Because usage is often unpredictable and the variants are numerous, okurigana must play a major role in Japanese orthographic disambiguation. Table 7.Okurigana Variants English Reading Standard Variants publish kakiarawasu perform okonau handling toriatsukai 3.3 Cross-Script Orthographic Variants Japanese is written in a mixture of four scripts (Halpern 1990): kanji (Chinese characters), two syllabic scripts called hiragana and katakana, and romaji (the Latin alphabet). Orthographic variation across scripts, which should play a major role in Japanese IR, is extremely common and mostly unpredictable, so that the same word can be written in hiragana, katakana or kanji, or even in a mixture of two scripts. Table 8 shows the major cross-script variation patterns in Japanese. Table 8. Cross-Script Variants Kanji vs. Hiragana Kanji vs. Katakana Kanji vs. hiragana vs. katakana Katakana vs. hybrid Kanji vs. katakana vs. hybrid Kanji vs. hybrid Hiragana vs</context>
</contexts>
<marker>Halpern, 1990</marker>
<rawString>Halpern, J. (1990) Outline Of Japanese Writing System. In “New Japanese-English Character Dictionary”, 6th printing, Kenkyusha Ltd., Tokyo, Japan (www.kanji.org/kanji/japanese/writing/outline.htm)</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Halpern</author>
<author>J Kerman</author>
</authors>
<title>The Pitfalls and Complexities of Chinese to Chinese Conversion.</title>
<date>1999</date>
<booktitle>Proc. of the Fourteenth International Unicode Conference in</booktitle>
<location>Cambridge, MA.</location>
<contexts>
<context position="1454" citStr="Halpern and Kerman 1999" startWordPosition="188" endWordPosition="191">uction Various factors contribute to the difficulties of CJK information retrieval. To achieve truly &amp;quot;intelligent&amp;quot; retrieval many challenges must be overcome. Some of the major issues include: 1. The lack of a standard orthography. To process the extremely large number of orthographic variants (especially in Japanese) and character forms requires support for advanced IR technologies such as crossorthographic searching (Halpern 2000). 2. The accurate conversion between Simplified Chinese (SC) and Traditional Chinese (TC), a deceptively simple but in fact extremely difficult computational task (Halpern and Kerman 1999). 3. The morphological complexity of Japanese and Korean poses a formidable challenge to the development of an accurate morphological analyzer. This performs such operations as canonicalization, stemming (removing inflectional endings) and conflation (reducing morphological variants to a single form) on the morphemic level. 4. The difficulty of performing accurate word segmentation, especially in Chinese and Japanese which are written without interword spacing. This involves identifying word boundaries by breaking a text stream into meaningful semantic units for dictionary lookup and indexing </context>
<context position="4559" citStr="Halpern and Kerman (1999)" startWordPosition="649" endWordPosition="652">s well known. Some factors contributing to this are the large number of characters in common use, their complex forms, the major differences between TC and SC along various dimensions, the presence of numerous orthographic variants in TC, and others. The numerous variants and the difficulty of converting between SC and TC are of special importance to Chinese IR applications. 2.2 Chinese-to-Chinese Conversion The process of automatically converting SC to/from TC, referred to as C2C conversion, is full of complexities and pitfalls. A detailed description of the linguistic issues can be found in Halpern and Kerman (1999), while technical issues related to encoding and character sets are described in Lunde (1999). The conversion can be implemented on three levels in increasing order of sophistication, briefly described below. 2.2.1 Code Conversion The easiest, but most unreliable, way to perform C2C conversion is on a codepoint-to-codepoint basis by looking the source up in a mapping table, such as the one shown below. This is referred to as code conversion or transcoding. Because of the numerous one-to-many ambiguities (which occur in both the SC-to-TC and the TC-to-SC directions), the rate of conversion fail</context>
</contexts>
<marker>Halpern, Kerman, 1999</marker>
<rawString>Halpern, J. and Kerman J. (1999) The Pitfalls and Complexities of Chinese to Chinese Conversion. Proc. of the Fourteenth International Unicode Conference in Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Halpern</author>
</authors>
<title>The Challenges of Intelligent Japanese Searching. Working paper (www.cjk.org/ cjk/joa/joapaper.htm), The CJK Dictionary Institute,</title>
<date>2000</date>
<location>Saitama, Japan.</location>
<contexts>
<context position="1266" citStr="Halpern 2000" startWordPosition="164" endWordPosition="165">rthographic variation, provides a brief analysis of the linguistic issues, and discusses why lexical databases should play a central role in the disambiguation process. 1 Introduction Various factors contribute to the difficulties of CJK information retrieval. To achieve truly &amp;quot;intelligent&amp;quot; retrieval many challenges must be overcome. Some of the major issues include: 1. The lack of a standard orthography. To process the extremely large number of orthographic variants (especially in Japanese) and character forms requires support for advanced IR technologies such as crossorthographic searching (Halpern 2000). 2. The accurate conversion between Simplified Chinese (SC) and Traditional Chinese (TC), a deceptively simple but in fact extremely difficult computational task (Halpern and Kerman 1999). 3. The morphological complexity of Japanese and Korean poses a formidable challenge to the development of an accurate morphological analyzer. This performs such operations as canonicalization, stemming (removing inflectional endings) and conflation (reducing morphological variants to a single form) on the morphemic level. 4. The difficulty of performing accurate word segmentation, especially in Chinese and </context>
<context position="12792" citStr="Halpern (2000)" startWordPosition="1931" endWordPosition="1932">vowels Multiple team Z hmu u チ ー ム テ ィ ー ム Traditional big ookii おおきい おうきい vs. continue tsuzuku つづく つずく The above is only a brief introduction to the most important types of kana variation. There are various others, including an optional middle dot (nakaguro) and small katakana variants (クォ vs. クオ), and the use of traditional (じ vs. ぢ) and historical (い vs. ゐ) kana. 3.5 Miscellaneous Variants There are various other types of orthographic variants in Japanese, which are beyond the scope of this paper. Only a couple of the important ones are mentioned below. A detailed treatment can be found in Halpern (2000). 3.5.1 Kanji Variants Though the Japanese writing system underwent major reforms in the postwar period and the character forms have by now been standardized, there is still a significant number of variants in common use, such as abbreviated forms in contemporary Japanese (才 for 歳 and 巾 for 幅) and traditional forms in proper nouns and classical works (such as 嶋 for 島 and 發 for 発). 3.5.2 Kun Homophones An important factor that contributes to the complexity of the Japanese writing system is the existence of a large number of homophones (words pronounced the same but written differently) and thei</context>
</contexts>
<marker>Halpern, 2000</marker>
<rawString>Halpern, J. (2000) The Challenges of Intelligent Japanese Searching. Working paper (www.cjk.org/ cjk/joa/joapaper.htm), The CJK Dictionary Institute, Saitama, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Halpern</author>
</authors>
<title>Variation in Traditional Chinese Orthography. Working paper (www.cjk.org/cjk/ cjk/reference/chinvar.htm), The CJK Dictionary Institute,</title>
<date>2001</date>
<location>Saitama, Japan.</location>
<contexts>
<context position="7570" citStr="Halpern 2001" startWordPosition="1097" endWordPosition="1098">-dependent. Lexemic conversion is the most difficult aspect of C2C conversion and can only be done with the help of mapping tables. Table 3 illustrates various patterns of cross-locale lexemic variation. Table 3. Lexemic Conversion English SC Taiwan TC Hong Kong TC Other TC Incorrect TC (orthographic) Software Taxi Osama bin Laden Oahu 2.3 Traditional Chinese Variants Traditional Chinese does not have a stable orthography. There are numerous TC variant forms, and much confusion prevails. To process TC (and to some extent SC) it is necessary to disambiguate these variants using mapping tables (Halpern 2001). 2.3.1 TC Variants in Taiwan and Hong Kong Traditional Chinese dictionaries often disagree on the choice of the standard TC form. TC variants can be classified into various types, as illustrated in Table 4. Table 4. TC Variants Var. 1 Var. 2 English Comment inside 100% interchangeable teach 100% interchangeable particle variant 2 not in Big5 for variant 2 not in Big5 sink; partially surname interchangeable leak; partially divulge interchangeable There are various reasons for the existence of TC variants, such as some TC forms are not being available in the Big Five character set, the occasion</context>
</contexts>
<marker>Halpern, 2001</marker>
<rawString>Halpern, J. (2001) Variation in Traditional Chinese Orthography. Working paper (www.cjk.org/cjk/ cjk/reference/chinvar.htm), The CJK Dictionary Institute, Saitama, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K L Kwok</author>
</authors>
<title>Lexicon Effects on Chinese Information Retrieval.</title>
<date>1997</date>
<booktitle>Proc. of 2nd Conf. on Empirical Methods in NLP. ACL.</booktitle>
<pages>141--8</pages>
<contexts>
<context position="17496" citStr="Kwok (1997)" startWordPosition="2668" endWordPosition="2669">he scope of this paper. This includes the use of abbreviations and acronyms and variation in interword spacing in multiword compounds. For example, &apos;Caribbean Sea&apos; (karibeuhae) may be written solid () or open (). 5 The Role of Lexical Databases Because of the irregular orthography of CJK languages, lexeme-based procedures such as orthographic disambiguation cannot be based on probabilistic methods (e.g. bigramming) alone. Many attempts have been made along these lines, as for example Brill (2001) and Goto et al. (2001), with some claiming performance equivalent to lexicon-based methods, while Kwok (1997) reports good results with only a small lexicon and simple segmentor. These methods may be satisfactory for pure IR (relevant document retrieval), but for orthographic disambiguation and C2C conversion, Emerson (2000) and others have shown that a robust morphological analyzer capable of processing lexemes, rather than bigrams or n-grams, must be supported by a large-scale computational lexicon (even 100,000 entries is much too small). The CJK Dictionary Institute (CJKI), which specializes in CJK computational lexicography, is engaged in an ongoing research and development effort to compile com</context>
</contexts>
<marker>Kwok, 1997</marker>
<rawString>Kwok, K.L. (1997) Lexicon Effects on Chinese Information Retrieval. Proc. of 2nd Conf. on Empirical Methods in NLP. ACL. pp.141-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken Lunde</author>
</authors>
<date>1999</date>
<booktitle>CJKV Information Processing. O’Reilly &amp; Associates,</booktitle>
<location>Sebastopol, CA.</location>
<contexts>
<context position="2668" citStr="Lunde (1999)" startWordPosition="360" endWordPosition="361">rposes. Good progress in this area is reported in Emerson (2000) and Yu et al. (2000). 5. Miscellaneous retrieval technologies such as lexeme-based retrieval (e.g. &apos;take off&apos; + &apos;jacket&apos; from &apos;took off his jacket&apos;), identifying syntactic phrases (such as Vf5ft*xa from Vf 5ft�_-Lf:), synonym expansion, and crosslanguage information retrieval (CLIR) (Goto et al. 2001). 6. Miscellaneous technical requirements such as transcoding between multiple character sets and encodings, support for Unicode, and input method editors (IME). Most of these issues have been satisfactorily resolved, as reported in Lunde (1999). 7. Proper nouns pose special difficulties for IR tools, as they are extremely numerous, difficult to detect without a lexicon, and have an unstable orthography. 8. Automatic recognition of terms and their variants, a complex topic beyond the scope of this paper. It is described in detail for European languages in Jacquemin (2001), and we are currently investigating it for Chinese and Japanese. Each of the above is a major issue that deserves a paper in its own right. Here, the focus is on orthographic disambiguation, which refers to the detection, normalization and conversion of CJK orthogra</context>
<context position="4652" citStr="Lunde (1999)" startWordPosition="665" endWordPosition="666">mplex forms, the major differences between TC and SC along various dimensions, the presence of numerous orthographic variants in TC, and others. The numerous variants and the difficulty of converting between SC and TC are of special importance to Chinese IR applications. 2.2 Chinese-to-Chinese Conversion The process of automatically converting SC to/from TC, referred to as C2C conversion, is full of complexities and pitfalls. A detailed description of the linguistic issues can be found in Halpern and Kerman (1999), while technical issues related to encoding and character sets are described in Lunde (1999). The conversion can be implemented on three levels in increasing order of sophistication, briefly described below. 2.2.1 Code Conversion The easiest, but most unreliable, way to perform C2C conversion is on a codepoint-to-codepoint basis by looking the source up in a mapping table, such as the one shown below. This is referred to as code conversion or transcoding. Because of the numerous one-to-many ambiguities (which occur in both the SC-to-TC and the TC-to-SC directions), the rate of conversion failure is unacceptably high. Table 1. Code Conversion SC TC1 TC2 TC3 TC4 Remarks one-to-one one-</context>
</contexts>
<marker>Lunde, 1999</marker>
<rawString>Lunde, Ken (1999) CJKV Information Processing. O’Reilly &amp; Associates, Sebastopol, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiwen Yu</author>
<author>Xue-feng Zhu</author>
<author>Hui Wang</author>
</authors>
<title>New Progress of the Grammatical Knowledge-base of Contemporary Chinese.</title>
<date>2000</date>
<journal>Journal of Chinese Information</journal>
<institution>Processing, Institute of Computational Linguistics, Peking University,</institution>
<location>Vol.15 No.1.</location>
<contexts>
<context position="2141" citStr="Yu et al. (2000)" startWordPosition="285" endWordPosition="288">able challenge to the development of an accurate morphological analyzer. This performs such operations as canonicalization, stemming (removing inflectional endings) and conflation (reducing morphological variants to a single form) on the morphemic level. 4. The difficulty of performing accurate word segmentation, especially in Chinese and Japanese which are written without interword spacing. This involves identifying word boundaries by breaking a text stream into meaningful semantic units for dictionary lookup and indexing purposes. Good progress in this area is reported in Emerson (2000) and Yu et al. (2000). 5. Miscellaneous retrieval technologies such as lexeme-based retrieval (e.g. &apos;take off&apos; + &apos;jacket&apos; from &apos;took off his jacket&apos;), identifying syntactic phrases (such as Vf5ft*xa from Vf 5ft�_-Lf:), synonym expansion, and crosslanguage information retrieval (CLIR) (Goto et al. 2001). 6. Miscellaneous technical requirements such as transcoding between multiple character sets and encodings, support for Unicode, and input method editors (IME). Most of these issues have been satisfactorily resolved, as reported in Lunde (1999). 7. Proper nouns pose special difficulties for IR tools, as they are ext</context>
</contexts>
<marker>Yu, Zhu, Wang, 2000</marker>
<rawString>Yu, Shiwen, Zhu, Xue-feng and Wang, Hui (2000) New Progress of the Grammatical Knowledge-base of Contemporary Chinese. Journal of Chinese Information Processing, Institute of Computational Linguistics, Peking University, Vol.15 No.1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B K Tsou</author>
<author>W F Tsoi</author>
<author>T B Y Hu Lai</author>
<author>J</author>
<author>S W K Chan</author>
</authors>
<title>LIVAC, a Chinese synchronous corpus, and some applications. In</title>
<date>2000</date>
<marker>Tsou, Tsoi, Lai, J, Chan, 2000</marker>
<rawString>Tsou, B.K., Tsoi, W.F., Lai, T.B.Y. Hu, J., and Chan S.W.K. (2000) LIVAC, a Chinese synchronous corpus, and some applications. In &amp;quot;2000</rawString>
</citation>
<citation valid="true">
<date>1986</date>
<booktitle>International Conference on Chinese Language ComputingICCLC2000&amp;quot;, Chicago . Zongbiao</booktitle>
<note>(Jianhuazi zongbiao) (Second Edition).</note>
<marker>1986</marker>
<rawString>International Conference on Chinese Language ComputingICCLC2000&amp;quot;, Chicago . Zongbiao (1986) (Jianhuazi zongbiao) (Second Edition).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>