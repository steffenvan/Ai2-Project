<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.037905">
<title confidence="0.997491">
Reproducible Results in Parsing-Based Machine Translation:
The JHU Shared Task Submission
</title>
<author confidence="0.995498">
Lane Schwartz *
</author>
<affiliation confidence="0.995953">
University of Minnesota
</affiliation>
<address confidence="0.678443">
Minneapolis, MN
</address>
<email confidence="0.998954">
lane@cs.umn.edu
</email>
<sectionHeader confidence="0.993899" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99975575">
We present the Johns Hopkins Univer-
sity submission to the 2010 WMT shared
translation task. We describe processing
steps using open data and open source
software used in our submission, and pro-
vide the scripts and configurations re-
quired to train, tune, and test our machine
translation system.
</bodyText>
<sectionHeader confidence="0.999267" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.983540245283019">
Research investigating natural language process-
ing and computational linguistics can and should
have an extremely low barrier to entry. The data
with which we work is customarily available in
common electronic formats. The computational
techniques which we apply can typically be per-
formed on commodity computing resources which
are widely available. In short, there should be no
reason why small research groups and even lone
researchers should not be able to join and make
substantive contributions furthering our field. The
reality is less encouraging.
Many published articles describe novel tech-
niques and provide interesting results, yet fail to
describe technical details in sufficient detail to al-
low their results to be reproduced by other re-
searchers. While there are notable and laudable
exceptions, many publications fail to provide the
source code and scripts necessary to reproduce re-
sults. The use of restricted data, not freely avail-
able for download by any interested researcher
only compounds these problems. Pedersen (2008)
rightly argues that the implementation details so
often ignored in publications are in fact essential
for our research to be reproducible science.
Reproducibility in machine translation is made
more challenging by the complexity of experi-
mental workflows. Results in machine translation
*Research conducted as a visiting researcher at Johns
Hopkins University
tasks are dependent on a cascade of processing
steps and configurations. While interesting sub-
sets of these usually appear in experimental de-
scriptions, many steps (preprocessing techniques,
alignment parameters, translation rule extraction
parameters, language model parameters, list of
features used) are invariably omitted, even though
these configurations are often critical to reproduc-
ing results.
This paper describes the Johns Hopkins Univer-
sity submission to the 2010 Workshop on Statis-
tical Machine Translation shared translation task.
Links to the software, scripts, and configurations
used to run the experiments described herein are
provided. The remainder of this paper is struc-
tured as follows. Section 2 lists the major ex-
amples of publicly available open source machine
translation systems, parallel corpora, and machine
translation workflow management systems. Sec-
tion 3 describes the experimental workflow used
to run the shared task translations, with the corre-
sponding experimental design in section 4. Sec-
tion 5 presents the shared task results.
</bodyText>
<sectionHeader confidence="0.999694" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9983993125">
The last four years have witnessed the implemen-
tation and release of numerous open source ma-
chine translation systems. The widely used Moses
system (Koehn et al., 2007) implements the stan-
dard phrase-based translation model. Parsing-
based translation models are implemented by
Joshua (Li et al., 2009), SAMT (Zollmann and
Venugopal, 2006), and cdec (Dyer et al., 2010).
Cunei (Phillips and Brown, 2009) implements
statistical example-based translation. Olteanu et
al. (2006) and Schwartz (2008) respectively pro-
vide additional open-source implementations of
phrase-based and hierarchical decoders.
The SRILM (Stolcke, 2002), IRSTLM (Fed-
erico et al., 2008), and RandLM (Talbot and Os-
borne, 2007) toolkits enable efficient training and
</bodyText>
<page confidence="0.969228">
177
</page>
<note confidence="0.6400945">
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 177–182,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figure confidence="0.998992043478261">
Download Data
Unzip Data
WMT Scripts
Remove XML
Tokenize
Normalize
Joshua
Berkeley Aligner
Subsample
Subsample for Truecasing
Align
Align Truecased Data
SRILM
Hiero
Train Truecase LM
Train LM
Extract Grammar
Extract Truecase Grammar
Run MERT
Translate
Run MBR on Translations
Restore to Truecase
Run MBR on Truecased Translations
</figure>
<figureCaption confidence="0.997636">
Figure 1: Machine translation workflow. Square nodes in grey indicate software and scripts.
</figureCaption>
<bodyText confidence="0.756811">
The scripts and configuration files used to implement and run this workflow are available
for download at http://sourceforge.net/projects/joshua/files/joshua/1.3/
wmt2010-experiment.tgz/download
</bodyText>
<page confidence="0.996828">
178
</page>
<bodyText confidence="0.999887863636364">
querying of n-gram language models.
Freely available parallel corpora for numer-
ous European languages have also been released
in recent years. These include the Europarl
(Koehn, 2005) and JRC-Acquis (Steinberger et al.,
2006) legislative corpora, each of which includes
data for most EU language pairs. The smaller
News Commentary corpora (Callison-Burch et al.,
2007; Callison-Burch et al., 2008) provide smaller
amounts of parallel data in the news genre. The re-
cent Fr-En 109 (Callison-Burch et al., 2009) cor-
pus aggregates huge numbers of parallel French-
English sentences from the web.
Open source systems to address the complex
workflows required to run non-trivial machine
translation experiments have also been developed.
These include experiment.perl (Koehn et
al., 2010), developed as a workflow management
system at the University of Edinburgh, and Loony-
Bin (Clark et al., 2010), a general hyperworkflow
management utility from Carnegie Melon Univer-
sity.
</bodyText>
<sectionHeader confidence="0.976967" genericHeader="method">
3 Managing Experiment Worliflows
</sectionHeader>
<bodyText confidence="0.999963735294117">
Running a statistical machine translation system to
achieve state-of-the-art performance involves the
configuration and execution of numerous interde-
pendent intermediate tools. To manage task de-
pendencies and tool configuration, our shared task
workflow consists of a set of dependency scripts
written for GNU Make (Stallman et al., 2006).
Figure 1 shows a graph depicting the steps in
our experimental workflow, and the dependencies
between steps. Each node in the graph represents
a step in the workflow; each step is implemented
as a Make script that defines how to run the tools
required in that step. In each experiment, an ad-
ditional configuration script is provided for each
experimental step, defining the parameters to be
used when running that step in the current experi-
ment. Optional front-end wrapper scripts can also
be provided, allowing for a complete experiment
to be run - from downloading data and software
through truecasing translated results - by execut-
ing a single make file.
This framework is also conducive to paralleliza-
tion. Many tasks, such as preprocessing numerous
training files, are not dependent on one another.
In such cases make can be configured to exe-
cute multiple processes simultaneously on a single
multi-processor machine. In cases where sched-
uled distributed computing environments such as
the Sun Grid Engine are configured, make files can
be processed by scheduler-aware make variants
(distmake, SGE qmake, Sun Studio dmake)
which distribute outstanding tasks to available dis-
tributed machines using the relevant distributed
scheduler.
</bodyText>
<sectionHeader confidence="0.99793" genericHeader="method">
4 Experimental Configuration
</sectionHeader>
<bodyText confidence="0.999868628571429">
Experimental workflows were configured1 and run
for six language pairs in the translation shared
task: English-French, English-German, English-
Spanish, French-English, German-English, and
Spanish-English.
In all experiments, only data freely available
for download was used. No restricted data from
the LDC or other sources was used. Table 1 lists
the parallel corpora used in training the translation
model for each experiment. The monolingual cor-
pora used in training each target language model
are listed in table 2. In all experiments, news-
test2008 was used as a development tuning corpus
during minimum error rate training; newstest2009
was used as a development test set. The shared
task data set newstest2010 was used as a final blind
test set.
All data was automatically downloaded, un-
zipped, and preprocessed prior to use. Files pro-
vided in XML format were converted to plain text
by selecting lines with &lt;seg&gt; tags, then removing
the beginning and end tags for each segment; this
processing was applied using GNU grep and sed.
The tokenize.perl and lowercase.perl
scripts provided for the shared task2 were applied
to all data.
Interpolated n-gram language models for the
four target languages were built using the SRI
Language Model Toolkit3, with n-gram order set
to 5. The Chen and Goodman (1998) technique
for modified Kneser-Ney discounting (Kneser and
Ney, 1995) was applied during language model
training.
Following Li et al. (2009), a subset of the avail-
able training sentences was selected via subsam-
</bodyText>
<footnote confidence="0.994190222222222">
1http://sourceforge.net/projects/joshua/files/joshua/1.3/wmt2010-
experiment.tgz/download
2http://www.statmt.org/wmt08/scripts.tgz with md5sum:
tokenize.perl 45cd1832827131013245eca76481441a
lowercase.perl a1958ab429b1e29d379063c3b9cd7062
3http://www-speech.sri.com/projects/srilm
SRILM version 1.5.7. Our experimental workflow requires
that SRILM be compiled separately, with the $SRILM envi-
ronment variable set to the install location.
</footnote>
<page confidence="0.972971">
179
</page>
<table confidence="0.999874571428571">
Source Target Parallel Corpora
German English news-commentary10.de-en europarl-v5.de-en
English German news-commentary10.de-en europarl-v5.de-en
French English news-commentary10.fr-en europarl-v5.fr-en giga-fren.release2 undoc.2000.en-fr
English French news-commentary10.fr-en europarl-v5.fr-en giga-fren.release2 undoc.2000.en-fr
Spanish English news-commentary10.es-en europarl-v5.es-en undoc.2000.en-es
English Spanish news-commentary10.es-en europarl-v5.es-en undoc.2000.en-es
</table>
<tableCaption confidence="0.995878">
Table 1: Parallel training data used for training translation model, per language pair
</tableCaption>
<table confidence="0.999669">
Target Monolingual Corpora
English europarl-v5.en news-commentary10.en news.en.shuffled undoc.2000.en-fr.en giga-fren.release2.en
French europarl-v5.fr news-commentary10.fr news.fr.shuffled undoc.2000.en-fr.fr giga-fren.release2.fr
German europarl-v5.de news-commentary10.de news.de.shuffled
Spanish europarl-v5.es news-commentary10.es news.es.shuffled undoc.2000.en-es.es
</table>
<tableCaption confidence="0.999227">
Table 2: Monolingual training data used for training language model, per target language
</tableCaption>
<bodyText confidence="0.999679428571429">
pling; training sentences are selected based on the
estimated likelihood of each sentence being useful
later for translating a particular test corpus.
Given a subsampled parallel training corpus,
word alignment is performed using the Berkeley
aligner4 (Liang et al., 2006).
For each language pair, a synchronous context
free translation grammar is extracted for a particu-
lar test set, following the methods of Lopez (2008)
as implemented in (Schwartz and Callison-Burch,
2010). For the largest training sets (French-
English and English-French) the original (Lopez,
2008) implementation included with Hiero was
used to save time during training5.
Because of the use of subsampling, the ex-
tracted translation grammars are targeted for use
with a specific test set. Our experiments were be-
gun prior to the release of the blind newstest2010
shared task test set. Subsampling was performed
for the development tuning set, news-test2008,
and the development test set, newstest2009. Once
the newstest2010 test set was released, the process
of subsampling, alignment, and grammar extrac-
tion was repeated to obtain translation grammars
targeted for use with the shared task test set.
Our experiments used hierarchical phrase-based
grammars containing exactly two nonterminals -
the wildcard nonterminal X, and S, used to glue
</bodyText>
<footnote confidence="0.990837">
4http://berkeleyaligner.googlecode.com/files/berkeleyaligner
unsupervised-2.1.tar.gz — Berkeley aligner version 2.1
5It is expected that using the Joshua implementation
should result in nearly identical results, albeit with somewhat
more time required to extract the grammar.
</footnote>
<bodyText confidence="0.99968296969697">
together neighboring constituents. Recent work
has shown that parsing-based machine translation
using SAMT (Zollmann and Venugopal, 2006)
grammars with rich nonterminal sets can demon-
strate substantial gains over hierarchical grammars
for certain language pairs (Baker et al., 2009).
Joshua supports such grammars; the experimental
workflow presented here could easily be extended
in future research to incorporate the use of SAMT
grammars with additional language pairs.
The Z-MERT implementation (Zaidan, 2009) of
minimum error rate training (Och, 2003) was used
for parameter tuning. Tuned grammars were used
by Joshua to translate all test sets. The Joshua de-
coder produces n-best lists of translations.
Rather than simply selecting the top candidate
from each list, we take the preferred candidate af-
ter perform minimum Bayes risk rescoring (Ku-
mar and Byrne, 2004).
Once a single translation has been extracted
for each sentence in the test set, we repeat the
procedures described above to train language and
translation models for use in translating lower-
cased results into a more human-readable true-
cased form. A truecase language model is
trained as above, but on the tokenized (but not
normalized) monolingual target language corpus.
Monotone word alignments are deterministically
created, mapping normalized lowercase training
text to the original truecase text. As in bilin-
gual translation, subsampling is performed for
the training set, and a translation grammar for
lowercase-to-truecase is extracted. No tuning is
</bodyText>
<page confidence="0.826115">
180
</page>
<footnote confidence="0.984384">
6http://sourceforge.net/projects/joshua/files/joshua/1.3/joshua-
1.3.tgz/download — Joshua version 1.3
</footnote>
<bodyText confidence="0.997561916666667">
performed. The Joshua decoder is used to trans-
late the lowercased target language test results into
truecase format. The detokenize.perl and
wrap-xml.perl scripts provided for the shared
task were manually applied to truecased transla-
tion results prior to final submission of results.
The code used for subsampling, grammar ex-
traction, decoding, minimum error rate training,
and minimum Bayes risk rescoring is provided
with Joshua6, with the exception of the original
(Lopez, 2008) grammar extraction implementa-
tion.
</bodyText>
<sectionHeader confidence="0.996167" genericHeader="method">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.958217555555556">
The experiments described in sections 3 and
4 above provided truecased translations for
six language pairs in the translation shared
task: English-French, English-German, English-
Spanish, French-English, German-English, and
Spanish-English. Table 3 lists the automatic met-
ric scores for the newstest2010 test set, accord-
ing to the BLEU (Papineni et al., 2002) and TER
(Snover et al., 2006) metrics.
</bodyText>
<table confidence="0.99872275">
Source Target BLEU BLEU- TER
cased
German English 21.3 19.5 0.660
English German 15.2 14.6 0.738
French English 27.7 26.4 0.614
English French 23.8 22.8 0.681
Spanish English 29.0 27.6 0.595
English Spanish 28.1 26.5 0.596
</table>
<tableCaption confidence="0.9201795">
Table 3: Automatic metric scores for the test set
newstest2010
</tableCaption>
<bodyText confidence="0.999787111111111">
The submitted system ranked highest among
shared task participants for the German-English
task, according to TER.
In order to provide points of comparison with
the 2009 Workshop on Statistical Machine Trans-
lation shared translation task participants, table
4 lists automatic metric scores for our systems’
translations of the newstest2009 test set, which we
used as a development test set.
</bodyText>
<sectionHeader confidence="0.938629" genericHeader="method">
6 Steps to Reproduce
</sectionHeader>
<bodyText confidence="0.9981595">
The experiments in this paper can be reproduced
by running the make scripts provided in the
</bodyText>
<table confidence="0.999221142857143">
Source Target BLEU
German English 18.19
English German 13.57
French English 26.41
English French 25.28
Spanish English 25.28
English Spanish 24.02
</table>
<tableCaption confidence="0.9659815">
Table 4: Automatic metric scores for the develop-
ment test set newstest2009
</tableCaption>
<bodyText confidence="0.998389714285714">
following file: http://sourceforge.net/
projects/joshua/files/joshua/1.3/
wmt2010-experiment.tgz/download.
The README file details how to configure the
workflow for your environment. Note that SRILM
must be downloaded and compiled separately
before running the experimental steps.
</bodyText>
<sectionHeader confidence="0.985111" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9434705">
This work was supported by the DARPA GALE
program (Contract No HR0011-06-2-0001).
</bodyText>
<sectionHeader confidence="0.990555" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998856862068966">
Kathy Baker, Steven Bethard, Michael Bloodgood,
Ralf Brown, Chris Callison-Burch, Glen Copper-
smith, Bonnie Dorr, Wes Filardo, Kendall Giles,
Anni Irvine, Mike Kayser, Lori Levin, Justin Mar-
tineau, Jim Mayfield, Scott Miller, Aaron Phillips,
Andrew Philpot, Christine Piatko, Lane Schwartz,
and David Zajic. 2009. Semantically informed ma-
chine translation (SIMT). SCALE summer work-
shop final report, Human Language Technology
Center Of Excellence.
Chris Callison-Burch, Cameron Fordyce, Philipp
Koehn, Christof Monz, and Josh Schroeder. 2007.
(Meta-) evaluation of machine translation. In Pro-
ceedings of the Second Workshop on Statistical Ma-
chine Translation (WMT07).
Chris Callison-Burch, Cameron Fordyce, Philipp
Koehn, Christof Monz, and Josh Schroeder. 2008.
Further meta-evaluation of machine translation. In
Proceedings of the Third Workshop on Statistical
Machine Translation (WMT08).
Chris Callison-Burch, Philipp Koehn, Christof Monz,
and Josh Schroeder. 2009. Findings of the 2009
Workshop on Statistical Machine Translation. In
Proceedings of the Fourth Workshop on Statistical
Machine Translation (WMT09), March.
Stanley Chen and Joshua Goodman. 1998. An em-
pirical study of smoothing techniques for language
modeling. Technical Report TR-10-98, Harvard
University, Cambridge, MA, USA, August.
</reference>
<page confidence="0.991584">
181
</page>
<reference confidence="0.999306954128441">
Jonathan Clark, Jonathan Weese, Byung Gyu Ahn,
Andreas Zollman, Qin Gao, Kenneth Heafield, and
Alon Lavie. 2010. The machine translation tool-
pack for LoonyBin: Automated management of
experimental machine translation hyperworkflows.
The Prague Bulletin of Mathematical Linguistics,
93:117–126, January.
C. Dyer, A. Lopez, J. Ganitkevitch, J. Weese,
F. Ture, P. Blunsom, H. Setiawan, V. Eidelman, and
P. Resnik. 2010. cdec: A decoder, alignment, and
learning framework for finite-state and context-free
translation models. In Proc. ACL (Demonstration
Track), Uppsala, Sweden.
Marcello Federico, Nicola Bertoldi, and Mauro Cet-
tolo. 2008. IRSTLM: An open source toolkit for
handling large scale language models. In Proc. In-
terspeech, Brisbane, Australia.
Reinhard Kneser and Hermann Ney. 1995. Improved
smoothing for mgram language modeling. In Pro-
ceedings of the International Conference on Acous-
tics, Speech and Signal Processing.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proc. ACL-2007 Demo and Poster Sessions.
Philipp Koehn, Anthony Rousseau, Ben Gottesmann,
Aurora Marsye, Fr´ed´eric Blain, and Eun-Jin Park,
2010. An Experiment Management System. Fourth
Machine Translation Marathon, Dublin, Ireland,
January.
Philipp Koehn. 2005. A parallel corpus for statistical
machine translation. In Proceedings of MT-Summit,
Phuket, Thailand.
Shankar Kumar and William Byrne. 2004. Minimum
bayes-risk decoding for statistical machine transla-
tion. In Proceedings of HLT/NAACL.
Zhifei Li, Chris Callison-Burch, Chris Dyer, Juri Gan-
itkevitch, Sanjeev Khudanpur, Lane Schwartz, Wren
Thornton, Jonathan Weese, and Omar Zaidan. 2009.
Joshua: An open source toolkit for parsing-based
machine translation. In Proceedings of the Fourth
Workshop on Statistical Machine Translation, pages
135–139, Athens, Greece, March. Association for
Computational Linguistics.
P. Liang, B. Taskar, and D. Klein. 2006. Align-
ment by agreement. In North American Association
for Computational Linguistics (NAACL), pages 104–
111.
Adam Lopez. 2008. Machine Translation by Pattern
Matching. Ph.D. thesis, University of Maryland.
Franz Josef Och. 2003. Minimum error rate training
for statistical machine translation. In Proceedings
of ACL.
Marian Olteanu, Chris Davis, Ionut Volosen, and Dan
Moldovan. 2006. Phramer an open source statis-
tical pharse-based translator. In HLT-NAACL 2006:
Proceedings of the Workshop on Statistical Machine
Translation, New York, June.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: A method for automatic
evaluation of machine translation. In Proceedings
ofACL.
Ted Pedersen. 2008. Empiricism is not a matter of
faith. Computational Linguistics, 34(3):465–470.
Aaron B. Phillips and Ralf D. Brown. 2009. Cunei ma-
chine translation platform: System description. In
3rd Workshop on Example-Based Machine Transla-
tion, Dublin, Ireland.
Lane Schwartz and Chris Callison-Burch. 2010. Hier-
archical phrase-based grammar extraction in joshua
suix arrays and prex trees. The Prague Bulletin of
Mathematical Linguistics, 93:157–166.
Lane Schwartz. 2008. An open-source hierarchical
phrase-based translation system. In Proceedings of
the 5th Midwest Computational Linguistics Collo-
quium (MCLC’08), May.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A study of
translation edit rate with targeted human annotation.
In Proceedings ofAMTA.
Richard M. Stallman, Roland McGrath, and Paul D.
Smith, 2006. GNU Make. Free Software Founda-
tion, Boston, MA, 0.70 edition, April.
Ralf Steinberger, Bruno Pouliquen, Anna Widiger,
Camelia Ignat, Tomaz Erjavec, Dan Tufis, and
Daniel Varga. 2006. The JRC-acquis: A multi-
lingual aligned parallel corpus with 20+ languages.
In Proceedings of the 5th International Conference
on Language Resources and Evaluation (LREC),
Genoa, Italy.
Andreas Stolcke. 2002. SRILM - an extensible lan-
guage modeling toolkit. In Proceedings of the Inter-
national Conference on Spoken Language Process-
ing, Denver, Colorado, September.
David Talbot and Miles Osborne. 2007. Randomised
language modelling for statistical machine transla-
tion. In Proceedings of ACL.
Omar F. Zaidan. 2009. Z-MERT: A fully configurable
open source tool for minimum error rate training of
machine translation systems. The Prague Bulletin of
Mathematical Linguistics, 91:79–88.
Andreas Zollmann and Ashish Venugopal. 2006. Syn-
tax augmented machine translation via chart pars-
ing. In Proceedings of the NAACL-2006 Workshop
on Statistical Machine Translation (WMT-06), New
York, New York.
</reference>
<page confidence="0.998015">
182
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.712294">
<title confidence="0.9928545">Reproducible Results in Parsing-Based Machine The JHU Shared Task Submission</title>
<author confidence="0.972837">Schwartz</author>
<affiliation confidence="0.8724935">University of Minneapolis,</affiliation>
<email confidence="0.999942">lane@cs.umn.edu</email>
<abstract confidence="0.999136777777778">We present the Johns Hopkins University submission to the 2010 WMT shared translation task. We describe processing steps using open data and open source software used in our submission, and provide the scripts and configurations required to train, tune, and test our machine translation system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Kathy Baker</author>
<author>Steven Bethard</author>
<author>Michael Bloodgood</author>
<author>Ralf Brown</author>
<author>Chris Callison-Burch</author>
<author>Glen Coppersmith</author>
<author>Bonnie Dorr</author>
<author>Wes Filardo</author>
<author>Kendall Giles</author>
</authors>
<title>Semantically informed machine translation (SIMT). SCALE summer workshop final report,</title>
<date>2009</date>
<institution>Human Language Technology Center Of Excellence.</institution>
<location>Anni Irvine, Mike Kayser, Lori Levin, Justin Martineau, Jim Mayfield, Scott Miller, Aaron Phillips, Andrew Philpot, Christine Piatko, Lane</location>
<contexts>
<context position="11981" citStr="Baker et al., 2009" startWordPosition="1665" endWordPosition="1668">nterminals - the wildcard nonterminal X, and S, used to glue 4http://berkeleyaligner.googlecode.com/files/berkeleyaligner unsupervised-2.1.tar.gz — Berkeley aligner version 2.1 5It is expected that using the Joshua implementation should result in nearly identical results, albeit with somewhat more time required to extract the grammar. together neighboring constituents. Recent work has shown that parsing-based machine translation using SAMT (Zollmann and Venugopal, 2006) grammars with rich nonterminal sets can demonstrate substantial gains over hierarchical grammars for certain language pairs (Baker et al., 2009). Joshua supports such grammars; the experimental workflow presented here could easily be extended in future research to incorporate the use of SAMT grammars with additional language pairs. The Z-MERT implementation (Zaidan, 2009) of minimum error rate training (Och, 2003) was used for parameter tuning. Tuned grammars were used by Joshua to translate all test sets. The Joshua decoder produces n-best lists of translations. Rather than simply selecting the top candidate from each list, we take the preferred candidate after perform minimum Bayes risk rescoring (Kumar and Byrne, 2004). Once a sing</context>
</contexts>
<marker>Baker, Bethard, Bloodgood, Brown, Callison-Burch, Coppersmith, Dorr, Filardo, Giles, 2009</marker>
<rawString>Kathy Baker, Steven Bethard, Michael Bloodgood, Ralf Brown, Chris Callison-Burch, Glen Coppersmith, Bonnie Dorr, Wes Filardo, Kendall Giles, Anni Irvine, Mike Kayser, Lori Levin, Justin Martineau, Jim Mayfield, Scott Miller, Aaron Phillips, Andrew Philpot, Christine Piatko, Lane Schwartz, and David Zajic. 2009. Semantically informed machine translation (SIMT). SCALE summer workshop final report, Human Language Technology Center Of Excellence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Cameron Fordyce</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Josh Schroeder</author>
</authors>
<title>(Meta-) evaluation of machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation (WMT07).</booktitle>
<contexts>
<context position="4878" citStr="Callison-Burch et al., 2007" startWordPosition="702" endWordPosition="705">orkflow. Square nodes in grey indicate software and scripts. The scripts and configuration files used to implement and run this workflow are available for download at http://sourceforge.net/projects/joshua/files/joshua/1.3/ wmt2010-experiment.tgz/download 178 querying of n-gram language models. Freely available parallel corpora for numerous European languages have also been released in recent years. These include the Europarl (Koehn, 2005) and JRC-Acquis (Steinberger et al., 2006) legislative corpora, each of which includes data for most EU language pairs. The smaller News Commentary corpora (Callison-Burch et al., 2007; Callison-Burch et al., 2008) provide smaller amounts of parallel data in the news genre. The recent Fr-En 109 (Callison-Burch et al., 2009) corpus aggregates huge numbers of parallel FrenchEnglish sentences from the web. Open source systems to address the complex workflows required to run non-trivial machine translation experiments have also been developed. These include experiment.perl (Koehn et al., 2010), developed as a workflow management system at the University of Edinburgh, and LoonyBin (Clark et al., 2010), a general hyperworkflow management utility from Carnegie Melon University. 3 </context>
</contexts>
<marker>Callison-Burch, Fordyce, Koehn, Monz, Schroeder, 2007</marker>
<rawString>Chris Callison-Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, and Josh Schroeder. 2007. (Meta-) evaluation of machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation (WMT07).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Cameron Fordyce</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Josh Schroeder</author>
</authors>
<title>Further meta-evaluation of machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation (WMT08).</booktitle>
<contexts>
<context position="4908" citStr="Callison-Burch et al., 2008" startWordPosition="706" endWordPosition="709"> indicate software and scripts. The scripts and configuration files used to implement and run this workflow are available for download at http://sourceforge.net/projects/joshua/files/joshua/1.3/ wmt2010-experiment.tgz/download 178 querying of n-gram language models. Freely available parallel corpora for numerous European languages have also been released in recent years. These include the Europarl (Koehn, 2005) and JRC-Acquis (Steinberger et al., 2006) legislative corpora, each of which includes data for most EU language pairs. The smaller News Commentary corpora (Callison-Burch et al., 2007; Callison-Burch et al., 2008) provide smaller amounts of parallel data in the news genre. The recent Fr-En 109 (Callison-Burch et al., 2009) corpus aggregates huge numbers of parallel FrenchEnglish sentences from the web. Open source systems to address the complex workflows required to run non-trivial machine translation experiments have also been developed. These include experiment.perl (Koehn et al., 2010), developed as a workflow management system at the University of Edinburgh, and LoonyBin (Clark et al., 2010), a general hyperworkflow management utility from Carnegie Melon University. 3 Managing Experiment Worliflows</context>
</contexts>
<marker>Callison-Burch, Fordyce, Koehn, Monz, Schroeder, 2008</marker>
<rawString>Chris Callison-Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, and Josh Schroeder. 2008. Further meta-evaluation of machine translation. In Proceedings of the Third Workshop on Statistical Machine Translation (WMT08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Josh Schroeder</author>
</authors>
<date>2009</date>
<booktitle>Findings of the 2009 Workshop on Statistical Machine Translation. In Proceedings of the Fourth Workshop on Statistical Machine Translation (WMT09),</booktitle>
<contexts>
<context position="5019" citStr="Callison-Burch et al., 2009" startWordPosition="725" endWordPosition="728"> available for download at http://sourceforge.net/projects/joshua/files/joshua/1.3/ wmt2010-experiment.tgz/download 178 querying of n-gram language models. Freely available parallel corpora for numerous European languages have also been released in recent years. These include the Europarl (Koehn, 2005) and JRC-Acquis (Steinberger et al., 2006) legislative corpora, each of which includes data for most EU language pairs. The smaller News Commentary corpora (Callison-Burch et al., 2007; Callison-Burch et al., 2008) provide smaller amounts of parallel data in the news genre. The recent Fr-En 109 (Callison-Burch et al., 2009) corpus aggregates huge numbers of parallel FrenchEnglish sentences from the web. Open source systems to address the complex workflows required to run non-trivial machine translation experiments have also been developed. These include experiment.perl (Koehn et al., 2010), developed as a workflow management system at the University of Edinburgh, and LoonyBin (Clark et al., 2010), a general hyperworkflow management utility from Carnegie Melon University. 3 Managing Experiment Worliflows Running a statistical machine translation system to achieve state-of-the-art performance involves the configur</context>
</contexts>
<marker>Callison-Burch, Koehn, Monz, Schroeder, 2009</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, Christof Monz, and Josh Schroeder. 2009. Findings of the 2009 Workshop on Statistical Machine Translation. In Proceedings of the Fourth Workshop on Statistical Machine Translation (WMT09), March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley Chen</author>
<author>Joshua Goodman</author>
</authors>
<title>An empirical study of smoothing techniques for language modeling.</title>
<date>1998</date>
<tech>Technical Report TR-10-98,</tech>
<institution>Harvard University,</institution>
<location>Cambridge, MA, USA,</location>
<contexts>
<context position="8425" citStr="Chen and Goodman (1998)" startWordPosition="1248" endWordPosition="1251">ed task data set newstest2010 was used as a final blind test set. All data was automatically downloaded, unzipped, and preprocessed prior to use. Files provided in XML format were converted to plain text by selecting lines with &lt;seg&gt; tags, then removing the beginning and end tags for each segment; this processing was applied using GNU grep and sed. The tokenize.perl and lowercase.perl scripts provided for the shared task2 were applied to all data. Interpolated n-gram language models for the four target languages were built using the SRI Language Model Toolkit3, with n-gram order set to 5. The Chen and Goodman (1998) technique for modified Kneser-Ney discounting (Kneser and Ney, 1995) was applied during language model training. Following Li et al. (2009), a subset of the available training sentences was selected via subsam1http://sourceforge.net/projects/joshua/files/joshua/1.3/wmt2010- experiment.tgz/download 2http://www.statmt.org/wmt08/scripts.tgz with md5sum: tokenize.perl 45cd1832827131013245eca76481441a lowercase.perl a1958ab429b1e29d379063c3b9cd7062 3http://www-speech.sri.com/projects/srilm SRILM version 1.5.7. Our experimental workflow requires that SRILM be compiled separately, with the $SRILM en</context>
</contexts>
<marker>Chen, Goodman, 1998</marker>
<rawString>Stanley Chen and Joshua Goodman. 1998. An empirical study of smoothing techniques for language modeling. Technical Report TR-10-98, Harvard University, Cambridge, MA, USA, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Clark</author>
<author>Jonathan Weese</author>
<author>Byung Gyu Ahn</author>
<author>Andreas Zollman</author>
<author>Qin Gao</author>
<author>Kenneth Heafield</author>
<author>Alon Lavie</author>
</authors>
<title>The machine translation toolpack for LoonyBin: Automated management of experimental machine translation hyperworkflows. The Prague Bulletin of Mathematical Linguistics,</title>
<date>2010</date>
<pages>93--117</pages>
<contexts>
<context position="5399" citStr="Clark et al., 2010" startWordPosition="782" endWordPosition="785"> data for most EU language pairs. The smaller News Commentary corpora (Callison-Burch et al., 2007; Callison-Burch et al., 2008) provide smaller amounts of parallel data in the news genre. The recent Fr-En 109 (Callison-Burch et al., 2009) corpus aggregates huge numbers of parallel FrenchEnglish sentences from the web. Open source systems to address the complex workflows required to run non-trivial machine translation experiments have also been developed. These include experiment.perl (Koehn et al., 2010), developed as a workflow management system at the University of Edinburgh, and LoonyBin (Clark et al., 2010), a general hyperworkflow management utility from Carnegie Melon University. 3 Managing Experiment Worliflows Running a statistical machine translation system to achieve state-of-the-art performance involves the configuration and execution of numerous interdependent intermediate tools. To manage task dependencies and tool configuration, our shared task workflow consists of a set of dependency scripts written for GNU Make (Stallman et al., 2006). Figure 1 shows a graph depicting the steps in our experimental workflow, and the dependencies between steps. Each node in the graph represents a step </context>
</contexts>
<marker>Clark, Weese, Ahn, Zollman, Gao, Heafield, Lavie, 2010</marker>
<rawString>Jonathan Clark, Jonathan Weese, Byung Gyu Ahn, Andreas Zollman, Qin Gao, Kenneth Heafield, and Alon Lavie. 2010. The machine translation toolpack for LoonyBin: Automated management of experimental machine translation hyperworkflows. The Prague Bulletin of Mathematical Linguistics, 93:117–126, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Dyer</author>
<author>A Lopez</author>
<author>J Ganitkevitch</author>
<author>J Weese</author>
<author>F Ture</author>
<author>P Blunsom</author>
<author>H Setiawan</author>
<author>V Eidelman</author>
<author>P Resnik</author>
</authors>
<title>cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models.</title>
<date>2010</date>
<booktitle>In Proc. ACL (Demonstration Track),</booktitle>
<location>Uppsala,</location>
<contexts>
<context position="3332" citStr="Dyer et al., 2010" startWordPosition="493" endWordPosition="496">chine translation workflow management systems. Section 3 describes the experimental workflow used to run the shared task translations, with the corresponding experimental design in section 4. Section 5 presents the shared task results. 2 Related Work The last four years have witnessed the implementation and release of numerous open source machine translation systems. The widely used Moses system (Koehn et al., 2007) implements the standard phrase-based translation model. Parsingbased translation models are implemented by Joshua (Li et al., 2009), SAMT (Zollmann and Venugopal, 2006), and cdec (Dyer et al., 2010). Cunei (Phillips and Brown, 2009) implements statistical example-based translation. Olteanu et al. (2006) and Schwartz (2008) respectively provide additional open-source implementations of phrase-based and hierarchical decoders. The SRILM (Stolcke, 2002), IRSTLM (Federico et al., 2008), and RandLM (Talbot and Osborne, 2007) toolkits enable efficient training and 177 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 177–182, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics Download Data Unzip Data WMT Scripts Remov</context>
</contexts>
<marker>Dyer, Lopez, Ganitkevitch, Weese, Ture, Blunsom, Setiawan, Eidelman, Resnik, 2010</marker>
<rawString>C. Dyer, A. Lopez, J. Ganitkevitch, J. Weese, F. Ture, P. Blunsom, H. Setiawan, V. Eidelman, and P. Resnik. 2010. cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models. In Proc. ACL (Demonstration Track), Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Mauro Cettolo</author>
</authors>
<title>IRSTLM: An open source toolkit for handling large scale language models.</title>
<date>2008</date>
<booktitle>In Proc. Interspeech,</booktitle>
<location>Brisbane, Australia.</location>
<contexts>
<context position="3619" citStr="Federico et al., 2008" startWordPosition="529" endWordPosition="533">ed the implementation and release of numerous open source machine translation systems. The widely used Moses system (Koehn et al., 2007) implements the standard phrase-based translation model. Parsingbased translation models are implemented by Joshua (Li et al., 2009), SAMT (Zollmann and Venugopal, 2006), and cdec (Dyer et al., 2010). Cunei (Phillips and Brown, 2009) implements statistical example-based translation. Olteanu et al. (2006) and Schwartz (2008) respectively provide additional open-source implementations of phrase-based and hierarchical decoders. The SRILM (Stolcke, 2002), IRSTLM (Federico et al., 2008), and RandLM (Talbot and Osborne, 2007) toolkits enable efficient training and 177 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 177–182, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics Download Data Unzip Data WMT Scripts Remove XML Tokenize Normalize Joshua Berkeley Aligner Subsample Subsample for Truecasing Align Align Truecased Data SRILM Hiero Train Truecase LM Train LM Extract Grammar Extract Truecase Grammar Run MERT Translate Run MBR on Translations Restore to Truecase Run MBR on Truecased Translations</context>
</contexts>
<marker>Federico, Bertoldi, Cettolo, 2008</marker>
<rawString>Marcello Federico, Nicola Bertoldi, and Mauro Cettolo. 2008. IRSTLM: An open source toolkit for handling large scale language models. In Proc. Interspeech, Brisbane, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Kneser</author>
<author>Hermann Ney</author>
</authors>
<title>Improved smoothing for mgram language modeling.</title>
<date>1995</date>
<booktitle>In Proceedings of the International Conference on Acoustics, Speech and Signal Processing.</booktitle>
<contexts>
<context position="8494" citStr="Kneser and Ney, 1995" startWordPosition="1257" endWordPosition="1260">ata was automatically downloaded, unzipped, and preprocessed prior to use. Files provided in XML format were converted to plain text by selecting lines with &lt;seg&gt; tags, then removing the beginning and end tags for each segment; this processing was applied using GNU grep and sed. The tokenize.perl and lowercase.perl scripts provided for the shared task2 were applied to all data. Interpolated n-gram language models for the four target languages were built using the SRI Language Model Toolkit3, with n-gram order set to 5. The Chen and Goodman (1998) technique for modified Kneser-Ney discounting (Kneser and Ney, 1995) was applied during language model training. Following Li et al. (2009), a subset of the available training sentences was selected via subsam1http://sourceforge.net/projects/joshua/files/joshua/1.3/wmt2010- experiment.tgz/download 2http://www.statmt.org/wmt08/scripts.tgz with md5sum: tokenize.perl 45cd1832827131013245eca76481441a lowercase.perl a1958ab429b1e29d379063c3b9cd7062 3http://www-speech.sri.com/projects/srilm SRILM version 1.5.7. Our experimental workflow requires that SRILM be compiled separately, with the $SRILM environment variable set to the install location. 179 Source Target Par</context>
</contexts>
<marker>Kneser, Ney, 1995</marker>
<rawString>Reinhard Kneser and Hermann Ney. 1995. Improved smoothing for mgram language modeling. In Proceedings of the International Conference on Acoustics, Speech and Signal Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. ACL-2007 Demo</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="3133" citStr="Koehn et al., 2007" startWordPosition="463" endWordPosition="466">ed herein are provided. The remainder of this paper is structured as follows. Section 2 lists the major examples of publicly available open source machine translation systems, parallel corpora, and machine translation workflow management systems. Section 3 describes the experimental workflow used to run the shared task translations, with the corresponding experimental design in section 4. Section 5 presents the shared task results. 2 Related Work The last four years have witnessed the implementation and release of numerous open source machine translation systems. The widely used Moses system (Koehn et al., 2007) implements the standard phrase-based translation model. Parsingbased translation models are implemented by Joshua (Li et al., 2009), SAMT (Zollmann and Venugopal, 2006), and cdec (Dyer et al., 2010). Cunei (Phillips and Brown, 2009) implements statistical example-based translation. Olteanu et al. (2006) and Schwartz (2008) respectively provide additional open-source implementations of phrase-based and hierarchical decoders. The SRILM (Stolcke, 2002), IRSTLM (Federico et al., 2008), and RandLM (Talbot and Osborne, 2007) toolkits enable efficient training and 177 Proceedings of the Joint 5th Wo</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proc. ACL-2007 Demo and Poster Sessions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Anthony Rousseau</author>
<author>Ben Gottesmann</author>
<author>Aurora Marsye</author>
<author>Fr´ed´eric Blain</author>
<author>Eun-Jin Park</author>
</authors>
<title>An Experiment Management System. Fourth Machine Translation Marathon,</title>
<date>2010</date>
<location>Dublin, Ireland,</location>
<contexts>
<context position="5290" citStr="Koehn et al., 2010" startWordPosition="764" endWordPosition="767"> Europarl (Koehn, 2005) and JRC-Acquis (Steinberger et al., 2006) legislative corpora, each of which includes data for most EU language pairs. The smaller News Commentary corpora (Callison-Burch et al., 2007; Callison-Burch et al., 2008) provide smaller amounts of parallel data in the news genre. The recent Fr-En 109 (Callison-Burch et al., 2009) corpus aggregates huge numbers of parallel FrenchEnglish sentences from the web. Open source systems to address the complex workflows required to run non-trivial machine translation experiments have also been developed. These include experiment.perl (Koehn et al., 2010), developed as a workflow management system at the University of Edinburgh, and LoonyBin (Clark et al., 2010), a general hyperworkflow management utility from Carnegie Melon University. 3 Managing Experiment Worliflows Running a statistical machine translation system to achieve state-of-the-art performance involves the configuration and execution of numerous interdependent intermediate tools. To manage task dependencies and tool configuration, our shared task workflow consists of a set of dependency scripts written for GNU Make (Stallman et al., 2006). Figure 1 shows a graph depicting the step</context>
</contexts>
<marker>Koehn, Rousseau, Gottesmann, Marsye, Blain, Park, 2010</marker>
<rawString>Philipp Koehn, Anthony Rousseau, Ben Gottesmann, Aurora Marsye, Fr´ed´eric Blain, and Eun-Jin Park, 2010. An Experiment Management System. Fourth Machine Translation Marathon, Dublin, Ireland, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of MT-Summit,</booktitle>
<location>Phuket, Thailand.</location>
<contexts>
<context position="4694" citStr="Koehn, 2005" startWordPosition="677" endWordPosition="678">Extract Grammar Extract Truecase Grammar Run MERT Translate Run MBR on Translations Restore to Truecase Run MBR on Truecased Translations Figure 1: Machine translation workflow. Square nodes in grey indicate software and scripts. The scripts and configuration files used to implement and run this workflow are available for download at http://sourceforge.net/projects/joshua/files/joshua/1.3/ wmt2010-experiment.tgz/download 178 querying of n-gram language models. Freely available parallel corpora for numerous European languages have also been released in recent years. These include the Europarl (Koehn, 2005) and JRC-Acquis (Steinberger et al., 2006) legislative corpora, each of which includes data for most EU language pairs. The smaller News Commentary corpora (Callison-Burch et al., 2007; Callison-Burch et al., 2008) provide smaller amounts of parallel data in the news genre. The recent Fr-En 109 (Callison-Burch et al., 2009) corpus aggregates huge numbers of parallel FrenchEnglish sentences from the web. Open source systems to address the complex workflows required to run non-trivial machine translation experiments have also been developed. These include experiment.perl (Koehn et al., 2010), de</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. A parallel corpus for statistical machine translation. In Proceedings of MT-Summit, Phuket, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shankar Kumar</author>
<author>William Byrne</author>
</authors>
<title>Minimum bayes-risk decoding for statistical machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT/NAACL.</booktitle>
<contexts>
<context position="12568" citStr="Kumar and Byrne, 2004" startWordPosition="1755" endWordPosition="1759">language pairs (Baker et al., 2009). Joshua supports such grammars; the experimental workflow presented here could easily be extended in future research to incorporate the use of SAMT grammars with additional language pairs. The Z-MERT implementation (Zaidan, 2009) of minimum error rate training (Och, 2003) was used for parameter tuning. Tuned grammars were used by Joshua to translate all test sets. The Joshua decoder produces n-best lists of translations. Rather than simply selecting the top candidate from each list, we take the preferred candidate after perform minimum Bayes risk rescoring (Kumar and Byrne, 2004). Once a single translation has been extracted for each sentence in the test set, we repeat the procedures described above to train language and translation models for use in translating lowercased results into a more human-readable truecased form. A truecase language model is trained as above, but on the tokenized (but not normalized) monolingual target language corpus. Monotone word alignments are deterministically created, mapping normalized lowercase training text to the original truecase text. As in bilingual translation, subsampling is performed for the training set, and a translation gr</context>
</contexts>
<marker>Kumar, Byrne, 2004</marker>
<rawString>Shankar Kumar and William Byrne. 2004. Minimum bayes-risk decoding for statistical machine translation. In Proceedings of HLT/NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhifei Li</author>
<author>Chris Callison-Burch</author>
<author>Chris Dyer</author>
<author>Juri Ganitkevitch</author>
<author>Sanjeev Khudanpur</author>
<author>Lane Schwartz</author>
<author>Wren Thornton</author>
<author>Jonathan Weese</author>
<author>Omar Zaidan</author>
</authors>
<title>Joshua: An open source toolkit for parsing-based machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Machine Translation,</booktitle>
<pages>135--139</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Athens, Greece,</location>
<contexts>
<context position="3265" citStr="Li et al., 2009" startWordPosition="482" endWordPosition="485">open source machine translation systems, parallel corpora, and machine translation workflow management systems. Section 3 describes the experimental workflow used to run the shared task translations, with the corresponding experimental design in section 4. Section 5 presents the shared task results. 2 Related Work The last four years have witnessed the implementation and release of numerous open source machine translation systems. The widely used Moses system (Koehn et al., 2007) implements the standard phrase-based translation model. Parsingbased translation models are implemented by Joshua (Li et al., 2009), SAMT (Zollmann and Venugopal, 2006), and cdec (Dyer et al., 2010). Cunei (Phillips and Brown, 2009) implements statistical example-based translation. Olteanu et al. (2006) and Schwartz (2008) respectively provide additional open-source implementations of phrase-based and hierarchical decoders. The SRILM (Stolcke, 2002), IRSTLM (Federico et al., 2008), and RandLM (Talbot and Osborne, 2007) toolkits enable efficient training and 177 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 177–182, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for C</context>
<context position="8565" citStr="Li et al. (2009)" startWordPosition="1268" endWordPosition="1271">iles provided in XML format were converted to plain text by selecting lines with &lt;seg&gt; tags, then removing the beginning and end tags for each segment; this processing was applied using GNU grep and sed. The tokenize.perl and lowercase.perl scripts provided for the shared task2 were applied to all data. Interpolated n-gram language models for the four target languages were built using the SRI Language Model Toolkit3, with n-gram order set to 5. The Chen and Goodman (1998) technique for modified Kneser-Ney discounting (Kneser and Ney, 1995) was applied during language model training. Following Li et al. (2009), a subset of the available training sentences was selected via subsam1http://sourceforge.net/projects/joshua/files/joshua/1.3/wmt2010- experiment.tgz/download 2http://www.statmt.org/wmt08/scripts.tgz with md5sum: tokenize.perl 45cd1832827131013245eca76481441a lowercase.perl a1958ab429b1e29d379063c3b9cd7062 3http://www-speech.sri.com/projects/srilm SRILM version 1.5.7. Our experimental workflow requires that SRILM be compiled separately, with the $SRILM environment variable set to the install location. 179 Source Target Parallel Corpora German English news-commentary10.de-en europarl-v5.de-en </context>
</contexts>
<marker>Li, Callison-Burch, Dyer, Ganitkevitch, Khudanpur, Schwartz, Thornton, Weese, Zaidan, 2009</marker>
<rawString>Zhifei Li, Chris Callison-Burch, Chris Dyer, Juri Ganitkevitch, Sanjeev Khudanpur, Lane Schwartz, Wren Thornton, Jonathan Weese, and Omar Zaidan. 2009. Joshua: An open source toolkit for parsing-based machine translation. In Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 135–139, Athens, Greece, March. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Liang</author>
<author>B Taskar</author>
<author>D Klein</author>
</authors>
<title>Alignment by agreement.</title>
<date>2006</date>
<booktitle>In North American Association for Computational Linguistics (NAACL),</booktitle>
<pages>104--111</pages>
<contexts>
<context position="10379" citStr="Liang et al., 2006" startWordPosition="1438" endWordPosition="1441">en.release2.en French europarl-v5.fr news-commentary10.fr news.fr.shuffled undoc.2000.en-fr.fr giga-fren.release2.fr German europarl-v5.de news-commentary10.de news.de.shuffled Spanish europarl-v5.es news-commentary10.es news.es.shuffled undoc.2000.en-es.es Table 2: Monolingual training data used for training language model, per target language pling; training sentences are selected based on the estimated likelihood of each sentence being useful later for translating a particular test corpus. Given a subsampled parallel training corpus, word alignment is performed using the Berkeley aligner4 (Liang et al., 2006). For each language pair, a synchronous context free translation grammar is extracted for a particular test set, following the methods of Lopez (2008) as implemented in (Schwartz and Callison-Burch, 2010). For the largest training sets (FrenchEnglish and English-French) the original (Lopez, 2008) implementation included with Hiero was used to save time during training5. Because of the use of subsampling, the extracted translation grammars are targeted for use with a specific test set. Our experiments were begun prior to the release of the blind newstest2010 shared task test set. Subsampling wa</context>
</contexts>
<marker>Liang, Taskar, Klein, 2006</marker>
<rawString>P. Liang, B. Taskar, and D. Klein. 2006. Alignment by agreement. In North American Association for Computational Linguistics (NAACL), pages 104– 111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Lopez</author>
</authors>
<title>Machine Translation by Pattern Matching.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Maryland.</institution>
<contexts>
<context position="10529" citStr="Lopez (2008)" startWordPosition="1464" endWordPosition="1465">de news.de.shuffled Spanish europarl-v5.es news-commentary10.es news.es.shuffled undoc.2000.en-es.es Table 2: Monolingual training data used for training language model, per target language pling; training sentences are selected based on the estimated likelihood of each sentence being useful later for translating a particular test corpus. Given a subsampled parallel training corpus, word alignment is performed using the Berkeley aligner4 (Liang et al., 2006). For each language pair, a synchronous context free translation grammar is extracted for a particular test set, following the methods of Lopez (2008) as implemented in (Schwartz and Callison-Burch, 2010). For the largest training sets (FrenchEnglish and English-French) the original (Lopez, 2008) implementation included with Hiero was used to save time during training5. Because of the use of subsampling, the extracted translation grammars are targeted for use with a specific test set. Our experiments were begun prior to the release of the blind newstest2010 shared task test set. Subsampling was performed for the development tuning set, news-test2008, and the development test set, newstest2009. Once the newstest2010 test set was released, th</context>
<context position="13814" citStr="Lopez, 2008" startWordPosition="1935" endWordPosition="1936"> extracted. No tuning is 180 6http://sourceforge.net/projects/joshua/files/joshua/1.3/joshua1.3.tgz/download — Joshua version 1.3 performed. The Joshua decoder is used to translate the lowercased target language test results into truecase format. The detokenize.perl and wrap-xml.perl scripts provided for the shared task were manually applied to truecased translation results prior to final submission of results. The code used for subsampling, grammar extraction, decoding, minimum error rate training, and minimum Bayes risk rescoring is provided with Joshua6, with the exception of the original (Lopez, 2008) grammar extraction implementation. 5 Experimental Results The experiments described in sections 3 and 4 above provided truecased translations for six language pairs in the translation shared task: English-French, English-German, EnglishSpanish, French-English, German-English, and Spanish-English. Table 3 lists the automatic metric scores for the newstest2010 test set, according to the BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) metrics. Source Target BLEU BLEU- TER cased German English 21.3 19.5 0.660 English German 15.2 14.6 0.738 French English 27.7 26.4 0.614 English French </context>
</contexts>
<marker>Lopez, 2008</marker>
<rawString>Adam Lopez. 2008. Machine Translation by Pattern Matching. Ph.D. thesis, University of Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training for statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="12254" citStr="Och, 2003" startWordPosition="1706" endWordPosition="1707">th somewhat more time required to extract the grammar. together neighboring constituents. Recent work has shown that parsing-based machine translation using SAMT (Zollmann and Venugopal, 2006) grammars with rich nonterminal sets can demonstrate substantial gains over hierarchical grammars for certain language pairs (Baker et al., 2009). Joshua supports such grammars; the experimental workflow presented here could easily be extended in future research to incorporate the use of SAMT grammars with additional language pairs. The Z-MERT implementation (Zaidan, 2009) of minimum error rate training (Och, 2003) was used for parameter tuning. Tuned grammars were used by Joshua to translate all test sets. The Joshua decoder produces n-best lists of translations. Rather than simply selecting the top candidate from each list, we take the preferred candidate after perform minimum Bayes risk rescoring (Kumar and Byrne, 2004). Once a single translation has been extracted for each sentence in the test set, we repeat the procedures described above to train language and translation models for use in translating lowercased results into a more human-readable truecased form. A truecase language model is trained </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training for statistical machine translation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marian Olteanu</author>
<author>Chris Davis</author>
<author>Ionut Volosen</author>
<author>Dan Moldovan</author>
</authors>
<title>Phramer an open source statistical pharse-based translator.</title>
<date>2006</date>
<booktitle>In HLT-NAACL 2006: Proceedings of the Workshop on Statistical Machine Translation,</booktitle>
<location>New York,</location>
<contexts>
<context position="3438" citStr="Olteanu et al. (2006)" startWordPosition="506" endWordPosition="509">n the shared task translations, with the corresponding experimental design in section 4. Section 5 presents the shared task results. 2 Related Work The last four years have witnessed the implementation and release of numerous open source machine translation systems. The widely used Moses system (Koehn et al., 2007) implements the standard phrase-based translation model. Parsingbased translation models are implemented by Joshua (Li et al., 2009), SAMT (Zollmann and Venugopal, 2006), and cdec (Dyer et al., 2010). Cunei (Phillips and Brown, 2009) implements statistical example-based translation. Olteanu et al. (2006) and Schwartz (2008) respectively provide additional open-source implementations of phrase-based and hierarchical decoders. The SRILM (Stolcke, 2002), IRSTLM (Federico et al., 2008), and RandLM (Talbot and Osborne, 2007) toolkits enable efficient training and 177 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 177–182, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics Download Data Unzip Data WMT Scripts Remove XML Tokenize Normalize Joshua Berkeley Aligner Subsample Subsample for Truecasing Align Align Truecased </context>
</contexts>
<marker>Olteanu, Davis, Volosen, Moldovan, 2006</marker>
<rawString>Marian Olteanu, Chris Davis, Ionut Volosen, and Dan Moldovan. 2006. Phramer an open source statistical pharse-based translator. In HLT-NAACL 2006: Proceedings of the Workshop on Statistical Machine Translation, New York, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="14231" citStr="Papineni et al., 2002" startWordPosition="1991" endWordPosition="1994">esults. The code used for subsampling, grammar extraction, decoding, minimum error rate training, and minimum Bayes risk rescoring is provided with Joshua6, with the exception of the original (Lopez, 2008) grammar extraction implementation. 5 Experimental Results The experiments described in sections 3 and 4 above provided truecased translations for six language pairs in the translation shared task: English-French, English-German, EnglishSpanish, French-English, German-English, and Spanish-English. Table 3 lists the automatic metric scores for the newstest2010 test set, according to the BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) metrics. Source Target BLEU BLEU- TER cased German English 21.3 19.5 0.660 English German 15.2 14.6 0.738 French English 27.7 26.4 0.614 English French 23.8 22.8 0.681 Spanish English 29.0 27.6 0.595 English Spanish 28.1 26.5 0.596 Table 3: Automatic metric scores for the test set newstest2010 The submitted system ranked highest among shared task participants for the German-English task, according to TER. In order to provide points of comparison with the 2009 Workshop on Statistical Machine Translation shared translation task participants, table 4 lists automatic</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: A method for automatic evaluation of machine translation. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
</authors>
<title>Empiricism is not a matter of faith.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>3</issue>
<contexts>
<context position="1522" citStr="Pedersen (2008)" startWordPosition="228" endWordPosition="229"> researchers should not be able to join and make substantive contributions furthering our field. The reality is less encouraging. Many published articles describe novel techniques and provide interesting results, yet fail to describe technical details in sufficient detail to allow their results to be reproduced by other researchers. While there are notable and laudable exceptions, many publications fail to provide the source code and scripts necessary to reproduce results. The use of restricted data, not freely available for download by any interested researcher only compounds these problems. Pedersen (2008) rightly argues that the implementation details so often ignored in publications are in fact essential for our research to be reproducible science. Reproducibility in machine translation is made more challenging by the complexity of experimental workflows. Results in machine translation *Research conducted as a visiting researcher at Johns Hopkins University tasks are dependent on a cascade of processing steps and configurations. While interesting subsets of these usually appear in experimental descriptions, many steps (preprocessing techniques, alignment parameters, translation rule extractio</context>
</contexts>
<marker>Pedersen, 2008</marker>
<rawString>Ted Pedersen. 2008. Empiricism is not a matter of faith. Computational Linguistics, 34(3):465–470.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aaron B Phillips</author>
<author>Ralf D Brown</author>
</authors>
<title>Cunei machine translation platform: System description.</title>
<date>2009</date>
<booktitle>In 3rd Workshop on Example-Based Machine Translation,</booktitle>
<location>Dublin, Ireland.</location>
<contexts>
<context position="3366" citStr="Phillips and Brown, 2009" startWordPosition="498" endWordPosition="501">management systems. Section 3 describes the experimental workflow used to run the shared task translations, with the corresponding experimental design in section 4. Section 5 presents the shared task results. 2 Related Work The last four years have witnessed the implementation and release of numerous open source machine translation systems. The widely used Moses system (Koehn et al., 2007) implements the standard phrase-based translation model. Parsingbased translation models are implemented by Joshua (Li et al., 2009), SAMT (Zollmann and Venugopal, 2006), and cdec (Dyer et al., 2010). Cunei (Phillips and Brown, 2009) implements statistical example-based translation. Olteanu et al. (2006) and Schwartz (2008) respectively provide additional open-source implementations of phrase-based and hierarchical decoders. The SRILM (Stolcke, 2002), IRSTLM (Federico et al., 2008), and RandLM (Talbot and Osborne, 2007) toolkits enable efficient training and 177 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 177–182, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics Download Data Unzip Data WMT Scripts Remove XML Tokenize Normalize Joshua Be</context>
</contexts>
<marker>Phillips, Brown, 2009</marker>
<rawString>Aaron B. Phillips and Ralf D. Brown. 2009. Cunei machine translation platform: System description. In 3rd Workshop on Example-Based Machine Translation, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lane Schwartz</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Hierarchical phrase-based grammar extraction in joshua suix arrays and prex trees.</title>
<date>2010</date>
<booktitle>The Prague Bulletin of Mathematical Linguistics,</booktitle>
<pages>93--157</pages>
<contexts>
<context position="10583" citStr="Schwartz and Callison-Burch, 2010" startWordPosition="1469" endWordPosition="1472">parl-v5.es news-commentary10.es news.es.shuffled undoc.2000.en-es.es Table 2: Monolingual training data used for training language model, per target language pling; training sentences are selected based on the estimated likelihood of each sentence being useful later for translating a particular test corpus. Given a subsampled parallel training corpus, word alignment is performed using the Berkeley aligner4 (Liang et al., 2006). For each language pair, a synchronous context free translation grammar is extracted for a particular test set, following the methods of Lopez (2008) as implemented in (Schwartz and Callison-Burch, 2010). For the largest training sets (FrenchEnglish and English-French) the original (Lopez, 2008) implementation included with Hiero was used to save time during training5. Because of the use of subsampling, the extracted translation grammars are targeted for use with a specific test set. Our experiments were begun prior to the release of the blind newstest2010 shared task test set. Subsampling was performed for the development tuning set, news-test2008, and the development test set, newstest2009. Once the newstest2010 test set was released, the process of subsampling, alignment, and grammar extra</context>
</contexts>
<marker>Schwartz, Callison-Burch, 2010</marker>
<rawString>Lane Schwartz and Chris Callison-Burch. 2010. Hierarchical phrase-based grammar extraction in joshua suix arrays and prex trees. The Prague Bulletin of Mathematical Linguistics, 93:157–166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lane Schwartz</author>
</authors>
<title>An open-source hierarchical phrase-based translation system.</title>
<date>2008</date>
<booktitle>In Proceedings of the 5th Midwest Computational Linguistics Colloquium (MCLC’08),</booktitle>
<contexts>
<context position="3458" citStr="Schwartz (2008)" startWordPosition="511" endWordPosition="512">ions, with the corresponding experimental design in section 4. Section 5 presents the shared task results. 2 Related Work The last four years have witnessed the implementation and release of numerous open source machine translation systems. The widely used Moses system (Koehn et al., 2007) implements the standard phrase-based translation model. Parsingbased translation models are implemented by Joshua (Li et al., 2009), SAMT (Zollmann and Venugopal, 2006), and cdec (Dyer et al., 2010). Cunei (Phillips and Brown, 2009) implements statistical example-based translation. Olteanu et al. (2006) and Schwartz (2008) respectively provide additional open-source implementations of phrase-based and hierarchical decoders. The SRILM (Stolcke, 2002), IRSTLM (Federico et al., 2008), and RandLM (Talbot and Osborne, 2007) toolkits enable efficient training and 177 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 177–182, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics Download Data Unzip Data WMT Scripts Remove XML Tokenize Normalize Joshua Berkeley Aligner Subsample Subsample for Truecasing Align Align Truecased Data SRILM Hiero Tra</context>
</contexts>
<marker>Schwartz, 2008</marker>
<rawString>Lane Schwartz. 2008. An open-source hierarchical phrase-based translation system. In Proceedings of the 5th Midwest Computational Linguistics Colloquium (MCLC’08), May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proceedings ofAMTA.</booktitle>
<contexts>
<context position="14261" citStr="Snover et al., 2006" startWordPosition="1997" endWordPosition="2000">pling, grammar extraction, decoding, minimum error rate training, and minimum Bayes risk rescoring is provided with Joshua6, with the exception of the original (Lopez, 2008) grammar extraction implementation. 5 Experimental Results The experiments described in sections 3 and 4 above provided truecased translations for six language pairs in the translation shared task: English-French, English-German, EnglishSpanish, French-English, German-English, and Spanish-English. Table 3 lists the automatic metric scores for the newstest2010 test set, according to the BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) metrics. Source Target BLEU BLEU- TER cased German English 21.3 19.5 0.660 English German 15.2 14.6 0.738 French English 27.7 26.4 0.614 English French 23.8 22.8 0.681 Spanish English 29.0 27.6 0.595 English Spanish 28.1 26.5 0.596 Table 3: Automatic metric scores for the test set newstest2010 The submitted system ranked highest among shared task participants for the German-English task, according to TER. In order to provide points of comparison with the 2009 Workshop on Statistical Machine Translation shared translation task participants, table 4 lists automatic metric scores for our systems</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings ofAMTA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard M Stallman</author>
<author>Roland McGrath</author>
<author>Paul D Smith</author>
</authors>
<date>2006</date>
<booktitle>GNU Make. Free Software Foundation,</booktitle>
<location>Boston, MA, 0.70 edition,</location>
<contexts>
<context position="5847" citStr="Stallman et al., 2006" startWordPosition="844" endWordPosition="847">een developed. These include experiment.perl (Koehn et al., 2010), developed as a workflow management system at the University of Edinburgh, and LoonyBin (Clark et al., 2010), a general hyperworkflow management utility from Carnegie Melon University. 3 Managing Experiment Worliflows Running a statistical machine translation system to achieve state-of-the-art performance involves the configuration and execution of numerous interdependent intermediate tools. To manage task dependencies and tool configuration, our shared task workflow consists of a set of dependency scripts written for GNU Make (Stallman et al., 2006). Figure 1 shows a graph depicting the steps in our experimental workflow, and the dependencies between steps. Each node in the graph represents a step in the workflow; each step is implemented as a Make script that defines how to run the tools required in that step. In each experiment, an additional configuration script is provided for each experimental step, defining the parameters to be used when running that step in the current experiment. Optional front-end wrapper scripts can also be provided, allowing for a complete experiment to be run - from downloading data and software through truec</context>
</contexts>
<marker>Stallman, McGrath, Smith, 2006</marker>
<rawString>Richard M. Stallman, Roland McGrath, and Paul D. Smith, 2006. GNU Make. Free Software Foundation, Boston, MA, 0.70 edition, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralf Steinberger</author>
<author>Bruno Pouliquen</author>
<author>Anna Widiger</author>
<author>Camelia Ignat</author>
<author>Tomaz Erjavec</author>
<author>Dan Tufis</author>
<author>Daniel Varga</author>
</authors>
<title>The JRC-acquis: A multilingual aligned parallel corpus with 20+ languages.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC),</booktitle>
<location>Genoa, Italy.</location>
<contexts>
<context position="4736" citStr="Steinberger et al., 2006" startWordPosition="681" endWordPosition="684">ase Grammar Run MERT Translate Run MBR on Translations Restore to Truecase Run MBR on Truecased Translations Figure 1: Machine translation workflow. Square nodes in grey indicate software and scripts. The scripts and configuration files used to implement and run this workflow are available for download at http://sourceforge.net/projects/joshua/files/joshua/1.3/ wmt2010-experiment.tgz/download 178 querying of n-gram language models. Freely available parallel corpora for numerous European languages have also been released in recent years. These include the Europarl (Koehn, 2005) and JRC-Acquis (Steinberger et al., 2006) legislative corpora, each of which includes data for most EU language pairs. The smaller News Commentary corpora (Callison-Burch et al., 2007; Callison-Burch et al., 2008) provide smaller amounts of parallel data in the news genre. The recent Fr-En 109 (Callison-Burch et al., 2009) corpus aggregates huge numbers of parallel FrenchEnglish sentences from the web. Open source systems to address the complex workflows required to run non-trivial machine translation experiments have also been developed. These include experiment.perl (Koehn et al., 2010), developed as a workflow management system at</context>
</contexts>
<marker>Steinberger, Pouliquen, Widiger, Ignat, Erjavec, Tufis, Varga, 2006</marker>
<rawString>Ralf Steinberger, Bruno Pouliquen, Anna Widiger, Camelia Ignat, Tomaz Erjavec, Dan Tufis, and Daniel Varga. 2006. The JRC-acquis: A multilingual aligned parallel corpus with 20+ languages. In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC), Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing,</booktitle>
<location>Denver, Colorado,</location>
<contexts>
<context position="3587" citStr="Stolcke, 2002" startWordPosition="526" endWordPosition="527"> four years have witnessed the implementation and release of numerous open source machine translation systems. The widely used Moses system (Koehn et al., 2007) implements the standard phrase-based translation model. Parsingbased translation models are implemented by Joshua (Li et al., 2009), SAMT (Zollmann and Venugopal, 2006), and cdec (Dyer et al., 2010). Cunei (Phillips and Brown, 2009) implements statistical example-based translation. Olteanu et al. (2006) and Schwartz (2008) respectively provide additional open-source implementations of phrase-based and hierarchical decoders. The SRILM (Stolcke, 2002), IRSTLM (Federico et al., 2008), and RandLM (Talbot and Osborne, 2007) toolkits enable efficient training and 177 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 177–182, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics Download Data Unzip Data WMT Scripts Remove XML Tokenize Normalize Joshua Berkeley Aligner Subsample Subsample for Truecasing Align Align Truecased Data SRILM Hiero Train Truecase LM Train LM Extract Grammar Extract Truecase Grammar Run MERT Translate Run MBR on Translations Restore to Truecase R</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an extensible language modeling toolkit. In Proceedings of the International Conference on Spoken Language Processing, Denver, Colorado, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Talbot</author>
<author>Miles Osborne</author>
</authors>
<title>Randomised language modelling for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="3658" citStr="Talbot and Osborne, 2007" startWordPosition="536" endWordPosition="540"> numerous open source machine translation systems. The widely used Moses system (Koehn et al., 2007) implements the standard phrase-based translation model. Parsingbased translation models are implemented by Joshua (Li et al., 2009), SAMT (Zollmann and Venugopal, 2006), and cdec (Dyer et al., 2010). Cunei (Phillips and Brown, 2009) implements statistical example-based translation. Olteanu et al. (2006) and Schwartz (2008) respectively provide additional open-source implementations of phrase-based and hierarchical decoders. The SRILM (Stolcke, 2002), IRSTLM (Federico et al., 2008), and RandLM (Talbot and Osborne, 2007) toolkits enable efficient training and 177 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 177–182, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics Download Data Unzip Data WMT Scripts Remove XML Tokenize Normalize Joshua Berkeley Aligner Subsample Subsample for Truecasing Align Align Truecased Data SRILM Hiero Train Truecase LM Train LM Extract Grammar Extract Truecase Grammar Run MERT Translate Run MBR on Translations Restore to Truecase Run MBR on Truecased Translations Figure 1: Machine translation workflow</context>
</contexts>
<marker>Talbot, Osborne, 2007</marker>
<rawString>David Talbot and Miles Osborne. 2007. Randomised language modelling for statistical machine translation. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Omar F Zaidan</author>
</authors>
<title>Z-MERT: A fully configurable open source tool for minimum error rate training of machine translation systems.</title>
<date>2009</date>
<booktitle>The Prague Bulletin of Mathematical Linguistics,</booktitle>
<pages>91--79</pages>
<contexts>
<context position="12211" citStr="Zaidan, 2009" startWordPosition="1699" endWordPosition="1700"> result in nearly identical results, albeit with somewhat more time required to extract the grammar. together neighboring constituents. Recent work has shown that parsing-based machine translation using SAMT (Zollmann and Venugopal, 2006) grammars with rich nonterminal sets can demonstrate substantial gains over hierarchical grammars for certain language pairs (Baker et al., 2009). Joshua supports such grammars; the experimental workflow presented here could easily be extended in future research to incorporate the use of SAMT grammars with additional language pairs. The Z-MERT implementation (Zaidan, 2009) of minimum error rate training (Och, 2003) was used for parameter tuning. Tuned grammars were used by Joshua to translate all test sets. The Joshua decoder produces n-best lists of translations. Rather than simply selecting the top candidate from each list, we take the preferred candidate after perform minimum Bayes risk rescoring (Kumar and Byrne, 2004). Once a single translation has been extracted for each sentence in the test set, we repeat the procedures described above to train language and translation models for use in translating lowercased results into a more human-readable truecased </context>
</contexts>
<marker>Zaidan, 2009</marker>
<rawString>Omar F. Zaidan. 2009. Z-MERT: A fully configurable open source tool for minimum error rate training of machine translation systems. The Prague Bulletin of Mathematical Linguistics, 91:79–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Zollmann</author>
<author>Ashish Venugopal</author>
</authors>
<title>Syntax augmented machine translation via chart parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the NAACL-2006 Workshop on Statistical Machine Translation (WMT-06),</booktitle>
<location>New York, New York.</location>
<contexts>
<context position="3302" citStr="Zollmann and Venugopal, 2006" startWordPosition="487" endWordPosition="490">slation systems, parallel corpora, and machine translation workflow management systems. Section 3 describes the experimental workflow used to run the shared task translations, with the corresponding experimental design in section 4. Section 5 presents the shared task results. 2 Related Work The last four years have witnessed the implementation and release of numerous open source machine translation systems. The widely used Moses system (Koehn et al., 2007) implements the standard phrase-based translation model. Parsingbased translation models are implemented by Joshua (Li et al., 2009), SAMT (Zollmann and Venugopal, 2006), and cdec (Dyer et al., 2010). Cunei (Phillips and Brown, 2009) implements statistical example-based translation. Olteanu et al. (2006) and Schwartz (2008) respectively provide additional open-source implementations of phrase-based and hierarchical decoders. The SRILM (Stolcke, 2002), IRSTLM (Federico et al., 2008), and RandLM (Talbot and Osborne, 2007) toolkits enable efficient training and 177 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 177–182, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics Download Dat</context>
<context position="11836" citStr="Zollmann and Venugopal, 2006" startWordPosition="1644" endWordPosition="1647">tain translation grammars targeted for use with the shared task test set. Our experiments used hierarchical phrase-based grammars containing exactly two nonterminals - the wildcard nonterminal X, and S, used to glue 4http://berkeleyaligner.googlecode.com/files/berkeleyaligner unsupervised-2.1.tar.gz — Berkeley aligner version 2.1 5It is expected that using the Joshua implementation should result in nearly identical results, albeit with somewhat more time required to extract the grammar. together neighboring constituents. Recent work has shown that parsing-based machine translation using SAMT (Zollmann and Venugopal, 2006) grammars with rich nonterminal sets can demonstrate substantial gains over hierarchical grammars for certain language pairs (Baker et al., 2009). Joshua supports such grammars; the experimental workflow presented here could easily be extended in future research to incorporate the use of SAMT grammars with additional language pairs. The Z-MERT implementation (Zaidan, 2009) of minimum error rate training (Och, 2003) was used for parameter tuning. Tuned grammars were used by Joshua to translate all test sets. The Joshua decoder produces n-best lists of translations. Rather than simply selecting </context>
</contexts>
<marker>Zollmann, Venugopal, 2006</marker>
<rawString>Andreas Zollmann and Ashish Venugopal. 2006. Syntax augmented machine translation via chart parsing. In Proceedings of the NAACL-2006 Workshop on Statistical Machine Translation (WMT-06), New York, New York.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>