<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000059">
<sectionHeader confidence="0.978025" genericHeader="abstract">
METAPHORIC GENERALIZATION THROUGH
SORT COERCION
</sectionHeader>
<address confidence="0.879508625">
Ellen Hays
10 Pine Avenue
Arlington, MA 02174
haysalinc.cis.upenn.edu
Samuel Bayer
The MITRE Corporation, A040
Burlington Rd.
Bedford, MA 01730
</address>
<email confidence="0.851698">
samÂ©mitre.org
</email>
<sectionHeader confidence="0.997381" genericHeader="keywords">
Abstract
</sectionHeader>
<bodyText confidence="0.999632777777778">
This paper presents a method for interpret-
ing metaphoric language in the context of a
portable natural language interface. The method
licenses metaphoric uses via coercions between
incompatible ontological sorts. The machinery
allows both previously-known and unexpected
metaphoric uses to be correctly interpreted and
evaluated with respect to the backend expert sys-
tem.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999988568181818">
One of the central issues in Al systems has been
how to model the domain: what are the primitives
of the ontological language, how are the ontolog-
ical sorts organized, and so on. Al researchers
have explored a wide range of object-centered
and relation-centered representations (for exam-
ple, Brachman and Schmolze (1985) and Minsky
(1975)). When setting up the domain model for
a natural language interface, though, one must
also keep the lexicon in mind, so that words can
be defined and processed efficiently; if possible,
the hierarchical organization of the domain model
should minimize sense ambiguity, by allowing lex-
ical items to point to classes that dominate the
objects that reflect each item&apos;s range of meanings.
However, a growing body of literature argues
that the generalizations about the world im-
plied by the lexicon do not correspond exactly
to standard computational notions of fine-grained
ontological structure. Rather, the mapping is
mediated by pervasive low-level metaphoric and
metonymic processes (as pointed out by Lakoff
(1987) and others) that make for a mismatch be-
tween the desired world model and the lexicon.
At the MITRE Corporation, we are developing
an interface architecture to support King Kong,
our portable natural language interface for ex-
pert systems, and AIMI, our multimedia interface
for the same class of systems.1 Portable inter-
faces provide an additional set of problems be-
yond simple domain modeling. In particular, in
our case, the structure the knowledge represen-
tation imposes on the backend domain model is
hierarchical and relation-based, and its form must
be consistent across system ports; thus the knowl-
edge representation may structure domain-specific
information in a way that is fundamentally differ-
ent from the way it is organized in the backend. In
this context, one needs to develop a computational
account of the low-level metaphor that creates the
mismatch between the domain model and the lex-
icon. In this paper, we will discuss a mechanism
implemented in King Kong that we call &amp;quot;sort co-
ercion&amp;quot; that is intended to address that mismatch.
</bodyText>
<sectionHeader confidence="0.992881" genericHeader="method">
2 Refinement in the King
Kong domain model
</sectionHeader>
<bodyText confidence="0.961296642857143">
In the King Kong knowledge representation, both
concepts and relations are organized hierarchi-
cally. King Kong exploits this hierarchy in a num-
ber of ways, of which the most relevant to this
discussion occurs in the process of refinement.
When King Kong interprets a sentence, it builds
an interpretation corresponding to the input. In-
terpretations represent a point in the semantic
1The AIMI system is, in fact, one of the domains to which
King Kong has been ported. The current implementation
of King Kong has also been ported to two mission planning
systems and one transportation planning system. The co-
ercion mechanism described here currently supports exam-
ples in the mission planning and interface domains.
</bodyText>
<page confidence="0.994312">
222
</page>
<bodyText confidence="0.999953846153846">
analysis that is subsequent to some lexical disam-
biguation but prior to the determination of scope
relationships and reference resolution. They are
built in large part out of knowledge representa-
tion objects. They have heads, for instance, which
are typically filled by relations from the domain
model, and argument lists, which are usually map-
pings from the arguments of the relation in the
head to other interpretations.
The heads of these interpretations can be very
general relations, and King Kong uses refinement
to find relations in the hierarchy that are dom-
inated by the head indicated by the input and
that are specific enough to be evaluated. Once
referents have been resolved, refinement chooses
appropriate leaf relations by recursively checking
the children of each relation in the subgraph acces-
sible from the input relation and eliminating any
children whose argument restrictions are disjoint
from the sorts of the arguments. Each leaf relation
has backend access code stored on it that allows
King Kong to communicate with the backend ex-
pert system. The code stored on the leaf relations
found by this procedure supports the evaluation
of the logical expressions generated from the in-
put interpretations.
</bodyText>
<sectionHeader confidence="0.995655" genericHeader="method">
3 Motivations for sort coer-
cion
</sectionHeader>
<bodyText confidence="0.99997437254902">
The obvious problem for a system using a hier-
archy of the kind just described is that in most
cases there is no direct, one-to-one mapping be-
tween words and concepts. Most lexical items have
a number of different meanings, and within those
meanings there are often different senses, as well
as various selectional restrictions and preferences,
whether rigidly defined or merely stylistic.
One case in point is the locative prepositions,
which have been studied in great detail by a
number of linguists, including Herskovits (1986),
whose analysis of static locative prepositions such
as in, on, and al defines a program of sorts for in-
terpreting each, in the presence of particular argu-
ments. The scheme consists of an ideal meaning (a
very abstract definition) and a number of use types
(more concrete senses). The relations so defined,
however, require that the system have recourse to
a number of &amp;quot;functions&amp;quot; that, in some sense, &amp;quot;co-
erce&amp;quot; the objects arguments to the relations from
one ontological sort to another.
Herskovits calls these geometric description
functions; they capture a number of different kinds
of conceptualization (or recasting) of objects. For
example, for the purposes of the abstract rela-
tion at(x,y) (&amp;quot;X [is] at Y&amp;quot;),2 both x and y are
taken to be points.3 Then in the actual instance of
the relation at(john,airport), according to this
model, we have conceptualized both of the (three-
dimensional) objects in the relation as points in or-
der to express that particular locative relation be-
tween them. In the same way, when we use at with
a temporal argument (&amp;quot;a meeting at 5 o&apos;clock&amp;quot;),
we are in some sense &amp;quot;viewing&amp;quot; a time point as a
spatial object, namely a geometric point.4
Since a geometric description function can ap-
ply to any argument of the appropriate ontolog-
ical sort (i.e., within the range of the function),
regardless of the relation it figures in, what this
scheme captures is a generalization about concep-
tual &amp;quot;transfer of reference&amp;quot;, as Herskovits has more
recently called it (Herskovits, 1989).
The coercion mechanism described in this pa-
per was inspired partly by Herskovits&apos; work and
partly by the system&apos;s existing domain model. It
is a response to the need for a one-to-many map-
ping from lexical items to ontological items (in this
case locative and event relations), and is an at-
tempt to capture explicitly some of the ways in
which changing the way an object is viewed allows
certain metaphoric and metonymic uses.
</bodyText>
<sectionHeader confidence="0.973542" genericHeader="method">
4 The coercion mechanism
</sectionHeader>
<bodyText confidence="0.999278666666667">
The central information source in our account of
metaphor and metonymy is a set of coercion rules.
Coercion rules declare different ways of viewing
particular classes of objects. So if we wish to view
temporal intervals as one-dimensional spatial ob-
jects (lines), we would declare:
</bodyText>
<listItem confidence="0.4455445">
(1) (detCoerce temporal-interval line)
These coercion rules can be chained; if we wish
to view events as temporal intervals (that is, the
intervals over which they occur), we could ulti-
mately view them as lines as well simply by adding
another declaration:
</listItem>
<footnote confidence="0.946549375">
2Herskovits follows Tahny (1983) and others in seeing
locative prepositions as defining a figure/ground relation-
ship between a located object and a reference object.
3The ideal meaning of at is for two points to coincide
(1986, p.128).
4 Jackendoff proposes a similar response to the problem,
with respect to temporal use of spatial expressions. See
(Jackendoff, 1983, ch.10).
</footnote>
<page confidence="0.997582">
223
</page>
<bodyText confidence="0.956355833333333">
(2) (deiCoerce
durative-event
temporal-interval)
King Kong uses these coercion rules in two re-
lated ways. The first is to license what we call
shadow relations. These are relations that have
no parent but are connected to the domain model
by means of a shadow link. This link requires
that the value restrictions on the arguments of the
shadowing relation be connected to the value re-
strictions on the shadowed relation by a chain of
coercion rules. These shadow links are required
because the normal subsumption relationship does
not permit the shadowed relations to be connected
to their shadows; the endpoints of coercion links
will typically be disjoint. Intuitively, these shadow
relations represent the metaphoric uses that Lakoff
called attention to. When King Kong encounters
a relation pointed to by the input that has shad-
ows associated with it, it exploits an expanded
version of the refinement mechanism described in
Section 2 to search through not only children but
also shadows for acceptable leaf relations.
Let us take a brief example. Imagine that we
wish to capture the low-level metaphor in a sen-
tence like &amp;quot;The length of the meeting is 5 hours.&amp;quot;
The ideal meaning of the length-of relation in-
volves a line and a one-dimensional (spatial) mea-
sure, which are the value restrictions on the two
arguments (indicated here as vr):
</bodyText>
<listItem confidence="0.89964375">
(3) (def Relation length-of
(arg object (yr line))
(arg measure (yr 1d-measure))
(super measure-of))
</listItem>
<bodyText confidence="0.9996914">
The coercions described in (1) and (2), together
with a view of quantities of time as spatial mea-
sures (shown in (4)), suffice to license the shadow
embodying the temporal metaphoric use of the
length-of relation in (3):
</bodyText>
<listItem confidence="0.84666275">
(4) (def Coerce
quantity-of-time id-measure)
(5) (defRelation length-of-event
(arg event
</listItem>
<bodyText confidence="0.987827967213115">
(yr durative-event))
(arg measure
(yr quantity-of-time))
(shadows length-of))
But the mechanisms introduced so far do not
address a particular requirement of the King Kong
metaphor mechanism that might not be imposed
on other such mechanisms: the resulting logical
expressions must be evaluable. Since King Kong is
an interface, its domain model captures the shape
of the data, but it does not itself store any facts;
it must consult an external (i.e., the backend sys-
tern&apos;s) database to reply to any queries. So when
it recognizes a metaphoric use, it must provide
the proper backend argument fillers to the back-
end database in order to evaluate the query. But
if the metaphoric use of the relation correspond-
ing to the input has an argument corresponding
to event and the ideal meaning requires an argu-
ment corresponding to line, as in the length-of
relation given above, how can King Kong provide
the proper backend individuals?
The answer lies in the way coercion rules inter-
act with the domain model. When they license
a shadow relation, they instantiate a point in the
space of possible coercions, and to this shadow re-
lation we can attach backend access code that ex-
pects objects corresponding to the classes in the
value restrictions of the current (shadowing) rela-
tions. In other words, in the example given above,
although conceptually we are viewing an instance
of event as an instance of line, we need not refer
to the ideal class at all in processing; the shadow
relation permits us to treat these instances as or-
dinary members of the event class. The existence
of this shadow implies that there is a conceptual
mismatch between the way the backend system
records this information and the way language ex-
presses it; the backend system considers the in-
put classes directly, while the ontology and lexicon
view these classes as coercions from other classes.5
But what if the backend system requires that
the input classes be coerced, just as the domain
model and lexicon do? This is the second way in
which the coercion rules can support metaphoric
language. Coercion rules can have fragments of
logical expressions attached to them that describe
how to convert items of one class to items of an-
other. We can use these augmented coercion rules
to process novel uses of relations. If a path of co-
ercions can be followed dynamically (rather than
built at load time, as when shadows are licensed),
the novel use can be evaluated, as long as the log-
5 This shadow, along with many others, could be auto-
matically generated from our set of coercion rules, but since
the backend access code that shadows are &amp;quot;repositories&amp;quot; for
cannot be automatically generated as well, that would not
be productive. Furthermore, we acknowledge the possi-
bility that the unconstrained application of these coercion
rules would generate shadow relations with no linguistic
validity.
</bodyText>
<page confidence="0.991317">
224
</page>
<bodyText confidence="0.999205307692308">
ical expressions attached to the coercion rules can
themselves be evaluated. In that case, the proce-
dure that builds logical expressions will fold the
logical expressions associated with the coercion
rules into the overall logical expression, in order
to create an evaluable expression.6
For example, consider a backend system that
knows about meetings and their start and end
times, but doesn&apos;t store their duration. Further-
more, it knows how to manipulate intervals of
time. We might amend the coercion rule in (2)
above in the following way, and replace the shadow
shown in (5):
</bodyText>
<figure confidence="0.933129666666667">
(6) (def Coerce
durative-event temporal-interval
(lambda x
(durative-event-has-interval
durative-event x)))
(7) (defRelation
durative-event-has-interval
(arg event
(yr durative-event))
(arg interval
(yr temporal-interval))
(super event-has-property))
(8) (defRelation length-of-interval
(arg interval
(yr temporal-interval))
(arg measure
(yr quantity-of-time))
(shadows length-of))
</figure>
<bodyText confidence="0.9989323">
In this situation, the length-of-interval re-
lation instantiates a point in the space of possible
coercions that represents the system&apos;s ability to
compare a temporal interval with a time measure-
ment. It represents the direct understanding of
something like &amp;quot;The length of the coffee break was
10 minutes,&amp;quot; where we assume that a coffee break
is a kind of temporal interval. Ignoring tense, the
logical expression corresponding to this example
is:7
</bodyText>
<listItem confidence="0.457594">
(9) (length-of coffee-breaki 10-minutes)
</listItem>
<bodyText confidence="0.9981705">
The generalized refinement process will locate
the shadow length-of-interval and use the
</bodyText>
<footnote confidence="0.8581136">
6I1 the coercion rules are not all evaluable, we can build
an interpretation for the input, but we cannot evaluate it.
7King Kong actually represents measurements as undif-
ferentiated pools of individuals, much as it represents &amp;quot;10
planes&amp;quot;, for instance. We may ignore that detail here.
</footnote>
<bodyText confidence="0.999641125">
code associated with it to communicate with the
backend system. We can do more, however. Given
the existence of the augmented coercion rule, we
can understand sentences like our first example
&amp;quot;The length of the meeting is 5 hours&amp;quot; by build-
ing a chain of coercions that consists of a single
link, from events to temporal intervals. In this
case, our logical expression will be:
</bodyText>
<figure confidence="0.8864582">
(10) (exists y
(lambda x
( durat ive- event-has - int erval
coffee-breaki x))
(length-of y 10-minutes))
</figure>
<bodyText confidence="0.999274666666667">
As long as there is backend access code asso-
ciated with the durative-event-has-interval
relation, we can process this use of the
length-of relation without the shadow in (5)
(length-of-event) present. In fact, we can pro-
cess any metaphoric reference to an event that
appears in an argument position whose filler is re-
stricted to intervals of time. Consider the overlap
relation, whose ideal meaning is a relation between
two planes or two lines. The coercion rules already
given will license a shadow that relates two inter-
vals:
</bodyText>
<listItem confidence="0.847549833333333">
(11) (defRelation overlap
(arg obj1 (yr line))
(arg obj2 (yr line))
(super static-locative))
(12) (defRelation temporal-overlap
(arg obji
</listItem>
<bodyText confidence="0.9386681">
(yr temporal-interval))
(arg obj2
(yr temporal-interval))
(shadows overlap))
The shadow in (12) corresponds to an example
like &amp;quot;The current calendar year overlaps with the
next fiscal year.&amp;quot; But given the augmented coer-
cion rule, we can understand sentences like &amp;quot;The
first meeting overlaps with the second meeting&amp;quot;
just as easily:
</bodyText>
<figure confidence="0.242295">
(13) (exists y
(lambda x
(durative-event-has-interval
meetingl x))
(exists z
(lambda x
(durative-event-has-interval
meeting2 x))
(overlap y z)))
</figure>
<page confidence="0.997162">
225
</page>
<bodyText confidence="0.999675230769231">
This method of supporting metaphorical ex-
tension by explicitly defining the space of pos-
sible ways of conceptualizing an object allows
us considerable flexibility in understanding novel
metaphoric use.8
The same augmented coercion rules can be used
if we wish to license a shadow relation that has
no backend access code associated with it. We
might want to use that strategy in the situation
where the metaphoric use can be anticipated but
the access code associated with the shadow would
have to perform exactly the same computation as
the coercion code.
</bodyText>
<sectionHeader confidence="0.962564" genericHeader="method">
5 Comparison with other ac-
counts
</sectionHeader>
<bodyText confidence="0.999988285714286">
As in DeJong and Waltz&apos;s work (1983), the King
Kong coercion mechanism is triggered by viola-
tions of sort restrictions on arguments. We do
not, however, agree with DeJong and Waltz&apos;s
contention that &amp;quot;Nouns are far less likely to be
metaphorical than verbs.&amp;quot; The symbiosis be-
tween shadows and coercion rules implies that the
metaphor lies not in the functor or its arguments,
but rather in the association between them. Fur-
thermore, our mechanism also structures the path
between metaphoric use and ideal meaning, and
provides computational support for argument co-
ercion. The mechanism has the same advantage
over the work of Jacobs and Martin.
</bodyText>
<subsectionHeader confidence="0.997558">
5.1 Jacobs and Martin
</subsectionHeader>
<bodyText confidence="0.99175">
In a series of papers (Besemer and Jacobs, 1987;
Jacobs, 1986; Jacobs, 1987), Paul Jacobs has de-
veloped a relationship he calls a view. Views
express a relationship between event types that
implements metaphoric extension. For example,
in order to handle examples like &amp;quot;The command
takes three arguments&amp;quot;, he defines the following
view:
</bodyText>
<sectionHeader confidence="0.990425" genericHeader="method">
(VIEW execute-operation
causal-double-transfer
(ROLE-PLAY input object-1)
(ROLE-PLAY output object-2)
(ROLE-PLAY user source-1)
(ROLE-PLAY operation source-2))
</sectionHeader>
<bodyText confidence="0.9954054">
Note that shadows always embody disjointness between
at least one of their arguments and those in the ideal mean-
ing. Thus, no input relation can be simultaneously inter-
preted both as a subsumed relation and as a shadow.
In Jacobs&apos; system, this view would incorporate
the metaphorical mappings from the full range of
expressions referring to exchange operations such
as giving, buying, and selling. As a result, the
mappings in this view may be used to understand
expressions such as &amp;quot;This command gives you the
file names&amp;quot;, and so on.
Like the work of Martin (see below), Jacobs&apos;
approach has the potential for grouping families
of relationships into situations, a capability King
Kong does not yet have. Jacobs&apos; views correspond
roughly to our shadow relations.
However, the view mechanism provides no lim-
itations on the correspondences between the ob-
jects in the ROLE-PLAY declarations, nor does there
seem to be any capability for computing one argu-
ment class from another. As a result, it is difficult
to see how Jacobs&apos; account would intelligently re-
strict the range of novel language use the system
will handle, or how it might be used to provide
computational support for sort coercion in an in-
terface.
Martin (1987a, 1987b), working with the same
mechanism, takes steps toward addressing the
first concern. His work involves learning new
metaphoric uses in light of already recognized
metaphors. So Martin&apos;s heuristics allow the sys-
tem to learn what &amp;quot;getting out of Lisp&amp;quot; means if
it knows what &amp;quot;getting into Lisp&amp;quot; means. His sys-
tem knows about entering and exiting, enabling
and disabling Lisp processes, and that there is
a map between entering and enabling Lisp. Be-
cause entering and exiting are closely connected
(they are related by the frame semantic relation
revers ible-st at e -change), Martin&apos;s system can
build the metaphoric link from exiting to disabling
Lisp. Techniques such as this one constrain the in-
terpretation of novel language use, since the sys-
tem can only generalize from the existing library of
metaphoric uses. However, they provide no com-
putational support for evaluating novel uses.
</bodyText>
<subsectionHeader confidence="0.887309">
5.2 Gentner et al.
</subsectionHeader>
<bodyText confidence="0.9998951">
Gentner&apos;s structure-mapping techniques (Gen-
tner, 1983; Gentner et al. 1987) are applicable
mostly to explicit analogies such as &amp;quot;An electric
battery is like a reservoir.&amp;quot; Her approach, imple-
mented by Falkenhainer and Forbus (1986), maps
the structure of the source of the metaphor to the
structure of the target by creating match hypothe-
ses between relational representations of the base
and target using a set of match construction rules.
But the central example of a match construction
</bodyText>
<page confidence="0.996047">
226
</page>
<bodyText confidence="0.999958222222222">
rule seems to require that the names of the predi-
cates in the facts being matched be identical. Un-
der this sort of construction rule, it is possible to
derive a metaphoric mapping only if the names
of the predicates have been set up to encode the
metaphor ahead of time. Under this system, it is
not possible to deduce new metaphors; in fact, one
can only recognize them if the metaphoric link has
been made but not recorded.
</bodyText>
<subsectionHeader confidence="0.999331">
5.3 Boguraev and Pustejovsky
</subsectionHeader>
<bodyText confidence="0.998818436619718">
Boguraev and Pustejovsky (1990) argue that the
normal conceptions of the structure of the lexicon
are impoverished for two major reasons. First, a
great number of distinctions beyond those usually
made are necessary to capture the essential as-
pects of lexical semantics. Second, the common
technique for representing ambiguity in the lexi-
con (enumeration) falls short because enumeration
of word senses neither organizes the senses intelli-
gently nor provides for creative use of words.
For instance, under the enumeration method,
the following uses of &amp;quot;fast&amp;quot; require that at least
these three senses be listed in the lexicon:
fast (1): able to move quickly (a fast
car)
fast(2): able to perform some act
quickly (a fast typist)
fast(3): taking little time (a fast oil
change)
However, these three senses are not enough to ac-
count for the creative use of &amp;quot;fast&amp;quot; in a phrase such
as &amp;quot;a fast highway&amp;quot;.
Pustejovsky&apos;s solution to this problem (outlined
also in (Pustejovsky, 1990)) is a &amp;quot;generative lex-
icon&amp;quot;, which organizes lexical items with respect
to one or more of: (1) argument structure, (2)
event structure, (3) qualia structure, and (4) lexi-
cal inheritance structure. These lexical structures
are intended to address the different ways in which
words are understood; the differing interpretations
of &amp;quot;fast&amp;quot; shown above are taken to be a function of
the differing qualia structures of &amp;quot;car&amp;quot;, &amp;quot;typist&amp;quot;,
&amp;quot;oil change&amp;quot;, and &amp;quot;highway&amp;quot;.
While Pustejovsky&apos;s proposal for a variety of
lexical structures is far richer than anything cur-
rently implemented in King Kong, one problem
with his account is that the links are links be-
tween lexical items and not between objects in a
domain model. Simple cases of anaphoric refer-
ence demonstrate that in many cases the coercions
that he conceives of are properties not of lexical
items but rather of the objects referred to:
John bought a Porsche, and it&apos;s fast.
John hired a typist, and he&apos;s fast.
I drove down 1-90 yesterday, and it&apos;s
fast.
John bought a new car, but Bill&apos;s is
faster.
John hired a good typist, but Bill&apos;s is
faster.
America is supposed to have good high-
ways, but Italy&apos;s are faster.
The lexical items whose qualia structures are in-
tended to account for the different interpretations
of &amp;quot;fast&amp;quot; are not present in the second clause of
each of the preceding examples, but the correct in-
terpretations are still available. This implies that
it is the language user&apos;s conception of the object
in question (that is, the user&apos;s world model) that
determines the precise sense of &amp;quot;fast&amp;quot;.
In our account, in contrast, the links that sup-
port the range of metaphoric extensions Puste-
jovsky deals with reside in the domain model. This
account also supports generalization of these ex-
tensions to hierarchies of semantic classes:
John bought a new car, and it&apos;s fast.
John bought a new vehicle, and it&apos;s fast.
and preserves these extensions under synonymy:
John bought a new car, and it&apos;s fast.
John bought a new automobile, and it&apos;s
fast.
</bodyText>
<sectionHeader confidence="0.99954" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999919">
One insight missed in most relation-based ac-
counts of metaphor9 is the wide space of possibil-
ities for conceptualizing the argument types: how
these possibilities are constrained, how the trans-
formations can be computed. The coercion mecha-
nism in King Kong supports metaphoric processes
both statically and dynamically, by defining how
metaphoric links between relations are established
and supporting computational tools for compre-
hending and processing novel metaphoric uses.
</bodyText>
<sectionHeader confidence="0.998864" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<footnote confidence="0.87995375">
This research was supported by the MITRE Cor-
poration under MSR project 91340.
9 With the exception of Boguraev and Pustejovsky&apos;s, of
course.
</footnote>
<page confidence="0.991213">
227
</page>
<sectionHeader confidence="0.795711" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.980633422222222">
[Besemer and Jacobs 1987]
David J. Besemer and Paul S. Jacobs.
FLUSH: A flexible lexicon design. In Proceed-
ings of the 25th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages
186-192.
[Boguraev and Pustejovsky 1990]
Branimir Boguraev and James Pustejovsky.
Lexical ambiguity and the role of knowl-
edge representation in lexicon design. In
COLING-90: Proceedings of the 13th Inter-
national Conference on Computational Lin-
guistics, volume 2, pages 36-41.
[Brachman and Schmolze 1985]
R.J. Brachman and J.G. Schmolze. An
overview of the XL-ONE knowledge represen-
tation system. Cognitive Science, 9(2):171-
216.
[DeJong and Waltz 1983]
Gerald F. DeJong and David L. Waltz. Un-
derstanding novel language. Computers and
Mathematics with Applications, 9(1):131-147.
[Falkenhainer et al. 1986]
B. Falkenhainer, K.D. Forbus, and D. Gen-
tner. The structure-mapping engine. In
AAAI-86: Proceedings of the Fifth National
Conference on Artificial Intelligence, pages
272-277.
[Gentner 1983]
Dedre Gentner. Structure-mapping: A theo-
retical framework for analogy. Cognitive Sci-
ence, 7:155-170.
[Gentner et al. 1987]
Dedre Gentner, Brian Falkenhainer, and Jan-
ice Skorstad. Metaphor: the good, the
bad and the ugly. In Yorick Wilks, edi-
tor, TINLAP-3: Theoretical Issues in Natural
Language Processing-3, pages 155-159, New
Mexico State University, Las Cruces.
[Herskovits 1986]
Annette Herskovits. Language and spatial
cognition: an interdisciplinary study of the
prepositions in English. Cambridge Univer-
sity Press, New York.
[Herskovits 1989]
Annette Herskovits. The linguistic expression
of spatial knowledge. L.A.U.D. Paper A 248,
Linguistic Agency University of Duisburg.
[Jackendoff 1983]
Ray Jackendoff. Semantics and Cognition.
MIT Press, Cambridge, MA.
[Jacobs 1986]
Paul S. Jacobs. Language analysis in not-so-
limited domains. In Proceedings of the IEEE
Fall Joint Computer Conference.
[Jacobs 1987]
Paul S. Jacobs. A knowledge framework for
natural language analysis. In IJCAI-87: Pro-
ceedings of the 10th International Joint Con-
ference on Artificial Intelligence, pages 675-
678.
[Lakoff 1987]
George Lakoff. Women, Fire, and Dangerous
Things. University of Chicago Press, Chicago.
[Martin 1987a]
James H. Martin. The acquisition of poly-
semy. In Proceedings of the Fourth Interna-
tional Workshop on Machine Learning, pages
198-204.
[Martin 1987b]
James H. Martin. Understanding new
metaphors. In IJCAI-87: Proceedings of the
10th International Conference on Artificial
Intelligence, pages 137-139.
[Minsky 1975]
Marvin Minsky. A framework for represent-
ing knowledge. In Patrick Henry Winston,
editor, The Psychology of Computer Vision,
chapter 6, pages 211-277. McGraw-Hill, New
York.
[Pustejovsky 1990]
James Pustejovsky. Lexical ambiguity and
the role of inheritance. Talk given at BBN,
Cambridge, MA, 6 November 1990.
[Talmy 1983]
Leonard Talmy. How language structures
space. In Herbert Pick and Linda Acredolo,
editors, Spatial Orientation: Theory, Re-
search, and Application. Plenum Press, New
York.
</reference>
<page confidence="0.997657">
228
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.302457">
<title confidence="0.9964265">METAPHORIC GENERALIZATION THROUGH SORT COERCION</title>
<author confidence="0.987238">Ellen Hays</author>
<address confidence="0.9898255">10 Pine Avenue Arlington, MA 02174</address>
<email confidence="0.999745">haysalinc.cis.upenn.edu</email>
<author confidence="0.998947">Samuel Bayer</author>
<affiliation confidence="0.55477">The MITRE Corporation, A040 Burlington Rd.</affiliation>
<address confidence="0.998216">Bedford, MA 01730</address>
<email confidence="0.993722">samÂ©mitre.org</email>
<abstract confidence="0.9778477">This paper presents a method for interpreting metaphoric language in the context of a portable natural language interface. The method licenses metaphoric uses via coercions between incompatible ontological sorts. The machinery allows both previously-known and unexpected metaphoric uses to be correctly interpreted and evaluated with respect to the backend expert system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>David J Besemer</author>
<author>Paul S Jacobs</author>
</authors>
<title>FLUSH: A flexible lexicon design.</title>
<booktitle>In Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>186--192</pages>
<marker>Besemer, Jacobs, </marker>
<rawString>[Besemer and Jacobs 1987] David J. Besemer and Paul S. Jacobs. FLUSH: A flexible lexicon design. In Proceedings of the 25th Annual Meeting of the Association for Computational Linguistics, pages 186-192.</rawString>
</citation>
<citation valid="true">
<title>Branimir Boguraev and James Pustejovsky. Lexical ambiguity and the role of knowledge representation in lexicon design.</title>
<date>1990</date>
<booktitle>In COLING-90: Proceedings of the 13th International Conference on Computational Linguistics,</booktitle>
<volume>2</volume>
<pages>36--41</pages>
<contexts>
<context position="21083" citStr="(1990)" startWordPosition="3379" endWordPosition="3379">ons of the base and target using a set of match construction rules. But the central example of a match construction 226 rule seems to require that the names of the predicates in the facts being matched be identical. Under this sort of construction rule, it is possible to derive a metaphoric mapping only if the names of the predicates have been set up to encode the metaphor ahead of time. Under this system, it is not possible to deduce new metaphors; in fact, one can only recognize them if the metaphoric link has been made but not recorded. 5.3 Boguraev and Pustejovsky Boguraev and Pustejovsky (1990) argue that the normal conceptions of the structure of the lexicon are impoverished for two major reasons. First, a great number of distinctions beyond those usually made are necessary to capture the essential aspects of lexical semantics. Second, the common technique for representing ambiguity in the lexicon (enumeration) falls short because enumeration of word senses neither organizes the senses intelligently nor provides for creative use of words. For instance, under the enumeration method, the following uses of &amp;quot;fast&amp;quot; require that at least these three senses be listed in the lexicon: fast </context>
</contexts>
<marker>1990</marker>
<rawString>[Boguraev and Pustejovsky 1990] Branimir Boguraev and James Pustejovsky. Lexical ambiguity and the role of knowledge representation in lexicon design. In COLING-90: Proceedings of the 13th International Conference on Computational Linguistics, volume 2, pages 36-41.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R J Brachman</author>
<author>J G Schmolze</author>
</authors>
<title>An overview of the XL-ONE knowledge representation system.</title>
<journal>Cognitive Science,</journal>
<pages>9--2</pages>
<marker>Brachman, Schmolze, </marker>
<rawString>[Brachman and Schmolze 1985] R.J. Brachman and J.G. Schmolze. An overview of the XL-ONE knowledge representation system. Cognitive Science, 9(2):171-216.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Gerald F DeJong</author>
<author>David L Waltz</author>
</authors>
<title>Understanding novel language.</title>
<journal>Computers and Mathematics with Applications,</journal>
<pages>9--1</pages>
<marker>DeJong, Waltz, </marker>
<rawString>[DeJong and Waltz 1983] Gerald F. DeJong and David L. Waltz. Understanding novel language. Computers and Mathematics with Applications, 9(1):131-147.</rawString>
</citation>
<citation valid="true">
<title>The structure-mapping engine.</title>
<date>1986</date>
<booktitle>In AAAI-86: Proceedings of the Fifth National Conference on Artificial Intelligence,</booktitle>
<pages>272--277</pages>
<contexts>
<context position="5251" citStr="(1986)" startWordPosition="828" endWordPosition="828">s generated from the input interpretations. 3 Motivations for sort coercion The obvious problem for a system using a hierarchy of the kind just described is that in most cases there is no direct, one-to-one mapping between words and concepts. Most lexical items have a number of different meanings, and within those meanings there are often different senses, as well as various selectional restrictions and preferences, whether rigidly defined or merely stylistic. One case in point is the locative prepositions, which have been studied in great detail by a number of linguists, including Herskovits (1986), whose analysis of static locative prepositions such as in, on, and al defines a program of sorts for interpreting each, in the presence of particular arguments. The scheme consists of an ideal meaning (a very abstract definition) and a number of use types (more concrete senses). The relations so defined, however, require that the system have recourse to a number of &amp;quot;functions&amp;quot; that, in some sense, &amp;quot;coerce&amp;quot; the objects arguments to the relations from one ontological sort to another. Herskovits calls these geometric description functions; they capture a number of different kinds of conceptuali</context>
<context position="20335" citStr="(1986)" startWordPosition="3248" endWordPosition="3248">ic relation revers ible-st at e -change), Martin&apos;s system can build the metaphoric link from exiting to disabling Lisp. Techniques such as this one constrain the interpretation of novel language use, since the system can only generalize from the existing library of metaphoric uses. However, they provide no computational support for evaluating novel uses. 5.2 Gentner et al. Gentner&apos;s structure-mapping techniques (Gentner, 1983; Gentner et al. 1987) are applicable mostly to explicit analogies such as &amp;quot;An electric battery is like a reservoir.&amp;quot; Her approach, implemented by Falkenhainer and Forbus (1986), maps the structure of the source of the metaphor to the structure of the target by creating match hypotheses between relational representations of the base and target using a set of match construction rules. But the central example of a match construction 226 rule seems to require that the names of the predicates in the facts being matched be identical. Under this sort of construction rule, it is possible to derive a metaphoric mapping only if the names of the predicates have been set up to encode the metaphor ahead of time. Under this system, it is not possible to deduce new metaphors; in f</context>
</contexts>
<marker>1986</marker>
<rawString>[Falkenhainer et al. 1986] B. Falkenhainer, K.D. Forbus, and D. Gentner. The structure-mapping engine. In AAAI-86: Proceedings of the Fifth National Conference on Artificial Intelligence, pages 272-277.</rawString>
</citation>
<citation valid="true">
<title>Dedre Gentner. Structure-mapping: A theoretical framework for analogy.</title>
<date>1983</date>
<journal>Cognitive Science,</journal>
<pages>7--155</pages>
<contexts>
<context position="7781" citStr="(1983)" startWordPosition="1248" endWordPosition="1248">mic uses. 4 The coercion mechanism The central information source in our account of metaphor and metonymy is a set of coercion rules. Coercion rules declare different ways of viewing particular classes of objects. So if we wish to view temporal intervals as one-dimensional spatial objects (lines), we would declare: (1) (detCoerce temporal-interval line) These coercion rules can be chained; if we wish to view events as temporal intervals (that is, the intervals over which they occur), we could ultimately view them as lines as well simply by adding another declaration: 2Herskovits follows Tahny (1983) and others in seeing locative prepositions as defining a figure/ground relationship between a located object and a reference object. 3The ideal meaning of at is for two points to coincide (1986, p.128). 4 Jackendoff proposes a similar response to the problem, with respect to temporal use of spatial expressions. See (Jackendoff, 1983, ch.10). 223 (2) (deiCoerce durative-event temporal-interval) King Kong uses these coercion rules in two related ways. The first is to license what we call shadow relations. These are relations that have no parent but are connected to the domain model by means of </context>
<context position="16840" citStr="(1983)" startWordPosition="2692" endWordPosition="2692">rting metaphorical extension by explicitly defining the space of possible ways of conceptualizing an object allows us considerable flexibility in understanding novel metaphoric use.8 The same augmented coercion rules can be used if we wish to license a shadow relation that has no backend access code associated with it. We might want to use that strategy in the situation where the metaphoric use can be anticipated but the access code associated with the shadow would have to perform exactly the same computation as the coercion code. 5 Comparison with other accounts As in DeJong and Waltz&apos;s work (1983), the King Kong coercion mechanism is triggered by violations of sort restrictions on arguments. We do not, however, agree with DeJong and Waltz&apos;s contention that &amp;quot;Nouns are far less likely to be metaphorical than verbs.&amp;quot; The symbiosis between shadows and coercion rules implies that the metaphor lies not in the functor or its arguments, but rather in the association between them. Furthermore, our mechanism also structures the path between metaphoric use and ideal meaning, and provides computational support for argument coercion. The mechanism has the same advantage over the work of Jacobs and </context>
</contexts>
<marker>1983</marker>
<rawString>[Gentner 1983] Dedre Gentner. Structure-mapping: A theoretical framework for analogy. Cognitive Science, 7:155-170.</rawString>
</citation>
<citation valid="true">
<title>Dedre Gentner, Brian Falkenhainer, and Janice Skorstad. Metaphor: the good, the bad and the ugly.</title>
<date>1987</date>
<booktitle>In Yorick Wilks, editor, TINLAP-3: Theoretical Issues in Natural Language Processing-3,</booktitle>
<pages>155--159</pages>
<institution>Mexico State University, Las Cruces.</institution>
<location>New</location>
<contexts>
<context position="1656" citStr="(1987)" startWordPosition="246" endWordPosition="246">n mind, so that words can be defined and processed efficiently; if possible, the hierarchical organization of the domain model should minimize sense ambiguity, by allowing lexical items to point to classes that dominate the objects that reflect each item&apos;s range of meanings. However, a growing body of literature argues that the generalizations about the world implied by the lexicon do not correspond exactly to standard computational notions of fine-grained ontological structure. Rather, the mapping is mediated by pervasive low-level metaphoric and metonymic processes (as pointed out by Lakoff (1987) and others) that make for a mismatch between the desired world model and the lexicon. At the MITRE Corporation, we are developing an interface architecture to support King Kong, our portable natural language interface for expert systems, and AIMI, our multimedia interface for the same class of systems.1 Portable interfaces provide an additional set of problems beyond simple domain modeling. In particular, in our case, the structure the knowledge representation imposes on the backend domain model is hierarchical and relation-based, and its form must be consistent across system ports; thus the </context>
</contexts>
<marker>1987</marker>
<rawString>[Gentner et al. 1987] Dedre Gentner, Brian Falkenhainer, and Janice Skorstad. Metaphor: the good, the bad and the ugly. In Yorick Wilks, editor, TINLAP-3: Theoretical Issues in Natural Language Processing-3, pages 155-159, New Mexico State University, Las Cruces.</rawString>
</citation>
<citation valid="false">
<date>1986</date>
<institution>Herskovits</institution>
<contexts>
<context position="5251" citStr="(1986)" startWordPosition="828" endWordPosition="828">s generated from the input interpretations. 3 Motivations for sort coercion The obvious problem for a system using a hierarchy of the kind just described is that in most cases there is no direct, one-to-one mapping between words and concepts. Most lexical items have a number of different meanings, and within those meanings there are often different senses, as well as various selectional restrictions and preferences, whether rigidly defined or merely stylistic. One case in point is the locative prepositions, which have been studied in great detail by a number of linguists, including Herskovits (1986), whose analysis of static locative prepositions such as in, on, and al defines a program of sorts for interpreting each, in the presence of particular arguments. The scheme consists of an ideal meaning (a very abstract definition) and a number of use types (more concrete senses). The relations so defined, however, require that the system have recourse to a number of &amp;quot;functions&amp;quot; that, in some sense, &amp;quot;coerce&amp;quot; the objects arguments to the relations from one ontological sort to another. Herskovits calls these geometric description functions; they capture a number of different kinds of conceptuali</context>
<context position="20335" citStr="(1986)" startWordPosition="3248" endWordPosition="3248">ic relation revers ible-st at e -change), Martin&apos;s system can build the metaphoric link from exiting to disabling Lisp. Techniques such as this one constrain the interpretation of novel language use, since the system can only generalize from the existing library of metaphoric uses. However, they provide no computational support for evaluating novel uses. 5.2 Gentner et al. Gentner&apos;s structure-mapping techniques (Gentner, 1983; Gentner et al. 1987) are applicable mostly to explicit analogies such as &amp;quot;An electric battery is like a reservoir.&amp;quot; Her approach, implemented by Falkenhainer and Forbus (1986), maps the structure of the source of the metaphor to the structure of the target by creating match hypotheses between relational representations of the base and target using a set of match construction rules. But the central example of a match construction 226 rule seems to require that the names of the predicates in the facts being matched be identical. Under this sort of construction rule, it is possible to derive a metaphoric mapping only if the names of the predicates have been set up to encode the metaphor ahead of time. Under this system, it is not possible to deduce new metaphors; in f</context>
</contexts>
<marker>1986</marker>
<rawString>[Herskovits 1986]</rawString>
</citation>
<citation valid="false">
<authors>
<author>Annette Herskovits</author>
</authors>
<title>Language and spatial cognition: an interdisciplinary study of the prepositions in English.</title>
<publisher>Cambridge University Press,</publisher>
<location>New York.</location>
<marker>Herskovits, </marker>
<rawString>Annette Herskovits. Language and spatial cognition: an interdisciplinary study of the prepositions in English. Cambridge University Press, New York.</rawString>
</citation>
<citation valid="false">
<date>1989</date>
<location>Herskovits</location>
<marker>1989</marker>
<rawString>[Herskovits 1989]</rawString>
</citation>
<citation valid="false">
<authors>
<author>Annette Herskovits</author>
</authors>
<title>The linguistic expression of spatial knowledge.</title>
<journal>L.A.U.D. Paper A</journal>
<volume>248</volume>
<institution>Linguistic Agency University of Duisburg.</institution>
<marker>Herskovits, </marker>
<rawString>Annette Herskovits. The linguistic expression of spatial knowledge. L.A.U.D. Paper A 248, Linguistic Agency University of Duisburg.</rawString>
</citation>
<citation valid="true">
<title>Ray Jackendoff. Semantics and Cognition.</title>
<date>1983</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="7781" citStr="(1983)" startWordPosition="1248" endWordPosition="1248">mic uses. 4 The coercion mechanism The central information source in our account of metaphor and metonymy is a set of coercion rules. Coercion rules declare different ways of viewing particular classes of objects. So if we wish to view temporal intervals as one-dimensional spatial objects (lines), we would declare: (1) (detCoerce temporal-interval line) These coercion rules can be chained; if we wish to view events as temporal intervals (that is, the intervals over which they occur), we could ultimately view them as lines as well simply by adding another declaration: 2Herskovits follows Tahny (1983) and others in seeing locative prepositions as defining a figure/ground relationship between a located object and a reference object. 3The ideal meaning of at is for two points to coincide (1986, p.128). 4 Jackendoff proposes a similar response to the problem, with respect to temporal use of spatial expressions. See (Jackendoff, 1983, ch.10). 223 (2) (deiCoerce durative-event temporal-interval) King Kong uses these coercion rules in two related ways. The first is to license what we call shadow relations. These are relations that have no parent but are connected to the domain model by means of </context>
<context position="16840" citStr="(1983)" startWordPosition="2692" endWordPosition="2692">rting metaphorical extension by explicitly defining the space of possible ways of conceptualizing an object allows us considerable flexibility in understanding novel metaphoric use.8 The same augmented coercion rules can be used if we wish to license a shadow relation that has no backend access code associated with it. We might want to use that strategy in the situation where the metaphoric use can be anticipated but the access code associated with the shadow would have to perform exactly the same computation as the coercion code. 5 Comparison with other accounts As in DeJong and Waltz&apos;s work (1983), the King Kong coercion mechanism is triggered by violations of sort restrictions on arguments. We do not, however, agree with DeJong and Waltz&apos;s contention that &amp;quot;Nouns are far less likely to be metaphorical than verbs.&amp;quot; The symbiosis between shadows and coercion rules implies that the metaphor lies not in the functor or its arguments, but rather in the association between them. Furthermore, our mechanism also structures the path between metaphoric use and ideal meaning, and provides computational support for argument coercion. The mechanism has the same advantage over the work of Jacobs and </context>
</contexts>
<marker>1983</marker>
<rawString>[Jackendoff 1983] Ray Jackendoff. Semantics and Cognition. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Paul S Jacobs</author>
</authors>
<title>Language analysis in not-solimited domains.</title>
<booktitle>In Proceedings of the IEEE Fall Joint Computer Conference.</booktitle>
<marker>Jacobs, </marker>
<rawString>[Jacobs 1986] Paul S. Jacobs. Language analysis in not-solimited domains. In Proceedings of the IEEE Fall Joint Computer Conference.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Paul S Jacobs</author>
</authors>
<title>A knowledge framework for natural language analysis.</title>
<booktitle>In IJCAI-87: Proceedings of the 10th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>675--678</pages>
<marker>Jacobs, </marker>
<rawString>[Jacobs 1987] Paul S. Jacobs. A knowledge framework for natural language analysis. In IJCAI-87: Proceedings of the 10th International Joint Conference on Artificial Intelligence, pages 675-678.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fire Women</author>
</authors>
<title>and Dangerous Things.</title>
<date>1987</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago. [Martin</location>
<marker>Women, 1987</marker>
<rawString>[Lakoff 1987] George Lakoff. Women, Fire, and Dangerous Things. University of Chicago Press, Chicago. [Martin 1987a]</rawString>
</citation>
<citation valid="false">
<authors>
<author>James H Martin</author>
</authors>
<title>The acquisition of polysemy.</title>
<booktitle>In Proceedings of the Fourth International Workshop on Machine Learning,</booktitle>
<pages>198--204</pages>
<marker>Martin, </marker>
<rawString>James H. Martin. The acquisition of polysemy. In Proceedings of the Fourth International Workshop on Machine Learning, pages 198-204.</rawString>
</citation>
<citation valid="false">
<authors>
<author>James H Martin</author>
</authors>
<title>Understanding new metaphors.</title>
<booktitle>In IJCAI-87: Proceedings of the 10th International Conference on Artificial Intelligence,</booktitle>
<pages>137--139</pages>
<marker>Martin, </marker>
<rawString>[Martin 1987b] James H. Martin. Understanding new metaphors. In IJCAI-87: Proceedings of the 10th International Conference on Artificial Intelligence, pages 137-139.</rawString>
</citation>
<citation valid="true">
<title>Marvin Minsky. A framework for representing knowledge.</title>
<date>1975</date>
<booktitle>The Psychology of Computer Vision, chapter 6,</booktitle>
<pages>211--277</pages>
<editor>In Patrick Henry Winston, editor,</editor>
<publisher>McGraw-Hill,</publisher>
<location>New York.</location>
<contexts>
<context position="940" citStr="(1975)" startWordPosition="136" endWordPosition="136">ce. The method licenses metaphoric uses via coercions between incompatible ontological sorts. The machinery allows both previously-known and unexpected metaphoric uses to be correctly interpreted and evaluated with respect to the backend expert system. 1 Introduction One of the central issues in Al systems has been how to model the domain: what are the primitives of the ontological language, how are the ontological sorts organized, and so on. Al researchers have explored a wide range of object-centered and relation-centered representations (for example, Brachman and Schmolze (1985) and Minsky (1975)). When setting up the domain model for a natural language interface, though, one must also keep the lexicon in mind, so that words can be defined and processed efficiently; if possible, the hierarchical organization of the domain model should minimize sense ambiguity, by allowing lexical items to point to classes that dominate the objects that reflect each item&apos;s range of meanings. However, a growing body of literature argues that the generalizations about the world implied by the lexicon do not correspond exactly to standard computational notions of fine-grained ontological structure. Rather</context>
</contexts>
<marker>1975</marker>
<rawString>[Minsky 1975] Marvin Minsky. A framework for representing knowledge. In Patrick Henry Winston, editor, The Psychology of Computer Vision, chapter 6, pages 211-277. McGraw-Hill, New York.</rawString>
</citation>
<citation valid="true">
<title>James Pustejovsky. Lexical ambiguity and the role of inheritance. Talk given at BBN,</title>
<date>1990</date>
<location>Cambridge, MA, 6</location>
<contexts>
<context position="21083" citStr="(1990)" startWordPosition="3379" endWordPosition="3379">ons of the base and target using a set of match construction rules. But the central example of a match construction 226 rule seems to require that the names of the predicates in the facts being matched be identical. Under this sort of construction rule, it is possible to derive a metaphoric mapping only if the names of the predicates have been set up to encode the metaphor ahead of time. Under this system, it is not possible to deduce new metaphors; in fact, one can only recognize them if the metaphoric link has been made but not recorded. 5.3 Boguraev and Pustejovsky Boguraev and Pustejovsky (1990) argue that the normal conceptions of the structure of the lexicon are impoverished for two major reasons. First, a great number of distinctions beyond those usually made are necessary to capture the essential aspects of lexical semantics. Second, the common technique for representing ambiguity in the lexicon (enumeration) falls short because enumeration of word senses neither organizes the senses intelligently nor provides for creative use of words. For instance, under the enumeration method, the following uses of &amp;quot;fast&amp;quot; require that at least these three senses be listed in the lexicon: fast </context>
</contexts>
<marker>1990</marker>
<rawString>[Pustejovsky 1990] James Pustejovsky. Lexical ambiguity and the role of inheritance. Talk given at BBN, Cambridge, MA, 6 November 1990.</rawString>
</citation>
<citation valid="true">
<title>Leonard Talmy. How language structures space.</title>
<date>1983</date>
<booktitle>In Herbert Pick and Linda Acredolo, editors, Spatial Orientation: Theory, Research, and Application.</booktitle>
<publisher>Plenum Press,</publisher>
<institution>Talmy</institution>
<location>New York.</location>
<contexts>
<context position="7781" citStr="(1983)" startWordPosition="1248" endWordPosition="1248">mic uses. 4 The coercion mechanism The central information source in our account of metaphor and metonymy is a set of coercion rules. Coercion rules declare different ways of viewing particular classes of objects. So if we wish to view temporal intervals as one-dimensional spatial objects (lines), we would declare: (1) (detCoerce temporal-interval line) These coercion rules can be chained; if we wish to view events as temporal intervals (that is, the intervals over which they occur), we could ultimately view them as lines as well simply by adding another declaration: 2Herskovits follows Tahny (1983) and others in seeing locative prepositions as defining a figure/ground relationship between a located object and a reference object. 3The ideal meaning of at is for two points to coincide (1986, p.128). 4 Jackendoff proposes a similar response to the problem, with respect to temporal use of spatial expressions. See (Jackendoff, 1983, ch.10). 223 (2) (deiCoerce durative-event temporal-interval) King Kong uses these coercion rules in two related ways. The first is to license what we call shadow relations. These are relations that have no parent but are connected to the domain model by means of </context>
<context position="16840" citStr="(1983)" startWordPosition="2692" endWordPosition="2692">rting metaphorical extension by explicitly defining the space of possible ways of conceptualizing an object allows us considerable flexibility in understanding novel metaphoric use.8 The same augmented coercion rules can be used if we wish to license a shadow relation that has no backend access code associated with it. We might want to use that strategy in the situation where the metaphoric use can be anticipated but the access code associated with the shadow would have to perform exactly the same computation as the coercion code. 5 Comparison with other accounts As in DeJong and Waltz&apos;s work (1983), the King Kong coercion mechanism is triggered by violations of sort restrictions on arguments. We do not, however, agree with DeJong and Waltz&apos;s contention that &amp;quot;Nouns are far less likely to be metaphorical than verbs.&amp;quot; The symbiosis between shadows and coercion rules implies that the metaphor lies not in the functor or its arguments, but rather in the association between them. Furthermore, our mechanism also structures the path between metaphoric use and ideal meaning, and provides computational support for argument coercion. The mechanism has the same advantage over the work of Jacobs and </context>
</contexts>
<marker>1983</marker>
<rawString>[Talmy 1983] Leonard Talmy. How language structures space. In Herbert Pick and Linda Acredolo, editors, Spatial Orientation: Theory, Research, and Application. Plenum Press, New York.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>