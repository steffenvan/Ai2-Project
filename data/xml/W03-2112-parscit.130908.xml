<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.924394">
Example-based Spoken Dialogue System using WOZ System Log
</title>
<author confidence="0.459958">
Hiroya MURAO *,**, Nobuo KAWAGUCHI **,† Shigeki MATSUBARA **,†
</author>
<affiliation confidence="0.358213">
Yukiko YAMAGUCHI† Yasuyoshi INAGAKI‡
* Digital Systems Development Center,SANYO Electric Co., Ltd.,
Hirakata-shi, Osaka, 573-8534 Japan
** Center for Integrated Acoustic Information Research,Nagoya University,
† Information Technology Center, Nagoya University,
</affiliation>
<address confidence="0.761048666666667">
Furo-cho, Chikusa-ku, Nagoya-shi, 464-8603 Japan
‡ The Faculty of Information Science and Technology, Aichi Prefectural University,
Nagakute-cho, Aichi-gun, Aichi, 480-1198, Japan
</address>
<email confidence="0.999231">
murao@hr.hm.rd.sanyo.co.jp
</email>
<sectionHeader confidence="0.995645" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998478">
This paper proposes a new framework for
a spoken dialogue system based on dia-
logue examples between human subjects
and the Wizard of OZ (WOZ) system. Us-
ing this framework and a model of infor-
mation retrieval dialogue, a spoken dia-
logue system for retrieving shop informa-
tion while driving in a car has been de-
signed. The system refers to the dialogue
examples to find an example that is suit-
able for generating a query or a reply. The
authors have also constructed a large-scale
dialogue database using a WOZ system,
which enables efficient collection of dia-
logue examples.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999897034482759">
Against the background of ever-increasing comput-
ing power, techniques for constructing spoken di-
alogue systems using large-scale speech and text
corpora have become the target of much research
(Levin et al., 1998; Young, 2002). In prior re-
search, the authors have proposed a spoken-dialogue
control technique using dialogue examples with the
aim of performing flexible dialogue control dur-
ing information-retrieval dialogue and of achieving
speech understanding robust against speech recog-
nition errors (Murao et al., 2001). This technique
uses input speech data and supplementary informa-
tion corresponding to input speech such as retrieval
formulas (queries) to form ”examples” that decide
system action. A system using this technique can-
not run effectively, however, without a large volume
of example data. Traditionally, though, collecting
human-to-human dialogue data and manually pro-
viding such supplementary information for each in-
stance of input speech has required considerable la-
bor.
In this paper, we address this problem and pro-
pose a new technique for constructing an example-
based dialogue system using, as example data, the
dialogue performed between a human subject and a
pseudo-spoken-dialogue system based on the Wiz-
ard of OZ (WOZ) scheme. We also describe a
specific spoken dialogue system for information re-
trieval that we constructed using this technique.
</bodyText>
<sectionHeader confidence="0.981065" genericHeader="method">
2 Dialogue Processing Based on Examples
</sectionHeader>
<bodyText confidence="0.999472333333333">
We first provide an overview of example-based dia-
logue processing that we previously proposed (Mu-
rao et al., 2001).
</bodyText>
<subsectionHeader confidence="0.999012">
2.1 Model of information retrieval dialogue
</subsectionHeader>
<bodyText confidence="0.9997358">
Given a scenario in which a human operator
searches an information database and returns infor-
mation to a user, dialog between the operator and
user can be modeled as shown in Fig. 1. The ele-
ments of this model are described below.
</bodyText>
<listItem confidence="0.9943218">
1. Request The user tells the operator the con-
tents of an inquiry and demands reference.
2. Retrieval The operator receiving the user’s re-
quest generates a query after referencing do-
main knowledge and current dialogue context
</listItem>
<figureCaption confidence="0.84393">
Figure 1: Information flow of information retrieval
dialogue
</figureCaption>
<bodyText confidence="0.855117666666667">
and then processes the query indirectly by ma-
nipulating a search tool such as an ordinary
computer.
</bodyText>
<listItem confidence="0.89310375">
3. Search results The search tool generates
search results.
4. Reply The operator returns a reply to the user
based on search results and dialogue context.
</listItem>
<bodyText confidence="0.998801185185185">
Setting up information flow in this way allows
us to view operator behavior in the following way.
Specifically, the operator in Fig. 1 makes two deci-
sions in the process of advancing dialog.
Decision 1: Generate a query after listening to user
speech
Decision 2: Generate a reply after receiving search
results
Here, an experienced operator would use more
than just the superficial information obtained from
user speech. To generate a query or reply that
best suits the user’s need at that time, the opera-
tor would also make use of domain knowledge, di-
alogue context, and the search results themselves.
In other words, this kind of dialogue processing can
be viewed as a mapping operation from input infor-
mation such as user speech and domain knowledge
to output information such as a query. With this in
mind, we considered whether a ”decision” to guide
such dialogue could be automatically performed by
referring to actual examples of behavior manifested
by an experienced human operator. In short, we de-
cided to store a large volume of dialogue examples,
i.e., mapping information, and to determine output
information for certain input information on the ba-
sis of mapping information stored in similar dia-
logue examples.
</bodyText>
<subsectionHeader confidence="0.991177333333333">
2.2 Generation of queries and replies based on
examples
2.2.1 Structure of example data
</subsectionHeader>
<bodyText confidence="0.99974075">
The two ”decisions” performed during the time of
information retrieval dialogue between the user and
operator can be expressed as a mapping between the
following input and output information.
</bodyText>
<listItem confidence="0.968398666666667">
• Input/output information in the decision for
generating a query:
Input User speech and dialogue context
Output Query
• Input/output information in the decision for
generating a reply:
</listItem>
<bodyText confidence="0.892012625">
Input User speech, dialogue context, and
search results
Output Reply
It is therefore sufficient to save those items that
cover such input and output information. Specifi-
cally, a large number of example data can be col-
lected using the following information as elements
to construct an example database.
</bodyText>
<listItem confidence="0.990771833333333">
1. Text of user speech
2. Query
3. Reply text
4. Search results
5. Dialogue context (past speech, grounding in-
formation, conversational objects, etc.)
</listItem>
<bodyText confidence="0.995125333333333">
The following describes the procedure for gener-
ating a query or reply with respect to input speech
by referencing an example database.
</bodyText>
<subsectionHeader confidence="0.49138">
2.2.2 Query generation process
</subsectionHeader>
<bodyText confidence="0.999868">
From among the examples in the example
database, the system extracts the one most similar
to the input speech and the dialogue context at that
time. It then adjusts the query in that example to fit
the input speech and generates a new query.
</bodyText>
<figure confidence="0.998421411764706">
(4)Reply
Domain Knowledge
and
Dialogue Context
Information
Database
Queries
Search
Results
Search
Tool
User
(1)Request
(2)Retrieval
(3)Search
Results
Operator
</figure>
<subsectionHeader confidence="0.490974">
2.2.3 Reply generation process
</subsectionHeader>
<bodyText confidence="0.999713857142857">
The system performs a search based on the gen-
erated query and receives search results. It then ex-
tracts the most similar example from the example
database with respect to input speech, the dialogue
context at that time, and the search results. Finally,
the system adjusts the reply in that example to fit the
current conditions and generates a new reply.
</bodyText>
<subsectionHeader confidence="0.99953">
2.3 Problem points
</subsectionHeader>
<bodyText confidence="0.999933888888889">
Operating a dialogue system based on dialogue
examples requires the construction of an example
database as described above. Constructing a large-
scale example database, moreover, requires a large
volume of dialogue text in which supplementary in-
formation such as queries and search results has
been provided with respect to input speech.
Up to now, we have been constructing an exam-
ple database by first collecting human-to-human di-
alogue and converting speech to text and then as-
signing queries, search results, and the like to each
instance of input speech. This, however, is a labori-
ous process. In addition, example data constructed
on the basis of human-to-human dialogue data may
have features different from those of human-to-
dialogue-system dialogue data. In other words, we
cannot call the above approach an optimal method
for constructing example data.
</bodyText>
<subsectionHeader confidence="0.8403735">
3 Construction of an Example Database
using the WOZ System
</subsectionHeader>
<bodyText confidence="0.999973285714286">
We propose the Wizard of OZ (WOZ) system as
one means of efficiently collecting dialogue data
that includes supplementary information attached to
speech. Carrying on a dialogue using WOZ makes
it possible to collect the information needed for
constructing an example database while collecting
speech data.
</bodyText>
<subsectionHeader confidence="0.998201">
3.1 WOZ system
</subsectionHeader>
<bodyText confidence="0.999954833333333">
When carrying on a dialogue using the WOZ sys-
tem, the user feels that he or she is talking to a com-
pletely mechanical system despite the fact that a hu-
man being is actually being used for some of the
elements making up the dialogue system. Collect-
ing dialogue data by WOZ should therefore result in
</bodyText>
<figureCaption confidence="0.999155">
Figure 2: Configuration of Wizard of OZ system
</figureCaption>
<bodyText confidence="0.999910838709677">
data that is closer to dialogue that would occur be-
tween a human and a machine.
Collecting spoken dialogue data using the WOZ
system has actually been performed a number of
times in the past (MADCOW, 1992; Bertenstam et
al., 1995; Life et al., 1996; Eskenazi et al., 1999;
San-Segundo et al., 2001; Lemmela and Boda, 2002;
Yoma et al., 2002). The objective of those stud-
ies, however, was to collect, analyze, and evaluate
dialogue data between people and artificial objects,
and in many cases, only one of the artificial-object’s
functions was taken over by a human, for example,
the speech recognition function.
Our study, however, goes further than the above.
In particular, we create special software (called
WOZ software) that allows a human being to per-
form the functions of interpreting user speech, gen-
erating queries and executing searches, and generat-
ing replies. We then propose a framework that en-
ables the operator (wizard) to carry on a dialogue
with the user while operating this WOZ software so
that obtained data can be used later to perform di-
rect control of a dialogue system. Specifically, we
configure a pseudo-spoken-dialogue system (WOZ)
consisting of WOZ software and an operator, hold
information retrieval dialogue between this system
and human subjects, and save the queries ,search re-
sults and reply statements generated at this time as
log information. We then use this log information
and text-converted speech to construct an example
database that can be used for dialogue control.
</bodyText>
<subsectionHeader confidence="0.996505">
3.2 System configuration
</subsectionHeader>
<bodyText confidence="0.91173">
Figure 2 shows the entire configuration of the WOZ
system that we constructed. In this configuration,
</bodyText>
<figure confidence="0.999728857142857">
User
Speech Input
Speech
Output
Speech
Symthesis
Information
Database
Search
Execution
Part
Reply Text
Log
Information
Query
Tree Structured
Keywords
Search
Results
Query
Generation
Part
The WoZ Software
Reply-Statement
Bigram
Touch Panel
and
Display
The Operator
control buttons
type of
keywords
keywords
search
results
</figure>
<figureCaption confidence="0.940377">
Figure 3: An example of display of Wizard of OZ system (1): Query generation part
</figureCaption>
<figure confidence="0.999423777777778">
control buttons
&amp;
standard phrases
search
results
type of
keywords
text input
buttons
</figure>
<figureCaption confidence="0.999936">
Figure 4: An example of display of Wizard of OZ system (2): Reply generation part
</figureCaption>
<bodyText confidence="0.995744551724138">
the WOZ software, which was created using the
C++ language, runs on a personal computer under
Windows2000. It consists of a screen for generat-
ing queries (query part) and a screen for generating
replies (reply part). Figures 3 and 4 show sample
screens of these parts. This GUI adopts a touch-
panel system to facilitate operations — an operator
only has to touch a button on one of these screens
to generate a query, search an information database,
generate a reply, or output synthesized speech.
WOZ software must feature high operability to
achieve natural dialogue between the WOZ system
and a human user. When designing WOZ software
on the basis of a human-to-human dialogue corpus
that we previously collected, we used the following
techniques to enable the system to operate in real
time while carrying on a dialogue with the user.
First, the query part arranges keywords in a tree
structure by search type so that appropriate key-
words can be selected at a touch to generate a query
and retrieve information quickly 1 . Search results
are displayed at the bottom of the screen in list form.
Second, the reply part displays text-input buttons
for generating replies and a list of search results.
The text-input buttons correspond to words, phrases,
and short standard sentences, and pushing them in
&apos;Queries that deal with context in regard to input speech are
currently not defined for the sake of simplicity in software op-
eration.
</bodyText>
<figure confidence="0.706155333333333">
•Hungry, but not enough time.
•Search Japanese food restaurant.
•You want to eat Chineese noodle.
</figure>
<figureCaption confidence="0.99961">
Figure 5: Examples of prompting panels
</figureCaption>
<bodyText confidence="0.999983913043478">
an appropriate order generates a reply in text form.
The arrangement of these text-input buttons on the
screen is based on connection frequency between
text elements (reply-statement bigram) as previously
determined from the human-to-human dialogue cor-
pus mentioned above. In other words, each text-
input button represents a text entry having the high-
est frequency of following the immediately previous
text entry to the left, which makes for quick genera-
tion of a reply. Furthermore, to enable quick input,
the section of the screen displaying the search results
has been designed so that the name portion of each
result can be touched directly and automatically in-
cluded in the reply. The generated reply in text form
is finally output in voice form via the speech synthe-
sis section of the system.
Switching back and forth between the query and
reply parts can be performed as needed using a
switch button. The reply part also includes but-
tons for instantly generating words and short phrases
of confirmation and encouragement (e.g., ”yes,” ”I
see”) while the user is speaking to create as natural
a dialogue as possible.
</bodyText>
<subsectionHeader confidence="0.9533705">
3.3 Collecting dialogue data by the WOZ
system
</subsectionHeader>
<bodyText confidence="0.999701923076923">
We targeted shop-information retrieval while driv-
ing a car as an information-retrieval application
based on spoken dialogue, and collected dialogue
data between the WOZ system and human subjects
(Kawaguchi et al., 2002). This data was collected
within an automobile driven by subjects each of
whom acted as a user searching for information. A
personal computer running the WOZ software was
placed in the automobile with the ”wizard” sitting
in the back seat. All spoken dialogue was recorded
using another personal computer.
Data collection was performed according to the
following procedure for a duration of about five min-
</bodyText>
<tableCaption confidence="0.997907">
Table 1: Collected WOZ data
</tableCaption>
<table confidence="0.856323">
Number of Speech length Speech Units
sessions (min.)
User WOZ User WOZ
487 499 791 13,828 12,487
utes per subject.
</table>
<listItem confidence="0.96580375">
• A prompting panel such as shown in Fig. 5 is
presented to the subject.
• The subject converses freely with WOZ based
on the prompting panel shown.
</listItem>
<bodyText confidence="0.9895916">
The wizard operates the WOZ system while lis-
tening to the subject, that is, the wizard performs an
appropriate search and returns a reply using speech
synthesis 2 .
Table 1 shows the scale of collected data.
</bodyText>
<subsectionHeader confidence="0.7543805">
3.4 Constructing an example database using
WOZ log information
</subsectionHeader>
<bodyText confidence="0.99924175">
WOZ software was designed to output detailed log
information. This information consists mainly of
the following items. All log information is recorded
with time stamps.
</bodyText>
<listItem confidence="0.999375875">
• Speaker ID (input by the wizard when initiating
a dialogue)
• Query generated for the input speech in ques-
tion
• Search results returned for the generated query
(number of hits and shop IDs)
• Text of reply generated by the operator (wiz-
ard)
</listItem>
<bodyText confidence="0.995475">
A saved WOZ log can be used to efficiently con-
struct an example database by the following proce-
dure. To begin with, a written record of user speech
is made based on the voice recording of spoken di-
alog with time information added. Next, based on
</bodyText>
<footnote confidence="0.9405918">
2The wizard generates queries, performs searches, and gen-
erates replies to the extent possible for speech to which defined
queries can be applied. If a query cannot be generated, the wiz-
ard will not keep trying and will generate only an appropriate
response.
</footnote>
<figureCaption confidence="0.999647">
Figure 6: A view of example-based dialogue system
</figureCaption>
<figure confidence="0.952123368421052">
(Well, search convenience stores near here.)
Reply
(I found CIRCLE-K Makinohara store and SUNKUS Kamenoi store near here.)
Dialogue history
Search results
Input text
(Result of speech
recognition)
The most similar
example
for query generation
The most similar
example
for reply generation
Table 2: Configuration of constructed example
database
Number of Number of
sessions examples
243 1,206
</figure>
<bodyText confidence="0.997277272727273">
the time information in the log output by WOZ soft-
ware, a correspondence is established between user
speech and queries and between search results and
replies.
We constructed an example database using a por-
tion of dialogue data collected in the above manner.
Table 2 summarizes the data used for this purpose.
Query and search-result correspondences were es-
tablished for about 20% of all user speech excluding
speech outside of the task in question and speech
outside of query specifications.
</bodyText>
<sectionHeader confidence="0.958809" genericHeader="method">
4 Spoken Dialogue System using Dialogue
Examples
</sectionHeader>
<bodyText confidence="0.999984285714286">
We here describe a dialogue system that runs using
the example database that we constructed (see (Mu-
rao et al., 2001) for details). The task is to search for
shop information while inside an automobile. This
system was implemented using the C++ language
under Windows2000. Figure 6 shows a screen shot
of this example-based dialogue system.
</bodyText>
<subsectionHeader confidence="0.995403">
4.1 System configuration
</subsectionHeader>
<bodyText confidence="0.973718666666667">
The following describes the components of this sys-
tem with reference to Fig. 7.
Dialogue example database (DEDB): Consists of
data constructed from dialogue text and log in-
formation output from WOZ software. Dia-
logue text is subjected to morphological anal-
ysis 3, and words essential to advancing the di-
alogue (e.g., shop name, facility name, food
name) are assigned word class tags based on
classes given to these words beforehand ac-
cording to meaning.
Word Class Database (WCDB): Consists of
words essential to the task in question and
classes given to them according to meaning.
Word classes are determined empirically based
on dialogue within the dialogue corpus.
Shop Information Database (SIDB): Consists of
a collection of information on about 800 restau-
rants and shops in Nagoya, the same as that
used in the WOZ system.
Speech Recognition: Uses “Japanese Dictation
Toolkit(Kawahara et al., 2000)”. The lan-
guage model was created from the previously
collected human-to-human dialogue corpus.
</bodyText>
<footnote confidence="0.84761">
3Using ChaSen morphological-analysis software for the
Japanese language (Asahara and Matsumoto, 2000).
</footnote>
<figure confidence="0.994081789473684">
Speech
Input
Speech
Output
Speech
Recognition
Speech
Synthesis
Dialogue Example
Database
(DEDB)
Query Generation
Reply Generation
Word class
Database
(WCDB)
Shop Information
Database
(SIDB)
</figure>
<table confidence="0.8355089375">
Search
Step1: Extracting similar example for query
Input: Etto, spaghetti no omise ni ikitai na.
(I&apos;d like to go to a spaghetti restaurant.)
Similar cases Keywords: [10: spaghetti],[omise (shop)],[iku (go)]
1st: U: &lt;10:Curry&gt; no [omise] ni [iki]tain desu kedo
(I&apos;d like to go to a curry restaurant. )
Q: search KEY=&lt;10:curry&gt;
2nd: U: &lt;10: Ramen(noodles)&gt; wo &lt;tabe&gt; ni [iki] taina
(I&apos;d like to eat noodles.)
Q: search KEY=&lt;10:ramen&gt;
3rd: U: [10: Spaghetti] de &lt;yu-mei&gt; na &lt;tokoro&gt; ga iidesu
( I prefer a popular resutaurant for spaghetti.)
Q: search KEY=&lt;10:spaghetti&gt;
Step2: Query Modification
Query in the similar case: search KEY=&lt;10:curry&gt;
Matched keywords pair: ( &lt;10:curry&gt; , &lt;10:spaghetti&gt; )
Output Query: search KEY=&lt;10:spaghetti&gt;
Step3: Search
Iutput Query: search KEY=&lt;10:spaghetti&gt;
Search Result: RESULT=NONE
Step4: Extracting similar example for reply
Input: Etto, spaghetti no omise ni ikitai na.
(I&apos;d like to go to a spaghetti restaurant.)
1st: U:&lt;10: Ramen(noodles)&gt; wo &lt;tabe&gt; ni [iki] taina
(I&apos;d like to eat noodles.)
Q: search KEY=&lt;10:ramen&gt;
S:&lt;10:Ramen(noodles)&gt; no [omise] wa chikaku ni arimasen
( There are no noodle restaurants near here.)
A: RESULT=NONE
2nd: U:&lt;10:Curry&gt; no [omise] ni [iki]tain desu kedo
(I&apos;d like to go to a curry restaurant. )
Q: search KEY=&lt;10:curry&gt;
S:Hai, Curry no omise wa 5-ken arimasu
(Well, I found 5 curry restaurants.)
A: RESULT=5, ID1=120,..,ID5=565
Similar cases{
Keywords: [10: spaghetti],[omise (shop)],[iku (go)]
Search Result: RESULT=NONE
Step5: Reply Modification
Reply in the similar case:
&lt;10:Ramen(noodles)&gt; no [omise] wa chikaku ni arimasen
( There are no noodle restaurants near here.)
Matched keywords pair:
( &lt;10:Ramen(noodles)&gt; , &lt;10:spaghetti&gt; )
Output Reply:
&lt;10:spaghetti&gt; no [omise] wa chikaku ni arimasen
( There are no spaghetti restaurants near here.)
</table>
<figureCaption confidence="0.982133333333333">
Figure 8: Example of query and reply generation
Figure 7: Configuration of example-based dialogue
system
</figureCaption>
<bodyText confidence="0.988213375">
Query Generation: Extracts from the DEDB the
example closest to current input speech and
conditions, modifies the query in that example
according to current conditions, and outputs the
result.
Search execution: Accesses the SIDB using the
generated query and obtains search results.
Reply Generation: Extracts from the DEDB the
example closest to input speech and search re-
sults, modifies the reply in that example ac-
cording to current conditions, and outputs the
result.
Speech Synthesis: Outputs replies in voice form
using a Japanese TTS (Text To Speech) soft-
ware “EleganTalk Ver. 2.1” by Sanyo Electric
Co., Ltd. .
</bodyText>
<subsectionHeader confidence="0.937464">
4.2 Operation
</subsectionHeader>
<bodyText confidence="0.9971035">
The following describes system operation (see Fig.
8 for a specific operation example).
</bodyText>
<subsectionHeader confidence="0.500171">
Step 1: Extracting similar example for query
</subsectionHeader>
<bodyText confidence="0.995929034482759">
For a speech recognition result, the system
extracts the most similar example from the
DEDB. The robustness of the similarity cal-
culation between the input utterance and the
utterance in the DEDB should be considered
against the speech recognition error. Therefore,
a keyword matching method using the word
class information is adopted. For a speech
recognition result combined with a morpholog-
ical analysis result, independent words and the
important words to which the word class tags
are assigned according to the information in
the WCDB are regarded as the keywords, and
their similarity is calculated as follows. For
each transcription of a user’s utterances in the
DEDB, the number of matched words and the
number of important words which belong to
the same word class are accumulated with the
correspondent weight and the result is treated
as the similarity. The utterance which marks
the highest similarity is regarded as the most
similar one.
Step2: Query Modification The query for the ex-
tracted example is modified with reference to
the input utterance. The modification is per-
formed by replacing the keywords in the refer-
ence query using word class information.
Step 3: Search The SIDB is searched by using the
modified query and a search result is obtained.
</bodyText>
<subsectionHeader confidence="0.448458">
Step 4: Extracting similar example for reply
</subsectionHeader>
<bodyText confidence="0.998604805555555">
The system extracts the most similar example
from the DEDB, by taking account of not only
the similarity between the input utterance and
the utterance in examples but also that between
the number of items in the search result and
that in the examples. Here, a total similarity
score is computed by performing a weighted
summation of two values: the utterance sim-
ilarity score and the search-results similarity
score obtained from the difference between
the number of search results in an example
and that obtained in Step 3. The search-results
similarity score is computed as follows.
When the number of search results by mod-
ified query is 0: Give the highest score to
examples in the example database with 0 num-
ber of search results and the lowest score to all
other examples.
When the number of search results by mod-
ified query is 1 or more: Give the high-
est score to examples in the example database
with the same number of search results and an
increasingly lower score as difference in the
number of search results becomes larger (use
heuristics).
For example, if not even one search result could
be obtained by the modified query, examples in
the example database with not even one search
result constitute a match.
Step 5: Reply Modification The reply statement
for the extracted example is modified with ref-
erence to the input utterance. The modification
is performed by replacing the words in the ref-
erence reply statement by using word class in-
formation. Then a speech synthesis module is
used to produce a reply speech.
</bodyText>
<subsectionHeader confidence="0.971104">
4.3 Adding, modification, and deletion of
example data
</subsectionHeader>
<bodyText confidence="0.999977333333333">
This system allows example data to be added, mod-
ified, and deleted. When a failed operation occurs
while carrying on a dialogue, for example, buttons
located at the bottom of the screen can be used to
modify existing example data, add new examples,
and delete unnecessary examples.
</bodyText>
<sectionHeader confidence="0.999198" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9995924">
This paper has proposed an efficient technique for
collecting example data using the Wizard of OZ
(WOZ) system for the purpose of guiding spoken di-
alogue using dialogue examples. This technique has
the following effects.
</bodyText>
<listItem confidence="0.9174314">
• Knowledge buried in the WOZ system log
(conversions from input speech to query and
reply, etc.) can be used as dialogue system
knowledge.
• Because dialogue is collected using the WOZ
</listItem>
<bodyText confidence="0.941999166666667">
system, the examples so collected are close to
dialogue that would occur in an environment
with an actual dialogue system. In other words,
dialogue examples can be collected under con-
ditions close to human-to-machine dialogue.
• The labor involved in recording speech neces-
sary for construction of an example database
can be reduced.
In future research, we plan to evaluate dialogue-
processing performance and context processing us-
ing example databases constructed with the WOZ
system.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99968015">
Masayuki Asahara and Yuji Matsumoto. 2000. Extended
models and tools for high-performance part-of-speech
tagger. In Proceedings of COLING 2000, July.
J. Bertenstam, M. Blomberg, R. Carlson, K. Elenius,
B. Granstrom, J. Gustafson, S. Hunnicutt, J. Hogberg,
R. Lindell, L. Neovius, A. de Serpa-Leitao, L. Nord,
and N. Strom. 1995. The waxholm application data-
base. In Proceedings of Eurospeech-95, volume 1,
pages 833–836.
Maxine Eskenazi, Alexander Rudnicky, Karin Gregory,
Paul Constantinides Robert Brennan, Christina Ben-
nett, and Jwan Allen. 1999. Data collection and pro-
cessing in the carnegie mellon communicator. In Pro-
ceedings of Eurospeech-99, volume 6, pages 2695–
2698.
Nobuo Kawaguchi, Shigeki Matsubara, Kazuya Takeda,
and Fumitada Itakura. 2002. Multi-dimensional
data acquisition for integrated acoustic information
research. In Proc. of 3rd International Language
Resources and Evaluation Conference (LREC-2002),
pages 2043–2046.
T. Kawahara, A. Lee, T. Kobayashi, K. Takeda, N. Mine-
matsu, S. Sagayama, K. Itou, A. Ito, M. Yamamoto,
A. Yamada, T. Utsuro, and K. Shikano. 2000. Free
software toolkit for japanese large vocabulary contin-
uous speech recognition. In Proceedings of ICSLP-
2000, volume 4, pages 476–479.
Saija-Maaria Lemmela and Peter Pal Boda. 2002. Effi-
cient combination of type-in and wizard-of-oz tests in
speech interface development process. In Proceedings
ofICSLP-2002, pages 1477–1480.
Esther Levin, Roberto Pieraccini, and Wieland Eckert.
1998. Using markov decision processes for learning
dialogue strategies. In Proceedings ofICASSP98, vol-
ume 1, pages 201–204.
A. Life, I. Salter, J.N. Temem, F. Bernard, S. Rosset,
S. Bennacef, and L. Lamel. 1996. Data collection
for the mask kiosk: Woz vs prototype system. In Pro-
ceedings ofICSLP-96, pages 1672–1675.
MADCOW. 1992. Multi-site data collection for a spo-
ken language corpus. In DARPA Speech and Natural
Language Workshop ’92.
Hiroya Murao, Nobuo Kawaguchi, Shigeki Matsubara,
and Yasuyoshi Inagaki. 2001. Example-based query
generation for spontaneous speech. In Proceedings of
2001 IEEE Workshop on Automatic Speech Recogni-
tion and Understanding (ASRU2001).
R. San-Segundo, J.M. Montero, J.M. Gutierrez, A. Gal-
lardo, J.D. Romeral, and J.M. Pardo. 2001. A
telephone-based railway information system for span-
ish: Development of a methodology for spoken dia-
logue design. In Proceedings of SIGdial-2001, pages
140–148.
Nestor Becerra Yoma, Angela Cortes, Mauricio Hormaz-
abal, and Enrique Lopez. 2002. Wizard of oz evalua-
tion of a dialogue with communicator system in chile.
In Proceedings ofICSLP-2002, pages 2701–2704.
Steve Young. 2002. Talking to machines (statistically
speaking). In Proceedings of ICSLP-2002, pages 9–
16.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.130040">
<title confidence="0.862518">Example-based Spoken Dialogue System using WOZ System Log</title>
<affiliation confidence="0.788903">MURAO KAWAGUCHI MATSUBARA Systems Development Center,SANYO Electric Co.,</affiliation>
<address confidence="0.988845">Hirakata-shi, Osaka, 573-8534</address>
<affiliation confidence="0.426152">for Integrated Acoustic Information Research,Nagoya</affiliation>
<address confidence="0.8529965">Technology Center, Nagoya Furo-cho, Chikusa-ku, Nagoya-shi, 464-8603</address>
<affiliation confidence="0.865661">Faculty of Information Science and Technology, Aichi Prefectural</affiliation>
<address confidence="0.92044">Nagakute-cho, Aichi-gun, Aichi, 480-1198,</address>
<email confidence="0.98156">murao@hr.hm.rd.sanyo.co.jp</email>
<abstract confidence="0.99836275">This paper proposes a new framework for a spoken dialogue system based on dialogue examples between human subjects and the Wizard of OZ (WOZ) system. Using this framework and a model of information retrieval dialogue, a spoken dialogue system for retrieving shop information while driving in a car has been designed. The system refers to the dialogue examples to find an example that is suitable for generating a query or a reply. The authors have also constructed a large-scale dialogue database using a WOZ system, which enables efficient collection of dialogue examples.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Masayuki Asahara</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Extended models and tools for high-performance part-of-speech tagger.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING</booktitle>
<contexts>
<context position="17749" citStr="Asahara and Matsumoto, 2000" startWordPosition="2841" endWordPosition="2844"> (WCDB): Consists of words essential to the task in question and classes given to them according to meaning. Word classes are determined empirically based on dialogue within the dialogue corpus. Shop Information Database (SIDB): Consists of a collection of information on about 800 restaurants and shops in Nagoya, the same as that used in the WOZ system. Speech Recognition: Uses “Japanese Dictation Toolkit(Kawahara et al., 2000)”. The language model was created from the previously collected human-to-human dialogue corpus. 3Using ChaSen morphological-analysis software for the Japanese language (Asahara and Matsumoto, 2000). Speech Input Speech Output Speech Recognition Speech Synthesis Dialogue Example Database (DEDB) Query Generation Reply Generation Word class Database (WCDB) Shop Information Database (SIDB) Search Step1: Extracting similar example for query Input: Etto, spaghetti no omise ni ikitai na. (I&apos;d like to go to a spaghetti restaurant.) Similar cases Keywords: [10: spaghetti],[omise (shop)],[iku (go)] 1st: U: &lt;10:Curry&gt; no [omise] ni [iki]tain desu kedo (I&apos;d like to go to a curry restaurant. ) Q: search KEY=&lt;10:curry&gt; 2nd: U: &lt;10: Ramen(noodles)&gt; wo &lt;tabe&gt; ni [iki] taina (I&apos;d like to eat noodles.) Q</context>
</contexts>
<marker>Asahara, Matsumoto, 2000</marker>
<rawString>Masayuki Asahara and Yuji Matsumoto. 2000. Extended models and tools for high-performance part-of-speech tagger. In Proceedings of COLING 2000, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bertenstam</author>
<author>M Blomberg</author>
<author>R Carlson</author>
<author>K Elenius</author>
<author>B Granstrom</author>
<author>J Gustafson</author>
<author>S Hunnicutt</author>
<author>J Hogberg</author>
<author>R Lindell</author>
<author>L Neovius</author>
<author>A de Serpa-Leitao</author>
<author>L Nord</author>
<author>N Strom</author>
</authors>
<title>The waxholm application database.</title>
<date>1995</date>
<booktitle>In Proceedings of Eurospeech-95,</booktitle>
<volume>1</volume>
<pages>833--836</pages>
<marker>Bertenstam, Blomberg, Carlson, Elenius, Granstrom, Gustafson, Hunnicutt, Hogberg, Lindell, Neovius, de Serpa-Leitao, Nord, Strom, 1995</marker>
<rawString>J. Bertenstam, M. Blomberg, R. Carlson, K. Elenius, B. Granstrom, J. Gustafson, S. Hunnicutt, J. Hogberg, R. Lindell, L. Neovius, A. de Serpa-Leitao, L. Nord, and N. Strom. 1995. The waxholm application database. In Proceedings of Eurospeech-95, volume 1, pages 833–836.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maxine Eskenazi</author>
<author>Alexander Rudnicky</author>
<author>Karin Gregory</author>
<author>Paul Constantinides Robert Brennan</author>
<author>Christina Bennett</author>
<author>Jwan Allen</author>
</authors>
<title>Data collection and processing in the carnegie mellon communicator.</title>
<date>1999</date>
<booktitle>In Proceedings of Eurospeech-99,</booktitle>
<volume>6</volume>
<pages>2695--2698</pages>
<contexts>
<context position="8510" citStr="Eskenazi et al., 1999" startWordPosition="1345" endWordPosition="1348">tem When carrying on a dialogue using the WOZ system, the user feels that he or she is talking to a completely mechanical system despite the fact that a human being is actually being used for some of the elements making up the dialogue system. Collecting dialogue data by WOZ should therefore result in Figure 2: Configuration of Wizard of OZ system data that is closer to dialogue that would occur between a human and a machine. Collecting spoken dialogue data using the WOZ system has actually been performed a number of times in the past (MADCOW, 1992; Bertenstam et al., 1995; Life et al., 1996; Eskenazi et al., 1999; San-Segundo et al., 2001; Lemmela and Boda, 2002; Yoma et al., 2002). The objective of those studies, however, was to collect, analyze, and evaluate dialogue data between people and artificial objects, and in many cases, only one of the artificial-object’s functions was taken over by a human, for example, the speech recognition function. Our study, however, goes further than the above. In particular, we create special software (called WOZ software) that allows a human being to perform the functions of interpreting user speech, generating queries and executing searches, and generating replies</context>
</contexts>
<marker>Eskenazi, Rudnicky, Gregory, Brennan, Bennett, Allen, 1999</marker>
<rawString>Maxine Eskenazi, Alexander Rudnicky, Karin Gregory, Paul Constantinides Robert Brennan, Christina Bennett, and Jwan Allen. 1999. Data collection and processing in the carnegie mellon communicator. In Proceedings of Eurospeech-99, volume 6, pages 2695– 2698.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nobuo Kawaguchi</author>
<author>Shigeki Matsubara</author>
<author>Kazuya Takeda</author>
<author>Fumitada Itakura</author>
</authors>
<title>Multi-dimensional data acquisition for integrated acoustic information research.</title>
<date>2002</date>
<booktitle>In Proc. of 3rd International Language Resources and Evaluation Conference (LREC-2002),</booktitle>
<pages>2043--2046</pages>
<contexts>
<context position="13412" citStr="Kawaguchi et al., 2002" startWordPosition="2137" endWordPosition="2140">synthesis section of the system. Switching back and forth between the query and reply parts can be performed as needed using a switch button. The reply part also includes buttons for instantly generating words and short phrases of confirmation and encouragement (e.g., ”yes,” ”I see”) while the user is speaking to create as natural a dialogue as possible. 3.3 Collecting dialogue data by the WOZ system We targeted shop-information retrieval while driving a car as an information-retrieval application based on spoken dialogue, and collected dialogue data between the WOZ system and human subjects (Kawaguchi et al., 2002). This data was collected within an automobile driven by subjects each of whom acted as a user searching for information. A personal computer running the WOZ software was placed in the automobile with the ”wizard” sitting in the back seat. All spoken dialogue was recorded using another personal computer. Data collection was performed according to the following procedure for a duration of about five minTable 1: Collected WOZ data Number of Speech length Speech Units sessions (min.) User WOZ User WOZ 487 499 791 13,828 12,487 utes per subject. • A prompting panel such as shown in Fig. 5 is prese</context>
</contexts>
<marker>Kawaguchi, Matsubara, Takeda, Itakura, 2002</marker>
<rawString>Nobuo Kawaguchi, Shigeki Matsubara, Kazuya Takeda, and Fumitada Itakura. 2002. Multi-dimensional data acquisition for integrated acoustic information research. In Proc. of 3rd International Language Resources and Evaluation Conference (LREC-2002), pages 2043–2046.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kawahara</author>
<author>A Lee</author>
<author>T Kobayashi</author>
<author>K Takeda</author>
<author>N Minematsu</author>
<author>S Sagayama</author>
<author>K Itou</author>
<author>A Ito</author>
<author>M Yamamoto</author>
<author>A Yamada</author>
<author>T Utsuro</author>
<author>K Shikano</author>
</authors>
<title>Free software toolkit for japanese large vocabulary continuous speech recognition.</title>
<date>2000</date>
<booktitle>In Proceedings of ICSLP2000,</booktitle>
<volume>4</volume>
<pages>476--479</pages>
<contexts>
<context position="17552" citStr="Kawahara et al., 2000" startWordPosition="2816" endWordPosition="2819">l to advancing the dialogue (e.g., shop name, facility name, food name) are assigned word class tags based on classes given to these words beforehand according to meaning. Word Class Database (WCDB): Consists of words essential to the task in question and classes given to them according to meaning. Word classes are determined empirically based on dialogue within the dialogue corpus. Shop Information Database (SIDB): Consists of a collection of information on about 800 restaurants and shops in Nagoya, the same as that used in the WOZ system. Speech Recognition: Uses “Japanese Dictation Toolkit(Kawahara et al., 2000)”. The language model was created from the previously collected human-to-human dialogue corpus. 3Using ChaSen morphological-analysis software for the Japanese language (Asahara and Matsumoto, 2000). Speech Input Speech Output Speech Recognition Speech Synthesis Dialogue Example Database (DEDB) Query Generation Reply Generation Word class Database (WCDB) Shop Information Database (SIDB) Search Step1: Extracting similar example for query Input: Etto, spaghetti no omise ni ikitai na. (I&apos;d like to go to a spaghetti restaurant.) Similar cases Keywords: [10: spaghetti],[omise (shop)],[iku (go)] 1st:</context>
</contexts>
<marker>Kawahara, Lee, Kobayashi, Takeda, Minematsu, Sagayama, Itou, Ito, Yamamoto, Yamada, Utsuro, Shikano, 2000</marker>
<rawString>T. Kawahara, A. Lee, T. Kobayashi, K. Takeda, N. Minematsu, S. Sagayama, K. Itou, A. Ito, M. Yamamoto, A. Yamada, T. Utsuro, and K. Shikano. 2000. Free software toolkit for japanese large vocabulary continuous speech recognition. In Proceedings of ICSLP2000, volume 4, pages 476–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saija-Maaria Lemmela</author>
<author>Peter Pal Boda</author>
</authors>
<title>Efficient combination of type-in and wizard-of-oz tests in speech interface development process.</title>
<date>2002</date>
<booktitle>In Proceedings ofICSLP-2002,</booktitle>
<pages>1477--1480</pages>
<contexts>
<context position="8560" citStr="Lemmela and Boda, 2002" startWordPosition="1353" endWordPosition="1356">tem, the user feels that he or she is talking to a completely mechanical system despite the fact that a human being is actually being used for some of the elements making up the dialogue system. Collecting dialogue data by WOZ should therefore result in Figure 2: Configuration of Wizard of OZ system data that is closer to dialogue that would occur between a human and a machine. Collecting spoken dialogue data using the WOZ system has actually been performed a number of times in the past (MADCOW, 1992; Bertenstam et al., 1995; Life et al., 1996; Eskenazi et al., 1999; San-Segundo et al., 2001; Lemmela and Boda, 2002; Yoma et al., 2002). The objective of those studies, however, was to collect, analyze, and evaluate dialogue data between people and artificial objects, and in many cases, only one of the artificial-object’s functions was taken over by a human, for example, the speech recognition function. Our study, however, goes further than the above. In particular, we create special software (called WOZ software) that allows a human being to perform the functions of interpreting user speech, generating queries and executing searches, and generating replies. We then propose a framework that enables the ope</context>
</contexts>
<marker>Lemmela, Boda, 2002</marker>
<rawString>Saija-Maaria Lemmela and Peter Pal Boda. 2002. Efficient combination of type-in and wizard-of-oz tests in speech interface development process. In Proceedings ofICSLP-2002, pages 1477–1480.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Esther Levin</author>
<author>Roberto Pieraccini</author>
<author>Wieland Eckert</author>
</authors>
<title>Using markov decision processes for learning dialogue strategies.</title>
<date>1998</date>
<booktitle>In Proceedings ofICASSP98,</booktitle>
<volume>1</volume>
<pages>201--204</pages>
<contexts>
<context position="1400" citStr="Levin et al., 1998" startWordPosition="200" endWordPosition="203">of information retrieval dialogue, a spoken dialogue system for retrieving shop information while driving in a car has been designed. The system refers to the dialogue examples to find an example that is suitable for generating a query or a reply. The authors have also constructed a large-scale dialogue database using a WOZ system, which enables efficient collection of dialogue examples. 1 Introduction Against the background of ever-increasing computing power, techniques for constructing spoken dialogue systems using large-scale speech and text corpora have become the target of much research (Levin et al., 1998; Young, 2002). In prior research, the authors have proposed a spoken-dialogue control technique using dialogue examples with the aim of performing flexible dialogue control during information-retrieval dialogue and of achieving speech understanding robust against speech recognition errors (Murao et al., 2001). This technique uses input speech data and supplementary information corresponding to input speech such as retrieval formulas (queries) to form ”examples” that decide system action. A system using this technique cannot run effectively, however, without a large volume of example data. Tra</context>
</contexts>
<marker>Levin, Pieraccini, Eckert, 1998</marker>
<rawString>Esther Levin, Roberto Pieraccini, and Wieland Eckert. 1998. Using markov decision processes for learning dialogue strategies. In Proceedings ofICASSP98, volume 1, pages 201–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Life</author>
<author>I Salter</author>
<author>J N Temem</author>
<author>F Bernard</author>
<author>S Rosset</author>
<author>S Bennacef</author>
<author>L Lamel</author>
</authors>
<title>Data collection for the mask kiosk: Woz vs prototype system.</title>
<date>1996</date>
<booktitle>In Proceedings ofICSLP-96,</booktitle>
<pages>1672--1675</pages>
<contexts>
<context position="8487" citStr="Life et al., 1996" startWordPosition="1341" endWordPosition="1344">h data. 3.1 WOZ system When carrying on a dialogue using the WOZ system, the user feels that he or she is talking to a completely mechanical system despite the fact that a human being is actually being used for some of the elements making up the dialogue system. Collecting dialogue data by WOZ should therefore result in Figure 2: Configuration of Wizard of OZ system data that is closer to dialogue that would occur between a human and a machine. Collecting spoken dialogue data using the WOZ system has actually been performed a number of times in the past (MADCOW, 1992; Bertenstam et al., 1995; Life et al., 1996; Eskenazi et al., 1999; San-Segundo et al., 2001; Lemmela and Boda, 2002; Yoma et al., 2002). The objective of those studies, however, was to collect, analyze, and evaluate dialogue data between people and artificial objects, and in many cases, only one of the artificial-object’s functions was taken over by a human, for example, the speech recognition function. Our study, however, goes further than the above. In particular, we create special software (called WOZ software) that allows a human being to perform the functions of interpreting user speech, generating queries and executing searches,</context>
</contexts>
<marker>Life, Salter, Temem, Bernard, Rosset, Bennacef, Lamel, 1996</marker>
<rawString>A. Life, I. Salter, J.N. Temem, F. Bernard, S. Rosset, S. Bennacef, and L. Lamel. 1996. Data collection for the mask kiosk: Woz vs prototype system. In Proceedings ofICSLP-96, pages 1672–1675.</rawString>
</citation>
<citation valid="true">
<authors>
<author>MADCOW</author>
</authors>
<title>Multi-site data collection for a spoken language corpus.</title>
<date>1992</date>
<booktitle>In DARPA Speech and Natural Language Workshop ’92.</booktitle>
<contexts>
<context position="8443" citStr="MADCOW, 1992" startWordPosition="1335" endWordPosition="1336">example database while collecting speech data. 3.1 WOZ system When carrying on a dialogue using the WOZ system, the user feels that he or she is talking to a completely mechanical system despite the fact that a human being is actually being used for some of the elements making up the dialogue system. Collecting dialogue data by WOZ should therefore result in Figure 2: Configuration of Wizard of OZ system data that is closer to dialogue that would occur between a human and a machine. Collecting spoken dialogue data using the WOZ system has actually been performed a number of times in the past (MADCOW, 1992; Bertenstam et al., 1995; Life et al., 1996; Eskenazi et al., 1999; San-Segundo et al., 2001; Lemmela and Boda, 2002; Yoma et al., 2002). The objective of those studies, however, was to collect, analyze, and evaluate dialogue data between people and artificial objects, and in many cases, only one of the artificial-object’s functions was taken over by a human, for example, the speech recognition function. Our study, however, goes further than the above. In particular, we create special software (called WOZ software) that allows a human being to perform the functions of interpreting user speech</context>
</contexts>
<marker>MADCOW, 1992</marker>
<rawString>MADCOW. 1992. Multi-site data collection for a spoken language corpus. In DARPA Speech and Natural Language Workshop ’92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Murao</author>
<author>Nobuo Kawaguchi</author>
<author>Shigeki Matsubara</author>
<author>Yasuyoshi Inagaki</author>
</authors>
<title>Example-based query generation for spontaneous speech.</title>
<date>2001</date>
<booktitle>In Proceedings of 2001 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU2001).</booktitle>
<contexts>
<context position="1711" citStr="Murao et al., 2001" startWordPosition="244" endWordPosition="247">ase using a WOZ system, which enables efficient collection of dialogue examples. 1 Introduction Against the background of ever-increasing computing power, techniques for constructing spoken dialogue systems using large-scale speech and text corpora have become the target of much research (Levin et al., 1998; Young, 2002). In prior research, the authors have proposed a spoken-dialogue control technique using dialogue examples with the aim of performing flexible dialogue control during information-retrieval dialogue and of achieving speech understanding robust against speech recognition errors (Murao et al., 2001). This technique uses input speech data and supplementary information corresponding to input speech such as retrieval formulas (queries) to form ”examples” that decide system action. A system using this technique cannot run effectively, however, without a large volume of example data. Traditionally, though, collecting human-to-human dialogue data and manually providing such supplementary information for each instance of input speech has required considerable labor. In this paper, we address this problem and propose a new technique for constructing an examplebased dialogue system using, as exam</context>
<context position="16399" citStr="Murao et al., 2001" startWordPosition="2632" endWordPosition="2636">y WOZ software, a correspondence is established between user speech and queries and between search results and replies. We constructed an example database using a portion of dialogue data collected in the above manner. Table 2 summarizes the data used for this purpose. Query and search-result correspondences were established for about 20% of all user speech excluding speech outside of the task in question and speech outside of query specifications. 4 Spoken Dialogue System using Dialogue Examples We here describe a dialogue system that runs using the example database that we constructed (see (Murao et al., 2001) for details). The task is to search for shop information while inside an automobile. This system was implemented using the C++ language under Windows2000. Figure 6 shows a screen shot of this example-based dialogue system. 4.1 System configuration The following describes the components of this system with reference to Fig. 7. Dialogue example database (DEDB): Consists of data constructed from dialogue text and log information output from WOZ software. Dialogue text is subjected to morphological analysis 3, and words essential to advancing the dialogue (e.g., shop name, facility name, food nam</context>
</contexts>
<marker>Murao, Kawaguchi, Matsubara, Inagaki, 2001</marker>
<rawString>Hiroya Murao, Nobuo Kawaguchi, Shigeki Matsubara, and Yasuyoshi Inagaki. 2001. Example-based query generation for spontaneous speech. In Proceedings of 2001 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R San-Segundo</author>
<author>J M Montero</author>
<author>J M Gutierrez</author>
<author>A Gallardo</author>
<author>J D Romeral</author>
<author>J M Pardo</author>
</authors>
<title>A telephone-based railway information system for spanish: Development of a methodology for spoken dialogue design.</title>
<date>2001</date>
<booktitle>In Proceedings of SIGdial-2001,</booktitle>
<pages>140--148</pages>
<contexts>
<context position="8536" citStr="San-Segundo et al., 2001" startWordPosition="1349" endWordPosition="1352">dialogue using the WOZ system, the user feels that he or she is talking to a completely mechanical system despite the fact that a human being is actually being used for some of the elements making up the dialogue system. Collecting dialogue data by WOZ should therefore result in Figure 2: Configuration of Wizard of OZ system data that is closer to dialogue that would occur between a human and a machine. Collecting spoken dialogue data using the WOZ system has actually been performed a number of times in the past (MADCOW, 1992; Bertenstam et al., 1995; Life et al., 1996; Eskenazi et al., 1999; San-Segundo et al., 2001; Lemmela and Boda, 2002; Yoma et al., 2002). The objective of those studies, however, was to collect, analyze, and evaluate dialogue data between people and artificial objects, and in many cases, only one of the artificial-object’s functions was taken over by a human, for example, the speech recognition function. Our study, however, goes further than the above. In particular, we create special software (called WOZ software) that allows a human being to perform the functions of interpreting user speech, generating queries and executing searches, and generating replies. We then propose a framew</context>
</contexts>
<marker>San-Segundo, Montero, Gutierrez, Gallardo, Romeral, Pardo, 2001</marker>
<rawString>R. San-Segundo, J.M. Montero, J.M. Gutierrez, A. Gallardo, J.D. Romeral, and J.M. Pardo. 2001. A telephone-based railway information system for spanish: Development of a methodology for spoken dialogue design. In Proceedings of SIGdial-2001, pages 140–148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nestor Becerra Yoma</author>
<author>Angela Cortes</author>
<author>Mauricio Hormazabal</author>
<author>Enrique Lopez</author>
</authors>
<title>Wizard of oz evaluation of a dialogue with communicator system in chile.</title>
<date>2002</date>
<booktitle>In Proceedings ofICSLP-2002,</booktitle>
<pages>2701--2704</pages>
<contexts>
<context position="8580" citStr="Yoma et al., 2002" startWordPosition="1357" endWordPosition="1360"> he or she is talking to a completely mechanical system despite the fact that a human being is actually being used for some of the elements making up the dialogue system. Collecting dialogue data by WOZ should therefore result in Figure 2: Configuration of Wizard of OZ system data that is closer to dialogue that would occur between a human and a machine. Collecting spoken dialogue data using the WOZ system has actually been performed a number of times in the past (MADCOW, 1992; Bertenstam et al., 1995; Life et al., 1996; Eskenazi et al., 1999; San-Segundo et al., 2001; Lemmela and Boda, 2002; Yoma et al., 2002). The objective of those studies, however, was to collect, analyze, and evaluate dialogue data between people and artificial objects, and in many cases, only one of the artificial-object’s functions was taken over by a human, for example, the speech recognition function. Our study, however, goes further than the above. In particular, we create special software (called WOZ software) that allows a human being to perform the functions of interpreting user speech, generating queries and executing searches, and generating replies. We then propose a framework that enables the operator (wizard) to ca</context>
</contexts>
<marker>Yoma, Cortes, Hormazabal, Lopez, 2002</marker>
<rawString>Nestor Becerra Yoma, Angela Cortes, Mauricio Hormazabal, and Enrique Lopez. 2002. Wizard of oz evaluation of a dialogue with communicator system in chile. In Proceedings ofICSLP-2002, pages 2701–2704.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Young</author>
</authors>
<title>Talking to machines (statistically speaking).</title>
<date>2002</date>
<booktitle>In Proceedings of ICSLP-2002,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="1414" citStr="Young, 2002" startWordPosition="204" endWordPosition="205">eval dialogue, a spoken dialogue system for retrieving shop information while driving in a car has been designed. The system refers to the dialogue examples to find an example that is suitable for generating a query or a reply. The authors have also constructed a large-scale dialogue database using a WOZ system, which enables efficient collection of dialogue examples. 1 Introduction Against the background of ever-increasing computing power, techniques for constructing spoken dialogue systems using large-scale speech and text corpora have become the target of much research (Levin et al., 1998; Young, 2002). In prior research, the authors have proposed a spoken-dialogue control technique using dialogue examples with the aim of performing flexible dialogue control during information-retrieval dialogue and of achieving speech understanding robust against speech recognition errors (Murao et al., 2001). This technique uses input speech data and supplementary information corresponding to input speech such as retrieval formulas (queries) to form ”examples” that decide system action. A system using this technique cannot run effectively, however, without a large volume of example data. Traditionally, th</context>
</contexts>
<marker>Young, 2002</marker>
<rawString>Steve Young. 2002. Talking to machines (statistically speaking). In Proceedings of ICSLP-2002, pages 9– 16.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>