<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000177">
<title confidence="0.995161">
Using Part-of-Speech Reranking to Improve Chinese Word Segmentation
</title>
<author confidence="0.993278">
Mengqiu Wang Yanxin Shi
</author>
<affiliation confidence="0.906415">
Language Technologies Institute
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 15213, USA
</affiliation>
<email confidence="0.999525">
{mengqiu,yanxins}@cs.cmu.edu
</email>
<sectionHeader confidence="0.993922" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999722944444445">
Chinese word segmentation and Part-of-
Speech (POS) tagging have been com-
monly considered as two separated tasks.
In this paper, we present a system that
performs Chinese word segmentation and
POS tagging simultaneously. We train a
segmenter and a tagger model separately
based on linear-chain Conditional Ran-
dom Fields (CRF), using lexical, morpho-
logical and semantic features. We propose
an approximated joint decoding method
by reranking the N-best segmenter out-
put, based POS tagging information. Ex-
perimental results on SIGHAN Bakeoff
dataset and Penn Chinese Treebank show
that our reranking method significantly
improve both segmentation and POS tag-
ging accuracies.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999414181818182">
Word segmentation and Part-of-speeching (POS)
tagging are the most fundamental tasks in Chinese
natural language processing (NLP). Traditionally,
these two tasks were treated as separate and in-
dependent processing steps chained together in a
pipeline. In such pipeline systems, errors intro-
duced at the early stage cannot be easily recov-
ered in later steps, causing a cascade of errors
and eventually harm overall performance. Intu-
itively, a correct segmentation of the input sen-
tence is more likely to give rise to a correct POS
tagging sequence than an incorrect segmentation.
Hinging on this idea, one way to avoid error prop-
agation in chaining subtasks such as segmentation
and POS tagging is to exploit the learning trans-
fer (Sutton and McCallum, 2005) among sub-
tasks, typically through joint inference. Sutton et
al. (2004) presented dynamic conditional random
fields (DCRF), a generalization of the traditional
linear-chain CRF that allow representation of in-
teraction among labels. They used loopy belief
propagation for inference approximation. Their
empirical results on the joint task of POS tagging
and NP-chunking suggested that DCRF gave supe-
rior performance over cascaded linear-chain CRF.
Ng and Low (2004) and Luo (2003) also trained
single joint models over the Chinese segmentation
and POS tagging subtasks. In their work, they
brought the two subtasks together by treating it as
a single tagging problem, for which they trained a
maximum entropy classifier to assign a combined
word boundary and POS tag to each character.
A major challenge, however, exists in doing
joint inference for complex and large-scale NLP
application. Sutton and McCallum (Sutton and
McCallum, 2005) suggested that in many cases ex-
act inference can be too expensive and thus formi-
dable. They presented an alternative approach in
which a linear-chain CRF is trained separately for
each subtask at training time, but at decoding time
they combined the learned weights from the CRF
cascade into a single grid-shaped factorial CRF
to perform joint decoding and make predictions
for all subtasks. Similar to (Sutton and McCal-
lum, 2005), in our system we also train a cas-
cade of linear-chain CRF for the subtasks. But
at decoding time, we experiment with an alterna-
tive approximation method to joint decoding, by
taking the n-best hypotheses from the segmenta-
tion model and use the POS tagging model for
reranking. We evaluated our system on the open
tracks of SIGHAN Bakeoff 2006 dataset. Fur-
thermore, to evaluate our reranking method’s im-
pact on the POS tagging task, we also performed
10-fold cross-validation tests on the 250k Penn
</bodyText>
<page confidence="0.980386">
205
</page>
<bodyText confidence="0.9639794">
Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 205–208,
Sydney, July 2006. c�2006 Association for Computational Linguistics
Chinese Treebank (CTB) (Xue et al., 2002). Re-
sults from both evaluations suggest that our simple
reranking method is very effective. We achieved
a consistent performance gain on both segmenta-
tion and POS tagging tasks over linearly-cascaded
CRF. Our official F-scores on the 2006 Bakeoff
open tracks are 0.935 (UPUC), 0.964 (CityU),
0.952 (MSRA) and 0.949 (CKIP).
</bodyText>
<sectionHeader confidence="0.985909" genericHeader="introduction">
2 Algorithm
</sectionHeader>
<bodyText confidence="0.999948333333333">
Given an observed Chinese character sequence
X = {C1, C2,..., Cn}, let S and T denote a seg-
mentation sequence and a POS tagging sequence
over X. Our goal is to find a segmentation se-
quence S and a POS tagging sequence T� that max-
imize the posterior probability :
</bodyText>
<equation confidence="0.911062">
P(S, T|X = {C1, C2,..., Cn}) (1)
</equation>
<bodyText confidence="0.999609">
Applying chain rule, we can further derive from
Equation 1 the following:
</bodyText>
<subsectionHeader confidence="0.789312">
&lt;�S, T�&gt;
</subsectionHeader>
<bodyText confidence="0.999975">
Since we have factorized the joint probability
in Equation 1 into two terms, we can now model
these two components using conditional random
fields (Lafferty et al., 2001). Linear-chain CRF
models define conditional probability, P(Z|X), by
linear-chain Markov random fields. In our case, X
is the sequence of characters or words, and Z is
the segmentation labels for characters (START or
NON-START, used to indicate word boundaries)
or the POS tagging for words (NN, VV, JJ, etc.).
The conditional probability is defined as:
</bodyText>
<equation confidence="0.88286475">
T K
P(Z|X) = N(X) exp (1: 1: Akfk(Z, X, t))
t�1 k�1
(3)
</equation>
<bodyText confidence="0.999667142857143">
where N(X) is a normalization term to guaran-
tee that the summation of the probability of all
label sequences is one. fk(Z, X, t) is the kth
localfeaturefunction at sequence position t. It
maps a pair of X and Z and an index t to {0,1}.
(A1, ..., AK) is a weight vector to be learned from
training set. A large positive value of Ai means
that the ith feature function’s value is frequent to
be 1, whereas a negative value of Ai means the ith
feature function’s value is unlikely to be 1.
At decoding time, we are interested in finding
the segmentation sequence S and POS tagging se-
quence T� that maximizes the probability defined
in Equation 2. Instead of exhaustively searching
the whole space of all possible segmentations, we
restrict our searching to S = {S1, S2, ..., SN},
where S is the restricted search space consisting
of N-best decoded segmentation sequences. This
N-best list of segmentation sequences, S, can be
obtained using modified Viterbi algorithm and A*
search (Schwartz and Chow, 1990).
</bodyText>
<sectionHeader confidence="0.999842" genericHeader="method">
3 Features
</sectionHeader>
<subsectionHeader confidence="0.989459">
3.1 Features for Segmentation
</subsectionHeader>
<bodyText confidence="0.99948525">
We adopted the basic segmentation features used
in (Ng and Low, 2004). These features are summa-
rized in Table 1 ((1.1)-(1.7)). In these templates,
C0 refers to the current character, and C−n, Cn re-
fer to the characters n positions to the left and right
of the current character, respectively. Pu(C0) in-
dicates whether C0 is a punctuation. T(Cn) clas-
sifies the character Cn into four classes: num-
bers, dates (year, month, date), English letters and
all other characters. LBegin(C0), LEnd(C0) and
LMid(C0) represent the maximum length of words
found in a lexicon1 that contain the current char-
acter as either the first, last or middle character, re-
spectively. Single(C0) indicates whether the cur-
rent character can be found as a single word in the
lexicon.
Besides the adopted basic features mentioned
above, we also experimented with additional se-
mantic features (Table 1 (1.8)). For (1.8), Sem0
refers to the semantic class of current character,
and Sem−1, Sem1 represent the semantic class
of characters one position to the left and right of
the current character, respectively. We obtained
a character’s semantic class from HowNet (Dong
and Dong, 2006). Since many characters have
multiple semantic classes defined by HowNet, it
is a non-trivial task to choose among the differ-
ent semantic classes. We performed contextual
disambiguation of characters’ semantic classes by
calculating semantic class similarities. For ex-
ample, let us assume the current character is
8(look,read) in a word context of 8TR(read
</bodyText>
<footnote confidence="0.9948925">
1We compiled our lexicon from three external re-
sources. HowNet: www.keenage.com; On-Line Chinese
Tools: www.mandarintools.com; Online Dictionary from
Peking University: http://ccl.pku.edu.cn/doubtfire/Course/
Chinese%20Information%20Processing/Source Code/
Chapter 8/Lexicon full 2000.zip
</footnote>
<equation confidence="0.423131666666667">
= arg max P(T|S, X = {C1, C2,..., Cn})
S,T
×P(S|X = {C1, C2, ..., Cn}) (2)
</equation>
<page confidence="0.993173">
206
</page>
<bodyText confidence="0.957615619047619">
newspaper). The character *(look) has two se-
mantic classes in HowNet, i.e. Ö(read) and N
M(doctor). To determine which class is more
appropriate, we check the example words illus-
trating the meanings of the two semantic classes,
given by HowNet. For 1(read), the exam-
ple word is *- 5(read book); for NM(doctor),
the example word is * ftsee a doctor). We
then calculated the semantic class similarity
scores between ç(newspaper) and - 5(book), and
ç(newspaper) and tillness), using HowNet’s
built-in similarity measure function. Since
ç(newspaper) and - 5(book) both have seman-
tic class 3Z- 5(document), their maximum simi-
larity score is 0.95, where the maximum similar-
ity score between ç(newspaper) and &gt;(illness)
is 0.03478. Therefore, Sem0Sem1 =1(read),3t
- 5(document). Similarly, we can figure out
Sem−1Sem0. For Sem0, we simply picked the
top four semantic classes ranked by HowNet, and
used ”‘NONE”’ for absent values.
</bodyText>
<equation confidence="0.8444960625">
Segmentation features
(1.1) Cn, n ∈ [−2, 2]
(1.2) CnCn+1, n ∈ [−2, 1]
(1.3) C_1C1
(1.4) Pu(C0)
(1.5) T (C_2)T (C_1)T (C0)T (C1)T (C2)
(1.6) LBe,in(C0), LEnd(C0)
(1.7) Single(C0)
(1.8) Sem0, SemnSemn+1, n ∈ −1, 0
POS tagging features
(2.1) Wn, n ∈ [−2, 2]
(2.2) WnWn+1, n ∈ [−2, 1]
(2.3) W_1W1
(2.4) Wn_1WnWn+1, n ∈ [−1, 1]
(2.5) Cn(W0), n ∈ [−2, 2]
(2.6) Len(W0)
</equation>
<bodyText confidence="0.281937">
(2.7) Other morphological features
</bodyText>
<tableCaption confidence="0.992525">
Table 1: Feature templates list
</tableCaption>
<subsectionHeader confidence="0.861445">
3.2 Features for POS Tagging
</subsectionHeader>
<bodyText confidence="0.999973769230769">
The bottom half of Table 1 summarizes the feature
templates we employed for POS tagging. W0 de-
notes the current word. W−n and Wn refer to the
words n positions to the left and right of the cur-
rent word, respectively. Cn(W0) is the nth char-
acter in current word. If the number of characters
in the word is less than 5, we use ”NONE” for ab-
sent characters. Len(W0) is the number of char-
acters in the current word. We also used a group
of binary features for each word, which are used to
represent the morphological properties of current
word, e.g. whether the current word is punctua-
tion, number, foreign name, etc.
</bodyText>
<sectionHeader confidence="0.996767" genericHeader="evaluation">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.999980416666666">
We evaluated our system’s segmentation results on
the SIGHAN Bakeoff 2006 dataset. To evaluate
our reranking method’s impact on the POS tagging
part, we also performed 10-fold cross-validation
tests on the 250k Penn Chinese Treebank (CTB
250k). The CRF model for POS tagging is trained
on CTB 250k in all the experiments. We report re-
call (R), precision (P), and F1-score (F) for both
word segmentation and POS tagging tasks. N
value is chosen to be 20 for the N-best list rerank-
ing, based on cross validation. For CRF learning
and decoding, we use the CRF++ toolkit2.
</bodyText>
<subsectionHeader confidence="0.645987">
4.1 Results on Bakeoff 2006 Dataset
</subsectionHeader>
<table confidence="0.9999362">
R P F RooV RiV
UPUC 0.942 0.928 0.935 0.711 0.964
CityU 0.964 0.964 0.964 0.787 0.971
MSRA 0.949 0.954 0.952 0.692 0.958
CKIP 0.953 0.946 0.949 0.679 0.965
</table>
<tableCaption confidence="0.8127905">
Table 2: Performance of our system on open tracks
of SIGHAN Bakeoff 2006.
</tableCaption>
<bodyText confidence="0.833143347826087">
We participated in the open tracks of the
SIGHAN Bakeoff 2006, and we achieved F-scores
of 0.935 (UPUC), 0.964 (CityU), 0.952 (MSRA)
and 0.949 (CKIP). More detailed performances
statistics including in-vocabulary recall (RiV) and
out-of-vocabulary recall (RooV) are shown in Table
More interesting to us is how much the N-best
list reranking method using POS tagging helped
to increase segmentation performance. For com-
parison, we ran a linear-cascade of segmentation
and POS tagging CRFs without reranking as the
baseline system, and the results are shown in Table
3. We can see that our reranking method consis-
tently improved segmentation scores. In particu-
lar, there is a greater improvement gained in recall
than precision across all four tracks. We observed
the greatest improvement from the UPUC track.
We think it is because our POS tagging model is
trained on CTB 250k, which could be drawn from
the same corpus as the UPUC training data, and
therefore there is a closer mapping between seg-
mentation standard of the POS tagging training
data and the segmentation training data (at this
</bodyText>
<footnote confidence="0.995591">
2http://chasen.org/ taku/software/CRF++/
</footnote>
<page confidence="0.994885">
207
</page>
<figure confidence="0.9409242">
5 Conclusion
CTB Segmentation Results
10 cross−fold validation test
CTB POS Tagging Results
10 cross−fold validation test
</figure>
<figureCaption confidence="0.7622265">
Figure 1: Segmentation and POS tagging results
on CTB corpus.
point we are not sure if there exists any overlap
between the UPUC test data and CTB 250k).
</figureCaption>
<table confidence="0.999908666666667">
Baseline system Final system
R P F R P F
UPUC 0.910 0.924 0.917 0.942 0.928 0.935
CityU 0.954 0.963 0.958 0.964 0.964 0.964
MSRA 0.935 0.953 0.944 0.949 0.954 0.952
CKIP 0.932 0.942 0.937 0.953 0.946 0.949
</table>
<tableCaption confidence="0.9652175">
Table 3: Comparison of the baseline system (with-
out POS reranking) and our final system.
</tableCaption>
<subsectionHeader confidence="0.770792">
4.2 Results on CTB Corpus
</subsectionHeader>
<bodyText confidence="0.999962392857143">
To evaluate our reranking method’s impact on the
POS tagging task, we also tested our systems on
CTB 250k corpus using 10-fold cross-validation.
Figure 1 summarizes the results of segmentation
and POS tagging tasks on CTB 250k corpus. From
figure 1 we can see that our reranking method im-
proved both the segmentation and tagging accu-
racies across all 10 tests. We conducted pairwise
t-tests and our reranking model was found to be
statistically significantly better than the baseline
model under significance level of 5.0−4 (p-value
for segmentation) and 3.3−5 (p-value for POS tag-
ging).
Our system uses conditional random fields for per-
forming Chinese word segmentation and POS tag-
ging tasks simultaneously. In particular, we pro-
posed an approximated joint decoding method by
reranking the N-best segmenter output, based POS
tagging information. Our experimental results on
both SIGHAN Bakeoff 2006 datasets and Chinese
Penn Treebank showed that our reranking method
consistently increased both segmentation and POS
tagging accuracies. It is worth noting that our
reranking method can be applied not only to Chi-
nese segmentation and POS tagging tasks, but also
to many other sequential tasks that can benefit
from learning transfer, such as POS tagging and
NP-chunking.
</bodyText>
<sectionHeader confidence="0.972677" genericHeader="conclusions">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.906017">
This work was supported in part by ARDA’s
AQUAINT Program.
</bodyText>
<sectionHeader confidence="0.997283" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998104482758621">
Zhengdong Dong and Qiang Dong. 2006. HowNet
And The Computation Of Meaning. World Scien-
tific.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proceedings ofICML ’01.
Xiaoqiang Luo. 2003. A maximum entropy Chinese
character-based parser. In Proceedings of EMNLP
’03.
Hwee Tou Ng and Jin Kiat Low. 2004. Chinese part-
of-speech tagging: One-at-a-time or all-at-once?
word-based or character-based? In Proceedings of
EMNLP ’04.
Richard Schwartz and Yen-Lu Chow. 1990. The n-
best algorithm: An efficient and exact procedure for
finding the n most likely sentence hypotheses. In
Proceedings ofICASSP ’90.
Charles Sutton and Andrew McCallum. 2005. Compo-
sition of conditional random fields for transfer learn-
ing. In Proceedings ofHLT/EMNLP ’05.
Charles Sutton, Khashayar Rohanimanesh, and An-
drew McCallum. 2004. Dynamic conditional ran-
dom fields: Factorized probabilistic models for la-
beling and segmenting sequence data. In Proceed-
ings ofICML ’04.
Nianwen Xue, Fu-Dong Chiou, and Martha Stone
Palmer. 2002. Building a large-scale annotated Chi-
nese corpus. In Proceedings of COLING ’02.
</reference>
<figure confidence="0.965770285714286">
94
93
97
F−Measure(%)
96
95
baseline
final system
1 2 3 4 5 6 7 8 9 10
88
87
94
93
F−Measure(%)
92
91
90
89
baseline
final system
1 2 3 4 5 6 7 8 9 10
</figure>
<page confidence="0.953679">
208
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.958019">
<title confidence="0.999978">Using Part-of-Speech Reranking to Improve Chinese Word Segmentation</title>
<author confidence="0.999544">Mengqiu Wang Yanxin Shi</author>
<affiliation confidence="0.999612333333333">Language Technologies Institute School of Computer Science Carnegie Mellon University</affiliation>
<address confidence="0.999497">Pittsburgh, PA 15213, USA</address>
<abstract confidence="0.997868157894737">Chinese word segmentation and Part-of- Speech (POS) tagging have been commonly considered as two separated tasks. In this paper, we present a system that performs Chinese word segmentation and POS tagging simultaneously. We train a segmenter and a tagger model separately based on linear-chain Conditional Random Fields (CRF), using lexical, morphological and semantic features. We propose an approximated joint decoding method by reranking the N-best segmenter output, based POS tagging information. Experimental results on SIGHAN Bakeoff dataset and Penn Chinese Treebank show that our reranking method significantly improve both segmentation and POS tagging accuracies.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Zhengdong Dong</author>
<author>Qiang Dong</author>
</authors>
<title>HowNet And The Computation Of Meaning. World Scientific.</title>
<date>2006</date>
<contexts>
<context position="7250" citStr="Dong and Dong, 2006" startWordPosition="1163" endWordPosition="1166">f words found in a lexicon1 that contain the current character as either the first, last or middle character, respectively. Single(C0) indicates whether the current character can be found as a single word in the lexicon. Besides the adopted basic features mentioned above, we also experimented with additional semantic features (Table 1 (1.8)). For (1.8), Sem0 refers to the semantic class of current character, and Sem−1, Sem1 represent the semantic class of characters one position to the left and right of the current character, respectively. We obtained a character’s semantic class from HowNet (Dong and Dong, 2006). Since many characters have multiple semantic classes defined by HowNet, it is a non-trivial task to choose among the different semantic classes. We performed contextual disambiguation of characters’ semantic classes by calculating semantic class similarities. For example, let us assume the current character is 8(look,read) in a word context of 8TR(read 1We compiled our lexicon from three external resources. HowNet: www.keenage.com; On-Line Chinese Tools: www.mandarintools.com; Online Dictionary from Peking University: http://ccl.pku.edu.cn/doubtfire/Course/ Chinese%20Information%20Processing</context>
</contexts>
<marker>Dong, Dong, 2006</marker>
<rawString>Zhengdong Dong and Qiang Dong. 2006. HowNet And The Computation Of Meaning. World Scientific.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings ofICML ’01.</booktitle>
<contexts>
<context position="4639" citStr="Lafferty et al., 2001" startWordPosition="724" endWordPosition="727"> 0.935 (UPUC), 0.964 (CityU), 0.952 (MSRA) and 0.949 (CKIP). 2 Algorithm Given an observed Chinese character sequence X = {C1, C2,..., Cn}, let S and T denote a segmentation sequence and a POS tagging sequence over X. Our goal is to find a segmentation sequence S and a POS tagging sequence T� that maximize the posterior probability : P(S, T|X = {C1, C2,..., Cn}) (1) Applying chain rule, we can further derive from Equation 1 the following: &lt;�S, T�&gt; Since we have factorized the joint probability in Equation 1 into two terms, we can now model these two components using conditional random fields (Lafferty et al., 2001). Linear-chain CRF models define conditional probability, P(Z|X), by linear-chain Markov random fields. In our case, X is the sequence of characters or words, and Z is the segmentation labels for characters (START or NON-START, used to indicate word boundaries) or the POS tagging for words (NN, VV, JJ, etc.). The conditional probability is defined as: T K P(Z|X) = N(X) exp (1: 1: Akfk(Z, X, t)) t�1 k�1 (3) where N(X) is a normalization term to guarantee that the summation of the probability of all label sequences is one. fk(Z, X, t) is the kth localfeaturefunction at sequence position t. It ma</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings ofICML ’01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoqiang Luo</author>
</authors>
<title>A maximum entropy Chinese character-based parser.</title>
<date>2003</date>
<booktitle>In Proceedings of EMNLP ’03.</booktitle>
<contexts>
<context position="2165" citStr="Luo (2003)" startWordPosition="319" endWordPosition="320">pagation in chaining subtasks such as segmentation and POS tagging is to exploit the learning transfer (Sutton and McCallum, 2005) among subtasks, typically through joint inference. Sutton et al. (2004) presented dynamic conditional random fields (DCRF), a generalization of the traditional linear-chain CRF that allow representation of interaction among labels. They used loopy belief propagation for inference approximation. Their empirical results on the joint task of POS tagging and NP-chunking suggested that DCRF gave superior performance over cascaded linear-chain CRF. Ng and Low (2004) and Luo (2003) also trained single joint models over the Chinese segmentation and POS tagging subtasks. In their work, they brought the two subtasks together by treating it as a single tagging problem, for which they trained a maximum entropy classifier to assign a combined word boundary and POS tag to each character. A major challenge, however, exists in doing joint inference for complex and large-scale NLP application. Sutton and McCallum (Sutton and McCallum, 2005) suggested that in many cases exact inference can be too expensive and thus formidable. They presented an alternative approach in which a line</context>
</contexts>
<marker>Luo, 2003</marker>
<rawString>Xiaoqiang Luo. 2003. A maximum entropy Chinese character-based parser. In Proceedings of EMNLP ’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hwee Tou Ng</author>
<author>Jin Kiat Low</author>
</authors>
<title>Chinese partof-speech tagging: One-at-a-time or all-at-once? word-based or character-based?</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP ’04.</booktitle>
<contexts>
<context position="2150" citStr="Ng and Low (2004)" startWordPosition="314" endWordPosition="317">way to avoid error propagation in chaining subtasks such as segmentation and POS tagging is to exploit the learning transfer (Sutton and McCallum, 2005) among subtasks, typically through joint inference. Sutton et al. (2004) presented dynamic conditional random fields (DCRF), a generalization of the traditional linear-chain CRF that allow representation of interaction among labels. They used loopy belief propagation for inference approximation. Their empirical results on the joint task of POS tagging and NP-chunking suggested that DCRF gave superior performance over cascaded linear-chain CRF. Ng and Low (2004) and Luo (2003) also trained single joint models over the Chinese segmentation and POS tagging subtasks. In their work, they brought the two subtasks together by treating it as a single tagging problem, for which they trained a maximum entropy classifier to assign a combined word boundary and POS tag to each character. A major challenge, however, exists in doing joint inference for complex and large-scale NLP application. Sutton and McCallum (Sutton and McCallum, 2005) suggested that in many cases exact inference can be too expensive and thus formidable. They presented an alternative approach </context>
<context position="6165" citStr="Ng and Low, 2004" startWordPosition="987" endWordPosition="990">time, we are interested in finding the segmentation sequence S and POS tagging sequence T� that maximizes the probability defined in Equation 2. Instead of exhaustively searching the whole space of all possible segmentations, we restrict our searching to S = {S1, S2, ..., SN}, where S is the restricted search space consisting of N-best decoded segmentation sequences. This N-best list of segmentation sequences, S, can be obtained using modified Viterbi algorithm and A* search (Schwartz and Chow, 1990). 3 Features 3.1 Features for Segmentation We adopted the basic segmentation features used in (Ng and Low, 2004). These features are summarized in Table 1 ((1.1)-(1.7)). In these templates, C0 refers to the current character, and C−n, Cn refer to the characters n positions to the left and right of the current character, respectively. Pu(C0) indicates whether C0 is a punctuation. T(Cn) classifies the character Cn into four classes: numbers, dates (year, month, date), English letters and all other characters. LBegin(C0), LEnd(C0) and LMid(C0) represent the maximum length of words found in a lexicon1 that contain the current character as either the first, last or middle character, respectively. Single(C0) </context>
</contexts>
<marker>Ng, Low, 2004</marker>
<rawString>Hwee Tou Ng and Jin Kiat Low. 2004. Chinese partof-speech tagging: One-at-a-time or all-at-once? word-based or character-based? In Proceedings of EMNLP ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Schwartz</author>
<author>Yen-Lu Chow</author>
</authors>
<title>The nbest algorithm: An efficient and exact procedure for finding the n most likely sentence hypotheses.</title>
<date>1990</date>
<booktitle>In Proceedings ofICASSP ’90.</booktitle>
<contexts>
<context position="6053" citStr="Schwartz and Chow, 1990" startWordPosition="969" endWordPosition="972">equent to be 1, whereas a negative value of Ai means the ith feature function’s value is unlikely to be 1. At decoding time, we are interested in finding the segmentation sequence S and POS tagging sequence T� that maximizes the probability defined in Equation 2. Instead of exhaustively searching the whole space of all possible segmentations, we restrict our searching to S = {S1, S2, ..., SN}, where S is the restricted search space consisting of N-best decoded segmentation sequences. This N-best list of segmentation sequences, S, can be obtained using modified Viterbi algorithm and A* search (Schwartz and Chow, 1990). 3 Features 3.1 Features for Segmentation We adopted the basic segmentation features used in (Ng and Low, 2004). These features are summarized in Table 1 ((1.1)-(1.7)). In these templates, C0 refers to the current character, and C−n, Cn refer to the characters n positions to the left and right of the current character, respectively. Pu(C0) indicates whether C0 is a punctuation. T(Cn) classifies the character Cn into four classes: numbers, dates (year, month, date), English letters and all other characters. LBegin(C0), LEnd(C0) and LMid(C0) represent the maximum length of words found in a lexi</context>
</contexts>
<marker>Schwartz, Chow, 1990</marker>
<rawString>Richard Schwartz and Yen-Lu Chow. 1990. The nbest algorithm: An efficient and exact procedure for finding the n most likely sentence hypotheses. In Proceedings ofICASSP ’90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Sutton</author>
<author>Andrew McCallum</author>
</authors>
<title>Composition of conditional random fields for transfer learning.</title>
<date>2005</date>
<booktitle>In Proceedings ofHLT/EMNLP ’05.</booktitle>
<contexts>
<context position="1685" citStr="Sutton and McCallum, 2005" startWordPosition="247" endWordPosition="250">Traditionally, these two tasks were treated as separate and independent processing steps chained together in a pipeline. In such pipeline systems, errors introduced at the early stage cannot be easily recovered in later steps, causing a cascade of errors and eventually harm overall performance. Intuitively, a correct segmentation of the input sentence is more likely to give rise to a correct POS tagging sequence than an incorrect segmentation. Hinging on this idea, one way to avoid error propagation in chaining subtasks such as segmentation and POS tagging is to exploit the learning transfer (Sutton and McCallum, 2005) among subtasks, typically through joint inference. Sutton et al. (2004) presented dynamic conditional random fields (DCRF), a generalization of the traditional linear-chain CRF that allow representation of interaction among labels. They used loopy belief propagation for inference approximation. Their empirical results on the joint task of POS tagging and NP-chunking suggested that DCRF gave superior performance over cascaded linear-chain CRF. Ng and Low (2004) and Luo (2003) also trained single joint models over the Chinese segmentation and POS tagging subtasks. In their work, they brought th</context>
<context position="3054" citStr="Sutton and McCallum, 2005" startWordPosition="459" endWordPosition="463">rd boundary and POS tag to each character. A major challenge, however, exists in doing joint inference for complex and large-scale NLP application. Sutton and McCallum (Sutton and McCallum, 2005) suggested that in many cases exact inference can be too expensive and thus formidable. They presented an alternative approach in which a linear-chain CRF is trained separately for each subtask at training time, but at decoding time they combined the learned weights from the CRF cascade into a single grid-shaped factorial CRF to perform joint decoding and make predictions for all subtasks. Similar to (Sutton and McCallum, 2005), in our system we also train a cascade of linear-chain CRF for the subtasks. But at decoding time, we experiment with an alternative approximation method to joint decoding, by taking the n-best hypotheses from the segmentation model and use the POS tagging model for reranking. We evaluated our system on the open tracks of SIGHAN Bakeoff 2006 dataset. Furthermore, to evaluate our reranking method’s impact on the POS tagging task, we also performed 10-fold cross-validation tests on the 250k Penn 205 Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 205–208, Sydney, </context>
</contexts>
<marker>Sutton, McCallum, 2005</marker>
<rawString>Charles Sutton and Andrew McCallum. 2005. Composition of conditional random fields for transfer learning. In Proceedings ofHLT/EMNLP ’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Sutton</author>
<author>Khashayar Rohanimanesh</author>
<author>Andrew McCallum</author>
</authors>
<title>Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data.</title>
<date>2004</date>
<booktitle>In Proceedings ofICML ’04.</booktitle>
<contexts>
<context position="1757" citStr="Sutton et al. (2004)" startWordPosition="258" endWordPosition="261">sing steps chained together in a pipeline. In such pipeline systems, errors introduced at the early stage cannot be easily recovered in later steps, causing a cascade of errors and eventually harm overall performance. Intuitively, a correct segmentation of the input sentence is more likely to give rise to a correct POS tagging sequence than an incorrect segmentation. Hinging on this idea, one way to avoid error propagation in chaining subtasks such as segmentation and POS tagging is to exploit the learning transfer (Sutton and McCallum, 2005) among subtasks, typically through joint inference. Sutton et al. (2004) presented dynamic conditional random fields (DCRF), a generalization of the traditional linear-chain CRF that allow representation of interaction among labels. They used loopy belief propagation for inference approximation. Their empirical results on the joint task of POS tagging and NP-chunking suggested that DCRF gave superior performance over cascaded linear-chain CRF. Ng and Low (2004) and Luo (2003) also trained single joint models over the Chinese segmentation and POS tagging subtasks. In their work, they brought the two subtasks together by treating it as a single tagging problem, for </context>
</contexts>
<marker>Sutton, Rohanimanesh, McCallum, 2004</marker>
<rawString>Charles Sutton, Khashayar Rohanimanesh, and Andrew McCallum. 2004. Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data. In Proceedings ofICML ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fu-Dong Chiou</author>
<author>Martha Stone Palmer</author>
</authors>
<title>Building a large-scale annotated Chinese corpus.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING ’02.</booktitle>
<contexts>
<context position="3755" citStr="Xue et al., 2002" startWordPosition="573" endWordPosition="576"> decoding time, we experiment with an alternative approximation method to joint decoding, by taking the n-best hypotheses from the segmentation model and use the POS tagging model for reranking. We evaluated our system on the open tracks of SIGHAN Bakeoff 2006 dataset. Furthermore, to evaluate our reranking method’s impact on the POS tagging task, we also performed 10-fold cross-validation tests on the 250k Penn 205 Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 205–208, Sydney, July 2006. c�2006 Association for Computational Linguistics Chinese Treebank (CTB) (Xue et al., 2002). Results from both evaluations suggest that our simple reranking method is very effective. We achieved a consistent performance gain on both segmentation and POS tagging tasks over linearly-cascaded CRF. Our official F-scores on the 2006 Bakeoff open tracks are 0.935 (UPUC), 0.964 (CityU), 0.952 (MSRA) and 0.949 (CKIP). 2 Algorithm Given an observed Chinese character sequence X = {C1, C2,..., Cn}, let S and T denote a segmentation sequence and a POS tagging sequence over X. Our goal is to find a segmentation sequence S and a POS tagging sequence T� that maximize the posterior probability : P(</context>
</contexts>
<marker>Xue, Chiou, Palmer, 2002</marker>
<rawString>Nianwen Xue, Fu-Dong Chiou, and Martha Stone Palmer. 2002. Building a large-scale annotated Chinese corpus. In Proceedings of COLING ’02.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>