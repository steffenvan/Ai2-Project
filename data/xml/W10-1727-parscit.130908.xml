<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007457">
<title confidence="0.9706465">
Vs and OOVs: Two Problems for Translation between German and
English
</title>
<author confidence="0.996702">
Sara Stymne, Maria Holmqvist, Lars Ahrenberg
</author>
<affiliation confidence="0.839686">
Link¨oping University
Sweden
</affiliation>
<email confidence="0.997502">
{sarst,marho,lah}@ida.liu.se
</email>
<sectionHeader confidence="0.997389" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999180466666667">
In this paper we report on experiments
with three preprocessing strategies for im-
proving translation output in a statistical
MT system. In training, two reordering
strategies were studied: (i) reorder on the
basis of the alignments from Giza++, and
(ii) reorder by moving all verbs to the
end of segments. In translation, out-of-
vocabulary words were preprocessed in a
knowledge-lite fashion to identify a likely
equivalent. All three strategies were im-
plemented for our EnglishHGerman sys-
tem submitted to the WMT10 shared task.
Combining them lead to improvements in
both language directions.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999422">
We present the Liu translation system for the con-
strained condition of the WMT10 shared transla-
tion task, between German and English in both di-
rections. The system is based on the 2009 Liu sub-
mission (Holmqvist et al., 2009), that used com-
pound processing, morphological sequence mod-
els, and improved alignment by reordering.
This year we have focused on two issues: trans-
lation of verbs, which is problematic for transla-
tion between English and German since the verb
placement is different with German verbs often be-
ing placed at the end of sentences; and OOVs, out-
of-vocabulary words, which are problematic for
machine translation in general. Verb translation
is targeted by trying to improve alignment, which
we believe is a crucial step for verb translation
since verbs that are far apart are often not aligned
at all. We do this mainly by moving verbs to the
end of sentences previous to alignment, which we
also combine with other alignments. We trans-
form OOVs into known words in a post-processing
step, based on casing, stemming, and splitting of
hyphenated compounds. In addition, we perform
general compound splitting for German both be-
fore training and translation, which also reduces
the OOV rate.
All results in this article are for the develop-
ment test set newstest2009, on truecased output.
We report Bleu scores (Papineni et al., 2002) and
Meteor ranking (without WordNet) scores (Agar-
wal and Lavie, 2008), using percent notation. We
also used other metrics, but as they gave similar
results they are not reported. For significance test-
ing we used approximate randomization (Riezler
and Maxwell, 2005), with p &lt; 0.05.
</bodyText>
<sectionHeader confidence="0.990487" genericHeader="method">
2 Baseline System
</sectionHeader>
<bodyText confidence="0.999925333333333">
The 2010 Liu system is based on the PBSMT base-
line system for the WMT shared translation task1.
We use the Moses toolkit (Koehn et al., 2007) for
decoding and to train translation models, Giza++
(Och and Ney, 2003) for word alignment, and the
SRILM toolkit (Stolcke, 2002) to train language
models. The main difference to the WMT base-
line is that the Liu system is trained on truecased
data, as in Koehn et al. (2008), instead of lower-
cased data. This means that there is no need for a
full recasing step after translation, instead we only
need to uppercase the first word in each sentence.
</bodyText>
<subsectionHeader confidence="0.993335">
2.1 Corpus
</subsectionHeader>
<bodyText confidence="0.999735888888889">
We participated in the constrained task, where we
only trained the Liu system on the news and Eu-
roparl corpora provided for the workshop. The
translation and reordering models were trained us-
ing the bilingual Europarl and news commentary
corpora, which we concatenated.
We used two sets of language models, one
where we first trained two models on Europarl
and news commentary, which we then interpolated
</bodyText>
<footnote confidence="0.997437">
1http://www.statmt.org/wmt10/baseline.
html
</footnote>
<page confidence="0.965956">
183
</page>
<note confidence="0.4607905">
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 183–188,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999930833333333">
with more weight given to the news commentary,
using weights from Koehn and Schroeder (2007).
The second set of language models were trained
on monolingual news data. For tuning we used
every second sentence, in total 1025 sentences, of
news-test2008.
</bodyText>
<subsectionHeader confidence="0.995627">
2.2 Training with Limited Computational
Resources
</subsectionHeader>
<bodyText confidence="0.999890136363636">
One challenge for us was to train the transla-
tion sytem with limited computational resources.
We trained all systems on one Intel Core 2 CPU,
3.0Ghz, 16 Gb of RAM, 64 bit Linux (RedHat)
machine. This constrained the possibilities of us-
ing the data provided by the workshop to the full.
The main problem was training the language mod-
els, since the monolingual data was very large
compared to the bilingual data.
In order to train language models that were both
fast at runtime, and possible to train with the avail-
able memory, we chose to use the SRILM toolkit
(Stolcke, 2002), with entropy-based pruning, with
10−8 as a threshold. To reduce the model size we
also used lower order models for the large corpus;
4-grams instead of 5-grams for words and 6-grams
instead of 7-grams for the morphological models.
It was still impossible to train on the monolingual
English news corpus, with nearly 50 million sen-
tences, so we split that corpus into three equal size
parts, and trained three models, that were interpo-
lated with equal weights.
</bodyText>
<sectionHeader confidence="0.992736" genericHeader="method">
3 Morphological Processing
</sectionHeader>
<bodyText confidence="0.999996444444445">
We added morphological processing to the base-
line system, by training additional sequence mod-
els on morphologically enriched part-of-speech
tags, and by compound processing for German.
We utilized the factored translation framework
in Moses, to enrich the baseline system with an
additional target sequence model. For English
we used part-of-speech tags obtained using Tree-
Tagger (Schmid, 1994), enriched with more fine-
grained tags for the number of determiners, in or-
der to target more agreement issues, since nouns
already have number in the tagset. For German
we used morphologically rich tags from RFTag-
ger (Schmid and Laws, 2008), that contains mor-
phological information such as case, number, and
gender for nouns and tense for verbs. We used
the extra factor in an additional sequence model
on the target side, which can improve word order
</bodyText>
<subsectionHeader confidence="0.880875">
System Bleu Meteor
</subsectionHeader>
<bodyText confidence="0.812138">
Baseline 13.42 48.83
+ morph 13.85 49.69
+ comp 14.24 49.41
</bodyText>
<tableCaption confidence="0.9224335">
Table 1: Results for morphological processing,
English—*German
</tableCaption>
<subsectionHeader confidence="0.929852">
System Bleu Meteor
</subsectionHeader>
<bodyText confidence="0.985795707317073">
Baseline 18.34 38.13
+ morph 18.39 37.86
+ comp 18.50 38.47
Table 2: Results for morphological processing,
German—*English
and agreement between words. For German the
factor was also used for compound merging.
Prior to training and translation, compound pro-
cessing was performed, using an empirical method
(Koehn and Knight, 2003; Stymne, 2008) that
splits words if they can be split into parts that oc-
cur in a monolingual corpus, choosing the split-
ting option with the highest arithmetic mean of its
part frequencies in the corpus. We split nouns,
adjectives and verbs, into parts that are content
words or particles. We imposed a length limit on
parts of 3 characters for translation from German
and of 6 characters for translation from English,
and we had a stop list of parts that often led to
errors, such as arische (Aryan) in konsularische
(consular). We allowed 10 common letter changes
(Langer, 1998) and hyphens at split points. Com-
pound parts were given a special part-of-speech
tag that matches the head word.
For translation into German, compound parts
were merged into full compounds using a method
described in Stymne and Holmqvist (2008), which
is based on matching of the special part-of-speech
tag for compound parts. A word with a compound
POS-tag were merged with the next word, if their
POS-tags were matching.
Tables 1 and 2 show the results of the addi-
tional morphological processing. Adding the se-
quence models on morphologically enriched part-
of-speech tags gave a significant improvement for
translation into German, but similar or worse re-
sults as the baseline for translation into English.
This is not surprising, since German morphology
is more complex than English morphology. The
addition of compound processing significantly im-
proved the results on Meteor for translation into
</bodyText>
<page confidence="0.993839">
184
</page>
<bodyText confidence="0.999980727272727">
English, and it also reduced the number of OOVs
in the translation output by 20.8%. For translation
into German, compound processing gave a signif-
icant improvement on both metrics compared to
the baseline, and on Bleu compared to the system
with morphological sequence models. Overall, we
believe that both compound splitting and morphol-
ogy are useful; thus all experiments reported in the
sequel are based on the baseline system with mor-
phology models and compound splitting, which
we will call base.
</bodyText>
<sectionHeader confidence="0.992205" genericHeader="method">
4 Improved Alignment by Reordering
</sectionHeader>
<bodyText confidence="0.999982129032258">
Previous work has shown that translation quality
can be improved by making the source language
more similar to the target language, for instance
in terms of word order (Wang et al., 2007; Xia
and McCord, 2004). In order to harmonize the
word order of the source and target sentence, they
applied hand-crafted or automatically induced re-
ordering rules to the source sentences of the train-
ing corpus. At decoding time, reordering rules
were again applied to input sentences before trans-
lation. The positive effects of such methods seem
to come from a combination of improved align-
ment and improved reordering during translation.
In contrast, we focus on improving the word
alignment by reordering the training corpus. The
training corpus is reordered prior to word align-
ment with Giza++ (Och and Ney, 2003) and then
the word links are re-adjusted back to the original
word positions. From the re-adjusted corpus, we
create phrase tables that allow translation of non-
reordered input text. Consequently, our reordering
only affects the word alignment and the phrase ta-
bles extracted from it.
We investigated two ways of reordering. The
first method is based on word alignments and the
other method is based on moving verbs to sim-
ilar positions in the source and target sentences.
We also investigated different combinations of re-
orderings and alignments. All results for the sys-
tems with improved reordering are shown in Ta-
bles 3 and 4.
</bodyText>
<subsectionHeader confidence="0.997784">
4.1 Reordering Based on Alignments
</subsectionHeader>
<bodyText confidence="0.9991592">
The first reordering method does not require any
syntactic information or rules for reordering. We
simply used symmetrized Giza++ word align-
ments to reorder the words in the source sentences
to reflect the target word order and applied Giza++
</bodyText>
<table confidence="0.9991715">
System Bleu Meteor
base 14.24 49.41
reorder 14.32 49.58
verb 13.93 49.22
base+verb 14.38 49.72
base+verb+reorder 14.39 49.39
</table>
<tableCaption confidence="0.867493">
Table 3: Results for improved alignment,
</tableCaption>
<table confidence="0.999856714285714">
English—*German
System Bleu Meteor
base 18.50 38.47
reorder 18.77 38.53
verb 18.61 38.53
base+verb 18.66 38.61
base+verb+reorder 18.73 38.59
</table>
<tableCaption confidence="0.899912">
Table 4: Results for improved alignment,
German—*English
</tableCaption>
<bodyText confidence="0.982932">
again to the reordered training corpus. The follow-
ing steps were performed to produce the final word
alignment:
</bodyText>
<listItem confidence="0.9898543">
1. Word align the training corpus with Giza++.
2. Reorder the source words according to the or-
der of the target words they are aligned to
(store the original source word positions for
later).
3. Word align the reordered source and original
target corpus with Giza++.
4. Re-adjust the new word alignments so that
they align source and target words in the orig-
inal corpus.
</listItem>
<bodyText confidence="0.9986034">
The system built on this word alignment (re-
order) had a significant improvement in Bleu score
over the unreordered baseline (base) for transla-
tion into English, and small improvements other-
wise.
</bodyText>
<subsectionHeader confidence="0.959105">
4.2 Verb movement
</subsectionHeader>
<bodyText confidence="0.999967125">
The positions of finite verbs are often very differ-
ent in English and German, where they are often
placed at the end of sentences. In several cases we
noted that finite verbs were misaligned by Giza++.
To improve the alignment of verbs, we moved all
verbs in both English and German to the end of the
sentences prior to word alignment. The reordered
sentences were word aligned with Giza++ and the
</bodyText>
<page confidence="0.995538">
185
</page>
<bodyText confidence="0.999878166666667">
resulting word links were then re-adjusted to align
words in the original corpus.
The system created from this alignment (verb)
resulted in significantly lower scores than base for
translation into German, and similar scores as base
for translation into English.
</bodyText>
<subsectionHeader confidence="0.999588">
4.3 Combination Systems
</subsectionHeader>
<bodyText confidence="0.999982684210526">
The alignment based on reordered verbs did not
produce a better alignment in terms of Bleu scores
of the resulting translations, which led us to the
conclusion that the alignment was noisy. How-
ever, it is possible that we did correctly align some
words that were misaligned in the baseline align-
ment. To investigate this issue we concatenated
first the baseline and verb alignments, and then all
three alignments, and extracted phrase tables from
the concatenated training sets.
All scores for both combined systems signifi-
cantly outperformed the unfactored baseline, and
were slightly better than base. For translation into
German it was best to use the combination of only
verb and base, which was significantly better than
base on Meteor. This shows that even though the
verb alignments were not good when used in a sin-
gle system, they still could contribute in a combi-
nation system.
</bodyText>
<sectionHeader confidence="0.828028" genericHeader="method">
5 Preprocessing of OOVs
</sectionHeader>
<bodyText confidence="0.9994365">
Out-of-vocabulary words, words that have not
been seen in the training data, are a problem in
statistical machine translation, since no transla-
tions have been observed for them. The standard
strategy is to transfer them as is to the translation
output, which, naive as it sounds, actually works
well in some cases, since many OOVs are numbers
or proper names (Stymne and Holmqvist, 2008).
However, it still results in incomprehensible words
in the output in many cases. We have investi-
gated several ways of changing unknown words
into similar words that have been seen in the train-
ing data, in a preprocessing step.
We also considered another OOV problem,
number formatting, since it differs between En-
glish and German. To address this, we swapped
decimal points/commas, and other delimeters for
unknown numbers in a post-processing step.
In the preprocessing step, we applied a num-
ber of transformations to each OOV word, accept-
ing the first applicable transformation that led to a
known word:
</bodyText>
<table confidence="0.7992045">
Type German English
total OOVs 1833 1489
casing 124 26
stemming 270 72
hyphenated words 230 124
end hyphens 24 –
</table>
<tableCaption confidence="0.773722">
Table 5: Number of affected words by OOV-
preprocessing
</tableCaption>
<listItem confidence="0.991865363636364">
1. Change the word into a known cased ver-
sion (since we trained a truecased system,
this handles cased variations of words)
2. Stem the word, and if we know the stem,
choose the most common realisation of that
stem (using a Porter stemmer)
3. For hyphenated words, split at the hyphen (if
any of the resulting parts are OOVs, they are
recursively treated as well)
4. Remove hyphens at the end of German words
(that could result from compound splitting)
</listItem>
<bodyText confidence="0.98826225">
The first two steps were based on frequency lists
of truecased and stemmed words that we compiled
from the monolingual training corpora.
Inspection of the initial results showed that
proper names were often changed into other words
in English, so we excluded them from the prepro-
cessing by not applying it to words with an initial
capital letter. This happened to a lesser extent for
German, but here it was impossible to use the same
simple heuristic for proper names, since German
nouns also have an initial capital letter.
The number of affected words for the baseline
using the final transformations are shown in Table
5. Even though we managed to transform some
words, we still lack a transformation for the ma-
jority of OOVs. Despite this, there is a tendency of
small improvements on both metrics in the major-
ity of cases in both translation directions, as shown
in Tables 6 and 7.
Figure 1 shows an example of how OOV pro-
cessing affects one sentence for translation from
German to English. In this case splitting a hy-
phenated compound gives a better translation,
even though the word opening is chosen rather
than jack. There is also a stemming change,
where the adjective ausgereiftesten (the most well-
engineered), is changed form superlative to posi-
tive. This results in a more understandable trans-
</bodyText>
<page confidence="0.994188">
186
</page>
<table confidence="0.8971548">
DE original Die besten und technisch ausgereiftesten Telefone mit einer 3,5-mm- ¨Offnung
DE preprocessed f¨ur normale Kopfh¨orer kosten bis zu f¨unfzehntausend Kronen.
die besten und technisch ausgereifte Telefone mit einer 3,5 mm ¨Offnung f¨ur
normale Kopf H¨orer kosten bis zu f¨unfzehntausend Kronen.
base+verb+reorder The best and technically ausgereiftesten phones with a 3,5-mm- ¨Offnung for
base+verb+reorder normal earphones cost up to fifteen thousand kronor.
+OOV The best and technologically advanced phones with a 3.5 mm opening for nor-
mal earphones cost up to fifteen thousand kronor.
EN reference The best and most technically well-equipped telephones, with a 3.5 mm jack
for ordinary headphones, cost up to fifteen thousand crowns.
</table>
<figureCaption confidence="0.898774">
Figure 1: Example of the effects of OOV processing for German—*English
</figureCaption>
<table confidence="0.999299166666667">
System Bleu Meteor
base 14.24 49.41
+ OOV 14.26 49.43
base+verb 14.38 49.72
+ OOV 14.42 49.75
+ MBR 14.41 49.77
</table>
<tableCaption confidence="0.702974">
Table 6: Results for OOV-processing and MBR,
English—*German.
</tableCaption>
<table confidence="0.999795166666667">
System Bleu Meteor
base 18.50 38.47
+ OOV 18.48 38.59
base+verb+reorder 18.73 38.59
+ OOV 18.81 38.70
+ MBR 18.84 38.75
</table>
<tableCaption confidence="0.87347">
Table 7: Results for OOV-processing and MBR,
German—*English.
</tableCaption>
<bodyText confidence="0.99989875">
lation, which, however, is harmful to automatic
scores, since the preceding word, technically,
which is identical to the reference, is changed into
technologically.
This work is related to work by Arora et al.
(2008), who transformed Hindi OOVs by us-
ing morphological analysers, before translation to
Japanese. Our work has the advantage that it is
more knowledge-lite, as it only needs a Porter
stemmer and a monolingual corpus. Mirkin et al.
(2009) used WordNet to replace OOVs by syn-
onyms or hypernyms, and chose the best overall
translation partly based on scoring of the source
transformations. Our OOV handling could po-
tentially be used in combination with both these
strategies.
</bodyText>
<sectionHeader confidence="0.997415" genericHeader="method">
6 Final Submission
</sectionHeader>
<bodyText confidence="0.999906210526316">
For the final Liu shared task submission we
used the base+verb+reorder+OOV system for
German—*English and the base+verb+OOV sys-
tem for English—*German, which had the best
overall scores considering all metrics. To these
systems we added minimum Bayes risk (MBR)
decoding (Kumar and Byrne, 2004). In standard
decoding, the top suggestion of the translation sys-
tem is chosen as the system output. In MBR de-
coding the risk is spread by choosing the trans-
lation that is most similar to the N highest scor-
ing translation suggestions from the system, with
N = 100, as suggested in Koehn et al. (2008).
MBR decoding gave hardly any changes in auto-
matic scores, as shown in Tables 6 and 7. The final
system was significantly better than the baseline in
all cases, and significantly better than base on Me-
teor in both translation directions, and on Bleu for
translation into English.
</bodyText>
<sectionHeader confidence="0.999232" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.9999375">
As in Holmqvist et al. (2009) reordering by us-
ing Giza++ in two phases had a small, but consis-
tent positive effect. Aligning verbs by co-locating
them at the end of sentences had a largely negative
effect. However, when output from this method
was concatenated with the baseline alignment be-
fore extracting the phrase table, there were con-
sistent improvements. Combining all three align-
ments, however, had mixed effects. Combining re-
ordering in training with a knowledge-lite method
for handling out-of-vocabulary words led to sig-
nificant improvements on Meteor scores for trans-
lation between German and English in both direc-
tions.
</bodyText>
<page confidence="0.996892">
187
</page>
<sectionHeader confidence="0.996178" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999855781818181">
Abhaya Agarwal and Alon Lavie. 2008. METEOR,
M-BLEU and M-TER: Evaluation metrics for high-
correlation with human rankings of machine transla-
tion output. In Proceedings of the Third Workshop
on Statistical Machine Translation, pages 115–118,
Columbus, Ohio, USA.
Karunesh Arora, Michael Paul, and Eiichiro Sumita.
2008. Translation of unknown words in phrase-
based statistical machine translation for languages
of rich morphology. In Proceedings of the 1st Inter-
national Workshop on Spoken Languages Technolo-
gies for Under-Resourced Languages, pages 70–75,
Hanoi, Vietnam.
Maria Holmqvist, Sara Stymne, Jody Foo, and Lars
Ahrenberg. 2009. Improving alignment for SMT
by reordering and augmenting the training corpus.
In Proceedings of the Fourth Workshop on Statis-
tical Machine Translation, pages 120–124, Athens,
Greece.
Philipp Koehn and Kevin Knight. 2003. Empirical
methods for compound splitting. In Proceedings of
the 10th Conference of the EACL, pages 187–193,
Budapest, Hungary.
Philipp Koehn and Josh Schroeder. 2007. Experi-
ments in domain adaptation for statistical machine
translation. In Proceedings of the Second Workshop
on Statistical Machine Translation, pages 224–227,
Prague, Czech Republic.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses:
Open source toolkit for statistical machine transla-
tion. In Proceedings of the 45th Annual Meeting
of the ACL, demonstration session, pages 177–180,
Prague, Czech Republic.
Philipp Koehn, Abhishek Arun, and Hieu Hoang.
2008. Towards better machine translation quality for
the German-English language pairs. In Proceedings
of the Third Workshop on Statistical Machine Trans-
lation, pages 139–142, Columbus, Ohio, USA.
Shankar Kumar and William Byrne. 2004. Minimum
Bayes-risk decoding for statistical machine transla-
tion. In Proceedings of the 2004 Human Language
Technology Conference of the NAACL, pages 169–
176, Boston, Massachusetts, USA.
Stefan Langer. 1998. Zur Morphologie und Seman-
tik von Nominalkomposita. In Tagungsband der
4. Konferenz zur Verarbeitung nat¨urlicher Sprache
(KONVENS), pages 83–97, Bonn, Germany.
Shachar Mirkin, Lucia Specia, Nicola Cancedda, Ido
Dagan, Marc Dymetman, and Idan Szpektor. 2009.
Source-language entailment modeling for translat-
ing unknown terms. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL
and the 4th International Joint Conference on Natu-
ral Language Processing of the AFNLP, pages 791–
799, Suntec, Singapore.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A method for automatic
evaluation of machine translation. In Proceedings
of the 40th Annual Meeting of the ACL, pages 311–
318, Philadelphia, Pennsylvania, USA.
Stefan Riezler and John T. Maxwell. 2005. On some
pitfalls in automatic evaluation and significance test-
ing for MT. In Proceedings of the Workshop on In-
trinsic and Extrinsic Evaluation Measures for MT
and/or Summarization at the 43th Annual Meeting of
the ACL, pages 57–64, Ann Arbor, Michigan, USA.
Helmut Schmid and Florian Laws. 2008. Estimation of
conditional probabilities with decision trees and an
application to fine-grained pos tagging. In Proceed-
ings of the 22th International Conference on Com-
putational Linguistics, pages 777–784, Manchester,
UK.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. In Proceedings of the
International Conference on New Methods in Lan-
guage Processing, pages 44–49, Manchester, UK.
Andreas Stolcke. 2002. SRILM – an extensible
language modeling toolkit. In Proceedings of the
Seventh International Conference on Spoken Lan-
guage Processing, pages 901–904, Denver, Col-
orado, USA.
Sara Stymne and Maria Holmqvist. 2008. Process-
ing of Swedish compounds for phrase-based statis-
tical machine translation. In Proceedings of the
12th Annual Conference of the European Associa-
tion for Machine Translation, pages 180–189, Ham-
burg, Germany.
Sara Stymne. 2008. German compounds in factored
statistical machine translation. In Proceedings of
GoTAL – 6th International Conference on Natural
Language Processing, pages 464–475, Gothenburg,
Sweden.
Chao Wang, Michael Collins, and Philipp Koehn.
2007. Chinese syntactic reordering for statistical
machine translation. In Proc. of the 2007 Joint Con-
ference on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning, pages 737–745, Prague, Czech Republic.
Fei Xia and Michael McCord. 2004. Improving
a statistical MT system with automatically learned
rewrite patterns. In Proceedings of the 20th Inter-
national Conference on Computational Linguistics,
pages 508–514, Geneva, Switzerland.
</reference>
<page confidence="0.997521">
188
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.381334">
<title confidence="0.8510285">Vs and OOVs: Two Problems for Translation between German and English</title>
<author confidence="0.64752">Sara Stymne</author>
<author confidence="0.64752">Maria Holmqvist</author>
<author confidence="0.64752">Lars</author>
<email confidence="0.54623">Link¨oping</email>
<abstract confidence="0.999122125">In this paper we report on experiments with three preprocessing strategies for improving translation output in a statistical MT system. In training, two reordering strategies were studied: (i) reorder on the basis of the alignments from Giza++, and (ii) reorder by moving all verbs to the end of segments. In translation, out-ofvocabulary words were preprocessed in a knowledge-lite fashion to identify a likely equivalent. All three strategies were imfor our system submitted to the WMT10 shared task. Combining them lead to improvements in both language directions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Abhaya Agarwal</author>
<author>Alon Lavie</author>
</authors>
<title>METEOR, M-BLEU and M-TER: Evaluation metrics for highcorrelation with human rankings of machine translation output.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>115--118</pages>
<location>Columbus, Ohio, USA.</location>
<contexts>
<context position="2210" citStr="Agarwal and Lavie, 2008" startWordPosition="347" endWordPosition="351">often not aligned at all. We do this mainly by moving verbs to the end of sentences previous to alignment, which we also combine with other alignments. We transform OOVs into known words in a post-processing step, based on casing, stemming, and splitting of hyphenated compounds. In addition, we perform general compound splitting for German both before training and translation, which also reduces the OOV rate. All results in this article are for the development test set newstest2009, on truecased output. We report Bleu scores (Papineni et al., 2002) and Meteor ranking (without WordNet) scores (Agarwal and Lavie, 2008), using percent notation. We also used other metrics, but as they gave similar results they are not reported. For significance testing we used approximate randomization (Riezler and Maxwell, 2005), with p &lt; 0.05. 2 Baseline System The 2010 Liu system is based on the PBSMT baseline system for the WMT shared translation task1. We use the Moses toolkit (Koehn et al., 2007) for decoding and to train translation models, Giza++ (Och and Ney, 2003) for word alignment, and the SRILM toolkit (Stolcke, 2002) to train language models. The main difference to the WMT baseline is that the Liu system is trai</context>
</contexts>
<marker>Agarwal, Lavie, 2008</marker>
<rawString>Abhaya Agarwal and Alon Lavie. 2008. METEOR, M-BLEU and M-TER: Evaluation metrics for highcorrelation with human rankings of machine translation output. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 115–118, Columbus, Ohio, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karunesh Arora</author>
<author>Michael Paul</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Translation of unknown words in phrasebased statistical machine translation for languages of rich morphology.</title>
<date>2008</date>
<booktitle>In Proceedings of the 1st International Workshop on Spoken Languages Technologies for Under-Resourced Languages,</booktitle>
<pages>70--75</pages>
<location>Hanoi, Vietnam.</location>
<contexts>
<context position="17093" citStr="Arora et al. (2008)" startWordPosition="2775" endWordPosition="2778"> effects of OOV processing for German—*English System Bleu Meteor base 14.24 49.41 + OOV 14.26 49.43 base+verb 14.38 49.72 + OOV 14.42 49.75 + MBR 14.41 49.77 Table 6: Results for OOV-processing and MBR, English—*German. System Bleu Meteor base 18.50 38.47 + OOV 18.48 38.59 base+verb+reorder 18.73 38.59 + OOV 18.81 38.70 + MBR 18.84 38.75 Table 7: Results for OOV-processing and MBR, German—*English. lation, which, however, is harmful to automatic scores, since the preceding word, technically, which is identical to the reference, is changed into technologically. This work is related to work by Arora et al. (2008), who transformed Hindi OOVs by using morphological analysers, before translation to Japanese. Our work has the advantage that it is more knowledge-lite, as it only needs a Porter stemmer and a monolingual corpus. Mirkin et al. (2009) used WordNet to replace OOVs by synonyms or hypernyms, and chose the best overall translation partly based on scoring of the source transformations. Our OOV handling could potentially be used in combination with both these strategies. 6 Final Submission For the final Liu shared task submission we used the base+verb+reorder+OOV system for German—*English and the b</context>
</contexts>
<marker>Arora, Paul, Sumita, 2008</marker>
<rawString>Karunesh Arora, Michael Paul, and Eiichiro Sumita. 2008. Translation of unknown words in phrasebased statistical machine translation for languages of rich morphology. In Proceedings of the 1st International Workshop on Spoken Languages Technologies for Under-Resourced Languages, pages 70–75, Hanoi, Vietnam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Holmqvist</author>
<author>Sara Stymne</author>
<author>Jody Foo</author>
<author>Lars Ahrenberg</author>
</authors>
<title>Improving alignment for SMT by reordering and augmenting the training corpus.</title>
<date>2009</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Machine Translation,</booktitle>
<pages>120--124</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="1013" citStr="Holmqvist et al., 2009" startWordPosition="152" endWordPosition="155">asis of the alignments from Giza++, and (ii) reorder by moving all verbs to the end of segments. In translation, out-ofvocabulary words were preprocessed in a knowledge-lite fashion to identify a likely equivalent. All three strategies were implemented for our EnglishHGerman system submitted to the WMT10 shared task. Combining them lead to improvements in both language directions. 1 Introduction We present the Liu translation system for the constrained condition of the WMT10 shared translation task, between German and English in both directions. The system is based on the 2009 Liu submission (Holmqvist et al., 2009), that used compound processing, morphological sequence models, and improved alignment by reordering. This year we have focused on two issues: translation of verbs, which is problematic for translation between English and German since the verb placement is different with German verbs often being placed at the end of sentences; and OOVs, outof-vocabulary words, which are problematic for machine translation in general. Verb translation is targeted by trying to improve alignment, which we believe is a crucial step for verb translation since verbs that are far apart are often not aligned at all. W</context>
<context position="18500" citStr="Holmqvist et al. (2009)" startWordPosition="3010" endWordPosition="3013"> In standard decoding, the top suggestion of the translation system is chosen as the system output. In MBR decoding the risk is spread by choosing the translation that is most similar to the N highest scoring translation suggestions from the system, with N = 100, as suggested in Koehn et al. (2008). MBR decoding gave hardly any changes in automatic scores, as shown in Tables 6 and 7. The final system was significantly better than the baseline in all cases, and significantly better than base on Meteor in both translation directions, and on Bleu for translation into English. 7 Conclusions As in Holmqvist et al. (2009) reordering by using Giza++ in two phases had a small, but consistent positive effect. Aligning verbs by co-locating them at the end of sentences had a largely negative effect. However, when output from this method was concatenated with the baseline alignment before extracting the phrase table, there were consistent improvements. Combining all three alignments, however, had mixed effects. Combining reordering in training with a knowledge-lite method for handling out-of-vocabulary words led to significant improvements on Meteor scores for translation between German and English in both direction</context>
</contexts>
<marker>Holmqvist, Stymne, Foo, Ahrenberg, 2009</marker>
<rawString>Maria Holmqvist, Sara Stymne, Jody Foo, and Lars Ahrenberg. 2009. Improving alignment for SMT by reordering and augmenting the training corpus. In Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 120–124, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Empirical methods for compound splitting.</title>
<date>2003</date>
<booktitle>In Proceedings of the 10th Conference of the EACL,</booktitle>
<pages>187--193</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="6386" citStr="Koehn and Knight, 2003" startWordPosition="1023" endWordPosition="1026">ouns and tense for verbs. We used the extra factor in an additional sequence model on the target side, which can improve word order System Bleu Meteor Baseline 13.42 48.83 + morph 13.85 49.69 + comp 14.24 49.41 Table 1: Results for morphological processing, English—*German System Bleu Meteor Baseline 18.34 38.13 + morph 18.39 37.86 + comp 18.50 38.47 Table 2: Results for morphological processing, German—*English and agreement between words. For German the factor was also used for compound merging. Prior to training and translation, compound processing was performed, using an empirical method (Koehn and Knight, 2003; Stymne, 2008) that splits words if they can be split into parts that occur in a monolingual corpus, choosing the splitting option with the highest arithmetic mean of its part frequencies in the corpus. We split nouns, adjectives and verbs, into parts that are content words or particles. We imposed a length limit on parts of 3 characters for translation from German and of 6 characters for translation from English, and we had a stop list of parts that often led to errors, such as arische (Aryan) in konsularische (consular). We allowed 10 common letter changes (Langer, 1998) and hyphens at spli</context>
</contexts>
<marker>Koehn, Knight, 2003</marker>
<rawString>Philipp Koehn and Kevin Knight. 2003. Empirical methods for compound splitting. In Proceedings of the 10th Conference of the EACL, pages 187–193, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Josh Schroeder</author>
</authors>
<title>Experiments in domain adaptation for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<pages>224--227</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="3776" citStr="Koehn and Schroeder (2007)" startWordPosition="602" endWordPosition="605">ora provided for the workshop. The translation and reordering models were trained using the bilingual Europarl and news commentary corpora, which we concatenated. We used two sets of language models, one where we first trained two models on Europarl and news commentary, which we then interpolated 1http://www.statmt.org/wmt10/baseline. html 183 Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 183–188, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics with more weight given to the news commentary, using weights from Koehn and Schroeder (2007). The second set of language models were trained on monolingual news data. For tuning we used every second sentence, in total 1025 sentences, of news-test2008. 2.2 Training with Limited Computational Resources One challenge for us was to train the translation sytem with limited computational resources. We trained all systems on one Intel Core 2 CPU, 3.0Ghz, 16 Gb of RAM, 64 bit Linux (RedHat) machine. This constrained the possibilities of using the data provided by the workshop to the full. The main problem was training the language models, since the monolingual data was very large compared to</context>
</contexts>
<marker>Koehn, Schroeder, 2007</marker>
<rawString>Philipp Koehn and Josh Schroeder. 2007. Experiments in domain adaptation for statistical machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, pages 224–227, Prague, Czech Republic.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
</authors>
<title>Chris Dyer, Ondrej Bojar,</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL, demonstration session,</booktitle>
<pages>177--180</pages>
<location>Alexandra</location>
<contexts>
<context position="2582" citStr="Koehn et al., 2007" startWordPosition="412" endWordPosition="415">n, which also reduces the OOV rate. All results in this article are for the development test set newstest2009, on truecased output. We report Bleu scores (Papineni et al., 2002) and Meteor ranking (without WordNet) scores (Agarwal and Lavie, 2008), using percent notation. We also used other metrics, but as they gave similar results they are not reported. For significance testing we used approximate randomization (Riezler and Maxwell, 2005), with p &lt; 0.05. 2 Baseline System The 2010 Liu system is based on the PBSMT baseline system for the WMT shared translation task1. We use the Moses toolkit (Koehn et al., 2007) for decoding and to train translation models, Giza++ (Och and Ney, 2003) for word alignment, and the SRILM toolkit (Stolcke, 2002) to train language models. The main difference to the WMT baseline is that the Liu system is trained on truecased data, as in Koehn et al. (2008), instead of lowercased data. This means that there is no need for a full recasing step after translation, instead we only need to uppercase the first word in each sentence. 2.1 Corpus We participated in the constrained task, where we only trained the Liu system on the news and Europarl corpora provided for the workshop. T</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL, demonstration session, pages 177–180, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Abhishek Arun</author>
<author>Hieu Hoang</author>
</authors>
<title>Towards better machine translation quality for the German-English language pairs.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>139--142</pages>
<location>Columbus, Ohio, USA.</location>
<contexts>
<context position="2858" citStr="Koehn et al. (2008)" startWordPosition="461" endWordPosition="464">also used other metrics, but as they gave similar results they are not reported. For significance testing we used approximate randomization (Riezler and Maxwell, 2005), with p &lt; 0.05. 2 Baseline System The 2010 Liu system is based on the PBSMT baseline system for the WMT shared translation task1. We use the Moses toolkit (Koehn et al., 2007) for decoding and to train translation models, Giza++ (Och and Ney, 2003) for word alignment, and the SRILM toolkit (Stolcke, 2002) to train language models. The main difference to the WMT baseline is that the Liu system is trained on truecased data, as in Koehn et al. (2008), instead of lowercased data. This means that there is no need for a full recasing step after translation, instead we only need to uppercase the first word in each sentence. 2.1 Corpus We participated in the constrained task, where we only trained the Liu system on the news and Europarl corpora provided for the workshop. The translation and reordering models were trained using the bilingual Europarl and news commentary corpora, which we concatenated. We used two sets of language models, one where we first trained two models on Europarl and news commentary, which we then interpolated 1http://ww</context>
<context position="18176" citStr="Koehn et al. (2008)" startWordPosition="2954" endWordPosition="2957">gies. 6 Final Submission For the final Liu shared task submission we used the base+verb+reorder+OOV system for German—*English and the base+verb+OOV system for English—*German, which had the best overall scores considering all metrics. To these systems we added minimum Bayes risk (MBR) decoding (Kumar and Byrne, 2004). In standard decoding, the top suggestion of the translation system is chosen as the system output. In MBR decoding the risk is spread by choosing the translation that is most similar to the N highest scoring translation suggestions from the system, with N = 100, as suggested in Koehn et al. (2008). MBR decoding gave hardly any changes in automatic scores, as shown in Tables 6 and 7. The final system was significantly better than the baseline in all cases, and significantly better than base on Meteor in both translation directions, and on Bleu for translation into English. 7 Conclusions As in Holmqvist et al. (2009) reordering by using Giza++ in two phases had a small, but consistent positive effect. Aligning verbs by co-locating them at the end of sentences had a largely negative effect. However, when output from this method was concatenated with the baseline alignment before extractin</context>
</contexts>
<marker>Koehn, Arun, Hoang, 2008</marker>
<rawString>Philipp Koehn, Abhishek Arun, and Hieu Hoang. 2008. Towards better machine translation quality for the German-English language pairs. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 139–142, Columbus, Ohio, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shankar Kumar</author>
<author>William Byrne</author>
</authors>
<title>Minimum Bayes-risk decoding for statistical machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Human Language Technology Conference of the NAACL,</booktitle>
<pages>169--176</pages>
<location>Boston, Massachusetts, USA.</location>
<contexts>
<context position="17876" citStr="Kumar and Byrne, 2004" startWordPosition="2898" endWordPosition="2901">nly needs a Porter stemmer and a monolingual corpus. Mirkin et al. (2009) used WordNet to replace OOVs by synonyms or hypernyms, and chose the best overall translation partly based on scoring of the source transformations. Our OOV handling could potentially be used in combination with both these strategies. 6 Final Submission For the final Liu shared task submission we used the base+verb+reorder+OOV system for German—*English and the base+verb+OOV system for English—*German, which had the best overall scores considering all metrics. To these systems we added minimum Bayes risk (MBR) decoding (Kumar and Byrne, 2004). In standard decoding, the top suggestion of the translation system is chosen as the system output. In MBR decoding the risk is spread by choosing the translation that is most similar to the N highest scoring translation suggestions from the system, with N = 100, as suggested in Koehn et al. (2008). MBR decoding gave hardly any changes in automatic scores, as shown in Tables 6 and 7. The final system was significantly better than the baseline in all cases, and significantly better than base on Meteor in both translation directions, and on Bleu for translation into English. 7 Conclusions As in</context>
</contexts>
<marker>Kumar, Byrne, 2004</marker>
<rawString>Shankar Kumar and William Byrne. 2004. Minimum Bayes-risk decoding for statistical machine translation. In Proceedings of the 2004 Human Language Technology Conference of the NAACL, pages 169– 176, Boston, Massachusetts, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Langer</author>
</authors>
<title>Zur Morphologie und Semantik von Nominalkomposita.</title>
<date>1998</date>
<booktitle>In Tagungsband der 4. Konferenz zur Verarbeitung nat¨urlicher Sprache (KONVENS),</booktitle>
<pages>83--97</pages>
<location>Bonn, Germany.</location>
<contexts>
<context position="6966" citStr="Langer, 1998" startWordPosition="1125" endWordPosition="1126">al method (Koehn and Knight, 2003; Stymne, 2008) that splits words if they can be split into parts that occur in a monolingual corpus, choosing the splitting option with the highest arithmetic mean of its part frequencies in the corpus. We split nouns, adjectives and verbs, into parts that are content words or particles. We imposed a length limit on parts of 3 characters for translation from German and of 6 characters for translation from English, and we had a stop list of parts that often led to errors, such as arische (Aryan) in konsularische (consular). We allowed 10 common letter changes (Langer, 1998) and hyphens at split points. Compound parts were given a special part-of-speech tag that matches the head word. For translation into German, compound parts were merged into full compounds using a method described in Stymne and Holmqvist (2008), which is based on matching of the special part-of-speech tag for compound parts. A word with a compound POS-tag were merged with the next word, if their POS-tags were matching. Tables 1 and 2 show the results of the additional morphological processing. Adding the sequence models on morphologically enriched partof-speech tags gave a significant improvem</context>
</contexts>
<marker>Langer, 1998</marker>
<rawString>Stefan Langer. 1998. Zur Morphologie und Semantik von Nominalkomposita. In Tagungsband der 4. Konferenz zur Verarbeitung nat¨urlicher Sprache (KONVENS), pages 83–97, Bonn, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shachar Mirkin</author>
<author>Lucia Specia</author>
<author>Nicola Cancedda</author>
<author>Ido Dagan</author>
<author>Marc Dymetman</author>
<author>Idan Szpektor</author>
</authors>
<title>Source-language entailment modeling for translating unknown terms.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>791--799</pages>
<location>Suntec, Singapore.</location>
<contexts>
<context position="17327" citStr="Mirkin et al. (2009)" startWordPosition="2813" endWordPosition="2816">Meteor base 18.50 38.47 + OOV 18.48 38.59 base+verb+reorder 18.73 38.59 + OOV 18.81 38.70 + MBR 18.84 38.75 Table 7: Results for OOV-processing and MBR, German—*English. lation, which, however, is harmful to automatic scores, since the preceding word, technically, which is identical to the reference, is changed into technologically. This work is related to work by Arora et al. (2008), who transformed Hindi OOVs by using morphological analysers, before translation to Japanese. Our work has the advantage that it is more knowledge-lite, as it only needs a Porter stemmer and a monolingual corpus. Mirkin et al. (2009) used WordNet to replace OOVs by synonyms or hypernyms, and chose the best overall translation partly based on scoring of the source transformations. Our OOV handling could potentially be used in combination with both these strategies. 6 Final Submission For the final Liu shared task submission we used the base+verb+reorder+OOV system for German—*English and the base+verb+OOV system for English—*German, which had the best overall scores considering all metrics. To these systems we added minimum Bayes risk (MBR) decoding (Kumar and Byrne, 2004). In standard decoding, the top suggestion of the t</context>
</contexts>
<marker>Mirkin, Specia, Cancedda, Dagan, Dymetman, Szpektor, 2009</marker>
<rawString>Shachar Mirkin, Lucia Specia, Nicola Cancedda, Ido Dagan, Marc Dymetman, and Idan Szpektor. 2009. Source-language entailment modeling for translating unknown terms. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 791– 799, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="2655" citStr="Och and Ney, 2003" startWordPosition="424" endWordPosition="427">e development test set newstest2009, on truecased output. We report Bleu scores (Papineni et al., 2002) and Meteor ranking (without WordNet) scores (Agarwal and Lavie, 2008), using percent notation. We also used other metrics, but as they gave similar results they are not reported. For significance testing we used approximate randomization (Riezler and Maxwell, 2005), with p &lt; 0.05. 2 Baseline System The 2010 Liu system is based on the PBSMT baseline system for the WMT shared translation task1. We use the Moses toolkit (Koehn et al., 2007) for decoding and to train translation models, Giza++ (Och and Ney, 2003) for word alignment, and the SRILM toolkit (Stolcke, 2002) to train language models. The main difference to the WMT baseline is that the Liu system is trained on truecased data, as in Koehn et al. (2008), instead of lowercased data. This means that there is no need for a full recasing step after translation, instead we only need to uppercase the first word in each sentence. 2.1 Corpus We participated in the constrained task, where we only trained the Liu system on the news and Europarl corpora provided for the workshop. The translation and reordering models were trained using the bilingual Eur</context>
<context position="9210" citStr="Och and Ney, 2003" startWordPosition="1484" endWordPosition="1487">; Xia and McCord, 2004). In order to harmonize the word order of the source and target sentence, they applied hand-crafted or automatically induced reordering rules to the source sentences of the training corpus. At decoding time, reordering rules were again applied to input sentences before translation. The positive effects of such methods seem to come from a combination of improved alignment and improved reordering during translation. In contrast, we focus on improving the word alignment by reordering the training corpus. The training corpus is reordered prior to word alignment with Giza++ (Och and Ney, 2003) and then the word links are re-adjusted back to the original word positions. From the re-adjusted corpus, we create phrase tables that allow translation of nonreordered input text. Consequently, our reordering only affects the word alignment and the phrase tables extracted from it. We investigated two ways of reordering. The first method is based on word alignments and the other method is based on moving verbs to similar positions in the source and target sentences. We also investigated different combinations of reorderings and alignments. All results for the systems with improved reordering </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the ACL,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, Pennsylvania, USA.</location>
<contexts>
<context position="2140" citStr="Papineni et al., 2002" startWordPosition="337" endWordPosition="340">rucial step for verb translation since verbs that are far apart are often not aligned at all. We do this mainly by moving verbs to the end of sentences previous to alignment, which we also combine with other alignments. We transform OOVs into known words in a post-processing step, based on casing, stemming, and splitting of hyphenated compounds. In addition, we perform general compound splitting for German both before training and translation, which also reduces the OOV rate. All results in this article are for the development test set newstest2009, on truecased output. We report Bleu scores (Papineni et al., 2002) and Meteor ranking (without WordNet) scores (Agarwal and Lavie, 2008), using percent notation. We also used other metrics, but as they gave similar results they are not reported. For significance testing we used approximate randomization (Riezler and Maxwell, 2005), with p &lt; 0.05. 2 Baseline System The 2010 Liu system is based on the PBSMT baseline system for the WMT shared translation task1. We use the Moses toolkit (Koehn et al., 2007) for decoding and to train translation models, Giza++ (Och and Ney, 2003) for word alignment, and the SRILM toolkit (Stolcke, 2002) to train language models. </context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the ACL, pages 311– 318, Philadelphia, Pennsylvania, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>John T Maxwell</author>
</authors>
<title>On some pitfalls in automatic evaluation and significance testing for MT.</title>
<date>2005</date>
<booktitle>In Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for MT and/or Summarization at the 43th Annual Meeting of the ACL,</booktitle>
<pages>57--64</pages>
<location>Ann Arbor, Michigan, USA.</location>
<contexts>
<context position="2406" citStr="Riezler and Maxwell, 2005" startWordPosition="378" endWordPosition="381">st-processing step, based on casing, stemming, and splitting of hyphenated compounds. In addition, we perform general compound splitting for German both before training and translation, which also reduces the OOV rate. All results in this article are for the development test set newstest2009, on truecased output. We report Bleu scores (Papineni et al., 2002) and Meteor ranking (without WordNet) scores (Agarwal and Lavie, 2008), using percent notation. We also used other metrics, but as they gave similar results they are not reported. For significance testing we used approximate randomization (Riezler and Maxwell, 2005), with p &lt; 0.05. 2 Baseline System The 2010 Liu system is based on the PBSMT baseline system for the WMT shared translation task1. We use the Moses toolkit (Koehn et al., 2007) for decoding and to train translation models, Giza++ (Och and Ney, 2003) for word alignment, and the SRILM toolkit (Stolcke, 2002) to train language models. The main difference to the WMT baseline is that the Liu system is trained on truecased data, as in Koehn et al. (2008), instead of lowercased data. This means that there is no need for a full recasing step after translation, instead we only need to uppercase the fir</context>
</contexts>
<marker>Riezler, Maxwell, 2005</marker>
<rawString>Stefan Riezler and John T. Maxwell. 2005. On some pitfalls in automatic evaluation and significance testing for MT. In Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for MT and/or Summarization at the 43th Annual Meeting of the ACL, pages 57–64, Ann Arbor, Michigan, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
<author>Florian Laws</author>
</authors>
<title>Estimation of conditional probabilities with decision trees and an application to fine-grained pos tagging.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22th International Conference on Computational Linguistics,</booktitle>
<pages>777--784</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="5684" citStr="Schmid and Laws, 2008" startWordPosition="913" endWordPosition="916">phological processing to the baseline system, by training additional sequence models on morphologically enriched part-of-speech tags, and by compound processing for German. We utilized the factored translation framework in Moses, to enrich the baseline system with an additional target sequence model. For English we used part-of-speech tags obtained using TreeTagger (Schmid, 1994), enriched with more finegrained tags for the number of determiners, in order to target more agreement issues, since nouns already have number in the tagset. For German we used morphologically rich tags from RFTagger (Schmid and Laws, 2008), that contains morphological information such as case, number, and gender for nouns and tense for verbs. We used the extra factor in an additional sequence model on the target side, which can improve word order System Bleu Meteor Baseline 13.42 48.83 + morph 13.85 49.69 + comp 14.24 49.41 Table 1: Results for morphological processing, English—*German System Bleu Meteor Baseline 18.34 38.13 + morph 18.39 37.86 + comp 18.50 38.47 Table 2: Results for morphological processing, German—*English and agreement between words. For German the factor was also used for compound merging. Prior to training</context>
</contexts>
<marker>Schmid, Laws, 2008</marker>
<rawString>Helmut Schmid and Florian Laws. 2008. Estimation of conditional probabilities with decision trees and an application to fine-grained pos tagging. In Proceedings of the 22th International Conference on Computational Linguistics, pages 777–784, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Conference on New Methods in Language Processing,</booktitle>
<pages>44--49</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="5444" citStr="Schmid, 1994" startWordPosition="874" endWordPosition="875">he monolingual English news corpus, with nearly 50 million sentences, so we split that corpus into three equal size parts, and trained three models, that were interpolated with equal weights. 3 Morphological Processing We added morphological processing to the baseline system, by training additional sequence models on morphologically enriched part-of-speech tags, and by compound processing for German. We utilized the factored translation framework in Moses, to enrich the baseline system with an additional target sequence model. For English we used part-of-speech tags obtained using TreeTagger (Schmid, 1994), enriched with more finegrained tags for the number of determiners, in order to target more agreement issues, since nouns already have number in the tagset. For German we used morphologically rich tags from RFTagger (Schmid and Laws, 2008), that contains morphological information such as case, number, and gender for nouns and tense for verbs. We used the extra factor in an additional sequence model on the target side, which can improve word order System Bleu Meteor Baseline 13.42 48.83 + morph 13.85 49.69 + comp 14.24 49.41 Table 1: Results for morphological processing, English—*German System</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Proceedings of the International Conference on New Methods in Language Processing, pages 44–49, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM – an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the Seventh International Conference on Spoken Language Processing,</booktitle>
<pages>901--904</pages>
<location>Denver, Colorado, USA.</location>
<contexts>
<context position="2713" citStr="Stolcke, 2002" startWordPosition="435" endWordPosition="436">eport Bleu scores (Papineni et al., 2002) and Meteor ranking (without WordNet) scores (Agarwal and Lavie, 2008), using percent notation. We also used other metrics, but as they gave similar results they are not reported. For significance testing we used approximate randomization (Riezler and Maxwell, 2005), with p &lt; 0.05. 2 Baseline System The 2010 Liu system is based on the PBSMT baseline system for the WMT shared translation task1. We use the Moses toolkit (Koehn et al., 2007) for decoding and to train translation models, Giza++ (Och and Ney, 2003) for word alignment, and the SRILM toolkit (Stolcke, 2002) to train language models. The main difference to the WMT baseline is that the Liu system is trained on truecased data, as in Koehn et al. (2008), instead of lowercased data. This means that there is no need for a full recasing step after translation, instead we only need to uppercase the first word in each sentence. 2.1 Corpus We participated in the constrained task, where we only trained the Liu system on the news and Europarl corpora provided for the workshop. The translation and reordering models were trained using the bilingual Europarl and news commentary corpora, which we concatenated. </context>
<context position="4561" citStr="Stolcke, 2002" startWordPosition="737" endWordPosition="738">g with Limited Computational Resources One challenge for us was to train the translation sytem with limited computational resources. We trained all systems on one Intel Core 2 CPU, 3.0Ghz, 16 Gb of RAM, 64 bit Linux (RedHat) machine. This constrained the possibilities of using the data provided by the workshop to the full. The main problem was training the language models, since the monolingual data was very large compared to the bilingual data. In order to train language models that were both fast at runtime, and possible to train with the available memory, we chose to use the SRILM toolkit (Stolcke, 2002), with entropy-based pruning, with 10−8 as a threshold. To reduce the model size we also used lower order models for the large corpus; 4-grams instead of 5-grams for words and 6-grams instead of 7-grams for the morphological models. It was still impossible to train on the monolingual English news corpus, with nearly 50 million sentences, so we split that corpus into three equal size parts, and trained three models, that were interpolated with equal weights. 3 Morphological Processing We added morphological processing to the baseline system, by training additional sequence models on morphologic</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM – an extensible language modeling toolkit. In Proceedings of the Seventh International Conference on Spoken Language Processing, pages 901–904, Denver, Colorado, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Stymne</author>
<author>Maria Holmqvist</author>
</authors>
<title>Processing of Swedish compounds for phrase-based statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 12th Annual Conference of the European Association for Machine Translation,</booktitle>
<pages>180--189</pages>
<location>Hamburg, Germany.</location>
<contexts>
<context position="7210" citStr="Stymne and Holmqvist (2008)" startWordPosition="1162" endWordPosition="1165">orpus. We split nouns, adjectives and verbs, into parts that are content words or particles. We imposed a length limit on parts of 3 characters for translation from German and of 6 characters for translation from English, and we had a stop list of parts that often led to errors, such as arische (Aryan) in konsularische (consular). We allowed 10 common letter changes (Langer, 1998) and hyphens at split points. Compound parts were given a special part-of-speech tag that matches the head word. For translation into German, compound parts were merged into full compounds using a method described in Stymne and Holmqvist (2008), which is based on matching of the special part-of-speech tag for compound parts. A word with a compound POS-tag were merged with the next word, if their POS-tags were matching. Tables 1 and 2 show the results of the additional morphological processing. Adding the sequence models on morphologically enriched partof-speech tags gave a significant improvement for translation into German, but similar or worse results as the baseline for translation into English. This is not surprising, since German morphology is more complex than English morphology. The addition of compound processing significant</context>
<context position="13164" citStr="Stymne and Holmqvist, 2008" startWordPosition="2130" endWordPosition="2133">nly verb and base, which was significantly better than base on Meteor. This shows that even though the verb alignments were not good when used in a single system, they still could contribute in a combination system. 5 Preprocessing of OOVs Out-of-vocabulary words, words that have not been seen in the training data, are a problem in statistical machine translation, since no translations have been observed for them. The standard strategy is to transfer them as is to the translation output, which, naive as it sounds, actually works well in some cases, since many OOVs are numbers or proper names (Stymne and Holmqvist, 2008). However, it still results in incomprehensible words in the output in many cases. We have investigated several ways of changing unknown words into similar words that have been seen in the training data, in a preprocessing step. We also considered another OOV problem, number formatting, since it differs between English and German. To address this, we swapped decimal points/commas, and other delimeters for unknown numbers in a post-processing step. In the preprocessing step, we applied a number of transformations to each OOV word, accepting the first applicable transformation that led to a know</context>
</contexts>
<marker>Stymne, Holmqvist, 2008</marker>
<rawString>Sara Stymne and Maria Holmqvist. 2008. Processing of Swedish compounds for phrase-based statistical machine translation. In Proceedings of the 12th Annual Conference of the European Association for Machine Translation, pages 180–189, Hamburg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Stymne</author>
</authors>
<title>German compounds in factored statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of GoTAL – 6th International Conference on Natural Language Processing,</booktitle>
<pages>464--475</pages>
<location>Gothenburg,</location>
<contexts>
<context position="6401" citStr="Stymne, 2008" startWordPosition="1027" endWordPosition="1028">. We used the extra factor in an additional sequence model on the target side, which can improve word order System Bleu Meteor Baseline 13.42 48.83 + morph 13.85 49.69 + comp 14.24 49.41 Table 1: Results for morphological processing, English—*German System Bleu Meteor Baseline 18.34 38.13 + morph 18.39 37.86 + comp 18.50 38.47 Table 2: Results for morphological processing, German—*English and agreement between words. For German the factor was also used for compound merging. Prior to training and translation, compound processing was performed, using an empirical method (Koehn and Knight, 2003; Stymne, 2008) that splits words if they can be split into parts that occur in a monolingual corpus, choosing the splitting option with the highest arithmetic mean of its part frequencies in the corpus. We split nouns, adjectives and verbs, into parts that are content words or particles. We imposed a length limit on parts of 3 characters for translation from German and of 6 characters for translation from English, and we had a stop list of parts that often led to errors, such as arische (Aryan) in konsularische (consular). We allowed 10 common letter changes (Langer, 1998) and hyphens at split points. Compo</context>
</contexts>
<marker>Stymne, 2008</marker>
<rawString>Sara Stymne. 2008. German compounds in factored statistical machine translation. In Proceedings of GoTAL – 6th International Conference on Natural Language Processing, pages 464–475, Gothenburg, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chao Wang</author>
<author>Michael Collins</author>
<author>Philipp Koehn</author>
</authors>
<title>Chinese syntactic reordering for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>737--745</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="8592" citStr="Wang et al., 2007" startWordPosition="1384" endWordPosition="1387">erman, compound processing gave a significant improvement on both metrics compared to the baseline, and on Bleu compared to the system with morphological sequence models. Overall, we believe that both compound splitting and morphology are useful; thus all experiments reported in the sequel are based on the baseline system with morphology models and compound splitting, which we will call base. 4 Improved Alignment by Reordering Previous work has shown that translation quality can be improved by making the source language more similar to the target language, for instance in terms of word order (Wang et al., 2007; Xia and McCord, 2004). In order to harmonize the word order of the source and target sentence, they applied hand-crafted or automatically induced reordering rules to the source sentences of the training corpus. At decoding time, reordering rules were again applied to input sentences before translation. The positive effects of such methods seem to come from a combination of improved alignment and improved reordering during translation. In contrast, we focus on improving the word alignment by reordering the training corpus. The training corpus is reordered prior to word alignment with Giza++ (</context>
</contexts>
<marker>Wang, Collins, Koehn, 2007</marker>
<rawString>Chao Wang, Michael Collins, and Philipp Koehn. 2007. Chinese syntactic reordering for statistical machine translation. In Proc. of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 737–745, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>Michael McCord</author>
</authors>
<title>Improving a statistical MT system with automatically learned rewrite patterns.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics,</booktitle>
<pages>508--514</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="8615" citStr="Xia and McCord, 2004" startWordPosition="1388" endWordPosition="1391">cessing gave a significant improvement on both metrics compared to the baseline, and on Bleu compared to the system with morphological sequence models. Overall, we believe that both compound splitting and morphology are useful; thus all experiments reported in the sequel are based on the baseline system with morphology models and compound splitting, which we will call base. 4 Improved Alignment by Reordering Previous work has shown that translation quality can be improved by making the source language more similar to the target language, for instance in terms of word order (Wang et al., 2007; Xia and McCord, 2004). In order to harmonize the word order of the source and target sentence, they applied hand-crafted or automatically induced reordering rules to the source sentences of the training corpus. At decoding time, reordering rules were again applied to input sentences before translation. The positive effects of such methods seem to come from a combination of improved alignment and improved reordering during translation. In contrast, we focus on improving the word alignment by reordering the training corpus. The training corpus is reordered prior to word alignment with Giza++ (Och and Ney, 2003) and </context>
</contexts>
<marker>Xia, McCord, 2004</marker>
<rawString>Fei Xia and Michael McCord. 2004. Improving a statistical MT system with automatically learned rewrite patterns. In Proceedings of the 20th International Conference on Computational Linguistics, pages 508–514, Geneva, Switzerland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>