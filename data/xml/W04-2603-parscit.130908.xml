<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000022">
<title confidence="0.997917">
A Powerful and General Approach to Context Exploitation in Natural
Language Processing
</title>
<author confidence="0.8935435">
Robert W. Means1*, Syrus C. Nemat-Nasser1,
Adrian T. Fan1, and Robert Hecht-Nielsen2,1
</author>
<affiliation confidence="0.94071625">
Computational Neurobiology
Institute for Neural Computation
ECE Department
University of California, San Diego
</affiliation>
<address confidence="0.937286">
La Jolla, CA 92093-0407
</address>
<email confidence="0.972656">
rh-n@ucsd.edu
</email>
<address confidence="0.897652333333333">
1 Fair Isaac Corporation 2
3661 Valley Centre Drive
San Diego, CA 92130
</address>
<email confidence="0.996283">
*rwm@fairisaac.com
</email>
<sectionHeader confidence="0.995582" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999929875">
In natural language, the meaning of a lexeme
often varies due to the specific surrounding
context. Computational approaches to natural
language processing can benefit from a reli-
able, long-range-context-dependent represen-
tation of the meaning of each lexeme that
appears in a given sentence. We have devel-
oped a general new technique that produces a
context-dependent ‘meaning’ representation
for a lexeme in a specific surrounding context.
The ‘meaning’ of a lexeme in a specific con-
text is represented by a list of semantically re-
placeable elements the members of which are
other lexemes from our experimental lexicon.
We have performed experiments with a lexi-
con composed of individual English words
and also with a lexicon of individual words
and selected phrases. The resulting lists can be
used to compare the ‘meaning’ of conceptual
units (individual words or frequently-
occurring phrases) in different contexts and
also can serve as features for machine learning
approaches to classify semantic roles and rela-
tionships.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999887145454545">
Statistical natural language approaches build models
based on annotated corpora as well as unlabeled cor-
pora. The latter, requiring unsupervised knowledge ac-
quisition, has the advantage of larger training sets—it is
possible to exploit corpora composed of billions of
words. A number of researchers have observed that such
use of very large corpora improves the stability of statis-
tical models (e.g. Banko and Brill, 2001).
The mathematical procedures employed here are based
upon Hecht-Nielsen’s neuroscience theory of cognition
(Hecht-Nielsen, 2003). In a nutshell, this theory holds
that cognition is based upon a procedure of ruling out all
unreasonable conclusions and then deciding, of the re-
maining conclusions, which are the least worst ones.
This mathematical symbolic predictive technique is
called confabulation. The knowledge employed by con-
fabulation is vast quantities of conditional probabilities
for pairs of symbols. This knowledge, which is of no
value for reasoning or probabilistic inference, is readily
obtainable. Hecht-Nielsen’s discovery is that, given the
proper coding of a problem into symbols, confabulation
works essentially as well as reasoning would if we were
in possession of the necessary ‘omniscient’ knowledge
that reasoning requires. Unfortunately, ‘omniscient’
knowledge is not practically obtainable, thereby making
attempts to implement reasoning, in any form, futile.
Confabulation, on the other hand, although it does re-
quire storage and use of large volumes of knowledge, is
simple and practical (e.g., see Table 5 for the number of
items of knowledge used in the experiments reported
here). Confabulation provides an explicit mechanism
that can now be used to build artificial intelligence.
Our approach to ‘meaning’ representation for lex-
emes is to provide a set of similar elements that are
grammatically and/or semantically interchangeable with
a given lexeme. Others have constructed lexical similar-
ity clusters using order-dependent co-occurrence statis-
tics, particularly with N-gram models—see Brown et al.
(1992) for an example where words are sorted into ex-
clusive classes based on bigram statistics. The occur-
rence statistics of bigrams do stabilize for frequent
words given a training corpus of hundreds of millions of
words. However, beyond tri-grams, the theoretical size
of a training corpus required for completeness is unrea-
sonable. Our method uses only pairwise conditionals.
To analyze a given text stream, we use a hierarchy
consisting of a word-level representation and a concep-
tual-unit-level representation to analyze arbitrary sin-
gle-clause English sentences. Each of these representa-
tions uses a lexicon of language element tokens to
encode free text as described below. The representation
of a sentence with two levels of hierarchy at the word
level and the phrase level is consistent with Late As-
signment of Syntax Theory, an analysis by synthesis
model advocated by Townsend and Bever (2001).
</bodyText>
<sectionHeader confidence="0.963384" genericHeader="method">
2 Lexicon Construction
</sectionHeader>
<bodyText confidence="0.99998705">
We construct a case-sensitive word-level lexicon based
on frequency of occurrence in our large English text
corpus of approximately 100 million sentences contain-
ing more than 2.3 billion white-space-separated tokens.
The raw corpus was assembled from a number of
newswire corpora, spanning roughly 14 years beginning
in 1988, and hand-selected modern-English, after 1800,
Gutenberg texts. We limit our lexicon to 63,000 tokens
at which point the frequency rank corresponds to a
minimum of 1000 occurrences.
After construction of our word-level lexicon, we
construct a postword word-level knowledge base for use
in creating a conceptual-unit lexicon. To create this
word-level knowledge base, we count token bigram
occurrences within our corpus and then calculate ante-
cedent support conditional probabilities as follows: For
a given token ti representing the ith word in our lexicon,
for each word lexicon token tj that occurs immediately
following ti in the training corpus, the antecedent sup-
port probability is approximated as:
</bodyText>
<listItem confidence="0.9414365">
• Assume the ith word of a sentence starts a concep-
tual unit;
• As long as p(ith word |(ith+1) word) &gt; T0, the con-
ceptual unit continues up to a maximum length;
• Punctuation marks, such as commas and quota-
tion marks terminate a conceptual unit directly.
</listItem>
<bodyText confidence="0.9999534">
The maximum conceptual unit length and the threshold
T0 have been somewhat arbitrarily chosen as 5 and 0. 02
respectively. We implement a complete frequency sort
of all observed conceptual units in the corpus. All con-
ceptual units with a minimum of 1000 occurrences are
retained. These 63,000 additional tokens are added to
the word level lexicon resulting in a conceptual unit
lexicon with 126,000 unique tokens. Figure 1 illustrates
the segmentation of an example sentence into word-
level tokens and conceptual-unit-level tokens.
</bodyText>
<figureCaption confidence="0.9965815">
Figure 1. Segmentation of a sentence into word
tokens and conceptual unit tokens
</figureCaption>
<equation confidence="0.801083">
p(ti  |tj) ≅ c(ti, tj) c(tj) (1)
3 SRE Expansion
</equation>
<bodyText confidence="0.999746075">
where c(ti, tj) is the count of the times the jth word
follows the ith word in the corpus and c(tj) is the total
count of the jth word in the corpus, excluding occur-
rences immediately following a punctuation mark.
Based on these quantities, ‘meaningful’ knowledge is
identified and assigned non-zero weights in the post-
word knowledge base if it has a co-occurrence count
c(ti, tj)≥3 and antecedent support probability
−4. Approximately 17 million token-
to-token knowledge items satisfied these two condi-
tions.
We compose our conceptual-unit lexicon from the
63,000 word-level tokens plus an additional 63,000
automatically identified conceptual units, each consist-
ing of between two and five word tokens. Conceptual
units are identified using the pairwise postword word-
level knowledge base as follows for each sentence in the
training corpus:
A Semantically Replaceable Element (SRE) is a word
or conceptual unit that can be used as a grammatically-
consistent, semantically similar substitute in a given
linguistic context. An SRE is similar to a synonym.
However, words and conceptual units are rarely exact
synonyms and often have multiple meanings that only
become clear in context. Our SRE expansion method
uses knowledge derived from the entire training corpus
to produce a list of ‘synonyms’ and then uses specific
surrounding context in a sentence to prune this list of
candidates into a list of SREs.
SRE expansion proceeds as follows: A test sentence
without internal punctuation is presented to the system.
This sentence is represented twice, once as a sequence
of individual word tokens and once as a sequence of
conceptual unit tokens (Figure 1). Figure 2 illustrates
the hierarchical architecture used for SRE expansion.
The hierarchy has two layers: a word analysis layer and
a conceptual unit analysis layer. We create knowledge
bases between the tokens in the conceptual unit layer
and the tokens in the word layer in the same manner
described for the postword word-level knowledge base.
</bodyText>
<equation confidence="0.9921905">
i  |tj) 1 . 0 10
&gt; x
t
p(
</equation>
<bodyText confidence="0.999727">
A conceptual unit has connections both to and from its
postwords and prewords. Separate knowledge bases to
and from the conceptual unit layer are created for both
postwords and prewords of conceptual units out to a
distance of plus or minus two words (see Figure 2).
These knowledge bases are normalized to limit the dy-
namic range of the strengths. Normalization proceeds as
follows:
</bodyText>
<listItem confidence="0.835027166666667">
• If ti is not followed by tj at least 3 times in our cor-
pus, the knowledge item is discarded;
• If p(ti  |tj) is less than or equal to a threshold
T1 =1. 0 x 10−4, the knowledge item is discarded;
• The strength Wji to token tj from token ti is calcu-
lated as Wji =log2(p(ti  |tj) / T1) .
</listItem>
<bodyText confidence="0.97516">
Logarithmic scaling of the antecedent support probabil-
ity reflects a biologically-inspired compression of dy-
namic range.
</bodyText>
<figureCaption confidence="0.8969925">
Figure 2. The hierarchical knowledge architecture:
One conceptual unit representation region is used
for SRE expansion along with two preceding word
regions and two postword regions. Solid arrows
indicate independent pairwise unidirectional
knowledge bases. Dashed arrows indicate the cor-
respondence between a conceptual unit and the
individual word tokens from which it is composed.
</figureCaption>
<bodyText confidence="0.99765976">
The knowledge bases between the conceptual unit layer
and the word layer are used to create a list of potential
synonyms. This is done by activating a token for the ith
conceptual unit in the sentence in the conceptual unit
region (Y in Figure 2). The conceptual-unit-to-word
knowledge bases activate other tokens in the four pre-
word and postword regions (X_2, X_1, X+1, and X+2 in
Figure 2). Each token within these regions is activated
with the strength Wji. Those word tokens, in turn, acti-
vate tokens back in the conceptual unit region by means
of the word-to-conceptual-unit knowledge bases. The
result is a set of active tokens in the original conceptual
unit region that are potential synonyms. This process
does not rely on the specific sentence context; it uses the
knowledge bases, trained on the entire corpus, to pro-
duce candidate synonyms. For example, when a word
(e.g. “suit”) is placed on the conceptual unit region, its
preword and postword tokens are ‘excited’ in the word
regions below with strength of excitation equal to the
corresponding weights. Those words in turn excite po-
tential synonyms that have most potential senses in the
conceptual unit region (e.g. lawsuit, jacket). The first
fourteen potential synonyms are listed in Table 1. Other
senses of “suit” are also excited with strengths that de-
pend on their usage in the training corpus.
</bodyText>
<figure confidence="0.619167466666667">
suit
suits
lawsuit
jacket
shirt
pants
lawsuits
jackets
trousers
coat
shirts
sweater
blazer
slacks
civil suit
</figure>
<tableCaption confidence="0.986155">
Table 1. The first fourteen potential synonyms
</tableCaption>
<bodyText confidence="0.966270448275862">
of the conceptual unit “suit”
To perform SRE expansion for a given sentence, we
first generate a list of up to 100 candidate synonyms for
each conceptual unit—It is possible though rare for a
word token to return less than 100 potential synonyms
using the procedure described above. The words sur-
rounding the conceptual unit are then used to remove
entries, pruning the list of potential synonyms. We use
up to two prewords and two postwords. Due to edge
effects at the start and end of the sentence, we always
have 2, 3, or 4 context words. The pruning operation
proceeds in two steps: First, we count the number of
knowledge base connections from the surrounding con-
text words to the actual word in the sentence; these
items of knowledge must be present in the word-to-
conceptual unit knowledge bases (Figure 2). Second, we
‘confirm’ potential synonyms that receive an equal or
greater number of connections from the surrounding
context words. The pruned list is termed an SRE expan-
sion. It tends to have semantic and syntactic agreement
with the given conceptual unit.
Apple filed a suit against IBM
Sun Microsystems had filed a lawsuit against Microsoft AT&amp;T
Compaq alleges a civil suit versus Intel
Intel dismissed a complaint was filed Intel Corp.
IGM settled the suit vs. HewlettPackard
Sun to drop lawsuits filed Dell
Microsoft copyright suits alleging Microsoft
Lotus the lawsuit accusing Oracle
</bodyText>
<table confidence="0.905616583333333">
Digital suits that gave Motorola
Microsoft Corp. classaction lawsuit struggle against Sony
Intel Corp. a petition in federal court Apple Computer
Computer an appeal were filed General Motors
Power a motion charging General Electric
AST a claim against Yugoslavia&apos;s NEC
Genentech civil suits that ended Digital
International Business Machines lawsuit was sparked 3M
Ascend in a suit that followed American Express
MCI a class action brought Philip Morris
AT&amp;T in a lawsuit to oust Procter &amp; Gamble
Motorola the complaint stemming from Kodak
</table>
<tableCaption confidence="0.76053">
Table 2. SRE expansion example: the word “suit” as in lawsuit. The first nineteen expansion terms are
displayed.
</tableCaption>
<subsectionHeader confidence="0.470034">
He wore a suit to the wedding
</subsectionHeader>
<bodyText confidence="0.781663487804878">
Wearing the suit to his birthday
wearing suits to their bridal
wore a jacket to our funeral
wears a coat to the traditional graduation
who wore a white to his own marriage
was wearing a shirt to the military gala
and wearing a black to her cocktail
who wears a gray to a Wedding
donned a helmet to my Christmas
to wear a T-shirt to your mourning
wear camouflage lavish
don inaugural
is wearing black-tie
donning festive
his trademark coronation
he wore prom
shirt glittering
jacket chiffon
trademark evening
Table 3. SRE expansion example: the word “suit” as in clothing. The first nineteen expansion terms
are displayed.
These arbitrarily chosen phrases demonstrate our meaning representation
Those unfairly chose words demonstrated one&apos;s significance representations
Many randomly constructed language to demonstrate to our truth protections
The two automatically shaped songs demonstrates my purpose protection
A few strictly themes demonstrating on our motives treatment
They deliberately symbols illustrate people&apos;s interpretation distribution
You properly rhetoric indicate our commitment dimension expression
The first they have been sentences have demonstrated their sense approximation
carefully images have shown the government&apos;s motives images
should not be poems prove your nature participation
who have been words confirm its commitment dimensions and democratic
should be remarks suggest America&apos;s expression description
are being the word reveal of their phrase supervision
correctly names underscore to their truths recognition
appropriately to describe show the ability insight status
were being texts to prove the administration&apos;s identity constituency
they will be scenes assess the president&apos;s emotion voting
they had been colors underline their skills themes equations
routinely comments reflect Washington&apos;s message immunity
selectively doubts about the party&apos;s vitality disclosure
</bodyText>
<tableCaption confidence="0.995068">
Table 4. SRE expansion example: an arbitrary sentence.
</tableCaption>
<table confidence="0.999761666666667">
Knowledge Base Items of Knowledge
Y to X_2 16,432,495
Y to X_, 16,189,554
Y to X+, 13,594,106
Y to X+2 16,796,927
X_2 to Y 22,451,444
X_, to Y 22,089,368
X+, to Y 17,597,506
X+2 to Y 23,973,514
</table>
<tableCaption confidence="0.999132">
Table 5. Size of knowledge bases used for the
</tableCaption>
<bodyText confidence="0.943783333333333">
SRE expansion
The SRE expansion procedure was applied to 33 sen-
tences which contained a total of 233 words. Each word
had 100 possible synonyms. The average number of
confirmed synonyms due to the surrounding context
was 28.2 with a standard deviation of 35.7. Tables 2, 3,
and 4 present three example sentences that have been
expanded using our method—a maximum of nineteen
expansion terms are displayed.
</bodyText>
<sectionHeader confidence="0.999809" genericHeader="conclusions">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999926823529412">
Our SRE expansion method provides a context-specific
‘meaning’ representation providing application builders
with features that could be applied to problems includ-
ing word sense disambiguation and named entity recog-
nition. Miller et al. (2004) describe a relevant technique
for the latter. To quantify the quality of our SRE expan-
sions will require an end-user application demonstration
that we are unable to provide at this time.
Our approach uses a very large training corpus, a hi-
erarchical architecture, and nine independent pairwise
co-occurrence knowledge bases. Individually, these
components have, in some form, been applied to com-
putational natural language processing by other re-
searchers. However, the combination of these
components in our biologically-inspired framework has
already produced novel methods that may prove useful
to the computational linguistics community.
Our knowledge bases are large, but they are not ex-
haustive. Our confirmation method accommodates a
certain amount of missing knowledge—instances where
two language elements should be linked, but our train-
ing procedure has failed to identify this link. This ap-
proach is a compromise reflecting the fact that our
knowledge bases still need improvement. To fix defi-
ciencies in our current knowledge bases, we require
further development. We do not believe that a pure un-
supervised statistical learning approach will suffice.
Instead, we are working to develop ‘education’ proce-
dures that apply supervised learning and hybrid learning
techniques to improve the quality and completeness of
our pairwise knowledge bases.
The authors wish to acknowledge significant past
and present contributions to this project by Rion L.
Snow and Katherine Mark.
</bodyText>
<sectionHeader confidence="0.99642" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999684235294118">
Banko, Michele and Brill, Eric, “Learning Curves and
Natural Language Disambiguation”, Proceedings of
HLT, pp. 93-99, 2001.
Brown, P.F., V.J. Della Pietra, P.V. deSouza, J.C. Lai,
and R.L. Mercer, “Class-based n-gram models of
natural language”, Association for Computational
Linguistics, 1992.
Hecht-Nielsen, R., “A theory of thalamocortex” In:
Hecht-Nielsen, R. and T. McKenna (Eds.), Compu-
tational Models for Neuroscience, pp. 85–124, Lon-
don: Springer-Verlag, 2003.
Miller, S., Guineness, J., and A. Zamanian, “Name tag-
ging with word clusters and discriminative training”,
To appear in Proceedings of HLT, 2004.
Townsend, David J. and Thomas G. Bever, Sentence
Comprehension, The MIT Press, Cambridge MA,
2001.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.270149">
<title confidence="0.935039666666667">A Powerful and General Approach to Context Exploitation in Natural Language Processing W. Syrus C.</title>
<author confidence="0.63712">T</author>
<author confidence="0.63712">Robert</author>
<affiliation confidence="0.99086225">Computational Neurobiology Institute for Neural Computation ECE Department University of California, San Diego</affiliation>
<address confidence="0.997571">La Jolla, CA 92093-0407</address>
<email confidence="0.999099">rh-n@ucsd.edu</email>
<affiliation confidence="0.56678">1Fair Isaac Corporation</affiliation>
<address confidence="0.996939">3661 Valley Centre Drive San Diego, CA 92130</address>
<abstract confidence="0.9942616">In natural language, the meaning of a lexeme often varies due to the specific surrounding context. Computational approaches to natural language processing can benefit from a reliable, long-range-context-dependent representation of the meaning of each lexeme that appears in a given sentence. We have developed a general new technique that produces a context-dependent ‘meaning’ representation for a lexeme in a specific surrounding context. The ‘meaning’ of a lexeme in a specific conis represented by a list of reelements members of which are other lexemes from our experimental lexicon. We have performed experiments with a lexicon composed of individual English words and also with a lexicon of individual words and selected phrases. The resulting lists can be used to compare the ‘meaning’ of conceptual units (individual words or frequentlyoccurring phrases) in different contexts and also can serve as features for machine learning approaches to classify semantic roles and relationships.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Eric Brill</author>
</authors>
<title>Learning Curves and Natural Language Disambiguation”,</title>
<date>2001</date>
<booktitle>Proceedings of HLT,</booktitle>
<pages>93--99</pages>
<contexts>
<context position="1887" citStr="Banko and Brill, 2001" startWordPosition="279" endWordPosition="282">its (individual words or frequentlyoccurring phrases) in different contexts and also can serve as features for machine learning approaches to classify semantic roles and relationships. 1 Introduction Statistical natural language approaches build models based on annotated corpora as well as unlabeled corpora. The latter, requiring unsupervised knowledge acquisition, has the advantage of larger training sets—it is possible to exploit corpora composed of billions of words. A number of researchers have observed that such use of very large corpora improves the stability of statistical models (e.g. Banko and Brill, 2001). The mathematical procedures employed here are based upon Hecht-Nielsen’s neuroscience theory of cognition (Hecht-Nielsen, 2003). In a nutshell, this theory holds that cognition is based upon a procedure of ruling out all unreasonable conclusions and then deciding, of the remaining conclusions, which are the least worst ones. This mathematical symbolic predictive technique is called confabulation. The knowledge employed by confabulation is vast quantities of conditional probabilities for pairs of symbols. This knowledge, which is of no value for reasoning or probabilistic inference, is readil</context>
</contexts>
<marker>Banko, Brill, 2001</marker>
<rawString>Banko, Michele and Brill, Eric, “Learning Curves and Natural Language Disambiguation”, Proceedings of HLT, pp. 93-99, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>V J Della Pietra</author>
<author>P V deSouza</author>
<author>J C Lai</author>
<author>R L Mercer</author>
</authors>
<title>Class-based n-gram models of natural language”, Association for Computational Linguistics,</title>
<date>1992</date>
<contexts>
<context position="3528" citStr="Brown et al. (1992)" startWordPosition="516" endWordPosition="519">lthough it does require storage and use of large volumes of knowledge, is simple and practical (e.g., see Table 5 for the number of items of knowledge used in the experiments reported here). Confabulation provides an explicit mechanism that can now be used to build artificial intelligence. Our approach to ‘meaning’ representation for lexemes is to provide a set of similar elements that are grammatically and/or semantically interchangeable with a given lexeme. Others have constructed lexical similarity clusters using order-dependent co-occurrence statistics, particularly with N-gram models—see Brown et al. (1992) for an example where words are sorted into exclusive classes based on bigram statistics. The occurrence statistics of bigrams do stabilize for frequent words given a training corpus of hundreds of millions of words. However, beyond tri-grams, the theoretical size of a training corpus required for completeness is unreasonable. Our method uses only pairwise conditionals. To analyze a given text stream, we use a hierarchy consisting of a word-level representation and a conceptual-unit-level representation to analyze arbitrary single-clause English sentences. Each of these representations uses a </context>
</contexts>
<marker>Brown, Pietra, deSouza, Lai, Mercer, 1992</marker>
<rawString>Brown, P.F., V.J. Della Pietra, P.V. deSouza, J.C. Lai, and R.L. Mercer, “Class-based n-gram models of natural language”, Association for Computational Linguistics, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hecht-Nielsen</author>
</authors>
<title>A theory of thalamocortex” In: Hecht-Nielsen,</title>
<date>2003</date>
<booktitle>Computational Models for Neuroscience,</booktitle>
<pages>85--124</pages>
<publisher>Springer-Verlag,</publisher>
<location>London:</location>
<contexts>
<context position="2016" citStr="Hecht-Nielsen, 2003" startWordPosition="296" endWordPosition="297">roaches to classify semantic roles and relationships. 1 Introduction Statistical natural language approaches build models based on annotated corpora as well as unlabeled corpora. The latter, requiring unsupervised knowledge acquisition, has the advantage of larger training sets—it is possible to exploit corpora composed of billions of words. A number of researchers have observed that such use of very large corpora improves the stability of statistical models (e.g. Banko and Brill, 2001). The mathematical procedures employed here are based upon Hecht-Nielsen’s neuroscience theory of cognition (Hecht-Nielsen, 2003). In a nutshell, this theory holds that cognition is based upon a procedure of ruling out all unreasonable conclusions and then deciding, of the remaining conclusions, which are the least worst ones. This mathematical symbolic predictive technique is called confabulation. The knowledge employed by confabulation is vast quantities of conditional probabilities for pairs of symbols. This knowledge, which is of no value for reasoning or probabilistic inference, is readily obtainable. Hecht-Nielsen’s discovery is that, given the proper coding of a problem into symbols, confabulation works essential</context>
</contexts>
<marker>Hecht-Nielsen, 2003</marker>
<rawString>Hecht-Nielsen, R., “A theory of thalamocortex” In: Hecht-Nielsen, R. and T. McKenna (Eds.), Computational Models for Neuroscience, pp. 85–124, London: Springer-Verlag, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Miller</author>
<author>J Guineness</author>
<author>A Zamanian</author>
</authors>
<title>Name tagging with word clusters and discriminative training”, To appear in</title>
<date>2004</date>
<booktitle>Proceedings of HLT,</booktitle>
<contexts>
<context position="16071" citStr="Miller et al. (2004)" startWordPosition="2520" endWordPosition="2523">was applied to 33 sentences which contained a total of 233 words. Each word had 100 possible synonyms. The average number of confirmed synonyms due to the surrounding context was 28.2 with a standard deviation of 35.7. Tables 2, 3, and 4 present three example sentences that have been expanded using our method—a maximum of nineteen expansion terms are displayed. 4 Discussion Our SRE expansion method provides a context-specific ‘meaning’ representation providing application builders with features that could be applied to problems including word sense disambiguation and named entity recognition. Miller et al. (2004) describe a relevant technique for the latter. To quantify the quality of our SRE expansions will require an end-user application demonstration that we are unable to provide at this time. Our approach uses a very large training corpus, a hierarchical architecture, and nine independent pairwise co-occurrence knowledge bases. Individually, these components have, in some form, been applied to computational natural language processing by other researchers. However, the combination of these components in our biologically-inspired framework has already produced novel methods that may prove useful to</context>
</contexts>
<marker>Miller, Guineness, Zamanian, 2004</marker>
<rawString>Miller, S., Guineness, J., and A. Zamanian, “Name tagging with word clusters and discriminative training”, To appear in Proceedings of HLT, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David J Townsend</author>
<author>Thomas G Bever</author>
</authors>
<title>Sentence Comprehension,</title>
<date>2001</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge MA,</location>
<contexts>
<context position="4426" citStr="Townsend and Bever (2001)" startWordPosition="658" endWordPosition="661">ining corpus required for completeness is unreasonable. Our method uses only pairwise conditionals. To analyze a given text stream, we use a hierarchy consisting of a word-level representation and a conceptual-unit-level representation to analyze arbitrary single-clause English sentences. Each of these representations uses a lexicon of language element tokens to encode free text as described below. The representation of a sentence with two levels of hierarchy at the word level and the phrase level is consistent with Late Assignment of Syntax Theory, an analysis by synthesis model advocated by Townsend and Bever (2001). 2 Lexicon Construction We construct a case-sensitive word-level lexicon based on frequency of occurrence in our large English text corpus of approximately 100 million sentences containing more than 2.3 billion white-space-separated tokens. The raw corpus was assembled from a number of newswire corpora, spanning roughly 14 years beginning in 1988, and hand-selected modern-English, after 1800, Gutenberg texts. We limit our lexicon to 63,000 tokens at which point the frequency rank corresponds to a minimum of 1000 occurrences. After construction of our word-level lexicon, we construct a postwor</context>
</contexts>
<marker>Townsend, Bever, 2001</marker>
<rawString>Townsend, David J. and Thomas G. Bever, Sentence Comprehension, The MIT Press, Cambridge MA, 2001.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>