<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011171">
<title confidence="0.975604">
The Excitement Open Platform for Textual Inferences
</title>
<author confidence="0.8378625">
Bernardo Magnini∗, Roberto Zanoli∗, Ido Dagan◦, Kathrin Eichler†, G¨unter Neumann†,
Tae-Gil Noh‡, Sebastian Pado‡, Asher Stern◦, Omer Levy◦
</author>
<affiliation confidence="0.350464">
∗FBK (magnini|zanoli@fbk.eu) ‡Heidelberg, Stuttgart Univ. (pado|noh@cl.uni-heidelberg.de)
</affiliation>
<email confidence="0.367268">
†DFKI (neumann|eichler@dfki.de) ◦Bar Ilan University (dagan|sterna3|omerlevy@cs.biu.ac.il)
</email>
<sectionHeader confidence="0.982697" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999970111111111">
This paper presents the Excitement Open
Platform (EOP), a generic architecture and
a comprehensive implementation for tex-
tual inference in multiple languages. The
platform includes state-of-art algorithms,
a large number of knowledge resources,
and facilities for experimenting and test-
ing innovative approaches. The EOP is
distributed as an open source software.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999889230769231">
In the last decade textual entailment (Dagan et al.,
2009) has been a very active topic in Computa-
tional Linguistics, providing a unifying framework
for textual inference. Several evaluation exercises
have been organized around Recognizing Textual
Entailment (RTE) challenges and many method-
ologies, algorithms and knowledge resources have
been proposed to address the task. However, re-
search in textual entailment is still fragmented and
there is no unifying algorithmic framework nor
software architecture.
In this paper, we present the Excitement Open
Platform (EOP), a generic architecture and a com-
prehensive implementation for multilingual textual
inference which we make available to the scien-
tific and technological communities. To a large
extent, the idea is to follow the successful experi-
ence of the Moses open source platform (Koehn et
al., 2007) in Machine Translation, which has made
a substantial impact on research in that field. The
EOP is the result of a two-year coordinated work
under the international project EXCITEMENT.1 A
consortium of four academic partners has defined
the EOP architectural specifications, implemented
the functional interfaces of the EOP components,
imported existing entailment engines into the EOP
</bodyText>
<footnote confidence="0.902479">
1http://www.excitement-project.eu
</footnote>
<bodyText confidence="0.999643029411765">
and finally designed and implemented a rich envi-
ronment to support open source distribution.
The goal of the platform is to provide function-
ality for the automatic identification of entailment
relations among texts. The EOP is based on a modu-
lar architecture with a particular focus on language-
independent algorithms. It allows developers and
users to combine linguistic pipelines, entailment al-
gorithms and linguistic resources within and across
languages with as little effort as possible. For ex-
ample, different entailment decision approaches
can share the same resources and the same sub-
components in the platform. A classification-based
algorithm can use the distance component of an
edit-distance based entailment decision approach,
and two different approaches can use the same set
of knowledge resources. Moreover, the platform
has various multilingual components for languages
like English, German and Italian. The result is an
ideal software environment for experimenting and
testing innovative approaches for textual inferences.
The EOP is distributed as an open source software2
and its use is open both to users interested in using
inference in applications and to developers willing
to extend the current functionalities.
The paper is structured as follows. Section 2
presents the platform architecture, highlighting
how the EOP component-based approach favors
interoperability. Section 3 provides a picture of
the current population of the EOP in terms of both
entailment algorithms and knowledge resources.
Section 4 introduces expected use cases of the plat-
form. Finally, Section 5 presents the main features
of the open source package.
</bodyText>
<sectionHeader confidence="0.972653" genericHeader="introduction">
2 Architecture
</sectionHeader>
<bodyText confidence="0.984230333333333">
The EOP platform takes as input two text portions,
the first called the Text (abbreviated with T), the
second called the Hypothesis (abbreviated with H).
</bodyText>
<footnote confidence="0.99198">
2http://hltfbk.github.io/
Excitement-Open-Platform/
</footnote>
<page confidence="0.997647">
43
</page>
<affiliation confidence="0.5052495">
Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 43–48,
Baltimore, Maryland USA, June 23-24, 2014. c�2014 Association for Computational Linguistics
</affiliation>
<figureCaption confidence="0.999761">
Figure 1: EOP architecture
</figureCaption>
<bodyText confidence="0.9998587">
The output is an entailment judgement, either ”En-
tailment” if T entails H, or ”NonEntailment” if the
relation does not hold. A confidence score for the
decision is also returned in both cases.
The EOP architecture (Pad´o et al., 2014) is based
on the concept of modularization with pluggable
and replaceable components to enable extension
and customization. The overall structure is shown
in Figure 1 and consists of two main parts. The
Linguistic Analysis Pipeline (LAP) is a series of
linguistic annotation components. The Entailment
Core (EC) performs the actual entailment recog-
nition. This separation ensures that (a) the com-
ponents in the EC only rely on linguistic analysis
in well-defined ways and (b) the LAP and EC can
be run independently of each other. Configuration
files are the principal means of configuring the EOP.
In the rest of this section we first provide an intro-
duction to the LAP, then we move to the EC and
finally describe the configuration files.
</bodyText>
<subsectionHeader confidence="0.998443">
2.1 Linguistic Analysis Pipeline (LAP)
</subsectionHeader>
<bodyText confidence="0.999200636363636">
The Linguistic Analysis Pipeline is a collection of
annotation components for Natural Language Pro-
cessing (NLP) based on the Apache UIMA frame-
work.3 Annotations range from tokenization to
part of speech tagging, chunking, Named Entity
Recognition and parsing. The adoption of UIMA
enables interoperability among components (e.g.,
substitution of one parser by another one) while
ensuring language independence. Input and output
of the components are represented in an extended
version of the DKPro type system based on UIMA
</bodyText>
<footnote confidence="0.969927">
3http://uima.apache.org/
</footnote>
<note confidence="0.6782345">
Common Analysis Structure (CAS) (Gurevych et
al., 2007; Noh and Pad´o, 2013).
</note>
<subsectionHeader confidence="0.986932">
2.2 Entailment Core (EC)
</subsectionHeader>
<bodyText confidence="0.999508288888889">
The Entailment Core performs the actual entail-
ment recognition based on the preprocessed text
made by the Linguistic Analysis Pipeline. It con-
sists of one or more Entailment Decision Algo-
rithms (EDAs) and zero or more subordinate com-
ponents. An EDA takes an entailment decision
(i.e., ”entailment” or ”no entailment”) while com-
ponents provide static and dynamic information for
the EDA.
Entailment Decision Algorithms are at the top
level in the EC. They compute an entailment deci-
sion for a given Text/Hypothesis (T/H) pair, and
can use components that provide standardized al-
gorithms or knowledge resources. The EOP ships
with several EDAs (cf. Section 3).
Scoring Components accept a Text/Hypothesis
pair as an input, and return a vector of scores.
Their output can be used directly to build minimal
classifier-based EDAs forming complete RTE sys-
tems. An extended version of these components are
the Distance Components that can produce normal-
ized and unnormalized distance/similarity values
in addition to the score vector.
Annotation Components can be used to add dif-
ferent annotations to the Text/Hypothesis pairs. An
example of such a type of component is one that
produces word or phrase alignments between the
Text and the Hypothesis.
Lexical Knowledge Components describe se-
mantic relationships between words. In the
EOP, this knowledge is represented as directed
rules made up of two word–POS pairs, where
the LHS (left-hand side) entails the RHS (right-
hand side), e.g., (shooting star, Noun) =⇒
(meteorite, Noun). Lexical Knowledge Compo-
nents provide an interface that allows for (a) listing
all RHS for a given LHS; (b) listing all LHS for
a given RHS; and (c) checking for an entailment
relation for a given LHS–RHS pair. The interface
also wraps all major lexical knowledge sources cur-
rently used in RTE research, including manually
constructed ontologies like WordNet, and encyclo-
pedic resources like Wikipedia.
Syntactic Knowledge Components capture en-
tailment relationships between syntactic and
</bodyText>
<figure confidence="0.999607818181818">
Raw Data
Decision
Dynamic and Static Components
(Algorithms and Knowledge)
Linguistic
Analysis Components
Entailment Decision
Algorithm (EDA)
Linguistic Analysis
Pipeline (LAP)
Entailment Core (EC)
</figure>
<page confidence="0.996281">
44
</page>
<bodyText confidence="0.998353181818182">
lexical-syntactic expressions. We represent such
relationships by entailment rules that link (option-
ally lexicalized) dependency tree fragments that
can contain variables as nodes. For example, the
rule fall of X =⇒ X falls, or X sells Y to Z =⇒
Z buys Y from X express general paraphrasing pat-
terns at the predicate-argument level that cannot be
captured by purely lexical rules. Formally, each
syntactic rule consists of two dependency tree frag-
ments plus a mapping from the variables of the
LHS tree to the variables of the RHS tree.4
</bodyText>
<subsectionHeader confidence="0.998754">
2.3 Configuration Files
</subsectionHeader>
<bodyText confidence="0.999947909090909">
The EC components can be combined into actual
inference engines through configuration files which
contain information to build a complete inference
engine. A configuration file completely describes
an experiment. For example, it specifies the re-
sources that the selected EDA has to use and the
data set to be analysed. The LAP needed for data
set preprocessing is another parameter that can be
configured too. The platform ships with a set of
predefined configuration files accompanied by sup-
porting documentation.
</bodyText>
<sectionHeader confidence="0.952517" genericHeader="method">
3 Entailment Algorithms and Resources
</sectionHeader>
<bodyText confidence="0.999923666666667">
This section provides a description of the Entail-
ment Algorithms and Knowledge Resources that
are distributed with the EOP.
</bodyText>
<subsectionHeader confidence="0.996868">
3.1 Entailment Algorithms
</subsectionHeader>
<bodyText confidence="0.987672040816327">
The current version of the EOP platform ships with
three EDAs corresponding to three different ap-
proaches to RTE: an EDA based on transformations
between T and H, an EDA based on edit distance
algorithms, and a classification based EDA using
features extracted from T and H.
Transformation-based EDA applies a sequence
of transformations on T with the goal of making
it identical to H. If each transformation preserves
(fully or partially) the meaning of the original text,
then it can be concluded that the modified text
(which is actually the Hypothesis) can be inferred
from the original one. Consider the following sim-
ple example where the text is ”The boy was located
by the police” and the Hypothesis is ”The child
was found by the police”. Two transformations for
”boy” —* ”child” and ”located” —* ”found” do the
job.
4Variables of the LHS may also map to null, when material
of the LHS must be present but is deleted in the inference step.
In the EOP we include a transformation based
inference system that adopts the knowledge based
transformations of Bar-Haim et al. (2007), while in-
corporating a probabilistic model to estimate trans-
formation confidences. In addition, it includes a
search algorithm which finds an optimal sequence
of transformations for any given T/H pair (Stern et
al., 2012).
Edit distance EDA involves using algorithms
casting textual entailment as the problem of map-
ping the whole content of T into the content of H.
Mappings are performed as sequences of editing
operations (i.e., insertion, deletion and substitu-
tion) on text portions needed to transform T into H,
where each edit operation has a cost associated with
it. The underlying intuition is that the probability
of an entailment relation between T and H is related
to the distance between them; see Kouylekov and
Magnini (2005) for a comprehensive experimental
study.
Classification based EDA uses a Maximum En-
tropy classifier to combine the outcomes of sev-
eral scoring functions and to learn a classification
model for recognizing entailment. The scoring
functions extract a number of features at various
linguistic levels (bag-of-words, syntactic dependen-
cies, semantic dependencies, named entities). The
approach was thoroughly described in Wang and
Neumann (2007).
</bodyText>
<subsectionHeader confidence="0.998205">
3.2 Knowledge Resources
</subsectionHeader>
<bodyText confidence="0.999898736842105">
As described in Section 2.2, knowledge resources
are crucial to recognize cases where T and H use
different textual expressions (words, phrases) while
preserving entailment. The EOP platform includes
a wide range of knowledge resources, including lex-
ical and syntactic resources, where some of them
are grabbed from manual resources, like dictionar-
ies, while others are learned automatically. Many
EOP resources are inherited from pre-existing RTE
systems migrated into the EOP platform, but now
use the same interfaces, which makes them acces-
sible in a uniform fashion.
There are about two dozen lexical (e.g. word-
nets) and syntactic resources for three languages
(i.e. English, Italian and German). However,
since there is still a clear predominance of En-
glish resources, the platform includes lexical and
syntactic knowledge mining tools to bootstrap re-
sources from corpora, both for other languages and
</bodyText>
<page confidence="0.996033">
45
</page>
<table confidence="0.9999504">
EDA Accuracy / F1
Transformation-based English RTE-3 67.13%
Transformation-based English RTE-6 49.55%
Edit-Distance English RTE-3 64.38%
Edit-Distance German RTE-3 59.88%
Edit-Distance Italian RTE-3 63.50%
Classification-based English RTE-3 65.25%
Classification-based German RTE-3 63.75%
Median of RTE-3 (English) submissions 61.75%
Median of RTE-6 (English) submissions 33.72%
</table>
<tableCaption confidence="0.999815">
Table 1: EDAs results
</tableCaption>
<bodyText confidence="0.9999375">
for specific domains. Particularly, the EOP plat-
form includes a language independent tool to build
Wikipedia resources (Shnarch et al., 2009), as well
as a language-independent framework for building
distributional similarity resources like DIRT (Lin
and Pantel, 2002) and Lin similarity(Lin, 1998).
</bodyText>
<subsectionHeader confidence="0.983558">
3.3 EOP Evaluation
</subsectionHeader>
<bodyText confidence="0.999983333333333">
Results for the three EDAs included in the EOP
platform are reported in Table 1. Each line rep-
resents an EDA, the language and the dataset
on which the EDA was evaluated. For brevity,
we omit here the knowledge resources used for
each EDA, even though knowledge configuration
clearly affects performance. The evaluations were
performed on RTE-3 dataset (Giampiccolo et al.,
2007), where the goal is to maximize accuracy. We
(manually) translated it to German and Italian for
evaluations: in both cases the results fix a refer-
ence for the two languages. The two new datasets
for German and English are available both as part
of the EOP distribution and independently5. The
transformation-based EDA was also evaluated on
RTE-6 dataset (Bentivogli et al., 2010), in which
the goal is to maximize the F1 measure.
The results of the included EDAs are higher than
median values of participated systems in RTE-3,
and they are competing with state-of-the-arts in
RTE-6 results. To the best of our knowledge, the
results of the EDAs as provided in the platform are
the highest among those available as open source
systems for the community.
</bodyText>
<sectionHeader confidence="0.995498" genericHeader="method">
4 Use Cases
</sectionHeader>
<bodyText confidence="0.9246535">
We see four primary use cases for the EOP. Their
requirements were reflected in our design choices.
Use Case 1: Applied Textual Entailment. This
category covers users who are not interested in the
</bodyText>
<footnote confidence="0.865074">
5http://www.excitement-project.eu/
index.php/results
</footnote>
<bodyText confidence="0.993955346938776">
details of RTE but who are interested in an NLP
task in which textual entailment can take over part
of or all of the semantic processing, such as Ques-
tion Answering or Intelligent Tutoring. Such users
require a system that is as easy to deploy as possi-
ble, which motivates our offer of the EOP platform
as a library. They also require a system that pro-
vides good quality at a reasonable efficiency as
well as guidance as to the best choice of parame-
ters. The latter point is realized through our results
archive in the official EOP Wiki on the EOP site.
Use Case 2: Textual Entailment Development.
This category covers researchers who are interested
in Recognizing Textual Entailment itself, for exam-
ple with the goal of developing novel algorithms
for detecting entailment. In contrast to the first
category, this group need to look ”under the hood”
of the EOP platform and access the source code of
the EOP. For this reason, we have spent substantial
effort to provide the code in a well-structured and
well-documented form.
A subclass of this group is formed by researchers
who want to set up a RTE infrastructure for lan-
guages in which it does not yet exist (that is, al-
most all languages). The requirements of this class
of users comprises clearly specified procedures to
replace the Linguistic Analysis Pipeline, which are
covered in our documentation, and simple methods
to acquire knowledge resources for these languages
(assuming that the EDAs themselves are largely
language-independent). These are provided by the
language-independent knowledge acquisition tools
which we offer alongside the platform (cf. Section
3.2).
Use Case 3: Lexical Semantics Evaluation. A
third category consists of researchers whose pri-
mary interest is in (lexical) semantics.
As long as their scientific results can be phrased
in terms of semantic similarities or inference rules,
the EOP platform can be used as a simple and stan-
dardized workbench for these results that indicates
the impact that the semantic knowledge under con-
sideration has on deciding textual entailment. The
main requirement for this user group is the simple
integration of new knowledge resources into the
EOP platform. This is catered for through the defi-
nition of the generic knowledge component inter-
faces (cf. Section 2.2) and detailed documentation
on how to implement these interfaces.
</bodyText>
<page confidence="0.998455">
46
</page>
<bodyText confidence="0.99970475">
Use Case 4: Educational Use. The fourth and
final use case is as an educational tool to support
academic courses and projects on Recognizing Tex-
tual Entailment and inference more generally. This
use case calls, in common with the others, for easy
usability and flexibility. Specifically for this use
case, we have also developed a series of tutorials
aimed at acquainting new users with the EOP plat-
form through a series of increasingly complexity
exercises that cover all areas of the EOP. We are
also posting proposals for projects to extend the
EOP on the EOP Wiki.
</bodyText>
<sectionHeader confidence="0.995371" genericHeader="method">
5 EOP Distribution
</sectionHeader>
<bodyText confidence="0.9973498125">
The EOP infrastructure follows state-of-the-art soft-
ware engineering standards to support both users
and developers with a flexible, scalable and easy to
use software environment. In addition to communi-
cation channels, like the mailing list and the issue
tracking system, the EOP infrastructure comprises
the following set of facilities.
Version Control System: We use GitHub,6 a
web-based hosting service for code and documen-
tation storage, development, and issue tracking.
Web Site: The GitHub Automatic Page Genera-
tor was used to build the EOP web site and Wiki,
containing a general introduction to the software
platform, the terms of its license, mailing lists to
contact the EOP members and links to the code
releases.
Documentation: Both user and developer docu-
mentation is available from Wiki pages; the pages
are written with the GitHub Wiki Editor and hosted
on the GitHub repository. The documentation in-
cludes a Quick Start guide to start using the EOP
platform right away, and a detailed step by step
tutorial.
Results Archive: As a new feature for commu-
nity building, EOP users can, and are encouraged
to, share their results: the platform configuration
files used to produce results as well as contact infor-
mation can be saved and archived into a dedicated
page on the EOP GitHub repository. That allows
other EOP users to replicate experiments under
the same condition and/or avoid doing experiments
that have already been done.
</bodyText>
<footnote confidence="0.880544">
6https://github.com/
</footnote>
<bodyText confidence="0.99854124">
Build Automation Tool: The EOP has been de-
veloped as a Maven7 multi-modules project, with
all modules sharing the same Maven standard struc-
ture, making it easier to find files in the project once
one is used to Maven.
Maven Artifacts Repository: Using a Maven
repository has a twofold goal: (i) to serve as an
internal private repository of all software libraries
used within the project (libraries are binary files
and should not be stored under version control sys-
tems, which are intended to be used with text files);
(ii) to make the produced EOP Maven artifacts
available (i.e., for users who want to use the EOP
as a library in their own code). We use Artifactory8
repository manager to store produced artifacts.
Continuous Integration: The EOP uses Jenk-
ins9 for Continuous Integration, a software develop-
ment practice where developers of a team integrate
their work frequently (e.g., daily).
Code Quality Tool: Ensuring the quality of the
produced software is one of the most important
aspects of software engineering. The EOP uses
tools like PMD10 that can automatically be run
during development to help the developers check
the quality of their software.
</bodyText>
<subsectionHeader confidence="0.992697">
5.1 Project Repository
</subsectionHeader>
<bodyText confidence="0.999966636363636">
The EOP Java source code is hosted on the EOP
Github repository and managed using Git. The
repository consists of three main branches: the
release branch contains the code that is supposed to
be in a production-ready state, whereas the master
branch contains the code to be incorporated into the
next release. When the source code in the master
branch reaches a stable point and is ready to be
released, all of the changes are merged back into
release. Finally, the gh-pages branch contains the
web site pages.
</bodyText>
<subsectionHeader confidence="0.997252">
5.2 Licensing
</subsectionHeader>
<bodyText confidence="0.9999628">
The software of the platform is released under the
terms of General Public License (GPL) version
3.11 The platform contains both components and
resources designed by the EOP developers, as well
as others that are well known and freely available
</bodyText>
<footnote confidence="0.9999284">
7http://maven.apache.org/
8http://www.jfrog.com/
9http://jenkins-ci.org/
10http://pmd.sourceforge.net
11http://www.gnu.org/licenses/gpl.html
</footnote>
<page confidence="0.99931">
47
</page>
<bodyText confidence="0.999982">
in the NLP research community. Additional com-
ponents and resources whose license is not compat-
ible with the EOP license have to be downloaded
and installed separately by the user.
</bodyText>
<sectionHeader confidence="0.998618" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999991666666667">
This paper has presented the main characteristics
of Excitement Open Platform platform, a rich envi-
ronment for experimenting and evaluating textual
entailment systems. On the software side, the EOP
is a complex endeavor to integrate tools and re-
sources in Computational Linguistics, including
pipelines for three languages, three pre-existing
entailment engines, and about two dozens of lex-
ical and syntactic resources. The EOP assumes a
clear and modular separation between linguistic
annotations, entailment algorithms and knowledge
resources which are used by the algorithms. A
relevant benefit of the architectural design is that
a high level of interoperability is reached, provid-
ing a stimulating environment for new research in
textual inferences.
The EOP platform has been already tested in sev-
eral pilot research projects and educational courses,
and it is currently distributed as open source soft-
ware under the GPL-3 license. To the best of our
knowledge, the entailment systems and their con-
figurations provided in the platform are the best
systems available as open source for the commu-
nity. As for the future, we are planning several
initiatives for the promotion of the platform in the
research community, as well as its active experi-
mentation in real application scenarios.
</bodyText>
<sectionHeader confidence="0.998226" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99978">
This work was partially supported by the EC-
funded project EXCITEMENT (FP7ICT-287923).
</bodyText>
<sectionHeader confidence="0.999278" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999918272727273">
Roy Bar-Haim, Ido Dagan, Iddo Greental, and Eyal
Shnarch. 2007. Semantic inference at the lexical-
syntactic level. In Proceedings of AAAI, pages 871–
876, Vancouver, BC.
Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa Trang
Dang, and Danilo Giampiccolo. 2010. The Sixth
PASCAL Recognizing Textual Entailment Chal-
lenge. In Proceedings of TAC, Gaithersburg, MD.
Ido Dagan, Bill Dolan, Bernardo Magnini, and Dan
Roth. 2009. Recognizing textual entailment: Ratio-
nal, evaluation and approaches. Journal of Natural
Language Engineering, 15(4):i–xvii.
Danilo Giampiccolo, Bernardo Magnini, Ido Dagan,
and Bill Dolan. 2007. The Third PASCAL Recog-
nising Textual Entailment Challenge. In Proceed-
ings of the ACL-PASCAL Workshop on Textual En-
tailment and Paraphrasing, Prague, Czech Repub-
lic.
Iryna Gurevych, Max M¨uhlh¨auser, Christof M¨uller,
J¨urgen Steimle, Markus Weimer, and Torsten Zesch.
2007. Darmstadt knowledge processing repository
based on UIMA. In Proceedings of the First Work-
shop on Unstructured Information Management Ar-
chitecture (UIMA@GSCL 2007), T¨ubingen, Ger-
many.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proceedings of the ACL demo session, pages 177–
180, Prague, Czech Republic.
Milen Kouylekov and Bernardo Magnini. 2005. Rec-
ognizing textual entailment with tree edit distance al-
gorithms. In Proceedings of the First PASCAL Chal-
lenges Workshop on Recognising Textual Entailment,
pages 17–20, Southampton, UK.
Dekang Lin and Patrick Pantel. 2002. Discovery of
Inference Rules for Question Answering. Journal of
Natural Language Engineering, 7(4):343–360.
Dekang Lin. 1998. Automatic retrieval and clustering
of similar words. In Proceedings of ACL/COLING,
pages 768–774, Montr´eal, Canada.
Tae-Gil Noh and Sebastian Pad´o. 2013. Using
UIMA to structure an open platform for textual en-
tailment. In Proceedings of the 3rd Workshop on
Unstructured Information Management Architecture
(UIMA@GSCL 2013).
Sebastian Pad´o, Tae-Gil Noh, Asher Stern, Rui Wang,
and Roberto Zanoli. 2014. Design and realiza-
tion of a modular architecture for textual entailment.
Journal of Natural Language Engineering. doi:
10.1017/S1351324913000351.
Eyal Shnarch, Libby Barak, and Ido Dagan. 2009. Ex-
tracting lexical reference rules from Wikipedia. In
Proceedings of ACL-IJCNLP, pages 450–458, Sin-
gapore.
Asher Stern, Roni Stern, Ido Dagan, and Ariel Felner.
2012. Efficient search for transformation-based in-
ference. In Proceedings of ACL, pages 283–291,
Jeju Island, South Korea.
Rui Wang and G¨unter Neumann. 2007. Recogniz-
ing textual entailment using a subsequence kernel
method. In Proceedings of AAAI, pages 937–945,
Vancouver, BC.
</reference>
<page confidence="0.999353">
48
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.896303">
<title confidence="0.999965">The Excitement Open Platform for Textual Inferences</title>
<author confidence="0.9746465">Roberto Ido Kathrin G¨unter Sebastian Asher Omer</author>
<affiliation confidence="0.9996775">Stuttgart Univ. Ilan University</affiliation>
<abstract confidence="0.9939622">This paper presents the Excitement Open Platform (EOP), a generic architecture and a comprehensive implementation for textual inference in multiple languages. The platform includes state-of-art algorithms, a large number of knowledge resources, and facilities for experimenting and testing innovative approaches. The EOP is distributed as an open source software.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Roy Bar-Haim</author>
</authors>
<title>Ido Dagan, Iddo Greental, and Eyal Shnarch.</title>
<date>2007</date>
<booktitle>In Proceedings of AAAI,</booktitle>
<pages>871--876</pages>
<location>Vancouver, BC.</location>
<marker>Bar-Haim, 2007</marker>
<rawString>Roy Bar-Haim, Ido Dagan, Iddo Greental, and Eyal Shnarch. 2007. Semantic inference at the lexicalsyntactic level. In Proceedings of AAAI, pages 871– 876, Vancouver, BC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luisa Bentivogli</author>
<author>Peter Clark</author>
<author>Ido Dagan</author>
<author>Hoa Trang Dang</author>
<author>Danilo Giampiccolo</author>
</authors>
<title>The Sixth PASCAL Recognizing Textual Entailment Challenge.</title>
<date>2010</date>
<booktitle>In Proceedings of TAC,</booktitle>
<location>Gaithersburg, MD.</location>
<contexts>
<context position="13978" citStr="Bentivogli et al., 2010" startWordPosition="2108" endWordPosition="2111">aset on which the EDA was evaluated. For brevity, we omit here the knowledge resources used for each EDA, even though knowledge configuration clearly affects performance. The evaluations were performed on RTE-3 dataset (Giampiccolo et al., 2007), where the goal is to maximize accuracy. We (manually) translated it to German and Italian for evaluations: in both cases the results fix a reference for the two languages. The two new datasets for German and English are available both as part of the EOP distribution and independently5. The transformation-based EDA was also evaluated on RTE-6 dataset (Bentivogli et al., 2010), in which the goal is to maximize the F1 measure. The results of the included EDAs are higher than median values of participated systems in RTE-3, and they are competing with state-of-the-arts in RTE-6 results. To the best of our knowledge, the results of the EDAs as provided in the platform are the highest among those available as open source systems for the community. 4 Use Cases We see four primary use cases for the EOP. Their requirements were reflected in our design choices. Use Case 1: Applied Textual Entailment. This category covers users who are not interested in the 5http://www.excit</context>
</contexts>
<marker>Bentivogli, Clark, Dagan, Dang, Giampiccolo, 2010</marker>
<rawString>Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa Trang Dang, and Danilo Giampiccolo. 2010. The Sixth PASCAL Recognizing Textual Entailment Challenge. In Proceedings of TAC, Gaithersburg, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
<author>Bernardo Magnini</author>
<author>Dan Roth</author>
</authors>
<title>Recognizing textual entailment: Rational, evaluation and approaches.</title>
<date>2009</date>
<journal>Journal of Natural Language Engineering,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="819" citStr="Dagan et al., 2009" startWordPosition="97" endWordPosition="100">gnini|zanoli@fbk.eu) ‡Heidelberg, Stuttgart Univ. (pado|noh@cl.uni-heidelberg.de) †DFKI (neumann|eichler@dfki.de) ◦Bar Ilan University (dagan|sterna3|omerlevy@cs.biu.ac.il) Abstract This paper presents the Excitement Open Platform (EOP), a generic architecture and a comprehensive implementation for textual inference in multiple languages. The platform includes state-of-art algorithms, a large number of knowledge resources, and facilities for experimenting and testing innovative approaches. The EOP is distributed as an open source software. 1 Introduction In the last decade textual entailment (Dagan et al., 2009) has been a very active topic in Computational Linguistics, providing a unifying framework for textual inference. Several evaluation exercises have been organized around Recognizing Textual Entailment (RTE) challenges and many methodologies, algorithms and knowledge resources have been proposed to address the task. However, research in textual entailment is still fragmented and there is no unifying algorithmic framework nor software architecture. In this paper, we present the Excitement Open Platform (EOP), a generic architecture and a comprehensive implementation for multilingual textual infe</context>
</contexts>
<marker>Dagan, Dolan, Magnini, Roth, 2009</marker>
<rawString>Ido Dagan, Bill Dolan, Bernardo Magnini, and Dan Roth. 2009. Recognizing textual entailment: Rational, evaluation and approaches. Journal of Natural Language Engineering, 15(4):i–xvii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Giampiccolo</author>
<author>Bernardo Magnini</author>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
</authors>
<title>The Third PASCAL Recognising Textual Entailment Challenge.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="13599" citStr="Giampiccolo et al., 2007" startWordPosition="2046" endWordPosition="2049">independent tool to build Wikipedia resources (Shnarch et al., 2009), as well as a language-independent framework for building distributional similarity resources like DIRT (Lin and Pantel, 2002) and Lin similarity(Lin, 1998). 3.3 EOP Evaluation Results for the three EDAs included in the EOP platform are reported in Table 1. Each line represents an EDA, the language and the dataset on which the EDA was evaluated. For brevity, we omit here the knowledge resources used for each EDA, even though knowledge configuration clearly affects performance. The evaluations were performed on RTE-3 dataset (Giampiccolo et al., 2007), where the goal is to maximize accuracy. We (manually) translated it to German and Italian for evaluations: in both cases the results fix a reference for the two languages. The two new datasets for German and English are available both as part of the EOP distribution and independently5. The transformation-based EDA was also evaluated on RTE-6 dataset (Bentivogli et al., 2010), in which the goal is to maximize the F1 measure. The results of the included EDAs are higher than median values of participated systems in RTE-3, and they are competing with state-of-the-arts in RTE-6 results. To the be</context>
</contexts>
<marker>Giampiccolo, Magnini, Dagan, Dolan, 2007</marker>
<rawString>Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. 2007. The Third PASCAL Recognising Textual Entailment Challenge. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
<author>Max M¨uhlh¨auser</author>
<author>Christof M¨uller</author>
<author>J¨urgen Steimle</author>
<author>Markus Weimer</author>
<author>Torsten Zesch</author>
</authors>
<title>Darmstadt knowledge processing repository based on UIMA.</title>
<date>2007</date>
<booktitle>In Proceedings of the First Workshop on Unstructured Information Management Architecture (UIMA@GSCL</booktitle>
<location>T¨ubingen, Germany.</location>
<marker>Gurevych, M¨uhlh¨auser, M¨uller, Steimle, Weimer, Zesch, 2007</marker>
<rawString>Iryna Gurevych, Max M¨uhlh¨auser, Christof M¨uller, J¨urgen Steimle, Markus Weimer, and Torsten Zesch. 2007. Darmstadt knowledge processing repository based on UIMA. In Proceedings of the First Workshop on Unstructured Information Management Architecture (UIMA@GSCL 2007), T¨ubingen, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL demo session,</booktitle>
<pages>177--180</pages>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="1619" citStr="Koehn et al., 2007" startWordPosition="216" endWordPosition="219"> Textual Entailment (RTE) challenges and many methodologies, algorithms and knowledge resources have been proposed to address the task. However, research in textual entailment is still fragmented and there is no unifying algorithmic framework nor software architecture. In this paper, we present the Excitement Open Platform (EOP), a generic architecture and a comprehensive implementation for multilingual textual inference which we make available to the scientific and technological communities. To a large extent, the idea is to follow the successful experience of the Moses open source platform (Koehn et al., 2007) in Machine Translation, which has made a substantial impact on research in that field. The EOP is the result of a two-year coordinated work under the international project EXCITEMENT.1 A consortium of four academic partners has defined the EOP architectural specifications, implemented the functional interfaces of the EOP components, imported existing entailment engines into the EOP 1http://www.excitement-project.eu and finally designed and implemented a rich environment to support open source distribution. The goal of the platform is to provide functionality for the automatic identification o</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of the ACL demo session, pages 177– 180, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milen Kouylekov</author>
<author>Bernardo Magnini</author>
</authors>
<title>Recognizing textual entailment with tree edit distance algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of the First PASCAL Challenges Workshop on Recognising Textual Entailment,</booktitle>
<pages>17--20</pages>
<location>Southampton, UK.</location>
<contexts>
<context position="11124" citStr="Kouylekov and Magnini (2005)" startWordPosition="1686" endWordPosition="1689"> search algorithm which finds an optimal sequence of transformations for any given T/H pair (Stern et al., 2012). Edit distance EDA involves using algorithms casting textual entailment as the problem of mapping the whole content of T into the content of H. Mappings are performed as sequences of editing operations (i.e., insertion, deletion and substitution) on text portions needed to transform T into H, where each edit operation has a cost associated with it. The underlying intuition is that the probability of an entailment relation between T and H is related to the distance between them; see Kouylekov and Magnini (2005) for a comprehensive experimental study. Classification based EDA uses a Maximum Entropy classifier to combine the outcomes of several scoring functions and to learn a classification model for recognizing entailment. The scoring functions extract a number of features at various linguistic levels (bag-of-words, syntactic dependencies, semantic dependencies, named entities). The approach was thoroughly described in Wang and Neumann (2007). 3.2 Knowledge Resources As described in Section 2.2, knowledge resources are crucial to recognize cases where T and H use different textual expressions (words</context>
</contexts>
<marker>Kouylekov, Magnini, 2005</marker>
<rawString>Milen Kouylekov and Bernardo Magnini. 2005. Recognizing textual entailment with tree edit distance algorithms. In Proceedings of the First PASCAL Challenges Workshop on Recognising Textual Entailment, pages 17–20, Southampton, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Discovery of Inference Rules for Question Answering.</title>
<date>2002</date>
<journal>Journal of Natural Language Engineering,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="13169" citStr="Lin and Pantel, 2002" startWordPosition="1977" endWordPosition="1980">TE-3 67.13% Transformation-based English RTE-6 49.55% Edit-Distance English RTE-3 64.38% Edit-Distance German RTE-3 59.88% Edit-Distance Italian RTE-3 63.50% Classification-based English RTE-3 65.25% Classification-based German RTE-3 63.75% Median of RTE-3 (English) submissions 61.75% Median of RTE-6 (English) submissions 33.72% Table 1: EDAs results for specific domains. Particularly, the EOP platform includes a language independent tool to build Wikipedia resources (Shnarch et al., 2009), as well as a language-independent framework for building distributional similarity resources like DIRT (Lin and Pantel, 2002) and Lin similarity(Lin, 1998). 3.3 EOP Evaluation Results for the three EDAs included in the EOP platform are reported in Table 1. Each line represents an EDA, the language and the dataset on which the EDA was evaluated. For brevity, we omit here the knowledge resources used for each EDA, even though knowledge configuration clearly affects performance. The evaluations were performed on RTE-3 dataset (Giampiccolo et al., 2007), where the goal is to maximize accuracy. We (manually) translated it to German and Italian for evaluations: in both cases the results fix a reference for the two languag</context>
</contexts>
<marker>Lin, Pantel, 2002</marker>
<rawString>Dekang Lin and Patrick Pantel. 2002. Discovery of Inference Rules for Question Answering. Journal of Natural Language Engineering, 7(4):343–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proceedings of ACL/COLING,</booktitle>
<pages>768--774</pages>
<location>Montr´eal, Canada.</location>
<contexts>
<context position="13199" citStr="Lin, 1998" startWordPosition="1983" endWordPosition="1984">RTE-6 49.55% Edit-Distance English RTE-3 64.38% Edit-Distance German RTE-3 59.88% Edit-Distance Italian RTE-3 63.50% Classification-based English RTE-3 65.25% Classification-based German RTE-3 63.75% Median of RTE-3 (English) submissions 61.75% Median of RTE-6 (English) submissions 33.72% Table 1: EDAs results for specific domains. Particularly, the EOP platform includes a language independent tool to build Wikipedia resources (Shnarch et al., 2009), as well as a language-independent framework for building distributional similarity resources like DIRT (Lin and Pantel, 2002) and Lin similarity(Lin, 1998). 3.3 EOP Evaluation Results for the three EDAs included in the EOP platform are reported in Table 1. Each line represents an EDA, the language and the dataset on which the EDA was evaluated. For brevity, we omit here the knowledge resources used for each EDA, even though knowledge configuration clearly affects performance. The evaluations were performed on RTE-3 dataset (Giampiccolo et al., 2007), where the goal is to maximize accuracy. We (manually) translated it to German and Italian for evaluations: in both cases the results fix a reference for the two languages. The two new datasets for G</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. In Proceedings of ACL/COLING, pages 768–774, Montr´eal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tae-Gil Noh</author>
<author>Sebastian Pad´o</author>
</authors>
<title>Using UIMA to structure an open platform for textual entailment.</title>
<date>2013</date>
<booktitle>In Proceedings of the 3rd Workshop on Unstructured Information Management Architecture (UIMA@GSCL</booktitle>
<marker>Noh, Pad´o, 2013</marker>
<rawString>Tae-Gil Noh and Sebastian Pad´o. 2013. Using UIMA to structure an open platform for textual entailment. In Proceedings of the 3rd Workshop on Unstructured Information Management Architecture (UIMA@GSCL 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Tae-Gil Noh</author>
<author>Asher Stern</author>
<author>Rui Wang</author>
<author>Roberto Zanoli</author>
</authors>
<title>Design and realization of a modular architecture for textual entailment.</title>
<date>2014</date>
<journal>Journal of Natural Language Engineering.</journal>
<volume>doi:</volume>
<pages>10--1017</pages>
<marker>Pad´o, Noh, Stern, Wang, Zanoli, 2014</marker>
<rawString>Sebastian Pad´o, Tae-Gil Noh, Asher Stern, Rui Wang, and Roberto Zanoli. 2014. Design and realization of a modular architecture for textual entailment. Journal of Natural Language Engineering. doi: 10.1017/S1351324913000351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eyal Shnarch</author>
<author>Libby Barak</author>
<author>Ido Dagan</author>
</authors>
<title>Extracting lexical reference rules from Wikipedia.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP,</booktitle>
<pages>450--458</pages>
<contexts>
<context position="13042" citStr="Shnarch et al., 2009" startWordPosition="1960" endWordPosition="1963">ing tools to bootstrap resources from corpora, both for other languages and 45 EDA Accuracy / F1 Transformation-based English RTE-3 67.13% Transformation-based English RTE-6 49.55% Edit-Distance English RTE-3 64.38% Edit-Distance German RTE-3 59.88% Edit-Distance Italian RTE-3 63.50% Classification-based English RTE-3 65.25% Classification-based German RTE-3 63.75% Median of RTE-3 (English) submissions 61.75% Median of RTE-6 (English) submissions 33.72% Table 1: EDAs results for specific domains. Particularly, the EOP platform includes a language independent tool to build Wikipedia resources (Shnarch et al., 2009), as well as a language-independent framework for building distributional similarity resources like DIRT (Lin and Pantel, 2002) and Lin similarity(Lin, 1998). 3.3 EOP Evaluation Results for the three EDAs included in the EOP platform are reported in Table 1. Each line represents an EDA, the language and the dataset on which the EDA was evaluated. For brevity, we omit here the knowledge resources used for each EDA, even though knowledge configuration clearly affects performance. The evaluations were performed on RTE-3 dataset (Giampiccolo et al., 2007), where the goal is to maximize accuracy. W</context>
</contexts>
<marker>Shnarch, Barak, Dagan, 2009</marker>
<rawString>Eyal Shnarch, Libby Barak, and Ido Dagan. 2009. Extracting lexical reference rules from Wikipedia. In Proceedings of ACL-IJCNLP, pages 450–458, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asher Stern</author>
<author>Roni Stern</author>
<author>Ido Dagan</author>
<author>Ariel Felner</author>
</authors>
<title>Efficient search for transformation-based inference.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>283--291</pages>
<location>Jeju Island, South</location>
<contexts>
<context position="10608" citStr="Stern et al., 2012" startWordPosition="1601" endWordPosition="1604">” and the Hypothesis is ”The child was found by the police”. Two transformations for ”boy” —* ”child” and ”located” —* ”found” do the job. 4Variables of the LHS may also map to null, when material of the LHS must be present but is deleted in the inference step. In the EOP we include a transformation based inference system that adopts the knowledge based transformations of Bar-Haim et al. (2007), while incorporating a probabilistic model to estimate transformation confidences. In addition, it includes a search algorithm which finds an optimal sequence of transformations for any given T/H pair (Stern et al., 2012). Edit distance EDA involves using algorithms casting textual entailment as the problem of mapping the whole content of T into the content of H. Mappings are performed as sequences of editing operations (i.e., insertion, deletion and substitution) on text portions needed to transform T into H, where each edit operation has a cost associated with it. The underlying intuition is that the probability of an entailment relation between T and H is related to the distance between them; see Kouylekov and Magnini (2005) for a comprehensive experimental study. Classification based EDA uses a Maximum Ent</context>
</contexts>
<marker>Stern, Stern, Dagan, Felner, 2012</marker>
<rawString>Asher Stern, Roni Stern, Ido Dagan, and Ariel Felner. 2012. Efficient search for transformation-based inference. In Proceedings of ACL, pages 283–291, Jeju Island, South Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Wang</author>
<author>G¨unter Neumann</author>
</authors>
<title>Recognizing textual entailment using a subsequence kernel method.</title>
<date>2007</date>
<booktitle>In Proceedings of AAAI,</booktitle>
<pages>937--945</pages>
<location>Vancouver, BC.</location>
<contexts>
<context position="11564" citStr="Wang and Neumann (2007)" startWordPosition="1748" endWordPosition="1751">ssociated with it. The underlying intuition is that the probability of an entailment relation between T and H is related to the distance between them; see Kouylekov and Magnini (2005) for a comprehensive experimental study. Classification based EDA uses a Maximum Entropy classifier to combine the outcomes of several scoring functions and to learn a classification model for recognizing entailment. The scoring functions extract a number of features at various linguistic levels (bag-of-words, syntactic dependencies, semantic dependencies, named entities). The approach was thoroughly described in Wang and Neumann (2007). 3.2 Knowledge Resources As described in Section 2.2, knowledge resources are crucial to recognize cases where T and H use different textual expressions (words, phrases) while preserving entailment. The EOP platform includes a wide range of knowledge resources, including lexical and syntactic resources, where some of them are grabbed from manual resources, like dictionaries, while others are learned automatically. Many EOP resources are inherited from pre-existing RTE systems migrated into the EOP platform, but now use the same interfaces, which makes them accessible in a uniform fashion. The</context>
</contexts>
<marker>Wang, Neumann, 2007</marker>
<rawString>Rui Wang and G¨unter Neumann. 2007. Recognizing textual entailment using a subsequence kernel method. In Proceedings of AAAI, pages 937–945, Vancouver, BC.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>