<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.067061">
<title confidence="0.997003">
Eliminating Redundancy by Spectral Relaxation for Multi-Document
Summarization
</title>
<author confidence="0.989669">
Fumiyo Fukumoto Akina Sakai Yoshimi Suzuki
</author>
<affiliation confidence="0.9974">
Interdisciplinary Graduate School of Medicine and Engineering
University of Yamanashi
</affiliation>
<email confidence="0.990389">
{fukumoto, t05kg014, ysuzuki}@yamanashi.ac.jp
</email>
<sectionHeader confidence="0.997334" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999966466666667">
This paper focuses on redundancy, over-
lapping information in multi-documents,
and presents a method for detecting
salient, key sentences from documents
that discuss the same event. To elimi-
nate redundancy, we used spectral clus-
tering and classified each sentence into
groups, each of which consists of seman-
tically related sentences. Then, we ap-
plied link analysis, the Markov Random
Walk (MRW) Model to deciding the im-
portance of a sentence within documents.
The method was tested on the NTCIR
evaluation data, and the result shows the
effectiveness of the method.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999984403225807">
With the exponential growth of information on the
Internet, it is becoming increasingly difficult for a
user to read and understand all the materials from
a series of large-scale document streams that is po-
tentially of interest. Multi-document summariza-
tion is an issue to attack the problem. It differs
from single document summarization in that it is
important to identify differences and similarities
across documents. Graph-based ranking methods,
such as PageRank (Page et al., 1998) and HITS
(Kleinberg, 1999) have recently applied and been
successfully used for multi-document summariza-
tion (Erkan and Radev, 2004; Mihalcea and Tarau,
2005). Given a set of documents, the model con-
structs graph consisting vertices and edges where
vertices are sentences and edges reflect the rela-
tionships between sentences. The model then ap-
plies a graph-based ranking method to obtain the
rank scores for the sentences. Finally, the sen-
tences with large rank scores are chosen into the
summary. However, when they are strung to-
gether, the resulting summary still contains much
overlapping information. Because all the sen-
tences are ranked based on a sentence as unit of
information. Therefore, for example, semanti-
cally related two sentences with “high recommen-
dation” are ranked with high score, and thus are
regarded as a summary sentence. To attack the
problem, Wan et al. proposed two models, i.e., the
Cluster-based conditional Markov Random Walk
model and the Cluster-based HITS model, both
make use of the theme clusters in the document set
(Wan and Yang, 2008). Their model first groups
documents into theme clusters by using a simple
clustering method, k-means. Next, the model con-
structs a directed or undirected graph to reflect the
relationships between sentences and clusters by
using link analysis. They reported that the results
on the DUC2001 and DUC2002 datasets showed
the effectiveness of their models. However, one
of the problems using multivariate clustering such
as k-means is that it is something of a black art
when applied to high-dimensional data. The avail-
able techniques for searching this large space do
not offer guarantees of global optimality, thus the
resulting summary still contains much overlapping
information, especially for a large amount of doc-
uments.
This paper focuses extractive summarization,
and present a method for detecting key sentences
from documents that discuss the same event. Like
Wan et al.’s approach, we applied link analysis,
the Markov Random Walk (MRW) model (Bre-
maud, 1999) to a graph consisting sentences and
clusters. To attack the problem dealing with the
high dimensional spaces, we applied spectral clus-
tering technique (Ng et al., 2002) to the sentences
from a document set. Spectral clustering is a trans-
formation of the original sentences into a set of or-
thogonal eigenvectors. We worked in the space de-
fined by the first few eigenvectors, using standard
clustering techniques in the transformed space.
</bodyText>
<page confidence="0.980716">
98
</page>
<note confidence="0.832613">
Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 98–102,
Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.968417" genericHeader="method">
2 Spectral Clustering
</sectionHeader>
<bodyText confidence="0.996760166666667">
Similar to other clustering algorithms, the spec-
tral clustering takes as input a matrix formed from
a pairwise similarity function over a set of data
points. Given a set of points S = {s1, · · · , sn}
in a high dimensional space, the algorithm is as
follows:
</bodyText>
<listItem confidence="0.8473405">
1. Form a distance matrix D E R2. We used
cosine similarity as a distance measure.
2. D is transformed to an affinity matrix Aij.
�
</listItem>
<equation confidence="0.953950333333333">
2
Aij = exp(− σ2 ), if i 7 j
0, otherwise.
</equation>
<bodyText confidence="0.871282">
Q2 is a parameter and controls the rate at
which affinity drops off with distance.
</bodyText>
<listItem confidence="0.999085">
3. The matrix L = D−1/2AD−1/2 is created. D
is a diagonal matrix whose (i,i) element is the
sum of A’s i-th row.
4. The eigenvectors and eigenvalues of L are
computed, and a new matrix is created from
the vectors associated with the number of l
largest eigenvalues.
5. Each item now has a vector of l coordinates
in the transformed space. These vectors are
normalized to unit length.
</listItem>
<equation confidence="0.9969994">
p(i→j|clus(si), clus(sj))
f(i→j|clus(si), clus(sj)) , if Ef =~ 0
f(i→k|clus(si), clus(sk)) (1)
0 , otherwise.
f(i —* j  |clus(si), clus(sj)) in formula (1) refers
</equation>
<bodyText confidence="0.998551666666667">
to the weight between two sentences si and sj,
conditioned on the two clusters containing the two
sentences, and defined by formula (2).
</bodyText>
<equation confidence="0.993924333333333">
f(i→j|clus(si), clus(sj))
= f(i→j)·{λ·π(clus(si))·ω(clus(si))
+(1 − λ)·π(clus(sj))·ω(clus(sj))} (2)
</equation>
<bodyText confidence="0.9913174">
λ E [0, 1] in formula (2) is the combination
weight controlling the relative contributions from
the source cluster and the destination cluster.
7r(clus(si)) denotes the value indicating the im-
portance of the cluster clus(si) in the document
set D. Similarly, w(si, clus(si)) refers to the sim-
ilarity value between the sentence si and its cluster
clus(si). These values are obtained by using the
cosine similarity. The new row-normalized matrix
M is defined by formula (3).
</bodyText>
<equation confidence="0.98346">
Mij = p(i → j  |clus(si), clus(sj)) (3)
</equation>
<bodyText confidence="0.999976">
The saliency scores for the sentences are com-
puted based on formula (3) by using the iterative
form in formula (4).
</bodyText>
<equation confidence="0.8240025">
= I
|S|
E
k_1
6. K-means is applied to S in the l-dimensional EScore(si) = µ Score(sj) · Mji + (1 − µ)
space. alljoi  |S  |(4)
</equation>
<sectionHeader confidence="0.977422" genericHeader="method">
3 Cluster-based Link Analysis
</sectionHeader>
<bodyText confidence="0.99919895">
The link analysis we used is an approach presented
by Wan et. al (Wan and Yang, 2008). The model
called “Cluster-based Conditional Markov Ran-
dom Walk Model” incorporates the cluster-level
information into the process of sentence rank-
ing. The model is summarized as follows: Let
7r(clus(si)) E [0, 1] be the importance of clus-
ter clus(si) in the whole document set D. Let
also w(si, clus(si)) E [0, 1] denote the strength of
the correlation between sentence si and its cluster
clus(si). clus(si) refers to the cluster containing
sentence si. The transition probability from si to
sj is defined by formula (1).
μ in formula (4) is the damping factor, which we
set to 0.85. The above process can be considered
as a Markov chain by taking the sentences as the
states and the final transition matrix is given by
formula (5), and each score of the sentences is ob-
tained by the principle eigenvector of the new tran-
sition matrix A.
</bodyText>
<equation confidence="0.995263">
A = µMT + (1 −I eeT
 |V (5)
</equation>
<bodyText confidence="0.99929975">
e� in formula (5) is a column vector with all ele-
ments equal to 1. We selected a certain number
of sentences according to rank score into the sum-
mary.
</bodyText>
<page confidence="0.997403">
99
</page>
<sectionHeader confidence="0.999675" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.9980431">
We had an experiment by using the NTCIR-31
SUMM to evaluate our approach. NTCIR-3 has
two tasks, single, and multi-document summariza-
tion. The data is collected from two years(1998-
1999) Mainichi Japanese Newspaper articles. We
used multi-document summarization task. There
are two types of gold standard data provided to
human judges, FBFREE DryRun and FormalRun,
each of which consists of 30 topics. There are two
types of correct summary according to the charac-
ter length, i.e., “long” and “short”. All documents
were tagged by a morphological analysis, ChaSen
(Matsumoto et al., 1997) and noun words are ex-
tracted.
We used FormalRun consisting of 30 topics as a
test data. Similarly, we randomly chose 10 topics
from the FBFREE DryRun data to tuning a param-
eter Q in Spectral Clustering, and the number of l
in the l-dimensional space obtained by the Spec-
tral Clustering. Q is searched in steps of 0.01 from
1.0 to 5.0. l in the l-dimensional space is searched
in steps 10% from 0 to 80% against the total num-
ber of words in the training data. The size that op-
timized the average F-score of 10 topics was cho-
sen. Here, F-score is the standard measure used
in the clustering algorithm, and it combines recall
and precision with an equal weight. Precision is a
ratio of the number of correct pair of sentences ob-
tained by the k-means divided by the total number
of pairs obtained by the k-means. Recall indicates
a ratio of the number of correct pair of sentences
obtained by the k-means divided by the total num-
ber of correct pairs. As a result, Q and l are set to
4.5 and 80%, respectively.
It is difficult to predict the actual cluster number
k in a given input sentences to produce optimal
results. The usual drawback in many clustering
algorithms is that they cannot give a valid criterion
for measuring class structure. Therefore, similar
to Wan et. al’s method (Wan and Yang, 2008), we
typically set the number of k of expected clusters
√
as N where N is the number of all sentences
in the document set. We used these values of the
parameters and evaluated by using test data.
We used two evaluation measures. One is co-
sine similarity between the generated summary by
the system and the human generated summary.
Another is ROUGE score used in DUC (Liu and
Hovy, 2003).
</bodyText>
<footnote confidence="0.925886">
1http://research.nii.ac.jp/ntcir/
</footnote>
<bodyText confidence="0.99991352173913">
We used a word instead of n-gram sequence in
formula (6). The results are shown in Table 1. “#
of doc” and “# of sent” refer to the average number
of documents and sentences, respectively. “# of
sum” denotes to the average number of summary
sentences provided by NTCIR3 SUMM. “cos” and
“ROUGE” refer to the results evaluated by using
cosine, and ROUGE score, respectively. “MRW”
indicates the results obtained by directly applying
MRW model to the input sentences.
We can see from Table 1 that our approach
(Spectral) outperforms the baselines, “MRW”
and “k-means”, regardless of the types of sum-
mary (long/short) and evaluation measures (co-
sine/ROUGE). The results obtained by three ap-
proaches show that “short” was better than “long”.
This indicates that the rank score of correct sen-
tences within the candidate sentences obtained
by the MRW model works well. Comparing
the results evaluated by “ROUGE” were worse
than those of “cos” at any approaches. One rea-
son is that the difference of summarization tech-
nique, i.e., our work is extractive summarization,
while the gold standard data provided by NTCIR-
3 SUMM is the abstracts written by human pro-
fessionals. As a result, a large number of words
in a candidate summary are extracted by our ap-
proaches. For future work, it is necessary to ex-
tend our method to involve paraphrasing for ex-
tracted key sentences to reduce the gap between
automatically generated summaries and human-
written abstracts (Barzilay et al., 1993; Carenini
and Cheung, 2008).
It is interesting to note how our approach affects
for the number of sentences as an input. Figure
1 illustrates the results of summary “long” with
evaluated ROUGE score. We can see from Figure
1 that our approach is more robust than k-means
and the MRW model, even for a large number of
input data. We have seen the same observations
from other three results, i.e., the results of short
and long with evaluated cos and short with evalu-
ated ROUGE.
We recall that the cluster number k is set to the
square root of the sentence number. We tested dif-
ferent number of k to see how the cluster number
</bodyText>
<figure confidence="0.994824857142857">
E
ROUGE = s∈Cand
E Countmat�h(ngram)
ngram∈s
E E Count(ngram)
s∈Cand ngram∈s
(6)
</figure>
<page confidence="0.947935">
100
</page>
<tableCaption confidence="0.999771">
Table 1: Results against 30 topics
</tableCaption>
<table confidence="0.99533225">
# of doc # of sent # of sum cos ROUGE
MRW k-means Spectral MRW k-means Spectral
Short 7.5 83.0 11.9 0.431 0.575 0.632 0.330 0.334 0.360
Long 20.4 0.371 0.408 0.477 0.180 0.186 0.209
</table>
<figure confidence="0.996394814814815">
0.4
0.35
0.3
0.25
ROUGE
0.2
0.15
0.1
0.05
0 50 100 150 200 250 300 350
# of sentences
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
ratio of the # of k
k-means
Spectral
MRW
Avg. ROUGE 0.21
0.205
0.2
0.195
0.19
0.185
0.18
0.175
MRW
k-means
Spectral
</figure>
<figureCaption confidence="0.999964">
Figure 1: Long with ROUGE vs. # of sentences
</figureCaption>
<bodyText confidence="0.99995965">
affects the summarization performance. In the ex-
periment, we set k = r∗  |N  |where r is a pa-
rameter ranged from 0 to 1 (Wan and Yang, 2008).
Because of space is limited, we report only the re-
sult with summary “long” and ROUGE score. The
result is shown in Figure 2.
Overall the results obtained by our approach
and k-means outperformed the results obtained
by directly applying MRW model, while the re-
sults by k-means was worse than the results by
MRW model when the ratio of the number of sen-
tences was larger than 0.8. This shows that cluster-
based summarization is effective reduce redun-
dancy, overlapping information. Figure 2 also
shows that our approach always outperforms, re-
gardless of how many number of sentences were
used. This indicates that the MRW model with
spectral clustering is more robust than that with
the baseline, k-means, with respect to the differ-
ent number of clusters.
</bodyText>
<sectionHeader confidence="0.999531" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.992405">
We have developed an approach to detect salient
sentences from documents that discuss the same
</bodyText>
<figureCaption confidence="0.5572215">
Figure 2: Long with ROUGE score measure vs. #
of k
</figureCaption>
<bodyText confidence="0.998923">
event. The results showed the effectiveness of the
method. Future work will include: (i) compar-
ing other approaches that uses link analysis to re-
duce redundancy, such as (Zhu et al., 2007), (ii)
applying the method to the DUC evaluation data
for quantitative evaluation, and (iii) extending the
method to classify sentences into more than one
classes by using soft-clustering techniques such as
EM (Dempster et al., 1977) and fuzzy c-means al-
gorithms (Zhang and Wang, 2007).
</bodyText>
<sectionHeader confidence="0.999016" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999388727272727">
R. Barzilay, K. R. McKeown, and M. Elhadad.
1993. Information Fusion in the Context of Multi-
document Summarization. In Proc. of the 37th An-
nual Meeting of the Association for Computational
Linguistics, pages 550–557.
P. Bremaud. 1999. Markov Chains: Gibbs Fields,
Monte Carlo Simulation, and Queues. Springer-
Verlag.
G. Carenini and J. C. K. Cheung. 2008. Extractive
vs. NLG-based Abstractive Summarization of Eval-
uative Text: The Effect of Corpus Controversiality.
</reference>
<page confidence="0.976158">
101
</page>
<reference confidence="0.999420276595745">
In Proc. of the 5th International Natural Language
Generation Conference, pages 33–41.
A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977.
Maximum Likelihood from Incomplete Data Via the
EM Algorithm. Royal Statistical Society, 39(B):1–
38.
G. Erkan and D. Radev. 2004. LexPageRank: Prestige
in Multi-document Text Summarization. In Proc. of
the 2004 Conference on Empirical Methods in Nat-
ural Language Processing, pages 365–371.
J. M. Kleinberg. 1999. Authoritative Sources in a Hy-
perlinked Environment. ACM, 46(5):604–632.
C-Y. Liu and E. H. Hovy. 2003. Automatic Evalu-
ation of Summaries Using N-gram Co-occurrence
Statistics. In Proc. of Human Language Technolo-
gies: The Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 71–78.
Y. Matsumoto, A. Kitauchi, T. Yamashita, Y. Haruno,
O. Imaichi, and T. Imamura. 1997. Japanese Mor-
phological Analysis System Chasen Mannual.
R. Mihalcea and P. Tarau. 2005. Language Indepen-
dent Extractive Summarization. In In Proc. of the
43nd Annual Meeting of the Association for Compu-
tational Linguistics, pages 49–52.
A. Y. Ng, M. I. Jordan, and Y. Weiss. 2002. On Spec-
tral Clustering: Analysis and an Algorithm, vol-
ume 14. MIT Press.
L. Page, S. Brin, R. Motwani, and T. Winograd. 1998.
The Pagerank Citation Ranking: Bringing Order to
the Web. In Technical report, Stanford Digital Li-
braries.
X. Wan and J. Yang. 2008. Multi-document Sum-
marization Using Cluster-based Link Analysis. In
Proc. of the 31st Annual International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval, pages 299–306.
Z. Zhang and R. Wang. 2007. Identification of
Overlapping Community Structure in Complex Net-
works using Fuzzy C-means Clustering. PHYSICA,
A(374):483–490.
X. Zhu, A. Goldberg, J. V. Gael, and D. Andrzejew-
ski. 2007. Improving Diversity in Ranking using
Absorbing Random Walks. In In Human Language
technologies: The Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, pages 97–104.
</reference>
<page confidence="0.998621">
102
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.838022">
<title confidence="0.9996305">Eliminating Redundancy by Spectral Relaxation for Summarization</title>
<author confidence="0.995623">Fumiyo Fukumoto Akina Sakai Yoshimi Suzuki</author>
<affiliation confidence="0.992661">Interdisciplinary Graduate School of Medicine and University of Yamanashi</affiliation>
<email confidence="0.867828">t05kg014,</email>
<abstract confidence="0.9987441875">This paper focuses on redundancy, overlapping information in multi-documents, and presents a method for detecting from documents that discuss the same event. To eliminate redundancy, we used spectral clustering and classified each sentence into groups, each of which consists of semantically related sentences. Then, we applied link analysis, the Markov Random Walk (MRW) Model to deciding the importance of a sentence within documents. The method was tested on the NTCIR evaluation data, and the result shows the effectiveness of the method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>K R McKeown</author>
<author>M Elhadad</author>
</authors>
<title>Information Fusion in the Context of Multidocument Summarization.</title>
<date>1993</date>
<booktitle>In Proc. of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>550--557</pages>
<contexts>
<context position="11014" citStr="Barzilay et al., 1993" startWordPosition="1830" endWordPosition="1833">works well. Comparing the results evaluated by “ROUGE” were worse than those of “cos” at any approaches. One reason is that the difference of summarization technique, i.e., our work is extractive summarization, while the gold standard data provided by NTCIR3 SUMM is the abstracts written by human professionals. As a result, a large number of words in a candidate summary are extracted by our approaches. For future work, it is necessary to extend our method to involve paraphrasing for extracted key sentences to reduce the gap between automatically generated summaries and humanwritten abstracts (Barzilay et al., 1993; Carenini and Cheung, 2008). It is interesting to note how our approach affects for the number of sentences as an input. Figure 1 illustrates the results of summary “long” with evaluated ROUGE score. We can see from Figure 1 that our approach is more robust than k-means and the MRW model, even for a large number of input data. We have seen the same observations from other three results, i.e., the results of short and long with evaluated cos and short with evaluated ROUGE. We recall that the cluster number k is set to the square root of the sentence number. We tested different number of k to s</context>
</contexts>
<marker>Barzilay, McKeown, Elhadad, 1993</marker>
<rawString>R. Barzilay, K. R. McKeown, and M. Elhadad. 1993. Information Fusion in the Context of Multidocument Summarization. In Proc. of the 37th Annual Meeting of the Association for Computational Linguistics, pages 550–557.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Bremaud</author>
</authors>
<title>Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues.</title>
<date>1999</date>
<publisher>SpringerVerlag.</publisher>
<contexts>
<context position="3371" citStr="Bremaud, 1999" startWordPosition="514" endWordPosition="516"> However, one of the problems using multivariate clustering such as k-means is that it is something of a black art when applied to high-dimensional data. The available techniques for searching this large space do not offer guarantees of global optimality, thus the resulting summary still contains much overlapping information, especially for a large amount of documents. This paper focuses extractive summarization, and present a method for detecting key sentences from documents that discuss the same event. Like Wan et al.’s approach, we applied link analysis, the Markov Random Walk (MRW) model (Bremaud, 1999) to a graph consisting sentences and clusters. To attack the problem dealing with the high dimensional spaces, we applied spectral clustering technique (Ng et al., 2002) to the sentences from a document set. Spectral clustering is a transformation of the original sentences into a set of orthogonal eigenvectors. We worked in the space defined by the first few eigenvectors, using standard clustering techniques in the transformed space. 98 Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 98–102, Uppsala, Sweden, 16 July 2010. c�2010 Associat</context>
</contexts>
<marker>Bremaud, 1999</marker>
<rawString>P. Bremaud. 1999. Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues. SpringerVerlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Carenini</author>
<author>J C K Cheung</author>
</authors>
<title>Extractive vs. NLG-based Abstractive Summarization of Evaluative Text: The Effect of Corpus Controversiality.</title>
<date>2008</date>
<contexts>
<context position="11042" citStr="Carenini and Cheung, 2008" startWordPosition="1834" endWordPosition="1837">he results evaluated by “ROUGE” were worse than those of “cos” at any approaches. One reason is that the difference of summarization technique, i.e., our work is extractive summarization, while the gold standard data provided by NTCIR3 SUMM is the abstracts written by human professionals. As a result, a large number of words in a candidate summary are extracted by our approaches. For future work, it is necessary to extend our method to involve paraphrasing for extracted key sentences to reduce the gap between automatically generated summaries and humanwritten abstracts (Barzilay et al., 1993; Carenini and Cheung, 2008). It is interesting to note how our approach affects for the number of sentences as an input. Figure 1 illustrates the results of summary “long” with evaluated ROUGE score. We can see from Figure 1 that our approach is more robust than k-means and the MRW model, even for a large number of input data. We have seen the same observations from other three results, i.e., the results of short and long with evaluated cos and short with evaluated ROUGE. We recall that the cluster number k is set to the square root of the sentence number. We tested different number of k to see how the cluster number E </context>
</contexts>
<marker>Carenini, Cheung, 2008</marker>
<rawString>G. Carenini and J. C. K. Cheung. 2008. Extractive vs. NLG-based Abstractive Summarization of Evaluative Text: The Effect of Corpus Controversiality.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proc. of the 5th International Natural Language Generation Conference,</booktitle>
<pages>33--41</pages>
<marker></marker>
<rawString>In Proc. of the 5th International Natural Language Generation Conference, pages 33–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A P Dempster</author>
<author>N M Laird</author>
<author>D B Rubin</author>
</authors>
<date>1977</date>
<booktitle>Maximum Likelihood from Incomplete Data Via the EM Algorithm. Royal Statistical Society, 39(B):1–</booktitle>
<pages>38</pages>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Maximum Likelihood from Incomplete Data Via the EM Algorithm. Royal Statistical Society, 39(B):1– 38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Erkan</author>
<author>D Radev</author>
</authors>
<title>LexPageRank: Prestige in Multi-document Text Summarization.</title>
<date>2004</date>
<booktitle>In Proc. of the 2004 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>365--371</pages>
<contexts>
<context position="1463" citStr="Erkan and Radev, 2004" startWordPosition="210" endWordPosition="213">n With the exponential growth of information on the Internet, it is becoming increasingly difficult for a user to read and understand all the materials from a series of large-scale document streams that is potentially of interest. Multi-document summarization is an issue to attack the problem. It differs from single document summarization in that it is important to identify differences and similarities across documents. Graph-based ranking methods, such as PageRank (Page et al., 1998) and HITS (Kleinberg, 1999) have recently applied and been successfully used for multi-document summarization (Erkan and Radev, 2004; Mihalcea and Tarau, 2005). Given a set of documents, the model constructs graph consisting vertices and edges where vertices are sentences and edges reflect the relationships between sentences. The model then applies a graph-based ranking method to obtain the rank scores for the sentences. Finally, the sentences with large rank scores are chosen into the summary. However, when they are strung together, the resulting summary still contains much overlapping information. Because all the sentences are ranked based on a sentence as unit of information. Therefore, for example, semantically related</context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>G. Erkan and D. Radev. 2004. LexPageRank: Prestige in Multi-document Text Summarization. In Proc. of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 365–371.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Kleinberg</author>
</authors>
<title>Authoritative Sources in a Hyperlinked Environment.</title>
<date>1999</date>
<pages>46--5</pages>
<publisher>ACM,</publisher>
<contexts>
<context position="1358" citStr="Kleinberg, 1999" startWordPosition="197" endWordPosition="198">ed on the NTCIR evaluation data, and the result shows the effectiveness of the method. 1 Introduction With the exponential growth of information on the Internet, it is becoming increasingly difficult for a user to read and understand all the materials from a series of large-scale document streams that is potentially of interest. Multi-document summarization is an issue to attack the problem. It differs from single document summarization in that it is important to identify differences and similarities across documents. Graph-based ranking methods, such as PageRank (Page et al., 1998) and HITS (Kleinberg, 1999) have recently applied and been successfully used for multi-document summarization (Erkan and Radev, 2004; Mihalcea and Tarau, 2005). Given a set of documents, the model constructs graph consisting vertices and edges where vertices are sentences and edges reflect the relationships between sentences. The model then applies a graph-based ranking method to obtain the rank scores for the sentences. Finally, the sentences with large rank scores are chosen into the summary. However, when they are strung together, the resulting summary still contains much overlapping information. Because all the sent</context>
</contexts>
<marker>Kleinberg, 1999</marker>
<rawString>J. M. Kleinberg. 1999. Authoritative Sources in a Hyperlinked Environment. ACM, 46(5):604–632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C-Y Liu</author>
<author>E H Hovy</author>
</authors>
<title>Automatic Evaluation of Summaries Using N-gram Co-occurrence Statistics.</title>
<date>2003</date>
<booktitle>In Proc. of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>71--78</pages>
<contexts>
<context position="9507" citStr="Liu and Hovy, 2003" startWordPosition="1583" endWordPosition="1586">ven input sentences to produce optimal results. The usual drawback in many clustering algorithms is that they cannot give a valid criterion for measuring class structure. Therefore, similar to Wan et. al’s method (Wan and Yang, 2008), we typically set the number of k of expected clusters √ as N where N is the number of all sentences in the document set. We used these values of the parameters and evaluated by using test data. We used two evaluation measures. One is cosine similarity between the generated summary by the system and the human generated summary. Another is ROUGE score used in DUC (Liu and Hovy, 2003). 1http://research.nii.ac.jp/ntcir/ We used a word instead of n-gram sequence in formula (6). The results are shown in Table 1. “# of doc” and “# of sent” refer to the average number of documents and sentences, respectively. “# of sum” denotes to the average number of summary sentences provided by NTCIR3 SUMM. “cos” and “ROUGE” refer to the results evaluated by using cosine, and ROUGE score, respectively. “MRW” indicates the results obtained by directly applying MRW model to the input sentences. We can see from Table 1 that our approach (Spectral) outperforms the baselines, “MRW” and “k-means”</context>
</contexts>
<marker>Liu, Hovy, 2003</marker>
<rawString>C-Y. Liu and E. H. Hovy. 2003. Automatic Evaluation of Summaries Using N-gram Co-occurrence Statistics. In Proc. of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 71–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Matsumoto</author>
<author>A Kitauchi</author>
<author>T Yamashita</author>
<author>Y Haruno</author>
<author>O Imaichi</author>
<author>T Imamura</author>
</authors>
<title>Japanese Morphological Analysis System Chasen Mannual.</title>
<date>1997</date>
<contexts>
<context position="7819" citStr="Matsumoto et al., 1997" startWordPosition="1274" endWordPosition="1277">nto the summary. 99 4 Experiments We had an experiment by using the NTCIR-31 SUMM to evaluate our approach. NTCIR-3 has two tasks, single, and multi-document summarization. The data is collected from two years(1998- 1999) Mainichi Japanese Newspaper articles. We used multi-document summarization task. There are two types of gold standard data provided to human judges, FBFREE DryRun and FormalRun, each of which consists of 30 topics. There are two types of correct summary according to the character length, i.e., “long” and “short”. All documents were tagged by a morphological analysis, ChaSen (Matsumoto et al., 1997) and noun words are extracted. We used FormalRun consisting of 30 topics as a test data. Similarly, we randomly chose 10 topics from the FBFREE DryRun data to tuning a parameter Q in Spectral Clustering, and the number of l in the l-dimensional space obtained by the Spectral Clustering. Q is searched in steps of 0.01 from 1.0 to 5.0. l in the l-dimensional space is searched in steps 10% from 0 to 80% against the total number of words in the training data. The size that optimized the average F-score of 10 topics was chosen. Here, F-score is the standard measure used in the clustering algorithm,</context>
</contexts>
<marker>Matsumoto, Kitauchi, Yamashita, Haruno, Imaichi, Imamura, 1997</marker>
<rawString>Y. Matsumoto, A. Kitauchi, T. Yamashita, Y. Haruno, O. Imaichi, and T. Imamura. 1997. Japanese Morphological Analysis System Chasen Mannual.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>P Tarau</author>
</authors>
<title>Language Independent Extractive Summarization. In</title>
<date>2005</date>
<booktitle>In Proc. of the 43nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>49--52</pages>
<contexts>
<context position="1490" citStr="Mihalcea and Tarau, 2005" startWordPosition="214" endWordPosition="217">growth of information on the Internet, it is becoming increasingly difficult for a user to read and understand all the materials from a series of large-scale document streams that is potentially of interest. Multi-document summarization is an issue to attack the problem. It differs from single document summarization in that it is important to identify differences and similarities across documents. Graph-based ranking methods, such as PageRank (Page et al., 1998) and HITS (Kleinberg, 1999) have recently applied and been successfully used for multi-document summarization (Erkan and Radev, 2004; Mihalcea and Tarau, 2005). Given a set of documents, the model constructs graph consisting vertices and edges where vertices are sentences and edges reflect the relationships between sentences. The model then applies a graph-based ranking method to obtain the rank scores for the sentences. Finally, the sentences with large rank scores are chosen into the summary. However, when they are strung together, the resulting summary still contains much overlapping information. Because all the sentences are ranked based on a sentence as unit of information. Therefore, for example, semantically related two sentences with “high r</context>
</contexts>
<marker>Mihalcea, Tarau, 2005</marker>
<rawString>R. Mihalcea and P. Tarau. 2005. Language Independent Extractive Summarization. In In Proc. of the 43nd Annual Meeting of the Association for Computational Linguistics, pages 49–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Y Ng</author>
<author>M I Jordan</author>
<author>Y Weiss</author>
</authors>
<title>On Spectral Clustering: Analysis and an Algorithm, volume 14.</title>
<date>2002</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="3540" citStr="Ng et al., 2002" startWordPosition="540" endWordPosition="543"> techniques for searching this large space do not offer guarantees of global optimality, thus the resulting summary still contains much overlapping information, especially for a large amount of documents. This paper focuses extractive summarization, and present a method for detecting key sentences from documents that discuss the same event. Like Wan et al.’s approach, we applied link analysis, the Markov Random Walk (MRW) model (Bremaud, 1999) to a graph consisting sentences and clusters. To attack the problem dealing with the high dimensional spaces, we applied spectral clustering technique (Ng et al., 2002) to the sentences from a document set. Spectral clustering is a transformation of the original sentences into a set of orthogonal eigenvectors. We worked in the space defined by the first few eigenvectors, using standard clustering techniques in the transformed space. 98 Proceedings of the 2010 Workshop on Graph-based Methods for Natural Language Processing, ACL 2010, pages 98–102, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics 2 Spectral Clustering Similar to other clustering algorithms, the spectral clustering takes as input a matrix formed from a pairwise si</context>
</contexts>
<marker>Ng, Jordan, Weiss, 2002</marker>
<rawString>A. Y. Ng, M. I. Jordan, and Y. Weiss. 2002. On Spectral Clustering: Analysis and an Algorithm, volume 14. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Page</author>
<author>S Brin</author>
<author>R Motwani</author>
<author>T Winograd</author>
</authors>
<title>The Pagerank Citation Ranking: Bringing Order to the Web. In</title>
<date>1998</date>
<tech>Technical report, Stanford Digital Libraries.</tech>
<contexts>
<context position="1331" citStr="Page et al., 1998" startWordPosition="191" endWordPosition="194">ocuments. The method was tested on the NTCIR evaluation data, and the result shows the effectiveness of the method. 1 Introduction With the exponential growth of information on the Internet, it is becoming increasingly difficult for a user to read and understand all the materials from a series of large-scale document streams that is potentially of interest. Multi-document summarization is an issue to attack the problem. It differs from single document summarization in that it is important to identify differences and similarities across documents. Graph-based ranking methods, such as PageRank (Page et al., 1998) and HITS (Kleinberg, 1999) have recently applied and been successfully used for multi-document summarization (Erkan and Radev, 2004; Mihalcea and Tarau, 2005). Given a set of documents, the model constructs graph consisting vertices and edges where vertices are sentences and edges reflect the relationships between sentences. The model then applies a graph-based ranking method to obtain the rank scores for the sentences. Finally, the sentences with large rank scores are chosen into the summary. However, when they are strung together, the resulting summary still contains much overlapping inform</context>
</contexts>
<marker>Page, Brin, Motwani, Winograd, 1998</marker>
<rawString>L. Page, S. Brin, R. Motwani, and T. Winograd. 1998. The Pagerank Citation Ranking: Bringing Order to the Web. In Technical report, Stanford Digital Libraries.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wan</author>
<author>J Yang</author>
</authors>
<title>Multi-document Summarization Using Cluster-based Link Analysis.</title>
<date>2008</date>
<booktitle>In Proc. of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>299--306</pages>
<contexts>
<context position="2404" citStr="Wan and Yang, 2008" startWordPosition="363" endWordPosition="366">arge rank scores are chosen into the summary. However, when they are strung together, the resulting summary still contains much overlapping information. Because all the sentences are ranked based on a sentence as unit of information. Therefore, for example, semantically related two sentences with “high recommendation” are ranked with high score, and thus are regarded as a summary sentence. To attack the problem, Wan et al. proposed two models, i.e., the Cluster-based conditional Markov Random Walk model and the Cluster-based HITS model, both make use of the theme clusters in the document set (Wan and Yang, 2008). Their model first groups documents into theme clusters by using a simple clustering method, k-means. Next, the model constructs a directed or undirected graph to reflect the relationships between sentences and clusters by using link analysis. They reported that the results on the DUC2001 and DUC2002 datasets showed the effectiveness of their models. However, one of the problems using multivariate clustering such as k-means is that it is something of a black art when applied to high-dimensional data. The available techniques for searching this large space do not offer guarantees of global opt</context>
<context position="6195" citStr="Wan and Yang, 2008" startWordPosition="995" endWordPosition="998">imilarly, w(si, clus(si)) refers to the similarity value between the sentence si and its cluster clus(si). These values are obtained by using the cosine similarity. The new row-normalized matrix M is defined by formula (3). Mij = p(i → j |clus(si), clus(sj)) (3) The saliency scores for the sentences are computed based on formula (3) by using the iterative form in formula (4). = I |S| E k_1 6. K-means is applied to S in the l-dimensional EScore(si) = µ Score(sj) · Mji + (1 − µ) space. alljoi |S |(4) 3 Cluster-based Link Analysis The link analysis we used is an approach presented by Wan et. al (Wan and Yang, 2008). The model called “Cluster-based Conditional Markov Random Walk Model” incorporates the cluster-level information into the process of sentence ranking. The model is summarized as follows: Let 7r(clus(si)) E [0, 1] be the importance of cluster clus(si) in the whole document set D. Let also w(si, clus(si)) E [0, 1] denote the strength of the correlation between sentence si and its cluster clus(si). clus(si) refers to the cluster containing sentence si. The transition probability from si to sj is defined by formula (1). μ in formula (4) is the damping factor, which we set to 0.85. The above proc</context>
<context position="9121" citStr="Wan and Yang, 2008" startWordPosition="1512" endWordPosition="1515"> the number of correct pair of sentences obtained by the k-means divided by the total number of pairs obtained by the k-means. Recall indicates a ratio of the number of correct pair of sentences obtained by the k-means divided by the total number of correct pairs. As a result, Q and l are set to 4.5 and 80%, respectively. It is difficult to predict the actual cluster number k in a given input sentences to produce optimal results. The usual drawback in many clustering algorithms is that they cannot give a valid criterion for measuring class structure. Therefore, similar to Wan et. al’s method (Wan and Yang, 2008), we typically set the number of k of expected clusters √ as N where N is the number of all sentences in the document set. We used these values of the parameters and evaluated by using test data. We used two evaluation measures. One is cosine similarity between the generated summary by the system and the human generated summary. Another is ROUGE score used in DUC (Liu and Hovy, 2003). 1http://research.nii.ac.jp/ntcir/ We used a word instead of n-gram sequence in formula (6). The results are shown in Table 1. “# of doc” and “# of sent” refer to the average number of documents and sentences, res</context>
<context position="12363" citStr="Wan and Yang, 2008" startWordPosition="2089" endWordPosition="2092">ainst 30 topics # of doc # of sent # of sum cos ROUGE MRW k-means Spectral MRW k-means Spectral Short 7.5 83.0 11.9 0.431 0.575 0.632 0.330 0.334 0.360 Long 20.4 0.371 0.408 0.477 0.180 0.186 0.209 0.4 0.35 0.3 0.25 ROUGE 0.2 0.15 0.1 0.05 0 50 100 150 200 250 300 350 # of sentences 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 ratio of the # of k k-means Spectral MRW Avg. ROUGE 0.21 0.205 0.2 0.195 0.19 0.185 0.18 0.175 MRW k-means Spectral Figure 1: Long with ROUGE vs. # of sentences affects the summarization performance. In the experiment, we set k = r∗ |N |where r is a parameter ranged from 0 to 1 (Wan and Yang, 2008). Because of space is limited, we report only the result with summary “long” and ROUGE score. The result is shown in Figure 2. Overall the results obtained by our approach and k-means outperformed the results obtained by directly applying MRW model, while the results by k-means was worse than the results by MRW model when the ratio of the number of sentences was larger than 0.8. This shows that clusterbased summarization is effective reduce redundancy, overlapping information. Figure 2 also shows that our approach always outperforms, regardless of how many number of sentences were used. This i</context>
</contexts>
<marker>Wan, Yang, 2008</marker>
<rawString>X. Wan and J. Yang. 2008. Multi-document Summarization Using Cluster-based Link Analysis. In Proc. of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 299–306.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Zhang</author>
<author>R Wang</author>
</authors>
<date>2007</date>
<booktitle>Identification of Overlapping Community Structure in Complex Networks using Fuzzy C-means Clustering. PHYSICA, A(374):483–490.</booktitle>
<marker>Zhang, Wang, 2007</marker>
<rawString>Z. Zhang and R. Wang. 2007. Identification of Overlapping Community Structure in Complex Networks using Fuzzy C-means Clustering. PHYSICA, A(374):483–490.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhu</author>
<author>A Goldberg</author>
<author>J V Gael</author>
<author>D Andrzejewski</author>
</authors>
<title>Improving Diversity in Ranking using Absorbing Random Walks. In</title>
<date>2007</date>
<booktitle>In Human Language technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>97--104</pages>
<marker>Zhu, Goldberg, Gael, Andrzejewski, 2007</marker>
<rawString>X. Zhu, A. Goldberg, J. V. Gael, and D. Andrzejewski. 2007. Improving Diversity in Ranking using Absorbing Random Walks. In In Human Language technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 97–104.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>