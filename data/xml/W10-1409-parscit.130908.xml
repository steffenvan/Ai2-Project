<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002903">
<title confidence="0.972617">
Parsing word clusters
</title>
<author confidence="0.883299">
Marie Candito* and Djamé Seddah*⋄
</author>
<affiliation confidence="0.558706">
⋆ Alpage (Université Paris 7/INRIA), 30 rue du château des rentiers 75013 Paris, France
⋄ Université Paris-Sorbonne, 28, rue Serpente, 75006 Paris, France
</affiliation>
<sectionHeader confidence="0.96932" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999805176470589">
We present and discuss experiments in sta-
tistical parsing of French, where terminal
forms used during training and parsing are
replaced by more general symbols, particu-
larly clusters of words obtained through un-
supervised linear clustering. We build on the
work of Candito and Crabbé (2009) who pro-
posed to use clusters built over slightly coars-
ened French inflected forms. We investigate
the alternative method of building clusters
over lemma/part-of-speech pairs, using a raw
corpus automatically tagged and lemmatized.
We find that both methods lead to compara-
ble improvement over the baseline (we ob-
tain F1=86.20% and F1=86.21% respectively,
compared to a baseline of F1=84.10%). Yet,
when we replace gold lemma/POS pairs with
their corresponding cluster, we obtain an up-
per bound (F1=87.80) that suggests room for
improvement for this technique, should tag-
ging/lemmatisation performance increase for
French.
We also analyze the improvement in perfor-
mance for both techniques with respect to
word frequency. We find that replacing word
forms with clusters improves attachment per-
formance for words that are originally either
unknown or low-frequency, since these words
are replaced by cluster symbols that tend to
have higher frequencies. Furthermore, clus-
tering also helps significantly for medium to
high frequency words, suggesting that training
on word clusters leads to better probability es-
timates for these words.
</bodyText>
<sectionHeader confidence="0.998893" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999974078947368">
Statistical parsing techniques have dramatically im-
proved over the last 15 years, yet lexical data sparse-
ness remains a critical problem. And the richer the
morphology of a language, the sparser the treebank-
driven lexicons will be for that language.
Koo et al. (2008) have proposed to use word clus-
ters as features to improve graph-based statistical
dependency parsing for English and Czech. Their
clusters are obtained using unsupervised clustering,
which makes it possible to use a raw corpus con-
taining several million words. Candito and Crabbé
(2009) applied clustering to generative constituency
parsing for French. They use a desinflection step that
removes some inflection marks from word forms and
then replaces them with word clusters, resulting in
a significant improvement in parsing performance.
Clustering words seems useful as a way of address-
ing the lexical data sparseness problem, since counts
on clusters are more reliable and lead to better prob-
ability estimates. Clustering also appears to address
the mismatch of vocabularies between the original
treebank and any external, potentially out-of-domain
corpus: clusters operate as an intermediary between
words from the treebank and words from the exter-
nal corpus used to compute clusters. Furthermore,
parsing word clusters instead of word forms aug-
ments the known vocabulary.
However, depending on the clustering method,
clusters are either not very reliable or are available
only for very frequent words. In order to parse word
clusters one needs to determine which word clusters
are reliable enough to be beneficial, so the tuning
of parameters such as cluster granularity and cluster
reliability becomes very important.
The aim of this paper is to give an in-depth study
of the &amp;quot;parsing word clusters&amp;quot; technique. In particu-
lar, starting from the Candito and Crabbé (2009) ex-
periments, we investigate the use of clustering lem-
</bodyText>
<page confidence="0.954744">
76
</page>
<note confidence="0.9904785">
Proceedings of the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 76–84,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999342642857143">
mas instead of desinflected forms. We also pro-
vide an analysis of the performance gains obtained
with respect to word frequency (frequent words, rare
words, unknown words).
In the next section, we describe the French tree-
bank used as the basis for all of our experiments.
We describe in section 3 the statistical parser used
for training and testing. We then describe the desin-
flection process used prior to unsupervised cluster-
ing (section 4), and the Brown algorithm we use for
unsupervised clustering (section ). We describe our
experiments and results in section 6, and provide a
discussion in section 7. We then point out some re-
lated work and conclude in section 9.
</bodyText>
<sectionHeader confidence="0.983885" genericHeader="introduction">
2 French Treebank
</sectionHeader>
<bodyText confidence="0.998841666666667">
For our experiments, we used the French Tree-
bank (Abeillé et al., 2003), which contains 12531
sentences, 350931 tokens, from the newspaper
Le Monde. We used the treebank instantiation
(hereafter FTB-UC) as first described in (Candito
and Crabbé, 2009), where:
</bodyText>
<listItem confidence="0.8342318">
(i) the rich original annotation containing morpho-
logical and functional information is mapped to a
simpler phrase-structure treebank with a tagset of
28 part-of-speech tags, and no functional annotation
(ii) some compounds with regular syntax are broken
down into phrases containing several simple words
(iii) the remaining sequences annotated as com-
pound words in the FTB are merged into a single
token, whose components are separated with an
underscore
</listItem>
<bodyText confidence="0.9985335">
For all experiments in this paper (tagging and
parsing) we used the same partition of the treebank
as these authors : first 10% for test, next 10% for
dev and the rest for training1.
</bodyText>
<sectionHeader confidence="0.918703" genericHeader="method">
3 Berkeley Parser
</sectionHeader>
<bodyText confidence="0.9996518">
We report here experiments using the Berkeley
PCFG parser with latent annotations (Petrov et al.,
2006), hereafter BKY, which is a constituent parser
that has been proven to perform well for French
(Crabbé and Candito, 2008; Seddah et al., 2009),
</bodyText>
<footnote confidence="0.854437333333333">
1More precisely the partition is : first 1235 sentences for
test, next 1235 sentences for development, and remaining 9881
sentences for training.
</footnote>
<bodyText confidence="0.999835314285714">
though a little lower than a combination of a tagger
plus the dependency-based MST parser (Candito et
al., 2010). Though PCFG-style parsers operate on
too narrow a domain of locality, splitting symbols
according to structural and/or lexical properties is
known to help parsing (Klein and Manning., 2003).
Following (Matsuzaki et al., 2005), the BKY algo-
rithm uses EM to estimate probabilities on symbols
that are automatically augmented with latent anno-
tations, a process which can be viewed as symbol
splitting. It iteratively evaluates each such split and
merges back the less beneficial ones. Crabbé and
Candito (2008) show that some of the information
carried by the latent annotations is lexical, since re-
placing words by their gold part-of-speech tag leads
to worse results than the corresponding perfect tag-
ging test, with words unchanged. This is a clear in-
dication that lexical distinctions are used, and perco-
late up the parse tree via the latent annotations.
We now describe how the BKY software handles
rare and unknown words, as this is pertinent to our
discussion in section 6. P(wItag) is calculated us-
ing Bayes’ rule, as P(tagjw)P(w)/P(tag). Rel-
ative frequency estimates are used for words that
are sufficiently frequent. For rare words (appear-
ing less than 10 times in our settings), P(tagjw)
is smoothed using the proportion of tokens in the
second half of the training set that were not seen in
the first half, and that have this tag. For unknown
words, words signatures are used: these are word
classes determined by information such as the word
suffix, whether the word is capitalized, whether it
contains digits, etc. P(wItag) is estimated with
P(signature(w) tag), and is also smoothed in the
same way rare words are.
</bodyText>
<sectionHeader confidence="0.962982" genericHeader="method">
4 Morphological clustering
</sectionHeader>
<bodyText confidence="0.9999494">
A first approach to word clustering is to cluster
forms on a morphological basis. In the case of
a relatively morphologically rich language such as
French, this is an obvious way to reduce lexical
sparseness caused by inflection.
(Candito and Crabbé, 2009) proposed the use of
a desinflection method, without resorting to part-of-
speech tagging. We propose an alternate method
here, which uses lemmas and part-of-speech tags
that are output by a tagger/lemmatizer. Because
</bodyText>
<page confidence="0.997393">
77
</page>
<bodyText confidence="0.999891083333333">
counts on lemmas are more reliable, clustering
over lemmas presumably produces clusters that are
more reliable than those produced by clustering over
desinflected forms. However, this approach does
create a constraint in which automatically tagged
and lemmatized text is required as input to the
parser, leading to the introduction of tagging errors.
Both morphological clustering methods make use
of the Lefff lexicon (Sagot, 2010). Before we de-
scribe these two methods, we briefly give basic in-
formation on French inflectional morphology and on
the Lefff.
</bodyText>
<subsectionHeader confidence="0.998842">
4.1 French inflection and the Leff lexicon
</subsectionHeader>
<bodyText confidence="0.999969642857143">
French nouns appear in singular and plural forms,
and have an intrinsic gender. The number and gen-
der of a noun determines the number and gender of
determiners, adjectives, past participles that depend
on it. Hence in the general case, past participles and
adjectives have four different forms. The major in-
flectional variation appears for finite verbs that vary
for tense, mood, person and number. A regular verb
may correspond to more than 60 inflected forms if
all tenses and mood are included. In practice, some
forms occur very rarely, because some tense/mood
pairs are rare, and further, in the case of newspa-
per text for instance, the first and second persons are
also rare. So for instance in the FTB-UC, there are
33 different forms for the highly frequent verb and
auxiliary avoir (to have), that appears 4557 times.
The medium frequency verb donner (to give) occurs
155 times, under 15 different forms. In the whole
treebank, there are 27130 unique word forms, corre-
sponding to 17570 lemmas.
The Lefff is a freely available rich morphologi-
cal and syntactic French lexicon (Sagot, 2010). It
contains 110, 477 lemmas (simple and compounds)
and 536,375 inflected forms. The coverage on the
FTB-UC is high : around 96% of the tokens, and
80,1% of the types are present in the Lefff (leaving
out punctuation and numeric tokens, and ignoring
case differences).
</bodyText>
<subsectionHeader confidence="0.965705">
4.2 Desinflection
</subsectionHeader>
<bodyText confidence="0.99998618">
The aim of the desinflection step is to reduce lex-
ical data sparseness caused by inflection, without
hurting parsability and without committing oneself
as far as lexical ambiguity is concerned. The idea
is to leave unchanged the parser’s task in disam-
biguating part-of-speech tags. In that case, mor-
phological clustering using lemmas is not an option,
since lemma assignment presupposes POS disam-
biguation. Furthermore, useful information such as
verb mood (which is needed to capture, for instance,
that infinitive verbs have no overt subject or that par-
ticipial clauses are sentence modifiers) is discarded
during lemmatization, though it is encoded in the
FTB with different projections for finite verbs (pro-
jecting sentences) versus non finite verbs (projecting
VPpart or VPinf).
The intuition of Candito and Crabbé (2009) is
that other inflectional markers in French (gender and
number for determiners, adjectives, pronouns and
nouns, or tense and person for verbs) are not crucial
for inferring the correct phrase-structure projection
for a given word. Consequently, they proposed to
achieve morphological clustering by desinflection,
namely by removing unneeded inflectional markers,
identified using the Lefff. This lexicon-based tech-
nique can be viewed as an intermediate method be-
tween stemming and lemmatization.
The desinflection process is as follows: for a to-
ken t to desinflect, if it is known in the lexicon,
then for each inflected lexical entry le of t, try to
get a corresponding singular entry. If correspond-
ing singular entries exist for all such le and all have
the same form, then replace t by the correspond-
ing form. For instance for wt=entrées (ambigu-
ous between entrances and entered, fem, plural), the
two lexical entries are [entrées/N/fem/plu] and [en-
trées/U/fem/plu/part/past]2, each have a correspond-
ing singular lexical entry, with form entrée.
The same process is used to map feminine forms
to corresponding masculine forms. This allows one
to change mangée (eaten, fem, sing) into mangé
(eaten, masc, sing). But for the form entrée, am-
biguous between N and Vpastpart entries, only the
participle has a corresponding masculine entry (with
form entré). In that case, in order to preserve the
original part-of-speech ambiguity, entrée is not re-
placed by entré. Finite verb forms, when unambigu-
ous with other parts-of-speech, are mapped to sec-
ond person plural present indicative corresponding
forms. This choice was made in order to avoid cre-
</bodyText>
<footnote confidence="0.986485">
2This is just an example and not the real Lefffformat.
</footnote>
<page confidence="0.990473">
78
</page>
<table confidence="0.99948325">
Dev set Overall Overall (-punct) Unseen (4.8)
POS acc 97.38 96.99 91.95
Lemma acc 98.20 97.93 92.52
Joint acc 96.35 95.81 87.16
Test set Overall Overall (-punct) Unseen (4.62)
POS acc 97.68 97.34 90.52
Lemma acc 98.36 98.12 91.54
Joint acc 96.74 96.26 85.28
</table>
<tableCaption confidence="0.963311">
Table 1: MORFETTE performance on the FTB-UC dev
and test sets (with and without punctuation)
</tableCaption>
<bodyText confidence="0.999150111111111">
ating ambiguity: the second person plural forms end
with a very typical -ez suffix, and the resulting form
is very unlikely ambiguous. For the first token of a
sentence, if it is unknown in the lexicon, the algo-
rithm tries to desinflect the corresponding lowercase
form.
This desinflection process reduces the number
of distinct tokens in the FTB-UC training set from
24110 to 18052.
</bodyText>
<subsectionHeader confidence="0.999811">
4.3 Part-of-speech tagging and lemmatization
</subsectionHeader>
<bodyText confidence="0.9999513">
In order to assign morphological tags and lemmas to
words we use a variation of the MORFETTE model
described in (Chrupała et al., 2008). It is a se-
quence labeling model which combines the predic-
tions of two classification models (one for morpho-
logical tagging and one for lemmatization) at decod-
ing time, using a beam search.
While (Chrupała et al., 2008) use Maximum Entropy
training to learn PM and PL, we use the MORFETTE
models described in (Seddah et al., 2010), that are
trained using the Averaged Sequence Perceptron al-
gorithm (Freund and Schapire, 1999). The two clas-
sification models incorporate additional features cal-
culated using the Leffflexicon.
Table 1 shows detailed results on dev set and
test set of the FTB-UC, when MORFETTE is trained
on the FTB-UC training set. To the best of our
knowledge the parts-of-speech tagging performance
is state-of-the-art for French3 and the lemmatization
performance has no comparable results.
</bodyText>
<sectionHeader confidence="0.929687" genericHeader="method">
5 Unsupervised clustering
</sectionHeader>
<footnote confidence="0.83839775">
3A pure MAXENT based tagger is described in (Denis and
Sagot, 2009), that also uses the Lefff, under the form of features
for the known categories of a word in the lexicon. The authors
report 97.70% of accuracy and 90.01% for unseen data.
</footnote>
<bodyText confidence="0.999984909090909">
We use the Brown et al. (1992) hard clustering al-
gorithm, which has proven useful for various NLP
tasks such as dependency parsing (Koo et al., 2008)
and named entity recognition (Liang, 2005). The al-
gorithm to obtain C clusters is as follows: each of
the C most frequent tokens of the corpus is assigned
its own distinct cluster. For the (C + 1)th most fre-
quent token, create a (C + 1)th cluster. Then for
each pair among the C + 1 resulting clusters, merge
the pair that minimizes the loss in the likelihood of
the corpus, according to a bigram language model
defined on the clusters. Repeat this operation for the
(C + 2)th most frequent token, etc. The result is a
hard clustering of words in the corpus into C distinct
clusters, though the process can be continued to fur-
ther merge pairs of clusters among the C clusters,
ending with a single cluster for the entire vocabu-
lary. A binary tree hierarchy of merges for the C
clusters can be obtained by tracing the merging pro-
cess, with each cluster identified by its path within
this binary tree. Clusters can thus be used at various
levels of granularity.
</bodyText>
<sectionHeader confidence="0.995418" genericHeader="method">
6 Experiments and results
</sectionHeader>
<subsectionHeader confidence="0.988492">
6.1 Clustering
</subsectionHeader>
<bodyText confidence="0.999883909090909">
For the Brown clustering algorithm, we used Percy
Liang’s code4, run on the L’Est Républicain corpus,
a 125 million word journalistic corpus, freely avail-
able at CNRTL5. The corpus was first tokenized and
segmented into sentences. For compound words,
the 240 most frequent compounds of the FTB-UC
were systematically recognized as one token. We
tried out the two alternate morphological clustering
processes described in section 4 as a preprocessing
step before the unsupervised clustering algorithm
was run on the L’Est Républicain corpus :
</bodyText>
<listItem confidence="0.8604548">
(i) word forms were replaced by corresponding
desinflected form
(ii) word forms were replaced by a concatenation
of the part-of-speech tag and lemma obtained with
MORFETTE6.
</listItem>
<footnote confidence="0.999633428571429">
4http://www.eecs.berkeley.edu/pliang/software
5http://www.cnrtl.fr/corpus/estrepublicain
6Because these experiments were first run with a version
of Morfette that was not yet optimized for lemmatization, we
chose to overide the MORFETTE lemma when the Lefff lemma
is available for a given form and part-of-speech tag pair sup-
plied by Morfette. Morfette’s current results (version 0.3.1) in
</footnote>
<page confidence="0.976098">
79
</page>
<table confidence="0.999757555555555">
Name Terminal symbols Vocabulary size Terminal symbols
in training set in training set in dev/test sets
BASELINE wf 24110 wf
DFL Desinflected wf 18052 Desinflected wf
DFL+CLUST&gt;X Cluster,(desinflected wf) 1773 (X = 200) Cluster,(desinflected wf)
GOLDCATLEMMA Gold POS+lemma 18654 Gold POS+lemma
AUTOCATLEMMA Gold POS+lemma 18654 Automatic POS+lemma
GOLDCATLEMMA+CLUST&gt;X Cluster2(gold POS+lemma) 1298 (X = 200) Cluster2(gold POS+lemma)
AUTOCATLEMMA+CLUST&gt;X Cluster2(gold POS+lemma) 1298 (X = 200) Cluster2(automatic POS+lemma)
</table>
<tableCaption confidence="0.999419">
Table 2: Types of terminal symbols used for training and parsing
</tableCaption>
<bodyText confidence="0.999974111111111">
In the first case we obtain clusters of desinflected
forms, whereas in the second case we obtain clusters
of tag+lemma pairs. Note that lemmas alone could
be used, but as noted earlier, important syntactic
information would be lost, particularly for verb
mood. We did try using clusters of lemmas, coupled
with a few suffixes to record the verb mood, but this
resulted in more or less the same performance as
clusters of tag+lemma pairs.
</bodyText>
<subsectionHeader confidence="0.999925">
6.2 Berkeley parser settings
</subsectionHeader>
<bodyText confidence="0.999990083333333">
For BKY we used Slav Petrov’s code, adapted for
French by Crabbé and Candito (2008) by modify-
ing the suffixes used to classify unknown words. We
use the partition between training, development and
test sets introduced in section 2. Note though that
the BKY algorithm itself uses two sets of sentences
at training: a learning set and a smaller validation
set for tuning model hyperparameters. In all experi-
ments in this paper, we used 2% of the training set as
as a validation set, and 98% as a learning set. This
differs from (Candito and Crabbé, 2009), where the
dev set was used as a validation set.
</bodyText>
<subsectionHeader confidence="0.960521">
6.3 Experiments
</subsectionHeader>
<bodyText confidence="0.991076976190477">
We then tested several settings differing only in the
terminal symbols used in the training set, and in the
dev and test sets. We list these settings in table 2. For
the settings involving unsupervised linear clustering:
DFL+CLUST&gt;X: Each desinflected form df is re-
placed by Clusters(df) : if df occurred more than
X times in the L’Est Républicain corpus, it is re-
placed by its cluster id, otherwise, a special clus-
ter UNKC is used. Further, a _c suffix is added if
lemmatization renders this step obsolete.
the desinflected form starts with a capital letter, and
additional features are appended, capturing whether
the form is all digits, ends with ant, or r, or ez (cf.
this is the ending of the desinflected forms of unam-
biguous finite verbs). (Candito and Crabbé, 2009)
showed that these additional features are needed be-
cause clusters are noisy: linear context clustering
sometimes groups together items that belong to dif-
ferent parts-of-speech.
GOLDCATLEMMA+CLUST&gt;X: The terminal
form used is the gold part-of-speech concatenated
to the cluster id of the gold POS+lemma, or UNKC
if that pair did not occur more than X times in the
L’Est Républicain corpus.
AUTOCATLEMMA+CLUST&gt;X: For the
training set, the same setting as GOLD-
CATLEMMA+CLUST&gt;X is used. But for the
dev and test sets, predicted parts-of-speech and
lemmas are used, as output by the MORFETTE tag-
ger/lemmatizer: the terminal form is the predicted
part-of-speech concatenated with the cluster id of
the predicted POS+lemma, or UNKC if that pair
was not frequent enough.
For the CLUST&gt;X experiments, we report results
with X = 200. We have found empirically that
varying X between 20 and 700 has very little effect
on performance gains, both for clustering of desin-
flected forms and clustering of tag+lemma pairs.
Also, all results are with a maximum number of
clusters set to 1000, and we found that limiting the
number of clusters (by taking only a prefix of the
cluster bit string) degrades results.
</bodyText>
<subsectionHeader confidence="0.939941">
6.4 Evaluation metrics
</subsectionHeader>
<bodyText confidence="0.9940725">
We evaluate parsing performance using labeled F-
Measure (combining labeled precision and labeled
</bodyText>
<page confidence="0.992048">
80
</page>
<table confidence="0.999848777777778">
DEV SET
TERMINAL SYMBOLS F1&lt;40 F1 UAS Tagging Acc.
BASELINE 86.06 83.81 89.23 96.44
DFL 86.65 84.67 (+0.86) 89.86 96.52
DFL+CLUST&gt;200 87.57 85.53 (+1.72) 90.68 96.47
AUTOCATLEMMA 86.77 84.52 (+0.71) 89.97 96.25
AUTOCATLEMMA+CLUST&gt;200 87.53 85.19 (+1.38) 90.39 96.78
GOLDCATLEMMA 87.74 85.53 (+1.72) 91.42 98.49
GOLDCATLEMMA+CLUST&gt;200 88.83 86.52 (+2.71) 92.11 99.46
TEST SET
TERMINAL SYMBOLS F1&lt;40 F1 UAS Tagging Acc.
BASELINE 86.16 84.10 89.57 96.97
DFL 87.13 85.07 (+0.93) 90.45 97.08
DFL+CLUST&gt;200 88.22 86.21 (+2.11) 90.96 96.98
AUTOCATLEMMA 86.85 84.83 (+0.73) 90.30 96.58
AUTOCATLEMMA+CLUST&gt;200 87.99 86.20 (+2.10) 91.22 97.11
GOLDCATLEMMA 88.16 85.90 (+1.80) 91.52 98.54
GOLDCATLEMMA+CLUST&gt;200 89.93 87.80 (+3.70) 92.83 99.41
</table>
<tableCaption confidence="0.98089625">
Table 3: Parsing performance on the dev set/test set when training and parsing make use of clustered terminal symbols.
F1&lt;40 is the F-Measure combining labeled precision and labeled recall for sentences of less than 40 words. All other
metrics are for all sentences of the dev set/test set. UAS = Unlabeled attachement score of converted constituency
trees into surface dependency trees. All metrics ignore punctuation tokens.
</tableCaption>
<bodyText confidence="0.996888428571429">
recall) both for sentences of less than 40 words, and
for all sentences7. We also use the unlabeled attach-
ment score (UAS), obtained when converting the
constituency trees output by the BKY parsers into
surface dependency trees, using the conversion pro-
cedure and software of (Candito et al., 2010)8. Punc-
tuation tokens are ignored in all metrics.
</bodyText>
<sectionHeader confidence="0.998962" genericHeader="method">
7 Discussion
</sectionHeader>
<bodyText confidence="0.9862765">
Results are shown in table 3. Our hope was that us-
ing lemmatization would improve overall accuracy
of unsupervised clustering, hence leading to better
parsing performance. However, results using both
methods are comparable.
7Note that often for statistical constituent parsing results are
given for sentences of less than 40 words, whereas for depen-
dency parsing, there is no such limitation. The experiment DFL
and DFL+CLUST&gt;200 are reproduced from the previous work
(Candito and Crabbé, 2009). More precisely, this previous work
reports F1 = 88.29 on the test set, but for sentences &lt; 40
words, for a DFL+CLUST&gt;20 experiment, and as previously
mentioned, the dev set was used as validation set for the BKY
algorithm. We report now F1 = 88.22 for the same less-than-
40-words sentences, leaving dev set unused at training time.
8The conversion uses head propagation rules to find the head
on the right-hand side of the CFG rules, first proposed for En-
glish in (Magerman, 1995). Hence the process is highly sensi-
tive to part-of-speech tags.
Table 3 shows that both morphological clustering
techniques (DFL and AUTOCATLEMMA) slightly
improve performance (+0.97 and +0.73 F1 over the
baseline for the test set)9. In the case of AUTO-
CATLEMMA, morphological ambiguity is totally ab-
sent in training set: each terminal symbol is the gold
POS+lemma pair, and hence appears with a unique
part-of-speech in the whole training set. But at pars-
ing time, the terminal symbols are the POS+lemma
pairs predicted by MORFETTE, which are wrong for
approximately 3% of the tokens. So when com-
paring the impact on parsing of the two morpho-
logical clustering techniques, it seems that the ad-
vantage of lemmatization (a sounder morphological
clustering compared to the desinflection process) is
counterbalanced by tagging errors that lead to wrong
POS+lemma pairs. Indeed, it can be verified that
</bodyText>
<footnote confidence="0.770872090909091">
9We have computed p-values for pairs of results, us-
ing Dan Bikel’s statistical significance tester for evalb out-
put (http://www.cis.upenn.edu/ dbikel/software.html). All ex-
periments have a p-value &lt; 0.05 both for recall and preci-
sion when compared to the baseline. The differences between
DFL and AUTOCATLEMMA, and between DFL+CLUST&gt;200
and AUTOCATLEMMA+CLUST&gt;200 are not statistically sig-
nificant (p − value &gt; 0.2). The gain obtained by adding
the unsupervised clustering is clearly significant (p − value &gt;
0.005), both when comparing AUTOCATLEMMA and AUTO-
CATLEMMA+CLUST&gt;200, and DFL and DFL+CLUST&gt;200.
</footnote>
<page confidence="0.993815">
81
</page>
<table confidence="0.7684748">
BASELINE DFL+CLUST&gt;200 AUTOCATLEMMA+CLUST&gt;200
FREQUENCY RANGE #tokens in dev set UAS Tagging UAS Tagging UAS Tagging
in original training set
any 31733 (100%) 89.23 96.43 90.68 96.45 90.39 96.78
0 (original unseen) 1892 (5.96%) 84.78 82.56 88.79 89.22 88.64 91.17
0 &lt; x &lt; 5 3376 (10.64%) 86.49 94.52 88.68 93.13 88.33 95.41
5 &lt; x &lt; 10 1906 (6.01%) 90.35 96.59 91.50 95.02 91.55 96.12
10 &lt; x &lt; 20 2248 (7.08%) 89.55 96.71 91.37 95.42 90.57 95.91
20 &lt; x &lt; 50 3395 (10.70%) 91.87 96.35 92.40 95.96 91.72 95.94
x &gt; 50 18916 (59.61%) 89.53 98.12 90.75 (+1.22) 98.12 90.56 (+1.03) 97.91
</table>
<tableCaption confidence="0.993846">
Table 4: Tagging accuracy and UAS scores for words in the dev set, grouped by ranges of frequencies in the original
training set.
</tableCaption>
<bodyText confidence="0.984443271428572">
when parsing the gold POS+lemma pairs (the non
realistic GOLDCATLEMMA setting10), performance
is greatly improved (+1.80 F1 over the baseline).
Replacing morphological clusters by their corre-
sponding unsupervised clusters leads to a further im-
provement, both for F1 score and for UAS. But here
again, using desinflection or tagging+lemmatisation
leads to more or less the same improvement. But
while the former method is unlikely improvable, the
latter method might reveal more effective if the per-
formance of the tagging/lemmatisation phase im-
proves. The GOLDCATLEMMA+CLUST&gt;200 ex-
periment gives the upper bound performance : it
leads to a +3.70F1 increase over the baseline, for
the test set. In that case, the terminal symbols are
made of the perfect POS plus the cluster of the per-
fect POS+lemma pair. Very few such terminal sym-
bols are unseen in training set, and all are unam-
biguous with respect to part-of-speech (hence the
99.46% tagging accuracy).
In order to better understand the causes of im-
provement, we have broken down the tagging accu-
racy scores and the UAS scores according to various
ranges of word frequencies. For word forms in the
dev set that occur x times in the original training
set, for x in a certain range, we look at how many
are correctly tagged by the parsers, and how many
receive the correct head when constituents are con-
verted into surface dependencies.
The results are shown in table 4. Unseen words
and rare words are much better handled (about +4
points for UAS for unseen words, and +2 points
10The GOLDCATLEMMA experiment leads to high tagging
accuracy, though not perfect, because of POS+lemma pairs
present in dev/test sets but missing in the training set.
for forms appearing less than 5 times). This is
simply obtained because the majority of original
rare or unknowns are replaced by terminal symbols
(either a cluster id or the UNKC token, plus suf-
fixes) that are shared by many forms in the tree-
bank, leading to higher counts. This can be veri-
fied by analyzing tagging accuracies and UAS scores
for various frequency ranges for the modified termi-
nal symbols : the symbols that replace the word
forms in the training set for DFL+CLUST&gt;X and
AUTOCATLEMMA+CLUST&gt;X experiments. This
is shown in table 5. It can be seen that the major-
ity of the tokens have now high-frequency. For in-
stance for the DFL+CLUST&gt;200 experiment, there
are only 0.09% terminal symbols in the dev set that
are unseen in training set, and 92.62% appear more
than 50 times. The parsers do not perform very
well on low-frequency modified terminal symbols,
but they are so few that it has little impact on the
overall performance.
Hence, in our parsing word clusters experiments,
there are almost no real unseen anymore, there are
only terminal symbols made of a cluster id or UNKC
(plus suffixes). More precisely, for instance about
30% of the original unseen in the dev set, are re-
placed by a UNKC* symbol, which means that 70%
are replaced by a cluster-based symbol and are thus
“connected” to the known vocabulary.
Interestingly, the improvement in performance is
also evident for words with high frequency in the
original treebank: for the forms appearing more
than 50 times in the original training set, the UAS
increases by +1.22 with DFL+CLUST&gt;200 and
+1.03 with AUTOCATLEMMA+CLUST&gt;200 (table
4). This means that despite any imperfections in the
</bodyText>
<page confidence="0.987566">
82
</page>
<table confidence="0.505996090909091">
DFL+CLUST&gt;200 AUTOCATLEMMA+CLUST&gt;200
FREQUENCY RANGE percentage UAS Tagging percentage UAS Tagging
in modified training set of dev set of dev set
any 100 90.68 96.45 100 90.39 96.78
0 (effective unseen) 0.09 86.21 58.62 0.08 84.00 40.00
0 &lt; x &lt; 5 0.45 88.19 86.81 0.32 70.30 70.30
5 &lt; x &lt; 10 0.64 90.69 91.18 0.37 92.24 79.31
10 &lt; x &lt; 20 1.31 90.12 94.22 0.87 89.53 88.09
20 &lt; x &lt; 50 4.88 88.64 92.19 3.30 86.44 92.65
x &gt; 50 92.62 90.81 96.83 95.07 90.60 97.21
replaced by UNKC* 8.58 90.64 88.10 8.73 89.67 90.07
</table>
<tableCaption confidence="0.750685666666667">
Table 5: Tagging accuracy and UAS scores for modified terminal symbols in the dev set, grouped by ranges of fre-
quencies in the modified training sets. The “replaced by UNKC*” line corresponds to the case where the desinflected
form or the POS+lemma pair does not appear more than 200 times in the L’est Républicain corpus.
</tableCaption>
<bodyText confidence="0.952071333333333">
unsupervised Brown clustering, which uses very lo-
cal information, the higher counts lead to better es-
timates even for high-frequency words.
</bodyText>
<sectionHeader confidence="0.999879" genericHeader="method">
8 Related work
</sectionHeader>
<bodyText confidence="0.999974972222222">
We have already cited the previous work of Koo et
al. (2008) which has directly inspired ours. Sagae
and Gordon (2009) explores the use of syntactic
clustering to improve transition-based dependency
parsing for English : using an available 30 mil-
lion word corpus parsed with a constituency parser,
words are represented as vectors of paths within the
obtained constituency parses. Words are then clus-
tered using a similarity metric between vectors of
syntactic paths. The clusters are used as features to
help a transition-based dependency parser. Note that
the word representation for clustering is more com-
plex (paths in parse trees), thus these authors have
to cluster a smaller vocabulary : the top 5000 most
frequent words are clustered.
Agirre et al. (2008) use the same approach of re-
placing words by more general symbols, but these
symbols are semantic classes. They test various
methods to assign semantic classes (gold seman-
tic class, most-frequent sense in sense-tagged data,
or a fully unsupervised sense tagger). Though the
method is very appealing, the reported improvement
in parsing is rather small, especially for the fully un-
supervised method.
Versley and Rehbein (2009) cluster words accord-
ing to linear context features, and use the clusters
as features to boost discriminative German parsing
for unknown words. Another approach to augment
the known vocabulary for a generative probabilistic
parser is the one pursued in (Goldberg et al., 2009).
Within a plain PCFG, the lexical probabilities for
words that are rare or absent in the treebank are
taken from an external lexical probability distribu-
tion, estimated using a lexicon and the Baulm-Welch
training of an HMM tagger. This is proven useful to
better parse Hebrew.
</bodyText>
<sectionHeader confidence="0.939351" genericHeader="conclusions">
9 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999986272727273">
We have provided a thorough study of the results
of parsing word clusters for French. We showed
that the clustering improves performance both for
unseen and rare words and for medium- to high-
frequency words. For French, preprocessing words
with desinflection or with tagging+lemmatisation
lead to comparable results. However, the method
using POS tagging is expected to yield higher per-
formance should a better tagger become available in
the future.
One avenue for further improvement is to use a
clustering technique that makes explicit use of syn-
tactic or semantic similarity, instead of simple linear
context sharing. While the Brown clustering algo-
rithm can be run on large raw corpus, it uses ex-
tremely local information (bigrams). The resulting
clusters are thus necessarily noisy, and semantic or
syntactic clustering would certainly be more appro-
priate. Since resource-based semantic clustering is
difficult for French due to a lack of resources, clus-
tering based on distributional syntactic similarity is
a worthwhile technique to investigate in the future.
</bodyText>
<page confidence="0.99851">
83
</page>
<sectionHeader confidence="0.99833" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9997285">
This work was supported by the ANR Sequoia
(ANR-08-EMER-013). We are grateful to our
anonymous reviewers for their comments and to
Grzegorz Chrupala for helping us with Morfette.
</bodyText>
<sectionHeader confidence="0.999181" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999901537634408">
Anne Abeillé, Lionel Clément, and François Toussenel,
2003. Building a Treebank for French. Kluwer, Dor-
drecht.
Eneko Agirre, Timothy Baldwin, and David Martinez.
2008. Improving parsing and PP attachment perfor-
mance with sense information. In Proceedings of
ACL-08: HLT, pages 317–325, Columbus, Ohio, June.
Association for Computational Linguistics.
Peter F. Brown, Vincent J. Della, Peter V. Desouza, Jen-
nifer C. Lai, and Robert L. Mercer. 1992. Class-based
n-gram models of natural language. Computational
linguistics, 18(4):467–479.
Marie Candito and Benoît Crabbé. 2009. Im-
proving generative statistical parsing with semi-
supervised word clustering. In Proceedings of the
11th International Conference on Parsing Technolo-
gies (IWPT’09), pages 138–141, Paris, France, Octo-
ber. Association for Computational Linguistics.
Marie Candito, Benoit Crabbé, and Pascal Denis. 2010.
Statistical french dependency parsing : Treebank
conversion and first results. In Proceedings of
LREC’2010, Valletta, Malta.
Grzegorz Chrupała, Georgiana Dinu, and Josef van Gen-
abith. 2008. Learning morphology with morfette. In
In Proceedings of LREC 2008, Marrakech, Morocco.
ELDA/ELRA.
Benoit Crabbé and Marie Candito. 2008. Expériences
d’analyse syntaxique statistique du français. In Actes
de la 15ème Conférence sur le Traitement Automatique
des Langues Naturelles (TALN’08), pages 45–54, Avi-
gnon, France.
Pascal Denis and Benoît Sagot. 2009. Coupling an anno-
tated corpus and a morphosyntactic lexicon for state-
of-the-art pos tagging with less human effort. In Proc.
ofPACLIC, Hong Kong, China.
Yoav Freund and Robert E. Schapire. 1999. Large mar-
gin classification using the perceptron algorithm. Ma-
chine learning, 37(3):277–296.
Yoav Goldberg, Reut Tsarfaty, Meni Adler, and Michael
Elhadad. 2009. Enhancing unlexicalized parsing per-
formance using a wide coverage lexicon, fuzzy tag-set
mapping, and EM-HMM-based lexical probabilities.
In Proc. of EACL-09, pages 327–335, Athens, Greece.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate unlexicalized parsing. In Proceedings of the 41st
Meeting ofthe Association for Computational Linguis-
tics.
Terry Koo, Xavier Carreras, and Michael Collins. 2008.
Simple semi-supervised dependency parsing. In Pro-
ceedings ofACL-08, pages 595–603, Columbus, USA.
Percy Liang. 2005. Semi-supervised learning for natural
language. In MIT Master’s thesis, Cambridge, USA.
D.M. Magerman. 1995. Statistical decision-tree mod-
els for parsing. In Proc. of ACL’95, pages 276–283,
Morristown, NJ, USA.
Takuya Matsuzaki, Yusuke Miyao, and Jun’ichi Tsujii.
2005. Probabilistic cfg with latent annotations. In
Proceedings of the 43rd Annual Meeting of the Associ-
ation for Computational Linguistics (ACL), pages 75–
82.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and inter-
pretable tree annotation. In Proc. ofACL-06, Sydney,
Australia.
Kenji Sagae and Andrew S. Gordon. 2009. Clustering
words by syntactic similarity improves dependency
parsing of predicate-argument structures. In Proceed-
ings of the 11th International Conference on Pars-
ing Technologies (IWPT’09), pages 192–201, Paris,
France, October. Association for Computational Lin-
guistics.
Benoît Sagot. 2010. The Lefff, a freely available
and large-coverage morphological and syntactic lexi-
con for french. In Proceedings of LREC’10, Valetta,
Malta.
Djamé Seddah, Marie Candito, and Benoit Crabbé. 2009.
Cross parser evaluation and tagset variation: A French
Treebank study. In Proceedings of the 11th Interna-
tion Conference on Parsing Technologies (IWPT’09),
pages 150–161, Paris, France, October. Association
for Computational Linguistics.
Djamé Seddah, Grzegorz Chrupała, Ozlem Cetinoglu,
Josef van Genabith, and Marie Candito. 2010.
Lemmatization and statistical lexicalized parsing of
morphologically-richlanguages. In Proceedings ofthe
NAACL/HLT Workshop on Statistical Parsing of Mor-
phologically Rich Languages (SPMRL 2010), Los An-
geles, CA.
Yannick Versley and Ines Rehbein. 2009. Scalable dis-
criminative parsing for german. In Proceedings of the
11th International Conference on Parsing Technolo-
gies (IWPT’09), pages 134–137, Paris, France, Octo-
ber. Association for Computational Linguistics.
</reference>
<page confidence="0.999243">
84
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.304493">
<title confidence="0.994092">Parsing word clusters</title>
<author confidence="0.375015">Djamé</author>
<affiliation confidence="0.480589">(Université Paris 7/INRIA), 30 rue du château des rentiers 75013 Paris,</affiliation>
<address confidence="0.858213">Paris-Sorbonne, 28, rue Serpente, 75006 Paris, France</address>
<abstract confidence="0.999181314285714">We present and discuss experiments in statistical parsing of French, where terminal forms used during training and parsing are replaced by more general symbols, particularly clusters of words obtained through unsupervised linear clustering. We build on the work of Candito and Crabbé (2009) who proposed to use clusters built over slightly coarsened French inflected forms. We investigate the alternative method of building clusters over lemma/part-of-speech pairs, using a raw corpus automatically tagged and lemmatized. We find that both methods lead to comparable improvement over the baseline (we oband respectively, to a baseline of Yet, when we replace gold lemma/POS pairs with their corresponding cluster, we obtain an upbound that suggests room for improvement for this technique, should tagging/lemmatisation performance increase for French. We also analyze the improvement in performance for both techniques with respect to word frequency. We find that replacing word forms with clusters improves attachment performance for words that are originally either unknown or low-frequency, since these words are replaced by cluster symbols that tend to have higher frequencies. Furthermore, clustering also helps significantly for medium to high frequency words, suggesting that training on word clusters leads to better probability estimates for these words.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeillé</author>
<author>Lionel Clément</author>
<author>François Toussenel</author>
</authors>
<title>Building a Treebank for French.</title>
<date>2003</date>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="4527" citStr="Abeillé et al., 2003" startWordPosition="699" endWordPosition="702">rds, rare words, unknown words). In the next section, we describe the French treebank used as the basis for all of our experiments. We describe in section 3 the statistical parser used for training and testing. We then describe the desinflection process used prior to unsupervised clustering (section 4), and the Brown algorithm we use for unsupervised clustering (section ). We describe our experiments and results in section 6, and provide a discussion in section 7. We then point out some related work and conclude in section 9. 2 French Treebank For our experiments, we used the French Treebank (Abeillé et al., 2003), which contains 12531 sentences, 350931 tokens, from the newspaper Le Monde. We used the treebank instantiation (hereafter FTB-UC) as first described in (Candito and Crabbé, 2009), where: (i) the rich original annotation containing morphological and functional information is mapped to a simpler phrase-structure treebank with a tagset of 28 part-of-speech tags, and no functional annotation (ii) some compounds with regular syntax are broken down into phrases containing several simple words (iii) the remaining sequences annotated as compound words in the FTB are merged into a single token, whose</context>
</contexts>
<marker>Abeillé, Clément, Toussenel, 2003</marker>
<rawString>Anne Abeillé, Lionel Clément, and François Toussenel, 2003. Building a Treebank for French. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Timothy Baldwin</author>
<author>David Martinez</author>
</authors>
<title>Improving parsing and PP attachment performance with sense information.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>317--325</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="30380" citStr="Agirre et al. (2008)" startWordPosition="4887" endWordPosition="4890">actic clustering to improve transition-based dependency parsing for English : using an available 30 million word corpus parsed with a constituency parser, words are represented as vectors of paths within the obtained constituency parses. Words are then clustered using a similarity metric between vectors of syntactic paths. The clusters are used as features to help a transition-based dependency parser. Note that the word representation for clustering is more complex (paths in parse trees), thus these authors have to cluster a smaller vocabulary : the top 5000 most frequent words are clustered. Agirre et al. (2008) use the same approach of replacing words by more general symbols, but these symbols are semantic classes. They test various methods to assign semantic classes (gold semantic class, most-frequent sense in sense-tagged data, or a fully unsupervised sense tagger). Though the method is very appealing, the reported improvement in parsing is rather small, especially for the fully unsupervised method. Versley and Rehbein (2009) cluster words according to linear context features, and use the clusters as features to boost discriminative German parsing for unknown words. Another approach to augment the</context>
</contexts>
<marker>Agirre, Baldwin, Martinez, 2008</marker>
<rawString>Eneko Agirre, Timothy Baldwin, and David Martinez. 2008. Improving parsing and PP attachment performance with sense information. In Proceedings of ACL-08: HLT, pages 317–325, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della</author>
<author>Peter V Desouza</author>
<author>Jennifer C Lai</author>
<author>Robert L Mercer</author>
</authors>
<title>Class-based n-gram models of natural language.</title>
<date>1992</date>
<journal>Computational linguistics,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="14545" citStr="Brown et al. (1992)" startWordPosition="2312" endWordPosition="2315">res calculated using the Leffflexicon. Table 1 shows detailed results on dev set and test set of the FTB-UC, when MORFETTE is trained on the FTB-UC training set. To the best of our knowledge the parts-of-speech tagging performance is state-of-the-art for French3 and the lemmatization performance has no comparable results. 5 Unsupervised clustering 3A pure MAXENT based tagger is described in (Denis and Sagot, 2009), that also uses the Lefff, under the form of features for the known categories of a word in the lexicon. The authors report 97.70% of accuracy and 90.01% for unseen data. We use the Brown et al. (1992) hard clustering algorithm, which has proven useful for various NLP tasks such as dependency parsing (Koo et al., 2008) and named entity recognition (Liang, 2005). The algorithm to obtain C clusters is as follows: each of the C most frequent tokens of the corpus is assigned its own distinct cluster. For the (C + 1)th most frequent token, create a (C + 1)th cluster. Then for each pair among the C + 1 resulting clusters, merge the pair that minimizes the loss in the likelihood of the corpus, according to a bigram language model defined on the clusters. Repeat this operation for the (C + 2)th mos</context>
</contexts>
<marker>Brown, Della, Desouza, Lai, Mercer, 1992</marker>
<rawString>Peter F. Brown, Vincent J. Della, Peter V. Desouza, Jennifer C. Lai, and Robert L. Mercer. 1992. Class-based n-gram models of natural language. Computational linguistics, 18(4):467–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie Candito</author>
<author>Benoît Crabbé</author>
</authors>
<title>Improving generative statistical parsing with semisupervised word clustering.</title>
<date>2009</date>
<booktitle>In Proceedings of the 11th International Conference on Parsing Technologies (IWPT’09),</booktitle>
<pages>138--141</pages>
<location>Paris, France,</location>
<contexts>
<context position="2214" citStr="Candito and Crabbé (2009)" startWordPosition="334" endWordPosition="337"> leads to better probability estimates for these words. 1 Introduction Statistical parsing techniques have dramatically improved over the last 15 years, yet lexical data sparseness remains a critical problem. And the richer the morphology of a language, the sparser the treebankdriven lexicons will be for that language. Koo et al. (2008) have proposed to use word clusters as features to improve graph-based statistical dependency parsing for English and Czech. Their clusters are obtained using unsupervised clustering, which makes it possible to use a raw corpus containing several million words. Candito and Crabbé (2009) applied clustering to generative constituency parsing for French. They use a desinflection step that removes some inflection marks from word forms and then replaces them with word clusters, resulting in a significant improvement in parsing performance. Clustering words seems useful as a way of addressing the lexical data sparseness problem, since counts on clusters are more reliable and lead to better probability estimates. Clustering also appears to address the mismatch of vocabularies between the original treebank and any external, potentially out-of-domain corpus: clusters operate as an in</context>
<context position="3504" citStr="Candito and Crabbé (2009)" startWordPosition="533" endWordPosition="536">ernal corpus used to compute clusters. Furthermore, parsing word clusters instead of word forms augments the known vocabulary. However, depending on the clustering method, clusters are either not very reliable or are available only for very frequent words. In order to parse word clusters one needs to determine which word clusters are reliable enough to be beneficial, so the tuning of parameters such as cluster granularity and cluster reliability becomes very important. The aim of this paper is to give an in-depth study of the &amp;quot;parsing word clusters&amp;quot; technique. In particular, starting from the Candito and Crabbé (2009) experiments, we investigate the use of clustering lem76 Proceedings of the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 76–84, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics mas instead of desinflected forms. We also provide an analysis of the performance gains obtained with respect to word frequency (frequent words, rare words, unknown words). In the next section, we describe the French treebank used as the basis for all of our experiments. We describe in section 3 the statistical parser used for training </context>
<context position="7790" citStr="Candito and Crabbé, 2009" startWordPosition="1224" endWordPosition="1227">re not seen in the first half, and that have this tag. For unknown words, words signatures are used: these are word classes determined by information such as the word suffix, whether the word is capitalized, whether it contains digits, etc. P(wItag) is estimated with P(signature(w) tag), and is also smoothed in the same way rare words are. 4 Morphological clustering A first approach to word clustering is to cluster forms on a morphological basis. In the case of a relatively morphologically rich language such as French, this is an obvious way to reduce lexical sparseness caused by inflection. (Candito and Crabbé, 2009) proposed the use of a desinflection method, without resorting to part-ofspeech tagging. We propose an alternate method here, which uses lemmas and part-of-speech tags that are output by a tagger/lemmatizer. Because 77 counts on lemmas are more reliable, clustering over lemmas presumably produces clusters that are more reliable than those produced by clustering over desinflected forms. However, this approach does create a constraint in which automatically tagged and lemmatized text is required as input to the parser, leading to the introduction of tagging errors. Both morphological clustering </context>
<context position="10820" citStr="Candito and Crabbé (2009)" startWordPosition="1707" endWordPosition="1710">a is to leave unchanged the parser’s task in disambiguating part-of-speech tags. In that case, morphological clustering using lemmas is not an option, since lemma assignment presupposes POS disambiguation. Furthermore, useful information such as verb mood (which is needed to capture, for instance, that infinitive verbs have no overt subject or that participial clauses are sentence modifiers) is discarded during lemmatization, though it is encoded in the FTB with different projections for finite verbs (projecting sentences) versus non finite verbs (projecting VPpart or VPinf). The intuition of Candito and Crabbé (2009) is that other inflectional markers in French (gender and number for determiners, adjectives, pronouns and nouns, or tense and person for verbs) are not crucial for inferring the correct phrase-structure projection for a given word. Consequently, they proposed to achieve morphological clustering by desinflection, namely by removing unneeded inflectional markers, identified using the Lefff. This lexicon-based technique can be viewed as an intermediate method between stemming and lemmatization. The desinflection process is as follows: for a token t to desinflect, if it is known in the lexicon, t</context>
<context position="18385" citStr="Candito and Crabbé, 2009" startWordPosition="2925" endWordPosition="2928">performance as clusters of tag+lemma pairs. 6.2 Berkeley parser settings For BKY we used Slav Petrov’s code, adapted for French by Crabbé and Candito (2008) by modifying the suffixes used to classify unknown words. We use the partition between training, development and test sets introduced in section 2. Note though that the BKY algorithm itself uses two sets of sentences at training: a learning set and a smaller validation set for tuning model hyperparameters. In all experiments in this paper, we used 2% of the training set as as a validation set, and 98% as a learning set. This differs from (Candito and Crabbé, 2009), where the dev set was used as a validation set. 6.3 Experiments We then tested several settings differing only in the terminal symbols used in the training set, and in the dev and test sets. We list these settings in table 2. For the settings involving unsupervised linear clustering: DFL+CLUST&gt;X: Each desinflected form df is replaced by Clusters(df) : if df occurred more than X times in the L’Est Républicain corpus, it is replaced by its cluster id, otherwise, a special cluster UNKC is used. Further, a _c suffix is added if lemmatization renders this step obsolete. the desinflected form star</context>
<context position="22557" citStr="Candito and Crabbé, 2009" startWordPosition="3580" endWordPosition="3583">sing the conversion procedure and software of (Candito et al., 2010)8. Punctuation tokens are ignored in all metrics. 7 Discussion Results are shown in table 3. Our hope was that using lemmatization would improve overall accuracy of unsupervised clustering, hence leading to better parsing performance. However, results using both methods are comparable. 7Note that often for statistical constituent parsing results are given for sentences of less than 40 words, whereas for dependency parsing, there is no such limitation. The experiment DFL and DFL+CLUST&gt;200 are reproduced from the previous work (Candito and Crabbé, 2009). More precisely, this previous work reports F1 = 88.29 on the test set, but for sentences &lt; 40 words, for a DFL+CLUST&gt;20 experiment, and as previously mentioned, the dev set was used as validation set for the BKY algorithm. We report now F1 = 88.22 for the same less-than40-words sentences, leaving dev set unused at training time. 8The conversion uses head propagation rules to find the head on the right-hand side of the CFG rules, first proposed for English in (Magerman, 1995). Hence the process is highly sensitive to part-of-speech tags. Table 3 shows that both morphological clustering techni</context>
</contexts>
<marker>Candito, Crabbé, 2009</marker>
<rawString>Marie Candito and Benoît Crabbé. 2009. Improving generative statistical parsing with semisupervised word clustering. In Proceedings of the 11th International Conference on Parsing Technologies (IWPT’09), pages 138–141, Paris, France, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie Candito</author>
<author>Benoit Crabbé</author>
<author>Pascal Denis</author>
</authors>
<title>Statistical french dependency parsing : Treebank conversion and first results.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC’2010,</booktitle>
<location>Valletta,</location>
<contexts>
<context position="5878" citStr="Candito et al., 2010" startWordPosition="913" endWordPosition="916"> the treebank as these authors : first 10% for test, next 10% for dev and the rest for training1. 3 Berkeley Parser We report here experiments using the Berkeley PCFG parser with latent annotations (Petrov et al., 2006), hereafter BKY, which is a constituent parser that has been proven to perform well for French (Crabbé and Candito, 2008; Seddah et al., 2009), 1More precisely the partition is : first 1235 sentences for test, next 1235 sentences for development, and remaining 9881 sentences for training. though a little lower than a combination of a tagger plus the dependency-based MST parser (Candito et al., 2010). Though PCFG-style parsers operate on too narrow a domain of locality, splitting symbols according to structural and/or lexical properties is known to help parsing (Klein and Manning., 2003). Following (Matsuzaki et al., 2005), the BKY algorithm uses EM to estimate probabilities on symbols that are automatically augmented with latent annotations, a process which can be viewed as symbol splitting. It iteratively evaluates each such split and merges back the less beneficial ones. Crabbé and Candito (2008) show that some of the information carried by the latent annotations is lexical, since repl</context>
<context position="22000" citStr="Candito et al., 2010" startWordPosition="3495" endWordPosition="3498">minal symbols. F1&lt;40 is the F-Measure combining labeled precision and labeled recall for sentences of less than 40 words. All other metrics are for all sentences of the dev set/test set. UAS = Unlabeled attachement score of converted constituency trees into surface dependency trees. All metrics ignore punctuation tokens. recall) both for sentences of less than 40 words, and for all sentences7. We also use the unlabeled attachment score (UAS), obtained when converting the constituency trees output by the BKY parsers into surface dependency trees, using the conversion procedure and software of (Candito et al., 2010)8. Punctuation tokens are ignored in all metrics. 7 Discussion Results are shown in table 3. Our hope was that using lemmatization would improve overall accuracy of unsupervised clustering, hence leading to better parsing performance. However, results using both methods are comparable. 7Note that often for statistical constituent parsing results are given for sentences of less than 40 words, whereas for dependency parsing, there is no such limitation. The experiment DFL and DFL+CLUST&gt;200 are reproduced from the previous work (Candito and Crabbé, 2009). More precisely, this previous work report</context>
</contexts>
<marker>Candito, Crabbé, Denis, 2010</marker>
<rawString>Marie Candito, Benoit Crabbé, and Pascal Denis. 2010. Statistical french dependency parsing : Treebank conversion and first results. In Proceedings of LREC’2010, Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Chrupała</author>
<author>Georgiana Dinu</author>
<author>Josef van Genabith</author>
</authors>
<title>Learning morphology with morfette. In</title>
<date>2008</date>
<booktitle>In Proceedings of LREC 2008,</booktitle>
<location>Marrakech, Morocco. ELDA/ELRA.</location>
<marker>Chrupała, Dinu, van Genabith, 2008</marker>
<rawString>Grzegorz Chrupała, Georgiana Dinu, and Josef van Genabith. 2008. Learning morphology with morfette. In In Proceedings of LREC 2008, Marrakech, Morocco. ELDA/ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benoit Crabbé</author>
<author>Marie Candito</author>
</authors>
<title>Expériences d’analyse syntaxique statistique du français.</title>
<date>2008</date>
<booktitle>In Actes de la 15ème Conférence sur le Traitement Automatique des Langues Naturelles (TALN’08),</booktitle>
<pages>45--54</pages>
<location>Avignon, France.</location>
<contexts>
<context position="5596" citStr="Crabbé and Candito, 2008" startWordPosition="868" endWordPosition="871">own into phrases containing several simple words (iii) the remaining sequences annotated as compound words in the FTB are merged into a single token, whose components are separated with an underscore For all experiments in this paper (tagging and parsing) we used the same partition of the treebank as these authors : first 10% for test, next 10% for dev and the rest for training1. 3 Berkeley Parser We report here experiments using the Berkeley PCFG parser with latent annotations (Petrov et al., 2006), hereafter BKY, which is a constituent parser that has been proven to perform well for French (Crabbé and Candito, 2008; Seddah et al., 2009), 1More precisely the partition is : first 1235 sentences for test, next 1235 sentences for development, and remaining 9881 sentences for training. though a little lower than a combination of a tagger plus the dependency-based MST parser (Candito et al., 2010). Though PCFG-style parsers operate on too narrow a domain of locality, splitting symbols according to structural and/or lexical properties is known to help parsing (Klein and Manning., 2003). Following (Matsuzaki et al., 2005), the BKY algorithm uses EM to estimate probabilities on symbols that are automatically aug</context>
<context position="17916" citStr="Crabbé and Candito (2008)" startWordPosition="2843" endWordPosition="2846">OS+lemma) Table 2: Types of terminal symbols used for training and parsing In the first case we obtain clusters of desinflected forms, whereas in the second case we obtain clusters of tag+lemma pairs. Note that lemmas alone could be used, but as noted earlier, important syntactic information would be lost, particularly for verb mood. We did try using clusters of lemmas, coupled with a few suffixes to record the verb mood, but this resulted in more or less the same performance as clusters of tag+lemma pairs. 6.2 Berkeley parser settings For BKY we used Slav Petrov’s code, adapted for French by Crabbé and Candito (2008) by modifying the suffixes used to classify unknown words. We use the partition between training, development and test sets introduced in section 2. Note though that the BKY algorithm itself uses two sets of sentences at training: a learning set and a smaller validation set for tuning model hyperparameters. In all experiments in this paper, we used 2% of the training set as as a validation set, and 98% as a learning set. This differs from (Candito and Crabbé, 2009), where the dev set was used as a validation set. 6.3 Experiments We then tested several settings differing only in the terminal sy</context>
</contexts>
<marker>Crabbé, Candito, 2008</marker>
<rawString>Benoit Crabbé and Marie Candito. 2008. Expériences d’analyse syntaxique statistique du français. In Actes de la 15ème Conférence sur le Traitement Automatique des Langues Naturelles (TALN’08), pages 45–54, Avignon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascal Denis</author>
<author>Benoît Sagot</author>
</authors>
<title>Coupling an annotated corpus and a morphosyntactic lexicon for stateof-the-art pos tagging with less human effort.</title>
<date>2009</date>
<booktitle>In Proc. ofPACLIC,</booktitle>
<location>Hong Kong, China.</location>
<contexts>
<context position="14343" citStr="Denis and Sagot, 2009" startWordPosition="2274" endWordPosition="2277">MORFETTE models described in (Seddah et al., 2010), that are trained using the Averaged Sequence Perceptron algorithm (Freund and Schapire, 1999). The two classification models incorporate additional features calculated using the Leffflexicon. Table 1 shows detailed results on dev set and test set of the FTB-UC, when MORFETTE is trained on the FTB-UC training set. To the best of our knowledge the parts-of-speech tagging performance is state-of-the-art for French3 and the lemmatization performance has no comparable results. 5 Unsupervised clustering 3A pure MAXENT based tagger is described in (Denis and Sagot, 2009), that also uses the Lefff, under the form of features for the known categories of a word in the lexicon. The authors report 97.70% of accuracy and 90.01% for unseen data. We use the Brown et al. (1992) hard clustering algorithm, which has proven useful for various NLP tasks such as dependency parsing (Koo et al., 2008) and named entity recognition (Liang, 2005). The algorithm to obtain C clusters is as follows: each of the C most frequent tokens of the corpus is assigned its own distinct cluster. For the (C + 1)th most frequent token, create a (C + 1)th cluster. Then for each pair among the C</context>
</contexts>
<marker>Denis, Sagot, 2009</marker>
<rawString>Pascal Denis and Benoît Sagot. 2009. Coupling an annotated corpus and a morphosyntactic lexicon for stateof-the-art pos tagging with less human effort. In Proc. ofPACLIC, Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Freund</author>
<author>Robert E Schapire</author>
</authors>
<title>Large margin classification using the perceptron algorithm.</title>
<date>1999</date>
<booktitle>Machine learning,</booktitle>
<pages>37--3</pages>
<contexts>
<context position="13866" citStr="Freund and Schapire, 1999" startWordPosition="2201" endWordPosition="2204">rom 24110 to 18052. 4.3 Part-of-speech tagging and lemmatization In order to assign morphological tags and lemmas to words we use a variation of the MORFETTE model described in (Chrupała et al., 2008). It is a sequence labeling model which combines the predictions of two classification models (one for morphological tagging and one for lemmatization) at decoding time, using a beam search. While (Chrupała et al., 2008) use Maximum Entropy training to learn PM and PL, we use the MORFETTE models described in (Seddah et al., 2010), that are trained using the Averaged Sequence Perceptron algorithm (Freund and Schapire, 1999). The two classification models incorporate additional features calculated using the Leffflexicon. Table 1 shows detailed results on dev set and test set of the FTB-UC, when MORFETTE is trained on the FTB-UC training set. To the best of our knowledge the parts-of-speech tagging performance is state-of-the-art for French3 and the lemmatization performance has no comparable results. 5 Unsupervised clustering 3A pure MAXENT based tagger is described in (Denis and Sagot, 2009), that also uses the Lefff, under the form of features for the known categories of a word in the lexicon. The authors repor</context>
</contexts>
<marker>Freund, Schapire, 1999</marker>
<rawString>Yoav Freund and Robert E. Schapire. 1999. Large margin classification using the perceptron algorithm. Machine learning, 37(3):277–296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Reut Tsarfaty</author>
<author>Meni Adler</author>
<author>Michael Elhadad</author>
</authors>
<title>Enhancing unlexicalized parsing performance using a wide coverage lexicon, fuzzy tag-set mapping, and EM-HMM-based lexical probabilities.</title>
<date>2009</date>
<booktitle>In Proc. of EACL-09,</booktitle>
<pages>327--335</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="31081" citStr="Goldberg et al., 2009" startWordPosition="4996" endWordPosition="4999">mbols are semantic classes. They test various methods to assign semantic classes (gold semantic class, most-frequent sense in sense-tagged data, or a fully unsupervised sense tagger). Though the method is very appealing, the reported improvement in parsing is rather small, especially for the fully unsupervised method. Versley and Rehbein (2009) cluster words according to linear context features, and use the clusters as features to boost discriminative German parsing for unknown words. Another approach to augment the known vocabulary for a generative probabilistic parser is the one pursued in (Goldberg et al., 2009). Within a plain PCFG, the lexical probabilities for words that are rare or absent in the treebank are taken from an external lexical probability distribution, estimated using a lexicon and the Baulm-Welch training of an HMM tagger. This is proven useful to better parse Hebrew. 9 Conclusion and future work We have provided a thorough study of the results of parsing word clusters for French. We showed that the clustering improves performance both for unseen and rare words and for medium- to highfrequency words. For French, preprocessing words with desinflection or with tagging+lemmatisation lea</context>
</contexts>
<marker>Goldberg, Tsarfaty, Adler, Elhadad, 2009</marker>
<rawString>Yoav Goldberg, Reut Tsarfaty, Meni Adler, and Michael Elhadad. 2009. Enhancing unlexicalized parsing performance using a wide coverage lexicon, fuzzy tag-set mapping, and EM-HMM-based lexical probabilities. In Proc. of EACL-09, pages 327–335, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Meeting ofthe Association for Computational Linguistics.</booktitle>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Meeting ofthe Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Xavier Carreras</author>
<author>Michael Collins</author>
</authors>
<title>Simple semi-supervised dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL-08,</booktitle>
<pages>595--603</pages>
<location>Columbus, USA.</location>
<contexts>
<context position="1927" citStr="Koo et al. (2008)" startWordPosition="290" endWordPosition="293">e for words that are originally either unknown or low-frequency, since these words are replaced by cluster symbols that tend to have higher frequencies. Furthermore, clustering also helps significantly for medium to high frequency words, suggesting that training on word clusters leads to better probability estimates for these words. 1 Introduction Statistical parsing techniques have dramatically improved over the last 15 years, yet lexical data sparseness remains a critical problem. And the richer the morphology of a language, the sparser the treebankdriven lexicons will be for that language. Koo et al. (2008) have proposed to use word clusters as features to improve graph-based statistical dependency parsing for English and Czech. Their clusters are obtained using unsupervised clustering, which makes it possible to use a raw corpus containing several million words. Candito and Crabbé (2009) applied clustering to generative constituency parsing for French. They use a desinflection step that removes some inflection marks from word forms and then replaces them with word clusters, resulting in a significant improvement in parsing performance. Clustering words seems useful as a way of addressing the le</context>
<context position="14664" citStr="Koo et al., 2008" startWordPosition="2332" endWordPosition="2335">E is trained on the FTB-UC training set. To the best of our knowledge the parts-of-speech tagging performance is state-of-the-art for French3 and the lemmatization performance has no comparable results. 5 Unsupervised clustering 3A pure MAXENT based tagger is described in (Denis and Sagot, 2009), that also uses the Lefff, under the form of features for the known categories of a word in the lexicon. The authors report 97.70% of accuracy and 90.01% for unseen data. We use the Brown et al. (1992) hard clustering algorithm, which has proven useful for various NLP tasks such as dependency parsing (Koo et al., 2008) and named entity recognition (Liang, 2005). The algorithm to obtain C clusters is as follows: each of the C most frequent tokens of the corpus is assigned its own distinct cluster. For the (C + 1)th most frequent token, create a (C + 1)th cluster. Then for each pair among the C + 1 resulting clusters, merge the pair that minimizes the loss in the likelihood of the corpus, according to a bigram language model defined on the clusters. Repeat this operation for the (C + 2)th most frequent token, etc. The result is a hard clustering of words in the corpus into C distinct clusters, though the proc</context>
<context position="29677" citStr="Koo et al. (2008)" startWordPosition="4776" endWordPosition="4779">81 96.83 95.07 90.60 97.21 replaced by UNKC* 8.58 90.64 88.10 8.73 89.67 90.07 Table 5: Tagging accuracy and UAS scores for modified terminal symbols in the dev set, grouped by ranges of frequencies in the modified training sets. The “replaced by UNKC*” line corresponds to the case where the desinflected form or the POS+lemma pair does not appear more than 200 times in the L’est Républicain corpus. unsupervised Brown clustering, which uses very local information, the higher counts lead to better estimates even for high-frequency words. 8 Related work We have already cited the previous work of Koo et al. (2008) which has directly inspired ours. Sagae and Gordon (2009) explores the use of syntactic clustering to improve transition-based dependency parsing for English : using an available 30 million word corpus parsed with a constituency parser, words are represented as vectors of paths within the obtained constituency parses. Words are then clustered using a similarity metric between vectors of syntactic paths. The clusters are used as features to help a transition-based dependency parser. Note that the word representation for clustering is more complex (paths in parse trees), thus these authors have</context>
</contexts>
<marker>Koo, Carreras, Collins, 2008</marker>
<rawString>Terry Koo, Xavier Carreras, and Michael Collins. 2008. Simple semi-supervised dependency parsing. In Proceedings ofACL-08, pages 595–603, Columbus, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
</authors>
<title>Semi-supervised learning for natural language.</title>
<date>2005</date>
<booktitle>In MIT Master’s thesis,</booktitle>
<location>Cambridge, USA.</location>
<contexts>
<context position="14707" citStr="Liang, 2005" startWordPosition="2340" endWordPosition="2341">best of our knowledge the parts-of-speech tagging performance is state-of-the-art for French3 and the lemmatization performance has no comparable results. 5 Unsupervised clustering 3A pure MAXENT based tagger is described in (Denis and Sagot, 2009), that also uses the Lefff, under the form of features for the known categories of a word in the lexicon. The authors report 97.70% of accuracy and 90.01% for unseen data. We use the Brown et al. (1992) hard clustering algorithm, which has proven useful for various NLP tasks such as dependency parsing (Koo et al., 2008) and named entity recognition (Liang, 2005). The algorithm to obtain C clusters is as follows: each of the C most frequent tokens of the corpus is assigned its own distinct cluster. For the (C + 1)th most frequent token, create a (C + 1)th cluster. Then for each pair among the C + 1 resulting clusters, merge the pair that minimizes the loss in the likelihood of the corpus, according to a bigram language model defined on the clusters. Repeat this operation for the (C + 2)th most frequent token, etc. The result is a hard clustering of words in the corpus into C distinct clusters, though the process can be continued to further merge pairs</context>
</contexts>
<marker>Liang, 2005</marker>
<rawString>Percy Liang. 2005. Semi-supervised learning for natural language. In MIT Master’s thesis, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Magerman</author>
</authors>
<title>Statistical decision-tree models for parsing.</title>
<date>1995</date>
<booktitle>In Proc. of ACL’95,</booktitle>
<pages>276--283</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="23038" citStr="Magerman, 1995" startWordPosition="3666" endWordPosition="3667">ng, there is no such limitation. The experiment DFL and DFL+CLUST&gt;200 are reproduced from the previous work (Candito and Crabbé, 2009). More precisely, this previous work reports F1 = 88.29 on the test set, but for sentences &lt; 40 words, for a DFL+CLUST&gt;20 experiment, and as previously mentioned, the dev set was used as validation set for the BKY algorithm. We report now F1 = 88.22 for the same less-than40-words sentences, leaving dev set unused at training time. 8The conversion uses head propagation rules to find the head on the right-hand side of the CFG rules, first proposed for English in (Magerman, 1995). Hence the process is highly sensitive to part-of-speech tags. Table 3 shows that both morphological clustering techniques (DFL and AUTOCATLEMMA) slightly improve performance (+0.97 and +0.73 F1 over the baseline for the test set)9. In the case of AUTOCATLEMMA, morphological ambiguity is totally absent in training set: each terminal symbol is the gold POS+lemma pair, and hence appears with a unique part-of-speech in the whole training set. But at parsing time, the terminal symbols are the POS+lemma pairs predicted by MORFETTE, which are wrong for approximately 3% of the tokens. So when compar</context>
</contexts>
<marker>Magerman, 1995</marker>
<rawString>D.M. Magerman. 1995. Statistical decision-tree models for parsing. In Proc. of ACL’95, pages 276–283, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takuya Matsuzaki</author>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Probabilistic cfg with latent annotations.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>75--82</pages>
<contexts>
<context position="6105" citStr="Matsuzaki et al., 2005" startWordPosition="946" endWordPosition="949">after BKY, which is a constituent parser that has been proven to perform well for French (Crabbé and Candito, 2008; Seddah et al., 2009), 1More precisely the partition is : first 1235 sentences for test, next 1235 sentences for development, and remaining 9881 sentences for training. though a little lower than a combination of a tagger plus the dependency-based MST parser (Candito et al., 2010). Though PCFG-style parsers operate on too narrow a domain of locality, splitting symbols according to structural and/or lexical properties is known to help parsing (Klein and Manning., 2003). Following (Matsuzaki et al., 2005), the BKY algorithm uses EM to estimate probabilities on symbols that are automatically augmented with latent annotations, a process which can be viewed as symbol splitting. It iteratively evaluates each such split and merges back the less beneficial ones. Crabbé and Candito (2008) show that some of the information carried by the latent annotations is lexical, since replacing words by their gold part-of-speech tag leads to worse results than the corresponding perfect tagging test, with words unchanged. This is a clear indication that lexical distinctions are used, and percolate up the parse tr</context>
</contexts>
<marker>Matsuzaki, Miyao, Tsujii, 2005</marker>
<rawString>Takuya Matsuzaki, Yusuke Miyao, and Jun’ichi Tsujii. 2005. Probabilistic cfg with latent annotations. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 75– 82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In Proc. ofACL-06,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="5476" citStr="Petrov et al., 2006" startWordPosition="848" endWordPosition="851"> tagset of 28 part-of-speech tags, and no functional annotation (ii) some compounds with regular syntax are broken down into phrases containing several simple words (iii) the remaining sequences annotated as compound words in the FTB are merged into a single token, whose components are separated with an underscore For all experiments in this paper (tagging and parsing) we used the same partition of the treebank as these authors : first 10% for test, next 10% for dev and the rest for training1. 3 Berkeley Parser We report here experiments using the Berkeley PCFG parser with latent annotations (Petrov et al., 2006), hereafter BKY, which is a constituent parser that has been proven to perform well for French (Crabbé and Candito, 2008; Seddah et al., 2009), 1More precisely the partition is : first 1235 sentences for test, next 1235 sentences for development, and remaining 9881 sentences for training. though a little lower than a combination of a tagger plus the dependency-based MST parser (Candito et al., 2010). Though PCFG-style parsers operate on too narrow a domain of locality, splitting symbols according to structural and/or lexical properties is known to help parsing (Klein and Manning., 2003). Follo</context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proc. ofACL-06, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Andrew S Gordon</author>
</authors>
<title>Clustering words by syntactic similarity improves dependency parsing of predicate-argument structures.</title>
<date>2009</date>
<booktitle>In Proceedings of the 11th International Conference on Parsing Technologies (IWPT’09),</booktitle>
<pages>192--201</pages>
<location>Paris, France,</location>
<contexts>
<context position="29735" citStr="Sagae and Gordon (2009)" startWordPosition="4785" endWordPosition="4788">.64 88.10 8.73 89.67 90.07 Table 5: Tagging accuracy and UAS scores for modified terminal symbols in the dev set, grouped by ranges of frequencies in the modified training sets. The “replaced by UNKC*” line corresponds to the case where the desinflected form or the POS+lemma pair does not appear more than 200 times in the L’est Républicain corpus. unsupervised Brown clustering, which uses very local information, the higher counts lead to better estimates even for high-frequency words. 8 Related work We have already cited the previous work of Koo et al. (2008) which has directly inspired ours. Sagae and Gordon (2009) explores the use of syntactic clustering to improve transition-based dependency parsing for English : using an available 30 million word corpus parsed with a constituency parser, words are represented as vectors of paths within the obtained constituency parses. Words are then clustered using a similarity metric between vectors of syntactic paths. The clusters are used as features to help a transition-based dependency parser. Note that the word representation for clustering is more complex (paths in parse trees), thus these authors have to cluster a smaller vocabulary : the top 5000 most frequ</context>
</contexts>
<marker>Sagae, Gordon, 2009</marker>
<rawString>Kenji Sagae and Andrew S. Gordon. 2009. Clustering words by syntactic similarity improves dependency parsing of predicate-argument structures. In Proceedings of the 11th International Conference on Parsing Technologies (IWPT’09), pages 192–201, Paris, France, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benoît Sagot</author>
</authors>
<title>The Lefff, a freely available and large-coverage morphological and syntactic lexicon for french.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC’10,</booktitle>
<location>Valetta,</location>
<contexts>
<context position="8441" citStr="Sagot, 2010" startWordPosition="1323" endWordPosition="1324">thod, without resorting to part-ofspeech tagging. We propose an alternate method here, which uses lemmas and part-of-speech tags that are output by a tagger/lemmatizer. Because 77 counts on lemmas are more reliable, clustering over lemmas presumably produces clusters that are more reliable than those produced by clustering over desinflected forms. However, this approach does create a constraint in which automatically tagged and lemmatized text is required as input to the parser, leading to the introduction of tagging errors. Both morphological clustering methods make use of the Lefff lexicon (Sagot, 2010). Before we describe these two methods, we briefly give basic information on French inflectional morphology and on the Lefff. 4.1 French inflection and the Leff lexicon French nouns appear in singular and plural forms, and have an intrinsic gender. The number and gender of a noun determines the number and gender of determiners, adjectives, past participles that depend on it. Hence in the general case, past participles and adjectives have four different forms. The major inflectional variation appears for finite verbs that vary for tense, mood, person and number. A regular verb may correspond to</context>
<context position="9706" citStr="Sagot, 2010" startWordPosition="1535" endWordPosition="1536">are included. In practice, some forms occur very rarely, because some tense/mood pairs are rare, and further, in the case of newspaper text for instance, the first and second persons are also rare. So for instance in the FTB-UC, there are 33 different forms for the highly frequent verb and auxiliary avoir (to have), that appears 4557 times. The medium frequency verb donner (to give) occurs 155 times, under 15 different forms. In the whole treebank, there are 27130 unique word forms, corresponding to 17570 lemmas. The Lefff is a freely available rich morphological and syntactic French lexicon (Sagot, 2010). It contains 110, 477 lemmas (simple and compounds) and 536,375 inflected forms. The coverage on the FTB-UC is high : around 96% of the tokens, and 80,1% of the types are present in the Lefff (leaving out punctuation and numeric tokens, and ignoring case differences). 4.2 Desinflection The aim of the desinflection step is to reduce lexical data sparseness caused by inflection, without hurting parsability and without committing oneself as far as lexical ambiguity is concerned. The idea is to leave unchanged the parser’s task in disambiguating part-of-speech tags. In that case, morphological cl</context>
</contexts>
<marker>Sagot, 2010</marker>
<rawString>Benoît Sagot. 2010. The Lefff, a freely available and large-coverage morphological and syntactic lexicon for french. In Proceedings of LREC’10, Valetta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Djamé Seddah</author>
<author>Marie Candito</author>
<author>Benoit Crabbé</author>
</authors>
<title>Cross parser evaluation and tagset variation: A French Treebank study.</title>
<date>2009</date>
<booktitle>In Proceedings of the 11th Internation Conference on Parsing Technologies (IWPT’09),</booktitle>
<pages>150--161</pages>
<location>Paris, France,</location>
<contexts>
<context position="5618" citStr="Seddah et al., 2009" startWordPosition="872" endWordPosition="875">g several simple words (iii) the remaining sequences annotated as compound words in the FTB are merged into a single token, whose components are separated with an underscore For all experiments in this paper (tagging and parsing) we used the same partition of the treebank as these authors : first 10% for test, next 10% for dev and the rest for training1. 3 Berkeley Parser We report here experiments using the Berkeley PCFG parser with latent annotations (Petrov et al., 2006), hereafter BKY, which is a constituent parser that has been proven to perform well for French (Crabbé and Candito, 2008; Seddah et al., 2009), 1More precisely the partition is : first 1235 sentences for test, next 1235 sentences for development, and remaining 9881 sentences for training. though a little lower than a combination of a tagger plus the dependency-based MST parser (Candito et al., 2010). Though PCFG-style parsers operate on too narrow a domain of locality, splitting symbols according to structural and/or lexical properties is known to help parsing (Klein and Manning., 2003). Following (Matsuzaki et al., 2005), the BKY algorithm uses EM to estimate probabilities on symbols that are automatically augmented with latent ann</context>
</contexts>
<marker>Seddah, Candito, Crabbé, 2009</marker>
<rawString>Djamé Seddah, Marie Candito, and Benoit Crabbé. 2009. Cross parser evaluation and tagset variation: A French Treebank study. In Proceedings of the 11th Internation Conference on Parsing Technologies (IWPT’09), pages 150–161, Paris, France, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Djamé Seddah</author>
<author>Grzegorz Chrupała</author>
<author>Ozlem Cetinoglu</author>
<author>Josef van Genabith</author>
<author>Marie Candito</author>
</authors>
<title>Lemmatization and statistical lexicalized parsing of morphologically-richlanguages.</title>
<date>2010</date>
<booktitle>In Proceedings ofthe NAACL/HLT Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL 2010),</booktitle>
<location>Los Angeles, CA.</location>
<marker>Seddah, Chrupała, Cetinoglu, van Genabith, Candito, 2010</marker>
<rawString>Djamé Seddah, Grzegorz Chrupała, Ozlem Cetinoglu, Josef van Genabith, and Marie Candito. 2010. Lemmatization and statistical lexicalized parsing of morphologically-richlanguages. In Proceedings ofthe NAACL/HLT Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL 2010), Los Angeles, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Versley</author>
<author>Ines Rehbein</author>
</authors>
<title>Scalable discriminative parsing for german.</title>
<date>2009</date>
<booktitle>In Proceedings of the 11th International Conference on Parsing Technologies (IWPT’09),</booktitle>
<pages>134--137</pages>
<location>Paris, France,</location>
<contexts>
<context position="30805" citStr="Versley and Rehbein (2009)" startWordPosition="4953" endWordPosition="4956">word representation for clustering is more complex (paths in parse trees), thus these authors have to cluster a smaller vocabulary : the top 5000 most frequent words are clustered. Agirre et al. (2008) use the same approach of replacing words by more general symbols, but these symbols are semantic classes. They test various methods to assign semantic classes (gold semantic class, most-frequent sense in sense-tagged data, or a fully unsupervised sense tagger). Though the method is very appealing, the reported improvement in parsing is rather small, especially for the fully unsupervised method. Versley and Rehbein (2009) cluster words according to linear context features, and use the clusters as features to boost discriminative German parsing for unknown words. Another approach to augment the known vocabulary for a generative probabilistic parser is the one pursued in (Goldberg et al., 2009). Within a plain PCFG, the lexical probabilities for words that are rare or absent in the treebank are taken from an external lexical probability distribution, estimated using a lexicon and the Baulm-Welch training of an HMM tagger. This is proven useful to better parse Hebrew. 9 Conclusion and future work We have provided</context>
</contexts>
<marker>Versley, Rehbein, 2009</marker>
<rawString>Yannick Versley and Ines Rehbein. 2009. Scalable discriminative parsing for german. In Proceedings of the 11th International Conference on Parsing Technologies (IWPT’09), pages 134–137, Paris, France, October. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>