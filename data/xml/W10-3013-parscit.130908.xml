<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000018">
<title confidence="0.9951025">
Hedge Detection and Scope Finding by Sequence Labeling
with Normalized Feature Selection∗
</title>
<author confidence="0.996689">
Shaodian Zhang12, Hai Zhao123†, Guodong Zhou3 and Bao-Liang Lu12
</author>
<affiliation confidence="0.99852">
1Center for Brain-Like Computing and Machine Intelligence
Dept of Computer Science and Engineering, Shanghai Jiao Tong University
2MOE-Microsoft Key Laboratory for Intelligent Computing and Intelligent Systems
Shanghai Jiao Tong University
3School of Computer Science and Technology, Soochow University
</affiliation>
<email confidence="0.983666">
zhangsd.sjtu@gmail.com, zhaohai@cs.sjtu.edu.cn
gdzhou@suda.edu.cn, blu@cs.sjtu.edu.cn
</email>
<sectionHeader confidence="0.993845" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999885210526316">
This paper presents a system which adopts
a standard sequence labeling technique for
hedge detection and scope finding. For
the first task, hedge detection, we formu-
late it as a hedge labeling problem, while
for the second task, we use a two-step la-
beling strategy, one for hedge cue label-
ing and the other for scope finding. In par-
ticular, various kinds of syntactic features
are systemically exploited and effectively
integrated using a large-scale normalized
feature selection method. Evaluation on
the CoNLL-2010 shared task shows that
our system achieves stable and competi-
tive results for all the closed tasks. Fur-
thermore, post-deadline experiments show
that the performance can be much further
improved using a sufficient feature selec-
tion.
</bodyText>
<sectionHeader confidence="0.998987" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9996685">
Hedges are linguistic devices representing spec-
ulative parts of articles. Previous works such as
(Hyland, 1996; Marco and Mercer, 2004; Light et
al., 2004; Thompson et al., 2008) present research
on hedge mainly as a linguistic phenomenon.
Meanwhile, detecting hedges and their scopes au-
tomatically are increasingly important tasks in nat-
ural language processing and information extrac-
tion, especially in biomedical community. The
shared task of CoNLL-2010 described in Farkas
et al. (2010) aims at detecting hedges (task 1)
and finding their scopes (task 2) for the literature
</bodyText>
<footnote confidence="0.786377">
∗ This work is partially supported by the National
Natural Science Foundation of China (Grants 60903119,
60773090, 90820018 and 90920004), the National Basic Re-
search Program of China (Grant No. 2009CB320901), and
the National High-Tech Research Program of China (Grant
No.2008AA02Z315).
†corresponding author
</footnote>
<bodyText confidence="0.999671909090909">
from BioScope corpus (Szarvas et al., 2008) and
Wikipedia. This paper describes a system adopt-
ing sequence labeling which performs competitive
in the official evaluation, as well as further test.
In addition, a large-scale feature selection proce-
dure is applied in training and development. Con-
sidering that BioScope corpus is annotated by two
independent linguists according to a formal guide-
line (Szarvas, 2008), while Wikipedia weasels are
tagged by netizens who are diverse in background
and various in evaluation criterion, it is needed to
handle them separately. Our system selects fea-
tures for Wikipedia and BioScope corpus indepen-
dently and evaluate them respectively, leading to
fine performances for all of them.
The rest of the paper is organized as follows.
The next section presents the technical details of
our system of hedge detection and scope finding.
Section 3 gives information of features. Section
4 shows the evaluation results, including official
results and further ones after official outputs col-
lection. Section 5 concludes the paper.
</bodyText>
<sectionHeader confidence="0.996837" genericHeader="introduction">
2 Methods
</sectionHeader>
<bodyText confidence="0.9999362">
Basically, the tasks are formulated as sequence la-
beling in our approach. The available label set dif-
fers between task 1 and 2. In addition, it is needed
to introduce an indicator in order to find scopes for
the multi-hedge sentences properly.
</bodyText>
<subsectionHeader confidence="0.981817">
2.1 Hedge detection
</subsectionHeader>
<bodyText confidence="0.99981475">
The valid label set of task 1, hedge detection, con-
tains only two labels: “Hedge” and “ ”, which
represent that a word is in a hedge cue or not
respectively. Since results of hedge detection in
this shared task are evaluated at sentence level, a
sentence will be classified as “uncertain” in the
post-process if it has one or more words labeled
“Hedge” in it and otherwise “certain”.
</bodyText>
<page confidence="0.943819">
92
</page>
<note confidence="0.9723595">
Proceedings of the Fourteenth Conference on Computational Natural Language Learning: Shared Task, pages 92–99,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<subsectionHeader confidence="0.981027">
2.2 Scope finding
</subsectionHeader>
<bodyText confidence="0.996963888888889">
The second task is divided into two steps in our
system. The first step is quite the same as what
the system does in task 1: labeling the words as in
hedge cues or not. Then the scope of each hedge
will be labeled by taking advantage of the result
of the first step. A scope can be denoted by a
beginning word and an ending word to represent
the first and the last element. In scope finding the
available label set contains “Begin”, “End”, “Mid-
dle” and “ ”, representing the first and last word in
the scope, in-scope and out-of-scope. As an exam-
ple, a sentence with hedge cue and scope labeling
is given in Table 1. Hedge cue “indicating” with
its scope from “indicating” itself to “transcription”
are labeled. While evaluating outputs, only “Be-
gin”s and “End”s will be taken into consideration
and be treated as the head and tail tokens of the
scopes of specific hedge cues.
</bodyText>
<tableCaption confidence="0.786699">
Table 1: A sentence with hedge cue and scope la-
beling
</tableCaption>
<bodyText confidence="0.976866833333333">
It seems that the best labeling result of task 1
can be used directly to be the proper intermediate
representation of task 2. However, the complexity
of scope finding for multi-hedge sentences forces
us to modify the intermediate result of task 2 for
the sake of handling the sentences with more than
one hedge cue correctly. Besides, since task 1 is
a sentence classification task essentially, while the
goal of the first step of task 2 is to label the words
as accurately as possible, it is easy to find that
the optimal labeling results of task 1 may not be
optimal to be the intermediate representations for
task 2. This problem can be solved if sentence-
level hedge detection and intermediate representa-
tion finding are treated as two separate tasks with
independent feature selection procedures. The de-
tails of feature selection will be given in section
3.
</bodyText>
<subsectionHeader confidence="0.997699">
2.3 Scope finding for multi-hedge cases
</subsectionHeader>
<bodyText confidence="0.999990688888889">
Sentences with more than one hedge cue are quite
common in both datasets of BioScope corpus and
Wikipedia. By counting hedges in every sentence,
we find that about one fourth of the sentences with
hedges have more than one hedge cue in all three
data sources (Table 2). In Morante and Daele-
mans (2009), three classifiers predict whether each
token is Begin, End or None and a postprocess-
ing is needed to associate Begins and Ends with
their corresponding hedge cues. In our approach,
in order to decrease ambiguous or illegal outputs
e.g. inequivalent numbers of Begins and Ends, a
pair of Begin and End without their correspond-
ing hedge cue between them, etc., sentences with
more than one hedge cue will be preprocessed by
making copies as many as the number of hedges
and be handled separately.
The sentence which is selected as a sample has
two hedge cues: “suggesting” and “may”, so our
system preprocesses the sentence into two single-
hedge ones, which is illustrated in Table 3. Now it
comes to the problem of finding scope for single-
hedge sentence. The two copies are labeled sep-
arately, getting one scope from “suggesting” to
“mitogenesis” for the hedge cue “suggesting” and
the other from “IFN-alpha” to “mitogenesis” for
“may”. Merging the two results will give the final
scope resolution of the sentence.
However, compared with matching Begins and
Ends in postprocessing given by Morante and
Daelemans (2009), the above method gives rise
to out of control of projections of the scopes,
i.e. scopes of hedges may partially overlap after
copies are merged. Since scopes should be in-
tact constituents of sentences, namely, subtrees in
syntax tree which never partly overlap with each
other, results like this are linguistically illegal and
should be discarded. We solve this problem by in-
troducing an instructional feature called “Indica-
tor”. For sentences with more than one hedge cue,
namely more than one copy while finding scopes,
words inside the union of existing (labeled) scopes
will be tagged as “Indicator” in unhandled copies
before every labeling. For example, after finding
scope for the first copy in Table 3 and words from
</bodyText>
<figure confidence="0.917229944444444">
Furthermore ...
, ...
inhibition ...
can ...
be ...
blocked ...
by ...
actinomycin ...
D ...
, ...
indicating ... Hedge Begin
a ... Middle
requirement ... Middle
for ... Middle
de ... Middle
novo ... Middle
transcription ... End
. ...
</figure>
<page confidence="0.981092">
93
</page>
<table confidence="0.99263725">
Dataset # Sentence # No-hedge ratio # One-hedge ratio # Multi-hedge ratio
Biomedical Abstracts 11871 9770 82.3% 1603 13.5% 498 4.2%
Biomedical Fulltexts 2670 2151 80.6% 385 14.4% 134 5.0%
Wikipedia 11111 8627 77.6% 1936 17.4% 548 4.9%
</table>
<tableCaption confidence="0.995469">
Table 2: Statistics of hedge amount
</tableCaption>
<figure confidence="0.993222956521739">
IFN-alpha IFN-alpha
also also
sensitized sensitized
T T
cells cells
to to
IL-2-induced IL-2-induced
proliferation proliferation
, ,
further further
suggesting Hedge suggesting
that that
IFN-alpha IFN-alpha
may may Hedge
be be
involved involved
in in
the the
regulation regulation
of of
T-cell T-cell
mitogenesis mitogenesis
. .
</figure>
<tableCaption confidence="0.8717985">
Table 3: An example of 2-hedge sentence before
scope finding
</tableCaption>
<bodyText confidence="0.9996369375">
“suggesting” to “mitogenesis” are put in the scope
of cue “suggesting”, these words should be tagged
“Indicator” in the second copy, whose result is il-
lustrated in Table 4. If not in a scope, any word is
tagged “ ” as the indicator. The “Indicator”s tag-
ging from “suggesting” to “mitogenesis” in Table
4 mean that no other than the situations of a) “Be-
gin” is after or at “suggesting” and “End” is before
or at “mitogenesis” b) Both “Begin” and “End” are
before “suggesting” c) Both next “Begin” and next
“End” are after “mitogenesis” can be accepted. In
other words, new labeling should keep the projec-
tions of scopes in the result. Although it is only
an instructional indicator and does not have any
coerciveness, the evaluation result of experiment
shows it effective.
</bodyText>
<sectionHeader confidence="0.990058" genericHeader="method">
3 Feature selection
</sectionHeader>
<bodyText confidence="0.9999664">
Since hedge and scope finding are quite novel
tasks and it is not easy to determine the effective
features by experience, a greedy feature selection
is conducted. As it mentioned in section 2, our
system divides scope finding into two sub-tasks:
</bodyText>
<equation confidence="0.885467846153846">
IFN-alpha ...
also ...
sensitized ...
T ...
cells ...
to ...
IL-2-induced ...
proliferation ...
, ...
further ...
suggesting ... Indicator
that ... Indicator
IFN-alpha ... Indicator Begin
</equation>
<bodyText confidence="0.9152755">
may ... Indicator Hedge Middle
be ... Indicator Middle
involved ... Indicator Middle
in ... Indicator Middle
the ... Indicator Middle
regulation ... Indicator Middle
of ... Indicator Middle
T-cell ... Indicator Middle
mitogenesis ... Indicator End
. ...
</bodyText>
<listItem confidence="0.43932325">
Table 4: Scope resolution with instructional fea-
ture: “Indicator”
a) Hedge cue labeling
b) Scope labeling
</listItem>
<bodyText confidence="0.998707947368421">
The first one is the same as hedge detection task
in strategy, but quite distinct in target of feature
set, because hedge detection is a task of sentence
classification while the first step of scope find-
ing aims at high accuracy of labeling hedge cues.
Therefore, three independent procedures of fea-
ture selection are conducted for BioScope corpus
dataset. As Wikipedia is not involved in the task of
scope finding, it only needs one final feature set.
About 200 feature templates are initially con-
sidered for each task. We mainly borrow ideas and
are enlightened by following sources while initial-
izing feature template sets:
a) Previous papers on hedge detection and
scope finding (Light et al., 2004; Medlock,
2008; Medlock and Briscoe, 2008; Kilicoglu
and Bergler, 2008; Szarvas, 2008; Ganter
and Strube, 2009; Morante and Daelemans,
2009);
</bodyText>
<page confidence="0.995642">
94
</page>
<listItem confidence="0.677503428571429">
b) Related works such as named entity recog-
nition (Collins, 1999) and text chunking
(Zhang et al., 2001);
c) Some literature on dependency parsing
(Nivre and Scholz, 2004; McDonald et al.,
2005; Nivre, 2009; Zhao et al., 2009c; Zhao
et al., 2009a);
</listItem>
<subsectionHeader confidence="0.998794">
3.1 Notations of Feature Template
</subsectionHeader>
<bodyText confidence="0.998571716216217">
A large amount of advanced syntactic features in-
cluding syntactic connections, paths, families and
their concatenations are introduced. Many of these
features come from dependency parsing, which
aims at building syntactic tree expressed by depen-
dencies between words. More details about de-
pendency parsing are given in Nivre and Scholz
(2004) and McDonald et al. (2005). The parser
in Zhao et al. (2009a) is used to construct de-
pendency structures in our system, and some of
the notations in this paper adopt those presented
in Zhao et al. (2009c). Feature templates are from
various combinations or integrations of the follow-
ing basic elements.
Word Property. This part of features includes
word form (form), lemma (lemma), part-of-speech
tag (pos), syntactic dependency (dp) , syntactic de-
pendency label (dprel).
Syntactic Connection. This includes syntactic
head (h), left(right) farthest(nearest) child (lm, ln,
rm and rn) and high (low) support verb, noun or
preposition. Here we specify the last one as an
example, support verb(noun/preposition). From a
given word to the syntactic root along the syntac-
tic tree, the first verb/noun/preposition that is met
is called its low support verb/noun/preposition,
and the nearest one to the root(farthest to
the given word) is called as its high support
verb/noun/preposition. The concept of support
verb was broadly used (Toutanova et al., 2005;
Xue, 2006; Jiang and Ng, 2006), and it is extended
to nouns and prepositions in Zhao et al. (2009b).
In addition, a slightly modified syntactic head, pp-
head, is introduced, it returns the left most sibling
of a given word if the word is headed by a prepo-
sition, otherwise it returns the original head.
Path. There are two basic types of path. One
is the linear path (linePath) in the sequence, the
other is the path in the syntactic parsing tree (dp-
Path). For example, m:njdpPath represents the
dependency path from word m to n. Assuming
that the two paths from m and n to the root are
pm and pn, m:njdpPathShare, m:njdpPathPred
and m:njdpPathArgu represent the common part
of pm and pn, part of pm which does not belong
to pn and part of pn which does not belong to pm,
respectively.
Family. A children set includes all syntactic
children(children) are used in the template nota-
tions.
Concatenation of Elements. For all collected
elements according to dpPath, children and so on,
we use three strategies to concatenate all those
strings to produce the feature value. The first is
seq, which concatenates all collected strings with-
out doing anything. The second is bag, which
removes all duplicated strings and sort the rest.
The third is noDup, which removes all duplicated
neighbored strings.
Hedge Cue Dictionary and Scope Indicator.
Hedge cues in the training set are collected and put
in a dictionary. Whether a word in the training or
testing set is in the dictionary (dic) is introduced
into feature templates. As the evaluation is non-
open, we do not put in any additional hedge cues
from other resources. An indicator (indicator) is
given for multi-hedge scope finding, as specified
in section 2.At last, in feature set for scope label-
ing, hedge represents that the word is in a hedge
cue.
At last, we take x as current token to be labeled,
and xm to denote neighbor words. m &gt; 0 repre-
sents that it is a word goes mth after current word
and m &lt; 0 for word −mth before current word.
</bodyText>
<subsectionHeader confidence="0.999148">
3.2 Feature template sets for each task
</subsectionHeader>
<bodyText confidence="0.999988235294118">
As optimal feature template subsets cannot be ex-
pected to be extracted from so large sets by hand,
greedy feature selections according to Zhao et al.
(2009b) are applied. The normalized feature selec-
tion has been proved to be effective in quite a lot
of NLP tasks and can often successfully select an
optimal or very close to optimal feature set from a
large-scale superset. Although usually it needs 3
to 4 loops denoted by “While” in the Algorithm 1
of Zhao et al. (2009b) to get the best template set,
we only complete one before official outputs col-
lection because of time limitation, which to a large
extent hinders the performance of the system.
Three template sets are selected for BioScope
corpus. One with the highest accuracy for
sentence-level hedge detection (Set B), one with
the best performance for word-level hedge cue la-
</bodyText>
<page confidence="0.997568">
95
</page>
<bodyText confidence="0.999965860465117">
beling (Set H) and another one with the maximal
F-score for scope finding (Set S). In addition, one
set is discovered for sentence-level hedge detec-
tion of Wikipedia (Set W)1 . Table 52 lists some
selected feature templates which are basic word or
hedging properties for the three sets of BioScope
corpus and Wikipedia. From the table we can see
it is clear that the combinations of lemma, POS
and word form of words in context, which are usu-
ally basic and common elements in NLP, are also
effective for hedge detection. And as we expected,
the feature that represents whether the word is in
the hedge list or not is very useful especially in
hedge cue finding, indicating that methods based
on a hedge cue lists (Light et al., 2004) or keyword
selection (Szarvas, 2008) are quite significant way
to accomplish such tasks.
Some a little complicated syntactic features
based on dependencies are systemically exploited
as features for tasks. Table 6 enumerates some of
the syntactic features which proves to be highly
effective. We noticed that lowSupportNoun, high-
SupportNoun and features derived from dpPath is
notably useful. It can be explained by the aware-
ness that hedge labeling and scope finding are to
process literatures in the level of semantics where
syntactic features are often helpful.
We continue our feature selection procedures
for BioScope corpus after official outputs collec-
tion and obtain feature template sets that bring bet-
ter performance. Table 7 gives some of the fea-
tures in the optimized sets for BioScope corpus
resolution. One difference between the new sets
and the old ones is the former contain more syntac-
tic elements, indicating that exploiting syntactic
feature is a correct choice. Another difference is
the new sets assemble more information of words
before or after the current word, especially words
linearly far away but close in syntax tree. Appear-
ance of combination of these two factors such as
x−1.lm.form seems to provide an evidence of the
insufficiency training and development of our sys-
tem submitted to some extent.
</bodyText>
<sectionHeader confidence="0.995085" genericHeader="evaluation">
4 Evaluation results
</sectionHeader>
<bodyText confidence="0.998251333333333">
Two tracks (closed and open challenges) are pro-
vided for CoNLL-2010 shared task. We partici-
pated in the closed challenge, select features based
</bodyText>
<footnote confidence="0.99699225">
1num in the set of Wikipedia represents the sequential
number of word in the sentence
2Contact the authors to get the full feature lists, as well as
entire optimized sets in post-deadline experiment
</footnote>
<figure confidence="0.978546642857143">
- x.lemma + x1.lemma + x_1.lemma
- + x.dic + x1.dic + x_1.dic
- x.lemma + x1.pos + x_1.pos + x.pos
Set B + x1.lemma + x_1.lemma
- x.form
- x.pos + x1.pos + x_1.pos + x2.pos
+ x_2.pos
x.dic + x1.dic + x_1.dic
x1.pos
- x.dic + x1.dic + x_1.dic + x2.dic
- + x_2.dic
- x.pos + x_1.pos
Set H x.dic
- x.dic + x.lemma + x.pos + x.form
- x.pos + x1.pos + x_1.pos + x2.pos
- + x_2.pos
- x_2.form + x_2.lemma
x_1.form + x.form
x.dic + x1.dic + x_1.dic
- x.dic + x1.dic + x_1.dic + x2.dic
- + x_2.dic + x3.dic + x_3.dic
- x.indicator
Set S x.hedge + x1.hedge + x_1.hedge
- x.lemma + x1.pos + x_1.pos + x.pos
- + x1.lemma + x_1.lemma
- x.pos + x.hedge + x.dp + x.dprel
x1.pos
x.pos + x1.pos + x_1.pos + x2.pos
</figure>
<table confidence="0.917607533333333">
+ x_2.pos
- x.lemma + x1.lemma + x_1.lemma
- + x.dic + x1.dic + x_1.dic
- x.lemma + x1.lemma + x_1.lemma
- +x2.lemma + x_2.lemma + x.dic
Set W + x1.dic + x_1.dic + x2.dic + x_2.dic
- x.lemma + x1.lemma
- x.hedge + x1.hedge + x_1.hedge
- + x2.hedge + x_2.hedge + x3.hedge
+ x_3.hedge
x.pos + x1.pos + x_1.pos +x2.pos
+ x_2.pos + x.dic + x1.dic + x_1.dic
+ x2.dic + x_2.dic
x.pos + x.dic
x.num + x.dic
</table>
<tableCaption confidence="0.768809">
Table 5: Selected feature template sets
</tableCaption>
<page confidence="0.750484">
96
</page>
<table confidence="0.999945847826087">
- x.lowSupportNoun:x  |dpPathArgu.dprel.seq
- x.lowSupportNoun:x|dpPathArgu.dprel.seq
- + x.lowSupportProp:x|dpPathArgu.dprel.seq
- x.lowSupoortNoun.pos
- x.pos + x.children.dprel.bag
Set B x.rm.dprel + x.form
- x.pphead.lemma
- x.form + x.children.dprel.bag
- x.lowSupportNoun:x—dpTreeRelation
- x.lowSupportProp.lemma
- x.form + x.children.dprel.noDup
- x.highSupportNoun:x|dpTreeRelation + x.form
x.lowSupportVerb.form
- x.lowSupportProp:x|dpPathShared.dprel.seq
- x.lowSupportProp:x|dpPathShared.pos.seq
- x.highSupportNoun.pos
- x.highSupportNoun:x|dpTreeRelation
- x.highSupportNoun:x|dpPathArgu.dprel.seq
Set H + x.highSupportProp:x|dpPathArgu.dprel.seq
- xlowSupportProp.lemma
- x.rm.dprel
- x.lm.form
- x.lemma + x.pphead.form
- x.lowSupportVerb.form
- x.rm.lemma + x.rm.form
- x.children.dprel.noDup
- x.children.dprel.bag
- x.highSupportNoun:x|dpTreeRelation
- x.lemma + x.pphead.form
Set S x.highSupportNoun:x|dpTreeRelation + x.form
- x.lowSupportVerb.form
- x.lowSupportVerb.lemma
- x.h.children.dprel.bag
- x.highSupportVerb.form
- x.lm.form
- x.lemma + x.pphead.form
- x.lm.dprel + x.pos
- x.lowSupportProp:x|dpPathPred.dprel.seq
- x.pphead.lemma
Set W x.rm.lemma
- x.lowSupportProp:x|dpTreeRelation
- x.lowSupportVerb:x|dpPathPred.dprel.seq
- x.lowSupportVerb:x|dpPathPred.pos.seq
- x.lowSupportVerb:x|dpPathShared.pos.seq
- x.lowSupportProp:x|dpPathShared.pos.seq
- x.lowSupportProp.form
</table>
<tableCaption confidence="0.893908">
Table 6: Syntactic features
</tableCaption>
<table confidence="0.473523928571428">
- x−1.lemma
- x.dic + x1.dic + x−1.dic + x2.dic
+ x−2.dic + x3.dic + x−3.dic
- x−1.pos + x1.pos
Set H x.rm.lemma
- x.rm.dprel
- x.lm.dprel + x.pos
- x.lowSupportNoun:x  |dpPathArgu.dprel.seq
- x.lowSupportNoun:x|dpPathArgu.dprel.seq
+ x.lowSupportProp:x|dpPathArgu.dprel.seq
- x−1.lemma
- x.lemma + x1.lemma + x−1.lemma + x.dic
+ x1.dic + x−1.dic
- x.form + x.lemma + x.pos + x.dic
Set B x−2.form + x−1.form
- x.highSupportNoun:x|dpTreeRelation
- x.highSupportNoun:x|dpPathArgu.dprel.seq
- x.lowSupportProp:x|dpPathShared.dprel.seq
- x−1.lm.form
- x1.form
- x.pos + x.dic
- x.hedge + x1.hedge + x−1.hedge
- x.pos + x1.pos + x−1.pos + x2.pos + x−2.pos
Set S x.children.dprel.bag
- x.lemma + x.pphead.form
- x.highSupportVerb.form
- x.highSupportNoun:x|dpTreeRelation + x.form
- x.lowSupportNoun:x|dpTreeRelation + x.form
</table>
<tableCaption confidence="0.682079">
Table 7: Selected improved feature template sets
for BioScope corpus
</tableCaption>
<bodyText confidence="0.9996154">
on the in-domain data and evaluated our system
on the in-domain and cross-domain evaluation set.
All the experiments are implemented and run by
Maximum Entropy Markov Models (McCallum,
2000).
</bodyText>
<subsectionHeader confidence="0.9671">
4.1 Official results
</subsectionHeader>
<bodyText confidence="0.999931714285714">
The official results for tasks are in Table 8, in
which three in-domain tests and cue matching
result for biomedical texts are listed. For the
first task for BioCorpus, our system gives F-score
0.8363 in in-domain test and for Wikipedia we
give F-score 0.5618 in closed evaluation. For the
second task, our system gives results in closed and
open test, with F-score 0.4425 and 0.4441 respec-
tively.
We compare the F-score of our system with the
best in the final result in Table 9. We rank pretty
high in Wikipedia hedge detection, while other
three are quite steady but not prominent. This is
mainly due to two reasons:
</bodyText>
<listItem confidence="0.947416">
1. Feature selection procedures are not perfectly
conducted.
2. Abstracts and fulltexts in BioScope are mixed
</listItem>
<bodyText confidence="0.6514025">
to be the training set, which proves quite in-
appropriate when the evaluation set contains
</bodyText>
<page confidence="0.99888">
97
</page>
<table confidence="0.847881">
only fulltext literature, since abstract and full-
text are quite different in terms of hedging.
Dataset F-score Best
Task1-closed 0.8363 0.8636
BioScope Task2-closed 0.4425 0.5732
Cue-matching 0.7853 0.8134
Wikipedia Task1-closed 0.5618 0.6017
</table>
<tableCaption confidence="0.999536">
Table 9: Comparing results with the best
</tableCaption>
<subsectionHeader confidence="0.968127">
4.2 Further results
</subsectionHeader>
<bodyText confidence="0.999555615384615">
Intact feature selection procedures for BioScope
corpus are conducted after official outputs collec-
tions. The results of evaluation with completely
selected features compared with the incomplete
one are given in Table 7. The system performs a
higher score on evaluation data (Table 10), which
is more competitive in both tasks on BioScope cor-
pus. The improvement for task 2 is significant, but
the increase of performance of hedge cue detec-
tion is less remarkable. We believe that a larger
fulltext training set and a more considerate train-
ing plan will help us to do better job in the future
work.
</bodyText>
<table confidence="0.99525325">
Dataset Complete Incomplete
Task1-closed 0.8522 0.8363
BioScope Task2-closed 0.5151 0.4425
Cue-matching 0.7990 0.7853
</table>
<tableCaption confidence="0.894269">
Table 10: Comparing improved outputs with the
best
</tableCaption>
<sectionHeader confidence="0.997959" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999974846153846">
We describe the system that uses sequence label-
ing with normalized feature selection and rich fea-
tures to detect hedges and find scopes for hedge
cues. Syntactic features which are derived from
dependencies are exploited, which prove to be
quite favorable. The evaluation results show that
our system is steady in performance and does
pretty good hedging and scope finding in both Bio-
Scope corpus and Wikipedia, especially when the
feature selection procedure is carefully and totally
conducted. The results suggest that sequence la-
beling and a feature-oriented method are effective
in such NLP tasks.
</bodyText>
<sectionHeader confidence="0.990256" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999648833333333">
Michael Collins. 1999. Head-Driven Statistical Mod-
els for Natural Language Parsing. Ph.D. thesis,
University of Pennsylvania.
Rich´ard Farkas, Veronika Vincze, Gy¨orgy M´ora, J´anos
Csirik, and Gy¨orgy Szarvas. 2010. The CoNLL-
2010 Shared Task: Learning to Detect Hedges and
their Scope in Natural Language Text. In Proceed-
ings of the Fourteenth Conference on Computational
Natural Language Learning (CoNLL-2010): Shared
Task, pages 1–12, Uppsala, Sweden, July. Associa-
tion for Computational Linguistics.
Viola Ganter and Michael Strube. 2009. Finding
hedges by chasing weasels: Hedge detection using
Wikipedia tags and shallow linguistic features. In
Proceedings of the ACL-IJCNLP 2009 Conference
Short Papers, pages 173–176, Suntec, Singapore, 4,
August.
Ken Hyland. 1996. Writing without conviction: Hedg-
ing in science research articles. Applied Linguistics,
17:433–54.
Zheng Ping Jiang and Hwee Tou Ng. 2006. Semantic
role labeling of NomBank: A maximum entropy ap-
proach. In Proceedings of the EMNLP-2006, pages
138–145, Sydney, Australia.
Halil Kilicoglu and Sabine Bergler. 2008. Recogniz-
ing speculative language in biomedical research ar-
ticles: a linguistically motivated perspective. BMC
Bioinformatics, 9.
Marc Light, Xin Ying Qiu, and Padimini Srinivasan.
2004. The language of bioscience: Facts, specula-
tions, and statements in between. In Proc. of the
BioLINK 2004, pages 17–24.
Chrysanne Di Marco and Robert E. Mercer. 2004.
Hedging in scientific articles as a means of classify-
ing citations. In Working Notes of the AAAI Spring
Symposium on Exploring Attitude and Affect in Text:
Theories and Applications, pages 50–54.
Andrew McCallum. 2000. Maximum entropy markov
models for information extraction and segmentation.
In Proceedings of ICML 2000, pages 591–598, Stan-
ford, California.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajic. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceed-
ings of HLT/EMNLP 05, pages 523–530, Vancouver,
Canada, October.
Ben Medlock and Ted Briscoe. 2008. Weakly super-
vised learning for hedge classification in scientific
literature. In Proceedings of 45th Annual Meeting
of the ACL, pages 992–999, Prague, Czech Repub-
lic, June.
Ben Medlock. 2008. Exploring hedge identification in
biomedical literature. Journal of Biomedical Infor-
matics, 41:636–654.
</reference>
<page confidence="0.996074">
98
</page>
<table confidence="0.9984228">
Dataset TP FP FN precision recall F-score
BioScope Task1-closed 669 141 121 0.8259 0.8468 0.8363
Task2-closed 441 519 592 0.4594 0.4269 0.4425
Cue-matching 788 172 259 0.8208 0.7526 0.7853
Wikipedia Task1-closed 991 303 1243 0.7658 0.4436 0.5618
</table>
<tableCaption confidence="0.989336">
Table 8: Official results of our submission for in-domain tasks
</tableCaption>
<reference confidence="0.999571333333333">
Roser Morante and Walter Daelemans. 2009. Learning
the scope of hedge cues in biomedical texts. In Pro-
ceedings of the Workshop on BioNLP, pages 28–36,
Boulder, Colorado, June.
Joakim Nivre and Mario Scholz. 2004. Deterministic
dependency parsing of English text. In Proceedings
of COLING-2004, pages 64–70, Geneva, Switzer-
land, August 23rd-27th.
Joakim Nivre. 2009. Non-projective dependency pars-
ing in expected linear time. In Proceedings of ACL-
IJCNLP 2009, pages 351–359, Suntec, Singapore,
2-7 August.
Gy¨orgy Szarvas, Veronika Vincze, Rich´ard Farkas, and
J´anos Csirik. 2008. The BioScope corpus: anno-
tation for negation, uncertainty and their scope in
biomedical texts. In Proceedings of BioNLP 2008,
pages 38–45, Columbus, Ohio, USA, June.
Gy¨orgy Szarvas. 2008. Hedge classification in
biomedical texts with a weakly supervised selection
of keywords. In Proceedings ofACL-08, pages 281–
289, Columbus, Ohio, USA, June.
Paul Thompson, Giulia Venturi, John McNaught,
Simonetta Montemagni, and Sophia Ananiadou.
2008. Categorising modality in biomedical texts. In
Proc. of the LREC 2008 Workshop on Building and
Evaluating Resources for Biomedical Text Mining,
pages 27–34, Marrakech.
Kristina Toutanova, Aria Haghighi, and Christopher D.
Manning. 2005. Joint learning improves semantic
role labeling. In Proceedings of ACL-2005, pages
589–596, Ann Arbor, USA.
Nianwen Xue. 2006. Semantic role labeling of nom-
inalized predicates in Chinese. In Proceedings of
the Human Language Technology Conference of the
NAACL (NAACL-2006), pages 431–438, New York
City, USA, June.
Tong Zhang, Fred Damerau, and David Johnson. 2001.
Text chunking using regularized winnow. In Pro-
ceedings of the 39th Annual Meeting on Associa-
tion for Computational Linguistics, pages 539–546,
Toulouse, France.
Hai Zhao, Wenliang Chen, Jun’ichi Kazama, Kiyotaka
Uchimoto, and Kentaro Torisawa. 2009a. Multi-
lingual dependency learning: Exploiting rich fea-
tures for tagging syntactic and semantic dependen-
cies. In Proceedings of CoNLL-2009, June 4-5,
Boulder, Colorado, USA.
Hai Zhao, Wenliang Chen, and Chunyu Kit. 2009b.
Semantic dependency parsing of NomBank and
PropBank: An efficient integrated approach via a
large-scale feature selection. In Proceedings of
EMNLP-2009, pages 30–39, Singapore.
Hai Zhao, Wenliang Chen, Chunyu Kit, and Guodong
Zhou. 2009c. Multilingual dependency learning:
A huge feature engineering method to semantic de-
pendency parsing. In Proceedings of CoNLL-2009,
June 4-5, Boulder, Colorado, USA.
</reference>
<page confidence="0.99897">
99
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.151718">
<title confidence="0.9921505">Hedge Detection and Scope Finding by Sequence Labeling Normalized Feature</title>
<author confidence="0.656271">Hai Guodong</author>
<title confidence="0.874284333333333">for Brain-Like Computing and Machine Dept of Computer Science and Engineering, Shanghai Jiao Tong Key Laboratory for Intelligent Computing and Intelligent</title>
<author confidence="0.989097">Shanghai Jiao Tong</author>
<affiliation confidence="0.605852">of Computer Science and Technology, Soochow</affiliation>
<email confidence="0.7692905">zhangsd.sjtu@gmail.com,gdzhou@suda.edu.cn,blu@cs.sjtu.edu.cn</email>
<abstract confidence="0.9910728">This paper presents a system which adopts a standard sequence labeling technique for hedge detection and scope finding. For the first task, hedge detection, we formulate it as a hedge labeling problem, while for the second task, we use a two-step labeling strategy, one for hedge cue labeling and the other for scope finding. In particular, various kinds of syntactic features are systemically exploited and effectively integrated using a large-scale normalized feature selection method. Evaluation on the CoNLL-2010 shared task shows that our system achieves stable and competitive results for all the closed tasks. Furthermore, post-deadline experiments show that the performance can be much further improved using a sufficient feature selection.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="11516" citStr="Collins, 1999" startWordPosition="1864" endWordPosition="1865">ture selection are conducted for BioScope corpus dataset. As Wikipedia is not involved in the task of scope finding, it only needs one final feature set. About 200 feature templates are initially considered for each task. We mainly borrow ideas and are enlightened by following sources while initializing feature template sets: a) Previous papers on hedge detection and scope finding (Light et al., 2004; Medlock, 2008; Medlock and Briscoe, 2008; Kilicoglu and Bergler, 2008; Szarvas, 2008; Ganter and Strube, 2009; Morante and Daelemans, 2009); 94 b) Related works such as named entity recognition (Collins, 1999) and text chunking (Zhang et al., 2001); c) Some literature on dependency parsing (Nivre and Scholz, 2004; McDonald et al., 2005; Nivre, 2009; Zhao et al., 2009c; Zhao et al., 2009a); 3.1 Notations of Feature Template A large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced. Many of these features come from dependency parsing, which aims at building syntactic tree expressed by dependencies between words. More details about dependency parsing are given in Nivre and Scholz (2004) and McDonald et al. (2005). The parser </context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rich´ard Farkas</author>
<author>Veronika Vincze</author>
<author>Gy¨orgy M´ora</author>
<author>J´anos Csirik</author>
<author>Gy¨orgy Szarvas</author>
</authors>
<title>The CoNLL2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task,</booktitle>
<pages>1--12</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<marker>Farkas, Vincze, M´ora, Csirik, Szarvas, 2010</marker>
<rawString>Rich´ard Farkas, Veronika Vincze, Gy¨orgy M´ora, J´anos Csirik, and Gy¨orgy Szarvas. 2010. The CoNLL2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task, pages 1–12, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viola Ganter</author>
<author>Michael Strube</author>
</authors>
<title>Finding hedges by chasing weasels: Hedge detection using Wikipedia tags and shallow linguistic features.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers,</booktitle>
<pages>173--176</pages>
<location>Suntec, Singapore, 4,</location>
<contexts>
<context position="11416" citStr="Ganter and Strube, 2009" startWordPosition="1846" endWordPosition="1849">of scope finding aims at high accuracy of labeling hedge cues. Therefore, three independent procedures of feature selection are conducted for BioScope corpus dataset. As Wikipedia is not involved in the task of scope finding, it only needs one final feature set. About 200 feature templates are initially considered for each task. We mainly borrow ideas and are enlightened by following sources while initializing feature template sets: a) Previous papers on hedge detection and scope finding (Light et al., 2004; Medlock, 2008; Medlock and Briscoe, 2008; Kilicoglu and Bergler, 2008; Szarvas, 2008; Ganter and Strube, 2009; Morante and Daelemans, 2009); 94 b) Related works such as named entity recognition (Collins, 1999) and text chunking (Zhang et al., 2001); c) Some literature on dependency parsing (Nivre and Scholz, 2004; McDonald et al., 2005; Nivre, 2009; Zhao et al., 2009c; Zhao et al., 2009a); 3.1 Notations of Feature Template A large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced. Many of these features come from dependency parsing, which aims at building syntactic tree expressed by dependencies between words. More details a</context>
</contexts>
<marker>Ganter, Strube, 2009</marker>
<rawString>Viola Ganter and Michael Strube. 2009. Finding hedges by chasing weasels: Hedge detection using Wikipedia tags and shallow linguistic features. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 173–176, Suntec, Singapore, 4, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken Hyland</author>
</authors>
<title>Writing without conviction: Hedging in science research articles.</title>
<date>1996</date>
<journal>Applied Linguistics,</journal>
<pages>17--433</pages>
<contexts>
<context position="1427" citStr="Hyland, 1996" startWordPosition="198" endWordPosition="199">gy, one for hedge cue labeling and the other for scope finding. In particular, various kinds of syntactic features are systemically exploited and effectively integrated using a large-scale normalized feature selection method. Evaluation on the CoNLL-2010 shared task shows that our system achieves stable and competitive results for all the closed tasks. Furthermore, post-deadline experiments show that the performance can be much further improved using a sufficient feature selection. 1 Introduction Hedges are linguistic devices representing speculative parts of articles. Previous works such as (Hyland, 1996; Marco and Mercer, 2004; Light et al., 2004; Thompson et al., 2008) present research on hedge mainly as a linguistic phenomenon. Meanwhile, detecting hedges and their scopes automatically are increasingly important tasks in natural language processing and information extraction, especially in biomedical community. The shared task of CoNLL-2010 described in Farkas et al. (2010) aims at detecting hedges (task 1) and finding their scopes (task 2) for the literature ∗ This work is partially supported by the National Natural Science Foundation of China (Grants 60903119, 60773090, 90820018 and 9092</context>
</contexts>
<marker>Hyland, 1996</marker>
<rawString>Ken Hyland. 1996. Writing without conviction: Hedging in science research articles. Applied Linguistics, 17:433–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Ping Jiang</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Semantic role labeling of NomBank: A maximum entropy approach.</title>
<date>2006</date>
<booktitle>In Proceedings of the EMNLP-2006,</booktitle>
<pages>138--145</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="13159" citStr="Jiang and Ng, 2006" startWordPosition="2120" endWordPosition="2123">(dprel). Syntactic Connection. This includes syntactic head (h), left(right) farthest(nearest) child (lm, ln, rm and rn) and high (low) support verb, noun or preposition. Here we specify the last one as an example, support verb(noun/preposition). From a given word to the syntactic root along the syntactic tree, the first verb/noun/preposition that is met is called its low support verb/noun/preposition, and the nearest one to the root(farthest to the given word) is called as its high support verb/noun/preposition. The concept of support verb was broadly used (Toutanova et al., 2005; Xue, 2006; Jiang and Ng, 2006), and it is extended to nouns and prepositions in Zhao et al. (2009b). In addition, a slightly modified syntactic head, pphead, is introduced, it returns the left most sibling of a given word if the word is headed by a preposition, otherwise it returns the original head. Path. There are two basic types of path. One is the linear path (linePath) in the sequence, the other is the path in the syntactic parsing tree (dpPath). For example, m:njdpPath represents the dependency path from word m to n. Assuming that the two paths from m and n to the root are pm and pn, m:njdpPathShare, m:njdpPathPred a</context>
</contexts>
<marker>Jiang, Ng, 2006</marker>
<rawString>Zheng Ping Jiang and Hwee Tou Ng. 2006. Semantic role labeling of NomBank: A maximum entropy approach. In Proceedings of the EMNLP-2006, pages 138–145, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Halil Kilicoglu</author>
<author>Sabine Bergler</author>
</authors>
<title>Recognizing speculative language in biomedical research articles: a linguistically motivated perspective.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<contexts>
<context position="11376" citStr="Kilicoglu and Bergler, 2008" startWordPosition="1840" endWordPosition="1843">entence classification while the first step of scope finding aims at high accuracy of labeling hedge cues. Therefore, three independent procedures of feature selection are conducted for BioScope corpus dataset. As Wikipedia is not involved in the task of scope finding, it only needs one final feature set. About 200 feature templates are initially considered for each task. We mainly borrow ideas and are enlightened by following sources while initializing feature template sets: a) Previous papers on hedge detection and scope finding (Light et al., 2004; Medlock, 2008; Medlock and Briscoe, 2008; Kilicoglu and Bergler, 2008; Szarvas, 2008; Ganter and Strube, 2009; Morante and Daelemans, 2009); 94 b) Related works such as named entity recognition (Collins, 1999) and text chunking (Zhang et al., 2001); c) Some literature on dependency parsing (Nivre and Scholz, 2004; McDonald et al., 2005; Nivre, 2009; Zhao et al., 2009c; Zhao et al., 2009a); 3.1 Notations of Feature Template A large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced. Many of these features come from dependency parsing, which aims at building syntactic tree expressed by de</context>
</contexts>
<marker>Kilicoglu, Bergler, 2008</marker>
<rawString>Halil Kilicoglu and Sabine Bergler. 2008. Recognizing speculative language in biomedical research articles: a linguistically motivated perspective. BMC Bioinformatics, 9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Light</author>
<author>Xin Ying Qiu</author>
<author>Padimini Srinivasan</author>
</authors>
<title>The language of bioscience: Facts, speculations, and statements in between.</title>
<date>2004</date>
<booktitle>In Proc. of the BioLINK</booktitle>
<pages>17--24</pages>
<contexts>
<context position="1471" citStr="Light et al., 2004" startWordPosition="204" endWordPosition="207"> other for scope finding. In particular, various kinds of syntactic features are systemically exploited and effectively integrated using a large-scale normalized feature selection method. Evaluation on the CoNLL-2010 shared task shows that our system achieves stable and competitive results for all the closed tasks. Furthermore, post-deadline experiments show that the performance can be much further improved using a sufficient feature selection. 1 Introduction Hedges are linguistic devices representing speculative parts of articles. Previous works such as (Hyland, 1996; Marco and Mercer, 2004; Light et al., 2004; Thompson et al., 2008) present research on hedge mainly as a linguistic phenomenon. Meanwhile, detecting hedges and their scopes automatically are increasingly important tasks in natural language processing and information extraction, especially in biomedical community. The shared task of CoNLL-2010 described in Farkas et al. (2010) aims at detecting hedges (task 1) and finding their scopes (task 2) for the literature ∗ This work is partially supported by the National Natural Science Foundation of China (Grants 60903119, 60773090, 90820018 and 90920004), the National Basic Research Program o</context>
<context position="11305" citStr="Light et al., 2004" startWordPosition="1830" endWordPosition="1833"> target of feature set, because hedge detection is a task of sentence classification while the first step of scope finding aims at high accuracy of labeling hedge cues. Therefore, three independent procedures of feature selection are conducted for BioScope corpus dataset. As Wikipedia is not involved in the task of scope finding, it only needs one final feature set. About 200 feature templates are initially considered for each task. We mainly borrow ideas and are enlightened by following sources while initializing feature template sets: a) Previous papers on hedge detection and scope finding (Light et al., 2004; Medlock, 2008; Medlock and Briscoe, 2008; Kilicoglu and Bergler, 2008; Szarvas, 2008; Ganter and Strube, 2009; Morante and Daelemans, 2009); 94 b) Related works such as named entity recognition (Collins, 1999) and text chunking (Zhang et al., 2001); c) Some literature on dependency parsing (Nivre and Scholz, 2004; McDonald et al., 2005; Nivre, 2009; Zhao et al., 2009c; Zhao et al., 2009a); 3.1 Notations of Feature Template A large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced. Many of these features come from de</context>
<context position="16732" citStr="Light et al., 2004" startWordPosition="2750" endWordPosition="2753">red for sentence-level hedge detection of Wikipedia (Set W)1 . Table 52 lists some selected feature templates which are basic word or hedging properties for the three sets of BioScope corpus and Wikipedia. From the table we can see it is clear that the combinations of lemma, POS and word form of words in context, which are usually basic and common elements in NLP, are also effective for hedge detection. And as we expected, the feature that represents whether the word is in the hedge list or not is very useful especially in hedge cue finding, indicating that methods based on a hedge cue lists (Light et al., 2004) or keyword selection (Szarvas, 2008) are quite significant way to accomplish such tasks. Some a little complicated syntactic features based on dependencies are systemically exploited as features for tasks. Table 6 enumerates some of the syntactic features which proves to be highly effective. We noticed that lowSupportNoun, highSupportNoun and features derived from dpPath is notably useful. It can be explained by the awareness that hedge labeling and scope finding are to process literatures in the level of semantics where syntactic features are often helpful. We continue our feature selection </context>
</contexts>
<marker>Light, Qiu, Srinivasan, 2004</marker>
<rawString>Marc Light, Xin Ying Qiu, and Padimini Srinivasan. 2004. The language of bioscience: Facts, speculations, and statements in between. In Proc. of the BioLINK 2004, pages 17–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chrysanne Di Marco</author>
<author>Robert E Mercer</author>
</authors>
<title>Hedging in scientific articles as a means of classifying citations.</title>
<date>2004</date>
<booktitle>In Working Notes of the AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications,</booktitle>
<pages>50--54</pages>
<marker>Di Marco, Mercer, 2004</marker>
<rawString>Chrysanne Di Marco and Robert E. Mercer. 2004. Hedging in scientific articles as a means of classifying citations. In Working Notes of the AAAI Spring Symposium on Exploring Attitude and Affect in Text: Theories and Applications, pages 50–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
</authors>
<title>Maximum entropy markov models for information extraction and segmentation.</title>
<date>2000</date>
<booktitle>In Proceedings of ICML 2000,</booktitle>
<pages>591--598</pages>
<location>Stanford, California.</location>
<contexts>
<context position="22079" citStr="McCallum, 2000" startWordPosition="3528" endWordPosition="3529">:x|dpPathArgu.dprel.seq - x.lowSupportProp:x|dpPathShared.dprel.seq - x−1.lm.form - x1.form - x.pos + x.dic - x.hedge + x1.hedge + x−1.hedge - x.pos + x1.pos + x−1.pos + x2.pos + x−2.pos Set S x.children.dprel.bag - x.lemma + x.pphead.form - x.highSupportVerb.form - x.highSupportNoun:x|dpTreeRelation + x.form - x.lowSupportNoun:x|dpTreeRelation + x.form Table 7: Selected improved feature template sets for BioScope corpus on the in-domain data and evaluated our system on the in-domain and cross-domain evaluation set. All the experiments are implemented and run by Maximum Entropy Markov Models (McCallum, 2000). 4.1 Official results The official results for tasks are in Table 8, in which three in-domain tests and cue matching result for biomedical texts are listed. For the first task for BioCorpus, our system gives F-score 0.8363 in in-domain test and for Wikipedia we give F-score 0.5618 in closed evaluation. For the second task, our system gives results in closed and open test, with F-score 0.4425 and 0.4441 respectively. We compare the F-score of our system with the best in the final result in Table 9. We rank pretty high in Wikipedia hedge detection, while other three are quite steady but not pro</context>
</contexts>
<marker>McCallum, 2000</marker>
<rawString>Andrew McCallum. 2000. Maximum entropy markov models for information extraction and segmentation. In Proceedings of ICML 2000, pages 591–598, Stanford, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajic</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP 05,</booktitle>
<pages>523--530</pages>
<location>Vancouver, Canada,</location>
<contexts>
<context position="11644" citStr="McDonald et al., 2005" startWordPosition="1883" endWordPosition="1886">nly needs one final feature set. About 200 feature templates are initially considered for each task. We mainly borrow ideas and are enlightened by following sources while initializing feature template sets: a) Previous papers on hedge detection and scope finding (Light et al., 2004; Medlock, 2008; Medlock and Briscoe, 2008; Kilicoglu and Bergler, 2008; Szarvas, 2008; Ganter and Strube, 2009; Morante and Daelemans, 2009); 94 b) Related works such as named entity recognition (Collins, 1999) and text chunking (Zhang et al., 2001); c) Some literature on dependency parsing (Nivre and Scholz, 2004; McDonald et al., 2005; Nivre, 2009; Zhao et al., 2009c; Zhao et al., 2009a); 3.1 Notations of Feature Template A large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced. Many of these features come from dependency parsing, which aims at building syntactic tree expressed by dependencies between words. More details about dependency parsing are given in Nivre and Scholz (2004) and McDonald et al. (2005). The parser in Zhao et al. (2009a) is used to construct dependency structures in our system, and some of the notations in this paper adopt t</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajic. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of HLT/EMNLP 05, pages 523–530, Vancouver, Canada, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Medlock</author>
<author>Ted Briscoe</author>
</authors>
<title>Weakly supervised learning for hedge classification in scientific literature.</title>
<date>2008</date>
<booktitle>In Proceedings of 45th Annual Meeting of the ACL,</booktitle>
<pages>992--999</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="11347" citStr="Medlock and Briscoe, 2008" startWordPosition="1836" endWordPosition="1839">ge detection is a task of sentence classification while the first step of scope finding aims at high accuracy of labeling hedge cues. Therefore, three independent procedures of feature selection are conducted for BioScope corpus dataset. As Wikipedia is not involved in the task of scope finding, it only needs one final feature set. About 200 feature templates are initially considered for each task. We mainly borrow ideas and are enlightened by following sources while initializing feature template sets: a) Previous papers on hedge detection and scope finding (Light et al., 2004; Medlock, 2008; Medlock and Briscoe, 2008; Kilicoglu and Bergler, 2008; Szarvas, 2008; Ganter and Strube, 2009; Morante and Daelemans, 2009); 94 b) Related works such as named entity recognition (Collins, 1999) and text chunking (Zhang et al., 2001); c) Some literature on dependency parsing (Nivre and Scholz, 2004; McDonald et al., 2005; Nivre, 2009; Zhao et al., 2009c; Zhao et al., 2009a); 3.1 Notations of Feature Template A large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced. Many of these features come from dependency parsing, which aims at building s</context>
</contexts>
<marker>Medlock, Briscoe, 2008</marker>
<rawString>Ben Medlock and Ted Briscoe. 2008. Weakly supervised learning for hedge classification in scientific literature. In Proceedings of 45th Annual Meeting of the ACL, pages 992–999, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Medlock</author>
</authors>
<title>Exploring hedge identification in biomedical literature.</title>
<date>2008</date>
<journal>Journal of Biomedical Informatics,</journal>
<pages>41--636</pages>
<contexts>
<context position="11320" citStr="Medlock, 2008" startWordPosition="1834" endWordPosition="1835">et, because hedge detection is a task of sentence classification while the first step of scope finding aims at high accuracy of labeling hedge cues. Therefore, three independent procedures of feature selection are conducted for BioScope corpus dataset. As Wikipedia is not involved in the task of scope finding, it only needs one final feature set. About 200 feature templates are initially considered for each task. We mainly borrow ideas and are enlightened by following sources while initializing feature template sets: a) Previous papers on hedge detection and scope finding (Light et al., 2004; Medlock, 2008; Medlock and Briscoe, 2008; Kilicoglu and Bergler, 2008; Szarvas, 2008; Ganter and Strube, 2009; Morante and Daelemans, 2009); 94 b) Related works such as named entity recognition (Collins, 1999) and text chunking (Zhang et al., 2001); c) Some literature on dependency parsing (Nivre and Scholz, 2004; McDonald et al., 2005; Nivre, 2009; Zhao et al., 2009c; Zhao et al., 2009a); 3.1 Notations of Feature Template A large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced. Many of these features come from dependency parsin</context>
</contexts>
<marker>Medlock, 2008</marker>
<rawString>Ben Medlock. 2008. Exploring hedge identification in biomedical literature. Journal of Biomedical Informatics, 41:636–654.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Walter Daelemans</author>
</authors>
<title>Learning the scope of hedge cues in biomedical texts.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on BioNLP,</booktitle>
<pages>28--36</pages>
<location>Boulder, Colorado,</location>
<contexts>
<context position="6273" citStr="Morante and Daelemans (2009)" startWordPosition="998" endWordPosition="1002">the intermediate representations for task 2. This problem can be solved if sentencelevel hedge detection and intermediate representation finding are treated as two separate tasks with independent feature selection procedures. The details of feature selection will be given in section 3. 2.3 Scope finding for multi-hedge cases Sentences with more than one hedge cue are quite common in both datasets of BioScope corpus and Wikipedia. By counting hedges in every sentence, we find that about one fourth of the sentences with hedges have more than one hedge cue in all three data sources (Table 2). In Morante and Daelemans (2009), three classifiers predict whether each token is Begin, End or None and a postprocessing is needed to associate Begins and Ends with their corresponding hedge cues. In our approach, in order to decrease ambiguous or illegal outputs e.g. inequivalent numbers of Begins and Ends, a pair of Begin and End without their corresponding hedge cue between them, etc., sentences with more than one hedge cue will be preprocessed by making copies as many as the number of hedges and be handled separately. The sentence which is selected as a sample has two hedge cues: “suggesting” and “may”, so our system pr</context>
<context position="11446" citStr="Morante and Daelemans, 2009" startWordPosition="1850" endWordPosition="1853">high accuracy of labeling hedge cues. Therefore, three independent procedures of feature selection are conducted for BioScope corpus dataset. As Wikipedia is not involved in the task of scope finding, it only needs one final feature set. About 200 feature templates are initially considered for each task. We mainly borrow ideas and are enlightened by following sources while initializing feature template sets: a) Previous papers on hedge detection and scope finding (Light et al., 2004; Medlock, 2008; Medlock and Briscoe, 2008; Kilicoglu and Bergler, 2008; Szarvas, 2008; Ganter and Strube, 2009; Morante and Daelemans, 2009); 94 b) Related works such as named entity recognition (Collins, 1999) and text chunking (Zhang et al., 2001); c) Some literature on dependency parsing (Nivre and Scholz, 2004; McDonald et al., 2005; Nivre, 2009; Zhao et al., 2009c; Zhao et al., 2009a); 3.1 Notations of Feature Template A large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced. Many of these features come from dependency parsing, which aims at building syntactic tree expressed by dependencies between words. More details about dependency parsing are gi</context>
</contexts>
<marker>Morante, Daelemans, 2009</marker>
<rawString>Roser Morante and Walter Daelemans. 2009. Learning the scope of hedge cues in biomedical texts. In Proceedings of the Workshop on BioNLP, pages 28–36, Boulder, Colorado, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Mario Scholz</author>
</authors>
<title>Deterministic dependency parsing of English text.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING-2004,</booktitle>
<pages>64--70</pages>
<location>Geneva, Switzerland,</location>
<contexts>
<context position="11621" citStr="Nivre and Scholz, 2004" startWordPosition="1879" endWordPosition="1882">k of scope finding, it only needs one final feature set. About 200 feature templates are initially considered for each task. We mainly borrow ideas and are enlightened by following sources while initializing feature template sets: a) Previous papers on hedge detection and scope finding (Light et al., 2004; Medlock, 2008; Medlock and Briscoe, 2008; Kilicoglu and Bergler, 2008; Szarvas, 2008; Ganter and Strube, 2009; Morante and Daelemans, 2009); 94 b) Related works such as named entity recognition (Collins, 1999) and text chunking (Zhang et al., 2001); c) Some literature on dependency parsing (Nivre and Scholz, 2004; McDonald et al., 2005; Nivre, 2009; Zhao et al., 2009c; Zhao et al., 2009a); 3.1 Notations of Feature Template A large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced. Many of these features come from dependency parsing, which aims at building syntactic tree expressed by dependencies between words. More details about dependency parsing are given in Nivre and Scholz (2004) and McDonald et al. (2005). The parser in Zhao et al. (2009a) is used to construct dependency structures in our system, and some of the notation</context>
</contexts>
<marker>Nivre, Scholz, 2004</marker>
<rawString>Joakim Nivre and Mario Scholz. 2004. Deterministic dependency parsing of English text. In Proceedings of COLING-2004, pages 64–70, Geneva, Switzerland, August 23rd-27th.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Non-projective dependency parsing in expected linear time.</title>
<date>2009</date>
<booktitle>In Proceedings of ACLIJCNLP 2009,</booktitle>
<pages>351--359</pages>
<location>Suntec,</location>
<contexts>
<context position="11657" citStr="Nivre, 2009" startWordPosition="1887" endWordPosition="1888">ture set. About 200 feature templates are initially considered for each task. We mainly borrow ideas and are enlightened by following sources while initializing feature template sets: a) Previous papers on hedge detection and scope finding (Light et al., 2004; Medlock, 2008; Medlock and Briscoe, 2008; Kilicoglu and Bergler, 2008; Szarvas, 2008; Ganter and Strube, 2009; Morante and Daelemans, 2009); 94 b) Related works such as named entity recognition (Collins, 1999) and text chunking (Zhang et al., 2001); c) Some literature on dependency parsing (Nivre and Scholz, 2004; McDonald et al., 2005; Nivre, 2009; Zhao et al., 2009c; Zhao et al., 2009a); 3.1 Notations of Feature Template A large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced. Many of these features come from dependency parsing, which aims at building syntactic tree expressed by dependencies between words. More details about dependency parsing are given in Nivre and Scholz (2004) and McDonald et al. (2005). The parser in Zhao et al. (2009a) is used to construct dependency structures in our system, and some of the notations in this paper adopt those presente</context>
</contexts>
<marker>Nivre, 2009</marker>
<rawString>Joakim Nivre. 2009. Non-projective dependency parsing in expected linear time. In Proceedings of ACLIJCNLP 2009, pages 351–359, Suntec, Singapore, 2-7 August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gy¨orgy Szarvas</author>
<author>Veronika Vincze</author>
<author>Rich´ard Farkas</author>
<author>J´anos Csirik</author>
</authors>
<title>The BioScope corpus: annotation for negation, uncertainty and their scope in biomedical texts.</title>
<date>2008</date>
<booktitle>In Proceedings of BioNLP</booktitle>
<pages>38--45</pages>
<location>Columbus, Ohio, USA,</location>
<contexts>
<context position="2248" citStr="Szarvas et al., 2008" startWordPosition="318" endWordPosition="321">ingly important tasks in natural language processing and information extraction, especially in biomedical community. The shared task of CoNLL-2010 described in Farkas et al. (2010) aims at detecting hedges (task 1) and finding their scopes (task 2) for the literature ∗ This work is partially supported by the National Natural Science Foundation of China (Grants 60903119, 60773090, 90820018 and 90920004), the National Basic Research Program of China (Grant No. 2009CB320901), and the National High-Tech Research Program of China (Grant No.2008AA02Z315). †corresponding author from BioScope corpus (Szarvas et al., 2008) and Wikipedia. This paper describes a system adopting sequence labeling which performs competitive in the official evaluation, as well as further test. In addition, a large-scale feature selection procedure is applied in training and development. Considering that BioScope corpus is annotated by two independent linguists according to a formal guideline (Szarvas, 2008), while Wikipedia weasels are tagged by netizens who are diverse in background and various in evaluation criterion, it is needed to handle them separately. Our system selects features for Wikipedia and BioScope corpus independentl</context>
</contexts>
<marker>Szarvas, Vincze, Farkas, Csirik, 2008</marker>
<rawString>Gy¨orgy Szarvas, Veronika Vincze, Rich´ard Farkas, and J´anos Csirik. 2008. The BioScope corpus: annotation for negation, uncertainty and their scope in biomedical texts. In Proceedings of BioNLP 2008, pages 38–45, Columbus, Ohio, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gy¨orgy Szarvas</author>
</authors>
<title>Hedge classification in biomedical texts with a weakly supervised selection of keywords.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL-08,</booktitle>
<pages>281--289</pages>
<location>Columbus, Ohio, USA,</location>
<contexts>
<context position="2618" citStr="Szarvas, 2008" startWordPosition="376" endWordPosition="377">3090, 90820018 and 90920004), the National Basic Research Program of China (Grant No. 2009CB320901), and the National High-Tech Research Program of China (Grant No.2008AA02Z315). †corresponding author from BioScope corpus (Szarvas et al., 2008) and Wikipedia. This paper describes a system adopting sequence labeling which performs competitive in the official evaluation, as well as further test. In addition, a large-scale feature selection procedure is applied in training and development. Considering that BioScope corpus is annotated by two independent linguists according to a formal guideline (Szarvas, 2008), while Wikipedia weasels are tagged by netizens who are diverse in background and various in evaluation criterion, it is needed to handle them separately. Our system selects features for Wikipedia and BioScope corpus independently and evaluate them respectively, leading to fine performances for all of them. The rest of the paper is organized as follows. The next section presents the technical details of our system of hedge detection and scope finding. Section 3 gives information of features. Section 4 shows the evaluation results, including official results and further ones after official out</context>
<context position="11391" citStr="Szarvas, 2008" startWordPosition="1844" endWordPosition="1845">the first step of scope finding aims at high accuracy of labeling hedge cues. Therefore, three independent procedures of feature selection are conducted for BioScope corpus dataset. As Wikipedia is not involved in the task of scope finding, it only needs one final feature set. About 200 feature templates are initially considered for each task. We mainly borrow ideas and are enlightened by following sources while initializing feature template sets: a) Previous papers on hedge detection and scope finding (Light et al., 2004; Medlock, 2008; Medlock and Briscoe, 2008; Kilicoglu and Bergler, 2008; Szarvas, 2008; Ganter and Strube, 2009; Morante and Daelemans, 2009); 94 b) Related works such as named entity recognition (Collins, 1999) and text chunking (Zhang et al., 2001); c) Some literature on dependency parsing (Nivre and Scholz, 2004; McDonald et al., 2005; Nivre, 2009; Zhao et al., 2009c; Zhao et al., 2009a); 3.1 Notations of Feature Template A large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced. Many of these features come from dependency parsing, which aims at building syntactic tree expressed by dependencies betw</context>
<context position="16769" citStr="Szarvas, 2008" startWordPosition="2757" endWordPosition="2758">Wikipedia (Set W)1 . Table 52 lists some selected feature templates which are basic word or hedging properties for the three sets of BioScope corpus and Wikipedia. From the table we can see it is clear that the combinations of lemma, POS and word form of words in context, which are usually basic and common elements in NLP, are also effective for hedge detection. And as we expected, the feature that represents whether the word is in the hedge list or not is very useful especially in hedge cue finding, indicating that methods based on a hedge cue lists (Light et al., 2004) or keyword selection (Szarvas, 2008) are quite significant way to accomplish such tasks. Some a little complicated syntactic features based on dependencies are systemically exploited as features for tasks. Table 6 enumerates some of the syntactic features which proves to be highly effective. We noticed that lowSupportNoun, highSupportNoun and features derived from dpPath is notably useful. It can be explained by the awareness that hedge labeling and scope finding are to process literatures in the level of semantics where syntactic features are often helpful. We continue our feature selection procedures for BioScope corpus after </context>
</contexts>
<marker>Szarvas, 2008</marker>
<rawString>Gy¨orgy Szarvas. 2008. Hedge classification in biomedical texts with a weakly supervised selection of keywords. In Proceedings ofACL-08, pages 281– 289, Columbus, Ohio, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Thompson</author>
<author>Giulia Venturi</author>
<author>John McNaught</author>
<author>Simonetta Montemagni</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Categorising modality in biomedical texts.</title>
<date>2008</date>
<booktitle>In Proc. of the LREC 2008 Workshop on Building and Evaluating Resources for Biomedical Text Mining,</booktitle>
<pages>27--34</pages>
<location>Marrakech.</location>
<contexts>
<context position="1495" citStr="Thompson et al., 2008" startWordPosition="208" endWordPosition="211">ding. In particular, various kinds of syntactic features are systemically exploited and effectively integrated using a large-scale normalized feature selection method. Evaluation on the CoNLL-2010 shared task shows that our system achieves stable and competitive results for all the closed tasks. Furthermore, post-deadline experiments show that the performance can be much further improved using a sufficient feature selection. 1 Introduction Hedges are linguistic devices representing speculative parts of articles. Previous works such as (Hyland, 1996; Marco and Mercer, 2004; Light et al., 2004; Thompson et al., 2008) present research on hedge mainly as a linguistic phenomenon. Meanwhile, detecting hedges and their scopes automatically are increasingly important tasks in natural language processing and information extraction, especially in biomedical community. The shared task of CoNLL-2010 described in Farkas et al. (2010) aims at detecting hedges (task 1) and finding their scopes (task 2) for the literature ∗ This work is partially supported by the National Natural Science Foundation of China (Grants 60903119, 60773090, 90820018 and 90920004), the National Basic Research Program of China (Grant No. 2009C</context>
</contexts>
<marker>Thompson, Venturi, McNaught, Montemagni, Ananiadou, 2008</marker>
<rawString>Paul Thompson, Giulia Venturi, John McNaught, Simonetta Montemagni, and Sophia Ananiadou. 2008. Categorising modality in biomedical texts. In Proc. of the LREC 2008 Workshop on Building and Evaluating Resources for Biomedical Text Mining, pages 27–34, Marrakech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Aria Haghighi</author>
<author>Christopher D Manning</author>
</authors>
<title>Joint learning improves semantic role labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL-2005,</booktitle>
<pages>589--596</pages>
<location>Ann Arbor, USA.</location>
<contexts>
<context position="13127" citStr="Toutanova et al., 2005" startWordPosition="2114" endWordPosition="2117"> (dp) , syntactic dependency label (dprel). Syntactic Connection. This includes syntactic head (h), left(right) farthest(nearest) child (lm, ln, rm and rn) and high (low) support verb, noun or preposition. Here we specify the last one as an example, support verb(noun/preposition). From a given word to the syntactic root along the syntactic tree, the first verb/noun/preposition that is met is called its low support verb/noun/preposition, and the nearest one to the root(farthest to the given word) is called as its high support verb/noun/preposition. The concept of support verb was broadly used (Toutanova et al., 2005; Xue, 2006; Jiang and Ng, 2006), and it is extended to nouns and prepositions in Zhao et al. (2009b). In addition, a slightly modified syntactic head, pphead, is introduced, it returns the left most sibling of a given word if the word is headed by a preposition, otherwise it returns the original head. Path. There are two basic types of path. One is the linear path (linePath) in the sequence, the other is the path in the syntactic parsing tree (dpPath). For example, m:njdpPath represents the dependency path from word m to n. Assuming that the two paths from m and n to the root are pm and pn, m</context>
</contexts>
<marker>Toutanova, Haghighi, Manning, 2005</marker>
<rawString>Kristina Toutanova, Aria Haghighi, and Christopher D. Manning. 2005. Joint learning improves semantic role labeling. In Proceedings of ACL-2005, pages 589–596, Ann Arbor, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
</authors>
<title>Semantic role labeling of nominalized predicates in Chinese.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL (NAACL-2006),</booktitle>
<pages>431--438</pages>
<location>New York City, USA,</location>
<contexts>
<context position="13138" citStr="Xue, 2006" startWordPosition="2118" endWordPosition="2119">ency label (dprel). Syntactic Connection. This includes syntactic head (h), left(right) farthest(nearest) child (lm, ln, rm and rn) and high (low) support verb, noun or preposition. Here we specify the last one as an example, support verb(noun/preposition). From a given word to the syntactic root along the syntactic tree, the first verb/noun/preposition that is met is called its low support verb/noun/preposition, and the nearest one to the root(farthest to the given word) is called as its high support verb/noun/preposition. The concept of support verb was broadly used (Toutanova et al., 2005; Xue, 2006; Jiang and Ng, 2006), and it is extended to nouns and prepositions in Zhao et al. (2009b). In addition, a slightly modified syntactic head, pphead, is introduced, it returns the left most sibling of a given word if the word is headed by a preposition, otherwise it returns the original head. Path. There are two basic types of path. One is the linear path (linePath) in the sequence, the other is the path in the syntactic parsing tree (dpPath). For example, m:njdpPath represents the dependency path from word m to n. Assuming that the two paths from m and n to the root are pm and pn, m:njdpPathSh</context>
</contexts>
<marker>Xue, 2006</marker>
<rawString>Nianwen Xue. 2006. Semantic role labeling of nominalized predicates in Chinese. In Proceedings of the Human Language Technology Conference of the NAACL (NAACL-2006), pages 431–438, New York City, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tong Zhang</author>
<author>Fred Damerau</author>
<author>David Johnson</author>
</authors>
<title>Text chunking using regularized winnow.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>539--546</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="11555" citStr="Zhang et al., 2001" startWordPosition="1869" endWordPosition="1872">ioScope corpus dataset. As Wikipedia is not involved in the task of scope finding, it only needs one final feature set. About 200 feature templates are initially considered for each task. We mainly borrow ideas and are enlightened by following sources while initializing feature template sets: a) Previous papers on hedge detection and scope finding (Light et al., 2004; Medlock, 2008; Medlock and Briscoe, 2008; Kilicoglu and Bergler, 2008; Szarvas, 2008; Ganter and Strube, 2009; Morante and Daelemans, 2009); 94 b) Related works such as named entity recognition (Collins, 1999) and text chunking (Zhang et al., 2001); c) Some literature on dependency parsing (Nivre and Scholz, 2004; McDonald et al., 2005; Nivre, 2009; Zhao et al., 2009c; Zhao et al., 2009a); 3.1 Notations of Feature Template A large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced. Many of these features come from dependency parsing, which aims at building syntactic tree expressed by dependencies between words. More details about dependency parsing are given in Nivre and Scholz (2004) and McDonald et al. (2005). The parser in Zhao et al. (2009a) is used to const</context>
</contexts>
<marker>Zhang, Damerau, Johnson, 2001</marker>
<rawString>Tong Zhang, Fred Damerau, and David Johnson. 2001. Text chunking using regularized winnow. In Proceedings of the 39th Annual Meeting on Association for Computational Linguistics, pages 539–546, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Zhao</author>
<author>Wenliang Chen</author>
<author>Jun’ichi Kazama</author>
<author>Kiyotaka Uchimoto</author>
<author>Kentaro Torisawa</author>
</authors>
<title>Multilingual dependency learning: Exploiting rich features for tagging syntactic and semantic dependencies.</title>
<date>2009</date>
<booktitle>In Proceedings of CoNLL-2009,</booktitle>
<location>Boulder, Colorado, USA.</location>
<contexts>
<context position="11676" citStr="Zhao et al., 2009" startWordPosition="1889" endWordPosition="1892">ut 200 feature templates are initially considered for each task. We mainly borrow ideas and are enlightened by following sources while initializing feature template sets: a) Previous papers on hedge detection and scope finding (Light et al., 2004; Medlock, 2008; Medlock and Briscoe, 2008; Kilicoglu and Bergler, 2008; Szarvas, 2008; Ganter and Strube, 2009; Morante and Daelemans, 2009); 94 b) Related works such as named entity recognition (Collins, 1999) and text chunking (Zhang et al., 2001); c) Some literature on dependency parsing (Nivre and Scholz, 2004; McDonald et al., 2005; Nivre, 2009; Zhao et al., 2009c; Zhao et al., 2009a); 3.1 Notations of Feature Template A large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced. Many of these features come from dependency parsing, which aims at building syntactic tree expressed by dependencies between words. More details about dependency parsing are given in Nivre and Scholz (2004) and McDonald et al. (2005). The parser in Zhao et al. (2009a) is used to construct dependency structures in our system, and some of the notations in this paper adopt those presented in Zhao et al. (2</context>
<context position="13226" citStr="Zhao et al. (2009" startWordPosition="2133" endWordPosition="2136">(right) farthest(nearest) child (lm, ln, rm and rn) and high (low) support verb, noun or preposition. Here we specify the last one as an example, support verb(noun/preposition). From a given word to the syntactic root along the syntactic tree, the first verb/noun/preposition that is met is called its low support verb/noun/preposition, and the nearest one to the root(farthest to the given word) is called as its high support verb/noun/preposition. The concept of support verb was broadly used (Toutanova et al., 2005; Xue, 2006; Jiang and Ng, 2006), and it is extended to nouns and prepositions in Zhao et al. (2009b). In addition, a slightly modified syntactic head, pphead, is introduced, it returns the left most sibling of a given word if the word is headed by a preposition, otherwise it returns the original head. Path. There are two basic types of path. One is the linear path (linePath) in the sequence, the other is the path in the syntactic parsing tree (dpPath). For example, m:njdpPath represents the dependency path from word m to n. Assuming that the two paths from m and n to the root are pm and pn, m:njdpPathShare, m:njdpPathPred and m:njdpPathArgu represent the common part of pm and pn, part of p</context>
<context position="15314" citStr="Zhao et al. (2009" startWordPosition="2501" endWordPosition="2504"> additional hedge cues from other resources. An indicator (indicator) is given for multi-hedge scope finding, as specified in section 2.At last, in feature set for scope labeling, hedge represents that the word is in a hedge cue. At last, we take x as current token to be labeled, and xm to denote neighbor words. m &gt; 0 represents that it is a word goes mth after current word and m &lt; 0 for word −mth before current word. 3.2 Feature template sets for each task As optimal feature template subsets cannot be expected to be extracted from so large sets by hand, greedy feature selections according to Zhao et al. (2009b) are applied. The normalized feature selection has been proved to be effective in quite a lot of NLP tasks and can often successfully select an optimal or very close to optimal feature set from a large-scale superset. Although usually it needs 3 to 4 loops denoted by “While” in the Algorithm 1 of Zhao et al. (2009b) to get the best template set, we only complete one before official outputs collection because of time limitation, which to a large extent hinders the performance of the system. Three template sets are selected for BioScope corpus. One with the highest accuracy for sentence-level </context>
</contexts>
<marker>Zhao, Chen, Kazama, Uchimoto, Torisawa, 2009</marker>
<rawString>Hai Zhao, Wenliang Chen, Jun’ichi Kazama, Kiyotaka Uchimoto, and Kentaro Torisawa. 2009a. Multilingual dependency learning: Exploiting rich features for tagging syntactic and semantic dependencies. In Proceedings of CoNLL-2009, June 4-5, Boulder, Colorado, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Zhao</author>
<author>Wenliang Chen</author>
<author>Chunyu Kit</author>
</authors>
<title>Semantic dependency parsing of NomBank and PropBank: An efficient integrated approach via a large-scale feature selection.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP-2009,</booktitle>
<pages>30--39</pages>
<contexts>
<context position="11676" citStr="Zhao et al., 2009" startWordPosition="1889" endWordPosition="1892">ut 200 feature templates are initially considered for each task. We mainly borrow ideas and are enlightened by following sources while initializing feature template sets: a) Previous papers on hedge detection and scope finding (Light et al., 2004; Medlock, 2008; Medlock and Briscoe, 2008; Kilicoglu and Bergler, 2008; Szarvas, 2008; Ganter and Strube, 2009; Morante and Daelemans, 2009); 94 b) Related works such as named entity recognition (Collins, 1999) and text chunking (Zhang et al., 2001); c) Some literature on dependency parsing (Nivre and Scholz, 2004; McDonald et al., 2005; Nivre, 2009; Zhao et al., 2009c; Zhao et al., 2009a); 3.1 Notations of Feature Template A large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced. Many of these features come from dependency parsing, which aims at building syntactic tree expressed by dependencies between words. More details about dependency parsing are given in Nivre and Scholz (2004) and McDonald et al. (2005). The parser in Zhao et al. (2009a) is used to construct dependency structures in our system, and some of the notations in this paper adopt those presented in Zhao et al. (2</context>
<context position="13226" citStr="Zhao et al. (2009" startWordPosition="2133" endWordPosition="2136">(right) farthest(nearest) child (lm, ln, rm and rn) and high (low) support verb, noun or preposition. Here we specify the last one as an example, support verb(noun/preposition). From a given word to the syntactic root along the syntactic tree, the first verb/noun/preposition that is met is called its low support verb/noun/preposition, and the nearest one to the root(farthest to the given word) is called as its high support verb/noun/preposition. The concept of support verb was broadly used (Toutanova et al., 2005; Xue, 2006; Jiang and Ng, 2006), and it is extended to nouns and prepositions in Zhao et al. (2009b). In addition, a slightly modified syntactic head, pphead, is introduced, it returns the left most sibling of a given word if the word is headed by a preposition, otherwise it returns the original head. Path. There are two basic types of path. One is the linear path (linePath) in the sequence, the other is the path in the syntactic parsing tree (dpPath). For example, m:njdpPath represents the dependency path from word m to n. Assuming that the two paths from m and n to the root are pm and pn, m:njdpPathShare, m:njdpPathPred and m:njdpPathArgu represent the common part of pm and pn, part of p</context>
<context position="15314" citStr="Zhao et al. (2009" startWordPosition="2501" endWordPosition="2504"> additional hedge cues from other resources. An indicator (indicator) is given for multi-hedge scope finding, as specified in section 2.At last, in feature set for scope labeling, hedge represents that the word is in a hedge cue. At last, we take x as current token to be labeled, and xm to denote neighbor words. m &gt; 0 represents that it is a word goes mth after current word and m &lt; 0 for word −mth before current word. 3.2 Feature template sets for each task As optimal feature template subsets cannot be expected to be extracted from so large sets by hand, greedy feature selections according to Zhao et al. (2009b) are applied. The normalized feature selection has been proved to be effective in quite a lot of NLP tasks and can often successfully select an optimal or very close to optimal feature set from a large-scale superset. Although usually it needs 3 to 4 loops denoted by “While” in the Algorithm 1 of Zhao et al. (2009b) to get the best template set, we only complete one before official outputs collection because of time limitation, which to a large extent hinders the performance of the system. Three template sets are selected for BioScope corpus. One with the highest accuracy for sentence-level </context>
</contexts>
<marker>Zhao, Chen, Kit, 2009</marker>
<rawString>Hai Zhao, Wenliang Chen, and Chunyu Kit. 2009b. Semantic dependency parsing of NomBank and PropBank: An efficient integrated approach via a large-scale feature selection. In Proceedings of EMNLP-2009, pages 30–39, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Zhao</author>
<author>Wenliang Chen</author>
<author>Chunyu Kit</author>
<author>Guodong Zhou</author>
</authors>
<title>Multilingual dependency learning: A huge feature engineering method to semantic dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of CoNLL-2009,</booktitle>
<location>Boulder, Colorado, USA.</location>
<contexts>
<context position="11676" citStr="Zhao et al., 2009" startWordPosition="1889" endWordPosition="1892">ut 200 feature templates are initially considered for each task. We mainly borrow ideas and are enlightened by following sources while initializing feature template sets: a) Previous papers on hedge detection and scope finding (Light et al., 2004; Medlock, 2008; Medlock and Briscoe, 2008; Kilicoglu and Bergler, 2008; Szarvas, 2008; Ganter and Strube, 2009; Morante and Daelemans, 2009); 94 b) Related works such as named entity recognition (Collins, 1999) and text chunking (Zhang et al., 2001); c) Some literature on dependency parsing (Nivre and Scholz, 2004; McDonald et al., 2005; Nivre, 2009; Zhao et al., 2009c; Zhao et al., 2009a); 3.1 Notations of Feature Template A large amount of advanced syntactic features including syntactic connections, paths, families and their concatenations are introduced. Many of these features come from dependency parsing, which aims at building syntactic tree expressed by dependencies between words. More details about dependency parsing are given in Nivre and Scholz (2004) and McDonald et al. (2005). The parser in Zhao et al. (2009a) is used to construct dependency structures in our system, and some of the notations in this paper adopt those presented in Zhao et al. (2</context>
<context position="13226" citStr="Zhao et al. (2009" startWordPosition="2133" endWordPosition="2136">(right) farthest(nearest) child (lm, ln, rm and rn) and high (low) support verb, noun or preposition. Here we specify the last one as an example, support verb(noun/preposition). From a given word to the syntactic root along the syntactic tree, the first verb/noun/preposition that is met is called its low support verb/noun/preposition, and the nearest one to the root(farthest to the given word) is called as its high support verb/noun/preposition. The concept of support verb was broadly used (Toutanova et al., 2005; Xue, 2006; Jiang and Ng, 2006), and it is extended to nouns and prepositions in Zhao et al. (2009b). In addition, a slightly modified syntactic head, pphead, is introduced, it returns the left most sibling of a given word if the word is headed by a preposition, otherwise it returns the original head. Path. There are two basic types of path. One is the linear path (linePath) in the sequence, the other is the path in the syntactic parsing tree (dpPath). For example, m:njdpPath represents the dependency path from word m to n. Assuming that the two paths from m and n to the root are pm and pn, m:njdpPathShare, m:njdpPathPred and m:njdpPathArgu represent the common part of pm and pn, part of p</context>
<context position="15314" citStr="Zhao et al. (2009" startWordPosition="2501" endWordPosition="2504"> additional hedge cues from other resources. An indicator (indicator) is given for multi-hedge scope finding, as specified in section 2.At last, in feature set for scope labeling, hedge represents that the word is in a hedge cue. At last, we take x as current token to be labeled, and xm to denote neighbor words. m &gt; 0 represents that it is a word goes mth after current word and m &lt; 0 for word −mth before current word. 3.2 Feature template sets for each task As optimal feature template subsets cannot be expected to be extracted from so large sets by hand, greedy feature selections according to Zhao et al. (2009b) are applied. The normalized feature selection has been proved to be effective in quite a lot of NLP tasks and can often successfully select an optimal or very close to optimal feature set from a large-scale superset. Although usually it needs 3 to 4 loops denoted by “While” in the Algorithm 1 of Zhao et al. (2009b) to get the best template set, we only complete one before official outputs collection because of time limitation, which to a large extent hinders the performance of the system. Three template sets are selected for BioScope corpus. One with the highest accuracy for sentence-level </context>
</contexts>
<marker>Zhao, Chen, Kit, Zhou, 2009</marker>
<rawString>Hai Zhao, Wenliang Chen, Chunyu Kit, and Guodong Zhou. 2009c. Multilingual dependency learning: A huge feature engineering method to semantic dependency parsing. In Proceedings of CoNLL-2009, June 4-5, Boulder, Colorado, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>