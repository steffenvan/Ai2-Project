<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.124551">
<title confidence="0.987426">
Empirical Acquisition of Differentiating Relations from Definitions
</title>
<author confidence="0.995248">
Tom O’Hara
</author>
<affiliation confidence="0.910837">
Department of Computer Science
New Mexico State University
</affiliation>
<address confidence="0.951523">
Las Cruces, NM 88003
</address>
<email confidence="0.999354">
tomohara@cs.nmsu.edu
</email>
<author confidence="0.988368">
Janyce Wiebe
</author>
<affiliation confidence="0.9986435">
Department of Computer Science
University of Pittsburgh
</affiliation>
<address confidence="0.687357">
Pittsburgh, PA 15260
</address>
<email confidence="0.999029">
wiebe@cs.pitt.edu
</email>
<sectionHeader confidence="0.993903" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999643125">
This paper describes a new automatic approach for
extracting conceptual distinctions from dictionary
definitions. A broad-coverage dependency parser is
first used to extract the lexical relations from the def-
initions. Then the relations are disambiguated using
associations learned from tagged corpora. This con-
trasts with earlier approaches using manually devel-
oped rules for disambiguation.
</bodyText>
<sectionHeader confidence="0.998791" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999960020408163">
Large-scale lexicons for computational semantics of-
ten lack sufficient distinguishing information for the
concepts serving to define words. For example,
WordNet (Miller, 1990) recently introduced new re-
lations for domain category and location in Version
2.0, along with 6,000+ instances; however, about
38% of the noun synsets are still not explicitly dis-
tinguished from sibling synsets.
Work on the Extended WordNet project
(Harabagiu et al., 1999) is achieving substan-
tial progress in making the information in WordNet
more explicit. The main goal is to transform the
definitions into a logical form representation suit-
able for drawing inferences; in addition, the content
words in the definitions are being disambiguated. In
the logical form representation, separate predicates
are used for each preposition, as well as for some
other functional words (e.g., conjunctions); thus,
ambiguity in the underlying relations implicit in
the definitions is not being resolved. The work
described here automates the process of relation
disambiguation. This can be used to further the
transformation of WordNet into an explicit lexical
knowledge base.
Earlier approaches to differentia extraction have
predominantly relied upon manually constructed
pattern matching rules for extracting relations from
dictionary definitions (Vanderwende, 1996; Barri`ere,
1997; Rus, 2002). These rules can be very precise,
but achieving broad-coverage can be difficult. Here
a broad coverage dependency parser is first used to
determine the syntactic relations that are present
among the constituents in the sentence. Then the
syntactic relations between sentential constituents
are converted into semantic relations between the
underlying concepts using statistical classification.
Isolating the disambiguation step from the extrac-
tion step in this manner allows for greater flexibil-
ity over earlier approaches. For example, different
parsers can be incorporated without having to re-
work the disambiguation process.
This paper is organized as follows: Section 2 de-
tails the steps in extracting the initial relations from
the definition parse. Section 3 illustrates the disam-
biguation process, the crucial part of this approach.
Section 4 presents an evaluation of the relations that
are extracted from the WordNet definitions. Lastly,
Section 5 compares the approach to previous ap-
proaches that have been tried.
</bodyText>
<sectionHeader confidence="0.97922" genericHeader="method">
2 Differentia Extraction
</sectionHeader>
<bodyText confidence="0.965028131578947">
The approach to differentia extraction is entirely au-
tomated. This starts with using the Link Grammar
Parser (Sleator and Temperley, 1993), a dependency
parser, to determine the syntactic lexical relations
that occur in the sentence. Dictionary definitions are
often given in the form of sentence fragments with
the headword omitted. For example, the definition
for the beverage sense of ‘wine’ is “fermented juice
(of grapes especially).” Therefore, prior to running
the definition analysis, the definitions are converted
into complete sentences, using simple templates for
each part of speech.
After parsing, a series of postprocessing steps is
performed prior to the extraction of the lexical rela-
tions. For the Link Parser, this mainly involves con-
version of the binary dependencies into relational tu-
ples and the realignment of the tuples around func-
tion words. The Link Parser outputs syntactic de-
pendencies among words, punctuation, and sentence
boundary markers. The parser uses quite specialized
syntactic relations, so these are converted into gen-
eral ones prior to the extraction of the relational tu-
ples. For example, the relation A, which is used for
pre-noun adjectives, is converted into modifies. Fig-
ure 1 illustrates the syntactic relations that would
be extracted, along with the original parser output.
The syntactic relationships are first converted
into relational tuples using the format (source-word,
relation-word, target-word). This conversion is per-
formed by following the dependencies involving the
content words, ignoring cases involving non-word el-
ements (e.g., punctuation). For example, the first
tuple extracted from the parse would be (n:wine,
Definition sentence:
Wine is fermented juice (of grapes especially).
Link Grammar parse:
(/////, Wd, 1. n:wine)
(/////, Xp, 10..)
</bodyText>
<listItem confidence="0.969683166666667">
(1. n:wine, Ss, 2. v:is)
(10.., RW, 11. /////)
(2. v:is, Ost, 4. n:juice)
(3. v:fermented, A, 4. n:juice)
(4. n:juice, MXs, 6. of)
(5. (, Xd, 6. of)
(6. of, Jp, 7. n:grapes)
(6. of, Xc, 9. ))
Extracted relations:
(1. n:wine, 2. v:is, 4. n:juice)
(3. v:fermented, modifies-3-4, 4. n:juice)
(4. n:juice, 6. of, 7. n:grapes)
</listItem>
<figureCaption confidence="0.998773">
Figure 1: Example for relation extraction.
</figureCaption>
<bodyText confidence="0.999985358490566">
v:is, n:juice). Certain types of dependencies are
treated specially by converting the syntactic rela-
tionships directly into a relational tuple involving a
special relation-indicating word (e.g., ‘modifies’).
The relational tuples extracted from the parse
form the basis for the lexical relations derived from
the definition. Structural ambiguity resolution is not
addressed here, so the first parse returned is used.
The remaining optional step assigns weights to the
relations that are extracted.
When using the relations in applications, it is de-
sirable to have a measure of how relevant the re-
lations are to the associated concepts. One such
measure would be the degree to which the relation
applies to the concept being described as opposed
to sibling concepts. To account for this, cue validi-
ties are used, borrowing from cognitive psychology
(Smith and Medin, 1981). Cue validities can be in-
terpreted as probabilities indicating the degree to
which features apply to a given concept versus sim-
ilar concepts (i.e., P(C|F)).
Cue validities are estimated by calculating the
percentage of times that the feature is associated
with a concept versus the total associations of con-
trasting concepts. This requires a means of deter-
mining the set of contrasting concepts for a given
concept. The simplest way of doing this would be to
just select the set of sibling concepts (e.g., synsets
sharing a common parent in WordNet). However,
due to the idiosyncratic way concepts are special-
ized in knowledge bases, this likely would not include
concepts intuitively considered as contrasting.
To alleviate this problem the most-informative an-
cestor will be used instead of the parent. This is
determined by selecting the ancestor that best bal-
ances frequency of occurrence in a tagged corpus
with specificity. This is similar to Resnik’s (1995)
notion of most-informative subsumer for a pair of
concepts. In his approach, estimated frequencies for
synsets are percolated up the hierarchy, so that the
frequency always increases as one proceeds up the
hierarchy. Therefore the first common ancestor for
a pair is the most-informative subsumer (i.e., has
most information content). Here attested frequen-
cies from SemCor (Miller et al., 1994) are used, so all
ancestors are considered. Specificity is accounted for
by applying a scaling factor to the frequencies that
decreases as one proceeds up the hierarchy. Thus,
‘informative’ is used more in an intuitive sense rather
than technical.
More details on the extraction process and the
subsequent disambiguation can be found in (O’Hara,
forthcoming).
</bodyText>
<sectionHeader confidence="0.998898" genericHeader="method">
3 Differentia Disambiguation
</sectionHeader>
<bodyText confidence="0.9929846">
After the differentia properties have been extracted
from a definition, the words for the relation source
and object terms are disambiguated to order to re-
duce vagueness in the relationships. In addition, the
relation types are converted from surface-level rela-
tions (e.g., object) or relation-indicating words (e.g.,
prepositions) into the underlying semantic relation.
Since WordNet serves as the knowledge base be-
ing targeted, term disambiguation involves select-
ing the most appropriate synset for both the source
and target terms. The WordNet definitions have re-
cently been sense-tagged as part of the Extended
WordNet (Novischi, 2002), so these annotations are
incorporated. For other dictionaries, use of tradi-
tional word-sense disambiguation algorithms would
be required.
With the emphasis on corpus analysis in computa-
tional linguistics, there has been shift away from re-
lying on explicitly coded knowledge towards the use
of knowledge inferred from naturally occurring text,
in particular text that has been annotated by hu-
mans to indicate phenomena of interest. The PENN
TREEBANK version II (Marcus et al., 1994) provided
the first large-scale set of case role annotations for
general-purpose text. These are very general roles
akin to Fillmore’s (1968) case roles. The Berkeley
FRAMENET (Fillmore et al., 2001) project provides
the most recent large-scale annotation of semantic
roles. These are at a much finer granularity than
those in Treebank, so they should prove quite use-
ful for applications learning detailed semantics from
corpora. O’Hara and Wiebe (2003) explain how
both inventories can be used for preposition disam-
biguation.
The goal of relation disambiguation is to deter-
mine the underlying semantic role indicated by par-
ticular words in a phrase or by word order. For
relations indicated directly by function words, the
disambiguation can be seen as a special case of word-
sense disambiguation (WSD). As an example, refin-
ing the relationship (‘dog’, ‘with’, ‘ears’) into (‘dog’,
has-part, ‘ears’), is equivalent to disambiguating the
preposition ‘with,’ given that the senses are the dif-
Local-context features
POS: part of speech of target word
POS−i: part-of-speech of ith word to left
POS+i: part-of-speech of ith word to right
Word: target wordform as is
Word−i: ith word to the left
Word+i: ith word to the right
</bodyText>
<figure confidence="0.85783925">
Collocational features
WordColli: word collocation for sense i
Class-based collocational features
HyperColls: hypernym collocation for sense i
</figure>
<figureCaption confidence="0.995711">
Figure 2: Features for preposition classifier.
</figureCaption>
<bodyText confidence="0.999771644444444">
ferent relations it can indicate. For relations that are
indicated implicitly (e.g., adjectival modification),
other classification techniques would be required, re-
flecting the more syntactic nature of the task.
A straightforward approach for preposition disam-
biguation would be to use standard WSD features,
such as the parts-of-speech of surrounding words
and, more importantly, collocations (e.g., lexical as-
sociations). Although this can be highly accurate,
it tends to overfit the data and to generalize poorly.
The latter is of particular concern here as the train-
ing data is taken from a different genre (e.g., news-
paper text rather than dictionary definitions). To
overcome these problems, a class-based approach is
used for the collocations, with WordNet high-level
synsets as the source of the word classes. Figure 2
lists the features used for the classifier.
For the application to differentia disambiguation,
the classifiers learned over Treebank and FrameNet
need to be combined. This can be done readily in a
cascaded fashion with the classifier for the most spe-
cific relation inventory (i.e., FrameNet) being used
first and then the other classifiers being applied in
turn whenever the classification is inconclusive. This
has the advantage that new resources can be in-
tegrated into the combined relation classifier with
minimal effort. However, the resulting role inven-
tory will likely be heterogeneous and might be prone
to inconsistent classifications. In addition, the role
inventory could change whenever new annotation re-
sources are incorporated, making the differentia dis-
ambiguation system less predictable.
Alternatively, the annotations can be converted
into a common inventory, and a separate relation
classifier induced over the resulting data. This has
the advantage that the target relation-type inven-
tory remains stable whenever new sources of relation
annotations are introduced. The drawback however
is that annotations from new resources must first be
mapped into the common inventory before incorpo-
ration. The latter approach is employed here. The
common inventory incorporates some of the general
relation types defined by Gildea and Jurafsky (2002)
for their experiments in classifying semantic rela-
tions in FrameNet using a reduced inventory.
</bodyText>
<table confidence="0.999531157894737">
Relation Frequency
Theme 0.316
Goal 0.116
Ground 0.080
Category 0.069
Agent 0.069
Cause 0.061
Manner 0.058
Recipient 0.053
Medium 0.039
Characteristic 0.022
Resource 0.021
Means 0.021
Source 0.019
Path 0.017
Experiencer 0.017
Accompaniment 0.011
Area 0.010
Direction 0.001
</table>
<tableCaption confidence="0.999694">
Table 1: Frequency of relations extracted.
</tableCaption>
<sectionHeader confidence="0.992934" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999178333333334">
The evaluation discussed here assesses the quality of
the information that would be added to the lexicons
with respect to relation disambiguation, which is the
focus of the research. An application-oriented evalu-
ation is discussed in (O’Hara, forthcoming), showing
how using the extracted information improves word-
sense disambiguation.
All the definitions from WordNet 1.7.1 were run
through the differentia-extraction process. This in-
volved 111,223 synsets, of which 10,810 had prepro-
cessing or parse-related errors leading to no relations
being extracted. Table 1 shows the frequency of the
relations in the output from the differentia extrac-
tion process. The most common relation used is
Theme, which occurs four times as much compared
to the annotations. It is usually annotated as the
sense for ‘of,’ which also occurs with roles Source,
Category, Ground, Agent, Characteristic, and Expe-
riencer. Some of these represent subtle distinctions,
so it is likely that the difference in the text genre is
causing the classifier to use the default more often.
Four human judges were recruited to evaluate ran-
dom samples of the relations that were extracted. To
allow for inter-coder reliability analysis, each evalua-
tor evaluated some samples that were also evaluated
by the others, half as part of a training phase and
half after training. In addition, they also evaluated
a few samples that were manually corrected before-
hand. This provides a baseline against which the
uncorrected results can be measured against. Be-
cause the research only addresses relations indicated
by prepositional phrases, the evaluation is restricted
to these cases. Specifically, the judges rate the as-
signment of relations to the prepositional phrases on
a scale from 1 to 5, with 5 being an exact match.
The evaluation is based on averaging the assess-
</bodyText>
<table confidence="0.998099">
Corrected Uncorrected
#Cases 10 #Cases 15
#Scores 40 #Scores 60
Mean 3.225 Mean 3.033
STDEV 1.625 STDEV 1.551
Score 0.60 Score 0.58
</table>
<tableCaption confidence="0.98935">
Table 2: Mean assessment score for all ex-
</tableCaption>
<bodyText confidence="0.992237375">
tracted relationships. 25 relationships were each
evaluated by 4 judges. Mean gives the mean of the
assessment ratings (from 1 to 5). Score gives ratings
relative to scale from 0 to 1.
ment scores over the relationships. Table 2 shows
the results from this evaluation, including the man-
ually corrected as well as the uncorrected subsets
of the relationships. For the corrected output, the
mean assessment value was 3.225, which translates
into an overall score of 0.60. For the uncorrected sys-
tem output, the mean assessment value was 3.033,
which translates into an overall score of 0.58. Al-
though the absolute score is not high, the system’s
output is generally acceptable, as the score for the
uncorrected set of relationships is close to that of the
manually corrected set.
</bodyText>
<sectionHeader confidence="0.999944" genericHeader="method">
5 Related work
</sectionHeader>
<bodyText confidence="0.999981076923077">
Most of the work addressing differentia extraction
has relied upon manually constructed extraction
rules (Vanderwende, 1996; Barri`ere, 1997; Rus,
2002). Here the emphasis is switched from transfor-
mation patterns for extracting relations into statis-
tical classification for relation disambiguation, given
tagged corpora with examples. This allows for bet-
ter coverage at the expense of precision. Note that
relation disambiguation is not yet addressed in Ex-
tended WordNet (Rus, 2002); for example, preposi-
tions are treated as predicates in the logical form
representation. Their extraction process is also
closely tied into the specifics of the parser, as a trans-
formation rule is developed for each grammar rule.
This work addresses the acquisition of conceptual
distinctions. In principle, it can handle any level
of granularity given sufficient training data; how-
ever, addressing distinctions at the level of near-
synonyms (Edmonds and Hirst, 2002) might require
customized analysis for each cluster of nearly syn-
onymous words. Inkpen and Hirst (2001) discuss
how this can be automated by analyzing specialized
synonymy dictionaries. Decision lists of indicative
keywords are learned for the broad types of prag-
matic distinctions, and these are then manually split
into decision lists for more-specific distinctions.
</bodyText>
<sectionHeader confidence="0.999326" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999965">
We have presented an empirical methodology for
extracting information from dictionary definitions.
This differs from previous approaches by using data-
driven relation disambiguation, using FrameNet se-
mantic roles annotations mapped into a reduced in-
ventory. All the definitions from WordNet 1.7.1 were
analyzed using this process, and the results evalu-
ated by four human judges. The overall results were
not high, but the evaluation was comparable to re-
lations that were manually corrected before coding.
</bodyText>
<sectionHeader confidence="0.996453" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999864">
C. Barri`ere. 1997. From Machine Readable Dictio-
naries to a Lexical Knowledge Base of Conceptual
Graphs. Ph.D. thesis, Simon Fraser University.
P. Edmonds and G. Hirst. 2002. Near-synonymy
and lexical choice. Computational Linguistics,
28(2):105–144.
C. Fillmore, C. Wooters, and C. Baker. 2001. Build-
ing a large lexical databank which provides deep
semantics. In Proc. PACLIC-01.
C. Fillmore. 1968. The case for case. In E. Bach
and R. Harms, editors, Universals in Linguistic
Theory. Holt, Rinehart and Winston, New York.
D. Gildea and D. Jurafsky. 2002. Automatic label-
ing of semantic roles. Computational Linguistics,
28(3):245–288.
S. Harabagiu, G. Miller, and D. Moldovan. 1999.
WordNet 2—A morphologically and semantically
enhanced resource. In Proc. SIGLEX Workshop.
D. Inkpen and G. Hirst. 2001. Building a lexical
knowledge-base of near-synonym differences. In
Proc. WordNet and Other Lexical Resources.
M. Marcus, G. Kim, M. Marcinkiewicz, R. MacIn-
tyre, et al. 1994. The Penn Treebank: Annotat-
ing predicate argument structure. In Proc. ARPA
Human Language Technology Workshop.
G. Miller, M. Chodorow, S. Landes, C. Leacock, and
R. Thomas. 1994. Using a semantic concordance
for sense identification. In Proc. ARPA Human
Language Technology Workshop.
G. Miller. 1990. Introduction. International Jour-
nal of Lexicography, 3(4).
A. Novischi. 2002. Accurate semantic annotations
via pattern matching. In Proc. FLAIRS 2002.
T. O’Hara and J. Wiebe. 2003. Preposition se-
mantic classification via Penn Treebank and
FrameNet. In Proc. CoNLL-03.
T. O’Hara. forthcoming. Empirical acquisition of
conceptual distinctions via dictionary definitions.
Ph.D. thesis, New Mexico State University.
P. Resnik. 1995. Disambiguating noun groupings
with respect to WordNet senses. In Proc. WVLC.
V. Rus. 2002. Logic Forms for WordNet Glosses.
Ph.D. thesis, Southern Methodist University.
D. Sleator and D. Temperley. 1993. Parsing English
with a link grammar. In Proc. Workshop on Pars-
ing Technologies.
E. Smith and D. Medin. 1981. Categories and Con-
cepts. Harvard University Press, Cambridge, MA.
L. Vanderwende. 1996. Understanding Noun Com-
pounds using Semantic Information Extracted
from On-Line Dictionaries. Ph.D. thesis, George-
town University.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.306808">
<title confidence="0.999904">Empirical Acquisition of Differentiating Relations from Definitions</title>
<author confidence="0.993713">Tom</author>
<affiliation confidence="0.851989666666667">Department of Computer New Mexico State Las Cruces, NM</affiliation>
<email confidence="0.998845">tomohara@cs.nmsu.edu</email>
<author confidence="0.727068">Janyce</author>
<affiliation confidence="0.999894">Department of Computer University of</affiliation>
<address confidence="0.77654">Pittsburgh, PA</address>
<email confidence="0.999615">wiebe@cs.pitt.edu</email>
<abstract confidence="0.992300333333333">This paper describes a new automatic approach for extracting conceptual distinctions from dictionary definitions. A broad-coverage dependency parser is first used to extract the lexical relations from the definitions. Then the relations are disambiguated using associations learned from tagged corpora. This contrasts with earlier approaches using manually developed rules for disambiguation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Barri`ere</author>
</authors>
<title>From Machine Readable Dictionaries to a Lexical Knowledge Base of Conceptual Graphs.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>Simon Fraser University.</institution>
<marker>Barri`ere, 1997</marker>
<rawString>C. Barri`ere. 1997. From Machine Readable Dictionaries to a Lexical Knowledge Base of Conceptual Graphs. Ph.D. thesis, Simon Fraser University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Edmonds</author>
<author>G Hirst</author>
</authors>
<title>Near-synonymy and lexical choice.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>2</issue>
<contexts>
<context position="16796" citStr="Edmonds and Hirst, 2002" startWordPosition="2545" endWordPosition="2548">examples. This allows for better coverage at the expense of precision. Note that relation disambiguation is not yet addressed in Extended WordNet (Rus, 2002); for example, prepositions are treated as predicates in the logical form representation. Their extraction process is also closely tied into the specifics of the parser, as a transformation rule is developed for each grammar rule. This work addresses the acquisition of conceptual distinctions. In principle, it can handle any level of granularity given sufficient training data; however, addressing distinctions at the level of nearsynonyms (Edmonds and Hirst, 2002) might require customized analysis for each cluster of nearly synonymous words. Inkpen and Hirst (2001) discuss how this can be automated by analyzing specialized synonymy dictionaries. Decision lists of indicative keywords are learned for the broad types of pragmatic distinctions, and these are then manually split into decision lists for more-specific distinctions. 6 Conclusion We have presented an empirical methodology for extracting information from dictionary definitions. This differs from previous approaches by using datadriven relation disambiguation, using FrameNet semantic roles annota</context>
</contexts>
<marker>Edmonds, Hirst, 2002</marker>
<rawString>P. Edmonds and G. Hirst. 2002. Near-synonymy and lexical choice. Computational Linguistics, 28(2):105–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fillmore</author>
<author>C Wooters</author>
<author>C Baker</author>
</authors>
<title>Building a large lexical databank which provides deep semantics.</title>
<date>2001</date>
<booktitle>In Proc. PACLIC-01.</booktitle>
<contexts>
<context position="9232" citStr="Fillmore et al., 2001" startWordPosition="1380" endWordPosition="1383">ies, use of traditional word-sense disambiguation algorithms would be required. With the emphasis on corpus analysis in computational linguistics, there has been shift away from relying on explicitly coded knowledge towards the use of knowledge inferred from naturally occurring text, in particular text that has been annotated by humans to indicate phenomena of interest. The PENN TREEBANK version II (Marcus et al., 1994) provided the first large-scale set of case role annotations for general-purpose text. These are very general roles akin to Fillmore’s (1968) case roles. The Berkeley FRAMENET (Fillmore et al., 2001) project provides the most recent large-scale annotation of semantic roles. These are at a much finer granularity than those in Treebank, so they should prove quite useful for applications learning detailed semantics from corpora. O’Hara and Wiebe (2003) explain how both inventories can be used for preposition disambiguation. The goal of relation disambiguation is to determine the underlying semantic role indicated by particular words in a phrase or by word order. For relations indicated directly by function words, the disambiguation can be seen as a special case of wordsense disambiguation (W</context>
</contexts>
<marker>Fillmore, Wooters, Baker, 2001</marker>
<rawString>C. Fillmore, C. Wooters, and C. Baker. 2001. Building a large lexical databank which provides deep semantics. In Proc. PACLIC-01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fillmore</author>
</authors>
<title>The case for case.</title>
<date>1968</date>
<booktitle>Universals in Linguistic Theory.</booktitle>
<editor>In E. Bach and R. Harms, editors,</editor>
<location>Holt, Rinehart and Winston, New York.</location>
<marker>Fillmore, 1968</marker>
<rawString>C. Fillmore. 1968. The case for case. In E. Bach and R. Harms, editors, Universals in Linguistic Theory. Holt, Rinehart and Winston, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="12628" citStr="Gildea and Jurafsky (2002)" startWordPosition="1894" endWordPosition="1897">rporated, making the differentia disambiguation system less predictable. Alternatively, the annotations can be converted into a common inventory, and a separate relation classifier induced over the resulting data. This has the advantage that the target relation-type inventory remains stable whenever new sources of relation annotations are introduced. The drawback however is that annotations from new resources must first be mapped into the common inventory before incorporation. The latter approach is employed here. The common inventory incorporates some of the general relation types defined by Gildea and Jurafsky (2002) for their experiments in classifying semantic relations in FrameNet using a reduced inventory. Relation Frequency Theme 0.316 Goal 0.116 Ground 0.080 Category 0.069 Agent 0.069 Cause 0.061 Manner 0.058 Recipient 0.053 Medium 0.039 Characteristic 0.022 Resource 0.021 Means 0.021 Source 0.019 Path 0.017 Experiencer 0.017 Accompaniment 0.011 Area 0.010 Direction 0.001 Table 1: Frequency of relations extracted. 4 Evaluation The evaluation discussed here assesses the quality of the information that would be added to the lexicons with respect to relation disambiguation, which is the focus of the re</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>D. Gildea and D. Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Harabagiu</author>
<author>G Miller</author>
<author>D Moldovan</author>
</authors>
<title>WordNet 2—A morphologically and semantically enhanced resource.</title>
<date>1999</date>
<booktitle>In Proc. SIGLEX Workshop.</booktitle>
<contexts>
<context position="1154" citStr="Harabagiu et al., 1999" startWordPosition="154" endWordPosition="157">ns are disambiguated using associations learned from tagged corpora. This contrasts with earlier approaches using manually developed rules for disambiguation. 1 Introduction Large-scale lexicons for computational semantics often lack sufficient distinguishing information for the concepts serving to define words. For example, WordNet (Miller, 1990) recently introduced new relations for domain category and location in Version 2.0, along with 6,000+ instances; however, about 38% of the noun synsets are still not explicitly distinguished from sibling synsets. Work on the Extended WordNet project (Harabagiu et al., 1999) is achieving substantial progress in making the information in WordNet more explicit. The main goal is to transform the definitions into a logical form representation suitable for drawing inferences; in addition, the content words in the definitions are being disambiguated. In the logical form representation, separate predicates are used for each preposition, as well as for some other functional words (e.g., conjunctions); thus, ambiguity in the underlying relations implicit in the definitions is not being resolved. The work described here automates the process of relation disambiguation. Thi</context>
</contexts>
<marker>Harabagiu, Miller, Moldovan, 1999</marker>
<rawString>S. Harabagiu, G. Miller, and D. Moldovan. 1999. WordNet 2—A morphologically and semantically enhanced resource. In Proc. SIGLEX Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Inkpen</author>
<author>G Hirst</author>
</authors>
<title>Building a lexical knowledge-base of near-synonym differences.</title>
<date>2001</date>
<booktitle>In Proc. WordNet and Other Lexical Resources.</booktitle>
<contexts>
<context position="16899" citStr="Inkpen and Hirst (2001)" startWordPosition="2561" endWordPosition="2564"> is not yet addressed in Extended WordNet (Rus, 2002); for example, prepositions are treated as predicates in the logical form representation. Their extraction process is also closely tied into the specifics of the parser, as a transformation rule is developed for each grammar rule. This work addresses the acquisition of conceptual distinctions. In principle, it can handle any level of granularity given sufficient training data; however, addressing distinctions at the level of nearsynonyms (Edmonds and Hirst, 2002) might require customized analysis for each cluster of nearly synonymous words. Inkpen and Hirst (2001) discuss how this can be automated by analyzing specialized synonymy dictionaries. Decision lists of indicative keywords are learned for the broad types of pragmatic distinctions, and these are then manually split into decision lists for more-specific distinctions. 6 Conclusion We have presented an empirical methodology for extracting information from dictionary definitions. This differs from previous approaches by using datadriven relation disambiguation, using FrameNet semantic roles annotations mapped into a reduced inventory. All the definitions from WordNet 1.7.1 were analyzed using this </context>
</contexts>
<marker>Inkpen, Hirst, 2001</marker>
<rawString>D. Inkpen and G. Hirst. 2001. Building a lexical knowledge-base of near-synonym differences. In Proc. WordNet and Other Lexical Resources.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>G Kim</author>
<author>M Marcinkiewicz</author>
<author>R MacIntyre</author>
</authors>
<title>The Penn Treebank: Annotating predicate argument structure.</title>
<date>1994</date>
<booktitle>In Proc. ARPA Human Language Technology Workshop.</booktitle>
<contexts>
<context position="9033" citStr="Marcus et al., 1994" startWordPosition="1350" endWordPosition="1353">oth the source and target terms. The WordNet definitions have recently been sense-tagged as part of the Extended WordNet (Novischi, 2002), so these annotations are incorporated. For other dictionaries, use of traditional word-sense disambiguation algorithms would be required. With the emphasis on corpus analysis in computational linguistics, there has been shift away from relying on explicitly coded knowledge towards the use of knowledge inferred from naturally occurring text, in particular text that has been annotated by humans to indicate phenomena of interest. The PENN TREEBANK version II (Marcus et al., 1994) provided the first large-scale set of case role annotations for general-purpose text. These are very general roles akin to Fillmore’s (1968) case roles. The Berkeley FRAMENET (Fillmore et al., 2001) project provides the most recent large-scale annotation of semantic roles. These are at a much finer granularity than those in Treebank, so they should prove quite useful for applications learning detailed semantics from corpora. O’Hara and Wiebe (2003) explain how both inventories can be used for preposition disambiguation. The goal of relation disambiguation is to determine the underlying semant</context>
</contexts>
<marker>Marcus, Kim, Marcinkiewicz, MacIntyre, 1994</marker>
<rawString>M. Marcus, G. Kim, M. Marcinkiewicz, R. MacIntyre, et al. 1994. The Penn Treebank: Annotating predicate argument structure. In Proc. ARPA Human Language Technology Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
<author>M Chodorow</author>
<author>S Landes</author>
<author>C Leacock</author>
<author>R Thomas</author>
</authors>
<title>Using a semantic concordance for sense identification.</title>
<date>1994</date>
<booktitle>In Proc. ARPA Human Language Technology Workshop.</booktitle>
<contexts>
<context position="7522" citStr="Miller et al., 1994" startWordPosition="1123" endWordPosition="1126">the most-informative ancestor will be used instead of the parent. This is determined by selecting the ancestor that best balances frequency of occurrence in a tagged corpus with specificity. This is similar to Resnik’s (1995) notion of most-informative subsumer for a pair of concepts. In his approach, estimated frequencies for synsets are percolated up the hierarchy, so that the frequency always increases as one proceeds up the hierarchy. Therefore the first common ancestor for a pair is the most-informative subsumer (i.e., has most information content). Here attested frequencies from SemCor (Miller et al., 1994) are used, so all ancestors are considered. Specificity is accounted for by applying a scaling factor to the frequencies that decreases as one proceeds up the hierarchy. Thus, ‘informative’ is used more in an intuitive sense rather than technical. More details on the extraction process and the subsequent disambiguation can be found in (O’Hara, forthcoming). 3 Differentia Disambiguation After the differentia properties have been extracted from a definition, the words for the relation source and object terms are disambiguated to order to reduce vagueness in the relationships. In addition, the re</context>
</contexts>
<marker>Miller, Chodorow, Landes, Leacock, Thomas, 1994</marker>
<rawString>G. Miller, M. Chodorow, S. Landes, C. Leacock, and R. Thomas. 1994. Using a semantic concordance for sense identification. In Proc. ARPA Human Language Technology Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
</authors>
<date>1990</date>
<journal>Introduction. International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="880" citStr="Miller, 1990" startWordPosition="113" endWordPosition="114">60 wiebe@cs.pitt.edu Abstract This paper describes a new automatic approach for extracting conceptual distinctions from dictionary definitions. A broad-coverage dependency parser is first used to extract the lexical relations from the definitions. Then the relations are disambiguated using associations learned from tagged corpora. This contrasts with earlier approaches using manually developed rules for disambiguation. 1 Introduction Large-scale lexicons for computational semantics often lack sufficient distinguishing information for the concepts serving to define words. For example, WordNet (Miller, 1990) recently introduced new relations for domain category and location in Version 2.0, along with 6,000+ instances; however, about 38% of the noun synsets are still not explicitly distinguished from sibling synsets. Work on the Extended WordNet project (Harabagiu et al., 1999) is achieving substantial progress in making the information in WordNet more explicit. The main goal is to transform the definitions into a logical form representation suitable for drawing inferences; in addition, the content words in the definitions are being disambiguated. In the logical form representation, separate predi</context>
</contexts>
<marker>Miller, 1990</marker>
<rawString>G. Miller. 1990. Introduction. International Journal of Lexicography, 3(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Novischi</author>
</authors>
<title>Accurate semantic annotations via pattern matching.</title>
<date>2002</date>
<booktitle>In Proc. FLAIRS</booktitle>
<contexts>
<context position="8550" citStr="Novischi, 2002" startWordPosition="1278" endWordPosition="1279">operties have been extracted from a definition, the words for the relation source and object terms are disambiguated to order to reduce vagueness in the relationships. In addition, the relation types are converted from surface-level relations (e.g., object) or relation-indicating words (e.g., prepositions) into the underlying semantic relation. Since WordNet serves as the knowledge base being targeted, term disambiguation involves selecting the most appropriate synset for both the source and target terms. The WordNet definitions have recently been sense-tagged as part of the Extended WordNet (Novischi, 2002), so these annotations are incorporated. For other dictionaries, use of traditional word-sense disambiguation algorithms would be required. With the emphasis on corpus analysis in computational linguistics, there has been shift away from relying on explicitly coded knowledge towards the use of knowledge inferred from naturally occurring text, in particular text that has been annotated by humans to indicate phenomena of interest. The PENN TREEBANK version II (Marcus et al., 1994) provided the first large-scale set of case role annotations for general-purpose text. These are very general roles a</context>
</contexts>
<marker>Novischi, 2002</marker>
<rawString>A. Novischi. 2002. Accurate semantic annotations via pattern matching. In Proc. FLAIRS 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T O’Hara</author>
<author>J Wiebe</author>
</authors>
<title>Preposition semantic classification via Penn Treebank and FrameNet. In</title>
<date>2003</date>
<booktitle>Proc. CoNLL-03.</booktitle>
<marker>O’Hara, Wiebe, 2003</marker>
<rawString>T. O’Hara and J. Wiebe. 2003. Preposition semantic classification via Penn Treebank and FrameNet. In Proc. CoNLL-03.</rawString>
</citation>
<citation valid="false">
<authors>
<author>forthcoming</author>
</authors>
<title>Empirical acquisition of conceptual distinctions via dictionary definitions.</title>
<tech>Ph.D. thesis,</tech>
<institution>New Mexico State University.</institution>
<marker>forthcoming, </marker>
<rawString>T. O’Hara. forthcoming. Empirical acquisition of conceptual distinctions via dictionary definitions. Ph.D. thesis, New Mexico State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Disambiguating noun groupings with respect to WordNet senses.</title>
<date>1995</date>
<booktitle>In Proc. WVLC. V. Rus.</booktitle>
<tech>Ph.D. thesis,</tech>
<institution>Southern Methodist University.</institution>
<marker>Resnik, 1995</marker>
<rawString>P. Resnik. 1995. Disambiguating noun groupings with respect to WordNet senses. In Proc. WVLC. V. Rus. 2002. Logic Forms for WordNet Glosses. Ph.D. thesis, Southern Methodist University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Sleator</author>
<author>D Temperley</author>
</authors>
<title>Parsing English with a link grammar.</title>
<date>1993</date>
<booktitle>In Proc. Workshop on Parsing Technologies.</booktitle>
<contexts>
<context position="3258" citStr="Sleator and Temperley, 1993" startWordPosition="460" endWordPosition="463">be incorporated without having to rework the disambiguation process. This paper is organized as follows: Section 2 details the steps in extracting the initial relations from the definition parse. Section 3 illustrates the disambiguation process, the crucial part of this approach. Section 4 presents an evaluation of the relations that are extracted from the WordNet definitions. Lastly, Section 5 compares the approach to previous approaches that have been tried. 2 Differentia Extraction The approach to differentia extraction is entirely automated. This starts with using the Link Grammar Parser (Sleator and Temperley, 1993), a dependency parser, to determine the syntactic lexical relations that occur in the sentence. Dictionary definitions are often given in the form of sentence fragments with the headword omitted. For example, the definition for the beverage sense of ‘wine’ is “fermented juice (of grapes especially).” Therefore, prior to running the definition analysis, the definitions are converted into complete sentences, using simple templates for each part of speech. After parsing, a series of postprocessing steps is performed prior to the extraction of the lexical relations. For the Link Parser, this mainl</context>
</contexts>
<marker>Sleator, Temperley, 1993</marker>
<rawString>D. Sleator and D. Temperley. 1993. Parsing English with a link grammar. In Proc. Workshop on Parsing Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Smith</author>
<author>D Medin</author>
</authors>
<title>Categories and Concepts.</title>
<date>1981</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="6163" citStr="Smith and Medin, 1981" startWordPosition="908" endWordPosition="911">parse form the basis for the lexical relations derived from the definition. Structural ambiguity resolution is not addressed here, so the first parse returned is used. The remaining optional step assigns weights to the relations that are extracted. When using the relations in applications, it is desirable to have a measure of how relevant the relations are to the associated concepts. One such measure would be the degree to which the relation applies to the concept being described as opposed to sibling concepts. To account for this, cue validities are used, borrowing from cognitive psychology (Smith and Medin, 1981). Cue validities can be interpreted as probabilities indicating the degree to which features apply to a given concept versus similar concepts (i.e., P(C|F)). Cue validities are estimated by calculating the percentage of times that the feature is associated with a concept versus the total associations of contrasting concepts. This requires a means of determining the set of contrasting concepts for a given concept. The simplest way of doing this would be to just select the set of sibling concepts (e.g., synsets sharing a common parent in WordNet). However, due to the idiosyncratic way concepts a</context>
</contexts>
<marker>Smith, Medin, 1981</marker>
<rawString>E. Smith and D. Medin. 1981. Categories and Concepts. Harvard University Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Vanderwende</author>
</authors>
<title>Understanding Noun Compounds using Semantic Information Extracted from On-Line Dictionaries.</title>
<date>1996</date>
<tech>Ph.D. thesis,</tech>
<institution>Georgetown University.</institution>
<contexts>
<context position="2041" citStr="Vanderwende, 1996" startWordPosition="282" endWordPosition="283">ated. In the logical form representation, separate predicates are used for each preposition, as well as for some other functional words (e.g., conjunctions); thus, ambiguity in the underlying relations implicit in the definitions is not being resolved. The work described here automates the process of relation disambiguation. This can be used to further the transformation of WordNet into an explicit lexical knowledge base. Earlier approaches to differentia extraction have predominantly relied upon manually constructed pattern matching rules for extracting relations from dictionary definitions (Vanderwende, 1996; Barri`ere, 1997; Rus, 2002). These rules can be very precise, but achieving broad-coverage can be difficult. Here a broad coverage dependency parser is first used to determine the syntactic relations that are present among the constituents in the sentence. Then the syntactic relations between sentential constituents are converted into semantic relations between the underlying concepts using statistical classification. Isolating the disambiguation step from the extraction step in this manner allows for greater flexibility over earlier approaches. For example, different parsers can be incorpor</context>
<context position="15970" citStr="Vanderwende, 1996" startWordPosition="2422" endWordPosition="2423">ed as well as the uncorrected subsets of the relationships. For the corrected output, the mean assessment value was 3.225, which translates into an overall score of 0.60. For the uncorrected system output, the mean assessment value was 3.033, which translates into an overall score of 0.58. Although the absolute score is not high, the system’s output is generally acceptable, as the score for the uncorrected set of relationships is close to that of the manually corrected set. 5 Related work Most of the work addressing differentia extraction has relied upon manually constructed extraction rules (Vanderwende, 1996; Barri`ere, 1997; Rus, 2002). Here the emphasis is switched from transformation patterns for extracting relations into statistical classification for relation disambiguation, given tagged corpora with examples. This allows for better coverage at the expense of precision. Note that relation disambiguation is not yet addressed in Extended WordNet (Rus, 2002); for example, prepositions are treated as predicates in the logical form representation. Their extraction process is also closely tied into the specifics of the parser, as a transformation rule is developed for each grammar rule. This work </context>
</contexts>
<marker>Vanderwende, 1996</marker>
<rawString>L. Vanderwende. 1996. Understanding Noun Compounds using Semantic Information Extracted from On-Line Dictionaries. Ph.D. thesis, Georgetown University.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>