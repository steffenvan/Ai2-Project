<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000143">
<title confidence="0.99069">
Concept Classification with Bayesian Multi-task Learning
</title>
<author confidence="0.805428">
Marcel van Gerven
</author>
<affiliation confidence="0.841222">
Radboud University Nijmegen
</affiliation>
<address confidence="0.472051666666667">
Intelligent Systems
Heyendaalseweg 135 6525 AJ
Nijmegen, The Netherlands
</address>
<email confidence="0.9886">
marcelge@cs.ru.nl
</email>
<author confidence="0.786489">
Irina Simanova
</author>
<affiliation confidence="0.713424">
Max Planck Institute for Psycholinguistics
</affiliation>
<address confidence="0.4153745">
Wundtlaan 1 6525 XD
Nijmegen, The Netherlands
</address>
<email confidence="0.990292">
irina.simanova@mpi.nl
</email>
<sectionHeader confidence="0.998521" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997786277777778">
Multivariate analysis allows decoding of sin-
gle trial data in individual subjects. Since dif-
ferent models are obtained for each subject it
becomes hard to perform an analysis on the
group level. We introduce a new algorithm for
Bayesian multi-task learning which imposes a
coupling between single-subject models. Us-
ing the CMU fMRI dataset it is shown that the
algorithm can be used for concept classifica-
tion based on the average activation of regions
in the AAL atlas. Concepts which were most
easily classified correspond to the categories
shelter, manipulation and eating, which is in
accordance with the literature. The multi-task
learning algorithm is shown to find regions of
interest that are common to all subjects which
therefore facilitates interpretation of the ob-
tained models.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998422948717949">
Multivariate analysis allows decoding of neural rep-
resentations at the single trial level in single sub-
jects. Its introduction into the field of cognitive neu-
roscience has led to novel insights about the neu-
ral representation of cognitive functions such as lan-
guage (Mitchell et al., 2008), memory (Hassabis et
al., 2009), and vision (Miyawaki et al., 2008).
However, interpretation of the models obtained
using a multivariate analysis can be hard due to
the fact that different models are obtained for indi-
vidual subjects. For example, when analyzing K
separately acquired datasets, K sets of model pa-
rameters will be obtained which may or may not
show a common pattern. In some sense, we are in
need of a second-level analysis such that we can
draw inferences on the group level, as in the con-
ventional analysis of neuroimaging data using the
general linear model. One way to achieve this in
the context of multivariate analysis is by means of
multi-task learning, a special case of transfer learn-
ing (Thrun, 1996) where model parameters for dif-
ferent tasks (datasets) are estimated simultaneously
and no longer assumed to be independent (Caru-
ana, 1997). In an fMRI context, multi-task learning
has been explored using canonical correlation anal-
ysis (Rustandi et al., 2009).
In a Bayesian setting, multi-task learning is typ-
ically realized by assuming a hierarchical Bayesian
framework where shared prior distributions condi-
tion task-specific parameters (Gelman et al., 1995).
In this paper, we explore a new Bayesian approach
to multi-task learning in the context of concept clas-
sification; i.e., the prediction of the semantic cate-
gory of concrete nouns from BOLD response. Effec-
tively, we are using a shared prior to induce param-
eter shrinkage. We show that Bayesian multi-task
learning leads to more interpretable models, thereby
facilitating the interpretation of the models obtained
using multivariate analysis.
</bodyText>
<sectionHeader confidence="0.954645" genericHeader="method">
2 Bayesian multi-task learning
</sectionHeader>
<bodyText confidence="0.999326285714286">
The goal of concept classification is to predict the
semantic category y of a presented (and previously
unseen) concrete noun from the measured BOLD re-
sponse x. In this paper, we will use Bayesian logis-
tic regression as the underlying classification model.
Let 13(y; p) = py(1 − p)&apos;−y denote the Bernoulli
distribution and l(x) = log(x/(1−x)) the logit link
</bodyText>
<page confidence="0.974299">
10
</page>
<note confidence="0.5838245">
Proceedings of the NAACL HLT 2010 First Workshop on Computational Neurolinguistics, pages 10–17,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<equation confidence="0.9932005">
S=0 S=10 S=100
β2 2 β2 2 β2 2
1 1 1
0 0 0
−1 −1 −1
−2 −2 −2
−2 −1 0 1 2 −2 −1 0 1 2 −2 −1 0 1 2
β1 β1 β1
</equation>
<figureCaption confidence="0.99380675">
Figure 1: Contour plots of samples drawn from the prior for two regression coefficients 01 and 02 given three different
values of the coupling strength s. For uncoupled covariates, the magnitude of one covariate has no influence on the
magnitude of the other covariate. For strongly coupled covariates, in contrast, a large magnitude of one covariate
increases the probability of a large magnitude in the other covariate.
</figureCaption>
<bodyText confidence="0.9881915">
function. We are interested in the following predic-
tive density:
</bodyText>
<equation confidence="0.739661">
Zp(y  |x, D, O) = 13(y; l−1(x&apos;β))p(β  |D, O)dβ
</equation>
<bodyText confidence="0.9999112">
where we integrate out the regression coefficients β
and condition on the response x, observed training
data D = (y, X) and hyper-parameters O. Using
Bayes rule, we can write the second term on the right
hand side as
</bodyText>
<equation confidence="0.880684">
p(β  |D, O) a p(D  |β)p(β  |O) (1)
</equation>
<bodyText confidence="0.758766">
where
</bodyText>
<equation confidence="0.9984535">
p(D  |β) = Y 13(yn; l−1(xnβ))
n
</equation>
<bodyText confidence="0.994978">
is the likelihood term, which does not depend on the
hyper-parameters O, and p(β  |O) is the prior on
the regression coefficients.
Let N(x; µ, O) denote a multivariate Gaussian
with mean µ and covariance matrix O. In order to
couple the tasks in a multi-task problem, we will use
the multivariate Laplace prior, which can be written
as a scale-mixture using auxiliary variables u and
v (van Gerven et al., 2010):
</bodyText>
<equation confidence="0.966674666666667">
p(β  |O) = Z Y
k !N(0k; 0, uk + vk)
x N(u; 0, O)N(v; 0, O)du dv
</equation>
<bodyText confidence="0.9975078">
The multivariate Laplace prior allows one to con-
trol the prior variance of the regression coefficients
β through the covariance matrix O of the auxiliary
variables u and v. This covariance matrix is conve-
niently specified in terms of the precision matrix:
</bodyText>
<equation confidence="0.994109">
O−1 = 1� VRV.
</equation>
<bodyText confidence="0.99918">
Here, 0 is a scale parameter which controls regu-
larization of the regression coefficients towards zero
and R is a structure matrix where rid = −s speci-
fies a fixed coupling strength s between covariate i
and covariate j. A negative rid penalizes differences
between covariates i and j, see van Gerven et al.
(2010) for details. V is a scaling matrix whose sole
purpose is to ensure that the prior variance of the
auxiliary variables is independent of the coupling
strength.1 Figure 1 shows the multivariate Laplace
prior for two covariates and three different coupling
strengths.
The specification of the prior in terms of 0 and
R promotes sparse solutions and allows the inclu-
sion of prior knowledge about the relation between
covariates. The posterior marginals for the latent
variables (β, u, v) can be approximated using ex-
pectation propagation (Minka, 2001) and the poste-
rior variance of the auxiliary variables ui (or vi by
symmetry) can be interpreted as a measure of im-
</bodyText>
<equation confidence="0.74345">
1 V is a matrix with -,/diag(R−1) on the diagonal.
</equation>
<page confidence="0.990996">
11
</page>
<bodyText confidence="0.999947692307692">
portance of the corresponding covariate xi since it
eventually determines how large the regression co-
efficients Oi can become.
Interpretation becomes complicated whenever we
have collected multiple datasets for the same task
since each corresponding model may give differ-
ent results regarding the importance of the co-
variates used when solving the classification prob-
lem. Multi-task learning presents a solution to this
problem by dropping the assumption that datasets
{D1, ... , DK} are independent. Here, this is eas-
ily realized using the multivariate Laplace prior by
working with the augmented dataset
</bodyText>
<equation confidence="0.95518125">
X1 0 0 0
0 X2 0 0
0 0 ... 0
0 0 0 XK
</equation>
<bodyText confidence="0.997219666666667">
and by assuming that each covariate is coupled be-
tween datasets. I.e., the structure matrix is given by
elements
</bodyText>
<equation confidence="0.97895725">
−s if i =� j and
(i − j)modP = 0
1 + (K − 1) · s ifi=j
0 otherwise
</equation>
<bodyText confidence="0.999992625">
where P stands for the number of covariates in each
dataset. In this way, we have coupled covariates over
datasets with coupling strength s. Note that this cou-
pling is realized on the level of the auxiliary vari-
ables and not on the regression coefficients. Hence,
coupled auxiliary variables control the magnitude of
the regression coefficients ,3 but the ,3’s themselves
can still be different for the individual subjects.
</bodyText>
<sectionHeader confidence="0.999399" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999979555555556">
In order to test our approach to Bayesian multi-task
learning for concept classification we have made
use of the CMU fMRI dataset2, which consists of
sixty concrete concepts in twelve categories. The
dataset was collected while nine English speakers
were presented with sixty line drawings of objects
with text labels and were instructed to think of the
same properties of the stimulus object consistently
during each presentation. For each concept there are
</bodyText>
<page confidence="0.328078">
2http://www.cs.cmu.edu/—tom/science2008
</page>
<bodyText confidence="0.999945275">
six instances per subject for which BOLD response
in multiple voxels was measured.
In our experiments we assessed whether previ-
ously unseen concepts from two different categories
(e.g., building-tool) can be classified correctly based
on measured BOLD response. To this end, all con-
cepts belonging to two out of the twelve semantic
categories were selected. Subsequently, we trained
a classifier on all concepts belonging to these two
categories save one. The semantic category of the
six instances of the left-out concept were then pre-
dicted using the trained classifier. This procedure
was repeated for each of the concepts and classifi-
cation performance was averaged over all concepts.
This performance was computed for all of the 66
possible category pairs.
In order to determine the effect of multi-task
learning, results were obtained when assuming no
coupling between datasets (s = 0) as well as when
assuming a very strong coupling between datasets
(s = 100). The scale parameter was fixed to 0 =
1. In order to allow the coupling to be made, all
datasets are required to contain the same features.
One way to achieve this is to warp the data for each
subject from native space to normalized space and to
perform the multi-task learning in normalized space.
Here, in contrast, we computed the average activa-
tion in 116 predefined regions of interest (ROIs) us-
ing the AAL atlas (Tzourio-Mazoyer et al., 2002).
ROI activations were used as input to the classifier.
This considerably reduces computational overhead
since we need to couple just 116 ROIs instead of
approximately 20000 voxels between all nine sub-
jects.3 Furthermore, it facilitates interpretation since
results can be analyzed at the ROI level instead of at
the single voxel level. Of course, this presupposes
that category-specific information is captured by the
average activation in predefined ROIs, which is an
important open question we set out to answer with
our experiments.
</bodyText>
<sectionHeader confidence="0.999991" genericHeader="evaluation">
4 Results
</sectionHeader>
<subsectionHeader confidence="0.999954">
4.1 Classification of category pairs
</subsectionHeader>
<bodyText confidence="0.9999385">
We achieved good classification performance for
many of the category pairs both with and with-
</bodyText>
<footnote confidence="0.8446675">
3The efficiency of our algorithm depends on the sparseness
of the structure matrix R.
</footnote>
<equation confidence="0.886727142857143">
D* = � � Y1 1[ ,
� � Y2
� � ...
� � YK
� �
1)
rid = {
</equation>
<page confidence="0.992655">
12
</page>
<tableCaption confidence="0.779173">
Table 1: Stimulus words from the semantic categories
0.75 that showed best classification accuracies. Superscripts
indicate the words belonging to the list of ten words with
</tableCaption>
<table confidence="0.7662264">
0.7 highest factor scores in the study by Just et al. (Just,
2010). We use the following abbreviations: s = shelter,
m = manipulation, e = eating.
0.65
Building Buildpart Tool Kitchen
apartments window chiselm glasse
barn doors hammerm knifem
houses chimney screwdriverm bottle
churchs closets pliersm cupe
igloo arch sawm spoonm
</table>
<figure confidence="0.993526259259259">
0.6
0.55
0.5
animal
bodypart
building
buildpart
clothing
furniture
insect
kitchen
manmade
tool
vegetable
vehicle
animal
bodypart
building
buildpart
clothing
furniture
insect
kitchen
manmade
tool
vegetable
vehicle
</figure>
<figureCaption confidence="0.650814857142857">
Figure 2: Accuracies for concept classification of the 66
category pairs. The upper triangular part shows the re-
sults of multi-task learning whereas the lower triangular
part shows the results of standard classification. Non-
significant outcomes have been masked (Wilcoxon rank
sum test on outcomes for all nine subjects, p=0.05, Bon-
ferroni corrected).
</figureCaption>
<bodyText confidence="0.9999704">
out multi-task learning. Figure 2 shows these re-
sults where non-significant outcomes have been
masked. Interestingly, outcomes for all subjects
showed a preference for particular category pairs.
The concepts from building-tool, building-kitchen
and buildpart-tool had the highest mean classifica-
tion accuracies (proportion of correctly classifier tri-
als) of 0.78, 0.76 and 0.74, closely followed by con-
cepts from building-clothing and animal-buildpart
with a mean classification accuracy of 0.71.
This result bears a strong resemblance to the re-
cent work of Just et al. (2010). The authors con-
ducted a factor analysis of fMRI brain activation in
response to presentations of written words of differ-
ent categories and discovered three semantic factors
with the highest predictive potential: manipulation,
eating and shelter-entry. They subsequently used
these factors to select voxels for a features set and
were able to accurately identify the activation gen-
erated by concrete word using multivariate learning
methods on the basis of selected voxels. Moreover,
using the factor-related activation profiles they were
able to identify common neuronal signatures for par-
ticular words across participants. The authors sug-
gest the revealed factors to represent major semantic
dimensions that relate to the ways the human being
can interact with an object. Although they assume
the existence of other semantic attributes that deter-
mine conceptual representation, the factors shelter,
manipulation and eating are proposed to be domi-
nant for the particular set of nouns. It is easy to draw
an analogy as the set of words used by Just and col-
leagues was exactly the same as in the current study.
Although the taxonomic categorization used in our
study does not exactly match the factor-based cate-
gorization, most of the items from categories build-
ing, buildpart, tool and kitchen show a strong corre-
spondence with one of the semantic factors and are
listed among ten words with highest factor scores
according to Just et al. (2010) (see Table 1).
The subsets of items that are set far apart in the
suggested semantic dimensions appear to be pre-
ferred by the classifier in our study. The classifier
was not able to identify the category of an unseen
concept in pairs building-buildpart and tool-kitchen,
possibly since they these categories shared the same
semantic features. Thus, the current study brings an
independent corroboration for the finding on the se-
mantic dimensions underlying concrete noun repre-
sentation.
</bodyText>
<subsectionHeader confidence="0.993967">
4.2 Single versus multi-task learning
</subsectionHeader>
<bodyText confidence="0.999885166666667">
The use of AAL regions instead of native voxel ac-
tivity patterns allowed efficient multi-task learning
by coupling each region between nine subjects. Re-
liable classification accuracies were obtained for all
the participants, although there were strong differ-
ences in individual performances (Fig. 3). The move
</bodyText>
<page confidence="0.993139">
13
</page>
<figure confidence="0.985426">
accuracy
subject
</figure>
<figureCaption confidence="0.99424575">
Figure 3: Classification performance per subject aver-
aged over all category pairs for standard classification and
multi-task learning (error bars show standard error of the
mean).
</figureCaption>
<bodyText confidence="0.99915">
to multi-task learning seems to improve classifica-
tion results slightly in most of subjects, although the
improvement is not significant.
The main outcome and advantage of our approach
to multi-task learning is the convergence of models
obtained from different subjects. Figure 4 shows
that the subject-specific models become strongly
correlated when they are obtained in the multi-task
setting, even for weak coupling strengths. For strong
coupling strengths, the models are almost perfectly
correlated, resulting in identical models for all the
nine subjects as shown in Fig. 4 for the category pair
building-tool. It is important to realize here that the
model is defined in terms of the variance of the aux-
iliary variables, which acts as a proxy to the impor-
tance of a region. At the level of the regression coef-
ficients ,3, the model will still find subject-specific
parameters due to the likelihood term in Eq. (1).
Even though the contribution of each brain region
is constrained by the induced coupling, this does
not impede but rather improve classification perfor-
mance. This fact entitles us to believe that our ap-
proach to multi-task learning tracks down the com-
mon task-specific activations while ignoring back-
ground noise.
Our study demonstrates that Bayesian multi-task
learning allows generalization across subjects. Our
algorithm identifies identical cortical locations as
being important in solving the classification prob-
lem for all individuals within the group. The iden-
tified regions agree with previously published re-
sults on concept encoding. For example, the re-
gions which were considered important for the cat-
egory pair building-tool (Fig. 5) are almost indis-
tinguishable from those described in a recent study
by Shinkareva et al. (2008). These are regions that
are traditionally considered to be involved in read-
ing, objects meaning retrieval and visual semantic
tasks (Vandenberghe et al., 1996; Phillips et al.,
2002).
Strikingly, very similar regions were picked by
the classifier for the other two category pairs with
high classification accuracy, i.e., building-kitchen
and buildpart-tool. This fact brings back the issue
about the semantic factors relevant for the discrimi-
nation of the entities from these categories. The fac-
tors shelter, manipulation and eating are associated
with the concepts from the first three addressed cat-
egory pairs. The locations of voxel clusters associ-
ated with the semantic factors in (Just et al., 2010)
match the brain regions that contributed to the clas-
sification for the three most optimal pairs in our ex-
periment. In the Just et al. study these were left
and right fusiform gyri, left and right precuneus and
left inferior temporal gyrus for shelter, left supra-
marginal gyrus, left postcentral gyrus and left infe-
rior temporal gyrus for manipulation and left inferior
frontal gyrus, left middle/inferior frontal gyri, and
left inferior temporal gyrus for eating. The occipital
lobes detected exclusively in our experiment might
be explained by the fact that in our experiment the
subjects were viewing picture-text pairs in contrast
to only text in (Just et al., 2010).
</bodyText>
<sectionHeader confidence="0.998563" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.989129923076923">
We have demonstrated that Bayesian multi-task
learning can be realized through Bayesian logistic
regression when using a multivariate Laplace prior
that couples features between multiple datasets.
This approach has not been used before and yields
promising results. As such it complements other
Bayesian and non-Bayesian approaches to multi-
task learning such as those reported in (Yu et al.,
2005; Dunson et al., 2008; Argyriou et al., 2008; van
Gerven et al., 2009; Obozinski et al., 2009; Rustandi
et al., 2009).
Results show that many category pairs can be
classified based on the average activation of regions
</bodyText>
<figure confidence="0.994892607142857">
0.8
0.75
0.7
0.65
0.6
0.55
0.5
1 2 3 4 5 6 7 8 9
standard
multi-task
14
1
2
3
4
5
6
Subject
7
8
9
1
2
3
4
5
6
Subject
7
8
9
Strong coupling (s = 100)
No coupling (s = 0)
A C
No coupling (s = 0)
1 2 3 4 5 6 7 8 9
B Weak coupling (s = 1)
0.9
0.5
0.98
0.92
0.86
0
AAL brain region
7
6
5
4
3
2
1
0
_1
_2
1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9
Subject Subject
</figure>
<figureCaption confidence="0.974549">
Figure 4: Correlation matrices for subject-specific models for standard classification (A) and multi-task learning (B)
with weak coupling (s=1) for building versus tool. The right panel (C) shows the difference between the obtained
models for standard classification and strong coupling (s=100) for the thirty most important AAL regions.
</figureCaption>
<bodyText confidence="0.999778617647059">
in the AAL template. Although obtained accura-
cies are lower than those which would have been ob-
tained using single-voxel activations, it is interesting
in its own right that the activation in just 116 pre-
defined regions still allows concept decoding. How-
ever, it remains an open question to what extent clas-
sifiability truly reflects semantic processing instead
of sensory processing of words and/or pictures.
The coupling induced by multi-task learning leads
to interpretable models when using auxiliary vari-
able variance as a measure of importance. The ob-
tained models for the pairs which were easiest to
classify corresponded well to the results reported
in (Shinkareva et al., 2008) and mapped nicely onto
the semantic features shelter, manipulation and eat-
ing identified in (Just et al., 2010).
In this paper we used the multivariate Laplace
prior to induce a coupling between tasks. It is
straightforward to combine this with other coupling
constraints such as coupling nearby regions within
subjects. Our algorithm also does not preclude
multi-task learning on thousands of voxels. Com-
putation time depends on the number of non-zeros
in the structure matrix R and matrices containing
hundreds of thousands of non-zero elements are still
manageable with computation time being in the or-
der of hours.
Another interesting application of multi-task
learning in the context of concept learning is to cou-
ple the datasets of all condition pairs within a sub-
ject. This effectively tries to find a model where used
regions of interest can predict multiple condition
pairs. The correlation structure between the models
for each condition pair then informs about their sim-
</bodyText>
<page confidence="0.9912">
15
</page>
<figureCaption confidence="0.999843">
Figure 5: The brain regions contributing to the identification of building versus tool categories.
</figureCaption>
<bodyText confidence="0.999407142857143">
ilarity. An interesting direction for future research
is to perform multi-task learning on the level of the
semantic features that define a concept instead of on
the concepts themselves. If we are able to predict the
semantic features reliably then we may be able to
predict previously unseen concepts from their con-
stituent features (Palatucci et al., 2009).
</bodyText>
<sectionHeader confidence="0.99896" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99953009375">
A. Argyriou, T Evgeniou, and M. Pontil. 2008. Con-
vex multi-task feature learning. Machine Learning,
73(3):243–272.
R. Caruana. 1997. Multitask learning. Machine Learn-
ing, 28(1):41–75.
D. Dunson, Y. Xue, and L. Carin. 2008. The ma-
trix stick-breaking process: flexible Bayes meta anal-
ysis. Journal of the American Statistical Association,
103(481):317–327.
A. Gelman, J. B. Carlin, H. S. Stern, and D. B. Rubin.
1995. Bayesian Data Analysis. Chapman and Hall,
London, UK, 1st edition.
D. Hassabis, C. Chu, G. Rees, N. Weiskopf, P. D.
Molyneux, and E. A. Maguire. 2009. Decoding neu-
ronal ensembles in the human hippocampus. Current
Biology, 19:546–554.
M. A. Just, V. L. Cherkassky, S. Aryal, and T. M.
Mitchell. 2010. A neurosemantic theory of concrete
noun representation based on the underlying brain
codes. PLoS ONE, 5(1):e8622.
T. Minka. 2001. Expectation propagation for approxi-
mate Bayesian inference. In J. Breese and D. Koller,
editors, Proceedings of the Seventeenth Conference on
Uncertainty in Artificial Intelligence, pages 362–369.
Morgan Kaufmann.
T. M. Mitchell, S. V. Shinkareva, A. Carlson, K.-M.
Chang, V. L. Malave, R. A. Mason, and M. A. Just.
2008. Predicting human brain activity associated with
the meanings of nouns. Science, 320(5880):1191–
1195.
Y. Miyawaki, H. Uchida, O. Yamashita, M. Sato,
Y. Morito, H. C. Tanabe, N. Sadato, and Y. Kamitani.
</reference>
<page confidence="0.970873">
16
</page>
<reference confidence="0.9999006875">
2008. Visual image reconstruction from human brain
activity using a combination of multiscale local image
decoders. Neuron, 60(5):915–929.
G. Obozinski, B. Taskar, and M. I. Jordan. 2009. Joint
covariate selection and joint subspace selection for
multiple classification problems. In Statistics and
Computing. Springer.
M. Palatucci, D. Pomerleau, G. Hinton, and T. Mitchell.
2009. Zero-shot learning with semantic output codes.
In Y. Bengio, D. Schuurmans, J. Lafferty, C. K. I.
Williams, and A. Culotta, editors, Neural Information
Processing Systems, pages 1410–1418.
J. A. Phillips, U. Noppeney, G. W. Humphreys, and C. J.
Price. 2002. Can segregation within the semantic
system account for category-specific deficits? Brain,
125(9):2067–2080.
I. Rustandi, M. A. Just, and T. M. Mitchell. 2009. Inte-
grating multiple-study multiple-subject fMRI datasets
using canonical correlation analysis. In Proceedings
of the MICCAI 2009 Workshop.
S. V. Shinkareva, R. A. Mason, V. L. Malave, W. Wang,
and T. M. Mitchell. 2008. Using fMRI brain activa-
tion to identify cognitive states associated with percep-
tion of tools and dwellings. PLoS ONE, 3(1):e1394.
S. Thrun. 1996. Is learning the n-th thing any easier than
learning the first? In Advances in Neural Information
Processing Systems, pages 640–646. The MIT Press.
N. Tzourio-Mazoyer, B. Landeau, D. Papathanassiou,
F. Crivello, O. Etard, N. Delcroix, B. Mazoyer, and
M. Joliot. 2002. Automated anatomical labeling of ac-
tivations in SPM using a macroscopic anatomical par-
cellation of the MNI MRI single-subject brain. Neu-
roimage, 15(1):273–289.
M. A. J. van Gerven, C. Hesse, O. Jensen, and T. Heskes.
2009. Interpreting single trial data using groupwise
regularisation. NeuroImage, 46:665–676.
M. A. J. van Gerven, B. Cseke, F. P. de Lange, and T. Hes-
kes. 2010. Efficient Bayesian multivariate fMRI anal-
ysis using a sparsifying spatio-temporal prior. Neu-
roImage, 50(1):150–161.
R. Vandenberghe, C. Price, R. Wise, O. Josephs, and R. S.
Frackowiak. 1996. Functional anatomy of a com-
mon semantic system for words and pictures. Nature,
383(6597):254–256.
K. Yu, V. Tresp, and A. Schwaighofer. 2005. Learning
Gaussian processes from multiple tasks. In Interna-
tional Conference on Machine Learning, pages 1012–
1019.
</reference>
<page confidence="0.999402">
17
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.052435">
<title confidence="0.999604">Concept Classification with Bayesian Multi-task Learning</title>
<author confidence="0.999963">Marcel van</author>
<affiliation confidence="0.7576415">Radboud University Intelligent</affiliation>
<address confidence="0.6869575">Heyendaalseweg 135 6525 Nijmegen, The</address>
<email confidence="0.70344">marcelge@cs.ru.nl</email>
<author confidence="0.597604">Irina Max Planck Institute for</author>
<address confidence="0.494203">Wundtlaan 1 6525 Nijmegen, The</address>
<email confidence="0.941416">irina.simanova@mpi.nl</email>
<abstract confidence="0.997123210526316">Multivariate analysis allows decoding of single trial data in individual subjects. Since different models are obtained for each subject it becomes hard to perform an analysis on the group level. We introduce a new algorithm for Bayesian multi-task learning which imposes a coupling between single-subject models. Using the CMU fMRI dataset it is shown that the algorithm can be used for concept classification based on the average activation of regions in the AAL atlas. Concepts which were most easily classified correspond to the categories shelter, manipulation and eating, which is in accordance with the literature. The multi-task learning algorithm is shown to find regions of interest that are common to all subjects which therefore facilitates interpretation of the obtained models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Argyriou</author>
<author>T Evgeniou</author>
<author>M Pontil</author>
</authors>
<date>2008</date>
<booktitle>Convex multi-task feature learning. Machine Learning,</booktitle>
<volume>73</volume>
<issue>3</issue>
<contexts>
<context position="18042" citStr="Argyriou et al., 2008" startWordPosition="2905" endWordPosition="2908">y in our experiment might be explained by the fact that in our experiment the subjects were viewing picture-text pairs in contrast to only text in (Just et al., 2010). 5 Discussion We have demonstrated that Bayesian multi-task learning can be realized through Bayesian logistic regression when using a multivariate Laplace prior that couples features between multiple datasets. This approach has not been used before and yields promising results. As such it complements other Bayesian and non-Bayesian approaches to multitask learning such as those reported in (Yu et al., 2005; Dunson et al., 2008; Argyriou et al., 2008; van Gerven et al., 2009; Obozinski et al., 2009; Rustandi et al., 2009). Results show that many category pairs can be classified based on the average activation of regions 0.8 0.75 0.7 0.65 0.6 0.55 0.5 1 2 3 4 5 6 7 8 9 standard multi-task 14 1 2 3 4 5 6 Subject 7 8 9 1 2 3 4 5 6 Subject 7 8 9 Strong coupling (s = 100) No coupling (s = 0) A C No coupling (s = 0) 1 2 3 4 5 6 7 8 9 B Weak coupling (s = 1) 0.9 0.5 0.98 0.92 0.86 0 AAL brain region 7 6 5 4 3 2 1 0 _1 _2 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 Subject Subject Figure 4: Correlation matrices for subject-specific mode</context>
</contexts>
<marker>Argyriou, Evgeniou, Pontil, 2008</marker>
<rawString>A. Argyriou, T Evgeniou, and M. Pontil. 2008. Convex multi-task feature learning. Machine Learning, 73(3):243–272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Caruana</author>
</authors>
<date>1997</date>
<booktitle>Multitask learning. Machine Learning,</booktitle>
<volume>28</volume>
<issue>1</issue>
<contexts>
<context position="2290" citStr="Caruana, 1997" startWordPosition="354" endWordPosition="356"> analyzing K separately acquired datasets, K sets of model parameters will be obtained which may or may not show a common pattern. In some sense, we are in need of a second-level analysis such that we can draw inferences on the group level, as in the conventional analysis of neuroimaging data using the general linear model. One way to achieve this in the context of multivariate analysis is by means of multi-task learning, a special case of transfer learning (Thrun, 1996) where model parameters for different tasks (datasets) are estimated simultaneously and no longer assumed to be independent (Caruana, 1997). In an fMRI context, multi-task learning has been explored using canonical correlation analysis (Rustandi et al., 2009). In a Bayesian setting, multi-task learning is typically realized by assuming a hierarchical Bayesian framework where shared prior distributions condition task-specific parameters (Gelman et al., 1995). In this paper, we explore a new Bayesian approach to multi-task learning in the context of concept classification; i.e., the prediction of the semantic category of concrete nouns from BOLD response. Effectively, we are using a shared prior to induce parameter shrinkage. We sh</context>
</contexts>
<marker>Caruana, 1997</marker>
<rawString>R. Caruana. 1997. Multitask learning. Machine Learning, 28(1):41–75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Dunson</author>
<author>Y Xue</author>
<author>L Carin</author>
</authors>
<title>The matrix stick-breaking process: flexible Bayes meta analysis.</title>
<date>2008</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>103</volume>
<issue>481</issue>
<contexts>
<context position="18019" citStr="Dunson et al., 2008" startWordPosition="2901" endWordPosition="2904">s detected exclusively in our experiment might be explained by the fact that in our experiment the subjects were viewing picture-text pairs in contrast to only text in (Just et al., 2010). 5 Discussion We have demonstrated that Bayesian multi-task learning can be realized through Bayesian logistic regression when using a multivariate Laplace prior that couples features between multiple datasets. This approach has not been used before and yields promising results. As such it complements other Bayesian and non-Bayesian approaches to multitask learning such as those reported in (Yu et al., 2005; Dunson et al., 2008; Argyriou et al., 2008; van Gerven et al., 2009; Obozinski et al., 2009; Rustandi et al., 2009). Results show that many category pairs can be classified based on the average activation of regions 0.8 0.75 0.7 0.65 0.6 0.55 0.5 1 2 3 4 5 6 7 8 9 standard multi-task 14 1 2 3 4 5 6 Subject 7 8 9 1 2 3 4 5 6 Subject 7 8 9 Strong coupling (s = 100) No coupling (s = 0) A C No coupling (s = 0) 1 2 3 4 5 6 7 8 9 B Weak coupling (s = 1) 0.9 0.5 0.98 0.92 0.86 0 AAL brain region 7 6 5 4 3 2 1 0 _1 _2 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 Subject Subject Figure 4: Correlation matrices fo</context>
</contexts>
<marker>Dunson, Xue, Carin, 2008</marker>
<rawString>D. Dunson, Y. Xue, and L. Carin. 2008. The matrix stick-breaking process: flexible Bayes meta analysis. Journal of the American Statistical Association, 103(481):317–327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gelman</author>
<author>J B Carlin</author>
<author>H S Stern</author>
<author>D B Rubin</author>
</authors>
<title>Bayesian Data Analysis.</title>
<date>1995</date>
<publisher>Chapman and Hall,</publisher>
<location>London, UK,</location>
<contexts>
<context position="2612" citStr="Gelman et al., 1995" startWordPosition="399" endWordPosition="402">ar model. One way to achieve this in the context of multivariate analysis is by means of multi-task learning, a special case of transfer learning (Thrun, 1996) where model parameters for different tasks (datasets) are estimated simultaneously and no longer assumed to be independent (Caruana, 1997). In an fMRI context, multi-task learning has been explored using canonical correlation analysis (Rustandi et al., 2009). In a Bayesian setting, multi-task learning is typically realized by assuming a hierarchical Bayesian framework where shared prior distributions condition task-specific parameters (Gelman et al., 1995). In this paper, we explore a new Bayesian approach to multi-task learning in the context of concept classification; i.e., the prediction of the semantic category of concrete nouns from BOLD response. Effectively, we are using a shared prior to induce parameter shrinkage. We show that Bayesian multi-task learning leads to more interpretable models, thereby facilitating the interpretation of the models obtained using multivariate analysis. 2 Bayesian multi-task learning The goal of concept classification is to predict the semantic category y of a presented (and previously unseen) concrete noun </context>
</contexts>
<marker>Gelman, Carlin, Stern, Rubin, 1995</marker>
<rawString>A. Gelman, J. B. Carlin, H. S. Stern, and D. B. Rubin. 1995. Bayesian Data Analysis. Chapman and Hall, London, UK, 1st edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hassabis</author>
<author>C Chu</author>
<author>G Rees</author>
<author>N Weiskopf</author>
<author>P D Molyneux</author>
<author>E A Maguire</author>
</authors>
<title>Decoding neuronal ensembles in the human hippocampus. Current Biology,</title>
<date>2009</date>
<contexts>
<context position="1456" citStr="Hassabis et al., 2009" startWordPosition="213" endWordPosition="216">assified correspond to the categories shelter, manipulation and eating, which is in accordance with the literature. The multi-task learning algorithm is shown to find regions of interest that are common to all subjects which therefore facilitates interpretation of the obtained models. 1 Introduction Multivariate analysis allows decoding of neural representations at the single trial level in single subjects. Its introduction into the field of cognitive neuroscience has led to novel insights about the neural representation of cognitive functions such as language (Mitchell et al., 2008), memory (Hassabis et al., 2009), and vision (Miyawaki et al., 2008). However, interpretation of the models obtained using a multivariate analysis can be hard due to the fact that different models are obtained for individual subjects. For example, when analyzing K separately acquired datasets, K sets of model parameters will be obtained which may or may not show a common pattern. In some sense, we are in need of a second-level analysis such that we can draw inferences on the group level, as in the conventional analysis of neuroimaging data using the general linear model. One way to achieve this in the context of multivariate</context>
</contexts>
<marker>Hassabis, Chu, Rees, Weiskopf, Molyneux, Maguire, 2009</marker>
<rawString>D. Hassabis, C. Chu, G. Rees, N. Weiskopf, P. D. Molyneux, and E. A. Maguire. 2009. Decoding neuronal ensembles in the human hippocampus. Current Biology, 19:546–554.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Just</author>
<author>V L Cherkassky</author>
<author>S Aryal</author>
<author>T M Mitchell</author>
</authors>
<title>A neurosemantic theory of concrete noun representation based on the underlying brain codes. PLoS ONE,</title>
<date>2010</date>
<pages>5--1</pages>
<contexts>
<context position="11968" citStr="Just et al. (2010)" startWordPosition="1956" endWordPosition="1959"> subjects, p=0.05, Bonferroni corrected). out multi-task learning. Figure 2 shows these results where non-significant outcomes have been masked. Interestingly, outcomes for all subjects showed a preference for particular category pairs. The concepts from building-tool, building-kitchen and buildpart-tool had the highest mean classification accuracies (proportion of correctly classifier trials) of 0.78, 0.76 and 0.74, closely followed by concepts from building-clothing and animal-buildpart with a mean classification accuracy of 0.71. This result bears a strong resemblance to the recent work of Just et al. (2010). The authors conducted a factor analysis of fMRI brain activation in response to presentations of written words of different categories and discovered three semantic factors with the highest predictive potential: manipulation, eating and shelter-entry. They subsequently used these factors to select voxels for a features set and were able to accurately identify the activation generated by concrete word using multivariate learning methods on the basis of selected voxels. Moreover, using the factor-related activation profiles they were able to identify common neuronal signatures for particular w</context>
<context position="13414" citStr="Just et al. (2010)" startWordPosition="2186" endWordPosition="2189">attributes that determine conceptual representation, the factors shelter, manipulation and eating are proposed to be dominant for the particular set of nouns. It is easy to draw an analogy as the set of words used by Just and colleagues was exactly the same as in the current study. Although the taxonomic categorization used in our study does not exactly match the factor-based categorization, most of the items from categories building, buildpart, tool and kitchen show a strong correspondence with one of the semantic factors and are listed among ten words with highest factor scores according to Just et al. (2010) (see Table 1). The subsets of items that are set far apart in the suggested semantic dimensions appear to be preferred by the classifier in our study. The classifier was not able to identify the category of an unseen concept in pairs building-buildpart and tool-kitchen, possibly since they these categories shared the same semantic features. Thus, the current study brings an independent corroboration for the finding on the semantic dimensions underlying concrete noun representation. 4.2 Single versus multi-task learning The use of AAL regions instead of native voxel activity patterns allowed e</context>
<context position="16917" citStr="Just et al., 2010" startWordPosition="2727" endWordPosition="2730">s meaning retrieval and visual semantic tasks (Vandenberghe et al., 1996; Phillips et al., 2002). Strikingly, very similar regions were picked by the classifier for the other two category pairs with high classification accuracy, i.e., building-kitchen and buildpart-tool. This fact brings back the issue about the semantic factors relevant for the discrimination of the entities from these categories. The factors shelter, manipulation and eating are associated with the concepts from the first three addressed category pairs. The locations of voxel clusters associated with the semantic factors in (Just et al., 2010) match the brain regions that contributed to the classification for the three most optimal pairs in our experiment. In the Just et al. study these were left and right fusiform gyri, left and right precuneus and left inferior temporal gyrus for shelter, left supramarginal gyrus, left postcentral gyrus and left inferior temporal gyrus for manipulation and left inferior frontal gyrus, left middle/inferior frontal gyri, and left inferior temporal gyrus for eating. The occipital lobes detected exclusively in our experiment might be explained by the fact that in our experiment the subjects were view</context>
<context position="19722" citStr="Just et al., 2010" startWordPosition="3228" endWordPosition="3231">tivation in just 116 predefined regions still allows concept decoding. However, it remains an open question to what extent classifiability truly reflects semantic processing instead of sensory processing of words and/or pictures. The coupling induced by multi-task learning leads to interpretable models when using auxiliary variable variance as a measure of importance. The obtained models for the pairs which were easiest to classify corresponded well to the results reported in (Shinkareva et al., 2008) and mapped nicely onto the semantic features shelter, manipulation and eating identified in (Just et al., 2010). In this paper we used the multivariate Laplace prior to induce a coupling between tasks. It is straightforward to combine this with other coupling constraints such as coupling nearby regions within subjects. Our algorithm also does not preclude multi-task learning on thousands of voxels. Computation time depends on the number of non-zeros in the structure matrix R and matrices containing hundreds of thousands of non-zero elements are still manageable with computation time being in the order of hours. Another interesting application of multi-task learning in the context of concept learning is</context>
</contexts>
<marker>Just, Cherkassky, Aryal, Mitchell, 2010</marker>
<rawString>M. A. Just, V. L. Cherkassky, S. Aryal, and T. M. Mitchell. 2010. A neurosemantic theory of concrete noun representation based on the underlying brain codes. PLoS ONE, 5(1):e8622.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Minka</author>
</authors>
<title>Expectation propagation for approximate Bayesian inference.</title>
<date>2001</date>
<booktitle>Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence,</booktitle>
<pages>362--369</pages>
<editor>In J. Breese and D. Koller, editors,</editor>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="6159" citStr="Minka, 2001" startWordPosition="1016" endWordPosition="1017">erences between covariates i and j, see van Gerven et al. (2010) for details. V is a scaling matrix whose sole purpose is to ensure that the prior variance of the auxiliary variables is independent of the coupling strength.1 Figure 1 shows the multivariate Laplace prior for two covariates and three different coupling strengths. The specification of the prior in terms of 0 and R promotes sparse solutions and allows the inclusion of prior knowledge about the relation between covariates. The posterior marginals for the latent variables (β, u, v) can be approximated using expectation propagation (Minka, 2001) and the posterior variance of the auxiliary variables ui (or vi by symmetry) can be interpreted as a measure of im1 V is a matrix with -,/diag(R−1) on the diagonal. 11 portance of the corresponding covariate xi since it eventually determines how large the regression coefficients Oi can become. Interpretation becomes complicated whenever we have collected multiple datasets for the same task since each corresponding model may give different results regarding the importance of the covariates used when solving the classification problem. Multi-task learning presents a solution to this problem by </context>
</contexts>
<marker>Minka, 2001</marker>
<rawString>T. Minka. 2001. Expectation propagation for approximate Bayesian inference. In J. Breese and D. Koller, editors, Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence, pages 362–369. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T M Mitchell</author>
<author>S V Shinkareva</author>
<author>A Carlson</author>
<author>K-M Chang</author>
<author>V L Malave</author>
<author>R A Mason</author>
<author>M A Just</author>
</authors>
<title>Predicting human brain activity associated with the meanings of nouns.</title>
<date>2008</date>
<journal>Science,</journal>
<volume>320</volume>
<issue>5880</issue>
<pages>1195</pages>
<contexts>
<context position="1424" citStr="Mitchell et al., 2008" startWordPosition="208" endWordPosition="211">ncepts which were most easily classified correspond to the categories shelter, manipulation and eating, which is in accordance with the literature. The multi-task learning algorithm is shown to find regions of interest that are common to all subjects which therefore facilitates interpretation of the obtained models. 1 Introduction Multivariate analysis allows decoding of neural representations at the single trial level in single subjects. Its introduction into the field of cognitive neuroscience has led to novel insights about the neural representation of cognitive functions such as language (Mitchell et al., 2008), memory (Hassabis et al., 2009), and vision (Miyawaki et al., 2008). However, interpretation of the models obtained using a multivariate analysis can be hard due to the fact that different models are obtained for individual subjects. For example, when analyzing K separately acquired datasets, K sets of model parameters will be obtained which may or may not show a common pattern. In some sense, we are in need of a second-level analysis such that we can draw inferences on the group level, as in the conventional analysis of neuroimaging data using the general linear model. One way to achieve thi</context>
</contexts>
<marker>Mitchell, Shinkareva, Carlson, Chang, Malave, Mason, Just, 2008</marker>
<rawString>T. M. Mitchell, S. V. Shinkareva, A. Carlson, K.-M. Chang, V. L. Malave, R. A. Mason, and M. A. Just. 2008. Predicting human brain activity associated with the meanings of nouns. Science, 320(5880):1191– 1195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Miyawaki</author>
<author>H Uchida</author>
<author>O Yamashita</author>
<author>M Sato</author>
<author>Y Morito</author>
<author>H C Tanabe</author>
<author>N Sadato</author>
<author>Y Kamitani</author>
</authors>
<title>Visual image reconstruction from human brain activity using a combination of multiscale local image decoders.</title>
<date>2008</date>
<journal>Neuron,</journal>
<volume>60</volume>
<issue>5</issue>
<contexts>
<context position="1492" citStr="Miyawaki et al., 2008" startWordPosition="219" endWordPosition="222">s shelter, manipulation and eating, which is in accordance with the literature. The multi-task learning algorithm is shown to find regions of interest that are common to all subjects which therefore facilitates interpretation of the obtained models. 1 Introduction Multivariate analysis allows decoding of neural representations at the single trial level in single subjects. Its introduction into the field of cognitive neuroscience has led to novel insights about the neural representation of cognitive functions such as language (Mitchell et al., 2008), memory (Hassabis et al., 2009), and vision (Miyawaki et al., 2008). However, interpretation of the models obtained using a multivariate analysis can be hard due to the fact that different models are obtained for individual subjects. For example, when analyzing K separately acquired datasets, K sets of model parameters will be obtained which may or may not show a common pattern. In some sense, we are in need of a second-level analysis such that we can draw inferences on the group level, as in the conventional analysis of neuroimaging data using the general linear model. One way to achieve this in the context of multivariate analysis is by means of multi-task </context>
</contexts>
<marker>Miyawaki, Uchida, Yamashita, Sato, Morito, Tanabe, Sadato, Kamitani, 2008</marker>
<rawString>Y. Miyawaki, H. Uchida, O. Yamashita, M. Sato, Y. Morito, H. C. Tanabe, N. Sadato, and Y. Kamitani. 2008. Visual image reconstruction from human brain activity using a combination of multiscale local image decoders. Neuron, 60(5):915–929.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Obozinski</author>
<author>B Taskar</author>
<author>M I Jordan</author>
</authors>
<title>Joint covariate selection and joint subspace selection for multiple classification problems.</title>
<date>2009</date>
<booktitle>In Statistics and Computing.</booktitle>
<publisher>Springer.</publisher>
<contexts>
<context position="18091" citStr="Obozinski et al., 2009" startWordPosition="2914" endWordPosition="2917">ct that in our experiment the subjects were viewing picture-text pairs in contrast to only text in (Just et al., 2010). 5 Discussion We have demonstrated that Bayesian multi-task learning can be realized through Bayesian logistic regression when using a multivariate Laplace prior that couples features between multiple datasets. This approach has not been used before and yields promising results. As such it complements other Bayesian and non-Bayesian approaches to multitask learning such as those reported in (Yu et al., 2005; Dunson et al., 2008; Argyriou et al., 2008; van Gerven et al., 2009; Obozinski et al., 2009; Rustandi et al., 2009). Results show that many category pairs can be classified based on the average activation of regions 0.8 0.75 0.7 0.65 0.6 0.55 0.5 1 2 3 4 5 6 7 8 9 standard multi-task 14 1 2 3 4 5 6 Subject 7 8 9 1 2 3 4 5 6 Subject 7 8 9 Strong coupling (s = 100) No coupling (s = 0) A C No coupling (s = 0) 1 2 3 4 5 6 7 8 9 B Weak coupling (s = 1) 0.9 0.5 0.98 0.92 0.86 0 AAL brain region 7 6 5 4 3 2 1 0 _1 _2 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 Subject Subject Figure 4: Correlation matrices for subject-specific models for standard classification (A) and multi-task</context>
</contexts>
<marker>Obozinski, Taskar, Jordan, 2009</marker>
<rawString>G. Obozinski, B. Taskar, and M. I. Jordan. 2009. Joint covariate selection and joint subspace selection for multiple classification problems. In Statistics and Computing. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palatucci</author>
<author>D Pomerleau</author>
<author>G Hinton</author>
<author>T Mitchell</author>
</authors>
<title>Zero-shot learning with semantic output codes. In</title>
<date>2009</date>
<booktitle>Neural Information Processing Systems,</booktitle>
<pages>1410--1418</pages>
<editor>Y. Bengio, D. Schuurmans, J. Lafferty, C. K. I. Williams, and A. Culotta, editors,</editor>
<marker>Palatucci, Pomerleau, Hinton, Mitchell, 2009</marker>
<rawString>M. Palatucci, D. Pomerleau, G. Hinton, and T. Mitchell. 2009. Zero-shot learning with semantic output codes. In Y. Bengio, D. Schuurmans, J. Lafferty, C. K. I. Williams, and A. Culotta, editors, Neural Information Processing Systems, pages 1410–1418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Phillips</author>
<author>U Noppeney</author>
<author>G W Humphreys</author>
<author>C J Price</author>
</authors>
<title>Can segregation within the semantic system account for category-specific deficits?</title>
<date>2002</date>
<journal>Brain,</journal>
<volume>125</volume>
<issue>9</issue>
<contexts>
<context position="16395" citStr="Phillips et al., 2002" startWordPosition="2647" endWordPosition="2650">ubjects. Our algorithm identifies identical cortical locations as being important in solving the classification problem for all individuals within the group. The identified regions agree with previously published results on concept encoding. For example, the regions which were considered important for the category pair building-tool (Fig. 5) are almost indistinguishable from those described in a recent study by Shinkareva et al. (2008). These are regions that are traditionally considered to be involved in reading, objects meaning retrieval and visual semantic tasks (Vandenberghe et al., 1996; Phillips et al., 2002). Strikingly, very similar regions were picked by the classifier for the other two category pairs with high classification accuracy, i.e., building-kitchen and buildpart-tool. This fact brings back the issue about the semantic factors relevant for the discrimination of the entities from these categories. The factors shelter, manipulation and eating are associated with the concepts from the first three addressed category pairs. The locations of voxel clusters associated with the semantic factors in (Just et al., 2010) match the brain regions that contributed to the classification for the three </context>
</contexts>
<marker>Phillips, Noppeney, Humphreys, Price, 2002</marker>
<rawString>J. A. Phillips, U. Noppeney, G. W. Humphreys, and C. J. Price. 2002. Can segregation within the semantic system account for category-specific deficits? Brain, 125(9):2067–2080.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Rustandi</author>
<author>M A Just</author>
<author>T M Mitchell</author>
</authors>
<title>Integrating multiple-study multiple-subject fMRI datasets using canonical correlation analysis.</title>
<date>2009</date>
<booktitle>In Proceedings of the MICCAI 2009 Workshop.</booktitle>
<contexts>
<context position="2410" citStr="Rustandi et al., 2009" startWordPosition="371" endWordPosition="374"> a common pattern. In some sense, we are in need of a second-level analysis such that we can draw inferences on the group level, as in the conventional analysis of neuroimaging data using the general linear model. One way to achieve this in the context of multivariate analysis is by means of multi-task learning, a special case of transfer learning (Thrun, 1996) where model parameters for different tasks (datasets) are estimated simultaneously and no longer assumed to be independent (Caruana, 1997). In an fMRI context, multi-task learning has been explored using canonical correlation analysis (Rustandi et al., 2009). In a Bayesian setting, multi-task learning is typically realized by assuming a hierarchical Bayesian framework where shared prior distributions condition task-specific parameters (Gelman et al., 1995). In this paper, we explore a new Bayesian approach to multi-task learning in the context of concept classification; i.e., the prediction of the semantic category of concrete nouns from BOLD response. Effectively, we are using a shared prior to induce parameter shrinkage. We show that Bayesian multi-task learning leads to more interpretable models, thereby facilitating the interpretation of the </context>
<context position="18115" citStr="Rustandi et al., 2009" startWordPosition="2918" endWordPosition="2921">t the subjects were viewing picture-text pairs in contrast to only text in (Just et al., 2010). 5 Discussion We have demonstrated that Bayesian multi-task learning can be realized through Bayesian logistic regression when using a multivariate Laplace prior that couples features between multiple datasets. This approach has not been used before and yields promising results. As such it complements other Bayesian and non-Bayesian approaches to multitask learning such as those reported in (Yu et al., 2005; Dunson et al., 2008; Argyriou et al., 2008; van Gerven et al., 2009; Obozinski et al., 2009; Rustandi et al., 2009). Results show that many category pairs can be classified based on the average activation of regions 0.8 0.75 0.7 0.65 0.6 0.55 0.5 1 2 3 4 5 6 7 8 9 standard multi-task 14 1 2 3 4 5 6 Subject 7 8 9 1 2 3 4 5 6 Subject 7 8 9 Strong coupling (s = 100) No coupling (s = 0) A C No coupling (s = 0) 1 2 3 4 5 6 7 8 9 B Weak coupling (s = 1) 0.9 0.5 0.98 0.92 0.86 0 AAL brain region 7 6 5 4 3 2 1 0 _1 _2 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 Subject Subject Figure 4: Correlation matrices for subject-specific models for standard classification (A) and multi-task learning (B) with weak </context>
</contexts>
<marker>Rustandi, Just, Mitchell, 2009</marker>
<rawString>I. Rustandi, M. A. Just, and T. M. Mitchell. 2009. Integrating multiple-study multiple-subject fMRI datasets using canonical correlation analysis. In Proceedings of the MICCAI 2009 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S V Shinkareva</author>
<author>R A Mason</author>
<author>V L Malave</author>
<author>W Wang</author>
<author>T M Mitchell</author>
</authors>
<title>Using fMRI brain activation to identify cognitive states associated with perception of tools and dwellings.</title>
<date>2008</date>
<journal>PLoS ONE,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="16212" citStr="Shinkareva et al. (2008)" startWordPosition="2619" endWordPosition="2622">i-task learning tracks down the common task-specific activations while ignoring background noise. Our study demonstrates that Bayesian multi-task learning allows generalization across subjects. Our algorithm identifies identical cortical locations as being important in solving the classification problem for all individuals within the group. The identified regions agree with previously published results on concept encoding. For example, the regions which were considered important for the category pair building-tool (Fig. 5) are almost indistinguishable from those described in a recent study by Shinkareva et al. (2008). These are regions that are traditionally considered to be involved in reading, objects meaning retrieval and visual semantic tasks (Vandenberghe et al., 1996; Phillips et al., 2002). Strikingly, very similar regions were picked by the classifier for the other two category pairs with high classification accuracy, i.e., building-kitchen and buildpart-tool. This fact brings back the issue about the semantic factors relevant for the discrimination of the entities from these categories. The factors shelter, manipulation and eating are associated with the concepts from the first three addressed ca</context>
<context position="19610" citStr="Shinkareva et al., 2008" startWordPosition="3210" endWordPosition="3213">an those which would have been obtained using single-voxel activations, it is interesting in its own right that the activation in just 116 predefined regions still allows concept decoding. However, it remains an open question to what extent classifiability truly reflects semantic processing instead of sensory processing of words and/or pictures. The coupling induced by multi-task learning leads to interpretable models when using auxiliary variable variance as a measure of importance. The obtained models for the pairs which were easiest to classify corresponded well to the results reported in (Shinkareva et al., 2008) and mapped nicely onto the semantic features shelter, manipulation and eating identified in (Just et al., 2010). In this paper we used the multivariate Laplace prior to induce a coupling between tasks. It is straightforward to combine this with other coupling constraints such as coupling nearby regions within subjects. Our algorithm also does not preclude multi-task learning on thousands of voxels. Computation time depends on the number of non-zeros in the structure matrix R and matrices containing hundreds of thousands of non-zero elements are still manageable with computation time being in </context>
</contexts>
<marker>Shinkareva, Mason, Malave, Wang, Mitchell, 2008</marker>
<rawString>S. V. Shinkareva, R. A. Mason, V. L. Malave, W. Wang, and T. M. Mitchell. 2008. Using fMRI brain activation to identify cognitive states associated with perception of tools and dwellings. PLoS ONE, 3(1):e1394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Thrun</author>
</authors>
<title>Is learning the n-th thing any easier than learning the first?</title>
<date>1996</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>640--646</pages>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="2151" citStr="Thrun, 1996" startWordPosition="334" endWordPosition="335">d using a multivariate analysis can be hard due to the fact that different models are obtained for individual subjects. For example, when analyzing K separately acquired datasets, K sets of model parameters will be obtained which may or may not show a common pattern. In some sense, we are in need of a second-level analysis such that we can draw inferences on the group level, as in the conventional analysis of neuroimaging data using the general linear model. One way to achieve this in the context of multivariate analysis is by means of multi-task learning, a special case of transfer learning (Thrun, 1996) where model parameters for different tasks (datasets) are estimated simultaneously and no longer assumed to be independent (Caruana, 1997). In an fMRI context, multi-task learning has been explored using canonical correlation analysis (Rustandi et al., 2009). In a Bayesian setting, multi-task learning is typically realized by assuming a hierarchical Bayesian framework where shared prior distributions condition task-specific parameters (Gelman et al., 1995). In this paper, we explore a new Bayesian approach to multi-task learning in the context of concept classification; i.e., the prediction o</context>
</contexts>
<marker>Thrun, 1996</marker>
<rawString>S. Thrun. 1996. Is learning the n-th thing any easier than learning the first? In Advances in Neural Information Processing Systems, pages 640–646. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Tzourio-Mazoyer</author>
<author>B Landeau</author>
<author>D Papathanassiou</author>
<author>F Crivello</author>
<author>O Etard</author>
<author>N Delcroix</author>
<author>B Mazoyer</author>
<author>M Joliot</author>
</authors>
<title>Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain.</title>
<date>2002</date>
<journal>Neuroimage,</journal>
<volume>15</volume>
<issue>1</issue>
<contexts>
<context position="9503" citStr="Tzourio-Mazoyer et al., 2002" startWordPosition="1573" endWordPosition="1576">e effect of multi-task learning, results were obtained when assuming no coupling between datasets (s = 0) as well as when assuming a very strong coupling between datasets (s = 100). The scale parameter was fixed to 0 = 1. In order to allow the coupling to be made, all datasets are required to contain the same features. One way to achieve this is to warp the data for each subject from native space to normalized space and to perform the multi-task learning in normalized space. Here, in contrast, we computed the average activation in 116 predefined regions of interest (ROIs) using the AAL atlas (Tzourio-Mazoyer et al., 2002). ROI activations were used as input to the classifier. This considerably reduces computational overhead since we need to couple just 116 ROIs instead of approximately 20000 voxels between all nine subjects.3 Furthermore, it facilitates interpretation since results can be analyzed at the ROI level instead of at the single voxel level. Of course, this presupposes that category-specific information is captured by the average activation in predefined ROIs, which is an important open question we set out to answer with our experiments. 4 Results 4.1 Classification of category pairs We achieved good</context>
</contexts>
<marker>Tzourio-Mazoyer, Landeau, Papathanassiou, Crivello, Etard, Delcroix, Mazoyer, Joliot, 2002</marker>
<rawString>N. Tzourio-Mazoyer, B. Landeau, D. Papathanassiou, F. Crivello, O. Etard, N. Delcroix, B. Mazoyer, and M. Joliot. 2002. Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain. Neuroimage, 15(1):273–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A J van Gerven</author>
<author>C Hesse</author>
<author>O Jensen</author>
<author>T Heskes</author>
</authors>
<title>Interpreting single trial data using groupwise regularisation.</title>
<date>2009</date>
<journal>NeuroImage,</journal>
<pages>46--665</pages>
<marker>van Gerven, Hesse, Jensen, Heskes, 2009</marker>
<rawString>M. A. J. van Gerven, C. Hesse, O. Jensen, and T. Heskes. 2009. Interpreting single trial data using groupwise regularisation. NeuroImage, 46:665–676.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A J van Gerven</author>
<author>B Cseke</author>
<author>F P de Lange</author>
<author>T Heskes</author>
</authors>
<title>Efficient Bayesian multivariate fMRI analysis using a sparsifying spatio-temporal prior.</title>
<date>2010</date>
<journal>NeuroImage,</journal>
<volume>50</volume>
<issue>1</issue>
<marker>van Gerven, Cseke, de Lange, Heskes, 2010</marker>
<rawString>M. A. J. van Gerven, B. Cseke, F. P. de Lange, and T. Heskes. 2010. Efficient Bayesian multivariate fMRI analysis using a sparsifying spatio-temporal prior. NeuroImage, 50(1):150–161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Vandenberghe</author>
<author>C Price</author>
<author>R Wise</author>
<author>O Josephs</author>
<author>R S Frackowiak</author>
</authors>
<title>Functional anatomy of a common semantic system for words and pictures.</title>
<date>1996</date>
<journal>Nature,</journal>
<volume>383</volume>
<issue>6597</issue>
<contexts>
<context position="16371" citStr="Vandenberghe et al., 1996" startWordPosition="2643" endWordPosition="2646">ows generalization across subjects. Our algorithm identifies identical cortical locations as being important in solving the classification problem for all individuals within the group. The identified regions agree with previously published results on concept encoding. For example, the regions which were considered important for the category pair building-tool (Fig. 5) are almost indistinguishable from those described in a recent study by Shinkareva et al. (2008). These are regions that are traditionally considered to be involved in reading, objects meaning retrieval and visual semantic tasks (Vandenberghe et al., 1996; Phillips et al., 2002). Strikingly, very similar regions were picked by the classifier for the other two category pairs with high classification accuracy, i.e., building-kitchen and buildpart-tool. This fact brings back the issue about the semantic factors relevant for the discrimination of the entities from these categories. The factors shelter, manipulation and eating are associated with the concepts from the first three addressed category pairs. The locations of voxel clusters associated with the semantic factors in (Just et al., 2010) match the brain regions that contributed to the class</context>
</contexts>
<marker>Vandenberghe, Price, Wise, Josephs, Frackowiak, 1996</marker>
<rawString>R. Vandenberghe, C. Price, R. Wise, O. Josephs, and R. S. Frackowiak. 1996. Functional anatomy of a common semantic system for words and pictures. Nature, 383(6597):254–256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yu</author>
<author>V Tresp</author>
<author>A Schwaighofer</author>
</authors>
<title>Learning Gaussian processes from multiple tasks.</title>
<date>2005</date>
<booktitle>In International Conference on Machine Learning,</booktitle>
<pages>1012--1019</pages>
<contexts>
<context position="17998" citStr="Yu et al., 2005" startWordPosition="2897" endWordPosition="2900">he occipital lobes detected exclusively in our experiment might be explained by the fact that in our experiment the subjects were viewing picture-text pairs in contrast to only text in (Just et al., 2010). 5 Discussion We have demonstrated that Bayesian multi-task learning can be realized through Bayesian logistic regression when using a multivariate Laplace prior that couples features between multiple datasets. This approach has not been used before and yields promising results. As such it complements other Bayesian and non-Bayesian approaches to multitask learning such as those reported in (Yu et al., 2005; Dunson et al., 2008; Argyriou et al., 2008; van Gerven et al., 2009; Obozinski et al., 2009; Rustandi et al., 2009). Results show that many category pairs can be classified based on the average activation of regions 0.8 0.75 0.7 0.65 0.6 0.55 0.5 1 2 3 4 5 6 7 8 9 standard multi-task 14 1 2 3 4 5 6 Subject 7 8 9 1 2 3 4 5 6 Subject 7 8 9 Strong coupling (s = 100) No coupling (s = 0) A C No coupling (s = 0) 1 2 3 4 5 6 7 8 9 B Weak coupling (s = 1) 0.9 0.5 0.98 0.92 0.86 0 AAL brain region 7 6 5 4 3 2 1 0 _1 _2 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 1 2 3 4 5 6 7 8 9 Subject Subject Figure 4: Co</context>
</contexts>
<marker>Yu, Tresp, Schwaighofer, 2005</marker>
<rawString>K. Yu, V. Tresp, and A. Schwaighofer. 2005. Learning Gaussian processes from multiple tasks. In International Conference on Machine Learning, pages 1012– 1019.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>