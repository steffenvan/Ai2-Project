<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.010277">
<title confidence="0.983728">
CPH: Sentiment analysis of Figurative Language on Twitter #easypeasy #not
</title>
<author confidence="0.997963">
Sarah McGillion H´ector Martinez Alonso Barbara Plank
</author>
<affiliation confidence="0.999615">
University of Copenhagen, Njalsgade 140, 2300 Copenhagen S, Denmark
</affiliation>
<email confidence="0.984756">
zhg159@alumni.ku.dk,alonso@hum.ku.dk,bplank@cst.dk
</email>
<sectionHeader confidence="0.99361" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999245">
This paper describes the details of our sys-
tem submitted to the SemEval 2015 shared
task on sentiment analysis of figurative lan-
guage on Twitter. We tackle the problem as
regression task and combine several base sys-
tems using stacked generalization (Wolpert,
1992). An initial analysis revealed that the
data is heavily biased, and a general sentiment
analysis system (GSA) performs poorly on
it. However, GSA proved helpful on the test
data, which contains an estimated 25% non-
figurative tweets. Our best system, a stacking
system with backoff to GSA, ranked 4th on the
final test data (Cosine 0.661, MSE 3.404).1
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999038">
Sentiment analysis (SA) is the task of determining
the sentiment of a given piece of text. The ampli-
tude of user-generated content produced every day
raises the importance of accurate automatic senti-
ment analysis, for applications ranging from, e.g.,
reputation analysis (Amig´o et al., 2013) to election
results prediction (Tjong Kim Sang and Bos, 2012).
However, figurative language is pervasive in user-
generated content, and figures of speech like irony,
sarcasm and metaphors impose relevant challenges
for a sentiment analysis system usually trained on
literal meanings. For instance, consider the fol-
lowing example:2 @CIA We hear you’re looking
for sentiment analysis to detect sarcasm in Tweets.
That’ll be easy! #SLA2014 #irony. Irony or sarcasm
</bodyText>
<footnote confidence="0.98988975">
1After submission time we discovered a bug in ST2,which
means that the results on the official website are of the GSA and
not of the stacking system with backoff.
2From the training data, label: -1.24; GSA prediction: +5.
</footnote>
<bodyText confidence="0.999718904761905">
does not result always in the exact opposite senti-
ment and therefore it is not as simple as just invert-
ing the scores from a general SA system. Only few
studies have attempted SA on figurative language so
far (Reyes and Rosso, 2012; Reyes et al., 2013).
The prediction of a fine-grained sentiment score
(between -5 and 5) for a tweet poses a series of chal-
lenges. First of all, accurate language technology
on tweets is hard due to sample bias, i.e., collections
of tweets are inherently biased towards the particular
time (or way, cf. §2) they were collected (Eisenstein,
2013; Hovy et al., 2014). Secondly, the notion of
figurativeness (or its complementary notion of liter-
ality) does not have a strong definition, let alone do
irony, sarcasm, or satire. As pointed out by Reyes
and Rosso (2012), “there is not a clear distinction
about the boundaries among these terms”. Yet alone
attaching a fine-grained score is far from straight-
forward. In fact, the gold standard consists of the
average score assigned by humans through crowd-
sourcing reflecting an uncertainty in ground truth.
</bodyText>
<sectionHeader confidence="0.922823" genericHeader="method">
2 Data Analysis
</sectionHeader>
<bodyText confidence="0.9999555">
The goal of the initial data exploration was to inves-
tigate the amount of non-figurativeness in the train
and trial data. Our analysis revealed that 99% of
the training data could be classified using a simple
heuristic: a regular expression decision list, here-
after called Tweet Label System (TLS), to split the
training data into different key-phrase subgroups.
The system searches for the expression in a tweet
and then assigns a label in a cascade fashion fol-
lowing the order in Table 2, which lists the 14 pos-
sible label types (plus NONE), their associated ex-
pressions along with the support for each category
</bodyText>
<page confidence="0.986503">
699
</page>
<bodyText confidence="0.8513715">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 699–703,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
in the training data. Table 1 shows that only a small
fraction of the train and trial data could not be asso-
ciated to a subgroup and it can be seen that the final
test data was estimated to have a very different dis-
tribution with 25% of tweets presumably containing
literal language use.
</bodyText>
<table confidence="0.997179666666667">
Dataset Train Trial Test
Instances 7988 920 4000
% Non-figurative 1% 7% 25%
</table>
<tableCaption confidence="0.9985435">
Table 1: Retrieved instances in each data set and esti-
mated amount of non-figurativeness.
</tableCaption>
<bodyText confidence="0.994494153846154">
Since there are obvious subgroups in the data, our
hypothesis is that this fact can be used to construct a
more informed baseline. In fact (§ 4.1), simply pre-
dicting the mean per subgroup pushed the constant
mean baseline performance considerably (from 0.73
to 0.81 Cosine, compared to random 0.59).
Figure 1 plots predicted scores (ridge model, §3.1)
of three subgroups against the gold scores on the
trial data. It can be seen that certain subgroups have
similar behaviour, ‘sarcasm’ has a generally nega-
tive cloud and the model performs well in predict-
ing these values, while other groups such as ‘SoTo-
Speak’ have more intra-group variance.
</bodyText>
<figure confidence="0.539542555555556">
Label Expression Support
SoToSpeak so to speak 135
Proverbial proverbial 22
JustKidding #justkidding -
Literally literally 344
Virtually virtually 8
YeahRight #yeahright 47
OhYouMust Oh.*you 2
asXas as .* as 83
</figure>
<tableCaption confidence="0.979909">
Table 2: Tweet Label Type and Expression.
</tableCaption>
<subsectionHeader confidence="0.82384">
The Effect of a General Sentiment System
</subsectionHeader>
<bodyText confidence="0.9999805">
The data for this task is very different from data that
most lexicon-based or general sentiment-analysis
models fare best on. In fact, running a general sen-
timent classifier (GSA) described in Elming et al.
(2014) on the trial data showed that its predictions
are actually slightly anti-correlated with the gold
standard scores for the Tweets in this task (cosine
similarity score of -0.08 and MSE of 18.62). We
exploited these anti-correlated results as features for
our stacking systems (cf. § 3.2). Figure 2 shows the
</bodyText>
<figureCaption confidence="0.998558">
Figure 1: Label Plots for RR predictions.
</figureCaption>
<bodyText confidence="0.998015">
distributions of the gold scores and GSA predictions
for the trial data. It shows that the gold distribution
is skewed with regards to the number of negative in-
stances to positives, while the GSA predicts more
positive sentiment.
</bodyText>
<figureCaption confidence="0.964581">
Figure 2: Distribution of Gold Scores and GSA Predic-
tions for Trial Data.
</figureCaption>
<sectionHeader confidence="0.986935" genericHeader="method">
3 System Description
</sectionHeader>
<bodyText confidence="0.999497">
We approach the task (Ghosh et al., 2015) as a re-
gression task (cf. §4.4), combining several systems
using stacking (§ 3.2), and relying on features with-
out POS, lemma or explicit use of lexicons, cf. § 3.3.
</bodyText>
<figure confidence="0.999537047058824">
−5.0 −2.5 0.0 2.5 5.0
gold
ridge
−2
−4
2
0
●
●
●
●
●
●
●
●
●
●
●
●
●
● ●
● ●
● ●
● ●
●
●
●
●
●
●
●
● ●
●
● ● ●
●
●
●
● ●
●
●
●
●
●
●
●
●
● ●
●
●
●
●
●
●
● ●
●
●
●
●
●
●
●
●
●
●
●
● ●
●
●
●
●
●
●
●
label
● asXas
sarcasm
sotospeak
Label Expression Support
Sarcasm #sarcas 2139
Irony #iron(y ic) 1444
Not #not 3601
Not2 not 29
about about 8
Oh oh 3
NONE - 92
</figure>
<page confidence="0.930528">
700
</page>
<subsectionHeader confidence="0.998948">
3.1 Single Systems
</subsectionHeader>
<bodyText confidence="0.995581888888889">
Ridge Regression (RR) A standard supervised
ridge regression model with default parameters.3
PCA GMM Ridge Regression (GMM) A ridge
regression model trained on the output of unsu-
pervised induced features, i.e., a Gaussian Mixture
Models (GMM) trained on PCA of word n-grams.
PCA was used to reduce the dimensionality to 100,
and GMM under the assumption that the data was
sampled from different distributions of figurative
language, k Gaussians were assumed (here k = 12).
Embeddings with Bayesian Ridge (EMBD) A
Bayesian Ridge Regressor learner with default pa-
rameters trained on only word embeddings. A cor-
pus was build from the training data and an in-house
Tweet collection sampled with the expressions from
the TLS. This resulted in a total of 3.7 million tweets
and 67 million tokens. For details on how the word
embeddings were built see §3.3.
</bodyText>
<subsectionHeader confidence="0.990584">
3.2 Ensembles
</subsectionHeader>
<bodyText confidence="0.999496533333333">
We developed two stacking systems (Wolpert,
1992), Stacking System 1 (ST1) and Stacking System
2: Stacking with Backoff (ST2). The systems used
for these are shown in Table 3 and the Meta Learner
used for both stacking systems is Linear Regression.
The systems used in ST1 and ST2 are not the only
differences between the two. ST2 uses the TLS to
identify the subgroup that each tweet belongs to. For
any tweet with the NONE subgrouping, the system
would back off to the predictions from the GSA. We
built ST2 as a system that is not limited to sentiment
analysis for a small subsection of language, the phe-
nomenon of figurative language, but is applicable in
situations covering many types of tweets including
those in which literal language is used.
</bodyText>
<table confidence="0.959901">
Single System / Stacking System ST1 ST2
RR X X
GMM X
EMBD X
GSA X X
</table>
<tableCaption confidence="0.992018">
Table 3: Systems in Ensemble Setups.
</tableCaption>
<footnote confidence="0.902268">
3http://scikit-learn.org/
</footnote>
<subsectionHeader confidence="0.936924">
3.3 Features
</subsectionHeader>
<bodyText confidence="0.999984875">
This section describe the features we used for the
models in §3.1. Table 4 indicates the type of fea-
tures used for the single models. Punctuation was
kept as its own lexical item and we found removing
stopwords and normalizing usernames to ’@USER’
increased performance and as such the preprocess-
ing methods are the same across the models. Fea-
tures were set on the trial data.
</bodyText>
<listItem confidence="0.846132823529412">
1. Word N-Grams Systems use different n-grams
as features. In RR counts of 1 and 5 word
grams, in GMM binary presence of 1,2, and 3
word grams.
2. Uppercase Words Counts of the numbers of
word in a Tweet with all uppercase letters.
3. Punctuation Contiguous sequences of ques-
tion, exclamation, and question and exclama-
tion marks.
4. TLS Label The subgrouping label from TLS.
5. Word Embeddings Parameters for word em-
beddings:4 100 dimensions, 5 minimum occur-
rences for a type to be included in the model, 5
word context window and 10-example negative
sampling. Each tweet was represented by 100
features that represented the average of all the
embeddings of the content words in the tweet.
</listItem>
<table confidence="0.999554666666667">
Features/Systems RR GMM EMBD
Word N-grams X X
Uppercase X
Punctuations X
TLS Label X
Word Embeddings X
</table>
<tableCaption confidence="0.997177">
Table 4: Features used in Single Models.
</tableCaption>
<sectionHeader confidence="0.999848" genericHeader="evaluation">
4 Results
</sectionHeader>
<subsectionHeader confidence="0.999749">
4.1 Constant Baselines &amp; Single Systems
</subsectionHeader>
<bodyText confidence="0.999982333333333">
We implemented the Mean, Mode, Median, Random
and TSL (§2) baseline systems. TSL is the hardest
baseline, and RR is the only system that beats it.
</bodyText>
<subsectionHeader confidence="0.971892">
4.2 Results Stacking Systems
</subsectionHeader>
<bodyText confidence="0.98889">
The performance of the stacking systems on the trial
data can be seen below in Table 6. ST2 did not per-
form well on the trial data although a reason for this
</bodyText>
<footnote confidence="0.980165">
4https://code.google.com/p/word2vec/
</footnote>
<page confidence="0.985766">
701
</page>
<table confidence="0.999567333333333">
System Cosine MSE
TLS 0.81 2.34
Mean 0.73 3.13
Mode 0.73 3.13
Median 0.73 3.31
Random 0.59 5.17
RR 0.88 1.60
GMM 0.79 2.55
EMB 0.78 2.64
</table>
<tableCaption confidence="0.995117">
Table 5: Baseline and Single Systems On Trial Data.
</tableCaption>
<bodyText confidence="0.611552">
is that only 7% of the trial data was found as not
belonging to a known figurative type of tweet.
</bodyText>
<table confidence="0.983689333333333">
System Cosine MSE
ST1 0.86 1.88
ST2 0.79 2.57
</table>
<tableCaption confidence="0.988978">
Table 6: Stacking Model Results on Trial Data.
</tableCaption>
<table confidence="0.9995842">
System Overall Sarcasm Irony Metaphor Other
RR 0.625 0.897 0.886 0.325 0.218
ST1 0.623 0.900 0.903 0.308 0.226
ST2 0.661 0.875 0.872 0.453 0.584
CLAC 0.758 0.892 0.904 0.655 0.584
</table>
<tableCaption confidence="0.999766">
Table 8: Cosine Test Results Breakdown.
</tableCaption>
<subsectionHeader confidence="0.991832">
4.4 The Case for Regression
</subsectionHeader>
<bodyText confidence="0.999882181818182">
Regression is less usual in NLP than classification.
However for this data, it is desirable to use regres-
sion, because it incorporates the ordered relation be-
tween the labels, instead of treating them as orthogo-
nal. It also keeps the decimal precision in the target
variable when training, which is relevant when the
target variable is the result of an average between
several annotations. We ran classification experi-
ments for this task but found that the best classi-
fication system’s6 performance (Cosine 0.82, MSE
2.51) is still far from the RR model (0.88,1.60).
</bodyText>
<sectionHeader confidence="0.999898" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<subsectionHeader confidence="0.999731">
4.3 Final Results
</subsectionHeader>
<bodyText confidence="0.999870266666667">
Three models were submitted for final evaluation on
the test data. The three models were RR, ST1, and
ST2. For the final results we scaled back values out-
side the range [-5,5] to the nearest whole number in
range. Tables 7 and 8 show the results for our sys-
tems on the final dataset and the performance of the
overall winning system for the task (CLAC) . Table
7 shows the overall cosine similarity and MSE for
the systems on the test data and Table 8 shows the
breakdown of the cosine similarity for the systems
on the different parts of language. It is interesting
to note that the performance of ST2 on the ‘Other’
type of language is identical as the performance for
CLAC, this is also the best cosine similarity score
‘Other’ out of all submissions.
</bodyText>
<table confidence="0.9885602">
System Test Cosine Test MSE
RR 0.625 3.079
ST1 0.623 3.078
ST2 0.661 3.404
CLAC 0.758 2.117
</table>
<tableCaption confidence="0.998944">
Table 7: Submission System Test Results.5
</tableCaption>
<bodyText confidence="0.999982529411765">
We tested three systems for their abilities to analyse
sentiment on figurative language from Twitter. Our
experiments showed that a general SA system
trained on literal Twitter language was highly anti-
correlated with gold scores for figurative tweets. We
found that for certain figurative types, sarcasm and
irony, our system’s predictions for these phenom-
ena faired well. Our system did not explicitly use
a lexicon to define the sentiment of a tweet, but
instead used machine learning and strictly corpus-
based features (no POS or lemma) to place us 4th
in the task. More effort may be needed to discrimi-
nate metaphorical from literal tweets to build a more
robust system, although, even for humans the senti-
ment of tweets is hard to judge. This can be seen
from the data where a number of tweets were re-
peated, but did not always share the same gold score.
</bodyText>
<footnote confidence="0.990185">
5The numbers in bold indicate the best performance among
our systems, underlined indicates the best performance between
any of our systems and the winning system.
6Decision Tree with 7 classes and using the minimum score
for instances in the classes in the training data to convert for
class labels to scores.
</footnote>
<page confidence="0.996306">
702
</page>
<sectionHeader confidence="0.995821" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999788314285714">
Enrique Amig´o, Jorge Carrillo De Albornoz, Irina
Chugur, Adolfo Corujo, Julio Gonzalo, Tamara
Martin, Edgar Meij, Maarten De Rijke, and Dami-
ano Spina. 2013. Overview of replab 2013: Evaluat-
ing online reputation monitoring systems. In Informa-
tion Access Evaluation. Multilinguality, Multimodal-
ity, and Visualization, pages 333–352. Springer.
Jacob Eisenstein. 2013. What to do about bad language
on the internet. In NAACL.
Jakob Elming, Barbara Plank, and Dirk Hovy. 2014. Ro-
bust cross-domain sentiment analysis for low-resource
languages. In Proceedings of the 5th Workshop on
Computational Approaches to Subjectivity, Sentiment
and Social Media Analysis.
A. Ghosh, G. Li, T. Veale, P. Rosso, E. Shutova, A. Reyes,
and J. Barnden. 2015. Semeval-2015 task 11: Senti-
ment analysis of figurative language in twitter. In Int.
Workshop on Semantic Evaluation (SemEval-2015).
Dirk Hovy, Barbara Plank, and Anders Søgaard. 2014.
When POS datasets don’t add up: Combatting sample
bias. In LREC.
Antonio Reyes and Paolo Rosso. 2012. Making objec-
tive decisions from subjective data: Detecting irony
in customer reviews. Decision Support Systems,
53(4):754–760.
Antonio Reyes, Paolo Rosso, and Tony Veale. 2013. A
multidimensional approach for detecting irony in twit-
ter. Language Resources and Evaluation, 47(1):239–
268.
Erik Tjong Kim Sang and Johan Bos. 2012. Predicting
the 2011 dutch senate election results with twitter. In
Proceedings of the Workshop on Semantic Analysis in
Social Media.
David H Wolpert. 1992. Stacked generalization. Neural
networks, 5(2):241–259.
</reference>
<page confidence="0.998994">
703
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.303788">
<title confidence="0.99294">CPH: Sentiment analysis of Figurative Language on Twitter #easypeasy #not</title>
<author confidence="0.999863">Sarah McGillion H´ector Martinez Alonso Barbara</author>
<affiliation confidence="0.998557">University of Copenhagen, Njalsgade 140, 2300 Copenhagen S,</affiliation>
<email confidence="0.87668">zhg159@alumni.ku.dk,alonso@hum.ku.dk,bplank@cst.dk</email>
<abstract confidence="0.954419666666667">This paper describes the details of our system submitted to the SemEval 2015 shared task on sentiment analysis of figurative language on Twitter. We tackle the problem as regression task and combine several base systems using stacked generalization (Wolpert, 1992). An initial analysis revealed that the data is heavily biased, and a general sentiment analysis system (GSA) performs poorly on it. However, GSA proved helpful on the test data, which contains an estimated 25% nonfigurative tweets. Our best system, a stacking system with backoff to GSA, ranked 4th on the test data (Cosine 0.661, MSE</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Adolfo Corujo Chugur</author>
<author>Julio Gonzalo</author>
<author>Tamara Martin</author>
<author>Edgar Meij</author>
<author>Maarten De Rijke</author>
<author>Damiano Spina</author>
</authors>
<title>Overview of replab 2013: Evaluating online reputation monitoring systems.</title>
<date>2013</date>
<booktitle>In Information Access Evaluation. Multilinguality, Multimodality, and Visualization,</booktitle>
<pages>333--352</pages>
<publisher>Springer.</publisher>
<marker>Chugur, Gonzalo, Martin, Meij, De Rijke, Spina, 2013</marker>
<rawString>Chugur, Adolfo Corujo, Julio Gonzalo, Tamara Martin, Edgar Meij, Maarten De Rijke, and Damiano Spina. 2013. Overview of replab 2013: Evaluating online reputation monitoring systems. In Information Access Evaluation. Multilinguality, Multimodality, and Visualization, pages 333–352. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
</authors>
<title>What to do about bad language on the internet.</title>
<date>2013</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="2439" citStr="Eisenstein, 2013" startWordPosition="382" endWordPosition="383">ata, label: -1.24; GSA prediction: +5. does not result always in the exact opposite sentiment and therefore it is not as simple as just inverting the scores from a general SA system. Only few studies have attempted SA on figurative language so far (Reyes and Rosso, 2012; Reyes et al., 2013). The prediction of a fine-grained sentiment score (between -5 and 5) for a tweet poses a series of challenges. First of all, accurate language technology on tweets is hard due to sample bias, i.e., collections of tweets are inherently biased towards the particular time (or way, cf. §2) they were collected (Eisenstein, 2013; Hovy et al., 2014). Secondly, the notion of figurativeness (or its complementary notion of literality) does not have a strong definition, let alone do irony, sarcasm, or satire. As pointed out by Reyes and Rosso (2012), “there is not a clear distinction about the boundaries among these terms”. Yet alone attaching a fine-grained score is far from straightforward. In fact, the gold standard consists of the average score assigned by humans through crowdsourcing reflecting an uncertainty in ground truth. 2 Data Analysis The goal of the initial data exploration was to investigate the amount of no</context>
</contexts>
<marker>Eisenstein, 2013</marker>
<rawString>Jacob Eisenstein. 2013. What to do about bad language on the internet. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jakob Elming</author>
<author>Barbara Plank</author>
<author>Dirk Hovy</author>
</authors>
<title>Robust cross-domain sentiment analysis for low-resource languages.</title>
<date>2014</date>
<booktitle>In Proceedings of the 5th Workshop on Computational Approaches</booktitle>
<contexts>
<context position="5369" citStr="Elming et al. (2014)" startWordPosition="861" endWordPosition="864">performs well in predicting these values, while other groups such as ‘SoToSpeak’ have more intra-group variance. Label Expression Support SoToSpeak so to speak 135 Proverbial proverbial 22 JustKidding #justkidding - Literally literally 344 Virtually virtually 8 YeahRight #yeahright 47 OhYouMust Oh.*you 2 asXas as .* as 83 Table 2: Tweet Label Type and Expression. The Effect of a General Sentiment System The data for this task is very different from data that most lexicon-based or general sentiment-analysis models fare best on. In fact, running a general sentiment classifier (GSA) described in Elming et al. (2014) on the trial data showed that its predictions are actually slightly anti-correlated with the gold standard scores for the Tweets in this task (cosine similarity score of -0.08 and MSE of 18.62). We exploited these anti-correlated results as features for our stacking systems (cf. § 3.2). Figure 2 shows the Figure 1: Label Plots for RR predictions. distributions of the gold scores and GSA predictions for the trial data. It shows that the gold distribution is skewed with regards to the number of negative instances to positives, while the GSA predicts more positive sentiment. Figure 2: Distributi</context>
</contexts>
<marker>Elming, Plank, Hovy, 2014</marker>
<rawString>Jakob Elming, Barbara Plank, and Dirk Hovy. 2014. Robust cross-domain sentiment analysis for low-resource languages. In Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ghosh</author>
<author>G Li</author>
<author>T Veale</author>
<author>P Rosso</author>
<author>E Shutova</author>
<author>A Reyes</author>
<author>J Barnden</author>
</authors>
<title>Semeval-2015 task 11: Sentiment analysis of figurative language in twitter.</title>
<date>2015</date>
<booktitle>In Int. Workshop on Semantic Evaluation (SemEval-2015).</booktitle>
<contexts>
<context position="6085" citStr="Ghosh et al., 2015" startWordPosition="980" endWordPosition="983">d standard scores for the Tweets in this task (cosine similarity score of -0.08 and MSE of 18.62). We exploited these anti-correlated results as features for our stacking systems (cf. § 3.2). Figure 2 shows the Figure 1: Label Plots for RR predictions. distributions of the gold scores and GSA predictions for the trial data. It shows that the gold distribution is skewed with regards to the number of negative instances to positives, while the GSA predicts more positive sentiment. Figure 2: Distribution of Gold Scores and GSA Predictions for Trial Data. 3 System Description We approach the task (Ghosh et al., 2015) as a regression task (cf. §4.4), combining several systems using stacking (§ 3.2), and relying on features without POS, lemma or explicit use of lexicons, cf. § 3.3. −5.0 −2.5 0.0 2.5 5.0 gold ridge −2 −4 2 0 ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● label ● asXas sarcasm sotospeak Label Expression Support Sarcasm #sarcas 2139 Irony #iron(y ic) 1444 Not #not 3601 Not2 not 29 about about 8 Oh oh 3 NONE - 92 700 3.1 Single Systems Ridge Regression (RR) A standard supervised ridge regr</context>
</contexts>
<marker>Ghosh, Li, Veale, Rosso, Shutova, Reyes, Barnden, 2015</marker>
<rawString>A. Ghosh, G. Li, T. Veale, P. Rosso, E. Shutova, A. Reyes, and J. Barnden. 2015. Semeval-2015 task 11: Sentiment analysis of figurative language in twitter. In Int. Workshop on Semantic Evaluation (SemEval-2015).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dirk Hovy</author>
<author>Barbara Plank</author>
<author>Anders Søgaard</author>
</authors>
<title>When POS datasets don’t add up: Combatting sample bias.</title>
<date>2014</date>
<booktitle>In LREC.</booktitle>
<contexts>
<context position="2459" citStr="Hovy et al., 2014" startWordPosition="384" endWordPosition="387"> GSA prediction: +5. does not result always in the exact opposite sentiment and therefore it is not as simple as just inverting the scores from a general SA system. Only few studies have attempted SA on figurative language so far (Reyes and Rosso, 2012; Reyes et al., 2013). The prediction of a fine-grained sentiment score (between -5 and 5) for a tweet poses a series of challenges. First of all, accurate language technology on tweets is hard due to sample bias, i.e., collections of tweets are inherently biased towards the particular time (or way, cf. §2) they were collected (Eisenstein, 2013; Hovy et al., 2014). Secondly, the notion of figurativeness (or its complementary notion of literality) does not have a strong definition, let alone do irony, sarcasm, or satire. As pointed out by Reyes and Rosso (2012), “there is not a clear distinction about the boundaries among these terms”. Yet alone attaching a fine-grained score is far from straightforward. In fact, the gold standard consists of the average score assigned by humans through crowdsourcing reflecting an uncertainty in ground truth. 2 Data Analysis The goal of the initial data exploration was to investigate the amount of non-figurativeness in </context>
</contexts>
<marker>Hovy, Plank, Søgaard, 2014</marker>
<rawString>Dirk Hovy, Barbara Plank, and Anders Søgaard. 2014. When POS datasets don’t add up: Combatting sample bias. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio Reyes</author>
<author>Paolo Rosso</author>
</authors>
<title>Making objective decisions from subjective data: Detecting irony in customer reviews. Decision Support Systems,</title>
<date>2012</date>
<pages>53--4</pages>
<contexts>
<context position="2093" citStr="Reyes and Rosso, 2012" startWordPosition="322" endWordPosition="325">ce, consider the following example:2 @CIA We hear you’re looking for sentiment analysis to detect sarcasm in Tweets. That’ll be easy! #SLA2014 #irony. Irony or sarcasm 1After submission time we discovered a bug in ST2,which means that the results on the official website are of the GSA and not of the stacking system with backoff. 2From the training data, label: -1.24; GSA prediction: +5. does not result always in the exact opposite sentiment and therefore it is not as simple as just inverting the scores from a general SA system. Only few studies have attempted SA on figurative language so far (Reyes and Rosso, 2012; Reyes et al., 2013). The prediction of a fine-grained sentiment score (between -5 and 5) for a tweet poses a series of challenges. First of all, accurate language technology on tweets is hard due to sample bias, i.e., collections of tweets are inherently biased towards the particular time (or way, cf. §2) they were collected (Eisenstein, 2013; Hovy et al., 2014). Secondly, the notion of figurativeness (or its complementary notion of literality) does not have a strong definition, let alone do irony, sarcasm, or satire. As pointed out by Reyes and Rosso (2012), “there is not a clear distinctio</context>
</contexts>
<marker>Reyes, Rosso, 2012</marker>
<rawString>Antonio Reyes and Paolo Rosso. 2012. Making objective decisions from subjective data: Detecting irony in customer reviews. Decision Support Systems, 53(4):754–760.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio Reyes</author>
<author>Paolo Rosso</author>
<author>Tony Veale</author>
</authors>
<title>A multidimensional approach for detecting irony in twitter. Language Resources and Evaluation,</title>
<date>2013</date>
<volume>47</volume>
<issue>1</issue>
<pages>268</pages>
<contexts>
<context position="2114" citStr="Reyes et al., 2013" startWordPosition="326" endWordPosition="329">ing example:2 @CIA We hear you’re looking for sentiment analysis to detect sarcasm in Tweets. That’ll be easy! #SLA2014 #irony. Irony or sarcasm 1After submission time we discovered a bug in ST2,which means that the results on the official website are of the GSA and not of the stacking system with backoff. 2From the training data, label: -1.24; GSA prediction: +5. does not result always in the exact opposite sentiment and therefore it is not as simple as just inverting the scores from a general SA system. Only few studies have attempted SA on figurative language so far (Reyes and Rosso, 2012; Reyes et al., 2013). The prediction of a fine-grained sentiment score (between -5 and 5) for a tweet poses a series of challenges. First of all, accurate language technology on tweets is hard due to sample bias, i.e., collections of tweets are inherently biased towards the particular time (or way, cf. §2) they were collected (Eisenstein, 2013; Hovy et al., 2014). Secondly, the notion of figurativeness (or its complementary notion of literality) does not have a strong definition, let alone do irony, sarcasm, or satire. As pointed out by Reyes and Rosso (2012), “there is not a clear distinction about the boundarie</context>
</contexts>
<marker>Reyes, Rosso, Veale, 2013</marker>
<rawString>Antonio Reyes, Paolo Rosso, and Tony Veale. 2013. A multidimensional approach for detecting irony in twitter. Language Resources and Evaluation, 47(1):239– 268.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Tjong Kim Sang</author>
<author>Johan Bos</author>
</authors>
<title>Predicting the 2011 dutch senate election results with twitter.</title>
<date>2012</date>
<booktitle>In Proceedings of the Workshop on Semantic Analysis in Social Media.</booktitle>
<contexts>
<context position="1240" citStr="Sang and Bos, 2012" startWordPosition="182" endWordPosition="185">em (GSA) performs poorly on it. However, GSA proved helpful on the test data, which contains an estimated 25% nonfigurative tweets. Our best system, a stacking system with backoff to GSA, ranked 4th on the final test data (Cosine 0.661, MSE 3.404).1 1 Introduction Sentiment analysis (SA) is the task of determining the sentiment of a given piece of text. The amplitude of user-generated content produced every day raises the importance of accurate automatic sentiment analysis, for applications ranging from, e.g., reputation analysis (Amig´o et al., 2013) to election results prediction (Tjong Kim Sang and Bos, 2012). However, figurative language is pervasive in usergenerated content, and figures of speech like irony, sarcasm and metaphors impose relevant challenges for a sentiment analysis system usually trained on literal meanings. For instance, consider the following example:2 @CIA We hear you’re looking for sentiment analysis to detect sarcasm in Tweets. That’ll be easy! #SLA2014 #irony. Irony or sarcasm 1After submission time we discovered a bug in ST2,which means that the results on the official website are of the GSA and not of the stacking system with backoff. 2From the training data, label: -1.24</context>
</contexts>
<marker>Sang, Bos, 2012</marker>
<rawString>Erik Tjong Kim Sang and Johan Bos. 2012. Predicting the 2011 dutch senate election results with twitter. In Proceedings of the Workshop on Semantic Analysis in Social Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David H Wolpert</author>
</authors>
<date>1992</date>
<booktitle>Stacked generalization. Neural networks,</booktitle>
<pages>5--2</pages>
<contexts>
<context position="7545" citStr="Wolpert, 1992" startWordPosition="1282" endWordPosition="1283">e dimensionality to 100, and GMM under the assumption that the data was sampled from different distributions of figurative language, k Gaussians were assumed (here k = 12). Embeddings with Bayesian Ridge (EMBD) A Bayesian Ridge Regressor learner with default parameters trained on only word embeddings. A corpus was build from the training data and an in-house Tweet collection sampled with the expressions from the TLS. This resulted in a total of 3.7 million tweets and 67 million tokens. For details on how the word embeddings were built see §3.3. 3.2 Ensembles We developed two stacking systems (Wolpert, 1992), Stacking System 1 (ST1) and Stacking System 2: Stacking with Backoff (ST2). The systems used for these are shown in Table 3 and the Meta Learner used for both stacking systems is Linear Regression. The systems used in ST1 and ST2 are not the only differences between the two. ST2 uses the TLS to identify the subgroup that each tweet belongs to. For any tweet with the NONE subgrouping, the system would back off to the predictions from the GSA. We built ST2 as a system that is not limited to sentiment analysis for a small subsection of language, the phenomenon of figurative language, but is app</context>
</contexts>
<marker>Wolpert, 1992</marker>
<rawString>David H Wolpert. 1992. Stacked generalization. Neural networks, 5(2):241–259.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>