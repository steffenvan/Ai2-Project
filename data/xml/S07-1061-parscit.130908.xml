<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000891">
<title confidence="0.973852">
RACAI: Meaning Affinity Models
</title>
<author confidence="0.986419">
Radu Ion
</author>
<affiliation confidence="0.981557">
Institute for Artificial Intelligence
</affiliation>
<address confidence="0.926875666666667">
13, “13 Septembrie”,
050711, Bucharest 5,
Romania
</address>
<email confidence="0.996981">
radu@racai.ro
</email>
<author confidence="0.96563">
Dan Tufis¸
</author>
<affiliation confidence="0.961752">
Institute for Artificial Intelligence
</affiliation>
<address confidence="0.923739666666667">
13, “13 Septembrie”,
050711, Bucharest 5,
Romania
</address>
<email confidence="0.996943">
tufis@racai.ro
</email>
<sectionHeader confidence="0.998586" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999564428571429">
This article introduces an unsupervised word
sense disambiguation algorithm that is in-
spired by the lexical attraction models of
Yuret (1998). It is based on the assump-
tion that the meanings of the words that
form a sentence can be best assigned by con-
structing an interpretation of the whole sen-
tence. This interpretation is facilitated by
a dependency-like context specification of
a content word within the sentence. Thus,
finding the context words of a target word
is a matter of finding a pseudo-syntactic de-
pendency analysis of the sentence, called a
linkage.
</bodyText>
<sectionHeader confidence="0.999458" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.993693230769231">
Word Sense Disambiguation (WSD) is a difficult
Natural Language Processing task which requires
that for every content word (noun, adjective, verb
or adverb) the appropriate meaning is automatically
selected from the available sense inventory1. Tradi-
tionally, the WSD algorithms are divided into two
rough classes: supervised and unsupervised. The
supervised paradigm relies on sense annotated cor-
pora, with the assumption that neighbouring disam-
biguate words provide a strongly discriminating and
generalizable context representation for the meaning
of a target word. Obviously, this approach suffers
from the knowledge acquisition bottleneck in that
</bodyText>
<footnote confidence="0.8797505">
1In principle, one can select meanings for any part of speech
that is represented into the semantic lexicon (prepositions for
instance) but the content words disambiguation is the de facto
standard.
</footnote>
<bodyText confidence="0.999961852941177">
there will never be enough training data to ensure
a scalable result of such algorithms. The unsuper-
vised alternative to WSD tries to alleviate the burden
of manually sense tagging the corpora, by employ-
ing algorithms that use different knowledge sources
to determine the correct meaning in context. In fact,
the “knowledge source usage” is another way to dis-
tinguish among the WSD methods. Such methods
call upon further processing of the text to be dis-
ambiguated such as parsing and/or use handcrafted,
semantically rich sense inventories such as Word-
Net (Fellbaum, 1998). WSD methods in this cate-
gory range from the very simple ranking based on
counting the number of words occurring in both the
target word’s context and its sense definitions in a
reference dictionary (Lesk, 1986) to the more elabo-
rated approaches using the semantic lexicon’s tax-
onomies, (shallow) parsing, collocation discovery
etc. (Stevenson and Wilks, 2001).
One of the central issues of any WSD implemen-
tation is given by the context representation. The
standard principle that is applied when trying to dis-
ambiguate the meaning of a word is that the same
word in similar contexts should have the same mean-
ing. By and large, the context of a target word is ma-
terialized by a collection of features among which
are: the collocates of the target word, the part-of-
speech (POS) of the target word, fk words sur-
rounding the target word and/or their POSes and so
on. More often than not, the contexts similarity is es-
timated by the distance in the feature vector space.
Lin (1997) defines the local context of a target word
by the collection of syntactic dependencies in which
the word takes part. According to this notion of con-
</bodyText>
<page confidence="0.951847">
282
</page>
<bodyText confidence="0.983356611111111">
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 282–287,
Prague, June 2007. c�2007 Association for Computational Linguistics
text, Lin assumes that two different words are likely
to have similar meanings if they occur in identical
local contexts.
What we will attempt here is to combine the two
views of context similarity/identity versus meaning
similarity/identity by using a dependency-like repre-
sentation of the context as a lexical attraction model.
More specifically, we will not consider any feature
of the context and will try to maximize a meaning at-
traction function over all linked words of a sentence.
In section 2 we will describe SynWSD, an unsuper-
vised, knowledge-based WSD algorithm and in sec-
tions 3 and 4 we will present the application of Syn-
WSD to two of SEMEVAL-2007 “all words” tasks:
English Coarse-Grained and English Fine-Grained.
Finally, with section 5 we will conclude the article.
</bodyText>
<sectionHeader confidence="0.997224" genericHeader="introduction">
2 SynWSD
</sectionHeader>
<bodyText confidence="0.999872">
The syntactic context representation is not new in
the realm of WSD algorithms. For instance, Lin
(1997) used the dependency relations of the target
word to specify its context and Stetina (1998) ex-
tracted head-modifier relations to obtain the context
pairs for each word of interest from a constituents
tree. The syntactic representation of the context of a
target word has one main advantage over the collec-
tion of features method: the target word is related
only with the relevant word(s) in its window and
not with all the words and thus, many noisy cooc-
currences are eliminated. Mel’ˇcuk (1988) further
strengthens the intuition of a syntactic context rep-
resentation with his Meaning Text Model in which
there is a deterministic translation from the surface
syntactic dependency realization of the sentence to
its deep syntactic one and therefore to the semantic
representation.
To use a syntactic analysis as a context representa-
tion, one needs a parser which will supply the WSD
algorithm with the required analysis. Because we
have intended to develop a language independent
WSD algorithm and because there is no available,
reliable dependency parser for Romanian, we have
backed off to a simpler, easier to obtain dependency-
like representation of a sentence: a slightly modified
version of the lexical attraction models of (Yuret,
1998).
</bodyText>
<subsectionHeader confidence="0.960828">
2.1 LexPar
</subsectionHeader>
<bodyText confidence="0.999938333333333">
Lexical attraction is viewed as the likelihood of a
syntactic dependency relation between two words of
a sentence and is measured by the pointwise mutual
information between them. Yuret (1998) shows that
the search for the lowest entropy lexical attraction
model leads to the unsupervised discovery of undi-
rected dependency relations or links.
LexPar (Ion and Barbu Mititelu, 2006) is a link
analyzer (a linker) which generates a connected,
undirected, acyclic and planar graph of an input sen-
tence in which the nodes are the words of the sen-
tence and the edges are the highest lexical attracted
dependency-like relations. This program is simi-
lar to the suboptimal one presented in (Yuret, 1998)
with the following main differences:
</bodyText>
<listItem confidence="0.958625461538462">
• the policy of checking pairs of words to be re-
lated is based on the assumption that most of
the syntactic relations2 are formed between ad-
jacent words and then between adjacent groups
of linked words;
• it operates on POS-tagged and lemmatized cor-
pora and attempts to improve parameter estima-
tion by using both lemmas and POS tags. The
score of a link is defined as the weighted sum
of the pointwise mutual information of the lem-
mas and of the POS tags, thus coping even with
the unknown lemmas;
• it uses a rule filter that will deny the formation
</listItem>
<bodyText confidence="0.860837909090909">
of certain links based on the POSes of the can-
didate words. For instance, neither the relation
between a determiner and an adverb nor the re-
lation between a singular determiner and a plu-
ral noun should be permitted;
In Figure 1 we have an example of a XML en-
coded, LexPar processed sentence. The head at-
tribute of the w tag specifies the position of the head
word of the tagged word. Because LexPar considers
non-directed dependency relations, for the purposes
of XML encoding3, the first word of every sentence
</bodyText>
<footnote confidence="0.9988266">
2At least for our languages of interest, namely English and
Romanian.
3The encoding of the morpho-syntactic descriptors (MSD) is
MULTEXT-East compliant (http://nl.ijs.si/ME/V3/
msd/00README.txt).
</footnote>
<page confidence="0.99724">
283
</page>
<figureCaption confidence="0.995485">
Figure 1: The XML representation of a LexPar pro-
cessed sentence.
</figureCaption>
<bodyText confidence="0.893600181818182">
(position 0) is always the root of the syntactic de-
pendency tree, its dependents are its children nodes,
and so on while we recursively build the tree from
the LexPar result.
We have chosen not to give a detailed presentation
of LexPar here (the reader is directed towards (Yuret,
1998; Ion and Barbu Mititelu, 2006)) and instead,
to briefly explain how the linkage in Figure 1 was
obtained. The processor begins by inspecting a list
G of groups of linked words which initially contains
the positions of each of the words in the sentence:
</bodyText>
<equation confidence="0.970047">
G0 = {(0), (1), (2), (3), (4), (5)}
</equation>
<bodyText confidence="0.9998874">
The linking policy is trying to link words in the
groups (0) and (1) or (1) and (2). The syntactic
rule filter says that auxiliary verbs (Va) can only
be linked with main verbs (Vm) and so one link is
formed and the list of groups becomes:
</bodyText>
<equation confidence="0.95342">
G1 = {(0), ((1, 2)), (3), (4), (5)}
</equation>
<bodyText confidence="0.99931325">
Next, the processor must decide linking the groups
((1, 2)) and (3) or (3) and (4) but the syntactic rule
filter is denying any link from positions 1 or 2 to 3
(no links from any kind of verb V to any kind of a
determiner D) or from 3 to 4 (no link from a nega-
tive determiner Dz3 to a qualificative adjective Af).
Continuing this way, the progress of G list is as fol-
lows:
</bodyText>
<equation confidence="0.999026333333333">
G1 = {(0), ((1, 2)), (3), ((4, 5))}
G2 = {((0, 2), (1, 2)), ((3, 5), (4, 5))}
G3 = {((0, 2), (1, 2), (2, 5), (3, 5), (4, 5))}
</equation>
<bodyText confidence="0.995667">
So in 3 steps G3 contains a single group of linked
words namely the linkage of the sentence.
</bodyText>
<subsectionHeader confidence="0.999147">
2.2 Meaning Affinity Models
</subsectionHeader>
<bodyText confidence="0.998624333333333">
If the lexical attraction models are geared towards
the discovery of the most probable syntactic rela-
tions of a sentence, we can naturally generalize this
idea to construct a class of models that will find a
combination of meanings that maximizes a certain
meaning attraction function over a linkage of a sen-
tence. We call this class of models the meaning
affinity models.
Optimizing meaning affinity over a syntactic rep-
resentation of a sentence has been tried in (Stetina et
al., 1998; Horbovanu, 2002). SynWSD (Ion, 2007)
is an implementation with two phases of the mean-
ing affinity concept: training which takes as input
a corpus with LexPar linked sentences (of the type
shown in Figure 1) and outputs a table M of mean-
ing co-occurrence frequencies and disambiguation
of a LexPar linked sentence 5, based on the counts
in table M from the previous phase.
Before continuing with the descriptions of these
phases, we will introduce the notations that we will
use throughout this section:
</bodyText>
<listItem confidence="0.951862909090909">
• A n-word sentence is represented by a vec-
tor 5 of n elements, each of them contain-
ing a triple (wordform, lemma, POS). For in-
stance, the first element from 5 in Figure 1 is
5[0] = (We, we, Pp1−pn);
• L is the LexPar linkage of 5, and is also a vec-
tor containing pairs of positions (i, j) in 5 that
are related, where 0 &lt; i &lt; j &lt; n;
• lem(5, i) and pos(5, i) are two functions that
give the lemma and the POS of the position i in
5, 0 &lt; i &lt; n.
</listItem>
<bodyText confidence="0.9975985">
The training phase is responsible for collecting
meaning co-occurrence counts. It simply iterates
over each sentence 5 of the training corpus and for
every link L[k] of the form (a, b) from its linkage,
does the following (K stores the total number of
recorded meaning pairs):
</bodyText>
<footnote confidence="0.5348296">
1. extracts the sets of meanings Ia and Ib corre-
sponding to the lemma lem(5, a) with the POS
pos(5, a) and to the lemma lem(5, b) with the
POS pos(5, b) from the sense inventory4;
4If the lemma does not appear in the sense inventory or its
</footnote>
<page confidence="0.987048">
284
</page>
<listItem confidence="0.997734428571428">
2. increases by 1 the M table frequencies for ev-
ery pair of the cartesian product Ia X Ib. For
every meaning m E Ia, the frequency of the
special pair (m, *) is increased with |Ib|. Simi-
larly, the pair (*, m) frequency is also increased
with |Ia |for m E Ib);
3. K +— K + |Ia X Ib|.
</listItem>
<bodyText confidence="0.995243105263158">
We have used the Princeton WordNet (Fellbaum,
1998), version 2.0 (PWN20) as our sense inventory
and the mappings from its synsets to the SUMO
ontology concepts (Niles and Pease, 2003) and to
the IRST domains (Magnini and Cavaglia, 2000).
Thus we have tree different sense inventories each
with a different granularity. For instance, the noun
homeless has 2 senses in PWN20, its first sense
(“someone with no housing”) being mapped onto the
more general Human SUMO concept and onto the
person IRST domain. The second sense of the
same noun is “people who are homeless” which cor-
responds to the same SUMO concept and to a differ-
ent IRST domain (factotum).
In order to reduce the number of recorded pairs
in the case of PWN20 meanings (the finest granular-
ity available) and to obtain reliable counts, we have
modified the step 1 of the training phase in the fol-
lowing manner:
</bodyText>
<listItem confidence="0.951794">
• if we are dealing with nouns or verbs, for every
meaning mi of the lemma, extract the upper-
most hypernym meaning which does not sub-
sume any other meaning of the same lemma;
• if we are dealing with adjectives, for every
meaning mi of the lemma, extract the meaning
of the head adjective if mi is part of a cluster;
• if we are dealing with adverbs, for every mean-
ing mi of the lemma, return mi (no generaliza-
tion is made available by the sense inventory in
this case).
</listItem>
<bodyText confidence="0.9548705">
This generalization procedure will be reversed at the
time of disambiguation as will be explained shortly.
</bodyText>
<footnote confidence="0.9051045">
POS does not give a noun, verb, adjective or adverb, the lemma
itself is returned as the sole meaning because in the disambigua-
tion phase we need a meaning for every word of the sentence,
be it content word or otherwise.
</footnote>
<figureCaption confidence="1">
Figure 2: The tree representation of the sentence in
Figure 1.
</figureCaption>
<bodyText confidence="0.864091785714286">
The disambiguation phase takes care of finding
the best interpretation of a linked sentence based on
the frequency table M. For a test sentence 5, with
the linkage L, the procedure goes as follows:
1. produce a proper tree T of positions from L by
taking position 0 as the root of the tree. Then,
for every link that contains 0 make the other po-
sition in the link a child of 0 and then, in a re-
cursive manner, apply the same process for all
children of 0. For instance, the tree for Figure
1 if depicted in Figure 2;
2. construct a vector P of sentence positions vis-
ited during a depth-first traversal of the T tree.
The vector of sentence positions for Figure 2 is
</bodyText>
<equation confidence="0.865953">
P = (0, 2, 5, 3, 5, 4, 5, 2, 1, 2, 0)
</equation>
<listItem confidence="0.9931878">
3. construct a meaning vector V of the same
length as P. V [i] contains the list of mean-
ings of the lemma lem(5, P[i]) with the POS
pos(5, P[i]). If the sense inventory is PWN20,
every meaning from the list is generalized as
described above;
4. finally, apply the Viterbi algorithm ((Viterbi,
1967)) on the V vector and extract the path (se-
quence of meanings) which maximizes mean-
ing affinity.
</listItem>
<bodyText confidence="0.98528175">
Each state transition is scored according to a
meaning affinity function. In our experiments we
have considered three meaning affinity functions. If
K is the total number of meaning pairs and if mi
</bodyText>
<page confidence="0.995131">
285
</page>
<bodyText confidence="0.999395833333333">
2. for each token identifier with its three union
sets of PWN20 meanings, SUMO categories
and IRST domains:
and m2 are two meanings from adjacent V positions
for which f(m1, m2) is the pair frequency extracted
from M, the functions are:
</bodyText>
<listItem confidence="0.791963">
1. DICE:
</listItem>
<equation confidence="0.995344333333333">
dice(m1, m2) _
2f(m1,m2)+2f(m2,m1)
f(m1,∗)+f(∗,m1)+f(m2,∗)+f(∗,m2)
</equation>
<listItem confidence="0.489151">
2. Pointwise mutual information:
</listItem>
<equation confidence="0.999089">
Mi(m1, m2) _
Kf(m1,m2)+Kf(m2,m1)
log (f(m1,∗)+f(∗,m1))(f(m2,∗)+f(∗,m2))
</equation>
<listItem confidence="0.6511335">
3. Log-Likelihood, ll(m1, m2) which is com-
puted as in (Moore, 2004).
</listItem>
<bodyText confidence="0.9997844">
After the Viterbi path (best path) has been calcu-
lated, every state (meaning) from V [i] (0 &lt; i &lt; |V |)
along this path is added to a final D vector. When the
PWN20 sense inventory is used, the reverse of the
generalization procedure is applied to each meaning
recorded in D, thus coming back to the meanings
of the words of S. Please note that an entry in D
may contain more than one meaning especially in
the case of PWN20 meanings for which there was
not enough training data.
</bodyText>
<sectionHeader confidence="0.958261" genericHeader="method">
3 SEMEVAL-2007 Task #7:
</sectionHeader>
<subsectionHeader confidence="0.903911">
Coarse-grained English All-Words
</subsectionHeader>
<bodyText confidence="0.957135111111111">
LexPar and SynWSD were trained on an 1 million
words corpus comprising the George Orwell’s 1984
novel and the SemCor corpus (Miller et al., 1993).
Both texts have been POS-tagged (with MULTEXT-
East compliant POS tags) and lemmatized and the
result was carefully checked by human judges to en-
sure a correct annotation.
SynWSD was run with all the meaning attraction
functions (dice, mi and ll) for all the sense in-
ventories (PWN20, SUMO categories and IRST do-
mains) and a combined result was submitted to the
task organizers. The combined result was prepared
in the following way:
1. for each sense inventory and for each token
identifier, get the union of the meanings for
each run (dice, mi and ll);
(a) for each PWN20 meaning mi in the union,
if there is a SUMO category that maps
onto it, increase mi’s weight by 1;
(b) for each PWN20 meaning mi in the union,
if there is a IRST domain that maps onto
it, increase mi’s weight by 1;
(c) from the set of weighted PWN20 mean-
ings, select the subset C that best over-
laps with a cluster. That is, the intersec-
tion between the subset and the cluster has
a maximal number of meanings for which
the sum of weights is also the greatest;
(d) output the lowest numbered meaning in C.
With this combination, the official F-measure of
SynWSD is 0.65712 which places it into the 11th
position out of 16 competing systems5.
Another possible combination is that of the inter-
section which is obtained with the exact same steps
as above, replacing the union operation with the in-
tersection. When the PWN20 meanings set is void,
we can make use of the most frequent sense (MFS)
backoff strategy thus selecting the MFS of the cur-
rent test word from PWN20. Working with the of-
ficial key file and scoring software, the intersection
combination with MFS backoff gives an F-measure
of 0.78713 corresponding to the 6th best result. The
same combination method but without MFS backoff
achieves a precision of 0.80559 but at the cost of a
very low F-measure (0.41492).
</bodyText>
<sectionHeader confidence="0.9895895" genericHeader="method">
4 SEMEVAL-2007 Task #17: English
All-Words
</sectionHeader>
<bodyText confidence="0.999728428571429">
For this task, LexPar and SynWSD were further
trained on a 12 million POS tagged and lemmatized
balanced corpus6. The run that was submitted was
the intersection combination with the MFS backoff
strategy which obtained an F-measure of 0.527. This
score puts our algorithm on the 8th position out of
14 competing systems. For the union combinator
</bodyText>
<footnote confidence="0.97468275">
5Precision = Recall = F-measure. In what follows, mention-
ing only the F-measure means that this equality holds.
6A random subset of the BNC (http://www.natcorp.
ox.ac.uk/).
</footnote>
<page confidence="0.996568">
286
</page>
<bodyText confidence="0.999769">
(the MFS backoff strategy is not applicable), the F-
measure decreases to 0.445 (101h place). Finally, if
we train SynWSD only on corpora from task#7, the
union combinator leads to an F-measure of 0.344.
</bodyText>
<sectionHeader confidence="0.999412" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999941181818182">
SynWSD is a knowledge-based, unsupervised WSD
algorithm that uses a dependency-like analysis of a
sentence as a uniform context representation. It is a
language independent algorithm that doesn’t require
any feature selection.
Our system can be improved in several ways.
First, one can modify the generalization procedure
in the case of PWN20 meanings in the sense of se-
lecting a fixed set of top level hypernyms. The size
of this set will directly affect the quality of meaning
co-occurrence frequencies. Second, one may study
the effect of a proper dependency parsing on the re-
sults of the disambiguation process including here
making use of the syntactic relations names and ori-
entation.
Even if SynWSD rankings are not the best avail-
able, we believe that the unsupervised approach to
the WSD problem combined with different knowl-
edge sources represents the future of these systems
even if, at least during the last semantic evalua-
tion exercise SENSEVAL-3, the supervised systems
achieved top rankings.
</bodyText>
<sectionHeader confidence="0.999165" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999923313432836">
Christiane Fellbaum, editor. 1998. WordNet. An Elec-
tronic Lexical Database. MIT Press, May.
Vladimir Horbovanu. 2002. Word Sense Disambigua-
tion using WordNet. ”Alexandru Ioan Cuza” Univer-
sity, Faculty of Computer Science, Ias¸i, Romania. In
Romanian.
Radu Ion and Verginica Barbu Mititelu. 2006. Con-
strained lexical attraction models. In Proceedings of
the Nineteenth International Florida Artificial Intelli-
gence Research Society Conference, pages 297–302,
Menlo Park, Calif., USA. AAAI Press.
Radu Ion. 2007. Word Sense Disambiguation meth-
ods applied to English and Romanian. Ph.D. thesis,
Research Institute for Artificial Intelligence (RACAI),
Romanian Academy, January. In Romanian, to be de-
fended.
Michael Lesk. 1986. Automatic sense disambiguation :
How to tell a pine cone from an ice cream cone. In
Proceedings of the 1986 SIGDOC Conference, Asso-
ciation for Computing Machinery, pages 24–26, New
York.
Dekang Lin. 1997. Using syntactic dependency as lo-
cal context to resolve word sense ambiguity. In Pro-
ceedings of the 35th Annual Meeting of the Association
for Computational Linguistics, pages 64–71, Madrid,
Spain, July.
Bernardo Magnini and Gabriela Cavaglia. 2000. Inte-
grating Subject Field Codes into WordNet. In Gavrili-
dou M., Crayannis G., Markantonatu S., Piperidis S.,
and Stainhaouer G., editors, Proceedings of LREC-
2000, Second International Conference on Language
Resources and Evaluation, pages 1413–1418, Athens,
Greece, June.
Igor Mel’ˇcuk. 1988. Dependency Syntax: theory and
practice. State University of New York Press, Albany,
NY.
George A. Miller, Claudia Leacock, Randee Tengi, and
Ross T. Bunker. 1993. A semantic concordance.
In Proceedings of the 3rd DARPA Workshop on Hu-
man Language Technology, pages 303–308, Plains-
boro, New Jersey.
Robert C. Moore. 2004. On Log-Likelihood Ratios and
the Significance of Rare Events. In Proceedings of
the 2004 Conference on Empirical Methods in Natu-
ral Language Processing, pages 333–340, Barcelona,
Spain.
Ian Niles and Adam Pease. 2003. Linking Lexicons
and Ontologies: Mapping WordNet to the Suggested
Upper Merged Ontology. In Proceedings of the 2003
International Conference on Information and Knowl-
edge Engineering (IKE 03), Las Vegas, Nevada, June.
Jiri Stetina, Sadao Kurohashi, and Makoto Nagao. 1998.
General word sense disambiguation method based on
a full sentential context. In Proceedings of the Coling-
ACL’98 Workshop “Usage of WordNet in Natural Lan-
guage Processing Systems”, pages 1–8, Montreal.
Mark Stevenson and Yorick Wilks. 2001. The interaction
of knowledge sources in word sense disambiguation.
Computational Linguistics, 27(3):321–349.
Andrew J. Viterbi. 1967. Error bounds for convolu-
tional codes and an asymptotically optimum decoding
algorithm. IEEE Transactions on Information Theory,
IT(13):260–269, April.
Deniz Yuret. 1998. Discovery of linguistic relations
using lexical attraction. Ph.D. thesis, Department of
Computer Science and Electrical Engineering, MIT,
May.
</reference>
<page confidence="0.997408">
287
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.695488">
<title confidence="0.998512">RACAI: Meaning Affinity Models</title>
<author confidence="0.992026">Radu Ion</author>
<affiliation confidence="0.997355">Institute for Artificial Intelligence</affiliation>
<address confidence="0.959034">13, “13 Septembrie”, 050711, Bucharest 5, Romania</address>
<email confidence="0.985932">radu@racai.ro</email>
<affiliation confidence="0.974422">Institute for Artificial Intelligence</affiliation>
<address confidence="0.955069666666667">13, “13 Septembrie”, 050711, Bucharest 5, Romania</address>
<email confidence="0.990528">tufis@racai.ro</email>
<abstract confidence="0.9963158">This article introduces an unsupervised word sense disambiguation algorithm that is inspired by the lexical attraction models of Yuret (1998). It is based on the assumption that the meanings of the words that form a sentence can be best assigned by constructing an interpretation of the whole sentence. This interpretation is facilitated by a dependency-like context specification of a content word within the sentence. Thus, finding the context words of a target word is a matter of finding a pseudo-syntactic dependency analysis of the sentence, called a linkage.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>WordNet. An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<contexts>
<context position="4559" citStr="(1998)" startWordPosition="721" endWordPosition="721">f the context and will try to maximize a meaning attraction function over all linked words of a sentence. In section 2 we will describe SynWSD, an unsupervised, knowledge-based WSD algorithm and in sections 3 and 4 we will present the application of SynWSD to two of SEMEVAL-2007 “all words” tasks: English Coarse-Grained and English Fine-Grained. Finally, with section 5 we will conclude the article. 2 SynWSD The syntactic context representation is not new in the realm of WSD algorithms. For instance, Lin (1997) used the dependency relations of the target word to specify its context and Stetina (1998) extracted head-modifier relations to obtain the context pairs for each word of interest from a constituents tree. The syntactic representation of the context of a target word has one main advantage over the collection of features method: the target word is related only with the relevant word(s) in its window and not with all the words and thus, many noisy cooccurrences are eliminated. Mel’ˇcuk (1988) further strengthens the intuition of a syntactic context representation with his Meaning Text Model in which there is a deterministic translation from the surface syntactic dependency realization</context>
<context position="5914" citStr="(1998)" startWordPosition="937" endWordPosition="937"> needs a parser which will supply the WSD algorithm with the required analysis. Because we have intended to develop a language independent WSD algorithm and because there is no available, reliable dependency parser for Romanian, we have backed off to a simpler, easier to obtain dependencylike representation of a sentence: a slightly modified version of the lexical attraction models of (Yuret, 1998). 2.1 LexPar Lexical attraction is viewed as the likelihood of a syntactic dependency relation between two words of a sentence and is measured by the pointwise mutual information between them. Yuret (1998) shows that the search for the lowest entropy lexical attraction model leads to the unsupervised discovery of undirected dependency relations or links. LexPar (Ion and Barbu Mititelu, 2006) is a link analyzer (a linker) which generates a connected, undirected, acyclic and planar graph of an input sentence in which the nodes are the words of the sentence and the edges are the highest lexical attracted dependency-like relations. This program is similar to the suboptimal one presented in (Yuret, 1998) with the following main differences: • the policy of checking pairs of words to be related is ba</context>
</contexts>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet. An Electronic Lexical Database. MIT Press, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Horbovanu</author>
</authors>
<title>Word Sense Disambiguation using WordNet. ”Alexandru Ioan Cuza”</title>
<date>2002</date>
<institution>University, Faculty of Computer Science, Ias¸i, Romania. In Romanian.</institution>
<contexts>
<context position="9758" citStr="Horbovanu, 2002" startWordPosition="1623" endWordPosition="1624">teps G3 contains a single group of linked words namely the linkage of the sentence. 2.2 Meaning Affinity Models If the lexical attraction models are geared towards the discovery of the most probable syntactic relations of a sentence, we can naturally generalize this idea to construct a class of models that will find a combination of meanings that maximizes a certain meaning attraction function over a linkage of a sentence. We call this class of models the meaning affinity models. Optimizing meaning affinity over a syntactic representation of a sentence has been tried in (Stetina et al., 1998; Horbovanu, 2002). SynWSD (Ion, 2007) is an implementation with two phases of the meaning affinity concept: training which takes as input a corpus with LexPar linked sentences (of the type shown in Figure 1) and outputs a table M of meaning co-occurrence frequencies and disambiguation of a LexPar linked sentence 5, based on the counts in table M from the previous phase. Before continuing with the descriptions of these phases, we will introduce the notations that we will use throughout this section: • A n-word sentence is represented by a vector 5 of n elements, each of them containing a triple (wordform, lemma</context>
</contexts>
<marker>Horbovanu, 2002</marker>
<rawString>Vladimir Horbovanu. 2002. Word Sense Disambiguation using WordNet. ”Alexandru Ioan Cuza” University, Faculty of Computer Science, Ias¸i, Romania. In Romanian.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Ion</author>
<author>Verginica Barbu Mititelu</author>
</authors>
<title>Constrained lexical attraction models.</title>
<date>2006</date>
<booktitle>In Proceedings of the Nineteenth International Florida Artificial Intelligence Research Society Conference,</booktitle>
<pages>297--302</pages>
<publisher>AAAI Press.</publisher>
<location>Menlo Park, Calif., USA.</location>
<marker>Ion, Mititelu, 2006</marker>
<rawString>Radu Ion and Verginica Barbu Mititelu. 2006. Constrained lexical attraction models. In Proceedings of the Nineteenth International Florida Artificial Intelligence Research Society Conference, pages 297–302, Menlo Park, Calif., USA. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Ion</author>
</authors>
<title>Word Sense Disambiguation methods applied to English and Romanian.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>Research Institute for Artificial Intelligence (RACAI), Romanian Academy,</institution>
<note>In Romanian, to be defended.</note>
<contexts>
<context position="9778" citStr="Ion, 2007" startWordPosition="1626" endWordPosition="1627">group of linked words namely the linkage of the sentence. 2.2 Meaning Affinity Models If the lexical attraction models are geared towards the discovery of the most probable syntactic relations of a sentence, we can naturally generalize this idea to construct a class of models that will find a combination of meanings that maximizes a certain meaning attraction function over a linkage of a sentence. We call this class of models the meaning affinity models. Optimizing meaning affinity over a syntactic representation of a sentence has been tried in (Stetina et al., 1998; Horbovanu, 2002). SynWSD (Ion, 2007) is an implementation with two phases of the meaning affinity concept: training which takes as input a corpus with LexPar linked sentences (of the type shown in Figure 1) and outputs a table M of meaning co-occurrence frequencies and disambiguation of a LexPar linked sentence 5, based on the counts in table M from the previous phase. Before continuing with the descriptions of these phases, we will introduce the notations that we will use throughout this section: • A n-word sentence is represented by a vector 5 of n elements, each of them containing a triple (wordform, lemma, POS). For instance</context>
</contexts>
<marker>Ion, 2007</marker>
<rawString>Radu Ion. 2007. Word Sense Disambiguation methods applied to English and Romanian. Ph.D. thesis, Research Institute for Artificial Intelligence (RACAI), Romanian Academy, January. In Romanian, to be defended.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Lesk</author>
</authors>
<title>Automatic sense disambiguation : How to tell a pine cone from an ice cream cone.</title>
<date>1986</date>
<booktitle>In Proceedings of the 1986 SIGDOC Conference, Association for Computing Machinery,</booktitle>
<pages>24--26</pages>
<location>New York.</location>
<contexts>
<context position="2481" citStr="Lesk, 1986" startWordPosition="377" endWordPosition="378">agging the corpora, by employing algorithms that use different knowledge sources to determine the correct meaning in context. In fact, the “knowledge source usage” is another way to distinguish among the WSD methods. Such methods call upon further processing of the text to be disambiguated such as parsing and/or use handcrafted, semantically rich sense inventories such as WordNet (Fellbaum, 1998). WSD methods in this category range from the very simple ranking based on counting the number of words occurring in both the target word’s context and its sense definitions in a reference dictionary (Lesk, 1986) to the more elaborated approaches using the semantic lexicon’s taxonomies, (shallow) parsing, collocation discovery etc. (Stevenson and Wilks, 2001). One of the central issues of any WSD implementation is given by the context representation. The standard principle that is applied when trying to disambiguate the meaning of a word is that the same word in similar contexts should have the same meaning. By and large, the context of a target word is materialized by a collection of features among which are: the collocates of the target word, the part-ofspeech (POS) of the target word, fk words surr</context>
</contexts>
<marker>Lesk, 1986</marker>
<rawString>Michael Lesk. 1986. Automatic sense disambiguation : How to tell a pine cone from an ice cream cone. In Proceedings of the 1986 SIGDOC Conference, Association for Computing Machinery, pages 24–26, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Using syntactic dependency as local context to resolve word sense ambiguity.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>64--71</pages>
<location>Madrid, Spain,</location>
<contexts>
<context position="3248" citStr="Lin (1997)" startWordPosition="511" endWordPosition="512"> the central issues of any WSD implementation is given by the context representation. The standard principle that is applied when trying to disambiguate the meaning of a word is that the same word in similar contexts should have the same meaning. By and large, the context of a target word is materialized by a collection of features among which are: the collocates of the target word, the part-ofspeech (POS) of the target word, fk words surrounding the target word and/or their POSes and so on. More often than not, the contexts similarity is estimated by the distance in the feature vector space. Lin (1997) defines the local context of a target word by the collection of syntactic dependencies in which the word takes part. According to this notion of con282 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 282–287, Prague, June 2007. c�2007 Association for Computational Linguistics text, Lin assumes that two different words are likely to have similar meanings if they occur in identical local contexts. What we will attempt here is to combine the two views of context similarity/identity versus meaning similarity/identity by using a dependency-like represent</context>
<context position="4468" citStr="Lin (1997)" startWordPosition="705" endWordPosition="706">he context as a lexical attraction model. More specifically, we will not consider any feature of the context and will try to maximize a meaning attraction function over all linked words of a sentence. In section 2 we will describe SynWSD, an unsupervised, knowledge-based WSD algorithm and in sections 3 and 4 we will present the application of SynWSD to two of SEMEVAL-2007 “all words” tasks: English Coarse-Grained and English Fine-Grained. Finally, with section 5 we will conclude the article. 2 SynWSD The syntactic context representation is not new in the realm of WSD algorithms. For instance, Lin (1997) used the dependency relations of the target word to specify its context and Stetina (1998) extracted head-modifier relations to obtain the context pairs for each word of interest from a constituents tree. The syntactic representation of the context of a target word has one main advantage over the collection of features method: the target word is related only with the relevant word(s) in its window and not with all the words and thus, many noisy cooccurrences are eliminated. Mel’ˇcuk (1988) further strengthens the intuition of a syntactic context representation with his Meaning Text Model in w</context>
</contexts>
<marker>Lin, 1997</marker>
<rawString>Dekang Lin. 1997. Using syntactic dependency as local context to resolve word sense ambiguity. In Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics, pages 64–71, Madrid, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernardo Magnini</author>
<author>Gabriela Cavaglia</author>
</authors>
<title>Integrating Subject Field Codes into WordNet.</title>
<date>2000</date>
<booktitle>Proceedings of LREC2000, Second International Conference on Language Resources and Evaluation,</booktitle>
<pages>1413--1418</pages>
<editor>In Gavrilidou M., Crayannis G., Markantonatu S., Piperidis S., and Stainhaouer G., editors,</editor>
<location>Athens, Greece,</location>
<contexts>
<context position="11730" citStr="Magnini and Cavaglia, 2000" startWordPosition="1999" endWordPosition="2002">he POS pos(5, b) from the sense inventory4; 4If the lemma does not appear in the sense inventory or its 284 2. increases by 1 the M table frequencies for every pair of the cartesian product Ia X Ib. For every meaning m E Ia, the frequency of the special pair (m, *) is increased with |Ib|. Similarly, the pair (*, m) frequency is also increased with |Ia |for m E Ib); 3. K +— K + |Ia X Ib|. We have used the Princeton WordNet (Fellbaum, 1998), version 2.0 (PWN20) as our sense inventory and the mappings from its synsets to the SUMO ontology concepts (Niles and Pease, 2003) and to the IRST domains (Magnini and Cavaglia, 2000). Thus we have tree different sense inventories each with a different granularity. For instance, the noun homeless has 2 senses in PWN20, its first sense (“someone with no housing”) being mapped onto the more general Human SUMO concept and onto the person IRST domain. The second sense of the same noun is “people who are homeless” which corresponds to the same SUMO concept and to a different IRST domain (factotum). In order to reduce the number of recorded pairs in the case of PWN20 meanings (the finest granularity available) and to obtain reliable counts, we have modified the step 1 of the tra</context>
</contexts>
<marker>Magnini, Cavaglia, 2000</marker>
<rawString>Bernardo Magnini and Gabriela Cavaglia. 2000. Integrating Subject Field Codes into WordNet. In Gavrilidou M., Crayannis G., Markantonatu S., Piperidis S., and Stainhaouer G., editors, Proceedings of LREC2000, Second International Conference on Language Resources and Evaluation, pages 1413–1418, Athens, Greece, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Mel’ˇcuk</author>
</authors>
<title>Dependency Syntax: theory and practice.</title>
<date>1988</date>
<publisher>Press,</publisher>
<institution>State University of New York</institution>
<location>Albany, NY.</location>
<marker>Mel’ˇcuk, 1988</marker>
<rawString>Igor Mel’ˇcuk. 1988. Dependency Syntax: theory and practice. State University of New York Press, Albany, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Claudia Leacock</author>
<author>Randee Tengi</author>
<author>Ross T Bunker</author>
</authors>
<title>A semantic concordance.</title>
<date>1993</date>
<booktitle>In Proceedings of the 3rd DARPA Workshop on Human Language Technology,</booktitle>
<pages>303--308</pages>
<location>Plainsboro, New Jersey.</location>
<contexts>
<context position="15698" citStr="Miller et al., 1993" startWordPosition="2711" endWordPosition="2714">state (meaning) from V [i] (0 &lt; i &lt; |V |) along this path is added to a final D vector. When the PWN20 sense inventory is used, the reverse of the generalization procedure is applied to each meaning recorded in D, thus coming back to the meanings of the words of S. Please note that an entry in D may contain more than one meaning especially in the case of PWN20 meanings for which there was not enough training data. 3 SEMEVAL-2007 Task #7: Coarse-grained English All-Words LexPar and SynWSD were trained on an 1 million words corpus comprising the George Orwell’s 1984 novel and the SemCor corpus (Miller et al., 1993). Both texts have been POS-tagged (with MULTEXTEast compliant POS tags) and lemmatized and the result was carefully checked by human judges to ensure a correct annotation. SynWSD was run with all the meaning attraction functions (dice, mi and ll) for all the sense inventories (PWN20, SUMO categories and IRST domains) and a combined result was submitted to the task organizers. The combined result was prepared in the following way: 1. for each sense inventory and for each token identifier, get the union of the meanings for each run (dice, mi and ll); (a) for each PWN20 meaning mi in the union, i</context>
</contexts>
<marker>Miller, Leacock, Tengi, Bunker, 1993</marker>
<rawString>George A. Miller, Claudia Leacock, Randee Tengi, and Ross T. Bunker. 1993. A semantic concordance. In Proceedings of the 3rd DARPA Workshop on Human Language Technology, pages 303–308, Plainsboro, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>On Log-Likelihood Ratios and the Significance of Rare Events.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>333--340</pages>
<location>Barcelona,</location>
<contexts>
<context position="15014" citStr="Moore, 2004" startWordPosition="2589" endWordPosition="2590">n our experiments we have considered three meaning affinity functions. If K is the total number of meaning pairs and if mi 285 2. for each token identifier with its three union sets of PWN20 meanings, SUMO categories and IRST domains: and m2 are two meanings from adjacent V positions for which f(m1, m2) is the pair frequency extracted from M, the functions are: 1. DICE: dice(m1, m2) _ 2f(m1,m2)+2f(m2,m1) f(m1,∗)+f(∗,m1)+f(m2,∗)+f(∗,m2) 2. Pointwise mutual information: Mi(m1, m2) _ Kf(m1,m2)+Kf(m2,m1) log (f(m1,∗)+f(∗,m1))(f(m2,∗)+f(∗,m2)) 3. Log-Likelihood, ll(m1, m2) which is computed as in (Moore, 2004). After the Viterbi path (best path) has been calculated, every state (meaning) from V [i] (0 &lt; i &lt; |V |) along this path is added to a final D vector. When the PWN20 sense inventory is used, the reverse of the generalization procedure is applied to each meaning recorded in D, thus coming back to the meanings of the words of S. Please note that an entry in D may contain more than one meaning especially in the case of PWN20 meanings for which there was not enough training data. 3 SEMEVAL-2007 Task #7: Coarse-grained English All-Words LexPar and SynWSD were trained on an 1 million words corpus c</context>
</contexts>
<marker>Moore, 2004</marker>
<rawString>Robert C. Moore. 2004. On Log-Likelihood Ratios and the Significance of Rare Events. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 333–340, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Niles</author>
<author>Adam Pease</author>
</authors>
<title>Linking Lexicons and Ontologies: Mapping WordNet to the Suggested Upper Merged Ontology.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 International Conference on Information and Knowledge Engineering (IKE 03),</booktitle>
<location>Las Vegas, Nevada,</location>
<contexts>
<context position="11677" citStr="Niles and Pease, 2003" startWordPosition="1990" endWordPosition="1993"> POS pos(5, a) and to the lemma lem(5, b) with the POS pos(5, b) from the sense inventory4; 4If the lemma does not appear in the sense inventory or its 284 2. increases by 1 the M table frequencies for every pair of the cartesian product Ia X Ib. For every meaning m E Ia, the frequency of the special pair (m, *) is increased with |Ib|. Similarly, the pair (*, m) frequency is also increased with |Ia |for m E Ib); 3. K +— K + |Ia X Ib|. We have used the Princeton WordNet (Fellbaum, 1998), version 2.0 (PWN20) as our sense inventory and the mappings from its synsets to the SUMO ontology concepts (Niles and Pease, 2003) and to the IRST domains (Magnini and Cavaglia, 2000). Thus we have tree different sense inventories each with a different granularity. For instance, the noun homeless has 2 senses in PWN20, its first sense (“someone with no housing”) being mapped onto the more general Human SUMO concept and onto the person IRST domain. The second sense of the same noun is “people who are homeless” which corresponds to the same SUMO concept and to a different IRST domain (factotum). In order to reduce the number of recorded pairs in the case of PWN20 meanings (the finest granularity available) and to obtain re</context>
</contexts>
<marker>Niles, Pease, 2003</marker>
<rawString>Ian Niles and Adam Pease. 2003. Linking Lexicons and Ontologies: Mapping WordNet to the Suggested Upper Merged Ontology. In Proceedings of the 2003 International Conference on Information and Knowledge Engineering (IKE 03), Las Vegas, Nevada, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiri Stetina</author>
<author>Sadao Kurohashi</author>
<author>Makoto Nagao</author>
</authors>
<title>General word sense disambiguation method based on a full sentential context.</title>
<date>1998</date>
<booktitle>In Proceedings of the ColingACL’98 Workshop “Usage of WordNet in Natural Language Processing Systems”,</booktitle>
<pages>1--8</pages>
<location>Montreal.</location>
<contexts>
<context position="9740" citStr="Stetina et al., 1998" startWordPosition="1619" endWordPosition="1622">5), (4, 5))} So in 3 steps G3 contains a single group of linked words namely the linkage of the sentence. 2.2 Meaning Affinity Models If the lexical attraction models are geared towards the discovery of the most probable syntactic relations of a sentence, we can naturally generalize this idea to construct a class of models that will find a combination of meanings that maximizes a certain meaning attraction function over a linkage of a sentence. We call this class of models the meaning affinity models. Optimizing meaning affinity over a syntactic representation of a sentence has been tried in (Stetina et al., 1998; Horbovanu, 2002). SynWSD (Ion, 2007) is an implementation with two phases of the meaning affinity concept: training which takes as input a corpus with LexPar linked sentences (of the type shown in Figure 1) and outputs a table M of meaning co-occurrence frequencies and disambiguation of a LexPar linked sentence 5, based on the counts in table M from the previous phase. Before continuing with the descriptions of these phases, we will introduce the notations that we will use throughout this section: • A n-word sentence is represented by a vector 5 of n elements, each of them containing a tripl</context>
</contexts>
<marker>Stetina, Kurohashi, Nagao, 1998</marker>
<rawString>Jiri Stetina, Sadao Kurohashi, and Makoto Nagao. 1998. General word sense disambiguation method based on a full sentential context. In Proceedings of the ColingACL’98 Workshop “Usage of WordNet in Natural Language Processing Systems”, pages 1–8, Montreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Stevenson</author>
<author>Yorick Wilks</author>
</authors>
<title>The interaction of knowledge sources in word sense disambiguation.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>3</issue>
<contexts>
<context position="2630" citStr="Stevenson and Wilks, 2001" startWordPosition="396" endWordPosition="399"> the “knowledge source usage” is another way to distinguish among the WSD methods. Such methods call upon further processing of the text to be disambiguated such as parsing and/or use handcrafted, semantically rich sense inventories such as WordNet (Fellbaum, 1998). WSD methods in this category range from the very simple ranking based on counting the number of words occurring in both the target word’s context and its sense definitions in a reference dictionary (Lesk, 1986) to the more elaborated approaches using the semantic lexicon’s taxonomies, (shallow) parsing, collocation discovery etc. (Stevenson and Wilks, 2001). One of the central issues of any WSD implementation is given by the context representation. The standard principle that is applied when trying to disambiguate the meaning of a word is that the same word in similar contexts should have the same meaning. By and large, the context of a target word is materialized by a collection of features among which are: the collocates of the target word, the part-ofspeech (POS) of the target word, fk words surrounding the target word and/or their POSes and so on. More often than not, the contexts similarity is estimated by the distance in the feature vector</context>
</contexts>
<marker>Stevenson, Wilks, 2001</marker>
<rawString>Mark Stevenson and Yorick Wilks. 2001. The interaction of knowledge sources in word sense disambiguation. Computational Linguistics, 27(3):321–349.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew J Viterbi</author>
</authors>
<title>Error bounds for convolutional codes and an asymptotically optimum decoding algorithm.</title>
<date>1967</date>
<journal>IEEE Transactions on Information Theory,</journal>
<volume>13</volume>
<contexts>
<context position="14231" citStr="Viterbi, 1967" startWordPosition="2468" endWordPosition="2469">n a recursive manner, apply the same process for all children of 0. For instance, the tree for Figure 1 if depicted in Figure 2; 2. construct a vector P of sentence positions visited during a depth-first traversal of the T tree. The vector of sentence positions for Figure 2 is P = (0, 2, 5, 3, 5, 4, 5, 2, 1, 2, 0) 3. construct a meaning vector V of the same length as P. V [i] contains the list of meanings of the lemma lem(5, P[i]) with the POS pos(5, P[i]). If the sense inventory is PWN20, every meaning from the list is generalized as described above; 4. finally, apply the Viterbi algorithm ((Viterbi, 1967)) on the V vector and extract the path (sequence of meanings) which maximizes meaning affinity. Each state transition is scored according to a meaning affinity function. In our experiments we have considered three meaning affinity functions. If K is the total number of meaning pairs and if mi 285 2. for each token identifier with its three union sets of PWN20 meanings, SUMO categories and IRST domains: and m2 are two meanings from adjacent V positions for which f(m1, m2) is the pair frequency extracted from M, the functions are: 1. DICE: dice(m1, m2) _ 2f(m1,m2)+2f(m2,m1) f(m1,∗)+f(∗,m1)+f(m2,</context>
</contexts>
<marker>Viterbi, 1967</marker>
<rawString>Andrew J. Viterbi. 1967. Error bounds for convolutional codes and an asymptotically optimum decoding algorithm. IEEE Transactions on Information Theory, IT(13):260–269, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deniz Yuret</author>
</authors>
<title>Discovery of linguistic relations using lexical attraction.</title>
<date>1998</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computer Science and Electrical Engineering, MIT,</institution>
<contexts>
<context position="5709" citStr="Yuret, 1998" startWordPosition="904" endWordPosition="905"> translation from the surface syntactic dependency realization of the sentence to its deep syntactic one and therefore to the semantic representation. To use a syntactic analysis as a context representation, one needs a parser which will supply the WSD algorithm with the required analysis. Because we have intended to develop a language independent WSD algorithm and because there is no available, reliable dependency parser for Romanian, we have backed off to a simpler, easier to obtain dependencylike representation of a sentence: a slightly modified version of the lexical attraction models of (Yuret, 1998). 2.1 LexPar Lexical attraction is viewed as the likelihood of a syntactic dependency relation between two words of a sentence and is measured by the pointwise mutual information between them. Yuret (1998) shows that the search for the lowest entropy lexical attraction model leads to the unsupervised discovery of undirected dependency relations or links. LexPar (Ion and Barbu Mititelu, 2006) is a link analyzer (a linker) which generates a connected, undirected, acyclic and planar graph of an input sentence in which the nodes are the words of the sentence and the edges are the highest lexical a</context>
<context position="8068" citStr="Yuret, 1998" startWordPosition="1303" endWordPosition="1304"> purposes of XML encoding3, the first word of every sentence 2At least for our languages of interest, namely English and Romanian. 3The encoding of the morpho-syntactic descriptors (MSD) is MULTEXT-East compliant (http://nl.ijs.si/ME/V3/ msd/00README.txt). 283 Figure 1: The XML representation of a LexPar processed sentence. (position 0) is always the root of the syntactic dependency tree, its dependents are its children nodes, and so on while we recursively build the tree from the LexPar result. We have chosen not to give a detailed presentation of LexPar here (the reader is directed towards (Yuret, 1998; Ion and Barbu Mititelu, 2006)) and instead, to briefly explain how the linkage in Figure 1 was obtained. The processor begins by inspecting a list G of groups of linked words which initially contains the positions of each of the words in the sentence: G0 = {(0), (1), (2), (3), (4), (5)} The linking policy is trying to link words in the groups (0) and (1) or (1) and (2). The syntactic rule filter says that auxiliary verbs (Va) can only be linked with main verbs (Vm) and so one link is formed and the list of groups becomes: G1 = {(0), ((1, 2)), (3), (4), (5)} Next, the processor must decide li</context>
</contexts>
<marker>Yuret, 1998</marker>
<rawString>Deniz Yuret. 1998. Discovery of linguistic relations using lexical attraction. Ph.D. thesis, Department of Computer Science and Electrical Engineering, MIT, May.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>