<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.987335">
Disambiguating
Grammatically Ambiguous Sentences
By Asking
</title>
<author confidence="0.947042">
Maseru Tomita
</author>
<affiliation confidence="0.824416">
Computer Science Department
Carnegie-Mellon University
Pittsburgh, PA 15213
</affiliation>
<sectionHeader confidence="0.892216" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.992353666666667">
The problem addressed in this paper is to
disambiguate grammatically ambiguous input
sentences by asking the user, who need not be a
computer specialist or a linguist, without showing any
parse trees or phrase structure rules. Explanation List
Comparison (ELC) is the technique that implements
this process. It is applicable to all parsers which are
based on phrase structure grammar, regardless of the
parser implementation. An experimental system has
been implemented at Carnegie-Mellon University, and it
has been applied to English-Japanese machine
translation at Kyoto University.
</bodyText>
<sectionHeader confidence="0.986629" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.997217">
A large number of techniques using semantic information have
been deve!oped to resolve natural language ambiguity. However,
not all ambiguity problems can be solved by those techniques at
the current state of art. Moreover, some sentences are absolutely
ambiguous, that is, even a human cannot disambiguate them.
Therefore, it is important tor the system to be capable of asking a
user questions interactively to disambiguate a sentence.
Here, we make an important condition that an user is neither a
computer scientist nor a linguist. Thus, an user may not recognize
any special terms or notations like a tree structure, phrase
structure grammar, etc.
The first system to disambiguate sentences by asking
interactively is perhaps a program called &amp;quot;disambiguator&amp;quot; in Kay&apos;s
MIND system [2]. Although the disambiguation algorithm is not
presented in [2], some basic ideas have been already
implemented in the Kay&apos;s system2. In this paper, we shall only
deal with grammatical ambiguity, or in other words, syntactic
ambiguity. Other ambiguity problems, such as word-sense
ambiguity and referential ambiguity, are excluded.
Suppose a system is given the sentence:
&amp;quot;Mary saw a man with a telescope&amp;quot;
</bodyText>
<footnote confidence="0.990853142857143">
1Thrz researcn was sponsored by the Defense Advanced Research Projects
Ageroy APPA Order No. 3597, monitored by the Air Force Avionics
Laboratory Undo Contract F33615-8i K-1539. The views and conclusions
caiita■neJ in this dncument are those of the authors and should not be interpreted
as representing the official policies. either expressed or implied, of the Defense
Advanced Research Projects Agency or the US Government.
2Personal communication.
</footnote>
<bodyText confidence="0.9545215">
and the system has a phrase structure grammar including the
following rules &lt;a&gt; - &lt;9&gt;:
</bodyText>
<figure confidence="0.729112142857143">
&lt;a&gt; S --&gt; NP + VP
&lt;b&gt; S --&gt; NP + VP + PP
&lt;c&gt; NP --&gt; *noun
&lt;d&gt; NP --&gt; *det + *noun
&lt;e&gt; NP --&gt; NP + PP
&lt;f&gt; PP --&gt; *prep + NP
&lt;g&gt; VP --&gt; *verb + NP
</figure>
<bodyText confidence="0.966228">
The system would produce two parse trees from the input
sentence (I. using rules &lt;b&gt;,&lt;c&gt;,&lt;g&gt;,&lt;d&gt;,&lt;f),&lt;d&gt;; II. using rules
&lt;a&gt;,&lt;c&gt;,&lt;g&gt;,&lt;e&gt;,&lt;d&gt;,&lt;D,&lt;d&gt;). The difference is whether the
preposition phrase &amp;quot;with a telescope&amp;quot; qualifies the noun phrase
&amp;quot;a man&amp;quot; or the sentence &amp;quot;Mary saw a man&amp;quot;. This paper shall
discuss on how to ask the use( to select his intended
interpretation without showing any kind of tree structures or
phrase structure grammar rules. Our desired question for that
sentence is thus something like:
</bodyText>
<listItem confidence="0.993275333333333">
1) The action &amp;quot;Mary saw a man&amp;quot; takes place &amp;quot;with a telescope&amp;quot;
2) &amp;quot;a man&amp;quot; is &amp;quot;with a telescope&amp;quot;
NUMBER?
</listItem>
<bodyText confidence="0.998859">
The technique to implement this, which is described in the
following sections, is called Explanation List Comparison.
</bodyText>
<sectionHeader confidence="0.987114" genericHeader="method">
2. Explanation List Comparison
</sectionHeader>
<bodyText confidence="0.999590666666667">
The basic idea is to attach an Explanation Template to each rule.
For example, each of the rules &lt;a&gt; - &lt;g&gt; would have an
explanation template as follows:
</bodyText>
<equation confidence="0.988155375">
Explanation Template
&apos;&lt;a&gt; ( 1) is a subject of the action (2)
&lt;b&gt; The action (1 2) takes place (3)
&lt;c&gt; ( 1) is a noun
&lt;d&gt; ( 1) is a determiner of (2)
&lt;e&gt; (1) is (2)
&lt;f&gt; (1) is a preposition of (2)
&lt;g&gt; (2) is an object of the verb (1)
</equation>
<bodyText confidence="0.99854675">
Whenever a rule is employed to parse a sentence, an
explanation is generated from its explanation template. Numbers
in an explanation template indicate n-th constituent of the right
hand side of the rule. For instance, when the rule &lt;f&gt;
</bodyText>
<equation confidence="0.552639">
PP --&gt; *prep + NP
</equation>
<bodyText confidence="0.397404">
matches &amp;quot;with a telescope&amp;quot; (*prep = &amp;quot;WITH&amp;quot;; NP = &amp;quot;a
</bodyText>
<page confidence="0.99718">
476
</page>
<bodyText confidence="0.928044777777778">
telescope&amp;quot;), the explanation
&amp;quot;(with) is a preposition of (a telescope)&amp;quot;
is generated. Whenever the system builds a parse tree, it also
builds a list of explanations wnich are generated from explanation
templates of all rules employed. We refer to such a list as an
explanation list. 1 he explanation lists of the parse trees in the
example above are:
Alternative I.
&lt;b&gt; The action (Mary saw a man) takes place (with a telescope)
</bodyText>
<equation confidence="0.997482384615385">
&lt;a&gt; (Mary) is a noun
&lt;g&gt; (a man) is an object of the verb (saw)
cd&gt; (A) is a determiner of (man)
&lt;f&gt; (with) is a preposition of (a telescope)
&lt;d&gt; (A) is a determiner of (telescope)
Alternative II.
&lt;a&gt; (Mary) is a subject of the action (saw a man with a telescope)
Cc&gt; (Mary) is a noun
&lt;g&gt; (a man with a telescope) is an object of the verb (saw)
&lt;0&gt; (a man) is (with a telescope)
&lt;d&gt; (A) is a determiner of (man)
&lt;f&gt; (with is a preposition of (a telescope)
&lt;d&gt; (A) is a determiner of (telescope)
</equation>
<bodyText confidence="0.999806142857143">
In order to disambiguate a sentence, the system only examines
these Explanation Lists, but not parse trees themselves. This
makes our method independent from internal representation of a
oal se tree. Loosely speaking, when a system produces more than
one parse tree, explanation lists of the trees are &amp;quot;compared&amp;quot; and
the &amp;quot;dilferelice&amp;quot; is shown to the user. The user is, then, asked to
select the correct alternative.
</bodyText>
<sectionHeader confidence="0.431687" genericHeader="method">
3. The revised version of ELC
</sectionHeader>
<bodyText confidence="0.990326555555555">
Unfortunately. the basic idea described in the preceding section
does riot work quite well. For instance, the difference of the two
explanation lists in our example is
The action (Mary saw a man) takes place (with a telescope),
inan) is an object of the verb (saw);
(Mary) is a subject of the action (saw a man with a telescope),
(a man with a telescope) is an object of the verb (saw),
(a man) is (with a telescope);
despite the fact that the essential difference is only
</bodyText>
<listItem confidence="0.9825045">
1) The action (Mary saw a man) takes place (with a telescope)
2) (a man) is (with a telescope)
</listItem>
<bodyText confidence="0.977306846153846">
Two refinement ideas, head and multiple explanations, are
introduced to solve this problem.
3.1. Head
We define head as a word or a minimal cluster of words which
are syntactically dominant in a group and could have the same
syntactic function as the whole group if they stood alone. For
example, the head of &amp;quot;VERY SMART PLAYERS IN NEW YORK&amp;quot; is
&amp;quot;PLAYERS&amp;quot;, and the head of &amp;quot;INCREDIBLY BEAUTIFUL&amp;quot; is
&amp;quot;BEAUTlFUL&amp;quot;, but the head of &amp;quot;I LOVE CATS&amp;quot; is &amp;quot;I LOVE CATS&amp;quot;
ilself. The idea is that. whenever the system shows a part of an
input sentence to the user, only the head of it is shown. To
implement this idea, each rule must have a head definition besides
an explanation template, as follows.
</bodyText>
<figure confidence="0.9832415">
Rule Head
&lt;a&gt; [1 2]
&lt;b&gt; [1 2]
&lt;c&gt; [I]
&lt;d&gt; [1 2]
&lt;e&gt; [1]
&lt;f) [1 2]
&lt;g&gt; [1 2]
</figure>
<bodyText confidence="0.970505714285714">
For instance, the head definition of the rule &lt;b&gt; says that the
head of the construction &amp;quot;NP + VP + PP&amp;quot; is a concatenation of
the head of 1-st constituent (NP) and the head of 2-nd constituent
(VP). The head of &amp;quot;A GIRL with A RED BAG saw A GREEN TREE
WITH a telescope&amp;quot; is, therefore, &amp;quot;A GIRL saw A TREE&amp;quot;, because
the head of &amp;quot;A GIRL with A RED BAG&amp;quot; (NP) is &amp;quot;A GIRL&amp;quot; and the
head of &amp;quot;saw A GREEN TREE&amp;quot; (VP) is &amp;quot;saw A TREE&amp;quot;.
In our example, the explanation
(Mary) is a subject of the action (saw a man with a telescope)
becomes
(Mary) is a subject of the action (saw a man),
and the explanation
(a man with a telescope) is an ob,ect of the verb (saw)
becomes
(a man) is an object of the verb (saw),
because the head of &amp;quot;saw a man with a telescope&amp;quot; is &amp;quot;saw a
man&amp;quot;, and the head of &amp;quot;a man with a telescope&amp;quot; is &amp;quot;a man&amp;quot;.
The difference of the two alternatives are now:
The action (Mary saw a man) take place (with a telescope);
(Mary) is a subject of the action (saw a man),
(a man) is (with a telescope);
</bodyText>
<subsectionHeader confidence="0.72132">
3.2. Multiple explanations
</subsectionHeader>
<bodyText confidence="0.99742475">
In the example system we have discussed above, each rule
generates exactly one explanation.. In general, multiple
explanations (including zero) can be generated by each rule. For
example, rule &lt;b&gt;
</bodyText>
<equation confidence="0.863128">
S --&gt; NP + VP + PP
</equation>
<bodyText confidence="0.87846875">
should have two explanation templates:
(1) is a subject of the action (2)
The action (1 2) takes place (3),
whereas rule &lt;a&gt;
</bodyText>
<equation confidence="0.679676">
S --&gt; NP + VP
should have only one explanation template:
(1) is a subject of the action (2).
</equation>
<bodyText confidence="0.9985595">
With the idea of head and multiple explanations, the system now
produces the ideal question, as we shall see below.
</bodyText>
<subsectionHeader confidence="0.611612">
3.3. Revised ELC
</subsectionHeader>
<bodyText confidence="0.979524">
To summarize, the system has a phrase structure grammar, and
each rule is followed by a head definition followed by an arbitrary
number of explanation templates.
</bodyText>
<page confidence="0.986204">
477
</page>
<table confidence="0.868513777777778">
Rule Head Explanation Template
&lt;a&gt; [1 2] (1) is a subject of the action (2)
&lt;b&gt; [1 2] (1) is a subject of the action (2)
The action (1 2) takes place (3)
&lt;c&gt; [1] &lt;&lt;none&gt;&gt;
&lt;d&gt; [1 2] (1) is a determiner of (2)
&lt;e&gt; [1] (1) is (2)
&lt;1&gt; [1 2] is a preposition of (2)
&lt;g&gt; [1 2] is an object of the verb (1)
</table>
<bodyText confidence="0.816826333333333">
With the ideas of head and multiple explanation, the system
builds the following two explanation lists from the sentence &amp;quot;Mary
saw a man with a telescope&amp;quot;.
</bodyText>
<equation confidence="0.8791175">
Alternative I.
&lt;b&gt; (Mary) is a subject of the action (saw a man)
&lt;b&gt; The action (Mary saw a man) takes place (with a telescope)
&lt;g&gt; (a man) is an object of the verb (saw)
&lt;d&gt; (A) is a determiner of (man)
&lt;f&gt; (with) is a preposition of (a telescope)
&lt;d&gt; (A) is a determiner of (telescope)
Alternative II.
&lt;a&gt; (Mary) is a subject of the action (saw a man)
&lt;g&gt; (a man) is an object of the verb (saw)
&lt;e&gt; (a man) is (with a telescope)
&lt;d&gt; (A) is a determiner of (man)
&lt;f&gt; (with is a preposition of (a telescope)
&lt;d&gt; (A) is a determiner of (telescope)
</equation>
<bodyText confidence="0.9966618">
The difference between these two is
The action (Mary saw a man) takes place (with a telescope)
and
(a man) is (with a telescope).
Thus, the system can ask the ideal question:
</bodyText>
<listItem confidence="0.988853333333333">
1) The action (Mary saw a man) takes place (with a telescope)
2) (a man) is (with a telescope)
Number?
</listItem>
<sectionHeader confidence="0.597651" genericHeader="method">
4. More Complex Example
</sectionHeader>
<bodyText confidence="0.988490222222222">
The example in the preceding sections is somewhat
oversimplified, in the sense that there are only two alternatives
and only two explanation lists are compared. If there were three
or more alternatives, comparing explanation lists would be not as
easy as comparing just two.
Consider the following example sentence:
Mary saw a man in the park with a telescope.
This ser.tence is ambiguous in 5 ways, and its 5 explanation lists
are shown below.
</bodyText>
<equation confidence="0.72130725">
Alternative I.
(a man) is (in the park)
(the park) is (with a telescope)
. .
</equation>
<listItem confidence="0.962609">
• No explanation list L in A contains more than one
explanation in a Qlist. That is,
</listItem>
<figure confidence="0.997824161290323">
Alternative II.
(a man) is (with a telescope)
(a man) is (in the park)
. .
Alternative III.
The action (Mary saw a man) takes place (with a telescope)
(a man) is (in the park)
. .
. .
. .
Alternative IV.
The action (Mary saw a man) takes place (in the park)
(the park) is (with a telescope)
• •
• •
. .
Alternative V.
The action (Mary saw a man) takes place (with a telescope)
The action (Mary saw a man) takes place (in the park)
. .
• •
. .
With these 5 explanation lists, the system asks the user a
question twice, as follows:
1) (a man) is (in the park)
2) The action (Mary saw a man) takes place (in the park)
NUMBER? 1
1) (the park) is (with a telescope)
2) (a man) is (with a telescope)
3) The action (Mary saw a man) takes place (with a telescope)
NUMBER? 3
</figure>
<bodyText confidence="0.900583">
The implementation of this is described in the following.
We refer to the set of explanation lists to be compared, a 1, L2, ...
), as A. If the number of explanation lists in A is one ; just return
the parsed tree which is associated with that explanation list. If
there are more than one explanation list in A, the system makes a
()list (Question list). The ()list is a list of explanations
</bodyText>
<equation confidence="0.468375833333333">
Qlist = e1, e2, , en)
which is shown to the user to ask a question as follows:
1) el
2) e2
n) en
Number?
</equation>
<bodyText confidence="0.736789125">
()list must satisfy the following two conditions to make sure that
always exactly one explanation is true.
• Each explanation list L in A must contain at least one
explanation e which is also in Olist. Mathematically,
the following predicate must be satisfied.
VL 3e(e EL A e E Qlist)
This condition makes sure that at least one of
explanations in a Qlist is true.
</bodyText>
<page confidence="0.983726">
478
</page>
<bodyText confidence="0.996412538461539">
e(3L3e3e.(LEAAeEL Ae&apos;EL
A e G Quist A e&apos; E Quist A ,e oe&apos;)
This condition makes sure that at most one of
explanations in Qlist is true.
The detailed algorithm of how to construct a Quist is presented in
Appendix.
Once a Quist is created, it is presented to the user. The user is
asked to select one correct explanation in the Olist, called the key
explanation. All explanation lists which do riot contain the key
explanation are removed from A. If A still contains more than one
explanation list, another Olist for this new A is created, and shown
to the user. This process is repeated until A contains only one
explanation list.
</bodyText>
<sectionHeader confidence="0.891163" genericHeader="method">
5. Concluding Remarks
</sectionHeader>
<bodyText confidence="0.99993524">
An experimental system has been written in Maclisp, and
running on Tops-20 at Computer Science Department, Carnegie-
Mellon University. The system parses input sentences provided by
a user according to grammar rules and a dictionary provided by a
super user. The system, then, asks the user questions, if
necessary, to disambiguate the sentence using the technique of
Explanation List Comparison. The system finally produces only
one parse tree of the sentence, which is the intended
interpretation of the user. 1 he parser is implemented in a bottom-
up, breath-first manner, but the idea described in the paper is
independent from the parser implementation and from any
specific grammar or dictionary.
The kind of ambiguity we have discussed is structural ambiguity.
An ambiguity is structural when two different structures can be
built up out of smaller constituents of the same given structure
and type. On the other hand, an ambiguity is lexical when one
word can serve as various parts of speech. Resolving lexical
ambiguity is somewhat easier, and indeed, it is implemented in the
system. As we can see in the Sample Runs below, the system first
resolves lexical ambiguity in the obvious manner, if necessary.
Recently, we have integrated our system into an English.
Japanese Machine Translation system [3], as a first step toward
user-friendly interactive machine translation [6]. The interactive
English Japanese machine translation system has been
implemented at Kyoto University in Japan [4, 5].
</bodyText>
<sectionHeader confidence="0.994209" genericHeader="method">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99981225">
I would like to thank Jaime Carbonell, Herb Simon,
Martin Kay. Jun-ich Tsujii, Toyoaki Nishida, Shuji
Doshita and Makoto Nagao for thoughtful comments
on an earlier version of this paper.
</bodyText>
<sectionHeader confidence="0.852184" genericHeader="method">
Appendix A: Quist-Construction Algorithm
</sectionHeader>
<figure confidence="0.843589428571429">
input A : set of explanation lists
output ()list : set of explanations
local e : explanation
L :explanation list (set of explanations)
U,C :set of explanation lists
1: C = 1%
2: U = A
</figure>
<listItem confidence="0.988507461538461">
3: ()list =
4: it U = 0 then return ()list
5: select one explanation e such that
e is in some explanation list E U,
but not in any explanation list G C;
if no such e exists, return ERROR
6: Olist Olist + {e}
7: C=C+ leEL AL EU)
8: U={1.1e0L AL E(U)}
9: goto 4
• The input to this procedure is a set of explanation
lists, {Li, L 2,
• The output of this procedure is a list of explanations,
</listItem>
<bodyText confidence="0.963373">
{e1&apos; e2&apos; &amp;quot; . en&apos; ) such that each explanation list, L.,
contains exactly one explanation which is in the Quist.
</bodyText>
<listItem confidence="0.981658">
• An explanation list L is called covered, if some
</listItem>
<bodyText confidence="0.984866">
explanation e in L is also in Quist. L is called
uncovered, if any of the explanations in L is not in
Olist. C is a set of covered explanation lists in A, and
U is a set of uncovered explanation lists in A.
</bodyText>
<listItem confidence="0.9960135">
• 1-3: initialization. Let Olist be empty. All explanation
lists in A are uncovered.
• 4: if all explanation lists are covered, quit.
• 5-6: select an explanation e and put it into Qlist to
</listItem>
<bodyText confidence="0.892404">
cover some of uncovered not explanation lists. e
must be such that it does exist in any of covered
explanation lists (if it does exist, the explanation list
has two explanation in A, violating the Olist
condition).
</bodyText>
<listItem confidence="0.999858666666667">
• 7-8: make uncovered explanation lists which are now
covered bye to be covered.
• 9: repeat the process until everything is covered.
</listItem>
<page confidence="0.999131">
479
</page>
<sectionHeader confidence="0.985045" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.946124">
Kay, M.
The MIND System.
Algorithmic Press, New York, 1973,.
Nishida, T. and Doshita, S.
An Application of Montague Grammar to English-Japanese
Machine Translation.
Proceedings of conference on Applied Natural Language
Processing :156-165,1983.
[3] Tomita, M., Nishida, T. and Doshita, S.
An Interactive English-Japanese Machine Translation
System.
Forthcoming (in Japanese), 1984.
[4] Tomita, M., Nishida, T. and Doshita, S.
User Front-End for disambiguation in Interactive Machine
Translation System.
In Tech. Reports of WGNLP. Information Processing
Society of Japan, (in Japanese, forthcoming), 1984.
[5] Tomita, M.
The Design Philosophy of Personal Machine Translation
System.
Technical Report, Computer Science Department,
Carnegie-Mellon University, 1983.
</reference>
<sectionHeader confidence="0.602954" genericHeader="method">
Appendix E3: Sample Runs
</sectionHeader>
<figure confidence="0.935252212121212">
(transline *(time flies like an arrow in Japan))
(—END OF PARSE-- 10 ALTERNATIVES)
(The word TIME (I) is:)
(1 : VERB)
(2 : NOUN)
NUMBER&gt; g
(The word FLIES (2) is:)
(I : VERB)
(2 : NOUN)
NUMBER&gt; 1
(1 : (AN ARROW) IS (IN JAPAN))
(2 : THE ACTION (TIME FLIES) TAKES PLACE (IN JAPAN))
NUMBER&gt; L
(S (NP (TIME *NOUN))
(FLIES *VERB)
(PP (LIKE *PREPOSITION) (NP (AN *DETERMINER) (ARROW *NOUN)))
(PP (IN *PREPOSITION) (JAPAN *NOUN)))
(transline &apos;(Mare saw a man in the apartment with a telescope))
(---END OF PARSE-- 5 ALTERNATIVES)
(1 : (A MAN) IS (IN THE APARTMENT))
(2 : THE ACTION (MARY SAW A MAN) TAKES PLACE (IN THE APARTMENT))
NUMBER&gt;
(I : (A MAN) IS (WITH A TELESCOPE))
(2 : (THE APARTMENT) IS (WITH A TELESCOPE))
(3 : THE ACTION (MARY SAW A MAN) TAKES PLACE (WITH A TELESCOPE))
NUMBER&gt; 3
(S (NP (MARY *NOUN))
(VP (SAW *VERB)
(NP (NP (A &apos;DETERMINER) (MAN &apos;NOUN))
(PP (IN *PREPOSIFION)
(NP ([HE *DETERMINER) (APARTMENT *NOUN)))))
(PP (WITH &apos;PREPOSITION)
(NP (A *DETERMINER) (TELESCOPE &amp;quot;NOUN))))
</figure>
<page confidence="0.981094">
480
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.411728">
<title confidence="0.9986405">Disambiguating Grammatically Ambiguous Sentences</title>
<author confidence="0.7657475">By Asking Maseru Tomita</author>
<affiliation confidence="0.999963">Computer Science Department Carnegie-Mellon University</affiliation>
<address confidence="0.999911">Pittsburgh, PA 15213</address>
<abstract confidence="0.982534923076923">The problem addressed in this paper is to disambiguate grammatically ambiguous input sentences by asking the user, who need not be a computer specialist or a linguist, without showing any parse trees or phrase structure rules. Explanation List Comparison (ELC) is the technique that implements this process. It is applicable to all parsers which are based on phrase structure grammar, regardless of the parser implementation. An experimental system has been implemented at Carnegie-Mellon University, and it has been applied to English-Japanese machine translation at Kyoto University.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>M Kay</author>
</authors>
<title>The MIND System.</title>
<marker>Kay, </marker>
<rawString>Kay, M. The MIND System.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Nishida</author>
<author>S Doshita</author>
</authors>
<date>1973</date>
<publisher>Algorithmic Press,</publisher>
<location>New York,</location>
<marker>Nishida, Doshita, 1973</marker>
<rawString>Algorithmic Press, New York, 1973,. Nishida, T. and Doshita, S.</rawString>
</citation>
<citation valid="false">
<title>An Application of Montague Grammar to English-Japanese Machine Translation.</title>
<marker></marker>
<rawString>An Application of Montague Grammar to English-Japanese Machine Translation.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Tomita</author>
<author>T Nishida</author>
<author>S Doshita</author>
</authors>
<booktitle>Proceedings of conference on Applied Natural Language Processing :156-165,1983. [3]</booktitle>
<marker>Tomita, Nishida, Doshita, </marker>
<rawString>Proceedings of conference on Applied Natural Language Processing :156-165,1983. [3] Tomita, M., Nishida, T. and Doshita, S.</rawString>
</citation>
<citation valid="false">
<title>An Interactive English-Japanese Machine Translation System.</title>
<marker></marker>
<rawString>An Interactive English-Japanese Machine Translation System.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Forthcoming</author>
</authors>
<title>User Front-End for disambiguation in Interactive Machine Translation System.</title>
<date>1984</date>
<marker>Forthcoming, 1984</marker>
<rawString>Forthcoming (in Japanese), 1984. [4] Tomita, M., Nishida, T. and Doshita, S. User Front-End for disambiguation in Interactive Machine Translation System.</rawString>
</citation>
<citation valid="true">
<authors>
<author>In Tech</author>
</authors>
<title>Reports of WGNLP.</title>
<date>1984</date>
<journal>Information Processing Society of Japan, (in Japanese,</journal>
<volume>forthcoming),</volume>
<note>[5] Tomita, M.</note>
<marker>Tech, 1984</marker>
<rawString>In Tech. Reports of WGNLP. Information Processing Society of Japan, (in Japanese, forthcoming), 1984. [5] Tomita, M.</rawString>
</citation>
<citation valid="false">
<title>The Design Philosophy of Personal Machine Translation System.</title>
<marker></marker>
<rawString>The Design Philosophy of Personal Machine Translation System.</rawString>
</citation>
<citation valid="false">
<date>1983</date>
<tech>Technical Report,</tech>
<institution>Computer Science Department, Carnegie-Mellon University,</institution>
<marker>1983</marker>
<rawString>Technical Report, Computer Science Department, Carnegie-Mellon University, 1983.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>