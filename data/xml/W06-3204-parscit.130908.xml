<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.306127">
<title confidence="0.987921">
Invited Talk:
Universal Constraint Rankings Result from Learning and Evolution
</title>
<author confidence="0.998496">
Paul Boersma
</author>
<affiliation confidence="0.9978735">
Institute of Phonetic Sciences
University of Amsterdam
</affiliation>
<address confidence="0.85542">
Herengracht 338
1016CG Amsterdam, The Netherlands
</address>
<email confidence="0.996356">
paul.boersma@uva.nl
</email>
<sectionHeader confidence="0.984849" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999953923076923">
Optimality Theory has met with a bad press in the more emergentist (e.g. computational) lit-
erature for its reliance on innate constraints and even on innate constraint rankings (positional
faithfulness, licensing by cue). In this talk I will show with computer simulations that even if
the learner’s initial grammar starts with a large number of constraints that have no inherent bias
towards unmarked or otherwise good sound systems, the learner will gradually turn the constraint
ranking into something resembling a universally unmarked sound system as an automatic result
of input frequencies and imperfections of the transmission channel. It turns out that the parents’
sound system is ”semi-learnable”: if the parents’ sound system happens to be universally marked,
the offspring will learn to mimic the quirks of this system to some extent, but they will tend
to turn the language into a universally unmarked sound system within three generations or so.
The conclusion will be that a bidirectional Optimality-Theoretic model of the grammar with two
phonological and two phonetic representations is compatible with the view that there is no innate
phonological substance in language acquisition.
</bodyText>
<page confidence="0.997482">
31
</page>
<note confidence="0.42782">
Proceedings of the Eighth Meeting of the ACL Special Interest Group on Computational Phonology at HLT-NAACL 2006, page 31,
New York City, USA, June 2006. c�2006 Association for Computational Linguistics
</note>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.289194">
<title confidence="0.94877">Invited Talk: Universal Constraint Rankings Result from Learning and Evolution</title>
<author confidence="0.992944">Paul</author>
<affiliation confidence="0.961251666666667">Institute of Phonetic University of Herengracht</affiliation>
<address confidence="0.976317">1016CG Amsterdam, The</address>
<email confidence="0.984922">paul.boersma@uva.nl</email>
<abstract confidence="0.943002625">Optimality Theory has met with a bad press in the more emergentist (e.g. computational) literature for its reliance on innate constraints and even on innate constraint rankings (positional faithfulness, licensing by cue). In this talk I will show with computer simulations that even if the learner’s initial grammar starts with a large number of constraints that have no inherent bias towards unmarked or otherwise good sound systems, the learner will gradually turn the constraint ranking into something resembling a universally unmarked sound system as an automatic result of input frequencies and imperfections of the transmission channel. It turns out that the parents’ sound system is ”semi-learnable”: if the parents’ sound system happens to be universally marked, the offspring will learn to mimic the quirks of this system to some extent, but they will tend to turn the language into a universally unmarked sound system within three generations or so. The conclusion will be that a bidirectional Optimality-Theoretic model of the grammar with two phonological and two phonetic representations is compatible with the view that there is no innate phonological substance in language acquisition. 31 of the Eighth Meeting of the ACL Special Interest Group on Computational Phonology at HLT-NAACL page 31,</abstract>
<intro confidence="0.424292">York City, USA, June 2006. Association for Computational Linguistics</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>