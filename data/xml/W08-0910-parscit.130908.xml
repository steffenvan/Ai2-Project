<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014449">
<title confidence="0.976575">
Retrieval of Reading Materials for Vocabulary and Reading Practice
</title>
<author confidence="0.998826">
Michael Heilman, Le Zhao, Juan Pino and Maxine Eskenazi
</author>
<affiliation confidence="0.878411">
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213, USA
</affiliation>
<email confidence="0.999544">
{mheilman,lezhao,jmpino,max}@cs.cmu.edu
</email>
<sectionHeader confidence="0.998604" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.994701785714286">
Finding appropriate, authentic reading mate-
rials is a challenge for language instructors.
The Web is a vast resource of texts, but most
pages are not suitable for reading practice, and
commercial search engines are not well suited
to finding texts that satisfy pedagogical con-
straints such as reading level, length, text qual-
ity, and presence of target vocabulary. We
present a system that uses various language
technologies to facilitate the retrieval and pre-
sentation of authentic reading materials gath-
ered from the Web. It is currently deployed in
two English as a Second Language courses at
the University of Pittsburgh.
</bodyText>
<sectionHeader confidence="0.999491" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999982346938776">
Reading practice is an important component of first
and second language learning, especially with re-
gards to vocabulary learning (Hafiz and Tudor,
1989). Appropriating suitable reading material for
the needs of a particular curriculum or particular stu-
dent, however, is a challenging process. Manually
authoring or editing readings is time-consuming and
raises issues of authenticity, which are particularly
significant in second language learning (Peacock,
1997). On the other hand, the Web is a vast resource
of authentic reading material, but commercial search
engines which are designed for a wide variety of in-
formation needs may not effectively facilitate the re-
trieval of appropriate readings for language learners.
In order to demonstrate the problem of finding ap-
propriate reading materials, here is a typical exam-
ple of an information need from a teacher of an En-
glish as a Second Language (ESL) course focused
on reading skills. This example was encountered
during the development of the system. It should
be noted that while we describe the system in the
context of ESL, we claim that the approach is gen-
eral enough to be applied to first language reading
practice and to languages other than English. To
fit within his existing curriculum, the ESL teacher
wanted to find texts on the specific topic of “interna-
tional travel.” He sought texts that contained at least
a few words from the list of target vocabulary that
his student were learning that week. In addition, he
needed the texts to be within a particular range of
reading difficulty, fifth to eighth grade in an Ameri-
can school, and shorter than a thousand words.
Sending the query “international travel” to a pop-
ular search engine did not produce a useful list of re-
sults1. The first result was a travel warning from the
Department of State2, which was at a high reading
level (grade 10 according to the approach described
by (Heilman et al., 2008)) and not likely to be of
interest to ESL students because of legal and techni-
cal details. Most of the subsequent results were for
commercial web sites and travel agencies. A query
for a subset of the target vocabulary words for the
course also produced poor results. Since the search
engine used strict boolean retrieval methods, the top
results for the query “deduce deviate hierarchy im-
plicit undertake” were all long lists of ESL vocabu-
lary words3.
We describe a search system, called REAP
Search, that is tailored to the needs of language
</bodyText>
<footnote confidence="0.999575333333333">
1www.google.com, March 5, 2008
2http://travel.state.gov/travel/cis pa tw/cis pa tw 1168.html
3e.g., www.espindle.org/university word list uwl.html
</footnote>
<page confidence="0.930241">
80
</page>
<note confidence="0.739288">
Proceedings of the Third ACL Workshop on Innovative Use of NLP for Building Educational Applications, pages 80–88,
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.999795590909091">
teachers and learners. The system facilitates the re-
trieval of texts satisfying particular pedagogical con-
straints such as reading level and text length, and al-
lows the user to constrain results so that they con-
tain at least some, but not necessarily all, of the
words from a user-specified target vocabulary list.
It also filters out inappropriate material as well as
pages that do not contain significant amounts of text
in well-formed sentences. The system provides sup-
port for learners including an interface for reading
texts, easy access to dictionary definitions, and vo-
cabulary exercises for practice and review.
The educational application employs multiple
language technologies to achieve its various goals.
Information retrieval and web search technologies
provide the core components. Automated text clas-
sifiers organize potential readings by general topic
area and reading difficulty. We are also developing
an approach to measuring reading difficulty that uses
a parser to extract grammatical structures. Part of
Speech (POS) tagging is used to filter web pages to
maintain text quality.
</bodyText>
<sectionHeader confidence="0.662045" genericHeader="introduction">
2 Path of a Reading
</sectionHeader>
<bodyText confidence="0.999931941176471">
In the REAP Search system, reading materials take a
path from the Web to students through various inter-
mediate steps as depicted in Figure 1. First, a crawl-
ing program issues queries to large-scale commer-
cial search engines to retrieve candidate documents.
These documents are annotated, filtered, and stored
in a digital library, or corpus. This digital library cre-
ation process is done offline. A customized search
interface facilitates the retrieval of useful reading
materials by teachers, who have particular curricu-
lar goals and constraints as part of their information
needs. The teachers organize their selected readings
through a curriculum manager. The reading inter-
face for students accesses the curriculum manager’s
database and provides the texts along with support
in the form of dictionary definitions and practice ex-
ercises.
</bodyText>
<sectionHeader confidence="0.884156" genericHeader="method">
3 Creating a Digital Library of Readings
</sectionHeader>
<bodyText confidence="0.9997307">
The foundation of the system is a digital library of
potential reading material. The customized search
component does not search the Web directly, but
rather accesses this filtered and annotated database
of Web pages. The current library consists of ap-
proximately five million documents. Construction
of the digital library begins with a set of target vo-
cabulary words that might be covered by a course or
set of courses (typically 100-1,500 words), and a set
of constraints on text characteristics. The constraints
can be divided into three sets: those that can be ex-
pressed in a search engine query (e.g., target words,
number of target words per text, date, Web domain),
those that can be applied using just information in
the Web search result list (e.g., document size), and
those that require local annotation and filtering (e.g.,
reading level, text quality, profanity).
The system obtains candidate documents by
query-based crawling, as opposed to following
chains of links. The query-based document crawl-
ing approach is designed to download documents
for particular target words. Queries are submitted
to a commercial Web search engine4, result links are
downloaded, and then the corresponding documents
are downloaded. A commercial web search engine
is used to avoid the cost of maintaining a massive,
overly general web corpus.
Queries consist of combinations of multiple tar-
get words. The system generates 30 queries for each
target word (30 is a manageable and sufficient num-
ber in practice). These are spread across 2-, 3-,
and 4-word combinations with other target words.
Queries to search engines can often specify a date
range. We employ ranges to find more recent mate-
rial, which students prefer. The tasks of submitting
queries, downloading the result pages, and extract-
ing document links are distributed among a dozen
or so clients running on desktop machines, to run as
background tasks. The clients periodically upload
their results to a server, and request a new batch of
queries.
Once the server has a list of candidate pages, it
downloads them and applies various filters. The fi-
nal yield of texts is typically approximately one per-
cent of the originally downloaded results. Many web
pages are too long, contain too little well-formed
text, or are far above the appropriate reading level
for language learners. After downloading docu-
ments, the system annotates them as described in
the next section. It then stores the pages in a full-
</bodyText>
<footnote confidence="0.994792">
4www.altavista.com
</footnote>
<page confidence="0.99831">
81
</page>
<figureCaption confidence="0.999905">
Figure 1: Path of Reading Materials from the Web to a Student.
</figureCaption>
<bodyText confidence="0.999895833333333">
text search engine called Indri, which is part of
the Lemur Toolkit5. This index provides a consis-
tent and efficient interface to the documents. Using
Lemur and the Indri Query Language allows for the
retrieval of annotated documents according to user-
specified constraints.
</bodyText>
<sectionHeader confidence="0.974091" genericHeader="method">
4 Annotations and Filters
</sectionHeader>
<bodyText confidence="0.999987">
Annotators automatically tag the documents in the
corpus to enable the filtering and retrieval of read-
ing material that matches user-specified pedagogical
constraints. Annotations include reading difficulty,
general topic area, text quality, and text length. Text
length is simply the number of word tokens appear-
ing in the document.
</bodyText>
<subsectionHeader confidence="0.999604">
4.1 Reading Level
</subsectionHeader>
<bodyText confidence="0.9998954">
The system employs a language modeling ap-
proach developed by Collins-Thompson and Callan
(Collins-Thompson and Callan, 2005) that creates a
model of the lexicon for each grade level and pre-
dicts reading level, or readability, of given docu-
ments according to those models. The readabil-
ity predictor is a specialized Naive Bayes classi-
fier with lexical unigram features. For web docu-
ments in particular, Collins-Thompson and Callan
report that this language modeling-based prediction
has a stronger correlation with human-assigned lev-
els than other commonly used readability measures.
This automatic readability measure allows the sys-
tem to satisfy user-specified constraints on reading
difficulty.
We are also experimenting with using syntac-
tic features to predict reading difficulty. Heilman,
Collins-Thompson, and Eskenazi (Heilman et al.,
2008) describe an approach that combines predic-
tions based on lexical and grammatical features. The
</bodyText>
<footnote confidence="0.896935">
5www.lemurproject.org
</footnote>
<bodyText confidence="0.999907555555556">
grammatical features are frequencies of occurrence
of grammatical constructions, which are computed
from automatic parses of input texts. Using multiple
measures of reading difficulty that focus on different
aspects of language may allow users more freedom
to find texts that match their needs. For example,
a teacher may want to find grammatically simpler
texts for use in a lesson focused on introducing dif-
ficult vocabulary.
</bodyText>
<subsectionHeader confidence="0.997799">
4.2 General Topic Area
</subsectionHeader>
<bodyText confidence="0.995956653846154">
A set of binary topic classifiers automatically clas-
sifies each potential reading by its general topic, as
described by Heilman, Juffs, and Eskenazi (2007).
This component allows users to search for readings
on their general interests without specifying a par-
ticular query (e.g., “international travel”) that might
unnecessarily constrain the results to a very narrow
topic.
A Linear Support Vector Machine text classifier
(Joachims, 1999) was trained on Web pages from
the Open Directory Project (ODP)6. These pages ef-
fectively have human-assigned topic labels because
they are organized into a multi-level hierarchy of
topics. The following general topics were manually
selected from categories in the ODP: Movies and
Theater; Music; Visual Arts; Computers and Tech-
nology; Business; Math, Physics and Chemistry; Bi-
ology and Environment; Social Sciences; Health and
Medicine; Fitness and Nutrition; Religion; Politics;
Law and Crime; History; American Sports; and Out-
door Recreation.
Web pages from the ODP were used as gold-
standard labels in the training data for the classi-
fiers. SVM-Light (Joachims, 1999) was used as an
implementation of the Support Vector Machines. In
preliminary tests, the linear kernel produced slightly
</bodyText>
<footnote confidence="0.738604">
6dmoz.org
</footnote>
<page confidence="0.996771">
82
</page>
<bodyText confidence="0.999964714285714">
better performance than a radial basis function ker-
nel. The values of the decision functions of the clas-
sifiers for each topic are used to annotate readings
with their likely topics.
The binary classifiers for each topic category were
evaluated according to the F1 measure, the harmonic
mean of precision and recall, using leave-one-out
cross-validation. Values for the F1 statistic range
from .68 to .86, with a mean value of .76 across
topics. For comparison, random guessing would be
expected to correctly choose the gold-standard label
only ten percent of the time. During an error analy-
sis, we observed that many of the erroneous classifi-
cations were, in fact, plausible for a human to make
as well. Many readings span multiple topics. For
example, a document on a hospital merger might be
classified as “Health and Medicine” when the cor-
rect label is “Business.” In the evaluation, the gold
standard included only the single topic specified by
the ODP. The final system, however, assigns multi-
ple topic labels when appropriate.
</bodyText>
<subsectionHeader confidence="0.999147">
4.3 Text Quality
</subsectionHeader>
<bodyText confidence="0.999959045454546">
A major challenge of using Web documents for ed-
ucational applications is that many web pages con-
tain little or no text in well-formed sentences and
paragraphs. We refer to this problem as “Text Qual-
ity.” Many pages consist of lists of links, navigation
menus, multimedia, tables of numerical data, etc. A
special annotation tool filters out such pages so that
they do not clutter up search results and make it dif-
ficult for users to find suitable reading materials.
The text quality filter estimates the proportion of
the word tokens in a page that are contained in well-
formed sentences. To do this it parses the Document
Object Model structure of the web page, and orga-
nizes it into text units delineated by the markup tags
in the document. Each new paragraph, table ele-
ment, span, or divider markup tag corresponds to the
beginning of a new text unit. The system then runs
a POS tagger7 over each text unit. We have found
that a simple check for whether the text unit con-
tains both a noun and a verb can effectively distin-
guish between content text units and those text units
that are just part of links, menus, etc. The proportion
</bodyText>
<footnote confidence="0.8458105">
7The OpenNLP toolkit’s tagger was used
(opennlp.sourceforge.net).
</footnote>
<bodyText confidence="0.9997955">
of the total tokens that are part of content text units
serves as a useful measure of text quality. We have
found that a threshold of about 85% content text is
appropriate, since most web pages contain at least
some non-content text in links, menus, etc. This ap-
proach to content extraction is related to previous
work on increasing the accessibility of web pages
(Gupta et al., 2003).
</bodyText>
<sectionHeader confidence="0.970813" genericHeader="method">
5 Constructing Queries
</sectionHeader>
<bodyText confidence="0.999971833333333">
Users search for readings in the annotated corpus
through a simple interface that appears similar to,
but extends the functionality of, the interfaces for
commercial web search engines. Figure 2 shows
a screenshot of the interface. Users have the op-
tion to specify ad hoc queries in a text field. They
can also use drop down menus to specify optional
minimum and/or maximum reading levels and text
lengths. Another optional drop-down menu allows
users to constrain the general topic area of results. A
separate screen allows users to specify a list of tar-
get vocabulary words, some but not all of which are
required to appear in the search results. For ease of
use, the target word list is stored for an entire session
(i.e., until the web browser application is closed)
rather than specified with each query. After the user
submits a query, the system displays multiple results
per screen with titles and snippets.
</bodyText>
<subsectionHeader confidence="0.981377">
5.1 Ranked versus Boolean Retrieval
</subsectionHeader>
<bodyText confidence="0.999948941176471">
In a standard boolean retrieval model, with AND as
the default operator, the results list consists of doc-
uments that contain all query terms. In conjunc-
tion with relevance ranking techniques, commercial
search engines typically use this model, a great ad-
vantage of which is speed. Boolean retrieval can en-
counter problems when queries have many terms be-
cause every one of the terms must appear in a doc-
ument for it to be selected. In such cases, few or
no satisfactory results may be retrieved. This issue
is relevant because a teacher might want to search
for texts that contain some, but not necessarily all,
of a list of target vocabulary words. For example,
a teacher might have a list of ten words, and any
text with five of those words would be useful to give
as vocabulary and reading practice. In such cases,
ranked retrieval models are more appropriate be-
</bodyText>
<page confidence="0.997899">
83
</page>
<figureCaption confidence="0.999852">
Figure 2: Screenshot of Search Interface for Finding Appropriate Readings.
</figureCaption>
<bodyText confidence="0.999898642857143">
cause they do not require that all of the query terms
appear. Instead, these models prefer multiple occur-
rences of different word types as opposed to multiple
occurrences of the same word tokens, allowing them
to rank documents with more distinct query terms
higher than those with distinct query terms. Docu-
ments that contain only some of the query terms are
thus assigned nonzero weights, allowing the user to
find useful texts that contain only some of the target
vocabulary. The REAP search system uses the Indri
Query Language’s “combine” and “weight” opera-
tors to implement a ranked retrieval model for target
vocabulary. For more information on text retrieval
models, see (Manning et al., 2008).
</bodyText>
<subsectionHeader confidence="0.99895">
5.2 Example Query
</subsectionHeader>
<bodyText confidence="0.999827551724138">
Figure 3 shows an example of a structured query
produced by the system from a teacher’s original
query and constraints. This example was slightly
altered from its original form for clarity of presen-
tation. The first line with the filrej operator filters
and rejects any documents that contain any of a long
list of words considered to be profanity, which are
omitted in the illustration for brevity and posterity.
The filreq operator in line 2 requires that all of the
constraints on reading level, text length and quality
in lines 2-4 are met. The weight operator at the start
of line 5 balances between the ad hoc query terms in
line 5 and the user-specific target vocabulary terms
in lines 6-8. The uw10 operator on line 5 tells the
system to prefer texts where the query terms appear
together in an unordered window of size 10. Such
proximity operators cause search engines to prefer
documents in which query terms appear near each
other. The implicit assumption is that the terms in
queries such as “coal miners safety” are more likely
to appear in the same sentence or paragraph in rele-
vant documents than irrelevant ones, even if they do
not appear consecutively. Importantly, query terms
are separated from target words because there are
usually a much greater number of target words, and
thus combining the two sets would often result in
the query terms being ignored. The higher weight
assigned to the set of target words ensures they are
not ignored.
</bodyText>
<sectionHeader confidence="0.98961" genericHeader="method">
6 Learner and Teacher Support
</sectionHeader>
<bodyText confidence="0.95973175">
In addition to search facilities, the system provides
extensive support for students to read and learn from
texts as well as support for teachers to track stu-
dents’ progress. All interfaces are web-based for
easy access and portability. Teachers use the search
system to find readings, which are stored in a cur-
riculum manager that allows them to organize their
selected texts. The manager interface allows teach-
ers to perform tasks such as specifying the order
of presentation of their selected readings, choosing
target words to be highlighted in the texts to focus
learner attention, and specifying time limits for each
text.
The list of available readings are shown to stu-
dents when they log in during class time or for
homework. Students select a text to read and move
on to the reading interface, which is illustrated in
Figure 4. The chosen web page is displayed in its
original format except that the original hyperlinks
and pop-ups are disabled. Target words that were
</bodyText>
<page confidence="0.996052">
84
</page>
<figureCaption confidence="0.999632">
Figure 3: Example Structured Query. The line numbers on the left are for reference only.
</figureCaption>
<bodyText confidence="0.999942826086957">
chosen by the teacher are highlighted and linked to
definitions. Students may also click on any other
unknown words to access definitions. The dictio-
nary definitions are provided from the Cambridge
Advanced Learner’s Dictionary8, which is authored
specifically for ESL learners. All dictionary access
is logged, and teachers can easily see which words
students look up.
The system also provides vocabulary exercises af-
ter each reading for additional practice and review
of target words. Currently, students complete cloze,
or fill-in-the-blank, exercises for each target word in
the readings. Other types of exercises are certainly
possible. For extra review, students also complete
exercises for target words from previous readings.
Students receive immediate feedback on the prac-
tice and review exercises. Currently, sets of the ex-
ercises are manually authored for each target word
and stored in a database, but we are exploring auto-
mated question generation techniques (Brown et al.,
2005; Liu et al., 2005). At runtime, the system se-
lects practice and review exercises from this reposi-
tory.
</bodyText>
<sectionHeader confidence="0.999878" genericHeader="method">
7 Related Work
</sectionHeader>
<bodyText confidence="0.983342483870968">
A number of recent projects have taken similar ap-
proaches to providing authentic texts for language
learners. WERTi (Amaral et al., 2006) is an in-
telligent automatic workbook that uses texts from
the Web to increase knowledge of English gram-
matical forms and functions. READ-X (Miltsakaki
and Troutt, 2007) is a tool for finding texts at spec-
ified reading levels. SourceFinder (Sheehan et al.,
2007) is an authoring tool for finding suitable texts
for standardized test items on verbal reasoning and
8dictionary.cambridge.org
reading comprehension.
The REAP Tutor (Brown and Eskenazi, 2004;
Heilman et al., 2006) for ESL vocabulary takes a
slightly different approach. Rather than teachers
choosing texts as in the REAP Search system, the
REAP Tutor itself selects individualized practice
readings from a digital library. The readings contain
target vocabulary words that a given student needs
to learn based on a student model. While the in-
dividualized REAP Tutor has the potential to better
match the needs of each student since each student
can work with different texts, a drawback of its ap-
proach is that instructors may have difficulty coor-
dinating group discussion about readings and inte-
grating the Tutor into their curriculum. In the REAP
Search system, however, teachers can find texts that
match the needs and interests of the class as a whole.
While some degree of individualization is lost, the
advantages of better coordinated support from teach-
ers and classroom integration are gained.
</bodyText>
<sectionHeader confidence="0.703075" genericHeader="method">
8 Pilot Study
</sectionHeader>
<subsectionHeader confidence="0.994208">
8.1 Description
</subsectionHeader>
<bodyText confidence="0.999968230769231">
Two teachers and over fifty students in two ESL
courses at the University of Pittsburgh used the sys-
tem as part of a pilot study in the Spring of 2008.
The courses focus on developing the reading skills
of high-intermediate ESL learners. The target vo-
cabulary words covered in the courses come from
the Academic Word List (Coxhead, 2000), a list
of broad-coverage, general purpose English words
that frequently appear in academic writing. Students
used the system once per week in a fifty-minute class
for eight weeks. For approximately half of a ses-
sion, students read the teacher-selected readings and
worked through individualized practice exercises.
</bodyText>
<page confidence="0.999446">
85
</page>
<figureCaption confidence="0.999874">
Figure 4: Screenshot of Student Interface Displaying a Reading and Dictionary Definition.
</figureCaption>
<bodyText confidence="0.999977909090909">
For the other half of each session, the teacher pro-
vided direct instruction on and facilitated discussion
about the texts and target words, making connec-
tions to the rest of the curriculum when possible.
For each session, the teachers found three to five
readings. Students read through at least two of the
readings, which were discussed in class. The extra
readings allowed faster readers to progress at their
own pace if they complete the first two. Teachers
learned to use the system in a training session that
lasted about 30 minutes.
</bodyText>
<subsectionHeader confidence="0.999931">
8.2 Usage Analysis
</subsectionHeader>
<bodyText confidence="0.999963541666667">
To better understand the two teachers’ interactions
with the search system, we analyzed query log data
from a four week period. In total, the teachers used
the system to select 23 readings for their students.
In the process, they issued 47 unique queries to the
system. Thus, on average they issued 2.04 queries
per chosen text. Ideally, a user would only have to
issue a single query to find useful texts, but from
the teachers’ comments it appears that the system’s
usability is sufficiently good in general. Most of
the time, they specified 20 target words, only some
of which appeared in their selected readings. The
teachers included ad hoc queries only some of the
time. These were informational in nature and ad-
dressed a variety of topics. Example queries in-
clude the following: “surviving winter”, “coal min-
ers safety”, “gender roles”, and “unidentified flying
objects”. The teachers chose these topics because
they matched up with topics discussed in other parts
of their courses’ curricula. In other cases, it was
more important for them to search for texts with tar-
get vocabulary rather than those on specific topics,
so they only specified target words and pedagogical
constraints.
</bodyText>
<subsectionHeader confidence="0.995577">
8.3 Post-test and Survey Results
</subsectionHeader>
<bodyText confidence="0.999985133333333">
At the end of the semester, students took an exit sur-
vey followed by a post-test consisting of cloze vo-
cabulary questions for the target words they prac-
ticed with the system. In previous semesters, the
REAP Tutor has been used in one of the two courses
that were part of the pilot study. For comparison
with those results, we focus our analysis on the sub-
set of data for the 20 students in that course. The
exit survey results, shown in 5, indicate that stu-
dents felt it was easy-to-use and should be used in
future classes. These survey results are actually very
similar to previous results from a Spring 2006 study
with the REAP Tutor (Heilman et al., 2006). How-
ever, responses to the prompt “My teacher helped
me to learn by discussing the readings after I read
</bodyText>
<page confidence="0.995601">
86
</page>
<figureCaption confidence="0.9972125">
Figure 5: The results from the pilot study exit survey, which used a Likert response format from 1-5 with 1=Strongly
Disagree, 3=Neither Agree nor Disagree, and 5=Strongly Agree. Error bars indicate standard deviations.
</figureCaption>
<bodyText confidence="0.999898583333333">
them” suggest that the tight integration of an edu-
cational system with other classroom activities, in-
cluding teacher-led discussions, can be beneficial.
Learning of target words was directly measured
by the post-test. On average, students answered
89% of cloze exercises correctly, compared to less
than 50% in previous studies with the REAP Tutor.
A direct comparison to those studies is challenging
since the system in this study provided instruction
on words that students were also studying as part of
their regular coursework, whereas systems in previ-
ous studies did not.
</bodyText>
<sectionHeader confidence="0.996164" genericHeader="discussions">
9 Discussion and Future Work
</sectionHeader>
<bodyText confidence="0.999977428571429">
We have described a system that enables teachers
to find appropriate, authentic texts from the Web
for vocabulary and reading practice. A variety of
language technologies ranging from text retrieval to
POS tagging perform essential functions in the sys-
tem. The system has been used in two courses by
over fifty ESL students.
A number of questions remain. Can language
learners effectively and efficiently use such a system
to search for reading materials directly, rather than
reading what a teacher selects? Students could use
the system, but a more polished user interface and
further progress on filtering out readings of low text
quality is necessary. Is such an approach adaptable
to other languages, especially less commonly taught
languages for which there are fewer available Web
pages? Certainly there are sufficient resources avail-
able on the Web in commonly taught languages such
as French or Japanese, but extending to other lan-
guages with fewer resources might be significantly
more challenging. How effective would such a tool
be in a first language classroom? Such an approach
should be suitable for use in first language class-
rooms, especially by teachers who need to find sup-
plemental materials for struggling readers. Are there
enough high-quality, low-reading level texts for very
young readers? From observations made while de-
veloping REAP, the proportion of Web pages below
fourth grade reading level is small. Finding appro-
priate materials for beginning readers is a challenge
that the REAP developers are actively addressing.
Issues of speed and scale are also important to
consider. Complex queries such as the one shown
in Figure 3 are not as efficient as boolean queries.
The current system takes a few seconds to return re-
sults from its database of several million readings.
Scaling up to a much larger digital library may re-
quire sophisticated distributed processing of queries
across multiple disks or multiple servers. However,
we maintain that this is an effective approach for
providing texts within a particular grade level range
or known target word list.
</bodyText>
<sectionHeader confidence="0.998631" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999845916666667">
This research was supported in part by the Insti-
tute of Education Sciences, U.S. Department of Ed-
ucation, through Grant R305B040063 to Carnegie
Mellon University; Dept. of Education grant
R305G03123; the Pittsburgh Science of Learning
Center which is funded by the National Science
Foundation, award number SBE-0354420; and a Na-
tional Science Foundation Graduate Research Fel-
lowship awarded to the first author. Any opin-
ions, findings, conclusions, or recommendations ex-
pressed in this material are the authors, and do not
necessarily reflect those of the sponsors.
</bodyText>
<sectionHeader confidence="0.998202" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.700734">
Luiz Amaral, Vanessa Metcalf and Detmar Meurers.
</reference>
<page confidence="0.991052">
87
</page>
<reference confidence="0.999742112676056">
2006. Language Awareness through Re-use of NLP
Technology. Pre-conference Workshop on NLP in
CALL – Computational and Linguistic Challenges.
CALICO 2006.
Jon Brown and Maxine Eskenazi. 2004. Retrieval of
authentic documents for reader-specific lexical prac-
tice. Proceedings of InSTIL/ICALL Symposium 2004.
Venice, Italy.
Jon Brown, Gwen Frishkoff, and Maxine Eskenazi.
2005. Automatic question generation for vocabulary
assessment. Proceedings of HLT/EMNLP 2005. Van-
couver, B.C.
Kevyn Collins-Thompson and Jamie Callan. 2005.
Predicting reading difficulty with statistical language
models. Journal of the American Society for Informa-
tion Science and Technology, 56(13). pp. 1448-1462.
Averil Coxhead. 2000. A New Academic Word List.
TESOL Quarterly, 34(2). pp. 213-238.
S. Gupta, G. Kaiser, D. Neistadt, and P. Grimm. 2003.
DOM-based content extraction of HTML documents.
ACM Press, New York.
F. M. Hafiz and Ian Tudor. 1989. Extensive reading
and the development of language skills. ELT Journal
43(1):4-13. Oxford University Press.
Michael Heilman, Kevyn Collins-Thompson, Maxine Es-
kenazi. 2008. An Analysis of Statistical Models and
Features for Reading Difficulty Prediction. The 3rd
Workshop on Innovative Use of NLP for Building Edu-
cational Applications. Association for Computational
Linguistics.
Michael Heilman, Alan Juffs, Maxine Eskenazi. 2007.
Choosing Reading Passages for Vocabulary Learning
by Topic to Increase Intrinsic Motivation. Proceedings
of the 13th International Conferenced on Artificial In-
telligence in Education. Marina del Rey, CA.
Michael Heilman, Kevyn Collins-Thompson, Jamie
Callan, and Maxine Eskenazi. 2006. Classroom suc-
cess of an Intelligent Tutoring System for lexical prac-
tice and reading comprehension. Proceedings of the
Ninth International Conference on Spoken Language
Processing. Pittsburgh, PA.
Thorsten Joachims. 1999. Making large-Scale SVM
Learning Practical. Advances in Kernel Methods -
Support Vector Learning, B. Schlkopf and C. Burges
and A. Smola (ed.) MIT-Press.
Chao-Lin Liu, Chun-Hung Wang, Zhao-Ming Gao, and
Shang-Ming Huang. 2005. Applications of Lexical
Information for Algorithmically Composing Multiple-
Choice Cloze Items Proceedings of the Second
Workshop on Building Educational Applications Us-
ing NLP. Association for Computational Linguistics.
Christopher D. Manning, Prabhakar Raghavan and Hin-
rich Schtze. 2008. Introduction to Information Re-
trieval. Cambridge University Press. Draft available
at http://www-csli.stanford.edu/∼hinrich/information-
retrieval-book.html.
Eleni Miltsakaki and Audrey Troutt. 2007. Read-X: Au-
tomatic Evaluation of Reading Difficulty of Web Text.
Proceedings of E-Learn 2007, sponsored by the Asso-
ciation for the Advancement of Computing in Educa-
tion. Quebec, Canada.
Matthew Peacock. 1997. The effect of authentic mate-
rials on the motivation of EFL learners. ELT Journal
51(2):144-156. Oxford University Press.
Kathleen M. Sheehan, Irene Kostin, Yoko Futagi. 2007.
SourceFinder: A Construct-Driven Approach for Lo-
cating Appropriately Targeted Reading Comprehen-
sion Source Texts. Proceedings of the SLaTE Work-
shop on Speech and Language Technology in Educa-
tion. Carnegie Mellon University and International
Speech Communication Association (ISCA).
</reference>
<page confidence="0.999408">
88
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.613487">
<title confidence="0.979697">Retrieval of Reading Materials for Vocabulary and Reading Practice</title>
<author confidence="0.977683">Le_Zhao Heilman</author>
<author confidence="0.977683">Juan Pino</author>
<affiliation confidence="0.932444">Language Technologies Carnegie Mellon</affiliation>
<address confidence="0.9929">Pittsburgh, PA 15213,</address>
<abstract confidence="0.980914466666667">Finding appropriate, authentic reading materials is a challenge for language instructors. The Web is a vast resource of texts, but most pages are not suitable for reading practice, and commercial search engines are not well suited to finding texts that satisfy pedagogical constraints such as reading level, length, text quality, and presence of target vocabulary. We present a system that uses various language technologies to facilitate the retrieval and presentation of authentic reading materials gathered from the Web. It is currently deployed in two English as a Second Language courses at the University of Pittsburgh.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Luiz Amaral</author>
</authors>
<title>Vanessa Metcalf and Detmar Meurers.</title>
<date>2006</date>
<booktitle>Language Awareness through Re-use of NLP Technology. Pre-conference Workshop on NLP in CALL – Computational and Linguistic Challenges. CALICO</booktitle>
<marker>Amaral, 2006</marker>
<rawString>Luiz Amaral, Vanessa Metcalf and Detmar Meurers. 2006. Language Awareness through Re-use of NLP Technology. Pre-conference Workshop on NLP in CALL – Computational and Linguistic Challenges. CALICO 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Brown</author>
<author>Maxine Eskenazi</author>
</authors>
<title>Retrieval of authentic documents for reader-specific lexical practice.</title>
<date>2004</date>
<booktitle>Proceedings of InSTIL/ICALL Symposium</booktitle>
<location>Venice, Italy.</location>
<contexts>
<context position="21102" citStr="Brown and Eskenazi, 2004" startWordPosition="3390" endWordPosition="3393">om this repository. 7 Related Work A number of recent projects have taken similar approaches to providing authentic texts for language learners. WERTi (Amaral et al., 2006) is an intelligent automatic workbook that uses texts from the Web to increase knowledge of English grammatical forms and functions. READ-X (Miltsakaki and Troutt, 2007) is a tool for finding texts at specified reading levels. SourceFinder (Sheehan et al., 2007) is an authoring tool for finding suitable texts for standardized test items on verbal reasoning and 8dictionary.cambridge.org reading comprehension. The REAP Tutor (Brown and Eskenazi, 2004; Heilman et al., 2006) for ESL vocabulary takes a slightly different approach. Rather than teachers choosing texts as in the REAP Search system, the REAP Tutor itself selects individualized practice readings from a digital library. The readings contain target vocabulary words that a given student needs to learn based on a student model. While the individualized REAP Tutor has the potential to better match the needs of each student since each student can work with different texts, a drawback of its approach is that instructors may have difficulty coordinating group discussion about readings an</context>
</contexts>
<marker>Brown, Eskenazi, 2004</marker>
<rawString>Jon Brown and Maxine Eskenazi. 2004. Retrieval of authentic documents for reader-specific lexical practice. Proceedings of InSTIL/ICALL Symposium 2004. Venice, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Brown</author>
<author>Gwen Frishkoff</author>
<author>Maxine Eskenazi</author>
</authors>
<title>Automatic question generation for vocabulary assessment.</title>
<date>2005</date>
<booktitle>Proceedings of HLT/EMNLP</booktitle>
<location>Vancouver, B.C.</location>
<contexts>
<context position="20394" citStr="Brown et al., 2005" startWordPosition="3278" endWordPosition="3281"> system also provides vocabulary exercises after each reading for additional practice and review of target words. Currently, students complete cloze, or fill-in-the-blank, exercises for each target word in the readings. Other types of exercises are certainly possible. For extra review, students also complete exercises for target words from previous readings. Students receive immediate feedback on the practice and review exercises. Currently, sets of the exercises are manually authored for each target word and stored in a database, but we are exploring automated question generation techniques (Brown et al., 2005; Liu et al., 2005). At runtime, the system selects practice and review exercises from this repository. 7 Related Work A number of recent projects have taken similar approaches to providing authentic texts for language learners. WERTi (Amaral et al., 2006) is an intelligent automatic workbook that uses texts from the Web to increase knowledge of English grammatical forms and functions. READ-X (Miltsakaki and Troutt, 2007) is a tool for finding texts at specified reading levels. SourceFinder (Sheehan et al., 2007) is an authoring tool for finding suitable texts for standardized test items on ve</context>
</contexts>
<marker>Brown, Frishkoff, Eskenazi, 2005</marker>
<rawString>Jon Brown, Gwen Frishkoff, and Maxine Eskenazi. 2005. Automatic question generation for vocabulary assessment. Proceedings of HLT/EMNLP 2005. Vancouver, B.C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevyn Collins-Thompson</author>
<author>Jamie Callan</author>
</authors>
<title>Predicting reading difficulty with statistical language models.</title>
<date>2005</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>56</volume>
<issue>13</issue>
<pages>1448--1462</pages>
<contexts>
<context position="9033" citStr="Collins-Thompson and Callan, 2005" startWordPosition="1420" endWordPosition="1423">s. Using Lemur and the Indri Query Language allows for the retrieval of annotated documents according to userspecified constraints. 4 Annotations and Filters Annotators automatically tag the documents in the corpus to enable the filtering and retrieval of reading material that matches user-specified pedagogical constraints. Annotations include reading difficulty, general topic area, text quality, and text length. Text length is simply the number of word tokens appearing in the document. 4.1 Reading Level The system employs a language modeling approach developed by Collins-Thompson and Callan (Collins-Thompson and Callan, 2005) that creates a model of the lexicon for each grade level and predicts reading level, or readability, of given documents according to those models. The readability predictor is a specialized Naive Bayes classifier with lexical unigram features. For web documents in particular, Collins-Thompson and Callan report that this language modeling-based prediction has a stronger correlation with human-assigned levels than other commonly used readability measures. This automatic readability measure allows the system to satisfy user-specified constraints on reading difficulty. We are also experimenting w</context>
</contexts>
<marker>Collins-Thompson, Callan, 2005</marker>
<rawString>Kevyn Collins-Thompson and Jamie Callan. 2005. Predicting reading difficulty with statistical language models. Journal of the American Society for Information Science and Technology, 56(13). pp. 1448-1462.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Averil Coxhead</author>
</authors>
<title>A New Academic Word List.</title>
<date>2000</date>
<journal>TESOL Quarterly,</journal>
<volume>34</volume>
<issue>2</issue>
<pages>213--238</pages>
<contexts>
<context position="22381" citStr="Coxhead, 2000" startWordPosition="3603" endWordPosition="3604"> system, however, teachers can find texts that match the needs and interests of the class as a whole. While some degree of individualization is lost, the advantages of better coordinated support from teachers and classroom integration are gained. 8 Pilot Study 8.1 Description Two teachers and over fifty students in two ESL courses at the University of Pittsburgh used the system as part of a pilot study in the Spring of 2008. The courses focus on developing the reading skills of high-intermediate ESL learners. The target vocabulary words covered in the courses come from the Academic Word List (Coxhead, 2000), a list of broad-coverage, general purpose English words that frequently appear in academic writing. Students used the system once per week in a fifty-minute class for eight weeks. For approximately half of a session, students read the teacher-selected readings and worked through individualized practice exercises. 85 Figure 4: Screenshot of Student Interface Displaying a Reading and Dictionary Definition. For the other half of each session, the teacher provided direct instruction on and facilitated discussion about the texts and target words, making connections to the rest of the curriculum w</context>
</contexts>
<marker>Coxhead, 2000</marker>
<rawString>Averil Coxhead. 2000. A New Academic Word List. TESOL Quarterly, 34(2). pp. 213-238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Gupta</author>
<author>G Kaiser</author>
<author>D Neistadt</author>
<author>P Grimm</author>
</authors>
<title>DOM-based content extraction of HTML documents.</title>
<date>2003</date>
<publisher>ACM Press,</publisher>
<location>New York.</location>
<contexts>
<context position="14201" citStr="Gupta et al., 2003" startWordPosition="2248" endWordPosition="2251">unit contains both a noun and a verb can effectively distinguish between content text units and those text units that are just part of links, menus, etc. The proportion 7The OpenNLP toolkit’s tagger was used (opennlp.sourceforge.net). of the total tokens that are part of content text units serves as a useful measure of text quality. We have found that a threshold of about 85% content text is appropriate, since most web pages contain at least some non-content text in links, menus, etc. This approach to content extraction is related to previous work on increasing the accessibility of web pages (Gupta et al., 2003). 5 Constructing Queries Users search for readings in the annotated corpus through a simple interface that appears similar to, but extends the functionality of, the interfaces for commercial web search engines. Figure 2 shows a screenshot of the interface. Users have the option to specify ad hoc queries in a text field. They can also use drop down menus to specify optional minimum and/or maximum reading levels and text lengths. Another optional drop-down menu allows users to constrain the general topic area of results. A separate screen allows users to specify a list of target vocabulary words</context>
</contexts>
<marker>Gupta, Kaiser, Neistadt, Grimm, 2003</marker>
<rawString>S. Gupta, G. Kaiser, D. Neistadt, and P. Grimm. 2003. DOM-based content extraction of HTML documents. ACM Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F M Hafiz</author>
<author>Ian Tudor</author>
</authors>
<title>Extensive reading and the development of language skills.</title>
<date>1989</date>
<journal>ELT Journal</journal>
<pages>43--1</pages>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="1050" citStr="Hafiz and Tudor, 1989" startWordPosition="151" endWordPosition="154">practice, and commercial search engines are not well suited to finding texts that satisfy pedagogical constraints such as reading level, length, text quality, and presence of target vocabulary. We present a system that uses various language technologies to facilitate the retrieval and presentation of authentic reading materials gathered from the Web. It is currently deployed in two English as a Second Language courses at the University of Pittsburgh. 1 Introduction Reading practice is an important component of first and second language learning, especially with regards to vocabulary learning (Hafiz and Tudor, 1989). Appropriating suitable reading material for the needs of a particular curriculum or particular student, however, is a challenging process. Manually authoring or editing readings is time-consuming and raises issues of authenticity, which are particularly significant in second language learning (Peacock, 1997). On the other hand, the Web is a vast resource of authentic reading material, but commercial search engines which are designed for a wide variety of information needs may not effectively facilitate the retrieval of appropriate readings for language learners. In order to demonstrate the p</context>
</contexts>
<marker>Hafiz, Tudor, 1989</marker>
<rawString>F. M. Hafiz and Ian Tudor. 1989. Extensive reading and the development of language skills. ELT Journal 43(1):4-13. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Heilman</author>
<author>Kevyn Collins-Thompson</author>
<author>Maxine Eskenazi</author>
</authors>
<title>An Analysis of Statistical Models and Features for Reading Difficulty Prediction. The 3rd Workshop on Innovative Use of NLP for Building Educational Applications. Association for Computational Linguistics.</title>
<date>2008</date>
<contexts>
<context position="2819" citStr="Heilman et al., 2008" startWordPosition="447" endWordPosition="450">cific topic of “international travel.” He sought texts that contained at least a few words from the list of target vocabulary that his student were learning that week. In addition, he needed the texts to be within a particular range of reading difficulty, fifth to eighth grade in an American school, and shorter than a thousand words. Sending the query “international travel” to a popular search engine did not produce a useful list of results1. The first result was a travel warning from the Department of State2, which was at a high reading level (grade 10 according to the approach described by (Heilman et al., 2008)) and not likely to be of interest to ESL students because of legal and technical details. Most of the subsequent results were for commercial web sites and travel agencies. A query for a subset of the target vocabulary words for the course also produced poor results. Since the search engine used strict boolean retrieval methods, the top results for the query “deduce deviate hierarchy implicit undertake” were all long lists of ESL vocabulary words3. We describe a search system, called REAP Search, that is tailored to the needs of language 1www.google.com, March 5, 2008 2http://travel.state.gov/</context>
<context position="9755" citStr="Heilman et al., 2008" startWordPosition="1526" endWordPosition="1529"> of given documents according to those models. The readability predictor is a specialized Naive Bayes classifier with lexical unigram features. For web documents in particular, Collins-Thompson and Callan report that this language modeling-based prediction has a stronger correlation with human-assigned levels than other commonly used readability measures. This automatic readability measure allows the system to satisfy user-specified constraints on reading difficulty. We are also experimenting with using syntactic features to predict reading difficulty. Heilman, Collins-Thompson, and Eskenazi (Heilman et al., 2008) describe an approach that combines predictions based on lexical and grammatical features. The 5www.lemurproject.org grammatical features are frequencies of occurrence of grammatical constructions, which are computed from automatic parses of input texts. Using multiple measures of reading difficulty that focus on different aspects of language may allow users more freedom to find texts that match their needs. For example, a teacher may want to find grammatically simpler texts for use in a lesson focused on introducing difficult vocabulary. 4.2 General Topic Area A set of binary topic classifier</context>
</contexts>
<marker>Heilman, Collins-Thompson, Eskenazi, 2008</marker>
<rawString>Michael Heilman, Kevyn Collins-Thompson, Maxine Eskenazi. 2008. An Analysis of Statistical Models and Features for Reading Difficulty Prediction. The 3rd Workshop on Innovative Use of NLP for Building Educational Applications. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Heilman</author>
<author>Alan Juffs</author>
<author>Maxine Eskenazi</author>
</authors>
<title>Choosing Reading Passages for Vocabulary Learning by Topic to Increase Intrinsic Motivation.</title>
<date>2007</date>
<booktitle>Proceedings of the 13th International Conferenced on Artificial Intelligence in Education. Marina del Rey,</booktitle>
<location>CA.</location>
<marker>Heilman, Juffs, Eskenazi, 2007</marker>
<rawString>Michael Heilman, Alan Juffs, Maxine Eskenazi. 2007. Choosing Reading Passages for Vocabulary Learning by Topic to Increase Intrinsic Motivation. Proceedings of the 13th International Conferenced on Artificial Intelligence in Education. Marina del Rey, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Heilman</author>
<author>Kevyn Collins-Thompson</author>
<author>Jamie Callan</author>
<author>Maxine Eskenazi</author>
</authors>
<title>Classroom success of an Intelligent Tutoring System for lexical practice and reading comprehension.</title>
<date>2006</date>
<booktitle>Proceedings of the Ninth International Conference on Spoken Language Processing.</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="21125" citStr="Heilman et al., 2006" startWordPosition="3394" endWordPosition="3397">ted Work A number of recent projects have taken similar approaches to providing authentic texts for language learners. WERTi (Amaral et al., 2006) is an intelligent automatic workbook that uses texts from the Web to increase knowledge of English grammatical forms and functions. READ-X (Miltsakaki and Troutt, 2007) is a tool for finding texts at specified reading levels. SourceFinder (Sheehan et al., 2007) is an authoring tool for finding suitable texts for standardized test items on verbal reasoning and 8dictionary.cambridge.org reading comprehension. The REAP Tutor (Brown and Eskenazi, 2004; Heilman et al., 2006) for ESL vocabulary takes a slightly different approach. Rather than teachers choosing texts as in the REAP Search system, the REAP Tutor itself selects individualized practice readings from a digital library. The readings contain target vocabulary words that a given student needs to learn based on a student model. While the individualized REAP Tutor has the potential to better match the needs of each student since each student can work with different texts, a drawback of its approach is that instructors may have difficulty coordinating group discussion about readings and integrating the Tutor</context>
<context position="25235" citStr="Heilman et al., 2006" startWordPosition="4077" endWordPosition="4080">ook an exit survey followed by a post-test consisting of cloze vocabulary questions for the target words they practiced with the system. In previous semesters, the REAP Tutor has been used in one of the two courses that were part of the pilot study. For comparison with those results, we focus our analysis on the subset of data for the 20 students in that course. The exit survey results, shown in 5, indicate that students felt it was easy-to-use and should be used in future classes. These survey results are actually very similar to previous results from a Spring 2006 study with the REAP Tutor (Heilman et al., 2006). However, responses to the prompt “My teacher helped me to learn by discussing the readings after I read 86 Figure 5: The results from the pilot study exit survey, which used a Likert response format from 1-5 with 1=Strongly Disagree, 3=Neither Agree nor Disagree, and 5=Strongly Agree. Error bars indicate standard deviations. them” suggest that the tight integration of an educational system with other classroom activities, including teacher-led discussions, can be beneficial. Learning of target words was directly measured by the post-test. On average, students answered 89% of cloze exercises </context>
</contexts>
<marker>Heilman, Collins-Thompson, Callan, Eskenazi, 2006</marker>
<rawString>Michael Heilman, Kevyn Collins-Thompson, Jamie Callan, and Maxine Eskenazi. 2006. Classroom success of an Intelligent Tutoring System for lexical practice and reading comprehension. Proceedings of the Ninth International Conference on Spoken Language Processing. Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<date>1999</date>
<booktitle>Making large-Scale SVM Learning Practical. Advances in Kernel Methods -Support Vector Learning,</booktitle>
<pages>MIT-Press.</pages>
<editor>B. Schlkopf and C. Burges and A. Smola (ed.)</editor>
<contexts>
<context position="10762" citStr="Joachims, 1999" startWordPosition="1677" endWordPosition="1678"> match their needs. For example, a teacher may want to find grammatically simpler texts for use in a lesson focused on introducing difficult vocabulary. 4.2 General Topic Area A set of binary topic classifiers automatically classifies each potential reading by its general topic, as described by Heilman, Juffs, and Eskenazi (2007). This component allows users to search for readings on their general interests without specifying a particular query (e.g., “international travel”) that might unnecessarily constrain the results to a very narrow topic. A Linear Support Vector Machine text classifier (Joachims, 1999) was trained on Web pages from the Open Directory Project (ODP)6. These pages effectively have human-assigned topic labels because they are organized into a multi-level hierarchy of topics. The following general topics were manually selected from categories in the ODP: Movies and Theater; Music; Visual Arts; Computers and Technology; Business; Math, Physics and Chemistry; Biology and Environment; Social Sciences; Health and Medicine; Fitness and Nutrition; Religion; Politics; Law and Crime; History; American Sports; and Outdoor Recreation. Web pages from the ODP were used as goldstandard label</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making large-Scale SVM Learning Practical. Advances in Kernel Methods -Support Vector Learning, B. Schlkopf and C. Burges and A. Smola (ed.) MIT-Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chao-Lin Liu</author>
<author>Chun-Hung Wang</author>
<author>Zhao-Ming Gao</author>
<author>Shang-Ming Huang</author>
</authors>
<title>Applications of Lexical Information for Algorithmically Composing MultipleChoice Cloze Items</title>
<date>2005</date>
<booktitle>Proceedings of the Second Workshop on Building Educational Applications Using NLP. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="20413" citStr="Liu et al., 2005" startWordPosition="3282" endWordPosition="3285">s vocabulary exercises after each reading for additional practice and review of target words. Currently, students complete cloze, or fill-in-the-blank, exercises for each target word in the readings. Other types of exercises are certainly possible. For extra review, students also complete exercises for target words from previous readings. Students receive immediate feedback on the practice and review exercises. Currently, sets of the exercises are manually authored for each target word and stored in a database, but we are exploring automated question generation techniques (Brown et al., 2005; Liu et al., 2005). At runtime, the system selects practice and review exercises from this repository. 7 Related Work A number of recent projects have taken similar approaches to providing authentic texts for language learners. WERTi (Amaral et al., 2006) is an intelligent automatic workbook that uses texts from the Web to increase knowledge of English grammatical forms and functions. READ-X (Miltsakaki and Troutt, 2007) is a tool for finding texts at specified reading levels. SourceFinder (Sheehan et al., 2007) is an authoring tool for finding suitable texts for standardized test items on verbal reasoning and </context>
</contexts>
<marker>Liu, Wang, Gao, Huang, 2005</marker>
<rawString>Chao-Lin Liu, Chun-Hung Wang, Zhao-Ming Gao, and Shang-Ming Huang. 2005. Applications of Lexical Information for Algorithmically Composing MultipleChoice Cloze Items Proceedings of the Second Workshop on Building Educational Applications Using NLP. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Schtze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press.</publisher>
<note>Draft available at http://www-csli.stanford.edu/∼hinrich/informationretrieval-book.html.</note>
<contexts>
<context position="16821" citStr="Manning et al., 2008" startWordPosition="2689" endWordPosition="2692">els prefer multiple occurrences of different word types as opposed to multiple occurrences of the same word tokens, allowing them to rank documents with more distinct query terms higher than those with distinct query terms. Documents that contain only some of the query terms are thus assigned nonzero weights, allowing the user to find useful texts that contain only some of the target vocabulary. The REAP search system uses the Indri Query Language’s “combine” and “weight” operators to implement a ranked retrieval model for target vocabulary. For more information on text retrieval models, see (Manning et al., 2008). 5.2 Example Query Figure 3 shows an example of a structured query produced by the system from a teacher’s original query and constraints. This example was slightly altered from its original form for clarity of presentation. The first line with the filrej operator filters and rejects any documents that contain any of a long list of words considered to be profanity, which are omitted in the illustration for brevity and posterity. The filreq operator in line 2 requires that all of the constraints on reading level, text length and quality in lines 2-4 are met. The weight operator at the start of</context>
</contexts>
<marker>Manning, Raghavan, Schtze, 2008</marker>
<rawString>Christopher D. Manning, Prabhakar Raghavan and Hinrich Schtze. 2008. Introduction to Information Retrieval. Cambridge University Press. Draft available at http://www-csli.stanford.edu/∼hinrich/informationretrieval-book.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleni Miltsakaki</author>
<author>Audrey Troutt</author>
</authors>
<title>Read-X: Automatic Evaluation of Reading Difficulty of Web Text.</title>
<date>2007</date>
<booktitle>Proceedings of E-Learn 2007, sponsored by the Association for the Advancement of Computing in Education.</booktitle>
<location>Quebec, Canada.</location>
<contexts>
<context position="20819" citStr="Miltsakaki and Troutt, 2007" startWordPosition="3348" endWordPosition="3351">d review exercises. Currently, sets of the exercises are manually authored for each target word and stored in a database, but we are exploring automated question generation techniques (Brown et al., 2005; Liu et al., 2005). At runtime, the system selects practice and review exercises from this repository. 7 Related Work A number of recent projects have taken similar approaches to providing authentic texts for language learners. WERTi (Amaral et al., 2006) is an intelligent automatic workbook that uses texts from the Web to increase knowledge of English grammatical forms and functions. READ-X (Miltsakaki and Troutt, 2007) is a tool for finding texts at specified reading levels. SourceFinder (Sheehan et al., 2007) is an authoring tool for finding suitable texts for standardized test items on verbal reasoning and 8dictionary.cambridge.org reading comprehension. The REAP Tutor (Brown and Eskenazi, 2004; Heilman et al., 2006) for ESL vocabulary takes a slightly different approach. Rather than teachers choosing texts as in the REAP Search system, the REAP Tutor itself selects individualized practice readings from a digital library. The readings contain target vocabulary words that a given student needs to learn bas</context>
</contexts>
<marker>Miltsakaki, Troutt, 2007</marker>
<rawString>Eleni Miltsakaki and Audrey Troutt. 2007. Read-X: Automatic Evaluation of Reading Difficulty of Web Text. Proceedings of E-Learn 2007, sponsored by the Association for the Advancement of Computing in Education. Quebec, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Peacock</author>
</authors>
<title>The effect of authentic materials on the motivation of EFL learners.</title>
<date>1997</date>
<journal>ELT Journal</journal>
<pages>51--2</pages>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="1361" citStr="Peacock, 1997" startWordPosition="195" endWordPosition="196"> materials gathered from the Web. It is currently deployed in two English as a Second Language courses at the University of Pittsburgh. 1 Introduction Reading practice is an important component of first and second language learning, especially with regards to vocabulary learning (Hafiz and Tudor, 1989). Appropriating suitable reading material for the needs of a particular curriculum or particular student, however, is a challenging process. Manually authoring or editing readings is time-consuming and raises issues of authenticity, which are particularly significant in second language learning (Peacock, 1997). On the other hand, the Web is a vast resource of authentic reading material, but commercial search engines which are designed for a wide variety of information needs may not effectively facilitate the retrieval of appropriate readings for language learners. In order to demonstrate the problem of finding appropriate reading materials, here is a typical example of an information need from a teacher of an English as a Second Language (ESL) course focused on reading skills. This example was encountered during the development of the system. It should be noted that while we describe the system in </context>
</contexts>
<marker>Peacock, 1997</marker>
<rawString>Matthew Peacock. 1997. The effect of authentic materials on the motivation of EFL learners. ELT Journal 51(2):144-156. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen M Sheehan</author>
<author>Irene Kostin</author>
<author>Yoko Futagi</author>
</authors>
<title>SourceFinder: A Construct-Driven Approach for Locating Appropriately Targeted Reading Comprehension Source Texts.</title>
<date>2007</date>
<booktitle>Proceedings of the SLaTE Workshop on Speech and Language Technology in Education. Carnegie Mellon University and International Speech Communication Association (ISCA).</booktitle>
<contexts>
<context position="20912" citStr="Sheehan et al., 2007" startWordPosition="3364" endWordPosition="3367">stored in a database, but we are exploring automated question generation techniques (Brown et al., 2005; Liu et al., 2005). At runtime, the system selects practice and review exercises from this repository. 7 Related Work A number of recent projects have taken similar approaches to providing authentic texts for language learners. WERTi (Amaral et al., 2006) is an intelligent automatic workbook that uses texts from the Web to increase knowledge of English grammatical forms and functions. READ-X (Miltsakaki and Troutt, 2007) is a tool for finding texts at specified reading levels. SourceFinder (Sheehan et al., 2007) is an authoring tool for finding suitable texts for standardized test items on verbal reasoning and 8dictionary.cambridge.org reading comprehension. The REAP Tutor (Brown and Eskenazi, 2004; Heilman et al., 2006) for ESL vocabulary takes a slightly different approach. Rather than teachers choosing texts as in the REAP Search system, the REAP Tutor itself selects individualized practice readings from a digital library. The readings contain target vocabulary words that a given student needs to learn based on a student model. While the individualized REAP Tutor has the potential to better match </context>
</contexts>
<marker>Sheehan, Kostin, Futagi, 2007</marker>
<rawString>Kathleen M. Sheehan, Irene Kostin, Yoko Futagi. 2007. SourceFinder: A Construct-Driven Approach for Locating Appropriately Targeted Reading Comprehension Source Texts. Proceedings of the SLaTE Workshop on Speech and Language Technology in Education. Carnegie Mellon University and International Speech Communication Association (ISCA).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>