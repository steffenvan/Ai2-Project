<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000128">
<title confidence="0.999154">
A Memory-Based Approach to Learning Shallow Natural
Language Patterns
</title>
<author confidence="0.980242">
Shlomo Argamon and Ido Dagan and Yuval Krymolowski
</author>
<affiliation confidence="0.9926305">
Department of Mathematics and Computer Science
Bar-Ilan University
</affiliation>
<address confidence="0.851101">
52900 Ramat Gan, Israel
</address>
<email confidence="0.998816">
fargamon,dagan,yuvalkl@cs.biu.ac.il
</email>
<sectionHeader confidence="0.993895" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999928173913043">
Recognizing shallow linguistic patterns, such as ba-
sic syntactic relationships between words, is a com-
mon task in applied natural language and text pro-
cessing. The common practice for approaching this
task is by tedious manual definition of possible pat-
tern structures, often in the form of regular expres-
sions or finite automata. This paper presents a novel
memory-based learning method that recognizes shal-
low patterns in new text based on a bracketed train-
ing corpus. The training data are stored as-is, in
efficient suffix-tree data structures. Generalization
is performed on-line at recognition time by compar-
ing subsequences of the new text to positive and
negative evidence in the corpus. This way, no in-
formation in the training is lost, as can happen in
other learning systems that construct a single gen-
eralized model at the time of training. The paper
presents experimental results for recognizing noun
phrase, subject-verb and verb-object patterns in En-
glish. Since the learning approach enables easy port-
ing to new domains, we plan to apply it to syntac-
tic patterns in other languages and to sub-language
patterns for information extraction.
</bodyText>
<sectionHeader confidence="0.998733" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999246576271187">
Identifying local patterns of syntactic sequences and
relationships is a fundamental task in natural lan-
guage processing (NLP). Such patterns may corre-
spond to syntactic phrases, like noun phrases, or to
pairs of words that participate in a syntactic rela-
tionship, like the heads of a verb-object relation.
Such patterns have been found useful in various
application areas, including information extraction,
text summarization, and bilingual alignment. Syn-
tactic patterns are useful also for many basic com-
putational linguistic tasks, such as statistical word
similarity and various disambiguation problems.
One approach for detecting syntactic patterns is to
obtain a full parse of a sentence and then extract the
required patterns. However, obtaining a complete
parse tree for a sentence is difficult in many cases,
and may not be necessary at all for identifying most
instances of local syntactic patterns.
An alternative approach is to avoid the complex-
ity of full parsing and instead to rely only on local
information. A variety of methods have been devel-
oped within this framework, known as shallow pars-
ing, chunking, local parsing etc. (e.g., (Abney, 1991;
Greffenstette, 1993)). These works have shown that
it is possible to identify most instances of local syn-
tactic patterns by rules that examine only the pat-
tern itself and its nearby context. Often, the rules
are applied to sentences that were tagged by part-
of-speech (POS) and are phrased by some form of
regular expressions or finite state automata.
Manual writing of local syntactic rules has become
a common practice for many applications. However,
writing rules is often tedious and time consuming.
Furthermore, extending the rules to different lan-
guages or sub-language domains can require sub-
stantial resources and expertise that are often not
available. As in many areas of NLP, a learning ap-
proach is appealing. Surprisingly, though, rather lit-
tle work has been devoted to learning local syntactic
patterns, mostly noun phrases (Ramshaw and Mar-
cus, 1995; Vilain and Day, 1996).
This paper presents a novel general learning ap-
proach for recognizing local sequential patterns, that
may be perceived as falling within the memory-
based learning paradigm. The method utilizes a
part-of-speech tagged training corpus in which all in-
stances of the target pattern are marked (bracketed).
The training data are stored as-is in suffix-tree data
structures, which enable linear time searching for
subsequences in the corpus.
The memory-based nature of the presented algo-
rithm stems from its deduction strategy: a new in-
stance of the target pattern is recognized by exam-
ining the raw training corpus, searching for positive
and negative evidence with respect to the given test
sequence. No model is created for the training cor-
pus, and the raw examples are not converted to any
other representation.
Consider the following examplel . Suppose we
</bodyText>
<footnote confidence="0.898129666666667">
1We use here the POS tags: DT = determiner, ADJ
= adjective, ADV = adverb, CONJ = conjunction, VB=verb,
PP=preposition, NN = singular noun, and NNP = plural noun.
</footnote>
<page confidence="0.998836">
67
</page>
<bodyText confidence="0.823765">
want to decide whether the candidate sequence
</bodyText>
<equation confidence="0.267485">
DT ADJ ADJ NN NNP
</equation>
<bodyText confidence="0.997059111111111">
is a noun phrase (NP) by comparing it to the train-
ing corpus. A good match would be if the entire
sequence appears as-is several times in the corpus.
However, due to data sparseness, an exact match
cannot always be expected.
A somewhat weaker match may be obtained if we
consider sub-parts of the candidate sequence (called
tiles). For example, suppose the corpus contains
noun phrase instances with the following structures:
</bodyText>
<listItem confidence="0.9970885">
(1) DT ADJ ADJ NN NN
(2) DT ADJ NN NNP
</listItem>
<bodyText confidence="0.99995525">
The first structure provides positive evidence that
the sequence &amp;quot;DT ADJ ADJ NM&amp;quot; is a possible NP pre-
fix while the second structure provides evidence for
&amp;quot;ADJ NN NNP&amp;quot; being an NP suffix. Together, these
two training instances provide positive evidence that
covers the entire candidate. Considering evidence
for sub-parts of the pattern enables us to general-
ize over the exact structures that are present in the
corpus. Similarly, we also consider the negative evi-
dence for such sub-parts by noting where they occur
in the corpus without being a corresponding part of
a target instance.
The proposed method, as described in detail in
the next section, formalizes this type of reasoning. It
searches specialized data structures for both positive
and negative evidence for sub-parts of the candidate
structure, and considers additional factors such as
context and evidence overlap. Section 3 presents ex-
perimental results for three target syntactic patterns
in English, and Section 4 describes related work.
</bodyText>
<sectionHeader confidence="0.975794" genericHeader="method">
2 The Algorithm
</sectionHeader>
<bodyText confidence="0.999887533333333">
The input to the Memory-Based Sequence Learning
(MBSL) algorithm is a sentence represented as a se-
quence of POS tags, and its output is a bracketed
sentence, indicating which subsequences of the sen-
tence are to be considered instances of the target
pattern (target instances). MBSL determines the
bracketing by first considering each subsequence of
the sentence as a candidate to be a target instance.
It computes a score for each candidate by comparing
it to the training corpus, which consists of a set of
pre-bracketed sentences. The algorithm then finds a
consistent bracketing for the input sentence, giving
preference to high scoring subsequences. In the re-
mainder of this section we describe the scoring and
bracketing methods in more detail.
</bodyText>
<subsectionHeader confidence="0.997885">
2.1 Scoring candidates
</subsectionHeader>
<bodyText confidence="0.999242285714286">
We first describe the mechanism for scoring an in-
dividual candidate. The input is a candidate sub-
sequence, along with its context, i.e., the other tags
in the input sentence. The method is presented at
two levels: a general memory-based learning schema
and a particular instantiation of it. Further instan-
tiations of the schema are expected in future work.
</bodyText>
<subsectionHeader confidence="0.811349">
2.1.1 The general MBSL schema
</subsectionHeader>
<bodyText confidence="0.981735479166666">
The MBSL scoring algorithm works by considering
situated candidates. A situated candidate is a sen-
tence containing one pair of brackets, indicating a
candidate to be a target instance. The portion of
the sentence between the brackets is the candidate
(as above), while the portion before and after the
candidate is its context. (Although we describe the
algorithm here for the general case of unlimited con-
text, for computational reasons our implementation
only considers a limited amount of context on either
side of the candidate.) This subsection describes
how to compute the score of a situated candidate
from the training corpus.
The idea of the MBSL scoring algorithm is to con-
struct a tiling of subsequences of a situated candi-
date which covers the entire candidate. We con-
sider as tiles subsequences of the situated candidate
which contain a bracket. (We thus consider only tiles
within or adjacent to the candidate that also include
a candidate boundary.)
Each tile is assigned a score based on its occur-
rence in the training memory. Since brackets cor-
respond to the boundaries of potential target in-
stances, it is important to consider how the bracket
positions in the tile correspond to those in the train-
ing memory.
For example, consider the training sentence
[ NN ] VB [ ADJ NN NN ] ADV PP [ NN ] .
We may now examine the occurrence in this sentence
of several possible tiles:
VB [ ADJ NN occurs positively in the sentence, and
NN NN ADV also occurs positively, while
NN [ NN ADV occurs negatively in the training sen-
tence, since the bracket does not correspond.
The positive evidence for a tile is measured by its
positive count, the number of times the tile (in-
cluding brackets) occurs in the training memory
with corresponding brackets. Similarly, the nega-
tive evidence for a tile is measured by its negative
count, the number of times that the POS sequence
of the tile occurs in the training memory with non-
corresponding brackets (either brackets in the train-
ing where they do not occur in the tile, or vice versa).
The total count of a tile is its positive count plus its
negative count, that is, the total count of the POS
sequence of the tile, regardless of bracket position.
The score f (t) of a tile t is a function of its positive
and negative counts.
</bodyText>
<page confidence="0.995086">
68
</page>
<table confidence="0.728659166666667">
Candidate: NN VB [ ADJ NN NN ] ADV
MTile VB [ ADJ NN NN ]
MTile VB [ ADJ
MTile [ ADJ NN
MTile NN NN ]
MTile NN ] ADV
</table>
<figureCaption confidence="0.885208">
Figure 1: A candidate subsequence with some of its
context, and 5 matching tiles found in the training
corpus.
</figureCaption>
<bodyText confidence="0.999689833333333">
The overall score of a situated candidate is gen-
erally a function of the scores of all the tiles for the
candidate, as well as the relations between the tiles&apos;
positions. These relations include tile adjacency,
overlap between tiles, the amount of context in a
tile, and so on.
</bodyText>
<subsubsectionHeader confidence="0.790801">
2.1.2 An instantiation of the MBSL schema
</subsubsectionHeader>
<bodyText confidence="0.999297">
In our instantiation of the MBSL schema, we define
the score f(t) of a tile t as the ratio of its positive
count pos(t) and its total count total(t):
</bodyText>
<equation confidence="0.991084666666667">
( yOs(t) 0
f(t) = total(t)
0 otherwise
</equation>
<bodyText confidence="0.999554">
for a predefined threshold 0. Tiles with a score of
1, and so with sufficient positive evidence, are called
matching tiles.
Each matching tile gives supporting evidence that
a part of the candidate can be a part of a target in-
stance. In order to combine this evidence, we try to
cover the entire candidate by a set of matching tiles,
with no gaps. Such a covering constitutes evidence
that the entire candidate is a target instance. For
example, consider the matching tiles shown for the
candidate in Figure 1. The set of matching tiles 2,
4, and 5 covers the candidate, as does the set of tiles
1 and 5. Also note that tile 1 constitutes a cover on
its own.
To make this precise, we first say that a tile T1
connects to a tile 7&apos;2 if (i) 2&apos;2 starts after T1 starts,
(ii) there is no gap between the end of T1 and the
start of 7&apos;2 (there may be some overlap), and (iii) T2
ends after T1 (neither tile includes the other). For
example, tiles 2 and 4 in the figure connect, while
tiles 2 and 5 do not, and neither do tiles 1 and 4
(since tile 1 includes tile 4 as a subsequence).
A cover for a situated candidate c is a sequence
of matching tiles which collectively cover the en-
tire candidate, including the boundary brackets, and
possibly some context, such that each tile connects
to the following one. A cover thus provides posi-
tive evidence for the entire sequence of tags in the
candidate.
The set of all the covers for a candidate summa-
rizes all of the evidence for the candidate being a
target instance. We therefore compute the score of
a candidate as a function of some statistics of the
set of all its covers. For example, if a candidate has
many different covers, it is more likely to be a target
instance, since many different pieces of evidence can
be brought to bear.
We have empirically found several statistics of the
cover set to be useful. These include, for each cover,
the number of tiles it contains, the total number of
context tags it contains, and the number of positions
which more than one tile covers (the amount of over-
lap). We thus compute, for the set of all covers of a
candidate c, the
</bodyText>
<listItem confidence="0.991074">
• Total number of different covers, num(c),
• Minimum number of matches in any cover,
minsize(c),
• Maximum amount of context in any cover,
maxcontext(c), and
• Maximum total overlap between tiles for any
cover, maxoverlap (c).
</listItem>
<bodyText confidence="0.9871996">
Each of these items gives an indication regarding the
overall strength of the cover-based evidence for the
candidate.
The score of the candidate is a linear function of
its statistics:
</bodyText>
<equation confidence="0.974717333333333">
f(c) = a num(c) — minsize(c)+
maxcontext (c)+
6 maxoverlap (c)
</equation>
<bodyText confidence="0.999836481481482">
If candidate c has no covers, we set f(c) = 0. Note
that minsize is weighted negatively, since a cover
with fewer tiles provides stronger evidence for the
candidate.
In the current implementation, the weights were
chosen so as to give a lexicographic ordering, pre-
ferring first candidates with more covers, then those
with covers containing fewer tiles, then those with
larger contexts, and finally, when all else is equal,
preferring candidates with more overlap between
tiles. We plan to investigate in the future a data-
driven approach (based on the Winnow algorithm)
for optimal selection and weighting of statistical fea-
tures of the score.
We compute a candidate&apos;s statistics efficiently by
performing a depth-first traversal of the cover graph
of the candidate. The cover graph is a directed
acyclic graph (DAG) whose nodes represent match-
ing tiles of the candidate, such that an arc exists
between nodes n and n&apos;, if tile n connects to n&apos;. A
special start node is added as the root of the DAG,
that connects to all of the nodes (tiles) that contain
an open bracket. There is a cover corresponding to
each path from the start node to a node (tile) that
contains a close bracket. Thus the statistics of all the
covers may be efficiently computed by traversing the
cover graph.
</bodyText>
<page confidence="0.994637">
69
</page>
<sectionHeader confidence="0.275866" genericHeader="method">
2.1.3 Summary
</sectionHeader>
<listItem confidence="0.928801153846154">
Given a candidate sequence and its context (a situ-
ated candidate):
1. Consider all the subsequences of the situated
candidate which include a bracket as tiles;
2. Compute a tile score as a function of its positive
count and total counts, by searching the train-
ing corpus. Determine which tiles are matching
tiles;
3. Construct the set of all possible covers for
the candidate, that is, sequences of connected
matching tiles that cover the entire candidate;
4. Compute the candidate score based on the
statistics of its covers.
</listItem>
<subsectionHeader confidence="0.9991">
2.2 Searching the training memory
</subsectionHeader>
<bodyText confidence="0.999985190476191">
The MBSL scoring algorithm searches the training
corpus for each subsequence of the sentence in or-
der to find matching tiles. Implementing this search
efficiently is therefore of prime importance. We do
so by encoding the training corpus using suffix trees
(Edward and McCreight, 1976), which provide string
searching in time which is linear in the length of the
searched string.
Inspired by Satta (1997), we build two suffix trees
for retrieving the positive and total counts for a tile.
The first suffix tree holds all pattern instances from
the training corpus surrounded by bracket symbols
and a fixed amount of context. Searching a given
tile (which includes a bracket symbol) in this tree
yields the positive count for the tile. The second
suffix tree holds an unbracketed version of the en-
tire training corpus. This tree is used for searching
the POS sequence of a tile, with brackets omitted,
yielding the total count for the tile (recall that the
negative count is the difference between the total
and positive counts).
</bodyText>
<subsectionHeader confidence="0.999798">
2.3 Selecting candidates
</subsectionHeader>
<bodyText confidence="0.999665875">
After the above procedure, each situated candidate
is assigned a score. In order to select a bracketing for
the input sentence, we assume that target instances
are non-overlapping (this is usually the case for the
types of patterns with which we experimented). We
use a simple constraint propagation algorithm that
finds the best choice of non-overlapping candidates
in an input sentence:
</bodyText>
<listItem confidence="0.975302166666667">
1. Examine each situated candidate c with
f (c) &gt; 0, in descending order of f (c):
(a) Add c&apos;s brackets to the sentence;
(b) Remove all situated candidates overlapping
with c which have not yet been examined.
2. Return the bracketed sentence.
</listItem>
<table confidence="0.9712718">
Train Data.
sentences words patterns
NP 8936 229598 54760
VO 16397 454375 14271
SV 16397 454375 25024
Test Data:
sentences words patterns
NP 2012 51401 12335
VO 1921 53604 1626
SV 1921 53604 3044
</table>
<tableCaption confidence="0.995814">
Table 1: Sizes of training and test data
</tableCaption>
<table confidence="0.999331285714286">
Len NP % VO % SV %
1 16959 31
2 21577 39 3203 22 7613 30
3 10264 19 5922 41 7265 29
4 3630 7 2952 21 3284 13
5 1460 3 1242 9 1697 7
6 521 1 506 4 1112 4
7 199 0 242 2 806 3
8 69 0 119 1 .592 2
9 40 0 44 0 446 2
10 18 0 20 0 392 2
&gt;10 23 0 23 0 1917 8
total 54760 14271 25024
avg. len 2.2 3.4 4.5
</table>
<tableCaption confidence="0.952347">
Table 2: Distribution of pattern lengths, total num-
</tableCaption>
<bodyText confidence="0.7139815">
ber of patterns and average length in the training
data.
</bodyText>
<sectionHeader confidence="0.997999" genericHeader="method">
3 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.998547">
3.1 The Data
</subsectionHeader>
<bodyText confidence="0.95449645">
We have tested our algorithm in recognizing three
syntactic patterns: noun phrase sequences (NP),
verb-object (VO), and subject-verb (SV) relations.
The NP patterns were delimited by &apos;P and &apos; ] &apos;
symbols at the borders of the phrase. For VO pat-
terns, we have put the starting delimiter before the
main verb and the ending delimiter after the object
head, thus covering the whole noun phrase compris-
ing the object; for example:
... investigators started to
[ view the lower price levels 7
as attractive ...
We used a similar policy for SV patterns, defining
the start of the pattern at the start of the subject
noun phrase and the end at the first verb encoun-
tered (not including auxiliaries and modals); for ex-
ample:
... argue that
[ the U.S. should regulate ]
the class ...
</bodyText>
<page confidence="0.978898">
70
</page>
<figure confidence="0.984384333333333">
90
a. 80
70
</figure>
<figureCaption confidence="0.9800225">
Figure 2: Recall-Precision curves for NP, VO, and
SV; 0.1 &lt;9 &lt;0.99
</figureCaption>
<bodyText confidence="0.999795235294118">
The subject and object noun-phrase borders were
those specified by the annotators, phrases which con-
tain conjunctions or appositives were not further an-
alyzed.
The training and testing data were derived from
the Penn TreeBank. We used the NP data prepared
by Ramshaw and Marcus (1995), hereafter RM95.
The SV and VO data were obtained using T (Tree-
Bank&apos;s search script language) scripts.2 Table 1
summarizes the sizes of the training and test data
sets and the number of examples in each.
The T scripts did not attempt to match depen-
dencies over very complex structures, since we are
concerned with shallow, or local, patterns. Table 2
shows the distribution of pattern length in the train
data. We also did not attempt to extract passive-
voice VO relations.
</bodyText>
<subsectionHeader confidence="0.99991">
3.2 Testing Methodology
</subsectionHeader>
<bodyText confidence="0.999184555555556">
The test procedure has two parameters: (a) maxi-
mum context size of a candidate, which limits what
queries are performed on the memory, and (b) the
threshold 9 used for establishing a matching tile,
which determines how to make use of the query re-
sults.
Recall and precision figures were obtained for var-
ious parameter values. Fo (van Rijsbergen, 1979), a
common measure in information retrieval, was used
</bodyText>
<footnote confidence="0.931034">
2The scripts may be found at the URL
http://www.cs.biu.ac.il/yuvalk/MBSL.
</footnote>
<bodyText confidence="0.951652">
as a single-figure measure of performance:
</bodyText>
<equation confidence="0.971899">
(#2 + 1) • P • R
= 02 p R
</equation>
<bodyText confidence="0.9957775">
We use # = 1 which gives no preference to either
recall or precision.
</bodyText>
<subsectionHeader confidence="0.966294">
3.3 Results
</subsectionHeader>
<bodyText confidence="0.999755219512195">
Table 3 summarizes the optimal parameter settings
and results for NP, VO, and SV on the test set. In
order to find the optimal values of the context size
and threshold, we tried 0.1 &lt; 9 &lt; 0.95, and maxi-
mum context sizes of 1,2, and 3. Our experiments
used 5-fold cross-validation on the training data to
determine the optimal parameter settings.
In experimenting with the maximum context size
parameter, we found that the difference between the
values of Fo for context sizes of 2 and 3 is less than
0.5% for the optimal threshold. Scores for a context
size of 1 yielded Fo values smaller by more than 1%
than the values for the larger contexts.
Figure 2 shows recall/precision curves for the
three data sets, obtained by varying 9 while keeping
the maximum context size at its optimal value. The
difference between Fo=1 values for different thresh-
olds was always less than 2%.
Performance may be measured also on a word-by
word basis, counting as a success any word which
was identified correctly as being part of the tar-
get pattern. That method was employed, along
with recall/precision, by RM95. We preferred to
measure performance by recall and precision for
complete patterns. Most errors involved identifica-
tions of slightly shifted, shorter or longer sequences.
Given a pattern consisting of five words, for example,
identifying only a four-word portion of this pattern
would yield both a recall and precision errors. Tag-
assignment scoring, on the other hand, will give it a
score of 80%. We hold the view that such an identi-
fication is an error, rather than a partial success.
We used the datasets created by RM95 for NP
learning; their results are shown in Table 3.3 The
Fo difference is small (0.4%), yet they use a richer
feature set, which incorporates lexical information as
well. The method of Ramshaw and Marcus makes a
decision per word, relying on predefined rule tem-
plates. The method presented here makes deci-
sions on sequences and uses sequences as its mem-
ory, thereby attaining a dynamic perspective of the
</bodyText>
<footnote confidence="0.982378875">
3Notice that our results, as well as those we cite from
RM95, pertains to a training set of 229,000 words. RM95
report also results for a larger training set, of 950,000 words,
for which recall/precision is 93.5%/93.1%, correspondingly
(F0=93.3%). Our system needs to be further optimized in
order to handle that amount of data, though our major con-
cern in future work is to reduce the overall amount of labeled
training data.
</footnote>
<figure confidence="0.856609">
70
80
Recall
90
</figure>
<page confidence="0.991609">
71
</page>
<table confidence="0.9986646">
Con. Thresh. BE Recall (%) Precision (%)
VO 2 0.5 81.3 89.8 77.1 83.0
SV 3 0.6 86.1 84.5 88.6 86.5
NP 3 0.6 91.4 91.6 91.6 91.6
RM95 (NP) 92.3 91.8 92.0
</table>
<tableCaption confidence="0.999266">
Table 3: Results with optimal parameter settings for context size and threshold, and breakeven points. The
</tableCaption>
<bodyText confidence="0.6700205">
last line shows the results of Ramshaw and Marcus (1995) (recognizing NP&apos;s) with the same train/test data.
The optimal parameters were obtained by 5-fold cross-validation.
</bodyText>
<figure confidence="0.981145">
90
_
85
400000
200000 300000
Words
by number of examples (left) and words (right)
20000 40000
Examples
</figure>
<figureCaption confidence="0.87559">
Figure 3: Learning curves for NP, VO, and SV
</figureCaption>
<figure confidence="0.995408777777778">
90
85
80
NP. 9=0.7 Con-2
SV, 9=0.9 Con...3
80
ij
75
1 I
VO, 9=0.3 Con-2
-
_ NP, 9=0.7 Con-2
_ SV, 9=0.8 Con.=3
- /
- I
J-
_ VO, 9=0.3 Con....2
; „
</figure>
<bodyText confidence="0.998611166666667">
pattern structure. We aim to incorporate lexical in-
formation as well in the future, it is still unclear
whether that will improve the results.
Figure 3 shows the learning curves by amount of
training examples and number of words in the train-
ing data, for particular parameter settings.
</bodyText>
<sectionHeader confidence="0.999974" genericHeader="method">
4 Related Work
</sectionHeader>
<bodyText confidence="0.99996">
Two previous methods for learning local syntactic
patterns follow the transformation-based paradigm
introduced by Brill (1992). Vilain and Day (1996)
identify (and classify) name phrases such as com-
pany names, locations, etc. Ramshaw and Marcus
(1995) detect noun phrases, by classifying each word
as being inside a phrase, outside or on the boundary
between phrases.
Finite state machines (FSMs) are a natural for-
malism for learning linear sequences. It was used
for learning linguistic structures other than shallow
syntax. Gold (1978) showed that learning regular
languages from positive examples is undecidable in
the limit. Recently, however, several learning meth-
ods have been proposed for restricted classes of FSM.
OSTIA (Onward Subsequential Transducer Infer-
ence Algorithm; Oncina, Garcia, and Vidal 1993),
learns a subsequential transducer in the limit. This
algorithm was used for natural-language tasks by Vi-
lar, Marzal, and Vidal (1994) for learning translation
of a limited-domain language, as well as by Gildea
and Jurafsky (1994) for learning phonological rules.
Ahonen et al. (1994) describe an algorithm for learn-
ing (k,h)-contextual regular languages, which they
use for learning the structure of SGML documents.
Apart from deterministic FSMs, there are a num-
ber of algorithms for learning stochastic models,
eg., (Stolcke and Omohundro, 1992; Carrasco and
Oncina, 1994; Ron et al., 1995). These algorithms
differ mainly by their state-merging strategies, used
for generalizing from the training data.
A major difference between the abovementioned
learning methods and our memory-based approach is
that the former employ generalized models that were
created at training time while the latter uses the
training corpus as-is and generalizes only at recog-
nition time.
Much work aimed at learning models for full pars-
ing, i.e., learning hierarchical structures. We re-
fer here only to the DOP (Data Oriented Parsing)
method (Bod, 1992) which, like the present work, is
a memory-based approach. This method constructs
parse alternatives for a sentence based on combina-
tions of subtrees in the training corpus. The MBSL
approach may be viewed as a linear analogy to DOP
in that it constructs a cover for a candidate based
</bodyText>
<page confidence="0.994091">
72
</page>
<bodyText confidence="0.999229">
on subsequences of training instances.
Other implementations of the memory-based
paradigm for NLP tasks include Daelemans et al.
(1996), for POS tagging; Cardie (1993), for syntactic
and semantic tagging; and Stanfill and Waltz (1986),
for word pronunciation. In all these works, examples
are represented as sets of features and the deduction
is carried out by finding the most similar cases. The
method presented here is radically different in that
it makes use of the raw sequential form of the data,
and generalizes by reconstructing test examples from
different pieces of the training data.
</bodyText>
<sectionHeader confidence="0.999293" genericHeader="method">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999950909090909">
We have presented a novel general schema and a par-
ticular instantiation of it for learning sequential pat-
terns. Applying the method to three syntactic pat-
terns in English yielded positive results, suggesting
its applicability for recognizing local linguistic pat-
terns. In future work we plan to investigate a data-
driven approach for optimal selection and weighting
of statistical features of candidate scores, as well as
to apply the method to syntactic patterns of Hebrew
and to domain-specific patterns for information ex-
traction.
</bodyText>
<sectionHeader confidence="0.996637" genericHeader="conclusions">
6 acknowledgements
</sectionHeader>
<bodyText confidence="0.998637625">
The authors wish to thank Yoram Singer for his
collaboration in an earlier phase of this research
project, and Giorgio Satta for helpful discussions.
We aiso thank the anonymous reviewers for their in-
structive comments. This research was supported
in part by grant 498/95-1 from the Israel Science
Foundation, and by grant 8560296 from the Israeli
Ministry of Science.
</bodyText>
<sectionHeader confidence="0.997876" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999732863013699">
S. P. Abney. 1991. Parsing by chunks. In R. C.
Berwick, S. P. Abney, and C. Tenny, editors,
Principle-Based Parsing: Computation and Psy-
cholinguistics, pages 257-278. Kluwer, Dordrecht.
H. Ahonen, H. Mannila, and E. Nikunen. 1994.
Forming grammars for structured documents: An
application of grammatical inference. In R. C.
Carrasco and J. Oncina, editors, Grammatical In-
ference and Applications (ICGI-94), pages 153-
167. Springer, Berlin, Heidelberg.
R. Bod. 1992. A computational model of language
performance: Data oriented parsing. In Coling,
pages 855-859, Nantes, Prance.
E. Brill. 1992. A simple rule-based part of speech
tagger. In proc. of the DARPA Workshop on
Speech and Natural Language.
C. Cardie. 1993. A case-based approach to knowl-
edge acquisition for domain-specific sentence anal-
ysis. In Proceedings of the 11th National Con-
ference on Artificial Intelligence, pages 798-803,
Menlo Park, CA, USA, July. AAAI Press.
R. C. Carrasco and J. Oncina. 1994. Learn-
ing stochastic regular grammars by means of a
state merging method. In R. C. Carrasco and
J. Oncina, editors, Grammatical Inference and
Applications (ICGI-94), pages 139-152. Springer,
Berlin, Heidelberg.
W. Daelemans, J. Zavrel, Berck P., and Gillis S.
1996. Mbt: A memory-based part of speech tag-
ger generator. In Eva Ejerhed and Ido Dagan, edi-
tors, Proceedings of the Fourth Workshop on Very
Large Corpora, pages 14-27. ACL SIGDAT.
T. Edward and M. McCreight. 1976. space-
economical suffix tree construction algorithm.
Journal of the ACM, 23(2):262-272, April.
D. Gildea and D. Jurafsky. 1994. Automatic induc-
tion of finite state transducers for simple phono-
logical rules. Technical Report TR-94-052, In-
ternational Computer Science Institute, Berkeley,
CA, October.
E. M. Gold. 1978. Complexity of automaton iden-
tification from given data. Information and Con-
trol, 37:302-320.
Gregory Greffenstette. 1993. Evaluation techniques
for automatic semantic extraction: Comparing
syntactic and window based approaches. In ACL
Workshop on Acquisition of Lexical Knowledge
From Text, Ohio State University, June.
L. A. Ramshaw and M. P. Marcus. 1995. Text
chunking using transformation-based learning. In
Proceedings of the Third Workshop on Very Large
Corpora.
D. Ron, Y. Singer, and N. Tishby. 1995. On the
learnability and usage of acyclic probabilistic fi-
nite automata. In Proceedings of the 8th Annual
Conference on Computational Learning Theory
(COLT&apos;95), pages 31-40, New York, NY, USA,
July. ACM Press.
G. Satta. 1997. String transformation learning. In
Proc. of the ACL/EACL Annual Meeting, pages
444-451, Madrid, Spain, July.
C. Stanfill and D. Waltz. 1986. Toward memory-
based reasoning. Communications of the ACM,
29(12):1213-1228, December.
A. Stolcke and S. Omohundro. 1992. Hidden
markov model induction by bayesian model merg-
ing. In Proceedings of Neural Information Pro-
cessing Systems 5 (NIPS-5).
C. J. van Rijsbergen. 1979. Information Retrieval.
Buttersworth.
M. B. Vilain and D. S. Day. 1996. Finite-state
phrase parsing by rule sequences. In Proc. of
COLING, Copenhagen, Denmark.
</reference>
<page confidence="0.999299">
73
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.984844">
<title confidence="0.99938">A Memory-Based Approach to Learning Shallow Natural Language Patterns</title>
<author confidence="0.999589">Argamon Dagan Krymolowski</author>
<affiliation confidence="0.999804">Department of Mathematics and Computer Science Bar-Ilan University</affiliation>
<address confidence="0.999586">52900 Ramat Gan, Israel</address>
<email confidence="0.999548">fargamon,dagan,yuvalkl@cs.biu.ac.il</email>
<abstract confidence="0.999478208333333">Recognizing shallow linguistic patterns, such as basic syntactic relationships between words, is a common task in applied natural language and text processing. The common practice for approaching this task is by tedious manual definition of possible pattern structures, often in the form of regular expressions or finite automata. This paper presents a novel memory-based learning method that recognizes shallow patterns in new text based on a bracketed training corpus. The training data are stored as-is, in efficient suffix-tree data structures. Generalization is performed on-line at recognition time by comparing subsequences of the new text to positive and negative evidence in the corpus. This way, no information in the training is lost, as can happen in other learning systems that construct a single generalized model at the time of training. The paper presents experimental results for recognizing noun phrase, subject-verb and verb-object patterns in English. Since the learning approach enables easy porting to new domains, we plan to apply it to syntactic patterns in other languages and to sub-language patterns for information extraction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S P Abney</author>
</authors>
<title>Parsing by chunks. In</title>
<date>1991</date>
<booktitle>Principle-Based Parsing: Computation and Psycholinguistics,</booktitle>
<pages>257--278</pages>
<editor>R. C. Berwick, S. P. Abney, and C. Tenny, editors,</editor>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="2589" citStr="Abney, 1991" startWordPosition="397" endWordPosition="398">cal word similarity and various disambiguation problems. One approach for detecting syntactic patterns is to obtain a full parse of a sentence and then extract the required patterns. However, obtaining a complete parse tree for a sentence is difficult in many cases, and may not be necessary at all for identifying most instances of local syntactic patterns. An alternative approach is to avoid the complexity of full parsing and instead to rely only on local information. A variety of methods have been developed within this framework, known as shallow parsing, chunking, local parsing etc. (e.g., (Abney, 1991; Greffenstette, 1993)). These works have shown that it is possible to identify most instances of local syntactic patterns by rules that examine only the pattern itself and its nearby context. Often, the rules are applied to sentences that were tagged by partof-speech (POS) and are phrased by some form of regular expressions or finite state automata. Manual writing of local syntactic rules has become a common practice for many applications. However, writing rules is often tedious and time consuming. Furthermore, extending the rules to different languages or sub-language domains can require sub</context>
</contexts>
<marker>Abney, 1991</marker>
<rawString>S. P. Abney. 1991. Parsing by chunks. In R. C. Berwick, S. P. Abney, and C. Tenny, editors, Principle-Based Parsing: Computation and Psycholinguistics, pages 257-278. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ahonen</author>
<author>H Mannila</author>
<author>E Nikunen</author>
</authors>
<title>Forming grammars for structured documents: An application of grammatical inference. In</title>
<date>1994</date>
<booktitle>Grammatical Inference and Applications (ICGI-94),</booktitle>
<pages>153--167</pages>
<editor>R. C. Carrasco and J. Oncina, editors,</editor>
<publisher>Springer,</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="23894" citStr="Ahonen et al. (1994)" startWordPosition="4085" endWordPosition="4088">nguistic structures other than shallow syntax. Gold (1978) showed that learning regular languages from positive examples is undecidable in the limit. Recently, however, several learning methods have been proposed for restricted classes of FSM. OSTIA (Onward Subsequential Transducer Inference Algorithm; Oncina, Garcia, and Vidal 1993), learns a subsequential transducer in the limit. This algorithm was used for natural-language tasks by Vilar, Marzal, and Vidal (1994) for learning translation of a limited-domain language, as well as by Gildea and Jurafsky (1994) for learning phonological rules. Ahonen et al. (1994) describe an algorithm for learning (k,h)-contextual regular languages, which they use for learning the structure of SGML documents. Apart from deterministic FSMs, there are a number of algorithms for learning stochastic models, eg., (Stolcke and Omohundro, 1992; Carrasco and Oncina, 1994; Ron et al., 1995). These algorithms differ mainly by their state-merging strategies, used for generalizing from the training data. A major difference between the abovementioned learning methods and our memory-based approach is that the former employ generalized models that were created at training time while</context>
</contexts>
<marker>Ahonen, Mannila, Nikunen, 1994</marker>
<rawString>H. Ahonen, H. Mannila, and E. Nikunen. 1994. Forming grammars for structured documents: An application of grammatical inference. In R. C. Carrasco and J. Oncina, editors, Grammatical Inference and Applications (ICGI-94), pages 153-167. Springer, Berlin, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bod</author>
</authors>
<title>A computational model of language performance: Data oriented parsing.</title>
<date>1992</date>
<booktitle>In Coling,</booktitle>
<pages>855--859</pages>
<location>Nantes, Prance.</location>
<contexts>
<context position="24744" citStr="Bod, 1992" startWordPosition="4217" endWordPosition="4218">ke and Omohundro, 1992; Carrasco and Oncina, 1994; Ron et al., 1995). These algorithms differ mainly by their state-merging strategies, used for generalizing from the training data. A major difference between the abovementioned learning methods and our memory-based approach is that the former employ generalized models that were created at training time while the latter uses the training corpus as-is and generalizes only at recognition time. Much work aimed at learning models for full parsing, i.e., learning hierarchical structures. We refer here only to the DOP (Data Oriented Parsing) method (Bod, 1992) which, like the present work, is a memory-based approach. This method constructs parse alternatives for a sentence based on combinations of subtrees in the training corpus. The MBSL approach may be viewed as a linear analogy to DOP in that it constructs a cover for a candidate based 72 on subsequences of training instances. Other implementations of the memory-based paradigm for NLP tasks include Daelemans et al. (1996), for POS tagging; Cardie (1993), for syntactic and semantic tagging; and Stanfill and Waltz (1986), for word pronunciation. In all these works, examples are represented as sets</context>
</contexts>
<marker>Bod, 1992</marker>
<rawString>R. Bod. 1992. A computational model of language performance: Data oriented parsing. In Coling, pages 855-859, Nantes, Prance.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>A simple rule-based part of speech tagger.</title>
<date>1992</date>
<booktitle>In proc. of the DARPA Workshop on Speech and Natural Language.</booktitle>
<contexts>
<context position="22921" citStr="Brill (1992)" startWordPosition="3939" endWordPosition="3940">e 3: Learning curves for NP, VO, and SV 90 85 80 NP. 9=0.7 Con-2 SV, 9=0.9 Con...3 80 ij 75 1 I VO, 9=0.3 Con-2 - _ NP, 9=0.7 Con-2 _ SV, 9=0.8 Con.=3 - / - I J_ VO, 9=0.3 Con....2 ; „ pattern structure. We aim to incorporate lexical information as well in the future, it is still unclear whether that will improve the results. Figure 3 shows the learning curves by amount of training examples and number of words in the training data, for particular parameter settings. 4 Related Work Two previous methods for learning local syntactic patterns follow the transformation-based paradigm introduced by Brill (1992). Vilain and Day (1996) identify (and classify) name phrases such as company names, locations, etc. Ramshaw and Marcus (1995) detect noun phrases, by classifying each word as being inside a phrase, outside or on the boundary between phrases. Finite state machines (FSMs) are a natural formalism for learning linear sequences. It was used for learning linguistic structures other than shallow syntax. Gold (1978) showed that learning regular languages from positive examples is undecidable in the limit. Recently, however, several learning methods have been proposed for restricted classes of FSM. OST</context>
</contexts>
<marker>Brill, 1992</marker>
<rawString>E. Brill. 1992. A simple rule-based part of speech tagger. In proc. of the DARPA Workshop on Speech and Natural Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cardie</author>
</authors>
<title>A case-based approach to knowledge acquisition for domain-specific sentence analysis.</title>
<date>1993</date>
<booktitle>In Proceedings of the 11th National Conference on Artificial Intelligence,</booktitle>
<pages>798--803</pages>
<publisher>AAAI Press.</publisher>
<location>Menlo Park, CA, USA,</location>
<contexts>
<context position="25199" citStr="Cardie (1993)" startWordPosition="4291" endWordPosition="4292">rk aimed at learning models for full parsing, i.e., learning hierarchical structures. We refer here only to the DOP (Data Oriented Parsing) method (Bod, 1992) which, like the present work, is a memory-based approach. This method constructs parse alternatives for a sentence based on combinations of subtrees in the training corpus. The MBSL approach may be viewed as a linear analogy to DOP in that it constructs a cover for a candidate based 72 on subsequences of training instances. Other implementations of the memory-based paradigm for NLP tasks include Daelemans et al. (1996), for POS tagging; Cardie (1993), for syntactic and semantic tagging; and Stanfill and Waltz (1986), for word pronunciation. In all these works, examples are represented as sets of features and the deduction is carried out by finding the most similar cases. The method presented here is radically different in that it makes use of the raw sequential form of the data, and generalizes by reconstructing test examples from different pieces of the training data. 5 Conclusions We have presented a novel general schema and a particular instantiation of it for learning sequential patterns. Applying the method to three syntactic pattern</context>
</contexts>
<marker>Cardie, 1993</marker>
<rawString>C. Cardie. 1993. A case-based approach to knowledge acquisition for domain-specific sentence analysis. In Proceedings of the 11th National Conference on Artificial Intelligence, pages 798-803, Menlo Park, CA, USA, July. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Carrasco</author>
<author>J Oncina</author>
</authors>
<title>Learning stochastic regular grammars by means of a state merging method. In</title>
<date>1994</date>
<booktitle>Grammatical Inference and Applications (ICGI-94),</booktitle>
<pages>139--152</pages>
<editor>R. C. Carrasco and J. Oncina, editors,</editor>
<publisher>Springer,</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="24183" citStr="Carrasco and Oncina, 1994" startWordPosition="4128" endWordPosition="4131">nference Algorithm; Oncina, Garcia, and Vidal 1993), learns a subsequential transducer in the limit. This algorithm was used for natural-language tasks by Vilar, Marzal, and Vidal (1994) for learning translation of a limited-domain language, as well as by Gildea and Jurafsky (1994) for learning phonological rules. Ahonen et al. (1994) describe an algorithm for learning (k,h)-contextual regular languages, which they use for learning the structure of SGML documents. Apart from deterministic FSMs, there are a number of algorithms for learning stochastic models, eg., (Stolcke and Omohundro, 1992; Carrasco and Oncina, 1994; Ron et al., 1995). These algorithms differ mainly by their state-merging strategies, used for generalizing from the training data. A major difference between the abovementioned learning methods and our memory-based approach is that the former employ generalized models that were created at training time while the latter uses the training corpus as-is and generalizes only at recognition time. Much work aimed at learning models for full parsing, i.e., learning hierarchical structures. We refer here only to the DOP (Data Oriented Parsing) method (Bod, 1992) which, like the present work, is a mem</context>
</contexts>
<marker>Carrasco, Oncina, 1994</marker>
<rawString>R. C. Carrasco and J. Oncina. 1994. Learning stochastic regular grammars by means of a state merging method. In R. C. Carrasco and J. Oncina, editors, Grammatical Inference and Applications (ICGI-94), pages 139-152. Springer, Berlin, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>J Zavrel</author>
<author>P Berck</author>
<author>S Gillis</author>
</authors>
<title>Mbt: A memory-based part of speech tagger generator.</title>
<date>1996</date>
<booktitle>In Eva Ejerhed and Ido Dagan, editors, Proceedings of the Fourth Workshop on Very Large Corpora,</booktitle>
<pages>14--27</pages>
<publisher>ACL SIGDAT.</publisher>
<contexts>
<context position="25167" citStr="Daelemans et al. (1996)" startWordPosition="4284" endWordPosition="4287">eralizes only at recognition time. Much work aimed at learning models for full parsing, i.e., learning hierarchical structures. We refer here only to the DOP (Data Oriented Parsing) method (Bod, 1992) which, like the present work, is a memory-based approach. This method constructs parse alternatives for a sentence based on combinations of subtrees in the training corpus. The MBSL approach may be viewed as a linear analogy to DOP in that it constructs a cover for a candidate based 72 on subsequences of training instances. Other implementations of the memory-based paradigm for NLP tasks include Daelemans et al. (1996), for POS tagging; Cardie (1993), for syntactic and semantic tagging; and Stanfill and Waltz (1986), for word pronunciation. In all these works, examples are represented as sets of features and the deduction is carried out by finding the most similar cases. The method presented here is radically different in that it makes use of the raw sequential form of the data, and generalizes by reconstructing test examples from different pieces of the training data. 5 Conclusions We have presented a novel general schema and a particular instantiation of it for learning sequential patterns. Applying the m</context>
</contexts>
<marker>Daelemans, Zavrel, Berck, Gillis, 1996</marker>
<rawString>W. Daelemans, J. Zavrel, Berck P., and Gillis S. 1996. Mbt: A memory-based part of speech tagger generator. In Eva Ejerhed and Ido Dagan, editors, Proceedings of the Fourth Workshop on Very Large Corpora, pages 14-27. ACL SIGDAT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Edward</author>
<author>M McCreight</author>
</authors>
<title>spaceeconomical suffix tree construction algorithm.</title>
<date>1976</date>
<journal>Journal of the ACM,</journal>
<pages>23--2</pages>
<contexts>
<context position="14958" citStr="Edward and McCreight, 1976" startWordPosition="2525" endWordPosition="2528"> and total counts, by searching the training corpus. Determine which tiles are matching tiles; 3. Construct the set of all possible covers for the candidate, that is, sequences of connected matching tiles that cover the entire candidate; 4. Compute the candidate score based on the statistics of its covers. 2.2 Searching the training memory The MBSL scoring algorithm searches the training corpus for each subsequence of the sentence in order to find matching tiles. Implementing this search efficiently is therefore of prime importance. We do so by encoding the training corpus using suffix trees (Edward and McCreight, 1976), which provide string searching in time which is linear in the length of the searched string. Inspired by Satta (1997), we build two suffix trees for retrieving the positive and total counts for a tile. The first suffix tree holds all pattern instances from the training corpus surrounded by bracket symbols and a fixed amount of context. Searching a given tile (which includes a bracket symbol) in this tree yields the positive count for the tile. The second suffix tree holds an unbracketed version of the entire training corpus. This tree is used for searching the POS sequence of a tile, with br</context>
</contexts>
<marker>Edward, McCreight, 1976</marker>
<rawString>T. Edward and M. McCreight. 1976. spaceeconomical suffix tree construction algorithm. Journal of the ACM, 23(2):262-272, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic induction of finite state transducers for simple phonological rules.</title>
<date>1994</date>
<tech>Technical Report TR-94-052,</tech>
<institution>International Computer Science Institute,</institution>
<location>Berkeley, CA,</location>
<contexts>
<context position="23840" citStr="Gildea and Jurafsky (1994)" startWordPosition="4077" endWordPosition="4080">m for learning linear sequences. It was used for learning linguistic structures other than shallow syntax. Gold (1978) showed that learning regular languages from positive examples is undecidable in the limit. Recently, however, several learning methods have been proposed for restricted classes of FSM. OSTIA (Onward Subsequential Transducer Inference Algorithm; Oncina, Garcia, and Vidal 1993), learns a subsequential transducer in the limit. This algorithm was used for natural-language tasks by Vilar, Marzal, and Vidal (1994) for learning translation of a limited-domain language, as well as by Gildea and Jurafsky (1994) for learning phonological rules. Ahonen et al. (1994) describe an algorithm for learning (k,h)-contextual regular languages, which they use for learning the structure of SGML documents. Apart from deterministic FSMs, there are a number of algorithms for learning stochastic models, eg., (Stolcke and Omohundro, 1992; Carrasco and Oncina, 1994; Ron et al., 1995). These algorithms differ mainly by their state-merging strategies, used for generalizing from the training data. A major difference between the abovementioned learning methods and our memory-based approach is that the former employ gener</context>
</contexts>
<marker>Gildea, Jurafsky, 1994</marker>
<rawString>D. Gildea and D. Jurafsky. 1994. Automatic induction of finite state transducers for simple phonological rules. Technical Report TR-94-052, International Computer Science Institute, Berkeley, CA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Gold</author>
</authors>
<title>Complexity of automaton identification from given data.</title>
<date>1978</date>
<journal>Information and Control,</journal>
<pages>37--302</pages>
<contexts>
<context position="23332" citStr="Gold (1978)" startWordPosition="4004" endWordPosition="4005">s in the training data, for particular parameter settings. 4 Related Work Two previous methods for learning local syntactic patterns follow the transformation-based paradigm introduced by Brill (1992). Vilain and Day (1996) identify (and classify) name phrases such as company names, locations, etc. Ramshaw and Marcus (1995) detect noun phrases, by classifying each word as being inside a phrase, outside or on the boundary between phrases. Finite state machines (FSMs) are a natural formalism for learning linear sequences. It was used for learning linguistic structures other than shallow syntax. Gold (1978) showed that learning regular languages from positive examples is undecidable in the limit. Recently, however, several learning methods have been proposed for restricted classes of FSM. OSTIA (Onward Subsequential Transducer Inference Algorithm; Oncina, Garcia, and Vidal 1993), learns a subsequential transducer in the limit. This algorithm was used for natural-language tasks by Vilar, Marzal, and Vidal (1994) for learning translation of a limited-domain language, as well as by Gildea and Jurafsky (1994) for learning phonological rules. Ahonen et al. (1994) describe an algorithm for learning (k</context>
</contexts>
<marker>Gold, 1978</marker>
<rawString>E. M. Gold. 1978. Complexity of automaton identification from given data. Information and Control, 37:302-320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Greffenstette</author>
</authors>
<title>Evaluation techniques for automatic semantic extraction: Comparing syntactic and window based approaches.</title>
<date>1993</date>
<booktitle>In ACL Workshop on Acquisition of Lexical Knowledge</booktitle>
<institution>From Text, Ohio State University,</institution>
<contexts>
<context position="2611" citStr="Greffenstette, 1993" startWordPosition="399" endWordPosition="400">larity and various disambiguation problems. One approach for detecting syntactic patterns is to obtain a full parse of a sentence and then extract the required patterns. However, obtaining a complete parse tree for a sentence is difficult in many cases, and may not be necessary at all for identifying most instances of local syntactic patterns. An alternative approach is to avoid the complexity of full parsing and instead to rely only on local information. A variety of methods have been developed within this framework, known as shallow parsing, chunking, local parsing etc. (e.g., (Abney, 1991; Greffenstette, 1993)). These works have shown that it is possible to identify most instances of local syntactic patterns by rules that examine only the pattern itself and its nearby context. Often, the rules are applied to sentences that were tagged by partof-speech (POS) and are phrased by some form of regular expressions or finite state automata. Manual writing of local syntactic rules has become a common practice for many applications. However, writing rules is often tedious and time consuming. Furthermore, extending the rules to different languages or sub-language domains can require substantial resources and</context>
</contexts>
<marker>Greffenstette, 1993</marker>
<rawString>Gregory Greffenstette. 1993. Evaluation techniques for automatic semantic extraction: Comparing syntactic and window based approaches. In ACL Workshop on Acquisition of Lexical Knowledge From Text, Ohio State University, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Ramshaw</author>
<author>M P Marcus</author>
</authors>
<title>Text chunking using transformation-based learning.</title>
<date>1995</date>
<booktitle>In Proceedings of the Third Workshop on Very Large Corpora.</booktitle>
<contexts>
<context position="3452" citStr="Ramshaw and Marcus, 1995" startWordPosition="533" endWordPosition="537"> were tagged by partof-speech (POS) and are phrased by some form of regular expressions or finite state automata. Manual writing of local syntactic rules has become a common practice for many applications. However, writing rules is often tedious and time consuming. Furthermore, extending the rules to different languages or sub-language domains can require substantial resources and expertise that are often not available. As in many areas of NLP, a learning approach is appealing. Surprisingly, though, rather little work has been devoted to learning local syntactic patterns, mostly noun phrases (Ramshaw and Marcus, 1995; Vilain and Day, 1996). This paper presents a novel general learning approach for recognizing local sequential patterns, that may be perceived as falling within the memorybased learning paradigm. The method utilizes a part-of-speech tagged training corpus in which all instances of the target pattern are marked (bracketed). The training data are stored as-is in suffix-tree data structures, which enable linear time searching for subsequences in the corpus. The memory-based nature of the presented algorithm stems from its deduction strategy: a new instance of the target pattern is recognized by </context>
<context position="18167" citStr="Ramshaw and Marcus (1995)" startWordPosition="3112" endWordPosition="3115">similar policy for SV patterns, defining the start of the pattern at the start of the subject noun phrase and the end at the first verb encountered (not including auxiliaries and modals); for example: ... argue that [ the U.S. should regulate ] the class ... 70 90 a. 80 70 Figure 2: Recall-Precision curves for NP, VO, and SV; 0.1 &lt;9 &lt;0.99 The subject and object noun-phrase borders were those specified by the annotators, phrases which contain conjunctions or appositives were not further analyzed. The training and testing data were derived from the Penn TreeBank. We used the NP data prepared by Ramshaw and Marcus (1995), hereafter RM95. The SV and VO data were obtained using T (TreeBank&apos;s search script language) scripts.2 Table 1 summarizes the sizes of the training and test data sets and the number of examples in each. The T scripts did not attempt to match dependencies over very complex structures, since we are concerned with shallow, or local, patterns. Table 2 shows the distribution of pattern length in the train data. We also did not attempt to extract passivevoice VO relations. 3.2 Testing Methodology The test procedure has two parameters: (a) maximum context size of a candidate, which limits what quer</context>
<context position="22085" citStr="Ramshaw and Marcus (1995)" startWordPosition="3791" endWordPosition="3794"> larger training set, of 950,000 words, for which recall/precision is 93.5%/93.1%, correspondingly (F0=93.3%). Our system needs to be further optimized in order to handle that amount of data, though our major concern in future work is to reduce the overall amount of labeled training data. 70 80 Recall 90 71 Con. Thresh. BE Recall (%) Precision (%) VO 2 0.5 81.3 89.8 77.1 83.0 SV 3 0.6 86.1 84.5 88.6 86.5 NP 3 0.6 91.4 91.6 91.6 91.6 RM95 (NP) 92.3 91.8 92.0 Table 3: Results with optimal parameter settings for context size and threshold, and breakeven points. The last line shows the results of Ramshaw and Marcus (1995) (recognizing NP&apos;s) with the same train/test data. The optimal parameters were obtained by 5-fold cross-validation. 90 _ 85 400000 200000 300000 Words by number of examples (left) and words (right) 20000 40000 Examples Figure 3: Learning curves for NP, VO, and SV 90 85 80 NP. 9=0.7 Con-2 SV, 9=0.9 Con...3 80 ij 75 1 I VO, 9=0.3 Con-2 - _ NP, 9=0.7 Con-2 _ SV, 9=0.8 Con.=3 - / - I J_ VO, 9=0.3 Con....2 ; „ pattern structure. We aim to incorporate lexical information as well in the future, it is still unclear whether that will improve the results. Figure 3 shows the learning curves by amount of </context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>L. A. Ramshaw and M. P. Marcus. 1995. Text chunking using transformation-based learning. In Proceedings of the Third Workshop on Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ron</author>
<author>Y Singer</author>
<author>N Tishby</author>
</authors>
<title>On the learnability and usage of acyclic probabilistic finite automata.</title>
<date>1995</date>
<booktitle>In Proceedings of the 8th Annual Conference on Computational Learning Theory (COLT&apos;95),</booktitle>
<pages>31--40</pages>
<publisher>ACM Press.</publisher>
<location>New York, NY, USA,</location>
<contexts>
<context position="24202" citStr="Ron et al., 1995" startWordPosition="4132" endWordPosition="4135"> Garcia, and Vidal 1993), learns a subsequential transducer in the limit. This algorithm was used for natural-language tasks by Vilar, Marzal, and Vidal (1994) for learning translation of a limited-domain language, as well as by Gildea and Jurafsky (1994) for learning phonological rules. Ahonen et al. (1994) describe an algorithm for learning (k,h)-contextual regular languages, which they use for learning the structure of SGML documents. Apart from deterministic FSMs, there are a number of algorithms for learning stochastic models, eg., (Stolcke and Omohundro, 1992; Carrasco and Oncina, 1994; Ron et al., 1995). These algorithms differ mainly by their state-merging strategies, used for generalizing from the training data. A major difference between the abovementioned learning methods and our memory-based approach is that the former employ generalized models that were created at training time while the latter uses the training corpus as-is and generalizes only at recognition time. Much work aimed at learning models for full parsing, i.e., learning hierarchical structures. We refer here only to the DOP (Data Oriented Parsing) method (Bod, 1992) which, like the present work, is a memory-based approach.</context>
</contexts>
<marker>Ron, Singer, Tishby, 1995</marker>
<rawString>D. Ron, Y. Singer, and N. Tishby. 1995. On the learnability and usage of acyclic probabilistic finite automata. In Proceedings of the 8th Annual Conference on Computational Learning Theory (COLT&apos;95), pages 31-40, New York, NY, USA, July. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Satta</author>
</authors>
<title>String transformation learning.</title>
<date>1997</date>
<booktitle>In Proc. of the ACL/EACL Annual Meeting,</booktitle>
<pages>444--451</pages>
<location>Madrid, Spain,</location>
<contexts>
<context position="15077" citStr="Satta (1997)" startWordPosition="2547" endWordPosition="2548">vers for the candidate, that is, sequences of connected matching tiles that cover the entire candidate; 4. Compute the candidate score based on the statistics of its covers. 2.2 Searching the training memory The MBSL scoring algorithm searches the training corpus for each subsequence of the sentence in order to find matching tiles. Implementing this search efficiently is therefore of prime importance. We do so by encoding the training corpus using suffix trees (Edward and McCreight, 1976), which provide string searching in time which is linear in the length of the searched string. Inspired by Satta (1997), we build two suffix trees for retrieving the positive and total counts for a tile. The first suffix tree holds all pattern instances from the training corpus surrounded by bracket symbols and a fixed amount of context. Searching a given tile (which includes a bracket symbol) in this tree yields the positive count for the tile. The second suffix tree holds an unbracketed version of the entire training corpus. This tree is used for searching the POS sequence of a tile, with brackets omitted, yielding the total count for the tile (recall that the negative count is the difference between the tot</context>
</contexts>
<marker>Satta, 1997</marker>
<rawString>G. Satta. 1997. String transformation learning. In Proc. of the ACL/EACL Annual Meeting, pages 444-451, Madrid, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Stanfill</author>
<author>D Waltz</author>
</authors>
<title>Toward memorybased reasoning.</title>
<date>1986</date>
<journal>Communications of the ACM,</journal>
<pages>29--12</pages>
<contexts>
<context position="25266" citStr="Stanfill and Waltz (1986)" startWordPosition="4299" endWordPosition="4302">rning hierarchical structures. We refer here only to the DOP (Data Oriented Parsing) method (Bod, 1992) which, like the present work, is a memory-based approach. This method constructs parse alternatives for a sentence based on combinations of subtrees in the training corpus. The MBSL approach may be viewed as a linear analogy to DOP in that it constructs a cover for a candidate based 72 on subsequences of training instances. Other implementations of the memory-based paradigm for NLP tasks include Daelemans et al. (1996), for POS tagging; Cardie (1993), for syntactic and semantic tagging; and Stanfill and Waltz (1986), for word pronunciation. In all these works, examples are represented as sets of features and the deduction is carried out by finding the most similar cases. The method presented here is radically different in that it makes use of the raw sequential form of the data, and generalizes by reconstructing test examples from different pieces of the training data. 5 Conclusions We have presented a novel general schema and a particular instantiation of it for learning sequential patterns. Applying the method to three syntactic patterns in English yielded positive results, suggesting its applicability</context>
</contexts>
<marker>Stanfill, Waltz, 1986</marker>
<rawString>C. Stanfill and D. Waltz. 1986. Toward memorybased reasoning. Communications of the ACM, 29(12):1213-1228, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
<author>S Omohundro</author>
</authors>
<title>Hidden markov model induction by bayesian model merging.</title>
<date>1992</date>
<booktitle>In Proceedings of Neural Information Processing Systems 5 (NIPS-5).</booktitle>
<contexts>
<context position="24156" citStr="Stolcke and Omohundro, 1992" startWordPosition="4124" endWordPosition="4127">rd Subsequential Transducer Inference Algorithm; Oncina, Garcia, and Vidal 1993), learns a subsequential transducer in the limit. This algorithm was used for natural-language tasks by Vilar, Marzal, and Vidal (1994) for learning translation of a limited-domain language, as well as by Gildea and Jurafsky (1994) for learning phonological rules. Ahonen et al. (1994) describe an algorithm for learning (k,h)-contextual regular languages, which they use for learning the structure of SGML documents. Apart from deterministic FSMs, there are a number of algorithms for learning stochastic models, eg., (Stolcke and Omohundro, 1992; Carrasco and Oncina, 1994; Ron et al., 1995). These algorithms differ mainly by their state-merging strategies, used for generalizing from the training data. A major difference between the abovementioned learning methods and our memory-based approach is that the former employ generalized models that were created at training time while the latter uses the training corpus as-is and generalizes only at recognition time. Much work aimed at learning models for full parsing, i.e., learning hierarchical structures. We refer here only to the DOP (Data Oriented Parsing) method (Bod, 1992) which, like</context>
</contexts>
<marker>Stolcke, Omohundro, 1992</marker>
<rawString>A. Stolcke and S. Omohundro. 1992. Hidden markov model induction by bayesian model merging. In Proceedings of Neural Information Processing Systems 5 (NIPS-5).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J van Rijsbergen</author>
</authors>
<date>1979</date>
<journal>Information Retrieval. Buttersworth.</journal>
<marker>van Rijsbergen, 1979</marker>
<rawString>C. J. van Rijsbergen. 1979. Information Retrieval. Buttersworth.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M B Vilain</author>
<author>D S Day</author>
</authors>
<title>Finite-state phrase parsing by rule sequences.</title>
<date>1996</date>
<booktitle>In Proc. of COLING,</booktitle>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="3475" citStr="Vilain and Day, 1996" startWordPosition="538" endWordPosition="541">ech (POS) and are phrased by some form of regular expressions or finite state automata. Manual writing of local syntactic rules has become a common practice for many applications. However, writing rules is often tedious and time consuming. Furthermore, extending the rules to different languages or sub-language domains can require substantial resources and expertise that are often not available. As in many areas of NLP, a learning approach is appealing. Surprisingly, though, rather little work has been devoted to learning local syntactic patterns, mostly noun phrases (Ramshaw and Marcus, 1995; Vilain and Day, 1996). This paper presents a novel general learning approach for recognizing local sequential patterns, that may be perceived as falling within the memorybased learning paradigm. The method utilizes a part-of-speech tagged training corpus in which all instances of the target pattern are marked (bracketed). The training data are stored as-is in suffix-tree data structures, which enable linear time searching for subsequences in the corpus. The memory-based nature of the presented algorithm stems from its deduction strategy: a new instance of the target pattern is recognized by examining the raw train</context>
<context position="22944" citStr="Vilain and Day (1996)" startWordPosition="3941" endWordPosition="3944">curves for NP, VO, and SV 90 85 80 NP. 9=0.7 Con-2 SV, 9=0.9 Con...3 80 ij 75 1 I VO, 9=0.3 Con-2 - _ NP, 9=0.7 Con-2 _ SV, 9=0.8 Con.=3 - / - I J_ VO, 9=0.3 Con....2 ; „ pattern structure. We aim to incorporate lexical information as well in the future, it is still unclear whether that will improve the results. Figure 3 shows the learning curves by amount of training examples and number of words in the training data, for particular parameter settings. 4 Related Work Two previous methods for learning local syntactic patterns follow the transformation-based paradigm introduced by Brill (1992). Vilain and Day (1996) identify (and classify) name phrases such as company names, locations, etc. Ramshaw and Marcus (1995) detect noun phrases, by classifying each word as being inside a phrase, outside or on the boundary between phrases. Finite state machines (FSMs) are a natural formalism for learning linear sequences. It was used for learning linguistic structures other than shallow syntax. Gold (1978) showed that learning regular languages from positive examples is undecidable in the limit. Recently, however, several learning methods have been proposed for restricted classes of FSM. OSTIA (Onward Subsequentia</context>
</contexts>
<marker>Vilain, Day, 1996</marker>
<rawString>M. B. Vilain and D. S. Day. 1996. Finite-state phrase parsing by rule sequences. In Proc. of COLING, Copenhagen, Denmark.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>