<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.028439">
<title confidence="0.9987595">
Stochastic Inversion Transduction Grammars for Obtaining Word Phrases
for Phrase-based Statistical Machine Translation
</title>
<author confidence="0.8118">
J.A. Sánchez and J.M. Benedí
</author>
<affiliation confidence="0.75856">
Departamento de Sistemas Informáticos y Computación
</affiliation>
<address confidence="0.739636">
Universidad Politécnica de Valencia
Valencia, Spain
</address>
<email confidence="0.996457">
jandreu@dsic.upv.esjbenedi@dsic.upv.es
</email>
<sectionHeader confidence="0.995607" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999730454545455">
An important problem that is related to
phrase-based statistical translation mod-
els is the obtaining of word phrases from
an aligned bilingual training corpus. In
this work, we propose obtaining word
phrases by means of a Stochastic Inver-
sion Translation Grammar. Experiments
on the shared task proposed in this work-
shop with the Europarl corpus have been
carried out and good results have been ob-
tained.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997924111111111">
Phrase-based statistical translation systems are cur-
rently providing excellent results in real machine
translation tasks (Zens et al., 2002; Och and Ney,
2003; Koehn, 2004). In phrase-based statistical
translation systems, the basic translation units are
word phrases.
An important problem that is related to phrase-
based statistical translation is to automatically ob-
tain bilingual word phrases from parallel corpora.
Several methods have been defined for dealing with
this problem (Och and Ney, 2003). In this work, we
study a method for obtaining word phrases that is
based on Stochastic Inversion Transduction Gram-
mars that was proposed in (Wu, 1997).
Stochastic Inversion Transduction Grammars
(SITG) can be viewed as a restricted Stochas-
tic Context-Free Syntax-Directed Transduction
Scheme. SITGs can be used to carry out a simulta-
neous parsing of both the input string and the output
string. In this work, we apply this idea to obtain
aligned word phrases to be used in phrase-based
translation systems (Sánchez and Benedí, 2006).
In Section 2, we review the phrase-based machine
translation approach. SITGs are reviewed in Sec-
tion 3. In Section 4, we present experiments on the
shared task proposed in this workshop with the Eu-
roparl corpus.
</bodyText>
<sectionHeader confidence="0.905956" genericHeader="method">
2 Phrase-based Statistical Machine
Transduction
</sectionHeader>
<bodyText confidence="0.997270826086957">
The translation units in a phrase-based statistical
translation system are bilingual phrases rather than
simple paired words. Several systems that fol-
low this approach have been presented in recent
works (Zens et al., 2002; Koehn, 2004). These sys-
tems have demonstrated excellent translation perfor-
mance in real tasks.
The basic idea of a phrase-based statistical ma-
chine translation system consists of the following
steps (Zens et al., 2002): first, the source sentence is
segmented into phrases; second, each source phrase
is translated into a target phrase; and third, the target
phrases are reordered in order to compose the target
sentence.
Bilingual translation phrases are an important
component of a phrase-based system. Different
methods have been defined to obtain bilingual trans-
lations phrases, mainly from word-based alignments
and from syntax-based models (Yamada and Knight,
2001).
In this work, we focus on learning bilingual word
phrases by using Stochastic Inversion Transduction
Grammars (SITGs) (Wu, 1997). This formalism al-
</bodyText>
<page confidence="0.949771">
130
</page>
<subsectionHeader confidence="0.7845485">
Proceedings of the Workshop on Statistical Machine Translation, pages 130–133,
New York City, June 2006. c�2006 Association for Computational Linguistics
</subsectionHeader>
<bodyText confidence="0.99984675">
lows us to obtain bilingual word phrases in a natu-
ral way from the bilingual parsing of two sentences.
In addition, the SITGs allow us to easily incorpo-
rate many desirable characteristics to word phrases
such as length restrictions, selection according to the
word alignment probability, bracketing information,
etc. We review this formalism in the following sec-
tion.
</bodyText>
<sectionHeader confidence="0.9586815" genericHeader="method">
3 Stochastic Inversion Transduction
Grammars
</sectionHeader>
<bodyText confidence="0.993450493506494">
Stochastic Inversion Transduction Grammars
(SITGs) (Wu, 1997) can be viewed as a restricted
subset of Stochastic Syntax-Directed Transduction
Grammars. They can be used to simultaneously
parse two strings, both the source and the target
sentences. SITGs are closely related to Stochastic
Context-Free Grammars.
Formally, a SITG in Chomsky Normal Forms
can be defined as a tuple ,
where: is a finite set of non-terminal symbols;
is the axiom of the SITG; is a finite set
of terminal symbols of language 1; and is a finite
set of terminal symbols of language 2. is a finite
set of: lexical rules of the type ,,
; direct syntactic rules that are noted as
; and inverse syntactic rules that are
noted as , where ,,
, and is the empty string. When a direct
syntactic rule is used in a parsing, both strings are
parsed with the syntactic rule . When an
inverse rule is used in a parsing, one string is parsed
with the syntactic rule , and the other
string is parsed with the syntactic rule .
Term of the tuple is a function that attaches a prob-
ability to each rule.
An efficient Viterbi-like parsing algorithm that is
based on a Dynamic Programing Scheme is pro-
posed in (Wu, 1997). The proposed algorithm has
a time complexity of . It is important
to note that this time complexity restricts the use of
the algorithm to real tasks with short strings.
If a bracketed corpus is available, then a modi-
fied version of the parsing algorithm can be defined
to take into account the bracketing of the strings.
&apos;A Normal Form for SITGs can be defined (Wu, 1997) by
analogy to the Chomsky Normal Form for Stochastic Context-
Free Grammars.
The modifications are similar to those proposed in
(Pereira and Schabes, 1992) for the inside algorithm.
Following the notation that is presented in (Pereira
and Schabes, 1992), we can define a partially brack-
eted corpus as a set of sentence pairs that are an-
notated with parentheses that mark constituent fron-
tiers. More precisely, a bracketed corpus is a set of
tuples , where and are strings,
is the bracketing of , and is the bracketing of .
Let be a parsing of and with the SITG . If
the SITG does not have useless symbols, then each
non-terminal that appears in each sentential form
of the derivation generates a pair of substrings
of ,, and of ,
, and defines a span of and
a span of . A derivation of and is com-
patible with and if all the spans defined by
it are compatible with and . This compatibil-
ity can be easily defined by the function
which takes a value of if does not overlap any
and, if does not overlap any ;
otherwise it takes a value of . This function filters
those derivations (or partial derivations) whose pars-
ing is not compatible with the bracketing defined in
the sample (Sánchez and Benedí, 2006).
The algorithm can be implemented to compute
only those subproblems in the Dynamic Program-
ing Scheme that are compatible with the bracket-
ing. Thus, the time complexity is for
an unbracketed string, while the time complexity is
for a fully bracketed string. It is impor-
tant to note that the last time complexity allows us to
work with real tasks with longer strings.
Moreover, the parse tree can be efficiently ob-
tained. Each node in the tree relates two word
phrases of the strings being parsed. The related word
phrases can be considered to be the translation of
each other. These word phrases can be used to com-
pute the translation table of a phrase-based machine
statistical translation system.
</bodyText>
<sectionHeader confidence="0.999807" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.946524571428571">
The experiments in this section were carried out for
the shared task proposed in this workshop. This
consisted of building a probabilistic phrase transla-
tion table for phrase-based statistical machine trans-
lation. Evaluation was translation quality on an un-
seen test set. The experiments were carried out using
,
</bodyText>
<page confidence="0.979867">
131
</page>
<bodyText confidence="0.7903975">
the Europarl corpus (Koehn, 2005). Table 1 shows
the language pairs and some figures of the training
</bodyText>
<table confidence="0.9980138">
corpora. The test set had sentences.
Languages Sentences # words (input/output)
De-En 751,088 15,257,871 / 16,052,702
Es-En 730,740 15,725,136 / 15,222,505
Fr-En 688,031 15,599,184 / 13,808,505
</table>
<tableCaption confidence="0.910188333333333">
Table 1: Figures of the training corpora. The lan-
guages are English (En), French (Fr), German (De)
and Spanish (Es)
</tableCaption>
<bodyText confidence="0.999897875">
A common framework was provided to all the par-
ticipants so that the results could be compared. The
material provided comprised of: a training set, a lan-
guage model, a baseline translation system (Koehn,
2004), and a word alignment. The participants could
augment these items by using: their own training
corpus, their own sentence alignment, their own lan-
guage model, or their own decoder. We only used
the provided material for the experiments reported
in this work. The BLEU score was used to measure
the results.
A SITG was obtained for every language pair in
this section as described below. The SITG was used
to parse paired sentences in the training sample by
using the parsing algorithm described in Section 3.
All pairs of word phrases that were derived from
each internal node in the parse tree, except the root
node, were considered for the phrase-based machine
translation system. A translation table was obtained
from paired word phrases by placing them in the ad-
equate order and counting the number of times that
each pair appeared in the phrases. These values were
then appropriately normalized (Sánchez and Benedí,
2006).
</bodyText>
<subsectionHeader confidence="0.999414">
4.1 Obtaining a SITG from an aligned corpus
</subsectionHeader>
<bodyText confidence="0.9992066">
For this experiment, a SITG was constructed for ev-
ery language pair as follows. The alignment was
used to compose lexical rules of the form
. The probability of each rule was obtained by
counting. Then, two additional rules of the form
and were added. It is im-
portant to point out that the constructed SITG did
not parse all the training sentences. Therefore, the
model was smoothed by adding all the rules of the
form and with low probabil-
ity, so that all the training sentences could be parsed.
The rules were then adequately normalized.
This SITG was used to obtain word phrases from
the training corpus. Then, these word phrases were
used by the Pharaoh system (Koehn, 2004) to trans-
late the test set. We used word phrases up to a given
length. In these experiments several lengths were
tested and the best values ranged from 6 to 10. Ta-
ble shows 2 the obtained results and the size of the
translation table.
</bodyText>
<table confidence="0.99861425">
Lang. BLEU Lang. BLEU
De-En 15.91 (8.7) En-De 11.20 (9.7)
Es-En 22.85 (6.5) En-Es 21.18 (8.6)
Fr-En 21.30 (7.3) En-Fr 20.12 (8.1)
</table>
<tableCaption confidence="0.66824">
Table 2: Obtained results for different pairs and di-
rections. The value in parentheses is the number of
word phrases in the translation table (in millions).
</tableCaption>
<bodyText confidence="0.99763">
Note that better results were obtained when En-
glish was the target language.
</bodyText>
<subsectionHeader confidence="0.92545">
4.2 Using bracketing information in the
parsing
</subsectionHeader>
<bodyText confidence="0.999909727272728">
As Section 3 describes, the parsing algorithm for
SITGs can be adequately modified in order to take
bracketed sentences into account. If the bracket-
ing respects linguistically motivated structures, then
aligned phrases with linguistic information can be
used. Note that this approach requires having qual-
ity parsed corpora available. This problem can be
reduced by using automatically learned parsers.
This experiment was carried out to determine the
performance of the translation when some kind of
structural information was incorporated in the pars-
ing algorithm described in Section 3. We bracketed
the English sentences of the Europarl corpus with
an automatically learned parser. This automatically
learned parser was trained with bracketed strings ob-
tained from the UPenn Treebank corpus. We then
obtained word phrases according to the bracketing
by using the same SITG that was described in the
previous section. The obtained phrases were used
with the Pharaoh system. Table 3 shows the results
obtained in this experiment.
Note that the results decreased slightly in all
</bodyText>
<page confidence="0.99147">
132
</page>
<table confidence="0.99214625">
Lang. BLEU Lang. BLEU
De-En 15.13 (7.1) En-De 10.40 (9.2)
Es-En 21.61 (6.6) En-Es 19.86 (9.6)
Fr-En 20.57 (6.3) En-Fr 18.95 (8.3)
</table>
<tableCaption confidence="0.993246">
Table 3: Obtained results for different pairs and di-
</tableCaption>
<bodyText confidence="0.998025071428571">
rections when word phrases were obtained from a
parsed corpus.The value in parentheses is the num-
ber of word phrases in the translation table (in mil-
lions).
cases. This may be due to the fact that the bracket-
ing incorporated hard restrictions to the paired word
phrases and some of them were too forced. In ad-
dition, many sentences could not be parsed (up to
5% on average) due to the bracketing. However, it
is important to point out that incorporating bracket-
ing information to the English sentences notably ac-
celerated the parsing algorithm, thereby accelerating
the process of obtaining word phrases, which is an
important detail given the magnitude of this corpus.
</bodyText>
<subsectionHeader confidence="0.999034">
4.3 Combining word phrases
</subsectionHeader>
<bodyText confidence="0.999870888888889">
Finally, we considered the combination of both
kinds of segments. The results can be seen in Ta-
ble 4. This table shows that the results improved the
results of Table 2 when English was the target lan-
guage. However, the results did not improve when
English was the source language. The reason for this
could be that both kinds of segments were different
in nature, and, therefore, the number of word phrases
increased notably, specially in the English part.
</bodyText>
<table confidence="0.99759475">
Lang. BLEU Lang. BLEU
De-En 16.39 (17.1) En-De 11.02 (15.3)
Es-En 22.96 (11.7) En-Es 20.86 (14.1)
Fr-En 21.73 (17.0) En-Fr 19.93 (14.9)
</table>
<tableCaption confidence="0.977154">
Table 4: Obtained results for different pairs and di-
</tableCaption>
<bodyText confidence="0.99364725">
rections when word phrases were obtained from a
non-parsed corpus and a parsed corpus.The value in
parentheses is the number of word phrases in the
translation table (in millions).
</bodyText>
<sectionHeader confidence="0.999634" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999960588235294">
In this work, we have explored the problem of
obtaining word phrases for phrase-based machine
translation systems from SITGs. We have described
how the parsing algorithms for this formalism can
be modified in order to take into account a brack-
eted corpus. If bracketed corpora are used the time
complexity can decrease notably and large tasks can
be considered. Experiments were reported for the
Europarl corpus, and the results obtained were com-
petitive.
For future work, we propose to work along dif-
ferent lines: first, to incorporate new linguistic in-
formation in both the parsing algorithm and in the
aligned corpus; second, to obtain better SITGs from
aligned bilingual corpora; an third, to improve the
SITG by estimating the syntactic rules. We also in-
tend to address other machine translation tasks.
</bodyText>
<sectionHeader confidence="0.997602" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998840666666667">
This work has been partially supported by the Uni-
versidad Politécnica de Valencia with the ILETA
project.
</bodyText>
<sectionHeader confidence="0.999023" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9995603">
P. Koehn. 2004. Pharaoh: a beam search decoder for
phrase-based statistical machine translation models.
In Proc. ofAMTA.
P. Koehn. 2005. Europarl: A parallel corpus for statisti-
cal machine translation. In Proc. ofMT Summit.
F.J. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational
Linguistics, 29(1):19–52.
F. Pereira and Y. Schabes. 1992. Inside-outside reesti-
mation from partially bracketed corpora. In Proceed-
ings of the 30th Annual Meeting of the Association for
Computational Linguistics, pages 128–135. University
of Delaware.
J.A. Sánchez and J.M. Benedí. 2006. Obtaining word
phrases with stochastic inversion transduction gram-
mars for phrase-based statistical machine translation.
In Proc. 11th Annual conference ofthe European Asso-
ciation for Machine Translation, page Accepted, Oslo,
Norway.
D. Wu. 1997. Stochastic inversion transduction gram-
mars and bilingual parsing of parallel corpora. Com-
putational Linguistics, 23(3):377–404.
K. Yamada and K. Knight. 2001. A syntax-based sta-
tistical translation model. In Proc. of the 39th Annual
Meeting of the Association of Computational Linguis-
tics, pages 523–530.
R. Zens, F.J. Och, and H. Ney. 2002. Phrase-based statis-
tical machine translation. In Proc. of the 25th Annual
German Conference on Artificial Intelligence, pages
18–32.
</reference>
<page confidence="0.999143">
133
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.258968">
<title confidence="0.9986145">Stochastic Inversion Transduction Grammars for Obtaining Word Phrases for Phrase-based Statistical Machine Translation</title>
<author confidence="0.565493">J A Sánchez</author>
<author confidence="0.565493">J M</author>
<affiliation confidence="0.8250255">Departamento de Sistemas Informáticos y Universidad Politécnica de</affiliation>
<address confidence="0.538424">Valencia, Spain</address>
<email confidence="0.990362">jandreu@dsic.upv.esjbenedi@dsic.upv.es</email>
<abstract confidence="0.98028375">An important problem that is related to phrase-based statistical translation models is the obtaining of word phrases from an aligned bilingual training corpus. In this work, we propose obtaining word phrases by means of a Stochastic Inversion Translation Grammar. Experiments on the shared task proposed in this workshop with the Europarl corpus have been carried out and good results have been obtained.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Pharaoh: a beam search decoder for phrase-based statistical machine translation models.</title>
<date>2004</date>
<booktitle>In Proc. ofAMTA.</booktitle>
<contexts>
<context position="892" citStr="Koehn, 2004" startWordPosition="123" endWordPosition="124">sic.upv.es Abstract An important problem that is related to phrase-based statistical translation models is the obtaining of word phrases from an aligned bilingual training corpus. In this work, we propose obtaining word phrases by means of a Stochastic Inversion Translation Grammar. Experiments on the shared task proposed in this workshop with the Europarl corpus have been carried out and good results have been obtained. 1 Introduction Phrase-based statistical translation systems are currently providing excellent results in real machine translation tasks (Zens et al., 2002; Och and Ney, 2003; Koehn, 2004). In phrase-based statistical translation systems, the basic translation units are word phrases. An important problem that is related to phrasebased statistical translation is to automatically obtain bilingual word phrases from parallel corpora. Several methods have been defined for dealing with this problem (Och and Ney, 2003). In this work, we study a method for obtaining word phrases that is based on Stochastic Inversion Transduction Grammars that was proposed in (Wu, 1997). Stochastic Inversion Transduction Grammars (SITG) can be viewed as a restricted Stochastic Context-Free Syntax-Direct</context>
<context position="2253" citStr="Koehn, 2004" startWordPosition="334" endWordPosition="335">this idea to obtain aligned word phrases to be used in phrase-based translation systems (Sánchez and Benedí, 2006). In Section 2, we review the phrase-based machine translation approach. SITGs are reviewed in Section 3. In Section 4, we present experiments on the shared task proposed in this workshop with the Europarl corpus. 2 Phrase-based Statistical Machine Transduction The translation units in a phrase-based statistical translation system are bilingual phrases rather than simple paired words. Several systems that follow this approach have been presented in recent works (Zens et al., 2002; Koehn, 2004). These systems have demonstrated excellent translation performance in real tasks. The basic idea of a phrase-based statistical machine translation system consists of the following steps (Zens et al., 2002): first, the source sentence is segmented into phrases; second, each source phrase is translated into a target phrase; and third, the target phrases are reordered in order to compose the target sentence. Bilingual translation phrases are an important component of a phrase-based system. Different methods have been defined to obtain bilingual translations phrases, mainly from word-based alignm</context>
<context position="8029" citStr="Koehn, 2004" startWordPosition="1306" endWordPosition="1307">oparl corpus (Koehn, 2005). Table 1 shows the language pairs and some figures of the training corpora. The test set had sentences. Languages Sentences # words (input/output) De-En 751,088 15,257,871 / 16,052,702 Es-En 730,740 15,725,136 / 15,222,505 Fr-En 688,031 15,599,184 / 13,808,505 Table 1: Figures of the training corpora. The languages are English (En), French (Fr), German (De) and Spanish (Es) A common framework was provided to all the participants so that the results could be compared. The material provided comprised of: a training set, a language model, a baseline translation system (Koehn, 2004), and a word alignment. The participants could augment these items by using: their own training corpus, their own sentence alignment, their own language model, or their own decoder. We only used the provided material for the experiments reported in this work. The BLEU score was used to measure the results. A SITG was obtained for every language pair in this section as described below. The SITG was used to parse paired sentences in the training sample by using the parsing algorithm described in Section 3. All pairs of word phrases that were derived from each internal node in the parse tree, exc</context>
<context position="9680" citStr="Koehn, 2004" startWordPosition="1588" endWordPosition="1589">r as follows. The alignment was used to compose lexical rules of the form . The probability of each rule was obtained by counting. Then, two additional rules of the form and were added. It is important to point out that the constructed SITG did not parse all the training sentences. Therefore, the model was smoothed by adding all the rules of the form and with low probability, so that all the training sentences could be parsed. The rules were then adequately normalized. This SITG was used to obtain word phrases from the training corpus. Then, these word phrases were used by the Pharaoh system (Koehn, 2004) to translate the test set. We used word phrases up to a given length. In these experiments several lengths were tested and the best values ranged from 6 to 10. Table shows 2 the obtained results and the size of the translation table. Lang. BLEU Lang. BLEU De-En 15.91 (8.7) En-De 11.20 (9.7) Es-En 22.85 (6.5) En-Es 21.18 (8.6) Fr-En 21.30 (7.3) En-Fr 20.12 (8.1) Table 2: Obtained results for different pairs and directions. The value in parentheses is the number of word phrases in the translation table (in millions). Note that better results were obtained when English was the target language. 4</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>P. Koehn. 2004. Pharaoh: a beam search decoder for phrase-based statistical machine translation models. In Proc. ofAMTA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proc. ofMT Summit.</booktitle>
<contexts>
<context position="7443" citStr="Koehn, 2005" startWordPosition="1213" endWordPosition="1214">two word phrases of the strings being parsed. The related word phrases can be considered to be the translation of each other. These word phrases can be used to compute the translation table of a phrase-based machine statistical translation system. 4 Experiments The experiments in this section were carried out for the shared task proposed in this workshop. This consisted of building a probabilistic phrase translation table for phrase-based statistical machine translation. Evaluation was translation quality on an unseen test set. The experiments were carried out using , 131 the Europarl corpus (Koehn, 2005). Table 1 shows the language pairs and some figures of the training corpora. The test set had sentences. Languages Sentences # words (input/output) De-En 751,088 15,257,871 / 16,052,702 Es-En 730,740 15,725,136 / 15,222,505 Fr-En 688,031 15,599,184 / 13,808,505 Table 1: Figures of the training corpora. The languages are English (En), French (Fr), German (De) and Spanish (Es) A common framework was provided to all the participants so that the results could be compared. The material provided comprised of: a training set, a language model, a baseline translation system (Koehn, 2004), and a word a</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>P. Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In Proc. ofMT Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="878" citStr="Och and Ney, 2003" startWordPosition="119" endWordPosition="122">sic.upv.esjbenedi@dsic.upv.es Abstract An important problem that is related to phrase-based statistical translation models is the obtaining of word phrases from an aligned bilingual training corpus. In this work, we propose obtaining word phrases by means of a Stochastic Inversion Translation Grammar. Experiments on the shared task proposed in this workshop with the Europarl corpus have been carried out and good results have been obtained. 1 Introduction Phrase-based statistical translation systems are currently providing excellent results in real machine translation tasks (Zens et al., 2002; Och and Ney, 2003; Koehn, 2004). In phrase-based statistical translation systems, the basic translation units are word phrases. An important problem that is related to phrasebased statistical translation is to automatically obtain bilingual word phrases from parallel corpora. Several methods have been defined for dealing with this problem (Och and Ney, 2003). In this work, we study a method for obtaining word phrases that is based on Stochastic Inversion Transduction Grammars that was proposed in (Wu, 1997). Stochastic Inversion Transduction Grammars (SITG) can be viewed as a restricted Stochastic Context-Free</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F.J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pereira</author>
<author>Y Schabes</author>
</authors>
<title>Inside-outside reestimation from partially bracketed corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>128--135</pages>
<institution>University of Delaware.</institution>
<contexts>
<context position="5333" citStr="Pereira and Schabes, 1992" startWordPosition="838" endWordPosition="841">terbi-like parsing algorithm that is based on a Dynamic Programing Scheme is proposed in (Wu, 1997). The proposed algorithm has a time complexity of . It is important to note that this time complexity restricts the use of the algorithm to real tasks with short strings. If a bracketed corpus is available, then a modified version of the parsing algorithm can be defined to take into account the bracketing of the strings. &apos;A Normal Form for SITGs can be defined (Wu, 1997) by analogy to the Chomsky Normal Form for Stochastic ContextFree Grammars. The modifications are similar to those proposed in (Pereira and Schabes, 1992) for the inside algorithm. Following the notation that is presented in (Pereira and Schabes, 1992), we can define a partially bracketed corpus as a set of sentence pairs that are annotated with parentheses that mark constituent frontiers. More precisely, a bracketed corpus is a set of tuples , where and are strings, is the bracketing of , and is the bracketing of . Let be a parsing of and with the SITG . If the SITG does not have useless symbols, then each non-terminal that appears in each sentential form of the derivation generates a pair of substrings of ,, and of , , and defines a span of a</context>
</contexts>
<marker>Pereira, Schabes, 1992</marker>
<rawString>F. Pereira and Y. Schabes. 1992. Inside-outside reestimation from partially bracketed corpora. In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics, pages 128–135. University of Delaware.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Sánchez</author>
<author>J M Benedí</author>
</authors>
<title>Obtaining word phrases with stochastic inversion transduction grammars for phrase-based statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proc. 11th Annual conference ofthe European Association for Machine Translation,</booktitle>
<location>page Accepted, Oslo,</location>
<contexts>
<context position="1755" citStr="Sánchez and Benedí, 2006" startWordPosition="255" endWordPosition="258">orpora. Several methods have been defined for dealing with this problem (Och and Ney, 2003). In this work, we study a method for obtaining word phrases that is based on Stochastic Inversion Transduction Grammars that was proposed in (Wu, 1997). Stochastic Inversion Transduction Grammars (SITG) can be viewed as a restricted Stochastic Context-Free Syntax-Directed Transduction Scheme. SITGs can be used to carry out a simultaneous parsing of both the input string and the output string. In this work, we apply this idea to obtain aligned word phrases to be used in phrase-based translation systems (Sánchez and Benedí, 2006). In Section 2, we review the phrase-based machine translation approach. SITGs are reviewed in Section 3. In Section 4, we present experiments on the shared task proposed in this workshop with the Europarl corpus. 2 Phrase-based Statistical Machine Transduction The translation units in a phrase-based statistical translation system are bilingual phrases rather than simple paired words. Several systems that follow this approach have been presented in recent works (Zens et al., 2002; Koehn, 2004). These systems have demonstrated excellent translation performance in real tasks. The basic idea of a</context>
<context position="6380" citStr="Sánchez and Benedí, 2006" startWordPosition="1035" endWordPosition="1038">es not have useless symbols, then each non-terminal that appears in each sentential form of the derivation generates a pair of substrings of ,, and of , , and defines a span of and a span of . A derivation of and is compatible with and if all the spans defined by it are compatible with and . This compatibility can be easily defined by the function which takes a value of if does not overlap any and, if does not overlap any ; otherwise it takes a value of . This function filters those derivations (or partial derivations) whose parsing is not compatible with the bracketing defined in the sample (Sánchez and Benedí, 2006). The algorithm can be implemented to compute only those subproblems in the Dynamic Programing Scheme that are compatible with the bracketing. Thus, the time complexity is for an unbracketed string, while the time complexity is for a fully bracketed string. It is important to note that the last time complexity allows us to work with real tasks with longer strings. Moreover, the parse tree can be efficiently obtained. Each node in the tree relates two word phrases of the strings being parsed. The related word phrases can be considered to be the translation of each other. These word phrases can </context>
<context position="8956" citStr="Sánchez and Benedí, 2006" startWordPosition="1458" endWordPosition="1461">ults. A SITG was obtained for every language pair in this section as described below. The SITG was used to parse paired sentences in the training sample by using the parsing algorithm described in Section 3. All pairs of word phrases that were derived from each internal node in the parse tree, except the root node, were considered for the phrase-based machine translation system. A translation table was obtained from paired word phrases by placing them in the adequate order and counting the number of times that each pair appeared in the phrases. These values were then appropriately normalized (Sánchez and Benedí, 2006). 4.1 Obtaining a SITG from an aligned corpus For this experiment, a SITG was constructed for every language pair as follows. The alignment was used to compose lexical rules of the form . The probability of each rule was obtained by counting. Then, two additional rules of the form and were added. It is important to point out that the constructed SITG did not parse all the training sentences. Therefore, the model was smoothed by adding all the rules of the form and with low probability, so that all the training sentences could be parsed. The rules were then adequately normalized. This SITG was </context>
</contexts>
<marker>Sánchez, Benedí, 2006</marker>
<rawString>J.A. Sánchez and J.M. Benedí. 2006. Obtaining word phrases with stochastic inversion transduction grammars for phrase-based statistical machine translation. In Proc. 11th Annual conference ofthe European Association for Machine Translation, page Accepted, Oslo, Norway.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="1373" citStr="Wu, 1997" startWordPosition="197" endWordPosition="198"> are currently providing excellent results in real machine translation tasks (Zens et al., 2002; Och and Ney, 2003; Koehn, 2004). In phrase-based statistical translation systems, the basic translation units are word phrases. An important problem that is related to phrasebased statistical translation is to automatically obtain bilingual word phrases from parallel corpora. Several methods have been defined for dealing with this problem (Och and Ney, 2003). In this work, we study a method for obtaining word phrases that is based on Stochastic Inversion Transduction Grammars that was proposed in (Wu, 1997). Stochastic Inversion Transduction Grammars (SITG) can be viewed as a restricted Stochastic Context-Free Syntax-Directed Transduction Scheme. SITGs can be used to carry out a simultaneous parsing of both the input string and the output string. In this work, we apply this idea to obtain aligned word phrases to be used in phrase-based translation systems (Sánchez and Benedí, 2006). In Section 2, we review the phrase-based machine translation approach. SITGs are reviewed in Section 3. In Section 4, we present experiments on the shared task proposed in this workshop with the Europarl corpus. 2 Ph</context>
<context position="3042" citStr="Wu, 1997" startWordPosition="451" endWordPosition="452"> steps (Zens et al., 2002): first, the source sentence is segmented into phrases; second, each source phrase is translated into a target phrase; and third, the target phrases are reordered in order to compose the target sentence. Bilingual translation phrases are an important component of a phrase-based system. Different methods have been defined to obtain bilingual translations phrases, mainly from word-based alignments and from syntax-based models (Yamada and Knight, 2001). In this work, we focus on learning bilingual word phrases by using Stochastic Inversion Transduction Grammars (SITGs) (Wu, 1997). This formalism al130 Proceedings of the Workshop on Statistical Machine Translation, pages 130–133, New York City, June 2006. c�2006 Association for Computational Linguistics lows us to obtain bilingual word phrases in a natural way from the bilingual parsing of two sentences. In addition, the SITGs allow us to easily incorporate many desirable characteristics to word phrases such as length restrictions, selection according to the word alignment probability, bracketing information, etc. We review this formalism in the following section. 3 Stochastic Inversion Transduction Grammars Stochastic</context>
<context position="4806" citStr="Wu, 1997" startWordPosition="749" endWordPosition="750">finite set of: lexical rules of the type ,, ; direct syntactic rules that are noted as ; and inverse syntactic rules that are noted as , where ,, , and is the empty string. When a direct syntactic rule is used in a parsing, both strings are parsed with the syntactic rule . When an inverse rule is used in a parsing, one string is parsed with the syntactic rule , and the other string is parsed with the syntactic rule . Term of the tuple is a function that attaches a probability to each rule. An efficient Viterbi-like parsing algorithm that is based on a Dynamic Programing Scheme is proposed in (Wu, 1997). The proposed algorithm has a time complexity of . It is important to note that this time complexity restricts the use of the algorithm to real tasks with short strings. If a bracketed corpus is available, then a modified version of the parsing algorithm can be defined to take into account the bracketing of the strings. &apos;A Normal Form for SITGs can be defined (Wu, 1997) by analogy to the Chomsky Normal Form for Stochastic ContextFree Grammars. The modifications are similar to those proposed in (Pereira and Schabes, 1992) for the inside algorithm. Following the notation that is presented in (P</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>D. Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377–404.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yamada</author>
<author>K Knight</author>
</authors>
<title>A syntax-based statistical translation model.</title>
<date>2001</date>
<booktitle>In Proc. of the 39th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>523--530</pages>
<contexts>
<context position="2912" citStr="Yamada and Knight, 2001" startWordPosition="430" endWordPosition="433">xcellent translation performance in real tasks. The basic idea of a phrase-based statistical machine translation system consists of the following steps (Zens et al., 2002): first, the source sentence is segmented into phrases; second, each source phrase is translated into a target phrase; and third, the target phrases are reordered in order to compose the target sentence. Bilingual translation phrases are an important component of a phrase-based system. Different methods have been defined to obtain bilingual translations phrases, mainly from word-based alignments and from syntax-based models (Yamada and Knight, 2001). In this work, we focus on learning bilingual word phrases by using Stochastic Inversion Transduction Grammars (SITGs) (Wu, 1997). This formalism al130 Proceedings of the Workshop on Statistical Machine Translation, pages 130–133, New York City, June 2006. c�2006 Association for Computational Linguistics lows us to obtain bilingual word phrases in a natural way from the bilingual parsing of two sentences. In addition, the SITGs allow us to easily incorporate many desirable characteristics to word phrases such as length restrictions, selection according to the word alignment probability, brack</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>K. Yamada and K. Knight. 2001. A syntax-based statistical translation model. In Proc. of the 39th Annual Meeting of the Association of Computational Linguistics, pages 523–530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Phrase-based statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proc. of the 25th Annual German Conference on Artificial Intelligence,</booktitle>
<pages>18--32</pages>
<contexts>
<context position="859" citStr="Zens et al., 2002" startWordPosition="115" endWordPosition="118">ia, Spain jandreu@dsic.upv.esjbenedi@dsic.upv.es Abstract An important problem that is related to phrase-based statistical translation models is the obtaining of word phrases from an aligned bilingual training corpus. In this work, we propose obtaining word phrases by means of a Stochastic Inversion Translation Grammar. Experiments on the shared task proposed in this workshop with the Europarl corpus have been carried out and good results have been obtained. 1 Introduction Phrase-based statistical translation systems are currently providing excellent results in real machine translation tasks (Zens et al., 2002; Och and Ney, 2003; Koehn, 2004). In phrase-based statistical translation systems, the basic translation units are word phrases. An important problem that is related to phrasebased statistical translation is to automatically obtain bilingual word phrases from parallel corpora. Several methods have been defined for dealing with this problem (Och and Ney, 2003). In this work, we study a method for obtaining word phrases that is based on Stochastic Inversion Transduction Grammars that was proposed in (Wu, 1997). Stochastic Inversion Transduction Grammars (SITG) can be viewed as a restricted Stoc</context>
<context position="2239" citStr="Zens et al., 2002" startWordPosition="330" endWordPosition="333">his work, we apply this idea to obtain aligned word phrases to be used in phrase-based translation systems (Sánchez and Benedí, 2006). In Section 2, we review the phrase-based machine translation approach. SITGs are reviewed in Section 3. In Section 4, we present experiments on the shared task proposed in this workshop with the Europarl corpus. 2 Phrase-based Statistical Machine Transduction The translation units in a phrase-based statistical translation system are bilingual phrases rather than simple paired words. Several systems that follow this approach have been presented in recent works (Zens et al., 2002; Koehn, 2004). These systems have demonstrated excellent translation performance in real tasks. The basic idea of a phrase-based statistical machine translation system consists of the following steps (Zens et al., 2002): first, the source sentence is segmented into phrases; second, each source phrase is translated into a target phrase; and third, the target phrases are reordered in order to compose the target sentence. Bilingual translation phrases are an important component of a phrase-based system. Different methods have been defined to obtain bilingual translations phrases, mainly from wor</context>
</contexts>
<marker>Zens, Och, Ney, 2002</marker>
<rawString>R. Zens, F.J. Och, and H. Ney. 2002. Phrase-based statistical machine translation. In Proc. of the 25th Annual German Conference on Artificial Intelligence, pages 18–32.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>