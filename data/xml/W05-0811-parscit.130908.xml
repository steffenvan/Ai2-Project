<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000148">
<note confidence="0.5986368">
Models for Inuktitut-English Word Alignment
Charles Schafer and Elliott Franco Dr´abek
Department of Computer Science
Johns Hopkins University
Baltimore, MD 21218, USA
</note>
<email confidence="0.967745">
Icschafer,edrabekl@cs.jhu.edu
</email>
<sectionHeader confidence="0.993304" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.985704333333333">
This paper presents a set of techniques for bitext word align-
ment, optimized for a language pair with the characteristics of
Inuktitut-English. The resulting systems exploit cross-lingual
affinities at the sublexical level of syllables and substrings, as
well as regular patterns of transliteration and the tendency to-
wards monotonicity of alignment. Our most successful systems
were based on classifier combination, and we found different
combination methods performed best under the target evalua-
tion metrics of F-measure and alignment error rate.
</bodyText>
<sectionHeader confidence="0.997974" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999518666666666">
Conventional word-alignment methods have been suc-
cessful at treating many language pairs, but may be lim-
ited in their ability to generalize beyond the Western Eu-
ropean language pairs for which they were originally
developed, to pairs which exhibit more complex diver-
gences in word order, morphology and lexical granular-
ity. Our approach to Inuktitut-English alignment was to
carefully consider the data in identifying difficulties par-
ticular to Inuktitut-English as well as possible simplify-
ing assumptions. We used these observations to construct
a novel weighted finite-state transducer alignment model
as well as a specialized transliteration model. We com-
bined these customized systems with 3 systems based
on IBM Model 4 alignments under several methods of
classifier combination. These combination strategies al-
lowed us to produce multiple submissions targeted at the
distinct evaluation measures via a precision/recall trade-
off.
</bodyText>
<sectionHeader confidence="0.957459" genericHeader="introduction">
2 Special Characteristics of the
Inuktitut-English Alignment Problem
</sectionHeader>
<bodyText confidence="0.9170825">
Guided by the discussion of Inuktitut in Mallon (1999),
we examined the Nunavut Hansards training and hand-
labeled trial data sets in order to identify special chal-
lenges and exploitable characteristics of the Inuktitut-
English word alignment problem. We were able to iden-
tify three: (1) Importance of sublexical Inuktitut units;
(2) 1-to-N Inuktitut-to-English alignment cardinality; (3)
Monotonicity of alignments.
2.1 Types and Tokens
Inuktitut has an extremely productive agglutinative mor-
phology, and an orthographic word may combine very
many individual morphemes. As a result, in Inuktitut-
English bitext we observe Inuktitut sentences with many
fewer word tokens than the corresponding English sen-
tences; the ratio of English to Inuktitut tokens in the
training corpus is 1.85.1 This suggests the importance of
looking below the Inuktitut word level when computing
lexical translation probabilities (or alignment affinities).
To reinforce the point, consider that the ratio of training
corpus types to tokens is 0.007 for English, and 0.194 for
Inuktitut. In developing a customized word alignment
solution for Inuktitut-English, a major goal was to han-
dle the huge number of Inuktitut word types seen only
once in the training corpus (337798 compared to 8792
for English), without demanding the development of a
morphological analyzer.
</bodyText>
<subsectionHeader confidence="0.985624">
2.2 Alignment
</subsectionHeader>
<bodyText confidence="0.999890555555556">
Considering English words in English sentence order,
4.7% of their alignments to Inuktitut were found to be
retrograde; that is, involving a decrease in Inuktitut word
position with respect to the previous English word’s
aligned Inuktitut position. Since this method of counting
retrograde alignments would assign a low count to mass
movements of large contiguous chunks, we also mea-
sured the number of inverted alignments over all pairs
of English word positions. That is, the sum
</bodyText>
<equation confidence="0.987847">
EeEa=1|e|
−1ib=|e|a+1r-i,EI(e,a)r-i,EI(e,b)(1 if i1 &gt; i2)
</equation>
<bodyText confidence="0.999859461538462">
was computed over all Inuktitut alignment sets I(e, x),
for e the English sentence and x the English word po-
sition. Dividing this sum by the obvious denominator
(replacing (1 if i1 &gt; i2) with (1) in the sum) yielded a
value of 1.6% inverted alignments.
Table 1 shows a histogram of alignment cardinalities
for both English and Inuktitut. Ninety-four percent of
English word tokens, and ninety-nine percent of those
having a non-null alignment, align to exactly one Inuk-
titut word. In development of a specialized word aligner
for this language pair (Section 3), we made use of the
observed reliability of these two properties, monotonic-
ity and 1-to-N cardinality.
</bodyText>
<sectionHeader confidence="0.862576" genericHeader="method">
3 Alignment by Weighted Finite-State
</sectionHeader>
<subsectionHeader confidence="0.665989">
Transducer Composition
</subsectionHeader>
<bodyText confidence="0.938667">
We designed a specialized alignment system to handle
the above-mentioned special characteristics of Inuktitut-
&apos;Though this ratio increases to 2.21 when considering only longer
sentences (20 or more English words), ignoring common short, formu-
laic sentence pairs such as ( Hudson Bay ) ( sanikiluaq ) .
</bodyText>
<page confidence="0.65772">
79
</page>
<note confidence="0.964738">
Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 79–82,
Ann Arbor, June 2005. c�Association for Computational Linguistics, 2005
</note>
<table confidence="0.99555925">
%Words Having Specified Alignment Cardinality
NULL 1 2 3 4 5 6 7
English 5 94 &lt;1 &lt;1 0 0 0 0
Inuktitut 3 43 20 14 10 5 3 2
</table>
<tableCaption confidence="0.990499">
Table 1: Alignment cardinalities for English-Inuktitut word
alignment, computed over the trial data.
</tableCaption>
<bodyText confidence="0.975610865384615">
English alignment. Our weighted finite-state transducer
(WFST) alignment model, illustrated in Figure 1, struc-
turally enforces monotonicity and 1-to-N cardinality, and
exploits sublexical information by incorporating associ-
ation scores between English words and Inuktitut word
substrings, based on co-occurrence in aligned sentences.
For each English word, an association score was com-
puted not only with each Inuktitut word, but also with
each Inuktitut character string of length ranging from
2 to 10 characters. This is similar to the technique de-
scribed in Martin et al. (2003) as part of their construc-
tion of a bilingual glossary from English-Inuktitut bi-
text. However, our goal is different and we keep all the
English-Inuktitut associations, rather than selecting only
the “best” ones using a greedy method, as do they. Addi-
tionally, before extracting all substrings from each Inuk-
titut word, we added a special character to the word’s
beginning and end (e.g., makkuttut —&gt; makkuttut ), in
order to exploit any preferences for word-initial or -final
placement.
The heuristic association score chosen was
p(worde|wordi) x p(wordi|worde), computed over all
the aligned sentence pairs. We have in the past observed
this to be a useful indicator of word association, and it
has the nice property of being in the range (0,1].
The WFST aligner is a composition of 4 transduc-
ers.2 The structure of the entire WFST composition en-
forces monotonicity, Inuktitut-to-English 1-N cardinal-
ity, and Inuktitut word fertilities ranging between 1 and
7. This model was implemented using the ATT finite-
state toolkit (Mohri et al., 1997). In Figure 1, [1] is
a linear transducer mapping each English position in a
particular English test sentence to the word at that posi-
tion. It is constructed so as to force each English word
to participate in exactly 1 alignment. [2] is a single-state
transducer mapping English word to Inuktitut substrings
(or full words) with weights derived from the association
scores.3 [3] is a transducer mapping Inuktitut substrings
(and full words) to their position in the Inuktitut test sen-
tence. Its construction allows a single Inuktitut position
to correspond to multiple English positions, while en-
forcing monotonicity. [4] is a transducer regulating the
allowed “fertility” values of Inuktitut words; each Inuk-
titut word is permitted a fertility of between 1 and 7. The
fertility values are assigned the probabilities correspond-
ing to observed relative frequencies in the trial data, and
2Bracketed numbers in the following discussion refer to the compo-
nent transducers as illustrated in Figure 1.
3Transducers [2] and [4] are shared across all sentence decodings.
in regards to elders and youth i want to make general comments
pijjutigillugu innatuqait amma makkuttut uqausiqakainnarumajunga
_pijjutigillugu_/1 _innatuqait_/2 _amma_/3 _makkuttut_/4 _uqausiqakainnarumajunga_/5
</bodyText>
<figureCaption confidence="0.854688">
Figure 1: WFST alignment system in composition order, in-
</figureCaption>
<bodyText confidence="0.975691">
stantiated for an example sentence from the development (trial)
data. To save space, only a representative portion of each ma-
chine is drawn. Transition weights are costs in the tropical
(min,+) semiring, derived from negative logs of probabilities
and association scores. Nonzero costs are indicated in paren-
theses.
are not conditioned on the identity of the Inuktitut word.
</bodyText>
<sectionHeader confidence="0.997136" genericHeader="method">
4 English-Inuktitut Transliteration
</sectionHeader>
<bodyText confidence="0.99972384">
Although in this corpus English and Inuktitut are both
written in Roman characters, English names are signifi-
cantly transformed when rendered in Inuktitut text. Con-
sider the following English/Inuktitut pairs from the train-
ing corpus: Chartrand/saaturaan, Chretien/kurittian
and the set of training corpus-attested Inuktitut render-
ings of Williams, Campbell, and McLean shown in Ta-
ble 2(A) (which does not include variations containing
the common -mut lexeme, meaning “to [a person]” (Mal-
lon, 1999)).
Clearly, not only does the English-to-Inuktitut trans-
formation radically change the name string, it does so
in a nondeterministic way which appears to be influ-
enced not only by the phonological preferences of Inuk-
titut but also by differing pronunciations of the name in
question and possibly by differing conventions of trans-
lators (note, for example, maklain versus mikliin for
McLean).
We trained a probabilistic finite-state transducer
(FST) to identify English-Inuktitut transliterated pairs
in aligned sentences. Training string pairs were ac-
quired from the training bitext in the following manner.
Whenever single instances of corresponding honorifics
were found in a sentence pair – these included the cor-
respondences (Ms , mis); (Mrs , missa/missis); (Mr ,
</bodyText>
<figure confidence="0.998497492307692">
1/in 2/regards 3/to 4/elders
5/and 6/youth
. . .
[1]
elders/_inna (0.90)
elders/_innat (1.09)
general/_uqausi (4.54)
and/_amma (.49)
and/_amm (.49)
and/_am (.54)
youth/_makku (1.10)
youth/_makkuttut_ (3.89) . . .
regards/_pijjutigillugu_ (3.49)
regards/_pijjuti (2.98)
[2]
...
_pijjut/1
illug/1
...
inna/2
_
atuqa/2
...
am/3
_
amm/3
_
...
_makku/4
kkutt/4
...
akainnar/5
ajunga/5
1
2
&lt;epsilon&gt;
(1.56)
&lt;epsilon&gt;
1 1
&lt;epsilon&gt;
&lt;epsilon&gt;
2 2
&lt;epsilon&gt;
&lt;epsilon&gt;
(1.56)
2 2 2
&lt;epsilon&gt;
&lt;epsilon&gt;
&lt;epsilon&gt;
&lt;epsilon&gt;
(1.90)
(1.90)
[4]
...
...
. . .
&lt;epsilon&gt;
(0.82)
1 1 1
&lt;epsilon&gt;
(0.82)
&lt;epsilon&gt; &lt;epsilon&gt; &lt;epsilon&gt; &lt;epsilon&gt; &lt;epsilon&gt;
[3]
80
(A) (B)
</figure>
<table confidence="0.782127888888889">
Williams McLean k sh
ailiams makalain k -4.2 s -7.2
uialims makkalain q -6.2 w
uilialums maklaain
uiliam maklain b ui -5.8
uiliammas maklainn p -4.3 v -6.1
uiliams maklait v -5.0 o
uilians makli
uliams maklii z a -4.2
viliams makliik j -5.2 aa -4.6
makliin s -5.8 uu -4.9
Campbell maklin ch u -5.1
malain
kaampu
kaampul matliin s -5.6 u
kaamvul miklain k -6.8 uu -5.5
kamvul mikliin u -5.6
miklin a -6.2
</table>
<tableCaption confidence="0.926499666666667">
Table 2: (A) Training-corpus-attested renderings of Williams,
Campbell, and McLean. (B) Top learned Inuktitut substi-
tutions and their log probabilities for several English (shown
</tableCaption>
<bodyText confidence="0.977400618181818">
underlined) orthographic characters (and character sequences).
Where top substitutions for English characters are shown, none
equal or better were omitted.
mista/mistu) – the immediately following capitalized En-
glish words (up to 2) were extracted and the same num-
ber of Inuktitut words were extracted to be used as train-
ing pairs. Thus, given the appearance in aligned sen-
tences of “Mr. Quirke” and “mista kuak”, the training
pair (Quirke,kuak) would be extracted. Common dis-
tractions such as “Mr Speaker” were filtered out. In or-
der to focus on the native English name problem (Inuk-
titut name rendering into English is much less noisy) the
English extractions were required to have appeared in a
large, news-corpus-derived English wordlist. This pro-
cedure resulted in a conservative, high-quality list of 434
unique name pairs. The probabilistic FST model we se-
lected was that of a memoryless (single-state) transducer
representing a joint distribution over character substitu-
tions, English insertions, and Inuktitut insertions. This
model is identical to that presented in Ristad and Yianilos
(1997). Prior to training, common English digraphs (e.g.,
“th” and “sh”) were mapped to unique single characters,
as were doubled consonants. Inuktitut “ng” and common
two-vowel sequences were also mapped to unique single
characters to elicit higher-quality results from the memo-
ryless transduction model employed. Some results of the
transducer training are displayed in Table 2(B). Proba-
bilistic FST weight training was accomplished using the
Dyna modeling language and DynaMITE parameter op-
timization toolkit (Eisner et al, 2004). The translitera-
tion modeling described here differs from such previous
transliteration work as Stalls and Knight (1998) in that
there is no explicit modeling of pronunciation, only a di-
rect transduction between written forms.
In applying transliteration on trial/test data, the
following criteria were used to select English words for
transliteration: (1) Word is capitalized (2) Word is not in
the exclusion list.4 For the top-ranked transliteration of
the English word present in the Inuktitut sentence, all
occurrences of that word in that sentence are marked as
aligned to the English word.
We have yet to evaluate English-Inuktitut translitera-
tion in isolation on a large test set. However, accuracy
on the workshop trial data was 4/4 hypotheses correct,
and on test data 2/6 correct. Of the 4 incorrect test
hypotheses, 2 were mistakes in identifying the correct
transliteration, and 2 mistakes resulted from attempting
to transliterate an English word such as “Councillors”
which should not be transliterated. Even with a rela-
tively low accuracy, the transliteration model, which is
used only as an individual voter in combination systems,
is unlikely to vote for the incorrect choice of another sys-
tem. Its purpose under system combination is to push a
good alignment link hypothesis up to the required vote
threshold.5
</bodyText>
<sectionHeader confidence="0.992403" genericHeader="method">
5 IBM Model 4 Alignments
</sectionHeader>
<bodyText confidence="0.999874260869565">
As a baseline and contributor to our combination sys-
tems, we ran GIZA++ (Och and Ney, 2000), to produce
alignments based on IBM Model 4. The IBM align-
ment models are asymmetric, requiring that one lan-
guage be idenitifed as the “e” language, whose words
are allowed many links each, and the other as the “f” lan-
guage, whose words are allowed at most one link each.
Although the observed alignment cardinalities naturally
suggest identifying Inuktitut as the “e” language and En-
glish as the “f” language, we ran both directions for com-
pleteness.
As a crude first attempt to capture sublexical corre-
spondences in the absence of a method for morpheme
segmentation, we developed a rough syllable segmenter
(spending approximately 2 person-hours), ran GIZA++
to produce alignments treating the syllables as words,
and chose, for each English word, the Inuktitut word or
words the largest number of whose syllables were linked
to it.
In the nomenclature of our results tables, giza++ syl-
labized refers to the latter system, giza++ E(1)-I(N) rep-
resents GIZA++ run with English as the “e” language,
and giza++ E(N)-I(1) sets English as the “f” language.
</bodyText>
<sectionHeader confidence="0.9548395" genericHeader="method">
6 System Performance and Combination
Methods
</sectionHeader>
<bodyText confidence="0.997898333333333">
We observed the 4 main systems (3 GIZA++ variants and
WFST) to have significantly different performance pro-
files in terms of precision and recall. Consistently, WFST
</bodyText>
<tableCaption confidence="0.4660277">
4Exclusion list was compiled as follows: (a) capitalized words in
2000 randomly selected English training sentences were examined,
Words such as Clerk, Federation, and Fisheries, which are frequently
capitalized but should not be transliterated, were put into the exclusion
list; in addition, any word with frequency &gt; 50 in the training corpus
was excluded, on the rationale that common-enough words would have
well-estimated translation probabilities already. 50 may seem like a
high threshold until one considers the high variability of the transliter-
ation process as demonstrated in Table 2(A).
5Refer to Section 6 for detailed descriptions of voting.
</tableCaption>
<table confidence="0.988870583333333">
81
SYSTEM P R F AER IHI/ITI
Individual system performance Trial Data
giza++E(1)-I(N) 63.4 26.6 37.5 32.9 0.42
giza++E(N)-I(1) 68.2 59.4 63.5 28.6 0.87
giza++ syllabized 83.6 44.5 58.1 18.3 0.53
WFST 70.3 72.7 71.5 27.8 1.03
Combination system performance Trial Data
F/AER Emphasis 85.4 63.5 72.9 12.3 0.74
AER Emphasis (1) 92.6 44.2 59.9 8.8 0.48
AER Emphasis (2) 95.1 38.0 54.3 9.5 0.40
F Emphasis 74.8 77.6 76.2 21.9 1.04
Recall Emphasis 66.9 82.1 73.8 28.9 1.23
Individual system performance Test Data
giza++E(1)-I(N) 49.7 18.6 27.0 45.2 0.37
giza++E(N)-I(1) 64.6 56.2 60.1 32.7 0.87
giza++ syllabized 84.9 44.0 57.9 15.6 0.52
WFST 65.4 68.3 66.8 33.7 1.04
(submitted) Combination system performance Test Data
F/AER Emphasis 84.4 58.6 69.2 14.3 0.69
AER Emphasis (1) 90.7 39.4 54.9 11.5 0.43
AER Emphasis (2) 96.7 32.3 48.4 9.5 0.33
F Emphasis 70.7 73.8 72.2 26.7 1.04
Recall Emphasis 62.6 81.7 70.1 34.2 1.31
</table>
<tableCaption confidence="0.999332">
Table 3: System performance evaluated on trial and test data.
</tableCaption>
<bodyText confidence="0.994527596153846">
The precision, recall and F-measure cited are the unlabeled
version (“probable,” in the nomenclature of this shared task).
The gold standard truth for trial data contained 710 alignments.
The test gold standard included 1972 alignments. The column
|H|/|T |lists ratio of hypothesis set size to truth set size for each
system.
won out on F-measure while giza++ syllabized attained
better alignment error rate (AER). Refer to Table 3 for
details of performance on trial and test data.
We investigated a number of system combination
methods, three of which were finally selected for use
in submitted systems. There were two basic methods of
combination: per-link voting and per-English-word vot-
ing.6 In per-link voting, an alignment link is included if
it is proposed by at least a certain number of the partic-
ipating individual systems. In per-English-word voting,
the best outgoing link is chosen for each English word
(the link which is supported by the greatest number of in-
dividual systems). Any ties are broken using the WFST
system choice. A high-recall variant of per-English-word
voting was included in which ties at vote-count 1 (in-
dicating a low-confidence decision) are not broken, but
rather all systems’ choices are submitted as hypotheses.
The transliteration model described in Section 4 was
included as a voter in each combination system, though it
made few hypotheses (6 on the test data). Composition of
the submitted systems was as follows: F/AER Empha-
6Combination methods we elected not to submit included voting
with trained weights and various stacked classifiers. The reasoning was
that with such a small development data set – 25 sentences – it was
unsafe to put faith in any but the simplest of classifier combination
schemes.
sis - per-link voting with decision criterion &gt;= 2 votes,
over all 5 described systems (WFST, 3 GIZA++ vari-
ants, transliteration). AER Emphasis (I) per-link voting,
&gt;= 2 votes, over all systems except giza++ E(N)-I(1).
AER Emphasis (II) per-link voting, &gt;= 3 votes, over
all systems. F Emphasis per-English-word voting, over
all systems, using WFST as tiebreaker. Recall Empha-
sis per-English-word voting, over all systems, high-recall
variant.
We elected to submit these systems because each
tailors to a distinct evaluation criterion (as suggested
by the naming convention). Experiments on trial data
convinced us that minimizing AER and maximizing F-
measure in a single system would be difficult. Mini-
mizing AER required such high-precision results that the
tradeoff in recall greatly lowered F-measure. It is inter-
esting to note that system combination does provide a
convenient means for adjusting alignment precision and
recall to suit the requirements of the problem or evalua-
tion standard at hand.
</bodyText>
<sectionHeader confidence="0.99949" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.946676166666667">
We have presented several individual and combined sys-
tems for word alignment of Inuktitut-English bitext. The
most successful individual systems were those targeted
to the specific characteristics of the language pair. The
combined systems generally outperformed the individual
systems, and different combination methods were able to
optimize for performance under different evaluation met-
rics. In particular, per-English-word voting performed
well on F-measure, while per-link voting performed well
on AER.
Acknowledgements: Many thanks to Eric Goldlust, David
Smith, and Noah Smith for help in using the Dyna language.
</bodyText>
<sectionHeader confidence="0.995001" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998218090909091">
J. Eisner, E. Goldlust, and N. A. Smith. 2004. Dyna: A declarative
language for implementing dynamic programs. In Proceedings of the
42nd Annual Meeting of the Association for Computational Linguistics
(ACL 2004), Companion Volume, pages 218-221.
M. Mallon. 1999. Inuktitut linguistics for technocrats. Technical re-
port, Ittukuluuk Language Programs, Iqaluit, Nunavut, Canada.
J. Martin, H. Johnson, B. Farley, and A. Maclachlan. 2003. Align-
ing and using an English-Inuktitut parallel corpus. In Proceedings of
Workshop on Building and Using Parallel Texts: Data Driven Machine
Translation and Beyond, HLT-NAACL 2003.
M. Mohri, F. Pereira, and M. Riley. 1997.
ATT General-purpose finite-state machine software tools.
http://www.research.att.com/sw/tools/fsm/.
F. J. Och and H. Ney. 2000. Improved statistical alignment models. In
Proceedings of the 38th Annual Meeting of the Association for Compu-
tational Linguistics, pages 440–447.
E. S. Ristad and P. N. Yianilos. 1997. Learning string edit distance. In
Machine Learning: Proceedings of the Fourteenth International Con-
ference, pages 287–295.
B. Stalls and K. Knight. 1998. Translating names and technical terms
in arabic text. In Proceedings of the COLING/ACL Workshop on Com-
putational Approaches to Semitic Languages.
</reference>
<page confidence="0.929749">
82
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.534799">
<title confidence="0.99994">Models for Inuktitut-English Word Alignment</title>
<author confidence="0.999929">Charles Schafer</author>
<author confidence="0.999929">Elliott Franco</author>
<affiliation confidence="0.776641">Department of Computer Johns Hopkins</affiliation>
<address confidence="0.997984">Baltimore, MD 21218,</address>
<abstract confidence="0.9967974">This paper presents a set of techniques for bitext word alignment, optimized for a language pair with the characteristics of Inuktitut-English. The resulting systems exploit cross-lingual affinities at the sublexical level of syllables and substrings, as well as regular patterns of transliteration and the tendency towards monotonicity of alignment. Our most successful systems were based on classifier combination, and we found different combination methods performed best under the target evaluation metrics of F-measure and alignment error rate.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Eisner</author>
<author>E Goldlust</author>
<author>N A Smith</author>
</authors>
<title>Dyna: A declarative language for implementing dynamic programs.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL 2004), Companion Volume,</booktitle>
<pages>218--221</pages>
<contexts>
<context position="12574" citStr="Eisner et al, 2004" startWordPosition="1912" endWordPosition="1915">Inuktitut insertions. This model is identical to that presented in Ristad and Yianilos (1997). Prior to training, common English digraphs (e.g., “th” and “sh”) were mapped to unique single characters, as were doubled consonants. Inuktitut “ng” and common two-vowel sequences were also mapped to unique single characters to elicit higher-quality results from the memoryless transduction model employed. Some results of the transducer training are displayed in Table 2(B). Probabilistic FST weight training was accomplished using the Dyna modeling language and DynaMITE parameter optimization toolkit (Eisner et al, 2004). The transliteration modeling described here differs from such previous transliteration work as Stalls and Knight (1998) in that there is no explicit modeling of pronunciation, only a direct transduction between written forms. In applying transliteration on trial/test data, the following criteria were used to select English words for transliteration: (1) Word is capitalized (2) Word is not in the exclusion list.4 For the top-ranked transliteration of the English word present in the Inuktitut sentence, all occurrences of that word in that sentence are marked as aligned to the English word. We </context>
</contexts>
<marker>Eisner, Goldlust, Smith, 2004</marker>
<rawString>J. Eisner, E. Goldlust, and N. A. Smith. 2004. Dyna: A declarative language for implementing dynamic programs. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL 2004), Companion Volume, pages 218-221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mallon</author>
</authors>
<title>Inuktitut linguistics for technocrats.</title>
<date>1999</date>
<tech>Technical report,</tech>
<institution>Ittukuluuk Language Programs,</institution>
<location>Iqaluit, Nunavut, Canada.</location>
<contexts>
<context position="1831" citStr="Mallon (1999)" startWordPosition="259" endWordPosition="260">nuktitut-English as well as possible simplifying assumptions. We used these observations to construct a novel weighted finite-state transducer alignment model as well as a specialized transliteration model. We combined these customized systems with 3 systems based on IBM Model 4 alignments under several methods of classifier combination. These combination strategies allowed us to produce multiple submissions targeted at the distinct evaluation measures via a precision/recall tradeoff. 2 Special Characteristics of the Inuktitut-English Alignment Problem Guided by the discussion of Inuktitut in Mallon (1999), we examined the Nunavut Hansards training and handlabeled trial data sets in order to identify special challenges and exploitable characteristics of the InuktitutEnglish word alignment problem. We were able to identify three: (1) Importance of sublexical Inuktitut units; (2) 1-to-N Inuktitut-to-English alignment cardinality; (3) Monotonicity of alignments. 2.1 Types and Tokens Inuktitut has an extremely productive agglutinative morphology, and an orthographic word may combine very many individual morphemes. As a result, in InuktitutEnglish bitext we observe Inuktitut sentences with many fewe</context>
<context position="8945" citStr="Mallon, 1999" startWordPosition="1353" endWordPosition="1355">ated in parentheses. are not conditioned on the identity of the Inuktitut word. 4 English-Inuktitut Transliteration Although in this corpus English and Inuktitut are both written in Roman characters, English names are significantly transformed when rendered in Inuktitut text. Consider the following English/Inuktitut pairs from the training corpus: Chartrand/saaturaan, Chretien/kurittian and the set of training corpus-attested Inuktitut renderings of Williams, Campbell, and McLean shown in Table 2(A) (which does not include variations containing the common -mut lexeme, meaning “to [a person]” (Mallon, 1999)). Clearly, not only does the English-to-Inuktitut transformation radically change the name string, it does so in a nondeterministic way which appears to be influenced not only by the phonological preferences of Inuktitut but also by differing pronunciations of the name in question and possibly by differing conventions of translators (note, for example, maklain versus mikliin for McLean). We trained a probabilistic finite-state transducer (FST) to identify English-Inuktitut transliterated pairs in aligned sentences. Training string pairs were acquired from the training bitext in the following </context>
</contexts>
<marker>Mallon, 1999</marker>
<rawString>M. Mallon. 1999. Inuktitut linguistics for technocrats. Technical report, Ittukuluuk Language Programs, Iqaluit, Nunavut, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Martin</author>
<author>H Johnson</author>
<author>B Farley</author>
<author>A Maclachlan</author>
</authors>
<title>Aligning and using an English-Inuktitut parallel corpus.</title>
<date>2003</date>
<booktitle>In Proceedings of Workshop on Building and Using Parallel Texts: Data Driven Machine Translation and Beyond, HLT-NAACL</booktitle>
<contexts>
<context position="5660" citStr="Martin et al. (2003)" startWordPosition="851" endWordPosition="854">ignment, computed over the trial data. English alignment. Our weighted finite-state transducer (WFST) alignment model, illustrated in Figure 1, structurally enforces monotonicity and 1-to-N cardinality, and exploits sublexical information by incorporating association scores between English words and Inuktitut word substrings, based on co-occurrence in aligned sentences. For each English word, an association score was computed not only with each Inuktitut word, but also with each Inuktitut character string of length ranging from 2 to 10 characters. This is similar to the technique described in Martin et al. (2003) as part of their construction of a bilingual glossary from English-Inuktitut bitext. However, our goal is different and we keep all the English-Inuktitut associations, rather than selecting only the “best” ones using a greedy method, as do they. Additionally, before extracting all substrings from each Inuktitut word, we added a special character to the word’s beginning and end (e.g., makkuttut —&gt; makkuttut ), in order to exploit any preferences for word-initial or -final placement. The heuristic association score chosen was p(worde|wordi) x p(wordi|worde), computed over all the aligned senten</context>
</contexts>
<marker>Martin, Johnson, Farley, Maclachlan, 2003</marker>
<rawString>J. Martin, H. Johnson, B. Farley, and A. Maclachlan. 2003. Aligning and using an English-Inuktitut parallel corpus. In Proceedings of Workshop on Building and Using Parallel Texts: Data Driven Machine Translation and Beyond, HLT-NAACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mohri</author>
<author>F Pereira</author>
<author>M Riley</author>
</authors>
<date>1997</date>
<note>ATT General-purpose finite-state machine software tools. http://www.research.att.com/sw/tools/fsm/.</note>
<contexts>
<context position="6704" citStr="Mohri et al., 1997" startWordPosition="1019" endWordPosition="1022"> exploit any preferences for word-initial or -final placement. The heuristic association score chosen was p(worde|wordi) x p(wordi|worde), computed over all the aligned sentence pairs. We have in the past observed this to be a useful indicator of word association, and it has the nice property of being in the range (0,1]. The WFST aligner is a composition of 4 transducers.2 The structure of the entire WFST composition enforces monotonicity, Inuktitut-to-English 1-N cardinality, and Inuktitut word fertilities ranging between 1 and 7. This model was implemented using the ATT finitestate toolkit (Mohri et al., 1997). In Figure 1, [1] is a linear transducer mapping each English position in a particular English test sentence to the word at that position. It is constructed so as to force each English word to participate in exactly 1 alignment. [2] is a single-state transducer mapping English word to Inuktitut substrings (or full words) with weights derived from the association scores.3 [3] is a transducer mapping Inuktitut substrings (and full words) to their position in the Inuktitut test sentence. Its construction allows a single Inuktitut position to correspond to multiple English positions, while enforc</context>
</contexts>
<marker>Mohri, Pereira, Riley, 1997</marker>
<rawString>M. Mohri, F. Pereira, and M. Riley. 1997. ATT General-purpose finite-state machine software tools. http://www.research.att.com/sw/tools/fsm/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>440--447</pages>
<contexts>
<context position="14020" citStr="Och and Ney, 2000" startWordPosition="2143" endWordPosition="2146">2 were mistakes in identifying the correct transliteration, and 2 mistakes resulted from attempting to transliterate an English word such as “Councillors” which should not be transliterated. Even with a relatively low accuracy, the transliteration model, which is used only as an individual voter in combination systems, is unlikely to vote for the incorrect choice of another system. Its purpose under system combination is to push a good alignment link hypothesis up to the required vote threshold.5 5 IBM Model 4 Alignments As a baseline and contributor to our combination systems, we ran GIZA++ (Och and Ney, 2000), to produce alignments based on IBM Model 4. The IBM alignment models are asymmetric, requiring that one language be idenitifed as the “e” language, whose words are allowed many links each, and the other as the “f” language, whose words are allowed at most one link each. Although the observed alignment cardinalities naturally suggest identifying Inuktitut as the “e” language and English as the “f” language, we ran both directions for completeness. As a crude first attempt to capture sublexical correspondences in the absence of a method for morpheme segmentation, we developed a rough syllable </context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F. J. Och and H. Ney. 2000. Improved statistical alignment models. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 440–447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E S Ristad</author>
<author>P N Yianilos</author>
</authors>
<title>Learning string edit distance.</title>
<date>1997</date>
<booktitle>In Machine Learning: Proceedings of the Fourteenth International Conference,</booktitle>
<pages>287--295</pages>
<contexts>
<context position="12048" citStr="Ristad and Yianilos (1997)" startWordPosition="1835" endWordPosition="1838">tractions such as “Mr Speaker” were filtered out. In order to focus on the native English name problem (Inuktitut name rendering into English is much less noisy) the English extractions were required to have appeared in a large, news-corpus-derived English wordlist. This procedure resulted in a conservative, high-quality list of 434 unique name pairs. The probabilistic FST model we selected was that of a memoryless (single-state) transducer representing a joint distribution over character substitutions, English insertions, and Inuktitut insertions. This model is identical to that presented in Ristad and Yianilos (1997). Prior to training, common English digraphs (e.g., “th” and “sh”) were mapped to unique single characters, as were doubled consonants. Inuktitut “ng” and common two-vowel sequences were also mapped to unique single characters to elicit higher-quality results from the memoryless transduction model employed. Some results of the transducer training are displayed in Table 2(B). Probabilistic FST weight training was accomplished using the Dyna modeling language and DynaMITE parameter optimization toolkit (Eisner et al, 2004). The transliteration modeling described here differs from such previous t</context>
</contexts>
<marker>Ristad, Yianilos, 1997</marker>
<rawString>E. S. Ristad and P. N. Yianilos. 1997. Learning string edit distance. In Machine Learning: Proceedings of the Fourteenth International Conference, pages 287–295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Stalls</author>
<author>K Knight</author>
</authors>
<title>Translating names and technical terms in arabic text.</title>
<date>1998</date>
<booktitle>In Proceedings of the COLING/ACL Workshop on Computational Approaches to Semitic Languages.</booktitle>
<contexts>
<context position="12695" citStr="Stalls and Knight (1998)" startWordPosition="1929" endWordPosition="1932">mmon English digraphs (e.g., “th” and “sh”) were mapped to unique single characters, as were doubled consonants. Inuktitut “ng” and common two-vowel sequences were also mapped to unique single characters to elicit higher-quality results from the memoryless transduction model employed. Some results of the transducer training are displayed in Table 2(B). Probabilistic FST weight training was accomplished using the Dyna modeling language and DynaMITE parameter optimization toolkit (Eisner et al, 2004). The transliteration modeling described here differs from such previous transliteration work as Stalls and Knight (1998) in that there is no explicit modeling of pronunciation, only a direct transduction between written forms. In applying transliteration on trial/test data, the following criteria were used to select English words for transliteration: (1) Word is capitalized (2) Word is not in the exclusion list.4 For the top-ranked transliteration of the English word present in the Inuktitut sentence, all occurrences of that word in that sentence are marked as aligned to the English word. We have yet to evaluate English-Inuktitut transliteration in isolation on a large test set. However, accuracy on the worksho</context>
</contexts>
<marker>Stalls, Knight, 1998</marker>
<rawString>B. Stalls and K. Knight. 1998. Translating names and technical terms in arabic text. In Proceedings of the COLING/ACL Workshop on Computational Approaches to Semitic Languages.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>