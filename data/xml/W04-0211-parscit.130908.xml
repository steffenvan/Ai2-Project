<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.971297">
Sentential Structure and Discourse Parsing
</title>
<author confidence="0.974353">
Livia Polanyi, Chris Culy, Martin van den Berg, Gian Lorenzo Thione, David Ahn1
</author>
<affiliation confidence="0.7430685">
FX Palo Alto Laboratory
3400 Hillview Ave, Bldg. 4
</affiliation>
<address confidence="0.967186">
Palo Alto, CA 94304
</address>
<email confidence="0.997858">
{polanyi|culy|vdberg|thione}@fxpal.com, ahn@science.uva.nl
</email>
<sectionHeader confidence="0.992492" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999595166666666">
In this paper, we describe how the LIDAS
System (Linguistic Discourse Analysis Sys-
tem), a discourse parser built as an implemen-
tation of the Unified Linguistic Discourse
Model (U-LDM) uses information from sen-
tential syntax and semantics along with lexical
semantic information to build the Open Right
Discourse Parse Tree (DPT) that serves as a
representation of the structure of the discourse
(Polanyi et al., 2004; Thione 2004a,b). More
specifically, we discuss how discourse seg-
mentation, sentence-level discourse parsing,
and text-level discourse parsing depend on the
relationship between sentential syntax and dis-
course. Specific discourse rules that use syn-
tactic information are used to identify possible
attachment points and attachment relations for
each Basic Discourse Unit to the DPT.
</bodyText>
<sectionHeader confidence="0.998695" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999930933333333">
In this paper, we describe discourse parsing under
the Unified Linguistic Discourse Model (U-LDM)
(Polanyi et al. 2004). In particular, we describe the
relationship between the output of sentential pars-
ing and discourse processing.
The goal of discourse parsing under the U-LDM
is to assign a proper semantic interpretation to
every utterance in a text. In order to do so, the
model constructs a structural representation of rela-
tions among the discourse segments that constitute
a text. This representation is realized as a Dis-
course Parse Tree (DPT). Incoming discourse ut-
terances are matched with the informational con-
text needed for interpretation, and attached to
nodes on the right edge of the tree.
</bodyText>
<footnote confidence="0.391926">
1 Current address:
Language and Inference Technology Group,
Informatics Institute
Kruislaan 403
1098 SJ Amsterdam, The Netherlands
</footnote>
<subsectionHeader confidence="0.951886">
1.1 Discourse Parse Tree
</subsectionHeader>
<bodyText confidence="0.9999851875">
The U-LDM builds upon the insights and mecha-
nisms of the Linguistic Discourse Model (LDM)
(Polanyi 1988). The DPT specifies which segments
are coordinated to one another (bear a similar rela-
tionship to a common higher order construct),
which are subordinated to other constituents (give
more information about entities or situations de-
scribed in that constituent, or, alternatively, inter-
rupt the flow of the discourse to interject unrelated
information), and which are related as constituents
of logical, language specific, rhetorical, genre spe-
cific or interactional structures (n-ary relations).
Importantly, the representation identifies which
constituents are available for continuation at any
moment in the development of a text and which are
no longer structurally accessible.
</bodyText>
<subsectionHeader confidence="0.924629">
1.2 Discourse Parsing
</subsectionHeader>
<bodyText confidence="0.999965473684211">
While full understanding of the meaning of con-
stituent utterances, world knowledge, inference
and complex reasoning are needed to create the
correct Discourse Parse Tree to represent the struc-
ture of discourse under the LDM, in developing the
U-LDM, it became apparent that most of the in-
formation needed to assign structural relations to a
text can be recovered from relating lexical, syntac-
tic and semantic information in constituent sen-
tences to information available at nodes on the
DPT. Largely formal methods involving manipu-
lating information in lexical ontologies and the
output of sentential syntactic and semantic analysis
are sufficient to account for most cases of dis-
course continuity, and give rise to only limited
ambiguity in most other cases.2 The assignment of
correct temporal, personal and spatial interpreta-
tion to utterances, which relies in large part on the
relative location of referential expression and their
</bodyText>
<footnote confidence="0.994623428571429">
2 Complex default logic based reasoning as in Struc-
tured Discourse Representation Theory (Asher 1993;
Asher and Lascarides 2003), speculations about the in-
tentions or beliefs of speakers (as in Grosz and Sidner
(1986)), or the intricate node labeling exercises familiar
from Rhetorical Structure Theory (Mann and Thompson
1988; Marcu 1999, 2000) are not necessary.
</footnote>
<bodyText confidence="0.980068">
referents in the DPT representation of the structure
of the discourse, can then often be recovered. From
a computational point of view, this is good news.
Parsing consists of the following steps for every
sentence of the discourse.
</bodyText>
<listItem confidence="0.9510755">
1. The sentence is parsed by a sentence level
parser, in our case the LFG-based Xerox Lin-
guistic Environment (XLE).
2. The sentence is broken up in discourse relevant
segment based on the syntactic information
from the sentence parser.
3. The segments are recombined into one or more
small discourse trees, called Basic Discourse
Unit (BDU) trees, representing the discourse
structure of the sentence.
4. The BDU trees corresponding to the sentence
are each attached to the DPT tree.3
</listItem>
<bodyText confidence="0.999496333333333">
In the remainder of this paper, we will describe
how the LIDAS System (Linguistic Discourse
Analysis System), a discourse parser built as an
implementation of the U-LDM, uses information
from sentential syntax and semantics along with
lexical semantic information to build up the struc-
tural representation of source texts4. Specifically,
we will discuss discourse segmentation, sentence-
level discourse parsing, and text-level discourse
parsing—phases of the discourse parsing process
that depend on the relationship between sentential
syntax and discourse.
</bodyText>
<sectionHeader confidence="0.891224" genericHeader="method">
2 Discourse Segments and Basic Discourse
Units
</sectionHeader>
<bodyText confidence="0.999661071428571">
U-LDM discourse segmentation is based on the
syntactic reflexes of the semantic content of the
linguistic phenomena making up discourse. Since
elementary discourse units must be identified to
build up discourse structure recursively, discourse
segments under the U-LDM are identified as the
syntactic units that encode a minimum unit of dis-
course function and/or meaning that must be inter-
preted relative to a set of contexts to be under-
stood. Minimal Functional units include greetings,
connectives, discourse PUSH/POP markers and
other “cue phrases” that connect or modify content
segments. Minimal meaning units are units that
express information about not more than one event,
</bodyText>
<footnote confidence="0.668468777777778">
3 If a sentence is sufficiently complex, it may consist
of two or more completely different independent dis-
course units. Such cases are treated as if the two parts of
the sentence were really two different sentences. One
consequence of this is that a syntactic coordination of
two sentences may correspond to a subordination in the
DPT, because they are treated independently.
4 The LiveTree environment for discourse parsing is
described in detail in Thione 2004b.
</footnote>
<bodyText confidence="0.999871125">
event-type or state of affairs in a possible world.
Roughly speaking they are “elementary proposi-
tions” or “event-type predicates” corresponding in
(neo-) Davidsonian semantics to an elementary
statement that contains at most one event-
quantifier. Structurally, a minimum meaning unit
does not contain a proper subpart that itself com-
municates content and has a syntactic correlate that
can stand on its own.
Under the U-LDM, segments can be discontinu-
ous (if there is overt material on both sides of an
intervening segment) or fragmentary. A single
word answer to a question is a complete segment,
whereas the same word uttered in an incomplete
and unrecoverable phrase is a fragment.
The U-LDM defines segmentation in purely sen-
tence syntactic terms. However, the choices of
definitions are motivated by semantic considera-
tions. For example, since auxiliaries and modals do
not refer to events distinctly from the main verb,
they do not form segments separate from the corre-
sponding main verbs. By the same reasoning, other
modal constructions that involve infinitives (e.g.
have to, ought to, etc.) also constitute a single
</bodyText>
<figureCaption confidence="0.97789025">
Content segments Simple clauses, Subordinate
(BDUs) clauses and participial phrases,
Secondary predications,5 Inter-
polations (e.g. parentheticals,
appositives, interruptions, etc.),
Fragments (e.g. section head-
ings, bullet items, etc.)
Operator segments Conjunctions that conjoin seg-
ments, Discourse operators
(e.g. “scene-setting” preposed
modifiers)6Discourse connec-
tives
</figureCaption>
<tableCaption confidence="0.7547035">
Table 1: Examples BDU and Operator Seg-
ments.
</tableCaption>
<bodyText confidence="0.999489111111111">
segment with their complements as do Cleft con-
structions, despite the presence of two verbs.7 On
the other hand, Equi verbs (e.g., try, persuade) and
Raising verbs (e.g., seem, believe, etc) form sepa-
rate BDUs from their verbal complements, since
both eventualities can be continued. In contrast,
even though event nominals, including gerunds,
refer to eventualities (possibly) distinct from the
verbs of which they are arguments or adjuncts,
</bodyText>
<footnote confidence="0.568992">
5 For example, “Chris served the chapter  |as Social
Chairman”
</footnote>
<page confidence="0.900643333333333">
6 For example: “Finally,  |the audio is summarized.”
7 For example: “It is segmentation that we are dis-
cussing.”
</page>
<bodyText confidence="0.969396962962963">
those eventualities can not (easily) be continued
and therefore are not segments.8
The U-LDM, in contrast to other discourse theo-
ries, has a fine-grained taxonomy of minimal units.
The most prominent distinction of discourse seg-
ments is between Basic Discourse Units (BDUs)
and Operator segments (see Table 1). BDUs are
segments realized in a linguistic utterance that can
independently provide the context for segments
later in the discourse. Operator segments can not
do so, they can only provide context for segments
in their scope.
In the following section, we explain more fully
how sentence syntax is used to segment sentences
into discourse segments.
2.1 The role of the XLE in discourse segmen-
tation
Dividing a text into discourse segments begins
by applying a sentence breaking algorithm to de-
termine the tokens to be segmented. These tokens
are normally complete sentences, but may also be
fragments in some cases such as titles or elliptical
phrases such as “Yes”. The tokens are processed
by a discourse segmenter. After the segmenter has
completed its work, segments are passed to a U-
LDM BDU-Tree parser, which constructs one or
more BDU-Trees from the BDUs identified in each
sentence.
The LIDAS segmenter first sends the input
chunk to be parsed by the Xerox Linguistic Envi-
ronment parser (XLE) (Maxwell and Kaplan
1989). The XLE is a robust Lexical Functional
Grammar (LFG) parser. The XLE tries to parse the
input, and returns either a packed representation of
all possible parses or the most probable parse as
selected by its stochastic disambiguation compo-
nent (Riezler et al. 2002). If the XLE can not find a
parse of the input as a complete sentence it tries to
construct a sequence of partially parsed fragments.9
The LIDAS segmenter segments the most probable
parse and, as a backup, the first parse from the
packed representation, if the first and the most
probable parse differ.
8 Note that the contrast between modal verbs on the
one hand and Raising and Equi verbs on the other
clearly shows that the surface form of a phrase (e.g., the
infinitival complements) is not always sufficient to de-
termine segment status. Similarly, a finite verb is not a
sufficient indicator of a segment, as seen in the cleft
constructions. Crucially, and appropriately, we need to
refer to the discourse property of potential continuation.
9 The XLE has a failure rate (i.e., no parse whatso-
ever) of approximately 0.5% on our corpus of technical
reports.
</bodyText>
<table confidence="0.9970596">
Content Segments
Certain F-structures with subjects10
Fragments
Parentheticals
Headers
Syntactic coordination (except conjunct itself)
Operator segments
Conjuncts in coordination
Initial comma separated modifiers
Subordinating conjunctions
</table>
<tableCaption confidence="0.999515">
Table 2. Segment classification configura-
</tableCaption>
<bodyText confidence="0.983586068965517">
tions.
The parse information consists of a c(onstituent)
structure (essentially a standard parse tree) and a
f(unctional) structure containing predicate-
argument information, modification information,
and other grammatical information such as tense
and agreement features. F-structures make up the
primary source of linguistic information used in
discourse parsing.
To identify the discourse segments within the
sentence, seven syntactic configurations in c-
structure and f-structure are examined. The rela-
tively small set of configurations in Table 2 ac-
counts for the full range of discourse segments.
According to these segmentation rules, it is pos-
sible for a segment to be embedded in another
segment. Because on the tree-projection of U-
LDM structures terminal nodes represent a con-
tiguous textual span, we recombine the two parts
of a non-contiguous segment in the BDU-tree (sec-
tion 4) and DPT (section 5) using the concatena-
tion relation (+). Concatenated nodes contain the
complete f-structure information of the completed
segment and are full-fledged BDUs, available for
further “anaphoric anchoring”.
All segments are returned to the discourse parser
in an XML format, which includes the f-structure
information as well as the textual spans for each
sentential segment.
</bodyText>
<sectionHeader confidence="0.995145" genericHeader="method">
3 Discourse Parsing
</sectionHeader>
<bodyText confidence="0.99040805">
The next step after segmentation is combining the
segments into a BDU-tree according to the rules of
discourse parsing, resulting in a discourse tree rep-
resenting the sentence. After that, the BDU-tree is
10 F-structures with SUBJ (subject) attributes are con-
sidered possible discourse segments since they typically
encode an eventuality. However, because they do not
introduce independent anchor points for future attach-
ment, the f-structures corresponding to modal and auxil-
iary verbs are excluded.
combined with the Discourse Parse Tree, again
according to the discourse parsing rules.
In discourse parsing, units of discourse are at-
tached to an emergent discourse tree. Attachment
always takes place on the right edge of the tree.
The parser has to make two decisions: what unit to
attach to and what relationship obtains between the
incoming unit and the selected attachment site. The
types of evidence are used to determine this in-
clude:
</bodyText>
<listItem confidence="0.94384519047619">
• syntactic information
o subordinate/complement relations, parallel
syntactic structure, topic/focus and centering
information, syntactic status of re-used lex-
emes, preposed adverbial constituents, etc.
• lexical information
o Information from lexical ontology: re-use of
same lexeme, synonym/antonym, hypernym,
participation in the same lexical frame as
well as specific discourse connectives tem-
poral and adverbial connectives indicating
set or sub-set membership of any type for
example, specifically, alternatively11.
o Modal information: realis status, modality,
genericity, tense, aspect, point of view12),
• Structural information of both the local at-
tachment point and of the BDU-tree
• Presence of constituents of incomplete n-ary
constructions on the right edge
o questions, initial greetings, genre-internal
units such as sections and sub-sections, etc.
</listItem>
<bodyText confidence="0.999764625">
The combined weight of the evidence determines
the attachment point and the attachment relation.
Interestingly, the weight given to each type of in-
formation is different for attachment site selection
and relationship determination. Lexical ontological
information, for example, is generally more impor-
tant in determining site, while semantic, syntactic
and lexical “cue” information is more relevant in
determining relationship.
In Polanyi et al. 2004, a small set of robust rules
is given for determining the attachment site and
relationship of an incoming BDU-tree to the exist-
ing parse tree of the discourse. In the present pa-
per, which has as its focus understanding the rela-
tionship of sentential syntax to discourse structure,
we concentrate on describing some fundamental
</bodyText>
<tableCaption confidence="0.680193833333333">
11 These expressions are used as input to specific
lexically driven rules that indicate language or genre
specific binary relations between BDUs as suggested by
Webber, Joshi and colleagues in their work on D-
LTAGs. (Webber and Joshi, 1998; Webber, Knott and
Joshi, 1999; Webber, Knott, Stone and Joshi 1999.)
</tableCaption>
<page confidence="0.453505">
12 See discussion Wiebe, 1994.
</page>
<bodyText confidence="0.999122333333333">
aspects of the relationship between the sentential
syntactic structure of an incoming sentence and its
corresponding sentential discourse structure.
</bodyText>
<subsectionHeader confidence="0.7915795">
3.1 The Sentential Syntax - Discourse Struc-
ture Interface
</subsectionHeader>
<bodyText confidence="0.922719476190476">
In discourse parsing with LIDAS, the output of
the XLE parser supplies functional constraints and
roles for syntactic structures. The syntactic struc-
ture of a sentence accounts for the discourse-
relevant relationships between segments within a
sentence. LIDAS grammars exploit this informa-
tion by mapping syntactic relations onto discourse
relations. The LIDAS grammar formalism permits
the parser to leverage the XLE’s output by (1)
checking positive or negative constraints (equality
or inequality operators) (2) recursively searching f-
structures for specified attributes (* and ? wild-
cards), (3) enforcing dependent constraints,13 and
(4) using Boolean connectives to combine con-
straints. (5) applying constraints universally or ex-
istentially to the set of matching f-structures. While
LIDAS grammar rules can incorporate constraints
that operate on all supported types of linguistic
evidence, Table 3 gives three examples of rules
that specify attachments based on the syntactic re-
lationship between constituents.
</bodyText>
<table confidence="0.9974697">
BDU-1,BDU-2:
BDU-1/phi = BDU-2/ADJUNCT/link;
4 Right-Subordination.
BDU-1,BDU-2:
BDU-1/*/ADJUNCT/link = BDU-2/phi;
4 Subordination.
BDU-1,BDU-2:
BDU-1/*/{XCOMP|COMP|COMP-EX}/link
= BDU-2/phi;
4 Context.
</table>
<tableCaption confidence="0.999947">
Table 3: Rules based on syntactic relationship.
</tableCaption>
<bodyText confidence="0.966387636363636">
Rule 1 captures one general case for preposed
modifiers. Prepositional and adverbial phrases,
often temporal modifiers, that precede the main
clause they modify can either elaborate on the
main clause or modify the context in which the
main clause is interpreted. Lexical information is
used to distinguish among different types of modi-
fiers. Rule 2 expresses the general case of subordi-
nate adjunct clauses and shows that the syntax for
13 For example, the following constraints show a de-
pendency between (1) and (3),
</bodyText>
<listItem confidence="0.980516666666667">
(1) BDU-1/(*)/ADJUNCT/link = BDU-2/phi;
(2) BDU-2/ADJUNCT-TYPE = “relative”;
(3) $1/SPEC/DET/DET-TYPE = &amp;quot;indef&amp;quot;;
</listItem>
<bodyText confidence="0.999815266666667">
One or more sub-f-structures that match the wildcard
in the first constraint are tested in the third constraint.
This constraint is part of a rule of sentential discourse
syntax used to identify non-restrictive relative clauses.
LIDAS’ discourse rules allows for recursive search
over f-structures by seeking adjunct phrases match-
ing the incoming BDU anywhere within the f-
structure of the attachment point. Rule 3, which
shows a compact syntax for disjunctive constraint,
builds a sentence level discourse relation, the Con-
text Binary, that forms a complex context unit
from its child constituents. Context Binaries are the
general case for clausal complementizers.
In the next section, we discuss one of the basic
discourse parsing rules.
</bodyText>
<subsectionHeader confidence="0.997459">
3.2 Discourse Subordination
</subsectionHeader>
<bodyText confidence="0.999337230769231">
We will assume the following extended hierarchy
of grammatical functions:14 PRED &gt; SUBJ &gt; OBJ
&gt; COMP &gt; ADJUNCT &gt; SPEC.15 Given this hier-
archy we propose as a general principle of dis-
course construction that promotion in the hierar-
chy means demotion in the discourse. For exam-
ple, if the SUBJ of the incoming unit of discourse
refers to the same entity16 as OBJ at the attachment
node, then the relationship between them will be a
subordination. In general, if an expression with
grammatical function GF in a BDU B refers to the
same (or a subcase of the same) entity as an ex-
pression with grammatical function GF’ in an ac-
cessible antecedent BDU A, where GF &gt; GF’, then
B will be attached as a subordinate structure to A
on the DPT. This principle is expressed as a rule in
the grammar that fires if it is not superseded by
other rules. For example, the Narrative rule, which
coordinates event clauses, takes precedence over
the Discourse Demotion Rule.
If the grammatical function hierarchy rule does
not apply, but the BDU refers to a subclass17 of the
antecedent BDU, there is evidence for a subordina-
tion relation. For example, if the subject of the
BDU stands in a part-of relationship with the sub-
ject of the antecedent BDU, we can conclude that
the relationship is a subordination.
14 PRED denotes the tensed verb. It plays a role in the
following discussion because verbs can be nominalized.
15 For the purposes of this hierarchy, grammatical
function COMP includes the features COMP-EX and
XCOMP. An element inside an expression with
a grammatical function GF is itself in that position with
respect to the elements that are not in that expression,
although a separate ordering might exist between ele-
ments within the same expression. C.f. Obliqueness
command in HPSG (Pollard and Sag, 1994).
16 In LIDAS, no reference resolution is done. Identity
of reference is approximated using lexical semantics.
17 The notion of subcase as used here covers a num-
ber of different notions. An expression e is a subcase of
f if (1) e is a set that is a subset of f, (2) e is a subtype of
f, or (3) e is a part of f, among other relations.
Table 4 gives the interaction of this rule with the
hierarchy rule and the resulting relationships: G
denotes whether a shift in the grammatical function
hierarchy occurred, and L whether the shifted ele-
ment refers to the same entity, part of that entity or
to an entity that is larger. If more than one such
expression can be found, we consider the expres-
sion in the incoming unit with the highest gram-
matical function.
</bodyText>
<table confidence="0.99853475">
G+ G0 G-
L+ S/C18 C S
L0 S C N/A
L- S S N/A
</table>
<tableCaption confidence="0.776928">
Table 4. Interactions of the hierarchy
and subcase rules.
</tableCaption>
<bodyText confidence="0.996367272727273">
The table is read as follows: take the expressions in
the incoming unit that have a relationship with an
expression in the attachment point. Let e be the
expression among these that has the highest gram-
matical function, and f be the corresponding ex-
pression in the attachment point. If the grammati-
cal function of e is higher than that of f, we write
G+, if it is the same G0, if it is lower G-. Similarly,
if e is a supercase of f, we write L+, if e and f refer
to the same entity L0, and if e is a subcase of f, L-.
For example
</bodyText>
<listItem confidence="0.321325">
1. U1: The man was wearing a coat.
U2: The Burberry looked brand new.
</listItem>
<bodyText confidence="0.810477821428571">
In this case we notice that the words coat and
Burberry are such that L&lt;coat, Burberry&gt; = L-
and we also notice that Burberry gets promoted to
the subject of the incoming unit, while coat was
the direct object of U1. Therefore G&lt;coat, Bur-
berry&gt; = G+. From Table 4 we correctly identify
that U2 does indeed subordinate on U1.
Both L- and G+ give evidence for discourse sub-
ordination. Grammatical function demotion G- is a
less clear case.19 Some mixed combinations sug-
gest discourse coordination (as for the preservation
case &lt;L0 , G0&gt;) while others contribute too little
18 Semantics would help to disambiguate this case. If
the antecedent f is more specific than the anaphoric
element e, two cases are possible. Either e is used as a
definite description referring to the same entity as f, in
which case the relation is a coordination, or e is used to
denote a larger class of entities than f, in which therela-
tion is likely to be a subordination.
19 As is understanding precisely what is involved
from a discourse relation point of view with complex,
mixed promotion/demotion phenomena (from the sub-
ject of an XCOMP to the adjunct of an OBJ, for exam-
ple)
significant information to independently determine
the discourse attachment (N/A cases). In those
cases, evidence from other rules in the grammar
determines the result.
</bodyText>
<sectionHeader confidence="0.678031" genericHeader="method">
4 BDU-Trees
</sectionHeader>
<bodyText confidence="0.890552">
Identifying the relationship of a BDU to the dis-
course in which it occurs is a complex parsing
process involving lexical, semantic, structural and
syntactic information. The first step in understand-
ing the relationship of a given BDU to the extra-
sentential discourse context is to understand the
role a BDU plays within the sentence in which it
occurs. As a first step of constructing a discourse
parse-tree of the sentence, the XLE parse and sen-
tential discourse rules are used to identify relation-
ships between the BDUs within the sentence re-
sulting in one or more BDU-trees. These small
sentence-level discourse trees consist of one main
clause and its subordinated clauses or preposed
modifiers.20
The root node of a BDU-tree represents the non-
subordinated material (often referred to as active
material) within that BDU-tree, including at least
the information of the main clause. The projection
of the root node on the active leaves is referred to
as the M-BDU (Main BDU). Only syntactic infor-
mation from the M-BDU is used to attached the
BDU-tree to the DPT. In general, a sentence yields
as many BDU-trees as top-level coordinated
clauses.
Consider, Example 2, a sentence taken from our
corpus of Technical Reports:
2. As a consequence, any hypertext link followed
opened a new browser window, which we think of
as a &amp;quot;Rabbit Hole&amp;quot; because the new window indi-
cates to users that they are no longer navigating in-
side the slideshow, but are instead navigating the
Web.
The U-LDM segmentation of this sentence:
</bodyText>
<construct confidence="0.9675042">
As a consequence  |any hypertext link  |followed |
opened a new browser window  |which we think of as a
&amp;quot;Rabbit Hole&amp;quot;  |because  |the new window indicates to
users  |that they  |are no longer navigating inside the
slideshow  |but  |are instead navigating the Web.
</construct>
<bodyText confidence="0.74186">
20 BDU-trees are very similar to the D-LTAG dis-
course segments (D-LDSs). However, BDU-trees in-
clude subordinated material, so they are typically larger
than D-LDSs. Furthermore, because U-LDM sentence
and discourse grammars are different, two BDU-trees
may stand in a coordinated relationship in sentence
grammar and be subordinated on the discourse level (cf.
example 1).
For compound sentences, members of the top-
level coordinate structures are attached independ-
ently, reflecting the fact that top-level coordinated
clauses can escape the boundaries of the sentence
when attaching to the main discourse structure. For
example, the discourse parse of the following pas-
sage, illustrated in Example 3, consists of two sen-
tences, five segments, four BDUs and three BDU-
Trees that eventually form one DPT.
</bodyText>
<listItem confidence="0.646073666666667">
3. S1: B1: The man soaked himself in the water.
S2: B2: It was warm and soothing B3 and he
decided to linger a little longer than usual.
</listItem>
<bodyText confidence="0.999874578947368">
Despite the apparent syntactic coordination be-
tween the two main clauses, the two BDU-Trees in
S2 show the independence of BDU-Tree/DPT at-
tachments. B1 describes a punctual event on a
main story line. B3 describes the next event. The
semantic and aspectual information of the verb to
soak in BDU-1 and of the copula in BDU-2 com-
municates a switch from an event-line to an em-
bedded elaboration. The syntactic promotion of
water from object of the preposition in the adjunct
phrase in the water to the subject (through ana-
phoric reference) in the next segment indicates dis-
course subordination. Given L0&lt;water, it&gt; and
G+&lt;ADJUNCT/OBJ/PRED, SUBJ/PRED&gt;, we
find from table X, &lt;L0 ,G+&gt; Æ S. As a conse-
quence, B2 is subordinated to B1. In the DPT, B3
is coordinated with B1 at a point above B2, despite
being syntactically coordinated to it at the senten-
tial level.
</bodyText>
<sectionHeader confidence="0.98976" genericHeader="method">
5 Global Discourse Construction
</sectionHeader>
<bodyText confidence="0.9763263125">
BDU-trees are attached to the DPT of the entire
discourse as single units by computing the rela-
tionship between their M-BDUs and the accessible
nodes aligned along the right edge of the DPT.
Rules of discourse attachment that include those
discussed for BDU construction as well as other
genre and structural level rules are used in global
DPT construction.
The parsing process at the Discourse Parse Tree
(DPT) level works as follows. Once BDU-Trees
have been constructed and are ready to be attached
to the DPT, each node along the right edge is ex-
amined, and, through a set of discourse rules, an
ordered set of active Discourse Constituent Units
(DCUs) is produced, representing possible attach-
ment points.21 This set can then be pruned of its n
21 Lexical information is the main source of evidence
in attachment site determination while other sources
contribute to a lesser degree. The opposite is true for
determining attachment relations
lowest scoring constituents, according to a preset
threshold or other criteria.
Example
Our group is developing new techniques for helping
manage information for enhanced collaboration. We
explore solutions for seamlessly connecting people to
their personal and shared resources. Our solutions in-
clude services for contextual and proactive information
access, personalized and collaborative office appli-
ances, collaborative annotation, and symbolic, statisti-
cal, and hybrid processing of natural language.
Our team includes researchers with diverse back-
</bodyText>
<table confidence="0.95763728125">
grounds including: ubiquitous computing, computer-
supported collaboration, HCI, IR , and NLP.
Segmented Text
1. Our group is developing new techniques for helping
2. manage information for enhanced collaboration.
3. We explore solutions for seamlessly connecting
people to their personal and shared resources.
4. Our solutions include services for contextual and
proactive information access, personalized and col-
laborative office appliances, collaborative annota-
tion, and symbolic, statistical, and hybrid process-
ing of natural language.
5. Our team includes researchers with diverse back-
grounds
6. including:
7. ubiquitous computing, computer-supported col-
laboration, HCI, IR , and NLP.
Rules
1-2 Intrasentential XCOMPS --&gt; CX
CX(1,2)-3 Demotion 2
[ Pres. Progressive to Simple Pre-
sent]
[ Our group --&gt; We ]
[ Same Verb Class ] --&gt; S
3-4 Promotion
[Solutions from OBJ to SUBJ] --&gt; S
5-6 Relative Adjunct with Null Deter-
miner --&gt; S
6-7 Colon + OBJ linked to NP segment
--&gt; CX
CX(1,2)-5 Synonym Subjects, Same
Tense --&gt; C22
</table>
<tableCaption confidence="0.99881">
Table 5. Analyzed Webpage Example
</tableCaption>
<bodyText confidence="0.993803833333334">
In the second stage, attachment rules are checked
against possible attachment sites. Rules that fire
successfully attach the BDU-Tree to the DPT at the
chosen site with the relationship specified by the
rule. Local semantic, lexical and syntactic informa-
tion is then percolated into the parent DCU. If mul-
tiple attachments at different sites are possible,
22 Discourse parsing is not unambiguous and different
analyses may apply. So, here the same subject, change
in progressive feature, and different verb class, which
also apply would create an S. Future research is needed
to understand precisely which rules take precedence.
ambiguous parses are generated; less preferred at-
tachments are discarded and the remaining attach-
ment choices generate valid parse trees.
Once a BDU-tree has been attached, its leaves
become terminal nodes of the DPT and nodes on
its right edge are accessible for continuation and
may serve as contextual anchors for subsequent
sentences. Table 5 shows an example text taken
from the FXPAL Webpage describing our research
group, a segmentation of the text and the DPT con-
structed following the rules. Figure 1 gives a s-
creenshot of the resulting tree.
</bodyText>
<figureCaption confidence="0.998968">
Figure 1: Tree of Analyzed Webpage Example
</figureCaption>
<sectionHeader confidence="0.900242" genericHeader="method">
6 Comparison with D-LTAG
</sectionHeader>
<bodyText confidence="0.999559236842105">
LIDAS is a purely symbolic discourse parser most
similar to the D-LTAG parser described in (Forbes
et. al. 2003). The overall structures of the LIDAS
and D-LTAG parsers are almost identical. There
are a number of apparently significant differences
between the underlying theories although some of
these may turn out to be notational variants after
more extensive analysis.
An important difference between D-LTAG and
U-LDM derives from the fundamental question of
segmentation; D-LTAG segments are larger than
our segments, corresponding more or less to BDU-
trees (but cf. footnote 20). In D-LTAG, because
only one grammar formalism governs both dis-
course and sentence level parsing, continuation can
also take place on parts of segments as defined by
sentence-level syntactic relations. Under the U-
LDM, which employs independent sentential and
discourse grammars, only segments are potential
anchors for continuation. Not only because we use
an external syntactic parser as an oracle that in-
forms segment attachment on the BDU-tree, but
more importantly because sentential syntax can be
overridden by discourse syntax in some cases.
Another basic difference between the two ap-
proaches is that D-LTAG builds its initial and aux-
iliary trees around connectives. Every discourse
relation is expressed by a, possibly empty, connec-
tive. In U-LDM, connectives give evidence about
the possible discourse relations, as do other parts
of the sentence, but they do not solely determine
discourse relation. We can thus account correctly
for cases in which the wrong connective is selected
to express a semantic relationship among seg-
ments.
Lastly, our parser is meant to be incremental at
the discourse level, whereas the D-LTAG parser
appears to operate on the discourse as a whole. 23
</bodyText>
<sectionHeader confidence="0.996568" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999693956521739">
In this paper we described a novel approach to dis-
course segmentation and discourse structure analy-
sis that unifies sentential syntax with discourse
structure and argued that most of the information
needed to assign a structural description to a text is
available from sentential syntactic parsing, senten-
tial semantic analysis and relationships among
words captured in a lexical ontology such as
WordNet. The U-LDM discourse rules and parsing
strategies presented here are a first step. We have
tested out these rules in analyzing a corpus of over
300 Technical Reports that have been summarized
under the PALSUMM System that operates on top
of LIDAS. (Polanyi et al 2004; Thione et al 2004)
Much work remains to be done. Understanding the
complex inter-relationships between rules is a for-
midable task. Critically important, too, is to unify
the semantically motivated structural analyses pre-
sented here with an explicit S-DRT type formal
semantic account of discourse semantics. How-
ever, we believe that the results presented here rep-
resent an important advance in understanding the
nature of natural language texts.
</bodyText>
<sectionHeader confidence="0.998639" genericHeader="references">
8 References
</sectionHeader>
<reference confidence="0.999915705128205">
Nicholas Asher. 1993. Reference to Abstract Objects in
English: A Philosophical Semantics for Natural Lan-
guage Metaphysics. Kluwer Academic Publishers.
Nicholas Asher and Alex Lascarides. 2003. Logics of
Conversation. Cambridge University Press.
Katherine Forbes, Eleni Miltsakaki, Rashmi Prasad,
Anoop Sarkar, Aravind Joshi and Bonnie Webber.
2003. D-LTAG System - Discourse Parsing with a
Lexicalized Tree-Adjoining Grammar, Journal of
Language, Logic and Information, 12(3).
Barbara Grosz and Candace Sidner. 1986. Attention,
Intention and the Structure of Discourse. Computa-
tional Linguistics 12:175-204.
William C. Mann and Sandra A. Thompson. 1988. Rhe-
torical Structure Theory: Towards a Functional The-
ory of Text Organization. Text 8(3)243-281.
23 In the current LIDAS implementation, we do not
represent ambiguity directly, but implement a greedy
parsing algorithm with backtracking. The non-locality
of the D-LTAG parser as described in Forbes et. al.
2003 may likewise be a consequence of their current
implementation.
Daniel Marcu. 1999. Discourse trees are good indicators
of importance in text. In Advances in Automatic Text
Summarization. I. Mani and Mark Maybury (eds),
123-136, The MIT Press.
Daniel Marcu. 2000. The Theory and Practice of Dis-
course Parsing and Summarization. The MIT Press.
Cambridge, MA.
John Maxwell and Ronald M. Kaplan. 1989. An over-
view of disjunctive constraint satisfaction. In Pro-
ceedings of the International Workshop on Parsing
Technologies, Pittsburgh, PA.
Livia Polanyi. 1988. A Formal Model of Discourse
Structure. Journal of Pragmatics 12: 601-639.
Livia Polanyi. 2004. A Rule-based Approach to Dis-
course Parsing. In Proceedings of SIGDIAL ’04.
Boston MA.
Stefan Riezler, Tracy H. King, Ronald M. Kaplan,
Richard Crouch, John T. Maxwell, and Mark John-
son. 2002. Parsing the Wall Street Journal using a
Lexical-Functional Grammar and discriminative es-
timation techniques. In Proceedings of the 40th An-
nual Meeting of the Association for Computational
Linguistics (ACL’02), Philadelphia, PA.
Stefan Riezler, Tracy H. King, Richard Crouch, and
Annie Zaenen. 2003. Statistical Sentence Condensa-
tion using Ambiguity Packing and Stochastic Disam-
biguation Methods for Lexical-Functional Grammar.
In Proceedings of HLT-NAACL&apos;03, Edmonton, Can-
ada.
Radu Soricut and Daniel Marcu. 2003. Sentence Level
Discourse Parsing using Syntactic and Lexical In-
formation. In Proceedings of HLT/NAACL’03, May
27-June 1, Edmonton, Canada
Thione, Gian Lorenzo, Martin van den Berg, Chris Culy
and Livia Polanyi. 2004a. Hybrid Text Summariza-
tion: Combining external relevance measures with
Structural Analysis. Proceedings ACL Workshop
Text Summarization Branches Out. Barcelona.
Thione, Gian Lorenzo, Martin van den Berg, Chris Culy
and Livia Polanyi. 2004b. LiveTree: An Integrated
Workbench for Discourse Processing. Proceedings
ACL Workshop on Discourse Annotation. Barcelona.
Bonnie Webber and Aravind Joshi, 1998. Anchoring a
lexicalized tree-adjoining grammar for discourse.
COLING/ACL Workshop in Discourse Realtions and
Discourse Markers. Montreal, Canada. 86-92.
Bonnie Webber, Alistair Knott and Aravind Joshi.
1999a. Multiple discourse connectives in a lexical-
ized grammar for discourse. In 3rd Int’l Workshop on
Computational Semantics. Tilburg. 309-325.
Bonnie Webber, Alistair Knott, Matthew Stone and
Aravind Joshi. 1999b. Discourse Relations: A Struc-
tural and Presuppositional Account Using Lexical-
ized TAGS. 37th ACL. College Park, MD. 41-48.
Wiebe, Janyce M. 1994. Tracking point of view in
narrative. Computational Linguistics 20 (2): 233-287.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.640972">
<title confidence="0.993045">Sentential Structure and Discourse Parsing</title>
<author confidence="0.705436">Chris Culy Polanyi</author>
<author confidence="0.705436">Martin van_den_Berg</author>
<author confidence="0.705436">Gian Lorenzo Thione</author>
<author confidence="0.705436">David</author>
<affiliation confidence="0.968346">FX Palo Alto Laboratory</affiliation>
<address confidence="0.9995315">3400 Hillview Ave, Bldg. 4 Palo Alto, CA 94304</address>
<email confidence="0.977707">{polanyi|culy|vdberg|thione}@fxpal.com, ahn@science.uva.nl</email>
<abstract confidence="0.996389947368421">In this paper, we describe how the LIDAS System (Linguistic Discourse Analysis System), a discourse parser built as an implementation of the Unified Linguistic Discourse Model (U-LDM) uses information from sentential syntax and semantics along with lexical semantic information to build the Open Right Discourse Parse Tree (DPT) that serves as a representation of the structure of the discourse (Polanyi et al., 2004; Thione 2004a,b). More specifically, we discuss how discourse segmentation, sentence-level discourse parsing, and text-level discourse parsing depend on the relationship between sentential syntax and discourse. Specific discourse rules that use syntactic information are used to identify possible attachment points and attachment relations for each Basic Discourse Unit to the DPT.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
</authors>
<title>Reference to Abstract Objects in English: A Philosophical Semantics for Natural Language Metaphysics.</title>
<date>1993</date>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="3780" citStr="Asher 1993" startWordPosition="565" endWordPosition="566">nstituent sentences to information available at nodes on the DPT. Largely formal methods involving manipulating information in lexical ontologies and the output of sentential syntactic and semantic analysis are sufficient to account for most cases of discourse continuity, and give rise to only limited ambiguity in most other cases.2 The assignment of correct temporal, personal and spatial interpretation to utterances, which relies in large part on the relative location of referential expression and their 2 Complex default logic based reasoning as in Structured Discourse Representation Theory (Asher 1993; Asher and Lascarides 2003), speculations about the intentions or beliefs of speakers (as in Grosz and Sidner (1986)), or the intricate node labeling exercises familiar from Rhetorical Structure Theory (Mann and Thompson 1988; Marcu 1999, 2000) are not necessary. referents in the DPT representation of the structure of the discourse, can then often be recovered. From a computational point of view, this is good news. Parsing consists of the following steps for every sentence of the discourse. 1. The sentence is parsed by a sentence level parser, in our case the LFG-based Xerox Linguistic Enviro</context>
</contexts>
<marker>Asher, 1993</marker>
<rawString>Nicholas Asher. 1993. Reference to Abstract Objects in English: A Philosophical Semantics for Natural Language Metaphysics. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
<author>Alex Lascarides</author>
</authors>
<title>Logics of Conversation.</title>
<date>2003</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="3808" citStr="Asher and Lascarides 2003" startWordPosition="567" endWordPosition="570">ntences to information available at nodes on the DPT. Largely formal methods involving manipulating information in lexical ontologies and the output of sentential syntactic and semantic analysis are sufficient to account for most cases of discourse continuity, and give rise to only limited ambiguity in most other cases.2 The assignment of correct temporal, personal and spatial interpretation to utterances, which relies in large part on the relative location of referential expression and their 2 Complex default logic based reasoning as in Structured Discourse Representation Theory (Asher 1993; Asher and Lascarides 2003), speculations about the intentions or beliefs of speakers (as in Grosz and Sidner (1986)), or the intricate node labeling exercises familiar from Rhetorical Structure Theory (Mann and Thompson 1988; Marcu 1999, 2000) are not necessary. referents in the DPT representation of the structure of the discourse, can then often be recovered. From a computational point of view, this is good news. Parsing consists of the following steps for every sentence of the discourse. 1. The sentence is parsed by a sentence level parser, in our case the LFG-based Xerox Linguistic Environment (XLE). 2. The sentence</context>
</contexts>
<marker>Asher, Lascarides, 2003</marker>
<rawString>Nicholas Asher and Alex Lascarides. 2003. Logics of Conversation. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katherine Forbes</author>
<author>Eleni Miltsakaki</author>
<author>Rashmi Prasad</author>
<author>Anoop Sarkar</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<title>D-LTAG System - Discourse Parsing with a Lexicalized Tree-Adjoining Grammar,</title>
<date>2003</date>
<journal>Journal of Language, Logic and Information,</journal>
<volume>12</volume>
<issue>3</issue>
<marker>Forbes, Miltsakaki, Prasad, Sarkar, Joshi, Webber, 2003</marker>
<rawString>Katherine Forbes, Eleni Miltsakaki, Rashmi Prasad, Anoop Sarkar, Aravind Joshi and Bonnie Webber. 2003. D-LTAG System - Discourse Parsing with a Lexicalized Tree-Adjoining Grammar, Journal of Language, Logic and Information, 12(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Grosz</author>
<author>Candace Sidner</author>
</authors>
<date>1986</date>
<booktitle>Attention, Intention and the Structure of Discourse. Computational Linguistics</booktitle>
<pages>12--175</pages>
<contexts>
<context position="3897" citStr="Grosz and Sidner (1986)" startWordPosition="582" endWordPosition="585">ulating information in lexical ontologies and the output of sentential syntactic and semantic analysis are sufficient to account for most cases of discourse continuity, and give rise to only limited ambiguity in most other cases.2 The assignment of correct temporal, personal and spatial interpretation to utterances, which relies in large part on the relative location of referential expression and their 2 Complex default logic based reasoning as in Structured Discourse Representation Theory (Asher 1993; Asher and Lascarides 2003), speculations about the intentions or beliefs of speakers (as in Grosz and Sidner (1986)), or the intricate node labeling exercises familiar from Rhetorical Structure Theory (Mann and Thompson 1988; Marcu 1999, 2000) are not necessary. referents in the DPT representation of the structure of the discourse, can then often be recovered. From a computational point of view, this is good news. Parsing consists of the following steps for every sentence of the discourse. 1. The sentence is parsed by a sentence level parser, in our case the LFG-based Xerox Linguistic Environment (XLE). 2. The sentence is broken up in discourse relevant segment based on the syntactic information from the s</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Barbara Grosz and Candace Sidner. 1986. Attention, Intention and the Structure of Discourse. Computational Linguistics 12:175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical Structure Theory: Towards a Functional Theory of Text Organization.</title>
<date>1988</date>
<tech>Text 8(3)243-281.</tech>
<contexts>
<context position="4006" citStr="Mann and Thompson 1988" startWordPosition="597" endWordPosition="600">ficient to account for most cases of discourse continuity, and give rise to only limited ambiguity in most other cases.2 The assignment of correct temporal, personal and spatial interpretation to utterances, which relies in large part on the relative location of referential expression and their 2 Complex default logic based reasoning as in Structured Discourse Representation Theory (Asher 1993; Asher and Lascarides 2003), speculations about the intentions or beliefs of speakers (as in Grosz and Sidner (1986)), or the intricate node labeling exercises familiar from Rhetorical Structure Theory (Mann and Thompson 1988; Marcu 1999, 2000) are not necessary. referents in the DPT representation of the structure of the discourse, can then often be recovered. From a computational point of view, this is good news. Parsing consists of the following steps for every sentence of the discourse. 1. The sentence is parsed by a sentence level parser, in our case the LFG-based Xerox Linguistic Environment (XLE). 2. The sentence is broken up in discourse relevant segment based on the syntactic information from the sentence parser. 3. The segments are recombined into one or more small discourse trees, called Basic Discourse</context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>William C. Mann and Sandra A. Thompson. 1988. Rhetorical Structure Theory: Towards a Functional Theory of Text Organization. Text 8(3)243-281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Forbes</author>
</authors>
<title>23 In the current LIDAS implementation, we do not represent ambiguity directly, but implement a greedy parsing algorithm with backtracking. The non-locality of the D-LTAG parser as described in</title>
<date>2003</date>
<marker>Forbes, 2003</marker>
<rawString>23 In the current LIDAS implementation, we do not represent ambiguity directly, but implement a greedy parsing algorithm with backtracking. The non-locality of the D-LTAG parser as described in Forbes et. al. 2003 may likewise be a consequence of their current implementation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>Discourse trees are good indicators of importance in text.</title>
<date>1999</date>
<booktitle>In Advances in Automatic Text Summarization. I. Mani and Mark Maybury (eds),</booktitle>
<pages>123--136</pages>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="4018" citStr="Marcu 1999" startWordPosition="601" endWordPosition="602">ost cases of discourse continuity, and give rise to only limited ambiguity in most other cases.2 The assignment of correct temporal, personal and spatial interpretation to utterances, which relies in large part on the relative location of referential expression and their 2 Complex default logic based reasoning as in Structured Discourse Representation Theory (Asher 1993; Asher and Lascarides 2003), speculations about the intentions or beliefs of speakers (as in Grosz and Sidner (1986)), or the intricate node labeling exercises familiar from Rhetorical Structure Theory (Mann and Thompson 1988; Marcu 1999, 2000) are not necessary. referents in the DPT representation of the structure of the discourse, can then often be recovered. From a computational point of view, this is good news. Parsing consists of the following steps for every sentence of the discourse. 1. The sentence is parsed by a sentence level parser, in our case the LFG-based Xerox Linguistic Environment (XLE). 2. The sentence is broken up in discourse relevant segment based on the syntactic information from the sentence parser. 3. The segments are recombined into one or more small discourse trees, called Basic Discourse Unit (BDU) </context>
</contexts>
<marker>Marcu, 1999</marker>
<rawString>Daniel Marcu. 1999. Discourse trees are good indicators of importance in text. In Advances in Automatic Text Summarization. I. Mani and Mark Maybury (eds), 123-136, The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>The Theory and Practice of Discourse Parsing and Summarization.</title>
<date>2000</date>
<publisher>The MIT Press.</publisher>
<location>Cambridge, MA.</location>
<marker>Marcu, 2000</marker>
<rawString>Daniel Marcu. 2000. The Theory and Practice of Discourse Parsing and Summarization. The MIT Press. Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Maxwell</author>
<author>Ronald M Kaplan</author>
</authors>
<title>An overview of disjunctive constraint satisfaction.</title>
<date>1989</date>
<booktitle>In Proceedings of the International Workshop on Parsing Technologies,</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="10010" citStr="Maxwell and Kaplan 1989" startWordPosition="1526" endWordPosition="1529">iding a text into discourse segments begins by applying a sentence breaking algorithm to determine the tokens to be segmented. These tokens are normally complete sentences, but may also be fragments in some cases such as titles or elliptical phrases such as “Yes”. The tokens are processed by a discourse segmenter. After the segmenter has completed its work, segments are passed to a ULDM BDU-Tree parser, which constructs one or more BDU-Trees from the BDUs identified in each sentence. The LIDAS segmenter first sends the input chunk to be parsed by the Xerox Linguistic Environment parser (XLE) (Maxwell and Kaplan 1989). The XLE is a robust Lexical Functional Grammar (LFG) parser. The XLE tries to parse the input, and returns either a packed representation of all possible parses or the most probable parse as selected by its stochastic disambiguation component (Riezler et al. 2002). If the XLE can not find a parse of the input as a complete sentence it tries to construct a sequence of partially parsed fragments.9 The LIDAS segmenter segments the most probable parse and, as a backup, the first parse from the packed representation, if the first and the most probable parse differ. 8 Note that the contrast betwee</context>
</contexts>
<marker>Maxwell, Kaplan, 1989</marker>
<rawString>John Maxwell and Ronald M. Kaplan. 1989. An overview of disjunctive constraint satisfaction. In Proceedings of the International Workshop on Parsing Technologies, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Livia Polanyi</author>
</authors>
<title>A Formal Model of Discourse Structure.</title>
<date>1988</date>
<journal>Journal of Pragmatics</journal>
<volume>12</volume>
<pages>601--639</pages>
<contexts>
<context position="2042" citStr="Polanyi 1988" startWordPosition="304" endWordPosition="305"> In order to do so, the model constructs a structural representation of relations among the discourse segments that constitute a text. This representation is realized as a Discourse Parse Tree (DPT). Incoming discourse utterances are matched with the informational context needed for interpretation, and attached to nodes on the right edge of the tree. 1 Current address: Language and Inference Technology Group, Informatics Institute Kruislaan 403 1098 SJ Amsterdam, The Netherlands 1.1 Discourse Parse Tree The U-LDM builds upon the insights and mechanisms of the Linguistic Discourse Model (LDM) (Polanyi 1988). The DPT specifies which segments are coordinated to one another (bear a similar relationship to a common higher order construct), which are subordinated to other constituents (give more information about entities or situations described in that constituent, or, alternatively, interrupt the flow of the discourse to interject unrelated information), and which are related as constituents of logical, language specific, rhetorical, genre specific or interactional structures (n-ary relations). Importantly, the representation identifies which constituents are available for continuation at any momen</context>
</contexts>
<marker>Polanyi, 1988</marker>
<rawString>Livia Polanyi. 1988. A Formal Model of Discourse Structure. Journal of Pragmatics 12: 601-639.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Livia Polanyi</author>
</authors>
<title>A Rule-based Approach to Discourse Parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of SIGDIAL ’04.</booktitle>
<location>Boston MA.</location>
<marker>Polanyi, 2004</marker>
<rawString>Livia Polanyi. 2004. A Rule-based Approach to Discourse Parsing. In Proceedings of SIGDIAL ’04. Boston MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Tracy H King</author>
<author>Ronald M Kaplan</author>
<author>Richard Crouch</author>
<author>John T Maxwell</author>
<author>Mark Johnson</author>
</authors>
<title>Parsing the Wall Street Journal using a Lexical-Functional Grammar and discriminative estimation techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL’02),</booktitle>
<location>Philadelphia, PA.</location>
<contexts>
<context position="10276" citStr="Riezler et al. 2002" startWordPosition="1570" endWordPosition="1573">okens are processed by a discourse segmenter. After the segmenter has completed its work, segments are passed to a ULDM BDU-Tree parser, which constructs one or more BDU-Trees from the BDUs identified in each sentence. The LIDAS segmenter first sends the input chunk to be parsed by the Xerox Linguistic Environment parser (XLE) (Maxwell and Kaplan 1989). The XLE is a robust Lexical Functional Grammar (LFG) parser. The XLE tries to parse the input, and returns either a packed representation of all possible parses or the most probable parse as selected by its stochastic disambiguation component (Riezler et al. 2002). If the XLE can not find a parse of the input as a complete sentence it tries to construct a sequence of partially parsed fragments.9 The LIDAS segmenter segments the most probable parse and, as a backup, the first parse from the packed representation, if the first and the most probable parse differ. 8 Note that the contrast between modal verbs on the one hand and Raising and Equi verbs on the other clearly shows that the surface form of a phrase (e.g., the infinitival complements) is not always sufficient to determine segment status. Similarly, a finite verb is not a sufficient indicator of </context>
</contexts>
<marker>Riezler, King, Kaplan, Crouch, Maxwell, Johnson, 2002</marker>
<rawString>Stefan Riezler, Tracy H. King, Ronald M. Kaplan, Richard Crouch, John T. Maxwell, and Mark Johnson. 2002. Parsing the Wall Street Journal using a Lexical-Functional Grammar and discriminative estimation techniques. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL’02), Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Riezler</author>
<author>Tracy H King</author>
<author>Richard Crouch</author>
<author>Annie Zaenen</author>
</authors>
<title>Statistical Sentence Condensation using Ambiguity Packing and Stochastic Disambiguation Methods for Lexical-Functional Grammar.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL&apos;03,</booktitle>
<location>Edmonton, Canada.</location>
<marker>Riezler, King, Crouch, Zaenen, 2003</marker>
<rawString>Stefan Riezler, Tracy H. King, Richard Crouch, and Annie Zaenen. 2003. Statistical Sentence Condensation using Ambiguity Packing and Stochastic Disambiguation Methods for Lexical-Functional Grammar. In Proceedings of HLT-NAACL&apos;03, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Soricut</author>
<author>Daniel Marcu</author>
</authors>
<title>Sentence Level Discourse Parsing using Syntactic and Lexical Information.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT/NAACL’03, May 27-June 1,</booktitle>
<location>Edmonton, Canada</location>
<marker>Soricut, Marcu, 2003</marker>
<rawString>Radu Soricut and Daniel Marcu. 2003. Sentence Level Discourse Parsing using Syntactic and Lexical Information. In Proceedings of HLT/NAACL’03, May 27-June 1, Edmonton, Canada</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gian Lorenzo Thione</author>
<author>Martin van den Berg</author>
<author>Chris Culy</author>
<author>Livia Polanyi</author>
</authors>
<title>Hybrid Text Summarization: Combining external relevance measures with Structural Analysis.</title>
<date>2004</date>
<booktitle>Proceedings ACL Workshop Text Summarization Branches Out.</booktitle>
<location>Barcelona.</location>
<marker>Thione, van den Berg, Culy, Polanyi, 2004</marker>
<rawString>Thione, Gian Lorenzo, Martin van den Berg, Chris Culy and Livia Polanyi. 2004a. Hybrid Text Summarization: Combining external relevance measures with Structural Analysis. Proceedings ACL Workshop Text Summarization Branches Out. Barcelona.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Gian Lorenzo Thione</author>
<author>Martin van den Berg</author>
</authors>
<title>Chris Culy and Livia Polanyi.</title>
<booktitle>2004b. LiveTree: An Integrated Workbench for Discourse Processing. Proceedings ACL Workshop on Discourse Annotation.</booktitle>
<location>Barcelona.</location>
<marker>Thione, van den Berg, </marker>
<rawString>Thione, Gian Lorenzo, Martin van den Berg, Chris Culy and Livia Polanyi. 2004b. LiveTree: An Integrated Workbench for Discourse Processing. Proceedings ACL Workshop on Discourse Annotation. Barcelona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Webber</author>
<author>Aravind Joshi</author>
</authors>
<title>Anchoring a lexicalized tree-adjoining grammar for discourse.</title>
<date>1998</date>
<booktitle>COLING/ACL Workshop in Discourse Realtions and Discourse Markers.</booktitle>
<pages>86--92</pages>
<location>Montreal,</location>
<contexts>
<context position="15543" citStr="Webber and Joshi, 1998" startWordPosition="2363" endWordPosition="2366">vant in determining relationship. In Polanyi et al. 2004, a small set of robust rules is given for determining the attachment site and relationship of an incoming BDU-tree to the existing parse tree of the discourse. In the present paper, which has as its focus understanding the relationship of sentential syntax to discourse structure, we concentrate on describing some fundamental 11 These expressions are used as input to specific lexically driven rules that indicate language or genre specific binary relations between BDUs as suggested by Webber, Joshi and colleagues in their work on DLTAGs. (Webber and Joshi, 1998; Webber, Knott and Joshi, 1999; Webber, Knott, Stone and Joshi 1999.) 12 See discussion Wiebe, 1994. aspects of the relationship between the sentential syntactic structure of an incoming sentence and its corresponding sentential discourse structure. 3.1 The Sentential Syntax - Discourse Structure Interface In discourse parsing with LIDAS, the output of the XLE parser supplies functional constraints and roles for syntactic structures. The syntactic structure of a sentence accounts for the discourserelevant relationships between segments within a sentence. LIDAS grammars exploit this informatio</context>
</contexts>
<marker>Webber, Joshi, 1998</marker>
<rawString>Bonnie Webber and Aravind Joshi, 1998. Anchoring a lexicalized tree-adjoining grammar for discourse. COLING/ACL Workshop in Discourse Realtions and Discourse Markers. Montreal, Canada. 86-92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Webber</author>
<author>Alistair Knott</author>
<author>Aravind Joshi</author>
</authors>
<title>Multiple discourse connectives in a lexicalized grammar for discourse.</title>
<date>1999</date>
<booktitle>In 3rd Int’l Workshop on Computational Semantics. Tilburg.</booktitle>
<pages>309--325</pages>
<marker>Webber, Knott, Joshi, 1999</marker>
<rawString>Bonnie Webber, Alistair Knott and Aravind Joshi. 1999a. Multiple discourse connectives in a lexicalized grammar for discourse. In 3rd Int’l Workshop on Computational Semantics. Tilburg. 309-325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Webber</author>
<author>Alistair Knott</author>
<author>Matthew Stone</author>
<author>Aravind Joshi</author>
</authors>
<date>1999</date>
<booktitle>Discourse Relations: A Structural and Presuppositional Account Using Lexicalized TAGS. 37th ACL. College Park, MD.</booktitle>
<pages>41--48</pages>
<marker>Webber, Knott, Stone, Joshi, 1999</marker>
<rawString>Bonnie Webber, Alistair Knott, Matthew Stone and Aravind Joshi. 1999b. Discourse Relations: A Structural and Presuppositional Account Using Lexicalized TAGS. 37th ACL. College Park, MD. 41-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce M Wiebe</author>
</authors>
<title>Tracking point of view in narrative.</title>
<date>1994</date>
<journal>Computational Linguistics</journal>
<volume>20</volume>
<issue>2</issue>
<pages>233--287</pages>
<contexts>
<context position="15643" citStr="Wiebe, 1994" startWordPosition="2381" endWordPosition="2382">the attachment site and relationship of an incoming BDU-tree to the existing parse tree of the discourse. In the present paper, which has as its focus understanding the relationship of sentential syntax to discourse structure, we concentrate on describing some fundamental 11 These expressions are used as input to specific lexically driven rules that indicate language or genre specific binary relations between BDUs as suggested by Webber, Joshi and colleagues in their work on DLTAGs. (Webber and Joshi, 1998; Webber, Knott and Joshi, 1999; Webber, Knott, Stone and Joshi 1999.) 12 See discussion Wiebe, 1994. aspects of the relationship between the sentential syntactic structure of an incoming sentence and its corresponding sentential discourse structure. 3.1 The Sentential Syntax - Discourse Structure Interface In discourse parsing with LIDAS, the output of the XLE parser supplies functional constraints and roles for syntactic structures. The syntactic structure of a sentence accounts for the discourserelevant relationships between segments within a sentence. LIDAS grammars exploit this information by mapping syntactic relations onto discourse relations. The LIDAS grammar formalism permits the p</context>
</contexts>
<marker>Wiebe, 1994</marker>
<rawString>Wiebe, Janyce M. 1994. Tracking point of view in narrative. Computational Linguistics 20 (2): 233-287.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>