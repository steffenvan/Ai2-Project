<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000453">
<title confidence="0.990711">
Social Text Normalization using Contextual Graph Random Walks
</title>
<author confidence="0.974262">
Hany Hassan Arul Menezes
</author>
<affiliation confidence="0.969836">
Microsoft Research Microsoft Research
</affiliation>
<address confidence="0.953325">
Redmond, WA Redmond, WA
</address>
<email confidence="0.997855">
hanyh@microsoft.com arulm@microsoft.com
</email>
<sectionHeader confidence="0.993867" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999897857142857">
We introduce a social media text normal-
ization system that can be deployed as a
preprocessing step for Machine Transla-
tion and various NLP applications to han-
dle social media text. The proposed sys-
tem is based on unsupervised learning of
the normalization equivalences from unla-
beled text. The proposed approach uses
Random Walks on a contextual similarity
bipartite graph constructed from n-gram
sequences on large unlabeled text corpus.
We show that the proposed approach has a
very high precision of (92.43) and a rea-
sonable recall of (56.4). When used as
a preprocessing step for a state-of-the-art
machine translation system, the translation
quality on social media text improved by
6%. The proposed approach is domain and
language independent and can be deployed
as a preprocessing step for any NLP appli-
cation to handle social media text.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99866901754386">
Social Media text is usually very noisy and con-
tains a lot of typos, ad-hoc abbreviations, pho-
netic substitutions, customized abbreviations and
slang language. The social media text is evolving
with new entities, words and expressions. Natural
language processing and understanding systems
such as Machine Translation, Information Extrac-
tion and Text-to-Speech are usually trained and
optimized for clean data; therefore such systems
would face a challenging problem with social me-
dia text.
Various social media genres developed distinct
characteristics. For example, SMS developed a
nature of shortening messages to avoid multiple
keystrokes. On the other hand, Facebook and in-
stant messaging developed another genre where
more emotional expressions and different abbre-
viations are very common. Somewhere in be-
tween, Twitter’s statuses come with some brevity
similar to SMS along with the social aspect of
Facebook. On the same time, various social me-
dia genres share many characteristics and typo
styles. For example, repeating letters or punctu-
ation for emphasizing and emotional expression
such as ”‘goooood morniiing”’. Using phonetic
spelling in a generalized way or to reflect a lo-
cal accent; such as ”‘wuz up bro”’ (what is up
brother). Eliminating vowels such as ”‘cm to c
my luv”’. Substituting numbers for letters such as
”‘4get”’ (forget) , ”‘2morrow”’ (tomorrow), and
”‘b4”’ (before). Substituting phonetically sim-
ilar letters such as ”‘phone”’ (fon). Slang ab-
breviations which usually abbreviates multi-word
expression such as ”‘LMS”’ (like my status) ,
”‘idk”’ (i do not know), ”‘rofl”’ (rolling on floor
laughing).
While social media genres share many charac-
teristics, they have significant differences as well.
It is crucial to have a solution for text normaliza-
tion that can adapt to such variations automati-
cally. We propose a text normalization approach
using an unsupervised method to induce normal-
ization equivalences from noisy data which can
adapt to any genre of social media.
In this paper, we focus on providing a solu-
tion for social media text normalization as a pre-
processing step for NLP applications. However,
this is a challenging problem for several reasons.
First, it is not straightforward to define the Out-of-
Vocabulary (OOV) words. Traditionally, an OOV
word is defined as a word that does not exist in
the vocabulary of a given system. However, this
definition is not adequate for the social media text
which has a very dynamic nature. Many words
and named entities that do not exist in a given vo-
cabulary should not be considered for normaliza-
tion. Second, same OOV word may have many
</bodyText>
<page confidence="0.946051">
1577
</page>
<note confidence="0.9135645">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1577–1586,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.9999389375">
appropriate normalization depending on the con-
text and on the domain. Third, text normalization
as a preprocessing step should have very high pre-
cision; in other words, it should provide conser-
vative and confident normalization and not over-
correct. Moreover, the text normalization should
have high recall, as well, to have a good impact on
the NLP applications.
In this paper, we introduce a social media text
normalization system which addresses the chal-
lenges mentioned above. The proposed system is
based on constructing a lattice from possible nor-
malization candidates and finding the best normal-
ization sequence according to an n-gram language
model using a Viterbi decoder. We propose an
unsupervised approach to learn the normalization
candidates from unlabeled text data. The proposed
approach uses Random Walks on a contextual sim-
ilarity graph constructed form n-gram sequences
on large unlabeled text corpus. The proposed ap-
proach is very scalable, accurate and adaptive to
any domain and language. We evaluate the ap-
proach on the normalization task as well as ma-
chine translation task.
The rest of this paper is organized as follows:
Section(2) discusses the related work, Section(3)
introduces the text normalization system and the
baseline candidate generators, Section(4) intro-
duces the proposed graph-based lexicon induction
approach, Section(5) discusses the experiments
and output analysis, and finally Section(6) con-
cludes and discusses future work.
</bodyText>
<sectionHeader confidence="0.999694" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999962647058824">
Early work handled the text normalization prob-
lem as a noisy channel model where the normal-
ized words go through a noisy channel to produce
the noisy text. (Brill and Moore, 2000) introduced
an approach for modeling the spelling errors as
a noisy channel model based on string to string
edits. Using this model gives significant perfor-
mance improvements compared to previously pro-
posed models. (Toutanova and Moore, 2002) im-
proved the string to string edits model by mod-
eling pronunciation similarities between words.
(Choudhury et al., 2007) introduced a supervised
HMM channel model for text normalization which
has been expanded by (Cook and Stevenson, 2009)
to introduce unsupervised noisy channel model
using probabilistic models for common abbrevi-
ation and various spelling errors types. Some
researchers used Statistical Machine Translation
approach for text normalization; formalizing the
problem as a translation from the noisy forms to
the normalized forms. (Aw et al., 2006) proposed
an approach for normalizing Short Messaging Ser-
vice (SMS) texts by translating it into normal-
ized forms using Phrase-based SMT techniques on
character level. The main drawback of these ap-
proaches is that the noisy channel model cannot
accurately represent the errors types without con-
textual information.
More recent approaches tried to handle the text
normalization problem using normalization lexi-
cons which map the noisy form of the word to a
normalized form. For example, (Han et al., 2011)
proposed an approach using a classifier to identify
the noisy words candidate for normalization; then
using some rules to generate lexical variants and a
small normalization lexicon. (Gouws et al., 2011)
proposed an approach using an impoverished nor-
malization lexicon based on string and distribu-
tional similarity along with a dictionary lookup
approach to detect noisy words. More recently,
(Han et al., 2012) introduced a similar approach
by generating a normalization lexicon based on
distributional similarity and string similarity. This
approach uses pairwise similarity where any two
words that share the same context are considered
as normalization equivalences. The pairwise ap-
proach has a number of limitations. First, it does
not take into account the relative frequencies of
the normalization equivalences that might share
different contexts. Therefore, the selection of the
normalization equivalences is performed on pair-
wise basis only and is not optimized over the
whole data. Secondly, the normalization equiva-
lences must appear in the exact same context to
be considered as a normalization candidate. These
limitations affect the accuracy and the coverage of
the produced lexicon.
Our approach also adopts a lexicon based ap-
proach for text normalization, we construct a lat-
tice from possible normalization candidates and
find the best normalization sequence according
to an n-gram language model using a Viterbi de-
coder. The normalization lexicon is acquired from
unlabeled data using random walks on a contex-
tual similarity graph constructed form n-gram se-
quences on large unlabeled text corpus. Our ap-
proach has some similarities with (Han et al.,
2012) since both approaches utilize a normaliza-
</bodyText>
<page confidence="0.987841">
1578
</page>
<bodyText confidence="0.999984777777778">
tion lexicon acquired form unlabeled data using
distributional and string similarities. However, our
approach is significantly different since we acquire
the lexicon using random walks on a contextual
similarity graph which has a number of advantages
over the pairwise similarity approach used in (Han
et al., 2012). Namely, the acquired normalization
equivalence are optimized globally over the whole
data, the rare equivalences are not considered as
good candidates unless there is a strong statistical
evidence across the data, and finally the normal-
ization equivalences may not share the same con-
text. Those are clear advantages over the pairwise
similarity approach and result in a lexicon with
higher accuracy as well as wider coverage. Those
advantages will be clearer when we describe the
proposed approach in details and during evalua-
tion and comparison to the pairwise approach.
</bodyText>
<sectionHeader confidence="0.989178" genericHeader="method">
3 Text Normalization System
</sectionHeader>
<bodyText confidence="0.999971086956521">
In this paper, we handle text normalization as a
lattice scoring approach, where the translation is
performed from noisy text as the source side to
the normalized text as the target side. Unlike con-
ventional MT systems, the translation table is not
learned from parallel aligned data; instead it is
modeled by the graph-based approach of lexicon
generation as we will describe later. We construct
a lattice from possible normalization candidates
and find the best normalization sequence accord-
ing to an n-gram language model using a Viterbi
decoder.
In this paper, we restrict the normalization lexi-
con to one-to-one word mappings, we do not con-
sider multi words mapping for the lexicon induc-
tion. To identify OOV candidates for normaliza-
tion; we restrict proposing normalization candi-
dates to the words that we have in our induced
normalization lexicon only. This way, the system
would provide more confident and conservative
normalization. We move the problem of identi-
fying OOV words to training time; at training time
we use soft criteria to identify OOV words.
</bodyText>
<subsectionHeader confidence="0.9504985">
3.1 Baseline Normalization Candidates
Generation
</subsectionHeader>
<bodyText confidence="0.988331205882353">
We experimented with two normalization candi-
date generators as baseline systems. The first is a
dictionary based spelling correction similar to As-
pell1. In this experiment we used the spell checker
lhttp://aspell.net/
to generate all possible candidates for OOV words
and then applied the Viterbi decoder on the con-
structed lattice to score the best correction candi-
dates using a language model.
Our second candidates generator is based on
a trie approximate string matching with K errors
similar to the approach proposed in (Chang et al.,
2010), where K errors can be caused by substi-
tution, insertion, or deletion operations. In our
implementation, we customized the errors opera-
tions to accommodate the nature of the social me-
dia text. Such as lengthening, letter substitution,
letter-number substitution and phonetic substitu-
tion. This approach overcomes the main problem
of the dictionary-based approach which is provid-
ing inappropriate normalization candidates to the
errors styles in the social media text.
As we will show in the experiments in
Section(5), dictionary-based normalization meth-
ods proved to be inadequate for social media do-
main normalization for many reasons. First, they
provide generic corrections which are inappropri-
ate for social media text. Second, they usually pro-
vide corrections with the minimal edit distance for
any word or named entity regardless of the nature
of the words. Finally, the previous approaches do
not take into account the dynamics of the social
media text where new terms can be introduced on
a daily basis.
</bodyText>
<sectionHeader confidence="0.975672" genericHeader="method">
4 Normalization Lexicons using
Graph-based Random Walks
</sectionHeader>
<subsectionHeader confidence="0.999821">
4.1 Bipartite Graph Representation
</subsectionHeader>
<bodyText confidence="0.982358111111111">
The main motivation of this approach is that
normalization equivalences share similar context;
which we call contextual similarity. For instance,
assume 5-gram sequences of words, two words
may be normalization equivalences if their n-gram
context shares the same two words on the left and
the same two words on the right. In other words,
they are sharing a wild card pattern such as (word
1 word 2 * word 4 word 5).
This contextual similarity can be represented as
a bipartite graph with the first partite representing
the words and the second partite representing the
n-gram contexts that may be shared by words. A
word node can be either normalized word or noisy
word. Identifying if a word is normalized or noisy
(candidate for normalization) is crucial since this
decision limits the candidate noisy words to be
normalized. We adopted a soft criteria for iden-
</bodyText>
<page confidence="0.995062">
1579
</page>
<figureCaption confidence="0.993034">
Figure 1: Bipartite Graph Representation, left
</figureCaption>
<bodyText confidence="0.898893545454546">
nodes represent contexts, gray right nodes repre-
sent the noisy words and white right nodes rep-
resent the normalized words. Edge weight is the
co-occurrence count of a word and its context.
tifying noisy words. A vocabulary is constructed
from a large clean corpus. Any word that does not
appear in this vocabulary more than a predefined
threshold (i.e. 10 times) is considered as a can-
didate for normalization (noisy word). Figure(1)
shows a sample of the bipartite graph G(W, C, E),
where noisy words are shown as gray nodes.
</bodyText>
<construct confidence="0.8455089">
Algorithm 4.1: CONSTxUCTBIrAxTITE(text)
comment: Construct Bipartite Graph
output (G(W, C, E))
comment: Extract all n-gram sequences
Ngrams +- EXTxACTNGxAMS(TextCorpus)
for each n E Ngrams
do
�
�comment: Check for center word
if ISNOISY(CenterWord)
</construct>
<equation confidence="0.986980875">
W +- ADDSOUxCENODE(CenterWord)
else
W +- ADDABSOxBINGNODE(CenterWord)
comment: add the context pattern
C +- ADD(Context)
comment: edge weight
��
E +- ADD(Context, Word, count)
</equation>
<bodyText confidence="0.988101692307692">
The bipartite graph, G(W, C, E), is composed
of W which includes all nodes representing nor-
malized words and noisy words, C which includes
all nodes representing shared context, and finally
E which represents the edges of the graph con-
necting word nodes and context nodes. The weight
on the edge is simply the number of occurrences
of a given word in a context. While construct-
ing the graph, we identify if a node represents a
noisy word (N) (called source node) or a normal-
ized word (M) (called absorbing node). The bi-
partite graph is constructed using the procedure in
Algorithm(4.1).
</bodyText>
<subsectionHeader confidence="0.990661">
4.2 Lexicon generation using Random Walks
</subsectionHeader>
<bodyText confidence="0.999960305555555">
Our proposed approach uses Markov Random
Walks on the bipartite graph in Figure(1) as de-
fined in (Norris, 1997). The main objective is to
identify pairs of noisy and normalized words that
can be considered as normalization equivalences.
In principal, this is similar to using random walks
for semi-supervised label propagation which has
been introduced in (Szummer and Jaakkola, 2002)
and then used in many other applications. For
example, (Hughes and Ramage, 2007) used ran-
dom walks on Wordnet graph to measure lexical
semantic relatedness between words. (Das and
Petrov, 2011) used graph-based label propagation
for cross-lingual knowledge transfers to induce
POS tags between two languages. (Minkov and
Cohen, 2012) introduced a path constrained graph
walk algorithm given a small number of labeled
examples to assess nodes relatedness in the graph.
In this paper, we apply the label propagation ap-
proach to the text normalization problem.
Consider a random walk on the bipartite graph
G(W, C, E) starting at a noisy word (source
node) and ending at a normalized word (absorb-
ing node). The walker starts from any source
node Ni belonging to the noisy words then move
to any other connected node Mj with probability
Pij. The transition between each pair of nodes
is defined by a transition probability Pij which
represents the normalized probability of the co-
occurrence counts of the word and the correspond-
ing context. Though the counts are symmetric, the
probability is not symmetric. This is due to the
probability normalization which is done according
to the nodes connectivity. Therefore, the transition
probability between any two nodes i, j is defined
as:
</bodyText>
<equation confidence="0.9616985">
∑Pij = Wij� Wik (1)
Vk
</equation>
<bodyText confidence="0.999856333333333">
For any non-connected pair of nodes, Pij =0. It
is worth noting that due to the bipartite graph rep-
resentation; any word node, either noisy (source)
or normalized (absorbing), is only connected to
context nodes and not directly connected to any
other word node.
</bodyText>
<figure confidence="0.996900095238095">
C3
C2
C4
C1
2
2
1 mking
4
4
2
3
5
1
1
1
1
making
makin
taking
takin
tkin
</figure>
<page confidence="0.933934">
1580
</page>
<bodyText confidence="0.9998276">
The algorithm repeats independent random
walks for K times where the walks traverse the
graph randomly according to the transition prob-
ability distribution in Eqn(1); each walk starts
from the source noisy node and ends at an absorb-
ing normalized node, or consumes the maximum
number of steps without hitting an absorbing node.
For any random walk the number of steps taken
to traverse between any two nodes is called the
hitting time (Norris, 1997). Therefore, the hit-
ting time between a noisy and a normalized pair
of nodes (n, m) with a walk r is h,(n, m). We
define the cost between the two nodes as the aver-
age hitting time H(n, m) of all walks that connect
those two nodes:
</bodyText>
<equation confidence="0.9828035">
H(n, m) = E hr(n, m)/R (2)
Vr
</equation>
<bodyText confidence="0.99970736">
Consider the bipartite graph in Figure(1), as-
sume a random walk starting at the source node
representing the noisy word ”tkin” then moves to
the context node C1 then to the absorbing node
representing the normalized word ”taking”. This
random walk will associate ”tkin” with ”taking”
with a walk of two steps (hits). Another random
walk that can connect the two words is [”tkin”
-+ C4 -+ ”takin” -+ C1 -+ ”taking”], which has
4 steps (hits). In this case, the cost of this pair
of nodes is the average number of hits connecting
them which is 3.
It is worth noting that the random walks are
selected according to the transition probability in
Eqn(1); therefore, the more probable paths will be
picked more frequently. The same pair of nodes
can be connected with many walks of various steps
(hits), and the same noisy word can be connected
to many other normalized words.
We define the contextual similarity probabil-
ity of a normalization equivalence pair n, m as
L(n, m). Which is the relative frequency of the
average hitting of those two nodes, H(n, m), and
all other normalized nodes linked to that noisy
word. Thus L(n, m), is calculated as:
</bodyText>
<equation confidence="0.981402">
L(n, m) = H(n, m)/ E H(n, mi) (3)
i
</equation>
<bodyText confidence="0.9999872">
Furthermore, we add another similarity cost be-
tween a noisy word and a normalized word based
on the lexical similarity cost, SimCost(n, m),
which we will describe in the next section. The
final cost associated with a pair is:
</bodyText>
<figure confidence="0.803847409090909">
Cost(n, m) = A1L(n, m) + A2SimCost(n, m) (4)
Algorithm 4.2: INDUCELEXICON(G)
output (Lexicon)
INIT((Lexicon))
for each n ∈ W ∈ G(W, C, E)
do
������������������ �
�
�������������������
{ INIT(Rn)
comment: for noisy nodes only
if ISNOISY(n)
comment: Calculate Lexical Sim Cost
Ln ← SIMCOST(Ln)
Ln ← PRUNE(Ln)
Lexicon ← ADD(Ln)
comment: do K random walks
for i ← 0 to K
comment: Calculate Avg. hits and normalize
Rn ← RANDOMWALK(n)
Ln ← NORMALIZE(Rn)
do
</figure>
<bodyText confidence="0.8877516">
We used uniform interpolation, both A1 and A2
equals 1. The final Lexicon is constructed using
those entries and if needed we prune the list to take
top N according to the cost above. The algorithm
is outlined in 4.2.
</bodyText>
<subsectionHeader confidence="0.999251">
4.3 Lexical Similarity Cost
</subsectionHeader>
<bodyText confidence="0.999943166666667">
We use a similarity function proposed in (Con-
tractor et al., 2010) which is based on Longest
Common Subsequence Ratio (LCSR) (Melamed,
1999). This cost function is defined as the ratio
of LCSR and Edit distance between two strings as
follows:
</bodyText>
<equation confidence="0.99911">
SimCost(n, m) = LCSR(n, m)/ED(n, m) (5)
LCSR(n, m) = LCS(n, m)/MaxLenght(n, m) (6)
</equation>
<bodyText confidence="0.999942888888889">
We have modified the Edit Distance calculation
ED(n,m) to be more adequate for social media text.
The edit distance is calculated between the conso-
nant skeleton of the two words; by removing all
vowels, we used Editex edit distance as proposed
in (Zobel and Philip, 1996), repetition is reduced
to a single letter before calculating the edit dis-
tance, and numbers in the middle of words are sub-
stituted by their equivalent letters.
</bodyText>
<sectionHeader confidence="0.999897" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.995938">
5.1 Training and Evaluation Data
</subsectionHeader>
<bodyText confidence="0.9977605">
We collected large amount of social media data to
generate the normalization lexicon using the ran-
</bodyText>
<page confidence="0.981639">
1581
</page>
<bodyText confidence="0.999806043478261">
dom walk approach. The data consists of 73 mil-
lion Twitter statuses. All tweets were collected
from March/April 2012 using the Twitter Stream-
ing APIs2. We augmented this data with 50 mil-
lion sentences of clean data from English LDC Gi-
gaword corpus 3. We combined both data, noisy
and clean, together to induce the normalization
dictionary from them. While the Gigaword clean
data was used to train the language model to score
the normalized lattice.
We constructed a test set of 1000 sentences of
social media which had been corrected by a na-
tive human annotator, the main guidelines were to
normalize noisy words to its corresponding clean
words in a consistent way according to the evi-
dences in the context. We will refer to this test
set as SM-Test. Furthermore, we developed a test
set for evaluating the effect of the normalization
system when used as a preprocessing step for Ma-
chine translation. The machine translation test set
is composed of 500 sentences of social media En-
glish text translated to normalized Spanish text by
a bi-lingual translator.
</bodyText>
<subsectionHeader confidence="0.9474795">
5.2 Evaluating Normalization Lexicon
Generation
</subsectionHeader>
<bodyText confidence="0.999782434782609">
We extracted 5-gram sequences from the com-
bined noisy and clean data; then we limited the
space of noisy 5-gram sequences to those which
contain only one noisy word as the center word
and all other words, representing the context, are
not noisy. As we mentioned before, we identify
whether the word is noisy or not by looking up
a vocabulary list constructed from clean data. In
these experiments, the vocabulary is constructed
from the Language Model data (50M sentences of
the English Gigaword corpus). Any word that ap-
pears less than 10 times in this vocabulary is con-
sidered noisy and candidate for normalization dur-
ing the lexicon induction process. It is worth not-
ing that our notion of noisy word does not mean it
is an OOV that has to be corrected; instead it in-
dicates that it is candidate for correction but may
be opted not to be normalized if there is no con-
fident normalization for it. This helps to maintain
the approach as a high precision text normaliza-
tion system which is highly preferable as an NLP
preprocessing step.
We constructed a lattice using normalization
</bodyText>
<footnote confidence="0.9955475">
2https://dev.twitter.com/docs/streaming-apis
3http://www.ldc.upenn.edu/Catalog/LDC2011T07
</footnote>
<bodyText confidence="0.999441161290323">
candidates and score the best Viterbi path with 5-
gram language model. We experimented with two
candidate generators as baseline systems, namely
the dictionary-based spelling correction and the
trie approximate match with K errors; where K=3.
For both candidate generators the cost function for
a given candidate is calculated using the lexical
similarity cost in Eqn(5). We compared those ap-
proaches with our newly proposed unsupervised
normalization lexicon induction; for this case the
cost for a candidate is the combined cost of the
contextual similarity probability and the lexical
similarity cost as defined in Eqn(4). We examine
the effect of data size and the steps of the random
walks on the accuracy and the coverage of the in-
duced dictionary.
We constructed the bipartite graph with the n-
gram sequences as described in Algorithm 4.1.
Then the Random Walks Algorithm in 4.2 is ap-
plied with 100 walks. The total number of word
nodes is about 7M nodes and the total number
of context nodes is about 480M nodes. We used
MapReduce framework to implement the pro-
posed technique to handle such large graph. We
experimented with the maximum number of ran-
dom walk steps of 2, 4 and 6; and with different
portions of the data as well. Finally, we pruned
the lexicon to keep the top 5 candidates per noisy
word.
Table(1) shows the resulting lexicons from dif-
ferent experiments.
</bodyText>
<table confidence="0.9997156">
Lexicon Lexicon Data Steps
Lex1 123K 20M 4
Lex2 281K 73 M 2
Lex3 327K 73M 4
Lex4 363K 73M 6
</table>
<tableCaption confidence="0.9239165">
Table 1: Generated Lexicons, steps are the Ran-
dom Walks maximum steps.
</tableCaption>
<bodyText confidence="0.9979373">
As shown in Table(1), we experimented with
different data sizes and steps of the random walks.
The more data we have the larger the lexicon we
get. Also larger steps increase the induced lexi-
con size. A random walk step size of 2 means that
the noisy/normalized pair shares the same context;
while a step size of 4 or more means that they may
not share the same context. Next, we will exam-
ine the effect of lexicon size on the normalization
task.
</bodyText>
<page confidence="0.986933">
1582
</page>
<subsectionHeader confidence="0.988548">
5.3 Text Normalization Evaluation
</subsectionHeader>
<bodyText confidence="0.99584625">
We experimented different candidate generators
and compared it to the unsupervised lexicon ap-
proach. Table(2) shows the precision and recall on
a the SM-Test set.
</bodyText>
<table confidence="0.998666571428571">
System Candidates Precision Recall F-Measure
Base1 Dict 33.9 15.1 20.98
Base2 Trie 26.64 27.65 27.13
RW1 Lex1 88.76 59.23 71.06
RW2 Lex2 90.66 54.06 67.73
RW3 Lex3 92.43 56.4 70.05
RW4 Lex4 90.87 60.73 72.8
</table>
<tableCaption confidence="0.9803795">
Table 2: Text Normalization with different lexi-
cons
</tableCaption>
<bodyText confidence="0.999964535714286">
In Table(2), the first baseline is using a dictio-
nary based spell checker; which gets low precision
and very low recall. Similarly the trie approximate
string match is doing a similar job with better re-
call though the precision is worst. Both of the
baseline approaches are inadequate for social me-
dia text since both will try to correct any word that
is similar to a word in the dictionary. The Trie ap-
proximate match is doing better job on the recall
since the approximate match is based on phonetic
and lexical similarities.
On the other hand, the induced normalization
lexicon approach is doing much better even with
a small amount of data as we can see with sys-
tem RW1 which uses Lex1 generated from 20M
sentences and has 123K lexicon entry. Increas-
ing the amount of training data does impact the
performance positively especially the recall. On
the other hand, increasing the number of steps has
a good impact on the recall as well; but with a
considerable impact on the precision. It is clear
that increasing the amount of data and keeping the
steps limit at ”‘4”’ gives better precision and cov-
erage as well. This is a preferred setting since the
main objective of this approach is to have better
precision to serve as a reliable preprocessing step
for Machine Translation and other NLP applica-
tions.
</bodyText>
<subsectionHeader confidence="0.999619">
5.4 Comparison with Pairwise Similarity
</subsectionHeader>
<bodyText confidence="0.993286222222222">
We present experimental results to compare our
proposed approach with (Han et al., 2012) which
used pairwise contextual similarity to induce a
normalization lexicon of 40K entries, we will refer
to this lexicon as HB-Dict. We compare the per-
formance of HB-Dict and our induced dictionary
(system RW3). We evaluate both system on SM-
Test test set and on (Han et al., 2012) test set of
548 sentences which we call here HB-Test.
</bodyText>
<table confidence="0.999749428571429">
System Precision Recall F-Measure
SM-Test
HB-Dict 71.90 26.30 38.51
RW3 92.43 56.4 70.05
HB-Test
HB-Dict 70.0 17.9 26.3
RW3 85.37 56.4 69.93
</table>
<tableCaption confidence="0.999039">
Table 3: Text Normalization Results
</tableCaption>
<bodyText confidence="0.99996556">
As shown in Table(3), RW3 system signifi-
cantly outperforms HB-Dict system with the lex-
icon from (Han et al., 2012) on both test sets for
both precision and recall. The contextual graph
random walks approach helps in providing high
precision lexicon since the sampling nature of the
approach helps in filtering out unreliable normal-
ization equivalences. The random walks will tra-
verse more frequent paths; which would lead to
more probable normalization equivalence. On the
other hand, the proposed approach provides high
recall as well which is hard to achieve with higher
precision. Since the proposed approach deploys
random walks to sample paths that can traverse
many steps, this relaxes the constraints that the
normalization equivalences have to share the same
context. Instead a noisy word may share a con-
text with another noisy word which in turn shares
a context with a clean equivalent normalization
word. Therefore, we end up with a lexicon that
have much higher recall than the pairwise simi-
larity approach since it explores equivalences be-
yond the pairwise relation. Moreover, the random
walk sampling emphasis the more frequent paths
and hence provides high precision lexicon.
</bodyText>
<subsectionHeader confidence="0.995238">
5.5 Output Analysis
</subsectionHeader>
<bodyText confidence="0.999925285714286">
Table(4) shows some examples of the induced nor-
malization equivalences, the first part shows good
examples where vowels are restored and phonetic
similar words are matched. Remarkably the cor-
rection ”‘viewablity”’ to ”‘visibility”’ is interest-
ing since the system picked the more frequent
form. Moreover, the lexicon contains some entries
with foreign language words normalized to its En-
glish translation. On the other hand, the lexicon
has some bad normalization such as ”‘unrecycled
”’ which should be normalized to ”‘non recycled”’
but since the system is limited to one word cor-
rection it did not get it. Another interesting bad
normalization is ”‘tutting”’ which is new type of
</bodyText>
<page confidence="0.982254">
1583
</page>
<note confidence="0.428956">
5.6 Machine Translation Task Evaluation
</note>
<bodyText confidence="0.997771705882353">
The final evaluation of the text normalization sys-
tem is an extrinsic evaluation where we evaluate
the effect of the text normalization task on a so-
cial media text translating from English to Span-
ish using a large scale translation system trained
on general domain data. The system is trained
on English-Spanish parallel data from WMT 2012
evaluation 4. The data consists of about 5M paral-
lel sentences on news, europal and UN data. The
system is a state of the art phrase based system
similar to Moses (Hoang et al., 2007). We used
The BLEU score (Papineni et al., 2002) to evaluate
the translation accuracy with and without the nor-
malization. Table(6) shows the translation evalua-
tion with different systems. The translation with
normalization was improved by about 6% from
29.02 to 30.87 using RW3 as a preprocessing step.
</bodyText>
<table confidence="0.997232">
System BLEU Impreovemnet
No Normalization 29.02 0%
Baseline1 29.13 0.37%
HB-Dict 29.76 3.69%
RW3 30.87 6.37%
</table>
<tableCaption confidence="0.975359">
Table 6: Translation Results
</tableCaption>
<sectionHeader confidence="0.783343" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999020909090909">
We introduced a social media text normalization
system that can be deployed as a preprocessor
for MT and various NLP applications to han-
dle social media text. The proposed approach is
very scalable, adaptive to any domain and lan-
guage. We show that the proposed unsupervised
approach provides a normalization system with
very high precision and a reasonable recall. We
compared the system with conventional correction
approaches and with recent previous work; and we
showed that it highly outperforms other systems.
Finally, we have used the system as a preprocess-
ing step for a machine translation system which
improved the translation quality by 6%.
As an extension to this work, we will extend the
approach to handle many-to-many normalization
pairs; also we plan to apply the approach to more
languages. Furthermore, the approach can be eas-
ily extended to handle similar problems such as ac-
cent restoration and generic entity normalization.
dancing and should not be corrected to ”‘tweet-
ing”’.
</bodyText>
<table confidence="0.997825714285714">
Noisy Clean Remarks
tnght tonight Vowels restored
darlin darling g restored
urung orange phonetic similarity
viewablity visibility good correction
unrecycled recycled negation ignored
tutting tweeting tutting is dancing type
</table>
<tableCaption confidence="0.999011">
Table 4: Lexicon Samples
</tableCaption>
<bodyText confidence="0.996719518518518">
Table 5 lists a number of examples and their
normalization using both Baseline1 and RW3. At
the first example, RW3 got the correct normaliza-
tion as ”interesting” which apparently is not the
one with the shortest edit distance, though it is
the most frequent candidate at the generated lex-
icon. The baseline system did not get it right; it
got a wrong normalization with shorter edit dis-
tance. Example(2) shows the same effect by get-
ting ”cuz” normalized to ”because”. At Exam-
ple(3), both the baseline and RW3 did not get
the correct normalization of ”yur” to ”you are”
which is currently a limitation in our system since
we only allow one-to-one word mapping in the
generated lexicons not one-to-many or many-to-
many. At Example(4), RW3 did not normalize
”dure” to ”sure” ; however the baseline normal-
ized it by mistake to ”dare”. This shows a char-
acteristic of the proposed approach; it is very con-
servative in proposing normalization which is de-
sirable as a preprocessing step for NLP applica-
tions. This limitation can be marginalized by pro-
viding more data for generating the lexicon. Fi-
nally, Example 4 shows also that the system nor-
malize ”gr8” which is mainly due to having a flex-
ible similarity cost during the normalization lexi-
con construction.
</bodyText>
<table confidence="0.81525125">
1. Source: Mad abt dt so mch intesting
Baseline1: Mad at do so much ingesting
RW3: Mad about that so much interesting
2. Source: i’l do cuz ma parnts r ma lyf
Baseline1: I’ll do cut ma parents r ma life
RW3: I’ll do because my parents are my life
3. Source: yur cuuuuute
Baseline1: yur cuuuuute
RW3: your cute
4. Source: I’m dure u will get a gr8 score
Baseline1: I’m dare you will get a gr8 score
RW3: I’m dure you will get a great score
</table>
<tableCaption confidence="0.997252">
Table 5: Normalization Examples
</tableCaption>
<footnote confidence="0.876928">
4http://www.statmt.or/wmt12
</footnote>
<page confidence="0.99424">
1584
</page>
<sectionHeader confidence="0.99831" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998984">
We would like to thank Lee Schwartz and Will
Lewis for their help in constructing the test sets
and in the error analysis. We would also like to
thank the anonymous reviewers for their helpful
and constructive comments.
</bodyText>
<sectionHeader confidence="0.999171" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9998872">
AiTi Aw, Min Zhang, Juan Xiao, and Jian Su. 2006.
A phrase-based statistical model for SMS text nor-
malization. In Proceedings of the 21st International
Conference on Computational Linguistics and 44th
Annual Meeting of the Association for Computa-
tional Linguistics, pages 3340, Sydney, Australia.
Eric Brill and Robert C. Moore. 2000. An improved er-
ror model for noisy channel spelling correction, In
ACL 2000: Proceedings of the 38th Annual Meeting
on Association for Computational Linguistics, En-
glewood Cliffs, NJ, USA.
Ye-In Chang and Jiun-Rung Chen and Min-Tze Hsu
2010. A hash trie filter method for approximate
string matching in genomic databases Applied In-
telligence, 33:1, pages 21:38, Springer US.
Monojit Choudhury, Rahul Saraf, Vijit Jain, Animesh
Mukherjee, Sudeshna Sarkar, and Anupam Basu
2007. Investigation and modeling of the structure of
texting language. International Journal of Document
Analysis and Recognition, vol. 10, pp. 157:174.
Danish Contractor and Tanveer Faruquie and Venkata
Subramaniam 2010. Unsupervised cleansing of
noisy text. In COLING ’10 Proceedings of the 23rd
International Conference on Computational Linguis-
tics, pages 189:196.
Paul Cook and Suzanne Stevenson. 2009. An unsu-
pervised model for text message normalization.. In
CALC 09: Proceedings of the Workshop on Compu-
tational Approaches to Linguistic Creativity, pages
71:78, Boulder, USA.
Dipanjan Das and Slav Petrov 2011 Unsuper-
vised part-of-speech tagging with bilingual graph-
based projections Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, pages
600:609, Portland, Oregon
Stephan Gouws, Dirk Hovy, and Donald Metzler.
2011. Unsupervised mining of lexical variants from
noisy text. In Proceedings of the First workshop on
Unsupervised Learning in NLP, pages 82:90, Edin-
burgh, Scotland.
Bo Han and Timothy Baldwin. 2011. Lexical normal-
isation of short text messages: Makn sens a twit-
ter. In Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics:
Human Language Technologies (ACL-HLT 2011),
pages 368:378, Portland, Oregon, USA.
Bo Han and Paul Cook and Timothy Baldwin 2012.
Automatically Constructing a Normalisation Dic-
tionary for Microblogs. Proceedings of the 2012
Joint Conference on Empirical Methods in Natu-
ral Language Processing and Computational Natural
Language Learning (EMNLP-CoNLL 2012), pages
421:432, Jeju Island, Korea.
Hieu Hoang and Alexandra Birch and Chris Callison-
burch and Richard Zens and Rwth Aachen and
Alexandra Constantin and Marcello Federico and
Nicola Bertoldi and Chris Dyer and Brooke Cowan
and Wade Shen and Christine Moran and Ondrej Bo-
jar 2007. Moses: Open source toolkit for statistical
machine translation.
Thad Hughes and Daniel Ramage 2007. Lexical se-
mantic relatedness with random graph walks Pro-
ceedings of Conference on Empirical Methods in
Natural Language Processing EMNLP, pp. 581589,
Prague
Fei Liu and Fuliang Weng and Bingqing Wang and
Yang Liu 2011. Insertion, Deletion, or Substi-
tution? Normalizing Text Messages without Pre-
categorization nor Supervision Proceedings of the
49th Annual Meeting of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, pages 19:24, Portland, Oregon
Dan Melamed 1999. Bitext Maps and Alignment via
Pattern Recognition. In Computational Linguistics,
25, pages 107:130.
Einat Minkov and William Cohen Graph Based
Similarity Measures for Synonym Extraction from
Parsed Text In Proceedings of the TextGraphs work-
shop 2012
J. Norris 1997. Markov Chains. Cambridge Univer-
sity Press.
Kishore Papineni and Salim Roukos and Todd Ward
and Wei-jing Zhu 2002. BLEU: a Method for Au-
tomatic Evaluation of Machine Translation. in Pro-
ceedings of ACL-2002: 40th Annual meeting of the
Association for Computational Linguistics. , pages
311:318.
Richard Sproat, Alan W. Black, Stanley Chen, Shankar
Kumar, Mari Ostendorf, and Christopher Richards.
Normalization of non-standard words. 2001.
Xu Sun and Jianfeng Gao and Daniel Micol and Chris
Quirk 2010. Learning Phrase-Based Spelling Error
Models from Clickthrough Data. Proceedings of the
48th Annual Meeting of the Association for Compu-
tational Linguistics, pages 266:274, Sweeden.
Martin Szummer and Tommi 2002. Partially labeled
classification with markov random walks. In Ad-
vances in Neural Information Processing Systems,
pages 945:952.
</reference>
<page confidence="0.80419">
1585
</page>
<reference confidence="0.998875181818182">
Kristina Toutanova and Robert C. Moore. Pronunci-
ation modeling for improved spelling correction..
2002. In Proceedings of the 40th Annual Meeting
on Association for Computational Linguistics, ACL
, pages 144151, Philadelphia, USA.
Justin Zobel and Philip Dart 1996. Phonetic string
matching: Lessons from information retrieval. in
Proceedings of the Eighteenth ACM SIGIR Inter-
national Conference on Research and Development
in Information Retrieval, pages 166:173, Zurich,
Switzerland.
</reference>
<page confidence="0.99291">
1586
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.638656">
<title confidence="0.997891">Social Text Normalization using Contextual Graph Random Walks</title>
<author confidence="0.799974">Hany Hassan Arul Menezes</author>
<affiliation confidence="0.997683">Microsoft Research Microsoft Research</affiliation>
<address confidence="0.989558">Redmond, WA Redmond, WA</address>
<email confidence="0.998756">hanyh@microsoft.comarulm@microsoft.com</email>
<abstract confidence="0.991089863636364">We introduce a social media text normalization system that can be deployed as a preprocessing step for Machine Translation and various NLP applications to handle social media text. The proposed system is based on unsupervised learning of the normalization equivalences from unlabeled text. The proposed approach uses Random Walks on a contextual similarity bipartite graph constructed from n-gram sequences on large unlabeled text corpus. We show that the proposed approach has a very high precision of (92.43) and a reasonable recall of (56.4). When used as a preprocessing step for a state-of-the-art machine translation system, the translation quality on social media text improved by 6%. The proposed approach is domain and language independent and can be deployed as a preprocessing step for any NLP application to handle social media text.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>AiTi Aw</author>
<author>Min Zhang</author>
<author>Juan Xiao</author>
<author>Jian Su</author>
</authors>
<title>A phrase-based statistical model for SMS text normalization.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>3340</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="6346" citStr="Aw et al., 2006" startWordPosition="976" endWordPosition="979">viously proposed models. (Toutanova and Moore, 2002) improved the string to string edits model by modeling pronunciation similarities between words. (Choudhury et al., 2007) introduced a supervised HMM channel model for text normalization which has been expanded by (Cook and Stevenson, 2009) to introduce unsupervised noisy channel model using probabilistic models for common abbreviation and various spelling errors types. Some researchers used Statistical Machine Translation approach for text normalization; formalizing the problem as a translation from the noisy forms to the normalized forms. (Aw et al., 2006) proposed an approach for normalizing Short Messaging Service (SMS) texts by translating it into normalized forms using Phrase-based SMT techniques on character level. The main drawback of these approaches is that the noisy channel model cannot accurately represent the errors types without contextual information. More recent approaches tried to handle the text normalization problem using normalization lexicons which map the noisy form of the word to a normalized form. For example, (Han et al., 2011) proposed an approach using a classifier to identify the noisy words candidate for normalization</context>
</contexts>
<marker>Aw, Zhang, Xiao, Su, 2006</marker>
<rawString>AiTi Aw, Min Zhang, Juan Xiao, and Jian Su. 2006. A phrase-based statistical model for SMS text normalization. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 3340, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>Robert C Moore</author>
</authors>
<title>An improved error model for noisy channel spelling correction,</title>
<date>2000</date>
<booktitle>In ACL 2000: Proceedings of the 38th Annual Meeting on Association for Computational Linguistics,</booktitle>
<location>Englewood Cliffs, NJ, USA.</location>
<contexts>
<context position="5540" citStr="Brill and Moore, 2000" startWordPosition="856" endWordPosition="859"> normalization task as well as machine translation task. The rest of this paper is organized as follows: Section(2) discusses the related work, Section(3) introduces the text normalization system and the baseline candidate generators, Section(4) introduces the proposed graph-based lexicon induction approach, Section(5) discusses the experiments and output analysis, and finally Section(6) concludes and discusses future work. 2 Related Work Early work handled the text normalization problem as a noisy channel model where the normalized words go through a noisy channel to produce the noisy text. (Brill and Moore, 2000) introduced an approach for modeling the spelling errors as a noisy channel model based on string to string edits. Using this model gives significant performance improvements compared to previously proposed models. (Toutanova and Moore, 2002) improved the string to string edits model by modeling pronunciation similarities between words. (Choudhury et al., 2007) introduced a supervised HMM channel model for text normalization which has been expanded by (Cook and Stevenson, 2009) to introduce unsupervised noisy channel model using probabilistic models for common abbreviation and various spelling</context>
</contexts>
<marker>Brill, Moore, 2000</marker>
<rawString>Eric Brill and Robert C. Moore. 2000. An improved error model for noisy channel spelling correction, In ACL 2000: Proceedings of the 38th Annual Meeting on Association for Computational Linguistics, Englewood Cliffs, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ye-In Chang</author>
<author>Jiun-Rung Chen</author>
<author>Min-Tze Hsu</author>
</authors>
<title>A hash trie filter method for approximate string matching in genomic databases</title>
<date>2010</date>
<journal>Applied Intelligence,</journal>
<volume>33</volume>
<pages>21--38</pages>
<publisher>Springer US.</publisher>
<contexts>
<context position="11147" citStr="Chang et al., 2010" startWordPosition="1723" endWordPosition="1726">a to identify OOV words. 3.1 Baseline Normalization Candidates Generation We experimented with two normalization candidate generators as baseline systems. The first is a dictionary based spelling correction similar to Aspell1. In this experiment we used the spell checker lhttp://aspell.net/ to generate all possible candidates for OOV words and then applied the Viterbi decoder on the constructed lattice to score the best correction candidates using a language model. Our second candidates generator is based on a trie approximate string matching with K errors similar to the approach proposed in (Chang et al., 2010), where K errors can be caused by substitution, insertion, or deletion operations. In our implementation, we customized the errors operations to accommodate the nature of the social media text. Such as lengthening, letter substitution, letter-number substitution and phonetic substitution. This approach overcomes the main problem of the dictionary-based approach which is providing inappropriate normalization candidates to the errors styles in the social media text. As we will show in the experiments in Section(5), dictionary-based normalization methods proved to be inadequate for social media d</context>
</contexts>
<marker>Chang, Chen, Hsu, 2010</marker>
<rawString>Ye-In Chang and Jiun-Rung Chen and Min-Tze Hsu 2010. A hash trie filter method for approximate string matching in genomic databases Applied Intelligence, 33:1, pages 21:38, Springer US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Monojit Choudhury</author>
<author>Rahul Saraf</author>
<author>Vijit Jain</author>
<author>Animesh Mukherjee</author>
<author>Sudeshna Sarkar</author>
<author>Anupam Basu</author>
</authors>
<title>Investigation and modeling of the structure of texting language.</title>
<date>2007</date>
<journal>International Journal of Document Analysis and Recognition,</journal>
<volume>10</volume>
<pages>157--174</pages>
<contexts>
<context position="5903" citStr="Choudhury et al., 2007" startWordPosition="912" endWordPosition="915">ysis, and finally Section(6) concludes and discusses future work. 2 Related Work Early work handled the text normalization problem as a noisy channel model where the normalized words go through a noisy channel to produce the noisy text. (Brill and Moore, 2000) introduced an approach for modeling the spelling errors as a noisy channel model based on string to string edits. Using this model gives significant performance improvements compared to previously proposed models. (Toutanova and Moore, 2002) improved the string to string edits model by modeling pronunciation similarities between words. (Choudhury et al., 2007) introduced a supervised HMM channel model for text normalization which has been expanded by (Cook and Stevenson, 2009) to introduce unsupervised noisy channel model using probabilistic models for common abbreviation and various spelling errors types. Some researchers used Statistical Machine Translation approach for text normalization; formalizing the problem as a translation from the noisy forms to the normalized forms. (Aw et al., 2006) proposed an approach for normalizing Short Messaging Service (SMS) texts by translating it into normalized forms using Phrase-based SMT techniques on charac</context>
</contexts>
<marker>Choudhury, Saraf, Jain, Mukherjee, Sarkar, Basu, 2007</marker>
<rawString>Monojit Choudhury, Rahul Saraf, Vijit Jain, Animesh Mukherjee, Sudeshna Sarkar, and Anupam Basu 2007. Investigation and modeling of the structure of texting language. International Journal of Document Analysis and Recognition, vol. 10, pp. 157:174.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Danish Contractor</author>
</authors>
<title>Tanveer Faruquie and Venkata Subramaniam 2010. Unsupervised cleansing of noisy text.</title>
<booktitle>In COLING ’10 Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>189--196</pages>
<marker>Contractor, </marker>
<rawString>Danish Contractor and Tanveer Faruquie and Venkata Subramaniam 2010. Unsupervised cleansing of noisy text. In COLING ’10 Proceedings of the 23rd International Conference on Computational Linguistics, pages 189:196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Cook</author>
<author>Suzanne Stevenson</author>
</authors>
<title>An unsupervised model for text message normalization..</title>
<date>2009</date>
<booktitle>In CALC 09: Proceedings of the Workshop on Computational Approaches to Linguistic Creativity,</booktitle>
<pages>71--78</pages>
<location>Boulder, USA.</location>
<contexts>
<context position="6022" citStr="Cook and Stevenson, 2009" startWordPosition="930" endWordPosition="933">ation problem as a noisy channel model where the normalized words go through a noisy channel to produce the noisy text. (Brill and Moore, 2000) introduced an approach for modeling the spelling errors as a noisy channel model based on string to string edits. Using this model gives significant performance improvements compared to previously proposed models. (Toutanova and Moore, 2002) improved the string to string edits model by modeling pronunciation similarities between words. (Choudhury et al., 2007) introduced a supervised HMM channel model for text normalization which has been expanded by (Cook and Stevenson, 2009) to introduce unsupervised noisy channel model using probabilistic models for common abbreviation and various spelling errors types. Some researchers used Statistical Machine Translation approach for text normalization; formalizing the problem as a translation from the noisy forms to the normalized forms. (Aw et al., 2006) proposed an approach for normalizing Short Messaging Service (SMS) texts by translating it into normalized forms using Phrase-based SMT techniques on character level. The main drawback of these approaches is that the noisy channel model cannot accurately represent the errors</context>
</contexts>
<marker>Cook, Stevenson, 2009</marker>
<rawString>Paul Cook and Suzanne Stevenson. 2009. An unsupervised model for text message normalization.. In CALC 09: Proceedings of the Workshop on Computational Approaches to Linguistic Creativity, pages 71:78, Boulder, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
</authors>
<title>Unsupervised part-of-speech tagging with bilingual graphbased projections</title>
<date>2011</date>
<booktitle>Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>600--609</pages>
<location>Portland, Oregon</location>
<contexts>
<context position="15326" citStr="Das and Petrov, 2011" startWordPosition="2390" endWordPosition="2393"> 4.2 Lexicon generation using Random Walks Our proposed approach uses Markov Random Walks on the bipartite graph in Figure(1) as defined in (Norris, 1997). The main objective is to identify pairs of noisy and normalized words that can be considered as normalization equivalences. In principal, this is similar to using random walks for semi-supervised label propagation which has been introduced in (Szummer and Jaakkola, 2002) and then used in many other applications. For example, (Hughes and Ramage, 2007) used random walks on Wordnet graph to measure lexical semantic relatedness between words. (Das and Petrov, 2011) used graph-based label propagation for cross-lingual knowledge transfers to induce POS tags between two languages. (Minkov and Cohen, 2012) introduced a path constrained graph walk algorithm given a small number of labeled examples to assess nodes relatedness in the graph. In this paper, we apply the label propagation approach to the text normalization problem. Consider a random walk on the bipartite graph G(W, C, E) starting at a noisy word (source node) and ending at a normalized word (absorbing node). The walker starts from any source node Ni belonging to the noisy words then move to any o</context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>Dipanjan Das and Slav Petrov 2011 Unsupervised part-of-speech tagging with bilingual graphbased projections Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 600:609, Portland, Oregon</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Gouws</author>
<author>Dirk Hovy</author>
<author>Donald Metzler</author>
</authors>
<title>Unsupervised mining of lexical variants from noisy text.</title>
<date>2011</date>
<booktitle>In Proceedings of the First workshop on Unsupervised Learning in NLP,</booktitle>
<pages>82--90</pages>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="7054" citStr="Gouws et al., 2011" startWordPosition="1087" endWordPosition="1090">it into normalized forms using Phrase-based SMT techniques on character level. The main drawback of these approaches is that the noisy channel model cannot accurately represent the errors types without contextual information. More recent approaches tried to handle the text normalization problem using normalization lexicons which map the noisy form of the word to a normalized form. For example, (Han et al., 2011) proposed an approach using a classifier to identify the noisy words candidate for normalization; then using some rules to generate lexical variants and a small normalization lexicon. (Gouws et al., 2011) proposed an approach using an impoverished normalization lexicon based on string and distributional similarity along with a dictionary lookup approach to detect noisy words. More recently, (Han et al., 2012) introduced a similar approach by generating a normalization lexicon based on distributional similarity and string similarity. This approach uses pairwise similarity where any two words that share the same context are considered as normalization equivalences. The pairwise approach has a number of limitations. First, it does not take into account the relative frequencies of the normalizatio</context>
</contexts>
<marker>Gouws, Hovy, Metzler, 2011</marker>
<rawString>Stephan Gouws, Dirk Hovy, and Donald Metzler. 2011. Unsupervised mining of lexical variants from noisy text. In Proceedings of the First workshop on Unsupervised Learning in NLP, pages 82:90, Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Timothy Baldwin</author>
</authors>
<title>Lexical normalisation of short text messages: Makn sens a twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:</booktitle>
<marker>Han, Baldwin, 2011</marker>
<rawString>Bo Han and Timothy Baldwin. 2011. Lexical normalisation of short text messages: Makn sens a twitter. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:</rawString>
</citation>
<citation valid="true">
<title>Human Language Technologies (ACL-HLT</title>
<date>2011</date>
<pages>368--378</pages>
<location>Portland, Oregon, USA.</location>
<marker>2011</marker>
<rawString>Human Language Technologies (ACL-HLT 2011), pages 368:378, Portland, Oregon, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Paul Cook</author>
<author>Timothy Baldwin</author>
</authors>
<title>Automatically Constructing a Normalisation Dictionary for Microblogs.</title>
<date>2012</date>
<booktitle>Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2012),</booktitle>
<pages>421--432</pages>
<location>Jeju Island,</location>
<contexts>
<context position="7262" citStr="Han et al., 2012" startWordPosition="1119" endWordPosition="1122">al information. More recent approaches tried to handle the text normalization problem using normalization lexicons which map the noisy form of the word to a normalized form. For example, (Han et al., 2011) proposed an approach using a classifier to identify the noisy words candidate for normalization; then using some rules to generate lexical variants and a small normalization lexicon. (Gouws et al., 2011) proposed an approach using an impoverished normalization lexicon based on string and distributional similarity along with a dictionary lookup approach to detect noisy words. More recently, (Han et al., 2012) introduced a similar approach by generating a normalization lexicon based on distributional similarity and string similarity. This approach uses pairwise similarity where any two words that share the same context are considered as normalization equivalences. The pairwise approach has a number of limitations. First, it does not take into account the relative frequencies of the normalization equivalences that might share different contexts. Therefore, the selection of the normalization equivalences is performed on pairwise basis only and is not optimized over the whole data. Secondly, the norma</context>
<context position="8523" citStr="Han et al., 2012" startWordPosition="1311" endWordPosition="1314">ct same context to be considered as a normalization candidate. These limitations affect the accuracy and the coverage of the produced lexicon. Our approach also adopts a lexicon based approach for text normalization, we construct a lattice from possible normalization candidates and find the best normalization sequence according to an n-gram language model using a Viterbi decoder. The normalization lexicon is acquired from unlabeled data using random walks on a contextual similarity graph constructed form n-gram sequences on large unlabeled text corpus. Our approach has some similarities with (Han et al., 2012) since both approaches utilize a normaliza1578 tion lexicon acquired form unlabeled data using distributional and string similarities. However, our approach is significantly different since we acquire the lexicon using random walks on a contextual similarity graph which has a number of advantages over the pairwise similarity approach used in (Han et al., 2012). Namely, the acquired normalization equivalence are optimized globally over the whole data, the rare equivalences are not considered as good candidates unless there is a strong statistical evidence across the data, and finally the normal</context>
<context position="26668" citStr="Han et al., 2012" startWordPosition="4338" endWordPosition="4341">vely especially the recall. On the other hand, increasing the number of steps has a good impact on the recall as well; but with a considerable impact on the precision. It is clear that increasing the amount of data and keeping the steps limit at ”‘4”’ gives better precision and coverage as well. This is a preferred setting since the main objective of this approach is to have better precision to serve as a reliable preprocessing step for Machine Translation and other NLP applications. 5.4 Comparison with Pairwise Similarity We present experimental results to compare our proposed approach with (Han et al., 2012) which used pairwise contextual similarity to induce a normalization lexicon of 40K entries, we will refer to this lexicon as HB-Dict. We compare the performance of HB-Dict and our induced dictionary (system RW3). We evaluate both system on SMTest test set and on (Han et al., 2012) test set of 548 sentences which we call here HB-Test. System Precision Recall F-Measure SM-Test HB-Dict 71.90 26.30 38.51 RW3 92.43 56.4 70.05 HB-Test HB-Dict 70.0 17.9 26.3 RW3 85.37 56.4 69.93 Table 3: Text Normalization Results As shown in Table(3), RW3 system significantly outperforms HB-Dict system with the lex</context>
</contexts>
<marker>Han, Cook, Baldwin, 2012</marker>
<rawString>Bo Han and Paul Cook and Timothy Baldwin 2012. Automatically Constructing a Normalisation Dictionary for Microblogs. Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2012), pages 421:432, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callisonburch</author>
<author>Richard Zens</author>
<author>Rwth Aachen</author>
<author>Alexandra Constantin</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Chris Dyer</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Ondrej Bojar</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<contexts>
<context position="29644" citStr="Hoang et al., 2007" startWordPosition="4823" endWordPosition="4826"> normalization is ”‘tutting”’ which is new type of 1583 5.6 Machine Translation Task Evaluation The final evaluation of the text normalization system is an extrinsic evaluation where we evaluate the effect of the text normalization task on a social media text translating from English to Spanish using a large scale translation system trained on general domain data. The system is trained on English-Spanish parallel data from WMT 2012 evaluation 4. The data consists of about 5M parallel sentences on news, europal and UN data. The system is a state of the art phrase based system similar to Moses (Hoang et al., 2007). We used The BLEU score (Papineni et al., 2002) to evaluate the translation accuracy with and without the normalization. Table(6) shows the translation evaluation with different systems. The translation with normalization was improved by about 6% from 29.02 to 30.87 using RW3 as a preprocessing step. System BLEU Impreovemnet No Normalization 29.02 0% Baseline1 29.13 0.37% HB-Dict 29.76 3.69% RW3 30.87 6.37% Table 6: Translation Results 6 Conclusion and Future Work We introduced a social media text normalization system that can be deployed as a preprocessor for MT and various NLP applications </context>
</contexts>
<marker>Hoang, Birch, Callisonburch, Zens, Aachen, Constantin, Federico, Bertoldi, Dyer, Cowan, Shen, Moran, Bojar, 2007</marker>
<rawString>Hieu Hoang and Alexandra Birch and Chris Callisonburch and Richard Zens and Rwth Aachen and Alexandra Constantin and Marcello Federico and Nicola Bertoldi and Chris Dyer and Brooke Cowan and Wade Shen and Christine Moran and Ondrej Bojar 2007. Moses: Open source toolkit for statistical machine translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thad Hughes</author>
<author>Daniel Ramage</author>
</authors>
<title>Lexical semantic relatedness with random graph walks</title>
<date>2007</date>
<booktitle>Proceedings of Conference on Empirical Methods in Natural Language Processing EMNLP,</booktitle>
<pages>581589</pages>
<location>Prague</location>
<contexts>
<context position="15213" citStr="Hughes and Ramage, 2007" startWordPosition="2372" endWordPosition="2375">rmalized word (M) (called absorbing node). The bipartite graph is constructed using the procedure in Algorithm(4.1). 4.2 Lexicon generation using Random Walks Our proposed approach uses Markov Random Walks on the bipartite graph in Figure(1) as defined in (Norris, 1997). The main objective is to identify pairs of noisy and normalized words that can be considered as normalization equivalences. In principal, this is similar to using random walks for semi-supervised label propagation which has been introduced in (Szummer and Jaakkola, 2002) and then used in many other applications. For example, (Hughes and Ramage, 2007) used random walks on Wordnet graph to measure lexical semantic relatedness between words. (Das and Petrov, 2011) used graph-based label propagation for cross-lingual knowledge transfers to induce POS tags between two languages. (Minkov and Cohen, 2012) introduced a path constrained graph walk algorithm given a small number of labeled examples to assess nodes relatedness in the graph. In this paper, we apply the label propagation approach to the text normalization problem. Consider a random walk on the bipartite graph G(W, C, E) starting at a noisy word (source node) and ending at a normalized</context>
</contexts>
<marker>Hughes, Ramage, 2007</marker>
<rawString>Thad Hughes and Daniel Ramage 2007. Lexical semantic relatedness with random graph walks Proceedings of Conference on Empirical Methods in Natural Language Processing EMNLP, pp. 581589, Prague</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Liu</author>
<author>Fuliang Weng</author>
<author>Bingqing Wang</author>
<author>Yang Liu</author>
</authors>
<title>Insertion, Deletion, or Substitution? Normalizing Text Messages without Precategorization nor Supervision</title>
<date>2011</date>
<booktitle>Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>pages</pages>
<location>Portland, Oregon</location>
<marker>Liu, Weng, Wang, Liu, 2011</marker>
<rawString>Fei Liu and Fuliang Weng and Bingqing Wang and Yang Liu 2011. Insertion, Deletion, or Substitution? Normalizing Text Messages without Precategorization nor Supervision Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 19:24, Portland, Oregon</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Melamed</author>
</authors>
<title>Bitext Maps and Alignment via Pattern Recognition.</title>
<date>1999</date>
<journal>In Computational Linguistics,</journal>
<volume>25</volume>
<pages>107--130</pages>
<contexts>
<context position="19731" citStr="Melamed, 1999" startWordPosition="3164" endWordPosition="3165">y if ISNOISY(n) comment: Calculate Lexical Sim Cost Ln ← SIMCOST(Ln) Ln ← PRUNE(Ln) Lexicon ← ADD(Ln) comment: do K random walks for i ← 0 to K comment: Calculate Avg. hits and normalize Rn ← RANDOMWALK(n) Ln ← NORMALIZE(Rn) do We used uniform interpolation, both A1 and A2 equals 1. The final Lexicon is constructed using those entries and if needed we prune the list to take top N according to the cost above. The algorithm is outlined in 4.2. 4.3 Lexical Similarity Cost We use a similarity function proposed in (Contractor et al., 2010) which is based on Longest Common Subsequence Ratio (LCSR) (Melamed, 1999). This cost function is defined as the ratio of LCSR and Edit distance between two strings as follows: SimCost(n, m) = LCSR(n, m)/ED(n, m) (5) LCSR(n, m) = LCS(n, m)/MaxLenght(n, m) (6) We have modified the Edit Distance calculation ED(n,m) to be more adequate for social media text. The edit distance is calculated between the consonant skeleton of the two words; by removing all vowels, we used Editex edit distance as proposed in (Zobel and Philip, 1996), repetition is reduced to a single letter before calculating the edit distance, and numbers in the middle of words are substituted by their eq</context>
</contexts>
<marker>Melamed, 1999</marker>
<rawString>Dan Melamed 1999. Bitext Maps and Alignment via Pattern Recognition. In Computational Linguistics, 25, pages 107:130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Einat Minkov</author>
<author>William Cohen</author>
</authors>
<title>Graph Based Similarity Measures for Synonym Extraction from Parsed Text</title>
<date>2012</date>
<booktitle>In Proceedings of the TextGraphs workshop</booktitle>
<contexts>
<context position="15466" citStr="Minkov and Cohen, 2012" startWordPosition="2409" endWordPosition="2412">n (Norris, 1997). The main objective is to identify pairs of noisy and normalized words that can be considered as normalization equivalences. In principal, this is similar to using random walks for semi-supervised label propagation which has been introduced in (Szummer and Jaakkola, 2002) and then used in many other applications. For example, (Hughes and Ramage, 2007) used random walks on Wordnet graph to measure lexical semantic relatedness between words. (Das and Petrov, 2011) used graph-based label propagation for cross-lingual knowledge transfers to induce POS tags between two languages. (Minkov and Cohen, 2012) introduced a path constrained graph walk algorithm given a small number of labeled examples to assess nodes relatedness in the graph. In this paper, we apply the label propagation approach to the text normalization problem. Consider a random walk on the bipartite graph G(W, C, E) starting at a noisy word (source node) and ending at a normalized word (absorbing node). The walker starts from any source node Ni belonging to the noisy words then move to any other connected node Mj with probability Pij. The transition between each pair of nodes is defined by a transition probability Pij which repr</context>
</contexts>
<marker>Minkov, Cohen, 2012</marker>
<rawString>Einat Minkov and William Cohen Graph Based Similarity Measures for Synonym Extraction from Parsed Text In Proceedings of the TextGraphs workshop 2012</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Norris</author>
</authors>
<title>Markov Chains.</title>
<date>1997</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="14859" citStr="Norris, 1997" startWordPosition="2320" endWordPosition="2321">ch includes all nodes representing shared context, and finally E which represents the edges of the graph connecting word nodes and context nodes. The weight on the edge is simply the number of occurrences of a given word in a context. While constructing the graph, we identify if a node represents a noisy word (N) (called source node) or a normalized word (M) (called absorbing node). The bipartite graph is constructed using the procedure in Algorithm(4.1). 4.2 Lexicon generation using Random Walks Our proposed approach uses Markov Random Walks on the bipartite graph in Figure(1) as defined in (Norris, 1997). The main objective is to identify pairs of noisy and normalized words that can be considered as normalization equivalences. In principal, this is similar to using random walks for semi-supervised label propagation which has been introduced in (Szummer and Jaakkola, 2002) and then used in many other applications. For example, (Hughes and Ramage, 2007) used random walks on Wordnet graph to measure lexical semantic relatedness between words. (Das and Petrov, 2011) used graph-based label propagation for cross-lingual knowledge transfers to induce POS tags between two languages. (Minkov and Cohen</context>
<context position="17225" citStr="Norris, 1997" startWordPosition="2716" endWordPosition="2717">is only connected to context nodes and not directly connected to any other word node. C3 C2 C4 C1 2 2 1 mking 4 4 2 3 5 1 1 1 1 making makin taking takin tkin 1580 The algorithm repeats independent random walks for K times where the walks traverse the graph randomly according to the transition probability distribution in Eqn(1); each walk starts from the source noisy node and ends at an absorbing normalized node, or consumes the maximum number of steps without hitting an absorbing node. For any random walk the number of steps taken to traverse between any two nodes is called the hitting time (Norris, 1997). Therefore, the hitting time between a noisy and a normalized pair of nodes (n, m) with a walk r is h,(n, m). We define the cost between the two nodes as the average hitting time H(n, m) of all walks that connect those two nodes: H(n, m) = E hr(n, m)/R (2) Vr Consider the bipartite graph in Figure(1), assume a random walk starting at the source node representing the noisy word ”tkin” then moves to the context node C1 then to the absorbing node representing the normalized word ”taking”. This random walk will associate ”tkin” with ”taking” with a walk of two steps (hits). Another random walk th</context>
</contexts>
<marker>Norris, 1997</marker>
<rawString>J. Norris 1997. Markov Chains. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-jing Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>in Proceedings of ACL-2002: 40th Annual meeting of the Association for Computational Linguistics. ,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="29692" citStr="Papineni et al., 2002" startWordPosition="4832" endWordPosition="4835">pe of 1583 5.6 Machine Translation Task Evaluation The final evaluation of the text normalization system is an extrinsic evaluation where we evaluate the effect of the text normalization task on a social media text translating from English to Spanish using a large scale translation system trained on general domain data. The system is trained on English-Spanish parallel data from WMT 2012 evaluation 4. The data consists of about 5M parallel sentences on news, europal and UN data. The system is a state of the art phrase based system similar to Moses (Hoang et al., 2007). We used The BLEU score (Papineni et al., 2002) to evaluate the translation accuracy with and without the normalization. Table(6) shows the translation evaluation with different systems. The translation with normalization was improved by about 6% from 29.02 to 30.87 using RW3 as a preprocessing step. System BLEU Impreovemnet No Normalization 29.02 0% Baseline1 29.13 0.37% HB-Dict 29.76 3.69% RW3 30.87 6.37% Table 6: Translation Results 6 Conclusion and Future Work We introduced a social media text normalization system that can be deployed as a preprocessor for MT and various NLP applications to handle social media text. The proposed approa</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni and Salim Roukos and Todd Ward and Wei-jing Zhu 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. in Proceedings of ACL-2002: 40th Annual meeting of the Association for Computational Linguistics. , pages 311:318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Sproat</author>
<author>Alan W Black</author>
<author>Stanley Chen</author>
<author>Shankar Kumar</author>
<author>Mari Ostendorf</author>
<author>Christopher Richards</author>
</authors>
<title>Normalization of non-standard words.</title>
<date>2001</date>
<marker>Sproat, Black, Chen, Kumar, Ostendorf, Richards, 2001</marker>
<rawString>Richard Sproat, Alan W. Black, Stanley Chen, Shankar Kumar, Mari Ostendorf, and Christopher Richards. Normalization of non-standard words. 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xu Sun</author>
<author>Jianfeng Gao</author>
<author>Daniel Micol</author>
<author>Chris Quirk</author>
</authors>
<title>Learning Phrase-Based Spelling Error Models from Clickthrough Data.</title>
<date>2010</date>
<booktitle>Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>266--274</pages>
<marker>Sun, Gao, Micol, Quirk, 2010</marker>
<rawString>Xu Sun and Jianfeng Gao and Daniel Micol and Chris Quirk 2010. Learning Phrase-Based Spelling Error Models from Clickthrough Data. Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 266:274, Sweeden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Szummer</author>
<author>Tommi</author>
</authors>
<title>Partially labeled classification with markov random walks.</title>
<date>2002</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>945--952</pages>
<marker>Szummer, Tommi, 2002</marker>
<rawString>Martin Szummer and Tommi 2002. Partially labeled classification with markov random walks. In Advances in Neural Information Processing Systems, pages 945:952.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Robert C Moore</author>
</authors>
<title>Pronunciation modeling for improved spelling correction..</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ,</booktitle>
<pages>144151</pages>
<location>Philadelphia, USA.</location>
<contexts>
<context position="5782" citStr="Toutanova and Moore, 2002" startWordPosition="893" endWordPosition="896">tion(4) introduces the proposed graph-based lexicon induction approach, Section(5) discusses the experiments and output analysis, and finally Section(6) concludes and discusses future work. 2 Related Work Early work handled the text normalization problem as a noisy channel model where the normalized words go through a noisy channel to produce the noisy text. (Brill and Moore, 2000) introduced an approach for modeling the spelling errors as a noisy channel model based on string to string edits. Using this model gives significant performance improvements compared to previously proposed models. (Toutanova and Moore, 2002) improved the string to string edits model by modeling pronunciation similarities between words. (Choudhury et al., 2007) introduced a supervised HMM channel model for text normalization which has been expanded by (Cook and Stevenson, 2009) to introduce unsupervised noisy channel model using probabilistic models for common abbreviation and various spelling errors types. Some researchers used Statistical Machine Translation approach for text normalization; formalizing the problem as a translation from the noisy forms to the normalized forms. (Aw et al., 2006) proposed an approach for normalizin</context>
</contexts>
<marker>Toutanova, Moore, 2002</marker>
<rawString>Kristina Toutanova and Robert C. Moore. Pronunciation modeling for improved spelling correction.. 2002. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL , pages 144151, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Justin Zobel</author>
<author>Philip Dart</author>
</authors>
<title>Phonetic string matching: Lessons from information retrieval.</title>
<date>1996</date>
<booktitle>in Proceedings of the Eighteenth ACM SIGIR International Conference on Research and Development in Information Retrieval,</booktitle>
<pages>166--173</pages>
<location>Zurich, Switzerland.</location>
<marker>Zobel, Dart, 1996</marker>
<rawString>Justin Zobel and Philip Dart 1996. Phonetic string matching: Lessons from information retrieval. in Proceedings of the Eighteenth ACM SIGIR International Conference on Research and Development in Information Retrieval, pages 166:173, Zurich, Switzerland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>