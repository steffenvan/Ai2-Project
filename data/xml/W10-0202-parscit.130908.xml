<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007272">
<title confidence="0.997163">
Emotion Detection in Email Customer Care
</title>
<author confidence="0.934565">
Narendra Gupta, Mazin Gilbert, and Giuseppe Di Fabbrizio
</author>
<affiliation confidence="0.748009">
AT&amp;T Labs - Research, Inc.
</affiliation>
<address confidence="0.849018">
Florham Park, NJ 07932 - USA
</address>
<email confidence="0.998958">
{ngupta,mazin,pino}@research.att.com
</email>
<sectionHeader confidence="0.9986" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996278">
Prompt and knowledgeable responses to cus-
tomers’ emails are critical in maximizing cus-
tomer satisfaction. Such emails often con-
tain complaints about unfair treatment due to
negligence, incompetence, rigid protocols, un-
friendly systems, and unresponsive personnel.
In this paper, we refer to these emails as emo-
tional emails. They provide valuable feedback
to improve contact center processes and cus-
tomer care, as well as, to enhance customer re-
tention. This paper describes a method for ex-
tracting salient features and identifying emo-
tional emails in customer care. Salient fea-
tures reflect customer frustration, dissatisfac-
tion with the business, and threats to either
leave, take legal action and/or report to au-
thorities. Compared to a baseline system us-
ing word ngrams, our proposed approach with
salient features resulted in a 20% absolute F-
measure improvement.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.989910891304348">
Emails are becoming the preferred communication
channel for customer service. For customers, it is a
way to avoid long hold times on call centers phone
calls and to keep a record of the information ex-
changes with the business. For businesses, it of-
fers an opportunity to best utilize customer service
representatives by evenly distributing the work load
over time, and for representatives, it allows time to
research the issue and respond to the customers in
a manner consistent with business policies. Busi-
nesses can further exploit the offline nature of this
10
channel by automatically routing the emails involv-
ing critical issues to specialized representatives. Be-
sides concerns related to products and services, busi-
nesses ensure that emails complaining about unfair
treatment due to negligence, incompetence, rigid
protocols and unfriendly systems, are always han-
dled with care. Such emails, referred to as emotional
emails, are critical to reduce the churn i.e., retain-
ing customers who otherwise would have taken their
business elsewhere, and, at the same time, they are a
valuable source of information for improving busi-
ness processes.
In recurring service oriented businesses, a large
number of customer emails may contain routine
complaints. While such complaints are important
and are addressed by customer service represen-
tatives, our purpose here is to identify emotional
emails where severity of the complaints and cus-
tomer dissatisfaction are relatively high. Emotional
emails may contain abusive and probably emotion-
ally charged language, but we are mainly interested
in identifying messages where, in addition to the
flames, the customer includes a concrete descrip-
tion of the problem experienced with the company
providing the service. In the context of customer
service, customers express their concerns in many
ways. Sometimes they convey a negative emotional
component articulated by phrases like disgusted
and you suck. In other cases, there is a minimum
emotional involvement by enumerating factual sen-
tences such as you overcharged, or take my
business elsewhere. In many cases, both
the emotional and factual components are actually
present. In this work, we have identified eight dif-
</bodyText>
<note confidence="0.53821">
Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 10–16,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.99989752631579">
ferent ways that customers use to express their emo-
tions in emails. Throughout this paper, these ways
will be referred to as Salient Features. We cast the
identification of emotional email as a text classifi-
cation problem, and show that using salient features
we can significantly improve the identification ac-
curacy. Compared to a baseline system which uses
Boosting (Schapire, 1999) withnword n-grams fea-
tures, our proposed system using salient features re-
sulted in improvement in f-measure from 0.52 to
0.72.
In section 2, we provide a summary of previous
work and its relationship with our contribution. In
section 3, we describe our method for emotion de-
tection and extraction of salient features. A series of
experiments demonstrating improvement in classifi-
cation performance is presented in section 4. We
conclude the paper by highlighting the main contri-
bution of this work in section 5.
</bodyText>
<sectionHeader confidence="0.99614" genericHeader="method">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999983554054054">
Extensive work has been done on emotion detec-
tion. In the context of human-computer dialogs, al-
though richer features including acoustic and intona-
tion are available, there is a general consensus (Lit-
man and Forbes-Riley, 2004b; Lee and Narayanan,
2005) about the use of lexical features to signifi-
cantly improve the accuracy of emotion detection.
Research has also been done in predicting ba-
sic emotions (also referred to as affects) within text
(Alm et al., 2005; Liu et al., 2003). To render speech
with prosodic contour conveying the emotional con-
tent of the text, one of 6 types of human emotions
(e.g., angry, disgusted, fearful, happy, sad, and sur-
prised) are identified for each sentence in the run-
ning text. Deducing such emotions from lexical con-
structs is a hard problem evidenced by little agree-
ment among humans. A Kappa value of 0.24-0.51
was shown in Alm et al. (2005). Liu et al. (2003)
have argued that the absence of affect laden surface
features i.e., key words, from the text does not imply
absence of emotions, therefore they have relied more
on common-sense knowledge. Instead of deducing
types emotions in each sentence, we are interested
in knowing if the entire email is emotional or not.
Additionally we are also interested in the intensity
and the cause of those emotions.
There is also a body of work in areas of creating
Semantic Orientation (SO) dictionaries (Hatzivas-
siloglou and McKeown, 1997; Turney and Littman,
2003; Esuli and Sebastiani, 2005) and their use in
identifying emotions laden sentences and polarity
(Yu and Hatzivassiloglou, 2003; Kim and Hovy,
2004; Hu and Liu, 2004) of those emotions. While
such dictionaries provide a useful starting point,
their use alone does not yield satisfactory results. In
Wilson et al. (2005), classification of phrases con-
taining positive, negative or neutral emotions is dis-
cussed. For this problem they show high agreement
among human annotators (Kappa of 0.84). They
also show that labeling phrases as positive, negative
or neutral only on the basis of presence of key word
from such dictionaries yields a classification accu-
racy of 48%. An obvious reason for this poor per-
formance is that semantic orientations of words are
context dependent.
Works reported in Wilson et al. (2005); Pang et al.
(2002) and Dave et al. (2003) have attempted to
mitigate this problem by using supervised meth-
ods. They report classification results using a num-
ber of different sets of features, including unigram
word features. Wilson et al. (2005) reports an im-
provement (63% to 65.7% accuracy) in performance
by using a host of features extracted from syntac-
tic dependencies. Similarly, Gamon (2004) shows
that the use of deep semantic features along with
word unigrams improve performances. Pang et al.
(2002) and Dave et al. (2003) on the other hand
confirmed that word unigrams provide the best clas-
sification results. This is in line with our experi-
ence as well and could be due to sparseness of the
data. We also used supervised methods to predict
emotional emails. To train predictive models we
used word ngrams (uni-, bi- and tri-grams) and a
number of binary features indicating the presence of
words/phrases from specific dictionaries.
Spertus (1997) discusses a system called Smoky
which recognizes hostile messages and is quite sim-
ilar to our work. While Smoky is interested in iden-
tifying messages that contain flames, our research
on emotional emails looks deeper to discover the
reasons for such flames. Besides word unigrams,
Smoky uses rules to derive additional features for
classification. These features are intended to cap-
ture different manifestations of the flames. Simi-
</bodyText>
<page confidence="0.995398">
11
</page>
<bodyText confidence="0.9999825">
larly, in our work we also use rules (in our case im-
plemented as table look-up) to derive additional fea-
tures of emotional emails.
The learning procedure in boosting minimizes the
negative conditional log likelihood of the training
data under this model, namely:
</bodyText>
<sectionHeader confidence="0.915442" genericHeader="method">
3 Emotion detection in emails
</sectionHeader>
<bodyText confidence="0.999986166666667">
We use supervised machine learning techniques to
detect emotional emails. In particular, our emotion
detector is a statistical classifier model trained using
hand labeled training examples. For each example,
a set of salient features is extracted. The major com-
ponents of our system are described below.
</bodyText>
<subsectionHeader confidence="0.992783">
3.1 Classifier
</subsectionHeader>
<bodyText confidence="0.999804242424242">
For detecting emotional emails we used Boostex-
ter as text classification. Our choice of machine
learning algorithm was not strategic and we have no
reason to believe that SVMs or maximum entropy–
based classifiers will not perform equally well.
Boostexter, which is based on the boosting family of
algorithms, was first proposed by Schapire (1999). It
has been applied successfully to numerous text clas-
sification applications (Gupta et al., 2005) at AT&amp;T.
Boosting builds a highly accurate classifier by com-
bining many “weak” base classifiers, each one of
which may only be moderately accurate. Boost-
ing constructs the collection of base classifiers iter-
atively. On each iteration t, the boosting algorithm
supplies the base learner weighted training data and
the base learner generates a base classifier ht. Set
of nonnegative weights wt encode how important it
is that ht correctly classifies each email. Generally,
emails that were most often misclassified by the pre-
ceding base classifiers will be given the most weight
so as to force the base learner to focus on the “hard-
est” examples. As described in Schapire and Singer
(1999), Boostexter uses confidence rated base clas-
sifiers h that for every example x (in our case it is the
customer emails) output a real number h(x) whose
sign (-1 or +1) is interpreted as a prediction(+1 indi-
cates emotional email), and whose magnitude |h(x)|
is a measure of “confidence.” The output of the final
classifier f is f(x) = ET t=1 ht(x), i.e., the sum of
confidence of all classifiers ht. The real-valued pre-
dictions of the final classifier f can be mapped onto a
confidence value between 0 and 1 by a logistic func-
tion;
</bodyText>
<equation confidence="0.996759">
conf(x = emotional email) = 1 + e−f(x) .
1
� ln(1 + e−yif(xi)).
i
</equation>
<bodyText confidence="0.9986045">
Here i iterates over all training examples and yi is
the label of ith example.
</bodyText>
<subsectionHeader confidence="0.998184">
3.2 Feature extraction
</subsectionHeader>
<bodyText confidence="0.998673111111111">
Emotional emails are a reaction to perceived exces-
sive loss of time and/or money by customers. Ex-
pressions of such reactions in emails are salient fea-
tures of emotional emails. For our data we have
identified the eight features listed below. While
many of these features are of general nature and can
be present in most customer service related emo-
tional emails, in this paper we make no claims about
their completeness.
</bodyText>
<listItem confidence="0.995003833333333">
1. Expression of negative emotions: Explic-
itly expressing customers affective states
by phrases like it upsets me, T am
frustrated;
2. Expression of negative opinions about
the company: by evaluative expres-
</listItem>
<bodyText confidence="0.98662575">
sions like dishonest dealings,
disrespectful. These could also be
insulting expressions like stink, suck,
idiots;
</bodyText>
<listItem confidence="0.948023733333333">
3. Threats to take their business elsewhere:
by expression like business elsewhere,
look for another provider. These
expressions are neither emotional or evaluative;
4. Threats to report to authorities: federal
agencies, consumer protection.
These are domain dependent names of agen-
cies. The mere presence of such names implies
customer threat;
5. Threats to take legal action: seek
retribution, lawsuit. These ex-
pressions may also not be emotional or
evaluative in nature;
6. Justification about why they should have been
treated better. A common way to do this is
</listItem>
<page confidence="0.993601">
12
</page>
<bodyText confidence="0.99917525">
to say things like long time customer,
loyal customer, etc. Semantic orienta-
tions of most phrases used to express this fea-
ture are positive;
</bodyText>
<listItem confidence="0.972426111111111">
7. Disassociate themselves from the company,
by using phrases like you people, your
service representative, etc. These
are analogous to rule class ”Noun Phrases used
as Appositions” in Spertus (1997).
8. State what was done wrong to them: grossly
overcharged, on hold for hours,
etc. These phrases may have negative or
neutral semantic orientations.
</listItem>
<bodyText confidence="0.999150375">
In addition to the word unigrams, salient features of
emotional emails are also used for training/testing
the emotional email classifier. While labeling the
training data, labelers look for salient features within
the email and also the severity of the loss perceived
by the customer. For example, email 1 in Fig. 1 is la-
beled as emotional because customer perception of
loss is severe to the point that the customer may can-
cel the service. On the other hand, email 2 is not
emotional because customer perceived loss is not se-
vere to the point of service cancellation. This cus-
tomer would be satisfied in this instant if he/she re-
ceives the requested information in a timely fashion.
To extract salient features from an email, eight
separate lists of phrases customers use to express
each of the salient features were manually created.
These lists were extracted from the training data
and can be considered as basic rules that identify
emotional emails. In the labeling guide for critical
emails labelers were instructed to look for salient
features in the email and keep a list of encountered
phrases. We further enriched these lists by: a) us-
ing general knowledge of English, we added vari-
ations to existing phrases and b) searching a large
body of email text (different from testing) for differ-
ent phrases in which key words from known phrases
participated. For example from the known phrase
lied to we used the word lied and found a
phrase blatantly lied. Using these lists we
extracted eight binary salient features for each email,
indicating presence/absence of phrases from the cor-
responding list in the email.
</bodyText>
<listItem confidence="0.837496909090909">
1. You are making this very difficult
for me. I was assured that
my &lt;SERVICE&gt; would remain at
&lt;CURRENCY&gt; per month. But you
raised it to &lt;CURRENCY&gt; per
month. If I had known you were
going to go back on your word,
I would have looked for another
Internet provider. Present
bill is &lt;CURRENCY&gt;, including
&lt;CURRENCY&gt; for &lt;SERVICE&gt;.
</listItem>
<figureCaption confidence="0.973401222222222">
2. I cannot figure out my current
charges. I have called several
times to straighten out a problem
with my service for &lt;PHONENO1&gt;
and &lt;PHONENO2&gt;. I am tired of
being put on hold. I cannot get
the information from the automated
phone service.
Figure 1: Email samples: 1) emotional; 2) neutral
</figureCaption>
<sectionHeader confidence="0.992871" genericHeader="evaluation">
4 Experiments and evaluation
</sectionHeader>
<bodyText confidence="0.996946875">
We performed several experiments to compare the
performance of our emotional email classifier with
that using a ngram based text classifier. For these
experiments we labeled 620 emails as training ex-
amples and 457 emails as test examples. Training
examples were labeled independently by two differ-
ent labelers1 with relatively high degree of agree-
ment among them. Kappa (Cohen, 1960) value of
0.814 was observed versus 0.5-0.7 reported for emo-
tion labeling tasks (Alm and Sproat, 2005; Litman
and Forbes-Riley, 2004a). Because of the relatively
high agreement among these labelers, with differ-
ent back ground, we did not feel the need to check
the agreement among more than 2 labelers. Table
1 shows that emotional emails are about 12-13% of
the total population.
</bodyText>
<table confidence="0.925750666666667">
Set Number of examples Critical Emails
Training 620 12%
Test 457 13%
</table>
<tableCaption confidence="0.999293">
Table 1: Distribution of emotional emails
</tableCaption>
<footnote confidence="0.9708325">
1One of the labeler was one of the authors of this paper and
other had linguistic back ground.
</footnote>
<page confidence="0.999324">
13
</page>
<bodyText confidence="0.999578965517241">
Due to the limited size of the training data we
used cross validation (leave-one-out) technique on
the test set to evaluate outcomes of different exper-
iments. In this round robin approach, each example
from the test set is tested using a model trained on
all remaining 1076 (620 plus 456) examples. Test
results on all 457 test examples are averaged.
Throughout all of our experiments, we computed
the classification accuracy of detecting emotional
emails using precision, recall and F-measure. No-
tice for our test data a classifier with majority vote
has a classification accuracy of 87%, but since none
of the emotional emails are identified, recall and F-
measure are both zero. On the other hand, a clas-
sifier which generates many more false positives
for each true positive, will have a lower classifi-
cation accuracy but a higher (non-zero) F-measure
than the majority vote classifier. Fig. 2 shows pre-
cision/recall curves for different experiments. The
black circles represent the operating point corre-
sponding to the best F-measure for each curve. Ac-
tual values of these points are provided in Table 2.
As a baseline experiment we used word ngram
features to train a classifier model. The graph la-
beled as “ngram features” in Fig. 2 shows the per-
formance of this classifier. The best F-measure in
this case is only 0.52. Obviously this low perfor-
mance can be attributed to the small training set and
the large feature space formed by word ngrams.
</bodyText>
<table confidence="0.999916307692308">
Recall Prec. F-Mes.
Ngram Features 0.45 0.61 0.52
Rule based:
Threshholding on
Salient Features counts 0.41 0.93 0.57
&gt; 4
&gt; 3 0.63 0.74 0.68
&gt; 2 0.81 0.53 0.63
Salient Features 0.77 0.65 0.70
ngram &amp;
Salient Features 0.65 0.81 0.72
Ngram &amp;
Random Features 0.57 0.67 0.61
</table>
<tableCaption confidence="0.9963355">
Table 2: Recall and precision corresponding to best F-
measure for different classifier models
</tableCaption>
<figureCaption confidence="0.981227666666667">
Figure 2: Precision/Recall curves for different experi-
ments. Large black circles indicate the operating point
with best F-Measure
</figureCaption>
<subsectionHeader confidence="0.999189">
4.1 Salient features
</subsectionHeader>
<bodyText confidence="0.999983619047619">
The baseline system was compared with a similar
system using salient features. First, we used a sim-
ple classification rule that we formulated by look-
ing at the training data. According to this rule, if
an email contained three or more salient features it
was classified as an emotional email. We classified
the test data using this rule and obtained and an F-
measure of 0.68 (see row labeled as &gt; 3 in Table 2).
Since no confidence thresholding can be used with
the deterministic rule, its performance is indicated
by a single point marked by the gray circle in Fig. 2.
This result clearly demonstrates high utility of our
salient features. To verify that the salient features
threshold count of 3 used in our simple classification
rule is the best, we also evaluated the performance of
the rule for the salient features with threshold count
of 2 and 4 (row labeled as &gt; 2 and &gt; 4 in Table 2).
In our next set experiments, we trained a clas-
sifier model using salient features alone and with
word ngrams. Corresponding cross validation re-
sults on the test data are annotated in Table 2 and in
</bodyText>
<page confidence="0.997755">
14
</page>
<figureCaption confidence="0.715083666666667">
Fig. 2 as “Salient Features” and “N-grams &amp; Salient More specifically by leveraging publically available
Features”, respectively. Incremental improvement in Semantic orientation dictionaries, and by enriching
best F-measure clearly shows: a) BoosTexter is able our dictionaries using phrases extracted from a large
</figureCaption>
<bodyText confidence="0.982271090909091">
to learn better rules than the simple rule of identify- corpus by matching syntactic patterns of some seed
ing three or more salient features. b) Even though phrases.
salient features provide a significant improvement References
in performance, there is still discriminative informa- Alm, Cecilia and Richard Sproat. 2005. Emotional
tion in ngram features. A direct consequence of the sequencing and development in fairy tales. In
second observation is that the detection accuracy can Proceedings of the First International Conference
be further improved by extending/refining the phrase on Affective Computing and Intelligent Interac-
lists and/or by using more labeled data so that to tion.
exploit the discriminative information in the word Alm, Cecilia Ovesdotter, Dan Roth, and Richard
ngram features. Sproat. 2005. Emotions from text: machine
Salient Features of emotional emails are the con- learning for text-based emotion prediction. In
sequence of our knowledge of how customers react HLT ’05: Proceedings of the conference on Hu-
to their excessive loss. To empirically demonstrate man Language Technology and Empirical Meth-
that eight different salient features used in identifi- ods in Natural Language Processing. Association
cation of emotional emails do provide complemen- for Computational Linguistics, Morristown, NJ,
tary evidence, we randomly distributed the phrases USA, pages 579–586.
in eight lists. We then used them to extract eight Cohen, J. 1960. A coefficient of agreement for nom-
binary features in the same manner as before. Best inal scales. Educational and Psychological Mea-
F-measure for this experiment is shown in the last surement 20(1):37–46.
row of Table 2, and labeled as “N-gram &amp; Random Dave, Kushal, Steve Lawrence, and David M. Pen-
Features”. Degradation in performance of this ex- nock. 2003. Mining the peanut gallery: Opinion
periment clearly demonstrates that salient features extraction and semantic classification of product
used by us provide complimentary and not redun- reviews. In Proceedings of WWW. pages 519–
dant information. 528.
5 Conclusions Esuli, A. and F. Sebastiani. 2005. Determin-
Customer emails complaining about unfair treat- ing the semantic orientation of terms through
ment are often emotional and are critical for busi- gloss classificaion. In Proceedings of CIKM-05,
nesses. They provide valuable feedback for improv- 14th ACM International Conference on Informa-
ing business processes and coaching agents. Fur- tion and Knowledge Management. Bremen, DE.,
thermore careful handling of such emails helps to pages 617–624.
improve customer retention. In this paper, we pre- Gamon, M. 2004. Sentiment classification on cus-
sented a method for emotional email identification. tomer feedback data: Noisy data large feature
We introduced the notion of salient features for vectors and the role of linguistic analysis. In Pro-
emotional emails, and demonstrated high agreement ceedings of COLING 2004. Geneva, Switzerland,
among two labelers in detecting emotional emails. pages 841–847.
We also demonstrated that extracting salient fea- Gupta, Narendra, Gokhan Tur, Dilek Hakkani-T¨ur,
tures from the email text and using them to train a Srinivas Banglore, Giuseppe Riccardi, and Mazin
classifier model can significantly improve identifi- Rahim. 2005. The AT&amp;T Spoken Language
cation accuracy. Compared to a baseline classifier Understanding System. IEEE Transactions on
which uses only the word ngrams features, the addi- Speech and Audio Processing 14(1):213–222.
tion of the salient features improved the F-measure Hatzivassiloglou, Vasileios and Kathleen McKeown.
from 0.52 to 0.72. Our current research is focused 1997. Predicting the semantic orientation of ad-
on improving the salient feature extraction process.
15
</bodyText>
<reference confidence="0.999704828125">
jectives. In Proceedings of the Joint ACL/EACL
Conference. pages 174–181.
Hu, Minqing and Bing Liu. 2004. Mining and sum-
marizing customer reviews. In Proceedings of the
ACM SIGKDD Conference on Knowledge Dis-
covery and Data Mining (KDD). pages 168–177.
Kim, Soo-Min and Eduard Hovy. 2004. Determin-
ing the sentiment of opinions. In Proceedings of
the International Conference on Computational
Linguistics (COLING).
Lee, Chul Min and Shrikanth S. Narayanan. 2005.
Toward detecting emotions in spoken dialogs.
IEEE Transactions on Speech and Audio Process-
ing 13(2):293–303.
Litman, D. and K. Forbes-Riley. 2004a. Annotat-
ing student emotional states in spoken tutoring
dialogues. In Proceedings of the 5th SIGdial
Workshop on Discourse and Dialogue (SIGdial).
Boston, MA.
Litman, D. and K. Forbes-Riley. 2004b. Predicting
student emotions in computer-human tutoring di-
alogues. In Proceedings of the 42nd Annual Meet-
ing of the Association for Compuational Linguis-
tics (ACL). Barcelone, Spain.
Liu, Hugo, Henry Lieberman, and Ted Selker. 2003.
A model of textual affect sensing using real-world
knowledge. In IUI ’03: Proceedings of the 8th
international conference on Intelligent user inter-
faces. ACM Press, Miami, Florida, USA, pages
125–132.
Pang, Bo, Lillian Lee, and Shivakumar
Vaithyanathan. 2002. Thumbs up? Sentiment
classification using machine learning techniques.
In Proceedings of the 2002 Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP). Philadelphia, Pennsylvania, pages
79–86.
Schapire, R.E. 1999. A brief introduction to boost-
ing. In Proceedings of IJCAI.
Schapire, R.E. and Y. Singer. 1999. Improved
boosting algorithms using confidence-rated pre-
dictions. Machine Learning 37(3):297–336.
Spertus, Ellen. 1997. Smokey: Automatic recogni-
tion of hostile messages. In In Proc. of Innova-
tive Applications of Artificial Intelligence. pages
1058–1065.
Turney, P. and M. Littman. 2003. Measuring praise
and criticism: Inference of semantic orientation
from association. ACM Transactions on Informa-
tion Systems 21(4):315–346.
Wilson, Theresa, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In HLT ’05: Proceed-
ings of the conference on Human Language Tech-
nology and Empirical Methods in Natural Lan-
guage Processing. Association for Computational
Linguistics, Morristown, NJ, USA, pages 347–
354.
Yu, Hong and Vasileios Hatzivassiloglou. 2003. To-
wards answering opinion questions: Separating
facts from opinions and identifying the polarity of
opinion sentences. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language
Processing (EMNLP).
</reference>
<page confidence="0.998649">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.905506">
<title confidence="0.999264">Emotion Detection in Email Customer Care</title>
<author confidence="0.999657">Narendra Gupta</author>
<author confidence="0.999657">Mazin Gilbert</author>
<author confidence="0.999657">Giuseppe Di</author>
<affiliation confidence="0.999148">AT&amp;T Labs - Research,</affiliation>
<address confidence="0.958827">Florham Park, NJ 07932 -</address>
<abstract confidence="0.997386952380952">Prompt and knowledgeable responses to customers’ emails are critical in maximizing customer satisfaction. Such emails often contain complaints about unfair treatment due to negligence, incompetence, rigid protocols, unfriendly systems, and unresponsive personnel. this paper, we refer to these emails as emo- They provide valuable feedback to improve contact center processes and customer care, as well as, to enhance customer retention. This paper describes a method for exfeatures identifying emotional emails in customer care. Salient features reflect customer frustration, dissatisfaction with the business, and threats to either leave, take legal action and/or report to authorities. Compared to a baseline system using word ngrams, our proposed approach with salient features resulted in a 20% absolute Fmeasure improvement.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>jectives</author>
</authors>
<booktitle>In Proceedings of the Joint ACL/EACL Conference.</booktitle>
<pages>174--181</pages>
<marker>jectives, </marker>
<rawString>jectives. In Proceedings of the Joint ACL/EACL Conference. pages 174–181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD).</booktitle>
<pages>168--177</pages>
<contexts>
<context position="6039" citStr="Hu and Liu, 2004" startWordPosition="946" endWordPosition="949">s not imply absence of emotions, therefore they have relied more on common-sense knowledge. Instead of deducing types emotions in each sentence, we are interested in knowing if the entire email is emotional or not. Additionally we are also interested in the intensity and the cause of those emotions. There is also a body of work in areas of creating Semantic Orientation (SO) dictionaries (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Esuli and Sebastiani, 2005) and their use in identifying emotions laden sentences and polarity (Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Hu and Liu, 2004) of those emotions. While such dictionaries provide a useful starting point, their use alone does not yield satisfactory results. In Wilson et al. (2005), classification of phrases containing positive, negative or neutral emotions is discussed. For this problem they show high agreement among human annotators (Kappa of 0.84). They also show that labeling phrases as positive, negative or neutral only on the basis of presence of key word from such dictionaries yields a classification accuracy of 48%. An obvious reason for this poor performance is that semantic orientations of words are context de</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Hu, Minqing and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD). pages 168–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Determining the sentiment of opinions.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING).</booktitle>
<contexts>
<context position="6020" citStr="Kim and Hovy, 2004" startWordPosition="942" endWordPosition="945">s, from the text does not imply absence of emotions, therefore they have relied more on common-sense knowledge. Instead of deducing types emotions in each sentence, we are interested in knowing if the entire email is emotional or not. Additionally we are also interested in the intensity and the cause of those emotions. There is also a body of work in areas of creating Semantic Orientation (SO) dictionaries (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Esuli and Sebastiani, 2005) and their use in identifying emotions laden sentences and polarity (Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Hu and Liu, 2004) of those emotions. While such dictionaries provide a useful starting point, their use alone does not yield satisfactory results. In Wilson et al. (2005), classification of phrases containing positive, negative or neutral emotions is discussed. For this problem they show high agreement among human annotators (Kappa of 0.84). They also show that labeling phrases as positive, negative or neutral only on the basis of presence of key word from such dictionaries yields a classification accuracy of 48%. An obvious reason for this poor performance is that semantic orientations of w</context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>Kim, Soo-Min and Eduard Hovy. 2004. Determining the sentiment of opinions. In Proceedings of the International Conference on Computational Linguistics (COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chul Min Lee</author>
<author>Shrikanth S Narayanan</author>
</authors>
<title>Toward detecting emotions in spoken dialogs.</title>
<date>2005</date>
<journal>IEEE Transactions on Speech and Audio Processing</journal>
<volume>13</volume>
<issue>2</issue>
<contexts>
<context position="4676" citStr="Lee and Narayanan, 2005" startWordPosition="717" endWordPosition="720">mary of previous work and its relationship with our contribution. In section 3, we describe our method for emotion detection and extraction of salient features. A series of experiments demonstrating improvement in classification performance is presented in section 4. We conclude the paper by highlighting the main contribution of this work in section 5. 2 Previous Work Extensive work has been done on emotion detection. In the context of human-computer dialogs, although richer features including acoustic and intonation are available, there is a general consensus (Litman and Forbes-Riley, 2004b; Lee and Narayanan, 2005) about the use of lexical features to significantly improve the accuracy of emotion detection. Research has also been done in predicting basic emotions (also referred to as affects) within text (Alm et al., 2005; Liu et al., 2003). To render speech with prosodic contour conveying the emotional content of the text, one of 6 types of human emotions (e.g., angry, disgusted, fearful, happy, sad, and surprised) are identified for each sentence in the running text. Deducing such emotions from lexical constructs is a hard problem evidenced by little agreement among humans. A Kappa value of 0.24-0.51 </context>
</contexts>
<marker>Lee, Narayanan, 2005</marker>
<rawString>Lee, Chul Min and Shrikanth S. Narayanan. 2005. Toward detecting emotions in spoken dialogs. IEEE Transactions on Speech and Audio Processing 13(2):293–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Litman</author>
<author>K Forbes-Riley</author>
</authors>
<title>Annotating student emotional states in spoken tutoring dialogues.</title>
<date>2004</date>
<booktitle>In Proceedings of the 5th SIGdial Workshop on Discourse and Dialogue (SIGdial).</booktitle>
<location>Boston, MA.</location>
<contexts>
<context position="4649" citStr="Litman and Forbes-Riley, 2004" startWordPosition="712" endWordPosition="716">. In section 2, we provide a summary of previous work and its relationship with our contribution. In section 3, we describe our method for emotion detection and extraction of salient features. A series of experiments demonstrating improvement in classification performance is presented in section 4. We conclude the paper by highlighting the main contribution of this work in section 5. 2 Previous Work Extensive work has been done on emotion detection. In the context of human-computer dialogs, although richer features including acoustic and intonation are available, there is a general consensus (Litman and Forbes-Riley, 2004b; Lee and Narayanan, 2005) about the use of lexical features to significantly improve the accuracy of emotion detection. Research has also been done in predicting basic emotions (also referred to as affects) within text (Alm et al., 2005; Liu et al., 2003). To render speech with prosodic contour conveying the emotional content of the text, one of 6 types of human emotions (e.g., angry, disgusted, fearful, happy, sad, and surprised) are identified for each sentence in the running text. Deducing such emotions from lexical constructs is a hard problem evidenced by little agreement among humans. </context>
<context position="15111" citStr="Litman and Forbes-Riley, 2004" startWordPosition="2435" endWordPosition="2438"> from the automated phone service. Figure 1: Email samples: 1) emotional; 2) neutral 4 Experiments and evaluation We performed several experiments to compare the performance of our emotional email classifier with that using a ngram based text classifier. For these experiments we labeled 620 emails as training examples and 457 emails as test examples. Training examples were labeled independently by two different labelers1 with relatively high degree of agreement among them. Kappa (Cohen, 1960) value of 0.814 was observed versus 0.5-0.7 reported for emotion labeling tasks (Alm and Sproat, 2005; Litman and Forbes-Riley, 2004a). Because of the relatively high agreement among these labelers, with different back ground, we did not feel the need to check the agreement among more than 2 labelers. Table 1 shows that emotional emails are about 12-13% of the total population. Set Number of examples Critical Emails Training 620 12% Test 457 13% Table 1: Distribution of emotional emails 1One of the labeler was one of the authors of this paper and other had linguistic back ground. 13 Due to the limited size of the training data we used cross validation (leave-one-out) technique on the test set to evaluate outcomes of differ</context>
</contexts>
<marker>Litman, Forbes-Riley, 2004</marker>
<rawString>Litman, D. and K. Forbes-Riley. 2004a. Annotating student emotional states in spoken tutoring dialogues. In Proceedings of the 5th SIGdial Workshop on Discourse and Dialogue (SIGdial). Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Litman</author>
<author>K Forbes-Riley</author>
</authors>
<title>Predicting student emotions in computer-human tutoring dialogues.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Compuational Linguistics (ACL). Barcelone,</booktitle>
<contexts>
<context position="4649" citStr="Litman and Forbes-Riley, 2004" startWordPosition="712" endWordPosition="716">. In section 2, we provide a summary of previous work and its relationship with our contribution. In section 3, we describe our method for emotion detection and extraction of salient features. A series of experiments demonstrating improvement in classification performance is presented in section 4. We conclude the paper by highlighting the main contribution of this work in section 5. 2 Previous Work Extensive work has been done on emotion detection. In the context of human-computer dialogs, although richer features including acoustic and intonation are available, there is a general consensus (Litman and Forbes-Riley, 2004b; Lee and Narayanan, 2005) about the use of lexical features to significantly improve the accuracy of emotion detection. Research has also been done in predicting basic emotions (also referred to as affects) within text (Alm et al., 2005; Liu et al., 2003). To render speech with prosodic contour conveying the emotional content of the text, one of 6 types of human emotions (e.g., angry, disgusted, fearful, happy, sad, and surprised) are identified for each sentence in the running text. Deducing such emotions from lexical constructs is a hard problem evidenced by little agreement among humans. </context>
<context position="15111" citStr="Litman and Forbes-Riley, 2004" startWordPosition="2435" endWordPosition="2438"> from the automated phone service. Figure 1: Email samples: 1) emotional; 2) neutral 4 Experiments and evaluation We performed several experiments to compare the performance of our emotional email classifier with that using a ngram based text classifier. For these experiments we labeled 620 emails as training examples and 457 emails as test examples. Training examples were labeled independently by two different labelers1 with relatively high degree of agreement among them. Kappa (Cohen, 1960) value of 0.814 was observed versus 0.5-0.7 reported for emotion labeling tasks (Alm and Sproat, 2005; Litman and Forbes-Riley, 2004a). Because of the relatively high agreement among these labelers, with different back ground, we did not feel the need to check the agreement among more than 2 labelers. Table 1 shows that emotional emails are about 12-13% of the total population. Set Number of examples Critical Emails Training 620 12% Test 457 13% Table 1: Distribution of emotional emails 1One of the labeler was one of the authors of this paper and other had linguistic back ground. 13 Due to the limited size of the training data we used cross validation (leave-one-out) technique on the test set to evaluate outcomes of differ</context>
</contexts>
<marker>Litman, Forbes-Riley, 2004</marker>
<rawString>Litman, D. and K. Forbes-Riley. 2004b. Predicting student emotions in computer-human tutoring dialogues. In Proceedings of the 42nd Annual Meeting of the Association for Compuational Linguistics (ACL). Barcelone, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hugo Liu</author>
<author>Henry Lieberman</author>
<author>Ted Selker</author>
</authors>
<title>A model of textual affect sensing using real-world knowledge.</title>
<date>2003</date>
<booktitle>In IUI ’03: Proceedings of the 8th international conference on Intelligent user interfaces.</booktitle>
<pages>125--132</pages>
<publisher>ACM Press,</publisher>
<location>Miami, Florida, USA,</location>
<contexts>
<context position="4906" citStr="Liu et al., 2003" startWordPosition="757" endWordPosition="760">nce is presented in section 4. We conclude the paper by highlighting the main contribution of this work in section 5. 2 Previous Work Extensive work has been done on emotion detection. In the context of human-computer dialogs, although richer features including acoustic and intonation are available, there is a general consensus (Litman and Forbes-Riley, 2004b; Lee and Narayanan, 2005) about the use of lexical features to significantly improve the accuracy of emotion detection. Research has also been done in predicting basic emotions (also referred to as affects) within text (Alm et al., 2005; Liu et al., 2003). To render speech with prosodic contour conveying the emotional content of the text, one of 6 types of human emotions (e.g., angry, disgusted, fearful, happy, sad, and surprised) are identified for each sentence in the running text. Deducing such emotions from lexical constructs is a hard problem evidenced by little agreement among humans. A Kappa value of 0.24-0.51 was shown in Alm et al. (2005). Liu et al. (2003) have argued that the absence of affect laden surface features i.e., key words, from the text does not imply absence of emotions, therefore they have relied more on common-sense kno</context>
</contexts>
<marker>Liu, Lieberman, Selker, 2003</marker>
<rawString>Liu, Hugo, Henry Lieberman, and Ted Selker. 2003. A model of textual affect sensing using real-world knowledge. In IUI ’03: Proceedings of the 8th international conference on Intelligent user interfaces. ACM Press, Miami, Florida, USA, pages 125–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<pages>79--86</pages>
<location>Philadelphia, Pennsylvania,</location>
<contexts>
<context position="6706" citStr="Pang et al. (2002)" startWordPosition="1054" endWordPosition="1057">de a useful starting point, their use alone does not yield satisfactory results. In Wilson et al. (2005), classification of phrases containing positive, negative or neutral emotions is discussed. For this problem they show high agreement among human annotators (Kappa of 0.84). They also show that labeling phrases as positive, negative or neutral only on the basis of presence of key word from such dictionaries yields a classification accuracy of 48%. An obvious reason for this poor performance is that semantic orientations of words are context dependent. Works reported in Wilson et al. (2005); Pang et al. (2002) and Dave et al. (2003) have attempted to mitigate this problem by using supervised methods. They report classification results using a number of different sets of features, including unigram word features. Wilson et al. (2005) reports an improvement (63% to 65.7% accuracy) in performance by using a host of features extracted from syntactic dependencies. Similarly, Gamon (2004) shows that the use of deep semantic features along with word unigrams improve performances. Pang et al. (2002) and Dave et al. (2003) on the other hand confirmed that word unigrams provide the best classification result</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Pang, Bo, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment classification using machine learning techniques. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP). Philadelphia, Pennsylvania, pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Schapire</author>
</authors>
<title>A brief introduction to boosting.</title>
<date>1999</date>
<booktitle>In Proceedings of IJCAI.</booktitle>
<contexts>
<context position="3894" citStr="Schapire, 1999" startWordPosition="593" endWordPosition="594">ified eight difProceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 10–16, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics ferent ways that customers use to express their emotions in emails. Throughout this paper, these ways will be referred to as Salient Features. We cast the identification of emotional email as a text classification problem, and show that using salient features we can significantly improve the identification accuracy. Compared to a baseline system which uses Boosting (Schapire, 1999) withnword n-grams features, our proposed system using salient features resulted in improvement in f-measure from 0.52 to 0.72. In section 2, we provide a summary of previous work and its relationship with our contribution. In section 3, we describe our method for emotion detection and extraction of salient features. A series of experiments demonstrating improvement in classification performance is presented in section 4. We conclude the paper by highlighting the main contribution of this work in section 5. 2 Previous Work Extensive work has been done on emotion detection. In the context of hu</context>
<context position="9040" citStr="Schapire (1999)" startWordPosition="1429" endWordPosition="1430">tect emotional emails. In particular, our emotion detector is a statistical classifier model trained using hand labeled training examples. For each example, a set of salient features is extracted. The major components of our system are described below. 3.1 Classifier For detecting emotional emails we used Boostexter as text classification. Our choice of machine learning algorithm was not strategic and we have no reason to believe that SVMs or maximum entropy– based classifiers will not perform equally well. Boostexter, which is based on the boosting family of algorithms, was first proposed by Schapire (1999). It has been applied successfully to numerous text classification applications (Gupta et al., 2005) at AT&amp;T. Boosting builds a highly accurate classifier by combining many “weak” base classifiers, each one of which may only be moderately accurate. Boosting constructs the collection of base classifiers iteratively. On each iteration t, the boosting algorithm supplies the base learner weighted training data and the base learner generates a base classifier ht. Set of nonnegative weights wt encode how important it is that ht correctly classifies each email. Generally, emails that were most often </context>
</contexts>
<marker>Schapire, 1999</marker>
<rawString>Schapire, R.E. 1999. A brief introduction to boosting. In Proceedings of IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Schapire</author>
<author>Y Singer</author>
</authors>
<title>Improved boosting algorithms using confidence-rated predictions.</title>
<date>1999</date>
<journal>Machine Learning</journal>
<volume>37</volume>
<issue>3</issue>
<contexts>
<context position="9828" citStr="Schapire and Singer (1999)" startWordPosition="1555" endWordPosition="1558">ining many “weak” base classifiers, each one of which may only be moderately accurate. Boosting constructs the collection of base classifiers iteratively. On each iteration t, the boosting algorithm supplies the base learner weighted training data and the base learner generates a base classifier ht. Set of nonnegative weights wt encode how important it is that ht correctly classifies each email. Generally, emails that were most often misclassified by the preceding base classifiers will be given the most weight so as to force the base learner to focus on the “hardest” examples. As described in Schapire and Singer (1999), Boostexter uses confidence rated base classifiers h that for every example x (in our case it is the customer emails) output a real number h(x) whose sign (-1 or +1) is interpreted as a prediction(+1 indicates emotional email), and whose magnitude |h(x)| is a measure of “confidence.” The output of the final classifier f is f(x) = ET t=1 ht(x), i.e., the sum of confidence of all classifiers ht. The real-valued predictions of the final classifier f can be mapped onto a confidence value between 0 and 1 by a logistic function; conf(x = emotional email) = 1 + e−f(x) . 1 � ln(1 + e−yif(xi)). i Here</context>
</contexts>
<marker>Schapire, Singer, 1999</marker>
<rawString>Schapire, R.E. and Y. Singer. 1999. Improved boosting algorithms using confidence-rated predictions. Machine Learning 37(3):297–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Spertus</author>
</authors>
<title>Smokey: Automatic recognition of hostile messages. In</title>
<date>1997</date>
<booktitle>In Proc. of Innovative Applications of Artificial Intelligence.</booktitle>
<pages>1058--1065</pages>
<contexts>
<context position="7646" citStr="Spertus (1997)" startWordPosition="1210" endWordPosition="1211">d from syntactic dependencies. Similarly, Gamon (2004) shows that the use of deep semantic features along with word unigrams improve performances. Pang et al. (2002) and Dave et al. (2003) on the other hand confirmed that word unigrams provide the best classification results. This is in line with our experience as well and could be due to sparseness of the data. We also used supervised methods to predict emotional emails. To train predictive models we used word ngrams (uni-, bi- and tri-grams) and a number of binary features indicating the presence of words/phrases from specific dictionaries. Spertus (1997) discusses a system called Smoky which recognizes hostile messages and is quite similar to our work. While Smoky is interested in identifying messages that contain flames, our research on emotional emails looks deeper to discover the reasons for such flames. Besides word unigrams, Smoky uses rules to derive additional features for classification. These features are intended to capture different manifestations of the flames. Simi11 larly, in our work we also use rules (in our case implemented as table look-up) to derive additional features of emotional emails. The learning procedure in boosting</context>
<context position="12176" citStr="Spertus (1997)" startWordPosition="1947" endWordPosition="1948">e presence of such names implies customer threat; 5. Threats to take legal action: seek retribution, lawsuit. These expressions may also not be emotional or evaluative in nature; 6. Justification about why they should have been treated better. A common way to do this is 12 to say things like long time customer, loyal customer, etc. Semantic orientations of most phrases used to express this feature are positive; 7. Disassociate themselves from the company, by using phrases like you people, your service representative, etc. These are analogous to rule class ”Noun Phrases used as Appositions” in Spertus (1997). 8. State what was done wrong to them: grossly overcharged, on hold for hours, etc. These phrases may have negative or neutral semantic orientations. In addition to the word unigrams, salient features of emotional emails are also used for training/testing the emotional email classifier. While labeling the training data, labelers look for salient features within the email and also the severity of the loss perceived by the customer. For example, email 1 in Fig. 1 is labeled as emotional because customer perception of loss is severe to the point that the customer may cancel the service. On the o</context>
</contexts>
<marker>Spertus, 1997</marker>
<rawString>Spertus, Ellen. 1997. Smokey: Automatic recognition of hostile messages. In In Proc. of Innovative Applications of Artificial Intelligence. pages 1058–1065.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
<author>M Littman</author>
</authors>
<title>Measuring praise and criticism: Inference of semantic orientation from association.</title>
<date>2003</date>
<journal>ACM Transactions on Information Systems</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="5873" citStr="Turney and Littman, 2003" startWordPosition="920" endWordPosition="923">A Kappa value of 0.24-0.51 was shown in Alm et al. (2005). Liu et al. (2003) have argued that the absence of affect laden surface features i.e., key words, from the text does not imply absence of emotions, therefore they have relied more on common-sense knowledge. Instead of deducing types emotions in each sentence, we are interested in knowing if the entire email is emotional or not. Additionally we are also interested in the intensity and the cause of those emotions. There is also a body of work in areas of creating Semantic Orientation (SO) dictionaries (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Esuli and Sebastiani, 2005) and their use in identifying emotions laden sentences and polarity (Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Hu and Liu, 2004) of those emotions. While such dictionaries provide a useful starting point, their use alone does not yield satisfactory results. In Wilson et al. (2005), classification of phrases containing positive, negative or neutral emotions is discussed. For this problem they show high agreement among human annotators (Kappa of 0.84). They also show that labeling phrases as positive, negative or neutral only on the basis of presence of key </context>
</contexts>
<marker>Turney, Littman, 2003</marker>
<rawString>Turney, P. and M. Littman. 2003. Measuring praise and criticism: Inference of semantic orientation from association. ACM Transactions on Information Systems 21(4):315–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In HLT ’05: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing. Association for Computational Linguistics,</booktitle>
<pages>347--354</pages>
<location>Morristown, NJ, USA,</location>
<contexts>
<context position="6192" citStr="Wilson et al. (2005)" startWordPosition="970" endWordPosition="973">e interested in knowing if the entire email is emotional or not. Additionally we are also interested in the intensity and the cause of those emotions. There is also a body of work in areas of creating Semantic Orientation (SO) dictionaries (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Esuli and Sebastiani, 2005) and their use in identifying emotions laden sentences and polarity (Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Hu and Liu, 2004) of those emotions. While such dictionaries provide a useful starting point, their use alone does not yield satisfactory results. In Wilson et al. (2005), classification of phrases containing positive, negative or neutral emotions is discussed. For this problem they show high agreement among human annotators (Kappa of 0.84). They also show that labeling phrases as positive, negative or neutral only on the basis of presence of key word from such dictionaries yields a classification accuracy of 48%. An obvious reason for this poor performance is that semantic orientations of words are context dependent. Works reported in Wilson et al. (2005); Pang et al. (2002) and Dave et al. (2003) have attempted to mitigate this problem by using supervised me</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Wilson, Theresa, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phraselevel sentiment analysis. In HLT ’05: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Morristown, NJ, USA, pages 347– 354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong Yu</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="6000" citStr="Yu and Hatzivassiloglou, 2003" startWordPosition="938" endWordPosition="941">surface features i.e., key words, from the text does not imply absence of emotions, therefore they have relied more on common-sense knowledge. Instead of deducing types emotions in each sentence, we are interested in knowing if the entire email is emotional or not. Additionally we are also interested in the intensity and the cause of those emotions. There is also a body of work in areas of creating Semantic Orientation (SO) dictionaries (Hatzivassiloglou and McKeown, 1997; Turney and Littman, 2003; Esuli and Sebastiani, 2005) and their use in identifying emotions laden sentences and polarity (Yu and Hatzivassiloglou, 2003; Kim and Hovy, 2004; Hu and Liu, 2004) of those emotions. While such dictionaries provide a useful starting point, their use alone does not yield satisfactory results. In Wilson et al. (2005), classification of phrases containing positive, negative or neutral emotions is discussed. For this problem they show high agreement among human annotators (Kappa of 0.84). They also show that labeling phrases as positive, negative or neutral only on the basis of presence of key word from such dictionaries yields a classification accuracy of 48%. An obvious reason for this poor performance is that semant</context>
</contexts>
<marker>Yu, Hatzivassiloglou, 2003</marker>
<rawString>Yu, Hong and Vasileios Hatzivassiloglou. 2003. Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>