<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008414">
<title confidence="0.9972765">
Learning Rules and Categorization Networks for Language
Standardization
</title>
<author confidence="0.993771">
Gerhard B van Huyssteen Marelie H Davel
</author>
<affiliation confidence="0.949972">
Human Language Technology Group Human Language Technology Group
Council for Scientific and Industrial Research Council for Scientific and Industrial Research
Pretoria, South Africa Pretoria, South Africa
</affiliation>
<email confidence="0.988122">
gvhuyssteen@csir.co.za mdavel@csir.co.za
</email>
<sectionHeader confidence="0.995461" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999749894736842">
In this research, we use machine learning
techniques to provide solutions for descriptive
linguists in the domain of language standardi-
zation. With regard to the personal name con-
struction in Afrikaans, we perform function
learning from word pairs using the De-
fault&amp;Refine algorithm. We demonstrate how
the extracted rules can be used to identify ir-
regularities in previously standardized con-
structions and to predict new forms of unseen
words. In addition, we define a generic, auto-
mated process that allows us to extract con-
structional schemas and present these visually
as categorization networks, similar to what is
often being used in Cognitive Grammar. We
conclude that computational modeling of con-
structions can contribute to new descriptive
linguistic insights, and to practical language
solutions.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999936545454545">
In the main, constructionist approaches to grammar
focus on discovering generalizations in language
by analyzing clusters of usage-based instances of
linguistic phenomena. Similarly, computational
linguistic approaches to grammar learning aim to
discover these very same patterns, using automated
techniques such as machine learning (ML).
In this research, we use techniques from ML to
analyze and predict irregular phenomena with li-
mited data available, and then represent these phe-
nomena visually in a way that is compatible with
the Cognitive Grammar descriptive framework (as
a constructionist approach to grammar; henceforth
CG). Our grand goal is to develop language tech-
nology tools that could be used in descriptive lin-
guistics. Specifically, we aim to (1) develop a
predictor that could suggest derivational forms for
novel base-forms; and (2) automatically extract
categorization networks (i.e. constructional sche-
mas and the relationships between them) from a
dataset, which could serve as a heuristic input to
descriptive linguistics.
</bodyText>
<sectionHeader confidence="0.99094" genericHeader="introduction">
2 Contextualization
</sectionHeader>
<bodyText confidence="0.998909058823529">
This research originates from a practical problem
related to language standardization. Similar to
standardization bodies for languages like Dutch,
and German, the “Afrikaanse Taalkommisie” (TK)
is the official body responsible for the description
and regulation of Afrikaans spelling. The TK regu-
larly publishes the official orthography of Afri-
kaans in the form of the Afrikaanse Woordelys en
Spelreëls (‘Afrikaans Wordlist and Spelling
Rules’; AWS (Taalkommissie, 2009)).
One of the challenges faced by the TK is to
standardize the spelling of foreign place names
(including names of countries, cities, regions,
provinces, etc.), and their derived forms (i.e. adjec-
tives, such as Amerika·ans ‘American’; and per-
sonal names, such as Amerika·ner ‘person from
America’). In the absence of sufficient usage-based
</bodyText>
<page confidence="0.993308">
39
</page>
<note confidence="0.9905295">
Proceedings of the NAACL HLT Workshop on Extracting and Using Constructions in Computational Linguistics, pages 39–46,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.9998904375">
evidence, many variant forms are often being ac-
cepted, either related to spelling or derivation;
compare for instance the variant spelling forms
Maskat or Masqat or Muskat ‘Muscat’, or the va-
riant derivational forms Turkmenistan·i or Turkme-
nistan·ner ‘person from Turkmenistan’. The TK is
therefore challenged with the task to give guide-
lines regarding spelling and derivation, while faced
with highly irregular and sparse data containing
many variants.
We contribute to address this challenge by dis-
covering the constructions in seemingly unsyste-
matic and irregular data. Based on our tools and
outputs, the TK could then revise existing irregu-
larities and variants, or use these tools to guide
future decisions.
</bodyText>
<sectionHeader confidence="0.999988" genericHeader="related work">
3 Related Work
</sectionHeader>
<subsectionHeader confidence="0.999816">
3.1 Constructional Schemas
</subsectionHeader>
<bodyText confidence="0.999916117647059">
Morphological constructions can be defined as
composite symbolic assemblies (i.e. complex
form-meaning pairings) smaller than phrases, con-
sisting of component structures between which
valence relations hold (Van Huyssteen, 2010; see
also Tuggy, 2005). One of the main component
structures in morphological constructions is the
morpheme, which is simply defined as a simplex
symbolic unit in the language system (i.e. it does
not contain smaller symbolic units as subparts).
More schematic symbolic assemblies (i.e. less spe-
cified in their characterization) are referred to as
constructional schemas.
Constructional schemas can be represented as a
network with relationships of categorization hold-
ing between different constructional schemas;
these categorization networks provide the structur-
al description of a construction (Langacker, 2008:
222). In the representations used in CG, categori-
zation relationships of elaboration (i.e. full instan-
tiations of a schema), extension (i.e. partial
instantiations), and correspondence are specified.
Entrenchment and ease of activation is indicated
by the thickness of boxes: the thicker the line of a
box, the more prototypical that unit is (Langacker,
2008: 226; see also Figure 5).
The aim of descriptive linguistics is to postulate
categorization networks that describe a construc-
tion in a language, based on usage data. Our re-
search contributes to this aim by automatically
creating visual representations of such language
models. For our current research, we are specifical-
ly interested in the personal name construction in
Afrikaans.
</bodyText>
<subsectionHeader confidence="0.999915">
3.2 Afrikaans Personal Name Construction
</subsectionHeader>
<bodyText confidence="0.997417272727273">
Formation of personal names by means of a per-
sonal name creating derivational suffix (NRPERS) is
a productive process in many languages. The spe-
cific category that we are investigating in this re-
search is personal names derived from place
names, such as Trinidad·ees ‘person from Trini-
dad’.
In one of the standard works on derivation in
Afrikaans, Kempen (1969) identifies a number of
NRPERS suffixes that are used in derivations from
place names. He finds that there is no obvious sys-
tematicity in their distribution (based on a dataset
of 132 instances), but concludes that, in derivations
of foreign place names, the -ees and -s morphemes
are most frequently used, with some distribution
also over -i, -n (especially -aan) and -r. In addition
to some of the morphemes mentioned by Kempen
(1969), Combrink (1990) also mentions a few,
while excluding others. In as far as we know, no
other description of this construction in Afrikaans
has been done, and based on the difference be-
tween Combrink (1990) and Kempen (1969), we
can also deduct that there is no comprehensive un-
derstanding of this construction.
Personal names from place names can be formed
in four basic ways in Afrikaans: (1) suffixation
(Aruba·an ‘Arubian’); (2) zero derivation (Aber-
deen ‘person from Aberdeen’); (3) clipping and
back-formation (Turk&lt;Turkye ‘person from Tur-
key’; Armeen&lt;Armenië ‘person from Armenia’);
and (4) lexicalization (Cornwallis&gt;Korniër ‘person
from Cornwallis’). In a rather large number of cas-
es (119 in our dataset of 1,034; see 5.1) none of the
above strategies can be applied, and then paraph-
rasing is being used (e.g. ŉ persoon van Akkra ‘a
person from Accra’).
Variants of morphemes (i.e. allomorphs) exist
for phonological reasons, of which a linking ele-
ment is the most prominent (Combrink, 1990).
Compare for example -aar in Brussel·aar ‘person
from Brussels’ (where the base-form is polysyllab-
ic) vs. -enaar in Delft·enaar ‘person from Delft’
(where the base-form is monosyllabic; Delftenaar
could therefore also be analyzed as Delft·en·aar).
</bodyText>
<page confidence="0.990507">
40
</page>
<bodyText confidence="0.999913545454545">
For our purposes, we consider -enaar as an allo-
morph (i.e. elaboration) of –aar, and is identified
as such in our categorization network (see Figure
5). Similarly, we classify morphemes as allo-
morphs in cases where an allomorph exists due to
identical vowel deletion (e.g. -an as a variant of -
aan when it combines with a base-form ending on
an -a, as in Afrika·an ‘person from Africa’), as well
as consonant doubling after a short, stressed sylla-
ble in the auslaut (e.g. -mer as a variant of -er, as
in Amsterdam·mer ‘person from Amsterdam’).
</bodyText>
<subsectionHeader confidence="0.997637">
3.3 Automatic Extraction of Constructional
Schemas
</subsectionHeader>
<bodyText confidence="0.9999845625">
Computational modeling of morphology is a vast
subfield in computational linguistics, gaining
popularity since the 1980s. Pioneering work in the
field has been done within the two-level morphol-
ogy framework, and elaborations on this frame-
work can be considered the basis of state-of-the-art
morphological analyzers today. However, since
constructing such analyzers manually is hugely
expensive in terms of time and human effort, the
approach does not scale well for new languages.
To overcome this obstacle, many computational
linguists have developed techniques towards the
automatic learning of morphology (e.g. Goldsmith,
2001). A key goal is to be able to produce a mor-
phological analysis of the words of a corpus when
only provided with the unannotated corpus.
We are interested in the related goal of function
learning: given a base-form of a word, learn other
forms of the word. Most typically, function learn-
ing takes pairs of words (base-forms plus in-
flected/derived forms) as input to discover patterns
in the data. This is also the paradigm used in the
current paper.
Several ML techniques have been used to solve
specific function learning tasks (such as learning
the past tense form of the English verb). Ap-
proaches include the use of decision trees, neural
networks, inductive logic programming, and statis-
tical approaches (Shalonova &amp; Flach, 2007).
We are not aware of any work related to the au-
tomated learning of categorization networks spe-
cifically.
</bodyText>
<sectionHeader confidence="0.996497" genericHeader="method">
4 Approach
</sectionHeader>
<bodyText confidence="0.999625285714286">
Our research has two complementary goals, dealt
with separately: (1) to develop a predictor that can
suggest potential derivational forms for novel base-
forms (and alternative forms for existing base-
forms with irregular forms); and (2) to automati-
cally extract categorization networks that are easily
interpretable by linguists.
</bodyText>
<subsectionHeader confidence="0.99965">
4.1 Prediction of Derivational Forms
</subsectionHeader>
<bodyText confidence="0.999990885714285">
In order to analyze existing and predict new deri-
vational forms, we use the Default&amp;Refine (D&amp;R)
algorithm (Davel &amp; Barnard, 2004). This algorithm
extracts context-sensitive rules from discrete data,
and is particularly effective when learning from
small training sets. It has the additional advantage
that rules generated are interpretable by humans.
When applied to the grapheme-to-phoneme predic-
tion task, it has been shown to outperform compar-
ative algorithms (Davel &amp; Barnard, 2008).
The D&amp;R algorithm defines a set of templates
and then uses a greedy search to find the most gen-
eral rule (matching the templates) that describes
the training data in question. Examples that are
successfully explained by this rule are removed
from the data set and the process repeated. When-
ever a new rule contradicts examples previously
dealt with successfully, these are again added to
the training data to be “re-explained” by a later
rule. The rule set therefore captures hierarchical
default behavior: the last rule defines the default
behavior for a specific pattern, and acts as a back-
off rule to the second-last (more refined) rule,
which would capture deviations from default beha-
vior. The second-last rule would then act as back-
off to the third-last rule, and so forth. Rules are
therefore explicitly ordered according to the re-
verse rule extraction order. (The rule extracted first
is matched last.)
Once a set of rules have been generated, these
describe the training data completely. In addition,
by tracing each of the possible rules that may apply
to a new pattern (in order), various alternative de-
rivational forms are identified, along with the evi-
dence supporting each option (as in Table 2).
</bodyText>
<subsectionHeader confidence="0.998682">
4.2 Extraction of Categorization Networks
</subsectionHeader>
<bodyText confidence="0.999942833333333">
While the D&amp;R rules extracted in Section Error!
Reference source not found. provide a perspec-
tive on the phenomena that occur, these rule sets
could become extremely large and, accordingly,
more difficult to interpret. We therefore attempt to
extract categorization networks (a la CG) as visual
</bodyText>
<page confidence="0.997292">
41
</page>
<bodyText confidence="0.992816333333333">
representations in a fully automated fashion. These
networks are more easily interpretable, especially
to humans.
An iterative string matching process is used to
structure “potential morphemes” within a directed
tree. Our main assumptions are that:
</bodyText>
<listItem confidence="0.941792636363636">
· the only input to the process consists of a
set of unannotated word pairs: base-form +
derivational form;
· a morpheme is added as a suffix;
· allomorphs are either shorter than the main
morpheme (i.e. characters removed) or
longer (i.e. characters added); and
· preference is given to larger strings that
occur systematically in the training data.
The following steps are followed:
1. Generate a list of initial transformation classes
</listItem>
<bodyText confidence="0.9945355">
based on the word pairs provided. These are
derived through a comparison based on the
longest common substring of the derivational
form and its respective base-form (see Table
1). The classes specify the character string to
be removed from the base-form (if any), and
the replacement string; note that ellipses indi-
cates the base-form (or part of it), and curly
brackets indicate deletions (i.e. in China, de-
lete the -a, and then add -ees). If a place name
and its personal name are identical, the class
will be “0”.
</bodyText>
<tableCaption confidence="0.999642">
Table 1: Examples of transformation classes
</tableCaption>
<table confidence="0.9654244">
Place Personal Class (constructional
name name schema)
Aberdeen Aberdeen [[x] [0]]
Amerika Amerikaner [[...] [ner]]
China Chinees [[...{a}] [ees]]
</table>
<listItem confidence="0.938822857142857">
2. Create a list of all transformation classes and,
per transformation class, a set of all deriva-
tional forms (referred to as the transformation
derivations set).
3. For each transformation derivations set, find
the largest end-of-word string common to all
members of that set (the set best string). The
set of all “set best strings” are referred to as the
best string list and can be interpreted as a set
of candidate morphemes.
4. For each transformation derivations set, con-
sider the elements in the best string list, and
determine if any subsets of the current set exist
that match a larger string currently in the best
</listItem>
<bodyText confidence="0.977281">
string list. If so, partition the set into subsets
accordingly. (Each subset is therefore identi-
fied by both a transformation class and a best
string. For example, three different sets, each
with a different best string may be related to a
single transformation class. This makes it poss-
ible to identify situations where an allomorph
is created in other ways than simply adding the
morpheme as a suffix.)
</bodyText>
<listItem confidence="0.957993689655173">
5. For each subset, update the set best string
based on the latest partition; update the best
string list to reflect new best strings created.
6. Repeat steps (4) and (5) until no further
changes are made. The set of morphemes are
considered stable, and it now remains to struc-
ture these elements into a visual categorization
network.
7. In order to create the categorization network,
we start with an empty directed graph. For
each set best string, create a list of all the trans-
formation classes that are applicable (as calcu-
lated above) and add these transformation
classes from largest to smallest to a single
branch of the tree. (One branch is created for
each string in the best string list, and is a first
attempt at capturing a morpheme along with its
different variations.)
8. Consider the nodes at each level (all nodes that
have the same node as parent) and wherever
one node fully contains another, move the con-
tained node to become the parent of the other
(cutting the link between the original parent
node and the contained node). This process en-
sures that morpheme candidates that are ac-
tually variations of other morphemes are
suppressed at each level of the tree.
9. Now combine any nodes that occur in different
places in the tree but have identical transfor-
</listItem>
<bodyText confidence="0.980161923076923">
mation classes, by merging the lower node
with the higher node. Only identical transfor-
mation classes are merged.
10. For each node in the final tree, consider
whether the left hand side of the transforma-
tion class can be refined, specifically by add-
ing additional matching characters based on
the final transformation derivations set.
The result of this process is a set of final transfor-
mation classes, each describing a constructional
schema, and the relationships among these con-
structional schemas, displayed as a categorization
network.
</bodyText>
<page confidence="0.999103">
42
</page>
<figureCaption confidence="0.949161">
Figure 1: Number of words, rules and initial trans-
formations for the various person-x data sets
</figureCaption>
<sectionHeader confidence="0.981972" genericHeader="method">
5 Experimental Setup and Results
</sectionHeader>
<subsectionHeader confidence="0.846103">
5.1 Data
</subsectionHeader>
<bodyText confidence="0.9999722">
The dataset that we use is the list of foreign place
names and their corresponding personal names
from the AWS (Taalkommissie, 2009). For pur-
poses of brevity, we only report on suffixation and
back-formation, and exclude cases with variant
morphemes, zero derivation and clipping, as well
as all cases of paraphrasing. 732 instances are re-
tained (from the original dataset of 1,034 in-
stances).
A supplementary dataset consisting of adjectival
derivations of place names was also taken from the
AWS and treated in the same manner as the per-
sonal names; this dataset is used in Section 6.3 to
verify certain of the findings. This set contains 786
instances.
</bodyText>
<subsectionHeader confidence="0.999871">
5.2 Development of Predictor
</subsectionHeader>
<bodyText confidence="0.99998625">
The full dataset is highly irregular, containing
many transformation classes that occur only once.
We are interested in these irregularities (in order to
identify words that may need further review), as
well as in more systematic phenomena that occur
in the data. We therefore create different data sets;
in each set (referred to as person-x) we only retain
those instances that occur x or more times in the
transformations. (The person-1 set therefore con-
tains all training data, including all exceptions,
while the person-6 set only contains transforma-
tions supported by 6 or more instances.) In Figure
</bodyText>
<figureCaption confidence="0.993299">
Figure 2: Cross-validated rule accuracy for the per-
son-x and adjective-x data sets.
</figureCaption>
<bodyText confidence="0.992081787878788">
1 the number of words and number of unique
transformation classes are displayed for each per-
son-x data set.
In order to verify the accuracy of our extracted
rules, we use 10-fold cross-validation to obtain a
mean accuracy per data set, as depicted in Figure 2
(labeled “person”). We also generate a rule set
from the training and test data combined: this larg-
er set is used to extract categorization networks.
When the rule set is structured as a graph (called
a rule network), the data can be interpreted as fol-
lows: the root node indicates the default transfor-
mation, which applies unless any child node is
matched by the base-form, which again only ap-
plies unless a child of the child node matches the
base-form (and so forth), which indicates that a
more refined rule should be applied. A small part
of a rule network is displayed in Figure 3, with
each node listing the end-of-word string of the
base-form that will trigger the rule, the transforma-
tion rule that will be applied, and the number of
instances of the rule in the training data. The com-
plete rule network is very large: 266 nodes for the
person-1 data set, as indicated in Figure 1.
As was expected, a large number of exceptional
rules are generated, indicating much inconsistency
in how derivations are formed. For the person-1
data set, 217 exceptions are identified. For each of
these exceptions, alternatives are suggested in or-
der of prototypicality by tracing the rule network,
as illustrated for the base-form Smirna in Table 2.
Automatically generated tables like these provide a
practical tool for language standardization.
</bodyText>
<page confidence="0.999788">
43
</page>
<sectionHeader confidence="0.871874" genericHeader="method">
6 Discussion
</sectionHeader>
<figureCaption confidence="0.814873">
Figure 3: A small subsection of a rule network
</figureCaption>
<tableCaption confidence="0.981655">
Table 2: Alternative suggestions for the exception:
</tableCaption>
<figure confidence="0.883002625">
Smirna -&gt; Smirnioot
Alternative Instances Examples
Smirna 1 Smirna&gt;Smirnioot
Smirnees 1 Navarra&gt;Navarrees
Smirnaan 58 Sparta&gt;Spartaan
Astana&gt;Astanaan
Smirnaer 155 Hiroshima&gt;Hiroshimaer
Breda&gt;Bredaer
</figure>
<subsectionHeader confidence="0.998325">
5.3 Development of Categorization Networks
</subsectionHeader>
<bodyText confidence="0.999967583333333">
The categorization network in Figure 5 was com-
piled automatically, as described in 4.2. Note that
this specific categorization network is based on
construction schemas with three or more support-
ing examples per node; for the sake of brevity, we
do not include the full categorization network
(based on all the examples) in this paper.
The relative prototypicality of constructional
schemas (indicated by the thickness of lines in
Figure 5) is determined post hoc by observing dis-
tribution frequencies. We obtain four natural clus-
ters in this way: highly prototypical (hundred or
more instantiations), prototypical (forty or more
instantiations), less prototypical (three or more in-
stantiations), and unprototypical (less than three
instantiations, therefore also including exceptions);
the latter category is not included in Figure 5.
Full instantiations of a schema (i.e. relationships
of elaboration) is indicated with solid arrows; the
highest node in our network represents the seman-
tic pole, and is here simply indicated as [[PLACE X]
[NRPERS]]. For each node in the network, we also
indicate the class frequency, and provide three ex-
amples of the base-form.
</bodyText>
<subsectionHeader confidence="0.99275">
6.1 Predictor
</subsectionHeader>
<bodyText confidence="0.998879">
The extracted rules immediately provide us with:
</bodyText>
<listItem confidence="0.985094285714286">
· An indication of the predictability of the
data (rule accuracy);
· A set of all exceptions (single instances
that require an individual rule to describe
that instance); and
· A predictor of new forms (applying the
rules to unseen words).
</listItem>
<bodyText confidence="0.9999565">
From the accuracies depicted in Figure 2, it is clear
that the full data set, including all phenomena that
only occur once, describes a difficult learning task,
with an overall accuracy of only 63.2% achieved.
When more systematic phenomena are investigated
(i.e. transformations with six or more instances),
our classification accuracy quickly increases above
80%, indicating that the predictor is in fact usable.
An error analysis reveals that improvements may
be possible by taking pronunciation information
into account (stress patterns, syllable information,
consonant categories, etc.).
A standardization body such as the TK could
use the automatically generated list of exceptions
(similar to Table 2) to review prior standardization
decisions. In addition, the predictor can be used to
suggest derivational forms for novel base-forms,
which could then be verified with usage data.
</bodyText>
<subsectionHeader confidence="0.997823">
6.2 Categorization Networks
</subsectionHeader>
<bodyText confidence="0.999994888888889">
From Figure 5, observe that we have identified
seven basic morphemes (i.e. nodes on the highest
level), viz. -aan, -aar, -ees, -er, -i, -iet and -ër;
with the exception of the latter, all these corres-
pond to the morphemes identified by Kempen
(1969) and Combrink (1990). Linguistically speak-
ing, -ër is actually an extension of the [[...] [er]]
construction, since the e-trema is used in Afrikaans
orthography as a variant of the letter “e” to signify
a syllable with a null onset, preceded by a syllable
without a coda. However, our algorithm treated -er
and -ër as two separate morphemes.
We can also observe that the [[...] [er]] con-
structional schema can be considered the most pro-
totypical schema (based on frequency). Other
prototypical constructional schemas include [[...a]
[an]], [[...] [ner]] and [[...] [ër]] (with the latter
two actually instantiations of [[...] [er]]). Within a
</bodyText>
<page confidence="0.997111">
44
</page>
<bodyText confidence="0.999936568627451">
CG framework, it is assumed that these prototypi-
cal constructional schemas are more likely to be
activated for the categorization of novel examples.
This observation contradicts Kempen’s (1969)
finding that there is no obvious systematicity in the
distribution of personal name forming suffixes, as
well as his finding that the -ees and -s morphemes
are most frequently used. Conversely, we did not
find in our data significant evidence for the promi-
nence that Kempen (1969) and Combrink (1990)
give to morphemes/allomorphs such as -der, -lees,
-naar, -aner, -een, -ein/-yn or -ioot; that does not
mean that these do not exist – they are just not as
prominent as these previous descriptions might
have made us believe.
Furthermore, if we look at allomorphs due to
linking elements, we identified six, viz. -nees,
-enaar, -iaan, -ner, -ter and -iër. With the excep-
tion of -nees, all these have also been identified by
Kempen (1969) and Combrink (1990). If we look
closely at the instantiations of [[...] [nees]], we see
that all base-form examples end on the stressed
syllables [an] or [on], with the exception of Bali
and Mali. A standardization body could therefore
investigate whether these two examples could not
be classified better under the [[...] [ër]] construc-
tional schema, resulting in, for example, Bali·Jr, as
we also find in Dutch. If this could be the case,
then it would make sense why -nees has not been
identified by other morphologists, since it would
then be a case of an allomorph due to consonant
doubling, and not due to a linking element.
A similar closer look at -ees vs. -nees shows that
all instantiations of the base-forms of [[...] [nees]]
end on a stressed syllable, while those for [[...]
[ees]] are unstressed. In the data, there is only one
exception to the latter schema, viz. Gaboen·ees
‘person from Gabon’. Since Gaboen ends on a
stressed syllable, it would actually fit better under
the [[...] [nees]] constructional schema. Support
for this hypothesis comes from Donaldson (1993),
where he indicates that it should be spelled Ga-
boen·nees. In the absence of usage data, and based
on this categorization network, the TK could there-
fore reconsider the spelling of Gaboen·ees.
Several similar observations can be made re-
garding inconsistencies in the data (e.g. inconsis-
tencies regarding base-forms ending on [stan]). In
this sense, categorization networks like these could
be a helpful descriptive tool for a standardization
body in finding systematicity in data and rules.
</bodyText>
<subsectionHeader confidence="0.731487">
6.3 Supplementary Data: Adjectival Deriva-
tions
</subsectionHeader>
<bodyText confidence="0.999848428571428">
In order to validate the generic process, the full
process (as described in 4.1 and 4.2) is repeated
using the supplementary data set of adjectival
forms described in 5.1. Results are positive: a simi-
larly efficient learning curve is obtained (see Fig-
ure 2) and the categorization network, although
quite different, is similarly interpretable (Figure 4).
</bodyText>
<figureCaption confidence="0.998442">
Figure 4: Categorization network for the adjective-4
</figureCaption>
<bodyText confidence="0.856637">
data set
</bodyText>
<sectionHeader confidence="0.982823" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999928857142857">
In this paper, we presented a methodology to au-
tomatically discover constructional schemas from
highly irregular data, and to represent these in a
way that is both interpretable by computers (pre-
dictive rule sets) and humans (categorization net-
works). The graphical representation is by and
large compatible with one of the major Construc-
tion Grammar theories, viz. CG: we show proto-
typical examples (based on frequency), and also
indicate relationships of elaboration. In future
work, these representations could be further re-
fined, to also indicate relationships of extensions
and correspondences. We have illustrated how
these representations could provide insight in our
knowledge of the morphology of Afrikaans, as
well as providing practical language solutions for
language standardization (such as the predictor and
the tables with alternative suggestions).
Other future work will continue in two direc-
tions: (1) refining the current tool for predicting
derivational forms by taking additional features
</bodyText>
<page confidence="0.997149">
45
</page>
<bodyText confidence="0.9999528">
into account, incorporating data that was left out in
our current experiments (such as zero derivations),
and benchmarking our results with regard to alter-
native approaches; and (2) applying our algorithm
to describe other morphological constructions.
</bodyText>
<sectionHeader confidence="0.996622" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.988561375">
Van Huyssteen is jointly affiliated with North-
West University. Support by NWU is hereby ac-
knowledged.
Part of this research was made possible through
a research grant by the South African National Re-
search Foundation (FA207041600015).
We would like to extend our gratitude to Handré
Groenewald and Martin Puttkammer for their help.
</bodyText>
<sectionHeader confidence="0.999369" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99980975">
Combrink, J.G.H. 1990. Afrikaanse morfologie [Afri-
kaans morphology]. Pretoria: Academica.
Davel, M. &amp; Barnard, E. 2004. A default-and-
refinement approach to pronunciation prediction.
Proceedings of the 15th Annual Symposium of the
Pattern Recognition Association of South Africa.
Grabouw, November 2004. pp 119-123.
Davel, M. &amp; Barnard, E. 2008. Pronunciation Prediction
with Default &amp; Refine. Computer Speech and Lan-
guage. 22: 374-393.
Donaldson, B.C. 1993. A Grammar of Afrikaans. Berlin:
Mouton de Gruyter.
Goldsmith, J. 2001. Unsupervised Learning of the Mor-
phology of a Natural Language. Computational Lin-
guistics 27, pp. 153-198.
Kempen, W. 1969. Samestelling, afleiding en woord-
soortelike meerfunksionaliteit in Afrikaans [Com-
pounding, derivation and change of part-of-speech
category in Afrikaans]. Kaapstad: Nasou.
Langacker, R.W. 2008. Cognitive Grammar: A Basic
Introduction. Oxford: Oxford University Press.
Shalonova, K. &amp; Flach, P. 2007. Morphology learning
using tree of aligned suffix rules. ICML Workshop:
Challenges and Applications of Grammar Induction.
Taalkommissie. (comp.). 2009. Afrikaanse Woordelys
en Spelreëls [Afrikaans Wordlist and Spelling Rules].
Tenth edition. Kaapstad: Pharos Dictionaries.
Tuggy, D. 2005. Cognitive Approach to Word-
Formation. In: Štekauer, P. &amp; Lieber, R. (eds.).
Handbook of Word-Formation. Dordrecht: Springer.
pp. 233-265.
Van Huyssteen, GB. 2010. (Re)defining Component
Structures in Morphological Constructions: A Cogni-
tive Grammar Perspective. In: Michel, S &amp; Onysko,
A (eds.). Cognitive Approaches to Word-Formation.
Berlin: Mouton de Gruyter. pp. 97-126.
</reference>
<figureCaption confidence="0.752265">
Figure 5: Categorization network for the person-4
</figureCaption>
<bodyText confidence="0.464591">
data set
</bodyText>
<page confidence="0.999229">
46
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.544129">
<title confidence="0.999896">Learning Rules and Categorization Networks for Standardization</title>
<author confidence="0.993223">Gerhard B van_Huyssteen Marelie H Davel</author>
<affiliation confidence="0.99669">Human Language Technology Group Human Language Technology Group Council for Scientific and Industrial Research Council for Scientific and Industrial Research</affiliation>
<address confidence="0.638664">Pretoria, South Africa Pretoria, South Africa</address>
<email confidence="0.839558">gvhuyssteen@csir.co.zamdavel@csir.co.za</email>
<abstract confidence="0.99832285">In this research, we use machine learning techniques to provide solutions for descriptive linguists in the domain of language standardization. With regard to the personal name construction in Afrikaans, we perform function learning from word pairs using the Default&amp;Refine algorithm. We demonstrate how the extracted rules can be used to identify irregularities in previously standardized constructions and to predict new forms of unseen words. In addition, we define a generic, automated process that allows us to extract constructional schemas and present these visually as categorization networks, similar to what is often being used in Cognitive Grammar. We conclude that computational modeling of constructions can contribute to new descriptive linguistic insights, and to practical language solutions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J G H Combrink</author>
</authors>
<title>Afrikaanse morfologie [Afrikaans morphology].</title>
<date>1990</date>
<location>Pretoria: Academica.</location>
<contexts>
<context position="6468" citStr="Combrink (1990)" startWordPosition="951" endWordPosition="952">ch is personal names derived from place names, such as Trinidad·ees ‘person from Trinidad’. In one of the standard works on derivation in Afrikaans, Kempen (1969) identifies a number of NRPERS suffixes that are used in derivations from place names. He finds that there is no obvious systematicity in their distribution (based on a dataset of 132 instances), but concludes that, in derivations of foreign place names, the -ees and -s morphemes are most frequently used, with some distribution also over -i, -n (especially -aan) and -r. In addition to some of the morphemes mentioned by Kempen (1969), Combrink (1990) also mentions a few, while excluding others. In as far as we know, no other description of this construction in Afrikaans has been done, and based on the difference between Combrink (1990) and Kempen (1969), we can also deduct that there is no comprehensive understanding of this construction. Personal names from place names can be formed in four basic ways in Afrikaans: (1) suffixation (Aruba·an ‘Arubian’); (2) zero derivation (Aberdeen ‘person from Aberdeen’); (3) clipping and back-formation (Turk&lt;Turkye ‘person from Turkey’; Armeen&lt;Armenië ‘person from Armenia’); and (4) lexicalization (Cor</context>
<context position="22553" citStr="Combrink (1990)" startWordPosition="3535" endWordPosition="3536">nt categories, etc.). A standardization body such as the TK could use the automatically generated list of exceptions (similar to Table 2) to review prior standardization decisions. In addition, the predictor can be used to suggest derivational forms for novel base-forms, which could then be verified with usage data. 6.2 Categorization Networks From Figure 5, observe that we have identified seven basic morphemes (i.e. nodes on the highest level), viz. -aan, -aar, -ees, -er, -i, -iet and -ër; with the exception of the latter, all these correspond to the morphemes identified by Kempen (1969) and Combrink (1990). Linguistically speaking, -ër is actually an extension of the [[...] [er]] construction, since the e-trema is used in Afrikaans orthography as a variant of the letter “e” to signify a syllable with a null onset, preceded by a syllable without a coda. However, our algorithm treated -er and -ër as two separate morphemes. We can also observe that the [[...] [er]] constructional schema can be considered the most prototypical schema (based on frequency). Other prototypical constructional schemas include [[...a] [an]], [[...] [ner]] and [[...] [ër]] (with the latter two actually instantiations of [</context>
<context position="24129" citStr="Combrink (1990)" startWordPosition="3790" endWordPosition="3791">d -s morphemes are most frequently used. Conversely, we did not find in our data significant evidence for the prominence that Kempen (1969) and Combrink (1990) give to morphemes/allomorphs such as -der, -lees, -naar, -aner, -een, -ein/-yn or -ioot; that does not mean that these do not exist – they are just not as prominent as these previous descriptions might have made us believe. Furthermore, if we look at allomorphs due to linking elements, we identified six, viz. -nees, -enaar, -iaan, -ner, -ter and -iër. With the exception of -nees, all these have also been identified by Kempen (1969) and Combrink (1990). If we look closely at the instantiations of [[...] [nees]], we see that all base-form examples end on the stressed syllables [an] or [on], with the exception of Bali and Mali. A standardization body could therefore investigate whether these two examples could not be classified better under the [[...] [ër]] constructional schema, resulting in, for example, Bali·Jr, as we also find in Dutch. If this could be the case, then it would make sense why -nees has not been identified by other morphologists, since it would then be a case of an allomorph due to consonant doubling, and not due to a linki</context>
</contexts>
<marker>Combrink, 1990</marker>
<rawString>Combrink, J.G.H. 1990. Afrikaanse morfologie [Afrikaans morphology]. Pretoria: Academica.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Davel</author>
<author>E Barnard</author>
</authors>
<title>A default-andrefinement approach to pronunciation prediction.</title>
<date>2004</date>
<booktitle>Proceedings of the 15th Annual Symposium of the Pattern Recognition Association of South Africa.</booktitle>
<pages>119--123</pages>
<location>Grabouw,</location>
<contexts>
<context position="10274" citStr="Davel &amp; Barnard, 2004" startWordPosition="1551" endWordPosition="1554">ach, 2007). We are not aware of any work related to the automated learning of categorization networks specifically. 4 Approach Our research has two complementary goals, dealt with separately: (1) to develop a predictor that can suggest potential derivational forms for novel baseforms (and alternative forms for existing baseforms with irregular forms); and (2) to automatically extract categorization networks that are easily interpretable by linguists. 4.1 Prediction of Derivational Forms In order to analyze existing and predict new derivational forms, we use the Default&amp;Refine (D&amp;R) algorithm (Davel &amp; Barnard, 2004). This algorithm extracts context-sensitive rules from discrete data, and is particularly effective when learning from small training sets. It has the additional advantage that rules generated are interpretable by humans. When applied to the grapheme-to-phoneme prediction task, it has been shown to outperform comparative algorithms (Davel &amp; Barnard, 2008). The D&amp;R algorithm defines a set of templates and then uses a greedy search to find the most general rule (matching the templates) that describes the training data in question. Examples that are successfully explained by this rule are removed</context>
</contexts>
<marker>Davel, Barnard, 2004</marker>
<rawString>Davel, M. &amp; Barnard, E. 2004. A default-andrefinement approach to pronunciation prediction. Proceedings of the 15th Annual Symposium of the Pattern Recognition Association of South Africa. Grabouw, November 2004. pp 119-123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Davel</author>
<author>E Barnard</author>
</authors>
<date>2008</date>
<booktitle>Pronunciation Prediction with Default &amp; Refine. Computer Speech and Language.</booktitle>
<volume>22</volume>
<pages>374--393</pages>
<contexts>
<context position="10631" citStr="Davel &amp; Barnard, 2008" startWordPosition="1602" endWordPosition="1605"> (2) to automatically extract categorization networks that are easily interpretable by linguists. 4.1 Prediction of Derivational Forms In order to analyze existing and predict new derivational forms, we use the Default&amp;Refine (D&amp;R) algorithm (Davel &amp; Barnard, 2004). This algorithm extracts context-sensitive rules from discrete data, and is particularly effective when learning from small training sets. It has the additional advantage that rules generated are interpretable by humans. When applied to the grapheme-to-phoneme prediction task, it has been shown to outperform comparative algorithms (Davel &amp; Barnard, 2008). The D&amp;R algorithm defines a set of templates and then uses a greedy search to find the most general rule (matching the templates) that describes the training data in question. Examples that are successfully explained by this rule are removed from the data set and the process repeated. Whenever a new rule contradicts examples previously dealt with successfully, these are again added to the training data to be “re-explained” by a later rule. The rule set therefore captures hierarchical default behavior: the last rule defines the default behavior for a specific pattern, and acts as a backoff ru</context>
</contexts>
<marker>Davel, Barnard, 2008</marker>
<rawString>Davel, M. &amp; Barnard, E. 2008. Pronunciation Prediction with Default &amp; Refine. Computer Speech and Language. 22: 374-393.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B C Donaldson</author>
</authors>
<title>A Grammar of Afrikaans.</title>
<date>1993</date>
<location>Berlin: Mouton</location>
<note>de Gruyter.</note>
<contexts>
<context position="25195" citStr="Donaldson (1993)" startWordPosition="3968" endWordPosition="3969"> -nees has not been identified by other morphologists, since it would then be a case of an allomorph due to consonant doubling, and not due to a linking element. A similar closer look at -ees vs. -nees shows that all instantiations of the base-forms of [[...] [nees]] end on a stressed syllable, while those for [[...] [ees]] are unstressed. In the data, there is only one exception to the latter schema, viz. Gaboen·ees ‘person from Gabon’. Since Gaboen ends on a stressed syllable, it would actually fit better under the [[...] [nees]] constructional schema. Support for this hypothesis comes from Donaldson (1993), where he indicates that it should be spelled Gaboen·nees. In the absence of usage data, and based on this categorization network, the TK could therefore reconsider the spelling of Gaboen·ees. Several similar observations can be made regarding inconsistencies in the data (e.g. inconsistencies regarding base-forms ending on [stan]). In this sense, categorization networks like these could be a helpful descriptive tool for a standardization body in finding systematicity in data and rules. 6.3 Supplementary Data: Adjectival Derivations In order to validate the generic process, the full process (a</context>
</contexts>
<marker>Donaldson, 1993</marker>
<rawString>Donaldson, B.C. 1993. A Grammar of Afrikaans. Berlin: Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Goldsmith</author>
</authors>
<title>Unsupervised Learning of the Morphology of a Natural Language.</title>
<date>2001</date>
<journal>Computational Linguistics</journal>
<volume>27</volume>
<pages>153--198</pages>
<contexts>
<context position="8930" citStr="Goldsmith, 2001" startWordPosition="1335" endWordPosition="1336">modeling of morphology is a vast subfield in computational linguistics, gaining popularity since the 1980s. Pioneering work in the field has been done within the two-level morphology framework, and elaborations on this framework can be considered the basis of state-of-the-art morphological analyzers today. However, since constructing such analyzers manually is hugely expensive in terms of time and human effort, the approach does not scale well for new languages. To overcome this obstacle, many computational linguists have developed techniques towards the automatic learning of morphology (e.g. Goldsmith, 2001). A key goal is to be able to produce a morphological analysis of the words of a corpus when only provided with the unannotated corpus. We are interested in the related goal of function learning: given a base-form of a word, learn other forms of the word. Most typically, function learning takes pairs of words (base-forms plus inflected/derived forms) as input to discover patterns in the data. This is also the paradigm used in the current paper. Several ML techniques have been used to solve specific function learning tasks (such as learning the past tense form of the English verb). Approaches i</context>
</contexts>
<marker>Goldsmith, 2001</marker>
<rawString>Goldsmith, J. 2001. Unsupervised Learning of the Morphology of a Natural Language. Computational Linguistics 27, pp. 153-198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Kempen</author>
</authors>
<title>Samestelling, afleiding en woordsoortelike meerfunksionaliteit in Afrikaans [Compounding, derivation and change of part-of-speech category in Afrikaans].</title>
<date>1969</date>
<publisher>Kaapstad: Nasou.</publisher>
<contexts>
<context position="6015" citStr="Kempen (1969)" startWordPosition="876" endWordPosition="877">esearch contributes to this aim by automatically creating visual representations of such language models. For our current research, we are specifically interested in the personal name construction in Afrikaans. 3.2 Afrikaans Personal Name Construction Formation of personal names by means of a personal name creating derivational suffix (NRPERS) is a productive process in many languages. The specific category that we are investigating in this research is personal names derived from place names, such as Trinidad·ees ‘person from Trinidad’. In one of the standard works on derivation in Afrikaans, Kempen (1969) identifies a number of NRPERS suffixes that are used in derivations from place names. He finds that there is no obvious systematicity in their distribution (based on a dataset of 132 instances), but concludes that, in derivations of foreign place names, the -ees and -s morphemes are most frequently used, with some distribution also over -i, -n (especially -aan) and -r. In addition to some of the morphemes mentioned by Kempen (1969), Combrink (1990) also mentions a few, while excluding others. In as far as we know, no other description of this construction in Afrikaans has been done, and based</context>
<context position="22533" citStr="Kempen (1969)" startWordPosition="3532" endWordPosition="3533">formation, consonant categories, etc.). A standardization body such as the TK could use the automatically generated list of exceptions (similar to Table 2) to review prior standardization decisions. In addition, the predictor can be used to suggest derivational forms for novel base-forms, which could then be verified with usage data. 6.2 Categorization Networks From Figure 5, observe that we have identified seven basic morphemes (i.e. nodes on the highest level), viz. -aan, -aar, -ees, -er, -i, -iet and -ër; with the exception of the latter, all these correspond to the morphemes identified by Kempen (1969) and Combrink (1990). Linguistically speaking, -ër is actually an extension of the [[...] [er]] construction, since the e-trema is used in Afrikaans orthography as a variant of the letter “e” to signify a syllable with a null onset, preceded by a syllable without a coda. However, our algorithm treated -er and -ër as two separate morphemes. We can also observe that the [[...] [er]] constructional schema can be considered the most prototypical schema (based on frequency). Other prototypical constructional schemas include [[...a] [an]], [[...] [ner]] and [[...] [ër]] (with the latter two actually</context>
<context position="24109" citStr="Kempen (1969)" startWordPosition="3787" endWordPosition="3788">g that the -ees and -s morphemes are most frequently used. Conversely, we did not find in our data significant evidence for the prominence that Kempen (1969) and Combrink (1990) give to morphemes/allomorphs such as -der, -lees, -naar, -aner, -een, -ein/-yn or -ioot; that does not mean that these do not exist – they are just not as prominent as these previous descriptions might have made us believe. Furthermore, if we look at allomorphs due to linking elements, we identified six, viz. -nees, -enaar, -iaan, -ner, -ter and -iër. With the exception of -nees, all these have also been identified by Kempen (1969) and Combrink (1990). If we look closely at the instantiations of [[...] [nees]], we see that all base-form examples end on the stressed syllables [an] or [on], with the exception of Bali and Mali. A standardization body could therefore investigate whether these two examples could not be classified better under the [[...] [ër]] constructional schema, resulting in, for example, Bali·Jr, as we also find in Dutch. If this could be the case, then it would make sense why -nees has not been identified by other morphologists, since it would then be a case of an allomorph due to consonant doubling, an</context>
</contexts>
<marker>Kempen, 1969</marker>
<rawString>Kempen, W. 1969. Samestelling, afleiding en woordsoortelike meerfunksionaliteit in Afrikaans [Compounding, derivation and change of part-of-speech category in Afrikaans]. Kaapstad: Nasou.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R W Langacker</author>
</authors>
<title>Cognitive Grammar: A Basic Introduction.</title>
<date>2008</date>
<publisher>University Press.</publisher>
<location>Oxford: Oxford</location>
<contexts>
<context position="4870" citStr="Langacker, 2008" startWordPosition="698" endWordPosition="699">0; see also Tuggy, 2005). One of the main component structures in morphological constructions is the morpheme, which is simply defined as a simplex symbolic unit in the language system (i.e. it does not contain smaller symbolic units as subparts). More schematic symbolic assemblies (i.e. less specified in their characterization) are referred to as constructional schemas. Constructional schemas can be represented as a network with relationships of categorization holding between different constructional schemas; these categorization networks provide the structural description of a construction (Langacker, 2008: 222). In the representations used in CG, categorization relationships of elaboration (i.e. full instantiations of a schema), extension (i.e. partial instantiations), and correspondence are specified. Entrenchment and ease of activation is indicated by the thickness of boxes: the thicker the line of a box, the more prototypical that unit is (Langacker, 2008: 226; see also Figure 5). The aim of descriptive linguistics is to postulate categorization networks that describe a construction in a language, based on usage data. Our research contributes to this aim by automatically creating visual rep</context>
</contexts>
<marker>Langacker, 2008</marker>
<rawString>Langacker, R.W. 2008. Cognitive Grammar: A Basic Introduction. Oxford: Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Shalonova</author>
<author>P Flach</author>
</authors>
<title>Morphology learning using tree of aligned suffix rules. ICML Workshop: Challenges and Applications of Grammar Induction.</title>
<date>2007</date>
<contexts>
<context position="9662" citStr="Shalonova &amp; Flach, 2007" startWordPosition="1457" endWordPosition="1460">ith the unannotated corpus. We are interested in the related goal of function learning: given a base-form of a word, learn other forms of the word. Most typically, function learning takes pairs of words (base-forms plus inflected/derived forms) as input to discover patterns in the data. This is also the paradigm used in the current paper. Several ML techniques have been used to solve specific function learning tasks (such as learning the past tense form of the English verb). Approaches include the use of decision trees, neural networks, inductive logic programming, and statistical approaches (Shalonova &amp; Flach, 2007). We are not aware of any work related to the automated learning of categorization networks specifically. 4 Approach Our research has two complementary goals, dealt with separately: (1) to develop a predictor that can suggest potential derivational forms for novel baseforms (and alternative forms for existing baseforms with irregular forms); and (2) to automatically extract categorization networks that are easily interpretable by linguists. 4.1 Prediction of Derivational Forms In order to analyze existing and predict new derivational forms, we use the Default&amp;Refine (D&amp;R) algorithm (Davel &amp; Ba</context>
</contexts>
<marker>Shalonova, Flach, 2007</marker>
<rawString>Shalonova, K. &amp; Flach, P. 2007. Morphology learning using tree of aligned suffix rules. ICML Workshop: Challenges and Applications of Grammar Induction.</rawString>
</citation>
<citation valid="true">
<title>Afrikaanse Woordelys en Spelreëls [Afrikaans Wordlist and Spelling Rules]. Tenth edition. Kaapstad: Pharos Dictionaries.</title>
<date>2009</date>
<marker>2009</marker>
<rawString>Taalkommissie. (comp.). 2009. Afrikaanse Woordelys en Spelreëls [Afrikaans Wordlist and Spelling Rules]. Tenth edition. Kaapstad: Pharos Dictionaries.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Tuggy</author>
</authors>
<title>Cognitive Approach to WordFormation.</title>
<date>2005</date>
<booktitle>Handbook of Word-Formation.</booktitle>
<pages>233--265</pages>
<editor>In: Štekauer, P. &amp; Lieber, R. (eds.).</editor>
<publisher>Springer.</publisher>
<location>Dordrecht:</location>
<contexts>
<context position="4279" citStr="Tuggy, 2005" startWordPosition="615" endWordPosition="616"> highly irregular and sparse data containing many variants. We contribute to address this challenge by discovering the constructions in seemingly unsystematic and irregular data. Based on our tools and outputs, the TK could then revise existing irregularities and variants, or use these tools to guide future decisions. 3 Related Work 3.1 Constructional Schemas Morphological constructions can be defined as composite symbolic assemblies (i.e. complex form-meaning pairings) smaller than phrases, consisting of component structures between which valence relations hold (Van Huyssteen, 2010; see also Tuggy, 2005). One of the main component structures in morphological constructions is the morpheme, which is simply defined as a simplex symbolic unit in the language system (i.e. it does not contain smaller symbolic units as subparts). More schematic symbolic assemblies (i.e. less specified in their characterization) are referred to as constructional schemas. Constructional schemas can be represented as a network with relationships of categorization holding between different constructional schemas; these categorization networks provide the structural description of a construction (Langacker, 2008: 222). I</context>
</contexts>
<marker>Tuggy, 2005</marker>
<rawString>Tuggy, D. 2005. Cognitive Approach to WordFormation. In: Štekauer, P. &amp; Lieber, R. (eds.). Handbook of Word-Formation. Dordrecht: Springer. pp. 233-265.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GB Van Huyssteen</author>
</authors>
<title>(Re)defining Component Structures in Morphological Constructions: A Cognitive Grammar Perspective.</title>
<date>2010</date>
<booktitle>Cognitive Approaches to Word-Formation. Berlin: Mouton de Gruyter.</booktitle>
<pages>97--126</pages>
<editor>In: Michel, S &amp; Onysko, A (eds.).</editor>
<marker>Van Huyssteen, 2010</marker>
<rawString>Van Huyssteen, GB. 2010. (Re)defining Component Structures in Morphological Constructions: A Cognitive Grammar Perspective. In: Michel, S &amp; Onysko, A (eds.). Cognitive Approaches to Word-Formation. Berlin: Mouton de Gruyter. pp. 97-126.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>