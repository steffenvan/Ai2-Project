<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008489">
<title confidence="0.941998">
Semi-Stacking for Semi-supervised Sentiment Classification
</title>
<author confidence="0.973283">
Shoushan Li†‡, Lei Huang†, Jingjing Wang†, Guodong Zhou†*
†Natural Language Processing Lab, Soochow University, China
</author>
<affiliation confidence="0.988436">
‡ Collaborative Innovation Center of Novel Software Technology and Industrialization
</affiliation>
<email confidence="0.965071">
{shoushan.li, lei.huang2013, djingwang}@gmail.com,
gdzhou@suda.edu.cn
</email>
<sectionHeader confidence="0.997045" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999448923076923">
In this paper, we address semi-supervised
sentiment learning via semi-stacking, which
integrates two or more semi-supervised
learning algorithms from an ensemble learn-
ing perspective. Specifically, we apply meta-
learning to predict the unlabeled data given
the outputs from the member algorithms and
propose N-fold cross validation to guarantee
a suitable size of the data for training the
meta-classifier. Evaluation on four domains
shows that such a semi-stacking strategy per-
forms consistently better than its member al-
gorithms.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999980708333333">
The past decade has witnessed a huge exploding
interest in sentiment analysis from the natural lan-
guage processing and data mining communities
due to its inherent challenges and wide applica-
tions (Pang et al., 2008; Liu, 2012). One funda-
mental task in sentiment analysis is sentiment
classification, which aims to determine the senti-
mental orientation a piece of text expresses (Pang
et al., 2002). For instance, the sentence &amp;quot;I abso-
lutely love this product.&amp;quot; is supposed to be deter-
mined as a positive expression in sentimental ori-
entation.
While early studies focus on supervised learn-
ing, where only labeled data are required to train
the classification model (Pang et al., 2002), recent
studies devote more and more to reduce the heavy
dependence on the large amount of labeled data
by exploiting semi-supervised learning ap-
proaches, such as co-training (Wan, 2009; Li et al.,
2011), label propagation (Sindhwani and Melville,
2008), and deep learning (Zhou et al., 2013), to
sentiment classification. Empirical evaluation on
various domains demonstrates the effectiveness of
the unlabeled data in enhancing the performance
</bodyText>
<note confidence="0.476562">
* Corresponding author
</note>
<bodyText confidence="0.999901214285714">
of sentiment classification. However, semi-super-
vised sentiment classification remains challeng-
ing due to the following reason.
Although various semi-supervised learning al-
gorithms are now available and have been shown
to be successful in exploiting unlabeled data to
improve the performance in sentiment classifica-
tion, each algorithm has its own characteristic
with different pros and cons. It is rather difficult
to tell which performs best in general. Therefore,
it remains difficult to pick a suitable algorithm for
a specific domain. For example, as shown in Li et
al. (2013), the co-training algorithm with personal
and impersonal views yields better performances
in two product domains: Book and Kitchen, while
the label propagation algorithm yields better per-
formances in other two product domains: DVD
and Electronic.
In this paper, we overcome the above challenge
above by combining two or more algorithms in-
stead of picking one of them to perform semi-su-
pervised learning. The basic idea of our algorithm
ensemble approach is to apply meta-learning to
re-predict the labels of the unlabeled data after ob-
taining their results from the member algorithms.
First, a small portion of labeled samples in the in-
itial labeled data, namely meta-samples, are
picked as unlabeled samples and added into the
initial unlabeled data to form a new unlabeled data.
Second, we use the remaining labeled data as the
new labeled data to perform semi-supervised
learning with each member algorithm. Third, we
collect the meta-samples’ probability results from
all member algorithms to train a meta-learning
classifier (called meta-classifier). Forth and fi-
nally, we utilize the meta-classifier to re-predict
the unlabeled samples as new automatically-la-
beled samples. Due to the limited number of la-
beled data in semi-supervised learning, we use N-
fold cross validation to obtain more meta-samples
for better learning the meta-classifier. In principle,
the above ensemble learning approach could be
</bodyText>
<page confidence="0.95372">
27
</page>
<bodyText confidence="0.922285625">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 27–31,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
seen as an extension of the famous stacking ap-
proach (Džeroski and Ženko, 2004) to semi-su-
pervised learning. For convenience, we call it
semi-stacking.
The remainder of this paper is organized as fol-
lows. Section 2 overviews the related work on
semi-supervised sentiment classification. Section
3 proposes our semi-stacking strategy to semi-su-
pervised sentiment classification. Section 4 pro-
poses the data filtering approach to filter low-con-
fident unlabeled samples. Section 5 evaluates our
approach with a benchmark dataset. Finally, Sec-
tion 6 gives the conclusion and future work.
</bodyText>
<sectionHeader confidence="0.999874" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999631619047618">
Early studies on sentiment classification mainly
focus on supervised learning methods with algo-
rithm designing and feature engineering (Pang et
al., 2002; Cui et al., 2006; Riloff et al., 2006; Li et
al., 2009). Recently, most studies on sentiment
classification aim to improve the performance by
exploiting unlabeled data in two main aspects:
semi-supervised learning (Dasgupta and Ng, 2009;
Wan, 2009; Li et al., 2010) and cross-domain
learning (Blitzer et al. 2007; He et al. 2011; Li et
al., 2013). Specifically, existing approaches to
semi-supervised sentiment classification could be
categorized into two main groups: bootstrapping-
style and graph-based.
As for bootstrapping-style approaches, Wan
(2009) considers two different languages as two
views and applies co-training to conduct semi-su-
pervised sentiment classification. Similarly, Li et
al. (2010) propose two views, named personal and
impersonal views, and apply co-training to use un-
labeled data in a monolingual corpus. More re-
cently, Gao et al. (2014) propose a feature sub-
space-based self-training to semi-supervised sen-
timent classification. Empirical evaluation
demonstrates that subspace-based self-training
outperforms co-training with personal and imper-
sonal views.
As for graph-based approaches, Sindhwani and
Melville (2008) first construct a document-word
bipartite graph to describe the relationship among
the labeled and unlabeled samples and then apply
label propagation to get the labels of the unlabeled
samples.
Unlike above studies, our research on semi-su-
pervised sentiment classification does not merely
focus on one single semi-supervised learning al-
gorithm but on two or more semi-supervised
learning algorithms with ensemble learning. To
the best of our knowledge, this is the first attempt
to combine two or more semi-supervised learning
algorithms in semi-supervised sentiment classifi-
cation.
</bodyText>
<sectionHeader confidence="0.989041" genericHeader="method">
3 Semi-Stacking for Semi-supervised
</sectionHeader>
<subsectionHeader confidence="0.881989">
Sentiment Classification
</subsectionHeader>
<bodyText confidence="0.961253157894737">
In semi-supervised sentiment classification, the
learning algorithm aims to learn a classifier from
a small scale of labeled samples, named initial la-
beled data, with a large number of unlabeled sam-
ples. In the sequel, we refer the labeled data as
L = {(x;, y; )JII where is the d dimen-
sional input vector, and is its output label. The
unlabeled data in the target domain is denoted as
U = {(xk)}k . Suppose is a semi-supervised
learning algorithm. The inputs of are and
, and the output is which de-
notes the unlabeled data with automatically as-
signed labels. Besides the labeled results, it is al-
ways possible to obtain the probability results, de-
noted as , which contains the posterior proba-
bilities belonging to the positive and negative cat-
egories of each unlabeled sample, i.e., &lt;
p(pos I xk), p(neg I xk) &gt;. For clarity, some im-
portant symbols are listed in Table 1.
</bodyText>
<tableCaption confidence="0.996322">
Table 1: Symbol definition
</tableCaption>
<table confidence="0.827237357142857">
Symbol Definition
Labeled data
Unlabeled data
Unlabeled data with automatically
assigned labels
The probability result of unlabeled
data
A supervised learning algorithm
A semi-supervised learning algo-
rithm
The meta-classifier obtained from
meta-learning
The test classifier for classifying the
test data
</table>
<subsectionHeader confidence="0.995062">
3.1 Framework Overview
</subsectionHeader>
<bodyText confidence="0.999846875">
In our approach, two member semi-supervised
learning algorithm are involved, namely, and
Demi respectively, and the objective is to leverage
both of them to get a better-performed semi-su-
pervised learning algorithm. Our basic idea is to
apply meta-learning to re-predict the labels of the
unlabeled data given the outputs from the member
algorithms. Figure 1 shows the framework of our
</bodyText>
<page confidence="0.993056">
28
</page>
<bodyText confidence="0.999593428571429">
implementation of the basic idea. The core com-
ponent in semi-stacking is the meta-classifier
learned from the meta-learning process, i.e., .
This classifier aims to make a better prediction on
the unlabeled samples by combining two different
probability results from the two member algo-
rithms.
</bodyText>
<figureCaption confidence="0.999378">
Figure 1: The framework of semi-stacking
</figureCaption>
<subsectionHeader confidence="0.999158">
3.2 Meta-learning
</subsectionHeader>
<bodyText confidence="0.999640909090909">
As shown above, meta-classifier is the core com-
ponent in semi-stacking, trained through the meta-
learning process. Here, meta- means the learning
samples are not represented by traditional descrip-
tive features, e.g., bag-of-words features, but by
the result features generated from member algo-
rithms. In our approach, the learning samples in
meta-learning are represented by the posterior
probabilities of the unlabeled samples belonging
to the positive and negative categories from mem-
ber algorithms, i.e.,
</bodyText>
<equation confidence="0.946609">
(1)
</equation>
<bodyText confidence="0.893925333333333">
Where p, (pos I xk) and p, (neg I xk) are the pos-
terior probabilities from the first semi-supervised
learning algorithm while pz (pos I xk) and
</bodyText>
<equation confidence="0.886256">
p2 (neg I xk) are the posterior probabilities from
</equation>
<bodyText confidence="0.998757">
the second semi-supervised learning algorithm.
The framework of the meta-learning process is
shown in Figure 2. In detail, we first split the ini-
tial labeled data into two partitions, L,,,,, and 4n
where L&amp;quot;.,,, is used as the new initial labeled data
while Ln is merged into the unlabeled data to
form a new set of unlabeled data L + U. Then,
two semi-supervised algorithms are performed
with the labeled data L,e,,, and the unlabeled data
L  U. Third and finally, the probability results
of 4n , together with their real labels are used as
meta-learning samples to train the meta-classifier.
The feature representation of each meta-sample is
defined in Formula (1).
</bodyText>
<figureCaption confidence="0.998819">
Figure 2: The framework of meta-learning
</figureCaption>
<subsectionHeader confidence="0.6800375">
3.3 Meta-learning with N-fold Cross Valida-
tion
</subsectionHeader>
<bodyText confidence="0.4514925">
Input: Labeled data , Unlabeled dataU
Output: The meta-classifierc.,.
</bodyText>
<figure confidence="0.990836769230769">
Procedure:
(a) Initialize the meta-sample setS„,,,Q=0
(b) Split L into folds, i.e.,
(c) For in :
c1) ,L=L
c2) Perform on andL&amp;quot;„+U
c3) Perform on andL&amp;quot;„+U
c4) Generate the meta-samples, ,
from the probability results of in the above
two steps.
c5)S..=S..+S..
(d) Train the meta-classifier withS.,,a
andl&amp;quot;&amp;quot;
</figure>
<figureCaption confidence="0.999146">
Figure 3: The algorithm description of meta-learning
with N-fold cross validation
</figureCaption>
<bodyText confidence="0.999492125">
One problem of meta-learning is that the data size
of might be too small to learn a good meta-
classifier. To better use the labeled samples in the
initial labeled data, we employ N-fold cross vali-
dation to generate more meta- samples. Specifi-
cally, we first split into folds. Then, we se-
lect one of them as and consider the others as
L&amp;quot;,„ and generate the meta-learning samples as
described in Section 3.2; Third and finally, we re-
peat the above step times by selecting a dif-
ferent fold as in each time. In this way, we can
obtain the meta-learning samples with the same
size as the initial labeled data. Figure 3 presents
the algorithm description of meta-learning with
N-fold cross validation. In our implementation,
we set to be 10.
</bodyText>
<page confidence="0.995185">
29
</page>
<figure confidence="0.999414740740741">
Accuracy
0.78
0.76
0.74
0.72
0.68
0.66
0.64
0.7
0.68
0.705
Book DVD Electronic Kitchen
Baseline Self-trainingFS Label Propagation Semi-Stacking
0.673
0.715
0.655
Using 100 labeled samples
0.683
0.663
0.703
0.718
0.71
0.730.738
0.673
0.75
0.735
0.76
</figure>
<figureCaption confidence="0.999796">
Figure 4: Performance comparison of baseline and three semi-supervised learning approaches
</figureCaption>
<sectionHeader confidence="0.997519" genericHeader="method">
4 Experimentation
</sectionHeader>
<bodyText confidence="0.999857967213115">
Dataset: The dataset contains product reviews
from four different domains: Book, DVD, Elec-
tronics and Kitchen appliances (Blitzer et al.,
2007), each of which contains 1000 positive and
1000 negative labeled reviews. We randomly se-
lect 100 instances as labeled data, 400 instances
are used as test data and remaining 1500 instances
as unlabeled data.
Features: Each review text is treated as a bag-of-
words and transformed into binary vectors encod-
ing the presence or absence of word unigrams and
bigrams.
Supervised learning algorithm: The maximum
entropy (ME) classifier implemented with the
public tool, Mallet Toolkits (http://mal-
let.cs.umass.edu/), where probability outputs are
provided.
Semi-supervised learning algorithms: (1) The
first member algorithm is called self-trainingFS,
proposed by Gao et al. (2014). This approach can
be seen as a special case of self-training. Different
from the traditional self-training, self-trainingFS
use the feature-subspace classifier to make the
prediction on the unlabeled samples instead of us-
ing the whole-space classifier. In our implementa-
tion, we use four random feature subspaces. (2)
The second member algorithm is called label
propagation, a graph-based semi-supervised
learning approach, proposed by Zhu and Ghah-
ramani (2002). In our implementation, the docu-
ment-word bipartite graph is adopted to build the
document-document graph (Sindhwani and Mel-
ville, 2008).
Significance testing: We perform t-test to evalu-
ate the significance of the performance difference
between two systems with different approaches
(Yang and Liu, 1999)
Figure 4 compares the performances of the
baseline approach and three semi-supervised
learning approaches. Here, the baseline approach
is the supervised learning approach by using only
the initial labeled data (i.e. no unlabeled data is
used). From the figure, we can see that both Self-
trainingFS and label propagation are successful in
exploiting unlabeled data to improve the perfor-
mances. Self-trainingFS outperforms label propa-
gation in three domains including Book, DVD,
and Kitchen but it performs worse in Electronic.
Our approach (semi-stacking) performs much bet-
ter than baseline with an impressive improvement
of 4.95% on average. Compared to the two mem-
ber algorithms, semi-stacking always yield a bet-
ter performance, although the improvement over
the better-performed member algorithm is slight,
only around 1%-2%. Significance test shows that
our approach performs significantly better than
worse-performed member algorithm (p-
value&lt;0.01) in all domains and it also performs
significantly better than better-performed member
algorithm (p-value&lt;0.05) in three domains, i.e.,
Book, DVD, and Kitchen.
</bodyText>
<sectionHeader confidence="0.999301" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9998898">
In this paper, we present a novel ensemble learn-
ing approach named semi-stacking to semi-super-
vised sentiment classification. Semi-stacking is
implemented by re-predicting the labels of the un-
labeled samples with meta-learning after two or
more member semi-supervised learning ap-
proaches have been performed. Experimental
evaluation in four domains demonstrates that
semi-stacking outperforms both member algo-
rithms.
</bodyText>
<page confidence="0.997206">
30
</page>
<sectionHeader confidence="0.999212" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998436">
This research work has been partially supported
by three NSFC grants, No.61273320,
No.61375073, No.61331011, and Collaborative
Innovation Center of Novel Software Technology
and Industrialization.
</bodyText>
<sectionHeader confidence="0.998971" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99995230882353">
Blitzer J., M. Dredze and F. Pereira. 2007. Biographies,
Bollywood, Boom-boxes and Blenders: Domain
Adaptation for Sentiment Classification. In Pro-
ceedings of ACL-07, pp.440-447.
Blum A. and T. Mitchell. 1998. Combining Labeled
and Unlabeled Data with Co-training. In Proceed-
ings of COLT-98,pp. 92-100.
Cui H., V. Mittal and M. Datar. 2006. Comparative Ex-
periments on Sentiment Classification for Online
Product Reviews. In Proceedings of AAAI-06,
pp.1265-1270.
Dasgupta S. and V. Ng. 2009. Mine the Easy, Classify
the Hard: A Semi-Supervised Approach to Auto-
matic Sentiment Classification. In Proceedings of
ACL-IJCNLP-09, pp.701-709, 2009.
Džeroski S. and B. Ženko. 2004. Is Combining Classi-
fiers with Stacking Better than Selecting the Best
One? Machine Learning, vol.54(3), pp.255-273,
2004.
Gao W., S. Li, Y. Xue, M. Wang, and G. Zhou. 2014.
Semi-supervised Sentiment Classification with
Self-training on Feature Subspaces. In Proceedings
of CLSW-14, pp.231-239.
He Y., C. Lin and H. Alani. 2011. Automatically Ex-
tracting Polarity-Bearing Topics for Cross-Domain
Sentiment Classification. In Proceedings of ACL-11,
pp.123-131.
Li S., C. Huang, G. Zhou and S. Lee. 2010. Employing
Personal/Impersonal Views in Supervised and
Semi-supervised Sentiment Classification. In Pro-
ceedings of ACL-10, pp.414-423.
Li S., R. Xia, C. Zong, and C. Huang. 2009. A Frame-
work of Feature Selection Methods for Text Catego-
rization. In Proceedings of ACL-IJCNLP-09,
pp.692-700.
Li S., Y. Xue, Z. Wang, and G. Zhou. 2013. Active
Learning for Cross-Domain Sentiment Classifica-
tion. In Proceedings of IJCAI-13, pp.2127-2133.
Li S., Z. Wang, G. Zhou and S. Lee. 2011. Semi-super-
vised Learning for Imbalanced Sentiment Classifi-
cation. In Proceedings of IJCAI-11, pp.1826-1831.
Liu B. 2012. Sentiment Analysis and Opinion Mining
(Introduction and Survey). Morgan &amp; Claypool
Publishers, May 2012.
Pang B. and L. Lee. 2008. Opinion Mining and Senti-
ment Analysis: Foundations and Trends. Infor-
mation Retrieval, vol.2(12), pp.1-135.
Pang B., L. Lee, and S. Vaithyanathan. 2002. Thumbs
up? Sentiment Classification using Machine Learn-
ing Techniques. In Proceedings of EMNLP-02,
pp.79-86.
Riloff E., S. Patwardhan and J. Wiebe. 2006. Feature
Subsumption for Opinion Analysis. In Proceedings
of EMNLP-06, pp.440-448.
Sindhwani V. and P. Melville. 2008. Document-Word
Co-Regularization for Semi-supervised Sentiment
Analysis. In Proceedings of ICDM-08, pp.1025-
1030.
Wan X. 2009. Co-Training for Cross-Lingual Senti-
ment Classification. In Proceedings of ACL-
IJCNLP-09, pp.235-243.
Yang Y. and X. Liu. 1999. A Re-Examination of Text
Categorization Methods. In Proceedings of SIGIR-
99.
Zhu X. and Z. Ghahramani. 2002. Learning from La-
beled and Unlabeled Data with Label Propagation.
CMU CALD Technical Report. CMU-CALD-02-
107.
</reference>
<page confidence="0.999913">
31
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.145781">
<title confidence="0.770180333333333">Semi-Stacking for Semi-supervised Sentiment Classification Language Processing Lab, Soochow University, China Innovation Center of Novel Software Technology and Industrialization</title>
<email confidence="0.574461">shoushan.li@gmail.com,gdzhou@suda.edu.cn</email>
<email confidence="0.574461">lei.huang2013@gmail.com,gdzhou@suda.edu.cn</email>
<email confidence="0.574461">djingwang@gmail.com,gdzhou@suda.edu.cn</email>
<abstract confidence="0.972274214285714">In this paper, we address semi-supervised sentiment learning via semi-stacking, which integrates two or more semi-supervised learning algorithms from an ensemble learnperspective. Specifically, we apply metalearning to predict the unlabeled data given the outputs from the member algorithms and cross validation to guarantee a suitable size of the data for training the Evaluation on four domains shows that such a semi-stacking strategy performs consistently better than its member algorithms.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Blitzer</author>
<author>M Dredze</author>
<author>F Pereira</author>
</authors>
<title>Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL-07,</booktitle>
<pages>440--447</pages>
<contexts>
<context position="5372" citStr="Blitzer et al. 2007" startWordPosition="793" endWordPosition="796">t unlabeled samples. Section 5 evaluates our approach with a benchmark dataset. Finally, Section 6 gives the conclusion and future work. 2 Related Work Early studies on sentiment classification mainly focus on supervised learning methods with algorithm designing and feature engineering (Pang et al., 2002; Cui et al., 2006; Riloff et al., 2006; Li et al., 2009). Recently, most studies on sentiment classification aim to improve the performance by exploiting unlabeled data in two main aspects: semi-supervised learning (Dasgupta and Ng, 2009; Wan, 2009; Li et al., 2010) and cross-domain learning (Blitzer et al. 2007; He et al. 2011; Li et al., 2013). Specifically, existing approaches to semi-supervised sentiment classification could be categorized into two main groups: bootstrappingstyle and graph-based. As for bootstrapping-style approaches, Wan (2009) considers two different languages as two views and applies co-training to conduct semi-supervised sentiment classification. Similarly, Li et al. (2010) propose two views, named personal and impersonal views, and apply co-training to use unlabeled data in a monolingual corpus. More recently, Gao et al. (2014) propose a feature subspace-based self-training </context>
<context position="11977" citStr="Blitzer et al., 2007" startWordPosition="1822" endWordPosition="1825">nts the algorithm description of meta-learning with N-fold cross validation. In our implementation, we set to be 10. 29 Accuracy 0.78 0.76 0.74 0.72 0.68 0.66 0.64 0.7 0.68 0.705 Book DVD Electronic Kitchen Baseline Self-trainingFS Label Propagation Semi-Stacking 0.673 0.715 0.655 Using 100 labeled samples 0.683 0.663 0.703 0.718 0.71 0.730.738 0.673 0.75 0.735 0.76 Figure 4: Performance comparison of baseline and three semi-supervised learning approaches 4 Experimentation Dataset: The dataset contains product reviews from four different domains: Book, DVD, Electronics and Kitchen appliances (Blitzer et al., 2007), each of which contains 1000 positive and 1000 negative labeled reviews. We randomly select 100 instances as labeled data, 400 instances are used as test data and remaining 1500 instances as unlabeled data. Features: Each review text is treated as a bag-ofwords and transformed into binary vectors encoding the presence or absence of word unigrams and bigrams. Supervised learning algorithm: The maximum entropy (ME) classifier implemented with the public tool, Mallet Toolkits (http://mallet.cs.umass.edu/), where probability outputs are provided. Semi-supervised learning algorithms: (1) The first</context>
</contexts>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>Blitzer J., M. Dredze and F. Pereira. 2007. Biographies, Bollywood, Boom-boxes and Blenders: Domain Adaptation for Sentiment Classification. In Proceedings of ACL-07, pp.440-447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Blum</author>
<author>T Mitchell</author>
</authors>
<title>Combining Labeled and Unlabeled Data with Co-training.</title>
<date>1998</date>
<booktitle>In Proceedings of COLT-98,pp.</booktitle>
<pages>92--100</pages>
<marker>Blum, Mitchell, 1998</marker>
<rawString>Blum A. and T. Mitchell. 1998. Combining Labeled and Unlabeled Data with Co-training. In Proceedings of COLT-98,pp. 92-100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cui</author>
<author>V Mittal</author>
<author>M Datar</author>
</authors>
<title>Comparative Experiments on Sentiment Classification for Online Product Reviews.</title>
<date>2006</date>
<booktitle>In Proceedings of AAAI-06,</booktitle>
<pages>1265--1270</pages>
<contexts>
<context position="5076" citStr="Cui et al., 2006" startWordPosition="747" endWordPosition="750">e remainder of this paper is organized as follows. Section 2 overviews the related work on semi-supervised sentiment classification. Section 3 proposes our semi-stacking strategy to semi-supervised sentiment classification. Section 4 proposes the data filtering approach to filter low-confident unlabeled samples. Section 5 evaluates our approach with a benchmark dataset. Finally, Section 6 gives the conclusion and future work. 2 Related Work Early studies on sentiment classification mainly focus on supervised learning methods with algorithm designing and feature engineering (Pang et al., 2002; Cui et al., 2006; Riloff et al., 2006; Li et al., 2009). Recently, most studies on sentiment classification aim to improve the performance by exploiting unlabeled data in two main aspects: semi-supervised learning (Dasgupta and Ng, 2009; Wan, 2009; Li et al., 2010) and cross-domain learning (Blitzer et al. 2007; He et al. 2011; Li et al., 2013). Specifically, existing approaches to semi-supervised sentiment classification could be categorized into two main groups: bootstrappingstyle and graph-based. As for bootstrapping-style approaches, Wan (2009) considers two different languages as two views and applies co</context>
</contexts>
<marker>Cui, Mittal, Datar, 2006</marker>
<rawString>Cui H., V. Mittal and M. Datar. 2006. Comparative Experiments on Sentiment Classification for Online Product Reviews. In Proceedings of AAAI-06, pp.1265-1270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Dasgupta</author>
<author>V Ng</author>
</authors>
<title>Mine the Easy, Classify the Hard: A Semi-Supervised Approach to Automatic Sentiment Classification.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP-09,</booktitle>
<pages>701--709</pages>
<contexts>
<context position="5296" citStr="Dasgupta and Ng, 2009" startWordPosition="780" endWordPosition="783">ication. Section 4 proposes the data filtering approach to filter low-confident unlabeled samples. Section 5 evaluates our approach with a benchmark dataset. Finally, Section 6 gives the conclusion and future work. 2 Related Work Early studies on sentiment classification mainly focus on supervised learning methods with algorithm designing and feature engineering (Pang et al., 2002; Cui et al., 2006; Riloff et al., 2006; Li et al., 2009). Recently, most studies on sentiment classification aim to improve the performance by exploiting unlabeled data in two main aspects: semi-supervised learning (Dasgupta and Ng, 2009; Wan, 2009; Li et al., 2010) and cross-domain learning (Blitzer et al. 2007; He et al. 2011; Li et al., 2013). Specifically, existing approaches to semi-supervised sentiment classification could be categorized into two main groups: bootstrappingstyle and graph-based. As for bootstrapping-style approaches, Wan (2009) considers two different languages as two views and applies co-training to conduct semi-supervised sentiment classification. Similarly, Li et al. (2010) propose two views, named personal and impersonal views, and apply co-training to use unlabeled data in a monolingual corpus. More</context>
</contexts>
<marker>Dasgupta, Ng, 2009</marker>
<rawString>Dasgupta S. and V. Ng. 2009. Mine the Easy, Classify the Hard: A Semi-Supervised Approach to Automatic Sentiment Classification. In Proceedings of ACL-IJCNLP-09, pp.701-709, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Džeroski</author>
<author>B Ženko</author>
</authors>
<title>Is Combining Classifiers with Stacking Better than Selecting the Best One?</title>
<date>2004</date>
<booktitle>Machine Learning,</booktitle>
<volume>54</volume>
<issue>3</issue>
<pages>255--273</pages>
<contexts>
<context position="4385" citStr="Džeroski and Ženko, 2004" startWordPosition="644" endWordPosition="647"> as new automatically-labeled samples. Due to the limited number of labeled data in semi-supervised learning, we use Nfold cross validation to obtain more meta-samples for better learning the meta-classifier. In principle, the above ensemble learning approach could be 27 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 27–31, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics seen as an extension of the famous stacking approach (Džeroski and Ženko, 2004) to semi-supervised learning. For convenience, we call it semi-stacking. The remainder of this paper is organized as follows. Section 2 overviews the related work on semi-supervised sentiment classification. Section 3 proposes our semi-stacking strategy to semi-supervised sentiment classification. Section 4 proposes the data filtering approach to filter low-confident unlabeled samples. Section 5 evaluates our approach with a benchmark dataset. Finally, Section 6 gives the conclusion and future work. 2 Related Work Early studies on sentiment classification mainly focus on supervised learning me</context>
</contexts>
<marker>Džeroski, Ženko, 2004</marker>
<rawString>Džeroski S. and B. Ženko. 2004. Is Combining Classifiers with Stacking Better than Selecting the Best One? Machine Learning, vol.54(3), pp.255-273, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gao</author>
<author>S Li</author>
<author>Y Xue</author>
<author>M Wang</author>
<author>G Zhou</author>
</authors>
<title>Semi-supervised Sentiment Classification with Self-training on Feature Subspaces.</title>
<date>2014</date>
<booktitle>In Proceedings of CLSW-14,</booktitle>
<pages>231--239</pages>
<contexts>
<context position="5924" citStr="Gao et al. (2014)" startWordPosition="873" endWordPosition="876">; Li et al., 2010) and cross-domain learning (Blitzer et al. 2007; He et al. 2011; Li et al., 2013). Specifically, existing approaches to semi-supervised sentiment classification could be categorized into two main groups: bootstrappingstyle and graph-based. As for bootstrapping-style approaches, Wan (2009) considers two different languages as two views and applies co-training to conduct semi-supervised sentiment classification. Similarly, Li et al. (2010) propose two views, named personal and impersonal views, and apply co-training to use unlabeled data in a monolingual corpus. More recently, Gao et al. (2014) propose a feature subspace-based self-training to semi-supervised sentiment classification. Empirical evaluation demonstrates that subspace-based self-training outperforms co-training with personal and impersonal views. As for graph-based approaches, Sindhwani and Melville (2008) first construct a document-word bipartite graph to describe the relationship among the labeled and unlabeled samples and then apply label propagation to get the labels of the unlabeled samples. Unlike above studies, our research on semi-supervised sentiment classification does not merely focus on one single semi-supe</context>
<context position="12651" citStr="Gao et al. (2014)" startWordPosition="1921" endWordPosition="1924">labeled reviews. We randomly select 100 instances as labeled data, 400 instances are used as test data and remaining 1500 instances as unlabeled data. Features: Each review text is treated as a bag-ofwords and transformed into binary vectors encoding the presence or absence of word unigrams and bigrams. Supervised learning algorithm: The maximum entropy (ME) classifier implemented with the public tool, Mallet Toolkits (http://mallet.cs.umass.edu/), where probability outputs are provided. Semi-supervised learning algorithms: (1) The first member algorithm is called self-trainingFS, proposed by Gao et al. (2014). This approach can be seen as a special case of self-training. Different from the traditional self-training, self-trainingFS use the feature-subspace classifier to make the prediction on the unlabeled samples instead of using the whole-space classifier. In our implementation, we use four random feature subspaces. (2) The second member algorithm is called label propagation, a graph-based semi-supervised learning approach, proposed by Zhu and Ghahramani (2002). In our implementation, the document-word bipartite graph is adopted to build the document-document graph (Sindhwani and Melville, 2008)</context>
</contexts>
<marker>Gao, Li, Xue, Wang, Zhou, 2014</marker>
<rawString>Gao W., S. Li, Y. Xue, M. Wang, and G. Zhou. 2014. Semi-supervised Sentiment Classification with Self-training on Feature Subspaces. In Proceedings of CLSW-14, pp.231-239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y He</author>
<author>C Lin</author>
<author>H Alani</author>
</authors>
<title>Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-11,</booktitle>
<pages>123--131</pages>
<contexts>
<context position="5388" citStr="He et al. 2011" startWordPosition="797" endWordPosition="800">Section 5 evaluates our approach with a benchmark dataset. Finally, Section 6 gives the conclusion and future work. 2 Related Work Early studies on sentiment classification mainly focus on supervised learning methods with algorithm designing and feature engineering (Pang et al., 2002; Cui et al., 2006; Riloff et al., 2006; Li et al., 2009). Recently, most studies on sentiment classification aim to improve the performance by exploiting unlabeled data in two main aspects: semi-supervised learning (Dasgupta and Ng, 2009; Wan, 2009; Li et al., 2010) and cross-domain learning (Blitzer et al. 2007; He et al. 2011; Li et al., 2013). Specifically, existing approaches to semi-supervised sentiment classification could be categorized into two main groups: bootstrappingstyle and graph-based. As for bootstrapping-style approaches, Wan (2009) considers two different languages as two views and applies co-training to conduct semi-supervised sentiment classification. Similarly, Li et al. (2010) propose two views, named personal and impersonal views, and apply co-training to use unlabeled data in a monolingual corpus. More recently, Gao et al. (2014) propose a feature subspace-based self-training to semi-supervis</context>
</contexts>
<marker>He, Lin, Alani, 2011</marker>
<rawString>He Y., C. Lin and H. Alani. 2011. Automatically Extracting Polarity-Bearing Topics for Cross-Domain Sentiment Classification. In Proceedings of ACL-11, pp.123-131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Li</author>
<author>C Huang</author>
<author>G Zhou</author>
<author>S Lee</author>
</authors>
<title>Employing Personal/Impersonal Views in Supervised and Semi-supervised Sentiment Classification.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL-10,</booktitle>
<pages>414--423</pages>
<contexts>
<context position="5325" citStr="Li et al., 2010" startWordPosition="786" endWordPosition="789">ta filtering approach to filter low-confident unlabeled samples. Section 5 evaluates our approach with a benchmark dataset. Finally, Section 6 gives the conclusion and future work. 2 Related Work Early studies on sentiment classification mainly focus on supervised learning methods with algorithm designing and feature engineering (Pang et al., 2002; Cui et al., 2006; Riloff et al., 2006; Li et al., 2009). Recently, most studies on sentiment classification aim to improve the performance by exploiting unlabeled data in two main aspects: semi-supervised learning (Dasgupta and Ng, 2009; Wan, 2009; Li et al., 2010) and cross-domain learning (Blitzer et al. 2007; He et al. 2011; Li et al., 2013). Specifically, existing approaches to semi-supervised sentiment classification could be categorized into two main groups: bootstrappingstyle and graph-based. As for bootstrapping-style approaches, Wan (2009) considers two different languages as two views and applies co-training to conduct semi-supervised sentiment classification. Similarly, Li et al. (2010) propose two views, named personal and impersonal views, and apply co-training to use unlabeled data in a monolingual corpus. More recently, Gao et al. (2014) </context>
</contexts>
<marker>Li, Huang, Zhou, Lee, 2010</marker>
<rawString>Li S., C. Huang, G. Zhou and S. Lee. 2010. Employing Personal/Impersonal Views in Supervised and Semi-supervised Sentiment Classification. In Proceedings of ACL-10, pp.414-423.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Li</author>
<author>R Xia</author>
<author>C Zong</author>
<author>C Huang</author>
</authors>
<title>A Framework of Feature Selection Methods for Text Categorization.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP-09,</booktitle>
<pages>692--700</pages>
<contexts>
<context position="5115" citStr="Li et al., 2009" startWordPosition="755" endWordPosition="758">as follows. Section 2 overviews the related work on semi-supervised sentiment classification. Section 3 proposes our semi-stacking strategy to semi-supervised sentiment classification. Section 4 proposes the data filtering approach to filter low-confident unlabeled samples. Section 5 evaluates our approach with a benchmark dataset. Finally, Section 6 gives the conclusion and future work. 2 Related Work Early studies on sentiment classification mainly focus on supervised learning methods with algorithm designing and feature engineering (Pang et al., 2002; Cui et al., 2006; Riloff et al., 2006; Li et al., 2009). Recently, most studies on sentiment classification aim to improve the performance by exploiting unlabeled data in two main aspects: semi-supervised learning (Dasgupta and Ng, 2009; Wan, 2009; Li et al., 2010) and cross-domain learning (Blitzer et al. 2007; He et al. 2011; Li et al., 2013). Specifically, existing approaches to semi-supervised sentiment classification could be categorized into two main groups: bootstrappingstyle and graph-based. As for bootstrapping-style approaches, Wan (2009) considers two different languages as two views and applies co-training to conduct semi-supervised se</context>
</contexts>
<marker>Li, Xia, Zong, Huang, 2009</marker>
<rawString>Li S., R. Xia, C. Zong, and C. Huang. 2009. A Framework of Feature Selection Methods for Text Categorization. In Proceedings of ACL-IJCNLP-09, pp.692-700.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Li</author>
<author>Y Xue</author>
<author>Z Wang</author>
<author>G Zhou</author>
</authors>
<title>Active Learning for Cross-Domain Sentiment Classification.</title>
<date>2013</date>
<booktitle>In Proceedings of IJCAI-13,</booktitle>
<pages>2127--2133</pages>
<contexts>
<context position="2619" citStr="Li et al. (2013)" startWordPosition="377" endWordPosition="380">performance * Corresponding author of sentiment classification. However, semi-supervised sentiment classification remains challenging due to the following reason. Although various semi-supervised learning algorithms are now available and have been shown to be successful in exploiting unlabeled data to improve the performance in sentiment classification, each algorithm has its own characteristic with different pros and cons. It is rather difficult to tell which performs best in general. Therefore, it remains difficult to pick a suitable algorithm for a specific domain. For example, as shown in Li et al. (2013), the co-training algorithm with personal and impersonal views yields better performances in two product domains: Book and Kitchen, while the label propagation algorithm yields better performances in other two product domains: DVD and Electronic. In this paper, we overcome the above challenge above by combining two or more algorithms instead of picking one of them to perform semi-supervised learning. The basic idea of our algorithm ensemble approach is to apply meta-learning to re-predict the labels of the unlabeled data after obtaining their results from the member algorithms. First, a small </context>
<context position="5406" citStr="Li et al., 2013" startWordPosition="801" endWordPosition="804">tes our approach with a benchmark dataset. Finally, Section 6 gives the conclusion and future work. 2 Related Work Early studies on sentiment classification mainly focus on supervised learning methods with algorithm designing and feature engineering (Pang et al., 2002; Cui et al., 2006; Riloff et al., 2006; Li et al., 2009). Recently, most studies on sentiment classification aim to improve the performance by exploiting unlabeled data in two main aspects: semi-supervised learning (Dasgupta and Ng, 2009; Wan, 2009; Li et al., 2010) and cross-domain learning (Blitzer et al. 2007; He et al. 2011; Li et al., 2013). Specifically, existing approaches to semi-supervised sentiment classification could be categorized into two main groups: bootstrappingstyle and graph-based. As for bootstrapping-style approaches, Wan (2009) considers two different languages as two views and applies co-training to conduct semi-supervised sentiment classification. Similarly, Li et al. (2010) propose two views, named personal and impersonal views, and apply co-training to use unlabeled data in a monolingual corpus. More recently, Gao et al. (2014) propose a feature subspace-based self-training to semi-supervised sentiment class</context>
</contexts>
<marker>Li, Xue, Wang, Zhou, 2013</marker>
<rawString>Li S., Y. Xue, Z. Wang, and G. Zhou. 2013. Active Learning for Cross-Domain Sentiment Classification. In Proceedings of IJCAI-13, pp.2127-2133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Li</author>
<author>Z Wang</author>
<author>G Zhou</author>
<author>S Lee</author>
</authors>
<title>Semi-supervised Learning for Imbalanced Sentiment Classification.</title>
<date>2011</date>
<booktitle>In Proceedings of IJCAI-11,</booktitle>
<pages>1826--1831</pages>
<contexts>
<context position="1773" citStr="Li et al., 2011" startWordPosition="254" endWordPosition="257"> is sentiment classification, which aims to determine the sentimental orientation a piece of text expresses (Pang et al., 2002). For instance, the sentence &amp;quot;I absolutely love this product.&amp;quot; is supposed to be determined as a positive expression in sentimental orientation. While early studies focus on supervised learning, where only labeled data are required to train the classification model (Pang et al., 2002), recent studies devote more and more to reduce the heavy dependence on the large amount of labeled data by exploiting semi-supervised learning approaches, such as co-training (Wan, 2009; Li et al., 2011), label propagation (Sindhwani and Melville, 2008), and deep learning (Zhou et al., 2013), to sentiment classification. Empirical evaluation on various domains demonstrates the effectiveness of the unlabeled data in enhancing the performance * Corresponding author of sentiment classification. However, semi-supervised sentiment classification remains challenging due to the following reason. Although various semi-supervised learning algorithms are now available and have been shown to be successful in exploiting unlabeled data to improve the performance in sentiment classification, each algorithm</context>
</contexts>
<marker>Li, Wang, Zhou, Lee, 2011</marker>
<rawString>Li S., Z. Wang, G. Zhou and S. Lee. 2011. Semi-supervised Learning for Imbalanced Sentiment Classification. In Proceedings of IJCAI-11, pp.1826-1831.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining (Introduction and Survey).</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool Publishers,</publisher>
<contexts>
<context position="1113" citStr="Liu, 2012" startWordPosition="149" endWordPosition="150">learning perspective. Specifically, we apply metalearning to predict the unlabeled data given the outputs from the member algorithms and propose N-fold cross validation to guarantee a suitable size of the data for training the meta-classifier. Evaluation on four domains shows that such a semi-stacking strategy performs consistently better than its member algorithms. 1 Introduction The past decade has witnessed a huge exploding interest in sentiment analysis from the natural language processing and data mining communities due to its inherent challenges and wide applications (Pang et al., 2008; Liu, 2012). One fundamental task in sentiment analysis is sentiment classification, which aims to determine the sentimental orientation a piece of text expresses (Pang et al., 2002). For instance, the sentence &amp;quot;I absolutely love this product.&amp;quot; is supposed to be determined as a positive expression in sentimental orientation. While early studies focus on supervised learning, where only labeled data are required to train the classification model (Pang et al., 2002), recent studies devote more and more to reduce the heavy dependence on the large amount of labeled data by exploiting semi-supervised learning </context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Liu B. 2012. Sentiment Analysis and Opinion Mining (Introduction and Survey). Morgan &amp; Claypool Publishers, May 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>Opinion Mining and Sentiment Analysis: Foundations and Trends.</title>
<date>2008</date>
<journal>Information Retrieval,</journal>
<volume>2</volume>
<issue>12</issue>
<pages>1--135</pages>
<marker>Pang, Lee, 2008</marker>
<rawString>Pang B. and L. Lee. 2008. Opinion Mining and Sentiment Analysis: Foundations and Trends. Information Retrieval, vol.2(12), pp.1-135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
<author>S Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment Classification using Machine Learning Techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP-02,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="1284" citStr="Pang et al., 2002" startWordPosition="174" endWordPosition="177">ation to guarantee a suitable size of the data for training the meta-classifier. Evaluation on four domains shows that such a semi-stacking strategy performs consistently better than its member algorithms. 1 Introduction The past decade has witnessed a huge exploding interest in sentiment analysis from the natural language processing and data mining communities due to its inherent challenges and wide applications (Pang et al., 2008; Liu, 2012). One fundamental task in sentiment analysis is sentiment classification, which aims to determine the sentimental orientation a piece of text expresses (Pang et al., 2002). For instance, the sentence &amp;quot;I absolutely love this product.&amp;quot; is supposed to be determined as a positive expression in sentimental orientation. While early studies focus on supervised learning, where only labeled data are required to train the classification model (Pang et al., 2002), recent studies devote more and more to reduce the heavy dependence on the large amount of labeled data by exploiting semi-supervised learning approaches, such as co-training (Wan, 2009; Li et al., 2011), label propagation (Sindhwani and Melville, 2008), and deep learning (Zhou et al., 2013), to sentiment classif</context>
<context position="5058" citStr="Pang et al., 2002" startWordPosition="743" endWordPosition="746">t semi-stacking. The remainder of this paper is organized as follows. Section 2 overviews the related work on semi-supervised sentiment classification. Section 3 proposes our semi-stacking strategy to semi-supervised sentiment classification. Section 4 proposes the data filtering approach to filter low-confident unlabeled samples. Section 5 evaluates our approach with a benchmark dataset. Finally, Section 6 gives the conclusion and future work. 2 Related Work Early studies on sentiment classification mainly focus on supervised learning methods with algorithm designing and feature engineering (Pang et al., 2002; Cui et al., 2006; Riloff et al., 2006; Li et al., 2009). Recently, most studies on sentiment classification aim to improve the performance by exploiting unlabeled data in two main aspects: semi-supervised learning (Dasgupta and Ng, 2009; Wan, 2009; Li et al., 2010) and cross-domain learning (Blitzer et al. 2007; He et al. 2011; Li et al., 2013). Specifically, existing approaches to semi-supervised sentiment classification could be categorized into two main groups: bootstrappingstyle and graph-based. As for bootstrapping-style approaches, Wan (2009) considers two different languages as two vi</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Pang B., L. Lee, and S. Vaithyanathan. 2002. Thumbs up? Sentiment Classification using Machine Learning Techniques. In Proceedings of EMNLP-02, pp.79-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>S Patwardhan</author>
<author>J Wiebe</author>
</authors>
<title>Feature Subsumption for Opinion Analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP-06,</booktitle>
<pages>440--448</pages>
<contexts>
<context position="5097" citStr="Riloff et al., 2006" startWordPosition="751" endWordPosition="754">s paper is organized as follows. Section 2 overviews the related work on semi-supervised sentiment classification. Section 3 proposes our semi-stacking strategy to semi-supervised sentiment classification. Section 4 proposes the data filtering approach to filter low-confident unlabeled samples. Section 5 evaluates our approach with a benchmark dataset. Finally, Section 6 gives the conclusion and future work. 2 Related Work Early studies on sentiment classification mainly focus on supervised learning methods with algorithm designing and feature engineering (Pang et al., 2002; Cui et al., 2006; Riloff et al., 2006; Li et al., 2009). Recently, most studies on sentiment classification aim to improve the performance by exploiting unlabeled data in two main aspects: semi-supervised learning (Dasgupta and Ng, 2009; Wan, 2009; Li et al., 2010) and cross-domain learning (Blitzer et al. 2007; He et al. 2011; Li et al., 2013). Specifically, existing approaches to semi-supervised sentiment classification could be categorized into two main groups: bootstrappingstyle and graph-based. As for bootstrapping-style approaches, Wan (2009) considers two different languages as two views and applies co-training to conduct </context>
</contexts>
<marker>Riloff, Patwardhan, Wiebe, 2006</marker>
<rawString>Riloff E., S. Patwardhan and J. Wiebe. 2006. Feature Subsumption for Opinion Analysis. In Proceedings of EMNLP-06, pp.440-448.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Sindhwani</author>
<author>P Melville</author>
</authors>
<title>Document-Word Co-Regularization for Semi-supervised Sentiment Analysis.</title>
<date>2008</date>
<booktitle>In Proceedings of ICDM-08,</booktitle>
<pages>1025--1030</pages>
<contexts>
<context position="1823" citStr="Sindhwani and Melville, 2008" startWordPosition="260" endWordPosition="263">ims to determine the sentimental orientation a piece of text expresses (Pang et al., 2002). For instance, the sentence &amp;quot;I absolutely love this product.&amp;quot; is supposed to be determined as a positive expression in sentimental orientation. While early studies focus on supervised learning, where only labeled data are required to train the classification model (Pang et al., 2002), recent studies devote more and more to reduce the heavy dependence on the large amount of labeled data by exploiting semi-supervised learning approaches, such as co-training (Wan, 2009; Li et al., 2011), label propagation (Sindhwani and Melville, 2008), and deep learning (Zhou et al., 2013), to sentiment classification. Empirical evaluation on various domains demonstrates the effectiveness of the unlabeled data in enhancing the performance * Corresponding author of sentiment classification. However, semi-supervised sentiment classification remains challenging due to the following reason. Although various semi-supervised learning algorithms are now available and have been shown to be successful in exploiting unlabeled data to improve the performance in sentiment classification, each algorithm has its own characteristic with different pros an</context>
<context position="6205" citStr="Sindhwani and Melville (2008)" startWordPosition="906" endWordPosition="909">strapping-style approaches, Wan (2009) considers two different languages as two views and applies co-training to conduct semi-supervised sentiment classification. Similarly, Li et al. (2010) propose two views, named personal and impersonal views, and apply co-training to use unlabeled data in a monolingual corpus. More recently, Gao et al. (2014) propose a feature subspace-based self-training to semi-supervised sentiment classification. Empirical evaluation demonstrates that subspace-based self-training outperforms co-training with personal and impersonal views. As for graph-based approaches, Sindhwani and Melville (2008) first construct a document-word bipartite graph to describe the relationship among the labeled and unlabeled samples and then apply label propagation to get the labels of the unlabeled samples. Unlike above studies, our research on semi-supervised sentiment classification does not merely focus on one single semi-supervised learning algorithm but on two or more semi-supervised learning algorithms with ensemble learning. To the best of our knowledge, this is the first attempt to combine two or more semi-supervised learning algorithms in semi-supervised sentiment classification. 3 Semi-Stacking </context>
<context position="13251" citStr="Sindhwani and Melville, 2008" startWordPosition="2007" endWordPosition="2011">proposed by Gao et al. (2014). This approach can be seen as a special case of self-training. Different from the traditional self-training, self-trainingFS use the feature-subspace classifier to make the prediction on the unlabeled samples instead of using the whole-space classifier. In our implementation, we use four random feature subspaces. (2) The second member algorithm is called label propagation, a graph-based semi-supervised learning approach, proposed by Zhu and Ghahramani (2002). In our implementation, the document-word bipartite graph is adopted to build the document-document graph (Sindhwani and Melville, 2008). Significance testing: We perform t-test to evaluate the significance of the performance difference between two systems with different approaches (Yang and Liu, 1999) Figure 4 compares the performances of the baseline approach and three semi-supervised learning approaches. Here, the baseline approach is the supervised learning approach by using only the initial labeled data (i.e. no unlabeled data is used). From the figure, we can see that both SelftrainingFS and label propagation are successful in exploiting unlabeled data to improve the performances. Self-trainingFS outperforms label propag</context>
</contexts>
<marker>Sindhwani, Melville, 2008</marker>
<rawString>Sindhwani V. and P. Melville. 2008. Document-Word Co-Regularization for Semi-supervised Sentiment Analysis. In Proceedings of ICDM-08, pp.1025-1030.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wan</author>
</authors>
<title>Co-Training for Cross-Lingual Sentiment Classification.</title>
<date>2009</date>
<booktitle>In Proceedings of ACLIJCNLP-09,</booktitle>
<pages>235--243</pages>
<contexts>
<context position="1755" citStr="Wan, 2009" startWordPosition="252" endWordPosition="253">nt analysis is sentiment classification, which aims to determine the sentimental orientation a piece of text expresses (Pang et al., 2002). For instance, the sentence &amp;quot;I absolutely love this product.&amp;quot; is supposed to be determined as a positive expression in sentimental orientation. While early studies focus on supervised learning, where only labeled data are required to train the classification model (Pang et al., 2002), recent studies devote more and more to reduce the heavy dependence on the large amount of labeled data by exploiting semi-supervised learning approaches, such as co-training (Wan, 2009; Li et al., 2011), label propagation (Sindhwani and Melville, 2008), and deep learning (Zhou et al., 2013), to sentiment classification. Empirical evaluation on various domains demonstrates the effectiveness of the unlabeled data in enhancing the performance * Corresponding author of sentiment classification. However, semi-supervised sentiment classification remains challenging due to the following reason. Although various semi-supervised learning algorithms are now available and have been shown to be successful in exploiting unlabeled data to improve the performance in sentiment classificati</context>
<context position="5307" citStr="Wan, 2009" startWordPosition="784" endWordPosition="785">oses the data filtering approach to filter low-confident unlabeled samples. Section 5 evaluates our approach with a benchmark dataset. Finally, Section 6 gives the conclusion and future work. 2 Related Work Early studies on sentiment classification mainly focus on supervised learning methods with algorithm designing and feature engineering (Pang et al., 2002; Cui et al., 2006; Riloff et al., 2006; Li et al., 2009). Recently, most studies on sentiment classification aim to improve the performance by exploiting unlabeled data in two main aspects: semi-supervised learning (Dasgupta and Ng, 2009; Wan, 2009; Li et al., 2010) and cross-domain learning (Blitzer et al. 2007; He et al. 2011; Li et al., 2013). Specifically, existing approaches to semi-supervised sentiment classification could be categorized into two main groups: bootstrappingstyle and graph-based. As for bootstrapping-style approaches, Wan (2009) considers two different languages as two views and applies co-training to conduct semi-supervised sentiment classification. Similarly, Li et al. (2010) propose two views, named personal and impersonal views, and apply co-training to use unlabeled data in a monolingual corpus. More recently, </context>
</contexts>
<marker>Wan, 2009</marker>
<rawString>Wan X. 2009. Co-Training for Cross-Lingual Sentiment Classification. In Proceedings of ACLIJCNLP-09, pp.235-243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Yang</author>
<author>X Liu</author>
</authors>
<title>A Re-Examination of Text Categorization Methods.</title>
<date>1999</date>
<booktitle>In Proceedings of SIGIR99.</booktitle>
<contexts>
<context position="13418" citStr="Yang and Liu, 1999" startWordPosition="2032" endWordPosition="2035">ce classifier to make the prediction on the unlabeled samples instead of using the whole-space classifier. In our implementation, we use four random feature subspaces. (2) The second member algorithm is called label propagation, a graph-based semi-supervised learning approach, proposed by Zhu and Ghahramani (2002). In our implementation, the document-word bipartite graph is adopted to build the document-document graph (Sindhwani and Melville, 2008). Significance testing: We perform t-test to evaluate the significance of the performance difference between two systems with different approaches (Yang and Liu, 1999) Figure 4 compares the performances of the baseline approach and three semi-supervised learning approaches. Here, the baseline approach is the supervised learning approach by using only the initial labeled data (i.e. no unlabeled data is used). From the figure, we can see that both SelftrainingFS and label propagation are successful in exploiting unlabeled data to improve the performances. Self-trainingFS outperforms label propagation in three domains including Book, DVD, and Kitchen but it performs worse in Electronic. Our approach (semi-stacking) performs much better than baseline with an im</context>
</contexts>
<marker>Yang, Liu, 1999</marker>
<rawString>Yang Y. and X. Liu. 1999. A Re-Examination of Text Categorization Methods. In Proceedings of SIGIR99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhu</author>
<author>Z Ghahramani</author>
</authors>
<title>Learning from Labeled and Unlabeled Data with Label Propagation.</title>
<date>2002</date>
<tech>CMU CALD Technical Report. CMU-CALD-02-107.</tech>
<contexts>
<context position="13114" citStr="Zhu and Ghahramani (2002)" startWordPosition="1987" endWordPosition="1991">ere probability outputs are provided. Semi-supervised learning algorithms: (1) The first member algorithm is called self-trainingFS, proposed by Gao et al. (2014). This approach can be seen as a special case of self-training. Different from the traditional self-training, self-trainingFS use the feature-subspace classifier to make the prediction on the unlabeled samples instead of using the whole-space classifier. In our implementation, we use four random feature subspaces. (2) The second member algorithm is called label propagation, a graph-based semi-supervised learning approach, proposed by Zhu and Ghahramani (2002). In our implementation, the document-word bipartite graph is adopted to build the document-document graph (Sindhwani and Melville, 2008). Significance testing: We perform t-test to evaluate the significance of the performance difference between two systems with different approaches (Yang and Liu, 1999) Figure 4 compares the performances of the baseline approach and three semi-supervised learning approaches. Here, the baseline approach is the supervised learning approach by using only the initial labeled data (i.e. no unlabeled data is used). From the figure, we can see that both SelftrainingF</context>
</contexts>
<marker>Zhu, Ghahramani, 2002</marker>
<rawString>Zhu X. and Z. Ghahramani. 2002. Learning from Labeled and Unlabeled Data with Label Propagation. CMU CALD Technical Report. CMU-CALD-02-107.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>