<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001876">
<title confidence="0.993446">
FAdR: A System for Recognizing False Online Advertisements
</title>
<author confidence="0.997424">
Yi-jie Tang and Hsin-Hsi Chen
</author>
<affiliation confidence="0.998466">
Department of Computer Science and Information Engineering
National Taiwan University, Taipei, Taiwan
</affiliation>
<email confidence="0.986966">
tangyj@nlg.csie.ntu.edu.tw;hhchen@ntu.edu.tw
</email>
<sectionHeader confidence="0.982515" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99998225">
More and more product information, in-
cluding advertisements and user reviews,
are presented to Internet users nowadays.
Some of the information is false, mislead-
ing or overstated, which can cause seri-
ousness and needs to be identified. Au-
thorities, advertisers, website owners and
consumers all have the needs to detect
such statements. In this paper, we propose
a False Advertisements Recognition sys-
tem called FAdR by using one-class and
binary classification models. Illegal adver-
tising lists made public by a government
and product descriptions from a shopping
website are obtained for training and test-
ing. The results show that the binary SVM
models can achieve the highest perfor-
mance when unigrams with the weighting
of log relative frequency ratios are used as
features. Comparatively, the benefit of the
one-class classification models is the ad-
justable rejection rate parameter, which
can be changed to suit different applica-
tions. Verb phrases more likely to intro-
duce overstated information are obtained
by mining the datasets. These phrases help
find problematic wordings in the advertis-
ing texts.
</bodyText>
<sectionHeader confidence="0.995135" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999969">
As online commerce and advertising keep grow-
ing, more and more consumers depend on infor-
mation on the Internet to make purchasing deci-
sions. This kind of information includes online
advertisements posted by businesses, and discus-
sions or reviews generated by users. However,
false statements can also be presented to con-
sumers. For example, some companies hire peo-
ple to post fake product reviews in an attempt to
promote their own products or reduce competi-
tors’ reputations (Ott et al., 2011). It is referred
to as deceptive opinion spamming and explored
in recent researches (Ott et al., 2011; Mukherjee
et al., 2012; Mukherjee et al., 2013; Fei et al.,
2013).
False statements and exaggerated content can
also be seen in online advertisements. These
statements can also be regarded as opinion
spams, while the authors, that is, the advertisers,
can be more easily identified. Yeh (2014) report-
ed the top two types of illegal advertisements on
the web, TV and broadcast are food (62.61%)
and cosmetic (24.26%). Of the dissemination
media, the web is the major source of false ad-
vertisements. Most inappropriate food-related
advertisements contain overstated health claims.
The medical effects and cure claims may also
appear in cosmetic advertising. As a result, ad-
vertising regulations are enforced in many coun-
tries to protect consumers from fraudulent and
misleading information. False, overstated or mis-
leading information and mentions of curative
effects can be prohibited by the authorities (FTC,
2000; DOH, 2009; CFIA, 2010).
To regulate online advertising, the authorities
need to review a large number of advertisements
and determine their legality, which is cost- and
time-consuming. Advertisers also need to know
the legality of their advertisements to avoid vio-
lating advertising laws. This becomes especially
important when every Internet user can be an
advertiser if s/he posts messages related to any
product announcement, promotion, or sales.
Website owners that accept advertisements have
to present appropriate advertisement contents to
users and avoid legal issues. Even Internet users
should also identify false advertisements in order
not to be misled. Thus, the recognition of false,
misleading or overstated information is an
emerging task.
This paper presents a False Advertisements
Recognition system called FAdR, and take two
</bodyText>
<page confidence="0.675724">
103
</page>
<bodyText confidence="0.968725636363636">
Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 103–108,
Baltimore, Maryland USA, June 23-24, 2014. c�2014 Association for Computational Linguistics
major sources of illegal advertisements on the
web, i.e., food and cosmetic advertising, as ex-
amples. Section 2 surveys the related work. Sec-
tion 3 introduces the datasets used in the experi-
ments. Section 4 presents classification models
and shows their performance. Section 5 mines
the overstated phrases. Section 6 demonstrates
the uses of FAdR system with screenshot. Both
sentence and document levels are considered.
</bodyText>
<sectionHeader confidence="0.999345" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99998188">
Gokhman et al. (2012) collected data from the
Internet and explored methods to construct a
gold standard corpus for “deception” studies. Ott
et al. (2011) studied methods to detect “disrup-
tive opinion spams.” Unlike conventional adver-
tising spams, these fake opinions look authentic
and are used to mislead users. Mukherjee et al.
(2013) used reviewer’s behavioral footprints to
detect spammer. As they pointed out, one of the
largest problems to solve this issue is that there is
no appropriate datasets for fake and non-fake
reviews.
Previous online advertising research mostly
focuses on bidding, matching or recommendation
of advertisements on websites. Ghosh et al.
(2009) studied bidding strategies for advertise-
ment allocations. Huang et al. (2008) proposed
an advertisement recommendation method by
classifying instant messages into the Yahoo cate-
gories. Scaiano and Inkpen (2011) used Wikipe-
dia for negative keyphrase generation to hide
advertisements that users are not interested in.
This paper, in contrast, focuses on identifying
false statements in online advertisements with
classification models.
</bodyText>
<sectionHeader confidence="0.99734" genericHeader="method">
3 Datasets
</sectionHeader>
<bodyText confidence="0.9999073">
We use the illegal advertising lists and state-
ments made public by the Taipei City Govern-
ment1 as the illegal advertising datasets. The con-
tents of the government data are split into sen-
tences by colon, period, question mark and ex-
clamation mark. Two types of datasets are built
for illegal food and cosmetic advertising, named
FOOD_ILLEGAL and COS_ILLEGAL, respec-
tively. Some illegal sentences in the illegal food
advertising dataset are shown below:
</bodyText>
<figure confidence="0.392897">
(1) 減少代謝廢物的堆積°
Reduces waste produced by metabolism
process.
(2) 減少失眠及疼r°
1 http://www.health.gov.tw/Default.aspx?tabid=295
Stops insomnia and pain.
(3) 治療高血壓 °
</figure>
<bodyText confidence="0.9927954">
Cures hypertension.
In the government website, the authority does
not regularly announce legal advertising data.
We adopt one-class classifiers with only illegal
data for this scenario, as shown in Section 4.1.
To experiment on binary classifiers, we collect
product descriptions from a shopping website2
and verify their legality manually to construct the
legal advertising datasets. The legal food and
cosmetic adverting datasets are named
FOOD_LEGAL and COS_LEGAL, respectively.
The numbers of the sentences in
FOOD_LEGAL, FOOD_ILLEGAL,
COS_LEGAL, and COS_ILLEGAL are 5,059,
7,033, 10,520, and 11,381, respectively.
</bodyText>
<sectionHeader confidence="0.997441" genericHeader="method">
4 Classification Models
</sectionHeader>
<bodyText confidence="0.994728666666667">
One-class Naïve Bayes and Bagging classifiers,
and binary classifiers based on Naïve Bayes and
SVM models are implemented.
</bodyText>
<subsectionHeader confidence="0.947702">
4.1 One-Class Classifiers
</subsectionHeader>
<bodyText confidence="0.999753">
We adopt the OneClassClassifier module
(Hempstalk et al., 2008) in the WEKA machine
learning tool to train one-class classifiers with
illegal statements only. The OneClassClassifier
module provides a rejection rate parameter for
adjusting the threshold between target and non-
target instances. The target class, which corre-
sponds to the illegal class in this study, is the
single class used to train the classifier. Higher
rejection rate means that more legal statements
will be preferred, but illegal statements may be
still incorrectly classified into legal ones. Naïve
Bayes and Bagging classifiers are chosen be-
cause they achieve best performance among the
algorithms we have explored in this experiment.
Each instance in the dataset, i.e., a sentence, is
represented by a word vector (w1, w2, É, w1000),
where wi is a binary value indicating whether a
word occurs in the sentence or not. The vocabu-
lary is selected from the illegal advertising da-
tasets. To properly filter out common words, we
count top 1,000 frequent words in the Sinica
Balanced Corpus of Modern Chinese3 and re-
move them from the vocabulary. The remaining
top 1,000 words are used for vector representation.
Total 532 illegal statements provided by the
Department of Health form the training set. An
</bodyText>
<footnote confidence="0.9117865">
2 http://www.7net.com.tw
3 http://app.sinica.edu.tw/kiwi/mkiwi/
</footnote>
<page confidence="0.824146">
104
</page>
<bodyText confidence="0.999639181818182">
illegal and a legal advertising dataset make up
the test set. The former consists of 317 illegal
sentences from Taipei City Government’s lists,
and the latter contains 203 legal statement exam-
ples from the Department of Health.
Table 1 shows the accuracies of Naïve Bayes
and Bagging classifiers in the food dataset. The
rejection rates from 0.7 to 0.8 are preferable for
most applications, because they result in higher
accuracy for legal statement classification while
not significantly reducing the performance of
illegal statement detection. Using the 0.7 rejec-
tion rate produces high performance for the ille-
gal class while 0.8 rejection rate does better for
the legal class. The actual choice of rejection
rate depends on the demands of users. For an
advertiser, it is important to avoid all possible
problematic statements. Thus, a lower rejection
rate will be more suitable. If the system is used
by the authorities, a rejection rate higher than 0.7
may be preferable because they don’t misjudge
too many legal advertisements.
</bodyText>
<table confidence="0.999926833333333">
Rejection rate 0.4 0.5 0.6 0.7 0.8 0.9
Naïve Illegal 85.33% 82.39% 79.01% 74.49% 68.17% 59.14%
Bayes
Legal 31.07% 39.81% 53.40% 63.11% 72.82% 86.41%
Bagging Illegal 92.78% 88.49% 84.65% 74.94% 69.07% 0.23%
Legal 3.88% 17.48% 27.18% 65.72% 82.52% 99.77%
</table>
<tableCaption confidence="0.9933535">
Table 1: Accuracies of Classifiers in Different Rejec-
tion Rates.
</tableCaption>
<subsectionHeader confidence="0.989853">
4.2 Binary Classifiers
</subsectionHeader>
<bodyText confidence="0.986365838709677">
We use FOOD LEGAL and FOOD ILLEGAL
_ _
datasets, and COS_LEGAL and COS_ILLEGAL
datasets to build binary classifiers for food and
cosmetic advertising classification, respectively.
Naïve Bayes classifiers and SVM classifiers im-
plemented with libSVM (Chang &amp; Lin, 2011) are
adopted. Ten-fold cross validation is used for the
training and testing tasks. Total 1,000 highly fre-
quent words are selected in the same way as in
Section 4.1 to form a word-based unigram fea-
ture set.
Two weighting schemes are considered. In the
binary weighting, each sentence is represented
by a word vector (w1, w2, É, w1000), where wi is a
binary value indicating whether a word occurs in
the sentence or not. In the weighting of log rela-
tive frequency ratio, we follow the idea of collo-
cation mining (Damerau, 1993). Relative fre-
quency ratio between two datasets has been
shown to be useful to discover collocations that
are characteristic of a dataset when compared to
the other dataset. It has been successfully applied
to mine sentiment words from microblog and to
model reader/writer emotion transition (Tang and
Chen, 2011, 2012).
The log relative frequency ratio (logRF) is
defined formally as follows. Given two datasets
A and B, the log relative frequency ratio for each
wi∈A∪B is computed with the following formula.
fA(wi)
</bodyText>
<equation confidence="0.963791">
 |A |
fB(wi)
 |B |
</equation>
<bodyText confidence="0.990710291666667">
logRFAB(wi) is a log ratio of relative frequen-
cies of word wi in A and B, fA(wi) and fB(wi) are
frequencies of wi in A and in B, respectively, and
|A |and |B |are total words in A and in B, respec-
tively. logRF values are used to estimate the dis-
tribution of the words in datasets A and B. If wi
has higher relative frequency in A than in B, then
logRFAB(wi)&gt;0, and vice versa. In our experi-
ments, logRF is used to present each unigram’s
distribution in the legal and illegal datasets, re-
placing the binary value for a unigram feature.
Tables 2 and 3 show the results of the classifi-
cation models with different combinations of
feature sets. When logRF is combined with Uni-
gram, the accuracy is significantly improved in
both the food and cosmetic datasets. We can also
see that the performance of all FOOD models are
higher than equivalent COS models. Possible
reasons may be that the effects of cosmetics are
related to body appearance, and inappropriate
cure claims are also related to body improvement
and appearance changes. There can be some
overlaps between the words used in legal and
illegal cosmetic advertising.
</bodyText>
<table confidence="0.999849">
Classification Mod- Naïve Bayes SVM
els →
Illegal vs. Legal →
Features ↓
Illegal Legal Illegal Legal
Unigram 92.59% 85.06% 89.46% 88.00%
Unigram + logRF 94.32% 86.37% 94.70% 91.68%
</table>
<tableCaption confidence="0.915905">
Table 2: Classification Accuracies for FOOD Datasets.
</tableCaption>
<table confidence="0.999970714285714">
Classification Mod- Naïve Bayes SVM
els →
Illegal vs. Legal →
Features ↓
Illegal Legal Illegal Legal
Unigram 86.48% 77.63% 82.47% 82.36%
Unigram + logRF 88.20% 83.06% 88.46% 83.41%
</table>
<tableCaption confidence="0.999096">
Table 3: Classification Accuracies for COS Datasets.
</tableCaption>
<sectionHeader confidence="0.93023" genericHeader="method">
5 Overstated Phrase Mining
</sectionHeader>
<bodyText confidence="0.999845">
Since the authority focuses on health claims in
advertising, almost all illegal statements an-
nounced by the government include an action
related to health improvement and a name that
refers to diseases or body conditions. Thus, we
can observe that most of the illegal statements
</bodyText>
<equation confidence="0.857189">
logRFAB(wi) =log
</equation>
<page confidence="0.573115">
105
</page>
<bodyText confidence="0.99996115">
recognized and forbidden by the authority con-
tain a health-related verb phrase consisting of a
transitive verb and an object. These illegal adver-
tising verb phrases can be mined from the da-
tasets for the government’s and advertisers’ ref-
erence. We can also use these verb phrases to
help the users of our system understand possible
reasons why the sentences in advertisements are
labeled as illegal.
We propose a mining method based on log
relative frequency ratio, which is described in
Section 4.2. We compute logRFAB(wi) to obtain
the words that are most likely to be used in ille-
gal advertising. We identify transitive verbs and
nouns in the word list based on POS tagging re-
sults generated by the CKIP parser4, and then use
them to examine if a verb phrase is presented in a
sentence. Total 979 verb phrases are mined from
the FOOD datasets, and 2,302 from the COS da-
taset. Table 4 shows some examples.
</bodyText>
<table confidence="0.999821785714286">
Dataset Illegal advertising verb phrases
Transitive verb Object noun
FOOD IN ImV
(improve) (physical condition)
fm&amp;quot;f U�
(inactivate) (bacteria)
fts isIM
(decompose) (cholesterol)
COS ilfL ImV
(purify) (body)
ff� 4 r
(ease) (pain)
MV Cf1m
(cure) (acne vulgaris)
</table>
<tableCaption confidence="0.965803">
Table 4: Example illegal verb phrases
mined from the FOOD and COS datasets.
</tableCaption>
<sectionHeader confidence="0.938451" genericHeader="method">
6 System Architecture
</sectionHeader>
<bodyText confidence="0.99891">
The FAdR system is composed of pre-
processing (Pre-Processor), recognition (Recog-
nizer), and explanation (Explainer) modules.
Figure 1 shows the overall system architecture.
</bodyText>
<subsectionHeader confidence="0.99005">
6.1 Pre-processing Module
</subsectionHeader>
<bodyText confidence="0.999946857142857">
Our classification models are sentence-based, so
the main purpose of the Pre-processor in the sys-
tem is detecting sentence boundaries. Four types
of punctuations, including period, colon, excla-
mation, and question mark, are used to segment a
document into sentences. Line breaks are also
regarded as a sentence boundary marker because
</bodyText>
<footnote confidence="0.353756">
4 http://ckipsvr.iis.sinica.edu.tw
</footnote>
<bodyText confidence="0.999769454545455">
many advertisements in Chinese put sentences in
separate lines and do not include any punctua-
tion. Sentences with less than three characters or
more than 80 characters are ignored.
Word segmentation is performed by using the
CKIP segmenter, which is an online service and
can be accessed through the TCP socket. Seg-
mented data will be represented by the corre-
sponding feature sets based on classification
model and converted to a format that the Recog-
nizer can read as input.
</bodyText>
<subsectionHeader confidence="0.613715">
Advertising Document
</subsectionHeader>
<bodyText confidence="0.75084025">
Advertising document
with sentence-based
legality labels and
explanations.
</bodyText>
<figureCaption confidence="0.991622">
Figure 1. System architecture of FAdR
</figureCaption>
<subsectionHeader confidence="0.994167">
6.2 Recognition Module
</subsectionHeader>
<bodyText confidence="0.9995688">
All processed sentences are sent from the Pre-
Processor to the Recognizer for legality identifi-
cation.
Since our training tasks are done in WEKA,
we can use the model files generated by WEKA
for implementing the Recognizer. The Recogniz-
er loads the pre-trained SVM models for food
and cosmetic advertising classification, and then
uses them for labeling the incoming sentences.
For the One-Class models, the model files are
pre-generated by training with different rejection
rates from 0.4 to 0.9. When the user adjusts the
threshold, the Recognizer chooses the corre-
sponding model to perform illegal sentences
identification.
</bodyText>
<figure confidence="0.994163769230769">
Recognizer
Explainer
Sentence
Segmenter
Word
Segmenter
Format
Converter
Pre-Processor
Classification
Models
Feature Sets
106
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.941587">
<title confidence="0.999778">FAdR: A System for Recognizing False Online Advertisements</title>
<author confidence="0.994819">Yi-jie Tang</author>
<author confidence="0.994819">Hsin-Hsi</author>
<affiliation confidence="0.99823">Department of Computer Science and Information National Taiwan University, Taipei,</affiliation>
<email confidence="0.991322">tangyj@nlg.csie.ntu.edu.tw;hhchen@ntu.edu.tw</email>
<abstract confidence="0.998551551724138">More and more product information, including advertisements and user reviews, are presented to Internet users nowadays. Some of the information is false, misleading or overstated, which can cause seriousness and needs to be identified. Authorities, advertisers, website owners and consumers all have the needs to detect such statements. In this paper, we propose syscalled using one-class and binary classification models. Illegal advertising lists made public by a government and product descriptions from a shopping website are obtained for training and testing. The results show that the binary SVM models can achieve the highest performance when unigrams with the weighting of log relative frequency ratios are used as features. Comparatively, the benefit of the one-class classification models is the adjustable rejection rate parameter, which can be changed to suit different applications. Verb phrases more likely to introduce overstated information are obtained by mining the datasets. These phrases help find problematic wordings in the advertising texts.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>