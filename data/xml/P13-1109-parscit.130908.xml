<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000201">
<title confidence="0.9993495">
Graph Propagation for Paraphrasing Out-of-Vocabulary Words in
Statistical Machine Translation∗
</title>
<author confidence="0.984902">
Majid Razmara1 Maryam Siahbani1 Gholamreza Haffari2 Anoop Sarkar1
</author>
<affiliation confidence="0.953227">
1 Simon Fraser University, Burnaby, BC, Canada
</affiliation>
<email confidence="0.963886">
{razmara,msiahban,anoop}@sfu.ca
</email>
<affiliation confidence="0.845825">
2 Monash University, Clayton, VIC, Australia
</affiliation>
<email confidence="0.99724">
reza@monash.edu
</email>
<sectionHeader confidence="0.976814" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999870454545454">
Out-of-vocabulary (oov) words or phrases
still remain a challenge in statistical machine
translation especially when a limited amount of
parallel text is available for training or when
there is a domain shift from training data to
test data. In this paper, we propose a novel
approach to finding translations for oov words.
We induce a lexicon by constructing a graph on
source language monolingual text and employ
a graph propagation technique in order to find
translations for all the source language phrases.
Our method differs from previous approaches
by adopting a graph propagation approach that
takes into account not only one-step (from oov
directly to a source language phrase that has a
translation) but multi-step paraphrases from oov
source language words to other source language
phrases and eventually to target language transla-
tions. Experimental results show that our graph
propagation method significantly improves per-
formance over two strong baselines under intrin-
sic and extrinsic evaluation metrics.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999941294117647">
Out-of-vocabulary (oov) words or phrases still re-
main a challenge in statistical machine translation.
SMT systems usually copy unknown words verba-
tim to the target language output. Although this is
helpful in translating a small fraction of oovs such
as named entities for languages with same writ-
ing systems, it harms the translation in other types
of oovs and distant language pairs. In general,
copied-over oovs are a hindrance to fluent, high
quality translation, and we can see evidence of this
in automatic measures such as BLEU (Papineni
et al., 2002) and also in human evaluation scores
such as HTER. The problem becomes more se-
vere when only a limited amount of parallel text is
available for training or when the training and test
data are from different domains. Even noisy trans-
lation of oovs can aid the language model to better
</bodyText>
<footnote confidence="0.89216875">
∗This research was partially supported by an NSERC,
Canada (RGPIN: 264905) grant. The third author was sup-
ported by an early career research award from Monash Uni-
versity to visit Simon Fraser University.
</footnote>
<bodyText confidence="0.9995602">
re-order the words in the target language (Zhang
et al., 2012).
Increasing the size of the parallel data can re-
duce the number of oovs. However, there will al-
ways be some words or phrases that are new to the
system and finding ways to translate such words
or phrases will be beneficial to the system. Re-
searchers have applied a number of approaches to
tackle this problem. Some approaches use pivot
languages (Callison-Burch et al., 2006) while oth-
ers use lexicon-induction-based approaches from
source language monolingual corpora (Koehn and
Knight, 2002; Garera et al., 2009; Marton et al.,
2009).
Pivot language techniques tackle this problem
by taking advantage of available parallel data be-
tween the source language and a third language.
Using a pivot language, oovs are translated into a
third language and back into the source language
and thereby paraphrases to those oov words are
extracted (Callison-Burch et al., 2006). For each
oov, the system can be augmented by aggregating
the translations of all its paraphrases and assign
them to the oov. However, these methods require
parallel corpora between the source language and
one or multiple pivot languages.
Another line of work exploits spelling and mor-
phological variants of oov words. Habash (2008)
presents techniques for online handling of oov
words for Arabic to English such as spelling ex-
pansion and morphological expansion. Huang et
al. (2011) proposes a method to combine sub-
lexical/constituent translations of an oov word or
phrase to generate its translations.
Several researchers have applied lexicon-
induction methods to create a bilingual lexicon
for those oovs. Marton et al. (2009) use a mono-
lingual text on the source side to find paraphrases
to oov words for which the translations are avail-
able. The translations for these paraphrases are
</bodyText>
<page confidence="0.950793">
1105
</page>
<note confidence="0.9132695">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1105–1115,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999863962962963">
then used as the translations of the oov word.
These methods are based on the distributional hy-
pothesis which states that words appearing in the
same contexts tend to have similar meaning (Har-
ris, 1954). Marton et al. (2009) showed that this
method improves over the baseline system where
oovs are untranslated.
We propose a graph propagation-based exten-
sion to the approach of Marton et al. (2009) in
which a graph is constructed from source language
monolingual text1 and the source-side of the avail-
able parallel data. Nodes that have related mean-
ings are connected together and nodes for which
we have translations in the phrase-table are an-
notated with target-side translations and their fea-
ture values. A graph propagation algorithm is then
used to propagate translations from labeled nodes
to unlabeled nodes (phrases appearing only in the
monolingual text and oovs). This provides a gen-
eral purpose approach to handle several types of
oovs, including morphological variants, spelling
variants and synonyms2.
Constructing such a huge graph and propagat-
ing messages through it pose severe computational
challenges. Throughout the paper, we will see how
these challenges are dealt with using scalable algo-
rithms.
</bodyText>
<sectionHeader confidence="0.981163" genericHeader="method">
2 Collocational Lexicon Induction
</sectionHeader>
<bodyText confidence="0.999787266666667">
Rapp (1995) introduced the notion of a distribu-
tional profile in bilingual lexicon induction from
monolingual data. A distributional profile (DP) of
a word or phrase type is a co-occurrence vector
created by combining all co-occurrence vectors of
the tokens of that phrase type. Each distributional
profile can be seen as a point in a |V |-dimensional
space where V is the vocabulary where each word
type represents a unique axis. Points (i.e. phrase
types) that are close to one another in this high-
dimensional space can represent paraphrases. This
approach has also been used in machine trans-
lation to find in-vocabulary paraphrases for oov
words on the source side and find a way to trans-
late them.
</bodyText>
<subsectionHeader confidence="0.993245">
2.1 Baseline System
</subsectionHeader>
<bodyText confidence="0.9982615">
Marton et al. (2009) was the first to successfully
integrate a collocational approach to finding trans-
</bodyText>
<footnote confidence="0.9964695">
1Here on by monolingual data we always mean monolin-
gual data on the source language
2Named entity oovs may be handled properly by copying
or transliteration.
</footnote>
<bodyText confidence="0.999723344827586">
lations for oov words into an end-to-end SMT sys-
tem. We explain their method in detail as we will
compare against this approach. The method re-
lies on monolingual distributional profiles (DPs)
which are numerical vectors representing the con-
text around each word. The goal is to find words or
phrases that appear in similar contexts as the oovs.
For each oov a distributional profile is created by
collecting all words appearing in a fixed distance
from all occurrences of the oov word in the mono-
lingual text. These co-occurrence counts are con-
verted to an association measure (Section 2.2) that
encodes the relatedness of each pair of words or
phrases.
Then, the most similar phrases to each oov are
found by measuring the similarity of their DPs to
that of the oov word. Marton et al. (2009) uses
a heuristic to prune the search space for finding
candidate paraphrases by keeping the surrounding
context (e.g. L R) of each occurrences of the
oov word. All phrases that appear in any of such
contexts are collected as candidate paraphrases.
For each of these paraphrases, a DP is constructed
and compared to that of the oov word using a sim-
ilarity measure (Section 2.2).
The top-k paraphrases that have translations in
the phrase-table are used to assign translations and
scores to each oov word by marginalizing transla-
tions over paraphrases:
</bodyText>
<equation confidence="0.981116333333333">
Y:
p(t|o) = p(t|s)p(s|o)
s
</equation>
<bodyText confidence="0.999958384615385">
where t is a phrase on the target side, o is the oov
word or phrase, and s is a paraphrase of o. p(s|o)
is estimated using a similarity measure over DPs
and p(t|s) is coming from the phrase-table.
We reimplemented this collocational approach
for finding translations for oovs and used it as a
baseline system.
Alternative ways of modeling and comparing
distributional profiles have been proposed (Rapp,
1999; Fung and Yee, 1998; Terra and Clarke,
2003; Garera et al., 2009; Marton et al., 2009).
We review some of them here and compare their
performance in Section 4.3.
</bodyText>
<subsectionHeader confidence="0.999302">
2.2 Association Measures
</subsectionHeader>
<bodyText confidence="0.999863666666667">
Given a word u, its distributional profile DP(u)
is constructed by counting surrounding words (in
a fixed window size) in a monolingual corpus.
</bodyText>
<equation confidence="0.98684">
DP(u) = I(A(u,wi))  |wi E V }
</equation>
<page confidence="0.931786">
1106
</page>
<bodyText confidence="0.9990830625">
The counts can be collected in positional3 (Rapp,
1999) or non-positional way (count all the word
occurrences within the sliding window). A(·, ·)
is an association measure and can simply be de-
fined as co-occurrence counts within sliding win-
dows. Stronger association measures can also be
used such as:
Conditional probability: the probability for the
occurrence of each word in DP given the occur-
rence of u: CP(u,wi) = P(wi|u) (Sch¨utze and
Pedersen, 1997)
Pointwise Mutual Information: this measure is
a transformation of the independence assumption
into a ratio. Positive values indicate that words
co-occur more than what we expect under the in-
dependence assumption (Lin, 1998):
</bodyText>
<equation confidence="0.9969382">
PMI(u, wi) = log2 P(u)P(wi)
Likelihood ratio: (Dunning, 1993) uses the like-
lihood ratio for word similarity:
_ L(P(wi|u);p) ∗ L(P(wi|¬u);p)
λ(u, wi) — L(P (wi|u); p1) ∗ L(P (wi|¬u); p2)
</equation>
<bodyText confidence="0.99924">
where L is likelihood function under the assump-
tion that word counts in text have binomial distri-
butions. The numerator represents the likelihood
of the hypothesis that u and wi are independent
</bodyText>
<equation confidence="0.7368075">
(P(wi|u) = P(wi|¬u) = p) and the denomina-
tor represents the likelihood of the hypothesis that
u and wi are dependent (P(wi|u) =6 P(wi|¬u) ,
P(wi|u) = p1, P(wi|¬u) = p2 )4.
</equation>
<bodyText confidence="0.993781428571428">
Chi-square test: is a statistical hypothesis testing
method to evaluate independence of two categori-
cal random variables, e.g. whether the occurrence
of u and wi (denoted by x and y respectively) are
independent. The test statistics χ2(u,wi) is the
deviation of the observed counts fx,y from their
expected values Ex,y:
</bodyText>
<equation confidence="0.917532">
�χ2(u, wi) :=
xE{wi,—wi}
</equation>
<subsectionHeader confidence="0.997108">
2.3 Similarity Measures
</subsectionHeader>
<bodyText confidence="0.9765495">
Various functions have been used to estimate
the similarity between distributional profiles.
3e.g., position 1 is the word immediately after, position -1
is the word immediately before etc.
</bodyText>
<footnote confidence="0.9817335">
4Binomial distribution B(k; n, θ) gives the probability of
observing k heads in n tosses of a coin where the coin pa-
rameter is θ. In our context, p, p1 and p2 are parameters of
Binomial distributions estimated using maximum likelihood.
</footnote>
<bodyText confidence="0.9906255">
Given two distributional profiles DP(u) and
DP(v), some similarity functions can be defined
as follows. Note that A(·, ·) stands for the various
association measures defined in Sec. 2.2.
Cosine coefficient is the cosine the angle between
two vectors DP(u) and DP(v):
</bodyText>
<equation confidence="0.980059">
cos(DP(u), DP(v)) =
EwiEV A(u, wi)A(v, wi)
&apos; EwiEV A(u, wi)2&apos; EwiEV A(v, wi)2
</equation>
<bodyText confidence="0.999844">
L1-Norm computes the accumulated distance
between entries of two distributional profiles
(L1(·, ·)). It has been used as word similarity mea-
sure in language modeling (Dagan et al., 1999).
</bodyText>
<equation confidence="0.9984195">
L1(DP(u), DP(v)) = � |A(u, wi)−A(v, wi)|
wiEV
</equation>
<bodyText confidence="0.967846">
Jensen-Shannon Divergence is a symmetric ver-
sion of contextual average mutual information
(KL) which is used by (Dagan et al., 1999) as
word similarity measure.
</bodyText>
<equation confidence="0.988138333333333">
JSD(DP(u), DP(v)) =KL(DP(u), AVGDP(u, v))+
KL(DP(v), AVGDP(u, v))
AV GDP(u, v) = S A(u, wi) 2 A(v, wi)  |wi ∈ V }
A(u, wi)
A(u, wi)log
A(v, wi)
</equation>
<sectionHeader confidence="0.966716" genericHeader="method">
3 Graph-based Lexicon Induction
</sectionHeader>
<bodyText confidence="0.9998884375">
We propose a novel approach to alleviate the oov
problem. Given a (possibly small amount of) par-
allel data between the source and target languages,
and a large monolingual data in the source lan-
guage, we construct a graph over all phrase types
in the monolingual text and the source side of the
parallel corpus and connect phrases that have sim-
ilar meanings (i.e. appear in similar context) to one
another. To do so, the distributional profiles of
all source phrase types are created. Each phrase
type represents a vertex in the graph and is con-
nected to other vertices with a weight defined by a
similarity measure between the two profiles (Sec-
tion 2.3). There are three types of vertices in the
graph: i) labeled nodes which appear in the par-
allel corpus and for which we have the target-side
</bodyText>
<equation confidence="0.882527">
P(u, wi)
� (fx,y − Ex,y)2
yE{u,—u} Ex,y
KL(DP(u), DP(v)) = �
wi∈V
</equation>
<page confidence="0.894489">
1107
</page>
<bodyText confidence="0.999668291666667">
translations5; ii) oov nodes from the dev/test set
for which we seek labels (translations); and iii) un-
labeled nodes (words or phrases) from the mono-
lingual data which appear usually between oov
nodes and labeled nodes. When a relatively small
parallel data is used, unlabeled nodes outnumber
labeled ones and many of them lie on the paths
between an oov node to labeled ones.
Marton et al. (2009)’s approach ignores these
bridging nodes and connects each oov node to the
k-nearest labeled nodes. One may argue that these
unlabeled nodes do not play a major role in the
graph and the labels will eventually get to the oov
nodes from the labeled nodes by directly connect-
ing them. However based on the definition of the
similarity measures using context, it is quite possi-
ble that an oov node and a labeled node which are
connected to the same unlabeled node do not share
any context words and hence are not directly con-
nected. For instance, consider three nodes, u (un-
labeled), o (oov) and l (labeled) where u has the
same left context words with o but share the right
context with l. o and l are not connected since they
do not share any context word.
Once a graph is constructed based on simi-
larities of phrases, graph propagation is used to
propagate the labels from labeled nodes to unla-
beled and oov nodes. The approach is based on
the smoothness assumption (Chapelle et al., 2006)
which states if two nodes are similar according to
the graph, then their output labels should also be
similar.
The baseline approach (Marton et al., 2009) can
be formulated as a bipartite graph with two types
of nodes: labeled nodes (L) and oov nodes (O).
Each oov node is connected to a number of labeled
nodes, and vice versa and there is no edge between
nodes of the same type. In such a graph, the sim-
ilarity of each pair of nodes is computed using
one of the similarity measures discussed above.
The labels are translations and their probabilities
(more specifically p(e|f)) from the phrase-table
extracted from the parallel corpus. Translations
get propagated to oov nodes using a label prop-
agation technique. However beside the difference
in the oov label assignment, there is a major differ-
ence between our bipartite graph and the baseline
(Marton et al., 2009): we do not use a heuristic to
</bodyText>
<footnote confidence="0.81358225">
5It is possible that a phrase appears in the parallel corpus,
but not in the phrase-table. This happens when the word-
alignment module is not able to align the phrase to a target
side word or words.
</footnote>
<bodyText confidence="0.999885411764706">
reduce the number of neighbor candidates and we
consider all possible candidates that share at least
one context word. This makes a significant differ-
ence in practice as shown in Section 4.3.1.
We also take advantage of unlabeled nodes to
help connect oov nodes to labeled ones. The dis-
cussed bipartite graph can easily be expanded to a
tripartite graph by adding unlabeled nodes. Fig-
ure 1 illustrate a tripartite graph in which unla-
beled nodes are connected to both labeled and oov
nodes. Again, there is no edge between nodes
of the same type. We also created the full graph
where all nodes can be freely connected to nodes
of any type including the same type. However,
constructing such graph and doing graph propa-
gation on it is computationally very expensive for
large n-grams.
</bodyText>
<subsectionHeader confidence="0.996892">
3.1 Label Propagation
</subsectionHeader>
<bodyText confidence="0.9998195">
Let G = (V, E, W) be a graph where V is the set
of vertices, E is the set of edges, and W is the edge
weight matrix. The vertex set V consists of la-
beled VL and unlabeled VU nodes, and the goal of
the labeling propagation algorithm is to compute
soft labels for unlabeled vertices from the labeled
vertices. Intuitively, the edge weight W (u, v) en-
codes the degree of our belief about the similarity
of the soft labeling for nodes u and v. A soft label
ˆYv ∈ Am+1 is a probability vector in (m + 1)-
dimensional simplex, where m is the number of
possible labels and the additional dimension ac-
counts for the undefined ⊥ label6.
In this paper, we make use of the modified Ad-
sorption (MAD) algorithm (Talukdar and Cram-
mer, 2009) which finds soft label vectors ˆYv to
solve the following unconstrained optimization
problem:
</bodyText>
<equation confidence="0.9776186">
p1,v||Yv − ˆYv||22 + (1)
�µ2 p2,vWv,u ||ˆYv − ˆYu||22 + (2)
v,u
�µ3 p3,v||ˆYv − Rv||2 (3)
v 2
</equation>
<bodyText confidence="0.999981666666667">
where µi and pi,v are hyper-parameters (∀v :
Ei pi,v = 1)7, and Rv ∈ Am+1 encodes our prior
belief about the labeling of a node v. The first
</bodyText>
<footnote confidence="0.5667118">
6Capturing those cases where the given data is not enough
to reliably compute a soft labeling using the initial m real
labels.
7The values of these hyper-parameters are set to their de-
faults in the Junto toolkit (Talukdar and Crammer, 2009).
</footnote>
<equation confidence="0.995479791666667">
�µ1
v∈VL
min
Yˆ
1108
O : oov nodes L : labeled nodes
t11 : p11
t12 : p12
t13 : p13
t21 : p21
t22 : p22
t23 : p23
t31 : p31
t32 : p32
t33 : p33
o3
o2
u1 u2 u3 u4 u5
o1
sim(o1, l1)
l1
l2
l3
U : unlabeled nodes
</equation>
<figureCaption confidence="0.999597">
Figure 1: A tripartite graph between oov, labeled and unlabeled nodes. Translations propagate either directly from labeled
nodes to oov nodes or indirectly via unlabeled nodes.
</figureCaption>
<bodyText confidence="0.984317352941177">
term (1) enforces the labeling of the algorithm to
match the seed labeling Y,, with different extent
for different labeled nodes. The second term (2)
enforces the smoothness of the labeling according
to the graph structure and edge weights. The last
term (3) regularizes the soft labeling for a vertex
v to match a priori label R,,, e.g. for high-degree
unlabeled nodes (hubs in the graph) we may be-
lieve that the neighbors are not going to produce
reliable label and hence the probability of unde-
fined label ⊥ should be higher. The optimiza-
tion problem can be solved with an efficient iter-
ative algorithm which is parallelized in a MapRe-
duce framework (Talukdar et al., 2008; Rao and
Yarowsky, 2009). We used the Junto label prop-
agation toolkit (Talukdar and Crammer, 2009) for
label propagation.
</bodyText>
<subsectionHeader confidence="0.999472">
3.2 Efficient Graph Construction
</subsectionHeader>
<bodyText confidence="0.999990289473684">
Graph-based approaches can easily become com-
putationally very expensive as the number of
nodes grow. In our case, we use phrases in the
monolingual text as graph vertices. These phrases
are n-grams up to a certain value, which can re-
sult in millions of nodes. For each node a distribu-
tional profile (DP) needs to be created. The num-
ber of possible edges can easily explode in size
as there can be as many as O(n2) edges where n
is the number of nodes. A common practice to
control the number of edges is to connect each
node to at most k other nodes (k-nearest neigh-
bor). However, finding the top-k nearest nodes to
each node requires considering its similarity to all
the other nodes which requires O(n2) computa-
tions and since n is usually very large, doing such
is practically intractable. Therefore, researchers
usually resort to an approximate k-NN algorithms
such as locality-sensitive hashing (?; Goyal et al.,
2012).
Fortunately, since we use context words as cues
for relating their meaning and since the similar-
ity measures are defined based on these cues, the
number of neighbors we need to consider for each
node is reduced by several orders of magnitude.
We incorporate an inverted-index-style data struc-
ture which indicates what nodes are neighbors
based on each context word. Therefore, the set
of neighbors of a node consists of union of all the
neighbors bridged by each context word in the DP
of the node. However, the number of neighbors to
be considered for each node even after this dras-
tic reduction is still large (in order of a few thou-
sands).
In order to deal with the computational chal-
lenges of such a large graph, we take advantage of
the Hadoop’s MapReduce functionality to do both
graph construction and label propagation steps.
</bodyText>
<sectionHeader confidence="0.997857" genericHeader="method">
4 Experiments &amp; Results
</sectionHeader>
<subsectionHeader confidence="0.820016">
4.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.9990135">
We experimented with two different domains for
the bilingual data: Europarl corpus (v7) (Koehn,
</bodyText>
<page confidence="0.963133">
1109
</page>
<table confidence="0.999921142857143">
Dataset Domain Sents Tokens En
Fr
Bitext Europarl 10K 298K 268K
EMEA 1M 16M 14M
Monotext Europarl 2M 60M –
Dev-set WMT05 2K 67K 58K
Test-set WMT05 2K 66K 58K
</table>
<tableCaption confidence="0.999912">
Table 1: Statistics of training sets in different domains.
</tableCaption>
<bodyText confidence="0.9971683125">
2005), and European Medicines Agency docu-
ments (EMEA) (Tiedemann, 2009) from French
to English. For the monolingual data, we used
French side of the Europarl corpus and we used
ACL/WMT 20058 data for dev/test sets. Table 1
summarizes statistics of the datasets used.
From the dev and test sets, we extract all source
words that do not appear in the phrase-table con-
structed from the parallel data. From the oovs, we
exclude numbers as well as named entities. We
apply a simple heuristic to detect named entities:
basically words that are capitalized in the original
dev/test set that do not appear at the beginning of
a sentence are named entities. Table 2 shows the
number of oov types and tokens for Europarl and
EMEA systems in both dev and test sets.
</bodyText>
<table confidence="0.9990325">
Dataset Dev Test
types tokens types tokens
Europarl 1893 2229 1830 2163
EMEA 2325 4317 2294 4190
</table>
<tableCaption confidence="0.991912">
Table 2: number of oovs in dev and test sets for Europarl and
EMEA systems.
</tableCaption>
<bodyText confidence="0.999652615384615">
For the end-to-end MT pipeline, we used
Moses (Koehn et al., 2007) with these stan-
dard features: relative-frequency and lexical trans-
lation model (TM) probabilities in both direc-
tions; distortion model; language model (LM)
and word count. Word alignment is done using
GIZA++ (Och and Ney, 2003). We used distortion
limit of 6 and max-phrase-length of 10 in all the
experiments. For the language model, we used the
KenLM toolkit (Heafield, 2011) to create a 5-gram
language model on the target side of the Europarl
corpus (v7) with approximately 54M tokens with
Kneser-Ney smoothing.
</bodyText>
<subsubsectionHeader confidence="0.930106">
4.1.1 Phrase-table Integration
</subsubsectionHeader>
<bodyText confidence="0.9924475">
Once the translations and their probabilities for
each oov are extracted, they are added to the
</bodyText>
<footnote confidence="0.820737">
8http://www.statmt.org/wpt05/mt-shared-task/
</footnote>
<bodyText confidence="0.9999074375">
phrase-table that is induced from the parallel text.
The probability for new entries are added as a
new feature in the log-linear framework to be
tuned along with other features. The value of
this newly introduced feature for original entries
in the phrase-table is set to 1. Similarly, the value
of original four probability features in the phrase-
table for the new entries are set to 1. The entire
training pipeline is as follows: (i) a phrase table is
constructed using parallel data as usual, (ii) oovs
for dev and test sets are extracted, (iii) oovs are
translated using graph propagation, (iv) oovs and
translations are added to the phrase table, intro-
ducing a new feature type, (v) the new phrase table
is tuned (with a LM) using MERT (Och, 2003) on
the dev set.
</bodyText>
<subsectionHeader confidence="0.937559">
4.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.999957740740741">
If we have a list of possible translations for oovs
with their probabilities, we become able to eval-
uate different methods we discussed. We word-
aligned the dev/test sets by concatenating them to
a large parallel corpus and running GIZA++ on
the whole set. The resulting word alignments are
used to extract the translations for each oov. The
correctness of this gold standard is limited to the
size of the parallel data used as well as the quality
of the word alignment software toolkit, and is not
100% precise. However, it gives a good estimate
of how each oov should be translated without the
need for human judgments.
For evaluating our baseline as well as graph-
based approaches, we use both intrinsic and
extrinsic evaluations. Two intrinsic evaluation
metrics that we use to evaluate the possible
translations for oovs are Mean Reciprocal Rank
(MRR) (Voorhees, 1999) and Recall. Intrinsic
evaluation metrics are faster to apply and are used
to optimize different hyper-parameters of the ap-
proach (e.g. window size, phrase length, etc.).
Once we come up with the optimized values for
the hyper-parameters, we extrinsically evaluate
different approaches by adding the new transla-
tions to the phrase-table and run it through the MT
pipeline.
</bodyText>
<subsectionHeader confidence="0.543558">
4.2.1 MRR
</subsectionHeader>
<bodyText confidence="0.9612476">
MRR is an Information Retrieval metric used to
evaluate any process that produces a ranked list of
possible candidates. The reciprocal rank of a list
is the inverse of the rank of the correct answer in
the list. Such score is averaged over a set, oov set
</bodyText>
<page confidence="0.72661">
1110
</page>
<equation confidence="0.9901398">
MRR (%)
in our case, to get the mean-reciprocal-rank score.
1
O = {oov}
ranki
</equation>
<bodyText confidence="0.9999822">
In a few cases, there are multiple translations for
an oov word (i.e. appearing more than once in the
parallel corpus and being assigned to multiple dif-
ferent phrases), we take the average of reciprocal
ranks for each of them.
</bodyText>
<subsectionHeader confidence="0.628701">
4.2.2 Recall
</subsectionHeader>
<bodyText confidence="0.996179388888889">
MRR takes the probabilities of oov translations
into account in sorting the list of candidate trans-
lations. However, in an MT pipeline, the language
model is supposed to rerank the hypotheses and
move more appropriate translations (in terms of
fluency) to the top of the list. Hence, we also
evaluate our candidate translation regardless of the
ranks. Since Moses uses a certain number of trans-
lations per source phrase (called the translation ta-
ble limit or ttl which we set to 20 in our experi-
ments) , we use the recall measure to evaluate the
top ttl translations in the list. Recall is another In-
formation Retrieval measure that is the fraction of
correct answers that are retrieved. For example, it
assigns score of 1 if the correct translation of the
oov word is in the top-k list and 0 otherwise. The
scores are averaged over all oovs to compute re-
call.
</bodyText>
<equation confidence="0.580316">
Recall =
</equation>
<bodyText confidence="0.9768365">
|{gold standard} n {candidate list}|
|{gold standard}|
</bodyText>
<subsectionHeader confidence="0.995134">
4.3 Intrinsic Results
</subsectionHeader>
<bodyText confidence="0.992962722222222">
In Section 2.2 and 2.3, different types of associa-
tion measures and similarity measures have been
explained to build and compare distributional pro-
files. Table 3 shows the results on Europarl when
using different similarity combinations. The mea-
sures are evaluated by fixing the window size to
4 and maximum candidate paraphrase length to 2
(e.g. bigram). First column shows the association
measures used to build DPs. As the results show,
the combination of PMI as association measure
and cosine as DP similarity measure outperforms
the other possible combinations. We use these two
measures throughout the rest of the experiments.
Figure 2 illustrates the effects of different win-
dow sizes and paraphrase lengths on MRR. As the
figure shows, the best MRR is reached when using
window size of 4 and trigram nodes. Going from
trigram to 4-gram results in a drop in MRR. One
</bodyText>
<table confidence="0.999408333333333">
Assoc cosine(%) RCL L1norm(%) RCL JSD(%) RCL
MRR MRR MRR
CP 1.66 4.16 2.18 5.55 2.33 6.32
LLR 1.79 4.26 0.13 0.37 0.5 1.00
PMI 3.91 7.75 0.50 1.17 0.59 1.21
Chi 1.66 4.16 0.26 0.55 0.03 0.05
</table>
<tableCaption confidence="0.9730725">
Table 3: Results of intrinsic evaluations (MRR and Recall)
on Europarl, window size 4 and paraphrase length 2
</tableCaption>
<figure confidence="0.987655875">
unigram bigram trigram quadgram
4.3
4.1
3.9
3.7
3.5
2 3 4 5 6 7
Window Size
</figure>
<figureCaption confidence="0.9935685">
Figure 2: Effects of different window sizes and paraphrase
length on the MRR of the dev set.
</figureCaption>
<bodyText confidence="0.999644944444444">
reason would be that distributional profiles for 4-
grams are very sparse and that negatively affects
the stability of similarity measures.
Figure 3 illustrates the effect of increasing the
size of monolingual text on both MRR and recall.
1x refers to the case of using 125k sentences for
the monolingual text and the 16x indicates using
the whole Europarl text on the source side (≈ 2M
sentences). As shown, there is a linear correla-
tion between the logarithm of the data size and
the MRR and recall ratios. Interestingly, MRR is
growing faster than recall by increasing the mono-
lingual text size, which means that the scoring
function gets better when more data is available.
The figure also indicates that a much bigger mono-
lingual text data can be used to further improve the
quality of the translations, however, at the expense
of more computational resources.
</bodyText>
<subsectionHeader confidence="0.446033">
Mono-text Size Ratio
</subsectionHeader>
<figureCaption confidence="0.988682">
Figure 3: Effect of increasing the monolingual text size on
MRR and Recall.
</figureCaption>
<figure confidence="0.986054928571429">
5
4
3
2
1
0
0 1x 2x 4x 8x 16x
Recall Ratio
MRR Ratio
1
MRR =
|O|
� Iol
i=1
</figure>
<page confidence="0.962199">
1111
</page>
<table confidence="0.9994746">
Graph Neighbor MRR % RCL %
Bipartite 20 5.2 12.5
Tripartite 15+5 5.9 12.6
Full 20 5.1 10.9
Baseline 20 3.7 7.2
</table>
<tableCaption confidence="0.982916">
Table 4: Intrinsic results of different types of graphs when
using unigram nodes on Europarl.
</tableCaption>
<table confidence="0.999929">
Type Node MRR % RCL %
Bipartite unigram 5.2 12.5
bigram 6.8 15.7
Tripartite unigram 5.9 12.6
bigram 6.9 15.9
Baseline bigram 3.9 7.7
</table>
<tableCaption confidence="0.999864">
Table 5: Results on using unigram or bigram nodes.
</tableCaption>
<subsectionHeader confidence="0.486619">
4.3.1 Graph-based Results
</subsectionHeader>
<bodyText confidence="0.999963090909091">
Table 4 shows the intrinsic results on the Eu-
roparl corpus when using unigram nodes in each
of the graphs. The results are evaluated on the
dev-set based on the gold alignment created us-
ing GIZA++. Each node is connected to at most
20 other nodes (same as the max-paraphrase-limit
in the baseline). For the tripartite graph, each
node is connected to 15 labeled nodes and 5 un-
labeled ones. The tripartite graph gets a slight im-
provement over the bipartite one, however, the full
graph failed to have the same increase. One rea-
son is that allowing paths longer than 2 between
oov and labeled nodes causes more noise to prop-
agate into the graph. In other words, a paraphrase
of a paraphrase of a paraphrase is not necessarily
a useful paraphrase for an oov as the translation
may no longer be a valid one.
Table 5 also shows the effect of using bigrams
instead of unigrams as graph nodes. There is an
improvement by going from unigrams to bigrams
in both bipartite and tripartite graphs. We did not
use trigrams or larger n-grams in our experiments.
</bodyText>
<subsectionHeader confidence="0.999296">
4.4 Extrinsic Results
</subsectionHeader>
<bodyText confidence="0.99173665">
The generated candidate translations for the oovs
can be added to the phrase-table created using
the parallel corpus to increase the coverage of the
phrase-table. This aggregated phrase-table is to be
tuned along with the language model on the dev
set, and run on the test set. BLEU (Papineni et
al., 2002) is still the de facto evaluation metric for
machine translation and we use that to measure
the quality of our proposed approaches for MT.
In these experiments, we do not use alignment in-
formation on dev or test sets unlike the previous
section.
Table 6 reports the Bleu scores for different do-
mains when the oov translations from the graph
propagation is added to the phrase-table and com-
pares them with the baseline system (i.e. Moses).
Results for our approach is based on unigram tri-
partite graphs and show that we improve over the
baseline in both the same-domain (Europarl) and
domain adaptation (EMEA) settings.
</bodyText>
<tableCaption confidence="0.993889">
Table 7 shows some translations found by our
system for oov words.
</tableCaption>
<table confidence="0.989062">
oov gold standard candiate list
undone particularly
particularly specific
sp´ecialement especially only
special particular
particular should
and
especially
assentiment approval support
agreement
approval
accession
will approve
endorses
</table>
<tableCaption confidence="0.9816585">
Table 7: Two examples of oov translations found by our
method.
</tableCaption>
<sectionHeader confidence="0.999366" genericHeader="method">
5 Related work
</sectionHeader>
<bodyText confidence="0.993255590909091">
There has been a long line of research on learning
translation pairs from non-parallel corpora (Rapp,
1995; Koehn and Knight, 2002; Haghighi et al.,
2008; Garera et al., 2009; Marton et al., 2009;
Laws et al., 2010). Most have focused on ex-
tracting a translation lexicon by mining monolin-
gual resources of data to find clues, using prob-
abilistic methods to map words, or by exploit-
ing the cross-language evidence of closely related
languages. Most of them evaluated only high-
frequency words of specific types (nouns or con-
tent words) (Rapp, 1995; Koehn and Knight, 2002;
Haghighi et al., 2008; Garera et al., 2009; Laws et
al., 2010) In contrast, we do not consider any con-
straint on our test data and our data includes many
low frequency words. It has been shown that trans-
lation of high-frequency words is easier than low
frequency words (Tamura et al., 2012).
Some methods have used a third language(s)
as pivot or bridge to find translation pairs (Mann
and Yarowsky, 2001; Schafer and Yarowsky, 2002;
Callison-Burch et al., 2006).
</bodyText>
<page confidence="0.974409">
1112
</page>
<table confidence="0.997512285714286">
Corpus System MRR Recall Dev Bleu Test Bleu
Europarl Baseline – – 28.53 28.97
Our approach 5.9 12.6 28.76 29.40*
EMEA Baseline – – 20.05 20.34
Our approach 3.6 7.4 20.54 20.80*
*
Statistically significant with p &lt; 0.02 using the bootstrap resampling significance test (in Moses).
</table>
<tableCaption confidence="0.998387">
Table 6: Bleu scores for different domains with or without using oov translations.
</tableCaption>
<bodyText confidence="0.999770034482759">
Context similarity has been used effectively in
bilingual lexicon induction (Rapp, 1995; Koehn
and Knight, 2002; Haghighi et al., 2008; Gar-
era et al., 2009; Marton et al., 2009; Laws et al.,
2010). It has been modeled in different ways: in
terms of adjacent words (Rapp, 1999; Fung and
Yee, 1998), or dependency relations (Garera et al.,
2009). Laws et al. (2010) used linguistic analy-
sis in the form of graph-based models instead of a
vector space. But all of these researches used an
available seed lexicon as the basic source of simi-
larity between source and target languages unlike
our method which just needs a monolingual cor-
pus of source language which is freely available
for many languages and a small bilingual corpora.
Some methods tried to alleviate the lack of seed
lexicon by using orthographic similarity to extract
a seed lexicon (Koehn and Knight, 2002; Fiser and
Ljubesic, 2011). But it is not a practical solution
in case of unrelated languages.
Haghighi et al. (2008) and Daum´e and Jagarla-
mudi (2011) proposed generative models based on
canonical correlation analysis to extract transla-
tion lexicons for non-parallel corpora by learning a
matching between source and target lexicons. Us-
ing monolingual features to represent words, fea-
ture vectors are projected from source and target
words into a canonical space to find the appropri-
ate matching between them. Their method relies
on context features which need a seed lexicon and
orthographic features which only works for phylo-
genetically related languages.
Graph-based semi-supervised methods have
been shown to be useful for domain adaptation in
MT as well. Alexandrescu and Kirchhoff (2009)
applied a graph-based method to determine simi-
larities between sentences and use these similari-
ties to promote similar translations for similar sen-
tences. They used a graph-based semi-supervised
model to re-rank the n-best translation hypothe-
sis. Liu et al. (2012) extended Alexandrescu’s
model to use translation consensus among simi-
lar sentences in bilingual training data by devel-
oping a new structured label propagation method.
They derived some features to use during decoding
process that has been shown useful in improving
translation quality. Our graph propagation method
connects monolingual source phrases with oovs to
obtain translation and so is a very different use of
graph propagation from these previous works.
Recently label propagation has been used for
lexicon induction (Tamura et al., 2012). They used
a graph based on context similarity as well as co-
occurrence graph in propagation process. Similar
to our approach they used unlabeled nodes in la-
bel propagation process. However, they use a seed
lexicon to define labels and comparable corpora to
construct graphs unlike our approach.
</bodyText>
<sectionHeader confidence="0.999015" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999963708333333">
We presented a novel approach for inducing oov
translations from a monolingual corpus on the
source side and a parallel data using graph prop-
agation. Our results showed improvement over
the baselines both in intrinsic evaluations and on
BLEU. Future work includes studying the effect
of size of parallel corpus on the induced oov trans-
lations. Increasing the size of parallel corpus on
one hand reduces the number of oovs. But, on
the other hand, there will be more labeled para-
phrases that increases the chance of finding the
correct translation for oovs in the test set.
Currently, we find paraphrases for oov words.
However, oovs can be considered as n-grams
(phrases) instead of unigrams. In this scenario,
we also can look for paraphrases and translations
for phrases containing oovs and add them to the
phrase-table as new translations along with the
translations for unigram oovs.
We also plan to explore different graph propa-
gation objective functions. Regularizing these ob-
jective functions appropriately might let us scale
to much larger data sets with an order of magni-
tude more nodes in the graph.
</bodyText>
<page confidence="0.987328">
1113
</page>
<sectionHeader confidence="0.979556" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999537">
Andrei Alexandrescu and Katrin Kirchhoff. 2009.
Graph-based learning for statistical machine trans-
lation. In Proceedings of Human Language Tech-
nologies: The 2009 Annual Conference of the North
American Chapter of the Association for Compu-
tational Linguistics, NAACL ’09, pages 119–127,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
C. Callison-Burch, P. Koehn, and M. Osborne. 2006.
Improved statistical machine translation using para-
phrases. In Proceedings of the main conference
on Human Language Technology Conference of the
North American Chapter of the Association of Com-
putational Linguistics, pages 17–24. Association for
Computational Linguistics.
O. Chapelle, B. Sch¨olkopf, and A. Zien, editors. 2006.
Semi-Supervised Learning. MIT Press, Cambridge,
MA.
Ido Dagan, Lillian Lee, and Fernando C. N. Pereira.
1999. Similarity-based models of word cooccur-
rence probabilities. Mach. Learn., 34(1-3):43–69,
February.
Hal Daum´e, III and Jagadeesh Jagarlamudi. 2011. Do-
main adaptation for machine translation by mining
unseen words. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies: short pa-
pers - Volume 2, HLT ’11, pages 407–412, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Ted Dunning. 1993. Accurate methods for the statis-
tics of surprise and coincidence. Comput. Linguist.,
19(1):61–74, March.
Darja Fiser and Nikola Ljubesic. 2011. Bilingual lexi-
con extraction from comparable corpora for closely
related languages. In RANLP, pages 125–131.
Pascale Fung and Lo Yuen Yee. 1998. An ir approach
for translating new words from nonparallel, compa-
rable texts. In Proceedings of the 36th Annual Meet-
ing of the Association for Computational Linguis-
tics and 17th International Conference on Computa-
tional Linguistics - Volume 1, ACL ’98, pages 414–
420. Association for Computational Linguistics.
Nikesh Garera, Chris Callison-Burch, and David
Yarowsky. 2009. Improving translation lexicon in-
duction from monolingual corpora via dependency
contexts and part-of-speech equivalences. In Pro-
ceedings of the Thirteenth Conference on Compu-
tational Natural Language Learning, CoNLL ’09,
pages 129–137, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Amit Goyal, Hal Daume III, and Raul Guerra. 2012.
Fast Large-Scale Approximate Graph Construction
for NLP. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP ’12.
Nizar Habash. 2008. Four techniques for online han-
dling of out-of-vocabulary words in arabic-english
statistical machine translation. In Proceedings of the
46th Annual Meeting of the Association for Compu-
tational Linguistics on Human Language Technolo-
gies: Short Papers, pages 57–60. Association for
Computational Linguistics.
Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,
and Dan Klein. 2008. Learning bilingual lexicons
from monolingual corpora. In ACL, pages 771–779.
Zellig Harris. 1954. Distributional structure. Word,
10(23):146–162.
Kenneth Heafield. 2011. Kenlm: Faster and smaller
language model queries. In Proceedings of the Sixth
Workshop on Statistical Machine Translation, pages
187–197.
Chung-Chi Huang, Ho-Ching Yen, Ping-Che Yang,
Shih-Ting Huang, and Jason S Chang. 2011. Us-
ing sublexical translations to handle the oov prob-
lem in machine translation. ACM Transactions on
Asian Language Information Processing (TALIP),
10(3):16.
Philipp Koehn and Kevin Knight. 2002. Learning a
translation lexicon from monolingual corpora. In
Proceedings of the ACL-02 workshop on Unsuper-
vised lexical acquisition - Volume 9, ULA ’02, pages
9–16, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: open
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
ACL ’07, pages 177–180, Stroudsburg, PA, USA.
ACL.
P. Koehn. 2005. Europarl: A parallel corpus for statis-
tical machine translation. In MT summit, volume 5.
Florian Laws, Lukas Michelbacher, Beate Dorow,
Christian Scheible, Ulrich Heid, and Hinrich
Sch¨utze. 2010. A linguistically grounded graph
model for bilingual lexicon extraction. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics: Posters, COLING ’10, pages
614–622, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Dekang Lin. 1998. Automatic retrieval and clustering
of similar words. In Proceedings of the 36th Annual
Meeting of the Association for Computational Lin-
guistics and 17th International Conference on Com-
putational Linguistics - Volume 2, ACL ’98, pages
768–774, Stroudsburg, PA, USA. Association for
Computational Linguistics.
</reference>
<page confidence="0.905203">
1114
</page>
<reference confidence="0.999890978947368">
Shujie Liu, Chi-Ho Li, Mu Li, and Ming Zhou. 2012.
Learning translation consensus with structured la-
bel propagation. In Proceedings of the 50th Annual
Meeting of the Association for Computational Lin-
guistics: Long Papers - Volume 1, ACL ’12, pages
302–310, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Gideon S. Mann and David Yarowsky. 2001. Mul-
tipath translation lexicon induction via bridge lan-
guages. In Proceedings of the second meeting of
the North American Chapter of the Association for
Computational Linguistics on Language technolo-
gies, NAACL ’01, pages 1–8, Stroudsburg, PA,
USA.
Yuval Marton, Chris Callison-Burch, and Philip
Resnik. 2009. Improved statistical machine trans-
lation using monolingually-derived paraphrases. In
Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing: Volume
1 - Volume 1, EMNLP ’09, pages 381–390, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Comput. Linguist., 29(1):19–51, March.
Franz Josef Och. 2003. Minimum error rate training
for statistical machine translation. In Proceedings of
the 41th Annual Meeting of the ACL, Sapporo, July.
ACL.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic eval-
uation of machine translation. In Proceedings of
the 40th Annual Meeting on Association for Com-
putational Linguistics, ACL ’02, pages 311–318,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Delip Rao and David Yarowsky. 2009. Ranking
and semi-supervised classification on large scale
graphs using map-reduce. In Proceedings of the
2009 Workshop on Graph-based Methods for Nat-
ural Language Processing, TextGraphs-4. Associa-
tion for Computational Linguistics.
Reinhard Rapp. 1995. Identifying word translations in
non-parallel texts. In Proceedings of the 33rd an-
nual meeting on Association for Computational Lin-
guistics, ACL ’95, pages 320–322. Association for
Computational Linguistics.
Reinhard Rapp. 1999. Automatic identification of
word translations from unrelated english and german
corpora. In Proceedings of the 37th annual meet-
ing of the Association for Computational Linguistics
on Computational Linguistics, ACL ’99, pages 519–
526. Association for Computational Linguistics.
Charles Schafer and David Yarowsky. 2002. Induc-
ing translation lexicons via diverse similarity mea-
sures and bridge languages. In proceedings of the
6th conference on Natural language learning - Vol-
ume 20, COLING-02, pages 1–7, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Hinrich Sch¨utze and Jan O. Pedersen. 1997. A
cooccurrence-based thesaurus and two applications
to information retrieval. Inf. Process. Manage.,
33(3):307–318, May.
Partha Pratim Talukdar and Koby Crammer. 2009.
New Regularized Algorithms for Transductive
Learning. In European Conference on Machine
Learning (ECML-PKDD).
Partha Pratim Talukdar, Joseph Reisinger, Marius
Pas¸ca, Deepak Ravichandran, Rahul Bhagat, and
Fernando Pereira. 2008. Weakly-supervised acqui-
sition of labeled class instances using graph random
walks. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP ’08.
Akihiro Tamura, Taro Watanabe, and Eiichiro Sumita.
2012. Bilingual lexicon extraction from compara-
ble corpora using label propagation. In EMNLP-
CoNLL, pages 24–36.
Egidio L. Terra and Charles L. A. Clarke. 2003. Fre-
quency estimates for statistical word similarity mea-
sures. In HLT-NAACL.
Jorg Tiedemann. 2009. News from opus - a collection
of multilingual parallel corpora with tools and inter-
faces. In N. Nicolov, K. Bontcheva, G. Angelova,
and R. Mitkov, editors, Recent Advances in Natu-
ral Language Processing, volume V, pages 237–248.
John Benjamins, Amsterdam/Philadelphia.
Ellen M. Voorhees. 1999. TREC-8 Question Answer-
ing Track Report. In Proceedings of the 8th Text
Retrieval Conference, pages 77–82.
Jiajun Zhang, Feifei Zhai, and Chengqing Zong. 2012.
Handling unknown words in statistical machine
translation from a new perspective. In Natural Lan-
guage Processing and Chinese Computing, pages
176–187. Springer.
</reference>
<page confidence="0.995027">
1115
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.570037">
<title confidence="0.983166">Graph Propagation for Paraphrasing Out-of-Vocabulary Words Machine</title>
<author confidence="0.937513">Maryam Gholamreza Anoop</author>
<address confidence="0.814643">1Simon Fraser University, Burnaby, BC, Canada 2Monash University, Clayton, VIC, Australia</address>
<email confidence="0.999922">reza@monash.edu</email>
<abstract confidence="0.998188608695652">Out-of-vocabulary (oov) words or phrases still remain a challenge in statistical machine translation especially when a limited amount of parallel text is available for training or when there is a domain shift from training data to test data. In this paper, we propose a novel approach to finding translations for oov words. We induce a lexicon by constructing a graph on source language monolingual text and employ a graph propagation technique in order to find translations for all the source language phrases. Our method differs from previous approaches by adopting a graph propagation approach that takes into account not only one-step (from oov directly to a source language phrase that has a translation) but multi-step paraphrases from oov source language words to other source language phrases and eventually to target language translations. Experimental results show that our graph propagation method significantly improves performance over two strong baselines under intrinsic and extrinsic evaluation metrics.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Andrei Alexandrescu</author>
<author>Katrin Kirchhoff</author>
</authors>
<title>Graph-based learning for statistical machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, NAACL ’09,</booktitle>
<pages>119--127</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="34013" citStr="Alexandrescu and Kirchhoff (2009)" startWordPosition="5740" endWordPosition="5743">enerative models based on canonical correlation analysis to extract translation lexicons for non-parallel corpora by learning a matching between source and target lexicons. Using monolingual features to represent words, feature vectors are projected from source and target words into a canonical space to find the appropriate matching between them. Their method relies on context features which need a seed lexicon and orthographic features which only works for phylogenetically related languages. Graph-based semi-supervised methods have been shown to be useful for domain adaptation in MT as well. Alexandrescu and Kirchhoff (2009) applied a graph-based method to determine similarities between sentences and use these similarities to promote similar translations for similar sentences. They used a graph-based semi-supervised model to re-rank the n-best translation hypothesis. Liu et al. (2012) extended Alexandrescu’s model to use translation consensus among similar sentences in bilingual training data by developing a new structured label propagation method. They derived some features to use during decoding process that has been shown useful in improving translation quality. Our graph propagation method connects monolingua</context>
</contexts>
<marker>Alexandrescu, Kirchhoff, 2009</marker>
<rawString>Andrei Alexandrescu and Katrin Kirchhoff. 2009. Graph-based learning for statistical machine translation. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, NAACL ’09, pages 119–127, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Callison-Burch</author>
<author>P Koehn</author>
<author>M Osborne</author>
</authors>
<title>Improved statistical machine translation using paraphrases.</title>
<date>2006</date>
<booktitle>In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics,</booktitle>
<pages>17--24</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2829" citStr="Callison-Burch et al., 2006" startWordPosition="440" endWordPosition="443"> was partially supported by an NSERC, Canada (RGPIN: 264905) grant. The third author was supported by an early career research award from Monash University to visit Simon Fraser University. re-order the words in the target language (Zhang et al., 2012). Increasing the size of the parallel data can reduce the number of oovs. However, there will always be some words or phrases that are new to the system and finding ways to translate such words or phrases will be beneficial to the system. Researchers have applied a number of approaches to tackle this problem. Some approaches use pivot languages (Callison-Burch et al., 2006) while others use lexicon-induction-based approaches from source language monolingual corpora (Koehn and Knight, 2002; Garera et al., 2009; Marton et al., 2009). Pivot language techniques tackle this problem by taking advantage of available parallel data between the source language and a third language. Using a pivot language, oovs are translated into a third language and back into the source language and thereby paraphrases to those oov words are extracted (Callison-Burch et al., 2006). For each oov, the system can be augmented by aggregating the translations of all its paraphrases and assign</context>
<context position="31978" citStr="Callison-Burch et al., 2006" startWordPosition="5410" endWordPosition="5413">vidence of closely related languages. Most of them evaluated only highfrequency words of specific types (nouns or content words) (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Laws et al., 2010) In contrast, we do not consider any constraint on our test data and our data includes many low frequency words. It has been shown that translation of high-frequency words is easier than low frequency words (Tamura et al., 2012). Some methods have used a third language(s) as pivot or bridge to find translation pairs (Mann and Yarowsky, 2001; Schafer and Yarowsky, 2002; Callison-Burch et al., 2006). 1112 Corpus System MRR Recall Dev Bleu Test Bleu Europarl Baseline – – 28.53 28.97 Our approach 5.9 12.6 28.76 29.40* EMEA Baseline – – 20.05 20.34 Our approach 3.6 7.4 20.54 20.80* * Statistically significant with p &lt; 0.02 using the bootstrap resampling significance test (in Moses). Table 6: Bleu scores for different domains with or without using oov translations. Context similarity has been used effectively in bilingual lexicon induction (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Marton et al., 2009; Laws et al., 2010). It has been modeled in different</context>
</contexts>
<marker>Callison-Burch, Koehn, Osborne, 2006</marker>
<rawString>C. Callison-Burch, P. Koehn, and M. Osborne. 2006. Improved statistical machine translation using paraphrases. In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, pages 17–24. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Chapelle</author>
<author>B Sch¨olkopf</author>
<author>A Zien</author>
<author>editors</author>
</authors>
<title>Semi-Supervised Learning.</title>
<date>2006</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Chapelle, Sch¨olkopf, Zien, editors, 2006</marker>
<rawString>O. Chapelle, B. Sch¨olkopf, and A. Zien, editors. 2006. Semi-Supervised Learning. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Lillian Lee</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Similarity-based models of word cooccurrence probabilities.</title>
<date>1999</date>
<pages>34--1</pages>
<location>Mach. Learn.,</location>
<contexts>
<context position="11343" citStr="Dagan et al., 1999" startWordPosition="1821" endWordPosition="1824"> p1 and p2 are parameters of Binomial distributions estimated using maximum likelihood. Given two distributional profiles DP(u) and DP(v), some similarity functions can be defined as follows. Note that A(·, ·) stands for the various association measures defined in Sec. 2.2. Cosine coefficient is the cosine the angle between two vectors DP(u) and DP(v): cos(DP(u), DP(v)) = EwiEV A(u, wi)A(v, wi) &apos; EwiEV A(u, wi)2&apos; EwiEV A(v, wi)2 L1-Norm computes the accumulated distance between entries of two distributional profiles (L1(·, ·)). It has been used as word similarity measure in language modeling (Dagan et al., 1999). L1(DP(u), DP(v)) = � |A(u, wi)−A(v, wi)| wiEV Jensen-Shannon Divergence is a symmetric version of contextual average mutual information (KL) which is used by (Dagan et al., 1999) as word similarity measure. JSD(DP(u), DP(v)) =KL(DP(u), AVGDP(u, v))+ KL(DP(v), AVGDP(u, v)) AV GDP(u, v) = S A(u, wi) 2 A(v, wi) |wi ∈ V } A(u, wi) A(u, wi)log A(v, wi) 3 Graph-based Lexicon Induction We propose a novel approach to alleviate the oov problem. Given a (possibly small amount of) parallel data between the source and target languages, and a large monolingual data in the source language, we construct a </context>
</contexts>
<marker>Dagan, Lee, Pereira, 1999</marker>
<rawString>Ido Dagan, Lillian Lee, and Fernando C. N. Pereira. 1999. Similarity-based models of word cooccurrence probabilities. Mach. Learn., 34(1-3):43–69, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Jagadeesh Jagarlamudi</author>
</authors>
<title>Domain adaptation for machine translation by mining unseen words.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11,</booktitle>
<pages>407--412</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Daum´e, Jagarlamudi, 2011</marker>
<rawString>Hal Daum´e, III and Jagadeesh Jagarlamudi. 2011. Domain adaptation for machine translation by mining unseen words. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11, pages 407–412, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Comput. Linguist.,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="9526" citStr="Dunning, 1993" startWordPosition="1526" endWordPosition="1527">window). A(·, ·) is an association measure and can simply be defined as co-occurrence counts within sliding windows. Stronger association measures can also be used such as: Conditional probability: the probability for the occurrence of each word in DP given the occurrence of u: CP(u,wi) = P(wi|u) (Sch¨utze and Pedersen, 1997) Pointwise Mutual Information: this measure is a transformation of the independence assumption into a ratio. Positive values indicate that words co-occur more than what we expect under the independence assumption (Lin, 1998): PMI(u, wi) = log2 P(u)P(wi) Likelihood ratio: (Dunning, 1993) uses the likelihood ratio for word similarity: _ L(P(wi|u);p) ∗ L(P(wi|¬u);p) λ(u, wi) — L(P (wi|u); p1) ∗ L(P (wi|¬u); p2) where L is likelihood function under the assumption that word counts in text have binomial distributions. The numerator represents the likelihood of the hypothesis that u and wi are independent (P(wi|u) = P(wi|¬u) = p) and the denominator represents the likelihood of the hypothesis that u and wi are dependent (P(wi|u) =6 P(wi|¬u) , P(wi|u) = p1, P(wi|¬u) = p2 )4. Chi-square test: is a statistical hypothesis testing method to evaluate independence of two categorical rando</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Ted Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Comput. Linguist., 19(1):61–74, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Darja Fiser</author>
<author>Nikola Ljubesic</author>
</authors>
<title>Bilingual lexicon extraction from comparable corpora for closely related languages. In</title>
<date>2011</date>
<booktitle>RANLP,</booktitle>
<pages>125--131</pages>
<contexts>
<context position="33244" citStr="Fiser and Ljubesic, 2011" startWordPosition="5622" endWordPosition="5625">1999; Fung and Yee, 1998), or dependency relations (Garera et al., 2009). Laws et al. (2010) used linguistic analysis in the form of graph-based models instead of a vector space. But all of these researches used an available seed lexicon as the basic source of similarity between source and target languages unlike our method which just needs a monolingual corpus of source language which is freely available for many languages and a small bilingual corpora. Some methods tried to alleviate the lack of seed lexicon by using orthographic similarity to extract a seed lexicon (Koehn and Knight, 2002; Fiser and Ljubesic, 2011). But it is not a practical solution in case of unrelated languages. Haghighi et al. (2008) and Daum´e and Jagarlamudi (2011) proposed generative models based on canonical correlation analysis to extract translation lexicons for non-parallel corpora by learning a matching between source and target lexicons. Using monolingual features to represent words, feature vectors are projected from source and target words into a canonical space to find the appropriate matching between them. Their method relies on context features which need a seed lexicon and orthographic features which only works for ph</context>
</contexts>
<marker>Fiser, Ljubesic, 2011</marker>
<rawString>Darja Fiser and Nikola Ljubesic. 2011. Bilingual lexicon extraction from comparable corpora for closely related languages. In RANLP, pages 125–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Lo Yuen Yee</author>
</authors>
<title>An ir approach for translating new words from nonparallel, comparable texts.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics - Volume 1, ACL ’98,</booktitle>
<pages>414--420</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8437" citStr="Fung and Yee, 1998" startWordPosition="1349" endWordPosition="1352"> paraphrases that have translations in the phrase-table are used to assign translations and scores to each oov word by marginalizing translations over paraphrases: Y: p(t|o) = p(t|s)p(s|o) s where t is a phrase on the target side, o is the oov word or phrase, and s is a paraphrase of o. p(s|o) is estimated using a similarity measure over DPs and p(t|s) is coming from the phrase-table. We reimplemented this collocational approach for finding translations for oovs and used it as a baseline system. Alternative ways of modeling and comparing distributional profiles have been proposed (Rapp, 1999; Fung and Yee, 1998; Terra and Clarke, 2003; Garera et al., 2009; Marton et al., 2009). We review some of them here and compare their performance in Section 4.3. 2.2 Association Measures Given a word u, its distributional profile DP(u) is constructed by counting surrounding words (in a fixed window size) in a monolingual corpus. DP(u) = I(A(u,wi)) |wi E V } 1106 The counts can be collected in positional3 (Rapp, 1999) or non-positional way (count all the word occurrences within the sliding window). A(·, ·) is an association measure and can simply be defined as co-occurrence counts within sliding windows. Stronger</context>
<context position="32644" citStr="Fung and Yee, 1998" startWordPosition="5522" endWordPosition="5525">leu Europarl Baseline – – 28.53 28.97 Our approach 5.9 12.6 28.76 29.40* EMEA Baseline – – 20.05 20.34 Our approach 3.6 7.4 20.54 20.80* * Statistically significant with p &lt; 0.02 using the bootstrap resampling significance test (in Moses). Table 6: Bleu scores for different domains with or without using oov translations. Context similarity has been used effectively in bilingual lexicon induction (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Marton et al., 2009; Laws et al., 2010). It has been modeled in different ways: in terms of adjacent words (Rapp, 1999; Fung and Yee, 1998), or dependency relations (Garera et al., 2009). Laws et al. (2010) used linguistic analysis in the form of graph-based models instead of a vector space. But all of these researches used an available seed lexicon as the basic source of similarity between source and target languages unlike our method which just needs a monolingual corpus of source language which is freely available for many languages and a small bilingual corpora. Some methods tried to alleviate the lack of seed lexicon by using orthographic similarity to extract a seed lexicon (Koehn and Knight, 2002; Fiser and Ljubesic, 2011)</context>
</contexts>
<marker>Fung, Yee, 1998</marker>
<rawString>Pascale Fung and Lo Yuen Yee. 1998. An ir approach for translating new words from nonparallel, comparable texts. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics - Volume 1, ACL ’98, pages 414– 420. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikesh Garera</author>
<author>Chris Callison-Burch</author>
<author>David Yarowsky</author>
</authors>
<title>Improving translation lexicon induction from monolingual corpora via dependency contexts and part-of-speech equivalences.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning, CoNLL ’09,</booktitle>
<pages>129--137</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2967" citStr="Garera et al., 2009" startWordPosition="459" endWordPosition="462">iversity to visit Simon Fraser University. re-order the words in the target language (Zhang et al., 2012). Increasing the size of the parallel data can reduce the number of oovs. However, there will always be some words or phrases that are new to the system and finding ways to translate such words or phrases will be beneficial to the system. Researchers have applied a number of approaches to tackle this problem. Some approaches use pivot languages (Callison-Burch et al., 2006) while others use lexicon-induction-based approaches from source language monolingual corpora (Koehn and Knight, 2002; Garera et al., 2009; Marton et al., 2009). Pivot language techniques tackle this problem by taking advantage of available parallel data between the source language and a third language. Using a pivot language, oovs are translated into a third language and back into the source language and thereby paraphrases to those oov words are extracted (Callison-Burch et al., 2006). For each oov, the system can be augmented by aggregating the translations of all its paraphrases and assign them to the oov. However, these methods require parallel corpora between the source language and one or multiple pivot languages. Another</context>
<context position="8482" citStr="Garera et al., 2009" startWordPosition="1357" endWordPosition="1360">hrase-table are used to assign translations and scores to each oov word by marginalizing translations over paraphrases: Y: p(t|o) = p(t|s)p(s|o) s where t is a phrase on the target side, o is the oov word or phrase, and s is a paraphrase of o. p(s|o) is estimated using a similarity measure over DPs and p(t|s) is coming from the phrase-table. We reimplemented this collocational approach for finding translations for oovs and used it as a baseline system. Alternative ways of modeling and comparing distributional profiles have been proposed (Rapp, 1999; Fung and Yee, 1998; Terra and Clarke, 2003; Garera et al., 2009; Marton et al., 2009). We review some of them here and compare their performance in Section 4.3. 2.2 Association Measures Given a word u, its distributional profile DP(u) is constructed by counting surrounding words (in a fixed window size) in a monolingual corpus. DP(u) = I(A(u,wi)) |wi E V } 1106 The counts can be collected in positional3 (Rapp, 1999) or non-positional way (count all the word occurrences within the sliding window). A(·, ·) is an association measure and can simply be defined as co-occurrence counts within sliding windows. Stronger association measures can also be used such a</context>
<context position="31119" citStr="Garera et al., 2009" startWordPosition="5263" endWordPosition="5266">e same-domain (Europarl) and domain adaptation (EMEA) settings. Table 7 shows some translations found by our system for oov words. oov gold standard candiate list undone particularly particularly specific sp´ecialement especially only special particular particular should and especially assentiment approval support agreement approval accession will approve endorses Table 7: Two examples of oov translations found by our method. 5 Related work There has been a long line of research on learning translation pairs from non-parallel corpora (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Marton et al., 2009; Laws et al., 2010). Most have focused on extracting a translation lexicon by mining monolingual resources of data to find clues, using probabilistic methods to map words, or by exploiting the cross-language evidence of closely related languages. Most of them evaluated only highfrequency words of specific types (nouns or content words) (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Laws et al., 2010) In contrast, we do not consider any constraint on our test data and our data includes many low frequency words. It has been shown that trans</context>
<context position="32503" citStr="Garera et al., 2009" startWordPosition="5495" endWordPosition="5499">ation pairs (Mann and Yarowsky, 2001; Schafer and Yarowsky, 2002; Callison-Burch et al., 2006). 1112 Corpus System MRR Recall Dev Bleu Test Bleu Europarl Baseline – – 28.53 28.97 Our approach 5.9 12.6 28.76 29.40* EMEA Baseline – – 20.05 20.34 Our approach 3.6 7.4 20.54 20.80* * Statistically significant with p &lt; 0.02 using the bootstrap resampling significance test (in Moses). Table 6: Bleu scores for different domains with or without using oov translations. Context similarity has been used effectively in bilingual lexicon induction (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Marton et al., 2009; Laws et al., 2010). It has been modeled in different ways: in terms of adjacent words (Rapp, 1999; Fung and Yee, 1998), or dependency relations (Garera et al., 2009). Laws et al. (2010) used linguistic analysis in the form of graph-based models instead of a vector space. But all of these researches used an available seed lexicon as the basic source of similarity between source and target languages unlike our method which just needs a monolingual corpus of source language which is freely available for many languages and a small bilingual corpora. Some methods tried to all</context>
</contexts>
<marker>Garera, Callison-Burch, Yarowsky, 2009</marker>
<rawString>Nikesh Garera, Chris Callison-Burch, and David Yarowsky. 2009. Improving translation lexicon induction from monolingual corpora via dependency contexts and part-of-speech equivalences. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning, CoNLL ’09, pages 129–137, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Goyal</author>
<author>Hal Daume</author>
<author>Raul Guerra</author>
</authors>
<title>Fast Large-Scale Approximate Graph Construction for NLP.</title>
<date>2012</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’12.</booktitle>
<contexts>
<context position="19320" citStr="Goyal et al., 2012" startWordPosition="3245" endWordPosition="3248">needs to be created. The number of possible edges can easily explode in size as there can be as many as O(n2) edges where n is the number of nodes. A common practice to control the number of edges is to connect each node to at most k other nodes (k-nearest neighbor). However, finding the top-k nearest nodes to each node requires considering its similarity to all the other nodes which requires O(n2) computations and since n is usually very large, doing such is practically intractable. Therefore, researchers usually resort to an approximate k-NN algorithms such as locality-sensitive hashing (?; Goyal et al., 2012). Fortunately, since we use context words as cues for relating their meaning and since the similarity measures are defined based on these cues, the number of neighbors we need to consider for each node is reduced by several orders of magnitude. We incorporate an inverted-index-style data structure which indicates what nodes are neighbors based on each context word. Therefore, the set of neighbors of a node consists of union of all the neighbors bridged by each context word in the DP of the node. However, the number of neighbors to be considered for each node even after this drastic reduction i</context>
</contexts>
<marker>Goyal, Daume, Guerra, 2012</marker>
<rawString>Amit Goyal, Hal Daume III, and Raul Guerra. 2012. Fast Large-Scale Approximate Graph Construction for NLP. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Four techniques for online handling of out-of-vocabulary words in arabic-english statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies: Short Papers,</booktitle>
<pages>57--60</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3653" citStr="Habash (2008)" startWordPosition="570" endWordPosition="571">taking advantage of available parallel data between the source language and a third language. Using a pivot language, oovs are translated into a third language and back into the source language and thereby paraphrases to those oov words are extracted (Callison-Burch et al., 2006). For each oov, the system can be augmented by aggregating the translations of all its paraphrases and assign them to the oov. However, these methods require parallel corpora between the source language and one or multiple pivot languages. Another line of work exploits spelling and morphological variants of oov words. Habash (2008) presents techniques for online handling of oov words for Arabic to English such as spelling expansion and morphological expansion. Huang et al. (2011) proposes a method to combine sublexical/constituent translations of an oov word or phrase to generate its translations. Several researchers have applied lexiconinduction methods to create a bilingual lexicon for those oovs. Marton et al. (2009) use a monolingual text on the source side to find paraphrases to oov words for which the translations are available. The translations for these paraphrases are 1105 Proceedings of the 51st Annual Meeting</context>
</contexts>
<marker>Habash, 2008</marker>
<rawString>Nizar Habash. 2008. Four techniques for online handling of out-of-vocabulary words in arabic-english statistical machine translation. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies: Short Papers, pages 57–60. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Percy Liang</author>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Klein</author>
</authors>
<title>Learning bilingual lexicons from monolingual corpora.</title>
<date>2008</date>
<booktitle>In ACL,</booktitle>
<pages>771--779</pages>
<contexts>
<context position="31098" citStr="Haghighi et al., 2008" startWordPosition="5259" endWordPosition="5262">the baseline in both the same-domain (Europarl) and domain adaptation (EMEA) settings. Table 7 shows some translations found by our system for oov words. oov gold standard candiate list undone particularly particularly specific sp´ecialement especially only special particular particular should and especially assentiment approval support agreement approval accession will approve endorses Table 7: Two examples of oov translations found by our method. 5 Related work There has been a long line of research on learning translation pairs from non-parallel corpora (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Marton et al., 2009; Laws et al., 2010). Most have focused on extracting a translation lexicon by mining monolingual resources of data to find clues, using probabilistic methods to map words, or by exploiting the cross-language evidence of closely related languages. Most of them evaluated only highfrequency words of specific types (nouns or content words) (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Laws et al., 2010) In contrast, we do not consider any constraint on our test data and our data includes many low frequency words. It has </context>
<context position="32482" citStr="Haghighi et al., 2008" startWordPosition="5491" endWordPosition="5494">r bridge to find translation pairs (Mann and Yarowsky, 2001; Schafer and Yarowsky, 2002; Callison-Burch et al., 2006). 1112 Corpus System MRR Recall Dev Bleu Test Bleu Europarl Baseline – – 28.53 28.97 Our approach 5.9 12.6 28.76 29.40* EMEA Baseline – – 20.05 20.34 Our approach 3.6 7.4 20.54 20.80* * Statistically significant with p &lt; 0.02 using the bootstrap resampling significance test (in Moses). Table 6: Bleu scores for different domains with or without using oov translations. Context similarity has been used effectively in bilingual lexicon induction (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Marton et al., 2009; Laws et al., 2010). It has been modeled in different ways: in terms of adjacent words (Rapp, 1999; Fung and Yee, 1998), or dependency relations (Garera et al., 2009). Laws et al. (2010) used linguistic analysis in the form of graph-based models instead of a vector space. But all of these researches used an available seed lexicon as the basic source of similarity between source and target languages unlike our method which just needs a monolingual corpus of source language which is freely available for many languages and a small bilingual corpora. Some</context>
</contexts>
<marker>Haghighi, Liang, Berg-Kirkpatrick, Klein, 2008</marker>
<rawString>Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick, and Dan Klein. 2008. Learning bilingual lexicons from monolingual corpora. In ACL, pages 771–779.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<date>1954</date>
<journal>Distributional structure. Word,</journal>
<volume>10</volume>
<issue>23</issue>
<contexts>
<context position="4606" citStr="Harris, 1954" startWordPosition="718" endWordPosition="720">a bilingual lexicon for those oovs. Marton et al. (2009) use a monolingual text on the source side to find paraphrases to oov words for which the translations are available. The translations for these paraphrases are 1105 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1105–1115, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics then used as the translations of the oov word. These methods are based on the distributional hypothesis which states that words appearing in the same contexts tend to have similar meaning (Harris, 1954). Marton et al. (2009) showed that this method improves over the baseline system where oovs are untranslated. We propose a graph propagation-based extension to the approach of Marton et al. (2009) in which a graph is constructed from source language monolingual text1 and the source-side of the available parallel data. Nodes that have related meanings are connected together and nodes for which we have translations in the phrase-table are annotated with target-side translations and their feature values. A graph propagation algorithm is then used to propagate translations from labeled nodes to un</context>
</contexts>
<marker>Harris, 1954</marker>
<rawString>Zellig Harris. 1954. Distributional structure. Word, 10(23):146–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
</authors>
<title>Kenlm: Faster and smaller language model queries.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<pages>187--197</pages>
<contexts>
<context position="21893" citStr="Heafield, 2011" startWordPosition="3687" endWordPosition="3688">taset Dev Test types tokens types tokens Europarl 1893 2229 1830 2163 EMEA 2325 4317 2294 4190 Table 2: number of oovs in dev and test sets for Europarl and EMEA systems. For the end-to-end MT pipeline, we used Moses (Koehn et al., 2007) with these standard features: relative-frequency and lexical translation model (TM) probabilities in both directions; distortion model; language model (LM) and word count. Word alignment is done using GIZA++ (Och and Ney, 2003). We used distortion limit of 6 and max-phrase-length of 10 in all the experiments. For the language model, we used the KenLM toolkit (Heafield, 2011) to create a 5-gram language model on the target side of the Europarl corpus (v7) with approximately 54M tokens with Kneser-Ney smoothing. 4.1.1 Phrase-table Integration Once the translations and their probabilities for each oov are extracted, they are added to the 8http://www.statmt.org/wpt05/mt-shared-task/ phrase-table that is induced from the parallel text. The probability for new entries are added as a new feature in the log-linear framework to be tuned along with other features. The value of this newly introduced feature for original entries in the phrase-table is set to 1. Similarly, th</context>
</contexts>
<marker>Heafield, 2011</marker>
<rawString>Kenneth Heafield. 2011. Kenlm: Faster and smaller language model queries. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 187–197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chung-Chi Huang</author>
<author>Ho-Ching Yen</author>
<author>Ping-Che Yang</author>
<author>Shih-Ting Huang</author>
<author>Jason S Chang</author>
</authors>
<title>Using sublexical translations to handle the oov problem in machine translation.</title>
<date>2011</date>
<journal>ACM Transactions on Asian Language Information Processing (TALIP),</journal>
<volume>10</volume>
<issue>3</issue>
<contexts>
<context position="3804" citStr="Huang et al. (2011)" startWordPosition="592" endWordPosition="595">third language and back into the source language and thereby paraphrases to those oov words are extracted (Callison-Burch et al., 2006). For each oov, the system can be augmented by aggregating the translations of all its paraphrases and assign them to the oov. However, these methods require parallel corpora between the source language and one or multiple pivot languages. Another line of work exploits spelling and morphological variants of oov words. Habash (2008) presents techniques for online handling of oov words for Arabic to English such as spelling expansion and morphological expansion. Huang et al. (2011) proposes a method to combine sublexical/constituent translations of an oov word or phrase to generate its translations. Several researchers have applied lexiconinduction methods to create a bilingual lexicon for those oovs. Marton et al. (2009) use a monolingual text on the source side to find paraphrases to oov words for which the translations are available. The translations for these paraphrases are 1105 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1105–1115, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics </context>
</contexts>
<marker>Huang, Yen, Yang, Huang, Chang, 2011</marker>
<rawString>Chung-Chi Huang, Ho-Ching Yen, Ping-Che Yang, Shih-Ting Huang, and Jason S Chang. 2011. Using sublexical translations to handle the oov problem in machine translation. ACM Transactions on Asian Language Information Processing (TALIP), 10(3):16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Learning a translation lexicon from monolingual corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 workshop on Unsupervised lexical acquisition - Volume 9, ULA ’02,</booktitle>
<pages>9--16</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2946" citStr="Koehn and Knight, 2002" startWordPosition="455" endWordPosition="458">rch award from Monash University to visit Simon Fraser University. re-order the words in the target language (Zhang et al., 2012). Increasing the size of the parallel data can reduce the number of oovs. However, there will always be some words or phrases that are new to the system and finding ways to translate such words or phrases will be beneficial to the system. Researchers have applied a number of approaches to tackle this problem. Some approaches use pivot languages (Callison-Burch et al., 2006) while others use lexicon-induction-based approaches from source language monolingual corpora (Koehn and Knight, 2002; Garera et al., 2009; Marton et al., 2009). Pivot language techniques tackle this problem by taking advantage of available parallel data between the source language and a third language. Using a pivot language, oovs are translated into a third language and back into the source language and thereby paraphrases to those oov words are extracted (Callison-Burch et al., 2006). For each oov, the system can be augmented by aggregating the translations of all its paraphrases and assign them to the oov. However, these methods require parallel corpora between the source language and one or multiple piv</context>
<context position="31075" citStr="Koehn and Knight, 2002" startWordPosition="5255" endWordPosition="5258">ow that we improve over the baseline in both the same-domain (Europarl) and domain adaptation (EMEA) settings. Table 7 shows some translations found by our system for oov words. oov gold standard candiate list undone particularly particularly specific sp´ecialement especially only special particular particular should and especially assentiment approval support agreement approval accession will approve endorses Table 7: Two examples of oov translations found by our method. 5 Related work There has been a long line of research on learning translation pairs from non-parallel corpora (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Marton et al., 2009; Laws et al., 2010). Most have focused on extracting a translation lexicon by mining monolingual resources of data to find clues, using probabilistic methods to map words, or by exploiting the cross-language evidence of closely related languages. Most of them evaluated only highfrequency words of specific types (nouns or content words) (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Laws et al., 2010) In contrast, we do not consider any constraint on our test data and our data includes many low f</context>
<context position="32459" citStr="Koehn and Knight, 2002" startWordPosition="5487" endWordPosition="5490">d language(s) as pivot or bridge to find translation pairs (Mann and Yarowsky, 2001; Schafer and Yarowsky, 2002; Callison-Burch et al., 2006). 1112 Corpus System MRR Recall Dev Bleu Test Bleu Europarl Baseline – – 28.53 28.97 Our approach 5.9 12.6 28.76 29.40* EMEA Baseline – – 20.05 20.34 Our approach 3.6 7.4 20.54 20.80* * Statistically significant with p &lt; 0.02 using the bootstrap resampling significance test (in Moses). Table 6: Bleu scores for different domains with or without using oov translations. Context similarity has been used effectively in bilingual lexicon induction (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Marton et al., 2009; Laws et al., 2010). It has been modeled in different ways: in terms of adjacent words (Rapp, 1999; Fung and Yee, 1998), or dependency relations (Garera et al., 2009). Laws et al. (2010) used linguistic analysis in the form of graph-based models instead of a vector space. But all of these researches used an available seed lexicon as the basic source of similarity between source and target languages unlike our method which just needs a monolingual corpus of source language which is freely available for many languages and a small </context>
</contexts>
<marker>Koehn, Knight, 2002</marker>
<rawString>Philipp Koehn and Kevin Knight. 2002. Learning a translation lexicon from monolingual corpora. In Proceedings of the ACL-02 workshop on Unsupervised lexical acquisition - Volume 9, ULA ’02, pages 9–16, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondˇrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07,</booktitle>
<pages>177--180</pages>
<publisher>ACL.</publisher>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="21515" citStr="Koehn et al., 2007" startWordPosition="3625" endWordPosition="3628">rom the parallel data. From the oovs, we exclude numbers as well as named entities. We apply a simple heuristic to detect named entities: basically words that are capitalized in the original dev/test set that do not appear at the beginning of a sentence are named entities. Table 2 shows the number of oov types and tokens for Europarl and EMEA systems in both dev and test sets. Dataset Dev Test types tokens types tokens Europarl 1893 2229 1830 2163 EMEA 2325 4317 2294 4190 Table 2: number of oovs in dev and test sets for Europarl and EMEA systems. For the end-to-end MT pipeline, we used Moses (Koehn et al., 2007) with these standard features: relative-frequency and lexical translation model (TM) probabilities in both directions; distortion model; language model (LM) and word count. Word alignment is done using GIZA++ (Och and Ney, 2003). We used distortion limit of 6 and max-phrase-length of 10 in all the experiments. For the language model, we used the KenLM toolkit (Heafield, 2011) to create a 5-gram language model on the target side of the Europarl corpus (v7) with approximately 54M tokens with Kneser-Ney smoothing. 4.1.1 Phrase-table Integration Once the translations and their probabilities for ea</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07, pages 177–180, Stroudsburg, PA, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In MT summit,</booktitle>
<volume>5</volume>
<marker>Koehn, 2005</marker>
<rawString>P. Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In MT summit, volume 5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Florian Laws</author>
<author>Lukas Michelbacher</author>
<author>Beate Dorow</author>
<author>Christian Scheible</author>
<author>Ulrich Heid</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>A linguistically grounded graph model for bilingual lexicon extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, COLING ’10,</booktitle>
<pages>614--622</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Laws, Michelbacher, Dorow, Scheible, Heid, Sch¨utze, 2010</marker>
<rawString>Florian Laws, Lukas Michelbacher, Beate Dorow, Christian Scheible, Ulrich Heid, and Hinrich Sch¨utze. 2010. A linguistically grounded graph model for bilingual lexicon extraction. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, COLING ’10, pages 614–622, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics - Volume 2, ACL ’98,</booktitle>
<pages>768--774</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="9463" citStr="Lin, 1998" startWordPosition="1517" endWordPosition="1518">nal way (count all the word occurrences within the sliding window). A(·, ·) is an association measure and can simply be defined as co-occurrence counts within sliding windows. Stronger association measures can also be used such as: Conditional probability: the probability for the occurrence of each word in DP given the occurrence of u: CP(u,wi) = P(wi|u) (Sch¨utze and Pedersen, 1997) Pointwise Mutual Information: this measure is a transformation of the independence assumption into a ratio. Positive values indicate that words co-occur more than what we expect under the independence assumption (Lin, 1998): PMI(u, wi) = log2 P(u)P(wi) Likelihood ratio: (Dunning, 1993) uses the likelihood ratio for word similarity: _ L(P(wi|u);p) ∗ L(P(wi|¬u);p) λ(u, wi) — L(P (wi|u); p1) ∗ L(P (wi|¬u); p2) where L is likelihood function under the assumption that word counts in text have binomial distributions. The numerator represents the likelihood of the hypothesis that u and wi are independent (P(wi|u) = P(wi|¬u) = p) and the denominator represents the likelihood of the hypothesis that u and wi are dependent (P(wi|u) =6 P(wi|¬u) , P(wi|u) = p1, P(wi|¬u) = p2 )4. Chi-square test: is a statistical hypothesis t</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics - Volume 2, ACL ’98, pages 768–774, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shujie Liu</author>
<author>Chi-Ho Li</author>
<author>Mu Li</author>
<author>Ming Zhou</author>
</authors>
<title>Learning translation consensus with structured label propagation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1, ACL ’12,</booktitle>
<pages>302--310</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="34278" citStr="Liu et al. (2012)" startWordPosition="5780" endWordPosition="5783">to a canonical space to find the appropriate matching between them. Their method relies on context features which need a seed lexicon and orthographic features which only works for phylogenetically related languages. Graph-based semi-supervised methods have been shown to be useful for domain adaptation in MT as well. Alexandrescu and Kirchhoff (2009) applied a graph-based method to determine similarities between sentences and use these similarities to promote similar translations for similar sentences. They used a graph-based semi-supervised model to re-rank the n-best translation hypothesis. Liu et al. (2012) extended Alexandrescu’s model to use translation consensus among similar sentences in bilingual training data by developing a new structured label propagation method. They derived some features to use during decoding process that has been shown useful in improving translation quality. Our graph propagation method connects monolingual source phrases with oovs to obtain translation and so is a very different use of graph propagation from these previous works. Recently label propagation has been used for lexicon induction (Tamura et al., 2012). They used a graph based on context similarity as we</context>
</contexts>
<marker>Liu, Li, Li, Zhou, 2012</marker>
<rawString>Shujie Liu, Chi-Ho Li, Mu Li, and Ming Zhou. 2012. Learning translation consensus with structured label propagation. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1, ACL ’12, pages 302–310, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon S Mann</author>
<author>David Yarowsky</author>
</authors>
<title>Multipath translation lexicon induction via bridge languages.</title>
<date>2001</date>
<booktitle>In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies, NAACL ’01,</booktitle>
<pages>1--8</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="31920" citStr="Mann and Yarowsky, 2001" startWordPosition="5402" endWordPosition="5405">s to map words, or by exploiting the cross-language evidence of closely related languages. Most of them evaluated only highfrequency words of specific types (nouns or content words) (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Laws et al., 2010) In contrast, we do not consider any constraint on our test data and our data includes many low frequency words. It has been shown that translation of high-frequency words is easier than low frequency words (Tamura et al., 2012). Some methods have used a third language(s) as pivot or bridge to find translation pairs (Mann and Yarowsky, 2001; Schafer and Yarowsky, 2002; Callison-Burch et al., 2006). 1112 Corpus System MRR Recall Dev Bleu Test Bleu Europarl Baseline – – 28.53 28.97 Our approach 5.9 12.6 28.76 29.40* EMEA Baseline – – 20.05 20.34 Our approach 3.6 7.4 20.54 20.80* * Statistically significant with p &lt; 0.02 using the bootstrap resampling significance test (in Moses). Table 6: Bleu scores for different domains with or without using oov translations. Context similarity has been used effectively in bilingual lexicon induction (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Marton et al., </context>
</contexts>
<marker>Mann, Yarowsky, 2001</marker>
<rawString>Gideon S. Mann and David Yarowsky. 2001. Multipath translation lexicon induction via bridge languages. In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies, NAACL ’01, pages 1–8, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuval Marton</author>
<author>Chris Callison-Burch</author>
<author>Philip Resnik</author>
</authors>
<title>Improved statistical machine translation using monolingually-derived paraphrases.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 - Volume 1, EMNLP ’09,</booktitle>
<pages>381--390</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2989" citStr="Marton et al., 2009" startWordPosition="463" endWordPosition="466">on Fraser University. re-order the words in the target language (Zhang et al., 2012). Increasing the size of the parallel data can reduce the number of oovs. However, there will always be some words or phrases that are new to the system and finding ways to translate such words or phrases will be beneficial to the system. Researchers have applied a number of approaches to tackle this problem. Some approaches use pivot languages (Callison-Burch et al., 2006) while others use lexicon-induction-based approaches from source language monolingual corpora (Koehn and Knight, 2002; Garera et al., 2009; Marton et al., 2009). Pivot language techniques tackle this problem by taking advantage of available parallel data between the source language and a third language. Using a pivot language, oovs are translated into a third language and back into the source language and thereby paraphrases to those oov words are extracted (Callison-Burch et al., 2006). For each oov, the system can be augmented by aggregating the translations of all its paraphrases and assign them to the oov. However, these methods require parallel corpora between the source language and one or multiple pivot languages. Another line of work exploits</context>
<context position="4628" citStr="Marton et al. (2009)" startWordPosition="721" endWordPosition="724">icon for those oovs. Marton et al. (2009) use a monolingual text on the source side to find paraphrases to oov words for which the translations are available. The translations for these paraphrases are 1105 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1105–1115, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics then used as the translations of the oov word. These methods are based on the distributional hypothesis which states that words appearing in the same contexts tend to have similar meaning (Harris, 1954). Marton et al. (2009) showed that this method improves over the baseline system where oovs are untranslated. We propose a graph propagation-based extension to the approach of Marton et al. (2009) in which a graph is constructed from source language monolingual text1 and the source-side of the available parallel data. Nodes that have related meanings are connected together and nodes for which we have translations in the phrase-table are annotated with target-side translations and their feature values. A graph propagation algorithm is then used to propagate translations from labeled nodes to unlabeled nodes (phrases</context>
<context position="6398" citStr="Marton et al. (2009)" startWordPosition="1004" endWordPosition="1007">ributional profile (DP) of a word or phrase type is a co-occurrence vector created by combining all co-occurrence vectors of the tokens of that phrase type. Each distributional profile can be seen as a point in a |V |-dimensional space where V is the vocabulary where each word type represents a unique axis. Points (i.e. phrase types) that are close to one another in this highdimensional space can represent paraphrases. This approach has also been used in machine translation to find in-vocabulary paraphrases for oov words on the source side and find a way to translate them. 2.1 Baseline System Marton et al. (2009) was the first to successfully integrate a collocational approach to finding trans1Here on by monolingual data we always mean monolingual data on the source language 2Named entity oovs may be handled properly by copying or transliteration. lations for oov words into an end-to-end SMT system. We explain their method in detail as we will compare against this approach. The method relies on monolingual distributional profiles (DPs) which are numerical vectors representing the context around each word. The goal is to find words or phrases that appear in similar contexts as the oovs. For each oov a </context>
<context position="8504" citStr="Marton et al., 2009" startWordPosition="1361" endWordPosition="1364">to assign translations and scores to each oov word by marginalizing translations over paraphrases: Y: p(t|o) = p(t|s)p(s|o) s where t is a phrase on the target side, o is the oov word or phrase, and s is a paraphrase of o. p(s|o) is estimated using a similarity measure over DPs and p(t|s) is coming from the phrase-table. We reimplemented this collocational approach for finding translations for oovs and used it as a baseline system. Alternative ways of modeling and comparing distributional profiles have been proposed (Rapp, 1999; Fung and Yee, 1998; Terra and Clarke, 2003; Garera et al., 2009; Marton et al., 2009). We review some of them here and compare their performance in Section 4.3. 2.2 Association Measures Given a word u, its distributional profile DP(u) is constructed by counting surrounding words (in a fixed window size) in a monolingual corpus. DP(u) = I(A(u,wi)) |wi E V } 1106 The counts can be collected in positional3 (Rapp, 1999) or non-positional way (count all the word occurrences within the sliding window). A(·, ·) is an association measure and can simply be defined as co-occurrence counts within sliding windows. Stronger association measures can also be used such as: Conditional probabi</context>
<context position="12990" citStr="Marton et al. (2009)" startWordPosition="2109" endWordPosition="2112">ection 2.3). There are three types of vertices in the graph: i) labeled nodes which appear in the parallel corpus and for which we have the target-side P(u, wi) � (fx,y − Ex,y)2 yE{u,—u} Ex,y KL(DP(u), DP(v)) = � wi∈V 1107 translations5; ii) oov nodes from the dev/test set for which we seek labels (translations); and iii) unlabeled nodes (words or phrases) from the monolingual data which appear usually between oov nodes and labeled nodes. When a relatively small parallel data is used, unlabeled nodes outnumber labeled ones and many of them lie on the paths between an oov node to labeled ones. Marton et al. (2009)’s approach ignores these bridging nodes and connects each oov node to the k-nearest labeled nodes. One may argue that these unlabeled nodes do not play a major role in the graph and the labels will eventually get to the oov nodes from the labeled nodes by directly connecting them. However based on the definition of the similarity measures using context, it is quite possible that an oov node and a labeled node which are connected to the same unlabeled node do not share any context words and hence are not directly connected. For instance, consider three nodes, u (unlabeled), o (oov) and l (labe</context>
<context position="14849" citStr="Marton et al., 2009" startWordPosition="2436" endWordPosition="2439">s (O). Each oov node is connected to a number of labeled nodes, and vice versa and there is no edge between nodes of the same type. In such a graph, the similarity of each pair of nodes is computed using one of the similarity measures discussed above. The labels are translations and their probabilities (more specifically p(e|f)) from the phrase-table extracted from the parallel corpus. Translations get propagated to oov nodes using a label propagation technique. However beside the difference in the oov label assignment, there is a major difference between our bipartite graph and the baseline (Marton et al., 2009): we do not use a heuristic to 5It is possible that a phrase appears in the parallel corpus, but not in the phrase-table. This happens when the wordalignment module is not able to align the phrase to a target side word or words. reduce the number of neighbor candidates and we consider all possible candidates that share at least one context word. This makes a significant difference in practice as shown in Section 4.3.1. We also take advantage of unlabeled nodes to help connect oov nodes to labeled ones. The discussed bipartite graph can easily be expanded to a tripartite graph by adding unlabel</context>
<context position="31140" citStr="Marton et al., 2009" startWordPosition="5267" endWordPosition="5270">rl) and domain adaptation (EMEA) settings. Table 7 shows some translations found by our system for oov words. oov gold standard candiate list undone particularly particularly specific sp´ecialement especially only special particular particular should and especially assentiment approval support agreement approval accession will approve endorses Table 7: Two examples of oov translations found by our method. 5 Related work There has been a long line of research on learning translation pairs from non-parallel corpora (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Marton et al., 2009; Laws et al., 2010). Most have focused on extracting a translation lexicon by mining monolingual resources of data to find clues, using probabilistic methods to map words, or by exploiting the cross-language evidence of closely related languages. Most of them evaluated only highfrequency words of specific types (nouns or content words) (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Laws et al., 2010) In contrast, we do not consider any constraint on our test data and our data includes many low frequency words. It has been shown that translation of high-freque</context>
<context position="32524" citStr="Marton et al., 2009" startWordPosition="5500" endWordPosition="5503"> Yarowsky, 2001; Schafer and Yarowsky, 2002; Callison-Burch et al., 2006). 1112 Corpus System MRR Recall Dev Bleu Test Bleu Europarl Baseline – – 28.53 28.97 Our approach 5.9 12.6 28.76 29.40* EMEA Baseline – – 20.05 20.34 Our approach 3.6 7.4 20.54 20.80* * Statistically significant with p &lt; 0.02 using the bootstrap resampling significance test (in Moses). Table 6: Bleu scores for different domains with or without using oov translations. Context similarity has been used effectively in bilingual lexicon induction (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Marton et al., 2009; Laws et al., 2010). It has been modeled in different ways: in terms of adjacent words (Rapp, 1999; Fung and Yee, 1998), or dependency relations (Garera et al., 2009). Laws et al. (2010) used linguistic analysis in the form of graph-based models instead of a vector space. But all of these researches used an available seed lexicon as the basic source of similarity between source and target languages unlike our method which just needs a monolingual corpus of source language which is freely available for many languages and a small bilingual corpora. Some methods tried to alleviate the lack of se</context>
</contexts>
<marker>Marton, Callison-Burch, Resnik, 2009</marker>
<rawString>Yuval Marton, Chris Callison-Burch, and Philip Resnik. 2009. Improved statistical machine translation using monolingually-derived paraphrases. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 - Volume 1, EMNLP ’09, pages 381–390, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Comput. Linguist.,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="21743" citStr="Och and Ney, 2003" startWordPosition="3660" endWordPosition="3663"> beginning of a sentence are named entities. Table 2 shows the number of oov types and tokens for Europarl and EMEA systems in both dev and test sets. Dataset Dev Test types tokens types tokens Europarl 1893 2229 1830 2163 EMEA 2325 4317 2294 4190 Table 2: number of oovs in dev and test sets for Europarl and EMEA systems. For the end-to-end MT pipeline, we used Moses (Koehn et al., 2007) with these standard features: relative-frequency and lexical translation model (TM) probabilities in both directions; distortion model; language model (LM) and word count. Word alignment is done using GIZA++ (Och and Ney, 2003). We used distortion limit of 6 and max-phrase-length of 10 in all the experiments. For the language model, we used the KenLM toolkit (Heafield, 2011) to create a 5-gram language model on the target side of the Europarl corpus (v7) with approximately 54M tokens with Kneser-Ney smoothing. 4.1.1 Phrase-table Integration Once the translations and their probabilities for each oov are extracted, they are added to the 8http://www.statmt.org/wpt05/mt-shared-task/ phrase-table that is induced from the parallel text. The probability for new entries are added as a new feature in the log-linear framework</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Comput. Linguist., 29(1):19–51, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training for statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41th Annual Meeting of the ACL,</booktitle>
<publisher>ACL.</publisher>
<location>Sapporo,</location>
<contexts>
<context position="22956" citStr="Och, 2003" startWordPosition="3860" endWordPosition="3861"> be tuned along with other features. The value of this newly introduced feature for original entries in the phrase-table is set to 1. Similarly, the value of original four probability features in the phrasetable for the new entries are set to 1. The entire training pipeline is as follows: (i) a phrase table is constructed using parallel data as usual, (ii) oovs for dev and test sets are extracted, (iii) oovs are translated using graph propagation, (iv) oovs and translations are added to the phrase table, introducing a new feature type, (v) the new phrase table is tuned (with a LM) using MERT (Och, 2003) on the dev set. 4.2 Evaluation If we have a list of possible translations for oovs with their probabilities, we become able to evaluate different methods we discussed. We wordaligned the dev/test sets by concatenating them to a large parallel corpus and running GIZA++ on the whole set. The resulting word alignments are used to extract the translations for each oov. The correctness of this gold standard is limited to the size of the parallel data used as well as the quality of the word alignment software toolkit, and is not 100% precise. However, it gives a good estimate of how each oov should</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training for statistical machine translation. In Proceedings of the 41th Annual Meeting of the ACL, Sapporo, July. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>311--318</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1903" citStr="Papineni et al., 2002" startWordPosition="279" endWordPosition="282">nder intrinsic and extrinsic evaluation metrics. 1 Introduction Out-of-vocabulary (oov) words or phrases still remain a challenge in statistical machine translation. SMT systems usually copy unknown words verbatim to the target language output. Although this is helpful in translating a small fraction of oovs such as named entities for languages with same writing systems, it harms the translation in other types of oovs and distant language pairs. In general, copied-over oovs are a hindrance to fluent, high quality translation, and we can see evidence of this in automatic measures such as BLEU (Papineni et al., 2002) and also in human evaluation scores such as HTER. The problem becomes more severe when only a limited amount of parallel text is available for training or when the training and test data are from different domains. Even noisy translation of oovs can aid the language model to better ∗This research was partially supported by an NSERC, Canada (RGPIN: 264905) grant. The third author was supported by an early career research award from Monash University to visit Simon Fraser University. re-order the words in the target language (Zhang et al., 2012). Increasing the size of the parallel data can red</context>
<context position="29945" citStr="Papineni et al., 2002" startWordPosition="5076" endWordPosition="5079"> as the translation may no longer be a valid one. Table 5 also shows the effect of using bigrams instead of unigrams as graph nodes. There is an improvement by going from unigrams to bigrams in both bipartite and tripartite graphs. We did not use trigrams or larger n-grams in our experiments. 4.4 Extrinsic Results The generated candidate translations for the oovs can be added to the phrase-table created using the parallel corpus to increase the coverage of the phrase-table. This aggregated phrase-table is to be tuned along with the language model on the dev set, and run on the test set. BLEU (Papineni et al., 2002) is still the de facto evaluation metric for machine translation and we use that to measure the quality of our proposed approaches for MT. In these experiments, we do not use alignment information on dev or test sets unlike the previous section. Table 6 reports the Bleu scores for different domains when the oov translations from the graph propagation is added to the phrase-table and compares them with the baseline system (i.e. Moses). Results for our approach is based on unigram tripartite graphs and show that we improve over the baseline in both the same-domain (Europarl) and domain adaptatio</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02, pages 311–318, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delip Rao</author>
<author>David Yarowsky</author>
</authors>
<title>Ranking and semi-supervised classification on large scale graphs using map-reduce.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing, TextGraphs-4. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="18266" citStr="Rao and Yarowsky, 2009" startWordPosition="3066" endWordPosition="3069">, with different extent for different labeled nodes. The second term (2) enforces the smoothness of the labeling according to the graph structure and edge weights. The last term (3) regularizes the soft labeling for a vertex v to match a priori label R,,, e.g. for high-degree unlabeled nodes (hubs in the graph) we may believe that the neighbors are not going to produce reliable label and hence the probability of undefined label ⊥ should be higher. The optimization problem can be solved with an efficient iterative algorithm which is parallelized in a MapReduce framework (Talukdar et al., 2008; Rao and Yarowsky, 2009). We used the Junto label propagation toolkit (Talukdar and Crammer, 2009) for label propagation. 3.2 Efficient Graph Construction Graph-based approaches can easily become computationally very expensive as the number of nodes grow. In our case, we use phrases in the monolingual text as graph vertices. These phrases are n-grams up to a certain value, which can result in millions of nodes. For each node a distributional profile (DP) needs to be created. The number of possible edges can easily explode in size as there can be as many as O(n2) edges where n is the number of nodes. A common practice</context>
</contexts>
<marker>Rao, Yarowsky, 2009</marker>
<rawString>Delip Rao and David Yarowsky. 2009. Ranking and semi-supervised classification on large scale graphs using map-reduce. In Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing, TextGraphs-4. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Identifying word translations in non-parallel texts.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd annual meeting on Association for Computational Linguistics, ACL ’95,</booktitle>
<pages>320--322</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5667" citStr="Rapp (1995)" startWordPosition="883" endWordPosition="884"> with target-side translations and their feature values. A graph propagation algorithm is then used to propagate translations from labeled nodes to unlabeled nodes (phrases appearing only in the monolingual text and oovs). This provides a general purpose approach to handle several types of oovs, including morphological variants, spelling variants and synonyms2. Constructing such a huge graph and propagating messages through it pose severe computational challenges. Throughout the paper, we will see how these challenges are dealt with using scalable algorithms. 2 Collocational Lexicon Induction Rapp (1995) introduced the notion of a distributional profile in bilingual lexicon induction from monolingual data. A distributional profile (DP) of a word or phrase type is a co-occurrence vector created by combining all co-occurrence vectors of the tokens of that phrase type. Each distributional profile can be seen as a point in a |V |-dimensional space where V is the vocabulary where each word type represents a unique axis. Points (i.e. phrase types) that are close to one another in this highdimensional space can represent paraphrases. This approach has also been used in machine translation to find in</context>
<context position="31051" citStr="Rapp, 1995" startWordPosition="5253" endWordPosition="5254">raphs and show that we improve over the baseline in both the same-domain (Europarl) and domain adaptation (EMEA) settings. Table 7 shows some translations found by our system for oov words. oov gold standard candiate list undone particularly particularly specific sp´ecialement especially only special particular particular should and especially assentiment approval support agreement approval accession will approve endorses Table 7: Two examples of oov translations found by our method. 5 Related work There has been a long line of research on learning translation pairs from non-parallel corpora (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Marton et al., 2009; Laws et al., 2010). Most have focused on extracting a translation lexicon by mining monolingual resources of data to find clues, using probabilistic methods to map words, or by exploiting the cross-language evidence of closely related languages. Most of them evaluated only highfrequency words of specific types (nouns or content words) (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Laws et al., 2010) In contrast, we do not consider any constraint on our test data and our </context>
<context position="32435" citStr="Rapp, 1995" startWordPosition="5485" endWordPosition="5486"> used a third language(s) as pivot or bridge to find translation pairs (Mann and Yarowsky, 2001; Schafer and Yarowsky, 2002; Callison-Burch et al., 2006). 1112 Corpus System MRR Recall Dev Bleu Test Bleu Europarl Baseline – – 28.53 28.97 Our approach 5.9 12.6 28.76 29.40* EMEA Baseline – – 20.05 20.34 Our approach 3.6 7.4 20.54 20.80* * Statistically significant with p &lt; 0.02 using the bootstrap resampling significance test (in Moses). Table 6: Bleu scores for different domains with or without using oov translations. Context similarity has been used effectively in bilingual lexicon induction (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Marton et al., 2009; Laws et al., 2010). It has been modeled in different ways: in terms of adjacent words (Rapp, 1999; Fung and Yee, 1998), or dependency relations (Garera et al., 2009). Laws et al. (2010) used linguistic analysis in the form of graph-based models instead of a vector space. But all of these researches used an available seed lexicon as the basic source of similarity between source and target languages unlike our method which just needs a monolingual corpus of source language which is freely available for man</context>
</contexts>
<marker>Rapp, 1995</marker>
<rawString>Reinhard Rapp. 1995. Identifying word translations in non-parallel texts. In Proceedings of the 33rd annual meeting on Association for Computational Linguistics, ACL ’95, pages 320–322. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Automatic identification of word translations from unrelated english and german corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics, ACL ’99,</booktitle>
<pages>519--526</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8417" citStr="Rapp, 1999" startWordPosition="1347" endWordPosition="1348">). The top-k paraphrases that have translations in the phrase-table are used to assign translations and scores to each oov word by marginalizing translations over paraphrases: Y: p(t|o) = p(t|s)p(s|o) s where t is a phrase on the target side, o is the oov word or phrase, and s is a paraphrase of o. p(s|o) is estimated using a similarity measure over DPs and p(t|s) is coming from the phrase-table. We reimplemented this collocational approach for finding translations for oovs and used it as a baseline system. Alternative ways of modeling and comparing distributional profiles have been proposed (Rapp, 1999; Fung and Yee, 1998; Terra and Clarke, 2003; Garera et al., 2009; Marton et al., 2009). We review some of them here and compare their performance in Section 4.3. 2.2 Association Measures Given a word u, its distributional profile DP(u) is constructed by counting surrounding words (in a fixed window size) in a monolingual corpus. DP(u) = I(A(u,wi)) |wi E V } 1106 The counts can be collected in positional3 (Rapp, 1999) or non-positional way (count all the word occurrences within the sliding window). A(·, ·) is an association measure and can simply be defined as co-occurrence counts within slidi</context>
<context position="32623" citStr="Rapp, 1999" startWordPosition="5520" endWordPosition="5521"> Bleu Test Bleu Europarl Baseline – – 28.53 28.97 Our approach 5.9 12.6 28.76 29.40* EMEA Baseline – – 20.05 20.34 Our approach 3.6 7.4 20.54 20.80* * Statistically significant with p &lt; 0.02 using the bootstrap resampling significance test (in Moses). Table 6: Bleu scores for different domains with or without using oov translations. Context similarity has been used effectively in bilingual lexicon induction (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Marton et al., 2009; Laws et al., 2010). It has been modeled in different ways: in terms of adjacent words (Rapp, 1999; Fung and Yee, 1998), or dependency relations (Garera et al., 2009). Laws et al. (2010) used linguistic analysis in the form of graph-based models instead of a vector space. But all of these researches used an available seed lexicon as the basic source of similarity between source and target languages unlike our method which just needs a monolingual corpus of source language which is freely available for many languages and a small bilingual corpora. Some methods tried to alleviate the lack of seed lexicon by using orthographic similarity to extract a seed lexicon (Koehn and Knight, 2002; Fise</context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>Reinhard Rapp. 1999. Automatic identification of word translations from unrelated english and german corpora. In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics, ACL ’99, pages 519– 526. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Schafer</author>
<author>David Yarowsky</author>
</authors>
<title>Inducing translation lexicons via diverse similarity measures and bridge languages.</title>
<date>2002</date>
<booktitle>In proceedings of the 6th conference on Natural language learning - Volume 20, COLING-02,</booktitle>
<pages>1--7</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="31948" citStr="Schafer and Yarowsky, 2002" startWordPosition="5406" endWordPosition="5409">loiting the cross-language evidence of closely related languages. Most of them evaluated only highfrequency words of specific types (nouns or content words) (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Laws et al., 2010) In contrast, we do not consider any constraint on our test data and our data includes many low frequency words. It has been shown that translation of high-frequency words is easier than low frequency words (Tamura et al., 2012). Some methods have used a third language(s) as pivot or bridge to find translation pairs (Mann and Yarowsky, 2001; Schafer and Yarowsky, 2002; Callison-Burch et al., 2006). 1112 Corpus System MRR Recall Dev Bleu Test Bleu Europarl Baseline – – 28.53 28.97 Our approach 5.9 12.6 28.76 29.40* EMEA Baseline – – 20.05 20.34 Our approach 3.6 7.4 20.54 20.80* * Statistically significant with p &lt; 0.02 using the bootstrap resampling significance test (in Moses). Table 6: Bleu scores for different domains with or without using oov translations. Context similarity has been used effectively in bilingual lexicon induction (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Marton et al., 2009; Laws et al., 2010). It</context>
</contexts>
<marker>Schafer, Yarowsky, 2002</marker>
<rawString>Charles Schafer and David Yarowsky. 2002. Inducing translation lexicons via diverse similarity measures and bridge languages. In proceedings of the 6th conference on Natural language learning - Volume 20, COLING-02, pages 1–7, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
<author>Jan O Pedersen</author>
</authors>
<title>A cooccurrence-based thesaurus and two applications to information retrieval.</title>
<date>1997</date>
<journal>Inf. Process. Manage.,</journal>
<volume>33</volume>
<issue>3</issue>
<marker>Sch¨utze, Pedersen, 1997</marker>
<rawString>Hinrich Sch¨utze and Jan O. Pedersen. 1997. A cooccurrence-based thesaurus and two applications to information retrieval. Inf. Process. Manage., 33(3):307–318, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Partha Pratim Talukdar</author>
<author>Koby Crammer</author>
</authors>
<title>New Regularized Algorithms for Transductive Learning.</title>
<date>2009</date>
<booktitle>In European Conference on Machine Learning (ECML-PKDD).</booktitle>
<contexts>
<context position="16609" citStr="Talukdar and Crammer, 2009" startWordPosition="2758" endWordPosition="2762">ge weight matrix. The vertex set V consists of labeled VL and unlabeled VU nodes, and the goal of the labeling propagation algorithm is to compute soft labels for unlabeled vertices from the labeled vertices. Intuitively, the edge weight W (u, v) encodes the degree of our belief about the similarity of the soft labeling for nodes u and v. A soft label ˆYv ∈ Am+1 is a probability vector in (m + 1)- dimensional simplex, where m is the number of possible labels and the additional dimension accounts for the undefined ⊥ label6. In this paper, we make use of the modified Adsorption (MAD) algorithm (Talukdar and Crammer, 2009) which finds soft label vectors ˆYv to solve the following unconstrained optimization problem: p1,v||Yv − ˆYv||22 + (1) �µ2 p2,vWv,u ||ˆYv − ˆYu||22 + (2) v,u �µ3 p3,v||ˆYv − Rv||2 (3) v 2 where µi and pi,v are hyper-parameters (∀v : Ei pi,v = 1)7, and Rv ∈ Am+1 encodes our prior belief about the labeling of a node v. The first 6Capturing those cases where the given data is not enough to reliably compute a soft labeling using the initial m real labels. 7The values of these hyper-parameters are set to their defaults in the Junto toolkit (Talukdar and Crammer, 2009). �µ1 v∈VL min Yˆ 1108 O : oov</context>
<context position="18340" citStr="Talukdar and Crammer, 2009" startWordPosition="3078" endWordPosition="3081">2) enforces the smoothness of the labeling according to the graph structure and edge weights. The last term (3) regularizes the soft labeling for a vertex v to match a priori label R,,, e.g. for high-degree unlabeled nodes (hubs in the graph) we may believe that the neighbors are not going to produce reliable label and hence the probability of undefined label ⊥ should be higher. The optimization problem can be solved with an efficient iterative algorithm which is parallelized in a MapReduce framework (Talukdar et al., 2008; Rao and Yarowsky, 2009). We used the Junto label propagation toolkit (Talukdar and Crammer, 2009) for label propagation. 3.2 Efficient Graph Construction Graph-based approaches can easily become computationally very expensive as the number of nodes grow. In our case, we use phrases in the monolingual text as graph vertices. These phrases are n-grams up to a certain value, which can result in millions of nodes. For each node a distributional profile (DP) needs to be created. The number of possible edges can easily explode in size as there can be as many as O(n2) edges where n is the number of nodes. A common practice to control the number of edges is to connect each node to at most k other</context>
</contexts>
<marker>Talukdar, Crammer, 2009</marker>
<rawString>Partha Pratim Talukdar and Koby Crammer. 2009. New Regularized Algorithms for Transductive Learning. In European Conference on Machine Learning (ECML-PKDD).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Partha Pratim Talukdar</author>
<author>Joseph Reisinger</author>
<author>Marius Pas¸ca</author>
<author>Deepak Ravichandran</author>
<author>Rahul Bhagat</author>
<author>Fernando Pereira</author>
</authors>
<title>Weakly-supervised acquisition of labeled class instances using graph random walks.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08.</booktitle>
<marker>Talukdar, Reisinger, Pas¸ca, Ravichandran, Bhagat, Pereira, 2008</marker>
<rawString>Partha Pratim Talukdar, Joseph Reisinger, Marius Pas¸ca, Deepak Ravichandran, Rahul Bhagat, and Fernando Pereira. 2008. Weakly-supervised acquisition of labeled class instances using graph random walks. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akihiro Tamura</author>
<author>Taro Watanabe</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Bilingual lexicon extraction from comparable corpora using label propagation. In EMNLPCoNLL,</title>
<date>2012</date>
<pages>24--36</pages>
<contexts>
<context position="31806" citStr="Tamura et al., 2012" startWordPosition="5383" endWordPosition="5386">racting a translation lexicon by mining monolingual resources of data to find clues, using probabilistic methods to map words, or by exploiting the cross-language evidence of closely related languages. Most of them evaluated only highfrequency words of specific types (nouns or content words) (Rapp, 1995; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Laws et al., 2010) In contrast, we do not consider any constraint on our test data and our data includes many low frequency words. It has been shown that translation of high-frequency words is easier than low frequency words (Tamura et al., 2012). Some methods have used a third language(s) as pivot or bridge to find translation pairs (Mann and Yarowsky, 2001; Schafer and Yarowsky, 2002; Callison-Burch et al., 2006). 1112 Corpus System MRR Recall Dev Bleu Test Bleu Europarl Baseline – – 28.53 28.97 Our approach 5.9 12.6 28.76 29.40* EMEA Baseline – – 20.05 20.34 Our approach 3.6 7.4 20.54 20.80* * Statistically significant with p &lt; 0.02 using the bootstrap resampling significance test (in Moses). Table 6: Bleu scores for different domains with or without using oov translations. Context similarity has been used effectively in bilingual </context>
<context position="34825" citStr="Tamura et al., 2012" startWordPosition="5862" endWordPosition="5865">sed model to re-rank the n-best translation hypothesis. Liu et al. (2012) extended Alexandrescu’s model to use translation consensus among similar sentences in bilingual training data by developing a new structured label propagation method. They derived some features to use during decoding process that has been shown useful in improving translation quality. Our graph propagation method connects monolingual source phrases with oovs to obtain translation and so is a very different use of graph propagation from these previous works. Recently label propagation has been used for lexicon induction (Tamura et al., 2012). They used a graph based on context similarity as well as cooccurrence graph in propagation process. Similar to our approach they used unlabeled nodes in label propagation process. However, they use a seed lexicon to define labels and comparable corpora to construct graphs unlike our approach. 6 Conclusion We presented a novel approach for inducing oov translations from a monolingual corpus on the source side and a parallel data using graph propagation. Our results showed improvement over the baselines both in intrinsic evaluations and on BLEU. Future work includes studying the effect of size</context>
</contexts>
<marker>Tamura, Watanabe, Sumita, 2012</marker>
<rawString>Akihiro Tamura, Taro Watanabe, and Eiichiro Sumita. 2012. Bilingual lexicon extraction from comparable corpora using label propagation. In EMNLPCoNLL, pages 24–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Egidio L Terra</author>
<author>Charles L A Clarke</author>
</authors>
<title>Frequency estimates for statistical word similarity measures.</title>
<date>2003</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="8461" citStr="Terra and Clarke, 2003" startWordPosition="1353" endWordPosition="1356">ve translations in the phrase-table are used to assign translations and scores to each oov word by marginalizing translations over paraphrases: Y: p(t|o) = p(t|s)p(s|o) s where t is a phrase on the target side, o is the oov word or phrase, and s is a paraphrase of o. p(s|o) is estimated using a similarity measure over DPs and p(t|s) is coming from the phrase-table. We reimplemented this collocational approach for finding translations for oovs and used it as a baseline system. Alternative ways of modeling and comparing distributional profiles have been proposed (Rapp, 1999; Fung and Yee, 1998; Terra and Clarke, 2003; Garera et al., 2009; Marton et al., 2009). We review some of them here and compare their performance in Section 4.3. 2.2 Association Measures Given a word u, its distributional profile DP(u) is constructed by counting surrounding words (in a fixed window size) in a monolingual corpus. DP(u) = I(A(u,wi)) |wi E V } 1106 The counts can be collected in positional3 (Rapp, 1999) or non-positional way (count all the word occurrences within the sliding window). A(·, ·) is an association measure and can simply be defined as co-occurrence counts within sliding windows. Stronger association measures ca</context>
</contexts>
<marker>Terra, Clarke, 2003</marker>
<rawString>Egidio L. Terra and Charles L. A. Clarke. 2003. Frequency estimates for statistical word similarity measures. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorg Tiedemann</author>
</authors>
<title>News from opus - a collection of multilingual parallel corpora with tools and interfaces.</title>
<date>2009</date>
<booktitle>Recent Advances in Natural Language Processing,</booktitle>
<volume>volume V,</volume>
<pages>237--248</pages>
<editor>In N. Nicolov, K. Bontcheva, G. Angelova, and R. Mitkov, editors,</editor>
<publisher>John Benjamins, Amsterdam/Philadelphia.</publisher>
<contexts>
<context position="20592" citStr="Tiedemann, 2009" startWordPosition="3462" endWordPosition="3463"> deal with the computational challenges of such a large graph, we take advantage of the Hadoop’s MapReduce functionality to do both graph construction and label propagation steps. 4 Experiments &amp; Results 4.1 Experimental Setup We experimented with two different domains for the bilingual data: Europarl corpus (v7) (Koehn, 1109 Dataset Domain Sents Tokens En Fr Bitext Europarl 10K 298K 268K EMEA 1M 16M 14M Monotext Europarl 2M 60M – Dev-set WMT05 2K 67K 58K Test-set WMT05 2K 66K 58K Table 1: Statistics of training sets in different domains. 2005), and European Medicines Agency documents (EMEA) (Tiedemann, 2009) from French to English. For the monolingual data, we used French side of the Europarl corpus and we used ACL/WMT 20058 data for dev/test sets. Table 1 summarizes statistics of the datasets used. From the dev and test sets, we extract all source words that do not appear in the phrase-table constructed from the parallel data. From the oovs, we exclude numbers as well as named entities. We apply a simple heuristic to detect named entities: basically words that are capitalized in the original dev/test set that do not appear at the beginning of a sentence are named entities. Table 2 shows the numb</context>
</contexts>
<marker>Tiedemann, 2009</marker>
<rawString>Jorg Tiedemann. 2009. News from opus - a collection of multilingual parallel corpora with tools and interfaces. In N. Nicolov, K. Bontcheva, G. Angelova, and R. Mitkov, editors, Recent Advances in Natural Language Processing, volume V, pages 237–248. John Benjamins, Amsterdam/Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
</authors>
<title>TREC-8 Question Answering Track Report.</title>
<date>1999</date>
<booktitle>In Proceedings of the 8th Text Retrieval Conference,</booktitle>
<pages>77--82</pages>
<contexts>
<context position="23859" citStr="Voorhees, 1999" startWordPosition="4012" endWordPosition="4013">The resulting word alignments are used to extract the translations for each oov. The correctness of this gold standard is limited to the size of the parallel data used as well as the quality of the word alignment software toolkit, and is not 100% precise. However, it gives a good estimate of how each oov should be translated without the need for human judgments. For evaluating our baseline as well as graphbased approaches, we use both intrinsic and extrinsic evaluations. Two intrinsic evaluation metrics that we use to evaluate the possible translations for oovs are Mean Reciprocal Rank (MRR) (Voorhees, 1999) and Recall. Intrinsic evaluation metrics are faster to apply and are used to optimize different hyper-parameters of the approach (e.g. window size, phrase length, etc.). Once we come up with the optimized values for the hyper-parameters, we extrinsically evaluate different approaches by adding the new translations to the phrase-table and run it through the MT pipeline. 4.2.1 MRR MRR is an Information Retrieval metric used to evaluate any process that produces a ranked list of possible candidates. The reciprocal rank of a list is the inverse of the rank of the correct answer in the list. Such </context>
</contexts>
<marker>Voorhees, 1999</marker>
<rawString>Ellen M. Voorhees. 1999. TREC-8 Question Answering Track Report. In Proceedings of the 8th Text Retrieval Conference, pages 77–82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiajun Zhang</author>
<author>Feifei Zhai</author>
<author>Chengqing Zong</author>
</authors>
<title>Handling unknown words in statistical machine translation from a new perspective.</title>
<date>2012</date>
<booktitle>In Natural Language Processing and Chinese Computing,</booktitle>
<pages>176--187</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="2453" citStr="Zhang et al., 2012" startWordPosition="374" endWordPosition="377">ce of this in automatic measures such as BLEU (Papineni et al., 2002) and also in human evaluation scores such as HTER. The problem becomes more severe when only a limited amount of parallel text is available for training or when the training and test data are from different domains. Even noisy translation of oovs can aid the language model to better ∗This research was partially supported by an NSERC, Canada (RGPIN: 264905) grant. The third author was supported by an early career research award from Monash University to visit Simon Fraser University. re-order the words in the target language (Zhang et al., 2012). Increasing the size of the parallel data can reduce the number of oovs. However, there will always be some words or phrases that are new to the system and finding ways to translate such words or phrases will be beneficial to the system. Researchers have applied a number of approaches to tackle this problem. Some approaches use pivot languages (Callison-Burch et al., 2006) while others use lexicon-induction-based approaches from source language monolingual corpora (Koehn and Knight, 2002; Garera et al., 2009; Marton et al., 2009). Pivot language techniques tackle this problem by taking advant</context>
</contexts>
<marker>Zhang, Zhai, Zong, 2012</marker>
<rawString>Jiajun Zhang, Feifei Zhai, and Chengqing Zong. 2012. Handling unknown words in statistical machine translation from a new perspective. In Natural Language Processing and Chinese Computing, pages 176–187. Springer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>