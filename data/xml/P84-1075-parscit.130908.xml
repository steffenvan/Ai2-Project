<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.912945">
The Design of a Computer Language for Linguistic Information
</title>
<author confidence="0.534526">
Stuart M. Shieber
</author>
<sectionHeader confidence="0.4239035" genericHeader="abstract">
Artificial Intelligence Center
SRI International
</sectionHeader>
<bodyText confidence="0.661532666666667">
and
Center for the Study of Language and Information
Stanford University
</bodyText>
<sectionHeader confidence="0.913118" genericHeader="introduction">
Abstract
</sectionHeader>
<bodyText confidence="0.999296833333333">
A considerable body of accumulated knowledge about
the design of languages for communicating information to
computers has been derived from the subfields of program-
ming language design and semantics. It has been the goal of
the PATR group at SRI to utilize a relevant portion of this
knowledge in implementing tools to facilitate communica-
tion of linguistic information to computers. The PATR-TI
formalism is our current computer language for encoding
linguistic information. This paper, a brief overview of that
formalism, attempts to explicate our design decisions in
terms of a set of properties that effective computer lan-
guages should incorporate.
</bodyText>
<sectionHeader confidence="0.9948" genericHeader="method">
1. Introduction&apos;
</sectionHeader>
<bodyText confidence="0.999940166666667">
The goal of natural-language processing research can
be stated quite simply: to endow computers with human
language capability. The pursuit of this objective, however,
has been a difficult task for at least two reasons: first, this
capability is far from being a well-understood phenomenon;
second, the tools for teaching computers what we do know
about human language are still very primitive. The solu-
tion of these problems lies within the respective domains of
linguistics and computer science.
Similar problems have arisen previously in computer
science. Whenever a new computer application area
emerges, there follow new modes of communication with
computers that are geared towards such areas. Computer
languages are a direct result of this need for effective com-
munication with computers. A considerable body of accu-
mulated knowledge about the design of languages for com-
municating information to computers has been derived from
the subfields of programming language design and seman-
</bodyText>
<subsectionHeader confidence="0.648453666666667">
&apos;This research has been made possible in part by a gift from the Sys-
tems Development Foundation, and was also supported by the Defense
Advanced Research Projects Agency under Contract N00039-80-C-
</subsectionHeader>
<bodyText confidence="0.989257146341464">
0575 with the Naval Electronic Systems Command. The views and
conclusions contained in this document are those of the author and
should not be interpreted as representative of the official policies, ei-
ther expressed or implied, of the Defense Advanced Research Projects
Agency, or the United States government.
The author is indebted to Fernando Pereira, Barbara Grosz, and Ray
Perrault for their comments on earlier drafts.
tics. It has been the goal of the PATR group at SRI2 to
utilize a relevant portion of this knowledge in implementing
tools to facilitate communication of linguistic information
to computers.
The PATR-II formalism is our current computer lan-
guage for encoding linguistic information. This paper, a
brief overview of that formalism, attempts to explicate our
design decisions in terms of a set of properties that effec-
tive computer languages should incorporate, namely: sim-
plicity, power, mathematical well-foundedness,
implementability, modularity, and declarativeness. More
extensive discussions of various aspects of the PATR-II for-
malism and systems can be found in papers by Shieber tt.
al., [831, Pereira and Shieber [841 and Karttunen [841.
The notion of designing specialized computer lan-
guages and systems to encode linguistic information is not
new; PROGRAMMAR [Winograd, 72], ATNs [Woods, 74
and DIALOGIC [Grosz, et al., 821 are but a few of the
better-known examples. Furthermore, a trend has arisen
recently in linguistics towards declarativeness in gram-
mar formalisms—for instance, lexical-functional grammar
(LFG) [Bresnan, 831, generalized phrase-structure gram-
mar (GPSG) fGazdar and Pullum, 82] and functional uni-
fication grammar (UG) [Kay, 83]. Finally, in computer sci-
ence there has been a great deal of interest in declarative
languages (e.g., logic programming and specification lan-
guages), and their supporting denotational semantics. But
to our knowledge, no attempt has yet been made to combine
the three approaches so as to yield a declarative computer
language with clear semantics designed specifically for en-
coding linguistic information. Such a language, of which
PATR-II is an example, would reflect a felicitous conver-
gence of ideas from linguistics, artificial intelligence, and
computer science.
</bodyText>
<sectionHeader confidence="0.943431" genericHeader="method">
2. The Critical Properties of the
Language
</sectionHeader>
<bodyText confidence="0.987103333333333">
It is not the purpose of this paper to provide a compre-
hensive description of the PATR-II project, or even of the
formalism itself. Rather, we will discuss briefly the critical
</bodyText>
<footnote confidence="0.786866333333333">
2This rather liquid group has included at various times: John Bear,
Lauri Karttunen, Fernando Pereira, Jane Robinson, Stan Rosenschein,
Susan Stucky, Mabry Tyson, Hans Uszkoreit, and the author.
</footnote>
<page confidence="0.998085">
362
</page>
<bodyText confidence="0.9998955">
properties of PATR-II to give a flavor for our approach to
the design of the language. References to papers with more
complete descriptions of particular aspects of the project
are provided when appropriate.
</bodyText>
<subsectionHeader confidence="0.818169">
2.1. Simplicity: An Introduction to the
PATR-II Formalism
</subsectionHeader>
<bodyText confidence="0.999607">
Building on a convergence of ideas from the linguistics
and Al communities, PATH-II takes as its primitive opera-
tion an extended pattern-matching technique, unification,
first used in logic and theorem-proving research and lately
finding its way into research in linguistics [Kay, 79; Gazdar
and PuIlum, 821 and knowledge representation [Reynolds,
70; Ait-Kaci, 83). Instead of unifying logic terms, how-
ever, PAIR unification operates on directed acyclic graphs
(DAG).3
DAGs can be atomic symbols or sets of label/value
pairs, where the values are themselves DAGs (either atomic
or complex). Two labels can have the same value—thus the
use of the term graph rather than tree. DAGs are notated
either by drawing the graph structure itself, with the la-
bels marking the arcs, or, as in this paper, by notating the
sets of label/value pairs in square brackets, with the labels
separated from their values by a colon; e.g., a DAG associ-
ated with the verb &amp;quot;knight&amp;quot; (as in &amp;quot;Ether wants to knight
Arthur&amp;quot;) would appear (in at least one of our grammars)
as
whose value will be the category of the associated lexical
entry. Other arcs may encode information about the syn-
tactic features, translation, or syntactic subcategorization
of the entry. But only the label cat has any special sig-
nificance; it provides the link between context-free phrase
structure rules and the DAGs, as explicated below.
PATR-II grammars consist of rules with a context-free
phrase structure portion and a set of unifications on the
DAGs associated with the constituents that participate in
the application of the rule. The grammar rules describe how
constituents can be built up to form new constituents with
associated DAGs. The right side of the rule lists the cat
values of the DAGs associated with the filial constituents;
the left side, the cat of the parent. The associated uni-
fications specify equivalences that must exist among the
various DAGs and sub-DAGs of the parent and children.
Thus, the formalism uses only one representation- --DAGs----
for lexical, syntactic, and semantic information, and one
operation—unification--on this representation.
By way of example, we present a trivial grammar for a
fragment of English with a lexicon associating words with
DAGs.
</bodyText>
<equation confidence="0.9397116">
S NP VP
&lt;VP agr&gt; = &lt;NP agr&gt;
V NP
&lt;VP agr&gt; = &lt;V agr&gt;
Uther:
</equation>
<bodyText confidence="0.914264633333334">
[cat: v
head: [aux: false
form: nonfinite
voice: active
trans: [pred: knight
argl: cf1134&gt;
arg2: &lt;f1138&gt;
[l]]
syncat : [first: [cat: np
head: [trans: &lt;f1134&gt;]]
rest: [first: [cat: np
head: [trans: &lt;f1138&gt;]]
rest: &lt;f1140&gt;
. lambda]
tail: &lt;f1140&gt;]]
Reentrant structure is notated by labeling the DAG with
an arbitrary label (in angle brackets), then using that label
for future references to the DAG,
Associated with each entry in the lexicon is a set of
DAGs.4 The root of each DAG will have an arc labeled cat
sTechnically, these are rooted, directed, acyclic graphs with labeled
arcs. Formal definition of these and other technical notions can be
found in Appendix A of Shieber et at. 1831. Note that some imple-
mentations have been extended to handle cyclic graph structures as
well as graph structures with disjunction and negation 1Karttunen,
841.
4In our implementation, this association is not directly encoded—since
this would yield a grossly inefficient characterization of the lexicon—
but is mediated by a morphological analyzer. See Section 2.6 for
further details.
</bodyText>
<equation confidence="0.890118636363637">
&lt;cal&gt; = np
&lt;agr number&gt; = singular
&lt;agr person&gt; = third
Arthur:
&lt;cat&gt; = np
&lt;agr number&gt; = singular
&lt;agr person&gt; = third
knights:
&lt;cat&gt; =
&lt;agr number&gt; = singular
&lt;agr person&gt; = third
</equation>
<bodyText confidence="0.999597058823529">
This grammar (plus lexicon) admits the two sentences
&amp;quot;Uther knights Arthur&amp;quot; and &amp;quot;Arthur knights Uther.&amp;quot; The
phrase structure associated with the first of these is:
Is [NP Uther) [yr Iv knights) [NP Arthur)))
The VP rule requires that the agr feature of the DAG
associated with the VP be the same as (unified with) the agr
of the V. Thus, the VP&apos;s agr feature will have as its value
the same node as the V&apos;s agr, and hence the same values
for the person and number features. Similarly, by virtue of
the unification associated with the S rule, the NP will have
the same agr value as the VP and, consequently, the V. We
have thus encoded a form of subject-verb agreement.
Note that the process of unification is order-independent.
For instance, we would get the same effect regardless of
whether the unifications at the top of the parse tree were
effected before or after those at the bottom. In either case,
the DAG associated with, e.g., the VP node would be
</bodyText>
<page confidence="0.994591">
363
</page>
<listItem confidence="0.570911333333333">
[cat: vp
agr: [person: third
number: singular]]
</listItem>
<bodyText confidence="0.9999305">
These trivial examples of grammars and lexicons offer
but a glimpse of the techniques used in writing PATR-H
grammars, arid do not begin to employ the power of unifi-
cation as a general information-passing mechanism. Exam-
ples of the use of PATR-II for encoding much more complex
linguistic phenomena can be found in Shieber et at. 184
</bodyText>
<subsectionHeader confidence="0.98753">
2.2. Power: Two Variants
</subsectionHeader>
<bodyText confidence="0.9999508">
Augmented phrase-structure grammars such as PATR-
II ran in fart be quite powerful. The ability to encode
unbounded amounts of information in the augmentations
(which PATIt-ll obviously allows) gives this formalism the
power of a Turing machine. As a linguistic theory, this
much power might be considered disadvantageous; as a
computer language, however, such power is clearly desir-
able. since the intent of the language is to enable the mod-
eling of many kinds of linguistic analyses from a range of
theories. As such, PATR-H is a tool, not a result.
Nevertheless, a good case could be made for maintain-
ing at lea.st the decidability of determining whether a string
is admitted by a PATR-II grammar. This property can be
ensured by requiring the context-free skeleton to have the
property of off-line parsability [Pereira, 83), which was used
originally in the definition of LFG to maintain the decid-
ability of that formalism [Kaplan and Bresnan, 83]. Off-line
parsability requires that the context-free &amp;quot;skeleton&amp;quot; of the
grammar allows no trivial cyclic derivations of the form
fl
</bodyText>
<subsectionHeader confidence="0.99699">
2.3. Mathematical Well-Foundedness: A
Denotational Semantics
</subsectionHeader>
<bodyText confidence="0.999967846153846">
One reason for maintaining the simplicity of the bare
PATR-I1 formalism is to permit a clean semantics for the
language. We have provided a denotational semantics for
PATR-11 [Pereira and Shieber, 841 based on the information
systems domain theory of Dana Scott [Scott, 82). Insofar as
more complex formalisms, such as GPSG and LFG, can be
modeled as appropriate notations for PATR-II grammars,
PATR-11&apos;s denotational semantics constitutes a framework
in which the semantics of these formalisms can also be de-
fined, discussed, and compared. As it appears that not all
the power of domain theory is needed for the semantics of
PATR-II, we are currently pursuing the possibility of build-
ing a semantics based on a less powerful mode1.3
</bodyText>
<subsectionHeader confidence="0.788575">
2.4. Flexibility: Modeling Linguistic Con-
structs
</subsectionHeader>
<bodyText confidence="0.993583902439025">
Clearly, the bare PATR-II formalism, as it was pre-
sented in Section 2.1, is sorely inadequate for any major
attempt at building natural-language grammars because of
its verbosity and redundancy. Efficiency of encoding was
5 But see Pereira and Shieber 184j for arguments in favor of using domain
theory even if all the available power is not utilized.
temporarily sacrificed in an attempt to keep the underlying
formalism simple, general, and semantically well-founded.
However, given a simple underlying formalism, we can build
more efficient, specialized languages on top of it, much as
MACLISP might be built on top of pure LISP. And just
as MACLISP need not be implemented (and is not imple-
mented) directly in pure LISP, specialized formalisms built
conceptually on top of pure PATR-II need not be so imple-
mented (although currently we do implement them directly
through pure PATR-II). The effectiveness of this approach
can be seen in the fact that at least a sizable portion of
English syntax has been encoded in various experimental
PATR-II grammars constructed to date. The syntactic con-
structs encoded include subcategorization of various com-
plement types (NPs, Ss, etc.), active, passive, &amp;quot;there&amp;quot; in-
sertion, extraposition, raising, and equi-NP constructions,
and unbounded dependencies (such as Wh-movement and
relative clauses). Other theory-dependent devices that have
been modeled with PATR-II include head-feature percola-
tion (Gazdar and Pullum, 821, and LFG-like semantic forms
[Kaplan and Bresnan, 83). Note that none of these con-
structs and techniques required expansion of the underly-
ing formalism; indeed, the constructions all make use of the
techniques described in this section. See Shieber et al. [831
for a detailed discussion of the modeling of some of these
phenomena.
The devices now available for molding PAM-II to con-
form to a particular intended usage or linguistic theory are
in their nascent stage. However, because of their great im-
portance in making the PATH-Il system a usable one, we
will discuss them briefly. It is important to keep in mind
that these methods should not be considered a part of the
underlying formalism, but merely &amp;quot;syntactic sugar&amp;quot; to in-
crease the system&apos;s utility and allow it to conform to a
user&apos;s intentions.
</bodyText>
<sectionHeader confidence="0.305055" genericHeader="method">
2.4.1. Templates
</sectionHeader>
<bodyText confidence="0.997574357142857">
Because so much of the information in the PATR-II
grammars under actual development tends to be encoded
in the lexicon, most of our research has been devoted to
methods for removing redundancy in the lexicon by allow-
ing the users themselves to define primitive constructs and
operations on lexical items. Primitive constructs, such as
the transitive, dyadic, or equi-NP properties of a verb, can
be defined by means of templates, that is, DAGs that en-
code some linguistically isolable portion of the DAG of a
lexical item. These template DAGs can then be combined
to build the lexical item out of the user-defined primitives.
As a simple example, we could define (with the follow-
ing syntax) the template Verb as
Let Verb be
</bodyText>
<equation confidence="0.900555">
&lt;cat&gt; = V
</equation>
<bodyText confidence="0.7439064">
and the template ThirdSing as
Let ThirdSing be
&lt;agr number&gt; = singular
&lt;agr person&gt; = third
The lexical entry for &amp;quot;knights&apos; would then be
</bodyText>
<page confidence="0.995813">
364
</page>
<bodyText confidence="0.875958444444444">
knights:
Verb ThirdSing
Templates can themselves refer to other templates, en-
abling definition of abstract linguistic concepts hierarchi-
cally. For instance, a modal verb template may use an aux-
iliary verb template, which in term may be defined using
the verb template above. In fact, templates are currently
employed for abstracting notions of subcategorization, verb
form, semantic type, and a host of other concepts.
</bodyText>
<subsectionHeader confidence="0.799866">
2.4.2. Lexical Rules
</subsectionHeader>
<bodyText confidence="0.999968347826087">
More complex relationships among lexical items can be
encoded by means of lexical rules. These rules, such as
passive and &amp;quot;there&amp;quot; insertion, are user-definable operations
on the lexical items, enabling one variant of a word to be
built from the specification of another variant. A lexical
rule is specified as a set of selective unifications relating an
input DAG and an output DAG. Thus, unification is the
primitive used in this device as well.
Lexical rules are used to encode the relationships among
various lexical entries that would typically be thought of as
transformations or relation-changing rules (depending on
one&apos;s ideological outlook). Because lexical rules perform
these operations, the lexicon need include only a proto-
type entry for each verb. The variant forms can be derived
through lexical rules applied in accordance with the mor-
phology actually found on the verb. (The morphological
analysis in the implementations of PATR-II is performed
by a program based on the system of Koskenniemi 1831 and
was written by Lauri Karttunen 18314
For instance, given a PATR-II grammar in which the
DAGs are used to emulate the f-structures of LFG, we
might write a passive lexical rule as follows (following Bres-
nan [83]):6
</bodyText>
<subsectionHeader confidence="0.287676">
Define Passive as
</subsectionHeader>
<bodyText confidence="0.802105909090909">
&lt;out cat&gt; = &lt;in cat&gt;
&lt;out form&gt; = pasaprt
&lt;out subj&gt; = &lt;in obj&gt;
&lt;out obj&gt; = &lt;in subj&gt;
The rule states in effect that the output DAG (the one
associated with the passive verb form) marks the lexical
item as being a passive verb whose object is the input
DAG&apos;s subject and whose subject is the input&apos;s object. Such
lexical rules have been used for encoding the active/passive
dichotomy, &amp;quot;there&amp;quot; insertion, extraposition, and other so-
called relation-changing rules.
</bodyText>
<subsectionHeader confidence="0.997171">
2.5. Modularity and Declarativeness
</subsectionHeader>
<bodyText confidence="0.9999775">
The PATR-II formalism is a completely declarative for-
malism, as evidenced by its denotational semantics and the
order-independence of its definition. Modularity is achieved
through the ability to define primitive templates and lex-
ical rules that are shared among lexical items, as well as
by the declarative nature of the grammar formalism itself,
</bodyText>
<footnote confidence="0.608866666666667">
6The example is merely meant to be indicative of the syntax for and
operation of lexical rules. We do not present this as a valid definition
of Passive for any grammar we have written in PATR-II.
</footnote>
<bodyText confidence="0.999491333333333">
removing problems of interaction of rules. Rules are guar-
anteed to always mean the same thing, regardless of the
environment of other rules in which they are placed.
</bodyText>
<subsectionHeader confidence="0.921995">
2.6. Implementability
</subsectionHeader>
<bodyText confidence="0.999802916666667">
Implementability is an empirical matter, given credence
by the fact that we now have three implementations of
the formalism. One desirable aspect of the simplicity and
declarative nature of the formalism is that even though
the three implementations differ substantially from one an-
other, using different parsing algorithms (with both top
down and bottom up properties), different implementations
of unification, different methods of compiling the rules, all
are able to run on exactly the same grammars yielding the
identical results.
The three implementations of the PATR-II system cur-
rently in operation at SRI are as follows:
</bodyText>
<listItem confidence="0.969167083333333">
• An INTERLISP version for the DEC-2060 using a
variant of the Cocke-Kasami-Younger parsing algo-
rithm and the KIMMO morphological analyzer [Kart-
tunen, 83], and a limited programming environment.
• A ZETALISP version for the Symbolics 3600 using a
left-corner parsing algorithm and the KIMNIO mor-
phological analyzer, with an extensive programming
environment (due primarily to Mabry Tyson) that in-
cludes incremental compilation, multiple window de-
bugging facilities, tracing, and an integrated editor.
• A Prolog version (DEC-10 Prolog) running on the
DEC-2060 by Fernando Pereira, designed primarily as
</listItem>
<bodyText confidence="0.9875285">
a testbed for experimentation with efficient structure-
sharing DAG unification algorithms, and incorporat-
ing an Earley-style parsing algorithm.
In addition, Lauri Karttunen and his students at the
University of Texas have implemented a system based on.
PATR-II but with several interesting extensions, including
disjunction and negation in the graph structures [Kart-
tunen, 84]. These extensions will undoubtedly be inte-
grated into the SRI systems and formal semantics for them
are being pursued.
</bodyText>
<sectionHeader confidence="0.996685" genericHeader="conclusions">
3. Conclusion
</sectionHeader>
<bodyText confidence="0.9999952">
The PATR-II formalism was designed as a computer
language for encoding linguistic information. The design
was influenced by current theory and practice in computer
science, and especially in the areas of programming lan-
guage design and semantics. The formalism is simple (con-
sisting of just one primitive operation, unification), power-
ful (although it can be constrained to be decidable), math-
ematically well-founded (with a complete denotational se-
mantics), flexible (as demonstrated by its ability to model
analyses in GPSG, LFG, DCG and other formalisms), mod-
ular (because of its higher-level notational devices such as
templates and lexical rules), declarative (yielding order-
independence of operations), and implementable (as demon-
strated by three quite dissimilar implemented systems and
one highly developed programming environment).
</bodyText>
<page confidence="0.996825">
365
</page>
<bodyText confidence="0.99994025">
As we have emphasized herein, PATR-II seems to rep-
resent a convergence of techniques from several domains—
computer science, programming language design, natural
language processing and linguistics. Its positioning at the
center of these trends arises, however, not from the ad-
mixture of many discrete techniques, but rather from the
application of a single simple yet powerful concept to the
encoding of linguistic information.
</bodyText>
<sectionHeader confidence="0.999423" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999819385964912">
Ait-Kaci, II., 1983: &amp;quot;A new Model of Computation Based on a
Calculus of Type Subsumption,&amp;quot; Doctoral Dissertation Pro-
posal, Dept. of Computer and Information Science, Univer-
sity of Pennsylvania (November).
Bresnan, Joan, 1983: The mental representation of grammatical
relations (ed.), Cambridge: MIT Press.
Gazdar, G. and C.K. PuHum, 1982: &amp;quot;GPSG: A Theoretical Syn-
opsis,&amp;quot; Indiana University Linguistics Club, Bloomington,
Indiana.
Grosz, B., N. Haas, C. Hendrix. J. Hobbs, P. Martin, R. Moore,
J. Robinson and S. Rosensehein, 1982: &apos;DIALOGIC: a
core natural-language processing system,&amp;quot; Proceedings of the
Ninth International Conference on Computational Linguis-
tics, Prague, Czechoslavakia (July), pp. 95-100.
Kaplan, R. and J. Bresnan, 1983: &amp;quot;Lexical-Functional Gram-
mar: A Formal System for Grammatical Representation,&amp;quot;
in J. 13resnan (ed.), The mental representation of grammat-
ical relations (ed.), cambridge: MIT Press.
Karttunen, L., 1981: &amp;quot;Features and Values,&amp;quot; Proceedings of
the Tenth International Conference on Computational Lin-
guistics, Stanford University, Stanford California (4-7 July,
1984).
Karttunen, L., 1983: &amp;quot;K IMMO: a general morphological proces-
sor,&apos; Texas Linguistic Forum, Volume 22 (December), pp.
161-185.
Kay, M., 1979: &amp;quot;Functional Crammar,&amp;quot; in Proceedings of the
Fifth Annual Meeting of the Berkeley Linguistics Society,
Berkeley, California (17-10 February).
Kay, M., 1083: &amp;quot;Unification Grammar,&amp;quot; unpublished memo, Xe-
rox Palo Alto Research Center.
Koskenniemi, K., 1083: &amp;quot;A Two level Model for Morphologi-
cal Analysis and Synthesis,&apos; forthcoming Ph.D. dissertation,
University of Helsinki, Helsinki, Finland.
Pereira, F. and D.11.D. Warren, 1983: &amp;quot;Parsing as Deduction,&amp;quot;
in Proceedings of the :21st Annual Meeting of the Association
for Computationol Linguistics (15-17 June), pp. 137-144.
Pereira, F. and S. Shieber, 1981: &amp;quot;The Semantics of Grammar
Formalisms Seen as Computer Languages,&amp;quot; Proceedings of
the Tenth International Conference on Computational Lin-
guistics, Stanford University, Stanford California (4-7 July,
1984).
Reynolds, J., 1970: &amp;quot;Transformational Systems and the Alge-
braic Structure of Atomic Formulas,&amp;quot; in D. Michie (ed.),
Machine Intelligence, Vol. 5, Chapter 7, Edinburgh, Scot-
land: Edinburgh University Press, pp. 135-151.
Scott, D., 1982: &amp;quot;Domains for Denotational Semantics,&amp;quot; ICALP
&apos;82, Aarhus, Denmark (July).
Shieber, S., H. Uszkoreit, F. Pereira, J. Robinson, and M. Tyson,
1983: &amp;quot;The Formalism and Implementation of PATR-II,&amp;quot; in
B. Grosz and M. Stickel, Research on Interactive Acquisi-
tion and Use of Knowledge, SRI Final Report 1804, SRI
International, Menlo Park, California (November).
Winograd, T., 1972: Understanding Natural Language, New
York, New York: Academic Press.
Woods, W., 1970: &amp;quot;Transition Network Grammars for Natural
Language Analysis,&amp;quot; Communications of the ACM, Vol. 13,
No. 10 (October).
</reference>
<page confidence="0.999077">
366
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.978567">
<title confidence="0.999981">The Design of a Computer Language for Linguistic Information</title>
<author confidence="0.999995">Stuart M Shieber</author>
<affiliation confidence="0.9987746">Artificial Intelligence Center SRI International and Center for the Study of Language and Information Stanford University</affiliation>
<abstract confidence="0.998801230769231">A considerable body of accumulated knowledge about the design of languages for communicating information to computers has been derived from the subfields of programming language design and semantics. It has been the goal of the PATR group at SRI to utilize a relevant portion of this knowledge in implementing tools to facilitate communication of linguistic information to computers. The PATR-TI formalism is our current computer language for encoding linguistic information. This paper, a brief overview of that formalism, attempts to explicate our design decisions in terms of a set of properties that effective computer languages should incorporate.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ait-Kaci</author>
</authors>
<title>A new Model of Computation Based on a Calculus of Type Subsumption,&amp;quot;</title>
<date>1983</date>
<institution>Doctoral Dissertation Proposal, Dept. of Computer and Information Science, University of Pennsylvania</institution>
<marker>Ait-Kaci, 1983</marker>
<rawString>Ait-Kaci, II., 1983: &amp;quot;A new Model of Computation Based on a Calculus of Type Subsumption,&amp;quot; Doctoral Dissertation Proposal, Dept. of Computer and Information Science, University of Pennsylvania (November).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan Bresnan</author>
</authors>
<title>The mental representation of grammatical relations</title>
<date>1983</date>
<editor>(ed.),</editor>
<publisher>MIT Press.</publisher>
<location>Cambridge:</location>
<marker>Bresnan, 1983</marker>
<rawString>Bresnan, Joan, 1983: The mental representation of grammatical relations (ed.), Cambridge: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
<author>C K PuHum</author>
</authors>
<title>GPSG: A Theoretical Synopsis,&amp;quot;</title>
<date>1982</date>
<institution>Indiana University Linguistics Club,</institution>
<location>Bloomington, Indiana.</location>
<marker>Gazdar, PuHum, 1982</marker>
<rawString>Gazdar, G. and C.K. PuHum, 1982: &amp;quot;GPSG: A Theoretical Synopsis,&amp;quot; Indiana University Linguistics Club, Bloomington, Indiana.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hobbs</author>
<author>P Martin</author>
<author>R Moore</author>
<author>J Robinson</author>
<author>S Rosensehein</author>
</authors>
<title>DIALOGIC: a core natural-language processing system,&amp;quot;</title>
<date>1982</date>
<booktitle>Proceedings of the Ninth International Conference on Computational Linguistics,</booktitle>
<pages>95--100</pages>
<location>Prague, Czechoslavakia</location>
<marker>Hobbs, Martin, Moore, Robinson, Rosensehein, 1982</marker>
<rawString>Grosz, B., N. Haas, C. Hendrix. J. Hobbs, P. Martin, R. Moore, J. Robinson and S. Rosensehein, 1982: &apos;DIALOGIC: a core natural-language processing system,&amp;quot; Proceedings of the Ninth International Conference on Computational Linguistics, Prague, Czechoslavakia (July), pp. 95-100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kaplan</author>
<author>J Bresnan</author>
</authors>
<title>Lexical-Functional Grammar: A Formal System for Grammatical Representation,&amp;quot;</title>
<date>1983</date>
<editor>in J. 13resnan (ed.),</editor>
<publisher>MIT Press.</publisher>
<location>cambridge:</location>
<marker>Kaplan, Bresnan, 1983</marker>
<rawString>Kaplan, R. and J. Bresnan, 1983: &amp;quot;Lexical-Functional Grammar: A Formal System for Grammatical Representation,&amp;quot; in J. 13resnan (ed.), The mental representation of grammatical relations (ed.), cambridge: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Karttunen</author>
</authors>
<title>Features and Values,&amp;quot;</title>
<date>1981</date>
<booktitle>Proceedings of the Tenth International Conference on Computational Linguistics,</booktitle>
<location>Stanford University, Stanford California</location>
<marker>Karttunen, 1981</marker>
<rawString>Karttunen, L., 1981: &amp;quot;Features and Values,&amp;quot; Proceedings of the Tenth International Conference on Computational Linguistics, Stanford University, Stanford California (4-7 July, 1984).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Karttunen</author>
</authors>
<title>K IMMO: a general morphological processor,&apos;</title>
<date>1983</date>
<journal>Texas Linguistic Forum, Volume</journal>
<volume>22</volume>
<pages>161--185</pages>
<marker>Karttunen, 1983</marker>
<rawString>Karttunen, L., 1983: &amp;quot;K IMMO: a general morphological processor,&apos; Texas Linguistic Forum, Volume 22 (December), pp. 161-185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
</authors>
<title>Functional Crammar,&amp;quot;</title>
<date>1979</date>
<booktitle>in Proceedings of the Fifth Annual Meeting of the Berkeley Linguistics Society,</booktitle>
<location>Berkeley, California</location>
<marker>Kay, 1979</marker>
<rawString>Kay, M., 1979: &amp;quot;Functional Crammar,&amp;quot; in Proceedings of the Fifth Annual Meeting of the Berkeley Linguistics Society, Berkeley, California (17-10 February).</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Kay</author>
</authors>
<title>1083: &amp;quot;Unification Grammar,&amp;quot; unpublished memo, Xerox Palo Alto Research Center.</title>
<marker>Kay, </marker>
<rawString>Kay, M., 1083: &amp;quot;Unification Grammar,&amp;quot; unpublished memo, Xerox Palo Alto Research Center.</rawString>
</citation>
<citation valid="false">
<authors>
<author>K Koskenniemi</author>
</authors>
<title>1083: &amp;quot;A Two level Model for Morphological Analysis and Synthesis,&apos; forthcoming</title>
<institution>University of Helsinki,</institution>
<location>Helsinki, Finland.</location>
<note>Ph.D. dissertation,</note>
<marker>Koskenniemi, </marker>
<rawString>Koskenniemi, K., 1083: &amp;quot;A Two level Model for Morphological Analysis and Synthesis,&apos; forthcoming Ph.D. dissertation, University of Helsinki, Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pereira</author>
<author>D 11 D Warren</author>
</authors>
<title>Parsing as Deduction,&amp;quot;</title>
<date>1983</date>
<booktitle>in Proceedings of the :21st Annual Meeting of the Association for Computationol Linguistics</booktitle>
<pages>137--144</pages>
<marker>Pereira, Warren, 1983</marker>
<rawString>Pereira, F. and D.11.D. Warren, 1983: &amp;quot;Parsing as Deduction,&amp;quot; in Proceedings of the :21st Annual Meeting of the Association for Computationol Linguistics (15-17 June), pp. 137-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pereira</author>
<author>S Shieber</author>
</authors>
<title>The Semantics of Grammar Formalisms Seen as Computer Languages,&amp;quot;</title>
<date>1981</date>
<booktitle>Proceedings of the Tenth International Conference on Computational Linguistics,</booktitle>
<location>Stanford University, Stanford California</location>
<marker>Pereira, Shieber, 1981</marker>
<rawString>Pereira, F. and S. Shieber, 1981: &amp;quot;The Semantics of Grammar Formalisms Seen as Computer Languages,&amp;quot; Proceedings of the Tenth International Conference on Computational Linguistics, Stanford University, Stanford California (4-7 July, 1984).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Reynolds</author>
</authors>
<title>Transformational Systems and the Algebraic Structure of Atomic Formulas,&amp;quot;</title>
<date>1970</date>
<journal>Machine Intelligence,</journal>
<volume>5</volume>
<pages>135--151</pages>
<editor>in D. Michie (ed.),</editor>
<publisher>Edinburgh University Press,</publisher>
<location>Edinburgh, Scotland:</location>
<marker>Reynolds, 1970</marker>
<rawString>Reynolds, J., 1970: &amp;quot;Transformational Systems and the Algebraic Structure of Atomic Formulas,&amp;quot; in D. Michie (ed.), Machine Intelligence, Vol. 5, Chapter 7, Edinburgh, Scotland: Edinburgh University Press, pp. 135-151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Scott</author>
</authors>
<title>Domains for Denotational Semantics,&amp;quot;</title>
<date>1982</date>
<booktitle>ICALP &apos;82,</booktitle>
<location>Aarhus, Denmark</location>
<marker>Scott, 1982</marker>
<rawString>Scott, D., 1982: &amp;quot;Domains for Denotational Semantics,&amp;quot; ICALP &apos;82, Aarhus, Denmark (July).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Shieber</author>
<author>H Uszkoreit</author>
<author>F Pereira</author>
<author>J Robinson</author>
<author>M Tyson</author>
</authors>
<title>The Formalism and Implementation of PATR-II,&amp;quot;</title>
<date>1983</date>
<booktitle>Research on Interactive Acquisition and Use of Knowledge, SRI Final Report 1804, SRI International,</booktitle>
<location>Menlo Park, California</location>
<note>in</note>
<marker>Shieber, Uszkoreit, Pereira, Robinson, Tyson, 1983</marker>
<rawString>Shieber, S., H. Uszkoreit, F. Pereira, J. Robinson, and M. Tyson, 1983: &amp;quot;The Formalism and Implementation of PATR-II,&amp;quot; in B. Grosz and M. Stickel, Research on Interactive Acquisition and Use of Knowledge, SRI Final Report 1804, SRI International, Menlo Park, California (November).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Winograd</author>
</authors>
<title>Understanding Natural Language,</title>
<date>1972</date>
<publisher>Academic Press.</publisher>
<location>New York, New York:</location>
<marker>Winograd, 1972</marker>
<rawString>Winograd, T., 1972: Understanding Natural Language, New York, New York: Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Woods</author>
</authors>
<title>Transition Network Grammars for Natural Language Analysis,&amp;quot;</title>
<date>1970</date>
<journal>Communications of the ACM,</journal>
<volume>13</volume>
<marker>Woods, 1970</marker>
<rawString>Woods, W., 1970: &amp;quot;Transition Network Grammars for Natural Language Analysis,&amp;quot; Communications of the ACM, Vol. 13, No. 10 (October).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>