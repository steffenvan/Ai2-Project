<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000019">
<title confidence="0.9148055">
Feasibility Study for Ellipsis Resolution in Dialogues
by Machine-Learning Technique
</title>
<author confidence="0.405584">
YAMAMOTO Kazuhide and SUMITA Eiichiro
</author>
<affiliation confidence="0.343833">
ATR Interpreting Telecommunications Research Laboratories
</affiliation>
<email confidence="0.964026">
E-mail: yamamotoOitl.atr.co.jp
</email>
<sectionHeader confidence="0.955781" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999735">
A method for resolving the ellipses that appear
in Japanese dialogues is proposed. This method
resolves not only the subject ellipsis, but also
those in object and other grammatical cases. In
this approach, a machine-learning algorithm is
used to select the attributes necessary for a res-
olution. A decision tree is built, and used as
the actual ellipsis resolver. The results of blind
tests have shown that the proposed method was
able to provide a resolution accuracy of 91.7%
for indirect objects, and 78.7% for subjects with
a verb predicate. By investigating the decision
tree we found that topic-dependent attributes
are necessary to obtain high performance res-
olution, and that indispensable attributes vary
according to the grammatical case. The prob-
lem of data size relative to decision-tree training
is also discussed.
</bodyText>
<sectionHeader confidence="0.99558" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999563949152542">
In machine translation systems, it is necessary
to resolve ellipses when the source language
doesn&apos;t express the subject or other grammat-
ical cases and the target must express it. The
problem of ellipsis resolution is also troublesome
in information extraction and other natural lan-
guage processing fields.
Several approaches have been proposed to
resolve ellipses, which consist of endophoric
(intrasentential or anaphoric) ellipses and ex-
ophoric (or extrasentential) ellipses. One of the
major approaches for endophoric ellipsis in the-
oretical basis utilizes the centering theory. How-
ever, its application to complex sentences has
not been established because most studies have
only investigated its effectiveness with succes-
sive simple sentences.
Several studies of this problem have been
made using the empirical approach. Among
them, Murata and Nagao (1997) proposed a
scoring approach where each constraint is man-
ually scored with an estimation of possibility,
and the resolution is conducted by totaling the
points each candidate receives. On the other
hand, Nakaiwa and Shirai (1996) proposed a
resolving algorithm for Japanese exophoric el-
lipses of written texts, utilizing semantic and
pragmatic constraints. They claimed that 100%
of the ellipses with exophoric referents could be
resolved, but the experiment was a closed test
with only a few samples. These approaches al-
ways require some effort to decide the scoring
or the preference of provided constraints.
Aone and Bennett (1995) applied a machine-
learning technique to anaphora resolution in
written texts. They attempted endophoric ellip-
sis resolution as a part of anaphora resolution,
with approximately 40% recall and 74% preci-
sion at best from 200 test samples. However,
they were not concerned with exophoric ellipsis.
In contrast, we applied a machine-learning ap-
proach to ellipsis resolution (Yamamoto et al.,
1997). In this previous work we resolved the
agent case ellipses in dialogue, with a limited
topic, and performed with approximately 90%
accuracy. This does not sufficiently determine
the effectiveness of the decision tree, and the
feasibility of this technique in resolving ellipses
by each surface case is also unclear.
We propose a method to resolve the ellipses
that appear in Japanese dialogues. This method
resolves not only the subject ellipsis, but also
the object and other grammatical cases. In this
approach, a machine-learning algorithm is used
to build a decision tree by selecting the neces-
sary attributes, and the decision tree is used as
the actual ellipsis resolver.
Another purpose of this paper is to discuss
how effective the machine-learning approach is
</bodyText>
<page confidence="0.988122">
1428
</page>
<bodyText confidence="0.9991639">
in the problem of ellipsis resolution. In the fol-
lowing sections, we discuss topic-dependency in
decision trees and compare the resolution effec-
tiveness of each grammatical case. The problem
of data size relative to the decision-tree training
is also discussed.
In this paper, we assume that the detection
of ellipses is performed by another module, such
as a parser. We only considered ellipses that are
commonly and clearly identified.
</bodyText>
<sectionHeader confidence="0.459085" genericHeader="method">
2 When to Resolve Ellipsis in MT ?
</sectionHeader>
<bodyText confidence="0.999965">
As described above, our major application for
ellipsis resolution is in machine translation. In
an MT process, there can be several approaches
about the timing of ellipsis resolution: when
analyzing the source language, when generat-
ing the target language, or at the same time as
translating process. Among these candidates,
most of the previous works with Japanese chose
the source-language approach. For instance,
Nakaiwa and Shirai (1996) attempted to re-
solve Japanese ellipsis in the source language
analysis of J-to-E MT, despite utilizing target-
dependent resolution candidates.
We originally thought that ellipsis resolution
in the MT was a generation problem, namely
a target-driven problem which utilizes some
help, if necessary, of source-language informa-
tion. This is because the problem is output-
dependent and it relies on demands from a
target language. In the J-to-Korean or J-to-
Chinese MT, all or most of the ellipses that
must be resolved in J-to-E are not necessary to
resolve.
However, we adopted source-language policy
in this paper, with the necessity that we con-
sider a multi-lingual MT system TDMT (Furuse
et al.. 1995), that deals with both J-to-E and J-
to-German MT. English and German grammar
are not generally believed to be similar.
</bodyText>
<sectionHeader confidence="0.966796" genericHeader="method">
3 Ellipsis Resolution by Machine
</sectionHeader>
<subsectionHeader confidence="0.674126">
Learning
</subsectionHeader>
<bodyText confidence="0.998245428571429">
Since a huge text corpus has become widely
available, the machine-learning approach has
been utilized for some problems in natural lan-
guage processing. The most popular touchstone
in this field is the verbal case frame or the trans-
lation rules (Tanaka, 1994). Machine-learning
algorithm has also been attempted to solve some
</bodyText>
<tableCaption confidence="0.989325">
Table 1: Tagged Ellipsis Types
</tableCaption>
<bodyText confidence="0.515072">
Tag Meaning
</bodyText>
<listItem confidence="0.9886145">
(lsg) first person, singular
(lp1) first person, plural
(2sg) second person, singular
(2pl) second person, plural
(g) person(s) in general
(a) anaphoric
</listItem>
<bodyText confidence="0.999844333333333">
discourse processing problems, for example, in
discourse segment boundaries or discourse cue
words (Walker and Moore, 1997). This sec-
tion describes a method to apply a decision-tree
learning approach, which is one of the machine-
learning approaches, to ellipsis resolution.
</bodyText>
<subsectionHeader confidence="0.997198">
3.1 Ellipsis Tagging
</subsectionHeader>
<bodyText confidence="0.999992590909091">
In order to train and evaluate our ellipsis re-
solver, we tagged some ellipsis types to a di-
alogue corpus. The ellipsis types used to tag
the corpus are shown in Table 1. Each ellipsis
marker is tagged at the predicate. We made a
distinction between first or second person and
person(s) in general. Note that `person(s) in
general&apos; refers to either an unidentified or an
unspecified person or persons. In Far-Eastern
languages such as Japanese, Korean, and Chi-
nese, there is no grammatically obligatory case
such as the subject in English. It is thus neces-
sary to distinguish such ellipses.
We also made a tag &apos;(a)&apos; which means the
mentioned ellipsis is anaphoric; in case we need
to refer back to the antecedent in the dialogue.
In this paper we are not concerned with resolv-
ing the antecedent that such ellipses refer to,
because it is necessary to have another module
to deal with the context for resolving such en-
dophoric ellipses, and the main target of this
paper is the exophoric ellipses.
</bodyText>
<subsectionHeader confidence="0.99991">
3.2 Learning Method
</subsectionHeader>
<bodyText confidence="0.999982625">
We used the C&amp;quot;4.5 algorithm by Quinlan (1993),
which is a well-known automatic classifier that
produces a binary decision tree. Although it
may be necessary to prune decision trees, no
pruning is performed throughout this experi-
ment, since we want to concentrate the dis-
cussion on the feasibility of machine learning.
As shown in the experiment by Aone and Ben-
</bodyText>
<page confidence="0.998188">
1429
</page>
<tableCaption confidence="0.997458">
Table 2: Number of training attributes
</tableCaption>
<table confidence="0.808584111111111">
Attributes Num.
Content words (predicate) 100
Content words (case frame) 100
Func. words (case particle) 9
Func. words (conj. particle) 21
Func. words (auxiliary verb) 132
Func. words (other) 4
Exophoric information 1
Total 367
</table>
<bodyText confidence="0.99963">
nett (1995), which attempted to discuss prun-
ing effects on the decision tree, no more con-
clusions are expected other than a trade-off be-
tween recall and precision. We leave the details
of decision-tree learning research to itself.
</bodyText>
<subsectionHeader confidence="0.994336">
3.3 Training Attributes
</subsectionHeader>
<bodyText confidence="0.999576">
The training attributes that we prepared for
Japanese ellipsis resolution are listed in Table
2. The training attributes in the table are clas-
sified into the following three groups:
</bodyText>
<listItem confidence="0.9996654">
• Exophoric information:
Speaker&apos;s social role.
o Topic-dependent information:
Predicates and their semantic categories.
• Topic-independent information:
</listItem>
<bodyText confidence="0.99990604">
Functional words which express tense,
modality, etc.
There is one approach that only uses topic-
independent information to resolve ellipses
that appear in dialogues. However, we took
the position that both topic-dependent and -
independent information should have different
knowledge. Thus, approaches utilizing only
topic-independent knowledge must have a per-
formance limit for developing an ellipsis resolu-
tion system. It is practical to seek an automat-
ically trainable system that utilizes both types
of knowledge.
The effective use of exophoric information,
i.e., from the actual world, may perform well
for resolving an ellipsis. Exophoric information
consists of a lot of elements, such as the time,
the place, the speaker, and the listener of the ut-
terance. However, it is difficult to become aware
of some of them, and some are rather difficult
to prescribe. Thus we utilize one element, the
speaker&apos;s social role, i.e., whether the speaker is
the customer or the clerk. The reason for this
is that it must be an influential attribute, and
it is easy to detect in the actual world. Many of
us would accept a real system such as a spoken-
language translation system that detects speech
with independent microphones.
It is generally agreed that attributes to re-
solve ellipses should be different in each case.
Thus although we have to prepare them on a
case by case basis, we trained a resolver with
the same attributes.
Because we must deal with the noisy input
that appears in real applications, the training
attributes, other than the speaker&apos;s social role,
are questioned on a morphological basis. We
give each attribute its positional information,
i.e., search space of morphemes from the target
predicate. Positional information can be one of
five kinds: before, at the latest, here, next, and
afterward. For example, a case particle is given
the position of &apos;before&apos;, the search position of a
prefix `o-&apos; or `go-&apos; is the &apos;latest&apos;, and an auxil-
iary verb is &apos;after&apos; the predicate. The attributes
of predicates, and their semantic categories are
placed in &apos;here&apos;.
For predicate semantics, we utilized the top
two layers of Kadokawa Ruigo Shin-Jiten, a
three-layered hierarchical Japanese thesaurus.
</bodyText>
<sectionHeader confidence="0.996927" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.9994223">
In this section we discuss the feasibility of the el-
lipsis resolver via a decision tree in detail from
three points of view: the amount of training
data, the topic dependency, and the case differ-
ence. The first two are discussed against `ga(v.)&apos;
case (see subsection 4.3).
We used F-measures metrics to evaluate the
performance of ellipsis resolution. The F-
measure is calculated by using recall and pre-
cision:
</bodyText>
<equation confidence="0.968671666666667">
2 xPxR (1)
F =
P R
</equation>
<bodyText confidence="0.975238">
where P is precision and R is recall. In this
paper, F-measure is described with a percentage
(%).
</bodyText>
<page confidence="0.867499">
1430
</page>
<table confidence="0.767872">
Performance (F-measure)
</table>
<tableCaption confidence="0.995046">
Table 3: Training size and performance
</tableCaption>
<table confidence="0.999489833333333">
Dial. Samp. lsg 2sg a Tot
25 463 71.0 55.6 66.2 59.0
50 863 76.4 69.7 71.5 67.2
100 1710 82.1 76.4 77.0 73.2
200 3448 85.1 79.8 79.7 76.7
400 6906 84.7 81.1 82.0 78.7
</table>
<subsectionHeader confidence="0.997499">
4.1 Amount of Training Data
</subsectionHeader>
<bodyText confidence="0.999987857142857">
We trained decision trees with a varied num-
ber of training dialogues, namely 25, 50, 100,
200 and 400 dialogues, each of which included
a smaller set of training dialogues. The exper-
iment was done with 100 test dialogues (1685
subject ellipses), and none were included in the
training dialogues.
Table 3 indicates the training size and perfor-
mance calculated by F-measure. This illustrates
that the performance improves as the training
size increases in all types of ellipses. Although
it is not shown in the table, we note that the
results in both recall and precision improve con-
tinuously as well as those in F-measure.
The performance difference of all ellipsis
types by training size is also plotted in Fig-
ure 1 on a semi-logarithmic scale. It is in-
teresting to see from the figures that the rate
of improvement gradually decelerates and that
some of the ellipsis types seem to have practi-
cally stopped improving at around 400 training
dialogues (6806 samples). Acme and Bennett
(1995) claimed that the overall anaphora res-
olution performance seems to have reached a
plateau at around 250 training examples. This
result, however, indicates that 104 105 train-
ing samples would be enough to train the trees
in this task.
The chart gives us more information that per-
formance limitation with our approach would
be 80% 85% because each ellipsis type seems
to approach the similar value, in particular for
those in large training samples (1sg) and (2sg).
Greater performance improvement is expected
by conducting more training in (2p1) and (g).
</bodyText>
<subsectionHeader confidence="0.955299">
4.2 Topic Dependencies
</subsectionHeader>
<bodyText confidence="0.9976">
It is completely satisfactory to build resolution
knowledge only with topic-independent infor-
mation. However, is it practical? We will dis-
cuss this question by conducting a few experi-
</bodyText>
<figure confidence="0.977512714285714">
100
80
60
40
20
50 100 200
Training size (dialogues)
</figure>
<figureCaption confidence="0.999933">
Figure 1: Training size and performance
</figureCaption>
<bodyText confidence="0.987478142857143">
ments.
We utilized the ATR travel arrangement cor-
pus (Furuse et al., 1994). The corpus contains
dialogues exchanged between two people. Var-
ious topics of travel arrangements such as im-
migration, sightseeing, shopping, and ticket or-
dering are included in the corpus. A dialogue
consists of 10 to 30 exchanges. We classified di-
alogues of the corpus into four topic categories:
H1 Hotel room reservation, modification and
cancellation
H2 Hotel service inquiry and troubleshooting
HR Other hotel arrangements, such as hotel se-
lection and an explanation of hotel facilities
</bodyText>
<sectionHeader confidence="0.448996" genericHeader="method">
R Other travel arrangements
</sectionHeader>
<bodyText confidence="0.999829533333333">
Fifty dialogues were chosen randomly from the
corpus in the topic category H1, H2, R, and the
overall topic T(= H1 + H2-1- HR -1- R) as train-
ing dialogues. We used 100 unseen dialogues as
test samples again, which were the same as the
samples used in the training-size experiment.
Table 4 shows the topic-dependency of each
topic category that we provide with the F-
measure. For instance, the first figure in the
`TI&apos; row (73.4) denotes that the accuracy with
the F-measure is 73.4% against topic H1 test
samples when training is conducted on T, i.e.,
all topics. Note that the second row of the table
indicates the ingredient of each topic in the test
samples (and thus, the corpus).
</bodyText>
<page confidence="0.996396">
1431
</page>
<tableCaption confidence="0.982026">
Table 4: Topic dependency Table 5: Performance of major types in case
</tableCaption>
<table confidence="0.995988428571429">
Train/Test 11 1112 IHR IR Total
(%) 20.1 27.7 11.2 40.9 100.0
Hi/ 78.1 55.9 65.3 61.6 63.7
H2/ 71.3 67.0 62.6 62.6 65.6
75.1 61.7 61.1 75.4 69.9
73.4 62.5 62.6 66.2 66.2
T - HR1 73.7 61.9 59.5 63.9 64.8
</table>
<bodyText confidence="0.99947004">
The results illustrate that very high accu-
racy is obtained when a training topic and a
test topic coincide. This implies the impor-
tance not to train dialogues of unnecessary top-
ics if the resolution topic is imaginable or re-
stricted, in order to obtain higher performance.
Among four topic subcategories, topic R shows
the highest accuracy (69.9%) in total perfor-
mance. The reason is not that topic R has
something important to train, but that topic
R contains the most test dialogues chosen at
random.
The table also illustrates that a resolver
trained in various kinds of topics (71&apos;) demon-
strates higher resolving accuracy against the
testing data set. It performs with better than
average accuracy in every topic compared to one
which is trained in a biased topic. By looking
at some examples it may be possible to build an
all-around ellipsis resolver, but topic-dependent
features are necessary for better performance.
The &apos;T - HR/&apos; resolver shows the lowest per-
formance (59.5%) against `/HR&apos; test set. This
result is more evidence supporting the impor-
tance of topic-dependent features.
</bodyText>
<subsectionHeader confidence="0.998443">
4.3 Difference in Surface Case
</subsectionHeader>
<bodyText confidence="0.999534">
We applied a machine-learned resolver to agent
case ellipses (Yamamoto et al., 1997). In this
paper, we discuss whether this technique is ap-
plicable to surface cases.
We examined the feasibility of a machine-
learned ellipsis resolver for three principal sur-
face cases in Japanese, `ga&apos;, &apos;wo&apos;, and &apos;ni&apos;l.
Roughly speaking, they express the subject, the
direct object, and the indirect object of a sen-
tence respectively. We classified the &apos;ga&apos; case
into two samples: a predicate of a sentence with
a `ga&apos; case ellipsis that is a verb or an adjective.
</bodyText>
<table confidence="0.9340634">
Case (lsg) (2sg) (a) Total
ga(adj.) 58.3 68.1 85.9 79.7
wo 66.7 - 97.7 95.6
ni 95.2 95.7 81.9 91.7
ga(v.) 84.7 81.1 82.0 78.7
</table>
<bodyText confidence="0.999778272727273">
In other words, this distinction corresponds to
whether a sentence in English is a be-verb or a
general-verb sentence. Henceforth, we call them
`ga(v.)&apos; and `ga(adj.)&apos; respectively.
The training attributes provided are the same
in all surface cases. They are listed in Table 2.
In the experiment, 300 training dialogues and
100 unseen test dialogues were used. The fol-
lowing results are shown in Table 52. The table
illustrates that the ga(adj.) resolver has a simi-
lar performance to the ga(v.) resolver, whereas
the former has a distinctive tendency toward the
latter in each ellipsis type. The ga(adj.) case
resolver produces unsatisfactory results in (lsg)
and (2sg) ellipses, since insufficient samples ap-
peared in the training set.
In the `wo&apos; case, more than 90% of the sam-
ples are tagged with (a), thus they are easily rec-
ognized as anaphoric. Although it may be diffi-
cult to decide the antecedents in the anaphoric
ellipses by using information in Table 2, the re-
sults show that it is possible to simply recog-
nize them. After recognizing that the ellipsis is
anaphoric, it is possible to resolve them in other
contextual processing modules, such as center-
ing.
It is important to note that a satisfactory per-
formance is presented for the &apos;ne case (mostly
indirect object). One reason for this could be
that many indirect objects refer to exophoric
persons, and thus an approach utilizing a deci-
sion tree that makes a selection from fixed de-
cision candidates is suitable for `ni&apos; resolution.
</bodyText>
<sectionHeader confidence="0.969032" genericHeader="method">
5 Inside a Decision Tree
</sectionHeader>
<bodyText confidence="0.99893225">
A decision tree is a convenient resolver for some
kinds of problems, but we should not regard it
as a black-box tool. It tells us what attributes
are important, whether or not the attributes are
</bodyText>
<footnote confidence="0.4016615">
2 We cannot investigate other optional cases due to a 2The result of the ga(v.) case is the same as &apos;400&apos; in
lack of samples. Table 3.
</footnote>
<page confidence="0.984583">
1432
</page>
<figure confidence="0.990347333333333">
a)
1000 2000 5000 10000
Training samples
</figure>
<figureCaption confidence="0.964931">
Figure 2: Training samples vs. nodes
</figureCaption>
<table confidence="0.6568106">
Table 6: Depth and maximum width of decision
tree
ga/25 /100 /400 ga(adj.) wo ni
Depth 27 34 49 28 10 18
Width 26 58 146 52 10 28
</table>
<bodyText confidence="0.993930666666667">
sufficient, and sometimes more. In this section,
we investigate decision trees and discuss them
in detail.
</bodyText>
<subsectionHeader confidence="0.978954">
5.1 Tree Shape
</subsectionHeader>
<bodyText confidence="0.999872052631579">
The relation between the number of training
samples and the number of nodes in a decision
tree is shown logarithmically in Figure 2. It
is clear from the chart that the two factors of
case are logarithmically linear. This is
because no pruning is conducted in building a
decision tree. We also see that a more compact
tree is built in the order of &apos;zoo&apos;, `ga(adj.)&apos;
and &apos;ga(v.)&apos;. This implies that the &apos;wo&apos; case is
the easiest of the four cases for characterizing
the individuality among the ellipsis types.
Table 6 shows node depth and the maximum
width in the decision trees we have built. By
studying Table 5 and Table 6, we can see that
the shallower the decision tree is, the better the
resolver performs. One explanation for this may
be that a deeper (and maybe bigger) decision
tree fails to characterize each ellipsis type well,
and thus it performs worse.
</bodyText>
<subsectionHeader confidence="0.972536">
5.2 Attribute Coverage
</subsectionHeader>
<bodyText confidence="0.999882866666667">
We define a factor &apos;coverage&apos; for each attribute.
Attribute coverage is the rate of the samples
used to reach a decision about the samples used
to build a decision tree. If an attribute is used
at the top node of a decision tree, the attribute
coverage is 100% in the definition, because all
samples use it (first) to reach their decision.
From this, we can learn the participation of each
attribute, i.e., each attribute&apos;s importance.
Some typical attribute-coverages are ex-
pressed in Table 7. Note that `ga(25)&apos; denotes
the results of `ga(v.)&apos; with 25-dialogue training.
A glance at the table will reveal that the cover-
age is not constant with an increasing number
of training dialogues. Here we build a hypothe-
sis from the table that more general attributes
are preferred with a increase in training size.
The table illustrates that the topic-
independent attributes increase with a rise
in training size, such as `-tekudasaru&apos; or
teitadaku&apos; (both auxiliary verbs which express
the hearer&apos;s action toward the speaker with the
speaker&apos;s respect). The table shows in contrast
that the topic-dependent attributes decrease,
such as `:before 72&apos; (a category in which words
concerned with intention are included before
the predicate mentioned) or `:before 94&apos;. There
are also some topic-independent words such as
`-ka&apos; (a particle that expresses that the sentence
is interrogative) or `:before 4//43&apos;s which are
still important regardless of the training size.
This indicates the advantages of a machine-
learning approach, because difficulties always
arise in differentiating these words in manual
approaches.
Table 8 also contrasts typical coverage in sur-
face cases. It illustrates that there is a distinct
difference between `ga(v.)&apos; and `ga(adj.)&apos;. The
resolver of the `ga(adj.)&apos; case is interested in
another cases, such as `-de&apos; or contents of an-
other case `:before /6/34&apos;, whereas `ga(v.)&apos; case
resolver checks some predicates and influential
functional words. Coverage of each attribute in
the &apos;Ili&apos; case has similar tendencies to those in
the `ga(v.)&apos; case, except for a few attributes.
</bodyText>
<sectionHeader confidence="0.989946" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.996459666666667">
This paper proposed a method for resolving the
ellipsis that appear in Japanese dialogues. A
machine-learning algorithm is used as the ac-
</bodyText>
<footnote confidence="0.991743">
3We practically regard them as topic-independent
words, because expressing the speaker&apos;s inten-
tion/thought is topic-independent.
</footnote>
<page confidence="0.987002">
1433
</page>
<tableCaption confidence="0.998516">
Table 7: Training Size vs. Coverage
</tableCaption>
<table confidence="0.999968916666667">
Attribute ga/25 ga/100 ga/400
:here 43(intention) 100.0 100.0 100.0
:here 41(thought) 72.8 84.8 86.5
`-ka&apos;(question) 53.1 83.2 66.3
`-tekudasaru&apos;(polite) 9.1 49.1 49.8
honorific verbs - 39.9 36.8
`-teitadaku&apos;(polite) - 33.2 33.9
`-suru&apos; (to do) 4.1 22.0 26.1
:before 72(facilities) 55.1 0.5 3.8
:before 94(bui1ding) 28.5 9.8 7.7
:before 83(language) 25.1 1.1 1.3
Speaker&apos;s role 11.7 9.1 20.5
</table>
<tableCaption confidence="0.988009">
Table 8: Case vs. Coverage
</tableCaption>
<table confidence="0.995372777777778">
Attribute ga/400 ga(adj.) nz
`-gozaimasu&apos;(polite) 100.0
:before 16(situation) 5.1 68.5 0.5
:before 34(statement) 5.3 59.0 11.2
`-de&apos;(case particle) 5.2 23.9 1.9
&apos;-o/-go&apos; 46.4 7.0 100.0
:here 43(intention) 100.0 49.8
:here 41(thought) 86.5 43.5
Speaker&apos;s role 20.5 33.1 28.0
</table>
<bodyText confidence="0.998854523809524">
tual ellipsis resolver with this approach. The
results of blind tests have proven that the pro-
posed method is able to provide a satisfactory
resolution accuracy of 91.7% in indirect objects,
and 78.7% in subjects with verb predicates.
We also discussed training size, topic depen-
dency and difference in grammatical case in a
decision tree. By investigating decision trees,
we conclude that topic-dependent attributes are
also necessary for obtaining higher performance,
and that indispensable attributes depend on the
grammatical case to resolve.
Although this paper limits its scope, the pro-
posed approach may also be applicable to other
problems, such as referential property and the
number of nouns, and in other languages such
as Korean. In addition, we will explore contex-
tual ellipses in the future, since it was found
that most of the ellipses that appeared in spo-
ken dialogues are found to be anaphoric in the
wo, case.
</bodyText>
<sectionHeader confidence="0.724126" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.92523025">
The authors would like to thank Dr. Naoya
Arakawa, who provided data regarding case el-
lipsis. We are also thankful to Mr. Hitoshi
Nishimura for conducting some experiments.
</bodyText>
<sectionHeader confidence="0.465754" genericHeader="references">
References
</sectionHeader>
<figureCaption confidence="0.928232259259259">
C. Aone and S. W. Bennett. 1995. Evaluat-
ing Automated and Manual Acquisition of
Anaphora Resolution Strategies. In Proc. of
33rd Annual Meeting of the ACL, pages 122-
129.
0. Furuse, Y. Sobashima, T. Takezawa, and
N. Uratani. 1994. Bilingual Corpus for
Speech Translation. In Proc. of AAAI&apos;94
Workshop on the Integration of Natural Lan-
guage and Speech Processing, pages 84-91.
0. Furuse, J. Kawai, H. Ha, S. Akamine,
and D.-B. Kim. 1995. Multi-lingual Spoken-
Language Translation Utilizing Translation
Examples. In Proc. of Natural Language Pro-
cessing Pacific-Rim Symposium (NLPRS&apos;95),
pages 544-549.
M. Murata and M. Nagao. 1997. An Estimate
of Referents of Pronouns in Japanese Sen-
tences using Examples and Surface Expres-
sions. Journal of Natural Language Process-
ing, 4(1):87-110. written in Japanese.
H. Nakaiwa and S. Shirai. 1996. Anaphora Res-
olution of Japanese Zero Pronouns with Deic-
tic Reference. In Proc. of COLING-96, pages
812-817.
J. R. Quinlan. 1993. C4.5: Programs for Ma-
chine Learning. Morgan Kaufmann.
</figureCaption>
<bodyText confidence="0.902053833333333">
H. Tanaka. 1994. Verbal Case Frame Ac-
quisition from a Biliungual Corpus: Grad-
ual Knowledge Acquisition. In Proc. of
COLING-94, pages 727-731.
M. Walker and J. D. Moore. 1997. Empirical
Studies in Discourse. Computational Linguis-
tics, 23(1):1-12, March.
K. Yamamoto, E. Sumita, 0. Furuse, and
H. lida. 1997. Ellipsis Resolution in Dia-
logues via Decision-Tree Learning. In Proc.
of Natural Language Processing Pacific-Rim
Symposium (NLPRS&apos;97), pages 423-428.
</bodyText>
<page confidence="0.979399">
1434
</page>
<figure confidence="0.98127023880597">
Acv: z Ei4KIMW.Vd 47—G :
LIPIK REEL &apos;A-05
ATR 11-PIMACiiiff9M
E-mail: yamamotaitl.atr.co.jp
11 74itilt50:13 tt 45WaYtti
ri*,moDp-,--maimt:31.0-cu, ,ItLcAoti,
z oppait:mit-g-wf: IV) 91Ifft&apos;Ir-C; Z.
gMX-O&apos;g UBAKffitz4c4ONSk-C;Uf&lt;c‹,%
PPElfiritcz CEtz5
VIV)t)Z tiff 7:z L&apos;,1ZsAg
is
Igt9all
(10*N-940DIVOV) z
7grit3t-c;tt, * (decision
tree) 1,:ct ZAN. arfti 1010EflAft
75&apos; ;ffilt-fAXt Llit5E1--- tiii60)Rmt-Itiivin
tRIA*4-W L, tt. -C El *Milt ;118 a) Wei
*FaUc-t;TV)
(exophoric ellipsis) 0Att
(endophoric ellipsis) 01.2.0 KIN&apos;r
itA-t V:13 -C :VItAkf*t-:
fttoAr, (DAft,
taU.
419t-Ltzc
t &lt; 0)
MIL .1. -C -C , &lt; 7-g-
*&apos;(J#A1A-i),13&amp;quot;TgLt--cti,Z.
ftlt71 rlitgPA-■01kfllit L -C, IfAM33-
f,11 tt
411*1-Z. PA*
oDZIH-I1z.&lt; t:
.1: )7J11t“rit.&apos;-)ZWzt)
t.c.o. I *Ziff.
• Xtti.*0-T-a-C&apos;Ditt
519
AKTifitilloferWCIMI:# -C.
• M7&apos;±-E1010AN.13 1 tYlale-*-W --clfR
7&apos;#EZIA“k1141-Z-T-itt&apos;llt If45----cr_-,.g47:
%AL L-C, N-7-61-IfiOVA)Aft,
MZIAMO-.7-2-.64Elfii Utz.
L tcik-±-*-C&apos;V44-W13Zt:Al L -C J&amp;quot;
tze,A, ft&apos;J VrLrcJttrvz#L--cli-i--5;t&lt;OW
tg-t:N1L-Cti,
Lo-)111.Z“)--t.c (Dtz±-cS,Z
L, t-&amp;quot;C; tz.
I tzI1*-M4:1M1L-C, Z3g0DAItti-f-&apos;14
ME&apos;Ti3Ylts ft. IX% 0) 3 t1 ilA
Ut tk1:
&amp;5z.
• 1-5-1 tUNI) Rzi aa7T-1-.VA
AVitt Z. rt_l 4 M)
0)MW*0111*Rt: t&amp;quot;C145-EX,/*Zittrlit
MS,Z.
• rillEt:::#1-Z-1-INE*Hikf*L L-C
104 105 :/ 0)*
0454-EMTk..0.1.1RU 80% -- 85% L-Tt9s.
hZ.
• U &lt; Tirr ft r*
ant IM a) 07* V:- 44-T1 ant g
il-MYznotik,g-/t,
[13&apos;E z otql:
• *s eo)
J:
H Z4W*04f45,.-6
LCC tztt,
11
1± il.i:1411:L et ;t:coc, El
</figure>
<reference confidence="0.9173952">
eLltlier..*(;)16 754.3Mii-,B.
gff*ec:130- z-101611r1-6 37ailt*or,iSgivz
ct-D-c-CM.:1:cz &apos;_cpti-z
1-f-A 4HYL&apos;i-Z1144FAS,Z :::.::Tic-tANX75&apos;13Ji7Turtorsv,to)1---r *Ski
Vplit&apos;ittt*
</reference>
<page confidence="0.990464">
1435
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.429213">
<title confidence="0.999948">Feasibility Study for Ellipsis Resolution in Dialogues</title>
<author confidence="0.629473">by Machine-Learning Technique Kazuhide Eiichiro</author>
<affiliation confidence="0.810974">ATR Interpreting Telecommunications Research Laboratories</affiliation>
<email confidence="0.981777">E-mail:yamamotoOitl.atr.co.jp</email>
<abstract confidence="0.999367157894737">A method for resolving the ellipses that appear in Japanese dialogues is proposed. This method resolves not only the subject ellipsis, but also those in object and other grammatical cases. In this approach, a machine-learning algorithm is used to select the attributes necessary for a resolution. A decision tree is built, and used as the actual ellipsis resolver. The results of blind tests have shown that the proposed method was able to provide a resolution accuracy of 91.7% for indirect objects, and 78.7% for subjects with a verb predicate. By investigating the decision tree we found that topic-dependent attributes are necessary to obtain high performance resolution, and that indispensable attributes vary according to the grammatical case. The problem of data size relative to decision-tree training is also discussed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<pages>16--754</pages>
<marker></marker>
<rawString>eLltlier..*(;)16 754.3Mii-,B.</rawString>
</citation>
<citation valid="false">
<title>gff*ec:130- z-101611r1-6 37ailt*or,iSgivz ct-D-c-CM.:1:cz &apos;_cpti-z 1-f-A 4HYL&apos;i-Z1144FAS,Z :::.::Tic-tANX75&apos;13Ji7Turtorsv,to)1---r</title>
<location>Ski</location>
<marker></marker>
<rawString>gff*ec:130- z-101611r1-6 37ailt*or,iSgivz ct-D-c-CM.:1:cz &apos;_cpti-z 1-f-A 4HYL&apos;i-Z1144FAS,Z :::.::Tic-tANX75&apos;13Ji7Turtorsv,to)1---r *Ski</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>