<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004723">
<title confidence="0.995799">
A Uniform Architecture for Parsing, Generation and Transfer
</title>
<author confidence="0.8477105">
Remi Zajac
Project POLYGLOSS*
</author>
<affiliation confidence="0.998837">
IMS-CL/Ifl-AIS, University of Stuttgart
</affiliation>
<address confidence="0.897868">
KeplerstraBe 17, D-7000 Stuttgart 1
</address>
<email confidence="0.995846">
zajac@informatik.uni-stuttgart.de
</email>
<sectionHeader confidence="0.993761" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999954166666667">
We present a uniform computational
architecture for developing reversible
grammars for parsing and generation, and
for bidirectional transfer in MT. We sketch
the principles of a general reversible ar-
chitecture and show how they are real-
ized in the rewriting system for typed fea-
ture structures developed at the Univer-
sity of Stuttgart. The reversibility of pars-
ing and generation, and the bidirection-
ality of transfer rules fall out of general
properties of the uniform architecture.
</bodyText>
<sectionHeader confidence="0.9991585" genericHeader="keywords">
1 PRINCIPLES FOR A UNIFORM AR-
CHITECTURE
</sectionHeader>
<bodyText confidence="0.990905870967742">
The principles for a uniform architecture
for parsing/generation and bidirectional trans-
fer are already contained in some PROLOG
implementations of logic grammars like DCGs.
For example, [Shieber 881 proposes to apply the
idea of Earley deduction [Pereira/Warren 83] to
generation. With the noticeable exception of
[Dymetman et al. 90], all of these approaches use
a context-free based mapping to relate a string
of words with a semantic structure. Almost all
of these approaches also rely on some specific
properties of the grammars intended to be pro-
cessed (semantic heads, guides, leading features,
specific representation of subcategorization, etc.).
They are also dependent on the direction in which
they are used: even if the grammar specifica-
tion is the same, two different compilers gener-
ate two different programs for parsing and gener-
ation. Using the PROLOG deduction mechanism
to have a simple and direct implementation of a
parser/generator, one has to solve some problems
due to the PROLOG evaluation method, for ex-
ample termination on uninstantiated goals: goals
have to be evaluated in a different order for pars-
ing and generation. A reordering of goals per-
formed by a rule compiler can be based on a di-
rect specification of the ordering by the grammar
writer [Dymetman/Isabelle 881, or can be derived
•Research reported in this paper is partly supported by the German Ministry of Research and Technology (BMFT,
Bundesminister fiir Forschung und Technologie), under grant No. 08 B3116 3. The views and conclusions contained herein
are those of the author and should not be interpreted as representing official policies.
</bodyText>
<page confidence="0.99747">
71
</page>
<bodyText confidence="0.99994372">
by a compiler by analysing the dataflow using only
input/output specifications [Strzalkowski 90].
But if we regard the grammar as a set of con-
straints to be satisfied, parsing and generation dif-
fer only in the nature of the &amp;quot;input&amp;quot;, and there is
no reason to use two different programs. An inter-
esting approach which uses only one program is
described in [Dymetman/Isabelle 88]. Within this
approach, a lazy evaluation mechanism, based on
the specification of input/output arguments, is im-
plemented, and the evaluation is completly data-
driven: the same program parses or generates de-
pending only on the form of the input term. Fur-
thermore, a reversible grammar need not to be
based only on constituency. [Dymetman et al. 90]
describes a class of reversible grammars (&amp;quot;Lexi-
cal Grammars&amp;quot;) based on a few composition rules
which are very reminiscent of categorial gram-
mars. Other kinds of approaches can also be en-
visaged, e.g. using a dependency structure and
linear precedence relations [Reape 90] (see also
[Pollard/Sag 87]).
From these experiments, we can outline desir-
able properties of a computational framework for
implementing reversible grammars:
</bodyText>
<listItem confidence="0.844326894736842">
• A unique general deductive mechanism is
used. Grammars define constraints on the
set of acceptable structures, and there is no
distinction between &amp;quot;input&amp;quot; and &amp;quot;output&amp;quot;.
• To abolish the input/output distinction, the
same kind of data structure is used to encode
both the string and the linguistic structure,
and they are embedded into one data struc-
ture that represents the relation between the
string and the associated linguistic structure
(c.f. the HPSG sign [Pollard/Sag 87]).
• Specific mapping properties, based on con-
stituency, linear precedence or functional
composition, are not part of the formalism
itself but are encoded explicitly using the
formalism.
• The deductive mechanism should be compu-
tationally well-behaved, especially with re-
spect to completeness.
</listItem>
<bodyText confidence="0.9996925">
In the next section, we show how these prop-
erties are realized in the Typed Feature Structure
rewriting system implemented at the University of
Stuttgartl. We then discuss the parsing and gen-
eration problem, and bidirectionality of transfer in
MT. Assuming that we have the proper machin-
ery, problems in parsing or generation can arise
only because of a deficiency in the grammar2: in
the last section, the termination problem and effi-
ciency issues are addressed.
</bodyText>
<sectionHeader confidence="0.998484" genericHeader="method">
2 A REWRITE MACHINE FOR TYPED
FEATURE STRUCTURES
</sectionHeader>
<bodyText confidence="0.902368384615384">
The basic motivation behind the Typed Fea-
ture Structure rewriting system is to provide a
language which has the same deductive and log-
ical properties of logic programming languages
such as PROLOG, but which is based on feature
terms instead of first order terms [Ait-Kaci 84,
Aft-Kaci 86, Emele/Zajac 904 Such a language
has a different semantics than the Herbrand se-
mantics: this semantics is based on the notion of
approximation, which captures in a computational
&apos;The TFS system has been implemented by Martin Emele and the author as part of the POLYGLOSS project.
&apos;As it is often the case in generation when using a grammar built initially for parsing.
&apos;See also [Emele/Zajac 90a] for a fixed-point semantics.
</bodyText>
<page confidence="0.997744">
72
</page>
<bodyText confidence="0.989342029411765">
framework the idea that feature structures repre-
sent partial information [Zajac 90b]3. Of course,
as in PROLOG,, problems of completeness and ef-
ficiency have to be addressed.
The universe of feature terms is structured in
an inheritance hierarchy which defines a partial
ordering on kinds of available information. The
backbone of the hierarchy is defined by a par-
tial order &lt; on &apos;a set of type symbols T. To this
set, we add two more symbols: T which repre-
sents completly underspecified information, and
1 which represents inconsistent information. Two
type symbols have a common most general sub-
type (Greatest Lower Bound — GLB): this sub-
type inherits all information associated with all
its super-types. We define a meet operation on two
type symbols A and B as A A B = glb(A, B). For-
mally, a type hierarchy defined as a tuple (T,&lt;, A)
is a meet semi-lattice. A technicality arises when
two types A and B have more than one GLB: in
that case, the set of GLBs is interpreted as a dis-
junction.
As different sets of attribute-value pairs make
sense for different kind of objects, we divide our
feature terms into different types. Terms are closed
in the sense that each type defines a specific associ-
ation of features (and restrictions on their possible
values) which are appropriate for it, expressed as a
feature structure .(the definition of the type). Since
types are organized in an inheritance hierarchy,
a type inherits all the features and value restric-
tions from all its super-types. This type-discipline
for feature structures enforces the following two
constraints: a term cannot have a feature which
</bodyText>
<footnote confidence="0.7941">
4Checked at compile time.
</footnote>
<bodyText confidence="0.9998804375">
is not appropriate for its type&apos; and conversely, a
pair of feature and value should always be defined
for some type. Thus a feature term is always typed
and it is not possible to introduce an arbitrary fea-
ture in a term (by unification): all features added
to some term should be appropriate for its type.
We use the attribute-value matrix (AVM) nota-
tion for feature terms and we write the type sym-
bol for each feature term in front of the opening
square bracket of the AVM. A type symbol which
does not have any feature defined for it is atomic.
All others types are complex.
A type definition has the following form: the
type symbol to be defined appears on the left-
hand side of the equation. The right-hand side
is an expression of conjunctions and disjunctions
of typed feature terms (Figure 1). Conjunctions
are interpreted as meets on typed feature terms
(implemented using a typed unification algorithm
[Emele 91]). The definition may have conditional
constraints expressed as a logical conjunction of
feature terms and introduced by &apos;:-&apos;. The right-
hand side feature term may contain the left-
hand side type symbol in a subterm (or in the
condition), thus defining a recursive type equa-
tion which gives the system the expressive power
needed to describe complex linguistic structures.
A subtype inherits all constraints of its super-
types monotonically: the constraints expressed as
an expression of feature terms are conjoined using
unification; the conditions are conjoined using the
logical and operation.
</bodyText>
<page confidence="0.990012">
73
</page>
<figure confidence="0.995259956521739">
1: NIL
APPENDO 2: i LIST
3: II
APPEND 2: LIST
3: LIST
1: LIST]
[
APPEND1
1: CONS[firstm &apos;-
rest
2: En LIST
3: CONS[firstlx]
rest.
LIST
\ [first: T
NIL CONS
rest: LIST
:- APPEND2:
3:
1
1:
[
rn
</figure>
<figureCaption confidence="0.999877">
Figure 2: Type hierarchy for LIST and APPEND (T and I omitted).
</figureCaption>
<bodyText confidence="0.9977">
A set of type definitions defines an inheri-
tance hierarchy of feature terms which specifies
the available approximations. Such a hierarchy is
compiled into a rewriting system as follows: each
direct link between a type A and a subtype B
generates a rewrite rule of the form A[a] --+ B[b]
where [a] and [b] are the definitions of A and B,
respectively.
The interpreter is given a &amp;quot;query&amp;quot; (a feature
term) to evaluate: this input term is already an
approximation of the final solution, though a very
rough approximation. The idea is to incremen-
tally add more information to that term using the
rewrite rules in order to get step by step closer
to the solution: we stop when we have the best
Possible approximation.
A rewrite step for a term t is defined as follows:
if u is a subterm oft of type A and there exists a
rewrite rule A[a] B[b] such that A[a] n u J_,
the right-hand side B[b] is unified with the sub-
term u, giving a new term t&apos; which is more spe-
cific than t. This rewrite step is applied non-
deterministically everywhere in the term until no
further rule is applicable5. Actually, the rewriting
process stops either when all types are minimal
types or when all subterms in a term correspond
exactly to some approximation defined by a type
in the hierarchy. A term is &amp;quot;solved&amp;quot; when any sub-
term is either more specific than the definition of
a minimal type, or does not give more information
than the definition of its type.
This defines an if and only if condition for a
term to be a solved-form, where any addition of
information will not bring anything new and is
implemented using a lazy rewriting strategy: the
application of a rule A[a] —&gt; B[b] at a subterm it
is actually triggered only when A[a] n 71 c A[a].
This lazy rewriting strategy implements a fully
data-driven computation scheme and avoids use-
less branches of computation. Thus, there is no
5Conditions do not change this general scheme and are omitted from the presentation for the sake of simplicity. See
for example [Dershowitz/Plaisted 88], and [Klop 90] for a survey.
</bodyText>
<page confidence="0.994497">
74
</page>
<table confidence="0.999527823529412">
NIL LIST
LIST ----&gt;
LIST CONS[first:
rest:
1: NIL
APPEND 2: LIST APPENDO 2: 0 LIST
LISTI
[1:
3: LIST 3:0 firstu
1: CONS
_rest :El 1: [n
2: 2: El LIST : — APPEND 2: El
[1: [ 1
APPEND LIST APPEND1
LIST]
3: LIST 3: CONS[first:m 3: 2
rest: in
</table>
<figureCaption confidence="0.989352">
Figure 3: Rewrite rules for LIST and APPEND.
</figureCaption>
<bodyText confidence="0.999872242424242">
need to have a special treatment to avoid what cor-
responds to the evaluation of un-instantiated goals
in PROLOG, since a general treatment based on
the semantics of ,the formalism itself is built in the
evaluation strategy of the interpreter.
The choice of which subterm to rewrite is
only partly driven by the availability of infor-
mation (using the lazy rewriting scheme). When
there are several subterms that could be rewrit-
ten, the computation rule is to choose the outer-
most ones (inner-most strategies are usually non-
terminating)6. Such an outer-most rewriting strat-
egy has interesting termination properties, since
there are problems where a TFS program will
terminate when the corresponding PROLOG pro-
gram will not7.
For a given subterm, the choice of which rule to
apply is done non-deterministically, and the search
space is explored depth-first using a backtrack-
ing scheme. This strategy is not complete, though
in association with the outer-most rule and with
the lazy evaluation scheme, it seems to terminate
on any &amp;quot;well-defined&amp;quot; problem, i.e. when terms
introduced by recursive definitions during exe-
cution are strictly decreasing according to some
mesure (for example, see the definition of guides
in [Dymetman et al. 90] for the parsing and gener-
ation problems). A complete breadth-first search
strategy is planned for debugging purposes.
The interpreter described above is implemented8
and has been used to test several models such
as LFG, HPSG, or DCG on toy examples
[Emele/Zajac 90b, Emele et al. 90, Zajac 90a].
</bodyText>
<footnote confidence="0.9072358">
6This outer-most rewriting strategy is similar to hyper-resolution in logic programming. The lazy evaluation mech-
anism is related to the &apos;freeze&apos; predicate of, e.g. Prolog-II and Sicstus Prolog, though in Prolog, it has to be called
explicitly.
7e.g. the problem of left-recursive rules in naive PROLOG implementations of DCGs
81i prototype version is publically available.
</footnote>
<page confidence="0.998194">
75
</page>
<sectionHeader confidence="0.996429" genericHeader="method">
3 PARSING, GENERATION, AND BIDI-
RECTIONAL TRANSFER
</sectionHeader>
<subsectionHeader confidence="0.999865">
3.1 Parsing/generation
</subsectionHeader>
<bodyText confidence="0.999127611111111">
A grammar describes the relation between
strings of words and linguistic structures. In or-
der to implement a reversible grammar, we have
to encode both kinds of structure using the same
kind of data structure provided by the TFS lan-
guage: typed feature structures. A linguistic struc-
ture will be encoded using features and values, and
the set of valid linguistic structures has to be de-
clared explicitly. A string of words will be encoded
as a list of word forms, using the same kind of def-
initions as in Figure 1.
To abolish the distinction between &amp;quot;input&amp;quot; and
&amp;quot;output&amp;quot;, the relation between a string and a lin-
guistic structure will be encoded in a single term
with, for example, two features, string and syn
and we can call the type of such a structure S1GN9.
The type SIGN is divided into several subtypes
corresponding to different mappings between a
string and a linguistic structure. We will have at
least the classification bewteen phrases and words.
The definition of a phrase will recursively relate
subphrases and substrings, and define the phrase
as a composition of subphrases and the string
as the concatenation of substrings. The formal-
ism does not impose constraints on how the re-
lations between phrases and strings are defined,
and the grammar writer has to define them ex-
plicitly. One possibility is to use context-free like
mappings, using for example the same kind of
encoding as in DCGs for PATR-like gramars or
HPSG [Emele/Zajac 90b]. But other possibilities
are available as well: using a kind of functional
composition reminiscent of categorial grammars
as in [Dymetman et al. 90], or linear precedence
rules [Pollard/Sag 87, Reape 90].
For example, a rule like [Shieber 86]1°
</bodyText>
<equation confidence="0.9887922">
S NP VP:
(S head) = (VP head)
(S headform) = finite
(VP syncat first) = (NP)
(VP syncat rest) = (end).
</equation>
<bodyText confidence="0.910465090909091">
is encoded in TFS using a type S for the sentence
type with two features np and vp for encoding the
constituent structure, and similarly for NPs and
VPs. The string associated with each constituent
is encoded under the feature string. The string
associated with the sentence is simply the concate-
nation of the string associated with the VP and
the string associated with the NP: this constraint
is expressed in a condition using the APPEND rela-
tion on lists (Figure 4).
The difference between the parsing and the
generation problem is then only in the form of the
term given to the interpreter for evaluation. An
underspecified term where only the string is given
defines the parsing problem:
S[string: (TJther storms Cornwall)]
An underspecified term where only the seman-
tic form is given defines the generation problem:
&apos;This is of course very reminiscent of HPSG, and it should not come as a surprise: HPSG is so far the only formal
linguistic theory based on the notion of typed feature structures [Pollard/Sag 87]. A computational formalism similar to
TFS is currently under design at CMU for implementing HPSG [Carpenter 90, Franz 90].
&apos;Using a more condensed notation for lists with angle brackets provided by the TFS syntax: a list
</bodyText>
<note confidence="0.797231">
CONS [first: Mary, rest: CONS[first : sings, rest: NIL]] is written as &lt;Mary sings&gt;.
</note>
<page confidence="0.961994">
76
</page>
<note confidence="0.726487">
[ pred: STORM
S head: trans: argl: UTHER
arg2: CORNWALL]
</note>
<bodyText confidence="0.999788428571429">
In both cases, the same interpreter uses the
same set of rewrite rules to fill in &amp;quot;missing in-
formation&amp;quot; according to the grammar definitions.
The result in both cases is exactly the same: a fully
specified term containing the string, the semantic
form, and also all other syntactic information like
the constituent structure (Figure 5).
</bodyText>
<subsectionHeader confidence="0.999922">
3.2 Bi-directional transfer in MT
</subsectionHeader>
<bodyText confidence="0.999936696969697">
We have sketched above a very general frame-
work for specifying mappings between a linguis-
tic structure, en&apos;coded as a feature structure and
a string, also encoded as a feature structure. We
apply a similar technique for specifying MT trans-
fer rules, which we prefer to call &amp;quot;contrastive
rules&amp;quot; since there is no directionality involved
[Zajac 89, Zajac, 90a].
The idea is rather simple: assume we are work-
ing with linguistic structures similar to LFG&apos;s
functional structures for English and French
[Kaplan et al. 89]. We define a translation rela-
tion as a type TAU-LEX with two features, eng for
the English structure and fr for the French struc-
ture. This &amp;quot;bilingual sign&amp;quot; is defined on the lexical
structure: each subtype of TAU-LEX defines a lexi-
cal correspondence between a partial English lexi-
cal structure and a partial French lexical structure
for a given lexical equivalence. Such a lexical con-
trastive definition also has to pair the arguments
recursively, and this is expressed in the condition
part of the definition (Figure 6). The translation
of syntactic features, like tense or determination,
is also specified in the condition part, and these
contrastive definitions are defined separately from
the lexical definitions.
The transfer problem for one direction or the
other is stated in the same way as for parsing or
generation: the input term is an under-specified
&amp;quot;bilingual sign&amp;quot; where only one structure for one
language is given. Using the contrastive grammar,
the interpreter fills in missing information and
builds a completely specified bilingual signil.
</bodyText>
<sectionHeader confidence="0.999962" genericHeader="method">
4 THE TERMINATION PROBLEM AND
EFFICIENCY ISSUES
</sectionHeader>
<bodyText confidence="0.984588173913043">
For parsing and generation, since no constraint
is imposed on the kind of mapping between the
string and the semantic form, termination has
to be proved for each class of grammar and
the for the particular evaluation mechanism used
for either parsing or generation with this gram-
mar. If we restrict ourselves to class of grammars
for which terminating evaluation algorithms are
known, we can implement those directly in TFS.
However, the TFS evaluation strategy allows more
naive implementations of grammars and the outer-
most evaluation of &amp;quot;sub-goals&amp;quot; terminates on a
strictly larger class of programs than for corre-
sponding logic programs implemented in a con-
ventional PROLOG. Furthermore, the grammar
writer does not need, and actually should not, be
aware of the control which follows the shape of the
input rather than a fixed strategy, thanks to the
lazy evaluation mechanism.
IIPSG-style grammars do not cause any prob-
lem: completeness and coherence as defined
for LFG, and extended to the general case
&amp;quot;See also [Reape &apos;90] for a &amp;quot;Shake&apos;n&apos;Bake&amp;quot; approach to MT (Whitelock).
</bodyText>
<page confidence="0.997037">
77
</page>
<bodyText confidence="0.99997365625">
by [Wedekind 88], are implemented in HPSG
using the &amp;quot;subcategorization feature principle&amp;quot;
[Johnson 87]. Termination conditions for parsing
are well understood in the framework of context-
free grammars. For generation using feature struc-
tures, one of the problems is that the input could
be &amp;quot;extended&amp;quot; during processing, i.e. arbitrary
feature structures could be introduced in the se-
mantic part of the input by unification with the
semantic part of a rule. However, if the semantic
part of the input is fully speficied according to a
set of type definitions describing the set of well-
formed semantic structures (and this condition is
easy to check), this cannot arise in a type-based
system. A more general approach is described in
[Dymetman et al. 90] who define sufficient prop-
erties for termination for parsing and generation
for the class of &amp;quot;Lexical Grammars&amp;quot; implemented
in PROLOG. These properties seem generalizable
to other classes of grammars as well, and are also
applicable to TFS implementations. The idea is
relatively simple and says that for parsing, each
rule must consume a non empty part of the string,
and for generation, each rule must consume a non
empty part of the semantic form. Since Lexical
Grammars are implemented in PROLOG, left-
recursion must be eliminated for parsing and for
generation, but this does not apply to TFS imple-
mentations.
Termination for reversible transfer grammars is
discussed in [van Noord 90]. One of the problems
mentioned is the extension of the &amp;quot;input&amp;quot;, as in
generation, and the answer is similar (see above).
however, properties similar to the &amp;quot;conservative
guides&amp;quot; of [Dymetman et al. 90] have to hold in
order to ensure termination.
The lazy evaluation mechanism has an al-
most optimal behavior on the class of prob-
lems that have an exponential complexity
when using the &amp;quot;generate and test&amp;quot; method
[van Hentenryck/Dincbas 87, Ait-Kaci/Meyer 90].
It is driven by the availability of information: as
soon as some piece of information is available, the
evaluation of constraints in which this information
appears is triggered. Thus, the search space is ex-
plored &amp;quot;intelligently&amp;quot;, never following branches of
computation that would correspond to uninstan-
ciated PROLOG goals. The lazy evaluation mech-
anism is not yet fully implemented in the current
version of TFS, but with the partial implementa-
tion we have, a gain of 50% for parsing has already
been achieved (in comparison with the previous
implementation using only the outer-most rewrit-
ing strategy).
The major drawback of the current implemen-
tation is the lack of an efficient indexing scheme
for objects. Since the dictionaries are accessed us-
ing unification only, each entry is tried one after
the other, leading to an extremely inefficient be-
havior with large dictionaries. However, we think
that a general indexing scheme based on a com-
bination of methods used in PROLOG implemen-
tations and in object-oriented database systems is
feasible.
</bodyText>
<sectionHeader confidence="0.98777" genericHeader="conclusions">
CONCLUSION
</sectionHeader>
<bodyText confidence="0.9999363">
We have described a uniform constraint-based
architecture for the implementation of reversible
unification grammars. The advantages of this ar-
chitecture in comparison of more traditional logic
(i.e. PROLOG) based architectures are: the in-
put/output distinction is truly abolished; the eval-
uation terminates on a strictly larger class of prob-
lems; it is directly based on typed feature struc-
tures, not first order terms; a single fully data-
driven constraint evaluation scheme is used; the
</bodyText>
<page confidence="0.993519">
78
</page>
<bodyText confidence="0.999887">
constraint evaluation scheme is directly derived
from the semantics of typed feature structures.
Thus, the TFS&apos; language allows a direct imple-
mentation of reversible unification grammars. Of
course, it does not dispense the grammar designer
with the proof of general formal properties that
any well-behaved grammar should have, but it
does allow the grammar writer to develop gram-
mars without thinking about any notion of control
or input/output distinction.
</bodyText>
<sectionHeader confidence="0.998855" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999058134328358">
[AIt-Kaci 84] Hassan Ait-Kaci. A Lattice Theoretic
Approach to Computation based on a Calculus of
Partially Ordered Types Structures. Ph.D Disserta-
tion, University of Pennsylvania.
[AIt-Kaci 86] Hassan Alt-Kaci. &amp;quot;An Algebraic Seman-
tics Approach to the Effective Resolution of Type
Equations&amp;quot;. Theoretical Computer Science 45, 293-
351.
[A4-Kaci/Meyer 90] Hassan Ait-Kaci and Richard
Meyer. &amp;quot;Wild_LIFE, a user manual&amp;quot;. PRL Technical
Note 1, Digital&apos; Equipement Corporation, Paris Re-
search Laboratory, Rueil-Malmaison, France, 1990.
[Calder et al. 89] Jonathan Calder, Mike Reape and
Henk Zeevat. &amp;quot;An algorithm for generation in uni-
fication grammars&amp;quot;. Proc. of the 4th Conference of
the European Chapter of the Association for Compu-
tational LinguiStics, 10-12 April 1989, Manchester.
[Carpenter 90] Bob Carpenter. &amp;quot;Typed feature struc-
tures: inheritance, (in)equality and extensionality&amp;quot;.
Proc. of the Workshop on Inheritance in Natural
Language Processing, Institute for Language Tech-
nology and AI, Tilburg University, Netherlands, Au-
gust 1990.
[Dershowitz/Plaisted 88] N. Dershowitz and D.A.
Plaisted. &amp;quot;Equational programming&amp;quot;. In Hayes,
Michie and Richards (eds.). Machine Intelligence 11.
Clarendon Press, Oxford, 1988.
[Dymetman/Isabelle 88] Marc Dymetman and Pierre
Isabelle. &amp;quot;Reversible logic grammars for machine
translation&amp;quot;. Proc. of the 2nd International Con-
ference on Theoretical and Methodological Issues
in Machine Translation of Natural Language, June
1988, Pittsburgh.
[Dymetman et al. 90] Marc Dymetman, Pierre Is-
abelle and Francois Perrault. &amp;quot;A symmetrical ap-
proach to parsing and generation&amp;quot;. Proc. of the 13th
International Conference on Computational Lin-
guistics - COLING&apos;90, Helsinki, August 1990.
[Emele 91] Martin Emele. &amp;quot;Unification with lazy non-
redundant copying&amp;quot;. 29th Annual Meeting of the
ACL, June 1991, Berkeley, CA.
[Emele/Zajac 90a] Martin Emele and Remi Zajac. &amp;quot;A
fixed-point semantics for feature type systems&amp;quot;.
Proc. of the 2nd Workshop on Conditional and
Typed Rewriting Systems - CTRS&apos;90, Montreal,
June 1990.
[Emele/Zajac 90b] Martin Emele and Remi Zajac.
&amp;quot;Typed Unification Grammars&amp;quot;. Proc. of the 13th
International Conference on Computational Lin-
guistics - COLING&apos;90, Helsinki, August 1990.
[Emele et al. 90] Martin Emele, Ulrich Heid, Stefan
Momma and Remi Zajac. &amp;quot;Organizing linguistic
knowledge for multilingual generation&amp;quot;. Proc. of
the 13th International Conference on Computational
Linguistics - COLING&apos;90, Helsinki, August 1990.
[Franz 90] Alex Franz. &amp;quot;A parser for HPSC,&apos;&amp;quot;. CMU re-
port CMU-LCL-90-3, Laboratory for Computational
Linguistics, Carnegie Mellon University, July 1990.
[Isabelle et al. 88] Pierre Isabelle, Marc Dymetman
and Eliot Macklovitch. &amp;quot;CRITTER: a translation
system for agricultural market reports.&amp;quot;. Proc. of
the 12th International Conference on Computational
Linguistics - COLING&apos;88, August 1988, Budapest.
[Johnson 87] Mark Johnson. &amp;quot;Grammatical relations
in attribute-value grammars&amp;quot;. Proc. of the West
Coast Conference on Formal Linguistics, Vol.6,
Stanford, 1987
</reference>
<page confidence="0.977519">
79
</page>
<reference confidence="0.999795580246914">
[Kaplan et al. 89] Ronald M. Kaplam, Klaus Netter,
Jurgen Wedekind, Annie Zaenen. &amp;quot;Translation by
structural correspondences&amp;quot;. Proc. of the 4th Euro-
pean ACL Conference, Manchester, 1989.
[Klop 90] Jan Willem Klop. &amp;quot;Term rewriting systems&amp;quot;.
To appear in S. Abramsky, D. Gabbay and T.
Maibaum. Handbook of Logic in Computer Science,
Vol.1, Oxford University Press.
[Newman 90] P. Newman. &amp;quot;Towards convenient bi-
directional grammar formalisms&amp;quot;. Proc. of the 13th
International Conference on Computational Lin-
guistics - COLING&apos;90, August 1990, Helsinki.
[Pereira/Warren 83] Fernando C.N. Pereira and David
Warren. &amp;quot;Parsing as deduction&amp;quot;. Proc. of the 21st
Annual Meeting of the ACL, 15-17 June 1983, Cam-
bridge, MA.
[Pollard/Sag 87] Carl Pollard and Ivan A. Sag.
Information-Based Syntax and Semantics. CSLI
Lecture Notes 13, Chicago University Press, 1987.
[Pollard/Moshier 89] Carl Pollard and Drew Moshier.
&amp;quot;Unifiying partial descriptions of sets&amp;quot;. In P. Hanson
(ed.) Information, Language and Cognition, Van-
couver Studies in Cognitive Science 1, University of
British Columbia Press, Vancouver.
[Reape 90] Mike Reape. &amp;quot;Parsing semi-free word or-
der and bounded discontinuous constituency and
&amp;quot;shake &apos;n&apos; bake&amp;quot; machine translation (or &apos;genera-
tion as parsing&apos;)&amp;quot;. Presented at the International
Workshop on Constraint Based Formalisms for Nat-
ural Language Generation, Bad Teinach, Germany,
November 1990.
[Russell et al. 90] Graham Russell, Susan Warwick
and John Carroll. &amp;quot;Asymmetry in parsing and gen-
eration with unification grammars: case studies from
ELU&amp;quot;. Proc. of the 28th Annual Meeting of the ACL,
6-9 June 1990, Pittsburgh.
[Shieber 86] Stuart Shieber.
An Introduction to Unification-based Grammar For-
malisms. CSLI Lectures Notes 4, Chicago University
Press, 1986.
[Shieber 88] Stuart Shieber. &amp;quot;A uniform architecture
for parsing and generation&amp;quot;. Proc. of the 12th Inter-
national Conference on Computational Linguistics -
COLING&apos;88, August 1988, Budapest.
[Shieber et al. 89] Stuart Shieber, Gertjan van Noord,
Robert Moore and Fernando Pereira. &amp;quot;A uniform ar-
chitecture for parsing and generation&amp;quot;. Proc. of the
27th Annual Meeting of the ACL, 26-27 June 1989,
Vancouver.
[Strzalkowski 90] Tomek Strzalkowski. &amp;quot;How to invert
a natural language parser into an efficient gener-
ator: an algorithm for logic grammars&amp;quot;. Proc. of
the 13th International Conference on Computational
Linguistics - COLING&apos;90, August 1990, Helsinki.
[van Hentenryck/Dincbas 87] P. van Hentenryck and
M. Dincbas. &amp;quot;Forward checking in logic program-
ming&amp;quot;. Proc. of the Ph International Conference on
Logic Programming, Melbourne, May 1987.
[van Noord 90] Gertjan van Noord. &amp;quot;Reversible unifi-
cation based machine translation&amp;quot;. Proc. of the 13th
International Conference on Computational Lin-
guistics - COLING&apos;90, August 1990, Helsinki.
[Wedekind 88] Jürgen Wedekind. &amp;quot;Generation as
structure driven generation&amp;quot;. Proc. of the 12th Inter-
national Conference on Computational Linguistics -
COLING &apos;88, August 1988, Budapest.
[Zajac 89] Remi Zajac. &amp;quot;A transfer model using a
typed feature structure rewriting system with in-
heritance&amp;quot;. Proc. of the 27th Annual Meeting of the
ACL, 26-27 June 1989, Vancouver.
[Zajac 90a] Remi Zajac. &amp;quot;A relational approach to
translation&amp;quot;. Proc. of the 3rd International Con-
ference on Theoretical and Methodological Issues in
Machine Translation of Natural Language, 11-13
June 1990, Austin.
[Zajac 90b] Remi Zajac. &amp;quot;Computing partial informa-
tion using approximations - Semantics of typed
feature structures&amp;quot;. Presented at the International
Workshop on Constraint Based Formalisms for Nat-
ural Language Generation, Bad Teinach, Germany,
November 1990.
</reference>
<page confidence="0.998233">
80
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.001092">
<title confidence="0.994999">A Uniform Architecture for Parsing, Generation and Transfer</title>
<author confidence="0.891677">Remi</author>
<affiliation confidence="0.98582">IMS-CL/Ifl-AIS, University of</affiliation>
<address confidence="0.930743">KeplerstraBe 17, D-7000 Stuttgart</address>
<email confidence="0.994715">zajac@informatik.uni-stuttgart.de</email>
<abstract confidence="0.980961889943075">We present a uniform computational architecture for developing reversible grammars for parsing and generation, and for bidirectional transfer in MT. We sketch the principles of a general reversible architecture and show how they are realized in the rewriting system for typed feadeveloped at the University of Stuttgart. The reversibility of parsing and generation, and the bidirectionality of transfer rules fall out of general properties of the uniform architecture. 1 PRINCIPLES FOR A UNIFORM AR- CHITECTURE The principles for a uniform architecture for parsing/generation and bidirectional transfer are already contained in some PROLOG logic grammars like DCGs. 881 proposes to apply the idea of Earley deduction [Pereira/Warren 83] to generation. With the noticeable exception of [Dymetman et al. 90], all of these approaches use a context-free based mapping to relate a string of words with a semantic structure. Almost all of these approaches also rely on some specific properties of the grammars intended to be processed (semantic heads, guides, leading features, specific representation of subcategorization, etc.). They are also dependent on the direction in which they are used: even if the grammar specification is the same, two different compilers generate two different programs for parsing and generation. Using the PROLOG deduction mechanism to have a simple and direct implementation of a parser/generator, one has to solve some problems due to the PROLOG evaluation method, for example termination on uninstantiated goals: goals have to be evaluated in a different order for parsing and generation. A reordering of goals performed by a rule compiler can be based on a direct specification of the ordering by the grammar writer [Dymetman/Isabelle 881, or can be derived •Research reported in this paper is partly supported by the German Ministry of Research and Technology (BMFT, Bundesminister fiir Forschung und Technologie), under grant No. 08 B3116 3. The views and conclusions contained herein are those of the author and should not be interpreted as representing official policies. 71 by a compiler by analysing the dataflow using only input/output specifications [Strzalkowski 90]. But if we regard the grammar as a set of constraints to be satisfied, parsing and generation differ only in the nature of the &amp;quot;input&amp;quot;, and there is no reason to use two different programs. An interesting approach which uses only one program is described in [Dymetman/Isabelle 88]. Within this approach, a lazy evaluation mechanism, based on the specification of input/output arguments, is implemented, and the evaluation is completly datadriven: the same program parses or generates depending only on the form of the input term. Furthermore, a reversible grammar need not to be based only on constituency. [Dymetman et al. 90] describes a class of reversible grammars (&amp;quot;Lexical Grammars&amp;quot;) based on a few composition rules which are very reminiscent of categorial grammars. Other kinds of approaches can also be envisaged, e.g. using a dependency structure and linear precedence relations [Reape 90] (see also [Pollard/Sag 87]). From these experiments, we can outline desirable properties of a computational framework for implementing reversible grammars: • A unique general deductive mechanism is used. Grammars define constraints on the set of acceptable structures, and there is no distinction between &amp;quot;input&amp;quot; and &amp;quot;output&amp;quot;. • To abolish the input/output distinction, the same kind of data structure is used to encode both the string and the linguistic structure, and they are embedded into one data structure that represents the relation between the string and the associated linguistic structure (c.f. the HPSG sign [Pollard/Sag 87]). • Specific mapping properties, based on constituency, linear precedence or functional composition, are not part of the formalism itself but are encoded explicitly using the formalism. • The deductive mechanism should be computationally well-behaved, especially with respect to completeness. In the next section, we show how these properties are realized in the Typed Feature Structure rewriting system implemented at the University of Stuttgartl. We then discuss the parsing and generation problem, and bidirectionality of transfer in MT. Assuming that we have the proper machinery, problems in parsing or generation can arise because of a deficiency in the in the last section, the termination problem and efficiency issues are addressed. 2 A REWRITE MACHINE FOR TYPED FEATURE STRUCTURES The basic motivation behind the Typed Feature Structure rewriting system is to provide a language which has the same deductive and logical properties of logic programming languages such as PROLOG, but which is based on feature terms instead of first order terms [Ait-Kaci 84, Aft-Kaci 86, Emele/Zajac 904 Such a language has a different semantics than the Herbrand semantics: this semantics is based on the notion of approximation, which captures in a computational &apos;The TFS system has been implemented by Martin Emele and the author as part of the POLYGLOSS project. &apos;As it is often the case in generation when using a grammar built initially for parsing. &apos;See also [Emele/Zajac 90a] for a fixed-point semantics. 72 framework the idea that feature structures reprepartial information [Zajac Of course, in problems of completeness and efficiency have to be addressed. The universe of feature terms is structured in an inheritance hierarchy which defines a partial ordering on kinds of available information. The backbone of the hierarchy is defined by a parorder &lt; on &apos;a set of symbols T. this we add two more symbols: represents completly underspecified information, and 1 which represents inconsistent information. Two type symbols have a common most general subtype (Greatest Lower Bound — GLB): this subtype inherits all information associated with all super-types. We define a on two symbols A and A = glb(A, B). Fora type hierarchy defined as a tuple A) is a meet semi-lattice. A technicality arises when types A and more than one GLB: in that case, the set of GLBs is interpreted as a disjunction. As different sets of attribute-value pairs make sense for different kind of objects, we divide our feature terms into different types. Terms are closed in the sense that each type defines a specific association of features (and restrictions on their possible values) which are appropriate for it, expressed as a feature structure .(the definition of the type). Since types are organized in an inheritance hierarchy, a type inherits all the features and value restrictions from all its super-types. This type-discipline for feature structures enforces the following two constraints: a term cannot have a feature which at compile time. is not appropriate for its type&apos; and conversely, a pair of feature and value should always be defined for some type. Thus a feature term is always typed and it is not possible to introduce an arbitrary feature in a term (by unification): all features added to some term should be appropriate for its type. We use the attribute-value matrix (AVM) notation for feature terms and we write the type symbol for each feature term in front of the opening square bracket of the AVM. A type symbol which does not have any feature defined for it is atomic. All others types are complex. A type definition has the following form: the type symbol to be defined appears on the lefthand side of the equation. The right-hand side is an expression of conjunctions and disjunctions of typed feature terms (Figure 1). Conjunctions are interpreted as meets on typed feature terms (implemented using a typed unification algorithm [Emele 91]). The definition may have conditional constraints expressed as a logical conjunction of feature terms and introduced by &apos;:-&apos;. The righthand side feature term may contain the lefthand side type symbol in a subterm (or in the condition), thus defining a recursive type equation which gives the system the expressive power needed to describe complex linguistic structures. A subtype inherits all constraints of its supertypes monotonically: the constraints expressed as an expression of feature terms are conjoined using unification; the conditions are conjoined using the logical and operation. 73 1: NIL 2: iLIST APPEND 2: LIST 3: LIST 1: LIST] [ APPEND1 1: CONS[firstm &apos;rest En 3: CONS[firstlx] rest. LIST \ [first: T NIL CONS rest: LIST :- APPEND2: 3: 1 1: [ rn Figure 2: Type hierarchy for LIST and APPEND (T and I omitted). A set of type definitions defines an inheritance hierarchy of feature terms which specifies the available approximations. Such a hierarchy is compiled into a rewriting system as follows: each link between a type a subtype a rewrite rule of the form [a] and the definitions of A and respectively. The interpreter is given a &amp;quot;query&amp;quot; (a feature term) to evaluate: this input term is already an approximation of the final solution, though a very rough approximation. The idea is to incrementally add more information to that term using the rewrite rules in order to get step by step closer to the solution: we stop when we have the best Possible approximation. rewrite step for a term defined as follows: u is a subterm type A and there exists a rule A[a] that u right-hand side unified with the subu, giving a new term is more spethan rewrite step is applied nondeterministically everywhere in the term until no rule is Actually, the rewriting process stops either when all types are minimal types or when all subterms in a term correspond exactly to some approximation defined by a type in the hierarchy. A term is &amp;quot;solved&amp;quot; when any subterm is either more specific than the definition of a minimal type, or does not give more information than the definition of its type. defines an and only if for a term to be a solved-form, where any addition of information will not bring anything new and is using a rewriting the of a rule A[a] —&gt; a subterm it actually triggered only when A[a] A[a]. This lazy rewriting strategy implements a fully data-driven computation scheme and avoids useless branches of computation. Thus, there is no do not change this general scheme and are omitted from the presentation for the sake of simplicity. See for example [Dershowitz/Plaisted 88], and [Klop 90] for a survey. 74 NIL LIST LIST ----&gt; 1: NIL APPEND 2: LIST APPENDO 2: 0 LIST [1: 3: LIST 3:0 firstu 1: CONS _rest :El 2: : — APPEND 2: El [1: [ 1 APPEND LIST APPEND1 LIST] 3: LIST 3: CONS[first:m Figure 3: Rewrite rules for LIST and APPEND. need to have a special treatment to avoid what corresponds to the evaluation of un-instantiated goals in PROLOG, since a general treatment based on semantics of formalism itself is built in the evaluation strategy of the interpreter. The choice of which subterm to rewrite is only partly driven by the availability of information (using the lazy rewriting scheme). When there are several subterms that could be rewritten, the computation rule is to choose the outermost ones (inner-most strategies are usually non- Such an outer-most rewriting strategy has interesting termination properties, since there are problems where a TFS program will terminate when the corresponding PROLOG prowill For a given subterm, the choice of which rule to apply is done non-deterministically, and the search space is explored depth-first using a backtracking scheme. This strategy is not complete, though in association with the outer-most rule and with the lazy evaluation scheme, it seems to terminate on any &amp;quot;well-defined&amp;quot; problem, i.e. when terms introduced by recursive definitions during execution are strictly decreasing according to some mesure (for example, see the definition of guides in [Dymetman et al. 90] for the parsing and generation problems). A complete breadth-first search strategy is planned for debugging purposes. interpreter described above is and has been used to test several models such as LFG, HPSG, or DCG on toy examples [Emele/Zajac 90b, Emele et al. 90, Zajac 90a]. outer-most strategy is similar to hyper-resolution in logic programming. The lazy evaluation mechanism is related to the &apos;freeze&apos; predicate of, e.g. Prolog-II and Sicstus Prolog, though in Prolog, it has to be called explicitly. the problem of left-recursive rules in naive PROLOG implementations of DCGs prototype version is publically available. 75 GENERATION, AND BIDI- RECTIONAL TRANSFER 3.1 Parsing/generation describes the relation between strings of words and linguistic structures. In order to implement a reversible grammar, we have to encode both kinds of structure using the same kind of data structure provided by the TFS language: typed feature structures. A linguistic structure will be encoded using features and values, and the set of valid linguistic structures has to be declared explicitly. A string of words will be encoded as a list of word forms, using the same kind of definitions as in Figure 1. To abolish the distinction between &amp;quot;input&amp;quot; and &amp;quot;output&amp;quot;, the relation between a string and a linguistic structure will be encoded in a single term for example, two features, we can call the type of such a structure type divided into several subtypes corresponding to different mappings between a string and a linguistic structure. We will have at least the classification bewteen phrases and words. The definition of a phrase will recursively relate subphrases and substrings, and define the phrase as a composition of subphrases and the string as the concatenation of substrings. The formalism does not impose constraints on how the relations between phrases and strings are defined, and the grammar writer has to define them explicitly. One possibility is to use context-free like mappings, using for example the same kind of encoding as in DCGs for PATR-like gramars or HPSG [Emele/Zajac 90b]. But other possibilities are available as well: using a kind of functional composition reminiscent of categorial grammars as in [Dymetman et al. 90], or linear precedence rules [Pollard/Sag 87, Reape 90]. example, a rule like [Shieber S NP VP: (S head) = (VP head) (S headform) = finite (VP syncat first) = (NP) (VP syncat rest) = (end). is encoded in TFS using a type S for the sentence with two features encoding the constituent structure, and similarly for NPs and VPs. The string associated with each constituent encoded under the feature string associated with the sentence is simply the concatenation of the string associated with the VP and the string associated with the NP: this constraint expressed in a condition using the relation on lists (Figure 4). The difference between the parsing and the generation problem is then only in the form of the term given to the interpreter for evaluation. An underspecified term where only the string is given defines the parsing problem: S[string: (TJther storms Cornwall)] An underspecified term where only the semantic form is given defines the generation problem: &apos;This is of course very reminiscent of HPSG, and it should not come as a surprise: HPSG is so far the only formal linguistic theory based on the notion of typed feature structures [Pollard/Sag 87]. A computational formalism similar to TFS is currently under design at CMU for implementing HPSG [Carpenter 90, Franz 90]. &apos;Using a more condensed notation for lists with angle brackets provided by the TFS syntax: a list CONS [first: Mary, rest: CONS[first : sings, rest: NIL]] is written as &lt;Mary sings&gt;. 76 pred: trans: argl: In both cases, the same interpreter uses the same set of rewrite rules to fill in &amp;quot;missing information&amp;quot; according to the grammar definitions. The result in both cases is exactly the same: a fully specified term containing the string, the semantic form, and also all other syntactic information like the constituent structure (Figure 5). 3.2 Bi-directional transfer in MT We have sketched above a very general framework for specifying mappings between a linguistic structure, en&apos;coded as a feature structure and a string, also encoded as a feature structure. We apply a similar technique for specifying MT transfer rules, which we prefer to call &amp;quot;contrastive rules&amp;quot; since there is no directionality involved [Zajac 89, Zajac, 90a]. The idea is rather simple: assume we are working with linguistic structures similar to LFG&apos;s functional structures for English and French [Kaplan et al. 89]. We define a translation relaas a type two features, English structure and the French structure. This &amp;quot;bilingual sign&amp;quot; is defined on the lexical each subtype of a lexical correspondence between a partial English lexical structure and a partial French lexical structure for a given lexical equivalence. Such a lexical contrastive definition also has to pair the arguments recursively, and this is expressed in the condition part of the definition (Figure 6). The translation of syntactic features, like tense or determination, is also specified in the condition part, and these contrastive definitions are defined separately from the lexical definitions. The transfer problem for one direction or the other is stated in the same way as for parsing or generation: the input term is an under-specified &amp;quot;bilingual sign&amp;quot; where only one structure for one language is given. Using the contrastive grammar, the interpreter fills in missing information and builds a completely specified bilingual signil. 4 THE TERMINATION PROBLEM AND EFFICIENCY ISSUES For parsing and generation, since no constraint is imposed on the kind of mapping between the string and the semantic form, termination has to be proved for each class of grammar and the for the particular evaluation mechanism used for either parsing or generation with this grammar. If we restrict ourselves to class of grammars for which terminating evaluation algorithms are known, we can implement those directly in TFS. However, the TFS evaluation strategy allows more naive implementations of grammars and the outermost evaluation of &amp;quot;sub-goals&amp;quot; terminates on a strictly larger class of programs than for corresponding logic programs implemented in a conventional PROLOG. Furthermore, the grammar writer does not need, and actually should not, be aware of the control which follows the shape of the input rather than a fixed strategy, thanks to the lazy evaluation mechanism. IIPSG-style grammars do not cause any problem: completeness and coherence as defined for LFG, and extended to the general case &amp;quot;See also [Reape &apos;90] for a &amp;quot;Shake&apos;n&apos;Bake&amp;quot; approach to MT (Whitelock). 77 by [Wedekind 88], are implemented in HPSG using the &amp;quot;subcategorization feature principle&amp;quot; [Johnson 87]. Termination conditions for parsing are well understood in the framework of contextfree grammars. For generation using feature structures, one of the problems is that the input could be &amp;quot;extended&amp;quot; during processing, i.e. arbitrary feature structures could be introduced in the semantic part of the input by unification with the semantic part of a rule. However, if the semantic part of the input is fully speficied according to a set of type definitions describing the set of wellformed semantic structures (and this condition is easy to check), this cannot arise in a type-based system. A more general approach is described in [Dymetman et al. 90] who define sufficient properties for termination for parsing and generation for the class of &amp;quot;Lexical Grammars&amp;quot; implemented in PROLOG. These properties seem generalizable to other classes of grammars as well, and are also applicable to TFS implementations. The idea is relatively simple and says that for parsing, each rule must consume a non empty part of the string, and for generation, each rule must consume a non empty part of the semantic form. Since Lexical Grammars are implemented in PROLOG, leftrecursion must be eliminated for parsing and for generation, but this does not apply to TFS implementations. Termination for reversible transfer grammars is discussed in [van Noord 90]. One of the problems mentioned is the extension of the &amp;quot;input&amp;quot;, as in generation, and the answer is similar (see above). however, properties similar to the &amp;quot;conservative guides&amp;quot; of [Dymetman et al. 90] have to hold in order to ensure termination. The lazy evaluation mechanism has an almost optimal behavior on the class of problems that have an exponential complexity when using the &amp;quot;generate and test&amp;quot; method [van Hentenryck/Dincbas 87, Ait-Kaci/Meyer 90]. It is driven by the availability of information: as soon as some piece of information is available, the evaluation of constraints in which this information appears is triggered. Thus, the search space is explored &amp;quot;intelligently&amp;quot;, never following branches of computation that would correspond to uninstanciated PROLOG goals. The lazy evaluation mechanism is not yet fully implemented in the current version of TFS, but with the partial implementation we have, a gain of 50% for parsing has already been achieved (in comparison with the previous implementation using only the outer-most rewriting strategy). The major drawback of the current implementation is the lack of an efficient indexing scheme for objects. Since the dictionaries are accessed using unification only, each entry is tried one after the other, leading to an extremely inefficient behavior with large dictionaries. However, we think that a general indexing scheme based on a combination of methods used in PROLOG implementations and in object-oriented database systems is feasible. CONCLUSION We have described a uniform constraint-based architecture for the implementation of reversible unification grammars. The advantages of this architecture in comparison of more traditional logic (i.e. PROLOG) based architectures are: the input/output distinction is truly abolished; the evaluation terminates on a strictly larger class of problems; it is directly based on typed feature structures, not first order terms; a single fully datadriven constraint evaluation scheme is used; the 78 constraint evaluation scheme is directly derived from the semantics of typed feature structures. Thus, the TFS&apos; language allows a direct implementation of reversible unification grammars. Of course, it does not dispense the grammar designer with the proof of general formal properties that any well-behaved grammar should have, but it does allow the grammar writer to develop grammars without thinking about any notion of control or input/output distinction.</abstract>
<note confidence="0.934445245283019">References 84] Hassan Ait-Kaci. Lattice Theoretic Approach to Computation based on a Calculus of Ordered Types Structures. Dissertation, University of Pennsylvania. [AIt-Kaci 86] Hassan Alt-Kaci. &amp;quot;An Algebraic Semantics Approach to the Effective Resolution of Type Computer Science 293- 351. [A4-Kaci/Meyer 90] Hassan Ait-Kaci and Richard Meyer. &amp;quot;Wild_LIFE, a user manual&amp;quot;. PRL Technical Note 1, Digital&apos; Equipement Corporation, Paris Research Laboratory, Rueil-Malmaison, France, 1990. [Calder et al. 89] Jonathan Calder, Mike Reape and Henk Zeevat. &amp;quot;An algorithm for generation in unigrammars&amp;quot;. Proc. of the Conference of the European Chapter of the Association for Compu- LinguiStics, April 1989, Manchester. [Carpenter 90] Bob Carpenter. &amp;quot;Typed feature structures: inheritance, (in)equality and extensionality&amp;quot;. Proc. of the Workshop on Inheritance in Natural Language Processing, Institute for Language Technology and AI, Tilburg University, Netherlands, August 1990. [Dershowitz/Plaisted 88] N. Dershowitz and D.A. &amp;quot;Equational programming&amp;quot;. and Richards (eds.). Intelligence 11. Clarendon Press, Oxford, 1988. [Dymetman/Isabelle 88] Marc Dymetman and Pierre Isabelle. &amp;quot;Reversible logic grammars for machine Proc. of the International Conference on Theoretical and Methodological Issues Machine Translation of Natural Language, 1988, Pittsburgh. [Dymetman et al. 90] Marc Dymetman, Pierre Isabelle and Francois Perrault. &amp;quot;A symmetrical apto parsing and generation&amp;quot;. Proc. of the International Conference on Computational Lin- - COLING&apos;90, August 1990. [Emele 91] Martin Emele. &amp;quot;Unification with lazy noncopying&amp;quot;. Annual Meeting of the 1991, Berkeley, CA. [Emele/Zajac 90a] Martin Emele and Remi Zajac. &amp;quot;A fixed-point semantics for feature type systems&amp;quot;. of the Workshop on Conditional and Rewriting Systems - CTRS&apos;90, June 1990. [Emele/Zajac 90b] Martin Emele and Remi Zajac. Unification Grammars&amp;quot;. Proc. of the International Conference on Computational Lin- - COLING&apos;90, August 1990. [Emele et al. 90] Martin Emele, Ulrich Heid, Stefan Momma and Remi Zajac. &amp;quot;Organizing linguistic knowledge for multilingual generation&amp;quot;. Proc. of International Conference on Computational - COLING&apos;90, August 1990. [Franz 90] Alex Franz. &amp;quot;A parser for HPSC,&apos;&amp;quot;. CMU report CMU-LCL-90-3, Laboratory for Computational Linguistics, Carnegie Mellon University, July 1990. [Isabelle et al. 88] Pierre Isabelle, Marc Dymetman and Eliot Macklovitch. &amp;quot;CRITTER: a translation system for agricultural market reports.&amp;quot;. Proc. of International Conference on Computational - COLING&apos;88, 1988, Budapest. [Johnson 87] Mark Johnson. &amp;quot;Grammatical relations attribute-value grammars&amp;quot;. Proc. of the Conference on Formal Linguistics, Stanford, 1987 79 [Kaplan et al. 89] Ronald M. Kaplam, Klaus Netter, Jurgen Wedekind, Annie Zaenen. &amp;quot;Translation by correspondences&amp;quot;. Proc. of the Euro- ACL Conference, 1989. [Klop 90] Jan Willem Klop. &amp;quot;Term rewriting systems&amp;quot;. To appear in S. Abramsky, D. Gabbay and T. of Logic in Computer Science, Vol.1, Oxford University Press. [Newman 90] P. Newman. &amp;quot;Towards convenient bigrammar formalisms&amp;quot;. Proc. of the International Conference on Computational Lin- - COLING&apos;90, 1990, Helsinki. [Pereira/Warren 83] Fernando C.N. Pereira and David &amp;quot;Parsing as deduction&amp;quot;. Proc. of the Meeting of the ACL, June 1983, Cambridge, MA. [Pollard/Sag 87] Carl Pollard and Ivan A. Sag. Syntax and Semantics. Lecture Notes 13, Chicago University Press, 1987. [Pollard/Moshier 89] Carl Pollard and Drew Moshier. &amp;quot;Unifiying partial descriptions of sets&amp;quot;. In P. Hanson Language and Cognition, Vancouver Studies in Cognitive Science 1, University of British Columbia Press, Vancouver. [Reape 90] Mike Reape. &amp;quot;Parsing semi-free word order and bounded discontinuous constituency and &amp;quot;shake &apos;n&apos; bake&amp;quot; machine translation (or &apos;generaas parsing&apos;)&amp;quot;. Presented at the Workshop on Constraint Based Formalisms for Nat- Language Generation, Teinach, Germany, November 1990. [Russell et al. 90] Graham Russell, Susan Warwick and John Carroll. &amp;quot;Asymmetry in parsing and generation with unification grammars: case studies from Proc. of the Annual Meeting of the ACL, 6-9 June 1990, Pittsburgh. [Shieber 86] Stuart Shieber.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Hassan Ait-Kaci</author>
</authors>
<title>A Lattice Theoretic Approach to Computation based on a Calculus of Partially Ordered Types Structures. Ph.D Dissertation,</title>
<institution>University of Pennsylvania.</institution>
<marker>[AIt-Kaci 84]</marker>
<rawString>Hassan Ait-Kaci. A Lattice Theoretic Approach to Computation based on a Calculus of Partially Ordered Types Structures. Ph.D Dissertation, University of Pennsylvania.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Hassan Alt-Kaci</author>
</authors>
<title>An Algebraic Semantics Approach to the Effective Resolution of Type Equations&amp;quot;.</title>
<journal>Theoretical Computer Science</journal>
<volume>45</volume>
<pages>293--351</pages>
<marker>[AIt-Kaci 86]</marker>
<rawString>Hassan Alt-Kaci. &amp;quot;An Algebraic Semantics Approach to the Effective Resolution of Type Equations&amp;quot;. Theoretical Computer Science 45, 293-351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hassan Ait-Kaci</author>
<author>Richard Meyer</author>
</authors>
<title>Wild_LIFE, a user manual&amp;quot;.</title>
<date>1990</date>
<tech>PRL Technical Note 1,</tech>
<institution>Digital&apos; Equipement Corporation, Paris Research Laboratory,</institution>
<location>Rueil-Malmaison, France,</location>
<marker>[A4-Kaci/Meyer 90]</marker>
<rawString>Hassan Ait-Kaci and Richard Meyer. &amp;quot;Wild_LIFE, a user manual&amp;quot;. PRL Technical Note 1, Digital&apos; Equipement Corporation, Paris Research Laboratory, Rueil-Malmaison, France, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Calder</author>
</authors>
<title>Mike Reape and Henk Zeevat. &amp;quot;An algorithm for generation in unification grammars&amp;quot;.</title>
<date>1989</date>
<booktitle>Proc. of the 4th Conference of the European Chapter of the Association for Computational LinguiStics,</booktitle>
<pages>10--12</pages>
<location>Manchester.</location>
<marker>[Calder et al. 89]</marker>
<rawString>Jonathan Calder, Mike Reape and Henk Zeevat. &amp;quot;An algorithm for generation in unification grammars&amp;quot;. Proc. of the 4th Conference of the European Chapter of the Association for Computational LinguiStics, 10-12 April 1989, Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>Typed feature structures: inheritance, (in)equality and extensionality&amp;quot;.</title>
<date>1990</date>
<booktitle>Proc. of the Workshop on Inheritance in Natural Language Processing, Institute for Language Technology and AI,</booktitle>
<location>Tilburg University, Netherlands,</location>
<marker>[Carpenter 90]</marker>
<rawString>Bob Carpenter. &amp;quot;Typed feature structures: inheritance, (in)equality and extensionality&amp;quot;. Proc. of the Workshop on Inheritance in Natural Language Processing, Institute for Language Technology and AI, Tilburg University, Netherlands, August 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Dershowitz</author>
<author>D A Plaisted</author>
</authors>
<title>Equational programming&amp;quot;.</title>
<date>1988</date>
<booktitle>Machine Intelligence 11.</booktitle>
<editor>In Hayes, Michie and Richards (eds.).</editor>
<publisher>Clarendon Press,</publisher>
<location>Oxford,</location>
<marker>[Dershowitz/Plaisted 88]</marker>
<rawString>N. Dershowitz and D.A. Plaisted. &amp;quot;Equational programming&amp;quot;. In Hayes, Michie and Richards (eds.). Machine Intelligence 11. Clarendon Press, Oxford, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Dymetman</author>
<author>Pierre Isabelle</author>
</authors>
<title>Reversible logic grammars for machine translation&amp;quot;.</title>
<date>1988</date>
<booktitle>Proc. of the 2nd International Conference on Theoretical and Methodological Issues in Machine Translation of Natural Language,</booktitle>
<location>Pittsburgh.</location>
<marker>[Dymetman/Isabelle 88]</marker>
<rawString>Marc Dymetman and Pierre Isabelle. &amp;quot;Reversible logic grammars for machine translation&amp;quot;. Proc. of the 2nd International Conference on Theoretical and Methodological Issues in Machine Translation of Natural Language, June 1988, Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Dymetman</author>
<author>Pierre Isabelle</author>
<author>Francois Perrault</author>
</authors>
<title>A symmetrical approach to parsing and generation&amp;quot;.</title>
<date>1990</date>
<booktitle>Proc. of the 13th International Conference on Computational Linguistics - COLING&apos;90,</booktitle>
<location>Helsinki,</location>
<marker>[Dymetman et al. 90]</marker>
<rawString>Marc Dymetman, Pierre Isabelle and Francois Perrault. &amp;quot;A symmetrical approach to parsing and generation&amp;quot;. Proc. of the 13th International Conference on Computational Linguistics - COLING&apos;90, Helsinki, August 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Emele</author>
</authors>
<title>Unification with lazy nonredundant copying&amp;quot;.</title>
<date>1991</date>
<booktitle>29th Annual Meeting of the ACL,</booktitle>
<location>Berkeley, CA.</location>
<marker>[Emele 91]</marker>
<rawString>Martin Emele. &amp;quot;Unification with lazy nonredundant copying&amp;quot;. 29th Annual Meeting of the ACL, June 1991, Berkeley, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Emele</author>
<author>Remi Zajac</author>
</authors>
<title>A fixed-point semantics for feature type systems&amp;quot;.</title>
<date>1990</date>
<booktitle>Proc. of the 2nd Workshop on Conditional and Typed Rewriting Systems - CTRS&apos;90,</booktitle>
<location>Montreal,</location>
<marker>[Emele/Zajac 90a]</marker>
<rawString>Martin Emele and Remi Zajac. &amp;quot;A fixed-point semantics for feature type systems&amp;quot;. Proc. of the 2nd Workshop on Conditional and Typed Rewriting Systems - CTRS&apos;90, Montreal, June 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Emele</author>
<author>Remi Zajac</author>
</authors>
<title>Typed Unification Grammars&amp;quot;.</title>
<date>1990</date>
<booktitle>Proc. of the 13th International Conference on Computational Linguistics - COLING&apos;90,</booktitle>
<location>Helsinki,</location>
<marker>[Emele/Zajac 90b]</marker>
<rawString>Martin Emele and Remi Zajac. &amp;quot;Typed Unification Grammars&amp;quot;. Proc. of the 13th International Conference on Computational Linguistics - COLING&apos;90, Helsinki, August 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Emele</author>
<author>Ulrich Heid</author>
<author>Stefan Momma</author>
<author>Remi Zajac</author>
</authors>
<title>Organizing linguistic knowledge for multilingual generation&amp;quot;.</title>
<date>1990</date>
<booktitle>Proc. of the 13th International Conference on Computational Linguistics - COLING&apos;90,</booktitle>
<location>Helsinki,</location>
<marker>[Emele et al. 90]</marker>
<rawString>Martin Emele, Ulrich Heid, Stefan Momma and Remi Zajac. &amp;quot;Organizing linguistic knowledge for multilingual generation&amp;quot;. Proc. of the 13th International Conference on Computational Linguistics - COLING&apos;90, Helsinki, August 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Franz</author>
</authors>
<title>A parser for HPSC,&apos;&amp;quot;.</title>
<date>1990</date>
<tech>CMU report CMU-LCL-90-3,</tech>
<institution>Laboratory for Computational Linguistics, Carnegie Mellon University,</institution>
<marker>[Franz 90]</marker>
<rawString>Alex Franz. &amp;quot;A parser for HPSC,&apos;&amp;quot;. CMU report CMU-LCL-90-3, Laboratory for Computational Linguistics, Carnegie Mellon University, July 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Isabelle</author>
<author>Marc Dymetman</author>
<author>Eliot Macklovitch</author>
</authors>
<title>CRITTER: a translation system for agricultural market reports.&amp;quot;.</title>
<date>1988</date>
<booktitle>Proc. of the 12th International Conference on Computational Linguistics - COLING&apos;88,</booktitle>
<location>Budapest.</location>
<marker>[Isabelle et al. 88]</marker>
<rawString>Pierre Isabelle, Marc Dymetman and Eliot Macklovitch. &amp;quot;CRITTER: a translation system for agricultural market reports.&amp;quot;. Proc. of the 12th International Conference on Computational Linguistics - COLING&apos;88, August 1988, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>Grammatical relations in attribute-value grammars&amp;quot;.</title>
<date>1987</date>
<booktitle>Proc. of the West Coast Conference on Formal Linguistics, Vol.6,</booktitle>
<location>Stanford,</location>
<marker>[Johnson 87]</marker>
<rawString>Mark Johnson. &amp;quot;Grammatical relations in attribute-value grammars&amp;quot;. Proc. of the West Coast Conference on Formal Linguistics, Vol.6, Stanford, 1987</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplam</author>
<author>Klaus Netter</author>
<author>Jurgen Wedekind</author>
</authors>
<title>Annie Zaenen. &amp;quot;Translation by structural correspondences&amp;quot;.</title>
<date>1989</date>
<booktitle>Proc. of the 4th European ACL Conference,</booktitle>
<location>Manchester,</location>
<marker>[Kaplan et al. 89]</marker>
<rawString>Ronald M. Kaplam, Klaus Netter, Jurgen Wedekind, Annie Zaenen. &amp;quot;Translation by structural correspondences&amp;quot;. Proc. of the 4th European ACL Conference, Manchester, 1989.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jan Willem Klop</author>
</authors>
<title>Term rewriting systems&amp;quot;.</title>
<booktitle>Handbook of Logic in Computer Science, Vol.1,</booktitle>
<publisher>University Press.</publisher>
<location>Oxford</location>
<note>To appear in</note>
<marker>[Klop 90]</marker>
<rawString>Jan Willem Klop. &amp;quot;Term rewriting systems&amp;quot;. To appear in S. Abramsky, D. Gabbay and T. Maibaum. Handbook of Logic in Computer Science, Vol.1, Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Newman</author>
</authors>
<title>Towards convenient bidirectional grammar formalisms&amp;quot;.</title>
<date>1990</date>
<booktitle>Proc. of the 13th International Conference on Computational Linguistics - COLING&apos;90,</booktitle>
<location>Helsinki.</location>
<marker>[Newman 90]</marker>
<rawString>P. Newman. &amp;quot;Towards convenient bidirectional grammar formalisms&amp;quot;. Proc. of the 13th International Conference on Computational Linguistics - COLING&apos;90, August 1990, Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>David Warren</author>
</authors>
<title>Parsing as deduction&amp;quot;.</title>
<date>1983</date>
<booktitle>Proc. of the 21st Annual Meeting of the ACL,</booktitle>
<pages>15--17</pages>
<location>Cambridge, MA.</location>
<marker>[Pereira/Warren 83]</marker>
<rawString>Fernando C.N. Pereira and David Warren. &amp;quot;Parsing as deduction&amp;quot;. Proc. of the 21st Annual Meeting of the ACL, 15-17 June 1983, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<title>Information-Based Syntax and Semantics.</title>
<date>1987</date>
<booktitle>CSLI Lecture Notes 13,</booktitle>
<publisher>Chicago University Press,</publisher>
<marker>[Pollard/Sag 87]</marker>
<rawString>Carl Pollard and Ivan A. Sag. Information-Based Syntax and Semantics. CSLI Lecture Notes 13, Chicago University Press, 1987.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Carl Pollard</author>
<author>Drew Moshier</author>
</authors>
<title>Unifiying partial descriptions of sets&amp;quot;.</title>
<booktitle>Information, Language and Cognition, Vancouver Studies in Cognitive Science 1, University of British</booktitle>
<editor>In P. Hanson (ed.)</editor>
<publisher>Columbia Press,</publisher>
<location>Vancouver.</location>
<marker>[Pollard/Moshier 89]</marker>
<rawString>Carl Pollard and Drew Moshier. &amp;quot;Unifiying partial descriptions of sets&amp;quot;. In P. Hanson (ed.) Information, Language and Cognition, Vancouver Studies in Cognitive Science 1, University of British Columbia Press, Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Reape</author>
</authors>
<title>Parsing semi-free word order and bounded discontinuous constituency and &amp;quot;shake &apos;n&apos; bake&amp;quot; machine translation (or &apos;generation as parsing&apos;)&amp;quot;. Presented at the International Workshop on Constraint Based Formalisms for Natural Language Generation,</title>
<date>1990</date>
<location>Bad Teinach, Germany,</location>
<marker>[Reape 90]</marker>
<rawString>Mike Reape. &amp;quot;Parsing semi-free word order and bounded discontinuous constituency and &amp;quot;shake &apos;n&apos; bake&amp;quot; machine translation (or &apos;generation as parsing&apos;)&amp;quot;. Presented at the International Workshop on Constraint Based Formalisms for Natural Language Generation, Bad Teinach, Germany, November 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Russell</author>
<author>Susan Warwick</author>
<author>John Carroll</author>
</authors>
<title>Asymmetry in parsing and generation with unification grammars: case studies from ELU&amp;quot;.</title>
<date>1990</date>
<booktitle>Proc. of the 28th Annual Meeting of the ACL,</booktitle>
<pages>6--9</pages>
<location>Pittsburgh.</location>
<marker>[Russell et al. 90]</marker>
<rawString>Graham Russell, Susan Warwick and John Carroll. &amp;quot;Asymmetry in parsing and generation with unification grammars: case studies from ELU&amp;quot;. Proc. of the 28th Annual Meeting of the ACL, 6-9 June 1990, Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
</authors>
<title>An Introduction to Unification-based Grammar Formalisms.</title>
<date>1986</date>
<journal>CSLI Lectures Notes</journal>
<volume>4</volume>
<publisher>Chicago University Press,</publisher>
<marker>[Shieber 86]</marker>
<rawString>Stuart Shieber. An Introduction to Unification-based Grammar Formalisms. CSLI Lectures Notes 4, Chicago University Press, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
</authors>
<title>A uniform architecture for parsing and generation&amp;quot;.</title>
<date>1988</date>
<booktitle>Proc. of the 12th International Conference on Computational Linguistics -COLING&apos;88,</booktitle>
<location>Budapest.</location>
<marker>[Shieber 88]</marker>
<rawString>Stuart Shieber. &amp;quot;A uniform architecture for parsing and generation&amp;quot;. Proc. of the 12th International Conference on Computational Linguistics -COLING&apos;88, August 1988, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
<author>Gertjan van Noord</author>
<author>Robert Moore</author>
<author>Fernando Pereira</author>
</authors>
<title>A uniform architecture for parsing and generation&amp;quot;.</title>
<date>1989</date>
<booktitle>Proc. of the 27th Annual Meeting of the ACL,</booktitle>
<pages>26--27</pages>
<location>Vancouver.</location>
<marker>[Shieber et al. 89]</marker>
<rawString>Stuart Shieber, Gertjan van Noord, Robert Moore and Fernando Pereira. &amp;quot;A uniform architecture for parsing and generation&amp;quot;. Proc. of the 27th Annual Meeting of the ACL, 26-27 June 1989, Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomek Strzalkowski</author>
</authors>
<title>How to invert a natural language parser into an efficient generator: an algorithm for logic grammars&amp;quot;.</title>
<date>1990</date>
<booktitle>Proc. of the 13th International Conference on Computational Linguistics - COLING&apos;90,</booktitle>
<location>Helsinki.</location>
<marker>[Strzalkowski 90]</marker>
<rawString>Tomek Strzalkowski. &amp;quot;How to invert a natural language parser into an efficient generator: an algorithm for logic grammars&amp;quot;. Proc. of the 13th International Conference on Computational Linguistics - COLING&apos;90, August 1990, Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P van Hentenryck</author>
<author>M Dincbas</author>
</authors>
<title>Forward checking in logic programming&amp;quot;.</title>
<date>1987</date>
<booktitle>Proc. of the Ph International Conference on Logic Programming,</booktitle>
<location>Melbourne,</location>
<marker>[van Hentenryck/Dincbas 87]</marker>
<rawString>P. van Hentenryck and M. Dincbas. &amp;quot;Forward checking in logic programming&amp;quot;. Proc. of the Ph International Conference on Logic Programming, Melbourne, May 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
</authors>
<title>Reversible unification based machine translation&amp;quot;.</title>
<date>1990</date>
<booktitle>Proc. of the 13th International Conference on Computational Linguistics - COLING&apos;90,</booktitle>
<location>Helsinki.</location>
<marker>[van Noord 90]</marker>
<rawString>Gertjan van Noord. &amp;quot;Reversible unification based machine translation&amp;quot;. Proc. of the 13th International Conference on Computational Linguistics - COLING&apos;90, August 1990, Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jürgen Wedekind</author>
</authors>
<title>Generation as structure driven generation&amp;quot;.</title>
<date>1988</date>
<booktitle>Proc. of the 12th International Conference on Computational Linguistics -COLING &apos;88,</booktitle>
<location>Budapest.</location>
<marker>[Wedekind 88]</marker>
<rawString>Jürgen Wedekind. &amp;quot;Generation as structure driven generation&amp;quot;. Proc. of the 12th International Conference on Computational Linguistics -COLING &apos;88, August 1988, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remi Zajac</author>
</authors>
<title>A transfer model using a typed feature structure rewriting system with inheritance&amp;quot;.</title>
<date>1989</date>
<booktitle>Proc. of the 27th Annual Meeting of the ACL,</booktitle>
<pages>26--27</pages>
<location>Vancouver.</location>
<marker>[Zajac 89]</marker>
<rawString>Remi Zajac. &amp;quot;A transfer model using a typed feature structure rewriting system with inheritance&amp;quot;. Proc. of the 27th Annual Meeting of the ACL, 26-27 June 1989, Vancouver.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remi Zajac</author>
</authors>
<title>A relational approach to translation&amp;quot;.</title>
<date>1990</date>
<booktitle>Proc. of the 3rd International Conference on Theoretical and Methodological Issues in Machine Translation of Natural Language,</booktitle>
<pages>11--13</pages>
<location>Austin.</location>
<marker>[Zajac 90a]</marker>
<rawString>Remi Zajac. &amp;quot;A relational approach to translation&amp;quot;. Proc. of the 3rd International Conference on Theoretical and Methodological Issues in Machine Translation of Natural Language, 11-13 June 1990, Austin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remi Zajac</author>
</authors>
<title>Computing partial information using approximations - Semantics of typed feature structures&amp;quot;. Presented at the International Workshop on Constraint Based Formalisms for Natural Language Generation,</title>
<date>1990</date>
<location>Bad Teinach, Germany,</location>
<marker>[Zajac 90b]</marker>
<rawString>Remi Zajac. &amp;quot;Computing partial information using approximations - Semantics of typed feature structures&amp;quot;. Presented at the International Workshop on Constraint Based Formalisms for Natural Language Generation, Bad Teinach, Germany, November 1990.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>