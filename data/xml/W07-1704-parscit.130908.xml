<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.990649">
Lemmatization of Polish Person Names
</title>
<author confidence="0.798368">
Jakub Piskorski
</author>
<affiliation confidence="0.6745065">
European Commission
Joint Research Centre
</affiliation>
<address confidence="0.8275795">
Via Fermi 1
21020 Ispra, Italy
</address>
<email confidence="0.990428">
Jakub.Piskorski@jrc.it
</email>
<author confidence="0.972685">
Marcin Sydow
</author>
<affiliation confidence="0.9072055">
Polish-Japanese Institute
of Information Technology
</affiliation>
<address confidence="0.870287">
Koszykowa 86
02-008 Warsaw, Poland
</address>
<email confidence="0.994448">
msyd@pjwstk.edu.pl
</email>
<author confidence="0.464423">
Anna Kup´s´c
</author>
<address confidence="0.5351135">
Université Paris3/LLF, PAS ICS
Case Postale 7031
2, place Jussieu
75251 Paris Cedex 05
</address>
<email confidence="0.883217">
akupsc@univ-paris3.fr
</email>
<sectionHeader confidence="0.993025" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999871888888889">
The paper presents two techniques for
lemmatization of Polish person names. First,
we apply a rule-based approach which re-
lies on linguistic information and heuris-
tics. Then, we investigate an alterna-
tive knowledge-poor method which employs
string distance measures. We provide an
evaluation of the adopted techniques using
a set of newspaper texts.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999980055555556">
Proper names constitute a significant part of natural
language texts (estimated to about 10% in newspa-
per articles) and are important for NLP applications,
such as Information Extraction, which rely on au-
tomatic text understanding.1 In particular, corefer-
ence resolution (e.g., identifying several name vari-
ants as referring to the same entity) plays a crucial
role in such systems. Although automatic recogni-
tion of proper names in English, French and other
major languages has been in the research focus for
over a decade now, cf. (Bikel et al., 1997), (Borth-
wick, 1999), (Li et al., 2003), only a few efforts have
been reported for Slavic languages, cf. (Cunning-
ham et al., 2003) (Russian and Bulgarian), (Pisko-
rski, 2005) (Polish). Rich inflection and a more re-
laxed word order make recognition of proper names
in Slavic more difficult than for other languages.
Moreover, inflection of proper names is usually
</bodyText>
<footnote confidence="0.997537333333333">
1The research presented in this paper was partially founded
by the Ministry of Education and Science (Poland), grant num-
ber 3T11C00727.
</footnote>
<page confidence="0.994569">
27
</page>
<bodyText confidence="0.999938090909091">
quite different from common nouns, which compli-
cates the lemmatization process necessary for cor-
rect coreference resolution. In this paper, we focus
on lemmatization of Polish person names, the most
idiosyncratic class of proper names in this language.
First, we report results of a rule-based symbolic ap-
proach. We apply different heuristics, mostly based
on the internal (morphological and syntactic) struc-
ture of proper names but also on the surrounding
context. Sometimes, however, the required infor-
mation is not available, even if the entire docu-
ment is considered, and lemmatization cannot be
performed. Therefore, we experimented with var-
ious knowledge-poor methods, namely string dis-
tance metrics, in order to test their usefulness for
lemmatization of Polish person names as an alterna-
tive technique, especially for cases where document-
level heuristics are insufficient.
Lemmatization of proper names in Slavic has not
attracted much attention so far but some work has
been done for Slovene: (Erjavec et al., 2004) present
a machine-learning approach to lemmatization of
unknown single-token words, whereas (Pouliquen et
al., 2005) report on a shallow approach to find base
forms.
The organization of the paper is as follows. First,
we present a description of phenomena which make
lemmatization of Polish person names a difficult
task. Next, a rule-based approach and its evaluation
are presented. Then, various string distance metrics
are introduced, followed by the results of experi-
ments on newspaper texts. The final section presents
conclusions and perspectives for future work.
</bodyText>
<subsubsectionHeader confidence="0.621136">
Balto-Slavonic Natural Language Processing 2007, June 29, 2007, pages 27–34,
</subsubsectionHeader>
<bodyText confidence="0.36486">
Prague, June 2007. c�2007 Association for Computational Linguistics
</bodyText>
<note confidence="0.390007875">
case male name female name
nom Kazimierz Polak Kazimiera Polak
gen Kazimierza Polaka Kazimiery Polak
dat Kazimierzowi Polakowi Kazimierze Polak
acc Kazimierza Polaka Kazimier˛e Polak
ins Kazimierzem Polakiem Kazimiera˛ Polak
loc Kazimierzu Polaku Kazimierze Polak
voc Kazimierzu Polaku Kazimiero Polak
</note>
<tableCaption confidence="0.997827">
Table 1: Declension of Polish male vs. female names
</tableCaption>
<table confidence="0.996995375">
case sg pl sg pl
nom goł ˛ab goł˛ebie Goł ˛ab Goł ˛abowie
gen goł˛ebia goł˛ebi Goł ˛aba Goł ˛ab6w
dat goł˛ebiowi goł˛ebiom Goł ˛abowi Goł ˛abom
acc goł˛ebia goł˛ebie Goł ˛aba Goł ˛ab6w
ins goł˛ebiem goł˛ebiami Goł ˛abem Goł ˛abami
loc goł˛ebia goł˛ebie Goł ˛abiu Goł ˛abach
voc goł˛ebiu goł˛ebie Goł ˛ab Goł ˛abowie
</table>
<tableCaption confidence="0.999597">
Table 2: Common noun vs. person name inflection
</tableCaption>
<sectionHeader confidence="0.8673365" genericHeader="method">
2 Declension Patterns of Polish Person
Names
</sectionHeader>
<bodyText confidence="0.999543721311475">
Polish is a West Slavic language with rich nomi-
nal inflection: nouns and adjectives are inflected for
case, number and gender. There are 7 cases, 2 num-
bers and traditionally 3 genders are distinguished:
masculine, feminine and neuter. Just like common
nouns, Polish person names undergo declension but
their inflectional patterns are more complicated. A
typical Polish name consists of a first name and a
last name; unlike in Russian or Bulgarian, there are
no patronymics. Additionally, titles (e.g., dr ‘Phd’,
in˙z. ‘engineer’, prof. ‘professor’) or honorific forms
(pan ‘Mr.’ or pani ‘Mrs./Miss’) are often used. In
general, both the first and the last name can be in-
flected, e.g., Jan Kowalski (nominative) vs. Jana
Kowalskiego (genitive/accusative). If the surname
is also a regular word form, things get more compli-
cated. Whether the last name can be inflected in such
cases depends on several factors, e.g., on the gen-
der of the first name, a category (part-of-speech) and
gender of the (common) word used as a surname.
For instance, if the surname is a masculine noun, it
is inflected only if the first name is also masculine.
This is illustrated in Table 1 with declension of the
male name Kazimierz Polak ‘Casimir Pole’ and its
variant with the female first name Kazimiera.
If the surname is an adjective (e.g., Niski ‘Short’),
it is inflected (according to the adjectival paradigm)
and agrees in gender with the first name, i.e., male
and female last name forms are different (e.g., Niski
‘Short’ (masc.) vs. Niska ‘Short’ (fem.)). The de-
clension of foreign surnames may strongly depend
on their origin, and in particular on the pronuncia-
tion. For example, the name Wilde is pronounced
differently in English and German, which impacts
its declension in Polish. If it’s of English origin, a
nominal declension is applied, i.e., Wilde’a (gen.),
whereas if it comes from German, an adjective-like
declension is adopted: Wildego (gen.).
Declension of surnames which are also common
nouns can be different from the declension of com-
mon nouns.2 In Table 2, we present a comparison
of the common noun goł ˛ab ‘dove’ in singular and
plural with the corresponding forms used for the
surname. A comprehensive overview of this rather
intriguing declension paradigm of Polish names is
given in (Grzenia, 1998).
Finally, first name forms present problems as
well. Foreign masculine first names, whose pro-
nounced version ends in a consonant or whose writ-
ten version ends in -a, -o, -y or -i do in general
get inflected (e.g., Jacques (nom.) vs. Jacques’a
(gen./acc.)), whereas names whose pronounced ver-
sion ends in a vowel and are stressed on the last syl-
lable (e.g., François) usually do not change form.
For female first names created from a male first
name, e.g., J6zef (masc.) vs. J6zefa (fem.), there is
a frequent homonymy between the nominative form
of the female name and the genitive/accusative form
of the corresponding male form, e.g., J6zefa is no-
minative of J6zefa (fem.) and genitive/accusative of
J6zef (masc.).
</bodyText>
<sectionHeader confidence="0.9951595" genericHeader="method">
3 Rule-Based Approach to Person Name
Lemmatization
</sectionHeader>
<subsectionHeader confidence="0.999537">
3.1 Experiment
</subsectionHeader>
<bodyText confidence="0.999960333333333">
Our rule-based approach to person name lemmatiza-
tion exploits existing resources (a dictionary of first
names and contextual triggers) and relies on con-
textual information (heuristics). It has been imple-
mented using SProUT, a shallow processing plat-
form, integrated with a Polish morphological anal-
</bodyText>
<footnote confidence="0.978292666666667">
2The declension of such surnames depends on the local tra-
dition and sometimes can be identical with the pattern used for
common nouns.
</footnote>
<page confidence="0.999385">
28
</page>
<bodyText confidence="0.999968272727273">
yser (Piskorski et al., 2004). For first names, all in-
flected forms of the most frequent Polish first names
are stored in a database so a simple gazetteer look-up
associates names with the corresponding base form.
We also used a list of ca 30 000 foreign first names
(nominative forms). For last names, we applied sev-
eral heuristic rules in order to recognize and produce
their base forms. First, we identify most common
types of Polish surnames, e.g., capitalized words
ending in -skiego, -skim, -skiemu or -icza, -iczem, -
iczu (typical last name suffixes), and convert them to
the corresponding base forms (i.e., words ending in
-ski and -icz, respectively). In this way, a significant
number of names can be lemmatized in a brute-force
manner.
For all remaining surnames, more sophisticated
rules have to be applied. As discussed in sec. 2,
these rules have to take into account several pieces
of information such as part-of-speech and gender
of the (common) word which serves as a surname,
but also gender of the first name. The major prob-
lem we encountered while applying these rules is
that the information necessary to trigger the appro-
priate rule is often missing. For example, in sen-
tence (1), inferring gender of the surname/first name
could involve a subcategorization frame for the verb
powiadomi´c ‘inform’, which requires an accusative
NP argument. In this way we might possibly predict
that the base form of Putina is Putin, as -a is the typi-
cal accusative ending of masculine names. Since the
subcategorization lexicon is not available, such in-
stances are either not covered or different heuristics
are employed for guessing the base form.
</bodyText>
<listItem confidence="0.420751">
(1) Powiadomiono wczoraj wieczorem V. Putina o
</listItem>
<bodyText confidence="0.975278884615385">
informed yesterday evening V. Putinacc about
ataku.
attack
‘Yesterday evening they informed V. Putin about the at-
tack.’
Additionally, grammar rules may produce vari-
ants of recognized full person names. For exam-
ple, for the full name CEO dr Jan Kowalski the fol-
lowing variants can be produced: Kowalski, CEO
Kowalski, dr Kowalski, etc. As the grammar rules
always return the longest match, a shorter form may
not be recognized. The produced variants are there-
fore used in the second pass through the text in order
to identify ‘incomplete’ forms. As no morphological
generation is involved, only base forms can be iden-
tified in this way. The system evaluation indicates
that 23.8% of the recognized names were identified
by this partial coreference resolution mechanism.
An analysis of incorrectly recognized named en-
tities (NEs) revealed that major problems concerned
(a) classical ambiguities, such as a proper name
vs. a common word, and (b) person vs. organiza-
tion name, caused by a specific word order and a
structural ambiguity of phrases containing NEs. Let
us consider the following examples to illustrate the
problems.
</bodyText>
<figure confidence="0.731984272727273">
(2) Dane Federalnego Urz˛edu Statystycznego
Datanom federalgen officegen statisticalgen
‘Data of the federal office for statistics’
(3) prezes Della
presidentnom Dellgen
‘president of Dell’
(4) kanclerz Austriak6w
chancellornom Austriansgen
‘chancellor of the Austrians’
(5) ... powiedział prezes sp6łki Kruk
said presidentnom companygen Kruknom
</figure>
<bodyText confidence="0.97170276">
‘. .. said the president of Kruk company / Kruk, the pre-
sident of the company’
The text fragment Dane Federalnego in (2) is rec-
ognized by the grammar as a person name since
Dane is a gazetteer entry for a foreign (English) first
name. Consequently, Federalnego Urz˛edu Statys-
tycznego could not be recognized as an organization
name. Potentially, heuristics solving such NE over-
lapping collisions could improve the precision. Sim-
ilar techniques have been applied to other languages.
In (3) and (4) the names Della ‘of Dell’ and Austri-
ak6w ‘of Austrians’ were erroneously recognized as
surnames. The rule matching a token representing
a title followed by a capitalized word, adopted for
English person names, is less reliable for Polish due
to declension of proper names and lack of prepo-
sitions in genitive constructions. One solution to
this problem would involve matching Della and Aus-
triak6w with their base forms (Dell and Austriacy,
resp.), which might appear in the immediate con-
text. In this way, the name type could be validated.
However, a corpus inspection revealed that quite fre-
quently no base form appears in the same document.
The last example, (5), illustrates another problem,
which is even harder to solve. The phrase prezes
</bodyText>
<page confidence="0.991674">
29
</page>
<bodyText confidence="0.999578111111111">
spółki Kruk is structurally ambiguous, i.e., it can
be bracketed as [prezes [spółki Kruk]] or [[prezes
spółki] Kruk]. Consequently, the name Kruk might
either refer to a company name (‘...said the pre-
sident of the Kruk company’) or to a person name
(‘... said Kruk, the president of the company’). In-
ferring the proper interpretation might not be possi-
ble even if we consider the subcategorization frame
of the verb powiedzie´c ‘to say’.
</bodyText>
<subsectionHeader confidence="0.994234">
3.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.907321571428571">
For evaluation of recognition and lemmatization of
person names, a set of 30 articles on various top-
ics (politics, finance, sports, culture and science) has
been randomly chosen from Rzeczpospolita (Weiss,
2007), a leading Polish newspaper. The total num-
ber of person name occurrences in this document set
amounts to 858. Evaluation of recognition’s preci-
sion and recall yielded 88.6% and 82.6%, respec-
tively. Precision of lemmatization of first names
and surnames achieved 92.2% and 75.6%, respec-
tively. For 12.4% of the recognized person names
more than one output structure was returned. For in-
stance, in case of the person name Marka Belki, the
first name Marka is interpreted by the gazetteer ei-
ther as an accusative form of the male name Marek
or as a nominative form of a foreign female name
Marka. In fact, 10% of the Polish first-name forms
in our gazetteer are ambiguous with respect to gen-
der. As for the last name Belki, it is a genitive form
of the common Polish noun belka ‘beam’, so the
base form can be obtained directly. Nevertheless,
as inflection of proper names differs from that of
common nouns, various combinations of the regular
noun Belka and the special proper name form Belki
are possible, which increases ambiguity of the iden-
tified form. All possible lemmatizations are as fol-
lows:
(6) Marek Belka (masc.),
Marka Belka (fem.),
Marek Belki (masc.),
Marka Belki (fem.)
A good heuristics to reduce such ambiguous
lemmatizations is to prioritize rules which refer to
morphological information over those which rely
solely on orthography and/or token types.
</bodyText>
<sectionHeader confidence="0.444627" genericHeader="method">
4 Application of String Distance Metrics
</sectionHeader>
<subsectionHeader confidence="0.516119">
for Lemmatization
</subsectionHeader>
<bodyText confidence="0.984081272727273">
Since knowledge-based lemmatization of Polish
NEs is extremely hard, we also explored a possibil-
ity of using string distance metrics for matching in-
flected person names with their base forms (and their
variants) in a collection of document, rather than
within a single document. The rest of this section de-
scribes our experiments in using different string dis-
tance metrics for this task, inspired by the work pre-
sented in (Cohen et al., 2003) and (Christen, 2006).
The problem can be formally defined as follows.
Let A, B and C be three sets of strings over some
alphabet E, with B C_ C. Further, let f : A —* B
be a function representing a mapping of inflected
forms (A) into their corresponding base forms (B).
Given, A and C (the search space), the task is to con-
struct an approximation of f, namely f : _A —* C.
_ f returns
f is said to re-
turn an incorrect answer. For another task, a multi-
result experiment, we construct an approximation
f* : A —* 2c, where f* returns the correct answer
for a if f(a) E f*(a).
</bodyText>
<subsectionHeader confidence="0.998171">
4.1 String distance metrics
</subsectionHeader>
<bodyText confidence="0.999926611111111">
In our experiments, we have explored mainly
character-level string metrics3 applied by the
database community for record linkage.
Our point of departure is the well-known Lev-
enshtein edit distance metric specified as the min-
imum number of character-level operations (inser-
tion, deletion or substitution) required for trans-
forming one string into another (Levenshtein, 1965)
and bag distance metric (Bartolini et al., 2002)
which is a time-efficient approximation of the Lev-
enshtein metric. Next, we have tested the Smith-
Waterman (Smith and Waterman, 1981) metric,
which is an extension of Levenshtein metric and al-
low a variable cost adjustment to edit operations and
an alphabet mapping to costs.
Another group of string metrics we explored is
based on a comparison of character-level n-grams in
two strings. The q-gram metric (Ukkonen, 1992) is
</bodyText>
<footnote confidence="0.964229666666667">
3Distance (similarity) metrics map a pair of strings s and t
to a real number r, where a smaller (larger) value of r indicates
greater (lower) similarity.
</footnote>
<table confidence="0.8232">
If _f(a) = f(a) for a E A, we say that
the correct answer for a; otherwise,
</table>
<page confidence="0.986046">
30
</page>
<bodyText confidence="0.988397174603175">
computed by counting the number of q-grams con-
tained in both strings. An extension to q-grams is
to add positional information, and to match only
common q-grams that occur at a specified distance
from each other (positional q-grams) (Gravano et
al., 2001). Finally, the skip-gram metric (Keskustalo
et al., 2003) is based on the idea that in addition
to forming bigrams of adjacent characters, bigrams
that skip characters are considered as well. Gram
classes are defined that specify what kind of skip-
grams are created, e.g. 10, 11 class means that regu-
lar bigrams (0 characters skipped) and bigrams that
skip one character are formed. We have explored
10, 11, 10, 21 and 10, 1, 21 gram classes.
Taking into account the Polish declension
paradigm, we also added a basic metric based on the
longest common prefix, calculated as follows:
CPδ(s, t) = ((|lcp(s, t) |+ 6)/(|s |· |t|),
where lcp(s, t) denotes the longest common prefix
for s and t. The symbol 6 is a parameter for favoring
certain suffix pairs in s (t). We have experimented
with two variants: CPδ, with 6 = 0 and CPδ.,
where 6 is set to 1 if s ends in: o, y, ˛a, ˛e, and t ends
in an a, or 0 otherwise. The latter setting results
from empirical study of the data and the declension
paradigm.
For coping with multi-token strings, we tested
a similar metric called longest common substrings
(LCS) (Christen, 2006), which recursively finds and
removes the longest common substring in the two
strings compared, up to a specified minimum length.
Its value is calculated as the ratio of the sum of all
found longest common substrings to the length of
the longer string. We extended LCS by additional
weighting the lengths of the longest common sub-
strings. The main idea is to penalize the longest
common substrings which do not match the begin-
ning of a token in at least one of the compared
strings. In such cases, the weight for lcs(s, t) (the
longest common substring for s and t) is computed
as follows. Let α denote the maximum number of
non-whitespace characters which precede the first
occurrence of lcs(s, t) in s or t. Then, lcs(s, t) is
assigned the weight:
where p has been experimentally set to 4. We refer
to the ‘weighted’ variant of LCS as W LCS.
Good results for name-matching tasks (Cohen et
al., 2003) have been reported using the Jaro metric
and its variant, the Jaro-Winkler (JW) metric (Win-
kler, 1999). These metrics are based on the num-
ber and order of common characters in two com-
pared strings. We have extended the Jaro-Winkler
metric to improve the comparison of multi-token
strings. We call this modification JWM and it can
be briefly characterized as follows. Let J(s, t) de-
note the value of the Jaro metric for s and t. Then,
let s = s ... sK and t = t ... tL, where si (ti) rep-
resent i-th token of s and t respectively, and assume,
without loss of generality, L G K. JWM(s, t) is
defined as:
JWM(s, t) = J(s, t)+6·boostp(s, t)·(1−J(s, t))
where 6 denotes the common prefix adjustment fac-
tor and boostp is calculated as follows:
</bodyText>
<equation confidence="0.9730215">
i
boostp(s, t) = L ·L Z  min(|lcp(si, ti)|, p)+
min(|lcp(sL, tL..tK)|, p)
L
</equation>
<bodyText confidence="0.999930958333333">
The main idea behind JWM is to boost the Jaro
similarity for strings with the highest number of
agreeing initial characters in the corresponding to-
kens in the compared strings.
Finally, for multi-token strings, we tested a recur-
sive matching pattern, known also as Monge-Elkan
distance (Monge and Elkan, 1996). The intuition be-
hind this measure is the assumption that a token in
s (strings are treated as sequences of tokens) corre-
sponds to a token in t which has the highest num-
ber of agreeing characters. The similarity between
s and t is the mean of these maximum scores. Two
further metrics for multi-token strings were investi-
gated, namely Sorted-Tokens and Permuted-Tokens.
The first one is computed in two steps: (a) first, to-
kens forming a full string are sorted alphabetically,
and then (b) an arbitrary metric is applied to com-
pute the similarity for the ‘sorted’ strings. The latter
compares all possible permutations of tokens form-
ing the full strings and returns the calculated maxi-
mal similarity value.
A detailed description of string metrics used here
is given in (Christen, 2006) and in (Piskorski et al.,
2007).
</bodyText>
<equation confidence="0.9994045">
wlcs(s,t) = |lcs(s, t) |+ α
|lcs(s, t) |+ α − max(α, p)
</equation>
<page confidence="0.999186">
31
</page>
<subsectionHeader confidence="0.997396">
4.2 Test Data
</subsectionHeader>
<bodyText confidence="0.998695363636363">
For the experiments on coreference of person names,
we used two resources: (a) a lexicon of the most
frequent Polish first names (PL-F(IRST)-NAMES)
consisting of pairs of an inflected form and the cor-
responding base form, and (b) an analogous lexicon
of inflected full person names (first name + surname)
(PL-FULL-NAMES).4 The latter resource was cre-
ated semi-automatically as follows. We have auto-
matically extracted a list of 22485 full person-name
candidates from a corpus of 15724 on-line news ar-
ticles from Rzeczpospolita by using PL-F-NAMES
lexicon and an additional list of 30000 uninflected
foreign first names. Subsequently, we have ran-
domly selected a subset of about 1900 entries (in-
flected forms) from this list.
In basic experiments, we simply used the base
forms as the search space. Moreover, we produced
variants of PL-F-NAMES and PL-FULL-NAMES
by adding to the search space base forms of for-
eign first names and a complete list of full names ex-
tracted from the Rzeczpospolita corpus, respectively.
Table 3 gives an overview of our test datasets.
</bodyText>
<table confidence="0.598466333333333">
Dataset #inflected #base search space
PL-F-NAMES 5941 1457 1457
PL-F-NAMES-2 5941 1457 25490
PL-FULL-NAMES 1900 1219 1219
PL-FULL-NAMES-2 1900 1219 2351
PL-FULL-NAMES-3 1900 1219 20000
</table>
<bodyText confidence="0.999163222222222">
Let s denote the number of strings for which a sin-
gle result (base form) was returned. Analogously,
m is the number of strings for which more than
one result was returned. Let s, and m, denote, re-
spectively, the number of correct single-result an-
swers returned and the number of multi-result an-
swers containing at least one correct result. The ac-
curacy metrics are computed as: AA = s,/(s + m),
SR = s,/s, and RAA = (s, + m,)/(s + m).
</bodyText>
<subsectionHeader confidence="0.98245">
4.4 Experiments
</subsectionHeader>
<bodyText confidence="0.999976285714286">
We started our experiments with the PL-F-NAME
dataset and applied all but the multi-token strings
distance metrics. The results of the accuracy eval-
uation are given in Table 4. The first three columns
give the accuracy figures, whereas the column la-
beled AV gives an average number of results re-
turned in the answer set.
</bodyText>
<subsectionHeader confidence="0.413876">
Metrics AA SR RAA AV
</subsectionHeader>
<table confidence="0.99994125">
Bag Distance 0.476 0.841 0.876 3.02
Levenshtein 0.708 0.971 0.976 2.08
Smith-Waterman 0.625 0.763 0.786 3.47
Jaro 0.775 0.820 0.826 2.06
Jaro-Winkler 0.820 0.831 0.831 2.03
q-grams 0.714 0.974 0.981 2.09
pos q-grams 0.721 0.976 0.982 2.09
skip grams 0.873 0.935 0.936 2.14
LCS 0.696 0.971 0.977 12.69
WLCS 0.731 0.983 0.986 2.97
CP5, 0.829 0.843 0.844 2.11
CP5, 0.947 0.956 0.955 2.18
</table>
<tableCaption confidence="0.997422">
Table 4: Results for PL-F-NAMES
Table 3: Dataset used for the experiments
</tableCaption>
<subsectionHeader confidence="0.997775">
4.3 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.984221757575757">
Since for a given string more than one answer can be
returned, we measured the accuracy in three ways.
First, we calculated the accuracy on the assumption
that a multi-result answer is incorrect and we defined
all-answer accuracy (AA) measure which penalizes
multi-result answers. Second, we measured the ac-
curacy of single-result answers (single-result accu-
racy (SR)) disregarding the multi-result answers.
Finally, we used a weaker measure which treats a
multi-result answer as correct if one of the results in
the answer set is correct (relaxed-all-answer accu-
racy (RAA)).
4Inflected forms which are identical to their corresponding
base form were excluded from the experiments since finding an
answer for such cases is straightforward.
Interestingly, the simple linguistically-aware
common prefix-based measure turned out to work
best in the AA category, which is the most relevant
one, whereas WLCS metrics is the most accurate in
case of single-result answers and the RAA category.
Thus, a combination of the two seems to be a rea-
sonable solution to further improve the performance
(i.e., if WLCS provides a single answer, return this
answer, otherwise return the answer of CPa,). Next,
the time-efficient skip grams metrics performed sur-
prisingly well in the AA category. This result was
achieved with 10, 21 gram classes. Recall that about
10% of the inflected first name forms in Polish are
ambiguous, as they are either a male or a female per-
son name, see sec. 2.
Clearly, the AA accuracy figures in the experi-
ment run on the PL-F-NAME-2 (with a large search
space) was significantly worse. However, the SR
</bodyText>
<page confidence="0.998186">
32
</page>
<bodyText confidence="0.999748">
accuracy for some of the metrics is still acceptable.
The top ranking metrics with respect to SR and AA
accuracy are given in Table 5. Metrics which return
more than 5 answers on average were excluded from
this list. Also in the case of PL-F-NAME-2 the com-
bination of WLCS and CPa, seems to be the best
choice.
‘recursive’ metrics on PL-FULL-NAMES-2, which
has a larger search space. The most significant re-
sults for the AA accuracy are given in Table 7. The
JWM metric seems to be the best choice as an in-
ternal metric, whereas WLCS, CPa, and Jaro per-
form slightly worse.
</bodyText>
<table confidence="0.9840175">
Internal M. Monge-Elkan Sorted-Tokens Permuted-Tokens
Metrics SR AA
WLCS 0.893 0.469
CPb, 0.879 0.855
pos 2-grams 0.876 0.426
skip grams 0.822 0.567
2-grams 0.810 0.398
LCS 0.768 0.340
CPb, 0.668 0.600
JW 0.620 0.560
</table>
<tableCaption confidence="0.999017">
Table 5: Top results for PL-F-NAMES-2
</tableCaption>
<bodyText confidence="0.9999754">
Finally, we have made experiments for full per-
son names, each represented as two tokens. It is
important to note that the order of the first name
and the surname in some of the entities in our test
datasets is swapped. This inaccuracy is introduced
by full names where the surname may also function
as a first name. Nevertheless, the results of the ex-
periment on PL-FULL-NAMES given in Table 6 are
nearly optimal. JWM, WLCS, LCS, skip grams
and Smith-Waterman were among the ‘best’ metrics.
</bodyText>
<table confidence="0.946573166666667">
Internal Metrics AA SR RAA AV
Bag Distance 0.891 0.966 0.966 3.13
Smith-Waterman 0,965 0,980 0,975 3,5
Levenshtein 0.951 0.978 0.970 4.59
Jaro 0.957 0.970 0.964 3.54
JW 0.952 0.964 0.958 3.74
JWM 0.962 0.974 0.968 3.74
2-grams 0.957 0.988 0.987 3.915
pos 3-grams 0.941 0.974 0.966 4.32
skip-grams 0.973 0.991 0.990 5.14
LCS 0.971 0.992 0.990 5.7
WLCS 0.975 0.993 0.992 6.29
</table>
<tableCaption confidence="0.985884">
Table 6: Results for PL-FULL-NAMES
</tableCaption>
<bodyText confidence="0.9991569">
The Monge-Elkan, Sorted-Tokens and Permuted-
Tokens scored in general only slightly better than the
basic metrics. The best results oscillating around
0.97, 0.99, and 0.99 for the three accuracy metrics
were obtained using LCS, WLCS, JWM and CPa
metrics as internal metrics. The highest score was
achieved by applying Sorted-Tokens with JWM with
0.976 in AA accuracy.
Further, in order to get a better picture, we have
compared the performance of the aforementioned
</bodyText>
<table confidence="0.999521454545454">
Bag Distance 0.868 0.745 0.745
Jaro 0.974 0.961 0.968
JWM 0.976 0.976 0.975
SmithWaterman 0.902 0.972 0.967
3-grams 0.848 0.930 0.911
pos 3-grams 0.855 0.928 0.913
skip-grams 0.951 0.967 0.961
LCS 0.941 0.960 0.951
WLCS 0.962 0.967 0.967
CPb, 0.969 n.a. n.a.
CPb, 0.974 n.a. n.a.
</table>
<tableCaption confidence="0.998871">
Table 7: AA accuracy for PL-FULL-NAMES-2
</tableCaption>
<bodyText confidence="0.9853922">
In our last experiment we selected the ‘best’
metrics so far and tested them against PL-FULL-
NAMES-3 (largest search space). The top results for
non-recursive metrics are given in Table 8. JWM
and WLCS turned out to achieve the best scores.
</bodyText>
<table confidence="0.923385875">
Metrics AA SR RAA AV
Levenshtein 0.791 0.896 0.897 2.20
Smith-Waterman 0.869 0.892 0.889 2.35
JW 0.791 0.807 0.802 2.11
JWM 0.892 0.900 0.901 2.11
skip-grams 0.852 0.906 0.912 2.04
LCS 0.827 0.925 0.930 2.48
WLCS 0.876 0.955 0.958 2.47
</table>
<tableCaption confidence="0.995555">
Table 8: Results for PL-FULL-NAMES-3
</tableCaption>
<bodyText confidence="0.999960777777778">
The top scores achieved for the recursive metrics
on PL-FULL-NAMES-3 were somewhat better. In
particular, Monge-Elkan performed best with CPa,
(0.937 AA and 0.946 SR) and slightly worse re-
sults were obtained with JWM. Sorted-Tokens scored
best in AA and SR accuracy with JWM (0.904) and
WLCS (0.949), respectively. Finally, for Permuted-
Tokens the identical setting yielded the best results,
namely 0.912 and 0.948, respectively.
</bodyText>
<sectionHeader confidence="0.995144" genericHeader="conclusions">
5 Conclusions and Perspectives
</sectionHeader>
<bodyText confidence="0.9994024">
For Slavic languages, rich and idiosyncratic inflec-
tion of proper names presents a serious problem for
lemmatization. In this paper we investigated two
different techniques for finding base forms of per-
son names in Polish. The first one employs heuris-
</bodyText>
<page confidence="0.997012">
33
</page>
<bodyText confidence="0.999984677419355">
tics and linguistic knowledge. This method does
not provide optimal results at the moment as nec-
essary tools and linguistic resources, e.g., a morpho-
logical generator or a subcategorization lexicon, are
still underdeveloped for Polish. Moreover, contex-
tual heuristics do not always find a solution as the
required information might not be present in a sin-
gle document. Therefore, we considered string dis-
tance metrics as an alternative approach. The results
of applying various measures indicate that for first
names, simple common prefix (CP6) metric obtains
the best results for all-answer accuracy, whereas
the weighted longest common substrings (WLC5)
measure provides the best score for the single-result
accuracy. Hence, a combination of these two metrics
seems the most appropriate knowledge-poor tech-
nique for lemmatizing Polish first names. As for full
names, our two modifications (WLC5 and JWM)
of standard distance metrics and CPa obtain good re-
sults as internal metrics for recursive measures and
as stand-alone measures.
Although the results are encouraging, the pre-
sented work should not be considered a final solu-
tion. We plan to experiment with the best scoring
metrics (e.g., for AA and SR) in order to find opti-
mal figures. Additionally, we consider combining
the two techniques. For example, string distance
metrics can be used for validation of names found
in the context. We also envisage applying the same
methods to other types of proper names as well as to
lemmatization of specialized terminology.
</bodyText>
<sectionHeader confidence="0.999279" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999935764705883">
I. Bartolini, P. Ciacca, and M. Patella. 2002. String matching
with metric trees using an approximate distance. In Proceed-
ings of SPIRE, LNCS 2476, Lisbon, Portugal.
D. Bikel, S. Miller, R. Schwartz, and R. Weischedel. 1997.
Nymble: A High-performance Learning Name-finder. In
Proceedings of ANLP-1997, Washington DC, USA.
A. Borthwick. 1999. A Maximum Entropy Approach to Named
Entity Recognition. PhD Thesis, Department of Computer
Science, New York University.
P. Christen. 2006. A Comparison of Personal Name Matching:
Techniques and Practical Issues. Technical report, TR-CS-
06-02, Computer Science Laboratory, The Australian Na-
tional University, Canberra, Australia.
W. Cohen, P. Ravikumar, and S. Fienberg. 2003. A compar-
ison of string metrics for matching names and records. In
Proceedings of the KDD2003.
H. Cunningham, E. Paskaleva, K. Bontcheva, and G. Angelova.
2003. Information extraction for Slavonic languages. In
Proceedings of the Workshop IESL, Borovets, Bulgaria.
T. Erjavec and S. Džeroski. 2004. Machine Learning of
Morphosyntactic Structure: Lemmatising Unknown Slovene
Words. In Journal of Applied Artificial Intelligence, 18(1),
pages 17-40.
L. Gravano, P. Ipeirotis, H. Jagadish, S. Koudas, N. Muthukrish-
nan, L. Pietarinen, and D. Srivastava. 2001. Using q-grams
in a DBMS for Approximate String Processing. IEEE Data
Engineering Bulletin, 24(4):28–34.
J. Grzenia. 1998. Słownik nazw własnych — ortografia,
wymowa, słowotwórstwo i odmiana. PWN.
H. Keskustalo, A. Pirkola, K. Visala, E. Leppanen, and
K. Jarvelin. 2003. Non-adjacent digrams improve matching
of cross-lingual spelling variants. In Proceedings of SPIRE,
LNCS 22857, Manaus, Brazil, pages 252–265.
V. Levenshtein. 1965. Binary Codes for Correcting Deletions,
Insertions, and Reversals. Doklady Akademii Nauk SSSR,
163(4):845–848.
W. Li, R. Yangarber, and R. Grishman. 2003. Bootstrapping
Learning of Semantic Classes from Positive and Negative
Examples. In Proceedings of the ICML-2003 Workshop on
The Continuum from Labeled to Unlabeled Data.
A. Monge and C. Elkan. 1996. The Field Matching Problem:
Algorithms and Applications. In Proceedings of Knowledge
Discovery and Data Mining 1996, pages 267–270.
J. Piskorski, P. Homola, M. Marciniak, A. Mykowiecka,
A. Przepiórkowski, and M. Woli´nski. 2004. Information
Extraction for Polish Using the Sprout Platform. Proceed-
ings of ISMIS 2004, Zakopane.
J. Piskorski. 2005. Named-entity Recognition for Polish with
SProUT. In Proceedings of IMTCI 2004, LNCS Vol 3490,
Warsaw, Poland.
J. Piskorski and M. Sydow. 2007. Usability of String Distance
Metrics for Name Matching Tasks in Polish. In progress.
B. Pouliquen, R. Steinberger, C. Ignat, I. Temnikova, A. Widi-
ger, W. Zaghouani and J. Žižka. 2005. Multilingual person
name recognition and transliteration. CORELA - Cognition,
Représentation, Langage. Numéros spéciaux, Le traitement
lexicographique des noms propres, ISSN 1638-5748.
T. Smith and M. Waterman. 1981. Identification of Common
Molecular Subsequences. Journal of Molecular Biology,
147:195–197.
E. Ukkonen. 1992. Approximate String Matching with q-
grams and Maximal Matches. Theoretical Computer Sci-
ence, 92(1):191–211.
D. Weiss. 2007. Korpus Rzeczpospolitej. Web document:
http://www.cs.put.poznan.pl/dweiss/rzeczpospolita
W. Winkler. 1999. The state of record linkage and current re-
search problems. Technical report, U.S. Bureau of the Cen-
sus, Washington, DC.
</reference>
<page confidence="0.999322">
34
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.012188">
<title confidence="0.9170345">Lemmatization of Polish Person Names Jakub</title>
<author confidence="0.669391">European</author>
<affiliation confidence="0.775872">Joint Research</affiliation>
<address confidence="0.69415">Via Fermi 21020 Ispra,</address>
<email confidence="0.834042">Jakub.Piskorski@jrc.it</email>
<author confidence="0.4418465">Marcin Polish-Japanese</author>
<affiliation confidence="0.4772285">of Information Koszykowa</affiliation>
<address confidence="0.855141">02-008 Warsaw,</address>
<email confidence="0.950829">msyd@pjwstk.edu.pl</email>
<note confidence="0.609370833333333">Anna Université Paris3/LLF, PAS Case Postale 2, place 75251 Paris Cedex akupsc@univ-paris3.fr</note>
<abstract confidence="0.9993845">The paper presents two techniques for lemmatization of Polish person names. First, we apply a rule-based approach which reon linguistic information and heuris- Then, we investigate an tive knowledge-poor method which employs string distance measures. We provide an evaluation of the adopted techniques using a set of newspaper texts.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I Bartolini</author>
<author>P Ciacca</author>
<author>M Patella</author>
</authors>
<title>String matching with metric trees using an approximate distance.</title>
<date>2002</date>
<booktitle>In Proceedings of SPIRE, LNCS 2476,</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="15827" citStr="Bartolini et al., 2002" startWordPosition="2535" endWordPosition="2538">turn an incorrect answer. For another task, a multiresult experiment, we construct an approximation f* : A —* 2c, where f* returns the correct answer for a if f(a) E f*(a). 4.1 String distance metrics In our experiments, we have explored mainly character-level string metrics3 applied by the database community for record linkage. Our point of departure is the well-known Levenshtein edit distance metric specified as the minimum number of character-level operations (insertion, deletion or substitution) required for transforming one string into another (Levenshtein, 1965) and bag distance metric (Bartolini et al., 2002) which is a time-efficient approximation of the Levenshtein metric. Next, we have tested the SmithWaterman (Smith and Waterman, 1981) metric, which is an extension of Levenshtein metric and allow a variable cost adjustment to edit operations and an alphabet mapping to costs. Another group of string metrics we explored is based on a comparison of character-level n-grams in two strings. The q-gram metric (Ukkonen, 1992) is 3Distance (similarity) metrics map a pair of strings s and t to a real number r, where a smaller (larger) value of r indicates greater (lower) similarity. If _f(a) = f(a) for </context>
</contexts>
<marker>Bartolini, Ciacca, Patella, 2002</marker>
<rawString>I. Bartolini, P. Ciacca, and M. Patella. 2002. String matching with metric trees using an approximate distance. In Proceedings of SPIRE, LNCS 2476, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bikel</author>
<author>S Miller</author>
<author>R Schwartz</author>
<author>R Weischedel</author>
</authors>
<title>Nymble: A High-performance Learning Name-finder.</title>
<date>1997</date>
<booktitle>In Proceedings of ANLP-1997,</booktitle>
<location>Washington DC, USA.</location>
<contexts>
<context position="1317" citStr="Bikel et al., 1997" startWordPosition="190" endWordPosition="193">adopted techniques using a set of newspaper texts. 1 Introduction Proper names constitute a significant part of natural language texts (estimated to about 10% in newspaper articles) and are important for NLP applications, such as Information Extraction, which rely on automatic text understanding.1 In particular, coreference resolution (e.g., identifying several name variants as referring to the same entity) plays a crucial role in such systems. Although automatic recognition of proper names in English, French and other major languages has been in the research focus for over a decade now, cf. (Bikel et al., 1997), (Borthwick, 1999), (Li et al., 2003), only a few efforts have been reported for Slavic languages, cf. (Cunningham et al., 2003) (Russian and Bulgarian), (Piskorski, 2005) (Polish). Rich inflection and a more relaxed word order make recognition of proper names in Slavic more difficult than for other languages. Moreover, inflection of proper names is usually 1The research presented in this paper was partially founded by the Ministry of Education and Science (Poland), grant number 3T11C00727. 27 quite different from common nouns, which complicates the lemmatization process necessary for correct</context>
</contexts>
<marker>Bikel, Miller, Schwartz, Weischedel, 1997</marker>
<rawString>D. Bikel, S. Miller, R. Schwartz, and R. Weischedel. 1997. Nymble: A High-performance Learning Name-finder. In Proceedings of ANLP-1997, Washington DC, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Borthwick</author>
</authors>
<title>A Maximum Entropy Approach to Named Entity Recognition.</title>
<date>1999</date>
<tech>PhD Thesis,</tech>
<institution>Department of Computer Science, New York University.</institution>
<contexts>
<context position="1336" citStr="Borthwick, 1999" startWordPosition="194" endWordPosition="196">ng a set of newspaper texts. 1 Introduction Proper names constitute a significant part of natural language texts (estimated to about 10% in newspaper articles) and are important for NLP applications, such as Information Extraction, which rely on automatic text understanding.1 In particular, coreference resolution (e.g., identifying several name variants as referring to the same entity) plays a crucial role in such systems. Although automatic recognition of proper names in English, French and other major languages has been in the research focus for over a decade now, cf. (Bikel et al., 1997), (Borthwick, 1999), (Li et al., 2003), only a few efforts have been reported for Slavic languages, cf. (Cunningham et al., 2003) (Russian and Bulgarian), (Piskorski, 2005) (Polish). Rich inflection and a more relaxed word order make recognition of proper names in Slavic more difficult than for other languages. Moreover, inflection of proper names is usually 1The research presented in this paper was partially founded by the Ministry of Education and Science (Poland), grant number 3T11C00727. 27 quite different from common nouns, which complicates the lemmatization process necessary for correct coreference resolu</context>
</contexts>
<marker>Borthwick, 1999</marker>
<rawString>A. Borthwick. 1999. A Maximum Entropy Approach to Named Entity Recognition. PhD Thesis, Department of Computer Science, New York University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Christen</author>
</authors>
<title>A Comparison of Personal Name Matching: Techniques and Practical Issues.</title>
<date>2006</date>
<tech>Technical report, TR-CS06-02,</tech>
<institution>Computer Science Laboratory, The Australian National University,</institution>
<location>Canberra, Australia.</location>
<contexts>
<context position="14824" citStr="Christen, 2006" startWordPosition="2359" endWordPosition="2360">to morphological information over those which rely solely on orthography and/or token types. 4 Application of String Distance Metrics for Lemmatization Since knowledge-based lemmatization of Polish NEs is extremely hard, we also explored a possibility of using string distance metrics for matching inflected person names with their base forms (and their variants) in a collection of document, rather than within a single document. The rest of this section describes our experiments in using different string distance metrics for this task, inspired by the work presented in (Cohen et al., 2003) and (Christen, 2006). The problem can be formally defined as follows. Let A, B and C be three sets of strings over some alphabet E, with B C_ C. Further, let f : A —* B be a function representing a mapping of inflected forms (A) into their corresponding base forms (B). Given, A and C (the search space), the task is to construct an approximation of f, namely f : _A —* C. _ f returns f is said to return an incorrect answer. For another task, a multiresult experiment, we construct an approximation f* : A —* 2c, where f* returns the correct answer for a if f(a) E f*(a). 4.1 String distance metrics In our experiments,</context>
<context position="17861" citStr="Christen, 2006" startWordPosition="2893" endWordPosition="2894">ed a basic metric based on the longest common prefix, calculated as follows: CPδ(s, t) = ((|lcp(s, t) |+ 6)/(|s |· |t|), where lcp(s, t) denotes the longest common prefix for s and t. The symbol 6 is a parameter for favoring certain suffix pairs in s (t). We have experimented with two variants: CPδ, with 6 = 0 and CPδ., where 6 is set to 1 if s ends in: o, y, ˛a, ˛e, and t ends in an a, or 0 otherwise. The latter setting results from empirical study of the data and the declension paradigm. For coping with multi-token strings, we tested a similar metric called longest common substrings (LCS) (Christen, 2006), which recursively finds and removes the longest common substring in the two strings compared, up to a specified minimum length. Its value is calculated as the ratio of the sum of all found longest common substrings to the length of the longer string. We extended LCS by additional weighting the lengths of the longest common substrings. The main idea is to penalize the longest common substrings which do not match the beginning of a token in at least one of the compared strings. In such cases, the weight for lcs(s, t) (the longest common substring for s and t) is computed as follows. Let α deno</context>
<context position="20676" citStr="Christen, 2006" startWordPosition="3389" endWordPosition="3390">r of agreeing characters. The similarity between s and t is the mean of these maximum scores. Two further metrics for multi-token strings were investigated, namely Sorted-Tokens and Permuted-Tokens. The first one is computed in two steps: (a) first, tokens forming a full string are sorted alphabetically, and then (b) an arbitrary metric is applied to compute the similarity for the ‘sorted’ strings. The latter compares all possible permutations of tokens forming the full strings and returns the calculated maximal similarity value. A detailed description of string metrics used here is given in (Christen, 2006) and in (Piskorski et al., 2007). wlcs(s,t) = |lcs(s, t) |+ α |lcs(s, t) |+ α − max(α, p) 31 4.2 Test Data For the experiments on coreference of person names, we used two resources: (a) a lexicon of the most frequent Polish first names (PL-F(IRST)-NAMES) consisting of pairs of an inflected form and the corresponding base form, and (b) an analogous lexicon of inflected full person names (first name + surname) (PL-FULL-NAMES).4 The latter resource was created semi-automatically as follows. We have automatically extracted a list of 22485 full person-name candidates from a corpus of 15724 on-line </context>
</contexts>
<marker>Christen, 2006</marker>
<rawString>P. Christen. 2006. A Comparison of Personal Name Matching: Techniques and Practical Issues. Technical report, TR-CS06-02, Computer Science Laboratory, The Australian National University, Canberra, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Cohen</author>
<author>P Ravikumar</author>
<author>S Fienberg</author>
</authors>
<title>A comparison of string metrics for matching names and records.</title>
<date>2003</date>
<booktitle>In Proceedings of the KDD2003.</booktitle>
<contexts>
<context position="14803" citStr="Cohen et al., 2003" startWordPosition="2354" endWordPosition="2357">ritize rules which refer to morphological information over those which rely solely on orthography and/or token types. 4 Application of String Distance Metrics for Lemmatization Since knowledge-based lemmatization of Polish NEs is extremely hard, we also explored a possibility of using string distance metrics for matching inflected person names with their base forms (and their variants) in a collection of document, rather than within a single document. The rest of this section describes our experiments in using different string distance metrics for this task, inspired by the work presented in (Cohen et al., 2003) and (Christen, 2006). The problem can be formally defined as follows. Let A, B and C be three sets of strings over some alphabet E, with B C_ C. Further, let f : A —* B be a function representing a mapping of inflected forms (A) into their corresponding base forms (B). Given, A and C (the search space), the task is to construct an approximation of f, namely f : _A —* C. _ f returns f is said to return an incorrect answer. For another task, a multiresult experiment, we construct an approximation f* : A —* 2c, where f* returns the correct answer for a if f(a) E f*(a). 4.1 String distance metric</context>
<context position="18762" citStr="Cohen et al., 2003" startWordPosition="3052" endWordPosition="3055"> weighting the lengths of the longest common substrings. The main idea is to penalize the longest common substrings which do not match the beginning of a token in at least one of the compared strings. In such cases, the weight for lcs(s, t) (the longest common substring for s and t) is computed as follows. Let α denote the maximum number of non-whitespace characters which precede the first occurrence of lcs(s, t) in s or t. Then, lcs(s, t) is assigned the weight: where p has been experimentally set to 4. We refer to the ‘weighted’ variant of LCS as W LCS. Good results for name-matching tasks (Cohen et al., 2003) have been reported using the Jaro metric and its variant, the Jaro-Winkler (JW) metric (Winkler, 1999). These metrics are based on the number and order of common characters in two compared strings. We have extended the Jaro-Winkler metric to improve the comparison of multi-token strings. We call this modification JWM and it can be briefly characterized as follows. Let J(s, t) denote the value of the Jaro metric for s and t. Then, let s = s ... sK and t = t ... tL, where si (ti) represent i-th token of s and t respectively, and assume, without loss of generality, L G K. JWM(s, t) is defined </context>
</contexts>
<marker>Cohen, Ravikumar, Fienberg, 2003</marker>
<rawString>W. Cohen, P. Ravikumar, and S. Fienberg. 2003. A comparison of string metrics for matching names and records. In Proceedings of the KDD2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cunningham</author>
<author>E Paskaleva</author>
<author>K Bontcheva</author>
<author>G Angelova</author>
</authors>
<title>Information extraction for Slavonic languages.</title>
<date>2003</date>
<booktitle>In Proceedings of the Workshop IESL, Borovets,</booktitle>
<contexts>
<context position="1446" citStr="Cunningham et al., 2003" startWordPosition="212" endWordPosition="216">uage texts (estimated to about 10% in newspaper articles) and are important for NLP applications, such as Information Extraction, which rely on automatic text understanding.1 In particular, coreference resolution (e.g., identifying several name variants as referring to the same entity) plays a crucial role in such systems. Although automatic recognition of proper names in English, French and other major languages has been in the research focus for over a decade now, cf. (Bikel et al., 1997), (Borthwick, 1999), (Li et al., 2003), only a few efforts have been reported for Slavic languages, cf. (Cunningham et al., 2003) (Russian and Bulgarian), (Piskorski, 2005) (Polish). Rich inflection and a more relaxed word order make recognition of proper names in Slavic more difficult than for other languages. Moreover, inflection of proper names is usually 1The research presented in this paper was partially founded by the Ministry of Education and Science (Poland), grant number 3T11C00727. 27 quite different from common nouns, which complicates the lemmatization process necessary for correct coreference resolution. In this paper, we focus on lemmatization of Polish person names, the most idiosyncratic class of proper </context>
</contexts>
<marker>Cunningham, Paskaleva, Bontcheva, Angelova, 2003</marker>
<rawString>H. Cunningham, E. Paskaleva, K. Bontcheva, and G. Angelova. 2003. Information extraction for Slavonic languages. In Proceedings of the Workshop IESL, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Erjavec</author>
<author>S Džeroski</author>
</authors>
<title>Machine Learning of Morphosyntactic Structure: Lemmatising Unknown Slovene Words.</title>
<date>2004</date>
<journal>In Journal of Applied Artificial Intelligence,</journal>
<volume>18</volume>
<issue>1</issue>
<pages>17--40</pages>
<marker>Erjavec, Džeroski, 2004</marker>
<rawString>T. Erjavec and S. Džeroski. 2004. Machine Learning of Morphosyntactic Structure: Lemmatising Unknown Slovene Words. In Journal of Applied Artificial Intelligence, 18(1), pages 17-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Gravano</author>
<author>P Ipeirotis</author>
<author>H Jagadish</author>
<author>S Koudas</author>
<author>N Muthukrishnan</author>
<author>L Pietarinen</author>
<author>D Srivastava</author>
</authors>
<title>Using q-grams in a DBMS for Approximate String Processing.</title>
<date>2001</date>
<journal>IEEE Data Engineering Bulletin,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="16741" citStr="Gravano et al., 2001" startWordPosition="2691" endWordPosition="2694">string metrics we explored is based on a comparison of character-level n-grams in two strings. The q-gram metric (Ukkonen, 1992) is 3Distance (similarity) metrics map a pair of strings s and t to a real number r, where a smaller (larger) value of r indicates greater (lower) similarity. If _f(a) = f(a) for a E A, we say that the correct answer for a; otherwise, 30 computed by counting the number of q-grams contained in both strings. An extension to q-grams is to add positional information, and to match only common q-grams that occur at a specified distance from each other (positional q-grams) (Gravano et al., 2001). Finally, the skip-gram metric (Keskustalo et al., 2003) is based on the idea that in addition to forming bigrams of adjacent characters, bigrams that skip characters are considered as well. Gram classes are defined that specify what kind of skipgrams are created, e.g. 10, 11 class means that regular bigrams (0 characters skipped) and bigrams that skip one character are formed. We have explored 10, 11, 10, 21 and 10, 1, 21 gram classes. Taking into account the Polish declension paradigm, we also added a basic metric based on the longest common prefix, calculated as follows: CPδ(s, t) = ((|lcp</context>
</contexts>
<marker>Gravano, Ipeirotis, Jagadish, Koudas, Muthukrishnan, Pietarinen, Srivastava, 2001</marker>
<rawString>L. Gravano, P. Ipeirotis, H. Jagadish, S. Koudas, N. Muthukrishnan, L. Pietarinen, and D. Srivastava. 2001. Using q-grams in a DBMS for Approximate String Processing. IEEE Data Engineering Bulletin, 24(4):28–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Grzenia</author>
</authors>
<title>Słownik nazw własnych — ortografia, wymowa, słowotwórstwo i odmiana.</title>
<date>1998</date>
<publisher>PWN.</publisher>
<contexts>
<context position="6628" citStr="Grzenia, 1998" startWordPosition="1030" endWordPosition="1031">ed differently in English and German, which impacts its declension in Polish. If it’s of English origin, a nominal declension is applied, i.e., Wilde’a (gen.), whereas if it comes from German, an adjective-like declension is adopted: Wildego (gen.). Declension of surnames which are also common nouns can be different from the declension of common nouns.2 In Table 2, we present a comparison of the common noun goł ˛ab ‘dove’ in singular and plural with the corresponding forms used for the surname. A comprehensive overview of this rather intriguing declension paradigm of Polish names is given in (Grzenia, 1998). Finally, first name forms present problems as well. Foreign masculine first names, whose pronounced version ends in a consonant or whose written version ends in -a, -o, -y or -i do in general get inflected (e.g., Jacques (nom.) vs. Jacques’a (gen./acc.)), whereas names whose pronounced version ends in a vowel and are stressed on the last syllable (e.g., François) usually do not change form. For female first names created from a male first name, e.g., J6zef (masc.) vs. J6zefa (fem.), there is a frequent homonymy between the nominative form of the female name and the genitive/accusative form o</context>
</contexts>
<marker>Grzenia, 1998</marker>
<rawString>J. Grzenia. 1998. Słownik nazw własnych — ortografia, wymowa, słowotwórstwo i odmiana. PWN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Keskustalo</author>
<author>A Pirkola</author>
<author>K Visala</author>
<author>E Leppanen</author>
<author>K Jarvelin</author>
</authors>
<title>Non-adjacent digrams improve matching of cross-lingual spelling variants.</title>
<date>2003</date>
<booktitle>In Proceedings of SPIRE, LNCS 22857,</booktitle>
<pages>252--265</pages>
<location>Manaus, Brazil,</location>
<contexts>
<context position="16798" citStr="Keskustalo et al., 2003" startWordPosition="2699" endWordPosition="2702"> character-level n-grams in two strings. The q-gram metric (Ukkonen, 1992) is 3Distance (similarity) metrics map a pair of strings s and t to a real number r, where a smaller (larger) value of r indicates greater (lower) similarity. If _f(a) = f(a) for a E A, we say that the correct answer for a; otherwise, 30 computed by counting the number of q-grams contained in both strings. An extension to q-grams is to add positional information, and to match only common q-grams that occur at a specified distance from each other (positional q-grams) (Gravano et al., 2001). Finally, the skip-gram metric (Keskustalo et al., 2003) is based on the idea that in addition to forming bigrams of adjacent characters, bigrams that skip characters are considered as well. Gram classes are defined that specify what kind of skipgrams are created, e.g. 10, 11 class means that regular bigrams (0 characters skipped) and bigrams that skip one character are formed. We have explored 10, 11, 10, 21 and 10, 1, 21 gram classes. Taking into account the Polish declension paradigm, we also added a basic metric based on the longest common prefix, calculated as follows: CPδ(s, t) = ((|lcp(s, t) |+ 6)/(|s |· |t|), where lcp(s, t) denotes the lo</context>
</contexts>
<marker>Keskustalo, Pirkola, Visala, Leppanen, Jarvelin, 2003</marker>
<rawString>H. Keskustalo, A. Pirkola, K. Visala, E. Leppanen, and K. Jarvelin. 2003. Non-adjacent digrams improve matching of cross-lingual spelling variants. In Proceedings of SPIRE, LNCS 22857, Manaus, Brazil, pages 252–265.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Levenshtein</author>
</authors>
<title>Binary Codes for Correcting Deletions, Insertions, and Reversals.</title>
<date>1965</date>
<booktitle>Doklady Akademii Nauk SSSR,</booktitle>
<pages>163--4</pages>
<contexts>
<context position="15778" citStr="Levenshtein, 1965" startWordPosition="2529" endWordPosition="2530">ely f : _A —* C. _ f returns f is said to return an incorrect answer. For another task, a multiresult experiment, we construct an approximation f* : A —* 2c, where f* returns the correct answer for a if f(a) E f*(a). 4.1 String distance metrics In our experiments, we have explored mainly character-level string metrics3 applied by the database community for record linkage. Our point of departure is the well-known Levenshtein edit distance metric specified as the minimum number of character-level operations (insertion, deletion or substitution) required for transforming one string into another (Levenshtein, 1965) and bag distance metric (Bartolini et al., 2002) which is a time-efficient approximation of the Levenshtein metric. Next, we have tested the SmithWaterman (Smith and Waterman, 1981) metric, which is an extension of Levenshtein metric and allow a variable cost adjustment to edit operations and an alphabet mapping to costs. Another group of string metrics we explored is based on a comparison of character-level n-grams in two strings. The q-gram metric (Ukkonen, 1992) is 3Distance (similarity) metrics map a pair of strings s and t to a real number r, where a smaller (larger) value of r indicates</context>
</contexts>
<marker>Levenshtein, 1965</marker>
<rawString>V. Levenshtein. 1965. Binary Codes for Correcting Deletions, Insertions, and Reversals. Doklady Akademii Nauk SSSR, 163(4):845–848.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Li</author>
<author>R Yangarber</author>
<author>R Grishman</author>
</authors>
<title>Bootstrapping Learning of Semantic Classes from Positive and Negative Examples.</title>
<date>2003</date>
<booktitle>In Proceedings of the ICML-2003 Workshop on The Continuum from Labeled to Unlabeled Data.</booktitle>
<contexts>
<context position="1355" citStr="Li et al., 2003" startWordPosition="197" endWordPosition="200">er texts. 1 Introduction Proper names constitute a significant part of natural language texts (estimated to about 10% in newspaper articles) and are important for NLP applications, such as Information Extraction, which rely on automatic text understanding.1 In particular, coreference resolution (e.g., identifying several name variants as referring to the same entity) plays a crucial role in such systems. Although automatic recognition of proper names in English, French and other major languages has been in the research focus for over a decade now, cf. (Bikel et al., 1997), (Borthwick, 1999), (Li et al., 2003), only a few efforts have been reported for Slavic languages, cf. (Cunningham et al., 2003) (Russian and Bulgarian), (Piskorski, 2005) (Polish). Rich inflection and a more relaxed word order make recognition of proper names in Slavic more difficult than for other languages. Moreover, inflection of proper names is usually 1The research presented in this paper was partially founded by the Ministry of Education and Science (Poland), grant number 3T11C00727. 27 quite different from common nouns, which complicates the lemmatization process necessary for correct coreference resolution. In this paper</context>
</contexts>
<marker>Li, Yangarber, Grishman, 2003</marker>
<rawString>W. Li, R. Yangarber, and R. Grishman. 2003. Bootstrapping Learning of Semantic Classes from Positive and Negative Examples. In Proceedings of the ICML-2003 Workshop on The Continuum from Labeled to Unlabeled Data.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Monge</author>
<author>C Elkan</author>
</authors>
<title>The Field Matching Problem: Algorithms and Applications.</title>
<date>1996</date>
<booktitle>In Proceedings of Knowledge Discovery and Data Mining</booktitle>
<pages>267--270</pages>
<contexts>
<context position="19889" citStr="Monge and Elkan, 1996" startWordPosition="3254" endWordPosition="3257">n of s and t respectively, and assume, without loss of generality, L G K. JWM(s, t) is defined as: JWM(s, t) = J(s, t)+6·boostp(s, t)·(1−J(s, t)) where 6 denotes the common prefix adjustment factor and boostp is calculated as follows: i boostp(s, t) = L ·L Z  min(|lcp(si, ti)|, p)+ min(|lcp(sL, tL..tK)|, p) L The main idea behind JWM is to boost the Jaro similarity for strings with the highest number of agreeing initial characters in the corresponding tokens in the compared strings. Finally, for multi-token strings, we tested a recursive matching pattern, known also as Monge-Elkan distance (Monge and Elkan, 1996). The intuition behind this measure is the assumption that a token in s (strings are treated as sequences of tokens) corresponds to a token in t which has the highest number of agreeing characters. The similarity between s and t is the mean of these maximum scores. Two further metrics for multi-token strings were investigated, namely Sorted-Tokens and Permuted-Tokens. The first one is computed in two steps: (a) first, tokens forming a full string are sorted alphabetically, and then (b) an arbitrary metric is applied to compute the similarity for the ‘sorted’ strings. The latter compares all po</context>
</contexts>
<marker>Monge, Elkan, 1996</marker>
<rawString>A. Monge and C. Elkan. 1996. The Field Matching Problem: Algorithms and Applications. In Proceedings of Knowledge Discovery and Data Mining 1996, pages 267–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Piskorski</author>
<author>P Homola</author>
<author>M Marciniak</author>
<author>A Mykowiecka</author>
<author>A Przepiórkowski</author>
<author>M Woli´nski</author>
</authors>
<title>Information Extraction for Polish Using the Sprout Platform.</title>
<date>2004</date>
<booktitle>Proceedings of ISMIS 2004,</booktitle>
<location>Zakopane.</location>
<marker>Piskorski, Homola, Marciniak, Mykowiecka, Przepiórkowski, Woli´nski, 2004</marker>
<rawString>J. Piskorski, P. Homola, M. Marciniak, A. Mykowiecka, A. Przepiórkowski, and M. Woli´nski. 2004. Information Extraction for Polish Using the Sprout Platform. Proceedings of ISMIS 2004, Zakopane.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Piskorski</author>
</authors>
<title>Named-entity Recognition for Polish with SProUT.</title>
<date>2005</date>
<booktitle>In Proceedings of IMTCI 2004, LNCS Vol 3490,</booktitle>
<location>Warsaw, Poland.</location>
<contexts>
<context position="1489" citStr="Piskorski, 2005" startWordPosition="220" endWordPosition="222">icles) and are important for NLP applications, such as Information Extraction, which rely on automatic text understanding.1 In particular, coreference resolution (e.g., identifying several name variants as referring to the same entity) plays a crucial role in such systems. Although automatic recognition of proper names in English, French and other major languages has been in the research focus for over a decade now, cf. (Bikel et al., 1997), (Borthwick, 1999), (Li et al., 2003), only a few efforts have been reported for Slavic languages, cf. (Cunningham et al., 2003) (Russian and Bulgarian), (Piskorski, 2005) (Polish). Rich inflection and a more relaxed word order make recognition of proper names in Slavic more difficult than for other languages. Moreover, inflection of proper names is usually 1The research presented in this paper was partially founded by the Ministry of Education and Science (Poland), grant number 3T11C00727. 27 quite different from common nouns, which complicates the lemmatization process necessary for correct coreference resolution. In this paper, we focus on lemmatization of Polish person names, the most idiosyncratic class of proper names in this language. First, we report re</context>
</contexts>
<marker>Piskorski, 2005</marker>
<rawString>J. Piskorski. 2005. Named-entity Recognition for Polish with SProUT. In Proceedings of IMTCI 2004, LNCS Vol 3490, Warsaw, Poland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Piskorski</author>
<author>M Sydow</author>
</authors>
<title>Usability of String Distance Metrics for Name Matching Tasks in Polish. In</title>
<date>2007</date>
<location>progress.</location>
<marker>Piskorski, Sydow, 2007</marker>
<rawString>J. Piskorski and M. Sydow. 2007. Usability of String Distance Metrics for Name Matching Tasks in Polish. In progress.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pouliquen</author>
<author>R Steinberger</author>
<author>C Ignat</author>
<author>I Temnikova</author>
<author>A Widiger</author>
<author>W Zaghouani</author>
<author>J Žižka</author>
</authors>
<title>Multilingual person name recognition and transliteration. CORELA - Cognition, Représentation, Langage. Numéros spéciaux, Le traitement lexicographique des noms propres,</title>
<date>2005</date>
<journal>ISSN</journal>
<pages>1638--5748</pages>
<contexts>
<context position="2958" citStr="Pouliquen et al., 2005" startWordPosition="443" endWordPosition="446">available, even if the entire document is considered, and lemmatization cannot be performed. Therefore, we experimented with various knowledge-poor methods, namely string distance metrics, in order to test their usefulness for lemmatization of Polish person names as an alternative technique, especially for cases where documentlevel heuristics are insufficient. Lemmatization of proper names in Slavic has not attracted much attention so far but some work has been done for Slovene: (Erjavec et al., 2004) present a machine-learning approach to lemmatization of unknown single-token words, whereas (Pouliquen et al., 2005) report on a shallow approach to find base forms. The organization of the paper is as follows. First, we present a description of phenomena which make lemmatization of Polish person names a difficult task. Next, a rule-based approach and its evaluation are presented. Then, various string distance metrics are introduced, followed by the results of experiments on newspaper texts. The final section presents conclusions and perspectives for future work. Balto-Slavonic Natural Language Processing 2007, June 29, 2007, pages 27–34, Prague, June 2007. c�2007 Association for Computational Linguistics c</context>
</contexts>
<marker>Pouliquen, Steinberger, Ignat, Temnikova, Widiger, Zaghouani, Žižka, 2005</marker>
<rawString>B. Pouliquen, R. Steinberger, C. Ignat, I. Temnikova, A. Widiger, W. Zaghouani and J. Žižka. 2005. Multilingual person name recognition and transliteration. CORELA - Cognition, Représentation, Langage. Numéros spéciaux, Le traitement lexicographique des noms propres, ISSN 1638-5748.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Smith</author>
<author>M Waterman</author>
</authors>
<title>Identification of Common Molecular Subsequences.</title>
<date>1981</date>
<journal>Journal of Molecular Biology,</journal>
<pages>147--195</pages>
<contexts>
<context position="15960" citStr="Smith and Waterman, 1981" startWordPosition="2556" endWordPosition="2559">the correct answer for a if f(a) E f*(a). 4.1 String distance metrics In our experiments, we have explored mainly character-level string metrics3 applied by the database community for record linkage. Our point of departure is the well-known Levenshtein edit distance metric specified as the minimum number of character-level operations (insertion, deletion or substitution) required for transforming one string into another (Levenshtein, 1965) and bag distance metric (Bartolini et al., 2002) which is a time-efficient approximation of the Levenshtein metric. Next, we have tested the SmithWaterman (Smith and Waterman, 1981) metric, which is an extension of Levenshtein metric and allow a variable cost adjustment to edit operations and an alphabet mapping to costs. Another group of string metrics we explored is based on a comparison of character-level n-grams in two strings. The q-gram metric (Ukkonen, 1992) is 3Distance (similarity) metrics map a pair of strings s and t to a real number r, where a smaller (larger) value of r indicates greater (lower) similarity. If _f(a) = f(a) for a E A, we say that the correct answer for a; otherwise, 30 computed by counting the number of q-grams contained in both strings. An e</context>
</contexts>
<marker>Smith, Waterman, 1981</marker>
<rawString>T. Smith and M. Waterman. 1981. Identification of Common Molecular Subsequences. Journal of Molecular Biology, 147:195–197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Ukkonen</author>
</authors>
<title>Approximate String Matching with qgrams and Maximal Matches.</title>
<date>1992</date>
<journal>Theoretical Computer Science,</journal>
<volume>92</volume>
<issue>1</issue>
<contexts>
<context position="16248" citStr="Ukkonen, 1992" startWordPosition="2605" endWordPosition="2606">number of character-level operations (insertion, deletion or substitution) required for transforming one string into another (Levenshtein, 1965) and bag distance metric (Bartolini et al., 2002) which is a time-efficient approximation of the Levenshtein metric. Next, we have tested the SmithWaterman (Smith and Waterman, 1981) metric, which is an extension of Levenshtein metric and allow a variable cost adjustment to edit operations and an alphabet mapping to costs. Another group of string metrics we explored is based on a comparison of character-level n-grams in two strings. The q-gram metric (Ukkonen, 1992) is 3Distance (similarity) metrics map a pair of strings s and t to a real number r, where a smaller (larger) value of r indicates greater (lower) similarity. If _f(a) = f(a) for a E A, we say that the correct answer for a; otherwise, 30 computed by counting the number of q-grams contained in both strings. An extension to q-grams is to add positional information, and to match only common q-grams that occur at a specified distance from each other (positional q-grams) (Gravano et al., 2001). Finally, the skip-gram metric (Keskustalo et al., 2003) is based on the idea that in addition to forming </context>
</contexts>
<marker>Ukkonen, 1992</marker>
<rawString>E. Ukkonen. 1992. Approximate String Matching with qgrams and Maximal Matches. Theoretical Computer Science, 92(1):191–211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Weiss</author>
</authors>
<title>Korpus Rzeczpospolitej. Web document: http://www.cs.put.poznan.pl/dweiss/rzeczpospolita</title>
<date>2007</date>
<contexts>
<context position="12931" citStr="Weiss, 2007" startWordPosition="2045" endWordPosition="2046">be bracketed as [prezes [spółki Kruk]] or [[prezes spółki] Kruk]. Consequently, the name Kruk might either refer to a company name (‘...said the president of the Kruk company’) or to a person name (‘... said Kruk, the president of the company’). Inferring the proper interpretation might not be possible even if we consider the subcategorization frame of the verb powiedzie´c ‘to say’. 3.2 Evaluation For evaluation of recognition and lemmatization of person names, a set of 30 articles on various topics (politics, finance, sports, culture and science) has been randomly chosen from Rzeczpospolita (Weiss, 2007), a leading Polish newspaper. The total number of person name occurrences in this document set amounts to 858. Evaluation of recognition’s precision and recall yielded 88.6% and 82.6%, respectively. Precision of lemmatization of first names and surnames achieved 92.2% and 75.6%, respectively. For 12.4% of the recognized person names more than one output structure was returned. For instance, in case of the person name Marka Belki, the first name Marka is interpreted by the gazetteer either as an accusative form of the male name Marek or as a nominative form of a foreign female name Marka. In fa</context>
</contexts>
<marker>Weiss, 2007</marker>
<rawString>D. Weiss. 2007. Korpus Rzeczpospolitej. Web document: http://www.cs.put.poznan.pl/dweiss/rzeczpospolita</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Winkler</author>
</authors>
<title>The state of record linkage and current research problems.</title>
<date>1999</date>
<booktitle>Technical report, U.S. Bureau of the Census,</booktitle>
<location>Washington, DC.</location>
<contexts>
<context position="18865" citStr="Winkler, 1999" startWordPosition="3070" endWordPosition="3072">strings which do not match the beginning of a token in at least one of the compared strings. In such cases, the weight for lcs(s, t) (the longest common substring for s and t) is computed as follows. Let α denote the maximum number of non-whitespace characters which precede the first occurrence of lcs(s, t) in s or t. Then, lcs(s, t) is assigned the weight: where p has been experimentally set to 4. We refer to the ‘weighted’ variant of LCS as W LCS. Good results for name-matching tasks (Cohen et al., 2003) have been reported using the Jaro metric and its variant, the Jaro-Winkler (JW) metric (Winkler, 1999). These metrics are based on the number and order of common characters in two compared strings. We have extended the Jaro-Winkler metric to improve the comparison of multi-token strings. We call this modification JWM and it can be briefly characterized as follows. Let J(s, t) denote the value of the Jaro metric for s and t. Then, let s = s ... sK and t = t ... tL, where si (ti) represent i-th token of s and t respectively, and assume, without loss of generality, L G K. JWM(s, t) is defined as: JWM(s, t) = J(s, t)+6·boostp(s, t)·(1−J(s, t)) where 6 denotes the common prefix adjustment factor </context>
</contexts>
<marker>Winkler, 1999</marker>
<rawString>W. Winkler. 1999. The state of record linkage and current research problems. Technical report, U.S. Bureau of the Census, Washington, DC.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>