<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9991815">
A Random Walk Approach to Selectional Preferences Based on
Preference Ranking and Propagation∗
</title>
<author confidence="0.999668">
Zhenhua Tian†, Hengheng Xiang, Ziqi Liu, Qinghua Zheng‡
</author>
<affiliation confidence="0.997344333333333">
Ministry of Education Key Lab for Intelligent Networks and Network Security
Department of Computer Science and Technology
Xi’an Jiaotong University
</affiliation>
<address confidence="0.871037">
Xi’an, Shaanxi 710049, China
</address>
<email confidence="0.998943">
{zhhtian†,qhzheng‡}@mail.xjtu.edu.cn
</email>
<sectionHeader confidence="0.993896" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999789">
This paper presents an unsupervised ran-
dom walk approach to alleviate data spar-
sity for selectional preferences. Based on
the measure of preferences between predi-
cates and arguments, the model aggregates
all the transitions from a given predicate to
its nearby predicates, and propagates their
argument preferences as the given predi-
cate’s smoothed preferences. Experimen-
tal results show that this approach out-
performs several state-of-the-art method-
s on the pseudo-disambiguation task, and
it better correlates with human plausibility
judgements.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997445344827586">
Selectional preferences (SP) or selectional restric-
tions capture the plausibility of predicates and
their arguments for a given relation. Kaze and
Fodor (1963) describe that predicates and their
arguments have strict boolean restrictions, either
satisfied or violated. Sentences are semantically
anomalous and not consistent in reading if they
violated the restrictions. Wilks (1973) argues that
“rejecting utterances is just what humans do not.
They try to understand them.” He further states s-
electional restrictions as preferences between the
predicates and arguments, where the violation can
be less preferred, but not fatal. For instance, given
the predicate word eat, word food is likely to be
its object, iPhone is likely to be implausible for it,
and tiger is less preferred but not curious.
SP have been proven to help many natural lan-
guage processing tasks that involve attachment de-
∗Partial of this work was done when the first author vis-
iting at Language Technologies Institute of Carnegie Mellon
University sponsored by the China Scholarship Council.
cisions, such as semantic role labeling (Resnik,
1993; Gildea and Jurafsky, 2002), word sense dis-
ambiguation (Resnik, 1997), human plausibility
judgements (Spasi´c and Ananiadou, 2004), syn-
tactic disambiguation (Toutanova et al., 2005),
word compositionality (McCarthy et al., 2007),
textual entailment (Pantel et al., 2007) and pro-
noun resolution (Bergsma et al., 2008) etc.
A direct approach to acquire SP is to extract
triples (q, r, a) of predicates, relations, and argu-
ments from a syntactically analyzed corpus, and
then conduct maximum likelihood estimation (M-
LE) on the data. However, this strategy is infea-
sible for many plausible triples due to data spar-
sity. For example, given the relation &lt;verb-dobj-
noun&gt; in a corpus, we may see plausible triples:
eat - {food, cake, apple, banana, candy...}
But we may not see plausible and implausible
triples such as:
eat - {watermelon, ziti, escarole, iPhone...}
Then how to use a smooth model to alleviate
data sparsity for SP?
Random walk models have been successful-
ly applied to alleviate the data sparsity issue on
collaborative filtering in recommender systems.
Many online businesses, such as Netflix, Ama-
zon.com, and Facebook, have used recommender
systems to provide personalized suggestions on
the movies, books, or friends that the users may
prefer and interested in (Liben-Nowell and Klein-
berg, 2007; Yildirim and Krishnamoorthy, 2008).
In this paper, we present an extension of using
the random walk model to alleviate data sparsi-
ty for SP. The main intuition is to aggregate all
the transitions from a given predicate to its near-
by predicates, and propagate their preferences on
arguments as the given predicate’s smoothed argu-
</bodyText>
<page confidence="0.969237">
1169
</page>
<note confidence="0.9084145">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1169–1179,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.8973565">
ment preferences. Our work and contributions are
summarized as follows:
</bodyText>
<listItem confidence="0.9433893">
• We present a framework of random walk ap-
proach to SP. It contains four components with
flexible configurations. Each component is cor-
responding to a specific functional operation on
the bipartite and monopartite graphs which rep-
resenting the SP data;
• We propose an adjusted preference ranking
method to measure SP based on the popularity
and association of predicate-argument pairs. It
better correlates with human plausibility judge-
ments. It also helps to discover similar predi-
cates more precisely;
• We introduce a probability function for random
walk based on the predicate distances. It con-
trols the influence of nearby and distant predi-
cates to achieve more accurate results;
• We find out that propagate the measured prefer-
ences of predicate-argument pairs is more prop-
er and natural for SP smooth. It helps to im-
prove the final performance significantly.
</listItem>
<bodyText confidence="0.999952444444445">
We conduct experiments using two sections of
the LDC English gigaword corpora as the general-
ization data. For the pseudo-disambiguation task,
we evaluate it on the Penn TreeBank-3 data. Re-
sults show that our model outperforms several pre-
vious methods. We further investigate the correla-
tions of smoothed scores with human plausibili-
ty judgements. Again our method achieves better
correlations on two third party data.
The remainder of the paper is organized as fol-
lows: Section 2 introduces related work. Section 3
briefly formulates the overall framework of our
method. Section 4 describes the detailed model
configurations, with discussions on their roles and
implications. Section 5 provides experiments on
both the pseudo-disambiguation task and human
plausibility judgements. Finally, Section 6 sum-
marizes the conclusions and future work.
</bodyText>
<sectionHeader confidence="0.999941" genericHeader="related work">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.996351">
2.1 WordNet-based Approach
</subsectionHeader>
<bodyText confidence="0.999962823529412">
Resnik (1996) conducts the pioneer work on
corpus-driven SP induction. For a given predi-
cate q, the system firstly computes its distribution
of argument semantic classes based on WordNet.
Then for a given argument a, the system collects
the set of candidate semantic classes which con-
tain the argument a, and ensures they are seen in
q. Finally the system picks a semantic class from
the candidates with the maximal selectional asso-
ciation score, and defines the score as smoothed
score of (q, a).
Many researchers have followed the so-called
WordNet-based approach to SP. One of the key
issues is to induce the set of argument semantic
classes that are acceptable by the given predicate.
Li and Abe (1998) propose a tree cut model based
on minimal description length (MDL) principle
for the induction of semantic classes. Clark and
Weir (2002) suggest a hypothesis testing method
by ascending the noun hierarchy of WordNet. Cia-
ramita and Johnson (2000) model WordNet as a
Bayesian network to solve the “explain away” am-
biguity. Beyond induction on argument classes on-
ly, Agirre and Martinez (2001) propose a class-to-
class model that simultaneously learns SP on both
the predicate and argument classes.
WordNet-based approach produces human in-
terpretable output, but suffers the poor lexical cov-
erage problem. Gildea and Jurafsky (2002) show
that clustering-based approach has better cover-
age than WordNet-based approach. Brockman-
n and Lapata (2003) find out that sophisticated
WordNet-based methods do not always outperfor-
m simple frequency-based methods.
</bodyText>
<subsectionHeader confidence="0.986251">
2.2 Distributional Models without WordNet
</subsectionHeader>
<bodyText confidence="0.99992995">
Alternatively, Rooth et al. (1999) propose an EM-
based clustering smooth for SP. The key idea is to
use the latent clusterings to take the place of Word-
Net semantic classes. Where the latent clusterings
are automatically derived from distributional da-
ta based on EM algorithm. Recently, more so-
phisticated methods are innovated for SP based on
topic models, where the latent variables (topics)
take the place of semantic classes and distribution-
al clusterings (S´eaghdha, 2010; Ritter et al., 2010).
Without introducing semantic classes and laten-
t variables, Keller and Lapata (2003) use the web
to obtain frequencies for unseen bigrams smooth.
Pantel et al. (2007) apply a collection of rules to
filter out incorrect inferences for SP. Specifically,
Dagan et al. (1999) introduce a general similarity-
based model for word co-occurrence probabilities,
which can be interpreted for SP. Similarly, Erk et
al. propose an argument-oriented similarity model
based on semantic or syntactic vector spaces (Erk,
</bodyText>
<page confidence="0.984322">
1170
</page>
<bodyText confidence="0.9998598">
2007; Erk et al., 2010). They compare several sim-
ilarity functions and weighting functions in their
model. Furthermore, instead of employing various
similarity functions, Bergsma et al. (2008) pro-
pose a discriminative approach to learn the weight-
s between the predicates, based on the verb-noun
co-occurrences and other kinds of features.
Random walk model falls into the non-class
based distributional approach. Previous literatures
have fully studied the selection of distance or sim-
ilarity functions to find out similar predicates and
arguments (Dagan et al., 1999; Erk et al., 2010), or
learn the weights between the predicates (Bergsma
et al., 2008). Instead, we put effort in following
issues: 1) how to measure SP; 2) how to trans-
fer between predicates using random walk; 3) how
to propagate the preferences for smooth. Experi-
ments show these issues are important for SP and
they should be addressed properly to achieve bet-
ter results.
</bodyText>
<sectionHeader confidence="0.965573" genericHeader="method">
3 RSP: A Random Walk Model for SP
</sectionHeader>
<bodyText confidence="0.9978936">
In this section, we briefly introduce how to address
SP using random walk. We propose a framework
of RSP with four components (functions). Each of
them are flexible to be configured. In summary,
Algorithm 1 describes the overall process.
</bodyText>
<listItem confidence="0.941660461538462">
Algorithm 1 RSP: Random walk model for SP
Require: Init bipartite graph G with raw counts
1: // Ranking on the bipartite graph G;
2: R = Ψ(G); // ranking function
3: // Project R to monopartite graph D
4: D = Φ(R); // distance function
5: // Transform D to stochastic matrix P
6: P = ∆(D); // probability function
7: // Get the convergence Pe
8: Pe = ∑∞(dP)t dP(I − dP)−1;
t=1 |(dP) =
9: return Smoothed bipartite graph Re
10: Re = Pe * R; // propagation function
</listItem>
<bodyText confidence="0.747667578947368">
Bipartite Graph Construction: For a giv-
en relation r, the observed predicate-argument
pairs can be represented by a bipartite graph
G=(X, Y, E). Where X={q1, q2,..., q„I are the
m predicates, and Y ={a1, a2, ..., a.I are the n ar-
guments. We initiate the links E with the raw
co-occurrence counts of seen predicate-argument
pairs in a given generalization data. We represent
the graph by an adjacency matrix with rows repre-
senting predicates and columns as arguments. For
convenience, we use indices i, j to represent pred-
icates q,, q�, and k, l for arguments a , at.
We employ a preference ranking function Ψ to
measure the SP between the predicates and argu-
ments. It transforms G to a corresponding bipar-
tite graph R, with links representing the strength
of SP. Each row of the adjacency matrix R denotes
the predicate vector ⃗qi or ⃗qj. We discuss the selec-
tion of Ψ in section 4.1.
</bodyText>
<equation confidence="0.880632">
Ψ := G S R (1)
</equation>
<figureCaption confidence="0.764677">
Figure 1: Illustration of (R) the bipartite
graph of the verb-dobj-noun relation, (Q) the
predicate-projection monopartite graph, and (A)
the argument-projection monopartite graph.
</figureCaption>
<bodyText confidence="0.999032538461538">
Monopartite Graph Projection: In order to
conduct random walk on the graph, we project
the bipartite graph R onto a monopartite graph
Q=(X, E) between the predicates, or A=(Y,E)
between the arguments (Zhou et al., 2007). Fig-
ure 1 illustrates the intuition of the projection. The
links in Q represent the indirect connects between
the predicates in R. Two predicates are connected
in Q if they share at least one common neighbor
argument in R. The weight of the links in Q could
be set by arbitrary distance measures. We refer D
as an instance of the projection Q by a given dis-
tance function Φ.
</bodyText>
<equation confidence="0.997702">
Φ := R S D (2)
</equation>
<bodyText confidence="0.9984085">
Stochastic Walking Strategy: We introduce a
probability function ∆ to transform the predicate
distances D into transition probabilities P. Where
P is a stochastic matrix, with each element pij
represents the transition probability from predicate
qi to qj. Generally speaking, nearby predicates
gain higher probabilities to be visited, while dis-
tant predicates will be penalized.
</bodyText>
<figure confidence="0.98788188">
∆ := D S P (3)
Predicate Projection
Argument Projection
Argument
Nodes
fish chicken
soil
Predicate
Nodes
cook eat consume harvest cultivate irrigate
can food fruit crop flower
cook
eat
consume
irrigate
cultivate
harvest
chicken
flower
fish
fruit
soil
can
food
crop
</figure>
<page confidence="0.98429">
1171
</page>
<bodyText confidence="0.942046416666667">
Follow Equation 4, we aggregate over all orders
of the transition probabilities P as the final sta-
tionary probabilities P. According to the Perron-
Frobenius theory, one can verify that it converges
to dP(I − dP)−1 when P is non-negative and
regular matrix (Li et al., 2009). Where t repre-
sents the orders: the length of the path between
two nodes in terms of edges. The damp factor
d E (0, 1), and its value mainly depends on the da-
ta sparsity level. Typically d prefers small values
such as 0.005. It means higher order transitions
are much less reliable than lower orders (Liben-
Nowell and Kleinberg, 2007).
= dP(I − dP)−1 (4)
Preference Propagation: in Equation 5, we
combine the converged transition probabilities P
with the measured preferences R as the propa-
gation function: 1) for a given predicate, firstly
it transfers to all nearby predicates with designed
probabilities; 2) then it sums over the arguments
preferred by these predicates with quantified s-
cores to get smoothed R. We further describe it-
s configuration details in Section 4.4 and Equa-
tion 12 with two propagation modes.
</bodyText>
<equation confidence="0.99944">
R = P * R (5)
</equation>
<sectionHeader confidence="0.997875" genericHeader="method">
4 Model Configurations
</sectionHeader>
<subsectionHeader confidence="0.9998765">
4.1 Preference Ranking: Measure the
Selectional Preferences
</subsectionHeader>
<bodyText confidence="0.999030555555556">
In collaborative filtering, usually there are explic-
it and scaled user ratings on their item prefer-
ences. For instance, a user ratings a movie with
a scoreE[0,10] on IMDB site. But in SP, the pref-
erences between the predicates and arguments are
implicit: their co-occurrence counts follow the
power law distribution and vary greatly.
Therefore, we employ a ranking function Ψ to
measure the SP of the seen predicate-argument
pairs. We suppose this could bring at least two
benefits: 1) a proper measure on the preferences
can make the discovering of nearby predicates
with similar preferences to be more accurate; 2)
while propagation, we propagate the scored pref-
erences, rather than the raw counts or condition-
al probabilities, which could be more proper and
agree with the nature of SP smooth. We denote
SelPref(q, a) as Pr(q, a) for short.
</bodyText>
<equation confidence="0.501309">
SelPref(q, a) = Ψ(q, a) (6)
</equation>
<bodyText confidence="0.999969866666666">
Previous literatures have well studied on various
smooth models for SP. However, they vary great-
ly on the measure of preferences. It is still not
clear how to do this best. Lapata et al. investigate
the correlations between the co-occurrence counts
(CT) c(q, a), or smoothed counts with the human
plausibility judgements (Lapata et al., 1999; Lap-
ata et al., 2001). Some introduce conditional prob-
ability (CP) p(a|q) for the decision of preference
judgements (Chambers and Jurafsky, 2010; Erk et
al., 2010; S´eaghdha, 2010). Meanwhile, the point-
wise mutual information (MI) is also employed
by many researchers to filter out incorrect infer-
ences (Pantel et al., 2007; Bergsma et al., 2008).
In this paper, we present an adjusted ranking
function (AR) in Equation 8 to measure the SP of
seen predicate-argument pairs. Intuitively, it mea-
sures the preferences by combining both the pop-
ularity and association, with parameters control
the uncertainty of the trade-off between the two.
We define the popularity as the joint probability
p(q, a) based on MLE, and the association as MI.
This is potentially similar to the process of human
plausibility judgements. One may judge the plau-
sibility of a predicate-argument collocation from
two sides: 1) if it has enough evidences and com-
monly to be seen; 2) if it has strong association
according to the cognition based on kinds of back-
ground knowledge. This metric is also similar to
the TF-IDF (TD) used in information retrieval.
</bodyText>
<equation confidence="0.995427">
G(q)pl
(a) (q, a) = p(q, a)α1 α2
p(q, a) /
s.t. α1, α2 E [0, 1]
</equation>
<bodyText confidence="0.999892">
We verify if a metric is better by two tasks:
1) how well it correlates with human plausibility
judgements; 2) how well it helps with the smooth
inference to disambiguate plausible and implausi-
ble instances. We conduct empirical experiments
on these issues in Section 5.3 and Section 5.4.
</bodyText>
<subsectionHeader confidence="0.9905745">
4.2 Distance Function: Projection of the
Monopartite Graph
</subsectionHeader>
<bodyText confidence="0.999819333333333">
In Equation 9, the distance function Φ is used to
discover nearby predicates with distance dzj. It
weights the links on the monopartite graph Q. It
</bodyText>
<equation confidence="0.984323333333333">
�∞
t=1
(dP)t
P=
|(dP)t|
ΨCT = c(q, a) ΨMI = log
= c(q, a) Ψ TD c(q, a)log( n )
ΨCP c(q, *) TD I a|
p(q, a)
p(q)p(a)
(7)
(8)
</equation>
<page confidence="0.876414">
1172
</page>
<bodyText confidence="0.999700666666667">
guides the walker to transfer between predicates.
We calculate Φ based on the vectors ⃗qi, ⃗qj repre-
sented by the measured preferences in R.
</bodyText>
<equation confidence="0.94174">
dij = Φ(⃗qi, ⃗qj) (9)
</equation>
<bodyText confidence="0.999821625">
Where Φ can be distance functions such as Eu-
clidean (norm) distance or Kullback-Leibler diver-
gence (KL) etc., or one minus the similarity func-
tions such as Jaccard and Cosine etc. The selection
of distributional functions has been fully studied
by previous work (Lee, 1999; Erk et al., 2010). In
this paper, we do not focus on this issue due to
page limits. We simply use the Cosine function:
</bodyText>
<equation confidence="0.911179">
∥⃗qi∥∥⃗qj∥ (10)
</equation>
<subsectionHeader confidence="0.659948">
4.3 Probability Function: the Walk Strategy
</subsectionHeader>
<bodyText confidence="0.9999932">
We define the probability function ∆ as Equa-
tion 11. Where the transition probability p(qj|qi)
in P is defined as a function of the distance dij
with a parameter δ. Intuitively, it means in a given
walk step, a predicate qj which is far away from
qi will get much less probability to be visited, and
qi has high probabilities to start walk from itself
and its nearby predicates to pursue good precision.
Once we get the transition matrix P, we can com-
pute P according to Equation 4.
</bodyText>
<equation confidence="0.997174333333333">
p(qj|qi) = ∆(dij) = (1 − dij)δ
Z(qi)
s.t. δ ≥ 0, dij ∈ [0, 1]
</equation>
<bodyText confidence="0.999969">
Where the parameter δ is used to control the bal-
ance of nearby and distant predicates. Z(qi) is the
normalize factor. Typically, δ around 2 can pro-
duce good enough results in most cases. We verify
the settings of δ in section 5.3.2.
</bodyText>
<subsectionHeader confidence="0.997017">
4.4 Propagation Function
</subsectionHeader>
<bodyText confidence="0.9995215">
The propagation function in Equation 5 is repre-
sented by the matrix form. It can be expanded and
rewritten as Equation 12. Where p(qj|qi) is the
converged transition probability from predicate qi
to qj. Pr(ak, qj) is the measured preference of
predicate qj with argument ak.
</bodyText>
<equation confidence="0.932739">
Pr(ak, qi) = �m �p(qj|qi) · Pr(ak, qj) (12)
j=1
</equation>
<bodyText confidence="0.9999552">
We employ two propagation modes (PropMode)
for the preference propagation function. One is
’CP’ mode. In this mode, we always set Pr(q, a)
as the conditional probability p(a|q) for the prop-
agation function, despite what Ψ is used for the
distance function. This mode is similar to previ-
ous methods (Dagan et al., 1999; Keller and Lap-
ata, 2003; Bergsma et al., 2008). The other is ’PP’
mode. We set ranking function Ψ=Pr(q, a) always
to be the same in both the distance function and the
propagation function. That means what we propa-
gated is the designed and scored preferences. This
could be more proper and agree with the nature
of SP smooth. We show the improvement of this
extension in section 5.3.1.
</bodyText>
<sectionHeader confidence="0.999668" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.964363">
5.1 Data Set
</subsectionHeader>
<bodyText confidence="0.999433333333333">
Generalization Data: We parsed the Agence
France-Presse (AFP) and New York Times (NYT)
sections of the LDC English Gigaword corpo-
ra (Parker et al., 2011), each from year 2001-2010.
The parser is provided by the Stanford CoreNLP
package1. We filter out all tokens containing
non-alphabetic characters, collect the &lt;verb-dobj-
noun &gt; triples from the syntactically analyzed da-
ta. Predicates (verbs) whose frequency lower than
30 and arguments (noun headwords) whose fre-
quency less than 5 are excluded out. No other fil-
ters have been done. The resulting data consist of:
</bodyText>
<listItem confidence="0.9375788">
• AFP: 26,118, 892 verb-dobj-noun observa-
tions with 1, 918, 275 distinct triples, totally
4, 771 predicates and 44, 777 arguments.
• NYT: 29,149, 574 verb-dobj-noun observa-
tions with 3, 281,391 distinct triples, totally
</listItem>
<bodyText confidence="0.974197923076923">
5, 782 predicates and 57, 480 arguments.
Test Data: For pseudo-disambiguation, we em-
ploy Penn TreeBank-3 (PTB) as the test data (Mar-
cus et al., 1999)2. We collect the 36,400 manu-
ally annotated verb-dobj-noun dependencies (with
23,553 distinct ones) from PTB. We keep depen-
dencies whose predicates and arguments are seen
in the generalization data. We randomly selec-
t 20% of these dependencies as the test set. We
split the test set equally into two parts: one as the
development set and the other as the final test set.
Human Plausibility Judgements Data: We
employ two human plausibility judgements data
</bodyText>
<footnote confidence="0.972204">
1http://nlp.stanford.edu/software/corenlp.shtml
2PTB includes 2, 499 stories from the Wall Street Journal
(WSJ). It is different with our two generalization data.
</footnote>
<equation confidence="0.94765925">
Φcosine(⃗qi, ⃗qj) = 1
⃗qi ·
⃗qj
(11)
</equation>
<page confidence="0.796963">
1173
</page>
<bodyText confidence="0.999926375">
for the correlation evaluation. In each they col-
lect a set of predicate-argument pairs, and anno-
tate with two kinds of human ratings: one for an
argument takes the role as the patient of a predi-
cate, and the other for the argument as the agent.
The rating values are between 1 and 7: e.g. they
assign hunter-subj-shoot with a rating 6.9 but 2.8
for shoot-dobj-hunter.
</bodyText>
<listItem confidence="0.837777909090909">
• PBP: Pad´o et al. (2007) develop a set of hu-
man plausibility ratings on the basis of the
Penn TreeBank and FrameNet respectively.
We refer PBP as their 212 patient ratings
from the Penn TreeBank.
• MRP: This data are originally contributed by
McRae et al. (1998). We use all their 723
patient-nn ratings.
Without explicit explanation, we remove all the
selected PTB tests and human plausibility pairs
from AFP and NYT to treat them unseen.
</listItem>
<subsectionHeader confidence="0.937646">
5.2 Comparison Methods
</subsectionHeader>
<bodyText confidence="0.999989583333333">
Since RSP falls into the unsupervised distribu-
tional approach, we compare it with previous
similarity-based methods and unsupervised gener-
ative topic model 3.
Erk et al. (Erk, 2007; Erk et al., 2010) are
the pioneers to address SP using similarity-based
method. For a given (q, a) in relation r, the mod-
el sums over the similarities between a and the
seen headwords a′ E Seen(q, r). They investi-
gated several similarity functions sim(a, a′) such
as Jaccard, Cosine, Lin, and nGCM etc., and dif-
ferent weighting functions wtq,r(a′).
</bodyText>
<equation confidence="0.9896505">
�S(q, r, a) =
a′
</equation>
<bodyText confidence="0.9998229">
For comparison, we suppose the primary cor-
pus and generalization corpus in their model to be
the same. We set the similarity function of their
model as nGCM, use both the FREQ and DISCR
weighting functions. The vector space is in SYN-
PRIMARY setting with 2, 000 basis elements.
Dagan et al. (1999) propose state-of-the-art
similarity based model for word co-occurrence
probabilities. Though it is not intended for SP, but
it can be interpreted and rewritten for SP as:
</bodyText>
<equation confidence="0.970834">
sim(q, q′)
Z(q) p(a|q′) (14)
</equation>
<footnote confidence="0.870663">
3The implementation of RSP and listed previous methods
are available at https://github.com/ZhenhuaTian/RSP
</footnote>
<bodyText confidence="0.999868826086956">
They use the k-closest nearbys as Simset(q),
with a parameter 0 to revise the similarity func-
tion. For comparison, we use the Jensen-Shannon
divergence (Lin, 1991) which shows the best per-
formance in their work as sim(q, q′), and optimize
the settings of k and 0 in our experiments.
LDA-SP: Another kind of sophisticated unsu-
pervised approaches for SP are latent variable
models based on Latent Dirichlet Allocation (L-
DA). O´ S´eaghdha (2010) applies topic models
for the SP induction with three variations: LDA,
Rooth-LDA, and Dual-LDA; Ritter et al. (2010)
focus on inferring latent topics and their distribu-
tions over multiple arguments and relations (e.g.,
the subject and direct object of a verb).
In this work, we compare with O´ S´eaghdha’s
original LDA approach to SP. We use the Mat-
lab Topic Modeling Toolbox4 for the inference
of latent topics. The hyper parameters are set as
suggested α=50/T and 0=200/n, where T is the
number of topics and n is the number of argu-
ments. We test T=100, 200, 300, each with 1, 000
iterations of Gibbs sampling.
</bodyText>
<subsectionHeader confidence="0.997774">
5.3 Pseudo-Disambiguation
</subsectionHeader>
<bodyText confidence="0.992747">
Pseudo-disambiguation has been used for SP e-
valuation by many researchers (Rooth et al., 1999;
Erk, 2007; Bergsma et al., 2008; Chambers and
Jurafsky, 2010; Ritter et al., 2010). First the sys-
tem removes a portion of seen predicate-argument
pairs from the generalization data to treat them as
unseen positive tests (q, a+). Then it introduces
confounder selection to create a pseudo negative
test (q, a−) for each positive (q, a+). Finally it
evaluates a SP model by how well the model dis-
ambiguates these positive and negative tests.
Confounder Selection: for a given (q, a+), the
system selects an argument a′ from the argumen-
t vocabulary. Then by ensure (q, a′) is unseen in
the generalization data, it treats a′ as pseudo a−.
This process guarantees that (q, a−) to be negative
in real case with very high probability. Previous
work have made advances on confounder selec-
tion with random, bucket and nearest confounder-
s. Random confounder (RND) most closes to the
realistic case; While nearest confounder (NER) is
reproducible and it avoids frequency bias (Cham-
bers and Jurafsky, 2010).
In this work, we employ both RND and NER
confounders: 1) for RND, we randomly select
</bodyText>
<equation confidence="0.935392">
4psiexp.ss.uci.edu/research/programs data/toolbox.htm
wtq,r(a′) · sim(a, a′) (13)
Zq,r
�
Pr(a|q) =
q′ESimset(q)
</equation>
<page confidence="0.948816">
1174
</page>
<bodyText confidence="0.997241454545455">
confounders according to the occurrence probabil-
ity of arguments. We sample confounders on both
the development and final test data with 100 itera-
tions. 2) for NER, firstly we sort the arguments by
their frequency. Then we select the nearest con-
founders with two iterations. One iteration selects
the confounder whose frequency is more than or
equal to a+, and the other iteration with frequency
lower than or equal to a+.
Evaluation Metric: we evaluate performance
on both the pairwise and pointwise settings:
</bodyText>
<listItem confidence="0.877877105263158">
1) On pairwise setting, we combine correspond-
ing (q, a+, a−) together as test instances. The per-
formance is evaluated based on the accuracy (AC-
C) metric. It computes the portion of test instances
(q, a+, a−) which correctly predicted by the s-
mooth model with score(q, a+) &gt; score(q, a−).
We weight each instance equally for macroACC,
and weight each by the frequency of the positive
pair (q, a+) for microACC.
2) On pointwise setting, we use each positive
test (q, a+) or negative test (q, a−) as test in-
stances independently. We treat it as a binary
classification task, and evaluate using the standard
area-under-the-curve (AUC) metric. This metric
is firstly employed for the SP evaluation by Ritter
et al (2010). For macroAUC, we weight each in-
stance equally; for microAUC, we weight each by
its argument frequency (Bergsma et al., 2008).
Parameters Tuning: The parameters are tuned
</listItem>
<bodyText confidence="0.985871714285714">
on the PTB development set, using AFP as the
generalization data. We report the overall perfor-
mance on the final test set. While using NYT as
the generalization data, we hold the same parame-
ter settings as AFP to ensure the results are robust.
Note that indeed the parameter settings would vary
among different generalization and test data.
</bodyText>
<subsectionHeader confidence="0.9670595">
5.3.1 Verify Ranking Function and
Propagation Method
</subsectionHeader>
<bodyText confidence="0.9999665">
This experiment is conducted on the PTB devel-
opment set with RND confounders. We use AFP
and NYT as the generalization data. For compari-
son, we set the distance function Φ as Cosine, with
default d=0.005, and S=1.
In Table 1, the evaluation metric is Accuracy.
The first 4 rows are the results of ’CP’ PropMode,
and the latter 3 rows are the ’PP’ PropMode. With
respect to the ranking function T, CP performs
the worst as it considers only the popularity rather
than association. The heavy bias on frequent pred-
icates and arguments has two major drawbacks: a)
The computation of predicate distances would re-
ly much more on frequent arguments, rather than
those arguments they preferred; b) While propaga-
tion, it may bias more on frequent arguments, too.
Even these frequent arguments are less preferred
and not proper to be propagated.
</bodyText>
<table confidence="0.999069444444444">
Crit. AFP NYT
macro micro macro micro
TCP 71.7 76.7 78.2 81.2
TMI 70.9 75.8 79.1 81.8
TTD 73.4 78.2 80.9 83.4
TAR 72.9 77.8 81.0 83.5
TMI 76.8 80.6 81.9 83.8
TT D 74.4 79.1 81.8 84.2
TAR 82.5 85.2 87.7 88.6
</table>
<tableCaption confidence="0.999974">
Table 1: Comparing different ranking functions.
</tableCaption>
<bodyText confidence="0.9998406">
For MI, it biases infrequent arguments with
strong association, without regarding to the popu-
lar arguments with more evidences. Furthermore,
the generalization data is automatically parsed and
kind of noisy, especially on infrequent predicates
and arguments. The noises could yield unreliable
estimations and decrease the performance. For T-
D, it outperforms MI method on ’CP’ PropMode,
but it not always outperforms MI on ’PP’ Prop-
Mode. It is no surprise to find out the adjusted
ranking AR achieves better results on both AFP
and NYT data, with α1=0.2 and α2=0.6. Finally,
it shows the ’PP’ mode, which propagating the de-
signed preference scores, gains significantly better
performance as discussed in Section 4.4.
</bodyText>
<subsectionHeader confidence="0.882957">
5.3.2 Verify S of the Probability Function
</subsectionHeader>
<bodyText confidence="0.999862333333333">
This experiment is conducted on the PTB develop-
ment tests with both RND and NER confounders.
The generalization data is AFP.
</bodyText>
<page confidence="0.5248022">
90
88
86
84
82
</page>
<footnote confidence="0.668804">
RND macro accuracy
RND micro accuracy
NER macro accuracy
NER micro accuracy
760 0.5 1 1.5 2 2.5 3 3.5 4 4.5
delta
</footnote>
<figureCaption confidence="0.995035">
Figure 2: Performance variation on different S.
</figureCaption>
<figure confidence="0.604215666666667">
accuracy (%)
80
78
</figure>
<page confidence="0.960208">
1175
</page>
<table confidence="0.999912181818182">
Criterion AFP NYT
RND NER RND NER
macro micro macro micro macro micro macro micro
Erk et al. FREQ 73.7 73.6 73.9 73.6 68.3 68.4 63.8 63.0
Erk et al.DZSCR 76.0 78.3 79.1 78.1 83.3 84.2 82.4 82.6
Dagan et al. 80.6 82.8 84.7 85.0 87.0 87.6 86.9 87.3
LDA-SP 82.0 83.5 83.7 82.9 89.1 89.0 87.9 87.8
RSPnaive 72.6 76.4 79.4 81.1 78.5 80.4 74.8 78.0
+Rank 74.0 77.7 83.5 85.2 81.4 83.1 84.5 86.9
+Rank+PP 83.5 85.2 87.2 87.0 88.2 88.2 88.0 88.3
+Rank+PP+Delta 86.2 87.3 88.4 88.1 90.6 90.1 91.1 89.3
</table>
<tableCaption confidence="0.998706">
Table 2: Pseudo-disambiguation results of different smooth models. Macro and micro Accuracy.
</tableCaption>
<figure confidence="0.995981208333333">
False Positive (FP)
False Positive (FP)
True Positive (TP)
0.8
0.6
0.4
0.2
00 0.2 0.4 0.6 0.8 1
1
Erk et al. macroAUC=0.72
Dagan et al. macroAUC=0.80
LDA−SP macroAUC=0.77
RSP−ALL macroAUC=0.84
1
True Positive (TP)
0.2
Erk et al. microAUC=0.62
Dagan et al. microAUC=0.83
LDA−SP microAUC=0.73
RSP−ALL microAUC=0.89
00 0.2 0.4 0.6 0.8 1
0.8
0.6
0.4
</figure>
<figureCaption confidence="0.999987">
Figure 3: Marco and micro ROC curves of different smooth models.
</figureCaption>
<bodyText confidence="0.99999575">
We set the ranking function Ψ as AR (with
tuned α1=0.2 and α2=0.6), the distance function
Φ as Cosine, default d=0.005, and we restrict 6 ∈
[0.5, 4]. Figure 2 shows 6 has significant impact
on the performance. Starting from 6=0.5, the sys-
tem gains better performance while 6 increasing.
It achieves good results around 6=2. This mean-
s for a given predicate, the penalty on its distant
predicates helps to get more accurate smooth. The
performance will drop if 6 becomes too big. This
means closest predicates are useful for smooth. It
it not better to penalize them heavily.
</bodyText>
<subsectionHeader confidence="0.786041">
5.3.3 Overall Performance
</subsectionHeader>
<bodyText confidence="0.9999432">
Finally we compare the overall performance of d-
ifferent models. We report the results on the PTB
final test set, with RND and NER confounders.
Table 2 shows the overall performance on Accu-
racy metric. Among previous methods in the first
4 rows, LDA-SP performs the best in most cas-
es. In the last 4 rows, RSPnaive means both the
ranking function and PropMode are set as ’CP’
and 6=1. This configuration yields poor perfor-
mance. Iteratively, by employing the adjusted
ranking function, smoothing with preference prop-
agation method, and revising the probability func-
tion with the parameter 6, RSP outperforms all
previous methods. The parameter settings of RSP-
All are α1=0.2, α2=0.6, 6=1.75 and d=0.005.
Figure 3 show the macro (left) and micro (right)
receiver-operating-characteristic (ROC) curves of
different models, using AFP as the generalization
data and RND confounders. For each kind of
previous methods, we show the best AUC they
achieved. RASP-All still performs the best on
the terms of AUC metric, achieving macroAUC
at 84% and microAUC at 89%. We also verified
the AUC metric using NYT as the generalization
data. The results are similar to the AFP data. It
is also interesting to find out that the ACC met-
ric is not always bring into correspondence with
the AUC metric. The difference mainly raise on
the pointwise and pairwise test settings of pseudo-
disambiguation.
</bodyText>
<subsectionHeader confidence="0.986366">
5.4 Human Plausibility Judgements
</subsectionHeader>
<bodyText confidence="0.999708">
We conduct empirical studies on the correla-
tions between different preference ranking func-
</bodyText>
<page confidence="0.969684">
1176
</page>
<table confidence="0.999892714285714">
Criterion AFP NYT
Spearman’s ρ Kendall’s T Spearman’s ρ Kendall’s T
PBP MRP PBP MRP PBP MRP PBP MRP
CT 0.49 0.36 0.37 0.28 0.54 0.44 0.41 0.34
CP 0.47 0.39 0.35 0.30 0.51 0.48 0.39 0.37
MI 0.56 0.39 0.43 0.31 0.54 0.49 0.41 0.38
TD 0.53 0.36 0.39 0.28 0.56 0.45 0.42 0.34
AR 0.58 0.40 0.44 0.31 0.58 0.50 0.44 0.39
Erk et al. FREQ 0.30 0.08 0.22 0.06 0.25 0.09 0.18 0.06
Erk et al.DZSCR 0.06 0.21 0.04 0.15 0.16 0.23 0.11 0.16
Dagan et al. 0.32 0.24 0.24 0.18 0.46 0.29 0.34 0.21
LDA-SP 0.31 0.32 0.23 0.23 0.38 0.38 0.28 0.28
LDA-SP+Bayes 0.39 0.25 0.30 0.18 0.40 0.32 0.30 0.23
RSP-All 0.46 0.31 0.34 0.23 0.53 0.38 0.40 0.28
</table>
<tableCaption confidence="0.999869">
Table 3: Correlation results on the human plausibility judgements data.
</tableCaption>
<bodyText confidence="0.999469242424242">
tions and human ratings. Follow Lapata et
al. (2001), we first collect the co-occurrence
counts of predicate-argument pairs in the human
plausibility data from AFP and NYT (before re-
moving them as unseen pairs). Then we score
them with different ranking functions (described
in Section 4.1) based on MLE. Inspired by Erk et
al. (2010), we do not suppose linear correlations
between the estimated scores and human ratings.
We use the Spearman’s ρ and Kendal’s T rank
correlation coefficient.
We also compare the correlations between the
smoothed scores of different models with human
ratings. With respect to upper bounds, Pad´o et
al. (2007) suggest that the typical agreement of
human participants is around a correlation of 0.7
on their plausibility data. We hold that automatic
models of plausibility can not be expected to sur-
pass this upper bound.
In Table 3, all coefficients are verified at signif-
icant level p&lt;0.01. The first 5 rows are the corre-
lations between the preference ranking function-
s and human ratings based on MLE. On both the
PBP and MRP data, the proposed AR metric better
correlates with human ratings than others, with α2
&gt;0.5 and α1 around [0.2, 0.35]. The latter 6 rows
are the results of smooth models. It shows LDA-
SP performs good correlation with human ratings,
where LDA-SP+Bayes refers to the Bayes predic-
tion method of Ritter et al. (2010). RSP model
gains the best correlation on the two plausibility
data in most cases, where the parameter settings
are the same as pseudo-disambiguation.
</bodyText>
<sectionHeader confidence="0.999075" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999984882352941">
In this work we present an random walk approach
to SP. Experiments show it is efficient and effec-
tive to address data sparsity for SP. It is also flex-
ible to be applied to new data. We find out that a
proper measure on SP between the predicates and
arguments is important for SP. It helps with the
discovering of nearby predicates and it makes the
preference propagation to be more accurate. An-
other issue is that it is not good enough to direct-
ly applies the similarity or distance functions for
smooth. Potential future work including but not
limited to follows: investigate argument-oriented
and personalized random walk, extend the model
in heterogenous network with multiple link types,
discover soft clusters using random walk for se-
mantic induction, and combine it with discrimina-
tive learning approach etc.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998102">
The research is supported in part by the Na-
tional High Technology Research and Devel-
opment Program 863 of China under Grant
No.2012AA011003; Key Projects in the Nation-
al Science and Technology Pillar Program under
Grant No.2011BAK08B02; Chinese Government
Graduate Student Overseas Study Program spon-
sored by the China Scholarship Council (CSC).
We also gratefully acknowledge the anonymous
reviewers for their helpful comments.
</bodyText>
<page confidence="0.993809">
1177
</page>
<sectionHeader confidence="0.990243" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999935883495146">
Eneko Agirre and David Martinez. 2001. Learning
class-to-class selectional preferences. In Proceed-
ings of the 2001 workshop on Computational Natu-
ral Language Learning.
Shane Bergsma, Dekang Lin, and Randy Goebel.
2008. Discriminative learning of selectional pref-
erence from unlabeled text. In EMNLP.
Carsten Brockmann and Mirella Lapata. 2003. Evalu-
ating and combining approaches to selectional pref-
erence acquisition. In EACL.
Nathanael Chambers and Dan Jurafsky. 2010. Improv-
ing the use of pseudo-words for evaluating selection-
al preferences. In ACL.
Massimiliano Ciaramita and Mark Johnson. 2000. Ex-
plaining away ambiguity: Learning verb selectional
preference with bayesian networks. In COLING.
Stephen Clark and David J. Weir. 2002. Class-based
probability estimation using a semantic hierarchy.
Computational Linguistics, 28(2):187–206.
Ido Dagan, Lillian Lee, and Fernando C. N. Pereira.
1999. Similarity-Based Models of Word Cooccur-
rence Probabilities. Machine Learning, 34:43–69.
Katrin Erk, Sebastian Pad´o, and Ulrike Pad´o. 2010. A
flexible, corpus-driven model of regular and inverse
selectional preferences. Computational Linguistics,
36(4):723–763.
Katrin Erk. 2007. A simple, similarity-based model
for selectional preferences. In ACL.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic
labeling of semantic roles. Computational Linguis-
tics, 28(3):245–288.
Jerrold J. Katz and Jerry A. Fodor. 1963. The structure
of a semantic theory. Language, 39(2):170–210.
Frank Keller and Mirella Lapata. 2003. Using the web
to obtain frequencies for unseen bigrams. Computa-
tional Linguistics, 29(3):459–484.
Maria Lapata, Scott McDonald, and Frank Keller.
1999. Determinants of adjective-noun plausibility.
In EACL, pages 30–36. Association for Computa-
tional Linguistics.
Maria Lapata, Frank Keller, and Scott McDonald.
2001. Evaluating smoothing algorithms against
plausibility judgements. In ACL, pages 354–361.
Association for Computational Linguistics.
Lillian Lee. 1999. Measures of distributional similar-
ity. In ACL, pages 25–32, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Hang Li and Naoki Abe. 1998. Generalizing case
frames using a thesaurus and the mdl principle.
Computational linguistics, 24(2):217–244.
Ming Li, Benjamin M Dias, Ian Jarman, Wael El-
Deredy, and Paulo JG Lisboa. 2009. Grocery shop-
ping recommendations based on basket-sensitive
random walk. In SIGKDD, pages 1215–1224.
ACM.
David Liben-Nowell and Jon Kleinberg. 2007. The
link-prediction problem for social networks. Jour-
nal of the American society for information science
and technology, 58(7):1019–1031.
Jianhua Lin. 1991. Divergence measures based on the
shannon entropy. IEEE Transactions on Information
Theory, 37(1):145–151.
Mitchell P. Marcus, Beatrice Santorini, Mary Ann
Marcinkiewicz, and Ann Taylor. 1999. Treebank-
3.
Diana McCarthy, Sriram Venkatapathy, and Aravind K.
Joshi. 2007. Detecting compositionality of verb-
object combinations using selectional preferences.
In EMNLP-CoNLL.
Ken McRae, Michael J. Spivey-Knowltonb, and
Michael K. Tanenhausc. 1998. Modeling the influ-
ence of thematic fit (and other constraints) in on-line
sentence comprehension. Journal of Memory and
Language, 38(3):283–312.
Sebastian Pad´o, Ulrike Pad´o, and Katrin Erk. 2007.
Flexible, corpus-based modelling of human plausi-
bility judgements. In EMNLP/CoNLL, volume 7.
Patrick Pantel, Rahul Bhagat, Bonaventura Coppola,
Timothy Chklovski, and Eduard Hovy. 2007. Is-
p: Learning inferential selectional preferences. In
NAACL-HLT.
Robert Parker, David Graff, Junbo Kong, Ke Chen, and
Kazuaki Maeda. 2011. English gigaword fifth edi-
tion.
Philip Resnik. 1993. Selection and information: a
class-based approach to lexical relationships. IRCS
Technical Reports Series.
Philip Resnik. 1996. Selectional constraints: An
information-theoretic model and its computational
realization. Cognition, 61(1):127–159.
Philip Resnik. 1997. Selectional preference and sense
disambiguation. In Proceedings of the ACL SIGLEX
Workshop on Tagging Text with Lexical Semantics:
Why, What, and How. Washington, DC.
Alan Ritter, Mausam, and Oren Etzioni. 2010. A la-
tent dirichlet allocation method for selectional pref-
erences. In ACL.
Mats Rooth, Stefan Riezler, Detlef Prescher, Glenn
Carroll, and Franz Beil. 1999. Inducing a semanti-
cally annotated lexicon via em-based clustering. In
ACL.
Diarmuid O´ S´eaghdha. 2010. Latent variable models
of selectional preference. In ACL.
</reference>
<page confidence="0.86699">
1178
</page>
<reference confidence="0.99799635">
Irena Spasi´c and Sophia Ananiadou. 2004. Us-
ing automatically learnt verb selectional preferences
for classification of biomedical terms. Journal of
Biomedical Informatics, 37(6):483–497.
Kristina Toutanova, Christopher D. Manning, Dan
Flickinger, and Stephan Oepen. 2005. Stochas-
tic hpsg parse disambiguation using the redwood-
s corpus. Research on Language &amp; Computation,
3(1):83–105.
Yorick Wilks. 1973. Preference semantics. Technical
report, DTIC Document.
Hilmi Yildirim and Mukkai S. Krishnamoorthy. 2008.
A random walk method for alleviating the sparsity
problem in collaborative filtering. In Proceedings of
the 2008 ACM conference on Recommender system-
s, pages 131–138. ACM.
Tao Zhou, Jie Renan, Mat´uˇs Medo, and Yi-Cheng
Zhang. 2007. Bipartite network projection and
personal recommendation. Physical Review E,
76(4):046115.
</reference>
<page confidence="0.996948">
1179
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.346050">
<title confidence="0.7798475">A Random Walk Approach to Selectional Preferences Based Ranking and Hengheng Xiang, Ziqi Liu, Qinghua Ministry of Education Key Lab for Intelligent Networks and Network</title>
<affiliation confidence="0.9652215">Department of Computer Science and Xi’an Jiaotong</affiliation>
<address confidence="0.977298">Xi’an, Shaanxi 710049,</address>
<abstract confidence="0.994537333333333">This paper presents an unsupervised random walk approach to alleviate data sparsity for selectional preferences. Based on the measure of preferences between predicates and arguments, the model aggregates all the transitions from a given predicate to its nearby predicates, and propagates their argument preferences as the given predicate’s smoothed preferences. Experimental results show that this approach outperforms several state-of-the-art methods on the pseudo-disambiguation task, and it better correlates with human plausibility judgements.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>David Martinez</author>
</authors>
<title>Learning class-to-class selectional preferences.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2001 workshop on Computational Natural Language Learning.</booktitle>
<contexts>
<context position="6808" citStr="Agirre and Martinez (2001)" startWordPosition="1044" endWordPosition="1047">smoothed score of (q, a). Many researchers have followed the so-called WordNet-based approach to SP. One of the key issues is to induce the set of argument semantic classes that are acceptable by the given predicate. Li and Abe (1998) propose a tree cut model based on minimal description length (MDL) principle for the induction of semantic classes. Clark and Weir (2002) suggest a hypothesis testing method by ascending the noun hierarchy of WordNet. Ciaramita and Johnson (2000) model WordNet as a Bayesian network to solve the “explain away” ambiguity. Beyond induction on argument classes only, Agirre and Martinez (2001) propose a class-toclass model that simultaneously learns SP on both the predicate and argument classes. WordNet-based approach produces human interpretable output, but suffers the poor lexical coverage problem. Gildea and Jurafsky (2002) show that clustering-based approach has better coverage than WordNet-based approach. Brockmann and Lapata (2003) find out that sophisticated WordNet-based methods do not always outperform simple frequency-based methods. 2.2 Distributional Models without WordNet Alternatively, Rooth et al. (1999) propose an EMbased clustering smooth for SP. The key idea is to </context>
</contexts>
<marker>Agirre, Martinez, 2001</marker>
<rawString>Eneko Agirre and David Martinez. 2001. Learning class-to-class selectional preferences. In Proceedings of the 2001 workshop on Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Dekang Lin</author>
<author>Randy Goebel</author>
</authors>
<title>Discriminative learning of selectional preference from unlabeled text.</title>
<date>2008</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="2371" citStr="Bergsma et al., 2008" startWordPosition="340" endWordPosition="343">proven to help many natural language processing tasks that involve attachment de∗Partial of this work was done when the first author visiting at Language Technologies Institute of Carnegie Mellon University sponsored by the China Scholarship Council. cisions, such as semantic role labeling (Resnik, 1993; Gildea and Jurafsky, 2002), word sense disambiguation (Resnik, 1997), human plausibility judgements (Spasi´c and Ananiadou, 2004), syntactic disambiguation (Toutanova et al., 2005), word compositionality (McCarthy et al., 2007), textual entailment (Pantel et al., 2007) and pronoun resolution (Bergsma et al., 2008) etc. A direct approach to acquire SP is to extract triples (q, r, a) of predicates, relations, and arguments from a syntactically analyzed corpus, and then conduct maximum likelihood estimation (MLE) on the data. However, this strategy is infeasible for many plausible triples due to data sparsity. For example, given the relation &lt;verb-dobjnoun&gt; in a corpus, we may see plausible triples: eat - {food, cake, apple, banana, candy...} But we may not see plausible and implausible triples such as: eat - {watermelon, ziti, escarole, iPhone...} Then how to use a smooth model to alleviate data sparsity</context>
<context position="8508" citStr="Bergsma et al. (2008)" startWordPosition="1299" endWordPosition="1302">003) use the web to obtain frequencies for unseen bigrams smooth. Pantel et al. (2007) apply a collection of rules to filter out incorrect inferences for SP. Specifically, Dagan et al. (1999) introduce a general similaritybased model for word co-occurrence probabilities, which can be interpreted for SP. Similarly, Erk et al. propose an argument-oriented similarity model based on semantic or syntactic vector spaces (Erk, 1170 2007; Erk et al., 2010). They compare several similarity functions and weighting functions in their model. Furthermore, instead of employing various similarity functions, Bergsma et al. (2008) propose a discriminative approach to learn the weights between the predicates, based on the verb-noun co-occurrences and other kinds of features. Random walk model falls into the non-class based distributional approach. Previous literatures have fully studied the selection of distance or similarity functions to find out similar predicates and arguments (Dagan et al., 1999; Erk et al., 2010), or learn the weights between the predicates (Bergsma et al., 2008). Instead, we put effort in following issues: 1) how to measure SP; 2) how to transfer between predicates using random walk; 3) how to pro</context>
<context position="15084" citStr="Bergsma et al., 2008" startWordPosition="2416" endWordPosition="2419"> SP. However, they vary greatly on the measure of preferences. It is still not clear how to do this best. Lapata et al. investigate the correlations between the co-occurrence counts (CT) c(q, a), or smoothed counts with the human plausibility judgements (Lapata et al., 1999; Lapata et al., 2001). Some introduce conditional probability (CP) p(a|q) for the decision of preference judgements (Chambers and Jurafsky, 2010; Erk et al., 2010; S´eaghdha, 2010). Meanwhile, the pointwise mutual information (MI) is also employed by many researchers to filter out incorrect inferences (Pantel et al., 2007; Bergsma et al., 2008). In this paper, we present an adjusted ranking function (AR) in Equation 8 to measure the SP of seen predicate-argument pairs. Intuitively, it measures the preferences by combining both the popularity and association, with parameters control the uncertainty of the trade-off between the two. We define the popularity as the joint probability p(q, a) based on MLE, and the association as MI. This is potentially similar to the process of human plausibility judgements. One may judge the plausibility of a predicate-argument collocation from two sides: 1) if it has enough evidences and commonly to be</context>
<context position="18664" citStr="Bergsma et al., 2008" startWordPosition="3054" endWordPosition="3057"> form. It can be expanded and rewritten as Equation 12. Where p(qj|qi) is the converged transition probability from predicate qi to qj. Pr(ak, qj) is the measured preference of predicate qj with argument ak. Pr(ak, qi) = �m �p(qj|qi) · Pr(ak, qj) (12) j=1 We employ two propagation modes (PropMode) for the preference propagation function. One is ’CP’ mode. In this mode, we always set Pr(q, a) as the conditional probability p(a|q) for the propagation function, despite what Ψ is used for the distance function. This mode is similar to previous methods (Dagan et al., 1999; Keller and Lapata, 2003; Bergsma et al., 2008). The other is ’PP’ mode. We set ranking function Ψ=Pr(q, a) always to be the same in both the distance function and the propagation function. That means what we propagated is the designed and scored preferences. This could be more proper and agree with the nature of SP smooth. We show the improvement of this extension in section 5.3.1. 5 Experiments 5.1 Data Set Generalization Data: We parsed the Agence France-Presse (AFP) and New York Times (NYT) sections of the LDC English Gigaword corpora (Parker et al., 2011), each from year 2001-2010. The parser is provided by the Stanford CoreNLP packag</context>
<context position="23818" citStr="Bergsma et al., 2008" startWordPosition="3909" endWordPosition="3912">pics and their distributions over multiple arguments and relations (e.g., the subject and direct object of a verb). In this work, we compare with O´ S´eaghdha’s original LDA approach to SP. We use the Matlab Topic Modeling Toolbox4 for the inference of latent topics. The hyper parameters are set as suggested α=50/T and 0=200/n, where T is the number of topics and n is the number of arguments. We test T=100, 200, 300, each with 1, 000 iterations of Gibbs sampling. 5.3 Pseudo-Disambiguation Pseudo-disambiguation has been used for SP evaluation by many researchers (Rooth et al., 1999; Erk, 2007; Bergsma et al., 2008; Chambers and Jurafsky, 2010; Ritter et al., 2010). First the system removes a portion of seen predicate-argument pairs from the generalization data to treat them as unseen positive tests (q, a+). Then it introduces confounder selection to create a pseudo negative test (q, a−) for each positive (q, a+). Finally it evaluates a SP model by how well the model disambiguates these positive and negative tests. Confounder Selection: for a given (q, a+), the system selects an argument a′ from the argument vocabulary. Then by ensure (q, a′) is unseen in the generalization data, it treats a′ as pseudo </context>
<context position="26337" citStr="Bergsma et al., 2008" startWordPosition="4325" endWordPosition="4328">tly predicted by the smooth model with score(q, a+) &gt; score(q, a−). We weight each instance equally for macroACC, and weight each by the frequency of the positive pair (q, a+) for microACC. 2) On pointwise setting, we use each positive test (q, a+) or negative test (q, a−) as test instances independently. We treat it as a binary classification task, and evaluate using the standard area-under-the-curve (AUC) metric. This metric is firstly employed for the SP evaluation by Ritter et al (2010). For macroAUC, we weight each instance equally; for microAUC, we weight each by its argument frequency (Bergsma et al., 2008). Parameters Tuning: The parameters are tuned on the PTB development set, using AFP as the generalization data. We report the overall performance on the final test set. While using NYT as the generalization data, we hold the same parameter settings as AFP to ensure the results are robust. Note that indeed the parameter settings would vary among different generalization and test data. 5.3.1 Verify Ranking Function and Propagation Method This experiment is conducted on the PTB development set with RND confounders. We use AFP and NYT as the generalization data. For comparison, we set the distance</context>
</contexts>
<marker>Bergsma, Lin, Goebel, 2008</marker>
<rawString>Shane Bergsma, Dekang Lin, and Randy Goebel. 2008. Discriminative learning of selectional preference from unlabeled text. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carsten Brockmann</author>
<author>Mirella Lapata</author>
</authors>
<title>Evaluating and combining approaches to selectional preference acquisition.</title>
<date>2003</date>
<booktitle>In EACL.</booktitle>
<contexts>
<context position="7159" citStr="Brockmann and Lapata (2003)" startWordPosition="1094" endWordPosition="1098"> Clark and Weir (2002) suggest a hypothesis testing method by ascending the noun hierarchy of WordNet. Ciaramita and Johnson (2000) model WordNet as a Bayesian network to solve the “explain away” ambiguity. Beyond induction on argument classes only, Agirre and Martinez (2001) propose a class-toclass model that simultaneously learns SP on both the predicate and argument classes. WordNet-based approach produces human interpretable output, but suffers the poor lexical coverage problem. Gildea and Jurafsky (2002) show that clustering-based approach has better coverage than WordNet-based approach. Brockmann and Lapata (2003) find out that sophisticated WordNet-based methods do not always outperform simple frequency-based methods. 2.2 Distributional Models without WordNet Alternatively, Rooth et al. (1999) propose an EMbased clustering smooth for SP. The key idea is to use the latent clusterings to take the place of WordNet semantic classes. Where the latent clusterings are automatically derived from distributional data based on EM algorithm. Recently, more sophisticated methods are innovated for SP based on topic models, where the latent variables (topics) take the place of semantic classes and distributional clu</context>
</contexts>
<marker>Brockmann, Lapata, 2003</marker>
<rawString>Carsten Brockmann and Mirella Lapata. 2003. Evaluating and combining approaches to selectional preference acquisition. In EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Improving the use of pseudo-words for evaluating selectional preferences.</title>
<date>2010</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="14882" citStr="Chambers and Jurafsky, 2010" startWordPosition="2383" endWordPosition="2386">hich could be more proper and agree with the nature of SP smooth. We denote SelPref(q, a) as Pr(q, a) for short. SelPref(q, a) = Ψ(q, a) (6) Previous literatures have well studied on various smooth models for SP. However, they vary greatly on the measure of preferences. It is still not clear how to do this best. Lapata et al. investigate the correlations between the co-occurrence counts (CT) c(q, a), or smoothed counts with the human plausibility judgements (Lapata et al., 1999; Lapata et al., 2001). Some introduce conditional probability (CP) p(a|q) for the decision of preference judgements (Chambers and Jurafsky, 2010; Erk et al., 2010; S´eaghdha, 2010). Meanwhile, the pointwise mutual information (MI) is also employed by many researchers to filter out incorrect inferences (Pantel et al., 2007; Bergsma et al., 2008). In this paper, we present an adjusted ranking function (AR) in Equation 8 to measure the SP of seen predicate-argument pairs. Intuitively, it measures the preferences by combining both the popularity and association, with parameters control the uncertainty of the trade-off between the two. We define the popularity as the joint probability p(q, a) based on MLE, and the association as MI. This i</context>
<context position="23847" citStr="Chambers and Jurafsky, 2010" startWordPosition="3913" endWordPosition="3916">utions over multiple arguments and relations (e.g., the subject and direct object of a verb). In this work, we compare with O´ S´eaghdha’s original LDA approach to SP. We use the Matlab Topic Modeling Toolbox4 for the inference of latent topics. The hyper parameters are set as suggested α=50/T and 0=200/n, where T is the number of topics and n is the number of arguments. We test T=100, 200, 300, each with 1, 000 iterations of Gibbs sampling. 5.3 Pseudo-Disambiguation Pseudo-disambiguation has been used for SP evaluation by many researchers (Rooth et al., 1999; Erk, 2007; Bergsma et al., 2008; Chambers and Jurafsky, 2010; Ritter et al., 2010). First the system removes a portion of seen predicate-argument pairs from the generalization data to treat them as unseen positive tests (q, a+). Then it introduces confounder selection to create a pseudo negative test (q, a−) for each positive (q, a+). Finally it evaluates a SP model by how well the model disambiguates these positive and negative tests. Confounder Selection: for a given (q, a+), the system selects an argument a′ from the argument vocabulary. Then by ensure (q, a′) is unseen in the generalization data, it treats a′ as pseudo a−. This process guarantees t</context>
</contexts>
<marker>Chambers, Jurafsky, 2010</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2010. Improving the use of pseudo-words for evaluating selectional preferences. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimiliano Ciaramita</author>
<author>Mark Johnson</author>
</authors>
<title>Explaining away ambiguity: Learning verb selectional preference with bayesian networks.</title>
<date>2000</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="6663" citStr="Ciaramita and Johnson (2000)" startWordPosition="1019" endWordPosition="1023"> seen in q. Finally the system picks a semantic class from the candidates with the maximal selectional association score, and defines the score as smoothed score of (q, a). Many researchers have followed the so-called WordNet-based approach to SP. One of the key issues is to induce the set of argument semantic classes that are acceptable by the given predicate. Li and Abe (1998) propose a tree cut model based on minimal description length (MDL) principle for the induction of semantic classes. Clark and Weir (2002) suggest a hypothesis testing method by ascending the noun hierarchy of WordNet. Ciaramita and Johnson (2000) model WordNet as a Bayesian network to solve the “explain away” ambiguity. Beyond induction on argument classes only, Agirre and Martinez (2001) propose a class-toclass model that simultaneously learns SP on both the predicate and argument classes. WordNet-based approach produces human interpretable output, but suffers the poor lexical coverage problem. Gildea and Jurafsky (2002) show that clustering-based approach has better coverage than WordNet-based approach. Brockmann and Lapata (2003) find out that sophisticated WordNet-based methods do not always outperform simple frequency-based metho</context>
</contexts>
<marker>Ciaramita, Johnson, 2000</marker>
<rawString>Massimiliano Ciaramita and Mark Johnson. 2000. Explaining away ambiguity: Learning verb selectional preference with bayesian networks. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>David J Weir</author>
</authors>
<title>Class-based probability estimation using a semantic hierarchy.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>2</issue>
<contexts>
<context position="6554" citStr="Clark and Weir (2002)" startWordPosition="1003" endWordPosition="1006">stem collects the set of candidate semantic classes which contain the argument a, and ensures they are seen in q. Finally the system picks a semantic class from the candidates with the maximal selectional association score, and defines the score as smoothed score of (q, a). Many researchers have followed the so-called WordNet-based approach to SP. One of the key issues is to induce the set of argument semantic classes that are acceptable by the given predicate. Li and Abe (1998) propose a tree cut model based on minimal description length (MDL) principle for the induction of semantic classes. Clark and Weir (2002) suggest a hypothesis testing method by ascending the noun hierarchy of WordNet. Ciaramita and Johnson (2000) model WordNet as a Bayesian network to solve the “explain away” ambiguity. Beyond induction on argument classes only, Agirre and Martinez (2001) propose a class-toclass model that simultaneously learns SP on both the predicate and argument classes. WordNet-based approach produces human interpretable output, but suffers the poor lexical coverage problem. Gildea and Jurafsky (2002) show that clustering-based approach has better coverage than WordNet-based approach. Brockmann and Lapata (</context>
</contexts>
<marker>Clark, Weir, 2002</marker>
<rawString>Stephen Clark and David J. Weir. 2002. Class-based probability estimation using a semantic hierarchy. Computational Linguistics, 28(2):187–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Lillian Lee</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Similarity-Based Models of Word Cooccurrence Probabilities.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>34--43</pages>
<contexts>
<context position="8078" citStr="Dagan et al. (1999)" startWordPosition="1237" endWordPosition="1240">dNet semantic classes. Where the latent clusterings are automatically derived from distributional data based on EM algorithm. Recently, more sophisticated methods are innovated for SP based on topic models, where the latent variables (topics) take the place of semantic classes and distributional clusterings (S´eaghdha, 2010; Ritter et al., 2010). Without introducing semantic classes and latent variables, Keller and Lapata (2003) use the web to obtain frequencies for unseen bigrams smooth. Pantel et al. (2007) apply a collection of rules to filter out incorrect inferences for SP. Specifically, Dagan et al. (1999) introduce a general similaritybased model for word co-occurrence probabilities, which can be interpreted for SP. Similarly, Erk et al. propose an argument-oriented similarity model based on semantic or syntactic vector spaces (Erk, 1170 2007; Erk et al., 2010). They compare several similarity functions and weighting functions in their model. Furthermore, instead of employing various similarity functions, Bergsma et al. (2008) propose a discriminative approach to learn the weights between the predicates, based on the verb-noun co-occurrences and other kinds of features. Random walk model falls</context>
<context position="18616" citStr="Dagan et al., 1999" startWordPosition="3045" endWordPosition="3048">on in Equation 5 is represented by the matrix form. It can be expanded and rewritten as Equation 12. Where p(qj|qi) is the converged transition probability from predicate qi to qj. Pr(ak, qj) is the measured preference of predicate qj with argument ak. Pr(ak, qi) = �m �p(qj|qi) · Pr(ak, qj) (12) j=1 We employ two propagation modes (PropMode) for the preference propagation function. One is ’CP’ mode. In this mode, we always set Pr(q, a) as the conditional probability p(a|q) for the propagation function, despite what Ψ is used for the distance function. This mode is similar to previous methods (Dagan et al., 1999; Keller and Lapata, 2003; Bergsma et al., 2008). The other is ’PP’ mode. We set ranking function Ψ=Pr(q, a) always to be the same in both the distance function and the propagation function. That means what we propagated is the designed and scored preferences. This could be more proper and agree with the nature of SP smooth. We show the improvement of this extension in section 5.3.1. 5 Experiments 5.1 Data Set Generalization Data: We parsed the Agence France-Presse (AFP) and New York Times (NYT) sections of the LDC English Gigaword corpora (Parker et al., 2011), each from year 2001-2010. The p</context>
<context position="22303" citStr="Dagan et al. (1999)" startWordPosition="3664" endWordPosition="3667">ss SP using similarity-based method. For a given (q, a) in relation r, the model sums over the similarities between a and the seen headwords a′ E Seen(q, r). They investigated several similarity functions sim(a, a′) such as Jaccard, Cosine, Lin, and nGCM etc., and different weighting functions wtq,r(a′). �S(q, r, a) = a′ For comparison, we suppose the primary corpus and generalization corpus in their model to be the same. We set the similarity function of their model as nGCM, use both the FREQ and DISCR weighting functions. The vector space is in SYNPRIMARY setting with 2, 000 basis elements. Dagan et al. (1999) propose state-of-the-art similarity based model for word co-occurrence probabilities. Though it is not intended for SP, but it can be interpreted and rewritten for SP as: sim(q, q′) Z(q) p(a|q′) (14) 3The implementation of RSP and listed previous methods are available at https://github.com/ZhenhuaTian/RSP They use the k-closest nearbys as Simset(q), with a parameter 0 to revise the similarity function. For comparison, we use the Jensen-Shannon divergence (Lin, 1991) which shows the best performance in their work as sim(q, q′), and optimize the settings of k and 0 in our experiments. LDA-SP: A</context>
</contexts>
<marker>Dagan, Lee, Pereira, 1999</marker>
<rawString>Ido Dagan, Lillian Lee, and Fernando C. N. Pereira. 1999. Similarity-Based Models of Word Cooccurrence Probabilities. Machine Learning, 34:43–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Sebastian Pad´o</author>
<author>Ulrike Pad´o</author>
</authors>
<title>A flexible, corpus-driven model of regular and inverse selectional preferences.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>4</issue>
<marker>Erk, Pad´o, Pad´o, 2010</marker>
<rawString>Katrin Erk, Sebastian Pad´o, and Ulrike Pad´o. 2010. A flexible, corpus-driven model of regular and inverse selectional preferences. Computational Linguistics, 36(4):723–763.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
</authors>
<title>A simple, similarity-based model for selectional preferences.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="21639" citStr="Erk, 2007" startWordPosition="3548" endWordPosition="3549"> set of human plausibility ratings on the basis of the Penn TreeBank and FrameNet respectively. We refer PBP as their 212 patient ratings from the Penn TreeBank. • MRP: This data are originally contributed by McRae et al. (1998). We use all their 723 patient-nn ratings. Without explicit explanation, we remove all the selected PTB tests and human plausibility pairs from AFP and NYT to treat them unseen. 5.2 Comparison Methods Since RSP falls into the unsupervised distributional approach, we compare it with previous similarity-based methods and unsupervised generative topic model 3. Erk et al. (Erk, 2007; Erk et al., 2010) are the pioneers to address SP using similarity-based method. For a given (q, a) in relation r, the model sums over the similarities between a and the seen headwords a′ E Seen(q, r). They investigated several similarity functions sim(a, a′) such as Jaccard, Cosine, Lin, and nGCM etc., and different weighting functions wtq,r(a′). �S(q, r, a) = a′ For comparison, we suppose the primary corpus and generalization corpus in their model to be the same. We set the similarity function of their model as nGCM, use both the FREQ and DISCR weighting functions. The vector space is in SY</context>
<context position="23796" citStr="Erk, 2007" startWordPosition="3907" endWordPosition="3908">g latent topics and their distributions over multiple arguments and relations (e.g., the subject and direct object of a verb). In this work, we compare with O´ S´eaghdha’s original LDA approach to SP. We use the Matlab Topic Modeling Toolbox4 for the inference of latent topics. The hyper parameters are set as suggested α=50/T and 0=200/n, where T is the number of topics and n is the number of arguments. We test T=100, 200, 300, each with 1, 000 iterations of Gibbs sampling. 5.3 Pseudo-Disambiguation Pseudo-disambiguation has been used for SP evaluation by many researchers (Rooth et al., 1999; Erk, 2007; Bergsma et al., 2008; Chambers and Jurafsky, 2010; Ritter et al., 2010). First the system removes a portion of seen predicate-argument pairs from the generalization data to treat them as unseen positive tests (q, a+). Then it introduces confounder selection to create a pseudo negative test (q, a−) for each positive (q, a+). Finally it evaluates a SP model by how well the model disambiguates these positive and negative tests. Confounder Selection: for a given (q, a+), the system selects an argument a′ from the argument vocabulary. Then by ensure (q, a′) is unseen in the generalization data, i</context>
</contexts>
<marker>Erk, 2007</marker>
<rawString>Katrin Erk. 2007. A simple, similarity-based model for selectional preferences. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="2082" citStr="Gildea and Jurafsky, 2002" startWordPosition="300" endWordPosition="303">as preferences between the predicates and arguments, where the violation can be less preferred, but not fatal. For instance, given the predicate word eat, word food is likely to be its object, iPhone is likely to be implausible for it, and tiger is less preferred but not curious. SP have been proven to help many natural language processing tasks that involve attachment de∗Partial of this work was done when the first author visiting at Language Technologies Institute of Carnegie Mellon University sponsored by the China Scholarship Council. cisions, such as semantic role labeling (Resnik, 1993; Gildea and Jurafsky, 2002), word sense disambiguation (Resnik, 1997), human plausibility judgements (Spasi´c and Ananiadou, 2004), syntactic disambiguation (Toutanova et al., 2005), word compositionality (McCarthy et al., 2007), textual entailment (Pantel et al., 2007) and pronoun resolution (Bergsma et al., 2008) etc. A direct approach to acquire SP is to extract triples (q, r, a) of predicates, relations, and arguments from a syntactically analyzed corpus, and then conduct maximum likelihood estimation (MLE) on the data. However, this strategy is infeasible for many plausible triples due to data sparsity. For example</context>
<context position="7046" citStr="Gildea and Jurafsky (2002)" startWordPosition="1079" endWordPosition="1082">pose a tree cut model based on minimal description length (MDL) principle for the induction of semantic classes. Clark and Weir (2002) suggest a hypothesis testing method by ascending the noun hierarchy of WordNet. Ciaramita and Johnson (2000) model WordNet as a Bayesian network to solve the “explain away” ambiguity. Beyond induction on argument classes only, Agirre and Martinez (2001) propose a class-toclass model that simultaneously learns SP on both the predicate and argument classes. WordNet-based approach produces human interpretable output, but suffers the poor lexical coverage problem. Gildea and Jurafsky (2002) show that clustering-based approach has better coverage than WordNet-based approach. Brockmann and Lapata (2003) find out that sophisticated WordNet-based methods do not always outperform simple frequency-based methods. 2.2 Distributional Models without WordNet Alternatively, Rooth et al. (1999) propose an EMbased clustering smooth for SP. The key idea is to use the latent clusterings to take the place of WordNet semantic classes. Where the latent clusterings are automatically derived from distributional data based on EM algorithm. Recently, more sophisticated methods are innovated for SP bas</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerrold J Katz</author>
<author>Jerry A Fodor</author>
</authors>
<title>The structure of a semantic theory.</title>
<date>1963</date>
<journal>Language,</journal>
<volume>39</volume>
<issue>2</issue>
<marker>Katz, Fodor, 1963</marker>
<rawString>Jerrold J. Katz and Jerry A. Fodor. 1963. The structure of a semantic theory. Language, 39(2):170–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Keller</author>
<author>Mirella Lapata</author>
</authors>
<title>Using the web to obtain frequencies for unseen bigrams.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="7891" citStr="Keller and Lapata (2003)" startWordPosition="1206" endWordPosition="1209">2.2 Distributional Models without WordNet Alternatively, Rooth et al. (1999) propose an EMbased clustering smooth for SP. The key idea is to use the latent clusterings to take the place of WordNet semantic classes. Where the latent clusterings are automatically derived from distributional data based on EM algorithm. Recently, more sophisticated methods are innovated for SP based on topic models, where the latent variables (topics) take the place of semantic classes and distributional clusterings (S´eaghdha, 2010; Ritter et al., 2010). Without introducing semantic classes and latent variables, Keller and Lapata (2003) use the web to obtain frequencies for unseen bigrams smooth. Pantel et al. (2007) apply a collection of rules to filter out incorrect inferences for SP. Specifically, Dagan et al. (1999) introduce a general similaritybased model for word co-occurrence probabilities, which can be interpreted for SP. Similarly, Erk et al. propose an argument-oriented similarity model based on semantic or syntactic vector spaces (Erk, 1170 2007; Erk et al., 2010). They compare several similarity functions and weighting functions in their model. Furthermore, instead of employing various similarity functions, Berg</context>
<context position="18641" citStr="Keller and Lapata, 2003" startWordPosition="3049" endWordPosition="3053">represented by the matrix form. It can be expanded and rewritten as Equation 12. Where p(qj|qi) is the converged transition probability from predicate qi to qj. Pr(ak, qj) is the measured preference of predicate qj with argument ak. Pr(ak, qi) = �m �p(qj|qi) · Pr(ak, qj) (12) j=1 We employ two propagation modes (PropMode) for the preference propagation function. One is ’CP’ mode. In this mode, we always set Pr(q, a) as the conditional probability p(a|q) for the propagation function, despite what Ψ is used for the distance function. This mode is similar to previous methods (Dagan et al., 1999; Keller and Lapata, 2003; Bergsma et al., 2008). The other is ’PP’ mode. We set ranking function Ψ=Pr(q, a) always to be the same in both the distance function and the propagation function. That means what we propagated is the designed and scored preferences. This could be more proper and agree with the nature of SP smooth. We show the improvement of this extension in section 5.3.1. 5 Experiments 5.1 Data Set Generalization Data: We parsed the Agence France-Presse (AFP) and New York Times (NYT) sections of the LDC English Gigaword corpora (Parker et al., 2011), each from year 2001-2010. The parser is provided by the </context>
</contexts>
<marker>Keller, Lapata, 2003</marker>
<rawString>Frank Keller and Mirella Lapata. 2003. Using the web to obtain frequencies for unseen bigrams. Computational Linguistics, 29(3):459–484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Lapata</author>
<author>Scott McDonald</author>
<author>Frank Keller</author>
</authors>
<title>Determinants of adjective-noun plausibility.</title>
<date>1999</date>
<booktitle>In EACL,</booktitle>
<pages>30--36</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="14737" citStr="Lapata et al., 1999" startWordPosition="2361" endWordPosition="2364">o be more accurate; 2) while propagation, we propagate the scored preferences, rather than the raw counts or conditional probabilities, which could be more proper and agree with the nature of SP smooth. We denote SelPref(q, a) as Pr(q, a) for short. SelPref(q, a) = Ψ(q, a) (6) Previous literatures have well studied on various smooth models for SP. However, they vary greatly on the measure of preferences. It is still not clear how to do this best. Lapata et al. investigate the correlations between the co-occurrence counts (CT) c(q, a), or smoothed counts with the human plausibility judgements (Lapata et al., 1999; Lapata et al., 2001). Some introduce conditional probability (CP) p(a|q) for the decision of preference judgements (Chambers and Jurafsky, 2010; Erk et al., 2010; S´eaghdha, 2010). Meanwhile, the pointwise mutual information (MI) is also employed by many researchers to filter out incorrect inferences (Pantel et al., 2007; Bergsma et al., 2008). In this paper, we present an adjusted ranking function (AR) in Equation 8 to measure the SP of seen predicate-argument pairs. Intuitively, it measures the preferences by combining both the popularity and association, with parameters control the uncert</context>
</contexts>
<marker>Lapata, McDonald, Keller, 1999</marker>
<rawString>Maria Lapata, Scott McDonald, and Frank Keller. 1999. Determinants of adjective-noun plausibility. In EACL, pages 30–36. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Lapata</author>
<author>Frank Keller</author>
<author>Scott McDonald</author>
</authors>
<title>Evaluating smoothing algorithms against plausibility judgements.</title>
<date>2001</date>
<booktitle>In ACL,</booktitle>
<pages>354--361</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="14759" citStr="Lapata et al., 2001" startWordPosition="2365" endWordPosition="2369">) while propagation, we propagate the scored preferences, rather than the raw counts or conditional probabilities, which could be more proper and agree with the nature of SP smooth. We denote SelPref(q, a) as Pr(q, a) for short. SelPref(q, a) = Ψ(q, a) (6) Previous literatures have well studied on various smooth models for SP. However, they vary greatly on the measure of preferences. It is still not clear how to do this best. Lapata et al. investigate the correlations between the co-occurrence counts (CT) c(q, a), or smoothed counts with the human plausibility judgements (Lapata et al., 1999; Lapata et al., 2001). Some introduce conditional probability (CP) p(a|q) for the decision of preference judgements (Chambers and Jurafsky, 2010; Erk et al., 2010; S´eaghdha, 2010). Meanwhile, the pointwise mutual information (MI) is also employed by many researchers to filter out incorrect inferences (Pantel et al., 2007; Bergsma et al., 2008). In this paper, we present an adjusted ranking function (AR) in Equation 8 to measure the SP of seen predicate-argument pairs. Intuitively, it measures the preferences by combining both the popularity and association, with parameters control the uncertainty of the trade-off</context>
<context position="32812" citStr="Lapata et al. (2001)" startWordPosition="5436" endWordPosition="5439"> 0.41 0.34 CP 0.47 0.39 0.35 0.30 0.51 0.48 0.39 0.37 MI 0.56 0.39 0.43 0.31 0.54 0.49 0.41 0.38 TD 0.53 0.36 0.39 0.28 0.56 0.45 0.42 0.34 AR 0.58 0.40 0.44 0.31 0.58 0.50 0.44 0.39 Erk et al. FREQ 0.30 0.08 0.22 0.06 0.25 0.09 0.18 0.06 Erk et al.DZSCR 0.06 0.21 0.04 0.15 0.16 0.23 0.11 0.16 Dagan et al. 0.32 0.24 0.24 0.18 0.46 0.29 0.34 0.21 LDA-SP 0.31 0.32 0.23 0.23 0.38 0.38 0.28 0.28 LDA-SP+Bayes 0.39 0.25 0.30 0.18 0.40 0.32 0.30 0.23 RSP-All 0.46 0.31 0.34 0.23 0.53 0.38 0.40 0.28 Table 3: Correlation results on the human plausibility judgements data. tions and human ratings. Follow Lapata et al. (2001), we first collect the co-occurrence counts of predicate-argument pairs in the human plausibility data from AFP and NYT (before removing them as unseen pairs). Then we score them with different ranking functions (described in Section 4.1) based on MLE. Inspired by Erk et al. (2010), we do not suppose linear correlations between the estimated scores and human ratings. We use the Spearman’s ρ and Kendal’s T rank correlation coefficient. We also compare the correlations between the smoothed scores of different models with human ratings. With respect to upper bounds, Pad´o et al. (2007) suggest th</context>
</contexts>
<marker>Lapata, Keller, McDonald, 2001</marker>
<rawString>Maria Lapata, Frank Keller, and Scott McDonald. 2001. Evaluating smoothing algorithms against plausibility judgements. In ACL, pages 354–361. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lillian Lee</author>
</authors>
<title>Measures of distributional similarity.</title>
<date>1999</date>
<booktitle>In ACL,</booktitle>
<pages>25--32</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="16992" citStr="Lee, 1999" startWordPosition="2754" endWordPosition="2755">hts the links on the monopartite graph Q. It �∞ t=1 (dP)t P= |(dP)t| ΨCT = c(q, a) ΨMI = log = c(q, a) Ψ TD c(q, a)log( n ) ΨCP c(q, *) TD I a| p(q, a) p(q)p(a) (7) (8) 1172 guides the walker to transfer between predicates. We calculate Φ based on the vectors ⃗qi, ⃗qj represented by the measured preferences in R. dij = Φ(⃗qi, ⃗qj) (9) Where Φ can be distance functions such as Euclidean (norm) distance or Kullback-Leibler divergence (KL) etc., or one minus the similarity functions such as Jaccard and Cosine etc. The selection of distributional functions has been fully studied by previous work (Lee, 1999; Erk et al., 2010). In this paper, we do not focus on this issue due to page limits. We simply use the Cosine function: ∥⃗qi∥∥⃗qj∥ (10) 4.3 Probability Function: the Walk Strategy We define the probability function ∆ as Equation 11. Where the transition probability p(qj|qi) in P is defined as a function of the distance dij with a parameter δ. Intuitively, it means in a given walk step, a predicate qj which is far away from qi will get much less probability to be visited, and qi has high probabilities to start walk from itself and its nearby predicates to pursue good precision. Once we get the</context>
</contexts>
<marker>Lee, 1999</marker>
<rawString>Lillian Lee. 1999. Measures of distributional similarity. In ACL, pages 25–32, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Li</author>
<author>Naoki Abe</author>
</authors>
<title>Generalizing case frames using a thesaurus and the mdl principle.</title>
<date>1998</date>
<journal>Computational linguistics,</journal>
<pages>24--2</pages>
<contexts>
<context position="6416" citStr="Li and Abe (1998)" startWordPosition="981" endWordPosition="984">ate q, the system firstly computes its distribution of argument semantic classes based on WordNet. Then for a given argument a, the system collects the set of candidate semantic classes which contain the argument a, and ensures they are seen in q. Finally the system picks a semantic class from the candidates with the maximal selectional association score, and defines the score as smoothed score of (q, a). Many researchers have followed the so-called WordNet-based approach to SP. One of the key issues is to induce the set of argument semantic classes that are acceptable by the given predicate. Li and Abe (1998) propose a tree cut model based on minimal description length (MDL) principle for the induction of semantic classes. Clark and Weir (2002) suggest a hypothesis testing method by ascending the noun hierarchy of WordNet. Ciaramita and Johnson (2000) model WordNet as a Bayesian network to solve the “explain away” ambiguity. Beyond induction on argument classes only, Agirre and Martinez (2001) propose a class-toclass model that simultaneously learns SP on both the predicate and argument classes. WordNet-based approach produces human interpretable output, but suffers the poor lexical coverage probl</context>
</contexts>
<marker>Li, Abe, 1998</marker>
<rawString>Hang Li and Naoki Abe. 1998. Generalizing case frames using a thesaurus and the mdl principle. Computational linguistics, 24(2):217–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming Li</author>
<author>Benjamin M Dias</author>
<author>Ian Jarman</author>
<author>Wael ElDeredy</author>
<author>Paulo JG Lisboa</author>
</authors>
<title>Grocery shopping recommendations based on basket-sensitive random walk.</title>
<date>2009</date>
<booktitle>In SIGKDD,</booktitle>
<pages>1215--1224</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="12607" citStr="Li et al., 2009" startWordPosition="2003" endWordPosition="2006"> probabilities to be visited, while distant predicates will be penalized. ∆ := D S P (3) Predicate Projection Argument Projection Argument Nodes fish chicken soil Predicate Nodes cook eat consume harvest cultivate irrigate can food fruit crop flower cook eat consume irrigate cultivate harvest chicken flower fish fruit soil can food crop 1171 Follow Equation 4, we aggregate over all orders of the transition probabilities P as the final stationary probabilities P. According to the PerronFrobenius theory, one can verify that it converges to dP(I − dP)−1 when P is non-negative and regular matrix (Li et al., 2009). Where t represents the orders: the length of the path between two nodes in terms of edges. The damp factor d E (0, 1), and its value mainly depends on the data sparsity level. Typically d prefers small values such as 0.005. It means higher order transitions are much less reliable than lower orders (LibenNowell and Kleinberg, 2007). = dP(I − dP)−1 (4) Preference Propagation: in Equation 5, we combine the converged transition probabilities P with the measured preferences R as the propagation function: 1) for a given predicate, firstly it transfers to all nearby predicates with designed probabi</context>
</contexts>
<marker>Li, Dias, Jarman, ElDeredy, Lisboa, 2009</marker>
<rawString>Ming Li, Benjamin M Dias, Ian Jarman, Wael ElDeredy, and Paulo JG Lisboa. 2009. Grocery shopping recommendations based on basket-sensitive random walk. In SIGKDD, pages 1215–1224. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Liben-Nowell</author>
<author>Jon Kleinberg</author>
</authors>
<title>The link-prediction problem for social networks.</title>
<date>2007</date>
<journal>Journal of the American</journal>
<pages>58--7</pages>
<contexts>
<context position="3361" citStr="Liben-Nowell and Kleinberg, 2007" startWordPosition="499" endWordPosition="503">s, we may see plausible triples: eat - {food, cake, apple, banana, candy...} But we may not see plausible and implausible triples such as: eat - {watermelon, ziti, escarole, iPhone...} Then how to use a smooth model to alleviate data sparsity for SP? Random walk models have been successfully applied to alleviate the data sparsity issue on collaborative filtering in recommender systems. Many online businesses, such as Netflix, Amazon.com, and Facebook, have used recommender systems to provide personalized suggestions on the movies, books, or friends that the users may prefer and interested in (Liben-Nowell and Kleinberg, 2007; Yildirim and Krishnamoorthy, 2008). In this paper, we present an extension of using the random walk model to alleviate data sparsity for SP. The main intuition is to aggregate all the transitions from a given predicate to its nearby predicates, and propagate their preferences on arguments as the given predicate’s smoothed argu1169 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1169–1179, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ment preferences. Our work and contributions are summarized as follows: • We</context>
</contexts>
<marker>Liben-Nowell, Kleinberg, 2007</marker>
<rawString>David Liben-Nowell and Jon Kleinberg. 2007. The link-prediction problem for social networks. Journal of the American society for information science and technology, 58(7):1019–1031.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianhua Lin</author>
</authors>
<title>Divergence measures based on the shannon entropy.</title>
<date>1991</date>
<journal>IEEE Transactions on Information Theory,</journal>
<volume>37</volume>
<issue>1</issue>
<contexts>
<context position="22774" citStr="Lin, 1991" startWordPosition="3735" endWordPosition="3736"> use both the FREQ and DISCR weighting functions. The vector space is in SYNPRIMARY setting with 2, 000 basis elements. Dagan et al. (1999) propose state-of-the-art similarity based model for word co-occurrence probabilities. Though it is not intended for SP, but it can be interpreted and rewritten for SP as: sim(q, q′) Z(q) p(a|q′) (14) 3The implementation of RSP and listed previous methods are available at https://github.com/ZhenhuaTian/RSP They use the k-closest nearbys as Simset(q), with a parameter 0 to revise the similarity function. For comparison, we use the Jensen-Shannon divergence (Lin, 1991) which shows the best performance in their work as sim(q, q′), and optimize the settings of k and 0 in our experiments. LDA-SP: Another kind of sophisticated unsupervised approaches for SP are latent variable models based on Latent Dirichlet Allocation (LDA). O´ S´eaghdha (2010) applies topic models for the SP induction with three variations: LDA, Rooth-LDA, and Dual-LDA; Ritter et al. (2010) focus on inferring latent topics and their distributions over multiple arguments and relations (e.g., the subject and direct object of a verb). In this work, we compare with O´ S´eaghdha’s original LDA ap</context>
</contexts>
<marker>Lin, 1991</marker>
<rawString>Jianhua Lin. 1991. Divergence measures based on the shannon entropy. IEEE Transactions on Information Theory, 37(1):145–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Ann Taylor</author>
</authors>
<date>1999</date>
<note>Treebank3.</note>
<contexts>
<context position="19965" citStr="Marcus et al., 1999" startWordPosition="3268" endWordPosition="3272">erb-dobjnoun &gt; triples from the syntactically analyzed data. Predicates (verbs) whose frequency lower than 30 and arguments (noun headwords) whose frequency less than 5 are excluded out. No other filters have been done. The resulting data consist of: • AFP: 26,118, 892 verb-dobj-noun observations with 1, 918, 275 distinct triples, totally 4, 771 predicates and 44, 777 arguments. • NYT: 29,149, 574 verb-dobj-noun observations with 3, 281,391 distinct triples, totally 5, 782 predicates and 57, 480 arguments. Test Data: For pseudo-disambiguation, we employ Penn TreeBank-3 (PTB) as the test data (Marcus et al., 1999)2. We collect the 36,400 manually annotated verb-dobj-noun dependencies (with 23,553 distinct ones) from PTB. We keep dependencies whose predicates and arguments are seen in the generalization data. We randomly select 20% of these dependencies as the test set. We split the test set equally into two parts: one as the development set and the other as the final test set. Human Plausibility Judgements Data: We employ two human plausibility judgements data 1http://nlp.stanford.edu/software/corenlp.shtml 2PTB includes 2, 499 stories from the Wall Street Journal (WSJ). It is different with our two ge</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, Taylor, 1999</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, Mary Ann Marcinkiewicz, and Ann Taylor. 1999. Treebank3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Sriram Venkatapathy</author>
<author>Aravind K Joshi</author>
</authors>
<title>Detecting compositionality of verbobject combinations using selectional preferences.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL.</booktitle>
<contexts>
<context position="2283" citStr="McCarthy et al., 2007" startWordPosition="326" endWordPosition="329">kely to be implausible for it, and tiger is less preferred but not curious. SP have been proven to help many natural language processing tasks that involve attachment de∗Partial of this work was done when the first author visiting at Language Technologies Institute of Carnegie Mellon University sponsored by the China Scholarship Council. cisions, such as semantic role labeling (Resnik, 1993; Gildea and Jurafsky, 2002), word sense disambiguation (Resnik, 1997), human plausibility judgements (Spasi´c and Ananiadou, 2004), syntactic disambiguation (Toutanova et al., 2005), word compositionality (McCarthy et al., 2007), textual entailment (Pantel et al., 2007) and pronoun resolution (Bergsma et al., 2008) etc. A direct approach to acquire SP is to extract triples (q, r, a) of predicates, relations, and arguments from a syntactically analyzed corpus, and then conduct maximum likelihood estimation (MLE) on the data. However, this strategy is infeasible for many plausible triples due to data sparsity. For example, given the relation &lt;verb-dobjnoun&gt; in a corpus, we may see plausible triples: eat - {food, cake, apple, banana, candy...} But we may not see plausible and implausible triples such as: eat - {watermel</context>
</contexts>
<marker>McCarthy, Venkatapathy, Joshi, 2007</marker>
<rawString>Diana McCarthy, Sriram Venkatapathy, and Aravind K. Joshi. 2007. Detecting compositionality of verbobject combinations using selectional preferences. In EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken McRae</author>
<author>Michael J Spivey-Knowltonb</author>
<author>Michael K Tanenhausc</author>
</authors>
<title>Modeling the influence of thematic fit (and other constraints) in on-line sentence comprehension.</title>
<date>1998</date>
<journal>Journal of Memory and Language,</journal>
<volume>38</volume>
<issue>3</issue>
<contexts>
<context position="21258" citStr="McRae et al. (1998)" startWordPosition="3486" endWordPosition="3489">lation evaluation. In each they collect a set of predicate-argument pairs, and annotate with two kinds of human ratings: one for an argument takes the role as the patient of a predicate, and the other for the argument as the agent. The rating values are between 1 and 7: e.g. they assign hunter-subj-shoot with a rating 6.9 but 2.8 for shoot-dobj-hunter. • PBP: Pad´o et al. (2007) develop a set of human plausibility ratings on the basis of the Penn TreeBank and FrameNet respectively. We refer PBP as their 212 patient ratings from the Penn TreeBank. • MRP: This data are originally contributed by McRae et al. (1998). We use all their 723 patient-nn ratings. Without explicit explanation, we remove all the selected PTB tests and human plausibility pairs from AFP and NYT to treat them unseen. 5.2 Comparison Methods Since RSP falls into the unsupervised distributional approach, we compare it with previous similarity-based methods and unsupervised generative topic model 3. Erk et al. (Erk, 2007; Erk et al., 2010) are the pioneers to address SP using similarity-based method. For a given (q, a) in relation r, the model sums over the similarities between a and the seen headwords a′ E Seen(q, r). They investigate</context>
</contexts>
<marker>McRae, Spivey-Knowltonb, Tanenhausc, 1998</marker>
<rawString>Ken McRae, Michael J. Spivey-Knowltonb, and Michael K. Tanenhausc. 1998. Modeling the influence of thematic fit (and other constraints) in on-line sentence comprehension. Journal of Memory and Language, 38(3):283–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Ulrike Pad´o</author>
<author>Katrin Erk</author>
</authors>
<title>Flexible, corpus-based modelling of human plausibility judgements.</title>
<date>2007</date>
<booktitle>In EMNLP/CoNLL,</booktitle>
<volume>7</volume>
<marker>Pad´o, Pad´o, Erk, 2007</marker>
<rawString>Sebastian Pad´o, Ulrike Pad´o, and Katrin Erk. 2007. Flexible, corpus-based modelling of human plausibility judgements. In EMNLP/CoNLL, volume 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Rahul Bhagat</author>
<author>Bonaventura Coppola</author>
<author>Timothy Chklovski</author>
<author>Eduard Hovy</author>
</authors>
<title>Isp: Learning inferential selectional preferences.</title>
<date>2007</date>
<booktitle>In NAACL-HLT.</booktitle>
<contexts>
<context position="2325" citStr="Pantel et al., 2007" startWordPosition="332" endWordPosition="335">less preferred but not curious. SP have been proven to help many natural language processing tasks that involve attachment de∗Partial of this work was done when the first author visiting at Language Technologies Institute of Carnegie Mellon University sponsored by the China Scholarship Council. cisions, such as semantic role labeling (Resnik, 1993; Gildea and Jurafsky, 2002), word sense disambiguation (Resnik, 1997), human plausibility judgements (Spasi´c and Ananiadou, 2004), syntactic disambiguation (Toutanova et al., 2005), word compositionality (McCarthy et al., 2007), textual entailment (Pantel et al., 2007) and pronoun resolution (Bergsma et al., 2008) etc. A direct approach to acquire SP is to extract triples (q, r, a) of predicates, relations, and arguments from a syntactically analyzed corpus, and then conduct maximum likelihood estimation (MLE) on the data. However, this strategy is infeasible for many plausible triples due to data sparsity. For example, given the relation &lt;verb-dobjnoun&gt; in a corpus, we may see plausible triples: eat - {food, cake, apple, banana, candy...} But we may not see plausible and implausible triples such as: eat - {watermelon, ziti, escarole, iPhone...} Then how to</context>
<context position="7973" citStr="Pantel et al. (2007)" startWordPosition="1220" endWordPosition="1223">n EMbased clustering smooth for SP. The key idea is to use the latent clusterings to take the place of WordNet semantic classes. Where the latent clusterings are automatically derived from distributional data based on EM algorithm. Recently, more sophisticated methods are innovated for SP based on topic models, where the latent variables (topics) take the place of semantic classes and distributional clusterings (S´eaghdha, 2010; Ritter et al., 2010). Without introducing semantic classes and latent variables, Keller and Lapata (2003) use the web to obtain frequencies for unseen bigrams smooth. Pantel et al. (2007) apply a collection of rules to filter out incorrect inferences for SP. Specifically, Dagan et al. (1999) introduce a general similaritybased model for word co-occurrence probabilities, which can be interpreted for SP. Similarly, Erk et al. propose an argument-oriented similarity model based on semantic or syntactic vector spaces (Erk, 1170 2007; Erk et al., 2010). They compare several similarity functions and weighting functions in their model. Furthermore, instead of employing various similarity functions, Bergsma et al. (2008) propose a discriminative approach to learn the weights between t</context>
<context position="15061" citStr="Pantel et al., 2007" startWordPosition="2412" endWordPosition="2415">ous smooth models for SP. However, they vary greatly on the measure of preferences. It is still not clear how to do this best. Lapata et al. investigate the correlations between the co-occurrence counts (CT) c(q, a), or smoothed counts with the human plausibility judgements (Lapata et al., 1999; Lapata et al., 2001). Some introduce conditional probability (CP) p(a|q) for the decision of preference judgements (Chambers and Jurafsky, 2010; Erk et al., 2010; S´eaghdha, 2010). Meanwhile, the pointwise mutual information (MI) is also employed by many researchers to filter out incorrect inferences (Pantel et al., 2007; Bergsma et al., 2008). In this paper, we present an adjusted ranking function (AR) in Equation 8 to measure the SP of seen predicate-argument pairs. Intuitively, it measures the preferences by combining both the popularity and association, with parameters control the uncertainty of the trade-off between the two. We define the popularity as the joint probability p(q, a) based on MLE, and the association as MI. This is potentially similar to the process of human plausibility judgements. One may judge the plausibility of a predicate-argument collocation from two sides: 1) if it has enough evide</context>
</contexts>
<marker>Pantel, Bhagat, Coppola, Chklovski, Hovy, 2007</marker>
<rawString>Patrick Pantel, Rahul Bhagat, Bonaventura Coppola, Timothy Chklovski, and Eduard Hovy. 2007. Isp: Learning inferential selectional preferences. In NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Parker</author>
<author>David Graff</author>
<author>Junbo Kong</author>
<author>Ke Chen</author>
<author>Kazuaki Maeda</author>
</authors>
<date>2011</date>
<note>English gigaword fifth edition.</note>
<contexts>
<context position="19183" citStr="Parker et al., 2011" startWordPosition="3144" endWordPosition="3147">de is similar to previous methods (Dagan et al., 1999; Keller and Lapata, 2003; Bergsma et al., 2008). The other is ’PP’ mode. We set ranking function Ψ=Pr(q, a) always to be the same in both the distance function and the propagation function. That means what we propagated is the designed and scored preferences. This could be more proper and agree with the nature of SP smooth. We show the improvement of this extension in section 5.3.1. 5 Experiments 5.1 Data Set Generalization Data: We parsed the Agence France-Presse (AFP) and New York Times (NYT) sections of the LDC English Gigaword corpora (Parker et al., 2011), each from year 2001-2010. The parser is provided by the Stanford CoreNLP package1. We filter out all tokens containing non-alphabetic characters, collect the &lt;verb-dobjnoun &gt; triples from the syntactically analyzed data. Predicates (verbs) whose frequency lower than 30 and arguments (noun headwords) whose frequency less than 5 are excluded out. No other filters have been done. The resulting data consist of: • AFP: 26,118, 892 verb-dobj-noun observations with 1, 918, 275 distinct triples, totally 4, 771 predicates and 44, 777 arguments. • NYT: 29,149, 574 verb-dobj-noun observations with 3, 2</context>
</contexts>
<marker>Parker, Graff, Kong, Chen, Maeda, 2011</marker>
<rawString>Robert Parker, David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. 2011. English gigaword fifth edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selection and information: a class-based approach to lexical relationships.</title>
<date>1993</date>
<tech>IRCS Technical Reports Series.</tech>
<contexts>
<context position="2054" citStr="Resnik, 1993" startWordPosition="298" endWordPosition="299"> restrictions as preferences between the predicates and arguments, where the violation can be less preferred, but not fatal. For instance, given the predicate word eat, word food is likely to be its object, iPhone is likely to be implausible for it, and tiger is less preferred but not curious. SP have been proven to help many natural language processing tasks that involve attachment de∗Partial of this work was done when the first author visiting at Language Technologies Institute of Carnegie Mellon University sponsored by the China Scholarship Council. cisions, such as semantic role labeling (Resnik, 1993; Gildea and Jurafsky, 2002), word sense disambiguation (Resnik, 1997), human plausibility judgements (Spasi´c and Ananiadou, 2004), syntactic disambiguation (Toutanova et al., 2005), word compositionality (McCarthy et al., 2007), textual entailment (Pantel et al., 2007) and pronoun resolution (Bergsma et al., 2008) etc. A direct approach to acquire SP is to extract triples (q, r, a) of predicates, relations, and arguments from a syntactically analyzed corpus, and then conduct maximum likelihood estimation (MLE) on the data. However, this strategy is infeasible for many plausible triples due t</context>
</contexts>
<marker>Resnik, 1993</marker>
<rawString>Philip Resnik. 1993. Selection and information: a class-based approach to lexical relationships. IRCS Technical Reports Series.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selectional constraints: An information-theoretic model and its computational realization.</title>
<date>1996</date>
<journal>Cognition,</journal>
<volume>61</volume>
<issue>1</issue>
<contexts>
<context position="5723" citStr="Resnik (1996)" startWordPosition="866" endWordPosition="867">tions of smoothed scores with human plausibility judgements. Again our method achieves better correlations on two third party data. The remainder of the paper is organized as follows: Section 2 introduces related work. Section 3 briefly formulates the overall framework of our method. Section 4 describes the detailed model configurations, with discussions on their roles and implications. Section 5 provides experiments on both the pseudo-disambiguation task and human plausibility judgements. Finally, Section 6 summarizes the conclusions and future work. 2 Related Work 2.1 WordNet-based Approach Resnik (1996) conducts the pioneer work on corpus-driven SP induction. For a given predicate q, the system firstly computes its distribution of argument semantic classes based on WordNet. Then for a given argument a, the system collects the set of candidate semantic classes which contain the argument a, and ensures they are seen in q. Finally the system picks a semantic class from the candidates with the maximal selectional association score, and defines the score as smoothed score of (q, a). Many researchers have followed the so-called WordNet-based approach to SP. One of the key issues is to induce the s</context>
</contexts>
<marker>Resnik, 1996</marker>
<rawString>Philip Resnik. 1996. Selectional constraints: An information-theoretic model and its computational realization. Cognition, 61(1):127–159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selectional preference and sense disambiguation.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL SIGLEX Workshop on Tagging Text with Lexical Semantics: Why, What, and How.</booktitle>
<location>Washington, DC.</location>
<contexts>
<context position="2124" citStr="Resnik, 1997" startWordPosition="308" endWordPosition="309">ere the violation can be less preferred, but not fatal. For instance, given the predicate word eat, word food is likely to be its object, iPhone is likely to be implausible for it, and tiger is less preferred but not curious. SP have been proven to help many natural language processing tasks that involve attachment de∗Partial of this work was done when the first author visiting at Language Technologies Institute of Carnegie Mellon University sponsored by the China Scholarship Council. cisions, such as semantic role labeling (Resnik, 1993; Gildea and Jurafsky, 2002), word sense disambiguation (Resnik, 1997), human plausibility judgements (Spasi´c and Ananiadou, 2004), syntactic disambiguation (Toutanova et al., 2005), word compositionality (McCarthy et al., 2007), textual entailment (Pantel et al., 2007) and pronoun resolution (Bergsma et al., 2008) etc. A direct approach to acquire SP is to extract triples (q, r, a) of predicates, relations, and arguments from a syntactically analyzed corpus, and then conduct maximum likelihood estimation (MLE) on the data. However, this strategy is infeasible for many plausible triples due to data sparsity. For example, given the relation &lt;verb-dobjnoun&gt; in a </context>
</contexts>
<marker>Resnik, 1997</marker>
<rawString>Philip Resnik. 1997. Selectional preference and sense disambiguation. In Proceedings of the ACL SIGLEX Workshop on Tagging Text with Lexical Semantics: Why, What, and How. Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Mausam</author>
<author>Oren Etzioni</author>
</authors>
<title>A latent dirichlet allocation method for selectional preferences.</title>
<date>2010</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="7806" citStr="Ritter et al., 2010" startWordPosition="1194" endWordPosition="1197">d WordNet-based methods do not always outperform simple frequency-based methods. 2.2 Distributional Models without WordNet Alternatively, Rooth et al. (1999) propose an EMbased clustering smooth for SP. The key idea is to use the latent clusterings to take the place of WordNet semantic classes. Where the latent clusterings are automatically derived from distributional data based on EM algorithm. Recently, more sophisticated methods are innovated for SP based on topic models, where the latent variables (topics) take the place of semantic classes and distributional clusterings (S´eaghdha, 2010; Ritter et al., 2010). Without introducing semantic classes and latent variables, Keller and Lapata (2003) use the web to obtain frequencies for unseen bigrams smooth. Pantel et al. (2007) apply a collection of rules to filter out incorrect inferences for SP. Specifically, Dagan et al. (1999) introduce a general similaritybased model for word co-occurrence probabilities, which can be interpreted for SP. Similarly, Erk et al. propose an argument-oriented similarity model based on semantic or syntactic vector spaces (Erk, 1170 2007; Erk et al., 2010). They compare several similarity functions and weighting functions</context>
<context position="23169" citStr="Ritter et al. (2010)" startWordPosition="3798" endWordPosition="3801">s methods are available at https://github.com/ZhenhuaTian/RSP They use the k-closest nearbys as Simset(q), with a parameter 0 to revise the similarity function. For comparison, we use the Jensen-Shannon divergence (Lin, 1991) which shows the best performance in their work as sim(q, q′), and optimize the settings of k and 0 in our experiments. LDA-SP: Another kind of sophisticated unsupervised approaches for SP are latent variable models based on Latent Dirichlet Allocation (LDA). O´ S´eaghdha (2010) applies topic models for the SP induction with three variations: LDA, Rooth-LDA, and Dual-LDA; Ritter et al. (2010) focus on inferring latent topics and their distributions over multiple arguments and relations (e.g., the subject and direct object of a verb). In this work, we compare with O´ S´eaghdha’s original LDA approach to SP. We use the Matlab Topic Modeling Toolbox4 for the inference of latent topics. The hyper parameters are set as suggested α=50/T and 0=200/n, where T is the number of topics and n is the number of arguments. We test T=100, 200, 300, each with 1, 000 iterations of Gibbs sampling. 5.3 Pseudo-Disambiguation Pseudo-disambiguation has been used for SP evaluation by many researchers (Ro</context>
<context position="26211" citStr="Ritter et al (2010)" startWordPosition="4304" endWordPosition="4307">formance is evaluated based on the accuracy (ACC) metric. It computes the portion of test instances (q, a+, a−) which correctly predicted by the smooth model with score(q, a+) &gt; score(q, a−). We weight each instance equally for macroACC, and weight each by the frequency of the positive pair (q, a+) for microACC. 2) On pointwise setting, we use each positive test (q, a+) or negative test (q, a−) as test instances independently. We treat it as a binary classification task, and evaluate using the standard area-under-the-curve (AUC) metric. This metric is firstly employed for the SP evaluation by Ritter et al (2010). For macroAUC, we weight each instance equally; for microAUC, we weight each by its argument frequency (Bergsma et al., 2008). Parameters Tuning: The parameters are tuned on the PTB development set, using AFP as the generalization data. We report the overall performance on the final test set. While using NYT as the generalization data, we hold the same parameter settings as AFP to ensure the results are robust. Note that indeed the parameter settings would vary among different generalization and test data. 5.3.1 Verify Ranking Function and Propagation Method This experiment is conducted on th</context>
<context position="34131" citStr="Ritter et al. (2010)" startWordPosition="5657" endWordPosition="5660"> data. We hold that automatic models of plausibility can not be expected to surpass this upper bound. In Table 3, all coefficients are verified at significant level p&lt;0.01. The first 5 rows are the correlations between the preference ranking functions and human ratings based on MLE. On both the PBP and MRP data, the proposed AR metric better correlates with human ratings than others, with α2 &gt;0.5 and α1 around [0.2, 0.35]. The latter 6 rows are the results of smooth models. It shows LDASP performs good correlation with human ratings, where LDA-SP+Bayes refers to the Bayes prediction method of Ritter et al. (2010). RSP model gains the best correlation on the two plausibility data in most cases, where the parameter settings are the same as pseudo-disambiguation. 6 Conclusions and Future Work In this work we present an random walk approach to SP. Experiments show it is efficient and effective to address data sparsity for SP. It is also flexible to be applied to new data. We find out that a proper measure on SP between the predicates and arguments is important for SP. It helps with the discovering of nearby predicates and it makes the preference propagation to be more accurate. Another issue is that it is</context>
</contexts>
<marker>Ritter, Mausam, Etzioni, 2010</marker>
<rawString>Alan Ritter, Mausam, and Oren Etzioni. 2010. A latent dirichlet allocation method for selectional preferences. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Rooth</author>
<author>Stefan Riezler</author>
<author>Detlef Prescher</author>
<author>Glenn Carroll</author>
<author>Franz Beil</author>
</authors>
<title>Inducing a semantically annotated lexicon via em-based clustering.</title>
<date>1999</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="7343" citStr="Rooth et al. (1999)" startWordPosition="1119" endWordPosition="1122">ay” ambiguity. Beyond induction on argument classes only, Agirre and Martinez (2001) propose a class-toclass model that simultaneously learns SP on both the predicate and argument classes. WordNet-based approach produces human interpretable output, but suffers the poor lexical coverage problem. Gildea and Jurafsky (2002) show that clustering-based approach has better coverage than WordNet-based approach. Brockmann and Lapata (2003) find out that sophisticated WordNet-based methods do not always outperform simple frequency-based methods. 2.2 Distributional Models without WordNet Alternatively, Rooth et al. (1999) propose an EMbased clustering smooth for SP. The key idea is to use the latent clusterings to take the place of WordNet semantic classes. Where the latent clusterings are automatically derived from distributional data based on EM algorithm. Recently, more sophisticated methods are innovated for SP based on topic models, where the latent variables (topics) take the place of semantic classes and distributional clusterings (S´eaghdha, 2010; Ritter et al., 2010). Without introducing semantic classes and latent variables, Keller and Lapata (2003) use the web to obtain frequencies for unseen bigram</context>
<context position="23785" citStr="Rooth et al., 1999" startWordPosition="3903" endWordPosition="3906">0) focus on inferring latent topics and their distributions over multiple arguments and relations (e.g., the subject and direct object of a verb). In this work, we compare with O´ S´eaghdha’s original LDA approach to SP. We use the Matlab Topic Modeling Toolbox4 for the inference of latent topics. The hyper parameters are set as suggested α=50/T and 0=200/n, where T is the number of topics and n is the number of arguments. We test T=100, 200, 300, each with 1, 000 iterations of Gibbs sampling. 5.3 Pseudo-Disambiguation Pseudo-disambiguation has been used for SP evaluation by many researchers (Rooth et al., 1999; Erk, 2007; Bergsma et al., 2008; Chambers and Jurafsky, 2010; Ritter et al., 2010). First the system removes a portion of seen predicate-argument pairs from the generalization data to treat them as unseen positive tests (q, a+). Then it introduces confounder selection to create a pseudo negative test (q, a−) for each positive (q, a+). Finally it evaluates a SP model by how well the model disambiguates these positive and negative tests. Confounder Selection: for a given (q, a+), the system selects an argument a′ from the argument vocabulary. Then by ensure (q, a′) is unseen in the generalizat</context>
</contexts>
<marker>Rooth, Riezler, Prescher, Carroll, Beil, 1999</marker>
<rawString>Mats Rooth, Stefan Riezler, Detlef Prescher, Glenn Carroll, and Franz Beil. 1999. Inducing a semantically annotated lexicon via em-based clustering. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diarmuid O´ S´eaghdha</author>
</authors>
<title>Latent variable models of selectional preference.</title>
<date>2010</date>
<booktitle>In ACL.</booktitle>
<marker>S´eaghdha, 2010</marker>
<rawString>Diarmuid O´ S´eaghdha. 2010. Latent variable models of selectional preference. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irena Spasi´c</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Using automatically learnt verb selectional preferences for classification of biomedical terms.</title>
<date>2004</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>37</volume>
<issue>6</issue>
<marker>Spasi´c, Ananiadou, 2004</marker>
<rawString>Irena Spasi´c and Sophia Ananiadou. 2004. Using automatically learnt verb selectional preferences for classification of biomedical terms. Journal of Biomedical Informatics, 37(6):483–497.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Christopher D Manning</author>
<author>Dan Flickinger</author>
<author>Stephan Oepen</author>
</authors>
<title>Stochastic hpsg parse disambiguation using the redwoods corpus.</title>
<date>2005</date>
<journal>Research on Language &amp; Computation,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="2236" citStr="Toutanova et al., 2005" startWordPosition="320" endWordPosition="323">rd food is likely to be its object, iPhone is likely to be implausible for it, and tiger is less preferred but not curious. SP have been proven to help many natural language processing tasks that involve attachment de∗Partial of this work was done when the first author visiting at Language Technologies Institute of Carnegie Mellon University sponsored by the China Scholarship Council. cisions, such as semantic role labeling (Resnik, 1993; Gildea and Jurafsky, 2002), word sense disambiguation (Resnik, 1997), human plausibility judgements (Spasi´c and Ananiadou, 2004), syntactic disambiguation (Toutanova et al., 2005), word compositionality (McCarthy et al., 2007), textual entailment (Pantel et al., 2007) and pronoun resolution (Bergsma et al., 2008) etc. A direct approach to acquire SP is to extract triples (q, r, a) of predicates, relations, and arguments from a syntactically analyzed corpus, and then conduct maximum likelihood estimation (MLE) on the data. However, this strategy is infeasible for many plausible triples due to data sparsity. For example, given the relation &lt;verb-dobjnoun&gt; in a corpus, we may see plausible triples: eat - {food, cake, apple, banana, candy...} But we may not see plausible a</context>
</contexts>
<marker>Toutanova, Manning, Flickinger, Oepen, 2005</marker>
<rawString>Kristina Toutanova, Christopher D. Manning, Dan Flickinger, and Stephan Oepen. 2005. Stochastic hpsg parse disambiguation using the redwoods corpus. Research on Language &amp; Computation, 3(1):83–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick Wilks</author>
</authors>
<title>Preference semantics.</title>
<date>1973</date>
<tech>Technical report, DTIC Document.</tech>
<contexts>
<context position="1320" citStr="Wilks (1973)" startWordPosition="179" endWordPosition="180">ate’s smoothed preferences. Experimental results show that this approach outperforms several state-of-the-art methods on the pseudo-disambiguation task, and it better correlates with human plausibility judgements. 1 Introduction Selectional preferences (SP) or selectional restrictions capture the plausibility of predicates and their arguments for a given relation. Kaze and Fodor (1963) describe that predicates and their arguments have strict boolean restrictions, either satisfied or violated. Sentences are semantically anomalous and not consistent in reading if they violated the restrictions. Wilks (1973) argues that “rejecting utterances is just what humans do not. They try to understand them.” He further states selectional restrictions as preferences between the predicates and arguments, where the violation can be less preferred, but not fatal. For instance, given the predicate word eat, word food is likely to be its object, iPhone is likely to be implausible for it, and tiger is less preferred but not curious. SP have been proven to help many natural language processing tasks that involve attachment de∗Partial of this work was done when the first author visiting at Language Technologies Ins</context>
</contexts>
<marker>Wilks, 1973</marker>
<rawString>Yorick Wilks. 1973. Preference semantics. Technical report, DTIC Document.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hilmi Yildirim</author>
<author>Mukkai S Krishnamoorthy</author>
</authors>
<title>A random walk method for alleviating the sparsity problem in collaborative filtering.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 ACM conference on Recommender systems,</booktitle>
<pages>131--138</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3397" citStr="Yildirim and Krishnamoorthy, 2008" startWordPosition="504" endWordPosition="507">at - {food, cake, apple, banana, candy...} But we may not see plausible and implausible triples such as: eat - {watermelon, ziti, escarole, iPhone...} Then how to use a smooth model to alleviate data sparsity for SP? Random walk models have been successfully applied to alleviate the data sparsity issue on collaborative filtering in recommender systems. Many online businesses, such as Netflix, Amazon.com, and Facebook, have used recommender systems to provide personalized suggestions on the movies, books, or friends that the users may prefer and interested in (Liben-Nowell and Kleinberg, 2007; Yildirim and Krishnamoorthy, 2008). In this paper, we present an extension of using the random walk model to alleviate data sparsity for SP. The main intuition is to aggregate all the transitions from a given predicate to its nearby predicates, and propagate their preferences on arguments as the given predicate’s smoothed argu1169 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1169–1179, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics ment preferences. Our work and contributions are summarized as follows: • We present a framework of random walk </context>
</contexts>
<marker>Yildirim, Krishnamoorthy, 2008</marker>
<rawString>Hilmi Yildirim and Mukkai S. Krishnamoorthy. 2008. A random walk method for alleviating the sparsity problem in collaborative filtering. In Proceedings of the 2008 ACM conference on Recommender systems, pages 131–138. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Zhou</author>
<author>Jie Renan</author>
<author>Mat´uˇs Medo</author>
<author>Yi-Cheng Zhang</author>
</authors>
<title>Bipartite network projection and personal recommendation. Physical Review E,</title>
<date>2007</date>
<contexts>
<context position="11295" citStr="Zhou et al., 2007" startWordPosition="1782" endWordPosition="1785">o a corresponding bipartite graph R, with links representing the strength of SP. Each row of the adjacency matrix R denotes the predicate vector ⃗qi or ⃗qj. We discuss the selection of Ψ in section 4.1. Ψ := G S R (1) Figure 1: Illustration of (R) the bipartite graph of the verb-dobj-noun relation, (Q) the predicate-projection monopartite graph, and (A) the argument-projection monopartite graph. Monopartite Graph Projection: In order to conduct random walk on the graph, we project the bipartite graph R onto a monopartite graph Q=(X, E) between the predicates, or A=(Y,E) between the arguments (Zhou et al., 2007). Figure 1 illustrates the intuition of the projection. The links in Q represent the indirect connects between the predicates in R. Two predicates are connected in Q if they share at least one common neighbor argument in R. The weight of the links in Q could be set by arbitrary distance measures. We refer D as an instance of the projection Q by a given distance function Φ. Φ := R S D (2) Stochastic Walking Strategy: We introduce a probability function ∆ to transform the predicate distances D into transition probabilities P. Where P is a stochastic matrix, with each element pij represents the t</context>
</contexts>
<marker>Zhou, Renan, Medo, Zhang, 2007</marker>
<rawString>Tao Zhou, Jie Renan, Mat´uˇs Medo, and Yi-Cheng Zhang. 2007. Bipartite network projection and personal recommendation. Physical Review E, 76(4):046115.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>