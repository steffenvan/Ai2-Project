<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000007">
<title confidence="0.996309">
Generating Shifting Sentiment for a Conversational Agent
</title>
<author confidence="0.999643">
Simon Whitehead Lawrence Cavedon
</author>
<affiliation confidence="0.99976">
University of Melbourne, Australia RMIT University, Australia
</affiliation>
<email confidence="0.990058">
srwhitehead@gmail.com lawrence.cavedon@rmit.edu.au
</email>
<sectionHeader confidence="0.993655" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999840933333333">
We investigate techniques for generating al-
ternative output sentences with varying sen-
timent, using (an approximation to) the
Valentino method, based on SentiWordNet, of
Guerini et al. We extend this method by filter-
ing out unacceptable candidate sentences, us-
ing bigrams sourced from different corpora to
determine whether lexical substitutions are ap-
propriate in the given context. We also com-
pare the generated candidates against human
judgements of whether the desired sentiment
shift has occurred: our results suggest limi-
tations with the overall knowledge-based ap-
proach, and we propose potential directions
for improvement.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99989195">
The design of more natural or believable conver-
sational agents (Bates, 1994; Pelachaud and Bilvi,
2003) requires the need for such agents to communi-
cate affectively, by the display of emotion or attitude
towards objects, other agents, or states of affairs.
More engaging or influential agents may seek to ac-
tually affect their conversational partner at a deeper
level, for example, by influencing their emotional
state (van der Sluis and Mellish, 2008). Previous
work in this area has explored the use of gestures and
facial expression (Caridakis et al., 2007) and rhythm
and prosody of speech (Zovato et al., 2008) for ex-
pressing affect; however there has been little work
on generation of affective language in dialogue.
Our general approach is inspired by (Fleischman
and Hovy, 2002)’s work on generating different
surface-level versions of utterance content, depend-
ing on an agent’s appraisals towards objects, char-
acters and events in its environment. While their
approach is effective, it relies on manual creation
</bodyText>
<page confidence="0.801595">
89
</page>
<bodyText confidence="0.9999159375">
of lexical alternatives, customized to the application
domain. We are interested in approaches that will
scale, and can be applied domain-independently.
While our ultimate aim is generation of language
that relects emotional state, in this work we in-
vestigate the automatic generation of varying “sen-
timent” in output utterances; we focus on senti-
ment mainly due to the recent development of use-
ful resources for this task. (Guerini et al., 2008)’s
Valentino system is an approach to automatically
generating candidate output utterances with differ-
ent sentiment from an original; the authors suggest
ECAs as a possible application scenario for their
techniques. We explore this suggestion, implement-
ing a lexical substitution (McCarthy and Navigli,
2007) approach to dialogue generation with sen-
timent, using the Valentino approach and associ-
ated resources. Lexical substitution approaches raise
well-known challenges, and we investigate a number
of techniques to address these in Section 4; for ex-
ample, using bigrams and grammatical relations to
determine which substitutions are acceptable based
on their context in a sentence.1
Our techniques show improvement over naive lex-
ical substitution; however, an evaluation with human
subjects suggests that a deeper problem is that even
“acceptable” candidate sentences generated by the
method do not match human judgements with re-
spect to sentiment shift: i.e., alternatives labeled as
more positive (resp., negative) than the original by
the system are often seen as a sentiment shift in the
opposite direction by human judges (Section 5).
</bodyText>
<sectionHeader confidence="0.970991" genericHeader="method">
2 Background: Valentino
</sectionHeader>
<bodyText confidence="0.891298">
The Valentino2 system (Guerini et al., 2008) is a
tool developed from WordNet and SentiWordNet
</bodyText>
<footnote confidence="0.998191">
1Guerini et al. suggest this as an area for further work.
2VALENced Text INOculator
</footnote>
<note confidence="0.9928755">
Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 89–97,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.997455230769231">
designed to produce more positively or negatively
slanted versions of text. Input to the system consists
of a short sentence, and a target valence (between
-1 and 1), which indicates the desired polarity and
magnitude of sentiment in the modified output text.
Valentino uses a number of strategies for adding, re-
moving, or substituting certain words in order to al-
ter the overall sentiment of the sentence. Table 1
shows examples of Valentino output for different tar-
get valences, with modifications in italics.
To perform the word-substitution, (Guerini et al.,
2008) created a resource of OVVTs3: vectors of se-
mantically related terms which may substitute for
one another. The OVVTs were constructed us-
ing structural analysis of WordNet, and are divided
into adjectives, nouns, and verbs. (Guerini et al.,
2008) also constructed a separate resource of Mod-
ifier OVVTs which list adverbs that can be used to
modify verbs. Modifier OVVTs were created using
verbs extracted from certain FrameNet4 categories,
then recording which adverbs occur next to these
verbs in the British National Corpus (BNC). Each
term in the Valentino resource was assigned a senti-
ment valence, which corresponds to the SentiWord-
Net score of its parent WordNet synset. Table 2
shows part of an OVVT containing the noun ‘man’.5
</bodyText>
<table confidence="0.6908444">
Term POS Sense Valence
hunk n 1 0.375
man n 1 0
dude n 1 -0.125
beau n 2 -0.125
</table>
<tableCaption confidence="0.997722">
Table 2: (Abridged) example of an OVVT
</tableCaption>
<bodyText confidence="0.9990045">
To generate a modified sentence, (Guerini et al.,
2008) apply the following strategies to each word6
until the sentence valence (total of term valences)
meets the target:
</bodyText>
<listItem confidence="0.754745666666667">
1. Paraphrase: Lemmas with only one sense
are replaced by their WordNet gloss, which is
scored for sentiment using the OVVTs;
</listItem>
<footnote confidence="0.9974655">
3We assume OVVT stands for Ordered Vector of Valenced
Terms; this is not explicit in (Guerini et al., 2008).
4http://framenet.icsi.berkeley.edu/
5All our examples and evaluations are using a version of the
OVVTs made available by Marco Guerini on May 13, 2009.
6Actually, to the lemma of each word.
</footnote>
<listItem confidence="0.986834">
2. Use of most frequent senses: The OVVTs are
searched using only the most frequent senses;
3. Adjective modification: Adjectives are re-
placed with their stronger/weaker alternatives
such that the target valence is not exceeded;
4. Verb modification: Verbs are modified by in-
serting, removing, or replacing intensifier or
downtoner adverbs.
</listItem>
<bodyText confidence="0.9988885">
The final sentence is rendered as surface text by
transforming each of the inserted lemmas back into
the original morphology.
(Guerini et al., 2008) suggest their system’s po-
tential application to dialogue generation in an ECA,
enabling emotional variation. However, they do not
present an evaluation of Valentino’s effectiveness.
We expect that not all output utterances generated
using their method will be sensible in the context of
a believable ECA, for the following reasons:
Unconventional Word Usage: Upon inspection,
we found the OVVTs often contain several
words which are no longer conventionally used
(e.g. “beau”). For an ECA to be believable, we
hypothesise that such unpopular words should
not be considered as potential candidates for
substitution.
Incorrect Grammatical Context: The naive ver-
sion of the Valentino method assumes that all
words in an OVVT can be substituted for one
another regardless of their context in the sen-
tence (see Table 3); Guerini et al. propose this
as an area for future work. We explore semi-
informed solutions using bigrams and gram-
matical relations to eliminate syntactically in-
correct substitutions.
</bodyText>
<listItem confidence="0.836839666666667">
... Williams was not interested (in) girls
... Williams was not concerned (with) girls
... Williams was not fascinated (by) girls
</listItem>
<tableCaption confidence="0.998746">
Table 3: Illustration of grammatical context issues
</tableCaption>
<sectionHeader confidence="0.992629" genericHeader="method">
3 Implementation
</sectionHeader>
<bodyText confidence="0.978943333333333">
We implemented a lexical substitution approach to
varying valence, closely following the Valentino ap-
proach described in (Guerini et al., 2008). We did
</bodyText>
<page confidence="0.995844">
90
</page>
<table confidence="0.986264857142857">
Valence Sentence
n/a Bob admitted that John is absolutely the best guy
1.0 Bob wholeheartedly admitted that John is absolutely a superb hunk
0.5 Bob openly admitted that John is highly the redeemingest signor
0.0 Bob admitted that John is highly a well-behaved sir
-0.5 Bob sadly confessed that John is nearly a well-behaved beau
-1.0 Bob harshly confessed that John is pretty an acceptable eunuch
</table>
<tableCaption confidence="0.999777">
Table 1: Example of Valentino sentiment shifting (Guerini et al., 2008)
</tableCaption>
<bodyText confidence="0.999907181818182">
not implement all the above strategies—in partic-
ular, we did not implement paraphrasing, adverb
modification, or morphology synthesis; rather we
focused on developing techniques that would ad-
dress the lexical substitution issues described above.
As with Valentino, we calculate sentence valence
by summing the valences of all terms in the sentence
which are present in the OVVTs7. However, as a
variation on Valentino, we aggregated sentence shift
into five broad categories: “major positive shift”;
“minor positive shift”; “no shift”; “minor negative
shift”; “major negative shift”.
Since most OVVTs contain only lemmas, we first
performed lemmatisation using the MorphAdorner8
package. To locate a term in the OVVTs, we first
search for the original word morphology, then if no
match is found we try using the lemma.
As with (Guerini et al., 2008), we included candi-
dates from multiple senses of a matching word; how-
ever, rather than stopping at the third most frequent
sense, we explored up to sense forty so as to increase
the number of possible substitutions for terms.9 We
performed a very naive version of word sense dis-
ambiguation (WSD) (see below), but lack of WSD
was an issue (discussed later).
Alternative sentences were generated by modify-
ing at most a single word; this reduces the explo-
sion in the number of alternatives, but the methods
described could just as easily apply to alternatives
constructed by varying multiple words.
The novel aspect of our implementation was the
“candidate filtering” techniques: i.e. techniques
for deciding whether to accept a candidate replace-
</bodyText>
<footnote confidence="0.99557175">
7Since we ignore adverbs, we do not include these when
scoring a sentence.
8http://morphadorner.northwestern.edu/
9Increasing this further increased the number of alternatives
</footnote>
<bodyText confidence="0.9226575">
but did not improve performance.
ment term as substitute in a given sentence; this was
specifically designed to address the issues above. In
the next section, we describe filtering techniques us-
ing simple bigrams and grammatical relations, and
evaluate the effectiveness of each.
</bodyText>
<sectionHeader confidence="0.991126" genericHeader="method">
4 Evaluation: Candidate Filtering
</sectionHeader>
<bodyText confidence="0.990043714285714">
The data set we used for this evaluation consisted of
25 sentences, randomly extracted from the BNC.10
The sentences were sourced from the BNC to avoid
any bias which may have been introduced had the
test sentences been created manually. We required
that each test sentence satisfy the following condi-
tions11:
</bodyText>
<listItem confidence="0.76279275">
1. The sentence must contain between 6 and 10
words (to reflect length of a typical dialogue
utterance);
2. The sentence must contain at least one term
</listItem>
<bodyText confidence="0.9258671">
which is found in the OVVTs (otherwise it
would be pointless for evaluation purposes);
the term may have any valence.12
Our second filtering technique requires informa-
tion about the grammatical relations between terms
in a sentence (illustrated in Figure 1). For this, we
used a version of the BNC which was pre-processed
with the RASP parser (Briscoe et al., 2006).
Our gold standard for candidate acceptability was
created using the first author’s judgements.13 In or-
</bodyText>
<footnote confidence="0.832045888888889">
10The size of our test data set was capped at 25 due to the time
required to create the gold standard (i.e., judging 1030 substitu-
tions consistently).
11These constraints reduced our sample set from the —4.6
million sentences in the BNC to approx. 627,000 sentences.
12The sentence can theoretically be valence-shifted by sub-
stituting that term, regardless of the term’s valence.
13With more time we would of course have preferred to use
multiple annotators. However, the judgement task was simple
</footnote>
<page confidence="0.998148">
91
</page>
<bodyText confidence="0.998561666666667">
der to be judged as an ACCEPT by the annotator,
a generated sentence needed to satisfy the following
criteria (otherwise it was labelled REJECT):
</bodyText>
<listItem confidence="0.990993">
1. Semantic Equivalence: The new sentence
should convey reasonably equivalent semantics
compared to the original: e.g., phrases such as
‘young boy’ and ‘small boy’ were considered
acceptably close;14
2. Grammatical Correctness: The new sentence
should not contain grammatical errors. For the
gold standard, terms were manually converted
into their original morphological form before
annotation (e.g., if the lemma ‘speak’ replaced
an instance of ‘shouted’, then it was converted
to ‘spoke’).
</listItem>
<subsectionHeader confidence="0.986904">
4.1 Evaluation Methodology
</subsectionHeader>
<bodyText confidence="0.995924666666667">
To evaluate each candidate selection method, we
performed the following procedure for each of our
25 test sentences:
</bodyText>
<listItem confidence="0.995607538461538">
1. Find all matching15 terms and retrieve the va-
lence score of each;
2. For each matching term:
(a) Retrieve the corresponding list of alterna-
tive terms from the OVVTs;
(b) Generate several different candidate sen-
tences by substituting each alternative
term into the original sentence;
(c) Apply the chosen candidate selection
technique to each generated sentence, and
label each as ACCEPT or REJECT (for
step 3);
3. Compare all system classifications to our gold
</listItem>
<bodyText confidence="0.779895333333333">
standard (automatically), and mark each as ei-
ther a true positive (TP), false positive (FP),
true negative (TN), or false negative (FN).
We then used the TP, FP, TN and FN counts to
compute the accuracy, precision, recall and F-score
enough for us to believe it to be reliable.
</bodyText>
<footnote confidence="0.9836518">
14A fairly liberal view of “semantic equivalence” was taken;
for example, for our purposes we consider all sentences in Table
1 to be more-or-less semantically equivalent.
15A matching term is defined as a term which has a corre-
sponding entry in the OVVTs.
</footnote>
<bodyText confidence="0.997611166666667">
across all generated sentences. These metrics are
used to compare the relative performance between
each of our candidate selection methods.
We describe each of our techniques and the re-
sults; we present all the measurements in a single
table (Table 5).16
</bodyText>
<subsectionHeader confidence="0.989459">
4.2 Candidate filtering using bigrams
</subsectionHeader>
<bodyText confidence="0.999093181818182">
For each candidate sentence generated, we exam-
ined the bigrams including the newly substituted
term. If both17 bigrams appear in the BNC, we take
this as an indication that the substitution is accept-
able, and we accept the candidate sentence. Other-
wise, the candidate is rejected. We pre-processed the
BNC to extract 8,463,295 unique bigrams, formatted
as lemma/pos lemma/pos pairs, where lemma
is the lemmatised word, and pos is the WordNet
POS. As a simple attempt to address word-sense dis-
ambiguation, we discriminated on POS18 when ex-
tracting and matching these bigrams. For example,
‘drive/n home/n’ and ‘drive/v home/n’
would be considered separate bigrams, as the term
‘drive’ occurs with different POS in each. We chose
to lemmatise all bigrams due to the relatively small
size of the BNC. Also, we did not consider bigrams
which are interrupted by sentence punctuation, as
this indicates a phrase break.
We take this bigram approach as our base-
line.19 This simple technique has reasonable accu-
racy (0.752: see Table 5) but this is due largely to the
high number of true negatives produced. The false
negatives are mainly caused by the BNC’s relatively
limited bigram coverage.
To address this issue, we sourced our bigrams
from the Google Web 1T Corpus, which covers
approximately one trillion words of English text
sourced from publicly accessible web pages. Com-
pared with the BNC, it has much greater coverage,
containing ∼314 million bigrams. However, Web
1T does not contain POS information, and due to
its size we did not lemmatise the bigrams. Using a
</bodyText>
<footnote confidence="0.992429375">
16Note that had we performed no filtering, all TN’s would
become FP’s and all FN’s would befome TP’s.
17For terms beginning/ending a sentence (or phrase sur-
rounded by punctuation), we only examine one bigram.
18We differentiated only adjectives, nouns, verbs, and ad-
verbs; all other POS were considered equivalent for the pur-
poses of bigram extraction.
19A lower baseline would be to perform no filtering.
</footnote>
<page confidence="0.991115">
92
</page>
<bodyText confidence="0.999976205882353">
smaller corpus, these differences may reduce cov-
erage and bigram matching accuracy. However we
hypothesise that using the Web 1T corpus, such lim-
itations should be outweighed by its sheer size.
From Table 5, we see a substantial increase in re-
call over our previous baseline, which supports our
hypothesis that using a larger corpus would increase
true positives and reduce false negatives. However,
the increased coverage of the Web 1T corpus brings
with it more opportunities for false positives, the
number of which has increased dramatically from
our baseline, causing a reduction in precision and
accuracy. Despite this, due to increased recall, we
achieved an improvement in overall F-score.
Due to its web-based nature, the Web 1T corpus
will contain more errors than a corpus sourced from
published print, such as the BNC. Bigrams which
occur infrequently may be a source of noise. We
hypothesized that a substitution is acceptable if its
replacement bigrams occur in some reasonable pro-
portion to the original bigrams. Hence, we experi-
mented with bigram frequency ratios, where a can-
didate is accepted only if its ratio exceeds a given
threshold The ratio is calculated as fr/fo, where
fr and fo represent the replacement and original
bigram frequencies, respectively. We repeated our
Web 1T bigrams experiment for several ratio thresh-
olds between 0 and 0.9, and measured the changes in
accuracy, precision and recall. Our results showed
that frequency ratio thresholding can reduce false
positives, leading to slightly increased precision for
certain ratios. However, true positives are also re-
duced, and we sacrifice significant recall for only
minor gains in precision.
</bodyText>
<subsectionHeader confidence="0.916016">
4.3 Filter using grammatical
relations
</subsectionHeader>
<bodyText confidence="0.901717">
Candidate selection using bigrams is a somewhat
naive approach, as it considers only the surface text
without regard for the underlying grammatical rela-
tions (GRs) between terms. To illustrate, consider
the example shown in Table 4.
We observed that alternatives for ‘lovely’ such as
‘picturesque’ and ‘scenic’ were falsely rejected us-
ing BNC bigrams.20 As bigrams, “picturesque fam-
ily” and “scenic family” seem like unnatural ways
20These candidates were accepted using the Web 1T corpus.
Context on their lovely family holidays
Term lovely
Alt.s handsome, picturesque, pretty,
splendid, scenic, resplendent, ...
</bodyText>
<tableCaption confidence="0.990974">
Table 4: Sample context &amp; replacements for ‘lovely’
</tableCaption>
<bodyText confidence="0.999643214285714">
of describing a family. However, in this context
‘lovely’ modifies ’holiday’, not ‘family’: this dis-
tinction is not picked up using simple bigrams. To
address this limitation, we extended our bigram can-
didate selection technique to consider grammatical
relations (GRs).
Our GR technique uses an input sentence in
RASP format. We only change one term per sen-
tence as before; however we first extract the term’s
GRs from the RASP annotation. We convert each
binary21 GR into a GR-bigram using the original or-
dering of terms in the sentence. Figure 1 illustrates
the GRs for our example sentence, and how such
translate into GR-bigrams.
</bodyText>
<footnote confidence="0.702327">
GR-bigrams extracted for ‘lovely’:
1. “lovely holidays”
</footnote>
<figureCaption confidence="0.999457">
Figure 1: Grammatical relations and GR-bigrams
</figureCaption>
<bodyText confidence="0.990459333333333">
By converting GRs into bigrams, we can take ad-
vantage of Web 1T’s extensive coverage. However,
due to our restrictions on GR types, it is possible to
obtain zero GR-bigrams for some words in a sen-
tence. This happens when the word has no modifier
or comparative relations associated with it. For these
words, we revert to our bigram selection technique.
Our results for candidate selection using GRs are
again shown in Table 5. Surprisingly, this technique
performs worse than using regular bigrams for all
metrics when compared to our baseline. We suspect
our GR selection technique performs no better than
21We only examine binary comparative and modifier GR
types, as RASP provides many other syntactic relations which
we deemed not relevant to our task.
</bodyText>
<figure confidence="0.88703325">
ncmod
“On their lovely family holidays”
ncmod
detmod/poss
</figure>
<page confidence="0.995488">
93
</page>
<bodyText confidence="0.996417333333333">
Web 1T bigrams simply due to the corpus’ extensive
coverage, which leads to a similar amount of false
positives.
</bodyText>
<table confidence="0.9998536">
Selection BNC Web 1T Web 1T
Technique Bigrams Bigrams GRs
True positives 22 55 150% 54 145%
False positives 45 155 244% 169 276%
True negatives 288 178 -38% 164 -43%
False negatives 57 24 -58% 25 -56%
Accuracy 0.752 0.566 -25% 0.529 -30%
Precision 0.328 0.262 -20% 0.242 -26%
Recall 0.278 0.696 150% 0.684 145%
F-score 0.301 0.381 26% 0.358 19%
</table>
<tableCaption confidence="0.999078">
Table 5: Collated results for all experiments
</tableCaption>
<subsectionHeader confidence="0.930667">
4.4 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999955294117647">
To explain our experimental results, we first look at
how the performance changes between our different
versions relative to the baseline (i.e., BNC Bigrams):
see Table 5. Note first that, while all methods in-
creased the number of true positives and decreased
false negatives, any performance gains were simply
drowned out by the massive increases in false posi-
tives that occurred: this is the main cause of our low
precision and recall. For the following discussion,
we focus on the use of Web IT bigrams, which was
the best performing filtering technique.
Since false positives are the most important
source of error to avoid in an ECA, we focus on
these. We examined the false positive instances
and categorised each error into the following four
groups. The distribution of errors into these cate-
gories is shown in Table 6.
</bodyText>
<table confidence="0.999254833333333">
Category No. FP % of all FP
Change in Meaning 76 49.03%
Incorrect WSD 42 27.10%
Phrase/Metaphor 31 20.00%
Grammatical 6 3.87%
Total 155 100%
</table>
<tableCaption confidence="0.994464">
Table 6: Distribution of classification errors
</tableCaption>
<subsubsectionHeader confidence="0.550137">
4.4.1 Change in meaning
</subsubsectionHeader>
<bodyText confidence="0.999864891891892">
A major limitation of the OVVT resource is that
several of the alternative terms simply cause too
much semantic change even when the correct sense
of the original term is detected. For example, some
alternatives for ‘winner’ are words such as ‘sleeper’,
‘upsetter’, and ‘walloper’. In the context of the
phrase “Cash prizes will be offered to the winners”,
we will almost always prefer the generic ‘winner’.
We suspect this limitation arises due to the meth-
ods used to construct the OVVTs; in particular the
use of the WordNet hyponym and hypernym re-
lations. For example, the ‘thing’ category in Word-
Net encompasses a multitude of more specific terms,
such as ‘ornament’, ‘structure’, ‘surface’, and ‘in-
stallation’. These terms all made their way into the
OVVT for ‘thing’, yet they are rarely appropriate
substitutions for ‘thing’. Conversely, we may not
wish to replace any specific terms with the more
generic ‘thing’ as this removes too much meaning.
As this kind of error accounted for almost half
of our false positives, addressing this limitation
may lead to significant gains in performance. This
likely requires a more conservative approach to con-
structing the OVVTs themselves, e.g., by incorpo-
rating corpus-based information, as per (Guerini et
al., 2008)’s approach to constructing the Modifier-
OVVTs): the technique for mining appropriate verb-
adverb pairings from the BNC could be generalised
to include other POS types.
Related to the problem of semantic change is the
idea of context-dependent semantics. For example,
certain qualifiers have opposing effects depending
on the appraisal of the subject: consider a “long
term illness” compared to a “long term vacation”.
One possible solution to this problem is to modify
the way valences are calculated to take into account
which terms modify one another.
</bodyText>
<subsectionHeader confidence="0.856531">
4.4.2 Incorrect word-sense disambiguation
</subsectionHeader>
<bodyText confidence="0.999946555555555">
The WSD approach used in our work adapted
from (Guerini et al., 2008) is only a crude approx-
imation to a complex problem; the WSD-related
problems could at least be alleviated by incorpo-
rating a more sophisticated WSD approach into the
pipeline. However, even if we could determine the
correct sense of each word, we are still left with the
limitation that the OVVTs are not exhaustive in their
coverage, with several word senses missing.
</bodyText>
<page confidence="0.998192">
94
</page>
<subsectionHeader confidence="0.683455">
4.4.3 Phrases and metaphors
</subsectionHeader>
<bodyText confidence="0.999872714285714">
Several false positives were caused by phrases
such as “long term”. Metaphors were a similar
cause for error, e.g. “stepping stone”. Phrase and
metaphor detection should improve our technique’s
performance, especially since the OVVTs contain
several phrases; however, these are known difficult
challenges in themselves.
</bodyText>
<subsectionHeader confidence="0.924605">
4.4.4 Grammatical errors
</subsectionHeader>
<bodyText confidence="0.9995299">
A grammatical error occurs when the alternative
term is acceptable semantically, yet further syntactic
modification to the sentence is needed to preserve
correct grammar: see Table 3.
An extension of our bigram approach could be to
use a larger window around replaced words to assess
the suitability of a substitution. Recent work has
shown this technique could be used to rank poten-
tial substitutions in order of acceptability (Hawker,
2007) and is worth considering as future work.
</bodyText>
<subsectionHeader confidence="0.9872025">
4.4.5 Limitations of bigrams and corpus
coverage
</subsectionHeader>
<bodyText confidence="0.998910473684211">
In some cases, our bigram selection technique is
ineffective when the term being changed is flanked
by stop words. In a corpus of sufficient size and cov-
erage, the majority of terms will occur next to stop
words far more often than they occur next to other,
less common terms. Hence, bigrams containing stop
words were a common source of false positives.
This limitation could be addressed in future work
by extending our grammatical relation technique to
include ternary GRs, which provide relations for
noun-verb phrases such as “solution to fitness” and
“solution to health”. Given these, we could accept
or reject based on the presence of the accompany-
ing trigrams in the Web 1T corpus. As described in
(Hawker, 2007), use of an even larger window, such
as 4-grams and 5-grams around replaced terms may
also address this issue, however the size of the Web
1T corpus for larger N-grams presents serious pro-
cessing challenges.22
</bodyText>
<sectionHeader confidence="0.992022" genericHeader="conclusions">
5 Evaluation: Sentiment Shift
</sectionHeader>
<bodyText confidence="0.9932275">
The technqiues described above attempt to create ac-
ceptable candidates to shift sentiment. However, this
</bodyText>
<footnote confidence="0.8659045">
22(Hassan et al., 2007) describes a successful approach to lex-
ical substitution that combines multiple knowledge sources.
</footnote>
<bodyText confidence="0.999967217391304">
leaves open the question as to whether the technique
has its desired effect: i.e. appropriately shifting sen-
timent. We designed an experiment which aims to
measure correlation between human judgements of
the sentiment shift in our generated candidates, and
our system’s representation of sentiment shift.
We presented subjects with an original sentence,
along with one of the generated candidates. Our
six subjects had no specialised knowledge of the
task and were all native English speakers. Sub-
jects were asked to judge the modified sentence for
change in sentiment relative to the original accord-
ing to the five shift categories described earlier (i.e.,
major/minor positive/negative/no shift). In order
to avoid bias and to clarify the task, we explained
that sentiment should be separated from changes in
meaning, or the reader’s opinions about the sen-
tences. Instead, we urged subjects to ask themselves
the question: “Is the author of the second sentence
saying what they’re saying in a more positive or
more negative way, compared to the first sentence?”
The sentences used were extracted from the BNC
at random, using the restrictions listed above. We
extracted 250 sentences to be used as the originals,
each of which was used as input to our sentiment
shifting system. For each original sentence, we pro-
duced all possible candidates using our best per-
forming candidate selection method, Web 1T Bi-
grams. We also limited our generation to changing
one term per sentence, as to not produce a combi-
natorial explosion in the number of candidates gen-
erated. This produced approximately 3000 modi-
fied candidates, including several candidates with no
sentiment shift.
Upon inspection, we found many generated can-
didates contained the types of errors described
above. Hence, we manually extracted original and
modified sentences until we had a total of 50 origi-
nals, and 100 shifted sentences. In selecting which
sentences to keep, we chose ones which sounded
the most natural, or had the least amount of seman-
tic change from the original. Manual selection was
performed in order to prevent introducing any bias
into judgements when a subject is confronted with
a grammatically incorrect or unnatural sentence. We
also aimed for a fairly even distribution of the shifted
</bodyText>
<page confidence="0.99608">
95
</page>
<bodyText confidence="0.911534">
sentences into the five sentiment shift intervals.23
</bodyText>
<subsectionHeader confidence="0.521521">
5.1 Results and analysis
</subsectionHeader>
<bodyText confidence="0.9999815">
We performed a pairwise Kendall’s Tau rank cor-
relation (Kendall and Gibbons, 1962), which com-
pares each human’s judgements with the system’s
sentiment shift, for all 100 generated sentences.
Kendall’s Tau measures the correlation between two
distributions on a scale of -1 to 1, with 1 indicating
total agreement; -1 indicating total disagreement;
and 0 indicating no (or random) correlation.
We measured the correlation using the five senti-
ment shift intervals, and also using judgement po-
larities, i.e. whether a score is positive, nega-
tive or zero. We only report on polarity results as
the finer-grained comparison showed similar results
with slightly less correlation.
Our results are shown in Table 7; Kendall’s Tau
correlations are shown above the shaded diagonal,
while the corresponding p-values for statistical sig-
nificance are shown below the diagonal.
</bodyText>
<subsectionHeader confidence="0.59259">
Kendall&apos;s Tau Correlation
</subsectionHeader>
<table confidence="0.7286725">
sys h1 h2 h3 h4 h5 h6
sys 0.075 0.024 -0.099 0.034 0.022 -0.078
h1 0.413 0.276 0.423 0.417 0.339 0.249
h2 0.790 0.002 0.406 0.348 0.361 0.198
h3 0.273 0.000 0.000 0.418 0.300 0.343
h4 0.708 0.000 0.000 0.000 0.325 0.277
h5 0.810 0.000 0.000 0.001 0.000 0.189
h6 0.393 0.006 0.029 0.000 0.002 0.040
</table>
<tableCaption confidence="0.9899875">
Table 7: Kendall’s Tau rank correlation between system
(sys) and human (hi) judgement polarities
</tableCaption>
<bodyText confidence="0.999781444444444">
Although the correlation observed between inter-
annotator judgements of polarity was fairly low, it
is statistically significant in all cases using a confi-
dence level of p &lt; 0.05. While this indicates there
was some agreement between human annotators, the
relatively low correlation indicates that judging sen-
timent is a fairly subjective task. However, we saw
no correlation between the human judgements and
our system’s representation of sentiment shift.
</bodyText>
<footnote confidence="0.72297725">
23Note: the judgement of which sentiment-shift category a
sentence-pair fell into was made by the system (and subjects);
the manual intervention in the experiment design was to remove
unacceptable sentence-pairs.
</footnote>
<bodyText confidence="0.999820829268293">
The poor correlation between human and system
polarities can possibly be attributed to a number
of reasons. (Guerini et al., 2008) mention that in
SentiWordNet, several of the WordNet synsets are
valenced incorrectly, with many having a valence of
zero, which we also observed in the OVVT resource.
Our survey results suggest that SentiWordNet in its
current form is not ideally suited to the task of gen-
erating sentiment in text using the Valentino method.
SentiWordNet may be effective when classifying
the sentiment of large texts; the valence scores can
be considered to reflect the degree to which each
word represents a sentiment “feature”. However, it
is somewhat unrealistic to assume that every term
will have the same effect on sentiment in all con-
texts; assigning words a ‘universal’ sentiment score
seems non-intuitive, and a finer-grained representa-
tion of sentiment is needed for short texts such as
dialogue utterances.
In sentiment generation, when choosing a re-
placement term from a set of alternatives, we are
more interested in each candidate’s effect on senti-
ment, relative to the other candidates. While a re-
source of semantically clustered terms is needed for
this task (such as the OVVTs), terms within each
cluster need to be ranked for sentiment in a localised
way, taking account of positivity or negativity rela-
tive to other terms in the cluster. Upon inspection
of several OVVTs, this ranking is a straightforward
task for a human to perform (if time-consuming).
However, the context of a substitution often de-
termines its effects of sentiment. Hence, we ar-
gue that future work in sentiment generation using
knowledge-based techniques should extend existing
resources to encompass ranking of candidates in a
contextual way, rather than ranking them statically
out of context. For example, an MRE-style (Traum
et al., 2003) approach could be used which goes be-
yond scoring the overall sentiment of an utterance,
but considers how sentiment (or attitude) is directed
towards agents, objects and events.
</bodyText>
<footnote confidence="0.9472515">
Acknowledgements: We thank Marco Guerini for kindly
providing us with the OVVTs resource, Tim Baldwin for
helpful suggestions for the evaluation in Section 5, and
the referees for valuable feedback. Cavedon’s contribu-
tion was partially supported by the Australian Research
Council under Linkage Grant LP0882013.
</footnote>
<bodyText confidence="0.313766">
p-value
</bodyText>
<page confidence="0.960274">
96
</page>
<sectionHeader confidence="0.995759" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999732446428572">
Joseph Bates. 1994. The Role of Emotion in Believable
Agents. Communications of the ACM, 37(7):122–125.
Ted Briscoe, John Carroll, and Rebecca Watson. 2006.
The Second Release of the RASP System. In Proceed-
ings of ACL, pages 77–80, Sydney.
G. Caridakis, A. Raouzaiou, E. Bevacqua, M. Mancini,
K. Karpouzis, L. Malatesta, and C. Pelachaud. 2007.
Virtual Agent Multimodal Mimicry of Humans. Lan-
guage Resources and Evaluation, 41(3):367–388.
Michael Fleischman and Eduard Hovy. 2002. Towards
Emotional Variation in Speech-Based Natural Lan-
guage Generation. In Proceedings of the Second In-
ternational Natural Language Generation Conference,
pages 57–64, New York.
Marco Guerini, Carlo Strapparava, and Oliviero Stock.
2008. Valentino: A Tool for Valence Shifting of Natu-
ral Language Texts. In Proceedings of the 6th Interna-
tional Conference on Language Resources and Evalu-
ation, Marrakech.
Samer Hassan, Andras Csomai, Carmen Banea, Ravi
Sinha, and Rada Mihalcea. 2007. Unt: Subfinder:
combining knowledge sources for automatic lexical
substitution. In Proc. Fourth Int. Workshop on Se-
mantic Evaluations (SemEval 2007), pages 410–413,
Prague.
Tobias Hawker. 2007. USYD: WSD and Lexical Sub-
stitution Using the Web1T Corpus. In Proc. 4th Int.
Workshop on Semantic Evaluations (SemEval 2007),
pages 446–453, Prague.
M.G. Kendall and J.D. Gibbons. 1962. Rank Correlation
Methods. Griffin London.
Diana McCarthy and Roberto Navigli. 2007. SemEval-
2007 task 10: English lexical substitution task. In
Proc. Fourth Int. Workshop on Semantic Evaluations
(SemEval 2007), pages 48–53, Prague.
Catherine Pelachaud and Massimo Bilvi. 2003. Compu-
tational Model of Believable Conversational Agents.
In Communication in Multiagent Systems, volume
2650 of Lecture Notes in Computer Science, pages
300–317. Springer.
David Traum, Michael Fleischman, and Eduard Hovy.
2003. NL Generation for Virtual Humans in a Com-
plex Social Environment. In In Proceedings of the
AAAI Spring Symposium on Natural Language Gener-
ation in Spoken and Written Dialogue, pages 151–158,
Palo Alto.
Ielka van der Sluis and Chris Mellish. 2008. Towards
Affective Natural Language Generation: Empirical In-
vestigations. In Proceedings of the Symposium on Af-
fective Language in Human and Machine, AISB, pages
9–16, Aberdeen.
E. Zovato, F. Tini Brunozzi, and M. Danieli. 2008. Inter-
play between pragmatic and acoustic level to embody
expressive cues in a Text to Speech system. In Pro-
ceedings of the Symposium on Affective Language in
Human and Machine, AISB, pages 88–91, Aberdeen.
</reference>
<page confidence="0.999691">
97
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.825837">
<title confidence="0.99972">Generating Shifting Sentiment for a Conversational Agent</title>
<author confidence="0.997931">Simon Whitehead Lawrence Cavedon</author>
<affiliation confidence="0.999529">University of Melbourne, Australia RMIT University, Australia</affiliation>
<email confidence="0.99162">srwhitehead@gmail.comlawrence.cavedon@rmit.edu.au</email>
<abstract confidence="0.987455375">We investigate techniques for generating alternative output sentences with varying sentiment, using (an approximation to) the Valentino method, based on SentiWordNet, of Guerini et al. We extend this method by filtering out unacceptable candidate sentences, using bigrams sourced from different corpora to determine whether lexical substitutions are appropriate in the given context. We also compare the generated candidates against human judgements of whether the desired sentiment shift has occurred: our results suggest limitations with the overall knowledge-based approach, and we propose potential directions for improvement.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Joseph Bates</author>
</authors>
<title>The Role of Emotion in Believable Agents.</title>
<date>1994</date>
<journal>Communications of the ACM,</journal>
<volume>37</volume>
<issue>7</issue>
<contexts>
<context position="933" citStr="Bates, 1994" startWordPosition="126" endWordPosition="127">imation to) the Valentino method, based on SentiWordNet, of Guerini et al. We extend this method by filtering out unacceptable candidate sentences, using bigrams sourced from different corpora to determine whether lexical substitutions are appropriate in the given context. We also compare the generated candidates against human judgements of whether the desired sentiment shift has occurred: our results suggest limitations with the overall knowledge-based approach, and we propose potential directions for improvement. 1 Introduction The design of more natural or believable conversational agents (Bates, 1994; Pelachaud and Bilvi, 2003) requires the need for such agents to communicate affectively, by the display of emotion or attitude towards objects, other agents, or states of affairs. More engaging or influential agents may seek to actually affect their conversational partner at a deeper level, for example, by influencing their emotional state (van der Sluis and Mellish, 2008). Previous work in this area has explored the use of gestures and facial expression (Caridakis et al., 2007) and rhythm and prosody of speech (Zovato et al., 2008) for expressing affect; however there has been little work o</context>
</contexts>
<marker>Bates, 1994</marker>
<rawString>Joseph Bates. 1994. The Role of Emotion in Believable Agents. Communications of the ACM, 37(7):122–125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
<author>Rebecca Watson</author>
</authors>
<title>The Second Release of the RASP System. In</title>
<date>2006</date>
<booktitle>Proceedings of ACL,</booktitle>
<pages>77--80</pages>
<location>Sydney.</location>
<contexts>
<context position="11128" citStr="Briscoe et al., 2006" startWordPosition="1729" endWordPosition="1732">entences been created manually. We required that each test sentence satisfy the following conditions11: 1. The sentence must contain between 6 and 10 words (to reflect length of a typical dialogue utterance); 2. The sentence must contain at least one term which is found in the OVVTs (otherwise it would be pointless for evaluation purposes); the term may have any valence.12 Our second filtering technique requires information about the grammatical relations between terms in a sentence (illustrated in Figure 1). For this, we used a version of the BNC which was pre-processed with the RASP parser (Briscoe et al., 2006). Our gold standard for candidate acceptability was created using the first author’s judgements.13 In or10The size of our test data set was capped at 25 due to the time required to create the gold standard (i.e., judging 1030 substitutions consistently). 11These constraints reduced our sample set from the —4.6 million sentences in the BNC to approx. 627,000 sentences. 12The sentence can theoretically be valence-shifted by substituting that term, regardless of the term’s valence. 13With more time we would of course have preferred to use multiple annotators. However, the judgement task was simpl</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>Ted Briscoe, John Carroll, and Rebecca Watson. 2006. The Second Release of the RASP System. In Proceedings of ACL, pages 77–80, Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Caridakis</author>
<author>A Raouzaiou</author>
<author>E Bevacqua</author>
<author>M Mancini</author>
<author>K Karpouzis</author>
<author>L Malatesta</author>
<author>C Pelachaud</author>
</authors>
<title>Virtual Agent Multimodal Mimicry of Humans. Language Resources and Evaluation,</title>
<date>2007</date>
<volume>41</volume>
<issue>3</issue>
<contexts>
<context position="1418" citStr="Caridakis et al., 2007" startWordPosition="202" endWordPosition="205">e propose potential directions for improvement. 1 Introduction The design of more natural or believable conversational agents (Bates, 1994; Pelachaud and Bilvi, 2003) requires the need for such agents to communicate affectively, by the display of emotion or attitude towards objects, other agents, or states of affairs. More engaging or influential agents may seek to actually affect their conversational partner at a deeper level, for example, by influencing their emotional state (van der Sluis and Mellish, 2008). Previous work in this area has explored the use of gestures and facial expression (Caridakis et al., 2007) and rhythm and prosody of speech (Zovato et al., 2008) for expressing affect; however there has been little work on generation of affective language in dialogue. Our general approach is inspired by (Fleischman and Hovy, 2002)’s work on generating different surface-level versions of utterance content, depending on an agent’s appraisals towards objects, characters and events in its environment. While their approach is effective, it relies on manual creation 89 of lexical alternatives, customized to the application domain. We are interested in approaches that will scale, and can be applied domai</context>
</contexts>
<marker>Caridakis, Raouzaiou, Bevacqua, Mancini, Karpouzis, Malatesta, Pelachaud, 2007</marker>
<rawString>G. Caridakis, A. Raouzaiou, E. Bevacqua, M. Mancini, K. Karpouzis, L. Malatesta, and C. Pelachaud. 2007. Virtual Agent Multimodal Mimicry of Humans. Language Resources and Evaluation, 41(3):367–388.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Fleischman</author>
<author>Eduard Hovy</author>
</authors>
<title>Towards Emotional Variation in Speech-Based Natural Language Generation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Second International Natural Language Generation Conference,</booktitle>
<pages>57--64</pages>
<location>New York.</location>
<contexts>
<context position="1644" citStr="Fleischman and Hovy, 2002" startWordPosition="239" endWordPosition="242">vely, by the display of emotion or attitude towards objects, other agents, or states of affairs. More engaging or influential agents may seek to actually affect their conversational partner at a deeper level, for example, by influencing their emotional state (van der Sluis and Mellish, 2008). Previous work in this area has explored the use of gestures and facial expression (Caridakis et al., 2007) and rhythm and prosody of speech (Zovato et al., 2008) for expressing affect; however there has been little work on generation of affective language in dialogue. Our general approach is inspired by (Fleischman and Hovy, 2002)’s work on generating different surface-level versions of utterance content, depending on an agent’s appraisals towards objects, characters and events in its environment. While their approach is effective, it relies on manual creation 89 of lexical alternatives, customized to the application domain. We are interested in approaches that will scale, and can be applied domain-independently. While our ultimate aim is generation of language that relects emotional state, in this work we investigate the automatic generation of varying “sentiment” in output utterances; we focus on sentiment mainly due</context>
</contexts>
<marker>Fleischman, Hovy, 2002</marker>
<rawString>Michael Fleischman and Eduard Hovy. 2002. Towards Emotional Variation in Speech-Based Natural Language Generation. In Proceedings of the Second International Natural Language Generation Conference, pages 57–64, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Guerini</author>
<author>Carlo Strapparava</author>
<author>Oliviero Stock</author>
</authors>
<title>Valentino: A Tool for Valence Shifting of Natural Language Texts.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Language Resources and Evaluation,</booktitle>
<location>Marrakech.</location>
<contexts>
<context position="2328" citStr="Guerini et al., 2008" startWordPosition="345" endWordPosition="348">ance content, depending on an agent’s appraisals towards objects, characters and events in its environment. While their approach is effective, it relies on manual creation 89 of lexical alternatives, customized to the application domain. We are interested in approaches that will scale, and can be applied domain-independently. While our ultimate aim is generation of language that relects emotional state, in this work we investigate the automatic generation of varying “sentiment” in output utterances; we focus on sentiment mainly due to the recent development of useful resources for this task. (Guerini et al., 2008)’s Valentino system is an approach to automatically generating candidate output utterances with different sentiment from an original; the authors suggest ECAs as a possible application scenario for their techniques. We explore this suggestion, implementing a lexical substitution (McCarthy and Navigli, 2007) approach to dialogue generation with sentiment, using the Valentino approach and associated resources. Lexical substitution approaches raise well-known challenges, and we investigate a number of techniques to address these in Section 4; for example, using bigrams and grammatical relations t</context>
<context position="4458" citStr="Guerini et al., 2008" startWordPosition="667" endWordPosition="670">10. c�2010 Association for Computational Linguistics designed to produce more positively or negatively slanted versions of text. Input to the system consists of a short sentence, and a target valence (between -1 and 1), which indicates the desired polarity and magnitude of sentiment in the modified output text. Valentino uses a number of strategies for adding, removing, or substituting certain words in order to alter the overall sentiment of the sentence. Table 1 shows examples of Valentino output for different target valences, with modifications in italics. To perform the word-substitution, (Guerini et al., 2008) created a resource of OVVTs3: vectors of semantically related terms which may substitute for one another. The OVVTs were constructed using structural analysis of WordNet, and are divided into adjectives, nouns, and verbs. (Guerini et al., 2008) also constructed a separate resource of Modifier OVVTs which list adverbs that can be used to modify verbs. Modifier OVVTs were created using verbs extracted from certain FrameNet4 categories, then recording which adverbs occur next to these verbs in the British National Corpus (BNC). Each term in the Valentino resource was assigned a sentiment valence</context>
<context position="5715" citStr="Guerini et al., 2008" startWordPosition="880" endWordPosition="883">Net score of its parent WordNet synset. Table 2 shows part of an OVVT containing the noun ‘man’.5 Term POS Sense Valence hunk n 1 0.375 man n 1 0 dude n 1 -0.125 beau n 2 -0.125 Table 2: (Abridged) example of an OVVT To generate a modified sentence, (Guerini et al., 2008) apply the following strategies to each word6 until the sentence valence (total of term valences) meets the target: 1. Paraphrase: Lemmas with only one sense are replaced by their WordNet gloss, which is scored for sentiment using the OVVTs; 3We assume OVVT stands for Ordered Vector of Valenced Terms; this is not explicit in (Guerini et al., 2008). 4http://framenet.icsi.berkeley.edu/ 5All our examples and evaluations are using a version of the OVVTs made available by Marco Guerini on May 13, 2009. 6Actually, to the lemma of each word. 2. Use of most frequent senses: The OVVTs are searched using only the most frequent senses; 3. Adjective modification: Adjectives are replaced with their stronger/weaker alternatives such that the target valence is not exceeded; 4. Verb modification: Verbs are modified by inserting, removing, or replacing intensifier or downtoner adverbs. The final sentence is rendered as surface text by transforming each</context>
<context position="7737" citStr="Guerini et al., 2008" startWordPosition="1190" endWordPosition="1193">VT can be substituted for one another regardless of their context in the sentence (see Table 3); Guerini et al. propose this as an area for future work. We explore semiinformed solutions using bigrams and grammatical relations to eliminate syntactically incorrect substitutions. ... Williams was not interested (in) girls ... Williams was not concerned (with) girls ... Williams was not fascinated (by) girls Table 3: Illustration of grammatical context issues 3 Implementation We implemented a lexical substitution approach to varying valence, closely following the Valentino approach described in (Guerini et al., 2008). We did 90 Valence Sentence n/a Bob admitted that John is absolutely the best guy 1.0 Bob wholeheartedly admitted that John is absolutely a superb hunk 0.5 Bob openly admitted that John is highly the redeemingest signor 0.0 Bob admitted that John is highly a well-behaved sir -0.5 Bob sadly confessed that John is nearly a well-behaved beau -1.0 Bob harshly confessed that John is pretty an acceptable eunuch Table 1: Example of Valentino sentiment shifting (Guerini et al., 2008) not implement all the above strategies—in particular, we did not implement paraphrasing, adverb modification, or morph</context>
<context position="9068" citStr="Guerini et al., 2008" startWordPosition="1401" endWordPosition="1404"> described above. As with Valentino, we calculate sentence valence by summing the valences of all terms in the sentence which are present in the OVVTs7. However, as a variation on Valentino, we aggregated sentence shift into five broad categories: “major positive shift”; “minor positive shift”; “no shift”; “minor negative shift”; “major negative shift”. Since most OVVTs contain only lemmas, we first performed lemmatisation using the MorphAdorner8 package. To locate a term in the OVVTs, we first search for the original word morphology, then if no match is found we try using the lemma. As with (Guerini et al., 2008), we included candidates from multiple senses of a matching word; however, rather than stopping at the third most frequent sense, we explored up to sense forty so as to increase the number of possible substitutions for terms.9 We performed a very naive version of word sense disambiguation (WSD) (see below), but lack of WSD was an issue (discussed later). Alternative sentences were generated by modifying at most a single word; this reduces the explosion in the number of alternatives, but the methods described could just as easily apply to alternatives constructed by varying multiple words. The </context>
<context position="22554" citStr="Guerini et al., 2008" startWordPosition="3568" endWordPosition="3571">terms, such as ‘ornament’, ‘structure’, ‘surface’, and ‘installation’. These terms all made their way into the OVVT for ‘thing’, yet they are rarely appropriate substitutions for ‘thing’. Conversely, we may not wish to replace any specific terms with the more generic ‘thing’ as this removes too much meaning. As this kind of error accounted for almost half of our false positives, addressing this limitation may lead to significant gains in performance. This likely requires a more conservative approach to constructing the OVVTs themselves, e.g., by incorporating corpus-based information, as per (Guerini et al., 2008)’s approach to constructing the ModifierOVVTs): the technique for mining appropriate verbadverb pairings from the BNC could be generalised to include other POS types. Related to the problem of semantic change is the idea of context-dependent semantics. For example, certain qualifiers have opposing effects depending on the appraisal of the subject: consider a “long term illness” compared to a “long term vacation”. One possible solution to this problem is to modify the way valences are calculated to take into account which terms modify one another. 4.4.2 Incorrect word-sense disambiguation The W</context>
<context position="30124" citStr="Guerini et al., 2008" startWordPosition="4764" endWordPosition="4767"> While this indicates there was some agreement between human annotators, the relatively low correlation indicates that judging sentiment is a fairly subjective task. However, we saw no correlation between the human judgements and our system’s representation of sentiment shift. 23Note: the judgement of which sentiment-shift category a sentence-pair fell into was made by the system (and subjects); the manual intervention in the experiment design was to remove unacceptable sentence-pairs. The poor correlation between human and system polarities can possibly be attributed to a number of reasons. (Guerini et al., 2008) mention that in SentiWordNet, several of the WordNet synsets are valenced incorrectly, with many having a valence of zero, which we also observed in the OVVT resource. Our survey results suggest that SentiWordNet in its current form is not ideally suited to the task of generating sentiment in text using the Valentino method. SentiWordNet may be effective when classifying the sentiment of large texts; the valence scores can be considered to reflect the degree to which each word represents a sentiment “feature”. However, it is somewhat unrealistic to assume that every term will have the same ef</context>
</contexts>
<marker>Guerini, Strapparava, Stock, 2008</marker>
<rawString>Marco Guerini, Carlo Strapparava, and Oliviero Stock. 2008. Valentino: A Tool for Valence Shifting of Natural Language Texts. In Proceedings of the 6th International Conference on Language Resources and Evaluation, Marrakech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samer Hassan</author>
<author>Andras Csomai</author>
<author>Carmen Banea</author>
<author>Ravi Sinha</author>
<author>Rada Mihalcea</author>
</authors>
<title>Unt: Subfinder: combining knowledge sources for automatic lexical substitution. In</title>
<date>2007</date>
<booktitle>Proc. Fourth Int. Workshop on Semantic Evaluations (SemEval</booktitle>
<pages>410--413</pages>
<location>Prague.</location>
<contexts>
<context position="25586" citStr="Hassan et al., 2007" startWordPosition="4049" endWordPosition="4052">ry GRs, which provide relations for noun-verb phrases such as “solution to fitness” and “solution to health”. Given these, we could accept or reject based on the presence of the accompanying trigrams in the Web 1T corpus. As described in (Hawker, 2007), use of an even larger window, such as 4-grams and 5-grams around replaced terms may also address this issue, however the size of the Web 1T corpus for larger N-grams presents serious processing challenges.22 5 Evaluation: Sentiment Shift The technqiues described above attempt to create acceptable candidates to shift sentiment. However, this 22(Hassan et al., 2007) describes a successful approach to lexical substitution that combines multiple knowledge sources. leaves open the question as to whether the technique has its desired effect: i.e. appropriately shifting sentiment. We designed an experiment which aims to measure correlation between human judgements of the sentiment shift in our generated candidates, and our system’s representation of sentiment shift. We presented subjects with an original sentence, along with one of the generated candidates. Our six subjects had no specialised knowledge of the task and were all native English speakers. Subject</context>
</contexts>
<marker>Hassan, Csomai, Banea, Sinha, Mihalcea, 2007</marker>
<rawString>Samer Hassan, Andras Csomai, Carmen Banea, Ravi Sinha, and Rada Mihalcea. 2007. Unt: Subfinder: combining knowledge sources for automatic lexical substitution. In Proc. Fourth Int. Workshop on Semantic Evaluations (SemEval 2007), pages 410–413, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tobias Hawker</author>
</authors>
<title>USYD: WSD and Lexical Substitution Using the Web1T Corpus.</title>
<date>2007</date>
<booktitle>In Proc. 4th Int. Workshop on Semantic Evaluations (SemEval</booktitle>
<pages>446--453</pages>
<location>Prague.</location>
<contexts>
<context position="24406" citStr="Hawker, 2007" startWordPosition="3858" endWordPosition="3859">ove our technique’s performance, especially since the OVVTs contain several phrases; however, these are known difficult challenges in themselves. 4.4.4 Grammatical errors A grammatical error occurs when the alternative term is acceptable semantically, yet further syntactic modification to the sentence is needed to preserve correct grammar: see Table 3. An extension of our bigram approach could be to use a larger window around replaced words to assess the suitability of a substitution. Recent work has shown this technique could be used to rank potential substitutions in order of acceptability (Hawker, 2007) and is worth considering as future work. 4.4.5 Limitations of bigrams and corpus coverage In some cases, our bigram selection technique is ineffective when the term being changed is flanked by stop words. In a corpus of sufficient size and coverage, the majority of terms will occur next to stop words far more often than they occur next to other, less common terms. Hence, bigrams containing stop words were a common source of false positives. This limitation could be addressed in future work by extending our grammatical relation technique to include ternary GRs, which provide relations for noun</context>
</contexts>
<marker>Hawker, 2007</marker>
<rawString>Tobias Hawker. 2007. USYD: WSD and Lexical Substitution Using the Web1T Corpus. In Proc. 4th Int. Workshop on Semantic Evaluations (SemEval 2007), pages 446–453, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M G Kendall</author>
<author>J D Gibbons</author>
</authors>
<title>Rank Correlation Methods.</title>
<date>1962</date>
<location>Griffin London.</location>
<contexts>
<context position="28122" citStr="Kendall and Gibbons, 1962" startWordPosition="4451" endWordPosition="4454">d modified sentences until we had a total of 50 originals, and 100 shifted sentences. In selecting which sentences to keep, we chose ones which sounded the most natural, or had the least amount of semantic change from the original. Manual selection was performed in order to prevent introducing any bias into judgements when a subject is confronted with a grammatically incorrect or unnatural sentence. We also aimed for a fairly even distribution of the shifted 95 sentences into the five sentiment shift intervals.23 5.1 Results and analysis We performed a pairwise Kendall’s Tau rank correlation (Kendall and Gibbons, 1962), which compares each human’s judgements with the system’s sentiment shift, for all 100 generated sentences. Kendall’s Tau measures the correlation between two distributions on a scale of -1 to 1, with 1 indicating total agreement; -1 indicating total disagreement; and 0 indicating no (or random) correlation. We measured the correlation using the five sentiment shift intervals, and also using judgement polarities, i.e. whether a score is positive, negative or zero. We only report on polarity results as the finer-grained comparison showed similar results with slightly less correlation. Our resu</context>
</contexts>
<marker>Kendall, Gibbons, 1962</marker>
<rawString>M.G. Kendall and J.D. Gibbons. 1962. Rank Correlation Methods. Griffin London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Roberto Navigli</author>
</authors>
<title>SemEval2007 task 10: English lexical substitution task. In</title>
<date>2007</date>
<booktitle>Proc. Fourth Int. Workshop on Semantic Evaluations (SemEval</booktitle>
<pages>48--53</pages>
<location>Prague.</location>
<contexts>
<context position="2636" citStr="McCarthy and Navigli, 2007" startWordPosition="388" endWordPosition="391">ied domain-independently. While our ultimate aim is generation of language that relects emotional state, in this work we investigate the automatic generation of varying “sentiment” in output utterances; we focus on sentiment mainly due to the recent development of useful resources for this task. (Guerini et al., 2008)’s Valentino system is an approach to automatically generating candidate output utterances with different sentiment from an original; the authors suggest ECAs as a possible application scenario for their techniques. We explore this suggestion, implementing a lexical substitution (McCarthy and Navigli, 2007) approach to dialogue generation with sentiment, using the Valentino approach and associated resources. Lexical substitution approaches raise well-known challenges, and we investigate a number of techniques to address these in Section 4; for example, using bigrams and grammatical relations to determine which substitutions are acceptable based on their context in a sentence.1 Our techniques show improvement over naive lexical substitution; however, an evaluation with human subjects suggests that a deeper problem is that even “acceptable” candidate sentences generated by the method do not match </context>
</contexts>
<marker>McCarthy, Navigli, 2007</marker>
<rawString>Diana McCarthy and Roberto Navigli. 2007. SemEval2007 task 10: English lexical substitution task. In Proc. Fourth Int. Workshop on Semantic Evaluations (SemEval 2007), pages 48–53, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine Pelachaud</author>
<author>Massimo Bilvi</author>
</authors>
<title>Computational Model of Believable Conversational Agents.</title>
<date>2003</date>
<booktitle>In Communication in Multiagent Systems,</booktitle>
<volume>2650</volume>
<pages>300--317</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="961" citStr="Pelachaud and Bilvi, 2003" startWordPosition="128" endWordPosition="131">he Valentino method, based on SentiWordNet, of Guerini et al. We extend this method by filtering out unacceptable candidate sentences, using bigrams sourced from different corpora to determine whether lexical substitutions are appropriate in the given context. We also compare the generated candidates against human judgements of whether the desired sentiment shift has occurred: our results suggest limitations with the overall knowledge-based approach, and we propose potential directions for improvement. 1 Introduction The design of more natural or believable conversational agents (Bates, 1994; Pelachaud and Bilvi, 2003) requires the need for such agents to communicate affectively, by the display of emotion or attitude towards objects, other agents, or states of affairs. More engaging or influential agents may seek to actually affect their conversational partner at a deeper level, for example, by influencing their emotional state (van der Sluis and Mellish, 2008). Previous work in this area has explored the use of gestures and facial expression (Caridakis et al., 2007) and rhythm and prosody of speech (Zovato et al., 2008) for expressing affect; however there has been little work on generation of affective la</context>
</contexts>
<marker>Pelachaud, Bilvi, 2003</marker>
<rawString>Catherine Pelachaud and Massimo Bilvi. 2003. Computational Model of Believable Conversational Agents. In Communication in Multiagent Systems, volume 2650 of Lecture Notes in Computer Science, pages 300–317. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Traum</author>
<author>Michael Fleischman</author>
<author>Eduard Hovy</author>
</authors>
<title>NL Generation for Virtual Humans in a Complex Social Environment. In</title>
<date>2003</date>
<booktitle>In Proceedings of the AAAI Spring Symposium on Natural Language Generation in Spoken and Written Dialogue,</booktitle>
<pages>151--158</pages>
<location>Palo Alto.</location>
<marker>Traum, Fleischman, Hovy, 2003</marker>
<rawString>David Traum, Michael Fleischman, and Eduard Hovy. 2003. NL Generation for Virtual Humans in a Complex Social Environment. In In Proceedings of the AAAI Spring Symposium on Natural Language Generation in Spoken and Written Dialogue, pages 151–158, Palo Alto.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ielka van der Sluis</author>
<author>Chris Mellish</author>
</authors>
<title>Towards Affective Natural Language Generation: Empirical Investigations.</title>
<date>2008</date>
<booktitle>In Proceedings of the Symposium on Affective Language in Human and Machine, AISB,</booktitle>
<pages>9--16</pages>
<location>Aberdeen.</location>
<marker>van der Sluis, Mellish, 2008</marker>
<rawString>Ielka van der Sluis and Chris Mellish. 2008. Towards Affective Natural Language Generation: Empirical Investigations. In Proceedings of the Symposium on Affective Language in Human and Machine, AISB, pages 9–16, Aberdeen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Zovato</author>
<author>F Tini Brunozzi</author>
<author>M Danieli</author>
</authors>
<title>Interplay between pragmatic and acoustic level to embody expressive cues in a Text to Speech system.</title>
<date>2008</date>
<booktitle>In Proceedings of the Symposium on Affective Language in Human and Machine, AISB,</booktitle>
<pages>88--91</pages>
<location>Aberdeen.</location>
<contexts>
<context position="1473" citStr="Zovato et al., 2008" startWordPosition="212" endWordPosition="215">tion The design of more natural or believable conversational agents (Bates, 1994; Pelachaud and Bilvi, 2003) requires the need for such agents to communicate affectively, by the display of emotion or attitude towards objects, other agents, or states of affairs. More engaging or influential agents may seek to actually affect their conversational partner at a deeper level, for example, by influencing their emotional state (van der Sluis and Mellish, 2008). Previous work in this area has explored the use of gestures and facial expression (Caridakis et al., 2007) and rhythm and prosody of speech (Zovato et al., 2008) for expressing affect; however there has been little work on generation of affective language in dialogue. Our general approach is inspired by (Fleischman and Hovy, 2002)’s work on generating different surface-level versions of utterance content, depending on an agent’s appraisals towards objects, characters and events in its environment. While their approach is effective, it relies on manual creation 89 of lexical alternatives, customized to the application domain. We are interested in approaches that will scale, and can be applied domain-independently. While our ultimate aim is generation o</context>
</contexts>
<marker>Zovato, Brunozzi, Danieli, 2008</marker>
<rawString>E. Zovato, F. Tini Brunozzi, and M. Danieli. 2008. Interplay between pragmatic and acoustic level to embody expressive cues in a Text to Speech system. In Proceedings of the Symposium on Affective Language in Human and Machine, AISB, pages 88–91, Aberdeen.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>