<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.046879">
<title confidence="0.992885">
Storybase: Towards Building a Knowledge Base for News Events
</title>
<author confidence="0.995881">
Zhaohui Wu†, Chen Liang‡, C. Lee Giles‡††Computer Science and Engineering, ‡Information Sciences and Technology
</author>
<affiliation confidence="0.939985">
The Pennsylvania State University
</affiliation>
<address confidence="0.674">
University Park, PA 16802, USA
</address>
<email confidence="0.997725">
zzw109@psu.edu, {cul226,giles}@ist.psu.edu
</email>
<sectionHeader confidence="0.993823" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999873333333333">
To better organize and understand online
news information, we propose Storybase1,
a knowledge base for news events that
builds upon Wikipedia current events and
daily Web news. It first constructs sto-
ries and their timelines based on Wikipedi-
a current events and then detects and links
daily news to enrich those Wikipedia sto-
ries with more comprehensive events. We
encode events and develop efficient even-
t clustering and chaining techniques in an
event space. We demonstrate Storybase
with a news events search engine that help-
s find historical and ongoing news stories
and inspect their dynamic timelines.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997971285714286">
Users are often overwhelmed by the flood of infor-
mation, especially frequently daily updated news.
Search engines effectively find news snippets and
related Web pages, or group similar pages in clus-
ters. However, it remains difficult to coherently
connect isolated information nuggets to form the
big picture, or to accurately track the flow of in-
formation to show the evolution of events. For ex-
ample, current news search engines or aggregation
sites, such as Google or Yahoo news, show only
isolated daily news events, without linking them
to historical events or show storylines.
Most existing knowledge bases such as DBpe-
dia and Freebase are designed for managing gen-
eral named entities or concepts and often lack cov-
erage or representation for temporally evolving
news events. For example, as of this writing, Free-
base has not treated “2014 Ferguson unrest” as an
“event”, let alone show its sub events or timelines.
As such, we propose building a knowledge base,
namely Storybase, that stores news events in a se-
</bodyText>
<footnote confidence="0.913992">
1http://breckenridge.ist.psu.edu:8000/storybase
</footnote>
<bodyText confidence="0.998681931034483">
mantic coherent schema that could explicitly dis-
play their evolving timelines. We define a story
as a set of topically or causally related and tempo-
rally ordered news events, usually corresponding
to a Wikipedia article such as “Malaysia Airlines
Flight 370”. An event is defined as something im-
portant happening at some time in some place, re-
ported by a set of news articles, which is encoded
by named entities, actors and actions used as the
main points in a plot.
Building an event knowledge base from scratch
is challenging, since it is difficult to obtain a
gold standard for events and their timelines. We
found that Wikipedia current events2 provide high-
quality manually edited news events. To scale up,
we link daily news sources and fit them into ex-
isting stories or create new stories, by efficien-
t event detection and storyline construction tech-
niques in a semantic space which is encoded with
news events’ entities, actors, and actions. From
April 1, 2013 to March 1, 2015, we have collect-
ed 1,256 stories consisting of 35,362 news events
from Wikipedia current events, and 35,166,735
daily news articles. Experimental evaluation com-
pares our methods for event clustering and chain-
ing with multiple baselines. We build a news event
search engine based on Storybase to show news s-
tories and their event chains.
Our main contributions include:
</bodyText>
<listItem confidence="0.995573222222222">
• A news event knowledge base, Storybase,
with a search interface for news storylines;
• The introduction of Wikipedia current events
as resources for building event knowledge
bases and as datasets for event detection and
storyline construction;
• New approaches for event clustering and
chaining with experimental comparisons to
other baselines.
</listItem>
<footnote confidence="0.994443">
2http://en.wikipedia.org/wiki/Portal:Current events
</footnote>
<page confidence="0.950719">
133
</page>
<note confidence="0.8425425">
Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 133–138,
Beijing, China, July 26-31, 2015. c�2015 ACL and AFNLP
</note>
<figureCaption confidence="0.998116">
Figure 1: Overall process of building Storybase
Figure 2: Examples of Wikipedia current events
</figureCaption>
<figure confidence="0.977146125">
+
News
Crawling web
news from
various sources
Preprocess
Categorization
Event Encoding
Clustering
Chaining
2. 2014 Ukrainian revolution
3. Malaysia Airlines Flight 370
1. War in Afghanistan
Knowledge Base
Event category
Story
Attacks and armed conflicts;
Disaster and accidents;
International relations;
Law and crime;
. . .
Actors, Actions
Entities, Theme
2 Overview and Definitions
</figure>
<figureCaption confidence="0.877194777777778">
Figure 1 shows the overall process for building S-
torybase. Input is daily crawled web news arti-
cles and Wikipedia current events. This generates
the storylines and builds the Storybase using five
steps system: preprocessing, categorization, event
encoding, clustering, and chaining. Details are in
Section 4. A news event search engine is built to
provide a query based interface to search and visu-
alize the Storybase, which is shown in Section 5.
</figureCaption>
<bodyText confidence="0.996118">
We now define concepts that will be frequently
referred to.
</bodyText>
<listItem confidence="0.9997699">
• A event identifies something (non-trivial)
happening in a certain place at a certain
time (Yang et al., 1999); it is a set of news
articles on the same news report.
• A story is a set of topical related news events.
• A storyline is a series of temporally ordered
events of the same story.
• Actors in an event are named entities that
make or receive actions.
• Actions are verbs that connect actors.
</listItem>
<bodyText confidence="0.999891222222222">
For example, as shown in Figure 2, “Pro-Russian
militants seize the regional prosecutor’s office in
the eastern Ukrainian city of Donetsk” is an even-
t reported by a set of articles from different news
sites. “2014 pro-Russian unrest in Ukraine” repre-
sents a story that consists of temporally evolving
events, which forms a storyline. “Pro-Russian mil-
itants” and “the regional prosecutor’s office” are
actors while “seize” is the action.
</bodyText>
<sectionHeader confidence="0.992053" genericHeader="method">
3 Data Collection
</sectionHeader>
<bodyText confidence="0.99998296969697">
Wikipedia current events list manually edited dai-
ly news events since 1998, which provide rich
semantics and structure for news stories and
events such as story names, event categories (not
Wikipedia categories), and links to Wikipedia con-
cepts, as shown by Figure 2. For example, we
can observe that the event “Pro-Russian militants
seize the regional prosecutor’s office in the east-
ern Ukrainian city of Donetsk” belongs to the sto-
ry “2014 pro-Russian unrest in Ukraine” and the
category “Armed conflicts and attacks”, contain-
ing links to Wikipedia concepts “Eastern Ukraini-
an” and “Donetsk”. Thus, we construct a storyline
for “2014 pro-Russian unrest in Ukraine” by con-
necting all events under it.
The category labels provide a natural way
to classify news events. However, since the
Wikipedia events are edited by various users, the
category labels are not always consistent. For ex-
ample, one may use “Armed conflicts and attack-
s” while others might use “Attack and conflict”.
After canonicalization using Levenshtein distance
and grouping similar labels using word based Jac-
card similarity, we manually clean all the labels
into 12 categories, as shown in Table 1.
Although Wikipedia provides high quality man-
ually edited news events, it covers only a smal-
l number of events every day, usually less than 30.
Thus, to scale up Storybase and make the stories
more comprehensive, starting from April 1, 2013,
we crawl daily news articles from a large number
of sources from various news publishers, provided
by GDELT3 project (Leetaru and Schrodt, 2013).
</bodyText>
<sectionHeader confidence="0.977342" genericHeader="method">
4 Building Storybase
</sectionHeader>
<subsectionHeader confidence="0.999699">
4.1 Preprocess and Categorization
</subsectionHeader>
<bodyText confidence="0.9999526">
To extract and parse Wikipedia current events,
we implement two template based extractors for
events between January 2003 and April 2006 and
those events after April 2006 respectively due to
their difference in templates. The news articles
linked at the end of each event description are also
crawled. We use boilerpipe4 to extract the title and
main text content of each news article. We extrac-
t the first three sentences in the main content for
summarization.
</bodyText>
<footnote confidence="0.9998675">
3http://www.gdeltproject.org/data.html
4https://code.google.com/p/boilerpipe/
</footnote>
<page confidence="0.995249">
134
</page>
<figure confidence="0.975561538461538">
ID Category
1 conflict, attack
2 disaster, accident
3 international relations
4 politics and elections
5 law and crime
6 business and economy
7 science and technology
8 sports
9 arts and culture
10 health, medicine, environment
11 education
12 deaths
</figure>
<tableCaption confidence="0.714786">
Table 1: Categories of events in Storybase
</tableCaption>
<figureCaption confidence="0.999692">
Figure 3: Screenshot of category “Conflict”
</figureCaption>
<bodyText confidence="0.999801888888889">
We maintain an N-to-1 mapping for each cate-
gory listed in Table 1. For example, any category
label in {“Armed conflicts and attacks”, “conflict-
s and attacks”, “Armed conflicts”, “Attacks and
conflicts”, “Attacks and armed conflicts”} will be
mapped to Category 1. For an event not belonging
to existing stories, we label its category using the
majority of their k-nearest (k=10) neighbors based
on the cosine similarity of event descriptions.
</bodyText>
<subsectionHeader confidence="0.990293">
4.2 Event Encoding
</subsectionHeader>
<bodyText confidence="0.999843714285714">
We encode an event as a vector containing named
entities, actors and actions. Named entities such
as people and locations in news reports contain
important information of the event. Core entities
that play important roles in an event are called
actors, which are usually people or organizations
that make or receive actions. We use the Stanford
CoreNLP (Manning et al., 2014) for the named
entity recognition and extract all Wikipedia con-
cepts appearing in news content. Entities that are
subjects or objects in the title and description are
treated as actors. If no entities are found, we then
use the CAMEO dictionaries5 for actor and action
extraction.
</bodyText>
<subsectionHeader confidence="0.999623">
4.3 Event Clustering and Chaining
</subsectionHeader>
<bodyText confidence="0.9966685">
Event clustering groups together news on
the same event. Locality-Sensitive Hashing
(LSH) (Van Durme and Lall, 2010) is used for
fast similarity comparison. We first do dedupli-
cation on all articles on the same date using 84
bits sim-Hashing (Charikar, 2002). We then use
modified sim-Hashing on the vector space of event
described in Section 4.2, rather than shingling or
bag-of-words (Paulev et al., 2010). A new article
is encoded into the event space with the content
</bodyText>
<footnote confidence="0.754924">
5http://eventdata.parusanalytics.com/data.dir/cameo.html
</footnote>
<bodyText confidence="0.998015342105263">
of its title and description. Its LSH key k (84 bit-
s binary code) is computed and compared to keys
of other articles. Articles whose keys have ham-
ming distances smaller than a threshold 0 among
each other will be clustered as an event. We then
check all events of the previous date and merge
two events into one if their distance (average ham-
ming distances of key pairs) is smaller than 0 and
their categories are the same.
Event chaining links an event to an existing
story or determines if it is the starting event of
a new story. While LSH could give high-purity
event clusters, it might not be able to determine
whether two events with distance larger than 0 are
topically related, or belong to the same story. Intu-
itively, an event should bring some novelty and p-
reserve some common information compared with
the previous ones in the story, causing a trade-
off between relevance and novelty, which could
be measured by some textual similarity. Adding
an event should also keep the storyline coherent.
To model coherence, we investigate two features,
the Connecting-Dots coherence score (Shahaf and
Guestrin, 2010) and KL-divergence. We use the
gradient boosting tree (Friedman, 2001) to learn if
an event belongs to a story by using the above fea-
tures of relevance/novelty and coherence, all based
on storylines constructed from Wikipedia current
events. For a story {ei,...,em}, (ei, {e1, ..., ei_1})
are positive pairs; (e_, {e1,..., ei_1}) are negative
pairs, i = 2,..., m, where e_ is an event randomly
sampled from other stories in the same date of ei.
For all GDELT news on date t, we first detect all
events using event clustering. For an event that has
not been merged into events of the previous date,
we use the model to decide which story it belongs
to. If none, the event will be served as the first
event of a new story with an empty story name.
</bodyText>
<page confidence="0.998589">
135
</page>
<figureCaption confidence="0.996602">
Figure 4: Screenshot results for the query “Crimea”
</figureCaption>
<sectionHeader confidence="0.983162" genericHeader="method">
5 Storybase Demonstration
</sectionHeader>
<bodyText confidence="0.999980722222222">
We demonstrate Storybase by building a news
event search engine that can retrieve and visual-
ize the stories. In the backend, we implemented
various facilities, such as ranking functions (B-
M25, cosine similarity, and inner product) and re-
fining metrics (popularity and recency). The rank-
ing functions compute relevance between queries
and stories while a story is represented by the story
name and all event descriptions. Popularity mea-
sures the impact of stories on Web. For simplic-
ity, we implement popularity as the accumulative
number of unique news reports for all events of a
story. Recency measures the timeliness or fresh-
ness, which is an important and helpful feature
for sorting and filtering news stories, and is im-
plemented by simply sorting stories based on the
date of their latest event.
The front page gives a category navigation list
in the left, a search box in the middle, and the re-
cent stories behind the box. A category links to the
recent events from the category, as shown by Fig-
ure 3. The demo contains three views: storyline,
story, and event. Figure 4 shows a screenshot of
the storyline view returned by querying “Crimea”.
The results are organized at the story level, where
we show a thumbnail of the event chain for each
story. The description, category, and date of an
event are presented in the event box. By clicking
the story name, it will direct to a story view page
that chronologically lists all its events where the
story name links to the corresponding Wikipedia
article. Clicking “more” for each event links to the
event view page that lists all the news articles of
the event. At the upper right corner there is drop-
down menu which allow users to set the ranking
functions and refine metrics.
</bodyText>
<sectionHeader confidence="0.999619" genericHeader="method">
6 Experiments
</sectionHeader>
<bodyText confidence="0.9999692">
We evaluate the event clustering and chain-
ing in an experimental dataset constructed us-
ing Wikipedia current events from 01/01/2013 to
01/31/2015, which contains 652 stories covering
9004 events with 8,944 news articles.
We first explore whether our event clustering
can effectively and efficiently cluster news arti-
cles of the same event. To construct the dataset,
we select the events that link to more than 4
news articles, which in total gives us 55 events
from 229 news articles. We then compare our
method with the state-of-art clustering algorithm-
s including K-means (Hartigan and Wong, 1979)
and DBSCAN (Ester et al., 1996), and the state-of-
art LSH methods including min-Hashing (Broder,
1997) and sim-Hashing (Charikar, 2002). We use
the cluster module provided by sklearn6. For both
K-means and DBSCAN, we use TFIDF based Eu-
clidean distance in bag-of-word space. For K-
means, we set the number of clusters to 55. For
</bodyText>
<footnote confidence="0.975574">
6http://scikit-learn.org/stable/modules/clustering.html
</footnote>
<page confidence="0.991605">
136
</page>
<table confidence="0.999651333333333">
Methods Precision Recall F1
K-means 76.2% 73.1% 74.6%
DBSCAN 77.9% 74.6% 76.2%
Min-Hashing 82.1% 51.2% 63.1%
Sim-Hashing 80.1% 50.2% 61.7%
Event-Hashing 79.6% 76.8% 78.2%
</table>
<tableCaption confidence="0.851084">
Table 2: Event clustering comparisons
</tableCaption>
<table confidence="0.9775394">
Methods Avg. Accuracy
Cosine 66.7%
Connecting-Dots Coherence 45.2%
KL Coherence 43.3%
Learning based Model 71.5%
</table>
<tableCaption confidence="0.999931">
Table 3: Comparisons of event chaining
</tableCaption>
<bodyText confidence="0.999775314285714">
DBSCAN, we set the neighborhood size (the min-
imum number of points required to form a dense
region) as 1. Both min-Hashing and sim-Hashing
generate an 84 bits binary code to represent an
event. We set θ as 5.
Table 2 shows the average precision, recal-
l, and F1 scores over all clusters. Our method
(Event-Hashing) outperforms both distance-based
and LSH based clustering algorithms in terms of
effectiveness, suggesting that our event represen-
tation using entities, actors, and actions is a more
promising approach than bag-of-word ones. Our
method is somewhat slower than min-Hashing and
sim-Hashing because of the extra computing on
the event space. It is worth noting that min-
Hashing and sim-Hashing have higher precisions
than ours, but at the cost of a big loss in recall.
We then evaluate the effectiveness of the even-
t chaining for constructing storylines. We use
the 458 stories starting in range [01/01/2013,
02/28/2014] for training and the other 194 stories
for testing. We define accuracy of a construct-
ed storyline as the fraction of the correctly linked
events. For testing, each story is initialized by its
first event. Thresholds of the three baseline mea-
sures are tuned in the training set. As shown by
Table 3, our learning based model combining the
three features significantly outperforms the base-
lines in average accuracy over the testing stories.
A small scale evaluation on the effectiveness
and efficiency of the news event search engine is
also performed. First, we evaluate the ranking per-
formance for different ranking functions on a test
query set including 10 different queries using pre-
cision at k (P@k). The query set contains “Unit-
</bodyText>
<table confidence="0.99953125">
Method P@3 P@5 P@10 AvgTimePerQuery
Inn. Pro. 57 66 69 133ms
BM25 100 94 92 104ms
Cosine 100 94 96 136ms
</table>
<tableCaption confidence="0.994677">
Table 4: Performance comparisons of ranking
methods on event search
</tableCaption>
<bodyText confidence="0.992338">
ed States”, ”Russia”, “China”, ”Barack Obama”,
”European Union”, ”President of the United S-
tates”, “Car bomb”, ”North Korea”, “South Kore-
a”, ”President of Russia”. We choose these queries
because they appear frequently in the news articles
and are very likely to be searched by users. Table 4
shows the performance of three ranking functions.
The P@k scores for BM25 and cosine similarity is
higher than inner product. This happens because
the inner product does not do normalization thus
favors the longer documents which should be less
relevant in our setting.
</bodyText>
<sectionHeader confidence="0.999957" genericHeader="method">
7 Related Work
</sectionHeader>
<bodyText confidence="0.999974266666667">
Little work has been reported on the building
of event knowledge bases with the exception of
EVIN (Kuzey and Weikum, 2014). However, their
main focus is on extracting named events from
news articles in an offline setting for knowledge
base population (Ji and Grishman, 2011), but not
building storylines for new events from large scale
daily news streams.
Topic detection and tracking (TDT) that ad-
dresses event-based organization of news has been
widely studied (Yang et al., 1999; Allan, 2002;
Petrovi´c et al., 2012). Furthermore, there is a
rich literature on bursty event detection (Klein-
berg, 2002; Fung et al., 2005; He et al., 2007),
where an “event” is a set of word features that
co-occur in certain time windows in text streams.
There is also an emerging interest in building news
timelines (Li and Li, 2013; Yan et al., 2011), event
chains (Chambers and Jurafsky, 2008; Shahaf and
Guestrin, 2010; Tannier and Moriceau, 2013), or
topic model based storylines (Ahmed et al., 2011).
It is worth noting that some work uses similar
event encoding based on actors and actions for po-
litical events (O’Connor et al., 2013). Our work
is different from existing work in both the repre-
sentation of an “event” and event detection tech-
niques. We use a three-layer (story-event-article)
representation to organize the storylines and de-
velop efficient clustering and chaining methods on
the event space.
</bodyText>
<page confidence="0.996728">
137
</page>
<sectionHeader confidence="0.967132" genericHeader="conclusions">
8 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999987111111111">
We presented Storybase, an event knowledge base
for news stories containing rich temporal and
semantic information and described a storyline
based news event search engine. Experimental re-
sults demonstrated that our proposed methods are
effective and efficient for event detection and s-
toryline based search. Future work could include
enriching properties of a story using Wikipedia in-
fobox and better summarizing events and stories.
</bodyText>
<sectionHeader confidence="0.994912" genericHeader="acknowledgments">
9 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999380333333333">
We acknowledge partial support from Raytheon
and the National Science Foundation, useful dis-
cussions with B.J. Simpson, Robert Cole, Philip
A. Schrodt, and Muhammed Y. Idris, and techni-
cal support from Jian Wu, Kyle Williams, and the
CiteseerX team.
</bodyText>
<sectionHeader confidence="0.998914" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999882987951807">
Amr Ahmed, Qirong Ho, Jacob Eisenstein, Eric Xing,
Alexander J Smola, and Choon Hui Teo. 2011. U-
nified analysis of streaming news. In WWW, pages
267–276.
James Allan. 2002. Introduction to topic detection
and tracking. In James Allan, editor, Topic Detec-
tion and Tracking, volume 12 of The Information
Retrieval Series, pages 1–16.
Andrei Z Broder. 1997. On the resemblance and con-
tainment of documents. In Compression and Com-
plexity of Sequences 1997., pages 21–29. IEEE.
Nathanael Chambers and Daniel Jurafsky. 2008. Un-
supervised learning of narrative event chains. In A-
CL, pages 789–797.
Moses S Charikar. 2002. Similarity estimation tech-
niques from rounding algorithms. In STOC, pages
380–388.
Martin Ester, Hans-Peter Kriegel, J¨org Sander, and X-
iaowei Xu. 1996. A density-based algorithm for
discovering clusters in large spatial databases with
noise. In KDD, volume 96, pages 226–231.
Jerome H Friedman. 2001. Greedy function approxi-
mation: a gradient boosting machine. Annals of s-
tatistics, pages 1189–1232.
Gabriel Pui Cheong Fung, Jeffrey Xu Yu, Philip S.
Yu, and Hongjun Lu. 2005. Parameter free bursty
events detection in text streams. In VLDB, pages
181–192.
J. A. Hartigan and M. A. Wong. 1979. A k-means
clustering algorithm. JSTOR: Applied Statistics,
28(1):100–108.
Qi He, Kuiyu Chang, and Ee-Peng Lim. 2007. An-
alyzing feature trajectories for event detection. In
SIGIR, pages 207–214.
Heng Ji and Ralph Grishman. 2011. Knowledge base
population: Successful approaches and challenges.
In ACL, pages 1148–1158.
Jon Kleinberg. 2002. Bursty and hierarchical structure
in streams. In KDD, pages 91–101.
Erdal Kuzey and Gerhard Weikum. 2014. Evin: build-
ing a knowledge base of events. In WWW compan-
ion, pages 103–106.
Kalev Leetaru and Philip A Schrodt. 2013. Gdelt:
Global data on events, location, and tone, 1979–
2012. In Paper presented at the ISA Annual Con-
vention, volume 2, page 4.
Jiwei Li and Sujian Li. 2013. Evolutionary hierarchi-
cal dirichlet process for timeline summarization. In
ACL, pages 556–560.
Christopher D. Manning, Mihai Surdeanu, John Bauer,
Jenny Finkel, Steven J. Bethard, and David Mc-
Closky. 2014. The Stanford CoreNLP natural lan-
guage processing toolkit. In ACL, pages 55–60.
Brendan O’Connor, Brandon M Stewart, and Noah A
Smith. 2013. Learning to extract international re-
lations from political context. In ACL (1), pages
1094–1104.
Loc Paulev, Herv Jgou, and Laurent Amsaleg. 2010.
Locality sensitive hashing: A comparison of hash
function types and querying mechanisms. Pattern
Recognition Letters, 31(11):1348 – 1358.
Saˇsa Petrovi´c, Miles Osborne, and Victor Lavrenko.
2012. Using paraphrases for improving first sto-
ry detection in news and twitter. In NAACL, pages
338–346.
Dafna Shahaf and Carlos Guestrin. 2010. Connecting
the dots between news articles. In KDD, pages 623–
632.
Xavier Tannier and V´eronique Moriceau. 2013. Build-
ing event threads out of multiple news articles. In
EMNLP, pages 958–967.
Benjamin Van Durme and Ashwin Lall. 2010. Online
generation of locality sensitive hash signatures. In
ACL, pages 231–235.
Rui Yan, Liang Kong, Congrui Huang, Xiaojun Wan,
Xiaoming Li, and Yan Zhang. 2011. Timeline gen-
eration through evolutionary trans-temporal summa-
rization. In EMNLP, pages 433–443.
Yiming Yang, Jaime G Carbonell, Ralf D Brown,
Thomas Pierce, Brian T Archibald, and Xin Li-
u. 1999. Learning approaches for detecting and
tracking news events. IEEE Intelligent Systems,
14(4):32–43.
</reference>
<page confidence="0.997331">
138
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.796614">
<title confidence="0.999732">Storybase: Towards Building a Knowledge Base for News Events</title>
<author confidence="0.993394">Chen C Lee Science</author>
<author confidence="0.993394">Sciences Engineering</author>
<affiliation confidence="0.807183">The Pennsylvania State</affiliation>
<address confidence="0.981104">University Park, PA 16802,</address>
<abstract confidence="0.9996281875">To better organize and understand online information, we propose a knowledge base for news events that builds upon Wikipedia current events and daily Web news. It first constructs stories and their timelines based on Wikipedia current events and then detects and links daily news to enrich those Wikipedia stories with more comprehensive events. We encode events and develop efficient event clustering and chaining techniques in an event space. We demonstrate Storybase with a news events search engine that helps find historical and ongoing news stories and inspect their dynamic timelines.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Amr Ahmed</author>
<author>Qirong Ho</author>
<author>Jacob Eisenstein</author>
<author>Eric Xing</author>
<author>Alexander J Smola</author>
<author>Choon Hui Teo</author>
</authors>
<title>Unified analysis of streaming news.</title>
<date>2011</date>
<booktitle>In WWW,</booktitle>
<pages>267--276</pages>
<contexts>
<context position="18325" citStr="Ahmed et al., 2011" startWordPosition="2953" endWordPosition="2956"> and tracking (TDT) that addresses event-based organization of news has been widely studied (Yang et al., 1999; Allan, 2002; Petrovi´c et al., 2012). Furthermore, there is a rich literature on bursty event detection (Kleinberg, 2002; Fung et al., 2005; He et al., 2007), where an “event” is a set of word features that co-occur in certain time windows in text streams. There is also an emerging interest in building news timelines (Li and Li, 2013; Yan et al., 2011), event chains (Chambers and Jurafsky, 2008; Shahaf and Guestrin, 2010; Tannier and Moriceau, 2013), or topic model based storylines (Ahmed et al., 2011). It is worth noting that some work uses similar event encoding based on actors and actions for political events (O’Connor et al., 2013). Our work is different from existing work in both the representation of an “event” and event detection techniques. We use a three-layer (story-event-article) representation to organize the storylines and develop efficient clustering and chaining methods on the event space. 137 8 Conclusion and Future Work We presented Storybase, an event knowledge base for news stories containing rich temporal and semantic information and described a storyline based news even</context>
</contexts>
<marker>Ahmed, Ho, Eisenstein, Xing, Smola, Teo, 2011</marker>
<rawString>Amr Ahmed, Qirong Ho, Jacob Eisenstein, Eric Xing, Alexander J Smola, and Choon Hui Teo. 2011. Unified analysis of streaming news. In WWW, pages 267–276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Allan</author>
</authors>
<title>Introduction to topic detection and tracking.</title>
<date>2002</date>
<booktitle>Topic Detection and Tracking,</booktitle>
<volume>12</volume>
<pages>1--16</pages>
<editor>In James Allan, editor,</editor>
<contexts>
<context position="17829" citStr="Allan, 2002" startWordPosition="2871" endWordPosition="2872">s not do normalization thus favors the longer documents which should be less relevant in our setting. 7 Related Work Little work has been reported on the building of event knowledge bases with the exception of EVIN (Kuzey and Weikum, 2014). However, their main focus is on extracting named events from news articles in an offline setting for knowledge base population (Ji and Grishman, 2011), but not building storylines for new events from large scale daily news streams. Topic detection and tracking (TDT) that addresses event-based organization of news has been widely studied (Yang et al., 1999; Allan, 2002; Petrovi´c et al., 2012). Furthermore, there is a rich literature on bursty event detection (Kleinberg, 2002; Fung et al., 2005; He et al., 2007), where an “event” is a set of word features that co-occur in certain time windows in text streams. There is also an emerging interest in building news timelines (Li and Li, 2013; Yan et al., 2011), event chains (Chambers and Jurafsky, 2008; Shahaf and Guestrin, 2010; Tannier and Moriceau, 2013), or topic model based storylines (Ahmed et al., 2011). It is worth noting that some work uses similar event encoding based on actors and actions for politica</context>
</contexts>
<marker>Allan, 2002</marker>
<rawString>James Allan. 2002. Introduction to topic detection and tracking. In James Allan, editor, Topic Detection and Tracking, volume 12 of The Information Retrieval Series, pages 1–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrei Z Broder</author>
</authors>
<title>On the resemblance and containment of documents.</title>
<date>1997</date>
<booktitle>In Compression and Complexity of Sequences</booktitle>
<pages>21--29</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="14275" citStr="Broder, 1997" startWordPosition="2302" endWordPosition="2303">ng Wikipedia current events from 01/01/2013 to 01/31/2015, which contains 652 stories covering 9004 events with 8,944 news articles. We first explore whether our event clustering can effectively and efficiently cluster news articles of the same event. To construct the dataset, we select the events that link to more than 4 news articles, which in total gives us 55 events from 229 news articles. We then compare our method with the state-of-art clustering algorithms including K-means (Hartigan and Wong, 1979) and DBSCAN (Ester et al., 1996), and the state-ofart LSH methods including min-Hashing (Broder, 1997) and sim-Hashing (Charikar, 2002). We use the cluster module provided by sklearn6. For both K-means and DBSCAN, we use TFIDF based Euclidean distance in bag-of-word space. For Kmeans, we set the number of clusters to 55. For 6http://scikit-learn.org/stable/modules/clustering.html 136 Methods Precision Recall F1 K-means 76.2% 73.1% 74.6% DBSCAN 77.9% 74.6% 76.2% Min-Hashing 82.1% 51.2% 63.1% Sim-Hashing 80.1% 50.2% 61.7% Event-Hashing 79.6% 76.8% 78.2% Table 2: Event clustering comparisons Methods Avg. Accuracy Cosine 66.7% Connecting-Dots Coherence 45.2% KL Coherence 43.3% Learning based Model</context>
</contexts>
<marker>Broder, 1997</marker>
<rawString>Andrei Z Broder. 1997. On the resemblance and containment of documents. In Compression and Complexity of Sequences 1997., pages 21–29. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Unsupervised learning of narrative event chains.</title>
<date>2008</date>
<booktitle>In ACL,</booktitle>
<pages>789--797</pages>
<contexts>
<context position="18215" citStr="Chambers and Jurafsky, 2008" startWordPosition="2936" endWordPosition="2939">i and Grishman, 2011), but not building storylines for new events from large scale daily news streams. Topic detection and tracking (TDT) that addresses event-based organization of news has been widely studied (Yang et al., 1999; Allan, 2002; Petrovi´c et al., 2012). Furthermore, there is a rich literature on bursty event detection (Kleinberg, 2002; Fung et al., 2005; He et al., 2007), where an “event” is a set of word features that co-occur in certain time windows in text streams. There is also an emerging interest in building news timelines (Li and Li, 2013; Yan et al., 2011), event chains (Chambers and Jurafsky, 2008; Shahaf and Guestrin, 2010; Tannier and Moriceau, 2013), or topic model based storylines (Ahmed et al., 2011). It is worth noting that some work uses similar event encoding based on actors and actions for political events (O’Connor et al., 2013). Our work is different from existing work in both the representation of an “event” and event detection techniques. We use a three-layer (story-event-article) representation to organize the storylines and develop efficient clustering and chaining methods on the event space. 137 8 Conclusion and Future Work We presented Storybase, an event knowledge bas</context>
</contexts>
<marker>Chambers, Jurafsky, 2008</marker>
<rawString>Nathanael Chambers and Daniel Jurafsky. 2008. Unsupervised learning of narrative event chains. In ACL, pages 789–797.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moses S Charikar</author>
</authors>
<title>Similarity estimation techniques from rounding algorithms.</title>
<date>2002</date>
<booktitle>In STOC,</booktitle>
<pages>380--388</pages>
<contexts>
<context position="9611" citStr="Charikar, 2002" startWordPosition="1513" endWordPosition="1514">he Stanford CoreNLP (Manning et al., 2014) for the named entity recognition and extract all Wikipedia concepts appearing in news content. Entities that are subjects or objects in the title and description are treated as actors. If no entities are found, we then use the CAMEO dictionaries5 for actor and action extraction. 4.3 Event Clustering and Chaining Event clustering groups together news on the same event. Locality-Sensitive Hashing (LSH) (Van Durme and Lall, 2010) is used for fast similarity comparison. We first do deduplication on all articles on the same date using 84 bits sim-Hashing (Charikar, 2002). We then use modified sim-Hashing on the vector space of event described in Section 4.2, rather than shingling or bag-of-words (Paulev et al., 2010). A new article is encoded into the event space with the content 5http://eventdata.parusanalytics.com/data.dir/cameo.html of its title and description. Its LSH key k (84 bits binary code) is computed and compared to keys of other articles. Articles whose keys have hamming distances smaller than a threshold 0 among each other will be clustered as an event. We then check all events of the previous date and merge two events into one if their distance</context>
<context position="14308" citStr="Charikar, 2002" startWordPosition="2306" endWordPosition="2307">m 01/01/2013 to 01/31/2015, which contains 652 stories covering 9004 events with 8,944 news articles. We first explore whether our event clustering can effectively and efficiently cluster news articles of the same event. To construct the dataset, we select the events that link to more than 4 news articles, which in total gives us 55 events from 229 news articles. We then compare our method with the state-of-art clustering algorithms including K-means (Hartigan and Wong, 1979) and DBSCAN (Ester et al., 1996), and the state-ofart LSH methods including min-Hashing (Broder, 1997) and sim-Hashing (Charikar, 2002). We use the cluster module provided by sklearn6. For both K-means and DBSCAN, we use TFIDF based Euclidean distance in bag-of-word space. For Kmeans, we set the number of clusters to 55. For 6http://scikit-learn.org/stable/modules/clustering.html 136 Methods Precision Recall F1 K-means 76.2% 73.1% 74.6% DBSCAN 77.9% 74.6% 76.2% Min-Hashing 82.1% 51.2% 63.1% Sim-Hashing 80.1% 50.2% 61.7% Event-Hashing 79.6% 76.8% 78.2% Table 2: Event clustering comparisons Methods Avg. Accuracy Cosine 66.7% Connecting-Dots Coherence 45.2% KL Coherence 43.3% Learning based Model 71.5% Table 3: Comparisons of ev</context>
</contexts>
<marker>Charikar, 2002</marker>
<rawString>Moses S Charikar. 2002. Similarity estimation techniques from rounding algorithms. In STOC, pages 380–388.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Ester</author>
<author>Hans-Peter Kriegel</author>
<author>J¨org Sander</author>
<author>Xiaowei Xu</author>
</authors>
<title>A density-based algorithm for discovering clusters in large spatial databases with noise.</title>
<date>1996</date>
<booktitle>In KDD,</booktitle>
<volume>96</volume>
<pages>226--231</pages>
<contexts>
<context position="14205" citStr="Ester et al., 1996" startWordPosition="2290" endWordPosition="2293">the event clustering and chaining in an experimental dataset constructed using Wikipedia current events from 01/01/2013 to 01/31/2015, which contains 652 stories covering 9004 events with 8,944 news articles. We first explore whether our event clustering can effectively and efficiently cluster news articles of the same event. To construct the dataset, we select the events that link to more than 4 news articles, which in total gives us 55 events from 229 news articles. We then compare our method with the state-of-art clustering algorithms including K-means (Hartigan and Wong, 1979) and DBSCAN (Ester et al., 1996), and the state-ofart LSH methods including min-Hashing (Broder, 1997) and sim-Hashing (Charikar, 2002). We use the cluster module provided by sklearn6. For both K-means and DBSCAN, we use TFIDF based Euclidean distance in bag-of-word space. For Kmeans, we set the number of clusters to 55. For 6http://scikit-learn.org/stable/modules/clustering.html 136 Methods Precision Recall F1 K-means 76.2% 73.1% 74.6% DBSCAN 77.9% 74.6% 76.2% Min-Hashing 82.1% 51.2% 63.1% Sim-Hashing 80.1% 50.2% 61.7% Event-Hashing 79.6% 76.8% 78.2% Table 2: Event clustering comparisons Methods Avg. Accuracy Cosine 66.7% C</context>
</contexts>
<marker>Ester, Kriegel, Sander, Xu, 1996</marker>
<rawString>Martin Ester, Hans-Peter Kriegel, J¨org Sander, and Xiaowei Xu. 1996. A density-based algorithm for discovering clusters in large spatial databases with noise. In KDD, volume 96, pages 226–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerome H Friedman</author>
</authors>
<title>Greedy function approximation: a gradient boosting machine. Annals of statistics,</title>
<date>2001</date>
<pages>1189--1232</pages>
<contexts>
<context position="11069" citStr="Friedman, 2001" startWordPosition="1753" endWordPosition="1754">clusters, it might not be able to determine whether two events with distance larger than 0 are topically related, or belong to the same story. Intuitively, an event should bring some novelty and preserve some common information compared with the previous ones in the story, causing a tradeoff between relevance and novelty, which could be measured by some textual similarity. Adding an event should also keep the storyline coherent. To model coherence, we investigate two features, the Connecting-Dots coherence score (Shahaf and Guestrin, 2010) and KL-divergence. We use the gradient boosting tree (Friedman, 2001) to learn if an event belongs to a story by using the above features of relevance/novelty and coherence, all based on storylines constructed from Wikipedia current events. For a story {ei,...,em}, (ei, {e1, ..., ei_1}) are positive pairs; (e_, {e1,..., ei_1}) are negative pairs, i = 2,..., m, where e_ is an event randomly sampled from other stories in the same date of ei. For all GDELT news on date t, we first detect all events using event clustering. For an event that has not been merged into events of the previous date, we use the model to decide which story it belongs to. If none, the event</context>
</contexts>
<marker>Friedman, 2001</marker>
<rawString>Jerome H Friedman. 2001. Greedy function approximation: a gradient boosting machine. Annals of statistics, pages 1189–1232.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriel Pui Cheong Fung</author>
<author>Jeffrey Xu Yu</author>
<author>Philip S Yu</author>
<author>Hongjun Lu</author>
</authors>
<title>Parameter free bursty events detection in text streams.</title>
<date>2005</date>
<booktitle>In VLDB,</booktitle>
<pages>181--192</pages>
<contexts>
<context position="17957" citStr="Fung et al., 2005" startWordPosition="2890" endWordPosition="2893">e work has been reported on the building of event knowledge bases with the exception of EVIN (Kuzey and Weikum, 2014). However, their main focus is on extracting named events from news articles in an offline setting for knowledge base population (Ji and Grishman, 2011), but not building storylines for new events from large scale daily news streams. Topic detection and tracking (TDT) that addresses event-based organization of news has been widely studied (Yang et al., 1999; Allan, 2002; Petrovi´c et al., 2012). Furthermore, there is a rich literature on bursty event detection (Kleinberg, 2002; Fung et al., 2005; He et al., 2007), where an “event” is a set of word features that co-occur in certain time windows in text streams. There is also an emerging interest in building news timelines (Li and Li, 2013; Yan et al., 2011), event chains (Chambers and Jurafsky, 2008; Shahaf and Guestrin, 2010; Tannier and Moriceau, 2013), or topic model based storylines (Ahmed et al., 2011). It is worth noting that some work uses similar event encoding based on actors and actions for political events (O’Connor et al., 2013). Our work is different from existing work in both the representation of an “event” and event de</context>
</contexts>
<marker>Fung, Yu, Yu, Lu, 2005</marker>
<rawString>Gabriel Pui Cheong Fung, Jeffrey Xu Yu, Philip S. Yu, and Hongjun Lu. 2005. Parameter free bursty events detection in text streams. In VLDB, pages 181–192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Hartigan</author>
<author>M A Wong</author>
</authors>
<title>A k-means clustering algorithm.</title>
<date>1979</date>
<journal>JSTOR: Applied Statistics,</journal>
<volume>28</volume>
<issue>1</issue>
<contexts>
<context position="14173" citStr="Hartigan and Wong, 1979" startWordPosition="2284" endWordPosition="2287">e metrics. 6 Experiments We evaluate the event clustering and chaining in an experimental dataset constructed using Wikipedia current events from 01/01/2013 to 01/31/2015, which contains 652 stories covering 9004 events with 8,944 news articles. We first explore whether our event clustering can effectively and efficiently cluster news articles of the same event. To construct the dataset, we select the events that link to more than 4 news articles, which in total gives us 55 events from 229 news articles. We then compare our method with the state-of-art clustering algorithms including K-means (Hartigan and Wong, 1979) and DBSCAN (Ester et al., 1996), and the state-ofart LSH methods including min-Hashing (Broder, 1997) and sim-Hashing (Charikar, 2002). We use the cluster module provided by sklearn6. For both K-means and DBSCAN, we use TFIDF based Euclidean distance in bag-of-word space. For Kmeans, we set the number of clusters to 55. For 6http://scikit-learn.org/stable/modules/clustering.html 136 Methods Precision Recall F1 K-means 76.2% 73.1% 74.6% DBSCAN 77.9% 74.6% 76.2% Min-Hashing 82.1% 51.2% 63.1% Sim-Hashing 80.1% 50.2% 61.7% Event-Hashing 79.6% 76.8% 78.2% Table 2: Event clustering comparisons Meth</context>
</contexts>
<marker>Hartigan, Wong, 1979</marker>
<rawString>J. A. Hartigan and M. A. Wong. 1979. A k-means clustering algorithm. JSTOR: Applied Statistics, 28(1):100–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi He</author>
<author>Kuiyu Chang</author>
<author>Ee-Peng Lim</author>
</authors>
<title>Analyzing feature trajectories for event detection. In</title>
<date>2007</date>
<booktitle>SIGIR,</booktitle>
<pages>207--214</pages>
<contexts>
<context position="17975" citStr="He et al., 2007" startWordPosition="2894" endWordPosition="2897">orted on the building of event knowledge bases with the exception of EVIN (Kuzey and Weikum, 2014). However, their main focus is on extracting named events from news articles in an offline setting for knowledge base population (Ji and Grishman, 2011), but not building storylines for new events from large scale daily news streams. Topic detection and tracking (TDT) that addresses event-based organization of news has been widely studied (Yang et al., 1999; Allan, 2002; Petrovi´c et al., 2012). Furthermore, there is a rich literature on bursty event detection (Kleinberg, 2002; Fung et al., 2005; He et al., 2007), where an “event” is a set of word features that co-occur in certain time windows in text streams. There is also an emerging interest in building news timelines (Li and Li, 2013; Yan et al., 2011), event chains (Chambers and Jurafsky, 2008; Shahaf and Guestrin, 2010; Tannier and Moriceau, 2013), or topic model based storylines (Ahmed et al., 2011). It is worth noting that some work uses similar event encoding based on actors and actions for political events (O’Connor et al., 2013). Our work is different from existing work in both the representation of an “event” and event detection techniques</context>
</contexts>
<marker>He, Chang, Lim, 2007</marker>
<rawString>Qi He, Kuiyu Chang, and Ee-Peng Lim. 2007. Analyzing feature trajectories for event detection. In SIGIR, pages 207–214.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
</authors>
<title>Knowledge base population: Successful approaches and challenges.</title>
<date>2011</date>
<booktitle>In ACL,</booktitle>
<pages>1148--1158</pages>
<contexts>
<context position="17609" citStr="Ji and Grishman, 2011" startWordPosition="2834" endWordPosition="2837"> articles and are very likely to be searched by users. Table 4 shows the performance of three ranking functions. The P@k scores for BM25 and cosine similarity is higher than inner product. This happens because the inner product does not do normalization thus favors the longer documents which should be less relevant in our setting. 7 Related Work Little work has been reported on the building of event knowledge bases with the exception of EVIN (Kuzey and Weikum, 2014). However, their main focus is on extracting named events from news articles in an offline setting for knowledge base population (Ji and Grishman, 2011), but not building storylines for new events from large scale daily news streams. Topic detection and tracking (TDT) that addresses event-based organization of news has been widely studied (Yang et al., 1999; Allan, 2002; Petrovi´c et al., 2012). Furthermore, there is a rich literature on bursty event detection (Kleinberg, 2002; Fung et al., 2005; He et al., 2007), where an “event” is a set of word features that co-occur in certain time windows in text streams. There is also an emerging interest in building news timelines (Li and Li, 2013; Yan et al., 2011), event chains (Chambers and Jurafsky</context>
</contexts>
<marker>Ji, Grishman, 2011</marker>
<rawString>Heng Ji and Ralph Grishman. 2011. Knowledge base population: Successful approaches and challenges. In ACL, pages 1148–1158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Kleinberg</author>
</authors>
<title>Bursty and hierarchical structure in streams.</title>
<date>2002</date>
<booktitle>In KDD,</booktitle>
<pages>91--101</pages>
<contexts>
<context position="17938" citStr="Kleinberg, 2002" startWordPosition="2887" endWordPosition="2889">elated Work Little work has been reported on the building of event knowledge bases with the exception of EVIN (Kuzey and Weikum, 2014). However, their main focus is on extracting named events from news articles in an offline setting for knowledge base population (Ji and Grishman, 2011), but not building storylines for new events from large scale daily news streams. Topic detection and tracking (TDT) that addresses event-based organization of news has been widely studied (Yang et al., 1999; Allan, 2002; Petrovi´c et al., 2012). Furthermore, there is a rich literature on bursty event detection (Kleinberg, 2002; Fung et al., 2005; He et al., 2007), where an “event” is a set of word features that co-occur in certain time windows in text streams. There is also an emerging interest in building news timelines (Li and Li, 2013; Yan et al., 2011), event chains (Chambers and Jurafsky, 2008; Shahaf and Guestrin, 2010; Tannier and Moriceau, 2013), or topic model based storylines (Ahmed et al., 2011). It is worth noting that some work uses similar event encoding based on actors and actions for political events (O’Connor et al., 2013). Our work is different from existing work in both the representation of an “</context>
</contexts>
<marker>Kleinberg, 2002</marker>
<rawString>Jon Kleinberg. 2002. Bursty and hierarchical structure in streams. In KDD, pages 91–101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erdal Kuzey</author>
<author>Gerhard Weikum</author>
</authors>
<title>Evin: building a knowledge base of events.</title>
<date>2014</date>
<booktitle>In WWW companion,</booktitle>
<pages>103--106</pages>
<contexts>
<context position="17457" citStr="Kuzey and Weikum, 2014" startWordPosition="2810" endWordPosition="2813">f the United States”, “Car bomb”, ”North Korea”, “South Korea”, ”President of Russia”. We choose these queries because they appear frequently in the news articles and are very likely to be searched by users. Table 4 shows the performance of three ranking functions. The P@k scores for BM25 and cosine similarity is higher than inner product. This happens because the inner product does not do normalization thus favors the longer documents which should be less relevant in our setting. 7 Related Work Little work has been reported on the building of event knowledge bases with the exception of EVIN (Kuzey and Weikum, 2014). However, their main focus is on extracting named events from news articles in an offline setting for knowledge base population (Ji and Grishman, 2011), but not building storylines for new events from large scale daily news streams. Topic detection and tracking (TDT) that addresses event-based organization of news has been widely studied (Yang et al., 1999; Allan, 2002; Petrovi´c et al., 2012). Furthermore, there is a rich literature on bursty event detection (Kleinberg, 2002; Fung et al., 2005; He et al., 2007), where an “event” is a set of word features that co-occur in certain time windows</context>
</contexts>
<marker>Kuzey, Weikum, 2014</marker>
<rawString>Erdal Kuzey and Gerhard Weikum. 2014. Evin: building a knowledge base of events. In WWW companion, pages 103–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kalev Leetaru</author>
<author>Philip A Schrodt</author>
</authors>
<title>Gdelt: Global data on events, location, and tone,</title>
<date>2013</date>
<booktitle>In Paper presented at the ISA Annual Convention,</booktitle>
<volume>2</volume>
<pages>4</pages>
<contexts>
<context position="7262" citStr="Leetaru and Schrodt, 2013" startWordPosition="1145" endWordPosition="1148">acks” while others might use “Attack and conflict”. After canonicalization using Levenshtein distance and grouping similar labels using word based Jaccard similarity, we manually clean all the labels into 12 categories, as shown in Table 1. Although Wikipedia provides high quality manually edited news events, it covers only a small number of events every day, usually less than 30. Thus, to scale up Storybase and make the stories more comprehensive, starting from April 1, 2013, we crawl daily news articles from a large number of sources from various news publishers, provided by GDELT3 project (Leetaru and Schrodt, 2013). 4 Building Storybase 4.1 Preprocess and Categorization To extract and parse Wikipedia current events, we implement two template based extractors for events between January 2003 and April 2006 and those events after April 2006 respectively due to their difference in templates. The news articles linked at the end of each event description are also crawled. We use boilerpipe4 to extract the title and main text content of each news article. We extract the first three sentences in the main content for summarization. 3http://www.gdeltproject.org/data.html 4https://code.google.com/p/boilerpipe/ 134</context>
</contexts>
<marker>Leetaru, Schrodt, 2013</marker>
<rawString>Kalev Leetaru and Philip A Schrodt. 2013. Gdelt: Global data on events, location, and tone, 1979– 2012. In Paper presented at the ISA Annual Convention, volume 2, page 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiwei Li</author>
<author>Sujian Li</author>
</authors>
<title>Evolutionary hierarchical dirichlet process for timeline summarization. In</title>
<date>2013</date>
<booktitle>ACL,</booktitle>
<pages>556--560</pages>
<contexts>
<context position="18153" citStr="Li and Li, 2013" startWordPosition="2926" endWordPosition="2929">n offline setting for knowledge base population (Ji and Grishman, 2011), but not building storylines for new events from large scale daily news streams. Topic detection and tracking (TDT) that addresses event-based organization of news has been widely studied (Yang et al., 1999; Allan, 2002; Petrovi´c et al., 2012). Furthermore, there is a rich literature on bursty event detection (Kleinberg, 2002; Fung et al., 2005; He et al., 2007), where an “event” is a set of word features that co-occur in certain time windows in text streams. There is also an emerging interest in building news timelines (Li and Li, 2013; Yan et al., 2011), event chains (Chambers and Jurafsky, 2008; Shahaf and Guestrin, 2010; Tannier and Moriceau, 2013), or topic model based storylines (Ahmed et al., 2011). It is worth noting that some work uses similar event encoding based on actors and actions for political events (O’Connor et al., 2013). Our work is different from existing work in both the representation of an “event” and event detection techniques. We use a three-layer (story-event-article) representation to organize the storylines and develop efficient clustering and chaining methods on the event space. 137 8 Conclusion </context>
</contexts>
<marker>Li, Li, 2013</marker>
<rawString>Jiwei Li and Sujian Li. 2013. Evolutionary hierarchical dirichlet process for timeline summarization. In ACL, pages 556–560.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Mihai Surdeanu</author>
<author>John Bauer</author>
<author>Jenny Finkel</author>
<author>Steven J Bethard</author>
<author>David McClosky</author>
</authors>
<title>The Stanford CoreNLP natural language processing toolkit.</title>
<date>2014</date>
<booktitle>In ACL,</booktitle>
<pages>55--60</pages>
<contexts>
<context position="9038" citStr="Manning et al., 2014" startWordPosition="1419" endWordPosition="1422">armed conflicts”} will be mapped to Category 1. For an event not belonging to existing stories, we label its category using the majority of their k-nearest (k=10) neighbors based on the cosine similarity of event descriptions. 4.2 Event Encoding We encode an event as a vector containing named entities, actors and actions. Named entities such as people and locations in news reports contain important information of the event. Core entities that play important roles in an event are called actors, which are usually people or organizations that make or receive actions. We use the Stanford CoreNLP (Manning et al., 2014) for the named entity recognition and extract all Wikipedia concepts appearing in news content. Entities that are subjects or objects in the title and description are treated as actors. If no entities are found, we then use the CAMEO dictionaries5 for actor and action extraction. 4.3 Event Clustering and Chaining Event clustering groups together news on the same event. Locality-Sensitive Hashing (LSH) (Van Durme and Lall, 2010) is used for fast similarity comparison. We first do deduplication on all articles on the same date using 84 bits sim-Hashing (Charikar, 2002). We then use modified sim-</context>
</contexts>
<marker>Manning, Surdeanu, Bauer, Finkel, Bethard, McClosky, 2014</marker>
<rawString>Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J. Bethard, and David McClosky. 2014. The Stanford CoreNLP natural language processing toolkit. In ACL, pages 55–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brendan O’Connor</author>
<author>Brandon M Stewart</author>
<author>Noah A Smith</author>
</authors>
<title>Learning to extract international relations from political context. In</title>
<date>2013</date>
<journal>ACL</journal>
<volume>1</volume>
<pages>1094--1104</pages>
<marker>O’Connor, Stewart, Smith, 2013</marker>
<rawString>Brendan O’Connor, Brandon M Stewart, and Noah A Smith. 2013. Learning to extract international relations from political context. In ACL (1), pages 1094–1104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Loc Paulev</author>
<author>Herv Jgou</author>
<author>Laurent Amsaleg</author>
</authors>
<title>Locality sensitive hashing: A comparison of hash function types and querying mechanisms.</title>
<date>2010</date>
<journal>Pattern Recognition Letters,</journal>
<volume>31</volume>
<issue>11</issue>
<pages>1358</pages>
<contexts>
<context position="9760" citStr="Paulev et al., 2010" startWordPosition="1535" endWordPosition="1538">es that are subjects or objects in the title and description are treated as actors. If no entities are found, we then use the CAMEO dictionaries5 for actor and action extraction. 4.3 Event Clustering and Chaining Event clustering groups together news on the same event. Locality-Sensitive Hashing (LSH) (Van Durme and Lall, 2010) is used for fast similarity comparison. We first do deduplication on all articles on the same date using 84 bits sim-Hashing (Charikar, 2002). We then use modified sim-Hashing on the vector space of event described in Section 4.2, rather than shingling or bag-of-words (Paulev et al., 2010). A new article is encoded into the event space with the content 5http://eventdata.parusanalytics.com/data.dir/cameo.html of its title and description. Its LSH key k (84 bits binary code) is computed and compared to keys of other articles. Articles whose keys have hamming distances smaller than a threshold 0 among each other will be clustered as an event. We then check all events of the previous date and merge two events into one if their distance (average hamming distances of key pairs) is smaller than 0 and their categories are the same. Event chaining links an event to an existing story or </context>
</contexts>
<marker>Paulev, Jgou, Amsaleg, 2010</marker>
<rawString>Loc Paulev, Herv Jgou, and Laurent Amsaleg. 2010. Locality sensitive hashing: A comparison of hash function types and querying mechanisms. Pattern Recognition Letters, 31(11):1348 – 1358.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saˇsa Petrovi´c</author>
<author>Miles Osborne</author>
<author>Victor Lavrenko</author>
</authors>
<title>Using paraphrases for improving first story detection in news and twitter.</title>
<date>2012</date>
<booktitle>In NAACL,</booktitle>
<pages>338--346</pages>
<marker>Petrovi´c, Osborne, Lavrenko, 2012</marker>
<rawString>Saˇsa Petrovi´c, Miles Osborne, and Victor Lavrenko. 2012. Using paraphrases for improving first story detection in news and twitter. In NAACL, pages 338–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dafna Shahaf</author>
<author>Carlos Guestrin</author>
</authors>
<title>Connecting the dots between news articles.</title>
<date>2010</date>
<booktitle>In KDD,</booktitle>
<pages>623--632</pages>
<contexts>
<context position="10999" citStr="Shahaf and Guestrin, 2010" startWordPosition="1741" endWordPosition="1744"> it is the starting event of a new story. While LSH could give high-purity event clusters, it might not be able to determine whether two events with distance larger than 0 are topically related, or belong to the same story. Intuitively, an event should bring some novelty and preserve some common information compared with the previous ones in the story, causing a tradeoff between relevance and novelty, which could be measured by some textual similarity. Adding an event should also keep the storyline coherent. To model coherence, we investigate two features, the Connecting-Dots coherence score (Shahaf and Guestrin, 2010) and KL-divergence. We use the gradient boosting tree (Friedman, 2001) to learn if an event belongs to a story by using the above features of relevance/novelty and coherence, all based on storylines constructed from Wikipedia current events. For a story {ei,...,em}, (ei, {e1, ..., ei_1}) are positive pairs; (e_, {e1,..., ei_1}) are negative pairs, i = 2,..., m, where e_ is an event randomly sampled from other stories in the same date of ei. For all GDELT news on date t, we first detect all events using event clustering. For an event that has not been merged into events of the previous date, we</context>
<context position="18242" citStr="Shahaf and Guestrin, 2010" startWordPosition="2940" endWordPosition="2943">t building storylines for new events from large scale daily news streams. Topic detection and tracking (TDT) that addresses event-based organization of news has been widely studied (Yang et al., 1999; Allan, 2002; Petrovi´c et al., 2012). Furthermore, there is a rich literature on bursty event detection (Kleinberg, 2002; Fung et al., 2005; He et al., 2007), where an “event” is a set of word features that co-occur in certain time windows in text streams. There is also an emerging interest in building news timelines (Li and Li, 2013; Yan et al., 2011), event chains (Chambers and Jurafsky, 2008; Shahaf and Guestrin, 2010; Tannier and Moriceau, 2013), or topic model based storylines (Ahmed et al., 2011). It is worth noting that some work uses similar event encoding based on actors and actions for political events (O’Connor et al., 2013). Our work is different from existing work in both the representation of an “event” and event detection techniques. We use a three-layer (story-event-article) representation to organize the storylines and develop efficient clustering and chaining methods on the event space. 137 8 Conclusion and Future Work We presented Storybase, an event knowledge base for news stories containi</context>
</contexts>
<marker>Shahaf, Guestrin, 2010</marker>
<rawString>Dafna Shahaf and Carlos Guestrin. 2010. Connecting the dots between news articles. In KDD, pages 623– 632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Tannier</author>
<author>V´eronique Moriceau</author>
</authors>
<title>Building event threads out of multiple news articles.</title>
<date>2013</date>
<booktitle>In EMNLP,</booktitle>
<pages>958--967</pages>
<contexts>
<context position="18271" citStr="Tannier and Moriceau, 2013" startWordPosition="2944" endWordPosition="2947">ew events from large scale daily news streams. Topic detection and tracking (TDT) that addresses event-based organization of news has been widely studied (Yang et al., 1999; Allan, 2002; Petrovi´c et al., 2012). Furthermore, there is a rich literature on bursty event detection (Kleinberg, 2002; Fung et al., 2005; He et al., 2007), where an “event” is a set of word features that co-occur in certain time windows in text streams. There is also an emerging interest in building news timelines (Li and Li, 2013; Yan et al., 2011), event chains (Chambers and Jurafsky, 2008; Shahaf and Guestrin, 2010; Tannier and Moriceau, 2013), or topic model based storylines (Ahmed et al., 2011). It is worth noting that some work uses similar event encoding based on actors and actions for political events (O’Connor et al., 2013). Our work is different from existing work in both the representation of an “event” and event detection techniques. We use a three-layer (story-event-article) representation to organize the storylines and develop efficient clustering and chaining methods on the event space. 137 8 Conclusion and Future Work We presented Storybase, an event knowledge base for news stories containing rich temporal and semantic</context>
</contexts>
<marker>Tannier, Moriceau, 2013</marker>
<rawString>Xavier Tannier and V´eronique Moriceau. 2013. Building event threads out of multiple news articles. In EMNLP, pages 958–967.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Van Durme</author>
<author>Ashwin Lall</author>
</authors>
<title>Online generation of locality sensitive hash signatures.</title>
<date>2010</date>
<booktitle>In ACL,</booktitle>
<pages>231--235</pages>
<marker>Van Durme, Lall, 2010</marker>
<rawString>Benjamin Van Durme and Ashwin Lall. 2010. Online generation of locality sensitive hash signatures. In ACL, pages 231–235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Yan</author>
<author>Liang Kong</author>
<author>Congrui Huang</author>
<author>Xiaojun Wan</author>
<author>Xiaoming Li</author>
<author>Yan Zhang</author>
</authors>
<title>Timeline generation through evolutionary trans-temporal summarization.</title>
<date>2011</date>
<booktitle>In EMNLP,</booktitle>
<pages>433--443</pages>
<contexts>
<context position="18172" citStr="Yan et al., 2011" startWordPosition="2930" endWordPosition="2933"> for knowledge base population (Ji and Grishman, 2011), but not building storylines for new events from large scale daily news streams. Topic detection and tracking (TDT) that addresses event-based organization of news has been widely studied (Yang et al., 1999; Allan, 2002; Petrovi´c et al., 2012). Furthermore, there is a rich literature on bursty event detection (Kleinberg, 2002; Fung et al., 2005; He et al., 2007), where an “event” is a set of word features that co-occur in certain time windows in text streams. There is also an emerging interest in building news timelines (Li and Li, 2013; Yan et al., 2011), event chains (Chambers and Jurafsky, 2008; Shahaf and Guestrin, 2010; Tannier and Moriceau, 2013), or topic model based storylines (Ahmed et al., 2011). It is worth noting that some work uses similar event encoding based on actors and actions for political events (O’Connor et al., 2013). Our work is different from existing work in both the representation of an “event” and event detection techniques. We use a three-layer (story-event-article) representation to organize the storylines and develop efficient clustering and chaining methods on the event space. 137 8 Conclusion and Future Work We </context>
</contexts>
<marker>Yan, Kong, Huang, Wan, Li, Zhang, 2011</marker>
<rawString>Rui Yan, Liang Kong, Congrui Huang, Xiaojun Wan, Xiaoming Li, and Yan Zhang. 2011. Timeline generation through evolutionary trans-temporal summarization. In EMNLP, pages 433–443.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yiming Yang</author>
<author>Jaime G Carbonell</author>
<author>Ralf D Brown</author>
<author>Thomas Pierce</author>
<author>Brian T Archibald</author>
<author>Xin Liu</author>
</authors>
<title>Learning approaches for detecting and tracking news events.</title>
<date>1999</date>
<journal>IEEE Intelligent Systems,</journal>
<volume>14</volume>
<issue>4</issue>
<contexts>
<context position="4959" citStr="Yang et al., 1999" startWordPosition="765" endWordPosition="768">igure 1 shows the overall process for building Storybase. Input is daily crawled web news articles and Wikipedia current events. This generates the storylines and builds the Storybase using five steps system: preprocessing, categorization, event encoding, clustering, and chaining. Details are in Section 4. A news event search engine is built to provide a query based interface to search and visualize the Storybase, which is shown in Section 5. We now define concepts that will be frequently referred to. • A event identifies something (non-trivial) happening in a certain place at a certain time (Yang et al., 1999); it is a set of news articles on the same news report. • A story is a set of topical related news events. • A storyline is a series of temporally ordered events of the same story. • Actors in an event are named entities that make or receive actions. • Actions are verbs that connect actors. For example, as shown in Figure 2, “Pro-Russian militants seize the regional prosecutor’s office in the eastern Ukrainian city of Donetsk” is an event reported by a set of articles from different news sites. “2014 pro-Russian unrest in Ukraine” represents a story that consists of temporally evolving events,</context>
<context position="17816" citStr="Yang et al., 1999" startWordPosition="2867" endWordPosition="2870">e inner product does not do normalization thus favors the longer documents which should be less relevant in our setting. 7 Related Work Little work has been reported on the building of event knowledge bases with the exception of EVIN (Kuzey and Weikum, 2014). However, their main focus is on extracting named events from news articles in an offline setting for knowledge base population (Ji and Grishman, 2011), but not building storylines for new events from large scale daily news streams. Topic detection and tracking (TDT) that addresses event-based organization of news has been widely studied (Yang et al., 1999; Allan, 2002; Petrovi´c et al., 2012). Furthermore, there is a rich literature on bursty event detection (Kleinberg, 2002; Fung et al., 2005; He et al., 2007), where an “event” is a set of word features that co-occur in certain time windows in text streams. There is also an emerging interest in building news timelines (Li and Li, 2013; Yan et al., 2011), event chains (Chambers and Jurafsky, 2008; Shahaf and Guestrin, 2010; Tannier and Moriceau, 2013), or topic model based storylines (Ahmed et al., 2011). It is worth noting that some work uses similar event encoding based on actors and actions</context>
</contexts>
<marker>Yang, Carbonell, Brown, Pierce, Archibald, Liu, 1999</marker>
<rawString>Yiming Yang, Jaime G Carbonell, Ralf D Brown, Thomas Pierce, Brian T Archibald, and Xin Liu. 1999. Learning approaches for detecting and tracking news events. IEEE Intelligent Systems, 14(4):32–43.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>