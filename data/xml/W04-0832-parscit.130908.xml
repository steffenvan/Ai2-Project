<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000168">
<note confidence="0.541342333333333">
SENSEVAL-3: Third International Workshop on the Evaluation of Systems
for the Semantic Analysis of Text, Barcelona, Spain, July 2004
Association for Computational Linguistics
</note>
<title confidence="0.9791095">
SENSEVAL Automatic Labeling of Semantic Roles using Maximum Entropy
Models
</title>
<author confidence="0.992779">
Namhee Kwon
</author>
<affiliation confidence="0.998749">
Information Science Institute
University of Southern California
</affiliation>
<address confidence="0.8183865">
4676 Admiralty Way
Marina del Rey, CA 90292
</address>
<email confidence="0.997254">
nkwon@isi.edu
</email>
<author confidence="0.987838">
Michael Fleischman
</author>
<affiliation confidence="0.9179545">
Messachusetts Institute of
Technology
</affiliation>
<address confidence="0.9044095">
77 Massachusetts Ave
Cambridge, MA 02139
</address>
<email confidence="0.998305">
mbf@mit.edu
</email>
<author confidence="0.988697">
Eduard Hovy
</author>
<affiliation confidence="0.998765">
Information Science Institute
University of Southern California
</affiliation>
<address confidence="0.8185315">
4676 Admiralty Way
Marina del Rey, CA 90292
</address>
<email confidence="0.997267">
hovy@isi.edu
</email>
<sectionHeader confidence="0.99381" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999935545454546">
As a task in SensEval-3, Automatic Labeling
of Semantic Roles is to identify frame
elements within a sentence and tag them with
appropriate semantic roles given a sentence, a
target word and its frame. We apply
Maximum Entropy classification with feature
sets of syntactic patterns from parse trees and
officially attain 80.2% precision and 65.4%
recall. When the frame element boundaries
are given, the system performs 86.7%
precision and 85.8% recall.
</bodyText>
<sectionHeader confidence="0.998489" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999865166666667">
The Automatic Labeling of Semantic Roles track
in SensEval-3 focuses on identifying frame
elements in sentences and tagging them with their
appropriate semantic roles based on FrameNet1.
For this task, we extend our previous work
(Fleischman et el., 2003) by adding a sentence
segmentation step and by adopting a few additional
feature vectors for Maximum Entropy Model.
Following the task definition, we assume the frame
and the lexical unit of target word are known
although we have assumed only the target word is
known in the previous work.
</bodyText>
<sectionHeader confidence="0.988975" genericHeader="introduction">
2 Model
</sectionHeader>
<bodyText confidence="0.970292636363636">
We separate the problem of FrameNet tagging
into three subsequent processes: 1) sentence
segmentation 2) frame element identification, and
3) semantic role tagging. We assume the frame
element (FE) boundaries match the parse
constituents, so we segment a sentence based on
parse constituents. We consider steps 2) and 3) as
classification problems. In frame element
identification, we use a binary classifier to
determine if each parse constituent is a FE or not,
while, in semantic role tagging, we classify each
</bodyText>
<footnote confidence="0.948458">
1 http://www.icsi.berkeley.edu/~framenet
</footnote>
<figureCaption confidence="0.719267">
identified FE into its appropriate semantic role.2
Figure 1 shows the sequence of steps.
</figureCaption>
<subsectionHeader confidence="0.955663">
Input sentence
</subsectionHeader>
<bodyText confidence="0.998981">
He fastened the panel from an old radio to the headboard with
sticky tape and tied the driving wheel to Pete &apos;s cardboard box
with string
</bodyText>
<listItem confidence="0.947905583333333">
1) Sentence Segmentation: choose the highest
constituents while separating target word
(He) (fastened the panel from an old radio to the headboard
with sticky tape) (and) (tied) (the driving wheel) (to Pete &apos;s
cardboard box) (with string)
2) Frame Element Identification: apply ME
classification to classify each segment into classes of
FE (frame element), T (target), NO (none) then extract
identified frame elements
(He) (the driving wheel) (to Pete &apos;s cardboard box) (with string)
3) Semantic Role Tagging: apply ME classification to
classify each FE Into classes of various semantic roles
</listItem>
<figure confidence="0.644380666666667">
Agent Item Goal Connector
Output role: Agent (He), Item (the driving wheel),
Goal (to Pete’s cardboard box), Connector (with string)
</figure>
<figureCaption confidence="0.796856">
Fig. 1. The sequence of steps on a sample sentence
having a target word “tied”.
</figureCaption>
<bodyText confidence="0.9999383">
We train the ME models using the GIS
algorithm (Darroch and Ratcliff, 1972) as
implemented in the YASMET ME package (Och,
2002). We use the YASMET MEtagger (Bender et
al. 2003) to perform the Viterbi search for
choosing the most probable tag sequence for a
sentence using the probabilities computed during
training. Feature weights are smoothed using
Gaussian priors with mean 0 (Chen and Rosenfeld,
1999).
</bodyText>
<subsectionHeader confidence="0.992637">
2.1 Sentence Segmentation
</subsectionHeader>
<bodyText confidence="0.981705384615385">
We segment a sentence into a sequence of non-
overlapping constituents instead of all individual
constituents. There are a number of advantages to
applying sentence segmentation before FE
2 We are currently ignoring null instantiations.
boundary identification. First, it allows us to
utilize sentence-wide features for FE identification.
The sentence-wide features, containing dependent
information between frame element such as the
previously identified class or the syntactic pattern,
have previously been shown to be powerful
features for role classification (Fleischman et al.,
2003). Further, it allows us to reduce the number
of candidate constituents for FE, which reduces the
convergence time in training.
The constituents are derived from a syntactic
parse tree3. Although we need to consider all
combinations of various level constituents in a
parse tree, we know the given target word should
be a separate segment because a target word is not
a part of other FEs.4 Since most frame elements
tend to be in higher levels of the parse tree, we
decide to use the highest constituents (the parse
constituents having the maximum number of
words) while separating the target word. Figure 2
shows an example of the segmentation for an
actual sentence in FrameNet with the target word
“tied”.
Fig. 2. A sample sentence segmentation: “tied” is
the target predicate, and the shaded constituent
represents each segment.
However, this segmentation reduces the FE
coverage of constituents (the number of
constituents matching frame elements). In Table 1,
“individual constituents” means a list of all
constituents, and “Sentence segmentation” means a
sequence of non-overlapping constituents that are
taken in our work. We can regard 85.8% as the
accuracy of the parser.
</bodyText>
<footnote confidence="0.9911792">
3 We use Charniak parser :
http://www.cs.brown.edu/people/ec/#software
4 Although 17% of constituents are both a target and a
frame element, there is no case that a target is a part of a
frame element.
</footnote>
<table confidence="0.940762666666667">
Method Number of FE coverage
constituents (%)
Individual 342,245 85.8
constituents
Sentence 66,401 79.5
segmentation
</table>
<tableCaption confidence="0.999809">
Table 1. FE coverage for the test set.
</tableCaption>
<subsectionHeader confidence="0.998448">
2.2 Frame Element Identification
</subsectionHeader>
<bodyText confidence="0.99998">
Frame element identification is executed for
segments to classify into the classes on FE, Target,
or None. When a constituent is both a target and a
frame element, we set it as a frame element when
training because we are interested in identifying
frame elements not a target.
The initial features are adopted from (Gildea and
Juraksky 2002) and (Fleischman, Kwon, and Hovy
2003), and a few additional features are also used.
The features are:
</bodyText>
<listItem confidence="0.965026857142857">
• Target predicate (target): The target is the
principal lexical item in a sentence.
• Target lexical name (lexunit): The formal
lexical name of target predicate is the string of
the original form of target word and
grammatical type. For example, when the
target is “tied”, the lexical name is “tie.v”.
• Target type (ltype): The target type is a part
of lexunit representing verb, noun, or adjective.
(e.g. “v” for a lexunit “tie.v”)
• Frame name (frame): The semantic frame is
defined in FrameNet with corresponding target.
• Constituent path (path): From the syntactic
parse tree of a sentence, we extract the path
</listItem>
<bodyText confidence="0.884369857142857">
from each constituent to the target predicate.
The path is represented by the nodes through
which one passes while traveling up the tree
from the constituent and then down through
the governing category to the target word. For
example, “the driving wheel” in the sentence
of Figure 2 has the path, NP↑VP↓VBD.
</bodyText>
<listItem confidence="0.939172">
• Partial path (ppath): The partial path is a
variation of path, and it produces the same path
as above if the constituent is under the same
“S” as target word, if not, it gives “nopath”.
• Syntactic Head (head): The syntactic head of
each constituent is obtained based on Michael
</listItem>
<bodyText confidence="0.992985">
Collins’s heuristic method5. When the head is
a proper noun, “proper-noun” substitutes for
the real head. The decision as to whether the
head is a proper noun is made based on the
part of speech tags used in the parse tree.
</bodyText>
<figure confidence="0.86730652">
5 http://www.ai.mit.edu/people/mcollins/papers/heads
S
CC
VP
NP
VP
VP
....
fastened the panel
from an old radio
to the headboard
with sticky tape
and
NP
PP
PP
NP
NP
PRP VBD DT VBG NN TO NP NN NN
IN
NN
NNP POS
He tied the driving wheel to Pete ‘s cardboard box
with
string
</figure>
<listItem confidence="0.9846955">
• Phrase Type (pt): The syntactic phrase type
(e.g., NP, PP) of each constituent is also
extracted from the parse tree. It is not the
same as the manually defined PT in FrameNet.
• Logical Function (lf): The logical functions of
constituents in a sentence are simplified into
three values: external argument, object
argument, other. When the constituent’s
phrase type is NP, we follow the links in the
parse tree from the constituent to the ancestors
until we meet either S or VP. If the S is found
first, we assign external argument to the
constituent, and if the VP is found, we assign
object argument. Otherwise, other is assigned.
• Position (pos): The position indicates whether
a constituent appears before or after the target
predicate.
• Voice (voice): The voice of a sentence (active,
passive) is determined by a simple regular
expression over the surface form of the
sentence.
• Previous class (c_n): The class information of
the nth-previous constituent (Target, FE, or
None) is used to exploit the dependency
between constituents. During training, this
information is provided by simply looking at
the true class of the constituent occurring n-
positions before the target element. During
testing, the hypothesized classes are used for
Viterbi search.
</listItem>
<table confidence="0.999717666666667">
Feature Set Example Functions
f(c, lexunit) f(c, tie.v) = 1
f(c, pt, pos, voice) f(c, NP,after,active) = 1
f(c, pt, lf) f(c, ADVP,obj) = 1
f(c, pt_-1, lf_-1) f(c, VBD_-1, other_-1) = 1
f(c, pt 1, lf 1) f(c, PP 1, other 1) = 1
f(c, head) f(c, wheel) = 1
f(c, head, frame) f(c, wheel, Attaching) = 1
f(c, path) f(c, NP↑VP↓VBD) = 1
f(c, path_-1) f(c, VBD_-1) = 1
f(c, path_1) f(c, PP↑VP↓VBD_1) = 1
f(c, target) f(c, tied) = 1
f(c, ppath) f(c, NP↑VP↓VBD) = 1
f(c, ppath, pos) f(c,NP↑VP↓VBD, after) = 1
f(c, ppath_-1, pos_-1) f(c, VBD_-1,after) = 1
f(c ,ltype, ppath) f(c, v, NP↑VP↓VBD) = 1
f(c ,ltype, path) f(c, v, NP↑VP↓VBD) = 1
f(c ,ltype, path_-1) f(c, v,VBD_-1) = 1
f(c frame) f(c, Attaching) = 1
f(c, frame, c_-1) f(c, Attaching, T_-1) = 1
f(c,frame, c_-2,c_-1) f(c, Attaching,NO_-2,T_-1)=1
</table>
<tableCaption confidence="0.996302">
Table 2. Feature sets used in ME frame element
</tableCaption>
<bodyText confidence="0.991557333333333">
identification. Example functions of “the driving
wheel” from the sample sentence in Fig.2.
The combinations of these features that are used
in the ME model are shown in Table 2. These
feature sets contain the previous or next
constituent’s features, for example, pt_-1
represents the previous constituent’s phrase type
and lf_1 represents the next constituent’s logical
function.
</bodyText>
<subsectionHeader confidence="0.999708">
2.3 Semantic Role Classification
</subsectionHeader>
<bodyText confidence="0.999747833333333">
Semantic role classification is executed only for
the constituents that are classified into FEs in the
previous FE identification phase by employing
Maximum Entropy classification.
In addition to the features in Section 2.2, two
more features are applied.
</bodyText>
<listItem confidence="0.997213166666667">
• Order (order): The relative position of a
frame element in a sentence is given. For
example, the sentence from Figure 2 has four
frame elements, where the element “He” has
order 0, while “with string” has order 3.
• Syntactic pattern (pat): The sentence level
</listItem>
<bodyText confidence="0.885775181818182">
syntactic pattern is generated from the parse
tree by considering the phrase type and logical
functions of each frame element in the
sentence. In the example sentence in Figure 2,
“He” is an external argument Noun Phrase,
“tied” is a target predicate, and “the driving
wheel” is an object argument Noun Phrase.
Thus, the syntactic pattern associated with the
sentence is [NP-ext, target, NP-obj, PP-other,
PP-other].
Table 3 shows the list of feature sets used for the
ME role classification.
Feature Set
f(r, lexunit) f(r, pt, lf)
f(r, target) f(r, pt_-1, lf_-1)
f(r, pt, pos, voice) f(r, pt_1, lf_1)
f(r, head) f(r, order, syn)
f(r, head, lexunit) f(r, lexunit, order, syn)
f(r, head, frame) f(r, pt, pos, voice, lexunit)
f(r, frame, r -1) f(r, frame, r -2,r -1)
—
f(r, frame,r_-3, r_-2,r_-1)
</bodyText>
<tableCaption confidence="0.973904">
Table 3. Feature sets used in role classification.
</tableCaption>
<sectionHeader confidence="0.999713" genericHeader="method">
3 Results
</sectionHeader>
<bodyText confidence="0.998983944444444">
SensEval-3 provides the following data set:
training set (24,558 sentences/ 51,323 frame
elements/ 40 frames), and test set (8,002 sentences/
16,279 frame elements/ 40 frames). We submit two
sets to SensEval-3, one (test A) is the output of all
above processes (identifying frame elements and
tagging them given a sentence), and the other (test
B) is to tag semantic roles given frame elements.
For test B, we attempt the role classification for all
frame elements including frame elements not
matching the parse tree constituents. Although
there are frame elements that have two different
semantic roles, we ignore those cases and assign
one semantic role per frame element. This
explains why test B shows 99% attempted frame
elements. The attempted number for test A is the
number of frame elements identified by our system.
Table 4 shows the official scores for these tests.
</bodyText>
<table confidence="0.998322">
Test Prec. Overlap Recall Attempted
Test A 80.2 78.4 65.4 81.5
Test B 86.7 86.6 85.8 99.0
</table>
<tableCaption confidence="0.998297">
Table 4. Final SensEval-3 scores for the test set.
</tableCaption>
<bodyText confidence="0.99966375">
In the official evaluation, the precision and recall
are calculated by counting correct roles that
overlap even in only one word with the reference
set. Overlap score shows how much of an actual
FE is identified as an FE not penalizing wrongly
identified part. Since this evaluation is so lenient,
we perform another evaluation to check exact
matches.
</bodyText>
<table confidence="0.9972735">
Method FE boundary FE boundary
Identification Identification &amp;
Role labeling
Prec Rec Prec Rec
Test A 80.3 66.1 71.1 58.5
Test B 100.0 99.0 86.7 85.8
</table>
<tableCaption confidence="0.999533">
Table 5. Exact match scores for the test set.
</tableCaption>
<sectionHeader confidence="0.994498" genericHeader="discussions">
4 Discussion and Conclusion
</sectionHeader>
<bodyText confidence="0.999932142857143">
Due to time limit, we’ve not done many
experiments with different feature sets or
thresholds in ME classification. We expect that
recall will increase with lower thresholds
especially in lenient evaluation and the final
performance will increase by optimizing
parameters.
</bodyText>
<sectionHeader confidence="0.999435" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999846078947368">
O. Bender, K. Macherey, F.J. Och, and H. Ney.
2003. Comparison of Alignment Templates
and Maximum Entropy Models for Natural
Language Processing. Proc. of EACL-2003.
Budapest, Hungary.
A. Berger, S. Della Pietra and V. Della Pietra,
1996. A Maximum Entropy Approach to Natural
Language Proc. of Computational Linguistics,
vol. 22, no. 1.
E. Charniak. 2000. A Maximum-Entropy-Inspired
Parser. Proc. of NAACL-2000, Seattle, USA.
S.F. Chen and R. Rosenfeld. 1999. A Gaussian
Prior for Smoothing Maximum Entropy Models.
Technical Report CMUCS-99-108, Carnegie
Mellon University.
J. N. Darroch and D. Ratcliff. 1972. Generalized
Iterative Scaling for Log-Linear Models. Annals
of Mathematical Statistics, 43:1470-1480.
C.Fillmore 1976. Frame Semantics and the Nature
of Language. Annals of the New York Academy
of Science Conference on the Origin and
Development of Language and Speech, Volume
280 (pp. 20-32).
M. Fleischman, N. Kwon, and E. Hovy. 2003.
Maximum Entropy Models for FrameNet
Classification. Proc. of Empirical Methods in
Natural Language Processing conference
(EMNLP), 2003. Sapporo, Japan.
D. Gildea and D. Jurafsky. 2002. Automatic
Labeling of Semantic Roles. Computational
Linguistics, 28(3) 245-288 14.
F.J. Och. 2002. Yet Another Maxent Toolkit:
YASMET www-i6.informatik.rwth-aachen.de/
Colleagues/och/.
C. Thompson, R. Levy, and C. Manning. 2003. A
Generative Model for FrameNet Semantic Role
Labeling. Proc. of the Fourteenth European
Conference on Machine Learning, 2003. Croatia.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.241878">
<note confidence="0.7361405">SENSEVAL-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, Barcelona, Spain, July 2004</note>
<title confidence="0.872364333333333">Association for Computational Linguistics SENSEVAL Automatic Labeling of Semantic Roles using Maximum Entropy Models</title>
<author confidence="0.950476">Namhee Kwon</author>
<affiliation confidence="0.998684">Information Science Institute University of Southern California</affiliation>
<address confidence="0.9988935">4676 Admiralty Way Marina del Rey, CA 90292</address>
<email confidence="0.999229">nkwon@isi.edu</email>
<author confidence="0.920358">Michael</author>
<affiliation confidence="0.9164455">Messachusetts Institute Technology</affiliation>
<address confidence="0.9920145">77 Massachusetts Cambridge, MA 02139</address>
<email confidence="0.99986">mbf@mit.edu</email>
<author confidence="0.996489">Eduard Hovy</author>
<affiliation confidence="0.998684">Information Science Institute University of Southern California</affiliation>
<address confidence="0.998978">4676 Admiralty Way Marina del Rey, CA 90292</address>
<email confidence="0.99882">hovy@isi.edu</email>
<abstract confidence="0.98750775">As a task in SensEval-3, Automatic Labeling of Semantic Roles is to identify frame elements within a sentence and tag them with appropriate semantic roles given a sentence, a target word and its frame. We Maximum Entropy classification with feature sets of syntactic patterns from parse trees and officially attain 80.2% precision and 65.4% recall. When the frame element boundaries are given, the system performs 86.7% precision and 85.8% recall.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>O Bender</author>
<author>K Macherey</author>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<date>2003</date>
<booktitle>Comparison of Alignment Templates and Maximum Entropy Models for Natural Language Processing. Proc. of EACL-2003.</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="3437" citStr="Bender et al. 2003" startWordPosition="523" endWordPosition="526">get), NO (none) then extract identified frame elements (He) (the driving wheel) (to Pete &apos;s cardboard box) (with string) 3) Semantic Role Tagging: apply ME classification to classify each FE Into classes of various semantic roles Agent Item Goal Connector Output role: Agent (He), Item (the driving wheel), Goal (to Pete’s cardboard box), Connector (with string) Fig. 1. The sequence of steps on a sample sentence having a target word “tied”. We train the ME models using the GIS algorithm (Darroch and Ratcliff, 1972) as implemented in the YASMET ME package (Och, 2002). We use the YASMET MEtagger (Bender et al. 2003) to perform the Viterbi search for choosing the most probable tag sequence for a sentence using the probabilities computed during training. Feature weights are smoothed using Gaussian priors with mean 0 (Chen and Rosenfeld, 1999). 2.1 Sentence Segmentation We segment a sentence into a sequence of nonoverlapping constituents instead of all individual constituents. There are a number of advantages to applying sentence segmentation before FE 2 We are currently ignoring null instantiations. boundary identification. First, it allows us to utilize sentence-wide features for FE identification. The se</context>
</contexts>
<marker>Bender, Macherey, Och, Ney, 2003</marker>
<rawString>O. Bender, K. Macherey, F.J. Och, and H. Ney. 2003. Comparison of Alignment Templates and Maximum Entropy Models for Natural Language Processing. Proc. of EACL-2003. Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Berger</author>
<author>S Della Pietra</author>
<author>V Della Pietra</author>
</authors>
<title>A Maximum Entropy Approach to Natural Language</title>
<date>1996</date>
<booktitle>Proc. of Computational Linguistics,</booktitle>
<volume>22</volume>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>A. Berger, S. Della Pietra and V. Della Pietra, 1996. A Maximum Entropy Approach to Natural Language Proc. of Computational Linguistics, vol. 22, no. 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>A Maximum-Entropy-Inspired Parser.</title>
<date>2000</date>
<booktitle>Proc. of NAACL-2000,</booktitle>
<location>Seattle, USA.</location>
<marker>Charniak, 2000</marker>
<rawString>E. Charniak. 2000. A Maximum-Entropy-Inspired Parser. Proc. of NAACL-2000, Seattle, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S F Chen</author>
<author>R Rosenfeld</author>
</authors>
<title>A Gaussian Prior for Smoothing Maximum Entropy Models.</title>
<date>1999</date>
<tech>Technical Report CMUCS-99-108,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="3666" citStr="Chen and Rosenfeld, 1999" startWordPosition="558" endWordPosition="561"> roles Agent Item Goal Connector Output role: Agent (He), Item (the driving wheel), Goal (to Pete’s cardboard box), Connector (with string) Fig. 1. The sequence of steps on a sample sentence having a target word “tied”. We train the ME models using the GIS algorithm (Darroch and Ratcliff, 1972) as implemented in the YASMET ME package (Och, 2002). We use the YASMET MEtagger (Bender et al. 2003) to perform the Viterbi search for choosing the most probable tag sequence for a sentence using the probabilities computed during training. Feature weights are smoothed using Gaussian priors with mean 0 (Chen and Rosenfeld, 1999). 2.1 Sentence Segmentation We segment a sentence into a sequence of nonoverlapping constituents instead of all individual constituents. There are a number of advantages to applying sentence segmentation before FE 2 We are currently ignoring null instantiations. boundary identification. First, it allows us to utilize sentence-wide features for FE identification. The sentence-wide features, containing dependent information between frame element such as the previously identified class or the syntactic pattern, have previously been shown to be powerful features for role classification (Fleischman</context>
</contexts>
<marker>Chen, Rosenfeld, 1999</marker>
<rawString>S.F. Chen and R. Rosenfeld. 1999. A Gaussian Prior for Smoothing Maximum Entropy Models. Technical Report CMUCS-99-108, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J N Darroch</author>
<author>D Ratcliff</author>
</authors>
<title>Generalized Iterative Scaling for Log-Linear Models.</title>
<date>1972</date>
<journal>Annals of Mathematical Statistics,</journal>
<pages>43--1470</pages>
<contexts>
<context position="3336" citStr="Darroch and Ratcliff, 1972" startWordPosition="505" endWordPosition="508">t Identification: apply ME classification to classify each segment into classes of FE (frame element), T (target), NO (none) then extract identified frame elements (He) (the driving wheel) (to Pete &apos;s cardboard box) (with string) 3) Semantic Role Tagging: apply ME classification to classify each FE Into classes of various semantic roles Agent Item Goal Connector Output role: Agent (He), Item (the driving wheel), Goal (to Pete’s cardboard box), Connector (with string) Fig. 1. The sequence of steps on a sample sentence having a target word “tied”. We train the ME models using the GIS algorithm (Darroch and Ratcliff, 1972) as implemented in the YASMET ME package (Och, 2002). We use the YASMET MEtagger (Bender et al. 2003) to perform the Viterbi search for choosing the most probable tag sequence for a sentence using the probabilities computed during training. Feature weights are smoothed using Gaussian priors with mean 0 (Chen and Rosenfeld, 1999). 2.1 Sentence Segmentation We segment a sentence into a sequence of nonoverlapping constituents instead of all individual constituents. There are a number of advantages to applying sentence segmentation before FE 2 We are currently ignoring null instantiations. boundar</context>
</contexts>
<marker>Darroch, Ratcliff, 1972</marker>
<rawString>J. N. Darroch and D. Ratcliff. 1972. Generalized Iterative Scaling for Log-Linear Models. Annals of Mathematical Statistics, 43:1470-1480.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fillmore</author>
</authors>
<title>Frame Semantics and the Nature of Language. Annals of the New York Academy</title>
<date></date>
<booktitle>of Science Conference on the Origin and Development of Language and Speech,</booktitle>
<volume>280</volume>
<pages>(pp.</pages>
<marker>Fillmore, </marker>
<rawString>C.Fillmore 1976. Frame Semantics and the Nature of Language. Annals of the New York Academy of Science Conference on the Origin and Development of Language and Speech, Volume 280 (pp. 20-32).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Fleischman</author>
<author>N Kwon</author>
<author>E Hovy</author>
</authors>
<title>Maximum Entropy Models for FrameNet Classification.</title>
<date>2003</date>
<booktitle>Proc. of Empirical Methods in Natural Language Processing conference (EMNLP),</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="4280" citStr="Fleischman et al., 2003" startWordPosition="643" endWordPosition="646">eld, 1999). 2.1 Sentence Segmentation We segment a sentence into a sequence of nonoverlapping constituents instead of all individual constituents. There are a number of advantages to applying sentence segmentation before FE 2 We are currently ignoring null instantiations. boundary identification. First, it allows us to utilize sentence-wide features for FE identification. The sentence-wide features, containing dependent information between frame element such as the previously identified class or the syntactic pattern, have previously been shown to be powerful features for role classification (Fleischman et al., 2003). Further, it allows us to reduce the number of candidate constituents for FE, which reduces the convergence time in training. The constituents are derived from a syntactic parse tree3. Although we need to consider all combinations of various level constituents in a parse tree, we know the given target word should be a separate segment because a target word is not a part of other FEs.4 Since most frame elements tend to be in higher levels of the parse tree, we decide to use the highest constituents (the parse constituents having the maximum number of words) while separating the target word. Fi</context>
</contexts>
<marker>Fleischman, Kwon, Hovy, 2003</marker>
<rawString>M. Fleischman, N. Kwon, and E. Hovy. 2003. Maximum Entropy Models for FrameNet Classification. Proc. of Empirical Methods in Natural Language Processing conference (EMNLP), 2003. Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic Labeling of Semantic Roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<pages>245--288</pages>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>D. Gildea and D. Jurafsky. 2002. Automatic Labeling of Semantic Roles. Computational Linguistics, 28(3) 245-288 14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<date>2002</date>
<booktitle>Yet Another Maxent Toolkit: YASMET www-i6.informatik.rwth-aachen.de/ Colleagues/och/.</booktitle>
<contexts>
<context position="3388" citStr="Och, 2002" startWordPosition="516" endWordPosition="517">to classes of FE (frame element), T (target), NO (none) then extract identified frame elements (He) (the driving wheel) (to Pete &apos;s cardboard box) (with string) 3) Semantic Role Tagging: apply ME classification to classify each FE Into classes of various semantic roles Agent Item Goal Connector Output role: Agent (He), Item (the driving wheel), Goal (to Pete’s cardboard box), Connector (with string) Fig. 1. The sequence of steps on a sample sentence having a target word “tied”. We train the ME models using the GIS algorithm (Darroch and Ratcliff, 1972) as implemented in the YASMET ME package (Och, 2002). We use the YASMET MEtagger (Bender et al. 2003) to perform the Viterbi search for choosing the most probable tag sequence for a sentence using the probabilities computed during training. Feature weights are smoothed using Gaussian priors with mean 0 (Chen and Rosenfeld, 1999). 2.1 Sentence Segmentation We segment a sentence into a sequence of nonoverlapping constituents instead of all individual constituents. There are a number of advantages to applying sentence segmentation before FE 2 We are currently ignoring null instantiations. boundary identification. First, it allows us to utilize sen</context>
</contexts>
<marker>Och, 2002</marker>
<rawString>F.J. Och. 2002. Yet Another Maxent Toolkit: YASMET www-i6.informatik.rwth-aachen.de/ Colleagues/och/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Thompson</author>
<author>R Levy</author>
<author>C Manning</author>
</authors>
<title>A Generative Model for FrameNet Semantic Role Labeling.</title>
<date>2003</date>
<booktitle>Proc. of the Fourteenth European Conference on Machine Learning,</booktitle>
<marker>Thompson, Levy, Manning, 2003</marker>
<rawString>C. Thompson, R. Levy, and C. Manning. 2003. A Generative Model for FrameNet Semantic Role Labeling. Proc. of the Fourteenth European Conference on Machine Learning, 2003. Croatia.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>