<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.993777">
Corpus-Based Linguistic Indicators for Aspectual Classification
</title>
<author confidence="0.997085">
Eric V. Siegel
</author>
<affiliation confidence="0.9960135">
Department of Computer Science
Columbia University
</affiliation>
<address confidence="0.907037">
New York, NY 10027
</address>
<sectionHeader confidence="0.971278" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998091">
Fourteen indicators that measure the frequency
of lexico-syntactic phenomena linguistically re-
lated to aspectual class are applied to aspec-
tual classification. This group of indicators is
shown to improve classification performance for
two aspectual distinctions, stativity and corn-
pletedness (i.e., telicity), over unrestricted sets
of verbs from two corpora. Several of these in-
dicators have not previously been discovered to
correlate with aspect.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999768242424243">
Aspectual classification maps clauses to a small
set of primitive categories in order to reason
about time. For example, events such as,
&amp;quot;You called your father,&amp;quot; are distinguished from
states such as, &amp;quot;You resemble your father.&amp;quot;
These two high-level categories correspond to
primitive distinctions in many domains, e.g., the
distinction between procedure and diagnosis in
the medical domain.
Aspectual classification further distinguishes
events according to completedness (i.e., telicity),
which determines whether an event reaches a
culmination point in time at which a new state
is introduced. For example, &amp;quot;I made a fire&amp;quot;
is culminated, since a new state is introduced
— something is made, whereas, &amp;quot;I gazed at the
sunset&amp;quot; is non-culminated.
Aspectual classification is necessary for inter-
preting temporal modifiers and assessing tem-
poral entailments (Vendler, 1967; Dowty, 1979;
Moens and Steedman, 1988; Dorr, 1992), and
is therefore a necessary component for applica-
tions that perform certain natural language in-
terpretation, natural language generation, sum-
marization, information retrieval, and machine
translation tasks.
Aspect introduces a large-scale, domain-
dependent lexical classification problem. Al-
though an aspectual lexicon of verbs would suf-
fice to classify many clauses by their main verb
only, a verb&apos;s primary class is often domain-
dependent (Siegel, 1998b). Therefore, it is nec-
essary to produce a specialized lexicon for each
domain.
Most approaches to automatically catego-
rizing words measure co-occurrences between
open-class lexical items (Schfitze, 1992; Hatzi-
vassiloglou and McKeown, 1993; Pereira et
al., 1993). This approach is limited since co-
occurrences between open-class lexical items is
sparse, and is not specialized for particular se-
mantic distinctions such as aspect.
In this paper, we describe an expandable
framework to classify verbs with linguistically-
specialized numerical indicators. Each linguis-
tic indicator measures the frequency of a lexico-
syntactic marker, e.g. the perfect tense. These
markers are linguistically related to aspect, so
the indicators are specialized for aspectual clas-
sification in particular. We perform an evalua-
tion of fourteen linguistic indicators over unre-
stricted sets of verbs from two corpora. When
used in combination, this group of indicators is
shown to improve classification performance for
two aspectual distinctions: stativity and com-
pletedness. Moreover, our analysis reveals a
predictive value for several indicators that have
not previously been discovered to correlate with
aspect in the linguistics literature.
The following section further describes as-
pect, and introduces linguistic insights that are
exploited by linguistic indicators. The next sec-
tion describes the set of linguistic indicators
evaluated in this paper. Then, our experimen-
tal method and results are given, followed by a
discussion and conclusions.
</bodyText>
<page confidence="0.997688">
112
</page>
<tableCaption confidence="0.967985">
Table 1: Aspectual classes. This table comes from
Moens and Steedman (Moens and Steedman, 1988).
</tableCaption>
<table confidence="0.938869571428572">
EVENTS STATES
punctual extended understand
Culm CULM CULM
PROCESS
recognize build a house
Non- POINT PROCESS
Culm hiccup run, swim
</table>
<sectionHeader confidence="0.855755" genericHeader="method">
2 Aspect in Natural Language
</sectionHeader>
<bodyText confidence="0.991324352941176">
Table 1 summarizes the three aspectual distinc-
tions, which compose five aspectual categories.
In addition to the two distinctions described
in the previous section, atomicity distinguishes
events according to whether they have a time
duration (punctual versus extended). Therefore,
four classes of events are derived: culmination,
culminated process, process, and point. These
aspectual distinctions are defined formally by
Dowty (1979).
Several researchers have developed models
that incorporate aspectual class to assess tem-
poral constraints between clauses (Passonneau,
1988; Dorr, 1992). For example, stativity must
be identified to detect temporal constraints be-
tween clauses connected with when, e.g., in in-
terpreting (1),
</bodyText>
<listItem confidence="0.987381333333333">
(1) She had good strength when objectively
tested.
the following temporal relationship holds:
</listItem>
<subsectionHeader confidence="0.731732">
have
test
</subsectionHeader>
<bodyText confidence="0.994906">
However, in interpreting (2),
</bodyText>
<listItem confidence="0.685451666666667">
(2) Phototherapy was discontinued when the
bilirubin came down to 13.
the temporal relationship is different:
</listItem>
<subsectionHeader confidence="0.5290185">
come
discontinue
</subsectionHeader>
<bodyText confidence="0.948068">
These aspectual distinctions are motivated by
a series of entailment constraints. In particu-
lar, certain lexico-syntactic features of a clause,
such as temporal adjuncts and tense, are con-
strained by and contribute to the aspectual class
of the clause (Vendler, 1967; Dowty, 1979).
Tables 2 illustrates an array of linguistic con-
Table 2: Several aspectual markers and associated
constraints on aspectual class, primarily from Kia-
vans&apos; summary summary (1994).
If a clause can occur: then it is:
with a temporal adverb Event
(e.g., then)
in progressive Extended
</bodyText>
<subsectionHeader confidence="0.809919">
Event
</subsectionHeader>
<bodyText confidence="0.999376555555556">
with a duration in-PP
(e.g., in an hour)
in the perfect tense
straints. Each entry in this table describes an
aspectual marker and the constraints on the as-
pectual category of any clause that appears with
that marker. For example, a clause must be
an extended event to appear in the progressive
tense, e.g.,
</bodyText>
<listItem confidence="0.999392">
(3) He was prospering in India. (extended),
which contrasts with,
(4) *You were noticing it. (punctual).
and,
(5) *She was seeming sad. (state).
</listItem>
<bodyText confidence="0.935517">
As a second example, an event must be cul-
minated to appear in the perfect tense, for ex-
ample,
</bodyText>
<listItem confidence="0.999127666666667">
(6) She had made an attempt. (culm.),
which contrasts with,
(7) *He has cowered down. (non-culm.)
</listItem>
<sectionHeader confidence="0.989629" genericHeader="method">
3 Linguistic Indicators
</sectionHeader>
<bodyText confidence="0.961755611111111">
The best way to exploit aspectual markers is not
obvious, since, while the presence of a marker in
a particular clause indicates a constraint on the
aspectual class of the clause, the absence thereof
does not place any constraint. Therefore, as
with most statistical methods for natural lan-
guage, the linguistic constraints associated with
markers are best exploited by a system that
measures co-occurrence frequencies. For exam-
ple, a verb that appears more frequently in the
progressive is more likely to describe an event.
Klavans and Chodorow (1992) pioneered the ap-
plication of statistical corpus analysis to aspec-
tual classification by ranking verbs according to
the frequencies with which they occur with cer-
tain aspectual markers.
Table 3 lists the linguistic indicators evalu-
ated for aspectual classification. Each indica-
</bodyText>
<figure confidence="0.981877">
Culm Event
Culm Event
or State
</figure>
<page confidence="0.524171">
113
</page>
<figure confidence="0.9602005">
Ling Indicator Example Clause
frequency
&amp;quot;not&amp;quot; or &amp;quot;never&amp;quot;
temporal adverb
no subject
past/pres partic
duration in-PP
perfect
present tense
progressive
manner adverb
evaluation adverb
past tense
duration for-PP
continuous adverb
(not applicable)
She can not explain why.
I saw to it then.
</figure>
<bodyText confidence="0.951125">
He was admitted.
...blood pressure going up.
She built it in an hour.
They have landed.
I am happy.
I am behaving myself.
She studied diligently.
They performed horribly.
/ was happy.
I sang for ten minutes.
She will live indefinitely.
</bodyText>
<tableCaption confidence="0.935961">
Table 3: Fourteen linguistic indicators evaluated for
aspectual classification.
</tableCaption>
<bodyText confidence="0.985490517241379">
tor has a unique value for each verb. The first
indicator, frequency, is simply the frequency
with which each verb occurs over the entire
corpus. The remaining 13 indicators measure
how frequently each verb occurs in a clause
with the named linguistic marker. For exam-
ple, the next three indicators listed measure the
frequency with which verbs 1) are modified by
not or never, 2) are modified by a temporal ad-
verb such as then or frequently, and 3) have no
deep subject (e.g., passive phrases such as, &amp;quot;She
was admitted to the hospital&amp;quot;). Further details
regarding these indicators and their linguistic
motivation is given by Siegel (1998b).
There are several reasons to expect superior
classification performance when employing mul-
tiple linguistic indicators in combination rather
than using them individually. While individ-
ual indicators have predictive value, they are
predictively incomplete. This incompleteness
has been illustrated empirically by showing that
some indicators help for only a subset of verbs
(Siegel, 1998b). Such incompleteness is due in
part to sparsity and noise of data when com-
puting indicator values over a corpus with lim-
ited size and some parsing errors. However, this
incompleteness is also a consequence of the lin-
guistic characteristics of various indicators. For
example:
</bodyText>
<listItem confidence="0.991986666666667">
• Aspectual coercion such as iteration com-
promises indicator measurements (Moens
and Steedman, 1988). For example, a
</listItem>
<bodyText confidence="0.977064">
punctual event appears with the progres-
sive in, &amp;quot;She was sneezing for a week.&amp;quot;
(point process culminated process)
In this example, for a week can only modify
an extended event, requiring the first coer-
cion. In addition, this for-PP also makes
an event culminated, causing the second
transformation.
</bodyText>
<listItem confidence="0.9984084">
• Some aspectual markers such as the
pseudo-cleft and manner adverbs test for
intentional events, and therefore are not
compatible with all events, e.g., &apos;4/ died
diligently.&amp;quot;
• The progressive indicator&apos;s predictiveness
for stativity is compromised by the fact
that many location verbs can appear with
the progressive, even in their stative sense,
e.g. &amp;quot;The book was lying on the shelf.&amp;quot;
(Dowty, 1979)
• Several indicators measure phenomena
that are not linguistically constrained by
any aspectual category, e.g., the present
tense, frequency and not/never indicators.
</listItem>
<sectionHeader confidence="0.786761" genericHeader="method">
4 Method and Results
</sectionHeader>
<bodyText confidence="0.99949352">
In this section, we evaluate the set of
fourteen linguistic indicators for two aspec-
tual distinctions: stativity and completed-
ness. Evaluation is over corpora of med-
ical reports and novels, respectively. This
data is summarized in Table 4 (available at
www. cs . co lumbia.edui-evs/VerbDat a).
First, linguistic indicators are each evalu-
ated individually. A training set is used to se-
lect indicator value thresholds for classification.
Then, we report the classification performance
achieved by combining multiple indicators. In
this case, the training set is used to optimize a
model for combining indicators. In both cases,
evaluation is performed over a separate test set
of clauses.
The combination of indicators is performed
by four standard supervised learning algo-
rithms: decision tree induction (Quinlan, 1986),
CART (Friedman, 1977), log-linear regression
(Santner and Duffy, 1989) and genetic program-
ming (GP) (Cramer, 1985; Koza, 1992).
A pilot study showed no further improve-
ment in accuracy or recall tradeoff by additional
learning algorithms: Naive Bayes (Duda and
</bodyText>
<page confidence="0.995013">
114
</page>
<table confidence="0.837246727272727">
stativrty completedness
corpus: 3,224 med reports 10 novels
size: 1,159,891 846,913
parsed
clauses: 97,973 75,289
training: 739 (634 eventsi 307 (196 culm)
testing: 739 (619 events) 308 (195 culm)
verbs in
test set: 222 204
clauses
excluded: be and have stative
</table>
<tableCaption confidence="0.9780875">
Table 4: Two classification problems on different
data sets.
</tableCaption>
<bodyText confidence="0.96974575">
Hart, 1973), Ripper (Cohen, 1995), ID3 (Quin-
lan, 1986), C4.5 (Quinlan, 1993), and met-
alearning to combine learning methods (Chan
and Stolfo, 1993).
</bodyText>
<subsectionHeader confidence="0.991437">
4.1 S tat ivity
</subsectionHeader>
<bodyText confidence="0.9999379">
Our experiments are performed across a cor-
pus of 3,224 medical discharge summaries. A
medical discharge summary describes the symp-
toms, history, diagnosis, treatment and outcome
of a patient&apos;s visit to the hospital. These re-
ports were parsed with the English Slot Gram-
mar (ESG) (McCord, 1990), resulting in 97,973
clauses that were parsed fully with no self-
diagnostic errors (ESO produced error messages
on 12,877 of this corpus&apos; 51,079 complex sen-
tences).
Be and have, the two most popular verbs, cov-
ering 31.9% of the clauses in this corpus, are
handled separately from all other verbs. Clauses
with be as their main verb, comprising 23.9% of
the corpus, always denote a state. Clauses with
have as their main verb, composing 8.0% of the
corpus, are highly ambiguous, and have been
addressed separately by considering the direct
object of such clauses (Siegel, 1998a).
</bodyText>
<subsubsectionHeader confidence="0.518338">
4.1.1 Manual Marking
</subsubsectionHeader>
<bodyText confidence="0.8556628">
1,851 clauses from the parsed corpus were man-
ually marked according to stativity. As a lin-
guistic test for marking, each clause was tested
for readability with &amp;quot;What happened was... &amp;quot;1
A comparison between human markers for this
test performed over a different corpus is re-
ported below in Section 4.2.1. Of these, 373
&apos;Manual labeling followed a strict set of linguistically-
motivated guidelines, e.g., negations were ignored
(Siegel, 1998b).
</bodyText>
<table confidence="0.9987513125">
Stative Event T-test
Mean Mean P-value
932.89 667.57 0.0000
4.44% 1.56% 0.0000
1.00% 2.70% 0.0000
36.05% 57.56% 0.0000
20.98% 15.37% 0.0005
0.16% 0.60% 0.0018
2.27% 3.44% 0.0054
11.19% 8.94% 0.0901
1.79% 2.69% 0.0903
0.00% 0.03% 0.1681
0.69% 1.19% 0.1766
62.85% 65.69% 0.2314
0.59% 0.61% 0.8402
0.04% 0.03% 0.8438
</table>
<tableCaption confidence="0.994405">
Table 5: Indicators discriminate between states and
events.
</tableCaption>
<bodyText confidence="0.9997352">
clauses were rejected because of parsing prob-
lems. This left 1,478 clauses, divided equally
into training and testing sets.
83.8% of clauses with main verbs other than
be and have are events, which thus provides a
baseline method of 83.8% for comparison. Since
our approach examines only the main verb of a
clause, classification accuracy over the test cases
has a maximum of 97.4% due to the presence of
verbs with multiple classes.
</bodyText>
<subsubsectionHeader confidence="0.855683">
4.1.2 Individual Indicators
</subsubsectionHeader>
<bodyText confidence="0.999788727272727">
The values of the indicators listed in Table 5
were computed, for each verb, across the 97,973
parsed clauses from our corpus of medical dis-
charge summaries.
The second and third columns of Table 5 show
the average value for each indicator over stative
and event clauses, as measured over the training
examples. For example, 4.44% of stative clauses
are modified by either not or never, but only
1.56% of event clauses were so modified.
The fourth column shows the results of T-
tests that compare indicator values over stative
training cases to those over event cases for each
indicator. As shown, the differences in stative
and event means are statistically significant (p
&lt; .01) for the first seven indicators.
Each indicator was tested individually for
classification accuracy by establishing a classifi-
cation threshold over the training data, and val-
idating performance over the testing data using
the same threshold. Only the frequency indi-
cator succeeded in significantly improving clas-
</bodyText>
<figure confidence="0.8282576875">
Linguistic
Indicator
frequency
&amp;quot;not&amp;quot; or &amp;quot;never&amp;quot;
temporal adverb
no subject
past/pres partic
duration in-PP
perfect
present tense
progressive
manner adverb
evaluation adverb
past tense
duration for-PP
continuous adverb
</figure>
<page confidence="0.792027">
115
</page>
<table confidence="0.999436">
acc States Events
recall prec recall prec
dt 93.9% 74.2% 86.4% 97.7% 95.1%
GP 91.2% 47.4% 97.3% 99.7% 90.7%
llr 86.7% 34.2% 68.3% 96.9% 88.4%
bl 83.8% 0.0% 100.0% 100.0% 83.8%
b12 94.5% 69.2% 95.4% 99.4% 94.3%
</table>
<tableCaption confidence="0.995808">
Table 6: Comparison of three learning methods
</tableCaption>
<bodyText confidence="0.935327272727273">
and two performance baselines, distinguishing states
from events.
sification accuracy by itself, achieving an accu-
racy of 88.0%. This improvement in accuracy
was achieved simply by discriminating the pop-
ular verb show as a state, but classifying all
other verbs as events. Although many domains
may primarily use show as an event, its appear-
ances in medical discharge summaries, such as,
&amp;quot;His lumbar puncture showed evidence of white
cells,&amp;quot; primarily utilize show to denote a state.
</bodyText>
<subsectionHeader confidence="0.47464">
4.1.3 Indicators in Combination
</subsectionHeader>
<bodyText confidence="0.99993725">
Three machine learning methods successfully
combined indicator values, improving classifi-
cation accuracy over the baseline measure. As
shown in Table 6, the decision tree attained the
highest accuracy, 93.9%. Binomial tests showed
this to be a significant improvement over the
88.0% accuracy achieved by the frequency indi-
cator alone, as well as over the other two learn-
ing methods. No further improvement in classi-
fication performance was achieved by CART.
The increase in the number of stative clauses
correctly classified, i.e. stative recall, illustrates
an even greater improvement over the base-
line. As shown in Table 6, the three learn-
ing methods achieved stative recalls of 74.2%,
47.4% and 34.2%, as compared to the 0.0% sta-
tive recall achieved by the baseline, while only
a small loss in recall over event clauses was suf-
fered. The baseline does not classify any stative
clauses correctly because it classifies all clauses
as events.
Classification performance is equally compet-
itive without the frequency indicator, although
this indicator appears to dominate over oth-
ers. When decision tree induction was employed
to combine only the 13 indicators other than
frequency, the resulting decision tree achieved
92.4% accuracy and 77.5% stative recall.
</bodyText>
<subsectionHeader confidence="0.989636">
4.2 Completedness
</subsectionHeader>
<bodyText confidence="0.99995925">
In medical discharge summaries, non-
culminated event clauses are rare. Therefore,
our experiments for classification according to
completedness are performed across a corpus
of ten novels comprising 846,913 words. These
novels were parsed with ESC, resulting in
75,289 fully-parsed clauses (22,505 of 59,816
sentences produced errors).
</bodyText>
<subsubsectionHeader confidence="0.513301">
4.2.1 Manual Marking
</subsubsectionHeader>
<bodyText confidence="0.999954566666667">
884 clauses from the parsed corpus were man-
ually marked according to completedness. Of
these, 109 were rejected because of parsing
problems, and 160 rejected because they de-
scribed states. The remaining 615 clauses were
divided into training and test sets such that the
distribution of classes was equal. The baseline
method in this case achieves 63.3% accuracy.
The linguistic test was selected for this task
by Passonneau (1988): If a clause in the past
progressive necessarily entails the past tense
reading, the clause describes a non-culminated
event. For example, We were talking just like
men (non-culm.) entails that We talked just
like men, but The woman was building a house
(culm.) does not necessarily entail that The
woman built a house. Cross-checking between
linguists shows high agreement. In particular,
in a pilot study manually annotating 89 clauses
from this corpus according to stativity, two lin-
guists agreed 81 times. Of 57 clauses agreed
to be events, 46 had agreement with respect to
completedness.
The verb say (point), which occurs nine times
in the test set, was initially marked incorrectly
as culminated, since points are non-extended
and therefore cannot be placed in the progres-
sive. After some initial experimentation, we cor-
rected the class of each occurrence of say in the
data.
</bodyText>
<subsubsectionHeader confidence="0.845853">
4.2.2 Individual Indicators
</subsubsectionHeader>
<bodyText confidence="0.979918428571429">
Table 7 is analogous to Table 5 for complete-
ness. The differences in culminated and non-
culminated means are statistically significant (p
&lt; .05) for the first six indicators. However, for
completedness, no indicator was shown to sig-
nificantly improve classification accuracy over
the baseline.
</bodyText>
<page confidence="0.997336">
116
</page>
<table confidence="0.999892875">
Cu1m Non-Culm T-test
Mean Mean P-value
7.87% 2.88% 0.0000
5.60% 3.41% 0.0000
0.19% 0.61% 0.0008
3.02% 5.03% 0.0031
14.03% 17.98% 0.0080
30.77% 26.55% 0.0241
0.27% 0.06% 0.0626
17.18% 14.29% 0.0757
0.34% 0.49% 0.1756
0.10% 0.49% 0.2563
345 . 86 286.55 0.5652
3.41% 3.15% 0.6164
0.46% 0.39% 0.7063
53.62% 54.36% 0.7132
</table>
<tableCaption confidence="0.9372016">
Table 7: Indicators discriminate between culmi-
nated and non-culminated events.
Table 8: Comparison of four learning methods
and two performance baselines, distinguishing cul-
minated from non-culminated events.
</tableCaption>
<subsectionHeader confidence="0.51224">
4.2.3 Indicators in Combination
</subsectionHeader>
<bodyText confidence="0.999655470588235">
As shown in Table 8, the highest accuracy,
74.0%, was attained by CART. A binomial test
shows this is a significant improvement over the
63.3% baseline.
The increase in non-culminated recall illus-
trates a greater improvement over the baseline.
As shown in Table 8, non-culminated recalls of
up to 53.6% were achieved by the learning meth-
ods, compared to 0.0%, achieved by the base-
line.
Additionally, a non-culminated F-measure of
61.9 was achieved by GP, when optimizing for
F-Measure, improving over 53.7 attained by the
optimal uninformed baseline. F-measure com-
putes a tradeoff between recall and precision
(Van Rijsbergen, 1979). In this work, we weigh
recall and precision equally, in which case,
</bodyText>
<equation confidence="0.3298955">
F - m recall*precision
easure (recall+precision)/2
</equation>
<bodyText confidence="0.972118">
Automatic methods highly prioritized the
perfect indicator. The induced decision tree uses
the perfect indicator as its first discriminator,
log-linear regression ranked the perfect indica-
tor as fourth out of fourteen, function trees cre-
ated by GP include the perfect indicator as one
of five indicators used together to increase clas-
sification performance, and the perfect indicator
tied as most highly correlated with completed-
ness (cf. Table 7).
</bodyText>
<sectionHeader confidence="0.997515" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999958181818182">
Since certain verbs are aspectually ambiguous,
and, in this work, clauses are classified by their
main verb only, a second baseline approach
would be to simply memorize the majority as-
pect of each verb in the training set, and classify
verbs in the test set accordingly. In this case,
test verbs that did not appear in the training set
would be classified according to majority class.
However, classifying verbs and clauses accord-
ing to numerical indicators has several impor-
tant advantages over this baseline:
</bodyText>
<listItem confidence="0.68518">
• Handles rare or unlabeled verbs. The
</listItem>
<bodyText confidence="0.893971823529412">
results we have shown serve to estimate
classification performance over &amp;quot;unseen&amp;quot;
verbs that were not included in the super-
vised training sample. Once the system
has been trained to distinguish by indi-
cator values, it can automatically classify
any verb that appears in unlabeled cor-
pora, since measuring linguistic indicators
for a verb is fully automatic. This also ap-
plies to verbs that are underrepresented in
the training set. For example, one node
of the resulting decision tree trained to
distinguish according to stativity identifies
19 stative test cases without misclassifying
any of 27 event test cases with verbs that
occur only one time each in the training
set.
</bodyText>
<listItem confidence="0.953680083333333">
• Success when training doesn&apos;t include
test verbs. To test this, all test verbs
were eliminated from the training set, and
log-linear regression was trained over this
smaller set to distinguish according to com-
pletedness. The result is shown in Table 8
(&amp;quot;1Ir2&amp;quot;). Accuracy remained higher than
the baseline &amp;quot;bl&amp;quot; (b12 not applicable), and
the recall tradeoff is felicitous.
• Improved performance. Memorizing
majority aspect does not achieve as high
an accuracy as the linguistic indicators for
</listItem>
<figure confidence="0.744537923076923">
Linguistic
Indicator
perfect
temporal adverb
manner adverb
progressive
past/pres partic
no subject
duration in-PP
present tense
duration for-PP
continuous adverb
frequency
</figure>
<table confidence="0.926022666666667">
&amp;quot;not&amp;quot; or &amp;quot;never&amp;quot;
evaluation adverb
past tense
acc Culminated Non-Culm
recall prec recall prec
CART 74.0% 86.2% 76.0% 53.1% 69.0%
Ur 70.5% 83.1% 73.6% 48.7% 62.5%
11r2 67.2% 81.5% 71.0% 42.5% 57.1%
GP 68.6% 77.3% 74.2% 53.6% 57.8%
dt 68.5% 86.2% 70.6% 38.1% 61.4%
bl 63.3% 100.0% 63.3% 0.0% 100.0%
b12 70.8% 94.9% 69.8% 29.2% 76.7%
</table>
<page confidence="0.997316">
117
</page>
<bodyText confidence="0.962315346153846">
completedness, nor does it achieve as wide
a recall tradeff for both stativity and corn-
pletedness. These results are indicated as
the second baselines (&amp;quot;b12&amp;quot;) in tables 6 and
8, respectively.
• Scalar values assigned to each verb al-
low the tradeoff between recall and preci-
sion to be selected for particular applica-
tions by selecting the classification thresh-
old. For example, in a separate study, op-
timizing for F-measure resulted in a more
dramatic tradeoff in recall values as com-
pared to those attained when optimizing
for accuracy (Siegel, 1998b). Moreover,
such scalar values can provide input to sys-
tems that perform reasoning on fuzzy or
uncertainty knowledge.
• This framework is expandable since
additional indicators can be introduced
by measuring the frequencies of additional
aspectual markers. Furthermore, indica-
tors measured over multiple clausal con-
stituents, e.g., main verb-object pairs, al-
leviate verb ambiguity and sparsity and
improve classification performance (Siegel,
1998b).
</bodyText>
<sectionHeader confidence="0.999671" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999491671232877">
We have developed a full-scale system for aspec-
tual classification with multiple linguistic indi-
cators. Once trained, this system can automati-
cally classify all verbs appearing in a corpus, in-
cluding &amp;quot;unseen&amp;quot; verbs that were not included
in the supervised training sample. This frame-
work is expandable, since additional lexico-
syntactic markers may also correlate with as-
pectual class. Future work will extend this ap-
proach to other semantic distinctions in natural
language.
Linguistic indicators successfully exploit lin-
guistic insights to provide a much-needed
method for aspectual classification. When com-
bined with a decision tree to classify according
to stativity, the indicators achieve an accuracy
of 93.9% and stative recall of 74.2%. When com-
bined with CART to classify according to corn-
pletedness, indicators achieved 74.0% accuracy
and 53.1% non-culminated recall.
A favorable tradeoff in recall presents an ad-
vantage for applications that weigh the identi-
fication of non-dominant classes more heavily
(Cardie and Howe, 1997). For example, cor-
rectly identifying occurrences of for that denote
event durations relies on positively identifying
non-culminated events. A system that summa-
rizes the duration of events which incorrectly
classifies &amp;quot;She ran (for a minute)&amp;quot; as culmi-
nated will not detect that &amp;quot;for a minute&amp;quot; de-
scribes the duration of the run event. This is be-
cause durative for-PPs that modify culminated
events denote the duration of the ensuing state,
e.g., I left the room for a minute. (Vendler,
1967)
Our analysis has revealed several insights re-
garding individual indicators. For example,
both duration in-PP and manner adverb are
particularly valuable for multiple aspectual dis-
tinctions — they were ranked in the top two po-
sitions by log-linear modeling for both stativity
and completedness.
We have discovered several new linguistic in-
dicators that are not traditionally linked to as-
pectual class. In particular, verb frequency with
no deep subject was positively correlated with
both stativity and completedness. Moreover,
four other indicators are newly linked to stativ-
ity: (1) Verb frequency, (2) occurrences modi-
fied by &amp;quot;not&amp;quot; or &amp;quot;never&amp;quot;, (3) occurrences in the
past or present participle, and (4) occurrences
in the perfect tense. Additionally, another three
were newly linked to completedness: (1) occur-
rences modified by a manner adverb, (2) occur-
rences in the past or present participle, and (3)
occurrences in the progressive.
These new correlations can be understood in
pragmatic terms. For example, since points
(non-culminated, punctual events, e.g., hiccup)
are rare, punctual events are likely to be cul-
minated. Therefore, an indicator that discrim-
inates events according to extendedness, e.g.,
the progressive, past/present participle, and du-
ration for-PP, is likely to also discriminate be-
tween culminated and non-culminated events.
As a second example, the not/never indica-
tor correlates with stativity in medical reports
because diagnoses (i.e., states) are often ruled
out in medical discharge summaries, e.g., &amp;quot;The
patient was not hypertensive,&amp;quot; but procedures
(i.e., events) that were not done are not usu-
ally mentioned, e.g., &apos;?An examination was not
performed.&amp;quot;
</bodyText>
<page confidence="0.997844">
118
</page>
<sectionHeader confidence="0.989139" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9991218">
Kathleen R. McKeown was extremely helpful regard-
ing the formulation of this work and Judith L. Kia-
vans
-
vans regarding linguistic techniques, and they, along
with Min-Yen Kan and Dragomir R. Radev provided
useful feedback on an earlier draft of this paper.
This research was supported in part by the
Columbia University Center for Advanced Technol-
ogy in High Performance Computing and Commu-
nications in Healthcare (funded by the New York
State Science and Technology Foundation), the Of-
fice of Naval Research under contract N00014-95-1-
0745 and by the National Science Foundation under
contract GER-90-24069.
</bodyText>
<sectionHeader confidence="0.99845" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999819478723404">
C. Cardie and N. Howe. 1997. Improving mi-
nority class prediction using case-specific feature
weights. In D. Fisher, editor, Proceedings of the
Fourteenth International Conference on Machine
Learning. Morgan Kaufmann.
P.K. Chan and S.J. Stolfo. 1993. Toward multistrat-
egy parallel and distributed learning in sequence
analysis. In Proceedings of the First International
Conference on Intelligent Systems for Molecular
Biology.
W. Cohen. 1995. Fast effective rule induction. In
Proc. 12th Intl. Conf. Machine Learning, pages
115-123.
N. Cramer. 1985. A representation for the adap-
tive generation of simple sequential programs. In
J. Grefenstette, editor, Proceedings of the [First]
International Conference on Genetic Algorithms.
Lawrence Erlbaum.
Dorr. 1992. A two-level knowledge represen-
tation for machine translation: lexical seman-
tics and tense/aspect. In James Pustejovsky
and Sabine Bergler, editors, Lexical Semantics
and Knowledge Representation. Springer Verlag,
Berlin.
D.R. Dowty. 1979. Word Meaning and Montague
Grammar. D. Reidel, Dordrecht, W. Germany.
R. 0. Duda and P.E. Hart. 1973. Pattern Classifi-
cation and Scene Analysis. Wiley, New York.
J.H. Friedman. 1977. A recursive partitioning deci-
sion rule for non-parametric classification. IEEE
Transactions on Computers.
V. Hatzivassiloglou and K. McKeown. 1993. To-
wards the automatic identification of adjectival
scales: clustering adjectives according to mean-
ing. In Proceedings of the 31st Annual Meeting of
the ACL, Columbus, Ohio, June. Association for
Computational Linguistics.
J.L. Klavans and M. Chodorow. 1992. Degrees of
stativity: the lexical representation of verb as-
pect. In Proceedings of the 14th International
Conference on Computation Linguistics.
J.L. Klavans. 1994. Linguistic tests over large cor-
pora: aspectual classes in the lexicon. Technical
report, Columbia University Dept. of Computer
Science. unpublished manuscript.
J.R. Koza. 1992. Genetic Programming: On the
programming of computers by means of natural
selection. MIT Press, Cambridge, MA.
M.C. McCord. 1990. SLOT GRAMMAR. In
R. Studer, editor, International Symposium on
Natural Language and Logic. Springer Verlag.
M. Moens and M. Steedman. 1988. Temporal ontol-
ogy and temporal reference. Computational Lin-
guistics, 14(2).
R.J. Passonneau. 1988. A computational model of
the semantics of tense and aspect. Computational
Linguistics, 14(2).
F. Pereira, N. Tishby, and L. Lee. 1993. Distribu-
tional clustering of english words. In Proceedings
of the 31st Conference of the ACL, Columbus,
Ohio. Association for Computational Linguistics.
J.R. Quinlan. 1986. Induction of decision trees. Ma-
chine Learning, 1(1):81-106.
J.R. Quinlan. 1993. C4.5: Programs for Machine
Learning. Morgan Kaufmann, San Mateo, CA.
T.J. Santner and D.E. Duffy. 1989. The Statistical
Analysis of Discrete Data. Springer-Verlag, New
York.
H. Schfitze. 1992. Dimensions of meaning. In Pro-
ceedings of Supercomputing.
E.V. Siegel and K.R. McKeown. 1996. Gathering
statistics to aspectually classify sentences with a
genetic algorithm. In K. Oflazer and H. Somers,
editors, Proceedings of the Second International
Conference on New Methods in Language Process-
ing, Ankara, Turkey, Sept. Bilkent University.
E.V. Siegel. 1997. Learning methods for combining
linguistic indicators to classify verbs. In Proceed-
ings of the Second Conference on Empirical Meth-
ods in Natural Language Processing, Providence,
RI, August.
E.V. Siegel. 1998a. Disambiguating verbs with the
wordnet category of the direct object. In Proced-
ings of the Usage of WordNet in Natural Language
Processing Systems Workshop, Montreal, Canada.
E.V. Siegel. 1998b. Linguistic Indicators for Lan-
guage Understanding: Using machine learning
methods to combine corpus-based indicators for
aspectual classification of clauses. Ph.D. thesis,
Columbia University.
C.J. Van Rijsbergen. 1979. Information Retrieval.
Butterwoths, London.
Z. Vendler. 1967. Verbs and times. In Linguistics in
Philosophy. Cornell University Press, Ithaca, NY.
</reference>
<page confidence="0.999099">
119
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.856661">
<title confidence="0.999759">Corpus-Based Linguistic Indicators for Aspectual Classification</title>
<author confidence="0.999997">Eric V Siegel</author>
<affiliation confidence="0.999907">Department of Computer Science Columbia University</affiliation>
<address confidence="0.999317">New York, NY 10027</address>
<abstract confidence="0.986035818181818">Fourteen indicators that measure the frequency of lexico-syntactic phenomena linguistically related to aspectual class are applied to aspectual classification. This group of indicators is shown to improve classification performance for two aspectual distinctions, stativity and cornpletedness (i.e., telicity), over unrestricted sets of verbs from two corpora. Several of these indicators have not previously been discovered to correlate with aspect.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Cardie</author>
<author>N Howe</author>
</authors>
<title>Improving minority class prediction using case-specific feature weights. In</title>
<date>1997</date>
<booktitle>Proceedings of the Fourteenth International Conference on Machine Learning.</booktitle>
<editor>D. Fisher, editor,</editor>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="24848" citStr="Cardie and Howe, 1997" startWordPosition="3819" endWordPosition="3822">pproach to other semantic distinctions in natural language. Linguistic indicators successfully exploit linguistic insights to provide a much-needed method for aspectual classification. When combined with a decision tree to classify according to stativity, the indicators achieve an accuracy of 93.9% and stative recall of 74.2%. When combined with CART to classify according to cornpletedness, indicators achieved 74.0% accuracy and 53.1% non-culminated recall. A favorable tradeoff in recall presents an advantage for applications that weigh the identification of non-dominant classes more heavily (Cardie and Howe, 1997). For example, correctly identifying occurrences of for that denote event durations relies on positively identifying non-culminated events. A system that summarizes the duration of events which incorrectly classifies &amp;quot;She ran (for a minute)&amp;quot; as culminated will not detect that &amp;quot;for a minute&amp;quot; describes the duration of the run event. This is because durative for-PPs that modify culminated events denote the duration of the ensuing state, e.g., I left the room for a minute. (Vendler, 1967) Our analysis has revealed several insights regarding individual indicators. For example, both duration in-PP a</context>
</contexts>
<marker>Cardie, Howe, 1997</marker>
<rawString>C. Cardie and N. Howe. 1997. Improving minority class prediction using case-specific feature weights. In D. Fisher, editor, Proceedings of the Fourteenth International Conference on Machine Learning. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P K Chan</author>
<author>S J Stolfo</author>
</authors>
<title>Toward multistrategy parallel and distributed learning in sequence analysis.</title>
<date>1993</date>
<booktitle>In Proceedings of the First International Conference on Intelligent Systems for Molecular Biology.</booktitle>
<contexts>
<context position="11351" citStr="Chan and Stolfo, 1993" startWordPosition="1711" endWordPosition="1714">85; Koza, 1992). A pilot study showed no further improvement in accuracy or recall tradeoff by additional learning algorithms: Naive Bayes (Duda and 114 stativrty completedness corpus: 3,224 med reports 10 novels size: 1,159,891 846,913 parsed clauses: 97,973 75,289 training: 739 (634 eventsi 307 (196 culm) testing: 739 (619 events) 308 (195 culm) verbs in test set: 222 204 clauses excluded: be and have stative Table 4: Two classification problems on different data sets. Hart, 1973), Ripper (Cohen, 1995), ID3 (Quinlan, 1986), C4.5 (Quinlan, 1993), and metalearning to combine learning methods (Chan and Stolfo, 1993). 4.1 S tat ivity Our experiments are performed across a corpus of 3,224 medical discharge summaries. A medical discharge summary describes the symptoms, history, diagnosis, treatment and outcome of a patient&apos;s visit to the hospital. These reports were parsed with the English Slot Grammar (ESG) (McCord, 1990), resulting in 97,973 clauses that were parsed fully with no selfdiagnostic errors (ESO produced error messages on 12,877 of this corpus&apos; 51,079 complex sentences). Be and have, the two most popular verbs, covering 31.9% of the clauses in this corpus, are handled separately from all other </context>
</contexts>
<marker>Chan, Stolfo, 1993</marker>
<rawString>P.K. Chan and S.J. Stolfo. 1993. Toward multistrategy parallel and distributed learning in sequence analysis. In Proceedings of the First International Conference on Intelligent Systems for Molecular Biology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Cohen</author>
</authors>
<title>Fast effective rule induction.</title>
<date>1995</date>
<booktitle>In Proc. 12th Intl. Conf. Machine Learning,</booktitle>
<pages>115--123</pages>
<contexts>
<context position="11238" citStr="Cohen, 1995" startWordPosition="1695" endWordPosition="1696">iedman, 1977), log-linear regression (Santner and Duffy, 1989) and genetic programming (GP) (Cramer, 1985; Koza, 1992). A pilot study showed no further improvement in accuracy or recall tradeoff by additional learning algorithms: Naive Bayes (Duda and 114 stativrty completedness corpus: 3,224 med reports 10 novels size: 1,159,891 846,913 parsed clauses: 97,973 75,289 training: 739 (634 eventsi 307 (196 culm) testing: 739 (619 events) 308 (195 culm) verbs in test set: 222 204 clauses excluded: be and have stative Table 4: Two classification problems on different data sets. Hart, 1973), Ripper (Cohen, 1995), ID3 (Quinlan, 1986), C4.5 (Quinlan, 1993), and metalearning to combine learning methods (Chan and Stolfo, 1993). 4.1 S tat ivity Our experiments are performed across a corpus of 3,224 medical discharge summaries. A medical discharge summary describes the symptoms, history, diagnosis, treatment and outcome of a patient&apos;s visit to the hospital. These reports were parsed with the English Slot Grammar (ESG) (McCord, 1990), resulting in 97,973 clauses that were parsed fully with no selfdiagnostic errors (ESO produced error messages on 12,877 of this corpus&apos; 51,079 complex sentences). Be and have,</context>
</contexts>
<marker>Cohen, 1995</marker>
<rawString>W. Cohen. 1995. Fast effective rule induction. In Proc. 12th Intl. Conf. Machine Learning, pages 115-123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Cramer</author>
</authors>
<title>A representation for the adaptive generation of simple sequential programs.</title>
<date>1985</date>
<booktitle>Proceedings of the [First] International Conference on Genetic Algorithms. Lawrence Erlbaum.</booktitle>
<editor>In J. Grefenstette, editor,</editor>
<contexts>
<context position="10731" citStr="Cramer, 1985" startWordPosition="1616" endWordPosition="1617">s are each evaluated individually. A training set is used to select indicator value thresholds for classification. Then, we report the classification performance achieved by combining multiple indicators. In this case, the training set is used to optimize a model for combining indicators. In both cases, evaluation is performed over a separate test set of clauses. The combination of indicators is performed by four standard supervised learning algorithms: decision tree induction (Quinlan, 1986), CART (Friedman, 1977), log-linear regression (Santner and Duffy, 1989) and genetic programming (GP) (Cramer, 1985; Koza, 1992). A pilot study showed no further improvement in accuracy or recall tradeoff by additional learning algorithms: Naive Bayes (Duda and 114 stativrty completedness corpus: 3,224 med reports 10 novels size: 1,159,891 846,913 parsed clauses: 97,973 75,289 training: 739 (634 eventsi 307 (196 culm) testing: 739 (619 events) 308 (195 culm) verbs in test set: 222 204 clauses excluded: be and have stative Table 4: Two classification problems on different data sets. Hart, 1973), Ripper (Cohen, 1995), ID3 (Quinlan, 1986), C4.5 (Quinlan, 1993), and metalearning to combine learning methods (Ch</context>
</contexts>
<marker>Cramer, 1985</marker>
<rawString>N. Cramer. 1985. A representation for the adaptive generation of simple sequential programs. In J. Grefenstette, editor, Proceedings of the [First] International Conference on Genetic Algorithms. Lawrence Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dorr</author>
</authors>
<title>A two-level knowledge representation for machine translation: lexical semantics and tense/aspect.</title>
<date>1992</date>
<booktitle>In James Pustejovsky and Sabine Bergler, editors, Lexical Semantics and Knowledge Representation.</booktitle>
<publisher>Springer Verlag,</publisher>
<location>Berlin.</location>
<contexts>
<context position="1546" citStr="Dorr, 1992" startWordPosition="219" endWordPosition="220">ins, e.g., the distinction between procedure and diagnosis in the medical domain. Aspectual classification further distinguishes events according to completedness (i.e., telicity), which determines whether an event reaches a culmination point in time at which a new state is introduced. For example, &amp;quot;I made a fire&amp;quot; is culminated, since a new state is introduced — something is made, whereas, &amp;quot;I gazed at the sunset&amp;quot; is non-culminated. Aspectual classification is necessary for interpreting temporal modifiers and assessing temporal entailments (Vendler, 1967; Dowty, 1979; Moens and Steedman, 1988; Dorr, 1992), and is therefore a necessary component for applications that perform certain natural language interpretation, natural language generation, summarization, information retrieval, and machine translation tasks. Aspect introduces a large-scale, domaindependent lexical classification problem. Although an aspectual lexicon of verbs would suffice to classify many clauses by their main verb only, a verb&apos;s primary class is often domaindependent (Siegel, 1998b). Therefore, it is necessary to produce a specialized lexicon for each domain. Most approaches to automatically categorizing words measure co-o</context>
<context position="4382" citStr="Dorr, 1992" startWordPosition="627" endWordPosition="628"> in Natural Language Table 1 summarizes the three aspectual distinctions, which compose five aspectual categories. In addition to the two distinctions described in the previous section, atomicity distinguishes events according to whether they have a time duration (punctual versus extended). Therefore, four classes of events are derived: culmination, culminated process, process, and point. These aspectual distinctions are defined formally by Dowty (1979). Several researchers have developed models that incorporate aspectual class to assess temporal constraints between clauses (Passonneau, 1988; Dorr, 1992). For example, stativity must be identified to detect temporal constraints between clauses connected with when, e.g., in interpreting (1), (1) She had good strength when objectively tested. the following temporal relationship holds: have test However, in interpreting (2), (2) Phototherapy was discontinued when the bilirubin came down to 13. the temporal relationship is different: come discontinue These aspectual distinctions are motivated by a series of entailment constraints. In particular, certain lexico-syntactic features of a clause, such as temporal adjuncts and tense, are constrained by </context>
</contexts>
<marker>Dorr, 1992</marker>
<rawString>Dorr. 1992. A two-level knowledge representation for machine translation: lexical semantics and tense/aspect. In James Pustejovsky and Sabine Bergler, editors, Lexical Semantics and Knowledge Representation. Springer Verlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Dowty</author>
</authors>
<title>Word Meaning and</title>
<date>1979</date>
<location>Dordrecht, W.</location>
<contexts>
<context position="1507" citStr="Dowty, 1979" startWordPosition="213" endWordPosition="214"> to primitive distinctions in many domains, e.g., the distinction between procedure and diagnosis in the medical domain. Aspectual classification further distinguishes events according to completedness (i.e., telicity), which determines whether an event reaches a culmination point in time at which a new state is introduced. For example, &amp;quot;I made a fire&amp;quot; is culminated, since a new state is introduced — something is made, whereas, &amp;quot;I gazed at the sunset&amp;quot; is non-culminated. Aspectual classification is necessary for interpreting temporal modifiers and assessing temporal entailments (Vendler, 1967; Dowty, 1979; Moens and Steedman, 1988; Dorr, 1992), and is therefore a necessary component for applications that perform certain natural language interpretation, natural language generation, summarization, information retrieval, and machine translation tasks. Aspect introduces a large-scale, domaindependent lexical classification problem. Although an aspectual lexicon of verbs would suffice to classify many clauses by their main verb only, a verb&apos;s primary class is often domaindependent (Siegel, 1998b). Therefore, it is necessary to produce a specialized lexicon for each domain. Most approaches to automa</context>
<context position="4228" citStr="Dowty (1979)" startWordPosition="607" endWordPosition="608">teedman, 1988). EVENTS STATES punctual extended understand Culm CULM CULM PROCESS recognize build a house Non- POINT PROCESS Culm hiccup run, swim 2 Aspect in Natural Language Table 1 summarizes the three aspectual distinctions, which compose five aspectual categories. In addition to the two distinctions described in the previous section, atomicity distinguishes events according to whether they have a time duration (punctual versus extended). Therefore, four classes of events are derived: culmination, culminated process, process, and point. These aspectual distinctions are defined formally by Dowty (1979). Several researchers have developed models that incorporate aspectual class to assess temporal constraints between clauses (Passonneau, 1988; Dorr, 1992). For example, stativity must be identified to detect temporal constraints between clauses connected with when, e.g., in interpreting (1), (1) She had good strength when objectively tested. the following temporal relationship holds: have test However, in interpreting (2), (2) Phototherapy was discontinued when the bilirubin came down to 13. the temporal relationship is different: come discontinue These aspectual distinctions are motivated by </context>
<context position="9609" citStr="Dowty, 1979" startWordPosition="1450" endWordPosition="1451">cess culminated process) In this example, for a week can only modify an extended event, requiring the first coercion. In addition, this for-PP also makes an event culminated, causing the second transformation. • Some aspectual markers such as the pseudo-cleft and manner adverbs test for intentional events, and therefore are not compatible with all events, e.g., &apos;4/ died diligently.&amp;quot; • The progressive indicator&apos;s predictiveness for stativity is compromised by the fact that many location verbs can appear with the progressive, even in their stative sense, e.g. &amp;quot;The book was lying on the shelf.&amp;quot; (Dowty, 1979) • Several indicators measure phenomena that are not linguistically constrained by any aspectual category, e.g., the present tense, frequency and not/never indicators. 4 Method and Results In this section, we evaluate the set of fourteen linguistic indicators for two aspectual distinctions: stativity and completedness. Evaluation is over corpora of medical reports and novels, respectively. This data is summarized in Table 4 (available at www. cs . co lumbia.edui-evs/VerbDat a). First, linguistic indicators are each evaluated individually. A training set is used to select indicator value thresh</context>
</contexts>
<marker>Dowty, 1979</marker>
<rawString>D.R. Dowty. 1979. Word Meaning and Montague Grammar. D. Reidel, Dordrecht, W. Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duda</author>
<author>P E Hart</author>
</authors>
<title>Pattern Classification and Scene Analysis.</title>
<date>1973</date>
<publisher>Wiley,</publisher>
<location>New York.</location>
<marker>Duda, Hart, 1973</marker>
<rawString>R. 0. Duda and P.E. Hart. 1973. Pattern Classification and Scene Analysis. Wiley, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Friedman</author>
</authors>
<title>A recursive partitioning decision rule for non-parametric classification.</title>
<date>1977</date>
<journal>IEEE Transactions on Computers.</journal>
<contexts>
<context position="10639" citStr="Friedman, 1977" startWordPosition="1603" endWordPosition="1604">d in Table 4 (available at www. cs . co lumbia.edui-evs/VerbDat a). First, linguistic indicators are each evaluated individually. A training set is used to select indicator value thresholds for classification. Then, we report the classification performance achieved by combining multiple indicators. In this case, the training set is used to optimize a model for combining indicators. In both cases, evaluation is performed over a separate test set of clauses. The combination of indicators is performed by four standard supervised learning algorithms: decision tree induction (Quinlan, 1986), CART (Friedman, 1977), log-linear regression (Santner and Duffy, 1989) and genetic programming (GP) (Cramer, 1985; Koza, 1992). A pilot study showed no further improvement in accuracy or recall tradeoff by additional learning algorithms: Naive Bayes (Duda and 114 stativrty completedness corpus: 3,224 med reports 10 novels size: 1,159,891 846,913 parsed clauses: 97,973 75,289 training: 739 (634 eventsi 307 (196 culm) testing: 739 (619 events) 308 (195 culm) verbs in test set: 222 204 clauses excluded: be and have stative Table 4: Two classification problems on different data sets. Hart, 1973), Ripper (Cohen, 1995),</context>
</contexts>
<marker>Friedman, 1977</marker>
<rawString>J.H. Friedman. 1977. A recursive partitioning decision rule for non-parametric classification. IEEE Transactions on Computers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hatzivassiloglou</author>
<author>K McKeown</author>
</authors>
<title>Towards the automatic identification of adjectival scales: clustering adjectives according to meaning.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the ACL,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="2241" citStr="Hatzivassiloglou and McKeown, 1993" startWordPosition="314" endWordPosition="318">t perform certain natural language interpretation, natural language generation, summarization, information retrieval, and machine translation tasks. Aspect introduces a large-scale, domaindependent lexical classification problem. Although an aspectual lexicon of verbs would suffice to classify many clauses by their main verb only, a verb&apos;s primary class is often domaindependent (Siegel, 1998b). Therefore, it is necessary to produce a specialized lexicon for each domain. Most approaches to automatically categorizing words measure co-occurrences between open-class lexical items (Schfitze, 1992; Hatzivassiloglou and McKeown, 1993; Pereira et al., 1993). This approach is limited since cooccurrences between open-class lexical items is sparse, and is not specialized for particular semantic distinctions such as aspect. In this paper, we describe an expandable framework to classify verbs with linguisticallyspecialized numerical indicators. Each linguistic indicator measures the frequency of a lexicosyntactic marker, e.g. the perfect tense. These markers are linguistically related to aspect, so the indicators are specialized for aspectual classification in particular. We perform an evaluation of fourteen linguistic indicato</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1993</marker>
<rawString>V. Hatzivassiloglou and K. McKeown. 1993. Towards the automatic identification of adjectival scales: clustering adjectives according to meaning. In Proceedings of the 31st Annual Meeting of the ACL, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Klavans</author>
<author>M Chodorow</author>
</authors>
<title>Degrees of stativity: the lexical representation of verb aspect.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th International Conference on Computation Linguistics.</booktitle>
<contexts>
<context position="6569" citStr="Klavans and Chodorow (1992)" startWordPosition="974" endWordPosition="977">trasts with, (7) *He has cowered down. (non-culm.) 3 Linguistic Indicators The best way to exploit aspectual markers is not obvious, since, while the presence of a marker in a particular clause indicates a constraint on the aspectual class of the clause, the absence thereof does not place any constraint. Therefore, as with most statistical methods for natural language, the linguistic constraints associated with markers are best exploited by a system that measures co-occurrence frequencies. For example, a verb that appears more frequently in the progressive is more likely to describe an event. Klavans and Chodorow (1992) pioneered the application of statistical corpus analysis to aspectual classification by ranking verbs according to the frequencies with which they occur with certain aspectual markers. Table 3 lists the linguistic indicators evaluated for aspectual classification. Each indicaCulm Event Culm Event or State 113 Ling Indicator Example Clause frequency &amp;quot;not&amp;quot; or &amp;quot;never&amp;quot; temporal adverb no subject past/pres partic duration in-PP perfect present tense progressive manner adverb evaluation adverb past tense duration for-PP continuous adverb (not applicable) She can not explain why. I saw to it then. H</context>
</contexts>
<marker>Klavans, Chodorow, 1992</marker>
<rawString>J.L. Klavans and M. Chodorow. 1992. Degrees of stativity: the lexical representation of verb aspect. In Proceedings of the 14th International Conference on Computation Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Klavans</author>
</authors>
<title>Linguistic tests over large corpora: aspectual classes in the lexicon.</title>
<date>1994</date>
<tech>Technical report,</tech>
<institution>Columbia University Dept. of Computer Science.</institution>
<note>unpublished manuscript.</note>
<marker>Klavans, 1994</marker>
<rawString>J.L. Klavans. 1994. Linguistic tests over large corpora: aspectual classes in the lexicon. Technical report, Columbia University Dept. of Computer Science. unpublished manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Koza</author>
</authors>
<title>Genetic Programming: On the programming of computers by means of natural selection.</title>
<date>1992</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="10744" citStr="Koza, 1992" startWordPosition="1618" endWordPosition="1619">luated individually. A training set is used to select indicator value thresholds for classification. Then, we report the classification performance achieved by combining multiple indicators. In this case, the training set is used to optimize a model for combining indicators. In both cases, evaluation is performed over a separate test set of clauses. The combination of indicators is performed by four standard supervised learning algorithms: decision tree induction (Quinlan, 1986), CART (Friedman, 1977), log-linear regression (Santner and Duffy, 1989) and genetic programming (GP) (Cramer, 1985; Koza, 1992). A pilot study showed no further improvement in accuracy or recall tradeoff by additional learning algorithms: Naive Bayes (Duda and 114 stativrty completedness corpus: 3,224 med reports 10 novels size: 1,159,891 846,913 parsed clauses: 97,973 75,289 training: 739 (634 eventsi 307 (196 culm) testing: 739 (619 events) 308 (195 culm) verbs in test set: 222 204 clauses excluded: be and have stative Table 4: Two classification problems on different data sets. Hart, 1973), Ripper (Cohen, 1995), ID3 (Quinlan, 1986), C4.5 (Quinlan, 1993), and metalearning to combine learning methods (Chan and Stolfo</context>
</contexts>
<marker>Koza, 1992</marker>
<rawString>J.R. Koza. 1992. Genetic Programming: On the programming of computers by means of natural selection. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M C McCord</author>
</authors>
<date>1990</date>
<booktitle>International Symposium on Natural Language and Logic.</booktitle>
<editor>SLOT GRAMMAR. In R. Studer, editor,</editor>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="11661" citStr="McCord, 1990" startWordPosition="1764" endWordPosition="1765">39 (619 events) 308 (195 culm) verbs in test set: 222 204 clauses excluded: be and have stative Table 4: Two classification problems on different data sets. Hart, 1973), Ripper (Cohen, 1995), ID3 (Quinlan, 1986), C4.5 (Quinlan, 1993), and metalearning to combine learning methods (Chan and Stolfo, 1993). 4.1 S tat ivity Our experiments are performed across a corpus of 3,224 medical discharge summaries. A medical discharge summary describes the symptoms, history, diagnosis, treatment and outcome of a patient&apos;s visit to the hospital. These reports were parsed with the English Slot Grammar (ESG) (McCord, 1990), resulting in 97,973 clauses that were parsed fully with no selfdiagnostic errors (ESO produced error messages on 12,877 of this corpus&apos; 51,079 complex sentences). Be and have, the two most popular verbs, covering 31.9% of the clauses in this corpus, are handled separately from all other verbs. Clauses with be as their main verb, comprising 23.9% of the corpus, always denote a state. Clauses with have as their main verb, composing 8.0% of the corpus, are highly ambiguous, and have been addressed separately by considering the direct object of such clauses (Siegel, 1998a). 4.1.1 Manual Marking </context>
</contexts>
<marker>McCord, 1990</marker>
<rawString>M.C. McCord. 1990. SLOT GRAMMAR. In R. Studer, editor, International Symposium on Natural Language and Logic. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Moens</author>
<author>M Steedman</author>
</authors>
<title>Temporal ontology and temporal reference.</title>
<date>1988</date>
<journal>Computational Linguistics,</journal>
<volume>14</volume>
<issue>2</issue>
<contexts>
<context position="1533" citStr="Moens and Steedman, 1988" startWordPosition="215" endWordPosition="218"> distinctions in many domains, e.g., the distinction between procedure and diagnosis in the medical domain. Aspectual classification further distinguishes events according to completedness (i.e., telicity), which determines whether an event reaches a culmination point in time at which a new state is introduced. For example, &amp;quot;I made a fire&amp;quot; is culminated, since a new state is introduced — something is made, whereas, &amp;quot;I gazed at the sunset&amp;quot; is non-culminated. Aspectual classification is necessary for interpreting temporal modifiers and assessing temporal entailments (Vendler, 1967; Dowty, 1979; Moens and Steedman, 1988; Dorr, 1992), and is therefore a necessary component for applications that perform certain natural language interpretation, natural language generation, summarization, information retrieval, and machine translation tasks. Aspect introduces a large-scale, domaindependent lexical classification problem. Although an aspectual lexicon of verbs would suffice to classify many clauses by their main verb only, a verb&apos;s primary class is often domaindependent (Siegel, 1998b). Therefore, it is necessary to produce a specialized lexicon for each domain. Most approaches to automatically categorizing words</context>
<context position="3630" citStr="Moens and Steedman, 1988" startWordPosition="520" endWordPosition="523">tual distinctions: stativity and completedness. Moreover, our analysis reveals a predictive value for several indicators that have not previously been discovered to correlate with aspect in the linguistics literature. The following section further describes aspect, and introduces linguistic insights that are exploited by linguistic indicators. The next section describes the set of linguistic indicators evaluated in this paper. Then, our experimental method and results are given, followed by a discussion and conclusions. 112 Table 1: Aspectual classes. This table comes from Moens and Steedman (Moens and Steedman, 1988). EVENTS STATES punctual extended understand Culm CULM CULM PROCESS recognize build a house Non- POINT PROCESS Culm hiccup run, swim 2 Aspect in Natural Language Table 1 summarizes the three aspectual distinctions, which compose five aspectual categories. In addition to the two distinctions described in the previous section, atomicity distinguishes events according to whether they have a time duration (punctual versus extended). Therefore, four classes of events are derived: culmination, culminated process, process, and point. These aspectual distinctions are defined formally by Dowty (1979). </context>
<context position="8891" citStr="Moens and Steedman, 1988" startWordPosition="1334" endWordPosition="1337"> than using them individually. While individual indicators have predictive value, they are predictively incomplete. This incompleteness has been illustrated empirically by showing that some indicators help for only a subset of verbs (Siegel, 1998b). Such incompleteness is due in part to sparsity and noise of data when computing indicator values over a corpus with limited size and some parsing errors. However, this incompleteness is also a consequence of the linguistic characteristics of various indicators. For example: • Aspectual coercion such as iteration compromises indicator measurements (Moens and Steedman, 1988). For example, a punctual event appears with the progressive in, &amp;quot;She was sneezing for a week.&amp;quot; (point process culminated process) In this example, for a week can only modify an extended event, requiring the first coercion. In addition, this for-PP also makes an event culminated, causing the second transformation. • Some aspectual markers such as the pseudo-cleft and manner adverbs test for intentional events, and therefore are not compatible with all events, e.g., &apos;4/ died diligently.&amp;quot; • The progressive indicator&apos;s predictiveness for stativity is compromised by the fact that many location ver</context>
</contexts>
<marker>Moens, Steedman, 1988</marker>
<rawString>M. Moens and M. Steedman. 1988. Temporal ontology and temporal reference. Computational Linguistics, 14(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Passonneau</author>
</authors>
<title>A computational model of the semantics of tense and aspect.</title>
<date>1988</date>
<journal>Computational Linguistics,</journal>
<volume>14</volume>
<issue>2</issue>
<contexts>
<context position="4369" citStr="Passonneau, 1988" startWordPosition="625" endWordPosition="626">run, swim 2 Aspect in Natural Language Table 1 summarizes the three aspectual distinctions, which compose five aspectual categories. In addition to the two distinctions described in the previous section, atomicity distinguishes events according to whether they have a time duration (punctual versus extended). Therefore, four classes of events are derived: culmination, culminated process, process, and point. These aspectual distinctions are defined formally by Dowty (1979). Several researchers have developed models that incorporate aspectual class to assess temporal constraints between clauses (Passonneau, 1988; Dorr, 1992). For example, stativity must be identified to detect temporal constraints between clauses connected with when, e.g., in interpreting (1), (1) She had good strength when objectively tested. the following temporal relationship holds: have test However, in interpreting (2), (2) Phototherapy was discontinued when the bilirubin came down to 13. the temporal relationship is different: come discontinue These aspectual distinctions are motivated by a series of entailment constraints. In particular, certain lexico-syntactic features of a clause, such as temporal adjuncts and tense, are co</context>
<context position="17588" citStr="Passonneau (1988)" startWordPosition="2694" endWordPosition="2695">pus of ten novels comprising 846,913 words. These novels were parsed with ESC, resulting in 75,289 fully-parsed clauses (22,505 of 59,816 sentences produced errors). 4.2.1 Manual Marking 884 clauses from the parsed corpus were manually marked according to completedness. Of these, 109 were rejected because of parsing problems, and 160 rejected because they described states. The remaining 615 clauses were divided into training and test sets such that the distribution of classes was equal. The baseline method in this case achieves 63.3% accuracy. The linguistic test was selected for this task by Passonneau (1988): If a clause in the past progressive necessarily entails the past tense reading, the clause describes a non-culminated event. For example, We were talking just like men (non-culm.) entails that We talked just like men, but The woman was building a house (culm.) does not necessarily entail that The woman built a house. Cross-checking between linguists shows high agreement. In particular, in a pilot study manually annotating 89 clauses from this corpus according to stativity, two linguists agreed 81 times. Of 57 clauses agreed to be events, 46 had agreement with respect to completedness. The ve</context>
</contexts>
<marker>Passonneau, 1988</marker>
<rawString>R.J. Passonneau. 1988. A computational model of the semantics of tense and aspect. Computational Linguistics, 14(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pereira</author>
<author>N Tishby</author>
<author>L Lee</author>
</authors>
<title>Distributional clustering of english words.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Conference of the ACL,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio.</location>
<contexts>
<context position="2264" citStr="Pereira et al., 1993" startWordPosition="319" endWordPosition="322">nterpretation, natural language generation, summarization, information retrieval, and machine translation tasks. Aspect introduces a large-scale, domaindependent lexical classification problem. Although an aspectual lexicon of verbs would suffice to classify many clauses by their main verb only, a verb&apos;s primary class is often domaindependent (Siegel, 1998b). Therefore, it is necessary to produce a specialized lexicon for each domain. Most approaches to automatically categorizing words measure co-occurrences between open-class lexical items (Schfitze, 1992; Hatzivassiloglou and McKeown, 1993; Pereira et al., 1993). This approach is limited since cooccurrences between open-class lexical items is sparse, and is not specialized for particular semantic distinctions such as aspect. In this paper, we describe an expandable framework to classify verbs with linguisticallyspecialized numerical indicators. Each linguistic indicator measures the frequency of a lexicosyntactic marker, e.g. the perfect tense. These markers are linguistically related to aspect, so the indicators are specialized for aspectual classification in particular. We perform an evaluation of fourteen linguistic indicators over unrestricted se</context>
</contexts>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>F. Pereira, N. Tishby, and L. Lee. 1993. Distributional clustering of english words. In Proceedings of the 31st Conference of the ACL, Columbus, Ohio. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Quinlan</author>
</authors>
<title>Induction of decision trees.</title>
<date>1986</date>
<booktitle>Machine Learning,</booktitle>
<pages>1--1</pages>
<contexts>
<context position="10616" citStr="Quinlan, 1986" startWordPosition="1600" endWordPosition="1601">This data is summarized in Table 4 (available at www. cs . co lumbia.edui-evs/VerbDat a). First, linguistic indicators are each evaluated individually. A training set is used to select indicator value thresholds for classification. Then, we report the classification performance achieved by combining multiple indicators. In this case, the training set is used to optimize a model for combining indicators. In both cases, evaluation is performed over a separate test set of clauses. The combination of indicators is performed by four standard supervised learning algorithms: decision tree induction (Quinlan, 1986), CART (Friedman, 1977), log-linear regression (Santner and Duffy, 1989) and genetic programming (GP) (Cramer, 1985; Koza, 1992). A pilot study showed no further improvement in accuracy or recall tradeoff by additional learning algorithms: Naive Bayes (Duda and 114 stativrty completedness corpus: 3,224 med reports 10 novels size: 1,159,891 846,913 parsed clauses: 97,973 75,289 training: 739 (634 eventsi 307 (196 culm) testing: 739 (619 events) 308 (195 culm) verbs in test set: 222 204 clauses excluded: be and have stative Table 4: Two classification problems on different data sets. Hart, 1973)</context>
</contexts>
<marker>Quinlan, 1986</marker>
<rawString>J.R. Quinlan. 1986. Induction of decision trees. Machine Learning, 1(1):81-106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Quinlan</author>
</authors>
<title>C4.5: Programs for Machine Learning.</title>
<date>1993</date>
<publisher>Morgan Kaufmann,</publisher>
<location>San Mateo, CA.</location>
<contexts>
<context position="11281" citStr="Quinlan, 1993" startWordPosition="1702" endWordPosition="1703">tner and Duffy, 1989) and genetic programming (GP) (Cramer, 1985; Koza, 1992). A pilot study showed no further improvement in accuracy or recall tradeoff by additional learning algorithms: Naive Bayes (Duda and 114 stativrty completedness corpus: 3,224 med reports 10 novels size: 1,159,891 846,913 parsed clauses: 97,973 75,289 training: 739 (634 eventsi 307 (196 culm) testing: 739 (619 events) 308 (195 culm) verbs in test set: 222 204 clauses excluded: be and have stative Table 4: Two classification problems on different data sets. Hart, 1973), Ripper (Cohen, 1995), ID3 (Quinlan, 1986), C4.5 (Quinlan, 1993), and metalearning to combine learning methods (Chan and Stolfo, 1993). 4.1 S tat ivity Our experiments are performed across a corpus of 3,224 medical discharge summaries. A medical discharge summary describes the symptoms, history, diagnosis, treatment and outcome of a patient&apos;s visit to the hospital. These reports were parsed with the English Slot Grammar (ESG) (McCord, 1990), resulting in 97,973 clauses that were parsed fully with no selfdiagnostic errors (ESO produced error messages on 12,877 of this corpus&apos; 51,079 complex sentences). Be and have, the two most popular verbs, covering 31.9%</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>J.R. Quinlan. 1993. C4.5: Programs for Machine Learning. Morgan Kaufmann, San Mateo, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T J Santner</author>
<author>D E Duffy</author>
</authors>
<title>The Statistical Analysis of Discrete Data.</title>
<date>1989</date>
<publisher>Springer-Verlag,</publisher>
<location>New York.</location>
<contexts>
<context position="10688" citStr="Santner and Duffy, 1989" startWordPosition="1607" endWordPosition="1610">lumbia.edui-evs/VerbDat a). First, linguistic indicators are each evaluated individually. A training set is used to select indicator value thresholds for classification. Then, we report the classification performance achieved by combining multiple indicators. In this case, the training set is used to optimize a model for combining indicators. In both cases, evaluation is performed over a separate test set of clauses. The combination of indicators is performed by four standard supervised learning algorithms: decision tree induction (Quinlan, 1986), CART (Friedman, 1977), log-linear regression (Santner and Duffy, 1989) and genetic programming (GP) (Cramer, 1985; Koza, 1992). A pilot study showed no further improvement in accuracy or recall tradeoff by additional learning algorithms: Naive Bayes (Duda and 114 stativrty completedness corpus: 3,224 med reports 10 novels size: 1,159,891 846,913 parsed clauses: 97,973 75,289 training: 739 (634 eventsi 307 (196 culm) testing: 739 (619 events) 308 (195 culm) verbs in test set: 222 204 clauses excluded: be and have stative Table 4: Two classification problems on different data sets. Hart, 1973), Ripper (Cohen, 1995), ID3 (Quinlan, 1986), C4.5 (Quinlan, 1993), and m</context>
</contexts>
<marker>Santner, Duffy, 1989</marker>
<rawString>T.J. Santner and D.E. Duffy. 1989. The Statistical Analysis of Discrete Data. Springer-Verlag, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schfitze</author>
</authors>
<title>Dimensions of meaning.</title>
<date>1992</date>
<booktitle>In Proceedings of Supercomputing.</booktitle>
<contexts>
<context position="2205" citStr="Schfitze, 1992" startWordPosition="312" endWordPosition="313">applications that perform certain natural language interpretation, natural language generation, summarization, information retrieval, and machine translation tasks. Aspect introduces a large-scale, domaindependent lexical classification problem. Although an aspectual lexicon of verbs would suffice to classify many clauses by their main verb only, a verb&apos;s primary class is often domaindependent (Siegel, 1998b). Therefore, it is necessary to produce a specialized lexicon for each domain. Most approaches to automatically categorizing words measure co-occurrences between open-class lexical items (Schfitze, 1992; Hatzivassiloglou and McKeown, 1993; Pereira et al., 1993). This approach is limited since cooccurrences between open-class lexical items is sparse, and is not specialized for particular semantic distinctions such as aspect. In this paper, we describe an expandable framework to classify verbs with linguisticallyspecialized numerical indicators. Each linguistic indicator measures the frequency of a lexicosyntactic marker, e.g. the perfect tense. These markers are linguistically related to aspect, so the indicators are specialized for aspectual classification in particular. We perform an evalua</context>
</contexts>
<marker>Schfitze, 1992</marker>
<rawString>H. Schfitze. 1992. Dimensions of meaning. In Proceedings of Supercomputing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E V Siegel</author>
<author>K R McKeown</author>
</authors>
<title>Gathering statistics to aspectually classify sentences with a genetic algorithm. In</title>
<date>1996</date>
<booktitle>Proceedings of the Second International Conference on New Methods in Language Processing,</booktitle>
<editor>K. Oflazer and H. Somers, editors,</editor>
<publisher>Bilkent University.</publisher>
<location>Ankara, Turkey,</location>
<marker>Siegel, McKeown, 1996</marker>
<rawString>E.V. Siegel and K.R. McKeown. 1996. Gathering statistics to aspectually classify sentences with a genetic algorithm. In K. Oflazer and H. Somers, editors, Proceedings of the Second International Conference on New Methods in Language Processing, Ankara, Turkey, Sept. Bilkent University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E V Siegel</author>
</authors>
<title>Learning methods for combining linguistic indicators to classify verbs.</title>
<date>1997</date>
<booktitle>In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Providence, RI,</location>
<marker>Siegel, 1997</marker>
<rawString>E.V. Siegel. 1997. Learning methods for combining linguistic indicators to classify verbs. In Proceedings of the Second Conference on Empirical Methods in Natural Language Processing, Providence, RI, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E V Siegel</author>
</authors>
<title>Disambiguating verbs with the wordnet category of the direct object.</title>
<date>1998</date>
<booktitle>In Procedings of the Usage of WordNet in Natural Language Processing Systems Workshop,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="2001" citStr="Siegel, 1998" startWordPosition="284" endWordPosition="285">cation is necessary for interpreting temporal modifiers and assessing temporal entailments (Vendler, 1967; Dowty, 1979; Moens and Steedman, 1988; Dorr, 1992), and is therefore a necessary component for applications that perform certain natural language interpretation, natural language generation, summarization, information retrieval, and machine translation tasks. Aspect introduces a large-scale, domaindependent lexical classification problem. Although an aspectual lexicon of verbs would suffice to classify many clauses by their main verb only, a verb&apos;s primary class is often domaindependent (Siegel, 1998b). Therefore, it is necessary to produce a specialized lexicon for each domain. Most approaches to automatically categorizing words measure co-occurrences between open-class lexical items (Schfitze, 1992; Hatzivassiloglou and McKeown, 1993; Pereira et al., 1993). This approach is limited since cooccurrences between open-class lexical items is sparse, and is not specialized for particular semantic distinctions such as aspect. In this paper, we describe an expandable framework to classify verbs with linguisticallyspecialized numerical indicators. Each linguistic indicator measures the frequency</context>
<context position="8123" citStr="Siegel (1998" startWordPosition="1224" endWordPosition="1225">each verb. The first indicator, frequency, is simply the frequency with which each verb occurs over the entire corpus. The remaining 13 indicators measure how frequently each verb occurs in a clause with the named linguistic marker. For example, the next three indicators listed measure the frequency with which verbs 1) are modified by not or never, 2) are modified by a temporal adverb such as then or frequently, and 3) have no deep subject (e.g., passive phrases such as, &amp;quot;She was admitted to the hospital&amp;quot;). Further details regarding these indicators and their linguistic motivation is given by Siegel (1998b). There are several reasons to expect superior classification performance when employing multiple linguistic indicators in combination rather than using them individually. While individual indicators have predictive value, they are predictively incomplete. This incompleteness has been illustrated empirically by showing that some indicators help for only a subset of verbs (Siegel, 1998b). Such incompleteness is due in part to sparsity and noise of data when computing indicator values over a corpus with limited size and some parsing errors. However, this incompleteness is also a consequence of</context>
<context position="12236" citStr="Siegel, 1998" startWordPosition="1860" endWordPosition="1861">ish Slot Grammar (ESG) (McCord, 1990), resulting in 97,973 clauses that were parsed fully with no selfdiagnostic errors (ESO produced error messages on 12,877 of this corpus&apos; 51,079 complex sentences). Be and have, the two most popular verbs, covering 31.9% of the clauses in this corpus, are handled separately from all other verbs. Clauses with be as their main verb, comprising 23.9% of the corpus, always denote a state. Clauses with have as their main verb, composing 8.0% of the corpus, are highly ambiguous, and have been addressed separately by considering the direct object of such clauses (Siegel, 1998a). 4.1.1 Manual Marking 1,851 clauses from the parsed corpus were manually marked according to stativity. As a linguistic test for marking, each clause was tested for readability with &amp;quot;What happened was... &amp;quot;1 A comparison between human markers for this test performed over a different corpus is reported below in Section 4.2.1. Of these, 373 &apos;Manual labeling followed a strict set of linguisticallymotivated guidelines, e.g., negations were ignored (Siegel, 1998b). Stative Event T-test Mean Mean P-value 932.89 667.57 0.0000 4.44% 1.56% 0.0000 1.00% 2.70% 0.0000 36.05% 57.56% 0.0000 20.98% 15.37% </context>
<context position="23345" citStr="Siegel, 1998" startWordPosition="3601" endWordPosition="3602">100.0% 63.3% 0.0% 100.0% b12 70.8% 94.9% 69.8% 29.2% 76.7% 117 completedness, nor does it achieve as wide a recall tradeff for both stativity and cornpletedness. These results are indicated as the second baselines (&amp;quot;b12&amp;quot;) in tables 6 and 8, respectively. • Scalar values assigned to each verb allow the tradeoff between recall and precision to be selected for particular applications by selecting the classification threshold. For example, in a separate study, optimizing for F-measure resulted in a more dramatic tradeoff in recall values as compared to those attained when optimizing for accuracy (Siegel, 1998b). Moreover, such scalar values can provide input to systems that perform reasoning on fuzzy or uncertainty knowledge. • This framework is expandable since additional indicators can be introduced by measuring the frequencies of additional aspectual markers. Furthermore, indicators measured over multiple clausal constituents, e.g., main verb-object pairs, alleviate verb ambiguity and sparsity and improve classification performance (Siegel, 1998b). 6 Conclusions We have developed a full-scale system for aspectual classification with multiple linguistic indicators. Once trained, this system can </context>
</contexts>
<marker>Siegel, 1998</marker>
<rawString>E.V. Siegel. 1998a. Disambiguating verbs with the wordnet category of the direct object. In Procedings of the Usage of WordNet in Natural Language Processing Systems Workshop, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E V Siegel</author>
</authors>
<title>Linguistic Indicators for Language Understanding: Using machine learning methods to combine corpus-based indicators for aspectual classification of clauses.</title>
<date>1998</date>
<tech>Ph.D. thesis,</tech>
<institution>Columbia University.</institution>
<contexts>
<context position="2001" citStr="Siegel, 1998" startWordPosition="284" endWordPosition="285">cation is necessary for interpreting temporal modifiers and assessing temporal entailments (Vendler, 1967; Dowty, 1979; Moens and Steedman, 1988; Dorr, 1992), and is therefore a necessary component for applications that perform certain natural language interpretation, natural language generation, summarization, information retrieval, and machine translation tasks. Aspect introduces a large-scale, domaindependent lexical classification problem. Although an aspectual lexicon of verbs would suffice to classify many clauses by their main verb only, a verb&apos;s primary class is often domaindependent (Siegel, 1998b). Therefore, it is necessary to produce a specialized lexicon for each domain. Most approaches to automatically categorizing words measure co-occurrences between open-class lexical items (Schfitze, 1992; Hatzivassiloglou and McKeown, 1993; Pereira et al., 1993). This approach is limited since cooccurrences between open-class lexical items is sparse, and is not specialized for particular semantic distinctions such as aspect. In this paper, we describe an expandable framework to classify verbs with linguisticallyspecialized numerical indicators. Each linguistic indicator measures the frequency</context>
<context position="8123" citStr="Siegel (1998" startWordPosition="1224" endWordPosition="1225">each verb. The first indicator, frequency, is simply the frequency with which each verb occurs over the entire corpus. The remaining 13 indicators measure how frequently each verb occurs in a clause with the named linguistic marker. For example, the next three indicators listed measure the frequency with which verbs 1) are modified by not or never, 2) are modified by a temporal adverb such as then or frequently, and 3) have no deep subject (e.g., passive phrases such as, &amp;quot;She was admitted to the hospital&amp;quot;). Further details regarding these indicators and their linguistic motivation is given by Siegel (1998b). There are several reasons to expect superior classification performance when employing multiple linguistic indicators in combination rather than using them individually. While individual indicators have predictive value, they are predictively incomplete. This incompleteness has been illustrated empirically by showing that some indicators help for only a subset of verbs (Siegel, 1998b). Such incompleteness is due in part to sparsity and noise of data when computing indicator values over a corpus with limited size and some parsing errors. However, this incompleteness is also a consequence of</context>
<context position="12236" citStr="Siegel, 1998" startWordPosition="1860" endWordPosition="1861">ish Slot Grammar (ESG) (McCord, 1990), resulting in 97,973 clauses that were parsed fully with no selfdiagnostic errors (ESO produced error messages on 12,877 of this corpus&apos; 51,079 complex sentences). Be and have, the two most popular verbs, covering 31.9% of the clauses in this corpus, are handled separately from all other verbs. Clauses with be as their main verb, comprising 23.9% of the corpus, always denote a state. Clauses with have as their main verb, composing 8.0% of the corpus, are highly ambiguous, and have been addressed separately by considering the direct object of such clauses (Siegel, 1998a). 4.1.1 Manual Marking 1,851 clauses from the parsed corpus were manually marked according to stativity. As a linguistic test for marking, each clause was tested for readability with &amp;quot;What happened was... &amp;quot;1 A comparison between human markers for this test performed over a different corpus is reported below in Section 4.2.1. Of these, 373 &apos;Manual labeling followed a strict set of linguisticallymotivated guidelines, e.g., negations were ignored (Siegel, 1998b). Stative Event T-test Mean Mean P-value 932.89 667.57 0.0000 4.44% 1.56% 0.0000 1.00% 2.70% 0.0000 36.05% 57.56% 0.0000 20.98% 15.37% </context>
<context position="23345" citStr="Siegel, 1998" startWordPosition="3601" endWordPosition="3602">100.0% 63.3% 0.0% 100.0% b12 70.8% 94.9% 69.8% 29.2% 76.7% 117 completedness, nor does it achieve as wide a recall tradeff for both stativity and cornpletedness. These results are indicated as the second baselines (&amp;quot;b12&amp;quot;) in tables 6 and 8, respectively. • Scalar values assigned to each verb allow the tradeoff between recall and precision to be selected for particular applications by selecting the classification threshold. For example, in a separate study, optimizing for F-measure resulted in a more dramatic tradeoff in recall values as compared to those attained when optimizing for accuracy (Siegel, 1998b). Moreover, such scalar values can provide input to systems that perform reasoning on fuzzy or uncertainty knowledge. • This framework is expandable since additional indicators can be introduced by measuring the frequencies of additional aspectual markers. Furthermore, indicators measured over multiple clausal constituents, e.g., main verb-object pairs, alleviate verb ambiguity and sparsity and improve classification performance (Siegel, 1998b). 6 Conclusions We have developed a full-scale system for aspectual classification with multiple linguistic indicators. Once trained, this system can </context>
</contexts>
<marker>Siegel, 1998</marker>
<rawString>E.V. Siegel. 1998b. Linguistic Indicators for Language Understanding: Using machine learning methods to combine corpus-based indicators for aspectual classification of clauses. Ph.D. thesis, Columbia University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Van Rijsbergen</author>
</authors>
<title>Information Retrieval.</title>
<date>1979</date>
<publisher>Butterwoths,</publisher>
<location>London.</location>
<marker>Van Rijsbergen, 1979</marker>
<rawString>C.J. Van Rijsbergen. 1979. Information Retrieval. Butterwoths, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Vendler</author>
</authors>
<title>Verbs and times.</title>
<date>1967</date>
<booktitle>In Linguistics in Philosophy.</booktitle>
<publisher>Cornell University Press,</publisher>
<location>Ithaca, NY.</location>
<contexts>
<context position="1494" citStr="Vendler, 1967" startWordPosition="211" endWordPosition="212">ries correspond to primitive distinctions in many domains, e.g., the distinction between procedure and diagnosis in the medical domain. Aspectual classification further distinguishes events according to completedness (i.e., telicity), which determines whether an event reaches a culmination point in time at which a new state is introduced. For example, &amp;quot;I made a fire&amp;quot; is culminated, since a new state is introduced — something is made, whereas, &amp;quot;I gazed at the sunset&amp;quot; is non-culminated. Aspectual classification is necessary for interpreting temporal modifiers and assessing temporal entailments (Vendler, 1967; Dowty, 1979; Moens and Steedman, 1988; Dorr, 1992), and is therefore a necessary component for applications that perform certain natural language interpretation, natural language generation, summarization, information retrieval, and machine translation tasks. Aspect introduces a large-scale, domaindependent lexical classification problem. Although an aspectual lexicon of verbs would suffice to classify many clauses by their main verb only, a verb&apos;s primary class is often domaindependent (Siegel, 1998b). Therefore, it is necessary to produce a specialized lexicon for each domain. Most approac</context>
<context position="5048" citStr="Vendler, 1967" startWordPosition="726" endWordPosition="727"> temporal constraints between clauses connected with when, e.g., in interpreting (1), (1) She had good strength when objectively tested. the following temporal relationship holds: have test However, in interpreting (2), (2) Phototherapy was discontinued when the bilirubin came down to 13. the temporal relationship is different: come discontinue These aspectual distinctions are motivated by a series of entailment constraints. In particular, certain lexico-syntactic features of a clause, such as temporal adjuncts and tense, are constrained by and contribute to the aspectual class of the clause (Vendler, 1967; Dowty, 1979). Tables 2 illustrates an array of linguistic conTable 2: Several aspectual markers and associated constraints on aspectual class, primarily from Kiavans&apos; summary summary (1994). If a clause can occur: then it is: with a temporal adverb Event (e.g., then) in progressive Extended Event with a duration in-PP (e.g., in an hour) in the perfect tense straints. Each entry in this table describes an aspectual marker and the constraints on the aspectual category of any clause that appears with that marker. For example, a clause must be an extended event to appear in the progressive tense</context>
<context position="25337" citStr="Vendler, 1967" startWordPosition="3901" endWordPosition="3902">ents an advantage for applications that weigh the identification of non-dominant classes more heavily (Cardie and Howe, 1997). For example, correctly identifying occurrences of for that denote event durations relies on positively identifying non-culminated events. A system that summarizes the duration of events which incorrectly classifies &amp;quot;She ran (for a minute)&amp;quot; as culminated will not detect that &amp;quot;for a minute&amp;quot; describes the duration of the run event. This is because durative for-PPs that modify culminated events denote the duration of the ensuing state, e.g., I left the room for a minute. (Vendler, 1967) Our analysis has revealed several insights regarding individual indicators. For example, both duration in-PP and manner adverb are particularly valuable for multiple aspectual distinctions — they were ranked in the top two positions by log-linear modeling for both stativity and completedness. We have discovered several new linguistic indicators that are not traditionally linked to aspectual class. In particular, verb frequency with no deep subject was positively correlated with both stativity and completedness. Moreover, four other indicators are newly linked to stativity: (1) Verb frequency,</context>
</contexts>
<marker>Vendler, 1967</marker>
<rawString>Z. Vendler. 1967. Verbs and times. In Linguistics in Philosophy. Cornell University Press, Ithaca, NY.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>