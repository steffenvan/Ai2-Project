<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000006">
<title confidence="0.9997065">
A Method for Correcting Errors in Speech Recognition Using the Statistical
Features of Character Co-occurrence
</title>
<author confidence="0.961439">
Satoshi Kaki, Eiichiro Sumita, and Hitoshi Iida
</author>
<affiliation confidence="0.809361">
ATR Interpreting Telecommunications Research Labs,
</affiliation>
<address confidence="0.799115">
Hikaridai 2-2 Seika-cho, Soraku-gun, Kyoto 619-0288, Japan
</address>
<email confidence="0.970404">
{skaki, sumita, iida}@itl.atr.co.jp
</email>
<sectionHeader confidence="0.997143" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999988952380952">
It is important to correct the errors in the results of
speech recognition to increase the performance of a
speech translation system. This paper proposes a
method for correcting errors using the statistical
features of character co-occurrence, and evaluates the
method.
The proposed method comprises two successive
correcting processes. The first process uses pairs of
strings: the first string is an erroneous substring of the
utterance predicted by speech recognition, the second
string is the corresponding section of the actual
utterance. Errors are detected and corrected according
to the database learned from erroneous-correct
utterance pairs. The remaining errors are passed to the
posterior process which uses a string in the corpus
that is similar to the string including recognition
errors.
The results of our evaluation show that the use of
our proposed method as a post-processor for speech
recognition is likely to make a significant contribution
to the performance of speech translation systems.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99992053125">
In spite of the increased performance of speech recognition
systems, the output still contains many errors. For language
processing such as a machine translation, it is extremely
difficult to deal with such errors.
In integrating recognition and translation into a speech
translation system, the development of the following
processes is therefore important: (1) detection of errors in
speech recognition results; (2) sorting of speech
recognition results by means of error detection; (3)
providing feedback to the recognition process and/or
making the user speak again; (4) correct errors, etc.
For this purpose, a number of methods have been
proposed. One method is to translate correct parts
extracted from speech recognition results by using the
semantic distance between words calculated with an
example-based approach (Walcita et al., 97). Another
method also obtains reliably recognized partial segments
of an utterance by cooperatively using both grammatical
and n-gram based statistical language constraints, and uses
a robust parsing technique to apply the grammatical
constraints described by context-free grammar (Tsukada et
al., 97). However, these methods do not carry out any error
correction on a recognition result, but only specify correct
parts in it.
In this paper we therefore propose a method for
correcting errors, which is characterized by learning the
trend of errors and expressions, and by processing in an
arbitrary length string.
Similar work on English was presented by (E.K.
Ringger et al., 96). Using a noisy-channel model, they
implemented a post-processor to correct word-level errors
committed by a speech recognizer.
</bodyText>
<sectionHeader confidence="0.991875" genericHeader="method">
2 Method for Correcting Errors
</sectionHeader>
<bodyText confidence="0.99825025">
We refer to two compositions of the proposal as Error-
Pattern-Correction (EPC) and Similar-String-Correction
(SSC) respectively. The correction using EPC and SSC
together in this order is abbreviated to EPC+SSC.
</bodyText>
<subsectionHeader confidence="0.909315">
2.1 Error-Pattern-Correction (EPC)
</subsectionHeader>
<bodyText confidence="0.9943246">
When examining errors in speech recognition, errors are
found to occur in regular patterns rather than at random.
EPC uses such error patterns for correction. We refer to
this pattern as an Error-Pattern.
An Error-Pattern is made up of two strings. One is the
</bodyText>
<figureCaption confidence="0.988288">
Figure 2-1 The block diagram for EPC
</figureCaption>
<figure confidence="0.9776655">
Matching Substituting
Input with Error- the Correct- Corrected
String Part of Error- Part for String
Pattern Error-Part
t
Error-Pattern-Database
</figure>
<page confidence="0.7197025">
pairs of Error- and Correct-Part
653
</page>
<bodyText confidence="0.9988542">
string including errors, and the other is the corresponding
correct string (the former string is referred to as the Error-
Part, and the latter as the Correct-Part respectively). These
parts are extracted from the speech recognition results and
the corresponding actual utterances, then they are stored in
a database (referred to as an Error-Pattern-Database). In
EPC, the correction is made by substituting a Correct-Part
for an Error-Part when the Error-Part is detected in a
recognition result (see Figure 2-1). Table 2-1 shows some
Error-Pattern examples.
</bodyText>
<tableCaption confidence="0.986342">
Table 2-1 Examples of Error-Patterns
</tableCaption>
<table confidence="0.9889636">
Correct-Part Error-Part
LtirIVI L: 7:cZa
L-crA1-4-0-,&apos; L. -c- -z- 6 tto-t,
+L.1,1/..: Li-- t L, -cot: I. it
V.1.0-i-A •V.1.1,1t--i_t
</table>
<subsectionHeader confidence="0.979465">
2.1.1 Extraction of Error-Patterns
</subsectionHeader>
<bodyText confidence="0.9994435">
The Error-Pattern-Database is mechanically prepared
using a pair of parts from the speech recognition
results and the corresponding actual utterance. The
examples below show candidates grouped according
to the correct part &apos;&lt;1131&gt;1 and the erroneous part 1.&lt;
&gt;&apos;.
</bodyText>
<table confidence="0.889066">
Error-Pattern Candidates Frq.
3
&lt;fr-T&gt; : 3
3
: IM.t.&lt;1&gt;Z111:1&apos; 2
rt=t&lt;PI&gt;VX&lt;&amp;quot; : d&gt;&lt; 1
</table>
<bodyText confidence="0.9981436">
EPC is a simple and effective method because it
detects and corrects errors only by pattern-matching.
The unrestricted use of Error-Patterns, however, may
produce the wrong correction. Therefore a careful
selection of Error-Patterns is necessary. In this
method, several selection conditions are applied in
order, as described below. Candidates passing all of
the conditions are employed as Error-Patterns.
Condition of High Frequency: Candidates of not less
than a given threshold value (2 in the experiment) in
frequency are selected to collect errors which have a high
frequency of occurrence in recognition results.
Condition of Non-Side Effect:, This step excludes the
candidate whose Error-Part is included in actual utterances
to prevent the Error-Part from matching with a section of
actual utterances.
Condition of Inclusion-1: Because a long Error-Part is
more accurate for matching, this step selects an Error-
Pattern whose Error-Part is as long as possible. For two
arbitrary candidates, when one of their Error-Parts includes
the other, and their frequencies are the same value, the
candidate whose Error-Part includes the other is accepted.
Condition of Inclusion-2: If some Error-Parts are derived
from different utterances and have a common part in them,
this common part is suitable for an Error-Pattern.
Therefore in this step, an Error-Pattern with its Error-Part
as short as possible is selected. For two arbitrary
candidates, when one of their Error-Parts includes the
other, and their frequencies have different values, the
included candidate is accepted.
</bodyText>
<subsectionHeader confidence="0.994539">
2.2 Similar-String-Correction (SSC)
</subsectionHeader>
<bodyText confidence="0.999969769230769">
In an erroneous Japanese sentence, the correct
expressions can be estimated frequently by the row of
characters before and after the erroneous sections of
the sentence. This means that we are involuntarily
applying a portion of a regular expression to an
erroneous section.
Instead of this portion of the regular expression,
SSC uses a collection of strings, the members of
which are in the corpus (this collection we refer to as
the String-Database). As shown in the block diagram
in figure 2-2, the correction is performed through the
following steps. the first step is error detection. The
next step is the retrieval of the string that is most
</bodyText>
<figureCaption confidence="0.985316">
Figure 2-2 The block diagram of SSC
</figureCaption>
<figure confidence="0.996998">
Input String
Error Probability of
Detection 3-Characters
Secitice
Retrieval of
Similar String 44—
Substitution of
Dissimilar Part
String-Database
Corrected String
</figure>
<page confidence="0.996887">
654
</page>
<bodyText confidence="0.9999638">
similar to the string including errors from the String-
Database (the former string is referred to as the
Similar-String, and the latter as the Error-String).
Finally, the correction is made using the difference
between these two strings.
</bodyText>
<subsectionHeader confidence="0.452303">
2.2.1 Procedure for Correction
</subsectionHeader>
<bodyText confidence="0.998874041666666">
The procedure for correction varies slightly,
depending on the position of the detected error: a top,
a middle, or a tail, in an utterance. Here we will
explain the case of a middle.
Step 1: Estimate an erroneous section (referred to as an
error-block) with error detection method&apos;. If there is no
error-block, the procedure is terminated.
Depending on the position of the error-block, the
procedure branches in the following way.
If P1 is less than T (T=4), then go to the step for a top.
If a value L - P2 + T is less than T, then go to the step
for a tail.
In all other cases, go to the step for a middle.
Here, P1 and P2 denote the start and end positions of
an error-block, and L denotes the length of the input string.
Step 2: Take the string (Error-String) that comprises an
error-block and each M (5 in the experiment) character
before and after the error-block out of the input string, and
using this string (Error-String) as a query key, retrieve a
string (Similar-String) from the String-Database to satisfy
the following condition. It must be located in a middle of
an utterance, it must have the highest value (S), and S must
be not less than a given threshold value ( 0.6 in the
experiment). Here, S is defined as:
</bodyText>
<equation confidence="0.767635">
S = (L - N) / L
</equation>
<bodyText confidence="0.921746733333333">
where L is the length of the Similar String, and N is the
minimum number of character insertions, deletions, or
substitutions necessary to transform the Error-String to the
Similar-String.
If there is no Similar-String, then go to step 1 leaving
this error-block undone.
Step 3: If the two strings (denoted A and B), that are each
K (2 in the experiment) characters before and after an
error-block in the Error-String, are found in the Similar-
String, take out the string (denoted C) between A and B in
1 For detecting errors in Japanese sentences, the method using the
probability of character sequence was reported to be fairly
effective (Araki et al., 93). The result of a preliminary
experiment was that the precision and recall rates were over
80% and over 70% respectively.
</bodyText>
<figure confidence="0.969402625">
&lt;error-block&gt;
lc,
Error-String: [-et] I ta&lt;HAW&gt;Ui [PI]
[A]
Substitution„— [B]
11,-........ IP
Similar-String: [ &amp;quot;C&apos; t ] 1 ta A tt It [11-1.]VIT:
ICI -4L
</figure>
<figureCaption confidence="0.834515">
Kgure 2-3 The procedure of SSC
</figureCaption>
<bodyText confidence="0.916182">
the Similar-String. If it is not found, then go to Step 1
leaving this error-block undone.
Substitute string C as the correct string for the string
between A and B in the Error-String (see figure 2-3).
</bodyText>
<sectionHeader confidence="0.998717" genericHeader="method">
3. Evaluation
</sectionHeader>
<subsectionHeader confidence="0.8370035">
3.1 Data Condition for Experiments
Results of Speech Recognition: We used 4806
</subsectionHeader>
<bodyText confidence="0.999712888888889">
recognition results including errors, from the output of
speech recognition (Masatalci et al., 96; Shimizu etal., 96)
experiment using an ATR spoken language database
(Morimoto et al., 94) on travel arrangements. The
characteristics of those results are shown in table 3-1.
The breakdown of these 4806 results is as follows:
4321 results were used for the preparation of Error-
Patterns and the other 495 results were used for the
evaluation.
</bodyText>
<tableCaption confidence="0.977258">
Table 3-1 The recognition characteristics
</tableCaption>
<table confidence="0.8500778">
Recognition Insertion Deletion Substitution Sum
accuracy(%)
(in character)
74.73 2642 1702 8087 12431
Preparation of Error-Patterns: As the threshold value
</table>
<bodyText confidence="0.9989234">
for the frequency of the occurrence, we employed a value
of not less than 2, therefore we obtained 629 Error-Patterns
using the 4321 results of speech recognition.
Preparation of the String-Database: Using the different
data-sets of the ATR spoken language database from the
above-mentioned 4806 results, we prepared the String-
Database.
We employed 3 as the threshold value for the frequency
of the occurrence, and 10 as the length of a string,
therefore obtaining 16655 strings.
</bodyText>
<subsectionHeader confidence="0.999646">
3.2 Two Factors for Evaluation
</subsectionHeader>
<bodyText confidence="0.99918625">
We evaluated the following two factors before and
after correction: (1) the counting of errors, and (2) the
effectiveness of the method in understanding the
recognized results.
</bodyText>
<page confidence="0.998357">
655
</page>
<bodyText confidence="0.916685222222222">
To confirm the effectiveness, the recognition
results were evaluated by two native Japanese. They
assigned one of five levels, A-E, to each recognition
result before and after correction, by comparing it
with the corresponding actual utterance. Finally, we
employed the overall results of the stricter of two
evaluators.
(A) No lacking in the meaning of the actual utterance,
and with perfect expression.
</bodyText>
<listItem confidence="0.982848666666667">
(B) No lacking in meaning, but with slightly awkward
expression.
(C) Slightly lacking in meaning.
(D) Considerably lacking in meaning.
(E) Unable to understand, and unable to imagine the
actual utterance.
</listItem>
<sectionHeader confidence="0.988925" genericHeader="evaluation">
4. Results and Discussions
</sectionHeader>
<subsectionHeader confidence="0.957668">
4.1 Decrease in the Number of Errors
</subsectionHeader>
<bodyText confidence="0.955943">
Table 4-1 shows the number of errors before and after
correction. These results show the following.
</bodyText>
<tableCaption confidence="0.99149">
Table 4-1 The number of errors before and after correction
</tableCaption>
<table confidence="0.9992978">
Insertion Deletion Substitution Sum
Before 264 206 891 1361
EPC 226(-14.4) 190(-7.8) 853(-4.3) I269(-6.8)
SSC 251( -4.9) 214(+3.9) 870(-2.4) I335(-1.9)
EPC+SSC 2I6(-18.2) 198(-3.9) 831(-7.9) 1245(-8.5)
</table>
<tableCaption confidence="0.278968">
The values inside brackets 0 are the rate of decrease
</tableCaption>
<bodyText confidence="0.99988">
In EPC+SSC, the rate of decrease was 8.5%, and
the decrease was obtained in all type of errors.
In SSC, the number of deletion errors increased by
3.9%. The reason for this is that in SSC, correction by
deleting the part of a substitution error frequently
caused new deletion errors as shown in the example
below. From the standpoint of the correction it might
be a mistaken correction, but it increases
understanding of the results by deleting a noise and
makes the results viable for machine translation. It
therefore practically refines the speech recognition
results.
</bodyText>
<footnote confidence="0.666914">
Correct String:
&apos;itto6 75cL
&amp;quot;Hai arigatou gozaimasu Kyoto Kanko Hoteru yoyaku galcari de
gozaimasu&amp;quot;, (Thank you for calling Kyoto Kanko Hotel reservations.)
Input String:
&apos;611 t) ■9 751 )1/-1,13114 n,1
t&apos;
&amp;quot;A hai arigatou gozaimasu e Kyoto Kanko Hoteru yanichilcan
gozaimasu&amp;quot;, (Thank you for calling Kyoto Kanko Hotel )
Corrected String:
i975cL ::**
&amp;quot;A hai arigatou gozaimasu e Kyoto Kanko Hoteru de gozaimasu&amp;quot;,
(Thank you for calling Kyoto Kanko Hotel.)
</footnote>
<subsectionHeader confidence="0.993607">
4.2 Improvement of Understandability
</subsectionHeader>
<bodyText confidence="0.975706833333333">
Table 4-2 shows the number of change in the
evaluated level.
The rate of improvement after correction was 7%.
There were also a lot of cases that improved their
level by recovering content words. For example, the
word &amp;quot;cash&amp;quot; was recovered in
(before-.after), &amp;quot;guide&amp;quot; in &apos;H - etc.
These results confirm that our method is effective
in improving the understanding of the recognition
results.
On the other hand, there were four level-down
cases. Three of these cases were caused by the
misdetection of errors in the SSC procedure. The
remaining case occurred in the EPC procedure. The
Error-Pattern used in this case could not be excluded
by the condition of non-side effects because its Error-
Part was not included in the corpus of the actual
utterance.
</bodyText>
<tableCaption confidence="0.9244365">
Table 4-2 The number of changes in the evaluated level before
and after correction.
</tableCaption>
<table confidence="0.838165333333333">
EPC SSC EPC+SSC
Improve 18( 3.7) 15( 3.1) 34( 7.0)
No Change 466( 96.1) 467( 96.3) 447( 92.2)
Down 1( 0.2) 3( 0.6) 4( 0.8)
The values inside brackets () are the rate (% of the number to total
number of evaluated results.
</table>
<subsectionHeader confidence="0.9852745">
4.3 More Applicable for a Result Having a Few
Errors
</subsectionHeader>
<bodyText confidence="0.9944035">
Table 4-3 shows the rate of change in the evaluated
level by the original number of erroneous characters2
</bodyText>
<tableCaption confidence="0.869894">
Table 4-3 The rate of change in the evaluated level by the
original number of erroneous characters involved in the
recognition results (EPC+SSC).
</tableCaption>
<table confidence="0.998598555555555">
Num. of erroneous Num. of Rate(%) of change
characters results
Improve No Down
Change
0 102 0.0 98.0 2.0
1 30 16.7 80.0 3.3
2 21 28.6 66.7 4.8
3 26 19.2 80.8 0.0
4 40 12.5 87.5 0.0
5 27 14.8 85.2 0.0
6 24 12.5 87.5 0.0
7 21 9.5 90.5 0.0
8 17 0.0 100.0 0.0
9 20 5.0 95.0 0.0
10 29 0.0 100.0 0.0
11 22 0.0 100.0 0.0
12 106 2.8 97.2 0.0
Total 485 7.0 92.2 0.8
</table>
<footnote confidence="0.869324666666667">
2 This number is the minimum number of character insertions,
deletions or substitutions necessary to transform the result of
recognition into a corresponding actual utterance.
</footnote>
<page confidence="0.997651">
656
</page>
<bodyText confidence="0.999897416666667">
included in the recognition results.
The recognition results improving their level after
correction mostly fell in the range of erroneous numbers
by not more than 7. The reasons for this are that with there
being many errors, the failure of the corrections increases
because the corrections are prevented by other surrounding
errors. In addition, when only a few successful corrections
have been made, they have little influence on the overall
understanding.
These results show that the proposed method is more
applicable for a recognition result having a few errors, as
compared with one having many errors.
</bodyText>
<sectionHeader confidence="0.999261" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.997967742857143">
As described above, our proposed method has the
following features:
(1) Since the proposed method is designed with a arbitrary
length string as a unit, it is capable of correcting errors
which are hard to deal with by methods designed to treat
words as units.
For example, the insertion error (&amp;quot;wo&amp;quot;) in the string
(&amp;quot;shiharai wo houhou&amp;quot;) shown in table 2-
1 cannot be corrected by a method designed to treat words
as units, because of the existence of the particle &apos; (&amp;quot;wo&amp;quot;)
as a correct word. However with the proposed method, it is
possible to correct this kind of error by using the row of
characters before and after &apos; (&amp;quot;wo&amp;quot;).
(2) In the proposed method of leaming the trend of errors
and expressions with long strings, it is possible to correct
errors where it is difficult to narrow the candidates down to
the correct character with the probability of the character
sequence alone.
When considering the candidate for &apos;T&apos; (&amp;quot;te&amp;quot;) in &apos;LC
T 6 I (&amp;quot;shitetekitnasurbode&amp;quot;) shown in table 2-1
to satisfy the probability of the character sequence, its
candidates, &apos;V (&amp;quot;i&amp;quot;), It-31 (&amp;quot;o&amp;quot;), &apos;TA&apos; (&amp;quot;itatla&amp;quot;) are arranged
in order of increasing probability. It is therefore difficult to
narrow the candidates into the correct character TA I
(&amp;quot;itada&amp;quot;) by the probability of character sequence alone.
But with the proposed method it is possible to correct this
kind of error by using the row of the characters before and
after &apos;T&apos; (&amp;quot;te&amp;quot;).
(3) Both the Error-Pattern-Database and String-Database
can be mechanically prepared, which reduces the effort
required to prepare the databases and makes it possible to
apply this method to a new recognition system in a short
time.
From the evaluation, it became clear that the
proposed method has the following effects:
</bodyText>
<listItem confidence="0.9852784">
(1) It reduces over 8% of the errors.
(2) It improves the understanding of the recognition results
by 7%.
(3) It has very little influence on correct recognition results.
(4) It is more applicable for a recognition result with a few
</listItem>
<bodyText confidence="0.948648333333333">
errors than one with many errors.
Judging from these results and features, the use of the
proposed method as a post-processor for speech
recognition is likely to make a significant contribution to
the performance of speech translation systems.
In the future, we will try to improve the correcting
accuracy by changing algorithms and will also try to
improve translation performance by combining our
method with Walcita&apos;s method.
</bodyText>
<sectionHeader confidence="0.999373" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999043875">
T. Aralci et al., 93. A Method for Detecting and Correcting of
Characters Wrongly Substituted, Deleted or Inserted in
Japanese Strings Using 2nd-Order Markov Model. IPSJ,
Report of SIG-NL, 97-5, pp. 29-35 (1993)
T. Morimoto et al., 94: A Speech and language database for
speech translation research. Proc. of ICSLP &apos;94, pp. 1791-
1794, 1994.
H. Masatalci et al., 96. Variable-order n-gram generation by
word-class splitting and consecutive word grouping. In Proc.
of ICASSP, 1996.
T. Shimizu et al., 96. Spontaneous Dialogue Speech Recognition
using Cross-word Context Constrained Word Graphs.
ICASSP &apos;96, pp. 145-148, 1996.
Y. Wakita et al., 97. Correct parts extraction from speech
recognition results using semantic distance calculation, and
its application to speech translation. ACIJEACL Workshop
Spoken Language Translation, pp. 24-31, 1997-7.
H. Tsulcada et al., 97. Integration of grammar and statistical
language constraints for partial word-sequence recognition.
In Proc. of 5th European Conference on Speech
Communication and Technology (EuroSpeech &apos;97), 1997.
EX.Ringger et al., 96. A Fertility Channel Model for Post-
Correction of Continuous Speech Recognition. ICSLP&apos;96, pp.
897-900, 1996.
</reference>
<page confidence="0.998017">
657
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.958732">
<title confidence="0.9941985">A Method for Correcting Errors in Speech Recognition Using the Statistical Features of Character Co-occurrence</title>
<author confidence="0.995965">Satoshi Kaki</author>
<author confidence="0.995965">Eiichiro Sumita</author>
<author confidence="0.995965">Hitoshi Iida</author>
<affiliation confidence="0.999564">ATR Interpreting Telecommunications Research Labs,</affiliation>
<address confidence="0.990005">Hikaridai 2-2 Seika-cho, Soraku-gun, Kyoto 619-0288, Japan</address>
<email confidence="0.982938">skaki@itl.atr.co.jp</email>
<email confidence="0.982938">sumita@itl.atr.co.jp</email>
<email confidence="0.982938">iida@itl.atr.co.jp</email>
<abstract confidence="0.999876954545455">It is important to correct the errors in the results of speech recognition to increase the performance of a speech translation system. This paper proposes a method for correcting errors using the statistical features of character co-occurrence, and evaluates the method. The proposed method comprises two successive correcting processes. The first process uses pairs of strings: the first string is an erroneous substring of the utterance predicted by speech recognition, the second string is the corresponding section of the actual utterance. Errors are detected and corrected according to the database learned from erroneous-correct utterance pairs. The remaining errors are passed to the posterior process which uses a string in the corpus that is similar to the string including recognition errors. The results of our evaluation show that the use of our proposed method as a post-processor for speech recognition is likely to make a significant contribution to the performance of speech translation systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Aralci</author>
</authors>
<title>A Method for Detecting and Correcting of Characters Wrongly Substituted, Deleted or Inserted</title>
<date>1993</date>
<booktitle>in Japanese Strings Using 2nd-Order Markov Model. IPSJ, Report of SIG-NL,</booktitle>
<pages>97--5</pages>
<marker>Aralci, 1993</marker>
<rawString>T. Aralci et al., 93. A Method for Detecting and Correcting of Characters Wrongly Substituted, Deleted or Inserted in Japanese Strings Using 2nd-Order Markov Model. IPSJ, Report of SIG-NL, 97-5, pp. 29-35 (1993)</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Morimoto</author>
</authors>
<title>94: A Speech and language database for speech translation research.</title>
<date>1994</date>
<booktitle>Proc. of ICSLP &apos;94,</booktitle>
<pages>1791--1794</pages>
<marker>Morimoto, 1994</marker>
<rawString>T. Morimoto et al., 94: A Speech and language database for speech translation research. Proc. of ICSLP &apos;94, pp. 1791-1794, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Masatalci</author>
</authors>
<title>96. Variable-order n-gram generation by word-class splitting and consecutive word grouping.</title>
<date>1996</date>
<booktitle>In Proc. of ICASSP,</booktitle>
<marker>Masatalci, 1996</marker>
<rawString>H. Masatalci et al., 96. Variable-order n-gram generation by word-class splitting and consecutive word grouping. In Proc. of ICASSP, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Shimizu</author>
</authors>
<title>96. Spontaneous Dialogue Speech Recognition using Cross-word Context Constrained Word Graphs.</title>
<date>1996</date>
<booktitle>ICASSP &apos;96,</booktitle>
<pages>145--148</pages>
<marker>Shimizu, 1996</marker>
<rawString>T. Shimizu et al., 96. Spontaneous Dialogue Speech Recognition using Cross-word Context Constrained Word Graphs. ICASSP &apos;96, pp. 145-148, 1996.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Y Wakita</author>
</authors>
<title>97. Correct parts extraction from speech recognition results using semantic distance calculation, and its application to speech translation.</title>
<journal>ACIJEACL Workshop Spoken Language Translation,</journal>
<pages>24--31</pages>
<marker>Wakita, </marker>
<rawString>Y. Wakita et al., 97. Correct parts extraction from speech recognition results using semantic distance calculation, and its application to speech translation. ACIJEACL Workshop Spoken Language Translation, pp. 24-31, 1997-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Tsulcada</author>
</authors>
<title>97. Integration of grammar and statistical language constraints for partial word-sequence recognition.</title>
<date>1997</date>
<booktitle>In Proc. of 5th European Conference on Speech Communication and Technology (EuroSpeech &apos;97),</booktitle>
<marker>Tsulcada, 1997</marker>
<rawString>H. Tsulcada et al., 97. Integration of grammar and statistical language constraints for partial word-sequence recognition. In Proc. of 5th European Conference on Speech Communication and Technology (EuroSpeech &apos;97), 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>EX Ringger</author>
</authors>
<title>A Fertility Channel Model for PostCorrection of Continuous Speech Recognition.</title>
<date>1996</date>
<booktitle>ICSLP&apos;96,</booktitle>
<pages>897--900</pages>
<marker>Ringger, 1996</marker>
<rawString>EX.Ringger et al., 96. A Fertility Channel Model for PostCorrection of Continuous Speech Recognition. ICSLP&apos;96, pp. 897-900, 1996.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>