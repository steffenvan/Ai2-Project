<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014347">
<title confidence="0.991015">
Action representation for NL instructions
</title>
<author confidence="0.982402">
Barbara Di Eugenio*
</author>
<affiliation confidence="0.9733335">
Department of Computer and Information Science
University of Pennsylvania
</affiliation>
<address confidence="0.58068">
Philadelphia, PA
</address>
<email confidence="0.898749">
dieugeni©linc.cis.upenn.edu
</email>
<sectionHeader confidence="0.99926" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.988327642857143">
The need to represent actions arises in many differ-
ent areas of investigation, such as philosophy [5], se-
mantics [10], and planning. In the first two areas,
representations are generally developed without any
computational concerns. The third area sees action
representation mainly as functional to the more gen-
eral task of reaching a certain goal: actions have of-
ten been represented by a predicate with some argu-
ments, such as move(John, blockl, rooml, rooms),
augmented with a description of its effects and of
what has to be true in the world for the action to
be executable [8]. Temporal relations between ac-
tions [1], and the generation relation [12], [2] have
also been explored.
However, if we ever want to be able to give in-
structions in NL to active agents, such as robots and
animated figures, we should start looking at the char-
acteristics of action descriptions in NL, and devising
formalisms that should be able to represent these
characteristics, at least in principle. NL action de-
scriptions are complex, and so are the inferences the
agent interpreting them is expected to draw.
As far as the complexity of action descriptions
goes, consider:
Ex. 1 Using a paint roller or brush, apply paste to
the wall, starting at the ceiling line and pasting down
a few feet and covering an area a few inches wider
than the width of the fabric.
The basic description apply paste to the wall is
augmented with the instrument to be used and with
direction and extent modifiers. The richness of the
possible modifications argues against representing
actions as predicates having a fixed number of ar-
guments.
Among the many complex inferences that an agent
interpreting instructions is assumed to be able to
draw, one type is of particular interest to me, namely,
the interaction between the intentional description of
an action - which I&apos;ll call the goal or the why - and
its executable counterpart - the how 1. Consider:
Ex. 2 a) Place a plank between two ladders
to create a simple scaffold.
</bodyText>
<subsectionHeader confidence="0.33523">
b) Place a plank between two ladders.
</subsectionHeader>
<bodyText confidence="0.994183923076923">
In both a) and b), the action to be executed
is &amp;quot;place a plank between two ladders&amp;quot;. However,
Ex. 2.b would be correctly interpreted by placing the
plank anywhere between the two ladders: this shows
that in a) the agent must be inferring the proper po-
sition for the plank from the expressed why &amp;quot;to create
a simple scaffold&amp;quot;.
My concern is with representations that allow
specification of both how&apos;s and why&apos;s, and with rea-
soning that allows inferences such as the above to
be made. In the rest of the paper, I will argue that
a hybrid representation formalism is best suited for
the knowledge I need to represent.
</bodyText>
<sectionHeader confidence="0.5254905" genericHeader="method">
2 A hybrid action representa-
tion formalism
</sectionHeader>
<bodyText confidence="0.999090636363636">
As I have argued elsewhere based on analysis of nat-
urally occurring data [14], [7], actions - action types,
to be precise - must be part of the underlying ontol-
ogy of the representation formalism; partial action
descriptions must be taken as basic; not only must
the usual participants in an action such as agent or
patient be represented, but also means, manner, di-
rection, extent etc.
Given these basic assumptions, it seems that
knowledge about actions falls into the following two
categories:
</bodyText>
<listItem confidence="0.992849571428571">
1. Terminological knowledge about an action-
type: its participants and its relation to other
action-types that it either specializes or ab-
stracts - e.g. slice specializes cut, loosen a screw
carefully specializes loosen a screw.
2. Non-terminological knowledge. First of all,
knowledge about the effects expected to occur
</listItem>
<footnote confidence="0.347035">
This research was supported by DARPA grant no. N0014- What executable means is debatable: see for example [12],
</footnote>
<page confidence="0.7424865">
85 -K0018. P. 63ff.
333
</page>
<bodyText confidence="0.994217803030303">
when an action of a given type is performed.
Because effects may occur during the perfor-
mance of an action, the basic aspectual profile
of the action-type [11] should also be included.
Clearly, this knowledge is not terminological; in
Ex. 3 Turn the screw counterclockwise but
don&apos;t loosen it completely.
the modifier not ... completely does not affect
the fact that don&apos;t loosen it completely is a loos-
ening action: only its default culmination con-
dition is affected.
Also, non-terminological knowledge must in-
clude information about relations between
action-types: temporal, generation, enablement,
and testing, where by testing I refer to the rela-
tion between two actions, one of which is a test
on the outcome or execution of the other.
The generation relation was introduced by Gold-
man in [9], and then used in planning by [1], [12],
[2]: it is particularly interesting with respect to
the representation of how&apos;s and why&apos;s, because
it appears to be the relation holding between
an intentional description of an action and its
executable counterpart - see [12].
This knowledge can be seen as common-sense
planning knowledge, which includes facts such
as to loosen a screw, you have to turn it coun-
terclockwise, but not recipes to achieve a certain
goal [2], such as how to assemble a piece of fur-
niture.
The distinction between terminological and non-
terminological knowledge was put forward in the past
as the basis of hybrid KR system, such as those that
stemmed from the KL-ONE formalism, for example
KRYPTON [3], KL-TWO [13], and more recently
CLASSIC [4]. Such systems provide an assertional
part, or A-Box, used to assert facts or beliefs, and a
terminological part, or T-Box, that accounts for the
meaning of the complex terms used in these asser-
tions.
In the past however, it has been the case that
terms defined in the T-box have been taken to cor-
respond to noun phrases in Natural Language, while
verbs are mapped onto the predicates used in the as-
sertions stored in the A-box. What I am proposing
here is that, to represent action-types, verb phrases
too have to map to concepts in the T-Box. I am advo-
cating a 1:1 mapping between verbs and action-type
names. This is a reasonable position, given that the
entities in the underlying ontology come from NL.
The knowledge I am encoding in the T-box is at
the linguistic level: an action description is composed
of a verb, i.e. an action-type name, its arguments
and possibly, some modifiers. The A-Box contains
the non-terminological knowledge delineated above.
I have started using CLASSIC to represent actions:
it is clear that I need to tailor it to my needs, because
it has limited assertional capacities. I also want to
explore the feasibility of adopting techniques similar
to those used in CLASP [6] to represent what I called
common-sense planning knowledge: CLASP builds
on top of CLASSIC to represent actions, plans and
scenarios. However, in CLASP actions are still tra-
ditionally seen as STRIPS-like operators, with pre-
and post-conditions: as I hope to have shown, there
is much more to action descriptions than that.
</bodyText>
<sectionHeader confidence="0.998548" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999897590909091">
[1] J. Allen. Towards a general theory of action and
time. Artificial Intelligence, 23:123-154, 1984.
[2] C. Balkanski. Modelling act-type relations in collab-
orative activity. Technical Report TR-23-90, Cen-
ter for Research in Computing Technology, Harvard
University, 1990.
[3] R. Brachman, R.Fikes, and H. Levesque. KRYP-
TON: A Functional Approach to Knowledge Repre-
sentation. Technical Report FLAIR 16, Fairchild
Laboratories for Artificial Intelligence, Palo Alto,
California, 1983.
[4] R. Brachman, D. McGuinness, P. Patel-Schneider,
L. Alperin Resnick, and A. Borgida. Living with
CLASSIC: when and how to use a KL-ONE-like lan-
guage. In J. Sowa, editor, Principles of Semantic
Networks, Morgan Kaufmann Publishers, Inc., 1990.
[5] D. Davidson. Essays on Actions and Events. Oxford
University Press, 1982.
[6] P. Devanbu and D. Litman. Plan-Based Termino-
logical Reasoning. 1991. To appear in Proceedings
of KR 91, Boston.
[7] B. Di Eugenio. A language for representing action
descriptions. Preliminary Thesis Proposal, Univer-
sity of Pennsylvania, 1990. Manuscript.
[8] R. Fikes and N. Nilsson. A new approach to the
application of theorem proving to problem solving.
Artificial Intelligence, 2:189-208, 1971.
[9] A. Goldman. A Theory of Human Action. Princeton
University Press, 1970.
[10] R. Jackendoff. Semantics and Cognition. Current
Studies in Linguistics Series, The MIT Press, 1983.
[11] M. Moens and M. Steedman. Temporal Ontology
and Temporal Reference. Computational Linguis-
tics, 14(2):15-28, 1988.
[12] M. Pollack. Inferring domain plans in question-
answering. PhD thesis, University of Pennsylvania,
1986.
[13] M. Vilain. The Restricted Language Architecture
of a Hybrid Representation System. In IJCA I-85,
1985.
[14] B. Webber and B. Di Eugenio. Free Adjuncts in
Natural Language Instructions. In Proceedings Thir-
teenth International Conference on Computational
Linguistics, CO LING 90, pages 395-400, 1990.
</reference>
<page confidence="0.999059">
334
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.963277">
<title confidence="0.998492">Action representation for NL instructions</title>
<author confidence="0.999934">Barbara Di_Eugenio</author>
<affiliation confidence="0.9999045">Department of Computer and Information Science University of Pennsylvania</affiliation>
<address confidence="0.979954">Philadelphia, PA</address>
<email confidence="0.984491">dieugeni©linc.cis.upenn.edu</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Allen</author>
</authors>
<title>Towards a general theory of action and time.</title>
<date>1984</date>
<journal>Artificial Intelligence,</journal>
<pages>23--123</pages>
<contexts>
<context position="818" citStr="[1]" startWordPosition="125" endWordPosition="125">nt actions arises in many different areas of investigation, such as philosophy [5], semantics [10], and planning. In the first two areas, representations are generally developed without any computational concerns. The third area sees action representation mainly as functional to the more general task of reaching a certain goal: actions have often been represented by a predicate with some arguments, such as move(John, blockl, rooml, rooms), augmented with a description of its effects and of what has to be true in the world for the action to be executable [8]. Temporal relations between actions [1], and the generation relation [12], [2] have also been explored. However, if we ever want to be able to give instructions in NL to active agents, such as robots and animated figures, we should start looking at the characteristics of action descriptions in NL, and devising formalisms that should be able to represent these characteristics, at least in principle. NL action descriptions are complex, and so are the inferences the agent interpreting them is expected to draw. As far as the complexity of action descriptions goes, consider: Ex. 1 Using a paint roller or brush, apply paste to the wall, </context>
<context position="4672" citStr="[1]" startWordPosition="777" endWordPosition="777">al; in Ex. 3 Turn the screw counterclockwise but don&apos;t loosen it completely. the modifier not ... completely does not affect the fact that don&apos;t loosen it completely is a loosening action: only its default culmination condition is affected. Also, non-terminological knowledge must include information about relations between action-types: temporal, generation, enablement, and testing, where by testing I refer to the relation between two actions, one of which is a test on the outcome or execution of the other. The generation relation was introduced by Goldman in [9], and then used in planning by [1], [12], [2]: it is particularly interesting with respect to the representation of how&apos;s and why&apos;s, because it appears to be the relation holding between an intentional description of an action and its executable counterpart - see [12]. This knowledge can be seen as common-sense planning knowledge, which includes facts such as to loosen a screw, you have to turn it counterclockwise, but not recipes to achieve a certain goal [2], such as how to assemble a piece of furniture. The distinction between terminological and nonterminological knowledge was put forward in the past as the basis of hybrid </context>
</contexts>
<marker>[1]</marker>
<rawString>J. Allen. Towards a general theory of action and time. Artificial Intelligence, 23:123-154, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Balkanski</author>
</authors>
<title>Modelling act-type relations in collaborative activity.</title>
<date>1990</date>
<tech>Technical Report TR-23-90,</tech>
<institution>Center for Research in Computing Technology, Harvard University,</institution>
<contexts>
<context position="857" citStr="[2]" startWordPosition="131" endWordPosition="131">as of investigation, such as philosophy [5], semantics [10], and planning. In the first two areas, representations are generally developed without any computational concerns. The third area sees action representation mainly as functional to the more general task of reaching a certain goal: actions have often been represented by a predicate with some arguments, such as move(John, blockl, rooml, rooms), augmented with a description of its effects and of what has to be true in the world for the action to be executable [8]. Temporal relations between actions [1], and the generation relation [12], [2] have also been explored. However, if we ever want to be able to give instructions in NL to active agents, such as robots and animated figures, we should start looking at the characteristics of action descriptions in NL, and devising formalisms that should be able to represent these characteristics, at least in principle. NL action descriptions are complex, and so are the inferences the agent interpreting them is expected to draw. As far as the complexity of action descriptions goes, consider: Ex. 1 Using a paint roller or brush, apply paste to the wall, starting at the ceiling line and pastin</context>
<context position="4683" citStr="[2]" startWordPosition="779" endWordPosition="779">3 Turn the screw counterclockwise but don&apos;t loosen it completely. the modifier not ... completely does not affect the fact that don&apos;t loosen it completely is a loosening action: only its default culmination condition is affected. Also, non-terminological knowledge must include information about relations between action-types: temporal, generation, enablement, and testing, where by testing I refer to the relation between two actions, one of which is a test on the outcome or execution of the other. The generation relation was introduced by Goldman in [9], and then used in planning by [1], [12], [2]: it is particularly interesting with respect to the representation of how&apos;s and why&apos;s, because it appears to be the relation holding between an intentional description of an action and its executable counterpart - see [12]. This knowledge can be seen as common-sense planning knowledge, which includes facts such as to loosen a screw, you have to turn it counterclockwise, but not recipes to achieve a certain goal [2], such as how to assemble a piece of furniture. The distinction between terminological and nonterminological knowledge was put forward in the past as the basis of hybrid KR system, </context>
</contexts>
<marker>[2]</marker>
<rawString>C. Balkanski. Modelling act-type relations in collaborative activity. Technical Report TR-23-90, Center for Research in Computing Technology, Harvard University, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Brachman</author>
<author>R Fikes</author>
<author>H Levesque</author>
</authors>
<title>KRYPTON: A Functional Approach to Knowledge Representation.</title>
<date>1983</date>
<tech>Technical Report FLAIR 16,</tech>
<institution>Fairchild Laboratories for Artificial Intelligence,</institution>
<location>Palo Alto, California,</location>
<contexts>
<context position="5360" citStr="[3]" startWordPosition="892" endWordPosition="892">&apos;s and why&apos;s, because it appears to be the relation holding between an intentional description of an action and its executable counterpart - see [12]. This knowledge can be seen as common-sense planning knowledge, which includes facts such as to loosen a screw, you have to turn it counterclockwise, but not recipes to achieve a certain goal [2], such as how to assemble a piece of furniture. The distinction between terminological and nonterminological knowledge was put forward in the past as the basis of hybrid KR system, such as those that stemmed from the KL-ONE formalism, for example KRYPTON [3], KL-TWO [13], and more recently CLASSIC [4]. Such systems provide an assertional part, or A-Box, used to assert facts or beliefs, and a terminological part, or T-Box, that accounts for the meaning of the complex terms used in these assertions. In the past however, it has been the case that terms defined in the T-box have been taken to correspond to noun phrases in Natural Language, while verbs are mapped onto the predicates used in the assertions stored in the A-box. What I am proposing here is that, to represent action-types, verb phrases too have to map to concepts in the T-Box. I am advoca</context>
</contexts>
<marker>[3]</marker>
<rawString>R. Brachman, R.Fikes, and H. Levesque. KRYPTON: A Functional Approach to Knowledge Representation. Technical Report FLAIR 16, Fairchild Laboratories for Artificial Intelligence, Palo Alto, California, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Brachman</author>
<author>D McGuinness</author>
<author>P Patel-Schneider</author>
<author>L Alperin Resnick</author>
<author>A Borgida</author>
</authors>
<title>Living with CLASSIC: when and how to use a KL-ONE-like language. In</title>
<date>1990</date>
<booktitle>Principles of Semantic Networks,</booktitle>
<editor>J. Sowa, editor,</editor>
<publisher>Morgan Kaufmann Publishers, Inc.,</publisher>
<contexts>
<context position="5404" citStr="[4]" startWordPosition="899" endWordPosition="899">elation holding between an intentional description of an action and its executable counterpart - see [12]. This knowledge can be seen as common-sense planning knowledge, which includes facts such as to loosen a screw, you have to turn it counterclockwise, but not recipes to achieve a certain goal [2], such as how to assemble a piece of furniture. The distinction between terminological and nonterminological knowledge was put forward in the past as the basis of hybrid KR system, such as those that stemmed from the KL-ONE formalism, for example KRYPTON [3], KL-TWO [13], and more recently CLASSIC [4]. Such systems provide an assertional part, or A-Box, used to assert facts or beliefs, and a terminological part, or T-Box, that accounts for the meaning of the complex terms used in these assertions. In the past however, it has been the case that terms defined in the T-box have been taken to correspond to noun phrases in Natural Language, while verbs are mapped onto the predicates used in the assertions stored in the A-box. What I am proposing here is that, to represent action-types, verb phrases too have to map to concepts in the T-Box. I am advocating a 1:1 mapping between verbs and action-</context>
</contexts>
<marker>[4]</marker>
<rawString>R. Brachman, D. McGuinness, P. Patel-Schneider, L. Alperin Resnick, and A. Borgida. Living with CLASSIC: when and how to use a KL-ONE-like language. In J. Sowa, editor, Principles of Semantic Networks, Morgan Kaufmann Publishers, Inc., 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Davidson</author>
</authors>
<title>Essays on Actions and Events.</title>
<date>1982</date>
<publisher>Oxford University Press,</publisher>
<marker>[5]</marker>
<rawString>D. Davidson. Essays on Actions and Events. Oxford University Press, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Devanbu</author>
<author>D Litman</author>
</authors>
<title>Plan-Based Terminological Reasoning.</title>
<date>1991</date>
<booktitle>Proceedings of KR 91,</booktitle>
<location>Boston.</location>
<note>To appear in</note>
<marker>[6]</marker>
<rawString>P. Devanbu and D. Litman. Plan-Based Terminological Reasoning. 1991. To appear in Proceedings of KR 91, Boston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Di Eugenio</author>
</authors>
<title>A language for representing action descriptions. Preliminary Thesis Proposal,</title>
<date>1990</date>
<publisher>Manuscript.</publisher>
<institution>University of Pennsylvania,</institution>
<contexts>
<context position="2969" citStr="[7]" startWordPosition="501" endWordPosition="501">lacing the plank anywhere between the two ladders: this shows that in a) the agent must be inferring the proper position for the plank from the expressed why &amp;quot;to create a simple scaffold&amp;quot;. My concern is with representations that allow specification of both how&apos;s and why&apos;s, and with reasoning that allows inferences such as the above to be made. In the rest of the paper, I will argue that a hybrid representation formalism is best suited for the knowledge I need to represent. 2 A hybrid action representation formalism As I have argued elsewhere based on analysis of naturally occurring data [14], [7], actions - action types, to be precise - must be part of the underlying ontology of the representation formalism; partial action descriptions must be taken as basic; not only must the usual participants in an action such as agent or patient be represented, but also means, manner, direction, extent etc. Given these basic assumptions, it seems that knowledge about actions falls into the following two categories: 1. Terminological knowledge about an actiontype: its participants and its relation to other action-types that it either specializes or abstracts - e.g. slice specializes cut, loosen a s</context>
</contexts>
<marker>[7]</marker>
<rawString>B. Di Eugenio. A language for representing action descriptions. Preliminary Thesis Proposal, University of Pennsylvania, 1990. Manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Fikes</author>
<author>N Nilsson</author>
</authors>
<title>A new approach to the application of theorem proving to problem solving.</title>
<date>1971</date>
<journal>Artificial Intelligence,</journal>
<pages>2--189</pages>
<contexts>
<context position="778" citStr="[8]" startWordPosition="119" endWordPosition="119">n.edu 1 Introduction The need to represent actions arises in many different areas of investigation, such as philosophy [5], semantics [10], and planning. In the first two areas, representations are generally developed without any computational concerns. The third area sees action representation mainly as functional to the more general task of reaching a certain goal: actions have often been represented by a predicate with some arguments, such as move(John, blockl, rooml, rooms), augmented with a description of its effects and of what has to be true in the world for the action to be executable [8]. Temporal relations between actions [1], and the generation relation [12], [2] have also been explored. However, if we ever want to be able to give instructions in NL to active agents, such as robots and animated figures, we should start looking at the characteristics of action descriptions in NL, and devising formalisms that should be able to represent these characteristics, at least in principle. NL action descriptions are complex, and so are the inferences the agent interpreting them is expected to draw. As far as the complexity of action descriptions goes, consider: Ex. 1 Using a paint ro</context>
</contexts>
<marker>[8]</marker>
<rawString>R. Fikes and N. Nilsson. A new approach to the application of theorem proving to problem solving. Artificial Intelligence, 2:189-208, 1971.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Goldman</author>
</authors>
<title>A Theory of Human Action.</title>
<date>1970</date>
<publisher>Princeton University Press,</publisher>
<contexts>
<context position="4638" citStr="[9]" startWordPosition="770" endWordPosition="770">this knowledge is not terminological; in Ex. 3 Turn the screw counterclockwise but don&apos;t loosen it completely. the modifier not ... completely does not affect the fact that don&apos;t loosen it completely is a loosening action: only its default culmination condition is affected. Also, non-terminological knowledge must include information about relations between action-types: temporal, generation, enablement, and testing, where by testing I refer to the relation between two actions, one of which is a test on the outcome or execution of the other. The generation relation was introduced by Goldman in [9], and then used in planning by [1], [12], [2]: it is particularly interesting with respect to the representation of how&apos;s and why&apos;s, because it appears to be the relation holding between an intentional description of an action and its executable counterpart - see [12]. This knowledge can be seen as common-sense planning knowledge, which includes facts such as to loosen a screw, you have to turn it counterclockwise, but not recipes to achieve a certain goal [2], such as how to assemble a piece of furniture. The distinction between terminological and nonterminological knowledge was put forward i</context>
</contexts>
<marker>[9]</marker>
<rawString>A. Goldman. A Theory of Human Action. Princeton University Press, 1970.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Jackendoff</author>
</authors>
<title>Semantics and Cognition.</title>
<date>1983</date>
<booktitle>Current Studies in Linguistics Series, The</booktitle>
<publisher>MIT Press,</publisher>
<marker>[10]</marker>
<rawString>R. Jackendoff. Semantics and Cognition. Current Studies in Linguistics Series, The MIT Press, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Moens</author>
<author>M Steedman</author>
</authors>
<title>Temporal Ontology and Temporal Reference.</title>
<date>1988</date>
<journal>Computational Linguistics,</journal>
<pages>14--2</pages>
<contexts>
<context position="4000" citStr="[11]" startWordPosition="668" endWordPosition="668">gical knowledge about an actiontype: its participants and its relation to other action-types that it either specializes or abstracts - e.g. slice specializes cut, loosen a screw carefully specializes loosen a screw. 2. Non-terminological knowledge. First of all, knowledge about the effects expected to occur This research was supported by DARPA grant no. N0014- What executable means is debatable: see for example [12], 85 -K0018. P. 63ff. 333 when an action of a given type is performed. Because effects may occur during the performance of an action, the basic aspectual profile of the action-type [11] should also be included. Clearly, this knowledge is not terminological; in Ex. 3 Turn the screw counterclockwise but don&apos;t loosen it completely. the modifier not ... completely does not affect the fact that don&apos;t loosen it completely is a loosening action: only its default culmination condition is affected. Also, non-terminological knowledge must include information about relations between action-types: temporal, generation, enablement, and testing, where by testing I refer to the relation between two actions, one of which is a test on the outcome or execution of the other. The generation rel</context>
</contexts>
<marker>[11]</marker>
<rawString>M. Moens and M. Steedman. Temporal Ontology and Temporal Reference. Computational Linguistics, 14(2):15-28, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pollack</author>
</authors>
<title>Inferring domain plans in questionanswering.</title>
<date>1986</date>
<tech>PhD thesis,</tech>
<institution>University of Pennsylvania,</institution>
<contexts>
<context position="852" citStr="[12]" startWordPosition="130" endWordPosition="130">nt areas of investigation, such as philosophy [5], semantics [10], and planning. In the first two areas, representations are generally developed without any computational concerns. The third area sees action representation mainly as functional to the more general task of reaching a certain goal: actions have often been represented by a predicate with some arguments, such as move(John, blockl, rooml, rooms), augmented with a description of its effects and of what has to be true in the world for the action to be executable [8]. Temporal relations between actions [1], and the generation relation [12], [2] have also been explored. However, if we ever want to be able to give instructions in NL to active agents, such as robots and animated figures, we should start looking at the characteristics of action descriptions in NL, and devising formalisms that should be able to represent these characteristics, at least in principle. NL action descriptions are complex, and so are the inferences the agent interpreting them is expected to draw. As far as the complexity of action descriptions goes, consider: Ex. 1 Using a paint roller or brush, apply paste to the wall, starting at the ceiling line and p</context>
<context position="3815" citStr="[12]" startWordPosition="635" endWordPosition="635">be represented, but also means, manner, direction, extent etc. Given these basic assumptions, it seems that knowledge about actions falls into the following two categories: 1. Terminological knowledge about an actiontype: its participants and its relation to other action-types that it either specializes or abstracts - e.g. slice specializes cut, loosen a screw carefully specializes loosen a screw. 2. Non-terminological knowledge. First of all, knowledge about the effects expected to occur This research was supported by DARPA grant no. N0014- What executable means is debatable: see for example [12], 85 -K0018. P. 63ff. 333 when an action of a given type is performed. Because effects may occur during the performance of an action, the basic aspectual profile of the action-type [11] should also be included. Clearly, this knowledge is not terminological; in Ex. 3 Turn the screw counterclockwise but don&apos;t loosen it completely. the modifier not ... completely does not affect the fact that don&apos;t loosen it completely is a loosening action: only its default culmination condition is affected. Also, non-terminological knowledge must include information about relations between action-types: tempora</context>
</contexts>
<marker>[12]</marker>
<rawString>M. Pollack. Inferring domain plans in questionanswering. PhD thesis, University of Pennsylvania, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Vilain</author>
</authors>
<title>The Restricted Language Architecture of a Hybrid Representation System. In</title>
<date>1985</date>
<booktitle>IJCA I-85,</booktitle>
<contexts>
<context position="5373" citStr="[13]" startWordPosition="894" endWordPosition="894">, because it appears to be the relation holding between an intentional description of an action and its executable counterpart - see [12]. This knowledge can be seen as common-sense planning knowledge, which includes facts such as to loosen a screw, you have to turn it counterclockwise, but not recipes to achieve a certain goal [2], such as how to assemble a piece of furniture. The distinction between terminological and nonterminological knowledge was put forward in the past as the basis of hybrid KR system, such as those that stemmed from the KL-ONE formalism, for example KRYPTON [3], KL-TWO [13], and more recently CLASSIC [4]. Such systems provide an assertional part, or A-Box, used to assert facts or beliefs, and a terminological part, or T-Box, that accounts for the meaning of the complex terms used in these assertions. In the past however, it has been the case that terms defined in the T-box have been taken to correspond to noun phrases in Natural Language, while verbs are mapped onto the predicates used in the assertions stored in the A-box. What I am proposing here is that, to represent action-types, verb phrases too have to map to concepts in the T-Box. I am advocating a 1:1 ma</context>
</contexts>
<marker>[13]</marker>
<rawString>M. Vilain. The Restricted Language Architecture of a Hybrid Representation System. In IJCA I-85, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Webber</author>
<author>B Di Eugenio</author>
</authors>
<title>Free Adjuncts in Natural Language Instructions.</title>
<date>1990</date>
<booktitle>In Proceedings Thirteenth International Conference on Computational Linguistics, CO LING 90,</booktitle>
<pages>395--400</pages>
<contexts>
<context position="2964" citStr="[14]" startWordPosition="500" endWordPosition="500">d by placing the plank anywhere between the two ladders: this shows that in a) the agent must be inferring the proper position for the plank from the expressed why &amp;quot;to create a simple scaffold&amp;quot;. My concern is with representations that allow specification of both how&apos;s and why&apos;s, and with reasoning that allows inferences such as the above to be made. In the rest of the paper, I will argue that a hybrid representation formalism is best suited for the knowledge I need to represent. 2 A hybrid action representation formalism As I have argued elsewhere based on analysis of naturally occurring data [14], [7], actions - action types, to be precise - must be part of the underlying ontology of the representation formalism; partial action descriptions must be taken as basic; not only must the usual participants in an action such as agent or patient be represented, but also means, manner, direction, extent etc. Given these basic assumptions, it seems that knowledge about actions falls into the following two categories: 1. Terminological knowledge about an actiontype: its participants and its relation to other action-types that it either specializes or abstracts - e.g. slice specializes cut, loose</context>
</contexts>
<marker>[14]</marker>
<rawString>B. Webber and B. Di Eugenio. Free Adjuncts in Natural Language Instructions. In Proceedings Thirteenth International Conference on Computational Linguistics, CO LING 90, pages 395-400, 1990.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>