<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.485178">
<title confidence="0.982088">
Supervised Sense Tagging using Support Vector Machines
</title>
<author confidence="0.998944">
Clara Cabezas, Philip Resnik, and Jessica Stevens
</author>
<affiliation confidence="0.999497">
Dept. of Linguistics and Institute for Advanced Computer Studies
University of Maryland, College Park, MD 20742 USA
</affiliation>
<email confidence="0.99611">
fclarac,resnik,stevenjcl@umiacs.umd.edu
</email>
<sectionHeader confidence="0.980009" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999507">
We describe the University of Maryland&apos;s su-
pervised sense tagger, which participated in the
SENSEVAL-2 lexical sample evaluations for En-
glish, Spanish, and Swedish; we also present un-
official results for Basque. We designed a highly
modular combination of language-independent
feature extraction and supervised learning us-
ing support vector machines in order to permit
rapid ramp-up, language independence, and ca-
pability for future expansion.
</bodyText>
<sectionHeader confidence="0.99551" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999962289473684">
The SENSEVAL-2 exercise provided an unprece-
dented opportunity to explore word sense dis-
ambiguation (WSD) in a common evaluation
framework for a large number of languages. In
past work, we have focused on unsupervised
methods for English, taking advantage of the
WordNet hierarchy and sometimes also selec-
tional preferences between predicates and argu-
ments (Resnik, 1997; Resnik, 1999). In the cur-
rent exercise, however, WordNet-like sense hi-
erarchies were not necessarily going to be avail-
able for all languages, and the predominance
of lexical selection tasks (rather than all-words
tasks) suggested adopting a disambiguation ap-
proach capable of exploiting manually anno-
tated training data. These considerations mo-
tivated a system design based on supervised
learning, where senses to be predicted did not
need to be treated as part of a semantic hierar-
chy.
Our design was also motivated by the role of
semantic selection techniques in our longer term
research agenda. In the context of our group&apos;s
work on cross-language information retrieval
and machine translation applications (Resnik et
al., 2001; Cabezas et al., 2001), lexical selection
— that is, choosing the right target-language
word given a source-language word in context
— is a crucial task. Because the lexical selec-
tion problem is extremely similar to sense selec-
tion, and because this was our first foray into
supervised methods, we took advantage of the
opportunity to construct an architecture that
will support both tasks.
In the sections that follow, we lay out
our system architecture, briefly summarize our
SENSEVAL-2 results, and discuss our plans for
future work.
</bodyText>
<sectionHeader confidence="0.915221" genericHeader="method">
2 System Architecture
</sectionHeader>
<bodyText confidence="0.9999784">
UMD&apos;s system follows the classic supervised
learning paradigm that, for WSD, is perhaps
best exemplified by Yarowsky&apos;s (1993) work.
Each word in the vocabulary is considered an
independent classification problem. First, an-
notated training instances for the ambiguous
word are analyzed so that each instance can
be represented as a collection of feature-value
pairs labeled with the correct category. Then,
these data are used for parameter estimation
within a supervised learning framework in or-
der to produce a trained classifier. Finally, the
trained classifier is given previously unseen test
instances and for each instance it predicts what
the appropriate category label should be.
</bodyText>
<subsectionHeader confidence="0.989247">
2.1 Contextual Features
</subsectionHeader>
<bodyText confidence="0.9996573">
We began by tokenizing all the training in-
stances using a simple language-specific tok-
enizer. Features were then defined in terms of
the presence of tokens either within a wide con-
text or at a certain position to the right or left
of the word being disambiguated.
In detail, let T be the set of unique tokens
found in the full set of training data (all train-
ing instances), plus the special token UNKNOWN,
which replaces any token in test data that was
</bodyText>
<page confidence="0.997989">
59
</page>
<bodyText confidence="0.996938826086956">
never seen during training. Define .Fwide = T.
A feature f E Twide will be considered present
and have a non-zero value if f appears any-
where in the wide context of the word being
disambiguated. For example, if we were disam-
biguating the word training that appears in the
first sentence of this paragraph, using the entire
paragraph as the wide context, then there would
be non-zero values for features WE, BEGAN, and
every other word in the paragraph. That is,
features correspond to surrounding words.1
Let E = {L3, L2, Li, Ri,R2, R3}7 signifying
the locations &amp;quot;three tokens to the left&amp;quot;, &amp;quot;two to-
kens to the left&amp;quot;, ..., &amp;quot;three tokens to the right&amp;quot;,
and define .Feolloe = {1:t I 1 E .0 and t E 7}. A
feature 1:t E Ycolloc will be considered present
and have a non-zero value if token t appears
at position 1 relative to the word being disam-
biguated. For example, if we were disambiguat-
ing the word training that appears in the first
sentence of this section, there would be non-zero
values for the features L3 :tokenizing, L2 : all,
Li :the, Li :instances, L2 :using, and L3: a.
</bodyText>
<subsectionHeader confidence="0.988153">
2.2 Feature Weights
</subsectionHeader>
<bodyText confidence="0.998685808510638">
The value associated with each feature is a
weight indicating how useful the feature is likely
to be in disambiguation, analogous to the term
weights used in representing documents as fea-
ture vectors for information retrieval.
In detail, let us designate the full feature set
as-r ll 1.71.
wide U Fcooc, and let NF =
Clearly some features are more useful than oth-
ers. For example, the feature into (word into
appearing anywhere in the context) is unlikely
to help distinguish among senses, although the
feature RI: into (word into appearing one word
to the right) might be useful for disambiguat-
ing among the senses of some verbs. In order to
assign weights to features based on their likely
utility, we follow a strategy similar to what is
done in information retrieval, defining inverse
category frequency (ICF), by analogy with in-
verse document frequency (IDF), as a function
of how many distinct categories a feature ap-
pears with in training data.
&apos;For SENSEVAL- 2 , we defined the surrounding context
for wide contexts as being anywhere within the test in-
stance, because instances comprised only a sentence or
two. In a more general setting the context could be de-
fined as a window of ±50 words, ±100 words, the entire
document, etc.
Specifically, if we are disambiguating a word
w with senses S = {81,32, , sN„}, then we de-
fine ICF,D(f ) = log(ATZ/N,v) where Naf, is the
number of distinct elements of S that ever co-
occur with feature f in the training data for
word w. For example, if a word has five senses,
and the feature L1 : the appears in some train-
ing instance for each of the five senses, then
ICF,(Li :the) = — log(5/5) = 0, correctly in-
dicating that this feature is not at all useful
for disambiguating among the five senses of this
word. The lower NI, is, the greater the value of
the ICF(f) value and hence the greater weight
accorded this feature.
Training and test instances are represented as
Ny-ary feature vectors: given a training or test
instance for a word w, the vector representa-
tion is defined by v[f] = ICF(f) if f E .T is
present, and zero otherwise.
</bodyText>
<subsectionHeader confidence="0.991906">
2.3 Learning Framework
</subsectionHeader>
<bodyText confidence="0.999834923076923">
Once training and test instances are represented
as feature vectors, it becomes possible to ex-
ploit any number of existing supervised learn-
ing algorithms. In general, such algorithms take
a set {(vi, ci), (v2, c2), , (vN, cN)} of training
instances, and produce a classifier that takes a
feature vector v as input and return a distri-
bution or confidence function over the possible
categories.
For SENSEVAL-2, we selected support vec-
tor machines (SVMs) as the supervised learn-
ing framework. We were motivated by the fact
that SVMs have been shown to achieve high per-
formance and work efficiently in environments
where there are very large numbers of features,
and also by the existence of a good off-the-
shelf implementation, SVM-Light, available for
research purposes (Joachims, 1999; Joachims,
1998).2
SVM learning is appropriate for binary clas-
sification tasks, rather than the multi-way clas-
sification needed for disambiguating among n
senses. For each word in the lexical sample
tasks, therefore, we constructed a family of
SVM classifiers, one for each of the word&apos;s Nw
senses. All positive training examples for a
</bodyText>
<footnote confidence="0.9928802">
2 Hearst (1998) presents a collection of brief
and illuminating discussions of SVMs; see
http://www.computer.org/intelligent/ex1998/pdf/x4018.pdf.
SVM-Light is available at http://www-ai.cs.uni-
dortmund.de/svm_light.
</footnote>
<page confidence="0.967762">
60
</page>
<table confidence="0.999926714285714">
Language Precision (%) Recall (%)
English (coarse) 64.3 64.3
English (fine) 56.8 56.8
Spanish (fine) 62.7 62.7
Swedish (mixed) 65.6 65.6
Swedish (fine) 61.1 61.1
Basque (fine) 70.3 70.3
</table>
<tableCaption confidence="0.8900375">
Table 1: UMD-SST lexical sample results
sense si of w were treated as negative training
</tableCaption>
<bodyText confidence="0.991631625">
examples for all the other senses j i.
In the testing phase, we convert test instances
for word to into feature vectors, and we then we
run these vectors through the SVM classifiers
for {S1, S2,.. sNJ-. For each instance, we se-
lect the sense for which the SVM classifier&apos;s re-
sponse is most strongly &amp;quot;yes&amp;quot; (or, equivalently,
most weakly &amp;quot;no&amp;quot;).
</bodyText>
<sectionHeader confidence="0.979161" genericHeader="method">
3 SENSEVAL-2 Results
</sectionHeader>
<bodyText confidence="0.999953333333334">
Table 1 shows the performance of UMD&apos;s su-
pervised sense tagger (UMD-SST) for the lex-
ical sample tasks in four languages. The fig-
ures for English, Spanish, and Swedish are offi-
cial SENSEVAL-2 results; the figures for Basque
are unofficial results kindly computed by the
Basque task organizers after SENSEVAL-2 be-
cause our Basque responses were not submitted
in time for official evaluation.
In general, we were quite pleased with the re-
sults, particularly since this was our first time
participating in SENSEVAL. UMD-SST turned
in a solid performance in comparison with the
baselines and other systems, with essentially
no language-specific alterations necessary other
than those required for tokenization. This en-
abled us to participate in system evaluation for
more languages than any site except JHU. We
consider this a good starting point for our fur-
ther investigations, which we now briefly de-
scribe.
</bodyText>
<sectionHeader confidence="0.999171" genericHeader="method">
4 Future Work
</sectionHeader>
<bodyText confidence="0.999966379310345">
Using the current system as a starting point,
we are engaged in three lines of further investi-
gation: linguistically richer contextual features,
corpus-dependent expansion of feature vectors,
and lexical selection via supervised learning.
In our preliminary tests using training and
development data, we experimented first with
using Ywide as the feature set, and obtained sig-
nificant improvements when we added Ycolloc
in order to capture collocations and other local
contextual features. In our follow-up efforts we
plan to use broad-coverage parsing to create a
set of features augmented further by grammat-
ical relations, thus capturing collocations medi-
ated by syntactic structure. For example, al-
though our current feature vectors could not
represent the presence of the word tagger as a
nearby collocate of the word describe in the ab-
stract of this paper, syntactically richer repre-
sentations of this context for the verb describe
would include the feature object=&apos;tagger&apos;.
Use of syntactic collocates will require broad-
coverage parsing in all the languages of inter-
est in order to identify grammatical relations;
for this we will take advantage of our other
work at Maryland on bootstrapping stochastic
parsers for new languages using parallel corpora
(Cabezas et al., 2001).
In our preliminary efforts we were not sur-
prised to find that sparseness of data was
a problem. Although we expect that some
improvements may be obtained by collapsing
across word variants — e.g. via morphologi-
cal equivalence classes or stemming we also
plan to focus our efforts on semantic expansion,
using document expansion techniques we have
developed in our research on cross-language in-
formation retrieval (Levow et al., 2001). We
have implemented a variant of the architecture
in which training contexts are used as queries
to a comparable corpus in order to retrieve re-
lated documents. The features from these docu-
ments are then added to the context representa-
tions, providing semantically enhanced feature
vectors. Evaluation of this approach using SEN-
SEVAL data is in progress.
Our third avenue of investigation focuses on
the use of our supervised WSD infrastructure
to address problems of lexical selection in ma-
chine translation. Empirically, there is a close
relationship between sense distinctions and pat-
terns of lexicalization across languages (Resnik
and Yarowsky, 1999). And operationally, there
is no real difference between labeling a word
with a sense tag from a monolingual dictionary
and labeling that word with a translation from a
bilingual dictionary. Using WSD techniques for
lexical selection primarily requires solving two
</bodyText>
<page confidence="0.997542">
61
</page>
<bodyText confidence="0.999969368421053">
problems. The first problem is acquisition of
annotated training data, and in this case large
corpora of translation-labeled words in context
can be created by obtaining parallel corpora,
performing word-level alignment, and labeling
each word with its correspondent in the other
language; this problem is already solved as part
of our infrastructure for research on statistical
machine translation (Cabezas et al., 2001). The
second problem is one of scalability: the ap-
proach we have described requires a separate
dassifer for every sense (or, now, every possi-
ble word-level translation) of every source lan-
guage word. This remains an open issue, but we
are optimistic about rapid developments in this
area since scaling up to large vocabularies is a
problem shared by everybody who wishes to use
supervised WSD techniques in a broad-coverage
setting.
</bodyText>
<sectionHeader confidence="0.999576" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999684363636364">
University of Maryland&apos;s sense tagger repre-
sents a classic instance of the supervised learn-
ing approach. At the same time, we have made
architectural choices that promote language in-
dependence, modularity, extensibility, and scal-
ability, and in a relatively short time period we
succeeded in putting together an implementa-
tion that performs quite credibly among an im-
pressive collection of competitors. We are en-
couraged by the results and we look forward to
participating in further SENSEVAL exercises.
</bodyText>
<sectionHeader confidence="0.997282" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999951375">
This work was supported in part by De-
partment of Defense contract MDA90496C1250
and DARPA/ITO Cooperative Agreement
N660010028910. We&apos;re very grateful to all the
SENSEVAL-2 organizers and task organizers for
their hard work, to Thorsten Joachims for mak-
ing SVM-Light available, and to David Mar-
tinez for computing our results for Basque.
</bodyText>
<sectionHeader confidence="0.999261" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999816255319149">
Clara Cabezas, Bonnie Dorr, and Philip Resnik.
2001. Spanish language processing at Univer-
sity of Maryland: Building infrastructure for
multilingual applications. In Proceedings of
the Second International Workshop on Span-
ish Language Processing and Language Tech-
nologies (SLPLT-2), Jaen, Spain, September.
Marti A. Hearst. 1998. Trends and controver-
sies: Support vector machines. IEEE Intelli-
gent Systems, 13(4):18-28.
Thorsten Joachims. 1998. Text categorization
with support vector machines: Learning with
many relevant features. In Proceedings of the
European Conference on Machine Learning.
Springer.
Thorsten Joachims. 1999. Making large-scale
SVM learning practical. In B. Scholkopf,
C. Burges, and A. Smola, editors, Advances
in Kernel Methods - Support Vector Learn-
ing. MIT Press.
Gina-Anne Levow, Douglas Oard, and Philip
Resnik. 2001. Rapidly retargetable interac-
tive translingual retrieval. In Human Lan-
guage Technology Conference (HLT-2001),
San Diego, CA, March.
Philip Resnik and David Yarowsky. 1999.
Distinguishing systems and distinguishing
senses: New evaluation methods for word
sense disambiguation. Natural Language En-
gineering, 5(2):113-133.
Philip Resnik, Douglas Oard, and Gina Levow.
2001. Improved cross-language retrieval us-
ing backoff translation. In Human Lan-
guage Technology Conference (HLT-2001),
San Diego, March.
Philip Resnik. 1997. Selectional preference
and sense disambiguation. In ANLP Work-
shop on Tagging Text with Lexical Semantics,
Washington, D.C., April.
Philip Resnik. 1999. Semantic similarity in
a taxonomy: An information-based measure
and its application to problems of ambiguity
in natural language. Journal of Artificial In-
telligence Research (JAM), 11:95-130.
David Yarowsky. 1993. One sense per colloca-
tion. ARPA Workshop on Human Language
Technology, March. Princeton.
</reference>
<page confidence="0.999189">
62
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.587846">
<title confidence="0.995988">Supervised Sense Tagging using Support Vector Machines</title>
<author confidence="0.995856">Philip Resnik Cabezas</author>
<affiliation confidence="0.8104075">Dept. of Linguistics and Institute for Advanced Computer University of Maryland, College Park, MD 20742</affiliation>
<email confidence="0.99983">fclarac,resnik,stevenjcl@umiacs.umd.edu</email>
<abstract confidence="0.995785636363636">We describe the University of Maryland&apos;s supervised sense tagger, which participated in the sample evaluations for English, Spanish, and Swedish; we also present unofficial results for Basque. We designed a highly modular combination of language-independent feature extraction and supervised learning using support vector machines in order to permit rapid ramp-up, language independence, and capability for future expansion.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Clara Cabezas</author>
<author>Bonnie Dorr</author>
<author>Philip Resnik</author>
</authors>
<title>Spanish language processing at University of Maryland: Building infrastructure for multilingual applications.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second International Workshop on Spanish Language Processing and Language Technologies (SLPLT-2),</booktitle>
<location>Jaen, Spain,</location>
<contexts>
<context position="1853" citStr="Cabezas et al., 2001" startWordPosition="269" endWordPosition="272">anguages, and the predominance of lexical selection tasks (rather than all-words tasks) suggested adopting a disambiguation approach capable of exploiting manually annotated training data. These considerations motivated a system design based on supervised learning, where senses to be predicted did not need to be treated as part of a semantic hierarchy. Our design was also motivated by the role of semantic selection techniques in our longer term research agenda. In the context of our group&apos;s work on cross-language information retrieval and machine translation applications (Resnik et al., 2001; Cabezas et al., 2001), lexical selection — that is, choosing the right target-language word given a source-language word in context — is a crucial task. Because the lexical selection problem is extremely similar to sense selection, and because this was our first foray into supervised methods, we took advantage of the opportunity to construct an architecture that will support both tasks. In the sections that follow, we lay out our system architecture, briefly summarize our SENSEVAL-2 results, and discuss our plans for future work. 2 System Architecture UMD&apos;s system follows the classic supervised learning paradigm t</context>
<context position="10939" citStr="Cabezas et al., 2001" startWordPosition="1773" endWordPosition="1776">d by syntactic structure. For example, although our current feature vectors could not represent the presence of the word tagger as a nearby collocate of the word describe in the abstract of this paper, syntactically richer representations of this context for the verb describe would include the feature object=&apos;tagger&apos;. Use of syntactic collocates will require broadcoverage parsing in all the languages of interest in order to identify grammatical relations; for this we will take advantage of our other work at Maryland on bootstrapping stochastic parsers for new languages using parallel corpora (Cabezas et al., 2001). In our preliminary efforts we were not surprised to find that sparseness of data was a problem. Although we expect that some improvements may be obtained by collapsing across word variants — e.g. via morphological equivalence classes or stemming we also plan to focus our efforts on semantic expansion, using document expansion techniques we have developed in our research on cross-language information retrieval (Levow et al., 2001). We have implemented a variant of the architecture in which training contexts are used as queries to a comparable corpus in order to retrieve related documents. The</context>
<context position="12719" citStr="Cabezas et al., 2001" startWordPosition="2047" endWordPosition="2050">word with a sense tag from a monolingual dictionary and labeling that word with a translation from a bilingual dictionary. Using WSD techniques for lexical selection primarily requires solving two 61 problems. The first problem is acquisition of annotated training data, and in this case large corpora of translation-labeled words in context can be created by obtaining parallel corpora, performing word-level alignment, and labeling each word with its correspondent in the other language; this problem is already solved as part of our infrastructure for research on statistical machine translation (Cabezas et al., 2001). The second problem is one of scalability: the approach we have described requires a separate dassifer for every sense (or, now, every possible word-level translation) of every source language word. This remains an open issue, but we are optimistic about rapid developments in this area since scaling up to large vocabularies is a problem shared by everybody who wishes to use supervised WSD techniques in a broad-coverage setting. 5 Conclusions University of Maryland&apos;s sense tagger represents a classic instance of the supervised learning approach. At the same time, we have made architectural cho</context>
</contexts>
<marker>Cabezas, Dorr, Resnik, 2001</marker>
<rawString>Clara Cabezas, Bonnie Dorr, and Philip Resnik. 2001. Spanish language processing at University of Maryland: Building infrastructure for multilingual applications. In Proceedings of the Second International Workshop on Spanish Language Processing and Language Technologies (SLPLT-2), Jaen, Spain, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Trends and controversies: Support vector machines.</title>
<date>1998</date>
<journal>IEEE Intelligent Systems,</journal>
<pages>13--4</pages>
<contexts>
<context position="7897" citStr="Hearst (1998)" startWordPosition="1304" endWordPosition="1305">hat SVMs have been shown to achieve high performance and work efficiently in environments where there are very large numbers of features, and also by the existence of a good off-theshelf implementation, SVM-Light, available for research purposes (Joachims, 1999; Joachims, 1998).2 SVM learning is appropriate for binary classification tasks, rather than the multi-way classification needed for disambiguating among n senses. For each word in the lexical sample tasks, therefore, we constructed a family of SVM classifiers, one for each of the word&apos;s Nw senses. All positive training examples for a 2 Hearst (1998) presents a collection of brief and illuminating discussions of SVMs; see http://www.computer.org/intelligent/ex1998/pdf/x4018.pdf. SVM-Light is available at http://www-ai.cs.unidortmund.de/svm_light. 60 Language Precision (%) Recall (%) English (coarse) 64.3 64.3 English (fine) 56.8 56.8 Spanish (fine) 62.7 62.7 Swedish (mixed) 65.6 65.6 Swedish (fine) 61.1 61.1 Basque (fine) 70.3 70.3 Table 1: UMD-SST lexical sample results sense si of w were treated as negative training examples for all the other senses j i. In the testing phase, we convert test instances for word to into feature vectors, a</context>
</contexts>
<marker>Hearst, 1998</marker>
<rawString>Marti A. Hearst. 1998. Trends and controversies: Support vector machines. IEEE Intelligent Systems, 13(4):18-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Text categorization with support vector machines: Learning with many relevant features.</title>
<date>1998</date>
<booktitle>In Proceedings of the European Conference on Machine Learning.</booktitle>
<publisher>Springer.</publisher>
<contexts>
<context position="7562" citStr="Joachims, 1998" startWordPosition="1250" endWordPosition="1251">ake a set {(vi, ci), (v2, c2), , (vN, cN)} of training instances, and produce a classifier that takes a feature vector v as input and return a distribution or confidence function over the possible categories. For SENSEVAL-2, we selected support vector machines (SVMs) as the supervised learning framework. We were motivated by the fact that SVMs have been shown to achieve high performance and work efficiently in environments where there are very large numbers of features, and also by the existence of a good off-theshelf implementation, SVM-Light, available for research purposes (Joachims, 1999; Joachims, 1998).2 SVM learning is appropriate for binary classification tasks, rather than the multi-way classification needed for disambiguating among n senses. For each word in the lexical sample tasks, therefore, we constructed a family of SVM classifiers, one for each of the word&apos;s Nw senses. All positive training examples for a 2 Hearst (1998) presents a collection of brief and illuminating discussions of SVMs; see http://www.computer.org/intelligent/ex1998/pdf/x4018.pdf. SVM-Light is available at http://www-ai.cs.unidortmund.de/svm_light. 60 Language Precision (%) Recall (%) English (coarse) 64.3 64.3 </context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>Thorsten Joachims. 1998. Text categorization with support vector machines: Learning with many relevant features. In Proceedings of the European Conference on Machine Learning. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making large-scale SVM learning practical.</title>
<date>1999</date>
<booktitle>Advances in Kernel Methods - Support Vector Learning.</booktitle>
<editor>In B. Scholkopf, C. Burges, and A. Smola, editors,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="7545" citStr="Joachims, 1999" startWordPosition="1248" endWordPosition="1249">uch algorithms take a set {(vi, ci), (v2, c2), , (vN, cN)} of training instances, and produce a classifier that takes a feature vector v as input and return a distribution or confidence function over the possible categories. For SENSEVAL-2, we selected support vector machines (SVMs) as the supervised learning framework. We were motivated by the fact that SVMs have been shown to achieve high performance and work efficiently in environments where there are very large numbers of features, and also by the existence of a good off-theshelf implementation, SVM-Light, available for research purposes (Joachims, 1999; Joachims, 1998).2 SVM learning is appropriate for binary classification tasks, rather than the multi-way classification needed for disambiguating among n senses. For each word in the lexical sample tasks, therefore, we constructed a family of SVM classifiers, one for each of the word&apos;s Nw senses. All positive training examples for a 2 Hearst (1998) presents a collection of brief and illuminating discussions of SVMs; see http://www.computer.org/intelligent/ex1998/pdf/x4018.pdf. SVM-Light is available at http://www-ai.cs.unidortmund.de/svm_light. 60 Language Precision (%) Recall (%) English (c</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making large-scale SVM learning practical. In B. Scholkopf, C. Burges, and A. Smola, editors, Advances in Kernel Methods - Support Vector Learning. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gina-Anne Levow</author>
<author>Douglas Oard</author>
<author>Philip Resnik</author>
</authors>
<title>Rapidly retargetable interactive translingual retrieval.</title>
<date>2001</date>
<booktitle>In Human Language Technology Conference (HLT-2001),</booktitle>
<location>San Diego, CA,</location>
<contexts>
<context position="11374" citStr="Levow et al., 2001" startWordPosition="1843" endWordPosition="1846">grammatical relations; for this we will take advantage of our other work at Maryland on bootstrapping stochastic parsers for new languages using parallel corpora (Cabezas et al., 2001). In our preliminary efforts we were not surprised to find that sparseness of data was a problem. Although we expect that some improvements may be obtained by collapsing across word variants — e.g. via morphological equivalence classes or stemming we also plan to focus our efforts on semantic expansion, using document expansion techniques we have developed in our research on cross-language information retrieval (Levow et al., 2001). We have implemented a variant of the architecture in which training contexts are used as queries to a comparable corpus in order to retrieve related documents. The features from these documents are then added to the context representations, providing semantically enhanced feature vectors. Evaluation of this approach using SENSEVAL data is in progress. Our third avenue of investigation focuses on the use of our supervised WSD infrastructure to address problems of lexical selection in machine translation. Empirically, there is a close relationship between sense distinctions and patterns of lex</context>
</contexts>
<marker>Levow, Oard, Resnik, 2001</marker>
<rawString>Gina-Anne Levow, Douglas Oard, and Philip Resnik. 2001. Rapidly retargetable interactive translingual retrieval. In Human Language Technology Conference (HLT-2001), San Diego, CA, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>David Yarowsky</author>
</authors>
<title>Distinguishing systems and distinguishing senses: New evaluation methods for word sense disambiguation.</title>
<date>1999</date>
<journal>Natural Language Engineering,</journal>
<pages>5--2</pages>
<contexts>
<context position="12030" citStr="Resnik and Yarowsky, 1999" startWordPosition="1944" endWordPosition="1947">t of the architecture in which training contexts are used as queries to a comparable corpus in order to retrieve related documents. The features from these documents are then added to the context representations, providing semantically enhanced feature vectors. Evaluation of this approach using SENSEVAL data is in progress. Our third avenue of investigation focuses on the use of our supervised WSD infrastructure to address problems of lexical selection in machine translation. Empirically, there is a close relationship between sense distinctions and patterns of lexicalization across languages (Resnik and Yarowsky, 1999). And operationally, there is no real difference between labeling a word with a sense tag from a monolingual dictionary and labeling that word with a translation from a bilingual dictionary. Using WSD techniques for lexical selection primarily requires solving two 61 problems. The first problem is acquisition of annotated training data, and in this case large corpora of translation-labeled words in context can be created by obtaining parallel corpora, performing word-level alignment, and labeling each word with its correspondent in the other language; this problem is already solved as part of </context>
</contexts>
<marker>Resnik, Yarowsky, 1999</marker>
<rawString>Philip Resnik and David Yarowsky. 1999. Distinguishing systems and distinguishing senses: New evaluation methods for word sense disambiguation. Natural Language Engineering, 5(2):113-133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Douglas Oard</author>
<author>Gina Levow</author>
</authors>
<title>Improved cross-language retrieval using backoff translation.</title>
<date>2001</date>
<booktitle>In Human Language Technology Conference (HLT-2001),</booktitle>
<location>San Diego,</location>
<contexts>
<context position="1830" citStr="Resnik et al., 2001" startWordPosition="265" endWordPosition="268">e available for all languages, and the predominance of lexical selection tasks (rather than all-words tasks) suggested adopting a disambiguation approach capable of exploiting manually annotated training data. These considerations motivated a system design based on supervised learning, where senses to be predicted did not need to be treated as part of a semantic hierarchy. Our design was also motivated by the role of semantic selection techniques in our longer term research agenda. In the context of our group&apos;s work on cross-language information retrieval and machine translation applications (Resnik et al., 2001; Cabezas et al., 2001), lexical selection — that is, choosing the right target-language word given a source-language word in context — is a crucial task. Because the lexical selection problem is extremely similar to sense selection, and because this was our first foray into supervised methods, we took advantage of the opportunity to construct an architecture that will support both tasks. In the sections that follow, we lay out our system architecture, briefly summarize our SENSEVAL-2 results, and discuss our plans for future work. 2 System Architecture UMD&apos;s system follows the classic supervi</context>
</contexts>
<marker>Resnik, Oard, Levow, 2001</marker>
<rawString>Philip Resnik, Douglas Oard, and Gina Levow. 2001. Improved cross-language retrieval using backoff translation. In Human Language Technology Conference (HLT-2001), San Diego, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selectional preference and sense disambiguation.</title>
<date>1997</date>
<booktitle>In ANLP Workshop on Tagging Text with Lexical Semantics,</booktitle>
<location>Washington, D.C.,</location>
<contexts>
<context position="1098" citStr="Resnik, 1997" startWordPosition="153" endWordPosition="154">esigned a highly modular combination of language-independent feature extraction and supervised learning using support vector machines in order to permit rapid ramp-up, language independence, and capability for future expansion. 1 Introduction The SENSEVAL-2 exercise provided an unprecedented opportunity to explore word sense disambiguation (WSD) in a common evaluation framework for a large number of languages. In past work, we have focused on unsupervised methods for English, taking advantage of the WordNet hierarchy and sometimes also selectional preferences between predicates and arguments (Resnik, 1997; Resnik, 1999). In the current exercise, however, WordNet-like sense hierarchies were not necessarily going to be available for all languages, and the predominance of lexical selection tasks (rather than all-words tasks) suggested adopting a disambiguation approach capable of exploiting manually annotated training data. These considerations motivated a system design based on supervised learning, where senses to be predicted did not need to be treated as part of a semantic hierarchy. Our design was also motivated by the role of semantic selection techniques in our longer term research agenda. </context>
</contexts>
<marker>Resnik, 1997</marker>
<rawString>Philip Resnik. 1997. Selectional preference and sense disambiguation. In ANLP Workshop on Tagging Text with Lexical Semantics, Washington, D.C., April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language.</title>
<date>1999</date>
<journal>Journal of Artificial Intelligence Research (JAM),</journal>
<pages>11--95</pages>
<contexts>
<context position="1113" citStr="Resnik, 1999" startWordPosition="155" endWordPosition="156">ly modular combination of language-independent feature extraction and supervised learning using support vector machines in order to permit rapid ramp-up, language independence, and capability for future expansion. 1 Introduction The SENSEVAL-2 exercise provided an unprecedented opportunity to explore word sense disambiguation (WSD) in a common evaluation framework for a large number of languages. In past work, we have focused on unsupervised methods for English, taking advantage of the WordNet hierarchy and sometimes also selectional preferences between predicates and arguments (Resnik, 1997; Resnik, 1999). In the current exercise, however, WordNet-like sense hierarchies were not necessarily going to be available for all languages, and the predominance of lexical selection tasks (rather than all-words tasks) suggested adopting a disambiguation approach capable of exploiting manually annotated training data. These considerations motivated a system design based on supervised learning, where senses to be predicted did not need to be treated as part of a semantic hierarchy. Our design was also motivated by the role of semantic selection techniques in our longer term research agenda. In the context </context>
</contexts>
<marker>Resnik, 1999</marker>
<rawString>Philip Resnik. 1999. Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language. Journal of Artificial Intelligence Research (JAM), 11:95-130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>One sense per collocation.</title>
<date>1993</date>
<booktitle>ARPA Workshop on Human Language Technology,</booktitle>
<location>March. Princeton.</location>
<marker>Yarowsky, 1993</marker>
<rawString>David Yarowsky. 1993. One sense per collocation. ARPA Workshop on Human Language Technology, March. Princeton.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>