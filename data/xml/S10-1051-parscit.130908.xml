<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000926">
<title confidence="0.983414">
UCD-Goggle: A Hybrid System for Noun Compound Paraphrasing
</title>
<author confidence="0.998331">
Guofu Li
</author>
<affiliation confidence="0.974539666666667">
School of Computer Science
and Informatics
University College Dublin
</affiliation>
<email confidence="0.925448">
guofu.li@ucd.ie
</email>
<author confidence="0.966281">
Alejandra Lopez-Fernandez
</author>
<affiliation confidence="0.93815125">
School of Computer Science
and Informatics
University College Dublin
alejandra.lopez
</affiliation>
<email confidence="0.970756">
-fernandez@ucd.ie
</email>
<author confidence="0.996319">
Tony Veale
</author>
<affiliation confidence="0.974443">
School of Computer Science
and Informatics
University College Dublin
</affiliation>
<email confidence="0.966536">
tony.veale@ucd.ie
</email>
<sectionHeader confidence="0.997087" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999896545454545">
This paper addresses the problem of rank-
ing a list of paraphrases associated with a
noun-noun compound as closely as possi-
ble to human raters (Butnariu et al., 2010).
UCD-Goggle tackles this task using se-
mantic knowledge learnt from the Google
n-grams together with human-preferences
for paraphrases mined from training data.
Empirical evaluation shows that UCD-
Goggle achieves 0.432 Spearman correla-
tion with human judgments.
</bodyText>
<sectionHeader confidence="0.999392" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999969641025641">
Noun compounds (NC) are sequences of nouns
acting as a single noun (Downing, 1977). Re-
search on noun compounds involves two main
tasks: NC detection and NC interpretation. The
latter has been studied in the context of many
natural language applications, including question-
answering, machine translation, information re-
trieval, and information extraction.
The use of multiple paraphrases as a semantic
intepretation of noun compounds has recently be-
come popular (Kim and Baldwin, 2006; Nakov
and Hearst, 2006; Butnariu and Veale, 2008;
Nakov, 2008). The best paraphrases are those
which most aptly characterize the relationship be-
tween the modifier noun and the head noun.
The aim of this current work is to provide a
ranking for a list of paraphrases that best approxi-
mates human rankings for the same paraphrases.
We have created a system called UCD-Goggle,
which uses semantic knowledge acquired from
Google n-grams together with human-preferences
mined from training data. Three major com-
ponents are involved in our system: B-score,
produced by a Bayesian algorithm using seman-
tic knowledge from the n-grams corpus with a
smoothing layer of additional inference; Rt-score
captures human preferences observed in the tail
distribution of training data; and Rp-score cap-
tures pairwise paraphrase preferences calculated
from the training data. Our best system for
SemEval-2 task 9 combines all three components
and achieves a Spearman correlation of 0.432 with
human rankings.
This paper is organized as follows: the Bayesian
B-score is introduced in section 2. In section 3
we describe two supervised approaches to mining
the preferences of human raters from training data.
Finally, section 4 presents the results of our empir-
ical evaluation of the UCD-Goggle system.
</bodyText>
<sectionHeader confidence="0.877968" genericHeader="method">
2 Semantic Approach
</sectionHeader>
<subsectionHeader confidence="0.999066">
2.1 Collecting Data
</subsectionHeader>
<bodyText confidence="0.999958333333333">
Google have made their web n-grams, also known
as Web-1T corpus, public via the Linguistic Data
Consortium (Brants and Franz, 2006). This cor-
pus contains sequences of n terms that occur more
than 40 times on the web.
We view the paraphrase task as that of suggest-
ing the right verb phrase for two nouns (But-
nariu and Veale, 2008). Previous work has shown
the n-grams corpus to be a promising resource
for retrieving semantic evidence for this approach.
However, the corpus itself needs to be tailored to
serve our purpose. Since the n-grams corpus is a
collection of raw snippets from the web, together
with their web frequency, certain pre-processing
steps are essential before it can be used as a semi-
structured knowledge base. Following a syntac-
tic pattern approach, snippets in the n-grams that
agree with the following patterns are harvested:
</bodyText>
<listItem confidence="0.99891475">
1. Head VP Mod
2. Head VP DET Mod
3. Head [that1which] VP Mod
4. Head [thatlwhich] VP DET Mod
</listItem>
<bodyText confidence="0.889441">
Here, DET denotes any of the determiners (i.e.,
</bodyText>
<page confidence="0.918322">
230
</page>
<bodyText confidence="0.955839909090909">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 230–233,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
the set of {an, a, the} for English), Head and Mod
are nouns for heads and modifiers, and VP stands
for verb-based paraphrases observed in the test
data. It must be highlighted that, when we collect
snippets for the KB, any Head or Mod that falls out
of the range of the dataset are also accepted via a
process of semantic slippage (to be discussed in
Sect. 2.4). The patterns listed above enable us to
collect examples such as:
</bodyText>
<listItem confidence="0.9991635">
1. “bread containing nut”
2. “pill alleviates the headache”
3. “novel which is about crimes”
4. “problem that involves the students”
</listItem>
<bodyText confidence="0.999065666666667">
After a shallow parse, these snippets are formal-
ized into the triple format hHead, Para, Modi.
The sample snippets above are represented as:
</bodyText>
<listItem confidence="0.998613">
1. hbread, contain, nuti
2. hpill, alleviate, headachei
3. hnovel, be about, crimei
4. hproblem, involve, studenti
</listItem>
<bodyText confidence="0.9992195">
We use kHead, Para, Modk to denote the fre-
quency of hHead, Para, Modi in the n-grams.
</bodyText>
<subsectionHeader confidence="0.998843">
2.2 Loosely Coupled Compound Analysis
</subsectionHeader>
<bodyText confidence="0.981969535714286">
Tens of millions of snippets are harvested and
cleaned up in this way, yet expecting even this
large set to provide decent coverage over the test
data is still unrealistic. We calculated the proba-
bility of an example in the test data to appear in
KB at less than 1%. To overcome the coverage is-
sue, a loosely coupled analysis and representation
of compounds is employed. Despite the fact that
both modifier and head can influence the ranking
of a paraphrase, we believe that either the modifier
or the head is the dominating factor in most cases.
This assumption has been shown to be plausible
by earlier work (Butnariu and Veale, 2008). Thus,
instead of storing complete triples in our KB, we
divide each complete triple into two partial triples
as shown below:
r (Head, Para,?i
Sl h?, Para, Modi
We can also retrieve these partial triples directly
from the n-grams corpus using partial patterns like
“Head Para” and “Para Mod”. However, just as
shorter incomplete patterns can produce a larger
KB, they also accept much more noise. For in-
stance, single-verb paraphrases are very common
among the test data. In these cases, the partial pat-
tern approach would need to harvest snippets with
the form “NN VV” or “VV NN” from 2-grams,
which are too common to be reliable.
</bodyText>
<subsectionHeader confidence="0.990932">
2.3 Probabilistic Framework
</subsectionHeader>
<bodyText confidence="0.97601725">
In the probabilistic framework, we define the B-
score as the conditional probability of a para-
phrase, Para, being suggested for a given com-
pound Comp:
</bodyText>
<equation confidence="0.85075">
B(Para; Comp) ≡ P(Para|Comp) (1)
</equation>
<bodyText confidence="0.5394165">
Using the KB, we can estimate this conditional
probability by applying the Bayes theorem:
</bodyText>
<equation confidence="0.99501925">
P(Comp|Para)P(Para)
P(Para|Comp) =
P(Comp)
(2)
</equation>
<bodyText confidence="0.547062">
The loose-coupling assumption (Sect. 2.2) allows
us to estimate P(Comp) as:
</bodyText>
<equation confidence="0.999257">
P(Comp) ≡ P(Mod ∨ Head). (3)
</equation>
<bodyText confidence="0.715764">
Meanwhile, a priori probabilities such as
P(Para) can be easily inferred from the KB.
</bodyText>
<subsectionHeader confidence="0.949366">
2.4 Inferential Smoothing Layer
</subsectionHeader>
<bodyText confidence="0.9999735">
After applying the loose-coupling technique de-
scribed in Section 2.2, the coverage of the KB
rises to 31.78% (see Figure 1). To further in-
crease this coverage, an inference layer is added
to the system. This layer aims to stretch the con-
tents of the KB via semantic slippage to the KB, as
guided by the maximization of a fitness function.
A WordNet-based similarity matrix is employed
(Seco et al., 2004) to provide a similarity measure
between nouns (so sim(x, x) is 1). Then, a su-
perset of Head or Mod (denoted as H and M re-
spectively) can be extracted by including all nouns
with similarity greater than 0 to any of them in the
test data. Formally, for Head we have:
</bodyText>
<equation confidence="0.996634">
H = {h|sim(h, Head) ≥ 0, Head in dataset}.
(4)
</equation>
<bodyText confidence="0.9999932">
The definition of M is analogous to that of H.
A system of equations is defined to produce al-
ternatives for Head and Mod and their smoothed
corpus frequencies (we show only the functions
for head here):
</bodyText>
<equation confidence="0.9768658">
h0 = Head
fit(h) = sim2(h,hn) × kh,p,?k
hn+1 = arg max fit(h)
h∈H
hHead, Para, Modi →
</equation>
<page confidence="0.980612">
231
</page>
<bodyText confidence="0.999614142857143">
Here, fit(h) is a fitness function of the can-
didate head h, in the context of a paraphrase p.
Empirically, we use h1 for Head and fit(h1) for
IlHead,Para,?Il when calculating the B-score
back in the probabilistic framework (Sect. 2.3). In
theory, we can apply this smoothing step repeat-
edly until convergence is obtained.
</bodyText>
<figureCaption confidence="0.999689">
Figure 1: Comparison on coverage.
</figureCaption>
<bodyText confidence="0.999908125">
This semantic slippage mechanism allows a
computer to infer the missing parts of the KB, by
building a bridge between the limitations of a fi-
nite KB and the knowledge demands of an appli-
cation. Figure 1 above shows how the coverage of
the system increases when using partial matching
and the smoothing technique, over the use of exact
matching with the KB.
</bodyText>
<sectionHeader confidence="0.998584" genericHeader="method">
3 Preferences for Paraphrases
</sectionHeader>
<subsectionHeader confidence="0.981396">
3.1 Tail-based Preference
</subsectionHeader>
<bodyText confidence="0.99990935">
Similar to various types of data studied by social
scientists, the distribution of strings in our corpus
tends to obey Zipf’s law (Zipf, 1936). The same
Zipfian trend was also observed in the compound-
paraphrase dataset: more than 190 out of 250 com-
pounds in the training data have 60% of their para-
phrases in an undiscriminating tail, while 245 of
250 have 50% of their paraphrases in the tail. We
thus assume the existence of a long tail in the para-
phrase list for each compound.
The tail of each paraphrase list can be a valuable
heuristic for modeling human paraphrase prefer-
ences. We refer to this model as the tail-based
preference model. We assume that an occurrence
of a paraphrase is deemed to occur in the tail iff it
is mentioned by the human raters only once. Thus,
the tail preference is defined as the probability that
a paraphrase appears in the non-tail part of the list
for all compounds in the training data. Formally,
it can be expressed as:
</bodyText>
<equation confidence="0.999152">
E δ(c, p)f(c, p)
cEC
f(c, p) (8)
</equation>
<bodyText confidence="0.9477105">
where C is the set of all compounds in the training
data and f(c, p) is the frequency of paraphrase p
on compound c as given by the human raters. The
δ(c, p) is a filter coefficient as shown below:
</bodyText>
<equation confidence="0.899028">
δ(c, p) = { 0, f (c, p) = 1� (9)
</equation>
<bodyText confidence="0.9999853">
The tail-based preference model is simple but
effective when used in conjunction with seman-
tic ranking via the KB acquired from n-grams.
However, an important drawback is that the tail
model assigns a static preference to paraphrase
(i.e., tail preferences are assumed to be context-
independent). More than that, this preference does
not take information from non-tail paraphrases
into consideration. Due to these downsides, we
use pairwise preferences described below.
</bodyText>
<subsectionHeader confidence="0.999816">
3.2 Pairwise Preference
</subsectionHeader>
<bodyText confidence="0.999988555555556">
To fully utilize the training data, we employ an-
other preference mining approach called pairwise
preference modeling. This approach applies the
principle of pairwise comparison (David, 1988)
to determine the rank of a paraphrase inside a list.
We build a pairwise comparison matrix Π for
paraphrases using the values of Equation 10 (here
we have assumed that each of the paraphrases has
been mapped into numeric values):
</bodyText>
<equation confidence="0.90694525">
� n(pi,pj) n(pi,pj)+n(pj,pi), n(pi, pj) &gt; n(pj, pi),
Πi,j =
0, otherwise.
(10)
</equation>
<bodyText confidence="0.977473">
where n(pi, pj) is the relative preferability of pi
to pj. To illustrate the logic behind n(x, y), we
imagine a scenario with three compounds shown
in Table 1:
abor. prob. abor. vote arti. desc.
involve 12 8 3
concern 10 9 5
be about 3 9 15
</bodyText>
<tableCaption confidence="0.998796">
Table 1: An example1 to illustrate n(x, y)
</tableCaption>
<footnote confidence="0.979157333333333">
1In this example, abor. prob. stands for abortion problem,
abor. vote stands for abortion vote, and arti. desc. stands for
artifact description
</footnote>
<equation confidence="0.963046666666667">
Rt(p) =
E
cEC
</equation>
<page confidence="0.98786">
232
</page>
<bodyText confidence="0.870300111111111">
The relative preferability is given by the number
of times that the frequency of pi from human raters
is greater than that of pj. Observing that 1 out of
3 times involve is ranked higher than concern, we
can calculate their relative preferability as:
n(involve, concern) = 1
n(concern, involve) = 2
Once the matrix is built, the preference score for
a paraphrase i is calculated as:
</bodyText>
<equation confidence="0.415405666666667">
Hi,j
(11)
|Pc|
</equation>
<bodyText confidence="0.9939254">
where Pc is the list of paraphrases for a given com-
pound c in the test data. The pairwise preference
puts a paraphrase in the context of its company, so
that the opinions of human raters can be approxi-
mated more precisely.
</bodyText>
<sectionHeader confidence="0.998944" genericHeader="method">
4 Empirical Results
</sectionHeader>
<bodyText confidence="0.995555">
We evaluated our system by tackling theSemEval-
2 task 9 test data. We created three systems with
different combinations of the three components
(B, Rt, Rp). Table 2 below shows the perfor-
mance of UCD-Goggle for each setting:
</bodyText>
<table confidence="0.996115">
System Config Spearman ρ Pearson r
I B+Rt 0.380 0.252
II Rp 0.418 0.375
III B + Rt + Rp 0.432 0.395
* Baseline 0.425 0.344
</table>
<tableCaption confidence="0.994202">
Table 2: Evaluation results on different settings of
</tableCaption>
<bodyText confidence="0.989199058823529">
the UCD-Goggle system.
The first setting is a hybrid system which first
calculates a ranking according to the ngrams cor-
pus and then applies a very simple preference
heuristic (Sect. 2.3 and 3.1). The second setting
simply applies the pairwise preference algorithm
to the training data to learn ranking preferences
(Sect. 3.2). Finally, the third setting integrates
both of these settings in a single approach.
The individual contribution of B-score and Rt
was tested by two-fold cross validation applied to
the training data. The training data was split into
two subsets and preferences were learnt from one
part and then applied to the other. As an unsuper-
vised algorithm, B-score produced Spearman cor-
relation of 0.31 while the Rt-score gave 0.33. We
noticed that more than 78% of the paraphrases had
0 score by Rt. This number not only reconfirmed
the existence of the long-tail phenomenon, but also
suggested that Rt-score alone could hardly capture
the preference on the non-tail part. On the other
hand, with more than 80% chance we could expect
B to produce a non-zero score for a paraphrase,
even if the paraphrase fell out of the topic. When
combined together, B and Rt complemented each
other and improved the performance considerably.
However, this combined effort still could not beat
the pairwise preference Rp or the baseline system,
which had no semantic knowledge involved. The
major limitation of our system is that the seman-
tic approach is totally ignorant of the training data.
In future work, we will intend to use it as a valu-
able resource in both KB construction and ranking
stage.
</bodyText>
<sectionHeader confidence="0.999679" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996546636363636">
T. Brants and A. Franz. 2006. Web 1T 5-gram Version
1. Linguistic Data Consortium.
C. Butnariu and T. Veale. 2008. A concept-centered
approach to noun-compound interpretation. In Proc.
of the 22nd COLING, pages 81–88, Manchester,
UK.
C. Butnariu, S. N. Kim, P. Nakov, D. O´ S´eaghdha,
S. Szpakowicz, and T. Veale. 2010. Semeval-2 task
9: The interpretation of noun compounds using para-
phrasing verbs and prepositions. In Workshop on
Semantic Evaluation, Uppsala, Sweden.
H. A. David. 1988. The Method of Paired Compar-
isons. Oxford University Press, New York.
P. Downing. 1977. On the creation and use of English
compound nouns. In Language 53, pages 810–842.
S. N. Kim and T. Baldwin. 2006. Interpreting seman-
tic relations in noun compounds via verb semantics.
In Proc. of the COLING/ACL, pages 491–498, Mor-
ristown, NJ, USA.
P. Nakov and M. A. Hearst. 2006. Using verbs to char-
acterize noun-noun relations. In Proc. of AIMSA,
pages 233–244.
P. Nakov. 2008. Noun compound interpretation using
paraphrasing verbs: Feasibility study. In Proc. of
the 13th AIMSA, pages 103–117, Berlin, Heidelberg.
Springer-Verlag.
N. Seco, T. Veale, and J. Hayes. 2004. An intrinsic
information content metric for semantic similarity
in WordNet. In Proc. of the 16th ECAI, Valencia,
Spain. John Wiley.
G. K. Zipf. 1936. The Psycho-Biology of Language:
An Introdution to Dynamic Philology. Routledge,
London.
</reference>
<figure confidence="0.617805666666667">
Rp(i; c) =
E
j∈P,
</figure>
<page confidence="0.989896">
233
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.433577">
<title confidence="0.999856">UCD-Goggle: A Hybrid System for Noun Compound Paraphrasing</title>
<author confidence="0.998793">Guofu Li</author>
<affiliation confidence="0.996586666666667">School of Computer Science and Informatics University College Dublin</affiliation>
<email confidence="0.882425">guofu.li@ucd.ie</email>
<author confidence="0.995693">Alejandra Lopez-Fernandez</author>
<affiliation confidence="0.995324333333333">School of Computer Science and Informatics University College Dublin</affiliation>
<email confidence="0.7698985">alejandra.lopez-fernandez@ucd.ie</email>
<author confidence="0.999981">Tony Veale</author>
<affiliation confidence="0.996329333333333">School of Computer Science and Informatics University College Dublin</affiliation>
<email confidence="0.96137">tony.veale@ucd.ie</email>
<abstract confidence="0.974139416666667">This paper addresses the problem of ranking a list of paraphrases associated with a noun-noun compound as closely as possible to human raters (Butnariu et al., 2010). UCD-Goggle tackles this task using semantic knowledge learnt from the Google together with human-preferences for paraphrases mined from training data. Empirical evaluation shows that UCD- Goggle achieves 0.432 Spearman correlation with human judgments.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Brants</author>
<author>A Franz</author>
</authors>
<title>Web 1T 5-gram Version 1. Linguistic Data Consortium.</title>
<date>2006</date>
<contexts>
<context position="2769" citStr="Brants and Franz, 2006" startWordPosition="409" endWordPosition="412">ed from the training data. Our best system for SemEval-2 task 9 combines all three components and achieves a Spearman correlation of 0.432 with human rankings. This paper is organized as follows: the Bayesian B-score is introduced in section 2. In section 3 we describe two supervised approaches to mining the preferences of human raters from training data. Finally, section 4 presents the results of our empirical evaluation of the UCD-Goggle system. 2 Semantic Approach 2.1 Collecting Data Google have made their web n-grams, also known as Web-1T corpus, public via the Linguistic Data Consortium (Brants and Franz, 2006). This corpus contains sequences of n terms that occur more than 40 times on the web. We view the paraphrase task as that of suggesting the right verb phrase for two nouns (Butnariu and Veale, 2008). Previous work has shown the n-grams corpus to be a promising resource for retrieving semantic evidence for this approach. However, the corpus itself needs to be tailored to serve our purpose. Since the n-grams corpus is a collection of raw snippets from the web, together with their web frequency, certain pre-processing steps are essential before it can be used as a semistructured knowledge base. F</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>T. Brants and A. Franz. 2006. Web 1T 5-gram Version 1. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Butnariu</author>
<author>T Veale</author>
</authors>
<title>A concept-centered approach to noun-compound interpretation.</title>
<date>2008</date>
<booktitle>In Proc. of the 22nd COLING,</booktitle>
<pages>81--88</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="1363" citStr="Butnariu and Veale, 2008" startWordPosition="190" endWordPosition="193">ws that UCDGoggle achieves 0.432 Spearman correlation with human judgments. 1 Introduction Noun compounds (NC) are sequences of nouns acting as a single noun (Downing, 1977). Research on noun compounds involves two main tasks: NC detection and NC interpretation. The latter has been studied in the context of many natural language applications, including questionanswering, machine translation, information retrieval, and information extraction. The use of multiple paraphrases as a semantic intepretation of noun compounds has recently become popular (Kim and Baldwin, 2006; Nakov and Hearst, 2006; Butnariu and Veale, 2008; Nakov, 2008). The best paraphrases are those which most aptly characterize the relationship between the modifier noun and the head noun. The aim of this current work is to provide a ranking for a list of paraphrases that best approximates human rankings for the same paraphrases. We have created a system called UCD-Goggle, which uses semantic knowledge acquired from Google n-grams together with human-preferences mined from training data. Three major components are involved in our system: B-score, produced by a Bayesian algorithm using semantic knowledge from the n-grams corpus with a smoothin</context>
<context position="2967" citStr="Butnariu and Veale, 2008" startWordPosition="447" endWordPosition="451">the Bayesian B-score is introduced in section 2. In section 3 we describe two supervised approaches to mining the preferences of human raters from training data. Finally, section 4 presents the results of our empirical evaluation of the UCD-Goggle system. 2 Semantic Approach 2.1 Collecting Data Google have made their web n-grams, also known as Web-1T corpus, public via the Linguistic Data Consortium (Brants and Franz, 2006). This corpus contains sequences of n terms that occur more than 40 times on the web. We view the paraphrase task as that of suggesting the right verb phrase for two nouns (Butnariu and Veale, 2008). Previous work has shown the n-grams corpus to be a promising resource for retrieving semantic evidence for this approach. However, the corpus itself needs to be tailored to serve our purpose. Since the n-grams corpus is a collection of raw snippets from the web, together with their web frequency, certain pre-processing steps are essential before it can be used as a semistructured knowledge base. Following a syntactic pattern approach, snippets in the n-grams that agree with the following patterns are harvested: 1. Head VP Mod 2. Head VP DET Mod 3. Head [that1which] VP Mod 4. Head [thatlwhich</context>
<context position="5388" citStr="Butnariu and Veale, 2008" startWordPosition="857" endWordPosition="860">lions of snippets are harvested and cleaned up in this way, yet expecting even this large set to provide decent coverage over the test data is still unrealistic. We calculated the probability of an example in the test data to appear in KB at less than 1%. To overcome the coverage issue, a loosely coupled analysis and representation of compounds is employed. Despite the fact that both modifier and head can influence the ranking of a paraphrase, we believe that either the modifier or the head is the dominating factor in most cases. This assumption has been shown to be plausible by earlier work (Butnariu and Veale, 2008). Thus, instead of storing complete triples in our KB, we divide each complete triple into two partial triples as shown below: r (Head, Para,?i Sl h?, Para, Modi We can also retrieve these partial triples directly from the n-grams corpus using partial patterns like “Head Para” and “Para Mod”. However, just as shorter incomplete patterns can produce a larger KB, they also accept much more noise. For instance, single-verb paraphrases are very common among the test data. In these cases, the partial pattern approach would need to harvest snippets with the form “NN VV” or “VV NN” from 2-grams, whic</context>
</contexts>
<marker>Butnariu, Veale, 2008</marker>
<rawString>C. Butnariu and T. Veale. 2008. A concept-centered approach to noun-compound interpretation. In Proc. of the 22nd COLING, pages 81–88, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Butnariu</author>
<author>S N Kim</author>
<author>P Nakov</author>
<author>D O´ S´eaghdha</author>
<author>S Szpakowicz</author>
<author>T Veale</author>
</authors>
<title>Semeval-2 task 9: The interpretation of noun compounds using paraphrasing verbs and prepositions.</title>
<date>2010</date>
<booktitle>In Workshop on Semantic Evaluation,</booktitle>
<location>Uppsala,</location>
<marker>Butnariu, Kim, Nakov, S´eaghdha, Szpakowicz, Veale, 2010</marker>
<rawString>C. Butnariu, S. N. Kim, P. Nakov, D. O´ S´eaghdha, S. Szpakowicz, and T. Veale. 2010. Semeval-2 task 9: The interpretation of noun compounds using paraphrasing verbs and prepositions. In Workshop on Semantic Evaluation, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H A David</author>
</authors>
<title>The Method of Paired Comparisons.</title>
<date>1988</date>
<publisher>Oxford University Press,</publisher>
<location>New York.</location>
<contexts>
<context position="10278" citStr="David, 1988" startWordPosition="1704" endWordPosition="1705">njunction with semantic ranking via the KB acquired from n-grams. However, an important drawback is that the tail model assigns a static preference to paraphrase (i.e., tail preferences are assumed to be contextindependent). More than that, this preference does not take information from non-tail paraphrases into consideration. Due to these downsides, we use pairwise preferences described below. 3.2 Pairwise Preference To fully utilize the training data, we employ another preference mining approach called pairwise preference modeling. This approach applies the principle of pairwise comparison (David, 1988) to determine the rank of a paraphrase inside a list. We build a pairwise comparison matrix Π for paraphrases using the values of Equation 10 (here we have assumed that each of the paraphrases has been mapped into numeric values): � n(pi,pj) n(pi,pj)+n(pj,pi), n(pi, pj) &gt; n(pj, pi), Πi,j = 0, otherwise. (10) where n(pi, pj) is the relative preferability of pi to pj. To illustrate the logic behind n(x, y), we imagine a scenario with three compounds shown in Table 1: abor. prob. abor. vote arti. desc. involve 12 8 3 concern 10 9 5 be about 3 9 15 Table 1: An example1 to illustrate n(x, y) 1In th</context>
</contexts>
<marker>David, 1988</marker>
<rawString>H. A. David. 1988. The Method of Paired Comparisons. Oxford University Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Downing</author>
</authors>
<title>On the creation and use of English compound nouns.</title>
<date>1977</date>
<booktitle>In Language 53,</booktitle>
<pages>810--842</pages>
<contexts>
<context position="912" citStr="Downing, 1977" startWordPosition="125" endWordPosition="126">l of Computer Science and Informatics University College Dublin tony.veale@ucd.ie Abstract This paper addresses the problem of ranking a list of paraphrases associated with a noun-noun compound as closely as possible to human raters (Butnariu et al., 2010). UCD-Goggle tackles this task using semantic knowledge learnt from the Google n-grams together with human-preferences for paraphrases mined from training data. Empirical evaluation shows that UCDGoggle achieves 0.432 Spearman correlation with human judgments. 1 Introduction Noun compounds (NC) are sequences of nouns acting as a single noun (Downing, 1977). Research on noun compounds involves two main tasks: NC detection and NC interpretation. The latter has been studied in the context of many natural language applications, including questionanswering, machine translation, information retrieval, and information extraction. The use of multiple paraphrases as a semantic intepretation of noun compounds has recently become popular (Kim and Baldwin, 2006; Nakov and Hearst, 2006; Butnariu and Veale, 2008; Nakov, 2008). The best paraphrases are those which most aptly characterize the relationship between the modifier noun and the head noun. The aim of</context>
</contexts>
<marker>Downing, 1977</marker>
<rawString>P. Downing. 1977. On the creation and use of English compound nouns. In Language 53, pages 810–842.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S N Kim</author>
<author>T Baldwin</author>
</authors>
<title>Interpreting semantic relations in noun compounds via verb semantics.</title>
<date>2006</date>
<booktitle>In Proc. of the COLING/ACL,</booktitle>
<pages>491--498</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="1313" citStr="Kim and Baldwin, 2006" startWordPosition="182" endWordPosition="185">ed from training data. Empirical evaluation shows that UCDGoggle achieves 0.432 Spearman correlation with human judgments. 1 Introduction Noun compounds (NC) are sequences of nouns acting as a single noun (Downing, 1977). Research on noun compounds involves two main tasks: NC detection and NC interpretation. The latter has been studied in the context of many natural language applications, including questionanswering, machine translation, information retrieval, and information extraction. The use of multiple paraphrases as a semantic intepretation of noun compounds has recently become popular (Kim and Baldwin, 2006; Nakov and Hearst, 2006; Butnariu and Veale, 2008; Nakov, 2008). The best paraphrases are those which most aptly characterize the relationship between the modifier noun and the head noun. The aim of this current work is to provide a ranking for a list of paraphrases that best approximates human rankings for the same paraphrases. We have created a system called UCD-Goggle, which uses semantic knowledge acquired from Google n-grams together with human-preferences mined from training data. Three major components are involved in our system: B-score, produced by a Bayesian algorithm using semantic</context>
</contexts>
<marker>Kim, Baldwin, 2006</marker>
<rawString>S. N. Kim and T. Baldwin. 2006. Interpreting semantic relations in noun compounds via verb semantics. In Proc. of the COLING/ACL, pages 491–498, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Nakov</author>
<author>M A Hearst</author>
</authors>
<title>Using verbs to characterize noun-noun relations.</title>
<date>2006</date>
<booktitle>In Proc. of AIMSA,</booktitle>
<pages>233--244</pages>
<contexts>
<context position="1337" citStr="Nakov and Hearst, 2006" startWordPosition="186" endWordPosition="189">Empirical evaluation shows that UCDGoggle achieves 0.432 Spearman correlation with human judgments. 1 Introduction Noun compounds (NC) are sequences of nouns acting as a single noun (Downing, 1977). Research on noun compounds involves two main tasks: NC detection and NC interpretation. The latter has been studied in the context of many natural language applications, including questionanswering, machine translation, information retrieval, and information extraction. The use of multiple paraphrases as a semantic intepretation of noun compounds has recently become popular (Kim and Baldwin, 2006; Nakov and Hearst, 2006; Butnariu and Veale, 2008; Nakov, 2008). The best paraphrases are those which most aptly characterize the relationship between the modifier noun and the head noun. The aim of this current work is to provide a ranking for a list of paraphrases that best approximates human rankings for the same paraphrases. We have created a system called UCD-Goggle, which uses semantic knowledge acquired from Google n-grams together with human-preferences mined from training data. Three major components are involved in our system: B-score, produced by a Bayesian algorithm using semantic knowledge from the n-gr</context>
</contexts>
<marker>Nakov, Hearst, 2006</marker>
<rawString>P. Nakov and M. A. Hearst. 2006. Using verbs to characterize noun-noun relations. In Proc. of AIMSA, pages 233–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Nakov</author>
</authors>
<title>Noun compound interpretation using paraphrasing verbs: Feasibility study.</title>
<date>2008</date>
<booktitle>In Proc. of the 13th AIMSA,</booktitle>
<pages>103--117</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="1377" citStr="Nakov, 2008" startWordPosition="194" endWordPosition="195"> 0.432 Spearman correlation with human judgments. 1 Introduction Noun compounds (NC) are sequences of nouns acting as a single noun (Downing, 1977). Research on noun compounds involves two main tasks: NC detection and NC interpretation. The latter has been studied in the context of many natural language applications, including questionanswering, machine translation, information retrieval, and information extraction. The use of multiple paraphrases as a semantic intepretation of noun compounds has recently become popular (Kim and Baldwin, 2006; Nakov and Hearst, 2006; Butnariu and Veale, 2008; Nakov, 2008). The best paraphrases are those which most aptly characterize the relationship between the modifier noun and the head noun. The aim of this current work is to provide a ranking for a list of paraphrases that best approximates human rankings for the same paraphrases. We have created a system called UCD-Goggle, which uses semantic knowledge acquired from Google n-grams together with human-preferences mined from training data. Three major components are involved in our system: B-score, produced by a Bayesian algorithm using semantic knowledge from the n-grams corpus with a smoothing layer of add</context>
</contexts>
<marker>Nakov, 2008</marker>
<rawString>P. Nakov. 2008. Noun compound interpretation using paraphrasing verbs: Feasibility study. In Proc. of the 13th AIMSA, pages 103–117, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Seco</author>
<author>T Veale</author>
<author>J Hayes</author>
</authors>
<title>An intrinsic information content metric for semantic similarity in WordNet.</title>
<date>2004</date>
<booktitle>In Proc. of the 16th ECAI,</booktitle>
<publisher>John Wiley.</publisher>
<location>Valencia, Spain.</location>
<contexts>
<context position="6996" citStr="Seco et al., 2004" startWordPosition="1124" endWordPosition="1127">-coupling assumption (Sect. 2.2) allows us to estimate P(Comp) as: P(Comp) ≡ P(Mod ∨ Head). (3) Meanwhile, a priori probabilities such as P(Para) can be easily inferred from the KB. 2.4 Inferential Smoothing Layer After applying the loose-coupling technique described in Section 2.2, the coverage of the KB rises to 31.78% (see Figure 1). To further increase this coverage, an inference layer is added to the system. This layer aims to stretch the contents of the KB via semantic slippage to the KB, as guided by the maximization of a fitness function. A WordNet-based similarity matrix is employed (Seco et al., 2004) to provide a similarity measure between nouns (so sim(x, x) is 1). Then, a superset of Head or Mod (denoted as H and M respectively) can be extracted by including all nouns with similarity greater than 0 to any of them in the test data. Formally, for Head we have: H = {h|sim(h, Head) ≥ 0, Head in dataset}. (4) The definition of M is analogous to that of H. A system of equations is defined to produce alternatives for Head and Mod and their smoothed corpus frequencies (we show only the functions for head here): h0 = Head fit(h) = sim2(h,hn) × kh,p,?k hn+1 = arg max fit(h) h∈H hHead, Para, Modi </context>
</contexts>
<marker>Seco, Veale, Hayes, 2004</marker>
<rawString>N. Seco, T. Veale, and J. Hayes. 2004. An intrinsic information content metric for semantic similarity in WordNet. In Proc. of the 16th ECAI, Valencia, Spain. John Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G K Zipf</author>
</authors>
<title>The Psycho-Biology of Language: An Introdution to Dynamic Philology.</title>
<date>1936</date>
<location>Routledge, London.</location>
<contexts>
<context position="8513" citStr="Zipf, 1936" startWordPosition="1397" endWordPosition="1398">vergence is obtained. Figure 1: Comparison on coverage. This semantic slippage mechanism allows a computer to infer the missing parts of the KB, by building a bridge between the limitations of a finite KB and the knowledge demands of an application. Figure 1 above shows how the coverage of the system increases when using partial matching and the smoothing technique, over the use of exact matching with the KB. 3 Preferences for Paraphrases 3.1 Tail-based Preference Similar to various types of data studied by social scientists, the distribution of strings in our corpus tends to obey Zipf’s law (Zipf, 1936). The same Zipfian trend was also observed in the compoundparaphrase dataset: more than 190 out of 250 compounds in the training data have 60% of their paraphrases in an undiscriminating tail, while 245 of 250 have 50% of their paraphrases in the tail. We thus assume the existence of a long tail in the paraphrase list for each compound. The tail of each paraphrase list can be a valuable heuristic for modeling human paraphrase preferences. We refer to this model as the tail-based preference model. We assume that an occurrence of a paraphrase is deemed to occur in the tail iff it is mentioned by</context>
</contexts>
<marker>Zipf, 1936</marker>
<rawString>G. K. Zipf. 1936. The Psycho-Biology of Language: An Introdution to Dynamic Philology. Routledge, London.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>