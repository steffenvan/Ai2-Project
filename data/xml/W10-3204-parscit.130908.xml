<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.959577">
Sequential Tagging of Semantic Roles on Chinese FrameNet
</title>
<author confidence="0.993983">
Jihong LI Ruibo WANG, Yahui GAO
</author>
<affiliation confidence="0.999881">
Computer Center Computer Center
Shanxi University Shanxi University
</affiliation>
<email confidence="0.996031">
lijh@sxu.edu.cn {wangruibo,gaoyahui}@sxu.edu.cn
</email>
<sectionHeader confidence="0.997338" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999935458333333">
In this paper, semantic role labeling(SRL)
on Chinese FrameNet is divided into the
subtasks of boundary identification(BI)
and semantic role classification(SRC).
These subtasks are regarded as the se-
quential tagging problem at the word
level, respectively. We use the conditional
random fields(CRFs) model to train and
test on a two-fold cross-validation data
set. The extracted features include 11
word-level and 15 shallow syntactic fea-
tures derived from automatic base chunk
parsing. We use the orthogonal array of
statistics to arrange the experiment so that
the best feature template is selected. The
experimental results show that given the
target word within a sentence, the best
F-measures of SRL can achieve 60.42%.
For the BI and SRC subtasks, the best F-
measures are 70.55 and 81%, respectively.
The statistical t-test shows that the im-
provement of our SRL model is not signif-
icant after appending the base chunk fea-
tures.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999968022727273">
Semantic parsing is important in natural lan-
guage processing, and it has attracted an increas-
ing number of studies in recent years. Cur-
rently, its most important aspect is the formaliza-
tion of the proposition meaning of one sentence
through the semantic role labeling. Therefore,
many large human-annotated corpora have been
constructed to support related research, such as
FrameNet (Baker et al., 1998), PropBank (Kings-
bury and Palmer, 2002), NomBank (Meyers et al.,
2004), and so on. On this basis, several interna-
tional semantic evaluations have been organized,
which include Senseval 3 (Litkowski, 2004),
SemEval 2007 (Baker,et al., 2007), CoNLL
2008 (Surdeanu et al., 2008), CoNLL 2009 (Hajic
et al., 2009), and so on.
The first SRL model on FrameNet was pro-
posed by Gildea and Jurafsky(2002). The model
consists of two subtasks of boundary identifica-
tion(BI) and semantic role classification(SRC).
Both subtasks were implemented on the pretreat-
ment results of the full parsing tree. Many lex-
ical and syntactic features were extracted to im-
prove the accuracy of the model. On the test data
of FrameNet, the system achieved 65% precision
and 61% recall.
Most works on SRL followed Gildea’s frame-
work of processing the SRL task on English
FrameNet and PropBank. They built their model
on the full parse tree and selected features using
various machine learning methods to improve the
accuracy of SRL models. Many attempts have
made significant progress, ssuch as the works of
Pradhan et al. (2005), Surdeanu et al. (2007),
and so on. Other researchers regarded the task
of SRL as a sequential tagging problem and em-
ployed the shallow chunking technique to solve it,
as described by Marquez at al. (2008).
Although the SRL model based on a full parse
tree has good performance in English, this method
of processing is not available in other languages,
especially in Chinese. A systemic study of Chi-
nese SRL was done by Xue et al. (2008). Like
the English SRL procedure, he removed many
</bodyText>
<page confidence="0.977523">
22
</page>
<note confidence="0.956493">
Proceedings of the 8th Workshop on Asian Language Resources, pages 22–29,
Beijing, China, 21-22 August 2010. c�2010 Asian Federation for Natural Language Processing
</note>
<bodyText confidence="0.999903811594203">
uncorrelated constituents of a parse tree and re-
lied on the remainder to identify the semantic
roles using the maximum entropy model. When
human-corrected parse is used, the F-measures
on the PropBank and NomBank achieve 92.0 and
69.6%, respectively. However, when automatic
full parse is used, the F-measures only achieve
71.9 and 60.4%, respectively. This significant de-
crease prompts us to analyze its causes and to find
a potential solution.
First, the Chinese human-annotated resources
of semantic roles are relatively small. Sun and
Gildea only studied the SRL of 10 Chinese verbs
and extracted 1,138 sentences in the Chinese Tree
Bank. The size of the Chinese PropBank and
Chinese NomBank used in the paper of Xue is
significantly smaller than the ones used in En-
glish language studies. Moreover, more verbs ex-
ist in Chinese than in English, which increases the
sparsity of Chinese Semantic Role data resources.
The same problem also exists in our experiment.
The current corpus of Chinese FrameNet includes
about 18,322 human-annotated sentences of 1,671
target words. There is only an average of less than
10 sentences for every target word. To reduce the
influence of the data sparsity, we adopt a two-fold
cross validation technique for train and test label-
ing.
Second, because of the lack of morphological
clues in Chinese, the accuracy of a state-of-the-art
parsing system significantly decreases when used
for a realistic scenario. In the preliminary stage
of building an SRL model of CFN, we employed
a Stanford full parser to parse all sentences in the
corpus and adopted the traditional SRL technique
on our data set. However, the experiment result
was insignificant. Only 76.48% of the semantic
roles in the data set have a constituent with the
same text span in the parse tree, and the F-measure
of BI can only achieves 54%. Therefore, we at-
tempted to use another processing technique for
SRL on CFN. We formalized SRL on CFN into a
sequential tagging problem at the word level. We
first extracted 11 word features into the baseline
model. Then we added 15 additional base chunk
features into the SRL model.
In this paper, the SRL task of CFN comprises
two subtasks: BI and SRC. These are regarded as
a sequential tagging problem at the word level.
Conditional random fields(CRFs) model is em-
ployed to train the model and predict the result
of the unlabeled sentence. To improve the accu-
racy of the model, base chunk features are intro-
duced, and the feature selection method involving
an orthogonal array is adopted. The experimen-
tal results illustrate that the F-measure of our SRL
model achieves 60.42%. This is the best SRL re-
sult of CFN so far.
The paper is organized as follows. In Section
2, we describe the situation of CFN and introduce
SRL on CFN. In Section 3, we propose our SRL
model in detail. In Section 4, the candidate feature
set is proposed, and the orthogonal-array-based
feature selection method is introduced. In Sec-
tion 5, we describe the experimental setup used
throughout this paper. In Section 6, we list our
experimental results and provide detailed analy-
sis. The conclusions and several further directions
are given at the end of this paper.
</bodyText>
<sectionHeader confidence="0.878379" genericHeader="introduction">
2 CFN and Its SRL task
</sectionHeader>
<bodyText confidence="0.99335336">
Chinese FrameNet(CFN) (You et al., 2005) is a re-
search project that has been developed by Shanxi
University, creating an FN-styled lexicon for Chi-
nese, based on the theory of Frame Semantics
(Fillmore, 1982) and supported by corpus evi-
dence. The results of the CFN project include a
lexical resource, called the CFN database, and as-
sociated software tools. Many natural language
processing(NLP) applications, such as Informa-
tion Retrieval and Machine Translation, will ben-
efit from this resource. In FN, the semantic roles
of a predicate are called the frame elements of a
frame. A frame has different frame elements. A
group of lexical units (LUs) that evokes the same
frame share the same names of frame elements.
The CFN project currently contains more than
1,671 LUs, more than 219 semantic frames, and
has exemplified more than 18,322 annotated sen-
tences. In addition to correct segmentation and
part of speech, every sentence in the database is
marked up to exemplify the semantic and syntac-
tic information of the target word. Each annotated
sentence contains only one target word.
(a). &lt;medium-np-subj % 1/m */q &gt; &lt;tgt=”
F,+it” -A-M/v &gt; &lt;msg-np-obj Alk/n —1-7/c */n
</bodyText>
<page confidence="0.995318">
23
</page>
<bodyText confidence="0.926445888888889">
0A/n &gt; ;/w
The CFN Corpus is currently at an early stage,
and the available CFN resource is relatively lim-
ited, so the SRL task on CFN is described as fol-
lows. Given a Chinese sentence, a target word,
and its frame, we identify the boundaries of the
frame elements within the sentence and label them
with the appropriate frame element name. This is
the same as the task in Senseval-3.
</bodyText>
<sectionHeader confidence="0.989355" genericHeader="method">
3 Shallow SRL Models
</sectionHeader>
<bodyText confidence="0.999878333333333">
This section proposes our SRL model architec-
ture, and describes the stages of our model in de-
tail.
</bodyText>
<subsectionHeader confidence="0.955509">
3.1 SRL Model Architecture
</subsectionHeader>
<bodyText confidence="0.923899235294118">
A family of SRL models can be constructed using
only shallow syntactic information as the input.
The main differences of the models in this family
mainly focus on the following two aspects.
i) model strategy: whether to combine the sub-
tasks of BI and SRC?
ii) tagging unit: which is used as the tagging
unit, word or chunk.
The one-stage and two-stage models are two
popular strategies used in SRL tasks, as described
by Sui et al. (2009). The word and the chunk are
regarded as the two different tagging units of the
SRL task.
In our SRL model, we consider BI and SRC as
two stages, and the word is always used as the tag-
ging unit. The detailed formalization is addressed
in the following subsections.
</bodyText>
<subsectionHeader confidence="0.998929">
3.2 BI
</subsectionHeader>
<bodyText confidence="0.9999672">
The aim of the BI stage is to identify all word
spans of the semantic roles in one Chinese sen-
tence. It can be regarded as a sequential tagging
problem. Using the IOB2 strategy (Erik et al.,
1999), we use the tag set {B,I,O1 to tag all words,
where tag ”B” represents the beginning word of a
chunk, ”I” denotes other tokens in the chunk, and
”O” is the tag of all tokens outside any chunks.
Therefore, the example sentence (a) can be repre-
sented as follows:
</bodyText>
<equation confidence="0.9896465">
(b). % 1|B * |I -A&amp;quot;M |O X%k |B -r7 |I #C* |I
0A |I ;|O
</equation>
<bodyText confidence="0.999825666666667">
To avoid the problem of data sparsity, we use all
sentences in our train data set to train the model of
BI.
</bodyText>
<subsectionHeader confidence="0.996616">
3.3 SRC
</subsectionHeader>
<bodyText confidence="0.999993461538461">
After predicting the boundaries of semantic role
chunks in a sentence, the proper semantic role
types should be assigned in the SRC step. Al-
though it can be easily modeled as a classification
problem, we regarded it as a sequential tagging
problem at the word level. An additional con-
straint is employed in this step: the boundary tags
of the predicting sequence of this stage should be
consistent with the the output of the BI stage.
One intuitive reason for this model strategy is
that the SRC step can use the same feature set as
BI, and it can further prove the rationality of our
feature optimization method.
</bodyText>
<subsectionHeader confidence="0.995897">
3.4 Postprocessing
</subsectionHeader>
<bodyText confidence="0.99864475">
Not all predicted IOB2 sequences can be trans-
formed to the original sentence correctly; there-
fore, they should satisfy the following compulsory
constraints.
</bodyText>
<listItem confidence="0.76381025">
(1) The tagging sequence should be regular.
”I...”, ”... OI...”, ”I-X...”, ”... O-I-X...”, ”... B-X-
I-Y...”, and ”B-I-X-I-X-I-Y...” are not the regular
IOB2 sequences.
</listItem>
<bodyText confidence="0.976179230769231">
(2) The tag for the target word must be ”O”.
We use the Algorithm 1 to justify whether the
IOB2 sequences are regular.
Moreover, at the SRC stage, the boundary tags
of the IOB2 sequence must be consistent with the
given boundary tags.
For the BI stage, we firstly add an additional
chunk type tag X to all &amp;quot;B&amp;quot; and &amp;quot;I&amp;quot; tags in the
IOB2 sequences, and then use Algorithm 1 to jus-
tify the regularity of the sequences.
In the testing stage of the SRL model, we use
the regular sequence with the max probability as
the optimal output.
</bodyText>
<page confidence="0.995769">
24
</page>
<construct confidence="0.516594">
Algorithm 1. justify the regular IO112 sequence
</construct>
<bodyText confidence="0.910584">
Input: (1) IO112 sequence:S = (si,.., sem)
where si G fB − X, I − X, O}, and 1 &lt; i &lt; n
(2) The position of target word in sentence pt
</bodyText>
<listItem confidence="0.992098083333333">
1, Initialization:
(1) Current chunk type: ct = NULL;
(2) Regularity of sequence: state =′ REG′;
2, Check the tag of target word: spt:
(1) If spt ==′ O′: go to Step 3;
(2) If spt &lt;&gt;′ O′: state =′ IRR′, and go to Step 4;
3,For(i = 1; i &lt; n; i + +)
(1) If si ==′ B − X′: ct =′ X′;
(2) If si ==′ I − X′ and ct &lt;&gt;′ X′: state =′ IRR′,
and go to Step 4;
(3) If si ==′ O′: ct = NULL;
4, Stop
</listItem>
<sectionHeader confidence="0.278903" genericHeader="method">
Output: Variable state;
</sectionHeader>
<subsectionHeader confidence="0.82893">
3.5 Why Word-by-word?
</subsectionHeader>
<bodyText confidence="0.999993260869565">
We ever tried to use the methods of constituent-
by-constituent and chunk-by-chunk to solve our
SRL task on CFN, but the experiment results il-
lustrate that they are not suitable to our task.
We use the Stanford Chinese full parser to parse
all sentences in the CFN corpus and use the SRL
model proposed by Xue et al.(2008) in our task.
However, the results is insignificant. Only 66.72%
of semantic roles are aligned with the constituents
of the full parse tree, and the F-measure of BI only
achieves 52.43%. The accuracy of the state-of-
the-art Chinese full parser is not high enough, so
it is not suitable to our SRL task.
Chunk-by-chunk is another choice for our task.
When We use base chunk as the tagging unit of
our model, only about 15% of semantic roles did
not align very well with the boundary of automati-
cally generated base chunks, and the F-measure is
significantly lower than the method of word-by-
word, as described by Wang et al.(2009).
Therefore, words are chosen as the tagging unit
of our SRL model, which showed significant re-
sults from the experiment.
</bodyText>
<sectionHeader confidence="0.970563" genericHeader="method">
4 Feature Selection and Optimization
</sectionHeader>
<bodyText confidence="0.993483230769231">
Word-level features and base-chunk features are
used in our SRL research.
Base chunk is a Chinese shallow parsing
scheme proposed by Professor Zhou. He con-
structed a high accuracy rule-based Chinese base
chunk parse (Zhou, 2009), the F-measure of
which can achieve 89%. We use this parse to gen-
erate all base chunks of the sentences in our cor-
pus and to extract several types of features from
them. The automatically generated base chunks
of example sentences (a) are given as follows:
(c).[mp-ZX % 1/m */q ] [vp-SG -�I&apos;M/v ] [np-
SG X7k/n ] tj/c [np-AM */n&apos;.9RA/n ] ;/w
</bodyText>
<subsectionHeader confidence="0.996438">
4.1 Candidate Feature Set
</subsectionHeader>
<bodyText confidence="0.904210454545455">
Three types of features are given as follows:
Features at the word level:
Word: The current token itself;
Part-of-Speech: The part of speech of the cur-
rent token;
Position: The position of the current word rela-
tive to the target word(before, after, or on);
Target word: The target word in the sentence;
Features at the base chunk level:
Syntactic label: The syntactic label of the cur-
rent token, such as, B-np,I-vp, etc;
Structural label: The structural label of the cur-
rent token, such as, B-SG, I-ZX, etc;
Head word and its Part of Speech: The head
word and its part of speech of the base chunk;
Shallow syntactic path: The combination of
the syntactic tags from the source base chunk,
which contains the current word, to the target base
chunk, which contains the target word of the sen-
tence;
Subcategory: The combination of the syntactic
tags of the base chunk around the target word;
Other Features:
Named entity: The three types of named entities
are considered: person, location, and time. They
can be directly mapped from the part of speech of
the current word.
Simplified sentence: A boolean feature. We use
the punctuation count of the sentence to estimate
whether the sentence is the simplified sentence.
Aside from the basic features described above,
we also use combinations of these features, such
as word/POS combination, etc.
</bodyText>
<subsectionHeader confidence="0.975786">
4.2 Feature Optimization Method
</subsectionHeader>
<bodyText confidence="0.983119833333333">
In the baseline model, we only introduce the fea-
tures at the word level. Table 1 shows the candi-
date features of our baseline model and proposes
their optional sizes of sliding windows.
For Table 1, we use the orthogonal array
L32(49 x 24) to conduct 32 different templates.
</bodyText>
<page confidence="0.991188">
25
</page>
<bodyText confidence="0.9998435">
The best template is chosen from the highest F-
measure for testing the 32 templates. The detailed
orthogonal-array-based feature selection method
was proposed by Li et al.(2010).
</bodyText>
<tableCaption confidence="0.99818">
Table 1. Candidate features of baseline models
</tableCaption>
<table confidence="0.999142538461538">
Feature type Window size
word [0,0] [-1,1] [-2,2] [-3,3]
bigram of word - [-1,1] [-2,2] [-3,3]
POS [0,0] [-1,1] [-2,2] [-3,3]
bigram of POS - [-1,1] [-2,2] [-3,3]
position [0,0] [-1,1] [-2,2] [-3,3]
bigram of position - [-1,1] [-2,2] [-3,3]
word/POS - [0,0] [-1,1] [-2,2]
word/position - [0,0] [-1,1] [-2,2]
POS/position - [0,0] [-1,1] [-2,2]
trigram of position - [-2,0] [-1,1] [0,2]
word/target word - [0,0]
target word [0,0]
</table>
<tableCaption confidence="0.72660275">
Compared with the baseline model, the features
at the word and base chunk levels are all consid-
ered in Table 2.
Table 2. Candidate features of the base chunk-based model
</tableCaption>
<table confidence="0.9957956">
Feature type Window size
word [0,0] [-1,1] [-2,2]
bigram of word - [-1,1] [-2,2]
POS [0,0] [-1,1] [-2,2]
bigram of POS - [-1,1] [-2,2]
position [0,0] [-1,1] [-2,2]
bigram of position - [-1,1] [-2,2]
word/POS - [0,0] [-1,1]
word/position - [0,0] [-1,1]
POS/position - [0,0] [-1,1]
trigram of position - [-2,0] [-1,1]
syntactic label [0,0] [-1,1] [-2,2]
syn-bigram - [-1,1] [-2,2]
Syn-trigram - [-1,1] [-2,2]
head word [0,0] [-1,1] [-2,2]
head word-bigram - [-1,1] [-2,2]
POS of Head [0,0] [-1,1] [-2,2]
POS-bigram of head - [-1,1] [-2,2]
syn/head word [0,0] [-1,1] [-2,2]
stru/head word [0,0] [-1,1] [-2,2]
shallow path - [0,0] [-1,1]
subcategory - [0,0] [0,0]
named Entity - [0,0] [0,0]
simplified Sentence - [0,0] [0,0]
target word(compulsory) [0,0]
</table>
<bodyText confidence="0.993835571428572">
The orthogonal array L54(21x325) is employed
to select the best feature template from all candi-
date feature templates in Table 2. To distinguish
it from the baseline model, we call the model
based on the table 2 as the ”base chunk-based SRL
model”.
For both feature sets described above, the target
word is the compulsory feature in every template,
and the boundary tags are introduced as features
during the SRC stage.
The feature templates in Table 2 cannot con-
tain the best feature template selected from Table
1. This is a disadvantage of our feature selection
method.
</bodyText>
<sectionHeader confidence="0.9974325" genericHeader="method">
5 Experimental Setup and Evaluation
Metrics
</sectionHeader>
<subsectionHeader confidence="0.999637">
5.1 Data Set
</subsectionHeader>
<bodyText confidence="0.9839355">
The experimental data set consists of all sentences
of 25 frames selected in the CFN corpus. These
sentences have the correct POS tags and CFN se-
mantic information; they are all auto parsed by
the rule-based Chinese base chunk parser. Table
3 shows some statistics on these 25 frames.
</bodyText>
<tableCaption confidence="0.998941">
Table 3. Summary of the experimental data set
</tableCaption>
<table confidence="0.997693142857143">
Frame FEs Sents Frame FEs Sents
AA 6 569 I1A 7 140
*PVU 5 345 F#i2L 10 1,603
;9t IL 3 141 A 4 170
At IL 5 185 ig-PIK 4 70
��A,,*P 14 499 ko)i 12 198
�;i 9 320 itX11 6 90
;94 8 283 its 7 80
#M�LA*P 13 379 efT� 11 125
�*P 9 258 i.;EM 9 101
44N 8 218 9*MIK 9 260
ie&amp;quot;PL 12 298 4FY% 10 106
it* 6 126 #, 8 74
IT, Nrf 5 54 Totals 200 6,692
</table>
<subsectionHeader confidence="0.997528">
5.2 Cross-validation technique
</subsectionHeader>
<bodyText confidence="0.999988411764706">
In all our experiments, three groups of two-fold
cross-validation sets are used to estimate the per-
formance of our SRL model. All sentences in a
frame are cut four-fold on average, where every
two folder are merged as train data, and the other
two folds are used as test data. Therefore, we can
obtain three groups of two-fold cross-validation
data sets.
Estimating the parameter of fold number is
one of the most difficult problems in the cross-
validation technique. We believe that in the task of
SRL, the two-fold cross validation set is a reason-
able choice, especially when the data set is relative
small. With a small data set, dividing it in half is
split of data set is the best approximation of the
real-world data distribution of semantic roles and
the sparse word tokens.
</bodyText>
<page confidence="0.987819">
26
</page>
<subsectionHeader confidence="0.988633">
5.3 Classifiers
</subsectionHeader>
<bodyText confidence="0.999971307692308">
CRFs model is used as the learning algorithm
in our experiments. Previous SRL research has
demonstrated that CRFs model is one of the best
statistical algorithms for SRL, such as the works
of Cohn et al. (2005) and Yu et al. (2007).
The crfpp toolkit&apos; is a good implementation of
the CRF classifier, which contains three different
training algorithms: CRFL1, CRFL2, and MIRA.
We only use CRFL2 with Gaussian priori regular-
ization and the variance parameter C=1.0.
where, K is the fold number of cross-validation
and n1 and n2 are the counts of training examples
and testing examples. In our experimental setting,
</bodyText>
<figure confidence="0.810873785714286">
K = 2 and n2 pz 1. Moreover, the estimation of
n1
the variance of the total F-measure is as follows:
Var(F) = V ar(13(F1 + F2 + F3))
3
1
9
=
∑
j=1
V ar(Fj)
d
5.4 Evaluation Metrics Using Var(Fj) to estimate V ar(Fj), we can
obtain:
</figure>
<bodyText confidence="0.996741653846154">
As described in SRL reseach, precision, recall,
and F-measure are also used as our evaluation
metrics. In addition, the standard deviation of the
F-measure is also adopted as an important metric
of our SRL model. The computation method of
these metrics is given as follows:
Let Pji, Rij and Fji be the precision, recall, and
F-measure of the jth group of the ith cross valida-
tion set, where j = 1, 2, 3 and i = 1, 2. The final
precision(P), recall(R), and F-measure(F) of our
SRL model are the expectation values of the Pij,
Rij, and Fji, respectively.
The estimation of the variance of cross-
validation is another difficult problem in the
cross-validation technique. Although it has been
proven that the uniform and unbiased estimation
of the variance of cross-validation does not ex-
ist (Yoshua et al., 2007), we adopted the method
proposed by Nadeau et al. (2007), to estimate the
variance of the F-measure of cross-validation sets.
This method is proposed hereinafter.
Let Fj be the average F-measure of the j group
experiment, that is, Fj = 12(Fj1 + Fj2), where
j = 1, 2, 3. The proposed estimator of the vari-
ance of Fj in the work of Nadeau et al. (2007) is
as follows:
</bodyText>
<equation confidence="0.9967129">
(12 + 1)∑
i=1
2
(Fji − Fj)
&apos;crfpp toolkit: http://crfpp.sourceforge.net/
1
Vdar(F) =
∑
9
(Fji − Fj)
</equation>
<bodyText confidence="0.994942">
Finally, we can derive the standard deviation of
√the F-measure, that is, std(F) = Vdar(F).
</bodyText>
<subsectionHeader confidence="0.993483">
5.5 Significance Test of Two SRL Models
</subsectionHeader>
<bodyText confidence="0.9999705">
To test the significance of SRL models A and B,
we use the following statistics S.
</bodyText>
<equation confidence="0.999652333333333">
S = √
V ar(F(A)) + Var(F(B))
F (A) − F (B) — t(n)
</equation>
<bodyText confidence="0.998292666666667">
where F(A) and F(B) are the F-measures of
models A and B, and n is the freedom degree of
t-distribution, an integer nearest to the n′.
</bodyText>
<equation confidence="0.9993335">
= 3(V ar(F(A)) + V ar(F(B)))2
n (Var(F(A))2 + Var(F(B))2)
</equation>
<bodyText confidence="0.969242714285714">
We use the p − value(·) to test the significance
of SRL models A and B, which are given as fol-
lows:
p − value(F(A), F(B)) = P(S &gt; t1−α/2(n))
If p − value(F(A), F(B)) &lt; 0.05, the differ-
ence of the F-measures between models A and B
is significant at 95% level.
</bodyText>
<figure confidence="0.969184125">
∑2
Vd ar(Fj) = (K 1 + n2) (Fj i − Fj)
n1
i=1
3
3
1
6
=
∑
j=1
j=1
Vdar(Fj)
2
∑
i=1
</figure>
<page confidence="0.990901">
27
</page>
<sectionHeader confidence="0.993796" genericHeader="evaluation">
6 Experimental Results and Discussion
</sectionHeader>
<bodyText confidence="0.999991333333333">
We summarized the experiment results of every
stage of our SRL model, that is, BI, SRC and a
combination of these two steps (BI+SRC).
</bodyText>
<subsectionHeader confidence="0.915187">
6.1 Baseline SRL Model
</subsectionHeader>
<bodyText confidence="0.996353">
The results of the baseline model are given in Ta-
ble 4, which only uses the features in Table 1.
</bodyText>
<tableCaption confidence="0.999582">
Table 4. Results of the baseline model
</tableCaption>
<table confidence="0.999068">
P(%) R(%) F(%) std(F)
BI 74.42 66.80 70.40 0.0031
SRC - - 80.32 0.0032
BI+SRC 62.87 56.44 59.48 0.0050
</table>
<bodyText confidence="0.999903909090909">
In Table 1, because the results of the SRC stage
are based on human-corrected boundary informa-
tion, the precision, recall, and F-measure of this
stage are the same. Therefore, we only give the
F-measure and its deviation at the SRC stage.
In the baseline model, the BI stage is the bot-
tleneck of our SRL model. Its F-measure only
achieves 70.4%, and the recall is lower than the
precision. Moreover, the F-measure of the final
model only achieves 59.48%, and its standard de-
viation is larger than both stages.
</bodyText>
<subsectionHeader confidence="0.999646">
6.2 Base chunk-based SRL Model
</subsectionHeader>
<bodyText confidence="0.999671666666667">
When base chunk features, proposed in Table 2,
are employed in the SRL model, we can obtain
the results summarized in Table 5.
</bodyText>
<tableCaption confidence="0.998676">
Table 5. Results of the base chunk-based model
</tableCaption>
<table confidence="0.997879">
P(%) R(%) F(%) std(F)
BI 74.69 66.85 70.55 0.0038
SRC - - 81.00 0.0029
BI+SRC 63.97 57.25 60.42 0.0049
</table>
<bodyText confidence="0.769692636363636">
A comparison of Table 4 and Table 5 provides
the following two conclusions.
(1) When base chunk features are used, all P, R,
F at every stage slightly increase (&lt; 1%).
(2) The significance test values between the
baseline model and the base chunk-based model
are given in Table 6. For every stage, the perfor-
mance boost after introducing the base chunk fea-
tures is not significant at 95% level. However, the
impact of base chunk features at the SRC stage is
larger than that at the BI stage.
</bodyText>
<tableCaption confidence="0.708905">
Table 6. Test values between two SRL models
</tableCaption>
<sectionHeader confidence="0.981425" genericHeader="conclusions">
7 Conclusions and Further Directions
</sectionHeader>
<bodyText confidence="0.9999254">
The SRL of Chinese predicates is a challenging
task. In this paper, we studied the task of SRL
on the CFN. We proposed a two-stage model and
exploited the CRFs classifier to implement the au-
tomatic SRL systems. Moreover, we introduced
the base chunk features and the OA-based method
to improve the performance of our model. Exper-
imental results shows that the F-measure of our
best model achieves 60.42%, and the base chunk
features cannot improve the SRL model signifi-
cantly.
In the future, we plan to introduce unlabeled
data into the training phase and use the EM-
schemed semi-supervised learning algorithms to
boost the accuracy of our SRL model.
</bodyText>
<sectionHeader confidence="0.981621" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999556666666667">
The authors would like to thank Prof. Kaiying
LIU for his comments and Prof. Qiang ZHOU for
the base-chunk parser.
</bodyText>
<sectionHeader confidence="0.998912" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9992046">
Baker, C., Fillmore, C., and John B. 1998. The Berke-
ley Framenet project. In Proceedings of COLING-
ACL, 86-90, Montreal, Canada.
Baker, C., Ellsworth, M., Erk, K. 2007. SemEval’07
Task 19: Frame semantic structure extraction. Pro-
ceedings of the 4th International Workshop on Se-
mantic Evaluations, 99-104, Prague, Czech Repub-
lic.
Cohn, T., Blunsom P. 2005. Semantic role labeling
with tree conditional random fields. Proceedings of
CoNLL 2005, ACL, 169-172.
Erik F., and John V. 1999. Representing text chunks.
In Proceedings of EACL’99, 173-179.
Fillmore, C. 1982. Frame Semantics. In The Linguis-
tic Society of Korea, Seoul: Hanshin.
Gildea, D., and Jurafsky, D. 2002. Automatic label-
ing for semantic roles. Computational Linguistics,
28(3):245-288.
Hajic, J., Ciaramita, M., Johansson, R., Kawahara, D.,
Marti, M., M`arquez, L., Meyers, A., Nivre, J., Pado,
S., Stepanek, J., Stranak, P., Surdeanu, M., Nian-
wen X., Zhang, Y. 2009. The CoNLL-2009 shared
task: syntactic and semantic dependencies in multi-
ple languages. In Proceedings of CoNLL 2009, 1-
18, Boulder, CO, USA..
</reference>
<figure confidence="0.551887666666667">
BI SRC BI+SRC
p − value
0.77 0.166 0.228
</figure>
<page confidence="0.99208">
28
</page>
<reference confidence="0.999941031746032">
Jihong, L., Ruibo, W., Weilin, W., and Guochen, L.
2010. Automatic Labeling of Semantic Roles on
Chinese FrameNet. Journal of Software, 2010,
21(4):597-611.
Jiangde, Y., Xiaozhong, F., Wenbo, P., and Zhengtao,
Y. 2007. Semantic role labeling based on condi-
tional random fields Journal of southeast university
(English edition), 23(2):5361-364.
Liping, Y., and Kaiying, L. 2005. Building Chinese
FrameNet database. In Proceedings of IEEE NLP-
KE’05 , 301-306.
Litkowski, K. 2004. Senseval-3 task automatic label-
ing of semantic roles. Third International Workshop
on the Evaluation of Systems for the Semantic Anal-
ysis of Text, 9-12, Barcelona, Spain.
M`arquez, L., Carreras, X., Litkowski, K., Stevenson,
S. 2008. Semantic Role Labeling: An Introduc-
tion to the Special Issue. Computational Linguis-
tics, 34(2):145-159.
Meyers, A., Reeves, R., Macleod, C., Szekely, R.,
Zielinska, V., Young, B., and Grishman, R. 2004.
The NomBank Project: An interim report. In Pro-
ceedings of the NAACL/HLT Workshop on Frontiers
in Corpus Annotation, 24-31, Boston, MA, USA.
Nadeau, C., and Bengio, Y. 2003. Inference for the
generalization error. Machine Learning, 52: 239-
281.
Nianwen, X. 2008. Labeling Chinese Predicates with
Semantic Roles. Computational Linguistics, 2008,
34(2): 225-255.
Paul, K., and Martha, P. 2002. From TreeBank to
PropBank. In Proceedings of LREC-2002, Canary
Islands, Spain.
Pradhan, S., Hacioglu, K., Krugler, V., Ward, W., Mar-
tin, J., Jurafsky, D. 2005. Support vector learn-
ing for semantic argument classification. Machine
Learning, 2005, 60(1):11-39.
Qiang, Z. 2007. A rule-based Chinese base chunk
parser. In Proc. of 7th International Conference
of Chinese Computation (ICCC-2007), 137-142,
Wuhan, China.
Ruibo, W. 2004. Automatic Semantic Role Label-
ing of Chinese FrameNet Based On Conditional
Random Fields Model. Thesis for the 2009 Mas-
ter’s Degree of Shanxi University, Taiyuan, Shanxi,
China.
Surdeanu, M., Johansson, R., Meyers, A., M`arquez,
L., Nivre, J. 2008. The CoNLL 2008 shared task
on joint parsing of syntactic and semantic depen-
dencies. In Proceedings of CoNLL 2008, 159-177,
Manchester, England, UK.
Surdeanu, M., M`arquez, L., Carreras, X., Comas, P.
2007. Combination strategies for semantic role la-
beling. Journal of Artificial Intelligence Research,
29:105-151.
Yoshua, B., and Yves, G. 2004. No unbiased estimator
of the variance of K-fold cross-validation Journal of
Machine Learning Research, 5:1089-1105.
Weiwei, S., Zhifang, S., Meng, W., and Xing, W. 2009.
Chinese semantic role labeling with shallow pars-
ing. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Process-
ing(EMNLP 2009), ACL, 1475-1483.
</reference>
<page confidence="0.999115">
29
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.884907">
<title confidence="0.997717">Sequential Tagging of Semantic Roles on Chinese FrameNet</title>
<author confidence="0.991906">Jihong LI Ruibo WANG</author>
<author confidence="0.991906">Yahui GAO</author>
<affiliation confidence="0.999449">Computer Center Computer Center Shanxi University Shanxi University</affiliation>
<abstract confidence="0.99563636">In this paper, semantic role labeling(SRL) on Chinese FrameNet is divided into the subtasks of boundary identification(BI) and semantic role classification(SRC). These subtasks are regarded as the sequential tagging problem at the word level, respectively. We use the conditional random fields(CRFs) model to train and test on a two-fold cross-validation data set. The extracted features include 11 word-level and 15 shallow syntactic features derived from automatic base chunk parsing. We use the orthogonal array of statistics to arrange the experiment so that the best feature template is selected. The experimental results show that given the target word within a sentence, the best F-measures of SRL can achieve 60.42%. For the BI and SRC subtasks, the best Fmeasures are 70.55 and 81%, respectively. The statistical t-test shows that the improvement of our SRL model is not significant after appending the base chunk features.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Baker</author>
<author>C Fillmore</author>
<author>B John</author>
</authors>
<title>The Berkeley Framenet project.</title>
<date>1998</date>
<booktitle>In Proceedings of COLINGACL,</booktitle>
<pages>86--90</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="1565" citStr="Baker et al., 1998" startWordPosition="234" endWordPosition="237"> BI and SRC subtasks, the best Fmeasures are 70.55 and 81%, respectively. The statistical t-test shows that the improvement of our SRL model is not significant after appending the base chunk features. 1 Introduction Semantic parsing is important in natural language processing, and it has attracted an increasing number of studies in recent years. Currently, its most important aspect is the formalization of the proposition meaning of one sentence through the semantic role labeling. Therefore, many large human-annotated corpora have been constructed to support related research, such as FrameNet (Baker et al., 1998), PropBank (Kingsbury and Palmer, 2002), NomBank (Meyers et al., 2004), and so on. On this basis, several international semantic evaluations have been organized, which include Senseval 3 (Litkowski, 2004), SemEval 2007 (Baker,et al., 2007), CoNLL 2008 (Surdeanu et al., 2008), CoNLL 2009 (Hajic et al., 2009), and so on. The first SRL model on FrameNet was proposed by Gildea and Jurafsky(2002). The model consists of two subtasks of boundary identification(BI) and semantic role classification(SRC). Both subtasks were implemented on the pretreatment results of the full parsing tree. Many lexical a</context>
</contexts>
<marker>Baker, Fillmore, John, 1998</marker>
<rawString>Baker, C., Fillmore, C., and John B. 1998. The Berkeley Framenet project. In Proceedings of COLINGACL, 86-90, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Baker</author>
<author>M Ellsworth</author>
<author>K Erk</author>
</authors>
<title>SemEval’07 Task 19: Frame semantic structure extraction.</title>
<date>2007</date>
<booktitle>Proceedings of the 4th International Workshop on Semantic Evaluations, 99-104,</booktitle>
<location>Prague, Czech Republic.</location>
<marker>Baker, Ellsworth, Erk, 2007</marker>
<rawString>Baker, C., Ellsworth, M., Erk, K. 2007. SemEval’07 Task 19: Frame semantic structure extraction. Proceedings of the 4th International Workshop on Semantic Evaluations, 99-104, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Cohn</author>
<author>P Blunsom</author>
</authors>
<title>Semantic role labeling with tree conditional random fields.</title>
<date>2005</date>
<booktitle>Proceedings of CoNLL</booktitle>
<pages>169--172</pages>
<marker>Cohn, Blunsom, 2005</marker>
<rawString>Cohn, T., Blunsom P. 2005. Semantic role labeling with tree conditional random fields. Proceedings of CoNLL 2005, ACL, 169-172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Erik</author>
<author>V John</author>
</authors>
<title>Representing text chunks.</title>
<date>1999</date>
<booktitle>In Proceedings of EACL’99,</booktitle>
<pages>173--179</pages>
<marker>Erik, John, 1999</marker>
<rawString>Erik F., and John V. 1999. Representing text chunks. In Proceedings of EACL’99, 173-179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fillmore</author>
</authors>
<title>Frame Semantics.</title>
<date>1982</date>
<booktitle>In The Linguistic Society of Korea, Seoul:</booktitle>
<publisher>Hanshin.</publisher>
<contexts>
<context position="6736" citStr="Fillmore, 1982" startWordPosition="1098" endWordPosition="1099">r SRL model in detail. In Section 4, the candidate feature set is proposed, and the orthogonal-array-based feature selection method is introduced. In Section 5, we describe the experimental setup used throughout this paper. In Section 6, we list our experimental results and provide detailed analysis. The conclusions and several further directions are given at the end of this paper. 2 CFN and Its SRL task Chinese FrameNet(CFN) (You et al., 2005) is a research project that has been developed by Shanxi University, creating an FN-styled lexicon for Chinese, based on the theory of Frame Semantics (Fillmore, 1982) and supported by corpus evidence. The results of the CFN project include a lexical resource, called the CFN database, and associated software tools. Many natural language processing(NLP) applications, such as Information Retrieval and Machine Translation, will benefit from this resource. In FN, the semantic roles of a predicate are called the frame elements of a frame. A frame has different frame elements. A group of lexical units (LUs) that evokes the same frame share the same names of frame elements. The CFN project currently contains more than 1,671 LUs, more than 219 semantic frames, and </context>
</contexts>
<marker>Fillmore, 1982</marker>
<rawString>Fillmore, C. 1982. Frame Semantics. In The Linguistic Society of Korea, Seoul: Hanshin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic labeling for semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<pages>28--3</pages>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Gildea, D., and Jurafsky, D. 2002. Automatic labeling for semantic roles. Computational Linguistics, 28(3):245-288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hajic</author>
<author>M Ciaramita</author>
<author>R Johansson</author>
<author>D Kawahara</author>
<author>M Marti</author>
<author>L M`arquez</author>
<author>A Meyers</author>
<author>J Nivre</author>
<author>S Pado</author>
<author>J Stepanek</author>
<author>P Stranak</author>
<author>M Surdeanu</author>
<author>X Nianwen</author>
<author>Y Zhang</author>
</authors>
<title>The CoNLL-2009 shared task: syntactic and semantic dependencies in multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of CoNLL</booktitle>
<pages>1--18</pages>
<location>Boulder, CO, USA..</location>
<marker>Hajic, Ciaramita, Johansson, Kawahara, Marti, M`arquez, Meyers, Nivre, Pado, Stepanek, Stranak, Surdeanu, Nianwen, Zhang, 2009</marker>
<rawString>Hajic, J., Ciaramita, M., Johansson, R., Kawahara, D., Marti, M., M`arquez, L., Meyers, A., Nivre, J., Pado, S., Stepanek, J., Stranak, P., Surdeanu, M., Nianwen X., Zhang, Y. 2009. The CoNLL-2009 shared task: syntactic and semantic dependencies in multiple languages. In Proceedings of CoNLL 2009, 1-18, Boulder, CO, USA..</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Jihong</author>
<author>W Ruibo</author>
<author>W Weilin</author>
<author>L Guochen</author>
</authors>
<title>Automatic Labeling of Semantic Roles on Chinese FrameNet.</title>
<date>2010</date>
<journal>Journal of Software,</journal>
<pages>21--4</pages>
<marker>Jihong, Ruibo, Weilin, Guochen, 2010</marker>
<rawString>Jihong, L., Ruibo, W., Weilin, W., and Guochen, L. 2010. Automatic Labeling of Semantic Roles on Chinese FrameNet. Journal of Software, 2010, 21(4):597-611.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Jiangde</author>
<author>F Xiaozhong</author>
<author>P Wenbo</author>
<author>Y Zhengtao</author>
</authors>
<title>Semantic role labeling based on conditional random fields</title>
<date>2007</date>
<journal>Journal of southeast university (English</journal>
<volume>edition),</volume>
<pages>23--2</pages>
<marker>Jiangde, Xiaozhong, Wenbo, Zhengtao, 2007</marker>
<rawString>Jiangde, Y., Xiaozhong, F., Wenbo, P., and Zhengtao, Y. 2007. Semantic role labeling based on conditional random fields Journal of southeast university (English edition), 23(2):5361-364.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Liping</author>
<author>L Kaiying</author>
</authors>
<title>Building Chinese FrameNet database.</title>
<date>2005</date>
<booktitle>In Proceedings of IEEE NLPKE’05 ,</booktitle>
<pages>301--306</pages>
<marker>Liping, Kaiying, 2005</marker>
<rawString>Liping, Y., and Kaiying, L. 2005. Building Chinese FrameNet database. In Proceedings of IEEE NLPKE’05 , 301-306.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Litkowski</author>
</authors>
<title>Senseval-3 task automatic labeling of semantic roles.</title>
<date>2004</date>
<booktitle>Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text,</booktitle>
<pages>9--12</pages>
<location>Barcelona,</location>
<contexts>
<context position="1769" citStr="Litkowski, 2004" startWordPosition="267" endWordPosition="268">oduction Semantic parsing is important in natural language processing, and it has attracted an increasing number of studies in recent years. Currently, its most important aspect is the formalization of the proposition meaning of one sentence through the semantic role labeling. Therefore, many large human-annotated corpora have been constructed to support related research, such as FrameNet (Baker et al., 1998), PropBank (Kingsbury and Palmer, 2002), NomBank (Meyers et al., 2004), and so on. On this basis, several international semantic evaluations have been organized, which include Senseval 3 (Litkowski, 2004), SemEval 2007 (Baker,et al., 2007), CoNLL 2008 (Surdeanu et al., 2008), CoNLL 2009 (Hajic et al., 2009), and so on. The first SRL model on FrameNet was proposed by Gildea and Jurafsky(2002). The model consists of two subtasks of boundary identification(BI) and semantic role classification(SRC). Both subtasks were implemented on the pretreatment results of the full parsing tree. Many lexical and syntactic features were extracted to improve the accuracy of the model. On the test data of FrameNet, the system achieved 65% precision and 61% recall. Most works on SRL followed Gildea’s framework of </context>
</contexts>
<marker>Litkowski, 2004</marker>
<rawString>Litkowski, K. 2004. Senseval-3 task automatic labeling of semantic roles. Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, 9-12, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L M`arquez</author>
<author>X Carreras</author>
<author>K Litkowski</author>
<author>S Stevenson</author>
</authors>
<title>Semantic Role Labeling: An Introduction to the Special Issue.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<pages>34--2</pages>
<marker>M`arquez, Carreras, Litkowski, Stevenson, 2008</marker>
<rawString>M`arquez, L., Carreras, X., Litkowski, K., Stevenson, S. 2008. Semantic Role Labeling: An Introduction to the Special Issue. Computational Linguistics, 34(2):145-159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Meyers</author>
<author>R Reeves</author>
<author>C Macleod</author>
<author>R Szekely</author>
<author>V Zielinska</author>
<author>B Young</author>
<author>R Grishman</author>
</authors>
<title>The NomBank Project: An interim report.</title>
<date>2004</date>
<booktitle>In Proceedings of the NAACL/HLT Workshop on Frontiers in Corpus Annotation,</booktitle>
<pages>24--31</pages>
<location>Boston, MA, USA.</location>
<contexts>
<context position="1635" citStr="Meyers et al., 2004" startWordPosition="245" endWordPosition="248">ely. The statistical t-test shows that the improvement of our SRL model is not significant after appending the base chunk features. 1 Introduction Semantic parsing is important in natural language processing, and it has attracted an increasing number of studies in recent years. Currently, its most important aspect is the formalization of the proposition meaning of one sentence through the semantic role labeling. Therefore, many large human-annotated corpora have been constructed to support related research, such as FrameNet (Baker et al., 1998), PropBank (Kingsbury and Palmer, 2002), NomBank (Meyers et al., 2004), and so on. On this basis, several international semantic evaluations have been organized, which include Senseval 3 (Litkowski, 2004), SemEval 2007 (Baker,et al., 2007), CoNLL 2008 (Surdeanu et al., 2008), CoNLL 2009 (Hajic et al., 2009), and so on. The first SRL model on FrameNet was proposed by Gildea and Jurafsky(2002). The model consists of two subtasks of boundary identification(BI) and semantic role classification(SRC). Both subtasks were implemented on the pretreatment results of the full parsing tree. Many lexical and syntactic features were extracted to improve the accuracy of the mo</context>
</contexts>
<marker>Meyers, Reeves, Macleod, Szekely, Zielinska, Young, Grishman, 2004</marker>
<rawString>Meyers, A., Reeves, R., Macleod, C., Szekely, R., Zielinska, V., Young, B., and Grishman, R. 2004. The NomBank Project: An interim report. In Proceedings of the NAACL/HLT Workshop on Frontiers in Corpus Annotation, 24-31, Boston, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Nadeau</author>
<author>Y Bengio</author>
</authors>
<title>Inference for the generalization error.</title>
<date>2003</date>
<booktitle>Machine Learning,</booktitle>
<volume>52</volume>
<pages>239--281</pages>
<marker>Nadeau, Bengio, 2003</marker>
<rawString>Nadeau, C., and Bengio, Y. 2003. Inference for the generalization error. Machine Learning, 52: 239-281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Nianwen</author>
</authors>
<title>Labeling Chinese Predicates with Semantic Roles. Computational Linguistics,</title>
<date>2008</date>
<volume>34</volume>
<issue>2</issue>
<pages>225--255</pages>
<marker>Nianwen, 2008</marker>
<rawString>Nianwen, X. 2008. Labeling Chinese Predicates with Semantic Roles. Computational Linguistics, 2008, 34(2): 225-255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Paul</author>
<author>P Martha</author>
</authors>
<title>From TreeBank to PropBank.</title>
<date>2002</date>
<booktitle>In Proceedings of LREC-2002, Canary Islands,</booktitle>
<marker>Paul, Martha, 2002</marker>
<rawString>Paul, K., and Martha, P. 2002. From TreeBank to PropBank. In Proceedings of LREC-2002, Canary Islands, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pradhan</author>
<author>K Hacioglu</author>
<author>V Krugler</author>
<author>W Ward</author>
<author>J Martin</author>
<author>D Jurafsky</author>
</authors>
<title>Support vector learning for semantic argument classification.</title>
<date>2005</date>
<booktitle>Machine Learning,</booktitle>
<pages>60--1</pages>
<contexts>
<context position="2662" citStr="Pradhan et al. (2005)" startWordPosition="413" endWordPosition="416">ole classification(SRC). Both subtasks were implemented on the pretreatment results of the full parsing tree. Many lexical and syntactic features were extracted to improve the accuracy of the model. On the test data of FrameNet, the system achieved 65% precision and 61% recall. Most works on SRL followed Gildea’s framework of processing the SRL task on English FrameNet and PropBank. They built their model on the full parse tree and selected features using various machine learning methods to improve the accuracy of SRL models. Many attempts have made significant progress, ssuch as the works of Pradhan et al. (2005), Surdeanu et al. (2007), and so on. Other researchers regarded the task of SRL as a sequential tagging problem and employed the shallow chunking technique to solve it, as described by Marquez at al. (2008). Although the SRL model based on a full parse tree has good performance in English, this method of processing is not available in other languages, especially in Chinese. A systemic study of Chinese SRL was done by Xue et al. (2008). Like the English SRL procedure, he removed many 22 Proceedings of the 8th Workshop on Asian Language Resources, pages 22–29, Beijing, China, 21-22 August 2010. </context>
</contexts>
<marker>Pradhan, Hacioglu, Krugler, Ward, Martin, Jurafsky, 2005</marker>
<rawString>Pradhan, S., Hacioglu, K., Krugler, V., Ward, W., Martin, J., Jurafsky, D. 2005. Support vector learning for semantic argument classification. Machine Learning, 2005, 60(1):11-39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Qiang</author>
</authors>
<title>A rule-based Chinese base chunk parser.</title>
<date>2007</date>
<booktitle>In Proc. of 7th International Conference of Chinese Computation (ICCC-2007),</booktitle>
<pages>137--142</pages>
<location>Wuhan, China.</location>
<marker>Qiang, 2007</marker>
<rawString>Qiang, Z. 2007. A rule-based Chinese base chunk parser. In Proc. of 7th International Conference of Chinese Computation (ICCC-2007), 137-142, Wuhan, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Ruibo</author>
</authors>
<title>Automatic Semantic Role Labeling of Chinese FrameNet Based On Conditional Random Fields Model. Thesis for the</title>
<date>2004</date>
<institution>Master’s Degree of Shanxi University,</institution>
<location>Taiyuan, Shanxi, China.</location>
<marker>Ruibo, 2004</marker>
<rawString>Ruibo, W. 2004. Automatic Semantic Role Labeling of Chinese FrameNet Based On Conditional Random Fields Model. Thesis for the 2009 Master’s Degree of Shanxi University, Taiyuan, Shanxi, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Surdeanu</author>
<author>R Johansson</author>
<author>A Meyers</author>
<author>L M`arquez</author>
<author>J Nivre</author>
</authors>
<title>The CoNLL</title>
<date>2008</date>
<booktitle>In Proceedings of CoNLL</booktitle>
<pages>159--177</pages>
<location>Manchester, England, UK.</location>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Surdeanu, M., Johansson, R., Meyers, A., M`arquez, L., Nivre, J. 2008. The CoNLL 2008 shared task on joint parsing of syntactic and semantic dependencies. In Proceedings of CoNLL 2008, 159-177, Manchester, England, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Surdeanu</author>
<author>L M`arquez</author>
<author>X Carreras</author>
<author>P Comas</author>
</authors>
<title>Combination strategies for semantic role labeling.</title>
<date>2007</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>29--105</pages>
<marker>Surdeanu, M`arquez, Carreras, Comas, 2007</marker>
<rawString>Surdeanu, M., M`arquez, L., Carreras, X., Comas, P. 2007. Combination strategies for semantic role labeling. Journal of Artificial Intelligence Research, 29:105-151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Yoshua</author>
<author>G Yves</author>
</authors>
<title>No unbiased estimator of the variance of K-fold cross-validation</title>
<date>2004</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>5--1089</pages>
<marker>Yoshua, Yves, 2004</marker>
<rawString>Yoshua, B., and Yves, G. 2004. No unbiased estimator of the variance of K-fold cross-validation Journal of Machine Learning Research, 5:1089-1105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Weiwei</author>
<author>S Zhifang</author>
<author>W Meng</author>
<author>W Xing</author>
</authors>
<title>Chinese semantic role labeling with shallow parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing(EMNLP</booktitle>
<pages>1475--1483</pages>
<marker>Weiwei, Zhifang, Meng, Xing, 2009</marker>
<rawString>Weiwei, S., Zhifang, S., Meng, W., and Xing, W. 2009. Chinese semantic role labeling with shallow parsing. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing(EMNLP 2009), ACL, 1475-1483.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>