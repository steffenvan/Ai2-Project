<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.988517">
Using Pivot-Based Paraphrasing and Sentiment Profiles to Improve a
Subjectivity Lexicon for Essay Data
</title>
<author confidence="0.794247">
Beata Beigman Klebanov, Nitin Madnani, Jill Burstein
</author>
<affiliation confidence="0.748992">
Educational Testing Service
</affiliation>
<address confidence="0.577008">
660 Rosedale Road, Princeton, NJ 08541, USA
</address>
<email confidence="0.997015">
{bbeigmanklebanov,nmadnani,jburstein@ets.org}
</email>
<sectionHeader confidence="0.994991" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999234">
We demonstrate a method of improving a seed
sentiment lexicon developed on essay data by
using a pivot-based paraphrasing system for
lexical expansion coupled with sentiment pro-
file enrichment using crowdsourcing. Profile
enrichment alone yields up to 15% improve-
ment in the accuracy of the seed lexicon on 3-
way sentence-level sentiment polarity classifi-
cation of essay data. Using lexical expansion
in addition to sentiment profiles provides a
further 7% improvement in performance. Ad-
ditional experiments show that the proposed
method is also effective with other subjectivity
lexicons and in a different domain of applica-
tion (product reviews).
</bodyText>
<sectionHeader confidence="0.998126" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999951533333333">
In almost any sub-field of computational linguistics,
creation of working systems starts with an invest-
ment in manually-generated or manually-annotated
data for computational exploration. In subjectivity
and sentiment analysis, annotation of training and
testing data and construction of subjectivity lexicons
have been the loci of costly labor investment.
Many subjectivity lexicons are mentioned in the
literature. The two large manually-built lexicons
for English – the General Inquirer (Stone et al.,
1966) and the lexicon provided with the Opinion-
Finder distribution (Wiebe and Riloff, 2005) – are
available for research and education only1 and un-
der GNU GPL license that disallows their incor-
poration into proprietary materials,2 respectively.
</bodyText>
<footnote confidence="0.9858685">
1http://www.wjh.harvard.edu/ inquirer/j1 1/manual/
2http://www.gnu.org/copyleft/gpl.html
</footnote>
<bodyText confidence="0.984065484848485">
Those wishing to integrate sentiment analysis into
products, along with those studying subjectivity in
languages other than English, or for specific do-
mains such as finance, or for particular genres
such as MySpace comments, reported construction
of lexicons (Taboada et al., 2011; Loughran and
McDonald, 2011; Thelwall et al., 2010; Rao and
Ravichandran, 2009; Jijkoun and Hofmann, 2009;
Pitel and Grefenstette, 2008; Mihalcea et al., 2007).
In this paper, we address the step of expanding
a small-scale, manually-built subjectivity lexicon (a
seed lexicon, typically for a domain or language
in question) into a much larger but noisier lexi-
con using an automatic procedure. We present
a novel expansion method using a state-of-the-art
paraphrasing system. The expansion yields a 4-fold
increase in lexicon size; yet, the expansion alone
is insufficient in order to improve performance on
sentence-level sentiment polarity classification.
In this paper we test the following hypothesis.
We suggest that the effectiveness of the expansion
is hampered by (1) introduction of opposite-polarity
items, such as introducing resolute as an expansion
of forceful, or remarkable as an expansion of pecu-
liar; (2) introduction of weakly polar, neutral, or am-
biguous words as expansions of polar seed words,
such as generating concern as an expansion of anx-
iety or future as an expansion of aftermath;3 (3) in-
ability to distinguish between stronger or clear-cut
versus weaker or ambiguous sentiment and to make
a differential use of those.
We address items (1) and (2) by enriching the lexi-
con with sentiment profiles (section 3), and propose
</bodyText>
<note confidence="0.677943">
3Table 2 and Figure 1 provide support to these assessments.
99
Transactions of the Association for Computational Linguistics, 1 (2013) 99–110. Action Editor: Chris Callison-Burch.
Submitted 12/2012; Published 5/2013. c�2013 Association for Computational Linguistics.
</note>
<bodyText confidence="0.99717">
a way of effectively utilizing this information for
the sentence-level sentiment polarity classification
task (sections 5 and 6). Profile-enrichment alone
yields up to 15% increase in performance for the
seed lexicon when using different machine learning
algorithms; paraphraser-based expansion with sen-
timent profiles improves performance by an addi-
tional 7%. Overall, we observe an improvement of
up to 25% in classification accuracy over the seed
lexicon without profiles.
In section 7, we present comparative evaluations,
demonstrating the competitiveness of the expanded
and profile-enriched lexicon, as well as the effective-
ness of the expansion and enrichment paradigm pre-
sented here for different subjectivity lexicons, dif-
ferent lexical expansion methods, and in a different
domain of application (product reviews).
</bodyText>
<sectionHeader confidence="0.946756" genericHeader="introduction">
2 Building Subjectivity Lexicons
</sectionHeader>
<bodyText confidence="0.999912769230769">
The goal of our sentiment analysis project is to allow
for the identification of sentiment in sentences that
appear in essay responses to a variety of tasks de-
signed to test English proficiency in both native- and
non-native-speaker populations in a standardized as-
sessment as well as in an instructional settings. In
order to allow for the future use of the sentiment
analyzer in a proprietory product and to ensure its fit
to the test-taker essay domain, we began our work
with the construction of a seed lexicon relying on
our materials (section 2.1). We then used a statisti-
cal paraphrasing system to expand the seed lexicon
(section 2.2).
</bodyText>
<subsectionHeader confidence="0.977827">
2.1 Seed Lexicon
</subsectionHeader>
<bodyText confidence="0.999932470588235">
In order to inform the process of lexicon construc-
tion, we randomly sampled 5,000 essays from a cor-
pus of about 100,000 essays containing writing sam-
ples across many topics. Essays were responses
to several different writing assignments, including
graduate school entrance exams, non-native English
speaker proficiency exams, and professional licen-
sure exams. Our seed lexicon is a combination of
(1) positive and negative sentiment words manually
selected from a full list of word types in these data,
and (2) words marked in a small-scale annotation of
a sample of sentences from these data for all posi-
tive and negative words. A more detailed descrip-
tion of the construction of seed lexicon can be found
in Beigman Klebanov et al (2012). The seed lexi-
con contains 749 single words, 406 positive and 343
negative.
</bodyText>
<subsectionHeader confidence="0.987185">
2.2 Expanded Lexicon
</subsectionHeader>
<bodyText confidence="0.9999925625">
We used a pivot-based lexical and phrasal para-
phrase generation system (Madnani and Dorr, 2013).
The paraphraser implements the pivot-based method
as described by Bannard and Callison-Burch (2005)
with several additional filtering mechanisms to in-
crease the precision of the extracted pairs. The
pivot-based method utilizes the inherent monolin-
gual semantic knowledge from bilingual corpora:
We first identify phrasal correspondences between
English and a given foreign language F, then map
from English to English by following translation
units from English to the other language and back.
For example, if the two English phrases e1 and e2
both correspond to the same foreign phrase f, then
they may be considered to be paraphrases of each
other with the following probability:
</bodyText>
<equation confidence="0.96733">
p(e1|e2) ≈ p(e1|f)p(f|e2)
</equation>
<bodyText confidence="0.995267333333333">
If there are several pivot phrases that link the two
English phrases, then they are all used in computing
the probability:
</bodyText>
<equation confidence="0.9604305">
p(e1|e2) ≈ � p(e1|f&apos;)p(f&apos;|e2)
P
</equation>
<table confidence="0.9993474">
Seed Expansion Seed Expansion
abuse exploitation costly onerous
accuse reproach dangerous unsafe
anxiety disquiet improve reinforce
conflict crisis invaluable precious
</table>
<tableCaption confidence="0.999934">
Table 1: Examples of paraphraser expansions.
</tableCaption>
<bodyText confidence="0.999765">
Some examples of expansions generated by the
paraphraser are shown in Table 1. More details
about this kind of approach can be found in Ban-
nard and Callison-Burch (2005). We use the French-
English parallel corpus (approximately 1.2 million
sentences) from the corpus of European parliamen-
tary proceedings (Koehn, 2005) as the data on which
pivoting is performed to extract the paraphrases.
However, the base paraphrase system is susceptible
</bodyText>
<page confidence="0.506682">
100
</page>
<bodyText confidence="0.999833733333333">
to large amounts of noise due to the imperfect bilin-
gual word alignments. Therefore, we implement ad-
ditional heuristics in order to minimize the num-
ber of noisy paraphrase pairs (Madnani and Dorr,
2013). For example, one such heuristic filters out
pairs where a function word may have been inferred
as a paraphrase of a content word. For the lexicon
expansion experiment reported here, we use the top
15 single-word paraphrases for every word from the
seed lexicon, excluding morphological variants of
the seed word. This process results in an expanded
lexicon of 2,994 different words, 1,666 positive and
1,761 negative (433 words are in both the positive
and the negative lists). The expanded lexicon in-
cludes the seed lexicon.
</bodyText>
<sectionHeader confidence="0.961826" genericHeader="method">
3 Inducing sentiment profiles
</sectionHeader>
<equation confidence="0.8418242">
Let γw be the sentiment profile of the word w.
γw = (ppos
w ,pneg
w ,pneu
w ) (1)
</equation>
<bodyText confidence="0.99996575">
where Σi∈{pos,neg,neu} piw = 1. Thus, a sentiment
profile of a word is essentially a 3-sided coin, cor-
responding to its probability of coming out positive,
negative, and neutral, respectively.
</bodyText>
<subsectionHeader confidence="0.999466">
3.1 Estimating sentiment profiles
</subsectionHeader>
<bodyText confidence="0.9999941">
Our goal is to estimate the profile using outcomes of
multiple trials as follows. For every word, a person
is shown the word and asked whether it is positive,
negative, or neutral. A person’s decision is modeled
as flipping the coin corresponding to the word, and
recording the outcome – positive, negative, or neu-
tral. We run N=20 such trials for every word in the
expanded lexicon using the CrowdFlower crowd-
sourcing site,4 for a total cost of $800. We use maxi-
mum likelihood estimate of sentiment profile:
</bodyText>
<equation confidence="0.9972675">
ˆpiw = ni (2)
w
</equation>
<bodyText confidence="0.995725666666667">
where niw is the proportion of N trials on the word w
that fell in cell i E {pos, neg, neu}. Table 2 shows
some estimated profiles.
Following Goodman (1965) and Quesenberry and
Hurst (1964), we calculate confidence intervals for
the parameters pi w:
</bodyText>
<equation confidence="0.972262">
(ˆpiw)− = (B + 2niw − T)/(2(N + B)) (3)
</equation>
<footnote confidence="0.625066">
4www.crowdflower.com
</footnote>
<table confidence="0.999088571428571">
Word ˆppos ˆpneu ˆpneg
w w w
forceful 0 0.15 0.85
resolute 0.8 0.15 0.05
peculiar 0.05 0.15 0.8
remarkable 1 0 0
anxiety 0 0 1
concern 0.25 0.4 0.35
absurd 0 0 1
laughable 0.5 0.05 0.45
deadly 0 0 1
fateful 0.25 0.45 0.3
consequence 0.05 0.15 0.8
outcome 0.15 0.85 0
</table>
<tableCaption confidence="0.958672666666667">
Table 2: Examples of estimated sentiment profiles.
Words in gray are expansions generated from words in
the preceding row; note the difference in the profiles.
</tableCaption>
<equation confidence="0.958417">
(ˆpiw)+ = (B + 2niw + T)/(2(N + B)) (4)
where
�T = B[B + 4niw(N − niw)/N]) (5)
</equation>
<bodyText confidence="0.997145555555556">
For confidence α that all pi w, i E {pos, neg, neu}
are simultaneously within their respective intervals,
the value of B is determined as the upper α/3x100th
percentile of the χ2 distribution with one degree of
freedom. We use α=0.1, resulting in B=4.55. The
resulting interval is about 0.2 around the estimated
value when ˆpiw is close to 0.5, and somewhat nar-
rower for ˆpiw closer to 0 or 1. We will use this infor-
mation when inducing features from the profiles.
</bodyText>
<subsectionHeader confidence="0.999852">
3.2 Sentiment distributions of the lexicons
</subsectionHeader>
<bodyText confidence="0.9988065">
The estimated sentiment profiles per word allow us
to visualize the distributions of the two lexicons. In
Figure 1, we plot the number of entries in the lexi-
con as a function of the difference in positive and
negative parts of the profile, in 0.2-wide bins. Thus,
a word w would be in the second-leftmost bin if
</bodyText>
<equation confidence="0.554868666666667">
−0.8 &lt; (ˆppos
w − ˆpneg
w ) &lt; −0.6.
</equation>
<bodyText confidence="0.999897428571428">
While the expansion process more than doubles
the number of words in the highest bins for both
the positive and the negative polarity, it clearly
introduces a large number of words in the low-
and medium bins into the lexicon. It is in this
sense that the expansion process is noisy; appa-
rently, seed words with clear and strong polarity
</bodyText>
<figure confidence="0.98776136">
101
800
600
400
200
0
−1.0
05
−0.5
10
0.0
0.5
1.0
−1.0
−0.5
0.0
−.
0.5
−0.
1.0
800
600
400
200
0
</figure>
<figureCaption confidence="0.9944505">
Figure 1: Sentiment distributions for the seed (left) and
the expanded (right) lexicons.
</figureCaption>
<bodyText confidence="0.975723">
are often expanded into low intensity, neutral, or
</bodyText>
<equation confidence="0.536797">
1200 1200 120
</equation>
<bodyText confidence="0.9139025">
ambiguous ones, as in pairs like absurd/laughable,
deadly/fateful, anxiety/concern shown in Table 2.
</bodyText>
<sectionHeader confidence="0.999915" genericHeader="method">
4 Related Work
</sectionHeader>
<bodyText confidence="0.982075">
The most popular seed expansion methods discussed
</bodyText>
<equation confidence="0.9278935">
8 80
800
in the literature are based on WordNet (Miller,
1995) or another lexicographic resource, on dis-
600 600
600
</equation>
<bodyText confidence="0.95471">
tributional similarity with the seeds, or on a mix-
ture thereof (Cruz et al., 2011; Baccianella et al.,
</bodyText>
<equation confidence="0.815083142857143">
400 400
2010; Velikovich et al., 2010; Qiu et al., 2009; Mo-
400
hammad et al., 2009; Esuli and Sebastiani, 2006;
Kim and Hovy, 2004; Andreevskaia and Bergler,
200 200
200
</equation>
<bodyText confidence="0.6741195">
2006; Hu and Liu, 2004; Kanayama and Nasukawa,
2006; Strapparava and Valitutti, 2004; Kamps et al.,
</bodyText>
<equation confidence="0.536783666666667">
0 0
2004; Takamura et al., 2005; Turney and Littman,
0
</equation>
<bodyText confidence="0.97354562745098">
2003; Hatzivassiloglou and McKeown, 1997). The
tributional similarity camp; we also experimented
with WordNet-based expansion as descibed in sec-
tion 7.2.
The task of assigning sentiment profiles to words
in a sentiment lexicon has been addressed in the lite-
rature. SentiWordNet assigns profiles to all words in
WordNet based on a propagation algorithm from a
small seed set manually annotated by a small num-
ber of judges (Baccianella et al., 2010; Cerini et al.,
2007). Andreevskaia and Bergler (2006) use graph
propagation algorithms on WordNet to assign cen-
1
-
trality scores in positive and negative categories; a
800 800 800 8
similar approach based on web-scale co-occurrence
graphs is discussed in Velikovich et al (2010). Thel-
wall et al (2010) manually annotated a set of words
600 600 600 6
for strength of sentiment and used machine learning
to fine-tune it. Taboada et al (2011) produced an
400 400 400 4
expert annotation of their lexicon with strength of
sentiment. Subasic and Huettner (2001) manually
built an affect lexicon with intensities. Wiebe and
200 200 200
Riloff (2005) classifed lexicon entries into weakly
and strongly subjective, based on their relative fre-
0 0 0
quency of appearance in subjective versus objective
contexts in a large5annotated dataset.
Our sentiment profiles are best thought of as
relatively fine-grained priors for the sentiment ex-
pressed by a given word out-of-context. These re-
flect a mixture of strength of sentiment �ood &gt;
ppos
decent), contextual ambiguity (concern can be in-
terpreted as similar to worry or to care, as in “Her
condition was causing concern” versus “He showed
genuine concern for her”), and dominance of a po-
lar connotation (abandon is ˆpneg=1; it has a negative
overtone even if the actual sense is not that of desert
but of vacate, as in “You must abandon your office”).
To the best of our knowledge, this paper presents
the first attempt to integrate judgements obtained
through crowdsourcing on a large scale into0a sen-
timent lexicon, showing the effectiveness of this
lexicon-enrichment procedure for a sentiment clas-
sification task.
−
</bodyText>
<sectionHeader confidence="0.805328" genericHeader="method">
5 Using profiles for sentence-level
</sectionHeader>
<subsectionHeader confidence="0.839528">
sentiment polarity classification
</subsectionHeader>
<bodyText confidence="0.99972625">
To evaluate the usefulness of the lexicons, we use
them to generate features for machine learning sys-
level sentiment polarity classification. To ensure ro-
bustness of the observed trends, we experiment with
a number of machine learning algorithms: SVM
Linear and RBF, Naive Bayes, Logistic Regression
(using WEKA (Hall et al., 2009)), and c5.0 Decision
Trees (Quinlan, 1993).5
</bodyText>
<subsectionHeader confidence="0.992319">
5.1 Data
</subsectionHeader>
<bodyText confidence="0.9998735">
We generated the data for training and testing the
machine learning systems as follows. We used our
</bodyText>
<footnote confidence="0.523758">
5available from http://rulequest.com/
</footnote>
<figure confidence="0.995263211538462">
0
0.0
0− 0.
5− 1.0
00
05
10
1
05
0.0
0 0.5
5− 1.
00
paraphrase-based expansion method is in the dis-
0−
tems, and compare5performance on 3-way sentence-
y
y
.0
y
n
.
7
. 0
00
05
CD �
10 n&apos;
1
y
5
n
.0
CD
7
n�
.5.
.
CD
0 0
1.0
.0
5
0
1 5
0 0
0.
0.
1.0
- 0 ,
ywa3- performance sentence- ,estm on compare and
102
</figure>
<bodyText confidence="0.999595823529412">
pool of 100,000 essays to sample a second, non-
overlapping set of 5,000 essays, so that no essay
used for lexicon development appears in this set.
From these essays, we randomly sampled 550 sen-
tences, and submitted them to sentiment polarity an-
notation by two experienced research assistants; 50
double-annotated sentenced showed K=0.8. TEST
set contains the 43 agreed double-annotated sen-
tences, and additional 238 sampled from the 500
single-annotated sentences, 281 sentence in total.
The category distribution in the TEST set is 46.6%
neutral, 32.4% positive, and 21% negative.
The TRAIN set contains the remaining sentences,
plus positive, negative, and neutral sentences anno-
tated during lexicon development, for the total of
1,631 sentences. The category distribution in TRAIN
is 39% neutral, 35% positive, 26% negative.
</bodyText>
<subsectionHeader confidence="0.997997">
5.2 From lexicons to features
</subsectionHeader>
<bodyText confidence="0.995425025">
Our goal is to evaluate the impact of sentiment pro-
files on sentence-level sentiment polarity classifica-
tion for the seed and the expanded lexicons, while
also looking for the most effective ways to represent
this information for machine learners.
We implement two baseline systems. One pro-
vides the machine learner with the most detailed in-
formation contained in a lexicon: BL-full has 2 fea-
tures for every lexicon word, taking the values (1,0)
for positive match in a sentence, (0,1) – for negative,
(1,1) for a word in both positive and negative parts
of the lexicon, and (0,0) otherwise.
The second baseline provides the machine learner
with only summary information about the overall
sentiment of the sentence. BL-sum uses only 2 fea-
tures: (1) the total count of positive words in the
sentence; (2) the total count of negative words in the
sentence, according to the given lexicon.
For the sentiment-enriched runs, we construct a
number of representations: Int-full, Int-sum, Int-
bin, and Int-c. Int-full and Int-sum are parallel to
the respective baseline systems. Int-full represents
each lexicon word as 2 features corresponding to the
word’s estimated ˆppos
w and ˆpneg
w , providing the most
detailed information to the machine learner. In the
Int-sum condition, we use ˆppos
w and ˆpneg
w for every
word to induce 2 features: (1) the sum of positive
probabilities of all words in the sentence; (2) the
sum of negative probabilities for all words in the
sentence, according to the given lexicon.
For Int-bin runs, we use bins of the size of 0.2 –
half of the maximal confidence interval – to group
together words with close estimates. We produce
10 features. For positive bins, the 5 features count
the number of words in the sentence that fall in
bini, 1 ≤ i ≤ 5, respectively, that is, words with
</bodyText>
<equation confidence="0.650032">
0.2(i −1) &lt; ˆppos
w ≤ 0.2i. Bin 1 also includes words
with ˆppos
</equation>
<bodyText confidence="0.9837753">
w = 0, since these cannot be distinguished
with high confidence from ˆppos
w =0.1. Note that we
do not provide a scale, we merely represent different
ranges with different features. This should allow the
machine learners the flexibility to weight the diffe-
rent bins differently when inducing classifiers.
The Int-c condition represents a coarse-grained
setting. We produce 4 features, two for each pola-
rity: (1) the number of words such that 0 ≤ ˆppos
</bodyText>
<equation confidence="0.800374333333333">
w &lt;
0.4; (2) the number of words such that 0.4 ≤ ˆppos
w ≤
</equation>
<tableCaption confidence="0.705377">
1; similarity for the negative polarity.
Table 3 summarizes conditions and features.
</tableCaption>
<table confidence="0.9999628">
Cond. #F Feature Description
BL-full 2|L |(1L11 nS(w), 1L—,nS(w))
BL-sum 2 f1=|{w : w ∈ Lpos ∩ S}|
f2=|{w : w ∈ Lneg ∩ S}|
Int-full 2|L |w , ˆpneg
(ˆppos
w ) ∀w ∈ A
Int-sum 2 w , EwEA ˆpneg
(EwEA ˆppos
w )
Int-bin 10 f1=|{w ∈ A : 0 ≤ ˆppos
w ≤ 0.2}|
...
f10=|{w ∈ A : 0.8 &lt; ˆpneg
w ≤ 1}|
Int-c 4 f1=|{w ∈ A : 0 ≤ ˆppos
w &lt; 0.4}|
...
f4=|{w ∈ A : 0.4 ≤ ˆpneg
w ≤ 1}|
</table>
<tableCaption confidence="0.99877">
Table 3: Description of conditions. Column 2 shows the
</tableCaption>
<bodyText confidence="0.862294666666667">
number of features. In column 3: 1 is an indicator func-
tion; L is a lexicon; LPO3 is the part of the lexicon con-
taining positive words (same with negatives); S is a sen-
tence for which a feature vector is built; A = L ∩ S. For
all w ∈ L − S in the -full conditions, w is represented
with (0,0).
</bodyText>
<sectionHeader confidence="0.999938" genericHeader="method">
6 Results
</sectionHeader>
<bodyText confidence="0.989381">
Table 4 shows classification accuracies for 5 ma-
chine learning systems across 6 conditions, for the
seed and the expanded lexicons.
Let BL denote the best-performing baseline (BL-
</bodyText>
<table confidence="0.988263617647059">
103
Machine Condition Seed Expanded
Learner
– Majority 0.466 0.466
c5.0 BL-full 0.441 0.498
BL-sum 0.512 0.480
Int-full 0.441 0.498
Int-sum 0.566 0.616
Int-bin 0.587 0.641
Int-c 0.530 0.577
SVM BL-full 0.466 0.466
RBF BL-sum 0.527 0.495
Int-full 0.466 0.466
Int-sum 0.548 0.601
Int-bin 0.573 0.644
Int-c 0.530 0.562
SVM BL-full 0.584 0.566
Linear BL-sum 0.509 0.502
Int-full 0.580 0.609
Int-sum 0.601 0.580
Int-bin 0.573 0.630
Int-c 0.569 0.569
Logistic BL-full 0.545 0.509
Regression BL-sum 0.545 0.509
Int-full 0.534 0.502
Int-sum 0.555 0.584
Int-bin 0.584 0.616
Int-c 0.545 0.577
Naive BL-full 0.598 0.584
Bayes BL-sum 0.509 0.473
Int-full 0.598 0.580
Int-sum 0.545 0.605
Int-bin 0.559 0.626
Int-c 0.537 0.601
</table>
<tableCaption confidence="0.9195786">
Table 4: Classification accuracies on TEST set. Majo-
rity baseline corresponds to classifying all sentences as
neutral. The best performance is boldfaced. Let BL
stand for the best-performing baseline (BL-full or BL-
sum) for a combination of machine learner and lexicon.
</tableCaption>
<table confidence="0.9647348">
We use Wilcoxon Signed-Rank test, reporting the num-
ber of signed ranks (N) and the sum of signed ranks (W).
Statistically significant results at p=0.05 are: Int-sum &gt;
BL (N=10, W=43); Int-bin &gt; BL (N=10, W=48); Int-
bin &gt; Int-sum (N=10, W=43); Int-bin &gt; Int-full (N=10,
W=47); Int-sum &gt; Int-full (N=10, W=37); Int-bin &gt; Int-
c (N=10, W=55); Int-sum &gt; Int-c (N=10, W=55); Ex-
panded &gt; Seed under Int condition (includes Int-full, Int-
sum, Int-bin, Int-c) (N=18, W=152, z=3.3). Differences
between Int-full, Int-c, and BL are not significant.
</table>
<bodyText confidence="0.983499022727273">
full or BL-sum) for a combination of machine
learner and lexicon. The results show that (1) Int-
bin &gt; Int-sum &gt; BL = Int-c = Int-full; (2) Ex-
panded &gt; Seed under Int condition. All inequalities
are statistically significant at p=0.05 (see caption of
Table 4 for details).
First, both the seed and the expanded lexicons
benefit from profile enrichment, although, as pre-
dicted, the expanded lexicon yields larger gains due
to its more varied profiles: The seed lexicon gains up
to 15% in accuracy (c5.0 BL-sum vs Int-bin), while
the expanded lexicon gains up to 30%, as SVM RBF
scores go up from 0.495 to 0.644.
Second, observe that profiling allows the ex-
panded lexicon to leverage its improved coverage:
While it is inferior to the best baseline run with the
seed lexicon for all systems, it succeeds in impro-
ving the seed lexicon accuracies by 5%-12% across
the different systems for the Int-bin runs. The best
run of the expanded lexicon (Int-bin for SVM RBF)
improves upon the best run of the seed lexicon (Int-
sum for SVM-linear) by 7%, demonstrating the suc-
cess of the paraphraser-based expansion once pro-
files are taken into account. Overall, comparing the
best baseline for the seed lexicon with Int-bin con-
dition of the expanded lexicon, we observe an im-
provement between 5% (0.598 to 0.626 for Naive
Bayes) and 25% (0.512 to 0.641 for c5.0), proving
the effectiviness of the paraphrase-based expansion
with profile enrichment paradigm.
Third, representing profiles using 10 bins (Int-bin)
provides a small but consistent improvement over
the summary representation (Int-sum) that sums
positivity and negativity of the sentiment-bearing
words in a sentence, over a coarse-grained represen-
tation (Int-c), as well as over the full-information
representation (Int-full). Even Naive Bayes and
SVM linear, known to work well with large feature
sets, show better performance in the Int-bin con-
dition for the expanded lexicon. The results indi-
cate that an intermediate degree of detail – between
summary-only and coarse-grained representation on
the one hand and full-information representation on
the other – is the best choice in our setting.
</bodyText>
<page confidence="0.941169">
104
</page>
<sectionHeader confidence="0.996286" genericHeader="method">
7 Comparative Evaluations
</sectionHeader>
<bodyText confidence="0.999993052631579">
In this section, we present comparative evaluations
of the work presented in this paper with respect to
related work. This section shows that the paraphrase
expansion+profile enrichment solution proposed in
this paper is effective for our task beyond off-the-
shelf solutions, and that its effectiveness generalizes
to sentiment analysis in a different domain. We also
show that profile enrichment can be effectively cou-
pled with other methods of lexical expansion, al-
though the paraphraser-based expansion receives a
larger boost in performance from profile enrichment
than the alternative expansion methods we consider.
In section 7.1, we demonstrate that the
paraphrase-based expansion and profile enrich-
ment yield superior performance on our data
relative to state-of-art subjectivity lexicons – Opin-
ionFinder, General Inquirer, and SentiWordNet.
In section 7.2, we show that profile enrichment
can be effectively coupled with other methods
of lexical expansion, such as a WordNet-based
expansion and an expansion that utilizes Lin’s
distributional thesaurus. However, we find that the
paraphraser-based expansion benefits the most from
profile enrichment, and attains better performance
on our data than the alterantive expansion methods.
In section 7.3, we show that the paraphrase-based
expansion and profile enrichment paradigm is
effective for other subjecitivy lexicons on other
data. We use a dataset of product reviews annotated
for sentence-level positivity and negativity as
new data for evaluation (Hu and Liu, 2004). We
use subsets of OpinionFinder, General Inquirer,
and sentiment lexicon from Hu and Liu (2004).
We demonstrate that paraphrase-based expansion
and profile enrichment improve the accuracy of
sentiment classification of product reviews for
every lexicon and machine learner combination; the
magnitude of improvement is 5% on average.
</bodyText>
<subsectionHeader confidence="0.99304">
7.1 Competitiveness of the Expanded Lexicon
</subsectionHeader>
<bodyText confidence="0.99976925">
Had we been able to use the OpinionFinder or
the General Inquirer lexicons (OFL and GIL) as-
is, how would the results have compared to those
attained using our lexicons? We performed the
baseline runs with both lexicons; OFL accuracies
were 0.544-0.594 across machine learning systems,
GIL’s – 0.491-0.584 (see GIL column in Table 5).
We also experimented with using the weaksubj
and strongsubj labels in OFL as somewhat parallel
distinctions to the ones presented here (see sec-
tion 4 – Related Work – for a more detailed discus-
sion). We used (1,0,0) profile for strong positives,
(0.3,0,0.7) for weak positives, (0,1,0) for strong neg-
atives, and (0,0.3,0.7) for weak negatives, and ran all
the feature representations discussed in section 5.2.
Table 5 column OFL shows the best run for every
machine learning system, across the different feature
representations, and choosing the better performing
run between vanilla OFL and the version enriched
with weak/strong distinctions.
</bodyText>
<table confidence="0.998800142857143">
Machine Seed OFL GIL SWN Exp.
Learner BL
c5.0 0.512 0.598 0.491 0.516 0.641
SVM-RBF 0.527 0.594 0.495 0.520 0.644
SVM-lin. 0.584 0.594 0.580 0.569 0.630
Log. Reg. 0.545 0.598 0.541 0.537 0.616
Naive B. 0.598 0.573 0.584 0.587 0.626
</table>
<tableCaption confidence="0.763596">
Table 5: Performance of different lexicons on essay data
using various machine learning systems. For each sys-
</tableCaption>
<bodyText confidence="0.997427347826087">
tem and lexicon, the best performance across the applica-
ble feature representations from section 5.2 and the vari-
ants (see text) is shown. Seed BL column shows the best
baseline performance of our seed lexicon – before para-
phraser expansion and profile enrichment were applied.
Exp. column shows the performance of Int-bin feature
representation for the expanded lexicon after profile en-
richment.
Additionally, we experimented with SentiWord-
Net (Baccianella et al., 2010). SentiWordNet is a
resource for opinion mining built on top of Word-
Net, which assigns each synset in WordNet a score
triplet (positive, negative, and objective), indicating
the strength of each of these three properties for the
words in the synset. The SentiWordNet annotations
were automatically generated, starting with a set of
manually labeled synsets. Currently, SentiWordNet
includes an automatic annotation for all the synsets
in WordNet, totaling more than 100,000 words. It
is therefore the largest-scale lexicon with intensity
information that is currently available.
Since SentiWordNet assigns scores to synsets and
since our data is not sense-tagged, we induced Sen-
</bodyText>
<figure confidence="0.953820956521739">
105
800
600
400
200
0
800
600
400
200
0
−1.0
−0.5
0.0
0.5
1.0
−1.0
−0.5
0.0
0.5
1.0
tiWordNet scores in the following ways. We part-
800
</figure>
<bodyText confidence="0.9996859375">
of-speech tagged our train and test data using Stan-
ford tagger (Toutanova et al., 2003). Then, we took
the SentiWordNet scores for the top sense for the
given part-of-speech (SWW-1). In a different vari-
ant, we took a weighted average of the scores for the
different senses, using the weighting algorithm pro-
vided on SentiWordNet website6 (SWN-2). Table 5
column SWN shows the best performance figures
between SWN-1 and SWN-2, across the feature rep-
resentations in section 5.2.
The comparative results in Table 5 clearly show
that while our vanilla seed lexicon performs com-
parably to off-the-shelf lexicons on our data, the
paraphraser-expanded lexicon with sentitment pro-
files outperforms OpinionFinder, General Inquirer,
and SentiWordNet.
</bodyText>
<figure confidence="0.641851">
1
0
</figure>
<subsectionHeader confidence="0.857302">
7.2 Sentiment Profile Enrichment with Other
Lexical Expansion Methods
</subsectionHeader>
<bodyText confidence="0.999836666666667">
We presented a novel lexicon expansion method
using a paraphrasing system. We also experimented
with more standard methods, using WordNet and
distributional similarity (Beigman Klebanov et al.,
2012; Esuli and Sebastian,02006; Kim and Hovy,
2004; Andreevskaia and Bergler, 2006; Hu and Liu,
2004; Kanayama and Nasukawa, 2006; Strapparava
and Valitutti, 2004; Kamps et al., 2004; Takamura
et al., 2005; Turney and Littman, 2003; Hatzivas-
</bodyText>
<equation confidence="0.512279">
0
</equation>
<bodyText confidence="0.999955352941177">
siloglou and McKeown, 1997). Specifically, we im-
plemented a WordNet (Miller, 1995)0based expan-
sion that uses the 3 most frequent synonyms of the
top sense of the seed word (WN-e). We also imple-
mented a method based on distributional similarity:
Using Lin’s proximity-based thesaurus (Lin, 1998)
trained on our in-house essay data as well as on well-
formed newswire texts, we took all words with the
proximity score &gt; 1.80 to any of the seed lexicon
words (Lin-e). Just like the paraphraser lexicon,
both perform worse than the seed lexicon in 9 out
of 10 baseline runs (BL-sum and Bl-full conditions
for the 5 machine learners).
To test the effect of profile enrichment, all words
in WN-e and Lin-e underwent profile estimation as
described in section 3.1, yielding lexicons WN-e-p
and Lin-e-p, respectively. Figure 2 shows the distri-
</bodyText>
<figure confidence="0.9700205">
0
0.0 td
05
.0
a
0
5
0.5
0
6http://sentiwordnet.isti.cnr.it/, under “Sample code.”
</figure>
<figureCaption confidence="0.997125">
Figure 2: Sentiment profile distributions for Lin-e-p (left)
and WN-e-p (right) lexicons.
</figureCaption>
<figure confidence="0.702892">
0.0 a
sed
butions. WN-e-p and Lin-e-p exhibit similar trends
1200 1200
</figure>
<bodyText confidence="0.94719325">
to those of the paraphraser. Substituting WN-e-p
for0Expanded data in Table 4, we find the same re-
lationships between the different feature sets: Int-
bin&gt;Int-sum&gt;Int-full=BL. For Lin-e-p, Int-sum de-
</bodyText>
<figure confidence="0.925178666666667">
800 800
teriorates: Int-bin&gt;Int-sum=Int-full=BL. For the
10−
20 runs in the Int condition, Paraphraser&gt;WN-e-
600 05 600
p&gt;Lin-e-p.7 Note that this is also the order of lexi-
0
con sizes: Lin-e is the most conservative expan-
0
sion (1,907 words), WN-e is the second with 2,527
0
1
</figure>
<bodyText confidence="0.915244117647059">
words, and the lexicon expanded using paraphrasing
is the largest with 2,994 words. Table 6 shows the
200 200
performance of Lin-e-p, WN-e-p, and of the Ex-
panded lexicon from Table 4 using the Int-bin fea-
0 0
ture representation. The average relative improve-
ments over the best baseline range between 6.6% to
14.6% for the different expansion methods.
Profile induction appears to be a powerful lexicon
clean-up procedure that works especially well with
more aggressive and thus potentially noisier expan-
1
sions: The machine learners depress low-intensity
and ambiguous expansions, thereby allowing the
effective utilization of the improved coverage of
sentiment-bearing vocabulary.
</bodyText>
<subsectionHeader confidence="0.746125333333333">
7.3 Effectiveness of the Paraphrase Expansion
with Profile Enrichment Paradigm in a
Different Domain
</subsectionHeader>
<bodyText confidence="0.999815333333333">
In order to check whether the paraphrase-based ex-
pasion and profile enrichment paradigm discussed in
this paper generalizes to other subjectivity lexicons
</bodyText>
<table confidence="0.888523454545454">
7All &gt; are signficant at p=0.05 using Wilcoxon test.
c
106
Machine Seed Lin-e-p WN-e-p Exp.
Learner BL
c5.0 0.512 0.584 0.616 0.641
SVM-RBF 0.527 0.598 0.601 0.644
SVM-lin. 0.584 0.577 0.569 0.630
Log. Reg. 0.545 0.587 0.580 0.616
Naive B. 0.598 0.591 0.623 0.626
Av. Gain 0.066 0.085 0.146
</table>
<tableCaption confidence="0.974722">
Table 6: Performance of WordNet-based, Lin-based, and
</tableCaption>
<bodyText confidence="0.930002">
Paraphraser-based expansions with profile enrichment in
the Int-bin condition. Seed BL column shows the best
baseline performance of the seed lexicon – before expan-
sion and profile enrichment were applied. The last line
shows the average relative gain over the best baseline
calculated as AGlex = Em∈M LexSeedB dBLm , where
</bodyText>
<equation confidence="0.4560685">
SeedBLm
M = {c5.0, SVM-RBF, SVM-linear, Logistic Regres-
</equation>
<bodyText confidence="0.96777975">
sion, Naive Bayes}, and lex E {Lin-e-p, Wn-e-p, Exp}.
and domains of application, we experimented with
a product reviews dataset (Hu and Liu, 2004) and
additional lexicons as follows.
</bodyText>
<subsectionHeader confidence="0.933537">
7.3.1 Lexicons
</subsectionHeader>
<bodyText confidence="0.999966363636364">
We use the OpinionFinder and General Inquirer
lexicons (OFL and GIL) as before, as well as
the lexicon of positive and negative sentiment and
opinion words available along with (Hu and Liu,
2004) product reviews dataset – HL.8
Since each of these lexicons contains more than
3,000 words, enrichment of the full lexicons with
profiles is beyond the financial scope of our project.
We therefore restrict each of the lexicons to the size
of their overlap with our seed lexicon (see 2.1); the
overlaps have between 415 and 467 words. These re-
stricted lexicons are our initial lexicons for the new
experiment that parallel the role of the seed lexicon
in the experiments on essay data.
For each of the 3 initial lexicons L, LE{OFL,
GIL, HL}, we follow the paraphrase-based expan-
sion as described in section 2.2. This results in about
4.5-fold expansion of each lexicon, the new lexi-
cons L-e, LE{OFL, GIL, HL}, numbering between
2,015 and 2,167 words. Both the initial and the ex-
panded lexicons now undergo profile enrichment as
described in section 3.1, producing lexicons L-p and
</bodyText>
<figure confidence="0.13542625">
8http://www.cs.uic.edu/—liub/FBS/sentiment-
analysis.html#lexicon
L-e-p, LE{OFL, GIL, HL}.
7.3.2 Data
</figure>
<bodyText confidence="0.999978545454545">
We use the dataset from Hu and Liu (2004)9 that
contains reviews of 5 products from amazon.com:
two digital cameras, a DVD player, an MP3 player,
and a cellular phone. The reviews are annotated at
sentence level with a label that desrcibes the par-
ticular feature that is the subject of the positive or
negative evaluation and the polarity and extent of
the evaluation. For example, the sentence “The
phone book is very user-friendly and the speaker-
phone is excellent” is labeled as PHONE BOOK[+2],
SPEAKERPHONE[+2], while the sentence “I am
bored with the silver look” is labeled LOOK[−1]. We
used all sentences that were labeled with a numeri-
cal score for at least one feature, removing a small
number of sentences labeled with both positive and
negative scores for different features.10 We used the
sign of the numerical score to label the sentences as
positive or negative. The resulting dataset consists
of 1,695 sentences, 1,061 positive and 634 nega-
tive; accuracy for a majority baseline on this dataset
is 0.626. Our experiments on this dataset are done
using 5-fold cross-validation.
</bodyText>
<sectionHeader confidence="0.875258" genericHeader="evaluation">
7.3.3 Results
</sectionHeader>
<bodyText confidence="0.998706588235294">
Table 7 shows classification accuracies for the
product review data using different lexicons and ma-
chine learners. We observe that the combination of
paraphrase-based expansion and profile enrichment
(L-e-p column in the table) resulted in an improved
performance over the initial lexicon (L column in
the table) in all cases, with the average gain of 5%
in accuracy.
Furthermore, the contributions of the expansion
and the profile enrichment are complementary, since
their combination performs better than each in iso-
lation. We note that profile enrichment alone for the
initial lexicon did not yield an improvement. This
can be explained by the fact that the initial lexicons
are highly polar, so profiles provide little additional
information: The percentage of words with ˆppo3 &gt;
0.8 or ˆpne9 &gt; 0.8 is 84%, 86% and 91% for GIL,
</bodyText>
<footnote confidence="0.2921888">
9http://www.cs.uic.edu/—liub/FBS/sentiment-
analysis.html#datasets, the link under “Customer Review
Datasets (5 products)”
10such as “The headset that comes with the phone has good
sound volume but it hurts the ears like you cannot imagine!”
</footnote>
<table confidence="0.988806727272727">
107
Machine Lexicon Variant
Learner
L L-p L-e L-e-p
L = OFL∩Seed, |L|=467, |L-e|=2,167
c5.0 0.663 0.670 0.691 0.704
SVM-RBF 0.668 0.676 0.693 0.714
SVM-lin. 0.675 0.670 0.688 0.696
Log. Reg. 0.666 0.658 0.693 0.698
Naive B. 0.668 0.668 0.686 0.695
L = GIL∩Seed, |L|=415,|L-e|=2,015
c5.0 0.644 0.658 0.663 0.686
SVM-RBF 0.650 0.665 0.653 0.683
SVM-lin. 0.665 0.665 0.677 0.681
Log. Reg. 0.664 0.658 0.678 0.694
Naive B. 0.669 0.666 0.678 0.703
L = HL∩Seed, |L|=434, |L-e|=2,054
c5.0 0.676 0.675 0.689 0.706
SVM-RBF 0.673 0.674 0.700 0.713
SVM-lin. 0.676 0.664 0.703 0.710
Log. Reg. 0.668 0.661 0.703 0.699
Naive B. 0.668 0.672 0.697 0.697
</table>
<tableCaption confidence="0.997787">
Table 7: Accuracies on product review data. For each ma-
</tableCaption>
<bodyText confidence="0.981907076923077">
chine learner and lexicon, the best baseline performance
is shown as L for the initial lexicon and as L-e for the
paraphrase-expanded lexicon. L-p and L-e-p show the
performance of Int-bin feature set on the profile-enriched
initial and paraphrase-expanded lexicons, respectively.
The three initial lexicons L are OpinionFinder (OFL),
General Inquirer (GIL), and (Hu and Liu, 2004) (HL),
each intersected with our seed lexicon. Sizes of the intial
and expanded lexicons are provided.
OFL, and HL-derived lexicons, respectively. In con-
trast, for the expanded lexicons, these percentages
are 51%, 53%, and 56%; these lexicons benefit from
profile enrichment.
</bodyText>
<sectionHeader confidence="0.99881" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999986227272728">
We demonstrated a method of improving a seed sen-
timent lexicon by using a pivot-based paraphrasing
system for lexical expansion and sentiment profile
enrichment using crowdsourcing. Profile enrich-
ment alone yielded up to 15% improvement in the
performance of the seed lexicon on the task of 3-
way sentence-level sentiment polarity classification
of test-taker essay data. While the lexical expansion
on its own failed to improve upon the performance
of the seed lexicon, it became much more effective
on top of sentiment profiles, generating a 7% perfor-
mance boost over the best profile-enriched run with
the seed lexicon. Overall, paraphrase-based expan-
sion coupled with profile enrichment yields an up to
25% improvement in accuracy.
Additionally, we showed that our paraphrase-
expanded and profile-enriched lexicon performs
significantly better on our data than off-the-shelf
subjectivity lexicons, namely, Opinion Finder, Gen-
eral Inquirer, and SentiWordNet. Furthermore, our
results suggest that paraphrase-based expansion de-
rives more benefit from profiles than two competing
expansion mechanisms based on WordNet and on
Lin’s distributional thesaurus.
Finally, we demonstrated the effectiveness of the
paraphraser-based expansion with profile enrich-
ment paradigm on a different dataset. We used Hu
and Liu (2004) product review data with sentence-
level sentiment polarity labels. Paraphrase-based
expansion with profile enrichment yielded an im-
proved performance across all lexicons and machine
learning algorithms we tried, with an average im-
provement rate of 5% in classification accuracy.
Recent literature argues that sentiment polarity
is a property of word senses, rather than of words
(Gyamfi et al., 2009; Su and Markert, 2008; Wiebe
and Mihalcea, 2006), although Dragut et al (2012)
successfully operate with “mostly negative” and
“mostly positive” words based on the polarity distri-
butions of word senses. We plan to address in future
work sense disambiguation for words that have mul-
tiple senses with very different sentiment, such as
stress, as either anxiety (negative) or emphasis (neu-
tral).
</bodyText>
<sectionHeader confidence="0.996032" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998863833333333">
Alina Andreevskaia and Sabine Bergler. 2006. Mining
WordNet for a fuzzy sentiment: Sentiment tag extrac-
tion of WordNet glosses. In Proceedings of EACL,
pages 209–216, Trento, Italy.
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. SENTIWORDNET 3.0: An Enhanced
Lexical Resource for Sentiment Analysis and Opinion
Mining. In Proceedings of LREC, pages 2200–2204,
Malta.
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In Proceed-
ings of ACL, pages 597–604, Ann Arbor, MI.
</reference>
<page confidence="0.811512">
108
</page>
<reference confidence="0.999502330188679">
Beata Beigman Klebanov, Jill Burstein, Nitin Madnani,
Adam Faulkner, and Joel Tetreault. 2012. Build-
ing sentiment lexicon(s) from scratch for essay data.
In Proceedings of the 13th International Conference
on Intelligent Text Processing and Computational Lin-
guistics (CICLing), New Delhi, India, March.
S. Cerini, V. Compagnoni, A. Demontis, M. Formentelli,
and G. Gandini. 2007. Micro-WNOp: A gold stan-
dard for the evaluation of automatically compiled lexi-
cal resources for opinion mining. In Andrea Sanso,
editor, Language resources and linguistic theory: Ty-
pology, second language acquisition, pages 200–210.
Franco Angeli Editore, Milano, IT.
Fermin L. Cruz, Jos´e A. Troyano, F. Javier Ortega, and
Fernando Enriquez. 2011. Automatic expansion
of feature-level opinion lexicons. In Proceedings of
the 2nd Workshop on Computational Approaches to
Subjectivity and Sentiment Analysis, pages 125–131,
Portland, Oregon, June.
Eduard Dragut, Hong Wang, Clement Yu, Prasad Sistla,
and Weiyi Meng. 2012. Polarity consistency check-
ing for sentiment dictionaries. In Proceedings of the
50th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
997–1005, Jeju Island, Korea, July. Association for
Computational Linguistics.
Andrea Esuli and Fabrizio Sebastiani. 2006. Determin-
ing term subjectivity and term orientation for opinion
mining. In Proceedings of EACL, pages 193–200,
Trento, Italy.
Leo A. Goodman. 1965. On Simultaneous Confidence
Intervals for Multinomial Proportions. Technometrics,
7(2):247–254.
Yaw Gyamfi, Janyce Wiebe, Rada Mihalcea, and Cem
Akkaya. 2009. Integrating knowledge for subjectivity
sense labeling. In Proceedings of NAACL, pages 10–
18, Boulder, CO.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA Data Mining Software: An Update.
SIGKDD Explorations, 11.
Vasileios Hatzivassiloglou and Kathleen McKeown.
1997. Predicting the semantic orientation of adjec-
tives. In Proceedings ofACL, pages 174–181, Madrid,
Spain.
Minqing Hu and Bing Liu. 2004. Mining and
summarizing customer reviews. In Proceedings of
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining, pages 168–177,
Seattle, WA.
Valentin Jijkoun and Katja Hofmann. 2009. Gener-
ating a Non-English Subjectivity Lexicon: Relations
That Matter. In Proceedings of EACL, pages 398–405,
Athens, Greece.
Jaap Kamps, Maarten Marx, Robert Mokken, and
Maarten de Rijke. 2004. Using WordNet to measure
semantic orientation of adjectives. In Proceedings of
LREC, pages 1115–1118, Lisbon, Portugal.
Hiroshi Kanayama and Tetsuya Nasukawa. 2006. Fully
automatic Lexicon Expansion for Domain-oriented
Sentiment Analysis. In Proceedings of EMNLP, pages
355–363, Syndey, Australia.
Soo-Min Kim and Edward Hovy. 2004. Determining the
sentiment of opinions. In Proceedings of COLING,
pages 1367–1373, Geneva, Switzerland.
Philip Koehn. 2005. EUROPARL: A Parallel corpus for
Statistical Machine Translation. In Proceedings of the
Machine Translation Summit.
Dekang Lin. 1998. Automatic retrieval and clustering of
similar words. In Proceedings ofACL, pages 768–774,
Montreal, Canada.
Tim Loughran and Bill McDonald. 2011. When is a Li-
ability not a Liability? Textual Analysis, Dictionaries,
and 10-Ks. Journal of Finance, 66:35–65.
Nitin Madnani and Bonnie Dorr. 2013. Generating Tar-
geted Paraphrases for Improved Translation. ACM
Transactions on Intelligent Systems and Technology, to
appear.
Rada Mihalcea, Carmen Banea, and Janyce Wiebe. 2007.
Learning multilingual subjective language via cross-
lingual projections. In Proceedings of ACL, pages
976–983, Prague, Czech Republic.
George Miller. 1995. WordNet: A lexical database.
Communications of the ACM, 38:39–41.
Saif Mohammad, Cody Dunne, and Bonnie Dorr. 2009.
Generating high-coverage semantic orientation lexi-
cons from overtly marked words and a thesaurus. In
Proceedings of EMNLP, pages 599–608, Singapore,
August.
Guillaume Pitel and Gregory Grefenstette. 2008. Semi-
automatic building method for a multidimensional af-
fect dictionary for a new language. In Proceedings of
LREC, Marrakech, Morocco.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2009.
Expanding domain sentiment lexicon through double
propagation. In Proceedings of the 21st international
jont conference on Artifical intelligence, IJCAI’09,
pages 1199–1204.
C. Quesenberry and D. Hurst. 1964. Large sample si-
multaneous confidence intervals for multinomial pro-
portions. Technometrics, 6:191–195.
J. R. Quinlan. 1993. C4.5: Programs for machine lear-
ning. Morgan Kaufmann Publishers.
Delip Rao and Deepak Ravichandran. 2009. Semi-
supervised polarity lexicon induction. In Proceedings
of EACL, pages 675–682, Athens.
</reference>
<page confidence="0.60433">
109
</page>
<reference confidence="0.999337021739131">
Philip Stone, Dexter Dunphy, Marshall Smith, and Daniel
Ogilvie. 1966. The General Inquirer: A Computer
Approach to Content Analysis. MIT Press.
Carlo Strapparava and Alessandro Valitutti. 2004.
WordNet-affect: an affective extension of WordNet.
In Proceedings of LREC, pages 1083–1086, Lisbon,
Portugal.
Fangzhong Su and Katja Markert. 2008. Eliciting
Subjectivity and Polarity Judgements on Word Senses.
In Proceedings of COLING, pages 825–832, Manch-
ester, UK.
P. Subasic and A. Huettner. 2001. Affect analysis of text
using fuzzy semantic typing. IEEE Transactions on
Fuzzy Systems, 9(4).
Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-
berly Voll, and Manfred Stede. 2011. Lexicon-Based
Method for Sentiment Analysis. Computational Lin-
guistics, 37(2):267–307.
Hiroya Takamura, Takashi Inui, and Manabu Okumura.
2005. Extracting semantic orientation of words using
spin model. In Proceedings of ACL, pages 133–140,
Ann Arbor, MI.
Mike Thelwall, Kevan Buckley, Georgios Paltoglou,
Di Cai, and Arvid Kappas. 2010. Sentiment strength
detection in short informal text. Journal of the Amer-
ican Society for Information Science and Technology,
61(12):2544–2558.
Kristina Toutanova, Dan Klein, Christopher Manning,
and Yoram Singer. 2003. Feature-Rich Part-of-
Speech Tagging with a Cyclic Dependency Network.
In Proceedings of HLT-NAACL, pages 252–259.
Peter Turney and Michael Littman. 2003. Measuring
praise and criticism: Inference of semantic orientation
from association. ACM Transactions on Information
Systems, 21(4):315346.
Leonid Velikovich, Sasha Blair-Goldensohn, Kerry Han-
nan, and Ryan McDonald. 2010. The viability of
Web-derived polarity lexicons. In Proceedings of
NAACL, pages 777–785, Los Angeles, CA.
Janyce Wiebe and Rada Mihalcea. 2006. Word sense
and subjectivity. In Proceedings of ACL, pages 1065–
1072, Sydney, Australia.
Janyce Wiebe and Ellen Riloff. 2005. Creating subjec-
tive and objective sentence classifiers from unanno-
tated texts. In Proceedings of CICLING (invited pa-
per), pages 486–497, Mexico City.
</reference>
<page confidence="0.927486">
110
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.755177">
<title confidence="0.946843">Using Pivot-Based Paraphrasing and Sentiment Profiles to Improve Subjectivity Lexicon for Essay Data</title>
<author confidence="0.968231">Beata Beigman Klebanov</author>
<author confidence="0.968231">Nitin Madnani</author>
<author confidence="0.968231">Jill</author>
<affiliation confidence="0.949384">Educational Testing</affiliation>
<address confidence="0.999152">660 Rosedale Road, Princeton, NJ 08541,</address>
<abstract confidence="0.9934981875">We demonstrate a method of improving a seed sentiment lexicon developed on essay data by using a pivot-based paraphrasing system for lexical expansion coupled with sentiment profile enrichment using crowdsourcing. Profile enrichment alone yields up to 15% improvement in the accuracy of the seed lexicon on 3way sentence-level sentiment polarity classification of essay data. Using lexical expansion in addition to sentiment profiles provides a further 7% improvement in performance. Additional experiments show that the proposed method is also effective with other subjectivity lexicons and in a different domain of application (product reviews).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alina Andreevskaia</author>
<author>Sabine Bergler</author>
</authors>
<title>Mining WordNet for a fuzzy sentiment: Sentiment tag extraction of WordNet glosses.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>209--216</pages>
<location>Trento, Italy.</location>
<contexts>
<context position="12725" citStr="Andreevskaia and Bergler (2006)" startWordPosition="2030" endWordPosition="2033">anayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 0 0 2004; Takamura et al., 2005; Turney and Littman, 0 2003; Hatzivassiloglou and McKeown, 1997). The tributional similarity camp; we also experimented with WordNet-based expansion as descibed in section 7.2. The task of assigning sentiment profiles to words in a sentiment lexicon has been addressed in the literature. SentiWordNet assigns profiles to all words in WordNet based on a propagation algorithm from a small seed set manually annotated by a small number of judges (Baccianella et al., 2010; Cerini et al., 2007). Andreevskaia and Bergler (2006) use graph propagation algorithms on WordNet to assign cen1 - trality scores in positive and negative categories; a 800 800 800 8 similar approach based on web-scale co-occurrence graphs is discussed in Velikovich et al (2010). Thelwall et al (2010) manually annotated a set of words 600 600 600 6 for strength of sentiment and used machine learning to fine-tune it. Taboada et al (2011) produced an 400 400 400 4 expert annotation of their lexicon with strength of sentiment. Subasic and Huettner (2001) manually built an affect lexicon with intensities. Wiebe and 200 200 200 Riloff (2005) classife</context>
<context position="28752" citStr="Andreevskaia and Bergler, 2006" startWordPosition="4657" endWordPosition="4660">n section 5.2. The comparative results in Table 5 clearly show that while our vanilla seed lexicon performs comparably to off-the-shelf lexicons on our data, the paraphraser-expanded lexicon with sentitment profiles outperforms OpinionFinder, General Inquirer, and SentiWordNet. 1 0 7.2 Sentiment Profile Enrichment with Other Lexical Expansion Methods We presented a novel lexicon expansion method using a paraphrasing system. We also experimented with more standard methods, using WordNet and distributional similarity (Beigman Klebanov et al., 2012; Esuli and Sebastian,02006; Kim and Hovy, 2004; Andreevskaia and Bergler, 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003; Hatzivas0 siloglou and McKeown, 1997). Specifically, we implemented a WordNet (Miller, 1995)0based expansion that uses the 3 most frequent synonyms of the top sense of the seed word (WN-e). We also implemented a method based on distributional similarity: Using Lin’s proximity-based thesaurus (Lin, 1998) trained on our in-house essay data as well as on wellformed newswire texts, we took all words with the proximity score &gt; 1.80 to any of the seed</context>
</contexts>
<marker>Andreevskaia, Bergler, 2006</marker>
<rawString>Alina Andreevskaia and Sabine Bergler. 2006. Mining WordNet for a fuzzy sentiment: Sentiment tag extraction of WordNet glosses. In Proceedings of EACL, pages 209–216, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefano Baccianella</author>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>SENTIWORDNET 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC,</booktitle>
<pages>2200--2204</pages>
<contexts>
<context position="12670" citStr="Baccianella et al., 2010" startWordPosition="2022" endWordPosition="2025">d Bergler, 200 200 200 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 0 0 2004; Takamura et al., 2005; Turney and Littman, 0 2003; Hatzivassiloglou and McKeown, 1997). The tributional similarity camp; we also experimented with WordNet-based expansion as descibed in section 7.2. The task of assigning sentiment profiles to words in a sentiment lexicon has been addressed in the literature. SentiWordNet assigns profiles to all words in WordNet based on a propagation algorithm from a small seed set manually annotated by a small number of judges (Baccianella et al., 2010; Cerini et al., 2007). Andreevskaia and Bergler (2006) use graph propagation algorithms on WordNet to assign cen1 - trality scores in positive and negative categories; a 800 800 800 8 similar approach based on web-scale co-occurrence graphs is discussed in Velikovich et al (2010). Thelwall et al (2010) manually annotated a set of words 600 600 600 6 for strength of sentiment and used machine learning to fine-tune it. Taboada et al (2011) produced an 400 400 400 4 expert annotation of their lexicon with strength of sentiment. Subasic and Huettner (2001) manually built an affect lexicon with in</context>
<context position="26847" citStr="Baccianella et al., 2010" startWordPosition="4362" endWordPosition="4365">0.616 Naive B. 0.598 0.573 0.584 0.587 0.626 Table 5: Performance of different lexicons on essay data using various machine learning systems. For each system and lexicon, the best performance across the applicable feature representations from section 5.2 and the variants (see text) is shown. Seed BL column shows the best baseline performance of our seed lexicon – before paraphraser expansion and profile enrichment were applied. Exp. column shows the performance of Int-bin feature representation for the expanded lexicon after profile enrichment. Additionally, we experimented with SentiWordNet (Baccianella et al., 2010). SentiWordNet is a resource for opinion mining built on top of WordNet, which assigns each synset in WordNet a score triplet (positive, negative, and objective), indicating the strength of each of these three properties for the words in the synset. The SentiWordNet annotations were automatically generated, starting with a set of manually labeled synsets. Currently, SentiWordNet includes an automatic annotation for all the synsets in WordNet, totaling more than 100,000 words. It is therefore the largest-scale lexicon with intensity information that is currently available. Since SentiWordNet as</context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2010</marker>
<rawString>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. SENTIWORDNET 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining. In Proceedings of LREC, pages 2200–2204, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with bilingual parallel corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>597--604</pages>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="6238" citStr="Bannard and Callison-Burch (2005)" startWordPosition="925" endWordPosition="928"> positive and negative sentiment words manually selected from a full list of word types in these data, and (2) words marked in a small-scale annotation of a sample of sentences from these data for all positive and negative words. A more detailed description of the construction of seed lexicon can be found in Beigman Klebanov et al (2012). The seed lexicon contains 749 single words, 406 positive and 343 negative. 2.2 Expanded Lexicon We used a pivot-based lexical and phrasal paraphrase generation system (Madnani and Dorr, 2013). The paraphraser implements the pivot-based method as described by Bannard and Callison-Burch (2005) with several additional filtering mechanisms to increase the precision of the extracted pairs. The pivot-based method utilizes the inherent monolingual semantic knowledge from bilingual corpora: We first identify phrasal correspondences between English and a given foreign language F, then map from English to English by following translation units from English to the other language and back. For example, if the two English phrases e1 and e2 both correspond to the same foreign phrase f, then they may be considered to be paraphrases of each other with the following probability: p(e1|e2) ≈ p(e1|f</context>
</contexts>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin Bannard and Chris Callison-Burch. 2005. Paraphrasing with bilingual parallel corpora. In Proceedings of ACL, pages 597–604, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beata Beigman Klebanov</author>
<author>Jill Burstein</author>
<author>Nitin Madnani</author>
<author>Adam Faulkner</author>
<author>Joel Tetreault</author>
</authors>
<title>Building sentiment lexicon(s) from scratch for essay data.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing),</booktitle>
<location>New Delhi, India,</location>
<contexts>
<context position="5944" citStr="Klebanov et al (2012)" startWordPosition="881" endWordPosition="884">0 essays containing writing samples across many topics. Essays were responses to several different writing assignments, including graduate school entrance exams, non-native English speaker proficiency exams, and professional licensure exams. Our seed lexicon is a combination of (1) positive and negative sentiment words manually selected from a full list of word types in these data, and (2) words marked in a small-scale annotation of a sample of sentences from these data for all positive and negative words. A more detailed description of the construction of seed lexicon can be found in Beigman Klebanov et al (2012). The seed lexicon contains 749 single words, 406 positive and 343 negative. 2.2 Expanded Lexicon We used a pivot-based lexical and phrasal paraphrase generation system (Madnani and Dorr, 2013). The paraphraser implements the pivot-based method as described by Bannard and Callison-Burch (2005) with several additional filtering mechanisms to increase the precision of the extracted pairs. The pivot-based method utilizes the inherent monolingual semantic knowledge from bilingual corpora: We first identify phrasal correspondences between English and a given foreign language F, then map from Englis</context>
<context position="28673" citStr="Klebanov et al., 2012" startWordPosition="4646" endWordPosition="4649"> figures between SWN-1 and SWN-2, across the feature representations in section 5.2. The comparative results in Table 5 clearly show that while our vanilla seed lexicon performs comparably to off-the-shelf lexicons on our data, the paraphraser-expanded lexicon with sentitment profiles outperforms OpinionFinder, General Inquirer, and SentiWordNet. 1 0 7.2 Sentiment Profile Enrichment with Other Lexical Expansion Methods We presented a novel lexicon expansion method using a paraphrasing system. We also experimented with more standard methods, using WordNet and distributional similarity (Beigman Klebanov et al., 2012; Esuli and Sebastian,02006; Kim and Hovy, 2004; Andreevskaia and Bergler, 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003; Hatzivas0 siloglou and McKeown, 1997). Specifically, we implemented a WordNet (Miller, 1995)0based expansion that uses the 3 most frequent synonyms of the top sense of the seed word (WN-e). We also implemented a method based on distributional similarity: Using Lin’s proximity-based thesaurus (Lin, 1998) trained on our in-house essay data as well as on wellformed newsw</context>
</contexts>
<marker>Klebanov, Burstein, Madnani, Faulkner, Tetreault, 2012</marker>
<rawString>Beata Beigman Klebanov, Jill Burstein, Nitin Madnani, Adam Faulkner, and Joel Tetreault. 2012. Building sentiment lexicon(s) from scratch for essay data. In Proceedings of the 13th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing), New Delhi, India, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Cerini</author>
<author>V Compagnoni</author>
<author>A Demontis</author>
<author>M Formentelli</author>
<author>G Gandini</author>
</authors>
<title>Micro-WNOp: A gold standard for the evaluation of automatically compiled lexical resources for opinion mining.</title>
<date>2007</date>
<booktitle>Language resources and linguistic theory: Typology, second language acquisition,</booktitle>
<pages>200--210</pages>
<editor>In Andrea Sanso, editor,</editor>
<location>Milano, IT.</location>
<contexts>
<context position="12692" citStr="Cerini et al., 2007" startWordPosition="2026" endWordPosition="2029">6; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 0 0 2004; Takamura et al., 2005; Turney and Littman, 0 2003; Hatzivassiloglou and McKeown, 1997). The tributional similarity camp; we also experimented with WordNet-based expansion as descibed in section 7.2. The task of assigning sentiment profiles to words in a sentiment lexicon has been addressed in the literature. SentiWordNet assigns profiles to all words in WordNet based on a propagation algorithm from a small seed set manually annotated by a small number of judges (Baccianella et al., 2010; Cerini et al., 2007). Andreevskaia and Bergler (2006) use graph propagation algorithms on WordNet to assign cen1 - trality scores in positive and negative categories; a 800 800 800 8 similar approach based on web-scale co-occurrence graphs is discussed in Velikovich et al (2010). Thelwall et al (2010) manually annotated a set of words 600 600 600 6 for strength of sentiment and used machine learning to fine-tune it. Taboada et al (2011) produced an 400 400 400 4 expert annotation of their lexicon with strength of sentiment. Subasic and Huettner (2001) manually built an affect lexicon with intensities. Wiebe and 2</context>
</contexts>
<marker>Cerini, Compagnoni, Demontis, Formentelli, Gandini, 2007</marker>
<rawString>S. Cerini, V. Compagnoni, A. Demontis, M. Formentelli, and G. Gandini. 2007. Micro-WNOp: A gold standard for the evaluation of automatically compiled lexical resources for opinion mining. In Andrea Sanso, editor, Language resources and linguistic theory: Typology, second language acquisition, pages 200–210. Franco Angeli Editore, Milano, IT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fermin L Cruz</author>
<author>Jos´e A Troyano</author>
<author>F Javier Ortega</author>
<author>Fernando Enriquez</author>
</authors>
<title>Automatic expansion of feature-level opinion lexicons.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis,</booktitle>
<pages>125--131</pages>
<location>Portland, Oregon,</location>
<contexts>
<context position="11877" citStr="Cruz et al., 2011" startWordPosition="1890" endWordPosition="1893">ty 101 800 600 400 200 0 −1.0 05 −0.5 10 0.0 0.5 1.0 −1.0 −0.5 0.0 −. 0.5 −0. 1.0 800 600 400 200 0 Figure 1: Sentiment distributions for the seed (left) and the expanded (right) lexicons. are often expanded into low intensity, neutral, or 1200 1200 120 ambiguous ones, as in pairs like absurd/laughable, deadly/fateful, anxiety/concern shown in Table 2. 4 Related Work The most popular seed expansion methods discussed 8 80 800 in the literature are based on WordNet (Miller, 1995) or another lexicographic resource, on dis600 600 600 tributional similarity with the seeds, or on a mixture thereof (Cruz et al., 2011; Baccianella et al., 400 400 2010; Velikovich et al., 2010; Qiu et al., 2009; Mo400 hammad et al., 2009; Esuli and Sebastiani, 2006; Kim and Hovy, 2004; Andreevskaia and Bergler, 200 200 200 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 0 0 2004; Takamura et al., 2005; Turney and Littman, 0 2003; Hatzivassiloglou and McKeown, 1997). The tributional similarity camp; we also experimented with WordNet-based expansion as descibed in section 7.2. The task of assigning sentiment profiles to words in a sentiment lexicon has been addressed in the </context>
</contexts>
<marker>Cruz, Troyano, Ortega, Enriquez, 2011</marker>
<rawString>Fermin L. Cruz, Jos´e A. Troyano, F. Javier Ortega, and Fernando Enriquez. 2011. Automatic expansion of feature-level opinion lexicons. In Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, pages 125–131, Portland, Oregon, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Dragut</author>
<author>Hong Wang</author>
<author>Clement Yu</author>
<author>Prasad Sistla</author>
<author>Weiyi Meng</author>
</authors>
<title>Polarity consistency checking for sentiment dictionaries.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>997--1005</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<marker>Dragut, Wang, Yu, Sistla, Meng, 2012</marker>
<rawString>Eduard Dragut, Hong Wang, Clement Yu, Prasad Sistla, and Weiyi Meng. 2012. Polarity consistency checking for sentiment dictionaries. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 997–1005, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Determining term subjectivity and term orientation for opinion mining.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>193--200</pages>
<location>Trento, Italy.</location>
<contexts>
<context position="12009" citStr="Esuli and Sebastiani, 2006" startWordPosition="1914" endWordPosition="1917">tributions for the seed (left) and the expanded (right) lexicons. are often expanded into low intensity, neutral, or 1200 1200 120 ambiguous ones, as in pairs like absurd/laughable, deadly/fateful, anxiety/concern shown in Table 2. 4 Related Work The most popular seed expansion methods discussed 8 80 800 in the literature are based on WordNet (Miller, 1995) or another lexicographic resource, on dis600 600 600 tributional similarity with the seeds, or on a mixture thereof (Cruz et al., 2011; Baccianella et al., 400 400 2010; Velikovich et al., 2010; Qiu et al., 2009; Mo400 hammad et al., 2009; Esuli and Sebastiani, 2006; Kim and Hovy, 2004; Andreevskaia and Bergler, 200 200 200 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 0 0 2004; Takamura et al., 2005; Turney and Littman, 0 2003; Hatzivassiloglou and McKeown, 1997). The tributional similarity camp; we also experimented with WordNet-based expansion as descibed in section 7.2. The task of assigning sentiment profiles to words in a sentiment lexicon has been addressed in the literature. SentiWordNet assigns profiles to all words in WordNet based on a propagation algorithm from a small seed set manually an</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. Determining term subjectivity and term orientation for opinion mining. In Proceedings of EACL, pages 193–200, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leo A Goodman</author>
</authors>
<title>On Simultaneous Confidence Intervals for Multinomial Proportions.</title>
<date>1965</date>
<journal>Technometrics,</journal>
<volume>7</volume>
<issue>2</issue>
<contexts>
<context position="9409" citStr="Goodman (1965)" startWordPosition="1444" endWordPosition="1445">ls as follows. For every word, a person is shown the word and asked whether it is positive, negative, or neutral. A person’s decision is modeled as flipping the coin corresponding to the word, and recording the outcome – positive, negative, or neutral. We run N=20 such trials for every word in the expanded lexicon using the CrowdFlower crowdsourcing site,4 for a total cost of $800. We use maximum likelihood estimate of sentiment profile: ˆpiw = ni (2) w where niw is the proportion of N trials on the word w that fell in cell i E {pos, neg, neu}. Table 2 shows some estimated profiles. Following Goodman (1965) and Quesenberry and Hurst (1964), we calculate confidence intervals for the parameters pi w: (ˆpiw)− = (B + 2niw − T)/(2(N + B)) (3) 4www.crowdflower.com Word ˆppos ˆpneu ˆpneg w w w forceful 0 0.15 0.85 resolute 0.8 0.15 0.05 peculiar 0.05 0.15 0.8 remarkable 1 0 0 anxiety 0 0 1 concern 0.25 0.4 0.35 absurd 0 0 1 laughable 0.5 0.05 0.45 deadly 0 0 1 fateful 0.25 0.45 0.3 consequence 0.05 0.15 0.8 outcome 0.15 0.85 0 Table 2: Examples of estimated sentiment profiles. Words in gray are expansions generated from words in the preceding row; note the difference in the profiles. (ˆpiw)+ = (B + 2ni</context>
</contexts>
<marker>Goodman, 1965</marker>
<rawString>Leo A. Goodman. 1965. On Simultaneous Confidence Intervals for Multinomial Proportions. Technometrics, 7(2):247–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaw Gyamfi</author>
<author>Janyce Wiebe</author>
<author>Rada Mihalcea</author>
<author>Cem Akkaya</author>
</authors>
<title>Integrating knowledge for subjectivity sense labeling.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<pages>10--18</pages>
<location>Boulder, CO.</location>
<marker>Gyamfi, Wiebe, Mihalcea, Akkaya, 2009</marker>
<rawString>Yaw Gyamfi, Janyce Wiebe, Rada Mihalcea, and Cem Akkaya. 2009. Integrating knowledge for subjectivity sense labeling. In Proceedings of NAACL, pages 10– 18, Boulder, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The WEKA Data Mining Software: An Update.</title>
<date>2009</date>
<journal>SIGKDD Explorations,</journal>
<volume>11</volume>
<contexts>
<context position="14734" citStr="Hall et al., 2009" startWordPosition="2355" endWordPosition="2358">he first attempt to integrate judgements obtained through crowdsourcing on a large scale into0a sentiment lexicon, showing the effectiveness of this lexicon-enrichment procedure for a sentiment classification task. − 5 Using profiles for sentence-level sentiment polarity classification To evaluate the usefulness of the lexicons, we use them to generate features for machine learning syslevel sentiment polarity classification. To ensure robustness of the observed trends, we experiment with a number of machine learning algorithms: SVM Linear and RBF, Naive Bayes, Logistic Regression (using WEKA (Hall et al., 2009)), and c5.0 Decision Trees (Quinlan, 1993).5 5.1 Data We generated the data for training and testing the machine learning systems as follows. We used our 5available from http://rulequest.com/ 0 0.0 0− 0. 5− 1.0 00 05 10 1 05 0.0 0 0.5 5− 1. 00 paraphrase-based expansion method is in the dis0− tems, and compare5performance on 3-way sentencey y .0 y n . 7 . 0 00 05 CD � 10 n&apos; 1 y 5 n .0 CD 7 n� .5. . CD 0 0 1.0 .0 5 0 1 5 0 0 0. 0. 1.0 - 0 , ywa3- performance sentence- ,estm on compare and 102 pool of 100,000 essays to sample a second, nonoverlapping set of 5,000 essays, so that no essay used fo</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The WEKA Data Mining Software: An Update. SIGKDD Explorations, 11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>174--181</pages>
<location>Madrid,</location>
<contexts>
<context position="12265" citStr="Hatzivassiloglou and McKeown, 1997" startWordPosition="1956" endWordPosition="1959">The most popular seed expansion methods discussed 8 80 800 in the literature are based on WordNet (Miller, 1995) or another lexicographic resource, on dis600 600 600 tributional similarity with the seeds, or on a mixture thereof (Cruz et al., 2011; Baccianella et al., 400 400 2010; Velikovich et al., 2010; Qiu et al., 2009; Mo400 hammad et al., 2009; Esuli and Sebastiani, 2006; Kim and Hovy, 2004; Andreevskaia and Bergler, 200 200 200 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 0 0 2004; Takamura et al., 2005; Turney and Littman, 0 2003; Hatzivassiloglou and McKeown, 1997). The tributional similarity camp; we also experimented with WordNet-based expansion as descibed in section 7.2. The task of assigning sentiment profiles to words in a sentiment lexicon has been addressed in the literature. SentiWordNet assigns profiles to all words in WordNet based on a propagation algorithm from a small seed set manually annotated by a small number of judges (Baccianella et al., 2010; Cerini et al., 2007). Andreevskaia and Bergler (2006) use graph propagation algorithms on WordNet to assign cen1 - trality scores in positive and negative categories; a 800 800 800 8 similar ap</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Vasileios Hatzivassiloglou and Kathleen McKeown. 1997. Predicting the semantic orientation of adjectives. In Proceedings ofACL, pages 174–181, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>168--177</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="12091" citStr="Hu and Liu, 2004" startWordPosition="1929" endWordPosition="1932">w intensity, neutral, or 1200 1200 120 ambiguous ones, as in pairs like absurd/laughable, deadly/fateful, anxiety/concern shown in Table 2. 4 Related Work The most popular seed expansion methods discussed 8 80 800 in the literature are based on WordNet (Miller, 1995) or another lexicographic resource, on dis600 600 600 tributional similarity with the seeds, or on a mixture thereof (Cruz et al., 2011; Baccianella et al., 400 400 2010; Velikovich et al., 2010; Qiu et al., 2009; Mo400 hammad et al., 2009; Esuli and Sebastiani, 2006; Kim and Hovy, 2004; Andreevskaia and Bergler, 200 200 200 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 0 0 2004; Takamura et al., 2005; Turney and Littman, 0 2003; Hatzivassiloglou and McKeown, 1997). The tributional similarity camp; we also experimented with WordNet-based expansion as descibed in section 7.2. The task of assigning sentiment profiles to words in a sentiment lexicon has been addressed in the literature. SentiWordNet assigns profiles to all words in WordNet based on a propagation algorithm from a small seed set manually annotated by a small number of judges (Baccianella et al., 2010; Cerini et al., 2007</context>
<context position="24678" citStr="Hu and Liu, 2004" startWordPosition="4025" endWordPosition="4028">ely coupled with other methods of lexical expansion, such as a WordNet-based expansion and an expansion that utilizes Lin’s distributional thesaurus. However, we find that the paraphraser-based expansion benefits the most from profile enrichment, and attains better performance on our data than the alterantive expansion methods. In section 7.3, we show that the paraphrase-based expansion and profile enrichment paradigm is effective for other subjecitivy lexicons on other data. We use a dataset of product reviews annotated for sentence-level positivity and negativity as new data for evaluation (Hu and Liu, 2004). We use subsets of OpinionFinder, General Inquirer, and sentiment lexicon from Hu and Liu (2004). We demonstrate that paraphrase-based expansion and profile enrichment improve the accuracy of sentiment classification of product reviews for every lexicon and machine learner combination; the magnitude of improvement is 5% on average. 7.1 Competitiveness of the Expanded Lexicon Had we been able to use the OpinionFinder or the General Inquirer lexicons (OFL and GIL) asis, how would the results have compared to those attained using our lexicons? We performed the baseline runs with both lexicons; O</context>
<context position="28770" citStr="Hu and Liu, 2004" startWordPosition="4661" endWordPosition="4664">esults in Table 5 clearly show that while our vanilla seed lexicon performs comparably to off-the-shelf lexicons on our data, the paraphraser-expanded lexicon with sentitment profiles outperforms OpinionFinder, General Inquirer, and SentiWordNet. 1 0 7.2 Sentiment Profile Enrichment with Other Lexical Expansion Methods We presented a novel lexicon expansion method using a paraphrasing system. We also experimented with more standard methods, using WordNet and distributional similarity (Beigman Klebanov et al., 2012; Esuli and Sebastian,02006; Kim and Hovy, 2004; Andreevskaia and Bergler, 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003; Hatzivas0 siloglou and McKeown, 1997). Specifically, we implemented a WordNet (Miller, 1995)0based expansion that uses the 3 most frequent synonyms of the top sense of the seed word (WN-e). We also implemented a method based on distributional similarity: Using Lin’s proximity-based thesaurus (Lin, 1998) trained on our in-house essay data as well as on wellformed newswire texts, we took all words with the proximity score &gt; 1.80 to any of the seed lexicon words (Li</context>
<context position="32271" citStr="Hu and Liu, 2004" startWordPosition="5215" endWordPosition="5218">623 0.626 Av. Gain 0.066 0.085 0.146 Table 6: Performance of WordNet-based, Lin-based, and Paraphraser-based expansions with profile enrichment in the Int-bin condition. Seed BL column shows the best baseline performance of the seed lexicon – before expansion and profile enrichment were applied. The last line shows the average relative gain over the best baseline calculated as AGlex = Em∈M LexSeedB dBLm , where SeedBLm M = {c5.0, SVM-RBF, SVM-linear, Logistic Regression, Naive Bayes}, and lex E {Lin-e-p, Wn-e-p, Exp}. and domains of application, we experimented with a product reviews dataset (Hu and Liu, 2004) and additional lexicons as follows. 7.3.1 Lexicons We use the OpinionFinder and General Inquirer lexicons (OFL and GIL) as before, as well as the lexicon of positive and negative sentiment and opinion words available along with (Hu and Liu, 2004) product reviews dataset – HL.8 Since each of these lexicons contains more than 3,000 words, enrichment of the full lexicons with profiles is beyond the financial scope of our project. We therefore restrict each of the lexicons to the size of their overlap with our seed lexicon (see 2.1); the overlaps have between 415 and 467 words. These restricted l</context>
<context position="33540" citStr="Hu and Liu (2004)" startWordPosition="5421" endWordPosition="5424">ent that parallel the role of the seed lexicon in the experiments on essay data. For each of the 3 initial lexicons L, LE{OFL, GIL, HL}, we follow the paraphrase-based expansion as described in section 2.2. This results in about 4.5-fold expansion of each lexicon, the new lexicons L-e, LE{OFL, GIL, HL}, numbering between 2,015 and 2,167 words. Both the initial and the expanded lexicons now undergo profile enrichment as described in section 3.1, producing lexicons L-p and 8http://www.cs.uic.edu/—liub/FBS/sentimentanalysis.html#lexicon L-e-p, LE{OFL, GIL, HL}. 7.3.2 Data We use the dataset from Hu and Liu (2004)9 that contains reviews of 5 products from amazon.com: two digital cameras, a DVD player, an MP3 player, and a cellular phone. The reviews are annotated at sentence level with a label that desrcibes the particular feature that is the subject of the positive or negative evaluation and the polarity and extent of the evaluation. For example, the sentence “The phone book is very user-friendly and the speakerphone is excellent” is labeled as PHONE BOOK[+2], SPEAKERPHONE[+2], while the sentence “I am bored with the silver look” is labeled LOOK[−1]. We used all sentences that were labeled with a nume</context>
<context position="36751" citStr="Hu and Liu, 2004" startWordPosition="5932" endWordPosition="5935">L|=434, |L-e|=2,054 c5.0 0.676 0.675 0.689 0.706 SVM-RBF 0.673 0.674 0.700 0.713 SVM-lin. 0.676 0.664 0.703 0.710 Log. Reg. 0.668 0.661 0.703 0.699 Naive B. 0.668 0.672 0.697 0.697 Table 7: Accuracies on product review data. For each machine learner and lexicon, the best baseline performance is shown as L for the initial lexicon and as L-e for the paraphrase-expanded lexicon. L-p and L-e-p show the performance of Int-bin feature set on the profile-enriched initial and paraphrase-expanded lexicons, respectively. The three initial lexicons L are OpinionFinder (OFL), General Inquirer (GIL), and (Hu and Liu, 2004) (HL), each intersected with our seed lexicon. Sizes of the intial and expanded lexicons are provided. OFL, and HL-derived lexicons, respectively. In contrast, for the expanded lexicons, these percentages are 51%, 53%, and 56%; these lexicons benefit from profile enrichment. 8 Conclusions We demonstrated a method of improving a seed sentiment lexicon by using a pivot-based paraphrasing system for lexical expansion and sentiment profile enrichment using crowdsourcing. Profile enrichment alone yielded up to 15% improvement in the performance of the seed lexicon on the task of 3- way sentence-lev</context>
<context position="38359" citStr="Hu and Liu (2004)" startWordPosition="6167" endWordPosition="6170"> up to 25% improvement in accuracy. Additionally, we showed that our paraphraseexpanded and profile-enriched lexicon performs significantly better on our data than off-the-shelf subjectivity lexicons, namely, Opinion Finder, General Inquirer, and SentiWordNet. Furthermore, our results suggest that paraphrase-based expansion derives more benefit from profiles than two competing expansion mechanisms based on WordNet and on Lin’s distributional thesaurus. Finally, we demonstrated the effectiveness of the paraphraser-based expansion with profile enrichment paradigm on a different dataset. We used Hu and Liu (2004) product review data with sentencelevel sentiment polarity labels. Paraphrase-based expansion with profile enrichment yielded an improved performance across all lexicons and machine learning algorithms we tried, with an average improvement rate of 5% in classification accuracy. Recent literature argues that sentiment polarity is a property of word senses, rather than of words (Gyamfi et al., 2009; Su and Markert, 2008; Wiebe and Mihalcea, 2006), although Dragut et al (2012) successfully operate with “mostly negative” and “mostly positive” words based on the polarity distributions of word sense</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 168–177, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valentin Jijkoun</author>
<author>Katja Hofmann</author>
</authors>
<title>Generating a Non-English Subjectivity Lexicon: Relations That Matter.</title>
<date>2009</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>398--405</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="2174" citStr="Jijkoun and Hofmann, 2009" startWordPosition="298" endWordPosition="301">e available for research and education only1 and under GNU GPL license that disallows their incorporation into proprietary materials,2 respectively. 1http://www.wjh.harvard.edu/ inquirer/j1 1/manual/ 2http://www.gnu.org/copyleft/gpl.html Those wishing to integrate sentiment analysis into products, along with those studying subjectivity in languages other than English, or for specific domains such as finance, or for particular genres such as MySpace comments, reported construction of lexicons (Taboada et al., 2011; Loughran and McDonald, 2011; Thelwall et al., 2010; Rao and Ravichandran, 2009; Jijkoun and Hofmann, 2009; Pitel and Grefenstette, 2008; Mihalcea et al., 2007). In this paper, we address the step of expanding a small-scale, manually-built subjectivity lexicon (a seed lexicon, typically for a domain or language in question) into a much larger but noisier lexicon using an automatic procedure. We present a novel expansion method using a state-of-the-art paraphrasing system. The expansion yields a 4-fold increase in lexicon size; yet, the expansion alone is insufficient in order to improve performance on sentence-level sentiment polarity classification. In this paper we test the following hypothesis.</context>
</contexts>
<marker>Jijkoun, Hofmann, 2009</marker>
<rawString>Valentin Jijkoun and Katja Hofmann. 2009. Generating a Non-English Subjectivity Lexicon: Relations That Matter. In Proceedings of EACL, pages 398–405, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaap Kamps</author>
<author>Maarten Marx</author>
<author>Robert Mokken</author>
<author>Maarten de Rijke</author>
</authors>
<title>Using WordNet to measure semantic orientation of adjectives.</title>
<date>2004</date>
<booktitle>In Proceedings of LREC,</booktitle>
<pages>1115--1118</pages>
<location>Lisbon, Portugal.</location>
<marker>Kamps, Marx, Mokken, de Rijke, 2004</marker>
<rawString>Jaap Kamps, Maarten Marx, Robert Mokken, and Maarten de Rijke. 2004. Using WordNet to measure semantic orientation of adjectives. In Proceedings of LREC, pages 1115–1118, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Kanayama</author>
<author>Tetsuya Nasukawa</author>
</authors>
<title>Fully automatic Lexicon Expansion for Domain-oriented Sentiment Analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>355--363</pages>
<location>Syndey, Australia.</location>
<contexts>
<context position="12120" citStr="Kanayama and Nasukawa, 2006" startWordPosition="1933" endWordPosition="1936">al, or 1200 1200 120 ambiguous ones, as in pairs like absurd/laughable, deadly/fateful, anxiety/concern shown in Table 2. 4 Related Work The most popular seed expansion methods discussed 8 80 800 in the literature are based on WordNet (Miller, 1995) or another lexicographic resource, on dis600 600 600 tributional similarity with the seeds, or on a mixture thereof (Cruz et al., 2011; Baccianella et al., 400 400 2010; Velikovich et al., 2010; Qiu et al., 2009; Mo400 hammad et al., 2009; Esuli and Sebastiani, 2006; Kim and Hovy, 2004; Andreevskaia and Bergler, 200 200 200 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 0 0 2004; Takamura et al., 2005; Turney and Littman, 0 2003; Hatzivassiloglou and McKeown, 1997). The tributional similarity camp; we also experimented with WordNet-based expansion as descibed in section 7.2. The task of assigning sentiment profiles to words in a sentiment lexicon has been addressed in the literature. SentiWordNet assigns profiles to all words in WordNet based on a propagation algorithm from a small seed set manually annotated by a small number of judges (Baccianella et al., 2010; Cerini et al., 2007). Andreevskaia and Bergler (</context>
<context position="28799" citStr="Kanayama and Nasukawa, 2006" startWordPosition="4665" endWordPosition="4668">clearly show that while our vanilla seed lexicon performs comparably to off-the-shelf lexicons on our data, the paraphraser-expanded lexicon with sentitment profiles outperforms OpinionFinder, General Inquirer, and SentiWordNet. 1 0 7.2 Sentiment Profile Enrichment with Other Lexical Expansion Methods We presented a novel lexicon expansion method using a paraphrasing system. We also experimented with more standard methods, using WordNet and distributional similarity (Beigman Klebanov et al., 2012; Esuli and Sebastian,02006; Kim and Hovy, 2004; Andreevskaia and Bergler, 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003; Hatzivas0 siloglou and McKeown, 1997). Specifically, we implemented a WordNet (Miller, 1995)0based expansion that uses the 3 most frequent synonyms of the top sense of the seed word (WN-e). We also implemented a method based on distributional similarity: Using Lin’s proximity-based thesaurus (Lin, 1998) trained on our in-house essay data as well as on wellformed newswire texts, we took all words with the proximity score &gt; 1.80 to any of the seed lexicon words (Lin-e). Just like the paraphras</context>
</contexts>
<marker>Kanayama, Nasukawa, 2006</marker>
<rawString>Hiroshi Kanayama and Tetsuya Nasukawa. 2006. Fully automatic Lexicon Expansion for Domain-oriented Sentiment Analysis. In Proceedings of EMNLP, pages 355–363, Syndey, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Edward Hovy</author>
</authors>
<title>Determining the sentiment of opinions.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>1367--1373</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="12029" citStr="Kim and Hovy, 2004" startWordPosition="1918" endWordPosition="1921">t) and the expanded (right) lexicons. are often expanded into low intensity, neutral, or 1200 1200 120 ambiguous ones, as in pairs like absurd/laughable, deadly/fateful, anxiety/concern shown in Table 2. 4 Related Work The most popular seed expansion methods discussed 8 80 800 in the literature are based on WordNet (Miller, 1995) or another lexicographic resource, on dis600 600 600 tributional similarity with the seeds, or on a mixture thereof (Cruz et al., 2011; Baccianella et al., 400 400 2010; Velikovich et al., 2010; Qiu et al., 2009; Mo400 hammad et al., 2009; Esuli and Sebastiani, 2006; Kim and Hovy, 2004; Andreevskaia and Bergler, 200 200 200 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 0 0 2004; Takamura et al., 2005; Turney and Littman, 0 2003; Hatzivassiloglou and McKeown, 1997). The tributional similarity camp; we also experimented with WordNet-based expansion as descibed in section 7.2. The task of assigning sentiment profiles to words in a sentiment lexicon has been addressed in the literature. SentiWordNet assigns profiles to all words in WordNet based on a propagation algorithm from a small seed set manually annotated by a small n</context>
<context position="28720" citStr="Kim and Hovy, 2004" startWordPosition="4653" endWordPosition="4656">re representations in section 5.2. The comparative results in Table 5 clearly show that while our vanilla seed lexicon performs comparably to off-the-shelf lexicons on our data, the paraphraser-expanded lexicon with sentitment profiles outperforms OpinionFinder, General Inquirer, and SentiWordNet. 1 0 7.2 Sentiment Profile Enrichment with Other Lexical Expansion Methods We presented a novel lexicon expansion method using a paraphrasing system. We also experimented with more standard methods, using WordNet and distributional similarity (Beigman Klebanov et al., 2012; Esuli and Sebastian,02006; Kim and Hovy, 2004; Andreevskaia and Bergler, 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003; Hatzivas0 siloglou and McKeown, 1997). Specifically, we implemented a WordNet (Miller, 1995)0based expansion that uses the 3 most frequent synonyms of the top sense of the seed word (WN-e). We also implemented a method based on distributional similarity: Using Lin’s proximity-based thesaurus (Lin, 1998) trained on our in-house essay data as well as on wellformed newswire texts, we took all words with the proximity</context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>Soo-Min Kim and Edward Hovy. 2004. Determining the sentiment of opinions. In Proceedings of COLING, pages 1367–1373, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Koehn</author>
</authors>
<title>EUROPARL: A Parallel corpus for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the Machine Translation Summit.</booktitle>
<contexts>
<context position="7532" citStr="Koehn, 2005" startWordPosition="1123" endWordPosition="1124">n they are all used in computing the probability: p(e1|e2) ≈ � p(e1|f&apos;)p(f&apos;|e2) P Seed Expansion Seed Expansion abuse exploitation costly onerous accuse reproach dangerous unsafe anxiety disquiet improve reinforce conflict crisis invaluable precious Table 1: Examples of paraphraser expansions. Some examples of expansions generated by the paraphraser are shown in Table 1. More details about this kind of approach can be found in Bannard and Callison-Burch (2005). We use the FrenchEnglish parallel corpus (approximately 1.2 million sentences) from the corpus of European parliamentary proceedings (Koehn, 2005) as the data on which pivoting is performed to extract the paraphrases. However, the base paraphrase system is susceptible 100 to large amounts of noise due to the imperfect bilingual word alignments. Therefore, we implement additional heuristics in order to minimize the number of noisy paraphrase pairs (Madnani and Dorr, 2013). For example, one such heuristic filters out pairs where a function word may have been inferred as a paraphrase of a content word. For the lexicon expansion experiment reported here, we use the top 15 single-word paraphrases for every word from the seed lexicon, excludi</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philip Koehn. 2005. EUROPARL: A Parallel corpus for Statistical Machine Translation. In Proceedings of the Machine Translation Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>768--774</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="29207" citStr="Lin, 1998" startWordPosition="4731" endWordPosition="4732">, using WordNet and distributional similarity (Beigman Klebanov et al., 2012; Esuli and Sebastian,02006; Kim and Hovy, 2004; Andreevskaia and Bergler, 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003; Hatzivas0 siloglou and McKeown, 1997). Specifically, we implemented a WordNet (Miller, 1995)0based expansion that uses the 3 most frequent synonyms of the top sense of the seed word (WN-e). We also implemented a method based on distributional similarity: Using Lin’s proximity-based thesaurus (Lin, 1998) trained on our in-house essay data as well as on wellformed newswire texts, we took all words with the proximity score &gt; 1.80 to any of the seed lexicon words (Lin-e). Just like the paraphraser lexicon, both perform worse than the seed lexicon in 9 out of 10 baseline runs (BL-sum and Bl-full conditions for the 5 machine learners). To test the effect of profile enrichment, all words in WN-e and Lin-e underwent profile estimation as described in section 3.1, yielding lexicons WN-e-p and Lin-e-p, respectively. Figure 2 shows the distri0 0.0 td 05 .0 a 0 5 0.5 0 6http://sentiwordnet.isti.cnr.it/,</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. In Proceedings ofACL, pages 768–774, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Loughran</author>
<author>Bill McDonald</author>
</authors>
<title>When is a Liability not a Liability? Textual Analysis, Dictionaries, and 10-Ks.</title>
<date>2011</date>
<journal>Journal of Finance,</journal>
<pages>66--35</pages>
<contexts>
<context position="2096" citStr="Loughran and McDonald, 2011" startWordPosition="286" endWordPosition="289">xicon provided with the OpinionFinder distribution (Wiebe and Riloff, 2005) – are available for research and education only1 and under GNU GPL license that disallows their incorporation into proprietary materials,2 respectively. 1http://www.wjh.harvard.edu/ inquirer/j1 1/manual/ 2http://www.gnu.org/copyleft/gpl.html Those wishing to integrate sentiment analysis into products, along with those studying subjectivity in languages other than English, or for specific domains such as finance, or for particular genres such as MySpace comments, reported construction of lexicons (Taboada et al., 2011; Loughran and McDonald, 2011; Thelwall et al., 2010; Rao and Ravichandran, 2009; Jijkoun and Hofmann, 2009; Pitel and Grefenstette, 2008; Mihalcea et al., 2007). In this paper, we address the step of expanding a small-scale, manually-built subjectivity lexicon (a seed lexicon, typically for a domain or language in question) into a much larger but noisier lexicon using an automatic procedure. We present a novel expansion method using a state-of-the-art paraphrasing system. The expansion yields a 4-fold increase in lexicon size; yet, the expansion alone is insufficient in order to improve performance on sentence-level sent</context>
</contexts>
<marker>Loughran, McDonald, 2011</marker>
<rawString>Tim Loughran and Bill McDonald. 2011. When is a Liability not a Liability? Textual Analysis, Dictionaries, and 10-Ks. Journal of Finance, 66:35–65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Madnani</author>
<author>Bonnie Dorr</author>
</authors>
<title>Generating Targeted Paraphrases for Improved Translation.</title>
<date>2013</date>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<note>to appear.</note>
<contexts>
<context position="6137" citStr="Madnani and Dorr, 2013" startWordPosition="912" endWordPosition="915">oficiency exams, and professional licensure exams. Our seed lexicon is a combination of (1) positive and negative sentiment words manually selected from a full list of word types in these data, and (2) words marked in a small-scale annotation of a sample of sentences from these data for all positive and negative words. A more detailed description of the construction of seed lexicon can be found in Beigman Klebanov et al (2012). The seed lexicon contains 749 single words, 406 positive and 343 negative. 2.2 Expanded Lexicon We used a pivot-based lexical and phrasal paraphrase generation system (Madnani and Dorr, 2013). The paraphraser implements the pivot-based method as described by Bannard and Callison-Burch (2005) with several additional filtering mechanisms to increase the precision of the extracted pairs. The pivot-based method utilizes the inherent monolingual semantic knowledge from bilingual corpora: We first identify phrasal correspondences between English and a given foreign language F, then map from English to English by following translation units from English to the other language and back. For example, if the two English phrases e1 and e2 both correspond to the same foreign phrase f, then the</context>
<context position="7861" citStr="Madnani and Dorr, 2013" startWordPosition="1175" endWordPosition="1178">ions generated by the paraphraser are shown in Table 1. More details about this kind of approach can be found in Bannard and Callison-Burch (2005). We use the FrenchEnglish parallel corpus (approximately 1.2 million sentences) from the corpus of European parliamentary proceedings (Koehn, 2005) as the data on which pivoting is performed to extract the paraphrases. However, the base paraphrase system is susceptible 100 to large amounts of noise due to the imperfect bilingual word alignments. Therefore, we implement additional heuristics in order to minimize the number of noisy paraphrase pairs (Madnani and Dorr, 2013). For example, one such heuristic filters out pairs where a function word may have been inferred as a paraphrase of a content word. For the lexicon expansion experiment reported here, we use the top 15 single-word paraphrases for every word from the seed lexicon, excluding morphological variants of the seed word. This process results in an expanded lexicon of 2,994 different words, 1,666 positive and 1,761 negative (433 words are in both the positive and the negative lists). The expanded lexicon includes the seed lexicon. 3 Inducing sentiment profiles Let γw be the sentiment profile of the wor</context>
</contexts>
<marker>Madnani, Dorr, 2013</marker>
<rawString>Nitin Madnani and Bonnie Dorr. 2013. Generating Targeted Paraphrases for Improved Translation. ACM Transactions on Intelligent Systems and Technology, to appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Carmen Banea</author>
<author>Janyce Wiebe</author>
</authors>
<title>Learning multilingual subjective language via crosslingual projections.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>976--983</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2228" citStr="Mihalcea et al., 2007" startWordPosition="306" endWordPosition="309">U GPL license that disallows their incorporation into proprietary materials,2 respectively. 1http://www.wjh.harvard.edu/ inquirer/j1 1/manual/ 2http://www.gnu.org/copyleft/gpl.html Those wishing to integrate sentiment analysis into products, along with those studying subjectivity in languages other than English, or for specific domains such as finance, or for particular genres such as MySpace comments, reported construction of lexicons (Taboada et al., 2011; Loughran and McDonald, 2011; Thelwall et al., 2010; Rao and Ravichandran, 2009; Jijkoun and Hofmann, 2009; Pitel and Grefenstette, 2008; Mihalcea et al., 2007). In this paper, we address the step of expanding a small-scale, manually-built subjectivity lexicon (a seed lexicon, typically for a domain or language in question) into a much larger but noisier lexicon using an automatic procedure. We present a novel expansion method using a state-of-the-art paraphrasing system. The expansion yields a 4-fold increase in lexicon size; yet, the expansion alone is insufficient in order to improve performance on sentence-level sentiment polarity classification. In this paper we test the following hypothesis. We suggest that the effectiveness of the expansion is</context>
</contexts>
<marker>Mihalcea, Banea, Wiebe, 2007</marker>
<rawString>Rada Mihalcea, Carmen Banea, and Janyce Wiebe. 2007. Learning multilingual subjective language via crosslingual projections. In Proceedings of ACL, pages 976–983, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Miller</author>
</authors>
<title>WordNet: A lexical database.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<pages>38--39</pages>
<contexts>
<context position="11742" citStr="Miller, 1995" startWordPosition="1868" endWordPosition="1869">bins into the lexicon. It is in this sense that the expansion process is noisy; apparently, seed words with clear and strong polarity 101 800 600 400 200 0 −1.0 05 −0.5 10 0.0 0.5 1.0 −1.0 −0.5 0.0 −. 0.5 −0. 1.0 800 600 400 200 0 Figure 1: Sentiment distributions for the seed (left) and the expanded (right) lexicons. are often expanded into low intensity, neutral, or 1200 1200 120 ambiguous ones, as in pairs like absurd/laughable, deadly/fateful, anxiety/concern shown in Table 2. 4 Related Work The most popular seed expansion methods discussed 8 80 800 in the literature are based on WordNet (Miller, 1995) or another lexicographic resource, on dis600 600 600 tributional similarity with the seeds, or on a mixture thereof (Cruz et al., 2011; Baccianella et al., 400 400 2010; Velikovich et al., 2010; Qiu et al., 2009; Mo400 hammad et al., 2009; Esuli and Sebastiani, 2006; Kim and Hovy, 2004; Andreevskaia and Bergler, 200 200 200 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 0 0 2004; Takamura et al., 2005; Turney and Littman, 0 2003; Hatzivassiloglou and McKeown, 1997). The tributional similarity camp; we also experimented with WordNet-based ex</context>
<context position="28995" citStr="Miller, 1995" startWordPosition="4697" endWordPosition="4698"> and SentiWordNet. 1 0 7.2 Sentiment Profile Enrichment with Other Lexical Expansion Methods We presented a novel lexicon expansion method using a paraphrasing system. We also experimented with more standard methods, using WordNet and distributional similarity (Beigman Klebanov et al., 2012; Esuli and Sebastian,02006; Kim and Hovy, 2004; Andreevskaia and Bergler, 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003; Hatzivas0 siloglou and McKeown, 1997). Specifically, we implemented a WordNet (Miller, 1995)0based expansion that uses the 3 most frequent synonyms of the top sense of the seed word (WN-e). We also implemented a method based on distributional similarity: Using Lin’s proximity-based thesaurus (Lin, 1998) trained on our in-house essay data as well as on wellformed newswire texts, we took all words with the proximity score &gt; 1.80 to any of the seed lexicon words (Lin-e). Just like the paraphraser lexicon, both perform worse than the seed lexicon in 9 out of 10 baseline runs (BL-sum and Bl-full conditions for the 5 machine learners). To test the effect of profile enrichment, all words in</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George Miller. 1995. WordNet: A lexical database. Communications of the ACM, 38:39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Cody Dunne</author>
<author>Bonnie Dorr</author>
</authors>
<title>Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>599--608</pages>
<location>Singapore,</location>
<marker>Mohammad, Dunne, Dorr, 2009</marker>
<rawString>Saif Mohammad, Cody Dunne, and Bonnie Dorr. 2009. Generating high-coverage semantic orientation lexicons from overtly marked words and a thesaurus. In Proceedings of EMNLP, pages 599–608, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guillaume Pitel</author>
<author>Gregory Grefenstette</author>
</authors>
<title>Semiautomatic building method for a multidimensional affect dictionary for a new language.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC,</booktitle>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="2204" citStr="Pitel and Grefenstette, 2008" startWordPosition="302" endWordPosition="305">d education only1 and under GNU GPL license that disallows their incorporation into proprietary materials,2 respectively. 1http://www.wjh.harvard.edu/ inquirer/j1 1/manual/ 2http://www.gnu.org/copyleft/gpl.html Those wishing to integrate sentiment analysis into products, along with those studying subjectivity in languages other than English, or for specific domains such as finance, or for particular genres such as MySpace comments, reported construction of lexicons (Taboada et al., 2011; Loughran and McDonald, 2011; Thelwall et al., 2010; Rao and Ravichandran, 2009; Jijkoun and Hofmann, 2009; Pitel and Grefenstette, 2008; Mihalcea et al., 2007). In this paper, we address the step of expanding a small-scale, manually-built subjectivity lexicon (a seed lexicon, typically for a domain or language in question) into a much larger but noisier lexicon using an automatic procedure. We present a novel expansion method using a state-of-the-art paraphrasing system. The expansion yields a 4-fold increase in lexicon size; yet, the expansion alone is insufficient in order to improve performance on sentence-level sentiment polarity classification. In this paper we test the following hypothesis. We suggest that the effective</context>
</contexts>
<marker>Pitel, Grefenstette, 2008</marker>
<rawString>Guillaume Pitel and Gregory Grefenstette. 2008. Semiautomatic building method for a multidimensional affect dictionary for a new language. In Proceedings of LREC, Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Expanding domain sentiment lexicon through double propagation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 21st international jont conference on Artifical intelligence, IJCAI’09,</booktitle>
<pages>1199--1204</pages>
<contexts>
<context position="11954" citStr="Qiu et al., 2009" startWordPosition="1904" endWordPosition="1907">1.0 800 600 400 200 0 Figure 1: Sentiment distributions for the seed (left) and the expanded (right) lexicons. are often expanded into low intensity, neutral, or 1200 1200 120 ambiguous ones, as in pairs like absurd/laughable, deadly/fateful, anxiety/concern shown in Table 2. 4 Related Work The most popular seed expansion methods discussed 8 80 800 in the literature are based on WordNet (Miller, 1995) or another lexicographic resource, on dis600 600 600 tributional similarity with the seeds, or on a mixture thereof (Cruz et al., 2011; Baccianella et al., 400 400 2010; Velikovich et al., 2010; Qiu et al., 2009; Mo400 hammad et al., 2009; Esuli and Sebastiani, 2006; Kim and Hovy, 2004; Andreevskaia and Bergler, 200 200 200 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 0 0 2004; Takamura et al., 2005; Turney and Littman, 0 2003; Hatzivassiloglou and McKeown, 1997). The tributional similarity camp; we also experimented with WordNet-based expansion as descibed in section 7.2. The task of assigning sentiment profiles to words in a sentiment lexicon has been addressed in the literature. SentiWordNet assigns profiles to all words in WordNet based on a </context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2009</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2009. Expanding domain sentiment lexicon through double propagation. In Proceedings of the 21st international jont conference on Artifical intelligence, IJCAI’09, pages 1199–1204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Quesenberry</author>
<author>D Hurst</author>
</authors>
<title>Large sample simultaneous confidence intervals for multinomial proportions.</title>
<date>1964</date>
<tech>Technometrics,</tech>
<pages>6--191</pages>
<contexts>
<context position="9442" citStr="Quesenberry and Hurst (1964)" startWordPosition="1447" endWordPosition="1450">every word, a person is shown the word and asked whether it is positive, negative, or neutral. A person’s decision is modeled as flipping the coin corresponding to the word, and recording the outcome – positive, negative, or neutral. We run N=20 such trials for every word in the expanded lexicon using the CrowdFlower crowdsourcing site,4 for a total cost of $800. We use maximum likelihood estimate of sentiment profile: ˆpiw = ni (2) w where niw is the proportion of N trials on the word w that fell in cell i E {pos, neg, neu}. Table 2 shows some estimated profiles. Following Goodman (1965) and Quesenberry and Hurst (1964), we calculate confidence intervals for the parameters pi w: (ˆpiw)− = (B + 2niw − T)/(2(N + B)) (3) 4www.crowdflower.com Word ˆppos ˆpneu ˆpneg w w w forceful 0 0.15 0.85 resolute 0.8 0.15 0.05 peculiar 0.05 0.15 0.8 remarkable 1 0 0 anxiety 0 0 1 concern 0.25 0.4 0.35 absurd 0 0 1 laughable 0.5 0.05 0.45 deadly 0 0 1 fateful 0.25 0.45 0.3 consequence 0.05 0.15 0.8 outcome 0.15 0.85 0 Table 2: Examples of estimated sentiment profiles. Words in gray are expansions generated from words in the preceding row; note the difference in the profiles. (ˆpiw)+ = (B + 2niw + T)/(2(N + B)) (4) where �T = </context>
</contexts>
<marker>Quesenberry, Hurst, 1964</marker>
<rawString>C. Quesenberry and D. Hurst. 1964. Large sample simultaneous confidence intervals for multinomial proportions. Technometrics, 6:191–195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Quinlan</author>
</authors>
<title>C4.5: Programs for machine learning.</title>
<date>1993</date>
<publisher>Morgan Kaufmann Publishers.</publisher>
<contexts>
<context position="14776" citStr="Quinlan, 1993" startWordPosition="2363" endWordPosition="2364">ned through crowdsourcing on a large scale into0a sentiment lexicon, showing the effectiveness of this lexicon-enrichment procedure for a sentiment classification task. − 5 Using profiles for sentence-level sentiment polarity classification To evaluate the usefulness of the lexicons, we use them to generate features for machine learning syslevel sentiment polarity classification. To ensure robustness of the observed trends, we experiment with a number of machine learning algorithms: SVM Linear and RBF, Naive Bayes, Logistic Regression (using WEKA (Hall et al., 2009)), and c5.0 Decision Trees (Quinlan, 1993).5 5.1 Data We generated the data for training and testing the machine learning systems as follows. We used our 5available from http://rulequest.com/ 0 0.0 0− 0. 5− 1.0 00 05 10 1 05 0.0 0 0.5 5− 1. 00 paraphrase-based expansion method is in the dis0− tems, and compare5performance on 3-way sentencey y .0 y n . 7 . 0 00 05 CD � 10 n&apos; 1 y 5 n .0 CD 7 n� .5. . CD 0 0 1.0 .0 5 0 1 5 0 0 0. 0. 1.0 - 0 , ywa3- performance sentence- ,estm on compare and 102 pool of 100,000 essays to sample a second, nonoverlapping set of 5,000 essays, so that no essay used for lexicon development appears in this set.</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>J. R. Quinlan. 1993. C4.5: Programs for machine learning. Morgan Kaufmann Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delip Rao</author>
<author>Deepak Ravichandran</author>
</authors>
<title>Semisupervised polarity lexicon induction.</title>
<date>2009</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>675--682</pages>
<location>Athens.</location>
<contexts>
<context position="2147" citStr="Rao and Ravichandran, 2009" startWordPosition="294" endWordPosition="297">Wiebe and Riloff, 2005) – are available for research and education only1 and under GNU GPL license that disallows their incorporation into proprietary materials,2 respectively. 1http://www.wjh.harvard.edu/ inquirer/j1 1/manual/ 2http://www.gnu.org/copyleft/gpl.html Those wishing to integrate sentiment analysis into products, along with those studying subjectivity in languages other than English, or for specific domains such as finance, or for particular genres such as MySpace comments, reported construction of lexicons (Taboada et al., 2011; Loughran and McDonald, 2011; Thelwall et al., 2010; Rao and Ravichandran, 2009; Jijkoun and Hofmann, 2009; Pitel and Grefenstette, 2008; Mihalcea et al., 2007). In this paper, we address the step of expanding a small-scale, manually-built subjectivity lexicon (a seed lexicon, typically for a domain or language in question) into a much larger but noisier lexicon using an automatic procedure. We present a novel expansion method using a state-of-the-art paraphrasing system. The expansion yields a 4-fold increase in lexicon size; yet, the expansion alone is insufficient in order to improve performance on sentence-level sentiment polarity classification. In this paper we tes</context>
</contexts>
<marker>Rao, Ravichandran, 2009</marker>
<rawString>Delip Rao and Deepak Ravichandran. 2009. Semisupervised polarity lexicon induction. In Proceedings of EACL, pages 675–682, Athens.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Stone</author>
<author>Dexter Dunphy</author>
<author>Marshall Smith</author>
<author>Daniel Ogilvie</author>
</authors>
<title>The General Inquirer: A Computer Approach to Content Analysis.</title>
<date>1966</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="1458" citStr="Stone et al., 1966" startWordPosition="200" endWordPosition="203"> with other subjectivity lexicons and in a different domain of application (product reviews). 1 Introduction In almost any sub-field of computational linguistics, creation of working systems starts with an investment in manually-generated or manually-annotated data for computational exploration. In subjectivity and sentiment analysis, annotation of training and testing data and construction of subjectivity lexicons have been the loci of costly labor investment. Many subjectivity lexicons are mentioned in the literature. The two large manually-built lexicons for English – the General Inquirer (Stone et al., 1966) and the lexicon provided with the OpinionFinder distribution (Wiebe and Riloff, 2005) – are available for research and education only1 and under GNU GPL license that disallows their incorporation into proprietary materials,2 respectively. 1http://www.wjh.harvard.edu/ inquirer/j1 1/manual/ 2http://www.gnu.org/copyleft/gpl.html Those wishing to integrate sentiment analysis into products, along with those studying subjectivity in languages other than English, or for specific domains such as finance, or for particular genres such as MySpace comments, reported construction of lexicons (Taboada et </context>
</contexts>
<marker>Stone, Dunphy, Smith, Ogilvie, 1966</marker>
<rawString>Philip Stone, Dexter Dunphy, Marshall Smith, and Daniel Ogilvie. 1966. The General Inquirer: A Computer Approach to Content Analysis. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlo Strapparava</author>
<author>Alessandro Valitutti</author>
</authors>
<title>WordNet-affect: an affective extension of WordNet.</title>
<date>2004</date>
<booktitle>In Proceedings of LREC,</booktitle>
<pages>1083--1086</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="12153" citStr="Strapparava and Valitutti, 2004" startWordPosition="1937" endWordPosition="1940">s ones, as in pairs like absurd/laughable, deadly/fateful, anxiety/concern shown in Table 2. 4 Related Work The most popular seed expansion methods discussed 8 80 800 in the literature are based on WordNet (Miller, 1995) or another lexicographic resource, on dis600 600 600 tributional similarity with the seeds, or on a mixture thereof (Cruz et al., 2011; Baccianella et al., 400 400 2010; Velikovich et al., 2010; Qiu et al., 2009; Mo400 hammad et al., 2009; Esuli and Sebastiani, 2006; Kim and Hovy, 2004; Andreevskaia and Bergler, 200 200 200 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 0 0 2004; Takamura et al., 2005; Turney and Littman, 0 2003; Hatzivassiloglou and McKeown, 1997). The tributional similarity camp; we also experimented with WordNet-based expansion as descibed in section 7.2. The task of assigning sentiment profiles to words in a sentiment lexicon has been addressed in the literature. SentiWordNet assigns profiles to all words in WordNet based on a propagation algorithm from a small seed set manually annotated by a small number of judges (Baccianella et al., 2010; Cerini et al., 2007). Andreevskaia and Bergler (2006) use graph propagation algor</context>
<context position="28832" citStr="Strapparava and Valitutti, 2004" startWordPosition="4669" endWordPosition="4672">anilla seed lexicon performs comparably to off-the-shelf lexicons on our data, the paraphraser-expanded lexicon with sentitment profiles outperforms OpinionFinder, General Inquirer, and SentiWordNet. 1 0 7.2 Sentiment Profile Enrichment with Other Lexical Expansion Methods We presented a novel lexicon expansion method using a paraphrasing system. We also experimented with more standard methods, using WordNet and distributional similarity (Beigman Klebanov et al., 2012; Esuli and Sebastian,02006; Kim and Hovy, 2004; Andreevskaia and Bergler, 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003; Hatzivas0 siloglou and McKeown, 1997). Specifically, we implemented a WordNet (Miller, 1995)0based expansion that uses the 3 most frequent synonyms of the top sense of the seed word (WN-e). We also implemented a method based on distributional similarity: Using Lin’s proximity-based thesaurus (Lin, 1998) trained on our in-house essay data as well as on wellformed newswire texts, we took all words with the proximity score &gt; 1.80 to any of the seed lexicon words (Lin-e). Just like the paraphraser lexicon, both perform worse th</context>
</contexts>
<marker>Strapparava, Valitutti, 2004</marker>
<rawString>Carlo Strapparava and Alessandro Valitutti. 2004. WordNet-affect: an affective extension of WordNet. In Proceedings of LREC, pages 1083–1086, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangzhong Su</author>
<author>Katja Markert</author>
</authors>
<title>Eliciting Subjectivity and Polarity Judgements on Word Senses.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>825--832</pages>
<location>Manchester, UK.</location>
<marker>Su, Markert, 2008</marker>
<rawString>Fangzhong Su and Katja Markert. 2008. Eliciting Subjectivity and Polarity Judgements on Word Senses. In Proceedings of COLING, pages 825–832, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Subasic</author>
<author>A Huettner</author>
</authors>
<title>Affect analysis of text using fuzzy semantic typing.</title>
<date>2001</date>
<journal>IEEE Transactions on Fuzzy Systems,</journal>
<volume>9</volume>
<issue>4</issue>
<contexts>
<context position="13229" citStr="Subasic and Huettner (2001)" startWordPosition="2116" endWordPosition="2119">ally annotated by a small number of judges (Baccianella et al., 2010; Cerini et al., 2007). Andreevskaia and Bergler (2006) use graph propagation algorithms on WordNet to assign cen1 - trality scores in positive and negative categories; a 800 800 800 8 similar approach based on web-scale co-occurrence graphs is discussed in Velikovich et al (2010). Thelwall et al (2010) manually annotated a set of words 600 600 600 6 for strength of sentiment and used machine learning to fine-tune it. Taboada et al (2011) produced an 400 400 400 4 expert annotation of their lexicon with strength of sentiment. Subasic and Huettner (2001) manually built an affect lexicon with intensities. Wiebe and 200 200 200 Riloff (2005) classifed lexicon entries into weakly and strongly subjective, based on their relative fre0 0 0 quency of appearance in subjective versus objective contexts in a large5annotated dataset. Our sentiment profiles are best thought of as relatively fine-grained priors for the sentiment expressed by a given word out-of-context. These reflect a mixture of strength of sentiment �ood &gt; ppos decent), contextual ambiguity (concern can be interpreted as similar to worry or to care, as in “Her condition was causing conc</context>
</contexts>
<marker>Subasic, Huettner, 2001</marker>
<rawString>P. Subasic and A. Huettner. 2001. Affect analysis of text using fuzzy semantic typing. IEEE Transactions on Fuzzy Systems, 9(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
<author>Julian Brooke</author>
<author>Milan Tofiloski</author>
<author>Kimberly Voll</author>
<author>Manfred Stede</author>
</authors>
<title>Lexicon-Based Method for Sentiment Analysis.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>2</issue>
<contexts>
<context position="2067" citStr="Taboada et al., 2011" startWordPosition="282" endWordPosition="285"> al., 1966) and the lexicon provided with the OpinionFinder distribution (Wiebe and Riloff, 2005) – are available for research and education only1 and under GNU GPL license that disallows their incorporation into proprietary materials,2 respectively. 1http://www.wjh.harvard.edu/ inquirer/j1 1/manual/ 2http://www.gnu.org/copyleft/gpl.html Those wishing to integrate sentiment analysis into products, along with those studying subjectivity in languages other than English, or for specific domains such as finance, or for particular genres such as MySpace comments, reported construction of lexicons (Taboada et al., 2011; Loughran and McDonald, 2011; Thelwall et al., 2010; Rao and Ravichandran, 2009; Jijkoun and Hofmann, 2009; Pitel and Grefenstette, 2008; Mihalcea et al., 2007). In this paper, we address the step of expanding a small-scale, manually-built subjectivity lexicon (a seed lexicon, typically for a domain or language in question) into a much larger but noisier lexicon using an automatic procedure. We present a novel expansion method using a state-of-the-art paraphrasing system. The expansion yields a 4-fold increase in lexicon size; yet, the expansion alone is insufficient in order to improve perfo</context>
<context position="13112" citStr="Taboada et al (2011)" startWordPosition="2097" endWordPosition="2100">tiWordNet assigns profiles to all words in WordNet based on a propagation algorithm from a small seed set manually annotated by a small number of judges (Baccianella et al., 2010; Cerini et al., 2007). Andreevskaia and Bergler (2006) use graph propagation algorithms on WordNet to assign cen1 - trality scores in positive and negative categories; a 800 800 800 8 similar approach based on web-scale co-occurrence graphs is discussed in Velikovich et al (2010). Thelwall et al (2010) manually annotated a set of words 600 600 600 6 for strength of sentiment and used machine learning to fine-tune it. Taboada et al (2011) produced an 400 400 400 4 expert annotation of their lexicon with strength of sentiment. Subasic and Huettner (2001) manually built an affect lexicon with intensities. Wiebe and 200 200 200 Riloff (2005) classifed lexicon entries into weakly and strongly subjective, based on their relative fre0 0 0 quency of appearance in subjective versus objective contexts in a large5annotated dataset. Our sentiment profiles are best thought of as relatively fine-grained priors for the sentiment expressed by a given word out-of-context. These reflect a mixture of strength of sentiment �ood &gt; ppos decent), c</context>
</contexts>
<marker>Taboada, Brooke, Tofiloski, Voll, Stede, 2011</marker>
<rawString>Maite Taboada, Julian Brooke, Milan Tofiloski, Kimberly Voll, and Manfred Stede. 2011. Lexicon-Based Method for Sentiment Analysis. Computational Linguistics, 37(2):267–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Takamura</author>
<author>Takashi Inui</author>
<author>Manabu Okumura</author>
</authors>
<title>Extracting semantic orientation of words using spin model.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>133--140</pages>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="12200" citStr="Takamura et al., 2005" startWordPosition="1947" endWordPosition="1950">, anxiety/concern shown in Table 2. 4 Related Work The most popular seed expansion methods discussed 8 80 800 in the literature are based on WordNet (Miller, 1995) or another lexicographic resource, on dis600 600 600 tributional similarity with the seeds, or on a mixture thereof (Cruz et al., 2011; Baccianella et al., 400 400 2010; Velikovich et al., 2010; Qiu et al., 2009; Mo400 hammad et al., 2009; Esuli and Sebastiani, 2006; Kim and Hovy, 2004; Andreevskaia and Bergler, 200 200 200 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 0 0 2004; Takamura et al., 2005; Turney and Littman, 0 2003; Hatzivassiloglou and McKeown, 1997). The tributional similarity camp; we also experimented with WordNet-based expansion as descibed in section 7.2. The task of assigning sentiment profiles to words in a sentiment lexicon has been addressed in the literature. SentiWordNet assigns profiles to all words in WordNet based on a propagation algorithm from a small seed set manually annotated by a small number of judges (Baccianella et al., 2010; Cerini et al., 2007). Andreevskaia and Bergler (2006) use graph propagation algorithms on WordNet to assign cen1 - trality score</context>
<context position="28875" citStr="Takamura et al., 2005" startWordPosition="4677" endWordPosition="4680">elf lexicons on our data, the paraphraser-expanded lexicon with sentitment profiles outperforms OpinionFinder, General Inquirer, and SentiWordNet. 1 0 7.2 Sentiment Profile Enrichment with Other Lexical Expansion Methods We presented a novel lexicon expansion method using a paraphrasing system. We also experimented with more standard methods, using WordNet and distributional similarity (Beigman Klebanov et al., 2012; Esuli and Sebastian,02006; Kim and Hovy, 2004; Andreevskaia and Bergler, 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003; Hatzivas0 siloglou and McKeown, 1997). Specifically, we implemented a WordNet (Miller, 1995)0based expansion that uses the 3 most frequent synonyms of the top sense of the seed word (WN-e). We also implemented a method based on distributional similarity: Using Lin’s proximity-based thesaurus (Lin, 1998) trained on our in-house essay data as well as on wellformed newswire texts, we took all words with the proximity score &gt; 1.80 to any of the seed lexicon words (Lin-e). Just like the paraphraser lexicon, both perform worse than the seed lexicon in 9 out of 10 baseline</context>
</contexts>
<marker>Takamura, Inui, Okumura, 2005</marker>
<rawString>Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2005. Extracting semantic orientation of words using spin model. In Proceedings of ACL, pages 133–140, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Thelwall</author>
<author>Kevan Buckley</author>
<author>Georgios Paltoglou</author>
<author>Di Cai</author>
<author>Arvid Kappas</author>
</authors>
<title>Sentiment strength detection in short informal text.</title>
<date>2010</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>61</volume>
<issue>12</issue>
<marker>Thelwall, Buckley, Paltoglou, Di Cai, Kappas, 2010</marker>
<rawString>Mike Thelwall, Kevan Buckley, Georgios Paltoglou, Di Cai, and Arvid Kappas. 2010. Sentiment strength detection in short informal text. Journal of the American Society for Information Science and Technology, 61(12):2544–2558.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-Rich Part-ofSpeech Tagging with a Cyclic Dependency Network.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>252--259</pages>
<contexts>
<context position="27747" citStr="Toutanova et al., 2003" startWordPosition="4508" endWordPosition="4511">s were automatically generated, starting with a set of manually labeled synsets. Currently, SentiWordNet includes an automatic annotation for all the synsets in WordNet, totaling more than 100,000 words. It is therefore the largest-scale lexicon with intensity information that is currently available. Since SentiWordNet assigns scores to synsets and since our data is not sense-tagged, we induced Sen105 800 600 400 200 0 800 600 400 200 0 −1.0 −0.5 0.0 0.5 1.0 −1.0 −0.5 0.0 0.5 1.0 tiWordNet scores in the following ways. We part800 of-speech tagged our train and test data using Stanford tagger (Toutanova et al., 2003). Then, we took the SentiWordNet scores for the top sense for the given part-of-speech (SWW-1). In a different variant, we took a weighted average of the scores for the different senses, using the weighting algorithm provided on SentiWordNet website6 (SWN-2). Table 5 column SWN shows the best performance figures between SWN-1 and SWN-2, across the feature representations in section 5.2. The comparative results in Table 5 clearly show that while our vanilla seed lexicon performs comparably to off-the-shelf lexicons on our data, the paraphraser-expanded lexicon with sentitment profiles outperfor</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher Manning, and Yoram Singer. 2003. Feature-Rich Part-ofSpeech Tagging with a Cyclic Dependency Network. In Proceedings of HLT-NAACL, pages 252–259.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
<author>Michael Littman</author>
</authors>
<title>Measuring praise and criticism: Inference of semantic orientation from association.</title>
<date>2003</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="28901" citStr="Turney and Littman, 2003" startWordPosition="4681" endWordPosition="4684">a, the paraphraser-expanded lexicon with sentitment profiles outperforms OpinionFinder, General Inquirer, and SentiWordNet. 1 0 7.2 Sentiment Profile Enrichment with Other Lexical Expansion Methods We presented a novel lexicon expansion method using a paraphrasing system. We also experimented with more standard methods, using WordNet and distributional similarity (Beigman Klebanov et al., 2012; Esuli and Sebastian,02006; Kim and Hovy, 2004; Andreevskaia and Bergler, 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 2004; Takamura et al., 2005; Turney and Littman, 2003; Hatzivas0 siloglou and McKeown, 1997). Specifically, we implemented a WordNet (Miller, 1995)0based expansion that uses the 3 most frequent synonyms of the top sense of the seed word (WN-e). We also implemented a method based on distributional similarity: Using Lin’s proximity-based thesaurus (Lin, 1998) trained on our in-house essay data as well as on wellformed newswire texts, we took all words with the proximity score &gt; 1.80 to any of the seed lexicon words (Lin-e). Just like the paraphraser lexicon, both perform worse than the seed lexicon in 9 out of 10 baseline runs (BL-sum and Bl-full </context>
</contexts>
<marker>Turney, Littman, 2003</marker>
<rawString>Peter Turney and Michael Littman. 2003. Measuring praise and criticism: Inference of semantic orientation from association. ACM Transactions on Information Systems, 21(4):315346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonid Velikovich</author>
<author>Sasha Blair-Goldensohn</author>
<author>Kerry Hannan</author>
<author>Ryan McDonald</author>
</authors>
<title>The viability of Web-derived polarity lexicons.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<pages>777--785</pages>
<location>Los Angeles, CA.</location>
<contexts>
<context position="11936" citStr="Velikovich et al., 2010" startWordPosition="1900" endWordPosition="1903">−1.0 −0.5 0.0 −. 0.5 −0. 1.0 800 600 400 200 0 Figure 1: Sentiment distributions for the seed (left) and the expanded (right) lexicons. are often expanded into low intensity, neutral, or 1200 1200 120 ambiguous ones, as in pairs like absurd/laughable, deadly/fateful, anxiety/concern shown in Table 2. 4 Related Work The most popular seed expansion methods discussed 8 80 800 in the literature are based on WordNet (Miller, 1995) or another lexicographic resource, on dis600 600 600 tributional similarity with the seeds, or on a mixture thereof (Cruz et al., 2011; Baccianella et al., 400 400 2010; Velikovich et al., 2010; Qiu et al., 2009; Mo400 hammad et al., 2009; Esuli and Sebastiani, 2006; Kim and Hovy, 2004; Andreevskaia and Bergler, 200 200 200 2006; Hu and Liu, 2004; Kanayama and Nasukawa, 2006; Strapparava and Valitutti, 2004; Kamps et al., 0 0 2004; Takamura et al., 2005; Turney and Littman, 0 2003; Hatzivassiloglou and McKeown, 1997). The tributional similarity camp; we also experimented with WordNet-based expansion as descibed in section 7.2. The task of assigning sentiment profiles to words in a sentiment lexicon has been addressed in the literature. SentiWordNet assigns profiles to all words in W</context>
</contexts>
<marker>Velikovich, Blair-Goldensohn, Hannan, McDonald, 2010</marker>
<rawString>Leonid Velikovich, Sasha Blair-Goldensohn, Kerry Hannan, and Ryan McDonald. 2010. The viability of Web-derived polarity lexicons. In Proceedings of NAACL, pages 777–785, Los Angeles, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Rada Mihalcea</author>
</authors>
<title>Word sense and subjectivity.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1065--1072</pages>
<location>Sydney, Australia.</location>
<marker>Wiebe, Mihalcea, 2006</marker>
<rawString>Janyce Wiebe and Rada Mihalcea. 2006. Word sense and subjectivity. In Proceedings of ACL, pages 1065– 1072, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Ellen Riloff</author>
</authors>
<title>Creating subjective and objective sentence classifiers from unannotated texts.</title>
<date>2005</date>
<booktitle>In Proceedings of CICLING (invited paper),</booktitle>
<pages>486--497</pages>
<location>Mexico City.</location>
<contexts>
<context position="1544" citStr="Wiebe and Riloff, 2005" startWordPosition="213" endWordPosition="216">t reviews). 1 Introduction In almost any sub-field of computational linguistics, creation of working systems starts with an investment in manually-generated or manually-annotated data for computational exploration. In subjectivity and sentiment analysis, annotation of training and testing data and construction of subjectivity lexicons have been the loci of costly labor investment. Many subjectivity lexicons are mentioned in the literature. The two large manually-built lexicons for English – the General Inquirer (Stone et al., 1966) and the lexicon provided with the OpinionFinder distribution (Wiebe and Riloff, 2005) – are available for research and education only1 and under GNU GPL license that disallows their incorporation into proprietary materials,2 respectively. 1http://www.wjh.harvard.edu/ inquirer/j1 1/manual/ 2http://www.gnu.org/copyleft/gpl.html Those wishing to integrate sentiment analysis into products, along with those studying subjectivity in languages other than English, or for specific domains such as finance, or for particular genres such as MySpace comments, reported construction of lexicons (Taboada et al., 2011; Loughran and McDonald, 2011; Thelwall et al., 2010; Rao and Ravichandran, 2</context>
</contexts>
<marker>Wiebe, Riloff, 2005</marker>
<rawString>Janyce Wiebe and Ellen Riloff. 2005. Creating subjective and objective sentence classifiers from unannotated texts. In Proceedings of CICLING (invited paper), pages 486–497, Mexico City.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>