<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000438">
<title confidence="0.9373055">
Train the Machine with What It Can Learn
− Corpus Selection for SMT
</title>
<author confidence="0.990331">
Xiwu Han
</author>
<affiliation confidence="0.864462666666667">
School of Computer Sci-
ence and Technology,
Heilongjiang University,
</affiliation>
<address confidence="0.927884">
Harbin City 150080 China
</address>
<email confidence="0.996834">
hxw@hlju.edu.cn
</email>
<author confidence="0.984382">
Hanzhang Li
</author>
<affiliation confidence="0.858352">
School of Computer Sci-
ence and Technology,
Heilongjiang University,
</affiliation>
<address confidence="0.926004">
Harbin City 150080 China
</address>
<email confidence="0.996769">
lhj@hlju.edu.cn
</email>
<author confidence="0.99491">
Tiejun Zhao
</author>
<affiliation confidence="0.987254">
School of Computer Science and
Technology,
Harbin Institute of Technology,
</affiliation>
<address confidence="0.947382">
Harbin City 150001 China
</address>
<email confidence="0.998879">
tjzhao@mtlab.hit.edu.cn
</email>
<sectionHeader confidence="0.998606" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998870444444445">
Statistical machine translation relies heavily
on available parallel corpora, but SMT may
not have the ability or intelligence to make
full use of the training set. Instead of col-
lecting more and more parallel training cor-
pora, this paper aims to improve SMT
performance by exploiting the full potential
of existing parallel corpora. We first iden-
tify literally translated sentence pairs via
lexical and grammatical compatibility, and
then use these data to train SMT models.
One experiment indicates that larger train-
ing corpora do not always lead to higher de-
coding performance when the added data
are not literal translations. And another ex-
periment shows that properly enlarging the
contribution of literal translation can im-
prove SMT performance significantly.
</bodyText>
<sectionHeader confidence="0.996783" genericHeader="keywords">
1 Introduction*
</sectionHeader>
<bodyText confidence="0.999413">
Parallel corpora are generally considered indis-
pensable for the training of a translation model in
statistical machine translation (SMT). And most
researchers tend to agree on the opinion that the
more data is used to estimate the parameters of
the translation model, the better it can approxi-
mate the true translation probabilities, and in turn
this will lead to a better translation performance.
However, even if large corpora are easily avail-
able, does an SMT system have the ability or
intelligence to make full use of a training set?
Another aspect is that larger amounts of train-
ing data also require larger computational re-
</bodyText>
<note confidence="0.949186">
* This research is jointly supported by the National Natural
Science Foundation of China under Grant No.60773069 and
60873169.
</note>
<bodyText confidence="0.999747333333333">
sources. With increasing quantities of training
data, the improvement of translation quality will
become smaller and smaller. Therefore, while
continuing to collect more and more parallel cor-
pora, it is also important to seek effective ways
of making better use of available parallel training
data.
Literal translation and free translation are two
basic skills of human translation. A literal trans-
lation is a translation that follows closely the
form of the source language, also known as
word-for-word translation (Larson 1984).
According to Mona Baker (1992) translation
needs to maintain equivalence at different levels
across languages. In bottom-up sequence, these
levels are: the word level, the above word level,
the grammatical level, the textual level and the
pragmatic level. Lower levels of equivalence are
often embedded in literal translation and easily
maintained, whereas higher levels are very im-
portant for free translation and very difficult to
be achieved even for experienced translators be-
cause this kind of equivalence more often than
not calls for thorough analysis and understanding
of the source language, which is obviously what
an SMT system cannot be capable of. So from
this perspective SMT may be regarded as a be-
ginner in learning how to translate.
The training of statistical machine translation
mainly depends on the alignment probabilities
estimated from certain frequencies observed in a
parallel corpus. Thus, we may say that SMT
translates according to its bilingual scanning ex-
periences, and there is actually no deep compre-
hension during the coding and decoding process.
Since human learners of translation generally
begin with the comparatively simpler techniques
of literal translation, our efforts described in this
paper are intended to discover whether a corpus
</bodyText>
<page confidence="0.986299">
27
</page>
<note confidence="0.9634665">
Proceedings of the 2nd Workshop on Building and Using Comparable Corpora, ACL-IJCNLP 2009, pages 27–33,
Suntec, Singapore, 6 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999618">
of literal translations better suits the training of
statistical machine translation.
In the following, section 2 introduces our cor-
pus and proposes a combined method to recog-
nize sentence pairs of literal translation. Section
3 describes our experiments with the acquired
corpus on SMT training from two points of view.
Section 4 analyzes the results from a linguistic
point of view. And the conclusion is given in
Section 5 with some suggestion for further work.
</bodyText>
<sectionHeader confidence="0.96329" genericHeader="introduction">
2 Literal Translation Recognition
</sectionHeader>
<bodyText confidence="0.999746166666667">
Early machine translations were notorious for
bad literal translations especially of idioms.
However, good literal translation means to trans-
late a sentence originally, and to keep the origi-
nal message form, including the construction of
the sentence, the meaning of the original words,
use of metaphors and so on. Such a translation
would be fluent and easy to comprehend by tar-
get language readers. If we suppose that the
training corpus for SMT is mainly constituted of
good translations, our first task is to identify
those literally translated sentence pairs.
</bodyText>
<subsectionHeader confidence="0.978495">
2.1 Our Corpus
</subsectionHeader>
<bodyText confidence="0.999690476190476">
The corpus used for our experiment consists of
650,000 bilingual sentence pairs of English and
Chinese, which were gathered either from public
and free Internet resources or from our own
translation works. The sentences are either trans-
lated from Chinese to English or vice versa.
To facilitate the process of recognition, before
the SMT experiment we preprocessed the corpus
for the word and POS information, with English
sentences parsed by (Collins 1999)’s head-driven
parser and Chinese sentences by the head-driven
parser of MI&amp;TLAB at Harbin Institute of Tech-
nology (Cao 2006).
We define the literally translated sentence
pairs as those that either embed enough word
pairs which can be looked up in a bilingual dic-
tionary, or share enough common grammatical
categories. Hence, we invented two cross-lingual
measures for the recognition of literal translation,
i.e. lexical compatibility and grammatical com-
patibility.
</bodyText>
<subsectionHeader confidence="0.999984">
2.2 Method of Lexical Compatibility
</subsectionHeader>
<bodyText confidence="0.980624489361702">
The seed version of our bilingual dictionary is
made up of 63,483 entries drawn from the bi-
lingual dictionary for the rule-based Chinese-
English machine translation system of CEMT2K
developed by MI&amp;TLAB at Harbin Institute of
Technology (Zhao 2001). We extended the seed
with synonyms from English WordNet v. 1.2 and
Chinese Extended Tongyicicilin v. 1.0. The ex-
tending algorithm is as follows.
Input: The seed version dictionary SD, Chi-
nese Extended Tongyicicilin CT, and
English WordNet EW
Output: An extended Chinese English dic-
tionary ED
Do:
a. For each entry in SD,
a) extend the Chinese part with all its
synonyms found in CT;
b) extend the English part with all its
synonyms found in EW;
c) accept the extended entry into ED.
b. For each entry in ED,
a) if its Chinese part is a subset of that of
another entry, merge them;
b) if its English part is a subset of that of
another entry, merge them.
An entry in our final extended dictionary in
turn is organized as bilingual synonym classes,
and there are altogether 43,820 entries including
212,367 Chinese and English lexical terms.
By looking up Chinese-English word pairs in
the extended dictionary, we defined the cross-
lingual measure of lexical compatibility for a
Chinese-English sentence pair as CL.
the number of word pairs looked up
the total number of all words
For the recognition task, we employed a maxi-
mum likelihood estimation filtering method with
an empirical threshold of 0.85 on the lexical
compatibility. Sentence pairs would be accepted
as literal translation if their lexical compatibility
CL &gt; 0.85.
Manual analysis on 15,000 sentence pairs
showed that for this method the precision is
94.65% and the recall is only 16.84%. The low
recall is obviously due to the limitations of our
bilingual dictionary.
</bodyText>
<subsectionHeader confidence="0.999967">
2.3 Method of Grammatical Compatibility
</subsectionHeader>
<bodyText confidence="0.9999774">
Although the diversity of grammatical categories
tends to be great, some common word classes,
such as nouns, pronouns, verbs, adjectives, etc,
mainly constitute the vocabularies of most natu-
ral languages. And our observations on English
</bodyText>
<equation confidence="0.857736">
CL =
</equation>
<page confidence="0.980314">
28
</page>
<bodyText confidence="0.99485925">
words or bad POS tagging results of both the
Chinese and English parsers. In contrast, those
sentence pairs correctly unrecalled are usually
free transcriptions or bad translations.
</bodyText>
<sectionHeader confidence="0.840031" genericHeader="method">
3 SMT Experiments
</sectionHeader>
<bodyText confidence="0.9998315">
and Chinese parallel corpora show that the more
literal a translation is, the more equivalent gram-
matical categories the pair of sentences may
share.
We thus define the cross-lingual measure of
grammatical compatibility as CG.
</bodyText>
<sectionHeader confidence="0.489482" genericHeader="method">
CG
</sectionHeader>
<bodyText confidence="0.999746">
GE, is an English grammatical category, JGE,J
is the number it occurs in the English sentence,
and GC, is the Chinese counterpart (see Table 1).
n is the number of common grammatical catego-
ries that make differences in the special task of
recognizing literal translated sentence pairs. A; is
the weight for the respective category, which is
trained by a simple gradient descent algorithm on
a sample of 10,000 manually analysed sentence
pairs.
</bodyText>
<table confidence="0.9143752">
i Chinese English
1 noun noun
2 pronoun pronoun
3 verb verb
4 adjective adjective and adverb
</table>
<tableCaption confidence="0.99964">
Table 1: Equivalent grammatical categories
</tableCaption>
<bodyText confidence="0.999929">
For the recognition task, we also employed a
maximum likelihood estimation filtering method
with an empirical threshold of 0.82 on the gram-
matical compatibility. Sentence pairs would be
accepted as literal translation if their grammatical
compatibility CG &gt; 0.82.
Evaluation on the held-out sample of 5,000
sentence pairs shows a precision ratio of 89.5%
and a recall ratio of 42.34%.
</bodyText>
<subsectionHeader confidence="0.997965">
2.4 Combination of the Two Methods
</subsectionHeader>
<bodyText confidence="0.999993375">
We simply combined the results of the two
methods mentioned above to obtain a larger use-
ful corpus. It is very interesting that the intersec-
tion between the results of the two methods
accounts only for a very small part, which is es-
timated to be 17.2% of all the identified sentence
pairs. The combined recognition results achieved
a precision of 92.33% and a recall of 54.78% on
the testing sample of 15,000 sentence pairs. And
on the total corpus, our combined method ac-
quired 201,062 sentence pairs that were classi-
fied to be the results of literal translation.
Further analysis on the sampled corpus shows
that the wrongly unrecalled literally translated
sentence pairs and the wrongly recalled ones are
mainly due to bad segmentation of Chinese
</bodyText>
<subsectionHeader confidence="0.999146">
3.1 Our Corpus and SMT System
</subsectionHeader>
<bodyText confidence="0.999978">
After excluding some too long sentence pairs, we
got our final training corpus, which includes
200,000 Chinese-English sentence pairs of literal
translation and 400,000 pairs of free translation1.
Our evaluation corpus was drawn from the
IWSLT Chinese-to-English MT test set of 2004,
which includes 506 Chinese sentences and 16
English reference sentences for each Chinese one.
Since our focus is not on a specific SMT ar-
chitecture, we use the off-the-shelf phrase-based
decoder Pharaoh (Koehn 2004). Pharaoh imple-
ments a beam search decoder for phrase-based
statistical models, and has the advantages of be-
ing freely available and widely used. The phrase
bilingual lexicon is derived from the intersection
of bi-directional IBM Model 4 alignments, ob-
tained with GIZA++ (Och and Ney 2003). For
better comparison between experimental results,
we kept all the system parameters as default,
while only tuning our own parameters.
</bodyText>
<subsectionHeader confidence="0.969472">
3.2 Experiment on Incremental Training
Corpora
</subsectionHeader>
<bodyText confidence="0.969902095238095">
This experiment was designed to check whether
it is true that larger training corpora always lead
to better SMT decoding performance. We ran-
domly segmented the 400,000 free translation
sentence pairs into 4 subsets, with each of them
including 100,000 pairs. A baseline SMT model
was trained with the 200,000 literal translation
sentence pairs, and then 4 other SMT models
were trained on extended corpora, of which each
later used corpus includes one more subset than
the previous one.
The decoding performances in terms of BLEU
and NIST scores of all 5 models are listed in the
second and third column of Table 2, and the last
column gives the numbers of out-of-vocabulary
(OOV) words of each model on the test set.
Curves in Figure 1 and 2, respectively, show the
trajectories of BLEU and NIST scores in accor-
dance with the sizes of extended training corpora.
&apos; Note that “free translations” are identified statistically
using our recognition method for literal translations.
</bodyText>
<figure confidence="0.5527745">
n Min( |GEi  |, |GCi  |)+1
H i Max( |GEi  |, |GCi  |) + 1
</figure>
<page confidence="0.950976">
29
</page>
<table confidence="0.998411333333333">
Corpus Size BLEU NIST OOV
200,000 0.3835 7.0982 47
300,000 0.3695 6.9096 45
400,000 0.4113 7.1242 32
500,000 0.4194 7.1824 21
600,000 0.4138 7.1566 18
</table>
<bodyText confidence="0.986728333333333">
A comparison between the different models’
BLEU and NIST scores shows that a larger train-
ing data set does not necessarily lead to better
SMT decoding performance. Based on the literal
translation data, when more and more free trans-
lation data are added to the training set, the per-
formance measures of the relevant SMT models
fall at first, then rise, and at finally fall again.
Furthermore, according to our manual analysis of
the decoding results, free translation data have
actually harmed the SMT model. It is just be-
cause the much smaller numbers of OOV words
have made up for the impairment that the per-
formance measures have risen for two times.
They, however, will fall when the decrease in
OOV words fails to make it up.
3.3 Experiment on Weighted Training Cor-
pora
This experiment was designed to exploit both the
contribution of literal translation and the advan-
tage of a large vocabulary from a larger corpus.
To achieve such a goal, minor modifications
need to be made towards the training corpus and
the module of GIZA++.
We start with an SMT training data set X,
which includes n bilingual sentence pairs, i.e. the
input vector X = {x1, x2, x3, ..., xi, ..., xn-1, xn}.
During the original training process, every sen-
tence pair xi contributes in the same way to the
estimation of parameters in the translation model
since the corpus has not been weighted. Now we
tried to adjust the contribution of xi according to
our previous decision whether it is literal transla-
tion or free translation. If we set the weight vec-
tor to be W = {w w w . w . w w }&apos;
b 2s 3s • • � n • • � n-b n ,
the weighted corpus would become X’ = WX =
{w1x1, w2 x2, w3x3, ..., wixi, ..., wn-1 xn-1, wn xn},
where
</bodyText>
<equation confidence="0.5907815">
wi = λ when xi is literal translation,
1 – λ otherwise.
</equation>
<bodyText confidence="0.999812230769231">
Hereby λ is an empirical weighting parameter
in the range of 0&lt;= λ &lt;=1.
The module of GIZA++ was modified to en-
sure that the weights imposed on sentence pairs
could be effectively transmitted to smaller trans-
lation units. GIZA++ builds word alignments by
means of counting occurrences of word pairs in
the training corpus. Given a possibly translatable
Chinese-English word pair D = &lt;c, e&gt;, the
number N of its occurrences in our original train-
ing corpus X can be calculated by summing up
its occurrence number Nxi in each sentence pair,
i.e.
</bodyText>
<equation confidence="0.545342">
∑n
i=1 Nxi
</equation>
<bodyText confidence="0.94034575">
Thus the weighted occurrence number N’ of
word pair D in the weighted training corpus can
be calculated via the following equation.
N&apos;= ∑n 1 Nwi∗xi = ∑n
</bodyText>
<subsectionHeader confidence="0.455925">
(wi ∗ Nxi
</subsectionHeader>
<bodyText confidence="0.999941357142857">
Finally, GIZA++ estimates word alignment
parameters on the basis of N’. Apart from this
modification, all other parts of PHARAOH had
been untouched to guarantee comparable ex-
perimental results.
We trained five SMT models of different
weights on the previously mentioned corpora of
free and literal translations. Table 3 lists both the
training parameters and relevant decoding per-
formances of the five models. Figures 3 and 4
show the trajectories of BLEU and NIST scores
in accordance with the weight variable. We can
see that the SMT model achieved the best per-
formance when λ was set to be 0.67.
</bodyText>
<tableCaption confidence="0.946548">
Table 2: SMT performance with extended corpora
</tableCaption>
<figureCaption confidence="0.999992">
Figure 1: Trajectory of BLEU score
Figure 2: Trajectory of NIST score
</figureCaption>
<bodyText confidence="0.484782">
N
</bodyText>
<page confidence="0.979118">
30
</page>
<table confidence="0.995888333333333">
Corpus Size λ BLEU NIST OOV
400,000 0 0.4001 6.9082 23
600,000 0.5 0.4138 7.0796 18
600,000 0.67 0.4259 7.2997 26
600,000 0.8 0.4243 7.2706 39
200,000 1 0.3835 7.0982 47
</table>
<bodyText confidence="0.999961794871795">
Among the five models, that of λ = 0.5 is the
baseline since here all sentence pairs contributed
in the same way. Those of λ = 0 and 1 are two
special cases designed to explore the isolated
contribution of free and literal translation corpora
in a contrastive way. Hereby the two models of
λ = 0.67 and 0.8 are the central part of our ex-
periment. According to the performance traject-
ories it seems that a reasonable increase in the
contribution of the corpus of literal translations
effectively improves the decoding performance
of the SMT system since the BLEU scores with λ
= 0.67 and 0.8 are higher than that of the baseline
which are 0.0121 and 0.0105, and of the NIST
scores which are 0.2201 and 0.191.
Our further analysis of the translation results
and the related evaluation scores with different
weight parameters showed that there exists some
potential for literal translations to be used to im-
prove SMT systems.
Our analysis indicates that two facts caused
most of the out-of-vocabulary words (see Table
3). First, some OOV words never occurred in the
training corpus; second, most others had been
pruned off due to their much lower frequencies.
Training corpora for λ = 0.67 and 0.8 have the
same size of as that for λ = 0.5, but they resulted
in much more OOV words than those for λ = 0.5
because the lower weight had decreased some
related alignment probabilities very much. It
seems that the large OOV increase must have
counteracted the potential improvement to a cer-
tain degree although it did not have a devastating
effects in these two cases. Therefore, a proper
selection of a corpus of literal translations as
training data would contribute more to the im-
provement of SMT models should some heuristic
pruning methods be employed to avoid a possi-
ble OOV increase.
</bodyText>
<sectionHeader confidence="0.999948" genericHeader="method">
4 Related work
</sectionHeader>
<bodyText confidence="0.999983973684211">
There have been a lot of studies on SMT training
data. Most of them are focused on parallel data
collections. Some work tried to acquire more
parallel sentences from the web (Nie et al. 1999;
Resnik and Smith 2003; Chen et al. 2004). Oth-
ers extracted parallel sentences from comparable
or non-parallel corpora (Munteanu and Marcu
2005, 2006). These works aim to collect more
parallel training corpora, while our work aims to
make better use of existing parallel corpora.
Some studies have also been conducted on
parallel data selection and adaptation. Eck et al.
(2005) proposed a method to select more infor-
mative sentences based on n-gram coverage.
They used n-grams to estimate the importance of
a sentence. The more previously unseen n-grams
exist in the sentence, the more important the sen-
tence is regarded. A TF-IDF weighting scheme
was also tried in their method, but did not show
improvements over n-grams. Their goal was to
decrease the amount of training data to make
SMT systems adaptable to small devices.
Some other works select training data accord-
ing to domain information of the test set.
Hildebrand et al. (2005) used an information re-
trieval method for translation model adaptation.
They selected sentences similar to the test set
from available in-of-domain and out-of-domain
training data to form an adapted translation
model. Lü et al. (2007) further used smaller
adapted data to optimize the distribution of the
whole training data. They took advantage both of
larger data and adapted data.
Unlike all the above-mentioned studies, our
method selected the training corpus according to
basic theories of literal and free translation. This
is somewhat similar to Lü et al. (2007), however,
our weighting scheme also tried to make use of
</bodyText>
<tableCaption confidence="0.973482">
Table 3: SMT performances with weighted corpora
</tableCaption>
<figureCaption confidence="0.9999935">
Figure 3: Trajectory of BLEU score
Figure 4: Trajectory of NIST score
</figureCaption>
<page confidence="0.999468">
31
</page>
<bodyText confidence="0.999548133333333">
both larger and smaller data, which are free
translations and literal translations in our case.
Besides, there have also been some studies on
language model adaptation in recent years, moti-
vated by the fact hat large-scale monolingual
corpora are easier to obtain than parallel corpora..
Examples are Zhao et al. (2004), Eck et al.
(2004), Zhang et al. (2006) and Mauser et al.
(2006). Since a language model is built for the
target language in SMT, a one pass translation is
usually needed to generate the n-best translation
candidates in language model adaptation. The
principle in our research could also be used for
translation re-ranking to further improve SMT
performance.
</bodyText>
<sectionHeader confidence="0.999778" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999711875">
This paper presents a new method to improve
statistical machine translation performance by
making better use of the available parallel train-
ing corpora. We at first identified literally trans-
lated sentence pairs by means of lexical and
grammatical compatibility, and then used these
data to train SMT models. Experimental results
show that literal and free translation corpora con-
tribute differently to the training of SMT models.
It seems that literal translation training data bet-
ter suit SMT system at its present level of intelli-
gence. The weighted training data can further
improve translation performance by enlarging
the contribution of literal translations while
maintaining a larger vocabulary from the larger
corpus of free translations. Detailed analysis
shows that a literal translation corpus would con-
tribute more to the improvement of SMT models
if some heuristic pruning methods would be em-
ployed to avoid possible OOV increase.
In future work, we will improve our methods
in several aspects. Currently, the recognition
method for literal translations and the weighting
schemes are very simple. It might work better by
trying some supervised recognition techniques or
using more complicated methods to determine
the weights of sentence pairs with variant literal
degree. What’s more, our present test corpus is
an out-of-domain one, and this might have im-
pacted the observations made in this work. Last,
employing our method to the language model
might also improve translation performance.
</bodyText>
<sectionHeader confidence="0.998811" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999884428571429">
We are obliged to the authors of English Word-
Net version 1.2 and Chinese Extended Tongy-
icicilin version 1.0 for the free dictionary re-
sources they provided. We also thank the two
reviewers for their constructive advices that we
referred to when preparing the last version of this
paper.
</bodyText>
<sectionHeader confidence="0.998455" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999345339622641">
Almut Silja Hildebrand, Matthias Eck, Stephan Vogel,
and Alex Waibel. 2005. Adaptation of the Transla-
tion Model for Statistical Machine Translation
based on Information Retrieval. Proceedings of
EAMT 2005: 133-142.
Arne Mauser, Richard Zens, Evgeny Matusov, Sasa
Hasan, Hermann Ney. 2006. The RWTH Statistical
Machine Translation System for the IWSLT 2006
Evaluation. Proceedings of International Work-
shop on Spoken Language Translation: 103-110.
Bing Zhao, Matthias Eck, Stephan Vogel. 2004. Lan-
guage Model Adaptation for Statistical Machine
Translation with structured query models.
COLING-2004.
Dragos Stefan Munteanu and Daniel Marcu. 2005.
Improving Machine Translation Performance by
Exploiting Comparable Corpora. Computational
Linguistics, 31 (4): 477-504.
Dragos Stefan Munteanu and Daniel Marcu. 2006.
Extracting Parallel Sub-Sentential Fragments from
Comparable Corpora. ACL-2006: 81-88.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment
models. Computational Linguistics, 29(1): 19-52.
Hailong Cao. 2006. Research on Chinese Syntactic
Parsing Based on Lexicalized Statistical Model,
Dissertation for PhD, Harbin Institute of Technol-
ogy, Harbin.
Jian-Yun Nie, Michel Simard, Pierre Isabelle, Richard
Durand. 1999. Cross-Language Information Re-
trieval based on Parallel Texts and Automatic Min-
ing of Parallel Texts in the Web. SIGIR-1999: 74-
81.
Jisong Chen, Rowena Chau, Chung-Hsing Yeh. 2004.
Discovering Parallel Text from the World Wide
Web. ACSW Frontiers 2004: 157-161.
Matthias Eck, Stephan Vogel, and Alex Waibel. 2004.
Language Model Adaptation for Statistical Ma-
chine Translation Based on Information Retrieval.
Proceedings of Fourth International Conference
on Language Resources and Evaluation: 327-330.
Michael Collins. 1999. Head-Driven Statistical Mod-
els for Natural Language Parsing. PhD Disserta-
tion, University of Pennsylvania.
Mona Baker. 2000. In Other Words: A Coursebook on
Translaton, Foreign Language Teaching and Re-
search Press, Beijing.
Mildred L. Larson. 1984. Meaning-based translation:
A guide to cross-language equivalence. Lanham,
MD: University Press of America.
Philipp Koehn. 2004. Pharaoh: a beam search decoder
for phrase-based statistical machine translation
models. In 6th Conference of the Association for
</reference>
<page confidence="0.984602">
32
</page>
<reference confidence="0.997593833333333">
Machine Translation in the Americas (AMTA),
Washington, DC.
Philip Resnik and Noah A. Smith. 2003. The Web as
a Parallel Corpus. Computational Linguistics,
29(3): 349-380.
Tiejun Zhao. 2001. Technical Reports for CEMT2K.
MI&amp;TLAB, Harbin Institute of Technology,
Harbin.
Yajuan Lü, Jin Huang and Qun Liu. 2007. Improving
Statistical Machine Translation Performance by
Training Data Selection and Optimization. Pro-
ceedings of the 2007 Joint Conference on Empiri-
cal Methods in Natural Language Processing and
Computational Natural Language Learning, pp.
343-350.
Ying Zhang, Almut Silja Hildebrand, Stephan Vogel.
2006. Distributed Language Modeling for N-best
List Re-ranking. EMNLP-2006: 216-223.
</reference>
<page confidence="0.99938">
33
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.991583">Train the Machine with What It Can Learn − Corpus Selection for SMT</title>
<author confidence="0.966256">Xiwu</author>
<affiliation confidence="0.808872333333333">of Computer ence and Heilongjiang</affiliation>
<address confidence="0.971075">Harbin City 150080 China</address>
<email confidence="0.941081">hxw@hlju.edu.cn</email>
<author confidence="0.781344">Hanzhang</author>
<affiliation confidence="0.76955">of Computer ence and Heilongjiang</affiliation>
<address confidence="0.967633">Harbin City 150080 China</address>
<email confidence="0.979987">lhj@hlju.edu.cn</email>
<author confidence="0.759068">Tiejun</author>
<affiliation confidence="0.9990805">School of Computer Science Harbin Institute of</affiliation>
<address confidence="0.900882">Harbin City 150001 China</address>
<email confidence="0.985776">tjzhao@mtlab.hit.edu.cn</email>
<abstract confidence="0.995806364620939">Statistical machine translation relies heavily on available parallel corpora, but SMT may not have the ability or intelligence to make full use of the training set. Instead of collecting more and more parallel training corpora, this paper aims to improve SMT performance by exploiting the full potential of existing parallel corpora. We first identify literally translated sentence pairs via lexical and grammatical compatibility, and then use these data to train SMT models. One experiment indicates that larger training corpora do not always lead to higher decoding performance when the added data are not literal translations. And another experiment shows that properly enlarging the contribution of literal translation can improve SMT performance significantly. Parallel corpora are generally considered indispensable for the training of a translation model in statistical machine translation (SMT). And most researchers tend to agree on the opinion that the more data is used to estimate the parameters of the translation model, the better it can approximate the true translation probabilities, and in turn this will lead to a better translation performance. However, even if large corpora are easily available, does an SMT system have the ability or intelligence to make full use of a training set? Another aspect is that larger amounts of traindata also require larger computational reresearch is jointly supported by the National Natural Science Foundation of China under Grant No.60773069 and 60873169. sources. With increasing quantities of training data, the improvement of translation quality will become smaller and smaller. Therefore, while continuing to collect more and more parallel corpora, it is also important to seek effective ways of making better use of available parallel training data. Literal translation and free translation are two basic skills of human translation. A literal translation is a translation that follows closely the form of the source language, also known as word-for-word translation (Larson 1984). According to Mona Baker (1992) translation needs to maintain equivalence at different levels across languages. In bottom-up sequence, these levels are: the word level, the above word level, the grammatical level, the textual level and the pragmatic level. Lower levels of equivalence are often embedded in literal translation and easily maintained, whereas higher levels are very important for free translation and very difficult to be achieved even for experienced translators because this kind of equivalence more often than not calls for thorough analysis and understanding of the source language, which is obviously what an SMT system cannot be capable of. So from this perspective SMT may be regarded as a beginner in learning how to translate. The training of statistical machine translation mainly depends on the alignment probabilities estimated from certain frequencies observed in a parallel corpus. Thus, we may say that SMT translates according to its bilingual scanning experiences, and there is actually no deep comprehension during the coding and decoding process. Since human learners of translation generally begin with the comparatively simpler techniques of literal translation, our efforts described in this paper are intended to discover whether a corpus 27 of the 2nd Workshop on Building and Using Comparable Corpora, ACL-IJCNLP pages Singapore, 6 August 2009. ACL and AFNLP of literal translations better suits the training of statistical machine translation. In the following, section 2 introduces our corpus and proposes a combined method to recognize sentence pairs of literal translation. Section 3 describes our experiments with the acquired corpus on SMT training from two points of view. Section 4 analyzes the results from a linguistic point of view. And the conclusion is given in Section 5 with some suggestion for further work. 2 Literal Translation Recognition Early machine translations were notorious for bad literal translations especially of idioms. However, good literal translation means to translate a sentence originally, and to keep the original message form, including the construction of the sentence, the meaning of the original words, use of metaphors and so on. Such a translation would be fluent and easy to comprehend by target language readers. If we suppose that the training corpus for SMT is mainly constituted of good translations, our first task is to identify those literally translated sentence pairs. 2.1 Our Corpus The corpus used for our experiment consists of 650,000 bilingual sentence pairs of English and Chinese, which were gathered either from public and free Internet resources or from our own translation works. The sentences are either translated from Chinese to English or vice versa. To facilitate the process of recognition, before the SMT experiment we preprocessed the corpus for the word and POS information, with English sentences parsed by (Collins 1999)’s head-driven parser and Chinese sentences by the head-driven parser of MI&amp;TLAB at Harbin Institute of Technology (Cao 2006). We define the literally translated sentence pairs as those that either embed enough word pairs which can be looked up in a bilingual dictionary, or share enough common grammatical categories. Hence, we invented two cross-lingual measures for the recognition of literal translation, i.e. lexical compatibility and grammatical compatibility. 2.2 Method of Lexical Compatibility The seed version of our bilingual dictionary is made up of 63,483 entries drawn from the bilingual dictionary for the rule-based Chinese- English machine translation system of CEMT2K developed by MI&amp;TLAB at Harbin Institute of Technology (Zhao 2001). We extended the seed with synonyms from English WordNet v. 1.2 and Chinese Extended Tongyicicilin v. 1.0. The extending algorithm is as follows. seed version dictionary Chi- Extended Tongyicicilin and WordNet extended Chinese English dic- Do: For each entry in a) extend the Chinese part with all its found in b) extend the English part with all its found in accept the extended entry into For each entry in a) if its Chinese part is a subset of that of another entry, merge them; b) if its English part is a subset of that of another entry, merge them. An entry in our final extended dictionary in turn is organized as bilingual synonym classes, and there are altogether 43,820 entries including 212,367 Chinese and English lexical terms. By looking up Chinese-English word pairs in the extended dictionary, we defined the crosslingual measure of lexical compatibility for a sentence pair as the number of word pairs looked up the total number of all words For the recognition task, we employed a maximum likelihood estimation filtering method with an empirical threshold of 0.85 on the lexical compatibility. Sentence pairs would be accepted as literal translation if their lexical compatibility 0.85. Manual analysis on 15,000 sentence pairs showed that for this method the precision is 94.65% and the recall is only 16.84%. The low recall is obviously due to the limitations of our bilingual dictionary. 2.3 Method of Grammatical Compatibility Although the diversity of grammatical categories tends to be great, some common word classes, such as nouns, pronouns, verbs, adjectives, etc, mainly constitute the vocabularies of most natural languages. And our observations on English = 28 words or bad POS tagging results of both the Chinese and English parsers. In contrast, those sentence pairs correctly unrecalled are usually free transcriptions or bad translations. 3 SMT Experiments and Chinese parallel corpora show that the more literal a translation is, the more equivalent grammatical categories the pair of sentences may share. We thus define the cross-lingual measure of compatibility as an English grammatical category, is the number it occurs in the English sentence, the Chinese counterpart (see Table 1). the number of common grammatical categories that make differences in the special task of literal translated sentence pairs. is the weight for the respective category, which is trained by a simple gradient descent algorithm on a sample of 10,000 manually analysed sentence pairs. i Chinese English 1 noun noun 2 pronoun pronoun 3 verb verb 4 adjective adjective and adverb Table 1: Equivalent grammatical categories For the recognition task, we also employed a maximum likelihood estimation filtering method with an empirical threshold of 0.82 on the grammatical compatibility. Sentence pairs would be accepted as literal translation if their grammatical 0.82. Evaluation on the held-out sample of 5,000 sentence pairs shows a precision ratio of 89.5% and a recall ratio of 42.34%. 2.4 Combination of the Two Methods We simply combined the results of the two methods mentioned above to obtain a larger useful corpus. It is very interesting that the intersection between the results of the two methods accounts only for a very small part, which is estimated to be 17.2% of all the identified sentence pairs. The combined recognition results achieved a precision of 92.33% and a recall of 54.78% on the testing sample of 15,000 sentence pairs. And on the total corpus, our combined method acquired 201,062 sentence pairs that were classified to be the results of literal translation. Further analysis on the sampled corpus shows that the wrongly unrecalled literally translated sentence pairs and the wrongly recalled ones are mainly due to bad segmentation of Chinese 3.1 Our Corpus and SMT System After excluding some too long sentence pairs, we got our final training corpus, which includes 200,000 Chinese-English sentence pairs of literal and 400,000 pairs of free Our evaluation corpus was drawn from the IWSLT Chinese-to-English MT test set of 2004, which includes 506 Chinese sentences and 16 English reference sentences for each Chinese one. Since our focus is not on a specific SMT architecture, we use the off-the-shelf phrase-based decoder Pharaoh (Koehn 2004). Pharaoh implements a beam search decoder for phrase-based statistical models, and has the advantages of being freely available and widely used. The phrase bilingual lexicon is derived from the intersection of bi-directional IBM Model 4 alignments, obtained with GIZA++ (Och and Ney 2003). For better comparison between experimental results, we kept all the system parameters as default, while only tuning our own parameters. 3.2 Experiment on Incremental Training Corpora This experiment was designed to check whether it is true that larger training corpora always lead to better SMT decoding performance. We randomly segmented the 400,000 free translation sentence pairs into 4 subsets, with each of them including 100,000 pairs. A baseline SMT model was trained with the 200,000 literal translation sentence pairs, and then 4 other SMT models were trained on extended corpora, of which each later used corpus includes one more subset than the previous one. The decoding performances in terms of BLEU and NIST scores of all 5 models are listed in the second and third column of Table 2, and the last column gives the numbers of out-of-vocabulary (OOV) words of each model on the test set. Curves in Figure 1 and 2, respectively, show the trajectories of BLEU and NIST scores in accordance with the sizes of extended training corpora. that “free translations” are identified statistically using our recognition method for literal translations. n |, || i  |,  ||) 29</abstract>
<address confidence="0.6606596">Corpus Size BLEU NIST OOV 200,000 0.3835 7.0982 47 300,000 0.3695 6.9096 45 400,000 0.4113 7.1242 32 500,000 0.4194 7.1824 21</address>
<phone confidence="0.88103">600,000 0.4138 7.1566 18</phone>
<abstract confidence="0.996722385714286">A comparison between the different models’ BLEU and NIST scores shows that a larger training data set does not necessarily lead to better SMT decoding performance. Based on the literal translation data, when more and more free translation data are added to the training set, the performance measures of the relevant SMT models fall at first, then rise, and at finally fall again. Furthermore, according to our manual analysis of the decoding results, free translation data have actually harmed the SMT model. It is just because the much smaller numbers of OOV words have made up for the impairment that the performance measures have risen for two times. They, however, will fall when the decrease in OOV words fails to make it up. 3.3 Experiment on Weighted Training Corpora This experiment was designed to exploit both the contribution of literal translation and the advantage of a large vocabulary from a larger corpus. To achieve such a goal, minor modifications need to be made towards the training corpus and the module of GIZA++. start with an SMT training data set includes sentence pairs, i.e. the vector ..., ..., During the original training process, every senpair in the same way to the estimation of parameters in the translation model since the corpus has not been weighted. Now we to adjust the contribution of to our previous decision whether it is literal translation or free translation. If we set the weight vecto be w w . w . w w 2s 3s • � • � weighted corpus would become where λ literal translation, – an empirical weighting parameter the range of 0&lt;= The module of GIZA++ was modified to ensure that the weights imposed on sentence pairs could be effectively transmitted to smaller translation units. GIZA++ builds word alignments by means of counting occurrences of word pairs in the training corpus. Given a possibly translatable word pair the its occurrences in our original traincorpus be calculated by summing up occurrence number each sentence pair, i.e. the weighted occurrence number pair the weighted training corpus can be calculated via the following equation. Finally, GIZA++ estimates word alignment on the basis of Apart from this modification, all other parts of PHARAOH had been untouched to guarantee comparable experimental results. We trained five SMT models of different weights on the previously mentioned corpora of free and literal translations. Table 3 lists both the training parameters and relevant decoding performances of the five models. Figures 3 and 4 show the trajectories of BLEU and NIST scores in accordance with the weight variable. We can see that the SMT model achieved the best perwhen set to be 0.67.</abstract>
<note confidence="0.327711833333333">Table 2: SMT performance with extended corpora Figure 1: Trajectory of BLEU score Figure 2: Trajectory of NIST score N 30 Corpus Size λ BLEU NIST OOV</note>
<phone confidence="0.5164562">400,000 0 0.4001 6.9082 23 600,000 0.5 0.4138 7.0796 18 600,000 0.67 0.4259 7.2997 26 600,000 0.8 0.4243 7.2706 39 200,000 1 0.3835 7.0982 47</phone>
<abstract confidence="0.999604565217391">the five models, that of 0.5 is the baseline since here all sentence pairs contributed the same way. Those of 0 and 1 are two special cases designed to explore the isolated contribution of free and literal translation corpora in a contrastive way. Hereby the two models of 0.67 and 0.8 are the central part of our experiment. According to the performance trajectories it seems that a reasonable increase in the contribution of the corpus of literal translations effectively improves the decoding performance the SMT system since the BLEU scores with = 0.67 and 0.8 are higher than that of the baseline which are 0.0121 and 0.0105, and of the NIST scores which are 0.2201 and 0.191. Our further analysis of the translation results and the related evaluation scores with different weight parameters showed that there exists some potential for literal translations to be used to improve SMT systems. Our analysis indicates that two facts caused most of the out-of-vocabulary words (see Table 3). First, some OOV words never occurred in the training corpus; second, most others had been pruned off due to their much lower frequencies. corpora for 0.67 and 0.8 have the size of as that for 0.5, but they resulted much more OOV words than those for 0.5 because the lower weight had decreased some related alignment probabilities very much. It seems that the large OOV increase must have counteracted the potential improvement to a certain degree although it did not have a devastating effects in these two cases. Therefore, a proper selection of a corpus of literal translations as training data would contribute more to the improvement of SMT models should some heuristic pruning methods be employed to avoid a possible OOV increase. 4 Related work There have been a lot of studies on SMT training data. Most of them are focused on parallel data collections. Some work tried to acquire more parallel sentences from the web (Nie et al. 1999; Resnik and Smith 2003; Chen et al. 2004). Others extracted parallel sentences from comparable or non-parallel corpora (Munteanu and Marcu 2005, 2006). These works aim to collect more parallel training corpora, while our work aims to make better use of existing parallel corpora. Some studies have also been conducted on parallel data selection and adaptation. Eck et al. (2005) proposed a method to select more informative sentences based on n-gram coverage. They used n-grams to estimate the importance of a sentence. The more previously unseen n-grams exist in the sentence, the more important the sentence is regarded. A TF-IDF weighting scheme was also tried in their method, but did not show improvements over n-grams. Their goal was to decrease the amount of training data to make SMT systems adaptable to small devices. Some other works select training data according to domain information of the test set. Hildebrand et al. (2005) used an information retrieval method for translation model adaptation. They selected sentences similar to the test set from available in-of-domain and out-of-domain training data to form an adapted translation model. Lü et al. (2007) further used smaller adapted data to optimize the distribution of the whole training data. They took advantage both of larger data and adapted data. Unlike all the above-mentioned studies, our method selected the training corpus according to basic theories of literal and free translation. This is somewhat similar to Lü et al. (2007), however, our weighting scheme also tried to make use of Table 3: SMT performances with weighted corpora Figure 3: Trajectory of BLEU score Figure 4: Trajectory of NIST score 31 both larger and smaller data, which are free translations and literal translations in our case. Besides, there have also been some studies on language model adaptation in recent years, motivated by the fact hat large-scale monolingual corpora are easier to obtain than parallel corpora.. Examples are Zhao et al. (2004), Eck et al. (2004), Zhang et al. (2006) and Mauser et al. (2006). Since a language model is built for the target language in SMT, a one pass translation is usually needed to generate the n-best translation candidates in language model adaptation. The principle in our research could also be used for translation re-ranking to further improve SMT performance. 5 Conclusions This paper presents a new method to improve statistical machine translation performance by making better use of the available parallel training corpora. We at first identified literally translated sentence pairs by means of lexical and grammatical compatibility, and then used these data to train SMT models. Experimental results show that literal and free translation corpora contribute differently to the training of SMT models. It seems that literal translation training data better suit SMT system at its present level of intelligence. The weighted training data can further improve translation performance by enlarging the contribution of literal translations while maintaining a larger vocabulary from the larger corpus of free translations. Detailed analysis shows that a literal translation corpus would contribute more to the improvement of SMT models if some heuristic pruning methods would be employed to avoid possible OOV increase. In future work, we will improve our methods in several aspects. Currently, the recognition method for literal translations and the weighting schemes are very simple. It might work better by trying some supervised recognition techniques or using more complicated methods to determine the weights of sentence pairs with variant literal degree. What’s more, our present test corpus is an out-of-domain one, and this might have impacted the observations made in this work. Last, employing our method to the language model might also improve translation performance. Acknowledgments We are obliged to the authors of English Word- Net version 1.2 and Chinese Extended Tongyversion 1.0 for the free dictionary resources they provided. We also thank the two reviewers for their constructive advices that we referred to when preparing the last version of this paper.</abstract>
<title confidence="0.878885">References</title>
<author confidence="0.7758675">Adaptation of the Transla-</author>
<title confidence="0.518938">tion Model for Statistical Machine Translation</title>
<note confidence="0.931040175">on Information Retrieval. of 133-142. Arne Mauser, Richard Zens, Evgeny Matusov, Sasa Hasan, Hermann Ney. 2006. The RWTH Statistical Machine Translation System for the IWSLT 2006 of International Workon Spoken Language 103-110. Bing Zhao, Matthias Eck, Stephan Vogel. 2004. Language Model Adaptation for Statistical Machine Translation with structured query models. COLING-2004. Dragos Stefan Munteanu and Daniel Marcu. 2005. Improving Machine Translation Performance by Comparable Corpora. 31 (4): 477-504. Dragos Stefan Munteanu and Daniel Marcu. 2006. Extracting Parallel Sub-Sentential Fragments from Corpora. 81-88. Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment 29(1): 19-52. Cao. 2006. on Chinese Syntactic Based on Lexicalized Statistical Dissertation for PhD, Harbin Institute of Technology, Harbin. Jian-Yun Nie, Michel Simard, Pierre Isabelle, Richard Durand. 1999. Cross-Language Information Retrieval based on Parallel Texts and Automatic Minof Parallel Texts in the Web. 74- 81. Jisong Chen, Rowena Chau, Chung-Hsing Yeh. 2004. Discovering Parallel Text from the World Wide Frontiers 157-161. Matthias Eck, Stephan Vogel, and Alex Waibel. 2004. Language Model Adaptation for Statistical Machine Translation Based on Information Retrieval. Proceedings of Fourth International Conference Language Resources and 327-330. Collins. 1999. Statistical Modfor Natural Language PhD Disserta-</note>
<affiliation confidence="0.90555">tion, University of Pennsylvania.</affiliation>
<address confidence="0.836504">Baker. 2000. Other Words: A Coursebook on</address>
<abstract confidence="0.565725777777778">Foreign Language Teaching and Research Press, Beijing. L. Larson. 1984. translation: guide to cross-language Lanham, MD: University Press of America. Philipp Koehn. 2004. Pharaoh: a beam search decoder for phrase-based statistical machine translation 6th Conference of the Association for 32</abstract>
<degree confidence="0.2745165">Translation in the Americas Washington, DC.</degree>
<author confidence="0.590849">The Web as Parallel Corpus</author>
<phone confidence="0.308792">29(3): 349-380.</phone>
<author confidence="0.797771">Reports for</author>
<affiliation confidence="0.944171">MI&amp;TLAB, Harbin Institute of Technology,</affiliation>
<address confidence="0.950172">Harbin.</address>
<note confidence="0.9341184">Yajuan Lü, Jin Huang and Qun Liu. 2007. Improving Statistical Machine Translation Performance by Data Selection and Optimization. Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Natural Language pp. 343-350. Ying Zhang, Almut Silja Hildebrand, Stephan Vogel. 2006. Distributed Language Modeling for N-best Re-ranking. 216-223.</note>
<intro confidence="0.575771">33</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Almut Silja Hildebrand</author>
<author>Matthias Eck</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Adaptation of the Translation Model for Statistical Machine Translation based on Information Retrieval.</title>
<date>2005</date>
<booktitle>Proceedings of EAMT 2005:</booktitle>
<pages>133--142</pages>
<contexts>
<context position="18728" citStr="Hildebrand et al. (2005)" startWordPosition="3087" endWordPosition="3090">ed on parallel data selection and adaptation. Eck et al. (2005) proposed a method to select more informative sentences based on n-gram coverage. They used n-grams to estimate the importance of a sentence. The more previously unseen n-grams exist in the sentence, the more important the sentence is regarded. A TF-IDF weighting scheme was also tried in their method, but did not show improvements over n-grams. Their goal was to decrease the amount of training data to make SMT systems adaptable to small devices. Some other works select training data according to domain information of the test set. Hildebrand et al. (2005) used an information retrieval method for translation model adaptation. They selected sentences similar to the test set from available in-of-domain and out-of-domain training data to form an adapted translation model. Lü et al. (2007) further used smaller adapted data to optimize the distribution of the whole training data. They took advantage both of larger data and adapted data. Unlike all the above-mentioned studies, our method selected the training corpus according to basic theories of literal and free translation. This is somewhat similar to Lü et al. (2007), however, our weighting scheme</context>
</contexts>
<marker>Hildebrand, Eck, Vogel, Waibel, 2005</marker>
<rawString>Almut Silja Hildebrand, Matthias Eck, Stephan Vogel, and Alex Waibel. 2005. Adaptation of the Translation Model for Statistical Machine Translation based on Information Retrieval. Proceedings of EAMT 2005: 133-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arne Mauser</author>
<author>Richard Zens</author>
<author>Evgeny Matusov</author>
<author>Sasa Hasan</author>
<author>Hermann Ney</author>
</authors>
<title>Evaluation.</title>
<date>2006</date>
<booktitle>The RWTH Statistical Machine Translation System for the IWSLT</booktitle>
<pages>103--110</pages>
<contexts>
<context position="19860" citStr="Mauser et al. (2006)" startWordPosition="3269" endWordPosition="3272">translation. This is somewhat similar to Lü et al. (2007), however, our weighting scheme also tried to make use of Table 3: SMT performances with weighted corpora Figure 3: Trajectory of BLEU score Figure 4: Trajectory of NIST score 31 both larger and smaller data, which are free translations and literal translations in our case. Besides, there have also been some studies on language model adaptation in recent years, motivated by the fact hat large-scale monolingual corpora are easier to obtain than parallel corpora.. Examples are Zhao et al. (2004), Eck et al. (2004), Zhang et al. (2006) and Mauser et al. (2006). Since a language model is built for the target language in SMT, a one pass translation is usually needed to generate the n-best translation candidates in language model adaptation. The principle in our research could also be used for translation re-ranking to further improve SMT performance. 5 Conclusions This paper presents a new method to improve statistical machine translation performance by making better use of the available parallel training corpora. We at first identified literally translated sentence pairs by means of lexical and grammatical compatibility, and then used these data to </context>
</contexts>
<marker>Mauser, Zens, Matusov, Hasan, Ney, 2006</marker>
<rawString>Arne Mauser, Richard Zens, Evgeny Matusov, Sasa Hasan, Hermann Ney. 2006. The RWTH Statistical Machine Translation System for the IWSLT 2006 Evaluation. Proceedings of International Workshop on Spoken Language Translation: 103-110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Zhao</author>
<author>Matthias Eck</author>
<author>Stephan Vogel</author>
</authors>
<title>Language Model Adaptation for Statistical Machine Translation with structured query models.</title>
<date>2004</date>
<pages>2004</pages>
<contexts>
<context position="19795" citStr="Zhao et al. (2004)" startWordPosition="3256" endWordPosition="3259">raining corpus according to basic theories of literal and free translation. This is somewhat similar to Lü et al. (2007), however, our weighting scheme also tried to make use of Table 3: SMT performances with weighted corpora Figure 3: Trajectory of BLEU score Figure 4: Trajectory of NIST score 31 both larger and smaller data, which are free translations and literal translations in our case. Besides, there have also been some studies on language model adaptation in recent years, motivated by the fact hat large-scale monolingual corpora are easier to obtain than parallel corpora.. Examples are Zhao et al. (2004), Eck et al. (2004), Zhang et al. (2006) and Mauser et al. (2006). Since a language model is built for the target language in SMT, a one pass translation is usually needed to generate the n-best translation candidates in language model adaptation. The principle in our research could also be used for translation re-ranking to further improve SMT performance. 5 Conclusions This paper presents a new method to improve statistical machine translation performance by making better use of the available parallel training corpora. We at first identified literally translated sentence pairs by means of le</context>
</contexts>
<marker>Zhao, Eck, Vogel, 2004</marker>
<rawString>Bing Zhao, Matthias Eck, Stephan Vogel. 2004. Language Model Adaptation for Statistical Machine Translation with structured query models. COLING-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragos Stefan Munteanu</author>
<author>Daniel Marcu</author>
</authors>
<title>Improving Machine Translation Performance by Exploiting Comparable Corpora.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>4</issue>
<pages>477--504</pages>
<contexts>
<context position="17932" citStr="Munteanu and Marcu 2005" startWordPosition="2955" endWordPosition="2958"> not have a devastating effects in these two cases. Therefore, a proper selection of a corpus of literal translations as training data would contribute more to the improvement of SMT models should some heuristic pruning methods be employed to avoid a possible OOV increase. 4 Related work There have been a lot of studies on SMT training data. Most of them are focused on parallel data collections. Some work tried to acquire more parallel sentences from the web (Nie et al. 1999; Resnik and Smith 2003; Chen et al. 2004). Others extracted parallel sentences from comparable or non-parallel corpora (Munteanu and Marcu 2005, 2006). These works aim to collect more parallel training corpora, while our work aims to make better use of existing parallel corpora. Some studies have also been conducted on parallel data selection and adaptation. Eck et al. (2005) proposed a method to select more informative sentences based on n-gram coverage. They used n-grams to estimate the importance of a sentence. The more previously unseen n-grams exist in the sentence, the more important the sentence is regarded. A TF-IDF weighting scheme was also tried in their method, but did not show improvements over n-grams. Their goal was to </context>
</contexts>
<marker>Munteanu, Marcu, 2005</marker>
<rawString>Dragos Stefan Munteanu and Daniel Marcu. 2005. Improving Machine Translation Performance by Exploiting Comparable Corpora. Computational Linguistics, 31 (4): 477-504.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragos Stefan Munteanu</author>
<author>Daniel Marcu</author>
</authors>
<title>Extracting Parallel Sub-Sentential Fragments from Comparable Corpora.</title>
<date>2006</date>
<volume>2006</volume>
<pages>81--88</pages>
<marker>Munteanu, Marcu, 2006</marker>
<rawString>Dragos Stefan Munteanu and Daniel Marcu. 2006. Extracting Parallel Sub-Sentential Fragments from Comparable Corpora. ACL-2006: 81-88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="11064" citStr="Och and Ney 2003" startWordPosition="1746" endWordPosition="1749">irs of free translation1. Our evaluation corpus was drawn from the IWSLT Chinese-to-English MT test set of 2004, which includes 506 Chinese sentences and 16 English reference sentences for each Chinese one. Since our focus is not on a specific SMT architecture, we use the off-the-shelf phrase-based decoder Pharaoh (Koehn 2004). Pharaoh implements a beam search decoder for phrase-based statistical models, and has the advantages of being freely available and widely used. The phrase bilingual lexicon is derived from the intersection of bi-directional IBM Model 4 alignments, obtained with GIZA++ (Och and Ney 2003). For better comparison between experimental results, we kept all the system parameters as default, while only tuning our own parameters. 3.2 Experiment on Incremental Training Corpora This experiment was designed to check whether it is true that larger training corpora always lead to better SMT decoding performance. We randomly segmented the 400,000 free translation sentence pairs into 4 subsets, with each of them including 100,000 pairs. A baseline SMT model was trained with the 200,000 literal translation sentence pairs, and then 4 other SMT models were trained on extended corpora, of which</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1): 19-52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hailong Cao</author>
</authors>
<title>Research on Chinese Syntactic Parsing Based on Lexicalized Statistical Model, Dissertation for PhD,</title>
<date>2006</date>
<institution>Harbin Institute of Technology,</institution>
<location>Harbin.</location>
<contexts>
<context position="5621" citStr="Cao 2006" startWordPosition="869" endWordPosition="870">ence pairs. 2.1 Our Corpus The corpus used for our experiment consists of 650,000 bilingual sentence pairs of English and Chinese, which were gathered either from public and free Internet resources or from our own translation works. The sentences are either translated from Chinese to English or vice versa. To facilitate the process of recognition, before the SMT experiment we preprocessed the corpus for the word and POS information, with English sentences parsed by (Collins 1999)’s head-driven parser and Chinese sentences by the head-driven parser of MI&amp;TLAB at Harbin Institute of Technology (Cao 2006). We define the literally translated sentence pairs as those that either embed enough word pairs which can be looked up in a bilingual dictionary, or share enough common grammatical categories. Hence, we invented two cross-lingual measures for the recognition of literal translation, i.e. lexical compatibility and grammatical compatibility. 2.2 Method of Lexical Compatibility The seed version of our bilingual dictionary is made up of 63,483 entries drawn from the bilingual dictionary for the rule-based ChineseEnglish machine translation system of CEMT2K developed by MI&amp;TLAB at Harbin Institute </context>
</contexts>
<marker>Cao, 2006</marker>
<rawString>Hailong Cao. 2006. Research on Chinese Syntactic Parsing Based on Lexicalized Statistical Model, Dissertation for PhD, Harbin Institute of Technology, Harbin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian-Yun Nie</author>
<author>Michel Simard</author>
<author>Pierre Isabelle</author>
<author>Richard Durand</author>
</authors>
<date>1999</date>
<booktitle>Cross-Language Information Retrieval based on Parallel Texts and Automatic Mining of Parallel Texts in the Web. SIGIR-1999:</booktitle>
<pages>74--81</pages>
<contexts>
<context position="17788" citStr="Nie et al. 1999" startWordPosition="2933" endWordPosition="2936">ies very much. It seems that the large OOV increase must have counteracted the potential improvement to a certain degree although it did not have a devastating effects in these two cases. Therefore, a proper selection of a corpus of literal translations as training data would contribute more to the improvement of SMT models should some heuristic pruning methods be employed to avoid a possible OOV increase. 4 Related work There have been a lot of studies on SMT training data. Most of them are focused on parallel data collections. Some work tried to acquire more parallel sentences from the web (Nie et al. 1999; Resnik and Smith 2003; Chen et al. 2004). Others extracted parallel sentences from comparable or non-parallel corpora (Munteanu and Marcu 2005, 2006). These works aim to collect more parallel training corpora, while our work aims to make better use of existing parallel corpora. Some studies have also been conducted on parallel data selection and adaptation. Eck et al. (2005) proposed a method to select more informative sentences based on n-gram coverage. They used n-grams to estimate the importance of a sentence. The more previously unseen n-grams exist in the sentence, the more important th</context>
</contexts>
<marker>Nie, Simard, Isabelle, Durand, 1999</marker>
<rawString>Jian-Yun Nie, Michel Simard, Pierre Isabelle, Richard Durand. 1999. Cross-Language Information Retrieval based on Parallel Texts and Automatic Mining of Parallel Texts in the Web. SIGIR-1999: 74-81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jisong Chen</author>
<author>Rowena Chau</author>
<author>Chung-Hsing Yeh</author>
</authors>
<title>Discovering Parallel Text from the World Wide Web. ACSW Frontiers</title>
<date>2004</date>
<pages>157--161</pages>
<contexts>
<context position="17830" citStr="Chen et al. 2004" startWordPosition="2941" endWordPosition="2944">OV increase must have counteracted the potential improvement to a certain degree although it did not have a devastating effects in these two cases. Therefore, a proper selection of a corpus of literal translations as training data would contribute more to the improvement of SMT models should some heuristic pruning methods be employed to avoid a possible OOV increase. 4 Related work There have been a lot of studies on SMT training data. Most of them are focused on parallel data collections. Some work tried to acquire more parallel sentences from the web (Nie et al. 1999; Resnik and Smith 2003; Chen et al. 2004). Others extracted parallel sentences from comparable or non-parallel corpora (Munteanu and Marcu 2005, 2006). These works aim to collect more parallel training corpora, while our work aims to make better use of existing parallel corpora. Some studies have also been conducted on parallel data selection and adaptation. Eck et al. (2005) proposed a method to select more informative sentences based on n-gram coverage. They used n-grams to estimate the importance of a sentence. The more previously unseen n-grams exist in the sentence, the more important the sentence is regarded. A TF-IDF weighting</context>
</contexts>
<marker>Chen, Chau, Yeh, 2004</marker>
<rawString>Jisong Chen, Rowena Chau, Chung-Hsing Yeh. 2004. Discovering Parallel Text from the World Wide Web. ACSW Frontiers 2004: 157-161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Eck</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Language Model Adaptation for Statistical Machine Translation Based on Information Retrieval.</title>
<date>2004</date>
<booktitle>Proceedings of Fourth International Conference on Language Resources and Evaluation:</booktitle>
<pages>327--330</pages>
<contexts>
<context position="19814" citStr="Eck et al. (2004)" startWordPosition="3260" endWordPosition="3263">ding to basic theories of literal and free translation. This is somewhat similar to Lü et al. (2007), however, our weighting scheme also tried to make use of Table 3: SMT performances with weighted corpora Figure 3: Trajectory of BLEU score Figure 4: Trajectory of NIST score 31 both larger and smaller data, which are free translations and literal translations in our case. Besides, there have also been some studies on language model adaptation in recent years, motivated by the fact hat large-scale monolingual corpora are easier to obtain than parallel corpora.. Examples are Zhao et al. (2004), Eck et al. (2004), Zhang et al. (2006) and Mauser et al. (2006). Since a language model is built for the target language in SMT, a one pass translation is usually needed to generate the n-best translation candidates in language model adaptation. The principle in our research could also be used for translation re-ranking to further improve SMT performance. 5 Conclusions This paper presents a new method to improve statistical machine translation performance by making better use of the available parallel training corpora. We at first identified literally translated sentence pairs by means of lexical and grammatic</context>
</contexts>
<marker>Eck, Vogel, Waibel, 2004</marker>
<rawString>Matthias Eck, Stephan Vogel, and Alex Waibel. 2004. Language Model Adaptation for Statistical Machine Translation Based on Information Retrieval. Proceedings of Fourth International Conference on Language Resources and Evaluation: 327-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>PhD</tech>
<institution>Dissertation, University of Pennsylvania.</institution>
<contexts>
<context position="5496" citStr="Collins 1999" startWordPosition="850" endWordPosition="851">training corpus for SMT is mainly constituted of good translations, our first task is to identify those literally translated sentence pairs. 2.1 Our Corpus The corpus used for our experiment consists of 650,000 bilingual sentence pairs of English and Chinese, which were gathered either from public and free Internet resources or from our own translation works. The sentences are either translated from Chinese to English or vice versa. To facilitate the process of recognition, before the SMT experiment we preprocessed the corpus for the word and POS information, with English sentences parsed by (Collins 1999)’s head-driven parser and Chinese sentences by the head-driven parser of MI&amp;TLAB at Harbin Institute of Technology (Cao 2006). We define the literally translated sentence pairs as those that either embed enough word pairs which can be looked up in a bilingual dictionary, or share enough common grammatical categories. Hence, we invented two cross-lingual measures for the recognition of literal translation, i.e. lexical compatibility and grammatical compatibility. 2.2 Method of Lexical Compatibility The seed version of our bilingual dictionary is made up of 63,483 entries drawn from the bilingua</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. PhD Dissertation, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Baker</author>
</authors>
<date>2000</date>
<booktitle>In Other Words: A Coursebook on Translaton, Foreign Language Teaching and</booktitle>
<publisher>Research Press,</publisher>
<location>Beijing.</location>
<marker>Baker, 2000</marker>
<rawString>Mona Baker. 2000. In Other Words: A Coursebook on Translaton, Foreign Language Teaching and Research Press, Beijing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mildred L Larson</author>
</authors>
<title>Meaning-based translation: A guide to cross-language equivalence.</title>
<date>1984</date>
<publisher>University Press of America.</publisher>
<location>Lanham, MD:</location>
<contexts>
<context position="2520" citStr="Larson 1984" startWordPosition="385" endWordPosition="386">National Natural Science Foundation of China under Grant No.60773069 and 60873169. sources. With increasing quantities of training data, the improvement of translation quality will become smaller and smaller. Therefore, while continuing to collect more and more parallel corpora, it is also important to seek effective ways of making better use of available parallel training data. Literal translation and free translation are two basic skills of human translation. A literal translation is a translation that follows closely the form of the source language, also known as word-for-word translation (Larson 1984). According to Mona Baker (1992) translation needs to maintain equivalence at different levels across languages. In bottom-up sequence, these levels are: the word level, the above word level, the grammatical level, the textual level and the pragmatic level. Lower levels of equivalence are often embedded in literal translation and easily maintained, whereas higher levels are very important for free translation and very difficult to be achieved even for experienced translators because this kind of equivalence more often than not calls for thorough analysis and understanding of the source languag</context>
</contexts>
<marker>Larson, 1984</marker>
<rawString>Mildred L. Larson. 1984. Meaning-based translation: A guide to cross-language equivalence. Lanham, MD: University Press of America.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Pharaoh: a beam search decoder for phrase-based statistical machine translation models.</title>
<date>2004</date>
<booktitle>In 6th Conference of the Association for Machine Translation in the Americas (AMTA),</booktitle>
<location>Washington, DC.</location>
<contexts>
<context position="10775" citStr="Koehn 2004" startWordPosition="1702" endWordPosition="1703">pairs and the wrongly recalled ones are mainly due to bad segmentation of Chinese 3.1 Our Corpus and SMT System After excluding some too long sentence pairs, we got our final training corpus, which includes 200,000 Chinese-English sentence pairs of literal translation and 400,000 pairs of free translation1. Our evaluation corpus was drawn from the IWSLT Chinese-to-English MT test set of 2004, which includes 506 Chinese sentences and 16 English reference sentences for each Chinese one. Since our focus is not on a specific SMT architecture, we use the off-the-shelf phrase-based decoder Pharaoh (Koehn 2004). Pharaoh implements a beam search decoder for phrase-based statistical models, and has the advantages of being freely available and widely used. The phrase bilingual lexicon is derived from the intersection of bi-directional IBM Model 4 alignments, obtained with GIZA++ (Och and Ney 2003). For better comparison between experimental results, we kept all the system parameters as default, while only tuning our own parameters. 3.2 Experiment on Incremental Training Corpora This experiment was designed to check whether it is true that larger training corpora always lead to better SMT decoding perfo</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Pharaoh: a beam search decoder for phrase-based statistical machine translation models. In 6th Conference of the Association for Machine Translation in the Americas (AMTA), Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Noah A Smith</author>
</authors>
<title>The Web as a Parallel Corpus.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>3</issue>
<pages>349--380</pages>
<contexts>
<context position="17811" citStr="Resnik and Smith 2003" startWordPosition="2937" endWordPosition="2940"> seems that the large OOV increase must have counteracted the potential improvement to a certain degree although it did not have a devastating effects in these two cases. Therefore, a proper selection of a corpus of literal translations as training data would contribute more to the improvement of SMT models should some heuristic pruning methods be employed to avoid a possible OOV increase. 4 Related work There have been a lot of studies on SMT training data. Most of them are focused on parallel data collections. Some work tried to acquire more parallel sentences from the web (Nie et al. 1999; Resnik and Smith 2003; Chen et al. 2004). Others extracted parallel sentences from comparable or non-parallel corpora (Munteanu and Marcu 2005, 2006). These works aim to collect more parallel training corpora, while our work aims to make better use of existing parallel corpora. Some studies have also been conducted on parallel data selection and adaptation. Eck et al. (2005) proposed a method to select more informative sentences based on n-gram coverage. They used n-grams to estimate the importance of a sentence. The more previously unseen n-grams exist in the sentence, the more important the sentence is regarded.</context>
</contexts>
<marker>Resnik, Smith, 2003</marker>
<rawString>Philip Resnik and Noah A. Smith. 2003. The Web as a Parallel Corpus. Computational Linguistics, 29(3): 349-380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tiejun Zhao</author>
</authors>
<date>2001</date>
<tech>Technical Reports for CEMT2K.</tech>
<institution>MI&amp;TLAB, Harbin Institute of Technology,</institution>
<location>Harbin.</location>
<contexts>
<context position="6246" citStr="Zhao 2001" startWordPosition="963" endWordPosition="964"> literally translated sentence pairs as those that either embed enough word pairs which can be looked up in a bilingual dictionary, or share enough common grammatical categories. Hence, we invented two cross-lingual measures for the recognition of literal translation, i.e. lexical compatibility and grammatical compatibility. 2.2 Method of Lexical Compatibility The seed version of our bilingual dictionary is made up of 63,483 entries drawn from the bilingual dictionary for the rule-based ChineseEnglish machine translation system of CEMT2K developed by MI&amp;TLAB at Harbin Institute of Technology (Zhao 2001). We extended the seed with synonyms from English WordNet v. 1.2 and Chinese Extended Tongyicicilin v. 1.0. The extending algorithm is as follows. Input: The seed version dictionary SD, Chinese Extended Tongyicicilin CT, and English WordNet EW Output: An extended Chinese English dictionary ED Do: a. For each entry in SD, a) extend the Chinese part with all its synonyms found in CT; b) extend the English part with all its synonyms found in EW; c) accept the extended entry into ED. b. For each entry in ED, a) if its Chinese part is a subset of that of another entry, merge them; b) if its English</context>
</contexts>
<marker>Zhao, 2001</marker>
<rawString>Tiejun Zhao. 2001. Technical Reports for CEMT2K. MI&amp;TLAB, Harbin Institute of Technology, Harbin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yajuan Lü</author>
<author>Jin Huang</author>
<author>Qun Liu</author>
</authors>
<title>Improving Statistical Machine Translation Performance by Training Data Selection and Optimization.</title>
<date>2007</date>
<booktitle>Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>343--350</pages>
<contexts>
<context position="18962" citStr="Lü et al. (2007)" startWordPosition="3122" endWordPosition="3125">ist in the sentence, the more important the sentence is regarded. A TF-IDF weighting scheme was also tried in their method, but did not show improvements over n-grams. Their goal was to decrease the amount of training data to make SMT systems adaptable to small devices. Some other works select training data according to domain information of the test set. Hildebrand et al. (2005) used an information retrieval method for translation model adaptation. They selected sentences similar to the test set from available in-of-domain and out-of-domain training data to form an adapted translation model. Lü et al. (2007) further used smaller adapted data to optimize the distribution of the whole training data. They took advantage both of larger data and adapted data. Unlike all the above-mentioned studies, our method selected the training corpus according to basic theories of literal and free translation. This is somewhat similar to Lü et al. (2007), however, our weighting scheme also tried to make use of Table 3: SMT performances with weighted corpora Figure 3: Trajectory of BLEU score Figure 4: Trajectory of NIST score 31 both larger and smaller data, which are free translations and literal translations in </context>
</contexts>
<marker>Lü, Huang, Liu, 2007</marker>
<rawString>Yajuan Lü, Jin Huang and Qun Liu. 2007. Improving Statistical Machine Translation Performance by Training Data Selection and Optimization. Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pp. 343-350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Zhang</author>
</authors>
<title>Almut Silja Hildebrand, Stephan Vogel.</title>
<date>2006</date>
<volume>2006</volume>
<pages>216--223</pages>
<marker>Zhang, 2006</marker>
<rawString>Ying Zhang, Almut Silja Hildebrand, Stephan Vogel. 2006. Distributed Language Modeling for N-best List Re-ranking. EMNLP-2006: 216-223.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>