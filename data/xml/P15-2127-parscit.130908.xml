<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.018115">
<title confidence="0.9993485">
Linguistic Template Extraction for Recognizing Reader-Emotion and
Emotional Resonance Writing Assistance
</title>
<author confidence="0.998321">
Yung-Chun Chang1,2, Cen-Chieh Chen1,3, Yu-Lun Hsieh1,3, Chien Chin Chen2, Wen-Lian Hsu1*
</author>
<affiliation confidence="0.999719333333333">
1Institute of Information Science, Academia Sinica, Taipei, Taiwan
2Department of Information Management, National Taiwan University, Taipei, Taiwan
3Department of Computer Science, National Chengchi University, Taipei, Taiwan
</affiliation>
<email confidence="0.992648">
1{changyc,can,morphe,hsu}@iis.sinica.edu.tw, 2patonchen@ntu.edu.tw
</email>
<sectionHeader confidence="0.993653" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999135">
In this paper, we propose a flexi-
ble principle-based approach (PBA) for
reader-emotion classification and writ-
ing assistance. PBA is a highly auto-
mated process that learns emotion tem-
plates from raw texts to characterize an
emotion and is comprehensible for hu-
mans. These templates are adopted to pre-
dict reader-emotion, and may further assist
in emotional resonance writing. Results
demonstrate that PBA can effectively de-
tect reader-emotions by exploiting the syn-
tactic structures and semantic associations
in the context, thus outperforming well-
known statistical text classification meth-
ods and the state-of-the-art reader-emotion
classification method. Moreover, writers
are able to create more emotional reso-
nance in articles under the assistance of the
generated emotion templates. These tem-
plates have been proven to be highly inter-
pretable, which is an attribute that is diffi-
cult to accomplish in traditional statistical
methods.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.989573351851852">
The Internet has rapidly grown into a powerful
medium for disseminating information. People
can easily share experiences and emotions anytime
and anywhere on social media websites. Human
feelings can be quickly collected through emotion
classification, as these emotions reflect an individ-
ual’s feelings and experiences toward some sub-
ject matters (Turney, 2002; Wilson et al., 2009).
Moreover, people can obtain more sponsorship
opportunities from manufacturers if their articles
about a certain product are able to create more
emotional resonance in the readers. Therefore,
*Corresponding author
emotion classification has been attracting more
and more attention, e.g., Chen et al. (2010), Purver
and Battersby (2012).
Emotion classification aims to predict the emo-
tion categories (e.g., happy or angry) of the given
text (Quan and Ren, 2009; Das and Bandyopad-
hyay, 2009). There are two aspects of emotions
in texts, namely, writer’s and reader’s emotions.
The former concerns the emotion expressed by
the writer of the text, and the latter concerns
the emotion a reader had after reading it. Rec-
ognizing reader-emotion is different and may be
even more complex than writer-emotion (Lin et
al., 2008; Tang and Chen, 2012). A writer may
directly express her emotions through sentiment
words. By contrast, reader-emotion possesses a
more perplexing nature, as even common words
can invoke different types of reader-emotions de-
pending on the reader’s personal experiences and
knowledge (Lin et al., 2007). For instance, a sen-
tence like “Kenya survivors describe deadly at-
tack at Garissa University” is simply stating the
facts without any emotion, but may invoke emo-
tions such as angry or worried in its readers.
In light of this rationale, we propose a principle-
based approach (PBA) for reader-emotion classifi-
cation. It is a highly automated process that in-
tegrates various types of knowledge to generate
discriminative linguistic templates that can be ac-
knowledged as the essential knowledge for hu-
mans to understand different kinds of emotions.
PBA recognizes reader-emotions of documents us-
ing an alignment algorithm that allows a template
to be partially matched through a statistical scor-
ing scheme. Experiments demonstrate that PBA
can achieve a better performance than other well-
known text categorization methods and the state-
of-the-art reader-emotion classification method.
Furthermore, we adopt these generated templates
to assist in emotional resonance writing. Results
show that writers are able to generate more emo-
</bodyText>
<page confidence="0.906066">
775
</page>
<bodyText confidence="0.441829">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 775–780,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</bodyText>
<equation confidence="0.985259">
−2log [p(w|E)N(w∧E)(1 )p(w|E)))N (EO )N(w(∧E)p(W  |)E)N(w∧-E)(p(E)  |(E))NN(E)¬E)
¬E)J (1)
</equation>
<bodyText confidence="0.999519333333333">
tional resonance in readers after exploiting these
templates, demonstrating the capability of PBA in
extracting templates with high interpretability.
</bodyText>
<sectionHeader confidence="0.680937" genericHeader="method">
2 Extracting Emotion Templates from
Raw Text
</sectionHeader>
<bodyText confidence="0.999729461538462">
PBA attempts to construct emotion templates
through recognition of crucial elements using a
three-layered approach. First, since keywords
contain important information, PBA learns reader-
emotion specific keywords using an effective
feature selection method, log likelihood ratio
(LLR) (Manning and Sch¨utze, 1999). It employs
Equation (1) to calculate the likelihood of the
assumption that the occurrence of a word w in
reader-emotion E is not random. In (1), E denotes
the set of documents of the reader-emotion in the
training data; N(E) and N(¬E) denote the num-
bers of documents that do or do not contain this
emotion, respectively; and N(w ∧ E) is the num-
ber of documents with emotion E and having w.
The probabilities p(w), p(w|E), and p(w|¬E) are
estimated using maximum likelihood estimation.
A larger LLR value is considered closely associ-
ated with an emotion. Words in the training data
are ranked by LLR values, and the top 200 are in-
cluded in our emotion keyword list.
Next, named entities (NEs) have been shown
to improve the performance of identifying top-
ics (Bashaddadh and Mohd, 2011). Thus, we uti-
lize Wikipedia to semi-automatically label NEs
with their semantic classes, which can be con-
sidered as a form of generalization. Wikipedia’s
category tags are used to label NEs recognized
by the Stanford NER1. If there are more than
one category tag for an NE, we select the most
dominant one with the highest number of as-
sociated Wikipedia pages. The assumption is
that the generality of a tag is indicated by the
number of Wikipedia pages that are linked to
it. For example, a query “奥巴马 (Obama)”
to the Wikipedia would return a page titled
“贝拉克.奥巴马 (Barack Obama)”. Within this
page, there are a number of category tags such
as “民主党 (Democratic Party)” and “X国总统
</bodyText>
<footnote confidence="0.890157">
1http://nlp.stanford.edu/software/CRF-NER.shtml
</footnote>
<bodyText confidence="0.999191744680851">
(Presidents of the United States)”. Suppose
“X国总统 (Presidents of the United States)” has
more out-going links, we will label “奥巴马
(Obama)” as “[X国总统] (Presidents of the
United States)”. We also annotate those NEs
not found in Wikipedia with their category tags.
In this manner, we can transform plain NEs
to a more general class and increase the cov-
erage of each label. Finally, to incorporate
richer semantic context, we exploit the Extended
HowNet (E-HowNet) (Chen et al., 2005) after
the above processes to tag the remaining text
with sense labels. Figure 1 illustrates crucial
element labeling process. Consider the clause
Cn = “奥巴马又代表民主党赢得X国总统选举
(Obama, representing the Democratic Party, won
the U.S. Presidential election)”. First, “奥巴马
(Obama)” is found in the emotion keyword list
and tagged. Then, NEs like “民主党 (Democratic
Party)” and “总统选举 (Presidential election)”
are recognized and tagged as “{政党 (Party)}”
and “{总统选举 (Presidential election)}”. Sub-
sequently, other terms such as “代表 (represent)”
and “赢得 (won)” are labeled with their corre-
sponding E-HowNet senses. Finally, we obtain the
sequence “[奥巴马] : {代表} : {政党} : {得到}
: {国家} : {总统选举} ([Obama] : {represents}
: {party} : {got} : {country} : {Presidential elec-
tion}).” This three-layered labeling process serves
as a generalization of the raw text for capturing
crucial elements used in the template generation
stage that follows.
The emotion template generation process aims
at automatically constructing representative tem-
plates consisting of a sequence of crucial el-
ements. We observed that the rank-frequency
distribution of the elements follows the Zipf’s
law (Manning and Sch¨utze, 1999). Thus, we
rank the templates according to their frequency,
and adopt a dominating set algorithm (Johnson,
1974) to use the top 20% templates to cover the
rest. First, we constructed a directed graph G =
{V, E}, in which vertices V contains all crucial
element sequences {CES1, · · · , CESm} in each
emotion, and edges E represent the dominating re-
lations between sequences. If CESx dominates
CESy, there is an edge CESx → CESy. A
</bodyText>
<page confidence="0.989003">
776
</page>
<figure confidence="0.875263666666667">
A clause Cn in an article:
Obama, representing the Democratic Party, won the U.S. Presidential election again
sequence of crucial elements
</figure>
<figureCaption confidence="0.998487">
Figure 1: Crucial element labeling process.
</figureCaption>
<figure confidence="0.989455566666666">
�����������������
��������������
Rft�K
�{��represen t} {��}
Party ��
{ get }��}
{ country { Presidential����elections }
� {represen �� t} {��}
Party ��
{ get }��}
{ country { Presidential����elections }
Domain
Keyword
Semantic
Class
Lexical
Database
Filtering
[ ��� ]
Barack Obama
LAET�
arack Obam
[ ��� ]
Barack Obama
[ ��� ]
Barack Obama
{ }
��
Party ��{ ��}
country { Presidential ���� elections }
</figure>
<bodyText confidence="0.999245538461539">
dominating relation is defined as follows. 1) Cru-
cial element sequences with high frequency are
selected as candidate dominators. 2) Longer se-
quences dominate shorter ones if their head and
tail elements are identical. The intermediate el-
ements are treated as insertions and/or deletions,
which can be scored based on their distribution in
this emotion during the matching process. Lastly,
we preserve top 100 most prominent and distinc-
tive ones from approximately 55,000 sequences
based on the dominating rate. This process serves
as a kind of dimension reduction and facilitates the
execution of our matching algorithm.
</bodyText>
<sectionHeader confidence="0.99" genericHeader="method">
3 Template Matching for Inference
</sectionHeader>
<bodyText confidence="0.99940575">
We believe that human perception of an emotion is
through recognizing important events or semantic
contents. For instance, when an article contains
strongly correlated words such as “Japan (coun-
try)”, “Earthquake (disaster)”, and “Tsunami (dis-
aster)” simultaneously, it is natural to conclude
that this article is more likely to elicit emotions
like depressed and worried rather than happy and
warm. Following this line of thought, PBA uses
an alignment algorithm (Needleman and Wun-
sch, 1970) to measure the similarity between tem-
plates and texts. It enables a single template to
match multiple semantically related expressions
with appropriate scores. For each clause in a doc-
ument dj, we first label crucial elements CE =
{ce1, · · · , cen}, followed by the matching proce-
dure that compares all sequences in CE from dj
to all emotion templates ET = {et1, · · · , etj} in
each emotion category, and calculates the scores.
Within the alignment matching, a statistical based
scoring criterion is used to score insertions, dele-
tions, and substitutions as described below. The
emotion ei with the highest sum of scores defined
in (2) is considered as the winner.
</bodyText>
<equation confidence="0.98885875">
Emotion(dj)
= arg max
ei∈E etn∈ETci,cem∈CEdj
A(etn · slk, cem · cel) (2)
</equation>
<bodyText confidence="0.999631529411765">
where slk and cel represent the kth slot of etn and
lth element of cem, respectively. Details for scor-
ing matched and unmatched elements are as fol-
lows. If etn·slk and cem·cel are identical, we add a
matched score (MS) obtained from the LLR value
of cel if it matches a keyword. Otherwise, the
score is determined by multiplying the frequency
of the crucial element in category ci by a normal-
izing factor A = 100, as in (3). On the other hand,
an unmatched element is given a score of insertion
or deletion. The insertion score (IS), defined as
(4), can be accounted for by the inversed entropy
of this element, which represents the uniqueness
or generality of it among categories. And the dele-
tion score (DS), defined as (5), is computed from
the log frequency of this crucial element in this
emotion category.
</bodyText>
<equation confidence="0.862714181818182">
A(etn, cem)
�=
k
�
l
777
P(celci) · log2(P(celci))
DS(cel) = log fcel
m
�
i=1
</equation>
<sectionHeader confidence="0.999723" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.996611">
4.1 Dataset and Setting
</subsectionHeader>
<bodyText confidence="0.999991176470588">
We collected a corpus of Chinese news articles
from Yahoo! Kimo News2, in which each article
is given votes from readers with emotion tags in
eight categories: angry, worried, boring, happy,
odd, depressing, warm, and informative. We con-
sider the voted emotions as the reader’s emotion
toward the news. Following previous studies such
as Lin et al. (2007) and Lin et al. (2008) that used
a similar source, we exclude “informative” as it is
not considered as an emotion category. To ensure
the quality of our evaluation, only articles with
a clear statistical distinction between the highest
vote of emotion and others determined by t-test
with a 95% confidence level are retained. Finally,
47,285 out of 68,026 articles are kept, and divided
into the training set and the test set, each contain-
ing 11,681 and 35,604 articles, respectively.
</bodyText>
<subsectionHeader confidence="0.993308">
4.2 Reader’s Emotion Classification
</subsectionHeader>
<bodyText confidence="0.999690142857143">
Several classification methods are implemented
and compared. Naive Bayes (McCallum et al.,
1998) serves as the baseline, denoted as NB. In
addition, a probabilistic graphical model that uses
LDA as document representation to train an SVM
classifier that determines a document as either rel-
evant or irrelevant (Blei et al., 2003), denotes as
LDA. Next, an emotion keyword-based model, de-
noted as KW, is trained using SVM to test the
effect of our keyword extraction approach. CF
is the state-of-the-art reader-emotion recognition
method that combines various features including
bigrams, words, metadata, and emotion category
words (Lin et al., 2007). For evaluation, we adopt
</bodyText>
<footnote confidence="0.911721">
2https://tw.news.yahoo.com
</footnote>
<bodyText confidence="0.99655125">
the accuracy measures as used by Lin et al. (2007),
and compute the macro-average (AM) and micro-
average (Aµ). Table 1 shows a comprehensive
evaluation of PBA and other methods3.
</bodyText>
<table confidence="0.999739545454545">
Emotion Accuracy(%)
NB LDA KW CF PBA
angry 47.00 74.21 79.21 83.71 87.83
worried 69.56 92.83 81.96 87.50 75.80
boring 75.67 76.21 84.34 87.52 90.52
happy 37.90 67.59 80.97 86.27 88.94
odd 73.90 85.40 77.05 84.25 83.34
depressing 73.76 81.43 85.00 87.70 92.15
warm 75.09 87.09 79.59 85.83 91.91
AM 58.11 76.10 80.36 85.80 86.43
Aµ 52.78 74.16 80.81 85.70 88.56
</table>
<tableCaption confidence="0.9605355">
Table 1: Comparison of the accuracies of five
reader-emotion classification systems.
</tableCaption>
<bodyText confidence="0.998108689655172">
Since NB only considers surface word weight-
ings and ignore inter-word relations, it only
achieved an accuracy of 58.11%. By contrast,
LDA includes both keywords and long-distance re-
lations, thus greatly outperforms NB with an over-
all accuracy of 76.10%. It even obtained the high-
est accuracy of 92.83% for the emotions “worried”
and “odd” among all methods. Notably, KW can
bring about substantial proficiency in detecting the
emotions, which indicates that reader-emotion can
be recognized effectively by using only the LLR
scores of keywords. Meanwhile, CF achieved a
satisfactory overall accuracy around 85%, due to
the combined lexical feature sets (e.g., charac-
ter bigrams, word dictionary, and emotion key-
words), paired with metadata of the articles. For
instance, we found that many sports-related ar-
ticles invoke the emotion “happy”. Specifically,
45% of all “happy” instances are sports-related,
and a sports-related article has a 31% chance of
having the emotion tag “happy”. Hence, the high
accuracy of the emotion category “happy” could
be the result of people’s general enthusiasm over
sports rather than a particular event. On top of
that, PBA can generate distinctive emotion tem-
plates to capture variations of similar expressions,
thus achieving better outcome.. For instance, the
template “{国家 country}” : [At occur] : [地震
earthquake] : {劫难 disaster}” is generated by PBA
</bodyText>
<footnote confidence="0.996393666666667">
3The dictionary required by all methods is constructed
by removing stop words according to (Zou et al., 2006),
and retaining tokens that make up 90% of the accumu-
lated frequency. As for unseen events, we used the Laplace
smoothing in NB. LDA is implemented using a toolkit
(http://nlp.stanford.edu/software/tmt/tmt-0.4/).
</footnote>
<equation confidence="0.971442875">
LLRcel, if cel ∈ keyword
λ fcel
�m
i=1
{
1
(4)
IS(cel) = m
MS(cel) =
, otherwise (3)
fcei
−
�
i=1
(5)
fcei
</equation>
<page confidence="0.989804">
778
</page>
<bodyText confidence="0.999932142857143">
for the emotion “worried”. It is perceivable that
this template is relaying information about dis-
astrous earthquakes in a country, and such news
often makes readers worry. The ability to yield
such emotion-specific, human interpretable tem-
plates could account for the outstanding perfor-
mance of PBA.
</bodyText>
<subsectionHeader confidence="0.994965">
4.3 Reader’s Emotion Templates Suggestion
in Emotional Resonance Writing
</subsectionHeader>
<bodyText confidence="0.999921675">
This experiment aims at testing the effectiveness
of the emotion templates in aiding writers to com-
pose articles with stronger emotional resonance.
Here, we only consider coarse-grained emotion
categories (i.e., positive and negative). Thus, fine-
grained emotions like happy, warm, and odd are
merged into ‘positive’, while angry, boring, de-
pressing, and worried are merged into ‘negative’.
10 templates for each of the fine-grained emo-
tions are selected, resulting in 30 and 40 templates
for the two coarse-grained emotions, respectively.
We recruited seven writers to compose two arti-
cles that they think will trigger positive and neg-
ative emotions without using templates (denoted
as NT). Then, we asked them to compose two
more articles with the aid of templates (denoted
as WT). Afterwards, all articles are randomly or-
ganized into a questionnaire to test the emotional
resonance. Subjects are required to perform two
tasks: 1) answer ‘positive’, ‘neutral’, or ‘negative’
2) give a score according to the five-point Likert
scale (Likert, 1932) for a given emotion. In the
end, 42 effective responses are gathered. For Task
1, the score is defined as the number of matching
responses and answers. As for Task 2, the score is
the sum of all articles. Higher scores indicate bet-
ter emotional resonance between writers and read-
ers. Figure 2 shows the sum of scores in Task 1
from all subjects, grouped by writer. As for Task 2,
Figure 3 shows the average score across subjects,
grouped by writers. In both tasks, we can see that
higher scores are obtained after using templates,
indicating that emotion templates can indeed assist
writers in creating stronger emotional resonance in
their composition.
To sum up, results show that PBA can gener-
ate emotion templates that not only help machines
predict reader’s emotion, but also effectively aid
writers in creating a stronger emotional resonance
with the readers.
</bodyText>
<figureCaption confidence="0.9948354">
Figure 2: Comparison of the number of correct
emotional response before and after utilizing tem-
plates.
Figure 3: Degree of emotional resonance between
writers and readers.
</figureCaption>
<sectionHeader confidence="0.997393" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999904166666667">
In this paper, we present PBA, a flexible, highly
automated, and human-interpretable approach
for reader-emotion classification. By capturing
prominent and representative patterns in texts,
PBA can effectively recognize the reader-emotion.
Results demonstrate that PBA outperforms other
reader-emotion detection methods, and can assist
writers in creating higher emotional resonance. In
the future, we plan to further refine and employ it
to other NLP applications. Also, additional work
can be done on combining statistical models into
different components of PBA.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997624333333333">
We are grateful to the anonymous reviewers for
their insightful comments. This research was sup-
ported by the Ministry of Science and Technology
of Taiwan under grant MOST 103-3111-Y-001-
027, 103-2221-E-002-106-MY2, and NSC102-
3113-P-001-006.
</bodyText>
<figure confidence="0.997361619047619">
Task-1
60
50
40
30
20
10
0
W3 W4 W5 W6 W7
NT WT
W1 W2
5
4
Task-2
W3 W4 W5 W6 W7
NT WT
W1 W2
3
2
1
0
</figure>
<page confidence="0.992439">
779
</page>
<sectionHeader confidence="0.988814" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999835886075949">
Omar Mabrook A Bashaddadh and Masnizah Mohd.
2011. Topic detection and tracking interface with
named entities approach. In Proceedings of the In-
ternational Conference on Semantic Technology and
Information Retrieval (STAIR), pages 215–219.
David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent Dirichlet allocation. Journal of Ma-
chine Learning Research, 3:993–1022.
Keh-Jiann Chen, Shu-Ling Huang, Yueh-Yin Shih, and
Yi-Jun Chen. 2005. Extended-HowNet - a represen-
tational framework for concepts. In Proceedings of
OntoLex 2005 - Ontologies and Lexical Resources
IJCNLP-05 Workshop.
Ying Chen, Sophia Yat Mei Lee, Shoushan Li, and
Chu-Ren Huang. 2010. Emotion cause detec-
tion with linguistic constructions. In Proceedings
of the 23rd International Conference on Computa-
tional Linguistics, pages 179–187.
Dipankar Das and Sivaji Bandyopadhyay. 2009. Word
to sentence level emotion tagging for bengali blogs.
In Proceedings of the ACL-IJCNLP 2009 Confer-
ence, pages 149–152.
David S. Johnson. 1974. Approximation algorithms
for combinatorial problems. Journal of Computer
and System Sciences, 9(3):256 – 278.
Rensis Likert. 1932. A technique for the measurement
of attitudes. Archives of Psychology, 140:1–55.
Kevin Hsin-Yih Lin, Changhua Yang, and Hsin-Hsi
Chen. 2007. What emotions do news articles trig-
ger in their readers? In Proceedings of the 30th An-
nual International ACM SIGIR Conference on Re-
search and Development in Information Retrieval,
pages 733–734.
Kevin Hsin-Yih Lin, Changhua Yang, and Hsin-Hsi
Chen. 2008. Emotion classification of online news
articles from the reader’s perspective. In Proceed-
ings of the 2008 IEEE/WIC/ACM International Con-
ference on Web Intelligence and Intelligent Agent
Technology, volume 1, pages 220–226.
Christopher D Manning and Hinrich Sch¨utze. 1999.
Foundations of statistical natural language process-
ing. MIT press.
Andrew McCallum, Kamal Nigam, et al. 1998. A
comparison of event models for naive bayes text
classification. In AAAI-98 workshop on learning for
text categorization, volume 752, pages 41–48.
Saul B Needleman and Christian D Wunsch. 1970.
A general method applicable to the search for simi-
larities in the amino acid sequence of two proteins.
Journal of Molecular Biology, 48(3):443–453.
Matthew Purver and Stuart Battersby. 2012. Experi-
menting with distant supervision for emotion classi-
fication. In Proceedings of the 13th Conference of
the European Chapter of the Association for Com-
putational Linguistics, pages 482–491.
Changqin Quan and Fuji Ren. 2009. Construction
of a blog emotion corpus for chinese emotional ex-
pression analysis. In Proceedings of the 2009 Con-
ference on Empirical Methods in Natural Language
Processing, volume 3, pages 1446–1454.
Yi-jie Tang and Hsin-Hsi Chen. 2012. Mining senti-
ment words from microblogs for predicting writer-
reader emotion transition. In Proceedings of the 8th
International Conference on Language Resources
and Evaluation (LREC), pages 1226–1229.
Peter D Turney. 2002. Thumbs up or thumbs down?:
semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of the 40th An-
nual Meeting of the Association for Computational
Linguistics, pages 417–424.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2009. Recognizing contextual polarity: An explo-
ration of features for phrase-level sentiment analy-
sis. Computational Linguistics, 35(3):399–433.
Feng Zou, Fu Lee Wang, Xiaotie Deng, Song Han, and
Lu Sheng Wang. 2006. Automatic construction of
chinese stop word list. In Proceedings of the 5th
WSEAS International Conference on Applied Com-
puter Science, pages 1010–1015.
</reference>
<page confidence="0.997134">
780
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.621489">
<title confidence="0.983618">Linguistic Template Extraction for Recognizing Reader-Emotion Emotional Resonance Writing Assistance</title>
<author confidence="0.993977">Cen-Chieh Yu-Lun Chien Chin Wen-Lian</author>
<affiliation confidence="0.868649666666667">of Information Science, Academia Sinica, Taipei, of Information Management, National Taiwan University, Taipei, of Computer Science, National Chengchi University, Taipei,</affiliation>
<abstract confidence="0.99875416">In this paper, we propose a flexible principle-based approach (PBA) for reader-emotion classification and writing assistance. PBA is a highly automated process that learns emotion templates from raw texts to characterize an emotion and is comprehensible for humans. These templates are adopted to predict reader-emotion, and may further assist in emotional resonance writing. Results demonstrate that PBA can effectively detect reader-emotions by exploiting the syntactic structures and semantic associations in the context, thus outperforming wellknown statistical text classification methods and the state-of-the-art reader-emotion classification method. Moreover, writers are able to create more emotional resonance in articles under the assistance of the generated emotion templates. These templates have been proven to be highly interpretable, which is an attribute that is difficult to accomplish in traditional statistical methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Omar Mabrook A Bashaddadh</author>
<author>Masnizah Mohd</author>
</authors>
<title>Topic detection and tracking interface with named entities approach.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Conference on Semantic Technology and Information Retrieval (STAIR),</booktitle>
<pages>215--219</pages>
<contexts>
<context position="5641" citStr="Bashaddadh and Mohd, 2011" startWordPosition="825" endWordPosition="828"> set of documents of the reader-emotion in the training data; N(E) and N(¬E) denote the numbers of documents that do or do not contain this emotion, respectively; and N(w ∧ E) is the number of documents with emotion E and having w. The probabilities p(w), p(w|E), and p(w|¬E) are estimated using maximum likelihood estimation. A larger LLR value is considered closely associated with an emotion. Words in the training data are ranked by LLR values, and the top 200 are included in our emotion keyword list. Next, named entities (NEs) have been shown to improve the performance of identifying topics (Bashaddadh and Mohd, 2011). Thus, we utilize Wikipedia to semi-automatically label NEs with their semantic classes, which can be considered as a form of generalization. Wikipedia’s category tags are used to label NEs recognized by the Stanford NER1. If there are more than one category tag for an NE, we select the most dominant one with the highest number of associated Wikipedia pages. The assumption is that the generality of a tag is indicated by the number of Wikipedia pages that are linked to it. For example, a query “奥巴马 (Obama)” to the Wikipedia would return a page titled “贝拉克.奥巴马 (Barack Obama)”. Within this page,</context>
</contexts>
<marker>Bashaddadh, Mohd, 2011</marker>
<rawString>Omar Mabrook A Bashaddadh and Masnizah Mohd. 2011. Topic detection and tracking interface with named entities approach. In Proceedings of the International Conference on Semantic Technology and Information Retrieval (STAIR), pages 215–219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent Dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="13071" citStr="Blei et al., 2003" startWordPosition="2038" endWordPosition="2041">hest vote of emotion and others determined by t-test with a 95% confidence level are retained. Finally, 47,285 out of 68,026 articles are kept, and divided into the training set and the test set, each containing 11,681 and 35,604 articles, respectively. 4.2 Reader’s Emotion Classification Several classification methods are implemented and compared. Naive Bayes (McCallum et al., 1998) serves as the baseline, denoted as NB. In addition, a probabilistic graphical model that uses LDA as document representation to train an SVM classifier that determines a document as either relevant or irrelevant (Blei et al., 2003), denotes as LDA. Next, an emotion keyword-based model, denoted as KW, is trained using SVM to test the effect of our keyword extraction approach. CF is the state-of-the-art reader-emotion recognition method that combines various features including bigrams, words, metadata, and emotion category words (Lin et al., 2007). For evaluation, we adopt 2https://tw.news.yahoo.com the accuracy measures as used by Lin et al. (2007), and compute the macro-average (AM) and microaverage (Aµ). Table 1 shows a comprehensive evaluation of PBA and other methods3. Emotion Accuracy(%) NB LDA KW CF PBA angry 47.00</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keh-Jiann Chen</author>
<author>Shu-Ling Huang</author>
<author>Yueh-Yin Shih</author>
<author>Yi-Jun Chen</author>
</authors>
<title>Extended-HowNet - a representational framework for concepts.</title>
<date>2005</date>
<booktitle>In Proceedings of OntoLex 2005 - Ontologies and Lexical Resources IJCNLP-05 Workshop.</booktitle>
<contexts>
<context position="6849" citStr="Chen et al., 2005" startWordPosition="1022" endWordPosition="1025">this page, there are a number of category tags such as “民主党 (Democratic Party)” and “X国总统 1http://nlp.stanford.edu/software/CRF-NER.shtml (Presidents of the United States)”. Suppose “X国总统 (Presidents of the United States)” has more out-going links, we will label “奥巴马 (Obama)” as “[X国总统] (Presidents of the United States)”. We also annotate those NEs not found in Wikipedia with their category tags. In this manner, we can transform plain NEs to a more general class and increase the coverage of each label. Finally, to incorporate richer semantic context, we exploit the Extended HowNet (E-HowNet) (Chen et al., 2005) after the above processes to tag the remaining text with sense labels. Figure 1 illustrates crucial element labeling process. Consider the clause Cn = “奥巴马又代表民主党赢得X国总统选举 (Obama, representing the Democratic Party, won the U.S. Presidential election)”. First, “奥巴马 (Obama)” is found in the emotion keyword list and tagged. Then, NEs like “民主党 (Democratic Party)” and “总统选举 (Presidential election)” are recognized and tagged as “{政党 (Party)}” and “{总统选举 (Presidential election)}”. Subsequently, other terms such as “代表 (represent)” and “赢得 (won)” are labeled with their corresponding E-HowNet senses. F</context>
</contexts>
<marker>Chen, Huang, Shih, Chen, 2005</marker>
<rawString>Keh-Jiann Chen, Shu-Ling Huang, Yueh-Yin Shih, and Yi-Jun Chen. 2005. Extended-HowNet - a representational framework for concepts. In Proceedings of OntoLex 2005 - Ontologies and Lexical Resources IJCNLP-05 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Chen</author>
<author>Sophia Yat Mei Lee</author>
<author>Shoushan Li</author>
<author>Chu-Ren Huang</author>
</authors>
<title>Emotion cause detection with linguistic constructions.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>179--187</pages>
<contexts>
<context position="2141" citStr="Chen et al. (2010)" startWordPosition="288" endWordPosition="291">information. People can easily share experiences and emotions anytime and anywhere on social media websites. Human feelings can be quickly collected through emotion classification, as these emotions reflect an individual’s feelings and experiences toward some subject matters (Turney, 2002; Wilson et al., 2009). Moreover, people can obtain more sponsorship opportunities from manufacturers if their articles about a certain product are able to create more emotional resonance in the readers. Therefore, *Corresponding author emotion classification has been attracting more and more attention, e.g., Chen et al. (2010), Purver and Battersby (2012). Emotion classification aims to predict the emotion categories (e.g., happy or angry) of the given text (Quan and Ren, 2009; Das and Bandyopadhyay, 2009). There are two aspects of emotions in texts, namely, writer’s and reader’s emotions. The former concerns the emotion expressed by the writer of the text, and the latter concerns the emotion a reader had after reading it. Recognizing reader-emotion is different and may be even more complex than writer-emotion (Lin et al., 2008; Tang and Chen, 2012). A writer may directly express her emotions through sentiment word</context>
</contexts>
<marker>Chen, Lee, Li, Huang, 2010</marker>
<rawString>Ying Chen, Sophia Yat Mei Lee, Shoushan Li, and Chu-Ren Huang. 2010. Emotion cause detection with linguistic constructions. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 179–187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipankar Das</author>
<author>Sivaji Bandyopadhyay</author>
</authors>
<title>Word to sentence level emotion tagging for bengali blogs.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Conference,</booktitle>
<pages>149--152</pages>
<contexts>
<context position="2324" citStr="Das and Bandyopadhyay, 2009" startWordPosition="317" endWordPosition="321">cation, as these emotions reflect an individual’s feelings and experiences toward some subject matters (Turney, 2002; Wilson et al., 2009). Moreover, people can obtain more sponsorship opportunities from manufacturers if their articles about a certain product are able to create more emotional resonance in the readers. Therefore, *Corresponding author emotion classification has been attracting more and more attention, e.g., Chen et al. (2010), Purver and Battersby (2012). Emotion classification aims to predict the emotion categories (e.g., happy or angry) of the given text (Quan and Ren, 2009; Das and Bandyopadhyay, 2009). There are two aspects of emotions in texts, namely, writer’s and reader’s emotions. The former concerns the emotion expressed by the writer of the text, and the latter concerns the emotion a reader had after reading it. Recognizing reader-emotion is different and may be even more complex than writer-emotion (Lin et al., 2008; Tang and Chen, 2012). A writer may directly express her emotions through sentiment words. By contrast, reader-emotion possesses a more perplexing nature, as even common words can invoke different types of reader-emotions depending on the reader’s personal experiences an</context>
</contexts>
<marker>Das, Bandyopadhyay, 2009</marker>
<rawString>Dipankar Das and Sivaji Bandyopadhyay. 2009. Word to sentence level emotion tagging for bengali blogs. In Proceedings of the ACL-IJCNLP 2009 Conference, pages 149–152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David S Johnson</author>
</authors>
<title>Approximation algorithms for combinatorial problems.</title>
<date>1974</date>
<journal>Journal of Computer and System Sciences, 9(3):256 –</journal>
<pages>278</pages>
<contexts>
<context position="8143" citStr="Johnson, 1974" startWordPosition="1218" endWordPosition="1219">ma] : {represents} : {party} : {got} : {country} : {Presidential election}).” This three-layered labeling process serves as a generalization of the raw text for capturing crucial elements used in the template generation stage that follows. The emotion template generation process aims at automatically constructing representative templates consisting of a sequence of crucial elements. We observed that the rank-frequency distribution of the elements follows the Zipf’s law (Manning and Sch¨utze, 1999). Thus, we rank the templates according to their frequency, and adopt a dominating set algorithm (Johnson, 1974) to use the top 20% templates to cover the rest. First, we constructed a directed graph G = {V, E}, in which vertices V contains all crucial element sequences {CES1, · · · , CESm} in each emotion, and edges E represent the dominating relations between sequences. If CESx dominates CESy, there is an edge CESx → CESy. A 776 A clause Cn in an article: Obama, representing the Democratic Party, won the U.S. Presidential election again sequence of crucial elements Figure 1: Crucial element labeling process. ����������������� �������������� Rft�K �{��represen t} {��} Party �� { get }��} { country { Pr</context>
</contexts>
<marker>Johnson, 1974</marker>
<rawString>David S. Johnson. 1974. Approximation algorithms for combinatorial problems. Journal of Computer and System Sciences, 9(3):256 – 278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rensis Likert</author>
</authors>
<title>A technique for the measurement of attitudes.</title>
<date>1932</date>
<journal>Archives of Psychology,</journal>
<pages>140--1</pages>
<contexts>
<context position="17310" citStr="Likert, 1932" startWordPosition="2703" endWordPosition="2704">otions are selected, resulting in 30 and 40 templates for the two coarse-grained emotions, respectively. We recruited seven writers to compose two articles that they think will trigger positive and negative emotions without using templates (denoted as NT). Then, we asked them to compose two more articles with the aid of templates (denoted as WT). Afterwards, all articles are randomly organized into a questionnaire to test the emotional resonance. Subjects are required to perform two tasks: 1) answer ‘positive’, ‘neutral’, or ‘negative’ 2) give a score according to the five-point Likert scale (Likert, 1932) for a given emotion. In the end, 42 effective responses are gathered. For Task 1, the score is defined as the number of matching responses and answers. As for Task 2, the score is the sum of all articles. Higher scores indicate better emotional resonance between writers and readers. Figure 2 shows the sum of scores in Task 1 from all subjects, grouped by writer. As for Task 2, Figure 3 shows the average score across subjects, grouped by writers. In both tasks, we can see that higher scores are obtained after using templates, indicating that emotion templates can indeed assist writers in creat</context>
</contexts>
<marker>Likert, 1932</marker>
<rawString>Rensis Likert. 1932. A technique for the measurement of attitudes. Archives of Psychology, 140:1–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Hsin-Yih Lin</author>
<author>Changhua Yang</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>What emotions do news articles trigger in their readers?</title>
<date>2007</date>
<booktitle>In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>733--734</pages>
<contexts>
<context position="2954" citStr="Lin et al., 2007" startWordPosition="417" endWordPosition="420">wo aspects of emotions in texts, namely, writer’s and reader’s emotions. The former concerns the emotion expressed by the writer of the text, and the latter concerns the emotion a reader had after reading it. Recognizing reader-emotion is different and may be even more complex than writer-emotion (Lin et al., 2008; Tang and Chen, 2012). A writer may directly express her emotions through sentiment words. By contrast, reader-emotion possesses a more perplexing nature, as even common words can invoke different types of reader-emotions depending on the reader’s personal experiences and knowledge (Lin et al., 2007). For instance, a sentence like “Kenya survivors describe deadly attack at Garissa University” is simply stating the facts without any emotion, but may invoke emotions such as angry or worried in its readers. In light of this rationale, we propose a principlebased approach (PBA) for reader-emotion classification. It is a highly automated process that integrates various types of knowledge to generate discriminative linguistic templates that can be acknowledged as the essential knowledge for humans to understand different kinds of emotions. PBA recognizes reader-emotions of documents using an al</context>
<context position="12222" citStr="Lin et al. (2007)" startWordPosition="1903" endWordPosition="1906">ong categories. And the deletion score (DS), defined as (5), is computed from the log frequency of this crucial element in this emotion category. A(etn, cem) �= k � l 777 P(celci) · log2(P(celci)) DS(cel) = log fcel m � i=1 4 Experiments 4.1 Dataset and Setting We collected a corpus of Chinese news articles from Yahoo! Kimo News2, in which each article is given votes from readers with emotion tags in eight categories: angry, worried, boring, happy, odd, depressing, warm, and informative. We consider the voted emotions as the reader’s emotion toward the news. Following previous studies such as Lin et al. (2007) and Lin et al. (2008) that used a similar source, we exclude “informative” as it is not considered as an emotion category. To ensure the quality of our evaluation, only articles with a clear statistical distinction between the highest vote of emotion and others determined by t-test with a 95% confidence level are retained. Finally, 47,285 out of 68,026 articles are kept, and divided into the training set and the test set, each containing 11,681 and 35,604 articles, respectively. 4.2 Reader’s Emotion Classification Several classification methods are implemented and compared. Naive Bayes (McCal</context>
<context position="13495" citStr="Lin et al. (2007)" startWordPosition="2101" endWordPosition="2104"> In addition, a probabilistic graphical model that uses LDA as document representation to train an SVM classifier that determines a document as either relevant or irrelevant (Blei et al., 2003), denotes as LDA. Next, an emotion keyword-based model, denoted as KW, is trained using SVM to test the effect of our keyword extraction approach. CF is the state-of-the-art reader-emotion recognition method that combines various features including bigrams, words, metadata, and emotion category words (Lin et al., 2007). For evaluation, we adopt 2https://tw.news.yahoo.com the accuracy measures as used by Lin et al. (2007), and compute the macro-average (AM) and microaverage (Aµ). Table 1 shows a comprehensive evaluation of PBA and other methods3. Emotion Accuracy(%) NB LDA KW CF PBA angry 47.00 74.21 79.21 83.71 87.83 worried 69.56 92.83 81.96 87.50 75.80 boring 75.67 76.21 84.34 87.52 90.52 happy 37.90 67.59 80.97 86.27 88.94 odd 73.90 85.40 77.05 84.25 83.34 depressing 73.76 81.43 85.00 87.70 92.15 warm 75.09 87.09 79.59 85.83 91.91 AM 58.11 76.10 80.36 85.80 86.43 Aµ 52.78 74.16 80.81 85.70 88.56 Table 1: Comparison of the accuracies of five reader-emotion classification systems. Since NB only considers sur</context>
</contexts>
<marker>Lin, Yang, Chen, 2007</marker>
<rawString>Kevin Hsin-Yih Lin, Changhua Yang, and Hsin-Hsi Chen. 2007. What emotions do news articles trigger in their readers? In Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 733–734.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Hsin-Yih Lin</author>
<author>Changhua Yang</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Emotion classification of online news articles from the reader’s perspective.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology,</booktitle>
<volume>1</volume>
<pages>220--226</pages>
<contexts>
<context position="2652" citStr="Lin et al., 2008" startWordPosition="372" endWordPosition="375">nding author emotion classification has been attracting more and more attention, e.g., Chen et al. (2010), Purver and Battersby (2012). Emotion classification aims to predict the emotion categories (e.g., happy or angry) of the given text (Quan and Ren, 2009; Das and Bandyopadhyay, 2009). There are two aspects of emotions in texts, namely, writer’s and reader’s emotions. The former concerns the emotion expressed by the writer of the text, and the latter concerns the emotion a reader had after reading it. Recognizing reader-emotion is different and may be even more complex than writer-emotion (Lin et al., 2008; Tang and Chen, 2012). A writer may directly express her emotions through sentiment words. By contrast, reader-emotion possesses a more perplexing nature, as even common words can invoke different types of reader-emotions depending on the reader’s personal experiences and knowledge (Lin et al., 2007). For instance, a sentence like “Kenya survivors describe deadly attack at Garissa University” is simply stating the facts without any emotion, but may invoke emotions such as angry or worried in its readers. In light of this rationale, we propose a principlebased approach (PBA) for reader-emotion</context>
<context position="12244" citStr="Lin et al. (2008)" startWordPosition="1908" endWordPosition="1911">e deletion score (DS), defined as (5), is computed from the log frequency of this crucial element in this emotion category. A(etn, cem) �= k � l 777 P(celci) · log2(P(celci)) DS(cel) = log fcel m � i=1 4 Experiments 4.1 Dataset and Setting We collected a corpus of Chinese news articles from Yahoo! Kimo News2, in which each article is given votes from readers with emotion tags in eight categories: angry, worried, boring, happy, odd, depressing, warm, and informative. We consider the voted emotions as the reader’s emotion toward the news. Following previous studies such as Lin et al. (2007) and Lin et al. (2008) that used a similar source, we exclude “informative” as it is not considered as an emotion category. To ensure the quality of our evaluation, only articles with a clear statistical distinction between the highest vote of emotion and others determined by t-test with a 95% confidence level are retained. Finally, 47,285 out of 68,026 articles are kept, and divided into the training set and the test set, each containing 11,681 and 35,604 articles, respectively. 4.2 Reader’s Emotion Classification Several classification methods are implemented and compared. Naive Bayes (McCallum et al., 1998) serv</context>
</contexts>
<marker>Lin, Yang, Chen, 2008</marker>
<rawString>Kevin Hsin-Yih Lin, Changhua Yang, and Hsin-Hsi Chen. 2008. Emotion classification of online news articles from the reader’s perspective. In Proceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology, volume 1, pages 220–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Foundations of statistical natural language processing.</title>
<date>1999</date>
<publisher>MIT press.</publisher>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>Christopher D Manning and Hinrich Sch¨utze. 1999. Foundations of statistical natural language processing. MIT press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Kamal Nigam</author>
</authors>
<title>A comparison of event models for naive bayes text classification.</title>
<date>1998</date>
<booktitle>In AAAI-98 workshop on learning for text categorization,</booktitle>
<volume>752</volume>
<pages>41--48</pages>
<marker>McCallum, Nigam, 1998</marker>
<rawString>Andrew McCallum, Kamal Nigam, et al. 1998. A comparison of event models for naive bayes text classification. In AAAI-98 workshop on learning for text categorization, volume 752, pages 41–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saul B Needleman</author>
<author>Christian D Wunsch</author>
</authors>
<title>A general method applicable to the search for similarities in the amino acid sequence of two proteins.</title>
<date>1970</date>
<journal>Journal of Molecular Biology,</journal>
<volume>48</volume>
<issue>3</issue>
<contexts>
<context position="10198" citStr="Needleman and Wunsch, 1970" startWordPosition="1547" endWordPosition="1551">ess serves as a kind of dimension reduction and facilitates the execution of our matching algorithm. 3 Template Matching for Inference We believe that human perception of an emotion is through recognizing important events or semantic contents. For instance, when an article contains strongly correlated words such as “Japan (country)”, “Earthquake (disaster)”, and “Tsunami (disaster)” simultaneously, it is natural to conclude that this article is more likely to elicit emotions like depressed and worried rather than happy and warm. Following this line of thought, PBA uses an alignment algorithm (Needleman and Wunsch, 1970) to measure the similarity between templates and texts. It enables a single template to match multiple semantically related expressions with appropriate scores. For each clause in a document dj, we first label crucial elements CE = {ce1, · · · , cen}, followed by the matching procedure that compares all sequences in CE from dj to all emotion templates ET = {et1, · · · , etj} in each emotion category, and calculates the scores. Within the alignment matching, a statistical based scoring criterion is used to score insertions, deletions, and substitutions as described below. The emotion ei with th</context>
</contexts>
<marker>Needleman, Wunsch, 1970</marker>
<rawString>Saul B Needleman and Christian D Wunsch. 1970. A general method applicable to the search for similarities in the amino acid sequence of two proteins. Journal of Molecular Biology, 48(3):443–453.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Purver</author>
<author>Stuart Battersby</author>
</authors>
<title>Experimenting with distant supervision for emotion classification.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>482--491</pages>
<contexts>
<context position="2170" citStr="Purver and Battersby (2012)" startWordPosition="292" endWordPosition="295">can easily share experiences and emotions anytime and anywhere on social media websites. Human feelings can be quickly collected through emotion classification, as these emotions reflect an individual’s feelings and experiences toward some subject matters (Turney, 2002; Wilson et al., 2009). Moreover, people can obtain more sponsorship opportunities from manufacturers if their articles about a certain product are able to create more emotional resonance in the readers. Therefore, *Corresponding author emotion classification has been attracting more and more attention, e.g., Chen et al. (2010), Purver and Battersby (2012). Emotion classification aims to predict the emotion categories (e.g., happy or angry) of the given text (Quan and Ren, 2009; Das and Bandyopadhyay, 2009). There are two aspects of emotions in texts, namely, writer’s and reader’s emotions. The former concerns the emotion expressed by the writer of the text, and the latter concerns the emotion a reader had after reading it. Recognizing reader-emotion is different and may be even more complex than writer-emotion (Lin et al., 2008; Tang and Chen, 2012). A writer may directly express her emotions through sentiment words. By contrast, reader-emotio</context>
</contexts>
<marker>Purver, Battersby, 2012</marker>
<rawString>Matthew Purver and Stuart Battersby. 2012. Experimenting with distant supervision for emotion classification. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 482–491.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Changqin Quan</author>
<author>Fuji Ren</author>
</authors>
<title>Construction of a blog emotion corpus for chinese emotional expression analysis.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<volume>3</volume>
<pages>1446--1454</pages>
<contexts>
<context position="2294" citStr="Quan and Ren, 2009" startWordPosition="313" endWordPosition="316">ugh emotion classification, as these emotions reflect an individual’s feelings and experiences toward some subject matters (Turney, 2002; Wilson et al., 2009). Moreover, people can obtain more sponsorship opportunities from manufacturers if their articles about a certain product are able to create more emotional resonance in the readers. Therefore, *Corresponding author emotion classification has been attracting more and more attention, e.g., Chen et al. (2010), Purver and Battersby (2012). Emotion classification aims to predict the emotion categories (e.g., happy or angry) of the given text (Quan and Ren, 2009; Das and Bandyopadhyay, 2009). There are two aspects of emotions in texts, namely, writer’s and reader’s emotions. The former concerns the emotion expressed by the writer of the text, and the latter concerns the emotion a reader had after reading it. Recognizing reader-emotion is different and may be even more complex than writer-emotion (Lin et al., 2008; Tang and Chen, 2012). A writer may directly express her emotions through sentiment words. By contrast, reader-emotion possesses a more perplexing nature, as even common words can invoke different types of reader-emotions depending on the re</context>
</contexts>
<marker>Quan, Ren, 2009</marker>
<rawString>Changqin Quan and Fuji Ren. 2009. Construction of a blog emotion corpus for chinese emotional expression analysis. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, volume 3, pages 1446–1454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi-jie Tang</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Mining sentiment words from microblogs for predicting writerreader emotion transition.</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>1226--1229</pages>
<contexts>
<context position="2674" citStr="Tang and Chen, 2012" startWordPosition="376" endWordPosition="379">on classification has been attracting more and more attention, e.g., Chen et al. (2010), Purver and Battersby (2012). Emotion classification aims to predict the emotion categories (e.g., happy or angry) of the given text (Quan and Ren, 2009; Das and Bandyopadhyay, 2009). There are two aspects of emotions in texts, namely, writer’s and reader’s emotions. The former concerns the emotion expressed by the writer of the text, and the latter concerns the emotion a reader had after reading it. Recognizing reader-emotion is different and may be even more complex than writer-emotion (Lin et al., 2008; Tang and Chen, 2012). A writer may directly express her emotions through sentiment words. By contrast, reader-emotion possesses a more perplexing nature, as even common words can invoke different types of reader-emotions depending on the reader’s personal experiences and knowledge (Lin et al., 2007). For instance, a sentence like “Kenya survivors describe deadly attack at Garissa University” is simply stating the facts without any emotion, but may invoke emotions such as angry or worried in its readers. In light of this rationale, we propose a principlebased approach (PBA) for reader-emotion classification. It is</context>
</contexts>
<marker>Tang, Chen, 2012</marker>
<rawString>Yi-jie Tang and Hsin-Hsi Chen. 2012. Mining sentiment words from microblogs for predicting writerreader emotion transition. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC), pages 1226–1229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>417--424</pages>
<contexts>
<context position="1812" citStr="Turney, 2002" startWordPosition="243" endWordPosition="244">ional resonance in articles under the assistance of the generated emotion templates. These templates have been proven to be highly interpretable, which is an attribute that is difficult to accomplish in traditional statistical methods. 1 Introduction The Internet has rapidly grown into a powerful medium for disseminating information. People can easily share experiences and emotions anytime and anywhere on social media websites. Human feelings can be quickly collected through emotion classification, as these emotions reflect an individual’s feelings and experiences toward some subject matters (Turney, 2002; Wilson et al., 2009). Moreover, people can obtain more sponsorship opportunities from manufacturers if their articles about a certain product are able to create more emotional resonance in the readers. Therefore, *Corresponding author emotion classification has been attracting more and more attention, e.g., Chen et al. (2010), Purver and Battersby (2012). Emotion classification aims to predict the emotion categories (e.g., happy or angry) of the given text (Quan and Ren, 2009; Das and Bandyopadhyay, 2009). There are two aspects of emotions in texts, namely, writer’s and reader’s emotions. Th</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D Turney. 2002. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 417–424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity: An exploration of features for phrase-level sentiment analysis.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>3</issue>
<contexts>
<context position="1834" citStr="Wilson et al., 2009" startWordPosition="245" endWordPosition="248">e in articles under the assistance of the generated emotion templates. These templates have been proven to be highly interpretable, which is an attribute that is difficult to accomplish in traditional statistical methods. 1 Introduction The Internet has rapidly grown into a powerful medium for disseminating information. People can easily share experiences and emotions anytime and anywhere on social media websites. Human feelings can be quickly collected through emotion classification, as these emotions reflect an individual’s feelings and experiences toward some subject matters (Turney, 2002; Wilson et al., 2009). Moreover, people can obtain more sponsorship opportunities from manufacturers if their articles about a certain product are able to create more emotional resonance in the readers. Therefore, *Corresponding author emotion classification has been attracting more and more attention, e.g., Chen et al. (2010), Purver and Battersby (2012). Emotion classification aims to predict the emotion categories (e.g., happy or angry) of the given text (Quan and Ren, 2009; Das and Bandyopadhyay, 2009). There are two aspects of emotions in texts, namely, writer’s and reader’s emotions. The former concerns the </context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2009</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2009. Recognizing contextual polarity: An exploration of features for phrase-level sentiment analysis. Computational Linguistics, 35(3):399–433.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feng Zou</author>
<author>Fu Lee Wang</author>
<author>Xiaotie Deng</author>
<author>Song Han</author>
<author>Lu Sheng Wang</author>
</authors>
<title>Automatic construction of chinese stop word list.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th WSEAS International Conference on Applied Computer Science,</booktitle>
<pages>1010--1015</pages>
<contexts>
<context position="15566" citStr="Zou et al., 2006" startWordPosition="2427" endWordPosition="2430">ces are sports-related, and a sports-related article has a 31% chance of having the emotion tag “happy”. Hence, the high accuracy of the emotion category “happy” could be the result of people’s general enthusiasm over sports rather than a particular event. On top of that, PBA can generate distinctive emotion templates to capture variations of similar expressions, thus achieving better outcome.. For instance, the template “{国家 country}” : [At occur] : [地震 earthquake] : {劫难 disaster}” is generated by PBA 3The dictionary required by all methods is constructed by removing stop words according to (Zou et al., 2006), and retaining tokens that make up 90% of the accumulated frequency. As for unseen events, we used the Laplace smoothing in NB. LDA is implemented using a toolkit (http://nlp.stanford.edu/software/tmt/tmt-0.4/). LLRcel, if cel ∈ keyword λ fcel �m i=1 { 1 (4) IS(cel) = m MS(cel) = , otherwise (3) fcei − � i=1 (5) fcei 778 for the emotion “worried”. It is perceivable that this template is relaying information about disastrous earthquakes in a country, and such news often makes readers worry. The ability to yield such emotion-specific, human interpretable templates could account for the outstand</context>
</contexts>
<marker>Zou, Wang, Deng, Han, Wang, 2006</marker>
<rawString>Feng Zou, Fu Lee Wang, Xiaotie Deng, Song Han, and Lu Sheng Wang. 2006. Automatic construction of chinese stop word list. In Proceedings of the 5th WSEAS International Conference on Applied Computer Science, pages 1010–1015.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>