<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008754">
<title confidence="0.993701">
Maximum Entropy Models for Named Entity Recognition
</title>
<author confidence="0.981135">
Oliver Bender and Franz Josef Och and Hermann Ney
</author>
<affiliation confidence="0.972387">
Lehrstuhl f¨ur Informatik VI Information Sciences Institute
Computer Science Department University of Southern California
RWTH Aachen - University of Technology Marina del Rey, CA 90292
</affiliation>
<address confidence="0.583198">
D-52056 Aachen, Germany och@isi.edu
</address>
<email confidence="0.995376">
bender,ney @cs.rwth-aachen.de
</email>
<sectionHeader confidence="0.995579" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999936545454545">
In this paper, we describe a system that applies
maximum entropy (ME) models to the task of
named entity recognition (NER). Starting with
an annotated corpus and a set of features which
are easily obtainable for almost any language,
we first build a baseline NE recognizer which
is then used to extract the named entities and
their context information from additional non-
annotated data. In turn, these lists are incor-
porated into the final recognizer to further im-
prove the recognition accuracy.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999196888888889">
In this paper, we present an approach for extracting the
named entities (NE) of natural language inputs which
uses the maximum entropy (ME) framework (Berger et
al., 1996). The objective can be described as follows.
Given a natural input sequence we
choose the NE tag sequence with the
highest probability among all possible tag sequences:
system described avoids relying on language-dependent
knowledge but instead uses a set of features which are
easily obtainable for almost any language.
The remainder of the paper is organized as follows: in
section 2, we outline the ME framework and specify the
features that were used for the experiments. We describe
the training and search procedure of our approach. Sec-
tion 3 presents experimental details and shows results ob-
tained on the English and German test sets. Finally, sec-
tion 4 closes with a summary and an outlook for future
work.
</bodyText>
<sectionHeader confidence="0.963684" genericHeader="method">
2 Maximum Entropy Models
</sectionHeader>
<bodyText confidence="0.972040666666667">
For our approach, we directly factorize the posterior
probability and determine the corresponding NE tag
for each word of an input sequence. We assume that
the decisions only depend on a limited window of
around the current word and
on the two predecessor tags. Thus, we obtain the follow-
ing second-order model:
The argmax operation denotes the search problem, i.e.
the generation of the sequence of named entities. Ac-
cording to the CoNLL-2003 competition, we concentrate
on four types of named entities: persons (PER), locations
(LOC), organizations (ORG), and names of miscellaneous
entities (MISC) that do not belong to the previous three
groups, e.g.
[PER Clinton] ’s [ORG Ballybunion] fans in-
vited to [LOC Chicago] .
Additionally, the task requires the processing of two
different languages from which only English was spec-
ified before the submission deadline. Therefore, the
A well-founded framework for directly modeling the
posterior probability is maximum en-
tropy (Berger et al., 1996). In this framework, we have
a set of feature functions
. For each feature function , there exists a
model parameter . The posterior probability can then
be modeled as follows:
m
</bodyText>
<subsectionHeader confidence="0.816094">
Tag Sequence
</subsectionHeader>
<figureCaption confidence="0.99934525">
Figure 1: Architecture of the maximum entropy model
approach.
The architecture of the ME approach is summarized in
Figure 1.
</figureCaption>
<bodyText confidence="0.9999736">
As for the CoNLL-2003 shared task, the data sets often
provide additional information like part-of-speech (POS)
tags. In order to take advantage of these knowledge
sources, our system is able to process several input se-
quences at the same time.
</bodyText>
<subsectionHeader confidence="0.992625">
2.1 Feature Functions
</subsectionHeader>
<bodyText confidence="0.946429117647059">
We have implemented a set of binary valued feature func-
tions for our system:
Lexical features: The words are compared to a
vocabulary. Words which are seen less than twice in the
training data are mapped onto an ’unknown word’. For-
mally, the feature
will fire if the word matches the vocabulary entry
and if the prediction for the current NE tag equals .
denotes the Kronecker-function.
Word features: Word characteristics are covered by
the word features, which test for:
- Capitalization: These features will fire if is cap-
italized, has an internal capital letter, or is fully cap-
italized.
- Digits and numbers: ASCII digit strings and number
expressions activate these features.
- Pre- and suffixes: If the prefix (suffix) of equals
a given prefix (suffix), these features will fire.
Transition features: Transition features model the de-
pendence on the two predecessor tags:
Prior features: The single named entity priors are in-
corporated by prior features. They just fire for the cur-
rently observed NE tag:
Compound features: Using the feature functions de-
fined so far, we can only specify features that refer to
a single word or tag. To enable also word phrases and
word/tag combinations, we introduce the following com-
pound features:
Dictionary features: Given a list of named entities,
the dictionary features check whether or not an entry of
occurs within the current window. Formally,
Respectively, the dictionary features fire if an entry of
a context list appears beside or around the current word
position .
</bodyText>
<subsectionHeader confidence="0.996655">
2.2 Feature Selection
</subsectionHeader>
<bodyText confidence="0.999824384615384">
Feature selection plays a crucial role in the ME frame-
work. In our system, we use simple count-based feature
reduction. Given a threshold , we only include those
features that have been observed on the training data at
least times. Although this method does not guarantee
to obtain a minimal set of features, it turned out to per-
form well in practice.
Experiments were carried out with different thresholds.
It turned out that for the NER task, a threshold of for the
English data and for the German corpus achieved the
best results for all features, except for the prefix and suffix
features, for which a threshold of ( resp.) yielded best
results.
</bodyText>
<figure confidence="0.986050222222222">
Input Sequence
✁
Preprocessing
Global Search
Postprocessing
exp
exp
entryOccurs
(1)
</figure>
<subsectionHeader confidence="0.967189">
2.3 Training
</subsectionHeader>
<bodyText confidence="0.996210181818182">
For training purposes, we consider the set of manually an-
notated and segmented training sentences to form a single
long sentence. As training criterion, we use the maximum
class posterior probability criterion:
This corresponds to maximizing the likelihood of the ME
model. Since the optimization criterion is convex, there is
only a single optimum and no convergence problems oc-
cur. To train the model parameters we use the Gen-
eralized Iterative Scaling (GIS) algorithm (Darroch and
Ratcliff, 1972).
In practice, the training procedure tends to result in an
overfitted model. To avoid overfitting, (Chen and Rosen-
feld, 1999) have suggested a smoothing method where a
Gaussian prior on the parameters is assumed. Instead of
maximizing the probability of the training data, we now
maximize the probability of the training data times the
prior probability of the model parameters:
where
This method tries to avoid very large lambda values and
avoids that features that occur only once for a specific
class get value infinity. Note that there is only one pa-
rameter for all model parameters .
</bodyText>
<subsectionHeader confidence="0.994848">
2.4 Search
</subsectionHeader>
<bodyText confidence="0.995458125">
In the test phase, the search is performed using the so-
called maximum approximation, i.e. the most likely se-
quence of named entities is chosen among all possible
sequences :
Therefore, the time-consuming renormalization in Eq. 1
is not needed during search. We run a Viterbi search to
find the highest probability sequence (Borthwick et al.,
1998).
</bodyText>
<sectionHeader confidence="0.999231" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.9999709">
Experiments were performed on English and German test
sets. The English data was derived from the Reuters cor-
pus&apos; while the German test sets were extracted from the
ECI Multilingual Text corpus. The data sets contain to-
kens (words and punctuation marks), information about
the sentence boundaries, as well as the assigned NE tags.
Additionally, a POS tag and a syntactic chunk tag were
assigned to each token. On the tag level, we distinguish
five tags (the four NE tags mentioned above and a filler
tag).
</bodyText>
<subsectionHeader confidence="0.9942205">
3.1 Incorporating Lists of Names and
Non-annotated Data
</subsectionHeader>
<bodyText confidence="0.99294">
For the English task, extra lists of names were provided,
and for both languages, additional non-annotated data
was supplied. Hence, the challenge was to find ways of
incorporating this information. Our system aims at this
challenge via the use of dictionary features.
While the provided lists could straightforward be inte-
grated, the raw data was processed in three stages:
</bodyText>
<listItem confidence="0.997048666666667">
1. Given the annotated training data, we used all fea-
tures except the dictionary ones to build a first base-
line NE recognizer.
2. Applying this recognizer, the non-annotated data
was processed and all named entities plus contexts
(up to three words beside the classified NE and the
two surrounding words) were extracted and stored
as additional lists.
3. These lists could again be integrated straightfor-
ward. It turned out that a threshold of five yielded
best results for both the lists of named entities as
well as for the context information.
</listItem>
<subsectionHeader confidence="0.939319">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.8351295">
Table 1 and Table 2 present the results obtained on the
development and test sets. For both languages, 1000 GIS
iterations were performed and the Gaussian prior method
was applied.
</bodyText>
<table confidence="0.9910384">
Test Set Precision Recall F
English devel. 90.01% 88.52% 89.26
English test 84.45% 82.90% 83.67
German devel. 73.60% 57.73% 64.70
German test 76.12% 60.74% 67.57
</table>
<tableCaption confidence="0.735596">
Table 1: Overall performance of the baseline system on
the development and test sets in English and German.
&apos;The Reuters corpus was kindly provided by Reuters Lim-
ited.
</tableCaption>
<figure confidence="0.690674666666667">
smoothed
no smoothing
86
</figure>
<figureCaption confidence="0.991158">
Figure 2: Results of the baseline system for different
smoothing parameters.
</figureCaption>
<bodyText confidence="0.999884">
As can be derived from table 1, our baseline recog-
nizer clearly outperforms the CoNLL-2003 baseline (e.g.
vs. ). To investigate the
contribution of the Gaussian prior method, several exper-
iments were carried out for different standard deviation
parameters. Figure 2 depicts the obtained F-Measures
in comparison to the performance of non-smoothed ME
models ( ). The gain in performance is ob-
vious.
By incorporating the information extracted from the
non-annotated data our system is further improved. On
the German data, the results show a performance degra-
dation. The main reason for this is due to the capitaliza-
tion of German nouns. Therefore, refined lists of proper
names are necessary.
</bodyText>
<sectionHeader confidence="0.999164" genericHeader="method">
4 Summary
</sectionHeader>
<bodyText confidence="0.999916307692308">
In conclusion, we have presented a system for the task of
named entity recognition that uses the maximum entropy
framework. We have shown that a baseline system based
on an annotated training set can be improved by incorpo-
rating additional non-annotated data.
For future investigations, we have to think about a
more sophisticated treatment of the additional informa-
tion. One promising possibility could be to extend our
system as follows: apply the baseline recognizer to an-
notate the raw data as before, but then use the output to
train a new recognizer. The scores of the new system are
incorporated as further features and the procedure is iter-
ated until convergence.
</bodyText>
<sectionHeader confidence="0.99752" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.919807">
A. L. Berger, S. A. Della Pietra, and V. J. Della
Pietra. 1996. A maximum entropy approach to nat-
ural language processing. Computational Linguistics,
22(1):39–72, March.
</reference>
<table confidence="0.997168541666667">
English devel. Precision Recall F
LOC 93.27% 93.58% 93.42
MISC 88.51% 81.02% 84.60
ORG 84.67% 83.59% 84.13
PER 92.26% 91.91% 92.09
Overall 90.32% 88.86% 89.58
English test Precision Recall F
LOC 86.44% 89.81% 88.09
MISC 78.35% 73.22% 75.70
ORG 80.27% 76.16% 78.16
PER 89.77% 87.88% 88.81
Overall 84.68% 83.18% 83.92
German devel. Precision Recall F
LOC 72.23% 71.13% 71.67
MISC 66.08% 44.95% 53.51
ORG 71.90% 56.49% 63.27
PER 82.77% 68.59% 75.02
Overall 74.16% 61.16% 67.04
German test Precision Recall F
LOC 69.06% 69.66% 69.36
MISC 66.52% 46.27% 54.58
ORG 68.84% 53.17% 60.00
PER 87.91% 75.48% 81.22
Overall 74.82% 63.82% 68.88
</table>
<tableCaption confidence="0.8171325">
Table 2: Results of the final system on the development
and test sets in English and German.
</tableCaption>
<reference confidence="0.853293846153846">
A. Borthwick, J. Sterling, E. Agichtein, and R. Gr-
isham. 1998. NYU: Description of the MENE
named entity system as used in MUC-7. In Pro-
ceedings of the Seventh Message Understanding
Conference (MUC-7), 6 pages, Fairfax, VA, April.
http://www.itl.nist.gov/iaui/894.02/related projects/muc/.
S. Chen and R. Rosenfeld. 1999. A gaussian prior
for smoothing maximum entropy models. Technical
Report CMUCS-99-108, Carnegie Mellon University,
Pittsburgh, PA.
J. N. Darroch and D. Ratcliff. 1972. Generalized iter-
ative scaling for log-linear models. Annals of Mathe-
matical Statistics, 43:1470–1480.
</reference>
<figure confidence="0.9939792">
P-Measure VA] 89
88
87
0 2 4 6 8 10
standard deviation
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.920502">
<title confidence="0.999817">Maximum Entropy Models for Named Entity Recognition</title>
<author confidence="0.999092">Bender Josef Och Ney</author>
<affiliation confidence="0.9898165">Lehrstuhl f¨ur Informatik VI Information Sciences Institute Computer Science Department University of Southern California</affiliation>
<address confidence="0.998328">RWTH Aachen - University of Technology Marina del Rey, CA 90292 Aachen, Germany</address>
<email confidence="0.956488">bender,ney@cs.rwth-aachen.de</email>
<abstract confidence="0.9986285">In this paper, we describe a system that applies maximum entropy (ME) models to the task of named entity recognition (NER). Starting with an annotated corpus and a set of features which are easily obtainable for almost any language, we first build a baseline NE recognizer which is then used to extract the named entities and their context information from additional nonannotated data. In turn, these lists are incorporated into the final recognizer to further improve the recognition accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A L Berger</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="1045" citStr="Berger et al., 1996" startWordPosition="156" endWordPosition="159">py (ME) models to the task of named entity recognition (NER). Starting with an annotated corpus and a set of features which are easily obtainable for almost any language, we first build a baseline NE recognizer which is then used to extract the named entities and their context information from additional nonannotated data. In turn, these lists are incorporated into the final recognizer to further improve the recognition accuracy. 1 Introduction In this paper, we present an approach for extracting the named entities (NE) of natural language inputs which uses the maximum entropy (ME) framework (Berger et al., 1996). The objective can be described as follows. Given a natural input sequence we choose the NE tag sequence with the highest probability among all possible tag sequences: system described avoids relying on language-dependent knowledge but instead uses a set of features which are easily obtainable for almost any language. The remainder of the paper is organized as follows: in section 2, we outline the ME framework and specify the features that were used for the experiments. We describe the training and search procedure of our approach. Section 3 presents experimental details and shows results obt</context>
<context position="2780" citStr="Berger et al., 1996" startWordPosition="434" endWordPosition="437">ration of the sequence of named entities. According to the CoNLL-2003 competition, we concentrate on four types of named entities: persons (PER), locations (LOC), organizations (ORG), and names of miscellaneous entities (MISC) that do not belong to the previous three groups, e.g. [PER Clinton] ’s [ORG Ballybunion] fans invited to [LOC Chicago] . Additionally, the task requires the processing of two different languages from which only English was specified before the submission deadline. Therefore, the A well-founded framework for directly modeling the posterior probability is maximum entropy (Berger et al., 1996). In this framework, we have a set of feature functions . For each feature function , there exists a model parameter . The posterior probability can then be modeled as follows: m Tag Sequence Figure 1: Architecture of the maximum entropy model approach. The architecture of the ME approach is summarized in Figure 1. As for the CoNLL-2003 shared task, the data sets often provide additional information like part-of-speech (POS) tags. In order to take advantage of these knowledge sources, our system is able to process several input sequences at the same time. 2.1 Feature Functions We have implemen</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>A. L. Berger, S. A. Della Pietra, and V. J. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–72, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Borthwick</author>
<author>J Sterling</author>
<author>E Agichtein</author>
<author>R Grisham</author>
</authors>
<title>NYU: Description of the MENE named entity system as used in MUC-7.</title>
<date>1998</date>
<booktitle>In Proceedings of the Seventh Message Understanding Conference (MUC-7),</booktitle>
<volume>6</volume>
<pages>pages,</pages>
<location>Fairfax, VA,</location>
<note>http://www.itl.nist.gov/iaui/894.02/related projects/muc/.</note>
<contexts>
<context position="7100" citStr="Borthwick et al., 1998" startWordPosition="1145" endWordPosition="1148">a times the prior probability of the model parameters: where This method tries to avoid very large lambda values and avoids that features that occur only once for a specific class get value infinity. Note that there is only one parameter for all model parameters . 2.4 Search In the test phase, the search is performed using the socalled maximum approximation, i.e. the most likely sequence of named entities is chosen among all possible sequences : Therefore, the time-consuming renormalization in Eq. 1 is not needed during search. We run a Viterbi search to find the highest probability sequence (Borthwick et al., 1998). 3 Experiments Experiments were performed on English and German test sets. The English data was derived from the Reuters corpus&apos; while the German test sets were extracted from the ECI Multilingual Text corpus. The data sets contain tokens (words and punctuation marks), information about the sentence boundaries, as well as the assigned NE tags. Additionally, a POS tag and a syntactic chunk tag were assigned to each token. On the tag level, we distinguish five tags (the four NE tags mentioned above and a filler tag). 3.1 Incorporating Lists of Names and Non-annotated Data For the English task, </context>
</contexts>
<marker>Borthwick, Sterling, Agichtein, Grisham, 1998</marker>
<rawString>A. Borthwick, J. Sterling, E. Agichtein, and R. Grisham. 1998. NYU: Description of the MENE named entity system as used in MUC-7. In Proceedings of the Seventh Message Understanding Conference (MUC-7), 6 pages, Fairfax, VA, April. http://www.itl.nist.gov/iaui/894.02/related projects/muc/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Chen</author>
<author>R Rosenfeld</author>
</authors>
<title>A gaussian prior for smoothing maximum entropy models.</title>
<date>1999</date>
<tech>Technical Report CMUCS-99-108,</tech>
<institution>Carnegie Mellon University,</institution>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="6278" citStr="Chen and Rosenfeld, 1999" startWordPosition="1007" endWordPosition="1011">For training purposes, we consider the set of manually annotated and segmented training sentences to form a single long sentence. As training criterion, we use the maximum class posterior probability criterion: This corresponds to maximizing the likelihood of the ME model. Since the optimization criterion is convex, there is only a single optimum and no convergence problems occur. To train the model parameters we use the Generalized Iterative Scaling (GIS) algorithm (Darroch and Ratcliff, 1972). In practice, the training procedure tends to result in an overfitted model. To avoid overfitting, (Chen and Rosenfeld, 1999) have suggested a smoothing method where a Gaussian prior on the parameters is assumed. Instead of maximizing the probability of the training data, we now maximize the probability of the training data times the prior probability of the model parameters: where This method tries to avoid very large lambda values and avoids that features that occur only once for a specific class get value infinity. Note that there is only one parameter for all model parameters . 2.4 Search In the test phase, the search is performed using the socalled maximum approximation, i.e. the most likely sequence of named e</context>
</contexts>
<marker>Chen, Rosenfeld, 1999</marker>
<rawString>S. Chen and R. Rosenfeld. 1999. A gaussian prior for smoothing maximum entropy models. Technical Report CMUCS-99-108, Carnegie Mellon University, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J N Darroch</author>
<author>D Ratcliff</author>
</authors>
<title>Generalized iterative scaling for log-linear models.</title>
<date>1972</date>
<journal>Annals of Mathematical Statistics,</journal>
<pages>43--1470</pages>
<contexts>
<context position="6152" citStr="Darroch and Ratcliff, 1972" startWordPosition="988" endWordPosition="991">( resp.) yielded best results. Input Sequence ✁ Preprocessing Global Search Postprocessing exp exp entryOccurs (1) 2.3 Training For training purposes, we consider the set of manually annotated and segmented training sentences to form a single long sentence. As training criterion, we use the maximum class posterior probability criterion: This corresponds to maximizing the likelihood of the ME model. Since the optimization criterion is convex, there is only a single optimum and no convergence problems occur. To train the model parameters we use the Generalized Iterative Scaling (GIS) algorithm (Darroch and Ratcliff, 1972). In practice, the training procedure tends to result in an overfitted model. To avoid overfitting, (Chen and Rosenfeld, 1999) have suggested a smoothing method where a Gaussian prior on the parameters is assumed. Instead of maximizing the probability of the training data, we now maximize the probability of the training data times the prior probability of the model parameters: where This method tries to avoid very large lambda values and avoids that features that occur only once for a specific class get value infinity. Note that there is only one parameter for all model parameters . 2.4 Search</context>
</contexts>
<marker>Darroch, Ratcliff, 1972</marker>
<rawString>J. N. Darroch and D. Ratcliff. 1972. Generalized iterative scaling for log-linear models. Annals of Mathematical Statistics, 43:1470–1480.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>