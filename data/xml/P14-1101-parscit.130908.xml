<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000064">
<title confidence="0.994958">
Weak semantic context helps phonetic learning
in a model of infant language acquisition
</title>
<author confidence="0.951151">
Stella Frank Naomi H. Feldman Sharon Goldwater
</author>
<affiliation confidence="0.843989666666667">
sfrank@inf.ed.ac.uk nhf@umd.edu sgwater@inf.ed.ac.uk
ILCC, School of Informatics Department of Linguistics ILCC, School of Informatics
University of Edinburgh University of Maryland University of Edinburgh
</affiliation>
<address confidence="0.731182">
Edinburgh, EH8 9AB, UK College Park, MD, 20742, USA Edinburgh, EH8 9AB, UK
</address>
<sectionHeader confidence="0.974699" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999964526315789">
Learning phonetic categories is one of the
first steps to learning a language, yet is hard
to do using only distributional phonetic in-
formation. Semantics could potentially be
useful, since words with different mean-
ings have distinct phonetics, but it is un-
clear how many word meanings are known
to infants learning phonetic categories. We
show that attending to a weaker source of
semantics, in the form of a distribution over
topics in the current context, can lead to
improvements in phonetic category learn-
ing. In our model, an extension of a pre-
vious model of joint word-form and pho-
netic category inference, the probability of
word-forms is topic-dependent, enabling
the model to find significantly better pho-
netic vowel categories and word-forms than
a model with no semantic knowledge.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999870785714286">
Infants begin learning the phonetic categories of
their native language in their first year (Kuhl et al.,
1992; Polka and Werker, 1994; Werker and Tees,
1984). In theory, semantic information could offer
a valuable cue for phoneme induction1 by helping
infants distinguish between minimal pairs, as lin-
guists do (Trubetzkoy, 1939). However, due to a
widespread assumption that infants do not know the
meanings of many words at the age when they are
learning phonetic categories (see Swingley, 2009
for a review), most recent models of early phonetic
category acquisition have explored the phonetic
learning problem in the absence of semantic infor-
mation (de Boer and Kuhl, 2003; Dillon et al., 2013;
</bodyText>
<footnote confidence="0.9849395">
1The models in this paper do not distinguish between pho-
netic and phonemic categories, since they do not capture
phonological processes (and there are also none present in
our synthetic data). We thus use the terms interchangeably.
</footnote>
<figureCaption confidence="0.9464335">
Feldman et al., 2013a; McMurray et al., 2009; Val-
labha et al., 2007).
</figureCaption>
<bodyText confidence="0.988440307692308">
Models without any semantic information are
likely to underestimate infants’ ability to learn pho-
netic categories. Infants learn language in the wild,
and quickly attune to the fact that words have (pos-
sibly unknown) meanings. The extent of infants’
semantic knowledge is not yet known, but existing
evidence shows that six-month-olds can associate
some words with their referents (Bergelson and
Swingley, 2012; Tincoff and Jusczyk, 1999, 2012),
leverage non-acoustic contexts such as objects or ar-
ticulations to distinguish similar sounds (Teinonen
et al., 2008; Yeung and Werker, 2009), and map
meaning (in the form of objects or images) to new
word-forms in some laboratory settings (Friedrich
and Friederici, 2011; Gogate and Bahrick, 2001;
Shukla et al., 2011). These findings indicate that
young infants are sensitive to co-occurrences be-
tween linguistic stimuli and at least some aspects
of the world.
In this paper we explore the potential contribu-
tion of semantic information to phonetic learning
by formalizing a model in which learners attend to
the word-level context in which phones appear (as
in the lexical-phonetic learning model of Feldman
et al., 2013a) and also to the situations in which
word-forms are used. The modeled situations con-
sist of combinations of categories of salient ac-
tivities or objects, similar to the activity contexts
explored by Roy et al. (2012), e.g.,‘getting dressed’
or ‘eating breakfast’. We assume that child learn-
ers are able to infer a representation of the situ-
ational context from their non-linguistic environ-
ment. However, in our simulations we approximate
the environmental information by running a topic
model (Blei et al., 2003) over a corpus of child-
directed speech to infer a topic distribution for each
situation. These topic distributions are then used as
input to our model to represent situational contexts.
The situational information in our model is simi-
</bodyText>
<page confidence="0.938502">
1073
</page>
<note confidence="0.865194">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1073–1083,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.958704227272727">
lar to that assumed by theories of cross-situational
word learning (Frank et al., 2009; Smith and Yu,
2008; Yu and Smith, 2007), but our model does not
require learners to map individual words to their ref-
erents. Even in the absence of word-meaning map-
pings, situational information is potentially useful
because similar-sounding words uttered in similar
situations are more likely to be tokens of the same
lexeme (containing the same phones) than similar-
sounding words uttered in different situations.
In simulations of vowel learning, inspired by
Vallabha et al. (2007) and Feldman et al. (2013a),
we show a clear improvement over previous mod-
els in both phonetic and lexical (word-form) cate-
gorization when situational context is used as an
additional source of information. This improve-
ment is especially noticeable when the word-level
context is providing less information, arguably the
more realistic setting. These results demonstrate
that relying on situational co-occurrence can im-
prove phonetic learning, even if learners do not yet
know the meanings of individual words.
</bodyText>
<sectionHeader confidence="0.76914" genericHeader="introduction">
2 Background and overview of models
</sectionHeader>
<bodyText confidence="0.999872074074074">
Infants attend to distributional characteristics of
their input (Maye et al., 2002, 2008), leading to
the hypothesis that phonetic categories could be
acquired on the basis of bottom-up distributional
learning alone (de Boer and Kuhl, 2003; Vallabha
et al., 2007; McMurray et al., 2009). However, this
would require sound categories to be well sepa-
rated, which often is not the case—for example,
see Figure 1, which shows the English vowel space
that is the focus of this paper.
Recent work has investigated whether infants
could overcome such distributional ambiguity by
incorporating top-down information, in particular,
the fact that phones appear within words. At six
months, infants begin to recognize word-forms
such as their name and other frequently occurring
words (Mandel et al., 1995; Jusczyk and Hohne,
1997), without necessarily linking a meaning to
these forms. This “protolexicon” can help differen-
tiate phonetic categories by adding word contexts
in which certain sound categories appear (Swingley,
2009; Feldman et al., 2013b). To explore this idea
further, Feldman et al. (2013a) implemented the
Lexical-Distributional (LD) model, which jointly
learns a set of phonetic vowel categories and a set
of word-forms containing those categories. Simula-
tions showed that the use of lexical context greatly
</bodyText>
<figureCaption confidence="0.800249">
Figure 1: The English vowel space (generated from
Hillenbrand et al. (1995), see Section 6.2), plotted
using the first two formants.
</figureCaption>
<bodyText confidence="0.986528">
improved phonetic learning.
Our own Topic-Lexical-Distributional (TLD)
model extends the LD model to include an addi-
tional type of context: the situations in which words
appear. To motivate this extension and clarify the
differences between the models, we now provide
a high-level overview of both models; details are
given in Sections 3 and 4.
</bodyText>
<subsectionHeader confidence="0.998882">
2.1 Overview of LD model
</subsectionHeader>
<bodyText confidence="0.999970944444445">
Both the LD and TLD models are computational-
level models of phonetic (specifically, vowel) cat-
egorization where phones (vowels) are presented
to the model in the context of words.2 The task is
to infer a set of phonetic categories and a set of
lexical items on the basis of the data observed for
each word token xi. In the original LD model, the
observations for token xi are its frame fi, which
consists of a list of consonants and slots for vowels,
and the list of vowel tokens wi. (The TLD model
includes additional observations, described below.)
A single vowel token, wig, is a two dimensional
vector representing the first two formants (peaks
in the frequency spectrum, ordered from lowest to
highest). For example, a token of the word kitty
would have the frame fi = k t , containing two
consonant phones, /k/ and /t/, with two vowel phone
slots in between, and two vowel formant vectors,
</bodyText>
<footnote confidence="0.9601218">
2For a related model that also tackles the word segmenta-
tion problem, see Elsner et al. (2013). In a model of phono-
logical learning, Fourtassi and Dupoux (submitted) show that
semantic context information similar to that used here remains
useful despite segmentation errors.
</footnote>
<figure confidence="0.996835142857143">
3500 3000 2500 2000 1500 1000 500
F2
F1
1000
1200
200
400
600
800
iy
ei
ih
ae
eh
er
ah
uh
oo
aw
uw
oa
</figure>
<page confidence="0.973837">
1074
</page>
<equation confidence="0.896767">
wi0 = [464, 2294] and wi1 = [412, 2760].3
</equation>
<bodyText confidence="0.999693">
Given the data, the model must assign each
vowel token to a vowel category, wij = c. Both
the LD and the TLD models do this using inter-
mediate lexemes, f, which contain vowel category
assignments, vtj = c, as well as a frame ft. If a
word token is assigned to a lexeme, xi = E, the
vowels within the word are assigned to that lex-
eme’s vowel categories, wij = vtj = c.4 The word
and lexeme frames must match, fi = ft.
Lexical information helps with phonetic catego-
rization because it can disambiguate highly over-
lapping categories, such as the ae and eh categories
in Figure 1. A purely distributional learner who ob-
serves a cluster of data points in the ae-eh region is
likely to assume all these points belong to a single
category because the distributions of the categories
are so similar. However, a learner who attends to
lexical context will notice a difference: contexts
that only occur with ae will be observed in one part
of the ae-eh region, while contexts that only oc-
cur with eh will be observed in a different (though
partially overlapping) space. The learner then has
evidence of two different categories occurring in
different sets of lexemes.
Simulations with the LD model show that using
lexical information to constrain phonetic learning
can greatly improve categorization accuracy (Feld-
man et al., 2013a), but it can also introduce errors.
When two word tokens contain the same consonant
frame but different vowels (i.e., minimal pairs),
the model is more likely to categorize those two
vowels together. Thus, the model has trouble distin-
guishing minimal pairs. Although young children
also have trouble with minimal pairs (Stager and
Werker, 1997; Thiessen, 2007), the LD model may
overestimate the degree of the problem. We hypoth-
esize that if a learner is able to associate words with
the contexts of their use (as children likely are), this
could provide a weak source of information for dis-
ambiguating minimal pairs even without knowing
their exact meanings. That is, if the learner hears
kV1t and kV2t in different situational contexts, they
are likely to be different lexical items (and V1 and
V2 different phones), despite the lexical similarity
between them.
</bodyText>
<footnote confidence="0.995524">
3In simulations we also experiment with frames in which
consonants are not represented perfectly.
4The notation is overloaded: wij refers both to the vowel
formants and the vowel category assignments, and xi refers
to both the token identity and its assignment to a lexeme.
</footnote>
<subsectionHeader confidence="0.993752">
2.2 Overview of TLD model
</subsectionHeader>
<bodyText confidence="0.99997068">
To demonstrate the benefit of situational informa-
tion, we develop the Topic-Lexical-Distributional
(TLD) model, which extends the LD model by as-
suming that words appear in situations analogous
to documents in a topic model. Each situation h
is associated with a mixture of topics Oh, which is
assumed to be observed. Thus, for the ith token in
situation h, denoted xhi, the observed data will be
its frame fhi, vowels whi, and topic vector Oh.
From an acquisition perspective, the observed
topic distribution represents the child’s knowledge
of the context of the interaction: she can distin-
guish bathtime from dinnertime, and is able to rec-
ognize that some topics appear in certain contexts
(e.g. animals on walks, vegetables at dinnertime)
and not in others (few vegetables appear at bath-
time). We assume that the child would learn these
topics from observing the world around her and
the co-occurrences of entities and activities in the
world. Within any given situation, there might be
a mixture of different (actual or possible) topics
that are salient to the child. We assume further that
as the child learns the language, she will begin to
associate specific words with each topic as well.
Thus, in the TLD model, the words used in a sit-
uation are topic-dependent, implying meaning, but
without pinpointing specific referents. Although the
model observes the distribution of topics in each
situation (corresponding to the child observing her
non-linguistic environment), it must learn to asso-
ciate each (phonetically and lexically ambiguous)
word token with a particular topic from that distri-
bution. The occurrence of similar-sounding words
in different situations with mostly non-overlapping
topics will provide evidence that those words be-
long to different topics and that they are therefore
different lexemes. Conversely, potential minimal
pairs that occur in situations with similar topic dis-
tributions are more likely to belong to the same
topic and thus the same lexeme.
Although we assume that children infer topic
distributions from the non-linguistic environment,
we will use transcripts from CHILDES to create the
word/phone learning input for our model. These
transcripts are not annotated with environmental
context, but Roy et al. (2012) found that topics
learned from similar transcript data using a topic
model were strongly correlated with immediate ac-
tivities and contexts. We therefore obtain the topic
distributions used as input to the TLD model by
</bodyText>
<page confidence="0.969439">
1075
</page>
<bodyText confidence="0.999924857142857">
training an LDA topic model (Blei et al., 2003)
on a superset of the child-directed transcript data
we use for lexical-phonetic learning, dividing the
transcripts into small sections (the ‘documents’ in
LDA) that serve as our distinct situations h. As
noted above, the learned document-topic distribu-
tions θ are treated as observed variables in the
TLD model to represent the situational context. The
topic-word distributions learned by LDA are dis-
carded, since these are based on the (correct and
unambiguous) words in the transcript, whereas the
TLD model is presented with phonetically ambigu-
ous versions of these word tokens and must learn to
disambiguate them and associate them with topics.
</bodyText>
<sectionHeader confidence="0.999875" genericHeader="method">
3 Lexical-Distributional Model
</sectionHeader>
<bodyText confidence="0.999996217391305">
In this section we describe more formally the gen-
erative process for the LD model (Feldman et al.,
2013a), a joint Bayesian model over phonetic cat-
egories and a lexicon, before describing the TLD
extension in the following section.
The set of phonetic categories and the lexicon are
both modeled using non-parametric Dirichlet Pro-
cess priors, which return a potentially infinite num-
ber of categories or lexemes. A DP is parametrized
as DP(α, H), where α is a real-valued hyperpa-
rameter and H is a base distribution. H may be con-
tinuous, as when it generates phonetic categories
in formant space, or discrete, as when it generates
lexemes as a list of phonetic categories.
A draw from a DP, G — DP(α, H), returns
a distribution over a set of draws from H, i.e., a
discrete distribution over a set of categories or lex-
emes generated by H. In the mixture model setting,
the category assignments are then generated from
G, with the datapoints themselves generated by the
corresponding components from H. If H is infinite,
the support of the DP is likewise infinite. During
inference, we marginalize over G.
</bodyText>
<subsectionHeader confidence="0.997387">
3.1 Phonetic Categories: IGMM
</subsectionHeader>
<bodyText confidence="0.999936363636364">
Following previous models of vowel learning (de
Boer and Kuhl, 2003; Vallabha et al., 2007; Mc-
Murray et al., 2009; Dillon et al., 2013) we assume
that vowel tokens are drawn from a Gaussian mix-
ture model. The Infinite Gaussian Mixture Model
(IGMM) (Rasmussen, 2000) includes a DP prior,
as described above, in which the base distribution
HC generates multivariate Gaussians drawn from
a Normal Inverse-Wishart prior.5 Each observation,
a formant vector wij, is drawn from the Gaussian
corresponding to its category assignment cij:
</bodyText>
<equation confidence="0.98265675">
µc, Ec — HC = NIW(µo, Eo, ν0)
GC — DP(αc, HC)
cij — GC
wij|cij = c — N(µc, Ec)
</equation>
<bodyText confidence="0.999961285714286">
The above model generates a category assignment
cij for each vowel token wij. This is the baseline
IGMM model, which clusters vowel tokens using
bottom-up distributional information only; the LD
model adds top-down information by assigning cat-
egories in the lexicon, rather than on the token
level.
</bodyText>
<subsectionHeader confidence="0.998757">
3.2 Lexicon
</subsectionHeader>
<bodyText confidence="0.999529">
In the LD model, vowel phones appear within
words drawn from the lexicon. Each such lexeme
is represented as a frame plus a list of vowel cate-
gories v`. Lexeme assignments for each token are
drawn from a DP with a lexicon-generating base
distribution HL. The category for each vowel to-
ken in the word is determined by the lexeme; the
formant values are drawn from the corresponding
Gaussian as in the IGMM:
</bodyText>
<equation confidence="0.998058">
GL — DP(αl, HL)
xi = ` — GL
wij|v`j = c — N(µc, Ec)
</equation>
<bodyText confidence="0.999870909090909">
HL generates lexemes by first drawing the num-
ber of phones from a geometric distribution and the
number of consonant phones from a binomial dis-
tribution. The consonants are then generated from a
DP with a uniform base distribution (but note they
are fixed at inference time, i.e., are observed cate-
gorically), while the vowel phones v` are generated
by the IGMM DP above, v`j — GC.
Note that two draws from HL may result in iden-
tical lexemes; these are nonetheless considered to
be separate (homophone) lexemes.
</bodyText>
<sectionHeader confidence="0.999879" genericHeader="method">
4 Topic-Lexical-Distributional Model
</sectionHeader>
<bodyText confidence="0.9994886">
The TLD model retains the IGMM vowel phone
component, but extends the lexicon of the LD
model by adding topic-specific lexicons, which cap-
ture the notion that lexeme probabilities are topic-
dependent. Specifically, the TLD model replaces
</bodyText>
<footnote confidence="0.4798005">
5This compound distribution is equivalent to
E. — IW(E0, v0), µ.|E. — N(µ0, νo )
</footnote>
<page confidence="0.927624">
1076
</page>
<bodyText confidence="0.999751282051282">
the Dirichlet Process lexicon with a Hierarchical
Dirichlet Process (HDP; Teh (2006)). In the HDP
lexicon, a top-level global lexicon is generated as
in the LD model. Topic-specific lexicons are then
drawn from the global lexicon, containing a subset
of the global lexicon (but since the size of the global
lexicon is unbounded, so are the topic-specific lex-
icons). These topic-specific lexicons are used to
generate the tokens in a similar manner to the LD
model. There are a fixed number of lower level
topic-lexicons; these are matched to the number
of topics in the LDA model used to infer the topic
distributions (see Section 6.4).
More formally, the global lexicon is generated
as a top-level DP: GL — DP(αl, HL) (see Sec-
tion 3.2; remember HL includes draws from the
IGMM over vowel categories). GL is in turn used
as the base distribution in the topic-level DPs,
Gk — DP(αk, GL). In the Chinese Restaurant
Franchise metaphor often used to describe HDPs,
GL is a global menu of dishes (lexemes). The topic-
specific lexicons are restaurants, each with its own
distribution over dishes; this distribution is defined
by seating customers (word tokens) at tables, each
of which serves a single dish from the menu: all
tokens x at the same table t are assigned to the
same lexeme Et. Inference (Section 5) is defined
in terms of tables rather than lexemes; if multiple
tables draw the same dish from GL, tokens at these
tables share a lexeme.
In the TLD model, tokens appear within situa-
tions, each of which has a distribution over topics
Oh. Each token xhi has a co-indexed topic assign-
ment variable, zhi, drawn from Oh, designating the
topic-lexicon from which the table for xhi is to be
drawn. The formant values for whij are drawn in
the same way as in the LD model, given the lexeme
assignment at xhi. This results in the following
model, shown in Figure 2:
</bodyText>
<equation confidence="0.9999522">
GL — DP(αl, HL) (8)
Gk — DP(αk, GL) (9)
zhi — Mult(Oh) (10)
xhi = t|zhi = k — Gk (11)
whij|xhi = t,v`tj = c — N(µc, Σc) (12)
</equation>
<sectionHeader confidence="0.999306" genericHeader="method">
5 Inference: Gibbs Sampling
</sectionHeader>
<bodyText confidence="0.992887882352941">
We use Gibbs sampling to infer three sets of vari-
ables in the TLD model: assignments to vowel cat-
egories in the lexemes, assignments of tokens to
Figure 2: TLD model, depicting, from left to right,
the IGMM component, the LD lexicon compo-
nent, the topic-specific lexicons, and finally the
token xhi, appearing in document h, with observed
vowel formants whij and frame fhi. The lexeme
assignment xhi and the topic assignment zhi are
inferred, the latter using the observed document-
topic distribution Oh. Note that fi is deterministic
given the lexeme assignment. Squared nodes depict
hyperparameters. A is the set of hyperparameters
used by HL when generating lexical items (see
Section 3.2).
topics, and assignments of tokens to tables (from
which the assignment to lexemes can be read off).
</bodyText>
<subsectionHeader confidence="0.997628">
5.1 Sampling lexeme vowel categories
</subsectionHeader>
<bodyText confidence="0.999966428571429">
Each vowel in the lexicon must be assigned to a
category in the IGMM. The posterior probability of
a category assignment is composed of the DP prior
over categories and the likelihood of the observed
vowels belonging to that category. We use w`j to
denote the set of vowel formants at position j in
words that have been assigned to lexeme E. Then,
</bodyText>
<equation confidence="0.994303125">
P(v`j = c|w, x, f\`)
a P(v`j = c|f\`)p(w`j|v`j = c, w\`j) (13)
The first (DP prior) factor is defined as:
� ( e, —  |j) _ Pc n. ate if c exists
Pv — cv\` n,
+a,
nc
(14)
</equation>
<bodyText confidence="0.999433857142857">
where nc is the number of other vowels in the lex-
icon, v\lj, assigned to category c. Note that there
is always positive probability of creating a new
category.
The likelihood of the vowels is calculated by
marginalizing over all possible means and vari-
ances of the Gaussian category parameters, given
</bodyText>
<figure confidence="0.995346125">
fhi
xhi
zhi
θh
whij
|whi|
|xh|
D
µo, κ0, Σ0, vo
A
GC
GL
Gk
K
αk
αc
αl
µc, Σc
00
HC
HL
αc
+
if c new
</figure>
<page confidence="0.988486">
1077
</page>
<bodyText confidence="0.9999265">
the NIW prior. For a single point (if |w`j |= 1),
this predictive posterior is in the form of a Student-t
distribution; for the more general case see Feldman
et al. (2013a), Eq. B3.
</bodyText>
<subsectionHeader confidence="0.997902">
5.2 Sampling table &amp; topic assignments
</subsectionHeader>
<bodyText confidence="0.998459">
We jointly sample x and z, the variables assigning
tokens to tables and topics. Resampling the table
assignment includes the possibility of changing to
a table with a different lexeme or drawing a new
table with a previously seen or novel lexeme. The
joint conditional probability of a table and topic
assignment, given all other current token assign-
ments, is:
</bodyText>
<equation confidence="0.99279875">
P(xhi = t, zhi = k|whi, θh, t\hi, e, w\hi)
= P(k|θh)P(t|k,`t, t\hi)
ri p(whi·|v`t· = c, w\hi) (15)
c∈C
</equation>
<bodyText confidence="0.973102444444444">
The first factor, the prior probability of topic k
in document h, is given by θhk obtained from the
LDA. The second factor is the prior probability of
assigning word xi to table t with lexeme ` given
topic k. It is given by the HDP, and depends on
whether the table t exists in the HDP topic-lexicon
for k and, likewise, whether any table in the topic-
lexicon has the lexeme `:
α` if t and ` new
</bodyText>
<equation confidence="0.8212825">
m+αl
(16)
</equation>
<bodyText confidence="0.999830571428571">
Here nkt is the number of other tokens at table t,
nk are the total number of tokens in topic k, m`
is the number of tables across all topics with the
lexeme `, and m is the total number of tables.
The third factor, the likelihood of the vowel for-
mants whi in the categories given by the lexeme vl,
is of the same form as the likelihood of vowel cate-
gories when resampling lexeme vowel assignments.
However, here it is calculated over the set of vow-
els in the token assigned to each vowel category
(i.e., the vowels at indices where v`t· = c). For a
new lexeme, we approximate the likelihood using
100 samples drawn from the prior, each weighted
by α/100 (Neal, 2000).
</bodyText>
<subsectionHeader confidence="0.987815">
5.3 Hyperparameters
</subsectionHeader>
<bodyText confidence="0.998368833333333">
The three hyperparameters governing the HDP over
the lexicon, αl and αk, and the DP over vowel cate-
gories, αc, are estimated using a slice sampler. The
remaining hyperparameters for the vowel category
and lexeme priors are set to the same values used
by Feldman et al. (2013a).
</bodyText>
<sectionHeader confidence="0.999059" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<subsectionHeader confidence="0.986598">
6.1 Corpus
</subsectionHeader>
<bodyText confidence="0.999843047619048">
We test our model on situated child directed speech,
taken from the C1 section of the Brent corpus in
CHILDES (Brent and Siskind, 2001; MacWhinney,
2000). This corpus consists of transcripts of speech
directed at infants between the ages of 9 and 15
months, captured in a naturalistic setting as par-
ent and child went about their day. This ensures
variability of situations.
Utterances with unintelligible words or quotes
are removed. We restrict the corpus to content
words by retaining only words tagged as adj,
n, part and v (adjectives, nouns, particles, and
verbs). This is in line with evidence that infants
distinguish content and function words on the basis
of acoustic signals (Shi and Werker, 2003). Vowel
categorization improves when attending only to
more prosodically and phonologically salient to-
kens (Adriaans and Swingley, 2012), which gen-
erally appear within content, not function words.
The final corpus consists of 13138 tokens and 1497
word types.
</bodyText>
<subsectionHeader confidence="0.99805">
6.2 Hillenbrand Vowels
</subsectionHeader>
<bodyText confidence="0.99983155">
The transcripts do not include phonetic information,
so, following Feldman et al. (2013a), we synthe-
size the formant values using data from Hillenbrand
et al. (1995). This dataset consists of a set of 1669
manually gathered formant values from 139 Amer-
ican English speakers (men, women and children)
for 12 vowels. For each vowel category, we con-
struct a Gaussian from the mean and covariance of
the datapoints belonging to that category, using the
first and second formant values measured at steady
state. We also construct a second dataset using only
datapoints from adult female speakers.
Each word in the dataset is converted to a phone-
mic representation using the CMU pronunciation
dictionary, which returns a sequence of Arpabet
phoneme symbols. If there are multiple possible
pronunciations, the first one is used. Each vowel
phoneme in the word is then replaced by formant
values drawn from the corresponding Hillenbrand
Gaussian for that vowel.
</bodyText>
<figure confidence="0.7984361">
P(t|k, `, t\hi) ∝ {
nkt if t in k
nk+αk
αk
nk+αk
m`
if t new, ` known
m+αl
αk
nk+αk
</figure>
<page confidence="0.958547">
1078
</page>
<subsectionHeader confidence="0.997807">
6.3 Merging Consonant Categories
</subsectionHeader>
<bodyText confidence="0.99997087804878">
The Arpabet encoding used in the phonemic rep-
resentation includes 24 consonants. We construct
datasets both using the full set of consonants—the
‘C24’ dataset—and with less fine-grained conso-
nant categories. Distinguishing all consonant cate-
gories assumes perfect learning of consonants prior
to vowel categorization and is thus somewhat unre-
alistic (Polka and Werker, 1994), but provides an
upper limit on the information that word-contexts
can give.
In the ‘C15’ dataset, the voicing distinction is
collapsed, leaving 15 consonant categories. The
collapsed categories are B/P, G/K, D/T, CH/JH,
V/F, TH/DH, S/Z, SH/ZH, R/L while HH, M, NG,
N, W, Y remain separate phonemes. This dataset
mirrors the finding in Mani and Plunkett (2010) that
12 month old infants are not sensitive to voicing
mispronunciations.
The ‘C6’ dataset distinguishes between only
6 coarse consonant phonemes, corresponding to
stops (B,P,G,K,D,T), affricates (CH,JH), fricatives
(V, F, TH, DH, S, Z, SH, ZH, HH), nasals (M,
NG, N), liquids (R, L), and semivowels/glides (W,
Y). This dataset makes minimal assumptions about
the category categories that infants could use in this
learning setting.
Decreasing the number of consonants increases
the ambiguity in the corpus: bat not only shares
a frame (b t) with boat and bite, but also, in the
C15 dataset, with put, pad and bad (b/p d/t), and
in the C6 dataset, with dog and kite, among many
others (STOP STOP). Table 1 shows the percent-
age of types and tokens that are ambiguous in each
dataset, that is, words in frames that match multiple
wordtypes. Note that we always evaluate against
the gold word identities, even when these are not
distinguished in the model’s input. These datasets
are intended to evaluate the degree of reliance on
consonant information in the LD and TLD models,
and to what extent the topics in the TLD model can
replace this information.
</bodyText>
<subsectionHeader confidence="0.960941">
6.4 Topics
</subsectionHeader>
<bodyText confidence="0.999970142857143">
The input to the TLD model includes a distribution
over topics for each situation, which we infer in
advance from the full Brent corpus (not only the
C1 subset) using LDA. Each transcript in the Brent
corpus captures about 75 minutes of parent-child
interaction, and thus multiple situations will be
included in each file. The transcripts do not delimit
</bodyText>
<table confidence="0.9977578">
Dataset C24 C15 C6
Input Types 1487 1426 1203
Frames 1259 1078 702
Ambig Types % 27.2 42.0 80.4
Ambig Tokens % 41.3 56.9 77.2
</table>
<tableCaption confidence="0.999542">
Table 1: Corpus statistics showing the increasing
</tableCaption>
<bodyText confidence="0.9646956">
amount of ambiguity as consonant categories are
merged. Input types are the number of word types
with distinct input representations (as opposed to
gold orthographic word types, of which there are
1497). Ambiguous types and tokens are those with
frames that match multiple (orthographic) word
types.
situations, so we do this somewhat arbitrarily by
splitting each transcript after 50 CDS utterances,
resulting in 203 situations for the Brent C1 dataset.
As well as function words, we also remove the
five most frequent content words (be, go, get, want,
come). On average, situations are only 59 words
long, reflecting the relative lack of content words
in CDS utterances.
We infer 50 topics for this set of situations using
the mallet toolkit (McCallum, 2002). Hyperpa-
rameters are inferred, which leads to a dominant
topic that includes mainly light verbs (have, let,
see, do). The other topics are less frequent but cap-
ture stronger semantic meaning (e.g. yummy, peach,
cookie, daddy, bib in one topic, shoe, let, put, hat,
pants in another). The word-topic assignments are
used to calculate unsmoothed situation-topic distri-
butions θ used by the TLD model.
</bodyText>
<subsectionHeader confidence="0.971747">
6.5 Evaluation
</subsectionHeader>
<bodyText confidence="0.9999775">
We evaluate against adult categories, i.e., the ‘gold-
standard’, since all learners of a language even-
tually converge on similar categories. (Since our
model is not a model of the learning process, we
do not compare the infant learning process to the
learning algorithm.) We evaluate both the inferred
phonetic categories and words using the clustering
evaluation measure V-Measure (VM; Rosenberg
and Hirschberg, 2007).6 VM is the harmonic mean
of two components, similar to F-score, where the
components (VC and VH) are measures of cross
entropy between the gold and model categorization.
</bodyText>
<footnote confidence="0.9976724">
6Other clustering measures, such as 1-1 matching and
pairwise precision and recall (accuracy and completeness)
showed the same trends, but VM has been demonstrated to
be the most stable measure when comparing solutions with
varying numbers of clusters (Christodoulopoulos et al., 2010).
</footnote>
<page confidence="0.996829">
1079
</page>
<figure confidence="0.99933544">
LD-all
TLD-all
LD-w
TLD-w
24 Cons 15 Cons 6 Cons
VM 90
85
80
75
3500
3000
2500
2000
F2
1500
1000
500
F1
1000
1200
400
200
600
800
Dataset
</figure>
<figureCaption confidence="0.998077">
Figure 3: Vowel evaluation. ‘all’ refers to datasets
</figureCaption>
<bodyText confidence="0.900595307692308">
with vowels synthesized from all speakers, ‘w’ to
datasets with vowels synthesized from adult female
speakers’ vowels. The bars show a 95% Confidence
Interval based on 5 runs. IGMM-all results in a VM
score of 53.9 (CI=0.5); IGMM-w has a VM score
of 65.0 (CI=0.2), not shown.
For vowels, VM measures how well the inferred
phonetic categorizations match the gold categories;
for lexemes, it measures whether tokens have been
assigned to the same lexemes both by the model
and the gold standard. Words are evaluated against
gold orthography, so homophones, e.g. hole and
whole, are distinct gold words.
</bodyText>
<subsectionHeader confidence="0.793217">
6.6 Results
</subsectionHeader>
<bodyText confidence="0.961836036363636">
We compare all three models—TLD, LD, and
IGMM—on the vowel categorization task, and
TLD and LD on the lexical categorization task
(since IGMM does not infer a lexicon). The datasets
correspond to two sets of conditions: firstly, either
using vowel categories synthesized from all speak-
ers or only adult female speakers, and secondly,
varying the coarseness of the observed consonant
categories. Each condition (model, vowel speak-
ers, consonant set) is run five times, using 1500
iterations of Gibbs sampling with hyperparameter
sampling. Overall, we find that TLD outperforms
the other models in both tasks, across all condi-
tions.
Vowel categorization results are shown in Fig-
ure 3. IGMM performs substantially worse than
both TLD and LD, with scores more than 30 points
lower than the best results for these models, clearly
showing the value of the protolexicon and repli-
Figure 4: Vowels found by the TLD model; su-
pervowels are indicated in red. The gold-standard
vowels are shown in gold in the background but are
mostly overlapped by the inferred categories.
cating the results found by Feldman et al. (2013a)
on this dataset. Furthermore, TLD consistently out-
performs the LD model, finding better phonetic
categories, both for vowels generated from the com-
bined categories of all speakers (‘all’) and vowels
generated from adult female speakers only (‘w’),
although the latter are clearly much easier for both
models to learn. Both models perform less well
when the consonant frames provide less informa-
tion, but the TLD model performance degrades less
than the LD performance.
Both the TLD and the LD models find ‘super-
vowel’ categories, which cover multiple vowel cat-
egories and are used to merge minimal pairs into a
single lexical item. Figure 4 shows example vowel
categories inferred by the TLD model, including
two supervowels. The TLD supervowels are used
much less frequently than the supervowels found
by the LD model, containing, on average, only two-
thirds as many tokens.
Figure 5 shows that TLD also outperforms LD
on the lexeme/word categorization task. Again per-
formance decreases as the consonant categories
become coarser, but the additional semantic infor-
mation in the TLD model compensates for the lack
of consonant information. In the individual com-
ponents of VM, TLD and LD have similar VC
(“recall”), but TLD has higher VH (“precision”),
demonstrating that the semantic information given
by the topics can separate potentially ambiguous
words, as hypothesized.
Overall, the contextual semantic information
</bodyText>
<page confidence="0.979674">
1080
</page>
<figure confidence="0.988628">
24 Cons 15 Cons 6 Cons
Dataset
</figure>
<figureCaption confidence="0.94477825">
Figure 5: Lexeme evaluation. ‘all’ refers to datasets
with vowels synthesized from all speakers, ‘w’ to
datasets with vowels synthesized from adult female
speakers’ vowels.
</figureCaption>
<bodyText confidence="0.999760727272727">
added in the TLD model leads to both better pho-
netic categorization and to a better protolexicon,
especially when the input is noisier, using degraded
consonants. Since infants are not likely to have per-
fect knowledge of phonetic categories at this stage,
semantic information is a potentially rich source
of information that could be drawn upon to offset
noise from other domains. The form of the seman-
tic information added in the TLD model is itself
quite weak, so the improvements shown here are in
line with what infant learners could achieve.
</bodyText>
<sectionHeader confidence="0.999173" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999988796296296">
Language acquisition is a complex task, in which
many heterogeneous sources of information may
be useful. In this paper, we investigated whether
contextual semantic information could be of help
when learning phonetic categories. We found that
this contextual information can improve phonetic
learning performance considerably, especially in
situations where there is a high degree of pho-
netic ambiguity in the word-forms that learners
hear. This suggests that previous models that have
ignored semantic information may have underesti-
mated the information that is available to infants.
Our model illustrates one way in which language
learners might harness the rich information that is
present in the world without first needing to acquire
a full inventory of word meanings.
The contextual semantic information that the
TLD model tracks is similar to that potentially
used in other linguistic learning tasks. Theories
of cross-situational word learning (Smith and Yu,
2008; Yu and Smith, 2007) assume that sensitivity
to situational co-occurrences between words and
non-linguistic contexts is a precursor to learning the
meanings of individual words. Under this view, con-
textual semantics is available to infants well before
they have acquired large numbers of semantic min-
imal pairs. However, recent experimental evidence
indicates that learners do not always retain detailed
information about the referents that are present in a
scene when they hear a word (Medina et al., 2011;
Trueswell et al., 2013). This evidence poses a di-
rect challenge to theories of cross-situational word
learning. Our account does not necessarily require
learners to track co-occurrences between words
and individual objects, but instead focuses on more
abstract information about salient events and topics
in the environment; it will be important to investi-
gate to what extent infants encode this information
and use it in phonetic learning.
Regardless of the specific way in which infants
encode semantic information, our method of adding
this information by using LDA topics from tran-
script data was shown to be effective. This method
is practical because it can approximate semantic
information without relying on extensive manual
annotation.
The LD model extended the phonetic catego-
rization task by adding word contexts; the TLD
model presented here goes even further, adding
larger situational contexts. Both forms of top-down
information help the low-level task of classifying
acoustic signals into phonetic categories, furthering
a holistic view of language learning with interac-
tion across multiple levels.
</bodyText>
<sectionHeader confidence="0.99815" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.991421333333333">
This work was supported by EPSRC grant
EP/H050442/1 and a James S. McDonnell Founda-
tion Scholar Award to the final author.
</bodyText>
<sectionHeader confidence="0.98218" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.982975428571429">
Frans Adriaans and Daniel Swingley. Distribu-
tional learning of vowel categories is supported
by prosody in infant-directed speech. In Pro-
ceedings of the 34th Annual Conference of the
Cognitive Science Society (CogSci), 2012.
E. Bergelson and D. Swingley. At 6-9 months,
human infants know the meanings of many
</bodyText>
<figure confidence="0.945709">
LD-all
TLD-all
LD-w
TLD-w
VM 100
98
96
94
92
</figure>
<page confidence="0.97497">
1081
</page>
<reference confidence="0.995607541666666">
common nouns. Proceedings of the National
Academy of Sciences, 109(9):3253–3258, Feb
2012.
David M. Blei, Thomas L. Griffiths, Michael I. Jor-
dan, and Joshua B. Tenenbaum. Hierarchical
topic models and the nested Chinese restaurant
process. In Advances in Neural Information Pro-
cessing Systems 16, 2003.
Michael R. Brent and Jeffrey M. Siskind. The role
of exposure to isolated words in early vocabulary
development. Cognition, 81(2):B33–B44, 2001.
Christos Christodoulopoulos, Sharon Goldwater,
and Mark Steedman. Two decades of unsuper-
vised POS induction: How far have we come?
In Proceedings of the 48th Annual Meeting of
the Association for Computational Linguistics
(ACL), pages 575–584, Cambridge, MA, Octo-
ber 2010. Association for Computational Lin-
guistics.
Bart de Boer and Patricia K. Kuhl. Investigating the
role of infant-directed speech with a computer
model. Acoustics Research Letters Online, 4(4):
129, 2003.
Brian Dillon, Ewan Dunbar, and William Idsardi. A
single-stage approach to learning phonological
categories: Insights from Inuktitut. Cognitive
Science, 37(2):344–377, Mar 2013.
Micha Elsner, Sharon Goldwater, Naomi Feldman,
and Frank Wood. A cognitive model of early
lexical acquisition with phonetic variability. In
Proceedings of the 18th Conference on Empir-
ical Methods in Natural Language Processing
(EMNLP), 2013.
Naomi H. Feldman, Thomas L. Griffiths, Sharon
Goldwater, and James L. Morgan. A role for the
developing lexicon in phonetic category acquisi-
tion. Psychological Review, 2013a.
Naomi H. Feldman, Emily B. Myers, Katherine S.
White, Thomas L. Griffiths, and James L. Mor-
gan. Word-level information influences phonetic
learning in adults and infants. Cognition, 127(3):
427–438, 2013b.
Abdellah Fourtassi and Emmanuel Dupoux. A rudi-
mentary lexicon and semantics help bootstrap
phoneme acquisition. Submitted.
Michael C. Frank, Noah D. Goodman, and
Joshua B. Tenenbaum. Using speakers’ refer-
ential intentions to model early cross-situational
word learning. Psychological Science, 20(5):
578–585, 2009.
Manuela Friedrich and Angela D. Friederici. Word
learning in 6-month-olds: Fast encoding—weak
retention. Journal of Cognitive Neuroscience, 23
(11):3228–3240, Nov 2011.
Lakshmi J. Gogate and Lorraine E. Bahrick. In-
tersensory redundancy and 7-month-old infants’
memory for arbitrary syllable-object relations.
Infancy, 2(2):219–231, Apr 2001.
J. Hillenbrand, L. A. Getty, M. J. Clark, and
K. Wheeler. Acoustic characteristics of Ameri-
can English vowels. Journal of the Acoustical
Society ofAmerica, 97(5 Pt 1):3099–3111, May
1995.
P. W. Jusczyk and Elizabeth A. Hohne. Infants’
memory for spoken words. Science, 277(5334):
1984–1986, Sep 1997.
Patricia K. Kuhl, Karen A. Williams, Francisco
Lacerda, Kenneth N. Stevens, and Bjorn Lind-
blom. Linguistic experience alters phonetic per-
ception in infants by 6 months of age. Science,
255(5044):606–608, 1992.
Brian MacWhinney. The CHILDES Project: Tools
for Analyzing Talk. Lawrence Erlbaum Asso-
ciates, 2000.
D. R. Mandel, P. W. Jusczyk, and D. B. Pisoni.
Infants’ recognition of the sound patterns of their
own names. Psychological Science, 6(5):314–
317, Sep 1995.
Nivedita Mani and Kim Plunkett. Twelve-month-
olds know their cups from their keps and tups.
Infancy, 15(5):445470, Sep 2010.
Jessica Maye, Daniel J. Weiss, and Richard N.
Aslin. Statistical phonetic learning in infants:
facilitation and feature generalization. Develop-
mental Science, 11(1):122–134, Jan 2008.
Jessica Maye, Janet F Werker, and LouAnn Gerken.
Infant sensitivity to distributional information
can affect phonetic discrimination. Cognition,
82(3):B101–B111, Jan 2002.
Andrew McCallum. MALLET: A machine learn-
ing for language toolkit, 2002.
Bob McMurray, Richard N. Aslin, and Joseph C.
Toscano. Statistical learning of phonetic cate-
gories: insights from a computational approach.
Developmental Science, 12(3):369–378, May
2009.
</reference>
<page confidence="0.901498">
1082
</page>
<reference confidence="0.999329822222222">
Tamara Nicol Medina, Jesse Snedeker, John C.
Trueswell, and Lila R. Gleitman. How words
can and cannot be learned by observation. Pro-
ceedings of the National Academy of Sciences,
108(22):9014–9019, 2011.
Radford Neal. Markov chain sampling methods
for Dirichlet process mixture models. Journal
of Computational and Graphical Statistics, 9:
249–265, 2000.
Linda Polka and Janet F. Werker. Developmen-
tal changes in perception of nonnative vowel
contrasts. Journal of Experimental Psychology:
Human Perception and Performance, 20(2):421–
435, 1994.
Carl Rasmussen. The infinite Gaussian mixture
model. In Advances in Neural Information Pro-
cessing Systems 13, 2000.
Andrew Rosenberg and Julia Hirschberg. V-
measure: A conditional entropy-based external
cluster evaluation measure. In Proceedings of
the 12th Conference on Empirical Methods in
Natural Language Processing (EMNLP), 2007.
Brandon C. Roy, Michael C. Frank, and Deb Roy.
Relating activity contexts to early word learning
in dense longitudinal data. In Proceedings of the
34th Annual Conference of the Cognitive Science
Society (CogSci), 2012.
Rushen Shi and Janet F. Werker. The basis of pref-
erence for lexical words in 6-month-old infants.
Developmental Science, 6(5):484–488, 2003.
M. Shukla, K. S. White, and R. N. Aslin. Prosody
guides the rapid mapping of auditory word forms
onto visual objects in 6-mo-old infants. Proceed-
ings of the National Academy of Sciences, 108
(15):6038–6043, Apr 2011.
Linda B. Smith and Chen Yu. Infants rapidly learn
word-referent mappings via cross-situational
statistics. Cognition, 106(3):1558–1568, 2008.
Christine L. Stager and Janet F. Werker. Infants
listen for more phonetic detail in speech percep-
tion than in word-learning tasks. Nature, 388:
381–382, 1997.
D. Swingley. Contributions of infant word learning
to language development. Philosophical Trans-
actions of the Royal Society B: Biological Sci-
ences, 364(1536):3617–3632, Nov 2009.
Yee Whye Teh. A hierarchical Bayesian language
model based on Pitman-Yor processes. In Pro-
ceedings of the 44th Annual Meeting of the As-
sociation for Computational Linguistics (ACL),
pages 985 – 992, Sydney, 2006.
Tuomas Teinonen, Richard N. Aslin, Paavo Alku,
and Gergely Csibra. Visual speech contributes to
phonetic learning in 6-month-old infants. Cogni-
tion, 108:850–855, 2008.
Erik D. Thiessen. The effect of distributional infor-
mation on children’s use of phonemic contrasts.
Journal of Memory and Language, 56(1):16–34,
Jan 2007.
R. Tincoff and P. W. Jusczyk. Some beginnings of
word comprehension in 6-month-olds. Psycho-
logical Science, 10(2):172–175, Mar 1999.
Ruth Tincoff and Peter W. Jusczyk. Six-month-
olds comprehend words that refer to parts of the
body. Infancy, 17(4):432444, Jul 2012.
N. S. Trubetzkoy. Grundb¨uge der Phonologie. Van-
denhoeck und Ruprecht, G¨ottingen, 1939.
John C. Trueswell, Tamara Nicol Medina, Alon
Hafri, and Lila R. Gleitman. Propose but ver-
ify: Fast mapping meets cross-situational word
learning. Cognitive Psychology, 66:126–156,
2013.
G. K. Vallabha, J. L. McClelland, F. Pons, J. F.
Werker, and S. Amano. Unsupervised learning
of vowel categories from infant-directed speech.
Proceedings of the National Academy of Sci-
ences, 104(33):13273–13278, Aug 2007.
Janet F. Werker and Richard C. Tees. Cross-
language speech perception: Evidence for per-
ceptual reorganization during the first year of
life. Infant Behavior and Development, 7:49–63,
1984.
H. Henny Yeung and Janet F. Werker. Learning
words’ sounds before learning how words sound:
9-month-olds use distinct objects as cues to cat-
egorize speech information. Cognition, 113(2):
234–243, Nov 2009.
Chen Yu and Linda B. Smith. Rapid word learning
under uncertainty via cross-situational statistics.
Psychological Science, 18(5):414–420, 2007.
</reference>
<page confidence="0.985749">
1083
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.960766">
<title confidence="0.9970065">Weak semantic context helps phonetic in a model of infant language acquisition</title>
<author confidence="0.999946">Stella Frank Naomi H Feldman Sharon Goldwater</author>
<email confidence="0.988359">sfrank@inf.ed.ac.uknhf@umd.edu</email>
<affiliation confidence="0.9984945">ILCC, School of Informatics Department of Linguistics ILCC, School of Informatics University of Edinburgh University of Maryland University of</affiliation>
<address confidence="0.991441">Edinburgh, EH8 9AB, UK College Park, MD, 20742, USA Edinburgh, EH8 9AB, UK</address>
<abstract confidence="0.9994232">Learning phonetic categories is one of the first steps to learning a language, yet is hard to do using only distributional phonetic information. Semantics could potentially be useful, since words with different meanings have distinct phonetics, but it is unclear how many word meanings are known to infants learning phonetic categories. We show that attending to a weaker source of semantics, in the form of a distribution over topics in the current context, can lead to improvements in phonetic category learning. In our model, an extension of a previous model of joint word-form and phonetic category inference, the probability of word-forms is topic-dependent, enabling the model to find significantly better phonetic vowel categories and word-forms than a model with no semantic knowledge.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>common nouns</author>
</authors>
<date>2012</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>109</volume>
<issue>9</issue>
<marker>nouns, 2012</marker>
<rawString>common nouns. Proceedings of the National Academy of Sciences, 109(9):3253–3258, Feb 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Thomas L Griffiths</author>
<author>Michael I Jordan</author>
<author>Joshua B Tenenbaum</author>
</authors>
<title>Hierarchical topic models and the nested Chinese restaurant process.</title>
<date>2003</date>
<booktitle>In Advances in Neural Information Processing Systems 16,</booktitle>
<contexts>
<context position="3918" citStr="Blei et al., 2003" startWordPosition="608" endWordPosition="611">d-level context in which phones appear (as in the lexical-phonetic learning model of Feldman et al., 2013a) and also to the situations in which word-forms are used. The modeled situations consist of combinations of categories of salient activities or objects, similar to the activity contexts explored by Roy et al. (2012), e.g.,‘getting dressed’ or ‘eating breakfast’. We assume that child learners are able to infer a representation of the situational context from their non-linguistic environment. However, in our simulations we approximate the environmental information by running a topic model (Blei et al., 2003) over a corpus of childdirected speech to infer a topic distribution for each situation. These topic distributions are then used as input to our model to represent situational contexts. The situational information in our model is simi1073 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1073–1083, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics lar to that assumed by theories of cross-situational word learning (Frank et al., 2009; Smith and Yu, 2008; Yu and Smith, 2007), but our model does not require lea</context>
<context position="13628" citStr="Blei et al., 2003" startWordPosition="2185" endWordPosition="2188">ons are more likely to belong to the same topic and thus the same lexeme. Although we assume that children infer topic distributions from the non-linguistic environment, we will use transcripts from CHILDES to create the word/phone learning input for our model. These transcripts are not annotated with environmental context, but Roy et al. (2012) found that topics learned from similar transcript data using a topic model were strongly correlated with immediate activities and contexts. We therefore obtain the topic distributions used as input to the TLD model by 1075 training an LDA topic model (Blei et al., 2003) on a superset of the child-directed transcript data we use for lexical-phonetic learning, dividing the transcripts into small sections (the ‘documents’ in LDA) that serve as our distinct situations h. As noted above, the learned document-topic distributions θ are treated as observed variables in the TLD model to represent the situational context. The topic-word distributions learned by LDA are discarded, since these are based on the (correct and unambiguous) words in the transcript, whereas the TLD model is presented with phonetically ambiguous versions of these word tokens and must learn to </context>
</contexts>
<marker>Blei, Griffiths, Jordan, Tenenbaum, 2003</marker>
<rawString>David M. Blei, Thomas L. Griffiths, Michael I. Jordan, and Joshua B. Tenenbaum. Hierarchical topic models and the nested Chinese restaurant process. In Advances in Neural Information Processing Systems 16, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Brent</author>
<author>Jeffrey M Siskind</author>
</authors>
<title>The role of exposure to isolated words in early vocabulary development.</title>
<date>2001</date>
<journal>Cognition,</journal>
<volume>81</volume>
<issue>2</issue>
<contexts>
<context position="23678" citStr="Brent and Siskind, 2001" startWordPosition="3955" endWordPosition="3958">, the vowels at indices where v`t· = c). For a new lexeme, we approximate the likelihood using 100 samples drawn from the prior, each weighted by α/100 (Neal, 2000). 5.3 Hyperparameters The three hyperparameters governing the HDP over the lexicon, αl and αk, and the DP over vowel categories, αc, are estimated using a slice sampler. The remaining hyperparameters for the vowel category and lexeme priors are set to the same values used by Feldman et al. (2013a). 6 Experiments 6.1 Corpus We test our model on situated child directed speech, taken from the C1 section of the Brent corpus in CHILDES (Brent and Siskind, 2001; MacWhinney, 2000). This corpus consists of transcripts of speech directed at infants between the ages of 9 and 15 months, captured in a naturalistic setting as parent and child went about their day. This ensures variability of situations. Utterances with unintelligible words or quotes are removed. We restrict the corpus to content words by retaining only words tagged as adj, n, part and v (adjectives, nouns, particles, and verbs). This is in line with evidence that infants distinguish content and function words on the basis of acoustic signals (Shi and Werker, 2003). Vowel categorization imp</context>
</contexts>
<marker>Brent, Siskind, 2001</marker>
<rawString>Michael R. Brent and Jeffrey M. Siskind. The role of exposure to isolated words in early vocabulary development. Cognition, 81(2):B33–B44, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christos Christodoulopoulos</author>
<author>Sharon Goldwater</author>
<author>Mark Steedman</author>
</authors>
<title>Two decades of unsupervised POS induction: How far have we come?</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>575--584</pages>
<location>Cambridge, MA,</location>
<contexts>
<context position="30090" citStr="Christodoulopoulos et al., 2010" startWordPosition="4989" endWordPosition="4992"> to the learning algorithm.) We evaluate both the inferred phonetic categories and words using the clustering evaluation measure V-Measure (VM; Rosenberg and Hirschberg, 2007).6 VM is the harmonic mean of two components, similar to F-score, where the components (VC and VH) are measures of cross entropy between the gold and model categorization. 6Other clustering measures, such as 1-1 matching and pairwise precision and recall (accuracy and completeness) showed the same trends, but VM has been demonstrated to be the most stable measure when comparing solutions with varying numbers of clusters (Christodoulopoulos et al., 2010). 1079 LD-all TLD-all LD-w TLD-w 24 Cons 15 Cons 6 Cons VM 90 85 80 75 3500 3000 2500 2000 F2 1500 1000 500 F1 1000 1200 400 200 600 800 Dataset Figure 3: Vowel evaluation. ‘all’ refers to datasets with vowels synthesized from all speakers, ‘w’ to datasets with vowels synthesized from adult female speakers’ vowels. The bars show a 95% Confidence Interval based on 5 runs. IGMM-all results in a VM score of 53.9 (CI=0.5); IGMM-w has a VM score of 65.0 (CI=0.2), not shown. For vowels, VM measures how well the inferred phonetic categorizations match the gold categories; for lexemes, it measures whe</context>
</contexts>
<marker>Christodoulopoulos, Goldwater, Steedman, 2010</marker>
<rawString>Christos Christodoulopoulos, Sharon Goldwater, and Mark Steedman. Two decades of unsupervised POS induction: How far have we come? In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL), pages 575–584, Cambridge, MA, October 2010. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bart de Boer</author>
<author>Patricia K Kuhl</author>
</authors>
<title>Investigating the role of infant-directed speech with a computer model.</title>
<date>2003</date>
<journal>Acoustics Research Letters Online,</journal>
<volume>4</volume>
<issue>4</issue>
<pages>129</pages>
<marker>de Boer, Kuhl, 2003</marker>
<rawString>Bart de Boer and Patricia K. Kuhl. Investigating the role of infant-directed speech with a computer model. Acoustics Research Letters Online, 4(4): 129, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Dillon</author>
<author>Ewan Dunbar</author>
<author>William Idsardi</author>
</authors>
<title>A single-stage approach to learning phonological categories: Insights from Inuktitut.</title>
<date>2013</date>
<journal>Cognitive Science,</journal>
<volume>37</volume>
<issue>2</issue>
<contexts>
<context position="1932" citStr="Dillon et al., 2013" startWordPosition="296" endWordPosition="299">r first year (Kuhl et al., 1992; Polka and Werker, 1994; Werker and Tees, 1984). In theory, semantic information could offer a valuable cue for phoneme induction1 by helping infants distinguish between minimal pairs, as linguists do (Trubetzkoy, 1939). However, due to a widespread assumption that infants do not know the meanings of many words at the age when they are learning phonetic categories (see Swingley, 2009 for a review), most recent models of early phonetic category acquisition have explored the phonetic learning problem in the absence of semantic information (de Boer and Kuhl, 2003; Dillon et al., 2013; 1The models in this paper do not distinguish between phonetic and phonemic categories, since they do not capture phonological processes (and there are also none present in our synthetic data). We thus use the terms interchangeably. Feldman et al., 2013a; McMurray et al., 2009; Vallabha et al., 2007). Models without any semantic information are likely to underestimate infants’ ability to learn phonetic categories. Infants learn language in the wild, and quickly attune to the fact that words have (possibly unknown) meanings. The extent of infants’ semantic knowledge is not yet known, but exist</context>
<context position="15577" citStr="Dillon et al., 2013" startWordPosition="2507" endWordPosition="2510">of phonetic categories. A draw from a DP, G — DP(α, H), returns a distribution over a set of draws from H, i.e., a discrete distribution over a set of categories or lexemes generated by H. In the mixture model setting, the category assignments are then generated from G, with the datapoints themselves generated by the corresponding components from H. If H is infinite, the support of the DP is likewise infinite. During inference, we marginalize over G. 3.1 Phonetic Categories: IGMM Following previous models of vowel learning (de Boer and Kuhl, 2003; Vallabha et al., 2007; McMurray et al., 2009; Dillon et al., 2013) we assume that vowel tokens are drawn from a Gaussian mixture model. The Infinite Gaussian Mixture Model (IGMM) (Rasmussen, 2000) includes a DP prior, as described above, in which the base distribution HC generates multivariate Gaussians drawn from a Normal Inverse-Wishart prior.5 Each observation, a formant vector wij, is drawn from the Gaussian corresponding to its category assignment cij: µc, Ec — HC = NIW(µo, Eo, ν0) GC — DP(αc, HC) cij — GC wij|cij = c — N(µc, Ec) The above model generates a category assignment cij for each vowel token wij. This is the baseline IGMM model, which clusters</context>
</contexts>
<marker>Dillon, Dunbar, Idsardi, 2013</marker>
<rawString>Brian Dillon, Ewan Dunbar, and William Idsardi. A single-stage approach to learning phonological categories: Insights from Inuktitut. Cognitive Science, 37(2):344–377, Mar 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Micha Elsner</author>
<author>Sharon Goldwater</author>
<author>Naomi Feldman</author>
<author>Frank Wood</author>
</authors>
<title>A cognitive model of early lexical acquisition with phonetic variability.</title>
<date>2013</date>
<booktitle>In Proceedings of the 18th Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<contexts>
<context position="8283" citStr="Elsner et al. (2013)" startWordPosition="1300" endWordPosition="1303">i are its frame fi, which consists of a list of consonants and slots for vowels, and the list of vowel tokens wi. (The TLD model includes additional observations, described below.) A single vowel token, wig, is a two dimensional vector representing the first two formants (peaks in the frequency spectrum, ordered from lowest to highest). For example, a token of the word kitty would have the frame fi = k t , containing two consonant phones, /k/ and /t/, with two vowel phone slots in between, and two vowel formant vectors, 2For a related model that also tackles the word segmentation problem, see Elsner et al. (2013). In a model of phonological learning, Fourtassi and Dupoux (submitted) show that semantic context information similar to that used here remains useful despite segmentation errors. 3500 3000 2500 2000 1500 1000 500 F2 F1 1000 1200 200 400 600 800 iy ei ih ae eh er ah uh oo aw uw oa 1074 wi0 = [464, 2294] and wi1 = [412, 2760].3 Given the data, the model must assign each vowel token to a vowel category, wij = c. Both the LD and the TLD models do this using intermediate lexemes, f, which contain vowel category assignments, vtj = c, as well as a frame ft. If a word token is assigned to a lexeme, </context>
</contexts>
<marker>Elsner, Goldwater, Feldman, Wood, 2013</marker>
<rawString>Micha Elsner, Sharon Goldwater, Naomi Feldman, and Frank Wood. A cognitive model of early lexical acquisition with phonetic variability. In Proceedings of the 18th Conference on Empirical Methods in Natural Language Processing (EMNLP), 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naomi H Feldman</author>
<author>Thomas L Griffiths</author>
<author>Sharon Goldwater</author>
<author>James L Morgan</author>
</authors>
<title>A role for the developing lexicon in phonetic category acquisition. Psychological Review,</title>
<date>2013</date>
<contexts>
<context position="2186" citStr="Feldman et al., 2013" startWordPosition="337" endWordPosition="340">However, due to a widespread assumption that infants do not know the meanings of many words at the age when they are learning phonetic categories (see Swingley, 2009 for a review), most recent models of early phonetic category acquisition have explored the phonetic learning problem in the absence of semantic information (de Boer and Kuhl, 2003; Dillon et al., 2013; 1The models in this paper do not distinguish between phonetic and phonemic categories, since they do not capture phonological processes (and there are also none present in our synthetic data). We thus use the terms interchangeably. Feldman et al., 2013a; McMurray et al., 2009; Vallabha et al., 2007). Models without any semantic information are likely to underestimate infants’ ability to learn phonetic categories. Infants learn language in the wild, and quickly attune to the fact that words have (possibly unknown) meanings. The extent of infants’ semantic knowledge is not yet known, but existing evidence shows that six-month-olds can associate some words with their referents (Bergelson and Swingley, 2012; Tincoff and Jusczyk, 1999, 2012), leverage non-acoustic contexts such as objects or articulations to distinguish similar sounds (Teinonen </context>
<context position="4951" citStr="Feldman et al. (2013" startWordPosition="767" endWordPosition="770">mputational Linguistics lar to that assumed by theories of cross-situational word learning (Frank et al., 2009; Smith and Yu, 2008; Yu and Smith, 2007), but our model does not require learners to map individual words to their referents. Even in the absence of word-meaning mappings, situational information is potentially useful because similar-sounding words uttered in similar situations are more likely to be tokens of the same lexeme (containing the same phones) than similarsounding words uttered in different situations. In simulations of vowel learning, inspired by Vallabha et al. (2007) and Feldman et al. (2013a), we show a clear improvement over previous models in both phonetic and lexical (word-form) categorization when situational context is used as an additional source of information. This improvement is especially noticeable when the word-level context is providing less information, arguably the more realistic setting. These results demonstrate that relying on situational co-occurrence can improve phonetic learning, even if learners do not yet know the meanings of individual words. 2 Background and overview of models Infants attend to distributional characteristics of their input (Maye et al., </context>
<context position="6514" citStr="Feldman et al., 2013" startWordPosition="1004" endWordPosition="1007"> the English vowel space that is the focus of this paper. Recent work has investigated whether infants could overcome such distributional ambiguity by incorporating top-down information, in particular, the fact that phones appear within words. At six months, infants begin to recognize word-forms such as their name and other frequently occurring words (Mandel et al., 1995; Jusczyk and Hohne, 1997), without necessarily linking a meaning to these forms. This “protolexicon” can help differentiate phonetic categories by adding word contexts in which certain sound categories appear (Swingley, 2009; Feldman et al., 2013b). To explore this idea further, Feldman et al. (2013a) implemented the Lexical-Distributional (LD) model, which jointly learns a set of phonetic vowel categories and a set of word-forms containing those categories. Simulations showed that the use of lexical context greatly Figure 1: The English vowel space (generated from Hillenbrand et al. (1995), see Section 6.2), plotted using the first two formants. improved phonetic learning. Our own Topic-Lexical-Distributional (TLD) model extends the LD model to include an additional type of context: the situations in which words appear. To motivate t</context>
<context position="9933" citStr="Feldman et al., 2013" startWordPosition="1594" endWordPosition="1598">nts belong to a single category because the distributions of the categories are so similar. However, a learner who attends to lexical context will notice a difference: contexts that only occur with ae will be observed in one part of the ae-eh region, while contexts that only occur with eh will be observed in a different (though partially overlapping) space. The learner then has evidence of two different categories occurring in different sets of lexemes. Simulations with the LD model show that using lexical information to constrain phonetic learning can greatly improve categorization accuracy (Feldman et al., 2013a), but it can also introduce errors. When two word tokens contain the same consonant frame but different vowels (i.e., minimal pairs), the model is more likely to categorize those two vowels together. Thus, the model has trouble distinguishing minimal pairs. Although young children also have trouble with minimal pairs (Stager and Werker, 1997; Thiessen, 2007), the LD model may overestimate the degree of the problem. We hypothesize that if a learner is able to associate words with the contexts of their use (as children likely are), this could provide a weak source of information for disambigua</context>
<context position="14412" citStr="Feldman et al., 2013" startWordPosition="2308" endWordPosition="2311">t serve as our distinct situations h. As noted above, the learned document-topic distributions θ are treated as observed variables in the TLD model to represent the situational context. The topic-word distributions learned by LDA are discarded, since these are based on the (correct and unambiguous) words in the transcript, whereas the TLD model is presented with phonetically ambiguous versions of these word tokens and must learn to disambiguate them and associate them with topics. 3 Lexical-Distributional Model In this section we describe more formally the generative process for the LD model (Feldman et al., 2013a), a joint Bayesian model over phonetic categories and a lexicon, before describing the TLD extension in the following section. The set of phonetic categories and the lexicon are both modeled using non-parametric Dirichlet Process priors, which return a potentially infinite number of categories or lexemes. A DP is parametrized as DP(α, H), where α is a real-valued hyperparameter and H is a base distribution. H may be continuous, as when it generates phonetic categories in formant space, or discrete, as when it generates lexemes as a list of phonetic categories. A draw from a DP, G — DP(α, H),</context>
<context position="21632" citStr="Feldman et al. (2013" startWordPosition="3581" endWordPosition="3584">n. ate if c exists Pv — cv\` n, +a, nc (14) where nc is the number of other vowels in the lexicon, v\lj, assigned to category c. Note that there is always positive probability of creating a new category. The likelihood of the vowels is calculated by marginalizing over all possible means and variances of the Gaussian category parameters, given fhi xhi zhi θh whij |whi| |xh| D µo, κ0, Σ0, vo A GC GL Gk K αk αc αl µc, Σc 00 HC HL αc + if c new 1077 the NIW prior. For a single point (if |w`j |= 1), this predictive posterior is in the form of a Student-t distribution; for the more general case see Feldman et al. (2013a), Eq. B3. 5.2 Sampling table &amp; topic assignments We jointly sample x and z, the variables assigning tokens to tables and topics. Resampling the table assignment includes the possibility of changing to a table with a different lexeme or drawing a new table with a previously seen or novel lexeme. The joint conditional probability of a table and topic assignment, given all other current token assignments, is: P(xhi = t, zhi = k|whi, θh, t\hi, e, w\hi) = P(k|θh)P(t|k,`t, t\hi) ri p(whi·|v`t· = c, w\hi) (15) c∈C The first factor, the prior probability of topic k in document h, is given by θhk obt</context>
<context position="23515" citStr="Feldman et al. (2013" startWordPosition="3927" endWordPosition="3930">el categories when resampling lexeme vowel assignments. However, here it is calculated over the set of vowels in the token assigned to each vowel category (i.e., the vowels at indices where v`t· = c). For a new lexeme, we approximate the likelihood using 100 samples drawn from the prior, each weighted by α/100 (Neal, 2000). 5.3 Hyperparameters The three hyperparameters governing the HDP over the lexicon, αl and αk, and the DP over vowel categories, αc, are estimated using a slice sampler. The remaining hyperparameters for the vowel category and lexeme priors are set to the same values used by Feldman et al. (2013a). 6 Experiments 6.1 Corpus We test our model on situated child directed speech, taken from the C1 section of the Brent corpus in CHILDES (Brent and Siskind, 2001; MacWhinney, 2000). This corpus consists of transcripts of speech directed at infants between the ages of 9 and 15 months, captured in a naturalistic setting as parent and child went about their day. This ensures variability of situations. Utterances with unintelligible words or quotes are removed. We restrict the corpus to content words by retaining only words tagged as adj, n, part and v (adjectives, nouns, particles, and verbs). </context>
<context position="32011" citStr="Feldman et al. (2013" startWordPosition="5309" endWordPosition="5312">of Gibbs sampling with hyperparameter sampling. Overall, we find that TLD outperforms the other models in both tasks, across all conditions. Vowel categorization results are shown in Figure 3. IGMM performs substantially worse than both TLD and LD, with scores more than 30 points lower than the best results for these models, clearly showing the value of the protolexicon and repliFigure 4: Vowels found by the TLD model; supervowels are indicated in red. The gold-standard vowels are shown in gold in the background but are mostly overlapped by the inferred categories. cating the results found by Feldman et al. (2013a) on this dataset. Furthermore, TLD consistently outperforms the LD model, finding better phonetic categories, both for vowels generated from the combined categories of all speakers (‘all’) and vowels generated from adult female speakers only (‘w’), although the latter are clearly much easier for both models to learn. Both models perform less well when the consonant frames provide less information, but the TLD model performance degrades less than the LD performance. Both the TLD and the LD models find ‘supervowel’ categories, which cover multiple vowel categories and are used to merge minimal</context>
</contexts>
<marker>Feldman, Griffiths, Goldwater, Morgan, 2013</marker>
<rawString>Naomi H. Feldman, Thomas L. Griffiths, Sharon Goldwater, and James L. Morgan. A role for the developing lexicon in phonetic category acquisition. Psychological Review, 2013a.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Naomi H Feldman</author>
<author>Emily B Myers</author>
<author>Katherine S White</author>
<author>Thomas L Griffiths</author>
<author>James L Morgan</author>
</authors>
<title>Word-level information influences phonetic learning in adults and infants.</title>
<journal>Cognition,</journal>
<volume>127</volume>
<issue>3</issue>
<pages>427--438</pages>
<marker>Feldman, Myers, White, Griffiths, Morgan, </marker>
<rawString>Naomi H. Feldman, Emily B. Myers, Katherine S. White, Thomas L. Griffiths, and James L. Morgan. Word-level information influences phonetic learning in adults and infants. Cognition, 127(3): 427–438, 2013b.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Abdellah Fourtassi</author>
<author>Emmanuel Dupoux</author>
</authors>
<title>A rudimentary lexicon and semantics help bootstrap phoneme acquisition.</title>
<note>Submitted.</note>
<marker>Fourtassi, Dupoux, </marker>
<rawString>Abdellah Fourtassi and Emmanuel Dupoux. A rudimentary lexicon and semantics help bootstrap phoneme acquisition. Submitted.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael C Frank</author>
<author>Noah D Goodman</author>
<author>Joshua B Tenenbaum</author>
</authors>
<title>Using speakers’ referential intentions to model early cross-situational word learning.</title>
<date>2009</date>
<journal>Psychological Science,</journal>
<volume>20</volume>
<issue>5</issue>
<pages>578--585</pages>
<contexts>
<context position="4441" citStr="Frank et al., 2009" startWordPosition="686" endWordPosition="689">tions we approximate the environmental information by running a topic model (Blei et al., 2003) over a corpus of childdirected speech to infer a topic distribution for each situation. These topic distributions are then used as input to our model to represent situational contexts. The situational information in our model is simi1073 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1073–1083, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics lar to that assumed by theories of cross-situational word learning (Frank et al., 2009; Smith and Yu, 2008; Yu and Smith, 2007), but our model does not require learners to map individual words to their referents. Even in the absence of word-meaning mappings, situational information is potentially useful because similar-sounding words uttered in similar situations are more likely to be tokens of the same lexeme (containing the same phones) than similarsounding words uttered in different situations. In simulations of vowel learning, inspired by Vallabha et al. (2007) and Feldman et al. (2013a), we show a clear improvement over previous models in both phonetic and lexical (word-fo</context>
</contexts>
<marker>Frank, Goodman, Tenenbaum, 2009</marker>
<rawString>Michael C. Frank, Noah D. Goodman, and Joshua B. Tenenbaum. Using speakers’ referential intentions to model early cross-situational word learning. Psychological Science, 20(5): 578–585, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manuela Friedrich</author>
<author>Angela D Friederici</author>
</authors>
<title>Word learning in 6-month-olds: Fast encoding—weak retention.</title>
<date>2011</date>
<journal>Journal of Cognitive Neuroscience,</journal>
<volume>23</volume>
<pages>11--3228</pages>
<contexts>
<context position="2953" citStr="Friedrich and Friederici, 2011" startWordPosition="455" endWordPosition="458"> learn phonetic categories. Infants learn language in the wild, and quickly attune to the fact that words have (possibly unknown) meanings. The extent of infants’ semantic knowledge is not yet known, but existing evidence shows that six-month-olds can associate some words with their referents (Bergelson and Swingley, 2012; Tincoff and Jusczyk, 1999, 2012), leverage non-acoustic contexts such as objects or articulations to distinguish similar sounds (Teinonen et al., 2008; Yeung and Werker, 2009), and map meaning (in the form of objects or images) to new word-forms in some laboratory settings (Friedrich and Friederici, 2011; Gogate and Bahrick, 2001; Shukla et al., 2011). These findings indicate that young infants are sensitive to co-occurrences between linguistic stimuli and at least some aspects of the world. In this paper we explore the potential contribution of semantic information to phonetic learning by formalizing a model in which learners attend to the word-level context in which phones appear (as in the lexical-phonetic learning model of Feldman et al., 2013a) and also to the situations in which word-forms are used. The modeled situations consist of combinations of categories of salient activities or ob</context>
</contexts>
<marker>Friedrich, Friederici, 2011</marker>
<rawString>Manuela Friedrich and Angela D. Friederici. Word learning in 6-month-olds: Fast encoding—weak retention. Journal of Cognitive Neuroscience, 23 (11):3228–3240, Nov 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lakshmi J Gogate</author>
<author>Lorraine E Bahrick</author>
</authors>
<title>Intersensory redundancy and 7-month-old infants’ memory for arbitrary syllable-object relations.</title>
<date>2001</date>
<journal>Infancy,</journal>
<volume>2</volume>
<issue>2</issue>
<contexts>
<context position="2979" citStr="Gogate and Bahrick, 2001" startWordPosition="459" endWordPosition="462">nts learn language in the wild, and quickly attune to the fact that words have (possibly unknown) meanings. The extent of infants’ semantic knowledge is not yet known, but existing evidence shows that six-month-olds can associate some words with their referents (Bergelson and Swingley, 2012; Tincoff and Jusczyk, 1999, 2012), leverage non-acoustic contexts such as objects or articulations to distinguish similar sounds (Teinonen et al., 2008; Yeung and Werker, 2009), and map meaning (in the form of objects or images) to new word-forms in some laboratory settings (Friedrich and Friederici, 2011; Gogate and Bahrick, 2001; Shukla et al., 2011). These findings indicate that young infants are sensitive to co-occurrences between linguistic stimuli and at least some aspects of the world. In this paper we explore the potential contribution of semantic information to phonetic learning by formalizing a model in which learners attend to the word-level context in which phones appear (as in the lexical-phonetic learning model of Feldman et al., 2013a) and also to the situations in which word-forms are used. The modeled situations consist of combinations of categories of salient activities or objects, similar to the acti</context>
</contexts>
<marker>Gogate, Bahrick, 2001</marker>
<rawString>Lakshmi J. Gogate and Lorraine E. Bahrick. Intersensory redundancy and 7-month-old infants’ memory for arbitrary syllable-object relations. Infancy, 2(2):219–231, Apr 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hillenbrand</author>
<author>L A Getty</author>
<author>M J Clark</author>
<author>K Wheeler</author>
</authors>
<title>Acoustic characteristics of American English vowels.</title>
<date>1995</date>
<journal>Journal of the Acoustical Society ofAmerica, 97(5 Pt</journal>
<volume>1</volume>
<contexts>
<context position="6865" citStr="Hillenbrand et al. (1995)" startWordPosition="1057" endWordPosition="1060"> words (Mandel et al., 1995; Jusczyk and Hohne, 1997), without necessarily linking a meaning to these forms. This “protolexicon” can help differentiate phonetic categories by adding word contexts in which certain sound categories appear (Swingley, 2009; Feldman et al., 2013b). To explore this idea further, Feldman et al. (2013a) implemented the Lexical-Distributional (LD) model, which jointly learns a set of phonetic vowel categories and a set of word-forms containing those categories. Simulations showed that the use of lexical context greatly Figure 1: The English vowel space (generated from Hillenbrand et al. (1995), see Section 6.2), plotted using the first two formants. improved phonetic learning. Our own Topic-Lexical-Distributional (TLD) model extends the LD model to include an additional type of context: the situations in which words appear. To motivate this extension and clarify the differences between the models, we now provide a high-level overview of both models; details are given in Sections 3 and 4. 2.1 Overview of LD model Both the LD and TLD models are computationallevel models of phonetic (specifically, vowel) categorization where phones (vowels) are presented to the model in the context of</context>
<context position="24700" citStr="Hillenbrand et al. (1995)" startWordPosition="4115" endWordPosition="4118">jectives, nouns, particles, and verbs). This is in line with evidence that infants distinguish content and function words on the basis of acoustic signals (Shi and Werker, 2003). Vowel categorization improves when attending only to more prosodically and phonologically salient tokens (Adriaans and Swingley, 2012), which generally appear within content, not function words. The final corpus consists of 13138 tokens and 1497 word types. 6.2 Hillenbrand Vowels The transcripts do not include phonetic information, so, following Feldman et al. (2013a), we synthesize the formant values using data from Hillenbrand et al. (1995). This dataset consists of a set of 1669 manually gathered formant values from 139 American English speakers (men, women and children) for 12 vowels. For each vowel category, we construct a Gaussian from the mean and covariance of the datapoints belonging to that category, using the first and second formant values measured at steady state. We also construct a second dataset using only datapoints from adult female speakers. Each word in the dataset is converted to a phonemic representation using the CMU pronunciation dictionary, which returns a sequence of Arpabet phoneme symbols. If there are </context>
</contexts>
<marker>Hillenbrand, Getty, Clark, Wheeler, 1995</marker>
<rawString>J. Hillenbrand, L. A. Getty, M. J. Clark, and K. Wheeler. Acoustic characteristics of American English vowels. Journal of the Acoustical Society ofAmerica, 97(5 Pt 1):3099–3111, May 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P W Jusczyk</author>
<author>Elizabeth A Hohne</author>
</authors>
<title>Infants’ memory for spoken words.</title>
<date>1997</date>
<journal>Science,</journal>
<volume>277</volume>
<issue>5334</issue>
<pages>1984--1986</pages>
<contexts>
<context position="6293" citStr="Jusczyk and Hohne, 1997" startWordPosition="972" endWordPosition="975">onal learning alone (de Boer and Kuhl, 2003; Vallabha et al., 2007; McMurray et al., 2009). However, this would require sound categories to be well separated, which often is not the case—for example, see Figure 1, which shows the English vowel space that is the focus of this paper. Recent work has investigated whether infants could overcome such distributional ambiguity by incorporating top-down information, in particular, the fact that phones appear within words. At six months, infants begin to recognize word-forms such as their name and other frequently occurring words (Mandel et al., 1995; Jusczyk and Hohne, 1997), without necessarily linking a meaning to these forms. This “protolexicon” can help differentiate phonetic categories by adding word contexts in which certain sound categories appear (Swingley, 2009; Feldman et al., 2013b). To explore this idea further, Feldman et al. (2013a) implemented the Lexical-Distributional (LD) model, which jointly learns a set of phonetic vowel categories and a set of word-forms containing those categories. Simulations showed that the use of lexical context greatly Figure 1: The English vowel space (generated from Hillenbrand et al. (1995), see Section 6.2), plotted </context>
</contexts>
<marker>Jusczyk, Hohne, 1997</marker>
<rawString>P. W. Jusczyk and Elizabeth A. Hohne. Infants’ memory for spoken words. Science, 277(5334): 1984–1986, Sep 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patricia K Kuhl</author>
<author>Karen A Williams</author>
<author>Francisco Lacerda</author>
<author>Kenneth N Stevens</author>
<author>Bjorn Lindblom</author>
</authors>
<title>Linguistic experience alters phonetic perception in infants by 6 months of age.</title>
<date>1992</date>
<journal>Science,</journal>
<volume>255</volume>
<issue>5044</issue>
<contexts>
<context position="1344" citStr="Kuhl et al., 1992" startWordPosition="202" endWordPosition="205">ants learning phonetic categories. We show that attending to a weaker source of semantics, in the form of a distribution over topics in the current context, can lead to improvements in phonetic category learning. In our model, an extension of a previous model of joint word-form and phonetic category inference, the probability of word-forms is topic-dependent, enabling the model to find significantly better phonetic vowel categories and word-forms than a model with no semantic knowledge. 1 Introduction Infants begin learning the phonetic categories of their native language in their first year (Kuhl et al., 1992; Polka and Werker, 1994; Werker and Tees, 1984). In theory, semantic information could offer a valuable cue for phoneme induction1 by helping infants distinguish between minimal pairs, as linguists do (Trubetzkoy, 1939). However, due to a widespread assumption that infants do not know the meanings of many words at the age when they are learning phonetic categories (see Swingley, 2009 for a review), most recent models of early phonetic category acquisition have explored the phonetic learning problem in the absence of semantic information (de Boer and Kuhl, 2003; Dillon et al., 2013; 1The model</context>
</contexts>
<marker>Kuhl, Williams, Lacerda, Stevens, Lindblom, 1992</marker>
<rawString>Patricia K. Kuhl, Karen A. Williams, Francisco Lacerda, Kenneth N. Stevens, and Bjorn Lindblom. Linguistic experience alters phonetic perception in infants by 6 months of age. Science, 255(5044):606–608, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian MacWhinney</author>
</authors>
<title>The CHILDES Project: Tools for Analyzing Talk. Lawrence Erlbaum Associates,</title>
<date>2000</date>
<contexts>
<context position="23697" citStr="MacWhinney, 2000" startWordPosition="3959" endWordPosition="3960">here v`t· = c). For a new lexeme, we approximate the likelihood using 100 samples drawn from the prior, each weighted by α/100 (Neal, 2000). 5.3 Hyperparameters The three hyperparameters governing the HDP over the lexicon, αl and αk, and the DP over vowel categories, αc, are estimated using a slice sampler. The remaining hyperparameters for the vowel category and lexeme priors are set to the same values used by Feldman et al. (2013a). 6 Experiments 6.1 Corpus We test our model on situated child directed speech, taken from the C1 section of the Brent corpus in CHILDES (Brent and Siskind, 2001; MacWhinney, 2000). This corpus consists of transcripts of speech directed at infants between the ages of 9 and 15 months, captured in a naturalistic setting as parent and child went about their day. This ensures variability of situations. Utterances with unintelligible words or quotes are removed. We restrict the corpus to content words by retaining only words tagged as adj, n, part and v (adjectives, nouns, particles, and verbs). This is in line with evidence that infants distinguish content and function words on the basis of acoustic signals (Shi and Werker, 2003). Vowel categorization improves when attendin</context>
</contexts>
<marker>MacWhinney, 2000</marker>
<rawString>Brian MacWhinney. The CHILDES Project: Tools for Analyzing Talk. Lawrence Erlbaum Associates, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Mandel</author>
<author>P W Jusczyk</author>
<author>D B Pisoni</author>
</authors>
<title>Infants’ recognition of the sound patterns of their own names.</title>
<date>1995</date>
<journal>Psychological Science,</journal>
<volume>6</volume>
<issue>5</issue>
<pages>317</pages>
<contexts>
<context position="6267" citStr="Mandel et al., 1995" startWordPosition="968" endWordPosition="971"> bottom-up distributional learning alone (de Boer and Kuhl, 2003; Vallabha et al., 2007; McMurray et al., 2009). However, this would require sound categories to be well separated, which often is not the case—for example, see Figure 1, which shows the English vowel space that is the focus of this paper. Recent work has investigated whether infants could overcome such distributional ambiguity by incorporating top-down information, in particular, the fact that phones appear within words. At six months, infants begin to recognize word-forms such as their name and other frequently occurring words (Mandel et al., 1995; Jusczyk and Hohne, 1997), without necessarily linking a meaning to these forms. This “protolexicon” can help differentiate phonetic categories by adding word contexts in which certain sound categories appear (Swingley, 2009; Feldman et al., 2013b). To explore this idea further, Feldman et al. (2013a) implemented the Lexical-Distributional (LD) model, which jointly learns a set of phonetic vowel categories and a set of word-forms containing those categories. Simulations showed that the use of lexical context greatly Figure 1: The English vowel space (generated from Hillenbrand et al. (1995), </context>
</contexts>
<marker>Mandel, Jusczyk, Pisoni, 1995</marker>
<rawString>D. R. Mandel, P. W. Jusczyk, and D. B. Pisoni. Infants’ recognition of the sound patterns of their own names. Psychological Science, 6(5):314– 317, Sep 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nivedita Mani</author>
<author>Kim Plunkett</author>
</authors>
<title>Twelve-montholds know their cups from their keps and tups.</title>
<date>2010</date>
<journal>Infancy,</journal>
<volume>15</volume>
<issue>5</issue>
<contexts>
<context position="26346" citStr="Mani and Plunkett (2010)" startWordPosition="4381" endWordPosition="4384">ng the full set of consonants—the ‘C24’ dataset—and with less fine-grained consonant categories. Distinguishing all consonant categories assumes perfect learning of consonants prior to vowel categorization and is thus somewhat unrealistic (Polka and Werker, 1994), but provides an upper limit on the information that word-contexts can give. In the ‘C15’ dataset, the voicing distinction is collapsed, leaving 15 consonant categories. The collapsed categories are B/P, G/K, D/T, CH/JH, V/F, TH/DH, S/Z, SH/ZH, R/L while HH, M, NG, N, W, Y remain separate phonemes. This dataset mirrors the finding in Mani and Plunkett (2010) that 12 month old infants are not sensitive to voicing mispronunciations. The ‘C6’ dataset distinguishes between only 6 coarse consonant phonemes, corresponding to stops (B,P,G,K,D,T), affricates (CH,JH), fricatives (V, F, TH, DH, S, Z, SH, ZH, HH), nasals (M, NG, N), liquids (R, L), and semivowels/glides (W, Y). This dataset makes minimal assumptions about the category categories that infants could use in this learning setting. Decreasing the number of consonants increases the ambiguity in the corpus: bat not only shares a frame (b t) with boat and bite, but also, in the C15 dataset, with pu</context>
</contexts>
<marker>Mani, Plunkett, 2010</marker>
<rawString>Nivedita Mani and Kim Plunkett. Twelve-montholds know their cups from their keps and tups. Infancy, 15(5):445470, Sep 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jessica Maye</author>
<author>Daniel J Weiss</author>
<author>Richard N Aslin</author>
</authors>
<title>Statistical phonetic learning in infants: facilitation and feature generalization.</title>
<date>2008</date>
<journal>Developmental Science,</journal>
<volume>11</volume>
<issue>1</issue>
<marker>Maye, Weiss, Aslin, 2008</marker>
<rawString>Jessica Maye, Daniel J. Weiss, and Richard N. Aslin. Statistical phonetic learning in infants: facilitation and feature generalization. Developmental Science, 11(1):122–134, Jan 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jessica Maye</author>
<author>Janet F Werker</author>
<author>LouAnn Gerken</author>
</authors>
<title>Infant sensitivity to distributional information can affect phonetic discrimination.</title>
<date>2002</date>
<journal>Cognition,</journal>
<volume>82</volume>
<issue>3</issue>
<contexts>
<context position="5555" citStr="Maye et al., 2002" startWordPosition="857" endWordPosition="860"> et al. (2013a), we show a clear improvement over previous models in both phonetic and lexical (word-form) categorization when situational context is used as an additional source of information. This improvement is especially noticeable when the word-level context is providing less information, arguably the more realistic setting. These results demonstrate that relying on situational co-occurrence can improve phonetic learning, even if learners do not yet know the meanings of individual words. 2 Background and overview of models Infants attend to distributional characteristics of their input (Maye et al., 2002, 2008), leading to the hypothesis that phonetic categories could be acquired on the basis of bottom-up distributional learning alone (de Boer and Kuhl, 2003; Vallabha et al., 2007; McMurray et al., 2009). However, this would require sound categories to be well separated, which often is not the case—for example, see Figure 1, which shows the English vowel space that is the focus of this paper. Recent work has investigated whether infants could overcome such distributional ambiguity by incorporating top-down information, in particular, the fact that phones appear within words. At six months, in</context>
</contexts>
<marker>Maye, Werker, Gerken, 2002</marker>
<rawString>Jessica Maye, Janet F Werker, and LouAnn Gerken. Infant sensitivity to distributional information can affect phonetic discrimination. Cognition, 82(3):B101–B111, Jan 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
</authors>
<title>MALLET: A machine learning for language toolkit,</title>
<date>2002</date>
<contexts>
<context position="28801" citStr="McCallum, 2002" startWordPosition="4791" endWordPosition="4792">to gold orthographic word types, of which there are 1497). Ambiguous types and tokens are those with frames that match multiple (orthographic) word types. situations, so we do this somewhat arbitrarily by splitting each transcript after 50 CDS utterances, resulting in 203 situations for the Brent C1 dataset. As well as function words, we also remove the five most frequent content words (be, go, get, want, come). On average, situations are only 59 words long, reflecting the relative lack of content words in CDS utterances. We infer 50 topics for this set of situations using the mallet toolkit (McCallum, 2002). Hyperparameters are inferred, which leads to a dominant topic that includes mainly light verbs (have, let, see, do). The other topics are less frequent but capture stronger semantic meaning (e.g. yummy, peach, cookie, daddy, bib in one topic, shoe, let, put, hat, pants in another). The word-topic assignments are used to calculate unsmoothed situation-topic distributions θ used by the TLD model. 6.5 Evaluation We evaluate against adult categories, i.e., the ‘goldstandard’, since all learners of a language eventually converge on similar categories. (Since our model is not a model of the learni</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>Andrew McCallum. MALLET: A machine learning for language toolkit, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob McMurray</author>
<author>Richard N Aslin</author>
<author>Joseph C Toscano</author>
</authors>
<title>Statistical learning of phonetic categories: insights from a computational approach.</title>
<date>2009</date>
<journal>Developmental Science,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="2210" citStr="McMurray et al., 2009" startWordPosition="341" endWordPosition="344">pread assumption that infants do not know the meanings of many words at the age when they are learning phonetic categories (see Swingley, 2009 for a review), most recent models of early phonetic category acquisition have explored the phonetic learning problem in the absence of semantic information (de Boer and Kuhl, 2003; Dillon et al., 2013; 1The models in this paper do not distinguish between phonetic and phonemic categories, since they do not capture phonological processes (and there are also none present in our synthetic data). We thus use the terms interchangeably. Feldman et al., 2013a; McMurray et al., 2009; Vallabha et al., 2007). Models without any semantic information are likely to underestimate infants’ ability to learn phonetic categories. Infants learn language in the wild, and quickly attune to the fact that words have (possibly unknown) meanings. The extent of infants’ semantic knowledge is not yet known, but existing evidence shows that six-month-olds can associate some words with their referents (Bergelson and Swingley, 2012; Tincoff and Jusczyk, 1999, 2012), leverage non-acoustic contexts such as objects or articulations to distinguish similar sounds (Teinonen et al., 2008; Yeung and </context>
<context position="5759" citStr="McMurray et al., 2009" startWordPosition="889" endWordPosition="892"> improvement is especially noticeable when the word-level context is providing less information, arguably the more realistic setting. These results demonstrate that relying on situational co-occurrence can improve phonetic learning, even if learners do not yet know the meanings of individual words. 2 Background and overview of models Infants attend to distributional characteristics of their input (Maye et al., 2002, 2008), leading to the hypothesis that phonetic categories could be acquired on the basis of bottom-up distributional learning alone (de Boer and Kuhl, 2003; Vallabha et al., 2007; McMurray et al., 2009). However, this would require sound categories to be well separated, which often is not the case—for example, see Figure 1, which shows the English vowel space that is the focus of this paper. Recent work has investigated whether infants could overcome such distributional ambiguity by incorporating top-down information, in particular, the fact that phones appear within words. At six months, infants begin to recognize word-forms such as their name and other frequently occurring words (Mandel et al., 1995; Jusczyk and Hohne, 1997), without necessarily linking a meaning to these forms. This “prot</context>
<context position="15555" citStr="McMurray et al., 2009" startWordPosition="2502" endWordPosition="2506">ates lexemes as a list of phonetic categories. A draw from a DP, G — DP(α, H), returns a distribution over a set of draws from H, i.e., a discrete distribution over a set of categories or lexemes generated by H. In the mixture model setting, the category assignments are then generated from G, with the datapoints themselves generated by the corresponding components from H. If H is infinite, the support of the DP is likewise infinite. During inference, we marginalize over G. 3.1 Phonetic Categories: IGMM Following previous models of vowel learning (de Boer and Kuhl, 2003; Vallabha et al., 2007; McMurray et al., 2009; Dillon et al., 2013) we assume that vowel tokens are drawn from a Gaussian mixture model. The Infinite Gaussian Mixture Model (IGMM) (Rasmussen, 2000) includes a DP prior, as described above, in which the base distribution HC generates multivariate Gaussians drawn from a Normal Inverse-Wishart prior.5 Each observation, a formant vector wij, is drawn from the Gaussian corresponding to its category assignment cij: µc, Ec — HC = NIW(µo, Eo, ν0) GC — DP(αc, HC) cij — GC wij|cij = c — N(µc, Ec) The above model generates a category assignment cij for each vowel token wij. This is the baseline IGMM</context>
</contexts>
<marker>McMurray, Aslin, Toscano, 2009</marker>
<rawString>Bob McMurray, Richard N. Aslin, and Joseph C. Toscano. Statistical learning of phonetic categories: insights from a computational approach. Developmental Science, 12(3):369–378, May 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tamara Nicol Medina</author>
<author>Jesse Snedeker</author>
<author>John C Trueswell</author>
<author>Lila R Gleitman</author>
</authors>
<title>How words can and cannot be learned by observation.</title>
<date>2011</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>108</volume>
<issue>22</issue>
<contexts>
<context position="35681" citStr="Medina et al., 2011" startWordPosition="5881" endWordPosition="5884">ntially used in other linguistic learning tasks. Theories of cross-situational word learning (Smith and Yu, 2008; Yu and Smith, 2007) assume that sensitivity to situational co-occurrences between words and non-linguistic contexts is a precursor to learning the meanings of individual words. Under this view, contextual semantics is available to infants well before they have acquired large numbers of semantic minimal pairs. However, recent experimental evidence indicates that learners do not always retain detailed information about the referents that are present in a scene when they hear a word (Medina et al., 2011; Trueswell et al., 2013). This evidence poses a direct challenge to theories of cross-situational word learning. Our account does not necessarily require learners to track co-occurrences between words and individual objects, but instead focuses on more abstract information about salient events and topics in the environment; it will be important to investigate to what extent infants encode this information and use it in phonetic learning. Regardless of the specific way in which infants encode semantic information, our method of adding this information by using LDA topics from transcript data w</context>
</contexts>
<marker>Medina, Snedeker, Trueswell, Gleitman, 2011</marker>
<rawString>Tamara Nicol Medina, Jesse Snedeker, John C. Trueswell, and Lila R. Gleitman. How words can and cannot be learned by observation. Proceedings of the National Academy of Sciences, 108(22):9014–9019, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radford Neal</author>
</authors>
<title>Markov chain sampling methods for Dirichlet process mixture models.</title>
<date>2000</date>
<journal>Journal of Computational and Graphical Statistics,</journal>
<volume>9</volume>
<pages>249--265</pages>
<contexts>
<context position="23219" citStr="Neal, 2000" startWordPosition="3879" endWordPosition="3880">e the total number of tokens in topic k, m` is the number of tables across all topics with the lexeme `, and m is the total number of tables. The third factor, the likelihood of the vowel formants whi in the categories given by the lexeme vl, is of the same form as the likelihood of vowel categories when resampling lexeme vowel assignments. However, here it is calculated over the set of vowels in the token assigned to each vowel category (i.e., the vowels at indices where v`t· = c). For a new lexeme, we approximate the likelihood using 100 samples drawn from the prior, each weighted by α/100 (Neal, 2000). 5.3 Hyperparameters The three hyperparameters governing the HDP over the lexicon, αl and αk, and the DP over vowel categories, αc, are estimated using a slice sampler. The remaining hyperparameters for the vowel category and lexeme priors are set to the same values used by Feldman et al. (2013a). 6 Experiments 6.1 Corpus We test our model on situated child directed speech, taken from the C1 section of the Brent corpus in CHILDES (Brent and Siskind, 2001; MacWhinney, 2000). This corpus consists of transcripts of speech directed at infants between the ages of 9 and 15 months, captured in a nat</context>
</contexts>
<marker>Neal, 2000</marker>
<rawString>Radford Neal. Markov chain sampling methods for Dirichlet process mixture models. Journal of Computational and Graphical Statistics, 9: 249–265, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linda Polka</author>
<author>Janet F Werker</author>
</authors>
<title>Developmental changes in perception of nonnative vowel contrasts.</title>
<date>1994</date>
<journal>Journal of Experimental Psychology: Human Perception and Performance,</journal>
<volume>20</volume>
<issue>2</issue>
<pages>435</pages>
<contexts>
<context position="1368" citStr="Polka and Werker, 1994" startWordPosition="206" endWordPosition="209">tic categories. We show that attending to a weaker source of semantics, in the form of a distribution over topics in the current context, can lead to improvements in phonetic category learning. In our model, an extension of a previous model of joint word-form and phonetic category inference, the probability of word-forms is topic-dependent, enabling the model to find significantly better phonetic vowel categories and word-forms than a model with no semantic knowledge. 1 Introduction Infants begin learning the phonetic categories of their native language in their first year (Kuhl et al., 1992; Polka and Werker, 1994; Werker and Tees, 1984). In theory, semantic information could offer a valuable cue for phoneme induction1 by helping infants distinguish between minimal pairs, as linguists do (Trubetzkoy, 1939). However, due to a widespread assumption that infants do not know the meanings of many words at the age when they are learning phonetic categories (see Swingley, 2009 for a review), most recent models of early phonetic category acquisition have explored the phonetic learning problem in the absence of semantic information (de Boer and Kuhl, 2003; Dillon et al., 2013; 1The models in this paper do not d</context>
<context position="25985" citStr="Polka and Werker, 1994" startWordPosition="4323" endWordPosition="4326">vowel phoneme in the word is then replaced by formant values drawn from the corresponding Hillenbrand Gaussian for that vowel. P(t|k, `, t\hi) ∝ { nkt if t in k nk+αk αk nk+αk m` if t new, ` known m+αl αk nk+αk 1078 6.3 Merging Consonant Categories The Arpabet encoding used in the phonemic representation includes 24 consonants. We construct datasets both using the full set of consonants—the ‘C24’ dataset—and with less fine-grained consonant categories. Distinguishing all consonant categories assumes perfect learning of consonants prior to vowel categorization and is thus somewhat unrealistic (Polka and Werker, 1994), but provides an upper limit on the information that word-contexts can give. In the ‘C15’ dataset, the voicing distinction is collapsed, leaving 15 consonant categories. The collapsed categories are B/P, G/K, D/T, CH/JH, V/F, TH/DH, S/Z, SH/ZH, R/L while HH, M, NG, N, W, Y remain separate phonemes. This dataset mirrors the finding in Mani and Plunkett (2010) that 12 month old infants are not sensitive to voicing mispronunciations. The ‘C6’ dataset distinguishes between only 6 coarse consonant phonemes, corresponding to stops (B,P,G,K,D,T), affricates (CH,JH), fricatives (V, F, TH, DH, S, Z, S</context>
</contexts>
<marker>Polka, Werker, 1994</marker>
<rawString>Linda Polka and Janet F. Werker. Developmental changes in perception of nonnative vowel contrasts. Journal of Experimental Psychology: Human Perception and Performance, 20(2):421– 435, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Rasmussen</author>
</authors>
<title>The infinite Gaussian mixture model.</title>
<date>2000</date>
<booktitle>In Advances in Neural Information Processing Systems 13,</booktitle>
<contexts>
<context position="15707" citStr="Rasmussen, 2000" startWordPosition="2530" endWordPosition="2531">on over a set of categories or lexemes generated by H. In the mixture model setting, the category assignments are then generated from G, with the datapoints themselves generated by the corresponding components from H. If H is infinite, the support of the DP is likewise infinite. During inference, we marginalize over G. 3.1 Phonetic Categories: IGMM Following previous models of vowel learning (de Boer and Kuhl, 2003; Vallabha et al., 2007; McMurray et al., 2009; Dillon et al., 2013) we assume that vowel tokens are drawn from a Gaussian mixture model. The Infinite Gaussian Mixture Model (IGMM) (Rasmussen, 2000) includes a DP prior, as described above, in which the base distribution HC generates multivariate Gaussians drawn from a Normal Inverse-Wishart prior.5 Each observation, a formant vector wij, is drawn from the Gaussian corresponding to its category assignment cij: µc, Ec — HC = NIW(µo, Eo, ν0) GC — DP(αc, HC) cij — GC wij|cij = c — N(µc, Ec) The above model generates a category assignment cij for each vowel token wij. This is the baseline IGMM model, which clusters vowel tokens using bottom-up distributional information only; the LD model adds top-down information by assigning categories in t</context>
</contexts>
<marker>Rasmussen, 2000</marker>
<rawString>Carl Rasmussen. The infinite Gaussian mixture model. In Advances in Neural Information Processing Systems 13, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Rosenberg</author>
<author>Julia Hirschberg</author>
</authors>
<title>Vmeasure: A conditional entropy-based external cluster evaluation measure.</title>
<date>2007</date>
<booktitle>In Proceedings of the 12th Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<contexts>
<context position="29633" citStr="Rosenberg and Hirschberg, 2007" startWordPosition="4919" endWordPosition="4922">my, peach, cookie, daddy, bib in one topic, shoe, let, put, hat, pants in another). The word-topic assignments are used to calculate unsmoothed situation-topic distributions θ used by the TLD model. 6.5 Evaluation We evaluate against adult categories, i.e., the ‘goldstandard’, since all learners of a language eventually converge on similar categories. (Since our model is not a model of the learning process, we do not compare the infant learning process to the learning algorithm.) We evaluate both the inferred phonetic categories and words using the clustering evaluation measure V-Measure (VM; Rosenberg and Hirschberg, 2007).6 VM is the harmonic mean of two components, similar to F-score, where the components (VC and VH) are measures of cross entropy between the gold and model categorization. 6Other clustering measures, such as 1-1 matching and pairwise precision and recall (accuracy and completeness) showed the same trends, but VM has been demonstrated to be the most stable measure when comparing solutions with varying numbers of clusters (Christodoulopoulos et al., 2010). 1079 LD-all TLD-all LD-w TLD-w 24 Cons 15 Cons 6 Cons VM 90 85 80 75 3500 3000 2500 2000 F2 1500 1000 500 F1 1000 1200 400 200 600 800 Datase</context>
</contexts>
<marker>Rosenberg, Hirschberg, 2007</marker>
<rawString>Andrew Rosenberg and Julia Hirschberg. Vmeasure: A conditional entropy-based external cluster evaluation measure. In Proceedings of the 12th Conference on Empirical Methods in Natural Language Processing (EMNLP), 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brandon C Roy</author>
<author>Michael C Frank</author>
<author>Deb Roy</author>
</authors>
<title>Relating activity contexts to early word learning in dense longitudinal data.</title>
<date>2012</date>
<booktitle>In Proceedings of the 34th Annual Conference of the Cognitive Science Society (CogSci),</booktitle>
<contexts>
<context position="3622" citStr="Roy et al. (2012)" startWordPosition="563" endWordPosition="566">ese findings indicate that young infants are sensitive to co-occurrences between linguistic stimuli and at least some aspects of the world. In this paper we explore the potential contribution of semantic information to phonetic learning by formalizing a model in which learners attend to the word-level context in which phones appear (as in the lexical-phonetic learning model of Feldman et al., 2013a) and also to the situations in which word-forms are used. The modeled situations consist of combinations of categories of salient activities or objects, similar to the activity contexts explored by Roy et al. (2012), e.g.,‘getting dressed’ or ‘eating breakfast’. We assume that child learners are able to infer a representation of the situational context from their non-linguistic environment. However, in our simulations we approximate the environmental information by running a topic model (Blei et al., 2003) over a corpus of childdirected speech to infer a topic distribution for each situation. These topic distributions are then used as input to our model to represent situational contexts. The situational information in our model is simi1073 Proceedings of the 52nd Annual Meeting of the Association for Com</context>
<context position="13357" citStr="Roy et al. (2012)" startWordPosition="2140" endWordPosition="2143">g words in different situations with mostly non-overlapping topics will provide evidence that those words belong to different topics and that they are therefore different lexemes. Conversely, potential minimal pairs that occur in situations with similar topic distributions are more likely to belong to the same topic and thus the same lexeme. Although we assume that children infer topic distributions from the non-linguistic environment, we will use transcripts from CHILDES to create the word/phone learning input for our model. These transcripts are not annotated with environmental context, but Roy et al. (2012) found that topics learned from similar transcript data using a topic model were strongly correlated with immediate activities and contexts. We therefore obtain the topic distributions used as input to the TLD model by 1075 training an LDA topic model (Blei et al., 2003) on a superset of the child-directed transcript data we use for lexical-phonetic learning, dividing the transcripts into small sections (the ‘documents’ in LDA) that serve as our distinct situations h. As noted above, the learned document-topic distributions θ are treated as observed variables in the TLD model to represent the </context>
</contexts>
<marker>Roy, Frank, Roy, 2012</marker>
<rawString>Brandon C. Roy, Michael C. Frank, and Deb Roy. Relating activity contexts to early word learning in dense longitudinal data. In Proceedings of the 34th Annual Conference of the Cognitive Science Society (CogSci), 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rushen Shi</author>
<author>Janet F Werker</author>
</authors>
<title>The basis of preference for lexical words in 6-month-old infants.</title>
<date>2003</date>
<journal>Developmental Science,</journal>
<volume>6</volume>
<issue>5</issue>
<contexts>
<context position="24252" citStr="Shi and Werker, 2003" startWordPosition="4048" endWordPosition="4051">rent corpus in CHILDES (Brent and Siskind, 2001; MacWhinney, 2000). This corpus consists of transcripts of speech directed at infants between the ages of 9 and 15 months, captured in a naturalistic setting as parent and child went about their day. This ensures variability of situations. Utterances with unintelligible words or quotes are removed. We restrict the corpus to content words by retaining only words tagged as adj, n, part and v (adjectives, nouns, particles, and verbs). This is in line with evidence that infants distinguish content and function words on the basis of acoustic signals (Shi and Werker, 2003). Vowel categorization improves when attending only to more prosodically and phonologically salient tokens (Adriaans and Swingley, 2012), which generally appear within content, not function words. The final corpus consists of 13138 tokens and 1497 word types. 6.2 Hillenbrand Vowels The transcripts do not include phonetic information, so, following Feldman et al. (2013a), we synthesize the formant values using data from Hillenbrand et al. (1995). This dataset consists of a set of 1669 manually gathered formant values from 139 American English speakers (men, women and children) for 12 vowels. Fo</context>
</contexts>
<marker>Shi, Werker, 2003</marker>
<rawString>Rushen Shi and Janet F. Werker. The basis of preference for lexical words in 6-month-old infants. Developmental Science, 6(5):484–488, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Shukla</author>
<author>K S White</author>
<author>R N Aslin</author>
</authors>
<title>Prosody guides the rapid mapping of auditory word forms onto visual objects in 6-mo-old infants.</title>
<date>2011</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>108</volume>
<pages>15--6038</pages>
<contexts>
<context position="3001" citStr="Shukla et al., 2011" startWordPosition="463" endWordPosition="466">wild, and quickly attune to the fact that words have (possibly unknown) meanings. The extent of infants’ semantic knowledge is not yet known, but existing evidence shows that six-month-olds can associate some words with their referents (Bergelson and Swingley, 2012; Tincoff and Jusczyk, 1999, 2012), leverage non-acoustic contexts such as objects or articulations to distinguish similar sounds (Teinonen et al., 2008; Yeung and Werker, 2009), and map meaning (in the form of objects or images) to new word-forms in some laboratory settings (Friedrich and Friederici, 2011; Gogate and Bahrick, 2001; Shukla et al., 2011). These findings indicate that young infants are sensitive to co-occurrences between linguistic stimuli and at least some aspects of the world. In this paper we explore the potential contribution of semantic information to phonetic learning by formalizing a model in which learners attend to the word-level context in which phones appear (as in the lexical-phonetic learning model of Feldman et al., 2013a) and also to the situations in which word-forms are used. The modeled situations consist of combinations of categories of salient activities or objects, similar to the activity contexts explored</context>
</contexts>
<marker>Shukla, White, Aslin, 2011</marker>
<rawString>M. Shukla, K. S. White, and R. N. Aslin. Prosody guides the rapid mapping of auditory word forms onto visual objects in 6-mo-old infants. Proceedings of the National Academy of Sciences, 108 (15):6038–6043, Apr 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linda B Smith</author>
<author>Chen Yu</author>
</authors>
<title>Infants rapidly learn word-referent mappings via cross-situational statistics.</title>
<date>2008</date>
<journal>Cognition,</journal>
<volume>106</volume>
<issue>3</issue>
<contexts>
<context position="4461" citStr="Smith and Yu, 2008" startWordPosition="690" endWordPosition="693"> the environmental information by running a topic model (Blei et al., 2003) over a corpus of childdirected speech to infer a topic distribution for each situation. These topic distributions are then used as input to our model to represent situational contexts. The situational information in our model is simi1073 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1073–1083, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics lar to that assumed by theories of cross-situational word learning (Frank et al., 2009; Smith and Yu, 2008; Yu and Smith, 2007), but our model does not require learners to map individual words to their referents. Even in the absence of word-meaning mappings, situational information is potentially useful because similar-sounding words uttered in similar situations are more likely to be tokens of the same lexeme (containing the same phones) than similarsounding words uttered in different situations. In simulations of vowel learning, inspired by Vallabha et al. (2007) and Feldman et al. (2013a), we show a clear improvement over previous models in both phonetic and lexical (word-form) categorization w</context>
<context position="35174" citStr="Smith and Yu, 2008" startWordPosition="5803" endWordPosition="5806">here there is a high degree of phonetic ambiguity in the word-forms that learners hear. This suggests that previous models that have ignored semantic information may have underestimated the information that is available to infants. Our model illustrates one way in which language learners might harness the rich information that is present in the world without first needing to acquire a full inventory of word meanings. The contextual semantic information that the TLD model tracks is similar to that potentially used in other linguistic learning tasks. Theories of cross-situational word learning (Smith and Yu, 2008; Yu and Smith, 2007) assume that sensitivity to situational co-occurrences between words and non-linguistic contexts is a precursor to learning the meanings of individual words. Under this view, contextual semantics is available to infants well before they have acquired large numbers of semantic minimal pairs. However, recent experimental evidence indicates that learners do not always retain detailed information about the referents that are present in a scene when they hear a word (Medina et al., 2011; Trueswell et al., 2013). This evidence poses a direct challenge to theories of cross-situat</context>
</contexts>
<marker>Smith, Yu, 2008</marker>
<rawString>Linda B. Smith and Chen Yu. Infants rapidly learn word-referent mappings via cross-situational statistics. Cognition, 106(3):1558–1568, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christine L Stager</author>
<author>Janet F Werker</author>
</authors>
<title>Infants listen for more phonetic detail in speech perception than in word-learning tasks.</title>
<date>1997</date>
<journal>Nature,</journal>
<volume>388</volume>
<pages>381--382</pages>
<contexts>
<context position="10278" citStr="Stager and Werker, 1997" startWordPosition="1649" endWordPosition="1652">erlapping) space. The learner then has evidence of two different categories occurring in different sets of lexemes. Simulations with the LD model show that using lexical information to constrain phonetic learning can greatly improve categorization accuracy (Feldman et al., 2013a), but it can also introduce errors. When two word tokens contain the same consonant frame but different vowels (i.e., minimal pairs), the model is more likely to categorize those two vowels together. Thus, the model has trouble distinguishing minimal pairs. Although young children also have trouble with minimal pairs (Stager and Werker, 1997; Thiessen, 2007), the LD model may overestimate the degree of the problem. We hypothesize that if a learner is able to associate words with the contexts of their use (as children likely are), this could provide a weak source of information for disambiguating minimal pairs even without knowing their exact meanings. That is, if the learner hears kV1t and kV2t in different situational contexts, they are likely to be different lexical items (and V1 and V2 different phones), despite the lexical similarity between them. 3In simulations we also experiment with frames in which consonants are not repr</context>
</contexts>
<marker>Stager, Werker, 1997</marker>
<rawString>Christine L. Stager and Janet F. Werker. Infants listen for more phonetic detail in speech perception than in word-learning tasks. Nature, 388: 381–382, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Swingley</author>
</authors>
<title>Contributions of infant word learning to language development.</title>
<date>2009</date>
<journal>Philosophical Transactions of the Royal Society B: Biological Sciences,</journal>
<volume>364</volume>
<issue>1536</issue>
<contexts>
<context position="1731" citStr="Swingley, 2009" startWordPosition="265" endWordPosition="266">ignificantly better phonetic vowel categories and word-forms than a model with no semantic knowledge. 1 Introduction Infants begin learning the phonetic categories of their native language in their first year (Kuhl et al., 1992; Polka and Werker, 1994; Werker and Tees, 1984). In theory, semantic information could offer a valuable cue for phoneme induction1 by helping infants distinguish between minimal pairs, as linguists do (Trubetzkoy, 1939). However, due to a widespread assumption that infants do not know the meanings of many words at the age when they are learning phonetic categories (see Swingley, 2009 for a review), most recent models of early phonetic category acquisition have explored the phonetic learning problem in the absence of semantic information (de Boer and Kuhl, 2003; Dillon et al., 2013; 1The models in this paper do not distinguish between phonetic and phonemic categories, since they do not capture phonological processes (and there are also none present in our synthetic data). We thus use the terms interchangeably. Feldman et al., 2013a; McMurray et al., 2009; Vallabha et al., 2007). Models without any semantic information are likely to underestimate infants’ ability to learn p</context>
<context position="6492" citStr="Swingley, 2009" startWordPosition="1002" endWordPosition="1003">e 1, which shows the English vowel space that is the focus of this paper. Recent work has investigated whether infants could overcome such distributional ambiguity by incorporating top-down information, in particular, the fact that phones appear within words. At six months, infants begin to recognize word-forms such as their name and other frequently occurring words (Mandel et al., 1995; Jusczyk and Hohne, 1997), without necessarily linking a meaning to these forms. This “protolexicon” can help differentiate phonetic categories by adding word contexts in which certain sound categories appear (Swingley, 2009; Feldman et al., 2013b). To explore this idea further, Feldman et al. (2013a) implemented the Lexical-Distributional (LD) model, which jointly learns a set of phonetic vowel categories and a set of word-forms containing those categories. Simulations showed that the use of lexical context greatly Figure 1: The English vowel space (generated from Hillenbrand et al. (1995), see Section 6.2), plotted using the first two formants. improved phonetic learning. Our own Topic-Lexical-Distributional (TLD) model extends the LD model to include an additional type of context: the situations in which words</context>
</contexts>
<marker>Swingley, 2009</marker>
<rawString>D. Swingley. Contributions of infant word learning to language development. Philosophical Transactions of the Royal Society B: Biological Sciences, 364(1536):3617–3632, Nov 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Whye Teh</author>
</authors>
<title>A hierarchical Bayesian language model based on Pitman-Yor processes.</title>
<date>2006</date>
<booktitle>In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics (ACL), pages 985 – 992,</booktitle>
<location>Sydney,</location>
<contexts>
<context position="17778" citStr="Teh (2006)" startWordPosition="2883" endWordPosition="2884">ted by the IGMM DP above, v`j — GC. Note that two draws from HL may result in identical lexemes; these are nonetheless considered to be separate (homophone) lexemes. 4 Topic-Lexical-Distributional Model The TLD model retains the IGMM vowel phone component, but extends the lexicon of the LD model by adding topic-specific lexicons, which capture the notion that lexeme probabilities are topicdependent. Specifically, the TLD model replaces 5This compound distribution is equivalent to E. — IW(E0, v0), µ.|E. — N(µ0, νo ) 1076 the Dirichlet Process lexicon with a Hierarchical Dirichlet Process (HDP; Teh (2006)). In the HDP lexicon, a top-level global lexicon is generated as in the LD model. Topic-specific lexicons are then drawn from the global lexicon, containing a subset of the global lexicon (but since the size of the global lexicon is unbounded, so are the topic-specific lexicons). These topic-specific lexicons are used to generate the tokens in a similar manner to the LD model. There are a fixed number of lower level topic-lexicons; these are matched to the number of topics in the LDA model used to infer the topic distributions (see Section 6.4). More formally, the global lexicon is generated </context>
</contexts>
<marker>Teh, 2006</marker>
<rawString>Yee Whye Teh. A hierarchical Bayesian language model based on Pitman-Yor processes. In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics (ACL), pages 985 – 992, Sydney, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tuomas Teinonen</author>
<author>Richard N Aslin</author>
</authors>
<title>Paavo Alku, and Gergely Csibra. Visual speech contributes to phonetic learning in 6-month-old infants.</title>
<date>2008</date>
<journal>Cognition,</journal>
<volume>108</volume>
<marker>Teinonen, Aslin, 2008</marker>
<rawString>Tuomas Teinonen, Richard N. Aslin, Paavo Alku, and Gergely Csibra. Visual speech contributes to phonetic learning in 6-month-old infants. Cognition, 108:850–855, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik D Thiessen</author>
</authors>
<title>The effect of distributional information on children’s use of phonemic contrasts.</title>
<date>2007</date>
<journal>Journal of Memory and Language,</journal>
<volume>56</volume>
<issue>1</issue>
<contexts>
<context position="10295" citStr="Thiessen, 2007" startWordPosition="1653" endWordPosition="1654">rner then has evidence of two different categories occurring in different sets of lexemes. Simulations with the LD model show that using lexical information to constrain phonetic learning can greatly improve categorization accuracy (Feldman et al., 2013a), but it can also introduce errors. When two word tokens contain the same consonant frame but different vowels (i.e., minimal pairs), the model is more likely to categorize those two vowels together. Thus, the model has trouble distinguishing minimal pairs. Although young children also have trouble with minimal pairs (Stager and Werker, 1997; Thiessen, 2007), the LD model may overestimate the degree of the problem. We hypothesize that if a learner is able to associate words with the contexts of their use (as children likely are), this could provide a weak source of information for disambiguating minimal pairs even without knowing their exact meanings. That is, if the learner hears kV1t and kV2t in different situational contexts, they are likely to be different lexical items (and V1 and V2 different phones), despite the lexical similarity between them. 3In simulations we also experiment with frames in which consonants are not represented perfectly</context>
</contexts>
<marker>Thiessen, 2007</marker>
<rawString>Erik D. Thiessen. The effect of distributional information on children’s use of phonemic contrasts. Journal of Memory and Language, 56(1):16–34, Jan 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Tincoff</author>
<author>P W Jusczyk</author>
</authors>
<title>Some beginnings of word comprehension in 6-month-olds.</title>
<date>1999</date>
<journal>Psychological Science,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="2673" citStr="Tincoff and Jusczyk, 1999" startWordPosition="412" endWordPosition="415">honological processes (and there are also none present in our synthetic data). We thus use the terms interchangeably. Feldman et al., 2013a; McMurray et al., 2009; Vallabha et al., 2007). Models without any semantic information are likely to underestimate infants’ ability to learn phonetic categories. Infants learn language in the wild, and quickly attune to the fact that words have (possibly unknown) meanings. The extent of infants’ semantic knowledge is not yet known, but existing evidence shows that six-month-olds can associate some words with their referents (Bergelson and Swingley, 2012; Tincoff and Jusczyk, 1999, 2012), leverage non-acoustic contexts such as objects or articulations to distinguish similar sounds (Teinonen et al., 2008; Yeung and Werker, 2009), and map meaning (in the form of objects or images) to new word-forms in some laboratory settings (Friedrich and Friederici, 2011; Gogate and Bahrick, 2001; Shukla et al., 2011). These findings indicate that young infants are sensitive to co-occurrences between linguistic stimuli and at least some aspects of the world. In this paper we explore the potential contribution of semantic information to phonetic learning by formalizing a model in which</context>
</contexts>
<marker>Tincoff, Jusczyk, 1999</marker>
<rawString>R. Tincoff and P. W. Jusczyk. Some beginnings of word comprehension in 6-month-olds. Psychological Science, 10(2):172–175, Mar 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruth Tincoff</author>
<author>Peter W Jusczyk</author>
</authors>
<title>Six-montholds comprehend words that refer to parts of the body.</title>
<date>2012</date>
<journal>Infancy,</journal>
<volume>17</volume>
<issue>4</issue>
<marker>Tincoff, Jusczyk, 2012</marker>
<rawString>Ruth Tincoff and Peter W. Jusczyk. Six-montholds comprehend words that refer to parts of the body. Infancy, 17(4):432444, Jul 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N S Trubetzkoy</author>
</authors>
<title>Grundb¨uge der Phonologie. Vandenhoeck und Ruprecht,</title>
<date>1939</date>
<location>G¨ottingen,</location>
<contexts>
<context position="1564" citStr="Trubetzkoy, 1939" startWordPosition="237" endWordPosition="238">model, an extension of a previous model of joint word-form and phonetic category inference, the probability of word-forms is topic-dependent, enabling the model to find significantly better phonetic vowel categories and word-forms than a model with no semantic knowledge. 1 Introduction Infants begin learning the phonetic categories of their native language in their first year (Kuhl et al., 1992; Polka and Werker, 1994; Werker and Tees, 1984). In theory, semantic information could offer a valuable cue for phoneme induction1 by helping infants distinguish between minimal pairs, as linguists do (Trubetzkoy, 1939). However, due to a widespread assumption that infants do not know the meanings of many words at the age when they are learning phonetic categories (see Swingley, 2009 for a review), most recent models of early phonetic category acquisition have explored the phonetic learning problem in the absence of semantic information (de Boer and Kuhl, 2003; Dillon et al., 2013; 1The models in this paper do not distinguish between phonetic and phonemic categories, since they do not capture phonological processes (and there are also none present in our synthetic data). We thus use the terms interchangeably</context>
</contexts>
<marker>Trubetzkoy, 1939</marker>
<rawString>N. S. Trubetzkoy. Grundb¨uge der Phonologie. Vandenhoeck und Ruprecht, G¨ottingen, 1939.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John C Trueswell</author>
<author>Tamara Nicol Medina</author>
<author>Alon Hafri</author>
<author>Lila R Gleitman</author>
</authors>
<title>Propose but verify: Fast mapping meets cross-situational word learning.</title>
<date>2013</date>
<journal>Cognitive Psychology,</journal>
<volume>66</volume>
<contexts>
<context position="35706" citStr="Trueswell et al., 2013" startWordPosition="5885" endWordPosition="5888"> linguistic learning tasks. Theories of cross-situational word learning (Smith and Yu, 2008; Yu and Smith, 2007) assume that sensitivity to situational co-occurrences between words and non-linguistic contexts is a precursor to learning the meanings of individual words. Under this view, contextual semantics is available to infants well before they have acquired large numbers of semantic minimal pairs. However, recent experimental evidence indicates that learners do not always retain detailed information about the referents that are present in a scene when they hear a word (Medina et al., 2011; Trueswell et al., 2013). This evidence poses a direct challenge to theories of cross-situational word learning. Our account does not necessarily require learners to track co-occurrences between words and individual objects, but instead focuses on more abstract information about salient events and topics in the environment; it will be important to investigate to what extent infants encode this information and use it in phonetic learning. Regardless of the specific way in which infants encode semantic information, our method of adding this information by using LDA topics from transcript data was shown to be effective.</context>
</contexts>
<marker>Trueswell, Medina, Hafri, Gleitman, 2013</marker>
<rawString>John C. Trueswell, Tamara Nicol Medina, Alon Hafri, and Lila R. Gleitman. Propose but verify: Fast mapping meets cross-situational word learning. Cognitive Psychology, 66:126–156, 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G K Vallabha</author>
<author>J L McClelland</author>
<author>F Pons</author>
<author>J F Werker</author>
<author>S Amano</author>
</authors>
<title>Unsupervised learning of vowel categories from infant-directed speech.</title>
<date>2007</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>104</volume>
<issue>33</issue>
<contexts>
<context position="2234" citStr="Vallabha et al., 2007" startWordPosition="345" endWordPosition="349">nfants do not know the meanings of many words at the age when they are learning phonetic categories (see Swingley, 2009 for a review), most recent models of early phonetic category acquisition have explored the phonetic learning problem in the absence of semantic information (de Boer and Kuhl, 2003; Dillon et al., 2013; 1The models in this paper do not distinguish between phonetic and phonemic categories, since they do not capture phonological processes (and there are also none present in our synthetic data). We thus use the terms interchangeably. Feldman et al., 2013a; McMurray et al., 2009; Vallabha et al., 2007). Models without any semantic information are likely to underestimate infants’ ability to learn phonetic categories. Infants learn language in the wild, and quickly attune to the fact that words have (possibly unknown) meanings. The extent of infants’ semantic knowledge is not yet known, but existing evidence shows that six-month-olds can associate some words with their referents (Bergelson and Swingley, 2012; Tincoff and Jusczyk, 1999, 2012), leverage non-acoustic contexts such as objects or articulations to distinguish similar sounds (Teinonen et al., 2008; Yeung and Werker, 2009), and map m</context>
<context position="4926" citStr="Vallabha et al. (2007)" startWordPosition="762" endWordPosition="765">. c�2014 Association for Computational Linguistics lar to that assumed by theories of cross-situational word learning (Frank et al., 2009; Smith and Yu, 2008; Yu and Smith, 2007), but our model does not require learners to map individual words to their referents. Even in the absence of word-meaning mappings, situational information is potentially useful because similar-sounding words uttered in similar situations are more likely to be tokens of the same lexeme (containing the same phones) than similarsounding words uttered in different situations. In simulations of vowel learning, inspired by Vallabha et al. (2007) and Feldman et al. (2013a), we show a clear improvement over previous models in both phonetic and lexical (word-form) categorization when situational context is used as an additional source of information. This improvement is especially noticeable when the word-level context is providing less information, arguably the more realistic setting. These results demonstrate that relying on situational co-occurrence can improve phonetic learning, even if learners do not yet know the meanings of individual words. 2 Background and overview of models Infants attend to distributional characteristics of t</context>
<context position="15532" citStr="Vallabha et al., 2007" startWordPosition="2498" endWordPosition="2501">crete, as when it generates lexemes as a list of phonetic categories. A draw from a DP, G — DP(α, H), returns a distribution over a set of draws from H, i.e., a discrete distribution over a set of categories or lexemes generated by H. In the mixture model setting, the category assignments are then generated from G, with the datapoints themselves generated by the corresponding components from H. If H is infinite, the support of the DP is likewise infinite. During inference, we marginalize over G. 3.1 Phonetic Categories: IGMM Following previous models of vowel learning (de Boer and Kuhl, 2003; Vallabha et al., 2007; McMurray et al., 2009; Dillon et al., 2013) we assume that vowel tokens are drawn from a Gaussian mixture model. The Infinite Gaussian Mixture Model (IGMM) (Rasmussen, 2000) includes a DP prior, as described above, in which the base distribution HC generates multivariate Gaussians drawn from a Normal Inverse-Wishart prior.5 Each observation, a formant vector wij, is drawn from the Gaussian corresponding to its category assignment cij: µc, Ec — HC = NIW(µo, Eo, ν0) GC — DP(αc, HC) cij — GC wij|cij = c — N(µc, Ec) The above model generates a category assignment cij for each vowel token wij. Th</context>
</contexts>
<marker>Vallabha, McClelland, Pons, Werker, Amano, 2007</marker>
<rawString>G. K. Vallabha, J. L. McClelland, F. Pons, J. F. Werker, and S. Amano. Unsupervised learning of vowel categories from infant-directed speech. Proceedings of the National Academy of Sciences, 104(33):13273–13278, Aug 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet F Werker</author>
<author>Richard C Tees</author>
</authors>
<title>Crosslanguage speech perception: Evidence for perceptual reorganization during the first year of life.</title>
<date>1984</date>
<journal>Infant Behavior and Development,</journal>
<volume>7</volume>
<contexts>
<context position="1392" citStr="Werker and Tees, 1984" startWordPosition="210" endWordPosition="213">that attending to a weaker source of semantics, in the form of a distribution over topics in the current context, can lead to improvements in phonetic category learning. In our model, an extension of a previous model of joint word-form and phonetic category inference, the probability of word-forms is topic-dependent, enabling the model to find significantly better phonetic vowel categories and word-forms than a model with no semantic knowledge. 1 Introduction Infants begin learning the phonetic categories of their native language in their first year (Kuhl et al., 1992; Polka and Werker, 1994; Werker and Tees, 1984). In theory, semantic information could offer a valuable cue for phoneme induction1 by helping infants distinguish between minimal pairs, as linguists do (Trubetzkoy, 1939). However, due to a widespread assumption that infants do not know the meanings of many words at the age when they are learning phonetic categories (see Swingley, 2009 for a review), most recent models of early phonetic category acquisition have explored the phonetic learning problem in the absence of semantic information (de Boer and Kuhl, 2003; Dillon et al., 2013; 1The models in this paper do not distinguish between phone</context>
</contexts>
<marker>Werker, Tees, 1984</marker>
<rawString>Janet F. Werker and Richard C. Tees. Crosslanguage speech perception: Evidence for perceptual reorganization during the first year of life. Infant Behavior and Development, 7:49–63, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Henny Yeung</author>
<author>Janet F Werker</author>
</authors>
<title>Learning words’ sounds before learning how words sound: 9-month-olds use distinct objects as cues to categorize speech information.</title>
<date>2009</date>
<journal>Cognition,</journal>
<volume>113</volume>
<issue>2</issue>
<pages>234--243</pages>
<contexts>
<context position="2823" citStr="Yeung and Werker, 2009" startWordPosition="434" endWordPosition="437"> al., 2009; Vallabha et al., 2007). Models without any semantic information are likely to underestimate infants’ ability to learn phonetic categories. Infants learn language in the wild, and quickly attune to the fact that words have (possibly unknown) meanings. The extent of infants’ semantic knowledge is not yet known, but existing evidence shows that six-month-olds can associate some words with their referents (Bergelson and Swingley, 2012; Tincoff and Jusczyk, 1999, 2012), leverage non-acoustic contexts such as objects or articulations to distinguish similar sounds (Teinonen et al., 2008; Yeung and Werker, 2009), and map meaning (in the form of objects or images) to new word-forms in some laboratory settings (Friedrich and Friederici, 2011; Gogate and Bahrick, 2001; Shukla et al., 2011). These findings indicate that young infants are sensitive to co-occurrences between linguistic stimuli and at least some aspects of the world. In this paper we explore the potential contribution of semantic information to phonetic learning by formalizing a model in which learners attend to the word-level context in which phones appear (as in the lexical-phonetic learning model of Feldman et al., 2013a) and also to the</context>
</contexts>
<marker>Yeung, Werker, 2009</marker>
<rawString>H. Henny Yeung and Janet F. Werker. Learning words’ sounds before learning how words sound: 9-month-olds use distinct objects as cues to categorize speech information. Cognition, 113(2): 234–243, Nov 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Yu</author>
<author>Linda B Smith</author>
</authors>
<title>Rapid word learning under uncertainty via cross-situational statistics.</title>
<date>2007</date>
<journal>Psychological Science,</journal>
<volume>18</volume>
<issue>5</issue>
<contexts>
<context position="4482" citStr="Yu and Smith, 2007" startWordPosition="694" endWordPosition="697">nformation by running a topic model (Blei et al., 2003) over a corpus of childdirected speech to infer a topic distribution for each situation. These topic distributions are then used as input to our model to represent situational contexts. The situational information in our model is simi1073 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1073–1083, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics lar to that assumed by theories of cross-situational word learning (Frank et al., 2009; Smith and Yu, 2008; Yu and Smith, 2007), but our model does not require learners to map individual words to their referents. Even in the absence of word-meaning mappings, situational information is potentially useful because similar-sounding words uttered in similar situations are more likely to be tokens of the same lexeme (containing the same phones) than similarsounding words uttered in different situations. In simulations of vowel learning, inspired by Vallabha et al. (2007) and Feldman et al. (2013a), we show a clear improvement over previous models in both phonetic and lexical (word-form) categorization when situational conte</context>
<context position="35195" citStr="Yu and Smith, 2007" startWordPosition="5807" endWordPosition="5810"> degree of phonetic ambiguity in the word-forms that learners hear. This suggests that previous models that have ignored semantic information may have underestimated the information that is available to infants. Our model illustrates one way in which language learners might harness the rich information that is present in the world without first needing to acquire a full inventory of word meanings. The contextual semantic information that the TLD model tracks is similar to that potentially used in other linguistic learning tasks. Theories of cross-situational word learning (Smith and Yu, 2008; Yu and Smith, 2007) assume that sensitivity to situational co-occurrences between words and non-linguistic contexts is a precursor to learning the meanings of individual words. Under this view, contextual semantics is available to infants well before they have acquired large numbers of semantic minimal pairs. However, recent experimental evidence indicates that learners do not always retain detailed information about the referents that are present in a scene when they hear a word (Medina et al., 2011; Trueswell et al., 2013). This evidence poses a direct challenge to theories of cross-situational word learning. </context>
</contexts>
<marker>Yu, Smith, 2007</marker>
<rawString>Chen Yu and Linda B. Smith. Rapid word learning under uncertainty via cross-situational statistics. Psychological Science, 18(5):414–420, 2007.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>