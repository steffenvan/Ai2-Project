<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001184">
<title confidence="0.987144">
Improving Word Segmentation by Simultaneously Learning Phonotactics
</title>
<author confidence="0.994477">
Daniel Blanchard
</author>
<affiliation confidence="0.9892015">
Computer &amp; Information Sciences
University of Delaware
</affiliation>
<email confidence="0.997859">
dsblanch@udel.edu
</email>
<author confidence="0.990479">
Jeffrey Heinz
</author>
<affiliation confidence="0.9825405">
Linguistics &amp; Cognitive Science
University of Delaware
</affiliation>
<email confidence="0.99834">
heinz@udel.edu
</email>
<sectionHeader confidence="0.997384" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997531294117647">
The most accurate unsupervised word seg-
mentation systems that are currently avail-
able (Brent, 1999; Venkataraman, 2001;
Goldwater, 2007) use a simple unigram
model of phonotactics. While this sim-
plifies some of the calculations, it over-
looks cues that infant language acquisition
researchers have shown to be useful for
segmentation (Mattys et al., 1999; Mattys
and Jusczyk, 2001). Here we explore the
utility of using bigram and trigram phono-
tactic models by enhancing Brent’s (1999)
MBDP-1 algorithm. The results show
the improved MBDP-Phon model outper-
forms other unsupervised word segmenta-
tion systems (e.g., Brent, 1999; Venkatara-
man, 2001; Goldwater, 2007).
</bodyText>
<sectionHeader confidence="0.999522" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999849571428571">
How do infants come to identify words in the
speech stream? As adults, we break up speech
into words with such ease that we often think
that there are audible pauses between words in the
same sentence. However, unlike some written lan-
guages, speech does not have any completely reli-
able markers for the breaks between words (Cole
and Jakimik, 1980). In fact, languages vary on how
they signal the ends of words (Cutler and Carter,
1987), which makes the task even more daunting.
Adults at least have a lexicon they can use to rec-
ognize familiar words, but when an infant is first
born, they do not have a pre-existing lexicon to
consult. In spite of these challenges, by the age of
</bodyText>
<footnote confidence="0.9028985">
© 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
</footnote>
<bodyText confidence="0.999960052631579">
six months infants can begin to segment words out
of speech (Bortfeld et al., 2005). Here we present
an efficient word segmentation system aimed to
model how infants accomplish the task.
While an algorithm that could reliably extract
orthographic representations of both novel and fa-
miliar words from acoustic data is something we
would like to see developed, following earlier re-
searchers, we simplify the problem by using a text
that does not contain any word boundary markers.
Hereafter, we use the phrase “word segmentation”
to mean some process which adds word boundaries
to a text that does not contain them.
This paper’s focus is on unsupervised, incre-
mental word segmentation algorithms; i.e., those
that do not rely on preexisting knowledge of a par-
ticular language, and those that segment the cor-
pus one utterance at a time. This is in contrast
to supervised word segmentation algorithms (e.g.,
Teahan et al., 2000), which are typically used for
segmenting text in documents written in languages
that do not put spaces between their words like
Chinese. (Of course, unsupervised word segmen-
tation algorithms also have this application.) This
also differs from batch segmentation algorithms
(Goldwater, 2007; Johnson, 2008b; Fleck, 2008),
which process the entire corpus at least once be-
fore outputting a segmentation of the corpus. Un-
supervised incremental algorithms are of interest
to some psycholinguists and acquisitionists inter-
ested in the problem of language learning, as well
as theoretical computer scientists who are inter-
ested in what unsupervised, incremental models
are capable of achieving.
Phonotactic patterns are the rules that deter-
mine what sequences of phonemes or allophones
are allowable within words. Learning the phono-
tactic patterns of a language is usually modeled
</bodyText>
<page confidence="0.995647">
65
</page>
<note confidence="0.8811375">
CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 65–72
Manchester, August 2008
</note>
<bodyText confidence="0.999652666666667">
separately from word segmentation; e.g., current
phonotactic learners such as Coleman and Pierre-
humbert (1997), Heinz (2007), or Hayes and Wil-
son (2008) are given word-sized units as input.
However, infants appear to simultaneously learn
which phoneme combinations are allowable within
words and how to extract words from the input. It
is reasonable that the two processes feed into one
another, and when infants acquire a critical mass of
phonotactic knowledge, they use it to make judge-
ments about what phoneme sequences can occur
within versus across word boundaries (Mattys and
Jusczyk, 2001). We use this insight, also suggested
by Venkataraman (2001) and recently utilized by
Fleck (2008) in a different manner, to enhance
Brent’s (1999) model MBDP-1, and significantly
increase segmentation accuracy. We call this mod-
ified segmentation model MBDP-Phon.
</bodyText>
<sectionHeader confidence="0.999977" genericHeader="related work">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.999716">
2.1 Word Segmentation
</subsectionHeader>
<bodyText confidence="0.9999653">
The problem of unsupervised word segmentation
has attracted many earlier researchers over the
past fifty years (e.g., Harris, 1954; Olivier, 1968;
de Marcken, 1995; Brent, 1999). In this section,
we describe the base model MBDP-1, along with
two other segmentation approaches, Venkataraman
(2001) and Goldwater (2007). In §4, we compare
MBDP-Phon to these models in more detail. For
a thorough review of word segmentation literature,
see Brent (1999) or Goldwater (2007).
</bodyText>
<subsectionHeader confidence="0.935253">
2.1.1 MBDP-1
</subsectionHeader>
<bodyText confidence="0.997078833333333">
Brent’s (1999) MBDP-1 (Model Based Dy-
namic Programming) algorithm is an implemen-
tation of the INCDROP framework (Brent, 1997)
that uses a Bayesian model of how to generate an
unsegmented text to insert word boundaries. The
generative model consists of five steps:
</bodyText>
<listItem confidence="0.999671545454545">
1. Choose a number of word types, n.
2. Pick n distinct strings from E+#, which will
make up the lexicon, L. Entries in L are la-
beled W1 ... Wn. W0 = $, where $ is the
utterance boundary marker.
3. Pick a function, f, which maps word types to
their frequency in the text.
4. Choose a function, s, to map positions in the
text to word types.
5. Concatenate the words in the order specified
by s, and remove the word delimiters (#).
</listItem>
<bodyText confidence="0.998752285714286">
It is important to note that this model treats the
generation of the text as a single event in the prob-
ability space, which allows Brent to make a num-
ber of simplifying assumptions. As the values for
n, L, f, and s completely determine the segmenta-
tion, the probability of a particular segmentation,
wm, can be calculated as:
</bodyText>
<equation confidence="0.998718">
P(wm) = P(n, L, f, s) (1)
</equation>
<bodyText confidence="0.99993775">
To allow the model to operate on one utterance at
a time, Brent states the probability of each word in
the text as a recursive function, R(wk), where wk
is the text up to and including the word at position
k, wk. Furthermore, there are two specific cases
for R: familiar words and novel words. If wk is
familiar, the model already has the word in its lex-
icon, and its score is calculated as in Equation 2.
</bodyText>
<equation confidence="0.9996335">
R(wk) = f(wk) Cf (wk) − 112 (2)
k f(wk) J
</equation>
<bodyText confidence="0.657765">
Otherwise, the word is novel, and its score is cal-
culated using Equation 31 (Brent and Tao, 2001),
</bodyText>
<equation confidence="0.999944666666667">
R(wk) =
PΣ(a1) ... PΣ(ay) (n−11
1−PΣ(#) ·n )
</equation>
<bodyText confidence="0.999926235294118">
where PE is the probability of a particular
phoneme occurring in the text. The third term of
the equation for novel words is where the model’s
unigram phonotactic model comes into play. We
detail how to plug a more sophisticated phonotac-
tic learning model into this equation in §3. With
the generative model established, MBDP-1 uses a
Viterbi-style search algorithm to find the segmen-
tation for each utterance that maximizes the R val-
ues for each word in the segmentation.
Venkataraman (2001) notes that considering the
generation of the text as a single event is un-
likely to be how infants approach the segmenta-
tion problem. However, MBDP-1 uses an incre-
mental search algorithm to segment one utterance
at a time, which is more plausible as a model of
infants’ word segmentation.
</bodyText>
<equation confidence="0.941435666666667">
1Brent (1999) originally described the novel word score
as R(wk) = 6 · nk · Pσ(Wnk ) (nk −11
π2 k · ,
nk−1·Enk
1− Pσ(Wj) nk
nk j=1
</equation>
<bodyText confidence="0.740006">
where Po is the probability of all the phonemes in the word
occurring together, but the denominator of the third term was
dropped in Brent and Tao (2001). This change drastically
speeds up the model, and only reduces segmentation accuracy
by ∼ 0.5%.
</bodyText>
<equation confidence="0.88529775">
6 n
π2 · k ·
2 (3)
2
</equation>
<page confidence="0.828071">
66
</page>
<subsubsectionHeader confidence="0.447742">
2.1.2 Venkataraman (2001)
</subsubsectionHeader>
<bodyText confidence="0.9995794375">
MBDP-1 is not the only incremental unsuper-
vised segmentation model that achieves promis-
ing results. Venkataraman’s (2001) model tracks
MBDP-1’s performance so closely that Batchelder
(2002) posits that the models are performing the
same operations, even though the authors describe
them differently.
Venkataraman’s model uses a more traditional,
smoothed n-gram model to describe the distribu-
tion of words in an unsegmented text.2 The most
probable segmentation is retrieved via a dynamic
programming algorithm, much like Brent (1999).
We use MBDP-1 rather than Venkataraman’s
approach as the basis for our model only because it
was more transparent how to plug in a phonotactic
learning module at the time this project began.
</bodyText>
<subsubsectionHeader confidence="0.618139">
2.1.3 Goldwater (2007)
</subsubsectionHeader>
<bodyText confidence="0.999957916666667">
We also compare our results to a segmenter put
forward by Goldwater (2007). Goldwater’s seg-
menter uses an underlying generative model, much
like MBDP-1 does, only her language model is
described as a Dirichlet process (see also John-
son, 2008b). While this model uses a unigram
model of phoneme distribution, as did MBDP-1, it
implements a bigram word model like Venkatara-
man (2001). A bigram word model is useful in
that it prevents the segmenter from assuming that
frequent word bigrams are not simply one word,
which Goldwater observes happen with a unigram
version of her model.
Goldwater uses a Gibbs sampler augmented
with simulated annealing to sample from the pos-
terior distribution of segmentations and deter-
mine the most likely segmentation of each utter-
ance.3 This approach requires non-incremental
learning.4 We include comparison with Goldwa-
ter’s segmenter because it outperforms MBDP-1
and Venkataraman (2001) in both precision and
recall, and we are interested in whether an incre-
mental algorithm supplemented with phonotactic
learning can match its performance.
</bodyText>
<subsectionHeader confidence="0.998791">
2.2 Phonotactic Learning
</subsectionHeader>
<bodyText confidence="0.999414">
Phonotactic acquisition models have seen a surge
in popularity recently (e.g., Coleman and Pierre-
</bodyText>
<footnote confidence="0.984392166666667">
2We refer the reader to Venkataraman (2001) for the de-
tails of this approach.
3We direct the reader to Goldwater (2007) for details.
4In our experiments and those in Goldwater (2007), the
segmenter runs through the corpus 1000 times before out-
putting the final segmentation.
</footnote>
<bodyText confidence="0.998522260869565">
humbert, 1997; Heinz, 2007; Hayes and Wilson,
2008). While Hayes and Wilson present a more
complex Maximum Entropy phonotactic model in
their paper than the one we add to MBDP-1, they
also evaluate a simple n-gram phonotactic learner
operating over phonemes. The input to the mod-
els is a list of English onsets and their frequency
in the lexicon, and the basic trigram learner simply
keeps track of the trigrams it has seen in the cor-
pus. They test the model on novel words with ac-
ceptable rhymes—some well-formed (e.g., [kIp]),
and some less well-formed (e.g., [stwIk])—so any
ill-formedness is attributable to onsets. This ba-
sic trigram model explains 87.7% of the variance
in the scores that Scholes (1966) reports his 7th
grade students gave when subjected to the same
test. When Hayes and Wilson run their Maximum
Entropy phonotactic learning model with n-grams
over phonological features, the r-score increases
substantially to 95.6%.
Given the success and simplicity of the basic n-
gram phonotactic model, we choose to integrate
this with MBDP-1.
</bodyText>
<sectionHeader confidence="0.981038" genericHeader="method">
3 Extending MBDP-1 with Phonotactics
</sectionHeader>
<bodyText confidence="0.999594214285714">
The main contribution of our work is adding
a phonotactic learning component to MBDP-1
(Brent, 1999). As we mention in §2.1.1, the third
term of Equation 3 is where MBDP-1’s unigram
phonotactic assumption surfaces. The original
model simply multiplies the probabilities of all the
phonemes in the word together and divides by one
minus the probability of a particular phoneme be-
ing the word boundary to come up with probabil-
ity of the phoneme combination. The order of the
phonemes in the word has no effect on its score.
The only change we make to MBDP-1 is to the
third term of Equation 3. In MBDP-Phon this be-
comes
</bodyText>
<equation confidence="0.977416">
PMLE(ai ... aj) (4)
</equation>
<bodyText confidence="0.999386428571428">
where ai ... aj is an n-gram inside a proposed
word, and a0 and aq are both the word boundary
symbol, #5.
It is important to note that probabilities calcu-
lated in Equation 4 are maximum likelihood esti-
mates of the joint probability of each n-gram in the
word. The maximum likelihood estimate (MLE)
</bodyText>
<footnote confidence="0.969626333333333">
5The model treats word boundary markers like a phoneme
for the purposes of storing n-grams (i.e., a word boundary
marker may occur anywhere within the n-grams).
</footnote>
<equation confidence="0.825704666666667">
q
ri
i=0
</equation>
<page confidence="0.979085">
67
</page>
<bodyText confidence="0.999983531914894">
for a particular n-gram inside a word is calculated
by dividing the total number of occurrences of that
n-gram (including in the word we are currently ex-
amining) by the total number of n-grams (includ-
ing those in the current word). The numbers of
n-grams are computed with respect to the obtained
lexicon, not the corpus, and thus the frequency of
lexical items in the corpus does not affect the n-
gram counts, just like Brent’s unigram phonotactic
model and other phonotactic learning models (e.g.,
Hayes and Wilson, 2008).
We use the joint probability instead of the con-
ditional probability which is often used in compu-
tational linguistics (Manning and Sch¨utze, 1999;
Jurafsky and Martin, 2000), because of our intu-
ition that the joint probability is truer to the idea
that a phonotactically well-formed word is made
up of n-grams that occur frequently in the lexicon.
On the other hand, the conditional probability is
used when one tries to predict the next phoneme
that will occur in a word, rather than judging the
well-formedness of the word as a whole.6
We are able to drop the denominator that was
originally in Equation 3, because PΣ(#) is zero
for an n-gram model when n &gt; 1. This sim-
ple modification allows the model to learn what
phonemes are more likely to occur at the begin-
nings and ends of words, and what combinations
of phonemes rarely occur within words.
What is especially interesting about this mod-
ification is that the phonotactic learning compo-
nent estimates the probabilities of the n-grams by
using their relative frequencies in the words the
segmenter has extracted. The phonotactic learner
is guaranteed to see at least two valid patterns in
every utterance, as the n-grams that occur at the
beginnings and ends of utterances are definitely
at the beginnings and ends of words. This al-
lows the learner to provide useful information to
the segmenter even early on, and as the segmenter
correctly identifies more words, the phonotactic
learner has more correct data to learn from. Not
only is this mutually beneficial process supported
by evidence from language acquisitionists (Mat-
tys et al., 1999; Mattys and Jusczyk, 2001), it also
resembles co-training (Blum and Mitchell, 1998).
We refer to the extended version of Brent’s model
</bodyText>
<footnote confidence="0.9985636">
6This intuition is backed up by preliminary results sug-
gesting MBDP-Phon performs better when using MLEs of the
joint probability as opposed to conditional probability. There
is an interesting question here, which is beyond the scope of
this paper, so we leave it for future investigation.
</footnote>
<bodyText confidence="0.39312">
described above as MBDP-Phon.
</bodyText>
<sectionHeader confidence="0.9982" genericHeader="method">
4 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.980736">
4.1 The Corpus
</subsectionHeader>
<bodyText confidence="0.999976">
We run all of our experiments on the Bernstein-
Ratner (1987) infant-directed speech corpus from
the CHILDES database (MacWhinney and Snow,
1985). This is the same corpus that Brent (1999),
Goldwater (2007), and Venkataraman (2001) eval-
uate their models on, and it has become the de
facto standard for segmentation testing, as unlike
other corpora in CHILDES, it was phonetically
transcribed.
We examine the transcription system Brent
(1999) uses and conclude some unorthodox
choices were made when transcribing the corpus.
Specifically, some phonemes that are normally
considered distinct are combined into one symbol,
which we call a bi-phone symbol. These phonemes
combinations include diphthongs and vowels fol-
lowed by /a/. Another seemingly arbitrary deci-
sion is the distinction between stressed and un-
stressed syllabic /a/ sound (i.e., there are differ-
ent symbols for the /a/ in “butter” and the /a/ in
“bird”) since stress is not marked elsewhere in the
corpus. To see the effect of these decisions, we
modified the corpus so that the bi-phone symbols
were split into two7 and the syllabic /a/ symbols
were collapsed into one.
</bodyText>
<subsectionHeader confidence="0.982069">
4.2 Accuracy
</subsectionHeader>
<bodyText confidence="0.9998919375">
We ran MBDP-1 on the original corpus, and the
modified version of the corpus. As illustrated by
Figures 1 and 2, MBDP-1 performs worse on the
modified corpus with respect to both precision and
recall. As MBDP-1 and MBDP-Phon are both iter-
ative learners, we calculate segmentation precision
and recall values over 500-utterance blocks. Per
Brent (1999) and Goldwater (2007), precision and
recall scores reflect correctly segmented words,
not correctly identified boundaries.
We also test to see how the addition of an n-gram
phonotactic model affects the segmentation accu-
racy of MBDP-Phon by comparing it to MBDP-
1 on our modified corpus.8 As seen in Figure 3,
MBDP-Phon using bigrams (henceforth MBDP-
Phon-Bigrams) is consistently more precise in its
</bodyText>
<footnote confidence="0.9979382">
7We only split diphthongs whose first phoneme can occur
in isolation in English, so the vowels in “bay” and “boat” were
not split.
8We also compare MBDP-Phon to MBDP-1 on the origi-
nal corpus. The results are given in Tables 1 and 2.
</footnote>
<page confidence="0.99834">
68
</page>
<figure confidence="0.999892809523809">
0.75 Modified Original MBDP-1 MBDP-Bigrams MBDP-Trigrams
0.85
0.70
0.65
Precision
0.60
0.55
0.50
0.45
0.80
0.75
Precision
0.70
0.65
0.60
0.55
0.50
500 1500 2500 3500 4500 5500 6500 7500 8500 9500
Utterances Processed
500 1500 2500 3500 4500 5500 6500 7500 8500 9500
Utterances Processed
</figure>
<figureCaption confidence="0.999885">
Figure 1: Precision of MBDP-1 on both corpora.
</figureCaption>
<figure confidence="0.914327">
0.80 Modified Original
</figure>
<figureCaption confidence="0.9924205">
Figure 3: Precision of MBDP-1 and MBDP-Phon
on modified corpus.
</figureCaption>
<figure confidence="0.999900409090909">
0.75
0.70
0.65
Recall
0.60
0.55
0.50
0.45
0.40
0.85
0.80
0.75
0.70
Recall
0.65
0.60
0.55
0.50
0.45
500 1500 2500 3500 4500 5500 6500 7500 8500 9500
Utterances Processed
MBDP-1 MBDP-Bigrams MBDP-Trigrams
</figure>
<figureCaption confidence="0.999982">
Figure 2: Recall of MBDP-1 on both corpora.
</figureCaption>
<bodyText confidence="0.996641722222222">
segmentation than MBDP-1, and bests it by - 18%
in the last block. Furthermore, MBDP-Phon-
Bigrams significantly outpaces MBDP-1 with re-
spect to recall only after seeing 1000 utterances,
and finishes the corpus - 10% ahead of MBDP-
1 (see Figure 4). MBDP-Phon-Trigrams does not
fair as well in our tests, falling behind MBDP-1
and MBDP-Phon-Bigrams in recall, and MBDP-
Phon-Bigrams in precision. We attribute this poor
performance to the fact that we are not currently
smoothing the n-gram models in any way, which
leads to data sparsity issues when using trigrams.
We discuss a potential solution to this problem in
§5.
Having established that MBDP-Phon-Bigrams
significantly outperforms MBDP-1, we compare
its segmentation accuracy to those of Goldwater
(2007) and Venkataraman (2001).9 As before, we
</bodyText>
<footnote confidence="0.932906">
9We only examine Venkataraman’s unigram model, as his
bigram and trigram models perform better on precision, but
worse on recall.
</footnote>
<figure confidence="0.985894666666667">
0.40
500 1500 2500 3500 4500 5500 6500 7500 8500 9500
Utterances Processed
</figure>
<figureCaption confidence="0.995266">
Figure 4: Recall of MBDP-1 and MBDP-Phon on
modified corpus.
</figureCaption>
<bodyText confidence="0.995837611111111">
run the models on the entire corpus, and then mea-
sure their performance over 500-utterance blocks.
MBDP-Phon-Bigrams edges out Goldwater’s
model in precision on our modified corpus, with
an average precision of 72.79% vs. Goldwa-
ter’s 70.73% (Table 1). If we drop the first 500-
utterance block for MBDP-Phon-Bigrams because
the model is still in the early learning stages,
whereas Goldwater’s has seen the entire corpus, its
average precision increases to 73.21% (Table 1).
When considering the recall scores in Table 2,
it becomes clear that MBDP-Phon-Bigrams has a
clear advantage over the other models. Its aver-
age recall is higher than or nearly equal to both
of the other models’ maximum scores. Since
Venkataraman’s (2001) model performs similarly
to MBDP-1, it is no surprise that MBDP-Phon-
Bigrams achieves higher precision and recall.
</bodyText>
<page confidence="0.998583">
69
</page>
<table confidence="0.999848533333333">
MBDP- Venkataraman Goldwater
Phon-
Bigrams
Original: Utterances 0 to 9790
Avg. 72.84% 67.46% 67.87%
Max. 79.91% 71.79% 71.98%
Min. 63.97% 61.77% 61.87%
Modified: Utterances 0 to 9790
Avg. 72.79% 59.64% 70.73%
Max. 80.60% 66.84% 74.61%
Min. 64.78% 52.54% 65.29%
Modified: Utterances 500 to 9790
Avg. 73.21% 59.54% 70.59%
Max. 80.60% 66.84% 74.61%
Min. 67.40% 52.54% 65.29%
</table>
<tableCaption confidence="0.975951">
Table 1: Precision statistics for MBDP-Phon-
Bigrams, Goldwater, and Venkataraman on both
corpora over 500-utterance blocks.
</tableCaption>
<table confidence="0.999948133333333">
MBDP- Venkataraman Goldwater
Phon-
Bigrams
Original: Utterances 0 to 9790
Avg. 72.03% 70.02% 71.02%
Max. 79.31% 75.59% 76.79%
Min. 44.71% 42.57% 64.32%
Modified: Utterances 0 to 9790
Avg. 74.63% 66.24% 70.48%
Max. 82.45% 70.47% 74.79%
Min. 47.63% 44.71% 63.74%
Modified: Utterances 500 to 9790
Avg. 76.05% 67.37% 70.28%
Max. 82.45% 70.47% 74.79%
Min. 71.92% 63.86% 63.74%
</table>
<tableCaption confidence="0.880743333333333">
Table 2: Recall statistics for MBDP-Phon-
Bigrams, Goldwater, and Venkataraman on both
corpora over 500-utterance blocks.
</tableCaption>
<bodyText confidence="0.999917476190476">
The only metric by which MBDP-Phon-
Bigrams does not outperform the other algorithms
is lexical precision, as shown in Table 3. Lexi-
cal precision is the ratio of the number of correctly
identified words in the lexicon to the total number
of words in the lexicon (Brent, 1999; Venkatara-
man, 2001).10 The relatively poor performance
of MBDP-Phon-Bigrams is due to the incremental
nature of the MBDP algorithm. Initially, it makes
numerous incorrect guesses that are added to the
lexicon, and there is no point at which the lexi-
con is purged of earlier erroneous guesses (c.f. the
improved lexical precision when omitting the first
block in Table 3). On the other hand, Goldwater’s
algorithm runs over the corpus multiple times, and
only produces output when it settles on a final seg-
mentation.
In sum, MBDP-Phon-Bigrams significantly im-
proves the accuracy of MBDP-1, and achieves
better performance than the models described in
Venkataraman (2001) and Goldwater (2007).
</bodyText>
<sectionHeader confidence="0.999116" genericHeader="method">
5 Future Work
</sectionHeader>
<bodyText confidence="0.994970894736842">
There are many ways to implement phonotactic
learning. One idea is to to use n-grams over phono-
logical features, as per Hayes and Wilson (2008).
Preliminary results have shown that we need to add
smoothing to our n-gram model, and we plan to use
10See Brent (1999) for a discussion of the meaning of this
statistic.
Modified Kneser-Ney smoothing (Chen and Good-
man, 1998).
Another approach would be to develop a
syllable-based phonotactic model (Coleman and
Pierrehumbert, 1997). Johnson (2008b) achieves
impressive segmentation results by adding a sylla-
ble level with Adaptor grammars.
Some languages (e.g., Finnish, and Navajo)
contain long-distance phonotactic constraints that
cannot be learned by n-gram learners (Heinz,
2007). Heinz (2007) shows that precedence-based
learners—which work like a bigram model, but
without the restriction that the elements in the bi-
gram be adjacent—can handle many long-distance
agreement patterns (e.g., vowel and consonantal
harmony) in the world’s languages. We posit that
adding such a learner to MBDP-Phon would allow
it to handle a greater variety of languages.
Since none of these approaches to phonotactic
learning depend on MBDP-1, it is also of interest
to integrate phonotactic learners with other word
segmentation strategies.
In addition to evaluating segmentation models
integrated with phonotactic learning on their seg-
mentation performance, it would be interesting to
evaluate the quality of the phonotactic grammars
obtained. A good point of comparison for English
are the constraints obtained by Hayes and Wilson
(2008), since the data with which they tested their
phonotactic learner is publicly available.
Finally, we are looking forward to investigat-
</bodyText>
<page confidence="0.989168">
70
</page>
<table confidence="0.999776333333333">
MBDP- Venkataraman Goldwater
Phon-
Bigrams
Original: Utterances 0 to 9790
Avg. 47.69% 49.78% 56.50%
Max. 49.71% 52.95% 63.09%
Min. 46.30% 41.83% 55.33%
Modified: Utterances 0 to 9790
Avg. 48.31% 45.98% 58.03%
Max. 50.42% 48.90% 65.58%
Min. 41.74% 36.57% 56.43%
Modified: Utterances 500 to 9790
Avg. 54.34% 53.06% 57.95%
Max. 63.76% 54.35% 62.30%
Min. 51.31% 51.95% 56.52%
</table>
<tableCaption confidence="0.990988">
Table 3: Lexical precision statistics for MBDP-
</tableCaption>
<bodyText confidence="0.858522714285714">
Phon-Bigrams, Goldwater, and Venkataraman on
both corpora over 500-utterance blocks.
ing the abilities of these segmenters on corpora
of different languages. Fleck (2008) tests her seg-
menter on a number of corpora, including Arabic
and Spanish, and Johnson (2008a) applies his seg-
menter to a corpus of Sesotho.
</bodyText>
<sectionHeader confidence="0.999431" genericHeader="method">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999990555555556">
From the results established in §4, we can con-
clude that MBDP-Phon using a bigram phonotac-
tic model is more accurate than the models de-
scribed in Brent (1999), Venkataraman (2001), and
Goldwater (2007). The n-gram phonotactic model
improves overall performance, and is especially
useful for corpora that do not encode diphthongs
with bi-phone symbols. The main reason there
is such a marked improvement with MBDP-Phon
vs. MBDP-1 when the bi-phone symbols were re-
moved from the original corpus is that these bi-
phone symbols effectively allow MBDP-1 to have
a select few bigrams in the cases where it would
otherwise over-segment.
The success of MBDP-Phon is not clear evi-
dence that the INCDROP framework (Brent, 1997)
is superior to Venkataraman or Goldwater’s mod-
els. We imagine that adding a phonotactic learning
component to either of their models would also im-
prove their performance.
We also tentatively conclude that phonotactic
patterns can be learned from unsegmented text.
However, the phonotactic patterns learned by our
model ought to be studied in detail to see how well
they match the phonotactic patterns of English.
MBDP-Phon’s performance reinforces the the-
ory put forward by language acquisition re-
searchers that phonotactic knowledge is a cue for
word segmentation (Mattys et al., 1999; Mattys
and Jusczyk, 2001). Furthermore, our results in-
dicate that learning phonotactic patterns can oc-
cur simultaneously with word segmentation. Fi-
nally, further investigation of the simultaneous ac-
quisition of phonotactics and word segmentation
appears fruitful for theoretical and computational
linguists, as well as acquisitionists.
</bodyText>
<sectionHeader confidence="0.992287" genericHeader="conclusions">
Acknoledgements
</sectionHeader>
<bodyText confidence="0.9998908">
We are grateful to Roberta Golinkoff who inspired
this project. We also thank Vijay Shanker for
valuable discussion, Michael Brent for the corpus,
and Sharon Goldwater for the latest version of her
code.
</bodyText>
<sectionHeader confidence="0.998884" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.975027142857143">
Batchelder, Eleanor Olds. 2002. Bootstrapping the
lexicon: a computational model of infant speech
segmentation. Cognition, 83(2):167–206.
Bernstein-Ratner, Nan. 1987. The phonology of
parent child speech, volume 6. Erlbaum, Hills-
dale, NJ.
Blum, Avrim and Tom Mitchell. 1998. Combining
labeled and unlabeled data with co-training. In
Workshop on Computational Learning Theory,
pages 92–100.
Bortfeld, Heather, James Morgan, Roberta
Golinkoff, and Karen Rathbun. 2005. Mommy
and me: Familiar names help launch babies into
speech-stream segmentation. Psychological
Science, 16(4):298–304.
Brent, Michael R. 1997. Towards a unified model
of lexical acquisition and lexical access. Journal
of Psycholinguistic Research, 26(3):363–375.
Brent, Michael R. 1999. An efficient, probabilis-
tically sound algorithm for segmentation and
word discovery. Machine Learning, 34:71–105.
Brent, Michael R and Xiaopeng Tao. 2001. Chi-
nese text segmentation with mbdp-1: Making
the most of training corpora. In 39th Annual
Meeting of the ACL, pages 82–89.
Chen, Stanley F and Joshua Goodman. 1998. An
empirical study of smoothing techniques for lan-
guage modeling. Technical Report TR-10-98,
</reference>
<page confidence="0.98013">
71
</page>
<reference confidence="0.998932865671642">
Center for Research in Computing Technology,
Harvard University.
Cole, Ronald and Jola Jakimik. 1980. A model of
speech perception, pages 136–163. Lawrence
Erlbaum Associates, Hillsdale, NJ.
Coleman, John and Janet Pierrehumbert. 1997.
Stochastic phonological grammars and accept-
ability. In Third Meeting of the ACL SIGPHON,
pages 49–56. ACL, Somerset, NJ.
Cutler, Anne and David Carter. 1987. The predom-
inance of strong initial syllables in the english
vocabulary. Computer Speech and Language,
2(3-4):133–142.
de Marcken, Carl. 1995. Acquiring a lexicon from
unsegmented speech. In 33rd Annual Meeting
of the ACL, pages 311–313.
Fleck, Margaret M. 2008. Lexicalized phonotactic
word segmentation. In 46th Annual Meeting of
the ACL, pages 130–138. ACL, Morristown, NJ.
Goldwater, Sharon. 2007. Nonparametric
Bayesian Models of Lexical Acquisition. Ph.D.
thesis, Brown University, Department of Cogni-
tive and Linguistic Sciences.
Harris, Zellig. 1954. Distributional structure.
Word, 10(2/3):146–62.
Hayes, Bruce and Colin Wilson. 2008. A maxi-
mum entropy model of phonotactics and phono-
tactic learning. Linguistic Inquiry.
Heinz, Jeffrey. 2007. Inductive Learning of Phono-
tactic Patterns. Ph.D. thesis, University of Cali-
fornia, Los Angeles, Department of Linguistics.
Johnson, Mark. 2008a. Unsupervised word seg-
mentation for sesotho using adaptor grammars.
In Tenth Meeting ofACL SIGMORPHON, pages
20–27. ACL, Morristown, NJ.
Johnson, Mark. 2008b. Using adaptor grammars
to identify synergies in the unsupervised acqui-
sition of linguistic structure. In 46th Annual
Meeting of the ACL, pages 398–406. ACL, Mor-
ristown, NJ.
Jurafsky, Daniel and James Martin. 2000. Speech
and Language Processing. Prentice-Hall.
MacWhinney, Brian and Catherine Snow. 1985.
The child language data exchange system. Jour-
nal of child language, 12(2):271–95.
Manning, Christopher and Hinrich Sch¨utze. 1999.
Foundations of Statistical Natural Language
Processing. MIT Press.
Mattys, Sven and Peter Jusczyk. 2001. Phonotac-
tic cues for segmentation of fluent speech by in-
fants. Cognition, 78:91–121.
Mattys, Sven, Peter Jusczyk, Paul Luce, and James
Morgan. 1999. Phonotactic and prosodic effects
on word segmentation in infants. Cognitive Psy-
chology, 38:465–494.
Olivier, Donald. 1968. Stochastic Grammars and
Language Acquisition Mechanisms. Ph.D. the-
sis, Harvard Univerity.
Scholes, Robert. 1966. Phonotactic Grammatical-
ity. Mouton, The Hague.
Teahan, W. J., Rodger McNab, Yingying Wen, and
Ian H. Witten. 2000. A compression-based al-
gorithm for chinese word segmentation. Com-
putational Linguistics, 26(3):375–393.
Venkataraman, Anand. 2001. A statistical model
for word discovery in transcribed speech. Com-
putational Linguistics, 27(3):352–372.
</reference>
<page confidence="0.998725">
72
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.689748">
<title confidence="0.999729">Improving Word Segmentation by Simultaneously Learning Phonotactics</title>
<author confidence="0.991698">Daniel</author>
<affiliation confidence="0.999574">Computer &amp; Information University of</affiliation>
<email confidence="0.9988">dsblanch@udel.edu</email>
<author confidence="0.96145">Jeffrey</author>
<affiliation confidence="0.9911265">Linguistics &amp; Cognitive University of</affiliation>
<email confidence="0.998135">heinz@udel.edu</email>
<abstract confidence="0.992214529411765">The most accurate unsupervised word segmentation systems that are currently available (Brent, 1999; Venkataraman, 2001; Goldwater, 2007) use a simple unigram model of phonotactics. While this simplifies some of the calculations, it overlooks cues that infant language acquisition researchers have shown to be useful for segmentation (Mattys et al., 1999; Mattys and Jusczyk, 2001). Here we explore the utility of using bigram and trigram phonotactic models by enhancing Brent’s (1999) MBDP-1 algorithm. The results show the improved MBDP-Phon model outperforms other unsupervised word segmentation systems (e.g., Brent, 1999; Venkatara-</abstract>
<address confidence="0.775892">man, 2001; Goldwater, 2007).</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eleanor Olds Batchelder</author>
</authors>
<title>Bootstrapping the lexicon: a computational model of infant speech segmentation.</title>
<date>2002</date>
<journal>Cognition,</journal>
<volume>83</volume>
<issue>2</issue>
<contexts>
<context position="8142" citStr="Batchelder (2002)" startWordPosition="1331" endWordPosition="1332">ent (1999) originally described the novel word score as R(wk) = 6 · nk · Pσ(Wnk ) (nk −11 π2 k · , nk−1·Enk 1− Pσ(Wj) nk nk j=1 where Po is the probability of all the phonemes in the word occurring together, but the denominator of the third term was dropped in Brent and Tao (2001). This change drastically speeds up the model, and only reduces segmentation accuracy by ∼ 0.5%. 6 n π2 · k · 2 (3) 2 66 2.1.2 Venkataraman (2001) MBDP-1 is not the only incremental unsupervised segmentation model that achieves promising results. Venkataraman’s (2001) model tracks MBDP-1’s performance so closely that Batchelder (2002) posits that the models are performing the same operations, even though the authors describe them differently. Venkataraman’s model uses a more traditional, smoothed n-gram model to describe the distribution of words in an unsegmented text.2 The most probable segmentation is retrieved via a dynamic programming algorithm, much like Brent (1999). We use MBDP-1 rather than Venkataraman’s approach as the basis for our model only because it was more transparent how to plug in a phonotactic learning module at the time this project began. 2.1.3 Goldwater (2007) We also compare our results to a segmen</context>
</contexts>
<marker>Batchelder, 2002</marker>
<rawString>Batchelder, Eleanor Olds. 2002. Bootstrapping the lexicon: a computational model of infant speech segmentation. Cognition, 83(2):167–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nan Bernstein-Ratner</author>
</authors>
<title>The phonology of parent child speech, volume 6. Erlbaum,</title>
<date>1987</date>
<location>Hillsdale, NJ.</location>
<marker>Bernstein-Ratner, 1987</marker>
<rawString>Bernstein-Ratner, Nan. 1987. The phonology of parent child speech, volume 6. Erlbaum, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avrim Blum</author>
<author>Tom Mitchell</author>
</authors>
<title>Combining labeled and unlabeled data with co-training.</title>
<date>1998</date>
<booktitle>In Workshop on Computational Learning Theory,</booktitle>
<pages>92--100</pages>
<contexts>
<context position="14583" citStr="Blum and Mitchell, 1998" startWordPosition="2390" endWordPosition="2393">xtracted. The phonotactic learner is guaranteed to see at least two valid patterns in every utterance, as the n-grams that occur at the beginnings and ends of utterances are definitely at the beginnings and ends of words. This allows the learner to provide useful information to the segmenter even early on, and as the segmenter correctly identifies more words, the phonotactic learner has more correct data to learn from. Not only is this mutually beneficial process supported by evidence from language acquisitionists (Mattys et al., 1999; Mattys and Jusczyk, 2001), it also resembles co-training (Blum and Mitchell, 1998). We refer to the extended version of Brent’s model 6This intuition is backed up by preliminary results suggesting MBDP-Phon performs better when using MLEs of the joint probability as opposed to conditional probability. There is an interesting question here, which is beyond the scope of this paper, so we leave it for future investigation. described above as MBDP-Phon. 4 Evaluation 4.1 The Corpus We run all of our experiments on the BernsteinRatner (1987) infant-directed speech corpus from the CHILDES database (MacWhinney and Snow, 1985). This is the same corpus that Brent (1999), Goldwater (2</context>
</contexts>
<marker>Blum, Mitchell, 1998</marker>
<rawString>Blum, Avrim and Tom Mitchell. 1998. Combining labeled and unlabeled data with co-training. In Workshop on Computational Learning Theory, pages 92–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heather Bortfeld</author>
<author>James Morgan</author>
<author>Roberta Golinkoff</author>
<author>Karen Rathbun</author>
</authors>
<title>Mommy and me: Familiar names help launch babies into speech-stream segmentation.</title>
<date>2005</date>
<journal>Psychological Science,</journal>
<volume>16</volume>
<issue>4</issue>
<contexts>
<context position="1873" citStr="Bortfeld et al., 2005" startWordPosition="281" endWordPosition="284">ds (Cole and Jakimik, 1980). In fact, languages vary on how they signal the ends of words (Cutler and Carter, 1987), which makes the task even more daunting. Adults at least have a lexicon they can use to recognize familiar words, but when an infant is first born, they do not have a pre-existing lexicon to consult. In spite of these challenges, by the age of © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. six months infants can begin to segment words out of speech (Bortfeld et al., 2005). Here we present an efficient word segmentation system aimed to model how infants accomplish the task. While an algorithm that could reliably extract orthographic representations of both novel and familiar words from acoustic data is something we would like to see developed, following earlier researchers, we simplify the problem by using a text that does not contain any word boundary markers. Hereafter, we use the phrase “word segmentation” to mean some process which adds word boundaries to a text that does not contain them. This paper’s focus is on unsupervised, incremental word segmentation</context>
</contexts>
<marker>Bortfeld, Morgan, Golinkoff, Rathbun, 2005</marker>
<rawString>Bortfeld, Heather, James Morgan, Roberta Golinkoff, and Karen Rathbun. 2005. Mommy and me: Familiar names help launch babies into speech-stream segmentation. Psychological Science, 16(4):298–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Brent</author>
</authors>
<title>Towards a unified model of lexical acquisition and lexical access.</title>
<date>1997</date>
<journal>Journal of Psycholinguistic Research,</journal>
<volume>26</volume>
<issue>3</issue>
<contexts>
<context position="5227" citStr="Brent, 1997" startWordPosition="797" endWordPosition="798">n The problem of unsupervised word segmentation has attracted many earlier researchers over the past fifty years (e.g., Harris, 1954; Olivier, 1968; de Marcken, 1995; Brent, 1999). In this section, we describe the base model MBDP-1, along with two other segmentation approaches, Venkataraman (2001) and Goldwater (2007). In §4, we compare MBDP-Phon to these models in more detail. For a thorough review of word segmentation literature, see Brent (1999) or Goldwater (2007). 2.1.1 MBDP-1 Brent’s (1999) MBDP-1 (Model Based Dynamic Programming) algorithm is an implementation of the INCDROP framework (Brent, 1997) that uses a Bayesian model of how to generate an unsegmented text to insert word boundaries. The generative model consists of five steps: 1. Choose a number of word types, n. 2. Pick n distinct strings from E+#, which will make up the lexicon, L. Entries in L are labeled W1 ... Wn. W0 = $, where $ is the utterance boundary marker. 3. Pick a function, f, which maps word types to their frequency in the text. 4. Choose a function, s, to map positions in the text to word types. 5. Concatenate the words in the order specified by s, and remove the word delimiters (#). It is important to note that t</context>
<context position="24822" citStr="Brent, 1997" startWordPosition="4004" endWordPosition="4005">ore accurate than the models described in Brent (1999), Venkataraman (2001), and Goldwater (2007). The n-gram phonotactic model improves overall performance, and is especially useful for corpora that do not encode diphthongs with bi-phone symbols. The main reason there is such a marked improvement with MBDP-Phon vs. MBDP-1 when the bi-phone symbols were removed from the original corpus is that these biphone symbols effectively allow MBDP-1 to have a select few bigrams in the cases where it would otherwise over-segment. The success of MBDP-Phon is not clear evidence that the INCDROP framework (Brent, 1997) is superior to Venkataraman or Goldwater’s models. We imagine that adding a phonotactic learning component to either of their models would also improve their performance. We also tentatively conclude that phonotactic patterns can be learned from unsegmented text. However, the phonotactic patterns learned by our model ought to be studied in detail to see how well they match the phonotactic patterns of English. MBDP-Phon’s performance reinforces the theory put forward by language acquisition researchers that phonotactic knowledge is a cue for word segmentation (Mattys et al., 1999; Mattys and J</context>
</contexts>
<marker>Brent, 1997</marker>
<rawString>Brent, Michael R. 1997. Towards a unified model of lexical acquisition and lexical access. Journal of Psycholinguistic Research, 26(3):363–375.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Brent</author>
</authors>
<title>An efficient, probabilistically sound algorithm for segmentation and word discovery.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>34--71</pages>
<contexts>
<context position="875" citStr="Brent, 1999" startWordPosition="121" endWordPosition="122">rate unsupervised word segmentation systems that are currently available (Brent, 1999; Venkataraman, 2001; Goldwater, 2007) use a simple unigram model of phonotactics. While this simplifies some of the calculations, it overlooks cues that infant language acquisition researchers have shown to be useful for segmentation (Mattys et al., 1999; Mattys and Jusczyk, 2001). Here we explore the utility of using bigram and trigram phonotactic models by enhancing Brent’s (1999) MBDP-1 algorithm. The results show the improved MBDP-Phon model outperforms other unsupervised word segmentation systems (e.g., Brent, 1999; Venkataraman, 2001; Goldwater, 2007). 1 Introduction How do infants come to identify words in the speech stream? As adults, we break up speech into words with such ease that we often think that there are audible pauses between words in the same sentence. However, unlike some written languages, speech does not have any completely reliable markers for the breaks between words (Cole and Jakimik, 1980). In fact, languages vary on how they signal the ends of words (Cutler and Carter, 1987), which makes the task even more daunting. Adults at least have a lexicon they can use to recognize familiar </context>
<context position="4794" citStr="Brent, 1999" startWordPosition="731" endWordPosition="732"> they use it to make judgements about what phoneme sequences can occur within versus across word boundaries (Mattys and Jusczyk, 2001). We use this insight, also suggested by Venkataraman (2001) and recently utilized by Fleck (2008) in a different manner, to enhance Brent’s (1999) model MBDP-1, and significantly increase segmentation accuracy. We call this modified segmentation model MBDP-Phon. 2 Related Work 2.1 Word Segmentation The problem of unsupervised word segmentation has attracted many earlier researchers over the past fifty years (e.g., Harris, 1954; Olivier, 1968; de Marcken, 1995; Brent, 1999). In this section, we describe the base model MBDP-1, along with two other segmentation approaches, Venkataraman (2001) and Goldwater (2007). In §4, we compare MBDP-Phon to these models in more detail. For a thorough review of word segmentation literature, see Brent (1999) or Goldwater (2007). 2.1.1 MBDP-1 Brent’s (1999) MBDP-1 (Model Based Dynamic Programming) algorithm is an implementation of the INCDROP framework (Brent, 1997) that uses a Bayesian model of how to generate an unsegmented text to insert word boundaries. The generative model consists of five steps: 1. Choose a number of word t</context>
<context position="7535" citStr="Brent (1999)" startWordPosition="1222" endWordPosition="1223">ay. We detail how to plug a more sophisticated phonotactic learning model into this equation in §3. With the generative model established, MBDP-1 uses a Viterbi-style search algorithm to find the segmentation for each utterance that maximizes the R values for each word in the segmentation. Venkataraman (2001) notes that considering the generation of the text as a single event is unlikely to be how infants approach the segmentation problem. However, MBDP-1 uses an incremental search algorithm to segment one utterance at a time, which is more plausible as a model of infants’ word segmentation. 1Brent (1999) originally described the novel word score as R(wk) = 6 · nk · Pσ(Wnk ) (nk −11 π2 k · , nk−1·Enk 1− Pσ(Wj) nk nk j=1 where Po is the probability of all the phonemes in the word occurring together, but the denominator of the third term was dropped in Brent and Tao (2001). This change drastically speeds up the model, and only reduces segmentation accuracy by ∼ 0.5%. 6 n π2 · k · 2 (3) 2 66 2.1.2 Venkataraman (2001) MBDP-1 is not the only incremental unsupervised segmentation model that achieves promising results. Venkataraman’s (2001) model tracks MBDP-1’s performance so closely that Batchelder</context>
<context position="11367" citStr="Brent, 1999" startWordPosition="1841" endWordPosition="1842">ill-formedness is attributable to onsets. This basic trigram model explains 87.7% of the variance in the scores that Scholes (1966) reports his 7th grade students gave when subjected to the same test. When Hayes and Wilson run their Maximum Entropy phonotactic learning model with n-grams over phonological features, the r-score increases substantially to 95.6%. Given the success and simplicity of the basic ngram phonotactic model, we choose to integrate this with MBDP-1. 3 Extending MBDP-1 with Phonotactics The main contribution of our work is adding a phonotactic learning component to MBDP-1 (Brent, 1999). As we mention in §2.1.1, the third term of Equation 3 is where MBDP-1’s unigram phonotactic assumption surfaces. The original model simply multiplies the probabilities of all the phonemes in the word together and divides by one minus the probability of a particular phoneme being the word boundary to come up with probability of the phoneme combination. The order of the phonemes in the word has no effect on its score. The only change we make to MBDP-1 is to the third term of Equation 3. In MBDP-Phon this becomes PMLE(ai ... aj) (4) where ai ... aj is an n-gram inside a proposed word, and a0 an</context>
<context position="15169" citStr="Brent (1999)" startWordPosition="2486" endWordPosition="2487"> (Blum and Mitchell, 1998). We refer to the extended version of Brent’s model 6This intuition is backed up by preliminary results suggesting MBDP-Phon performs better when using MLEs of the joint probability as opposed to conditional probability. There is an interesting question here, which is beyond the scope of this paper, so we leave it for future investigation. described above as MBDP-Phon. 4 Evaluation 4.1 The Corpus We run all of our experiments on the BernsteinRatner (1987) infant-directed speech corpus from the CHILDES database (MacWhinney and Snow, 1985). This is the same corpus that Brent (1999), Goldwater (2007), and Venkataraman (2001) evaluate their models on, and it has become the de facto standard for segmentation testing, as unlike other corpora in CHILDES, it was phonetically transcribed. We examine the transcription system Brent (1999) uses and conclude some unorthodox choices were made when transcribing the corpus. Specifically, some phonemes that are normally considered distinct are combined into one symbol, which we call a bi-phone symbol. These phonemes combinations include diphthongs and vowels followed by /a/. Another seemingly arbitrary decision is the distinction betw</context>
<context position="16479" citStr="Brent (1999)" startWordPosition="2695" endWordPosition="2696">butter” and the /a/ in “bird”) since stress is not marked elsewhere in the corpus. To see the effect of these decisions, we modified the corpus so that the bi-phone symbols were split into two7 and the syllabic /a/ symbols were collapsed into one. 4.2 Accuracy We ran MBDP-1 on the original corpus, and the modified version of the corpus. As illustrated by Figures 1 and 2, MBDP-1 performs worse on the modified corpus with respect to both precision and recall. As MBDP-1 and MBDP-Phon are both iterative learners, we calculate segmentation precision and recall values over 500-utterance blocks. Per Brent (1999) and Goldwater (2007), precision and recall scores reflect correctly segmented words, not correctly identified boundaries. We also test to see how the addition of an n-gram phonotactic model affects the segmentation accuracy of MBDP-Phon by comparing it to MBDP1 on our modified corpus.8 As seen in Figure 3, MBDP-Phon using bigrams (henceforth MBDPPhon-Bigrams) is consistently more precise in its 7We only split diphthongs whose first phoneme can occur in isolation in English, so the vowels in “bay” and “boat” were not split. 8We also compare MBDP-Phon to MBDP-1 on the original corpus. The resul</context>
<context position="20947" citStr="Brent, 1999" startWordPosition="3404" endWordPosition="3405">odified: Utterances 0 to 9790 Avg. 74.63% 66.24% 70.48% Max. 82.45% 70.47% 74.79% Min. 47.63% 44.71% 63.74% Modified: Utterances 500 to 9790 Avg. 76.05% 67.37% 70.28% Max. 82.45% 70.47% 74.79% Min. 71.92% 63.86% 63.74% Table 2: Recall statistics for MBDP-PhonBigrams, Goldwater, and Venkataraman on both corpora over 500-utterance blocks. The only metric by which MBDP-PhonBigrams does not outperform the other algorithms is lexical precision, as shown in Table 3. Lexical precision is the ratio of the number of correctly identified words in the lexicon to the total number of words in the lexicon (Brent, 1999; Venkataraman, 2001).10 The relatively poor performance of MBDP-Phon-Bigrams is due to the incremental nature of the MBDP algorithm. Initially, it makes numerous incorrect guesses that are added to the lexicon, and there is no point at which the lexicon is purged of earlier erroneous guesses (c.f. the improved lexical precision when omitting the first block in Table 3). On the other hand, Goldwater’s algorithm runs over the corpus multiple times, and only produces output when it settles on a final segmentation. In sum, MBDP-Phon-Bigrams significantly improves the accuracy of MBDP-1, and achie</context>
<context position="24264" citStr="Brent (1999)" startWordPosition="3916" endWordPosition="3917"> 9790 Avg. 54.34% 53.06% 57.95% Max. 63.76% 54.35% 62.30% Min. 51.31% 51.95% 56.52% Table 3: Lexical precision statistics for MBDPPhon-Bigrams, Goldwater, and Venkataraman on both corpora over 500-utterance blocks. ing the abilities of these segmenters on corpora of different languages. Fleck (2008) tests her segmenter on a number of corpora, including Arabic and Spanish, and Johnson (2008a) applies his segmenter to a corpus of Sesotho. 6 Conclusion From the results established in §4, we can conclude that MBDP-Phon using a bigram phonotactic model is more accurate than the models described in Brent (1999), Venkataraman (2001), and Goldwater (2007). The n-gram phonotactic model improves overall performance, and is especially useful for corpora that do not encode diphthongs with bi-phone symbols. The main reason there is such a marked improvement with MBDP-Phon vs. MBDP-1 when the bi-phone symbols were removed from the original corpus is that these biphone symbols effectively allow MBDP-1 to have a select few bigrams in the cases where it would otherwise over-segment. The success of MBDP-Phon is not clear evidence that the INCDROP framework (Brent, 1997) is superior to Venkataraman or Goldwater’</context>
</contexts>
<marker>Brent, 1999</marker>
<rawString>Brent, Michael R. 1999. An efficient, probabilistically sound algorithm for segmentation and word discovery. Machine Learning, 34:71–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Brent</author>
<author>Xiaopeng Tao</author>
</authors>
<title>Chinese text segmentation with mbdp-1: Making the most of training corpora.</title>
<date>2001</date>
<booktitle>In 39th Annual Meeting of the ACL,</booktitle>
<pages>82--89</pages>
<contexts>
<context position="6694" citStr="Brent and Tao, 2001" startWordPosition="1077" endWordPosition="1080">rticular segmentation, wm, can be calculated as: P(wm) = P(n, L, f, s) (1) To allow the model to operate on one utterance at a time, Brent states the probability of each word in the text as a recursive function, R(wk), where wk is the text up to and including the word at position k, wk. Furthermore, there are two specific cases for R: familiar words and novel words. If wk is familiar, the model already has the word in its lexicon, and its score is calculated as in Equation 2. R(wk) = f(wk) Cf (wk) − 112 (2) k f(wk) J Otherwise, the word is novel, and its score is calculated using Equation 31 (Brent and Tao, 2001), R(wk) = PΣ(a1) ... PΣ(ay) (n−11 1−PΣ(#) ·n ) where PE is the probability of a particular phoneme occurring in the text. The third term of the equation for novel words is where the model’s unigram phonotactic model comes into play. We detail how to plug a more sophisticated phonotactic learning model into this equation in §3. With the generative model established, MBDP-1 uses a Viterbi-style search algorithm to find the segmentation for each utterance that maximizes the R values for each word in the segmentation. Venkataraman (2001) notes that considering the generation of the text as a singl</context>
</contexts>
<marker>Brent, Tao, 2001</marker>
<rawString>Brent, Michael R and Xiaopeng Tao. 2001. Chinese text segmentation with mbdp-1: Making the most of training corpora. In 39th Annual Meeting of the ACL, pages 82–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
<author>Joshua Goodman</author>
</authors>
<title>An empirical study of smoothing techniques for language modeling.</title>
<date>1998</date>
<tech>Technical Report TR-10-98,</tech>
<contexts>
<context position="22025" citStr="Chen and Goodman, 1998" startWordPosition="3576" endWordPosition="3580"> only produces output when it settles on a final segmentation. In sum, MBDP-Phon-Bigrams significantly improves the accuracy of MBDP-1, and achieves better performance than the models described in Venkataraman (2001) and Goldwater (2007). 5 Future Work There are many ways to implement phonotactic learning. One idea is to to use n-grams over phonological features, as per Hayes and Wilson (2008). Preliminary results have shown that we need to add smoothing to our n-gram model, and we plan to use 10See Brent (1999) for a discussion of the meaning of this statistic. Modified Kneser-Ney smoothing (Chen and Goodman, 1998). Another approach would be to develop a syllable-based phonotactic model (Coleman and Pierrehumbert, 1997). Johnson (2008b) achieves impressive segmentation results by adding a syllable level with Adaptor grammars. Some languages (e.g., Finnish, and Navajo) contain long-distance phonotactic constraints that cannot be learned by n-gram learners (Heinz, 2007). Heinz (2007) shows that precedence-based learners—which work like a bigram model, but without the restriction that the elements in the bigram be adjacent—can handle many long-distance agreement patterns (e.g., vowel and consonantal harmon</context>
</contexts>
<marker>Chen, Goodman, 1998</marker>
<rawString>Chen, Stanley F and Joshua Goodman. 1998. An empirical study of smoothing techniques for language modeling. Technical Report TR-10-98,</rawString>
</citation>
<citation valid="false">
<institution>Center for Research in Computing Technology, Harvard University.</institution>
<marker></marker>
<rawString>Center for Research in Computing Technology, Harvard University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald Cole</author>
<author>Jola Jakimik</author>
</authors>
<title>A model of speech perception,</title>
<date>1980</date>
<pages>136--163</pages>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="1278" citStr="Cole and Jakimik, 1980" startWordPosition="187" endWordPosition="190">ility of using bigram and trigram phonotactic models by enhancing Brent’s (1999) MBDP-1 algorithm. The results show the improved MBDP-Phon model outperforms other unsupervised word segmentation systems (e.g., Brent, 1999; Venkataraman, 2001; Goldwater, 2007). 1 Introduction How do infants come to identify words in the speech stream? As adults, we break up speech into words with such ease that we often think that there are audible pauses between words in the same sentence. However, unlike some written languages, speech does not have any completely reliable markers for the breaks between words (Cole and Jakimik, 1980). In fact, languages vary on how they signal the ends of words (Cutler and Carter, 1987), which makes the task even more daunting. Adults at least have a lexicon they can use to recognize familiar words, but when an infant is first born, they do not have a pre-existing lexicon to consult. In spite of these challenges, by the age of © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. six months infants can begin to segment words out of speech (Bortfeld et al., 2005). Her</context>
</contexts>
<marker>Cole, Jakimik, 1980</marker>
<rawString>Cole, Ronald and Jola Jakimik. 1980. A model of speech perception, pages 136–163. Lawrence Erlbaum Associates, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Coleman</author>
<author>Janet Pierrehumbert</author>
</authors>
<title>Stochastic phonological grammars and acceptability.</title>
<date>1997</date>
<booktitle>In Third Meeting of the ACL SIGPHON,</booktitle>
<pages>49--56</pages>
<publisher>ACL,</publisher>
<location>Somerset, NJ.</location>
<contexts>
<context position="3830" citStr="Coleman and Pierrehumbert (1997)" startWordPosition="580" endWordPosition="584">inguists and acquisitionists interested in the problem of language learning, as well as theoretical computer scientists who are interested in what unsupervised, incremental models are capable of achieving. Phonotactic patterns are the rules that determine what sequences of phonemes or allophones are allowable within words. Learning the phonotactic patterns of a language is usually modeled 65 CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 65–72 Manchester, August 2008 separately from word segmentation; e.g., current phonotactic learners such as Coleman and Pierrehumbert (1997), Heinz (2007), or Hayes and Wilson (2008) are given word-sized units as input. However, infants appear to simultaneously learn which phoneme combinations are allowable within words and how to extract words from the input. It is reasonable that the two processes feed into one another, and when infants acquire a critical mass of phonotactic knowledge, they use it to make judgements about what phoneme sequences can occur within versus across word boundaries (Mattys and Jusczyk, 2001). We use this insight, also suggested by Venkataraman (2001) and recently utilized by Fleck (2008) in a different </context>
<context position="22132" citStr="Coleman and Pierrehumbert, 1997" startWordPosition="3591" endWordPosition="3594">ntly improves the accuracy of MBDP-1, and achieves better performance than the models described in Venkataraman (2001) and Goldwater (2007). 5 Future Work There are many ways to implement phonotactic learning. One idea is to to use n-grams over phonological features, as per Hayes and Wilson (2008). Preliminary results have shown that we need to add smoothing to our n-gram model, and we plan to use 10See Brent (1999) for a discussion of the meaning of this statistic. Modified Kneser-Ney smoothing (Chen and Goodman, 1998). Another approach would be to develop a syllable-based phonotactic model (Coleman and Pierrehumbert, 1997). Johnson (2008b) achieves impressive segmentation results by adding a syllable level with Adaptor grammars. Some languages (e.g., Finnish, and Navajo) contain long-distance phonotactic constraints that cannot be learned by n-gram learners (Heinz, 2007). Heinz (2007) shows that precedence-based learners—which work like a bigram model, but without the restriction that the elements in the bigram be adjacent—can handle many long-distance agreement patterns (e.g., vowel and consonantal harmony) in the world’s languages. We posit that adding such a learner to MBDP-Phon would allow it to handle a gr</context>
</contexts>
<marker>Coleman, Pierrehumbert, 1997</marker>
<rawString>Coleman, John and Janet Pierrehumbert. 1997. Stochastic phonological grammars and acceptability. In Third Meeting of the ACL SIGPHON, pages 49–56. ACL, Somerset, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anne Cutler</author>
<author>David Carter</author>
</authors>
<title>The predominance of strong initial syllables in the english vocabulary.</title>
<date>1987</date>
<journal>Computer Speech and Language,</journal>
<pages>2--3</pages>
<contexts>
<context position="1366" citStr="Cutler and Carter, 1987" startWordPosition="203" endWordPosition="206"> algorithm. The results show the improved MBDP-Phon model outperforms other unsupervised word segmentation systems (e.g., Brent, 1999; Venkataraman, 2001; Goldwater, 2007). 1 Introduction How do infants come to identify words in the speech stream? As adults, we break up speech into words with such ease that we often think that there are audible pauses between words in the same sentence. However, unlike some written languages, speech does not have any completely reliable markers for the breaks between words (Cole and Jakimik, 1980). In fact, languages vary on how they signal the ends of words (Cutler and Carter, 1987), which makes the task even more daunting. Adults at least have a lexicon they can use to recognize familiar words, but when an infant is first born, they do not have a pre-existing lexicon to consult. In spite of these challenges, by the age of © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. six months infants can begin to segment words out of speech (Bortfeld et al., 2005). Here we present an efficient word segmentation system aimed to model how infants accomplish</context>
</contexts>
<marker>Cutler, Carter, 1987</marker>
<rawString>Cutler, Anne and David Carter. 1987. The predominance of strong initial syllables in the english vocabulary. Computer Speech and Language, 2(3-4):133–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl de Marcken</author>
</authors>
<title>Acquiring a lexicon from unsegmented speech.</title>
<date>1995</date>
<booktitle>In 33rd Annual Meeting of the ACL,</booktitle>
<pages>311--313</pages>
<marker>de Marcken, 1995</marker>
<rawString>de Marcken, Carl. 1995. Acquiring a lexicon from unsegmented speech. In 33rd Annual Meeting of the ACL, pages 311–313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Margaret M Fleck</author>
</authors>
<title>Lexicalized phonotactic word segmentation.</title>
<date>2008</date>
<booktitle>In 46th Annual Meeting of the ACL,</booktitle>
<pages>130--138</pages>
<publisher>ACL,</publisher>
<location>Morristown, NJ.</location>
<contexts>
<context position="3035" citStr="Fleck, 2008" startWordPosition="466" endWordPosition="467"> is on unsupervised, incremental word segmentation algorithms; i.e., those that do not rely on preexisting knowledge of a particular language, and those that segment the corpus one utterance at a time. This is in contrast to supervised word segmentation algorithms (e.g., Teahan et al., 2000), which are typically used for segmenting text in documents written in languages that do not put spaces between their words like Chinese. (Of course, unsupervised word segmentation algorithms also have this application.) This also differs from batch segmentation algorithms (Goldwater, 2007; Johnson, 2008b; Fleck, 2008), which process the entire corpus at least once before outputting a segmentation of the corpus. Unsupervised incremental algorithms are of interest to some psycholinguists and acquisitionists interested in the problem of language learning, as well as theoretical computer scientists who are interested in what unsupervised, incremental models are capable of achieving. Phonotactic patterns are the rules that determine what sequences of phonemes or allophones are allowable within words. Learning the phonotactic patterns of a language is usually modeled 65 CoNLL 2008: Proceedings of the 12th Confer</context>
<context position="4414" citStr="Fleck (2008)" startWordPosition="676" endWordPosition="677">man and Pierrehumbert (1997), Heinz (2007), or Hayes and Wilson (2008) are given word-sized units as input. However, infants appear to simultaneously learn which phoneme combinations are allowable within words and how to extract words from the input. It is reasonable that the two processes feed into one another, and when infants acquire a critical mass of phonotactic knowledge, they use it to make judgements about what phoneme sequences can occur within versus across word boundaries (Mattys and Jusczyk, 2001). We use this insight, also suggested by Venkataraman (2001) and recently utilized by Fleck (2008) in a different manner, to enhance Brent’s (1999) model MBDP-1, and significantly increase segmentation accuracy. We call this modified segmentation model MBDP-Phon. 2 Related Work 2.1 Word Segmentation The problem of unsupervised word segmentation has attracted many earlier researchers over the past fifty years (e.g., Harris, 1954; Olivier, 1968; de Marcken, 1995; Brent, 1999). In this section, we describe the base model MBDP-1, along with two other segmentation approaches, Venkataraman (2001) and Goldwater (2007). In §4, we compare MBDP-Phon to these models in more detail. For a thorough rev</context>
<context position="23952" citStr="Fleck (2008)" startWordPosition="3860" endWordPosition="3861">g forward to investigat70 MBDP- Venkataraman Goldwater PhonBigrams Original: Utterances 0 to 9790 Avg. 47.69% 49.78% 56.50% Max. 49.71% 52.95% 63.09% Min. 46.30% 41.83% 55.33% Modified: Utterances 0 to 9790 Avg. 48.31% 45.98% 58.03% Max. 50.42% 48.90% 65.58% Min. 41.74% 36.57% 56.43% Modified: Utterances 500 to 9790 Avg. 54.34% 53.06% 57.95% Max. 63.76% 54.35% 62.30% Min. 51.31% 51.95% 56.52% Table 3: Lexical precision statistics for MBDPPhon-Bigrams, Goldwater, and Venkataraman on both corpora over 500-utterance blocks. ing the abilities of these segmenters on corpora of different languages. Fleck (2008) tests her segmenter on a number of corpora, including Arabic and Spanish, and Johnson (2008a) applies his segmenter to a corpus of Sesotho. 6 Conclusion From the results established in §4, we can conclude that MBDP-Phon using a bigram phonotactic model is more accurate than the models described in Brent (1999), Venkataraman (2001), and Goldwater (2007). The n-gram phonotactic model improves overall performance, and is especially useful for corpora that do not encode diphthongs with bi-phone symbols. The main reason there is such a marked improvement with MBDP-Phon vs. MBDP-1 when the bi-phone</context>
</contexts>
<marker>Fleck, 2008</marker>
<rawString>Fleck, Margaret M. 2008. Lexicalized phonotactic word segmentation. In 46th Annual Meeting of the ACL, pages 130–138. ACL, Morristown, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
</authors>
<title>Nonparametric Bayesian Models of Lexical Acquisition.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>Brown University, Department of Cognitive and Linguistic Sciences.</institution>
<contexts>
<context position="913" citStr="Goldwater, 2007" startWordPosition="126" endWordPosition="127">on systems that are currently available (Brent, 1999; Venkataraman, 2001; Goldwater, 2007) use a simple unigram model of phonotactics. While this simplifies some of the calculations, it overlooks cues that infant language acquisition researchers have shown to be useful for segmentation (Mattys et al., 1999; Mattys and Jusczyk, 2001). Here we explore the utility of using bigram and trigram phonotactic models by enhancing Brent’s (1999) MBDP-1 algorithm. The results show the improved MBDP-Phon model outperforms other unsupervised word segmentation systems (e.g., Brent, 1999; Venkataraman, 2001; Goldwater, 2007). 1 Introduction How do infants come to identify words in the speech stream? As adults, we break up speech into words with such ease that we often think that there are audible pauses between words in the same sentence. However, unlike some written languages, speech does not have any completely reliable markers for the breaks between words (Cole and Jakimik, 1980). In fact, languages vary on how they signal the ends of words (Cutler and Carter, 1987), which makes the task even more daunting. Adults at least have a lexicon they can use to recognize familiar words, but when an infant is first bor</context>
<context position="3005" citStr="Goldwater, 2007" startWordPosition="462" endWordPosition="463"> contain them. This paper’s focus is on unsupervised, incremental word segmentation algorithms; i.e., those that do not rely on preexisting knowledge of a particular language, and those that segment the corpus one utterance at a time. This is in contrast to supervised word segmentation algorithms (e.g., Teahan et al., 2000), which are typically used for segmenting text in documents written in languages that do not put spaces between their words like Chinese. (Of course, unsupervised word segmentation algorithms also have this application.) This also differs from batch segmentation algorithms (Goldwater, 2007; Johnson, 2008b; Fleck, 2008), which process the entire corpus at least once before outputting a segmentation of the corpus. Unsupervised incremental algorithms are of interest to some psycholinguists and acquisitionists interested in the problem of language learning, as well as theoretical computer scientists who are interested in what unsupervised, incremental models are capable of achieving. Phonotactic patterns are the rules that determine what sequences of phonemes or allophones are allowable within words. Learning the phonotactic patterns of a language is usually modeled 65 CoNLL 2008: </context>
<context position="4934" citStr="Goldwater (2007)" startWordPosition="751" endWordPosition="752">We use this insight, also suggested by Venkataraman (2001) and recently utilized by Fleck (2008) in a different manner, to enhance Brent’s (1999) model MBDP-1, and significantly increase segmentation accuracy. We call this modified segmentation model MBDP-Phon. 2 Related Work 2.1 Word Segmentation The problem of unsupervised word segmentation has attracted many earlier researchers over the past fifty years (e.g., Harris, 1954; Olivier, 1968; de Marcken, 1995; Brent, 1999). In this section, we describe the base model MBDP-1, along with two other segmentation approaches, Venkataraman (2001) and Goldwater (2007). In §4, we compare MBDP-Phon to these models in more detail. For a thorough review of word segmentation literature, see Brent (1999) or Goldwater (2007). 2.1.1 MBDP-1 Brent’s (1999) MBDP-1 (Model Based Dynamic Programming) algorithm is an implementation of the INCDROP framework (Brent, 1997) that uses a Bayesian model of how to generate an unsegmented text to insert word boundaries. The generative model consists of five steps: 1. Choose a number of word types, n. 2. Pick n distinct strings from E+#, which will make up the lexicon, L. Entries in L are labeled W1 ... Wn. W0 = $, where $ is the </context>
<context position="8702" citStr="Goldwater (2007)" startWordPosition="1418" endWordPosition="1419">s MBDP-1’s performance so closely that Batchelder (2002) posits that the models are performing the same operations, even though the authors describe them differently. Venkataraman’s model uses a more traditional, smoothed n-gram model to describe the distribution of words in an unsegmented text.2 The most probable segmentation is retrieved via a dynamic programming algorithm, much like Brent (1999). We use MBDP-1 rather than Venkataraman’s approach as the basis for our model only because it was more transparent how to plug in a phonotactic learning module at the time this project began. 2.1.3 Goldwater (2007) We also compare our results to a segmenter put forward by Goldwater (2007). Goldwater’s segmenter uses an underlying generative model, much like MBDP-1 does, only her language model is described as a Dirichlet process (see also Johnson, 2008b). While this model uses a unigram model of phoneme distribution, as did MBDP-1, it implements a bigram word model like Venkataraman (2001). A bigram word model is useful in that it prevents the segmenter from assuming that frequent word bigrams are not simply one word, which Goldwater observes happen with a unigram version of her model. Goldwater uses a </context>
<context position="10021" citStr="Goldwater (2007)" startWordPosition="1624" endWordPosition="1625">ions and determine the most likely segmentation of each utterance.3 This approach requires non-incremental learning.4 We include comparison with Goldwater’s segmenter because it outperforms MBDP-1 and Venkataraman (2001) in both precision and recall, and we are interested in whether an incremental algorithm supplemented with phonotactic learning can match its performance. 2.2 Phonotactic Learning Phonotactic acquisition models have seen a surge in popularity recently (e.g., Coleman and Pierre2We refer the reader to Venkataraman (2001) for the details of this approach. 3We direct the reader to Goldwater (2007) for details. 4In our experiments and those in Goldwater (2007), the segmenter runs through the corpus 1000 times before outputting the final segmentation. humbert, 1997; Heinz, 2007; Hayes and Wilson, 2008). While Hayes and Wilson present a more complex Maximum Entropy phonotactic model in their paper than the one we add to MBDP-1, they also evaluate a simple n-gram phonotactic learner operating over phonemes. The input to the models is a list of English onsets and their frequency in the lexicon, and the basic trigram learner simply keeps track of the trigrams it has seen in the corpus. They </context>
<context position="15187" citStr="Goldwater (2007)" startWordPosition="2488" endWordPosition="2489">chell, 1998). We refer to the extended version of Brent’s model 6This intuition is backed up by preliminary results suggesting MBDP-Phon performs better when using MLEs of the joint probability as opposed to conditional probability. There is an interesting question here, which is beyond the scope of this paper, so we leave it for future investigation. described above as MBDP-Phon. 4 Evaluation 4.1 The Corpus We run all of our experiments on the BernsteinRatner (1987) infant-directed speech corpus from the CHILDES database (MacWhinney and Snow, 1985). This is the same corpus that Brent (1999), Goldwater (2007), and Venkataraman (2001) evaluate their models on, and it has become the de facto standard for segmentation testing, as unlike other corpora in CHILDES, it was phonetically transcribed. We examine the transcription system Brent (1999) uses and conclude some unorthodox choices were made when transcribing the corpus. Specifically, some phonemes that are normally considered distinct are combined into one symbol, which we call a bi-phone symbol. These phonemes combinations include diphthongs and vowels followed by /a/. Another seemingly arbitrary decision is the distinction between stressed and u</context>
<context position="16500" citStr="Goldwater (2007)" startWordPosition="2698" endWordPosition="2699">a/ in “bird”) since stress is not marked elsewhere in the corpus. To see the effect of these decisions, we modified the corpus so that the bi-phone symbols were split into two7 and the syllabic /a/ symbols were collapsed into one. 4.2 Accuracy We ran MBDP-1 on the original corpus, and the modified version of the corpus. As illustrated by Figures 1 and 2, MBDP-1 performs worse on the modified corpus with respect to both precision and recall. As MBDP-1 and MBDP-Phon are both iterative learners, we calculate segmentation precision and recall values over 500-utterance blocks. Per Brent (1999) and Goldwater (2007), precision and recall scores reflect correctly segmented words, not correctly identified boundaries. We also test to see how the addition of an n-gram phonotactic model affects the segmentation accuracy of MBDP-Phon by comparing it to MBDP1 on our modified corpus.8 As seen in Figure 3, MBDP-Phon using bigrams (henceforth MBDPPhon-Bigrams) is consistently more precise in its 7We only split diphthongs whose first phoneme can occur in isolation in English, so the vowels in “bay” and “boat” were not split. 8We also compare MBDP-Phon to MBDP-1 on the original corpus. The results are given in Table</context>
<context position="18539" citStr="Goldwater (2007)" startWordPosition="3029" endWordPosition="3030">o recall only after seeing 1000 utterances, and finishes the corpus - 10% ahead of MBDP1 (see Figure 4). MBDP-Phon-Trigrams does not fair as well in our tests, falling behind MBDP-1 and MBDP-Phon-Bigrams in recall, and MBDPPhon-Bigrams in precision. We attribute this poor performance to the fact that we are not currently smoothing the n-gram models in any way, which leads to data sparsity issues when using trigrams. We discuss a potential solution to this problem in §5. Having established that MBDP-Phon-Bigrams significantly outperforms MBDP-1, we compare its segmentation accuracy to those of Goldwater (2007) and Venkataraman (2001).9 As before, we 9We only examine Venkataraman’s unigram model, as his bigram and trigram models perform better on precision, but worse on recall. 0.40 500 1500 2500 3500 4500 5500 6500 7500 8500 9500 Utterances Processed Figure 4: Recall of MBDP-1 and MBDP-Phon on modified corpus. run the models on the entire corpus, and then measure their performance over 500-utterance blocks. MBDP-Phon-Bigrams edges out Goldwater’s model in precision on our modified corpus, with an average precision of 72.79% vs. Goldwater’s 70.73% (Table 1). If we drop the first 500- utterance block</context>
<context position="21639" citStr="Goldwater (2007)" startWordPosition="3512" endWordPosition="3513">s is due to the incremental nature of the MBDP algorithm. Initially, it makes numerous incorrect guesses that are added to the lexicon, and there is no point at which the lexicon is purged of earlier erroneous guesses (c.f. the improved lexical precision when omitting the first block in Table 3). On the other hand, Goldwater’s algorithm runs over the corpus multiple times, and only produces output when it settles on a final segmentation. In sum, MBDP-Phon-Bigrams significantly improves the accuracy of MBDP-1, and achieves better performance than the models described in Venkataraman (2001) and Goldwater (2007). 5 Future Work There are many ways to implement phonotactic learning. One idea is to to use n-grams over phonological features, as per Hayes and Wilson (2008). Preliminary results have shown that we need to add smoothing to our n-gram model, and we plan to use 10See Brent (1999) for a discussion of the meaning of this statistic. Modified Kneser-Ney smoothing (Chen and Goodman, 1998). Another approach would be to develop a syllable-based phonotactic model (Coleman and Pierrehumbert, 1997). Johnson (2008b) achieves impressive segmentation results by adding a syllable level with Adaptor grammars</context>
<context position="24307" citStr="Goldwater (2007)" startWordPosition="3921" endWordPosition="3922">.76% 54.35% 62.30% Min. 51.31% 51.95% 56.52% Table 3: Lexical precision statistics for MBDPPhon-Bigrams, Goldwater, and Venkataraman on both corpora over 500-utterance blocks. ing the abilities of these segmenters on corpora of different languages. Fleck (2008) tests her segmenter on a number of corpora, including Arabic and Spanish, and Johnson (2008a) applies his segmenter to a corpus of Sesotho. 6 Conclusion From the results established in §4, we can conclude that MBDP-Phon using a bigram phonotactic model is more accurate than the models described in Brent (1999), Venkataraman (2001), and Goldwater (2007). The n-gram phonotactic model improves overall performance, and is especially useful for corpora that do not encode diphthongs with bi-phone symbols. The main reason there is such a marked improvement with MBDP-Phon vs. MBDP-1 when the bi-phone symbols were removed from the original corpus is that these biphone symbols effectively allow MBDP-1 to have a select few bigrams in the cases where it would otherwise over-segment. The success of MBDP-Phon is not clear evidence that the INCDROP framework (Brent, 1997) is superior to Venkataraman or Goldwater’s models. We imagine that adding a phonotac</context>
</contexts>
<marker>Goldwater, 2007</marker>
<rawString>Goldwater, Sharon. 2007. Nonparametric Bayesian Models of Lexical Acquisition. Ph.D. thesis, Brown University, Department of Cognitive and Linguistic Sciences.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<date>1954</date>
<booktitle>Distributional structure. Word,</booktitle>
<pages>10--2</pages>
<marker>Harris, 1954</marker>
<rawString>Harris, Zellig. 1954. Distributional structure. Word, 10(2/3):146–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruce Hayes</author>
<author>Colin Wilson</author>
</authors>
<title>A maximum entropy model of phonotactics and phonotactic learning. Linguistic Inquiry.</title>
<date>2008</date>
<contexts>
<context position="3872" citStr="Hayes and Wilson (2008)" startWordPosition="588" endWordPosition="592">lem of language learning, as well as theoretical computer scientists who are interested in what unsupervised, incremental models are capable of achieving. Phonotactic patterns are the rules that determine what sequences of phonemes or allophones are allowable within words. Learning the phonotactic patterns of a language is usually modeled 65 CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 65–72 Manchester, August 2008 separately from word segmentation; e.g., current phonotactic learners such as Coleman and Pierrehumbert (1997), Heinz (2007), or Hayes and Wilson (2008) are given word-sized units as input. However, infants appear to simultaneously learn which phoneme combinations are allowable within words and how to extract words from the input. It is reasonable that the two processes feed into one another, and when infants acquire a critical mass of phonotactic knowledge, they use it to make judgements about what phoneme sequences can occur within versus across word boundaries (Mattys and Jusczyk, 2001). We use this insight, also suggested by Venkataraman (2001) and recently utilized by Fleck (2008) in a different manner, to enhance Brent’s (1999) model MB</context>
<context position="10228" citStr="Hayes and Wilson, 2008" startWordPosition="1654" endWordPosition="1657"> Venkataraman (2001) in both precision and recall, and we are interested in whether an incremental algorithm supplemented with phonotactic learning can match its performance. 2.2 Phonotactic Learning Phonotactic acquisition models have seen a surge in popularity recently (e.g., Coleman and Pierre2We refer the reader to Venkataraman (2001) for the details of this approach. 3We direct the reader to Goldwater (2007) for details. 4In our experiments and those in Goldwater (2007), the segmenter runs through the corpus 1000 times before outputting the final segmentation. humbert, 1997; Heinz, 2007; Hayes and Wilson, 2008). While Hayes and Wilson present a more complex Maximum Entropy phonotactic model in their paper than the one we add to MBDP-1, they also evaluate a simple n-gram phonotactic learner operating over phonemes. The input to the models is a list of English onsets and their frequency in the lexicon, and the basic trigram learner simply keeps track of the trigrams it has seen in the corpus. They test the model on novel words with acceptable rhymes—some well-formed (e.g., [kIp]), and some less well-formed (e.g., [stwIk])—so any ill-formedness is attributable to onsets. This basic trigram model explai</context>
<context position="12898" citStr="Hayes and Wilson, 2008" startWordPosition="2109" endWordPosition="2112">of storing n-grams (i.e., a word boundary marker may occur anywhere within the n-grams). q ri i=0 67 for a particular n-gram inside a word is calculated by dividing the total number of occurrences of that n-gram (including in the word we are currently examining) by the total number of n-grams (including those in the current word). The numbers of n-grams are computed with respect to the obtained lexicon, not the corpus, and thus the frequency of lexical items in the corpus does not affect the ngram counts, just like Brent’s unigram phonotactic model and other phonotactic learning models (e.g., Hayes and Wilson, 2008). We use the joint probability instead of the conditional probability which is often used in computational linguistics (Manning and Sch¨utze, 1999; Jurafsky and Martin, 2000), because of our intuition that the joint probability is truer to the idea that a phonotactically well-formed word is made up of n-grams that occur frequently in the lexicon. On the other hand, the conditional probability is used when one tries to predict the next phoneme that will occur in a word, rather than judging the well-formedness of the word as a whole.6 We are able to drop the denominator that was originally in Eq</context>
<context position="21798" citStr="Hayes and Wilson (2008)" startWordPosition="3538" endWordPosition="3541">point at which the lexicon is purged of earlier erroneous guesses (c.f. the improved lexical precision when omitting the first block in Table 3). On the other hand, Goldwater’s algorithm runs over the corpus multiple times, and only produces output when it settles on a final segmentation. In sum, MBDP-Phon-Bigrams significantly improves the accuracy of MBDP-1, and achieves better performance than the models described in Venkataraman (2001) and Goldwater (2007). 5 Future Work There are many ways to implement phonotactic learning. One idea is to to use n-grams over phonological features, as per Hayes and Wilson (2008). Preliminary results have shown that we need to add smoothing to our n-gram model, and we plan to use 10See Brent (1999) for a discussion of the meaning of this statistic. Modified Kneser-Ney smoothing (Chen and Goodman, 1998). Another approach would be to develop a syllable-based phonotactic model (Coleman and Pierrehumbert, 1997). Johnson (2008b) achieves impressive segmentation results by adding a syllable level with Adaptor grammars. Some languages (e.g., Finnish, and Navajo) contain long-distance phonotactic constraints that cannot be learned by n-gram learners (Heinz, 2007). Heinz (2007</context>
<context position="23229" citStr="Hayes and Wilson (2008)" startWordPosition="3751" endWordPosition="3754"> consonantal harmony) in the world’s languages. We posit that adding such a learner to MBDP-Phon would allow it to handle a greater variety of languages. Since none of these approaches to phonotactic learning depend on MBDP-1, it is also of interest to integrate phonotactic learners with other word segmentation strategies. In addition to evaluating segmentation models integrated with phonotactic learning on their segmentation performance, it would be interesting to evaluate the quality of the phonotactic grammars obtained. A good point of comparison for English are the constraints obtained by Hayes and Wilson (2008), since the data with which they tested their phonotactic learner is publicly available. Finally, we are looking forward to investigat70 MBDP- Venkataraman Goldwater PhonBigrams Original: Utterances 0 to 9790 Avg. 47.69% 49.78% 56.50% Max. 49.71% 52.95% 63.09% Min. 46.30% 41.83% 55.33% Modified: Utterances 0 to 9790 Avg. 48.31% 45.98% 58.03% Max. 50.42% 48.90% 65.58% Min. 41.74% 36.57% 56.43% Modified: Utterances 500 to 9790 Avg. 54.34% 53.06% 57.95% Max. 63.76% 54.35% 62.30% Min. 51.31% 51.95% 56.52% Table 3: Lexical precision statistics for MBDPPhon-Bigrams, Goldwater, and Venkataraman on bo</context>
</contexts>
<marker>Hayes, Wilson, 2008</marker>
<rawString>Hayes, Bruce and Colin Wilson. 2008. A maximum entropy model of phonotactics and phonotactic learning. Linguistic Inquiry.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Heinz</author>
</authors>
<title>Inductive Learning of Phonotactic Patterns.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>University of California, Los Angeles, Department of Linguistics.</institution>
<contexts>
<context position="3844" citStr="Heinz (2007)" startWordPosition="585" endWordPosition="586">ested in the problem of language learning, as well as theoretical computer scientists who are interested in what unsupervised, incremental models are capable of achieving. Phonotactic patterns are the rules that determine what sequences of phonemes or allophones are allowable within words. Learning the phonotactic patterns of a language is usually modeled 65 CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 65–72 Manchester, August 2008 separately from word segmentation; e.g., current phonotactic learners such as Coleman and Pierrehumbert (1997), Heinz (2007), or Hayes and Wilson (2008) are given word-sized units as input. However, infants appear to simultaneously learn which phoneme combinations are allowable within words and how to extract words from the input. It is reasonable that the two processes feed into one another, and when infants acquire a critical mass of phonotactic knowledge, they use it to make judgements about what phoneme sequences can occur within versus across word boundaries (Mattys and Jusczyk, 2001). We use this insight, also suggested by Venkataraman (2001) and recently utilized by Fleck (2008) in a different manner, to enh</context>
<context position="10203" citStr="Heinz, 2007" startWordPosition="1652" endWordPosition="1653">ms MBDP-1 and Venkataraman (2001) in both precision and recall, and we are interested in whether an incremental algorithm supplemented with phonotactic learning can match its performance. 2.2 Phonotactic Learning Phonotactic acquisition models have seen a surge in popularity recently (e.g., Coleman and Pierre2We refer the reader to Venkataraman (2001) for the details of this approach. 3We direct the reader to Goldwater (2007) for details. 4In our experiments and those in Goldwater (2007), the segmenter runs through the corpus 1000 times before outputting the final segmentation. humbert, 1997; Heinz, 2007; Hayes and Wilson, 2008). While Hayes and Wilson present a more complex Maximum Entropy phonotactic model in their paper than the one we add to MBDP-1, they also evaluate a simple n-gram phonotactic learner operating over phonemes. The input to the models is a list of English onsets and their frequency in the lexicon, and the basic trigram learner simply keeps track of the trigrams it has seen in the corpus. They test the model on novel words with acceptable rhymes—some well-formed (e.g., [kIp]), and some less well-formed (e.g., [stwIk])—so any ill-formedness is attributable to onsets. This b</context>
<context position="22385" citStr="Heinz, 2007" startWordPosition="3627" endWordPosition="3628">r Hayes and Wilson (2008). Preliminary results have shown that we need to add smoothing to our n-gram model, and we plan to use 10See Brent (1999) for a discussion of the meaning of this statistic. Modified Kneser-Ney smoothing (Chen and Goodman, 1998). Another approach would be to develop a syllable-based phonotactic model (Coleman and Pierrehumbert, 1997). Johnson (2008b) achieves impressive segmentation results by adding a syllable level with Adaptor grammars. Some languages (e.g., Finnish, and Navajo) contain long-distance phonotactic constraints that cannot be learned by n-gram learners (Heinz, 2007). Heinz (2007) shows that precedence-based learners—which work like a bigram model, but without the restriction that the elements in the bigram be adjacent—can handle many long-distance agreement patterns (e.g., vowel and consonantal harmony) in the world’s languages. We posit that adding such a learner to MBDP-Phon would allow it to handle a greater variety of languages. Since none of these approaches to phonotactic learning depend on MBDP-1, it is also of interest to integrate phonotactic learners with other word segmentation strategies. In addition to evaluating segmentation models integrat</context>
</contexts>
<marker>Heinz, 2007</marker>
<rawString>Heinz, Jeffrey. 2007. Inductive Learning of Phonotactic Patterns. Ph.D. thesis, University of California, Los Angeles, Department of Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>Unsupervised word segmentation for sesotho using adaptor grammars.</title>
<date>2008</date>
<booktitle>In Tenth Meeting ofACL SIGMORPHON,</booktitle>
<pages>pages</pages>
<publisher>ACL,</publisher>
<location>Morristown, NJ.</location>
<contexts>
<context position="3020" citStr="Johnson, 2008" startWordPosition="464" endWordPosition="465">is paper’s focus is on unsupervised, incremental word segmentation algorithms; i.e., those that do not rely on preexisting knowledge of a particular language, and those that segment the corpus one utterance at a time. This is in contrast to supervised word segmentation algorithms (e.g., Teahan et al., 2000), which are typically used for segmenting text in documents written in languages that do not put spaces between their words like Chinese. (Of course, unsupervised word segmentation algorithms also have this application.) This also differs from batch segmentation algorithms (Goldwater, 2007; Johnson, 2008b; Fleck, 2008), which process the entire corpus at least once before outputting a segmentation of the corpus. Unsupervised incremental algorithms are of interest to some psycholinguists and acquisitionists interested in the problem of language learning, as well as theoretical computer scientists who are interested in what unsupervised, incremental models are capable of achieving. Phonotactic patterns are the rules that determine what sequences of phonemes or allophones are allowable within words. Learning the phonotactic patterns of a language is usually modeled 65 CoNLL 2008: Proceedings of </context>
<context position="8944" citStr="Johnson, 2008" startWordPosition="1457" endWordPosition="1459">e the distribution of words in an unsegmented text.2 The most probable segmentation is retrieved via a dynamic programming algorithm, much like Brent (1999). We use MBDP-1 rather than Venkataraman’s approach as the basis for our model only because it was more transparent how to plug in a phonotactic learning module at the time this project began. 2.1.3 Goldwater (2007) We also compare our results to a segmenter put forward by Goldwater (2007). Goldwater’s segmenter uses an underlying generative model, much like MBDP-1 does, only her language model is described as a Dirichlet process (see also Johnson, 2008b). While this model uses a unigram model of phoneme distribution, as did MBDP-1, it implements a bigram word model like Venkataraman (2001). A bigram word model is useful in that it prevents the segmenter from assuming that frequent word bigrams are not simply one word, which Goldwater observes happen with a unigram version of her model. Goldwater uses a Gibbs sampler augmented with simulated annealing to sample from the posterior distribution of segmentations and determine the most likely segmentation of each utterance.3 This approach requires non-incremental learning.4 We include comparison</context>
<context position="22147" citStr="Johnson (2008" startWordPosition="3595" endWordPosition="3596">-1, and achieves better performance than the models described in Venkataraman (2001) and Goldwater (2007). 5 Future Work There are many ways to implement phonotactic learning. One idea is to to use n-grams over phonological features, as per Hayes and Wilson (2008). Preliminary results have shown that we need to add smoothing to our n-gram model, and we plan to use 10See Brent (1999) for a discussion of the meaning of this statistic. Modified Kneser-Ney smoothing (Chen and Goodman, 1998). Another approach would be to develop a syllable-based phonotactic model (Coleman and Pierrehumbert, 1997). Johnson (2008b) achieves impressive segmentation results by adding a syllable level with Adaptor grammars. Some languages (e.g., Finnish, and Navajo) contain long-distance phonotactic constraints that cannot be learned by n-gram learners (Heinz, 2007). Heinz (2007) shows that precedence-based learners—which work like a bigram model, but without the restriction that the elements in the bigram be adjacent—can handle many long-distance agreement patterns (e.g., vowel and consonantal harmony) in the world’s languages. We posit that adding such a learner to MBDP-Phon would allow it to handle a greater variety o</context>
<context position="24044" citStr="Johnson (2008" startWordPosition="3876" endWordPosition="3877">o 9790 Avg. 47.69% 49.78% 56.50% Max. 49.71% 52.95% 63.09% Min. 46.30% 41.83% 55.33% Modified: Utterances 0 to 9790 Avg. 48.31% 45.98% 58.03% Max. 50.42% 48.90% 65.58% Min. 41.74% 36.57% 56.43% Modified: Utterances 500 to 9790 Avg. 54.34% 53.06% 57.95% Max. 63.76% 54.35% 62.30% Min. 51.31% 51.95% 56.52% Table 3: Lexical precision statistics for MBDPPhon-Bigrams, Goldwater, and Venkataraman on both corpora over 500-utterance blocks. ing the abilities of these segmenters on corpora of different languages. Fleck (2008) tests her segmenter on a number of corpora, including Arabic and Spanish, and Johnson (2008a) applies his segmenter to a corpus of Sesotho. 6 Conclusion From the results established in §4, we can conclude that MBDP-Phon using a bigram phonotactic model is more accurate than the models described in Brent (1999), Venkataraman (2001), and Goldwater (2007). The n-gram phonotactic model improves overall performance, and is especially useful for corpora that do not encode diphthongs with bi-phone symbols. The main reason there is such a marked improvement with MBDP-Phon vs. MBDP-1 when the bi-phone symbols were removed from the original corpus is that these biphone symbols effectively all</context>
</contexts>
<marker>Johnson, 2008</marker>
<rawString>Johnson, Mark. 2008a. Unsupervised word segmentation for sesotho using adaptor grammars. In Tenth Meeting ofACL SIGMORPHON, pages 20–27. ACL, Morristown, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>Using adaptor grammars to identify synergies in the unsupervised acquisition of linguistic structure.</title>
<date>2008</date>
<booktitle>In 46th Annual Meeting of the ACL,</booktitle>
<pages>398--406</pages>
<publisher>ACL,</publisher>
<location>Morristown, NJ.</location>
<contexts>
<context position="3020" citStr="Johnson, 2008" startWordPosition="464" endWordPosition="465">is paper’s focus is on unsupervised, incremental word segmentation algorithms; i.e., those that do not rely on preexisting knowledge of a particular language, and those that segment the corpus one utterance at a time. This is in contrast to supervised word segmentation algorithms (e.g., Teahan et al., 2000), which are typically used for segmenting text in documents written in languages that do not put spaces between their words like Chinese. (Of course, unsupervised word segmentation algorithms also have this application.) This also differs from batch segmentation algorithms (Goldwater, 2007; Johnson, 2008b; Fleck, 2008), which process the entire corpus at least once before outputting a segmentation of the corpus. Unsupervised incremental algorithms are of interest to some psycholinguists and acquisitionists interested in the problem of language learning, as well as theoretical computer scientists who are interested in what unsupervised, incremental models are capable of achieving. Phonotactic patterns are the rules that determine what sequences of phonemes or allophones are allowable within words. Learning the phonotactic patterns of a language is usually modeled 65 CoNLL 2008: Proceedings of </context>
<context position="8944" citStr="Johnson, 2008" startWordPosition="1457" endWordPosition="1459">e the distribution of words in an unsegmented text.2 The most probable segmentation is retrieved via a dynamic programming algorithm, much like Brent (1999). We use MBDP-1 rather than Venkataraman’s approach as the basis for our model only because it was more transparent how to plug in a phonotactic learning module at the time this project began. 2.1.3 Goldwater (2007) We also compare our results to a segmenter put forward by Goldwater (2007). Goldwater’s segmenter uses an underlying generative model, much like MBDP-1 does, only her language model is described as a Dirichlet process (see also Johnson, 2008b). While this model uses a unigram model of phoneme distribution, as did MBDP-1, it implements a bigram word model like Venkataraman (2001). A bigram word model is useful in that it prevents the segmenter from assuming that frequent word bigrams are not simply one word, which Goldwater observes happen with a unigram version of her model. Goldwater uses a Gibbs sampler augmented with simulated annealing to sample from the posterior distribution of segmentations and determine the most likely segmentation of each utterance.3 This approach requires non-incremental learning.4 We include comparison</context>
<context position="22147" citStr="Johnson (2008" startWordPosition="3595" endWordPosition="3596">-1, and achieves better performance than the models described in Venkataraman (2001) and Goldwater (2007). 5 Future Work There are many ways to implement phonotactic learning. One idea is to to use n-grams over phonological features, as per Hayes and Wilson (2008). Preliminary results have shown that we need to add smoothing to our n-gram model, and we plan to use 10See Brent (1999) for a discussion of the meaning of this statistic. Modified Kneser-Ney smoothing (Chen and Goodman, 1998). Another approach would be to develop a syllable-based phonotactic model (Coleman and Pierrehumbert, 1997). Johnson (2008b) achieves impressive segmentation results by adding a syllable level with Adaptor grammars. Some languages (e.g., Finnish, and Navajo) contain long-distance phonotactic constraints that cannot be learned by n-gram learners (Heinz, 2007). Heinz (2007) shows that precedence-based learners—which work like a bigram model, but without the restriction that the elements in the bigram be adjacent—can handle many long-distance agreement patterns (e.g., vowel and consonantal harmony) in the world’s languages. We posit that adding such a learner to MBDP-Phon would allow it to handle a greater variety o</context>
<context position="24044" citStr="Johnson (2008" startWordPosition="3876" endWordPosition="3877">o 9790 Avg. 47.69% 49.78% 56.50% Max. 49.71% 52.95% 63.09% Min. 46.30% 41.83% 55.33% Modified: Utterances 0 to 9790 Avg. 48.31% 45.98% 58.03% Max. 50.42% 48.90% 65.58% Min. 41.74% 36.57% 56.43% Modified: Utterances 500 to 9790 Avg. 54.34% 53.06% 57.95% Max. 63.76% 54.35% 62.30% Min. 51.31% 51.95% 56.52% Table 3: Lexical precision statistics for MBDPPhon-Bigrams, Goldwater, and Venkataraman on both corpora over 500-utterance blocks. ing the abilities of these segmenters on corpora of different languages. Fleck (2008) tests her segmenter on a number of corpora, including Arabic and Spanish, and Johnson (2008a) applies his segmenter to a corpus of Sesotho. 6 Conclusion From the results established in §4, we can conclude that MBDP-Phon using a bigram phonotactic model is more accurate than the models described in Brent (1999), Venkataraman (2001), and Goldwater (2007). The n-gram phonotactic model improves overall performance, and is especially useful for corpora that do not encode diphthongs with bi-phone symbols. The main reason there is such a marked improvement with MBDP-Phon vs. MBDP-1 when the bi-phone symbols were removed from the original corpus is that these biphone symbols effectively all</context>
</contexts>
<marker>Johnson, 2008</marker>
<rawString>Johnson, Mark. 2008b. Using adaptor grammars to identify synergies in the unsupervised acquisition of linguistic structure. In 46th Annual Meeting of the ACL, pages 398–406. ACL, Morristown, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>James Martin</author>
</authors>
<title>Speech and Language Processing.</title>
<date>2000</date>
<publisher>Prentice-Hall.</publisher>
<contexts>
<context position="13072" citStr="Jurafsky and Martin, 2000" startWordPosition="2136" endWordPosition="2139">tal number of occurrences of that n-gram (including in the word we are currently examining) by the total number of n-grams (including those in the current word). The numbers of n-grams are computed with respect to the obtained lexicon, not the corpus, and thus the frequency of lexical items in the corpus does not affect the ngram counts, just like Brent’s unigram phonotactic model and other phonotactic learning models (e.g., Hayes and Wilson, 2008). We use the joint probability instead of the conditional probability which is often used in computational linguistics (Manning and Sch¨utze, 1999; Jurafsky and Martin, 2000), because of our intuition that the joint probability is truer to the idea that a phonotactically well-formed word is made up of n-grams that occur frequently in the lexicon. On the other hand, the conditional probability is used when one tries to predict the next phoneme that will occur in a word, rather than judging the well-formedness of the word as a whole.6 We are able to drop the denominator that was originally in Equation 3, because PΣ(#) is zero for an n-gram model when n &gt; 1. This simple modification allows the model to learn what phonemes are more likely to occur at the beginnings an</context>
</contexts>
<marker>Jurafsky, Martin, 2000</marker>
<rawString>Jurafsky, Daniel and James Martin. 2000. Speech and Language Processing. Prentice-Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian MacWhinney</author>
<author>Catherine Snow</author>
</authors>
<title>The child language data exchange system.</title>
<date>1985</date>
<journal>Journal of child language,</journal>
<volume>12</volume>
<issue>2</issue>
<contexts>
<context position="15126" citStr="MacWhinney and Snow, 1985" startWordPosition="2476" endWordPosition="2479"> Mattys and Jusczyk, 2001), it also resembles co-training (Blum and Mitchell, 1998). We refer to the extended version of Brent’s model 6This intuition is backed up by preliminary results suggesting MBDP-Phon performs better when using MLEs of the joint probability as opposed to conditional probability. There is an interesting question here, which is beyond the scope of this paper, so we leave it for future investigation. described above as MBDP-Phon. 4 Evaluation 4.1 The Corpus We run all of our experiments on the BernsteinRatner (1987) infant-directed speech corpus from the CHILDES database (MacWhinney and Snow, 1985). This is the same corpus that Brent (1999), Goldwater (2007), and Venkataraman (2001) evaluate their models on, and it has become the de facto standard for segmentation testing, as unlike other corpora in CHILDES, it was phonetically transcribed. We examine the transcription system Brent (1999) uses and conclude some unorthodox choices were made when transcribing the corpus. Specifically, some phonemes that are normally considered distinct are combined into one symbol, which we call a bi-phone symbol. These phonemes combinations include diphthongs and vowels followed by /a/. Another seemingly</context>
</contexts>
<marker>MacWhinney, Snow, 1985</marker>
<rawString>MacWhinney, Brian and Catherine Snow. 1985. The child language data exchange system. Journal of child language, 12(2):271–95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Manning</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing.</title>
<date>1999</date>
<publisher>MIT Press.</publisher>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>Manning, Christopher and Hinrich Sch¨utze. 1999. Foundations of Statistical Natural Language Processing. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sven Mattys</author>
<author>Peter Jusczyk</author>
</authors>
<title>Phonotactic cues for segmentation of fluent speech by infants.</title>
<date>2001</date>
<journal>Cognition,</journal>
<pages>78--91</pages>
<contexts>
<context position="631" citStr="Mattys and Jusczyk, 2001" startWordPosition="82" endWordPosition="85">ing Word Segmentation by Simultaneously Learning Phonotactics Daniel Blanchard Computer &amp; Information Sciences University of Delaware dsblanch@udel.edu Jeffrey Heinz Linguistics &amp; Cognitive Science University of Delaware heinz@udel.edu Abstract The most accurate unsupervised word segmentation systems that are currently available (Brent, 1999; Venkataraman, 2001; Goldwater, 2007) use a simple unigram model of phonotactics. While this simplifies some of the calculations, it overlooks cues that infant language acquisition researchers have shown to be useful for segmentation (Mattys et al., 1999; Mattys and Jusczyk, 2001). Here we explore the utility of using bigram and trigram phonotactic models by enhancing Brent’s (1999) MBDP-1 algorithm. The results show the improved MBDP-Phon model outperforms other unsupervised word segmentation systems (e.g., Brent, 1999; Venkataraman, 2001; Goldwater, 2007). 1 Introduction How do infants come to identify words in the speech stream? As adults, we break up speech into words with such ease that we often think that there are audible pauses between words in the same sentence. However, unlike some written languages, speech does not have any completely reliable markers for th</context>
<context position="4316" citStr="Mattys and Jusczyk, 2001" startWordPosition="659" endWordPosition="662">5–72 Manchester, August 2008 separately from word segmentation; e.g., current phonotactic learners such as Coleman and Pierrehumbert (1997), Heinz (2007), or Hayes and Wilson (2008) are given word-sized units as input. However, infants appear to simultaneously learn which phoneme combinations are allowable within words and how to extract words from the input. It is reasonable that the two processes feed into one another, and when infants acquire a critical mass of phonotactic knowledge, they use it to make judgements about what phoneme sequences can occur within versus across word boundaries (Mattys and Jusczyk, 2001). We use this insight, also suggested by Venkataraman (2001) and recently utilized by Fleck (2008) in a different manner, to enhance Brent’s (1999) model MBDP-1, and significantly increase segmentation accuracy. We call this modified segmentation model MBDP-Phon. 2 Related Work 2.1 Word Segmentation The problem of unsupervised word segmentation has attracted many earlier researchers over the past fifty years (e.g., Harris, 1954; Olivier, 1968; de Marcken, 1995; Brent, 1999). In this section, we describe the base model MBDP-1, along with two other segmentation approaches, Venkataraman (2001) an</context>
<context position="14526" citStr="Mattys and Jusczyk, 2001" startWordPosition="2382" endWordPosition="2385">heir relative frequencies in the words the segmenter has extracted. The phonotactic learner is guaranteed to see at least two valid patterns in every utterance, as the n-grams that occur at the beginnings and ends of utterances are definitely at the beginnings and ends of words. This allows the learner to provide useful information to the segmenter even early on, and as the segmenter correctly identifies more words, the phonotactic learner has more correct data to learn from. Not only is this mutually beneficial process supported by evidence from language acquisitionists (Mattys et al., 1999; Mattys and Jusczyk, 2001), it also resembles co-training (Blum and Mitchell, 1998). We refer to the extended version of Brent’s model 6This intuition is backed up by preliminary results suggesting MBDP-Phon performs better when using MLEs of the joint probability as opposed to conditional probability. There is an interesting question here, which is beyond the scope of this paper, so we leave it for future investigation. described above as MBDP-Phon. 4 Evaluation 4.1 The Corpus We run all of our experiments on the BernsteinRatner (1987) infant-directed speech corpus from the CHILDES database (MacWhinney and Snow, 1985)</context>
</contexts>
<marker>Mattys, Jusczyk, 2001</marker>
<rawString>Mattys, Sven and Peter Jusczyk. 2001. Phonotactic cues for segmentation of fluent speech by infants. Cognition, 78:91–121.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sven Mattys</author>
<author>Peter Jusczyk</author>
<author>Paul Luce</author>
<author>James Morgan</author>
</authors>
<title>Phonotactic and prosodic effects on word segmentation in infants.</title>
<date>1999</date>
<pages>38--465</pages>
<publisher>Cognitive Psychology,</publisher>
<contexts>
<context position="14499" citStr="Mattys et al., 1999" startWordPosition="2377" endWordPosition="2381">he n-grams by using their relative frequencies in the words the segmenter has extracted. The phonotactic learner is guaranteed to see at least two valid patterns in every utterance, as the n-grams that occur at the beginnings and ends of utterances are definitely at the beginnings and ends of words. This allows the learner to provide useful information to the segmenter even early on, and as the segmenter correctly identifies more words, the phonotactic learner has more correct data to learn from. Not only is this mutually beneficial process supported by evidence from language acquisitionists (Mattys et al., 1999; Mattys and Jusczyk, 2001), it also resembles co-training (Blum and Mitchell, 1998). We refer to the extended version of Brent’s model 6This intuition is backed up by preliminary results suggesting MBDP-Phon performs better when using MLEs of the joint probability as opposed to conditional probability. There is an interesting question here, which is beyond the scope of this paper, so we leave it for future investigation. described above as MBDP-Phon. 4 Evaluation 4.1 The Corpus We run all of our experiments on the BernsteinRatner (1987) infant-directed speech corpus from the CHILDES database </context>
</contexts>
<marker>Mattys, Jusczyk, Luce, Morgan, 1999</marker>
<rawString>Mattys, Sven, Peter Jusczyk, Paul Luce, and James Morgan. 1999. Phonotactic and prosodic effects on word segmentation in infants. Cognitive Psychology, 38:465–494.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Olivier</author>
</authors>
<title>Stochastic Grammars and Language Acquisition Mechanisms.</title>
<date>1968</date>
<tech>Ph.D. thesis,</tech>
<institution>Harvard Univerity.</institution>
<contexts>
<context position="4762" citStr="Olivier, 1968" startWordPosition="726" endWordPosition="727">al mass of phonotactic knowledge, they use it to make judgements about what phoneme sequences can occur within versus across word boundaries (Mattys and Jusczyk, 2001). We use this insight, also suggested by Venkataraman (2001) and recently utilized by Fleck (2008) in a different manner, to enhance Brent’s (1999) model MBDP-1, and significantly increase segmentation accuracy. We call this modified segmentation model MBDP-Phon. 2 Related Work 2.1 Word Segmentation The problem of unsupervised word segmentation has attracted many earlier researchers over the past fifty years (e.g., Harris, 1954; Olivier, 1968; de Marcken, 1995; Brent, 1999). In this section, we describe the base model MBDP-1, along with two other segmentation approaches, Venkataraman (2001) and Goldwater (2007). In §4, we compare MBDP-Phon to these models in more detail. For a thorough review of word segmentation literature, see Brent (1999) or Goldwater (2007). 2.1.1 MBDP-1 Brent’s (1999) MBDP-1 (Model Based Dynamic Programming) algorithm is an implementation of the INCDROP framework (Brent, 1997) that uses a Bayesian model of how to generate an unsegmented text to insert word boundaries. The generative model consists of five ste</context>
</contexts>
<marker>Olivier, 1968</marker>
<rawString>Olivier, Donald. 1968. Stochastic Grammars and Language Acquisition Mechanisms. Ph.D. thesis, Harvard Univerity.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Scholes</author>
</authors>
<title>Phonotactic Grammaticality.</title>
<date>1966</date>
<publisher>Mouton, The Hague.</publisher>
<contexts>
<context position="10886" citStr="Scholes (1966)" startWordPosition="1767" endWordPosition="1768">lex Maximum Entropy phonotactic model in their paper than the one we add to MBDP-1, they also evaluate a simple n-gram phonotactic learner operating over phonemes. The input to the models is a list of English onsets and their frequency in the lexicon, and the basic trigram learner simply keeps track of the trigrams it has seen in the corpus. They test the model on novel words with acceptable rhymes—some well-formed (e.g., [kIp]), and some less well-formed (e.g., [stwIk])—so any ill-formedness is attributable to onsets. This basic trigram model explains 87.7% of the variance in the scores that Scholes (1966) reports his 7th grade students gave when subjected to the same test. When Hayes and Wilson run their Maximum Entropy phonotactic learning model with n-grams over phonological features, the r-score increases substantially to 95.6%. Given the success and simplicity of the basic ngram phonotactic model, we choose to integrate this with MBDP-1. 3 Extending MBDP-1 with Phonotactics The main contribution of our work is adding a phonotactic learning component to MBDP-1 (Brent, 1999). As we mention in §2.1.1, the third term of Equation 3 is where MBDP-1’s unigram phonotactic assumption surfaces. The </context>
</contexts>
<marker>Scholes, 1966</marker>
<rawString>Scholes, Robert. 1966. Phonotactic Grammaticality. Mouton, The Hague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W J Teahan</author>
<author>Rodger McNab</author>
<author>Yingying Wen</author>
<author>Ian H Witten</author>
</authors>
<title>A compression-based algorithm for chinese word segmentation.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>3</issue>
<contexts>
<context position="2715" citStr="Teahan et al., 2000" startWordPosition="418" endWordPosition="421">stic data is something we would like to see developed, following earlier researchers, we simplify the problem by using a text that does not contain any word boundary markers. Hereafter, we use the phrase “word segmentation” to mean some process which adds word boundaries to a text that does not contain them. This paper’s focus is on unsupervised, incremental word segmentation algorithms; i.e., those that do not rely on preexisting knowledge of a particular language, and those that segment the corpus one utterance at a time. This is in contrast to supervised word segmentation algorithms (e.g., Teahan et al., 2000), which are typically used for segmenting text in documents written in languages that do not put spaces between their words like Chinese. (Of course, unsupervised word segmentation algorithms also have this application.) This also differs from batch segmentation algorithms (Goldwater, 2007; Johnson, 2008b; Fleck, 2008), which process the entire corpus at least once before outputting a segmentation of the corpus. Unsupervised incremental algorithms are of interest to some psycholinguists and acquisitionists interested in the problem of language learning, as well as theoretical computer scientis</context>
</contexts>
<marker>Teahan, McNab, Wen, Witten, 2000</marker>
<rawString>Teahan, W. J., Rodger McNab, Yingying Wen, and Ian H. Witten. 2000. A compression-based algorithm for chinese word segmentation. Computational Linguistics, 26(3):375–393.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anand Venkataraman</author>
</authors>
<title>A statistical model for word discovery in transcribed speech.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>3</issue>
<contexts>
<context position="895" citStr="Venkataraman, 2001" startWordPosition="123" endWordPosition="125">ised word segmentation systems that are currently available (Brent, 1999; Venkataraman, 2001; Goldwater, 2007) use a simple unigram model of phonotactics. While this simplifies some of the calculations, it overlooks cues that infant language acquisition researchers have shown to be useful for segmentation (Mattys et al., 1999; Mattys and Jusczyk, 2001). Here we explore the utility of using bigram and trigram phonotactic models by enhancing Brent’s (1999) MBDP-1 algorithm. The results show the improved MBDP-Phon model outperforms other unsupervised word segmentation systems (e.g., Brent, 1999; Venkataraman, 2001; Goldwater, 2007). 1 Introduction How do infants come to identify words in the speech stream? As adults, we break up speech into words with such ease that we often think that there are audible pauses between words in the same sentence. However, unlike some written languages, speech does not have any completely reliable markers for the breaks between words (Cole and Jakimik, 1980). In fact, languages vary on how they signal the ends of words (Cutler and Carter, 1987), which makes the task even more daunting. Adults at least have a lexicon they can use to recognize familiar words, but when an i</context>
<context position="4376" citStr="Venkataraman (2001)" startWordPosition="670" endWordPosition="671">g., current phonotactic learners such as Coleman and Pierrehumbert (1997), Heinz (2007), or Hayes and Wilson (2008) are given word-sized units as input. However, infants appear to simultaneously learn which phoneme combinations are allowable within words and how to extract words from the input. It is reasonable that the two processes feed into one another, and when infants acquire a critical mass of phonotactic knowledge, they use it to make judgements about what phoneme sequences can occur within versus across word boundaries (Mattys and Jusczyk, 2001). We use this insight, also suggested by Venkataraman (2001) and recently utilized by Fleck (2008) in a different manner, to enhance Brent’s (1999) model MBDP-1, and significantly increase segmentation accuracy. We call this modified segmentation model MBDP-Phon. 2 Related Work 2.1 Word Segmentation The problem of unsupervised word segmentation has attracted many earlier researchers over the past fifty years (e.g., Harris, 1954; Olivier, 1968; de Marcken, 1995; Brent, 1999). In this section, we describe the base model MBDP-1, along with two other segmentation approaches, Venkataraman (2001) and Goldwater (2007). In §4, we compare MBDP-Phon to these mod</context>
<context position="7233" citStr="Venkataraman (2001)" startWordPosition="1170" endWordPosition="1171">rd is novel, and its score is calculated using Equation 31 (Brent and Tao, 2001), R(wk) = PΣ(a1) ... PΣ(ay) (n−11 1−PΣ(#) ·n ) where PE is the probability of a particular phoneme occurring in the text. The third term of the equation for novel words is where the model’s unigram phonotactic model comes into play. We detail how to plug a more sophisticated phonotactic learning model into this equation in §3. With the generative model established, MBDP-1 uses a Viterbi-style search algorithm to find the segmentation for each utterance that maximizes the R values for each word in the segmentation. Venkataraman (2001) notes that considering the generation of the text as a single event is unlikely to be how infants approach the segmentation problem. However, MBDP-1 uses an incremental search algorithm to segment one utterance at a time, which is more plausible as a model of infants’ word segmentation. 1Brent (1999) originally described the novel word score as R(wk) = 6 · nk · Pσ(Wnk ) (nk −11 π2 k · , nk−1·Enk 1− Pσ(Wj) nk nk j=1 where Po is the probability of all the phonemes in the word occurring together, but the denominator of the third term was dropped in Brent and Tao (2001). This change drastically s</context>
<context position="9084" citStr="Venkataraman (2001)" startWordPosition="1480" endWordPosition="1482">much like Brent (1999). We use MBDP-1 rather than Venkataraman’s approach as the basis for our model only because it was more transparent how to plug in a phonotactic learning module at the time this project began. 2.1.3 Goldwater (2007) We also compare our results to a segmenter put forward by Goldwater (2007). Goldwater’s segmenter uses an underlying generative model, much like MBDP-1 does, only her language model is described as a Dirichlet process (see also Johnson, 2008b). While this model uses a unigram model of phoneme distribution, as did MBDP-1, it implements a bigram word model like Venkataraman (2001). A bigram word model is useful in that it prevents the segmenter from assuming that frequent word bigrams are not simply one word, which Goldwater observes happen with a unigram version of her model. Goldwater uses a Gibbs sampler augmented with simulated annealing to sample from the posterior distribution of segmentations and determine the most likely segmentation of each utterance.3 This approach requires non-incremental learning.4 We include comparison with Goldwater’s segmenter because it outperforms MBDP-1 and Venkataraman (2001) in both precision and recall, and we are interested in whe</context>
<context position="15212" citStr="Venkataraman (2001)" startWordPosition="2491" endWordPosition="2492"> to the extended version of Brent’s model 6This intuition is backed up by preliminary results suggesting MBDP-Phon performs better when using MLEs of the joint probability as opposed to conditional probability. There is an interesting question here, which is beyond the scope of this paper, so we leave it for future investigation. described above as MBDP-Phon. 4 Evaluation 4.1 The Corpus We run all of our experiments on the BernsteinRatner (1987) infant-directed speech corpus from the CHILDES database (MacWhinney and Snow, 1985). This is the same corpus that Brent (1999), Goldwater (2007), and Venkataraman (2001) evaluate their models on, and it has become the de facto standard for segmentation testing, as unlike other corpora in CHILDES, it was phonetically transcribed. We examine the transcription system Brent (1999) uses and conclude some unorthodox choices were made when transcribing the corpus. Specifically, some phonemes that are normally considered distinct are combined into one symbol, which we call a bi-phone symbol. These phonemes combinations include diphthongs and vowels followed by /a/. Another seemingly arbitrary decision is the distinction between stressed and unstressed syllabic /a/ so</context>
<context position="18563" citStr="Venkataraman (2001)" startWordPosition="3032" endWordPosition="3033">eeing 1000 utterances, and finishes the corpus - 10% ahead of MBDP1 (see Figure 4). MBDP-Phon-Trigrams does not fair as well in our tests, falling behind MBDP-1 and MBDP-Phon-Bigrams in recall, and MBDPPhon-Bigrams in precision. We attribute this poor performance to the fact that we are not currently smoothing the n-gram models in any way, which leads to data sparsity issues when using trigrams. We discuss a potential solution to this problem in §5. Having established that MBDP-Phon-Bigrams significantly outperforms MBDP-1, we compare its segmentation accuracy to those of Goldwater (2007) and Venkataraman (2001).9 As before, we 9We only examine Venkataraman’s unigram model, as his bigram and trigram models perform better on precision, but worse on recall. 0.40 500 1500 2500 3500 4500 5500 6500 7500 8500 9500 Utterances Processed Figure 4: Recall of MBDP-1 and MBDP-Phon on modified corpus. run the models on the entire corpus, and then measure their performance over 500-utterance blocks. MBDP-Phon-Bigrams edges out Goldwater’s model in precision on our modified corpus, with an average precision of 72.79% vs. Goldwater’s 70.73% (Table 1). If we drop the first 500- utterance block for MBDP-Phon-Bigrams b</context>
<context position="20968" citStr="Venkataraman, 2001" startWordPosition="3406" endWordPosition="3408">rances 0 to 9790 Avg. 74.63% 66.24% 70.48% Max. 82.45% 70.47% 74.79% Min. 47.63% 44.71% 63.74% Modified: Utterances 500 to 9790 Avg. 76.05% 67.37% 70.28% Max. 82.45% 70.47% 74.79% Min. 71.92% 63.86% 63.74% Table 2: Recall statistics for MBDP-PhonBigrams, Goldwater, and Venkataraman on both corpora over 500-utterance blocks. The only metric by which MBDP-PhonBigrams does not outperform the other algorithms is lexical precision, as shown in Table 3. Lexical precision is the ratio of the number of correctly identified words in the lexicon to the total number of words in the lexicon (Brent, 1999; Venkataraman, 2001).10 The relatively poor performance of MBDP-Phon-Bigrams is due to the incremental nature of the MBDP algorithm. Initially, it makes numerous incorrect guesses that are added to the lexicon, and there is no point at which the lexicon is purged of earlier erroneous guesses (c.f. the improved lexical precision when omitting the first block in Table 3). On the other hand, Goldwater’s algorithm runs over the corpus multiple times, and only produces output when it settles on a final segmentation. In sum, MBDP-Phon-Bigrams significantly improves the accuracy of MBDP-1, and achieves better performanc</context>
<context position="24285" citStr="Venkataraman (2001)" startWordPosition="3918" endWordPosition="3919">34% 53.06% 57.95% Max. 63.76% 54.35% 62.30% Min. 51.31% 51.95% 56.52% Table 3: Lexical precision statistics for MBDPPhon-Bigrams, Goldwater, and Venkataraman on both corpora over 500-utterance blocks. ing the abilities of these segmenters on corpora of different languages. Fleck (2008) tests her segmenter on a number of corpora, including Arabic and Spanish, and Johnson (2008a) applies his segmenter to a corpus of Sesotho. 6 Conclusion From the results established in §4, we can conclude that MBDP-Phon using a bigram phonotactic model is more accurate than the models described in Brent (1999), Venkataraman (2001), and Goldwater (2007). The n-gram phonotactic model improves overall performance, and is especially useful for corpora that do not encode diphthongs with bi-phone symbols. The main reason there is such a marked improvement with MBDP-Phon vs. MBDP-1 when the bi-phone symbols were removed from the original corpus is that these biphone symbols effectively allow MBDP-1 to have a select few bigrams in the cases where it would otherwise over-segment. The success of MBDP-Phon is not clear evidence that the INCDROP framework (Brent, 1997) is superior to Venkataraman or Goldwater’s models. We imagine </context>
</contexts>
<marker>Venkataraman, 2001</marker>
<rawString>Venkataraman, Anand. 2001. A statistical model for word discovery in transcribed speech. Computational Linguistics, 27(3):352–372.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>