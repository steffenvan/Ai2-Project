<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001204">
<title confidence="0.990361">
Rule-based Translation With Statistical Phrase-based Post-editing
</title>
<author confidence="0.771211">
Michel Simard, Nicola Ueffing, Pierre Isabelle and Roland Kuhn
</author>
<affiliation confidence="0.2955505">
Interactive Language Technologies Group
National Research Council of Canada
</affiliation>
<address confidence="0.303568">
Gatineau, Canada, K1A 0R6
</address>
<email confidence="0.715559">
firstname.lastname@nrc-cnrc.gc.ca
</email>
<sectionHeader confidence="0.985191" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999976916666666">
This article describes a machine translation
system based on an automatic post-editing
strategy: initially translate the input text into
the target-language using a rule-based MT
system, then automatically post-edit the out-
put using a statistical phrase-based system.
An implementation of this approach based
on the SYSTRAN and PORTAGE MT sys-
tems was used in the shared task of the Sec-
ond Workshop on Statistical Machine Trans-
lation. Experimental results on the test data
of the previous campaign are presented.
</bodyText>
<sectionHeader confidence="0.998788" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99992079661017">
Simard et al. (2007) have recently shown how a sta-
tistical phrase-based machine translation system can
be used as an automatic post-editing (APE) layer,
on top of a rule-based machine translation system.
The motivation for their work is the repetitive nature
of the errors typically made by rule-based systems.
Given appropriate training material, a statistical MT
system can be trained to correct these systematic er-
rors, therefore reducing the post-editing effort. The
statistical system views the output of the rule-based
system as the source language, and reference hu-
man translations as the target language. Because the
training material for the APE layer will typically be
domain-specific, this process can be viewed as a way
of automatically adapting a rule-based system to a
specific application domain.
This approach has been shown experimentally
to produce large improvements in performance not
only over the baseline rule-based system that it cor-
rects, but also over a similar statistical phrase-based
MT system used in standalone mode, i.e. translating
the “real” source text directly: Simard et al. report a
reduction in post-editing effort of up to a third when
compared to the input rule-based translation, and as
much as 5 BLEU points improvement over the direct
SMT approach.
These impressive results, however, were obtained
in a very specific and somewhat unusual context:
the training and test corpora were extracted from
a collection of manually post-edited machine trans-
lations. The two corpora (one English-to-French,
one French-to-English) each contained three paral-
lel “views” of the same data: 1) the source language
text, 2) a machine translation of that text into the
target language, as produced by a commercial rule-
based MT system, and 3) the final target-language
version of the text, produced by manually post-
editing the machine translation. Furthermore, the
corpus was very small, at least by SMT standards:
500K words of source-language data in the French-
to-English direction, 350K words in the English-to-
French. Because of this, the authors were left with
two important questions: 1) how would the results
scale up to much larger quantities of training data?
and 2) are the results related to the dependent nature
of the translations, i.e. is the automatic post-editing
approach still effective when the machine and hu-
man translations are produced independently of one
another?
With these two questions in mind, we partici-
pated in the shared task of the Second Workshop
on Statistical Machine Translation with an auto-
matic post-editing strategy: initially translate the in-
put text into the target-language using a rule-based
system, namely SYSTRAN, and automatically post-
edit the output using a statistical phrase-based sys-
tem, namely PORTAGE. We describe our system in
more detail in Section 2, and present some experi-
mental results in Section 3.
</bodyText>
<page confidence="0.996839">
203
</page>
<note confidence="0.510149">
Proceedings of the Second Workshop on Statistical Machine Translation, pages 203–206,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.85387" genericHeader="method">
2 System description
</sectionHeader>
<bodyText confidence="0.998896428571429">
Our system is composed of two main components:
a rule-based MT system, which handles the initial
translation into the target language, and a statistical
phrase-based post-editing system, which performs
domain-specific corrections and adaptations to the
output. We describe each component separately be-
low.
</bodyText>
<subsectionHeader confidence="0.954222">
2.1 Rule-based Translation
</subsectionHeader>
<bodyText confidence="0.9998947">
The initial source-to-target language translation is
performed using the SYSTRAN machine translation
system, version 6. A detailed overview of SYS-
TRAN systems can be found in Dugast et al. (2007).
For this shared task, we used the French-to-English
and English-to-French configurations of the system.
Although it is possible to provide the system with
specialized lexica, we did not rely on this feature,
and used the system in its basic “out-of-the-box”
configuration.
</bodyText>
<subsectionHeader confidence="0.999195">
2.2 Statistical Phrase-based Post-Editing
</subsectionHeader>
<bodyText confidence="0.872742392857143">
The output of the rule-based MT system described
above is fed into a post-editing layer that performs
domain-specific corrections and adaptation. This
operation is conceptually not very different from a
“target-to-target” translation; for this task, we used
the PORTAGE system, a state-of-the-art statistical
phrase-based machine translation system developed
at the National Research Council of Canada (NRC).1
A general description of PORTAGE can be found in
(Sadat et al., 2005).
For our participation in this shared task, we de-
cided to configure and train the PORTAGE system
for post-editing in a manner as much as possible
similar to the corresponding translation system, the
details of which can be found in (Ueffing et al.,
2007). The main features of this configuration are:
• The use of two distinct phrase tables, contain-
ing phrase pairs extracted from the Europarl
and the News Commentary training corpora re-
spectively.
• Multiple phrase-probability feature functions
in the log-linear models, including a joint prob-
&apos;A version of PORTAGE is made available by the NRC to
Canadian universities for research and education purposes.
ability estimate, a standard frequency-based
conditional probability estimate, and variants
thereof based on different smoothing methods
(Foster et al., 2006).
</bodyText>
<listItem confidence="0.997421090909091">
• A 4-gram language model trained on the com-
bined Europarl and News Commentary target-
language corpora.
• A 3-gram adapted language model: this is
trained on a mini-corpus of test-relevant target-
language sentences, extracted from the training
material using standard information retrieval
techniques.
• A 5-gram truecasing model, trained on the
combined Europarl and News Commentary
target-language corpora.
</listItem>
<subsectionHeader confidence="0.995367">
2.3 Training data
</subsectionHeader>
<bodyText confidence="0.999994571428571">
Ideally, the training material for the post-editing
layer of our system should consist in a corpus of
text in two parallel versions: on the one hand, raw
machine translation output, and on the other hand,
manually post-edited versions of these translations.
This is the type of data that was used in the initial
study of Simard et al. (2007).
Unfortunately, this sort of training data is seldom
available. Instead, we propose using training ma-
terial derived directly from standard, source-target
parallel corpora. The idea is to translate the source
portion of the parallel corpus into the target lan-
guage, using the rule-based MT component. The
post-editing component can then be trained using
this translation as “source” training material, and the
existing target portion of the parallel corpus as “tar-
get” training material. Note how this sort of data
is subtly different from the data used by Simard et
al.: there, the “target” text was dependent on the
“source”, in the sense that it was produced by manu-
ally post-editing the machine translation; here, the
two can be said to be independent, in the sense
that both “source” and “target” were produced inde-
pendently by man and machine (but from the same
“real” source, of course). It was one of the initial
motivations of the current work to verify to what ex-
tent the performance of the APE approach is affected
by using two different translations (human and ma-
</bodyText>
<page confidence="0.995225">
204
</page>
<table confidence="0.950552777777778">
en—*fr fr—*en
Europarl (&gt;32M words/language)
SYSTRAN 23.06 20.11
PORTAGE 31.01 30.90
SYSTRAN+PORTAGE 31.11 30.61
News Commentary (1M words/language)
SYSTRAN 24.41 18.09
PORTAGE 25.98 25.17
SYSTRAN+PORTAGE 28.80 26.79
</table>
<tableCaption confidence="0.90467">
Table 1: System performances on WMT-06 test. All
figures are single-reference BLEU scores, computed
on truecased, detokenized translations.
</tableCaption>
<bodyText confidence="0.9908477">
chine) instead of two versions of the same transla-
tion (raw MT versus post-edited MT).
We concentrated our efforts on the English-
French language pair. For each translation direc-
tion, we prepared two systems: one for the Eu-
roparl domain, and one for the News Commentary
domain. The two systems have almost identical
configurations (phrase tables, log-linear model fea-
tures, etc.); the only differences between the two
are the adapted language model, which is computed
based on the specific text to be translated and the
parameters of the log-linear models, which are opti-
mized using domain-specific development sets. For
the Europarl domain system, we used the dev2006
and devtest2006 data sets, while for the News Com-
mentary, we used the nc-dev2007. Typically, the
optimization procedure will give higher weights to
Europarl-trained phrase tables for the Europarl do-
main systems, and inversely for the News Commen-
tary domain systems.
</bodyText>
<sectionHeader confidence="0.996759" genericHeader="method">
3 Experimental Results
</sectionHeader>
<bodyText confidence="0.999976632653061">
We computed BLEU scores for all four systems on
the 2006 test data (test2006 for the Europarl do-
main and nc-devtest2007 for the News Commen-
tary). The results are presented in Table 1. As points
of comparison, we also give the scores obtained by
the SYSTRAN systems on their own (i.e. without a
post-editing layer), and by the PORTAGE MT sys-
tems on their own (i.e. translating directly source
into target).
The first observation is that, as was the case
in the Simard et al. study, post-editing (SYS-
TRAN+PORTAGE lines) very significantly in-
creases the BLEU scores of the rule-based system
(SYSTRAN lines). This increase is more spectacu-
lar in the Europarl domain and when translating into
English, but it is visible for all four systems.
For the News Commentary domain, the APE
strategy (SYSTRAN+PORTAGE lines) clearly out-
performs the direct SMT strategy (PORTAGE lines):
translating into English, the gain exceeds 1.5 BLEU
points, while for French, it is close to 3 BLEU
points. In contrast, for the Europarl domain, both ap-
proaches display similar performances. Let us recall
that the News Commentary corpus contains less than
50K sentence pairs, totalling a little over one mil-
lion words in each language. With close to 1.3 mil-
lion sentence pairs, the Europarl corpus is almost 30
times larger. Our results therefore appear to confirm
one of the conjectures of the Simard et al. study:
that APE is better suited for domains with limited
quantities of available training data. To better un-
derstand this behavior, we trained series of APE and
SMT systems on the Europarl data, using increas-
ing amounts of training data. The resulting learning
curves are presented in Figure 1.2
As observed in the Simard et al. study, while both
the SMT and APE systems improve quite steadily
with more data (note the logarithmic scale), SMT
appears to improve more rapidly than APE. How-
ever, there doesn’t seem to be a clear “crossover”
point, as initially conjectured by Simard et al. In-
stead, SMT eventually catches up with APE (any-
where between 100K and 1M sentence pairs), be-
yond which point both approaches appear to be more
or less equivalent. Again, one impressive feature
of the APE strategy is how little data is actually re-
quired to improve upon the rule-based system upon
which it is built: around 5000 sentence pairs for
English-to-French, and 2000 for French-to-English.
</bodyText>
<sectionHeader confidence="0.99812" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.855496625">
We have presented a combination MT system based
on a post-editing strategy, in which a statistical
phrase-based system corrects the output of a rule-
based translation system. Experiments confirm the
2The systems used for this experiment are simplified ver-
sions of those described in Section 2, using only one phrase
table, a trigram language model and no rescoring; furthermore,
they were optimized and tested on short sentences only.
</bodyText>
<page confidence="0.995046">
205
</page>
<figure confidence="0.987579971428571">
English to French French to English
BLEU score
0.28
0.26
0.24
0.22
0.18
0.16
0.14
0.12
0.3
0.2
0.1
BLEU score
0.28
0.26
0.24
0.22
0.18
0.16
0.14
0.12
0.3
0.2
0.1
SYSTRAN
PORTAGE
SYSTRAN + PORTAGE
SYSTRAN
PORTAGE
SYSTRAN + PORTAGE
1 10 100 1000
Training sentences (x 1000)
1 10 100 1000
Training sentences (x 1000)
</figure>
<figureCaption confidence="0.9682145">
Figure 1: BLEU scores on Europarl data under increasing amounts of training data for PORTAGE SMT
alone and SYSTRAN MT with PORTAGE APE.
</figureCaption>
<bodyText confidence="0.9998936">
conclusions of earlier studies: not only can phrase-
based post-editing significantly improve the out-
put of a rule-based MT system (in terms of BLEU
score), but when training data is scarce, it also out-
performs a direct phrase-based MT strategy. Fur-
thermore, our results indicate that the training data
for the post-editing component does not need to be
manually post-edited translations, it can be gener-
ated from standard parallel corpora. Finally, our ex-
periments show that while post-editing is most effec-
tive when little training data is available, it remains
competitive with phrase-based translation even with
much larger amounts of data.
This work opens the door to a number of lines of
investigation. For example, it was mentioned earlier
that phrase-based APE could be seen as a form of au-
tomatic domain-adaptation for rule-based methods.
One thing we would like to verify is how this ap-
proach compares to the standard “lexical customiza-
tion” method proposed by most rule-based MT ven-
dors. Also, in the experiments reported here, we
have used identical configurations for the APE and
direct SMT systems. However, it might be possible
to modify the phrase-based system so as to better
adapt it to the APE task. For example, it could be
useful for the APE layer to “look” at the real source-
language text, in addition to the MT output it is post-
editing. Finally, we have so far considered the front-
end rule-based system as a “black box”. But in the
end, the real question is: Which part of the rule-
based processing is really making things easier for
the phrase-based post-editing layer? Answering this
question will likely require diving into the internals
of the rule-based component. These are all direc-
tions that we are currently pursuing.
</bodyText>
<sectionHeader confidence="0.998074" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.77589425">
This work was done as part of a collaboration with
SYSTRAN S.A. Many thanks go to Jean Senellart,
Jens Stephan, Dimitris Sabatakakis and all those
people behind the scene at SYSTRAN.
</bodyText>
<sectionHeader confidence="0.980707" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999425625">
L. Dugast, J. Senellart, and P. Koehn. 2007. Statistical
Post-Edition on SYSTRAN Rule-Based Translation
System. In Proceedings of the Second Workshop On
Statistical Machine Translation, Prague, Czech Re-
public.
G. Foster, R. Kuhn, and H. Johnson. 2006. Phrasetable
Smoothing for Statistical Machine Translation. In
Proceedings of EMNLP 2006, pages 53–61, Sydney,
Australia.
F. Sadat, H. Johnson, A. Agbago, G. Foster, R. Kuhn,
J. Martin, and A. Tikuisis. 2005. PORTAGE: A
Phrase-Based Machine Translation System. In Pro-
ceedings of the ACL Workshop on Building and Using
Parallel Texts, pages 129–132, Ann Arbor, USA.
M. Simard, C. Goutte, and P. Isabelle. 2007. Sta-
tistical Phrase-Based Post-Editing. In Human Lan-
guage Technologies 2007: The Conference of the
North American Chapter of the Association for Com-
putational Linguistics; Proceedings of the Main Con-
ference, pages 508–515, Rochester, USA.
N. Ueffing, M. Simard, S. Larkin, and H. Johnson. 2007.
NRC’s PORTAGE system for WMT 2007. In Pro-
ceedings of the Second Workshop On Statistical Ma-
chine Translation, Prague, Czech Republic.
</reference>
<page confidence="0.998892">
206
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.857665">
<title confidence="0.99838">Rule-based Translation With Statistical Phrase-based Post-editing</title>
<author confidence="0.955968">Michel Simard</author>
<author confidence="0.955968">Nicola Ueffing</author>
<author confidence="0.955968">Pierre Isabelle</author>
<author confidence="0.955968">Roland</author>
<affiliation confidence="0.9172705">Interactive Language Technologies National Research Council of</affiliation>
<address confidence="0.979861">Gatineau, Canada, K1A</address>
<email confidence="0.996889">firstname.lastname@nrc-cnrc.gc.ca</email>
<abstract confidence="0.999056538461539">This article describes a machine translation based on an post-editing strategy: initially translate the input text into the target-language using a rule-based MT system, then automatically post-edit the output using a statistical phrase-based system. An implementation of this approach based on the SYSTRAN and PORTAGE MT systems was used in the shared task of the Second Workshop on Statistical Machine Translation. Experimental results on the test data of the previous campaign are presented.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Dugast</author>
<author>J Senellart</author>
<author>P Koehn</author>
</authors>
<title>Statistical Post-Edition on SYSTRAN Rule-Based Translation System.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop On Statistical Machine Translation,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="4390" citStr="Dugast et al. (2007)" startWordPosition="658" endWordPosition="661">6, Prague, June 2007. c�2007 Association for Computational Linguistics 2 System description Our system is composed of two main components: a rule-based MT system, which handles the initial translation into the target language, and a statistical phrase-based post-editing system, which performs domain-specific corrections and adaptations to the output. We describe each component separately below. 2.1 Rule-based Translation The initial source-to-target language translation is performed using the SYSTRAN machine translation system, version 6. A detailed overview of SYSTRAN systems can be found in Dugast et al. (2007). For this shared task, we used the French-to-English and English-to-French configurations of the system. Although it is possible to provide the system with specialized lexica, we did not rely on this feature, and used the system in its basic “out-of-the-box” configuration. 2.2 Statistical Phrase-based Post-Editing The output of the rule-based MT system described above is fed into a post-editing layer that performs domain-specific corrections and adaptation. This operation is conceptually not very different from a “target-to-target” translation; for this task, we used the PORTAGE system, a sta</context>
</contexts>
<marker>Dugast, Senellart, Koehn, 2007</marker>
<rawString>L. Dugast, J. Senellart, and P. Koehn. 2007. Statistical Post-Edition on SYSTRAN Rule-Based Translation System. In Proceedings of the Second Workshop On Statistical Machine Translation, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Foster</author>
<author>R Kuhn</author>
<author>H Johnson</author>
</authors>
<title>Phrasetable Smoothing for Statistical Machine Translation.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<pages>53--61</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="6003" citStr="Foster et al., 2006" startWordPosition="898" endWordPosition="901">he details of which can be found in (Ueffing et al., 2007). The main features of this configuration are: • The use of two distinct phrase tables, containing phrase pairs extracted from the Europarl and the News Commentary training corpora respectively. • Multiple phrase-probability feature functions in the log-linear models, including a joint prob&apos;A version of PORTAGE is made available by the NRC to Canadian universities for research and education purposes. ability estimate, a standard frequency-based conditional probability estimate, and variants thereof based on different smoothing methods (Foster et al., 2006). • A 4-gram language model trained on the combined Europarl and News Commentary targetlanguage corpora. • A 3-gram adapted language model: this is trained on a mini-corpus of test-relevant targetlanguage sentences, extracted from the training material using standard information retrieval techniques. • A 5-gram truecasing model, trained on the combined Europarl and News Commentary target-language corpora. 2.3 Training data Ideally, the training material for the post-editing layer of our system should consist in a corpus of text in two parallel versions: on the one hand, raw machine translation</context>
</contexts>
<marker>Foster, Kuhn, Johnson, 2006</marker>
<rawString>G. Foster, R. Kuhn, and H. Johnson. 2006. Phrasetable Smoothing for Statistical Machine Translation. In Proceedings of EMNLP 2006, pages 53–61, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sadat</author>
<author>H Johnson</author>
<author>A Agbago</author>
<author>G Foster</author>
<author>R Kuhn</author>
<author>J Martin</author>
<author>A Tikuisis</author>
</authors>
<title>PORTAGE: A Phrase-Based Machine Translation System.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Building and Using Parallel Texts,</booktitle>
<pages>129--132</pages>
<location>Ann Arbor, USA.</location>
<contexts>
<context position="5186" citStr="Sadat et al., 2005" startWordPosition="772" endWordPosition="775">we did not rely on this feature, and used the system in its basic “out-of-the-box” configuration. 2.2 Statistical Phrase-based Post-Editing The output of the rule-based MT system described above is fed into a post-editing layer that performs domain-specific corrections and adaptation. This operation is conceptually not very different from a “target-to-target” translation; for this task, we used the PORTAGE system, a state-of-the-art statistical phrase-based machine translation system developed at the National Research Council of Canada (NRC).1 A general description of PORTAGE can be found in (Sadat et al., 2005). For our participation in this shared task, we decided to configure and train the PORTAGE system for post-editing in a manner as much as possible similar to the corresponding translation system, the details of which can be found in (Ueffing et al., 2007). The main features of this configuration are: • The use of two distinct phrase tables, containing phrase pairs extracted from the Europarl and the News Commentary training corpora respectively. • Multiple phrase-probability feature functions in the log-linear models, including a joint prob&apos;A version of PORTAGE is made available by the NRC to </context>
</contexts>
<marker>Sadat, Johnson, Agbago, Foster, Kuhn, Martin, Tikuisis, 2005</marker>
<rawString>F. Sadat, H. Johnson, A. Agbago, G. Foster, R. Kuhn, J. Martin, and A. Tikuisis. 2005. PORTAGE: A Phrase-Based Machine Translation System. In Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 129–132, Ann Arbor, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Simard</author>
<author>C Goutte</author>
<author>P Isabelle</author>
</authors>
<title>Statistical Phrase-Based Post-Editing.</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,</booktitle>
<pages>508--515</pages>
<location>Rochester, USA.</location>
<contexts>
<context position="821" citStr="Simard et al. (2007)" startWordPosition="111" endWordPosition="114">ada Gatineau, Canada, K1A 0R6 firstname.lastname@nrc-cnrc.gc.ca Abstract This article describes a machine translation system based on an automatic post-editing strategy: initially translate the input text into the target-language using a rule-based MT system, then automatically post-edit the output using a statistical phrase-based system. An implementation of this approach based on the SYSTRAN and PORTAGE MT systems was used in the shared task of the Second Workshop on Statistical Machine Translation. Experimental results on the test data of the previous campaign are presented. 1 Introduction Simard et al. (2007) have recently shown how a statistical phrase-based machine translation system can be used as an automatic post-editing (APE) layer, on top of a rule-based machine translation system. The motivation for their work is the repetitive nature of the errors typically made by rule-based systems. Given appropriate training material, a statistical MT system can be trained to correct these systematic errors, therefore reducing the post-editing effort. The statistical system views the output of the rule-based system as the source language, and reference human translations as the target language. Because</context>
<context position="6771" citStr="Simard et al. (2007)" startWordPosition="1019" endWordPosition="1022">trained on a mini-corpus of test-relevant targetlanguage sentences, extracted from the training material using standard information retrieval techniques. • A 5-gram truecasing model, trained on the combined Europarl and News Commentary target-language corpora. 2.3 Training data Ideally, the training material for the post-editing layer of our system should consist in a corpus of text in two parallel versions: on the one hand, raw machine translation output, and on the other hand, manually post-edited versions of these translations. This is the type of data that was used in the initial study of Simard et al. (2007). Unfortunately, this sort of training data is seldom available. Instead, we propose using training material derived directly from standard, source-target parallel corpora. The idea is to translate the source portion of the parallel corpus into the target language, using the rule-based MT component. The post-editing component can then be trained using this translation as “source” training material, and the existing target portion of the parallel corpus as “target” training material. Note how this sort of data is subtly different from the data used by Simard et al.: there, the “target” text was</context>
</contexts>
<marker>Simard, Goutte, Isabelle, 2007</marker>
<rawString>M. Simard, C. Goutte, and P. Isabelle. 2007. Statistical Phrase-Based Post-Editing. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 508–515, Rochester, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ueffing</author>
<author>M Simard</author>
<author>S Larkin</author>
<author>H Johnson</author>
</authors>
<title>NRC’s PORTAGE system for WMT</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop On Statistical Machine Translation,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="5441" citStr="Ueffing et al., 2007" startWordPosition="816" endWordPosition="819">ific corrections and adaptation. This operation is conceptually not very different from a “target-to-target” translation; for this task, we used the PORTAGE system, a state-of-the-art statistical phrase-based machine translation system developed at the National Research Council of Canada (NRC).1 A general description of PORTAGE can be found in (Sadat et al., 2005). For our participation in this shared task, we decided to configure and train the PORTAGE system for post-editing in a manner as much as possible similar to the corresponding translation system, the details of which can be found in (Ueffing et al., 2007). The main features of this configuration are: • The use of two distinct phrase tables, containing phrase pairs extracted from the Europarl and the News Commentary training corpora respectively. • Multiple phrase-probability feature functions in the log-linear models, including a joint prob&apos;A version of PORTAGE is made available by the NRC to Canadian universities for research and education purposes. ability estimate, a standard frequency-based conditional probability estimate, and variants thereof based on different smoothing methods (Foster et al., 2006). • A 4-gram language model trained on</context>
</contexts>
<marker>Ueffing, Simard, Larkin, Johnson, 2007</marker>
<rawString>N. Ueffing, M. Simard, S. Larkin, and H. Johnson. 2007. NRC’s PORTAGE system for WMT 2007. In Proceedings of the Second Workshop On Statistical Machine Translation, Prague, Czech Republic.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>