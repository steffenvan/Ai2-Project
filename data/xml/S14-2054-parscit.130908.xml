<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.020022">
<title confidence="0.872734">
IIT Patna: Supervised Approach for Sentiment Analysis in Twitter
</title>
<author confidence="0.972175">
Raja Selvarajan and Asif Ekbal
</author>
<affiliation confidence="0.9984">
Department of Computer Science and Engineering
Indian Institute of Technology Patna, India
</affiliation>
<email confidence="0.989252">
{raja.cs10,asif}@iitp.ac.in
</email>
<sectionHeader confidence="0.995217" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.987716692307692">
In this paper we report our works for
SemEval-2014 Sentiment Analysis in
Twitter evaluation challenge. This is the
first time we attempt for this task, and
our submissions are based on supervised
machine learning algorithm. We use Sup-
port Vector Machine for both the tasks,
viz. contextual polarity disambiguation
and message polarity classification. We
identify and implement a small set of
features for each the tasks, and did not
make use of any external resources and/or
tools. The systems are tuned on the devel-
opment sets and finally blind evaluation is
performed on the respective test set, which
consists of the datasets of five different
domains. Our submission for the first
task shows the F-score values of 76.3%,
77.04%, 70.91%, 72.25% and 66.32% for
LiveJournal2014, SMS2013, Twitter2013,
Twitter2014 and Twitter2014Sarcasm
datasets, respectively. The system devel-
oped for the second task yields the F-score
values of 54.68%, 40.56%, 50.32%,
48.22% and 36.73%, respectively for the
five different test datasets.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.957881018867925">
During the past few years, the communications in
the forms of microblogging and text messaging
have emerged and become ubiquitous. Opinions
and sentiments about the surrounding worlds are
widely expressed through the mediums of Twit-
ter messages (Tweets) and Cell phone messages
(SMS). The availability of social content gener-
ated on sites such as Twitter creates new opportu-
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
nities to automatically study public opinion. Deal-
ing with these informal text genres presents new
challenges for data mining and language process-
ing techniques beyond those encountered when
working with more traditional text genres such as
newswire. Tweets and SMS messages are short
in length, usually a sentence or a headline rather
than a document. These texts are very informal in
nature and contains creative spellings and punctu-
ation symbols (Nakov et al., 2013). Text also con-
tains lots of misspellings, slang, out-of-vocabulary
words, URLs, and genre-specific terminology and
abbreviations, e.g., RT for reTweet and #hash-
tags. The kind of these specific features pose great
challenges for building various lexical and syntac-
tic resources and/or tools, which are required for
efficient processing of texts. These aspects also
introduce complexities to build the state-of-the-
art data mining systems. In recent times, there
has been a huge interest to mine and understand
the opinions and sentiments that people are com-
municating in social media (Barbosa and Feng,
2010; Bifet et al., 2011; Pak and Paroubek, 2010;
Kouloumpis et al., 2011). Recent studies show
the interests in sentiment analysis of Tweets across
a variety of domains such as commerce (Jansen
et al., 2009), health (Chew and Eysenbach, 2010;
Salathe and Khandelwal, 2011) and disaster man-
agement (Mandel et al., 2012).
Another aspect of social media data, such as
twitter messages, is that they include rich informa-
tion about the individuals involved in the commu-
nication. For e.g., twitter maintains information
about who follows whom. ReTweets (reshares of a
Tweet) and tags inside of Tweets provide discourse
information (Nakov et al., 2013). Efficient mod-
elling of such information is crucial in the sense
that it provides a mean to empirically study the
social interactions where opinion is conveyed.
Several corpora with detailed opinion and senti-
ment annotation have been made freely available,
</bodyText>
<page confidence="0.987322">
324
</page>
<note confidence="0.730477">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 324–328,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.99996878">
e.g., the MPQA corpus (Barbosa and Feng, 2005)
of newswire text; i-sieve (Kouloumpis et al., 2011)
and TASS corpus2 (Villena-Roman et al., 2013)
for Twitter sentiment. These resources were either
in non-social media or they were small and propri-
etary. They further focused on message-level sen-
timent. The SemEval-2013 shared task (Nakov et
al., 2013) on sentiment analysis in Twitter releases
SemEval Tweet corpus, which contains Tweets
and SMS messages with sentiment expressions an-
notated with contextual phrase-level polarity as
well as an overall message-level polarity. Among
the 44 submissions, the highest-performing sys-
tem (Mohammad et al., 2013) made use of Sup-
port Vector Machine (SVM) classifier. It obtained
the F-scores of 69.02% in the message-level task
and 88.93% in the term-level task. Variety of fea-
tures were implemented based on surface-forms,
semantics, and sentiment features. They generated
two large wordsentiment association lexicons, one
from Tweets with sentiment-word hashtags, and
one from Tweets with emoticons. They showed
that in message-level task, the lexicon-based fea-
tures gained 5 F-score points over all the others.
SemEval-14 shared task 1 on sentiment analy-
sis in Twitter is a continuing effort to promote the
research in this direction. Similar to the previ-
ous year’s evaluation campaigns two primary tasks
were addressed in this year challenge. The first
task (i.e. Subtask A) deals with contextual polar-
ity disambiguation and the second task (i.e. Sub-
task B) was about message polarity classification.
For Subtask A, for a given message containing a
marked instance of a word or phrase, the goal is to
determine whether that instance is positive, nega-
tive or neutral in that context. In Subtask B, for a
given message, the task is to classify whether the
message is of positive, negative, or neutral sen-
timent. For messages that convey both positive
and negative sentiments, the stronger one should
be chosen.
In this paper we report on our submissions as
part of our first-time participation in this kind of
task (i.e. sentiment classification). We develop the
systems based on supervised machine learning al-
gorithm, namely Support Vector Machine (SVM)
(Joachims, 1999; Vapnik, 1995). We identify and
implement a very small set of features that do not
make use of any external resources and/or tools.
For each task the system is tuned on the devel-
</bodyText>
<footnote confidence="0.907852">
1http://alt.qcri.org/semeval2014/task9/
</footnote>
<bodyText confidence="0.97381">
opment data, and finally blind evaluation is per-
formed on the test data.
</bodyText>
<sectionHeader confidence="0.981727" genericHeader="introduction">
2 Methods
</sectionHeader>
<bodyText confidence="0.9997923">
We develop two systems, one for contextual polar-
ity disambiguation and the other for message po-
larity classification. Each of the systems is based
on supervised machine learning algorithm, namely
SVM. Support vector machines (Joachims, 1999;
Vapnik, 1995) have been shown to be highly ef-
fective at traditional text categorization, generally
outperforming many other classifiers such as naive
Bayes (Joachims, 1999; Vapnik, 1995). They are
large-margin, rather than probabilistic, classifiers.
For solving the two-class problem, the basic idea
behind the training procedure is to find a hyper-
plane, represented by vector w, that not only sepa-
rates the document vectors in one class from those
in the other, but for which the separation, or mar-
gin, is as large as possible. This search corre-
sponds to a constrained optimization problem; let-
ting cj in 1,-1 (corresponding to positive and neg-
ative classes, respectively) be the correct class of
the document dj, the solution could be written as:
</bodyText>
<equation confidence="0.922737">
w� := Ej ajcj dj, aj &gt;= 0
</equation>
<bodyText confidence="0.999975333333333">
where, the aj’s are obtained by solving a dual opti-
mization problem. Those dj such that aj is greater
than zero are called support vectors, since they are
the only document vectors contributing to w. Clas-
sification of test instances consists simply of deter-
mining which side of w’s hyperplane they fall on.
</bodyText>
<subsectionHeader confidence="0.983856">
2.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.9998758">
We pre-process Tweet to normalize it by replac-
ing all ”URLs” to ”http://url” and all user-ids
to ”@usr”, and this is performed by the regular
expression based simple pattern matching tech-
niques. We remove punctuation markers from the
start and end positions of Tweets. For e.g., ’the
day is beautiful!’ is converted to ’the day is beauti-
ful’. Multiple whitespaces are replaced with single
whitespace. Stop-words are removed from each
review.
</bodyText>
<subsectionHeader confidence="0.94054">
2.2 Features
</subsectionHeader>
<bodyText confidence="0.999582">
In this work we use same set of features for both
the tasks. Each Tweet is represented as a vector
consisting of the following features:
</bodyText>
<listItem confidence="0.96787">
1. Local contexts: We extract the unigrams and
bigrams from the training and test datasets.
</listItem>
<page confidence="0.994512">
325
</page>
<bodyText confidence="0.960474333333333">
A feature is defined that checks the occur-
rences of these n-grams in a particular Tweet
or phrase.
</bodyText>
<listItem confidence="0.937719588235294">
2. Upper case: This feature is binary valued
with a value set to 1 if all the characters of
a phrase or Tweet are capitalized, and 0 oth-
erwise. This indicates that the target message
or context contains either positive or negative
sentiment.
3. Elongated words: The feature checks
whether a word contains a character that re-
peats more than twice. This indicates the
presence of a positive sentiment word in the
surrounding. This was defined in lines with
the one reported in (Mohammad et al., 2013).
4. Hash tags: This feature checks the number
of hash tags in the Tweet. The value of this
feature is set equal to the absolute number of
features.
5. Repeated characters: This feature checks
</listItem>
<bodyText confidence="0.792251833333333">
whether the word(s) have at least three
consecutive repeated characters (e.g.,
happppppppy, hurrrrrey etc.). In such cases,
the words are normalized to contain only
upto two repeated characters. This helps to
capture the words having similar structures.
</bodyText>
<listItem confidence="0.726582">
6. Negated contexts: A negated word can af-
fect the polarity of the target word. A negated
segment is defined as a sequence of tokens
that starts with a negation word (e..g, no,
couldn’t etc.) and ends with a punctuation
marks (e.g.,,,., :, ;, !, ?). All the words follow-
ing the negation word are suffixed with NEG-
ATIVE, and the polarity features are also
converted with NEGATIVE in line with (Mo-
hammad et al., 2013).
</listItem>
<sectionHeader confidence="0.93889" genericHeader="method">
3 Experimental Results and Analysis
</sectionHeader>
<bodyText confidence="0.999556625">
The SemEval-2014 shared task datasets are based
on SemEval-2013 competition datasets. It covers
a range of topics, including a mixture of entities,
products and events. Keywords and Twitter hash-
tags were used to identify messages relevant to the
selected topic. The selected test sets were taken
from the five different domains. We perform ex-
periment with the python based NLTK toolki2. We
</bodyText>
<footnote confidence="0.95443">
2http://www.nltk.org/
</footnote>
<table confidence="0.999439">
Class precision recall F-score
Positive 72.02 90.45 80.19
Negative 76.86 53.70 63.23
Neutral 7.69 22.22 3.45
Average 52.19 55.46 53.77
</table>
<tableCaption confidence="0.9456065">
Table 1: Results on development set for Task-A
(%).
</tableCaption>
<table confidence="0.99983">
Class precision recall F-score
Positive 49.92 63.75 55.99
Negative 42.59 31.94 36.51
Neutral 59.54 53.49 56.35
Average 50.68 49.73 66.39
</table>
<tableCaption confidence="0.8378975">
Table 2: Results on development set for Task-B (in
%).
</tableCaption>
<bodyText confidence="0.999106958333333">
carried out experiments with the different classi-
fiers. However we report the results of SVM as
it produced the highest accuracy with respect to
this particular feature set. We use the default pa-
rameters of SVM as implemented in this toolkit.
We submitted two runs, one for each task. Both
of our submissions were constrained in nature, i.e.
we did not make use of any additional resources
and/or tools to build our systems.
We perform several experiments using the de-
velopment set. Best results are reported in Table 1
and Table 2 for Task-A and Task-B, respectively.
Evaluation shows that for message polarity dis-
ambiguation we obtain the average precision, re-
call and F-score values of 52.19%, 55.46% and
53.77%, respectively. For message polarity clas-
sification we obtain the precision, recall and F-
Score values of 50.68%, 49.73% and 66.39%, re-
spectively. It is evident from the evaluation that
the first task suffers most due to the problems in
classifying the tweets having neutral sentiments,
whereas the second task faces difficulties in clas-
sifying the negative sentiments. We report the con-
fusion matrices in Table 3 and Table 4 for the first
</bodyText>
<table confidence="0.96341675">
gs\pred positive negative neutral
positive 502 50 3
negative 160 196 9
neutral 35 9 1
</table>
<tableCaption confidence="0.9943">
Table 3: Confusion matrix for A. Here, gs: Gold
standard; pred: Predicted class.
</tableCaption>
<page confidence="0.9632">
326
</page>
<table confidence="0.99972025">
gs\pred positive negative neutral
positive 313 43 135
negative 102 92 94
neutral 212 81 337
</table>
<tableCaption confidence="0.9886105">
Table 4: Confusion matrix for B. Here, gs: Gold
standard; pred: Predicted class.
</tableCaption>
<bodyText confidence="0.999838517241379">
and second development sets, respectively. Error
analysis suggests that most miss-classifications are
because of the less number of neutral instances
compared to the positive and negative instances in
Task-A. For the Task-B training set, the number
of instances of positive and neutral sentiments are
very low compared to the negative sentiment.
After tuning the systems on the development
sets, we perform blind evaluation on the test
datasets. Evaluation results on the test sets are
reported in Table 5 for both the tasks. The
evaluation is carried out based on the evaluation
scripts as provided by the organizers. For mes-
sage polarity disambiguation we obtain the high-
est F-score of 77.04% for the SMS data type
in Task-A. The system shows the F-scores of
76.03%, 70.91%, 72.25% and 66.35% for Live-
Journal2014, Twitter2013, Twitter2014 and Twit-
ter2014sarcasm, respectively. For the second task
the system attains the highest F-score value of
54.68% for the LiveJournal2014 dataset. For the
other datasets, the system shows the F-scores of
40.56%, 50.32%, 48.22% and 36.73% for the
SMS2013, Twitter2013 and Twitter2014Sarcasm,
respectively. We followed a simple approach that
needs fine-tuning in many places. Currently our
systems lack behind the best reported systems by
margins of approximately 11-18% F-scores for
Task-A, and 19-30% F-scores for Task-B.
</bodyText>
<sectionHeader confidence="0.994521" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.997288583333333">
In this paper we report our works as part of our
participation to the SemEval-14 shared task on
sentiment analysis for Twitter data. Our systems
were developed based on SVM. We use a small
set of features, and did not make use of any ex-
ternal resources and/or tools in any of the tasks.
Each of the systems is tuned on the development
set, and blind evaluation is performed on the test
set. Evaluation shows that our system achieves the
F-score values in the ranges of 66-76% for Task-A
and 36-55% for Task-B.
It is to be noted that this is our first participa-
</bodyText>
<table confidence="0.999263833333333">
Task Test-set Average
F-score
A LiveJournal2014 76.03
SMS2013 77.04
Twitter2013 70.91
Twitter2014 72.25
Twitter2014Sarcasm 66.35
B LiveJournal2014 54.68
SMS2013 40.56
Twitter2013 50.32
Twitter2014 48.22
Twitter2014Sarcasm 36.73
</table>
<tableCaption confidence="0.999896">
Table 5: Results on the test set.
</tableCaption>
<bodyText confidence="0.9998401">
tion, and there are many ways to improve the per-
formance of the models. Firstly we would like to
identify more features in order to improve the ac-
curacies. We also plan to come up with proper sets
of features for the two task. Efficient feature se-
lection techniques will be implemented to identify
the most effective feature set for each of the tasks.
We would like to apply evolutionary optimization
techniques to optimize the different issues of ma-
chine learning algorithm.
</bodyText>
<sectionHeader confidence="0.99714" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99955748">
Luciano Barbosa and Junlan Feng. 2005. Robust Sen-
timent Detection on Twitter from Biased and Noisy
Data. 39:2-3.
Luciano Barbosa and Junlan Feng. 2010. Robust Sen-
timent Detection on Twitter from Biased and Noisy
Data. In Proceedings of the 23rd International Con-
ference on Computational Linguistics (COLING),
Beijing, China.
Albert Bifet, Geoffrey Holmes, Bernhard Pfahringer,
and Ricard Gavald‘a. 2011. Detecting Sentiment
Change in Twitter Streaming Data. Journal of Ma-
chine Learning Research - Proceedings Track, 17:5–
11.
Cynthia Chew and Gunther Eysenbach. 2010. Pan-
demics in the Age of Twitter: Content Analysis
of Tweets during the 2009 H1N1 Outbreak. PLoS
ONE, 5(11):e14118+.
Bernard J. Jansen, Mimi Zhang, Kate Sobel, and Ab-
dur Chowdury. 2009. Twitter Power: Tweets as
Electronic Word of Mouth. Journal of the Ameri-
can Society for Information Science and Technology,
60(11):2169–2188.
Thorsten Joachims, 1999. Making Large Scale SVM
Learning Practical, pages 169–184. MIT Press,
Cambridge, MA, USA.
</reference>
<page confidence="0.980109">
327
</page>
<reference confidence="0.999652521739131">
Efthymios Kouloumpis, Theresa Wilson, and Johanna
Moore. 2011. Twitter Sentiment Analysis: The
Good the Bad and the OMG! In Proceedings of
the Fifth International Conference on Weblogs and
Social Media, ICWSM, pages 538–541, Barcelona,
Spain.
Benjamin Mandel, Aron Culotta, John Boulahanis,
Danielle Stark, Bonnie Lewis, and Jeremy Rodrigue.
2012. A Demographic Analysis of Online Senti-
ment during Hurricane Irene. In Proceedings of
the Second Workshop on Language in Social Media,
LSM 12, Stroudsburg.
Saif M. Mohammad, Svetlana Kiritchenko, and Xiao-
dan Zhu. 2013. NRC-Canada: Building the State-
of-the-Art in Sentiment Analysis of Tweets. In Pro-
ceedings of Second Joint Conference on Lexical and
Computational Semantics (*SEM), Volume 2: Sev-
enth International Workshop on Semantic Evalua-
tion (SemEval 2013), pages 321–327, Atlanta, Geor-
gia.
Preslav Nakov, Sara Rosenthal, Zornitsa Kozareva,
Veselin Stoyanov, Alan Ritter, and Theresa Wilson.
2013. Semeval-2013 task 2: Sentiment Analysis in
Twitter. In Second Joint Conference on Lexical and
Computational Semantics (*SEM), Volume 2: Pro-
ceedings of the Seventh International Workshop on
Semantic Evaluation (SemEval 2013), pages 312–
320, Atlanta, Georgia, USA, June.
Alexander Pak and Patrick Paroubek. 2010. Twitter
Based System: Using Twitter for Disambiguating
Sentiment Ambiguous Adjectives. In Proceedings
of the 5th International Workshop on Semantic Eval-
uation, SemEval 10, Los Angeles,USA.
Marcel Salathe and Shashank Khandelwal. 2011. As-
sessing Vaccination Sentiments with Online Social
Media: Implications for Infectious Disease Dynam-
ics and Control. PLoS Computational Biology,
7(10):e14118+.
Vladimir N. Vapnik. 1995. The Nature of Statistical
Learning Theory. Springer-Verlag New York, Inc.,
New York, NY, USA.
Julio Villena-Roman, Sara Lana-Serrano, Eugenio
Martnez-Camara, Jose Carlos Gonzalez, and Cristo-
bal. 2013. Tass - Workshop on Sentiment Analy-
sis at SEPLN. In Proceedings of Procesamiento del
Lenguaje Natural, pages 50:37–44.
</reference>
<page confidence="0.998352">
328
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.416370">
<title confidence="0.995708">IIT Patna: Supervised Approach for Sentiment Analysis in Twitter</title>
<author confidence="0.997199">Raja Selvarajan</author>
<author confidence="0.997199">Asif</author>
<affiliation confidence="0.999069">Department of Computer Science and Indian Institute of Technology Patna,</affiliation>
<abstract confidence="0.939644">In this paper we report our works for SemEval-2014 Sentiment Analysis in Twitter evaluation challenge. This is the first time we attempt for this task, and our submissions are based on supervised machine learning algorithm. We use Support Vector Machine for both the tasks, viz. contextual polarity disambiguation polarity We identify and implement a small set of features for each the tasks, and did not make use of any external resources and/or tools. The systems are tuned on the development sets and finally blind evaluation is performed on the respective test set, which consists of the datasets of five different domains. Our submission for the first task shows the F-score values of 76.3%, 77.04%, 70.91%, 72.25% and 66.32% for LiveJournal2014, SMS2013, Twitter2013, Twitter2014 and Twitter2014Sarcasm datasets, respectively. The system developed for the second task yields the F-score values of 54.68%, 40.56%, 50.32%, 48.22% and 36.73%, respectively for the five different test datasets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Luciano Barbosa</author>
<author>Junlan Feng</author>
</authors>
<date>2005</date>
<booktitle>Robust Sentiment Detection on Twitter from Biased and Noisy Data.</booktitle>
<pages>39--2</pages>
<contexts>
<context position="4012" citStr="Barbosa and Feng, 2005" startWordPosition="604" endWordPosition="607">ation. For e.g., twitter maintains information about who follows whom. ReTweets (reshares of a Tweet) and tags inside of Tweets provide discourse information (Nakov et al., 2013). Efficient modelling of such information is crucial in the sense that it provides a mean to empirically study the social interactions where opinion is conveyed. Several corpora with detailed opinion and sentiment annotation have been made freely available, 324 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 324–328, Dublin, Ireland, August 23-24, 2014. e.g., the MPQA corpus (Barbosa and Feng, 2005) of newswire text; i-sieve (Kouloumpis et al., 2011) and TASS corpus2 (Villena-Roman et al., 2013) for Twitter sentiment. These resources were either in non-social media or they were small and proprietary. They further focused on message-level sentiment. The SemEval-2013 shared task (Nakov et al., 2013) on sentiment analysis in Twitter releases SemEval Tweet corpus, which contains Tweets and SMS messages with sentiment expressions annotated with contextual phrase-level polarity as well as an overall message-level polarity. Among the 44 submissions, the highest-performing system (Mohammad et al</context>
</contexts>
<marker>Barbosa, Feng, 2005</marker>
<rawString>Luciano Barbosa and Junlan Feng. 2005. Robust Sentiment Detection on Twitter from Biased and Noisy Data. 39:2-3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luciano Barbosa</author>
<author>Junlan Feng</author>
</authors>
<title>Robust Sentiment Detection on Twitter from Biased and Noisy Data.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING),</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="2925" citStr="Barbosa and Feng, 2010" startWordPosition="435" endWordPosition="438">ov et al., 2013). Text also contains lots of misspellings, slang, out-of-vocabulary words, URLs, and genre-specific terminology and abbreviations, e.g., RT for reTweet and #hashtags. The kind of these specific features pose great challenges for building various lexical and syntactic resources and/or tools, which are required for efficient processing of texts. These aspects also introduce complexities to build the state-of-theart data mining systems. In recent times, there has been a huge interest to mine and understand the opinions and sentiments that people are communicating in social media (Barbosa and Feng, 2010; Bifet et al., 2011; Pak and Paroubek, 2010; Kouloumpis et al., 2011). Recent studies show the interests in sentiment analysis of Tweets across a variety of domains such as commerce (Jansen et al., 2009), health (Chew and Eysenbach, 2010; Salathe and Khandelwal, 2011) and disaster management (Mandel et al., 2012). Another aspect of social media data, such as twitter messages, is that they include rich information about the individuals involved in the communication. For e.g., twitter maintains information about who follows whom. ReTweets (reshares of a Tweet) and tags inside of Tweets provide </context>
</contexts>
<marker>Barbosa, Feng, 2010</marker>
<rawString>Luciano Barbosa and Junlan Feng. 2010. Robust Sentiment Detection on Twitter from Biased and Noisy Data. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING), Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Albert Bifet</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Ricard Gavald‘a</author>
</authors>
<title>Detecting Sentiment Change in Twitter Streaming Data.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research - Proceedings Track,</journal>
<volume>17</volume>
<pages>11</pages>
<marker>Bifet, Holmes, Pfahringer, Gavald‘a, 2011</marker>
<rawString>Albert Bifet, Geoffrey Holmes, Bernhard Pfahringer, and Ricard Gavald‘a. 2011. Detecting Sentiment Change in Twitter Streaming Data. Journal of Machine Learning Research - Proceedings Track, 17:5– 11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia Chew</author>
<author>Gunther Eysenbach</author>
</authors>
<title>Pandemics in the Age of Twitter: Content Analysis</title>
<date>2010</date>
<booktitle>of Tweets during the 2009 H1N1 Outbreak. PLoS ONE,</booktitle>
<pages>5--11</pages>
<contexts>
<context position="3163" citStr="Chew and Eysenbach, 2010" startWordPosition="474" endWordPosition="477">nges for building various lexical and syntactic resources and/or tools, which are required for efficient processing of texts. These aspects also introduce complexities to build the state-of-theart data mining systems. In recent times, there has been a huge interest to mine and understand the opinions and sentiments that people are communicating in social media (Barbosa and Feng, 2010; Bifet et al., 2011; Pak and Paroubek, 2010; Kouloumpis et al., 2011). Recent studies show the interests in sentiment analysis of Tweets across a variety of domains such as commerce (Jansen et al., 2009), health (Chew and Eysenbach, 2010; Salathe and Khandelwal, 2011) and disaster management (Mandel et al., 2012). Another aspect of social media data, such as twitter messages, is that they include rich information about the individuals involved in the communication. For e.g., twitter maintains information about who follows whom. ReTweets (reshares of a Tweet) and tags inside of Tweets provide discourse information (Nakov et al., 2013). Efficient modelling of such information is crucial in the sense that it provides a mean to empirically study the social interactions where opinion is conveyed. Several corpora with detailed opin</context>
</contexts>
<marker>Chew, Eysenbach, 2010</marker>
<rawString>Cynthia Chew and Gunther Eysenbach. 2010. Pandemics in the Age of Twitter: Content Analysis of Tweets during the 2009 H1N1 Outbreak. PLoS ONE, 5(11):e14118+.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard J Jansen</author>
<author>Mimi Zhang</author>
<author>Kate Sobel</author>
<author>Abdur Chowdury</author>
</authors>
<title>Twitter Power: Tweets as Electronic Word of Mouth.</title>
<date>2009</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>60</volume>
<issue>11</issue>
<contexts>
<context position="3129" citStr="Jansen et al., 2009" startWordPosition="469" endWordPosition="472">fic features pose great challenges for building various lexical and syntactic resources and/or tools, which are required for efficient processing of texts. These aspects also introduce complexities to build the state-of-theart data mining systems. In recent times, there has been a huge interest to mine and understand the opinions and sentiments that people are communicating in social media (Barbosa and Feng, 2010; Bifet et al., 2011; Pak and Paroubek, 2010; Kouloumpis et al., 2011). Recent studies show the interests in sentiment analysis of Tweets across a variety of domains such as commerce (Jansen et al., 2009), health (Chew and Eysenbach, 2010; Salathe and Khandelwal, 2011) and disaster management (Mandel et al., 2012). Another aspect of social media data, such as twitter messages, is that they include rich information about the individuals involved in the communication. For e.g., twitter maintains information about who follows whom. ReTweets (reshares of a Tweet) and tags inside of Tweets provide discourse information (Nakov et al., 2013). Efficient modelling of such information is crucial in the sense that it provides a mean to empirically study the social interactions where opinion is conveyed. </context>
</contexts>
<marker>Jansen, Zhang, Sobel, Chowdury, 2009</marker>
<rawString>Bernard J. Jansen, Mimi Zhang, Kate Sobel, and Abdur Chowdury. 2009. Twitter Power: Tweets as Electronic Word of Mouth. Journal of the American Society for Information Science and Technology, 60(11):2169–2188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making Large Scale SVM Learning Practical,</title>
<date>1999</date>
<pages>169--184</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="6179" citStr="Joachims, 1999" startWordPosition="945" endWordPosition="946">d instance of a word or phrase, the goal is to determine whether that instance is positive, negative or neutral in that context. In Subtask B, for a given message, the task is to classify whether the message is of positive, negative, or neutral sentiment. For messages that convey both positive and negative sentiments, the stronger one should be chosen. In this paper we report on our submissions as part of our first-time participation in this kind of task (i.e. sentiment classification). We develop the systems based on supervised machine learning algorithm, namely Support Vector Machine (SVM) (Joachims, 1999; Vapnik, 1995). We identify and implement a very small set of features that do not make use of any external resources and/or tools. For each task the system is tuned on the devel1http://alt.qcri.org/semeval2014/task9/ opment data, and finally blind evaluation is performed on the test data. 2 Methods We develop two systems, one for contextual polarity disambiguation and the other for message polarity classification. Each of the systems is based on supervised machine learning algorithm, namely SVM. Support vector machines (Joachims, 1999; Vapnik, 1995) have been shown to be highly effective at </context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims, 1999. Making Large Scale SVM Learning Practical, pages 169–184. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Efthymios Kouloumpis</author>
<author>Theresa Wilson</author>
<author>Johanna Moore</author>
</authors>
<title>Twitter Sentiment Analysis: The Good the Bad and the OMG!</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifth International Conference on Weblogs and Social Media, ICWSM,</booktitle>
<pages>538--541</pages>
<location>Barcelona,</location>
<contexts>
<context position="2995" citStr="Kouloumpis et al., 2011" startWordPosition="447" endWordPosition="450">t-of-vocabulary words, URLs, and genre-specific terminology and abbreviations, e.g., RT for reTweet and #hashtags. The kind of these specific features pose great challenges for building various lexical and syntactic resources and/or tools, which are required for efficient processing of texts. These aspects also introduce complexities to build the state-of-theart data mining systems. In recent times, there has been a huge interest to mine and understand the opinions and sentiments that people are communicating in social media (Barbosa and Feng, 2010; Bifet et al., 2011; Pak and Paroubek, 2010; Kouloumpis et al., 2011). Recent studies show the interests in sentiment analysis of Tweets across a variety of domains such as commerce (Jansen et al., 2009), health (Chew and Eysenbach, 2010; Salathe and Khandelwal, 2011) and disaster management (Mandel et al., 2012). Another aspect of social media data, such as twitter messages, is that they include rich information about the individuals involved in the communication. For e.g., twitter maintains information about who follows whom. ReTweets (reshares of a Tweet) and tags inside of Tweets provide discourse information (Nakov et al., 2013). Efficient modelling of suc</context>
</contexts>
<marker>Kouloumpis, Wilson, Moore, 2011</marker>
<rawString>Efthymios Kouloumpis, Theresa Wilson, and Johanna Moore. 2011. Twitter Sentiment Analysis: The Good the Bad and the OMG! In Proceedings of the Fifth International Conference on Weblogs and Social Media, ICWSM, pages 538–541, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Mandel</author>
<author>Aron Culotta</author>
<author>John Boulahanis</author>
<author>Danielle Stark</author>
<author>Bonnie Lewis</author>
<author>Jeremy Rodrigue</author>
</authors>
<title>A Demographic Analysis of Online Sentiment during Hurricane Irene.</title>
<date>2012</date>
<booktitle>In Proceedings of the Second Workshop on Language in Social Media, LSM 12,</booktitle>
<location>Stroudsburg.</location>
<contexts>
<context position="3240" citStr="Mandel et al., 2012" startWordPosition="486" endWordPosition="489"> required for efficient processing of texts. These aspects also introduce complexities to build the state-of-theart data mining systems. In recent times, there has been a huge interest to mine and understand the opinions and sentiments that people are communicating in social media (Barbosa and Feng, 2010; Bifet et al., 2011; Pak and Paroubek, 2010; Kouloumpis et al., 2011). Recent studies show the interests in sentiment analysis of Tweets across a variety of domains such as commerce (Jansen et al., 2009), health (Chew and Eysenbach, 2010; Salathe and Khandelwal, 2011) and disaster management (Mandel et al., 2012). Another aspect of social media data, such as twitter messages, is that they include rich information about the individuals involved in the communication. For e.g., twitter maintains information about who follows whom. ReTweets (reshares of a Tweet) and tags inside of Tweets provide discourse information (Nakov et al., 2013). Efficient modelling of such information is crucial in the sense that it provides a mean to empirically study the social interactions where opinion is conveyed. Several corpora with detailed opinion and sentiment annotation have been made freely available, 324 Proceedings</context>
</contexts>
<marker>Mandel, Culotta, Boulahanis, Stark, Lewis, Rodrigue, 2012</marker>
<rawString>Benjamin Mandel, Aron Culotta, John Boulahanis, Danielle Stark, Bonnie Lewis, and Jeremy Rodrigue. 2012. A Demographic Analysis of Online Sentiment during Hurricane Irene. In Proceedings of the Second Workshop on Language in Social Media, LSM 12, Stroudsburg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Svetlana Kiritchenko</author>
<author>Xiaodan Zhu</author>
</authors>
<title>NRC-Canada: Building the Stateof-the-Art in Sentiment Analysis of Tweets.</title>
<date>2013</date>
<booktitle>In Proceedings of Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>321--327</pages>
<location>Atlanta,</location>
<contexts>
<context position="4620" citStr="Mohammad et al., 2013" startWordPosition="694" endWordPosition="697">nd Feng, 2005) of newswire text; i-sieve (Kouloumpis et al., 2011) and TASS corpus2 (Villena-Roman et al., 2013) for Twitter sentiment. These resources were either in non-social media or they were small and proprietary. They further focused on message-level sentiment. The SemEval-2013 shared task (Nakov et al., 2013) on sentiment analysis in Twitter releases SemEval Tweet corpus, which contains Tweets and SMS messages with sentiment expressions annotated with contextual phrase-level polarity as well as an overall message-level polarity. Among the 44 submissions, the highest-performing system (Mohammad et al., 2013) made use of Support Vector Machine (SVM) classifier. It obtained the F-scores of 69.02% in the message-level task and 88.93% in the term-level task. Variety of features were implemented based on surface-forms, semantics, and sentiment features. They generated two large wordsentiment association lexicons, one from Tweets with sentiment-word hashtags, and one from Tweets with emoticons. They showed that in message-level task, the lexicon-based features gained 5 F-score points over all the others. SemEval-14 shared task 1 on sentiment analysis in Twitter is a continuing effort to promote the res</context>
<context position="9109" citStr="Mohammad et al., 2013" startWordPosition="1431" endWordPosition="1434">g and test datasets. 325 A feature is defined that checks the occurrences of these n-grams in a particular Tweet or phrase. 2. Upper case: This feature is binary valued with a value set to 1 if all the characters of a phrase or Tweet are capitalized, and 0 otherwise. This indicates that the target message or context contains either positive or negative sentiment. 3. Elongated words: The feature checks whether a word contains a character that repeats more than twice. This indicates the presence of a positive sentiment word in the surrounding. This was defined in lines with the one reported in (Mohammad et al., 2013). 4. Hash tags: This feature checks the number of hash tags in the Tweet. The value of this feature is set equal to the absolute number of features. 5. Repeated characters: This feature checks whether the word(s) have at least three consecutive repeated characters (e.g., happppppppy, hurrrrrey etc.). In such cases, the words are normalized to contain only upto two repeated characters. This helps to capture the words having similar structures. 6. Negated contexts: A negated word can affect the polarity of the target word. A negated segment is defined as a sequence of tokens that starts with a n</context>
</contexts>
<marker>Mohammad, Kiritchenko, Zhu, 2013</marker>
<rawString>Saif M. Mohammad, Svetlana Kiritchenko, and Xiaodan Zhu. 2013. NRC-Canada: Building the Stateof-the-Art in Sentiment Analysis of Tweets. In Proceedings of Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 321–327, Atlanta, Georgia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Sara Rosenthal</author>
<author>Zornitsa Kozareva</author>
<author>Veselin Stoyanov</author>
<author>Alan Ritter</author>
<author>Theresa Wilson</author>
</authors>
<title>Semeval-2013 task 2: Sentiment Analysis in Twitter.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>312--320</pages>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="2319" citStr="Nakov et al., 2013" startWordPosition="343" endWordPosition="346"> International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ nities to automatically study public opinion. Dealing with these informal text genres presents new challenges for data mining and language processing techniques beyond those encountered when working with more traditional text genres such as newswire. Tweets and SMS messages are short in length, usually a sentence or a headline rather than a document. These texts are very informal in nature and contains creative spellings and punctuation symbols (Nakov et al., 2013). Text also contains lots of misspellings, slang, out-of-vocabulary words, URLs, and genre-specific terminology and abbreviations, e.g., RT for reTweet and #hashtags. The kind of these specific features pose great challenges for building various lexical and syntactic resources and/or tools, which are required for efficient processing of texts. These aspects also introduce complexities to build the state-of-theart data mining systems. In recent times, there has been a huge interest to mine and understand the opinions and sentiments that people are communicating in social media (Barbosa and Feng</context>
<context position="3567" citStr="Nakov et al., 2013" startWordPosition="537" endWordPosition="540">ak and Paroubek, 2010; Kouloumpis et al., 2011). Recent studies show the interests in sentiment analysis of Tweets across a variety of domains such as commerce (Jansen et al., 2009), health (Chew and Eysenbach, 2010; Salathe and Khandelwal, 2011) and disaster management (Mandel et al., 2012). Another aspect of social media data, such as twitter messages, is that they include rich information about the individuals involved in the communication. For e.g., twitter maintains information about who follows whom. ReTweets (reshares of a Tweet) and tags inside of Tweets provide discourse information (Nakov et al., 2013). Efficient modelling of such information is crucial in the sense that it provides a mean to empirically study the social interactions where opinion is conveyed. Several corpora with detailed opinion and sentiment annotation have been made freely available, 324 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 324–328, Dublin, Ireland, August 23-24, 2014. e.g., the MPQA corpus (Barbosa and Feng, 2005) of newswire text; i-sieve (Kouloumpis et al., 2011) and TASS corpus2 (Villena-Roman et al., 2013) for Twitter sentiment. These resources were either in no</context>
</contexts>
<marker>Nakov, Rosenthal, Kozareva, Stoyanov, Ritter, Wilson, 2013</marker>
<rawString>Preslav Nakov, Sara Rosenthal, Zornitsa Kozareva, Veselin Stoyanov, Alan Ritter, and Theresa Wilson. 2013. Semeval-2013 task 2: Sentiment Analysis in Twitter. In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 312– 320, Atlanta, Georgia, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Pak</author>
<author>Patrick Paroubek</author>
</authors>
<title>Twitter Based System: Using Twitter for Disambiguating Sentiment Ambiguous Adjectives.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation, SemEval 10,</booktitle>
<location>Los Angeles,USA.</location>
<contexts>
<context position="2969" citStr="Pak and Paroubek, 2010" startWordPosition="443" endWordPosition="446"> misspellings, slang, out-of-vocabulary words, URLs, and genre-specific terminology and abbreviations, e.g., RT for reTweet and #hashtags. The kind of these specific features pose great challenges for building various lexical and syntactic resources and/or tools, which are required for efficient processing of texts. These aspects also introduce complexities to build the state-of-theart data mining systems. In recent times, there has been a huge interest to mine and understand the opinions and sentiments that people are communicating in social media (Barbosa and Feng, 2010; Bifet et al., 2011; Pak and Paroubek, 2010; Kouloumpis et al., 2011). Recent studies show the interests in sentiment analysis of Tweets across a variety of domains such as commerce (Jansen et al., 2009), health (Chew and Eysenbach, 2010; Salathe and Khandelwal, 2011) and disaster management (Mandel et al., 2012). Another aspect of social media data, such as twitter messages, is that they include rich information about the individuals involved in the communication. For e.g., twitter maintains information about who follows whom. ReTweets (reshares of a Tweet) and tags inside of Tweets provide discourse information (Nakov et al., 2013). </context>
</contexts>
<marker>Pak, Paroubek, 2010</marker>
<rawString>Alexander Pak and Patrick Paroubek. 2010. Twitter Based System: Using Twitter for Disambiguating Sentiment Ambiguous Adjectives. In Proceedings of the 5th International Workshop on Semantic Evaluation, SemEval 10, Los Angeles,USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcel Salathe</author>
<author>Shashank Khandelwal</author>
</authors>
<title>Assessing Vaccination Sentiments with Online Social Media: Implications for Infectious Disease Dynamics and Control.</title>
<date>2011</date>
<journal>PLoS Computational Biology,</journal>
<volume>7</volume>
<issue>10</issue>
<contexts>
<context position="3194" citStr="Salathe and Khandelwal, 2011" startWordPosition="478" endWordPosition="481">lexical and syntactic resources and/or tools, which are required for efficient processing of texts. These aspects also introduce complexities to build the state-of-theart data mining systems. In recent times, there has been a huge interest to mine and understand the opinions and sentiments that people are communicating in social media (Barbosa and Feng, 2010; Bifet et al., 2011; Pak and Paroubek, 2010; Kouloumpis et al., 2011). Recent studies show the interests in sentiment analysis of Tweets across a variety of domains such as commerce (Jansen et al., 2009), health (Chew and Eysenbach, 2010; Salathe and Khandelwal, 2011) and disaster management (Mandel et al., 2012). Another aspect of social media data, such as twitter messages, is that they include rich information about the individuals involved in the communication. For e.g., twitter maintains information about who follows whom. ReTweets (reshares of a Tweet) and tags inside of Tweets provide discourse information (Nakov et al., 2013). Efficient modelling of such information is crucial in the sense that it provides a mean to empirically study the social interactions where opinion is conveyed. Several corpora with detailed opinion and sentiment annotation ha</context>
</contexts>
<marker>Salathe, Khandelwal, 2011</marker>
<rawString>Marcel Salathe and Shashank Khandelwal. 2011. Assessing Vaccination Sentiments with Online Social Media: Implications for Infectious Disease Dynamics and Control. PLoS Computational Biology, 7(10):e14118+.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer-Verlag</publisher>
<location>New York,</location>
<contexts>
<context position="6194" citStr="Vapnik, 1995" startWordPosition="947" endWordPosition="948">word or phrase, the goal is to determine whether that instance is positive, negative or neutral in that context. In Subtask B, for a given message, the task is to classify whether the message is of positive, negative, or neutral sentiment. For messages that convey both positive and negative sentiments, the stronger one should be chosen. In this paper we report on our submissions as part of our first-time participation in this kind of task (i.e. sentiment classification). We develop the systems based on supervised machine learning algorithm, namely Support Vector Machine (SVM) (Joachims, 1999; Vapnik, 1995). We identify and implement a very small set of features that do not make use of any external resources and/or tools. For each task the system is tuned on the devel1http://alt.qcri.org/semeval2014/task9/ opment data, and finally blind evaluation is performed on the test data. 2 Methods We develop two systems, one for contextual polarity disambiguation and the other for message polarity classification. Each of the systems is based on supervised machine learning algorithm, namely SVM. Support vector machines (Joachims, 1999; Vapnik, 1995) have been shown to be highly effective at traditional tex</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>Vladimir N. Vapnik. 1995. The Nature of Statistical Learning Theory. Springer-Verlag New York, Inc., New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julio Villena-Roman</author>
<author>Sara Lana-Serrano</author>
<author>Eugenio Martnez-Camara</author>
<author>Jose Carlos Gonzalez</author>
<author>Cristobal</author>
</authors>
<title>Tass - Workshop on Sentiment Analysis at SEPLN.</title>
<date>2013</date>
<booktitle>In Proceedings of Procesamiento del Lenguaje Natural,</booktitle>
<pages>50--37</pages>
<contexts>
<context position="4110" citStr="Villena-Roman et al., 2013" startWordPosition="619" endWordPosition="622"> Tweet) and tags inside of Tweets provide discourse information (Nakov et al., 2013). Efficient modelling of such information is crucial in the sense that it provides a mean to empirically study the social interactions where opinion is conveyed. Several corpora with detailed opinion and sentiment annotation have been made freely available, 324 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 324–328, Dublin, Ireland, August 23-24, 2014. e.g., the MPQA corpus (Barbosa and Feng, 2005) of newswire text; i-sieve (Kouloumpis et al., 2011) and TASS corpus2 (Villena-Roman et al., 2013) for Twitter sentiment. These resources were either in non-social media or they were small and proprietary. They further focused on message-level sentiment. The SemEval-2013 shared task (Nakov et al., 2013) on sentiment analysis in Twitter releases SemEval Tweet corpus, which contains Tweets and SMS messages with sentiment expressions annotated with contextual phrase-level polarity as well as an overall message-level polarity. Among the 44 submissions, the highest-performing system (Mohammad et al., 2013) made use of Support Vector Machine (SVM) classifier. It obtained the F-scores of 69.02% i</context>
</contexts>
<marker>Villena-Roman, Lana-Serrano, Martnez-Camara, Gonzalez, Cristobal, 2013</marker>
<rawString>Julio Villena-Roman, Sara Lana-Serrano, Eugenio Martnez-Camara, Jose Carlos Gonzalez, and Cristobal. 2013. Tass - Workshop on Sentiment Analysis at SEPLN. In Proceedings of Procesamiento del Lenguaje Natural, pages 50:37–44.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>