<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000038">
<title confidence="0.933698">
FUNCTIONAL UNIFICATION GRAMMAR:
A FORMALISM FOR MACHINE TRANSLATION
</title>
<author confidence="0.995127">
Martin Kay
</author>
<affiliation confidence="0.6006135">
Xerox Palo Alto Research Center
3333 Coyote Hill Road
Palo Alto
California 94304
</affiliation>
<keyword confidence="0.6795035">
and
CSLI, Stanford
</keyword>
<sectionHeader confidence="0.952587" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997439">
Functional Unification Grammar provides an opportunity
to encompass within one formalism and computational system
the parts of machine translation systems that have usually been
treated separately, natably analysis, transfer, and synthesis.
Many of the advantages of this formalism come from the fact
that it is monotonic allowing data structures to grow differently
as different nondeterministic alternatives in a computation are
pursued, but never to be modified in any way. A striking feature
of this system is that it is fundamental reversible, allowing a to
translate as b only if b could translate as a.
</bodyText>
<sectionHeader confidence="0.867312" genericHeader="method">
I Overview
</sectionHeader>
<subsectionHeader confidence="0.513015">
A. Machine Translation
</subsectionHeader>
<bodyText confidence="0.99854534883721">
A classical translating machine stands with one foot on the
input text and one on the output. The input text is analyzed by
the components of the machine that make up the left leg, each one
feeding information into the one above it. Information is passed
from component to component down the right leg to construct
the output text. The components of each leg correspond to the
chapters of an introductory textbook on linguistics with phonology
or graphology at the bottom, then syntax, semantics, and so on.
The legs join where languages are no longer differentiated and
linguistics shades off into psychology and philosophy. The higher
levels are also the ones whose theoretical underpinnings are less
well known and system designers therefore often tie the legs
together somewhere lower down, constructing a more or less ad
hoc bridge, pivot, or transfer component.
We connot be sure that the classical design is the right
design, or the best design, for a translating machine. But it does
have several strong points. Since the structure of the components
is grounded in linguistic theory, it is possible to divide each of
these components into two parts: a formal description of the
relevant facts about the language, and an interpreter of the
formalism. The formal description is data whereas the interpreter
is program. The formal description should ideally serve the needs
of synthesis and analysis indifferently. On the other hand we
would expect different interpreters to be required in the two legs
of the machine. We expect to be able to use identical interpreters
in corresponding places in all machines of similar design because
the information they embody comes from general lingusitic theory
and not from particular languages. The scheme therefore has
the advantage of modularity. The linguistic descriptions are
independent of the leg of the machine they are used in and the
programs are independent of the languages to which they are
applied.
For all the advantgages of the classical design, it is not
hard to imagine improvements. In the best all possible worlds,
there would only be one formalism in which all the facts about a
language—morphological, syntactic, semantic, or whatever—could
he stated. A formalism powerful enough to accommodate the
various different kinds of linguistic phenomena with equal facility
might be unappealing to theoretical linguists because powerful
formal systems do not make powerful claims. But the engineering
advantages are clear to see. A single formalism would straightfor-
wardly reduce the number of interpreters to two, one for analysis
and one for synthesis. Furthermore, the explanatory value of a
theory clearly rests on a great deal more than the restriciveness of
its formal base. In particular, the possiblity of encompassing what
had hitherto been thought to require altogether different kinds of
treatment within a single framework could be theoretically inter-
esting.
Another clear improvement on the classical design would
&apos;result from merging •the two interpreters associated with a for-
malism. The most obvious advantage to be hoped for with
this move would be that the overall structure of the translating
machine would be greatly simplified, though this would not neces-
sarily happen. It is also reasonable to hope that the machine would
be more robust, easier to modify and maintain, and altogether
more perspicuous. This is because a device to which analysis and
synthesis look essentially the same is one that is fundamentally
less time dependent, with fewer internal variables and states; it
is apt to work by monitoring constraints laid down in the formal
description and ensuring that they are maintained, rather than
carrying out long and complex sequences of steps in a carefully
prescribed order. •
These advantages are available in large measure through
a class of formal devices that are slowly gaining acceptance in
linguistics and which are based on the relations contracted by
formal objects rather than by transformations of one formal object
into another. These systems are all procedurally monotonic in the
sense that, while new information may be added to existing data
structures, possibly different information on different branches of
a nondeterministic process, nothing is ever deleted or changed.
As a result, the particular order in which elementary events take
place is of little importance. Lexical Functional Grammar and
Generalized Phrase-Structure grammar share these relational and
monotonic properties. They are also characteristics of Functional
Unificational Grammar (FUG) which I believe also has additional
properties that suit it particularly well to the needs of experimen-
tal machine-translation systems.
The term experimental must be taken quite seriously here
though, if my view of machine translation were more generally
held, it would be redundant. I believe that all machine translation
of natural languages is experimental and that he who claims
otherwise does his more serious colleagues a serious disservice. I
should not wish any thing that I say in this paper as a claim to
have solved any of the miriad problems that stand between us and
working machine translation systems worthy of the name. The
contribution that FUG might make is, I believe, a great deal more
</bodyText>
<page confidence="0.997857">
75
</page>
<bodyText confidence="0.997367166666667">
conjuncts from disjuncts by the kinds of brackets used to enclose
their members; the conjuncts and disjuncts of a = p, b = q, and
c = r are written
modest, namely to reformalize more simply and perspicuously
what has been done before and which has come to be regarded, as
I said at the outset &amp;quot;classical&amp;quot;.
</bodyText>
<subsectionHeader confidence="0.515586">
B. Functional Unification Grammar
</subsectionHeader>
<bodyText confidence="0.994826195652174">
FUG traffics in descriptions and there is essentially only one
kind of description, whether for lexical items, phrases, sentences,
or entire languages. Descriptions do not distinguish among levels
in the linguistic hierarchy. This is not to say that the distinctions
among the levels are unreal or that a linguist working with
the formalism whould not respect them. It means only that the
notation and its interpretation are always uniform. Either a pair
of descriptions is incompatible or they are combinable into a single
description.
Within FUG, every object has infinitely many descriptions,
though a given grammar partitions the descriptions of the words
and phrases in its language into a finite number of equivalence
classes, one for each interpretation that the grammar assigns to it.
The members of an equivalence class differ along dimensions that
are grammatically irrelevant—when they were uttered, whether
they ammused Queen Victoria, or whether they contain a prime
number of words. Each equivalence class constitutes a lattice
with just one member that contains none of these grammatically
irrelevant properties, and this canonical member is the only one
a linguist would normally concern himself with. However, a
grammatical irrelevancy that acquires relevance in the present
context is the description of possible translations of a word or
phrase, or of one of its interpretations, in one or more other
languages.
A description is an expression over an essentially arbitrary
basic vocabulary. The relations among sets of descriptions there-
fore remain unchanged under one-for-one mappings of their basic
vocabularies. It is therefore possible to arrange that different
grammars share no terms except for possible quotations from
the languages described. Canonical descriptions of a pair of
sentences in different languages according to grammars that
shared no terms could always be unified into a single descrip-
tion which would, of course, not be canonical. Since all pairs
are unifiable, the relation that they establish between sentences
is entriely arbitrary. However, a third grammar can be written
that unifies with these combined descriptions only if the sentences
they describe in the two langauages stand in a certain relation
to one another. The relation we are interested in is, of course,
the translation relation which, for the purposes of the kind of
experimantal system I have in mind I take to be definable even
for isolated sentences. Such a transfer grammar can readily cap-
ture all the components of the translation relation that have in
fact been built into translation systems: correspondences between
words and continuous or discontinuous phrases, use of selectional
features or local contexts, case frames, reordering rules, lexical
functions, compositional semantics, and so on.
</bodyText>
<sectionHeader confidence="0.955746" genericHeader="method">
II The Formalism
</sectionHeader>
<subsectionHeader confidence="0.912526">
A. Functional Descriptions
</subsectionHeader>
<bodyText confidence="0.999954272727273">
In &apos;FUG, linguistic objects are represented by functional
descriptions (FDs). The basic constituent of a functional descrip-
tion is a feature consisting of an attribute and an associated value.
We write features in the form a = v, where a is the attribute and
v, the value. Attributes are arbitrary words with no significant
internal structure. Values can be of various types, the simplest of
which is an atomic value, also an arbitrary word. So Cat = S is
a feature of the most elementary type. It appears in the descrip-
tions of sentences, and which declares that their Category is S.
The only kinds of non-atomic values that will concern us here are
constituent sets, patterns and FDs themselves.
</bodyText>
<equation confidence="0.7792122">
A FD is a Boolean expression over features. We distinguish
{a P a= P
qi and lb —
bq}
c = q c = r
</equation>
<bodyText confidence="0.999855">
respectively. The vertical arrangement of these expressions has
proved convenient and it is of minor importance in that braces
of the ordinary variety are used for a different purpose in FUG,
namely to enclose the members of consituent sets. The following
FD describes all sentences whose subject is a singular noun phrase
in the nominative or accusative cases
</bodyText>
<equation confidence="0.968967333333333">
Cat =-- S
Cat = NP
(1) Subj = Num = Sing
</equation>
<bodyText confidence="0.997927717391305">
It is a crucial property of FDs that no attribute should figure
more than once in any conjunct, though a given attribute may
appear in feature lists that are themselves the values of different
attributes. This being the case, it is always possible to identify
a given conjunct or disjunct in a FD by giving a sequence of
attributes (al. • •ak). al is a attribute in the FD whose value,
v1, is another FD. The attribute a2 is an attribute in vi whose
value if an FD, and so on. Sequences of attributes of this kind are
referred to as paths. If the FD contains disjuncts, then the value
identified by the path will naturally also be a disjunct.
We sometimes write a path as the value of an attribute to
indicate that that value of that attribute is not only eaqual to
the value identified by the path but that these values are one
and the same, inshort, that they are unified in a sense soon to
be explained. Roughly, if more information were acquired about
one of the values so that more features were added to it, the same
additions would be reflected in the other value. This would not
automatically happen because a pair of values happened to be the
, same. So, for example, if the topic of the sentence were also its
object, we might write
[Object = v
Topic = (Object)]
where v is some FD.
Constituent sets are sets of paths identifying within a given
FD the descriptions of its constituents in the sense of phrase-
structure grammar. No constituent set is specified in example (I)
above and the question of whether the subject is a constituent is
therefore left open.
Example (2), though still artificially simple, is more realis-
tic. It is a syntactic description of the sentence John knows Mary.
Perhaps the most striking property of this description is that
descriptions of constituents are embedded one inside another, even
though the constituents themselves are not so embedded. The
value of the Head attribute describes a constituent of the sentence,
a fact which is declared in the value of the CSet attribute. We also
see that the sentence has a second attribute whose decription is
to be found as the value of the Subject of the Head of the Head of
the sentence. The reason for this arrangement will become clear
shortly.
In example (2), every conjunct in which the CSet attribute
has a value other than NONE also has a substantive value for the
attribute Pat. The value of this attribute is a regular expression
over paths which restricts the order in which the constituents must
appear. By convention, if no pattern is given for a description
which nevertheless does have constituents, they may occur in any
order. We shall have more to say about patterns in due course.
</bodyText>
<figure confidence="0.77872325">
{Case = Noml
Case = Acc j
76
B. Unification
</figure>
<bodyText confidence="0.995013617647059">
Essentially the only operation used in processing FUG is that
of Unification, the paradigm example of a monotonic operation.
Given a pair of descriptions, the unification process first deter-
mines whether they are compatible in the sense of allowing the
possibility of there being some object that is in the extension of
both of them. This possibility would be excluded if there were a
path in one of the two descriptions that lead to an atomic value
while the same path in the other one lead to some other value.
This would occur if, for example, one described a sentence with a
singular subject and the other a sentence with a plural subject, or
if one described a sentence and the other a noun phrase. There can
also be incompatibilities in respect of other kinds of value. Thus,
if one has a pattern requiring the subject to precede the main verb
whereas the other specifies the other order, the two descriptions
will be incompatible. Constituent sets are incompatible if they
are not the same.
We have briefly considered how three different types of descrip-
tion behave under unification. Implicit in what we have said is
that descriptions of different types do not unify with one another.
Grammars, which are the descriptions of the infinite sets of sen-
tences that make up a language constitute a type of description
that is structurally identical an ordinary FD but is distinguished
on the grounds that it behaves slightly differently under unifica-
tion. In particular, it is possible to unify a grammar with another
grammar to produce a new grammar, but it is also possible to
unify a grammar with a FD, in which case the result is a new
FD. The rules for unifying grammars with grammars are the
same as those for unifying FDs with FDs. The rules for unify-
ing grammars with FDs, however, are slightly different and in
the difference lies the ability of FUG to describe structures recur-
sively and hence to provide for sentences of unbounded size. The
rule for unifying grammars with FDs requires the grammars to
be unified—following the rules for FD unification—with each in-
dividual constituent of the FD.
</bodyText>
<equation confidence="0.998225363636364">
([Head = [Head = [Cat = Nr]] 1
CSet = {(Head Head Subj)(Head))
Pat = ((Head Head Subj)(Head))
Cat = V
{Head = [{Obj = NONE 1
Obj -= &apos;Cat = NPD
CSet = NONE
[Head
[Cat = N 11
=
CSet = NONE]]
</equation>
<bodyText confidence="0.999339448275862">
By way of illustration, consider the grammar in (3). Like
most grammars, it is a disjunction of clauses, one for each (non-
terminal) category or constituent type in the language. The
first of the three clauses in the principle dirjunction describes
sentences as having a head whose head is of category V. This
characterization is in line with so called X-theory, according to
which a sentence belongs to the category V. In general, a phrase
of category X, for whatever X, has a head constituent of category
X, that is, a category with the same name but one less bar. X
is built into the very fabric of the version of FUG illutrated here
where, for example, a setence is by definition a phrase whose
head&apos;s head is a verb. The head of a sentence is a V, that is,
a phrase whose head is of category V and which has no head
of its own. A phrase with this description cannot unify with
the first clause in the grammar because its head has the feature
[Head = NONE].
Of sentences, the grammar says that they have two con-
stituents. It is no surprise that the second of these is its head.
The first would usually be called its subject but is here charac-
terized as the subject of its verb. This does not imply that there
must be lexical entries not only for all the verbs in the language
but that there must be such an entry for each of the subjects that
the verb might have. What it does mean is that the subject must
be unifiable with any description the verb gives of its subject and
thus provides automatically both for any selectional restrictions
that a verb might place on its subject but also for agreement in
person and number between subject and verb. Objects are handled
in an analogous manner. Thus, the lexical entries for the French
verb forms connait and sait might be as follows:
</bodyText>
<equation confidence="0.998117">
Cat = V
Lex = connaitre
Tense = Pres
Pers = 3
Subj = Num = Sing
Anim = +
I
</equation>
<bodyText confidence="0.9020904">
Obj = [Cat = NP]
Each requires its subject to be third person, singular and animate.
Taking a rather simplistic view of the difference between these
verbs for the sake of the example, this lexicon states that connatt
takes noun phrases as objects, whereas sait takes sentences.
</bodyText>
<sectionHeader confidence="0.921769" genericHeader="method">
III Translation
</sectionHeader>
<subsectionHeader confidence="0.981251">
A. Syntax
</subsectionHeader>
<bodyText confidence="0.999975928571429">
Consider now the French sentence Jean connatt Marie which
is presumably a reasonable rendering of the English sentence
John knows Mary, a possible fumctional description of which
we was given in (2). I take it that the French sentence has
an essentially isomorphic structure. In fact, following the plan
laid out at the beginning of the paper, let us assume that the
functional description of the French sentence is that given in (2)
with obvious replacements for the values of the Lex attribute and
with attribute names x, in the English grammar systematically
replaced by F-x, in the French. Thus we have F-Cat, F-Head, etc.
Suppose now, that, using the English grammar and a suitable
parsing algorithm, the structure given in (2) is derived from the
English sentence, and that this description is then unified with
the following transfer grammar:
</bodyText>
<equation confidence="0.992895444444444">
Cat = (F-Cat)
[L-ex =x _ John
F Jean
Lex
7= Ma
[F&apos;-Lex =MrYariel
Lex = know
F-Lex = connaltrell
IF-Lex = savoir
</equation>
<bodyText confidence="0.997126588235294">
The first clause of the principal conjunct states a very strong
requirement, namely that the description of a phrase in one of
the two languages should be a description of a phrase of the
same category in the other language. The disjunct that follows
is essentially a bilingual lexicon that requires the description of
a lexical item in one language to be a description of that word&apos;s
counterpart in the other language. It allows the English verb
know to be set in correspondence with either connattre or savoir
and gives no means by which to distinguish them. In the simple
example we are developing, the choice will be determined on the
basis of criteria expressed only in the French grammar, namely
whether the object is a noun phrase or a sentence.
This is about as trivial a transfer grammar as one could
readily imagine writing. It profits to the minimal possible extent
from the power of FUG. Nevertheless, it should already do better
than word-for-word translation because the transfer grammar says
nothing at all about the order of the words or phrases. If the
</bodyText>
<equation confidence="0.585254375">
(3)
Cat = V
Lex = savoir
Tense = Pres
Pers = 3
Subj = Num = Sing
Anim = +
Obj = [Cat = S]
</equation>
<page confidence="0.9924">
77
</page>
<bodyText confidence="0.999807571428571">
English grammar states that pronominal objects follow the verb
and the French one says that they precede, the same transfer
grammar, though still without any explicit mention of order,
will cause the appropriate &amp;quot;reordering&amp;quot; to take place. Similarly,
nothing more would be required in the transfer grammar in order
to place adjectives properly with respect to the nouns they modify,
and so forth.
</bodyText>
<subsectionHeader confidence="0.780317">
B. Semantics
</subsectionHeader>
<bodyText confidence="0.998674142857143">
It may be objected to the line of argument that I have been
persuing that it requires the legs of the translating machine to be
tied together at too lower a level, essentially at the level of syntax.
To be sure, it allows more elaborate transfer grammars than the
one just illustrated so that the translation of a sentence would
not have to be structurally isomorphic with its source, modulo
ordering. But the device is essentially syntactic. However, the
relations that can be characterized by FUG and similar monotonic
devices are in fact a great deal more diverse than this suggests. In
particular, much of what falls under the umbrella of semantics in
modern linguistics also fits conveniently within this framework.
Something of the flavor of this can be captured from the following
example. Suppose that the lexical entries for the words all and
dogs are as follows:
</bodyText>
<equation confidence="0.912007916666667">
-
Cat =-- Det
Lex = all
Num = Plur
Def = +
I.
Sense =
Cat = N
Lex = dog
Art = [Num = Plur
Sense = (Sense)
Sense = [Prop = ri
</equation>
<bodyText confidence="0.97865575">
= [Type = Fred]]]Pred = dog
When the first of these is unified with the value of the Art
attribute in the second as required by the grammar, the result is
as follows:
</bodyText>
<equation confidence="0.995878230769231">
-Cat = N
Lex = dog
Cat = Det
Lex = All
Art= Def =+
Num = Plur
_Sense = (Sense)
Type = All
Type = Implies
Type = Pred
Pred = dog
Arg = (Sense Var)
P2 = Arg = (Sense Var)1
</equation>
<bodyText confidence="0.917404">
This, in turn, is readily interpretable as a description of the logical
expression
</bodyText>
<equation confidence="0.471755">
Vq.dog(q)AP(g)
</equation>
<bodyText confidence="0.999806">
It remains to provide verbs with a sense that provides a suitable
value for P, that is, for (Sense Prop P2 Pred). An example would
be the following:
</bodyText>
<equation confidence="0.9777585">
Cat = V
Lex = barks
Tense = Pres
Pers = 3
Subj = {Num = Sing
Anim = +
Obj = NONE
Sense = [Prop=--- [P2 = [Fred = bark]]]
</equation>
<sectionHeader confidence="0.73298" genericHeader="method">
IV Conclusion
</sectionHeader>
<bodyText confidence="0.9999729375">
It has not been possible in this paper to give more than an
impression of how an experimental machine translation system
might be constructed based on FUG. I hope, however, that it
has been possible to convey something of the value of monotonic
systems for this purpose. Implementing FUG in an efficient way
requires skill and a variety of little known techniques. However,
the programs, though subtle, are not large and, once written,
they provide the grammarian and lexicographer with an emmense
wealth of expressive devices. Any system implemented strictly
within this framework will be reversible in the sense that, if it
translates from language A to language B the, to the same extent,
it translates from B to A. If the set S is among the translations
it delivers for a, then a will be among the translations of each
member of S. I know of no system that comes close to providing
these advantages and I know of no facility provided for in any
system proposed hitherto that it not subsumable under FUG
</bodyText>
<equation confidence="0.9740064">
Type = all
Type = Implies
Prop = [1&apos;1 = [Arg = (Sense Var)11I
P2= Arg = (Sense Var)]
Sense = Prop = IP1 =
</equation>
<page confidence="0.990274">
78
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.999604">FUNCTIONAL UNIFICATION GRAMMAR: A FORMALISM FOR MACHINE TRANSLATION</title>
<author confidence="0.999972">Martin Kay</author>
<affiliation confidence="0.997711">Xerox Palo Alto Research Center</affiliation>
<address confidence="0.858023666666667">3333 Coyote Hill Road Palo Alto California 94304</address>
<affiliation confidence="0.548908">and</affiliation>
<address confidence="0.635887">CSLI, Stanford</address>
<abstract confidence="0.991546813688212">Functional Unification Grammar provides an opportunity to encompass within one formalism and computational system the parts of machine translation systems that have usually been treated separately, natably analysis, transfer, and synthesis. Many of the advantages of this formalism come from the fact that it is monotonic allowing data structures to grow differently as different nondeterministic alternatives in a computation are pursued, but never to be modified in any way. A striking feature of this system is that it is fundamental reversible, allowing a to as if translate as I Overview A. Machine Translation A classical translating machine stands with one foot on the input text and one on the output. The input text is analyzed by the components of the machine that make up the left leg, each one feeding information into the one above it. Information is passed from component to component down the right leg to construct the output text. The components of each leg correspond to the chapters of an introductory textbook on linguistics with phonology or graphology at the bottom, then syntax, semantics, and so on. The legs join where languages are no longer differentiated and linguistics shades off into psychology and philosophy. The higher levels are also the ones whose theoretical underpinnings are less well known and system designers therefore often tie the legs together somewhere lower down, constructing a more or less ad pivot, or transfer component. We connot be sure that the classical design is the right design, or the best design, for a translating machine. But it does have several strong points. Since the structure of the components is grounded in linguistic theory, it is possible to divide each of these components into two parts: a formal description of the relevant facts about the language, and an interpreter of the formalism. The formal description is data whereas the interpreter is program. The formal description should ideally serve the needs of synthesis and analysis indifferently. On the other hand we would expect different interpreters to be required in the two legs of the machine. We expect to be able to use identical interpreters in corresponding places in all machines of similar design because the information they embody comes from general lingusitic theory and not from particular languages. The scheme therefore has the advantage of modularity. The linguistic descriptions are independent of the leg of the machine they are used in and the programs are independent of the languages to which they are applied. For all the advantgages of the classical design, it is not hard to imagine improvements. In the best all possible worlds, there would only be one formalism in which all the facts about a language—morphological, syntactic, semantic, or whatever—could he stated. A formalism powerful enough to accommodate the various different kinds of linguistic phenomena with equal facility might be unappealing to theoretical linguists because powerful formal systems do not make powerful claims. But the engineering advantages are clear to see. A single formalism would straightforwardly reduce the number of interpreters to two, one for analysis and one for synthesis. Furthermore, the explanatory value of a theory clearly rests on a great deal more than the restriciveness of its formal base. In particular, the possiblity of encompassing what had hitherto been thought to require altogether different kinds of treatment within a single framework could be theoretically interesting. Another clear improvement on the classical design would &apos;result from merging •the two interpreters associated with a formalism. The most obvious advantage to be hoped for with this move would be that the overall structure of the translating would be greatly simplified, though this would not neces- It is also reasonable to hope that the machine would be more robust, easier to modify and maintain, and altogether more perspicuous. This is because a device to which analysis and synthesis look essentially the same is one that is fundamentally less time dependent, with fewer internal variables and states; it is apt to work by monitoring constraints laid down in the formal description and ensuring that they are maintained, rather than carrying out long and complex sequences of steps in a carefully prescribed order. • These advantages are available in large measure through a class of formal devices that are slowly gaining acceptance in linguistics and which are based on the relations contracted by formal objects rather than by transformations of one formal object another. These systems are all procedurally the sense that, while new information may be added to existing data structures, possibly different information on different branches of a nondeterministic process, nothing is ever deleted or changed. As a result, the particular order in which elementary events take place is of little importance. Lexical Functional Grammar and Generalized Phrase-Structure grammar share these relational and monotonic properties. They are also characteristics of Functional Unificational Grammar (FUG) which I believe also has additional properties that suit it particularly well to the needs of experimental machine-translation systems. term be taken quite seriously here though, if my view of machine translation were more generally it would be redundant. that all machine translation of natural languages is experimental and that he who claims otherwise does his more serious colleagues a serious disservice. I should not wish any thing that I say in this paper as a claim to have solved any of the miriad problems that stand between us and machine translation systems worthy of the name. contribution that FUG might make is, I believe, a great deal more 75 conjuncts from disjuncts by the kinds of brackets used to enclose members; the conjuncts and disjuncts of a = b = q, r are written modest, namely to reformalize more simply and perspicuously what has been done before and which has come to be regarded, as I said at the outset &amp;quot;classical&amp;quot;. Functional Unification FUG traffics in descriptions and there is essentially only one kind of description, whether for lexical items, phrases, sentences, or entire languages. Descriptions do not distinguish among levels in the linguistic hierarchy. This is not to say that the distinctions among the levels are unreal or that a linguist working with the formalism whould not respect them. It means only that the notation and its interpretation are always uniform. Either a pair of descriptions is incompatible or they are combinable into a single description. Within FUG, every object has infinitely many descriptions, though a given grammar partitions the descriptions of the words and phrases in its language into a finite number of equivalence classes, one for each interpretation that the grammar assigns to it. The members of an equivalence class differ along dimensions that are grammatically irrelevant—when they were uttered, whether they ammused Queen Victoria, or whether they contain a prime number of words. Each equivalence class constitutes a lattice with just one member that contains none of these grammatically properties, and this is the only one a linguist would normally concern himself with. However, a grammatical irrelevancy that acquires relevance in the present context is the description of possible translations of a word or phrase, or of one of its interpretations, in one or more other languages. A description is an expression over an essentially arbitrary basic vocabulary. The relations among sets of descriptions therefore remain unchanged under one-for-one mappings of their basic vocabularies. It is therefore possible to arrange that different grammars share no terms except for possible quotations from the languages described. Canonical descriptions of a pair of in different languages according to grammars shared no terms could always be unified into a single description which would, of course, not be canonical. Since all pairs are unifiable, the relation that they establish between sentences is entriely arbitrary. However, a third grammar can be written that unifies with these combined descriptions only if the sentences they describe in the two langauages stand in a certain relation to one another. The relation we are interested in is, of course, the translation relation which, for the purposes of the kind of experimantal system I have in mind I take to be definable even isolated sentences. Such a can readily capture all the components of the translation relation that have in fact been built into translation systems: correspondences between and continuous or discontinuous phrases, use of local contexts, case frames, reordering rules, lexical functions, compositional semantics, and so on. II The Formalism A. Functional Descriptions &apos;FUG, objects are represented by The basic constituent of a functional descripis a of an associated We write features in the form a = v, where a is the attribute and value. Attributes are arbitrary words with no significant internal structure. Values can be of various types, the simplest of is an value, an arbitrary word. So = S is a feature of the most elementary type. It appears in the descripof sentences, and which declares that their is S. The only kinds of non-atomic values that will concern us here are sets, patterns FDs themselves. A FD is a Boolean expression over features. We distinguish P a= P qi and lb — c = r respectively. The vertical arrangement of these expressions has proved convenient and it is of minor importance in that braces of the ordinary variety are used for a different purpose in FUG, namely to enclose the members of consituent sets. The following FD describes all sentences whose subject is a singular noun phrase in the nominative or accusative cases Cat =-- S Cat = NP Subj = = Sing It is a crucial property of FDs that no attribute should figure more than once in any conjunct, though a given attribute may appear in feature lists that are themselves the values of different attributes. This being the case, it is always possible to identify a given conjunct or disjunct in a FD by giving a sequence of (al. • •ak). is a attribute in the FD whose value, another FD. The attribute a2 is an attribute in whose value if an FD, and so on. Sequences of attributes of this kind are to as the FD contains disjuncts, then the value identified by the path will naturally also be a disjunct. We sometimes write a path as the value of an attribute to indicate that that value of that attribute is not only eaqual to the value identified by the path but that these values are one the same, inshort, that they are a sense soon to be explained. Roughly, if more information were acquired about one of the values so that more features were added to it, the same additions would be reflected in the other value. This would not automatically happen because a pair of values happened to be the , same. So, for example, if the topic of the sentence were also its object, we might write = v = is FD. Constituent sets are sets of paths identifying within a given FD the descriptions of its constituents in the sense of phrasestructure grammar. No constituent set is specified in example (I) above and the question of whether the subject is a constituent is therefore left open. Example (2), though still artificially simple, is more realis- It is a syntactic description of the sentence knows Mary. Perhaps the most striking property of this description is that descriptions of constituents are embedded one inside another, even though the constituents themselves are not so embedded. The of the describes a constituent of the sentence, fact which is declared in the value of the We also see that the sentence has a second attribute whose decription is to be found as the value of the Subject of the Head of the Head of the sentence. The reason for this arrangement will become clear shortly. example (2), every conjunct in which the a value other than has a substantive value for the value of this attribute is a regular expression over paths which restricts the order in which the constituents must appear. By convention, if no pattern is given for a description which nevertheless does have constituents, they may occur in any order. We shall have more to say about patterns in due course. = Noml Case = Acc j 76 B. Unification Essentially the only operation used in processing FUG is that paradigm example of a monotonic operation. Given a pair of descriptions, the unification process first determines whether they are compatible in the sense of allowing the possibility of there being some object that is in the extension of both of them. This possibility would be excluded if there were a path in one of the two descriptions that lead to an atomic value while the same path in the other one lead to some other value. This would occur if, for example, one described a sentence with a singular subject and the other a sentence with a plural subject, or if one described a sentence and the other a noun phrase. There can also be incompatibilities in respect of other kinds of value. Thus, if one has a pattern requiring the subject to precede the main verb whereas the other specifies the other order, the two descriptions will be incompatible. Constituent sets are incompatible if they are not the same. We have briefly considered how three different types of description behave under unification. Implicit in what we have said is that descriptions of different types do not unify with one another. Grammars, which are the descriptions of the infinite sets of sentences that make up a language constitute a type of description that is structurally identical an ordinary FD but is distinguished on the grounds that it behaves slightly differently under unification. In particular, it is possible to unify a grammar with another grammar to produce a new grammar, but it is also possible to unify a grammar with a FD, in which case the result is a new FD. The rules for unifying grammars with grammars are the same as those for unifying FDs with FDs. The rules for unifying grammars with FDs, however, are slightly different and in the difference lies the ability of FUG to describe structures recursively and hence to provide for sentences of unbounded size. The rule for unifying grammars with FDs requires the grammars to unified—following the rules for FD unification—with inof the FD.</abstract>
<note confidence="0.41839">Head = [Cat = Nr]] 1</note>
<title confidence="0.631250333333333">CSet = {(Head Head Subj)(Head)) Pat = ((Head Head Subj)(Head)) Cat = V = = NONE 1 Obj -= &apos;Cat = NPD CSet = NONE</title>
<abstract confidence="0.882373727272728">N 11 = = NONE]] By way of illustration, consider the grammar in (3). Like most grammars, it is a disjunction of clauses, one for each (nonterminal) category or constituent type in the language. The first of the three clauses in the principle dirjunction describes sentences as having a head whose head is of category V. This characterization is in line with so called X-theory, according to which a sentence belongs to the category V. In general, a phrase category whatever a of category is, a category with the same name but one less bar. is built into the very fabric of the version of FUG illutrated here where, for example, a setence is by definition a phrase whose head&apos;s head is a verb. The head of a sentence is a V, that is, a phrase whose head is of category V and which has no head of its own. A phrase with this description cannot unify with the first clause in the grammar because its head has the feature [Head = NONE]. Of sentences, the grammar says that they have two constituents. It is no surprise that the second of these is its head. The first would usually be called its subject but is here characterized as the subject of its verb. This does not imply that there must be lexical entries not only for all the verbs in the language but that there must be such an entry for each of the subjects that the verb might have. What it does mean is that the subject must be unifiable with any description the verb gives of its subject and thus provides automatically both for any selectional restrictions that a verb might place on its subject but also for agreement in person and number between subject and verb. Objects are handled in an analogous manner. Thus, the lexical entries for the French forms be as follows: Cat = V Lex = connaitre Tense = Pres Pers = 3 Subj = Num = Sing Anim = + I Obj = [Cat = NP] Each requires its subject to be third person, singular and animate. Taking a rather simplistic view of the difference between these for the sake of the example, this lexicon states that noun phrases as objects, whereas sentences.</abstract>
<title confidence="0.790758">III Translation</title>
<author confidence="0.770975">A Syntax</author>
<abstract confidence="0.939115058823529">now the French sentence connatt Marie is presumably a reasonable rendering of the English sentence knows Mary, possible fumctional description of which we was given in (2). I take it that the French sentence has an essentially isomorphic structure. In fact, following the plan laid out at the beginning of the paper, let us assume that the functional description of the French sentence is that given in (2) obvious replacements for the values of the attribute names the English grammar systematically by the French. Thus we have F-Head, etc. Suppose now, that, using the English grammar and a suitable parsing algorithm, the structure given in (2) is derived from the English sentence, and that this description is then unified with following Cat = (F-Cat) _ John F Jean Lex Ma Lex = know F-Lex = connaltrell IF-Lex = savoir The first clause of the principal conjunct states a very strong requirement, namely that the description of a phrase in one of the two languages should be a description of a phrase of the same category in the other language. The disjunct that follows is essentially a bilingual lexicon that requires the description of a lexical item in one language to be a description of that word&apos;s counterpart in the other language. It allows the English verb be set in correspondence with either and gives no means by which to distinguish them. In the simple example we are developing, the choice will be determined on the basis of criteria expressed only in the French grammar, namely whether the object is a noun phrase or a sentence. This is about as trivial a transfer grammar as one could readily imagine writing. It profits to the minimal possible extent from the power of FUG. Nevertheless, it should already do better than word-for-word translation because the transfer grammar says nothing at all about the order of the words or phrases. If the Cat = V Lex = savoir Tense = Pres Pers = 3 Subj = Num = Sing Anim = + Obj = [Cat = S] 77 English grammar states that pronominal objects follow the verb and the French one says that they precede, the same transfer grammar, though still without any explicit mention of order, will cause the appropriate &amp;quot;reordering&amp;quot; to take place. Similarly, nothing more would be required in the transfer grammar in order to place adjectives properly with respect to the nouns they modify, and so forth. It may be objected to the line of argument that I have been persuing that it requires the legs of the translating machine to be tied together at too lower a level, essentially at the level of syntax. To be sure, it allows more elaborate transfer grammars than the one just illustrated so that the translation of a sentence would have to be structurally isomorphic with its source, ordering. But the device is essentially syntactic. However, the relations that can be characterized by FUG and similar monotonic devices are in fact a great deal more diverse than this suggests. In particular, much of what falls under the umbrella of semantics in modern linguistics also fits conveniently within this framework. Something of the flavor of this can be captured from the following Suppose that the lexical entries for the words are follows:</abstract>
<title confidence="0.80323625">Cat =-- Det Lex = all Num = Plur Def = + Sense = Cat = N Lex = dog</title>
<author confidence="0.803192">Art</author>
<abstract confidence="0.743489333333333">Sense = (Sense) Sense = [Prop = ri [Type = = dog the first of these is unified with the value of the attribute in the second as required by the grammar, the result is as follows:</abstract>
<title confidence="0.807213636363636">N Lex = dog Cat = Det Lex = All Art= Def =+ Num = Plur _Sense = (Sense) Type = All Type = Implies Type = Pred Pred = dog</title>
<abstract confidence="0.7505715">Arg = (Sense Var) P2 = Arg = (Sense Var)1 This, in turn, is readily interpretable as a description of the logical expression Vq.dog(q)AP(g) It remains to provide verbs with a sense that provides a suitable for is, for (Sense Prop P2 Pred). An example would be the following: Cat = V Lex = barks Tense = Pres Pers = 3 Subj = {Num = Sing Anim = + Obj = NONE = [P2 = [Fred = bark]]] IV Conclusion It has not been possible in this paper to give more than an impression of how an experimental machine translation system might be constructed based on FUG. I hope, however, that it has been possible to convey something of the value of monotonic systems for this purpose. Implementing FUG in an efficient way requires skill and a variety of little known techniques. However, the programs, though subtle, are not large and, once written, they provide the grammarian and lexicographer with an emmense wealth of expressive devices. Any system implemented strictly within this framework will be reversible in the sense that, if it translates from language A to language B the, to the same extent, translates from B to A. If the set among the translations it delivers for a, then a will be among the translations of each of I of no system that comes close to providing these advantages and I know of no facility provided for in any system proposed hitherto that it not subsumable under FUG =</abstract>
<note confidence="0.4464384">Type = Implies Prop = [1&apos;1 = [Arg = (Sense Var)11I P2= Arg = (Sense Var)] Sense = Prop = IP1 = 78</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>