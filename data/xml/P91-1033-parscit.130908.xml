<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.4361025">
FEATURE LOGIC WITH WEAK SUBSUMPTION
CONSTRAINTS
</title>
<author confidence="0.281211">
Jochen Dorre
</author>
<note confidence="0.708886">
IBM Deutschland GmbH
Science Center — IKBS
P.O. Box 80 08 80
D-7000 Stuttgart 80, Germany
</note>
<sectionHeader confidence="0.874927" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.995534142857143">
In the general framework of a constraint-based
grammar formalism often some sort of feature
logic serves as the constraint language to de-
scribe linguistic objects. We investigate the ex-
tension of basic feature logic with subsumption
(or matching) constraints, based on a weak no-
tion of subsumption. This mechanism of one-
way information flow is generally deemed to be
necessary to give linguistically satisfactory de-
scriptions of coordination phenomena in such
formalisms. We show that the problem whether
a set of constraints is satisfiable in this logic is
decidable in polynomial time and give a solution
algorithm.
</bodyText>
<sectionHeader confidence="0.99874" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999603">
Many of the current constraint-based grammar
formalisms, as e.g. FUG [Kay 79, Kay 85], LFG
[Kaplan/Bresnan 82], HPSG [Pollard/Sag 87],
PATR-II [Shieber et al. 83] and its derivates,
model linguistic knowledge in recursive fea-
ture structures. Feature (or functional) equa-
tions, as in LFG, or feature terms, as in FUG
or STUF [Bouma et al. 88], are used as con-
straints to describe declaratively what proper-
ties should be assigned to a linguistic entity.
In the last few years, the study of the for-
mal semantics and formal properties of logics
involving such constraints has made substan-
tial progress [Kasper/Rounds 86, Johnson 87,
Smolka 88, Smolka 89], e.g., by making precise
which sublanguages of predicate logic it corre-
sponds to. This paves the way not only for reli-
able implementations of these formalisms, but
also for extensions of the basic logic with a
precisely defined meaning. The extension we
present here, weak subsumption constraints, is
a mechanism of one-way information flow, often
proposed for a logical treatment of coordination
in a feature-based unification grammar.1 It can
&apos;Another application would be type inference in a
grammar formalism (or programming language) that
be informally described as a device, which en-
ables us to require that one part of a (solution)
feature structure has to be subsumed (be an in-
stance of) another part.
Consider the following example of a coordina-
tion with &amp;quot;and&amp;quot;, taken from [Shieber 89].
</bodyText>
<listItem confidence="0.9792315">
(1) Pat hired [NP a Republican] and
kip a banker].
(2) *Pat hired [NP a Republican] and
[AP proud of it].
</listItem>
<bodyText confidence="0.99924405">
Clearly (2) is ungrammatical since the verb
&amp;quot;hire&amp;quot; requires a noun phrase as object com-
plement and this requirement has to be ful-
filled by both coordinated complements. This
subcategorization requirement is modeled in
a unification-based grammar generally using
equations which cause the features of a comple-
ment (or parts thereof encoding the type) to get
unified with features encoding the requirements
of the respective position in the subcategoriza-
tion frame of the verb. Thus we could assume
that for a coordination the type-encoding fea-
tures of each element have to be &amp;quot;unified into&amp;quot;
the respective position in the subcategorization
frame. This entails that the coordinated ele-
ments are taken to be of one single type, which
then can be viewed as the type of the whole
coordination. This approach works fine for the
verb &amp;quot;hire&amp;quot;, but certain verbs, used very fre-
quently, do not require this strict identity.
</bodyText>
<listItem confidence="0.989662">
(3) Pat has become [NP a banker] and
[Ar very conservative].
(4) Pat is [Ar healthy] and [pp of
sound mind].
</listItem>
<bodyText confidence="0.9998465">
The verb &amp;quot;become&amp;quot; may have either noun-
phrase or adjective-phrase complements, &amp;quot;to
be&amp;quot; allows prepositional and verb phrases in
addition, and these may appear intermixed in
a coordination. In order to allow for such
&amp;quot;polymorphic&amp;quot; type requirements, we want to
</bodyText>
<subsectionHeader confidence="0.562023">
uses a type discipline with polymorphic types.
</subsectionHeader>
<page confidence="0.984351">
256
</page>
<bodyText confidence="0.999102">
state, that (the types of) coordinated arguments
each should be an instance of the respective re-
quirement from the verb. Expressed in a gen-
eral rule for (constituent) coordination, we want
the structures of coordinated phrases to be in-
stances of the structure of the coordination. Us-
ing subsumption constraints the rule basically
looks like this:
</bodyText>
<note confidence="0.339648">
E —4 C and D
</note>
<sectionHeader confidence="0.627077" genericHeader="introduction">
EDC
</sectionHeader>
<subsectionHeader confidence="0.610009">
EDD
</subsectionHeader>
<bodyText confidence="0.8475502">
With an encoding of the types like the one pro-
posed in HPSG we can model the subcatego-
rization requirements for &amp;quot;to be&amp;quot; and &amp;quot;to be-
come&amp;quot; as generalizations of all allowed types (cf.
Fig. 1).
</bodyText>
<figure confidence="0.956562777777778">
n: 1 n: +
NP= v: AP= v:
bar: 2 bar: 2
- n: -
VP= v: PP= [ v:
bar: 2 bar: 2
&apos;to become&apos; requires:
In: +
bar: 2 .1
</figure>
<figureCaption confidence="0.999989">
Figure 1: Encoding of syntactic type
</figureCaption>
<bodyText confidence="0.999964551724138">
A similar treatment of constituent coordina-
tion has been proposed in [Kaplan/Maxwell 88],
where the coordinated elements are required to
be in a set of feature structures and where the
feature structure of the whole set is defined as
the generalization (greatest lower hound w.r.t.
subsumption) of its elements. This entails
the requirement stated above, namely that the
structure of the coordination subsumes those of
its elements. In fact, it seems that especially in
the context of set-valued feature structures (cf.
[Rounds 88]) we need some method of inheri-
tance of constraints, since if we want to state
general combination rules which apply to the
set-valued objects as well, we would like con-
straints imposed on them to affect also their
members in a principled way.
Now, recently it turned out that a feature logic
involving subsumption constraints, which are
based on the generally adopted notion of sub-
sumption for feature graphs is undecidable (cf.
[DOrre/Rounds 90]). In the present paper we
therefore investigate a weaker notion of sub-
sumption, which we can roughly characterize as
relaxing the constraint that an instance of a fea-
ture graph contains all of its path equivalencies.
Observe, that path equivalencies play no role in
the subcategorization requirements in our ex-
amples above.
</bodyText>
<sectionHeader confidence="0.985172" genericHeader="method">
2 Feature Algebras
</sectionHeader>
<bodyText confidence="0.998953318181818">
In this section we define the basic structures
which are possible interpretations of feature de-
scriptions, the expressions of our feature logic.
Instead of restricting ourselves to a specific in-
terpretation, like in [Kasper/Rounds 86] where
feature structures are defined as a special kind
of finite automata, we employ an open-world se-
mantics as in predicate logic. We adopt most
of the basic definitions from [Smolka 89]. The
mathematical structures which serve us as in-
terpretations are called feature algebras.
We begin by assuming the pairwise disjoint sets
of symbols L, A and V, called the sets of fea-
tures (or labels), atoms (or constants) and vari-
ables, respectively. Generally we use the letters
f, g, h for features, a, b,c for atoms, and x, y, z
for variables. The letters s and 2 always denote
variables or atoms. We assume that there are
infinitely many variables.
A feature algebra A is a pair (D4, .A) consisting
of a nonempty set DA (the domain of A) and an
interpretation .A defined on L and A such that
</bodyText>
<listItem confidence="0.999655666666667">
• aA E DA for a E A. (atoms are constants)
• If a b then aA V. (unique name as-
sumption)
• If f is a feature then fA is a unary partial
function on DA. (features are functional)
• No feature is defined on an atom.
</listItem>
<bodyText confidence="0.994526823529412">
Notation. We write function symbols on the
right following the notation for record fields in
computer languages, so that f(d) is written df.
If f is defined at d, we write df I, and other-
wise df T. We use p,q,r to denote strings of
features, called paths. The interpretation func-
tion .A is straightforwardly extended to paths:
for the empty path e, € A is the identity on DA;
for a path p = pA is the unary partial
function which is the composition of the func-
tions fiA f, where fiA is applied first.
A feature algebra of special interest is the Fea-
ture Graph Algebra F, since it is canonical
in the sense that whenever there exists a solu-
tion for a formula in basic feature logic in some
feature algebra then there is also one in the Fea-
ture Graph Algebra. The same holds if we ex-
</bodyText>
<equation confidence="0.7029625">
&apos;to be&apos; requires:
[ bar : 2]
</equation>
<page confidence="0.984691">
257
</page>
<bodyText confidence="0.999893833333333">
tend our logic to subsumption constraints (see
[Diirre/Rounds 90]). A feature graph is a rooted
and connected directed graph. The nodes are
either variables or atoms, where atoms may ap-
pear only as terminal nodes. The edges are la-
beled with features and for every node no two
outgoing edges may be labeled with the same
feature.
We formalize feature graphs as pairs (so, E)
where so E V UA is the root and EC Vx
L x (V U A) is a set of triples, the edges. The
following conditions hold:
</bodyText>
<listItem confidence="0.9589035">
1. If so E A, then E = 0.
2. If(x,f,$)artd(x,f,2)areinE,thens—i.
3. If (z, f, s) is in E, then E contains edges
leading from the root so to the node z.
</listItem>
<bodyText confidence="0.998198727272727">
Let G = (zo, E) be a feature graph containing
an edge (zo, f, a). The subgraph under f of G
(written GI f) is the maximal graph (a, E&apos;) such
that E&apos; C E.
Now it is clear how the Feature Graph Algebra
.7&amp;quot; is to be defined. DF is the set of all feature
graphs. The interpretation of an atom al. is the
feature graph (a, 0), and for a feature f we let
Gf-7 = f, if this is defined. It is easy to
verify that .7&amp;quot; is a feature algebra.
Feature graphs are normally seen as data ob-
jects containing information. From this view-
point there exists a natural preorder, called sub-
gumption preorder, that orders feature graphs
according to their informational content thereby
abstracting away from variable names. We do
not introduce subsumption on feature graphs
here directly, but instead we define a subsump-
tion order on feature algebras in general.
Let A and B be feature algebras. A simulation
between A and B is a relation A C DA x DB
satisfying the following conditions:
</bodyText>
<listItem confidence="0.9978424">
1. if (aA,d) E A then d = aB , for each atom
a, and
2. for any d E DA, e E DB and f E L: if
dfA 1 and (d,e) E A, then e fB and
(dfA,efB) E A.
</listItem>
<bodyText confidence="0.886492636363636">
Notice that the union of two simulations and
the transitive closure of a simulation are also
simulations.
A partial homomorphism 7 between A and
B is a simulation between the two which is a
partial function. If A = B we also call 7 a partial
endomorphism.
Definition. Let A be a feature algebra. The
(strong) subsumption preorder CA and
the weak subsumption preorder EA of A
are defined as follows:
</bodyText>
<listItem confidence="0.9619246">
• d (strongly) subsumes e (written d EA e)
if there is an endomorphism -y such that
7(d) = e.
• d weakly subsumes e (written d CA e) if
there is a simulation A such that dAe.
</listItem>
<bodyText confidence="0.9922266">
It can be shown (see [Smolka 89]) that the
subsumption preorder of the feature graph
algebra coincides with the subsumption or-
der usually defined on feature graphs, e.g. in
[Kasper/Rounds 86].
Example: Consider the feature algebra de-
picted in Fig. 2, which consists of the elements
{1, 2, 3, 4, 5, a, b} where a and b shall be (the pic-
tures of) atoms and 1, g, i and j shall be features
whose interpretations are as indicated.
</bodyText>
<figure confidence="0.944854">
a ab
</figure>
<figureCaption confidence="0.999765">
Figure 2: Example of Weak Subsumption
</figureCaption>
<bodyText confidence="0.9997712">
Now, element 1 does not strongly subsume 3,
since for 3 it does not hold, that its f-value
equals its g-value. However, the simulation A
demonstrates that they stand in the weak sub-
sumption relation: 1 C 3.
</bodyText>
<sectionHeader confidence="0.997126" genericHeader="method">
3 Constraints
</sectionHeader>
<bodyText confidence="0.984878928571429">
To describe feature algebras we use a relational
language similar to the language of feature de-
scriptions in LFG or path equations in PATR-
II. Our syntax of constraints shall allow for the
forms
xp = yq, xp = a, xp yq
where p and q are paths (possibly empty), a E
A, and z and y are variables. A feature clause
is a finite set of constraints of the above forms.
As usual we interpret constraints with respect
to a variable assignment, in order to make sure
that variables are interpreted uniformly in the
whole set. An assignment is a mapping a of
variables to the elements of some feature alge-
</bodyText>
<figure confidence="0.999499">
a
simulation A
1A3
2A4
25
(Lila
bb
</figure>
<page confidence="0.985665">
258
</page>
<bodyText confidence="0.982670294117647">
bra. A constraint 0 is satisfied in A under as-
signment a, written (A, a) = 0, as follows:
(A, a) zp yq iff a(x)pA = a(y)qA
(A, a) xp 4-- a if a(x)pA = aA
(A, a) xpEyg if a(z)PA
The solutions of a clause C in a feature alge-
bra A are those assignments which satisfy each
constraint in C. Two clauses C1 and C2 are
equivalent iff they have the same set of solu-
tions in every feature algebra A.
The problem we want to consider is the follow-
ing:
Given a clause C with symbols from
V, L and A, does C have a solution in
some feature algebra?
We call this problem the weak semiunification
problem in feature algebras.2
</bodyText>
<sectionHeader confidence="0.986586" genericHeader="method">
4 An Algorithm
</sectionHeader>
<subsectionHeader confidence="0.987657">
4.1 Presolved Form
</subsectionHeader>
<bodyText confidence="0.885879195652174">
We give a solution algorithm for feature clauses
based on normalization, i.e. the goal is to de-
fine a normal form which exhibits unsatisfiabil-
ity and rewrite rules which transform each fea-
ture clause into normal form. The normal form
we present here actually is only half the way to
a solution, but we show below that with the use
of a standard algorithm solutions can be gener-
ated from it.
First we introduce the restricted syntax of the
normal form. Clauses containing only con-
straints of the following forms are called sim-
ple:
x f y, x = s, z y
where s is either a variable or an atom. Each
feature clause can be restated in linear time as
an equisatisfiable simple feature clause whose
solutions are extensions of the solutions of the
original clause, through the introduction of aux-
iliary variables. This step is trivial.
A feature clause C is called presolved if it is
simple and satisfies the following conditions.
2The analogous problem for (strong) subsumption
constraints is undecidable, even if we restrict ourselves
to finite feature algebras. Actually, this problem could
be shown to be equivalent to the semiunification prob-
lem for rational trees, i.e. first-order terms which may
contain cycles. The interested reader is referred to
[Thirre/Rounds 90].
Cl. If x y is in C, then z occurs exactly once
in C.
C2. If zf = y and zf z are in C, then y = z.
C3. Hz Ey and y z are in C, then z E z is
in C (transitive closure).
C4. If x y and z f 4-- z&apos; and yf 4-- y&apos; are in
C, then z&apos; y&apos; is in C (downward propa-
gation closure).
In the first step our algorithm attempts to trans-
form feature clauses to presolved form, thereby
solving the equational part. In the simplifica-
tion rules (cf. Fig. 3) we have adapted some
of Smolka&apos;s rules for feature clauses including
complements [Smolka 89]. In the rules [x/s]C
denotes the clause C where every occurrence of
z has been replaced with s, and 0 &amp; C denotes
the feature clause {0} U C provided 0 fl C.
</bodyText>
<construct confidence="0.9148244">
Theorem 1 Let C be a simple feature clause.
Then
I. if C can be rewritten to D using one of
the rules, then D is a simple feature clause
equivalent to C,
</construct>
<listItem confidence="0.86992025">
2. for every non-normal simple feature clause
one of the rewrite rules applies,
S. there is no infinite chain C -4 CI -4 C2
• • •
</listItem>
<bodyText confidence="0.989881666666667">
Proof.3 The first part can be verified straight-
forwardly by inspecting the rules. The same
holds for the second part. To show the termina-
tion claim first observe that the application of
the last two rules can safely be postponed until
no one of the others can apply any more, since
they only introduce subsumption constraints,
which cannot feed the other rules. Now, call
a variable x isolated in a clause C, if C contains
an equation z = y and z occurs exactly once in
C. The first rule strictly increases the number
of isolated variables and no rule ever decreases
it. Application of the second and third rule de-
crease the number of equational constraints or
the number of features appearing in C, which
no other rule increase. Finally, the last two
rules strictly increase the number of subsump-
tion constraints for a constant set of variables.
Hence, no infinite chain of rewriting steps may
be produced.
We will show now, that the presolved form can
be seen as a nondeterministic finite automaton
&apos;Part of this proof has been directly adapted from
[Smolka 89].
</bodyText>
<page confidence="0.985278">
259
</page>
<figure confidence="0.9782205">
• y &amp; C x y &amp; [z/]C, if x occurs in C and x y
• &amp; C - xEy&amp;yEz&amp;zEz&amp;C, ifzEzVC
xf=--y&amp;x“---z&amp;C - xEy&amp;xf.2.--x&apos;&amp;yfrLy&apos;Srx&apos;Ey&apos;&amp;C
xEy&amp;yEz&amp;C if z&apos; E y&apos; C
</figure>
<figureCaption confidence="0.999801">
Figure 3: Rewriting to presolved form
</figureCaption>
<bodyText confidence="0.997146">
with e-moves and that we can read off solutions
from its deterministic equivalent, if that is of
a special, trivially verifiable, form, called clash-
free.
</bodyText>
<subsectionHeader confidence="0.9953425">
4.2 The Transition Relation 6c of a
Presolved Clause C
</subsectionHeader>
<bodyText confidence="0.992157461538461">
The intuition behind this construction is, that
subsumption constraints basically enforce that
information about one variable (and the space
reachable from it) has to be inherited by (copied
to) another variable. For example the con-
straints x E y and xi, 2.= a entail that also
yp = a has to hold.4 Now, if we have a con-
straint z E y, we could think of actually copying
the information found under x to y, e.g. xf x&apos;
would be copied to yf y&apos;, where yl is a new
variable, and z&apos; would be linked to y&apos; by z&apos;
However, this treatment is hard to control in the
presence of cycles, which always can occur. In-
stead of actually copying we also can regard a
constraint x E y as a pointer from y back to x
leading us to the information which is needed to
construct the local solution of y. To extend this
view we regard the whole presolved clause C as
a finite automaton: take variables and atoms
as nodes, a feature constraint as an arc labeled
with the feature, constraints z s and y E
as e-moves from z to a or y. We can show then
that C is unsatisfiable if there is some z from
which we reach atom a via path p such that we
can also reach b(0 a) via p or there is a path
starting from z whose proper prefix is p.
Formally, let NFA .A.rc of presolved clause C be
4 From this point of view the difference between weak
and strong subsumption can be captured in the type
of information they enforce to be inherited. Strong
subsumption requires path equivalences to be inherited
(x E y and xp xq implies yp yq), whereas weak
subsumption does not.
defined as follows. Its states are the variables
occurring in C (Vc) plus the atoms plus the
states qp and the initial state q0. The set of
final states is Vc U {qp}. The alphabet of Aic is
VcuLUAu{e}.6
The transition relation is defined as follows:6
</bodyText>
<equation confidence="0.970357">
:= {(go, x, x) I x E Vc}
U {(a, a, qp) I a E A}
U {(y,e, z) ix 2yE C}
U {(x, f,y) I xf E CI
U {(x,e, s)lx=sE C}
</equation>
<bodyText confidence="0.996002833333333">
As usual, let ic be the extension of 5c to paths.
Notice that zpa E L(gc) if (x, p, a) E ic •
The language accepted by this automaton con-
tains strings of the forms xp or xpa, where a
string zp indicates that in a solution a the ob-
ject a(x)pA should be defined and zpa tells us
further that this object should be aA.
A set of strings of (V x L*) U (V x L* x A) is
called clash-free if it does not contain a string
zpa together with xpb (where a 0 b) or together
with zpf. It is clear that the property of a reg-
ular language L of being clash-free with respect
to L and A can be read off immediately from
a DFA D for it: if 1, contains a state q with
6(q, a) E F and either 8(q,b) E F (where a 0 b)
or 6(q, f) E F, then it is not clash-free, other-
wise it is.
We now present our central theorem.
</bodyText>
<construct confidence="0.438351">
Theorem 2 Let Co be a feature clause, C its
presolved form and .Aic the NFA as constructed
</construct>
<tableCaption confidence="0.788913">
5If L or A are infinite we restrict ourselves to the sets
of symbols actually occurring in C.
6Notice that if x s E C, then either s is an atom or
x occurs only once. Thus it is pointless to have an arc
from s to x, since we either have already the maximum
of information for s or x will not provide any new arcs.
</tableCaption>
<bodyText confidence="0.333225">
oc
</bodyText>
<page confidence="0.986638">
260
</page>
<bodyText confidence="0.9344915">
above. Then the following conditions are equiv-
dent:
</bodyText>
<listItem confidence="0.972572">
1. L(.1t(c) is clash-free
2. There exists a finite feature algebra A and
</listItem>
<bodyText confidence="0.914436714285714">
an assignment a such that (A,a) Co,
provided the set of atoms is finite.
Y. There exists a feature algebra A and an as-
signment a such that (A,a) = Co.
Proof. see Appendix A.
Now the algorithm consists of the following sim-
ple or well-understood steps:
</bodyText>
<listItem confidence="0.97652425">
1: (a) Solve the equational constraints of C,
which can be done using standard uni-
fication methods, exemplified by rules
1) to 3).
</listItem>
<bodyText confidence="0.8942835">
(b) Make the set of weak subsumption
constraints transitively and &amp;quot;down-
ward&amp;quot; closed (rules 4) and 5)).
2: The result interpreted as an NFA is made
deterministic using standard methods and
tested of being clash-free.
</bodyText>
<subsectionHeader confidence="0.9893605">
4.3 Determining Clash-Freeness Di-
rectly
</subsectionHeader>
<bodyText confidence="0.99915521875">
For the purpose of proving the algorithm cor-
rect it was easiest to assume that clash-freeness
is determined after transforming the NFA of the
presolved form into a deterministic automaton.
However, this translation step has a time com-
plexity which is exponential with the number
of states in the worst case. In this section[A we
consider a technique to determine clash-freeness
directly from the NFA representation of the pre-
solved form in polynomial time. We do not go
into implementational details, though. Instead
we are concerned to describe the different steps
more from a logical point of view. It can be
assumed that there is still room left for opti-
mizations which improve efficiency.
In a first step we eliminate all the e-transitions
from the NFA M. We will call the result
still fic. For every pair of a variable node
x and an atom node a let .Arc[x, a] be the
(sub-)automaton of all states of .11rc reachable
from x, but with the atom a being the only final
state. Thus, .Arc[x, a] accepts exactly the lan-
guage of all strings p for which xpa E L(Arc).
Likewise, let .Arc[x,rd be the (sub-)automaton
of all states of Arc reachable from z, but where
every atom node besides a is in the set of fi-
nal states as well as every node with an outgo-
ing feature arc. The set accepted by this ma-
chine contains every string p such that xpb E
L(Arc), (b a) or xpf E L(A/c). If and only if
the intersection of these two machines is empty
for every x and a, L(A(c) is clash-free.
</bodyText>
<subsectionHeader confidence="0.99864">
4.4 Complexity
</subsectionHeader>
<bodyText confidence="0.961311581395349">
Let us now examine the complexity of the dif-
ferent steps of the algorithm.
We know that Part la) can be done (using
the efficient union/find technique to maintain
equivalence classes of variables and vectors of
features for each representative) in nearly lin-
ear time, the result being smaller or of equal
size than Co. Part lb) may blow up the clause
to a size at most quadratic with the number
of different variables n, since we cannot have
more subsumption constraints than this. For
every new subsumption constraint, trying to ap-
ply rule 4) might involve at most 2n membership
test to check whether we are actually adding a
new constraint, whereas for rule 5) this number
only depends on the size of L. Hence, we stay
within cubic time until here.
Determining whether the presolved form is
clash-free from the NFA representation is done
in three steps. The e-free representation of Arc
does not increase the number of states. If n, a
and 1 are the numbers of variables, atoms and
features resp. in the initial clause, then the
number of edges is in any case smaller than
(n a)2 • I, since there are only n -I- a states.
This computation can be performed in time of
an order less than o((n + a)3).
Second, we have to build the intersections for
Arc[x, a] and N.c[x,Ti] for every z and a. Inter-
section of two NFAs is done by building a cross-
product machine, requiring maximally o((n +
arl • I) time and space.7 The test for emptiness
of these intersection machines is again trivial
and can be performed in constant time.
Hence, we estimate a total time and space com-
plexity of order n • a • (n + a)l • I.
71&apos;1118 is an estimate for the number of edges, since the
number of states is below (n a)2. As usual, we assume
appropriate data structures where we can neglect the
order of access times. Probably the space (and time)
complexity can be reduced further, since we actually do
not need the representations of the intersection machines
besides for testing, whether they can accept anything.
</bodyText>
<page confidence="0.997181">
261
</page>
<sectionHeader confidence="0.997073" genericHeader="method">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999993882352941">
We proposed an extension to the basic feature
logic of variables, features, atoms, and equa-
tional constraints. This extension provides a
means for one-way information passing. We
have given a simple, but nevertheless completely
formal semantics for the logic and have shown
that the satisfiability (or unification) problem
in the logic involving weak subsumption con-
straints is decidable in polynomial time. Fur-
thermore, the first part of the algorithm is a sur-
prisingly simple extension of a standard unifica-
tion algorithm for feature logic. We have formu-
lated the second part of the problem as a simple
property of the regular language which the out-
come of the first part defines. Hence, we could
make use of standard techniques from automata
theory to solve this part of the problem. The
algorithm has been proved to be correct, com-
plete, and guaranteed to terminate. There are
no problems with cycles or with infinite chains
of subsumption relations as generated by a con-
straint like z E xf.a
The basic algorithmic requirements to solve the
problem being understood, the challenge now is
to find ways how solutions can be found in a
more incremental way, if we already have solu-
tions for subsets of a clause. To achieve this we
plan to amalgamate more closely the two parts
algorithms, for instance, through implementing
the check for clash-freeness also with the help
of (a new form of) constraints. It would be in-
teresting also from a theoretical point of view
to find out how much of the complexity of the
second part is really necessary.
</bodyText>
<sectionHeader confidence="0.943556" genericHeader="method">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.999681833333333">
I am indebted to Bill Rounds for reading a first draft
of this paper and pointing out to me a way to test
dash-freeness in polynomial time. Of course, any
remaining errors are those of the author. I would
also like to thank Gert Smolka for giving valuable
comments on the first draft.
</bodyText>
<sectionHeader confidence="0.999213" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.997991089552239">
[Bourns et al. 881 Gosse Bourna, Esther Konig and
Hans Uszkoreit. A flexible graph-unification for-
malism and its application to natural-language
processing. In: IBM Journal of Research and De-
velopment, 1988.
See [Shieber 89] for a discussion of this problem.
[DOrre/Rounds 90] Jochen DC■rre and William C.
Rounds. On Subsumption and Semiunification in
Feature Algebras. In Proceedings of the 5th An-
nual Symposium on Logic in Computer Science,
pages 300-310, Philadelphia, PA., 1990. Also ap-
pears in: Journal of Symbolic Computation.
[Johnson 871 Mark Johnson. Attribute. Value Logic
and the Theory of Grammar. CSLI Lecture Notes
16, CSLI, Stanford University, 1987.
[Kaplan/Bresnan 82] Ronald M. Kaplan and Joan
Bresnan. Lexical Functional Grammar: A For-
mal System for Grammatical Representation. In:
J. Bresnan (ed.), The Mental Representation of
Grammatical Relations. MIT Press, Cambridge,
Massachusetts, 1982.
[Kaplan/Maxwell 88] Ronald M. Kaplan and John
T. Maxwell III. Constituent Coordination in
Lexical-Functional Grammar. In: Proc. of COL-
ING&apos;88, pp.303-305, Budapest, Hungary, 1988.
[Kasper/Rounds 86] Robert T. Kasper and William
C. Rounds. A Logical Semantics for Feature
Structures. In: Proceedings of the 24th Annual
Meeting of the A CL. Columbia University, New
York, NY, 1986.
[Kay 79] Martin Kay. Functional Grammar. In: C.
Chiarello et al. (eds.) Proceedings of the 5th An-
nual Meeting of the Berkeley Linguistic Society.
1979.
[Kay 85] Martin Kay. Parsing in Functional Unifi-
cation Grammar. In: D. Dowty, L. Karttunen,
and A. Zwicky (eds.) Natural Language Parsing,
Cambridge, England, 1985
[Pollard/Sag 87] Carl Pollard and Ivan A. Sag.
Information-Based Syntax and Semantics, Vol.
I. CSLI Lecture Notes 13, CSLI, Stanford Uni-
versity, 1987.
[Rounds 88] William C. Rounds. Set Values for
Unification-Based Grammar Formalisms and
Logic Programming. CSLI-Report 88-129, CSLI,
Stanford University, 1988.
[Shieber et al. 83] Stuart M. Shieber, Hans Uszko-
reit, Fernando C.N. Pereira, J.J. Robinson, M.
Tyson. The formalism and implementation of
PATR.-II. In: J. Bresnan (ed.), Research on In-
teractive Acquisition and Use of Knowledge, SRI
International, Menlo Park, CA, 1983.
[Shieber 89] Stuart M. Shieber. Parsing and Type
Inference for Natural and Computer Languages.
Technical Note 460, SRI International, Menlo
Park, CA, March 1989.
[Smolka, 88] Gert Smolka. A Feature Logic with Sub-
sorts. LILOG-Report 33, IWBS, IBM Deutsch-
land, W. Germany, May 1988. To appear in the
Journal of Automated Reasoning.
[Smolka 89] Gert Smolka. Feature Constraint Log-
ics for Unification Grammars. IWBS R.eport 93,
IWBS, IBM Deutschland, W. Germany, Nov.
1989. To appear in the Proceedings of the Work-
shop on Unification Formalisms—Syntax, Se-
mantics and Implementation, Titisee, The MIT
Press, 1990.
</reference>
<page confidence="0.998313">
262
</page>
<sectionHeader confidence="0.970731" genericHeader="method">
Appendix A: Proof of Theorem 2
</sectionHeader>
<bodyText confidence="0.568328833333333">
From Theorem 1 we know that C is equivalent to (Jo,
i.e. it suffices to show the theorem for the existence
of solutions of C in 2) and 3). Since 2) 3) is
obvious, it remains to show 1) 2) and 3) 1).
1) 2): We construct a finite model (A, a) whose
domain contains partial functions from paths to
atoms (DA C L* A). Interpretation and variable
assignment are given as follows:
• aA = {(e, a)} for every atom a (the function
mapping only the empty string to a)
• for every f E L,x E L*-+A:
{(P, a) (iP, a) E X)
• a(x)= {(p, a) I xpa E L(Arc)), which is a par-
tial function, due to 1).
Now let the elements of the domain be, besides in-
terpretations of atoms, just those objects (partial
functions) which can be reached by application of
some features to some
</bodyText>
<listItem confidence="0.842542">
• DA = {a(x)qA I xEITc,qEL*} U {aA I aEA}.
</listItem>
<bodyText confidence="0.9912815">
To see that DA is finite, we first observe
that the domain of each a(x) is a regular set
UP I rPaEgc,aEA}) and the range is finite. Now,
for a regular set R call fp I qpER} the suffix language
of R with respect to string q. It is clear, that there
are only finitely many suffix languages, since each
corresponds to one state in the minimal finite au-
tomaton for R. But then also the number of partial
functions &amp;quot;reachable&amp;quot; from an a(x) is finite, since
the domain of a(x)qA is a suffix language of the do-
main of a(x).
We now show that given 1) the model (A, a) satisfies
all constraints in C.
• If x a E C: xa E L(.A.G) (e, a) E a(x).
Now we know from 1) that no other pair is in
a(x), i.e. a(x) = aA.
</bodyText>
<listItem confidence="0.383984285714286">
• If x = y E C: Since x occurs only once in
C, the only transition from x is (x, e, y), thus
(x,p, a) E Sc if (1/,1; a) E Sc. We conclude
that (p, a) E a(x) if (p, a) E cr(y).
• If xf y EC: Let (p, a) E a(x)f A . Then
(x,fp,a) E Sc• This implies that there is a
state x&apos; reachable with n e-moves (n &gt; 0) from
</listItem>
<bodyText confidence="0.9149995">
x such that x&apos; f E C and (V,p,a) E
i.e. z&apos; is the last state before f is consumed
on a path consuming /pa. But now, since e-
moves on such a chain correspond to subsump-
tion constraints (none of the variables in the
chain is isolated) and since C is transitively
closed for subsumption constraints, C has to
contain a constraint x&apos; E x. But the last con-
dition for normal form now tells us, that also
y&apos; E y is in C, implying (y,e,y&apos;) E (Sc. Hence,
</bodyText>
<reference confidence="0.926598224489796">
P a) E 8c and (p, a) E
Conversely, let (p, a) E a(y). Then (y, p, a) E
Sc. From the construction also (2,, LY) E 5c
hence (fp,a) E a(x) and (p, a) E a(x)fA.
• If xpy E C: The simulation witnessing
a(x) EA a(y) is simply the subset relation.
Suppose (p, a) E a(x). We conclude (x,p, a) ..E
5c, but also (y, E, z) E 5c. Hence, (Y,P, a) E Sc
and (p, a) E a(y).
In order to show the other direction let us first show
a property needed in the proof.
Lemma 1 If (A, a) is a model for pre solved clause
C and (x,p,$) E Sc, then a(s) EA a(x)pA. (If
= a let a(a) = aA for this purpose.)
Proof. We show by induction over the definition
of 8c that, given the condition above, there exists a
simulation A in .4 such that a(s)Aa(x)pA.
1. p = e and = y: A =ID.
2. p = e and y x E C: since a is a solution,
there exists a simulation A with a(y)Aa(x) 1=
a(x)eAJ.
3. p = f and xf-L- y E C: A =ID, since
= a(y).
4. p = e and x s E C: A =ID, since a(x) =
a(s).
5. p = qr and (x,q,y) E Sc. and (Y,r, 8) E Sc:
by induction hypothesis there exist Ai and A2
such that a(y)Ala(x)qA and a(8)A2a(y)r4.
Let A = (Al U A2)* (the transitive clo-
sure of their union), then a(y)Aa(x)qA and
a(s)4a(y)r4. But now, since a(y)r A „I, and
A is a simulation, also a(y)rA Aat(r)qATA.
Hence, a(s)Aa(x)(qr)A. 0
Now let us proof 3) z 1) of the main theorem by
contradiction.
3) = 1):
Suppose 1) does not hold, but (A,a) = C. Then
there is a string xpa E L(AtC) such that
Case 1: xpb E L(AG) where a 0 b.
From (x,p, a) E c and (x,P,b) E Sc
know with lemma 1 that aA EA a(x)pA and
b A CA a(x)pA. But this contradicts condition
1) for a simulation: a(x)pA = aA bA =
awpA.
Case 2: xpf E L(Al.c).
As in case 1) we have a(x)pA = aA. From
(x,pf,y) E we get a(y) EA a(x)(pf)A ,
which entails that fA has to be defined for
a(x)pA, a contradiction.
</reference>
<subsectionHeader confidence="0.226737">
This completes the proof.
</subsectionHeader>
<bodyText confidence="0.421724">
xf A =
we
</bodyText>
<page confidence="0.993722">
263
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.771620">
<title confidence="0.996369">FEATURE LOGIC WITH WEAK SUBSUMPTION CONSTRAINTS</title>
<author confidence="0.994387">Jochen Dorre</author>
<affiliation confidence="0.998885">IBM Deutschland GmbH</affiliation>
<address confidence="0.938482666666667">Science Center — IKBS P.O. Box 80 08 80 D-7000 Stuttgart 80, Germany</address>
<abstract confidence="0.996782733333333">In the general framework of a constraint-based grammar formalism often some sort of feature logic serves as the constraint language to describe linguistic objects. We investigate the extension of basic feature logic with subsumption (or matching) constraints, based on a weak notion of subsumption. This mechanism of oneway information flow is generally deemed to be necessary to give linguistically satisfactory descriptions of coordination phenomena in such formalisms. We show that the problem whether a set of constraints is satisfiable in this logic is polynomial time and give a algorithm.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>881 Gosse Bourna, Esther Konig and Hans Uszkoreit. A flexible graph-unification formalism and its application to natural-language processing. In:</title>
<date>1988</date>
<journal>IBM Journal of Research and Development,</journal>
<marker>1988</marker>
<rawString>[Bourns et al. 881 Gosse Bourna, Esther Konig and Hans Uszkoreit. A flexible graph-unification formalism and its application to natural-language processing. In: IBM Journal of Research and Development, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>See</author>
</authors>
<title>[Shieber 89] for a discussion of this problem. [DOrre/Rounds 90] Jochen DC■rre and</title>
<date>1990</date>
<journal>Journal of Symbolic Computation.</journal>
<booktitle>In Proceedings of the 5th Annual Symposium on Logic in Computer Science,</booktitle>
<pages>300--310</pages>
<location>Philadelphia, PA.,</location>
<marker>See, 1990</marker>
<rawString>See [Shieber 89] for a discussion of this problem. [DOrre/Rounds 90] Jochen DC■rre and William C. Rounds. On Subsumption and Semiunification in Feature Algebras. In Proceedings of the 5th Annual Symposium on Logic in Computer Science, pages 300-310, Philadelphia, PA., 1990. Also appears in: Journal of Symbolic Computation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Attribute</author>
</authors>
<title>Value Logic and the Theory of Grammar.</title>
<date>1987</date>
<booktitle>CSLI Lecture Notes 16, CSLI,</booktitle>
<institution>Stanford University,</institution>
<marker>Attribute, 1987</marker>
<rawString>[Johnson 871 Mark Johnson. Attribute. Value Logic and the Theory of Grammar. CSLI Lecture Notes 16, CSLI, Stanford University, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
<author>Joan Bresnan</author>
</authors>
<title>Lexical Functional Grammar: A Formal System for Grammatical Representation.</title>
<date>1982</date>
<editor>In: J. Bresnan (ed.),</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts,</location>
<marker>Kaplan, Bresnan, 1982</marker>
<rawString>[Kaplan/Bresnan 82] Ronald M. Kaplan and Joan Bresnan. Lexical Functional Grammar: A Formal System for Grammatical Representation. In: J. Bresnan (ed.), The Mental Representation of Grammatical Relations. MIT Press, Cambridge, Massachusetts, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
<author>John T Maxwell</author>
</authors>
<title>Constituent Coordination in Lexical-Functional Grammar. In:</title>
<date>1988</date>
<booktitle>Proc. of COLING&apos;88,</booktitle>
<pages>303--305</pages>
<location>Budapest, Hungary,</location>
<marker>Kaplan, Maxwell, 1988</marker>
<rawString>[Kaplan/Maxwell 88] Ronald M. Kaplan and John T. Maxwell III. Constituent Coordination in Lexical-Functional Grammar. In: Proc. of COLING&apos;88, pp.303-305, Budapest, Hungary, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert T Kasper</author>
<author>William C Rounds</author>
</authors>
<title>A Logical Semantics for Feature Structures. In:</title>
<date>1986</date>
<booktitle>Proceedings of the 24th Annual Meeting of the A CL.</booktitle>
<institution>Columbia University,</institution>
<location>New York, NY,</location>
<marker>Kasper, Rounds, 1986</marker>
<rawString>[Kasper/Rounds 86] Robert T. Kasper and William C. Rounds. A Logical Semantics for Feature Structures. In: Proceedings of the 24th Annual Meeting of the A CL. Columbia University, New York, NY, 1986.</rawString>
</citation>
<citation valid="true">
<date>1979</date>
<booktitle>Proceedings of the 5th Annual Meeting of the Berkeley Linguistic Society.</booktitle>
<editor>[Kay 79] Martin Kay. Functional Grammar. In: C. Chiarello et al. (eds.)</editor>
<marker>1979</marker>
<rawString>[Kay 79] Martin Kay. Functional Grammar. In: C. Chiarello et al. (eds.) Proceedings of the 5th Annual Meeting of the Berkeley Linguistic Society. 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Parsing in Functional Unification Grammar. In:</title>
<date>1985</date>
<booktitle>Natural Language Parsing,</booktitle>
<editor>D. Dowty, L. Karttunen, and A. Zwicky (eds.)</editor>
<location>Cambridge, England,</location>
<marker>Kay, 1985</marker>
<rawString>[Kay 85] Martin Kay. Parsing in Functional Unification Grammar. In: D. Dowty, L. Karttunen, and A. Zwicky (eds.) Natural Language Parsing, Cambridge, England, 1985</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan A Sag</author>
</authors>
<date>1987</date>
<booktitle>Information-Based Syntax and Semantics, Vol. I. CSLI Lecture Notes 13, CSLI,</booktitle>
<institution>Stanford University,</institution>
<marker>Pollard, Sag, 1987</marker>
<rawString>[Pollard/Sag 87] Carl Pollard and Ivan A. Sag. Information-Based Syntax and Semantics, Vol. I. CSLI Lecture Notes 13, CSLI, Stanford University, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Rounds</author>
</authors>
<title>Set Values for Unification-Based Grammar Formalisms and Logic Programming. CSLI-Report 88-129, CSLI,</title>
<date>1988</date>
<institution>Stanford University,</institution>
<marker>Rounds, 1988</marker>
<rawString>[Rounds 88] William C. Rounds. Set Values for Unification-Based Grammar Formalisms and Logic Programming. CSLI-Report 88-129, CSLI, Stanford University, 1988.</rawString>
</citation>
<citation valid="true">
<title>The formalism and implementation of PATR.-II.</title>
<date>1983</date>
<booktitle>Research on Interactive Acquisition and Use of Knowledge, SRI International,</booktitle>
<editor>[Shieber et al. 83] Stuart M. Shieber, Hans Uszkoreit, Fernando C.N. Pereira, J.J. Robinson, M. Tyson.</editor>
<location>Menlo Park, CA,</location>
<marker>1983</marker>
<rawString>[Shieber et al. 83] Stuart M. Shieber, Hans Uszkoreit, Fernando C.N. Pereira, J.J. Robinson, M. Tyson. The formalism and implementation of PATR.-II. In: J. Bresnan (ed.), Research on Interactive Acquisition and Use of Knowledge, SRI International, Menlo Park, CA, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>Parsing and Type Inference for Natural and Computer Languages.</title>
<date>1989</date>
<booktitle>Technical Note 460, SRI International,</booktitle>
<location>Menlo Park, CA,</location>
<marker>Shieber, 1989</marker>
<rawString>[Shieber 89] Stuart M. Shieber. Parsing and Type Inference for Natural and Computer Languages. Technical Note 460, SRI International, Menlo Park, CA, March 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gert Smolka</author>
</authors>
<title>A Feature Logic with Subsorts. LILOG-Report 33, IWBS, IBM Deutschland,</title>
<date>1988</date>
<journal>the Journal of Automated Reasoning.</journal>
<location>W. Germany,</location>
<note>To appear in</note>
<marker>Smolka, 1988</marker>
<rawString>[Smolka, 88] Gert Smolka. A Feature Logic with Subsorts. LILOG-Report 33, IWBS, IBM Deutschland, W. Germany, May 1988. To appear in the Journal of Automated Reasoning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gert Smolka</author>
</authors>
<title>Feature Constraint Logics for Unification Grammars.</title>
<date>1989</date>
<booktitle>the Proceedings of the Workshop on Unification Formalisms—Syntax, Semantics and Implementation, Titisee, The</booktitle>
<tech>IWBS R.eport 93, IWBS, IBM</tech>
<publisher>MIT Press,</publisher>
<note>To appear in</note>
<marker>Smolka, 1989</marker>
<rawString>[Smolka 89] Gert Smolka. Feature Constraint Logics for Unification Grammars. IWBS R.eport 93, IWBS, IBM Deutschland, W. Germany, Nov. 1989. To appear in the Proceedings of the Workshop on Unification Formalisms—Syntax, Semantics and Implementation, Titisee, The MIT Press, 1990.</rawString>
</citation>
<citation valid="false">
<title>E 8c and (p, a) E Conversely, let (p, a) E a(y). Then (y, p, a) E Sc. From the construction also (2,, LY) E 5c hence (fp,a) E a(x) and (p, a) E a(x)fA. • If xpy E C: The simulation witnessing a(x) EA a(y) is simply the subset relation.</title>
<booktitle>Suppose (p, a) E a(x). We conclude (x,p, a) ..E 5c, but also (y, E, z) E 5c. Hence, (Y,P, a) E Sc and (p, a) E</booktitle>
<location>a(y).</location>
<marker></marker>
<rawString>P a) E 8c and (p, a) E Conversely, let (p, a) E a(y). Then (y, p, a) E Sc. From the construction also (2,, LY) E 5c hence (fp,a) E a(x) and (p, a) E a(x)fA. • If xpy E C: The simulation witnessing a(x) EA a(y) is simply the subset relation. Suppose (p, a) E a(x). We conclude (x,p, a) ..E 5c, but also (y, E, z) E 5c. Hence, (Y,P, a) E Sc and (p, a) E a(y).</rawString>
</citation>
<citation valid="false">
<title>In order to show the other direction let us first show a property needed in the proof.</title>
<marker></marker>
<rawString>In order to show the other direction let us first show a property needed in the proof.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Lemma</author>
</authors>
<title>a) is a model for pre solved clause C and (x,p,$) E Sc, then a(s) EA a(x)pA. (If = a let a(a) = aA for this purpose.) Proof. We show by induction over the definition of 8c that, given the condition above, there exists a simulation A in .4 such that a(s)Aa(x)pA.</title>
<booktitle>1. p = e and = y: A =ID. 2. p = e and y x E C: since</booktitle>
<location>a(s).</location>
<marker>Lemma, </marker>
<rawString>Lemma 1 If (A, a) is a model for pre solved clause C and (x,p,$) E Sc, then a(s) EA a(x)pA. (If = a let a(a) = aA for this purpose.) Proof. We show by induction over the definition of 8c that, given the condition above, there exists a simulation A in .4 such that a(s)Aa(x)pA. 1. p = e and = y: A =ID. 2. p = e and y x E C: since a is a solution, there exists a simulation A with a(y)Aa(x) 1= a(x)eAJ. 3. p = f and xf-L- y E C: A =ID, since = a(y). 4. p = e and x s E C: A =ID, since a(x) = a(s).</rawString>
</citation>
<citation valid="false">
<title>8) E Sc: by induction hypothesis there exist Ai and A2 such that a(y)Ala(x)qA and a(8)A2a(y)r4.</title>
<marker></marker>
<rawString>5. p = qr and (x,q,y) E Sc. and (Y,r, 8) E Sc: by induction hypothesis there exist Ai and A2 such that a(y)Ala(x)qA and a(8)A2a(y)r4.</rawString>
</citation>
<citation valid="false">
<title>Let A = (Al U A2)* (the transitive closure of their union), then a(y)Aa(x)qA and a(s)4a(y)r4. But now, since a(y)r A „I, and A is a simulation, also a(y)rA Aat(r)qATA.</title>
<marker></marker>
<rawString>Let A = (Al U A2)* (the transitive closure of their union), then a(y)Aa(x)qA and a(s)4a(y)r4. But now, since a(y)r A „I, and A is a simulation, also a(y)rA Aat(r)qATA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>aAaA Hence</author>
</authors>
<title>0 Now let us proof 3) z 1) of the main theorem by contradiction.</title>
<marker>Hence, </marker>
<rawString>Hence, a(s)Aa(x)(qr)A. 0 Now let us proof 3) z 1) of the main theorem by contradiction.</rawString>
</citation>
<citation valid="false">
<title>1): Suppose 1) does not hold, but (A,a) = C. Then there is a string xpa E L(AtC) such that Case 1: xpb E L(AG) where a 0 b.</title>
<marker></marker>
<rawString>3) = 1): Suppose 1) does not hold, but (A,a) = C. Then there is a string xpa E L(AtC) such that Case 1: xpb E L(AG) where a 0 b.</rawString>
</citation>
<citation valid="false">
<authors>
<author>From</author>
</authors>
<title>a) E c and (x,P,b) E Sc know with lemma 1 that aA EA a(x)pA and b A CA a(x)pA. But this contradicts condition 1) for a simulation: a(x)pA = aA bA = awpA.</title>
<marker>From, </marker>
<rawString>From (x,p, a) E c and (x,P,b) E Sc know with lemma 1 that aA EA a(x)pA and b A CA a(x)pA. But this contradicts condition 1) for a simulation: a(x)pA = aA bA = awpA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Case</author>
</authors>
<title>2: xpf E L(Al.c). As in case 1) we have a(x)pA = aA. From (x,pf,y) E we get a(y) EA a(x)(pf)A , which entails that fA has to be defined for a(x)pA, a contradiction.</title>
<marker>Case, </marker>
<rawString>Case 2: xpf E L(Al.c). As in case 1) we have a(x)pA = aA. From (x,pf,y) E we get a(y) EA a(x)(pf)A , which entails that fA has to be defined for a(x)pA, a contradiction.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>