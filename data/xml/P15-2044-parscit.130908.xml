<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001938">
<title confidence="0.996881">
If all you have is a bit of the Bible:
Learning POS taggers for truly low-resource languages
</title>
<author confidence="0.996893">
ˇZeljko Agi´c, Dirk Hovy, and Anders Søgaard
</author>
<affiliation confidence="0.9987">
Center for Language Technology
University of Copenhagen, Denmark
</affiliation>
<address confidence="0.907465">
Njalsgade 140
</address>
<email confidence="0.999398">
{zeljko.agic|dirk.hovy|soegaard}@hum.ku.dk
</email>
<sectionHeader confidence="0.997396" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999908391304348">
We present a simple method for learning
part-of-speech taggers for languages like
Akawaio, Aukan, or Cakchiquel – lan-
guages for which nothing but a translation
of parts of the Bible exists. By aggre-
gating over the tags from a few annotated
languages and spreading them via word-
alignment on the verses, we learn POS
taggers for 100 languages, using the lan-
guages to bootstrap each other. We eval-
uate our cross-lingual models on the 25
languages where test sets exist, as well as
on another 10 for which we have tag dic-
tionaries. Our approach performs much
better (20-30%) than state-of-the-art unsu-
pervised POS taggers induced from Bible
translations, and is often competitive with
weakly supervised approaches that assume
high-quality parallel corpora, representa-
tive monolingual corpora with perfect to-
kenization, and/or tag dictionaries. We
make models for all 100 languages avail-
able.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999725444444444">
Most previous work in cross-lingual NLP has been
limited to training and evaluating on no more than
a dozen languages, typically all from the major
Indo-European languages. While it has been ob-
served repeatedly that using multiple source lan-
guages improves performance (Yarowsky et al.,
2001; Yarowsky and Ngai, 2001; Fossum and Ab-
ney, 2005; McDonald et al., 2011), most avail-
able techniques work best for closely related lan-
guages.
In contrast, this paper presents an effort to learn
POS taggers for truly low-resource languages,
with minimum assumptions about the available
language resources. Most low-resource languages
are non-Indo-European, and typically, their typo-
logical and geographic neighbors have sparse re-
sources as well. However, for a surprisingly large
number of languages, translations of the Bible (or
parts of it) exist. Due to the canonical nature and
the verse format, these translations are viable par-
allel data, albeit lacking annotation. In our exper-
iments, we use word alignments across all pairs
of 100 parallel Bible translations to bootstrap an-
notation projections for those languages without
any (even just weakly) supervised taggers. The
projections provide both pseudo-annotated data as
well as tag dictionaries for all languages. We use
both resources to train semi-supervised POS tag-
gers following Garrette and Baldridge (2013).
Our contributionWe present a novel approach to
learning POS taggers for truly low-resource lan-
guages, where only a translation of (parts of) the
Bible is available. We obtain results competi-
tive with approaches that assume the availability
of larger volumes of more representative paral-
lel corpora, perfectly tokenized monolingual cor-
pora, and/or tag dictionaries for the target lan-
guages. Additionally, we make the POS tagging
models for 100 languages publicly available and
extend the mappings in Petrov et al. (2011) for six
new languages (Hindi, Croatian, Icelandic, Nor-
wegian, Persian, and Serbian). The models, map-
pings, as well as a complete list of all the re-
sources used in these experiments, are available at
https://bitbucket.org/lowlands/.
</bodyText>
<sectionHeader confidence="0.998758" genericHeader="introduction">
2 Experiments
</sectionHeader>
<bodyText confidence="0.925618428571429">
Our approach is a combination of simple tech-
niques. Part of the process is depicted in Figure 1,
and the algorithm is presented in Algorithm 1. As-
sume we have n languages for which we assume
the availability of m verses of the Bible. We run
IBM-21 on all n(n − 1) pairs of languages. As-
sume also manually POS-annotated training data
</bodyText>
<footnote confidence="0.5320602">
1github.com/clab/fast_align
268
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 268–272,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</footnote>
<equation confidence="0.775013">
G É EN HR DE É G
versej
</equation>
<bodyText confidence="0.999960888888889">
is available for the first k of these languages. We
then run taggers for these languages on the corre-
sponding translations of the Bible to predict tags
for all tokens in these translations.
We can think of this partially annotated multi-
parallel corpus as a tensor object. Each column
is a language li, and each row a verse vj (triv-
ially sentence-aligned to the corresponding verses
in the other columns). In each cell of this ma-
trix M(i, j, ·), we have a sequence of word tokens.
For two languages, l1 and l2, the word tokens in
M(1, j, ·) can be aligned (by IBM-2) to multiple
word tokens in M(2, j, ·), but not all words need
to be aligned.
After running supervised POS taggers on the
k languages for which we have training data, we
have POS-annotated the word tokens in k columns
of our tensor object. We then project the POS
tag of each word token w to all other word tokens
aligned to w. In our experiments, k = 17 or 18 (if
the target language is not one of the languages for
which we have training data), which means each
word token will potentially have many POS tags
projected onto it. Note that the number of tags can
exceed 18, since many-to-many word alignments
are allowed.
We now use these projections to train POS tag-
gers for the remaining n − k languages. We
use aggregated projected annotations as token-
level supervision. We aggregate from the incom-
ing projected POS tags by majority voting. We
also use the complete set of projections onto each
word type in the target language as a type-level
tag dictionary. We combine the tag dictionary
and the token-level projections to train discrimina-
tive, type-constrained POS taggers (Collins, 2002;
T¨ackstr¨om et al., 2013). Below we refer to these
POS taggers as using k sources (k-SRC).
These n many POS taggers can now also be
used to obtain predictions for all word tokens in
our tensor object. This corresponds to doing the
second loop over lines 8–17 in Algorithm 1. For
each of our n languages, we thus complete the ten-
sor by projecting tags into word tokens from the
n − 1 remaining source languages. For the k su-
pervised languages, we project the tags produced
by the supervised POS taggers rather than the tags
obtained by projection. We can then train our fi-
nal POS taggers for all n languages – 100, in our
case – using projections from 99 languages (n-1-
SRC). Note that we also train projected taggers for
those languages for which we have annotated data.
This is to enable us to evaluate our methodology
on more languages.
</bodyText>
<equation confidence="0.378066">
Algorithm 1 Train n taggers with supervision for
k
</equation>
<listItem confidence="0.978220545454546">
1: Let M be a tensor with M(i, j, ) the word-aligned token
sequence in the jth verse of the Bible in language i
2: for i &lt; k do
3: Train TNT tagger for li using manually annotated data
4: for j &lt; m do
5: Obtain POS predictions for M(i, j, )
6: end for
7: end for
8: for I E {0, 11 do
9: if i &gt; k, I = 1 then
10: Train TNT tagger for li using projected annota-
tions in M(i, , )
11: end if
12: Populate M(i, , ) by propagating tags across align-
ments
13: for i &lt; n do
14: Use majority voting to obtain one tag per word
15: Obtain type-level tag dictionary from all the data
16: Train TNT/GAR tagger for li using projected an-
notations in M(i, , ) and tag dictionary
17: end for
18: end for
</listItem>
<bodyText confidence="0.99989325">
DataWe use the 100 translations of (parts of) the
Bible available as part of the Edinburgh Multi-
lingual Parallel Bible Corpus (Christodouloupou-
los and Steedman, 2014).2 This dataset includes
translations into languages such as Akawaio,
Aukan or Cakchiquel. The majority of these lan-
guages are non-Indoeuropean, and 39 of them
have less than one million speakers. For 54 of
</bodyText>
<page confidence="0.379208">
2homepages.inf.ed.ac.uk/s0787820/bible/
</page>
<figureCaption confidence="0.990121">
Figure 1: An illustration of our approach.
</figureCaption>
<table confidence="0.9901849">
In the beginning was the word
U početku bijaše Riječ
Am Anfang war das Wort
ADP NOUN VERB DET NOUN
HR EN DE É voted confidence
U ADP ADP ... ADP 0.8667
početku NOUN, DET NOUN ... NOUN 0.7448
bijaše VERB VERB ... VERB 0.8560
Riječ DET, NOUN DET, NOUN ... NOUN 0.6307
ADP DET NOUN VERB DET NOUN
269
UNSUPERVISED UPPER BOUNDS
BASELINES OUR SYSTEMS WEAKLY SUP SUPERVISED
OOV BROWN 2HMM TNT-k-SRC TNT-n-1-SRC GAR-k-SRC GAR-n-1-SRC DAS LI GAR TNT
bul YT 31.8 54.5 71.8 78.0 77.7 75.7 75.7 - - 83.1 96.9
ces YT 44.3 51.9 66.3 71.7 73.3 70.9 71.4 - - - 98.7
dan YT 28.6 58.6 69.6 78.6 79.0 73.7 73.3 83.2 83.3 78.8 96.7
deu YT 36.8 45.3 70.0 80.5 80.2 77.6 77.6 82.8 85.8 87.1 98.1
eng YT 38.0 58.2 62.6 72.4 73.0 72.2 72.6 - 87.1 80.8 96.7
eus NT 64.6 46.0 41.6 63.4 62.8 57.3 56.9 - - 66.9 93.7
fra YT 26.1 42.0 76.5 76.1 76.6 78.6 80.2 - - 85.5 95.1
ell YT 63.7 43.0 49.8 51.9 52.3 57.9 59.0 82.5 79.2 64.4 -
hin Y 36.1 59.5 69.2 70.9 67.6 70.8 71.5 - - --
hrv Y 34.7 52.8 65.6 67.8 67.1 67.2 66.7 - - --
hun YT 41.2 45.9 57.4 70.0 70.4 71.3 72.0 - - 77.9 95.6
isl Y 19.7 42.6 65.9 70.6 69.0 68.7 68.3 - - - -
ind YT 29.4 52.6 73.1 76.6 76.8 74.9 76.0 - - 87.1 95.1
ita YT 24.0 45.1 78.3 76.5 76.9 78.5 79.2 86.8 86.5 83.5 95.8
plt Y 35.0 48.9 44.3 56.4 56.6 62.0 64.6 - - - -
mar Y 33.0 55.8 45.8 52.0 52.9 52.8 52.3 - - - -
nor YT 27.5 56.1 73.0 77.0 76.7 75.4 76.0 - - 84.3 97.7
pes Y 33.6 57.9 61.5 59.3 59.6 59.1 60.8 - - - -
pol YT 36.4 52.2 68.7 75.6 75.1 70.8 74.0 - - - 95.7
por YT 27.9 54.5 74.3 82.9 83.8 81.1 82.0 87.9 84.5 87.3 96.8
slv Y 15.8 42.1 78.1 79.5 80.5 68.7 70.1 - - - -
spa YT 21.9 52.6 47.3 81.1 81.4 82.6 82.6 84.2 86.4 88.7 96.2
srp Y 41.7 59.3 47.3 69.6 69.2 67.9 67.2 - - - 94.7
swe YT 31.5 58.5 68.4 74.7 75.2 71.4 71.9 80.5 86.1 76.1 94.7
tur YT 41.6 53.7 46.8 60.5 61.3 56.5 57.9 - - 72.2 89.1
average ≤ 50 52.2 64.4 72.1 72.2 70.8 71.5
</table>
<tableCaption confidence="0.966444333333333">
Table 1: Results on 25 test languages. Y=entire Bible available. N=only New Testament available.
T=manually annotated data available for training (but not used to obtain results for the language itself).
Unsupervised baselines are evaluated using optimal 1:1 mappings.
</tableCaption>
<bodyText confidence="0.999915041666667">
these languages, we have a translation of the entire
Bible. For 42, we only have the New Testament,
and for the remaining four we only have parts of
the New Testament. We note that Bible trans-
lations typically have fewer POS-unambiguous
words than newswire (Christodouloupoulos and
Steedman, 2014). We also note that in rare cases
sentences span multiple verses, which means, we
sometimes train POS taggers on partial sentences.
See Christodouloupoulos and Steedman (2014)
for further discussion of the resource. Most of
the manually annotated resources were obtained
from the CoNLL 2006-2007 releases of various
treebanks, the NLTK corpora, the HamleDT re-
sources, and the Universal Dependencies project.
We provide a complete overview of the resources
athttps://bitbucket.org/lowlands/
ModelsWe train TNT POS taggers (Brants, 2000)
using only token-level projections. We also train
semi-supervised POS taggers using the approach
in Garrette and Baldridge (2013) (GAR), using
both projections and dictionaries, as well as the
unlabelled Bible translations.3 We use the English
data as development data. We train TNT and GAR
</bodyText>
<equation confidence="0.564114">
3github.com/dhgarrette/
low-resource-pos-tagging-2014/
</equation>
<bodyText confidence="0.998764541666667">
using k or n − 1 source languages, leading to four
taggers in total.
Baselines Our baselines are two standard unsu-
pervised POS induction algorithms: Brown clus-
tering using the implementation by Percy Liang4
and second-order unsupervised HMMs using lo-
gistic regression for emission probabilities (Berg-
Kirkpatrick et al., 2010; Li et al., 2012), with and
without our Bible tag dictionaries.5
Upper bounds The weakly supervised system
in Das and Petrov (2011) (DAS) relies on larger
volumes of more representative and perfectly tok-
enized parallel data than we assume, as well as a
representative sample of unlabeled data. Such data
is simply not available for many of the languages
considered here. The weakly supervised system in
Li et al. (2012) (LI) also relies on crowd-sourced
type-level tag dictionaries, not available for most
of the languages of concern to us. We present their
reported results. Finally, we train the two base
POS taggers (GAR and TNT) on the manually an-
notated data available for 17 of our languages, to
be able to compare against state-of-the-art perfor-
mance of supervised POS taggers.
</bodyText>
<footnote confidence="0.8980015">
4github.com/percyliang/brown-cluster
5code.google.com/p/wikily-supervised-pos-tagger/
</footnote>
<page confidence="0.995753">
270
</page>
<bodyText confidence="0.999323526315789">
Results Our results on the 25 test languages are
consistently better than the unsupervised base-
lines, with the exceptions of Marathi and Persian,
and by a very large margin. Our average per-
formance across the languages with OOV rates
smaller than 50% is above 70%. While previous
papers on weakly supervised POS tagging (e.g.,
DAS and LI) have presented slightly better results
for the small set of Indo-European languages in
the CoNLL 2006–7 shared tasks, we emphasize
again that our set-up requires fewer resources and
does not rely on perfectly tokenized training data.
Our parallel data also suffers from a severe, but
more realistic domain bias. Note that doing the
second round of projections (n-1-SRC) often im-
proves performance by about a percentage point,
but this improvement is not consistent across lan-
guages. We observe that most errors are due to
our systems predicting too many nouns. Note that
for the two languages with underlined OOV rates
(≥ 50), performance is very low. This is due to
differences in orthography and tokenization. We
leave out those results in the averages, but leave
them in the results table.
To evaluate on more low-resource languages,
we also extracted tag dictionaries from Wik-
tionary for another 10 languages, from Afrikaans
to Swahili. Figure 2 presents the type-level in-
vocabulary tag errors of the projected tags in the
Bible. This figure is similar to the ones used in
Li et al. (2012). We also computed token-level ac-
curacies, where every tag assignment licensed by
Wiktionary counts as correct. For three languages,
results were 80-90%: Afrikaans, Lithuanian, and
Russian. For another three languages, results were
50-70%: Hebrew, Romanian, and Swahili. Results
were 35-50% for the remaining four languages:
Latin, Maori, Albanian, and Ewe.
</bodyText>
<sectionHeader confidence="0.999963" genericHeader="related work">
3 Related work
</sectionHeader>
<bodyText confidence="0.999595666666667">
The Bible has been used as a resource for ma-
chine translation and multi-lingual information
retrieval before, e.g., (Chew et al., 2006). It
has also been used in cross-lingual POS tagging
(Yarowsky et al., 2001; Fossum and Abney, 2005),
NP-chunking (Yarowsky et al., 2001; Yarowsky
and Ngai, 2001) and cross-lingual dependency
parsing (Sukhareva and Chiarcos, 2014) before.
Yarowsky et al. (2001) and Fossum and Abney
(2005) use word-aligned parallel translations of
the Bible to project the predictions of POS taggers
for several language pairs, including English,
</bodyText>
<figureCaption confidence="0.899046">
Figure 2: Type-level in-vocabulary tag errors as
the percentage of word types assigned a set of tags
that is disjoint, identical to, overlaps, is a subset,
or is a superset of the Wiktionary tags.
</figureCaption>
<bodyText confidence="0.999981735294118">
German, and Spanish to Czech and French. The
resulting annotated target language corpora enable
them to train POS taggers for these languages.
Yarowsky and Ngai (2001) showed similar results
using just the Hansards corpus on English to
French and Chinese. Our work is inspired by
these approaches, yet broader in scope on both the
source and target side.
Das and Petrov (2011) use word-aligned text
to automatically create type-level tag dictionaries.
Earlier work on building tag dictionaries from
word-aligned text includes Probst (2003). Their
tag dictionaries contain target language trigrams
to be able to disambiguate ambiguous target
language words. To handle the noise in the
automatically obtained dictionaries, they use label
propagation on a similarity graph to smooth and
expand the label distributions. Our approach is
similar to theirs in using projections to obtain
type-level tag dictionaries, but we keep the token
supervision and type supervision apart and end up
with a model more similar to that of T¨ackstr¨om
et al. (2013), who combine word-aligned text
with crowdsourced type-level tag dictionaries.
T¨ackstr¨om et al. (2013) constrain Viterbi search
via type-level tag dictionaries, pruning all tags
not licensed by the dictionary. For the remaining
tags, they use high-confidence word alignments
to further prune the Viterbi search. We follow
T¨ackstr¨om et al. (2013) in using our automatically
created, not crowdsourced, tag dictionaries to
prune tags during search, but we use word align-
ments to obtain token-level annotations that we
use as annotated training data, similar to Fossum
</bodyText>
<figure confidence="0.9890904">
identical overlap subset superset
afr als ewe heb lat lit mri ron rus swh
disjoint
100
80
60
% entries
40
20
0
</figure>
<page confidence="0.992834">
271
</page>
<bodyText confidence="0.9997375">
and Abney (2005), Yarowsky et al. (2001), and
Yarowsky and Ngai (2001).
Duong et al. (2013) use word-alignment
probabilities to select training data for their
cross-lingual POS models. They consider a
simple single-source training set-up. We also tried
ranking projected training data by confidence,
using an ensemble of projections from 17–99
source languages and majority voting to obtain
probabilities for the token-level target-language
projections, but this did not lead to improvements
on the English development data.
</bodyText>
<sectionHeader confidence="0.999619" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999979444444444">
We present a novel approach to learning POS
taggers, assuming only that parts of the Bible are
available for the target language. Our approach
combines annotation projection, bootstrapping,
and label propagation to learn POS taggers that
perform significantly better than unsupervised
baselines, and often competitive to state-of-the-art
weakly supervised POS taggers that assume more
and better resources are available.
</bodyText>
<sectionHeader confidence="0.996937" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9915845">
This research is funded by the ERC Starting Grant
LOWLANDS No. 313695.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996431169491525">
Taylor Berg-Kirkpatrick, Alexandre Bouchard-Cote,
John DeNero, , and Dan Klein. 2010. Painless un-
supervised learning with features. In Proceedings of
NAACL.
Thorsten Brants. 2000. Tnt: a statistical part-of-
speech tagger. In ANLP.
Peter Chew, Steve Verzi, Travis Bauer, and Jonathan
McClain. 2006. Evaluation of the bible as a re-
source for cross-language information retrieval. In
ACL Workshop on n Multilingual Language Re-
sources and Interoperability.
Cristos Christodouloupoulos and Mark Steedman.
2014. A massively parallel corpus: the bible in 100
languages. Language Resources and Evaluation.
Michael Collins. 2002. Discriminative Training Meth-
ods for Hidden Markov Models: Theory and Exper-
iments with Perceptron Algorithms. In EMNLP.
Dipanjan Das and Slav Petrov. 2011. Unsupervised
part-of-speech tagging with bilingual graph-based
projections. In ACL.
Long Duong, Paul Cook, Steven Bird, and Pavel
Pecina. 2013. Simpler unsupervised pos tagging
with bilingual projections. In Proceedings of ACL.
Victoria Fossum and Steven Abney. 2005. Automati-
cally inducing a part-of-speech tagger by projecting
from multiple source languages across aligned cor-
pora. In IJCNLP.
Dan Garrette and Jason Baldridge. 2013. Learning a
part-of-speech tagger from two hours of annotation.
In NAACL.
Shen Li, Jo˜ao Grac¸a, and Ben Taskar. 2012. Wiki-ly
supervised part-of-speech tagging. In EMNLP.
Ryan McDonald, Slav Petrov, and Keith Hall. 2011.
Multi-source transfer of delexicalized dependency
parsers. In EMNLP.
Slav Petrov, Dipanjan Das, and Ryan McDonald.
2011. A universal part-of-speech tagset. CoRR
abs/1104.2086.
Katharina Probst. 2003. Using ‘smart’ bilingual pro-
jection to feature-tag a monolingual dictionary. In
CoNLL.
Maria Sukhareva and Christian Chiarcos. 2014. Di-
achronic proximity vs. data sparsity in cross-lingual
parser projection. In COLING Workshop on Apply-
ing NLP Tools to Similar Languages, Varieties and
Dialects.
Oscar T¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan
McDonald, and Joakim Nivre. 2013. Token and
type constraints for cross-lingual part-of-speech tag-
ging. TACL, 1:1–12.
David Yarowsky and Grace Ngai. 2001. Inducing mul-
tilingual pos taggers and np brackets via robust pro-
jection across aligned corpora. In Proceedings of
NAACL.
David Yarowsky, Grace Ngai, and Richard Wicen-
towski. 2001. Inducing multilingual text analysis
tools via robust projection across aligned corpora.
In Proceedings of the first international conference
on Human language technology research.
</reference>
<page confidence="0.997097">
272
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.449994">
<title confidence="0.971356">If all you have is a bit of the Bible: Learning POS taggers for truly low-resource languages</title>
<author confidence="0.593043">Dirk Hovy Agi´c</author>
<author confidence="0.593043">Anders</author>
<affiliation confidence="0.993325">Center for Language University of Copenhagen,</affiliation>
<email confidence="0.868881">Njalsgade</email>
<abstract confidence="0.996680125">We present a simple method for learning part-of-speech taggers for languages like Akawaio, Aukan, or Cakchiquel – languages for which nothing but a translation of parts of the Bible exists. By aggregating over the tags from a few annotated languages and spreading them via wordalignment on the verses, we learn POS taggers for 100 languages, using the languages to bootstrap each other. We evaluate our cross-lingual models on the 25 languages where test sets exist, as well as on another 10 for which we have tag dictionaries. Our approach performs much better (20-30%) than state-of-the-art unsupervised POS taggers induced from Bible translations, and is often competitive with weakly supervised approaches that assume high-quality parallel corpora, representative monolingual corpora with perfect tokenization, and/or tag dictionaries. We make models for all 100 languages available.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Alexandre Bouchard-Cote</author>
<author>John DeNero</author>
</authors>
<title>Painless unsupervised learning with features.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<marker>Berg-Kirkpatrick, Bouchard-Cote, DeNero, 2010</marker>
<rawString>Taylor Berg-Kirkpatrick, Alexandre Bouchard-Cote, John DeNero, , and Dan Klein. 2010. Painless unsupervised learning with features. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>Tnt: a statistical part-ofspeech tagger.</title>
<date>2000</date>
<booktitle>In ANLP.</booktitle>
<contexts>
<context position="10624" citStr="Brants, 2000" startWordPosition="1864" endWordPosition="1865">r POS-unambiguous words than newswire (Christodouloupoulos and Steedman, 2014). We also note that in rare cases sentences span multiple verses, which means, we sometimes train POS taggers on partial sentences. See Christodouloupoulos and Steedman (2014) for further discussion of the resource. Most of the manually annotated resources were obtained from the CoNLL 2006-2007 releases of various treebanks, the NLTK corpora, the HamleDT resources, and the Universal Dependencies project. We provide a complete overview of the resources athttps://bitbucket.org/lowlands/ ModelsWe train TNT POS taggers (Brants, 2000) using only token-level projections. We also train semi-supervised POS taggers using the approach in Garrette and Baldridge (2013) (GAR), using both projections and dictionaries, as well as the unlabelled Bible translations.3 We use the English data as development data. We train TNT and GAR 3github.com/dhgarrette/ low-resource-pos-tagging-2014/ using k or n − 1 source languages, leading to four taggers in total. Baselines Our baselines are two standard unsupervised POS induction algorithms: Brown clustering using the implementation by Percy Liang4 and second-order unsupervised HMMs using logis</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>Thorsten Brants. 2000. Tnt: a statistical part-ofspeech tagger. In ANLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Chew</author>
<author>Steve Verzi</author>
<author>Travis Bauer</author>
<author>Jonathan McClain</author>
</authors>
<title>Evaluation of the bible as a resource for cross-language information retrieval.</title>
<date>2006</date>
<booktitle>In ACL Workshop on n Multilingual Language Resources and Interoperability.</booktitle>
<contexts>
<context position="14111" citStr="Chew et al., 2006" startWordPosition="2404" endWordPosition="2407">ary tag errors of the projected tags in the Bible. This figure is similar to the ones used in Li et al. (2012). We also computed token-level accuracies, where every tag assignment licensed by Wiktionary counts as correct. For three languages, results were 80-90%: Afrikaans, Lithuanian, and Russian. For another three languages, results were 50-70%: Hebrew, Romanian, and Swahili. Results were 35-50% for the remaining four languages: Latin, Maori, Albanian, and Ewe. 3 Related work The Bible has been used as a resource for machine translation and multi-lingual information retrieval before, e.g., (Chew et al., 2006). It has also been used in cross-lingual POS tagging (Yarowsky et al., 2001; Fossum and Abney, 2005), NP-chunking (Yarowsky et al., 2001; Yarowsky and Ngai, 2001) and cross-lingual dependency parsing (Sukhareva and Chiarcos, 2014) before. Yarowsky et al. (2001) and Fossum and Abney (2005) use word-aligned parallel translations of the Bible to project the predictions of POS taggers for several language pairs, including English, Figure 2: Type-level in-vocabulary tag errors as the percentage of word types assigned a set of tags that is disjoint, identical to, overlaps, is a subset, or is a super</context>
</contexts>
<marker>Chew, Verzi, Bauer, McClain, 2006</marker>
<rawString>Peter Chew, Steve Verzi, Travis Bauer, and Jonathan McClain. 2006. Evaluation of the bible as a resource for cross-language information retrieval. In ACL Workshop on n Multilingual Language Resources and Interoperability.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristos Christodouloupoulos</author>
<author>Mark Steedman</author>
</authors>
<title>A massively parallel corpus: the bible in 100 languages. Language Resources and Evaluation.</title>
<date>2014</date>
<contexts>
<context position="7368" citStr="Christodouloupoulos and Steedman, 2014" startWordPosition="1246" endWordPosition="1250">OS predictions for M(i, j, ) 6: end for 7: end for 8: for I E {0, 11 do 9: if i &gt; k, I = 1 then 10: Train TNT tagger for li using projected annotations in M(i, , ) 11: end if 12: Populate M(i, , ) by propagating tags across alignments 13: for i &lt; n do 14: Use majority voting to obtain one tag per word 15: Obtain type-level tag dictionary from all the data 16: Train TNT/GAR tagger for li using projected annotations in M(i, , ) and tag dictionary 17: end for 18: end for DataWe use the 100 translations of (parts of) the Bible available as part of the Edinburgh Multilingual Parallel Bible Corpus (Christodouloupoulos and Steedman, 2014).2 This dataset includes translations into languages such as Akawaio, Aukan or Cakchiquel. The majority of these languages are non-Indoeuropean, and 39 of them have less than one million speakers. For 54 of 2homepages.inf.ed.ac.uk/s0787820/bible/ Figure 1: An illustration of our approach. In the beginning was the word U početku bijaše Riječ Am Anfang war das Wort ADP NOUN VERB DET NOUN HR EN DE É voted confidence U ADP ADP ... ADP 0.8667 početku NOUN, DET NOUN ... NOUN 0.7448 bijaše VERB VERB ... VERB 0.8560 Riječ DET, NOUN DET, NOUN ... NOUN 0.6307 ADP DET NOUN VERB DET NOUN 269 UNSUPERVISED </context>
<context position="10089" citStr="Christodouloupoulos and Steedman, 2014" startWordPosition="1786" endWordPosition="1789"> 61.3 56.5 57.9 - - 72.2 89.1 average ≤ 50 52.2 64.4 72.1 72.2 70.8 71.5 Table 1: Results on 25 test languages. Y=entire Bible available. N=only New Testament available. T=manually annotated data available for training (but not used to obtain results for the language itself). Unsupervised baselines are evaluated using optimal 1:1 mappings. these languages, we have a translation of the entire Bible. For 42, we only have the New Testament, and for the remaining four we only have parts of the New Testament. We note that Bible translations typically have fewer POS-unambiguous words than newswire (Christodouloupoulos and Steedman, 2014). We also note that in rare cases sentences span multiple verses, which means, we sometimes train POS taggers on partial sentences. See Christodouloupoulos and Steedman (2014) for further discussion of the resource. Most of the manually annotated resources were obtained from the CoNLL 2006-2007 releases of various treebanks, the NLTK corpora, the HamleDT resources, and the Universal Dependencies project. We provide a complete overview of the resources athttps://bitbucket.org/lowlands/ ModelsWe train TNT POS taggers (Brants, 2000) using only token-level projections. We also train semi-supervise</context>
</contexts>
<marker>Christodouloupoulos, Steedman, 2014</marker>
<rawString>Cristos Christodouloupoulos and Mark Steedman. 2014. A massively parallel corpus: the bible in 100 languages. Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms.</title>
<date>2002</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="5624" citStr="Collins, 2002" startWordPosition="909" endWordPosition="910">potentially have many POS tags projected onto it. Note that the number of tags can exceed 18, since many-to-many word alignments are allowed. We now use these projections to train POS taggers for the remaining n − k languages. We use aggregated projected annotations as tokenlevel supervision. We aggregate from the incoming projected POS tags by majority voting. We also use the complete set of projections onto each word type in the target language as a type-level tag dictionary. We combine the tag dictionary and the token-level projections to train discriminative, type-constrained POS taggers (Collins, 2002; T¨ackstr¨om et al., 2013). Below we refer to these POS taggers as using k sources (k-SRC). These n many POS taggers can now also be used to obtain predictions for all word tokens in our tensor object. This corresponds to doing the second loop over lines 8–17 in Algorithm 1. For each of our n languages, we thus complete the tensor by projecting tags into word tokens from the n − 1 remaining source languages. For the k supervised languages, we project the tags produced by the supervised POS taggers rather than the tags obtained by projection. We can then train our final POS taggers for all n l</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
</authors>
<title>Unsupervised part-of-speech tagging with bilingual graph-based projections.</title>
<date>2011</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="11427" citStr="Das and Petrov (2011)" startWordPosition="1980" endWordPosition="1983">well as the unlabelled Bible translations.3 We use the English data as development data. We train TNT and GAR 3github.com/dhgarrette/ low-resource-pos-tagging-2014/ using k or n − 1 source languages, leading to four taggers in total. Baselines Our baselines are two standard unsupervised POS induction algorithms: Brown clustering using the implementation by Percy Liang4 and second-order unsupervised HMMs using logistic regression for emission probabilities (BergKirkpatrick et al., 2010; Li et al., 2012), with and without our Bible tag dictionaries.5 Upper bounds The weakly supervised system in Das and Petrov (2011) (DAS) relies on larger volumes of more representative and perfectly tokenized parallel data than we assume, as well as a representative sample of unlabeled data. Such data is simply not available for many of the languages considered here. The weakly supervised system in Li et al. (2012) (LI) also relies on crowd-sourced type-level tag dictionaries, not available for most of the languages of concern to us. We present their reported results. Finally, we train the two base POS taggers (GAR and TNT) on the manually annotated data available for 17 of our languages, to be able to compare against st</context>
<context position="15115" citStr="Das and Petrov (2011)" startWordPosition="2564" endWordPosition="2567"> for several language pairs, including English, Figure 2: Type-level in-vocabulary tag errors as the percentage of word types assigned a set of tags that is disjoint, identical to, overlaps, is a subset, or is a superset of the Wiktionary tags. German, and Spanish to Czech and French. The resulting annotated target language corpora enable them to train POS taggers for these languages. Yarowsky and Ngai (2001) showed similar results using just the Hansards corpus on English to French and Chinese. Our work is inspired by these approaches, yet broader in scope on both the source and target side. Das and Petrov (2011) use word-aligned text to automatically create type-level tag dictionaries. Earlier work on building tag dictionaries from word-aligned text includes Probst (2003). Their tag dictionaries contain target language trigrams to be able to disambiguate ambiguous target language words. To handle the noise in the automatically obtained dictionaries, they use label propagation on a similarity graph to smooth and expand the label distributions. Our approach is similar to theirs in using projections to obtain type-level tag dictionaries, but we keep the token supervision and type supervision apart and e</context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>Dipanjan Das and Slav Petrov. 2011. Unsupervised part-of-speech tagging with bilingual graph-based projections. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Duong</author>
<author>Paul Cook</author>
<author>Steven Bird</author>
<author>Pavel Pecina</author>
</authors>
<title>Simpler unsupervised pos tagging with bilingual projections.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="16558" citStr="Duong et al. (2013)" startWordPosition="2787" endWordPosition="2790">aries, pruning all tags not licensed by the dictionary. For the remaining tags, they use high-confidence word alignments to further prune the Viterbi search. We follow T¨ackstr¨om et al. (2013) in using our automatically created, not crowdsourced, tag dictionaries to prune tags during search, but we use word alignments to obtain token-level annotations that we use as annotated training data, similar to Fossum identical overlap subset superset afr als ewe heb lat lit mri ron rus swh disjoint 100 80 60 % entries 40 20 0 271 and Abney (2005), Yarowsky et al. (2001), and Yarowsky and Ngai (2001). Duong et al. (2013) use word-alignment probabilities to select training data for their cross-lingual POS models. They consider a simple single-source training set-up. We also tried ranking projected training data by confidence, using an ensemble of projections from 17–99 source languages and majority voting to obtain probabilities for the token-level target-language projections, but this did not lead to improvements on the English development data. 4 Conclusions We present a novel approach to learning POS taggers, assuming only that parts of the Bible are available for the target language. Our approach combines </context>
</contexts>
<marker>Duong, Cook, Bird, Pecina, 2013</marker>
<rawString>Long Duong, Paul Cook, Steven Bird, and Pavel Pecina. 2013. Simpler unsupervised pos tagging with bilingual projections. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victoria Fossum</author>
<author>Steven Abney</author>
</authors>
<title>Automatically inducing a part-of-speech tagger by projecting from multiple source languages across aligned corpora. In IJCNLP.</title>
<date>2005</date>
<contexts>
<context position="1512" citStr="Fossum and Abney, 2005" startWordPosition="230" endWordPosition="234">uced from Bible translations, and is often competitive with weakly supervised approaches that assume high-quality parallel corpora, representative monolingual corpora with perfect tokenization, and/or tag dictionaries. We make models for all 100 languages available. 1 Introduction Most previous work in cross-lingual NLP has been limited to training and evaluating on no more than a dozen languages, typically all from the major Indo-European languages. While it has been observed repeatedly that using multiple source languages improves performance (Yarowsky et al., 2001; Yarowsky and Ngai, 2001; Fossum and Abney, 2005; McDonald et al., 2011), most available techniques work best for closely related languages. In contrast, this paper presents an effort to learn POS taggers for truly low-resource languages, with minimum assumptions about the available language resources. Most low-resource languages are non-Indo-European, and typically, their typological and geographic neighbors have sparse resources as well. However, for a surprisingly large number of languages, translations of the Bible (or parts of it) exist. Due to the canonical nature and the verse format, these translations are viable parallel data, albe</context>
<context position="14211" citStr="Fossum and Abney, 2005" startWordPosition="2421" endWordPosition="2424">i et al. (2012). We also computed token-level accuracies, where every tag assignment licensed by Wiktionary counts as correct. For three languages, results were 80-90%: Afrikaans, Lithuanian, and Russian. For another three languages, results were 50-70%: Hebrew, Romanian, and Swahili. Results were 35-50% for the remaining four languages: Latin, Maori, Albanian, and Ewe. 3 Related work The Bible has been used as a resource for machine translation and multi-lingual information retrieval before, e.g., (Chew et al., 2006). It has also been used in cross-lingual POS tagging (Yarowsky et al., 2001; Fossum and Abney, 2005), NP-chunking (Yarowsky et al., 2001; Yarowsky and Ngai, 2001) and cross-lingual dependency parsing (Sukhareva and Chiarcos, 2014) before. Yarowsky et al. (2001) and Fossum and Abney (2005) use word-aligned parallel translations of the Bible to project the predictions of POS taggers for several language pairs, including English, Figure 2: Type-level in-vocabulary tag errors as the percentage of word types assigned a set of tags that is disjoint, identical to, overlaps, is a subset, or is a superset of the Wiktionary tags. German, and Spanish to Czech and French. The resulting annotated target </context>
</contexts>
<marker>Fossum, Abney, 2005</marker>
<rawString>Victoria Fossum and Steven Abney. 2005. Automatically inducing a part-of-speech tagger by projecting from multiple source languages across aligned corpora. In IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Garrette</author>
<author>Jason Baldridge</author>
</authors>
<title>Learning a part-of-speech tagger from two hours of annotation.</title>
<date>2013</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="2533" citStr="Garrette and Baldridge (2013)" startWordPosition="384" endWordPosition="387">ll. However, for a surprisingly large number of languages, translations of the Bible (or parts of it) exist. Due to the canonical nature and the verse format, these translations are viable parallel data, albeit lacking annotation. In our experiments, we use word alignments across all pairs of 100 parallel Bible translations to bootstrap annotation projections for those languages without any (even just weakly) supervised taggers. The projections provide both pseudo-annotated data as well as tag dictionaries for all languages. We use both resources to train semi-supervised POS taggers following Garrette and Baldridge (2013). Our contributionWe present a novel approach to learning POS taggers for truly low-resource languages, where only a translation of (parts of) the Bible is available. We obtain results competitive with approaches that assume the availability of larger volumes of more representative parallel corpora, perfectly tokenized monolingual corpora, and/or tag dictionaries for the target languages. Additionally, we make the POS tagging models for 100 languages publicly available and extend the mappings in Petrov et al. (2011) for six new languages (Hindi, Croatian, Icelandic, Norwegian, Persian, and Ser</context>
<context position="10754" citStr="Garrette and Baldridge (2013)" startWordPosition="1880" endWordPosition="1883">ntences span multiple verses, which means, we sometimes train POS taggers on partial sentences. See Christodouloupoulos and Steedman (2014) for further discussion of the resource. Most of the manually annotated resources were obtained from the CoNLL 2006-2007 releases of various treebanks, the NLTK corpora, the HamleDT resources, and the Universal Dependencies project. We provide a complete overview of the resources athttps://bitbucket.org/lowlands/ ModelsWe train TNT POS taggers (Brants, 2000) using only token-level projections. We also train semi-supervised POS taggers using the approach in Garrette and Baldridge (2013) (GAR), using both projections and dictionaries, as well as the unlabelled Bible translations.3 We use the English data as development data. We train TNT and GAR 3github.com/dhgarrette/ low-resource-pos-tagging-2014/ using k or n − 1 source languages, leading to four taggers in total. Baselines Our baselines are two standard unsupervised POS induction algorithms: Brown clustering using the implementation by Percy Liang4 and second-order unsupervised HMMs using logistic regression for emission probabilities (BergKirkpatrick et al., 2010; Li et al., 2012), with and without our Bible tag dictiona</context>
</contexts>
<marker>Garrette, Baldridge, 2013</marker>
<rawString>Dan Garrette and Jason Baldridge. 2013. Learning a part-of-speech tagger from two hours of annotation. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shen Li</author>
<author>Jo˜ao Grac¸a</author>
<author>Ben Taskar</author>
</authors>
<title>Wiki-ly supervised part-of-speech tagging.</title>
<date>2012</date>
<booktitle>In EMNLP.</booktitle>
<marker>Li, Grac¸a, Taskar, 2012</marker>
<rawString>Shen Li, Jo˜ao Grac¸a, and Ben Taskar. 2012. Wiki-ly supervised part-of-speech tagging. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Slav Petrov</author>
<author>Keith Hall</author>
</authors>
<title>Multi-source transfer of delexicalized dependency parsers.</title>
<date>2011</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="1536" citStr="McDonald et al., 2011" startWordPosition="235" endWordPosition="238">ions, and is often competitive with weakly supervised approaches that assume high-quality parallel corpora, representative monolingual corpora with perfect tokenization, and/or tag dictionaries. We make models for all 100 languages available. 1 Introduction Most previous work in cross-lingual NLP has been limited to training and evaluating on no more than a dozen languages, typically all from the major Indo-European languages. While it has been observed repeatedly that using multiple source languages improves performance (Yarowsky et al., 2001; Yarowsky and Ngai, 2001; Fossum and Abney, 2005; McDonald et al., 2011), most available techniques work best for closely related languages. In contrast, this paper presents an effort to learn POS taggers for truly low-resource languages, with minimum assumptions about the available language resources. Most low-resource languages are non-Indo-European, and typically, their typological and geographic neighbors have sparse resources as well. However, for a surprisingly large number of languages, translations of the Bible (or parts of it) exist. Due to the canonical nature and the verse format, these translations are viable parallel data, albeit lacking annotation. I</context>
</contexts>
<marker>McDonald, Petrov, Hall, 2011</marker>
<rawString>Ryan McDonald, Slav Petrov, and Keith Hall. 2011. Multi-source transfer of delexicalized dependency parsers. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dipanjan Das</author>
<author>Ryan McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2011</date>
<note>CoRR abs/1104.2086.</note>
<contexts>
<context position="3054" citStr="Petrov et al. (2011)" startWordPosition="464" endWordPosition="467"> We use both resources to train semi-supervised POS taggers following Garrette and Baldridge (2013). Our contributionWe present a novel approach to learning POS taggers for truly low-resource languages, where only a translation of (parts of) the Bible is available. We obtain results competitive with approaches that assume the availability of larger volumes of more representative parallel corpora, perfectly tokenized monolingual corpora, and/or tag dictionaries for the target languages. Additionally, we make the POS tagging models for 100 languages publicly available and extend the mappings in Petrov et al. (2011) for six new languages (Hindi, Croatian, Icelandic, Norwegian, Persian, and Serbian). The models, mappings, as well as a complete list of all the resources used in these experiments, are available at https://bitbucket.org/lowlands/. 2 Experiments Our approach is a combination of simple techniques. Part of the process is depicted in Figure 1, and the algorithm is presented in Algorithm 1. Assume we have n languages for which we assume the availability of m verses of the Bible. We run IBM-21 on all n(n − 1) pairs of languages. Assume also manually POS-annotated training data 1github.com/clab/fas</context>
</contexts>
<marker>Petrov, Das, McDonald, 2011</marker>
<rawString>Slav Petrov, Dipanjan Das, and Ryan McDonald. 2011. A universal part-of-speech tagset. CoRR abs/1104.2086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katharina Probst</author>
</authors>
<title>Using ‘smart’ bilingual projection to feature-tag a monolingual dictionary. In CoNLL.</title>
<date>2003</date>
<contexts>
<context position="15278" citStr="Probst (2003)" startWordPosition="2587" endWordPosition="2588">tical to, overlaps, is a subset, or is a superset of the Wiktionary tags. German, and Spanish to Czech and French. The resulting annotated target language corpora enable them to train POS taggers for these languages. Yarowsky and Ngai (2001) showed similar results using just the Hansards corpus on English to French and Chinese. Our work is inspired by these approaches, yet broader in scope on both the source and target side. Das and Petrov (2011) use word-aligned text to automatically create type-level tag dictionaries. Earlier work on building tag dictionaries from word-aligned text includes Probst (2003). Their tag dictionaries contain target language trigrams to be able to disambiguate ambiguous target language words. To handle the noise in the automatically obtained dictionaries, they use label propagation on a similarity graph to smooth and expand the label distributions. Our approach is similar to theirs in using projections to obtain type-level tag dictionaries, but we keep the token supervision and type supervision apart and end up with a model more similar to that of T¨ackstr¨om et al. (2013), who combine word-aligned text with crowdsourced type-level tag dictionaries. T¨ackstr¨om et a</context>
</contexts>
<marker>Probst, 2003</marker>
<rawString>Katharina Probst. 2003. Using ‘smart’ bilingual projection to feature-tag a monolingual dictionary. In CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Sukhareva</author>
<author>Christian Chiarcos</author>
</authors>
<title>Diachronic proximity vs. data sparsity in cross-lingual parser projection.</title>
<date>2014</date>
<booktitle>In COLING Workshop on Applying NLP Tools to Similar Languages, Varieties and Dialects.</booktitle>
<contexts>
<context position="14341" citStr="Sukhareva and Chiarcos, 2014" startWordPosition="2438" endWordPosition="2441">t. For three languages, results were 80-90%: Afrikaans, Lithuanian, and Russian. For another three languages, results were 50-70%: Hebrew, Romanian, and Swahili. Results were 35-50% for the remaining four languages: Latin, Maori, Albanian, and Ewe. 3 Related work The Bible has been used as a resource for machine translation and multi-lingual information retrieval before, e.g., (Chew et al., 2006). It has also been used in cross-lingual POS tagging (Yarowsky et al., 2001; Fossum and Abney, 2005), NP-chunking (Yarowsky et al., 2001; Yarowsky and Ngai, 2001) and cross-lingual dependency parsing (Sukhareva and Chiarcos, 2014) before. Yarowsky et al. (2001) and Fossum and Abney (2005) use word-aligned parallel translations of the Bible to project the predictions of POS taggers for several language pairs, including English, Figure 2: Type-level in-vocabulary tag errors as the percentage of word types assigned a set of tags that is disjoint, identical to, overlaps, is a subset, or is a superset of the Wiktionary tags. German, and Spanish to Czech and French. The resulting annotated target language corpora enable them to train POS taggers for these languages. Yarowsky and Ngai (2001) showed similar results using just </context>
</contexts>
<marker>Sukhareva, Chiarcos, 2014</marker>
<rawString>Maria Sukhareva and Christian Chiarcos. 2014. Diachronic proximity vs. data sparsity in cross-lingual parser projection. In COLING Workshop on Applying NLP Tools to Similar Languages, Varieties and Dialects.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Token and type constraints for cross-lingual part-of-speech tagging.</title>
<date>2013</date>
<tech>TACL,</tech>
<pages>1--1</pages>
<marker>T¨ackstr¨om, Das, Petrov, McDonald, Nivre, 2013</marker>
<rawString>Oscar T¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan McDonald, and Joakim Nivre. 2013. Token and type constraints for cross-lingual part-of-speech tagging. TACL, 1:1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
</authors>
<title>Inducing multilingual pos taggers and np brackets via robust projection across aligned corpora. In</title>
<date>2001</date>
<booktitle>Proceedings of NAACL.</booktitle>
<contexts>
<context position="1488" citStr="Yarowsky and Ngai, 2001" startWordPosition="226" endWordPosition="229">upervised POS taggers induced from Bible translations, and is often competitive with weakly supervised approaches that assume high-quality parallel corpora, representative monolingual corpora with perfect tokenization, and/or tag dictionaries. We make models for all 100 languages available. 1 Introduction Most previous work in cross-lingual NLP has been limited to training and evaluating on no more than a dozen languages, typically all from the major Indo-European languages. While it has been observed repeatedly that using multiple source languages improves performance (Yarowsky et al., 2001; Yarowsky and Ngai, 2001; Fossum and Abney, 2005; McDonald et al., 2011), most available techniques work best for closely related languages. In contrast, this paper presents an effort to learn POS taggers for truly low-resource languages, with minimum assumptions about the available language resources. Most low-resource languages are non-Indo-European, and typically, their typological and geographic neighbors have sparse resources as well. However, for a surprisingly large number of languages, translations of the Bible (or parts of it) exist. Due to the canonical nature and the verse format, these translations are vi</context>
<context position="14273" citStr="Yarowsky and Ngai, 2001" startWordPosition="2430" endWordPosition="2433">re every tag assignment licensed by Wiktionary counts as correct. For three languages, results were 80-90%: Afrikaans, Lithuanian, and Russian. For another three languages, results were 50-70%: Hebrew, Romanian, and Swahili. Results were 35-50% for the remaining four languages: Latin, Maori, Albanian, and Ewe. 3 Related work The Bible has been used as a resource for machine translation and multi-lingual information retrieval before, e.g., (Chew et al., 2006). It has also been used in cross-lingual POS tagging (Yarowsky et al., 2001; Fossum and Abney, 2005), NP-chunking (Yarowsky et al., 2001; Yarowsky and Ngai, 2001) and cross-lingual dependency parsing (Sukhareva and Chiarcos, 2014) before. Yarowsky et al. (2001) and Fossum and Abney (2005) use word-aligned parallel translations of the Bible to project the predictions of POS taggers for several language pairs, including English, Figure 2: Type-level in-vocabulary tag errors as the percentage of word types assigned a set of tags that is disjoint, identical to, overlaps, is a subset, or is a superset of the Wiktionary tags. German, and Spanish to Czech and French. The resulting annotated target language corpora enable them to train POS taggers for these la</context>
<context position="16537" citStr="Yarowsky and Ngai (2001)" startWordPosition="2783" endWordPosition="2786">via type-level tag dictionaries, pruning all tags not licensed by the dictionary. For the remaining tags, they use high-confidence word alignments to further prune the Viterbi search. We follow T¨ackstr¨om et al. (2013) in using our automatically created, not crowdsourced, tag dictionaries to prune tags during search, but we use word alignments to obtain token-level annotations that we use as annotated training data, similar to Fossum identical overlap subset superset afr als ewe heb lat lit mri ron rus swh disjoint 100 80 60 % entries 40 20 0 271 and Abney (2005), Yarowsky et al. (2001), and Yarowsky and Ngai (2001). Duong et al. (2013) use word-alignment probabilities to select training data for their cross-lingual POS models. They consider a simple single-source training set-up. We also tried ranking projected training data by confidence, using an ensemble of projections from 17–99 source languages and majority voting to obtain probabilities for the token-level target-language projections, but this did not lead to improvements on the English development data. 4 Conclusions We present a novel approach to learning POS taggers, assuming only that parts of the Bible are available for the target language. O</context>
</contexts>
<marker>Yarowsky, Ngai, 2001</marker>
<rawString>David Yarowsky and Grace Ngai. 2001. Inducing multilingual pos taggers and np brackets via robust projection across aligned corpora. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
<author>Richard Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of the first international conference on Human language technology research.</booktitle>
<contexts>
<context position="1463" citStr="Yarowsky et al., 2001" startWordPosition="222" endWordPosition="225">an state-of-the-art unsupervised POS taggers induced from Bible translations, and is often competitive with weakly supervised approaches that assume high-quality parallel corpora, representative monolingual corpora with perfect tokenization, and/or tag dictionaries. We make models for all 100 languages available. 1 Introduction Most previous work in cross-lingual NLP has been limited to training and evaluating on no more than a dozen languages, typically all from the major Indo-European languages. While it has been observed repeatedly that using multiple source languages improves performance (Yarowsky et al., 2001; Yarowsky and Ngai, 2001; Fossum and Abney, 2005; McDonald et al., 2011), most available techniques work best for closely related languages. In contrast, this paper presents an effort to learn POS taggers for truly low-resource languages, with minimum assumptions about the available language resources. Most low-resource languages are non-Indo-European, and typically, their typological and geographic neighbors have sparse resources as well. However, for a surprisingly large number of languages, translations of the Bible (or parts of it) exist. Due to the canonical nature and the verse format, </context>
<context position="14186" citStr="Yarowsky et al., 2001" startWordPosition="2417" endWordPosition="2420">r to the ones used in Li et al. (2012). We also computed token-level accuracies, where every tag assignment licensed by Wiktionary counts as correct. For three languages, results were 80-90%: Afrikaans, Lithuanian, and Russian. For another three languages, results were 50-70%: Hebrew, Romanian, and Swahili. Results were 35-50% for the remaining four languages: Latin, Maori, Albanian, and Ewe. 3 Related work The Bible has been used as a resource for machine translation and multi-lingual information retrieval before, e.g., (Chew et al., 2006). It has also been used in cross-lingual POS tagging (Yarowsky et al., 2001; Fossum and Abney, 2005), NP-chunking (Yarowsky et al., 2001; Yarowsky and Ngai, 2001) and cross-lingual dependency parsing (Sukhareva and Chiarcos, 2014) before. Yarowsky et al. (2001) and Fossum and Abney (2005) use word-aligned parallel translations of the Bible to project the predictions of POS taggers for several language pairs, including English, Figure 2: Type-level in-vocabulary tag errors as the percentage of word types assigned a set of tags that is disjoint, identical to, overlaps, is a subset, or is a superset of the Wiktionary tags. German, and Spanish to Czech and French. The re</context>
<context position="16507" citStr="Yarowsky et al. (2001)" startWordPosition="2778" endWordPosition="2781">3) constrain Viterbi search via type-level tag dictionaries, pruning all tags not licensed by the dictionary. For the remaining tags, they use high-confidence word alignments to further prune the Viterbi search. We follow T¨ackstr¨om et al. (2013) in using our automatically created, not crowdsourced, tag dictionaries to prune tags during search, but we use word alignments to obtain token-level annotations that we use as annotated training data, similar to Fossum identical overlap subset superset afr als ewe heb lat lit mri ron rus swh disjoint 100 80 60 % entries 40 20 0 271 and Abney (2005), Yarowsky et al. (2001), and Yarowsky and Ngai (2001). Duong et al. (2013) use word-alignment probabilities to select training data for their cross-lingual POS models. They consider a simple single-source training set-up. We also tried ranking projected training data by confidence, using an ensemble of projections from 17–99 source languages and majority voting to obtain probabilities for the token-level target-language projections, but this did not lead to improvements on the English development data. 4 Conclusions We present a novel approach to learning POS taggers, assuming only that parts of the Bible are availa</context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>David Yarowsky, Grace Ngai, and Richard Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proceedings of the first international conference on Human language technology research.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>