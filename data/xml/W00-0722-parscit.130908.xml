<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.064335">
<note confidence="0.816245">
In: Proceedings of CoNLL-2000 and LLL-2000, pages 111-114, Lisbon, Portugal, 2000.
</note>
<title confidence="0.997983">
Minimal Commitment and Full Lexical Disambiguation:
Balancing Rules and Hidden Markov Models
</title>
<author confidence="0.9994">
Patrick Ruch and Robert Baud and Pierrette Bouillon and Gilbert Robert*
</author>
<affiliation confidence="0.9996275">
Medical Informatics Division, University Hospital of Geneva
ISSCO, University of Geneva
</affiliation>
<email confidence="0.924629">
fruch, baudl@dim.hcuge .ch, {bouillon, robert}@issco .unige.ch
</email>
<sectionHeader confidence="0.981231" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999306125">
In this paper we describe the construction of
a part-of-speech tagger both for medical doc-
ument retrieval purposes and XP extraction.
Therefore we have designed a double system: for
retrieval purposes, we rely on a rule-based ar-
chitecture, called minimal commitment, which
is likely to be completed by a data-driven tool
(HMM) when full disambiguation is necessary.
</bodyText>
<sectionHeader confidence="0.995511" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.990891444444444">
Nowadays, most medical information is stored
in textual documents&apos;, but such large amount
of data may remain useless if retrieving the rel-
evant information in a reasonable time becomes
impossible. Although some large-scale informa-
tion retrieval (IR) evaluations, made on unre-
stricted corpora (Hersh and al., 1998), and on
medical texts (Hersh, 1998), are quite critical
towards linguistic engineering, we believe that
natural language processing is the best solution
to face two major problems of text retrieval en-
gines: expansion of the query and lexical dis-
ambiguation. Disambiguation can be separated
between MS (morpho-syntactic, i.e. the part-of-
speech (PUS) and some other features) and WS
(word-sense) disambiguation. Although we aim
at developing a common architecture for pro-
cessing both the MS and the WS disambigua-
tion (Ruch and al., 1999), this paper focuses on
the MS tagging.
* We would like to thank Thierry Etchegoyhen and Erik
Tjong Kim Sang for their helpful assistance while writing
this paper. The Swiss National Fundation supported the
present study.
&apos;While our studies were made on French corpora, the
examples are provided in English -when possible- for the
sake of clarity.
</bodyText>
<sectionHeader confidence="0.917407" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999976647058824">
Before starting to develop our own MS tagger,
some preliminary studies on general available
systems were conducted; if these studies go far
beyong the scope of this paper, we would like
to report on the main conclusions. Both statis-
tical taggers (HMM) and constraint-based sys-
tems were assessed. Two guidelines were fram-
ing the study: performances and minimal com-
mitment. We call minimal commitment2 the
property of a system, which does not attempt
to solve ambiguities when it is not likely to solve
it well! Such property seems important for IR
purposes, where we might prefer noise rather
than silence in the recall process. However, it
must remain optional, as some other tasks (such
as the NP extraction, or the phrase chunking
(Abney, 1991)) may need a full disambiguation.
</bodyText>
<subsectionHeader confidence="0.837265">
2.1 Data-driven tools
</subsectionHeader>
<bodyText confidence="0.999848083333333">
We adapted the output of our morphological
analyser for tagging purposes (Bouillon et al.,
1999). We trained and wrote manual biases
for an HMM tagger, but results were never far
above 97% (i.e. about 3% of error); with an av-
erage ambiguity level of around 16%, it means
that almost 20% of the ambiguities were at-
tributed a wrong tag! We attempted to set
a confidence threshold, so that for similarly
weighted transitions, the system would keep the
ambiguity, as in (Weischedel and al., 1993), but
results were not satisfying.
</bodyText>
<subsectionHeader confidence="0.990757">
2.2 Constraint-based systems
</subsectionHeader>
<bodyText confidence="0.991999">
We also looked at more powerful principle-
based parsers, and tests were conducted on
</bodyText>
<footnote confidence="0.998185666666667">
2The first one using this expression was maybe M.
Marcus, lately we can find a quite similar idea in Sil-
berztein (1997).
</footnote>
<page confidence="0.994715">
111
</page>
<table confidence="0.996231785714286">
Token Lemma Lexical tag(s)
fast fast a
section section nc[s]
of of sp
the the dad
internal internal a
faces face/to face nc[p]/v[s03]
Token Lexical tags Disambiguated tag
fast a a
section nc[s] nc[s]
of sp sp
the dad dad
internal a a
faces nc[p]/v[s03] nc[p]
</table>
<tableCaption confidence="0.9697155">
Table 1: Tag-like representation of MS lexical
features
</tableCaption>
<bodyText confidence="0.99420075">
FIPSTAG3 (a Government and Binding chart-
parser (Wehrli, 1992)). Although this system
performed well on general texts, with about
0.7% of errors, its results on medical texts
were about the same as stochastic taggers. As
we could not adapt our medical morphological
analyser on this very integrated system, it had
to cope with several unknown words.
</bodyText>
<sectionHeader confidence="0.997095" genericHeader="method">
3 Methods
</sectionHeader>
<bodyText confidence="0.999981454545455">
In order to assess the system, we selected a
corpus (40000 tokens) based equally on three
types of documents: reports of surgery, dis-
charge summaries and follow-up notes. This ad
hoc corpus is split into 5 equivalent sets. The
first one (set A, 8520 words) will serve to write
the basic rules of the tagger, while the other sets
(set B, 8480 tokens, C, 7447 tokens, D, 7311
tokens, and E, 8242 tokens), will be used for
assessment purposes and incremental improve-
ments of the system.
</bodyText>
<subsectionHeader confidence="0.997025">
3.1 Lexicon, morphological analysis
and guesser
</subsectionHeader>
<bodyText confidence="0.999990166666667">
The lexicon, with around 20000 entries, covers
exhaustively the whole ICD-10. The morpho-
logical analyser is morpheme-based (Baud et al.,
1998), it maps each inflected surface form of a
word to its canonical lexical form, followed by
the relevant morphological features. Words ab-
sent from the lexicon follow a two-step guess-
ing process. First, the unknown token is anal-
ysed regarding its respective morphemes, if this
first stage fails then a last attempt is made to
guess the hypothetical MS tags of the token.
The first stage is based on the assumption that
</bodyText>
<footnote confidence="0.99595325">
3For a MULTEXT-like description of the FTP-
STAG tagset see Ruch P, 1997: Table de COT-
respondance GRACE/FIPSTAG, available at
http://latl.unige.ch/doc/etiquettes.ps
</footnote>
<tableCaption confidence="0.98924">
Table 2: Example of tagging
</tableCaption>
<bodyText confidence="0.999837375">
unknown words in medical documents are very
likely to belong to the medical jargon, the sec-
ond one supposed that neologisms follow regular
inflectional patterns. If regarding the morpho-
syntax, both stages are functionally equivalent,
as each one provides a set of morpho-syntactic
information, they radically behave differently
regarding the WS information. For guessing
WS categories only the first stage guesser is
relevant, as inflectional patterns are not suffi-
cient for guessing the semantic of a given token.
Thus, the ending able characterises very proba-
bly an adjective, but does not provide any se-
mantic information4 on it.
Let us consider two examples of words absent
from the lexicon. First, allomorph: the prefix
part allo, and the suffix part, morph, are listed
in the lexicon, with all the MS and the WS fea-
tures, therefore it is recognized by the first-stage
guesser. Second, allocution, it can not be split
into any affix, as cution is not a morpheme, but
the ending tion refers to some features (noun,
singular) in the second-stage guesser. As the
underlying objective of the project is to retrieve
documents, the main and most complete infor-
mation is provided by the first-stage guesser,
and the second-stage is only interesting for MS
tagging, as in (Chanod and Tapanainen, 1995).
Finally (tab. 1), some of the morpho-syntactic
features provided by the lemmatizer are ex-
pressed into the MS tagset5, to be processed
by the tagger (tab. 2).
</bodyText>
<footnote confidence="0.999325857142857">
4A minimal set of lexical semantic types, based on
the UMLS, has been defined in (Ruch and al., 1999).
5The MS tagset tends to follow the MULTEXT lexi-
cal description for French, modified within the GRACE
action (http://www.limsi.fr/TLP/grace/doc/GTR-3-
2.1.tex). However, it is not always possible, as this
description does not allow any morpheme annotation.
</footnote>
<page confidence="0.99067">
112
</page>
<table confidence="0.9996835">
Evaluation 1-Set B 2-Set C 3-Set D 4-Set E
Tokens with lexical ambiguities 1178 (13.9) 1273 (17.1) 1132 (15.5) 1221 (14.8)
Tokens correctly tagged 8243 (97.2) 7177 (96.4) 7137 (97.6) 8082 (98.1)
Tokens still ambiguous, with GC 161 (1.9) 183 (2.5) 136 (1.9) 101 (1.2)
Tokens ambiguous, without GC - 9 (0.1) 2 (0) 9 (0.1)
Tokens incorrectly tagged 76 (0.9) 78 (1.0) 36 (0.5) 51(0.6)
</table>
<tableCaption confidence="0.956345">
Table 3: Results for each evaluation (GC stands for good candidates)
</tableCaption>
<table confidence="0.885165333333333">
Statistical evaluation on the residual ambiguity MFT HMM
Tokens correctly tagged 8136 (98.7) 8165 (99.1)
Tokens incorrectly tagged 107 (1.3) 78 (0.9)
</table>
<tableCaption confidence="0.999208">
Table 4: Processing the residual ambiguity
</tableCaption>
<subsectionHeader confidence="0.999884">
3.2 Studying the ambiguities
</subsectionHeader>
<bodyText confidence="0.99980945">
Our first investigations aimed at assessing the
overall ambiguity of medical texts. We found
that 1227 tokens (14.4% of the whole sample6)
were ambiguous in set A, and 511 tokens (6.0%)
were unknown. We first decided not to care
about unknown words, therefore they were not
taking into account in the first assessment (cf.
Performances). However, some frequent words
were missing, so that together with the MS
guesser, we would improve the guessing score by
adding some lexemes. Thus, adding 232 entries
in the lexicon and linking it with the Swiss com-
pendium (for drugs and chemicals) provides an
unknown word rate of less than 3%. This result
includes also the pre-processing of patients and
physicians names (Ruch and al., 2000). Con-
cerning the ambiguities, we found that 5 to-
kens were responsible for half of the ambiguities,
while in unrestricted corpora this number seems
around 16 (Chanod and Tapanainen, 1995).
</bodyText>
<subsectionHeader confidence="0.933704">
3.2.1 Local rules
</subsectionHeader>
<bodyText confidence="0.9999434">
We separated the set A in 8 subsets of about
1000 tokens, in order to write the rules. We
wrote around 50 rules (which generated more
than 150 operative rules) for the first subset,
while for the 8th, only 12 rules were necessary
to reach a score close to 100% on set A. These
rules are using intermediate symbols (such as
the Kleene star) in order to ease and improve
the rule-writing process, these symbols are re-
placed when the operative rules are generated.
</bodyText>
<footnote confidence="0.956671">
6For comparison, the average ambiguity rate is about
25-30% in unrestricted corpora.
</footnote>
<bodyText confidence="0.964379">
Here is an example of a rule:
proprIvr*Unc[**] -4 proprbv[**]
This rule says &apos;if a token is ambiguous be-
tween (/) a verb (v), whatever (**) features it
has (3rd or lst/2nd person, singular or plural),
and a common noun, whatever (**) features it
has, and such token is preceded by a personal
pronoun (prop), whatever (**) features this pro-
noun has (3rd or lst/2nd person), then the am-
biguous token can be rewritten as a verb, keep-
ing its original features (**)&apos;.
</bodyText>
<sectionHeader confidence="0.999573" genericHeader="method">
4 Performances
</sectionHeader>
<subsectionHeader confidence="0.996315">
4.1 Maximizing the minimal
commitment
</subsectionHeader>
<bodyText confidence="0.9998015">
Four successive evaluations were conducted
(tab. 3); after each session, the necessary rules
were added in order to get a tagging score close
to 100%. In parallel, words were entered into
the lexicon, and productive endings were added
into the MS guesser. The second, third, and
fourth evaluations were performed with activat-
ing the MS guesser. Let us note that translation
phenomena (Paroubek and al., 1998), which
turn the lexical category of a word into another
one, seem rare in medical texts (only 3 cases
were not foreseen in the lexicon).
A success rate of 98% (tab. 3, evaluation
4) is not a bad result for a tagger, but the
main result concerns the error rate, with less
than 1% of error, the system seems particularly
minimally committed7. Another interesting re-
sult concerns the residual ambiguity (tokens still
</bodyText>
<footnote confidence="0.913545">
7Let us note that in the assessment 1, the system had
</footnote>
<page confidence="0.998782">
113
</page>
<bodyText confidence="0.999770545454545">
ambiguous, with GC): in the set E, at least half
of these ambiguities could be handled by writ-
ing more rules. However some of these ambigui-
ties are clearly untractable with such contextual
rules, and would demand more lexical informa-
tion, as in le patient presente une douleur ab-
dominale brutale et diffuse (the patient shows
an acute and diffuse abdominal pain/the pa-
tient shows an acute abdominal pain and dis-
tributes*8), where diffuse could be adjective or
verb.
</bodyText>
<subsectionHeader confidence="0.98873">
4.2 Maximizing the success rate
</subsectionHeader>
<bodyText confidence="0.999920357142857">
A last experiment is made: on the set E, which
has been disambiguated by the rule-based tag-
ger, we decided to apply two more disambigua-
tions, in order to handle the residual ambi-
guity. First, we apply the most frequent tag
(MFT) model, as baseline, then the HMM. Both
the MFT and the HMM transitions are calcu-
lated on the set B+C+D, tagged manually, but
without any manual improvement (bias) of the
model.
Table 4 shows that for the residual ambiguity,
i.e. the ambiguity, which remained untractable
by the rule-based tagger, the HMM provides an
interesting disambiguation accuracy9.
</bodyText>
<sectionHeader confidence="0.99651" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999629">
We have presented a rule-based tagger for elec-
tronic medical records. The first target of
this tool is the disambiguation for IR purposes,
therefore we decided to design a system with-
out any heuristics. As second target, the system
will be used for conducting NP extraction tasks
and shallow parsing: the system must be able
to provide a fully disambiguated output; there-
fore we used the HMM tool for completing the
disambiguation task.
</bodyText>
<sectionHeader confidence="0.990207" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.5445988">
Abney, Steven. 1991. Parsing by chunks. In R.
Berwick and S. Abney and C. Tenny, editors,
Principle-based parsing, pages 257-278. Kluwer.
Robert Baud, C. Lovis, and AM. Rassinoux. 1998.
Morpho-semantic parsing of medical expressions.
</reference>
<footnote confidence="0.861002571428571">
about 1000 operative rules, while the assessment 4 was
conducted with more than 2000 rules.
8The lexical information on the valence + OBJECT
is necessary for disambiguating the verb form of diffuse.
8The accuracy of the HMM tagger, on the fully am-
biguous version of set E, was 96.3%, while the MFT per-
formed about 93.5%.
</footnote>
<reference confidence="0.997813853658537">
In Proceedings of AMIA&apos;1998, pages 760-764, Or-
lando.
Pierrette Bouillon, R Baud, G Robert, and P Ruch.
1999. Indexing by statistical tagging. In Proceed-
ings of the JADT&apos;2000, pages 35-42, Lausanne.
Jean-Pierre Chanod and Path Tapanainen. 1995.
Tagging french: comparing a statistical and
a constraint-based method. In Proceedings of
EACL&apos;95, pages 149-156, Dublin.
William, Hersh and S. Price and D. Kraemer and
B. Chan and L. Sacherek and D. Olson. 1998.
A large-scale comparison of boolean vs. natural
language searching for the trec-7 interactive track.
In TREC 1998, pages 429-438.
William Hersh. 1998. Information retrieval at the
millenium. In Proceedings of AMIA &apos;1998, pages
38-45, Lake Buena Vista, FL.
Paroubek, Patrick and G. Adda and J. Mariani and
J. Lecomte and M. Rajman. 1998. The GRACE
french part-of-speech tagging evaluation task. In
Proceedings of LREC&apos;1998, Granada.
Ruch, Patrick and J. Wagner and P. Bouillon and R.
Baud and A.-M. Rassinoux and G. Robert. 1999.
Medtag: Tag-like semantics for medical document
indexing. In Proceedings of A MIA &apos;99, pages 35-
42, Washington.
Ruch, Patrick and R. Baud and A.-M. Rassinoux
and P. Bouillon and G. Robert 2000. Medical
document anonymization with a semantic lexicon.
In Proceedings of AMIA&apos;2000, Los Angeles.
Max Silberztein. 1997. The lexical analysis of nat-
ural languages. In Emmanuel Roche and Yves
Shabes, editors, Finite-State Language Process-
ing, pages 176-205. MIT Press.
Eric Wehrli. 1992. The IPS system. In Proceedings
COLING-92, pages 870-874.
Weischedel, Ralph and M. Meeler and R. Shwartz
and L. Ramshaw and J. Palmucci, 1993. Cop-
ing with ambiguity and unknown words through
probabilistic models. Computational Linguistics,
19(2):359-382.
</reference>
<page confidence="0.998635">
114
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.404754">
<note confidence="0.962682">of CoNLL-2000 and LLL-2000, Lisbon, Portugal, 2000.</note>
<title confidence="0.9659025">Minimal Commitment and Full Lexical Balancing Rules and Hidden Markov Models</title>
<author confidence="0.960792">Ruch Baud Bouillon</author>
<affiliation confidence="0.923197">Medical Informatics Division, University Hospital of ISSCO, University of</affiliation>
<email confidence="0.508611">.ch,{bouillon,robert}@issco.unige.ch</email>
<abstract confidence="0.997762444444445">In this paper we describe the construction of a part-of-speech tagger both for medical document retrieval purposes and XP extraction. Therefore we have designed a double system: for retrieval purposes, we rely on a rule-based architecture, called minimal commitment, which is likely to be completed by a data-driven tool (HMM) when full disambiguation is necessary.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Parsing by chunks.</title>
<date>1991</date>
<booktitle>Principle-based parsing,</booktitle>
<pages>257--278</pages>
<editor>In R. Berwick and S. Abney and C. Tenny, editors,</editor>
<publisher>Kluwer.</publisher>
<contexts>
<context position="2745" citStr="Abney, 1991" startWordPosition="422" endWordPosition="423">o far beyong the scope of this paper, we would like to report on the main conclusions. Both statistical taggers (HMM) and constraint-based systems were assessed. Two guidelines were framing the study: performances and minimal commitment. We call minimal commitment2 the property of a system, which does not attempt to solve ambiguities when it is not likely to solve it well! Such property seems important for IR purposes, where we might prefer noise rather than silence in the recall process. However, it must remain optional, as some other tasks (such as the NP extraction, or the phrase chunking (Abney, 1991)) may need a full disambiguation. 2.1 Data-driven tools We adapted the output of our morphological analyser for tagging purposes (Bouillon et al., 1999). We trained and wrote manual biases for an HMM tagger, but results were never far above 97% (i.e. about 3% of error); with an average ambiguity level of around 16%, it means that almost 20% of the ambiguities were attributed a wrong tag! We attempted to set a confidence threshold, so that for similarly weighted transitions, the system would keep the ambiguity, as in (Weischedel and al., 1993), but results were not satisfying. 2.2 Constraint-ba</context>
</contexts>
<marker>Abney, 1991</marker>
<rawString>Abney, Steven. 1991. Parsing by chunks. In R. Berwick and S. Abney and C. Tenny, editors, Principle-based parsing, pages 257-278. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rassinoux</author>
</authors>
<title>Morpho-semantic parsing of medical expressions.</title>
<date>1998</date>
<booktitle>In Proceedings of AMIA&apos;1998,</booktitle>
<pages>760--764</pages>
<location>Orlando.</location>
<marker>Rassinoux, 1998</marker>
<rawString>Robert Baud, C. Lovis, and AM. Rassinoux. 1998. Morpho-semantic parsing of medical expressions. In Proceedings of AMIA&apos;1998, pages 760-764, Orlando.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierrette Bouillon</author>
<author>R Baud</author>
<author>G Robert</author>
<author>P Ruch</author>
</authors>
<title>Indexing by statistical tagging.</title>
<date>1999</date>
<booktitle>In Proceedings of the JADT&apos;2000,</booktitle>
<pages>35--42</pages>
<location>Lausanne.</location>
<contexts>
<context position="2897" citStr="Bouillon et al., 1999" startWordPosition="443" endWordPosition="446">tems were assessed. Two guidelines were framing the study: performances and minimal commitment. We call minimal commitment2 the property of a system, which does not attempt to solve ambiguities when it is not likely to solve it well! Such property seems important for IR purposes, where we might prefer noise rather than silence in the recall process. However, it must remain optional, as some other tasks (such as the NP extraction, or the phrase chunking (Abney, 1991)) may need a full disambiguation. 2.1 Data-driven tools We adapted the output of our morphological analyser for tagging purposes (Bouillon et al., 1999). We trained and wrote manual biases for an HMM tagger, but results were never far above 97% (i.e. about 3% of error); with an average ambiguity level of around 16%, it means that almost 20% of the ambiguities were attributed a wrong tag! We attempted to set a confidence threshold, so that for similarly weighted transitions, the system would keep the ambiguity, as in (Weischedel and al., 1993), but results were not satisfying. 2.2 Constraint-based systems We also looked at more powerful principlebased parsers, and tests were conducted on 2The first one using this expression was maybe M. Marcus</context>
</contexts>
<marker>Bouillon, Baud, Robert, Ruch, 1999</marker>
<rawString>Pierrette Bouillon, R Baud, G Robert, and P Ruch. 1999. Indexing by statistical tagging. In Proceedings of the JADT&apos;2000, pages 35-42, Lausanne.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Pierre Chanod</author>
<author>Path Tapanainen</author>
</authors>
<title>Tagging french: comparing a statistical and a constraint-based method.</title>
<date>1995</date>
<booktitle>In Proceedings of EACL&apos;95,</booktitle>
<pages>149--156</pages>
<location>Dublin.</location>
<contexts>
<context position="6820" citStr="Chanod and Tapanainen, 1995" startWordPosition="1092" endWordPosition="1095"> absent from the lexicon. First, allomorph: the prefix part allo, and the suffix part, morph, are listed in the lexicon, with all the MS and the WS features, therefore it is recognized by the first-stage guesser. Second, allocution, it can not be split into any affix, as cution is not a morpheme, but the ending tion refers to some features (noun, singular) in the second-stage guesser. As the underlying objective of the project is to retrieve documents, the main and most complete information is provided by the first-stage guesser, and the second-stage is only interesting for MS tagging, as in (Chanod and Tapanainen, 1995). Finally (tab. 1), some of the morpho-syntactic features provided by the lemmatizer are expressed into the MS tagset5, to be processed by the tagger (tab. 2). 4A minimal set of lexical semantic types, based on the UMLS, has been defined in (Ruch and al., 1999). 5The MS tagset tends to follow the MULTEXT lexical description for French, modified within the GRACE action (http://www.limsi.fr/TLP/grace/doc/GTR-3- 2.1.tex). However, it is not always possible, as this description does not allow any morpheme annotation. 112 Evaluation 1-Set B 2-Set C 3-Set D 4-Set E Tokens with lexical ambiguities 11</context>
<context position="8932" citStr="Chanod and Tapanainen, 1995" startWordPosition="1434" endWordPosition="1437">ount in the first assessment (cf. Performances). However, some frequent words were missing, so that together with the MS guesser, we would improve the guessing score by adding some lexemes. Thus, adding 232 entries in the lexicon and linking it with the Swiss compendium (for drugs and chemicals) provides an unknown word rate of less than 3%. This result includes also the pre-processing of patients and physicians names (Ruch and al., 2000). Concerning the ambiguities, we found that 5 tokens were responsible for half of the ambiguities, while in unrestricted corpora this number seems around 16 (Chanod and Tapanainen, 1995). 3.2.1 Local rules We separated the set A in 8 subsets of about 1000 tokens, in order to write the rules. We wrote around 50 rules (which generated more than 150 operative rules) for the first subset, while for the 8th, only 12 rules were necessary to reach a score close to 100% on set A. These rules are using intermediate symbols (such as the Kleene star) in order to ease and improve the rule-writing process, these symbols are replaced when the operative rules are generated. 6For comparison, the average ambiguity rate is about 25-30% in unrestricted corpora. Here is an example of a rule: pro</context>
</contexts>
<marker>Chanod, Tapanainen, 1995</marker>
<rawString>Jean-Pierre Chanod and Path Tapanainen. 1995. Tagging french: comparing a statistical and a constraint-based method. In Proceedings of EACL&apos;95, pages 149-156, Dublin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hersh William</author>
<author>S Price</author>
<author>D Kraemer</author>
<author>B Chan</author>
<author>L Sacherek</author>
<author>D Olson</author>
</authors>
<date>1998</date>
<marker>William, Price, Kraemer, Chan, Sacherek, Olson, 1998</marker>
<rawString>William, Hersh and S. Price and D. Kraemer and B. Chan and L. Sacherek and D. Olson. 1998.</rawString>
</citation>
<citation valid="true">
<title>A large-scale comparison of boolean vs. natural language searching for the trec-7 interactive track.</title>
<date>1998</date>
<booktitle>In TREC</booktitle>
<pages>429--438</pages>
<marker>1998</marker>
<rawString>A large-scale comparison of boolean vs. natural language searching for the trec-7 interactive track. In TREC 1998, pages 429-438.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Hersh</author>
</authors>
<title>Information retrieval at the millenium.</title>
<date>1998</date>
<booktitle>In Proceedings of AMIA &apos;1998,</booktitle>
<pages>38--45</pages>
<location>Lake Buena Vista, FL.</location>
<contexts>
<context position="1138" citStr="Hersh, 1998" startWordPosition="162" endWordPosition="163"> XP extraction. Therefore we have designed a double system: for retrieval purposes, we rely on a rule-based architecture, called minimal commitment, which is likely to be completed by a data-driven tool (HMM) when full disambiguation is necessary. 1 Introduction Nowadays, most medical information is stored in textual documents&apos;, but such large amount of data may remain useless if retrieving the relevant information in a reasonable time becomes impossible. Although some large-scale information retrieval (IR) evaluations, made on unrestricted corpora (Hersh and al., 1998), and on medical texts (Hersh, 1998), are quite critical towards linguistic engineering, we believe that natural language processing is the best solution to face two major problems of text retrieval engines: expansion of the query and lexical disambiguation. Disambiguation can be separated between MS (morpho-syntactic, i.e. the part-ofspeech (PUS) and some other features) and WS (word-sense) disambiguation. Although we aim at developing a common architecture for processing both the MS and the WS disambiguation (Ruch and al., 1999), this paper focuses on the MS tagging. * We would like to thank Thierry Etchegoyhen and Erik Tjong </context>
</contexts>
<marker>Hersh, 1998</marker>
<rawString>William Hersh. 1998. Information retrieval at the millenium. In Proceedings of AMIA &apos;1998, pages 38-45, Lake Buena Vista, FL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Paroubek</author>
<author>G Adda</author>
<author>J Mariani</author>
<author>J Lecomte</author>
<author>M Rajman</author>
</authors>
<title>The GRACE french part-of-speech tagging evaluation task.</title>
<date>1998</date>
<booktitle>In Proceedings of LREC&apos;1998,</booktitle>
<location>Granada.</location>
<marker>Paroubek, Adda, Mariani, Lecomte, Rajman, 1998</marker>
<rawString>Paroubek, Patrick and G. Adda and J. Mariani and J. Lecomte and M. Rajman. 1998. The GRACE french part-of-speech tagging evaluation task. In Proceedings of LREC&apos;1998, Granada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Ruch</author>
<author>J Wagner</author>
<author>P Bouillon</author>
<author>R Baud</author>
<author>A-M Rassinoux</author>
<author>G Robert</author>
</authors>
<title>Medtag: Tag-like semantics for medical document indexing.</title>
<date>1999</date>
<booktitle>In Proceedings of A MIA &apos;99,</booktitle>
<pages>35--42</pages>
<location>Washington.</location>
<marker>Ruch, Wagner, Bouillon, Baud, Rassinoux, Robert, 1999</marker>
<rawString>Ruch, Patrick and J. Wagner and P. Bouillon and R. Baud and A.-M. Rassinoux and G. Robert. 1999. Medtag: Tag-like semantics for medical document indexing. In Proceedings of A MIA &apos;99, pages 35-42, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Ruch</author>
<author>R Baud</author>
<author>A-M Rassinoux</author>
<author>P Bouillon</author>
<author>G Robert</author>
</authors>
<title>Medical document anonymization with a semantic lexicon.</title>
<date>2000</date>
<booktitle>In Proceedings of AMIA&apos;2000,</booktitle>
<location>Los Angeles.</location>
<marker>Ruch, Baud, Rassinoux, Bouillon, Robert, 2000</marker>
<rawString>Ruch, Patrick and R. Baud and A.-M. Rassinoux and P. Bouillon and G. Robert 2000. Medical document anonymization with a semantic lexicon. In Proceedings of AMIA&apos;2000, Los Angeles.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Silberztein</author>
</authors>
<title>The lexical analysis of natural languages.</title>
<date>1997</date>
<booktitle>In Emmanuel Roche and Yves Shabes, editors, Finite-State Language Processing,</booktitle>
<pages>176--205</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="3560" citStr="Silberztein (1997)" startWordPosition="558" endWordPosition="560">MM tagger, but results were never far above 97% (i.e. about 3% of error); with an average ambiguity level of around 16%, it means that almost 20% of the ambiguities were attributed a wrong tag! We attempted to set a confidence threshold, so that for similarly weighted transitions, the system would keep the ambiguity, as in (Weischedel and al., 1993), but results were not satisfying. 2.2 Constraint-based systems We also looked at more powerful principlebased parsers, and tests were conducted on 2The first one using this expression was maybe M. Marcus, lately we can find a quite similar idea in Silberztein (1997). 111 Token Lemma Lexical tag(s) fast fast a section section nc[s] of of sp the the dad internal internal a faces face/to face nc[p]/v[s03] Token Lexical tags Disambiguated tag fast a a section nc[s] nc[s] of sp sp the dad dad internal a a faces nc[p]/v[s03] nc[p] Table 1: Tag-like representation of MS lexical features FIPSTAG3 (a Government and Binding chartparser (Wehrli, 1992)). Although this system performed well on general texts, with about 0.7% of errors, its results on medical texts were about the same as stochastic taggers. As we could not adapt our medical morphological analyser on th</context>
</contexts>
<marker>Silberztein, 1997</marker>
<rawString>Max Silberztein. 1997. The lexical analysis of natural languages. In Emmanuel Roche and Yves Shabes, editors, Finite-State Language Processing, pages 176-205. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Wehrli</author>
</authors>
<title>The IPS system.</title>
<date>1992</date>
<booktitle>In Proceedings COLING-92,</booktitle>
<pages>870--874</pages>
<contexts>
<context position="3942" citStr="Wehrli, 1992" startWordPosition="623" endWordPosition="624">.2 Constraint-based systems We also looked at more powerful principlebased parsers, and tests were conducted on 2The first one using this expression was maybe M. Marcus, lately we can find a quite similar idea in Silberztein (1997). 111 Token Lemma Lexical tag(s) fast fast a section section nc[s] of of sp the the dad internal internal a faces face/to face nc[p]/v[s03] Token Lexical tags Disambiguated tag fast a a section nc[s] nc[s] of sp sp the dad dad internal a a faces nc[p]/v[s03] nc[p] Table 1: Tag-like representation of MS lexical features FIPSTAG3 (a Government and Binding chartparser (Wehrli, 1992)). Although this system performed well on general texts, with about 0.7% of errors, its results on medical texts were about the same as stochastic taggers. As we could not adapt our medical morphological analyser on this very integrated system, it had to cope with several unknown words. 3 Methods In order to assess the system, we selected a corpus (40000 tokens) based equally on three types of documents: reports of surgery, discharge summaries and follow-up notes. This ad hoc corpus is split into 5 equivalent sets. The first one (set A, 8520 words) will serve to write the basic rules of the ta</context>
</contexts>
<marker>Wehrli, 1992</marker>
<rawString>Eric Wehrli. 1992. The IPS system. In Proceedings COLING-92, pages 870-874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Weischedel</author>
<author>M Meeler</author>
<author>R Shwartz</author>
<author>L Ramshaw</author>
<author>J Palmucci</author>
</authors>
<title>Coping with ambiguity and unknown words through probabilistic models.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--2</pages>
<marker>Weischedel, Meeler, Shwartz, Ramshaw, Palmucci, 1993</marker>
<rawString>Weischedel, Ralph and M. Meeler and R. Shwartz and L. Ramshaw and J. Palmucci, 1993. Coping with ambiguity and unknown words through probabilistic models. Computational Linguistics, 19(2):359-382.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>