<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000479">
<title confidence="0.9978185">
Terminological variants for document selection and
question/answer matching
</title>
<author confidence="0.971507">
Olivier Ferret Brigitte Grau Martine Hurault-Plantet
Gabriel Illouz Christian Jacquemin
</author>
<affiliation confidence="0.896215">
LIMSI-CNRS
</affiliation>
<address confidence="0.868472">
Bat.508 Universite ParisXI
91403 Orsay, France
</address>
<email confidence="0.990206">
{ferret, grau, mhp, gabrieli, jacquemin}@limsi.fr
</email>
<sectionHeader confidence="0.998576" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999894222222222">
Answering precise questions requires
applying Natural Language techniques
in order to locate the answers inside
retrieved documents. The QALC
system, presented in this paper,
participated to the Question Answering
track of the TREC8 and TREC9
evaluations. QALC exploits an analysis
of documents based on the search for
multi-word terms and their variations.
These indexes are used to select a
minimal number of documents to be
processed and to give indices when
comparing question and sentence
representations. This comparison also
takes advantage of a question analysis
module and recognition of numeric and
named entities in the documents.
</bodyText>
<sectionHeader confidence="0.999629" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999920752293578">
The Question Answering (QA) track at TREC8
and TREC9 is due to the recent need for more
sophisticated paradigms in Information
Retrieval (IR). Question answering generally
refers to encyclopedic or factual questions that
require concise answers. But current IR
techniques do not yet enable a system to give
precise answers to precise questions. Question
answering is thus an area of IR that calls for
Natural Language Processing (NLP) techniques
that can provide rich linguistic features as
output. Such NLP modules should be deeply
integrated in search and matching components
so that answer selection can be performed on
such linguistic features and take advantage of
them. In addition, IR and NLP techniques have
to collaborate in the resulting system in order to
cope with large-scale and broad coverage text
databases while deriving benefit from added
knowledge.
We developed a system for question
answering, QALC, evaluated in the framework
of the QA tracks at TREC8 and TREC9. The
QALC system comprises NLP modules for
multi-word term and named entity extraction
with a specific concern for term conflation
through variant recognition. Since named entity
recognition has already been described
extensively in other publications (Baluja 1999),
we present the contribution of terminological
variants to adding knowledge to our system.
The two main activities involving
terminology in NLP are term acquisition and
term recognition. Basically, terms can be viewed
as a particular type of lexical data. Term
variation may involve structural, morphological,
and semantic transformations of single or multi-
words terms (Fabre and Jacquemin, 2000).
In this paper, we describe how QALC uses
high level indexes, made of terms and variants,
to select among documents the most relevant
ones with regard to a question, and then to
match candidate answers with this question. In
the selection process, the documents first
retrieved by a search engine, are then
postfiltered and ranked through a weighting
scheme based on high level indexes, in order to
retain the top ranked ones. Similarly, all systems
that participated in TREC9 have a search engine
component that firstly selects a subset of the
provided database of about one million
documents. Since a search engine produces a
ranked list of relevant documents, systems then
have to define the highest number of documents
to retain. Indeed, having too many documents
leads to a question processing time that is too
long, but conversely, having too few documents
reduces the possibility of obtaining the correct
answer. For reducing the amount of text to
process, one approach consists of keeping one or
more relevant text paragraphs from each
document retrieved. Kwok et al (2000), for
instance use an IR engine that retrieves the top
300 sub-documents of about 300-550 words and,
on the other hand, the FALCON system
(Harabagiu et all 2000) performs a paragraph
retrieval stage after the application of a boolean
retrieval engine. These systems work on the
whole database and apply a bag-of-words
technique to select passages whereas QALC first
retains a large subset of documents, among
which it then selects relevant documents by
applying richer criteria based on the use of the
linguistic structures of the words.
QALC indexes, used for document selection,
are made of single and multi-word terms
retrieved by a 2-step procedure: (1) automatic
term extraction from questions through part-of-
speech tagging and pattern matching and
(2) automatic document indexing through term
recognition and variant conflation. As a result,
linguistic variation is explicitly addressed
through the exploitation of word paradigms,
contrarily to other approaches like the one taken
in COPSY (Schwarz 1988) where an
approximate matching technique between the
query and the documents implicitly takes it into
account. Finally, terms acquired at step (1) and
indexes from step (2) are also used by the
matching procedure between a question and the
relevant document sentences.
In the next section, we describe the
architecture of the QALC system. Then, we
present the question processing for term
extraction. We continue with the description of
FASTR, a transformational shallow parser that
recognizes and marks the extracted terms as well
as their linguistic variants within the documents.
The two following sections present the modules
of the QALC system where terms and variants
are used, namely the document selection and
question/answer matching modules. Finally, we
present the results obtained by the QALC
system as well as an evaluation of the
contribution of this NLP technique to the QA
task through the use of the reference collections
for the QA track. In conclusion, suggestions for
more ambitious, but still realistic, developments
using NLP are outlined.
</bodyText>
<sectionHeader confidence="0.949236" genericHeader="method">
2 System Overview
</sectionHeader>
<bodyText confidence="0.995286833333333">
Natural Language Processing components in the
QALC system (see Figure 1) enrich the selected
documents with terminological indexes in order
to go beyond reasoning about single words. Rich
linguistic features are also used to deduce what a
question is about.
</bodyText>
<subsectionHeader confidence="0.687026">
Question/Sentence pairing
</subsectionHeader>
<footnote confidence="0.321525">
Ordered sequences of 250 and
50 characters
</footnote>
<figureCaption confidence="0.999233">
Figure 1. The QALC system
</figureCaption>
<bodyText confidence="0.999911">
The analysis of a question relies on a shallow
parser which spots discriminating patterns and
assigns categories to the question. The
categories correspond to the types of entities that
are likely to constitute the answer to the
question.
In order to select the best documents from
the results given by the search engine and to
</bodyText>
<figure confidence="0.994473789473684">
Tagged Questions:
Named entity tags
Question analysis
Questions
Named entity
recognition
Re-indexing and selection of
documents (FASTR)
Tagged sentences: named entity
tags and term indexation
Subset of ranked documents
Candidate
terms
Search engine
Retrieved
documents
Vocabulary &amp;
frequencies
Corpus
</figure>
<bodyText confidence="0.999848705882353">
locate the answers inside them, we work with
terms and their variants, i.e. morphologic,
syntactic and semantic equivalent expressions.
A term extractor has been developed, based on
syntactic patterns which describe complex
nominal phrases and their subparts. These terms
are used by FASTR (Jacquemin 1999), a
shallow transformational natural language
analyzer that recognizes their occurrences and
their variants. Each occurrence or variant
constitutes an index that is subsequently used in
the processes of document ranking and
question/document matching.
Documents are ordered according to a weight
computed thanks to the number and the quality
of the terms and variants they contain. For
example, original terms with proper names are
considered more reliable than semantic variants.
An analysis of the weight graph enables the
system to select a relevant subpart of the
documents, whose size varies along the
questions. This selection takes all its importance
when applying the last processes which consist
of recognizing named-entities and analyzing
each sentence to decide whether it is a possible
answer or not. As such processes are time
consuming we attempt to limit their application
to a minimal number of documents.
Named entities are recognized in the
documents and used to measure the similarity
between the document sentences and a question.
Named entities receive one of the following
types: person, organization, location (city or
place), number (a time expression or a number
expression). They are defined in a way similar to
the MUC task and recognized through a
combination of lexico-syntactic patterns and
significantly large lexical data.
Finally, the question/answer matching
module uses all the data extracted from the
questions and the documents by the preceding
modules. We developed a similarity measure
that attributes weights to each characteristic, i.e.
named entity tags and terms and variants, and
makes a combination of them. The QALC
system proposes long and short answers.
Concerning the short ones, the system focuses
on parts of sentences that contain the expected
named entity tags, when they are known, or on
the largest subpart without any terms of the
question.
</bodyText>
<sectionHeader confidence="0.99472" genericHeader="method">
3 Terms and Variants
</sectionHeader>
<subsectionHeader confidence="0.996526">
3.1 Term extraction
</subsectionHeader>
<bodyText confidence="0.999968461538462">
For automatic acquisition of terms from
questions, we use a simple technique of filtering
through patterns of part-of-speech categories.
No statistical ranking is possible because of the
small size of the questions from which terms are
extracted. First, questions are tagged with the
help of the TreeTagger (Schmid 1999). Patterns
of syntactic categories are then used to extract
terms from the tagged questions. They are very
close to those described by Justeson and
Katz (1995), but we do not include post-posed
prepositional phrases. The pattern used for
extracting terms is:
</bodyText>
<equation confidence="0.9878285">
(((((JJ  |NN  |NP  |VBG)) ? (JJ  |NN  |NP  |VBG) (NP
 |NN)))  |(VBD)  |(NN)  |(NP)  |(CD))
</equation>
<bodyText confidence="0.999939210526316">
where NN are common nouns, NP proper nouns,
JJ adjectives, VBG gerunds, VBD past
participles and CD numeral determiners.
The longest string is acquired first and
substrings can only be acquired if they do not
begin at the same word as the superstring. For
instance, from the sequence nameNN of�N theDT
USNP helicopterNN pilotNN shotVBD downRP,
the following four terms are acquired: U S
helicopter pilot, helicopter pilot, pilot, and
shoot.
The mode of acquisition chosen for terms
amounts to considering only the substructures
that correspond to an attachment of modifiers to
the leftmost constituents (the closest one). For
instance, the decomposition of US helicopter
pilot into helicopter pilot and pilot is equivalent
to extracting the subconstituents of the structure
[US [helicopter [pilot]]].
</bodyText>
<subsectionHeader confidence="0.998915">
3.2 Variant recognition through FASTR
</subsectionHeader>
<bodyText confidence="0.995847211538461">
The automatic indexing of documents is
performed by FASTR (Jacquemin 1999), a
transformational shallow parser for the
recognition of term occurrences and variants.
Terms are transformed into grammar rules and
the single words building these terms are
extracted and linked to their morphological and
semantic families.
The morphological family of a single word w
is the set M(w) of terms in the CELEX database
(CELEX 1998) which have the same root
morpheme as w. For instance, the morphological
family of the noun maker is made of the nouns
maker, make and remake, and the verbs to make
and to remake.
The semantic family of a single word w is the
union S(w) of the synsets of WordNet1.6
(Fellbaum 1998) to which w belongs. A synset is
a set of words that are synonymous for at least
one of their meanings. Thus, the semantic family
of a word w is the set of the words w&apos; such that
w&apos; is considered as a synonym of one of the
meanings of w. The semantic family of maker,
obtained from WordNet1.6, is composed of
three nouns: maker, manufacturer, shaper and
the semantic family of car is car, auto,
automobile, machine, motorcar.
Variant patterns that rely on morphological
and semantic families are generated through
metarules. They are used to extract terms and
variants from the document sentences in the
TREC corpus. For instance, the following
pattern, named NtoSemArg, extracts the
occurrence making many automobiles as a
variant of the term car maker:
VM(&apos;maker&apos;) RP? PREP? (ART (NNINP)? PREP)?
ART? (JJ I NN I NP I VBD I VBG)10-3] NS(&apos;car&apos;)
where RP are particles, PREP prepositions, ART
articles, and VBD, VBG verbs. VM(&apos;maker&apos;) is
any verb in the morphological family of the
noun maker and NS(&apos;car&apos;) is any noun in the
semantic family of car.
Relying on the above morphological and
semantic families, auto maker, auto parts
maker, car manufacturer, make autos, and
making many automobiles are extracted as
correct variants of the original term car maker
through the set of metarules used for the QA
track experiment. Unfortunately, some incorrect
variants are extracted as well, such as make
those cuts in auto produced by the preceding
metarule.
</bodyText>
<subsectionHeader confidence="0.997677">
3.3 Document selection
</subsectionHeader>
<bodyText confidence="0.999342714285714">
The output of NLP-based indexing is a list of
term occurrences composed of a document
identifier d, a term identifier—a pair t(q,i)
composed of a question number q and a unique
index i—, a text sequence, and a variation
identifier v (a metarule). For instance, the
following index :
</bodyText>
<equation confidence="0.540774">
LA092690-0038 t(131,1)
</equation>
<bodyText confidence="0.996053785714286">
making many automobiles NtoVSemArg
means that the occurrence making many
automobiles from document d=LA092690-0038
is obtained as a variant of term i=1 in question
q=131 (car maker) through the variation
NtoVSemArg given in Section 3.2.
Each document d selected for a question q is
associated with a weight. The weighting scheme
relies on a measure of quality of the different
families of variations described by
Jacquemin (1999): non-variant occurrences are
weighted 3.0, morphological and morpho-
syntactic variants are weighted 2.0, and
semantic and morpho-syntactico-semantic
variants are weighted 1.0.
Since proper names are more reliable indices
than common names, each term t(q,i) receives a
weight P(t(q , i )) between 0 and 1.0
corresponding to its proportion of proper names.
For instance, President Cleveland&apos;s wife is
weighted 2/3=0.66. Since another factor of
reliability is the length of terms, a factor lt(q,i)l
in the weighting formula denotes the number of
words in term t(q,i). The weight Wq(d) of a
query q in a document d is given by the
following formula (1). The products of the
weightings of each term extracted by the indexer
are summed over the indices I(d) extracted from
document d and normalized according to the
number of terms IT(q)l in query q.
Mainly two types of weighting curves are
observed for the retrieved documents: curves
with a plateau and a sharp slope at a given
threshold (Figure 2.a) and curves with a slightly
decreasing weight (Figure 2.b).
The edge of a plateau is detected by examining
simultaneously the relative decrease of the slope
with respect to the preceding one, and the
relative decrease of the value with respect to the
preceding one. When a threshold is detected, we
only select documents before this threshold,
otherwise a fixed cutoff threshold is used. In our
</bodyText>
<equation confidence="0.9999162">
W q(d) = ∑
(t (q, i), v)∈I(d)
w (v ) × (1 + 2P(t(q, i))) × t(q,i)
T ( q)
(1)
</equation>
<bodyText confidence="0.999839875">
experiments, for each query q, the 200 best
ranked documents retrieved by the search
engine1 were subsequently processed by the re-
indexing module. Our studies (Ferret et al. 2000)
show that 200 is a minimum number such as
almost all the relevant documents are kept.
When no threshold was detected, we fixed the
value of the threshold to 100.
</bodyText>
<figure confidence="0.8913015">
rank of the document
(a) Question #86
</figure>
<figureCaption confidence="0.999907">
Figure 2. Two types of weighting curve.
</figureCaption>
<bodyText confidence="0.997645">
Through this method, the cutoff threshold is
8 for question #87 (Who followed Willy Brandt
as chancellor of the Federal Republic of
Germany?, Figure 2(a))2 and 100 for question
#86 (Who won two gold medals in skiing in the
Olympic Games in Calgary?, Figure 2(b)). As
indicated by Figure 2(a), there is an important
difference of weight between documents #8 and
#9. The weight of document #8 is 9.57 while the
</bodyText>
<footnote confidence="0.816107">
1 We used in particular Indexal (Loupy et al 1998), a search
engine provided by Bertin Technologie.
2 Questions come from the TREC8 data.
</footnote>
<bodyText confidence="0.99995175">
weight of document #9 is 7.29 because the term
Federal Republic only exists in document #8.
This term has a high weight because it is
composed of two proper names.
</bodyText>
<sectionHeader confidence="0.997645" genericHeader="method">
4 Question-Answer Matching
</sectionHeader>
<subsectionHeader confidence="0.999064">
4.1 Question type categorization
</subsectionHeader>
<bodyText confidence="0.999907769230769">
Question type categorization is performed in
order to assign features to questions and use
these features for the similarity measurement
between a question and potential answer
sentences. Basically, question categorization
allows the prediction of the kind(s) of answer,
called target (for instance, NUMBER).
Sentences inside the retrieved documents are
labeled with the same tags as questions. During
the similarity measurement, the more the
question and a sentence share the same tags, the
more they are considered as involved in a
question-answer relation. For example:
</bodyText>
<figure confidence="0.890681">
Question:
How many people live in the Falklands?
—&gt; target = NUMBER
Answer:
Falklands population of &lt;bnumex
TYPE=NUMBER&gt; 2,100 &lt;enumex&gt; is
concentrated.
</figure>
<bodyText confidence="0.9903075">
We established 17 types of answer. Some
systems define more categories. For instance
Prager et all (2000) identify about 50 types of
answer.
</bodyText>
<subsectionHeader confidence="0.9929">
4.2 Answer Selection
</subsectionHeader>
<bodyText confidence="0.999978625">
In the QALC system, we have taken the
sentence as a basic unit because it is large
enough to contain the answer to questions about
simple facts and to give a context that permits
the user to judge if the suggested answer is
actually correct. The module associates each
question with the Na most similar sentences (Na
is equal to 5 for the QA task at TREC).
The overall principle of the selection process
is the following: each sentence from the
documents selected for a question is compared
with this question. To perform this comparison,
sentences and questions are turned into vectors
that contain three kinds of elements: content
words, term identifiers and named entity tags. A
specific weight (between 0 and 1.0) is associated
</bodyText>
<figure confidence="0.996657685714286">
0 10 20 30 40 50 60 70 80 90 100
weight
weight
10
4
2
4
2
9
8
7
6
5
3
0
6
5
3
0
1
1
0
10
Truncation of the ranked list
20
30
rank of the document
40
Question #87
50
60
70
80
90
100
</figure>
<bodyText confidence="0.999374194444445">
with each of these elements in order to express
their relative importance.
The content words are the lemmatized forms
of mainly adjectives, verbs and nouns such as
they are given by the TreeTagger. Each content
word in a vector is weighted according to its
degree of specificity in relation to the corpus in
which answers are searched through the tf.idf
weighting scheme. For questions, the term
identifiers refer to the terms extracted by the
term extractor described in Section 3.1 and
receive a fixed weight. In sentence vectors, term
identifiers are associated with the normalized
score from the ranking module (see Section 3.3).
The named entity tags correspond to the possible
types of answers, provided by the question
analysis module. In each sentence these tags
delimit the named entities that were recognized
by the corresponding module of the QALC
system and specify their type. Unlike term
identifiers, named entity tags are given the same
fixed weight in both sentence and question
vectors because the matching module uses the
types of the named entities and not their values.
In our experiments, the linguistic features
(terms and named entities) are used to favor
appropriate sentences when they have not
enough content words in common with the
question or when the question only contains a
few content words. Thus, the weights of term
identifiers or named entity tags are reduced by
applying a coefficient in order to be globally
lower than the weights of the content words.
Finally, the comparison between a sentence
vector Vd and a question vector Vq is achieved
by computing the following similarity measure:
</bodyText>
<equation confidence="0.945352">
∑ .
∑jsim (Vq , Vd ) = iwd : (2)
j
wq
</equation>
<bodyText confidence="0.9996336875">
where wqj is the weight of an element in the
question vector and wdi is the weight of an
element in a sentence vector that is also in the
question vector. This measure evaluates the
proportion and the importance of the elements in
the question vector that are found in the
sentence vector with regards to all the elements
of the question vector. Moreover, when the
similarity value is nearly the same for two
sentences, we favor the one in which the content
words of the question are the least scattered.
The next part gives an example of the
matching operations for the TREC8 question
Q16 What two US biochemists won the Nobel
Prize in medicine in 1992? This question is
turned into the following vector:
</bodyText>
<table confidence="0.6957685">
two (1.0) US (1.0) biochemist (0.9)
nobel (1.0) prize (0,6) medicine (0,5)
win (0,3) 1992 (1.0) &lt;PERSON&gt; (0.5)
16.01 (0.5) 16.04 (0.5)
</table>
<bodyText confidence="0.990614615384616">
where &lt;PERSON&gt; is the expected type of the
answer, 16.01 is the identifier of the U S
biochemist term and 16.04 is the identifier of the
Nobel Prize term.
The same kind of vector is built for the
sentence &lt;NUMBER&gt; Two &lt;/NUMBER&gt; US
biochemists, &lt;PERSON&gt; Edwin Krebs
&lt;/PERSON&gt; and &lt;CITY&gt; Edmond &lt;/CITY&gt;
Fischer, jointly won the &lt;NUMBER&gt; 1992
&lt;/NUMBER&gt; Nobel Medicine Prize for work
that could advance the search for an anti-cancer
drug, coming from the document FT924-14045
that was selected for the question Q163 :
</bodyText>
<table confidence="0.99530025">
two (1.0) US (1.0) biochemist (0.9)
nobel (1.0) prize (0,6) medicine (0,5)
win (0,3) 1992 (1.0) Edwin (0.0)
Krebs (0.0) Edmond (0.0) Fischer (0.0)
work (0.0) advance (0.0) search (0.0)
anti-cancer (0.0) jointly (0.0) drug (0.0)
&lt;PERSON&gt; (0.5) &lt;NUMBER&gt; (0.0) &lt;CITY&gt;(0.0)
16.01 (0.5) 16.04 (0.3)
</table>
<bodyText confidence="0.999988666666667">
where the weight 0.0 is given to the elements
that are not part of the question vector. The term
US biochemist is found with no variation and
Nobel Prize appears as a syntactic variant.
Finally, according to (2), the similarity measure
between theses two vectors is equal to 0.974.
</bodyText>
<sectionHeader confidence="0.999491" genericHeader="evaluation">
5 Results and Evaluation
</sectionHeader>
<bodyText confidence="0.999990375">
We sent to TREC9 three runs whose variations
concern the searched engine used and the length
of the answer (250 or 50 characters). Among
those runs, the best one obtained a score of
0.407 with 375 correct answers among 682
questions, for answers of 250 characters length.
The score computed by NIST is the reciprocal
mean of the rank, from 1 to 5, of the correct
</bodyText>
<footnote confidence="0.610489">
3 This sentence is taken from the output of the named entity
recognizer.
</footnote>
<bodyText confidence="0.958145372093023">
answer. With this score, the QALC system was
ranked 6th among 25 participants at TREC 9
QA task.
Document selection relies on a quantitative
measure, i.e. the document weight, whose
computation is based on syntactic and semantic
indices, i.e. the terms and the terminological
variants. Those indices allow the system to take
into account words as well as group of words
and their internal relations within the
documents. Following examples, that we have
got from selected documents for TREC9 QA
task, show what kind of indices are added to the
question words.
For the question 252 When was the first flush
toilet invented? , one multi-word extracted term
is flush toilet. This term is marked by FASTR
when recognized in a document, but it is also
marked when a variant is found, as for instance
low-flush toilet in the following document
sentence where low-flush is recognized as
equivalent to flush:
Santa Barbara , Calif. , is giving $ 80 to
anyone who converts to a low-flush toilet.
252.01 flush toilet[JJ][NN]
low-flush[flush][JJ] toilet[toilet][NN]
1.00
In the given examples, after the identification
number of the term, appears the reference term,
made of the lemmatized form of the words and
their syntactic category, followed by the variant
found in the sentence, with each word, its
lemmatized form and its category, and finally its
weight.
In the example above, the term found in the
sentence is equivalent to the reference term, and
thus its weight is 1.00.
The second example shows a semantic
variant. Salary and average salary are terms
extracted from the question 337, What&apos;s the
average salary of a professional baseball player
?. The semantic variant pay, got from WordNet,
was recognized in the following sentence:
</bodyText>
<footnote confidence="0.75136475">
Did the NBA union opt for the courtroom
because its members, whose average pay tops
$500000 a year, wouldn&apos;t stand still for a
strike over free agency ?
</footnote>
<figure confidence="0.4513605">
337.01 salary[NN] pay[pay][NN] 0.25
337.00 average [JJ]salary[NN]
average[average][JJ] pay[pay][NN]
0.40
</figure>
<bodyText confidence="0.999856473684211">
In order to evaluate the efficiency of the
selection process, we proceeded to several
measures. We apply our system on the material
given for the TREC8 evaluation, one time with
the selection process, and another time without
this process. At each time, 200 documents were
returned by the search engine for each of the 200
questions. When selection was applied, at most
100 documents were selected and subsequently
processed by the matching module. Otherwise,
the 200 documents were processed. The system
was scored by 0.463 in the first case, and by
0.452 in the second case. These results show
that the score increases when processing less
documents above all because it is just the
relevant documents that are selected.
The benefit from performing such a selection
is also illustrated by the results given in Table 1,
computed on the TREC9 results.
</bodyText>
<table confidence="0.970835375">
Number of documents selected 100 «100
by ranking
Distribution among the 342 340
questions (50%) (50%)
Number of correct answers 175 200
(51%) (59%)
Number of correct answer at 88 128
rank 1 (50%) (64%)
</table>
<tableCaption confidence="0.999742">
Table 1. Evaluation of the ranking process
</tableCaption>
<bodyText confidence="0.9998755625">
We see that the selection process discards a
lot of documents for 50% of the questions (340
questions are processed from less than 100
documents). The document set retrieved for
those questions had a weighting curve with a
sharp slope and a plateau as in Figure 2(a).
QALC finds more often the correct answer and
in a better position for these 340 questions than
for the 342 remaining ones. The average number
of documents selected, when there are less than
100, is 37. These results are very interesting
when applying such time-consuming processes
as named entity recognition and
question/sentence matching. Document selection
will also enable us to apply later on syntactic
and semantic sentence analysis.
</bodyText>
<sectionHeader confidence="0.999498" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999993512195122">
The goal of a question-answering system is to
find an answer to a precise question, with a
response time short enough to satisfy the user.
As the answer is searched within a great amount
of documents, it seems relevant to apply mainly
numerical methods because they are fast. But, as
we said in the introduction, precise answers
cannot be obtained without adding NLP tools to
IR techniques. In this paper, we proposed a
question answering system which uses
terminological variants first to reduce the
number of documents to process while
increasing the system performance, and then to
improve the matching between a question and its
potential answers. Furthermore, reducing the
amount of text to process will afterwards allow
us to apply more complex methods such as
semantic analysis. Indeed, TREC organizers
foresee a number of possible improvements for
the future : real-time answering, evaluation and
justification of the answer, completeness of the
answer which could result from answers
distributed along multiple documents, and
finally interactive question answering so that the
user could specify her/his intention. All those
improvements require more data sources as well
as advanced reasoning about pragmatic and
semantic knowledge.
Thus, the improvements that we now want to
bring to our system will essentially pertain to a
semantic and pragmatic approach. For instance,
WordNet that we already use to get the semantic
variants of a word, will be exploited to refine
our set of question types. We also plan to use a
shallow syntactico-semantic parser in order to
construct a semantic representation of both the
potential answer and the question. This
representation will allow QALC to select the
answer not only from the terms and variants but
also from the syntactic and semantic links that
terms share with each other.
</bodyText>
<sectionHeader confidence="0.99948" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999896333333333">
Baluja, S., Vibhu O. M., Sukthankar, R. 1999
Applying machine learning for high performance
named-entity extraction. Proceedings
PACLING&apos;99 Waterloo, CA. 365-378.
CELEX. 1998.
http://www.ldc.upenn.edu/readme_files/celex.read
me.html. Consortium for Lexical Resources,
UPenns, Eds.
Fabre C., Jacquemin C, 2000. Boosting variant
recognition with light semantics. Proceedings
COLING 2000, pp. 264-270, Luxemburg.
Fellbaum, C. 1998. WordNet: An Electronic Lexical
Database. Cambridge, MA, MIT Press.
Ferret O., Grau B., Hurault-Plantet M., Illouz G.,
Jacquemin C. (2000), QALC — the Question-
Answering system of LIMSI-CNRS, pre-
proceedings of TREC9, NIST, Gaithersburg, CA.
Harabagiu S., Pasca M., Maiorano J. 2000.
Experiments with Open-Domain Textual Question
Answering. Proceedings of Coling&apos;2000,
Saarbrucken, Germany.
Jacquemin C. 1999. Syntagmatic and paradigmatic
representations of term variation. Proceedings of
ACL&apos;99. 341-348.
Justeson J., Katz S. 1995. Technical terminology:
some linguistic properties and an algorithm for
identification in texte. Natural Language
Engineering. 1: 9-27.
Kwok K.L., Grunfeld L., Dinstl N., Chan M. 2000.
TREC9 Cross Language, Web and Question-
Answering Track experiments using PIRCS. Pre-
proceedings of TREC9, Gaithersburg, MD, NIST
Eds. 26-35.
Loupy C. , Bellot P., El-Beze M., Marteau P.-F..
Query Expansion and Classification of Retrieved
Documents, TREC (1998), 382-389.
Prager J., Brown, E., Radev, D., Czuba, K. (2000),
One Search Engine or two for Question-
Answering, NISTs, Eds., Proceedings of TREC9,
Gaithersburg, MD. 250-254.
Schmid H. 1999. Improvments in Part-of-Speech
Tagging with an Application To German.
Natural Language Processing Using Very Large
Corpora, Dordrecht, S. Armstrong, K. W. Chuch,
P. Isabelle, E. Tzoukermann, D. Yarowski, Eds.,
Kluwer Academic Publisher.
Schwarz C. 1988. The TINA Project: text content
analysis at the Corporate Research Laboratories at
Siemens. Proceedings of Intelligent Multimedia
Information Retrieval Systems and Management
(RIAO&apos;88) Cambridge, MA. 361-368.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.341687">
<title confidence="0.990578">Terminological variants for document selection question/answer matching</title>
<author confidence="0.8579685">Olivier Ferret Brigitte Grau Martine Hurault-Plantet Gabriel Illouz Christian Jacquemin</author>
<affiliation confidence="0.749816">LIMSI-CNRS Bat.508 Universite</affiliation>
<address confidence="0.999373">91403 Orsay, France</address>
<email confidence="0.997798">ferret@limsi.fr</email>
<email confidence="0.997798">grau@limsi.fr</email>
<email confidence="0.997798">mhp@limsi.fr</email>
<email confidence="0.997798">gabrieli@limsi.fr</email>
<email confidence="0.997798">jacquemin@limsi.fr</email>
<abstract confidence="0.998527315789474">Answering precise questions requires applying Natural Language techniques in order to locate the answers inside retrieved documents. The QALC system, presented in this paper, participated to the Question Answering track of the TREC8 and TREC9 evaluations. QALC exploits an analysis of documents based on the search for multi-word terms and their variations. These indexes are used to select a minimal number of documents to be processed and to give indices when comparing question and sentence representations. This comparison also takes advantage of a question analysis module and recognition of numeric and named entities in the documents.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Baluja</author>
<author>O M Vibhu</author>
<author>R Sukthankar</author>
</authors>
<title>Applying machine learning for high performance named-entity extraction.</title>
<date>1999</date>
<booktitle>Proceedings PACLING&apos;99</booktitle>
<pages>365--378</pages>
<location>Waterloo, CA.</location>
<marker>Baluja, Vibhu, Sukthankar, 1999</marker>
<rawString>Baluja, S., Vibhu O. M., Sukthankar, R. 1999 Applying machine learning for high performance named-entity extraction. Proceedings PACLING&apos;99 Waterloo, CA. 365-378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>CELEX</author>
</authors>
<title>http://www.ldc.upenn.edu/readme_files/celex.read me.html. Consortium for Lexical Resources,</title>
<date>1998</date>
<location>UPenns, Eds.</location>
<contexts>
<context position="10900" citStr="CELEX 1998" startWordPosition="1669" endWordPosition="1670">tion of US helicopter pilot into helicopter pilot and pilot is equivalent to extracting the subconstituents of the structure [US [helicopter [pilot]]]. 3.2 Variant recognition through FASTR The automatic indexing of documents is performed by FASTR (Jacquemin 1999), a transformational shallow parser for the recognition of term occurrences and variants. Terms are transformed into grammar rules and the single words building these terms are extracted and linked to their morphological and semantic families. The morphological family of a single word w is the set M(w) of terms in the CELEX database (CELEX 1998) which have the same root morpheme as w. For instance, the morphological family of the noun maker is made of the nouns maker, make and remake, and the verbs to make and to remake. The semantic family of a single word w is the union S(w) of the synsets of WordNet1.6 (Fellbaum 1998) to which w belongs. A synset is a set of words that are synonymous for at least one of their meanings. Thus, the semantic family of a word w is the set of the words w&apos; such that w&apos; is considered as a synonym of one of the meanings of w. The semantic family of maker, obtained from WordNet1.6, is composed of three noun</context>
</contexts>
<marker>CELEX, 1998</marker>
<rawString>CELEX. 1998. http://www.ldc.upenn.edu/readme_files/celex.read me.html. Consortium for Lexical Resources, UPenns, Eds.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fabre</author>
<author>C Jacquemin</author>
</authors>
<title>Boosting variant recognition with light semantics.</title>
<date>2000</date>
<booktitle>Proceedings COLING</booktitle>
<pages>264--270</pages>
<location>Luxemburg.</location>
<contexts>
<context position="2583" citStr="Fabre and Jacquemin, 2000" startWordPosition="375" endWordPosition="378">es for multi-word term and named entity extraction with a specific concern for term conflation through variant recognition. Since named entity recognition has already been described extensively in other publications (Baluja 1999), we present the contribution of terminological variants to adding knowledge to our system. The two main activities involving terminology in NLP are term acquisition and term recognition. Basically, terms can be viewed as a particular type of lexical data. Term variation may involve structural, morphological, and semantic transformations of single or multiwords terms (Fabre and Jacquemin, 2000). In this paper, we describe how QALC uses high level indexes, made of terms and variants, to select among documents the most relevant ones with regard to a question, and then to match candidate answers with this question. In the selection process, the documents first retrieved by a search engine, are then postfiltered and ranked through a weighting scheme based on high level indexes, in order to retain the top ranked ones. Similarly, all systems that participated in TREC9 have a search engine component that firstly selects a subset of the provided database of about one million documents. Sinc</context>
</contexts>
<marker>Fabre, Jacquemin, 2000</marker>
<rawString>Fabre C., Jacquemin C, 2000. Boosting variant recognition with light semantics. Proceedings COLING 2000, pp. 264-270, Luxemburg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="11181" citStr="Fellbaum 1998" startWordPosition="1722" endWordPosition="1723">tional shallow parser for the recognition of term occurrences and variants. Terms are transformed into grammar rules and the single words building these terms are extracted and linked to their morphological and semantic families. The morphological family of a single word w is the set M(w) of terms in the CELEX database (CELEX 1998) which have the same root morpheme as w. For instance, the morphological family of the noun maker is made of the nouns maker, make and remake, and the verbs to make and to remake. The semantic family of a single word w is the union S(w) of the synsets of WordNet1.6 (Fellbaum 1998) to which w belongs. A synset is a set of words that are synonymous for at least one of their meanings. Thus, the semantic family of a word w is the set of the words w&apos; such that w&apos; is considered as a synonym of one of the meanings of w. The semantic family of maker, obtained from WordNet1.6, is composed of three nouns: maker, manufacturer, shaper and the semantic family of car is car, auto, automobile, machine, motorcar. Variant patterns that rely on morphological and semantic families are generated through metarules. They are used to extract terms and variants from the document sentences in </context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Fellbaum, C. 1998. WordNet: An Electronic Lexical Database. Cambridge, MA, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Ferret</author>
<author>B Grau</author>
<author>M Hurault-Plantet</author>
<author>G Illouz</author>
<author>C Jacquemin</author>
</authors>
<date>2000</date>
<booktitle>QALC — the QuestionAnswering system of LIMSI-CNRS, preproceedings of TREC9,</booktitle>
<location>NIST, Gaithersburg, CA.</location>
<contexts>
<context position="15040" citStr="Ferret et al. 2000" startWordPosition="2364" endWordPosition="2367">easing weight (Figure 2.b). The edge of a plateau is detected by examining simultaneously the relative decrease of the slope with respect to the preceding one, and the relative decrease of the value with respect to the preceding one. When a threshold is detected, we only select documents before this threshold, otherwise a fixed cutoff threshold is used. In our W q(d) = ∑ (t (q, i), v)∈I(d) w (v ) × (1 + 2P(t(q, i))) × t(q,i) T ( q) (1) experiments, for each query q, the 200 best ranked documents retrieved by the search engine1 were subsequently processed by the reindexing module. Our studies (Ferret et al. 2000) show that 200 is a minimum number such as almost all the relevant documents are kept. When no threshold was detected, we fixed the value of the threshold to 100. rank of the document (a) Question #86 Figure 2. Two types of weighting curve. Through this method, the cutoff threshold is 8 for question #87 (Who followed Willy Brandt as chancellor of the Federal Republic of Germany?, Figure 2(a))2 and 100 for question #86 (Who won two gold medals in skiing in the Olympic Games in Calgary?, Figure 2(b)). As indicated by Figure 2(a), there is an important difference of weight between documents #8 an</context>
</contexts>
<marker>Ferret, Grau, Hurault-Plantet, Illouz, Jacquemin, 2000</marker>
<rawString>Ferret O., Grau B., Hurault-Plantet M., Illouz G., Jacquemin C. (2000), QALC — the QuestionAnswering system of LIMSI-CNRS, preproceedings of TREC9, NIST, Gaithersburg, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Harabagiu</author>
<author>M Pasca</author>
<author>J Maiorano</author>
</authors>
<title>Experiments with Open-Domain Textual Question Answering.</title>
<date>2000</date>
<booktitle>Proceedings of Coling&apos;2000,</booktitle>
<location>Saarbrucken, Germany.</location>
<marker>Harabagiu, Pasca, Maiorano, 2000</marker>
<rawString>Harabagiu S., Pasca M., Maiorano J. 2000. Experiments with Open-Domain Textual Question Answering. Proceedings of Coling&apos;2000, Saarbrucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Jacquemin</author>
</authors>
<title>Syntagmatic and paradigmatic representations of term variation.</title>
<date>1999</date>
<booktitle>Proceedings of ACL&apos;99.</booktitle>
<pages>341--348</pages>
<contexts>
<context position="7043" citStr="Jacquemin 1999" startWordPosition="1071" endWordPosition="1072"> and to Tagged Questions: Named entity tags Question analysis Questions Named entity recognition Re-indexing and selection of documents (FASTR) Tagged sentences: named entity tags and term indexation Subset of ranked documents Candidate terms Search engine Retrieved documents Vocabulary &amp; frequencies Corpus locate the answers inside them, we work with terms and their variants, i.e. morphologic, syntactic and semantic equivalent expressions. A term extractor has been developed, based on syntactic patterns which describe complex nominal phrases and their subparts. These terms are used by FASTR (Jacquemin 1999), a shallow transformational natural language analyzer that recognizes their occurrences and their variants. Each occurrence or variant constitutes an index that is subsequently used in the processes of document ranking and question/document matching. Documents are ordered according to a weight computed thanks to the number and the quality of the terms and variants they contain. For example, original terms with proper names are considered more reliable than semantic variants. An analysis of the weight graph enables the system to select a relevant subpart of the documents, whose size varies alo</context>
<context position="10553" citStr="Jacquemin 1999" startWordPosition="1614" endWordPosition="1615">eDT USNP helicopterNN pilotNN shotVBD downRP, the following four terms are acquired: U S helicopter pilot, helicopter pilot, pilot, and shoot. The mode of acquisition chosen for terms amounts to considering only the substructures that correspond to an attachment of modifiers to the leftmost constituents (the closest one). For instance, the decomposition of US helicopter pilot into helicopter pilot and pilot is equivalent to extracting the subconstituents of the structure [US [helicopter [pilot]]]. 3.2 Variant recognition through FASTR The automatic indexing of documents is performed by FASTR (Jacquemin 1999), a transformational shallow parser for the recognition of term occurrences and variants. Terms are transformed into grammar rules and the single words building these terms are extracted and linked to their morphological and semantic families. The morphological family of a single word w is the set M(w) of terms in the CELEX database (CELEX 1998) which have the same root morpheme as w. For instance, the morphological family of the noun maker is made of the nouns maker, make and remake, and the verbs to make and to remake. The semantic family of a single word w is the union S(w) of the synsets o</context>
<context position="13392" citStr="Jacquemin (1999)" startWordPosition="2087" endWordPosition="2088"> pair t(q,i) composed of a question number q and a unique index i—, a text sequence, and a variation identifier v (a metarule). For instance, the following index : LA092690-0038 t(131,1) making many automobiles NtoVSemArg means that the occurrence making many automobiles from document d=LA092690-0038 is obtained as a variant of term i=1 in question q=131 (car maker) through the variation NtoVSemArg given in Section 3.2. Each document d selected for a question q is associated with a weight. The weighting scheme relies on a measure of quality of the different families of variations described by Jacquemin (1999): non-variant occurrences are weighted 3.0, morphological and morphosyntactic variants are weighted 2.0, and semantic and morpho-syntactico-semantic variants are weighted 1.0. Since proper names are more reliable indices than common names, each term t(q,i) receives a weight P(t(q , i )) between 0 and 1.0 corresponding to its proportion of proper names. For instance, President Cleveland&apos;s wife is weighted 2/3=0.66. Since another factor of reliability is the length of terms, a factor lt(q,i)l in the weighting formula denotes the number of words in term t(q,i). The weight Wq(d) of a query q in a </context>
</contexts>
<marker>Jacquemin, 1999</marker>
<rawString>Jacquemin C. 1999. Syntagmatic and paradigmatic representations of term variation. Proceedings of ACL&apos;99. 341-348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Justeson</author>
<author>S Katz</author>
</authors>
<title>Technical terminology: some linguistic properties and an algorithm for identification in texte.</title>
<date>1995</date>
<journal>Natural Language Engineering.</journal>
<volume>1</volume>
<pages>9--27</pages>
<contexts>
<context position="9460" citStr="Justeson and Katz (1995)" startWordPosition="1443" endWordPosition="1446">ed named entity tags, when they are known, or on the largest subpart without any terms of the question. 3 Terms and Variants 3.1 Term extraction For automatic acquisition of terms from questions, we use a simple technique of filtering through patterns of part-of-speech categories. No statistical ranking is possible because of the small size of the questions from which terms are extracted. First, questions are tagged with the help of the TreeTagger (Schmid 1999). Patterns of syntactic categories are then used to extract terms from the tagged questions. They are very close to those described by Justeson and Katz (1995), but we do not include post-posed prepositional phrases. The pattern used for extracting terms is: (((((JJ |NN |NP |VBG)) ? (JJ |NN |NP |VBG) (NP |NN))) |(VBD) |(NN) |(NP) |(CD)) where NN are common nouns, NP proper nouns, JJ adjectives, VBG gerunds, VBD past participles and CD numeral determiners. The longest string is acquired first and substrings can only be acquired if they do not begin at the same word as the superstring. For instance, from the sequence nameNN of�N theDT USNP helicopterNN pilotNN shotVBD downRP, the following four terms are acquired: U S helicopter pilot, helicopter pilo</context>
</contexts>
<marker>Justeson, Katz, 1995</marker>
<rawString>Justeson J., Katz S. 1995. Technical terminology: some linguistic properties and an algorithm for identification in texte. Natural Language Engineering. 1: 9-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K L Kwok</author>
<author>L Grunfeld</author>
<author>N Dinstl</author>
<author>M Chan</author>
</authors>
<title>TREC9 Cross Language, Web and QuestionAnswering Track experiments using PIRCS.</title>
<date>2000</date>
<booktitle>Preproceedings of TREC9,</booktitle>
<pages>26--35</pages>
<location>Gaithersburg, MD, NIST</location>
<contexts>
<context position="3665" citStr="Kwok et al (2000)" startWordPosition="552" endWordPosition="555">ted in TREC9 have a search engine component that firstly selects a subset of the provided database of about one million documents. Since a search engine produces a ranked list of relevant documents, systems then have to define the highest number of documents to retain. Indeed, having too many documents leads to a question processing time that is too long, but conversely, having too few documents reduces the possibility of obtaining the correct answer. For reducing the amount of text to process, one approach consists of keeping one or more relevant text paragraphs from each document retrieved. Kwok et al (2000), for instance use an IR engine that retrieves the top 300 sub-documents of about 300-550 words and, on the other hand, the FALCON system (Harabagiu et all 2000) performs a paragraph retrieval stage after the application of a boolean retrieval engine. These systems work on the whole database and apply a bag-of-words technique to select passages whereas QALC first retains a large subset of documents, among which it then selects relevant documents by applying richer criteria based on the use of the linguistic structures of the words. QALC indexes, used for document selection, are made of single </context>
</contexts>
<marker>Kwok, Grunfeld, Dinstl, Chan, 2000</marker>
<rawString>Kwok K.L., Grunfeld L., Dinstl N., Chan M. 2000. TREC9 Cross Language, Web and QuestionAnswering Track experiments using PIRCS. Preproceedings of TREC9, Gaithersburg, MD, NIST Eds. 26-35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Bellot</author>
<author>M El-Beze</author>
<author>P-F Marteau</author>
</authors>
<title>Query Expansion and Classification of Retrieved Documents,</title>
<date>1998</date>
<pages>382--389</pages>
<location>TREC</location>
<marker>Bellot, El-Beze, Marteau, 1998</marker>
<rawString>Loupy C. , Bellot P., El-Beze M., Marteau P.-F.. Query Expansion and Classification of Retrieved Documents, TREC (1998), 382-389.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Prager</author>
<author>E Brown</author>
<author>D Radev</author>
<author>K Czuba</author>
</authors>
<title>One Search Engine or two for QuestionAnswering, NISTs, Eds.,</title>
<date>2000</date>
<booktitle>Proceedings of TREC9,</booktitle>
<pages>250--254</pages>
<location>Gaithersburg, MD.</location>
<marker>Prager, Brown, Radev, Czuba, 2000</marker>
<rawString>Prager J., Brown, E., Radev, D., Czuba, K. (2000), One Search Engine or two for QuestionAnswering, NISTs, Eds., Proceedings of TREC9, Gaithersburg, MD. 250-254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Improvments in Part-of-Speech Tagging with an Application To German. Natural Language Processing Using Very Large Corpora,</title>
<date>1999</date>
<publisher>Kluwer Academic Publisher.</publisher>
<location>Dordrecht,</location>
<contexts>
<context position="9301" citStr="Schmid 1999" startWordPosition="1419" endWordPosition="1420"> them. The QALC system proposes long and short answers. Concerning the short ones, the system focuses on parts of sentences that contain the expected named entity tags, when they are known, or on the largest subpart without any terms of the question. 3 Terms and Variants 3.1 Term extraction For automatic acquisition of terms from questions, we use a simple technique of filtering through patterns of part-of-speech categories. No statistical ranking is possible because of the small size of the questions from which terms are extracted. First, questions are tagged with the help of the TreeTagger (Schmid 1999). Patterns of syntactic categories are then used to extract terms from the tagged questions. They are very close to those described by Justeson and Katz (1995), but we do not include post-posed prepositional phrases. The pattern used for extracting terms is: (((((JJ |NN |NP |VBG)) ? (JJ |NN |NP |VBG) (NP |NN))) |(VBD) |(NN) |(NP) |(CD)) where NN are common nouns, NP proper nouns, JJ adjectives, VBG gerunds, VBD past participles and CD numeral determiners. The longest string is acquired first and substrings can only be acquired if they do not begin at the same word as the superstring. For insta</context>
</contexts>
<marker>Schmid, 1999</marker>
<rawString>Schmid H. 1999. Improvments in Part-of-Speech Tagging with an Application To German. Natural Language Processing Using Very Large Corpora, Dordrecht, S. Armstrong, K. W. Chuch, P. Isabelle, E. Tzoukermann, D. Yarowski, Eds., Kluwer Academic Publisher.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Schwarz</author>
</authors>
<title>The TINA Project: text content analysis at the Corporate Research Laboratories at Siemens.</title>
<date>1988</date>
<booktitle>Proceedings of Intelligent Multimedia Information Retrieval Systems and Management (RIAO&apos;88)</booktitle>
<pages>361--368</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="4675" citStr="Schwarz 1988" startWordPosition="709" endWordPosition="710">ents, among which it then selects relevant documents by applying richer criteria based on the use of the linguistic structures of the words. QALC indexes, used for document selection, are made of single and multi-word terms retrieved by a 2-step procedure: (1) automatic term extraction from questions through part-ofspeech tagging and pattern matching and (2) automatic document indexing through term recognition and variant conflation. As a result, linguistic variation is explicitly addressed through the exploitation of word paradigms, contrarily to other approaches like the one taken in COPSY (Schwarz 1988) where an approximate matching technique between the query and the documents implicitly takes it into account. Finally, terms acquired at step (1) and indexes from step (2) are also used by the matching procedure between a question and the relevant document sentences. In the next section, we describe the architecture of the QALC system. Then, we present the question processing for term extraction. We continue with the description of FASTR, a transformational shallow parser that recognizes and marks the extracted terms as well as their linguistic variants within the documents. The two following</context>
</contexts>
<marker>Schwarz, 1988</marker>
<rawString>Schwarz C. 1988. The TINA Project: text content analysis at the Corporate Research Laboratories at Siemens. Proceedings of Intelligent Multimedia Information Retrieval Systems and Management (RIAO&apos;88) Cambridge, MA. 361-368.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>