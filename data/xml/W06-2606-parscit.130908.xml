<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001275">
<title confidence="0.986431">
Reranking Translation Hypotheses Using Structural Properties
</title>
<author confidence="0.985521">
Saˇsa Hasan, Oliver Bender, Hermann Ney
</author>
<affiliation confidence="0.980964">
Chair of Computer Science VI
RWTH Aachen University
</affiliation>
<address confidence="0.63531">
D-52056 Aachen, Germany
</address>
<email confidence="0.998685">
{hasan,bender,ney}@cs.rwth-aachen.de
</email>
<sectionHeader confidence="0.998596" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999908857142857">
We investigate methods that add syntac-
tically motivated features to a statistical
machine translation system in a reranking
framework. The goal is to analyze whether
shallow parsing techniques help in iden-
tifying ungrammatical hypotheses. We
show that improvements are possible by
utilizing supertagging, lightweight depen-
dency analysis, a link grammar parser and
a maximum-entropy based chunk parser.
Adding features to n-best lists and dis-
criminatively training the system on a de-
velopment set increases the BLEU score
up to 0.7% on the test set.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999257">
Statistically driven machine translation systems
are currently the dominant type of system in the
MT community. Though much better than tradi-
tional rule-based approaches, these systems still
make a lot of errors that seem, at least from a hu-
man point of view, illogical.
The main purpose of this paper is to investigate
a means of identifying ungrammatical hypotheses
from the output of a machine translation system
by using grammatical knowledge that expresses
syntactic dependencies of words or word groups.
We introduce several methods that try to establish
this kind of linkage between the words of a hy-
pothesis and, thus, determine its well-formedness,
or “fluency”. We perform rescoring experiments
that rerank n-best lists according to the presented
framework.
As methodologies deriving well-formedness of
a sentence we use supertagging (Bangalore and
Joshi, 1999) with lightweight dependency anal-
ysis (LDA)1 (Bangalore, 2000), link grammars
(Sleator and Temperley, 1993) and a maximum-
entropy (ME) based chunk parser (Bender et al.,
2003). The former two approaches explicitly
model the syntactic dependencies between words.
Each hypothesis that contains irregularities, such
as broken linkages or non-satisfied dependencies,
should be penalized or rejected accordingly. For
the ME chunker, the idea is to train n-gram mod-
els on the chunk or POS sequences and directly
use the log-probability as feature score.
In general, these concepts and the underlying
programs should be robust and fast in order to be
able to cope with large amounts of data (as it is the
case for n-best lists). The experiments presented
show a small though consistent improvement in
terms of automatic evaluation measures chosen for
evaluation. BLEU score improvements, for in-
stance, lie in the range from 0.3 to 0.7% on the
test set.
In the following, Section 2 gives an overview
on related work in this domain. In Section 3
we review our general approach to statistical ma-
chine translation (SMT) and introduce the main
methodologies used for deriving syntactic depen-
dencies on words or word groups, namely su-
pertagging/LDA, link grammars and ME chunk-
ing. The corpora and the experiments are dis-
cussed in Section 4. The paper is concluded in
Section 5.
</bodyText>
<sectionHeader confidence="0.999931" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999564">
In (Och et al., 2004), the effects of integrating
syntactic structure into a state-of-the-art statistical
machine translation system are investigated. The
approach is similar to the approach presented here:
</bodyText>
<footnote confidence="0.9683185">
1In the context of this work, the term LDA is not to be
confused with linear discriminant analysis.
</footnote>
<page confidence="0.99941">
41
</page>
<bodyText confidence="0.999870833333333">
firstly, a word graph is generated using the base-
line SMT system and n-best lists are extracted ac-
cordingly, then additional feature functions repre-
senting syntactic knowledge are added and the cor-
responding scaling factors are trained discrimina-
tively on a development n-best list.
Och and colleagues investigated a large amount
of different feature functions. The field of appli-
cation varies from simple syntactic features, such
as IBM model 1 score, over shallow parsing tech-
niques to more complex methods using grammars
and intricate parsing procedures. The results were
rather disappointing. Only one of the simplest
models, i.e. the implicit syntactic feature derived
from IBM model 1 score, yielded consistent and
significant improvements. All other methods had
only a very small effect on the overall perfor-
mance.
</bodyText>
<sectionHeader confidence="0.998971" genericHeader="method">
3 Framework
</sectionHeader>
<bodyText confidence="0.999338">
In the following sections, the theoretical frame-
work of statistical machine translation using a di-
rect approach is reviewed. We introduce the su-
pertagging and lightweight dependency analysis
approach, link grammars and maximum-entropy
based chunking technique.
</bodyText>
<subsectionHeader confidence="0.993172">
3.1 Direct approach to SMT
</subsectionHeader>
<bodyText confidence="0.788087">
In statistical machine translation, the best trans-
lation ˆe1 = ˆe1 . . . ˆei . . . ˆeˆI of source words fJ
</bodyText>
<equation confidence="0.981034">
ˆI 1 =
f1 ... fj ... fJ is obtained by maximizing the con-
ditional probability
ˆe1 = argmax
ˆI
I,ei
= argmax {Pr(fJ 1 |eI 1) · Pr(eI1)}
I,ei
</equation>
<bodyText confidence="0.999024555555555">
using Bayes decision rule. The first probability
on the right-hand side of the equation denotes the
translation model whereas the second is the target
language model.
An alternative to this classical source-channel
approach is the direct modeling of the posterior
probability Pr(eI1|fJ1 ) which is utilized here. Us-
ing a log-linear model (Och and Ney, 2002), we
obtain
</bodyText>
<equation confidence="0.882739833333333">
(�M )
exp m=1 λmhm(eI 1, fJ 1 )
E exp (EM1 λmhm(e&apos;i&apos;, fJ1)),
e�I�
1
(2)
</equation>
<bodyText confidence="0.999995166666667">
where λm are the scaling factors of the models de-
noted by feature functions hm(·). The denomina-
tor represents a normalization factor that depends
only on the source sentence fJ1 . Therefore, we can
omit it during the search process, leading to the
following decision rule:
</bodyText>
<equation confidence="0.999880166666667">
ˆe1 = argmax
ˆI
I,ei � M
m=1
E �
λmhm(eI1, fJ1) (3)
</equation>
<bodyText confidence="0.997886857142857">
This approach is a generalization of the source-
channel approach. It has the advantage that ad-
ditional models h(·) can be easily integrated into
the overall system. The model scaling factors
λM1 are trained according to the maximum en-
tropy principle, e.g., using the GIS algorithm. Al-
ternatively, one can train them with respect to
the final translation quality measured by an error
criterion (Och, 2003). For the results reported
in this paper, we optimized the scaling factors
with respect to a linear interpolation of word error
rate (WER), position-independent word error rate
(PER), BLEU and NIST score using the Downhill
Simplex algorithm (Press et al., 2002).
</bodyText>
<subsectionHeader confidence="0.999604">
3.2 Supertagging/LDA
</subsectionHeader>
<bodyText confidence="0.999550961538461">
Supertagging (Bangalore and Joshi, 1999) uses the
Lexicalized Tree Adjoining Grammar formalism
(LTAG) (XTAG Research Group, 2001). Tree Ad-
joining Grammars incorporate a tree-rewriting for-
malism using elementary trees that can be com-
bined by two operations, namely substitution and
adjunction, to derive more complex tree structures
of the sentence considered. Lexicalization allows
us to associate each elementary tree with a lexical
item called the anchor. In LTAGs, every elemen-
tary tree has such a lexical anchor, also called head
word. It is possible that there is more than one el-
ementary structure associated with a lexical item,
as e.g. for the case of verbs with different subcat-
egorization frames.
The elementary structures, called initial and
auxiliary trees, hold all dependent elements within
the same structure, thus imposing constraints on
the lexical anchors in a local context. Basically,
supertagging is very similar to part-of-speech tag-
ging. Instead of POS tags, richer descriptions,
namely the elementary structures of LTAGs, are
annotated to the words of a sentence. For this pur-
pose, they are called supertags in order to distin-
guish them from ordinary POS tags. The result
is an “almost parse” because of the dependencies
</bodyText>
<equation confidence="0.966827666666667">
{Pr(eI1|fJ1 )}
(1)
Pr(eI1|fJ1 ) =
</equation>
<page confidence="0.932968">
42
</page>
<figure confidence="0.948542166666667">
was[α2]
food[α1] delicious[α3]
D D S S EA EA
P P
the[β1] very[β2]
the food was very delicious
</figure>
<figureCaption confidence="0.8926155">
Figure 1: LDA: example of a derivation tree, β
nodes are the result of the adjunction operation on
auxiliary trees, α nodes of substitution on initial
trees.
</figureCaption>
<bodyText confidence="0.999970162162162">
coded within the supertags. Usually, a lexical item
can have many supertags, depending on the vari-
ous contexts it appears in. Therefore, the local am-
biguity is larger than for the case of POS tags. An
LTAG parser for this scenario can be very slow, i.e.
its computational complexity is in O(n6), because
of the large number of supertags, i.e. elementary
trees, that have to be examined during a parse. In
order to speed up the parsing process, we can ap-
ply n-gram models on a supertag basis in order to
filter out incompatible descriptions and thus im-
prove the performance of the parser. In (Banga-
lore and Joshi, 1999), a trigram supertagger with
smoothing and back-off is reported that achieves
an accuracy of 92.2% when trained on one million
running words.
There is another aspect to the dependencies
coded in the elementary structures. We can use
them to actually derive a shallow parse of the sen-
tence in linear time. The procedure is presented
in (Bangalore, 2000) and is called lightweight de-
pendency analysis. The concept is comparable to
chunking. The lightweight dependency analyzer
(LDA) finds the arguments for the encoded depen-
dency requirements. There exist two types of slots
that can be filled. On the one hand, nodes marked
for substitution (in α-trees) have to be filled by the
complements of the lexical anchor. On the other
hand, the foot nodes (i.e. nodes marked for adjunc-
tion in β-trees) take words that are being modified
by the supertag. Figure 1 shows a tree derived by
LDA on the sentence the food was very delicious
from the C-Star’03 corpus (cf. Section 4.1).
The supertagging and LDA tools are available
from the XTAG research group website.2
As features considered for the reranking exper-
iments we choose:
</bodyText>
<footnote confidence="0.943522">
2http://www.cis.upenn.edu/˜xtag/
</footnote>
<figureCaption confidence="0.9900555">
Figure 2: Link grammar: example of a valid link-
age satisfying all constraints.
</figureCaption>
<listItem confidence="0.999618">
• Supertagger output: directly use the log-
likelihoods as feature score. This did not im-
prove performance significantly, so the model
was discarded from the final system.
• LDA output:
</listItem>
<bodyText confidence="0.979594857142857">
– dependency coverage: determine the
number of covered elements, i.e. where
the dependency slots are filled to the left
and right
– separate features for the number of mod-
ifiers and complements determined by
the LDA
</bodyText>
<subsectionHeader confidence="0.999783">
3.3 Link grammar
</subsectionHeader>
<bodyText confidence="0.9998965">
Similar to the ideas presented in the previous sec-
tion, link grammars also explicitly code depen-
dencies between words (Sleator and Temperley,
1993). These dependencies are called links which
reflect the local requirements of each word. Sev-
eral constraints have to be satisfied within the link
grammar formalism to derive correct linkages, i.e.
sets of links, of a sequence of words:
</bodyText>
<listItem confidence="0.986346">
1. Planarity: links are not allowed to cross each
other
2. Connectivity: links suffice to connect all
words of a sentence
3. Satisfaction: linking requirements of each
word are satisfied
</listItem>
<bodyText confidence="0.999846625">
An example of a valid linkage is shown in Fig-
ure 2. The link grammar parser that we use is
freely available from the authors’ website.3 Sim-
ilar to LTAG, the link grammar formalism is lex-
icalized which allows for enhancing the methods
with probabilistic n-gram models (as is also the
case for supertagging). In (Lafferty et al., 1992),
the link grammar is used to derive a new class of
</bodyText>
<footnote confidence="0.965909">
3http://www.link.cs.cmu.edu/link/
</footnote>
<page confidence="0.999189">
43
</page>
<figure confidence="0.747927">
[NP the food ] [VP was] [ADJP very delicious]
the/DT food/NN was/VBD very/RB delicious/JJ
</figure>
<figureCaption confidence="0.955401">
Figure 3: Chunking and POS tagging: a tag next
</figureCaption>
<bodyText confidence="0.646506666666667">
to the opening bracket denotes the type of chunk,
whereas the corresponding POS tag is given after
the word.
</bodyText>
<equation confidence="0.999555181818182">
p( i−1 i+2 i+2
ci  |ci−2 , ei−2, gi−2) , (5)
I
i=1
order model:
Pr(cI1|eI1, gI1) =
I
=
i=1
Pr(ci|ci−1
1 , eI 1,gI 1) (4)
</equation>
<bodyText confidence="0.999881222222222">
language models that, in comparison to traditional
n-gram LMs, incorporate capabilities for express-
ing long-range dependencies between words.
The link grammar dictionary that specifies the
words and their corresponding valid links cur-
rently holds approximately 60 000 entries and han-
dles a wide variety of phenomena in English. It is
derived from newspaper texts.
Within our reranking framework, we use link
grammar features that express a possible well-
formedness of the translation hypothesis. The sim-
plest feature is a binary one stating whether the
link grammar parser could derive a complete link-
age or not, which should be a strong indicator of
a syntactically correct sentence. Additionally, we
added a normalized cost of the matching process
which turned out not to be very helpful for rescor-
ing, so it was discarded.
</bodyText>
<subsectionHeader confidence="0.969516">
3.4 ME chunking
</subsectionHeader>
<bodyText confidence="0.962171842105263">
Like the methods described in the two preced-
ing sections, text chunking consists of dividing a
text into syntactically correlated non-overlapping
groups of words. Figure 3 shows again our ex-
ample sentence illustrating this task. Chunks are
represented as groups of words between square
brackets. We employ the 11 chunk types as de-
fined for the CoNLL-2000 shared task (Tjong Kim
Sang and Buchholz, 2000).
For the experiments, we apply a maximum-
entropy based tagger which has been successfully
evaluated on natural language understanding and
named entity recognition (Bender et al., 2003).
Within this tool, we directly factorize the poste-
rior probability and determine the corresponding
chunk tag for each word of an input sequence. We
assume that the decisions depend only on a lim-
ited window ei+2
i−2 = ei−2...ei+2 around the current
</bodyText>
<note confidence="0.446604">
word ei and on the two predecessor chunk tags
</note>
<footnote confidence="0.5418915">
ci−1
i−2. In addition, part-of-speech (POS) tags gI1
</footnote>
<figureCaption confidence="0.7777115">
are assigned and incorporated into the model (cf.
Figure 3). Thus, we obtain the following second-
</figureCaption>
<bodyText confidence="0.999975866666666">
where the step from Eq. 4 to 5 reflects our model
assumptions.
Furthermore, we have implemented a set of bi-
nary valued feature functions for our system, in-
cluding lexical, word and transition features, prior
features, and compound features, cf. (Bender et
al., 2003). We run simple count-based feature
reduction and train the model parameters using
the Generalized Iterative Scaling (GIS) algorithm
(Darroch and Ratcliff, 1972). In practice, the
training procedure tends to result in an overfitted
model. To avoid this, a smoothing method is ap-
plied where a Gaussian prior on the parameters is
assumed (Chen and Rosenfeld, 1999).
Within our reranking framework, we firstly use
the ME based tagger to produce the POS and
chunk sequences for the different n-best list hy-
potheses. Given several n-gram models trained on
the WSJ corpus for both POS and chunk models,
we then rescore the n-best hypotheses and simply
use the log-probabilities as additional features. In
order to adapt our system to the characteristics of
the data used, we build POS and chunk n-gram
models on the training corpus part. These domain-
specific models are also added to the n-best lists.
The ME chunking approach does not model ex-
plicit syntactic linkages of words. Instead, it in-
corporates a statistical framework to exploit valid
and syntactically coherent groups of words by ad-
ditionally looking at the word classes.
</bodyText>
<sectionHeader confidence="0.99982" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.9999221">
For the experiments, we use the translation sys-
tem described in (Zens et al., 2005). Our phrase-
based decoder uses several models during search
that are interpolated in a log-linear way (as ex-
pressed in Eq. 3), such as phrase-based translation
models, word-based lexicon models, a language,
deletion and simple reordering model and word
and phrase penalties. A word graph containing
the most likely translation hypotheses is generated
during the search process. Out of this compact
</bodyText>
<page confidence="0.997791">
44
</page>
<table confidence="0.999578666666667">
Supplied Data Track
Arabic Chinese Japanese English
Train Sentences 20 000
Running Words 180 075 176199 198 453 189 927
Vocabulary 15 371 8 687 9 277 6 870
Singletons 8 319 4 006 4 431 2 888
C-Star’03 Sentences 506
Running Words 3 552 3 630 4130 3 823
OOVs (Running Words) 133 114 61 65
IWSLT’04 Sentences 500
Running Words 3 597 3 681 4131 3 837
OOVs (Running Words) 142 83 71 58
</table>
<tableCaption confidence="0.999957">
Table 1: Corpus statistics after preprocessing.
</tableCaption>
<bodyText confidence="0.9999564">
representation, we extract n-best lists as described
in (Zens and Ney, 2005). These n-best lists serve
as a starting point for our experiments. The meth-
ods presented in Section 3 produce scores that are
used as additional features for the n-best lists.
</bodyText>
<subsectionHeader confidence="0.973496">
4.1 Corpora
</subsectionHeader>
<bodyText confidence="0.9999528">
The experiments are carried out on a subset
of the Basic Travel Expression Corpus (BTEC)
(Takezawa et al., 2002), as it is used for the sup-
plied data track condition of the IWSLT evaluation
campaign. BTEC is a multilingual speech corpus
which contains tourism-related sentences similar
to those that are found in phrase books. For the
supplied data track, the training corpus contains
20000 sentences. Two test sets, C-Star’03 and
IWSLT’04, are available for the language pairs
Arabic-English, Chinese-English and Japanese-
English.
The corpus statistics are shown in Table 1. The
average source sentence length is between seven
and eight words for all languages. So the task is
rather limited and very domain-specific. The ad-
vantage is that many different reranking experi-
ments with varying feature function settings can
be carried out easily and quickly in order to ana-
lyze the effects of the different models.
In the following, we use the C-Star’03 set for
development and tuning of the system’s parame-
ters. After that, the IWSLT’04 set is used as a
blind test set in order to measure the performance
of the models.
</bodyText>
<subsectionHeader confidence="0.984345">
4.2 Rescoring experiments
</subsectionHeader>
<bodyText confidence="0.99993572972973">
The use of n-best lists in machine translation has
several advantages. It alleviates the effects of the
huge search space which is represented in word
graphs by using a compact excerpt of the n best
hypotheses generated by the system. Especially
for limited domain tasks, the size of the n-best list
can be rather small but still yield good oracle er-
ror rates. Empirically, n-best lists should have an
appropriate size such that the oracle error rate, i.e.
the error rate of the best hypothesis with respect to
an error measure (such as WER or PER) is approx-
imately half the baseline error rate of the system.
N-best lists are suitable for easily applying several
rescoring techniques since the hypotheses are al-
ready fully generated. In comparison, word graph
rescoring techniques need specialized tools which
can traverse the graph accordingly. Since a node
within a word graph allows for many histories, one
can only apply local rescoring techniques, whereas
for n-best lists, techniques can be used that con-
sider properties of the whole sentence.
For the Chinese-English and Arabic-English
task, we set the n-best list size to n = 1500. For
Japanese-English, n = 1000 produces oracle er-
ror rates that are deemed to be sufficiently low,
namely 17.7% and 14.8% for WER and PER, re-
spectively. The single-best output for Japanese-
English has a word error rate of 33.3% and
position-independent word error rate of 25.9%.
For the experiments, we add additional fea-
tures to the initial models of our decoder that have
shown to be particularly useful in the past, such as
IBM model 1 score, a clustered language model
score and a word penalty that prevents the hy-
potheses to become too short. A detailed defini-
tion of these additional features is given in (Zens
et al., 2005). Thus, the baseline we start with is
</bodyText>
<page confidence="0.996901">
45
</page>
<table confidence="0.999755285714286">
Chinese → English, C-Star’03 NIST BLEU[%] mWER[%] mPER[%]
Baseline 8.17 46.2 48.6 41.4
with supertagging/LDA 8.29 46.5 48.4 41.0
with link grammar 8.43 45.6 47.9 41.1
with supertagging/LDA + link grammar 8.22 47.5 47.7 40.8
with ME chunker 8.65 47.3 47.4 40.4
with all models 8.42 47.0 47.4 40.5
Chinese → English, IWSLT’04 NIST BLEU[%] mWER[%] mPER[%]
Baseline 8.67 45.5 49.1 39.8
with supertagging/LDA 8.68 45.4 49.8 40.3
with link grammar 8.81 45.0 49.0 40.2
with supertagging/LDA+link grammar 8.56 46.0 49.1 40.6
with ME chunker 9.00 44.6 49.3 40.6
with all models 8.89 46.2 48.1 39.6
</table>
<tableCaption confidence="0.987972">
Table 2: Effect of successively adding syntactic features to the Chinese-English n-best list for C-Star’03
(development set) and IWSLT’04 (test set).
</tableCaption>
<table confidence="0.99726075">
BASE Any messages for me?
RESC Do you have any messages for me?
REFE Do you have any messages for me?
BASE She, not yet?
RESC She has not come yet?
REFE Lenny, she has not come in?
BASE How much is it to the?
RESC How much is it to the local call?
REFE How much is it to the city centre?
BASE This blot or.
RESC This is not clean.
REFE This still is not clean.
</table>
<tableCaption confidence="0.998869">
Table 3: Translation examples for the Chinese-
</tableCaption>
<bodyText confidence="0.976912307692308">
English test set (IWSLT’04): baseline system
(BASE) vs. rescored hypotheses (RESC) and refer-
ence translation (REFE).
already a very strong one. The log-linear inter-
polation weights am from Eq. 3 are directly opti-
mized using the Downhill Simplex algorithm on a
linear combination of WER (word error rate), PER
(position-independent word error rate), NIST and
BLEU score.
In Table 2, we show the effect of adding the
presented features successively to the baseline.
Separate entries for experiments using supertag-
ging/LDA and link grammars show that a combi-
nation of these syntactic approaches always yields
some gain in translation quality (regarding BLEU
score). The performance of the maximum-entropy
based chunking is comparable. A combination of
all three models still yields a small improvement.
Table 3 shows some examples for the Chinese-
English test set. The rescored translations are syn-
tactically coherent, though semantical correctness
cannot be guaranteed. On the test data, we achieve
an overall improvement of 0.7%, 0.5% and 0.3%
in BLEU score for Chinese-English, Japanese-
English and Arabic-English, respectively (cf. Ta-
bles 4 and 5).
</bodyText>
<subsectionHeader confidence="0.992201">
4.3 Discussion
</subsectionHeader>
<bodyText confidence="0.999921909090909">
From the tables, it can be seen that the use of
syntactically motivated feature functions within
a reranking concept helps to slightly reduce the
number of translation errors of the overall trans-
lation system. Although the improvement on the
IWSLT’04 set is only moderate, the results are
nevertheless comparable or better to the ones from
(Och et al., 2004), where, starting from IBM
model 1 baseline, an additional improvement of
only 0.4% BLEU was achieved using more com-
plex methods.
For the maximum-entropy based chunking ap-
proach, n-grams with n = 4 work best for the
chunker that is trained on WSJ data. The domain-
specific rescoring model which results from the
chunker being trained on the BTEC corpora turns
out to prefer higher order n-grams, with n = 6 or
more. This might be an indicator of the domain-
specific rescoring model successfully capturing
more local context.
The training of the other models, i.e. supertag-
ging/LDA and link grammar, is also performed on
</bodyText>
<page confidence="0.997529">
46
</page>
<table confidence="0.999818857142857">
Japanese → English, C-Star’03 NIST BLEU[%] mWER[%] mPER[%]
Baseline 9.09 57.8 31.3 25.0
with supertagging/LDA 9.13 57.8 31.3 24.8
with link grammar 9.46 57.6 31.9 25.3
with supertagging/LDA + link grammar 9.24 58.2 31.0 24.8
with ME chunker 9.31 58.7 30.9 24.4
with all models 9.21 58.9 30.5 24.3
Japanese → English, IWSLT’04 NIST BLEU[%] mWER[%] mPER[%]
Baseline 9.22 54.7 34.1 25.5
with supertagging/LDA 9.27 54.8 34.2 25.6
with link grammar 9.37 54.9 34.3 25.9
with supertagging/LDA + link grammar 9.30 55.0 34.0 25.6
with ME chunker 9.27 55.0 34.2 25.5
with all models 9.27 55.2 33.9 25.5
</table>
<tableCaption confidence="0.990014">
Table 4: Effect of successively adding syntactic features to the Japanese-English n-best list for C-Star’03
(development set) and IWSLT’04 (test set).
</tableCaption>
<table confidence="0.999895571428571">
Arabic → English, C-Star’03 NIST BLEU[%] mWER[%] mPER[%]
Baseline 10.18 64.3 23.9 20.6
with supertagging/LDA 10.13 64.6 23.4 20.1
with link grammar 10.06 64.7 23.4 20.3
with supertagging/LDA + link grammar 10.20 65.0 23.2 20.2
with ME chunker 10.11 65.1 23.0 19.9
with all models 10.23 65.2 23.0 19.9
Arabic → English, IWSLT’04 NIST BLEU[%] mWER[%] mPER[%]
Baseline 9.75 59.8 26.1 21.9
with supertagging/LDA 9.77 60.5 25.6 21.5
with link grammar 9.74 60.5 25.9 21.7
with supertagging/LDA + link grammar 9.86 60.8 26.0 21.6
with ME chunker 9.71 59.9 25.9 21.8
with all models 9.84 60.1 26.4 21.9
</table>
<tableCaption confidence="0.759628">
Table 5: Effect of successively adding syntactic features to the Arabic-English n-best list for C-Star’03
(development set) and IWSLT’04 (test set).
</tableCaption>
<bodyText confidence="0.99933352631579">
out-of-domain data. Thus, further improvements
should be possible if the models were adapted to
the BTEC domain. This would require the prepa-
ration of an annotated corpus for the supertagger
and a specialized link grammar, which are both
time-consuming tasks.
The syntactically motivated methods (supertag-
ging/LDA and link grammars) perform similarly
to the maximum-entropy based chunker. It seems
that both approaches successfully exploit struc-
tural properties of language. However, one outlier
is ME chunking on the Chinese-English test data,
where we observe a lower BLEU but a larger NIST
score. For Arabic-English, the combination of all
methods does not seem to generalize well on the
test set. In that case, supertagging/LDA and link
grammar outperforms the ME chunker: the over-
all improvement is 1% absolute in terms of BLEU
score.
</bodyText>
<sectionHeader confidence="0.99954" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999987714285714">
We added syntactically motivated features to a sta-
tistical machine translation system in a rerank-
ing framework. The goal was to analyze whether
shallow parsing techniques help in identifying un-
grammatical hypotheses. We showed that some
improvements are possible by utilizing supertag-
ging, lightweight dependency analysis, a link
</bodyText>
<page confidence="0.997697">
47
</page>
<bodyText confidence="0.9999736">
grammar parser and a maximum-entropy based
chunk parser. Adding features to n-best lists and
discriminatively training the system on a develop-
ment set helped to gain up to 0.7% in BLEU score
on the test set.
Future work could include developing an
adapted LTAG for the BTEC domain or incor-
porating n-gram models into the link grammar
concept in order to derive a long-range language
model (Lafferty et al., 1992). However, we feel
that the current improvements are not significant
enough to justify these efforts. Additionally, we
will apply these reranking methods to larger cor-
pora in order to study the effects on longer sen-
tences from more complex domains.
</bodyText>
<sectionHeader confidence="0.999157" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999705625">
This work has been partly funded by the
European Union under the integrated project
TC-Star (Technology and Corpora for Speech
to Speech Translation, IST-2002-FP6-506738,
http://www.tc-star.org), and by the R&amp;D project
TRAMES managed by Bertin Technologies as
prime contractor and operated by the french DGA
(D´el´egation G´en´erale pour l’Armement).
</bodyText>
<sectionHeader confidence="0.99952" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999647146341464">
Srinivas Bangalore and Aravind K. Joshi. 1999. Su-
pertagging: An approach to almost parsing. Com-
putational Linguistics, 25(2):237–265.
Srinivas Bangalore. 2000. A lightweight dependency
analyzer for partial parsing. Computational Linguis-
tics, 6(2):113–138.
Oliver Bender, Klaus Macherey, Franz Josef Och, and
Hermann Ney. 2003. Comparison of alignment
templates and maximum entropy models for natural
language understanding. In EACL03: 10th Conf. of
the Europ. Chapter of the Association for Computa-
tional Linguistics, pages 11–18, Budapest, Hungary,
April.
Stanley F. Chen and Ronald Rosenfeld. 1999. A gaus-
sian prior for smoothing maximum entropy models.
Technical Report CMUCS-99-108, Carnegie Mellon
University, Pittsburgh, PA.
J. N. Darroch and D. Ratcliff. 1972. Generalized iter-
ative scaling for log-linear models. Annals of Math-
ematical Statistics, 43:1470–1480.
John Lafferty, Daniel Sleator, and Davy Temperley.
1992. Grammatical trigrams: A probabilistic model
of link grammar. In Proc. of the AAAI Fall Sympo-
sium on Probabilistic Approaches to Natural Lan-
guage, pages 89–97, Cambridge, MA.
Franz Josef Och and Hermann Ney. 2002. Discrimina-
tive training and maximum entropy models for sta-
tistical machine translation. In Proc. of the 40th An-
nual Meeting of the Association for Computational
Linguistics (ACL), pages 295–302, Philadelphia, PA,
July.
Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur,
Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar
Kumar, Libin Shen, David Smith, Katherine Eng,
Viren Jain, Zhen Jin, and Dragomir Radev. 2004.
A smorgasbord of features for statistical machine
translation. In Proc. 2004 Meeting of the North
American chapter of the Association for Compu-
tational Linguistics (HLT-NAACL), pages 161–168,
Boston, MA.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proc. of the
41st Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 160–167, Sapporo,
Japan, July.
William H. Press, Saul A. Teukolsky, William T. Vet-
terling, and Brian P. Flannery. 2002. Numerical
Recipes in C++. Cambridge University Press, Cam-
bridge, UK.
Daniel Sleator and Davy Temperley. 1993. Parsing
English with a link grammar. In Third International
Workshop on Parsing Technologies, Tilburg/Durbuy,
The Netherlands/Belgium, August.
Toshiyuki Takezawa, Eiichiro Sumita, F. Sugaya,
H. Yamamoto, and S. Yamamoto. 2002. Toward
a broad-coverage bilingual corpus for speech trans-
lation of travel conversations in the real world. In
Proc. of the Third Int. Conf. on Language Resources
and Evaluation (LREC), pages 147–152, Las Pal-
mas, Spain, May.
Erik F. Tjong Kim Sang and Sabine Buchholz.
2000. Introduction to the CoNLL-2000 shared
task: Chunking. In Proceedings of CoNLL-2000
and LLL-2000, pages 127–132, Lisbon, Portugal,
September.
XTAG Research Group. 2001. A Lexicalized Tree
Adjoining Grammar for English. Technical Re-
port IRCS-01-03, IRCS, University of Pennsylvania,
Philadelphia, PA, USA.
Richard Zens and Hermann Ney. 2005. Word graphs
for statistical machine translation. In 43rd Annual
Meeting of the Assoc. for Computational Linguis-
tics: Proc. Workshop on Building and Using Par-
allel Texts: Data-Driven Machine Translation and
Beyond, pages 191–198, Ann Arbor, MI, June.
Richard Zens, Oliver Bender, Saˇsa Hasan, Shahram
Khadivi, Evgeny Matusov, Jia Xu, Yuqi Zhang, and
Hermann Ney. 2005. The RWTH phrase-based
statistical machine translation system. In Proceed-
ings of the International Workshop on Spoken Lan-
guage Translation (IWSLT), pages 155–162, Pitts-
burgh, PA, October.
</reference>
<page confidence="0.999354">
48
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.853360">
<title confidence="0.999856">Reranking Translation Hypotheses Using Structural Properties</title>
<author confidence="0.99909">Saˇsa Hasan</author>
<author confidence="0.99909">Oliver Bender</author>
<author confidence="0.99909">Hermann</author>
<affiliation confidence="0.94312">Chair of Computer Science RWTH Aachen</affiliation>
<address confidence="0.989889">D-52056 Aachen,</address>
<abstract confidence="0.998010333333333">We investigate methods that add syntactically motivated features to a statistical machine translation system in a reranking framework. The goal is to analyze whether shallow parsing techniques help in identifying ungrammatical hypotheses. We show that improvements are possible by utilizing supertagging, lightweight dependency analysis, a link grammar parser and a maximum-entropy based chunk parser. features to lists and discriminatively training the system on a development set increases the BLEU score up to 0.7% on the test set.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>Aravind K Joshi</author>
</authors>
<title>Supertagging: An approach to almost parsing.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>2</issue>
<contexts>
<context position="1658" citStr="Bangalore and Joshi, 1999" startWordPosition="240" endWordPosition="243">point of view, illogical. The main purpose of this paper is to investigate a means of identifying ungrammatical hypotheses from the output of a machine translation system by using grammatical knowledge that expresses syntactic dependencies of words or word groups. We introduce several methods that try to establish this kind of linkage between the words of a hypothesis and, thus, determine its well-formedness, or “fluency”. We perform rescoring experiments that rerank n-best lists according to the presented framework. As methodologies deriving well-formedness of a sentence we use supertagging (Bangalore and Joshi, 1999) with lightweight dependency analysis (LDA)1 (Bangalore, 2000), link grammars (Sleator and Temperley, 1993) and a maximumentropy (ME) based chunk parser (Bender et al., 2003). The former two approaches explicitly model the syntactic dependencies between words. Each hypothesis that contains irregularities, such as broken linkages or non-satisfied dependencies, should be penalized or rejected accordingly. For the ME chunker, the idea is to train n-gram models on the chunk or POS sequences and directly use the log-probability as feature score. In general, these concepts and the underlying program</context>
<context position="6209" citStr="Bangalore and Joshi, 1999" startWordPosition="983" endWordPosition="986"> models h(·) can be easily integrated into the overall system. The model scaling factors λM1 are trained according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by an error criterion (Och, 2003). For the results reported in this paper, we optimized the scaling factors with respect to a linear interpolation of word error rate (WER), position-independent word error rate (PER), BLEU and NIST score using the Downhill Simplex algorithm (Press et al., 2002). 3.2 Supertagging/LDA Supertagging (Bangalore and Joshi, 1999) uses the Lexicalized Tree Adjoining Grammar formalism (LTAG) (XTAG Research Group, 2001). Tree Adjoining Grammars incorporate a tree-rewriting formalism using elementary trees that can be combined by two operations, namely substitution and adjunction, to derive more complex tree structures of the sentence considered. Lexicalization allows us to associate each elementary tree with a lexical item called the anchor. In LTAGs, every elementary tree has such a lexical anchor, also called head word. It is possible that there is more than one elementary structure associated with a lexical item, as e</context>
<context position="8321" citStr="Bangalore and Joshi, 1999" startWordPosition="1333" endWordPosition="1337"> trees. coded within the supertags. Usually, a lexical item can have many supertags, depending on the various contexts it appears in. Therefore, the local ambiguity is larger than for the case of POS tags. An LTAG parser for this scenario can be very slow, i.e. its computational complexity is in O(n6), because of the large number of supertags, i.e. elementary trees, that have to be examined during a parse. In order to speed up the parsing process, we can apply n-gram models on a supertag basis in order to filter out incompatible descriptions and thus improve the performance of the parser. In (Bangalore and Joshi, 1999), a trigram supertagger with smoothing and back-off is reported that achieves an accuracy of 92.2% when trained on one million running words. There is another aspect to the dependencies coded in the elementary structures. We can use them to actually derive a shallow parse of the sentence in linear time. The procedure is presented in (Bangalore, 2000) and is called lightweight dependency analysis. The concept is comparable to chunking. The lightweight dependency analyzer (LDA) finds the arguments for the encoded dependency requirements. There exist two types of slots that can be filled. On the </context>
</contexts>
<marker>Bangalore, Joshi, 1999</marker>
<rawString>Srinivas Bangalore and Aravind K. Joshi. 1999. Supertagging: An approach to almost parsing. Computational Linguistics, 25(2):237–265.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
</authors>
<title>A lightweight dependency analyzer for partial parsing.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>6</volume>
<issue>2</issue>
<contexts>
<context position="1720" citStr="Bangalore, 2000" startWordPosition="250" endWordPosition="251">te a means of identifying ungrammatical hypotheses from the output of a machine translation system by using grammatical knowledge that expresses syntactic dependencies of words or word groups. We introduce several methods that try to establish this kind of linkage between the words of a hypothesis and, thus, determine its well-formedness, or “fluency”. We perform rescoring experiments that rerank n-best lists according to the presented framework. As methodologies deriving well-formedness of a sentence we use supertagging (Bangalore and Joshi, 1999) with lightweight dependency analysis (LDA)1 (Bangalore, 2000), link grammars (Sleator and Temperley, 1993) and a maximumentropy (ME) based chunk parser (Bender et al., 2003). The former two approaches explicitly model the syntactic dependencies between words. Each hypothesis that contains irregularities, such as broken linkages or non-satisfied dependencies, should be penalized or rejected accordingly. For the ME chunker, the idea is to train n-gram models on the chunk or POS sequences and directly use the log-probability as feature score. In general, these concepts and the underlying programs should be robust and fast in order to be able to cope with l</context>
<context position="8673" citStr="Bangalore, 2000" startWordPosition="1394" endWordPosition="1395">trees, that have to be examined during a parse. In order to speed up the parsing process, we can apply n-gram models on a supertag basis in order to filter out incompatible descriptions and thus improve the performance of the parser. In (Bangalore and Joshi, 1999), a trigram supertagger with smoothing and back-off is reported that achieves an accuracy of 92.2% when trained on one million running words. There is another aspect to the dependencies coded in the elementary structures. We can use them to actually derive a shallow parse of the sentence in linear time. The procedure is presented in (Bangalore, 2000) and is called lightweight dependency analysis. The concept is comparable to chunking. The lightweight dependency analyzer (LDA) finds the arguments for the encoded dependency requirements. There exist two types of slots that can be filled. On the one hand, nodes marked for substitution (in α-trees) have to be filled by the complements of the lexical anchor. On the other hand, the foot nodes (i.e. nodes marked for adjunction in β-trees) take words that are being modified by the supertag. Figure 1 shows a tree derived by LDA on the sentence the food was very delicious from the C-Star’03 corpus </context>
</contexts>
<marker>Bangalore, 2000</marker>
<rawString>Srinivas Bangalore. 2000. A lightweight dependency analyzer for partial parsing. Computational Linguistics, 6(2):113–138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver Bender</author>
<author>Klaus Macherey</author>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Comparison of alignment templates and maximum entropy models for natural language understanding.</title>
<date>2003</date>
<booktitle>In EACL03: 10th Conf. of the Europ. Chapter of the Association for Computational Linguistics,</booktitle>
<pages>11--18</pages>
<location>Budapest, Hungary,</location>
<contexts>
<context position="1832" citStr="Bender et al., 2003" startWordPosition="266" endWordPosition="269">grammatical knowledge that expresses syntactic dependencies of words or word groups. We introduce several methods that try to establish this kind of linkage between the words of a hypothesis and, thus, determine its well-formedness, or “fluency”. We perform rescoring experiments that rerank n-best lists according to the presented framework. As methodologies deriving well-formedness of a sentence we use supertagging (Bangalore and Joshi, 1999) with lightweight dependency analysis (LDA)1 (Bangalore, 2000), link grammars (Sleator and Temperley, 1993) and a maximumentropy (ME) based chunk parser (Bender et al., 2003). The former two approaches explicitly model the syntactic dependencies between words. Each hypothesis that contains irregularities, such as broken linkages or non-satisfied dependencies, should be penalized or rejected accordingly. For the ME chunker, the idea is to train n-gram models on the chunk or POS sequences and directly use the log-probability as feature score. In general, these concepts and the underlying programs should be robust and fast in order to be able to cope with large amounts of data (as it is the case for n-best lists). The experiments presented show a small though consist</context>
<context position="12754" citStr="Bender et al., 2003" startWordPosition="2062" endWordPosition="2065">it was discarded. 3.4 ME chunking Like the methods described in the two preceding sections, text chunking consists of dividing a text into syntactically correlated non-overlapping groups of words. Figure 3 shows again our example sentence illustrating this task. Chunks are represented as groups of words between square brackets. We employ the 11 chunk types as defined for the CoNLL-2000 shared task (Tjong Kim Sang and Buchholz, 2000). For the experiments, we apply a maximumentropy based tagger which has been successfully evaluated on natural language understanding and named entity recognition (Bender et al., 2003). Within this tool, we directly factorize the posterior probability and determine the corresponding chunk tag for each word of an input sequence. We assume that the decisions depend only on a limited window ei+2 i−2 = ei−2...ei+2 around the current word ei and on the two predecessor chunk tags ci−1 i−2. In addition, part-of-speech (POS) tags gI1 are assigned and incorporated into the model (cf. Figure 3). Thus, we obtain the following secondwhere the step from Eq. 4 to 5 reflects our model assumptions. Furthermore, we have implemented a set of binary valued feature functions for our system, in</context>
</contexts>
<marker>Bender, Macherey, Och, Ney, 2003</marker>
<rawString>Oliver Bender, Klaus Macherey, Franz Josef Och, and Hermann Ney. 2003. Comparison of alignment templates and maximum entropy models for natural language understanding. In EACL03: 10th Conf. of the Europ. Chapter of the Association for Computational Linguistics, pages 11–18, Budapest, Hungary, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
<author>Ronald Rosenfeld</author>
</authors>
<title>A gaussian prior for smoothing maximum entropy models.</title>
<date>1999</date>
<tech>Technical Report CMUCS-99-108,</tech>
<institution>Carnegie Mellon University,</institution>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="13827" citStr="Chen and Rosenfeld, 1999" startWordPosition="2237" endWordPosition="2240">re the step from Eq. 4 to 5 reflects our model assumptions. Furthermore, we have implemented a set of binary valued feature functions for our system, including lexical, word and transition features, prior features, and compound features, cf. (Bender et al., 2003). We run simple count-based feature reduction and train the model parameters using the Generalized Iterative Scaling (GIS) algorithm (Darroch and Ratcliff, 1972). In practice, the training procedure tends to result in an overfitted model. To avoid this, a smoothing method is applied where a Gaussian prior on the parameters is assumed (Chen and Rosenfeld, 1999). Within our reranking framework, we firstly use the ME based tagger to produce the POS and chunk sequences for the different n-best list hypotheses. Given several n-gram models trained on the WSJ corpus for both POS and chunk models, we then rescore the n-best hypotheses and simply use the log-probabilities as additional features. In order to adapt our system to the characteristics of the data used, we build POS and chunk n-gram models on the training corpus part. These domainspecific models are also added to the n-best lists. The ME chunking approach does not model explicit syntactic linkage</context>
</contexts>
<marker>Chen, Rosenfeld, 1999</marker>
<rawString>Stanley F. Chen and Ronald Rosenfeld. 1999. A gaussian prior for smoothing maximum entropy models. Technical Report CMUCS-99-108, Carnegie Mellon University, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J N Darroch</author>
<author>D Ratcliff</author>
</authors>
<title>Generalized iterative scaling for log-linear models.</title>
<date>1972</date>
<journal>Annals of Mathematical Statistics,</journal>
<pages>43--1470</pages>
<contexts>
<context position="13626" citStr="Darroch and Ratcliff, 1972" startWordPosition="2203" endWordPosition="2206">ent word ei and on the two predecessor chunk tags ci−1 i−2. In addition, part-of-speech (POS) tags gI1 are assigned and incorporated into the model (cf. Figure 3). Thus, we obtain the following secondwhere the step from Eq. 4 to 5 reflects our model assumptions. Furthermore, we have implemented a set of binary valued feature functions for our system, including lexical, word and transition features, prior features, and compound features, cf. (Bender et al., 2003). We run simple count-based feature reduction and train the model parameters using the Generalized Iterative Scaling (GIS) algorithm (Darroch and Ratcliff, 1972). In practice, the training procedure tends to result in an overfitted model. To avoid this, a smoothing method is applied where a Gaussian prior on the parameters is assumed (Chen and Rosenfeld, 1999). Within our reranking framework, we firstly use the ME based tagger to produce the POS and chunk sequences for the different n-best list hypotheses. Given several n-gram models trained on the WSJ corpus for both POS and chunk models, we then rescore the n-best hypotheses and simply use the log-probabilities as additional features. In order to adapt our system to the characteristics of the data u</context>
</contexts>
<marker>Darroch, Ratcliff, 1972</marker>
<rawString>J. N. Darroch and D. Ratcliff. 1972. Generalized iterative scaling for log-linear models. Annals of Mathematical Statistics, 43:1470–1480.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Daniel Sleator</author>
<author>Davy Temperley</author>
</authors>
<title>Grammatical trigrams: A probabilistic model of link grammar.</title>
<date>1992</date>
<booktitle>In Proc. of the AAAI Fall Symposium on Probabilistic Approaches to Natural Language,</booktitle>
<pages>89--97</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="10872" citStr="Lafferty et al., 1992" startWordPosition="1753" endWordPosition="1756">in the link grammar formalism to derive correct linkages, i.e. sets of links, of a sequence of words: 1. Planarity: links are not allowed to cross each other 2. Connectivity: links suffice to connect all words of a sentence 3. Satisfaction: linking requirements of each word are satisfied An example of a valid linkage is shown in Figure 2. The link grammar parser that we use is freely available from the authors’ website.3 Similar to LTAG, the link grammar formalism is lexicalized which allows for enhancing the methods with probabilistic n-gram models (as is also the case for supertagging). In (Lafferty et al., 1992), the link grammar is used to derive a new class of 3http://www.link.cs.cmu.edu/link/ 43 [NP the food ] [VP was] [ADJP very delicious] the/DT food/NN was/VBD very/RB delicious/JJ Figure 3: Chunking and POS tagging: a tag next to the opening bracket denotes the type of chunk, whereas the corresponding POS tag is given after the word. p( i−1 i+2 i+2 ci |ci−2 , ei−2, gi−2) , (5) I i=1 order model: Pr(cI1|eI1, gI1) = I = i=1 Pr(ci|ci−1 1 , eI 1,gI 1) (4) language models that, in comparison to traditional n-gram LMs, incorporate capabilities for expressing long-range dependencies between words. The</context>
<context position="25112" citStr="Lafferty et al., 1992" startWordPosition="4099" endWordPosition="4102">s to analyze whether shallow parsing techniques help in identifying ungrammatical hypotheses. We showed that some improvements are possible by utilizing supertagging, lightweight dependency analysis, a link 47 grammar parser and a maximum-entropy based chunk parser. Adding features to n-best lists and discriminatively training the system on a development set helped to gain up to 0.7% in BLEU score on the test set. Future work could include developing an adapted LTAG for the BTEC domain or incorporating n-gram models into the link grammar concept in order to derive a long-range language model (Lafferty et al., 1992). However, we feel that the current improvements are not significant enough to justify these efforts. Additionally, we will apply these reranking methods to larger corpora in order to study the effects on longer sentences from more complex domains. Acknowledgments This work has been partly funded by the European Union under the integrated project TC-Star (Technology and Corpora for Speech to Speech Translation, IST-2002-FP6-506738, http://www.tc-star.org), and by the R&amp;D project TRAMES managed by Bertin Technologies as prime contractor and operated by the french DGA (D´el´egation G´en´erale po</context>
</contexts>
<marker>Lafferty, Sleator, Temperley, 1992</marker>
<rawString>John Lafferty, Daniel Sleator, and Davy Temperley. 1992. Grammatical trigrams: A probabilistic model of link grammar. In Proc. of the AAAI Fall Symposium on Probabilistic Approaches to Natural Language, pages 89–97, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proc. of the 40th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>295--302</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="5073" citStr="Och and Ney, 2002" startWordPosition="791" endWordPosition="794">proach to SMT In statistical machine translation, the best translation ˆe1 = ˆe1 . . . ˆei . . . ˆeˆI of source words fJ ˆI 1 = f1 ... fj ... fJ is obtained by maximizing the conditional probability ˆe1 = argmax ˆI I,ei = argmax {Pr(fJ 1 |eI 1) · Pr(eI1)} I,ei using Bayes decision rule. The first probability on the right-hand side of the equation denotes the translation model whereas the second is the target language model. An alternative to this classical source-channel approach is the direct modeling of the posterior probability Pr(eI1|fJ1 ) which is utilized here. Using a log-linear model (Och and Ney, 2002), we obtain (�M ) exp m=1 λmhm(eI 1, fJ 1 ) E exp (EM1 λmhm(e&apos;i&apos;, fJ1)), e�I� 1 (2) where λm are the scaling factors of the models denoted by feature functions hm(·). The denominator represents a normalization factor that depends only on the source sentence fJ1 . Therefore, we can omit it during the search process, leading to the following decision rule: ˆe1 = argmax ˆI I,ei � M m=1 E � λmhm(eI1, fJ1) (3) This approach is a generalization of the sourcechannel approach. It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λ</context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>Franz Josef Och and Hermann Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In Proc. of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 295–302, Philadelphia, PA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Daniel Gildea</author>
</authors>
<title>Sanjeev Khudanpur, Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar Kumar,</title>
<date>2004</date>
<booktitle>In Proc. 2004 Meeting of the North American chapter of the Association for Computational Linguistics (HLT-NAACL),</booktitle>
<pages>161--168</pages>
<location>Libin Shen, David Smith, Katherine Eng, Viren Jain, Zhen</location>
<marker>Och, Gildea, 2004</marker>
<rawString>Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur, Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar Kumar, Libin Shen, David Smith, Katherine Eng, Viren Jain, Zhen Jin, and Dragomir Radev. 2004. A smorgasbord of features for statistical machine translation. In Proc. 2004 Meeting of the North American chapter of the Association for Computational Linguistics (HLT-NAACL), pages 161–168, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. of the 41st Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan,</location>
<contexts>
<context position="5885" citStr="Och, 2003" startWordPosition="937" endWordPosition="938">ization factor that depends only on the source sentence fJ1 . Therefore, we can omit it during the search process, leading to the following decision rule: ˆe1 = argmax ˆI I,ei � M m=1 E � λmhm(eI1, fJ1) (3) This approach is a generalization of the sourcechannel approach. It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM1 are trained according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by an error criterion (Och, 2003). For the results reported in this paper, we optimized the scaling factors with respect to a linear interpolation of word error rate (WER), position-independent word error rate (PER), BLEU and NIST score using the Downhill Simplex algorithm (Press et al., 2002). 3.2 Supertagging/LDA Supertagging (Bangalore and Joshi, 1999) uses the Lexicalized Tree Adjoining Grammar formalism (LTAG) (XTAG Research Group, 2001). Tree Adjoining Grammars incorporate a tree-rewriting formalism using elementary trees that can be combined by two operations, namely substitution and adjunction, to derive more complex </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proc. of the 41st Annual Meeting of the Association for Computational Linguistics (ACL), pages 160–167, Sapporo, Japan, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William H Press</author>
<author>Saul A Teukolsky</author>
<author>William T Vetterling</author>
<author>Brian P Flannery</author>
</authors>
<title>Numerical Recipes in C++.</title>
<date>2002</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK.</location>
<contexts>
<context position="6146" citStr="Press et al., 2002" startWordPosition="976" endWordPosition="979">cechannel approach. It has the advantage that additional models h(·) can be easily integrated into the overall system. The model scaling factors λM1 are trained according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by an error criterion (Och, 2003). For the results reported in this paper, we optimized the scaling factors with respect to a linear interpolation of word error rate (WER), position-independent word error rate (PER), BLEU and NIST score using the Downhill Simplex algorithm (Press et al., 2002). 3.2 Supertagging/LDA Supertagging (Bangalore and Joshi, 1999) uses the Lexicalized Tree Adjoining Grammar formalism (LTAG) (XTAG Research Group, 2001). Tree Adjoining Grammars incorporate a tree-rewriting formalism using elementary trees that can be combined by two operations, namely substitution and adjunction, to derive more complex tree structures of the sentence considered. Lexicalization allows us to associate each elementary tree with a lexical item called the anchor. In LTAGs, every elementary tree has such a lexical anchor, also called head word. It is possible that there is more tha</context>
</contexts>
<marker>Press, Teukolsky, Vetterling, Flannery, 2002</marker>
<rawString>William H. Press, Saul A. Teukolsky, William T. Vetterling, and Brian P. Flannery. 2002. Numerical Recipes in C++. Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Sleator</author>
<author>Davy Temperley</author>
</authors>
<title>Parsing English with a link grammar.</title>
<date>1993</date>
<booktitle>In Third International Workshop on Parsing Technologies, Tilburg/Durbuy, The Netherlands/Belgium,</booktitle>
<contexts>
<context position="1765" citStr="Sleator and Temperley, 1993" startWordPosition="254" endWordPosition="257">atical hypotheses from the output of a machine translation system by using grammatical knowledge that expresses syntactic dependencies of words or word groups. We introduce several methods that try to establish this kind of linkage between the words of a hypothesis and, thus, determine its well-formedness, or “fluency”. We perform rescoring experiments that rerank n-best lists according to the presented framework. As methodologies deriving well-formedness of a sentence we use supertagging (Bangalore and Joshi, 1999) with lightweight dependency analysis (LDA)1 (Bangalore, 2000), link grammars (Sleator and Temperley, 1993) and a maximumentropy (ME) based chunk parser (Bender et al., 2003). The former two approaches explicitly model the syntactic dependencies between words. Each hypothesis that contains irregularities, such as broken linkages or non-satisfied dependencies, should be penalized or rejected accordingly. For the ME chunker, the idea is to train n-gram models on the chunk or POS sequences and directly use the log-probability as feature score. In general, these concepts and the underlying programs should be robust and fast in order to be able to cope with large amounts of data (as it is the case for n</context>
<context position="10116" citStr="Sleator and Temperley, 1993" startWordPosition="1626" endWordPosition="1629">grammar: example of a valid linkage satisfying all constraints. • Supertagger output: directly use the loglikelihoods as feature score. This did not improve performance significantly, so the model was discarded from the final system. • LDA output: – dependency coverage: determine the number of covered elements, i.e. where the dependency slots are filled to the left and right – separate features for the number of modifiers and complements determined by the LDA 3.3 Link grammar Similar to the ideas presented in the previous section, link grammars also explicitly code dependencies between words (Sleator and Temperley, 1993). These dependencies are called links which reflect the local requirements of each word. Several constraints have to be satisfied within the link grammar formalism to derive correct linkages, i.e. sets of links, of a sequence of words: 1. Planarity: links are not allowed to cross each other 2. Connectivity: links suffice to connect all words of a sentence 3. Satisfaction: linking requirements of each word are satisfied An example of a valid linkage is shown in Figure 2. The link grammar parser that we use is freely available from the authors’ website.3 Similar to LTAG, the link grammar formali</context>
</contexts>
<marker>Sleator, Temperley, 1993</marker>
<rawString>Daniel Sleator and Davy Temperley. 1993. Parsing English with a link grammar. In Third International Workshop on Parsing Technologies, Tilburg/Durbuy, The Netherlands/Belgium, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Toshiyuki Takezawa</author>
<author>Eiichiro Sumita</author>
<author>F Sugaya</author>
<author>H Yamamoto</author>
<author>S Yamamoto</author>
</authors>
<title>Toward a broad-coverage bilingual corpus for speech translation of travel conversations in the real world.</title>
<date>2002</date>
<booktitle>In Proc. of the Third Int. Conf. on Language Resources and Evaluation (LREC),</booktitle>
<pages>147--152</pages>
<location>Las Palmas, Spain,</location>
<contexts>
<context position="15897" citStr="Takezawa et al., 2002" startWordPosition="2588" endWordPosition="2591"> 2 888 C-Star’03 Sentences 506 Running Words 3 552 3 630 4130 3 823 OOVs (Running Words) 133 114 61 65 IWSLT’04 Sentences 500 Running Words 3 597 3 681 4131 3 837 OOVs (Running Words) 142 83 71 58 Table 1: Corpus statistics after preprocessing. representation, we extract n-best lists as described in (Zens and Ney, 2005). These n-best lists serve as a starting point for our experiments. The methods presented in Section 3 produce scores that are used as additional features for the n-best lists. 4.1 Corpora The experiments are carried out on a subset of the Basic Travel Expression Corpus (BTEC) (Takezawa et al., 2002), as it is used for the supplied data track condition of the IWSLT evaluation campaign. BTEC is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books. For the supplied data track, the training corpus contains 20000 sentences. Two test sets, C-Star’03 and IWSLT’04, are available for the language pairs Arabic-English, Chinese-English and JapaneseEnglish. The corpus statistics are shown in Table 1. The average source sentence length is between seven and eight words for all languages. So the task is rather limited and very domain-spec</context>
</contexts>
<marker>Takezawa, Sumita, Sugaya, Yamamoto, Yamamoto, 2002</marker>
<rawString>Toshiyuki Takezawa, Eiichiro Sumita, F. Sugaya, H. Yamamoto, and S. Yamamoto. 2002. Toward a broad-coverage bilingual corpus for speech translation of travel conversations in the real world. In Proc. of the Third Int. Conf. on Language Resources and Evaluation (LREC), pages 147–152, Las Palmas, Spain, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
<author>Sabine Buchholz</author>
</authors>
<title>Introduction to the CoNLL-2000 shared task: Chunking.</title>
<date>2000</date>
<booktitle>In Proceedings of CoNLL-2000 and LLL-2000,</booktitle>
<pages>127--132</pages>
<location>Lisbon, Portugal,</location>
<contexts>
<context position="12570" citStr="Sang and Buchholz, 2000" startWordPosition="2035" endWordPosition="2038">hould be a strong indicator of a syntactically correct sentence. Additionally, we added a normalized cost of the matching process which turned out not to be very helpful for rescoring, so it was discarded. 3.4 ME chunking Like the methods described in the two preceding sections, text chunking consists of dividing a text into syntactically correlated non-overlapping groups of words. Figure 3 shows again our example sentence illustrating this task. Chunks are represented as groups of words between square brackets. We employ the 11 chunk types as defined for the CoNLL-2000 shared task (Tjong Kim Sang and Buchholz, 2000). For the experiments, we apply a maximumentropy based tagger which has been successfully evaluated on natural language understanding and named entity recognition (Bender et al., 2003). Within this tool, we directly factorize the posterior probability and determine the corresponding chunk tag for each word of an input sequence. We assume that the decisions depend only on a limited window ei+2 i−2 = ei−2...ei+2 around the current word ei and on the two predecessor chunk tags ci−1 i−2. In addition, part-of-speech (POS) tags gI1 are assigned and incorporated into the model (cf. Figure 3). Thus, w</context>
</contexts>
<marker>Sang, Buchholz, 2000</marker>
<rawString>Erik F. Tjong Kim Sang and Sabine Buchholz. 2000. Introduction to the CoNLL-2000 shared task: Chunking. In Proceedings of CoNLL-2000 and LLL-2000, pages 127–132, Lisbon, Portugal, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>XTAG Research Group</author>
</authors>
<title>A Lexicalized Tree Adjoining Grammar for English.</title>
<date>2001</date>
<tech>Technical Report IRCS-01-03,</tech>
<institution>IRCS, University of Pennsylvania,</institution>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="6298" citStr="Group, 2001" startWordPosition="997" endWordPosition="998">d according to the maximum entropy principle, e.g., using the GIS algorithm. Alternatively, one can train them with respect to the final translation quality measured by an error criterion (Och, 2003). For the results reported in this paper, we optimized the scaling factors with respect to a linear interpolation of word error rate (WER), position-independent word error rate (PER), BLEU and NIST score using the Downhill Simplex algorithm (Press et al., 2002). 3.2 Supertagging/LDA Supertagging (Bangalore and Joshi, 1999) uses the Lexicalized Tree Adjoining Grammar formalism (LTAG) (XTAG Research Group, 2001). Tree Adjoining Grammars incorporate a tree-rewriting formalism using elementary trees that can be combined by two operations, namely substitution and adjunction, to derive more complex tree structures of the sentence considered. Lexicalization allows us to associate each elementary tree with a lexical item called the anchor. In LTAGs, every elementary tree has such a lexical anchor, also called head word. It is possible that there is more than one elementary structure associated with a lexical item, as e.g. for the case of verbs with different subcategorization frames. The elementary structu</context>
</contexts>
<marker>Group, 2001</marker>
<rawString>XTAG Research Group. 2001. A Lexicalized Tree Adjoining Grammar for English. Technical Report IRCS-01-03, IRCS, University of Pennsylvania, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Zens</author>
<author>Hermann Ney</author>
</authors>
<title>Word graphs for statistical machine translation.</title>
<date>2005</date>
<booktitle>In 43rd Annual Meeting of the Assoc. for Computational Linguistics: Proc. Workshop on Building and Using Parallel Texts: Data-Driven Machine Translation and Beyond,</booktitle>
<pages>191--198</pages>
<location>Ann Arbor, MI,</location>
<contexts>
<context position="15596" citStr="Zens and Ney, 2005" startWordPosition="2537" endWordPosition="2540"> containing the most likely translation hypotheses is generated during the search process. Out of this compact 44 Supplied Data Track Arabic Chinese Japanese English Train Sentences 20 000 Running Words 180 075 176199 198 453 189 927 Vocabulary 15 371 8 687 9 277 6 870 Singletons 8 319 4 006 4 431 2 888 C-Star’03 Sentences 506 Running Words 3 552 3 630 4130 3 823 OOVs (Running Words) 133 114 61 65 IWSLT’04 Sentences 500 Running Words 3 597 3 681 4131 3 837 OOVs (Running Words) 142 83 71 58 Table 1: Corpus statistics after preprocessing. representation, we extract n-best lists as described in (Zens and Ney, 2005). These n-best lists serve as a starting point for our experiments. The methods presented in Section 3 produce scores that are used as additional features for the n-best lists. 4.1 Corpora The experiments are carried out on a subset of the Basic Travel Expression Corpus (BTEC) (Takezawa et al., 2002), as it is used for the supplied data track condition of the IWSLT evaluation campaign. BTEC is a multilingual speech corpus which contains tourism-related sentences similar to those that are found in phrase books. For the supplied data track, the training corpus contains 20000 sentences. Two test </context>
</contexts>
<marker>Zens, Ney, 2005</marker>
<rawString>Richard Zens and Hermann Ney. 2005. Word graphs for statistical machine translation. In 43rd Annual Meeting of the Assoc. for Computational Linguistics: Proc. Workshop on Building and Using Parallel Texts: Data-Driven Machine Translation and Beyond, pages 191–198, Ann Arbor, MI, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Zens</author>
<author>Oliver Bender</author>
<author>Saˇsa Hasan</author>
<author>Shahram Khadivi</author>
<author>Evgeny Matusov</author>
<author>Jia Xu</author>
<author>Yuqi Zhang</author>
<author>Hermann Ney</author>
</authors>
<title>The RWTH phrase-based statistical machine translation system.</title>
<date>2005</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation (IWSLT),</booktitle>
<pages>155--162</pages>
<location>Pittsburgh, PA,</location>
<contexts>
<context position="14690" citStr="Zens et al., 2005" startWordPosition="2381" endWordPosition="2384">score the n-best hypotheses and simply use the log-probabilities as additional features. In order to adapt our system to the characteristics of the data used, we build POS and chunk n-gram models on the training corpus part. These domainspecific models are also added to the n-best lists. The ME chunking approach does not model explicit syntactic linkages of words. Instead, it incorporates a statistical framework to exploit valid and syntactically coherent groups of words by additionally looking at the word classes. 4 Experiments For the experiments, we use the translation system described in (Zens et al., 2005). Our phrasebased decoder uses several models during search that are interpolated in a log-linear way (as expressed in Eq. 3), such as phrase-based translation models, word-based lexicon models, a language, deletion and simple reordering model and word and phrase penalties. A word graph containing the most likely translation hypotheses is generated during the search process. Out of this compact 44 Supplied Data Track Arabic Chinese Japanese English Train Sentences 20 000 Running Words 180 075 176199 198 453 189 927 Vocabulary 15 371 8 687 9 277 6 870 Singletons 8 319 4 006 4 431 2 888 C-Star’0</context>
<context position="18698" citStr="Zens et al., 2005" startWordPosition="3057" endWordPosition="3060">e-English, n = 1000 produces oracle error rates that are deemed to be sufficiently low, namely 17.7% and 14.8% for WER and PER, respectively. The single-best output for JapaneseEnglish has a word error rate of 33.3% and position-independent word error rate of 25.9%. For the experiments, we add additional features to the initial models of our decoder that have shown to be particularly useful in the past, such as IBM model 1 score, a clustered language model score and a word penalty that prevents the hypotheses to become too short. A detailed definition of these additional features is given in (Zens et al., 2005). Thus, the baseline we start with is 45 Chinese → English, C-Star’03 NIST BLEU[%] mWER[%] mPER[%] Baseline 8.17 46.2 48.6 41.4 with supertagging/LDA 8.29 46.5 48.4 41.0 with link grammar 8.43 45.6 47.9 41.1 with supertagging/LDA + link grammar 8.22 47.5 47.7 40.8 with ME chunker 8.65 47.3 47.4 40.4 with all models 8.42 47.0 47.4 40.5 Chinese → English, IWSLT’04 NIST BLEU[%] mWER[%] mPER[%] Baseline 8.67 45.5 49.1 39.8 with supertagging/LDA 8.68 45.4 49.8 40.3 with link grammar 8.81 45.0 49.0 40.2 with supertagging/LDA+link grammar 8.56 46.0 49.1 40.6 with ME chunker 9.00 44.6 49.3 40.6 with a</context>
</contexts>
<marker>Zens, Bender, Hasan, Khadivi, Matusov, Xu, Zhang, Ney, 2005</marker>
<rawString>Richard Zens, Oliver Bender, Saˇsa Hasan, Shahram Khadivi, Evgeny Matusov, Jia Xu, Yuqi Zhang, and Hermann Ney. 2005. The RWTH phrase-based statistical machine translation system. In Proceedings of the International Workshop on Spoken Language Translation (IWSLT), pages 155–162, Pittsburgh, PA, October.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>