<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000023">
<title confidence="0.902633">
Semi-Automatic Recognition of Noun Modifier Relationships
</title>
<author confidence="0.941512">
Ken BARKER and Stan SZPAKOWICZ
</author>
<affiliation confidence="0.9715995">
School of Information Technology and Engineering
University of Ottawa
</affiliation>
<address confidence="0.791074">
Ottawa, Canada K1N 6N5
</address>
<email confidence="0.973871">
(kbarker, szpak}@site.uottawa.ca
</email>
<sectionHeader confidence="0.993152" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999863060606061">
Semantic relationships among words and
phrases are often marked by explicit syntactic
or lexical clues that help recognize such rela-
tionships in texts. Within complex nominals,
however, few overt clues are available. Sys-
tems that analyze such nominals must com-
pensate for the lack of surface clues with
other information. One way is to load the
system with lexical semantics for nouns or
adjectives. This merely shifts the problem
elsewhere: how do we define the lexical se-
mantics and build large semantic lexicons?
Another way is to find constructions similar
to a given complex nominal, for which the
relationships are already known. This is the
way we chose, but it too has drawbacks.
Similarity is not easily assessed, similar ana-
lyzed constructions may not exist, and if they
do exist, their analysis may not be appropriate
for the current nominal.
We present a semi-automatic system that
identifies semantic relationships in noun
phrases without using precoded noun or ad-
jective semantics. Instead, partial matching on
previously analyzed noun phrases leads to a
tentative interpretation of a new input. Proc-
essing can start without prior analyses, but the
early stage requires user interaction. As more
noun phrases are analyzed, the system learns
to find better interpretations and reduces its
reliance on the user. In experiments on Eng-
lish technical texts the system correctly iden-
tified 60-70% of relationships automatically.
</bodyText>
<sectionHeader confidence="0.999334" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998158">
Any system that extracts knowledge from text
cannot ignore complex noun phrases. In technical
domains especially, noun phrases carry much of
the information. Part of that information is con-
tained in words; cataloguing the semantics of sin-
gle words for computational purposes is a difficult
task that has received much attention. But part of
the information in noun phrases is contained in the
relationships between components.
We have built a system for noun modifier re-
lationship (NMR) analysis that assigns semantic
relationships in complex noun phrases. Syntactic
analysis finds noun phrases in a sentence and pro-
vides a flat list of premodifiers and postmodifying
prepositional phrases and appositives. The NMR
analyzer first brackets the flat list of premodifiers
into modifier-head pairs. Next, it assigns NMRs to
each pair. NMRs are also assigned to the relation-
ships between the noun phrase and each post-
modifying phrase.
</bodyText>
<sectionHeader confidence="0.996875" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.799869">
2.1 Noun Compounds
</subsectionHeader>
<bodyText confidence="0.999861565217391">
A head noun along with a noun premodifier is
often called a noun compound. Syntactically a
noun compound acts as a noun: a modifier or a
head may again be a compound. The NMR ana-
lyzer deals with the semantics of a particular kind
of compound, namely those that are transparent
and endocentric.
The meaning of a transparent compound can
be derived from the meaning of its elements. For
example, laser printer is transparent (a printer
that uses a laser). Guinea pig is opaque: there is
no obvious direct relationship to guinea or to pig.
An endocentric compound is a hyponym of its
head. Desktop computer is endocentric because it
is a kind of computer. Bird brain is exocentric
because it does not refer to a kind of brain, but
rather to a kind of person (whose brain resembles
that of a bird).
Since the NMR analyzer is intended for tech-
nical texts, the restriction to transparent endocen-
tric compounds should not limit the utility of the
system. Our experiments have found no opaque or
exocentric compounds in the test texts.
</bodyText>
<page confidence="0.983734">
96
</page>
<subsectionHeader confidence="0.999617">
2.2 Semantic Relations in Noun Phrases
</subsectionHeader>
<bodyText confidence="0.99990268">
Most of the research on relationships between
nouns and modifiers deals with noun compounds,
but these relationships also hold between nouns
and adjective premodifiers or postmodifying
prepositional phrases. Lists of semantic labels
have been proposed, based on the theory that a
compound expresses one of a small number of
covert semantic relations.
Levi (1978) argues that semantics and word
formation make noun-noun compounds a hetero-
geneous class. She removes opaque compounds
and adds nominal non-predicating adjectives. For
this class Levi offers nine semantic labels. Ac-
cording to her theory, these labels represent un-
derlying predicates deleted during compound
formation. George (1987) disputes the claim that
Levi&apos;s non-predicating adjectives never appear in
predicative position.
Warren (1978) describes a multi-level system
of semantic labels for noun-noun relationships.
Warren (1984) extends the earlier work to cover
adjective premodifiers as well as nouns. The
similarity of the two lists suggests that many ad-
jectives and premodifying nouns can be handled
by the same set of semantic relations.
</bodyText>
<subsectionHeader confidence="0.999875">
2.3 Recognizing Semantic Relations
</subsectionHeader>
<bodyText confidence="0.9999775">
Programs that uncover the relationships in modi-
fier-noun compounds often base their analysis on
the semantics of the individual words (or a com-
position thereof). Such systems assume the exis-
tence of some semantic lexicon.
Leonard&apos;s system (1984) assigns semantic la-
bels to noun-noun compounds based on a diction-
ary that includes taxonomic and meronymic (part-
whole) information, information about the syntac-
tic behaviour of nouns and about the relationships
between nouns and verbs. Finin (1986) produces
multiple semantic interpretations of modifier-noun
compounds. The interpretations are based on pre-
coded semantic class information and domain-
dependent frames describing the roles that can be
associated with certain nouns. Ter Stal&apos;s system
(1996) identifies concepts in text and unifies them
with structures extracted from a hand-coded lexi-
con containing syntactic information, logical form
templates and taxonomic information.
In an attempt to avoid the hand-coding re-
quired in other systems, Vanderwende (1993)
automatically extracts semantic features of nouns
from online dictionaries. Combinations of features
imply particular semantic interpretations of the
relationship between two nouns in a compound.
</bodyText>
<sectionHeader confidence="0.927662" genericHeader="method">
3 Noun Modifier Relationship Labels
</sectionHeader>
<tableCaption confidence="0.51812425">
Table 1 lists the NMRs used by our analyzer. The
list is based on similar lists found in literature on
the semantics of noun compounds. It may evolve
as experimental evidence suggests changes.
</tableCaption>
<table confidence="0.8805623">
Agent (agt) Material (matr)
Beneficiary (bent) Object (obj)
Cause (caus) Possessor (poss)
Container (ctn) Product (prod)
Content (cont) Property (prop)
Destination (dest) Purpose (purp)
Equative (equa) Result (resu)
Instrument (inst) Source (src)
Located (led) Time (time)
Location (lc) Topic (top)
</table>
<tableCaption confidence="0.998386">
Table 1: The noun modifier relationships
</tableCaption>
<bodyText confidence="0.933599769230769">
For each NMR, we give a paraphrase and example
modifier-noun compounds. Following the tradi-
tion in the study of noun compound semantics, the
paraphrases act as definitions and can be used to
check the acceptability of different interpretations
of a compound. The paraphrases serve as defini-
tions in this section and to help with interpretation
during user interactions (as illustrated in section
6). In the analyzer, awkward paraphrases with
adjectives could be improved by replacing adjec-
tives with their WordNet pertainyms (Miller,
1990), giving, for example, &amp;quot;charity benefits from
charitable donation&amp;quot; instead of &amp;quot;charitable bene-
fits from charitable donation&amp;quot;.
Agent: compound is performed by modifier
student protest, band concert, military assault
Beneficiary: modifier benefits from compound
student price, charitable donation
Cause: modifier causes compound
exam anxiety, overdue fine
Container: modifier contains compound
printer tray, flood water, film music, story idea
Content: modifier is contained in compound
paper tray, eviction notice, oil pan
Destination: modifier is destination of compound
game bus, exit route, entrance stairs
</bodyText>
<page confidence="0.990061">
97
</page>
<bodyText confidence="0.843287571428571">
Equative: modifier is also head
composer arranger, player coach
Instrument: modifier is used in compound
electron microscope, diesel engine, laser printer
Located: modifier is located at compound
building site, home town, solar system
Location: modifier is the location of compound
lab printer, internal combustion, desert storm
Material: compound is made of modifier
carbon deposit, gingerbread man, water vapour
Object: modifier is acted on by compound
engine repair, horse doctor
Possessor: modifier has compound
national debt, student loan, company car
</bodyText>
<equation confidence="0.556864571428571">
Product: modifier is a product of compound
automobile factory, light bulb, colour printer
Property: compound is modifier
blue car, big house, fast computer
Purpose: compound is meant for modifier
concert hall, soup pot, grinding abrasive
Result: modifier is a result of compound
</equation>
<bodyText confidence="0.950232714285714">
storm cloud, cold virus, death penalty
Source: modifier is the source of compound
foreign capital, chest pain, north wind
Time: modifier is the time of compound
winter semester, late supper, morning class
Topic: compound is concerned with modifier
computer expert, safety standard, horror novel
</bodyText>
<sectionHeader confidence="0.986188" genericHeader="method">
4 Noun Modifier Bracketing
</sectionHeader>
<bodyText confidence="0.999603">
Before assigning NMRs, the system must bracket
the head noun and the premodifier sequence into
modifier-head pairs. Example (2) shows the
bracketing for noun phrase (1).
</bodyText>
<listItem confidence="0.9969615">
(1) dynamic high impedance microphone
(2) (dynamic ((high impedance) microphone))
</listItem>
<bodyText confidence="0.998931538461538">
The bracketing problem for noun-noun-noun
compounds has been investigated by Liberman &amp;
Sproat (1992), Pustejovsky et al. (1993), Resnik
(1993) and Lauer (1995) among others. Since the
NMR analyzer must handle premodifier se-
quences of any length with both nouns and adjec-
tives, it requires more general techniques. Our
semi-automatic bracketer (Barker, 1998) allows
for any number of adjective or noun premodifiers.
After bracketing, each non-atomic element of
a bracketed pair is considered a subphrase of the
original phrase. The subphrases for the bracketing
in (2) appear in (3), (4) and (5).
</bodyText>
<listItem confidence="0.998577333333333">
(3) high impedance
(4) high_impedance microphone
(5) dynamic high_impedance_microphone
</listItem>
<bodyText confidence="0.9997055">
Each subphrase consists of a modifier (possibly
compound, as in (4)) and a head (possibly com-
pound, as in (5)). The NMR analyzer assigns an
NMR to the modifier-head pair that makes up
each subphrase.
Once an NMR has been assigned, the system
must store the assignment to help automate future
processing. Instead of memorizing complete noun
phrases (or even complete subphrases) and analy-
ses, the system reduces compound modifiers and
compound heads to their own local heads and
stores these reduced pairs with their assigned
NMR. This allows it to analyze different noun
phrases that have only reduced pairs in common
with previous phrases. For example, (6) and (7)
have the reduced pair (8) in common. If (6) has
already been analyzed, its analysis can be used to
assist in the analysis of (7)—see section 5.1.
</bodyText>
<listItem confidence="0.979465">
(6) (dynamic ((high impedance) microphone))
(7) (dynamic (cardioid (vocal microphone)))
(8) (dynamic microphone)
</listItem>
<sectionHeader confidence="0.947081" genericHeader="method">
5 Assigning NMRs
</sectionHeader>
<bodyText confidence="0.996169461538462">
Three kinds of construction require NMR assign-
ments: the modifier-head pairs from the bracketed
premodifier sequence; postmodifying preposi-
tional phrases; appositives.
These three kinds of input can be generalized
to a single form—a triple consisting of modifier,
head and marker (M, H, Mk). For premodifiers,
Mk is the symbol nil, since no lexical item links
the premodifier to the head. For postmodifying
prepositional phrases Mk is the preposition. For
appositives, Mk is the symbol appos. The
(M, H, Mk) triples for examples (9), (10) and (11)
appear in Table 2.
</bodyText>
<listItem confidence="0.996463666666667">
(9) monitor cable plug
(10) large piece of chocolate cake
(11) my brother, a friend to all young people
</listItem>
<bodyText confidence="0.999355833333333">
To assign an NMR to a triple (M, H, Mk), the
system looks for previous triples whose distance
to the current triple is minimal. The NMRs as-
signed to previous similar triples comprise lists of
candidate NMRs. The analyzer then finds what it
considers the best NMR from these lists of candi-
</bodyText>
<page confidence="0.983609">
98
</page>
<tableCaption confidence="0.999567">
Table 2: (M, H, Mk) triples for (9), (10) and (11)
</tableCaption>
<bodyText confidence="0.975888">
dates to present to the user for approval. Apposi-
tives are automatically assigned Equative.
</bodyText>
<subsectionHeader confidence="0.988927">
5.1 Distance Between Triples
</subsectionHeader>
<bodyText confidence="0.999877944444445">
The distance between two triples is a measure of
the degree to which their modifiers, heads and
markers match. Table 3 gives the eight different
values for distance used by NMR analysis.
The analyzer looks for previous triples at the
lower distances before attempting to find triples at
higher distances. For example, it will try to find
identical triples before trying to find triples whose
markers do not match.
Several things about the distance measures
require explanation. First, a preposition is more
similar to a nil marker than to a different preposi-
tion. Unlike a different preposition, the nil marker
is not known to be different from the marker in an
overtly marked pair.
Next, no evidence suggests that triples with
matching M are more similar or less similar than
triples with matching H (distances 3 and 6).
Triples with matching prepositional marker
(distance 4) are considered more similar than tri-
ples with matching M or H only. A preposition is
an overt indicator of the relationship between M
and H (see Quirk, 1985: chapter 9) so a correla-
tion is more likely between the preposition and the
NMR than between a given M or H and the NMR.
If the current triple has a prepositional marker
not seen in any previous triple (distance 5), the
system finds candidate NMRs in its NMR marker
dictionary. This dictionary was constructed from a
list of about 50 common atomic and phrasal
prepositions. The various meanings of each
preposition were mapped to NMRs by hand. Since
the list of prepositions is small, dictionary con-
struction was not a difficult knowledge engineer-
ing task (requiring just twenty hours of work of a
secondary school student).
</bodyText>
<subsectionHeader confidence="0.997598">
5.2 The Best NMRs
</subsectionHeader>
<bodyText confidence="0.998764714285714">
The lists of candidate NMRs consist of all those
NMRs previously assigned to (M, H, Mk) triples
at a minimum distance from the triple under
analysis. If the minimum distance was 3 or 6,
there may be two candidate lists: LM contains the
NMRs previously assigned to triples with match-
ing M, LH—with matching H. The analyzer at-
tempts to choose a set R of candidates to suggest
to the user as the best NMRs for the current triple.
If there is one list L of candidate NMRs, R
contains the NMR (or NMRs) that occur most
frequently in L. For two lists LM and LH, R could
be found in several ways. We could take R to
contain the most frequent NMRs in LMkJ LH. This
absolute frequency approach has a bias towards
NMRs in the larger of the two lists.
Alternatively, the system could prefer NMRs
with the highest relative frequency in their lists. If
there is less variety in the NMRs in Li than in LH,
M might be a more consistent indicator of NMR
than H. Consider example (12).
</bodyText>
<listItem confidence="0.253136">
(12) front line
</listItem>
<bodyText confidence="0.622608">
Compounds with the modifier front may always
have been assigned Location. Compounds with
</bodyText>
<figure confidence="0.957984782608695">
Modifier Head Marker
monitor
monitor_cable
chocolate
large
chocolate_cake
cable nil
plug nil
cake nil
piece nil
large_piece of
young
young_people
friend
people
friend
brother
nil
to
appos
dist current triple revious tri le exam le
0 (M, H, Mk) (M, H, Mk) wall beside a garden wall beside a garden
1 (M, H, &lt;prep&gt;) (M, H, nil) wall beside a garden garden wall
</figure>
<page confidence="0.878368333333333">
2 (M, H, Mk) (M, H, _) wall beside a garden wall around a garden
3 (M, H, Mk) (M, _, Mk) or (_, H, Mk) pile of garbage pile of sweaters
4 (M, H, &lt;prep&gt;) (_, _, &lt;prep&gt;) pile of garbage house of bricks
5 (M, H, &lt;prep&gt;) L, _, J ice in the cup nmrm(in, [ctn,inst,loc,src,time])
6 (M, H, Mk) (M, _, J or (_, H, J wall beside a garden garden fence
7 (M, H, Mk) (_, _, ._) wall beside a garden pile of garbage
</page>
<tableCaption confidence="0.999557">
Table 3: Measures of distance between triples
</tableCaption>
<page confidence="0.998676">
99
</page>
<bodyText confidence="0.999969083333333">
the head line may have been assigned many dif-
ferent NMRs. If line has been seen as a head more
often than front as a modifier, one of the NMRs
assigned to line may have the highest absolute
frequency in Li L.) LH. But if Location has the
highest relative frequency, this method correctly
assigns Location to (12). There is a potential bias,
however, for smaller lists (a single NMR in a list
always has the highest relative frequency).
To avoid these biases, we could combine ab-
solute and relative frequencies. Each NMR i is
assigned a score si calculated as:
</bodyText>
<subsectionHeader confidence="0.455935">
freq(i E Lu)2 freq(i E LH)2
</subsectionHeader>
<bodyText confidence="0.861666">
Si ILMIILHI
R would contain NMR(s) with the highest score.
This combined formula was used in the experi-
ment described in section 7.
</bodyText>
<subsectionHeader confidence="0.998627">
5.3 Premodifiers as Classifiers
</subsectionHeader>
<bodyText confidence="0.97293825">
Since NMR analysis deals with endocentric com-
pounds we can recover a taxonomic relationship
from triples with a nil marker. Consider example
(13) and its reduced pairs in (14):
</bodyText>
<listItem confidence="0.982331333333333">
(13) ((laser printer) stand)
(14) (laser printer)
(printer stand)
</listItem>
<bodyText confidence="0.994243333333333">
These pairs produce the following output:
laser_printer_stand isa stand
laser_printer isa printer
</bodyText>
<sectionHeader confidence="0.994949" genericHeader="method">
6 User Interaction
</sectionHeader>
<bodyText confidence="0.999969352941177">
The NMR analyzer is intended to start processing
from scratch. A session begins with no previous
triples to match against the triple at hand. To
compensate for the lack of previous analyses, the
system relies on the help of a user, who supplies
the correct NMR when the system cannot deter-
mine it automatically.
In order to supply the correct NMR, or even
to determine if the suggested NMR is correct, the
user must be familiar with the NMR definitions.
To minimize the burden of this requirement, all
interactions use the modifier and head of the cur-
rent phrase in the paraphrases from section 3.
Furthermore, if the appropriate NMR is not
among those suggested by the system, the user
can request the complete list of paraphrases with
the current modifier and head.
</bodyText>
<subsectionHeader confidence="0.999759">
6.1 An Example
</subsectionHeader>
<bodyText confidence="0.995174">
Figure 1 shows the interaction for phrases (15)-
(18). The system starts with no previously ana-
lyzed phrases. The NMR marker dictionary maps
the preposition of to twelve NMRs: Agent, Cause,
Content, Equative, Located, Material, Object,
Possessor, Property, Result, Source, Topic.
</bodyText>
<listItem confidence="0.99873025">
(15) small gasoline engine
(16) the repair of diesel engines
(17) diesel engine repair shop
(18) an auto repair center
</listItem>
<bodyText confidence="0.9594815">
User input is shown bold underlined. At any
prompt the user may type &apos;list&apos; to view the com-
plete list of NMR paraphrases for the current
modifier and head.
</bodyText>
<sectionHeader confidence="0.995594" genericHeader="evaluation">
7 Evaluation
</sectionHeader>
<bodyText confidence="0.999994">
We present the results of evaluating the NMR
analyzer in the context of a large knowledge ac-
quisition experiment (see Barker et al., 1998). The
NMR analyzer is one part of a larger interactive
semantic analysis system. The experiment evalu-
ated the semantic analysis of Atkinson (1990). We
refer to it as the small engines experiment. Other
experiments have shown similar results.
We consider three evaluation criteria. First,
we evaluate the analyzer&apos;s ability to learn to make
better suggestions to the user as more noun
phrases are analyzed. Second, we evaluate its
coverage by comparing the number of relation-
ships assigned with the total number of such rela-
tionships in the text (i.e., the number it should
have assigned). Third, we assess the burden that
semi-automatic analysis places on the user.
</bodyText>
<subsectionHeader confidence="0.999663">
7.1 Improvement in System Performance
</subsectionHeader>
<bodyText confidence="0.999813846153846">
Since the system starts with no previous noun
phrase analyses, the user is responsible for sup-
plying NMRs at the beginning of a session. To
measure the rate of learning, we compare the cu-
mulative number of assignments required from the
user to the cumulative number of correct assign-
ments suggested by the system.
In the small engines experiment, 886 modi-
fier-noun pairs were assigned an NMR. We con-
sider the system&apos;s assignment correct when the
correct label is among its suggestions. According
to this definition, 608 of the 886 NMRs (69%)
were assigned correctly by the system. For most
</bodyText>
<page confidence="0.982105">
100
</page>
<bodyText confidence="0.86889988">
of these assignments (97.5%) the system offered a
single suggestion. It had multiple (on average 3.3)
suggestions only 22 times.
Phrase (15): small gasoline engine
There is a relationship between
gasoline and gasoline engine.
Please enter a valid NMR label: inst
Do you accept the NMR Instrument:
gasoline is used in gasoline_engine Y
There is a relationship between
small and small gasoline_engine.
Please enter a valid NMR label: prop
Do you accept the NMR Property:
small gasoline engine is small Y
Phrase (16): the repair of diesel engines
There is a relationship between
diesel and diesel engine.
NMR Analyzer&apos;s best suggestions for this input:
(1) prop: diesel engine is diesel
(2) inst: diesel is used in diesel engine
Please enter a number between 1 and 2: 2
Do you accept the NMR Instrument:
diesel is used in diesel engine Y
There is a relationship between
diesel engine and repair.
</bodyText>
<listItem confidence="0.639436714285714">
NMR Analyzers best suggestions for this input:
(1) agt: repair is performed by diesel engine
(2) caus: diesel engine causes repair
...
(7) obj: diesel engine is acted on by repair
...
(12) top: repair is concerned with diesel engine
</listItem>
<bodyText confidence="0.668508052631579">
Please enter a number between 1 and 12: 7
Do you accept the NMR Object:
diesel engine is acted on by repair Y
Phrase (17): diesel engine repair shop
Do you accept the NMR Instrument:
diesel is used in diesel engine Y
Do you accept the NMR Object:
diesel engine is acted on by diesel engine_repair Y
There is a relationship between
diesel engine_repair and diesel engine_repair shop.
Please enter a valid NMR label: pm
Do you accept the NMR Purpose:
diesel engine_repair shop is meant for
diesel engine_repair Y
Phrase (18): an auto repair center
Do you accept the NMR Object:
auto is acted on by auto_repair Y
Do you accept the NMR Purpose:
auto repair centeris meant for auto_repair Y
</bodyText>
<figureCaption confidence="0.998419">
Figure 1: NMR analysis interaction for (15)-(18)
</figureCaption>
<bodyText confidence="0.99636075">
Figure 2 shows the cumulative number of
NMR assignments supplied by the user versus
those determined correctly by the system. After
about 100 assignments, the system was able to
make the majority of assignments automatically.
The curves in the figure show that the system
learns to make better suggestions as more phrases
are analyzed.
</bodyText>
<figure confidence="0.992565533333333">
700
600 —
500
xi)
(i)
400
300
o
200
100 —
o
0
0 0 0 0 0 0 0 0
•-• CV CO ct V) CD N. OD
number of modifier-noun pairs
</figure>
<figureCaption confidence="0.998303">
Figure 2: Cumulative NMR assignments
</figureCaption>
<subsectionHeader confidence="0.972474">
7.2 NMR Coverage
</subsectionHeader>
<bodyText confidence="0.999963416666667">
The NMR analyzer depends on a parser to find
noun phrases in a text. If parsing is not 100% suc-
cessful, the analyzer will not see all noun phrases
in the input text. It is not feasible to find manually
the total number of relationships in a text—even
in one of only a few hundred sentences. To meas-
ure coverage, we sampled 100 modifier-noun
pairs at random from the small engines text and
found that 87 of them appeared in the analyzer&apos;s
output. At 95% confidence, we can say that the
system extracted between 79.0% and 92.2% of the
modifier-noun relationships in the text.
</bodyText>
<subsectionHeader confidence="0.989076">
7.3 User Burden
</subsectionHeader>
<bodyText confidence="0.999972888888889">
User burden is a fairly subjective criterion. To
measure burden, we assigned an &amp;quot;onus&amp;quot; rating to
each interaction during the small engines experi-
ment. The onus is a number from 0 to 3. 0 means
that the correct NMR was obvious, whether sug-
gested by the system or supplied by the user. 1
means that selecting an NMR required a few mo-
ments of reflection. A rating of 2 means that the
interaction required serious thought, but we were
</bodyText>
<figure confidence="0.6880055">
system
user
</figure>
<page confidence="0.98824">
101
</page>
<bodyText confidence="0.999929">
ultimately able to choose an NMR. 3 means that
even after much contemplation, we were unable to
agree on an NMR.
The average user onus rating was 0.1 for
NMR interactions in the small engines experi-
ment. 808 of the 886 NMR assignments received
an onus rating of 0; 71 had a rating of 1; 7 re-
ceived a rating of 2. No interactions were rated
onus level 3.
</bodyText>
<sectionHeader confidence="0.999291" genericHeader="discussions">
8 Future Work
</sectionHeader>
<bodyText confidence="0.9999879">
Although the list of NMRs was inspired by the
relationships found commonly in others&apos; lists, it
has not undergone a more rigorous validation
(such as one described in Barker et al., 1997).
In section 5.2 we discussed different ap-
proaches to choosing NMRs from two lists of
candidates. We have implemented and compared
five different techniques for choosing the best
NMRs, but experimental results are inconclusive
as to which techniques are better. We should seek
a more theoretically sound approach followed by
further experimentation.
The NMR analyzer currently allows its stored
triples (and associated NMRs) to be saved in a file
at the end of a session. Any number of such files
can be reloaded at the beginning of subsequent
sessions, &amp;quot;seeding&amp;quot; the new sessions. It is neces-
sary to establish the extent to which the triples and
assignments from one text or domain are useful in
the analysis of noun phrases from another domain.
</bodyText>
<sectionHeader confidence="0.996558" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.995259">
This work is supported by the Natural Sciences
and Engineering Research Council of Canada.
</bodyText>
<sectionHeader confidence="0.999253" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999955532258064">
Atkinson, Henry F. (1990). Mechanics of Small En-
gines. New York: Gregg Division, McGraw-Hill.
Barker, Ken (1998). &amp;quot;A Trainable Bracketer for Noun
Modifiers&amp;quot;. The Twelfth Canadian Conference on
Artificial Intelligence.
Barker, Ken, Terry Copeck, Sylvain Delisle &amp; Stan
Szpakowicz (1997). &amp;quot;Systematic Construction of a
Versatile Case System.&amp;quot; Journal of Natural Lan-
guage Engineering 3(4), December 1997.
Barker, Ken, Sylvain Delisle &amp; Stan Szpakowicz
(1998). &amp;quot;Test-Driving TANKA: Evaluating a Semi-
Automatic System of Text Analysis for Knowledge
Acquisition.&amp;quot; The Twelfth Canadian Conference on
Artificial Intelligence.
Finin, Timothy W. (1986). &amp;quot;Constraining the Interpre-
tation of Nominal Compounds in a Limited Con-
text.&amp;quot; In Analyzing Language in Restricted Domains:
Sublanguage Description and Processing, R. Grish-
man &amp; R. Kittredge, eds., Lawrence Erlbaum,
Hillsdale, pp. 163-173.
George, Steffi (1987). On &amp;quot;Nominal Non-Predicating&amp;quot;
Adjectives in English. Frankfurt am Main: Peter
Lang.
Lauer, Mark (1995). &amp;quot;Corpus Statistics Meet the Noun
Compound: Some Empirical Results.&amp;quot; Proceedings
of the 33rd Annual Meeting of the Association for
Computational Linguistics. Cambridge. 47-54.
Leonard, Rosemary (1984). The Interpretation of Eng-
lish Noun Sequences on the Computer. Amsterdam:
North-Holland.
Levi, Judith N. (1978). The Syntax and Semantics of
Complex Nominals. New York: Academic Press.
Liberman, Mark &amp; Richard Sproat (1992). &amp;quot;Stress and
Structure of Modified Noun Phrases.&amp;quot; Lexical Mat-
ters (CSLI Lecture Notes, 24). Stanford: Center for
the Study of Language and Information.
Miller, George A., ed. (1990). &amp;quot;WordNet: An On-Line
Lexical Database.&amp;quot; International Journal of Lexicog-
raphy 3(4).
Pustejovsky, James, S. Bergler &amp; P. Anick (1993).
&amp;quot;Lexical Semantic Techniques for Corpus Analysis.&amp;quot;
Computational Linguistics 19(2). 331-358.
Quirk, Randolph, Sidney Greenbaum, Geoffrey Leech
&amp; Jan Svartvik (1985). A Comprehensive Grammar
of the English Language. London: Longman.
Resnik, Philip Stuart (1993). &amp;quot;Selection and Informa-
tion: A Class-Based Approach to Lexical Relation-
ships.&amp;quot; Ph.D. thesis, IRCS Report 93-42, University
of Pennsylvania.
ter Stal, Wilco (1996). &amp;quot;Automated Interpretation of
Nominal Compounds in a Technical Domain.&amp;quot; Ph.D.
thesis, University of Twente, The Netherlands.
Vanderwende, Lucy (1993). &amp;quot;SENS: The System for
Evaluating Noun Sequences.&amp;quot; In Natural Language
Processing: The PLNLP Approach, K. Jensen, G.
Heidorn &amp; S. Richardson, eds., Kluwer Academic
Publishers, Boston, pp. 161-173.
Warren, Beatrice (1978). Semantic Patterns of Noun-
Noun Compounds. Goteborg: Acta Universitatis
Gothoburgensis.
Warren, Beatrice (1984). Classing Adjectives. Gote-
borg: Acta Universitatis Gothoburgensis.
</reference>
<page confidence="0.998625">
102
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.727177">
<title confidence="0.999958">Semi-Automatic Recognition of Noun Modifier Relationships</title>
<author confidence="0.99995">Ken BARKER</author>
<author confidence="0.99995">Stan SZPAKOWICZ</author>
<affiliation confidence="0.9995385">School of Information Technology and Engineering University of Ottawa</affiliation>
<address confidence="0.978876">Ottawa, Canada K1N 6N5</address>
<email confidence="0.993712">(kbarker,szpak}@site.uottawa.ca</email>
<abstract confidence="0.991854735294117">Semantic relationships among words and phrases are often marked by explicit syntactic or lexical clues that help recognize such relationships in texts. Within complex nominals, however, few overt clues are available. Systems that analyze such nominals must compensate for the lack of surface clues with other information. One way is to load the system with lexical semantics for nouns or adjectives. This merely shifts the problem elsewhere: how do we define the lexical semantics and build large semantic lexicons? way is to find constructions complex nominal, for which the relationships are already known. This is the way we chose, but it too has drawbacks. Similarity is not easily assessed, similar analyzed constructions may not exist, and if they do exist, their analysis may not be appropriate for the current nominal. We present a semi-automatic system that identifies semantic relationships in noun phrases without using precoded noun or adjective semantics. Instead, partial matching on previously analyzed noun phrases leads to a tentative interpretation of a new input. Processing can start without prior analyses, but the early stage requires user interaction. As more noun phrases are analyzed, the system learns to find better interpretations and reduces its reliance on the user. In experiments on English technical texts the system correctly identified 60-70% of relationships automatically.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Henry F Atkinson</author>
</authors>
<title>Mechanics of Small Engines.</title>
<date>1990</date>
<location>New York: Gregg Division, McGraw-Hill.</location>
<contexts>
<context position="18267" citStr="Atkinson (1990)" startWordPosition="2938" endWordPosition="2939">ossessor, Property, Result, Source, Topic. (15) small gasoline engine (16) the repair of diesel engines (17) diesel engine repair shop (18) an auto repair center User input is shown bold underlined. At any prompt the user may type &apos;list&apos; to view the complete list of NMR paraphrases for the current modifier and head. 7 Evaluation We present the results of evaluating the NMR analyzer in the context of a large knowledge acquisition experiment (see Barker et al., 1998). The NMR analyzer is one part of a larger interactive semantic analysis system. The experiment evaluated the semantic analysis of Atkinson (1990). We refer to it as the small engines experiment. Other experiments have shown similar results. We consider three evaluation criteria. First, we evaluate the analyzer&apos;s ability to learn to make better suggestions to the user as more noun phrases are analyzed. Second, we evaluate its coverage by comparing the number of relationships assigned with the total number of such relationships in the text (i.e., the number it should have assigned). Third, we assess the burden that semi-automatic analysis places on the user. 7.1 Improvement in System Performance Since the system starts with no previous n</context>
</contexts>
<marker>Atkinson, 1990</marker>
<rawString>Atkinson, Henry F. (1990). Mechanics of Small Engines. New York: Gregg Division, McGraw-Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken Barker</author>
</authors>
<title>A Trainable Bracketer for Noun Modifiers&amp;quot;.</title>
<date>1998</date>
<booktitle>The Twelfth Canadian Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="9555" citStr="Barker, 1998" startWordPosition="1440" endWordPosition="1441">ng Before assigning NMRs, the system must bracket the head noun and the premodifier sequence into modifier-head pairs. Example (2) shows the bracketing for noun phrase (1). (1) dynamic high impedance microphone (2) (dynamic ((high impedance) microphone)) The bracketing problem for noun-noun-noun compounds has been investigated by Liberman &amp; Sproat (1992), Pustejovsky et al. (1993), Resnik (1993) and Lauer (1995) among others. Since the NMR analyzer must handle premodifier sequences of any length with both nouns and adjectives, it requires more general techniques. Our semi-automatic bracketer (Barker, 1998) allows for any number of adjective or noun premodifiers. After bracketing, each non-atomic element of a bracketed pair is considered a subphrase of the original phrase. The subphrases for the bracketing in (2) appear in (3), (4) and (5). (3) high impedance (4) high_impedance microphone (5) dynamic high_impedance_microphone Each subphrase consists of a modifier (possibly compound, as in (4)) and a head (possibly compound, as in (5)). The NMR analyzer assigns an NMR to the modifier-head pair that makes up each subphrase. Once an NMR has been assigned, the system must store the assignment to hel</context>
</contexts>
<marker>Barker, 1998</marker>
<rawString>Barker, Ken (1998). &amp;quot;A Trainable Bracketer for Noun Modifiers&amp;quot;. The Twelfth Canadian Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken Barker</author>
</authors>
<title>Terry Copeck, Sylvain Delisle &amp; Stan Szpakowicz</title>
<date>1997</date>
<journal>Journal of Natural Language Engineering</journal>
<volume>3</volume>
<issue>4</issue>
<marker>Barker, 1997</marker>
<rawString>Barker, Ken, Terry Copeck, Sylvain Delisle &amp; Stan Szpakowicz (1997). &amp;quot;Systematic Construction of a Versatile Case System.&amp;quot; Journal of Natural Language Engineering 3(4), December 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ken Barker</author>
</authors>
<title>Sylvain Delisle &amp; Stan Szpakowicz</title>
<date>1998</date>
<booktitle>The Twelfth Canadian Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="9555" citStr="Barker, 1998" startWordPosition="1440" endWordPosition="1441">ng Before assigning NMRs, the system must bracket the head noun and the premodifier sequence into modifier-head pairs. Example (2) shows the bracketing for noun phrase (1). (1) dynamic high impedance microphone (2) (dynamic ((high impedance) microphone)) The bracketing problem for noun-noun-noun compounds has been investigated by Liberman &amp; Sproat (1992), Pustejovsky et al. (1993), Resnik (1993) and Lauer (1995) among others. Since the NMR analyzer must handle premodifier sequences of any length with both nouns and adjectives, it requires more general techniques. Our semi-automatic bracketer (Barker, 1998) allows for any number of adjective or noun premodifiers. After bracketing, each non-atomic element of a bracketed pair is considered a subphrase of the original phrase. The subphrases for the bracketing in (2) appear in (3), (4) and (5). (3) high impedance (4) high_impedance microphone (5) dynamic high_impedance_microphone Each subphrase consists of a modifier (possibly compound, as in (4)) and a head (possibly compound, as in (5)). The NMR analyzer assigns an NMR to the modifier-head pair that makes up each subphrase. Once an NMR has been assigned, the system must store the assignment to hel</context>
</contexts>
<marker>Barker, 1998</marker>
<rawString>Barker, Ken, Sylvain Delisle &amp; Stan Szpakowicz (1998). &amp;quot;Test-Driving TANKA: Evaluating a SemiAutomatic System of Text Analysis for Knowledge Acquisition.&amp;quot; The Twelfth Canadian Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy W Finin</author>
</authors>
<title>Constraining the Interpretation of Nominal Compounds in a Limited Context.&amp;quot; In</title>
<date>1986</date>
<booktitle>Analyzing Language in Restricted Domains: Sublanguage Description and Processing,</booktitle>
<pages>163--173</pages>
<editor>R. Grishman &amp; R. Kittredge, eds., Lawrence Erlbaum,</editor>
<location>Hillsdale,</location>
<contexts>
<context position="5348" citStr="Finin (1986)" startWordPosition="835" endWordPosition="836">tives and premodifying nouns can be handled by the same set of semantic relations. 2.3 Recognizing Semantic Relations Programs that uncover the relationships in modifier-noun compounds often base their analysis on the semantics of the individual words (or a composition thereof). Such systems assume the existence of some semantic lexicon. Leonard&apos;s system (1984) assigns semantic labels to noun-noun compounds based on a dictionary that includes taxonomic and meronymic (partwhole) information, information about the syntactic behaviour of nouns and about the relationships between nouns and verbs. Finin (1986) produces multiple semantic interpretations of modifier-noun compounds. The interpretations are based on precoded semantic class information and domaindependent frames describing the roles that can be associated with certain nouns. Ter Stal&apos;s system (1996) identifies concepts in text and unifies them with structures extracted from a hand-coded lexicon containing syntactic information, logical form templates and taxonomic information. In an attempt to avoid the hand-coding required in other systems, Vanderwende (1993) automatically extracts semantic features of nouns from online dictionaries. C</context>
</contexts>
<marker>Finin, 1986</marker>
<rawString>Finin, Timothy W. (1986). &amp;quot;Constraining the Interpretation of Nominal Compounds in a Limited Context.&amp;quot; In Analyzing Language in Restricted Domains: Sublanguage Description and Processing, R. Grishman &amp; R. Kittredge, eds., Lawrence Erlbaum, Hillsdale, pp. 163-173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steffi George</author>
</authors>
<title>On &amp;quot;Nominal Non-Predicating&amp;quot; Adjectives in English. Frankfurt am Main: Peter Lang.</title>
<date>1987</date>
<contexts>
<context position="4401" citStr="George (1987)" startWordPosition="693" endWordPosition="694">n compounds, but these relationships also hold between nouns and adjective premodifiers or postmodifying prepositional phrases. Lists of semantic labels have been proposed, based on the theory that a compound expresses one of a small number of covert semantic relations. Levi (1978) argues that semantics and word formation make noun-noun compounds a heterogeneous class. She removes opaque compounds and adds nominal non-predicating adjectives. For this class Levi offers nine semantic labels. According to her theory, these labels represent underlying predicates deleted during compound formation. George (1987) disputes the claim that Levi&apos;s non-predicating adjectives never appear in predicative position. Warren (1978) describes a multi-level system of semantic labels for noun-noun relationships. Warren (1984) extends the earlier work to cover adjective premodifiers as well as nouns. The similarity of the two lists suggests that many adjectives and premodifying nouns can be handled by the same set of semantic relations. 2.3 Recognizing Semantic Relations Programs that uncover the relationships in modifier-noun compounds often base their analysis on the semantics of the individual words (or a composi</context>
</contexts>
<marker>George, 1987</marker>
<rawString>George, Steffi (1987). On &amp;quot;Nominal Non-Predicating&amp;quot; Adjectives in English. Frankfurt am Main: Peter Lang.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Lauer</author>
</authors>
<title>Corpus Statistics Meet the Noun Compound: Some Empirical Results.&amp;quot;</title>
<date>1995</date>
<booktitle>Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics. Cambridge.</booktitle>
<pages>47--54</pages>
<contexts>
<context position="9357" citStr="Lauer (1995)" startWordPosition="1410" endWordPosition="1411">Time: modifier is the time of compound winter semester, late supper, morning class Topic: compound is concerned with modifier computer expert, safety standard, horror novel 4 Noun Modifier Bracketing Before assigning NMRs, the system must bracket the head noun and the premodifier sequence into modifier-head pairs. Example (2) shows the bracketing for noun phrase (1). (1) dynamic high impedance microphone (2) (dynamic ((high impedance) microphone)) The bracketing problem for noun-noun-noun compounds has been investigated by Liberman &amp; Sproat (1992), Pustejovsky et al. (1993), Resnik (1993) and Lauer (1995) among others. Since the NMR analyzer must handle premodifier sequences of any length with both nouns and adjectives, it requires more general techniques. Our semi-automatic bracketer (Barker, 1998) allows for any number of adjective or noun premodifiers. After bracketing, each non-atomic element of a bracketed pair is considered a subphrase of the original phrase. The subphrases for the bracketing in (2) appear in (3), (4) and (5). (3) high impedance (4) high_impedance microphone (5) dynamic high_impedance_microphone Each subphrase consists of a modifier (possibly compound, as in (4)) and a h</context>
</contexts>
<marker>Lauer, 1995</marker>
<rawString>Lauer, Mark (1995). &amp;quot;Corpus Statistics Meet the Noun Compound: Some Empirical Results.&amp;quot; Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics. Cambridge. 47-54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rosemary Leonard</author>
</authors>
<title>The Interpretation of English Noun Sequences on the Computer.</title>
<date>1984</date>
<publisher>North-Holland.</publisher>
<location>Amsterdam:</location>
<marker>Leonard, 1984</marker>
<rawString>Leonard, Rosemary (1984). The Interpretation of English Noun Sequences on the Computer. Amsterdam: North-Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith N Levi</author>
</authors>
<title>The Syntax and Semantics of Complex Nominals.</title>
<date>1978</date>
<publisher>Academic Press.</publisher>
<location>New York:</location>
<contexts>
<context position="4070" citStr="Levi (1978)" startWordPosition="646" endWordPosition="647">intended for technical texts, the restriction to transparent endocentric compounds should not limit the utility of the system. Our experiments have found no opaque or exocentric compounds in the test texts. 96 2.2 Semantic Relations in Noun Phrases Most of the research on relationships between nouns and modifiers deals with noun compounds, but these relationships also hold between nouns and adjective premodifiers or postmodifying prepositional phrases. Lists of semantic labels have been proposed, based on the theory that a compound expresses one of a small number of covert semantic relations. Levi (1978) argues that semantics and word formation make noun-noun compounds a heterogeneous class. She removes opaque compounds and adds nominal non-predicating adjectives. For this class Levi offers nine semantic labels. According to her theory, these labels represent underlying predicates deleted during compound formation. George (1987) disputes the claim that Levi&apos;s non-predicating adjectives never appear in predicative position. Warren (1978) describes a multi-level system of semantic labels for noun-noun relationships. Warren (1984) extends the earlier work to cover adjective premodifiers as well </context>
</contexts>
<marker>Levi, 1978</marker>
<rawString>Levi, Judith N. (1978). The Syntax and Semantics of Complex Nominals. New York: Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Liberman</author>
<author>Richard Sproat</author>
</authors>
<title>Stress and Structure of Modified Noun Phrases.&amp;quot;</title>
<date>1992</date>
<journal>Lexical Matters (CSLI Lecture Notes,</journal>
<volume>24</volume>
<contexts>
<context position="9298" citStr="Liberman &amp; Sproat (1992)" startWordPosition="1399" endWordPosition="1402">fier is the source of compound foreign capital, chest pain, north wind Time: modifier is the time of compound winter semester, late supper, morning class Topic: compound is concerned with modifier computer expert, safety standard, horror novel 4 Noun Modifier Bracketing Before assigning NMRs, the system must bracket the head noun and the premodifier sequence into modifier-head pairs. Example (2) shows the bracketing for noun phrase (1). (1) dynamic high impedance microphone (2) (dynamic ((high impedance) microphone)) The bracketing problem for noun-noun-noun compounds has been investigated by Liberman &amp; Sproat (1992), Pustejovsky et al. (1993), Resnik (1993) and Lauer (1995) among others. Since the NMR analyzer must handle premodifier sequences of any length with both nouns and adjectives, it requires more general techniques. Our semi-automatic bracketer (Barker, 1998) allows for any number of adjective or noun premodifiers. After bracketing, each non-atomic element of a bracketed pair is considered a subphrase of the original phrase. The subphrases for the bracketing in (2) appear in (3), (4) and (5). (3) high impedance (4) high_impedance microphone (5) dynamic high_impedance_microphone Each subphrase co</context>
</contexts>
<marker>Liberman, Sproat, 1992</marker>
<rawString>Liberman, Mark &amp; Richard Sproat (1992). &amp;quot;Stress and Structure of Modified Noun Phrases.&amp;quot; Lexical Matters (CSLI Lecture Notes, 24). Stanford: Center for the Study of Language and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>ed</author>
</authors>
<title>WordNet: An On-Line Lexical Database.&amp;quot;</title>
<date>1990</date>
<journal>International Journal of Lexicography</journal>
<volume>3</volume>
<issue>4</issue>
<marker>Miller, ed, 1990</marker>
<rawString>Miller, George A., ed. (1990). &amp;quot;WordNet: An On-Line Lexical Database.&amp;quot; International Journal of Lexicography 3(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>S Bergler</author>
<author>P Anick</author>
</authors>
<title>Lexical Semantic Techniques for Corpus Analysis.&amp;quot;</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<issue>2</issue>
<pages>331--358</pages>
<contexts>
<context position="9325" citStr="Pustejovsky et al. (1993)" startWordPosition="1403" endWordPosition="1406">ound foreign capital, chest pain, north wind Time: modifier is the time of compound winter semester, late supper, morning class Topic: compound is concerned with modifier computer expert, safety standard, horror novel 4 Noun Modifier Bracketing Before assigning NMRs, the system must bracket the head noun and the premodifier sequence into modifier-head pairs. Example (2) shows the bracketing for noun phrase (1). (1) dynamic high impedance microphone (2) (dynamic ((high impedance) microphone)) The bracketing problem for noun-noun-noun compounds has been investigated by Liberman &amp; Sproat (1992), Pustejovsky et al. (1993), Resnik (1993) and Lauer (1995) among others. Since the NMR analyzer must handle premodifier sequences of any length with both nouns and adjectives, it requires more general techniques. Our semi-automatic bracketer (Barker, 1998) allows for any number of adjective or noun premodifiers. After bracketing, each non-atomic element of a bracketed pair is considered a subphrase of the original phrase. The subphrases for the bracketing in (2) appear in (3), (4) and (5). (3) high impedance (4) high_impedance microphone (5) dynamic high_impedance_microphone Each subphrase consists of a modifier (possi</context>
</contexts>
<marker>Pustejovsky, Bergler, Anick, 1993</marker>
<rawString>Pustejovsky, James, S. Bergler &amp; P. Anick (1993). &amp;quot;Lexical Semantic Techniques for Corpus Analysis.&amp;quot; Computational Linguistics 19(2). 331-358.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Randolph Quirk</author>
<author>Sidney Greenbaum</author>
<author>Geoffrey Leech</author>
<author>Jan Svartvik</author>
</authors>
<title>A Comprehensive Grammar of the English Language.</title>
<date>1985</date>
<publisher>Longman.</publisher>
<location>London:</location>
<marker>Quirk, Greenbaum, Leech, Svartvik, 1985</marker>
<rawString>Quirk, Randolph, Sidney Greenbaum, Geoffrey Leech &amp; Jan Svartvik (1985). A Comprehensive Grammar of the English Language. London: Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Stuart Resnik</author>
</authors>
<title>Selection and Information: A Class-Based Approach to Lexical Relationships.&amp;quot;</title>
<date>1993</date>
<tech>Ph.D. thesis, IRCS Report 93-42,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="9340" citStr="Resnik (1993)" startWordPosition="1407" endWordPosition="1408"> pain, north wind Time: modifier is the time of compound winter semester, late supper, morning class Topic: compound is concerned with modifier computer expert, safety standard, horror novel 4 Noun Modifier Bracketing Before assigning NMRs, the system must bracket the head noun and the premodifier sequence into modifier-head pairs. Example (2) shows the bracketing for noun phrase (1). (1) dynamic high impedance microphone (2) (dynamic ((high impedance) microphone)) The bracketing problem for noun-noun-noun compounds has been investigated by Liberman &amp; Sproat (1992), Pustejovsky et al. (1993), Resnik (1993) and Lauer (1995) among others. Since the NMR analyzer must handle premodifier sequences of any length with both nouns and adjectives, it requires more general techniques. Our semi-automatic bracketer (Barker, 1998) allows for any number of adjective or noun premodifiers. After bracketing, each non-atomic element of a bracketed pair is considered a subphrase of the original phrase. The subphrases for the bracketing in (2) appear in (3), (4) and (5). (3) high impedance (4) high_impedance microphone (5) dynamic high_impedance_microphone Each subphrase consists of a modifier (possibly compound, a</context>
</contexts>
<marker>Resnik, 1993</marker>
<rawString>Resnik, Philip Stuart (1993). &amp;quot;Selection and Information: A Class-Based Approach to Lexical Relationships.&amp;quot; Ph.D. thesis, IRCS Report 93-42, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ter Stal</author>
</authors>
<title>Automated Interpretation of Nominal Compounds in a Technical Domain.&amp;quot;</title>
<date>1996</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Twente, The Netherlands.</institution>
<marker>Stal, 1996</marker>
<rawString>ter Stal, Wilco (1996). &amp;quot;Automated Interpretation of Nominal Compounds in a Technical Domain.&amp;quot; Ph.D. thesis, University of Twente, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucy Vanderwende</author>
</authors>
<title>SENS: The System for Evaluating Noun Sequences.&amp;quot;</title>
<date>1993</date>
<booktitle>In Natural Language Processing: The PLNLP Approach,</booktitle>
<pages>161--173</pages>
<editor>K. Jensen, G. Heidorn &amp; S. Richardson, eds.,</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Boston,</location>
<contexts>
<context position="5870" citStr="Vanderwende (1993)" startWordPosition="908" endWordPosition="909">e syntactic behaviour of nouns and about the relationships between nouns and verbs. Finin (1986) produces multiple semantic interpretations of modifier-noun compounds. The interpretations are based on precoded semantic class information and domaindependent frames describing the roles that can be associated with certain nouns. Ter Stal&apos;s system (1996) identifies concepts in text and unifies them with structures extracted from a hand-coded lexicon containing syntactic information, logical form templates and taxonomic information. In an attempt to avoid the hand-coding required in other systems, Vanderwende (1993) automatically extracts semantic features of nouns from online dictionaries. Combinations of features imply particular semantic interpretations of the relationship between two nouns in a compound. 3 Noun Modifier Relationship Labels Table 1 lists the NMRs used by our analyzer. The list is based on similar lists found in literature on the semantics of noun compounds. It may evolve as experimental evidence suggests changes. Agent (agt) Material (matr) Beneficiary (bent) Object (obj) Cause (caus) Possessor (poss) Container (ctn) Product (prod) Content (cont) Property (prop) Destination (dest) Pur</context>
</contexts>
<marker>Vanderwende, 1993</marker>
<rawString>Vanderwende, Lucy (1993). &amp;quot;SENS: The System for Evaluating Noun Sequences.&amp;quot; In Natural Language Processing: The PLNLP Approach, K. Jensen, G. Heidorn &amp; S. Richardson, eds., Kluwer Academic Publishers, Boston, pp. 161-173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beatrice Warren</author>
</authors>
<title>Semantic Patterns of NounNoun Compounds. Goteborg: Acta Universitatis Gothoburgensis.</title>
<date>1978</date>
<contexts>
<context position="4511" citStr="Warren (1978)" startWordPosition="707" endWordPosition="708">sitional phrases. Lists of semantic labels have been proposed, based on the theory that a compound expresses one of a small number of covert semantic relations. Levi (1978) argues that semantics and word formation make noun-noun compounds a heterogeneous class. She removes opaque compounds and adds nominal non-predicating adjectives. For this class Levi offers nine semantic labels. According to her theory, these labels represent underlying predicates deleted during compound formation. George (1987) disputes the claim that Levi&apos;s non-predicating adjectives never appear in predicative position. Warren (1978) describes a multi-level system of semantic labels for noun-noun relationships. Warren (1984) extends the earlier work to cover adjective premodifiers as well as nouns. The similarity of the two lists suggests that many adjectives and premodifying nouns can be handled by the same set of semantic relations. 2.3 Recognizing Semantic Relations Programs that uncover the relationships in modifier-noun compounds often base their analysis on the semantics of the individual words (or a composition thereof). Such systems assume the existence of some semantic lexicon. Leonard&apos;s system (1984) assigns sem</context>
</contexts>
<marker>Warren, 1978</marker>
<rawString>Warren, Beatrice (1978). Semantic Patterns of NounNoun Compounds. Goteborg: Acta Universitatis Gothoburgensis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beatrice Warren</author>
</authors>
<title>Classing Adjectives. Goteborg: Acta Universitatis Gothoburgensis.</title>
<date>1984</date>
<contexts>
<context position="4604" citStr="Warren (1984)" startWordPosition="719" endWordPosition="720">pound expresses one of a small number of covert semantic relations. Levi (1978) argues that semantics and word formation make noun-noun compounds a heterogeneous class. She removes opaque compounds and adds nominal non-predicating adjectives. For this class Levi offers nine semantic labels. According to her theory, these labels represent underlying predicates deleted during compound formation. George (1987) disputes the claim that Levi&apos;s non-predicating adjectives never appear in predicative position. Warren (1978) describes a multi-level system of semantic labels for noun-noun relationships. Warren (1984) extends the earlier work to cover adjective premodifiers as well as nouns. The similarity of the two lists suggests that many adjectives and premodifying nouns can be handled by the same set of semantic relations. 2.3 Recognizing Semantic Relations Programs that uncover the relationships in modifier-noun compounds often base their analysis on the semantics of the individual words (or a composition thereof). Such systems assume the existence of some semantic lexicon. Leonard&apos;s system (1984) assigns semantic labels to noun-noun compounds based on a dictionary that includes taxonomic and meronym</context>
</contexts>
<marker>Warren, 1984</marker>
<rawString>Warren, Beatrice (1984). Classing Adjectives. Goteborg: Acta Universitatis Gothoburgensis.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>