<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004201">
<title confidence="0.994756">
Construction of a Chinese Idiom Knowledge Base and Its Applications
</title>
<author confidence="0.998302">
Lei Wang
</author>
<affiliation confidence="0.998044666666667">
Key Laboratory of Computational
Linguistics of Ministry of Education
Department of English, Peking University
</affiliation>
<email confidence="0.996323">
wangleics@pku.edu.cn
</email>
<sectionHeader confidence="0.993851" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9994229">
Idioms are not only interesting but also
distinctive in a language for its continuity
and metaphorical meaning in its context.
This paper introduces the construction of
a Chinese idiom knowledge base by the
Institute of Computational Linguistics at
Peking University and describes an
experiment that aims at the automatic
emotion classification of Chinese idioms.
In the process, we expect to know more
about how the constituents in a fossilized
composition like an idiom function so as
to affect its semantic or grammatical
properties. As an important Chinese
language resource, our idiom knowledge
base will play a major role in applications
such as linguistic research, teaching
Chinese as a foreign language and even as
a tool for preserving this non-material
Chinese cultural and historical heritage.
</bodyText>
<sectionHeader confidence="0.998995" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999963647058824">
An idiom is a multi-word expression that has a
figurative meaning that is comprehended in
regard to a common use of that expression that
is separate from the literal meaning or definition
of the words of which it is made (McArthur,
1992). From a linguistic perspective, idioms are
usually presumed to be figures of speech that
are contradictory to the principle of
compositionality. The words that construct an
idiom no longer keep their original meaning or
popular sense, while in the process of its
formation it develops a specialized meaning as
an entity whose sense is different from the
literal meanings of the constituent elements.
Although an idiom is an expression not
readily analyzable from its grammatical
structure or from the meaning of its component
</bodyText>
<author confidence="0.661537">
Shiwen Yu
</author>
<affiliation confidence="0.782188333333333">
Key Laboratory of Computational
Linguistics of Ministry of Education,
Peking University
</affiliation>
<email confidence="0.971521">
yusw@pku.edu.cn
</email>
<bodyText confidence="0.99963634883721">
words, it is the distinctive form or construction
of a particular language that has a unique form
or style characteristic only of that language. An
idiom is also used, in most cases, with some
intention of the writer or to express certain
emotion or attitude. Thus in nature, idioms are
exaggerative and descriptive and do not belong
to the plain type.
Therefore, to classify idioms according to
its emotional property or descriptive property is
important for many practical applications. In
recent years, emotion classification has become
a very popular task in the area of Natural
Language Processing (NLP), which tries to
predict sentiment (opinion, emotion, etc.) from
texts. Most research has focused on subjectivity
(subjective/objective) or polarity
(positive/neutral/negative) classification. The
applications with this respect include human or
machine translation, automatic text
classification or Teaching Chinese as a Foreign
Language (TCFL). For example, when a student
learning Chinese as a foreign language
encounters an idiom in his or her reading or
conversation, for better understanding it is
important for him or her to know whether the
idiom is used to indicate an appreciative or
derogatory sense which is very crucial to
understand the attitude of the idiom user.
Another example is that long articles about
politics in newspapers often include a lot of
idiom usage to boost their expressiveness and
these idioms may carry emotional information.
Obviously by knowing the emotional
inclination we may easily obtain a clue about
the general attitude of the particular medium.
We may even be able to detect or monitor
automatically the possible hostile attitude from
certain electronic media which today provide so
huge amount of information that seems hard for
human processing on a daily basis.
The rest of this paper is organized as
follows. Section 2 describes the construction of
</bodyText>
<page confidence="0.996065">
11
</page>
<subsectionHeader confidence="0.710389">
Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 11–18,
Beijing, August 2010
</subsectionHeader>
<bodyText confidence="0.9994746">
a Chinese Idiom Knowledge Base (CIKB) and
introduces its several applications so far.
Section 3 concludes the related work that serves
as the basis of the building of CIKB and the
emotion classification experiment introduced in
this paper. Section 4 describes the classification
method, feature settings, the process of emotion
classification and the analysis of the result.
Section 5 includes conclusions and our future
work.
</bodyText>
<subsectionHeader confidence="0.7624665">
2 Chinese Idioms and Chinese Idiom
Knowledge Base
</subsectionHeader>
<bodyText confidence="0.981811825581395">
Generally an idiom is a metaphor — a term
requiring some background knowledge,
contextual information, or cultural experience,
mostly to use only within a particular language,
where conversational parties must possess
common cultural references. Therefore, idioms
are not considered part of the language, but part
of a nation’s history, society or culture. As
culture typically is localized, idioms often can
only be understood within the same cultural
background; nevertheless, this is not a definite
rule because some idioms can overcome
cultural barriers and easily be translated across
languages, and their metaphoric meanings can
still be deduced. Contrary to common
knowledge that language is a living thing,
idioms do not readily change as time passes.
Some idioms gain and lose favor in popular
literature or speeches, but they rarely have any
actual shift in their constructs as long as they do
not become extinct. In real life, people also
have a natural tendency to over exaggerate what
they mean or over describe what they see or
hear sometimes and this gives birth to new
idioms by accident.
Most Chinese idioms ()Aia: chéng1 yǔ,
literally meaning &amp;quot;set phrases&amp;quot;) are derived
from ancient literature, especially Chinese
classics, and are widely used in written Chinese
texts. Some idioms appear in spoken or
vernacular Chinese. The majority of Chinese
idioms consist of four characters, but some have
fewer or more. The meaning of an idiom
usually surpasses the sum of the meanings
1 The marks on the letters in a Pinyin are for the five tones
of Chinese characters.
carried by the few characters, as Chinese idioms
are often closely related with the fable, story or
historical account from which they were
originally born. As their constructs remain
stable through history, Chinese idioms do not
follow the usual lexical pattern and syntax of
modern Chinese language which has been
reformed many a time. They are instead highly
compact and resemble more ancient Chinese
language in many linguistic features.
Usually a Chinese idiom reflects the moral
behind the story that it is derived. (Lo, 1997)
For example, the idiom &amp;quot; 6*VE &amp;quot; (pò fǔ chén
zhōu) literally means &amp;quot;smash the cauldrons and
sink the boats.&amp;quot; It was based on a historical
story where General Xiang Yu in Qin Dynasty
(221 B. C. – 207 B. C.) ordered his army to
destroy all cooking utensils and boats after they
crossed a river into the enemy’s territory. He
and his men won the battle for their &amp;quot;life or
death&amp;quot; courage and &amp;quot;no-retreat&amp;quot; policy.
Although there are similar phrases in English,
such as &amp;quot;burning bridges&amp;quot; or &amp;quot;crossing the
Rubicon&amp;quot;, this particular idiom cannot be used
in a losing scenario because the story behind it
does not indicate a failure. Another typical
example is the idiom &amp;quot;�M�-F&amp;quot; (guā tián lǐ
xià) which literally means &amp;quot;melon field, under
the plum trees&amp;quot;. Metaphorically it implies a
suspicious situation. Derived from a verse
called ((RT(T) (jūn zǐ xíng, meaning &amp;quot;A
Gentleman’s Journey&amp;quot;) from Eastern Han
Dynasty (A. D. 25 – A. D. 220), the idiom is
originated from two lines of the poem &amp;quot;AMT
`M&amp;�-FT )W&amp;quot; (guā tián bù nà lǚ, lǐ xià bù
zhěng guān) which describe a code of conduct
for a gentleman that says &amp;quot;Don&apos;t adjust your
shoes in a melon field and don’t tidy your hat
under plum trees&amp;quot; in order to avoid suspicion of
stealing. However, most Chinese idioms do not
possess an allusion nature and are just a
combination of morphemes that will give this
set phrase phonetic, semantic or formal
expressiveness. For example, the idiom &amp;quot;X)�x
41k&amp;quot; (huān tiān xǐ dì, metaphorically meaning
&amp;quot;be highly delighted&amp;quot;) literally means &amp;quot;happy
heaven and joyful earth&amp;quot;; or in the idiom &amp;quot;Win
Ate&amp;quot; (láng dāng rù yù, meaning &amp;quot;be thrown
into the jail&amp;quot;), the word &amp;quot;Win&amp;quot; is just the sound
of a prisoner’s fetters.
</bodyText>
<page confidence="0.993066">
12
</page>
<bodyText confidence="0.999970142857143">
For the importance of idioms in Chinese
language and culture, an idiom bank with about
6,790 entries were included in the most
influential Chinese language knowledge base –
the Grammatical Knowledge base of
Contemporary Chinese (GKB) completed by
the Institute of Computational Linguistics at
Peking University (ICL), which has been
working on language resources for over 20
years and building many knowledge bases on
Chinese language. Based on that, the Chinese
Idiom Knowledge Base (CIKB) had been
constructed from the year 2004 to 2009 and
collects more than 38, 000 idioms with more
semantic and pragmatic properties added.
Basically the properties of each entry in
CIKB can be classified into four categories:
lexical, semantic, syntactic and pragmatic, each
of which also includes several fields in its
container -- the SQL database. Table 1 shows
the details about the fields.
</bodyText>
<table confidence="0.9975516">
Categories Properties
Lexical idiom, Pinyin2, full Pinyin3,
bianti4, explanation, origin
Semantic synonym, antonym, literal
translation, free translation,
English equivalent
Syntactic compositionality, syntactic
function
Pragmatic frequency, emotion, event
(context), grade
</table>
<tableCaption confidence="0.999776">
Table 1. Property categories of CIKB.
</tableCaption>
<bodyText confidence="0.96700764">
There are three fields of translation as we
can see in Table 1. In spite of the fact that a
2 Pinyin (拼音, literally &amp;quot;phonetics&amp;quot;, or more literally,
&amp;quot;spelling sound&amp;quot; or &amp;quot;spelled sound&amp;quot;), or more formally
Hanyu Pinyin (汉语拼音, Chinese Pinyin), is currently the
most commonly used Romanization system for standard
Mandarin. The system is now used in mainland China,
Hong Kong, Macau, parts of Taiwan, Malaysia and
Singapore to teach Mandarin Chinese and internationally
to teach Mandarin as a second language. It is also often
used to spell Chinese names in foreign publications and
can be used to enter Chinese characters on computers and
cell phones.
3 full Pinyin, a form of Pinyin that replaces the tone marks
with numbers 1 to 5 to indicate the five tones of Chinese
characters for the convenience of computer processing.
4 bianti, a variant form of the idiom that was caused by
random misuse, literary malapropism, etc.
literal translation of an idiom will not reflect its
metaphorical meaning generally, it will still be
of value to those who expect to get familiar
with the constituent characters and may want to
connect its literal meaning with its metaphorical
meaning, especially for those learners of
Chinese as a foreign language.
</bodyText>
<figureCaption confidence="0.998896">
Figure 1. The hierarchical structure of CIKB.
</figureCaption>
<bodyText confidence="0.990213586206897">
The idioms are classified into three grades
in terms of appearance in texts and complexity
of annotation. The most commonly used 3,000
idioms serve as the core idioms based on the
statistics obtained from the corpus of People’s
Daily (the year of 1998), a newspaper that has
the largest circulation in China. Another 11,000
idioms are selected into a category named as
basic idioms (fully annotated in every field) and
the total 38,117 forms the whole knowledge
base. Its hierarchical structure can be seen in
Figure 1.
The syntactic category aims at NLP tasks
like automatic identification or machine
translation. Compared with English idioms, the
identification of Chinese idioms is not so
difficult for its fossilized structure, i.e.
continuity in a text. To build a lexicon like
CIKB will complete the task successfully. As
for machine translation, however, it is
completely another story because the
compositional complexity of Chinese idioms
enables them to function as different syntactic
constituents with variable part-of-speech (POS).
We classify them into nine categories according
to its compositional relations of the morphemes
and into seven categories according to its
syntactic functions that they may serve in a
sentence, as is shown in Table 2.
</bodyText>
<figure confidence="0.975323666666667">
Core 3,000
Basic 11,000
CIKB 38,117
</figure>
<page confidence="0.981944">
13
</page>
<table confidence="0.9902385">
No. Compositionality Tag No. Syntactic function Tag
1 modifier-head construction pz 1 as a noun IN
2 subject-predicate phrase zw 2 as a verb IV
3 Coordination bl 3 as an adjective IA
4 predicate-object phrase db 4 as a complement IC
5 predicate-complement dbu 5 as an adverbial ID
6 predicate-object-complement dbb 6 as a classifier IB
7 serial verb ld 7 as a modifier IM
8 pivotal verb jy
9 Repetition fz
</table>
<tableCaption confidence="0.999673">
Table 2. Compositionality and syntactic functions of idioms.
</tableCaption>
<bodyText confidence="0.9996954375">
Upon the completion of CIKB, a few
research projects have been conducted to
investigate possible applications. Li (2006)
investigates the frequency and formation of
idiom usage in People’s Daily and Wang (2010)
selects 1,000 popular idioms from CIKB to
compile a book for Chinese learners. On the
basis of CIKB, we also made a couple of
attempts on the automatic classification of
idioms to identify the token-level characteristics
of an idiom. This paper will focus on the
emotion classification of idioms with machine
learning method and the work will be elaborated
in section 4. Here we define the emotion types
as ―appreciative (A)&amp;quot;, ―derogatory (D)&amp;quot; and
―neutral (N)&amp;quot;.
</bodyText>
<sectionHeader confidence="0.972973" genericHeader="related work">
3 Related Work on Idiom Knowledge
Base and Its Applications
</sectionHeader>
<bodyText confidence="0.999227363636364">
There has not been much work on the
construction of an idiom corpus or an idiom
knowledge base. With this respect, Birke and
Sarkar (2006) and Fellbaum (2007) are
exceptions. Birke and Sarkar (2006) constructed
a corpus of English idiomatic expressions with
automatic method. They selected 50 expressions
and collected about 6,600 examples. They call
the corpus TroFi Example Base, which is
available on the Web.
As far as idiom identification is concerned,
the work is classified into two kinds: one is for
idiom types and the other is for idiom tokens.
With the former, phrases that can be interpreted
as idioms are found in text corpora, typically for
lexicographers to compile idiom dictionaries.
Previous studies have mostly focused on the
idiom type identification (Lin, 1999; Baldwin et
al., 2003; Shudo et al., 2004). However, there
has been a growing interest in idiom token
identification recently (Katz and Giesbrecht,
2006; Hashimoto et al., 2006; Cook et al., 2007).
Our work elaborated in section 4 is also an
attempt in this regard.
Despite the recent enthusiasm for
multiword expressions, the idiom token
identification is in an early stage of its
development. Given that many language
teaching and learning tasks like TCFL have been
developed as a result of the availability of
language resources, idiom token identification
should also be developed when adequate idiom
resources are provided. To this end, we have
constructed the CIKB and hope to find
applications of value, for example, emotion
classification, event classification and text
analysis based on idiom usage and its context.
According to the granularity of text,
emotion analysis of texts can be divided into
three levels: text (Pang et al., 2002; Cui et al.,
2006), sentence (Pang et al., 2004), word
(Hatzivassiloglou et al., 1997; Wiebe 2000).
According to the sources of emotion prediction,
classification methods can be divided into
knowledge based methods and machine learning
based methods. The former uses lexicons or
knowledge bases to build a new lexicon that
contains emotion words. WordNet is often used
to compute the emotion prediction of words
(Hatzivassiloglou et al., 1997; Andrea 2005).
Meanwhile, incorporating knowledge into the
machine learning architecture as features is a
popular trend and untagged copra are often used
to do emotion classification research (Turney et
al., 2002; Akkaya et al., 2009).
</bodyText>
<page confidence="0.999228">
14
</page>
<sectionHeader confidence="0.9831585" genericHeader="method">
4 An NLP Application of Emotion
Classification on CIKB
</sectionHeader>
<bodyText confidence="0.999956466666667">
In this paper, we focus on the emotion prediction
of idioms conducted by machine learning
method. To do this, we aim to investigate how
the compositional constituents of an idiom affect
its emotion orientation from the token level,
especially for multi-word expressions with so
obvious an exaggerative and descriptive nature
like idioms. From CIKB, 20,000 idioms are
selected as the training corpus and 3,000 idioms
as the test corpus. The detailed distribution of
idioms in each emotion group is shown in Table
3. We can see that neutral has the largest number
of idioms, accounting for 41.08% and 36.67% in
the training and test corpus respectively, but
there is not a big difference between groups.
</bodyText>
<table confidence="0.9994462">
Training corpus Test corpus
number percentage number Percentage
Appreciative(A) 6967 34.84% 1011 33.70%
Neutral(N) 8216 41.08% 1100 36.67%
Derogatory(D) 4817 24.08% 889 29.63%
</table>
<tableCaption confidence="0.999805">
Table 3. The distribution of idioms in each emotion group.
</tableCaption>
<bodyText confidence="0.998683066666667">
Support Vector Machine (SVM) (Cortes
and Vapnik, 1995) is adopted as the
classification method to predict emotions in
idioms. LIBLINEAR (Fan et al., 2008), a
library for large SVM linear classification, is
used for implementation. The solver is set be
L2-loss SVM dual. Parameter C is set to be 2-5.
Three classes of features and their various
combinations are examined and used, including
Chinese characters, words and part-of-speeches.
Detailed features and related abbreviations are
shown as in Table 4.
Because Chinese sentences are written in
a consecutive string of characters, we need to
segment a sentence into individual words to
obtain the word feature. ICTCLAS (Zhang et
al., 2003), a tool developed by the Institute of
Computing Technology of Chinese Academy
of Sciences (ICT), is used for word
segmentation and part-of-speech tagging. We
adopt precision, recall and F-score (13=1) as the
evaluation parameters. From Table 5 we can
see that i_cb has a better performance than i_cu,
which indicates that a bigram model usually
performs better than a unigram model. But
when we segment the idioms and use i_wu, we
find that the performance gets bad. This may
be because the compositionality of Chinese
idioms is quite fossilized and the errors caused
by segmentation introduce some noise.
</bodyText>
<table confidence="0.994196571428572">
Features and their abbreviations Idiom(i) Explanation(e)
Chinese characters character unigram(i_cu, e_cu) √5 √
character bigram(i_cb, e_cb) √ √
Words word unigram(i_wu, e_wu) √ √
word bigram(i_wb, e_wu) X √
Word/part-of-speech word/pos unigram(i_wpu, e_wpu) √ √
word/pos bigram(i_wpb, e_wpb) X X
</table>
<tableCaption confidence="0.999269">
Table 4. Features selected for emotion prediction.
</tableCaption>
<page confidence="0.820157">
5 “✓” indicates the feature is selected while “X” indicates the feature is not selected.
15
</page>
<bodyText confidence="0.999504433333333">
We want to know whether we will have a
better performance if we add more features
from the other fields of CIKB. Obviously the
most relevant feature will be the explanation of
an idiom. Therefore we add the texts in the
explanation field as features in the experiment.
We find that by adding more features from the
explanation field, the performance does
improve. But when the POS feature is
introduced, the performance gets bad. This may
be because as Chinese idioms keep
grammatical properties of ancient Chinese
language and its POS is very different from the
setting of the tool designed primarily for
modern Chinese, more noise is introduced by
using POS here. Finally we can see that the
combination i_cu+i_cb+e_wu+e_wb achieves
the best performance in both Chinese character
features and word features.
Most importantly, we notice that although
for idioms themselves segmentation does not
affect the performance in a positive way,
segmentation of the explanations does improve
the performance. Thus we may conclude that
the compositionality of an idiom is very
different from its explanation which is written
in modern Chinese while the idiom itself is still
character-based and keeps its original
morphemes that are inherited from ancient
Chinese language.
</bodyText>
<table confidence="0.999893153846154">
Features or features Result
combined
Precision Recall F-score
i_cu 63.23% 75.16% 68.68%
i_cb 65.78% 78.24% 71.47%
i_wu 62.51% 73.42% 68.35%
i_wpu 60.03% 71.89% 65.43%
i_cu+e_wu 66.40% 80.05% 72.59%
i_cu+e_wpu 65.68% 77.95% 71.29%
i_cu+e_wb 65.08% 76.14% 70.18%
I_cu+i_cb 67.33% 80.82% 73.46%
i_cu+i_cb+e_wu 68.55% 81.37% 74.41%
i_cu+i_cb+e_wu+e_wb 70.18% 82.71% 75.93%
</table>
<tableCaption confidence="0.999684">
Table 5. The result of emotion classification with idioms and their explanations.
</tableCaption>
<figure confidence="0.7457905">
1k 2k 5k 10k 15k 20k
Size of training data
</figure>
<figureCaption confidence="0.994897">
Figure 2. Learning curve of the feature combination i_cu+i_cb+e_wu+e_wb.
</figureCaption>
<figure confidence="0.996429">
80%
75%
70%
65%
60%
55%
</figure>
<figureCaption confidence="0.831952666666667">
Figure 2 shows the learning curve of the
best classifier with the feature combination
i_cu+i_cb+e_wu+e_wb. We can see that the
</figureCaption>
<bodyText confidence="0.999550666666667">
accuracy keeps improving with the increase of
the size of training set, and peaks at 20,000
idioms. It shows the potential to improve the
</bodyText>
<page confidence="0.99349">
16
</page>
<bodyText confidence="0.97526">
performance of emotion classification by
enlarging the training data set.
</bodyText>
<sectionHeader confidence="0.975746" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999992058823529">
This paper introduces the construction of CIKB
by ICL at Peking University and its several
applications so far. One application – the
emotion classification of idioms – was
elaborated to show our effort in exploring the
token-level characteristics of Chinese idioms.
Therefore we select a number of idioms from
CIKB to classify them into three emotion
groups. SVM is employed for automatic
classification. Three classes of features are
examined and experiments show that certain
feature combinations achieve good
performance. The learning curve indicates that
performance may be further improved with the
increase of training data size.
Now we also hope to classify the idioms
into categories according to their usage in
</bodyText>
<sectionHeader confidence="0.998164" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.979307307692308">
Akkaya, Cem, Janyce Wiebe, and Rada
Mihalcea. 2009. Subjectivity Word Sense
Disambiguation. In Proceedings of the
2009 Conference on Empirical Methods in
Natural Language Processing: Volume 1:
pp.190-199.
Andrea, Esuli. 2005. Determining the Semantic
Orientation of Terms through Gloss
Classification. In Proceedings of the 14th
ACM International Conference on
Information and Knowledge Management:
pp.617-624.
Baldwin, Timothy, Colin Bannard, Takaaki
Tanaka, and Dominic Widdows. 2003. An
Empirical Model of Multiword Expression
Decomposability. In Proceedings of the
ACL 2003 Workshop on Multiword
Expressions: Analysis, Acquisition and
Treatment - Volume 18: pp.89-96.
Cook, Paul, Afsaneh Fazly, and Suzanne
Stevenson. 2007. Pulling Their Weight:
Exploiting Syntactic Forms for the
Automatic Identification of Idiomatic
Expressions in Context. In Proceedings of
the Workshop on A Broader Perspective
on Multiword Expressions: pp. 41-48.
</reference>
<bodyText confidence="0.987252090909091">
context, i.e., under what circumstances they are
often used (event classification). Various
linguistic features and real-world knowledge
will be considered to incorporate into the
machine learning classifier to improve
classification result. The work is in progress
and we hope the emotion classification and the
event classification will be compared to
determine their underlining relations and hope
that more applications can be found in our
future work based on CIKB.
</bodyText>
<sectionHeader confidence="0.994732" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998113142857143">
The work in this paper is supported by a grant
from the 973 National Basic Research Program
of China (No. 2004CB318102). The authors
are grateful to Dr. Li Yun and Professor Zhu
Xuefeng for their work on CIKB and the
anonymous reviewers for their helpful advice
to improve the paper.
</bodyText>
<reference confidence="0.995379038461539">
Cortes, Corinna and Vladimir Vapnik. 1995.
Support-Vector Networks. Machine
Learning, 20(3): pp. 273-297.
Cui, Hang, Vibhu Mittal, and Mayur Datar.
2006. Comparative Experiments on
Sentiment Classification for Online
Product Reviews. In Proceedings of the
21st National Conference on Artificial
Intelligence-Volume 2: pp.1265-1270.
Fan, Rong-En, Chang Kai-Wei, Cho-Jui Hsieh,
Xiang-Rui Wang, Chih-Jen Lin. 2008.
LIBLINEAR: A Library for Large Linear
Classification. Journal of Machine
Learning Research 9 (2008):
pp.1871-1874.
Fellbaum, Christiane. 2007. Idioms and
Collocations: Corpus-based Linguistic
and Lexicographic Studies (Research in
Corpus and Discourse). Continuum
International Publishing Group Ltd.,
London, UK.
Hashimoto, Chikara, Satoshi Sato, and
Takehito Utsuro. 2006. Japanese Idiom
Recognition: Drawing a Line between
Literal and Idiomatic Meanings. In
Proceedings of the COLING/ACL on
</reference>
<page confidence="0.987826">
17
</page>
<reference confidence="0.999827527027027">
Main Conference Poster Sessions: pp.
353-360.
Hatzivassiloglou, Vasileios, and Kathleen
McKeown. 1997. Predicting the Semantic
Orientation of Adjectives. In Proceedings
of the Eighth Conference on European
Chapter of the Association for
Computational Linguistics: pp.174-181.
Katz, Graham, and Eugenie Giesbrecht. 2006.
Automatic Identification of
Non-compositional Multi-word
Expressions Using Latent Semantic
Analysis. In Proceedings of the Workshop
on Multiword Expressions: Identifying
and Exploiting Underlying Properties:
pp.12-19.
Li, Yun, Zhang Huarui, Wang Hongjun, and
Yu Shiwen. 2006. Investigation on the
Frequency and Formation of Idioms in
People’s Daily. In Proceedings of the 7th
Chinese Lexicon and Semantics Workshop:
pp.241-248.
Lin, Dekang. 1999. Automatic Identification of
Noncompositional Phrases. In
Proceedings of the 37th Annual Meeting
of the Association for Computational
Linguistics on Computational Linguistics:
pp.317-324.
Lo, Wing Huen. 1997. Best Chinese Idioms
(Vol. 3). Hai Feng Publishing Co., Hong
Kong, China.
McArthur, Tom. 1992. The Oxford Companion
to the English Language. Oxford
University Press, Oxford, UK.
Pang, Bo and Lillian Lee. 2004. A Sentimental
Education: Sentiment Analysis Using
Subjectivity Summarization Based on
Minimum Cuts. In Proceedings of the
42nd Annual Meeting on Association for
Computational Linguistics: pp.271-278.
Pang, Bo, Lillian Lee, and Shivakumar
Vaithyanathan. 2002. Thumb up?
Sentiment Classification Using Machine
Learning Techniques. In Proceedings of
the ACL-02 Conference on Empirical
Methods in Natural Language Processing:
pp.79-86.
Shudo, Kosho, Toshifumi Tanabe, Masahito
Takahashi, and Kenji Yoshimura. 2004.
MWEs as Nonpropositional Content
Indicators. In Proceedings of the
Workshop on Multiword Expressions:
Integrating Processing: pp.32-39.
Turney, Peter D. 2002. Thumps Up or Thumps
Down? Semantic Orientation Applied to
Unsupervised Classification of Reviews.
In Proceedings of the 40th Annual
Meeting on Association for Computational
Linguistics: pp.417-424.
Wang, Lei. Forthcoming 2010. 1,000 Idioms
for Chinese Learners. Peking University
Press, Beijing, China.
Wiebe, Janyce. 2000. Learning Subjective
Adjectives from Corpora. In Proceedings
of the Seventeenth National Conference on
Artificial Intelligence and Twelfth
Conference on Innovative Applications of
Artificial Intelligence: pp.735-740.
Zhang, Huaping, Yu Hongkui, Xiong Deyi,
Liu Qun. 2003. HHMM-based Chinese
Lexical Analyzer ICTCLAS. In
Proceedings of the Second SIGHAN
Workshop on Chinese Language
Processing: pp.184-187.
</reference>
<page confidence="0.999288">
18
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.997963">Construction of a Chinese Idiom Knowledge Base and Its Applications</title>
<author confidence="0.81864">Lei</author>
<affiliation confidence="0.674632333333333">Key Laboratory of Linguistics of Ministry of Department of English, Peking</affiliation>
<email confidence="0.955544">wangleics@pku.edu.cn</email>
<abstract confidence="0.994664054945055">Idioms are not only interesting but also distinctive in a language for its continuity and metaphorical meaning in its context. This paper introduces the construction of a Chinese idiom knowledge base by the Institute of Computational Linguistics at Peking University and describes an experiment that aims at the automatic emotion classification of Chinese idioms. In the process, we expect to know more about how the constituents in a fossilized composition like an idiom function so as to affect its semantic or grammatical properties. As an important Chinese language resource, our idiom knowledge base will play a major role in applications such as linguistic research, teaching Chinese as a foreign language and even as a tool for preserving this non-material Chinese cultural and historical heritage. An idiom is a multi-word expression that has a figurative meaning that is comprehended in regard to a common use of that expression that is separate from the literal meaning or definition of the words of which it is made (McArthur, 1992). From a linguistic perspective, idioms are usually presumed to be figures of speech that are contradictory to the principle of compositionality. The words that construct an idiom no longer keep their original meaning or popular sense, while in the process of its formation it develops a specialized meaning as an entity whose sense is different from the literal meanings of the constituent elements. Although an idiom is an expression not readily analyzable from its grammatical structure or from the meaning of its component Shiwen Key Laboratory of Linguistics of Ministry of Peking yusw@pku.edu.cn words, it is the distinctive form or construction of a particular language that has a unique form or style characteristic only of that language. An idiom is also used, in most cases, with some intention of the writer or to express certain emotion or attitude. Thus in nature, idioms are exaggerative and descriptive and do not belong to the plain type. Therefore, to classify idioms according to its emotional property or descriptive property is important for many practical applications. In recent years, emotion classification has become a very popular task in the area of Natural Language Processing (NLP), which tries to predict sentiment (opinion, emotion, etc.) from texts. Most research has focused on subjectivity (subjective/objective) or (positive/neutral/negative) classification. The applications with this respect include human or machine translation, automatic classification or Teaching Chinese as a Foreign Language (TCFL). For example, when a student learning Chinese as a foreign language encounters an idiom in his or her reading or conversation, for better understanding it is important for him or her to know whether the idiom is used to indicate an appreciative or derogatory sense which is very crucial to understand the attitude of the idiom user. Another example is that long articles about politics in newspapers often include a lot of idiom usage to boost their expressiveness and these idioms may carry emotional information. Obviously by knowing the emotional inclination we may easily obtain a clue about the general attitude of the particular medium. We may even be able to detect or monitor automatically the possible hostile attitude from certain electronic media which today provide so huge amount of information that seems hard for human processing on a daily basis. The rest of this paper is organized as follows. Section 2 describes the construction of 11 of the Multiword Expressions: From Theory to Applications (MWE pages Beijing, August 2010 a Chinese Idiom Knowledge Base (CIKB) and introduces its several applications so far. Section 3 concludes the related work that serves as the basis of the building of CIKB and the emotion classification experiment introduced in this paper. Section 4 describes the classification method, feature settings, the process of emotion classification and the analysis of the result. Section 5 includes conclusions and our future work. 2 Chinese Idioms and Chinese Idiom Knowledge Base an idiom is a metaphor term requiring some background knowledge, contextual information, or cultural experience, mostly to use only within a particular language, where conversational parties must possess common cultural references. Therefore, idioms are not considered part of the language, but part a history, society or culture. As culture typically is localized, idioms often can only be understood within the same cultural background; nevertheless, this is not a definite rule because some idioms can overcome cultural barriers and easily be translated across languages, and their metaphoric meanings can still be deduced. Contrary to common knowledge that language is a living thing, idioms do not readily change as time passes. Some idioms gain and lose favor in popular literature or speeches, but they rarely have any actual shift in their constructs as long as they do not become extinct. In real life, people also have a natural tendency to over exaggerate what they mean or over describe what they see or hear sometimes and this gives birth to new idioms by accident. Chinese idioms yǔ, meaning phrases&amp;quot;) are derived from ancient literature, especially Chinese classics, and are widely used in written Chinese texts. Some idioms appear in spoken or vernacular Chinese. The majority of Chinese idioms consist of four characters, but some have fewer or more. The meaning of an idiom usually surpasses the sum of the meanings marks on the letters in a Pinyin are for the five tones of Chinese characters. carried by the few characters, as Chinese idioms are often closely related with the fable, story or historical account from which they were originally born. As their constructs remain stable through history, Chinese idioms do not follow the usual lexical pattern and syntax of modern Chinese language which has been reformed many a time. They are instead highly compact and resemble more ancient Chinese language in many linguistic features. Usually a Chinese idiom reflects the moral behind the story that it is derived. (Lo, 1997) example, the idiom &amp;quot; (pò fǔ chén literally means the cauldrons and the It based on a historical story where General Xiang Yu in Qin Dynasty B. C. B. C.) ordered his army to destroy all cooking utensils and boats after they river into the enemy’s territory. He his men won the battle for their or and policy. Although there are similar phrases in English, such as &amp;quot;burning bridges&amp;quot; or &amp;quot;crossing the this particular idiom cannot be used in a losing scenario because the story behind it does not indicate a failure. Another typical is the idiom (guā tián lǐ which literally &amp;quot;melon field, under plum it implies a suspicious situation. Derived from a verse zǐ xíng, meaning &amp;quot;A Journey&amp;quot;) Eastern Han (A. D. 25 D. 220), the idiom is from two lines of the poem (guā tián bù nà lǚ, lǐ xià bù which describe a code of conduct a gentleman says &amp;quot;Don&apos;t adjust your in a melon field tidy your hat trees&amp;quot; in order to avoid suspicion of stealing. However, most Chinese idioms do not possess an allusion nature and are just a combination of morphemes that will give this set phrase phonetic, semantic or formal For example, the idiom (huān tiān xǐ dì, meaning highly literally means and joyful or in the idiom (láng dāng rù yù, thrown the the word just the sound a fetters. 12 For the importance of idioms in Chinese language and culture, an idiom bank with about 6,790 entries were included in the most Chinese language knowledge base the Grammatical Knowledge base of Contemporary Chinese (GKB) completed by the Institute of Computational Linguistics at Peking University (ICL), which has been working on language resources for over 20 years and building many knowledge bases on Chinese language. Based on that, the Chinese Idiom Knowledge Base (CIKB) had been constructed from the year 2004 to 2009 and collects more than 38, 000 idioms with more semantic and pragmatic properties added. Basically the properties of each entry in CIKB can be classified into four categories: lexical, semantic, syntactic and pragmatic, each of which also includes several fields in its container -the SQL database. Table 1 shows the details about the fields. Categories Properties Lexical full explanation, origin Semantic synonym, antonym, literal translation, free translation, English equivalent Syntactic compositionality, syntactic function Pragmatic frequency, emotion, event (context), grade Table 1. Property categories of CIKB. There are three fields of translation as we can see in Table 1. In spite of the fact that a literally &amp;quot;phonetics&amp;quot;, or more literally, sound&amp;quot; or &amp;quot;spelled or more formally Pinyin Chinese Pinyin), is currently the most commonly used Romanization system for standard Mandarin. The system is now used in mainland China, Hong Kong, Macau, parts of Taiwan, Malaysia and Singapore to teach Mandarin Chinese and internationally to teach Mandarin as a second language. It is also often used to spell Chinese names in foreign publications and can be used to enter Chinese characters on computers and cell phones. Pinyin, a form of Pinyin that replaces the tone marks with numbers 1 to 5 to indicate the five tones of Chinese characters for the convenience of computer processing. a variant form of the idiom that was caused by random misuse, literary malapropism, etc. literal translation of an idiom will not reflect its metaphorical meaning generally, it will still be of value to those who expect to get familiar with the constituent characters and may want to connect its literal meaning with its metaphorical meaning, especially for those learners of Chinese as a foreign language. Figure 1. The hierarchical structure of CIKB. The idioms are classified into three grades in terms of appearance in texts and complexity of annotation. The most commonly used 3,000 idioms serve as the core idioms based on the statistics obtained from the corpus of People’s Daily (the year of 1998), a newspaper that has the largest circulation in China. Another 11,000 idioms are selected into a category named as basic idioms (fully annotated in every field) and the total 38,117 forms the whole knowledge base. Its hierarchical structure can be seen in Figure 1. The syntactic category aims at NLP tasks like automatic identification or machine translation. Compared with English idioms, the identification of Chinese idioms is not so difficult for its fossilized structure, i.e. continuity in a text. To build a lexicon like CIKB will complete the task successfully. As for machine translation, however, it is completely another story because the compositional complexity of Chinese idioms enables them to function as different syntactic constituents with variable part-of-speech (POS). We classify them into nine categories according to its compositional relations of the morphemes and into seven categories according to its syntactic functions that they may serve in a sentence, as is shown in Table 2.</abstract>
<note confidence="0.4372275">Core 3,000 Basic 11,000 CIKB 38,117 13</note>
<abstract confidence="0.994677678414097">No. Compositionality Tag No. Syntactic function Tag 1 modifier-head construction pz 1 as a noun IN 2 subject-predicate phrase zw 2 as a verb IV 3 Coordination bl 3 as an adjective IA 4 predicate-object phrase db 4 as a complement IC 5 predicate-complement dbu 5 as an adverbial ID 6 predicate-object-complement dbb 6 as a classifier IB 7 serial verb ld 7 as a modifier IM 8 pivotal verb jy 9 Repetition fz Table 2. Compositionality and syntactic functions of idioms. Upon the completion of CIKB, a few research projects have been conducted to investigate possible applications. Li (2006) investigates the frequency and formation of idiom usage in People’s Daily and Wang (2010) selects 1,000 popular idioms from CIKB to compile a book for Chinese learners. On the basis of CIKB, we also made a couple of attempts on the automatic classification of idioms to identify the token-level characteristics of an idiom. This paper will focus on the emotion classification of idioms with machine learning method and the work will be elaborated in section 4. Here we define the emotion types as ―appreciative (A)&amp;quot;, ―derogatory (D)&amp;quot; and 3 Related Work on Idiom Knowledge Base and Its Applications There has not been much work on the construction of an idiom corpus or an idiom knowledge base. With this respect, Birke and Sarkar (2006) and Fellbaum (2007) are exceptions. Birke and Sarkar (2006) constructed a corpus of English idiomatic expressions with automatic method. They selected 50 expressions and collected about 6,600 examples. They call the corpus TroFi Example Base, which is available on the Web. As far as idiom identification is concerned, the work is classified into two kinds: one is for idiom types and the other is for idiom tokens. With the former, phrases that can be interpreted as idioms are found in text corpora, typically for lexicographers to compile idiom dictionaries. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Baldwin et al., 2003; Shudo et al., 2004). However, there has been a growing interest in idiom token identification recently (Katz and Giesbrecht, 2006; Hashimoto et al., 2006; Cook et al., 2007). Our work elaborated in section 4 is also an attempt in this regard. Despite the recent enthusiasm for multiword expressions, the idiom token identification is in an early stage of its development. Given that many language teaching and learning tasks like TCFL have been developed as a result of the availability of language resources, idiom token identification should also be developed when adequate idiom resources are provided. To this end, we have constructed the CIKB and hope to find applications of value, for example, emotion classification, event classification and text analysis based on idiom usage and its context. According to the granularity of text, emotion analysis of texts can be divided into three levels: text (Pang et al., 2002; Cui et al., 2006), sentence (Pang et al., 2004), word (Hatzivassiloglou et al., 1997; Wiebe 2000). According to the sources of emotion prediction, classification methods can be divided into knowledge based methods and machine learning based methods. The former uses lexicons or knowledge bases to build a new lexicon that contains emotion words. WordNet is often used to compute the emotion prediction of words (Hatzivassiloglou et al., 1997; Andrea 2005). Meanwhile, incorporating knowledge into the machine learning architecture as features is a popular trend and untagged copra are often used to do emotion classification research (Turney et al., 2002; Akkaya et al., 2009). 14 4 An NLP Application of Emotion Classification on CIKB In this paper, we focus on the emotion prediction of idioms conducted by machine learning method. To do this, we aim to investigate how the compositional constituents of an idiom affect its emotion orientation from the token level, especially for multi-word expressions with so obvious an exaggerative and descriptive nature like idioms. From CIKB, 20,000 idioms are selected as the training corpus and 3,000 idioms as the test corpus. The detailed distribution of idioms in each emotion group is shown in Table 3. We can see that neutral has the largest number of idioms, accounting for 41.08% and 36.67% in the training and test corpus respectively, but there is not a big difference between groups. Training corpus Test corpus number percentage number Percentage Appreciative(A) 6967 34.84% 1011 33.70% Neutral(N) 8216 41.08% 1100 36.67% Derogatory(D) 4817 24.08% 889 29.63% Table 3. The distribution of idioms in each emotion group. Support Vector Machine (SVM) (Cortes and Vapnik, 1995) is adopted as the classification method to predict emotions in idioms. LIBLINEAR (Fan et al., 2008), a library for large SVM linear classification, is used for implementation. The solver is set be SVM dual. Parameter set to be Three classes of features and their various combinations are examined and used, including Chinese characters, words and part-of-speeches. Detailed features and related abbreviations are shown as in Table 4. Because Chinese sentences are written in a consecutive string of characters, we need to segment a sentence into individual words to obtain the word feature. ICTCLAS (Zhang et al., 2003), a tool developed by the Institute of Computing Technology of Chinese Academy of Sciences (ICT), is used for word segmentation and part-of-speech tagging. We precision, recall and F-score as the evaluation parameters. From Table 5 we can see that i_cb has a better performance than i_cu, which indicates that a bigram model usually performs better than a unigram model. But when we segment the idioms and use i_wu, we find that the performance gets bad. This may be because the compositionality of Chinese idioms is quite fossilized and the errors caused by segmentation introduce some noise. Features and their abbreviations Idiom(i) Explanation(e) Chinese characters character unigram(i_cu, e_cu) √ character bigram(i_cb, e_cb) √ √ Words word unigram(i_wu, e_wu) √ √ word bigram(i_wb, e_wu) X √ Word/part-of-speech word/pos unigram(i_wpu, e_wpu) √ √ word/pos bigram(i_wpb, e_wpb) X X Table 4. Features selected for emotion prediction. the feature is selected while the feature is not selected. 15 We want to know whether we will have a better performance if we add more features from the other fields of CIKB. Obviously the most relevant feature will be the explanation of an idiom. Therefore we add the texts in the explanation field as features in the experiment. We find that by adding more features from the explanation field, the performance does improve. But when the POS feature is introduced, the performance gets bad. This may be because as Chinese idioms keep grammatical properties of ancient Chinese language and its POS is very different from the setting of the tool designed primarily for modern Chinese, more noise is introduced by using POS here. Finally we can see that the combination i_cu+i_cb+e_wu+e_wb achieves the best performance in both Chinese character features and word features. Most importantly, we notice that although for idioms themselves segmentation does not affect the performance in a positive way, segmentation of the explanations does improve the performance. Thus we may conclude that the compositionality of an idiom is very different from its explanation which is written in modern Chinese while the idiom itself is still character-based and keeps its original morphemes that are inherited from ancient Chinese language. Features or Result combined Precision Recall F-score i_cu 63.23% 75.16% 68.68% i_cb 65.78% 78.24% 71.47% i_wu 62.51% 73.42% 68.35% i_wpu 60.03% 71.89% 65.43% i_cu+e_wu 66.40% 80.05% 72.59% i_cu+e_wpu 65.68% 77.95% 71.29% i_cu+e_wb 65.08% 76.14% 70.18% I_cu+i_cb 67.33% 80.82% 73.46% i_cu+i_cb+e_wu 68.55% 81.37% 74.41% i_cu+i_cb+e_wu+e_wb 70.18% 82.71% 75.93% Table 5. The result of emotion classification with idioms and their explanations. 2k 5k 10k 15k 20k of training data Figure 2. Learning curve of the feature combination i_cu+i_cb+e_wu+e_wb. 80% 75% 70% 65% 60% 55% Figure 2 shows the learning curve of the best classifier with the feature combination i_cu+i_cb+e_wu+e_wb. We can see that the accuracy keeps improving with the increase of the size of training set, and peaks at 20,000 idioms. It shows the potential to improve the 16 performance of emotion classification by enlarging the training data set. 5 Conclusions and Future Work This paper introduces the construction of CIKB by ICL at Peking University and its several so far. One application classification of idioms elaborated to show our effort in exploring the token-level characteristics of Chinese idioms. Therefore we select a number of idioms from CIKB to classify them into three emotion groups. SVM is employed for automatic classification. Three classes of features are examined and experiments show that certain feature combinations achieve good performance. The learning curve indicates that performance may be further improved with the increase of training data size. Now we also hope to classify the idioms into categories according to their usage in</abstract>
<note confidence="0.932245590909091">References Akkaya, Cem, Janyce Wiebe, and Rada Mihalcea. 2009. Subjectivity Word Sense In of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1: pp.190-199. Andrea, Esuli. 2005. Determining the Semantic Orientation of Terms through Gloss In of the International on and Knowledge pp.617-624. Baldwin, Timothy, Colin Bannard, Takaaki Tanaka, and Dominic Widdows. 2003. An Empirical Model of Multiword Expression In of the ACL 2003 Workshop on Multiword Expressions: Analysis, Acquisition and - Volume 18: Cook, Paul, Afsaneh Fazly, and Suzanne Stevenson. 2007. Pulling Their Weight:</note>
<title confidence="0.7496595">Exploiting Syntactic Forms for the Automatic Identification of Idiomatic</title>
<abstract confidence="0.903752863636364">in Context. In of the Workshop on A Broader Perspective Multiword pp. 41-48. context, i.e., under what circumstances they are often used (event classification). Various linguistic features and real-world knowledge will be considered to incorporate into the machine learning classifier to improve classification result. The work is in progress and we hope the emotion classification and the event classification will be compared to determine their underlining relations and hope that more applications can be found in our future work based on CIKB. Acknowledgements The work in this paper is supported by a grant from the 973 National Basic Research Program of China (No. 2004CB318102). The authors are grateful to Dr. Li Yun and Professor Zhu Xuefeng for their work on CIKB and the anonymous reviewers for their helpful advice to improve the paper.</abstract>
<note confidence="0.88674575">Cortes, Corinna and Vladimir Vapnik. 1995. Networks. 20(3): pp. 273-297. Cui, Hang, Vibhu Mittal, and Mayur Datar. 2006. Comparative Experiments on Sentiment Classification for Online Reviews. In of the 21st National Conference on Artificial pp.1265-1270. Fan, Rong-En, Chang Kai-Wei, Cho-Jui Hsieh, Xiang-Rui Wang, Chih-Jen Lin. 2008. LIBLINEAR: A Library for Large Linear of Machine Research (2008): pp.1871-1874. Christiane. 2007. and</note>
<title confidence="0.727195">Collocations: Corpus-based Linguistic</title>
<author confidence="0.883184">Lexicographic Studies</author>
<affiliation confidence="0.973349">and Discourse). International Publishing Group Ltd.,</affiliation>
<address confidence="0.6408625">London, UK. Hashimoto, Chikara, Satoshi Sato, and</address>
<note confidence="0.910551142857143">Takehito Utsuro. 2006. Japanese Idiom Recognition: Drawing a Line between Literal and Idiomatic Meanings. In Proceedings of the COLING/ACL on 17 Conference Poster pp. 353-360. Hatzivassiloglou, Vasileios, and Kathleen McKeown. 1997. Predicting the Semantic of Adjectives. In of the Eighth Conference on European Chapter of the Association for Linguistics: Katz, Graham, and Eugenie Giesbrecht. 2006.</note>
<title confidence="0.9792425">Automatic Identification of Non-compositional Expressions Using Latent Semantic In of the Workshop on Multiword Expressions: Identifying Exploiting Underlying</title>
<note confidence="0.988910230769231">pp.12-19. Li, Yun, Zhang Huarui, Wang Hongjun, and Yu Shiwen. 2006. Investigation on the Frequency and Formation of Idioms in Daily. In of the 7th Chinese Lexicon and Semantics Workshop: pp.241-248. Lin, Dekang. 1999. Automatic Identification of Noncompositional Phrases. Proceedings of the 37th Annual Meeting of the Association for Computational on Computational pp.317-324.</note>
<title confidence="0.872516">Wing Huen. 1997. Chinese Idioms</title>
<author confidence="0.889403">Hai Feng Publishing Co</author>
<author confidence="0.889403">Hong</author>
<address confidence="0.829406">Kong, China.</address>
<note confidence="0.913264090909091">Tom. 1992. Oxford Companion the English Language. University Press, Oxford, UK. Pang, Bo and Lillian Lee. 2004. A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Cuts. In of the 42nd Annual Meeting on Association for pp.271-278. Pang, Bo, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumb up?</note>
<title confidence="0.864026">Sentiment Classification Using Machine</title>
<author confidence="0.50026">In of</author>
<note confidence="0.973517875">the ACL-02 Conference on Empirical Methods in Natural Language Processing: pp.79-86. Shudo, Kosho, Toshifumi Tanabe, Masahito Takahashi, and Kenji Yoshimura. 2004. MWEs as Nonpropositional Content In of the Workshop on Multiword Expressions: pp.32-39. Turney, Peter D. 2002. Thumps Up or Thumps Down? Semantic Orientation Applied to Unsupervised Classification of Reviews. of the 40th Annual Meeting on Association for Computational pp.417-424. Lei. Forthcoming 2010. Idioms</note>
<affiliation confidence="0.898051">Chinese Learners. University</affiliation>
<address confidence="0.893455">Press, Beijing, China.</address>
<note confidence="0.507523416666667">Wiebe, Janyce. 2000. Learning Subjective from Corpora. In of the Seventeenth National Conference on Artificial Intelligence and Twelfth Conference on Innovative Applications of Intelligence: Zhang, Huaping, Yu Hongkui, Xiong Deyi, Liu Qun. 2003. HHMM-based Chinese Lexical Analyzer ICTCLAS. In Proceedings of the Second SIGHAN Workshop on Chinese Language pp.184-187.</note>
<intro confidence="0.478562">18</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Cem Akkaya</author>
<author>Janyce Wiebe</author>
<author>Rada Mihalcea</author>
</authors>
<title>Subjectivity Word Sense Disambiguation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing:</booktitle>
<volume>1</volume>
<pages>190--199</pages>
<contexts>
<context position="15606" citStr="Akkaya et al., 2009" startWordPosition="2482" endWordPosition="2485">atzivassiloglou et al., 1997; Wiebe 2000). According to the sources of emotion prediction, classification methods can be divided into knowledge based methods and machine learning based methods. The former uses lexicons or knowledge bases to build a new lexicon that contains emotion words. WordNet is often used to compute the emotion prediction of words (Hatzivassiloglou et al., 1997; Andrea 2005). Meanwhile, incorporating knowledge into the machine learning architecture as features is a popular trend and untagged copra are often used to do emotion classification research (Turney et al., 2002; Akkaya et al., 2009). 14 4 An NLP Application of Emotion Classification on CIKB In this paper, we focus on the emotion prediction of idioms conducted by machine learning method. To do this, we aim to investigate how the compositional constituents of an idiom affect its emotion orientation from the token level, especially for multi-word expressions with so obvious an exaggerative and descriptive nature like idioms. From CIKB, 20,000 idioms are selected as the training corpus and 3,000 idioms as the test corpus. The detailed distribution of idioms in each emotion group is shown in Table 3. We can see that neutral h</context>
</contexts>
<marker>Akkaya, Wiebe, Mihalcea, 2009</marker>
<rawString>Akkaya, Cem, Janyce Wiebe, and Rada Mihalcea. 2009. Subjectivity Word Sense Disambiguation. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1: pp.190-199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Esuli Andrea</author>
</authors>
<title>Determining the Semantic Orientation of Terms through Gloss Classification.</title>
<date>2005</date>
<booktitle>In Proceedings of the 14th ACM International Conference on Information and Knowledge Management:</booktitle>
<pages>617--624</pages>
<contexts>
<context position="15385" citStr="Andrea 2005" startWordPosition="2451" endWordPosition="2452">d on idiom usage and its context. According to the granularity of text, emotion analysis of texts can be divided into three levels: text (Pang et al., 2002; Cui et al., 2006), sentence (Pang et al., 2004), word (Hatzivassiloglou et al., 1997; Wiebe 2000). According to the sources of emotion prediction, classification methods can be divided into knowledge based methods and machine learning based methods. The former uses lexicons or knowledge bases to build a new lexicon that contains emotion words. WordNet is often used to compute the emotion prediction of words (Hatzivassiloglou et al., 1997; Andrea 2005). Meanwhile, incorporating knowledge into the machine learning architecture as features is a popular trend and untagged copra are often used to do emotion classification research (Turney et al., 2002; Akkaya et al., 2009). 14 4 An NLP Application of Emotion Classification on CIKB In this paper, we focus on the emotion prediction of idioms conducted by machine learning method. To do this, we aim to investigate how the compositional constituents of an idiom affect its emotion orientation from the token level, especially for multi-word expressions with so obvious an exaggerative and descriptive n</context>
</contexts>
<marker>Andrea, 2005</marker>
<rawString>Andrea, Esuli. 2005. Determining the Semantic Orientation of Terms through Gloss Classification. In Proceedings of the 14th ACM International Conference on Information and Knowledge Management: pp.617-624.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Colin Bannard</author>
<author>Takaaki Tanaka</author>
<author>Dominic Widdows</author>
</authors>
<title>An Empirical Model of Multiword Expression Decomposability.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment - Volume</booktitle>
<volume>18</volume>
<pages>89--96</pages>
<contexts>
<context position="14003" citStr="Baldwin et al., 2003" startWordPosition="2232" endWordPosition="2235">d Sarkar (2006) constructed a corpus of English idiomatic expressions with automatic method. They selected 50 expressions and collected about 6,600 examples. They call the corpus TroFi Example Base, which is available on the Web. As far as idiom identification is concerned, the work is classified into two kinds: one is for idiom types and the other is for idiom tokens. With the former, phrases that can be interpreted as idioms are found in text corpora, typically for lexicographers to compile idiom dictionaries. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Baldwin et al., 2003; Shudo et al., 2004). However, there has been a growing interest in idiom token identification recently (Katz and Giesbrecht, 2006; Hashimoto et al., 2006; Cook et al., 2007). Our work elaborated in section 4 is also an attempt in this regard. Despite the recent enthusiasm for multiword expressions, the idiom token identification is in an early stage of its development. Given that many language teaching and learning tasks like TCFL have been developed as a result of the availability of language resources, idiom token identification should also be developed when adequate idiom resources are pr</context>
</contexts>
<marker>Baldwin, Bannard, Tanaka, Widdows, 2003</marker>
<rawString>Baldwin, Timothy, Colin Bannard, Takaaki Tanaka, and Dominic Widdows. 2003. An Empirical Model of Multiword Expression Decomposability. In Proceedings of the ACL 2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment - Volume 18: pp.89-96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Cook</author>
<author>Afsaneh Fazly</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Pulling Their Weight: Exploiting Syntactic Forms for the Automatic Identification of Idiomatic Expressions in Context.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on A Broader Perspective on Multiword Expressions:</booktitle>
<pages>41--48</pages>
<contexts>
<context position="14178" citStr="Cook et al., 2007" startWordPosition="2260" endWordPosition="2263">s TroFi Example Base, which is available on the Web. As far as idiom identification is concerned, the work is classified into two kinds: one is for idiom types and the other is for idiom tokens. With the former, phrases that can be interpreted as idioms are found in text corpora, typically for lexicographers to compile idiom dictionaries. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Baldwin et al., 2003; Shudo et al., 2004). However, there has been a growing interest in idiom token identification recently (Katz and Giesbrecht, 2006; Hashimoto et al., 2006; Cook et al., 2007). Our work elaborated in section 4 is also an attempt in this regard. Despite the recent enthusiasm for multiword expressions, the idiom token identification is in an early stage of its development. Given that many language teaching and learning tasks like TCFL have been developed as a result of the availability of language resources, idiom token identification should also be developed when adequate idiom resources are provided. To this end, we have constructed the CIKB and hope to find applications of value, for example, emotion classification, event classification and text analysis based on </context>
</contexts>
<marker>Cook, Fazly, Stevenson, 2007</marker>
<rawString>Cook, Paul, Afsaneh Fazly, and Suzanne Stevenson. 2007. Pulling Their Weight: Exploiting Syntactic Forms for the Automatic Identification of Idiomatic Expressions in Context. In Proceedings of the Workshop on A Broader Perspective on Multiword Expressions: pp. 41-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Corinna Cortes</author>
<author>Vladimir Vapnik</author>
</authors>
<title>Support-Vector Networks.</title>
<date>1995</date>
<booktitle>Machine Learning,</booktitle>
<volume>20</volume>
<issue>3</issue>
<pages>273--297</pages>
<contexts>
<context position="16657" citStr="Cortes and Vapnik, 1995" startWordPosition="2648" endWordPosition="2651">selected as the training corpus and 3,000 idioms as the test corpus. The detailed distribution of idioms in each emotion group is shown in Table 3. We can see that neutral has the largest number of idioms, accounting for 41.08% and 36.67% in the training and test corpus respectively, but there is not a big difference between groups. Training corpus Test corpus number percentage number Percentage Appreciative(A) 6967 34.84% 1011 33.70% Neutral(N) 8216 41.08% 1100 36.67% Derogatory(D) 4817 24.08% 889 29.63% Table 3. The distribution of idioms in each emotion group. Support Vector Machine (SVM) (Cortes and Vapnik, 1995) is adopted as the classification method to predict emotions in idioms. LIBLINEAR (Fan et al., 2008), a library for large SVM linear classification, is used for implementation. The solver is set be L2-loss SVM dual. Parameter C is set to be 2-5. Three classes of features and their various combinations are examined and used, including Chinese characters, words and part-of-speeches. Detailed features and related abbreviations are shown as in Table 4. Because Chinese sentences are written in a consecutive string of characters, we need to segment a sentence into individual words to obtain the word</context>
</contexts>
<marker>Cortes, Vapnik, 1995</marker>
<rawString>Cortes, Corinna and Vladimir Vapnik. 1995. Support-Vector Networks. Machine Learning, 20(3): pp. 273-297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Cui</author>
<author>Vibhu Mittal</author>
<author>Mayur Datar</author>
</authors>
<title>Comparative Experiments on Sentiment Classification for Online Product Reviews.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st National Conference on Artificial Intelligence-Volume</booktitle>
<volume>2</volume>
<pages>1265--1270</pages>
<contexts>
<context position="14947" citStr="Cui et al., 2006" startWordPosition="2383" endWordPosition="2386">ation is in an early stage of its development. Given that many language teaching and learning tasks like TCFL have been developed as a result of the availability of language resources, idiom token identification should also be developed when adequate idiom resources are provided. To this end, we have constructed the CIKB and hope to find applications of value, for example, emotion classification, event classification and text analysis based on idiom usage and its context. According to the granularity of text, emotion analysis of texts can be divided into three levels: text (Pang et al., 2002; Cui et al., 2006), sentence (Pang et al., 2004), word (Hatzivassiloglou et al., 1997; Wiebe 2000). According to the sources of emotion prediction, classification methods can be divided into knowledge based methods and machine learning based methods. The former uses lexicons or knowledge bases to build a new lexicon that contains emotion words. WordNet is often used to compute the emotion prediction of words (Hatzivassiloglou et al., 1997; Andrea 2005). Meanwhile, incorporating knowledge into the machine learning architecture as features is a popular trend and untagged copra are often used to do emotion classif</context>
</contexts>
<marker>Cui, Mittal, Datar, 2006</marker>
<rawString>Cui, Hang, Vibhu Mittal, and Mayur Datar. 2006. Comparative Experiments on Sentiment Classification for Online Product Reviews. In Proceedings of the 21st National Conference on Artificial Intelligence-Volume 2: pp.1265-1270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Chang Kai-Wei</author>
<author>Cho-Jui Hsieh</author>
<author>Xiang-Rui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBLINEAR: A Library for Large Linear Classification.</title>
<date>2008</date>
<journal>Journal of Machine Learning Research</journal>
<volume>9</volume>
<pages>1871--1874</pages>
<contexts>
<context position="16757" citStr="Fan et al., 2008" startWordPosition="2664" endWordPosition="2667"> each emotion group is shown in Table 3. We can see that neutral has the largest number of idioms, accounting for 41.08% and 36.67% in the training and test corpus respectively, but there is not a big difference between groups. Training corpus Test corpus number percentage number Percentage Appreciative(A) 6967 34.84% 1011 33.70% Neutral(N) 8216 41.08% 1100 36.67% Derogatory(D) 4817 24.08% 889 29.63% Table 3. The distribution of idioms in each emotion group. Support Vector Machine (SVM) (Cortes and Vapnik, 1995) is adopted as the classification method to predict emotions in idioms. LIBLINEAR (Fan et al., 2008), a library for large SVM linear classification, is used for implementation. The solver is set be L2-loss SVM dual. Parameter C is set to be 2-5. Three classes of features and their various combinations are examined and used, including Chinese characters, words and part-of-speeches. Detailed features and related abbreviations are shown as in Table 4. Because Chinese sentences are written in a consecutive string of characters, we need to segment a sentence into individual words to obtain the word feature. ICTCLAS (Zhang et al., 2003), a tool developed by the Institute of Computing Technology of</context>
</contexts>
<marker>Fan, Kai-Wei, Hsieh, Wang, Lin, 2008</marker>
<rawString>Fan, Rong-En, Chang Kai-Wei, Cho-Jui Hsieh, Xiang-Rui Wang, Chih-Jen Lin. 2008. LIBLINEAR: A Library for Large Linear Classification. Journal of Machine Learning Research 9 (2008): pp.1871-1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>Idioms and Collocations: Corpus-based Linguistic and Lexicographic Studies (Research</title>
<date>2007</date>
<booktitle>in Corpus and Discourse). Continuum International</booktitle>
<publisher>Publishing Group Ltd.,</publisher>
<location>London, UK.</location>
<contexts>
<context position="13358" citStr="Fellbaum (2007)" startWordPosition="2132" endWordPosition="2133">se learners. On the basis of CIKB, we also made a couple of attempts on the automatic classification of idioms to identify the token-level characteristics of an idiom. This paper will focus on the emotion classification of idioms with machine learning method and the work will be elaborated in section 4. Here we define the emotion types as ―appreciative (A)&amp;quot;, ―derogatory (D)&amp;quot; and ―neutral (N)&amp;quot;. 3 Related Work on Idiom Knowledge Base and Its Applications There has not been much work on the construction of an idiom corpus or an idiom knowledge base. With this respect, Birke and Sarkar (2006) and Fellbaum (2007) are exceptions. Birke and Sarkar (2006) constructed a corpus of English idiomatic expressions with automatic method. They selected 50 expressions and collected about 6,600 examples. They call the corpus TroFi Example Base, which is available on the Web. As far as idiom identification is concerned, the work is classified into two kinds: one is for idiom types and the other is for idiom tokens. With the former, phrases that can be interpreted as idioms are found in text corpora, typically for lexicographers to compile idiom dictionaries. Previous studies have mostly focused on the idiom type id</context>
</contexts>
<marker>Fellbaum, 2007</marker>
<rawString>Fellbaum, Christiane. 2007. Idioms and Collocations: Corpus-based Linguistic and Lexicographic Studies (Research in Corpus and Discourse). Continuum International Publishing Group Ltd., London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chikara Hashimoto</author>
<author>Satoshi Sato</author>
<author>Takehito Utsuro</author>
</authors>
<title>Japanese Idiom Recognition: Drawing a Line between Literal and Idiomatic Meanings.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Main Conference Poster Sessions:</booktitle>
<pages>353--360</pages>
<contexts>
<context position="14158" citStr="Hashimoto et al., 2006" startWordPosition="2256" endWordPosition="2259">les. They call the corpus TroFi Example Base, which is available on the Web. As far as idiom identification is concerned, the work is classified into two kinds: one is for idiom types and the other is for idiom tokens. With the former, phrases that can be interpreted as idioms are found in text corpora, typically for lexicographers to compile idiom dictionaries. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Baldwin et al., 2003; Shudo et al., 2004). However, there has been a growing interest in idiom token identification recently (Katz and Giesbrecht, 2006; Hashimoto et al., 2006; Cook et al., 2007). Our work elaborated in section 4 is also an attempt in this regard. Despite the recent enthusiasm for multiword expressions, the idiom token identification is in an early stage of its development. Given that many language teaching and learning tasks like TCFL have been developed as a result of the availability of language resources, idiom token identification should also be developed when adequate idiom resources are provided. To this end, we have constructed the CIKB and hope to find applications of value, for example, emotion classification, event classification and tex</context>
</contexts>
<marker>Hashimoto, Sato, Utsuro, 2006</marker>
<rawString>Hashimoto, Chikara, Satoshi Sato, and Takehito Utsuro. 2006. Japanese Idiom Recognition: Drawing a Line between Literal and Idiomatic Meanings. In Proceedings of the COLING/ACL on Main Conference Poster Sessions: pp. 353-360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen McKeown</author>
</authors>
<title>Predicting the Semantic Orientation of Adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings of the Eighth Conference on European Chapter of the Association for Computational Linguistics:</booktitle>
<pages>174--181</pages>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Hatzivassiloglou, Vasileios, and Kathleen McKeown. 1997. Predicting the Semantic Orientation of Adjectives. In Proceedings of the Eighth Conference on European Chapter of the Association for Computational Linguistics: pp.174-181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Katz</author>
<author>Eugenie Giesbrecht</author>
</authors>
<title>Automatic Identification of Non-compositional Multi-word Expressions Using Latent Semantic Analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties:</booktitle>
<pages>12--19</pages>
<contexts>
<context position="14134" citStr="Katz and Giesbrecht, 2006" startWordPosition="2252" endWordPosition="2255">collected about 6,600 examples. They call the corpus TroFi Example Base, which is available on the Web. As far as idiom identification is concerned, the work is classified into two kinds: one is for idiom types and the other is for idiom tokens. With the former, phrases that can be interpreted as idioms are found in text corpora, typically for lexicographers to compile idiom dictionaries. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Baldwin et al., 2003; Shudo et al., 2004). However, there has been a growing interest in idiom token identification recently (Katz and Giesbrecht, 2006; Hashimoto et al., 2006; Cook et al., 2007). Our work elaborated in section 4 is also an attempt in this regard. Despite the recent enthusiasm for multiword expressions, the idiom token identification is in an early stage of its development. Given that many language teaching and learning tasks like TCFL have been developed as a result of the availability of language resources, idiom token identification should also be developed when adequate idiom resources are provided. To this end, we have constructed the CIKB and hope to find applications of value, for example, emotion classification, even</context>
</contexts>
<marker>Katz, Giesbrecht, 2006</marker>
<rawString>Katz, Graham, and Eugenie Giesbrecht. 2006. Automatic Identification of Non-compositional Multi-word Expressions Using Latent Semantic Analysis. In Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties: pp.12-19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yun Li</author>
<author>Zhang Huarui</author>
<author>Wang Hongjun</author>
<author>Yu Shiwen</author>
</authors>
<title>Investigation on the Frequency and Formation of Idioms in People’s Daily.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Chinese Lexicon and Semantics Workshop:</booktitle>
<pages>241--248</pages>
<marker>Li, Huarui, Hongjun, Shiwen, 2006</marker>
<rawString>Li, Yun, Zhang Huarui, Wang Hongjun, and Yu Shiwen. 2006. Investigation on the Frequency and Formation of Idioms in People’s Daily. In Proceedings of the 7th Chinese Lexicon and Semantics Workshop: pp.241-248.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic Identification of Noncompositional Phrases.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics on Computational Linguistics:</booktitle>
<pages>317--324</pages>
<contexts>
<context position="13981" citStr="Lin, 1999" startWordPosition="2230" endWordPosition="2231">s. Birke and Sarkar (2006) constructed a corpus of English idiomatic expressions with automatic method. They selected 50 expressions and collected about 6,600 examples. They call the corpus TroFi Example Base, which is available on the Web. As far as idiom identification is concerned, the work is classified into two kinds: one is for idiom types and the other is for idiom tokens. With the former, phrases that can be interpreted as idioms are found in text corpora, typically for lexicographers to compile idiom dictionaries. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Baldwin et al., 2003; Shudo et al., 2004). However, there has been a growing interest in idiom token identification recently (Katz and Giesbrecht, 2006; Hashimoto et al., 2006; Cook et al., 2007). Our work elaborated in section 4 is also an attempt in this regard. Despite the recent enthusiasm for multiword expressions, the idiom token identification is in an early stage of its development. Given that many language teaching and learning tasks like TCFL have been developed as a result of the availability of language resources, idiom token identification should also be developed when adequate </context>
</contexts>
<marker>Lin, 1999</marker>
<rawString>Lin, Dekang. 1999. Automatic Identification of Noncompositional Phrases. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics on Computational Linguistics: pp.317-324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wing Huen Lo</author>
</authors>
<date>1997</date>
<journal>Best Chinese Idioms</journal>
<volume>3</volume>
<publisher>Hai Feng Publishing Co.,</publisher>
<location>Hong Kong, China.</location>
<contexts>
<context position="6527" citStr="Lo, 1997" startWordPosition="1016" endWordPosition="1017">rks on the letters in a Pinyin are for the five tones of Chinese characters. carried by the few characters, as Chinese idioms are often closely related with the fable, story or historical account from which they were originally born. As their constructs remain stable through history, Chinese idioms do not follow the usual lexical pattern and syntax of modern Chinese language which has been reformed many a time. They are instead highly compact and resemble more ancient Chinese language in many linguistic features. Usually a Chinese idiom reflects the moral behind the story that it is derived. (Lo, 1997) For example, the idiom &amp;quot; 6*VE &amp;quot; (pò fǔ chén zhōu) literally means &amp;quot;smash the cauldrons and sink the boats.&amp;quot; It was based on a historical story where General Xiang Yu in Qin Dynasty (221 B. C. – 207 B. C.) ordered his army to destroy all cooking utensils and boats after they crossed a river into the enemy’s territory. He and his men won the battle for their &amp;quot;life or death&amp;quot; courage and &amp;quot;no-retreat&amp;quot; policy. Although there are similar phrases in English, such as &amp;quot;burning bridges&amp;quot; or &amp;quot;crossing the Rubicon&amp;quot;, this particular idiom cannot be used in a losing scenario because the story behind it does </context>
</contexts>
<marker>Lo, 1997</marker>
<rawString>Lo, Wing Huen. 1997. Best Chinese Idioms (Vol. 3). Hai Feng Publishing Co., Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom McArthur</author>
</authors>
<title>The Oxford Companion to the English Language.</title>
<date>1992</date>
<publisher>Oxford University Press,</publisher>
<location>Oxford, UK.</location>
<contexts>
<context position="1275" citStr="McArthur, 1992" startWordPosition="194" endWordPosition="195">ed composition like an idiom function so as to affect its semantic or grammatical properties. As an important Chinese language resource, our idiom knowledge base will play a major role in applications such as linguistic research, teaching Chinese as a foreign language and even as a tool for preserving this non-material Chinese cultural and historical heritage. 1 Introduction An idiom is a multi-word expression that has a figurative meaning that is comprehended in regard to a common use of that expression that is separate from the literal meaning or definition of the words of which it is made (McArthur, 1992). From a linguistic perspective, idioms are usually presumed to be figures of speech that are contradictory to the principle of compositionality. The words that construct an idiom no longer keep their original meaning or popular sense, while in the process of its formation it develops a specialized meaning as an entity whose sense is different from the literal meanings of the constituent elements. Although an idiom is an expression not readily analyzable from its grammatical structure or from the meaning of its component Shiwen Yu Key Laboratory of Computational Linguistics of Ministry of Educ</context>
</contexts>
<marker>McArthur, 1992</marker>
<rawString>McArthur, Tom. 1992. The Oxford Companion to the English Language. Oxford University Press, Oxford, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics:</booktitle>
<pages>271--278</pages>
<marker>Pang, Lee, 2004</marker>
<rawString>Pang, Bo and Lillian Lee. 2004. A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics: pp.271-278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumb up? Sentiment Classification Using Machine Learning Techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing:</booktitle>
<pages>79--86</pages>
<contexts>
<context position="14928" citStr="Pang et al., 2002" startWordPosition="2379" endWordPosition="2382">iom token identification is in an early stage of its development. Given that many language teaching and learning tasks like TCFL have been developed as a result of the availability of language resources, idiom token identification should also be developed when adequate idiom resources are provided. To this end, we have constructed the CIKB and hope to find applications of value, for example, emotion classification, event classification and text analysis based on idiom usage and its context. According to the granularity of text, emotion analysis of texts can be divided into three levels: text (Pang et al., 2002; Cui et al., 2006), sentence (Pang et al., 2004), word (Hatzivassiloglou et al., 1997; Wiebe 2000). According to the sources of emotion prediction, classification methods can be divided into knowledge based methods and machine learning based methods. The former uses lexicons or knowledge bases to build a new lexicon that contains emotion words. WordNet is often used to compute the emotion prediction of words (Hatzivassiloglou et al., 1997; Andrea 2005). Meanwhile, incorporating knowledge into the machine learning architecture as features is a popular trend and untagged copra are often used to</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Pang, Bo, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumb up? Sentiment Classification Using Machine Learning Techniques. In Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing: pp.79-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kosho Shudo</author>
<author>Toshifumi Tanabe</author>
<author>Masahito Takahashi</author>
<author>Kenji Yoshimura</author>
</authors>
<title>MWEs as Nonpropositional Content Indicators.</title>
<date>2004</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: Integrating Processing:</booktitle>
<pages>32--39</pages>
<contexts>
<context position="14024" citStr="Shudo et al., 2004" startWordPosition="2236" endWordPosition="2239">ucted a corpus of English idiomatic expressions with automatic method. They selected 50 expressions and collected about 6,600 examples. They call the corpus TroFi Example Base, which is available on the Web. As far as idiom identification is concerned, the work is classified into two kinds: one is for idiom types and the other is for idiom tokens. With the former, phrases that can be interpreted as idioms are found in text corpora, typically for lexicographers to compile idiom dictionaries. Previous studies have mostly focused on the idiom type identification (Lin, 1999; Baldwin et al., 2003; Shudo et al., 2004). However, there has been a growing interest in idiom token identification recently (Katz and Giesbrecht, 2006; Hashimoto et al., 2006; Cook et al., 2007). Our work elaborated in section 4 is also an attempt in this regard. Despite the recent enthusiasm for multiword expressions, the idiom token identification is in an early stage of its development. Given that many language teaching and learning tasks like TCFL have been developed as a result of the availability of language resources, idiom token identification should also be developed when adequate idiom resources are provided. To this end, </context>
</contexts>
<marker>Shudo, Tanabe, Takahashi, Yoshimura, 2004</marker>
<rawString>Shudo, Kosho, Toshifumi Tanabe, Masahito Takahashi, and Kenji Yoshimura. 2004. MWEs as Nonpropositional Content Indicators. In Proceedings of the Workshop on Multiword Expressions: Integrating Processing: pp.32-39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumps Up or Thumps Down? Semantic Orientation Applied to Unsupervised Classification of Reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics:</booktitle>
<pages>417--424</pages>
<marker>Turney, 2002</marker>
<rawString>Turney, Peter D. 2002. Thumps Up or Thumps Down? Semantic Orientation Applied to Unsupervised Classification of Reviews. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics: pp.417-424.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Lei Wang</author>
</authors>
<title>Forthcoming 2010. 1,000 Idioms for Chinese Learners.</title>
<publisher>Peking University Press,</publisher>
<location>Beijing, China.</location>
<marker>Wang, </marker>
<rawString>Wang, Lei. Forthcoming 2010. 1,000 Idioms for Chinese Learners. Peking University Press, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
</authors>
<title>Learning Subjective Adjectives from Corpora.</title>
<date>2000</date>
<booktitle>In Proceedings of the Seventeenth National Conference on Artificial Intelligence and Twelfth Conference on Innovative Applications of Artificial Intelligence:</booktitle>
<pages>735--740</pages>
<contexts>
<context position="15027" citStr="Wiebe 2000" startWordPosition="2397" endWordPosition="2398">earning tasks like TCFL have been developed as a result of the availability of language resources, idiom token identification should also be developed when adequate idiom resources are provided. To this end, we have constructed the CIKB and hope to find applications of value, for example, emotion classification, event classification and text analysis based on idiom usage and its context. According to the granularity of text, emotion analysis of texts can be divided into three levels: text (Pang et al., 2002; Cui et al., 2006), sentence (Pang et al., 2004), word (Hatzivassiloglou et al., 1997; Wiebe 2000). According to the sources of emotion prediction, classification methods can be divided into knowledge based methods and machine learning based methods. The former uses lexicons or knowledge bases to build a new lexicon that contains emotion words. WordNet is often used to compute the emotion prediction of words (Hatzivassiloglou et al., 1997; Andrea 2005). Meanwhile, incorporating knowledge into the machine learning architecture as features is a popular trend and untagged copra are often used to do emotion classification research (Turney et al., 2002; Akkaya et al., 2009). 14 4 An NLP Applica</context>
</contexts>
<marker>Wiebe, 2000</marker>
<rawString>Wiebe, Janyce. 2000. Learning Subjective Adjectives from Corpora. In Proceedings of the Seventeenth National Conference on Artificial Intelligence and Twelfth Conference on Innovative Applications of Artificial Intelligence: pp.735-740.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huaping Zhang</author>
<author>Yu Hongkui</author>
<author>Xiong Deyi</author>
<author>Liu Qun</author>
</authors>
<title>HHMM-based Chinese Lexical Analyzer ICTCLAS.</title>
<date>2003</date>
<booktitle>In Proceedings of the Second SIGHAN Workshop on Chinese Language Processing:</booktitle>
<pages>184--187</pages>
<contexts>
<context position="17295" citStr="Zhang et al., 2003" startWordPosition="2749" endWordPosition="2752">classification method to predict emotions in idioms. LIBLINEAR (Fan et al., 2008), a library for large SVM linear classification, is used for implementation. The solver is set be L2-loss SVM dual. Parameter C is set to be 2-5. Three classes of features and their various combinations are examined and used, including Chinese characters, words and part-of-speeches. Detailed features and related abbreviations are shown as in Table 4. Because Chinese sentences are written in a consecutive string of characters, we need to segment a sentence into individual words to obtain the word feature. ICTCLAS (Zhang et al., 2003), a tool developed by the Institute of Computing Technology of Chinese Academy of Sciences (ICT), is used for word segmentation and part-of-speech tagging. We adopt precision, recall and F-score (13=1) as the evaluation parameters. From Table 5 we can see that i_cb has a better performance than i_cu, which indicates that a bigram model usually performs better than a unigram model. But when we segment the idioms and use i_wu, we find that the performance gets bad. This may be because the compositionality of Chinese idioms is quite fossilized and the errors caused by segmentation introduce some </context>
</contexts>
<marker>Zhang, Hongkui, Deyi, Qun, 2003</marker>
<rawString>Zhang, Huaping, Yu Hongkui, Xiong Deyi, Liu Qun. 2003. HHMM-based Chinese Lexical Analyzer ICTCLAS. In Proceedings of the Second SIGHAN Workshop on Chinese Language Processing: pp.184-187.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>