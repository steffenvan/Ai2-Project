<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000114">
<title confidence="0.982599">
Associative Descriptions and Salience: A Preliminary Investigation
</title>
<author confidence="0.996766">
Massimo Poesio
</author>
<affiliation confidence="0.999555">
Department of Computer Science, University of Essex
</affiliation>
<email confidence="0.978753">
poesio@essex.ac.uk
</email>
<sectionHeader confidence="0.997209" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99985325">
We discuss the problems involved in
identifying and annotating bridging de-
scriptions in corpora of English, and
present results concerning the correla-
tion between bridging descriptions and
Centering obtained using a reliably an-
notated corpus and automatic focus-
tracking methods.
</bodyText>
<sectionHeader confidence="0.993324" genericHeader="categories and subject descriptors">
1 Introduction and Motivations
</sectionHeader>
<bodyText confidence="0.9998133">
In previous work (Poesio et al., 1997; Poesio and
Vieira, 1998; Poesio et al., 1998; Vieira and Poe-
sio, 2000; Poesio et al., 2002a) we studied the
use of BRIDGING REFERENCES (Clark, 1977) and
other types of definite descriptions in corpora of
English, and developed methods for identifying
their ANCHOR1 exclusively based on lexical in-
formation and simple window-based segmentation
methods. Three questions for future research were
identified in that work:
</bodyText>
<listItem confidence="0.981554363636364">
1. When the full range of bridging references
identified by Clark is considered, subjects
have serious difficulty agreeing on bridging
references, and are only able to identify very
few (Poesio and Vieira, 1998);
2. Even large lexical resources such as Word-
Net (Fellbaum, 1998) do not contain all the
necessary information for resolving Bridging
Descriptions (Bps) even if only those Bps
that rely on the type of relations found in
WordNet such as hyponymy, synonymy, or
</listItem>
<bodyText confidence="0.983641825">
I We borrow the term anchor from Fraurud (1990) to indi-
cate the discourse entity with which the bridging reference is
&apos;associated&apos; - reserving &apos;antecedent&apos; for identity anaphora.
meronymy (e.g., the window I a house) are
considered. In almost 40% of the cases, no
semantic relation could be found between
such bridging references and their anchor
(Poesio et al., 1997; Vieira and Poesio, 2000);
3. Even when a lexical resource did contain in-
formation about the existence of a relation
between a bridging description and its an-
chor (30% of the total with WordNet), sim-
ply choosing as anchor the entity which is
semantically closer to the BD in the chosen
window leads to very poor results. In about
half of the cases, a competing discourse en-
tity was semantically closer than the actual
anchor. We concluded that the resolution
of a bridging description does not depend
only on lexical information, but also involves
other information—perhaps, about which enti-
ties are most salient, either in the basic sense
of being more recent, or perhaps by being the
&apos;focus&apos;, as already claimed by Sidner (1979).
We addressed the second of these problems by de-
veloping methods for automatically acquiring the
lexical information needed to resolve (a subset of)
Bps (Poesio et al., 1998; Poesio et al., 2002a). In
parallel with that effort, we have been develop-
ing reliable methods for annotating bridging ref-
erences, and created a corpus which can be be
used to study them with greater accuracy (Poe-
sio, 2000). We have also been developing auto-
matic methods for tracking the &apos;focus&apos; of a dis-
course in the sense of Centering Theory (Grosz
et al., 1995; Walker et al., 1998) which allow us
to compare the many existing definitions of no-
tions such as &apos;utterance&apos;, &apos;ranking,&apos; Backward-
Looking Center,&apos; etc., identifying those that re-
sulted in fewer violations of the theory&apos;s claims
</bodyText>
<page confidence="0.999722">
31
</page>
<bodyText confidence="0.9916055625">
(Poesio et al., 2000; Poesio et al., 2002b). In the
work reported here, we exploited our corpus and
these focus-tracking techniques to study the cor-
relation between &apos;salience&apos; and bridging reference
resolution, focusing on ASSOCIATIVE DESCRIP-
TIONS (Aps)—i.e., bridging references realized as
the-NPs, related to their anchor by a relation other
than identity (Hawkins, 1978). The structure of
this paper is as follows. In section 2, we discuss
the corpus used in this study, how it was anno-
tated, and the methods used to track the CB in
this corpus. In section 3, we present our results
concerning the correlation between bridging ref-
erences and salience. Finally, in section 4, we
present preliminary findings concerning the use of
lexical semantics as a filter.
</bodyText>
<sectionHeader confidence="0.991168" genericHeader="method">
2 Methods
</sectionHeader>
<bodyText confidence="0.9999605">
One of the main motivations for this work is that
we felt that we could improve upon our previous
results by exploiting the results of our other work
on referring expressions in general and of salience
(Poesio et al., 2000; Poesio, 2000). As a result
of this work we had at our disposal the GNOME
corpus whose NPs, and the anaphoric relations be-
tween them, had been marked in a reliable way
(Poesio, 2000). In this section we briefly discuss
the corpus and how it was annotated.
</bodyText>
<subsectionHeader confidence="0.947782">
2.1 The Corpus
</subsectionHeader>
<bodyText confidence="0.9995149">
The GNOME corpus (Poesio, 2000) includes texts
from three domains, two of which were used in
this study. The museum subcorpus consists of de-
scriptions of museum objects and brief texts about
the artists that produced them.2 The pharmaceu-
tical subcorpus is a selection of leaflets provid-
ing the patients with mandatory information about
their medicine.3 Each subcorpus contains about
6,000 NPs; in this study we used texts from the
first two domains, for a total of about 3,000 NPS,
</bodyText>
<footnote confidence="0.992740555555556">
2The museum subcorpus extends the corpus collected to
support the ILEX and SOLE projects at the University of Edin-
burgh. ILEX generates Web pages describing museum objects
(Oberlander et al., 1998) The SOLE project extended ILEX
with concept-to-speech abilities (Hitzeman et al., 1998).
3The leafets in the pharmaceutical subcorpus are a sub-
set of the collection of all patient leafhts in the UK , digi-
tized to support the ICONOCLAST project at the University of
Brighton (Scott et al., 1998).
</footnote>
<bodyText confidence="0.9984374">
about 600 of which are definite descriptions. Of
the potential candidates for &apos;utterances&apos;, the cor-
pus includes about 500 sentences, and 900 finite
clauses; the actual number of utterances used in
the study is one of the parameters that we varied.
</bodyText>
<subsectionHeader confidence="0.996011">
2.2 Annotation
</subsectionHeader>
<bodyText confidence="0.989433">
Motivations The marking scheme used in (Poe-
sio and Vieira, 1998) wasn&apos;t completely satisfac-
tory. For one thing, our method for annotating
bridging references didn&apos;t guarantee agreement.
Secondly, although our work had revealed that
many definite NPS could simultaneously belong to
two classes - e.g., be directly anaphoric on one
entity, while bridging on another one—our scheme
wouldn&apos;t allow our annotators to mark this infor-
mation. Finally, we didn&apos;t have a way for mark-
ing genuinely ambiguous cases. These problems
were avoided by the marking schemes developed
for the GNOME and MATE projects. The following
example from the GNOME corpus illustrates how
anaphoric expressions may be related to more than
one anchor in sometimes complex ways:
</bodyText>
<listItem confidence="0.963605916666667">
(1) a. Each coffer also has a lid that opens in
two sections.
b. The upper lid reveals a shallow compart-
ment,
c. while the main lid lifts to reveal the inte-
rior of the coffer.
d. The 1689 inventory of the Grand
Dauphin, the oldest son of Louis XIV,
lists a jewel coffer of similar form and
decoration;
e. according to this inventory, André-
Charles Boulle made the coffer.
</listItem>
<bodyText confidence="0.989870333333334">
f. The two stands are of the same date as
the coffers, but were originally designed
to hold rectangular cabinets.
Notice, first of all, that both the upper lid in (lb)
and the main lid in (1c) are related to both each
coffer and a lid in (la). Determining the exact re-
lation is made more difficult by the fact that these
are examples of so-called telescoping—when an
anaphoric expression appears to be &apos;in the scope&apos;
of a quantified expression even though that scope
should have been &apos;closed off&apos; by the end of the
sentence—but the relation with the coffer is almost
</bodyText>
<page confidence="0.998607">
32
</page>
<bodyText confidence="0.999164">
certainly a PART-OF relation, whereas the rela-
tion with the lid as a whole may be viewed either
as PART-OF or perhaps SET-ELEMENT. Next,
notice the coffers
Basics The GNOME corpus was annotated
according to a systematic manual, available
from the GNOME project&apos;s home page at
http: //www.hcrc . ed. ac .uk/ - gnome.
The annotation scheme derives from the MATE
scheme (Poesio et al., 1999). Only the most
important details of the scheme will be discussed.
All sentences in the GNOME corpus are marked
as elements of type (s). In addition, all units of
text in the corpus that might be identified with ut-
terances (in the Centering sense) are marked as
(unit) elements. Each NP is marked with a (ne)
tag and with a variety of attributes capturing syn-
tactic and semantic properties.
</bodyText>
<subsectionHeader confidence="0.752258">
Marking Bridging References and other
</subsectionHeader>
<bodyText confidence="0.999716151515151">
Anaphors The problem with bridging refer-
ences is that many NPs evoke discourse entities
that are related to other discourse entities, without
truly establishing a &apos;bridge&apos; with the rest of the
discourse. An obvious example of this are NPs
indicating the possessor in a possessive NP, such
as the definite description the Sun King in the
Sun King&apos;s possessions. Clearly, the discourse
entity denoted by the Sun King is semantically
related to the discourse entity denoted by the
possessive NP; yet it&apos;s also clear that this NP
does not establish a link to previous discourse.
(Furthermore, identifying the anchor of this NP
is not a problem.) In order to be consistent
about what we classified as &apos;bridging reference&apos;,
we developed, first of all, methods for marking
both identity and associative semantic relations;
secondly, and simplifying matters somewhat, we
only classified as bridging references the NPs
related by (non-identity) semantic relations with
discourse entities last mentioned in the previous
utterance (in the sense of Centering, see below).
In the MATE / GNOME scheme, anaphoric rela-
tions are not marked using attributes of the (ne)
element, as in the muc scheme and most other
schemes, but using a separate (ante) element.
The (ante) element itself specifies the index
of the anaphoric expression and the type of se-
mantic relation (e.g., identity), whereas one or
more embedded (anchor) elements indicate pos-
sible antecedents (the presence of more than one
(anchor) element indicates that the anaphoric
expression is ambiguous). (See (2).)
</bodyText>
<figure confidence="0.748245117647059">
(2) &lt;unit finite=&apos;finite-yes&apos;&gt;
&lt;ne id=&apos;ne546&apos; gf=&apos;subj&apos;&gt;
The drawing of
&lt;ne id=&apos;ne547&apos; gf=&apos;np-compl&apos;&gt;
the corner cupboard, &lt;/ne&gt;&lt;/ne&gt;
&lt;unit finite=&apos;no-finite&apos;&gt;
or more probably
&lt;ne id=&apos;ne548&apos; gf=&apos;no-gf&apos;&gt;
an engraving of
&lt;ne id=&apos;ne549&apos; gf=&apos;np-compl&apos;&gt;
it
&lt;/ne&gt;&lt;/ne&gt;
&lt;/unit&gt;,
&lt;/unit&gt;
&lt;ante current=&amp;quot;ne549&amp;quot; rel=&amp;quot;ident&amp;quot;›
&lt;anchor ID=&amp;quot;ne547&amp;quot;›
&lt;/ante&gt;
</figure>
<bodyText confidence="0.999793655172414">
Separating the (ante) element from the (ne) ele-
ment makes it possible to mark an NP both as core-
ferring with one entity, and bridging on a second
one, if necessary: this can be done by specifying
two separate (ante) elements. It is also possi-
ble to mark ambiguous anaphoric expressions, by
specifying more than one (anchor) element.
Previous work, particularly in the context of the
muc initiative, suggested that while it&apos;s fairly easy
to achieve agreement on identity relations, mark-
ing up bridging references is quite hard. This was
confirmed In our own previous work, in which
we found that our subjects only agreed on about
5% of bridging descriptions (Poesio and Vieira,
1998). We addressed this problem by limiting the
types of relations annotators are supposed to mark
up, and by specifying priorities. Our annotators
only annotated four types of relations, a subset of
those proposed in the &apos;extended relations&apos; version
of the MATE scheme (Poesio et al., 1999): iden-
tity (IDENT), set membership (ELEMENT), subset
(SUBSET), and &apos;generalized possession&apos; (P OS 5),
which also includes part-of relations. In addi-
tion, we asked our annotators to use a special tag
OTHER to mark up semantic relations between an
anaphoric expression and an entity introduced by
an NP in a previous clause or layout element, when
such relation existed and no other semantic rela-
tion between the (unit) in which the NP occurred
</bodyText>
<page confidence="0.995177">
33
</page>
<bodyText confidence="0.988495162790698">
and previous units had been identified.
As expected, we obtained a rather good agree-
ment on identity relations. In our most recent anal-
ysis (two annotators looking at the anaphoric rela-
tions between 200 NPs) we observed no real dis-
agreements; 79.4% of these relations were marked
up by both annotators; 12.8% by only one of them;
and in 7.7% of the cases, one of the annotators
marked up a closer antecedent than the other. For
bridging references, only 4.8% relations were now
marked differently; on the other hand, only 22% of
bridging references were marked in the same way
by both annotators. In other words, although our
current scheme does limit the disagreements on
antecedents and relations, we still find that 73.17%
of relations are marked by only one annotator.
2.3 Automatic tracking of focus according to
Centering theory
The notion of &apos;topic&apos; or &apos;discourse focus&apos; has of-
ten been claimed to play an important role in
the interpretation and production of anaphoric ex-
pressions, including bridging references (Grosz,
1977; Sidner, 1979; Sanford and Garrod, 1981;
McKeown, 1986; Grosz et al., 1995; Dale, 1992;
Walker et al., 1998), but it is notoriously difficult
to pin down. Sidner (1979) developed detailed
algorithms implementing her claim (and Grosz&apos;s
(Grosz, 1977)) that the interpretation of bridging
references depend on focusing information. Her
proposals however rely heavily on commonsense
knowledge, and for this reason have never been
extensively evaluated.4
As the basis for the work reported here, we used
the terminology and ideas introduced in what is
currently the best-known formalization of the idea
of topic in Computational Linguistics, Centering
Theory (Grosz et al., 1995; Walker et al., 1998), in
particular the notions of Backward-Looking Cen-
ter (cB) and Preferred Center (cP). In the &apos;main-
stream&apos; version of Centering (Grosz et al., 1995),
it is assumed that each UTTERANCE introduces
new discourse entities (or Forward-Looking Cen-
ters) into the discourse, and in so doing, updates
</bodyText>
<footnote confidence="0.7568952">
4Carter (1987) actually implemented a system with the
necessary commonsense knowledge to test Sidner&apos;s theory,
but given that all the necessary knowledge had to be provided
by hand, the system was only tested on a restricted —although
not small—number of examples.
</footnote>
<bodyText confidence="0.99987365">
the &apos;local focus&apos;. It is further assumed that the dis-
course entities introduced (or better, REALIZED)
by an utterance are ranked; the most highly ranked
entity in an utterance is called the CP. The CB is
Centering&apos;s equivalent of the notion of &apos;topic&apos; or
&apos;focus&apos;, and is defined as follows:
CB cB(Ui), the BACKWARD-LOOKING CENTER
of utterance Ui, is the highest ranked element
of cP(Ui_i) that is realized in U.
Centering provides no definition of the notions
of &apos;ranking&apos;, &apos;utterance&apos; and &apos;realization&apos;; re-
searchers using the theory have to specify their
own. In previous work, we did a comparative
analysis of the many existing proposals concern-
ing Centering Theory&apos;s parameters (Poesio et al.,
2000; Poesio et al., 2002b). The GNOME corpus,
annotated as discussed above, was used to auto-
matically compute &apos;utterances&apos; according to dif-
ferent definitions proposed in the literature, and
then to compute the cPs and the CB (if any) of each
utterance on the basis of the anaphoric information
and according to different views of ranking. This
information was the used to find violations of the
main claims of the theory.
One of our results was that two ways of specify-
ing the parameters of the theory gave the best (and
pretty much equivalent) results, in the sense that
it led to the fewest violations of the main claims
of the theory. Both of these involved identify-
ing utterances with sentences, and allowing for in-
direct realization of the CB; but they differed in
the ranking function. In one case, grammatical
function was used (subjects rank more highly than
objects that rank more highly than adjuncts) aug-
mented with a linear disambiguation factor; in the
other, Strube and Hahn&apos;s (1999) ranking function
based on &apos;information status,&apos; according to which
hearer-old entities are ranked more highly than in-
ferrables, which in turn are ranked more highly
than hearer-new entities (Prince, 1992).
</bodyText>
<sectionHeader confidence="0.958774" genericHeader="method">
3 Salience and Bridging Reference
</sectionHeader>
<bodyText confidence="0.9999332">
The annotated corpus and the focus tracking
scripts discussed above were used to investigate
the extent to which the interpretation of BDS de-
pended on the salience of potential anchors. In
this section we discuss our main findings.
</bodyText>
<page confidence="0.993865">
34
</page>
<subsectionHeader confidence="0.753782">
3.1 Bridging descriptions in the GNOME
corpus
</subsectionHeader>
<bodyText confidence="0.9970188">
A total of 2073 semantic relations are marked up
in the GNOME corpus. These can be classified
as follows, where IDENT is identity, and POSS-
NPs are the relations between the possessor and
the possessee in a possessive NP:
</bodyText>
<table confidence="0.9235138">
Type of relation Number
IDENT 1164
POSS-NPs 328
SUBSET, ELEMENT, POSS, OTHER 581
Total 2073
</table>
<bodyText confidence="0.999044555555555">
Several types of NPS can be used to introduce
objects related to previous discourse entities by the
type of &apos;associative&apos; relations usually involved in
bridging reference: definite descriptions, posses-
sive NPs, demonstratives, and even quantifiers. Of
the 581 &apos;other&apos; relations in the previous table, 194
are expressed by definite descriptions; 169 definite
descriptions in total enter into such relations.5 If
we identify utterances with sentences, 110 of these
associative description have their anchor in utter-
ances preceding the current one (henceforth, U-1),
and could thus be classified as &apos;bridging&apos; under
the simplified definition used here. If utterances
are identified with finite clauses, we have instead
128 Bps. The statistics concerning the distance
between an associative description and its closest
anchor, with sentences as utterances, can be sum-
marized as follows:
</bodyText>
<figure confidence="0.369106714285714">
Distance Number of BDs whose
anchor is that far
0 (same utterance) 59
1 72
2 20
3-5 (total) 11
6 or more 7
</figure>
<bodyText confidence="0.984441333333333">
(Notice that 95.8% of the anchors are found in the
same utterance or the previous 5, confirming the
results of (Poesio and Vieira, 1998).)
</bodyText>
<subsectionHeader confidence="0.999976">
3.2 Bridging descriptions and recency
</subsectionHeader>
<bodyText confidence="0.96179864">
The simplest hypothesis concerning BD resolution
is that their anchors are identified searching first
in the previous utterance, then in the utterance be-
fore that, etc.—i.e., following the search strategy
first proposed in (Winograd, 1972; Hobbs, 1978;
5As discussed above, an anaphoric expression may be se-
mantically related to more than one discourse entity.
Sidner, 1979). Utterances may be searched left-
to-right or right-to-left (&apos;most recent first&apos;).
In our corpus, 68% (49 / 72) of associative de-
scriptions whose anchor is in the previous sen-
tence have the first-mentioned entity (henceforth,
Fm(S-1)) as their anchor, and 44.5% of the to-
tal. Of the ADS whose anchor is in the current
or previous clause, 64% have as anchor the first-
mentioned element of the previous clause. By con-
strast, for only 15% (11 / 72) of Bps whose anchor
is in S-1, this anchor is the last-mentioned entity in
S-1. These figures confirm the preference for first-
mention over recency often observed in the litera-
ture (Gernsbacher and Hargreaves, 1988; Gordon
et al., 1993). In fact, even entities in second and
third position are significantly more preferred than
those in last position (23.6%, 17 / 72). These fig-
ures are summarized by the following table:
</bodyText>
<table confidence="0.940934666666667">
Position of anchor Number of ADs whose
anchor is in that position
1 49
2-3 17
last 11
Total 72
</table>
<bodyText confidence="0.998977428571429">
In other words, if you have perfect knowledge
about which definite description is bridging, but
don&apos;t know anything else, choosing as anchor of a
BD FM(U-1) will give you 44.5% accuracy. This
may not seem much, but it&apos;s better than the results
obtained with either of the strategies of choosing
the anchor on the basis of lexical closeness that we
tried in the past, looking for the closest sense in
WordNet, which resulted in a 39% accuracy (Poe-
sio et al., 1997), and looking for the closest ele-
ment in a vectorial space (Poesio et al., 1998), with
an accuracy of 22.2%. To do better than that, ad-
ditional information is needed to evaluate the sug-
gestions made by the search strategy.
</bodyText>
<subsectionHeader confidence="0.999945">
3.3 Bridging descriptions and focusing
</subsectionHeader>
<bodyText confidence="0.999974888888889">
A more complex hypothesis concerning the search
for the anchor of a BD is that it involves infor-
mation about which entities are in focus (Sidner,
1979). Using Centering terminology, and ignor-
ing direct anaphors and more complex cases, Sid-
ner&apos;s algorithm (more precisely, her &apos;Associated
Specification&apos;, &apos;Inferred Specification,&apos; and &apos;Set-
Element Specification&apos; rules) could be reformu-
lated as follows ((Sidner, 1979), p. 123-124):
</bodyText>
<page confidence="0.995916">
35
</page>
<listItem confidence="0.999652333333333">
1. Try first as anchor CB(U-1) (or cP(U-1));
2. If that fails, try all other CFS in ranking order;
3. If that&apos;s not acceptable, try the stacked foci.
</listItem>
<bodyText confidence="0.99989905">
If we identify utterances with sentences and we
use Strube and Hahn&apos;s ranking function, then
CB(U-1) is the anchor of 37 out of the 72 BDS
whose anchor is in the previous utterance (51.3%),
and 33.6% overall (37 / 110). Virtually identical
results are obtained if grammatical function (+ a
linear disambiguation function) is used for rank-
ing. The results are slightly better when the CP is
considered, and with Strube-Hahn ranking. 38.2%
of BDS have cP(U-1) as their anchor (58% of those
whose anchor is in U- ). (With grammatical func-
tion ranking, only 22 Bps have cP(U-1) as their
anchor.) The results are also unchanged if finite
clauses are used instead of sentences: 40 out of
119 BDs, 33.6%, have CB(11-1) as their anchor,
and 42 out of 119 have cP(U-1). Clearly, simply
choosing the CB (or the cP) as the anchor doesn&apos;t
work very well, although choosing the CP would
give slightly better results. These results are sum-
marized (for sentences) by the following table:
</bodyText>
<table confidence="0.988999714285714">
Focusing status Number ADs Overall perc. Perc. S-1
CB(S-1) 37 33.6% 51.3%
CP(S-1) 42 38.2% 58%
CB(S.) or CP(S&apos;), 93 84.5%
for some S&apos;
CB(S) 70 63.6%
Total 110 100% 100%
</table>
<bodyText confidence="0.999039909090909">
Clearly, simply choosing as anchor the CB or CP of
the previous sentence or finite clause doesn&apos;t work
very well - not even as well as choosing Pm(S-1).
An example of AD whose anchor is neither CB(S-
1) nor cP(S-1) is (If): the anchor of the AD the two
stands is the coffers, whereas the CB and CP of S-
1 is the inventory. The following is an example in
which focusing information helps: the anchor of
the AD the central door is this monumental cabi-
net, which is both the CB and the CP of (3a) (only
with Strube-Hahn ranking):
</bodyText>
<listItem confidence="0.7785856">
(3) a. The decoration on this monumental cabi-
net refers to the French king Louis XIV&apos;s
military victories.
b. A panel of marquetry showing the cock-
erel of France standing triumphant over
</listItem>
<bodyText confidence="0.89494972972973">
both the eagle of the Holy Roman Em-
pire and the lion of Spain and the Spanish
Netherlands decorates the central door.
One bit of information coming from focusing,
however, appears to be very useful. With sen-
tences as utterances, and either Strube / Hahn or
grammatical function ranking, 98 out of 110 an-
chors of associative descriptions, 89%, are entities
that have previously been CB or CP. The results
are similar if we identify utterances with finite
clauses: in this case, 106 out of 119 anchors, 89%
again, were previously CBS (the percentage for cPs
is still high, but significantly lower, 82.3%). An
example of AD whose anchor is an entity which
serves as the CB or CP of a sentence other than S-1
is again the two stands in (10. In fact, close anal-
ysis of the 12 cases in which the anchor never was
either a CB nor a CP reveals that in virtually all
cases the annotation was rather difficult, and there
are only two clear cases of AD whose anchor had
never before been either a CB or a CP—the skin and
the treated area in (4).
(4) a. Side effects may occur when PRODUCT-
X is applied to large areas of the body,
and for long periods of time (more than
4 weeks), especially if waterproof dress-
ings are used.
b. These include. thinning of the skin on or
around the treated area.
Clearly, limiting the search to past CBs, even if fol-
lowing a simpler recency order, would pay off.
To conclude, simply knowing CB(U-1) or CP(U-
1) is not even as useful by itself as knowing Pm(U-
1), but limiting the search to previous CBS might
be very useful, provided that ways are found of
&apos;checking&apos; that the proposed solution is plausible,
as hypothesized by Sidner.
</bodyText>
<sectionHeader confidence="0.7950645" genericHeader="method">
4 Filtering using lexical knowledge:
preliminary investigations
</sectionHeader>
<bodyText confidence="0.999970111111111">
Although the results above are not terribly impres-
sive, what Sidner (1979) actually proposed is that
anaphors, including bridging references, are re-
solved by a two-stage process whereby first hy-
potheses are suggested on the basis of focusing
information, and then commonsense inference is
used to accept or reject these hypotheses. In this
section we briefly consider how easy such a filter-
ing strategy would be to implement.
</bodyText>
<page confidence="0.994908">
36
</page>
<subsectionHeader confidence="0.997086">
4.1 Using WordNet
</subsectionHeader>
<bodyText confidence="0.995102802631579">
Our earlier results suggested that implementing
Sidner&apos;s filter is not going to be too easy if all
we have is WordNet (Poesio et al., 1997; Vieira
and Poesio, 2000); preliminary studies with the
GNOME corpus confirm this finding. The 110
definite descriptions with an associative interpre-
tation and that are truly &apos;bridging&apos; to a previous
utterance enter into a total of 97 ELEMENT,
SUBSET, or POSS relations with an anchor in one
of the previous utterances. (Often, with more than
one.) We ran a script attempting to find a direct
lexical connection in WordNet between any one
of the senses of the BD and any one of the senses
of the potential anchors in the previous utterances.
The script follows the search algorithm discussed
above: it starts from the most recent utterance and
goes backwards; in each utterance, it considers
the cFs left-to-right, following the order found
to be best in the tests discussed above; and it
stops when it finds a direct link All of the part-of
relations encoded in WordNet (PART MERONYM,
MEMBER MERONYM, SUBSTANCE MERONYM,
PART HOLONYM, MEMBER HOLONYM, and
SUBSTANCE HOLONYM) are considered as
possible links. The results are very bad: in only 6
cases the script found a direct lexical connection;
and none of these 6 CFS was a plausible anchor
for the BD.
Can these results be improved by simply adopt-
ing a more extended search strategy? We think that
this is unlikely. Consider the following example:
(5) a. This table&apos;s marquetry of ivory and horn,
painted blue underneath, would have fol-
lowed the house&apos;s blue-and-white color
scheme, imitating blue-and-white Chi-
nese porcelain, a fashionable and highly
prized material.
b. Blue-and-white ceramic tiles decorated
the house, and some of the furniture was
also painted blue-and-white.
The anchor for the BD the furniture is clearly one
of the mentions of the house. The problem is that
there is no link at all in WordNet between house
and furniture: the only objects mentioned as parts
of houses are their structural parts, such as rooms
or walls. A preliminary study of the 110 ADs in
our corpus indicates that a more complex may be
found in about 30-40% of the cases. This sug-
gests limits the improvements that we can expect
from more sophisticated mechanisms for search-
ing WordNet. In fact, in our earlier work using a
more complex search strategy, in less than 25% of
the cases a path between a meronymic AD and the
intended anchor could be found.
4.2 Using lexical information acquired from
corpora
On the other hand, our earlier studies already
revealed, first of all, that information about
meronymy is perhaps the weakest aspect of Word-
Net&apos;s lexical base; and second, that this is one
aspect of lexical knowledge where construction-
based lexical acquisition methods offer the oppor-
tunity of significantly increased precision / recall
((Poesio et al., 2002a) report a 66.7% recall and
72.7% precision for this class). We tested this
by a very crude strategy—given an AD with head
noun N and a possible anchor with head noun N&apos;,
call Google with the pattern the N of the N&apos;. The
results are remarkably good: at least 50 hits are
found for all AD-anchor pairs in the examples in
this paper, with the exception of the pair stand-
coffer in (10; and in all of the other examples, the
correct solution is found by considering as candi-
date antecedents cB(S-1), cF(S-1), and Fm(S-1),
and choosing the one whose head noun results in
the highest number of hits.
</bodyText>
<sectionHeader confidence="0.999327" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999909666666667">
The first conclusion of this study is that even if
we have near-perfect knowledge about focus, the
first-mentioned entity of U-1 is still significanly
more likely to be the anchor of a bridging descrip-
tion than CB (U-1). However, focusing information
might still be useful provided that we found effec-
tive ways of filtering away implausible anchors,
since 84.5% of anchors were previously CBS. Cur-
rent versions of WordNet at least don&apos;t provide
enough information for this filtering task, con-
firming previous results by ourselves and others
(Gaizauskas et al., 1995); but corpus-based meth-
ods for acquiring information about meronymy
such as those discussed in (Poesio et al., 2002a)
(and other recent work) appear very promising.
</bodyText>
<page confidence="0.997993">
37
</page>
<bodyText confidence="0.752279333333333">
M. Poesio and R. Vieira. 1998. A corpus-based investiga-
tion of defi nite description use. Computational Linguis-
tics, 24(2):183-216, June.
</bodyText>
<note confidence="0.6930046">
References
D. M. Carter. 1987. Interpreting Anaphors in Natural Lan-
guage Texts. Ellis Horwood, Chichester, UK.
E. Charniak. 1986. A neat theory of marker passing. In
Proceedings of the Fifth AAAI, pages 584-588.
</note>
<reference confidence="0.999902043010753">
H. H. Clark. 1977. Bridging. In P. N. Johnson-Laird and P.C.
Wason, editors, Thinking: Readings in Cognitive Science.
Cambridge University Press, London and New York.
R. Dale. 1992. Generating Referring Expressions. The MIT
Press, Cambridge, MA.
C. Fellbaum, editor. 1998. WordNet: An electronic lexical
database. The MIT Press.
K. Fraurud. 1990. Definiteness and the processing of NPs in
natural discourse. Journal of Semantics, 7:395-433.
R. Gaizauskas, T. Wakao, K. Humphreys, H. Cunningham,
and Y. Wilks. 1995. University of Sheffi eld: description
of the LaSIE System as used for MUC-6. In Proceedings
of the Sixth Message Understanding Conference (MUC-
6), pages 207-220. Morgan Kauffmann.
M. A. Gernsbacher and D. Hargreaves. 1988. Accessing sen-
tence participants: The advantage of fi rst mention. Jour-
nal of Memory and Language, 27:699-717.
P. C. Gordon, B. J. Grosz, and L. A. Gillion. 1993. Pro-
nouns, names, and the centering of attention in discourse.
Cognitive Science, 17:311-348.
B. J. Grosz, A. K. Joshi, and S. Weinstein. 1995. Center-
ing: A framework for modeling the local coherence of
discourse. Computational Linguistics, 21(2):202-225.
B. J. Grosz. 1977. The Representation and Use of Focus in
Dialogue Understanding. Ph.D. thesis, Stanford.
J. A. Hawkins. 1978. Definiteness and Indefiniteness.
Croom Helm, London.
J. Hitzeman, A. Black, P. Taylor, C. Mellish, and J. Ober-
lander. 1998. On the use of automatically generated
discourse-level information in a concept-to-speech syn-
thesis system. In (ICSLP98)„ Paper 591, Australia.
J. R. Hobbs. 1978. Resolving pronoun references. Lingua,
44:311-338.
K. R. McKeown. 1986. Discourse strategies for generating
natural language text. In B. J. Grosz, K. Sparck Jones, and
B. Lynn Webber, editors, Readings in Natural Language
Processing, pages 479-500. Morgan Kaufmann, Los Al-
tos, CA.
P. Norvig. 1989. Marker passing as a weak method for infer-
encing. Cognitive Science, 13(4):569-620.
J. Oberlander, M. O&apos;Donnell, A. Knott, and C. Mellish.
1998. Conversation in the museum: Experiments in dy-
namic hypermedia with the intelligent labelling explorer.
New Review of Hypermedia and Multimedia, 4:11-32.
M. Poesio, R. Vieira, and S. Teufel. 1997. Resolving bridg-
ing references in unrestricted text. In R. Mitkov, editor,
Proc. of the ACL Workshop on Operational Factors in Ro-
bust Anaphora Resolution, pages 1-6, Madrid.
M. Poesio, S. Schulte im Walde, and C. Brew. 1998. Lexical
clustering and defi nite description interpretation. In Proc.
of the AAAI Spring Symposium on Learning for Discourse,
pages 82-89, Stanford, CA, March. AAAI.
M. Poesio, F. Bruneseaux, and L. Romary. 1999. The MATE
meta-scheme for coreference in dialogues in multiple lan-
guages. In M. Walker, editor, Proc. of the ACL Workshop
on Discourse Tagging, pages 65-74.
M. Poesio, H. Cheng, R. Henschel, J. M. Hitzeman, R. Kib-
ble, and R. Stevenson. 2000. Specifying the parameters of
Centering Theory. In Proc. of the 38th ACL, Hong Kong,
October.
M. Poesio, T. Ishikawa, S. Schulte im Walde, and R. Vieira.
2002a. Acquiring lexical knowledge for anaphora resolu-
tion. In Proc. of the 3rd LREC, Las Palmas, Canaria.
M. Poesio, R. Stevenson, H. Cheng, B. Di Eugenio, and J. M.
Hitzeman. 2002b. A corpus-based evaluation of centering
theory. NLE-TN 01, University of Essex, Department of
Computer Science, April. Submitted for publication.
M. Poesio. 2000. Annotating a corpus to develop and evalu-
ate discourse entity realization algorithms: issues and pre-
liminary results. In Proc. of the 2nd LREC, pages 211-
218, Athens, May.
E. F. Prince. 1992. The ZPG letter: subjects, definiteness,
and information status. In S. Thompson and W. Mann,
editors, Discourse description: diverse analyses of a fund-
raising text, pages 295-325. John Benjamins.
A. J. Sanford and S. C. Garrod. 1981. Understanding Written
Language. Wiley, Chichester.
D. Scott, R. Power, and R. Evans. 1998. Generation as a so-
lution to its own problem. In Proc. of the 9th International
Workshop on Natural Language Generation.
C. L. Sidner. 1979. Towards a computational theory of defi-
nite anaphora comprehension in English discourse. Ph.D.
thesis, MIT.
M. Strube and U. Hahn. 1999. Functional centering-
grounding referential coherence in information structure.
Computational Linguistics, 25(3):309-344.
R. Vieira and M. Poesio. 2000. An empirically-based sys-
tem for processing defi nite descriptions. Computational
Linguistics, 26(4), December.
M. A. Walker, A. K. Joshi, and E. F. Prince, editors. 1998.
Centering Theory in Discourse. Clarendon Press / Oxford.
Terry Winograd. 1972. Understanding Natural Language.
Academic Press.
</reference>
<page confidence="0.999351">
38
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.926236">
<title confidence="0.999951">Associative Descriptions and Salience: A Preliminary Investigation</title>
<author confidence="0.999919">Massimo Poesio</author>
<affiliation confidence="0.997292">Department of Computer Science, University of</affiliation>
<email confidence="0.968439">poesio@essex.ac.uk</email>
<abstract confidence="0.995122555555556">We discuss the problems involved in identifying and annotating bridging descriptions in corpora of English, and present results concerning the correlation between bridging descriptions and Centering obtained using a reliably annotated corpus and automatic focustracking methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H H Clark</author>
</authors>
<date>1977</date>
<booktitle>Thinking: Readings in Cognitive Science.</booktitle>
<editor>Bridging. In P. N. Johnson-Laird and P.C. Wason, editors,</editor>
<publisher>Cambridge University Press,</publisher>
<location>London and New York.</location>
<contexts>
<context position="659" citStr="Clark, 1977" startWordPosition="93" endWordPosition="94">inary Investigation Massimo Poesio Department of Computer Science, University of Essex poesio@essex.ac.uk Abstract We discuss the problems involved in identifying and annotating bridging descriptions in corpora of English, and present results concerning the correlation between bridging descriptions and Centering obtained using a reliably annotated corpus and automatic focustracking methods. 1 Introduction and Motivations In previous work (Poesio et al., 1997; Poesio and Vieira, 1998; Poesio et al., 1998; Vieira and Poesio, 2000; Poesio et al., 2002a) we studied the use of BRIDGING REFERENCES (Clark, 1977) and other types of definite descriptions in corpora of English, and developed methods for identifying their ANCHOR1 exclusively based on lexical information and simple window-based segmentation methods. Three questions for future research were identified in that work: 1. When the full range of bridging references identified by Clark is considered, subjects have serious difficulty agreeing on bridging references, and are only able to identify very few (Poesio and Vieira, 1998); 2. Even large lexical resources such as WordNet (Fellbaum, 1998) do not contain all the necessary information for res</context>
</contexts>
<marker>Clark, 1977</marker>
<rawString>H. H. Clark. 1977. Bridging. In P. N. Johnson-Laird and P.C. Wason, editors, Thinking: Readings in Cognitive Science. Cambridge University Press, London and New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
</authors>
<title>Generating Referring Expressions.</title>
<date>1992</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="12719" citStr="Dale, 1992" startWordPosition="2075" endWordPosition="2076">r hand, only 22% of bridging references were marked in the same way by both annotators. In other words, although our current scheme does limit the disagreements on antecedents and relations, we still find that 73.17% of relations are marked by only one annotator. 2.3 Automatic tracking of focus according to Centering theory The notion of &apos;topic&apos; or &apos;discourse focus&apos; has often been claimed to play an important role in the interpretation and production of anaphoric expressions, including bridging references (Grosz, 1977; Sidner, 1979; Sanford and Garrod, 1981; McKeown, 1986; Grosz et al., 1995; Dale, 1992; Walker et al., 1998), but it is notoriously difficult to pin down. Sidner (1979) developed detailed algorithms implementing her claim (and Grosz&apos;s (Grosz, 1977)) that the interpretation of bridging references depend on focusing information. Her proposals however rely heavily on commonsense knowledge, and for this reason have never been extensively evaluated.4 As the basis for the work reported here, we used the terminology and ideas introduced in what is currently the best-known formalization of the idea of topic in Computational Linguistics, Centering Theory (Grosz et al., 1995; Walker et a</context>
</contexts>
<marker>Dale, 1992</marker>
<rawString>R. Dale. 1992. Generating Referring Expressions. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An electronic lexical database.</title>
<date>1998</date>
<editor>C. Fellbaum, editor.</editor>
<publisher>The MIT Press.</publisher>
<marker>1998</marker>
<rawString>C. Fellbaum, editor. 1998. WordNet: An electronic lexical database. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Fraurud</author>
</authors>
<title>Definiteness and the processing of NPs in natural discourse.</title>
<date>1990</date>
<journal>Journal of Semantics,</journal>
<pages>7--395</pages>
<contexts>
<context position="1447" citStr="Fraurud (1990)" startWordPosition="216" endWordPosition="217">w-based segmentation methods. Three questions for future research were identified in that work: 1. When the full range of bridging references identified by Clark is considered, subjects have serious difficulty agreeing on bridging references, and are only able to identify very few (Poesio and Vieira, 1998); 2. Even large lexical resources such as WordNet (Fellbaum, 1998) do not contain all the necessary information for resolving Bridging Descriptions (Bps) even if only those Bps that rely on the type of relations found in WordNet such as hyponymy, synonymy, or I We borrow the term anchor from Fraurud (1990) to indicate the discourse entity with which the bridging reference is &apos;associated&apos; - reserving &apos;antecedent&apos; for identity anaphora. meronymy (e.g., the window I a house) are considered. In almost 40% of the cases, no semantic relation could be found between such bridging references and their anchor (Poesio et al., 1997; Vieira and Poesio, 2000); 3. Even when a lexical resource did contain information about the existence of a relation between a bridging description and its anchor (30% of the total with WordNet), simply choosing as anchor the entity which is semantically closer to the BD in the </context>
</contexts>
<marker>Fraurud, 1990</marker>
<rawString>K. Fraurud. 1990. Definiteness and the processing of NPs in natural discourse. Journal of Semantics, 7:395-433.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gaizauskas</author>
<author>T Wakao</author>
<author>K Humphreys</author>
<author>H Cunningham</author>
<author>Y Wilks</author>
</authors>
<title>University of Sheffi eld: description of the LaSIE System as used for MUC-6.</title>
<date>1995</date>
<booktitle>In Proceedings of the Sixth Message Understanding Conference (MUC6),</booktitle>
<pages>207--220</pages>
<publisher>Morgan Kauffmann.</publisher>
<marker>Gaizauskas, Wakao, Humphreys, Cunningham, Wilks, 1995</marker>
<rawString>R. Gaizauskas, T. Wakao, K. Humphreys, H. Cunningham, and Y. Wilks. 1995. University of Sheffi eld: description of the LaSIE System as used for MUC-6. In Proceedings of the Sixth Message Understanding Conference (MUC6), pages 207-220. Morgan Kauffmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Gernsbacher</author>
<author>D Hargreaves</author>
</authors>
<title>Accessing sentence participants: The advantage of fi rst mention.</title>
<date>1988</date>
<journal>Journal of Memory and Language,</journal>
<pages>27--699</pages>
<contexts>
<context position="18613" citStr="Gernsbacher and Hargreaves, 1988" startWordPosition="3021" endWordPosition="3024">hed leftto-right or right-to-left (&apos;most recent first&apos;). In our corpus, 68% (49 / 72) of associative descriptions whose anchor is in the previous sentence have the first-mentioned entity (henceforth, Fm(S-1)) as their anchor, and 44.5% of the total. Of the ADS whose anchor is in the current or previous clause, 64% have as anchor the firstmentioned element of the previous clause. By constrast, for only 15% (11 / 72) of Bps whose anchor is in S-1, this anchor is the last-mentioned entity in S-1. These figures confirm the preference for firstmention over recency often observed in the literature (Gernsbacher and Hargreaves, 1988; Gordon et al., 1993). In fact, even entities in second and third position are significantly more preferred than those in last position (23.6%, 17 / 72). These figures are summarized by the following table: Position of anchor Number of ADs whose anchor is in that position 1 49 2-3 17 last 11 Total 72 In other words, if you have perfect knowledge about which definite description is bridging, but don&apos;t know anything else, choosing as anchor of a BD FM(U-1) will give you 44.5% accuracy. This may not seem much, but it&apos;s better than the results obtained with either of the strategies of choosing th</context>
</contexts>
<marker>Gernsbacher, Hargreaves, 1988</marker>
<rawString>M. A. Gernsbacher and D. Hargreaves. 1988. Accessing sentence participants: The advantage of fi rst mention. Journal of Memory and Language, 27:699-717.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P C Gordon</author>
<author>B J Grosz</author>
<author>L A Gillion</author>
</authors>
<title>Pronouns, names, and the centering of attention in discourse.</title>
<date>1993</date>
<journal>Cognitive Science,</journal>
<pages>17--311</pages>
<contexts>
<context position="18635" citStr="Gordon et al., 1993" startWordPosition="3025" endWordPosition="3028">(&apos;most recent first&apos;). In our corpus, 68% (49 / 72) of associative descriptions whose anchor is in the previous sentence have the first-mentioned entity (henceforth, Fm(S-1)) as their anchor, and 44.5% of the total. Of the ADS whose anchor is in the current or previous clause, 64% have as anchor the firstmentioned element of the previous clause. By constrast, for only 15% (11 / 72) of Bps whose anchor is in S-1, this anchor is the last-mentioned entity in S-1. These figures confirm the preference for firstmention over recency often observed in the literature (Gernsbacher and Hargreaves, 1988; Gordon et al., 1993). In fact, even entities in second and third position are significantly more preferred than those in last position (23.6%, 17 / 72). These figures are summarized by the following table: Position of anchor Number of ADs whose anchor is in that position 1 49 2-3 17 last 11 Total 72 In other words, if you have perfect knowledge about which definite description is bridging, but don&apos;t know anything else, choosing as anchor of a BD FM(U-1) will give you 44.5% accuracy. This may not seem much, but it&apos;s better than the results obtained with either of the strategies of choosing the anchor on the basis </context>
</contexts>
<marker>Gordon, Grosz, Gillion, 1993</marker>
<rawString>P. C. Gordon, B. J. Grosz, and L. A. Gillion. 1993. Pronouns, names, and the centering of attention in discourse. Cognitive Science, 17:311-348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>A K Joshi</author>
<author>S Weinstein</author>
</authors>
<title>Centering: A framework for modeling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--2</pages>
<contexts>
<context position="3037" citStr="Grosz et al., 1995" startWordPosition="482" endWordPosition="485">re recent, or perhaps by being the &apos;focus&apos;, as already claimed by Sidner (1979). We addressed the second of these problems by developing methods for automatically acquiring the lexical information needed to resolve (a subset of) Bps (Poesio et al., 1998; Poesio et al., 2002a). In parallel with that effort, we have been developing reliable methods for annotating bridging references, and created a corpus which can be be used to study them with greater accuracy (Poesio, 2000). We have also been developing automatic methods for tracking the &apos;focus&apos; of a discourse in the sense of Centering Theory (Grosz et al., 1995; Walker et al., 1998) which allow us to compare the many existing definitions of notions such as &apos;utterance&apos;, &apos;ranking,&apos; BackwardLooking Center,&apos; etc., identifying those that resulted in fewer violations of the theory&apos;s claims 31 (Poesio et al., 2000; Poesio et al., 2002b). In the work reported here, we exploited our corpus and these focus-tracking techniques to study the correlation between &apos;salience&apos; and bridging reference resolution, focusing on ASSOCIATIVE DESCRIPTIONS (Aps)—i.e., bridging references realized as the-NPs, related to their anchor by a relation other than identity (Hawkins, </context>
<context position="12707" citStr="Grosz et al., 1995" startWordPosition="2071" endWordPosition="2074">erently; on the other hand, only 22% of bridging references were marked in the same way by both annotators. In other words, although our current scheme does limit the disagreements on antecedents and relations, we still find that 73.17% of relations are marked by only one annotator. 2.3 Automatic tracking of focus according to Centering theory The notion of &apos;topic&apos; or &apos;discourse focus&apos; has often been claimed to play an important role in the interpretation and production of anaphoric expressions, including bridging references (Grosz, 1977; Sidner, 1979; Sanford and Garrod, 1981; McKeown, 1986; Grosz et al., 1995; Dale, 1992; Walker et al., 1998), but it is notoriously difficult to pin down. Sidner (1979) developed detailed algorithms implementing her claim (and Grosz&apos;s (Grosz, 1977)) that the interpretation of bridging references depend on focusing information. Her proposals however rely heavily on commonsense knowledge, and for this reason have never been extensively evaluated.4 As the basis for the work reported here, we used the terminology and ideas introduced in what is currently the best-known formalization of the idea of topic in Computational Linguistics, Centering Theory (Grosz et al., 1995;</context>
</contexts>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>B. J. Grosz, A. K. Joshi, and S. Weinstein. 1995. Centering: A framework for modeling the local coherence of discourse. Computational Linguistics, 21(2):202-225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
</authors>
<title>The Representation and Use of Focus</title>
<date>1977</date>
<booktitle>in Dialogue Understanding. Ph.D. thesis,</booktitle>
<location>Stanford.</location>
<contexts>
<context position="12632" citStr="Grosz, 1977" startWordPosition="2061" endWordPosition="2062">r. For bridging references, only 4.8% relations were now marked differently; on the other hand, only 22% of bridging references were marked in the same way by both annotators. In other words, although our current scheme does limit the disagreements on antecedents and relations, we still find that 73.17% of relations are marked by only one annotator. 2.3 Automatic tracking of focus according to Centering theory The notion of &apos;topic&apos; or &apos;discourse focus&apos; has often been claimed to play an important role in the interpretation and production of anaphoric expressions, including bridging references (Grosz, 1977; Sidner, 1979; Sanford and Garrod, 1981; McKeown, 1986; Grosz et al., 1995; Dale, 1992; Walker et al., 1998), but it is notoriously difficult to pin down. Sidner (1979) developed detailed algorithms implementing her claim (and Grosz&apos;s (Grosz, 1977)) that the interpretation of bridging references depend on focusing information. Her proposals however rely heavily on commonsense knowledge, and for this reason have never been extensively evaluated.4 As the basis for the work reported here, we used the terminology and ideas introduced in what is currently the best-known formalization of the idea o</context>
</contexts>
<marker>Grosz, 1977</marker>
<rawString>B. J. Grosz. 1977. The Representation and Use of Focus in Dialogue Understanding. Ph.D. thesis, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Hawkins</author>
</authors>
<title>Definiteness and Indefiniteness.</title>
<date>1978</date>
<location>Croom Helm, London.</location>
<contexts>
<context position="3642" citStr="Hawkins, 1978" startWordPosition="576" endWordPosition="577">al., 1995; Walker et al., 1998) which allow us to compare the many existing definitions of notions such as &apos;utterance&apos;, &apos;ranking,&apos; BackwardLooking Center,&apos; etc., identifying those that resulted in fewer violations of the theory&apos;s claims 31 (Poesio et al., 2000; Poesio et al., 2002b). In the work reported here, we exploited our corpus and these focus-tracking techniques to study the correlation between &apos;salience&apos; and bridging reference resolution, focusing on ASSOCIATIVE DESCRIPTIONS (Aps)—i.e., bridging references realized as the-NPs, related to their anchor by a relation other than identity (Hawkins, 1978). The structure of this paper is as follows. In section 2, we discuss the corpus used in this study, how it was annotated, and the methods used to track the CB in this corpus. In section 3, we present our results concerning the correlation between bridging references and salience. Finally, in section 4, we present preliminary findings concerning the use of lexical semantics as a filter. 2 Methods One of the main motivations for this work is that we felt that we could improve upon our previous results by exploiting the results of our other work on referring expressions in general and of salienc</context>
</contexts>
<marker>Hawkins, 1978</marker>
<rawString>J. A. Hawkins. 1978. Definiteness and Indefiniteness. Croom Helm, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hitzeman</author>
<author>A Black</author>
<author>P Taylor</author>
<author>C Mellish</author>
<author>J Oberlander</author>
</authors>
<title>On the use of automatically generated discourse-level information in a concept-to-speech synthesis system.</title>
<date>1998</date>
<booktitle>In (ICSLP98)„ Paper 591,</booktitle>
<contexts>
<context position="5303" citStr="Hitzeman et al., 1998" startWordPosition="857" endWordPosition="860">tions of museum objects and brief texts about the artists that produced them.2 The pharmaceutical subcorpus is a selection of leaflets providing the patients with mandatory information about their medicine.3 Each subcorpus contains about 6,000 NPs; in this study we used texts from the first two domains, for a total of about 3,000 NPS, 2The museum subcorpus extends the corpus collected to support the ILEX and SOLE projects at the University of Edinburgh. ILEX generates Web pages describing museum objects (Oberlander et al., 1998) The SOLE project extended ILEX with concept-to-speech abilities (Hitzeman et al., 1998). 3The leafets in the pharmaceutical subcorpus are a subset of the collection of all patient leafhts in the UK , digitized to support the ICONOCLAST project at the University of Brighton (Scott et al., 1998). about 600 of which are definite descriptions. Of the potential candidates for &apos;utterances&apos;, the corpus includes about 500 sentences, and 900 finite clauses; the actual number of utterances used in the study is one of the parameters that we varied. 2.2 Annotation Motivations The marking scheme used in (Poesio and Vieira, 1998) wasn&apos;t completely satisfactory. For one thing, our method for a</context>
</contexts>
<marker>Hitzeman, Black, Taylor, Mellish, Oberlander, 1998</marker>
<rawString>J. Hitzeman, A. Black, P. Taylor, C. Mellish, and J. Oberlander. 1998. On the use of automatically generated discourse-level information in a concept-to-speech synthesis system. In (ICSLP98)„ Paper 591, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Hobbs</author>
</authors>
<title>Resolving pronoun references.</title>
<date>1978</date>
<journal>Lingua,</journal>
<pages>44--311</pages>
<contexts>
<context position="17833" citStr="Hobbs, 1978" startWordPosition="2891" endWordPosition="2892">closest anchor, with sentences as utterances, can be summarized as follows: Distance Number of BDs whose anchor is that far 0 (same utterance) 59 1 72 2 20 3-5 (total) 11 6 or more 7 (Notice that 95.8% of the anchors are found in the same utterance or the previous 5, confirming the results of (Poesio and Vieira, 1998).) 3.2 Bridging descriptions and recency The simplest hypothesis concerning BD resolution is that their anchors are identified searching first in the previous utterance, then in the utterance before that, etc.—i.e., following the search strategy first proposed in (Winograd, 1972; Hobbs, 1978; 5As discussed above, an anaphoric expression may be semantically related to more than one discourse entity. Sidner, 1979). Utterances may be searched leftto-right or right-to-left (&apos;most recent first&apos;). In our corpus, 68% (49 / 72) of associative descriptions whose anchor is in the previous sentence have the first-mentioned entity (henceforth, Fm(S-1)) as their anchor, and 44.5% of the total. Of the ADS whose anchor is in the current or previous clause, 64% have as anchor the firstmentioned element of the previous clause. By constrast, for only 15% (11 / 72) of Bps whose anchor is in S-1, th</context>
</contexts>
<marker>Hobbs, 1978</marker>
<rawString>J. R. Hobbs. 1978. Resolving pronoun references. Lingua, 44:311-338.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K R McKeown</author>
</authors>
<title>Discourse strategies for generating natural language text.</title>
<date>1986</date>
<booktitle>Readings in Natural Language Processing,</booktitle>
<pages>479--500</pages>
<editor>In B. J. Grosz, K. Sparck Jones, and B. Lynn Webber, editors,</editor>
<publisher>Morgan Kaufmann,</publisher>
<location>Los Altos, CA.</location>
<contexts>
<context position="12687" citStr="McKeown, 1986" startWordPosition="2069" endWordPosition="2070">now marked differently; on the other hand, only 22% of bridging references were marked in the same way by both annotators. In other words, although our current scheme does limit the disagreements on antecedents and relations, we still find that 73.17% of relations are marked by only one annotator. 2.3 Automatic tracking of focus according to Centering theory The notion of &apos;topic&apos; or &apos;discourse focus&apos; has often been claimed to play an important role in the interpretation and production of anaphoric expressions, including bridging references (Grosz, 1977; Sidner, 1979; Sanford and Garrod, 1981; McKeown, 1986; Grosz et al., 1995; Dale, 1992; Walker et al., 1998), but it is notoriously difficult to pin down. Sidner (1979) developed detailed algorithms implementing her claim (and Grosz&apos;s (Grosz, 1977)) that the interpretation of bridging references depend on focusing information. Her proposals however rely heavily on commonsense knowledge, and for this reason have never been extensively evaluated.4 As the basis for the work reported here, we used the terminology and ideas introduced in what is currently the best-known formalization of the idea of topic in Computational Linguistics, Centering Theory </context>
</contexts>
<marker>McKeown, 1986</marker>
<rawString>K. R. McKeown. 1986. Discourse strategies for generating natural language text. In B. J. Grosz, K. Sparck Jones, and B. Lynn Webber, editors, Readings in Natural Language Processing, pages 479-500. Morgan Kaufmann, Los Altos, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Norvig</author>
</authors>
<title>Marker passing as a weak method for inferencing.</title>
<date>1989</date>
<journal>Cognitive Science,</journal>
<pages>13--4</pages>
<marker>Norvig, 1989</marker>
<rawString>P. Norvig. 1989. Marker passing as a weak method for inferencing. Cognitive Science, 13(4):569-620.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Oberlander</author>
<author>M O&apos;Donnell</author>
<author>A Knott</author>
<author>C Mellish</author>
</authors>
<title>Conversation in the museum: Experiments in dynamic hypermedia with the intelligent labelling explorer. New Review of Hypermedia and Multimedia,</title>
<date>1998</date>
<pages>4--11</pages>
<contexts>
<context position="5215" citStr="Oberlander et al., 1998" startWordPosition="845" endWordPosition="848">ee domains, two of which were used in this study. The museum subcorpus consists of descriptions of museum objects and brief texts about the artists that produced them.2 The pharmaceutical subcorpus is a selection of leaflets providing the patients with mandatory information about their medicine.3 Each subcorpus contains about 6,000 NPs; in this study we used texts from the first two domains, for a total of about 3,000 NPS, 2The museum subcorpus extends the corpus collected to support the ILEX and SOLE projects at the University of Edinburgh. ILEX generates Web pages describing museum objects (Oberlander et al., 1998) The SOLE project extended ILEX with concept-to-speech abilities (Hitzeman et al., 1998). 3The leafets in the pharmaceutical subcorpus are a subset of the collection of all patient leafhts in the UK , digitized to support the ICONOCLAST project at the University of Brighton (Scott et al., 1998). about 600 of which are definite descriptions. Of the potential candidates for &apos;utterances&apos;, the corpus includes about 500 sentences, and 900 finite clauses; the actual number of utterances used in the study is one of the parameters that we varied. 2.2 Annotation Motivations The marking scheme used in (</context>
</contexts>
<marker>Oberlander, O&apos;Donnell, Knott, Mellish, 1998</marker>
<rawString>J. Oberlander, M. O&apos;Donnell, A. Knott, and C. Mellish. 1998. Conversation in the museum: Experiments in dynamic hypermedia with the intelligent labelling explorer. New Review of Hypermedia and Multimedia, 4:11-32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>R Vieira</author>
<author>S Teufel</author>
</authors>
<title>Resolving bridging references in unrestricted text.</title>
<date>1997</date>
<booktitle>Proc. of the ACL Workshop on Operational Factors in Robust Anaphora Resolution,</booktitle>
<pages>1--6</pages>
<editor>In R. Mitkov, editor,</editor>
<location>Madrid.</location>
<contexts>
<context position="1767" citStr="Poesio et al., 1997" startWordPosition="265" endWordPosition="268">n large lexical resources such as WordNet (Fellbaum, 1998) do not contain all the necessary information for resolving Bridging Descriptions (Bps) even if only those Bps that rely on the type of relations found in WordNet such as hyponymy, synonymy, or I We borrow the term anchor from Fraurud (1990) to indicate the discourse entity with which the bridging reference is &apos;associated&apos; - reserving &apos;antecedent&apos; for identity anaphora. meronymy (e.g., the window I a house) are considered. In almost 40% of the cases, no semantic relation could be found between such bridging references and their anchor (Poesio et al., 1997; Vieira and Poesio, 2000); 3. Even when a lexical resource did contain information about the existence of a relation between a bridging description and its anchor (30% of the total with WordNet), simply choosing as anchor the entity which is semantically closer to the BD in the chosen window leads to very poor results. In about half of the cases, a competing discourse entity was semantically closer than the actual anchor. We concluded that the resolution of a bridging description does not depend only on lexical information, but also involves other information—perhaps, about which entities are</context>
<context position="19379" citStr="Poesio et al., 1997" startWordPosition="3157" endWordPosition="3161">7 / 72). These figures are summarized by the following table: Position of anchor Number of ADs whose anchor is in that position 1 49 2-3 17 last 11 Total 72 In other words, if you have perfect knowledge about which definite description is bridging, but don&apos;t know anything else, choosing as anchor of a BD FM(U-1) will give you 44.5% accuracy. This may not seem much, but it&apos;s better than the results obtained with either of the strategies of choosing the anchor on the basis of lexical closeness that we tried in the past, looking for the closest sense in WordNet, which resulted in a 39% accuracy (Poesio et al., 1997), and looking for the closest element in a vectorial space (Poesio et al., 1998), with an accuracy of 22.2%. To do better than that, additional information is needed to evaluate the suggestions made by the search strategy. 3.3 Bridging descriptions and focusing A more complex hypothesis concerning the search for the anchor of a BD is that it involves information about which entities are in focus (Sidner, 1979). Using Centering terminology, and ignoring direct anaphors and more complex cases, Sidner&apos;s algorithm (more precisely, her &apos;Associated Specification&apos;, &apos;Inferred Specification,&apos; and &apos;SetE</context>
<context position="24379" citStr="Poesio et al., 1997" startWordPosition="4036" endWordPosition="4039">ledge: preliminary investigations Although the results above are not terribly impressive, what Sidner (1979) actually proposed is that anaphors, including bridging references, are resolved by a two-stage process whereby first hypotheses are suggested on the basis of focusing information, and then commonsense inference is used to accept or reject these hypotheses. In this section we briefly consider how easy such a filtering strategy would be to implement. 36 4.1 Using WordNet Our earlier results suggested that implementing Sidner&apos;s filter is not going to be too easy if all we have is WordNet (Poesio et al., 1997; Vieira and Poesio, 2000); preliminary studies with the GNOME corpus confirm this finding. The 110 definite descriptions with an associative interpretation and that are truly &apos;bridging&apos; to a previous utterance enter into a total of 97 ELEMENT, SUBSET, or POSS relations with an anchor in one of the previous utterances. (Often, with more than one.) We ran a script attempting to find a direct lexical connection in WordNet between any one of the senses of the BD and any one of the senses of the potential anchors in the previous utterances. The script follows the search algorithm discussed above: </context>
</contexts>
<marker>Poesio, Vieira, Teufel, 1997</marker>
<rawString>M. Poesio, R. Vieira, and S. Teufel. 1997. Resolving bridging references in unrestricted text. In R. Mitkov, editor, Proc. of the ACL Workshop on Operational Factors in Robust Anaphora Resolution, pages 1-6, Madrid.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>S Schulte im Walde</author>
<author>C Brew</author>
</authors>
<title>Lexical clustering and defi nite description interpretation.</title>
<date>1998</date>
<booktitle>In Proc. of the AAAI Spring Symposium on Learning for Discourse,</booktitle>
<pages>82--89</pages>
<publisher>AAAI.</publisher>
<location>Stanford, CA,</location>
<contexts>
<context position="2672" citStr="Poesio et al., 1998" startWordPosition="417" endWordPosition="420"> window leads to very poor results. In about half of the cases, a competing discourse entity was semantically closer than the actual anchor. We concluded that the resolution of a bridging description does not depend only on lexical information, but also involves other information—perhaps, about which entities are most salient, either in the basic sense of being more recent, or perhaps by being the &apos;focus&apos;, as already claimed by Sidner (1979). We addressed the second of these problems by developing methods for automatically acquiring the lexical information needed to resolve (a subset of) Bps (Poesio et al., 1998; Poesio et al., 2002a). In parallel with that effort, we have been developing reliable methods for annotating bridging references, and created a corpus which can be be used to study them with greater accuracy (Poesio, 2000). We have also been developing automatic methods for tracking the &apos;focus&apos; of a discourse in the sense of Centering Theory (Grosz et al., 1995; Walker et al., 1998) which allow us to compare the many existing definitions of notions such as &apos;utterance&apos;, &apos;ranking,&apos; BackwardLooking Center,&apos; etc., identifying those that resulted in fewer violations of the theory&apos;s claims 31 (Poe</context>
<context position="19459" citStr="Poesio et al., 1998" startWordPosition="3173" endWordPosition="3176"> Number of ADs whose anchor is in that position 1 49 2-3 17 last 11 Total 72 In other words, if you have perfect knowledge about which definite description is bridging, but don&apos;t know anything else, choosing as anchor of a BD FM(U-1) will give you 44.5% accuracy. This may not seem much, but it&apos;s better than the results obtained with either of the strategies of choosing the anchor on the basis of lexical closeness that we tried in the past, looking for the closest sense in WordNet, which resulted in a 39% accuracy (Poesio et al., 1997), and looking for the closest element in a vectorial space (Poesio et al., 1998), with an accuracy of 22.2%. To do better than that, additional information is needed to evaluate the suggestions made by the search strategy. 3.3 Bridging descriptions and focusing A more complex hypothesis concerning the search for the anchor of a BD is that it involves information about which entities are in focus (Sidner, 1979). Using Centering terminology, and ignoring direct anaphors and more complex cases, Sidner&apos;s algorithm (more precisely, her &apos;Associated Specification&apos;, &apos;Inferred Specification,&apos; and &apos;SetElement Specification&apos; rules) could be reformulated as follows ((Sidner, 1979), p</context>
</contexts>
<marker>Poesio, Walde, Brew, 1998</marker>
<rawString>M. Poesio, S. Schulte im Walde, and C. Brew. 1998. Lexical clustering and defi nite description interpretation. In Proc. of the AAAI Spring Symposium on Learning for Discourse, pages 82-89, Stanford, CA, March. AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>F Bruneseaux</author>
<author>L Romary</author>
</authors>
<title>The MATE meta-scheme for coreference in dialogues in multiple languages.</title>
<date>1999</date>
<booktitle>Proc. of the ACL Workshop on Discourse Tagging,</booktitle>
<pages>65--74</pages>
<editor>In M. Walker, editor,</editor>
<contexts>
<context position="7852" citStr="Poesio et al., 1999" startWordPosition="1292" endWordPosition="1295">o-called telescoping—when an anaphoric expression appears to be &apos;in the scope&apos; of a quantified expression even though that scope should have been &apos;closed off&apos; by the end of the sentence—but the relation with the coffer is almost 32 certainly a PART-OF relation, whereas the relation with the lid as a whole may be viewed either as PART-OF or perhaps SET-ELEMENT. Next, notice the coffers Basics The GNOME corpus was annotated according to a systematic manual, available from the GNOME project&apos;s home page at http: //www.hcrc . ed. ac .uk/ - gnome. The annotation scheme derives from the MATE scheme (Poesio et al., 1999). Only the most important details of the scheme will be discussed. All sentences in the GNOME corpus are marked as elements of type (s). In addition, all units of text in the corpus that might be identified with utterances (in the Centering sense) are marked as (unit) elements. Each NP is marked with a (ne) tag and with a variety of attributes capturing syntactic and semantic properties. Marking Bridging References and other Anaphors The problem with bridging references is that many NPs evoke discourse entities that are related to other discourse entities, without truly establishing a &apos;bridge&apos;</context>
<context position="11154" citStr="Poesio et al., 1999" startWordPosition="1814" endWordPosition="1817">articularly in the context of the muc initiative, suggested that while it&apos;s fairly easy to achieve agreement on identity relations, marking up bridging references is quite hard. This was confirmed In our own previous work, in which we found that our subjects only agreed on about 5% of bridging descriptions (Poesio and Vieira, 1998). We addressed this problem by limiting the types of relations annotators are supposed to mark up, and by specifying priorities. Our annotators only annotated four types of relations, a subset of those proposed in the &apos;extended relations&apos; version of the MATE scheme (Poesio et al., 1999): identity (IDENT), set membership (ELEMENT), subset (SUBSET), and &apos;generalized possession&apos; (P OS 5), which also includes part-of relations. In addition, we asked our annotators to use a special tag OTHER to mark up semantic relations between an anaphoric expression and an entity introduced by an NP in a previous clause or layout element, when such relation existed and no other semantic relation between the (unit) in which the NP occurred 33 and previous units had been identified. As expected, we obtained a rather good agreement on identity relations. In our most recent analysis (two annotator</context>
</contexts>
<marker>Poesio, Bruneseaux, Romary, 1999</marker>
<rawString>M. Poesio, F. Bruneseaux, and L. Romary. 1999. The MATE meta-scheme for coreference in dialogues in multiple languages. In M. Walker, editor, Proc. of the ACL Workshop on Discourse Tagging, pages 65-74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>H Cheng</author>
<author>R Henschel</author>
<author>J M Hitzeman</author>
<author>R Kibble</author>
<author>R Stevenson</author>
</authors>
<title>Specifying the parameters of Centering Theory.</title>
<date>2000</date>
<booktitle>In Proc. of the 38th ACL,</booktitle>
<location>Hong Kong,</location>
<contexts>
<context position="3288" citStr="Poesio et al., 2000" startWordPosition="523" endWordPosition="526">998; Poesio et al., 2002a). In parallel with that effort, we have been developing reliable methods for annotating bridging references, and created a corpus which can be be used to study them with greater accuracy (Poesio, 2000). We have also been developing automatic methods for tracking the &apos;focus&apos; of a discourse in the sense of Centering Theory (Grosz et al., 1995; Walker et al., 1998) which allow us to compare the many existing definitions of notions such as &apos;utterance&apos;, &apos;ranking,&apos; BackwardLooking Center,&apos; etc., identifying those that resulted in fewer violations of the theory&apos;s claims 31 (Poesio et al., 2000; Poesio et al., 2002b). In the work reported here, we exploited our corpus and these focus-tracking techniques to study the correlation between &apos;salience&apos; and bridging reference resolution, focusing on ASSOCIATIVE DESCRIPTIONS (Aps)—i.e., bridging references realized as the-NPs, related to their anchor by a relation other than identity (Hawkins, 1978). The structure of this paper is as follows. In section 2, we discuss the corpus used in this study, how it was annotated, and the methods used to track the CB in this corpus. In section 3, we present our results concerning the correlation betwee</context>
<context position="14586" citStr="Poesio et al., 2000" startWordPosition="2365" endWordPosition="2368">r better, REALIZED) by an utterance are ranked; the most highly ranked entity in an utterance is called the CP. The CB is Centering&apos;s equivalent of the notion of &apos;topic&apos; or &apos;focus&apos;, and is defined as follows: CB cB(Ui), the BACKWARD-LOOKING CENTER of utterance Ui, is the highest ranked element of cP(Ui_i) that is realized in U. Centering provides no definition of the notions of &apos;ranking&apos;, &apos;utterance&apos; and &apos;realization&apos;; researchers using the theory have to specify their own. In previous work, we did a comparative analysis of the many existing proposals concerning Centering Theory&apos;s parameters (Poesio et al., 2000; Poesio et al., 2002b). The GNOME corpus, annotated as discussed above, was used to automatically compute &apos;utterances&apos; according to different definitions proposed in the literature, and then to compute the cPs and the CB (if any) of each utterance on the basis of the anaphoric information and according to different views of ranking. This information was the used to find violations of the main claims of the theory. One of our results was that two ways of specifying the parameters of the theory gave the best (and pretty much equivalent) results, in the sense that it led to the fewest violations</context>
</contexts>
<marker>Poesio, Cheng, Henschel, Hitzeman, Kibble, Stevenson, 2000</marker>
<rawString>M. Poesio, H. Cheng, R. Henschel, J. M. Hitzeman, R. Kibble, and R. Stevenson. 2000. Specifying the parameters of Centering Theory. In Proc. of the 38th ACL, Hong Kong, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>T Ishikawa</author>
<author>S Schulte im Walde</author>
<author>R Vieira</author>
</authors>
<title>Acquiring lexical knowledge for anaphora resolution.</title>
<date>2002</date>
<booktitle>In Proc. of the 3rd LREC,</booktitle>
<location>Las Palmas, Canaria.</location>
<contexts>
<context position="2693" citStr="Poesio et al., 2002" startWordPosition="421" endWordPosition="424"> poor results. In about half of the cases, a competing discourse entity was semantically closer than the actual anchor. We concluded that the resolution of a bridging description does not depend only on lexical information, but also involves other information—perhaps, about which entities are most salient, either in the basic sense of being more recent, or perhaps by being the &apos;focus&apos;, as already claimed by Sidner (1979). We addressed the second of these problems by developing methods for automatically acquiring the lexical information needed to resolve (a subset of) Bps (Poesio et al., 1998; Poesio et al., 2002a). In parallel with that effort, we have been developing reliable methods for annotating bridging references, and created a corpus which can be be used to study them with greater accuracy (Poesio, 2000). We have also been developing automatic methods for tracking the &apos;focus&apos; of a discourse in the sense of Centering Theory (Grosz et al., 1995; Walker et al., 1998) which allow us to compare the many existing definitions of notions such as &apos;utterance&apos;, &apos;ranking,&apos; BackwardLooking Center,&apos; etc., identifying those that resulted in fewer violations of the theory&apos;s claims 31 (Poesio et al., 2000; Poe</context>
<context position="14607" citStr="Poesio et al., 2002" startWordPosition="2369" endWordPosition="2372">y an utterance are ranked; the most highly ranked entity in an utterance is called the CP. The CB is Centering&apos;s equivalent of the notion of &apos;topic&apos; or &apos;focus&apos;, and is defined as follows: CB cB(Ui), the BACKWARD-LOOKING CENTER of utterance Ui, is the highest ranked element of cP(Ui_i) that is realized in U. Centering provides no definition of the notions of &apos;ranking&apos;, &apos;utterance&apos; and &apos;realization&apos;; researchers using the theory have to specify their own. In previous work, we did a comparative analysis of the many existing proposals concerning Centering Theory&apos;s parameters (Poesio et al., 2000; Poesio et al., 2002b). The GNOME corpus, annotated as discussed above, was used to automatically compute &apos;utterances&apos; according to different definitions proposed in the literature, and then to compute the cPs and the CB (if any) of each utterance on the basis of the anaphoric information and according to different views of ranking. This information was the used to find violations of the main claims of the theory. One of our results was that two ways of specifying the parameters of the theory gave the best (and pretty much equivalent) results, in the sense that it led to the fewest violations of the main claims o</context>
<context position="27091" citStr="Poesio et al., 2002" startWordPosition="4488" endWordPosition="4491">ticated mechanisms for searching WordNet. In fact, in our earlier work using a more complex search strategy, in less than 25% of the cases a path between a meronymic AD and the intended anchor could be found. 4.2 Using lexical information acquired from corpora On the other hand, our earlier studies already revealed, first of all, that information about meronymy is perhaps the weakest aspect of WordNet&apos;s lexical base; and second, that this is one aspect of lexical knowledge where constructionbased lexical acquisition methods offer the opportunity of significantly increased precision / recall ((Poesio et al., 2002a) report a 66.7% recall and 72.7% precision for this class). We tested this by a very crude strategy—given an AD with head noun N and a possible anchor with head noun N&apos;, call Google with the pattern the N of the N&apos;. The results are remarkably good: at least 50 hits are found for all AD-anchor pairs in the examples in this paper, with the exception of the pair standcoffer in (10; and in all of the other examples, the correct solution is found by considering as candidate antecedents cB(S-1), cF(S-1), and Fm(S-1), and choosing the one whose head noun results in the highest number of hits. 5 Con</context>
</contexts>
<marker>Poesio, Ishikawa, Walde, Vieira, 2002</marker>
<rawString>M. Poesio, T. Ishikawa, S. Schulte im Walde, and R. Vieira. 2002a. Acquiring lexical knowledge for anaphora resolution. In Proc. of the 3rd LREC, Las Palmas, Canaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>R Stevenson</author>
<author>H Cheng</author>
<author>B Di Eugenio</author>
<author>J M Hitzeman</author>
</authors>
<title>A corpus-based evaluation of centering theory.</title>
<date>2002</date>
<journal>NLE-TN</journal>
<volume>01</volume>
<institution>University of Essex, Department of Computer Science,</institution>
<note>Submitted for publication.</note>
<marker>Poesio, Stevenson, Cheng, Di Eugenio, Hitzeman, 2002</marker>
<rawString>M. Poesio, R. Stevenson, H. Cheng, B. Di Eugenio, and J. M. Hitzeman. 2002b. A corpus-based evaluation of centering theory. NLE-TN 01, University of Essex, Department of Computer Science, April. Submitted for publication.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
</authors>
<title>Annotating a corpus to develop and evaluate discourse entity realization algorithms: issues and preliminary results.</title>
<date>2000</date>
<booktitle>In Proc. of the 2nd LREC,</booktitle>
<pages>211--218</pages>
<location>Athens,</location>
<contexts>
<context position="1793" citStr="Poesio, 2000" startWordPosition="271" endWordPosition="272">s WordNet (Fellbaum, 1998) do not contain all the necessary information for resolving Bridging Descriptions (Bps) even if only those Bps that rely on the type of relations found in WordNet such as hyponymy, synonymy, or I We borrow the term anchor from Fraurud (1990) to indicate the discourse entity with which the bridging reference is &apos;associated&apos; - reserving &apos;antecedent&apos; for identity anaphora. meronymy (e.g., the window I a house) are considered. In almost 40% of the cases, no semantic relation could be found between such bridging references and their anchor (Poesio et al., 1997; Vieira and Poesio, 2000); 3. Even when a lexical resource did contain information about the existence of a relation between a bridging description and its anchor (30% of the total with WordNet), simply choosing as anchor the entity which is semantically closer to the BD in the chosen window leads to very poor results. In about half of the cases, a competing discourse entity was semantically closer than the actual anchor. We concluded that the resolution of a bridging description does not depend only on lexical information, but also involves other information—perhaps, about which entities are most salient, either in t</context>
<context position="4279" citStr="Poesio, 2000" startWordPosition="688" endWordPosition="689">paper is as follows. In section 2, we discuss the corpus used in this study, how it was annotated, and the methods used to track the CB in this corpus. In section 3, we present our results concerning the correlation between bridging references and salience. Finally, in section 4, we present preliminary findings concerning the use of lexical semantics as a filter. 2 Methods One of the main motivations for this work is that we felt that we could improve upon our previous results by exploiting the results of our other work on referring expressions in general and of salience (Poesio et al., 2000; Poesio, 2000). As a result of this work we had at our disposal the GNOME corpus whose NPs, and the anaphoric relations between them, had been marked in a reliable way (Poesio, 2000). In this section we briefly discuss the corpus and how it was annotated. 2.1 The Corpus The GNOME corpus (Poesio, 2000) includes texts from three domains, two of which were used in this study. The museum subcorpus consists of descriptions of museum objects and brief texts about the artists that produced them.2 The pharmaceutical subcorpus is a selection of leaflets providing the patients with mandatory information about their m</context>
<context position="24405" citStr="Poesio, 2000" startWordPosition="4042" endWordPosition="4043">s Although the results above are not terribly impressive, what Sidner (1979) actually proposed is that anaphors, including bridging references, are resolved by a two-stage process whereby first hypotheses are suggested on the basis of focusing information, and then commonsense inference is used to accept or reject these hypotheses. In this section we briefly consider how easy such a filtering strategy would be to implement. 36 4.1 Using WordNet Our earlier results suggested that implementing Sidner&apos;s filter is not going to be too easy if all we have is WordNet (Poesio et al., 1997; Vieira and Poesio, 2000); preliminary studies with the GNOME corpus confirm this finding. The 110 definite descriptions with an associative interpretation and that are truly &apos;bridging&apos; to a previous utterance enter into a total of 97 ELEMENT, SUBSET, or POSS relations with an anchor in one of the previous utterances. (Often, with more than one.) We ran a script attempting to find a direct lexical connection in WordNet between any one of the senses of the BD and any one of the senses of the potential anchors in the previous utterances. The script follows the search algorithm discussed above: it starts from the most re</context>
</contexts>
<marker>Poesio, 2000</marker>
<rawString>M. Poesio. 2000. Annotating a corpus to develop and evaluate discourse entity realization algorithms: issues and preliminary results. In Proc. of the 2nd LREC, pages 211-218, Athens, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E F Prince</author>
</authors>
<title>The ZPG letter: subjects, definiteness, and information status.</title>
<date>1992</date>
<pages>295--325</pages>
<editor>In S. Thompson and W. Mann, editors,</editor>
<publisher>John Benjamins.</publisher>
<contexts>
<context position="15785" citStr="Prince, 1992" startWordPosition="2566" endWordPosition="2567">est violations of the main claims of the theory. Both of these involved identifying utterances with sentences, and allowing for indirect realization of the CB; but they differed in the ranking function. In one case, grammatical function was used (subjects rank more highly than objects that rank more highly than adjuncts) augmented with a linear disambiguation factor; in the other, Strube and Hahn&apos;s (1999) ranking function based on &apos;information status,&apos; according to which hearer-old entities are ranked more highly than inferrables, which in turn are ranked more highly than hearer-new entities (Prince, 1992). 3 Salience and Bridging Reference The annotated corpus and the focus tracking scripts discussed above were used to investigate the extent to which the interpretation of BDS depended on the salience of potential anchors. In this section we discuss our main findings. 34 3.1 Bridging descriptions in the GNOME corpus A total of 2073 semantic relations are marked up in the GNOME corpus. These can be classified as follows, where IDENT is identity, and POSSNPs are the relations between the possessor and the possessee in a possessive NP: Type of relation Number IDENT 1164 POSS-NPs 328 SUBSET, ELEMEN</context>
</contexts>
<marker>Prince, 1992</marker>
<rawString>E. F. Prince. 1992. The ZPG letter: subjects, definiteness, and information status. In S. Thompson and W. Mann, editors, Discourse description: diverse analyses of a fundraising text, pages 295-325. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A J Sanford</author>
<author>S C Garrod</author>
</authors>
<title>Understanding Written Language.</title>
<date>1981</date>
<publisher>Wiley,</publisher>
<location>Chichester.</location>
<contexts>
<context position="12672" citStr="Sanford and Garrod, 1981" startWordPosition="2065" endWordPosition="2068"> only 4.8% relations were now marked differently; on the other hand, only 22% of bridging references were marked in the same way by both annotators. In other words, although our current scheme does limit the disagreements on antecedents and relations, we still find that 73.17% of relations are marked by only one annotator. 2.3 Automatic tracking of focus according to Centering theory The notion of &apos;topic&apos; or &apos;discourse focus&apos; has often been claimed to play an important role in the interpretation and production of anaphoric expressions, including bridging references (Grosz, 1977; Sidner, 1979; Sanford and Garrod, 1981; McKeown, 1986; Grosz et al., 1995; Dale, 1992; Walker et al., 1998), but it is notoriously difficult to pin down. Sidner (1979) developed detailed algorithms implementing her claim (and Grosz&apos;s (Grosz, 1977)) that the interpretation of bridging references depend on focusing information. Her proposals however rely heavily on commonsense knowledge, and for this reason have never been extensively evaluated.4 As the basis for the work reported here, we used the terminology and ideas introduced in what is currently the best-known formalization of the idea of topic in Computational Linguistics, Ce</context>
</contexts>
<marker>Sanford, Garrod, 1981</marker>
<rawString>A. J. Sanford and S. C. Garrod. 1981. Understanding Written Language. Wiley, Chichester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Scott</author>
<author>R Power</author>
<author>R Evans</author>
</authors>
<title>Generation as a solution to its own problem.</title>
<date>1998</date>
<booktitle>In Proc. of the 9th International Workshop on Natural Language Generation.</booktitle>
<contexts>
<context position="5510" citStr="Scott et al., 1998" startWordPosition="894" endWordPosition="897">ch subcorpus contains about 6,000 NPs; in this study we used texts from the first two domains, for a total of about 3,000 NPS, 2The museum subcorpus extends the corpus collected to support the ILEX and SOLE projects at the University of Edinburgh. ILEX generates Web pages describing museum objects (Oberlander et al., 1998) The SOLE project extended ILEX with concept-to-speech abilities (Hitzeman et al., 1998). 3The leafets in the pharmaceutical subcorpus are a subset of the collection of all patient leafhts in the UK , digitized to support the ICONOCLAST project at the University of Brighton (Scott et al., 1998). about 600 of which are definite descriptions. Of the potential candidates for &apos;utterances&apos;, the corpus includes about 500 sentences, and 900 finite clauses; the actual number of utterances used in the study is one of the parameters that we varied. 2.2 Annotation Motivations The marking scheme used in (Poesio and Vieira, 1998) wasn&apos;t completely satisfactory. For one thing, our method for annotating bridging references didn&apos;t guarantee agreement. Secondly, although our work had revealed that many definite NPS could simultaneously belong to two classes - e.g., be directly anaphoric on one entit</context>
</contexts>
<marker>Scott, Power, Evans, 1998</marker>
<rawString>D. Scott, R. Power, and R. Evans. 1998. Generation as a solution to its own problem. In Proc. of the 9th International Workshop on Natural Language Generation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Sidner</author>
</authors>
<title>Towards a computational theory of definite anaphora comprehension in English discourse.</title>
<date>1979</date>
<tech>Ph.D. thesis,</tech>
<institution>MIT.</institution>
<contexts>
<context position="2498" citStr="Sidner (1979)" startWordPosition="391" endWordPosition="392">between a bridging description and its anchor (30% of the total with WordNet), simply choosing as anchor the entity which is semantically closer to the BD in the chosen window leads to very poor results. In about half of the cases, a competing discourse entity was semantically closer than the actual anchor. We concluded that the resolution of a bridging description does not depend only on lexical information, but also involves other information—perhaps, about which entities are most salient, either in the basic sense of being more recent, or perhaps by being the &apos;focus&apos;, as already claimed by Sidner (1979). We addressed the second of these problems by developing methods for automatically acquiring the lexical information needed to resolve (a subset of) Bps (Poesio et al., 1998; Poesio et al., 2002a). In parallel with that effort, we have been developing reliable methods for annotating bridging references, and created a corpus which can be be used to study them with greater accuracy (Poesio, 2000). We have also been developing automatic methods for tracking the &apos;focus&apos; of a discourse in the sense of Centering Theory (Grosz et al., 1995; Walker et al., 1998) which allow us to compare the many exi</context>
<context position="12646" citStr="Sidner, 1979" startWordPosition="2063" endWordPosition="2064">ng references, only 4.8% relations were now marked differently; on the other hand, only 22% of bridging references were marked in the same way by both annotators. In other words, although our current scheme does limit the disagreements on antecedents and relations, we still find that 73.17% of relations are marked by only one annotator. 2.3 Automatic tracking of focus according to Centering theory The notion of &apos;topic&apos; or &apos;discourse focus&apos; has often been claimed to play an important role in the interpretation and production of anaphoric expressions, including bridging references (Grosz, 1977; Sidner, 1979; Sanford and Garrod, 1981; McKeown, 1986; Grosz et al., 1995; Dale, 1992; Walker et al., 1998), but it is notoriously difficult to pin down. Sidner (1979) developed detailed algorithms implementing her claim (and Grosz&apos;s (Grosz, 1977)) that the interpretation of bridging references depend on focusing information. Her proposals however rely heavily on commonsense knowledge, and for this reason have never been extensively evaluated.4 As the basis for the work reported here, we used the terminology and ideas introduced in what is currently the best-known formalization of the idea of topic in Com</context>
<context position="17956" citStr="Sidner, 1979" startWordPosition="2910" endWordPosition="2911">ar 0 (same utterance) 59 1 72 2 20 3-5 (total) 11 6 or more 7 (Notice that 95.8% of the anchors are found in the same utterance or the previous 5, confirming the results of (Poesio and Vieira, 1998).) 3.2 Bridging descriptions and recency The simplest hypothesis concerning BD resolution is that their anchors are identified searching first in the previous utterance, then in the utterance before that, etc.—i.e., following the search strategy first proposed in (Winograd, 1972; Hobbs, 1978; 5As discussed above, an anaphoric expression may be semantically related to more than one discourse entity. Sidner, 1979). Utterances may be searched leftto-right or right-to-left (&apos;most recent first&apos;). In our corpus, 68% (49 / 72) of associative descriptions whose anchor is in the previous sentence have the first-mentioned entity (henceforth, Fm(S-1)) as their anchor, and 44.5% of the total. Of the ADS whose anchor is in the current or previous clause, 64% have as anchor the firstmentioned element of the previous clause. By constrast, for only 15% (11 / 72) of Bps whose anchor is in S-1, this anchor is the last-mentioned entity in S-1. These figures confirm the preference for firstmention over recency often obs</context>
<context position="19792" citStr="Sidner, 1979" startWordPosition="3232" endWordPosition="3233">r of the strategies of choosing the anchor on the basis of lexical closeness that we tried in the past, looking for the closest sense in WordNet, which resulted in a 39% accuracy (Poesio et al., 1997), and looking for the closest element in a vectorial space (Poesio et al., 1998), with an accuracy of 22.2%. To do better than that, additional information is needed to evaluate the suggestions made by the search strategy. 3.3 Bridging descriptions and focusing A more complex hypothesis concerning the search for the anchor of a BD is that it involves information about which entities are in focus (Sidner, 1979). Using Centering terminology, and ignoring direct anaphors and more complex cases, Sidner&apos;s algorithm (more precisely, her &apos;Associated Specification&apos;, &apos;Inferred Specification,&apos; and &apos;SetElement Specification&apos; rules) could be reformulated as follows ((Sidner, 1979), p. 123-124): 35 1. Try first as anchor CB(U-1) (or cP(U-1)); 2. If that fails, try all other CFS in ranking order; 3. If that&apos;s not acceptable, try the stacked foci. If we identify utterances with sentences and we use Strube and Hahn&apos;s ranking function, then CB(U-1) is the anchor of 37 out of the 72 BDS whose anchor is in the previo</context>
<context position="23868" citStr="Sidner (1979)" startWordPosition="3953" endWordPosition="3954"> if waterproof dressings are used. b. These include. thinning of the skin on or around the treated area. Clearly, limiting the search to past CBs, even if following a simpler recency order, would pay off. To conclude, simply knowing CB(U-1) or CP(U1) is not even as useful by itself as knowing Pm(U1), but limiting the search to previous CBS might be very useful, provided that ways are found of &apos;checking&apos; that the proposed solution is plausible, as hypothesized by Sidner. 4 Filtering using lexical knowledge: preliminary investigations Although the results above are not terribly impressive, what Sidner (1979) actually proposed is that anaphors, including bridging references, are resolved by a two-stage process whereby first hypotheses are suggested on the basis of focusing information, and then commonsense inference is used to accept or reject these hypotheses. In this section we briefly consider how easy such a filtering strategy would be to implement. 36 4.1 Using WordNet Our earlier results suggested that implementing Sidner&apos;s filter is not going to be too easy if all we have is WordNet (Poesio et al., 1997; Vieira and Poesio, 2000); preliminary studies with the GNOME corpus confirm this findin</context>
</contexts>
<marker>Sidner, 1979</marker>
<rawString>C. L. Sidner. 1979. Towards a computational theory of definite anaphora comprehension in English discourse. Ph.D. thesis, MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Strube</author>
<author>U Hahn</author>
</authors>
<title>Functional centeringgrounding referential coherence in information structure.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<pages>25--3</pages>
<marker>Strube, Hahn, 1999</marker>
<rawString>M. Strube and U. Hahn. 1999. Functional centeringgrounding referential coherence in information structure. Computational Linguistics, 25(3):309-344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Vieira</author>
<author>M Poesio</author>
</authors>
<title>An empirically-based system for processing defi nite descriptions.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>4</issue>
<contexts>
<context position="1793" citStr="Vieira and Poesio, 2000" startWordPosition="269" endWordPosition="272">rces such as WordNet (Fellbaum, 1998) do not contain all the necessary information for resolving Bridging Descriptions (Bps) even if only those Bps that rely on the type of relations found in WordNet such as hyponymy, synonymy, or I We borrow the term anchor from Fraurud (1990) to indicate the discourse entity with which the bridging reference is &apos;associated&apos; - reserving &apos;antecedent&apos; for identity anaphora. meronymy (e.g., the window I a house) are considered. In almost 40% of the cases, no semantic relation could be found between such bridging references and their anchor (Poesio et al., 1997; Vieira and Poesio, 2000); 3. Even when a lexical resource did contain information about the existence of a relation between a bridging description and its anchor (30% of the total with WordNet), simply choosing as anchor the entity which is semantically closer to the BD in the chosen window leads to very poor results. In about half of the cases, a competing discourse entity was semantically closer than the actual anchor. We concluded that the resolution of a bridging description does not depend only on lexical information, but also involves other information—perhaps, about which entities are most salient, either in t</context>
<context position="24405" citStr="Vieira and Poesio, 2000" startWordPosition="4040" endWordPosition="4043">vestigations Although the results above are not terribly impressive, what Sidner (1979) actually proposed is that anaphors, including bridging references, are resolved by a two-stage process whereby first hypotheses are suggested on the basis of focusing information, and then commonsense inference is used to accept or reject these hypotheses. In this section we briefly consider how easy such a filtering strategy would be to implement. 36 4.1 Using WordNet Our earlier results suggested that implementing Sidner&apos;s filter is not going to be too easy if all we have is WordNet (Poesio et al., 1997; Vieira and Poesio, 2000); preliminary studies with the GNOME corpus confirm this finding. The 110 definite descriptions with an associative interpretation and that are truly &apos;bridging&apos; to a previous utterance enter into a total of 97 ELEMENT, SUBSET, or POSS relations with an anchor in one of the previous utterances. (Often, with more than one.) We ran a script attempting to find a direct lexical connection in WordNet between any one of the senses of the BD and any one of the senses of the potential anchors in the previous utterances. The script follows the search algorithm discussed above: it starts from the most re</context>
</contexts>
<marker>Vieira, Poesio, 2000</marker>
<rawString>R. Vieira and M. Poesio. 2000. An empirically-based system for processing defi nite descriptions. Computational Linguistics, 26(4), December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Walker</author>
<author>A K Joshi</author>
</authors>
<date>1998</date>
<booktitle>Centering Theory in Discourse. Clarendon Press /</booktitle>
<editor>and E. F. Prince, editors.</editor>
<location>Oxford.</location>
<marker>Walker, Joshi, 1998</marker>
<rawString>M. A. Walker, A. K. Joshi, and E. F. Prince, editors. 1998. Centering Theory in Discourse. Clarendon Press / Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Winograd</author>
</authors>
<title>Understanding Natural Language.</title>
<date>1972</date>
<publisher>Academic Press.</publisher>
<contexts>
<context position="17820" citStr="Winograd, 1972" startWordPosition="2889" endWordPosition="2890">ription and its closest anchor, with sentences as utterances, can be summarized as follows: Distance Number of BDs whose anchor is that far 0 (same utterance) 59 1 72 2 20 3-5 (total) 11 6 or more 7 (Notice that 95.8% of the anchors are found in the same utterance or the previous 5, confirming the results of (Poesio and Vieira, 1998).) 3.2 Bridging descriptions and recency The simplest hypothesis concerning BD resolution is that their anchors are identified searching first in the previous utterance, then in the utterance before that, etc.—i.e., following the search strategy first proposed in (Winograd, 1972; Hobbs, 1978; 5As discussed above, an anaphoric expression may be semantically related to more than one discourse entity. Sidner, 1979). Utterances may be searched leftto-right or right-to-left (&apos;most recent first&apos;). In our corpus, 68% (49 / 72) of associative descriptions whose anchor is in the previous sentence have the first-mentioned entity (henceforth, Fm(S-1)) as their anchor, and 44.5% of the total. Of the ADS whose anchor is in the current or previous clause, 64% have as anchor the firstmentioned element of the previous clause. By constrast, for only 15% (11 / 72) of Bps whose anchor </context>
</contexts>
<marker>Winograd, 1972</marker>
<rawString>Terry Winograd. 1972. Understanding Natural Language. Academic Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>