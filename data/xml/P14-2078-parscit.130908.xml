<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.994983">
Mutual Disambiguation for Entity Linking
</title>
<author confidence="0.967291">
Eric Charton
</author>
<affiliation confidence="0.888487">
Polytechnique Montr´eal
</affiliation>
<address confidence="0.565861">
Montr´eal, QC, Canada
</address>
<email confidence="0.972257">
eric.charton@polymtl.ca
</email>
<author confidence="0.548625">
Ludovic Jean-Louis
</author>
<affiliation confidence="0.47354">
Polytechnique Montr´eal
</affiliation>
<email confidence="0.986184">
ludovic.jean-louis@polymtl.ca
</email>
<sectionHeader confidence="0.993651" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999379818181818">
The disambiguation algorithm presented in
this paper is implemented in SemLinker, an
entity linking system. First, named entities
are linked to candidate Wikipedia pages by
a generic annotation engine. Then, the al-
gorithm re-ranks candidate links according to
mutual relations between all the named enti-
ties found in the document. The evaluation
is based on experiments conducted on the test
corpus of the TAC-KBP 2012 entity linking
task.
</bodyText>
<sectionHeader confidence="0.998797" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999927192307692">
The Entity Linking (EL) task consists in linking
name mentions of named entities (NEs) found in a
document to their corresponding entities in a ref-
erence Knowledge Base (KB). These NEs can be
of type person (PER), organization (ORG), etc.,
and they are usually represented in the KB by a
Uniform Resource Identifier (URI). Dealing with
ambiguity is one of the key difficulties in this task,
since mentions are often highly polysemous, and
potentially related to many different KB entries.
Various approaches have been proposed to solve
the named entity disambiguation (NED) problem.
Most of them involve the use of surface forms ex-
tracted from Wikipedia. Surface forms consist of
a word or a group of words that match lexical units
like Paris or New York City. They are used as
matching sequences to locate corresponding can-
didate entries in the KB, and then to disambiguate
those candidates using similarity measures.
The NED problem is related to the Word Sense
Disambiguation (WSD) problem (Navigli, 2009),
and is often more challenging since mentions of
NEs can be highly ambiguous. For instance,
names of places can be very common as is Paris,
which refers to 26 different places in Wikipedia.
Hence, systems that attempt to address the NED
</bodyText>
<sectionHeader confidence="0.38461" genericHeader="introduction">
Marie-Jean Meurs
</sectionHeader>
<affiliation confidence="0.619989">
Concordia University
Montr´eal, QC, Canada
</affiliation>
<email confidence="0.923145">
marie-jean.meurs@concordia.ca
</email>
<author confidence="0.660054">
Michel Gagnon
</author>
<affiliation confidence="0.36046">
Polytechnique Montr´eal
</affiliation>
<email confidence="0.92597">
michel.gagnon@polymtl.ca
</email>
<bodyText confidence="0.999914048780488">
problem must include disambiguation resources.
In the context of the Named Entity Recognition
(NER) task, such resources can be generic and
generative. This generative approach does not ap-
ply to the EL task where each entity to be linked to
a semantic description has a specific word context,
marker of its exact identity.
One of the classical approach to conduct the
disambiguation process in NED applications is to
consider the context of the mention to be mapped,
and compare this context with contextual informa-
tion about the potential target entities (see for in-
stance the KIM system (Popov et al., 2003)). This
is usually done using similarity measures (such as
cosine similarity, weighted Jaccard distance, KL
divergence...) that evaluate the distance between
a bag of words related to a candidate annotation,
and the words surrounding the entity to annotate
in the text.
In more recent approaches, it is suggested that
annotation processes based on similarity distance
measures can be improved by making use of other
annotations present in the same document. Such
techniques are referred to as semantic related-
ness (Strube and Ponzetto, 2006), collective dis-
ambiguation (Hoffart et al., 2011b), or joint dis-
ambiguation (Fahrni et al., 2012). The idea is to
evaluate in a set of candidate links which one is
the most likely to be correct by taking the other
links contained in the document into account. For
example, if a NE describes a city name like Paris,
it is more probable that the correct link for this
city name designates Paris (France) rather than
Paris (Texas) if a neighbor entity offers candidate
links semantically related to Paris (France) like
the Seine river or the Champs-Elys´ees. Such tech-
niques mostly involve exploration of graphs result-
ing of all the candidate annotations proposed for a
given document, and try to rank the best candi-
dates for each annotation using an ontology. The
ontology (like YAGO or DBPedia) provides a pre-
</bodyText>
<page confidence="0.988131">
476
</page>
<bodyText confidence="0.988025633333333">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 476–481,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
existing set of potential relations between the enti-
ties to link (like for instance, in our previous exam-
ple, Paris (France) has river Seine) that will
be used to rank the best candidates according to
their mutual presence in the document.
In this paper we explore the capabilities of a dis-
ambiguation algorithm using all the available an-
notation layers of NEs to improve their links. The
paper makes the following novel propositions: 1)
the ontology used to evaluate the relatedness of
candidates is replaced by internal links and cate-
gories from the Wikipedia corpus; 2) the coher-
ence of entities is improved prior to the calcula-
tion of semantic relatedness using a co-reference
resolution algorithm, and a NE label correction
method; 3) the proposed method is robust enough
to improve the performance of existing entity link-
ing annotation engines, which are capable of pro-
viding a set of ranked candidates for each annota-
tion in a document.
This paper is organized as follows. Section 2
describes related works. The proposed method is
presented in Section 3 where we explain how our
SemLinker system prepares documents that con-
tain mentions to disambiguate, then we detail the
disambiguation algorithm. The evaluation of the
complete system is provided in Section 4. Finally,
we discuss the obtained results, and conclude.
</bodyText>
<sectionHeader confidence="0.999693" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999654">
Entity annotation and linking in natural language
text has been extensively studied in NLP research.
A strong effort has been conducted recently by the
TAC-KBP evaluation task (Ji et al., 2010) to cre-
ate standardized corpus, and annotation standards
based on Wikipedia for evaluation and comparison
of EL systems. In this paper, we consider the TAC-
KBP framework. We describe below some recent
approaches proposed for solving the EL task.
</bodyText>
<subsectionHeader confidence="0.99083">
2.1 Wikipedia-based Disambiguation Methods
</subsectionHeader>
<bodyText confidence="0.999931722222222">
The use of Wikipedia for explicit disambiguation
dates back to (Bunescu and Pasca, 2006) who built
a system that compared the context of a mention
to the Wikipedia categories of an entity candidate.
Lately, (Cucerzan, 2007; Milne and Witten, 2008;
Nguyen and Cao, 2008) extended this framework
by using richer features for similarity comparison.
Some authors like Milne and Witten (2008) uti-
lized machine learning methods rather than a sim-
ilarity function to map mentions to entities. They
also introduced the notion of semantic relatedness.
Alternative propositions were suggested in other
works like (Han and Zhao, 2009) that considered
the relatedness of common noun phrases in a men-
tion context with Wikipedia article names. While
all these approaches focus on semantic relation be-
tween entities, their potential is limited by the sep-
arate mapping of candidate links for each mention.
</bodyText>
<subsectionHeader confidence="0.998939">
2.2 Semantic Web Compliant Methods
</subsectionHeader>
<bodyText confidence="0.99993312">
More recently, several systems have been
launched as web services dedicated to EL tasks.
Most of them are compliant with new emergent
semantic web standards like LinkedData network.
DBPedia Spotlight (Mendes et al., 2011) is a
system that finds mentions of DBpedia (Auer
et al., 2007) resources in a textual document.
Wikimeta (Charton and Gagnon, 2012) is another
system relying on DBpedia. It uses bags of words
to disambiguate semantic entities according to
a cosine similarity algorithm. Those systems
have been compared with commercial ones
like AlchemyAPI, Zemanta, or Open Calais
in (Gangemi, 2013). The study showed that
they perform differently on various essential
aspects of EL tasks (mention detection, linking,
disambiguation). This suggests a wide range of
potential improvements on many aspects of the
EL task. Only some of these systems introduce
the semantic relatedness in their methods like
the AIDA (Hoffart et al., 2011b) system. It
proposes a disambiguation method that combines
popularity-based priors, similarity measures, and
coherence. It relies on the Wikipedia-derived
YAGO2 (Hoffart et al., 2011a) knowledge base.
</bodyText>
<sectionHeader confidence="0.990035" genericHeader="method">
3 Proposed Algorithm
</sectionHeader>
<bodyText confidence="0.999970285714286">
We propose a mutual disambiguation algorithm
that improves the accuracy of entity links in a doc-
ument by using successive corrections applied to
an annotation object representing this document.
The annotation object is composed of information
extracted from the document along with linguistic
and semantic annotations as described hereafter.
</bodyText>
<subsectionHeader confidence="0.999006">
3.1 Annotation Object
</subsectionHeader>
<bodyText confidence="0.9999848">
Documents are processed by an annotator capable
of producing POS tags for each word, as well as
spans, NE surface forms, NE labels and ranked
candidate Wikipedia URIs for each candidate NE.
For each document D, this knowledge is gathered
</bodyText>
<page confidence="0.992003">
477
</page>
<bodyText confidence="0.999967652173913">
in an array called annotation object, which has ini-
tially one row per document lexical unit. Since the
system focuses on NEs, rows with lexical units
that do not belong to a NE SF are dropped from
the annotation object, and NE SF are refined as de-
scribed in (Charton et al., 2014). When NE SF are
spanned over several rows, these rows are merged
into a single one. Thus, we consider an annotation
object AD, which is an array with a row for each
NE, and columns storing related knowledge.
If n NEs were annotated in D, then AD has n
rows. If l candidate URIs are provided for each
NE, then AD has (l + 4) columns cu,uE{1,l+4}.
Columns c1 to cl store Wikipedia URIs associated
with NEs, ordered by decreasing values of likeli-
hood. Column cl+1 stores the offset of the NEs,
cl+2 stores their surface forms, cl+3 stores the NE
labels (PER, ORG, ...), and cl+4 stores the (vec-
tors of) POS tags associated with the NE surface
forms. AD contains all the available knowledge
about the NEs found in D. Before being processed
by the disambiguation module, AD is dynamically
updated by correction processes.
</bodyText>
<subsectionHeader confidence="0.998909">
3.2 Named Entity Label Correction
</subsectionHeader>
<bodyText confidence="0.999990727272727">
To support the correction process based on co-
reference chains, the system tries to correct NE
labels for all the NEs listed in the annotation ob-
ject. The NE label correction process assigns the
same NE label to all the NEs associated with the
same first rank URI. For all the rows in AD, sets of
rows with identical first rank URIs are considered.
Then, for each set, NE labels are counted per type,
and all the rows in a same set are updated with the
most frequent NE label found in the set, i.e. all the
NEs in this set are tagged with this label.
</bodyText>
<subsectionHeader confidence="0.999838">
3.3 Correction Based on Co-reference Chains
</subsectionHeader>
<bodyText confidence="0.999805789473684">
First rank candidate URIs are corrected by a pro-
cess that relies on co-reference chains found in
the document. The co-reference detection is con-
ducted using the information recorded in the anno-
tation object. Among the NEs present in the docu-
ment, the ones that co-refer are identified and clus-
tered by logical rules applied to the content of the
annotation object. When a co-reference chain of
NEs is detected, the system assigns the same URI
to all the members of the chain. This URI is se-
lected through a decision process that gives more
weight to longer surface forms and frequent URIs.
The following example illustrates an application
of this correction process:
Three sentences are extracted from a document
about Paris, the French capital. NEs are indicated
in brackets, first rank URIs and surface forms are
added below the content of each sentence.
- [Paris] is famous around the world.
</bodyText>
<note confidence="0.464869">
URI1: http://en.wikipedia.org/wiki/Paris Hilton
</note>
<bodyText confidence="0.4342698">
NE surface form: Paris
- The [city of Paris] attracts millions of tourists.
URI1: http://en.wikipedia.org/wiki/Paris
NE surface form: city of Paris
- The [capital of France] is easy to reach by train.
</bodyText>
<footnote confidence="0.478283">
URI1: http://en.wikipedia.org/wiki/Paris
</footnote>
<bodyText confidence="0.985062333333333">
NE surface form: capital of France
The three NEs found in these sentences com-
pose a co-reference chain. The second NE has
a longer surface form than the first one, and
its associated first rank URI is the most fre-
quent. Hence, the co-reference correction pro-
cess will assign the right URI to the first NE
(URI1: http://en.wikipedia.org/wiki/Paris), which
was wrongly linked to the actress Paris Hilton.
</bodyText>
<subsectionHeader confidence="0.948569">
3.4 Mutual Disambiguation Process
</subsectionHeader>
<bodyText confidence="0.997512535714286">
The extraction of an accurate link is a process oc-
curring after the URI annotation of NEs in the
whole document. The system makes use of all
the semantic content stored in AD to locally im-
prove the precision of each URI annotation in the
document. The Mutual Disambiguation Process
(MDP) relies on the graph of all the relations (in-
ternal links, categories) between Wikipedia con-
tent related to the document annotations.
A basic example of semantic relatedness that
should be captured is explained hereafter. Let us
consider the mention IBM in a given document.
Candidate NE annotations for this mention can be
International Business Machine or International
Brotherhood of Magicians. But if the IBM men-
tion co-occurs with a Thomas Watson, Jr mention
in the document, there will probably be more links
between the International Business Machine and
Thomas Watson, Jr related Wikipedia pages than
between the International Brotherhood of Magi-
cians and Thomas Watson, Jr related Wikipedia
pages. The purpose of the MDP is to capture this
semantic relatedness information contained in the
graph of links extracted from Wikipedia pages re-
lated to each candidate annotation.
In MDP, for each Wikipedia URI candidate an-
notation, all the internal links and categories con-
tained in the source Wikipedia document related
</bodyText>
<page confidence="0.995233">
478
</page>
<bodyText confidence="0.999902153846154">
to this URI are collected. This information will be
used to calculate a weight for each of the l can-
didate URI annotations of each mention. For a
given NE, this weight is expected to measure the
mutual relations of a candidate annotation with all
the other candidate annotations of NEs in the doc-
ument. The input of the MDP is an annotation
object AD with n rows, obtained as explained in
Section 3.1. For all i E [1, n], k E [1, l], we build
the set 5 k , composed of the Wikipedia URIs and
categories contained in the source Wikipedia doc-
ument related to the URI stored in AD[i][k] that
we will refer to as URI k to ease the reading.
</bodyText>
<sectionHeader confidence="0.623277" genericHeader="method">
Scoring:
</sectionHeader>
<bodyText confidence="0.9698245">
For all i, j E [1, n], k E [1, l], we want to cal-
culate the weight of mutual relations between the
candidate URI k and all the first rank candidates
URI1� for j =� i. The calculation combines two
scores that we called direct semantic relation score
(dsr score) and common semantic relation score
(csr score):
- the dsr score for URI k sums up the number of
occurrences of URI k in 51� for all j E [1, n]−{i}.
- the csr score for URI k sums up the number of
common URIs and categories between 5 k and 51�
for all j E [1, n] − {i}.
We assumed the dsr score was much more
semantically significant than the csr score, and
translated this assumption in the weight calcula-
tion by introducing two correction parameters α
and Q used in the final scoring calculation.
Re-ranking:
For all i E [1, n], for each set of URIs {URI k , k E
[1, l]}, the re-ranking process is conducted ac-
cording to the following steps:
For all i E I,
</bodyText>
<listItem confidence="0.956861714285714">
1. bk E [1, l], calculate dsr score(URI k )
2. bk E [1, l], calculate csr score(URI k )
3. bk E [1, l], calculate
mutual relation score(URI k ) =
α.dsr score(URI k )+Q.csr score(URI k )
4. re-order {URI k, k E [1, l]}, by
decreasing order of mutual relation score.
</listItem>
<bodyText confidence="0.904683666666667">
In the following, we detail the MDP in the con-
text of a toy example to illustrate how it works.
The document contains two sentences, NE men-
tions are in bold:
IBM has 12 research laboratories
worldwide. Thomas J. Watson, Jr.
became president of the company.
For the first NE mention [IBM], AD contains
two candidate URIs identifying two different re-
sources:
[IBM]URIi - International Brotherhood of Magicians
URIi - International Business Machines Corporation
For the second NE mention [Thomas J.
Watson, Jr.], AD contains the following can-
didate URI, which is ranked first:
</bodyText>
<equation confidence="0.259656">
[Thomas J. Watson, Jr.] URI12 - Thomas Watson, Jr.
</equation>
<bodyText confidence="0.962922315789474">
51 1 gathers URIs and categories contained in the
International Brotherhood of Magicians Wikipedia
page. 512 is associated to the International Business
Machines Corporation, and 512 to the Thomas Watson,
Jr. page. dsr score(URI11) sums up the number of
occurrences of URI11 in 51� for all j E [1, n]−{1}.
Hence, in the current example, dsr score(URI11) is
the number of occurrences of URI11 in 512, namely
the number of times the International Brotherhood
of Magicians are cited in the Thomas Watson, Jr.
page. Similarly, dsr score(URI21) is equal to the
number of times the International Business Machines
Corporation is cited in the Thomas Watson, Jr. page.
csr score(URI11) sums up the number of common
URIs and categories between 511 and 512, i.e. the
number of URIs and categories appearing in both
International Brotherhood of Magicians and Thomas
Watson, Jr. pages. csr score(URI21) counts the
number of URIs and categories appearing in both
</bodyText>
<subsectionHeader confidence="0.932541">
International Business Machines Corporation and
Thomas Watson, Jr. pages.
</subsectionHeader>
<bodyText confidence="0.978845">
After calculation, we have:
mutual relation score(URII) &lt; mutual relation score(URII)
The candidate URIs for [IBM] are re-ranked
accordingly, and International Business Machines
Corporation becomes its first rank candidate.
</bodyText>
<sectionHeader confidence="0.998406" genericHeader="evaluation">
4 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999858142857143">
SemLinker has been evaluated on the TAC-KBP
2012 EL task (Charton et al., 2013). In this task,
mentions of entities found in a document collec-
tion must be linked to entities in a reference KB, or
to new named entities discovered in the collection.
The document collection built for KBP 2012 con-
tains a combination of newswire articles (News),
</bodyText>
<page confidence="0.998024">
479
</page>
<table confidence="0.986800888888889">
TAC-KBP2012 systems
modules no disambiguation
Category B3+P B3+R B3+F1
Overall 0.620 0.633 0.626
PER 0.771 0.791 0.781
ORG 0.600 0.571 0.585
GPE 0.412 0.465 0.437
News 0.663 0.691 0.677
Web 0.536 0.520 0.528
</table>
<figure confidence="0.98469793220339">
1st
0.730
0.809
0.715
0.627
0.782
0.630
2nd
0.699
0.840
0.615
0.579
0.759
0.580
3rd
B3+F1
0.689
0.714
0.717
0.614
0.710
0.508
median
B3+F1
0.536
0.645
0.485
0.428
0.574
0.491
B3+F1 B3+F1
SemLinker
MDP only all modules
B3+P B3+R B3+F1
B3+P B3+R B3+F1
0.675 0.681
0.785 0.795
0.622 0.578
0.570 0.628
0.678
0.790
0.599
0.598
0.694 0.695
0.828 0.838
0.621 0.569
0.574 0.626
0.695
0.833
0.594
0.599
0.728 0.748
0.572 0.550
0.750 0.767
0.585 0.556
0.738
0.561
0.758
0.570
</figure>
<tableCaption confidence="0.8720885">
Table 1: SemLinker results on the TAC-KBP 2012 test corpus with/out disambiguation modules, and
three best results and median from TAC-KBP 2012 systems.
</tableCaption>
<bodyText confidence="0.99960525">
posts to blogs and newsgroups (Web). Given a
query that consists of a document with a specified
name mention of an entity, the task is to determine
the correct node in the reference KB for the entity,
adding a new node for the entity if it is not already
in the reference KB. Entities can be of type person
(PER), organization (ORG), or geopolitical entity
(GPE). The reference knowledge base is derived
from an October 2008 dump of English Wikipedia,
which includes 818,741 nodes. Table 2 provides a
breakdown of the queries per categories of entities,
and per type of documents.
</bodyText>
<table confidence="0.680557">
Category All PER ORG GPE News Web
# queries 2226 918 706 602 1471 755
</table>
<tableCaption confidence="0.833998">
Table 2: Breakdown of the TAC-KBP 2012 test
</tableCaption>
<bodyText confidence="0.969329727272727">
corpus queries according to entity types, and doc-
ument categories.
A complete description of these linguistic re-
sources can be found in (Ellis et al., 2011). For
the sake of reproducibility, we applied the KBP
scoring metric (B3 + F) described in (TAC-KBP,
2012), and we used the KBP scorer1.
The evaluated system makes use of the
Wikimeta annotation engine. The maximum num-
ber of candidate URIs is l = 15. The MDP correc-
tion parameters α and Q described in Section 3.4
have been experimentally set to α = 10, Q = 2.
Table 1 presents the results obtained by the sys-
tem in three configurations. In the first column,
the system is evaluated without the disambigua-
tion module. In the second column, we applied
the MDP without correction processes. The sys-
tem with the complete disambiguation module ob-
tained the results provided in the third column.
The three best results and the median from TAC-
KBP 2012 systems are shown in the remaining
columns for the sake of comparison.
</bodyText>
<footnote confidence="0.9278605">
1http://www.nist.gov/tac/2013/KBP/
EntityLinking/tools.html
</footnote>
<bodyText confidence="0.999945428571429">
We observe that the complete algorithm (co-
references, named entity labels and MDP) pro-
vides the best results on PER NE links. On GPE
and ORG entities, the simple application of MDP
without prior corrections obtains the best results.
A slight loss of accuracy is observed on ORG NEs
when the MDP is applied with corrections. For
those three categories of entities, we show that the
complete system improves the performance of a
simple algorithm using distance measures. Results
on categories News and Web show that the best
performance on the whole KBP corpus (without
distinction of NE categories) is obtained with the
complete algorithm.
</bodyText>
<sectionHeader confidence="0.998835" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999934375">
The presented system provides a robust seman-
tic disambiguation method, based on mutual re-
lation of entities inside a document, using a stan-
dard annotation engine. It uses co-reference, NE
normalization methods, and Wikipedia internal
links as mutual disambiguation resource to im-
prove the annotations. We show that our propo-
sition improves the performance of a standard an-
notation engine applied to the TAC-KBP evalua-
tion framework. SemLinker is fully implemented,
and publicly released as an open source toolkit
(http://code.google.com/p/semlinker). It
has been deployed in the TAC-KBP 2013 evalu-
ation campaign. Our future work will integrate
other annotation engines in the system architecture
in a collaborative approach.
</bodyText>
<sectionHeader confidence="0.997734" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<footnote confidence="0.965754166666667">
This research was supported as part of Dr Eric
Charton’s Mitacs Elevate Grant sponsored by
3CE. Participation of Dr Marie-Jean Meurs was
supported by the Genozymes Project funded by
Genome Canada &amp; G´enome Qu´ebec. The Con-
cordia Tsang Lab provided computing resources.
</footnote>
<page confidence="0.996982">
480
</page>
<sectionHeader confidence="0.989533" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999745055555556">
S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens
Lehmann, Richard Cyganiak, and Zachary Ives.
2007. Dbpedia: A nucleus for a web of open data.
In The semantic web, pages 722–735. Springer.
Razvan C. Bunescu and Marius Pasca. 2006. Us-
ing encyclopedic knowledge for named entity dis-
ambiguation. In Proceedings of the Conference of
the European Chapter of the Association for Com-
putational Linguistics (EACL). ACL.
Eric Charton and Michel Gagnon. 2012. A disam-
biguation resource extracted from Wikipedia for se-
mantic annotation. In Proceedings of LREC 2012.
Eric Charton, Marie-Jean Meurs, Ludovic Jean-Louis,
and Michel Gagnon. 2013. SemLinker system
for KBP2013: A disambiguation algorithm based
on mutual relations of semantic annotations inside
a document. In Text Analysis Conference KBP.
U.S. National Institute of Standards and Technology
(NIST).
Eric Charton, Marie-Jean Meurs, Ludovic Jean-Louis,
and Michel Gagnon. 2014. Improving Entity Link-
ing using Surface Form Refinement. In Proceedings
of LREC 2014.
Silviu Cucerzan. 2007. Large-scale named entity dis-
ambiguation based on wikipedia data. In Proceed-
ings of the Conference on Empirical Methods in Nat-
ural Language Processing EMNLP-CoNLL. ACL.
Joe Ellis, Xuansong Li, Kira Griffitt, Stephanie M
Strassel, and Jonathan Wright. 2011. Linguistic re-
sources for 2012 knowledge base population evalu-
ations. In Proceedings of TAC-KBP 2012.
Angela Fahrni, Thierry G¨ockel, and Michael Strube.
2012. Hitsmonolingual and cross-lingual entity
linking system at tac 2012: A joint approach. In
TAC (Text Analysis Conference) 2012 Workshop.
Aldo Gangemi. 2013. A Comparison of Knowledge
Extraction Tools for the Semantic Web. In The 10th
Extended Semantic Web Conference (ESWC) 2013.
Xianpei Han and Jun Zhao. 2009. Named entity
disambiguation by leveraging wikipedia semantic
knowledge. In Proceedings of the Conference on
Information and Knowledge Management (CIKM).
ACM.
Johannes Hoffart, Fabian M Suchanek, Klaus
Berberich, Edwin Lewis-Kelham, Gerard De Melo,
and Gerhard Weikum. 2011a. Yago2: exploring and
querying world knowledge in time, space, context,
and many languages. In Proceedings of the 20th
international conference companion on World wide
web, pages 229–232. ACM.
Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bor-
dino, Hagen F¨urstenau, Manfred Pinkal, Marc Span-
iol, Bilyana Taneva, Stefan Thater, and Gerhard
Weikum. 2011b. Robust disambiguation of named
entities in text. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing, pages 782–792. Association for Computational
Linguistics.
Heng Ji, Ralph Grishman, HT Dang, and K Griffitt.
2010. Overview of the TAC 2010 knowledge base
population track. Proceedings of TAC 2010.
Pablo N Mendes, Max Jakob, Andr´es Garc´ıa-Silva, and
Christian Bizer. 2011. DBpedia Spotlight: Shed-
ding Light on the Web of Documents. In The 7th
International Conference on Semantic Systems (I-
Semantics) 2011, pages 1–8.
David N. Milne and Ian H. Witten. 2008. Named en-
tity disambiguation by leveraging wikipedia seman-
tic knowledge. In Proceedings of the Conference on
Information and Knowledge Management (CIKM).
ACM.
Roberto Navigli. 2009. Word sense disambiguation: A
survey. ACM Computing Surveys (CSUR), 41(2):10.
Hien T. Nguyen and Tru H. Cao. 2008. Named
entity disambiguation on an ontology enriched by
wikipedia. In Research, Innovation and Vision for
the Future, 2008. RIVF 2008. IEEE International
Conference on, pages 247–254. IEEE.
Borislav Popov, Atanas Kiryakov, Angel Kirilov, Dimi-
tar Manov, Damyan Ognyanoff, and Miroslav Gora-
nov. 2003. KIM – Semantic annotation platform.
Lecture Notes in Computer Science, pages 834–849.
Michael Strube and Simone Paolo Ponzetto. 2006.
WikiRelate! Computing Semantic Relatedness Us-
ing Wikipedia. In AAAI, volume 6, pages 1419–
1424.
TAC-KBP. 2012. Proposed Task Description for
Knowledge-Base Population at TAC 2012. In Pro-
ceedings of TAC-KBP 2012. National Institute of
Standards and Technology.
</reference>
<page confidence="0.998699">
481
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.578398">
<title confidence="0.999896">Mutual Disambiguation for Entity Linking</title>
<author confidence="0.997989">Eric Charton</author>
<affiliation confidence="0.983585">Polytechnique Montr´eal</affiliation>
<address confidence="0.99341">Montr´eal, QC, Canada</address>
<email confidence="0.998027">eric.charton@polymtl.ca</email>
<author confidence="0.747374">Ludovic Jean-Louis</author>
<affiliation confidence="0.716422">Polytechnique Montr´eal</affiliation>
<email confidence="0.992761">ludovic.jean-louis@polymtl.ca</email>
<abstract confidence="0.995914166666667">The disambiguation algorithm presented in this paper is implemented in SemLinker, an entity linking system. First, named entities are linked to candidate Wikipedia pages by a generic annotation engine. Then, the algorithm re-ranks candidate links according to mutual relations between all the named entities found in the document. The evaluation is based on experiments conducted on the test corpus of the TAC-KBP 2012 entity linking task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S¨oren Auer</author>
<author>Christian Bizer</author>
<author>Georgi Kobilarov</author>
<author>Jens Lehmann</author>
<author>Richard Cyganiak</author>
<author>Zachary Ives</author>
</authors>
<title>Dbpedia: A nucleus for a web of open data.</title>
<date>2007</date>
<booktitle>In The semantic web,</booktitle>
<pages>722--735</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="7264" citStr="Auer et al., 2007" startWordPosition="1139" endWordPosition="1142"> works like (Han and Zhao, 2009) that considered the relatedness of common noun phrases in a mention context with Wikipedia article names. While all these approaches focus on semantic relation between entities, their potential is limited by the separate mapping of candidate links for each mention. 2.2 Semantic Web Compliant Methods More recently, several systems have been launched as web services dedicated to EL tasks. Most of them are compliant with new emergent semantic web standards like LinkedData network. DBPedia Spotlight (Mendes et al., 2011) is a system that finds mentions of DBpedia (Auer et al., 2007) resources in a textual document. Wikimeta (Charton and Gagnon, 2012) is another system relying on DBpedia. It uses bags of words to disambiguate semantic entities according to a cosine similarity algorithm. Those systems have been compared with commercial ones like AlchemyAPI, Zemanta, or Open Calais in (Gangemi, 2013). The study showed that they perform differently on various essential aspects of EL tasks (mention detection, linking, disambiguation). This suggests a wide range of potential improvements on many aspects of the EL task. Only some of these systems introduce the semantic relatedn</context>
</contexts>
<marker>Auer, Bizer, Kobilarov, Lehmann, Cyganiak, Ives, 2007</marker>
<rawString>S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives. 2007. Dbpedia: A nucleus for a web of open data. In The semantic web, pages 722–735. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
<author>Marius Pasca</author>
</authors>
<title>Using encyclopedic knowledge for named entity disambiguation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics (EACL).</booktitle>
<publisher>ACL.</publisher>
<contexts>
<context position="6144" citStr="Bunescu and Pasca, 2006" startWordPosition="962" endWordPosition="965">uss the obtained results, and conclude. 2 Related Work Entity annotation and linking in natural language text has been extensively studied in NLP research. A strong effort has been conducted recently by the TAC-KBP evaluation task (Ji et al., 2010) to create standardized corpus, and annotation standards based on Wikipedia for evaluation and comparison of EL systems. In this paper, we consider the TACKBP framework. We describe below some recent approaches proposed for solving the EL task. 2.1 Wikipedia-based Disambiguation Methods The use of Wikipedia for explicit disambiguation dates back to (Bunescu and Pasca, 2006) who built a system that compared the context of a mention to the Wikipedia categories of an entity candidate. Lately, (Cucerzan, 2007; Milne and Witten, 2008; Nguyen and Cao, 2008) extended this framework by using richer features for similarity comparison. Some authors like Milne and Witten (2008) utilized machine learning methods rather than a similarity function to map mentions to entities. They also introduced the notion of semantic relatedness. Alternative propositions were suggested in other works like (Han and Zhao, 2009) that considered the relatedness of common noun phrases in a menti</context>
</contexts>
<marker>Bunescu, Pasca, 2006</marker>
<rawString>Razvan C. Bunescu and Marius Pasca. 2006. Using encyclopedic knowledge for named entity disambiguation. In Proceedings of the Conference of the European Chapter of the Association for Computational Linguistics (EACL). ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Charton</author>
<author>Michel Gagnon</author>
</authors>
<title>A disambiguation resource extracted from Wikipedia for semantic annotation.</title>
<date>2012</date>
<booktitle>In Proceedings of LREC</booktitle>
<contexts>
<context position="7333" citStr="Charton and Gagnon, 2012" startWordPosition="1149" endWordPosition="1152">ss of common noun phrases in a mention context with Wikipedia article names. While all these approaches focus on semantic relation between entities, their potential is limited by the separate mapping of candidate links for each mention. 2.2 Semantic Web Compliant Methods More recently, several systems have been launched as web services dedicated to EL tasks. Most of them are compliant with new emergent semantic web standards like LinkedData network. DBPedia Spotlight (Mendes et al., 2011) is a system that finds mentions of DBpedia (Auer et al., 2007) resources in a textual document. Wikimeta (Charton and Gagnon, 2012) is another system relying on DBpedia. It uses bags of words to disambiguate semantic entities according to a cosine similarity algorithm. Those systems have been compared with commercial ones like AlchemyAPI, Zemanta, or Open Calais in (Gangemi, 2013). The study showed that they perform differently on various essential aspects of EL tasks (mention detection, linking, disambiguation). This suggests a wide range of potential improvements on many aspects of the EL task. Only some of these systems introduce the semantic relatedness in their methods like the AIDA (Hoffart et al., 2011b) system. It</context>
</contexts>
<marker>Charton, Gagnon, 2012</marker>
<rawString>Eric Charton and Michel Gagnon. 2012. A disambiguation resource extracted from Wikipedia for semantic annotation. In Proceedings of LREC 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Charton</author>
<author>Marie-Jean Meurs</author>
<author>Ludovic Jean-Louis</author>
<author>Michel Gagnon</author>
</authors>
<title>SemLinker system for KBP2013: A disambiguation algorithm based on mutual relations of semantic annotations inside a document.</title>
<date>2013</date>
<booktitle>In Text Analysis Conference KBP. U.S. National Institute of Standards and Technology (NIST).</booktitle>
<contexts>
<context position="17221" citStr="Charton et al., 2013" startWordPosition="2822" endWordPosition="2825">en 511 and 512, i.e. the number of URIs and categories appearing in both International Brotherhood of Magicians and Thomas Watson, Jr. pages. csr score(URI21) counts the number of URIs and categories appearing in both International Business Machines Corporation and Thomas Watson, Jr. pages. After calculation, we have: mutual relation score(URII) &lt; mutual relation score(URII) The candidate URIs for [IBM] are re-ranked accordingly, and International Business Machines Corporation becomes its first rank candidate. 4 Experiments and Results SemLinker has been evaluated on the TAC-KBP 2012 EL task (Charton et al., 2013). In this task, mentions of entities found in a document collection must be linked to entities in a reference KB, or to new named entities discovered in the collection. The document collection built for KBP 2012 contains a combination of newswire articles (News), 479 TAC-KBP2012 systems modules no disambiguation Category B3+P B3+R B3+F1 Overall 0.620 0.633 0.626 PER 0.771 0.791 0.781 ORG 0.600 0.571 0.585 GPE 0.412 0.465 0.437 News 0.663 0.691 0.677 Web 0.536 0.520 0.528 1st 0.730 0.809 0.715 0.627 0.782 0.630 2nd 0.699 0.840 0.615 0.579 0.759 0.580 3rd B3+F1 0.689 0.714 0.717 0.614 0.710 0.50</context>
</contexts>
<marker>Charton, Meurs, Jean-Louis, Gagnon, 2013</marker>
<rawString>Eric Charton, Marie-Jean Meurs, Ludovic Jean-Louis, and Michel Gagnon. 2013. SemLinker system for KBP2013: A disambiguation algorithm based on mutual relations of semantic annotations inside a document. In Text Analysis Conference KBP. U.S. National Institute of Standards and Technology (NIST).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Charton</author>
<author>Marie-Jean Meurs</author>
<author>Ludovic Jean-Louis</author>
<author>Michel Gagnon</author>
</authors>
<title>Improving Entity Linking using Surface Form Refinement.</title>
<date>2014</date>
<booktitle>In Proceedings of LREC</booktitle>
<contexts>
<context position="9030" citStr="Charton et al., 2014" startWordPosition="1414" endWordPosition="1417">ument along with linguistic and semantic annotations as described hereafter. 3.1 Annotation Object Documents are processed by an annotator capable of producing POS tags for each word, as well as spans, NE surface forms, NE labels and ranked candidate Wikipedia URIs for each candidate NE. For each document D, this knowledge is gathered 477 in an array called annotation object, which has initially one row per document lexical unit. Since the system focuses on NEs, rows with lexical units that do not belong to a NE SF are dropped from the annotation object, and NE SF are refined as described in (Charton et al., 2014). When NE SF are spanned over several rows, these rows are merged into a single one. Thus, we consider an annotation object AD, which is an array with a row for each NE, and columns storing related knowledge. If n NEs were annotated in D, then AD has n rows. If l candidate URIs are provided for each NE, then AD has (l + 4) columns cu,uE{1,l+4}. Columns c1 to cl store Wikipedia URIs associated with NEs, ordered by decreasing values of likelihood. Column cl+1 stores the offset of the NEs, cl+2 stores their surface forms, cl+3 stores the NE labels (PER, ORG, ...), and cl+4 stores the (vectors of)</context>
</contexts>
<marker>Charton, Meurs, Jean-Louis, Gagnon, 2014</marker>
<rawString>Eric Charton, Marie-Jean Meurs, Ludovic Jean-Louis, and Michel Gagnon. 2014. Improving Entity Linking using Surface Form Refinement. In Proceedings of LREC 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
</authors>
<title>Large-scale named entity disambiguation based on wikipedia data.</title>
<date>2007</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing EMNLP-CoNLL. ACL.</booktitle>
<contexts>
<context position="6278" citStr="Cucerzan, 2007" startWordPosition="986" endWordPosition="987">P research. A strong effort has been conducted recently by the TAC-KBP evaluation task (Ji et al., 2010) to create standardized corpus, and annotation standards based on Wikipedia for evaluation and comparison of EL systems. In this paper, we consider the TACKBP framework. We describe below some recent approaches proposed for solving the EL task. 2.1 Wikipedia-based Disambiguation Methods The use of Wikipedia for explicit disambiguation dates back to (Bunescu and Pasca, 2006) who built a system that compared the context of a mention to the Wikipedia categories of an entity candidate. Lately, (Cucerzan, 2007; Milne and Witten, 2008; Nguyen and Cao, 2008) extended this framework by using richer features for similarity comparison. Some authors like Milne and Witten (2008) utilized machine learning methods rather than a similarity function to map mentions to entities. They also introduced the notion of semantic relatedness. Alternative propositions were suggested in other works like (Han and Zhao, 2009) that considered the relatedness of common noun phrases in a mention context with Wikipedia article names. While all these approaches focus on semantic relation between entities, their potential is li</context>
</contexts>
<marker>Cucerzan, 2007</marker>
<rawString>Silviu Cucerzan. 2007. Large-scale named entity disambiguation based on wikipedia data. In Proceedings of the Conference on Empirical Methods in Natural Language Processing EMNLP-CoNLL. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joe Ellis</author>
<author>Xuansong Li</author>
<author>Kira Griffitt</author>
<author>Stephanie M Strassel</author>
<author>Jonathan Wright</author>
</authors>
<title>Linguistic resources for 2012 knowledge base population evaluations.</title>
<date>2011</date>
<booktitle>In Proceedings of TAC-KBP</booktitle>
<contexts>
<context position="19167" citStr="Ellis et al., 2011" startWordPosition="3153" endWordPosition="3156">y if it is not already in the reference KB. Entities can be of type person (PER), organization (ORG), or geopolitical entity (GPE). The reference knowledge base is derived from an October 2008 dump of English Wikipedia, which includes 818,741 nodes. Table 2 provides a breakdown of the queries per categories of entities, and per type of documents. Category All PER ORG GPE News Web # queries 2226 918 706 602 1471 755 Table 2: Breakdown of the TAC-KBP 2012 test corpus queries according to entity types, and document categories. A complete description of these linguistic resources can be found in (Ellis et al., 2011). For the sake of reproducibility, we applied the KBP scoring metric (B3 + F) described in (TAC-KBP, 2012), and we used the KBP scorer1. The evaluated system makes use of the Wikimeta annotation engine. The maximum number of candidate URIs is l = 15. The MDP correction parameters α and Q described in Section 3.4 have been experimentally set to α = 10, Q = 2. Table 1 presents the results obtained by the system in three configurations. In the first column, the system is evaluated without the disambiguation module. In the second column, we applied the MDP without correction processes. The system </context>
</contexts>
<marker>Ellis, Li, Griffitt, Strassel, Wright, 2011</marker>
<rawString>Joe Ellis, Xuansong Li, Kira Griffitt, Stephanie M Strassel, and Jonathan Wright. 2011. Linguistic resources for 2012 knowledge base population evaluations. In Proceedings of TAC-KBP 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angela Fahrni</author>
<author>Thierry G¨ockel</author>
<author>Michael Strube</author>
</authors>
<title>Hitsmonolingual and cross-lingual entity linking system at tac 2012: A joint approach.</title>
<date>2012</date>
<booktitle>In TAC (Text Analysis Conference) 2012 Workshop.</booktitle>
<marker>Fahrni, G¨ockel, Strube, 2012</marker>
<rawString>Angela Fahrni, Thierry G¨ockel, and Michael Strube. 2012. Hitsmonolingual and cross-lingual entity linking system at tac 2012: A joint approach. In TAC (Text Analysis Conference) 2012 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aldo Gangemi</author>
</authors>
<title>A Comparison of Knowledge Extraction Tools for the Semantic Web.</title>
<date>2013</date>
<booktitle>In The 10th Extended Semantic Web Conference (ESWC)</booktitle>
<contexts>
<context position="7585" citStr="Gangemi, 2013" startWordPosition="1189" endWordPosition="1190"> Methods More recently, several systems have been launched as web services dedicated to EL tasks. Most of them are compliant with new emergent semantic web standards like LinkedData network. DBPedia Spotlight (Mendes et al., 2011) is a system that finds mentions of DBpedia (Auer et al., 2007) resources in a textual document. Wikimeta (Charton and Gagnon, 2012) is another system relying on DBpedia. It uses bags of words to disambiguate semantic entities according to a cosine similarity algorithm. Those systems have been compared with commercial ones like AlchemyAPI, Zemanta, or Open Calais in (Gangemi, 2013). The study showed that they perform differently on various essential aspects of EL tasks (mention detection, linking, disambiguation). This suggests a wide range of potential improvements on many aspects of the EL task. Only some of these systems introduce the semantic relatedness in their methods like the AIDA (Hoffart et al., 2011b) system. It proposes a disambiguation method that combines popularity-based priors, similarity measures, and coherence. It relies on the Wikipedia-derived YAGO2 (Hoffart et al., 2011a) knowledge base. 3 Proposed Algorithm We propose a mutual disambiguation algori</context>
</contexts>
<marker>Gangemi, 2013</marker>
<rawString>Aldo Gangemi. 2013. A Comparison of Knowledge Extraction Tools for the Semantic Web. In The 10th Extended Semantic Web Conference (ESWC) 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianpei Han</author>
<author>Jun Zhao</author>
</authors>
<title>Named entity disambiguation by leveraging wikipedia semantic knowledge.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Information and Knowledge Management (CIKM).</booktitle>
<publisher>ACM.</publisher>
<contexts>
<context position="6678" citStr="Han and Zhao, 2009" startWordPosition="1045" endWordPosition="1048"> use of Wikipedia for explicit disambiguation dates back to (Bunescu and Pasca, 2006) who built a system that compared the context of a mention to the Wikipedia categories of an entity candidate. Lately, (Cucerzan, 2007; Milne and Witten, 2008; Nguyen and Cao, 2008) extended this framework by using richer features for similarity comparison. Some authors like Milne and Witten (2008) utilized machine learning methods rather than a similarity function to map mentions to entities. They also introduced the notion of semantic relatedness. Alternative propositions were suggested in other works like (Han and Zhao, 2009) that considered the relatedness of common noun phrases in a mention context with Wikipedia article names. While all these approaches focus on semantic relation between entities, their potential is limited by the separate mapping of candidate links for each mention. 2.2 Semantic Web Compliant Methods More recently, several systems have been launched as web services dedicated to EL tasks. Most of them are compliant with new emergent semantic web standards like LinkedData network. DBPedia Spotlight (Mendes et al., 2011) is a system that finds mentions of DBpedia (Auer et al., 2007) resources in </context>
</contexts>
<marker>Han, Zhao, 2009</marker>
<rawString>Xianpei Han and Jun Zhao. 2009. Named entity disambiguation by leveraging wikipedia semantic knowledge. In Proceedings of the Conference on Information and Knowledge Management (CIKM). ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Hoffart</author>
<author>Fabian M Suchanek</author>
<author>Klaus Berberich</author>
<author>Edwin Lewis-Kelham</author>
<author>Gerard De Melo</author>
<author>Gerhard Weikum</author>
</authors>
<title>Yago2: exploring and querying world knowledge in time, space, context, and many languages.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th international conference companion on World wide web,</booktitle>
<pages>229--232</pages>
<publisher>ACM.</publisher>
<marker>Hoffart, Suchanek, Berberich, Lewis-Kelham, De Melo, Weikum, 2011</marker>
<rawString>Johannes Hoffart, Fabian M Suchanek, Klaus Berberich, Edwin Lewis-Kelham, Gerard De Melo, and Gerhard Weikum. 2011a. Yago2: exploring and querying world knowledge in time, space, context, and many languages. In Proceedings of the 20th international conference companion on World wide web, pages 229–232. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Hoffart</author>
<author>Mohamed Amir Yosef</author>
<author>Ilaria Bordino</author>
<author>Hagen F¨urstenau</author>
<author>Manfred Pinkal</author>
<author>Marc Spaniol</author>
<author>Bilyana Taneva</author>
<author>Stefan Thater</author>
<author>Gerhard Weikum</author>
</authors>
<title>Robust disambiguation of named entities in text.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>782--792</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Hoffart, Yosef, Bordino, F¨urstenau, Pinkal, Spaniol, Taneva, Thater, Weikum, 2011</marker>
<rawString>Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen F¨urstenau, Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, and Gerhard Weikum. 2011b. Robust disambiguation of named entities in text. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 782–792. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>HT Dang</author>
<author>K Griffitt</author>
</authors>
<title>knowledge base population track.</title>
<date>2010</date>
<journal>Overview of the TAC</journal>
<booktitle>Proceedings of TAC</booktitle>
<contexts>
<context position="5768" citStr="Ji et al., 2010" startWordPosition="905" endWordPosition="908">annotation in a document. This paper is organized as follows. Section 2 describes related works. The proposed method is presented in Section 3 where we explain how our SemLinker system prepares documents that contain mentions to disambiguate, then we detail the disambiguation algorithm. The evaluation of the complete system is provided in Section 4. Finally, we discuss the obtained results, and conclude. 2 Related Work Entity annotation and linking in natural language text has been extensively studied in NLP research. A strong effort has been conducted recently by the TAC-KBP evaluation task (Ji et al., 2010) to create standardized corpus, and annotation standards based on Wikipedia for evaluation and comparison of EL systems. In this paper, we consider the TACKBP framework. We describe below some recent approaches proposed for solving the EL task. 2.1 Wikipedia-based Disambiguation Methods The use of Wikipedia for explicit disambiguation dates back to (Bunescu and Pasca, 2006) who built a system that compared the context of a mention to the Wikipedia categories of an entity candidate. Lately, (Cucerzan, 2007; Milne and Witten, 2008; Nguyen and Cao, 2008) extended this framework by using richer fe</context>
</contexts>
<marker>Ji, Grishman, Dang, Griffitt, 2010</marker>
<rawString>Heng Ji, Ralph Grishman, HT Dang, and K Griffitt. 2010. Overview of the TAC 2010 knowledge base population track. Proceedings of TAC 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pablo N Mendes</author>
<author>Max Jakob</author>
<author>Andr´es Garc´ıa-Silva</author>
<author>Christian Bizer</author>
</authors>
<title>DBpedia Spotlight: Shedding Light on the Web of Documents.</title>
<date>2011</date>
<booktitle>In The 7th International Conference on Semantic Systems (ISemantics)</booktitle>
<pages>1--8</pages>
<marker>Mendes, Jakob, Garc´ıa-Silva, Bizer, 2011</marker>
<rawString>Pablo N Mendes, Max Jakob, Andr´es Garc´ıa-Silva, and Christian Bizer. 2011. DBpedia Spotlight: Shedding Light on the Web of Documents. In The 7th International Conference on Semantic Systems (ISemantics) 2011, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David N Milne</author>
<author>Ian H Witten</author>
</authors>
<title>Named entity disambiguation by leveraging wikipedia semantic knowledge.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Information and Knowledge Management (CIKM).</booktitle>
<publisher>ACM.</publisher>
<contexts>
<context position="6302" citStr="Milne and Witten, 2008" startWordPosition="988" endWordPosition="991">rong effort has been conducted recently by the TAC-KBP evaluation task (Ji et al., 2010) to create standardized corpus, and annotation standards based on Wikipedia for evaluation and comparison of EL systems. In this paper, we consider the TACKBP framework. We describe below some recent approaches proposed for solving the EL task. 2.1 Wikipedia-based Disambiguation Methods The use of Wikipedia for explicit disambiguation dates back to (Bunescu and Pasca, 2006) who built a system that compared the context of a mention to the Wikipedia categories of an entity candidate. Lately, (Cucerzan, 2007; Milne and Witten, 2008; Nguyen and Cao, 2008) extended this framework by using richer features for similarity comparison. Some authors like Milne and Witten (2008) utilized machine learning methods rather than a similarity function to map mentions to entities. They also introduced the notion of semantic relatedness. Alternative propositions were suggested in other works like (Han and Zhao, 2009) that considered the relatedness of common noun phrases in a mention context with Wikipedia article names. While all these approaches focus on semantic relation between entities, their potential is limited by the separate ma</context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>David N. Milne and Ian H. Witten. 2008. Named entity disambiguation by leveraging wikipedia semantic knowledge. In Proceedings of the Conference on Information and Knowledge Management (CIKM). ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word sense disambiguation: A survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys (CSUR),</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="1669" citStr="Navigli, 2009" startWordPosition="252" endWordPosition="253">ce mentions are often highly polysemous, and potentially related to many different KB entries. Various approaches have been proposed to solve the named entity disambiguation (NED) problem. Most of them involve the use of surface forms extracted from Wikipedia. Surface forms consist of a word or a group of words that match lexical units like Paris or New York City. They are used as matching sequences to locate corresponding candidate entries in the KB, and then to disambiguate those candidates using similarity measures. The NED problem is related to the Word Sense Disambiguation (WSD) problem (Navigli, 2009), and is often more challenging since mentions of NEs can be highly ambiguous. For instance, names of places can be very common as is Paris, which refers to 26 different places in Wikipedia. Hence, systems that attempt to address the NED Marie-Jean Meurs Concordia University Montr´eal, QC, Canada marie-jean.meurs@concordia.ca Michel Gagnon Polytechnique Montr´eal michel.gagnon@polymtl.ca problem must include disambiguation resources. In the context of the Named Entity Recognition (NER) task, such resources can be generic and generative. This generative approach does not apply to the EL task wh</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word sense disambiguation: A survey. ACM Computing Surveys (CSUR), 41(2):10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hien T Nguyen</author>
<author>Tru H Cao</author>
</authors>
<title>Named entity disambiguation on an ontology enriched by wikipedia.</title>
<date>2008</date>
<booktitle>In Research, Innovation and Vision for the Future,</booktitle>
<pages>247--254</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="6325" citStr="Nguyen and Cao, 2008" startWordPosition="992" endWordPosition="995">ducted recently by the TAC-KBP evaluation task (Ji et al., 2010) to create standardized corpus, and annotation standards based on Wikipedia for evaluation and comparison of EL systems. In this paper, we consider the TACKBP framework. We describe below some recent approaches proposed for solving the EL task. 2.1 Wikipedia-based Disambiguation Methods The use of Wikipedia for explicit disambiguation dates back to (Bunescu and Pasca, 2006) who built a system that compared the context of a mention to the Wikipedia categories of an entity candidate. Lately, (Cucerzan, 2007; Milne and Witten, 2008; Nguyen and Cao, 2008) extended this framework by using richer features for similarity comparison. Some authors like Milne and Witten (2008) utilized machine learning methods rather than a similarity function to map mentions to entities. They also introduced the notion of semantic relatedness. Alternative propositions were suggested in other works like (Han and Zhao, 2009) that considered the relatedness of common noun phrases in a mention context with Wikipedia article names. While all these approaches focus on semantic relation between entities, their potential is limited by the separate mapping of candidate link</context>
</contexts>
<marker>Nguyen, Cao, 2008</marker>
<rawString>Hien T. Nguyen and Tru H. Cao. 2008. Named entity disambiguation on an ontology enriched by wikipedia. In Research, Innovation and Vision for the Future, 2008. RIVF 2008. IEEE International Conference on, pages 247–254. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Borislav Popov</author>
</authors>
<title>Atanas Kiryakov, Angel Kirilov, Dimitar Manov, Damyan Ognyanoff, and Miroslav Goranov.</title>
<date>2003</date>
<booktitle>KIM – Semantic annotation platform. Lecture Notes in Computer Science,</booktitle>
<pages>834--849</pages>
<marker>Popov, 2003</marker>
<rawString>Borislav Popov, Atanas Kiryakov, Angel Kirilov, Dimitar Manov, Damyan Ognyanoff, and Miroslav Goranov. 2003. KIM – Semantic annotation platform. Lecture Notes in Computer Science, pages 834–849.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>WikiRelate! Computing Semantic Relatedness Using Wikipedia.</title>
<date>2006</date>
<booktitle>In AAAI,</booktitle>
<volume>6</volume>
<pages>1419--1424</pages>
<contexts>
<context position="3210" citStr="Strube and Ponzetto, 2006" startWordPosition="488" endWordPosition="491">t the potential target entities (see for instance the KIM system (Popov et al., 2003)). This is usually done using similarity measures (such as cosine similarity, weighted Jaccard distance, KL divergence...) that evaluate the distance between a bag of words related to a candidate annotation, and the words surrounding the entity to annotate in the text. In more recent approaches, it is suggested that annotation processes based on similarity distance measures can be improved by making use of other annotations present in the same document. Such techniques are referred to as semantic relatedness (Strube and Ponzetto, 2006), collective disambiguation (Hoffart et al., 2011b), or joint disambiguation (Fahrni et al., 2012). The idea is to evaluate in a set of candidate links which one is the most likely to be correct by taking the other links contained in the document into account. For example, if a NE describes a city name like Paris, it is more probable that the correct link for this city name designates Paris (France) rather than Paris (Texas) if a neighbor entity offers candidate links semantically related to Paris (France) like the Seine river or the Champs-Elys´ees. Such techniques mostly involve exploration </context>
</contexts>
<marker>Strube, Ponzetto, 2006</marker>
<rawString>Michael Strube and Simone Paolo Ponzetto. 2006. WikiRelate! Computing Semantic Relatedness Using Wikipedia. In AAAI, volume 6, pages 1419– 1424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>TAC-KBP</author>
</authors>
<title>Proposed Task Description for Knowledge-Base Population at TAC</title>
<date>2012</date>
<booktitle>In Proceedings of TAC-KBP 2012. National Institute of Standards and Technology.</booktitle>
<contexts>
<context position="624" citStr="TAC-KBP 2012" startWordPosition="82" endWordPosition="83">biguation for Entity Linking Eric Charton Polytechnique Montr´eal Montr´eal, QC, Canada eric.charton@polymtl.ca Ludovic Jean-Louis Polytechnique Montr´eal ludovic.jean-louis@polymtl.ca Abstract The disambiguation algorithm presented in this paper is implemented in SemLinker, an entity linking system. First, named entities are linked to candidate Wikipedia pages by a generic annotation engine. Then, the algorithm re-ranks candidate links according to mutual relations between all the named entities found in the document. The evaluation is based on experiments conducted on the test corpus of the TAC-KBP 2012 entity linking task. 1 Introduction The Entity Linking (EL) task consists in linking name mentions of named entities (NEs) found in a document to their corresponding entities in a reference Knowledge Base (KB). These NEs can be of type person (PER), organization (ORG), etc., and they are usually represented in the KB by a Uniform Resource Identifier (URI). Dealing with ambiguity is one of the key difficulties in this task, since mentions are often highly polysemous, and potentially related to many different KB entries. Various approaches have been proposed to solve the named entity disambigua</context>
<context position="17190" citStr="TAC-KBP 2012" startWordPosition="2818" endWordPosition="2819">s and categories between 511 and 512, i.e. the number of URIs and categories appearing in both International Brotherhood of Magicians and Thomas Watson, Jr. pages. csr score(URI21) counts the number of URIs and categories appearing in both International Business Machines Corporation and Thomas Watson, Jr. pages. After calculation, we have: mutual relation score(URII) &lt; mutual relation score(URII) The candidate URIs for [IBM] are re-ranked accordingly, and International Business Machines Corporation becomes its first rank candidate. 4 Experiments and Results SemLinker has been evaluated on the TAC-KBP 2012 EL task (Charton et al., 2013). In this task, mentions of entities found in a document collection must be linked to entities in a reference KB, or to new named entities discovered in the collection. The document collection built for KBP 2012 contains a combination of newswire articles (News), 479 TAC-KBP2012 systems modules no disambiguation Category B3+P B3+R B3+F1 Overall 0.620 0.633 0.626 PER 0.771 0.791 0.781 ORG 0.600 0.571 0.585 GPE 0.412 0.465 0.437 News 0.663 0.691 0.677 Web 0.536 0.520 0.528 1st 0.730 0.809 0.715 0.627 0.782 0.630 2nd 0.699 0.840 0.615 0.579 0.759 0.580 3rd B3+F1 0.6</context>
<context position="19005" citStr="TAC-KBP 2012" startWordPosition="3128" endWordPosition="3129">t with a specified name mention of an entity, the task is to determine the correct node in the reference KB for the entity, adding a new node for the entity if it is not already in the reference KB. Entities can be of type person (PER), organization (ORG), or geopolitical entity (GPE). The reference knowledge base is derived from an October 2008 dump of English Wikipedia, which includes 818,741 nodes. Table 2 provides a breakdown of the queries per categories of entities, and per type of documents. Category All PER ORG GPE News Web # queries 2226 918 706 602 1471 755 Table 2: Breakdown of the TAC-KBP 2012 test corpus queries according to entity types, and document categories. A complete description of these linguistic resources can be found in (Ellis et al., 2011). For the sake of reproducibility, we applied the KBP scoring metric (B3 + F) described in (TAC-KBP, 2012), and we used the KBP scorer1. The evaluated system makes use of the Wikimeta annotation engine. The maximum number of candidate URIs is l = 15. The MDP correction parameters α and Q described in Section 3.4 have been experimentally set to α = 10, Q = 2. Table 1 presents the results obtained by the system in three configurations. </context>
</contexts>
<marker>TAC-KBP, 2012</marker>
<rawString>TAC-KBP. 2012. Proposed Task Description for Knowledge-Base Population at TAC 2012. In Proceedings of TAC-KBP 2012. National Institute of Standards and Technology.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>