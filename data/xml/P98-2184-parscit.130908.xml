<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.715289">
How Verb Subcategorization Frequencies Are Affected By Corpus Choice
</title>
<author confidence="0.707231">
Douglas Roland
</author>
<affiliation confidence="0.813541285714286">
University of Colorado
Department of Linguistics
Boulder, CO 80309-0295
Dougl as.Rol and @ col orado. edu
Daniel Jurafsky
University of Colorado
Dept. of Linguistics &amp; Inst. of Cognitive Science
</affiliation>
<address confidence="0.330026">
Boulder, CO 80309-0295
</address>
<email confidence="0.93889">
jurafsky@colorado.edu
</email>
<sectionHeader confidence="0.95951" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999404709677419">
The probabilistic relation between verbs and
their arguments plays an important role in
modern statistical parsers and supertaggers,
and in psychological theories of language
processing. But these probabilities are
computed in very different ways by the two
sets of researchers. Computational linguists
compute verb subcategorization probabilities
from large corpora while psycholinguists
compute them from psychological studies
(sentence production and completion tasks).
Recent studies have found differences
between corpus frequencies and
psycholinguistic measures. We analyze
subcategorization frequencies from four
different corpora: psychological sentence
production data (Connine et al. 1984), written
text (Brown and WSJ), and telephone
conversation data (Switchboard). We find
two different sources for the differences.
Discourse influence is a result of how verb
use is affected by different discourse types
such as narrative, connected discourse, and
single sentence productions. Semantic
influence is a result of different corpora using
different senses of verbs, which have different
subcategorization frequencies. We conclude
that verb sense and discourse type play an
important role in the frequencies observed in
different experimental and corpus based
sources of verb subcategorization frequencies.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999814333333333">
The probabilistic relation between verbs and their
arguments plays an important role in modern
statistical parsers and supertaggers (Charniak
1995, Collins 1996/1997, Joshi and Srinivas 1994,
Kim, Srinivas, and Trueswell 1997, Stolcke et al.
1997), and in psychological theories of language
processing (Clifton et al. 1984, Ferreira &amp;
McClure 1997, Garnsey et al. 1997, Jurafsky 1996,
MacDonald 1994, Mitchell &amp; Holmes 1985,
Tanenhaus et al. 1990, Trueswell et al. 1993).
These probabilities are computed in very different
ways by the two sets of researchers.
Psychological studies use methods such as
sentence completion and sentence production for
collecting verb argument structure probabilities.
In sentence completion, subjects are asked to
complete a sentence fragment. Garnsey at al.
(1997) used a proper name followed by a verb,
such as &amp;quot;Debbie remembered &amp;quot; In
sentence subjects are asked to write any sentence
containing a given verb. An example of this type
of study is Confine et al. (1984).
An alternative to these psychological methods is
to use corpus data. This can be done
automatically with unparsed corpora (Briscoe and
Carroll 1997, Manning 1993, Ushioda et al. 1993),
from parsed corpora such as Marcus et al.&apos;s (1993)
Treebank (Merlo 1994, Framis 1994) or manually
as was done for COMLEX (Macleod and
Grishman 1994). The advantage of any of these
corpus methods is the much greater amount of
data that can be used, and the much more natural
contexts. This seems to make it preferable to
data generated in psychological studies.
Recent studies (Merlo 1994, Gibson et al. 1996)
have found differences between corpus
frequencies and experimental measures. This
suggests that corpus-based frequencies and
experiment-based frequencies may not be
interchangeable. To clarify the nature of the
differences between various corpora and to find
the causes of these differences, we analyzed
</bodyText>
<page confidence="0.99144">
1122
</page>
<bodyText confidence="0.999454">
psychological sentence production data (Connine
et al. 1984), written discourse (Brown and WSJ
from Penn Treebank - Marcus et al. 1993), and
conversational data (Switchboard - Godfrey et al.
1992). We found that the subcategorization
frequencies in each of these sources are different.
We performed three experiments to (1) find the
causes of general differences between corpora, (2)
measure the size of these differences, and (3) find
verb specific differences. The rest of this paper
describes our methodology and the two sources of
subcategorization probability differences:
discourse influence and semantic influence.
</bodyText>
<sectionHeader confidence="0.996283" genericHeader="introduction">
2 Methodology
</sectionHeader>
<bodyText confidence="0.999770285714286">
For the sentence production data, we used the
numbers published in the original Connine et al.
paper as well as the original data, which we were
able to review thanks to the generosity of Charles
Clifton. The Connine data (CFJCF) consists of
examples of 127 verbs, each classified as
belonging to one of 15 subcategorization frames.
We added a 16th category for direct quotations
(which appeared in the corpus data but not the
Connine data). Examples of these categories,
taken from the Brown Corpus, appear in figure 1
below. There are approximately 14,000 verb
tokens in the CFJCF data set.
For the BC, WSJ, and SWBD data, we counted
subcategorizations using tgrep scripts based on the
Penn Treebank. We automatically extracted and
categorized all examples of the 127 verbs used in
the Connine study. We used the same verb
subcategorization categories as the Connine study.
There were approximately 21,000 relevant verb
tokens in the Brown Corpus, 25,000 relevant verb
</bodyText>
<listItem confidence="0.831837652173913">
1 [0] Barbara asked, as they heard the front door close.
2 [PP] Guerrillas were racing [toward him].
3 [mf-S] Hank thanked them and promised [to observe the rules].
4 [inf-S]/PP/ Labor fights [to change its collar from blue to white].
5 [wh-S] I know now [why the students insisted that I go to Hiroshima even when I told them I didn&apos;t
want to].
6 [that-S] She promised [that she would soon take a few day&apos;s leave and visit the uncle she had never
seen, on the island of Oyajima --which was not very far from Yokosuka].
7 [verb-ing] But I couldn&apos;t help [thinking that Nadine and Wally were getting just what they deserved].
8 [perception Far off, in the dusk, he heard [voices singing, muffled but strong].
complement.]
9 [NP] The turtle immediately withdrew into its private council room to study [the phenomenon].
10 [NP][NP] The mayor of the town taught [them] [English and French].
11 [NP][PP] They bought [rustled cattle] [from the outlaw], kept him supplied with guns and
ammunition, harbored his men in their houses.
12 [NP][inf-S] She had assumed before then that one day he would ask [her] [to marry him].
13 [NP][wh-S] I asked [Wisman] [what would happen if he broke out the go codes and tried to start
transmitting one].
14 [NP][that-S] But, in departing, Lewis begged [Breasted] [that there be no liquor in the apartment at the
Grosvenor on his return], and he took with him the first thirty galleys of Elmer Gantry.
15 [passive] A cold supper was ordered and a bottle of port.
16 Quotes He writes [&amp;quot;Confucius held that in times of stress, one should take short views â€” only up to
lunchtime.&amp;quot;]
</listItem>
<figureCaption confidence="0.88738">
Figure 1 - examples of each subcategorization frame from Brown Corpus
</figureCaption>
<page confidence="0.961342">
1123
</page>
<bodyText confidence="0.999827583333333">
tokens in the Wall Street Journal Corpus, and
10,000 in Switchboard. Unlike the Connine data,
where all verbs were equally represented, the
frequencies of each verb in the corpora varied.
For each calculation where individual verb
frequency could affect the outcome, we
normalized for frequency, and eliminated verbs
with less than 50 examples. This left 77 out of
127 verbs in the Brown Corpus, 74 in the Wall
Street Journal, and only 30 verbs in Switchboard.
This was not a problem with the Connine data
where most verbs had approximately 100 tokens.
</bodyText>
<sectionHeader confidence="0.9967" genericHeader="method">
3 Experiment 1
</sectionHeader>
<bodyText confidence="0.9999092">
The purpose of the first experiment is to analyze
the general (non-verb-specific) differences
between argument structure frequencies in the
data sources. In order to do this, the data for each
verb in the corpus was normalized to remove the
effects of verb frequency. The average
frequency of each subcategorization frame was
calculated for each corpus. The average
frequencies for each of the data sources were then
compared.
</bodyText>
<subsectionHeader confidence="0.902361">
3.1 Results
</subsectionHeader>
<bodyText confidence="0.999948428571429">
We found that the three corpora consisting of
connected discourse (BC, WSJ, SWBD) shared a
common set of differences when compared to the
CFJCF sentence production data. There were
three general categories of differences between the
corpora, and all can be related to discourse type.
These categories are:
</bodyText>
<listItem confidence="0.999308333333333">
(1) passive sentences
(2) zero anaphora
(3) quotations
</listItem>
<subsubsectionHeader confidence="0.933621">
3.1.1 Passive Sentences
</subsubsectionHeader>
<bodyText confidence="0.9998984">
The CFJCF single sentence productions had the
smallest number of passive sentences. The
connected spoken discourse in Switchboard had
more passives, followed by the written discourse
in the Wall Street Journal and the Brown Corpus.
</bodyText>
<table confidence="0.9623088">
Data Source % passive sentences
CFJCF 0.6%
Switchboard 2.2%
Wall Street Journal 6.7%
Brown Corpus 7.8%
</table>
<bodyText confidence="0.9994888">
Passive is generally used in English to emphasize
the undergoer (to keep the topic in subject
position) and/or to de-emphasize the identity of
the agent (Thompson 1987). Both of these
reasons are affected by the type of discourse. If
there is no preceding discourse, then there is no
pre-existing topic to keep in subject position. In
addition, with no context for the sentence, there is
less likely to be a reason to de-emphasize the
agent of the sentence.
</bodyText>
<subsubsectionHeader confidence="0.976278">
3.1.2 Zero Anaphora
</subsubsectionHeader>
<bodyText confidence="0.996994">
The increase in zero anaphora (not overtly
mentioning understood arguments) is caused by
two factors. Generally, as the amount of
surrounding context increases (going from single
sentence to connected discourse) the need to
overtly express all of the arguments with a verb
decreases.
</bodyText>
<table confidence="0.904039">
Data Source % [0] subcat frame
CFJCF 7%
Wall Street Journal 8%
Brown 13%
Switchboard 18%
</table>
<bodyText confidence="0.967124727272727">
Verbs that can describe actions (agree, disappear,
escape, follow, leave, sing, wait) were typically
used with some form of argument in single
sentences, such as:
&amp;quot;I had a test that day, so I really wanted to escape
from school.&amp;quot; (CFJCF data).
Such verbs were more likely to be used without
any arguments in connected discourse as in:
&amp;quot;She escaped , crawled through the usual mine
fields, under barbed wire, was shot at, swam a
river, and we finally picked her up in Linz.&amp;quot;
(Brown Corpus)
In this case, the argument of &amp;quot;escaped&amp;quot;,
(&amp;quot;imprisonment&amp;quot;) was understood from the
previous sentence. Verbs of propositional
attitude (agree, guess, know, see, understand) are
typically used transitively in written corpora and
single-sentence production:
&amp;quot;I guessed the right answer on the quiz.&amp;quot;
(CFJCF).
In spoken discourse, these verbs are more likely to
be used metalinguistically, with the previous
</bodyText>
<page confidence="0.980179">
1124
</page>
<bodyText confidence="0.951431">
discourse contribution understood as the argument
of the verb:
</bodyText>
<note confidence="0.625829">
&amp;quot;I see.&amp;quot; (Switchboard)
&amp;quot;I guess.&amp;quot; (Switchboard)
</note>
<subsubsectionHeader confidence="0.295195">
3.1.3 Quotations
</subsubsectionHeader>
<bodyText confidence="0.3195598">
Quotations are usually used in narrative, which is
more likely in connected discourse than in an
isolated sentence. This difference mainly effects
verbs of communication (e.g. answer, ask, call,
describe, read, say, write).
</bodyText>
<table confidence="0.999346">
Data Source Percent Direct
Quotation
CFJCF 0%
Switchboard 0%
Brown 4%
Wall Street Journal 6%
</table>
<bodyText confidence="0.992395636363636">
These verbs are used in corpora to discuss details
of the contents of communication:
&amp;quot;Turning to the reporters, she asked, &apos;Did you
hear her? &amp;quot;(Brown)
In single sentence production, they are used to
describe the (new) act of communication itself:
&amp;quot;Ile asked a lot of questions at school.&amp;quot; (CFJCF)
We are currently working on systematically
identifying indirect quotes in the corpora and the
CFJCF data to analyze in more detail how they fit
in to this picture.
</bodyText>
<sectionHeader confidence="0.999294" genericHeader="method">
4 Experiment 2
</sectionHeader>
<bodyText confidence="0.99996">
Our first experiment suggested that discourse
factors were the primary cause of
subcategorization differences. One way to test
this hypothesis is to eliminate discourse factors
and see if this removes subcategorization
differences.
We measure the difference between the way a verb
is used in two different corpora by counting the
number of sentences (per hundred) where a verb in
one corpus would have to be used with a different
subcategorization in order for the two corpora to
yield the same subcategorization frequencies.
This same number can also be calculated for the
overall subcategorization frequencies of two
corpora to show the overall difference between the
two corpora.
Our procedure for measuring the effect of
discourse is as follows (illustrated using passive
as an example):
</bodyText>
<listItem confidence="0.996500857142857">
1. Measure the difference between two corpora
(WSJ vs CFJCF)
% Passive - WSJ vs CFJCF
2. Remove differences caused by discourse
effects (based on BC vs CFJCF). CFJCF has
22% the number of passives that BC has.
% Passive - BC vs CFJCF
</listItem>
<bodyText confidence="0.907739333333333">
We then linearly scale the number of passives
found in WSJ to reflect the difference found
between BC and CFJCF.
</bodyText>
<listItem confidence="0.995913">
% Passive - WSJ (adjusted) vs CFJCF
3. re-measure the difference between two
corpora (WSJ vs CFJCF)
4. amount of improvement = size of discourse
effect
</listItem>
<bodyText confidence="0.96907">
This method was applied to the passive, quote,
and zero subcat frames, since these are the ones
that show discourse-based differences. Before
</bodyText>
<page confidence="0.965393">
1125
</page>
<bodyText confidence="0.999923769230769">
the mapping, WSJ has a difference of 17
frames/100 overall difference when compared
with CFJCF. After the mapping, the difference
is only 9.6 frames/100 overall difference. This
indicates that 43% of the overall cross-verb
differences between these two corpora are caused
by discourse effects.
We use this mapping procedure to measure the
size and consistency of the discourse effects. A
more sophisticated mapping procedure would be
appropriate for other purposes since the verbs with
the best matches between corpora are actually
made worse by this mapping procedure.
</bodyText>
<sectionHeader confidence="0.997542" genericHeader="method">
5 Experiment 3
</sectionHeader>
<bodyText confidence="0.9396615">
Argument preference was also affected by verb
semantics. To examine this effect, we took two
sample ambiguous verbs, &amp;quot;charge&amp;quot; and &amp;quot;pass&amp;quot;.
We hand coded them for semantic senses in each
of the corpora we used as follows:
Examples of &apos;charge&apos; taken from BC.
</bodyText>
<figureCaption confidence="0.558475333333333">
accuse: &amp;quot;His petition charged mental cruelty.&amp;quot;
attack: &amp;quot;When he charged Mickey was ready.&amp;quot;
money: &amp;quot;... 20 per cent ... was all he charged the
</figureCaption>
<figure confidence="0.828641">
traders.&amp;quot;
Examples of `pass&apos; taken from BC.
</figure>
<figureCaption confidence="0.861321">
movement: &amp;quot;Blue Throat &apos;s men spotted him ... as he
passed.&amp;quot;
law: &amp;quot;The President noted that Congress last year
passed a law providing grants ...&amp;quot;
transfer: &amp;quot;He asked, when she passed him a glass.&amp;quot;
test: &amp;quot;Those who T stayed had * to pass tests.&amp;quot;
</figureCaption>
<bodyText confidence="0.987692">
We then asked two questions:
</bodyText>
<listItem confidence="0.9970578">
1. Do different verb senses have different
argument structure preferences?
2. Do different corpora have different verb
sense preferences, and therefore potentially
different argument structure preferences?
</listItem>
<bodyText confidence="0.818843846153846">
For both verbs examined (pass and charge) there
was a significant effect of verb sense on argument
structure probabilities (by X2 p &lt;.001 for `charge&apos;
and p &lt;.001 for `pass&apos;). The following chart
shows a sam le of this difference:
that NP NP PP passive
Charge(accuse) 32 0 24 25
Charge(money) 0 19 24 1
Sample Frames and Senses from WSJ
We then analyzed how often each sense was used
in each of the corpora and found that there was
again a significant difference (by X2 p &lt;.001 for
&apos;charge&apos; and p &lt;.001 for &apos;pass&apos;).
</bodyText>
<table confidence="0.990112181818182">
accuse money run/attack b
C
BC 22 13 15 4
WSJ 88 69 1 7
SWBD 1 16 0 0
Senses of &apos;Charge&apos; used in each corpus
movement c. transfer t dt
t
BC 136 32 16 2 44
WSJ 11 76 31 8 22
SWBD 0 5 2 1 0
</table>
<subsectionHeader confidence="0.363801">
Senses of &apos;Pass&apos; used in each corpus
</subsectionHeader>
<bodyText confidence="0.999922266666667">
This analysis shows that it is possible for shifts in
the relative frequency of each of a verbs senses to
influence the observed subcat frequencies.
We are currently extending our study to see if verb
senses have constant subcategorization
frequencies across corpora. This would be useful
for word sense disambiguation and for parsing.
If the verb sense is known, then a parser could use
this information to help look for likely arguments.
If the subcatagorization is known, then a
clisambiguator could use this information to find
the sense of the verb. These could be used to
bootstrap each other relying on the heuristic that
only one sense is used within any discourse (Gale,
Church, &amp; Yarowsky 1992).
</bodyText>
<sectionHeader confidence="0.997472" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.999031">
We had previously hoped to evaluate the accuracy
of our treebank induduced subcategorization
probabilities by comparing them with the
COMLEX hand-coded probabilities (Macleod and
</bodyText>
<page confidence="0.984801">
1126
</page>
<bodyText confidence="0.994317428571428">
Grislunan 1994), but we used a different set of
subcategorization frames than COMLEX.
Instead, we hand checked a random sample of our
data for errors.
The error rate in our data is between 3% and 7%
for all verbs excluding &apos;say&apos; type verbs such as
&apos;answer&apos;, &apos;ask&apos;, &apos;call&apos;, &apos;read&apos;, &apos;say&apos;, and &apos;write&apos;.
The error rate is given as a range due to the
subjectivity of some types of errors. The errors
can be divided into two classes; errors which are
due to mis-parsed sentences in Treebank&apos;, and
errors which are due to the inadequacy of our
search strings in indentifying certain syntactic
attems.
</bodyText>
<table confidence="0.8633995">
Treebank-based errors
PP attachment 1%
verb+particle vs verb+PP 2%
NP/adverbial distinction 2%
misc. miss-parsed sentences 1%
Errors based on our search strings
missed traces and displaced arguments 1%
&amp;quot;say&amp;quot; verbs missing quotes 6%
</table>
<bodyText confidence="0.977126">
Error rate by category
In trying to estimate the maximum amount of
error in our data, we found cases where it was
possible to disagree with the parses/tags given in
Treebank. Treebank examples given below
include prepositional attachment (1), the verb-
particle/preposition distinction (2), and the
NP/adverbial distinction (3).
</bodyText>
<listItem confidence="0.999727333333333">
1. &amp;quot;Sam, I thought you [knew [everything]â€ž
[about Tokyo]ppl&amp;quot; (BC)
2. &amp;quot;...who has since moved [on to other
methods]pp?&amp;quot; (BC)
3. &amp;quot;Gross stopped [briefly]Np?, then went on.&amp;quot;
(BC)
</listItem>
<bodyText confidence="0.960992735294118">
Missed traces and displaced argument errors were
a result of the difficulty in writing search strings
1 All of our search patterns are based only on the
information available in the Treebank 1 coding system,
since the Brown Corpus is only available in this
scheme. The error rate for corpora available in
Treebank 2 form would have been lower had we used
all available information.
to find arguments that were located to the left of
the verb. This is because arbitrary amounts of
structure can intervene, expecially in the case of
traces.
Six percent of the data (overall) was improperly
classified due to the failure of our search patterns
to identify all of the quote-type arguments which
occur in &apos;say&apos; type verbs. The identification of
these elements is particularly problematic due to
the asyntactic nature of these arguments, ranging
from a sound (He said `Argh!&apos;) to complex
sentences. The presence or absense of quotation
marks was not a completely reliable indicator of
these arguments. This type of error affects only
a small subset of the total number of verbs. 27%
of the examples of these verbs were mis-classified,
always by failing to find a quote-type argument of
the verb. Using separate search strings for these
verbs would greatly improve the accuracy of these
searches.
Our eventual goal is to develop a set of regular
expressions that work on flat tagged corpora
instead of TreeBank parsed structures to allow us
to gather information from larger corpora than
have been done by the TreeBank project (see
Manning 1993 and Gahl 1998).
</bodyText>
<sectionHeader confidence="0.998509" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.996652368421053">
We find that there are significant differences
between the verb subcategorization frequencies
generated through experimental methods and
corpus methods, and between the frequencies found
in different corpora. We have identified two
distinct sources for these differences. Discourse
influences are caused by the changes in the ways
language is used in different discourse types and
are to some extent predictable from the discourse
type of the corpus in question. Semantic
influences are based on the semantic context of the
discourse. These differences may be predictable
from the relative frequencies of each of the possible
senses of the verbs in the corpus. An extensive
analysis of the frame and sense frequencies of
different verbs across different corpora is needed to
verify this. This work is presently being carried
out by us and others (Baker, Fillmore, &amp; Lowe
1998). It is certain, however, that verb sense and
</bodyText>
<page confidence="0.982903">
1127
</page>
<bodyText confidence="0.99975625">
discourse type play an important role in the
frequencies observed in different experimental and
corpus based sources of verb subcategorization
frequencies
</bodyText>
<sectionHeader confidence="0.996793" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<reference confidence="0.467964375">
This project was supported by the generosity of the
NSF via NSF 11(I-9704046 and NSF [RI-9618838 and
the Committee on Research and Creative Work at the
graduate school of the University of Colorado,
Boulder. Many thanks to Giulia Bencini, Charles
Clifton, Charles Fillmore, Susanne Gahl, Michelle
Gregory, Uli Heid, Paola Merlo, Bill Raymond, and
Philip Resnik.
</reference>
<sectionHeader confidence="0.97558" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998710043103448">
Baker, C. Fillmore, C., &amp; Lowe, J.B. (1998) Framenet
ACL 1998
Biber, D. (1993) Using Register-Diversified Corpora for
General Language Studies. Computational Linguistics,
1912, pp. 219-241.
Briscoe T. and Carrol J. (1997) Automatic Extraction of
Subcategorization from Corpora.
Charniak, E. (1997) Statistical parsing with a context-free
grammar and word statistics. Proceedings of the
Fourteenth National Conference on Artificial Intelligence
MAI Press, Menlo Park
Clifton, C., Frazier, L, &amp; Connine, C. (1984) Lexical
expectations in sentence comprehension. Journal of
Verbal Learning and Verbal Behavior, 23, 696-708.
Collins, M. J. (1996) A new statistical parser based on
bigram lexical dependencies. In Proceedings of ACL-96,
184--191, Santa Cruz, CA.
Collins, M. J. (1997) Three generative, lexicalised models
for statistical parsing. In Proceedings of ACL-97.
Connine, Cynthia, Fernandez Ferreira, Charlie Jones,
Charles Clifton and Lyn Frazier. (1984) Verb Frame
Preference: Descriptive Norms. Journal of
Psycholinguistic Research 13, 307-319
Ferreira, F., and McClure, KK (1997). Parsing of
Garden-path Sentences with Reciprocal Verbs.
Language and Cognitive Processes, 12, 273-306.
Framis, F.R. (1994). An experiment on learning
appropriate selectional restrictions from a parsed corpus.
Manuscript.
Gahl, S. (1998). Automatic extraction of subcorpora based
on subcategorization frames from a part-of-speech tagged
corpus. Proceedings of ACL-98, Montreal.
Gale, WA., Church, KW, and Yarowsky, D. (1992). One
Sense Per Discourse. Darpa Speech and Natural
Language Workshop.
Garnsey, S. M., Pearlmutter, N. J., Myers, E. &amp; Lotocky, M.
A. (1997). The contributions of verb bias and plausibility
to the comprehension of temporarily ambiguous
sentences. Journal of Memory and Language, 37, 58-93.
Gibson, E., Schutze, C., &amp; Salomon, A. (1996). The
relationship between the frequency and the processing
complexity of linguistic structure. Journal of
Psycholinguistic Research 25(1), 59-92.
Godfrey, J., E. Hollimarz, J. McDanieL (1992)
SWITCHBOARD : Telephone speech corpus for
research and development. Proceedings of ICASSP-92,
517--520, San Francisco.
Joshi, A. &amp; B. Srinivas. (1994) Disambiguation of super
parts of speech (or supertags): almost parsing.
Proceedings of COLING &apos;94.
Juliano, C., and Tanenhaus, M.K. Contingent frequency
effects in syntactic ambiguity resolution. In proceedings of
the 15th annual conference of the cognitive science
society, LEA: Hillsdale, NJ.
Jurafsky, D. ( 1996) A probabilistic model of lexical and
syntactic access and disambiguation. Cognitive
Science, 20, 137-194.
Lafferty, J., D. Sleator, and D. Temperley. (1992)
Grammatical trigrams: A probabilistic model of link
grammar. In Proceedings of the 1992 MAI Fall
Symposium on Probabilistic Approaches to Natural
Language.
MacDonald, M. C. (1994) Probabilistic constraints and
syntactic ambiguity resolution. Language and Cognitive
Processes 9.157--201.
MacDonald, M. C., Pearlmutter, N. .1. &amp; Seidenberg, M. S.
(1994). The lexical nature of syntactic ambiguity
resolution. Psychological Review, 101, 676-703.
Macleod, C. &amp; Grishman, R. ( 1994) COMLEX Syntax
Reference Manual Version 1.2. Linguistic Data
Consortium, University of Pennsylvania.
Manning, C. D. (1993) Automatic Acquisition of a Large
Subcategorization Dictionary from Corpora. Proceedings
of ACL-93, 235-242.
Marcus, M.P., Santorini, B. &amp; Marcinkiewicz, M.A.. (1993)
Building a Large Annotated Corpus of English: The Penn
Treebank. Computational Linguistics 19.2: 313-330.
Marcus, M. P., Kim, G. Marcinkiewicz, M.A., MacIntyre, R.,
Ann Bies, Ferguson, M., Katz, K, and Schasberger, B..
(1994) The Penn Treebank: Annotating predicate
argument structure. ARPA Human Language
Technology Workshop, Plainsboro, NJ, 114-119.
Meyers, A., Macleod, C., and Grishman, R.. (1995)
Comlex Syntax 2.0 manual for tagged entries.
Merlo, P. ( 1994). A Corpus-Based Analysis of Verb
Continuation Frequencies for Syntactic Processing.
Journal of Pyscholinguistic Research 23.6:435-457.
Mitchell, D. C. and V. M. Holmes. (1985) The role of
specific information about the verb in parsing sentences
with local structural ambiguity. Journal of Memory and
Language 24.542-559.
Stolcice, A., C. Chelba, D. Engle, V. Jimenez, L Mangu, H.
Printz, E. Ristad, R. Rosenfeld, D. Wu, F. Jelinek and S.
Khudanpur. (1997) Dependency Language Modeling.
Center for Language and Speech Processing Research
Note No. 24. Johns Hopkins University, Baltimore.
Thompson, S. A. (1987) The Passive in English: A Discourse
Perspective. In Channon, Robert &amp; Shockey, Linda
(Eds.) In Honor of Use Lehiste/Ilse Lehiste
Puhendusteos. Dordrecht: Foris, 497-511.
Trueswell, J., M. Tanenhaus and C. Kello. (1993) Verb-
Specific Constraints in Sentence Processing: Separating
Effects of Lexical Preference from Garden-Paths. Journal
of Experimental Psychology: Learning, Memory and
Cognition 19.3, 528-553
Trueswell, J. &amp; M. Tanenhaus. (1994) Toward a lexicalist
framework for constraint-based syntactic ambiguity
resolution. In C. Clifton, K Rayner &amp; L. Frazier (Eds.)
Perspectives on Sentence Processing. Hillsdale, NJ:
Erlbaum, 155-179.
Ushioda, A., Evans, D., Gibson, T. &amp; Waibel, A. (1993)
The automatic acquisition of frequencies of verb
subcategorization frames from tagged corpora. In
Boguraev, B. &amp; Pustejovsky, J. eds. SIGLEX ACL
Workshop of Acquisition of Lexical Knowledge from Text.
Columbus, Ohio: 95-106
</reference>
<page confidence="0.995249">
1128
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.642424">
<title confidence="0.999294">How Verb Subcategorization Frequencies Are Affected By Corpus Choice</title>
<author confidence="0.999863">Douglas Roland</author>
<affiliation confidence="0.999949">University of Colorado Department of Linguistics</affiliation>
<address confidence="0.999773">Boulder, CO 80309-0295</address>
<email confidence="0.649306">Douglas.Roland@colorado.edu</email>
<author confidence="0.997951">Daniel Jurafsky</author>
<affiliation confidence="0.999878">University of Colorado Dept. of Linguistics &amp; Inst. of Cognitive Science</affiliation>
<address confidence="0.999667">Boulder, CO 80309-0295</address>
<email confidence="0.999893">jurafsky@colorado.edu</email>
<abstract confidence="0.9997808125">The probabilistic relation between verbs and their arguments plays an important role in modern statistical parsers and supertaggers, and in psychological theories of language processing. But these probabilities are computed in very different ways by the two sets of researchers. Computational linguists compute verb subcategorization probabilities from large corpora while psycholinguists compute them from psychological studies (sentence production and completion tasks). Recent studies have found differences between corpus frequencies and psycholinguistic measures. We analyze subcategorization frequencies from four different corpora: psychological sentence production data (Connine et al. 1984), written text (Brown and WSJ), and telephone conversation data (Switchboard). We find two different sources for the differences. influence a result of how verb use is affected by different discourse types such as narrative, connected discourse, and sentence productions. Semantic is result of different corpora using different senses of verbs, which have different subcategorization frequencies. We conclude that verb sense and discourse type play an important role in the frequencies observed in different experimental and corpus based sources of verb subcategorization frequencies.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Bill Raymond Merlo</author>
<author>Philip Resnik</author>
</authors>
<title>This project was supported by the generosity of the NSF via NSF 11(I-9704046 and NSF [RI-9618838 and the Committee on Research and Creative Work at the graduate school of the</title>
<institution>University of Colorado, Boulder. Many thanks to Giulia Bencini, Charles Clifton, Charles Fillmore, Susanne Gahl, Michelle Gregory, Uli Heid, Paola</institution>
<marker>Merlo, Resnik, </marker>
<rawString>This project was supported by the generosity of the NSF via NSF 11(I-9704046 and NSF [RI-9618838 and the Committee on Research and Creative Work at the graduate school of the University of Colorado, Boulder. Many thanks to Giulia Bencini, Charles Clifton, Charles Fillmore, Susanne Gahl, Michelle Gregory, Uli Heid, Paola Merlo, Bill Raymond, and Philip Resnik.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fillmore Baker</author>
<author>C</author>
<author>J B Lowe</author>
</authors>
<date>1998</date>
<booktitle>Framenet ACL</booktitle>
<marker>Baker, C, Lowe, 1998</marker>
<rawString>Baker, C. Fillmore, C., &amp; Lowe, J.B. (1998) Framenet ACL 1998</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Biber</author>
</authors>
<title>Using Register-Diversified Corpora for General Language Studies.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>219--241</pages>
<marker>Biber, 1993</marker>
<rawString>Biber, D. (1993) Using Register-Diversified Corpora for General Language Studies. Computational Linguistics, 1912, pp. 219-241.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Briscoe</author>
<author>J Carrol</author>
</authors>
<title>Automatic Extraction of Subcategorization from Corpora.</title>
<date>1997</date>
<marker>Briscoe, Carrol, 1997</marker>
<rawString>Briscoe T. and Carrol J. (1997) Automatic Extraction of Subcategorization from Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>Statistical parsing with a context-free grammar and word statistics.</title>
<date>1997</date>
<booktitle>Proceedings of the Fourteenth National Conference on Artificial Intelligence</booktitle>
<publisher>MAI Press,</publisher>
<location>Menlo Park</location>
<marker>Charniak, 1997</marker>
<rawString>Charniak, E. (1997) Statistical parsing with a context-free grammar and word statistics. Proceedings of the Fourteenth National Conference on Artificial Intelligence MAI Press, Menlo Park</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Clifton</author>
<author>L Frazier</author>
<author>C Connine</author>
</authors>
<title>Lexical expectations in sentence comprehension.</title>
<date>1984</date>
<journal>Journal of Verbal Learning and Verbal Behavior,</journal>
<volume>23</volume>
<pages>696--708</pages>
<contexts>
<context position="1986" citStr="Clifton et al. 1984" startWordPosition="264" endWordPosition="267"> corpora using different senses of verbs, which have different subcategorization frequencies. We conclude that verb sense and discourse type play an important role in the frequencies observed in different experimental and corpus based sources of verb subcategorization frequencies. 1 Introduction The probabilistic relation between verbs and their arguments plays an important role in modern statistical parsers and supertaggers (Charniak 1995, Collins 1996/1997, Joshi and Srinivas 1994, Kim, Srinivas, and Trueswell 1997, Stolcke et al. 1997), and in psychological theories of language processing (Clifton et al. 1984, Ferreira &amp; McClure 1997, Garnsey et al. 1997, Jurafsky 1996, MacDonald 1994, Mitchell &amp; Holmes 1985, Tanenhaus et al. 1990, Trueswell et al. 1993). These probabilities are computed in very different ways by the two sets of researchers. Psychological studies use methods such as sentence completion and sentence production for collecting verb argument structure probabilities. In sentence completion, subjects are asked to complete a sentence fragment. Garnsey at al. (1997) used a proper name followed by a verb, such as &amp;quot;Debbie remembered &amp;quot; In sentence subjects are asked to write any sentence con</context>
</contexts>
<marker>Clifton, Frazier, Connine, 1984</marker>
<rawString>Clifton, C., Frazier, L, &amp; Connine, C. (1984) Lexical expectations in sentence comprehension. Journal of Verbal Learning and Verbal Behavior, 23, 696-708.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Collins</author>
</authors>
<title>A new statistical parser based on bigram lexical dependencies.</title>
<date>1996</date>
<booktitle>In Proceedings of ACL-96,</booktitle>
<pages>184--191</pages>
<location>Santa Cruz, CA.</location>
<contexts>
<context position="1824" citStr="Collins 1996" startWordPosition="242" endWordPosition="243"> affected by different discourse types such as narrative, connected discourse, and single sentence productions. Semantic influence is a result of different corpora using different senses of verbs, which have different subcategorization frequencies. We conclude that verb sense and discourse type play an important role in the frequencies observed in different experimental and corpus based sources of verb subcategorization frequencies. 1 Introduction The probabilistic relation between verbs and their arguments plays an important role in modern statistical parsers and supertaggers (Charniak 1995, Collins 1996/1997, Joshi and Srinivas 1994, Kim, Srinivas, and Trueswell 1997, Stolcke et al. 1997), and in psychological theories of language processing (Clifton et al. 1984, Ferreira &amp; McClure 1997, Garnsey et al. 1997, Jurafsky 1996, MacDonald 1994, Mitchell &amp; Holmes 1985, Tanenhaus et al. 1990, Trueswell et al. 1993). These probabilities are computed in very different ways by the two sets of researchers. Psychological studies use methods such as sentence completion and sentence production for collecting verb argument structure probabilities. In sentence completion, subjects are asked to complete a sen</context>
</contexts>
<marker>Collins, 1996</marker>
<rawString>Collins, M. J. (1996) A new statistical parser based on bigram lexical dependencies. In Proceedings of ACL-96, 184--191, Santa Cruz, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Collins</author>
</authors>
<title>Three generative, lexicalised models for statistical parsing.</title>
<date>1997</date>
<booktitle>In Proceedings of ACL-97.</booktitle>
<marker>Collins, 1997</marker>
<rawString>Collins, M. J. (1997) Three generative, lexicalised models for statistical parsing. In Proceedings of ACL-97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia Connine</author>
<author>Fernandez Ferreira</author>
<author>Charlie Jones</author>
<author>Charles Clifton</author>
<author>Lyn Frazier</author>
</authors>
<title>Verb Frame Preference: Descriptive Norms.</title>
<date>1984</date>
<journal>Journal of Psycholinguistic Research</journal>
<volume>13</volume>
<pages>307--319</pages>
<contexts>
<context position="1032" citStr="Connine et al. 1984" startWordPosition="129" endWordPosition="132"> role in modern statistical parsers and supertaggers, and in psychological theories of language processing. But these probabilities are computed in very different ways by the two sets of researchers. Computational linguists compute verb subcategorization probabilities from large corpora while psycholinguists compute them from psychological studies (sentence production and completion tasks). Recent studies have found differences between corpus frequencies and psycholinguistic measures. We analyze subcategorization frequencies from four different corpora: psychological sentence production data (Connine et al. 1984), written text (Brown and WSJ), and telephone conversation data (Switchboard). We find two different sources for the differences. Discourse influence is a result of how verb use is affected by different discourse types such as narrative, connected discourse, and single sentence productions. Semantic influence is a result of different corpora using different senses of verbs, which have different subcategorization frequencies. We conclude that verb sense and discourse type play an important role in the frequencies observed in different experimental and corpus based sources of verb subcategorizat</context>
<context position="3630" citStr="Connine et al. 1984" startWordPosition="521" endWordPosition="524">ntage of any of these corpus methods is the much greater amount of data that can be used, and the much more natural contexts. This seems to make it preferable to data generated in psychological studies. Recent studies (Merlo 1994, Gibson et al. 1996) have found differences between corpus frequencies and experimental measures. This suggests that corpus-based frequencies and experiment-based frequencies may not be interchangeable. To clarify the nature of the differences between various corpora and to find the causes of these differences, we analyzed 1122 psychological sentence production data (Connine et al. 1984), written discourse (Brown and WSJ from Penn Treebank - Marcus et al. 1993), and conversational data (Switchboard - Godfrey et al. 1992). We found that the subcategorization frequencies in each of these sources are different. We performed three experiments to (1) find the causes of general differences between corpora, (2) measure the size of these differences, and (3) find verb specific differences. The rest of this paper describes our methodology and the two sources of subcategorization probability differences: discourse influence and semantic influence. 2 Methodology For the sentence product</context>
</contexts>
<marker>Connine, Ferreira, Jones, Clifton, Frazier, 1984</marker>
<rawString>Connine, Cynthia, Fernandez Ferreira, Charlie Jones, Charles Clifton and Lyn Frazier. (1984) Verb Frame Preference: Descriptive Norms. Journal of Psycholinguistic Research 13, 307-319</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Ferreira</author>
<author>KK McClure</author>
</authors>
<date>1997</date>
<booktitle>Parsing of Garden-path Sentences with Reciprocal Verbs. Language and Cognitive Processes,</booktitle>
<volume>12</volume>
<pages>273--306</pages>
<contexts>
<context position="2011" citStr="Ferreira &amp; McClure 1997" startWordPosition="268" endWordPosition="271">ent senses of verbs, which have different subcategorization frequencies. We conclude that verb sense and discourse type play an important role in the frequencies observed in different experimental and corpus based sources of verb subcategorization frequencies. 1 Introduction The probabilistic relation between verbs and their arguments plays an important role in modern statistical parsers and supertaggers (Charniak 1995, Collins 1996/1997, Joshi and Srinivas 1994, Kim, Srinivas, and Trueswell 1997, Stolcke et al. 1997), and in psychological theories of language processing (Clifton et al. 1984, Ferreira &amp; McClure 1997, Garnsey et al. 1997, Jurafsky 1996, MacDonald 1994, Mitchell &amp; Holmes 1985, Tanenhaus et al. 1990, Trueswell et al. 1993). These probabilities are computed in very different ways by the two sets of researchers. Psychological studies use methods such as sentence completion and sentence production for collecting verb argument structure probabilities. In sentence completion, subjects are asked to complete a sentence fragment. Garnsey at al. (1997) used a proper name followed by a verb, such as &amp;quot;Debbie remembered &amp;quot; In sentence subjects are asked to write any sentence containing a given verb. An </context>
</contexts>
<marker>Ferreira, McClure, 1997</marker>
<rawString>Ferreira, F., and McClure, KK (1997). Parsing of Garden-path Sentences with Reciprocal Verbs. Language and Cognitive Processes, 12, 273-306.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F R Framis</author>
</authors>
<title>An experiment on learning appropriate selectional restrictions from a parsed corpus.</title>
<date>1994</date>
<tech>Manuscript.</tech>
<contexts>
<context position="2937" citStr="Framis 1994" startWordPosition="417" endWordPosition="418">verb argument structure probabilities. In sentence completion, subjects are asked to complete a sentence fragment. Garnsey at al. (1997) used a proper name followed by a verb, such as &amp;quot;Debbie remembered &amp;quot; In sentence subjects are asked to write any sentence containing a given verb. An example of this type of study is Confine et al. (1984). An alternative to these psychological methods is to use corpus data. This can be done automatically with unparsed corpora (Briscoe and Carroll 1997, Manning 1993, Ushioda et al. 1993), from parsed corpora such as Marcus et al.&apos;s (1993) Treebank (Merlo 1994, Framis 1994) or manually as was done for COMLEX (Macleod and Grishman 1994). The advantage of any of these corpus methods is the much greater amount of data that can be used, and the much more natural contexts. This seems to make it preferable to data generated in psychological studies. Recent studies (Merlo 1994, Gibson et al. 1996) have found differences between corpus frequencies and experimental measures. This suggests that corpus-based frequencies and experiment-based frequencies may not be interchangeable. To clarify the nature of the differences between various corpora and to find the causes of the</context>
</contexts>
<marker>Framis, 1994</marker>
<rawString>Framis, F.R. (1994). An experiment on learning appropriate selectional restrictions from a parsed corpus. Manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Gahl</author>
</authors>
<title>Automatic extraction of subcorpora based on subcategorization frames from a part-of-speech tagged corpus.</title>
<date>1998</date>
<booktitle>Proceedings of ACL-98,</booktitle>
<location>Montreal.</location>
<contexts>
<context position="18725" citStr="Gahl 1998" startWordPosition="3008" endWordPosition="3009">t a completely reliable indicator of these arguments. This type of error affects only a small subset of the total number of verbs. 27% of the examples of these verbs were mis-classified, always by failing to find a quote-type argument of the verb. Using separate search strings for these verbs would greatly improve the accuracy of these searches. Our eventual goal is to develop a set of regular expressions that work on flat tagged corpora instead of TreeBank parsed structures to allow us to gather information from larger corpora than have been done by the TreeBank project (see Manning 1993 and Gahl 1998). 7 Conclusion We find that there are significant differences between the verb subcategorization frequencies generated through experimental methods and corpus methods, and between the frequencies found in different corpora. We have identified two distinct sources for these differences. Discourse influences are caused by the changes in the ways language is used in different discourse types and are to some extent predictable from the discourse type of the corpus in question. Semantic influences are based on the semantic context of the discourse. These differences may be predictable from the rela</context>
</contexts>
<marker>Gahl, 1998</marker>
<rawString>Gahl, S. (1998). Automatic extraction of subcorpora based on subcategorization frames from a part-of-speech tagged corpus. Proceedings of ACL-98, Montreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>WA Gale</author>
<author>KW Church</author>
<author>D Yarowsky</author>
</authors>
<title>One Sense Per Discourse. Darpa Speech and Natural Language Workshop.</title>
<date>1992</date>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>Gale, WA., Church, KW, and Yarowsky, D. (1992). One Sense Per Discourse. Darpa Speech and Natural Language Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Garnsey</author>
<author>N J Pearlmutter</author>
<author>E Myers</author>
<author>M A Lotocky</author>
</authors>
<title>The contributions of verb bias and plausibility to the comprehension of temporarily ambiguous sentences.</title>
<date>1997</date>
<journal>Journal of Memory and Language,</journal>
<volume>37</volume>
<pages>58--93</pages>
<contexts>
<context position="2032" citStr="Garnsey et al. 1997" startWordPosition="272" endWordPosition="275">h have different subcategorization frequencies. We conclude that verb sense and discourse type play an important role in the frequencies observed in different experimental and corpus based sources of verb subcategorization frequencies. 1 Introduction The probabilistic relation between verbs and their arguments plays an important role in modern statistical parsers and supertaggers (Charniak 1995, Collins 1996/1997, Joshi and Srinivas 1994, Kim, Srinivas, and Trueswell 1997, Stolcke et al. 1997), and in psychological theories of language processing (Clifton et al. 1984, Ferreira &amp; McClure 1997, Garnsey et al. 1997, Jurafsky 1996, MacDonald 1994, Mitchell &amp; Holmes 1985, Tanenhaus et al. 1990, Trueswell et al. 1993). These probabilities are computed in very different ways by the two sets of researchers. Psychological studies use methods such as sentence completion and sentence production for collecting verb argument structure probabilities. In sentence completion, subjects are asked to complete a sentence fragment. Garnsey at al. (1997) used a proper name followed by a verb, such as &amp;quot;Debbie remembered &amp;quot; In sentence subjects are asked to write any sentence containing a given verb. An example of this type </context>
</contexts>
<marker>Garnsey, Pearlmutter, Myers, Lotocky, 1997</marker>
<rawString>Garnsey, S. M., Pearlmutter, N. J., Myers, E. &amp; Lotocky, M. A. (1997). The contributions of verb bias and plausibility to the comprehension of temporarily ambiguous sentences. Journal of Memory and Language, 37, 58-93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Gibson</author>
<author>C Schutze</author>
<author>A Salomon</author>
</authors>
<title>The relationship between the frequency and the processing complexity of linguistic structure.</title>
<date>1996</date>
<journal>Journal of Psycholinguistic Research</journal>
<volume>25</volume>
<issue>1</issue>
<pages>59--92</pages>
<contexts>
<context position="3260" citStr="Gibson et al. 1996" startWordPosition="471" endWordPosition="474">is Confine et al. (1984). An alternative to these psychological methods is to use corpus data. This can be done automatically with unparsed corpora (Briscoe and Carroll 1997, Manning 1993, Ushioda et al. 1993), from parsed corpora such as Marcus et al.&apos;s (1993) Treebank (Merlo 1994, Framis 1994) or manually as was done for COMLEX (Macleod and Grishman 1994). The advantage of any of these corpus methods is the much greater amount of data that can be used, and the much more natural contexts. This seems to make it preferable to data generated in psychological studies. Recent studies (Merlo 1994, Gibson et al. 1996) have found differences between corpus frequencies and experimental measures. This suggests that corpus-based frequencies and experiment-based frequencies may not be interchangeable. To clarify the nature of the differences between various corpora and to find the causes of these differences, we analyzed 1122 psychological sentence production data (Connine et al. 1984), written discourse (Brown and WSJ from Penn Treebank - Marcus et al. 1993), and conversational data (Switchboard - Godfrey et al. 1992). We found that the subcategorization frequencies in each of these sources are different. We p</context>
</contexts>
<marker>Gibson, Schutze, Salomon, 1996</marker>
<rawString>Gibson, E., Schutze, C., &amp; Salomon, A. (1996). The relationship between the frequency and the processing complexity of linguistic structure. Journal of Psycholinguistic Research 25(1), 59-92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Godfrey</author>
<author>E Hollimarz</author>
<author>J McDanieL</author>
</authors>
<title>SWITCHBOARD : Telephone speech corpus for research and development.</title>
<date>1992</date>
<booktitle>Proceedings of ICASSP-92,</booktitle>
<pages>517--520</pages>
<location>San Francisco.</location>
<contexts>
<context position="3766" citStr="Godfrey et al. 1992" startWordPosition="543" endWordPosition="546"> to make it preferable to data generated in psychological studies. Recent studies (Merlo 1994, Gibson et al. 1996) have found differences between corpus frequencies and experimental measures. This suggests that corpus-based frequencies and experiment-based frequencies may not be interchangeable. To clarify the nature of the differences between various corpora and to find the causes of these differences, we analyzed 1122 psychological sentence production data (Connine et al. 1984), written discourse (Brown and WSJ from Penn Treebank - Marcus et al. 1993), and conversational data (Switchboard - Godfrey et al. 1992). We found that the subcategorization frequencies in each of these sources are different. We performed three experiments to (1) find the causes of general differences between corpora, (2) measure the size of these differences, and (3) find verb specific differences. The rest of this paper describes our methodology and the two sources of subcategorization probability differences: discourse influence and semantic influence. 2 Methodology For the sentence production data, we used the numbers published in the original Connine et al. paper as well as the original data, which we were able to review </context>
</contexts>
<marker>Godfrey, Hollimarz, McDanieL, 1992</marker>
<rawString>Godfrey, J., E. Hollimarz, J. McDanieL (1992) SWITCHBOARD : Telephone speech corpus for research and development. Proceedings of ICASSP-92, 517--520, San Francisco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Joshi</author>
<author>B Srinivas</author>
</authors>
<title>Disambiguation of super parts of speech (or supertags): almost parsing.</title>
<date>1994</date>
<booktitle>Proceedings of COLING &apos;94.</booktitle>
<contexts>
<context position="1854" citStr="Joshi and Srinivas 1994" startWordPosition="244" endWordPosition="247">ent discourse types such as narrative, connected discourse, and single sentence productions. Semantic influence is a result of different corpora using different senses of verbs, which have different subcategorization frequencies. We conclude that verb sense and discourse type play an important role in the frequencies observed in different experimental and corpus based sources of verb subcategorization frequencies. 1 Introduction The probabilistic relation between verbs and their arguments plays an important role in modern statistical parsers and supertaggers (Charniak 1995, Collins 1996/1997, Joshi and Srinivas 1994, Kim, Srinivas, and Trueswell 1997, Stolcke et al. 1997), and in psychological theories of language processing (Clifton et al. 1984, Ferreira &amp; McClure 1997, Garnsey et al. 1997, Jurafsky 1996, MacDonald 1994, Mitchell &amp; Holmes 1985, Tanenhaus et al. 1990, Trueswell et al. 1993). These probabilities are computed in very different ways by the two sets of researchers. Psychological studies use methods such as sentence completion and sentence production for collecting verb argument structure probabilities. In sentence completion, subjects are asked to complete a sentence fragment. Garnsey at al.</context>
</contexts>
<marker>Joshi, Srinivas, 1994</marker>
<rawString>Joshi, A. &amp; B. Srinivas. (1994) Disambiguation of super parts of speech (or supertags): almost parsing. Proceedings of COLING &apos;94.</rawString>
</citation>
<citation valid="false">
<authors>
<author>C Juliano</author>
<author>M K Tanenhaus</author>
</authors>
<title>Contingent frequency effects in syntactic ambiguity resolution.</title>
<booktitle>In proceedings of the 15th annual conference of the cognitive science society,</booktitle>
<location>LEA: Hillsdale, NJ.</location>
<marker>Juliano, Tanenhaus, </marker>
<rawString>Juliano, C., and Tanenhaus, M.K. Contingent frequency effects in syntactic ambiguity resolution. In proceedings of the 15th annual conference of the cognitive science society, LEA: Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Jurafsky</author>
</authors>
<title>A probabilistic model of lexical and syntactic access and disambiguation.</title>
<date>1996</date>
<journal>Cognitive Science,</journal>
<volume>20</volume>
<pages>137--194</pages>
<contexts>
<context position="2047" citStr="Jurafsky 1996" startWordPosition="276" endWordPosition="277">ategorization frequencies. We conclude that verb sense and discourse type play an important role in the frequencies observed in different experimental and corpus based sources of verb subcategorization frequencies. 1 Introduction The probabilistic relation between verbs and their arguments plays an important role in modern statistical parsers and supertaggers (Charniak 1995, Collins 1996/1997, Joshi and Srinivas 1994, Kim, Srinivas, and Trueswell 1997, Stolcke et al. 1997), and in psychological theories of language processing (Clifton et al. 1984, Ferreira &amp; McClure 1997, Garnsey et al. 1997, Jurafsky 1996, MacDonald 1994, Mitchell &amp; Holmes 1985, Tanenhaus et al. 1990, Trueswell et al. 1993). These probabilities are computed in very different ways by the two sets of researchers. Psychological studies use methods such as sentence completion and sentence production for collecting verb argument structure probabilities. In sentence completion, subjects are asked to complete a sentence fragment. Garnsey at al. (1997) used a proper name followed by a verb, such as &amp;quot;Debbie remembered &amp;quot; In sentence subjects are asked to write any sentence containing a given verb. An example of this type of study is Con</context>
</contexts>
<marker>Jurafsky, 1996</marker>
<rawString>Jurafsky, D. ( 1996) A probabilistic model of lexical and syntactic access and disambiguation. Cognitive Science, 20, 137-194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>D Sleator</author>
<author>D Temperley</author>
</authors>
<title>Grammatical trigrams: A probabilistic model of link grammar.</title>
<date>1992</date>
<booktitle>In Proceedings of the 1992 MAI Fall Symposium on Probabilistic Approaches to Natural Language.</booktitle>
<marker>Lafferty, Sleator, Temperley, 1992</marker>
<rawString>Lafferty, J., D. Sleator, and D. Temperley. (1992) Grammatical trigrams: A probabilistic model of link grammar. In Proceedings of the 1992 MAI Fall Symposium on Probabilistic Approaches to Natural Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M C MacDonald</author>
</authors>
<title>Probabilistic constraints and syntactic ambiguity resolution.</title>
<date>1994</date>
<booktitle>Language and Cognitive Processes</booktitle>
<pages>9--157</pages>
<contexts>
<context position="2063" citStr="MacDonald 1994" startWordPosition="278" endWordPosition="279">requencies. We conclude that verb sense and discourse type play an important role in the frequencies observed in different experimental and corpus based sources of verb subcategorization frequencies. 1 Introduction The probabilistic relation between verbs and their arguments plays an important role in modern statistical parsers and supertaggers (Charniak 1995, Collins 1996/1997, Joshi and Srinivas 1994, Kim, Srinivas, and Trueswell 1997, Stolcke et al. 1997), and in psychological theories of language processing (Clifton et al. 1984, Ferreira &amp; McClure 1997, Garnsey et al. 1997, Jurafsky 1996, MacDonald 1994, Mitchell &amp; Holmes 1985, Tanenhaus et al. 1990, Trueswell et al. 1993). These probabilities are computed in very different ways by the two sets of researchers. Psychological studies use methods such as sentence completion and sentence production for collecting verb argument structure probabilities. In sentence completion, subjects are asked to complete a sentence fragment. Garnsey at al. (1997) used a proper name followed by a verb, such as &amp;quot;Debbie remembered &amp;quot; In sentence subjects are asked to write any sentence containing a given verb. An example of this type of study is Confine et al. (198</context>
</contexts>
<marker>MacDonald, 1994</marker>
<rawString>MacDonald, M. C. (1994) Probabilistic constraints and syntactic ambiguity resolution. Language and Cognitive Processes 9.157--201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M C MacDonald</author>
<author>N Pearlmutter</author>
</authors>
<title>The lexical nature of syntactic ambiguity resolution.</title>
<date>1994</date>
<journal>Psychological Review,</journal>
<volume>101</volume>
<pages>676--703</pages>
<marker>MacDonald, Pearlmutter, 1994</marker>
<rawString>MacDonald, M. C., Pearlmutter, N. .1. &amp; Seidenberg, M. S. (1994). The lexical nature of syntactic ambiguity resolution. Psychological Review, 101, 676-703.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Macleod</author>
<author>R Grishman</author>
</authors>
<title>COMLEX Syntax Reference Manual Version 1.2. Linguistic Data Consortium,</title>
<date>1994</date>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="3000" citStr="Macleod and Grishman 1994" startWordPosition="426" endWordPosition="429">e completion, subjects are asked to complete a sentence fragment. Garnsey at al. (1997) used a proper name followed by a verb, such as &amp;quot;Debbie remembered &amp;quot; In sentence subjects are asked to write any sentence containing a given verb. An example of this type of study is Confine et al. (1984). An alternative to these psychological methods is to use corpus data. This can be done automatically with unparsed corpora (Briscoe and Carroll 1997, Manning 1993, Ushioda et al. 1993), from parsed corpora such as Marcus et al.&apos;s (1993) Treebank (Merlo 1994, Framis 1994) or manually as was done for COMLEX (Macleod and Grishman 1994). The advantage of any of these corpus methods is the much greater amount of data that can be used, and the much more natural contexts. This seems to make it preferable to data generated in psychological studies. Recent studies (Merlo 1994, Gibson et al. 1996) have found differences between corpus frequencies and experimental measures. This suggests that corpus-based frequencies and experiment-based frequencies may not be interchangeable. To clarify the nature of the differences between various corpora and to find the causes of these differences, we analyzed 1122 psychological sentence product</context>
</contexts>
<marker>Macleod, Grishman, 1994</marker>
<rawString>Macleod, C. &amp; Grishman, R. ( 1994) COMLEX Syntax Reference Manual Version 1.2. Linguistic Data Consortium, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
</authors>
<title>Automatic Acquisition of a Large Subcategorization Dictionary from Corpora.</title>
<date>1993</date>
<booktitle>Proceedings of ACL-93,</booktitle>
<pages>235--242</pages>
<contexts>
<context position="2828" citStr="Manning 1993" startWordPosition="399" endWordPosition="400">rchers. Psychological studies use methods such as sentence completion and sentence production for collecting verb argument structure probabilities. In sentence completion, subjects are asked to complete a sentence fragment. Garnsey at al. (1997) used a proper name followed by a verb, such as &amp;quot;Debbie remembered &amp;quot; In sentence subjects are asked to write any sentence containing a given verb. An example of this type of study is Confine et al. (1984). An alternative to these psychological methods is to use corpus data. This can be done automatically with unparsed corpora (Briscoe and Carroll 1997, Manning 1993, Ushioda et al. 1993), from parsed corpora such as Marcus et al.&apos;s (1993) Treebank (Merlo 1994, Framis 1994) or manually as was done for COMLEX (Macleod and Grishman 1994). The advantage of any of these corpus methods is the much greater amount of data that can be used, and the much more natural contexts. This seems to make it preferable to data generated in psychological studies. Recent studies (Merlo 1994, Gibson et al. 1996) have found differences between corpus frequencies and experimental measures. This suggests that corpus-based frequencies and experiment-based frequencies may not be in</context>
<context position="18710" citStr="Manning 1993" startWordPosition="3005" endWordPosition="3006">tion marks was not a completely reliable indicator of these arguments. This type of error affects only a small subset of the total number of verbs. 27% of the examples of these verbs were mis-classified, always by failing to find a quote-type argument of the verb. Using separate search strings for these verbs would greatly improve the accuracy of these searches. Our eventual goal is to develop a set of regular expressions that work on flat tagged corpora instead of TreeBank parsed structures to allow us to gather information from larger corpora than have been done by the TreeBank project (see Manning 1993 and Gahl 1998). 7 Conclusion We find that there are significant differences between the verb subcategorization frequencies generated through experimental methods and corpus methods, and between the frequencies found in different corpora. We have identified two distinct sources for these differences. Discourse influences are caused by the changes in the ways language is used in different discourse types and are to some extent predictable from the discourse type of the corpus in question. Semantic influences are based on the semantic context of the discourse. These differences may be predictabl</context>
</contexts>
<marker>Manning, 1993</marker>
<rawString>Manning, C. D. (1993) Automatic Acquisition of a Large Subcategorization Dictionary from Corpora. Proceedings of ACL-93, 235-242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a Large Annotated Corpus of English: The Penn Treebank.</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<pages>313--330</pages>
<contexts>
<context position="3705" citStr="Marcus et al. 1993" startWordPosition="534" endWordPosition="537"> can be used, and the much more natural contexts. This seems to make it preferable to data generated in psychological studies. Recent studies (Merlo 1994, Gibson et al. 1996) have found differences between corpus frequencies and experimental measures. This suggests that corpus-based frequencies and experiment-based frequencies may not be interchangeable. To clarify the nature of the differences between various corpora and to find the causes of these differences, we analyzed 1122 psychological sentence production data (Connine et al. 1984), written discourse (Brown and WSJ from Penn Treebank - Marcus et al. 1993), and conversational data (Switchboard - Godfrey et al. 1992). We found that the subcategorization frequencies in each of these sources are different. We performed three experiments to (1) find the causes of general differences between corpora, (2) measure the size of these differences, and (3) find verb specific differences. The rest of this paper describes our methodology and the two sources of subcategorization probability differences: discourse influence and semantic influence. 2 Methodology For the sentence production data, we used the numbers published in the original Connine et al. pape</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Marcus, M.P., Santorini, B. &amp; Marcinkiewicz, M.A.. (1993) Building a Large Annotated Corpus of English: The Penn Treebank. Computational Linguistics 19.2: 313-330.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M P Marcus</author>
<author>G Marcinkiewicz Kim</author>
<author>M A MacIntyre</author>
<author>Ann Bies R</author>
<author>M Ferguson</author>
<author>K Katz</author>
<author>B Schasberger</author>
</authors>
<marker>Marcus, Kim, MacIntyre, R, Ferguson, Katz, Schasberger, </marker>
<rawString>Marcus, M. P., Kim, G. Marcinkiewicz, M.A., MacIntyre, R., Ann Bies, Ferguson, M., Katz, K, and Schasberger, B..</rawString>
</citation>
<citation valid="true">
<title>The Penn Treebank: Annotating predicate argument structure. ARPA Human Language Technology Workshop,</title>
<date>1994</date>
<pages>114--119</pages>
<location>Plainsboro, NJ,</location>
<marker>1994</marker>
<rawString>(1994) The Penn Treebank: Annotating predicate argument structure. ARPA Human Language Technology Workshop, Plainsboro, NJ, 114-119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Meyers</author>
<author>C Macleod</author>
<author>R Grishman</author>
</authors>
<date>1995</date>
<journal>Comlex Syntax</journal>
<volume>2</volume>
<note>manual for tagged entries.</note>
<marker>Meyers, Macleod, Grishman, 1995</marker>
<rawString>Meyers, A., Macleod, C., and Grishman, R.. (1995) Comlex Syntax 2.0 manual for tagged entries.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Merlo</author>
</authors>
<title>A Corpus-Based Analysis of Verb Continuation Frequencies for Syntactic Processing.</title>
<date>1994</date>
<journal>Journal of Pyscholinguistic Research</journal>
<pages>23--6</pages>
<contexts>
<context position="2923" citStr="Merlo 1994" startWordPosition="415" endWordPosition="416"> collecting verb argument structure probabilities. In sentence completion, subjects are asked to complete a sentence fragment. Garnsey at al. (1997) used a proper name followed by a verb, such as &amp;quot;Debbie remembered &amp;quot; In sentence subjects are asked to write any sentence containing a given verb. An example of this type of study is Confine et al. (1984). An alternative to these psychological methods is to use corpus data. This can be done automatically with unparsed corpora (Briscoe and Carroll 1997, Manning 1993, Ushioda et al. 1993), from parsed corpora such as Marcus et al.&apos;s (1993) Treebank (Merlo 1994, Framis 1994) or manually as was done for COMLEX (Macleod and Grishman 1994). The advantage of any of these corpus methods is the much greater amount of data that can be used, and the much more natural contexts. This seems to make it preferable to data generated in psychological studies. Recent studies (Merlo 1994, Gibson et al. 1996) have found differences between corpus frequencies and experimental measures. This suggests that corpus-based frequencies and experiment-based frequencies may not be interchangeable. To clarify the nature of the differences between various corpora and to find the</context>
</contexts>
<marker>Merlo, 1994</marker>
<rawString>Merlo, P. ( 1994). A Corpus-Based Analysis of Verb Continuation Frequencies for Syntactic Processing. Journal of Pyscholinguistic Research 23.6:435-457.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D C Mitchell</author>
<author>V M Holmes</author>
</authors>
<title>The role of specific information about the verb in parsing sentences with local structural ambiguity.</title>
<date>1985</date>
<journal>Journal of Memory and Language</journal>
<pages>24--542</pages>
<contexts>
<context position="2087" citStr="Mitchell &amp; Holmes 1985" startWordPosition="280" endWordPosition="283">onclude that verb sense and discourse type play an important role in the frequencies observed in different experimental and corpus based sources of verb subcategorization frequencies. 1 Introduction The probabilistic relation between verbs and their arguments plays an important role in modern statistical parsers and supertaggers (Charniak 1995, Collins 1996/1997, Joshi and Srinivas 1994, Kim, Srinivas, and Trueswell 1997, Stolcke et al. 1997), and in psychological theories of language processing (Clifton et al. 1984, Ferreira &amp; McClure 1997, Garnsey et al. 1997, Jurafsky 1996, MacDonald 1994, Mitchell &amp; Holmes 1985, Tanenhaus et al. 1990, Trueswell et al. 1993). These probabilities are computed in very different ways by the two sets of researchers. Psychological studies use methods such as sentence completion and sentence production for collecting verb argument structure probabilities. In sentence completion, subjects are asked to complete a sentence fragment. Garnsey at al. (1997) used a proper name followed by a verb, such as &amp;quot;Debbie remembered &amp;quot; In sentence subjects are asked to write any sentence containing a given verb. An example of this type of study is Confine et al. (1984). An alternative to th</context>
</contexts>
<marker>Mitchell, Holmes, 1985</marker>
<rawString>Mitchell, D. C. and V. M. Holmes. (1985) The role of specific information about the verb in parsing sentences with local structural ambiguity. Journal of Memory and Language 24.542-559.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcice</author>
<author>C Chelba</author>
<author>D Engle</author>
<author>V Jimenez</author>
<author>L Mangu</author>
<author>H Printz</author>
<author>E Ristad</author>
<author>R Rosenfeld</author>
<author>D Wu</author>
<author>F Jelinek</author>
<author>S Khudanpur</author>
</authors>
<title>Dependency Language Modeling. Center for Language and Speech Processing Research Note No.</title>
<date>1997</date>
<tech>24.</tech>
<institution>Johns Hopkins University,</institution>
<location>Baltimore.</location>
<marker>Stolcice, Chelba, Engle, Jimenez, Mangu, Printz, Ristad, Rosenfeld, Wu, Jelinek, Khudanpur, 1997</marker>
<rawString>Stolcice, A., C. Chelba, D. Engle, V. Jimenez, L Mangu, H. Printz, E. Ristad, R. Rosenfeld, D. Wu, F. Jelinek and S. Khudanpur. (1997) Dependency Language Modeling. Center for Language and Speech Processing Research Note No. 24. Johns Hopkins University, Baltimore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S A Thompson</author>
</authors>
<title>The Passive in English: A Discourse Perspective.</title>
<date>1987</date>
<booktitle>In Channon, Robert &amp; Shockey, Linda (Eds.) In Honor of Use Lehiste/Ilse Lehiste Puhendusteos.</booktitle>
<pages>497--511</pages>
<location>Dordrecht: Foris,</location>
<contexts>
<context position="8753" citStr="Thompson 1987" startWordPosition="1363" endWordPosition="1364">rse type. These categories are: (1) passive sentences (2) zero anaphora (3) quotations 3.1.1 Passive Sentences The CFJCF single sentence productions had the smallest number of passive sentences. The connected spoken discourse in Switchboard had more passives, followed by the written discourse in the Wall Street Journal and the Brown Corpus. Data Source % passive sentences CFJCF 0.6% Switchboard 2.2% Wall Street Journal 6.7% Brown Corpus 7.8% Passive is generally used in English to emphasize the undergoer (to keep the topic in subject position) and/or to de-emphasize the identity of the agent (Thompson 1987). Both of these reasons are affected by the type of discourse. If there is no preceding discourse, then there is no pre-existing topic to keep in subject position. In addition, with no context for the sentence, there is less likely to be a reason to de-emphasize the agent of the sentence. 3.1.2 Zero Anaphora The increase in zero anaphora (not overtly mentioning understood arguments) is caused by two factors. Generally, as the amount of surrounding context increases (going from single sentence to connected discourse) the need to overtly express all of the arguments with a verb decreases. Data S</context>
</contexts>
<marker>Thompson, 1987</marker>
<rawString>Thompson, S. A. (1987) The Passive in English: A Discourse Perspective. In Channon, Robert &amp; Shockey, Linda (Eds.) In Honor of Use Lehiste/Ilse Lehiste Puhendusteos. Dordrecht: Foris, 497-511.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Trueswell</author>
<author>M Tanenhaus</author>
<author>C Kello</author>
</authors>
<title>VerbSpecific Constraints in Sentence Processing: Separating Effects of Lexical Preference from Garden-Paths.</title>
<date>1993</date>
<journal>Journal of Experimental Psychology: Learning, Memory and Cognition</journal>
<volume>19</volume>
<pages>528--553</pages>
<contexts>
<context position="2134" citStr="Trueswell et al. 1993" startWordPosition="288" endWordPosition="291"> an important role in the frequencies observed in different experimental and corpus based sources of verb subcategorization frequencies. 1 Introduction The probabilistic relation between verbs and their arguments plays an important role in modern statistical parsers and supertaggers (Charniak 1995, Collins 1996/1997, Joshi and Srinivas 1994, Kim, Srinivas, and Trueswell 1997, Stolcke et al. 1997), and in psychological theories of language processing (Clifton et al. 1984, Ferreira &amp; McClure 1997, Garnsey et al. 1997, Jurafsky 1996, MacDonald 1994, Mitchell &amp; Holmes 1985, Tanenhaus et al. 1990, Trueswell et al. 1993). These probabilities are computed in very different ways by the two sets of researchers. Psychological studies use methods such as sentence completion and sentence production for collecting verb argument structure probabilities. In sentence completion, subjects are asked to complete a sentence fragment. Garnsey at al. (1997) used a proper name followed by a verb, such as &amp;quot;Debbie remembered &amp;quot; In sentence subjects are asked to write any sentence containing a given verb. An example of this type of study is Confine et al. (1984). An alternative to these psychological methods is to use corpus data</context>
</contexts>
<marker>Trueswell, Tanenhaus, Kello, 1993</marker>
<rawString>Trueswell, J., M. Tanenhaus and C. Kello. (1993) VerbSpecific Constraints in Sentence Processing: Separating Effects of Lexical Preference from Garden-Paths. Journal of Experimental Psychology: Learning, Memory and Cognition 19.3, 528-553</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Trueswell</author>
<author>M Tanenhaus</author>
</authors>
<title>Toward a lexicalist framework for constraint-based syntactic ambiguity resolution. In</title>
<date>1994</date>
<pages>155--179</pages>
<publisher>Erlbaum,</publisher>
<location>Hillsdale, NJ:</location>
<marker>Trueswell, Tanenhaus, 1994</marker>
<rawString>Trueswell, J. &amp; M. Tanenhaus. (1994) Toward a lexicalist framework for constraint-based syntactic ambiguity resolution. In C. Clifton, K Rayner &amp; L. Frazier (Eds.) Perspectives on Sentence Processing. Hillsdale, NJ: Erlbaum, 155-179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ushioda</author>
<author>D Evans</author>
<author>T Gibson</author>
<author>A Waibel</author>
</authors>
<title>The automatic acquisition of frequencies of verb subcategorization frames from tagged corpora.</title>
<date>1993</date>
<booktitle>SIGLEX ACL Workshop of Acquisition of Lexical Knowledge from Text.</booktitle>
<pages>95--106</pages>
<editor>In Boguraev, B. &amp; Pustejovsky, J. eds.</editor>
<location>Columbus, Ohio:</location>
<contexts>
<context position="2850" citStr="Ushioda et al. 1993" startWordPosition="401" endWordPosition="404">logical studies use methods such as sentence completion and sentence production for collecting verb argument structure probabilities. In sentence completion, subjects are asked to complete a sentence fragment. Garnsey at al. (1997) used a proper name followed by a verb, such as &amp;quot;Debbie remembered &amp;quot; In sentence subjects are asked to write any sentence containing a given verb. An example of this type of study is Confine et al. (1984). An alternative to these psychological methods is to use corpus data. This can be done automatically with unparsed corpora (Briscoe and Carroll 1997, Manning 1993, Ushioda et al. 1993), from parsed corpora such as Marcus et al.&apos;s (1993) Treebank (Merlo 1994, Framis 1994) or manually as was done for COMLEX (Macleod and Grishman 1994). The advantage of any of these corpus methods is the much greater amount of data that can be used, and the much more natural contexts. This seems to make it preferable to data generated in psychological studies. Recent studies (Merlo 1994, Gibson et al. 1996) have found differences between corpus frequencies and experimental measures. This suggests that corpus-based frequencies and experiment-based frequencies may not be interchangeable. To clar</context>
</contexts>
<marker>Ushioda, Evans, Gibson, Waibel, 1993</marker>
<rawString>Ushioda, A., Evans, D., Gibson, T. &amp; Waibel, A. (1993) The automatic acquisition of frequencies of verb subcategorization frames from tagged corpora. In Boguraev, B. &amp; Pustejovsky, J. eds. SIGLEX ACL Workshop of Acquisition of Lexical Knowledge from Text. Columbus, Ohio: 95-106</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>