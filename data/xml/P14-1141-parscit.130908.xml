<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000010">
<title confidence="0.990107">
Predicting Instructor’s Intervention in MOOC forums
</title>
<author confidence="0.995708">
Snigdha Chaturvedi Dan Goldwasser Hal Daum´e III
</author>
<affiliation confidence="0.9992985">
Department of Computer Science,
University of Maryland, College Park, Maryland
</affiliation>
<email confidence="0.990916">
{snigdhac, goldwas1, hal}@umiacs.umd.edu
</email>
<sectionHeader confidence="0.993796" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999800111111111">
Instructor intervention in student discus-
sion forums is a vital component in
Massive Open Online Courses (MOOCs),
where personalized interaction is limited.
This paper introduces the problem of pre-
dicting instructor interventions in MOOC
forums. We propose several prediction
models designed to capture unique aspects
of MOOCs, combining course informa-
tion, forum structure and posts content.
Our models abstract contents of individ-
ual posts of threads using latent categories,
learned jointly with the binary interven-
tion prediction problem. Experiments over
data from two Coursera MOOCs demon-
strate that incorporating the structure of
threads into the learning problem leads to
better predictive performance.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999975233333333">
Ubiquitous computing and easy access to high
bandwidth internet have reshaped the modus
operandi in distance education towards Massive
Open Online Courses (MOOCs). Courses offered
by ventures such as Coursera and Udacity now im-
part inexpensive and high-quality education from
field-experts to thousands of learners across geo-
graphic and cultural barriers.
Even as the MOOC model shows exciting pos-
sibilities, it presents a multitude of challenges that
must first be negotiated to completely realize its
potential. MOOCs platforms have been especially
criticized on grounds of lacking a personalized
educational experience (Edmundson, 2012). Un-
like traditional classrooms, the predominant mode
of interaction between students and instructors in
MOOCs is via online discussion forums. Ideally,
forum discussions can help make up for the lack
of direct interaction, by enabling students to ask
questions and clarify doubts. However, due to
huge class sizes, even during the short duration
of a course, MOOCs witness a very large number
of threads on these forums. Owing to extremely
skewed ratios of students to instructional staff, it
can be prohibitively time-consuming for the in-
structional staff to manually follow all threads of a
forum. Hence there is a pressing need for automat-
ically curating the discussions for the instructors.
In this paper, we focus on identifying situa-
tions in which instructor (used interchangeably
with “instructional staff” in this paper) interven-
tion is warranted. Using existing forum posts and
interactions, we frame this as a binary prediction
problem of identifying instructor’s intervention in
forum threads. Our initial analysis revealed that
instructors usually intervene on threads discussing
students’ issues close to a quiz or exam. They
also take interest in grading issues and logistics
problems. There are multiple cues specific to the
MOOC setting, which when combined with the
rich lexical information present in the forums, can
yield useful predictive models.
Analyzing forum-postings contents and bring-
ing the most pertinent content to the instructor’s
attention would help instructors receive timely
feedback and design interventions as needed.
From the students’ perspective, the problem is ev-
ident from an examination of existing forum con-
tent, indicating that if students want instructor’s
input on some issues, the only way for them to
get his/her attention is by ‘up-voting’ their votes.
Fig. 1 provides some examples of this behavior.
This is clearly an inefficient solution.
Our main technical contribution is introducing
three different models addressing the task of pre-
dicting instructor interventions. The first uses a lo-
gistic regression model that primarily incorporates
high level information about threads and posts.
However, forum threads have structure which is
not leveraged our initial model. We present two
</bodyText>
<page confidence="0.92752">
1501
</page>
<note confidence="0.7188692">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1501–1511,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
“The problem summary: Anyone else having problems viewing the video lecture...very choppy. If you are also experi-
encing this issue; please upvote this post.”
“I read that by up-voting threads and posts you can get the instructors’ attention faster.”
</note>
<footnote confidence="0.668016333333333">
“Its is very bad to me that I achieved 10 marks in my 1st assignment and now 9 marks in my 2nd assignment, now I won’t
get certificate, please Course staff it is my appeal to change the passing scheme or please be lenient. Please upvote my
post so that staff take this problem under consideration.”
</footnote>
<figureCaption confidence="0.9738855">
Figure 1: Sample posts that showing students desiring instructor’s attention have to resolve to the ineffi-
cient method of getting their posts upvoted.
</figureCaption>
<bodyText confidence="0.998810333333333">
additional structured models. Both models assume
that posts of a thread structure it in form of a story
or a “chain of events.” For example, an opening
post of a thread might pose a question and the fol-
lowing posts can then answer or comment on the
question. Our second and third models tap this
linear ‘chain of events’ behavior by assuming that
individual posts belong to latent categories which
represent their textual content at an abstract level
and that an instructor’s decision to reply to a post
is based on this chain of events (represented by the
latent categories). We present two different ways
of utilizing this ‘chain of events’ behavior for pre-
dicting instructor’s intervention which can be ei-
ther simply modeled as the ‘next step’ is this chain
of events (Linear Chain Markov Model) or as a
decision globally depending on the entire chain
(Global Chain Model). Our experiments on two
different datasets reveal that using the latent post
categories helps in better prediction.
Our contributions can be summarized as:
</bodyText>
<listItem confidence="0.92368675">
• We motivate and introduce the important
problem of predicting instructor intervention
in MOOC forums
• We present two chain based models that in-
corporate thread structure.
• We show the utility of modeling thread struc-
ture, and the value of lexical and domain spe-
cific knowledge for the prediction task
</listItem>
<sectionHeader confidence="0.99955" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998484264150943">
To the best of our knowledge, the problem of pre-
dicting instructor’s intervention in MOOC forums
has not been addressed yet. Prior work deals with
analyzing general online discussion forums of so-
cial media sites (Kleinberg, 2013): such as pre-
dicting comment volume (Backstrom et al., 2013;
De Choudhury et al., 2009; Wang et al., 2012;
Tsagkias et al., 2009; Yano and Smith, 2010; Artzi
et al., 2012) and rate of content diffusion (Kwak et
al., 2010; Lerman and Ghosh, 2010; Bakshy et al.,
2011; Romero et al., 2011; Artzi et al., 2012) and
also question answering (Chaturvedi et al., 2014).
Wang et al. (2007) incorporate thread structure
of conversations using features in email threads
while Goldwasser and Daum´e III (2014) use la-
tent structure, aimed to identify relevant dialog
segments, for predicting objections during court-
room deliberations. Other related work include
speech act recognition in emails and forums but
at a sentence level (Jeong et al., 2009), and us-
ing social network analysis to improve message
classification into pre-determined types (Fortuna
et al., 2007). Discussion forums data has also been
used to address other interesting challenges such
as extracting chatbox knowledge for use in gen-
eral online forums (Huang et al., 2007) and auto-
matically extracting answers from discussion fo-
rums (Catherine et al., 2013), subjectivity analy-
sis of online forums (Biyani et al., 2013). Most
of these methods use ideas similar to ours: identi-
fying that threads (or discussions) have an under-
lying structure and that messages belong to cate-
gories. However, they operate in a different do-
main, which makes their goals and methods dif-
ferent from ours.
Our work is most closely related to that of Back-
strom et al. (2013) which introduced the re-entry
prediction task —predicting whether a user who
has participated in a thread will later contribute
another comment to it. While seemingly related,
their prediction task, focusing on users who have
already commented on a thread, and their algorith-
mic approach are different than ours. Our work
is also very closely related to that of Wang et al.
(2013) who predict solvedness —which predicts
if there is a solution to the original problem posted
in the thread. Like us, they believe that category
of posts can assist in the prediction task, however,
possibly owing to the complexity of general dis-
cussion forums, they had to manually create and
annotate data with a sophisticated taxonomy. We
do not make such assumptions.
The work presented in (G´omez et al., 2008;
</bodyText>
<page confidence="0.993976">
1502
</page>
<bodyText confidence="0.999399774193548">
Liben-Nowell and Kleinberg, 2008; Kumar et al.,
2010; Golub and Jackson, 2010; Wang et al.,
2011; Aumayr et al., 2011) discuss characteriz-
ing threads using reply-graphs (often trees) and
learning this structure. However, this representa-
tion is not natural for the MOOC domain where
discussions are relatively more focused on the
thread topic and are better organized using sec-
tions within the forums.
Although most prior work focuses on discus-
sion forums of social media sites such as Twitter
or Facebook, where the dynamics of interaction is
very different from MOOCs, a small number of
recent work address the unique MOOC setting.
Stump et al. (2013) propose a framework for
categorizing forum posts by designing a taxonomy
and annotating posts manually to assist general fo-
rum analysis. Our model learns categories in a
data-driven manner guided by the binary super-
vision (intervention decision) and serves a differ-
ent purpose. Nevertheless, in Sec. 4.3 we compare
the categories learnt by our models with those pro-
posed by Stump et al. (2013).
Apart from this, recent works have looked into
interesting challenges in this domain such as bet-
ter peer grading models (Piech et al., 2013), code
review (Huang et al., 2013; Nguyen et al., 2014),
improving student engagement (Anderson et al.,
2014) and understanding how students learn and
code (Piech et al., 2012; Kizilcec et al., 2013;
Ramesh et al., 2013).
</bodyText>
<sectionHeader confidence="0.999037" genericHeader="method">
3 Intervention Prediction Models
</sectionHeader>
<bodyText confidence="0.55594">
In this section, we explain our models in detail.
</bodyText>
<subsectionHeader confidence="0.999551">
3.1 Problem Setting
</subsectionHeader>
<bodyText confidence="0.999946533333333">
In our description it is assumed that a discus-
sion board is organized into multiple forums (rep-
resenting topics such as “Assignment”, “Study
Group” etc.). A forum consists of multiple
threads. Each thread (t) has a title and consists of
multiple posts (pi). Individual posts do not have
a title and the number of posts varies dramatically
from one thread to another. We address the prob-
lem of predicting if the course instructor would in-
tervene on a thread, t. The instructor’s decision to
intervene, r, equals 0 when the instructor doesn’t
reply to the thread and 1 otherwise. The individual
posts are not assumed to be labeled with any cat-
egory and the only supervision given to the model
during training is in form of intervention decision.
</bodyText>
<subsectionHeader confidence="0.998723">
3.2 Logistic Regression (LR)
</subsectionHeader>
<bodyText confidence="0.999806333333333">
Our first attempt at solving this problem involved
training a logistic regression for the binary predic-
tion task which models P(rIt).
</bodyText>
<subsectionHeader confidence="0.933061">
3.2.1 Feature Engineering
</subsectionHeader>
<bodyText confidence="0.987127846153846">
Our logistic regression model uses the follow-
ing two types of features: Thread only features
and Aggregated post features. ‘Thread only fea-
tures’ capture information about the thread such
as when, where, by who was the thread posted and
lexical features based on the title of the thread.
While these features provide a high-level infor-
mation about the thread, it is also important to
analyze the contents of the posts of the thread.
In order to maintain a manageable feature space,
we compress the features from posts and represent
them using our ‘Aggregated post features’.
Thread only features:
</bodyText>
<listItem confidence="0.997969375">
1. a binary feature indicating if the thread was
started by an anonymous user
2. three binary features indicating whether the
thread was marked as approved, unresolved
or deleted (respectively)
3. forum id in which the thread was posted
4. time when the thread was started
5. time of last posting on the thread
6. total number of posts in the thread
7. a binary feature indicating if the thread title
contains the words lecture or lectures
8. a binary feature indicating if the thread title
contains the words assignment, quiz, grade,
project, exam (and their plural forms)
Aggregated post features:
9. sum of number of votes received by the indi-
vidual posts
10. mean and variance of the posting times of in-
dividual posts in the thread
11. mean of time difference between the post-
ing times of individual posts and the closest
course landmark. A course landmark is the
deadline of an assignment, exam or project.
12. sum of count of occurrences of assessment
related words e.g. grade, exam, assignment,
quiz, reading, project etc. in the posts
13. sum of count of occurrences of words indicat-
ing technical problems e.g. problem, error
14. sum of count of occurrences of thread con-
clusive words like thank you and thank
15. sum of count of occurrences of request, sub-
mit, suggest
</listItem>
<page confidence="0.909437">
1503
</page>
<figure confidence="0.998536">
(a) Linear Chain Markov Model (LCMM)
(b) Global Chain Model (GCM)
</figure>
<figureCaption confidence="0.996505">
Figure 2: Diagrams of the Linear Chain Markov
</figureCaption>
<bodyText confidence="0.97743475">
Model (LCMM) and the Global Chain Model
(GCM). pi, r and 0(t) are observed and hi are the
latent variables. pi and hi represent the posts of
the thread and their latent categories respectively;
r represents the instructor’s intervention and 0(t)
represent the non-structural features used by the
logistic regression model.
We had also considered and dropped (because
of no performance gain) other features about iden-
tity of the user who started the thread, number
of distinct participants in the thread (an impor-
tant feature used by Backstrom et al. (2013)), bi-
nary feature indicating if the first and the last posts
were by the same user, average number of words
in the thread’s posts, lexical features capturing ref-
erences to the instructors in the posts etc.
</bodyText>
<subsectionHeader confidence="0.999034">
3.3 Linear Chain Markov Model (LCMM)
</subsectionHeader>
<bodyText confidence="0.995221583333333">
The logistic regression model is good at exploit-
ing the thread level features but not the content of
individual posts. The ‘Aggregated post features’
attempt to capture this information but since the
number of posts in a thread is variable, these fea-
tures relied on aggregated values. We believe that
considering aggregate values is not sufficient for
the task in hand. As noted before, posts of a thread
are not independent of each other. Instead, they
are arranged chronologically such that a post is
published in reply to the preceding posts and this
For every thread, t, in the dataset:
</bodyText>
<listItem confidence="0.929578555555556">
1. Choose a start state, h1, and emit the first
post, p1.
2. For every subsequent post, pi b i E
{2...n} :
(a) Transition from hi−1 to hi.
(b) Emit post pi.
3. Generate the instructor’s intervention
decision, r, using the last state hn and
non-structural features, 0(t).
</listItem>
<figureCaption confidence="0.8817705">
Figure 3: Instructor’s intervention decision pro-
cess for the Linear Chain Markov Model.
</figureCaption>
<bodyText confidence="0.99807148">
might effect an instructor’s decision to reply. For
example, consider a thread that starts with a ques-
tion. The following posts will be students’ attempt
to answer the question or raise further concerns or
comment on previous posts. The instructor’s post,
though a future event, will be a part of this process.
We, therefore, propose to model this complete
process using a linear chain markov model shown
in Fig. 2a. The model abstractly represents the in-
formation from individual posts (pi) using latent
categories (hi). The intervention decision, r, is
the last step in the chain and thus incorporates in-
formation from the individual posts. It also de-
pends on the thread level features: ‘Thread only
features’ and the ‘Aggregated post features’ jointly
represented by 0(t) (also referred to as the non-
structural features). This process is explained in
Fig. 3.
We use hand-crafted features to model the dy-
namics of the generative process. Whenever a la-
tent state emits a post or transits to another latent
state (or to the final intervention decision state),
emission and transition features get fired which are
then multiplied by respective weights to compute
a thread’s ‘score’:
</bodyText>
<equation confidence="0.9917">
fw(t,p) = max[w · φ(p, r, h, t)] (1)
h
</equation>
<bodyText confidence="0.999915">
Note that the non-structural features, 0(t), also
contribute to the final score.
</bodyText>
<subsectionHeader confidence="0.979154">
3.3.1 Learning and Inference
</subsectionHeader>
<bodyText confidence="0.9999878">
During training we maximize the combined scores
of all threads in the dataset using a generic EM
style algorithm. The supervision in this model is
provided only in form of the observed interven-
tion decision, r and the post categories, hi are hid-
</bodyText>
<equation confidence="0.999611125">
p1 p2 pn
h1
h2 hn r φ(t)
T
p1 p2 pn
T
h1 h2 hn
r φ(t)
</equation>
<page confidence="0.944607">
1504
</page>
<bodyText confidence="0.999917272727273">
den. The model uses the pseudocode shown in Al-
gorithm 1 to iteratively refine the weight vectors.
In each iteration, the model first uses viterbi algo-
rithm to decode thread sequences with the current
weights wt to find optimal highest scoring latent
state sequences that agree with the observed in-
tervention state (r = r0). In the next step, given
the latent state assignments from the previous step,
a structured perceptron algorithm (Collins, 2002)
is used to update the weights wt+1 using weights
from the previous step, wt, initialization.
</bodyText>
<listItem confidence="0.9454585">
Algorithm 1 Training algorithm for LCMM
1: Input: Labeled data D = {(t, p, r)i}
2: Output: Weights w
3: Initialization: Set wj randomly, bj
4: for t : 1 to N do
5: ˆhi = arg maxh[wt · 0(p, r, h, t)] such
that r = ribi
6: wt+1 = StructuredPerceptron(t, p, ˆh, r)
7: end for
8: return w
</listItem>
<bodyText confidence="0.999119333333333">
While testing, we use the learned weights and
viterbi decoding to compute the intervention state
and the best scoring latent category sequence.
</bodyText>
<subsectionHeader confidence="0.863929">
3.3.2 Feature Engineering
</subsectionHeader>
<bodyText confidence="0.99983025">
In addition to the ‘Thread Only Features’ and the
‘Aggregated post features’, 0(t) (Sec. 3.2.1, this
model uses the following emission and transition
features:
</bodyText>
<subsubsectionHeader confidence="0.749609">
Post Emission Features:
</subsubsectionHeader>
<listItem confidence="0.961464871794872">
1. 0(pi, hi) = count of occurrences of question
words or question marks in pi if the state is
hi; 0 otherwise.
2. 0(pi, hi) = count of occurrences of thank
words (thank you or thanks) in pi if the state
is hi; 0 otherwise.
3. 0(pi, hi) = count of occurrences of greeting
words (e.g. hi, hello, good morning, welcome
etc ) in pi if the state is hi; 0 otherwise.
4. 0(pi, hi) = count of occurrences of assess-
ment related words (e.g. grade, exam, assign-
ment, quiz, reading, project etc.) in pi if the
state is hi; 0 otherwise.
5. 0(pi, hi) = count of occurrences of request,
submit or suggest in pi if the state is hi; 0
otherwise.
6. 0(pi, hi) = log(course duration/t(pi)) if the
state is hi; 0 otherwise. Here t(pi) is the dif-
ference between the posting time of pi and
the closest course landmark (assignment or
project deadline or exam).
7. 0(pi, pi−1, hi) = difference between posting
times of pi and pi−1 normalized by course
duration if the state is hi; 0 otherwise.
Transition Features:
1. 0(hi−1, hi) = 1 if previous state is hi−1 and
current state is hi; 0 otherwise.
2. 0(hi−1, hi, pi, pi−1) = cosine similarity be-
tween pi−1 and pi if previous state is hi−1
and current state is hi; 0 otherwise.
3. 0(hi−1, hi, pi, pi−1) = length of pi if previ-
ous state is hi−1, pi−1 has non-zero question
words and current state is hi; 0 otherwise.
4. 0(hn, r) = 1 if last post’s state is hn and in-
tervention decision is r; 0 otherwise.
5. 0(hn, r, pn) = 1 if last post’s state is hn, pn
has non-zero question words and intervention
decision is r; 0 otherwise.
6. 0(hn, r, pn) = log(course duration/t(pn)) if
</listItem>
<bodyText confidence="0.8650296">
last post’s state is hn and intervention deci-
sion is r; 0 otherwise. Here t(pn) is the dif-
ference between the posting time of pn and
the closest course landmark (assignment or
project deadline or exam).
</bodyText>
<subsectionHeader confidence="0.692587">
3.4 Global Chain Model (GCM)
</subsectionHeader>
<bodyText confidence="0.999665875">
In this model we propose another way of incorpo-
rating the chain structure of a thread. Like the pre-
vious model, this model also assumes that posts
belong to latent categories. It, however, doesn’t
model the instructor’s intervention decision as a
step in the thread generation process. Instead, it
assumes that instructor’s decision to intervene is
dependent on all the posts in the threads, mod-
eled using the latent post categories. This model
is shown in Fig. 2b. Assuming that p represents
posts of thread t, h represents the latent category
assignments, r represents the intervention deci-
sion; feature vector, 0(p, r, h, t), is extracted for
each thread and using the weight vector, w, this
model defines a decision function, similar to what
is shown in Equation 1.
</bodyText>
<subsectionHeader confidence="0.939248">
3.4.1 Learning and Inference
</subsectionHeader>
<bodyText confidence="0.999513666666667">
Similar to the traditional maximum margin based
Support Vector Machine (SVM) formulation, our
model’s objective function is defined as:
</bodyText>
<equation confidence="0.94102625">
l(−rjfw(tj,pj)) (2)
min
w λ2||w||2 + T
j
</equation>
<page confidence="0.917769">
1505
</page>
<bodyText confidence="0.998583">
where A is the regularization coefficient, tj is the
jth thread with intervention decision rj and pj are
the posts of this thread. w is the weight vector, l(·)
is the squared hinge loss function and f,,,(tj, pj) is
defined in Equation 1.
Replacing the term f,,,(tj, pj) with the con-
tents of Equation 1 in the minimization objective
above, reveals the key difference from the tradi-
tional SVM formulation - the objective function
has a maximum term inside the global minimiza-
tion problem making it non-convex.
We, therefore, employ the optimization algo-
rithm presented in (Chang et al., 2010) to solve
this problem. Exploiting the semi-convexity prop-
erty (Felzenszwalb et al., 2010), the algorithm
works in two steps, each executed iteratively. In
the first step, it determines the latent variable as-
signments for positive examples. The algorithm
then performs two step iteratively - first it deter-
mines the structural assignments for the negative
examples, and then optimizes the fixed objective
function using a cutting plane algorithm. Once
this process converges for negative examples, the
algorithm reassigns values to the latent variables
for positive examples, and proceeds to the second
step. The algorithm stops once a local minimum
is reached. A somewhat similar approach, which
uses the Convex-Concave Procedure (CCCP) is
presented by (Yu and Joachims, 2009).
At test time, given a thread, t, and it posts, p,
we use the learned weights to compute f,,,(t, p)
and classify it as belonging to the positive class
(instructor intervenes) if f,,,(t, p) ≥ 0.
</bodyText>
<subsectionHeader confidence="0.693108">
3.4.2 Feature Engineering
</subsectionHeader>
<bodyText confidence="0.997428857142857">
The feature set used by this model is very sim-
ilar to the features used by the previous model.
In addition to the non-structural features used
by the logistic regression model (Sec. 3.2.1), it
uses all the Post Emission features and the three
transition features represented by φ(hi−1, hi) and
φ(hi−1, hi, pi, pi−1) as described in Sec. 3.3.2.
</bodyText>
<sectionHeader confidence="0.997681" genericHeader="method">
4 Empirical Evaluation
</sectionHeader>
<bodyText confidence="0.914913">
This section describes our experiments.
</bodyText>
<subsectionHeader confidence="0.957248">
4.1 Datasets and Evaluation Measure
</subsectionHeader>
<bodyText confidence="0.999812666666667">
For our experiments, we have used the forum
content of two MOOCs from different domains
(science and humanities), offered by Coursera1,
</bodyText>
<footnote confidence="0.929177">
1https://www.coursera.org/
</footnote>
<bodyText confidence="0.999787025">
a leading education technology company. Both
courses were taught by professors from the Uni-
versity of Maryland, College Park.
Genes and the Human Condition (From Behav-
ior to Biotechnology) (GHC) dataset. 2 This
course was attended by 30,000 students and the
instructional staff comprised of 2 instructors, 3
Teaching Assistants and 56 technical support staff.
The discussion forum of this course consisted of
980 threads composed of about 3,800 posts.
Women and the Civil Rights Movement (WCR)
dataset. 3 The course consisted of a classroom
of about 14,600 students, 1 instructor, 6 Teaching
Assistants and 49 support staff. Its discussion fo-
rum consisted of 800 threads and 3,900 posts.
We evaluate our models on held-out test sets.
For the GHC dataset, the test set consisted of 186
threads out of which the instructor intervened on
24 while, for the WCR dataset, the instructor in-
tervened on 21 out of 155 threads.
Also, it was commonly observed that after an
instructor intervenes on a thread, its posting and/or
viewing behavior increases. We, therefore, only
consider the student posts until the instructor’s first
intervention. Care was also taken to not use fea-
tures that increased/decreased disproportionately
because of the instructor’s intervention such as
number of views or votes of a thread.
In our evaluation we approximate instructor’s
‘should reply’ instances with those where the in-
structor indeed replied. Unlike general forum
users, we believe that the correlation between the
two scenarios is quite high for instructors. It is
their responsibility to reply, and by choosing to a
MOOC, they have ‘bought in’ to the idea of forum
participation. The relatively smaller class sizes of
these two MOOCs also ensured that most threads
were manually reviewed, thus reducing instances
of ‘missed’ threads while retaining the posting be-
havior and content of a typical MOOC.
</bodyText>
<subsectionHeader confidence="0.974155">
4.2 Experimental Results
</subsectionHeader>
<bodyText confidence="0.999941666666667">
Since the purpose of solving this problem is to
identify the threads which should be brought to
the notice of the instructors, we measure the per-
formance of our models using F-measure of the
positive class. The values of various parameters
were selected using 10-fold Cross Validation on
</bodyText>
<footnote confidence="0.998316666666667">
2https://www.coursera.org/course/genes
3https://www.coursera.org/course/
womencivilrights
</footnote>
<page confidence="0.959265">
1506
</page>
<table confidence="0.9957595">
Model Genes and the Human Condition (GHC) Women and the Civil Rights (WCR)
P R F P R F
LR 44.44 16.67 24.24 66.67 15.38 25.00
J48 45.50 20.80 28.55 25.00 23.10 24.01
LCMM 33.33 29.17 31.11 42.86 23.08 30.00
GCM 60.00 25.00 35.29 50.00 18.52 27.03
</table>
<tableCaption confidence="0.997959">
Table 1: Held-out test set performances of chain models, LCMM and GCM, are better than that of the
</tableCaption>
<figureCaption confidence="0.740443">
unstructured models, LR and J48.
Figure 4: Visualization of lexical contents of the
</figureCaption>
<bodyText confidence="0.999163740740741">
categories learnt by our model from the GHC
dataset. Each row is a category and each column
represents a feature vector. Bright cream color
represents high values while lower values are rep-
resented by darker shades. Dark beige columns
are used to better separate the five feature clusters,
F1-F5, which represent words that are common in
thanking, logistics-related, introductory, syllabus
related and miscellaneous posts respectively. Cat-
egories 1,2,3 and 4 are dominated by F2, F4, F1
and F3 respectively indicating a semantic segrega-
tion of posts by our model’s categories.
the training set. Table 1 presents the performances
of the proposed models on the held-out test sets.
We also report performance of a decision tree
(J48) on the test sets for sake of comparison.
We can see that the chain based models, Linear
Chain Markov Model (LCMM) and Global Chain
Model (GCM), outperform the unstructured mod-
els, namely Logistic regression (LR) and Decision
Trees (J48). This validates our hypothesis that us-
ing the post structure results in better modeling of
instructor’s intervention.
The table also reveals that GCM yields high pre-
cision and low recall values, which is possibly due
to the model being more conservative owing to in-
formation from all posts of the thread.
</bodyText>
<subsectionHeader confidence="0.997521">
4.3 Visual Exploration of Categories
</subsectionHeader>
<bodyText confidence="0.999991083333333">
Our chain based models assume that posts belong
to different (latent) categories and use these cate-
gories to make intervention predictions. Since this
process of discovering categories is data driven, it
would be interesting to examine the contents of
these categories. Fig. 4 presents a heat map of
lexical content of categories identified by LCMM
from the GHC dataset. The value of H (num-
ber of categories) was set to be 4 and was pre-
determined during the model selection procedure.
Each row of the heat map represents a category
and the columns represent values of individual fea-
</bodyText>
<equation confidence="0.3979675">
tures, f(w, c), defined as: f(w, c) = C(w,c)
&lt;C(w,c)&gt;
</equation>
<bodyText confidence="0.999639518518518">
where, C(w, c) is total count of occurrences of a
word, w, in all posts assigned to category, c and
&lt; C(w, c) &gt; represents its expected count based
on its frequency in the dataset. While the actual
size of vocabulary is huge, we use only a small
subset of words in our feature vector for this visu-
alization. These feature values, after normaliza-
tion, are represented in the heat map using col-
ors ranging from bright cream (high value) to dark
black (low value). The darker the shade of a cell,
the lower is the value represented by it.
For visual convenience, the features are man-
ually clustered into five groups (F1 to F5) each
separated by a dark beige colored column in the
heat map. The first column of the heat map rep-
resents the F1 group which consists of words like
thank you, thanks etc. These words are character-
istic of posts that mark either the conclusion of a
resolved thread or are posted towards the end of
the course. Rows corresponding to the category 3
in Table 2 show two examples of such posts. Simi-
larly, F2 represents the features related to logistics
of the course and F3 captures introductory posts
by new students. Finally, F4 contains words that
are closely related to the subfield of gene and hu-
man conditions and would appear in posts that dis-
cuss specific aspects or chapters of the course con-
</bodyText>
<page confidence="0.9498">
1507
</page>
<figure confidence="0.468145">
(a) Genes and the Human Condition dataset
</figure>
<bodyText confidence="0.999670333333333">
tents, while F5 contains general buzz words that
would appear frequently in any biology course.
Analyzing individual rows of the heat map, we
can see that out of F1 to F4, Categories 1, 2, 3 and
4 are dominated by logistics (F2), course content
related (F4), thank you (F1) and introductory posts
(F3) respectively, represented by bright colors in
their respective rows. We also observe similar cor-
relations while examining the columns of the heat
map. Also, F5, which contains words common to
the gene and human health domain, is scattered
across multiple categories. For example, dna/rna
and breeding are sufficiently frequent in category
1 as well as 2.
Table 2 gives examples of representative posts
from the four clusters. Due to space constraints,
we show only part of the complete post. We can
see that these examples agree with our observa-
tions from the heat map.
Furthermore, as noted in Sec. 2, we compare
the semantics of clusters learnt by our models with
those proposed by Stump et al. (2013) even though
the two categorizations are not directly compara-
ble. Nevertheless, generally speaking, our cate-
gory 1 corresponds to Stump et al. (2013)’s Course
structure/policies and category 2 corresponds to
Content. Interestingly, categories 3 and 4, which
represent valedictory and introductory posts, cor-
respond to a single Social/affective from the previ-
ous work.
We can, therefore, conclude that the model, in-
deed splits the posts into categories that look se-
mantically coherent to the human eyes.
</bodyText>
<figure confidence="0.741593">
(b) Women and the Civil Rights Movement dataset
</figure>
<figureCaption confidence="0.9785405">
Figure 5: Cross validation performances of the
two models with increasing number of categories.
</figureCaption>
<bodyText confidence="0.982036">
to the explicit regularization coefficient which
helps combat over-fitting, by encouraging zero
weights for unnecessary categories.
</bodyText>
<subsectionHeader confidence="0.986137">
4.4 Choice of Number of Categories
</subsectionHeader>
<bodyText confidence="0.9996579375">
Our chain based models, assigning forum posts to
latent categories, are parameterized with H, the
number of categories. We therefore, study the sen-
sitivity of our models to this parameter. Fig. 5,
plots the 10-fold cross validation performance of
the models with increasing values of H for the two
datasets. Interestingly, the sensitivity of the two
models to the value of H is very different.
The LCMM model’s performance fluctuates as
the value of H increases. The initial performance
improvement might be due to an increase in the ex-
pressive power of the model. Performance peaks
at H = 4 and then decreases, perhaps owing to
over-fitting of the data.
In contrast, GCM performance remains steady
for various values of H which might be attributed
</bodyText>
<subsectionHeader confidence="0.698812">
4.5 How important are linguistic features?
</subsectionHeader>
<bodyText confidence="0.998381">
We now focus on the structure independent fea-
tures and experiment with their predictive value,
according to types. We divide the features used by
the LR into the following categories:4
</bodyText>
<listItem confidence="0.991901727272727">
• Full: set of all features (feature no. 1 to 15)
• lexical: based on content of thread titles and
posts (feature no. 7 to 8 and 12 to 13)
• landmark: based on course landmarks (e.g,
exams, quizzes) information (feature no. 11)
• MOOCs-specific: features specific to the
MOOCs domain (lexical + landmark fea-
tures)
• post: based only on aggregated posts infor-
mation (feature no. 9 to 15)
• temporal: based on posting time patterns
</listItem>
<bodyText confidence="0.962334875">
(feature no. 4, 5 and 10)
Fig. 6 shows 10-fold cross validation F-measure
of the positive class for LR when different types of
features are excluded from the full set.
The figure reveals that the MOOCs-specific
features (purple bar) are important for both the
datasets indicating a need for designing special-
ized models for forums analysis in this domain.
</bodyText>
<footnote confidence="0.932531">
4Please refer to Sec 3.2.1 for description of the feature id.
</footnote>
<page confidence="0.923917">
1508
</page>
<table confidence="0.999215444444444">
Category Example posts
1 ‘I’m having some issues with video playback. I have downloaded the videos to my laptop...’
1 ‘There was no mention of the nuclear envelope in the Week One lecture, yet it was in the quiz. Is this a mistake?’
2 ‘DNA methylation is a crucial part of normal development of organisms and cell differentiation in higher organisms...’
2 ‘In the lecture, she said there are...I don’t see how tumor-suppressor genes are a cancer group mutation.’
3 ‘Thank you very much for a most enjoyable and informative course.’
3 ‘Great glossary! Thank you!’
4 ‘Hello everyone, I’m ... from the Netherlands. I’m a life science student.
4 ‘Hi, my name is ... this is my third class with coursera’
</table>
<tableCaption confidence="0.9874855">
Table 2: Representative posts from the four categories learnt by our model. Due to space and privacy
concerns we omit some parts of the text, indicated by “... ”.
</tableCaption>
<figure confidence="0.9776655">
(a) Genes and the Human Condition dataset
(b) Women and the Civil Rights Movement dataset
</figure>
<figureCaption confidence="0.921283">
Figure 6: Cross validation performances of the
various feature types for the two datasets.
</figureCaption>
<bodyText confidence="0.999573117647059">
Also, lexical features (red bar) and post features
(blue bar) have pretty dramatic effects in GHC and
WCR data respectively.
Interestingly, removing the landmark feature set
(green bar) causes a considerable drop in predic-
tive performance, even though it consists of only
one feature. Other temporal features (orange bar)
also turn out to be important for the prediction.
From a separate instructor activity vs time graph
(not shown due to space constraints), we observed
that instructors tend to get more active as the
course progresses and their activity level also in-
creases around quizzes/exams deadlines.
We can, therefore, conclude that all feature
types are important and that lexical as well as
MOOC specific analysis is necessary for model-
ing instructor’s intervention.
</bodyText>
<sectionHeader confidence="0.999299" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999972875">
One of the main challenges in MOOCs is man-
aging student-instructor interaction. The massive
scale of these courses rules out any form of per-
sonalized interaction, leaving instructors with the
need to go over the forum discussions, gauge stu-
dent reactions and selectively respond when ap-
propriate. This time consuming and error prone
task stresses the need for methods and tools sup-
plying this actionable information automatically.
This paper takes a first step in that direction,
and formulates the novel problem of predicting in-
structor intervention in MOOC discussion forums.
Our main technical contribution is to construct
predictive models combining information about
forum post content and posting behavior with in-
formation about the course and its landmarks.
We propose three models for addressing the
task. The first, a logistic regression model is
trained on thread level and aggregated post fea-
tures. The other two models take thread structure
into account when making the prediction. These
models assume that posts can be represented by
categories which characterize post content at an
abstract level, and treat category assignments as
latent variables organized according to, and influ-
enced by, the forum thread structure.
Our experiments on forum data from two differ-
ent Coursera MOOCs show that utilizing thread
structure is important for predicting instructor’s
behavior. Furthermore, our qualitative analysis
shows that our latent categories are semantically
coherent to human eye.
</bodyText>
<page confidence="0.995306">
1509
</page>
<sectionHeader confidence="0.989529" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999062788990825">
Ashton Anderson, Daniel P. Huttenlocher, Jon M.
Kleinberg, and Jure Leskovec. 2014. Engaging with
massive online courses. In WWW, pages 687–698.
Yoav Artzi, Patrick Pantel, and Michael Gamon. 2012.
Predicting responses to microblog posts. In Pro-
ceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
NAACL HLT ’12, pages 602–606, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Erik Aumayr, Jeffrey Chan, and Conor Hayes. 2011.
Reconstruction of threaded conversations in online
discussion forums. In Lada A. Adamic, Ricardo A.
Baeza-Yates, and Scott Counts, editors, ICWSM.
The AAAI Press.
Lars Backstrom, Jon Kleinberg, Lillian Lee, and Cris-
tian Danescu-Niculescu-Mizil. 2013. Characteriz-
ing and curating conversation threads: Expansion,
focus, volume, re-entry. In Proceedings of the Sixth
ACM International Conference on Web Search and
Data Mining, WSDM ’13, pages 13–22, New York,
NY, USA. ACM.
Eytan Bakshy, Jake M. Hofman, Winter A. Mason, and
Duncan J. Watts. 2011. Everyone’s an influencer:
Quantifying influence on twitter. In Proceedings of
the Fourth ACM International Conference on Web
Search and Data Mining, WSDM ’11, pages 65–74,
New York, NY, USA. ACM.
Prakhar Biyani, Cornelia Caragea, and Prasenjit Mitra.
2013. Predicting subjectivity orientation of online
forum threads. In CICLing (2), pages 109–120.
Rose Catherine, Rashmi Gangadharaiah, Karthik
Visweswariah, and Dinesh Raghu. 2013. Semi-
supervised answer extraction from discussion fo-
rums. In Proceedings of the Sixth International Joint
Conference on Natural Language Processing, pages
1–9, Nagoya, Japan, October. Asian Federation of
Natural Language Processing.
Ming-Wei Chang, Dan Goldwasser, Dan Roth, and
Vivek Srikumar. 2010. Discriminative learning over
constrained latent representations. In Human Lan-
guage Technologies: The 2010 Annual Conference
of the North American Chapter of the Association
for Computational Linguistics, HLT ’10, pages 429–
437, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Snigdha Chaturvedi, Vittorio Castelli, Radu Florian,
Ramesh M. Nallapati, and Hema Raghavan. 2014.
Joint question clustering and relevance prediction
for open domain non-factoid question answering. In
Proceedings of the 23rd International Conference on
World Wide Web, WWW ’14, pages 503–514, Re-
public and Canton of Geneva, Switzerland. Interna-
tional World Wide Web Conferences Steering Com-
mittee.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and exper-
iments with perceptron algorithms. In Proceedings
of the ACL-02 Conference on Empirical Methods in
Natural Language Processing - Volume 10, EMNLP
’02, pages 1–8, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Munmun De Choudhury, Hari Sundaram, Ajita John,
and Dor´ee Duncan Seligmann. 2009. What makes
conversations interesting? themes, participants and
consequences of conversations in online social me-
dia. In 18th International World Wide Web Confer-
ence (WWW), pages 331–331, April.
Mark Edmundson. 2012. The trouble with online edu-
cation, July 19. http://www.nytimes.com/
2012/07/20/opinion/the-trouble-
with-online-education.html.
Pedro F. Felzenszwalb, Ross B. Girshick, David
McAllester, and Deva Ramanan. 2010. Object
detection with discriminatively trained part-based
models. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 32(9):1627–1645.
Blaz Fortuna, Eduarda Mendes Rodrigues, and Natasa
Milic-Frayling. 2007. Improving the classifica-
tion of newsgroup messages through social network
analysis. In Proceedings of the Sixteenth ACM Con-
ference on Conference on Information and Knowl-
edge Management, CIKM ’07, pages 877–880, New
York, NY, USA. ACM.
Dan Goldwasser and Hal Daum´e III. 2014. “I object!”
modeling latent pragmatic effects in courtroom di-
alogues. European Chapter of the Association for
Computational Linguistics (EACL), April. To ap-
pear.
Benjamin Golub and Matthew O. Jackson. 2010. See-
ing only the successes: The power of selection bias
in explaining the structure of observed internet dif-
fusions.
Vicenc¸ G´omez, Andreas Kaltenbrunner, and Vicente
L´opez. 2008. Statistical analysis of the social net-
work and discussion threads in slashdot. In Proceed-
ings of the 17th International Conference on World
Wide Web, WWW ’08, pages 645–654, New York,
NY, USA. ACM.
Jizhou Huang, Ming Zhou, and Dan Yang. 2007. Ex-
tracting chatbox knowledge from online discussion
forums. In Proceedings of the 20th International
Joint Conference on Artifical Intelligence, IJCAI’07,
pages 423–428, San Francisco, CA, USA. Morgan
Kaufmann Publishers Inc.
Jonathan Huang, Chris Piech, Andy Nguyen, and
Leonidas J. Guibas. 2013. Syntactic and functional
variability of a million code submissions in a ma-
chine learning mooc. In AIED Workshops.
</reference>
<page confidence="0.744234">
1510
</page>
<reference confidence="0.99991512">
Minwoo Jeong, Chin-Yew Lin, and Gary Geunbae Lee.
2009. Semi-supervised speech act recognition in
emails and forums. In Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing: Volume 3 - Volume 3, EMNLP
’9, pages 1250–1259, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Ren´e F. Kizilcec, Chris Piech, and Emily Schnei-
der. 2013. Deconstructing disengagement: analyz-
ing learner subpopulations in massive open online
courses. In LAK, pages 170–179.
Jon M. Kleinberg. 2013. Computational perspectives
on social phenomena at global scales. In Francesca
Rossi, editor, IJCAI. IJCAI/AAAI.
Ravi Kumar, Mohammad Mahdian, and Mary McGlo-
hon. 2010. Dynamics of conversations. In Pro-
ceedings of the 16th ACM SIGKDD International
Conference on Knowledge Discovery and Data Min-
ing, KDD ’10, pages 553–562, New York, NY, USA.
ACM.
Haewoon Kwak, Changhyun Lee, Hosung Park, and
Sue Moon. 2010. What is twitter, a social network
or a news media? In Proceedings of the 19th In-
ternational Conference on World Wide Web, WWW
’10, pages 591–600, New York, NY, USA. ACM.
K. Lerman and R. Ghosh. 2010. Information conta-
gion: An empirical study of the spread of news on
digg and twitter social networks. In Proceedings of
4th International Conference on Weblogs and Social
Media (ICWSM).
David Liben-Nowell and Jon Kleinberg. 2008. Trac-
ing the flow of information on a global scale using
Internet chain-letter data. Proceedings of the Na-
tional Academy of Sciences, 105(12):4633–4638, 25
March.
Andy Nguyen, Christopher Piech, Jonathan Huang,
and Leonidas J. Guibas. 2014. Codewebs: scalable
homework search for massive open online program-
ming courses. In WWW, pages 491–502.
Chris Piech, Mehran Sahami, Daphne Koller, Steve
Cooper, and Paulo Blikstein. 2012. Modeling how
students learn to program. In SIGCSE, pages 153–
160.
Chris Piech, Jonathan Huang, Zhenghao Chen, Chuong
Do, Andrew Ng, and Daphne Koller. 2013. Tuned
models of peer assessment in MOOCs. In Proceed-
ings of The 6th International Conference on Educa-
tional Data Mining (EDM 2013).
Arti Ramesh, Dan Goldwasser, Bert Huang, Hal
Daum´e III, and Lise Getoor. 2013. Modeling
learner engagement in moocs using probabilistic soft
logic. In NIPS Workshop on Data Driven Education.
Daniel M. Romero, Brendan Meeder, and Jon Klein-
berg. 2011. Differences in the mechanics of in-
formation diffusion across topics: Idioms, political
hashtags, and complex contagion on twitter. In Pro-
ceedings of the 20th International Conference on
World Wide Web, WWW ’11, pages 695–704, New
York, NY, USA. ACM.
Glenda S. Stump, Jennifer DeBoer, Jonathan Whit-
tinghill, and Lori Breslow. 2013. Development of a
framework to classify mooc discussion forum posts:
Methodology and challenges.
Manos Tsagkias, Wouter Weerkamp, and Maarten
de Rijke. 2009. Predicting the volume of com-
ments on online news stories. In Proceedings of the
18th ACM Conference on Information and Knowl-
edge Management, CIKM ’09, pages 1765–1768,
New York, NY, USA. ACM.
Yi-Chia Wang, Mahesh Joshi, and Carolyn Penstein
Ros. 2007. A feature based approach to leveraging
context for classifying newsgroup style discussion
segments. In John A. Carroll, Antal van den Bosch,
and Annie Zaenen, editors, ACL. The Association
for Computational Linguistics.
Hongning Wang, Chi Wang, ChengXiang Zhai, and Ji-
awei Han. 2011. Learning online discussion struc-
tures by conditional random fields. In Proceedings
of the 34th International ACM SIGIR Conference
on Research and Development in Information Re-
trieval, SIGIR ’11, pages 435–444, New York, NY,
USA. ACM.
Chunyan Wang, Mao Ye, and Bernardo A. Huberman.
2012. From user comments to on-line conversa-
tions. In Proceedings of the 18th ACM SIGKDD
International Conference on Knowledge Discovery
and Data Mining, KDD ’12, pages 244–252, New
York, NY, USA. ACM.
Li Wang, Su Nam Kim, and Timothy Baldwin. 2013.
The utility of discourse structure in forum thread re-
trieval. In AIRS, pages 284–295.
Tae Yano and Noah A. Smith. 2010. What’s worthy of
comment? content and comment volume in political
blogs. In William W. Cohen and Samuel Gosling,
editors, ICWSM. The AAAI Press.
Chun-Nam John Yu and Thorsten Joachims. 2009.
Learning structural svms with latent variables. In
Proceedings of the 26th Annual International Con-
ference on Machine Learning, ICML ’09, pages
1169–1176, New York, NY, USA. ACM.
</reference>
<page confidence="0.99258">
1511
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.769766">
<title confidence="0.999862">Predicting Instructor’s Intervention in MOOC forums</title>
<author confidence="0.990745">Snigdha Chaturvedi Dan Goldwasser Hal Daum´e</author>
<affiliation confidence="0.940699">Department of Computer University of Maryland, College Park, Maryland</affiliation>
<email confidence="0.899526">goldwas1,</email>
<abstract confidence="0.999137315789474">Instructor intervention in student discussion forums is a vital component in Massive Open Online Courses (MOOCs), where personalized interaction is limited. This paper introduces the problem of predicting instructor interventions in MOOC forums. We propose several prediction models designed to capture unique aspects of MOOCs, combining course information, forum structure and posts content. Our models abstract contents of individual posts of threads using latent categories, learned jointly with the binary intervention prediction problem. Experiments over from two demonstrate that incorporating the structure of threads into the learning problem leads to better predictive performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ashton Anderson</author>
<author>Daniel P Huttenlocher</author>
<author>Jon M Kleinberg</author>
<author>Jure Leskovec</author>
</authors>
<title>Engaging with massive online courses.</title>
<date>2014</date>
<booktitle>In WWW,</booktitle>
<pages>687--698</pages>
<contexts>
<context position="9921" citStr="Anderson et al., 2014" startWordPosition="1558" endWordPosition="1561">r categorizing forum posts by designing a taxonomy and annotating posts manually to assist general forum analysis. Our model learns categories in a data-driven manner guided by the binary supervision (intervention decision) and serves a different purpose. Nevertheless, in Sec. 4.3 we compare the categories learnt by our models with those proposed by Stump et al. (2013). Apart from this, recent works have looked into interesting challenges in this domain such as better peer grading models (Piech et al., 2013), code review (Huang et al., 2013; Nguyen et al., 2014), improving student engagement (Anderson et al., 2014) and understanding how students learn and code (Piech et al., 2012; Kizilcec et al., 2013; Ramesh et al., 2013). 3 Intervention Prediction Models In this section, we explain our models in detail. 3.1 Problem Setting In our description it is assumed that a discussion board is organized into multiple forums (representing topics such as “Assignment”, “Study Group” etc.). A forum consists of multiple threads. Each thread (t) has a title and consists of multiple posts (pi). Individual posts do not have a title and the number of posts varies dramatically from one thread to another. We address the pr</context>
</contexts>
<marker>Anderson, Huttenlocher, Kleinberg, Leskovec, 2014</marker>
<rawString>Ashton Anderson, Daniel P. Huttenlocher, Jon M. Kleinberg, and Jure Leskovec. 2014. Engaging with massive online courses. In WWW, pages 687–698.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Artzi</author>
<author>Patrick Pantel</author>
<author>Michael Gamon</author>
</authors>
<title>Predicting responses to microblog posts.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ’12,</booktitle>
<pages>602--606</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6486" citStr="Artzi et al., 2012" startWordPosition="998" endWordPosition="1001">s • We present two chain based models that incorporate thread structure. • We show the utility of modeling thread structure, and the value of lexical and domain specific knowledge for the prediction task 2 Related Work To the best of our knowledge, the problem of predicting instructor’s intervention in MOOC forums has not been addressed yet. Prior work deals with analyzing general online discussion forums of social media sites (Kleinberg, 2013): such as predicting comment volume (Backstrom et al., 2013; De Choudhury et al., 2009; Wang et al., 2012; Tsagkias et al., 2009; Yano and Smith, 2010; Artzi et al., 2012) and rate of content diffusion (Kwak et al., 2010; Lerman and Ghosh, 2010; Bakshy et al., 2011; Romero et al., 2011; Artzi et al., 2012) and also question answering (Chaturvedi et al., 2014). Wang et al. (2007) incorporate thread structure of conversations using features in email threads while Goldwasser and Daum´e III (2014) use latent structure, aimed to identify relevant dialog segments, for predicting objections during courtroom deliberations. Other related work include speech act recognition in emails and forums but at a sentence level (Jeong et al., 2009), and using social network analys</context>
</contexts>
<marker>Artzi, Pantel, Gamon, 2012</marker>
<rawString>Yoav Artzi, Patrick Pantel, and Michael Gamon. 2012. Predicting responses to microblog posts. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ’12, pages 602–606, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Aumayr</author>
<author>Jeffrey Chan</author>
<author>Conor Hayes</author>
</authors>
<title>Reconstruction of threaded conversations in online discussion forums.</title>
<date>2011</date>
<editor>In Lada A. Adamic, Ricardo A. Baeza-Yates, and Scott Counts, editors, ICWSM.</editor>
<publisher>The AAAI Press.</publisher>
<contexts>
<context position="8742" citStr="Aumayr et al., 2011" startWordPosition="1367" endWordPosition="1370">ent than ours. Our work is also very closely related to that of Wang et al. (2013) who predict solvedness —which predicts if there is a solution to the original problem posted in the thread. Like us, they believe that category of posts can assist in the prediction task, however, possibly owing to the complexity of general discussion forums, they had to manually create and annotate data with a sophisticated taxonomy. We do not make such assumptions. The work presented in (G´omez et al., 2008; 1502 Liben-Nowell and Kleinberg, 2008; Kumar et al., 2010; Golub and Jackson, 2010; Wang et al., 2011; Aumayr et al., 2011) discuss characterizing threads using reply-graphs (often trees) and learning this structure. However, this representation is not natural for the MOOC domain where discussions are relatively more focused on the thread topic and are better organized using sections within the forums. Although most prior work focuses on discussion forums of social media sites such as Twitter or Facebook, where the dynamics of interaction is very different from MOOCs, a small number of recent work address the unique MOOC setting. Stump et al. (2013) propose a framework for categorizing forum posts by designing a t</context>
</contexts>
<marker>Aumayr, Chan, Hayes, 2011</marker>
<rawString>Erik Aumayr, Jeffrey Chan, and Conor Hayes. 2011. Reconstruction of threaded conversations in online discussion forums. In Lada A. Adamic, Ricardo A. Baeza-Yates, and Scott Counts, editors, ICWSM. The AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lars Backstrom</author>
<author>Jon Kleinberg</author>
<author>Lillian Lee</author>
<author>Cristian Danescu-Niculescu-Mizil</author>
</authors>
<title>Characterizing and curating conversation threads: Expansion, focus, volume, re-entry.</title>
<date>2013</date>
<booktitle>In Proceedings of the Sixth ACM International Conference on Web Search and Data Mining, WSDM ’13,</booktitle>
<pages>13--22</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6374" citStr="Backstrom et al., 2013" startWordPosition="977" endWordPosition="980">ummarized as: • We motivate and introduce the important problem of predicting instructor intervention in MOOC forums • We present two chain based models that incorporate thread structure. • We show the utility of modeling thread structure, and the value of lexical and domain specific knowledge for the prediction task 2 Related Work To the best of our knowledge, the problem of predicting instructor’s intervention in MOOC forums has not been addressed yet. Prior work deals with analyzing general online discussion forums of social media sites (Kleinberg, 2013): such as predicting comment volume (Backstrom et al., 2013; De Choudhury et al., 2009; Wang et al., 2012; Tsagkias et al., 2009; Yano and Smith, 2010; Artzi et al., 2012) and rate of content diffusion (Kwak et al., 2010; Lerman and Ghosh, 2010; Bakshy et al., 2011; Romero et al., 2011; Artzi et al., 2012) and also question answering (Chaturvedi et al., 2014). Wang et al. (2007) incorporate thread structure of conversations using features in email threads while Goldwasser and Daum´e III (2014) use latent structure, aimed to identify relevant dialog segments, for predicting objections during courtroom deliberations. Other related work include speech ac</context>
<context position="7823" citStr="Backstrom et al. (2013)" startWordPosition="1214" endWordPosition="1218">also been used to address other interesting challenges such as extracting chatbox knowledge for use in general online forums (Huang et al., 2007) and automatically extracting answers from discussion forums (Catherine et al., 2013), subjectivity analysis of online forums (Biyani et al., 2013). Most of these methods use ideas similar to ours: identifying that threads (or discussions) have an underlying structure and that messages belong to categories. However, they operate in a different domain, which makes their goals and methods different from ours. Our work is most closely related to that of Backstrom et al. (2013) which introduced the re-entry prediction task —predicting whether a user who has participated in a thread will later contribute another comment to it. While seemingly related, their prediction task, focusing on users who have already commented on a thread, and their algorithmic approach are different than ours. Our work is also very closely related to that of Wang et al. (2013) who predict solvedness —which predicts if there is a solution to the original problem posted in the thread. Like us, they believe that category of posts can assist in the prediction task, however, possibly owing to the</context>
<context position="13618" citStr="Backstrom et al. (2013)" startWordPosition="2179" endWordPosition="2182">al Chain Model (GCM) Figure 2: Diagrams of the Linear Chain Markov Model (LCMM) and the Global Chain Model (GCM). pi, r and 0(t) are observed and hi are the latent variables. pi and hi represent the posts of the thread and their latent categories respectively; r represents the instructor’s intervention and 0(t) represent the non-structural features used by the logistic regression model. We had also considered and dropped (because of no performance gain) other features about identity of the user who started the thread, number of distinct participants in the thread (an important feature used by Backstrom et al. (2013)), binary feature indicating if the first and the last posts were by the same user, average number of words in the thread’s posts, lexical features capturing references to the instructors in the posts etc. 3.3 Linear Chain Markov Model (LCMM) The logistic regression model is good at exploiting the thread level features but not the content of individual posts. The ‘Aggregated post features’ attempt to capture this information but since the number of posts in a thread is variable, these features relied on aggregated values. We believe that considering aggregate values is not sufficient for the t</context>
</contexts>
<marker>Backstrom, Kleinberg, Lee, Danescu-Niculescu-Mizil, 2013</marker>
<rawString>Lars Backstrom, Jon Kleinberg, Lillian Lee, and Cristian Danescu-Niculescu-Mizil. 2013. Characterizing and curating conversation threads: Expansion, focus, volume, re-entry. In Proceedings of the Sixth ACM International Conference on Web Search and Data Mining, WSDM ’13, pages 13–22, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eytan Bakshy</author>
<author>Jake M Hofman</author>
<author>Winter A Mason</author>
<author>Duncan J Watts</author>
</authors>
<title>Everyone’s an influencer: Quantifying influence on twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fourth ACM International Conference on Web Search and Data Mining, WSDM ’11,</booktitle>
<pages>65--74</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6580" citStr="Bakshy et al., 2011" startWordPosition="1015" endWordPosition="1018"> of modeling thread structure, and the value of lexical and domain specific knowledge for the prediction task 2 Related Work To the best of our knowledge, the problem of predicting instructor’s intervention in MOOC forums has not been addressed yet. Prior work deals with analyzing general online discussion forums of social media sites (Kleinberg, 2013): such as predicting comment volume (Backstrom et al., 2013; De Choudhury et al., 2009; Wang et al., 2012; Tsagkias et al., 2009; Yano and Smith, 2010; Artzi et al., 2012) and rate of content diffusion (Kwak et al., 2010; Lerman and Ghosh, 2010; Bakshy et al., 2011; Romero et al., 2011; Artzi et al., 2012) and also question answering (Chaturvedi et al., 2014). Wang et al. (2007) incorporate thread structure of conversations using features in email threads while Goldwasser and Daum´e III (2014) use latent structure, aimed to identify relevant dialog segments, for predicting objections during courtroom deliberations. Other related work include speech act recognition in emails and forums but at a sentence level (Jeong et al., 2009), and using social network analysis to improve message classification into pre-determined types (Fortuna et al., 2007). Discuss</context>
</contexts>
<marker>Bakshy, Hofman, Mason, Watts, 2011</marker>
<rawString>Eytan Bakshy, Jake M. Hofman, Winter A. Mason, and Duncan J. Watts. 2011. Everyone’s an influencer: Quantifying influence on twitter. In Proceedings of the Fourth ACM International Conference on Web Search and Data Mining, WSDM ’11, pages 65–74, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prakhar Biyani</author>
<author>Cornelia Caragea</author>
<author>Prasenjit Mitra</author>
</authors>
<title>Predicting subjectivity orientation of online forum threads.</title>
<date>2013</date>
<booktitle>In CICLing (2),</booktitle>
<pages>109--120</pages>
<contexts>
<context position="7492" citStr="Biyani et al., 2013" startWordPosition="1156" endWordPosition="1159">gments, for predicting objections during courtroom deliberations. Other related work include speech act recognition in emails and forums but at a sentence level (Jeong et al., 2009), and using social network analysis to improve message classification into pre-determined types (Fortuna et al., 2007). Discussion forums data has also been used to address other interesting challenges such as extracting chatbox knowledge for use in general online forums (Huang et al., 2007) and automatically extracting answers from discussion forums (Catherine et al., 2013), subjectivity analysis of online forums (Biyani et al., 2013). Most of these methods use ideas similar to ours: identifying that threads (or discussions) have an underlying structure and that messages belong to categories. However, they operate in a different domain, which makes their goals and methods different from ours. Our work is most closely related to that of Backstrom et al. (2013) which introduced the re-entry prediction task —predicting whether a user who has participated in a thread will later contribute another comment to it. While seemingly related, their prediction task, focusing on users who have already commented on a thread, and their a</context>
</contexts>
<marker>Biyani, Caragea, Mitra, 2013</marker>
<rawString>Prakhar Biyani, Cornelia Caragea, and Prasenjit Mitra. 2013. Predicting subjectivity orientation of online forum threads. In CICLing (2), pages 109–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rose Catherine</author>
<author>Rashmi Gangadharaiah</author>
<author>Karthik Visweswariah</author>
<author>Dinesh Raghu</author>
</authors>
<title>Semisupervised answer extraction from discussion forums.</title>
<date>2013</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the Sixth International Joint Conference on Natural Language Processing,</booktitle>
<pages>1--9</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="7430" citStr="Catherine et al., 2013" startWordPosition="1146" endWordPosition="1149">(2014) use latent structure, aimed to identify relevant dialog segments, for predicting objections during courtroom deliberations. Other related work include speech act recognition in emails and forums but at a sentence level (Jeong et al., 2009), and using social network analysis to improve message classification into pre-determined types (Fortuna et al., 2007). Discussion forums data has also been used to address other interesting challenges such as extracting chatbox knowledge for use in general online forums (Huang et al., 2007) and automatically extracting answers from discussion forums (Catherine et al., 2013), subjectivity analysis of online forums (Biyani et al., 2013). Most of these methods use ideas similar to ours: identifying that threads (or discussions) have an underlying structure and that messages belong to categories. However, they operate in a different domain, which makes their goals and methods different from ours. Our work is most closely related to that of Backstrom et al. (2013) which introduced the re-entry prediction task —predicting whether a user who has participated in a thread will later contribute another comment to it. While seemingly related, their prediction task, focusin</context>
</contexts>
<marker>Catherine, Gangadharaiah, Visweswariah, Raghu, 2013</marker>
<rawString>Rose Catherine, Rashmi Gangadharaiah, Karthik Visweswariah, and Dinesh Raghu. 2013. Semisupervised answer extraction from discussion forums. In Proceedings of the Sixth International Joint Conference on Natural Language Processing, pages 1–9, Nagoya, Japan, October. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming-Wei Chang</author>
<author>Dan Goldwasser</author>
<author>Dan Roth</author>
<author>Vivek Srikumar</author>
</authors>
<title>Discriminative learning over constrained latent representations.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10,</booktitle>
<pages>429--437</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="21033" citStr="Chang et al., 2010" startWordPosition="3473" endWordPosition="3476">2) min w λ2||w||2 + T j 1505 where A is the regularization coefficient, tj is the jth thread with intervention decision rj and pj are the posts of this thread. w is the weight vector, l(·) is the squared hinge loss function and f,,,(tj, pj) is defined in Equation 1. Replacing the term f,,,(tj, pj) with the contents of Equation 1 in the minimization objective above, reveals the key difference from the traditional SVM formulation - the objective function has a maximum term inside the global minimization problem making it non-convex. We, therefore, employ the optimization algorithm presented in (Chang et al., 2010) to solve this problem. Exploiting the semi-convexity property (Felzenszwalb et al., 2010), the algorithm works in two steps, each executed iteratively. In the first step, it determines the latent variable assignments for positive examples. The algorithm then performs two step iteratively - first it determines the structural assignments for the negative examples, and then optimizes the fixed objective function using a cutting plane algorithm. Once this process converges for negative examples, the algorithm reassigns values to the latent variables for positive examples, and proceeds to the seco</context>
</contexts>
<marker>Chang, Goldwasser, Roth, Srikumar, 2010</marker>
<rawString>Ming-Wei Chang, Dan Goldwasser, Dan Roth, and Vivek Srikumar. 2010. Discriminative learning over constrained latent representations. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10, pages 429– 437, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Snigdha Chaturvedi</author>
<author>Vittorio Castelli</author>
<author>Radu Florian</author>
<author>Ramesh M Nallapati</author>
<author>Hema Raghavan</author>
</authors>
<title>Joint question clustering and relevance prediction for open domain non-factoid question answering.</title>
<date>2014</date>
<booktitle>In Proceedings of the 23rd International Conference on World Wide Web, WWW ’14,</booktitle>
<pages>503--514</pages>
<institution>Republic and Canton of Geneva, Switzerland. International World Wide Web Conferences Steering Committee.</institution>
<contexts>
<context position="6676" citStr="Chaturvedi et al., 2014" startWordPosition="1031" endWordPosition="1034">he prediction task 2 Related Work To the best of our knowledge, the problem of predicting instructor’s intervention in MOOC forums has not been addressed yet. Prior work deals with analyzing general online discussion forums of social media sites (Kleinberg, 2013): such as predicting comment volume (Backstrom et al., 2013; De Choudhury et al., 2009; Wang et al., 2012; Tsagkias et al., 2009; Yano and Smith, 2010; Artzi et al., 2012) and rate of content diffusion (Kwak et al., 2010; Lerman and Ghosh, 2010; Bakshy et al., 2011; Romero et al., 2011; Artzi et al., 2012) and also question answering (Chaturvedi et al., 2014). Wang et al. (2007) incorporate thread structure of conversations using features in email threads while Goldwasser and Daum´e III (2014) use latent structure, aimed to identify relevant dialog segments, for predicting objections during courtroom deliberations. Other related work include speech act recognition in emails and forums but at a sentence level (Jeong et al., 2009), and using social network analysis to improve message classification into pre-determined types (Fortuna et al., 2007). Discussion forums data has also been used to address other interesting challenges such as extracting ch</context>
</contexts>
<marker>Chaturvedi, Castelli, Florian, Nallapati, Raghavan, 2014</marker>
<rawString>Snigdha Chaturvedi, Vittorio Castelli, Radu Florian, Ramesh M. Nallapati, and Hema Raghavan. 2014. Joint question clustering and relevance prediction for open domain non-factoid question answering. In Proceedings of the 23rd International Conference on World Wide Web, WWW ’14, pages 503–514, Republic and Canton of Geneva, Switzerland. International World Wide Web Conferences Steering Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing - Volume 10, EMNLP ’02,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="16896" citStr="Collins, 2002" startWordPosition="2740" endWordPosition="2741">del is provided only in form of the observed intervention decision, r and the post categories, hi are hidp1 p2 pn h1 h2 hn r φ(t) T p1 p2 pn T h1 h2 hn r φ(t) 1504 den. The model uses the pseudocode shown in Algorithm 1 to iteratively refine the weight vectors. In each iteration, the model first uses viterbi algorithm to decode thread sequences with the current weights wt to find optimal highest scoring latent state sequences that agree with the observed intervention state (r = r0). In the next step, given the latent state assignments from the previous step, a structured perceptron algorithm (Collins, 2002) is used to update the weights wt+1 using weights from the previous step, wt, initialization. Algorithm 1 Training algorithm for LCMM 1: Input: Labeled data D = {(t, p, r)i} 2: Output: Weights w 3: Initialization: Set wj randomly, bj 4: for t : 1 to N do 5: ˆhi = arg maxh[wt · 0(p, r, h, t)] such that r = ribi 6: wt+1 = StructuredPerceptron(t, p, ˆh, r) 7: end for 8: return w While testing, we use the learned weights and viterbi decoding to compute the intervention state and the best scoring latent category sequence. 3.3.2 Feature Engineering In addition to the ‘Thread Only Features’ and the ‘</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing - Volume 10, EMNLP ’02, pages 1–8, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Munmun De Choudhury</author>
<author>Hari Sundaram</author>
<author>Ajita John</author>
<author>Dor´ee Duncan Seligmann</author>
</authors>
<title>What makes conversations interesting? themes, participants and consequences of conversations in online social media.</title>
<date>2009</date>
<booktitle>In 18th International World Wide Web Conference (WWW),</booktitle>
<pages>331--331</pages>
<marker>De Choudhury, Sundaram, John, Seligmann, 2009</marker>
<rawString>Munmun De Choudhury, Hari Sundaram, Ajita John, and Dor´ee Duncan Seligmann. 2009. What makes conversations interesting? themes, participants and consequences of conversations in online social media. In 18th International World Wide Web Conference (WWW), pages 331–331, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Edmundson</author>
</authors>
<title>The trouble with online education,</title>
<date>2012</date>
<note>http://www.nytimes.com/ 2012/07/20/opinion/the-troublewith-online-education.html.</note>
<contexts>
<context position="1595" citStr="Edmundson, 2012" startWordPosition="221" endWordPosition="222">d easy access to high bandwidth internet have reshaped the modus operandi in distance education towards Massive Open Online Courses (MOOCs). Courses offered by ventures such as Coursera and Udacity now impart inexpensive and high-quality education from field-experts to thousands of learners across geographic and cultural barriers. Even as the MOOC model shows exciting possibilities, it presents a multitude of challenges that must first be negotiated to completely realize its potential. MOOCs platforms have been especially criticized on grounds of lacking a personalized educational experience (Edmundson, 2012). Unlike traditional classrooms, the predominant mode of interaction between students and instructors in MOOCs is via online discussion forums. Ideally, forum discussions can help make up for the lack of direct interaction, by enabling students to ask questions and clarify doubts. However, due to huge class sizes, even during the short duration of a course, MOOCs witness a very large number of threads on these forums. Owing to extremely skewed ratios of students to instructional staff, it can be prohibitively time-consuming for the instructional staff to manually follow all threads of a forum.</context>
</contexts>
<marker>Edmundson, 2012</marker>
<rawString>Mark Edmundson. 2012. The trouble with online education, July 19. http://www.nytimes.com/ 2012/07/20/opinion/the-troublewith-online-education.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pedro F Felzenszwalb</author>
<author>Ross B Girshick</author>
<author>David McAllester</author>
<author>Deva Ramanan</author>
</authors>
<title>Object detection with discriminatively trained part-based models.</title>
<date>2010</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>32</volume>
<issue>9</issue>
<contexts>
<context position="21123" citStr="Felzenszwalb et al., 2010" startWordPosition="3486" endWordPosition="3489">th thread with intervention decision rj and pj are the posts of this thread. w is the weight vector, l(·) is the squared hinge loss function and f,,,(tj, pj) is defined in Equation 1. Replacing the term f,,,(tj, pj) with the contents of Equation 1 in the minimization objective above, reveals the key difference from the traditional SVM formulation - the objective function has a maximum term inside the global minimization problem making it non-convex. We, therefore, employ the optimization algorithm presented in (Chang et al., 2010) to solve this problem. Exploiting the semi-convexity property (Felzenszwalb et al., 2010), the algorithm works in two steps, each executed iteratively. In the first step, it determines the latent variable assignments for positive examples. The algorithm then performs two step iteratively - first it determines the structural assignments for the negative examples, and then optimizes the fixed objective function using a cutting plane algorithm. Once this process converges for negative examples, the algorithm reassigns values to the latent variables for positive examples, and proceeds to the second step. The algorithm stops once a local minimum is reached. A somewhat similar approach,</context>
</contexts>
<marker>Felzenszwalb, Girshick, McAllester, Ramanan, 2010</marker>
<rawString>Pedro F. Felzenszwalb, Ross B. Girshick, David McAllester, and Deva Ramanan. 2010. Object detection with discriminatively trained part-based models. IEEE Transactions on Pattern Analysis and Machine Intelligence, 32(9):1627–1645.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Blaz Fortuna</author>
<author>Eduarda Mendes Rodrigues</author>
<author>Natasa Milic-Frayling</author>
</authors>
<title>Improving the classification of newsgroup messages through social network analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management, CIKM ’07,</booktitle>
<pages>877--880</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="7171" citStr="Fortuna et al., 2007" startWordPosition="1105" endWordPosition="1108">osh, 2010; Bakshy et al., 2011; Romero et al., 2011; Artzi et al., 2012) and also question answering (Chaturvedi et al., 2014). Wang et al. (2007) incorporate thread structure of conversations using features in email threads while Goldwasser and Daum´e III (2014) use latent structure, aimed to identify relevant dialog segments, for predicting objections during courtroom deliberations. Other related work include speech act recognition in emails and forums but at a sentence level (Jeong et al., 2009), and using social network analysis to improve message classification into pre-determined types (Fortuna et al., 2007). Discussion forums data has also been used to address other interesting challenges such as extracting chatbox knowledge for use in general online forums (Huang et al., 2007) and automatically extracting answers from discussion forums (Catherine et al., 2013), subjectivity analysis of online forums (Biyani et al., 2013). Most of these methods use ideas similar to ours: identifying that threads (or discussions) have an underlying structure and that messages belong to categories. However, they operate in a different domain, which makes their goals and methods different from ours. Our work is mos</context>
</contexts>
<marker>Fortuna, Rodrigues, Milic-Frayling, 2007</marker>
<rawString>Blaz Fortuna, Eduarda Mendes Rodrigues, and Natasa Milic-Frayling. 2007. Improving the classification of newsgroup messages through social network analysis. In Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management, CIKM ’07, pages 877–880, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Goldwasser</author>
<author>Hal Daum´e</author>
</authors>
<title>I object!” modeling latent pragmatic effects in courtroom dialogues.</title>
<date>2014</date>
<booktitle>European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<note>To appear.</note>
<marker>Goldwasser, Daum´e, 2014</marker>
<rawString>Dan Goldwasser and Hal Daum´e III. 2014. “I object!” modeling latent pragmatic effects in courtroom dialogues. European Chapter of the Association for Computational Linguistics (EACL), April. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Golub</author>
<author>Matthew O Jackson</author>
</authors>
<title>Seeing only the successes: The power of selection bias in explaining the structure of observed internet diffusions.</title>
<date>2010</date>
<contexts>
<context position="8701" citStr="Golub and Jackson, 2010" startWordPosition="1359" endWordPosition="1362">d, and their algorithmic approach are different than ours. Our work is also very closely related to that of Wang et al. (2013) who predict solvedness —which predicts if there is a solution to the original problem posted in the thread. Like us, they believe that category of posts can assist in the prediction task, however, possibly owing to the complexity of general discussion forums, they had to manually create and annotate data with a sophisticated taxonomy. We do not make such assumptions. The work presented in (G´omez et al., 2008; 1502 Liben-Nowell and Kleinberg, 2008; Kumar et al., 2010; Golub and Jackson, 2010; Wang et al., 2011; Aumayr et al., 2011) discuss characterizing threads using reply-graphs (often trees) and learning this structure. However, this representation is not natural for the MOOC domain where discussions are relatively more focused on the thread topic and are better organized using sections within the forums. Although most prior work focuses on discussion forums of social media sites such as Twitter or Facebook, where the dynamics of interaction is very different from MOOCs, a small number of recent work address the unique MOOC setting. Stump et al. (2013) propose a framework for </context>
</contexts>
<marker>Golub, Jackson, 2010</marker>
<rawString>Benjamin Golub and Matthew O. Jackson. 2010. Seeing only the successes: The power of selection bias in explaining the structure of observed internet diffusions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vicenc¸ G´omez</author>
<author>Andreas Kaltenbrunner</author>
<author>Vicente L´opez</author>
</authors>
<title>Statistical analysis of the social network and discussion threads in slashdot.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th International Conference on World Wide Web, WWW ’08,</booktitle>
<pages>645--654</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>G´omez, Kaltenbrunner, L´opez, 2008</marker>
<rawString>Vicenc¸ G´omez, Andreas Kaltenbrunner, and Vicente L´opez. 2008. Statistical analysis of the social network and discussion threads in slashdot. In Proceedings of the 17th International Conference on World Wide Web, WWW ’08, pages 645–654, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jizhou Huang</author>
<author>Ming Zhou</author>
<author>Dan Yang</author>
</authors>
<title>Extracting chatbox knowledge from online discussion forums.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th International Joint Conference on Artifical Intelligence, IJCAI’07,</booktitle>
<pages>423--428</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="7345" citStr="Huang et al., 2007" startWordPosition="1133" endWordPosition="1136">of conversations using features in email threads while Goldwasser and Daum´e III (2014) use latent structure, aimed to identify relevant dialog segments, for predicting objections during courtroom deliberations. Other related work include speech act recognition in emails and forums but at a sentence level (Jeong et al., 2009), and using social network analysis to improve message classification into pre-determined types (Fortuna et al., 2007). Discussion forums data has also been used to address other interesting challenges such as extracting chatbox knowledge for use in general online forums (Huang et al., 2007) and automatically extracting answers from discussion forums (Catherine et al., 2013), subjectivity analysis of online forums (Biyani et al., 2013). Most of these methods use ideas similar to ours: identifying that threads (or discussions) have an underlying structure and that messages belong to categories. However, they operate in a different domain, which makes their goals and methods different from ours. Our work is most closely related to that of Backstrom et al. (2013) which introduced the re-entry prediction task —predicting whether a user who has participated in a thread will later cont</context>
</contexts>
<marker>Huang, Zhou, Yang, 2007</marker>
<rawString>Jizhou Huang, Ming Zhou, and Dan Yang. 2007. Extracting chatbox knowledge from online discussion forums. In Proceedings of the 20th International Joint Conference on Artifical Intelligence, IJCAI’07, pages 423–428, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Huang</author>
<author>Chris Piech</author>
<author>Andy Nguyen</author>
<author>Leonidas J Guibas</author>
</authors>
<title>Syntactic and functional variability of a million code submissions in a machine learning mooc.</title>
<date>2013</date>
<booktitle>In AIED Workshops.</booktitle>
<contexts>
<context position="9845" citStr="Huang et al., 2013" startWordPosition="1547" endWordPosition="1550">ress the unique MOOC setting. Stump et al. (2013) propose a framework for categorizing forum posts by designing a taxonomy and annotating posts manually to assist general forum analysis. Our model learns categories in a data-driven manner guided by the binary supervision (intervention decision) and serves a different purpose. Nevertheless, in Sec. 4.3 we compare the categories learnt by our models with those proposed by Stump et al. (2013). Apart from this, recent works have looked into interesting challenges in this domain such as better peer grading models (Piech et al., 2013), code review (Huang et al., 2013; Nguyen et al., 2014), improving student engagement (Anderson et al., 2014) and understanding how students learn and code (Piech et al., 2012; Kizilcec et al., 2013; Ramesh et al., 2013). 3 Intervention Prediction Models In this section, we explain our models in detail. 3.1 Problem Setting In our description it is assumed that a discussion board is organized into multiple forums (representing topics such as “Assignment”, “Study Group” etc.). A forum consists of multiple threads. Each thread (t) has a title and consists of multiple posts (pi). Individual posts do not have a title and the numbe</context>
</contexts>
<marker>Huang, Piech, Nguyen, Guibas, 2013</marker>
<rawString>Jonathan Huang, Chris Piech, Andy Nguyen, and Leonidas J. Guibas. 2013. Syntactic and functional variability of a million code submissions in a machine learning mooc. In AIED Workshops.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minwoo Jeong</author>
<author>Chin-Yew Lin</author>
<author>Gary Geunbae Lee</author>
</authors>
<title>Semi-supervised speech act recognition in emails and forums.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 3 - Volume 3, EMNLP ’9,</booktitle>
<pages>1250--1259</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="7053" citStr="Jeong et al., 2009" startWordPosition="1088" endWordPosition="1091">al., 2009; Yano and Smith, 2010; Artzi et al., 2012) and rate of content diffusion (Kwak et al., 2010; Lerman and Ghosh, 2010; Bakshy et al., 2011; Romero et al., 2011; Artzi et al., 2012) and also question answering (Chaturvedi et al., 2014). Wang et al. (2007) incorporate thread structure of conversations using features in email threads while Goldwasser and Daum´e III (2014) use latent structure, aimed to identify relevant dialog segments, for predicting objections during courtroom deliberations. Other related work include speech act recognition in emails and forums but at a sentence level (Jeong et al., 2009), and using social network analysis to improve message classification into pre-determined types (Fortuna et al., 2007). Discussion forums data has also been used to address other interesting challenges such as extracting chatbox knowledge for use in general online forums (Huang et al., 2007) and automatically extracting answers from discussion forums (Catherine et al., 2013), subjectivity analysis of online forums (Biyani et al., 2013). Most of these methods use ideas similar to ours: identifying that threads (or discussions) have an underlying structure and that messages belong to categories.</context>
</contexts>
<marker>Jeong, Lin, Lee, 2009</marker>
<rawString>Minwoo Jeong, Chin-Yew Lin, and Gary Geunbae Lee. 2009. Semi-supervised speech act recognition in emails and forums. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 3 - Volume 3, EMNLP ’9, pages 1250–1259, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ren´e F Kizilcec</author>
<author>Chris Piech</author>
<author>Emily Schneider</author>
</authors>
<title>Deconstructing disengagement: analyzing learner subpopulations in massive open online courses.</title>
<date>2013</date>
<booktitle>In LAK,</booktitle>
<pages>170--179</pages>
<contexts>
<context position="10010" citStr="Kizilcec et al., 2013" startWordPosition="1573" endWordPosition="1576"> general forum analysis. Our model learns categories in a data-driven manner guided by the binary supervision (intervention decision) and serves a different purpose. Nevertheless, in Sec. 4.3 we compare the categories learnt by our models with those proposed by Stump et al. (2013). Apart from this, recent works have looked into interesting challenges in this domain such as better peer grading models (Piech et al., 2013), code review (Huang et al., 2013; Nguyen et al., 2014), improving student engagement (Anderson et al., 2014) and understanding how students learn and code (Piech et al., 2012; Kizilcec et al., 2013; Ramesh et al., 2013). 3 Intervention Prediction Models In this section, we explain our models in detail. 3.1 Problem Setting In our description it is assumed that a discussion board is organized into multiple forums (representing topics such as “Assignment”, “Study Group” etc.). A forum consists of multiple threads. Each thread (t) has a title and consists of multiple posts (pi). Individual posts do not have a title and the number of posts varies dramatically from one thread to another. We address the problem of predicting if the course instructor would intervene on a thread, t. The instruct</context>
</contexts>
<marker>Kizilcec, Piech, Schneider, 2013</marker>
<rawString>Ren´e F. Kizilcec, Chris Piech, and Emily Schneider. 2013. Deconstructing disengagement: analyzing learner subpopulations in massive open online courses. In LAK, pages 170–179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon M Kleinberg</author>
</authors>
<title>Computational perspectives on social phenomena at global scales.</title>
<date>2013</date>
<editor>In Francesca Rossi, editor, IJCAI.</editor>
<publisher>IJCAI/AAAI.</publisher>
<contexts>
<context position="6315" citStr="Kleinberg, 2013" startWordPosition="969" endWordPosition="970">elps in better prediction. Our contributions can be summarized as: • We motivate and introduce the important problem of predicting instructor intervention in MOOC forums • We present two chain based models that incorporate thread structure. • We show the utility of modeling thread structure, and the value of lexical and domain specific knowledge for the prediction task 2 Related Work To the best of our knowledge, the problem of predicting instructor’s intervention in MOOC forums has not been addressed yet. Prior work deals with analyzing general online discussion forums of social media sites (Kleinberg, 2013): such as predicting comment volume (Backstrom et al., 2013; De Choudhury et al., 2009; Wang et al., 2012; Tsagkias et al., 2009; Yano and Smith, 2010; Artzi et al., 2012) and rate of content diffusion (Kwak et al., 2010; Lerman and Ghosh, 2010; Bakshy et al., 2011; Romero et al., 2011; Artzi et al., 2012) and also question answering (Chaturvedi et al., 2014). Wang et al. (2007) incorporate thread structure of conversations using features in email threads while Goldwasser and Daum´e III (2014) use latent structure, aimed to identify relevant dialog segments, for predicting objections during co</context>
</contexts>
<marker>Kleinberg, 2013</marker>
<rawString>Jon M. Kleinberg. 2013. Computational perspectives on social phenomena at global scales. In Francesca Rossi, editor, IJCAI. IJCAI/AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ravi Kumar</author>
<author>Mohammad Mahdian</author>
<author>Mary McGlohon</author>
</authors>
<title>Dynamics of conversations.</title>
<date>2010</date>
<booktitle>In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’10,</booktitle>
<pages>553--562</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="8676" citStr="Kumar et al., 2010" startWordPosition="1355" endWordPosition="1358">commented on a thread, and their algorithmic approach are different than ours. Our work is also very closely related to that of Wang et al. (2013) who predict solvedness —which predicts if there is a solution to the original problem posted in the thread. Like us, they believe that category of posts can assist in the prediction task, however, possibly owing to the complexity of general discussion forums, they had to manually create and annotate data with a sophisticated taxonomy. We do not make such assumptions. The work presented in (G´omez et al., 2008; 1502 Liben-Nowell and Kleinberg, 2008; Kumar et al., 2010; Golub and Jackson, 2010; Wang et al., 2011; Aumayr et al., 2011) discuss characterizing threads using reply-graphs (often trees) and learning this structure. However, this representation is not natural for the MOOC domain where discussions are relatively more focused on the thread topic and are better organized using sections within the forums. Although most prior work focuses on discussion forums of social media sites such as Twitter or Facebook, where the dynamics of interaction is very different from MOOCs, a small number of recent work address the unique MOOC setting. Stump et al. (2013)</context>
</contexts>
<marker>Kumar, Mahdian, McGlohon, 2010</marker>
<rawString>Ravi Kumar, Mohammad Mahdian, and Mary McGlohon. 2010. Dynamics of conversations. In Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’10, pages 553–562, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haewoon Kwak</author>
<author>Changhyun Lee</author>
<author>Hosung Park</author>
<author>Sue Moon</author>
</authors>
<title>What is twitter, a social network or a news media?</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th International Conference on World Wide Web, WWW ’10,</booktitle>
<pages>591--600</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6535" citStr="Kwak et al., 2010" startWordPosition="1007" endWordPosition="1010">ate thread structure. • We show the utility of modeling thread structure, and the value of lexical and domain specific knowledge for the prediction task 2 Related Work To the best of our knowledge, the problem of predicting instructor’s intervention in MOOC forums has not been addressed yet. Prior work deals with analyzing general online discussion forums of social media sites (Kleinberg, 2013): such as predicting comment volume (Backstrom et al., 2013; De Choudhury et al., 2009; Wang et al., 2012; Tsagkias et al., 2009; Yano and Smith, 2010; Artzi et al., 2012) and rate of content diffusion (Kwak et al., 2010; Lerman and Ghosh, 2010; Bakshy et al., 2011; Romero et al., 2011; Artzi et al., 2012) and also question answering (Chaturvedi et al., 2014). Wang et al. (2007) incorporate thread structure of conversations using features in email threads while Goldwasser and Daum´e III (2014) use latent structure, aimed to identify relevant dialog segments, for predicting objections during courtroom deliberations. Other related work include speech act recognition in emails and forums but at a sentence level (Jeong et al., 2009), and using social network analysis to improve message classification into pre-det</context>
</contexts>
<marker>Kwak, Lee, Park, Moon, 2010</marker>
<rawString>Haewoon Kwak, Changhyun Lee, Hosung Park, and Sue Moon. 2010. What is twitter, a social network or a news media? In Proceedings of the 19th International Conference on World Wide Web, WWW ’10, pages 591–600, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Lerman</author>
<author>R Ghosh</author>
</authors>
<title>Information contagion: An empirical study of the spread of news on digg and twitter social networks.</title>
<date>2010</date>
<booktitle>In Proceedings of 4th International Conference on Weblogs and Social Media (ICWSM).</booktitle>
<contexts>
<context position="6559" citStr="Lerman and Ghosh, 2010" startWordPosition="1011" endWordPosition="1014">e. • We show the utility of modeling thread structure, and the value of lexical and domain specific knowledge for the prediction task 2 Related Work To the best of our knowledge, the problem of predicting instructor’s intervention in MOOC forums has not been addressed yet. Prior work deals with analyzing general online discussion forums of social media sites (Kleinberg, 2013): such as predicting comment volume (Backstrom et al., 2013; De Choudhury et al., 2009; Wang et al., 2012; Tsagkias et al., 2009; Yano and Smith, 2010; Artzi et al., 2012) and rate of content diffusion (Kwak et al., 2010; Lerman and Ghosh, 2010; Bakshy et al., 2011; Romero et al., 2011; Artzi et al., 2012) and also question answering (Chaturvedi et al., 2014). Wang et al. (2007) incorporate thread structure of conversations using features in email threads while Goldwasser and Daum´e III (2014) use latent structure, aimed to identify relevant dialog segments, for predicting objections during courtroom deliberations. Other related work include speech act recognition in emails and forums but at a sentence level (Jeong et al., 2009), and using social network analysis to improve message classification into pre-determined types (Fortuna e</context>
</contexts>
<marker>Lerman, Ghosh, 2010</marker>
<rawString>K. Lerman and R. Ghosh. 2010. Information contagion: An empirical study of the spread of news on digg and twitter social networks. In Proceedings of 4th International Conference on Weblogs and Social Media (ICWSM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Liben-Nowell</author>
<author>Jon Kleinberg</author>
</authors>
<title>Tracing the flow of information on a global scale using Internet chain-letter data.</title>
<date>2008</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>105</volume>
<issue>12</issue>
<pages>25</pages>
<contexts>
<context position="8656" citStr="Liben-Nowell and Kleinberg, 2008" startWordPosition="1351" endWordPosition="1354">ocusing on users who have already commented on a thread, and their algorithmic approach are different than ours. Our work is also very closely related to that of Wang et al. (2013) who predict solvedness —which predicts if there is a solution to the original problem posted in the thread. Like us, they believe that category of posts can assist in the prediction task, however, possibly owing to the complexity of general discussion forums, they had to manually create and annotate data with a sophisticated taxonomy. We do not make such assumptions. The work presented in (G´omez et al., 2008; 1502 Liben-Nowell and Kleinberg, 2008; Kumar et al., 2010; Golub and Jackson, 2010; Wang et al., 2011; Aumayr et al., 2011) discuss characterizing threads using reply-graphs (often trees) and learning this structure. However, this representation is not natural for the MOOC domain where discussions are relatively more focused on the thread topic and are better organized using sections within the forums. Although most prior work focuses on discussion forums of social media sites such as Twitter or Facebook, where the dynamics of interaction is very different from MOOCs, a small number of recent work address the unique MOOC setting.</context>
</contexts>
<marker>Liben-Nowell, Kleinberg, 2008</marker>
<rawString>David Liben-Nowell and Jon Kleinberg. 2008. Tracing the flow of information on a global scale using Internet chain-letter data. Proceedings of the National Academy of Sciences, 105(12):4633–4638, 25 March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andy Nguyen</author>
<author>Christopher Piech</author>
<author>Jonathan Huang</author>
<author>Leonidas J Guibas</author>
</authors>
<title>Codewebs: scalable homework search for massive open online programming courses. In</title>
<date>2014</date>
<booktitle>WWW,</booktitle>
<pages>491--502</pages>
<contexts>
<context position="9867" citStr="Nguyen et al., 2014" startWordPosition="1551" endWordPosition="1554"> setting. Stump et al. (2013) propose a framework for categorizing forum posts by designing a taxonomy and annotating posts manually to assist general forum analysis. Our model learns categories in a data-driven manner guided by the binary supervision (intervention decision) and serves a different purpose. Nevertheless, in Sec. 4.3 we compare the categories learnt by our models with those proposed by Stump et al. (2013). Apart from this, recent works have looked into interesting challenges in this domain such as better peer grading models (Piech et al., 2013), code review (Huang et al., 2013; Nguyen et al., 2014), improving student engagement (Anderson et al., 2014) and understanding how students learn and code (Piech et al., 2012; Kizilcec et al., 2013; Ramesh et al., 2013). 3 Intervention Prediction Models In this section, we explain our models in detail. 3.1 Problem Setting In our description it is assumed that a discussion board is organized into multiple forums (representing topics such as “Assignment”, “Study Group” etc.). A forum consists of multiple threads. Each thread (t) has a title and consists of multiple posts (pi). Individual posts do not have a title and the number of posts varies dram</context>
</contexts>
<marker>Nguyen, Piech, Huang, Guibas, 2014</marker>
<rawString>Andy Nguyen, Christopher Piech, Jonathan Huang, and Leonidas J. Guibas. 2014. Codewebs: scalable homework search for massive open online programming courses. In WWW, pages 491–502.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Piech</author>
<author>Mehran Sahami</author>
<author>Daphne Koller</author>
<author>Steve Cooper</author>
<author>Paulo Blikstein</author>
</authors>
<title>Modeling how students learn to program. In</title>
<date>2012</date>
<booktitle>SIGCSE,</booktitle>
<pages>153--160</pages>
<contexts>
<context position="9987" citStr="Piech et al., 2012" startWordPosition="1569" endWordPosition="1572">s manually to assist general forum analysis. Our model learns categories in a data-driven manner guided by the binary supervision (intervention decision) and serves a different purpose. Nevertheless, in Sec. 4.3 we compare the categories learnt by our models with those proposed by Stump et al. (2013). Apart from this, recent works have looked into interesting challenges in this domain such as better peer grading models (Piech et al., 2013), code review (Huang et al., 2013; Nguyen et al., 2014), improving student engagement (Anderson et al., 2014) and understanding how students learn and code (Piech et al., 2012; Kizilcec et al., 2013; Ramesh et al., 2013). 3 Intervention Prediction Models In this section, we explain our models in detail. 3.1 Problem Setting In our description it is assumed that a discussion board is organized into multiple forums (representing topics such as “Assignment”, “Study Group” etc.). A forum consists of multiple threads. Each thread (t) has a title and consists of multiple posts (pi). Individual posts do not have a title and the number of posts varies dramatically from one thread to another. We address the problem of predicting if the course instructor would intervene on a </context>
</contexts>
<marker>Piech, Sahami, Koller, Cooper, Blikstein, 2012</marker>
<rawString>Chris Piech, Mehran Sahami, Daphne Koller, Steve Cooper, and Paulo Blikstein. 2012. Modeling how students learn to program. In SIGCSE, pages 153– 160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Piech</author>
<author>Jonathan Huang</author>
<author>Zhenghao Chen</author>
<author>Chuong Do</author>
<author>Andrew Ng</author>
<author>Daphne Koller</author>
</authors>
<title>Tuned models of peer assessment in MOOCs.</title>
<date>2013</date>
<booktitle>In Proceedings of The 6th International Conference on Educational Data Mining (EDM</booktitle>
<contexts>
<context position="9812" citStr="Piech et al., 2013" startWordPosition="1541" endWordPosition="1544"> a small number of recent work address the unique MOOC setting. Stump et al. (2013) propose a framework for categorizing forum posts by designing a taxonomy and annotating posts manually to assist general forum analysis. Our model learns categories in a data-driven manner guided by the binary supervision (intervention decision) and serves a different purpose. Nevertheless, in Sec. 4.3 we compare the categories learnt by our models with those proposed by Stump et al. (2013). Apart from this, recent works have looked into interesting challenges in this domain such as better peer grading models (Piech et al., 2013), code review (Huang et al., 2013; Nguyen et al., 2014), improving student engagement (Anderson et al., 2014) and understanding how students learn and code (Piech et al., 2012; Kizilcec et al., 2013; Ramesh et al., 2013). 3 Intervention Prediction Models In this section, we explain our models in detail. 3.1 Problem Setting In our description it is assumed that a discussion board is organized into multiple forums (representing topics such as “Assignment”, “Study Group” etc.). A forum consists of multiple threads. Each thread (t) has a title and consists of multiple posts (pi). Individual posts </context>
</contexts>
<marker>Piech, Huang, Chen, Do, Ng, Koller, 2013</marker>
<rawString>Chris Piech, Jonathan Huang, Zhenghao Chen, Chuong Do, Andrew Ng, and Daphne Koller. 2013. Tuned models of peer assessment in MOOCs. In Proceedings of The 6th International Conference on Educational Data Mining (EDM 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arti Ramesh</author>
<author>Dan Goldwasser</author>
<author>Bert Huang</author>
<author>Hal Daum´e</author>
<author>Lise Getoor</author>
</authors>
<title>Modeling learner engagement in moocs using probabilistic soft logic.</title>
<date>2013</date>
<booktitle>In NIPS Workshop on Data Driven Education.</booktitle>
<marker>Ramesh, Goldwasser, Huang, Daum´e, Getoor, 2013</marker>
<rawString>Arti Ramesh, Dan Goldwasser, Bert Huang, Hal Daum´e III, and Lise Getoor. 2013. Modeling learner engagement in moocs using probabilistic soft logic. In NIPS Workshop on Data Driven Education.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Romero</author>
<author>Brendan Meeder</author>
<author>Jon Kleinberg</author>
</authors>
<title>Differences in the mechanics of information diffusion across topics: Idioms, political hashtags, and complex contagion on twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th International Conference on World Wide Web, WWW ’11,</booktitle>
<pages>695--704</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6601" citStr="Romero et al., 2011" startWordPosition="1019" endWordPosition="1022">tructure, and the value of lexical and domain specific knowledge for the prediction task 2 Related Work To the best of our knowledge, the problem of predicting instructor’s intervention in MOOC forums has not been addressed yet. Prior work deals with analyzing general online discussion forums of social media sites (Kleinberg, 2013): such as predicting comment volume (Backstrom et al., 2013; De Choudhury et al., 2009; Wang et al., 2012; Tsagkias et al., 2009; Yano and Smith, 2010; Artzi et al., 2012) and rate of content diffusion (Kwak et al., 2010; Lerman and Ghosh, 2010; Bakshy et al., 2011; Romero et al., 2011; Artzi et al., 2012) and also question answering (Chaturvedi et al., 2014). Wang et al. (2007) incorporate thread structure of conversations using features in email threads while Goldwasser and Daum´e III (2014) use latent structure, aimed to identify relevant dialog segments, for predicting objections during courtroom deliberations. Other related work include speech act recognition in emails and forums but at a sentence level (Jeong et al., 2009), and using social network analysis to improve message classification into pre-determined types (Fortuna et al., 2007). Discussion forums data has a</context>
</contexts>
<marker>Romero, Meeder, Kleinberg, 2011</marker>
<rawString>Daniel M. Romero, Brendan Meeder, and Jon Kleinberg. 2011. Differences in the mechanics of information diffusion across topics: Idioms, political hashtags, and complex contagion on twitter. In Proceedings of the 20th International Conference on World Wide Web, WWW ’11, pages 695–704, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glenda S Stump</author>
<author>Jennifer DeBoer</author>
<author>Jonathan Whittinghill</author>
<author>Lori Breslow</author>
</authors>
<title>Development of a framework to classify mooc discussion forum posts: Methodology and challenges.</title>
<date>2013</date>
<contexts>
<context position="9276" citStr="Stump et al. (2013)" startWordPosition="1453" endWordPosition="1456"> Kumar et al., 2010; Golub and Jackson, 2010; Wang et al., 2011; Aumayr et al., 2011) discuss characterizing threads using reply-graphs (often trees) and learning this structure. However, this representation is not natural for the MOOC domain where discussions are relatively more focused on the thread topic and are better organized using sections within the forums. Although most prior work focuses on discussion forums of social media sites such as Twitter or Facebook, where the dynamics of interaction is very different from MOOCs, a small number of recent work address the unique MOOC setting. Stump et al. (2013) propose a framework for categorizing forum posts by designing a taxonomy and annotating posts manually to assist general forum analysis. Our model learns categories in a data-driven manner guided by the binary supervision (intervention decision) and serves a different purpose. Nevertheless, in Sec. 4.3 we compare the categories learnt by our models with those proposed by Stump et al. (2013). Apart from this, recent works have looked into interesting challenges in this domain such as better peer grading models (Piech et al., 2013), code review (Huang et al., 2013; Nguyen et al., 2014), improvi</context>
<context position="29680" citStr="Stump et al. (2013)" startWordPosition="4896" endWordPosition="4899"> similar correlations while examining the columns of the heat map. Also, F5, which contains words common to the gene and human health domain, is scattered across multiple categories. For example, dna/rna and breeding are sufficiently frequent in category 1 as well as 2. Table 2 gives examples of representative posts from the four clusters. Due to space constraints, we show only part of the complete post. We can see that these examples agree with our observations from the heat map. Furthermore, as noted in Sec. 2, we compare the semantics of clusters learnt by our models with those proposed by Stump et al. (2013) even though the two categorizations are not directly comparable. Nevertheless, generally speaking, our category 1 corresponds to Stump et al. (2013)’s Course structure/policies and category 2 corresponds to Content. Interestingly, categories 3 and 4, which represent valedictory and introductory posts, correspond to a single Social/affective from the previous work. We can, therefore, conclude that the model, indeed splits the posts into categories that look semantically coherent to the human eyes. (b) Women and the Civil Rights Movement dataset Figure 5: Cross validation performances of the tw</context>
</contexts>
<marker>Stump, DeBoer, Whittinghill, Breslow, 2013</marker>
<rawString>Glenda S. Stump, Jennifer DeBoer, Jonathan Whittinghill, and Lori Breslow. 2013. Development of a framework to classify mooc discussion forum posts: Methodology and challenges.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manos Tsagkias</author>
<author>Wouter Weerkamp</author>
<author>Maarten de Rijke</author>
</authors>
<title>Predicting the volume of comments on online news stories.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th ACM Conference on Information and Knowledge Management, CIKM ’09,</booktitle>
<pages>1765--1768</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Tsagkias, Weerkamp, de Rijke, 2009</marker>
<rawString>Manos Tsagkias, Wouter Weerkamp, and Maarten de Rijke. 2009. Predicting the volume of comments on online news stories. In Proceedings of the 18th ACM Conference on Information and Knowledge Management, CIKM ’09, pages 1765–1768, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi-Chia Wang</author>
<author>Mahesh Joshi</author>
<author>Carolyn Penstein Ros</author>
</authors>
<title>A feature based approach to leveraging context for classifying newsgroup style discussion segments. In</title>
<date>2007</date>
<editor>John A. Carroll, Antal van den Bosch, and Annie Zaenen, editors, ACL.</editor>
<publisher>The Association for Computational Linguistics.</publisher>
<contexts>
<context position="6696" citStr="Wang et al. (2007)" startWordPosition="1035" endWordPosition="1038">ed Work To the best of our knowledge, the problem of predicting instructor’s intervention in MOOC forums has not been addressed yet. Prior work deals with analyzing general online discussion forums of social media sites (Kleinberg, 2013): such as predicting comment volume (Backstrom et al., 2013; De Choudhury et al., 2009; Wang et al., 2012; Tsagkias et al., 2009; Yano and Smith, 2010; Artzi et al., 2012) and rate of content diffusion (Kwak et al., 2010; Lerman and Ghosh, 2010; Bakshy et al., 2011; Romero et al., 2011; Artzi et al., 2012) and also question answering (Chaturvedi et al., 2014). Wang et al. (2007) incorporate thread structure of conversations using features in email threads while Goldwasser and Daum´e III (2014) use latent structure, aimed to identify relevant dialog segments, for predicting objections during courtroom deliberations. Other related work include speech act recognition in emails and forums but at a sentence level (Jeong et al., 2009), and using social network analysis to improve message classification into pre-determined types (Fortuna et al., 2007). Discussion forums data has also been used to address other interesting challenges such as extracting chatbox knowledge for </context>
</contexts>
<marker>Wang, Joshi, Ros, 2007</marker>
<rawString>Yi-Chia Wang, Mahesh Joshi, and Carolyn Penstein Ros. 2007. A feature based approach to leveraging context for classifying newsgroup style discussion segments. In John A. Carroll, Antal van den Bosch, and Annie Zaenen, editors, ACL. The Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongning Wang</author>
<author>Chi Wang</author>
<author>ChengXiang Zhai</author>
<author>Jiawei Han</author>
</authors>
<title>Learning online discussion structures by conditional random fields.</title>
<date>2011</date>
<booktitle>In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’11,</booktitle>
<pages>435--444</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="8720" citStr="Wang et al., 2011" startWordPosition="1363" endWordPosition="1366">approach are different than ours. Our work is also very closely related to that of Wang et al. (2013) who predict solvedness —which predicts if there is a solution to the original problem posted in the thread. Like us, they believe that category of posts can assist in the prediction task, however, possibly owing to the complexity of general discussion forums, they had to manually create and annotate data with a sophisticated taxonomy. We do not make such assumptions. The work presented in (G´omez et al., 2008; 1502 Liben-Nowell and Kleinberg, 2008; Kumar et al., 2010; Golub and Jackson, 2010; Wang et al., 2011; Aumayr et al., 2011) discuss characterizing threads using reply-graphs (often trees) and learning this structure. However, this representation is not natural for the MOOC domain where discussions are relatively more focused on the thread topic and are better organized using sections within the forums. Although most prior work focuses on discussion forums of social media sites such as Twitter or Facebook, where the dynamics of interaction is very different from MOOCs, a small number of recent work address the unique MOOC setting. Stump et al. (2013) propose a framework for categorizing forum </context>
</contexts>
<marker>Wang, Wang, Zhai, Han, 2011</marker>
<rawString>Hongning Wang, Chi Wang, ChengXiang Zhai, and Jiawei Han. 2011. Learning online discussion structures by conditional random fields. In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’11, pages 435–444, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chunyan Wang</author>
<author>Mao Ye</author>
<author>Bernardo A Huberman</author>
</authors>
<title>From user comments to on-line conversations.</title>
<date>2012</date>
<booktitle>In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’12,</booktitle>
<pages>244--252</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6420" citStr="Wang et al., 2012" startWordPosition="986" endWordPosition="989">tant problem of predicting instructor intervention in MOOC forums • We present two chain based models that incorporate thread structure. • We show the utility of modeling thread structure, and the value of lexical and domain specific knowledge for the prediction task 2 Related Work To the best of our knowledge, the problem of predicting instructor’s intervention in MOOC forums has not been addressed yet. Prior work deals with analyzing general online discussion forums of social media sites (Kleinberg, 2013): such as predicting comment volume (Backstrom et al., 2013; De Choudhury et al., 2009; Wang et al., 2012; Tsagkias et al., 2009; Yano and Smith, 2010; Artzi et al., 2012) and rate of content diffusion (Kwak et al., 2010; Lerman and Ghosh, 2010; Bakshy et al., 2011; Romero et al., 2011; Artzi et al., 2012) and also question answering (Chaturvedi et al., 2014). Wang et al. (2007) incorporate thread structure of conversations using features in email threads while Goldwasser and Daum´e III (2014) use latent structure, aimed to identify relevant dialog segments, for predicting objections during courtroom deliberations. Other related work include speech act recognition in emails and forums but at a se</context>
</contexts>
<marker>Wang, Ye, Huberman, 2012</marker>
<rawString>Chunyan Wang, Mao Ye, and Bernardo A. Huberman. 2012. From user comments to on-line conversations. In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’12, pages 244–252, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Wang</author>
<author>Su Nam Kim</author>
<author>Timothy Baldwin</author>
</authors>
<title>The utility of discourse structure in forum thread retrieval.</title>
<date>2013</date>
<booktitle>In AIRS,</booktitle>
<pages>284--295</pages>
<contexts>
<context position="8204" citStr="Wang et al. (2013)" startWordPosition="1277" endWordPosition="1280">ave an underlying structure and that messages belong to categories. However, they operate in a different domain, which makes their goals and methods different from ours. Our work is most closely related to that of Backstrom et al. (2013) which introduced the re-entry prediction task —predicting whether a user who has participated in a thread will later contribute another comment to it. While seemingly related, their prediction task, focusing on users who have already commented on a thread, and their algorithmic approach are different than ours. Our work is also very closely related to that of Wang et al. (2013) who predict solvedness —which predicts if there is a solution to the original problem posted in the thread. Like us, they believe that category of posts can assist in the prediction task, however, possibly owing to the complexity of general discussion forums, they had to manually create and annotate data with a sophisticated taxonomy. We do not make such assumptions. The work presented in (G´omez et al., 2008; 1502 Liben-Nowell and Kleinberg, 2008; Kumar et al., 2010; Golub and Jackson, 2010; Wang et al., 2011; Aumayr et al., 2011) discuss characterizing threads using reply-graphs (often tree</context>
</contexts>
<marker>Wang, Kim, Baldwin, 2013</marker>
<rawString>Li Wang, Su Nam Kim, and Timothy Baldwin. 2013. The utility of discourse structure in forum thread retrieval. In AIRS, pages 284–295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tae Yano</author>
<author>Noah A Smith</author>
</authors>
<title>What’s worthy of comment? content and comment volume in political blogs.</title>
<date>2010</date>
<editor>In William W. Cohen and Samuel Gosling, editors, ICWSM.</editor>
<publisher>The AAAI Press.</publisher>
<contexts>
<context position="6465" citStr="Yano and Smith, 2010" startWordPosition="994" endWordPosition="997">rvention in MOOC forums • We present two chain based models that incorporate thread structure. • We show the utility of modeling thread structure, and the value of lexical and domain specific knowledge for the prediction task 2 Related Work To the best of our knowledge, the problem of predicting instructor’s intervention in MOOC forums has not been addressed yet. Prior work deals with analyzing general online discussion forums of social media sites (Kleinberg, 2013): such as predicting comment volume (Backstrom et al., 2013; De Choudhury et al., 2009; Wang et al., 2012; Tsagkias et al., 2009; Yano and Smith, 2010; Artzi et al., 2012) and rate of content diffusion (Kwak et al., 2010; Lerman and Ghosh, 2010; Bakshy et al., 2011; Romero et al., 2011; Artzi et al., 2012) and also question answering (Chaturvedi et al., 2014). Wang et al. (2007) incorporate thread structure of conversations using features in email threads while Goldwasser and Daum´e III (2014) use latent structure, aimed to identify relevant dialog segments, for predicting objections during courtroom deliberations. Other related work include speech act recognition in emails and forums but at a sentence level (Jeong et al., 2009), and using </context>
</contexts>
<marker>Yano, Smith, 2010</marker>
<rawString>Tae Yano and Noah A. Smith. 2010. What’s worthy of comment? content and comment volume in political blogs. In William W. Cohen and Samuel Gosling, editors, ICWSM. The AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chun-Nam John Yu</author>
<author>Thorsten Joachims</author>
</authors>
<title>Learning structural svms with latent variables.</title>
<date>2009</date>
<booktitle>In Proceedings of the 26th Annual International Conference on Machine Learning, ICML ’09,</booktitle>
<pages>1169--1176</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="21810" citStr="Yu and Joachims, 2009" startWordPosition="3590" endWordPosition="3593"> the first step, it determines the latent variable assignments for positive examples. The algorithm then performs two step iteratively - first it determines the structural assignments for the negative examples, and then optimizes the fixed objective function using a cutting plane algorithm. Once this process converges for negative examples, the algorithm reassigns values to the latent variables for positive examples, and proceeds to the second step. The algorithm stops once a local minimum is reached. A somewhat similar approach, which uses the Convex-Concave Procedure (CCCP) is presented by (Yu and Joachims, 2009). At test time, given a thread, t, and it posts, p, we use the learned weights to compute f,,,(t, p) and classify it as belonging to the positive class (instructor intervenes) if f,,,(t, p) ≥ 0. 3.4.2 Feature Engineering The feature set used by this model is very similar to the features used by the previous model. In addition to the non-structural features used by the logistic regression model (Sec. 3.2.1), it uses all the Post Emission features and the three transition features represented by φ(hi−1, hi) and φ(hi−1, hi, pi, pi−1) as described in Sec. 3.3.2. 4 Empirical Evaluation This section</context>
</contexts>
<marker>Yu, Joachims, 2009</marker>
<rawString>Chun-Nam John Yu and Thorsten Joachims. 2009. Learning structural svms with latent variables. In Proceedings of the 26th Annual International Conference on Machine Learning, ICML ’09, pages 1169–1176, New York, NY, USA. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>