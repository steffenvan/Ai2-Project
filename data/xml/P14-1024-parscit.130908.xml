<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000029">
<title confidence="0.997307">
Metaphor Detection with Cross-Lingual Model Transfer
</title>
<author confidence="0.985116">
Yulia Tsvetkov Leonid Boytsov Anatole Gershman Eric Nyberg Chris Dyer
</author>
<affiliation confidence="0.882197333333333">
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA 15213 USA
</affiliation>
<email confidence="0.981876">
{ytsvetko, srchvrs, anatoleg, ehn, cdyer}@cs.cmu.edu
</email>
<sectionHeader confidence="0.99459" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999874125">
We show that it is possible to reliably dis-
criminate whether a syntactic construction
is meant literally or metaphorically using
lexical semantic features of the words that
participate in the construction. Our model
is constructed using English resources,
and we obtain state-of-the-art performance
relative to previous work in this language.
Using a model transfer approach by piv-
oting through a bilingual dictionary, we
show our model can identify metaphoric
expressions in other languages. We pro-
vide results on three new test sets in Span-
ish, Farsi, and Russian. The results sup-
port the hypothesis that metaphors are
conceptual, rather than lexical, in nature.
</bodyText>
<sectionHeader confidence="0.998782" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999952767857143">
Lakoff and Johnson (1980) characterize metaphor
as reasoning about one thing in terms of another,
i.e., a metaphor is a type of conceptual mapping,
where words or phrases are applied to objects and
actions in ways that do not permit a literal inter-
pretation. They argue that metaphors play a fun-
damental communicative role in verbal and writ-
ten interactions, claiming that much of our every-
day language is delivered in metaphorical terms.
There is empirical evidence supporting the claim:
recent corpus studies have estimated that the pro-
portion of words used metaphorically ranges from
5% to 20% (Steen et al., 2010), and Thibodeau and
Boroditsky (2011) provide evidence that a choice
of metaphors affects decision making.
Given the prevalence and importance of
metaphoric language, effective automatic detec-
tion of metaphors would have a number of ben-
efits, both practical and scientific. Language pro-
cessing applications that need to understand lan-
guage or preserve meaning (information extrac-
tion, machine translation, dialog systems, senti-
ment analysis, and text analytics, etc.) would have
access to a potentially useful high-level bit of in-
formation about whether something is to be under-
stood literally or not. Second, scientific hypothe-
ses about metaphoric language could be tested
more easily at a larger scale with automation.
However, metaphor detection is a hard problem.
On one hand, there is a subjective component: hu-
mans may disagree whether a particular expres-
sion is used metaphorically or not, as there is no
clear-cut semantic distinction between figurative
and metaphorical language (Shutova, 2010). On
the other, metaphors can be domain- and context-
dependent.1
Previous work has focused on metaphor identi-
fication in English, using both extensive manually-
created linguistic resources (Mason, 2004; Gedi-
gian et al., 2006; Krishnakumaran and Zhu, 2007;
Turney et al., 2011; Broadwell et al., 2013) and
corpus-based approaches (Birke and Sarkar, 2007;
Shutova et al., 2013; Neuman et al., 2013; Shutova
and Sun, 2013; Hovy et al., 2013). We build on
this foundation and also extend metaphor detec-
tion into other languages in which few resources
may exist. Our work makes the following con-
tributions: (1) we develop a new state-of-the-art
English metaphor detection system that uses con-
ceptual semantic features, such as a degree of ab-
stractness and semantic supersenses;2 (2) we cre-
ate new metaphor-annotated corpora for Russian
and English;3 (3) using a paradigm of model trans-
fer (McDonald et al., 2011; T¨ackstr¨om et al., 2013;
Kozhenikov and Titov, 2013), we provide sup-
port for the hypothesis that metaphors are concep-
</bodyText>
<footnote confidence="0.996993428571429">
1For example, drowning students could be used metaphor-
ically to describe the situation where students are over-
whelmed with work, but in the sentence a lifeguard saved
drowning students, this phrase is used literally.
2https://github.com/ytsvetko/metaphor
3http://www.cs.cmu.edu/˜ytsvetko/
metaphor/datasets.zip
</footnote>
<page confidence="0.8608">
248
</page>
<note confidence="0.8423555">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 248–258,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.927368333333333">
tual (rather than lexical) in nature by showing that
our English-trained model can detect metaphors in
Spanish, Farsi, and Russian.
</bodyText>
<sectionHeader confidence="0.988091" genericHeader="introduction">
2 Methodology
</sectionHeader>
<bodyText confidence="0.870437166666667">
Our task in this work is to define features that dis-
tinguish between metaphoric and literal uses of
two syntactic constructions: subject-verb-object
(SVO) and adjective-noun (AN) tuples.4 We give
examples of a prototypical metaphoric usage of
each type:
</bodyText>
<listItem confidence="0.847319">
• SVO metaphors. A sentence containing a
metaphoric SVO relation is my car drinks
gasoline. According to Wilks (1978), this
metaphor represents a violation of selectional
preferences for the verb drink, which is nor-
mally associated with animate subjects (the
car is inanimate and, hence, cannot drink in
the literal sense of the verb).
• AN metaphors. The phrase broken promise
is an AN metaphor, where attributes from
</listItem>
<bodyText confidence="0.9806442">
a concrete domain (associated with the con-
crete word broken) are transferred to a more
abstract domain, which is represented by the
relatively abstract word promise. That is, we
map an abstract concept promise to a concrete
domain of physical things, where things can
be literally broken to pieces.
Motivated by Lakoff’s (1980) argument that
metaphors are systematic conceptual mappings,
we will use coarse-grained conceptual, rather than
fine-grained lexical features, in our classifier. Con-
ceptual features pertain to concepts and ideas as
opposed to individual words or phrases expressed
in a particular language. In this sense, as long as
two words in two different languages refer to the
same concepts, their conceptual features should
be the same. Furthermore, we hypothesize that
our coarse semantic features give us a language-
invariant representation suitable for metaphor de-
tection. To test this hypothesis, we use a cross-
lingual model transfer approach: we use bilingual
dictionaries to project words from other syntactic
constructions found in other languages into En-
glish and then apply the English model on the de-
rived conceptual representations.
</bodyText>
<footnote confidence="0.8529368">
4Our decision to focus on SVO and AN metaphors is jus-
tified by corpus studies that estimate that verb- and adjective-
based metaphors account for a substantial proportion of all
metaphoric expressions, approximately 60% and 24%, re-
spectively (Shutova and Teufel, 2010; Gandy et al., 2013).
</footnote>
<bodyText confidence="0.9989375625">
Each SVO (or AN) instance will be represented
by a triple (duple) from which a feature vector
will be extracted.5 The vector will consist of the
concatenation of the conceptual features (which
we discuss below) for all participating words, and
conjunction features for word pairs.6 For example,
to generate the feature vector for the SVO triple
(car, drink, gasoline), we compute all the features
for the individual words car, drink, gasoline and
combine them with the conjunction features for
the pairs car drink and drink gasoline.
We define three main feature categories (1) ab-
stractness and imageability, (2) supersenses, (3)
unsupervised vector-space word representations;
each category corresponds to a group of features
with a common theme and representation.
</bodyText>
<listItem confidence="0.90048425">
• Abstractness and imageability. Abstract-
ness and imageability were shown to be use-
ful in detection of metaphors (it is easier to
invoke mental pictures of concrete and im-
ageable words) (Turney et al., 2011; Broad-
well et al., 2013). We expect that abstract-
ness, used in conjunction features (e.g., a
feature denoting that the subject is abstract
and the verb is concrete), is especially use-
ful: semantically, an abstract agent perform-
ing a concrete action is a strong signal of
metaphorical usage.
</listItem>
<bodyText confidence="0.9984621">
Although often correlated with abstractness,
imageability is not a redundant property.
While most abstract things are hard to visu-
alize, some call up images, e.g., vengeance
calls up an emotional image, torture calls up
emotions and even visual images. There are
concrete things that are hard to visualize too,
for example, abbey is harder to visualize than
banana (B. MacWhinney, personal commu-
nication).
</bodyText>
<listItem confidence="0.958741">
• Supersenses. Supersenses7 are coarse se-
mantic categories originating in WordNet.
For nouns and verbs there are 45 classes:
26 for nouns and 15 for verbs, for example,
</listItem>
<footnote confidence="0.9981297">
5Looking at components of the syntactic constructions in-
dependent of their context has its limitations, as discussed
above with the drowning students example; however, it sim-
plifies the representation challenges considerably.
6If word one is represented by features u ∈ R&apos; and word
two by features v ∈ R&apos; then the conjunction feature vector
is the vectorization of the outer product uvT.
7Supersenses are called “lexicographer classes” in Word-
Net documentation (Fellbaum, 1998), http://wordnet.
princeton.edu/man/lexnames.5WN.html
</footnote>
<page confidence="0.998754">
249
</page>
<bodyText confidence="0.997045608695652">
noun.body, noun.animal, verb.consumption,
or verb.motion (Ciaramita and Altun, 2006).
English adjectives do not, as yet, have a sim-
ilar high-level semantic partitioning in Word-
Net, thus we use a 13-class taxonomy of ad-
jective supersenses constructed by Tsvetkov
et al. (2014) (discussed in §3.2).
Supersenses are particularly attractive fea-
tures for metaphor detection: coarse sense
taxonomies can be viewed as semantic con-
cepts, and since concept mapping is a pro-
cess in which metaphors are born, we
expect different supersense co-occurrences
in metaphoric and literal combinations.
In “drinks gasoline”, for example, map-
ping to supersenses would yield a pair
&lt;verb.consumption, noun.substance&gt;, con-
trasted with &lt;verb.consumption, noun.food&gt;
for “drinks juice”. In addition, this coarse
semantic categorization is preserved in trans-
lation (Schneider et al., 2013), which makes
supersense features suitable for cross-lingual
approaches such as ours.
</bodyText>
<listItem confidence="0.99801635">
• Vector space word representations. Vec-
tor space word representations learned us-
ing unsupervised algorithms are often effec-
tive features in supervised learning methods
(Turian et al., 2010). In particular, many such
representations are designed to capture lex-
ical semantic properties and are quite effec-
tive features in semantic processing, includ-
ing named entity recognition (Turian et al.,
2009), word sense disambiguation (Huang et
al., 2012), and lexical entailment (Baroni et
al., 2012). In a recent study, Mikolov et
al. (2013) reveal an interesting cross-lingual
property of distributed word representations:
there is a strong similarity between the vec-
tor spaces across languages that can be eas-
ily captured by linear mapping. Thus, vector
space models can also be seen as vectors of
(latent) semantic concepts, that preserve their
“meaning” across languages.
</listItem>
<sectionHeader confidence="0.762737" genericHeader="method">
3 Model and Feature Extraction
</sectionHeader>
<bodyText confidence="0.952755333333333">
In this section we describe a classification model,
and provide details on mono- and cross-lingual
implementation of features.
</bodyText>
<subsectionHeader confidence="0.999742">
3.1 Classification using Random Forests
</subsectionHeader>
<bodyText confidence="0.999924047619048">
To make classification decisions, we use a random
forest classifier (Breiman, 2001), an ensemble of
decision tree classifiers learned from many inde-
pendent subsamples of the training data. Given
an input, each tree classifier assigns a probabil-
ity to each label; those probabilities are averaged
to compute the probability distribution across the
ensemble. Random forest ensembles are partic-
ularly suitable for our resource-scarce scenario:
rather than overfitting, they produce a limiting
value of the generalization error as the number
of trees increases,8 and no hyperparameter tuning
is required. In addition, decision-tree classifiers
learn non-linear responses to inputs and often out-
perform logistic regression (Perlich et al., 2003).9
Our random forest classifier models the probabil-
ity that the input syntactic relation is metaphorical.
If this probability is above a threshold, the relation
is classified as metaphoric, otherwise it is literal.
We used the scikit-learn toolkit to train our
classifiers (Pedregosa et al., 2011).
</bodyText>
<subsectionHeader confidence="0.999272">
3.2 Feature extraction
</subsectionHeader>
<bodyText confidence="0.999964761904762">
Abstractness and imageability. The MRC psy-
cholinguistic database is a large dictionary listing
linguistic and psycholinguistic attributes obtained
experimentally (Wilson, 1988).10 It includes,
among other data, 4,295 words rated by the de-
grees of abstractness and 1,156 words rated by the
imageability. Similarly to Tsvetkov et al. (2013),
we use a logistic regression classifier to propagate
abstractness and imageability scores from MRC
ratings to all words for which we have vector space
representations. More specifically, we calculate
the degree of abstractness and imageability of all
English items that have a vector space representa-
tion, using vector elements as features. We train
two separate classifiers for abstractness and im-
ageability on a seed set of words from the MRC
database. Degrees of abstractness and imageabil-
ity are posterior probabilities of classifier predic-
tions. We binarize these posteriors into abstract-
concrete (or imageable-unimageable) boolean in-
dicators using pre-defined thresholds.11 Perfor-
</bodyText>
<footnote confidence="0.919178428571429">
8See Theorem 1.2 in (Breiman, 2001) for details.
9In our experiments, random forests model slightly out-
performed logistic regression and SVM classifiers.
10http://ota.oucs.ox.ac.uk/headers/
1054.xml
11Thresholds are equal to 0.8 for abstractness and to 0.9
for imageability. They were chosen empirically based on ac-
</footnote>
<page confidence="0.986119">
250
</page>
<bodyText confidence="0.996738111111111">
mance of these classifiers, tested on a sampled
held-out data, is 0.94 and 0.85 for the abstractness
and imageability classifiers, respectively.
Supersenses. In the case of SVO relations, we
incorporate supersense features for nouns and
verbs; noun and adjective supersenses are used in
the case of AN relations.
Supersenses of nouns and verbs. A lexical item
can belong to several synsets, which are associ-
ated with different supersenses. Degrees of mem-
bership in different supersenses are represented
by feature vectors, where each element corre-
sponds to one supersense. For example, the word
head (when used as a noun) participates in 33
synsets, three of which are related to the super-
sense noun.body. The value of the feature corre-
sponding to this supersense is 3/33 ≈ 0.09.
Supersenses of adjectives. WordNet lacks
coarse-grained semantic categories for adjectives.
To divide adjectives into groups, Tsvetkov et al.
(2014) use 13 top-level classes from the adapted
taxonomy of Hundsnurscher and Splett (1982),
which is incorporated in GermaNet (Hamp and
Feldweg, 1997). For example, the top-level
classes in GermaNet include: adj.feeling (e.g.,
willing, pleasant, cheerful); adj.substance (e.g.,
dry, ripe, creamy); adj.spatial (e.g., adjacent, gi-
gantic).12 For each adjective type in WordNet,
they produce a vector with a classifier posterior
probabilities corresponding to degrees of mem-
bership of this word in one of the 13 semantic
classes,13 similar to the feature vectors we build
for nouns and verbs. For example, for a word
calm the top-2 categories (with the first and second
highest degrees of membership) are adj.behavior
and adj.feeling.
Vector space word representations. We em-
ploy 64-dimensional vector-space word represen-
tations constructed by Faruqui and Dyer (2014).14
Vector construction algorithm is a variation on
traditional latent semantic analysis (Deerwester
et al., 1990) that uses multilingual information
to produce representations in which synonymous
words have similar vectors. The vectors were
curacy during cross-validation.
</bodyText>
<footnote confidence="0.935419166666667">
12For the full taxonomy see http://www.sfs.
uni-tuebingen.de/lsd/adjectives.shtml
13http://www.cs.cmu.edu/˜ytsvetko/
adj-supersenses.tar.gz
14http://www.cs.cmu.edu/˜mfaruqui/soft.
html
</footnote>
<bodyText confidence="0.995303">
trained on the news commentary corpus released
by WMT-2011,15 comprising 180,834 types.
</bodyText>
<subsectionHeader confidence="0.999845">
3.3 Cross-lingual feature projection
</subsectionHeader>
<bodyText confidence="0.9999971875">
For languages other than English, feature vectors
are projected to English features using translation
dictionaries. We used the Babylon dictionary,16
which is a proprietary resource, but any bilingual
dictionary can in principle be used. For a non-
English word in a source language, we first ob-
tain all translations into English. Then, we av-
erage all feature vectors related to these transla-
tions. Consider an example related to projection
of WordNet supersenses. A Russian word ro.Iosa
is translated as head and brain. Hence, we select
all the synsets of the nouns head and brain. There
are 38 such synsets (33 for head and 5 for brain).
Four of these synsets are associated with the su-
persense noun.body. Therefore, the value of the
feature noun.body is 4/38 ≈ 0.11.
</bodyText>
<sectionHeader confidence="0.99864" genericHeader="method">
4 Datasets
</sectionHeader>
<bodyText confidence="0.999962">
In this section we describe a training and testing
dataset as well a data collection procedure.
</bodyText>
<subsectionHeader confidence="0.999068">
4.1 English training sets
</subsectionHeader>
<bodyText confidence="0.999992681818182">
To train an SVO metaphor classifier, we employ
the TroFi (Trope Finder) dataset.17 TroFi includes
3,737 manually annotated English sentences from
the Wall Street Journal (Birke and Sarkar, 2007).
Each sentence contains either literal or metaphori-
cal use for one of 50 English verbs. First, we use a
dependency parser (Martins et al., 2010) to extract
subject-verb-object (SVO) relations. Then, we fil-
ter extracted relations to eliminate parsing-related
errors, and relations with verbs which are not in
the TroFi verb list. After filtering, there are 953
metaphorical and 656 literal SVO relations which
we use as a training set.
In the case of AN relations, we construct and
make publicly available a training set contain-
ing 884 metaphorical AN pairs and 884 pairs
with literal meaning. It was collected by two
annotators using public resources (collections of
metaphors on the web). At least one additional
person carefully examined and culled the col-
lected metaphors, by removing duplicates, weak
metaphors, and metaphorical phrases (such as
</bodyText>
<footnote confidence="0.99928575">
15http://www.statmt.org/wmt11/
16http://www.babylon.com
17http://www.cs.sfu.ca/˜anoop/students/
jbirke/
</footnote>
<page confidence="0.994878">
251
</page>
<bodyText confidence="0.9991675">
drowning students) whose interpretation depends
on the context.
</bodyText>
<subsectionHeader confidence="0.989726">
4.2 Multilingual test sets
</subsectionHeader>
<bodyText confidence="0.9986043">
We collect and annotate metaphoric and literal test
sentences in four languages. Thus, we compile
eight test datasets, four for SVO relations, and
four for AN relations. Each dataset has an equal
number of metaphors and non-metaphors, i.e., the
datasets are balanced. English (EN) and Russian
(RU) datasets have been compiled by our team
and are publicly available. Spanish (ES) and Farsi
(FA) datasets are published elsewhere (Levin et al.,
2014). Table 1 lists test set sizes.
</bodyText>
<table confidence="0.9975622">
SVO AN
EN 222 200
RU 240 200
ES 220 120
FA 44 320
</table>
<tableCaption confidence="0.997308">
Table 1: Sizes of the eight test sets. Each dataset is
</tableCaption>
<bodyText confidence="0.992292642857143">
balanced, i.e., it has an equal number of metaphors
and non-metaphors. For example, English SVO
dataset has 222 relations: 111 metaphoric and 111
literal.
We used the following procedure to compile the
EN and RU test sets. A moderator started with seed
lists of 1000 most common verbs and adjectives.18
Then she used the SketchEngine, which pro-
vides searching capability for the TenTen Web cor-
pus,19 to extract sentences with words that fre-
quently co-occurred with words from the seed
lists. From these sentences, she removed sen-
tences that contained more than one metaphor, and
sentences with non-SVO and non-AN metaphors.
Remaining sentences were annotated by several
native speakers (five for English and six for Rus-
sian), who judged AN and SVO phrases in con-
text. The annotation instructions were general:
“Please, mark in bold all words that, in your opin-
ion, are used non-literally in the following sen-
tences. In many sentences, all the words may be
used literally.” The Fleiss’ Kappas for 5 English
and 6 Russian annotators are: EN-AN = .76, RU-
18Selection of 1000 most common verbs and adjectives
achieves much broader lexical and domain coverage than
what can be realistically obtained from continuous text. Our
test sentence domains are, therefore, diverse: economic, po-
litical, sports, etc.
</bodyText>
<footnote confidence="0.570085">
19http://trac.sketchengine.co.uk/wiki/
Corpora/enTenTen
</footnote>
<bodyText confidence="0.997999">
AN = .85, EN-SVO = .75, RU-SVO = .78. For the fi-
nal selection, we filtered out low-agreement (&lt;.8)
sentences.
The test candidate sentences were selected by
a person who did not participate in the selection
of the training samples. No English annotators of
the test set, and only one Russian annotator out
of 6 participated in the selection of the training
samples. Thus, we trust that annotator judgments
were not biased towards the cases that the system
is trained to process.
</bodyText>
<sectionHeader confidence="0.999847" genericHeader="method">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.998729">
5.1 English experiments
</subsectionHeader>
<bodyText confidence="0.999880272727273">
Our task, as defined in Section 2, is to classify
SVO and AN relations as either metaphoric or lit-
eral. We first conduct a 10-fold cross-validation
experiment on the training set defined in Section
4.1. We represent each candidate relation using
the features described in Section 3.2, and evalu-
ate performance of the three feature categories and
their combinations. This is done by computing an
accuracy in the 10-fold cross validation. Experi-
mental results are given in Table 2, where we also
provide the number of features in each feature set.
</bodyText>
<table confidence="0.998547571428571">
SVO ACC AN ACC
# FEAT # FEAT
AbsImg 20 0.73* 16 0.76*
Supersense 67 0.77* 116 0.79*
AbsImg+Sup. 87 0.78* 132 0.80*
VSM 192 0.81 228 0.84*
All 279 0.82 360 0.86
</table>
<tableCaption confidence="0.988306">
Table 2: 10-fold cross validation results for three
</tableCaption>
<bodyText confidence="0.998823466666667">
feature categories and their combination, for clas-
sifiers trained on English SVO and AN training
sets. # FEAT column shows a number of features.
ACC column reports an accuracy score in the 10-
fold cross validation. Statistically significant dif-
ferences (p &lt; 0.01) from the all-feature combina-
tion are marked with a star.
These results show superior performance over
previous state-of-the-art results, confirming our
hypothesis that conceptual features are effective
in metaphor classification. For the SVO task, the
cross-validation accuracy is about 10% better than
that of Tsvetkov et al. (2013). For the AN task,
the cross validation accuracy is better by 8% than
the result of Turney et al. (2011) (two baseline
</bodyText>
<page confidence="0.984914">
252
</page>
<bodyText confidence="0.98042847368421">
methods are described in Section 5.2). We can
see that all types of features have good perfor-
mance on their own (VSM is the strongest feature
type). Noun supersense features alone allows us to
achieve an accuracy of 75%, i.e., adjective super-
sense features contribute 4% to adjective-noun su-
persense feature combination. Experiments with
the pairs of features yield better results than in-
dividual features, implying that the feature cate-
gories are not redundant. Yet, combining all fea-
tures leads to even higher accuracy during cross-
validation. In the case of the AN task, a difference
between the All feature combination and any other
combination of features listed in Table 2 is statis-
tically significant (p &lt; 0.01 for both the sign and
the permutation test).
Although the first experiment shows very high
scores, the 10-fold cross-validation cannot fully
reflect the generality of the model, because all
</bodyText>
<subsectionHeader confidence="0.6273005">
Tru Posiv Rate
Tru Posiv Rate
</subsectionHeader>
<bodyText confidence="0.992940352941177">
folds are parts of the same corpus. They are col-
lected by the same human judges and belong to the
same domain. Therefore, experiments on out-of-
domain data are crucial. We carry out such exper-
iments using held-out SVO and AN EN test sets,
described in Section 4.2 and Table 1. In this ex-
periment, we measure the f-score. We classify
SVO and AN relations using a classifier trained on
the All feature combination and balanced thresh-
olds. The values of the f-score are 0.76, both for
SVO and AN tasks. This out-of-domain experi-
ment suggests that our classifier is portable across
domains and genres.
However, (1) different application may have
different requirements for recall/precision, and (2)
classification results may be skewed towards hav-
ing high precision and low recall (or vice versa). It
is possible to trade precision for recall by choos-
ing a different threshold. Thus, in addition to
giving a single f-score value for balanced thresh-
olds, we present a Receiver Operator Characteris-
tic (ROC) curve, where we plot a fraction of true
positives against the fraction of false positives for
100 threshold values in the range from zero to one.
The area under the ROC curve (AUC) can be in-
terpreted as the probability that a classifier will as-
sign a higher score to a randomly chosen positive
example than to a randomly chosen negative ex-
ample.20 For a randomly guessing classifier, the
ROC curve is a dashed diagonal line. A bad classi-
20Assuming that positive examples are labeled by ones,
and negative examples are labeled by zeros.
fier has an ROC curve that goes close to the dashed
diagonal or even below it.
</bodyText>
<figure confidence="0.998313363636364">
1.0
0.8
0.6
0.4
Supersenses (area = 0.77)
AbsImg (area = 0.73)
VSM (area = 0.8)
All (area = 0.79)
0.00.0 0.2 0.4 0.6 0.8 1.0
False Positive Rate
(a) SVO
1.0
0.8
0.6
0.4
AbsImg (area = 0.9)
Supersenses (area = 0.86)
VSM (area = 0.89)
All (area = 0.92)
0.00.0 0.2 0.4 0.6 0.8 1.0
False Positive Rate
(b) AN
</figure>
<figureCaption confidence="0.992003538461538">
Figure 1: ROC curves for classifiers trained using
different feature sets (English SVO and AN test
sets).
According to ROC plots in Figure 1, all three
feature sets are effective, both for SVO and for
AN tasks. Abstractness and Imageability features
work better for adjectives and nouns, which is in
line with previous findings (Turney et al., 2011;
Broadwell et al., 2013). It can be also seen that
VSM features are very effective. This is in line
with results of Hovy et al. (2013), who found that
it is hard to improve over the classifier that uses
only VSM features.
</figureCaption>
<subsectionHeader confidence="0.999518">
5.2 Comparison to baselines
</subsectionHeader>
<bodyText confidence="0.997384">
In this section, we compare our method to state-of-
the-art methods of Tsvetkov et al. (2013) and of
Turney et al. (2011), who focused on classifying
SVO and AN relations, respectively.
In the case of SVO relations, we use software
</bodyText>
<figure confidence="0.9125455">
0.2
0.2
</figure>
<page confidence="0.998027">
253
</page>
<bodyText confidence="0.999836533333333">
and datasets from Tsvetkov et al. (2013). These
datasets, denoted as an SVO-baseline, consist of
98 English and 149 Russian sentences. We train
SVO metaphor detection tools on SVO relations
extracted from TroFi sentences and evaluate them
on the SVO-baseline dataset. We also use the same
thresholds for classifier posterior probabilities as
Tsvetkov et al. (2013). Our approach is different
from that of Tsvetkov et al. (2013) in that it uses
additional features (vector space word representa-
tions) and a different classification method (we use
random forests while Tsvetkov et al. (2013) use
logistic regression). According to Table 3, we ob-
tain higher performance scores for both Russian
and English.
</bodyText>
<sectionHeader confidence="0.557575" genericHeader="method">
EN RU
</sectionHeader>
<bodyText confidence="0.835964">
SVO-baseline 0.78 0.76
This work 0.86 0.85
</bodyText>
<tableCaption confidence="0.619624">
Table 3: Comparing f-scores of our SVO
metaphor detection method to the baselines.
</tableCaption>
<bodyText confidence="0.99982988">
In the case of AN relations, we use the dataset
(denoted as an AN-baseline) created by Turney
et al. (2011) (see Section 4.1 in the referred pa-
per for details). Turney et al. (2011) manu-
ally annotated 100 pairs where an adjective was
one of the following: dark, deep, hard, sweet,
and worm. The pairs were presented to five
human judges who rated each pair on a scale
from 1 (very literal/denotative) to 4 (very non-
literal/connotative). Turney et al. (2011) train
logistic-regression employing only abstractness
ratings as features. Performance of the method
was evaluated using the 10-fold cross-validation
separately for each judge.
We replicate the above described evaluation
procedure of Turney et al. (2011) using their
model and features. In our classifier, we use the
All feature combination and the balanced thresh-
old as described in Section 5.1.
According to results in Table 4, almost all of the
judge-specific f-scores are slightly higher for our
system, as well as the overall average f-score.
In both baseline comparisons, we obtain perfor-
mance at least as good as in previously published
studies.
</bodyText>
<subsectionHeader confidence="0.961395">
5.3 Cross-lingual experiments
</subsectionHeader>
<bodyText confidence="0.99904">
In the next experiment we corroborate the main
hypothesis of this paper: a model trained on En-
</bodyText>
<table confidence="0.997176285714286">
AN-baseline This work
Judge 1 0.73 0.75
Judge 2 0.81 0.84
Judge 3 0.84 0.88
Judge 4 0.79 0.81
Judge 5 0.78 0.77
average 0.79 0.81
</table>
<tableCaption confidence="0.994717">
Table 4: Comparing AN metaphor detection
</tableCaption>
<bodyText confidence="0.985041609756097">
method to the baselines: accuracy of the 10-
fold cross validation on annotations of five human
judges.
glish data can be successfully applied to other
languages. Namely, we use a trained English
model discussed in Section 5.1 to classify literal
and metaphoric SVO and AN relations in English,
Spanish, Farsi and Russian test sets, listed in Sec-
tion 4.2. This time we used all available features.
Experimental results for all four languages, are
given in Figure 2. The ROC curves for SVO and
AN tasks are plotted in Figure 2a and Figure 2b,
respectively. Each curve corresponds to a test set
described in Table 1. In addition, we perform an
oracle experiment, to obtain actual f-score values
for best thresholds. Detailed results are shown in
Table 5.
Consistent results with high f-scores are ob-
tained across all four languages. Note that higher
scores are obtained for the Russian test set. We hy-
pothesize that this happens due to a higher-quality
translation dictionary (which allows a more accu-
rate model transfer). Relatively lower (yet rea-
sonable) results for Farsi can be explained by a
smaller size of the bilingual dictionary (thus, fewer
feature projections can be obtained). Also note
that, in our experience, most of Farsi metaphors
are adjective-noun constructions. This is why the
AN FA dataset in Table 1 is significantly larger
than SVO FA. In that, for the AN Farsi task we
observe high performance scores.
Figure 2 and Table 5 confirm, that we ob-
tain similar, robust results on four very differ-
ent languages, using the same English classi-
fiers. We view this result as a strong evidence of
language-independent nature of our metaphor de-
tection method. In particular, this shows that pro-
posed conceptual features can be used to detect se-
lectional preferences violation across languages.
To summarize the experimental section, our
metaphor detection approach obtains state-of-the-
</bodyText>
<page confidence="0.996587">
254
</page>
<figure confidence="0.999473555555556">
1.0
0.8
0.6
0.4
0.2
0.00.0 0.2 0.4 0.6 0.8 1.0
False Positive Rate
(a) SVO
(b) AN
</figure>
<figureCaption confidence="0.9233972">
Figure 2: Cross-lingual experiment: ROC curves
for classifiers trained on the English data using a
combination of all features, and applied to SVO
and AN metaphoric and literal relations in four test
languages: English, Russian, Spanish, and Farsi.
</figureCaption>
<bodyText confidence="0.994096666666667">
art performance in English, is effective when ap-
plied to out-of-domain English data, and works
cross-lingually.
</bodyText>
<subsectionHeader confidence="0.985646">
5.4 Examples
</subsectionHeader>
<bodyText confidence="0.996861916666667">
Manual data analysis on adjective-noun pairs sup-
ports an abstractness-concreteness hypothesis for-
mulated by several independent research studies.
For example, in English we classify as metaphoric
dirty word and cloudy future. Word pairs dirty
diaper and cloudy weather have same adjectives.
Yet they are classified as literal. Indeed, diaper
is a more concrete term than word and weather
is more concrete than future. Same pattern is ob-
served in non-English datasets. In Russian, áîëü✲
íîå îáùåñòâî “sick society” and ïóñòîé çâóê
“empty sound” are classified as metaphoric, while
</bodyText>
<table confidence="0.9929898">
SVO AN
EN 0.79 0.85
RU 0.84 0.77
ES 0.76 0.72
FA 0.75 0.74
</table>
<tableCaption confidence="0.598201333333333">
Table 5: Cross-lingual experiment: f-scores for
classifiers trained on the English data using a com-
bination of all features, and applied, with optimal
thresholds, to SVO and AN metaphoric and literal
relations in four test languages: English, Russian,
Spanish, and Farsi.
</tableCaption>
<bodyText confidence="0.999486411764706">
áîëüíàÿ áàáóøêà “sick grandmother” and ïó✲
ñòàÿ ÷àøêà “empty cup” are classified as literal.
Spanish example of an adjective-noun metaphor
is a well-known m´usculo econ´omico “economic
muscle”. We also observe that non-metaphoric ad-
jective noun pairs tend to have more imageable ad-
jectives, such as literal derecho humano “human
right”. In Spanish, human is more imageable than
economic.
Verb-based examples that are correctly clas-
sified by our model are: blunder escaped no-
tice (metaphoric) and prisoner escaped jail (lit-
eral). We hypothesize that supersense features are
instrumental in the correct classification of these
examples: &lt;noun.person,verb.motion&gt; is usually
used literally, while &lt;noun.act,verb.motion&gt; is
used metaphorically.
</bodyText>
<sectionHeader confidence="0.999863" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999908368421053">
For a historic overview and a survey of
common approaches to metaphor detection,
we refer the reader to recent reviews by
Shutova et al. (Shutova, 2010; Shutova et al.,
2013). Here we focus only on recent approaches.
Shutova et al. (2010) proposed a bottom-up
method: one starts from a set of seed metaphors
and seeks phrases where verbs and/or nouns be-
long to the same cluster as verbs or nouns in seed
examples.
Turney et al. (2011) show how abstractness
scores could be used to detect metaphorical AN
phrases. Neuman et al. (2013) describe a Concrete
Category Overlap algorithm, where co-occurrence
statistics and Turney’s abstractness scores are used
to determine WordNet supersenses that corre-
spond to literal usage of a given adjective or verb.
For example, given an adjective, we can learn that
it modifies concrete nouns that usually have the
</bodyText>
<figure confidence="0.8950078">
EN (area = 0.79)
ES (area = 0.71)
FA (area = 0.69)
RU (area = 0.89)
False Positive Rate
0.8
0.6
0.4
0.00.0 0.2 0.4 0.6 0.8 1.0
0.2
1.0
EN (area = 0.92)
ES (area = 0.73)
FA (area = 0.83)
RU (area = 0.8)
</figure>
<page confidence="0.99686">
255
</page>
<bodyText confidence="0.999975333333333">
supersense noun.body. If this adjective modifies
a noun with the supersense noun.feeling, we con-
clude that a metaphor is found.
Broadwell et al. (2013) argue that metaphors
are highly imageable words that do not belong
to a discussion topic. To implement this idea,
they extend MRC imageability scores to all dic-
tionary words using links among WordNet super-
senses (mostly hypernym and hyponym relations).
Strzalkowski et al. (2013) carry out experiments
in a specific (government-related) domain for four
languages: English, Spanish, Farsi, and Russian.
Strzalkowski et al. (2013) explain the algorithm
only for English and say that is the same for Span-
ish, Farsi, and Russian. Because they heavily
rely on WordNet and availability of imageability
scores, their approach may not be applicable to
low-resource languages.
Hovy et al. (2013) applied tree kernels to
metaphor detection. Their method also employs
WordNet supersenses, but it is not clear from the
description whether WordNet is essential or can
be replaced with some other lexical resource. We
cannot compare directly our model with this work
because our classifier is restricted to detection of
only SVO and AN metaphors.
Tsvetkov et al. (2013) propose a cross-lingual
detection method that uses only English lexical re-
sources and a dependency parser. Their study fo-
cuses only on the verb-based metaphors. Tsvetkov
et al. (2013) employ only English and Russian
data. Current work builds on this study, and incor-
porates new syntactic relations as metaphor candi-
dates, adds several new feature sets and different,
more reliable datasets for evaluating results. We
demonstrate results on two new languages, Span-
ish and Farsi, to emphasize the generality of the
method.
A words sense disambiguation (WSD) is a re-
lated problem, where one identifies meanings of
polysemous words. The difference is that in the
WSD task, we need to select an already existing
sense, while for the metaphor detection, the goal
is to identify cases of sense borrowing. Studies
showed that cross-lingual evidence allows one to
achieve a state-of-the-art performance in the WSD
task, yet, most cross-lingual WSD methods em-
ploy parallel corpora (Navigli, 2009).
</bodyText>
<sectionHeader confidence="0.996429" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9999685">
The key contribution of our work is that we show
how to identify metaphors across languages by
building a model in English and applying it—
without adaptation—to other languages: Spanish,
Farsi, and Russian. This model uses language-
independent (rather than lexical or language spe-
cific) conceptual features. Not only do we estab-
lish benchmarks for Spanish, Farsi, and Russian,
but we also achieve state-of-the-art performance
in English. In addition, we present a comparison
of relative contributions of several types of fea-
tures. We concentrate on metaphors in the con-
text of two kinds of syntactic relations: subject-
verb-object (SVO) relations and adjective-noun
(AN) relations, which account for a majority of all
metaphorical phrases.
Future work will expand the scope of metaphor
identification by including nominal metaphoric re-
lations as well as explore techniques for incor-
porating contextual features, which can play a
key role in identifying certain kinds of metaphors.
Second, cross-lingual model transfer can be im-
proved with more careful cross-lingual feature
projection.
</bodyText>
<sectionHeader confidence="0.997237" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999439">
We are extremely grateful to Shuly Wintner for a
thorough review that helped us improve this draft;
we also thank people who helped in creating the
datasets and/or provided valuable feedback on this
work: Ed Hovy, Vlad Niculae, Davida Fromm,
Brian MacWhinney, Carlos Ramirez, and other
members of the CMU METAL team. This work
was supported by the U.S. Army Research Labo-
ratory and the U.S. Army Research Office under
contract/grant number W911NF-10-1-0533.
</bodyText>
<sectionHeader confidence="0.997911" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995550818181818">
Marco Baroni, Raffaella Bernardi, Ngoc-Quynh Do,
and Chung-chieh Shan. 2012. Entailment above the
word level in distributional semantics. In Proc. of
EACL, pages 23–32.
Julia Birke and Anoop Sarkar. 2007. Active learning
for the identification of nonliteral language. In Proc.
of the Workshop on Computational Approaches to
Figurative Language, FigLanguages ’07, pages 21–
28.
Leo Breiman. 2001. Random forests. Machine Learn-
ing, 45(1):5–32.
</reference>
<page confidence="0.989932">
256
</page>
<reference confidence="0.999834292452831">
George Aaron Broadwell, Umit Boz, Ignacio Cases,
Tomek Strzalkowski, Laurie Feldman, Sarah Taylor,
Samira Shaikh, Ting Liu, Kit Cho, and Nick Webb.
2013. Using imageability and topic chaining to lo-
cate metaphors in linguistic corpora. In Social Com-
puting, Behavioral-Cultural Modeling and Predic-
tion, pages 102–110. Springer.
Massimiliano Ciaramita and Yasemin Altun. 2006.
Broad-coverage sense disambiguation and informa-
tion extraction with a supersense sequence tagger. In
Proc. of EMNLP, pages 594–602.
Scott C. Deerwester, Susan T Dumais, Thomas K. Lan-
dauer, George W. Furnas, and Richard A. Harshman.
1990. Indexing by latent semantic analysis. JASIS,
41(6):391–407.
Manaal Faruqui and Chris Dyer. 2014. Improving
vector space word representations using multilingual
correlation. In Proc. of EACL. Association for Com-
putational Linguistics.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. Language, Speech and
Communication. MIT Press.
Lisa Gandy, Nadji Allan, Mark Atallah, Ophir Frieder,
Newton Howard, Sergey Kanareykin, Moshe Kop-
pel, Mark Last, Yair Neuman, and Shlomo Arga-
mon. 2013. Automatic identification of conceptual
metaphors with limited knowledge. In Proc. of the
Twenty-Seventh AAAI Conference on Artificial Intel-
ligence, pages 328–334.
Matt Gedigian, John Bryant, Srini Narayanan, and Bra-
nimir Ciric. 2006. Catching metaphors. In Pro-
ceedings of the 3rd Workshop on Scalable Natural
Language Understanding, pages 41–48.
Birgit Hamp and Helmut Feldweg. 1997. Germanet-
a lexical-semantic net for German. In Proc. of
ACL workshop Automatic Information Extraction
and Building of Lexical Semantic Resources for NLP
Applications, pages 9–15.
Dirk Hovy, Shashank Srivastava, Sujay Kumar Jauhar,
Mrinmaya Sachan, Kartik Goyal, Huiying Li, Whit-
ney Sanders, and Eduard Hovy. 2013. Identifying
metaphorical word use with tree kernels. In Proc. of
the First Workshop on Metaphor in NLP, page 52.
Eric H. Huang, Richard Socher, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Improving word
representations via global context and multiple word
prototypes. In Proc. of ACL, pages 873–882.
Franz Hundsnurscher and Jochen Splett. 1982. Se-
mantik der Adjektive des Deutschen. Number 3137.
Westdeutscher Verlag.
Mikhail Kozhenikov and Ivan Titov. 2013. Cross-
lingual transfer of semantic role labeling models. In
Proc. of ACL, pages 1190–1200.
Saisuresh Krishnakumaran and Xiaojin Zhu. 2007.
Hunting elusive metaphors using lexical resources.
In Proc. of the Workshop on Computational ap-
proaches to Figurative Language, pages 13–20.
George Lakoff and Mark Johnson. 1980. Conceptual
metaphor in everyday language. The Journal of Phi-
losophy, pages 453–486.
Lori Levin, Teruko Mitamura, Davida Fromm, Brian
MacWhinney, Jaime Carbonell, Weston Feely,
Robert Frederking, Anatole Gershman, and Carlos
Ramirez. 2014. Resources for the detection of con-
ventionalized metaphors in four languages. In Proc.
of LREC.
Andr´e F. T. Martins, Noah A. Smith, Eric P. Xing, Pe-
dro M. Q. Aguiar, and M´ario A. T. Figueiredo. 2010.
Turbo parsers: dependency parsing by approximate
variational inference. In Proc. of ENMLP, pages 34–
44.
Zachary J Mason. 2004. CorMet: a computational,
corpus-based conventional metaphor extraction sys-
tem. Computational Linguistics, 30(1):23–44.
Ryan McDonald, Slav Petrov, and Keith Hall. 2011.
Multi-source transfer of delexicalized dependency
parsers. In Proc. of EMNLP.
Tomas Mikolov, Quoc V. Le, and Ilya Sutskever. 2013.
Exploiting similarities among languages for Ma-
chine Translation. CoRR, abs/1309.4168.
Roberto Navigli. 2009. Word sense disambiguation:
A survey. ACM Comput. Surv., 41(2):10:1–10:69,
February.
Yair Neuman, Dan Assaf, Yohai Cohen, Mark Last,
Shlomo Argamon, Newton Howard, and Ophir
Frieder. 2013. Metaphor identification in large texts
corpora. PloS one, 8(4):e62343.
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,
B. Thirion, O. Grisel, M. Blondel, P. Pretten-
hofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Pas-
sos, D. Cournapeau, M. Brucher, M. Perrot, and
E. Duchesnay. 2011. Scikit-learn: Machine learn-
ing in Python. Journal of Machine Learning Re-
search, 12:2825–2830.
Claudia Perlich, Foster Provost, and Jeffrey S. Si-
monoff. 2003. Tree induction vs. logistic regres-
sion: a learning-curve analysis. Journal of Machine
Learning Research, 4:211–255.
Nathan Schneider, Behrang Mohit, Chris Dyer, Kemal
Oflazer, and Noah A Smith. 2013. Supersense tag-
ging for Arabic: the MT-in-the-middle attack. In
Proc. of NAACL-HLT, pages 661–667.
Ekaterina Shutova and Lin Sun. 2013. Unsupervised
metaphor identification using hierarchical graph fac-
torization clustering. In Proc. of NAACL-HLT,
pages 978–988.
</reference>
<page confidence="0.981044">
257
</page>
<table confidence="0.346728285714286">
Michael Wilson. 1988. MRC Psycholinguistic
Database: Machine-usable dictionary, version 2.00.
Behavior Research Methods, Instruments, &amp; Com-
puters, 20(1):6–10.
Ekaterina Shutova and Simone Teufel. 2010.
Metaphor corpus annotated for source-target domain
mappings. In Proc. of LREC, pages 3255–3261.
</table>
<reference confidence="0.999729958333333">
Ekaterina Shutova, Lin Sun, and Anna Korhonen.
2010. Metaphor identification using verb and noun
clustering. In Proc. of COLING, pages 1002–1010.
Ekaterina Shutova, Simone Teufel, and Anna Korho-
nen. 2013. Statistical metaphor processing. Com-
putational Linguistics, 39(2):301–353.
Ekaterina Shutova. 2010. Models of metaphor in NLP.
In Proc. of ACL, pages 688–697.
Gerard J Steen, Aletta G Dorst, J Berenike Her-
rmann, Anna A Kaal, and Tina Krennmayr.
2010. Metaphor in usage. Cognitive Linguistics,
21(4):765–796.
Tomek Strzalkowski, George Aaron Broadwell, Sarah
Taylor, Laurie Feldman, Boris Yamrom, Samira
Shaikh, Ting Liu, Kit Cho, Umit Boz, Ignacio Cases,
et al. 2013. Robust extraction of metaphors from
novel data. In Proc. of the First Workshop on
Metaphor in NLP, page 67.
Oscar T¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan
McDonald, and Joakim Nivre. 2013. Token and
type constraints for cross-lingual part-of-speech tag-
ging. TACL, 1:1–12.
Paul H Thibodeau and Lera Boroditsky. 2011.
Metaphors we think with: The role of metaphor in
reasoning. PLoS One, 6(2):e16782.
Yulia Tsvetkov, Elena Mukomel, and Anatole Gersh-
man. 2013. Cross-lingual metaphor detection using
common semantic features. In The 1st Workshop on
Metaphor in NLP 2013, page 45.
Yulia Tsvetkov, Nathan Schneider, Dirk Hovy, Archna
Bhatia, Manaal Faruqui, and Chris Dyer. 2014.
Augmenting English adjective senses with super-
senses. In Proc. of LREC.
Joseph Turian, Lev Ratinov, Yoshua Bengio, and Dan
Roth. 2009. A preliminary evaluation of word rep-
resentations for named-entity recognition. In NIPS
Workshop on Grammar Induction, Representation of
Language and Language Learning, pages 1–8.
Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning. In Proc. ofACL, pages
384–394.
Peter D. Turney, Yair Neuman, Dan Assaf, and Yohai
Cohen. 2011. Literal and metaphorical sense iden-
tification through concrete and abstract context. In
Proc. of EMNL, pages 680–690.
Yorick Wilks. 1978. Making preferences more active.
Artificial Intelligence, 11(3):197–223.
</reference>
<page confidence="0.996135">
258
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.266301">
<title confidence="0.627378">Metaphor Detection with Cross-Lingual Model Transfer Yulia Tsvetkov Leonid Boytsov Anatole Gershman Eric Nyberg Chris Language Technologies</title>
<affiliation confidence="0.982399">Carnegie Mellon</affiliation>
<address confidence="0.999281">Pittsburgh, PA 15213</address>
<email confidence="0.767684">srchvrs,anatoleg,ehn,</email>
<abstract confidence="0.999119352941176">We show that it is possible to reliably discriminate whether a syntactic construction is meant literally or metaphorically using lexical semantic features of the words that participate in the construction. Our model is constructed using English resources, and we obtain state-of-the-art performance relative to previous work in this language. Using a model transfer approach by pivoting through a bilingual dictionary, we show our model can identify metaphoric expressions in other languages. We provide results on three new test sets in Spanish, Farsi, and Russian. The results support the hypothesis that metaphors are conceptual, rather than lexical, in nature.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Raffaella Bernardi</author>
<author>Ngoc-Quynh Do</author>
<author>Chung-chieh Shan</author>
</authors>
<title>Entailment above the word level in distributional semantics.</title>
<date>2012</date>
<booktitle>In Proc. of EACL,</booktitle>
<pages>23--32</pages>
<contexts>
<context position="10188" citStr="Baroni et al., 2012" startWordPosition="1541" endWordPosition="1544">ed in translation (Schneider et al., 2013), which makes supersense features suitable for cross-lingual approaches such as ours. • Vector space word representations. Vector space word representations learned using unsupervised algorithms are often effective features in supervised learning methods (Turian et al., 2010). In particular, many such representations are designed to capture lexical semantic properties and are quite effective features in semantic processing, including named entity recognition (Turian et al., 2009), word sense disambiguation (Huang et al., 2012), and lexical entailment (Baroni et al., 2012). In a recent study, Mikolov et al. (2013) reveal an interesting cross-lingual property of distributed word representations: there is a strong similarity between the vector spaces across languages that can be easily captured by linear mapping. Thus, vector space models can also be seen as vectors of (latent) semantic concepts, that preserve their “meaning” across languages. 3 Model and Feature Extraction In this section we describe a classification model, and provide details on mono- and cross-lingual implementation of features. 3.1 Classification using Random Forests To make classification de</context>
</contexts>
<marker>Baroni, Bernardi, Do, Shan, 2012</marker>
<rawString>Marco Baroni, Raffaella Bernardi, Ngoc-Quynh Do, and Chung-chieh Shan. 2012. Entailment above the word level in distributional semantics. In Proc. of EACL, pages 23–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Birke</author>
<author>Anoop Sarkar</author>
</authors>
<title>Active learning for the identification of nonliteral language.</title>
<date>2007</date>
<booktitle>In Proc. of the Workshop on Computational Approaches to Figurative Language, FigLanguages ’07,</booktitle>
<pages>21--28</pages>
<contexts>
<context position="2919" citStr="Birke and Sarkar, 2007" startWordPosition="439" endWordPosition="442">etaphor detection is a hard problem. On one hand, there is a subjective component: humans may disagree whether a particular expression is used metaphorically or not, as there is no clear-cut semantic distinction between figurative and metaphorical language (Shutova, 2010). On the other, metaphors can be domain- and contextdependent.1 Previous work has focused on metaphor identification in English, using both extensive manuallycreated linguistic resources (Mason, 2004; Gedigian et al., 2006; Krishnakumaran and Zhu, 2007; Turney et al., 2011; Broadwell et al., 2013) and corpus-based approaches (Birke and Sarkar, 2007; Shutova et al., 2013; Neuman et al., 2013; Shutova and Sun, 2013; Hovy et al., 2013). We build on this foundation and also extend metaphor detection into other languages in which few resources may exist. Our work makes the following contributions: (1) we develop a new state-of-the-art English metaphor detection system that uses conceptual semantic features, such as a degree of abstractness and semantic supersenses;2 (2) we create new metaphor-annotated corpora for Russian and English;3 (3) using a paradigm of model transfer (McDonald et al., 2011; T¨ackstr¨om et al., 2013; Kozhenikov and Tit</context>
<context position="16637" citStr="Birke and Sarkar, 2007" startWordPosition="2487" endWordPosition="2490"> word ro.Iosa is translated as head and brain. Hence, we select all the synsets of the nouns head and brain. There are 38 such synsets (33 for head and 5 for brain). Four of these synsets are associated with the supersense noun.body. Therefore, the value of the feature noun.body is 4/38 ≈ 0.11. 4 Datasets In this section we describe a training and testing dataset as well a data collection procedure. 4.1 English training sets To train an SVO metaphor classifier, we employ the TroFi (Trope Finder) dataset.17 TroFi includes 3,737 manually annotated English sentences from the Wall Street Journal (Birke and Sarkar, 2007). Each sentence contains either literal or metaphorical use for one of 50 English verbs. First, we use a dependency parser (Martins et al., 2010) to extract subject-verb-object (SVO) relations. Then, we filter extracted relations to eliminate parsing-related errors, and relations with verbs which are not in the TroFi verb list. After filtering, there are 953 metaphorical and 656 literal SVO relations which we use as a training set. In the case of AN relations, we construct and make publicly available a training set containing 884 metaphorical AN pairs and 884 pairs with literal meaning. It was</context>
</contexts>
<marker>Birke, Sarkar, 2007</marker>
<rawString>Julia Birke and Anoop Sarkar. 2007. Active learning for the identification of nonliteral language. In Proc. of the Workshop on Computational Approaches to Figurative Language, FigLanguages ’07, pages 21– 28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leo Breiman</author>
</authors>
<title>Random forests.</title>
<date>2001</date>
<booktitle>Machine Learning,</booktitle>
<volume>45</volume>
<issue>1</issue>
<contexts>
<context position="10846" citStr="Breiman, 2001" startWordPosition="1641" endWordPosition="1642">eveal an interesting cross-lingual property of distributed word representations: there is a strong similarity between the vector spaces across languages that can be easily captured by linear mapping. Thus, vector space models can also be seen as vectors of (latent) semantic concepts, that preserve their “meaning” across languages. 3 Model and Feature Extraction In this section we describe a classification model, and provide details on mono- and cross-lingual implementation of features. 3.1 Classification using Random Forests To make classification decisions, we use a random forest classifier (Breiman, 2001), an ensemble of decision tree classifiers learned from many independent subsamples of the training data. Given an input, each tree classifier assigns a probability to each label; those probabilities are averaged to compute the probability distribution across the ensemble. Random forest ensembles are particularly suitable for our resource-scarce scenario: rather than overfitting, they produce a limiting value of the generalization error as the number of trees increases,8 and no hyperparameter tuning is required. In addition, decision-tree classifiers learn non-linear responses to inputs and of</context>
<context position="12886" citStr="Breiman, 2001" startWordPosition="1938" endWordPosition="1939">to all words for which we have vector space representations. More specifically, we calculate the degree of abstractness and imageability of all English items that have a vector space representation, using vector elements as features. We train two separate classifiers for abstractness and imageability on a seed set of words from the MRC database. Degrees of abstractness and imageability are posterior probabilities of classifier predictions. We binarize these posteriors into abstractconcrete (or imageable-unimageable) boolean indicators using pre-defined thresholds.11 Perfor8See Theorem 1.2 in (Breiman, 2001) for details. 9In our experiments, random forests model slightly outperformed logistic regression and SVM classifiers. 10http://ota.oucs.ox.ac.uk/headers/ 1054.xml 11Thresholds are equal to 0.8 for abstractness and to 0.9 for imageability. They were chosen empirically based on ac250 mance of these classifiers, tested on a sampled held-out data, is 0.94 and 0.85 for the abstractness and imageability classifiers, respectively. Supersenses. In the case of SVO relations, we incorporate supersense features for nouns and verbs; noun and adjective supersenses are used in the case of AN relations. Sup</context>
</contexts>
<marker>Breiman, 2001</marker>
<rawString>Leo Breiman. 2001. Random forests. Machine Learning, 45(1):5–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Aaron Broadwell</author>
<author>Umit Boz</author>
<author>Ignacio Cases</author>
<author>Tomek Strzalkowski</author>
<author>Laurie Feldman</author>
<author>Sarah Taylor</author>
<author>Samira Shaikh</author>
<author>Ting Liu</author>
<author>Kit Cho</author>
<author>Nick Webb</author>
</authors>
<title>Using imageability and topic chaining to locate metaphors in linguistic corpora.</title>
<date>2013</date>
<booktitle>In Social Computing, Behavioral-Cultural Modeling and Prediction,</booktitle>
<pages>102--110</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="2867" citStr="Broadwell et al., 2013" startWordPosition="432" endWordPosition="435"> easily at a larger scale with automation. However, metaphor detection is a hard problem. On one hand, there is a subjective component: humans may disagree whether a particular expression is used metaphorically or not, as there is no clear-cut semantic distinction between figurative and metaphorical language (Shutova, 2010). On the other, metaphors can be domain- and contextdependent.1 Previous work has focused on metaphor identification in English, using both extensive manuallycreated linguistic resources (Mason, 2004; Gedigian et al., 2006; Krishnakumaran and Zhu, 2007; Turney et al., 2011; Broadwell et al., 2013) and corpus-based approaches (Birke and Sarkar, 2007; Shutova et al., 2013; Neuman et al., 2013; Shutova and Sun, 2013; Hovy et al., 2013). We build on this foundation and also extend metaphor detection into other languages in which few resources may exist. Our work makes the following contributions: (1) we develop a new state-of-the-art English metaphor detection system that uses conceptual semantic features, such as a degree of abstractness and semantic supersenses;2 (2) we create new metaphor-annotated corpora for Russian and English;3 (3) using a paradigm of model transfer (McDonald et al.</context>
<context position="7369" citStr="Broadwell et al., 2013" startWordPosition="1122" endWordPosition="1126">pute all the features for the individual words car, drink, gasoline and combine them with the conjunction features for the pairs car drink and drink gasoline. We define three main feature categories (1) abstractness and imageability, (2) supersenses, (3) unsupervised vector-space word representations; each category corresponds to a group of features with a common theme and representation. • Abstractness and imageability. Abstractness and imageability were shown to be useful in detection of metaphors (it is easier to invoke mental pictures of concrete and imageable words) (Turney et al., 2011; Broadwell et al., 2013). We expect that abstractness, used in conjunction features (e.g., a feature denoting that the subject is abstract and the verb is concrete), is especially useful: semantically, an abstract agent performing a concrete action is a strong signal of metaphorical usage. Although often correlated with abstractness, imageability is not a redundant property. While most abstract things are hard to visualize, some call up images, e.g., vengeance calls up an emotional image, torture calls up emotions and even visual images. There are concrete things that are hard to visualize too, for example, abbey is </context>
<context position="24854" citStr="Broadwell et al., 2013" startWordPosition="3842" endWordPosition="3845">= 0.73) VSM (area = 0.8) All (area = 0.79) 0.00.0 0.2 0.4 0.6 0.8 1.0 False Positive Rate (a) SVO 1.0 0.8 0.6 0.4 AbsImg (area = 0.9) Supersenses (area = 0.86) VSM (area = 0.89) All (area = 0.92) 0.00.0 0.2 0.4 0.6 0.8 1.0 False Positive Rate (b) AN Figure 1: ROC curves for classifiers trained using different feature sets (English SVO and AN test sets). According to ROC plots in Figure 1, all three feature sets are effective, both for SVO and for AN tasks. Abstractness and Imageability features work better for adjectives and nouns, which is in line with previous findings (Turney et al., 2011; Broadwell et al., 2013). It can be also seen that VSM features are very effective. This is in line with results of Hovy et al. (2013), who found that it is hard to improve over the classifier that uses only VSM features. 5.2 Comparison to baselines In this section, we compare our method to state-ofthe-art methods of Tsvetkov et al. (2013) and of Turney et al. (2011), who focused on classifying SVO and AN relations, respectively. In the case of SVO relations, we use software 0.2 0.2 253 and datasets from Tsvetkov et al. (2013). These datasets, denoted as an SVO-baseline, consist of 98 English and 149 Russian sentence</context>
<context position="32794" citStr="Broadwell et al. (2013)" startWordPosition="5139" endWordPosition="5142">re co-occurrence statistics and Turney’s abstractness scores are used to determine WordNet supersenses that correspond to literal usage of a given adjective or verb. For example, given an adjective, we can learn that it modifies concrete nouns that usually have the EN (area = 0.79) ES (area = 0.71) FA (area = 0.69) RU (area = 0.89) False Positive Rate 0.8 0.6 0.4 0.00.0 0.2 0.4 0.6 0.8 1.0 0.2 1.0 EN (area = 0.92) ES (area = 0.73) FA (area = 0.83) RU (area = 0.8) 255 supersense noun.body. If this adjective modifies a noun with the supersense noun.feeling, we conclude that a metaphor is found. Broadwell et al. (2013) argue that metaphors are highly imageable words that do not belong to a discussion topic. To implement this idea, they extend MRC imageability scores to all dictionary words using links among WordNet supersenses (mostly hypernym and hyponym relations). Strzalkowski et al. (2013) carry out experiments in a specific (government-related) domain for four languages: English, Spanish, Farsi, and Russian. Strzalkowski et al. (2013) explain the algorithm only for English and say that is the same for Spanish, Farsi, and Russian. Because they heavily rely on WordNet and availability of imageability sco</context>
</contexts>
<marker>Broadwell, Boz, Cases, Strzalkowski, Feldman, Taylor, Shaikh, Liu, Cho, Webb, 2013</marker>
<rawString>George Aaron Broadwell, Umit Boz, Ignacio Cases, Tomek Strzalkowski, Laurie Feldman, Sarah Taylor, Samira Shaikh, Ting Liu, Kit Cho, and Nick Webb. 2013. Using imageability and topic chaining to locate metaphors in linguistic corpora. In Social Computing, Behavioral-Cultural Modeling and Prediction, pages 102–110. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimiliano Ciaramita</author>
<author>Yasemin Altun</author>
</authors>
<title>Broad-coverage sense disambiguation and information extraction with a supersense sequence tagger.</title>
<date>2006</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>594--602</pages>
<contexts>
<context position="8830" citStr="Ciaramita and Altun, 2006" startWordPosition="1342" endWordPosition="1345">ample, 5Looking at components of the syntactic constructions independent of their context has its limitations, as discussed above with the drowning students example; however, it simplifies the representation challenges considerably. 6If word one is represented by features u ∈ R&apos; and word two by features v ∈ R&apos; then the conjunction feature vector is the vectorization of the outer product uvT. 7Supersenses are called “lexicographer classes” in WordNet documentation (Fellbaum, 1998), http://wordnet. princeton.edu/man/lexnames.5WN.html 249 noun.body, noun.animal, verb.consumption, or verb.motion (Ciaramita and Altun, 2006). English adjectives do not, as yet, have a similar high-level semantic partitioning in WordNet, thus we use a 13-class taxonomy of adjective supersenses constructed by Tsvetkov et al. (2014) (discussed in §3.2). Supersenses are particularly attractive features for metaphor detection: coarse sense taxonomies can be viewed as semantic concepts, and since concept mapping is a process in which metaphors are born, we expect different supersense co-occurrences in metaphoric and literal combinations. In “drinks gasoline”, for example, mapping to supersenses would yield a pair &lt;verb.consumption, noun</context>
</contexts>
<marker>Ciaramita, Altun, 2006</marker>
<rawString>Massimiliano Ciaramita and Yasemin Altun. 2006. Broad-coverage sense disambiguation and information extraction with a supersense sequence tagger. In Proc. of EMNLP, pages 594–602.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott C Deerwester</author>
<author>Susan T Dumais</author>
<author>Thomas K Landauer</author>
<author>George W Furnas</author>
<author>Richard A Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>JASIS,</journal>
<volume>41</volume>
<issue>6</issue>
<contexts>
<context position="15072" citStr="Deerwester et al., 1990" startWordPosition="2261" endWordPosition="2264">tive type in WordNet, they produce a vector with a classifier posterior probabilities corresponding to degrees of membership of this word in one of the 13 semantic classes,13 similar to the feature vectors we build for nouns and verbs. For example, for a word calm the top-2 categories (with the first and second highest degrees of membership) are adj.behavior and adj.feeling. Vector space word representations. We employ 64-dimensional vector-space word representations constructed by Faruqui and Dyer (2014).14 Vector construction algorithm is a variation on traditional latent semantic analysis (Deerwester et al., 1990) that uses multilingual information to produce representations in which synonymous words have similar vectors. The vectors were curacy during cross-validation. 12For the full taxonomy see http://www.sfs. uni-tuebingen.de/lsd/adjectives.shtml 13http://www.cs.cmu.edu/˜ytsvetko/ adj-supersenses.tar.gz 14http://www.cs.cmu.edu/˜mfaruqui/soft. html trained on the news commentary corpus released by WMT-2011,15 comprising 180,834 types. 3.3 Cross-lingual feature projection For languages other than English, feature vectors are projected to English features using translation dictionaries. We used the Ba</context>
</contexts>
<marker>Deerwester, Dumais, Landauer, Furnas, Harshman, 1990</marker>
<rawString>Scott C. Deerwester, Susan T Dumais, Thomas K. Landauer, George W. Furnas, and Richard A. Harshman. 1990. Indexing by latent semantic analysis. JASIS, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manaal Faruqui</author>
<author>Chris Dyer</author>
</authors>
<title>Improving vector space word representations using multilingual correlation.</title>
<date>2014</date>
<booktitle>In Proc. of EACL. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="14958" citStr="Faruqui and Dyer (2014)" startWordPosition="2246" endWordPosition="2249">ant, cheerful); adj.substance (e.g., dry, ripe, creamy); adj.spatial (e.g., adjacent, gigantic).12 For each adjective type in WordNet, they produce a vector with a classifier posterior probabilities corresponding to degrees of membership of this word in one of the 13 semantic classes,13 similar to the feature vectors we build for nouns and verbs. For example, for a word calm the top-2 categories (with the first and second highest degrees of membership) are adj.behavior and adj.feeling. Vector space word representations. We employ 64-dimensional vector-space word representations constructed by Faruqui and Dyer (2014).14 Vector construction algorithm is a variation on traditional latent semantic analysis (Deerwester et al., 1990) that uses multilingual information to produce representations in which synonymous words have similar vectors. The vectors were curacy during cross-validation. 12For the full taxonomy see http://www.sfs. uni-tuebingen.de/lsd/adjectives.shtml 13http://www.cs.cmu.edu/˜ytsvetko/ adj-supersenses.tar.gz 14http://www.cs.cmu.edu/˜mfaruqui/soft. html trained on the news commentary corpus released by WMT-2011,15 comprising 180,834 types. 3.3 Cross-lingual feature projection For languages ot</context>
</contexts>
<marker>Faruqui, Dyer, 2014</marker>
<rawString>Manaal Faruqui and Chris Dyer. 2014. Improving vector space word representations using multilingual correlation. In Proc. of EACL. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database. Language, Speech and Communication.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. Language, Speech and Communication. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lisa Gandy</author>
<author>Nadji Allan</author>
<author>Mark Atallah</author>
<author>Ophir Frieder</author>
<author>Newton Howard</author>
<author>Sergey Kanareykin</author>
<author>Moshe Koppel</author>
<author>Mark Last</author>
<author>Yair Neuman</author>
<author>Shlomo Argamon</author>
</authors>
<title>Automatic identification of conceptual metaphors with limited knowledge.</title>
<date>2013</date>
<booktitle>In Proc. of the Twenty-Seventh AAAI Conference on Artificial Intelligence,</booktitle>
<pages>328--334</pages>
<contexts>
<context position="6369" citStr="Gandy et al., 2013" startWordPosition="965" endWordPosition="968">anguageinvariant representation suitable for metaphor detection. To test this hypothesis, we use a crosslingual model transfer approach: we use bilingual dictionaries to project words from other syntactic constructions found in other languages into English and then apply the English model on the derived conceptual representations. 4Our decision to focus on SVO and AN metaphors is justified by corpus studies that estimate that verb- and adjectivebased metaphors account for a substantial proportion of all metaphoric expressions, approximately 60% and 24%, respectively (Shutova and Teufel, 2010; Gandy et al., 2013). Each SVO (or AN) instance will be represented by a triple (duple) from which a feature vector will be extracted.5 The vector will consist of the concatenation of the conceptual features (which we discuss below) for all participating words, and conjunction features for word pairs.6 For example, to generate the feature vector for the SVO triple (car, drink, gasoline), we compute all the features for the individual words car, drink, gasoline and combine them with the conjunction features for the pairs car drink and drink gasoline. We define three main feature categories (1) abstractness and ima</context>
</contexts>
<marker>Gandy, Allan, Atallah, Frieder, Howard, Kanareykin, Koppel, Last, Neuman, Argamon, 2013</marker>
<rawString>Lisa Gandy, Nadji Allan, Mark Atallah, Ophir Frieder, Newton Howard, Sergey Kanareykin, Moshe Koppel, Mark Last, Yair Neuman, and Shlomo Argamon. 2013. Automatic identification of conceptual metaphors with limited knowledge. In Proc. of the Twenty-Seventh AAAI Conference on Artificial Intelligence, pages 328–334.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Gedigian</author>
<author>John Bryant</author>
<author>Srini Narayanan</author>
<author>Branimir Ciric</author>
</authors>
<title>Catching metaphors.</title>
<date>2006</date>
<booktitle>In Proceedings of the 3rd Workshop on Scalable Natural Language Understanding,</booktitle>
<pages>41--48</pages>
<contexts>
<context position="2791" citStr="Gedigian et al., 2006" startWordPosition="419" endWordPosition="423">cond, scientific hypotheses about metaphoric language could be tested more easily at a larger scale with automation. However, metaphor detection is a hard problem. On one hand, there is a subjective component: humans may disagree whether a particular expression is used metaphorically or not, as there is no clear-cut semantic distinction between figurative and metaphorical language (Shutova, 2010). On the other, metaphors can be domain- and contextdependent.1 Previous work has focused on metaphor identification in English, using both extensive manuallycreated linguistic resources (Mason, 2004; Gedigian et al., 2006; Krishnakumaran and Zhu, 2007; Turney et al., 2011; Broadwell et al., 2013) and corpus-based approaches (Birke and Sarkar, 2007; Shutova et al., 2013; Neuman et al., 2013; Shutova and Sun, 2013; Hovy et al., 2013). We build on this foundation and also extend metaphor detection into other languages in which few resources may exist. Our work makes the following contributions: (1) we develop a new state-of-the-art English metaphor detection system that uses conceptual semantic features, such as a degree of abstractness and semantic supersenses;2 (2) we create new metaphor-annotated corpora for R</context>
</contexts>
<marker>Gedigian, Bryant, Narayanan, Ciric, 2006</marker>
<rawString>Matt Gedigian, John Bryant, Srini Narayanan, and Branimir Ciric. 2006. Catching metaphors. In Proceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 41–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Birgit Hamp</author>
<author>Helmut Feldweg</author>
</authors>
<title>Germaneta lexical-semantic net for German.</title>
<date>1997</date>
<booktitle>In Proc. of ACL workshop Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications,</booktitle>
<pages>9--15</pages>
<contexts>
<context position="14244" citStr="Hamp and Feldweg, 1997" startWordPosition="2141" endWordPosition="2144">membership in different supersenses are represented by feature vectors, where each element corresponds to one supersense. For example, the word head (when used as a noun) participates in 33 synsets, three of which are related to the supersense noun.body. The value of the feature corresponding to this supersense is 3/33 ≈ 0.09. Supersenses of adjectives. WordNet lacks coarse-grained semantic categories for adjectives. To divide adjectives into groups, Tsvetkov et al. (2014) use 13 top-level classes from the adapted taxonomy of Hundsnurscher and Splett (1982), which is incorporated in GermaNet (Hamp and Feldweg, 1997). For example, the top-level classes in GermaNet include: adj.feeling (e.g., willing, pleasant, cheerful); adj.substance (e.g., dry, ripe, creamy); adj.spatial (e.g., adjacent, gigantic).12 For each adjective type in WordNet, they produce a vector with a classifier posterior probabilities corresponding to degrees of membership of this word in one of the 13 semantic classes,13 similar to the feature vectors we build for nouns and verbs. For example, for a word calm the top-2 categories (with the first and second highest degrees of membership) are adj.behavior and adj.feeling. Vector space word </context>
</contexts>
<marker>Hamp, Feldweg, 1997</marker>
<rawString>Birgit Hamp and Helmut Feldweg. 1997. Germaneta lexical-semantic net for German. In Proc. of ACL workshop Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications, pages 9–15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dirk Hovy</author>
<author>Shashank Srivastava</author>
<author>Sujay Kumar Jauhar</author>
<author>Mrinmaya Sachan</author>
<author>Kartik Goyal</author>
<author>Huiying Li</author>
<author>Whitney Sanders</author>
<author>Eduard Hovy</author>
</authors>
<title>Identifying metaphorical word use with tree kernels.</title>
<date>2013</date>
<booktitle>In Proc. of the First Workshop on Metaphor in NLP,</booktitle>
<pages>52</pages>
<contexts>
<context position="3005" citStr="Hovy et al., 2013" startWordPosition="455" endWordPosition="458">may disagree whether a particular expression is used metaphorically or not, as there is no clear-cut semantic distinction between figurative and metaphorical language (Shutova, 2010). On the other, metaphors can be domain- and contextdependent.1 Previous work has focused on metaphor identification in English, using both extensive manuallycreated linguistic resources (Mason, 2004; Gedigian et al., 2006; Krishnakumaran and Zhu, 2007; Turney et al., 2011; Broadwell et al., 2013) and corpus-based approaches (Birke and Sarkar, 2007; Shutova et al., 2013; Neuman et al., 2013; Shutova and Sun, 2013; Hovy et al., 2013). We build on this foundation and also extend metaphor detection into other languages in which few resources may exist. Our work makes the following contributions: (1) we develop a new state-of-the-art English metaphor detection system that uses conceptual semantic features, such as a degree of abstractness and semantic supersenses;2 (2) we create new metaphor-annotated corpora for Russian and English;3 (3) using a paradigm of model transfer (McDonald et al., 2011; T¨ackstr¨om et al., 2013; Kozhenikov and Titov, 2013), we provide support for the hypothesis that metaphors are concep1For example</context>
<context position="24964" citStr="Hovy et al. (2013)" startWordPosition="3864" endWordPosition="3867">bsImg (area = 0.9) Supersenses (area = 0.86) VSM (area = 0.89) All (area = 0.92) 0.00.0 0.2 0.4 0.6 0.8 1.0 False Positive Rate (b) AN Figure 1: ROC curves for classifiers trained using different feature sets (English SVO and AN test sets). According to ROC plots in Figure 1, all three feature sets are effective, both for SVO and for AN tasks. Abstractness and Imageability features work better for adjectives and nouns, which is in line with previous findings (Turney et al., 2011; Broadwell et al., 2013). It can be also seen that VSM features are very effective. This is in line with results of Hovy et al. (2013), who found that it is hard to improve over the classifier that uses only VSM features. 5.2 Comparison to baselines In this section, we compare our method to state-ofthe-art methods of Tsvetkov et al. (2013) and of Turney et al. (2011), who focused on classifying SVO and AN relations, respectively. In the case of SVO relations, we use software 0.2 0.2 253 and datasets from Tsvetkov et al. (2013). These datasets, denoted as an SVO-baseline, consist of 98 English and 149 Russian sentences. We train SVO metaphor detection tools on SVO relations extracted from TroFi sentences and evaluate them on </context>
<context position="33481" citStr="Hovy et al. (2013)" startWordPosition="5245" endWordPosition="5248">o a discussion topic. To implement this idea, they extend MRC imageability scores to all dictionary words using links among WordNet supersenses (mostly hypernym and hyponym relations). Strzalkowski et al. (2013) carry out experiments in a specific (government-related) domain for four languages: English, Spanish, Farsi, and Russian. Strzalkowski et al. (2013) explain the algorithm only for English and say that is the same for Spanish, Farsi, and Russian. Because they heavily rely on WordNet and availability of imageability scores, their approach may not be applicable to low-resource languages. Hovy et al. (2013) applied tree kernels to metaphor detection. Their method also employs WordNet supersenses, but it is not clear from the description whether WordNet is essential or can be replaced with some other lexical resource. We cannot compare directly our model with this work because our classifier is restricted to detection of only SVO and AN metaphors. Tsvetkov et al. (2013) propose a cross-lingual detection method that uses only English lexical resources and a dependency parser. Their study focuses only on the verb-based metaphors. Tsvetkov et al. (2013) employ only English and Russian data. Current </context>
</contexts>
<marker>Hovy, Srivastava, Jauhar, Sachan, Goyal, Li, Sanders, Hovy, 2013</marker>
<rawString>Dirk Hovy, Shashank Srivastava, Sujay Kumar Jauhar, Mrinmaya Sachan, Kartik Goyal, Huiying Li, Whitney Sanders, and Eduard Hovy. 2013. Identifying metaphorical word use with tree kernels. In Proc. of the First Workshop on Metaphor in NLP, page 52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric H Huang</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Improving word representations via global context and multiple word prototypes.</title>
<date>2012</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>873--882</pages>
<contexts>
<context position="10142" citStr="Huang et al., 2012" startWordPosition="1534" endWordPosition="1537">his coarse semantic categorization is preserved in translation (Schneider et al., 2013), which makes supersense features suitable for cross-lingual approaches such as ours. • Vector space word representations. Vector space word representations learned using unsupervised algorithms are often effective features in supervised learning methods (Turian et al., 2010). In particular, many such representations are designed to capture lexical semantic properties and are quite effective features in semantic processing, including named entity recognition (Turian et al., 2009), word sense disambiguation (Huang et al., 2012), and lexical entailment (Baroni et al., 2012). In a recent study, Mikolov et al. (2013) reveal an interesting cross-lingual property of distributed word representations: there is a strong similarity between the vector spaces across languages that can be easily captured by linear mapping. Thus, vector space models can also be seen as vectors of (latent) semantic concepts, that preserve their “meaning” across languages. 3 Model and Feature Extraction In this section we describe a classification model, and provide details on mono- and cross-lingual implementation of features. 3.1 Classification </context>
</contexts>
<marker>Huang, Socher, Manning, Ng, 2012</marker>
<rawString>Eric H. Huang, Richard Socher, Christopher D. Manning, and Andrew Y. Ng. 2012. Improving word representations via global context and multiple word prototypes. In Proc. of ACL, pages 873–882.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Hundsnurscher</author>
<author>Jochen Splett</author>
</authors>
<date>1982</date>
<booktitle>Semantik der Adjektive des Deutschen. Number 3137. Westdeutscher Verlag.</booktitle>
<contexts>
<context position="14184" citStr="Hundsnurscher and Splett (1982)" startWordPosition="2132" endWordPosition="2135">ynsets, which are associated with different supersenses. Degrees of membership in different supersenses are represented by feature vectors, where each element corresponds to one supersense. For example, the word head (when used as a noun) participates in 33 synsets, three of which are related to the supersense noun.body. The value of the feature corresponding to this supersense is 3/33 ≈ 0.09. Supersenses of adjectives. WordNet lacks coarse-grained semantic categories for adjectives. To divide adjectives into groups, Tsvetkov et al. (2014) use 13 top-level classes from the adapted taxonomy of Hundsnurscher and Splett (1982), which is incorporated in GermaNet (Hamp and Feldweg, 1997). For example, the top-level classes in GermaNet include: adj.feeling (e.g., willing, pleasant, cheerful); adj.substance (e.g., dry, ripe, creamy); adj.spatial (e.g., adjacent, gigantic).12 For each adjective type in WordNet, they produce a vector with a classifier posterior probabilities corresponding to degrees of membership of this word in one of the 13 semantic classes,13 similar to the feature vectors we build for nouns and verbs. For example, for a word calm the top-2 categories (with the first and second highest degrees of memb</context>
</contexts>
<marker>Hundsnurscher, Splett, 1982</marker>
<rawString>Franz Hundsnurscher and Jochen Splett. 1982. Semantik der Adjektive des Deutschen. Number 3137. Westdeutscher Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikhail Kozhenikov</author>
<author>Ivan Titov</author>
</authors>
<title>Crosslingual transfer of semantic role labeling models.</title>
<date>2013</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>1190--1200</pages>
<contexts>
<context position="3528" citStr="Kozhenikov and Titov, 2013" startWordPosition="539" endWordPosition="542">e and Sarkar, 2007; Shutova et al., 2013; Neuman et al., 2013; Shutova and Sun, 2013; Hovy et al., 2013). We build on this foundation and also extend metaphor detection into other languages in which few resources may exist. Our work makes the following contributions: (1) we develop a new state-of-the-art English metaphor detection system that uses conceptual semantic features, such as a degree of abstractness and semantic supersenses;2 (2) we create new metaphor-annotated corpora for Russian and English;3 (3) using a paradigm of model transfer (McDonald et al., 2011; T¨ackstr¨om et al., 2013; Kozhenikov and Titov, 2013), we provide support for the hypothesis that metaphors are concep1For example, drowning students could be used metaphorically to describe the situation where students are overwhelmed with work, but in the sentence a lifeguard saved drowning students, this phrase is used literally. 2https://github.com/ytsvetko/metaphor 3http://www.cs.cmu.edu/˜ytsvetko/ metaphor/datasets.zip 248 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 248–258, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics tual (rather than lexica</context>
</contexts>
<marker>Kozhenikov, Titov, 2013</marker>
<rawString>Mikhail Kozhenikov and Ivan Titov. 2013. Crosslingual transfer of semantic role labeling models. In Proc. of ACL, pages 1190–1200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saisuresh Krishnakumaran</author>
<author>Xiaojin Zhu</author>
</authors>
<title>Hunting elusive metaphors using lexical resources.</title>
<date>2007</date>
<booktitle>In Proc. of the Workshop on Computational approaches to Figurative Language,</booktitle>
<pages>13--20</pages>
<contexts>
<context position="2821" citStr="Krishnakumaran and Zhu, 2007" startWordPosition="424" endWordPosition="427">eses about metaphoric language could be tested more easily at a larger scale with automation. However, metaphor detection is a hard problem. On one hand, there is a subjective component: humans may disagree whether a particular expression is used metaphorically or not, as there is no clear-cut semantic distinction between figurative and metaphorical language (Shutova, 2010). On the other, metaphors can be domain- and contextdependent.1 Previous work has focused on metaphor identification in English, using both extensive manuallycreated linguistic resources (Mason, 2004; Gedigian et al., 2006; Krishnakumaran and Zhu, 2007; Turney et al., 2011; Broadwell et al., 2013) and corpus-based approaches (Birke and Sarkar, 2007; Shutova et al., 2013; Neuman et al., 2013; Shutova and Sun, 2013; Hovy et al., 2013). We build on this foundation and also extend metaphor detection into other languages in which few resources may exist. Our work makes the following contributions: (1) we develop a new state-of-the-art English metaphor detection system that uses conceptual semantic features, such as a degree of abstractness and semantic supersenses;2 (2) we create new metaphor-annotated corpora for Russian and English;3 (3) using</context>
</contexts>
<marker>Krishnakumaran, Zhu, 2007</marker>
<rawString>Saisuresh Krishnakumaran and Xiaojin Zhu. 2007. Hunting elusive metaphors using lexical resources. In Proc. of the Workshop on Computational approaches to Figurative Language, pages 13–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
<author>Mark Johnson</author>
</authors>
<title>Conceptual metaphor in everyday language.</title>
<date>1980</date>
<journal>The Journal of Philosophy,</journal>
<pages>453--486</pages>
<contexts>
<context position="974" citStr="Lakoff and Johnson (1980)" startWordPosition="137" endWordPosition="140">ction is meant literally or metaphorically using lexical semantic features of the words that participate in the construction. Our model is constructed using English resources, and we obtain state-of-the-art performance relative to previous work in this language. Using a model transfer approach by pivoting through a bilingual dictionary, we show our model can identify metaphoric expressions in other languages. We provide results on three new test sets in Spanish, Farsi, and Russian. The results support the hypothesis that metaphors are conceptual, rather than lexical, in nature. 1 Introduction Lakoff and Johnson (1980) characterize metaphor as reasoning about one thing in terms of another, i.e., a metaphor is a type of conceptual mapping, where words or phrases are applied to objects and actions in ways that do not permit a literal interpretation. They argue that metaphors play a fundamental communicative role in verbal and written interactions, claiming that much of our everyday language is delivered in metaphorical terms. There is empirical evidence supporting the claim: recent corpus studies have estimated that the proportion of words used metaphorically ranges from 5% to 20% (Steen et al., 2010), and Th</context>
</contexts>
<marker>Lakoff, Johnson, 1980</marker>
<rawString>George Lakoff and Mark Johnson. 1980. Conceptual metaphor in everyday language. The Journal of Philosophy, pages 453–486.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lori Levin</author>
<author>Teruko Mitamura</author>
<author>Davida Fromm</author>
<author>Brian MacWhinney</author>
<author>Jaime Carbonell</author>
<author>Weston Feely</author>
<author>Robert Frederking</author>
<author>Anatole Gershman</author>
<author>Carlos Ramirez</author>
</authors>
<title>Resources for the detection of conventionalized metaphors in four languages.</title>
<date>2014</date>
<booktitle>In Proc. of LREC.</booktitle>
<contexts>
<context position="18134" citStr="Levin et al., 2014" startWordPosition="2710" endWordPosition="2713">11/ 16http://www.babylon.com 17http://www.cs.sfu.ca/˜anoop/students/ jbirke/ 251 drowning students) whose interpretation depends on the context. 4.2 Multilingual test sets We collect and annotate metaphoric and literal test sentences in four languages. Thus, we compile eight test datasets, four for SVO relations, and four for AN relations. Each dataset has an equal number of metaphors and non-metaphors, i.e., the datasets are balanced. English (EN) and Russian (RU) datasets have been compiled by our team and are publicly available. Spanish (ES) and Farsi (FA) datasets are published elsewhere (Levin et al., 2014). Table 1 lists test set sizes. SVO AN EN 222 200 RU 240 200 ES 220 120 FA 44 320 Table 1: Sizes of the eight test sets. Each dataset is balanced, i.e., it has an equal number of metaphors and non-metaphors. For example, English SVO dataset has 222 relations: 111 metaphoric and 111 literal. We used the following procedure to compile the EN and RU test sets. A moderator started with seed lists of 1000 most common verbs and adjectives.18 Then she used the SketchEngine, which provides searching capability for the TenTen Web corpus,19 to extract sentences with words that frequently co-occurred wit</context>
</contexts>
<marker>Levin, Mitamura, Fromm, MacWhinney, Carbonell, Feely, Frederking, Gershman, Ramirez, 2014</marker>
<rawString>Lori Levin, Teruko Mitamura, Davida Fromm, Brian MacWhinney, Jaime Carbonell, Weston Feely, Robert Frederking, Anatole Gershman, and Carlos Ramirez. 2014. Resources for the detection of conventionalized metaphors in four languages. In Proc. of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´e F T Martins</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
<author>Pedro M Q Aguiar</author>
<author>M´ario A T Figueiredo</author>
</authors>
<title>Turbo parsers: dependency parsing by approximate variational inference.</title>
<date>2010</date>
<booktitle>In Proc. of ENMLP,</booktitle>
<pages>34--44</pages>
<contexts>
<context position="16782" citStr="Martins et al., 2010" startWordPosition="2512" endWordPosition="2515"> and 5 for brain). Four of these synsets are associated with the supersense noun.body. Therefore, the value of the feature noun.body is 4/38 ≈ 0.11. 4 Datasets In this section we describe a training and testing dataset as well a data collection procedure. 4.1 English training sets To train an SVO metaphor classifier, we employ the TroFi (Trope Finder) dataset.17 TroFi includes 3,737 manually annotated English sentences from the Wall Street Journal (Birke and Sarkar, 2007). Each sentence contains either literal or metaphorical use for one of 50 English verbs. First, we use a dependency parser (Martins et al., 2010) to extract subject-verb-object (SVO) relations. Then, we filter extracted relations to eliminate parsing-related errors, and relations with verbs which are not in the TroFi verb list. After filtering, there are 953 metaphorical and 656 literal SVO relations which we use as a training set. In the case of AN relations, we construct and make publicly available a training set containing 884 metaphorical AN pairs and 884 pairs with literal meaning. It was collected by two annotators using public resources (collections of metaphors on the web). At least one additional person carefully examined and </context>
</contexts>
<marker>Martins, Smith, Xing, Aguiar, Figueiredo, 2010</marker>
<rawString>Andr´e F. T. Martins, Noah A. Smith, Eric P. Xing, Pedro M. Q. Aguiar, and M´ario A. T. Figueiredo. 2010. Turbo parsers: dependency parsing by approximate variational inference. In Proc. of ENMLP, pages 34– 44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zachary J Mason</author>
</authors>
<title>CorMet: a computational, corpus-based conventional metaphor extraction system.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="2768" citStr="Mason, 2004" startWordPosition="417" endWordPosition="418">ly or not. Second, scientific hypotheses about metaphoric language could be tested more easily at a larger scale with automation. However, metaphor detection is a hard problem. On one hand, there is a subjective component: humans may disagree whether a particular expression is used metaphorically or not, as there is no clear-cut semantic distinction between figurative and metaphorical language (Shutova, 2010). On the other, metaphors can be domain- and contextdependent.1 Previous work has focused on metaphor identification in English, using both extensive manuallycreated linguistic resources (Mason, 2004; Gedigian et al., 2006; Krishnakumaran and Zhu, 2007; Turney et al., 2011; Broadwell et al., 2013) and corpus-based approaches (Birke and Sarkar, 2007; Shutova et al., 2013; Neuman et al., 2013; Shutova and Sun, 2013; Hovy et al., 2013). We build on this foundation and also extend metaphor detection into other languages in which few resources may exist. Our work makes the following contributions: (1) we develop a new state-of-the-art English metaphor detection system that uses conceptual semantic features, such as a degree of abstractness and semantic supersenses;2 (2) we create new metaphor-</context>
</contexts>
<marker>Mason, 2004</marker>
<rawString>Zachary J Mason. 2004. CorMet: a computational, corpus-based conventional metaphor extraction system. Computational Linguistics, 30(1):23–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Slav Petrov</author>
<author>Keith Hall</author>
</authors>
<title>Multi-source transfer of delexicalized dependency parsers.</title>
<date>2011</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="3473" citStr="McDonald et al., 2011" startWordPosition="531" endWordPosition="534">l et al., 2013) and corpus-based approaches (Birke and Sarkar, 2007; Shutova et al., 2013; Neuman et al., 2013; Shutova and Sun, 2013; Hovy et al., 2013). We build on this foundation and also extend metaphor detection into other languages in which few resources may exist. Our work makes the following contributions: (1) we develop a new state-of-the-art English metaphor detection system that uses conceptual semantic features, such as a degree of abstractness and semantic supersenses;2 (2) we create new metaphor-annotated corpora for Russian and English;3 (3) using a paradigm of model transfer (McDonald et al., 2011; T¨ackstr¨om et al., 2013; Kozhenikov and Titov, 2013), we provide support for the hypothesis that metaphors are concep1For example, drowning students could be used metaphorically to describe the situation where students are overwhelmed with work, but in the sentence a lifeguard saved drowning students, this phrase is used literally. 2https://github.com/ytsvetko/metaphor 3http://www.cs.cmu.edu/˜ytsvetko/ metaphor/datasets.zip 248 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 248–258, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association</context>
</contexts>
<marker>McDonald, Petrov, Hall, 2011</marker>
<rawString>Ryan McDonald, Slav Petrov, and Keith Hall. 2011. Multi-source transfer of delexicalized dependency parsers. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Quoc V Le</author>
<author>Ilya Sutskever</author>
</authors>
<title>Exploiting similarities among languages for Machine Translation.</title>
<date>2013</date>
<location>CoRR, abs/1309.4168.</location>
<contexts>
<context position="10230" citStr="Mikolov et al. (2013)" startWordPosition="1549" endWordPosition="1552">), which makes supersense features suitable for cross-lingual approaches such as ours. • Vector space word representations. Vector space word representations learned using unsupervised algorithms are often effective features in supervised learning methods (Turian et al., 2010). In particular, many such representations are designed to capture lexical semantic properties and are quite effective features in semantic processing, including named entity recognition (Turian et al., 2009), word sense disambiguation (Huang et al., 2012), and lexical entailment (Baroni et al., 2012). In a recent study, Mikolov et al. (2013) reveal an interesting cross-lingual property of distributed word representations: there is a strong similarity between the vector spaces across languages that can be easily captured by linear mapping. Thus, vector space models can also be seen as vectors of (latent) semantic concepts, that preserve their “meaning” across languages. 3 Model and Feature Extraction In this section we describe a classification model, and provide details on mono- and cross-lingual implementation of features. 3.1 Classification using Random Forests To make classification decisions, we use a random forest classifier</context>
</contexts>
<marker>Mikolov, Le, Sutskever, 2013</marker>
<rawString>Tomas Mikolov, Quoc V. Le, and Ilya Sutskever. 2013. Exploiting similarities among languages for Machine Translation. CoRR, abs/1309.4168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word sense disambiguation: A survey.</title>
<date>2009</date>
<journal>ACM Comput. Surv.,</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="34837" citStr="Navigli, 2009" startWordPosition="5462" endWordPosition="5463">reliable datasets for evaluating results. We demonstrate results on two new languages, Spanish and Farsi, to emphasize the generality of the method. A words sense disambiguation (WSD) is a related problem, where one identifies meanings of polysemous words. The difference is that in the WSD task, we need to select an already existing sense, while for the metaphor detection, the goal is to identify cases of sense borrowing. Studies showed that cross-lingual evidence allows one to achieve a state-of-the-art performance in the WSD task, yet, most cross-lingual WSD methods employ parallel corpora (Navigli, 2009). 7 Conclusion The key contribution of our work is that we show how to identify metaphors across languages by building a model in English and applying it— without adaptation—to other languages: Spanish, Farsi, and Russian. This model uses languageindependent (rather than lexical or language specific) conceptual features. Not only do we establish benchmarks for Spanish, Farsi, and Russian, but we also achieve state-of-the-art performance in English. In addition, we present a comparison of relative contributions of several types of features. We concentrate on metaphors in the context of two kind</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word sense disambiguation: A survey. ACM Comput. Surv., 41(2):10:1–10:69, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yair Neuman</author>
<author>Dan Assaf</author>
<author>Yohai Cohen</author>
<author>Mark Last</author>
<author>Shlomo Argamon</author>
<author>Newton Howard</author>
<author>Ophir Frieder</author>
</authors>
<title>Metaphor identification in large texts corpora.</title>
<date>2013</date>
<tech>PloS one, 8(4):e62343.</tech>
<contexts>
<context position="2962" citStr="Neuman et al., 2013" startWordPosition="447" endWordPosition="450">nd, there is a subjective component: humans may disagree whether a particular expression is used metaphorically or not, as there is no clear-cut semantic distinction between figurative and metaphorical language (Shutova, 2010). On the other, metaphors can be domain- and contextdependent.1 Previous work has focused on metaphor identification in English, using both extensive manuallycreated linguistic resources (Mason, 2004; Gedigian et al., 2006; Krishnakumaran and Zhu, 2007; Turney et al., 2011; Broadwell et al., 2013) and corpus-based approaches (Birke and Sarkar, 2007; Shutova et al., 2013; Neuman et al., 2013; Shutova and Sun, 2013; Hovy et al., 2013). We build on this foundation and also extend metaphor detection into other languages in which few resources may exist. Our work makes the following contributions: (1) we develop a new state-of-the-art English metaphor detection system that uses conceptual semantic features, such as a degree of abstractness and semantic supersenses;2 (2) we create new metaphor-annotated corpora for Russian and English;3 (3) using a paradigm of model transfer (McDonald et al., 2011; T¨ackstr¨om et al., 2013; Kozhenikov and Titov, 2013), we provide support for the hypot</context>
<context position="32119" citStr="Neuman et al. (2013)" startWordPosition="5020" endWordPosition="5023">ly used literally, while &lt;noun.act,verb.motion&gt; is used metaphorically. 6 Related Work For a historic overview and a survey of common approaches to metaphor detection, we refer the reader to recent reviews by Shutova et al. (Shutova, 2010; Shutova et al., 2013). Here we focus only on recent approaches. Shutova et al. (2010) proposed a bottom-up method: one starts from a set of seed metaphors and seeks phrases where verbs and/or nouns belong to the same cluster as verbs or nouns in seed examples. Turney et al. (2011) show how abstractness scores could be used to detect metaphorical AN phrases. Neuman et al. (2013) describe a Concrete Category Overlap algorithm, where co-occurrence statistics and Turney’s abstractness scores are used to determine WordNet supersenses that correspond to literal usage of a given adjective or verb. For example, given an adjective, we can learn that it modifies concrete nouns that usually have the EN (area = 0.79) ES (area = 0.71) FA (area = 0.69) RU (area = 0.89) False Positive Rate 0.8 0.6 0.4 0.00.0 0.2 0.4 0.6 0.8 1.0 0.2 1.0 EN (area = 0.92) ES (area = 0.73) FA (area = 0.83) RU (area = 0.8) 255 supersense noun.body. If this adjective modifies a noun with the supersense </context>
</contexts>
<marker>Neuman, Assaf, Cohen, Last, Argamon, Howard, Frieder, 2013</marker>
<rawString>Yair Neuman, Dan Assaf, Yohai Cohen, Mark Last, Shlomo Argamon, Newton Howard, and Ophir Frieder. 2013. Metaphor identification in large texts corpora. PloS one, 8(4):e62343.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pedregosa</author>
<author>G Varoquaux</author>
<author>A Gramfort</author>
<author>V Michel</author>
<author>B Thirion</author>
<author>O Grisel</author>
<author>M Blondel</author>
<author>P Prettenhofer</author>
<author>R Weiss</author>
<author>V Dubourg</author>
<author>J Vanderplas</author>
<author>A Passos</author>
<author>D Cournapeau</author>
<author>M Brucher</author>
<author>M Perrot</author>
<author>E Duchesnay</author>
</authors>
<title>Scikit-learn: Machine learning in Python.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>12--2825</pages>
<contexts>
<context position="11800" citStr="Pedregosa et al., 2011" startWordPosition="1779" endWordPosition="1782"> resource-scarce scenario: rather than overfitting, they produce a limiting value of the generalization error as the number of trees increases,8 and no hyperparameter tuning is required. In addition, decision-tree classifiers learn non-linear responses to inputs and often outperform logistic regression (Perlich et al., 2003).9 Our random forest classifier models the probability that the input syntactic relation is metaphorical. If this probability is above a threshold, the relation is classified as metaphoric, otherwise it is literal. We used the scikit-learn toolkit to train our classifiers (Pedregosa et al., 2011). 3.2 Feature extraction Abstractness and imageability. The MRC psycholinguistic database is a large dictionary listing linguistic and psycholinguistic attributes obtained experimentally (Wilson, 1988).10 It includes, among other data, 4,295 words rated by the degrees of abstractness and 1,156 words rated by the imageability. Similarly to Tsvetkov et al. (2013), we use a logistic regression classifier to propagate abstractness and imageability scores from MRC ratings to all words for which we have vector space representations. More specifically, we calculate the degree of abstractness and imag</context>
</contexts>
<marker>Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot, Duchesnay, 2011</marker>
<rawString>F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825–2830.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Perlich</author>
<author>Foster Provost</author>
<author>Jeffrey S Simonoff</author>
</authors>
<title>Tree induction vs. logistic regression: a learning-curve analysis.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>4--211</pages>
<contexts>
<context position="11503" citStr="Perlich et al., 2003" startWordPosition="1734" endWordPosition="1737">ifiers learned from many independent subsamples of the training data. Given an input, each tree classifier assigns a probability to each label; those probabilities are averaged to compute the probability distribution across the ensemble. Random forest ensembles are particularly suitable for our resource-scarce scenario: rather than overfitting, they produce a limiting value of the generalization error as the number of trees increases,8 and no hyperparameter tuning is required. In addition, decision-tree classifiers learn non-linear responses to inputs and often outperform logistic regression (Perlich et al., 2003).9 Our random forest classifier models the probability that the input syntactic relation is metaphorical. If this probability is above a threshold, the relation is classified as metaphoric, otherwise it is literal. We used the scikit-learn toolkit to train our classifiers (Pedregosa et al., 2011). 3.2 Feature extraction Abstractness and imageability. The MRC psycholinguistic database is a large dictionary listing linguistic and psycholinguistic attributes obtained experimentally (Wilson, 1988).10 It includes, among other data, 4,295 words rated by the degrees of abstractness and 1,156 words ra</context>
</contexts>
<marker>Perlich, Provost, Simonoff, 2003</marker>
<rawString>Claudia Perlich, Foster Provost, and Jeffrey S. Simonoff. 2003. Tree induction vs. logistic regression: a learning-curve analysis. Journal of Machine Learning Research, 4:211–255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathan Schneider</author>
<author>Behrang Mohit</author>
<author>Chris Dyer</author>
<author>Kemal Oflazer</author>
<author>Noah A Smith</author>
</authors>
<title>Supersense tagging for Arabic: the MT-in-the-middle attack.</title>
<date>2013</date>
<booktitle>In Proc. of NAACL-HLT,</booktitle>
<pages>661--667</pages>
<contexts>
<context position="9610" citStr="Schneider et al., 2013" startWordPosition="1457" endWordPosition="1460">structed by Tsvetkov et al. (2014) (discussed in §3.2). Supersenses are particularly attractive features for metaphor detection: coarse sense taxonomies can be viewed as semantic concepts, and since concept mapping is a process in which metaphors are born, we expect different supersense co-occurrences in metaphoric and literal combinations. In “drinks gasoline”, for example, mapping to supersenses would yield a pair &lt;verb.consumption, noun.substance&gt;, contrasted with &lt;verb.consumption, noun.food&gt; for “drinks juice”. In addition, this coarse semantic categorization is preserved in translation (Schneider et al., 2013), which makes supersense features suitable for cross-lingual approaches such as ours. • Vector space word representations. Vector space word representations learned using unsupervised algorithms are often effective features in supervised learning methods (Turian et al., 2010). In particular, many such representations are designed to capture lexical semantic properties and are quite effective features in semantic processing, including named entity recognition (Turian et al., 2009), word sense disambiguation (Huang et al., 2012), and lexical entailment (Baroni et al., 2012). In a recent study, M</context>
</contexts>
<marker>Schneider, Mohit, Dyer, Oflazer, Smith, 2013</marker>
<rawString>Nathan Schneider, Behrang Mohit, Chris Dyer, Kemal Oflazer, and Noah A Smith. 2013. Supersense tagging for Arabic: the MT-in-the-middle attack. In Proc. of NAACL-HLT, pages 661–667.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
<author>Lin Sun</author>
</authors>
<title>Unsupervised metaphor identification using hierarchical graph factorization clustering.</title>
<date>2013</date>
<booktitle>In Proc. of NAACL-HLT,</booktitle>
<pages>978--988</pages>
<contexts>
<context position="2985" citStr="Shutova and Sun, 2013" startWordPosition="451" endWordPosition="454">tive component: humans may disagree whether a particular expression is used metaphorically or not, as there is no clear-cut semantic distinction between figurative and metaphorical language (Shutova, 2010). On the other, metaphors can be domain- and contextdependent.1 Previous work has focused on metaphor identification in English, using both extensive manuallycreated linguistic resources (Mason, 2004; Gedigian et al., 2006; Krishnakumaran and Zhu, 2007; Turney et al., 2011; Broadwell et al., 2013) and corpus-based approaches (Birke and Sarkar, 2007; Shutova et al., 2013; Neuman et al., 2013; Shutova and Sun, 2013; Hovy et al., 2013). We build on this foundation and also extend metaphor detection into other languages in which few resources may exist. Our work makes the following contributions: (1) we develop a new state-of-the-art English metaphor detection system that uses conceptual semantic features, such as a degree of abstractness and semantic supersenses;2 (2) we create new metaphor-annotated corpora for Russian and English;3 (3) using a paradigm of model transfer (McDonald et al., 2011; T¨ackstr¨om et al., 2013; Kozhenikov and Titov, 2013), we provide support for the hypothesis that metaphors ar</context>
</contexts>
<marker>Shutova, Sun, 2013</marker>
<rawString>Ekaterina Shutova and Lin Sun. 2013. Unsupervised metaphor identification using hierarchical graph factorization clustering. In Proc. of NAACL-HLT, pages 978–988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
<author>Lin Sun</author>
<author>Anna Korhonen</author>
</authors>
<title>Metaphor identification using verb and noun clustering.</title>
<date>2010</date>
<booktitle>In Proc. of COLING,</booktitle>
<pages>1002--1010</pages>
<contexts>
<context position="31824" citStr="Shutova et al. (2010)" startWordPosition="4968" endWordPosition="4971">than economic. Verb-based examples that are correctly classified by our model are: blunder escaped notice (metaphoric) and prisoner escaped jail (literal). We hypothesize that supersense features are instrumental in the correct classification of these examples: &lt;noun.person,verb.motion&gt; is usually used literally, while &lt;noun.act,verb.motion&gt; is used metaphorically. 6 Related Work For a historic overview and a survey of common approaches to metaphor detection, we refer the reader to recent reviews by Shutova et al. (Shutova, 2010; Shutova et al., 2013). Here we focus only on recent approaches. Shutova et al. (2010) proposed a bottom-up method: one starts from a set of seed metaphors and seeks phrases where verbs and/or nouns belong to the same cluster as verbs or nouns in seed examples. Turney et al. (2011) show how abstractness scores could be used to detect metaphorical AN phrases. Neuman et al. (2013) describe a Concrete Category Overlap algorithm, where co-occurrence statistics and Turney’s abstractness scores are used to determine WordNet supersenses that correspond to literal usage of a given adjective or verb. For example, given an adjective, we can learn that it modifies concrete nouns that usua</context>
</contexts>
<marker>Shutova, Sun, Korhonen, 2010</marker>
<rawString>Ekaterina Shutova, Lin Sun, and Anna Korhonen. 2010. Metaphor identification using verb and noun clustering. In Proc. of COLING, pages 1002–1010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
<author>Simone Teufel</author>
<author>Anna Korhonen</author>
</authors>
<title>Statistical metaphor processing.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>39</volume>
<issue>2</issue>
<contexts>
<context position="2941" citStr="Shutova et al., 2013" startWordPosition="443" endWordPosition="446">ard problem. On one hand, there is a subjective component: humans may disagree whether a particular expression is used metaphorically or not, as there is no clear-cut semantic distinction between figurative and metaphorical language (Shutova, 2010). On the other, metaphors can be domain- and contextdependent.1 Previous work has focused on metaphor identification in English, using both extensive manuallycreated linguistic resources (Mason, 2004; Gedigian et al., 2006; Krishnakumaran and Zhu, 2007; Turney et al., 2011; Broadwell et al., 2013) and corpus-based approaches (Birke and Sarkar, 2007; Shutova et al., 2013; Neuman et al., 2013; Shutova and Sun, 2013; Hovy et al., 2013). We build on this foundation and also extend metaphor detection into other languages in which few resources may exist. Our work makes the following contributions: (1) we develop a new state-of-the-art English metaphor detection system that uses conceptual semantic features, such as a degree of abstractness and semantic supersenses;2 (2) we create new metaphor-annotated corpora for Russian and English;3 (3) using a paradigm of model transfer (McDonald et al., 2011; T¨ackstr¨om et al., 2013; Kozhenikov and Titov, 2013), we provide </context>
<context position="31760" citStr="Shutova et al., 2013" startWordPosition="4957" endWordPosition="4960">recho humano “human right”. In Spanish, human is more imageable than economic. Verb-based examples that are correctly classified by our model are: blunder escaped notice (metaphoric) and prisoner escaped jail (literal). We hypothesize that supersense features are instrumental in the correct classification of these examples: &lt;noun.person,verb.motion&gt; is usually used literally, while &lt;noun.act,verb.motion&gt; is used metaphorically. 6 Related Work For a historic overview and a survey of common approaches to metaphor detection, we refer the reader to recent reviews by Shutova et al. (Shutova, 2010; Shutova et al., 2013). Here we focus only on recent approaches. Shutova et al. (2010) proposed a bottom-up method: one starts from a set of seed metaphors and seeks phrases where verbs and/or nouns belong to the same cluster as verbs or nouns in seed examples. Turney et al. (2011) show how abstractness scores could be used to detect metaphorical AN phrases. Neuman et al. (2013) describe a Concrete Category Overlap algorithm, where co-occurrence statistics and Turney’s abstractness scores are used to determine WordNet supersenses that correspond to literal usage of a given adjective or verb. For example, given an a</context>
</contexts>
<marker>Shutova, Teufel, Korhonen, 2013</marker>
<rawString>Ekaterina Shutova, Simone Teufel, and Anna Korhonen. 2013. Statistical metaphor processing. Computational Linguistics, 39(2):301–353.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
</authors>
<title>Models of metaphor in NLP.</title>
<date>2010</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>688--697</pages>
<contexts>
<context position="2569" citStr="Shutova, 2010" startWordPosition="388" endWordPosition="389">ine translation, dialog systems, sentiment analysis, and text analytics, etc.) would have access to a potentially useful high-level bit of information about whether something is to be understood literally or not. Second, scientific hypotheses about metaphoric language could be tested more easily at a larger scale with automation. However, metaphor detection is a hard problem. On one hand, there is a subjective component: humans may disagree whether a particular expression is used metaphorically or not, as there is no clear-cut semantic distinction between figurative and metaphorical language (Shutova, 2010). On the other, metaphors can be domain- and contextdependent.1 Previous work has focused on metaphor identification in English, using both extensive manuallycreated linguistic resources (Mason, 2004; Gedigian et al., 2006; Krishnakumaran and Zhu, 2007; Turney et al., 2011; Broadwell et al., 2013) and corpus-based approaches (Birke and Sarkar, 2007; Shutova et al., 2013; Neuman et al., 2013; Shutova and Sun, 2013; Hovy et al., 2013). We build on this foundation and also extend metaphor detection into other languages in which few resources may exist. Our work makes the following contributions: </context>
<context position="31737" citStr="Shutova, 2010" startWordPosition="4955" endWordPosition="4956">h as literal derecho humano “human right”. In Spanish, human is more imageable than economic. Verb-based examples that are correctly classified by our model are: blunder escaped notice (metaphoric) and prisoner escaped jail (literal). We hypothesize that supersense features are instrumental in the correct classification of these examples: &lt;noun.person,verb.motion&gt; is usually used literally, while &lt;noun.act,verb.motion&gt; is used metaphorically. 6 Related Work For a historic overview and a survey of common approaches to metaphor detection, we refer the reader to recent reviews by Shutova et al. (Shutova, 2010; Shutova et al., 2013). Here we focus only on recent approaches. Shutova et al. (2010) proposed a bottom-up method: one starts from a set of seed metaphors and seeks phrases where verbs and/or nouns belong to the same cluster as verbs or nouns in seed examples. Turney et al. (2011) show how abstractness scores could be used to detect metaphorical AN phrases. Neuman et al. (2013) describe a Concrete Category Overlap algorithm, where co-occurrence statistics and Turney’s abstractness scores are used to determine WordNet supersenses that correspond to literal usage of a given adjective or verb. </context>
</contexts>
<marker>Shutova, 2010</marker>
<rawString>Ekaterina Shutova. 2010. Models of metaphor in NLP. In Proc. of ACL, pages 688–697.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard J Steen</author>
<author>Aletta G Dorst</author>
<author>J Berenike Herrmann</author>
<author>Anna A Kaal</author>
<author>Tina Krennmayr</author>
</authors>
<title>Metaphor in usage.</title>
<date>2010</date>
<journal>Cognitive Linguistics,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="1566" citStr="Steen et al., 2010" startWordPosition="235" endWordPosition="238">n Lakoff and Johnson (1980) characterize metaphor as reasoning about one thing in terms of another, i.e., a metaphor is a type of conceptual mapping, where words or phrases are applied to objects and actions in ways that do not permit a literal interpretation. They argue that metaphors play a fundamental communicative role in verbal and written interactions, claiming that much of our everyday language is delivered in metaphorical terms. There is empirical evidence supporting the claim: recent corpus studies have estimated that the proportion of words used metaphorically ranges from 5% to 20% (Steen et al., 2010), and Thibodeau and Boroditsky (2011) provide evidence that a choice of metaphors affects decision making. Given the prevalence and importance of metaphoric language, effective automatic detection of metaphors would have a number of benefits, both practical and scientific. Language processing applications that need to understand language or preserve meaning (information extraction, machine translation, dialog systems, sentiment analysis, and text analytics, etc.) would have access to a potentially useful high-level bit of information about whether something is to be understood literally or not</context>
</contexts>
<marker>Steen, Dorst, Herrmann, Kaal, Krennmayr, 2010</marker>
<rawString>Gerard J Steen, Aletta G Dorst, J Berenike Herrmann, Anna A Kaal, and Tina Krennmayr. 2010. Metaphor in usage. Cognitive Linguistics, 21(4):765–796.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomek Strzalkowski</author>
<author>George Aaron Broadwell</author>
<author>Sarah Taylor</author>
<author>Laurie Feldman</author>
<author>Boris Yamrom</author>
<author>Samira Shaikh</author>
<author>Ting Liu</author>
<author>Kit Cho</author>
<author>Umit Boz</author>
<author>Ignacio Cases</author>
</authors>
<title>Robust extraction of metaphors from novel data.</title>
<date>2013</date>
<booktitle>In Proc. of the First Workshop on Metaphor in NLP,</booktitle>
<pages>67</pages>
<contexts>
<context position="33074" citStr="Strzalkowski et al. (2013)" startWordPosition="5183" endWordPosition="5186">0.79) ES (area = 0.71) FA (area = 0.69) RU (area = 0.89) False Positive Rate 0.8 0.6 0.4 0.00.0 0.2 0.4 0.6 0.8 1.0 0.2 1.0 EN (area = 0.92) ES (area = 0.73) FA (area = 0.83) RU (area = 0.8) 255 supersense noun.body. If this adjective modifies a noun with the supersense noun.feeling, we conclude that a metaphor is found. Broadwell et al. (2013) argue that metaphors are highly imageable words that do not belong to a discussion topic. To implement this idea, they extend MRC imageability scores to all dictionary words using links among WordNet supersenses (mostly hypernym and hyponym relations). Strzalkowski et al. (2013) carry out experiments in a specific (government-related) domain for four languages: English, Spanish, Farsi, and Russian. Strzalkowski et al. (2013) explain the algorithm only for English and say that is the same for Spanish, Farsi, and Russian. Because they heavily rely on WordNet and availability of imageability scores, their approach may not be applicable to low-resource languages. Hovy et al. (2013) applied tree kernels to metaphor detection. Their method also employs WordNet supersenses, but it is not clear from the description whether WordNet is essential or can be replaced with some ot</context>
</contexts>
<marker>Strzalkowski, Broadwell, Taylor, Feldman, Yamrom, Shaikh, Liu, Cho, Boz, Cases, 2013</marker>
<rawString>Tomek Strzalkowski, George Aaron Broadwell, Sarah Taylor, Laurie Feldman, Boris Yamrom, Samira Shaikh, Ting Liu, Kit Cho, Umit Boz, Ignacio Cases, et al. 2013. Robust extraction of metaphors from novel data. In Proc. of the First Workshop on Metaphor in NLP, page 67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Token and type constraints for cross-lingual part-of-speech tagging.</title>
<date>2013</date>
<tech>TACL,</tech>
<pages>1--1</pages>
<marker>T¨ackstr¨om, Das, Petrov, McDonald, Nivre, 2013</marker>
<rawString>Oscar T¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan McDonald, and Joakim Nivre. 2013. Token and type constraints for cross-lingual part-of-speech tagging. TACL, 1:1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul H Thibodeau</author>
<author>Lera Boroditsky</author>
</authors>
<title>Metaphors we think with: The role of metaphor in reasoning.</title>
<date>2011</date>
<journal>PLoS One,</journal>
<volume>6</volume>
<issue>2</issue>
<contexts>
<context position="1603" citStr="Thibodeau and Boroditsky (2011)" startWordPosition="240" endWordPosition="243">0) characterize metaphor as reasoning about one thing in terms of another, i.e., a metaphor is a type of conceptual mapping, where words or phrases are applied to objects and actions in ways that do not permit a literal interpretation. They argue that metaphors play a fundamental communicative role in verbal and written interactions, claiming that much of our everyday language is delivered in metaphorical terms. There is empirical evidence supporting the claim: recent corpus studies have estimated that the proportion of words used metaphorically ranges from 5% to 20% (Steen et al., 2010), and Thibodeau and Boroditsky (2011) provide evidence that a choice of metaphors affects decision making. Given the prevalence and importance of metaphoric language, effective automatic detection of metaphors would have a number of benefits, both practical and scientific. Language processing applications that need to understand language or preserve meaning (information extraction, machine translation, dialog systems, sentiment analysis, and text analytics, etc.) would have access to a potentially useful high-level bit of information about whether something is to be understood literally or not. Second, scientific hypotheses about</context>
</contexts>
<marker>Thibodeau, Boroditsky, 2011</marker>
<rawString>Paul H Thibodeau and Lera Boroditsky. 2011. Metaphors we think with: The role of metaphor in reasoning. PLoS One, 6(2):e16782.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yulia Tsvetkov</author>
<author>Elena Mukomel</author>
<author>Anatole Gershman</author>
</authors>
<title>Cross-lingual metaphor detection using common semantic features.</title>
<date>2013</date>
<booktitle>In The 1st Workshop on Metaphor in NLP 2013,</booktitle>
<pages>45</pages>
<contexts>
<context position="12163" citStr="Tsvetkov et al. (2013)" startWordPosition="1830" endWordPosition="1833"> the probability that the input syntactic relation is metaphorical. If this probability is above a threshold, the relation is classified as metaphoric, otherwise it is literal. We used the scikit-learn toolkit to train our classifiers (Pedregosa et al., 2011). 3.2 Feature extraction Abstractness and imageability. The MRC psycholinguistic database is a large dictionary listing linguistic and psycholinguistic attributes obtained experimentally (Wilson, 1988).10 It includes, among other data, 4,295 words rated by the degrees of abstractness and 1,156 words rated by the imageability. Similarly to Tsvetkov et al. (2013), we use a logistic regression classifier to propagate abstractness and imageability scores from MRC ratings to all words for which we have vector space representations. More specifically, we calculate the degree of abstractness and imageability of all English items that have a vector space representation, using vector elements as features. We train two separate classifiers for abstractness and imageability on a seed set of words from the MRC database. Degrees of abstractness and imageability are posterior probabilities of classifier predictions. We binarize these posteriors into abstractconcr</context>
<context position="21500" citStr="Tsvetkov et al. (2013)" startWordPosition="3264" endWordPosition="3267">ation results for three feature categories and their combination, for classifiers trained on English SVO and AN training sets. # FEAT column shows a number of features. ACC column reports an accuracy score in the 10- fold cross validation. Statistically significant differences (p &lt; 0.01) from the all-feature combination are marked with a star. These results show superior performance over previous state-of-the-art results, confirming our hypothesis that conceptual features are effective in metaphor classification. For the SVO task, the cross-validation accuracy is about 10% better than that of Tsvetkov et al. (2013). For the AN task, the cross validation accuracy is better by 8% than the result of Turney et al. (2011) (two baseline 252 methods are described in Section 5.2). We can see that all types of features have good performance on their own (VSM is the strongest feature type). Noun supersense features alone allows us to achieve an accuracy of 75%, i.e., adjective supersense features contribute 4% to adjective-noun supersense feature combination. Experiments with the pairs of features yield better results than individual features, implying that the feature categories are not redundant. Yet, combining</context>
<context position="25171" citStr="Tsvetkov et al. (2013)" startWordPosition="3900" endWordPosition="3903"> sets (English SVO and AN test sets). According to ROC plots in Figure 1, all three feature sets are effective, both for SVO and for AN tasks. Abstractness and Imageability features work better for adjectives and nouns, which is in line with previous findings (Turney et al., 2011; Broadwell et al., 2013). It can be also seen that VSM features are very effective. This is in line with results of Hovy et al. (2013), who found that it is hard to improve over the classifier that uses only VSM features. 5.2 Comparison to baselines In this section, we compare our method to state-ofthe-art methods of Tsvetkov et al. (2013) and of Turney et al. (2011), who focused on classifying SVO and AN relations, respectively. In the case of SVO relations, we use software 0.2 0.2 253 and datasets from Tsvetkov et al. (2013). These datasets, denoted as an SVO-baseline, consist of 98 English and 149 Russian sentences. We train SVO metaphor detection tools on SVO relations extracted from TroFi sentences and evaluate them on the SVO-baseline dataset. We also use the same thresholds for classifier posterior probabilities as Tsvetkov et al. (2013). Our approach is different from that of Tsvetkov et al. (2013) in that it uses addit</context>
<context position="33850" citStr="Tsvetkov et al. (2013)" startWordPosition="5304" endWordPosition="5307">ain the algorithm only for English and say that is the same for Spanish, Farsi, and Russian. Because they heavily rely on WordNet and availability of imageability scores, their approach may not be applicable to low-resource languages. Hovy et al. (2013) applied tree kernels to metaphor detection. Their method also employs WordNet supersenses, but it is not clear from the description whether WordNet is essential or can be replaced with some other lexical resource. We cannot compare directly our model with this work because our classifier is restricted to detection of only SVO and AN metaphors. Tsvetkov et al. (2013) propose a cross-lingual detection method that uses only English lexical resources and a dependency parser. Their study focuses only on the verb-based metaphors. Tsvetkov et al. (2013) employ only English and Russian data. Current work builds on this study, and incorporates new syntactic relations as metaphor candidates, adds several new feature sets and different, more reliable datasets for evaluating results. We demonstrate results on two new languages, Spanish and Farsi, to emphasize the generality of the method. A words sense disambiguation (WSD) is a related problem, where one identifies </context>
</contexts>
<marker>Tsvetkov, Mukomel, Gershman, 2013</marker>
<rawString>Yulia Tsvetkov, Elena Mukomel, and Anatole Gershman. 2013. Cross-lingual metaphor detection using common semantic features. In The 1st Workshop on Metaphor in NLP 2013, page 45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yulia Tsvetkov</author>
<author>Nathan Schneider</author>
<author>Dirk Hovy</author>
<author>Archna Bhatia</author>
<author>Manaal Faruqui</author>
<author>Chris Dyer</author>
</authors>
<title>Augmenting English adjective senses with supersenses.</title>
<date>2014</date>
<booktitle>In Proc. of LREC.</booktitle>
<contexts>
<context position="9021" citStr="Tsvetkov et al. (2014)" startWordPosition="1374" endWordPosition="1377">presentation challenges considerably. 6If word one is represented by features u ∈ R&apos; and word two by features v ∈ R&apos; then the conjunction feature vector is the vectorization of the outer product uvT. 7Supersenses are called “lexicographer classes” in WordNet documentation (Fellbaum, 1998), http://wordnet. princeton.edu/man/lexnames.5WN.html 249 noun.body, noun.animal, verb.consumption, or verb.motion (Ciaramita and Altun, 2006). English adjectives do not, as yet, have a similar high-level semantic partitioning in WordNet, thus we use a 13-class taxonomy of adjective supersenses constructed by Tsvetkov et al. (2014) (discussed in §3.2). Supersenses are particularly attractive features for metaphor detection: coarse sense taxonomies can be viewed as semantic concepts, and since concept mapping is a process in which metaphors are born, we expect different supersense co-occurrences in metaphoric and literal combinations. In “drinks gasoline”, for example, mapping to supersenses would yield a pair &lt;verb.consumption, noun.substance&gt;, contrasted with &lt;verb.consumption, noun.food&gt; for “drinks juice”. In addition, this coarse semantic categorization is preserved in translation (Schneider et al., 2013), which mak</context>
<context position="14098" citStr="Tsvetkov et al. (2014)" startWordPosition="2119" endWordPosition="2122">tions. Supersenses of nouns and verbs. A lexical item can belong to several synsets, which are associated with different supersenses. Degrees of membership in different supersenses are represented by feature vectors, where each element corresponds to one supersense. For example, the word head (when used as a noun) participates in 33 synsets, three of which are related to the supersense noun.body. The value of the feature corresponding to this supersense is 3/33 ≈ 0.09. Supersenses of adjectives. WordNet lacks coarse-grained semantic categories for adjectives. To divide adjectives into groups, Tsvetkov et al. (2014) use 13 top-level classes from the adapted taxonomy of Hundsnurscher and Splett (1982), which is incorporated in GermaNet (Hamp and Feldweg, 1997). For example, the top-level classes in GermaNet include: adj.feeling (e.g., willing, pleasant, cheerful); adj.substance (e.g., dry, ripe, creamy); adj.spatial (e.g., adjacent, gigantic).12 For each adjective type in WordNet, they produce a vector with a classifier posterior probabilities corresponding to degrees of membership of this word in one of the 13 semantic classes,13 similar to the feature vectors we build for nouns and verbs. For example, f</context>
</contexts>
<marker>Tsvetkov, Schneider, Hovy, Bhatia, Faruqui, Dyer, 2014</marker>
<rawString>Yulia Tsvetkov, Nathan Schneider, Dirk Hovy, Archna Bhatia, Manaal Faruqui, and Chris Dyer. 2014. Augmenting English adjective senses with supersenses. In Proc. of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev Ratinov</author>
<author>Yoshua Bengio</author>
<author>Dan Roth</author>
</authors>
<title>A preliminary evaluation of word representations for named-entity recognition.</title>
<date>2009</date>
<booktitle>In NIPS Workshop on Grammar Induction, Representation of Language and Language Learning,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="10094" citStr="Turian et al., 2009" startWordPosition="1527" endWordPosition="1530">on, noun.food&gt; for “drinks juice”. In addition, this coarse semantic categorization is preserved in translation (Schneider et al., 2013), which makes supersense features suitable for cross-lingual approaches such as ours. • Vector space word representations. Vector space word representations learned using unsupervised algorithms are often effective features in supervised learning methods (Turian et al., 2010). In particular, many such representations are designed to capture lexical semantic properties and are quite effective features in semantic processing, including named entity recognition (Turian et al., 2009), word sense disambiguation (Huang et al., 2012), and lexical entailment (Baroni et al., 2012). In a recent study, Mikolov et al. (2013) reveal an interesting cross-lingual property of distributed word representations: there is a strong similarity between the vector spaces across languages that can be easily captured by linear mapping. Thus, vector space models can also be seen as vectors of (latent) semantic concepts, that preserve their “meaning” across languages. 3 Model and Feature Extraction In this section we describe a classification model, and provide details on mono- and cross-lingual</context>
</contexts>
<marker>Turian, Ratinov, Bengio, Roth, 2009</marker>
<rawString>Joseph Turian, Lev Ratinov, Yoshua Bengio, and Dan Roth. 2009. A preliminary evaluation of word representations for named-entity recognition. In NIPS Workshop on Grammar Induction, Representation of Language and Language Learning, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: a simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In Proc. ofACL,</booktitle>
<pages>384--394</pages>
<contexts>
<context position="9886" citStr="Turian et al., 2010" startWordPosition="1496" endWordPosition="1499">persense co-occurrences in metaphoric and literal combinations. In “drinks gasoline”, for example, mapping to supersenses would yield a pair &lt;verb.consumption, noun.substance&gt;, contrasted with &lt;verb.consumption, noun.food&gt; for “drinks juice”. In addition, this coarse semantic categorization is preserved in translation (Schneider et al., 2013), which makes supersense features suitable for cross-lingual approaches such as ours. • Vector space word representations. Vector space word representations learned using unsupervised algorithms are often effective features in supervised learning methods (Turian et al., 2010). In particular, many such representations are designed to capture lexical semantic properties and are quite effective features in semantic processing, including named entity recognition (Turian et al., 2009), word sense disambiguation (Huang et al., 2012), and lexical entailment (Baroni et al., 2012). In a recent study, Mikolov et al. (2013) reveal an interesting cross-lingual property of distributed word representations: there is a strong similarity between the vector spaces across languages that can be easily captured by linear mapping. Thus, vector space models can also be seen as vectors </context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010. Word representations: a simple and general method for semi-supervised learning. In Proc. ofACL, pages 384–394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Yair Neuman</author>
<author>Dan Assaf</author>
<author>Yohai Cohen</author>
</authors>
<title>Literal and metaphorical sense identification through concrete and abstract context.</title>
<date>2011</date>
<booktitle>In Proc. of EMNL,</booktitle>
<pages>680--690</pages>
<contexts>
<context position="2842" citStr="Turney et al., 2011" startWordPosition="428" endWordPosition="431"> could be tested more easily at a larger scale with automation. However, metaphor detection is a hard problem. On one hand, there is a subjective component: humans may disagree whether a particular expression is used metaphorically or not, as there is no clear-cut semantic distinction between figurative and metaphorical language (Shutova, 2010). On the other, metaphors can be domain- and contextdependent.1 Previous work has focused on metaphor identification in English, using both extensive manuallycreated linguistic resources (Mason, 2004; Gedigian et al., 2006; Krishnakumaran and Zhu, 2007; Turney et al., 2011; Broadwell et al., 2013) and corpus-based approaches (Birke and Sarkar, 2007; Shutova et al., 2013; Neuman et al., 2013; Shutova and Sun, 2013; Hovy et al., 2013). We build on this foundation and also extend metaphor detection into other languages in which few resources may exist. Our work makes the following contributions: (1) we develop a new state-of-the-art English metaphor detection system that uses conceptual semantic features, such as a degree of abstractness and semantic supersenses;2 (2) we create new metaphor-annotated corpora for Russian and English;3 (3) using a paradigm of model </context>
<context position="7344" citStr="Turney et al., 2011" startWordPosition="1118" endWordPosition="1121">nk, gasoline), we compute all the features for the individual words car, drink, gasoline and combine them with the conjunction features for the pairs car drink and drink gasoline. We define three main feature categories (1) abstractness and imageability, (2) supersenses, (3) unsupervised vector-space word representations; each category corresponds to a group of features with a common theme and representation. • Abstractness and imageability. Abstractness and imageability were shown to be useful in detection of metaphors (it is easier to invoke mental pictures of concrete and imageable words) (Turney et al., 2011; Broadwell et al., 2013). We expect that abstractness, used in conjunction features (e.g., a feature denoting that the subject is abstract and the verb is concrete), is especially useful: semantically, an abstract agent performing a concrete action is a strong signal of metaphorical usage. Although often correlated with abstractness, imageability is not a redundant property. While most abstract things are hard to visualize, some call up images, e.g., vengeance calls up an emotional image, torture calls up emotions and even visual images. There are concrete things that are hard to visualize to</context>
<context position="21604" citStr="Turney et al. (2011)" startWordPosition="3284" endWordPosition="3287">nd AN training sets. # FEAT column shows a number of features. ACC column reports an accuracy score in the 10- fold cross validation. Statistically significant differences (p &lt; 0.01) from the all-feature combination are marked with a star. These results show superior performance over previous state-of-the-art results, confirming our hypothesis that conceptual features are effective in metaphor classification. For the SVO task, the cross-validation accuracy is about 10% better than that of Tsvetkov et al. (2013). For the AN task, the cross validation accuracy is better by 8% than the result of Turney et al. (2011) (two baseline 252 methods are described in Section 5.2). We can see that all types of features have good performance on their own (VSM is the strongest feature type). Noun supersense features alone allows us to achieve an accuracy of 75%, i.e., adjective supersense features contribute 4% to adjective-noun supersense feature combination. Experiments with the pairs of features yield better results than individual features, implying that the feature categories are not redundant. Yet, combining all features leads to even higher accuracy during crossvalidation. In the case of the AN task, a differ</context>
<context position="24829" citStr="Turney et al., 2011" startWordPosition="3838" endWordPosition="3841">= 0.77) AbsImg (area = 0.73) VSM (area = 0.8) All (area = 0.79) 0.00.0 0.2 0.4 0.6 0.8 1.0 False Positive Rate (a) SVO 1.0 0.8 0.6 0.4 AbsImg (area = 0.9) Supersenses (area = 0.86) VSM (area = 0.89) All (area = 0.92) 0.00.0 0.2 0.4 0.6 0.8 1.0 False Positive Rate (b) AN Figure 1: ROC curves for classifiers trained using different feature sets (English SVO and AN test sets). According to ROC plots in Figure 1, all three feature sets are effective, both for SVO and for AN tasks. Abstractness and Imageability features work better for adjectives and nouns, which is in line with previous findings (Turney et al., 2011; Broadwell et al., 2013). It can be also seen that VSM features are very effective. This is in line with results of Hovy et al. (2013), who found that it is hard to improve over the classifier that uses only VSM features. 5.2 Comparison to baselines In this section, we compare our method to state-ofthe-art methods of Tsvetkov et al. (2013) and of Turney et al. (2011), who focused on classifying SVO and AN relations, respectively. In the case of SVO relations, we use software 0.2 0.2 253 and datasets from Tsvetkov et al. (2013). These datasets, denoted as an SVO-baseline, consist of 98 English</context>
<context position="26265" citStr="Turney et al. (2011)" startWordPosition="4079" endWordPosition="4082">r probabilities as Tsvetkov et al. (2013). Our approach is different from that of Tsvetkov et al. (2013) in that it uses additional features (vector space word representations) and a different classification method (we use random forests while Tsvetkov et al. (2013) use logistic regression). According to Table 3, we obtain higher performance scores for both Russian and English. EN RU SVO-baseline 0.78 0.76 This work 0.86 0.85 Table 3: Comparing f-scores of our SVO metaphor detection method to the baselines. In the case of AN relations, we use the dataset (denoted as an AN-baseline) created by Turney et al. (2011) (see Section 4.1 in the referred paper for details). Turney et al. (2011) manually annotated 100 pairs where an adjective was one of the following: dark, deep, hard, sweet, and worm. The pairs were presented to five human judges who rated each pair on a scale from 1 (very literal/denotative) to 4 (very nonliteral/connotative). Turney et al. (2011) train logistic-regression employing only abstractness ratings as features. Performance of the method was evaluated using the 10-fold cross-validation separately for each judge. We replicate the above described evaluation procedure of Turney et al. (</context>
<context position="32020" citStr="Turney et al. (2011)" startWordPosition="5004" endWordPosition="5007">re instrumental in the correct classification of these examples: &lt;noun.person,verb.motion&gt; is usually used literally, while &lt;noun.act,verb.motion&gt; is used metaphorically. 6 Related Work For a historic overview and a survey of common approaches to metaphor detection, we refer the reader to recent reviews by Shutova et al. (Shutova, 2010; Shutova et al., 2013). Here we focus only on recent approaches. Shutova et al. (2010) proposed a bottom-up method: one starts from a set of seed metaphors and seeks phrases where verbs and/or nouns belong to the same cluster as verbs or nouns in seed examples. Turney et al. (2011) show how abstractness scores could be used to detect metaphorical AN phrases. Neuman et al. (2013) describe a Concrete Category Overlap algorithm, where co-occurrence statistics and Turney’s abstractness scores are used to determine WordNet supersenses that correspond to literal usage of a given adjective or verb. For example, given an adjective, we can learn that it modifies concrete nouns that usually have the EN (area = 0.79) ES (area = 0.71) FA (area = 0.69) RU (area = 0.89) False Positive Rate 0.8 0.6 0.4 0.00.0 0.2 0.4 0.6 0.8 1.0 0.2 1.0 EN (area = 0.92) ES (area = 0.73) FA (area = 0.8</context>
</contexts>
<marker>Turney, Neuman, Assaf, Cohen, 2011</marker>
<rawString>Peter D. Turney, Yair Neuman, Dan Assaf, and Yohai Cohen. 2011. Literal and metaphorical sense identification through concrete and abstract context. In Proc. of EMNL, pages 680–690.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick Wilks</author>
</authors>
<title>Making preferences more active.</title>
<date>1978</date>
<journal>Artificial Intelligence,</journal>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="4621" citStr="Wilks (1978)" startWordPosition="694" endWordPosition="695">8, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics tual (rather than lexical) in nature by showing that our English-trained model can detect metaphors in Spanish, Farsi, and Russian. 2 Methodology Our task in this work is to define features that distinguish between metaphoric and literal uses of two syntactic constructions: subject-verb-object (SVO) and adjective-noun (AN) tuples.4 We give examples of a prototypical metaphoric usage of each type: • SVO metaphors. A sentence containing a metaphoric SVO relation is my car drinks gasoline. According to Wilks (1978), this metaphor represents a violation of selectional preferences for the verb drink, which is normally associated with animate subjects (the car is inanimate and, hence, cannot drink in the literal sense of the verb). • AN metaphors. The phrase broken promise is an AN metaphor, where attributes from a concrete domain (associated with the concrete word broken) are transferred to a more abstract domain, which is represented by the relatively abstract word promise. That is, we map an abstract concept promise to a concrete domain of physical things, where things can be literally broken to pieces.</context>
</contexts>
<marker>Wilks, 1978</marker>
<rawString>Yorick Wilks. 1978. Making preferences more active. Artificial Intelligence, 11(3):197–223.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>