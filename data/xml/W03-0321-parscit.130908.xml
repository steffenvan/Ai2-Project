<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.026061">
<title confidence="0.9949075">
Comparing the Sentence Alignment Yield from Two News
Corpora Using a Dictionary-Based Alignment System
</title>
<author confidence="0.7157065">
Stephen Nightingale Hideki Tanaka
ATR, Kyoto, JAPAN ATR, Kyoto, JAPAN
</author>
<email confidence="0.865338">
Stephen.Nightingale@atr.co.jp Hideki .Tanaka@atr . co . jp
</email>
<sectionHeader confidence="0.993709" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999763857142857">
Corpus-based MT requires the input of
large sentence aligned bilingual corpora,
but these are hard to find for Japanese.
Bilingual news corpora seem to offer a use-
ful resource for Machine Translation, but
their quality is variable. Sentence align-
ments produced by filtering literal word
translations from the NHK corpus yield dis-
appointing results, though correlating NP
translations performs better. Using this
method gets even better results from the
Nikkei corpus. This paper reports sentence
alignment results from 2 corpora, in a 2-
pass dictionary based alignment system.
</bodyText>
<sectionHeader confidence="0.991584" genericHeader="keywords">
1 Credits
</sectionHeader>
<bodyText confidence="0.998841666666667">
The research for this paper was done under a grant
from the Telecommunications Advanced Organiza-
tion (TAO) of Japan.
</bodyText>
<sectionHeader confidence="0.998934" genericHeader="introduction">
2 Introduction
</sectionHeader>
<bodyText confidence="0.999942431818182">
Large, sentence-aligned bilingual corpora suitable for
input to corpus-based Machine Translation are not
a natural product of the translator&apos;s art. They are
specifically crafted and selected for a high degree of
word and phrase alignment. There is a healthy body
of literature attesting to this fact, with simple length-
based methods (Gale and Church, 1991), dictionary-
based alignments such as (Haruno and Yamazaki,
1996), and more sophisticated bags of words ap-
proaches, suitable for noisy corpora, such as Kvec
(Fung and Church, 1993). All these methods are in-
tended to produce aligned corpora which can be in-
put to Statistical Machine Translation (SMT) train-
ing. With noisy corpora such as news article trans-
lation pairs, some are more free translations, some
summarizations. Occasionally too, there are close
literal translations. The NHK and Nikkei are two
different news corpora which have been reported in
ICSLP (Tanaka et al, 2002). Attempts to sentence-
align the NHK corpus using numerically derived sin-
gle word correspondences have been disappointing
(Nightingale and Tanaka, 2002). We therefore rede-
veloped the alignment method to give the dictionary
check primacy over the statistical comparator, and
modified its scope to find Noun Phrase translations
first (Nightingale and Tanaka, 2003). The method
is applied in a second pass to find sentence align-
ments, taking account of the NP alignments already
discovered, but still the proportion of incommensu-
rable sentence pairs is very high. More recently, a
part of the Nikkei corpus became available, and we
applied the same method so that: (a) the two cor-
pora could be compared for their yield, and (b) so
that we could realize a larger aligned corpus for MT
investigations. The Nikkei corpus yields better re-
sults using the same method. Both the alignment
method and the results are described in this paper.
After some brief description of the corpora in Sec-
tion 3, the alignment method is shown in Section
4, in three parts, with the Many-to-1 tokenization,
translation candidate generation, and the dictionary
filtering separately described. The alignment results
for NPs and for sentences are given in Section 5, with
some concluding remarks in 6.
</bodyText>
<sectionHeader confidence="0.994399" genericHeader="method">
3 The Corpora
</sectionHeader>
<bodyText confidence="0.995982416666667">
The NHK and Nikkei are news article corpora, hav-
ing typically 4-10 sentences in each article, average
lengths 20+ words, with no guarantee of 1-for-1 sen-
tence alignment. NHK comprises 41.1K article pairs
covering 1995-2000, which we split into two parts ac-
cording to news genre, with 29.6K and 11.5K; Nikkei
has 1929 article pairs from July 2000. To extract
and correlate word groups such as Noun Phrases,
we parse the corpora using (Charniak, 2001) for En-
glish, and CaboCha (Kudoh and Matsumoto, 2000)
for Japanese. A Charniak parse is shown in the ex-
ample below.
</bodyText>
<equation confidence="0.987503166666667">
(Si (NP (DT the) (NN team))
(VP (MD will)
(ADVP (RB also))
(VP (VB compare)
(NP (NN risk) (NN capital) (NNS allocations))
(PP (IN with) (NP (NN profitability)))))
</equation>
<bodyText confidence="0.999764666666667">
We find the phrasal structures in the sentence using
a lexicalization program which extracts the words or
POS&apos;s according to parameter, as in this list:
</bodyText>
<listItem confidence="0.98951875">
(a) NP = the team
(b) NP = risk capital allocations
(c) NP = profitability
(d) PP = with profitability
(e) VP = compare NP
(f) VP = will ADVP VP
(g) S = the team will also compare risk capital allo-
cations with profitability
</listItem>
<bodyText confidence="0.999959666666667">
The sentence contains 3 NPs extracted fully lexi-
calized, a PP, 2 VPs extracted partially lexicalized
and a sentence, S fully lexicalized. The corpora con-
tain many thousands of NPs, VPs and sentences
which can be thus extracted. A separate program
lexicalizes the dependency chunks of Japanese. In
the case of investigating NP alignments, all other
structures are filtered out. The sentence counts and
unique NP counts are given in Table 1. The Nikkei
shows a much higher proportion of Unique NPs than
the NHK, with similar numbers of NPs (38K E/55K
J) from a much smaller corpus.
</bodyText>
<table confidence="0.85449575">
Corpus Articles Sents Unq NPs
NHK 1 29.6K 218K /180K 57K /32K
NHK2 11.5K 86K/81K 37K/28K
Nikkei 1929 21K/15K 38K/55K
</table>
<tableCaption confidence="0.999555">
Table 1: NHK and Nikkei Corpus Statistics
</tableCaption>
<sectionHeader confidence="0.979692" genericHeader="method">
4 Extracting Alignments
</sectionHeader>
<bodyText confidence="0.999878625">
Investigations of the EGYPT tools (Al Onaizan et al,
2000; Och and Ney, 2000) for SMT show that the sur-
face details of the two languages are abstracted away
from the problem of identifying translation candi-
dates (or token alignments). EGYPT&apos;s Whittle cor-
pus pre-processor tokenizes the vocabulary in source
and target corpora and maps words to tokens 1-to-1.
An example of input is given below, with a sentence
</bodyText>
<figure confidence="0.5891435">
English Compound Frequency
205
7J-N&apos; Ai • 7N b A 204
117K ti&apos;M A tr&amp;quot; 204
</figure>
<tableCaption confidence="0.961926">
Table 2: Noun Phrases
</tableCaption>
<bodyText confidence="0.9974462">
from the Japanese input file in 1(a) and its trans-
lation from the English input file in 1(b). Whittle
tokenizes the vocabulary and maps words to tokens
as in (2) (a) and (b), where each unique word form
associates with a single value.
</bodyText>
<equation confidence="0.970159833333333">
1(a) 9 ) — /l
&amp;quot;C. &lt; to a
1(b) bring me one small bottle of chilled mineral wa-
ter please .
2(a) 5899 14 1303 6 1383 4031 8 97 143 16 2
2(b) 195 18 39 231 547 24 3857 1101 169 9 2
</equation>
<bodyText confidence="0.999965866666667">
EGYPT&apos;s Giza, the SMT training tool engine
takes these token vector pairs and performs the IBM
Model 1-5 transformations (Brown, et al, 1993) to
generate a translation model. Because of the ab-
straction, Giza only knows about these token vectors
and not about words and sentences. It is perfectly
feasible therefore to map more complex word groups
onto single tokens, in this instance parsed phrasal
structures. Although we ultimately departed from
EGYPT, this was one of the inspirations for our mod-
ularization discussed below. Because we extracted
phrasal chunks from the corpus, these are tokenized
with many words mapped to one token (4.1). Can-
didate generation proceeds with these token vector
pairs (4.2), followed by dictionary filtering (4.3).
</bodyText>
<subsectionHeader confidence="0.976187">
4.1 Flexible Tokenization
</subsectionHeader>
<bodyText confidence="0.999780428571428">
The tokenizer takes as input pairs of word strings,
which may be phrases or sentences, articles or para-
graphs: the surface form can be identical to that
taken by Whittle. These need not be complete sen-
tences. The primary sources are filtered for salient
features such as Noun Phrases, discarding verbal
phenomena and function words. The tokenizer also
takes as input lists of word groups, such as NPs, to
be identified in the source strings, and mapped onto
single tokens. Examples (not translation pairs) of
such NP lists are given in Table 2, with determiners
and postpositions pruned. Nouns occurring singly
(e.g civilians) are not excluded.
The strategy is to first tokenize individual words,
</bodyText>
<figure confidence="0.984456333333333">
civilians
110
chemical weapons 110
foreign ministry spokesman 109
Japanese Compound
Frequency
</figure>
<bodyText confidence="0.999448083333333">
and separately tokenize the word group lists, then
map words to tokens 1-for-1, to create token vec-
tors. In a second pass, the token sequences from the
word group lists are substituted into the token vec-
tors, thus compressing them. As example, the sen-
tence pair in 1(a) and (b) can be filtered for Noun
Phrases, yielding the result in 3 (a) and (b), and
mapped onto tokens in 4(a) and (b). The tokenized
word groups are then remapped to give the tokenized
NP sequences in 5(a) and (b), where for example the
string &amp;quot;one small bottle&amp;quot; maps to the unique token
9991.
</bodyText>
<equation confidence="0.870266166666667">
3(a) )1.1, — — (/J■ )
3(b) (me) (one small bottle) (chilled mineral water)
(5899 14 1303) (1383 4031)
(18) (39 231 547) (3857 1101 169)
9990 9999
18 9991 9992
</equation>
<bodyText confidence="0.9643216">
Following translation candidate generation we ex-
pect to see the pairings: 11\ = one_small _bottle,
and
chilled_mineral_water identified as translation
pairs.
</bodyText>
<table confidence="0.950135857142857">
4.2 Translation Candidate Generation
Japanese English
-f ,=1 —*:=1 a J--)li — )li foreign schools
9T-111 A foreign schools
$1.1M E&apos;E foreign schools
IA W foreign schools
ft- foreign schools
</table>
<tableCaption confidence="0.99907">
Table 3: Raw Translation Candidates
</tableCaption>
<bodyText confidence="0.999016130434783">
Previous experiments (Nightingale and Tanaka,
2003) compared the results of translation candidate
generation and statistical filtering using various nu-
meric comparators, then compared the filtered re-
sults against dictionary translations. For example
applying a Mutual Information value and selecting
the higher values as plausible translations; or apply-
ing the EM algorithm over word counts and select-
ing the higher probabilities as plausible translations.
When we compare these against exhaustive genera-
tion/selection by dictionary matching (Section 4.3),
we find that the exhaustive method yields more plau-
sible translation candidates. For this exercise we
use the exhaustive method, generating M * N token
pairs over all sentence pairs. This yields 6.4M candi-
dates for NHK1, 2M for NHK2 and 342K for Nikkei.
This generation creates candidates which are token
pairs. These are relexicalized to produce entries such
as those in Table 3, with no statistical comparator.
There are many inappropriate candidates (Nos. 3, 4,
5 and more) and a few appropriate (Nos. 1, 2). Se-
lection is performed entirely by the dictionary filter,
next.
</bodyText>
<subsectionHeader confidence="0.98819">
4.3 The Dictionary Filter
</subsectionHeader>
<bodyText confidence="0.999979333333333">
When the volume of good translation results depends
on the magnitude and word sense variation of the dic-
tionary it behooves you to get a big dictionary. We
use the combination of EDICT, ENAMDICT and EI-
JIRO with a total of 1.2M entries. ENAMDICT with
200K names is particularly important for matching
news articles, which contain many such references.
The method of accounting for dictionary equivalence
is fully described in (Nightingale and Tanaka, 2003).
Briefly, we count word matches in translation candi-
date pairs and for each unique English NP take the
pair with the highest number of matches. In Table 3,
the second entry with 2 overlaps is accepted (foreign
schools = 9l-111 A [foreign person school]). Plu-
rals are dealt with by lemmatization heuristics, so
schools=school. When checking for sentence align-
ment we add a prior check of the known NP pairs to
yield a total word+phrase match count.
</bodyText>
<sectionHeader confidence="0.999212" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.998532357142857">
First Pass: NP Alignments: In NHK1 with 218K
English and 180K Japanese sentences there are 57K
and 32K, NPs. The alignment finds 24504 unique
translation candidates, or 43% of the English NPs.
Results from the second part of the NHK corpus are
in the same range, with 12.2K found from 37K or
33%. The results of processing the Nikkei corpus
are significantly better. Of 38K English NPs the ex-
traction process yields 24.3K or 64%. Training to
establish verb frame translations was less successful
since our corpora generally have a low literal transla-
tion rate: because Verbs are not always translated as
Verbs, and actual verb translations used in practice
differ from forms which can be found in the dictio-
nary.
Second Pass: Sentence Alignments: Aligned
sentence pairs are discovered by lexicalizing sen-
tential clauses extracted from the Charniak and
Cabocha parses. From the Nikkei corpus with
21K/15K English and Japanese sentence pairs, we
find 2825 pairs containing 6 or more matching word
or phrases. An example with 10 matches is given
in Table 4. 2825/21K gives us about a 13.5% re-
covery rate. This means that no adequate literal
translation can be found among the Japanese sen-
tences for 18K of the English sentences. There are a
very few existing Japanese English corpora of around
150K sentence pairs: the ATR Basic Travel Expres-
</bodyText>
<table confidence="0.9983363">
Counts word overlap=10, jlength=52, elength=36
Japanese
OM _I 1,,= J: 6 L &apos;1: 9i, )k — t — M El* 1-- M Wr t 6&apos;MPP (1) MC IR* b lt VX* (1) al
— AL Z4)6 .1 L. M 3.-}ii■-D t,-..
English it costs foreign companies between four and 11 times more to set up manufacturing
operations in japan than in europe and the u s according to a survey by the japan external
trade organization jetro .
Matches EI 7# =japan (japan) W A =trade (trade),=&apos;; x. b 0 =external (japanese external trade
organization) t =set (set) DM =survey (survey) &apos;:: 9is =foreign (foreign) b =cost (cost)
KOK =europe (europe k america) IN =four (four) ffi =times (times)
</table>
<tableCaption confidence="0.99987">
Table 4: Results of Sentence Alignment
</tableCaption>
<bodyText confidence="0.999830833333333">
sions Corpus, and the Yomiuri News Corpus, both
of which have been in great part hand-aligned. In
order to generate a parallel corpus automatically of
this size, we would need to start with a raw corpus
of about 1 million sentence pairs, assuming the same
translation quality holds throughout. In contrast the
NHK alignments are much poorer using the 6 or more
dictionary matches criterion, with 1265 aligned sen-
tences from 200K, or 0.63%, and 656 aligned sen-
tences from 86K, or 0.76%. Most of the translation
candidates have match counts lower than 6, probably
too low to merit their inclusion as aligned sentences.
</bodyText>
<sectionHeader confidence="0.999671" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999898642857143">
Content-aligned news corpora should be suitable raw
material for training corpora, but different transla-
tion strategies seem to yield different proportions of
literal versus stylistic translation candidates. The
two news corpora we sentence-aligned yield differ-
ing results, with a higher proportion extracted from
the Nikkei than the NHK. In both cases there is a
big reduction from the content-aligned source corpus
to sentence alignments we hope are more suitable
as MT input. Perhaps higher correlations can be
achieved using richer linguistic means such as expres-
sion and idiom matching, and perhaps Corpus Based
methods can be applied iteratively to help achieve
these.
</bodyText>
<sectionHeader confidence="0.999512" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999322090909091">
Al Onaizan. Yaser et al. 2000. Statistical Machine
Translation, Final Report. Johns Hopkins Univer-
sity, Baltimore, MD.
Brown. Peter et al. 1993. The Mathematics of Ma-
chine Translation: Parameter Estimation. Com-
putational Linguistics, vol 19, number 2, pp 263-
311, 1993.
Charniak, Eugene.: 2001. Immediate Head Parsing
for Language Models. In Proceedings of the 39th
Annual Meeting of the Association for Computa-
tional Linguistics, 2001
Fung, Pascale. and Church, Kenneth. W. 1993. K-
Vec: A New Approach for Aligning Parallel Texts.
In Proceedings 15th COLING pp 1096-1102 (1994)
Gale, William .A. and Church, Kenneth .W. 1991. A
Program for Aligning Sentences in Bilingual Cor-
pora. ACL 1991 pp177-184.
Haruno. Masahiko. and Yamazaki. Takefumi. 1991.
High-Performance Bilingual Text Alignment Using
Statistical and Dictionary Information. ACL 1996
pp131-138.
Kudoh, Taku. and Matsumoto, Yuji. 2000. Japanese
Dependency Structure Analysis Based on Support
Vector Machines. In Empirical Methods in Natu-
ral Language processing and Very Large Corpora,
Pages 18-25, 2000
Nightingale, Stephen. and Tanaka, Hideki. 2002.
Aligning for SMT: Results from Real World Cor-
pora. Presented at the Forum on Information
Technology, FIT, Tokyo.
Nightingale, Stephen. and Tanaka, Hideki. 2003.
The Word is Mightier than the Count: Accumu-
lating Translation Resources from Parsed Parallel
Corpora. in Proceedings CICLing 2003, Springer-
Verlag LNCS 2588 pp420-431, Alexander Gelbukh
(Ed).
Och, Franz Josef. and Ney, Hermann. 2000. Im-
proved Statistical Alignment Models. in Proceed-
ings of the 38th Annual Meeting of the Associa-
tion for Computational Linguistics, pp. 440-447,
Hongkong, China, October 2000.
Tanaka, Hideki. et al. 2002. Speech to Speech Trans-
lation System for Monologues — Data Drivers Ap-
proach ICSLP, Denver Colorado, 2002
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.250524">
<title confidence="0.999254">Comparing the Sentence Alignment Yield from Two Corpora Using a Dictionary-Based Alignment System</title>
<author confidence="0.997347">Stephen Nightingale Hideki Tanaka</author>
<address confidence="0.349411">ATR, Kyoto, JAPAN ATR, Kyoto, JAPAN</address>
<author confidence="0.946594">Stephen Nightingaleatr co jp Hideki Tanakaatr</author>
<abstract confidence="0.9997142">Corpus-based MT requires the input of large sentence aligned bilingual corpora, but these are hard to find for Japanese. Bilingual news corpora seem to offer a useful resource for Machine Translation, but their quality is variable. Sentence alignments produced by filtering literal word translations from the NHK corpus yield disappointing results, though correlating NP translations performs better. Using this method gets even better results from the Nikkei corpus. This paper reports sentence alignment results from 2 corpora, in a 2pass dictionary based alignment system.</abstract>
<note confidence="0.86782925">1 Credits The research for this paper was done under a grant from the Telecommunications Advanced Organization (TAO) of Japan.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yaser</author>
</authors>
<title>Statistical Machine Translation, Final Report. Johns Hopkins University,</title>
<date>2000</date>
<location>Baltimore, MD.</location>
<marker>Yaser, 2000</marker>
<rawString>Al Onaizan. Yaser et al. 2000. Statistical Machine Translation, Final Report. Johns Hopkins University, Baltimore, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter</author>
</authors>
<title>The Mathematics of Machine Translation: Parameter Estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<pages>263--311</pages>
<marker>Peter, 1993</marker>
<rawString>Brown. Peter et al. 1993. The Mathematics of Machine Translation: Parameter Estimation. Computational Linguistics, vol 19, number 2, pp 263-311, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>Immediate Head Parsing for Language Models.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<contexts>
<context position="3635" citStr="Charniak, 2001" startWordPosition="572" endWordPosition="573">e dictionary filtering separately described. The alignment results for NPs and for sentences are given in Section 5, with some concluding remarks in 6. 3 The Corpora The NHK and Nikkei are news article corpora, having typically 4-10 sentences in each article, average lengths 20+ words, with no guarantee of 1-for-1 sentence alignment. NHK comprises 41.1K article pairs covering 1995-2000, which we split into two parts according to news genre, with 29.6K and 11.5K; Nikkei has 1929 article pairs from July 2000. To extract and correlate word groups such as Noun Phrases, we parse the corpora using (Charniak, 2001) for English, and CaboCha (Kudoh and Matsumoto, 2000) for Japanese. A Charniak parse is shown in the example below. (Si (NP (DT the) (NN team)) (VP (MD will) (ADVP (RB also)) (VP (VB compare) (NP (NN risk) (NN capital) (NNS allocations)) (PP (IN with) (NP (NN profitability))))) We find the phrasal structures in the sentence using a lexicalization program which extracts the words or POS&apos;s according to parameter, as in this list: (a) NP = the team (b) NP = risk capital allocations (c) NP = profitability (d) PP = with profitability (e) VP = compare NP (f) VP = will ADVP VP (g) S = the team will a</context>
</contexts>
<marker>Charniak, 2001</marker>
<rawString>Charniak, Eugene.: 2001. Immediate Head Parsing for Language Models. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics, 2001</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
</authors>
<title>KVec: A New Approach for Aligning Parallel Texts.</title>
<date>1993</date>
<booktitle>In Proceedings 15th COLING</booktitle>
<pages>1096--1102</pages>
<contexts>
<context position="1496" citStr="Church, 1993" startWordPosition="224" endWordPosition="225">m the Telecommunications Advanced Organization (TAO) of Japan. 2 Introduction Large, sentence-aligned bilingual corpora suitable for input to corpus-based Machine Translation are not a natural product of the translator&apos;s art. They are specifically crafted and selected for a high degree of word and phrase alignment. There is a healthy body of literature attesting to this fact, with simple lengthbased methods (Gale and Church, 1991), dictionarybased alignments such as (Haruno and Yamazaki, 1996), and more sophisticated bags of words approaches, suitable for noisy corpora, such as Kvec (Fung and Church, 1993). All these methods are intended to produce aligned corpora which can be input to Statistical Machine Translation (SMT) training. With noisy corpora such as news article translation pairs, some are more free translations, some summarizations. Occasionally too, there are close literal translations. The NHK and Nikkei are two different news corpora which have been reported in ICSLP (Tanaka et al, 2002). Attempts to sentencealign the NHK corpus using numerically derived single word correspondences have been disappointing (Nightingale and Tanaka, 2002). We therefore redeveloped the alignment metho</context>
</contexts>
<marker>Church, 1993</marker>
<rawString>Fung, Pascale. and Church, Kenneth. W. 1993. KVec: A New Approach for Aligning Parallel Texts. In Proceedings 15th COLING pp 1096-1102 (1994)</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
</authors>
<title>A Program for Aligning Sentences in Bilingual Corpora.</title>
<date>1991</date>
<pages>177--184</pages>
<publisher>ACL</publisher>
<contexts>
<context position="1317" citStr="Gale and Church, 1991" startWordPosition="194" endWordPosition="197">ikkei corpus. This paper reports sentence alignment results from 2 corpora, in a 2- pass dictionary based alignment system. 1 Credits The research for this paper was done under a grant from the Telecommunications Advanced Organization (TAO) of Japan. 2 Introduction Large, sentence-aligned bilingual corpora suitable for input to corpus-based Machine Translation are not a natural product of the translator&apos;s art. They are specifically crafted and selected for a high degree of word and phrase alignment. There is a healthy body of literature attesting to this fact, with simple lengthbased methods (Gale and Church, 1991), dictionarybased alignments such as (Haruno and Yamazaki, 1996), and more sophisticated bags of words approaches, suitable for noisy corpora, such as Kvec (Fung and Church, 1993). All these methods are intended to produce aligned corpora which can be input to Statistical Machine Translation (SMT) training. With noisy corpora such as news article translation pairs, some are more free translations, some summarizations. Occasionally too, there are close literal translations. The NHK and Nikkei are two different news corpora which have been reported in ICSLP (Tanaka et al, 2002). Attempts to sent</context>
</contexts>
<marker>Gale, Church, 1991</marker>
<rawString>Gale, William .A. and Church, Kenneth .W. 1991. A Program for Aligning Sentences in Bilingual Corpora. ACL 1991 pp177-184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masahiko</author>
<author>Yamazaki Takefumi</author>
</authors>
<title>High-Performance Bilingual Text Alignment Using Statistical and Dictionary Information. ACL</title>
<date>1991</date>
<pages>131--138</pages>
<marker>Masahiko, Takefumi, 1991</marker>
<rawString>Haruno. Masahiko. and Yamazaki. Takefumi. 1991. High-Performance Bilingual Text Alignment Using Statistical and Dictionary Information. ACL 1996 pp131-138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuji Matsumoto</author>
</authors>
<title>Japanese Dependency Structure Analysis Based on Support Vector Machines.</title>
<date>2000</date>
<booktitle>In Empirical Methods in Natural Language processing and Very Large Corpora,</booktitle>
<pages>18--25</pages>
<contexts>
<context position="3688" citStr="Matsumoto, 2000" startWordPosition="581" endWordPosition="582">gnment results for NPs and for sentences are given in Section 5, with some concluding remarks in 6. 3 The Corpora The NHK and Nikkei are news article corpora, having typically 4-10 sentences in each article, average lengths 20+ words, with no guarantee of 1-for-1 sentence alignment. NHK comprises 41.1K article pairs covering 1995-2000, which we split into two parts according to news genre, with 29.6K and 11.5K; Nikkei has 1929 article pairs from July 2000. To extract and correlate word groups such as Noun Phrases, we parse the corpora using (Charniak, 2001) for English, and CaboCha (Kudoh and Matsumoto, 2000) for Japanese. A Charniak parse is shown in the example below. (Si (NP (DT the) (NN team)) (VP (MD will) (ADVP (RB also)) (VP (VB compare) (NP (NN risk) (NN capital) (NNS allocations)) (PP (IN with) (NP (NN profitability))))) We find the phrasal structures in the sentence using a lexicalization program which extracts the words or POS&apos;s according to parameter, as in this list: (a) NP = the team (b) NP = risk capital allocations (c) NP = profitability (d) PP = with profitability (e) VP = compare NP (f) VP = will ADVP VP (g) S = the team will also compare risk capital allocations with profitabili</context>
</contexts>
<marker>Matsumoto, 2000</marker>
<rawString>Kudoh, Taku. and Matsumoto, Yuji. 2000. Japanese Dependency Structure Analysis Based on Support Vector Machines. In Empirical Methods in Natural Language processing and Very Large Corpora, Pages 18-25, 2000</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Tanaka</author>
</authors>
<title>Aligning for SMT: Results from Real World Corpora. Presented at the Forum on Information Technology,</title>
<date>2002</date>
<location>FIT, Tokyo.</location>
<contexts>
<context position="2050" citStr="Tanaka, 2002" startWordPosition="310" endWordPosition="311">ble for noisy corpora, such as Kvec (Fung and Church, 1993). All these methods are intended to produce aligned corpora which can be input to Statistical Machine Translation (SMT) training. With noisy corpora such as news article translation pairs, some are more free translations, some summarizations. Occasionally too, there are close literal translations. The NHK and Nikkei are two different news corpora which have been reported in ICSLP (Tanaka et al, 2002). Attempts to sentencealign the NHK corpus using numerically derived single word correspondences have been disappointing (Nightingale and Tanaka, 2002). We therefore redeveloped the alignment method to give the dictionary check primacy over the statistical comparator, and modified its scope to find Noun Phrase translations first (Nightingale and Tanaka, 2003). The method is applied in a second pass to find sentence alignments, taking account of the NP alignments already discovered, but still the proportion of incommensurable sentence pairs is very high. More recently, a part of the Nikkei corpus became available, and we applied the same method so that: (a) the two corpora could be compared for their yield, and (b) so that we could realize a </context>
</contexts>
<marker>Tanaka, 2002</marker>
<rawString>Nightingale, Stephen. and Tanaka, Hideki. 2002. Aligning for SMT: Results from Real World Corpora. Presented at the Forum on Information Technology, FIT, Tokyo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Tanaka</author>
</authors>
<title>The Word is Mightier than the Count: Accumulating Translation Resources from Parsed Parallel Corpora.</title>
<date>2003</date>
<booktitle>in Proceedings CICLing 2003, SpringerVerlag LNCS</booktitle>
<volume>2588</volume>
<pages>420--431</pages>
<location>Alexander Gelbukh (Ed).</location>
<contexts>
<context position="2260" citStr="Tanaka, 2003" startWordPosition="341" endWordPosition="342">ch as news article translation pairs, some are more free translations, some summarizations. Occasionally too, there are close literal translations. The NHK and Nikkei are two different news corpora which have been reported in ICSLP (Tanaka et al, 2002). Attempts to sentencealign the NHK corpus using numerically derived single word correspondences have been disappointing (Nightingale and Tanaka, 2002). We therefore redeveloped the alignment method to give the dictionary check primacy over the statistical comparator, and modified its scope to find Noun Phrase translations first (Nightingale and Tanaka, 2003). The method is applied in a second pass to find sentence alignments, taking account of the NP alignments already discovered, but still the proportion of incommensurable sentence pairs is very high. More recently, a part of the Nikkei corpus became available, and we applied the same method so that: (a) the two corpora could be compared for their yield, and (b) so that we could realize a larger aligned corpus for MT investigations. The Nikkei corpus yields better results using the same method. Both the alignment method and the results are described in this paper. After some brief description of</context>
<context position="8700" citStr="Tanaka, 2003" startWordPosition="1440" endWordPosition="1441">unique token 9991. 3(a) )1.1, — — (/J■ ) 3(b) (me) (one small bottle) (chilled mineral water) (5899 14 1303) (1383 4031) (18) (39 231 547) (3857 1101 169) 9990 9999 18 9991 9992 Following translation candidate generation we expect to see the pairings: 11\ = one_small _bottle, and chilled_mineral_water identified as translation pairs. 4.2 Translation Candidate Generation Japanese English -f ,=1 —*:=1 a J--)li — )li foreign schools 9T-111 A foreign schools $1.1M E&apos;E foreign schools IA W foreign schools ft- foreign schools Table 3: Raw Translation Candidates Previous experiments (Nightingale and Tanaka, 2003) compared the results of translation candidate generation and statistical filtering using various numeric comparators, then compared the filtered results against dictionary translations. For example applying a Mutual Information value and selecting the higher values as plausible translations; or applying the EM algorithm over word counts and selecting the higher probabilities as plausible translations. When we compare these against exhaustive generation/selection by dictionary matching (Section 4.3), we find that the exhaustive method yields more plausible translation candidates. For this exer</context>
<context position="10263" citStr="Tanaka, 2003" startWordPosition="1684" endWordPosition="1685">ndidates (Nos. 3, 4, 5 and more) and a few appropriate (Nos. 1, 2). Selection is performed entirely by the dictionary filter, next. 4.3 The Dictionary Filter When the volume of good translation results depends on the magnitude and word sense variation of the dictionary it behooves you to get a big dictionary. We use the combination of EDICT, ENAMDICT and EIJIRO with a total of 1.2M entries. ENAMDICT with 200K names is particularly important for matching news articles, which contain many such references. The method of accounting for dictionary equivalence is fully described in (Nightingale and Tanaka, 2003). Briefly, we count word matches in translation candidate pairs and for each unique English NP take the pair with the highest number of matches. In Table 3, the second entry with 2 overlaps is accepted (foreign schools = 9l-111 A [foreign person school]). Plurals are dealt with by lemmatization heuristics, so schools=school. When checking for sentence alignment we add a prior check of the known NP pairs to yield a total word+phrase match count. 5 Results First Pass: NP Alignments: In NHK1 with 218K English and 180K Japanese sentences there are 57K and 32K, NPs. The alignment finds 24504 unique</context>
</contexts>
<marker>Tanaka, 2003</marker>
<rawString>Nightingale, Stephen. and Tanaka, Hideki. 2003. The Word is Mightier than the Count: Accumulating Translation Resources from Parsed Parallel Corpora. in Proceedings CICLing 2003, SpringerVerlag LNCS 2588 pp420-431, Alexander Gelbukh (Ed).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hermann Ney</author>
</authors>
<title>Improved Statistical Alignment Models.</title>
<date>2000</date>
<booktitle>in Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>440--447</pages>
<location>Hongkong, China,</location>
<contexts>
<context position="5131" citStr="Ney, 2000" startWordPosition="833" endWordPosition="834">separate program lexicalizes the dependency chunks of Japanese. In the case of investigating NP alignments, all other structures are filtered out. The sentence counts and unique NP counts are given in Table 1. The Nikkei shows a much higher proportion of Unique NPs than the NHK, with similar numbers of NPs (38K E/55K J) from a much smaller corpus. Corpus Articles Sents Unq NPs NHK 1 29.6K 218K /180K 57K /32K NHK2 11.5K 86K/81K 37K/28K Nikkei 1929 21K/15K 38K/55K Table 1: NHK and Nikkei Corpus Statistics 4 Extracting Alignments Investigations of the EGYPT tools (Al Onaizan et al, 2000; Och and Ney, 2000) for SMT show that the surface details of the two languages are abstracted away from the problem of identifying translation candidates (or token alignments). EGYPT&apos;s Whittle corpus pre-processor tokenizes the vocabulary in source and target corpora and maps words to tokens 1-to-1. An example of input is given below, with a sentence English Compound Frequency 205 7J-N&apos; Ai • 7N b A 204 117K ti&apos;M A tr&amp;quot; 204 Table 2: Noun Phrases from the Japanese input file in 1(a) and its translation from the English input file in 1(b). Whittle tokenizes the vocabulary and maps words to tokens as in (2) (a) and (</context>
</contexts>
<marker>Ney, 2000</marker>
<rawString>Och, Franz Josef. and Ney, Hermann. 2000. Improved Statistical Alignment Models. in Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pp. 440-447, Hongkong, China, October 2000.</rawString>
</citation>
<citation valid="true">
<title>Speech to Speech Translation System for Monologues — Data Drivers Approach ICSLP,</title>
<date>2002</date>
<location>Denver Colorado,</location>
<marker>2002</marker>
<rawString>Tanaka, Hideki. et al. 2002. Speech to Speech Translation System for Monologues — Data Drivers Approach ICSLP, Denver Colorado, 2002</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>