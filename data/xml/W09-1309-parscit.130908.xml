<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.016934">
<title confidence="0.987816">
Disambiguation of Biomedical Abbreviations
</title>
<author confidence="0.999803">
Mark Stevenson1, Yikun Guo2, Abdulaziz Al Amri3 and Robert Gaizauskas4
</author>
<affiliation confidence="0.9977325">
Department of Computer Science
University of Sheffield
</affiliation>
<address confidence="0.953070333333333">
Regent Court, 211 Portobello
Sheffield, S1 4DP
United Kingdom
</address>
<email confidence="0.997736">
1,2,4{initial.surname}@dcs.shef.ac.uk,3abdulazizmail@gmail.com
</email>
<sectionHeader confidence="0.995594" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998831764705882">
Abbreviations are common in biomedical doc-
uments and many are ambiguous in the sense
that they have several potential expansions.
Identifying the correct expansion is necessary
for language understanding and important for
applications such as document retrieval. Iden-
tifying the correct expansion can be viewed as
a Word Sense Disambiguation (WSD) prob-
lem. A WSD system that uses a variety of
knowledge sources, including two types of in-
formation specific to the biomedical domain,
is also described. This system was tested on a
corpus of ambiguous abbreviations, created by
automatically identifying the correct expan-
sion in Medline abstracts, and found to iden-
tify the correct expansion with up to 99% ac-
curacy.
</bodyText>
<sectionHeader confidence="0.999136" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9990815">
Many abbreviations are ambiguous in the sense that
they have more than one possible expansion. For
example, expansions for “NLP” include “Neuro-
linguistic Programming” as well as “Natural Lan-
guage Processing”. Ambiguous abbreviations form
a challenge to language understanding since iden-
tification of the correct expansion is often impor-
tant. The query “NLP”, for example, returns pages
which refer to “Neuro-linguistic programming” for
most web search engines, pages which are of lim-
ited value to those interested in Natural Language
Processing. In some cases this problem could be
obviated by altering the query terms, for example
including “Natural”, “Language” and “Processing”.
</bodyText>
<page confidence="0.979638">
71
</page>
<bodyText confidence="0.999464588235294">
However, this will not help when the abbreviation’s
expansion does not occur within the document. Fred
and Cheng (1999) point out that this is often the case
in biomedical documents, in this domain ubiquitous
abbreviations (such as DNA and mRNA) often ap-
pear without an expansion.
It has been reported that misinterpretation of ab-
breviations in biomedical documents has lead to
medical practitioners making fatal errors (Fred and
Cheng, 1999). However, identifying the correct ex-
pansion is not a straightforward task since an ab-
breviation may have several possible expansions.
Chang et al. (2002) reported that abbreviations in
biomedical journal articles consisting of six charac-
ters or less have an average of 4.61 possible mean-
ings and Pustejovsky et al. (2002) mention that the
simple abbreviation “AC” is associated with at least
10 strings in different biomedical documents includ-
ing “atrioventricular connection”, “anterior colpor-
rhaphy procedure”, “auditory cortex” and “atypical
carcinoid”.
The problem of identifying the correct expansion
of an ambiguous abbreviation can be viewed as a
Word Sense Disambiguation (WSD) task where the
various expansions are the “senses” of the abbrevia-
tion. In this paper we approach the problem in this
way by applying a WSD system which has previ-
ously been applied to biomedical text (Stevenson et
al., 2008). The WSD system uses a variety of infor-
mation sources, including those traditionally applied
to the WSD problem in addition to two knowledge
sources that are specific to the biomedical domain.
Evaluation of systems for disambiguating am-
biguous abbreviations has been hindered by the fact
</bodyText>
<note confidence="0.883888">
Proceedings of the Workshop on BioNLP, pages 71–79,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.9996625">
that there is no freely available benchmark corpus
against which approaches can be compared. We de-
scribe a process whereby such a corpus can be cre-
ated by automatically mining abstracts from Med-
line. This corpus is being made publicly available
to encourage comparative research in this area. Our
abbreviation disambiguation system was evaluated
against this corpus and found to identify the correct
abbreviation with up to 99% accuracy.
The remainder of this paper is organised as fol-
lows. The next section describes relevant previous
work on disambiguation of abbreviations. Section
3 describes a supervised learning WSD system tai-
lored specifically to the biomedical domain. Section
4 describes the automatic creation of a corpus of am-
biguous abbreviations designed specifically for the
training and evaluation of abbreviation disambigua-
tion systems. Section 5 describes the evaluation of
our system on this corpus. Our conclusions are pre-
sented in Section 6.
</bodyText>
<sectionHeader confidence="0.996162" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999824643835617">
Gaudan et al. (2005) distinguish two types of abbre-
viations: global and local. Global abbreviations are
those found in documents without the expansion ex-
plicitly stated, while local abbreviations are defined
in the same document in which the abbreviation oc-
curs. Our work is concerned with the problem of
disambiguating global abbreviations. Gaudan et al.
(2005) point out that global abbreviations are often
ambiguous.
Various researchers have explored the problem
of disambiguating global abbreviations in biomed-
ical documents. Liu et al. (2001)(2002) used sev-
eral domain-specific knowledge sources to identify
terms which are semantically related to each possi-
ble expansion but which have only one sense them-
selves. Instances of these terms were identified in
a corpus of biomedical journal abstracts and used
as training data. Their learning algorithm uses a
variety of features including all words in the ab-
stract and collocations of the ambiguous abbrevia-
tion. They report an accuracy of 97% on a small set
of abbreviations. Liu et al. (2004) present a fully
supervised approach. They compared a variety of
supervised machine learning algorithms and found
that the best performance over a set of 15 ambigu-
ous abbreviations, 98.6%, was obtained using Naive
Bayes. Gaudan et al. (2005) use a Support Vector
Machine trained on a bag-of-words model and re-
port an accuracy of 98.5%. Yu et al. (2006) exper-
imented with two supervised learning algorithms:
Naive Bayes and Support Vector Machines. They
extracted a corpus containing examples of 60 ab-
breviations from a set of biomedical journal articles
which was split so that abstracts in which the abbre-
viations were defined were used as training data and
those in which no definition is found as test data.
Abbreviations in the test portion were manually dis-
ambiguated. They report 79% coverage and 80%
precision using a Naive Bayes classifier. Pakho-
mov (2002) applied a maximum entropy model to
identify the meanings of ambiguous abbreviations in
10,000 rheumatology notes with around 89% accu-
racy. Joshi et al. (2006) disambiguated abbreviations
in clinical notes using three supervised learning al-
gorithms (Naive Bayes, decision trees and Support
Vector Machines). They used a range of features and
found that the best performance was obtained when
these were combined. Unfortunately direct compari-
son of these methods is made difficult by the fact that
various researchers have evaluated their approaches
on different data sets.
A variety of approaches have also been proposed
for the problem of disambiguating local abbrevia-
tions in biomedical documents. This task is equiv-
alent to identifying the abbreviation’s expansion in
the document. The problem is relatively straight-
forward for abbreviations which are created by se-
lecting the first character from each word in the ex-
pansion, such as “angiotensin converting enzyme
(ACE)”, but is more difficult when this convention
is not followed, for example “acetylchlinesterase
(ACE)”, “antisocial personality (ASP)” and “cata-
lase (CAT)”. Okazaki et al. (2008) recently pro-
posed an approach to this problem based on dis-
criminative alignment that has been shown to per-
form well. However, the most common solutions
are based on heuristic approaches, for example
Adar (2004) and Zhou et al. (2006). Pustejovsky
et al. (2002) used hand-built regular expressions.
Schwartz and Hearst (2003) describe an approach
which starts by identifying the set of candidate ex-
pansions in the same sentence as an abbreviation.
The most likely one is identified by searching for the
</bodyText>
<page confidence="0.996796">
72
</page>
<bodyText confidence="0.9979315">
shortest candidate which contains all the characters
in the abbreviation in the correct order.
</bodyText>
<sectionHeader confidence="0.934246" genericHeader="method">
3 Abbreviation Disambiguation System
</sectionHeader>
<bodyText confidence="0.999764173913044">
Our abbreviation disambiguation system is based on
a state-of-the-art WSD system that has been adapted
to the biomedical domain by augmenting it with ad-
ditional knowledge sources. The system on which
our approach is based (Agirre and Martinez, 2004)
participated in the Senseval-3 challenge (Mihalcea
et al., 2004) with a performance close to the best
system for the lexical sample tasks in two languages
while the version adapted to the biomedical domain
has achieved the best recorded results (Stevenson et
al., 2008) on a standard test set consisting of am-
biguous terms (Weeber et al., 2001).
This system is based on a supervised learning ap-
proach with features derived from text around the
ambiguous word that are domain independent. We
refer to these as general features. This feature set
has been adapted for the disambiguation of biomed-
ical text by adding further linguistic features and two
different types of domain-specific features: CUIs (as
used by McInnes et al. (2007)) and Medical Sub-
ject Heading (MeSH) terms. This set of features is
more diverse than have been explored by previous
approaches to abbreviation disambiguation.
</bodyText>
<subsectionHeader confidence="0.965635">
3.1 Features
</subsectionHeader>
<bodyText confidence="0.997461166666667">
Our feature set contains a number of parameters
(e.g. thresholds for unigram and CUI frequencies).
These parameters were set to the same values that
were used when the system was applied to gen-
eral biomedical terms (Stevenson et al., 2008) since
these were found to perform well. We also use the
entire abstract as the context of the ambiguous term
for relevant features rather than just the sentence
containing the term. Effects of altering these vari-
ables are consistent with previous results (Liu et al.,
2004; Joshi et al., 2005; McInnes et al., 2007) and
are not reported here.
</bodyText>
<listItem confidence="0.978498142857143">
General features: The system uses a wide range
of domain-independent features that are commonly
employed for WSD.
• Local collocations: A total of 41 features which
extensively describe the context of the am-
biguous word and fall into two main types:
(1) bigrams and trigrams containing the am-
</listItem>
<bodyText confidence="0.9859874">
biguous word constructed from lemmas, word
forms or PoS tags and (2) preceding/following
lemma/word-form of the content words (adjec-
tive, adverb, noun and verb) in the same sen-
tence as the ambiguous abbreviation. For ex-
ample, consider the sentence below with the
target abreviation BSA.
“Lean BSA was obtained from height
and lean body weight ...”
The features would include the following:
left-content-word-lemma “lean BSA”, right-
function-word-lemma “BSA be”, left-POS “JJ
NNP”, right-POS “NNP VBD”, left-content-
word-form “Lean BSA”, right-function-word-
form “BSA was”, etc.
</bodyText>
<listItem confidence="0.941153833333333">
• Salient bigrams: Salient bigrams within the ab-
stract with high log-likelihood scores, as de-
scribed by Pedersen (2001).
• Unigrams: Lemmas of all content words in the
abstract and words within a ±4-word window
around the target word, excluding those in a list
</listItem>
<bodyText confidence="0.963350909090909">
of stopwords. In addition, the lemmas of any
unigrams appearing at least twice in the entire
corpus and which are found in the abstract are
also included as features.
Concept Unique Identifiers (CUIs): We follow
the approach presented by McInnes et al. (2007) to
generate features based on UMLS Concept Unique
Identifiers (CUIs). The MetaMap program (Aron-
son, 2001) identifies all words and terms in a
text which could be mapped onto a UMLS CUI.
MetaMap does not disambiguate the senses of the
concepts, instead it enumerates likely candidate con-
cepts. For example, MetaMap will segment the
phrase “Lean BSA was obtained from height and
lean body weight ...” into four chunks: “Lean
BSA”, “obtained”, “from height” and “lean body
weight”. The first chunk will be mapped onto
three CUIs: “C1261466: BSA (Body surface area)”,
“C1511233: BSA (NCI Board of Scientific Ad-
visors)” and “C0036774: BSA (Serum Albumin,
Bovine)”. The chunk “lean body weight” is mapped
onto two concepts: “C0005910: Body Weight”
</bodyText>
<page confidence="0.993437">
73
</page>
<bodyText confidence="0.999806708333333">
and “C1305866: Body Weight (Weighing patient)”1.
CUIs occurring more than twice in an abstract are in-
cluded as features. CUIs have been used for various
disambiguation tasks in the biomedical domain, in-
cluding disambiguation of ambiguous general terms
(McInnes et al., 2007) and gene symbol disambigua-
tion (Xu et al., 2007), but not, to our knowledge, for
abbreviation disambiguation.
Medical Subject Headings (MeSH): The fi-
nal feature is also specific to the biomedical do-
main. Medical Subject Headings (MeSH) (Nelson
et al., 2002) is a controlled vocabulary for index-
ing biomedical and health-related information and
documents. MeSH terms are manually assigned to
abstracts by human indexers. The latest version of
MeSH (2009) contains over 25,000 terms organised
into an 11 level hierarchy.
The MeSH terms assigned to the abstract in which
each ambiguous word occurs are used as features.
For example, the abstract containing our example
phrase has been assigned 16 terms including “Body
Surface Area”, “Body Weight”, “Humans” and “Or-
gan Size” . MeSH terms have previously been used
for abbreviation disambiguation by Yu et al. (2006).
</bodyText>
<subsectionHeader confidence="0.999855">
3.2 Learning Algorithms
</subsectionHeader>
<bodyText confidence="0.970300264705882">
We compared three machine leaning algorithms
which have previously been shown to be effective
for WSD tasks.
The Vector Space Model (VSM) is a memory-
based learning algorithm which was used by Agirre
and Mart´ınez (2004). Each occurrence of an
ambiguous word is represented as a binary vec-
tor in which each position indicates the occur-
rence/absence of a feature. A single centroid vector
is generated for each sense during training. These
centroids are compared with the vectors that repre-
sent new examples using the cosine metric to com-
pute similarity. The sense assigned to a new example
is that of the closest centroid.
The Naive Bayes (NB) classifier is based on a
probabilistic model which assumes conditional in-
dependence of features given the target classifica-
tion. It calculates the posterior probability that an
1The first of these, C0005910, refers to the weight of
a patient as a property of that individual while the second,
C1305866, refers to the process of weighing a patient as part
of a diagnostic procedure.
instance belongs to a particular class given the prior
probabilities of the class and the conditional proba-
bility of each feature given the target class.
Support Vector Machines (SVM) have been
widely used in classification tasks. SVMs map
feature vectors onto a high dimensional space and
construct a classifier by searching for the hyper-
plane that gives the greatest separation between the
classes.
We used our own implementation of the Vector
Space Model and Weka implementations (Witten
and Frank, 2005) of the other two algorithms.
</bodyText>
<sectionHeader confidence="0.999007" genericHeader="method">
4 Evaluation Corpus
</sectionHeader>
<bodyText confidence="0.9999661">
The most common method for generating corpora
to train and test WSD systems is to manually an-
notate instances of ambiguous terms found in text
with the appropriate meaning. However, this process
is both time-consuming and difficult (Artstein and
Poesio, 2008). An alternative to manual tagging is
to find a way of automatically creating sense tagged
corpora. For the translation of ambiguous English
words Ng et al. (2003) made use of the fact that the
various senses are often translated differently. For
example when “bank” is used in the ‘financial insti-
tution’ sense it is translated to French as “banque”
and “bord” when it is used to mean ‘edge of river’.
However, a disadvantage of this approach is that it
relies on the existence of parallel text which may
not be available. In the biomedical domain Liu et al.
(2001)(2002) created a corpus using unambiguous
related terms (see Section 2) although they found
that it was not always possible to identify suitable
related terms.
</bodyText>
<subsectionHeader confidence="0.992551">
4.1 Corpus Creation
</subsectionHeader>
<bodyText confidence="0.998713545454545">
Liu et al. (2001) also made use of the fact that
when abbreviations are introduced they are often ac-
companied by their expansion, for example “BSA
(bovine serum albumin)”. This phenomenon was
exploited to automatically generate a corpus of ab-
breviations and associated definitions by replacing
the abbreviation and expansion with the abbrevia-
tion alone. For example, the sentence “The adsorp-
tion behavior of bovine serum albumin (BSA) on
a Sepharose based hydrophobic interaction support
has been studied.” becomes “The adsorption behav-
</bodyText>
<page confidence="0.99446">
74
</page>
<note confidence="0.7110905">
“BSA” AND “body surface area” NOT “bovine serum albumin”
“BSA” AND “bovine serum albumin” NOT “body surface area”
</note>
<figureCaption confidence="0.999298">
Figure 1: Example queries for abbreviation “BSA”
</figureCaption>
<bodyText confidence="0.999742216666667">
ior of BSA on a Sepharose based hydrophobic inter-
action support has been studied.”
We used this approach to create a corpus of sense
tagged abbreviations in biomedical documents using
a set of 21 three letter abbreviations used in previ-
ous research on abbreviation disambiguation (Liu et
al., 2001; Liu et al., 2002; Liu et al., 2004). Pos-
sible expansions for the majority of these abbrevi-
ations were listed in these papers. For the few re-
maining ones possible expansions were taken from
the Medstract database (Pustejovsky et al., 2002).
We searched for instances of these abbreviations in
Medline, a database containing more than 18 mil-
lion abstracts from publications in biomedicine and
the life sciences. For each abbreviation we queried
Medline, using the Entrez interface, to identify doc-
uments containing one of its meanings. For exam-
ple the abbreviation “BSA” has two possible expan-
sions: “body surface area” and “bovine serum alu-
min”. Medline is searched to identify documents
that contain each possible expansion of the abbre-
viation using the queries shown in Figure 1. Each
query matches documents containing the abbrevia-
tion and relevant expansion and no mentions of the
other possible expansion(s).
The retrieved documents are then processed to
remove the expansions of each abbreviation. The
Schwartz and Hearst (2003) algorithm for identi-
fying abbreviations and the relevant expansion (see
Section 2) is then run over each of the retrieved ab-
stracts to identify the correct expansion. The expan-
sion is removed from the document and stored sep-
arately, effectively creating a sense tagged corpus.
For convenience the abstracts are converted into a
format similar to the one used for the NLM-WSD
corpus (Weeber et al., 2001).
The resulting corpus consists of 55,655 docu-
ments. For each abbreviation Table 1 shows the
number of abstracts retrieved from Medline (in the
column labeled “Abstracts”) and the number of ex-
pansions (“Count” column). The column labelled
“Rare” lists the number of expansions that account
for fewer than 1% of the occurrences of an abbre-
viation and “Frequent” lists the percentage of occu-
rances represented by the most frequent expansion.
It can be seen that there is a wide variation between
the number of abstracts retrieved for each abbrevi-
ation. CSF occurs in 14,871 abstracts and ASP in
just 71. There is also a wide variation between the
frequency of the most common expansion with over
99% of the occurrences of “CSF” representing one
expansion (“cerebrospinal fluid”) while for “ASP”
two of the five possible expansions (“antisocial per-
sonality” and “aspartate”) each account for almost
34% of the documents. In addition, several abbrevi-
ations have expansions which occur only rarely. For
example, two of the expansions of “APC” (“atrial
pressure complexes” and “aphidicholin”) each have
only a single document and account for just 0.03%
of the instances of that abbreviation.
</bodyText>
<subsectionHeader confidence="0.99489">
4.2 Corpus Reduction
</subsectionHeader>
<bodyText confidence="0.999923272727273">
Given the diversity of the abbreviations which were
downloaded from Medline, both in terms of num-
ber of documents and distribution of senses, sub-
sets of this corpus that are more suitable for WSD
experiments were created. Corpora containing 100,
200 and 300 randomly selected examples of each ab-
breviation were generated and these are referred to
as Corpus.100, Corpus.200 and Corpus.300 respec-
tively.
Some of the 21 abbreviations were not suitable
for inclusion in these corpora. Abbreviations were
not included in the relevant corpus if an insufficient
number of examples were retrieved from Medline.
For example, only 71 abstracts containing “ASP”
were retrieved and it is is not included in any of the
three corpora. Similarly, “ANA” and “FDP” are not
included in Corpus.200 or Corpus.300 and “DIP”
not included in Corpus.300. In addition, rare senses,
those which represent fewer than 1% of the occur-
rences of an abbreviation in all retrieved abstracts,
were discarded. Finally, two abbreviations (“ACE”
and “CSF”) have only one sense that is not “Rare”
</bodyText>
<page confidence="0.997017">
75
</page>
<table confidence="0.999091416666667">
Abstracts Count Expansions
Rare Frequent
ACE 3105 3 2 98.7
ANA 100 3 0 58.0
APC 3146 5 2 39.4
ASP 71 5 0 33.8
BPD 1841 3 0 46.7
BSA 5373 2 0 86.4
CAT 4636 3 1 55.2
CML 2234 4 2 91.7
CMV 7665 2 0 96.7
CSF 14871 3 2 99.1
DIP 209 2 0 75.1
EMG 2052 2 0 88.4
FDP 130 4 0 78.5
LAM 325 4 1 48.3
MAC 955 5 1 64.3
MCP 815 5 1 50.2
PCA 2442 5 1 68.9
PCP 1642 2 0 57.8
PEG 607 2 0 94.1
PVC 234 2 2 78.2
RSV 3202 2 0 76.7
Average 2650 3.2 0.6 70.8
</table>
<tableCaption confidence="0.993575">
Table 1: Properties of abbreviations corpus retrieved
from Medline
</tableCaption>
<bodyText confidence="0.999429833333333">
(see Table 1) and these were also excluded from the
reduced corpora.
Consequently, Corpus.100 contains 18 abbrevia-
tions (“ACE”, “ASP” and “CSF” are excluded), Cor-
pus.200 contains 16 (“ANA” and “FDP” are also
excluded) and Corpus.300 contains 14 (“DIP” and
“PVC” also excluded). Where an abbreviation is in-
cluded in more than one corpus, all the examples in
the smaller corpus are included in the larger one(s).
For example, the 100 examples of “APC” in Cor-
pus.100 are also included in Corpus.200 and Cor-
pus.300.
</bodyText>
<sectionHeader confidence="0.999601" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999716452830189">
Various combinations of learning algorithms and
features were applied to the three reduced corpora
described in Section 4.2. Performance of the WSD
system is measured in terms of the proportion of ab-
breviation instances for which the correct expansion
is identified. 10-fold cross validation was used for
all experiments and all quoted results refer to the av-
erage performance across the 10 folds. Results are
shown in Table 2. The baseline figures, based on
selecting the most frequent expansion for each ab-
breviation, are shown for each corpus. Note that
these figures vary slightly across the three corpora
because of the different abbreviations each contains
(see Section 4.2).
A first observation is that performance of the
WSD system is consistently better than the base-
line for the relevant corpus and, with a few excep-
tions, above 90%. As might be expected, perfor-
mance improves as additional training examples are
added. However, even when the number of exam-
ples is relatively low, just 100, performance of the
best configuration (VSM learning algorithm with all
three types of feature) is 97.4%.
The best result, 99% (300 training examples,
VSM learning algorithm with all feature types), ex-
ceeds reported performance of previous abbreviation
disambiguation systems (see Section 2). Although
these results are not directly comparable, since these
studies used different evaluation corpora, the set
of ambiguous abbreviations used in this study and
methodology for corpus creation are similar to those
used by Liu et al. (2001)(2002)(2004).
The best performance for each learning algorithm
is obtained when all three types of features are com-
bined. The difference between performance ob-
tained using all three feature types and using only
the MeSH or CUI features is statistically significant
(Wilcoxon Signed Ranks test, p &lt; 0.01) although
the difference between this and performance using
just the linguistic features is not.
The VSM learning algorithm generally performs
better than either the SVM or Naive Bayes learning
algorithms. The difference between performance of
VSM and the other algorithms is statistically signif-
icant for Corpus.100 but not for the other two, sug-
gesting that this learning algorithm is better able to
cope with small number of training examples than
Naive Bayes and Support Vector Machines. Strong
performance of the VSM algorithm is consistent
with previous work which has shown that this algo-
rithm performs well on the disambiguation of am-
biguous terms in both biomedical and general text
(Agirre and Martinez, 2004; Stevenson et al., 2008).
</bodyText>
<page confidence="0.962851">
76
</page>
<table confidence="0.999855333333333">
Features
Algorithm Linguistic CUI MeSH Linguistic Linguistic CUI+ Linguistic+
+CUI +MeSH MeSH MeSH+CUI
Corpus.100 (Baseline = 69.0%)
SVM 0.934 0.900 0.949 0.947 0.946 0.938 0.954
NB 0.940 0.917 0.949 0.951 0.947 0.944 0.958
VSM 0.968 0.937 0.888 0.970 0.971 0.939 0.974
Corpus.200 (Baseline = 69.1%)
SVM 0.957 0.911 0.964 0.964 0.964 0.947 0.965
NB 0.966 0.926 0.962 0.969 0.971 0.955 0.972
VSM 0.979 0.930 0.894 0.982 0.981 0.947 0.984
Corpus.300 (Baseline = 68.7%)
SVM 0.966 0.914 0.970 0.968 0.974 0.954 0.975
NB 0.971 0.933 0.960 0.971 0.976 0.960 0.978
VSM 0.981 0.938 0.894 0.987 0.985 0.957 0.990
</table>
<tableCaption confidence="0.999696">
Table 2: Performance of WSD system using various combinations of learning algorithms and features.
</tableCaption>
<bodyText confidence="0.999964428571429">
Performance of our system on this task is higher
than would be expected for most WSD tasks sug-
gesting that the problem of abbreviation disam-
biguation is simpler than the disambiguation of gen-
eral terms. The most probable reason for this is that
the various expansions of abbreviations in our cor-
pus are more distinct and better defined than senses
for general terms. For example, the three possi-
ble expansions for “ANA” in our corpus are a pro-
fessional body (“American Nurses Association”), a
type of medical test (“antinuclear”) and a neuro-
transmitter (“Anandamide”). It is likely that these
diverse meanings will tend to occur in very differ-
ent contexts and in documents with different topics.
On the other hand it is widely accepted that distinc-
tions between possible meanings of words in natu-
ral language are often vague (Kilgarriff, 1993). It
is likely that clearer distinctions between possible
expansions of abbreviations make the task of iden-
tifying the correct one more straightforward than
identifying meanings of ambiguous words. In ad-
dition, the creation of annotated data for WSD is of-
ten hampered by the difficulty in obtaining sufficient
agreement between annotators (Artstein and Poesio,
2008; Weeber et al., 2001) and this problem does not
apply to our automatically-generated corpus.
Results in Table 2 indicate that CUIs are use-
ful features in the disambiguation of abbreviations.
This is in contrast with previous experiments on am-
biguous terms in biomedical documents (Stevenson
et al., 2008) in which it was found that the best
performance as obtained using only linguistic and
MeSH features. It is likely that the clear distinction
between expansions of abbreviations is the reason
behind this difference. CUIs are assigned automat-
ically by the MetaMap program (Aronson, 2001).
However, this assignment is very noisy. It is likely
that the various expansions of abbreviations are dis-
tinct enough for this noise to be tolerated by the
learning algorithms while it causes problems when
the meanings are closer together, such as in the case
of ambiguous terms.
</bodyText>
<subsectionHeader confidence="0.999822">
5.1 Performance of Individual Abbreviations
</subsectionHeader>
<bodyText confidence="0.999976428571429">
Table 3 shows the performance of the best WSD sys-
tem (VSM learning algorithm with all features) for
each abbreviation in the three subsets of our corpus.
Our system performs well for all abbreviations. Ac-
curacy is no lower than 92% for any abbreviation
using Corpus.100 and no lower than 97% for Cor-
pus.300, demonstrating that the approach is robust.
In fact, the approach still performs well for abbre-
viations with low baseline scores, such as “APC”,
“BPD” and “LAM”.
It is interesting to note that the abbreviations with
the lowest performance tend to have expansions that
are closely related. For example, the two expansions
of “EMG” are ‘electromyography’ and ‘electromyo-
</bodyText>
<page confidence="0.994725">
77
</page>
<table confidence="0.999912619047619">
100 Corpus 300
200
ANA 0.980 - -
APC 0.980 1.000 1.000
BPD 1.000 1.000 1.000
BSA 0.970 0.970 0.982
CAT 0.990 0.990 1.000
CML 0.960 0.963 0.978
CMV 0.970 0.970 0.970
DIP 1.000 1.000 -
EMG 0.920 0.960 0.980
FDP 0.970 - -
LAM 0.960 0.980 0.980
MAC 0.970 0.990 0.989
MCP 0.980 0.978 1.000
PCA 0.960 0.987 0.992
PCP 0.990 1.000 1.000
PEG 0.980 0.982 1.000
PVC 0.990 1.000 -
RSV 0.960 0.972 0.978
Overall 0.974 0.984 0.990
</table>
<tableCaption confidence="0.994471">
Table 3: Performance of WSD system over individual ab-
breviations in three reduced corpora
</tableCaption>
<bodyText confidence="0.999969357142857">
gram’ while for “LAM” one expansion (‘Lymphan-
gioleiomyomatosis’) is a rare lung disease and the
other (‘Lipoarabinomannan’) a molecule associated
with another lung disease (tuberculosis). On the
other hand, abbreviations that are more accurately
disambiguated tend to have expansions with more
distinct meanings. For example, “BPD” can be an
acronym for ‘borderline personality disorder’ (a psy-
chiatric diagnosis), ‘bronchopulmonary dysplasia’
(a lung disease) or ‘biparietal diameter’ (diameter of
a foetus’ head in an ultrasound) and the expansions
of “DIP” are ‘desquamative interstitial pneumonia’
(a lung disease) and ‘distal interphalangeal joints’
(types of joints in the human hand and foot).
</bodyText>
<sectionHeader confidence="0.999667" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999979592592593">
This paper has presented an approach to the disam-
biguation of ambiguous abbreviations in biomedi-
cal documents. We treat this problem as a form
of WSD and apply a system that combines a wider
range of features than have been previously applied,
including those which are commonly used within
WSD systems in addition to information from two
domain-specific knowledge sources. The approach
is evaluated using a corpus of abbreviations auto-
matically mined from Medline and found to iden-
tify the correct expansion with accuracy of up to
99%. This figure is higher than previously reported
results for abbreviation disambiguation systems, al-
though direct comparison is difficult due to the use
of different data sets. It was also found that best per-
formance could be obtained using a simple machine
learning algorithm and a diverse range of knowledge
sources. Performance of our system is higher than is
normally achieved by WSD systems when applied
to general terms and we suggest that the reason for
this is that the various expansions of abbreviations
are better defined and more distinct than the senses
of ambiguous words.
This study has been limited to the disambiguation
of abbreviations consisting of exactly three letters.
Possibilities for future work include experimenting
with abbreviations of various lengths.
</bodyText>
<subsectionHeader confidence="0.756445">
Data
</subsectionHeader>
<bodyText confidence="0.9999015">
The corpus described in Section 4 has been
made freely available for research and may
be obtained from http://nlp.shef.ac.uk/
BioWSD/downloads/abbreviationdata/.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999884">
We are grateful to the anonymous reviewers of this
paper for their valuable feedback.
</bodyText>
<sectionHeader confidence="0.99858" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997526133333333">
E. Adar. 2004. SaRAD: A simple and robust abbrevia-
tion dictionary. Bioinformatics, 20(4):527–533.
E. Agirre and D. Martinez. 2004. The Basque Coun-
try University system: English and Basque tasks. In
Rada Mihalcea and Phil Edmonds, editors, Senseval-
3: Third International Workshop on the Evaluation of
Systems for the Semantic Analysis of Text, pages 44–
48, Barcelona, Spain, July.
A. Aronson. 2001. Effective mapping of biomedical text
to the UMLS Metathesaurus: the MetaMap program.
In Proceedings of the American Medical Informatics
Association (AMIA), pages 17–21.
R. Artstein and M. Poesio. 2008. Inter-coder agreement
for computational linguistics. Computational Linguis-
tics, 34(4):555–596.
</reference>
<page confidence="0.995652">
78
</page>
<note confidence="0.763865">
J. Chang, H. Sch¨utze, and R. Altman. 2002. Creating an
Online Dictionary of Abbreviations from MEDLINE.
The Journal of the American Medical Informatics As-
</note>
<reference confidence="0.996403823529412">
sociation, 9(6):612–620.
H. Fred and T. Cheng. 1999. Acronymesis: the explod-
ing misuse of acronyms. Texas Heart Institute Jour-
nal, 30:255–257.
S. Gaudan, H. Kirsch, and D. Rebholz-Schuhmann.
2005. Resolving abbreviations to their senses in Med-
line. Bioinformatics, 21(18):3658–3664.
M. Joshi, T. Pedersen, and R. Maclin. 2005. A Compara-
tive Study of Support Vector Machines Applied to the
Word Sense Disambiguation Problem for the Medical
Domain. In Proceedings of the Second Indian Confer-
ence on Artificial Intelligence (IICAI-05), pages 3449–
3468, Pune, India.
M. Joshi, S. Pakhomov, T. Pedersen, and C. Chute. 2006.
A comparative study of supervised learning as applied
to acronym expansion in clinical reports. In Proceed-
ings of the Annual Symposium of the American Medi-
cal Informatics Association, pages 399–403, Washing-
ton, DC.
A. Kilgarriff. 1993. Dictionary word sense distinctions:
An enquiry into their nature. Computers and the Hu-
manities, 26:356–387.
H. Liu, Y. Lussier, and C. Friedman. 2001. Disam-
biguating ambiguous biomedical terms in biomedical
narrative text: An unsupervised method. Journal of
Biomedical Informatics, 34:249–261.
H. Liu, S. Johnson, and C. Friedman. 2002. Au-
tomatic Resolution of Ambiguous Terms Based on
Machine Learning and Conceptual Relations in the
UMLS. Journal of the American Medical Informatics
Association, 9(6):621–636.
H. Liu, V. Teller, and C. Friedman. 2004. A Multi-aspect
Comparison Study of Supervised Word Sense Disam-
biguation. Journal of the American Medical Informat-
ics Association, 11(4):320–331.
B. McInnes, T. Pedersen, and J. Carlis. 2007. Using
UMLS Concept Unique Identifiers (CUIs) for Word
Sense Disambiguation in the Biomedical Domain. In
Proceedings of the Annual Symposium of the Ameri-
can Medical Informatics Association, pages 533–537,
Chicago, IL.
R. Mihalcea, T. Chklovski, and A. Kilgarriff. 2004. The
Senseval-3 English lexical sample task. In Proceed-
ings of Senseval-3: The Third International Workshop
on the Evaluation of Systems for the Semantic Analysis
of Text, Barcelona, Spain.
S. Nelson, T. Powell, and B. Humphreys. 2002. The
Unified Medical Language System (UMLS) Project.
In Allen Kent and Carolyn M. Hall, editors, Ency-
clopedia of Library and Information Science. Marcel
Dekker, Inc.
H. Ng, B. Wang, and S. Chan. 2003. Exploiting Parallel
Texts for Word Sense Disambiguation: an Empirical
Study. In Proceedings of the 41st Annual Meeting of
the Association for Computational Linguistics (ACL-
03), pages 455–462, Sapporo, Japan.
N. Okazaki, S. Ananiadou, and J. Tsujii. 2008. A dis-
criminative alignment model for abbreviation recogni-
tion. In Proceedings of the 22nd International Con-
ference on Computational Linguistics (Coling 2008),
pages 657–664, Manchester, UK.
S. Pakhomov. 2002. Semi-supervised maximum entropy
based approach to acronym and abbreviation normal-
ization in medical texts. In Proceedings of the 40th
Annual Meeting of the Association for Computational
Linguistics, pages 160–167, Philadelphia, PA.
T. Pedersen. 2001. A Decision Tree of Bigrams is an
Accurate Predictor of Word Sense. In Proceedings
of the Second Meeting of the North American Chap-
ter of the Association for Computational Linguistics
(NAACL-01), pages 79–86, Pittsburgh, PA.
J. Pustejovsky, J. Castano, R. Saur, A. Rumshisky,
J. Zhang, and W. Luo. 2002. Medstract: Creating
Large-scale Information Servers for Biomedical Li-
braries. In ACL 2002 Workshop on Natural Language
Processing in the Biomedical Domain.
A. Schwartz and M. Hearst. 2003. A simple algorithm
for identifying abbreviation definitions in biomedical
text. In Proceedings of the Pacific Symposium on Bio-
computing, Kauai.
M. Stevenson, Y. Guo, R. Gaizauskas, and D. Martinez.
2008. Disambiguation of biomedical text using di-
verse sources of information. BMC Bioinformatics,
9(Suppl 11):S7.
M. Weeber, J. Mork, and A. Aronson. 2001. Developing
a Test Collection for Biomedical Word Sense Disam-
biguation. In Proceedings of AMAI Symposium, pages
746–50, Washington, DC.
I. Witten and E. Frank. 2005. Data Mining: Practical
machine learning tools and techniques. Morgan Kauf-
mann, San Francisco.
H. Xu, J. Fan, G. Hripcsak, E. Mendonc¸a, Markatou M.,
and Friedman C. 2007. Gene symbol disambigua-
tion using knowledge-based profiles. Bioinformatics,
23(8):1015–22.
H. Yu, W. Kim, V. Hatzivassiloglou, and J. Wilbur. 2006.
A large scale, corpus-based approach for automati-
cally disambigutaing biomedical abbreviations. ACM
Transactions on Information Systems, 24(3):380–404.
W. Zhou, I. Vetle, and N. Smalheiser. 2006. ADAM: an-
other database of abbreviations in MEDLINE. Bioin-
formatics, 22(22):2813–2818.
</reference>
<page confidence="0.999047">
79
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.370439">
<title confidence="0.998879">Disambiguation of Biomedical Abbreviations</title>
<author confidence="0.999625">Yikun Abdulaziz Al</author>
<affiliation confidence="0.9936085">Department of Computer University of</affiliation>
<address confidence="0.7580165">Regent Court, 211 Sheffield, S1</address>
<note confidence="0.79022">United</note>
<abstract confidence="0.985285722222222">Abbreviations are common in biomedical documents and many are ambiguous in the sense that they have several potential expansions. Identifying the correct expansion is necessary for language understanding and important for applications such as document retrieval. Identifying the correct expansion can be viewed as a Word Sense Disambiguation (WSD) problem. A WSD system that uses a variety of knowledge sources, including two types of information specific to the biomedical domain, is also described. This system was tested on a corpus of ambiguous abbreviations, created by automatically identifying the correct expansion in Medline abstracts, and found to identify the correct expansion with up to 99% accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Adar</author>
</authors>
<title>SaRAD: A simple and robust abbreviation dictionary.</title>
<date>2004</date>
<journal>Bioinformatics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="7743" citStr="Adar (2004)" startWordPosition="1185" endWordPosition="1186">tion’s expansion in the document. The problem is relatively straightforward for abbreviations which are created by selecting the first character from each word in the expansion, such as “angiotensin converting enzyme (ACE)”, but is more difficult when this convention is not followed, for example “acetylchlinesterase (ACE)”, “antisocial personality (ASP)” and “catalase (CAT)”. Okazaki et al. (2008) recently proposed an approach to this problem based on discriminative alignment that has been shown to perform well. However, the most common solutions are based on heuristic approaches, for example Adar (2004) and Zhou et al. (2006). Pustejovsky et al. (2002) used hand-built regular expressions. Schwartz and Hearst (2003) describe an approach which starts by identifying the set of candidate expansions in the same sentence as an abbreviation. The most likely one is identified by searching for the 72 shortest candidate which contains all the characters in the abbreviation in the correct order. 3 Abbreviation Disambiguation System Our abbreviation disambiguation system is based on a state-of-the-art WSD system that has been adapted to the biomedical domain by augmenting it with additional knowledge so</context>
</contexts>
<marker>Adar, 2004</marker>
<rawString>E. Adar. 2004. SaRAD: A simple and robust abbreviation dictionary. Bioinformatics, 20(4):527–533.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>D Martinez</author>
</authors>
<title>The Basque Country University system: English and Basque tasks.</title>
<date>2004</date>
<booktitle>Senseval3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text,</booktitle>
<pages>44--48</pages>
<editor>In Rada Mihalcea and Phil Edmonds, editors,</editor>
<location>Barcelona, Spain,</location>
<contexts>
<context position="8419" citStr="Agirre and Martinez, 2004" startWordPosition="1288" endWordPosition="1291"> used hand-built regular expressions. Schwartz and Hearst (2003) describe an approach which starts by identifying the set of candidate expansions in the same sentence as an abbreviation. The most likely one is identified by searching for the 72 shortest candidate which contains all the characters in the abbreviation in the correct order. 3 Abbreviation Disambiguation System Our abbreviation disambiguation system is based on a state-of-the-art WSD system that has been adapted to the biomedical domain by augmenting it with additional knowledge sources. The system on which our approach is based (Agirre and Martinez, 2004) participated in the Senseval-3 challenge (Mihalcea et al., 2004) with a performance close to the best system for the lexical sample tasks in two languages while the version adapted to the biomedical domain has achieved the best recorded results (Stevenson et al., 2008) on a standard test set consisting of ambiguous terms (Weeber et al., 2001). This system is based on a supervised learning approach with features derived from text around the ambiguous word that are domain independent. We refer to these as general features. This feature set has been adapted for the disambiguation of biomedical t</context>
<context position="24084" citStr="Agirre and Martinez, 2004" startWordPosition="3844" endWordPosition="3847">ot. The VSM learning algorithm generally performs better than either the SVM or Naive Bayes learning algorithms. The difference between performance of VSM and the other algorithms is statistically significant for Corpus.100 but not for the other two, suggesting that this learning algorithm is better able to cope with small number of training examples than Naive Bayes and Support Vector Machines. Strong performance of the VSM algorithm is consistent with previous work which has shown that this algorithm performs well on the disambiguation of ambiguous terms in both biomedical and general text (Agirre and Martinez, 2004; Stevenson et al., 2008). 76 Features Algorithm Linguistic CUI MeSH Linguistic Linguistic CUI+ Linguistic+ +CUI +MeSH MeSH MeSH+CUI Corpus.100 (Baseline = 69.0%) SVM 0.934 0.900 0.949 0.947 0.946 0.938 0.954 NB 0.940 0.917 0.949 0.951 0.947 0.944 0.958 VSM 0.968 0.937 0.888 0.970 0.971 0.939 0.974 Corpus.200 (Baseline = 69.1%) SVM 0.957 0.911 0.964 0.964 0.964 0.947 0.965 NB 0.966 0.926 0.962 0.969 0.971 0.955 0.972 VSM 0.979 0.930 0.894 0.982 0.981 0.947 0.984 Corpus.300 (Baseline = 68.7%) SVM 0.966 0.914 0.970 0.968 0.974 0.954 0.975 NB 0.971 0.933 0.960 0.971 0.976 0.960 0.978 VSM 0.981 0.</context>
</contexts>
<marker>Agirre, Martinez, 2004</marker>
<rawString>E. Agirre and D. Martinez. 2004. The Basque Country University system: English and Basque tasks. In Rada Mihalcea and Phil Edmonds, editors, Senseval3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, pages 44– 48, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Aronson</author>
</authors>
<title>Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program.</title>
<date>2001</date>
<booktitle>In Proceedings of the American Medical Informatics Association (AMIA),</booktitle>
<pages>17--21</pages>
<contexts>
<context position="11401" citStr="Aronson, 2001" startWordPosition="1769" endWordPosition="1771">grams: Salient bigrams within the abstract with high log-likelihood scores, as described by Pedersen (2001). • Unigrams: Lemmas of all content words in the abstract and words within a ±4-word window around the target word, excluding those in a list of stopwords. In addition, the lemmas of any unigrams appearing at least twice in the entire corpus and which are found in the abstract are also included as features. Concept Unique Identifiers (CUIs): We follow the approach presented by McInnes et al. (2007) to generate features based on UMLS Concept Unique Identifiers (CUIs). The MetaMap program (Aronson, 2001) identifies all words and terms in a text which could be mapped onto a UMLS CUI. MetaMap does not disambiguate the senses of the concepts, instead it enumerates likely candidate concepts. For example, MetaMap will segment the phrase “Lean BSA was obtained from height and lean body weight ...” into four chunks: “Lean BSA”, “obtained”, “from height” and “lean body weight”. The first chunk will be mapped onto three CUIs: “C1261466: BSA (Body surface area)”, “C1511233: BSA (NCI Board of Scientific Advisors)” and “C0036774: BSA (Serum Albumin, Bovine)”. The chunk “lean body weight” is mapped onto t</context>
<context position="26616" citStr="Aronson, 2001" startWordPosition="4251" endWordPosition="4252">tstein and Poesio, 2008; Weeber et al., 2001) and this problem does not apply to our automatically-generated corpus. Results in Table 2 indicate that CUIs are useful features in the disambiguation of abbreviations. This is in contrast with previous experiments on ambiguous terms in biomedical documents (Stevenson et al., 2008) in which it was found that the best performance as obtained using only linguistic and MeSH features. It is likely that the clear distinction between expansions of abbreviations is the reason behind this difference. CUIs are assigned automatically by the MetaMap program (Aronson, 2001). However, this assignment is very noisy. It is likely that the various expansions of abbreviations are distinct enough for this noise to be tolerated by the learning algorithms while it causes problems when the meanings are closer together, such as in the case of ambiguous terms. 5.1 Performance of Individual Abbreviations Table 3 shows the performance of the best WSD system (VSM learning algorithm with all features) for each abbreviation in the three subsets of our corpus. Our system performs well for all abbreviations. Accuracy is no lower than 92% for any abbreviation using Corpus.100 and </context>
</contexts>
<marker>Aronson, 2001</marker>
<rawString>A. Aronson. 2001. Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program. In Proceedings of the American Medical Informatics Association (AMIA), pages 17–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Artstein</author>
<author>M Poesio</author>
</authors>
<title>Inter-coder agreement for computational linguistics.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<pages>9--6</pages>
<contexts>
<context position="15045" citStr="Artstein and Poesio, 2008" startWordPosition="2352" endWordPosition="2355">een widely used in classification tasks. SVMs map feature vectors onto a high dimensional space and construct a classifier by searching for the hyperplane that gives the greatest separation between the classes. We used our own implementation of the Vector Space Model and Weka implementations (Witten and Frank, 2005) of the other two algorithms. 4 Evaluation Corpus The most common method for generating corpora to train and test WSD systems is to manually annotate instances of ambiguous terms found in text with the appropriate meaning. However, this process is both time-consuming and difficult (Artstein and Poesio, 2008). An alternative to manual tagging is to find a way of automatically creating sense tagged corpora. For the translation of ambiguous English words Ng et al. (2003) made use of the fact that the various senses are often translated differently. For example when “bank” is used in the ‘financial institution’ sense it is translated to French as “banque” and “bord” when it is used to mean ‘edge of river’. However, a disadvantage of this approach is that it relies on the existence of parallel text which may not be available. In the biomedical domain Liu et al. (2001)(2002) created a corpus using unam</context>
<context position="26025" citStr="Artstein and Poesio, 2008" startWordPosition="4156" endWordPosition="4159">hat these diverse meanings will tend to occur in very different contexts and in documents with different topics. On the other hand it is widely accepted that distinctions between possible meanings of words in natural language are often vague (Kilgarriff, 1993). It is likely that clearer distinctions between possible expansions of abbreviations make the task of identifying the correct one more straightforward than identifying meanings of ambiguous words. In addition, the creation of annotated data for WSD is often hampered by the difficulty in obtaining sufficient agreement between annotators (Artstein and Poesio, 2008; Weeber et al., 2001) and this problem does not apply to our automatically-generated corpus. Results in Table 2 indicate that CUIs are useful features in the disambiguation of abbreviations. This is in contrast with previous experiments on ambiguous terms in biomedical documents (Stevenson et al., 2008) in which it was found that the best performance as obtained using only linguistic and MeSH features. It is likely that the clear distinction between expansions of abbreviations is the reason behind this difference. CUIs are assigned automatically by the MetaMap program (Aronson, 2001). However</context>
</contexts>
<marker>Artstein, Poesio, 2008</marker>
<rawString>R. Artstein and M. Poesio. 2008. Inter-coder agreement for computational linguistics. Computational Linguistics, 34(4):555–596. sociation, 9(6):612–620.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Fred</author>
<author>T Cheng</author>
</authors>
<title>Acronymesis: the exploding misuse of acronyms.</title>
<date>1999</date>
<journal>Texas Heart Institute Journal,</journal>
<pages>30--255</pages>
<contexts>
<context position="1836" citStr="Fred and Cheng (1999)" startWordPosition="263" endWordPosition="266">ral Language Processing”. Ambiguous abbreviations form a challenge to language understanding since identification of the correct expansion is often important. The query “NLP”, for example, returns pages which refer to “Neuro-linguistic programming” for most web search engines, pages which are of limited value to those interested in Natural Language Processing. In some cases this problem could be obviated by altering the query terms, for example including “Natural”, “Language” and “Processing”. 71 However, this will not help when the abbreviation’s expansion does not occur within the document. Fred and Cheng (1999) point out that this is often the case in biomedical documents, in this domain ubiquitous abbreviations (such as DNA and mRNA) often appear without an expansion. It has been reported that misinterpretation of abbreviations in biomedical documents has lead to medical practitioners making fatal errors (Fred and Cheng, 1999). However, identifying the correct expansion is not a straightforward task since an abbreviation may have several possible expansions. Chang et al. (2002) reported that abbreviations in biomedical journal articles consisting of six characters or less have an average of 4.61 po</context>
</contexts>
<marker>Fred, Cheng, 1999</marker>
<rawString>H. Fred and T. Cheng. 1999. Acronymesis: the exploding misuse of acronyms. Texas Heart Institute Journal, 30:255–257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Gaudan</author>
<author>H Kirsch</author>
<author>D Rebholz-Schuhmann</author>
</authors>
<title>Resolving abbreviations to their senses in Medline.</title>
<date>2005</date>
<journal>Bioinformatics,</journal>
<volume>21</volume>
<issue>18</issue>
<contexts>
<context position="4489" citStr="Gaudan et al. (2005)" startWordPosition="673" endWordPosition="676">identify the correct abbreviation with up to 99% accuracy. The remainder of this paper is organised as follows. The next section describes relevant previous work on disambiguation of abbreviations. Section 3 describes a supervised learning WSD system tailored specifically to the biomedical domain. Section 4 describes the automatic creation of a corpus of ambiguous abbreviations designed specifically for the training and evaluation of abbreviation disambiguation systems. Section 5 describes the evaluation of our system on this corpus. Our conclusions are presented in Section 6. 2 Previous Work Gaudan et al. (2005) distinguish two types of abbreviations: global and local. Global abbreviations are those found in documents without the expansion explicitly stated, while local abbreviations are defined in the same document in which the abbreviation occurs. Our work is concerned with the problem of disambiguating global abbreviations. Gaudan et al. (2005) point out that global abbreviations are often ambiguous. Various researchers have explored the problem of disambiguating global abbreviations in biomedical documents. Liu et al. (2001)(2002) used several domain-specific knowledge sources to identify terms w</context>
<context position="5758" citStr="Gaudan et al. (2005)" startWordPosition="871" endWordPosition="874">pansion but which have only one sense themselves. Instances of these terms were identified in a corpus of biomedical journal abstracts and used as training data. Their learning algorithm uses a variety of features including all words in the abstract and collocations of the ambiguous abbreviation. They report an accuracy of 97% on a small set of abbreviations. Liu et al. (2004) present a fully supervised approach. They compared a variety of supervised machine learning algorithms and found that the best performance over a set of 15 ambiguous abbreviations, 98.6%, was obtained using Naive Bayes. Gaudan et al. (2005) use a Support Vector Machine trained on a bag-of-words model and report an accuracy of 98.5%. Yu et al. (2006) experimented with two supervised learning algorithms: Naive Bayes and Support Vector Machines. They extracted a corpus containing examples of 60 abbreviations from a set of biomedical journal articles which was split so that abstracts in which the abbreviations were defined were used as training data and those in which no definition is found as test data. Abbreviations in the test portion were manually disambiguated. They report 79% coverage and 80% precision using a Naive Bayes clas</context>
</contexts>
<marker>Gaudan, Kirsch, Rebholz-Schuhmann, 2005</marker>
<rawString>S. Gaudan, H. Kirsch, and D. Rebholz-Schuhmann. 2005. Resolving abbreviations to their senses in Medline. Bioinformatics, 21(18):3658–3664.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Joshi</author>
<author>T Pedersen</author>
<author>R Maclin</author>
</authors>
<title>A Comparative Study of Support Vector Machines Applied to the Word Sense Disambiguation Problem for the Medical Domain.</title>
<date>2005</date>
<booktitle>In Proceedings of the Second Indian Conference on Artificial Intelligence (IICAI-05),</booktitle>
<pages>3449--3468</pages>
<location>Pune, India.</location>
<contexts>
<context position="9857" citStr="Joshi et al., 2005" startWordPosition="1524" endWordPosition="1527">ave been explored by previous approaches to abbreviation disambiguation. 3.1 Features Our feature set contains a number of parameters (e.g. thresholds for unigram and CUI frequencies). These parameters were set to the same values that were used when the system was applied to general biomedical terms (Stevenson et al., 2008) since these were found to perform well. We also use the entire abstract as the context of the ambiguous term for relevant features rather than just the sentence containing the term. Effects of altering these variables are consistent with previous results (Liu et al., 2004; Joshi et al., 2005; McInnes et al., 2007) and are not reported here. General features: The system uses a wide range of domain-independent features that are commonly employed for WSD. • Local collocations: A total of 41 features which extensively describe the context of the ambiguous word and fall into two main types: (1) bigrams and trigrams containing the ambiguous word constructed from lemmas, word forms or PoS tags and (2) preceding/following lemma/word-form of the content words (adjective, adverb, noun and verb) in the same sentence as the ambiguous abbreviation. For example, consider the sentence below wit</context>
</contexts>
<marker>Joshi, Pedersen, Maclin, 2005</marker>
<rawString>M. Joshi, T. Pedersen, and R. Maclin. 2005. A Comparative Study of Support Vector Machines Applied to the Word Sense Disambiguation Problem for the Medical Domain. In Proceedings of the Second Indian Conference on Artificial Intelligence (IICAI-05), pages 3449– 3468, Pune, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Joshi</author>
<author>S Pakhomov</author>
<author>T Pedersen</author>
<author>C Chute</author>
</authors>
<title>A comparative study of supervised learning as applied to acronym expansion in clinical reports.</title>
<date>2006</date>
<booktitle>In Proceedings of the Annual Symposium of the American Medical Informatics Association,</booktitle>
<pages>399--403</pages>
<location>Washington, DC.</location>
<contexts>
<context position="6540" citStr="Joshi et al. (2006)" startWordPosition="1000" endWordPosition="1003">s: Naive Bayes and Support Vector Machines. They extracted a corpus containing examples of 60 abbreviations from a set of biomedical journal articles which was split so that abstracts in which the abbreviations were defined were used as training data and those in which no definition is found as test data. Abbreviations in the test portion were manually disambiguated. They report 79% coverage and 80% precision using a Naive Bayes classifier. Pakhomov (2002) applied a maximum entropy model to identify the meanings of ambiguous abbreviations in 10,000 rheumatology notes with around 89% accuracy. Joshi et al. (2006) disambiguated abbreviations in clinical notes using three supervised learning algorithms (Naive Bayes, decision trees and Support Vector Machines). They used a range of features and found that the best performance was obtained when these were combined. Unfortunately direct comparison of these methods is made difficult by the fact that various researchers have evaluated their approaches on different data sets. A variety of approaches have also been proposed for the problem of disambiguating local abbreviations in biomedical documents. This task is equivalent to identifying the abbreviation’s e</context>
</contexts>
<marker>Joshi, Pakhomov, Pedersen, Chute, 2006</marker>
<rawString>M. Joshi, S. Pakhomov, T. Pedersen, and C. Chute. 2006. A comparative study of supervised learning as applied to acronym expansion in clinical reports. In Proceedings of the Annual Symposium of the American Medical Informatics Association, pages 399–403, Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
</authors>
<title>Dictionary word sense distinctions: An enquiry into their nature.</title>
<date>1993</date>
<booktitle>Computers and the Humanities,</booktitle>
<pages>26--356</pages>
<contexts>
<context position="25660" citStr="Kilgarriff, 1993" startWordPosition="4103" endWordPosition="4104">n for this is that the various expansions of abbreviations in our corpus are more distinct and better defined than senses for general terms. For example, the three possible expansions for “ANA” in our corpus are a professional body (“American Nurses Association”), a type of medical test (“antinuclear”) and a neurotransmitter (“Anandamide”). It is likely that these diverse meanings will tend to occur in very different contexts and in documents with different topics. On the other hand it is widely accepted that distinctions between possible meanings of words in natural language are often vague (Kilgarriff, 1993). It is likely that clearer distinctions between possible expansions of abbreviations make the task of identifying the correct one more straightforward than identifying meanings of ambiguous words. In addition, the creation of annotated data for WSD is often hampered by the difficulty in obtaining sufficient agreement between annotators (Artstein and Poesio, 2008; Weeber et al., 2001) and this problem does not apply to our automatically-generated corpus. Results in Table 2 indicate that CUIs are useful features in the disambiguation of abbreviations. This is in contrast with previous experimen</context>
</contexts>
<marker>Kilgarriff, 1993</marker>
<rawString>A. Kilgarriff. 1993. Dictionary word sense distinctions: An enquiry into their nature. Computers and the Humanities, 26:356–387.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Liu</author>
<author>Y Lussier</author>
<author>C Friedman</author>
</authors>
<title>Disambiguating ambiguous biomedical terms in biomedical narrative text: An unsupervised method.</title>
<date>2001</date>
<journal>Journal of Biomedical Informatics,</journal>
<pages>34--249</pages>
<contexts>
<context position="5016" citStr="Liu et al. (2001)" startWordPosition="751" endWordPosition="754">s corpus. Our conclusions are presented in Section 6. 2 Previous Work Gaudan et al. (2005) distinguish two types of abbreviations: global and local. Global abbreviations are those found in documents without the expansion explicitly stated, while local abbreviations are defined in the same document in which the abbreviation occurs. Our work is concerned with the problem of disambiguating global abbreviations. Gaudan et al. (2005) point out that global abbreviations are often ambiguous. Various researchers have explored the problem of disambiguating global abbreviations in biomedical documents. Liu et al. (2001)(2002) used several domain-specific knowledge sources to identify terms which are semantically related to each possible expansion but which have only one sense themselves. Instances of these terms were identified in a corpus of biomedical journal abstracts and used as training data. Their learning algorithm uses a variety of features including all words in the abstract and collocations of the ambiguous abbreviation. They report an accuracy of 97% on a small set of abbreviations. Liu et al. (2004) present a fully supervised approach. They compared a variety of supervised machine learning algori</context>
<context position="15611" citStr="Liu et al. (2001)" startWordPosition="2451" endWordPosition="2454">consuming and difficult (Artstein and Poesio, 2008). An alternative to manual tagging is to find a way of automatically creating sense tagged corpora. For the translation of ambiguous English words Ng et al. (2003) made use of the fact that the various senses are often translated differently. For example when “bank” is used in the ‘financial institution’ sense it is translated to French as “banque” and “bord” when it is used to mean ‘edge of river’. However, a disadvantage of this approach is that it relies on the existence of parallel text which may not be available. In the biomedical domain Liu et al. (2001)(2002) created a corpus using unambiguous related terms (see Section 2) although they found that it was not always possible to identify suitable related terms. 4.1 Corpus Creation Liu et al. (2001) also made use of the fact that when abbreviations are introduced they are often accompanied by their expansion, for example “BSA (bovine serum albumin)”. This phenomenon was exploited to automatically generate a corpus of abbreviations and associated definitions by replacing the abbreviation and expansion with the abbreviation alone. For example, the sentence “The adsorption behavior of bovine serum</context>
<context position="23063" citStr="Liu et al. (2001)" startWordPosition="3684" endWordPosition="3687">are added. However, even when the number of examples is relatively low, just 100, performance of the best configuration (VSM learning algorithm with all three types of feature) is 97.4%. The best result, 99% (300 training examples, VSM learning algorithm with all feature types), exceeds reported performance of previous abbreviation disambiguation systems (see Section 2). Although these results are not directly comparable, since these studies used different evaluation corpora, the set of ambiguous abbreviations used in this study and methodology for corpus creation are similar to those used by Liu et al. (2001)(2002)(2004). The best performance for each learning algorithm is obtained when all three types of features are combined. The difference between performance obtained using all three feature types and using only the MeSH or CUI features is statistically significant (Wilcoxon Signed Ranks test, p &lt; 0.01) although the difference between this and performance using just the linguistic features is not. The VSM learning algorithm generally performs better than either the SVM or Naive Bayes learning algorithms. The difference between performance of VSM and the other algorithms is statistically signifi</context>
</contexts>
<marker>Liu, Lussier, Friedman, 2001</marker>
<rawString>H. Liu, Y. Lussier, and C. Friedman. 2001. Disambiguating ambiguous biomedical terms in biomedical narrative text: An unsupervised method. Journal of Biomedical Informatics, 34:249–261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Liu</author>
<author>S Johnson</author>
<author>C Friedman</author>
</authors>
<title>Automatic Resolution of Ambiguous Terms Based on Machine Learning and Conceptual Relations in the UMLS.</title>
<date>2002</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>9</volume>
<issue>6</issue>
<contexts>
<context position="16808" citStr="Liu et al., 2002" startWordPosition="2639" endWordPosition="2642">ior of bovine serum albumin (BSA) on a Sepharose based hydrophobic interaction support has been studied.” becomes “The adsorption behav74 “BSA” AND “body surface area” NOT “bovine serum albumin” “BSA” AND “bovine serum albumin” NOT “body surface area” Figure 1: Example queries for abbreviation “BSA” ior of BSA on a Sepharose based hydrophobic interaction support has been studied.” We used this approach to create a corpus of sense tagged abbreviations in biomedical documents using a set of 21 three letter abbreviations used in previous research on abbreviation disambiguation (Liu et al., 2001; Liu et al., 2002; Liu et al., 2004). Possible expansions for the majority of these abbreviations were listed in these papers. For the few remaining ones possible expansions were taken from the Medstract database (Pustejovsky et al., 2002). We searched for instances of these abbreviations in Medline, a database containing more than 18 million abstracts from publications in biomedicine and the life sciences. For each abbreviation we queried Medline, using the Entrez interface, to identify documents containing one of its meanings. For example the abbreviation “BSA” has two possible expansions: “body surface area</context>
</contexts>
<marker>Liu, Johnson, Friedman, 2002</marker>
<rawString>H. Liu, S. Johnson, and C. Friedman. 2002. Automatic Resolution of Ambiguous Terms Based on Machine Learning and Conceptual Relations in the UMLS. Journal of the American Medical Informatics Association, 9(6):621–636.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Liu</author>
<author>V Teller</author>
<author>C Friedman</author>
</authors>
<title>A Multi-aspect Comparison Study of Supervised Word Sense Disambiguation.</title>
<date>2004</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>11</volume>
<issue>4</issue>
<contexts>
<context position="5517" citStr="Liu et al. (2004)" startWordPosition="833" endWordPosition="836">earchers have explored the problem of disambiguating global abbreviations in biomedical documents. Liu et al. (2001)(2002) used several domain-specific knowledge sources to identify terms which are semantically related to each possible expansion but which have only one sense themselves. Instances of these terms were identified in a corpus of biomedical journal abstracts and used as training data. Their learning algorithm uses a variety of features including all words in the abstract and collocations of the ambiguous abbreviation. They report an accuracy of 97% on a small set of abbreviations. Liu et al. (2004) present a fully supervised approach. They compared a variety of supervised machine learning algorithms and found that the best performance over a set of 15 ambiguous abbreviations, 98.6%, was obtained using Naive Bayes. Gaudan et al. (2005) use a Support Vector Machine trained on a bag-of-words model and report an accuracy of 98.5%. Yu et al. (2006) experimented with two supervised learning algorithms: Naive Bayes and Support Vector Machines. They extracted a corpus containing examples of 60 abbreviations from a set of biomedical journal articles which was split so that abstracts in which the</context>
<context position="9837" citStr="Liu et al., 2004" startWordPosition="1520" endWordPosition="1523">ore diverse than have been explored by previous approaches to abbreviation disambiguation. 3.1 Features Our feature set contains a number of parameters (e.g. thresholds for unigram and CUI frequencies). These parameters were set to the same values that were used when the system was applied to general biomedical terms (Stevenson et al., 2008) since these were found to perform well. We also use the entire abstract as the context of the ambiguous term for relevant features rather than just the sentence containing the term. Effects of altering these variables are consistent with previous results (Liu et al., 2004; Joshi et al., 2005; McInnes et al., 2007) and are not reported here. General features: The system uses a wide range of domain-independent features that are commonly employed for WSD. • Local collocations: A total of 41 features which extensively describe the context of the ambiguous word and fall into two main types: (1) bigrams and trigrams containing the ambiguous word constructed from lemmas, word forms or PoS tags and (2) preceding/following lemma/word-form of the content words (adjective, adverb, noun and verb) in the same sentence as the ambiguous abbreviation. For example, consider th</context>
<context position="16827" citStr="Liu et al., 2004" startWordPosition="2643" endWordPosition="2646">m albumin (BSA) on a Sepharose based hydrophobic interaction support has been studied.” becomes “The adsorption behav74 “BSA” AND “body surface area” NOT “bovine serum albumin” “BSA” AND “bovine serum albumin” NOT “body surface area” Figure 1: Example queries for abbreviation “BSA” ior of BSA on a Sepharose based hydrophobic interaction support has been studied.” We used this approach to create a corpus of sense tagged abbreviations in biomedical documents using a set of 21 three letter abbreviations used in previous research on abbreviation disambiguation (Liu et al., 2001; Liu et al., 2002; Liu et al., 2004). Possible expansions for the majority of these abbreviations were listed in these papers. For the few remaining ones possible expansions were taken from the Medstract database (Pustejovsky et al., 2002). We searched for instances of these abbreviations in Medline, a database containing more than 18 million abstracts from publications in biomedicine and the life sciences. For each abbreviation we queried Medline, using the Entrez interface, to identify documents containing one of its meanings. For example the abbreviation “BSA” has two possible expansions: “body surface area” and “bovine serum</context>
</contexts>
<marker>Liu, Teller, Friedman, 2004</marker>
<rawString>H. Liu, V. Teller, and C. Friedman. 2004. A Multi-aspect Comparison Study of Supervised Word Sense Disambiguation. Journal of the American Medical Informatics Association, 11(4):320–331.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B McInnes</author>
<author>T Pedersen</author>
<author>J Carlis</author>
</authors>
<title>Using UMLS Concept Unique Identifiers (CUIs) for Word Sense Disambiguation in the Biomedical Domain.</title>
<date>2007</date>
<booktitle>In Proceedings of the Annual Symposium of the American Medical Informatics Association,</booktitle>
<pages>533--537</pages>
<location>Chicago, IL.</location>
<contexts>
<context position="9152" citStr="McInnes et al. (2007)" startWordPosition="1408" endWordPosition="1411">r the lexical sample tasks in two languages while the version adapted to the biomedical domain has achieved the best recorded results (Stevenson et al., 2008) on a standard test set consisting of ambiguous terms (Weeber et al., 2001). This system is based on a supervised learning approach with features derived from text around the ambiguous word that are domain independent. We refer to these as general features. This feature set has been adapted for the disambiguation of biomedical text by adding further linguistic features and two different types of domain-specific features: CUIs (as used by McInnes et al. (2007)) and Medical Subject Heading (MeSH) terms. This set of features is more diverse than have been explored by previous approaches to abbreviation disambiguation. 3.1 Features Our feature set contains a number of parameters (e.g. thresholds for unigram and CUI frequencies). These parameters were set to the same values that were used when the system was applied to general biomedical terms (Stevenson et al., 2008) since these were found to perform well. We also use the entire abstract as the context of the ambiguous term for relevant features rather than just the sentence containing the term. Effec</context>
<context position="11295" citStr="McInnes et al. (2007)" startWordPosition="1752" endWordPosition="1755">NNP”, right-POS “NNP VBD”, left-contentword-form “Lean BSA”, right-function-wordform “BSA was”, etc. • Salient bigrams: Salient bigrams within the abstract with high log-likelihood scores, as described by Pedersen (2001). • Unigrams: Lemmas of all content words in the abstract and words within a ±4-word window around the target word, excluding those in a list of stopwords. In addition, the lemmas of any unigrams appearing at least twice in the entire corpus and which are found in the abstract are also included as features. Concept Unique Identifiers (CUIs): We follow the approach presented by McInnes et al. (2007) to generate features based on UMLS Concept Unique Identifiers (CUIs). The MetaMap program (Aronson, 2001) identifies all words and terms in a text which could be mapped onto a UMLS CUI. MetaMap does not disambiguate the senses of the concepts, instead it enumerates likely candidate concepts. For example, MetaMap will segment the phrase “Lean BSA was obtained from height and lean body weight ...” into four chunks: “Lean BSA”, “obtained”, “from height” and “lean body weight”. The first chunk will be mapped onto three CUIs: “C1261466: BSA (Body surface area)”, “C1511233: BSA (NCI Board of Scient</context>
</contexts>
<marker>McInnes, Pedersen, Carlis, 2007</marker>
<rawString>B. McInnes, T. Pedersen, and J. Carlis. 2007. Using UMLS Concept Unique Identifiers (CUIs) for Word Sense Disambiguation in the Biomedical Domain. In Proceedings of the Annual Symposium of the American Medical Informatics Association, pages 533–537, Chicago, IL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>T Chklovski</author>
<author>A Kilgarriff</author>
</authors>
<title>The Senseval-3 English lexical sample task.</title>
<date>2004</date>
<booktitle>In Proceedings of Senseval-3: The Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="8484" citStr="Mihalcea et al., 2004" startWordPosition="1297" endWordPosition="1300">ribe an approach which starts by identifying the set of candidate expansions in the same sentence as an abbreviation. The most likely one is identified by searching for the 72 shortest candidate which contains all the characters in the abbreviation in the correct order. 3 Abbreviation Disambiguation System Our abbreviation disambiguation system is based on a state-of-the-art WSD system that has been adapted to the biomedical domain by augmenting it with additional knowledge sources. The system on which our approach is based (Agirre and Martinez, 2004) participated in the Senseval-3 challenge (Mihalcea et al., 2004) with a performance close to the best system for the lexical sample tasks in two languages while the version adapted to the biomedical domain has achieved the best recorded results (Stevenson et al., 2008) on a standard test set consisting of ambiguous terms (Weeber et al., 2001). This system is based on a supervised learning approach with features derived from text around the ambiguous word that are domain independent. We refer to these as general features. This feature set has been adapted for the disambiguation of biomedical text by adding further linguistic features and two different types</context>
</contexts>
<marker>Mihalcea, Chklovski, Kilgarriff, 2004</marker>
<rawString>R. Mihalcea, T. Chklovski, and A. Kilgarriff. 2004. The Senseval-3 English lexical sample task. In Proceedings of Senseval-3: The Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Nelson</author>
<author>T Powell</author>
<author>B Humphreys</author>
</authors>
<title>The Unified Medical Language System</title>
<date>2002</date>
<booktitle>Encyclopedia of Library and Information Science.</booktitle>
<editor>(UMLS) Project. In Allen Kent and Carolyn M. Hall, editors,</editor>
<publisher>Marcel Dekker, Inc.</publisher>
<contexts>
<context position="12573" citStr="Nelson et al., 2002" startWordPosition="1955" endWordPosition="1958">”. The chunk “lean body weight” is mapped onto two concepts: “C0005910: Body Weight” 73 and “C1305866: Body Weight (Weighing patient)”1. CUIs occurring more than twice in an abstract are included as features. CUIs have been used for various disambiguation tasks in the biomedical domain, including disambiguation of ambiguous general terms (McInnes et al., 2007) and gene symbol disambiguation (Xu et al., 2007), but not, to our knowledge, for abbreviation disambiguation. Medical Subject Headings (MeSH): The final feature is also specific to the biomedical domain. Medical Subject Headings (MeSH) (Nelson et al., 2002) is a controlled vocabulary for indexing biomedical and health-related information and documents. MeSH terms are manually assigned to abstracts by human indexers. The latest version of MeSH (2009) contains over 25,000 terms organised into an 11 level hierarchy. The MeSH terms assigned to the abstract in which each ambiguous word occurs are used as features. For example, the abstract containing our example phrase has been assigned 16 terms including “Body Surface Area”, “Body Weight”, “Humans” and “Organ Size” . MeSH terms have previously been used for abbreviation disambiguation by Yu et al. (</context>
</contexts>
<marker>Nelson, Powell, Humphreys, 2002</marker>
<rawString>S. Nelson, T. Powell, and B. Humphreys. 2002. The Unified Medical Language System (UMLS) Project. In Allen Kent and Carolyn M. Hall, editors, Encyclopedia of Library and Information Science. Marcel Dekker, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ng</author>
<author>B Wang</author>
<author>S Chan</author>
</authors>
<title>Exploiting Parallel Texts for Word Sense Disambiguation: an Empirical Study.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL03),</booktitle>
<pages>455--462</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="15208" citStr="Ng et al. (2003)" startWordPosition="2379" endWordPosition="2382">atest separation between the classes. We used our own implementation of the Vector Space Model and Weka implementations (Witten and Frank, 2005) of the other two algorithms. 4 Evaluation Corpus The most common method for generating corpora to train and test WSD systems is to manually annotate instances of ambiguous terms found in text with the appropriate meaning. However, this process is both time-consuming and difficult (Artstein and Poesio, 2008). An alternative to manual tagging is to find a way of automatically creating sense tagged corpora. For the translation of ambiguous English words Ng et al. (2003) made use of the fact that the various senses are often translated differently. For example when “bank” is used in the ‘financial institution’ sense it is translated to French as “banque” and “bord” when it is used to mean ‘edge of river’. However, a disadvantage of this approach is that it relies on the existence of parallel text which may not be available. In the biomedical domain Liu et al. (2001)(2002) created a corpus using unambiguous related terms (see Section 2) although they found that it was not always possible to identify suitable related terms. 4.1 Corpus Creation Liu et al. (2001)</context>
</contexts>
<marker>Ng, Wang, Chan, 2003</marker>
<rawString>H. Ng, B. Wang, and S. Chan. 2003. Exploiting Parallel Texts for Word Sense Disambiguation: an Empirical Study. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL03), pages 455–462, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Okazaki</author>
<author>S Ananiadou</author>
<author>J Tsujii</author>
</authors>
<title>A discriminative alignment model for abbreviation recognition.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (Coling</booktitle>
<pages>657--664</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="7532" citStr="Okazaki et al. (2008)" startWordPosition="1148" endWordPosition="1151">d their approaches on different data sets. A variety of approaches have also been proposed for the problem of disambiguating local abbreviations in biomedical documents. This task is equivalent to identifying the abbreviation’s expansion in the document. The problem is relatively straightforward for abbreviations which are created by selecting the first character from each word in the expansion, such as “angiotensin converting enzyme (ACE)”, but is more difficult when this convention is not followed, for example “acetylchlinesterase (ACE)”, “antisocial personality (ASP)” and “catalase (CAT)”. Okazaki et al. (2008) recently proposed an approach to this problem based on discriminative alignment that has been shown to perform well. However, the most common solutions are based on heuristic approaches, for example Adar (2004) and Zhou et al. (2006). Pustejovsky et al. (2002) used hand-built regular expressions. Schwartz and Hearst (2003) describe an approach which starts by identifying the set of candidate expansions in the same sentence as an abbreviation. The most likely one is identified by searching for the 72 shortest candidate which contains all the characters in the abbreviation in the correct order.</context>
</contexts>
<marker>Okazaki, Ananiadou, Tsujii, 2008</marker>
<rawString>N. Okazaki, S. Ananiadou, and J. Tsujii. 2008. A discriminative alignment model for abbreviation recognition. In Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 657–664, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pakhomov</author>
</authors>
<title>Semi-supervised maximum entropy based approach to acronym and abbreviation normalization in medical texts.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="6381" citStr="Pakhomov (2002)" startWordPosition="976" endWordPosition="978">upport Vector Machine trained on a bag-of-words model and report an accuracy of 98.5%. Yu et al. (2006) experimented with two supervised learning algorithms: Naive Bayes and Support Vector Machines. They extracted a corpus containing examples of 60 abbreviations from a set of biomedical journal articles which was split so that abstracts in which the abbreviations were defined were used as training data and those in which no definition is found as test data. Abbreviations in the test portion were manually disambiguated. They report 79% coverage and 80% precision using a Naive Bayes classifier. Pakhomov (2002) applied a maximum entropy model to identify the meanings of ambiguous abbreviations in 10,000 rheumatology notes with around 89% accuracy. Joshi et al. (2006) disambiguated abbreviations in clinical notes using three supervised learning algorithms (Naive Bayes, decision trees and Support Vector Machines). They used a range of features and found that the best performance was obtained when these were combined. Unfortunately direct comparison of these methods is made difficult by the fact that various researchers have evaluated their approaches on different data sets. A variety of approaches hav</context>
</contexts>
<marker>Pakhomov, 2002</marker>
<rawString>S. Pakhomov. 2002. Semi-supervised maximum entropy based approach to acronym and abbreviation normalization in medical texts. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 160–167, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
</authors>
<title>A Decision Tree of Bigrams is an Accurate Predictor of Word Sense.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL-01),</booktitle>
<pages>79--86</pages>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="10894" citStr="Pedersen (2001)" startWordPosition="1686" endWordPosition="1687">following lemma/word-form of the content words (adjective, adverb, noun and verb) in the same sentence as the ambiguous abbreviation. For example, consider the sentence below with the target abreviation BSA. “Lean BSA was obtained from height and lean body weight ...” The features would include the following: left-content-word-lemma “lean BSA”, rightfunction-word-lemma “BSA be”, left-POS “JJ NNP”, right-POS “NNP VBD”, left-contentword-form “Lean BSA”, right-function-wordform “BSA was”, etc. • Salient bigrams: Salient bigrams within the abstract with high log-likelihood scores, as described by Pedersen (2001). • Unigrams: Lemmas of all content words in the abstract and words within a ±4-word window around the target word, excluding those in a list of stopwords. In addition, the lemmas of any unigrams appearing at least twice in the entire corpus and which are found in the abstract are also included as features. Concept Unique Identifiers (CUIs): We follow the approach presented by McInnes et al. (2007) to generate features based on UMLS Concept Unique Identifiers (CUIs). The MetaMap program (Aronson, 2001) identifies all words and terms in a text which could be mapped onto a UMLS CUI. MetaMap does</context>
</contexts>
<marker>Pedersen, 2001</marker>
<rawString>T. Pedersen. 2001. A Decision Tree of Bigrams is an Accurate Predictor of Word Sense. In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL-01), pages 79–86, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
<author>J Castano</author>
<author>R Saur</author>
<author>A Rumshisky</author>
<author>J Zhang</author>
<author>W Luo</author>
</authors>
<title>Medstract: Creating Large-scale Information Servers for Biomedical Libraries.</title>
<date>2002</date>
<booktitle>In ACL 2002 Workshop on Natural Language Processing in the Biomedical Domain.</booktitle>
<contexts>
<context position="2481" citStr="Pustejovsky et al. (2002)" startWordPosition="365" endWordPosition="368"> is often the case in biomedical documents, in this domain ubiquitous abbreviations (such as DNA and mRNA) often appear without an expansion. It has been reported that misinterpretation of abbreviations in biomedical documents has lead to medical practitioners making fatal errors (Fred and Cheng, 1999). However, identifying the correct expansion is not a straightforward task since an abbreviation may have several possible expansions. Chang et al. (2002) reported that abbreviations in biomedical journal articles consisting of six characters or less have an average of 4.61 possible meanings and Pustejovsky et al. (2002) mention that the simple abbreviation “AC” is associated with at least 10 strings in different biomedical documents including “atrioventricular connection”, “anterior colporrhaphy procedure”, “auditory cortex” and “atypical carcinoid”. The problem of identifying the correct expansion of an ambiguous abbreviation can be viewed as a Word Sense Disambiguation (WSD) task where the various expansions are the “senses” of the abbreviation. In this paper we approach the problem in this way by applying a WSD system which has previously been applied to biomedical text (Stevenson et al., 2008). The WSD s</context>
<context position="7793" citStr="Pustejovsky et al. (2002)" startWordPosition="1192" endWordPosition="1195">e problem is relatively straightforward for abbreviations which are created by selecting the first character from each word in the expansion, such as “angiotensin converting enzyme (ACE)”, but is more difficult when this convention is not followed, for example “acetylchlinesterase (ACE)”, “antisocial personality (ASP)” and “catalase (CAT)”. Okazaki et al. (2008) recently proposed an approach to this problem based on discriminative alignment that has been shown to perform well. However, the most common solutions are based on heuristic approaches, for example Adar (2004) and Zhou et al. (2006). Pustejovsky et al. (2002) used hand-built regular expressions. Schwartz and Hearst (2003) describe an approach which starts by identifying the set of candidate expansions in the same sentence as an abbreviation. The most likely one is identified by searching for the 72 shortest candidate which contains all the characters in the abbreviation in the correct order. 3 Abbreviation Disambiguation System Our abbreviation disambiguation system is based on a state-of-the-art WSD system that has been adapted to the biomedical domain by augmenting it with additional knowledge sources. The system on which our approach is based (</context>
<context position="17030" citStr="Pustejovsky et al., 2002" startWordPosition="2676" endWordPosition="2679">serum albumin” NOT “body surface area” Figure 1: Example queries for abbreviation “BSA” ior of BSA on a Sepharose based hydrophobic interaction support has been studied.” We used this approach to create a corpus of sense tagged abbreviations in biomedical documents using a set of 21 three letter abbreviations used in previous research on abbreviation disambiguation (Liu et al., 2001; Liu et al., 2002; Liu et al., 2004). Possible expansions for the majority of these abbreviations were listed in these papers. For the few remaining ones possible expansions were taken from the Medstract database (Pustejovsky et al., 2002). We searched for instances of these abbreviations in Medline, a database containing more than 18 million abstracts from publications in biomedicine and the life sciences. For each abbreviation we queried Medline, using the Entrez interface, to identify documents containing one of its meanings. For example the abbreviation “BSA” has two possible expansions: “body surface area” and “bovine serum alumin”. Medline is searched to identify documents that contain each possible expansion of the abbreviation using the queries shown in Figure 1. Each query matches documents containing the abbreviation </context>
</contexts>
<marker>Pustejovsky, Castano, Saur, Rumshisky, Zhang, Luo, 2002</marker>
<rawString>J. Pustejovsky, J. Castano, R. Saur, A. Rumshisky, J. Zhang, and W. Luo. 2002. Medstract: Creating Large-scale Information Servers for Biomedical Libraries. In ACL 2002 Workshop on Natural Language Processing in the Biomedical Domain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Schwartz</author>
<author>M Hearst</author>
</authors>
<title>A simple algorithm for identifying abbreviation definitions in biomedical text.</title>
<date>2003</date>
<booktitle>In Proceedings of the Pacific Symposium on Biocomputing, Kauai.</booktitle>
<contexts>
<context position="7857" citStr="Schwartz and Hearst (2003)" startWordPosition="1200" endWordPosition="1203"> are created by selecting the first character from each word in the expansion, such as “angiotensin converting enzyme (ACE)”, but is more difficult when this convention is not followed, for example “acetylchlinesterase (ACE)”, “antisocial personality (ASP)” and “catalase (CAT)”. Okazaki et al. (2008) recently proposed an approach to this problem based on discriminative alignment that has been shown to perform well. However, the most common solutions are based on heuristic approaches, for example Adar (2004) and Zhou et al. (2006). Pustejovsky et al. (2002) used hand-built regular expressions. Schwartz and Hearst (2003) describe an approach which starts by identifying the set of candidate expansions in the same sentence as an abbreviation. The most likely one is identified by searching for the 72 shortest candidate which contains all the characters in the abbreviation in the correct order. 3 Abbreviation Disambiguation System Our abbreviation disambiguation system is based on a state-of-the-art WSD system that has been adapted to the biomedical domain by augmenting it with additional knowledge sources. The system on which our approach is based (Agirre and Martinez, 2004) participated in the Senseval-3 challe</context>
<context position="17825" citStr="Schwartz and Hearst (2003)" startWordPosition="2799" endWordPosition="2802">s. For each abbreviation we queried Medline, using the Entrez interface, to identify documents containing one of its meanings. For example the abbreviation “BSA” has two possible expansions: “body surface area” and “bovine serum alumin”. Medline is searched to identify documents that contain each possible expansion of the abbreviation using the queries shown in Figure 1. Each query matches documents containing the abbreviation and relevant expansion and no mentions of the other possible expansion(s). The retrieved documents are then processed to remove the expansions of each abbreviation. The Schwartz and Hearst (2003) algorithm for identifying abbreviations and the relevant expansion (see Section 2) is then run over each of the retrieved abstracts to identify the correct expansion. The expansion is removed from the document and stored separately, effectively creating a sense tagged corpus. For convenience the abstracts are converted into a format similar to the one used for the NLM-WSD corpus (Weeber et al., 2001). The resulting corpus consists of 55,655 documents. For each abbreviation Table 1 shows the number of abstracts retrieved from Medline (in the column labeled “Abstracts”) and the number of expans</context>
</contexts>
<marker>Schwartz, Hearst, 2003</marker>
<rawString>A. Schwartz and M. Hearst. 2003. A simple algorithm for identifying abbreviation definitions in biomedical text. In Proceedings of the Pacific Symposium on Biocomputing, Kauai.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stevenson</author>
<author>Y Guo</author>
<author>R Gaizauskas</author>
<author>D Martinez</author>
</authors>
<title>Disambiguation of biomedical text using diverse sources of information.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<pages>11--7</pages>
<contexts>
<context position="3070" citStr="Stevenson et al., 2008" startWordPosition="455" endWordPosition="458">ings and Pustejovsky et al. (2002) mention that the simple abbreviation “AC” is associated with at least 10 strings in different biomedical documents including “atrioventricular connection”, “anterior colporrhaphy procedure”, “auditory cortex” and “atypical carcinoid”. The problem of identifying the correct expansion of an ambiguous abbreviation can be viewed as a Word Sense Disambiguation (WSD) task where the various expansions are the “senses” of the abbreviation. In this paper we approach the problem in this way by applying a WSD system which has previously been applied to biomedical text (Stevenson et al., 2008). The WSD system uses a variety of information sources, including those traditionally applied to the WSD problem in addition to two knowledge sources that are specific to the biomedical domain. Evaluation of systems for disambiguating ambiguous abbreviations has been hindered by the fact Proceedings of the Workshop on BioNLP, pages 71–79, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics that there is no freely available benchmark corpus against which approaches can be compared. We describe a process whereby such a corpus can be created by automatically mining abst</context>
<context position="8689" citStr="Stevenson et al., 2008" startWordPosition="1331" endWordPosition="1334">tains all the characters in the abbreviation in the correct order. 3 Abbreviation Disambiguation System Our abbreviation disambiguation system is based on a state-of-the-art WSD system that has been adapted to the biomedical domain by augmenting it with additional knowledge sources. The system on which our approach is based (Agirre and Martinez, 2004) participated in the Senseval-3 challenge (Mihalcea et al., 2004) with a performance close to the best system for the lexical sample tasks in two languages while the version adapted to the biomedical domain has achieved the best recorded results (Stevenson et al., 2008) on a standard test set consisting of ambiguous terms (Weeber et al., 2001). This system is based on a supervised learning approach with features derived from text around the ambiguous word that are domain independent. We refer to these as general features. This feature set has been adapted for the disambiguation of biomedical text by adding further linguistic features and two different types of domain-specific features: CUIs (as used by McInnes et al. (2007)) and Medical Subject Heading (MeSH) terms. This set of features is more diverse than have been explored by previous approaches to abbrev</context>
<context position="24109" citStr="Stevenson et al., 2008" startWordPosition="3848" endWordPosition="3851">thm generally performs better than either the SVM or Naive Bayes learning algorithms. The difference between performance of VSM and the other algorithms is statistically significant for Corpus.100 but not for the other two, suggesting that this learning algorithm is better able to cope with small number of training examples than Naive Bayes and Support Vector Machines. Strong performance of the VSM algorithm is consistent with previous work which has shown that this algorithm performs well on the disambiguation of ambiguous terms in both biomedical and general text (Agirre and Martinez, 2004; Stevenson et al., 2008). 76 Features Algorithm Linguistic CUI MeSH Linguistic Linguistic CUI+ Linguistic+ +CUI +MeSH MeSH MeSH+CUI Corpus.100 (Baseline = 69.0%) SVM 0.934 0.900 0.949 0.947 0.946 0.938 0.954 NB 0.940 0.917 0.949 0.951 0.947 0.944 0.958 VSM 0.968 0.937 0.888 0.970 0.971 0.939 0.974 Corpus.200 (Baseline = 69.1%) SVM 0.957 0.911 0.964 0.964 0.964 0.947 0.965 NB 0.966 0.926 0.962 0.969 0.971 0.955 0.972 VSM 0.979 0.930 0.894 0.982 0.981 0.947 0.984 Corpus.300 (Baseline = 68.7%) SVM 0.966 0.914 0.970 0.968 0.974 0.954 0.975 NB 0.971 0.933 0.960 0.971 0.976 0.960 0.978 VSM 0.981 0.938 0.894 0.987 0.985 0.9</context>
<context position="26330" citStr="Stevenson et al., 2008" startWordPosition="4204" endWordPosition="4207">n possible expansions of abbreviations make the task of identifying the correct one more straightforward than identifying meanings of ambiguous words. In addition, the creation of annotated data for WSD is often hampered by the difficulty in obtaining sufficient agreement between annotators (Artstein and Poesio, 2008; Weeber et al., 2001) and this problem does not apply to our automatically-generated corpus. Results in Table 2 indicate that CUIs are useful features in the disambiguation of abbreviations. This is in contrast with previous experiments on ambiguous terms in biomedical documents (Stevenson et al., 2008) in which it was found that the best performance as obtained using only linguistic and MeSH features. It is likely that the clear distinction between expansions of abbreviations is the reason behind this difference. CUIs are assigned automatically by the MetaMap program (Aronson, 2001). However, this assignment is very noisy. It is likely that the various expansions of abbreviations are distinct enough for this noise to be tolerated by the learning algorithms while it causes problems when the meanings are closer together, such as in the case of ambiguous terms. 5.1 Performance of Individual Ab</context>
</contexts>
<marker>Stevenson, Guo, Gaizauskas, Martinez, 2008</marker>
<rawString>M. Stevenson, Y. Guo, R. Gaizauskas, and D. Martinez. 2008. Disambiguation of biomedical text using diverse sources of information. BMC Bioinformatics, 9(Suppl 11):S7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Weeber</author>
<author>J Mork</author>
<author>A Aronson</author>
</authors>
<title>Developing a Test Collection for Biomedical Word Sense Disambiguation.</title>
<date>2001</date>
<booktitle>In Proceedings of AMAI Symposium,</booktitle>
<pages>746--50</pages>
<location>Washington, DC.</location>
<contexts>
<context position="8764" citStr="Weeber et al., 2001" startWordPosition="1345" endWordPosition="1348">ion Disambiguation System Our abbreviation disambiguation system is based on a state-of-the-art WSD system that has been adapted to the biomedical domain by augmenting it with additional knowledge sources. The system on which our approach is based (Agirre and Martinez, 2004) participated in the Senseval-3 challenge (Mihalcea et al., 2004) with a performance close to the best system for the lexical sample tasks in two languages while the version adapted to the biomedical domain has achieved the best recorded results (Stevenson et al., 2008) on a standard test set consisting of ambiguous terms (Weeber et al., 2001). This system is based on a supervised learning approach with features derived from text around the ambiguous word that are domain independent. We refer to these as general features. This feature set has been adapted for the disambiguation of biomedical text by adding further linguistic features and two different types of domain-specific features: CUIs (as used by McInnes et al. (2007)) and Medical Subject Heading (MeSH) terms. This set of features is more diverse than have been explored by previous approaches to abbreviation disambiguation. 3.1 Features Our feature set contains a number of pa</context>
<context position="18229" citStr="Weeber et al., 2001" startWordPosition="2866" endWordPosition="2869">ing the abbreviation and relevant expansion and no mentions of the other possible expansion(s). The retrieved documents are then processed to remove the expansions of each abbreviation. The Schwartz and Hearst (2003) algorithm for identifying abbreviations and the relevant expansion (see Section 2) is then run over each of the retrieved abstracts to identify the correct expansion. The expansion is removed from the document and stored separately, effectively creating a sense tagged corpus. For convenience the abstracts are converted into a format similar to the one used for the NLM-WSD corpus (Weeber et al., 2001). The resulting corpus consists of 55,655 documents. For each abbreviation Table 1 shows the number of abstracts retrieved from Medline (in the column labeled “Abstracts”) and the number of expansions (“Count” column). The column labelled “Rare” lists the number of expansions that account for fewer than 1% of the occurrences of an abbreviation and “Frequent” lists the percentage of occurances represented by the most frequent expansion. It can be seen that there is a wide variation between the number of abstracts retrieved for each abbreviation. CSF occurs in 14,871 abstracts and ASP in just 71</context>
<context position="26047" citStr="Weeber et al., 2001" startWordPosition="4160" endWordPosition="4163">will tend to occur in very different contexts and in documents with different topics. On the other hand it is widely accepted that distinctions between possible meanings of words in natural language are often vague (Kilgarriff, 1993). It is likely that clearer distinctions between possible expansions of abbreviations make the task of identifying the correct one more straightforward than identifying meanings of ambiguous words. In addition, the creation of annotated data for WSD is often hampered by the difficulty in obtaining sufficient agreement between annotators (Artstein and Poesio, 2008; Weeber et al., 2001) and this problem does not apply to our automatically-generated corpus. Results in Table 2 indicate that CUIs are useful features in the disambiguation of abbreviations. This is in contrast with previous experiments on ambiguous terms in biomedical documents (Stevenson et al., 2008) in which it was found that the best performance as obtained using only linguistic and MeSH features. It is likely that the clear distinction between expansions of abbreviations is the reason behind this difference. CUIs are assigned automatically by the MetaMap program (Aronson, 2001). However, this assignment is v</context>
</contexts>
<marker>Weeber, Mork, Aronson, 2001</marker>
<rawString>M. Weeber, J. Mork, and A. Aronson. 2001. Developing a Test Collection for Biomedical Word Sense Disambiguation. In Proceedings of AMAI Symposium, pages 746–50, Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Witten</author>
<author>E Frank</author>
</authors>
<title>Data Mining: Practical machine learning tools and techniques.</title>
<date>2005</date>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco.</location>
<contexts>
<context position="14736" citStr="Witten and Frank, 2005" startWordPosition="2303" endWordPosition="2306">dividual while the second, C1305866, refers to the process of weighing a patient as part of a diagnostic procedure. instance belongs to a particular class given the prior probabilities of the class and the conditional probability of each feature given the target class. Support Vector Machines (SVM) have been widely used in classification tasks. SVMs map feature vectors onto a high dimensional space and construct a classifier by searching for the hyperplane that gives the greatest separation between the classes. We used our own implementation of the Vector Space Model and Weka implementations (Witten and Frank, 2005) of the other two algorithms. 4 Evaluation Corpus The most common method for generating corpora to train and test WSD systems is to manually annotate instances of ambiguous terms found in text with the appropriate meaning. However, this process is both time-consuming and difficult (Artstein and Poesio, 2008). An alternative to manual tagging is to find a way of automatically creating sense tagged corpora. For the translation of ambiguous English words Ng et al. (2003) made use of the fact that the various senses are often translated differently. For example when “bank” is used in the ‘financia</context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>I. Witten and E. Frank. 2005. Data Mining: Practical machine learning tools and techniques. Morgan Kaufmann, San Francisco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Xu</author>
<author>J Fan</author>
<author>G Hripcsak</author>
<author>E Mendonc¸a</author>
<author>M Markatou</author>
<author>C Friedman</author>
</authors>
<title>Gene symbol disambiguation using knowledge-based profiles.</title>
<date>2007</date>
<journal>Bioinformatics,</journal>
<volume>23</volume>
<issue>8</issue>
<marker>Xu, Fan, Hripcsak, Mendonc¸a, Markatou, Friedman, 2007</marker>
<rawString>H. Xu, J. Fan, G. Hripcsak, E. Mendonc¸a, Markatou M., and Friedman C. 2007. Gene symbol disambiguation using knowledge-based profiles. Bioinformatics, 23(8):1015–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yu</author>
<author>W Kim</author>
<author>V Hatzivassiloglou</author>
<author>J Wilbur</author>
</authors>
<title>A large scale, corpus-based approach for automatically disambigutaing biomedical abbreviations.</title>
<date>2006</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>24</volume>
<issue>3</issue>
<contexts>
<context position="5869" citStr="Yu et al. (2006)" startWordPosition="892" endWordPosition="895">l journal abstracts and used as training data. Their learning algorithm uses a variety of features including all words in the abstract and collocations of the ambiguous abbreviation. They report an accuracy of 97% on a small set of abbreviations. Liu et al. (2004) present a fully supervised approach. They compared a variety of supervised machine learning algorithms and found that the best performance over a set of 15 ambiguous abbreviations, 98.6%, was obtained using Naive Bayes. Gaudan et al. (2005) use a Support Vector Machine trained on a bag-of-words model and report an accuracy of 98.5%. Yu et al. (2006) experimented with two supervised learning algorithms: Naive Bayes and Support Vector Machines. They extracted a corpus containing examples of 60 abbreviations from a set of biomedical journal articles which was split so that abstracts in which the abbreviations were defined were used as training data and those in which no definition is found as test data. Abbreviations in the test portion were manually disambiguated. They report 79% coverage and 80% precision using a Naive Bayes classifier. Pakhomov (2002) applied a maximum entropy model to identify the meanings of ambiguous abbreviations in </context>
<context position="13178" citStr="Yu et al. (2006)" startWordPosition="2050" endWordPosition="2053"> al., 2002) is a controlled vocabulary for indexing biomedical and health-related information and documents. MeSH terms are manually assigned to abstracts by human indexers. The latest version of MeSH (2009) contains over 25,000 terms organised into an 11 level hierarchy. The MeSH terms assigned to the abstract in which each ambiguous word occurs are used as features. For example, the abstract containing our example phrase has been assigned 16 terms including “Body Surface Area”, “Body Weight”, “Humans” and “Organ Size” . MeSH terms have previously been used for abbreviation disambiguation by Yu et al. (2006). 3.2 Learning Algorithms We compared three machine leaning algorithms which have previously been shown to be effective for WSD tasks. The Vector Space Model (VSM) is a memorybased learning algorithm which was used by Agirre and Mart´ınez (2004). Each occurrence of an ambiguous word is represented as a binary vector in which each position indicates the occurrence/absence of a feature. A single centroid vector is generated for each sense during training. These centroids are compared with the vectors that represent new examples using the cosine metric to compute similarity. The sense assigned to</context>
</contexts>
<marker>Yu, Kim, Hatzivassiloglou, Wilbur, 2006</marker>
<rawString>H. Yu, W. Kim, V. Hatzivassiloglou, and J. Wilbur. 2006. A large scale, corpus-based approach for automatically disambigutaing biomedical abbreviations. ACM Transactions on Information Systems, 24(3):380–404.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Zhou</author>
<author>I Vetle</author>
<author>N Smalheiser</author>
</authors>
<title>ADAM: another database of abbreviations in MEDLINE.</title>
<date>2006</date>
<journal>Bioinformatics,</journal>
<volume>22</volume>
<issue>22</issue>
<contexts>
<context position="7766" citStr="Zhou et al. (2006)" startWordPosition="1188" endWordPosition="1191"> in the document. The problem is relatively straightforward for abbreviations which are created by selecting the first character from each word in the expansion, such as “angiotensin converting enzyme (ACE)”, but is more difficult when this convention is not followed, for example “acetylchlinesterase (ACE)”, “antisocial personality (ASP)” and “catalase (CAT)”. Okazaki et al. (2008) recently proposed an approach to this problem based on discriminative alignment that has been shown to perform well. However, the most common solutions are based on heuristic approaches, for example Adar (2004) and Zhou et al. (2006). Pustejovsky et al. (2002) used hand-built regular expressions. Schwartz and Hearst (2003) describe an approach which starts by identifying the set of candidate expansions in the same sentence as an abbreviation. The most likely one is identified by searching for the 72 shortest candidate which contains all the characters in the abbreviation in the correct order. 3 Abbreviation Disambiguation System Our abbreviation disambiguation system is based on a state-of-the-art WSD system that has been adapted to the biomedical domain by augmenting it with additional knowledge sources. The system on wh</context>
</contexts>
<marker>Zhou, Vetle, Smalheiser, 2006</marker>
<rawString>W. Zhou, I. Vetle, and N. Smalheiser. 2006. ADAM: another database of abbreviations in MEDLINE. Bioinformatics, 22(22):2813–2818.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>