<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.999239">
Learning Dependency Relations of
Japanese Compound Functional Expressions
</title>
<author confidence="0.809348">
Takehito Utsurot and Takao Shimet and Masatoshi Tsuchiyatt
Suguru Matsuyoshitt and Satoshi Satott
</author>
<affiliation confidence="0.813064571428571">
†Graduate School of Systems and Information Engineering, University of Tsukuba,
1-1-1, Tennodai, Tsukuba, 305-8573, JAPAN
$NEC Corporation
††Computer Center, Toyohashi University of Technology,
Tenpaku-cho, Toyohashi, 441–8580, JAPAN
†$Graduate School of Engineering, Nagoya University,
Furo-cho, Chikusa-ku, Nagoya, 464–8603, JAPAN
</affiliation>
<sectionHeader confidence="0.980335" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999926470588235">
This paper proposes an approach of process-
ing Japanese compound functional expressions
by identifying them and analyzing their depen-
dency relations through a machine learning tech-
nique. First, we formalize the task of identify-
ing Japanese compound functional expressions
in a text as a machine learning based chunking
problem. Next, against the results of identify-
ing compound functional expressions, we apply
the method of dependency analysis based on the
cascaded chunking model. The results of ex-
perimental evaluation show that, the dependency
analysis model achieves improvements when ap-
plied after identifying compound functional ex-
pressions, compared with the case where it is ap-
plied without identifying compound functional
expressions.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999719142857143">
In addition to single functional words, the Japanese
language has many more compound functional ex-
pressions which consist of more than one word in-
cluding both content words and functional words.
They are very important for recognizing syntactic
structures of Japanese sentences and for understand-
ing their semantic content. Recognition and under-
standing of them are also very important for vari-
ous kinds of NLP applications such as dialogue sys-
tems, machine translation, and question answering.
However, recognition and semantic interpretation of
compound functional expressions are especially dif-
ficult because it often happens that one compound
expression may have both a literal (i.e. compo-
</bodyText>
<page confidence="0.997693">
65
</page>
<bodyText confidence="0.999931068965517">
sitional) content word usage and a non-literal (i.e.
non-compositional) functional usage.
For example, Table 1 shows two example sen-
tences of a compound expression “に (ni) ついて
(tsuite)”, which consists of a post-positional particle
“に (ni)”, and a conjugated form “ついて (tsuite)” of
a verb “つく (tsuku)”. In the sentence (A), the com-
pound expression functions as a case-marking parti-
cle and has a non-compositional functional meaning
“about”. On the other hand, in the sentence (B), the
expression simply corresponds to a literal concate-
nation of the usages of the constituents: the post-
positional particle “に (ni)” and the verb “ついて
(tsuite)”, and has a content word meaning “follow”.
Therefore, when considering machine translation of
these Japanese sentences into English, it is neces-
sary to judge precisely the usage of the compound
expression “に (ni) ついて (tsuite)”, as shown in the
English translation of the two sentences in Table 1.
There exist widely-used Japanese text processing
tools, i.e. combinations of a morphological analy-
sis tool and a subsequent parsing tool, such as JU-
MAN1+ KNP2 and ChaSen3+ CaboCha4. However,
they process those compound expressions only par-
tially, in that their morphological analysis dictionar-
ies list only a limited number of compound expres-
sions. Furthermore, even if certain expressions are
listed in a morphological analysis dictionary, those
existing tools often fail in resolving the ambigui-
</bodyText>
<footnote confidence="0.99522">
1http://nlp.kuee.kyoto-u.ac.jp/
nl-resource/juman-e.html
2http://nlp.kuee.kyoto-u.ac.jp/
nl-resource/knp-e.html
3http://chasen.naist.jp/hiki/ChaSen/
4http://chasen.org/˜taku/software/
cabocha/
</footnote>
<note confidence="0.9565865">
Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 65–72,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<table confidence="0.9422055">
私 (watashi) は (ha) 彼 (kare) に (ni) ついて (tsuite) 話した (hanashita)
(I) (TOP) (he) (about) (talked)
(I talked about him.)
私 (watashi) は (ha) 彼 (kare) に (ni) ついて (tsuite) 走った (hashitta)
(I) (TOP) (he) (ACC) (follow) (ran)
(I ran following him.)
</table>
<tableCaption confidence="0.998354">
Table 1: Translation Selection of a Japanese Compound Expression “に (ni) ついて (tsuite)”
</tableCaption>
<figureCaption confidence="0.975448">
Figure 1: Example of Improving Dependency Analysis of Compound Functional Expressions by Identifying
them before Dependency Analysis
</figureCaption>
<figure confidence="0.98094872972973">
(1) Correct Dependency Relation by Identifying Compound Functional Expression: “䈫㵥䈚䈩”
with a Case Marking Particle Usage.
Correct English Translation:
( As a means of solving the problem, USA recommended the activity of OSCE in which Russia participates.)
(2) Incorrect Dependency Relation without Identifying Compound Functional Expression: “䈫㵥䈚䈩”,
which Literally Consists of a Post-positional Particle “䈫” (with) and a Conjugation Form “䈚䈩”
of a Verb “䈜䉎” (do).
☨࿖ 䈲
USA-TOP
⸃᳿ᚻᲑ 䈫
with a means for
solution
䊨䉲䉝 䉅
Russia-NOM also
ෳട 䈚䈩 䈇䉎
participate in
䈚䈩䇮
ో᰷቟଻දജᯏ᭴ 䈱
of OSCE
ᵴ↪ 䉕
activity-ACC
ㅴ⸒䈚䈢䇯
recommended
䊨䉲䉝 䉅
Russia-NOM also
ෳട 䈚䈩 䈇䉎
participate in
ᵴ↪ 䉕
activity-ACC
ㅴ⸒䈚䈢䇯
recommended
ో᰷቟଻දജᯏ᭴ 䈱
of OSCE
☨࿖ 䈲
USA-TOP
⸃᳿ᚻᲑ 䈫 䈚䈩䇮
as a means for solution
</figure>
<bodyText confidence="0.9997147">
ties of their usages, such as those in Table 1. This
is mainly because the framework of these existing
tools is not designed so as to resolve such ambigu-
ities of compound (possibly functional) expressions
by carefully considering the context of those expres-
sions.
Actually, as we introduce in the next section, as a
first step towards studying computational processing
of compound functional expressions, we start with
125 major functional expressions which have non-
compositional usages, as well as their variants (337
expressions in total). Out of those 337 expressions,
111 have both a content word usage and a functional
usage. However, the combination of JUMAN+KNP
is capable of distinguishing the two usages only for
43 of the 111 expressions, and the combination of
ChaSen+CaboCha only for 40 of those 111 expres-
sions. Furthermore, the failure in distinguishing the
two usages may cause errors of syntactic analysis.
For example, (1) of Figure 1 gives an example of
identifying a correct modifiee of the second bunsetsu
segment 5 “解決手段として (as a means for solu-
tion)” including a Japanese compound functional ex-
pression “として (as)”, by appropriately detecting
the compound functional expression before depen-
dency analysis. On the other hand, (2) of Figure 1
gives an example of incorrectly indicating an erro-
neous modifiee of the third bunsetsu “して”, which
actually happens if we do not identify the compound
functional expression “として (as)” before depen-
dency analysis of this sentence.
Considering such a situation, it is necessary to
develop a tool which properly recognizes and se-
mantically interprets Japanese compound functional
expressions. This paper proposes an approach of
processing Japanese compound functional expres-
sions by identifying them and analyzing their de-
pendency relations through a machine learning tech-
nique. The overall flow of processing compound
functional expressions in a Japanese sentence is il-
</bodyText>
<footnote confidence="0.959465666666667">
5A Japanese bunsetsu segment is a phrasal unit which con-
sits of at least one content word and zero or more functional
words.
</footnote>
<page confidence="0.84941">
66
</page>
<figure confidence="0.999822876923077">
morphological
analysis
by ChaSen
ᚻᲑ
(means)
䈫
(with)
䈚
☨࿖䈲⸃᳿ᚻᲑ䈫䈚䈩䇮 (do)
䊨䉲䉝䉅ෳട䈚䈩䈇䉎ో᰷
቟଻දജᯏ᭴䈱ᵴ↪䉕 䈩
ㅴ⸒䈚䈢䇯 (and)
࡮࡮࡮
⸃᳿
(solution)
( As a means of solving the
problem, USA recommended the
activity of OSCE in which Russia
participates.)
Identifying
compound
functional
expression
chunking
compound
functional
expression
bunsetsu
segmentation
&amp;
dependency
analysis
bunsetsu
segment
⸃᳿
(solution)
ᚻᲑ
(means)
䈫䈚䈩
(as)
࡮࡮࡮
࡮࡮࡮
dependency
relation
࡮࡮࡮
࡮࡮࡮
⸃᳿
(solution)
ᚻᲑ
(means)
䈫
(with)
䈚
(do)
䈩
(and)
࡮࡮࡮
࡮࡮࡮
⸃᳿
(solution)
ᚻᲑ
(means)
䈫䈚䈩
(as)
࡮࡮࡮
</figure>
<figureCaption confidence="0.999732">
Figure 2: Overall Flow of Processing Compound Functional Expressions in a Japanese Sentence
</figureCaption>
<bodyText confidence="0.999986769230769">
lustrated in Figure 2. First of all, we assume a
sequence of morphemes obtained by a variant of
ChaSen with all the compound functional expres-
sions removed from its outputs, as an input to our
procedure of identifying compound functional ex-
pressions and analyzing their dependency relations.
We formalize the task of identifying Japanese com-
pound functional expressions in a text as a machine
learning based chunking problem (Tsuchiya et al.,
2006). We employ the technique of Support Vec-
tor Machines (SVMs) (Vapnik, 1998) as the ma-
chine learning technique, which has been success-
fully applied to various natural language process-
ing tasks including chunking tasks such as phrase
chunking and named entity chunking. Next, against
the results of identifying compound functional ex-
pressions, we apply the method of dependency anal-
ysis based on the cascaded chunking model (Kudo
and Matsumoto, 2002), which is simple and efficient
because it parses a sentence deterministically only
deciding whether the current bunsetsu segment mod-
ifies the one on its immediate right hand side. As
we showed in Figure 1, identifying compound func-
tional expressions before analyzing dependencies in
a sentence does actually help deciding dependency
relations of compound functional expressions.
In the experimental evaluation, we focus on 59
expressions having balanced distribution of their us-
ages in the newspaper text corpus and are among the
most difficult ones in terms of their identification in
a text. We first show that the proposed method of
chunking compound functional expressions signifi-
cantly outperforms existing Japanese text processing
tools. Next, we further show that the dependency
analysis model of (Kudo and Matsumoto, 2002) ap-
plied to the results of identifying compound func-
tional expressions significantly outperforms the one
applied to the results without identifying compound
functional expressions.
</bodyText>
<sectionHeader confidence="0.9271625" genericHeader="introduction">
2 Japanese Compound Functional
Expressions
</sectionHeader>
<bodyText confidence="0.9999413125">
There exist several collections which list Japanese
functional expressions and examine their usages.
For example, (Morita and Matsuki, 1989) exam-
ine 450 functional expressions and (Group Jamashii,
1998) also lists 965 expressions and their example
sentences. Compared with those two collections,
Gendaigo Hukugouji Youreishu (National Language
Research Institute, 2001) (henceforth, denoted as
GHY) concentrates on 125 major functional expres-
sions which have non-compositional usages, as well
as their variants6, and collects example sentences of
those expressions. As we mentioned in the previous
section, as a first step towards developing a tool for
identifying Japanese compound functional expres-
sions, we start with those 125 major functional ex-
pressions and their variants (337 expressions in to-
</bodyText>
<footnote confidence="0.8873688">
6For each of those 125 major expressions, the differences
between it and its variants are summarized as below: i) inser-
tion/deletion/alternation of certain particles, ii) alternation of
synonymous words, iii) normal/honorific/conversational forms,
iv) base/adnominal/negative forms.
</footnote>
<page confidence="0.994345">
67
</page>
<figure confidence="0.48165">
(a) Classification of Compound Functional Expressions based on Grammatical Function
</figure>
<table confidence="0.998587743589744">
Grammatical Function Type # of major expressions # of variants Example
post-positional conjunctive particle 36 67 くせに (kuse-ni)
particle type
case-marking particle 45 121 として (to-shite)
adnominal particle 2 3 という (to-iu)
auxiliary verb type 42 146 ていい (te-ii)
total 125 337 —
(b) Examples of Classifying Functional/Content Usages
Expression Example sentence (English translation) Usage
くせに 兄には金をやる くせに 、おれには手紙をよこしただけだ。 functional
(kuse-ni) (くせに (kuse-ni) = while)
(To my brother, (someone) gave money, while (he/she) did noth-
ing to me but just sent a letter.)
くせに 彼のその くせに みんな驚いた。 content
(kuse-ni) (∼ くせに (kuse-ni)
= by one’s habit
(They all were surprised by his habit.)
として 彼はその問題の専門家 として 知られている。 functional
(to-shite) (∼ として (to-shite)
= as ∼)
(He is known as an expert of the problem.)
として これが正しいかどうかはっきり として 下さい。 content
(to-shite) (∼ を ∼ として (to-shite)
=make ∼ ∼
(Please make it clear whether this is true or not.)
という 彼は生きている という 知らせを聞いた。 functional
(to-iu) (∼ という (to-iu) = that ∼)
(I heard that he is alive.)
という 「遊びに来て下さい」 という 人もいる。 content
(to-iu) (∼ という (to-iu)
= say (that) ∼)
(Somebody says “Please visit us.”.)
ていい この議論が終ったら休憩し ていい 。 functional
(te-ii) (∼ ていい (te-ii) = may ∼)
(You may have a break after we finish this discussion.)
ていい このかばんは大きく ていい 。 content
(te-ii) (∼ ていい (te-ii)
= nice because ∼)
(This bag is nice because it is big.)
</table>
<tableCaption confidence="0.999367">
Table 2: Classification and Example Usages of Compound Functional Expressions
</tableCaption>
<bodyText confidence="0.9990820625">
tal). In this paper, following (Sag et al., 2002), we
regard each variant as a fixed expression, rather than
a semi-fixed expression or a syntactically-flexible
expression 7. Then, we focus on evaluating the
effectiveness of straightforwardly applying a stan-
dard chunking technique to the task of identifying
Japanese compound functional expressions.
As in Table 2 (a), according to their grammat-
ical functions, those 337 expressions in total are
roughly classified into post-positional particle type,
and auxiliary verb type. Functional expressions of
post-positional particle type are further classified
into three subtypes: i) conjunctive particle types,
which are used for constructing subordinate clauses,
ii) case-marking particle types, iii) adnominal parti-
cle types, which are used for constructing adnominal
</bodyText>
<footnote confidence="0.758998">
7Compound functional expressions of auxiliary verb types
can be regarded as syntactically-flexible expressions.
</footnote>
<bodyText confidence="0.9771495">
clauses. Furthermore, for examples of compound
functional expressions listed in Table 2 (a), Table 2
(b) gives their example sentences as well as the de-
scription of their usages.
</bodyText>
<sectionHeader confidence="0.990278" genericHeader="method">
3 Identifying Compound Functional
</sectionHeader>
<subsectionHeader confidence="0.562397">
Expressions by Chunking with SVMs
</subsectionHeader>
<bodyText confidence="0.999979625">
This section describes summaries of formalizing the
chunking task using SVMs (Tsuchiya et al., 2006).
In this paper, we use an SVMs-based chunking tool
YamCha8 (Kudo and Matsumoto, 2001). In the
SVMs-based chunking framework, SVMs are used
as classifiers for assigning labels for representing
chunks to each token. In our task of chunking
Japanese compound functional expressions, each
</bodyText>
<footnote confidence="0.9967205">
8http://chasen.org/˜taku/software/
yamcha/
</footnote>
<page confidence="0.99869">
68
</page>
<bodyText confidence="0.99888225">
sentence is represented as a sequence of morphemes,
where a morpheme is regarded as a token.
formation on the candidate compound functional ex-
pression at i-th position.
</bodyText>
<subsectionHeader confidence="0.998148">
3.1 Chunk Representation
</subsectionHeader>
<bodyText confidence="0.989262681818182">
For representing proper chunks, we employ IOB2
representation, which has been studied well in var-
ious chunking tasks of natural language processing.
This method uses the following set of three labels
for representing proper chunks.
I Current token is a middle or the end of a
chunk consisting of more than one token.
O Current token is outside of any chunk.
B Current token is the beginning of a chunk.
Given a candidate expression, we classify the us-
ages of the expression into two classes: functional
and content. Accordingly, we distinguish the chunks
of the two types: the functional type chunk and the
content type chunk. In total, we have the follow-
ing five labels for representing those chunks: B-
functional, I-functional, B-content, I-content, and
O. Finally, as for extending SVMs to multi-class
classifiers, we experimentally compare the pairwise
method and the one vs. rest method, where the pair-
wise method slightly outperformed the one vs. rest
method. Throughout the paper, we show results with
the pairwise method.
</bodyText>
<subsectionHeader confidence="0.961398">
3.2 Features
</subsectionHeader>
<bodyText confidence="0.99797">
For the feature sets for training/testing of SVMs, we
use the information available in the surrounding con-
text, such as the morphemes, their parts-of-speech
tags, as well as the chunk labels. More precisely,
suppose that we identify the chunk label ci for the
i-th morpheme:
</bodyText>
<equation confidence="0.5849642">
−→ Parsing Direction −→
Morpheme mi−2 mi−1 mi mi+1 mi+2
Feature set Fi−2 Fi−1 Fi Fi+1 Fi+2
at a position
Chunk label ci−2 ci−1 ci
</equation>
<bodyText confidence="0.9956884">
Here, mi is the morpheme appearing at i-th posi-
tion, Fi is the feature set at i-th position, and ci is
the chunk label for i-th morpheme. Roughly speak-
ing, when identifying the chunk label ci for the i-th
morpheme, we use the feature sets Fi−2, Fi−1, Fi,
Fi+1, Fi+2 at the positions i − 2, i − 1, i, i + 1,
i + 2, as well as the preceding two chunk labels ci−2
and ci−1. The detailed definition of the feature set
Fi at i-th position is given in (Tsuchiya et al., 2006),
which mainly consists of morphemes as well as in-
</bodyText>
<sectionHeader confidence="0.979886666666667" genericHeader="method">
4 Learning Dependency Relations of
Japanese Compound Functional
Expressions
</sectionHeader>
<subsectionHeader confidence="0.914950333333333">
4.1 Japanese Dependency Analysis using
Cascaded Chunking
4.1.1 Cascaded Chunking Model
</subsectionHeader>
<bodyText confidence="0.85989975">
First of all, we define a Japanese sen-
tence as a sequence of bunsetsu segments
B = (b1, b2, ... , b.) and its syntactic struc-
ture as a sequence of dependency patterns
</bodyText>
<equation confidence="0.657827">
D = (Dep(1), Dep(2), ... , Dep(m − 1)), where
Dep(i) = j means that the bunsetsu segment bi
</equation>
<bodyText confidence="0.846115">
depends on (modifies) bunsetsu segment b-. In
this framework, we assume that the dependency
sequence D satisfies the following two constraints:
1. Japanese is a head-final language. Thus, except
for the rightmost one, each bunsetsu segment
modifies exactly one bunsetsu segment among
those appearing to its right.
</bodyText>
<listItem confidence="0.64502">
2. Dependencies do not cross one another.
</listItem>
<bodyText confidence="0.999885111111111">
Unlike probabilistic dependency analysis models
of Japanese, the cascaded chunking model of Kudo
and Matsumoto (2002) does not require the proba-
bilities of dependencies and parses a sentence de-
terministically. Since Japanese is a head-final lan-
guage, and the chunking can be regarded as the cre-
ation of a dependency between two bunsetsu seg-
ments, this model simplifies the process of Japanese
dependency analysis as follows: 9
</bodyText>
<listItem confidence="0.9968347">
1. Put an O tag on all bunsetsu segments. The O
tag indicates that the dependency relation of the
current segment is undecided.
2. For each bunsetsu segment with an O tag, de-
cide whether it modifies the bunsetsu segment
on its immediate right hand side. If so, the O
tag is replaced with a D tag.
3. Delete all bunsetsu segments with a D tag that
immediately follows a bunsetsu segment with
an O tag.
</listItem>
<footnote confidence="0.9861675">
9The O and D tags used in this section have no relation to
those chunk reppresentation tags introduced in section 3.1.
</footnote>
<page confidence="0.996821">
69
</page>
<figure confidence="0.756914">
ᓐ䈲 ᓐᅚ䈱 ᷷䈎䈇 ⌀ᔃ䈮 ᗵേ䈚䈢䇯
He her warm heart be moved
( He was moved by her warm heart. )
Initialization
</figure>
<figureCaption confidence="0.9971525">
Figure 3: Example of the Parsing Process with Cas-
caded Chunking Model
</figureCaption>
<listItem confidence="0.692525333333333">
4. Terminate the algorithm if a single bunsetsu
segment remains, otherwise return to the step
2 and repeat.
</listItem>
<bodyText confidence="0.8267345">
Figure 3 shows an example of the parsing process
with the cascaded chunking model.
</bodyText>
<sectionHeader confidence="0.541289" genericHeader="method">
4.1.2 Features
</sectionHeader>
<bodyText confidence="0.999984172413793">
As a Japanese dependency analyzer based on the
cascaded chunking model, we use the publicly avail-
able version of CaboCha (Kudo and Matsumoto,
2002), which is trained with the manually parsed
sentences of Kyoto text corpus (Kurohashi and Na-
gao, 1998), that are 38,400 sentences selected from
the 1995 Mainichi newspaper text.
The standard feature set used by CaboCha con-
sists of static features and dynamic features. Static
features are those solely defined once the pair
of modifier/modifiee bunsetsu segments is speci-
fied. For the pair of modifier/modifiee bunsetsu
segments, the following are used as static fea-
tures: head words and their parts-of-speech tags,
inflection-types/forms, functional words and their
parts-of-speech tags, inflection-types/forms, inflec-
tion forms of the words that appear at the end
of bunsetsu segments. As for features between
modifier/modifiee bunsetsu segments, the distance
of modifier/modifiee bunsetsu segments, existence
of case-particles, brackets, quotation-marks, and
punctuation-marks are used as static features. On the
other hand, dynamic features are created during the
parsing process, so that, when a certain dependency
relation is determined, it can have some influence
on other dependency relations. Dynamic features in-
clude bunsetsu segments modifying the current can-
didate modifiee (see Kudo and Matsumoto (2002)
for the details).
</bodyText>
<subsectionHeader confidence="0.9985205">
4.2 Coping with Compound Functional
Expressions
</subsectionHeader>
<bodyText confidence="0.990203911764706">
As we show in Figure 2, a compound functional ex-
pression is identified as a sequence of several mor-
phemes and then chunked into one morpheme. The
result of this identification process is then trans-
formed into the sequence of bunsetsu segments. Fi-
nally, to this modified sequence of bunsetsu seg-
ments, the method of dependency analysis based on
the cascaded chunking model is applied.
Here, when chunking a sequence of several mor-
phemes constituting a compound functional expres-
sion, the following two cases may exist:
(A) As in the case of the example (A) in Table 1, the
two morphemes constituting a compound func-
tional expression “に (ni) ついて (tsuite)” over-
laps the boundary of two bunsetsu segments.
In such a case, when chunking the two mor-
phemes into one morpheme corresponding to
a compound functional expression, those two
bunsetsu segments are concatenated into one
bunsetsu segment.
彼 に ついて 彼 について
kare ni tsuite =⇒ kare ni-tsuite
(he) (he) (about)
(B) As we show below, a compound functional ex-
pression “こと (koto) が (ga) ある (aru)” over-
laps the boundary of two bunsetsu segments,
though the two bunsetsu segments concatenat-
ing into one bunsetsu segment does include no
content words. In such a case, its immedi-
ate left bunsetsu segment (“行っ(itt) た (ta)“ in
the example below), which corresponds to the
content word part of “こと (koto) が (ga) ある
(aru)”, has to be concatenated into the bunsetsu
segment “こと (koto) が (ga) ある (aru)”.
</bodyText>
<figure confidence="0.997255538461539">
Input: ᓐ䈲 ᓐᅚ䈱 ᷷䈎䈇 ⌀ᔃ䈮 ᗵേ䈚䈢䇯
Tag: O O O O O
Input:
Tag:
ᓐ䈲 ᗵേ䈚䈢䇯
D
Deleted
O
Input: ᗵേ䈚䈢䇯
Tag: O
Finish
Deleted
Input:
Tag:
Input:
Tag:
Input:
Tag:
ᓐ䈲 ᓐᅚ䈱 ᷷䈎䈇 ⌀ᔃ䈮 ᗵേ䈚䈢䇯
O O D D O
Deleted
ᓐ䈲 ᓐᅚ䈱 ⌀ᔃ䈮 ᗵേ䈚䈢䇯
O D D O
Deleted
ᓐ䈲 ⌀ᔃ䈮 ᗵേ䈚䈢䇯
O D O
</figure>
<page confidence="0.913832">
70
</page>
<bodyText confidence="0.897311965517241">
行っ た こと が ある 行っ た ことがある
itt ta koto ga aru =⇒ itt ta koto-ga-aru
(went) (have been ∼)
Next, to the compound functional expression, we
assign one of the four grammatical function types
listed in Table 2 as its POS tag. For example,
the compound functional expression “に (ni) ついて
(tsuite)” in (A) above is assigned the grammatical
function type “case-marking particle type”, while “
こと (koto) が (ga) ある (aru)” in (B) is assigned
“auxiliary verb type”.
These modifications cause differences in the final
feature representations. For example, let us compare
the feature representations of the modifier bunsetsu
segments in (1) and (2) of Figure 1. In (1), the mod-
ifier bunsetsu segment is “解決手段として” which
has the compound functional expression “として”
in its functional word part. On the other hand, in
(2), the modifier bunsetsu segment is “して”, which
corresponds to the literal verb usage of a part of the
compound functional expression “として”. In the
final feature representations below, this causes the
following differences in head words and functional
words / POS of the modifier bunsetsu segments:
(1) of Figure 1 (2) of Figure 1
head word 手段 (means) する (do)
functional word として (as) て (and)
POS subsequent to nominal conjunctive
/ modifying predicate particle
</bodyText>
<sectionHeader confidence="0.997529" genericHeader="method">
5 Experimental Evaluation
</sectionHeader>
<subsectionHeader confidence="0.992505">
5.1 Training/Test Data Sets
</subsectionHeader>
<bodyText confidence="0.996663411764706">
For the training of chunking compound functional
expressions, we collected 2,429 example sentences
from the 1995 Mainichi newspaper text corpus. For
each of the 59 compound functional expressions for
evaluation mentioned in section 1, at least 50 ex-
amples are included in this training set. For the
testing of chunking compound functional expres-
sions, as well as training/testing of learning depen-
dencies of compound functional expressions, we
used manually-parsed sentences of Kyoto text cor-
pus (Kurohashi and Nagao, 1998), that are 38,400
sentences selected from the 1995 Mainichi newspa-
per text (the 2,429 sentences above are selected so
that they are exclusive of the 37,400 sentences of
Kyoto text corpus.). To those data sets, we manually
annotate usage labels of the 59 compound functional
expressions (details in Table 3).
</bodyText>
<table confidence="0.9631236">
Usages # of
functional content total sentences
for chunker 1918 1165 3083 2429
training
Kyoto text corpus 5744 1959 7703 38400
</table>
<tableCaption confidence="0.999812">
Table 3: Statistics of Data Sets
Table 4: Evaluation Results of Chunking (%)
</tableCaption>
<subsectionHeader confidence="0.98911">
5.2 Chunking
</subsectionHeader>
<bodyText confidence="0.999998666666667">
As we show in Table 4, performance of our SVMs-
based chunkers as well as several baselines includ-
ing existing Japanese text processing tools is evalu-
ated in terms of precision/recall/Fβ_1 of identifying
all the 5,744 functional chunks included in the test
data (Kyoto text corpus in Table 3). Performance is
evaluated also in terms of accuracy of classifying de-
tected candidate expressions into functional/content
chunks. Among those baselines, “majority ( = func-
tional)” always assigns functional usage to the de-
tected candidate expressions. Performance of our
SVMs-based chunkers is measured through 10-fold
cross validation. Our SVMs-based chunker signif-
icantly outperforms those baselines both in Fβ_1
and classification accuracy. As we mentioned in
section 1, existing Japanese text processing tools
process compound functional expressions only par-
tially, which causes damage in recall in Table 4.
</bodyText>
<subsectionHeader confidence="0.99951">
5.3 Analyzing Dependency Relations
</subsectionHeader>
<bodyText confidence="0.999879923076923">
We evaluate the accuracies of judging dependency
relations of compound functional expressions by the
variant of CaboCha trained with Kyoto text cor-
pus annotated with usage labels of compound func-
tional expressions. This performance is measured
through 10-fold cross validation with the modified
version of the Kyoto text corpus. In the evaluation
phase, according to the flow of Figure 2, first we ap-
ply the chunker of compound functional expressions
trained with all the 2,429 sentences in Table 3 and
obtain the results of chunked compound functional
expressions with about 90% correct rate. Then, bun-
setsu segmentation and dependency analysis are per-
</bodyText>
<table confidence="0.9695135625">
Identifying Acc. of
functional chunks classifying
functional /
content
chunks
Prec. Rec. Fβ=1
majority ( =functional) 74.6 100 85.5 74.6
Juman/KNP 85.8 40.5 55.0 58.4
ChaSen/CaboCha 85.2 26.7 40.6 51.1
SVM 91.4 94.6 92.9 89.3
71
modifier modifiee
baselines CaboCha (w/o FE) 72.5 88.0
CaboCha (public) 73.9 87.6
chunker + CaboCha (proposed) 74.0 88.0
reference + CaboCha (proposed) 74.4 88.1
</table>
<tableCaption confidence="0.999578">
Table 5: Accuracies of Identifying Modi-
</tableCaption>
<bodyText confidence="0.991205926829268">
fier(s)/Modifiee (%)
formed by our variant of CaboCha, where accu-
racies of identifying modifier(s)/modifiee of com-
pound functional expressions are measured as in Ta-
ble 5 (“chunker + CaboCha (proposed)” denotes that
inputs to CaboCha (proposed) are with 90% correct
rate, while “reference + CaboCha (proposed)” de-
notes that they are with 100% correct rate). Here,
“CaboCha (w/o FE)” denotes a baseline variant of
CaboCha, with all the compound functional expres-
sions removed from its inputs (which are outputs
from ChaSen), while “CaoboCha (public)” denotes
the publicly available version of CaboCha, which
have some portion of the compound functional ex-
pressions included in its inputs.
For the modifier accuracy, the difference of
“chunker + CaboCha (proposed)” and “CaboCha
(w/o FE)” is statistically significant at a level of
0.05. Identifying compound functional expressions
typically contributes to improvements when the lit-
eral constituents of a compound functional expres-
sion include a verb. In such a case, for bunsetsu
segments which usually modifies a verb, an incor-
rect modifee candidate is removed, which results in
improvements in the modifier accuracy. The dif-
ference between ‘CaoboCha (public)” and “chunker
+ CaboCha (proposed)” is slight because the pub-
licly available version of CaboCha seems to include
compound functional expressions which are dam-
aged in identifying their modifiers with “CaboCha
(w/o FE)”. For the modifiee accuracy, the difference
of “chunker + CaboCha (proposed)” and “CaboCha
(w/o FE)” is zero. Here, more than 100 instances of
improvements like the one in Figure 1 are observed,
while almost the same number of additional fail-
ures are also observed mainly because of the sparse-
ness problem. Furthermore, in the case of the modi-
fiee accuracy, it is somehow difficult to expect im-
provement because identifying modifiees of func-
tional/content bunsetsu segments mostly depends on
features other than functional/content distinction.
</bodyText>
<sectionHeader confidence="0.9913" genericHeader="conclusions">
6 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.999977611111111">
We proposed an approach of processing Japanese
compound functional expressions by identifying
them and analyzing their dependency relations
through a machine learning technique. This ap-
proach is novel in that it has never been applied
to any language so far. Experimental evaluation
showed that the dependency analysis model applied
to the results of identifying compound functional ex-
pressions significantly outperforms the one applied
to the results without identifying compound func-
tional expressions. The proposed framework has ad-
vantages over an approach based on manually cre-
ated rules such as the one in (Shudo et al., 2004), in
that it requires human cost to create manually and
maintain those rules. Related works include Nivre
and Nilsson (2004), which reports improvement of
Swedish parsing when multi word units are manu-
ally annotated.
</bodyText>
<sectionHeader confidence="0.999114" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9999083125">
Group Jamashii, editor. 1998. Nihongo Bunkei Jiten. Kuroshio
Publisher. (in Japanese).
T. Kudo and Y. Matsumoto. 2001. Chunking with support vec-
tor machines. In Proc. 2nd NAACL, pages 192–199.
T. Kudo and Y. Matsumoto. 2002. Japanese dependency ana-
lyisis using cascaded chunking. In Proc. 6th CoNLL, pages
63–69.
S. Kurohashi and M. Nagao. 1998. Building a Japanese parsed
corpus while improving the parsing system. In Proc. 1st
LREC, pages 719–724.
Y. Morita and M. Matsuki. 1989. Nihongo Hyougen Bunkei,
volume 5 of NAFL Sensho. ALC. (in Japanese).
National Language Research Institute. 2001. Gendaigo Huku-
gouji Youreishu. (in Japanese).
J. Nivre and J. Nilsson. 2004. Multiword units in syntactic
parsing. In Proc. LREC Workshop, Methodologies and Eval-
uation ofMultiword Units in Real-World Applications, pages
39–46.
I. Sag, T. Baldwin, F. Bond, A. Copestake, and D. Flickinger.
2002. Multiword expressions: A pain in the neck for NLP.
In Proc. 3rd CICLING, pages 1–15.
K. Shudo, T. Tanabe, M. Takahashi, and K. Yoshimura. 2004.
MWEs as non-propositional content indicators. In Proc. 2nd
ACL Workshop on Multiword Expressions: Integrating Pro-
cessing, pages 32–39.
M. Tsuchiya, T. Shime, T. Takagi, T. Utsuro, K. Uchimoto,
S. Matsuyoshi, S. Sato, and S. Nakagawa. 2006. Chunk-
ing Japanese compound functional expressions by machine
learning. In Proc. Workshop on Multi-Word-Expressions in
a Multilingual Context, pages 25–32.
V. N. Vapnik. 1998. Statistical Learning Theory. Wiley-
Interscience.
</reference>
<page confidence="0.998721">
72
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.302429">
<title confidence="0.999866">Learning Dependency Relations</title>
<author confidence="0.725505">Japanese Compound Functional Expressions</author>
<affiliation confidence="0.994327">School of Systems and Information Engineering, University of</affiliation>
<address confidence="0.944614">1-1-1, Tennodai, Tsukuba, 305-8573,</address>
<affiliation confidence="0.571435">Center, Toyohashi University of</affiliation>
<address confidence="0.981094">Tenpaku-cho, Toyohashi, 441–8580,</address>
<affiliation confidence="0.859091">School of Engineering, Nagoya</affiliation>
<address confidence="0.98748">Furo-cho, Chikusa-ku, Nagoya, 464–8603, JAPAN</address>
<abstract confidence="0.997102222222222">This paper proposes an approach of processing Japanese compound functional expressions by identifying them and analyzing their dependency relations through a machine learning technique. First, we formalize the task of identifying Japanese compound functional expressions in a text as a machine learning based chunking problem. Next, against the results of identifying compound functional expressions, we apply the method of dependency analysis based on the cascaded chunking model. The results of experimental evaluation show that, the dependency analysis model achieves improvements when applied after identifying compound functional expressions, compared with the case where it is applied without identifying compound functional expressions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Nihongo Bunkei Jiten. Kuroshio Publisher.</title>
<date>1998</date>
<editor>Group Jamashii, editor.</editor>
<note>(in Japanese).</note>
<marker>1998</marker>
<rawString>Group Jamashii, editor. 1998. Nihongo Bunkei Jiten. Kuroshio Publisher. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kudo</author>
<author>Y Matsumoto</author>
</authors>
<title>Chunking with support vector machines.</title>
<date>2001</date>
<booktitle>In Proc. 2nd NAACL,</booktitle>
<pages>192--199</pages>
<contexts>
<context position="13588" citStr="Kudo and Matsumoto, 2001" startWordPosition="2031" endWordPosition="2034">types, iii) adnominal particle types, which are used for constructing adnominal 7Compound functional expressions of auxiliary verb types can be regarded as syntactically-flexible expressions. clauses. Furthermore, for examples of compound functional expressions listed in Table 2 (a), Table 2 (b) gives their example sentences as well as the description of their usages. 3 Identifying Compound Functional Expressions by Chunking with SVMs This section describes summaries of formalizing the chunking task using SVMs (Tsuchiya et al., 2006). In this paper, we use an SVMs-based chunking tool YamCha8 (Kudo and Matsumoto, 2001). In the SVMs-based chunking framework, SVMs are used as classifiers for assigning labels for representing chunks to each token. In our task of chunking Japanese compound functional expressions, each 8http://chasen.org/˜taku/software/ yamcha/ 68 sentence is represented as a sequence of morphemes, where a morpheme is regarded as a token. formation on the candidate compound functional expression at i-th position. 3.1 Chunk Representation For representing proper chunks, we employ IOB2 representation, which has been studied well in various chunking tasks of natural language processing. This method</context>
</contexts>
<marker>Kudo, Matsumoto, 2001</marker>
<rawString>T. Kudo and Y. Matsumoto. 2001. Chunking with support vector machines. In Proc. 2nd NAACL, pages 192–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kudo</author>
<author>Y Matsumoto</author>
</authors>
<title>Japanese dependency analyisis using cascaded chunking.</title>
<date>2002</date>
<booktitle>In Proc. 6th CoNLL,</booktitle>
<pages>63--69</pages>
<contexts>
<context position="8566" citStr="Kudo and Matsumoto, 2002" startWordPosition="1284" endWordPosition="1287">dependency relations. We formalize the task of identifying Japanese compound functional expressions in a text as a machine learning based chunking problem (Tsuchiya et al., 2006). We employ the technique of Support Vector Machines (SVMs) (Vapnik, 1998) as the machine learning technique, which has been successfully applied to various natural language processing tasks including chunking tasks such as phrase chunking and named entity chunking. Next, against the results of identifying compound functional expressions, we apply the method of dependency analysis based on the cascaded chunking model (Kudo and Matsumoto, 2002), which is simple and efficient because it parses a sentence deterministically only deciding whether the current bunsetsu segment modifies the one on its immediate right hand side. As we showed in Figure 1, identifying compound functional expressions before analyzing dependencies in a sentence does actually help deciding dependency relations of compound functional expressions. In the experimental evaluation, we focus on 59 expressions having balanced distribution of their usages in the newspaper text corpus and are among the most difficult ones in terms of their identification in a text. We fi</context>
<context position="16889" citStr="Kudo and Matsumoto (2002)" startWordPosition="2579" endWordPosition="2582">ts syntactic structure as a sequence of dependency patterns D = (Dep(1), Dep(2), ... , Dep(m − 1)), where Dep(i) = j means that the bunsetsu segment bi depends on (modifies) bunsetsu segment b-. In this framework, we assume that the dependency sequence D satisfies the following two constraints: 1. Japanese is a head-final language. Thus, except for the rightmost one, each bunsetsu segment modifies exactly one bunsetsu segment among those appearing to its right. 2. Dependencies do not cross one another. Unlike probabilistic dependency analysis models of Japanese, the cascaded chunking model of Kudo and Matsumoto (2002) does not require the probabilities of dependencies and parses a sentence deterministically. Since Japanese is a head-final language, and the chunking can be regarded as the creation of a dependency between two bunsetsu segments, this model simplifies the process of Japanese dependency analysis as follows: 9 1. Put an O tag on all bunsetsu segments. The O tag indicates that the dependency relation of the current segment is undecided. 2. For each bunsetsu segment with an O tag, decide whether it modifies the bunsetsu segment on its immediate right hand side. If so, the O tag is replaced with a </context>
<context position="18244" citStr="Kudo and Matsumoto, 2002" startWordPosition="2819" endWordPosition="2822">sed in this section have no relation to those chunk reppresentation tags introduced in section 3.1. 69 ᓐ䈲 ᓐ䈱 䈎䈇 ⌀ᔃ䈮 ᗵേ䈚䈢䇯 He her warm heart be moved ( He was moved by her warm heart. ) Initialization Figure 3: Example of the Parsing Process with Cascaded Chunking Model 4. Terminate the algorithm if a single bunsetsu segment remains, otherwise return to the step 2 and repeat. Figure 3 shows an example of the parsing process with the cascaded chunking model. 4.1.2 Features As a Japanese dependency analyzer based on the cascaded chunking model, we use the publicly available version of CaboCha (Kudo and Matsumoto, 2002), which is trained with the manually parsed sentences of Kyoto text corpus (Kurohashi and Nagao, 1998), that are 38,400 sentences selected from the 1995 Mainichi newspaper text. The standard feature set used by CaboCha consists of static features and dynamic features. Static features are those solely defined once the pair of modifier/modifiee bunsetsu segments is specified. For the pair of modifier/modifiee bunsetsu segments, the following are used as static features: head words and their parts-of-speech tags, inflection-types/forms, functional words and their parts-of-speech tags, inflection-</context>
</contexts>
<marker>Kudo, Matsumoto, 2002</marker>
<rawString>T. Kudo and Y. Matsumoto. 2002. Japanese dependency analyisis using cascaded chunking. In Proc. 6th CoNLL, pages 63–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kurohashi</author>
<author>M Nagao</author>
</authors>
<title>Building a Japanese parsed corpus while improving the parsing system.</title>
<date>1998</date>
<booktitle>In Proc. 1st LREC,</booktitle>
<pages>719--724</pages>
<contexts>
<context position="18346" citStr="Kurohashi and Nagao, 1998" startWordPosition="2835" endWordPosition="2839">9 ᓐ䈲 ᓐ䈱 䈎䈇 ⌀ᔃ䈮 ᗵേ䈚䈢䇯 He her warm heart be moved ( He was moved by her warm heart. ) Initialization Figure 3: Example of the Parsing Process with Cascaded Chunking Model 4. Terminate the algorithm if a single bunsetsu segment remains, otherwise return to the step 2 and repeat. Figure 3 shows an example of the parsing process with the cascaded chunking model. 4.1.2 Features As a Japanese dependency analyzer based on the cascaded chunking model, we use the publicly available version of CaboCha (Kudo and Matsumoto, 2002), which is trained with the manually parsed sentences of Kyoto text corpus (Kurohashi and Nagao, 1998), that are 38,400 sentences selected from the 1995 Mainichi newspaper text. The standard feature set used by CaboCha consists of static features and dynamic features. Static features are those solely defined once the pair of modifier/modifiee bunsetsu segments is specified. For the pair of modifier/modifiee bunsetsu segments, the following are used as static features: head words and their parts-of-speech tags, inflection-types/forms, functional words and their parts-of-speech tags, inflection-types/forms, inflection forms of the words that appear at the end of bunsetsu segments. As for feature</context>
<context position="23044" citStr="Kurohashi and Nagao, 1998" startWordPosition="3605" endWordPosition="3608">minal conjunctive / modifying predicate particle 5 Experimental Evaluation 5.1 Training/Test Data Sets For the training of chunking compound functional expressions, we collected 2,429 example sentences from the 1995 Mainichi newspaper text corpus. For each of the 59 compound functional expressions for evaluation mentioned in section 1, at least 50 examples are included in this training set. For the testing of chunking compound functional expressions, as well as training/testing of learning dependencies of compound functional expressions, we used manually-parsed sentences of Kyoto text corpus (Kurohashi and Nagao, 1998), that are 38,400 sentences selected from the 1995 Mainichi newspaper text (the 2,429 sentences above are selected so that they are exclusive of the 37,400 sentences of Kyoto text corpus.). To those data sets, we manually annotate usage labels of the 59 compound functional expressions (details in Table 3). Usages # of functional content total sentences for chunker 1918 1165 3083 2429 training Kyoto text corpus 5744 1959 7703 38400 Table 3: Statistics of Data Sets Table 4: Evaluation Results of Chunking (%) 5.2 Chunking As we show in Table 4, performance of our SVMsbased chunkers as well as sev</context>
</contexts>
<marker>Kurohashi, Nagao, 1998</marker>
<rawString>S. Kurohashi and M. Nagao. 1998. Building a Japanese parsed corpus while improving the parsing system. In Proc. 1st LREC, pages 719–724.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Morita</author>
<author>M Matsuki</author>
</authors>
<title>Nihongo Hyougen Bunkei,</title>
<date>1989</date>
<volume>5</volume>
<note>of NAFL Sensho. ALC. (in Japanese).</note>
<contexts>
<context position="9761" citStr="Morita and Matsuki, 1989" startWordPosition="1457" endWordPosition="1460">dentification in a text. We first show that the proposed method of chunking compound functional expressions significantly outperforms existing Japanese text processing tools. Next, we further show that the dependency analysis model of (Kudo and Matsumoto, 2002) applied to the results of identifying compound functional expressions significantly outperforms the one applied to the results without identifying compound functional expressions. 2 Japanese Compound Functional Expressions There exist several collections which list Japanese functional expressions and examine their usages. For example, (Morita and Matsuki, 1989) examine 450 functional expressions and (Group Jamashii, 1998) also lists 965 expressions and their example sentences. Compared with those two collections, Gendaigo Hukugouji Youreishu (National Language Research Institute, 2001) (henceforth, denoted as GHY) concentrates on 125 major functional expressions which have non-compositional usages, as well as their variants6, and collects example sentences of those expressions. As we mentioned in the previous section, as a first step towards developing a tool for identifying Japanese compound functional expressions, we start with those 125 major fun</context>
</contexts>
<marker>Morita, Matsuki, 1989</marker>
<rawString>Y. Morita and M. Matsuki. 1989. Nihongo Hyougen Bunkei, volume 5 of NAFL Sensho. ALC. (in Japanese).</rawString>
</citation>
<citation valid="true">
<title>Gendaigo Hukugouji Youreishu.</title>
<date>2001</date>
<institution>National Language Research Institute.</institution>
<note>(in Japanese).</note>
<marker>2001</marker>
<rawString>National Language Research Institute. 2001. Gendaigo Hukugouji Youreishu. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Nilsson</author>
</authors>
<title>Multiword units in syntactic parsing.</title>
<date>2004</date>
<booktitle>In Proc. LREC Workshop, Methodologies and Evaluation ofMultiword Units in Real-World Applications,</booktitle>
<pages>39--46</pages>
<marker>Nivre, Nilsson, 2004</marker>
<rawString>J. Nivre and J. Nilsson. 2004. Multiword units in syntactic parsing. In Proc. LREC Workshop, Methodologies and Evaluation ofMultiword Units in Real-World Applications, pages 39–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Sag</author>
<author>T Baldwin</author>
<author>F Bond</author>
<author>A Copestake</author>
<author>D Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proc. 3rd CICLING,</booktitle>
<pages>1--15</pages>
<contexts>
<context position="12275" citStr="Sag et al., 2002" startWordPosition="1844" endWordPosition="1847">∼ ∼ (Please make it clear whether this is true or not.) という 彼は生きている という 知らせを聞いた。 functional (to-iu) (∼ という (to-iu) = that ∼) (I heard that he is alive.) という 「遊びに来て下さい」 という 人もいる。 content (to-iu) (∼ という (to-iu) = say (that) ∼) (Somebody says “Please visit us.”.) ていい この議論が終ったら休憩し ていい 。 functional (te-ii) (∼ ていい (te-ii) = may ∼) (You may have a break after we finish this discussion.) ていい このかばんは大きく ていい 。 content (te-ii) (∼ ていい (te-ii) = nice because ∼) (This bag is nice because it is big.) Table 2: Classification and Example Usages of Compound Functional Expressions tal). In this paper, following (Sag et al., 2002), we regard each variant as a fixed expression, rather than a semi-fixed expression or a syntactically-flexible expression 7. Then, we focus on evaluating the effectiveness of straightforwardly applying a standard chunking technique to the task of identifying Japanese compound functional expressions. As in Table 2 (a), according to their grammatical functions, those 337 expressions in total are roughly classified into post-positional particle type, and auxiliary verb type. Functional expressions of post-positional particle type are further classified into three subtypes: i) conjunctive particl</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>I. Sag, T. Baldwin, F. Bond, A. Copestake, and D. Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Proc. 3rd CICLING, pages 1–15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Shudo</author>
<author>T Tanabe</author>
<author>M Takahashi</author>
<author>K Yoshimura</author>
</authors>
<title>MWEs as non-propositional content indicators.</title>
<date>2004</date>
<booktitle>In Proc. 2nd ACL Workshop on Multiword Expressions: Integrating Processing,</booktitle>
<pages>32--39</pages>
<marker>Shudo, Tanabe, Takahashi, Yoshimura, 2004</marker>
<rawString>K. Shudo, T. Tanabe, M. Takahashi, and K. Yoshimura. 2004. MWEs as non-propositional content indicators. In Proc. 2nd ACL Workshop on Multiword Expressions: Integrating Processing, pages 32–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tsuchiya</author>
<author>T Shime</author>
<author>T Takagi</author>
<author>T Utsuro</author>
<author>K Uchimoto</author>
<author>S Matsuyoshi</author>
<author>S Sato</author>
<author>S Nakagawa</author>
</authors>
<title>Chunking Japanese compound functional expressions by machine learning.</title>
<date>2006</date>
<booktitle>In Proc. Workshop on Multi-Word-Expressions in a Multilingual Context,</booktitle>
<pages>25--32</pages>
<contexts>
<context position="8119" citStr="Tsuchiya et al., 2006" startWordPosition="1214" endWordPosition="1217"> ᚻ (means) 䈫 (with) 䈚 (do) 䈩 (and)   ⸃ (solution) ᚻ (means) 䈫䈚䈩 (as)  Figure 2: Overall Flow of Processing Compound Functional Expressions in a Japanese Sentence lustrated in Figure 2. First of all, we assume a sequence of morphemes obtained by a variant of ChaSen with all the compound functional expressions removed from its outputs, as an input to our procedure of identifying compound functional expressions and analyzing their dependency relations. We formalize the task of identifying Japanese compound functional expressions in a text as a machine learning based chunking problem (Tsuchiya et al., 2006). We employ the technique of Support Vector Machines (SVMs) (Vapnik, 1998) as the machine learning technique, which has been successfully applied to various natural language processing tasks including chunking tasks such as phrase chunking and named entity chunking. Next, against the results of identifying compound functional expressions, we apply the method of dependency analysis based on the cascaded chunking model (Kudo and Matsumoto, 2002), which is simple and efficient because it parses a sentence deterministically only deciding whether the current bunsetsu segment modifies the one on its</context>
<context position="13502" citStr="Tsuchiya et al., 2006" startWordPosition="2017" endWordPosition="2020">es, which are used for constructing subordinate clauses, ii) case-marking particle types, iii) adnominal particle types, which are used for constructing adnominal 7Compound functional expressions of auxiliary verb types can be regarded as syntactically-flexible expressions. clauses. Furthermore, for examples of compound functional expressions listed in Table 2 (a), Table 2 (b) gives their example sentences as well as the description of their usages. 3 Identifying Compound Functional Expressions by Chunking with SVMs This section describes summaries of formalizing the chunking task using SVMs (Tsuchiya et al., 2006). In this paper, we use an SVMs-based chunking tool YamCha8 (Kudo and Matsumoto, 2001). In the SVMs-based chunking framework, SVMs are used as classifiers for assigning labels for representing chunks to each token. In our task of chunking Japanese compound functional expressions, each 8http://chasen.org/˜taku/software/ yamcha/ 68 sentence is represented as a sequence of morphemes, where a morpheme is regarded as a token. formation on the candidate compound functional expression at i-th position. 3.1 Chunk Representation For representing proper chunks, we employ IOB2 representation, which has b</context>
<context position="15944" citStr="Tsuchiya et al., 2006" startWordPosition="2428" endWordPosition="2431">for the i-th morpheme: −→ Parsing Direction −→ Morpheme mi−2 mi−1 mi mi+1 mi+2 Feature set Fi−2 Fi−1 Fi Fi+1 Fi+2 at a position Chunk label ci−2 ci−1 ci Here, mi is the morpheme appearing at i-th position, Fi is the feature set at i-th position, and ci is the chunk label for i-th morpheme. Roughly speaking, when identifying the chunk label ci for the i-th morpheme, we use the feature sets Fi−2, Fi−1, Fi, Fi+1, Fi+2 at the positions i − 2, i − 1, i, i + 1, i + 2, as well as the preceding two chunk labels ci−2 and ci−1. The detailed definition of the feature set Fi at i-th position is given in (Tsuchiya et al., 2006), which mainly consists of morphemes as well as in4 Learning Dependency Relations of Japanese Compound Functional Expressions 4.1 Japanese Dependency Analysis using Cascaded Chunking 4.1.1 Cascaded Chunking Model First of all, we define a Japanese sentence as a sequence of bunsetsu segments B = (b1, b2, ... , b.) and its syntactic structure as a sequence of dependency patterns D = (Dep(1), Dep(2), ... , Dep(m − 1)), where Dep(i) = j means that the bunsetsu segment bi depends on (modifies) bunsetsu segment b-. In this framework, we assume that the dependency sequence D satisfies the following t</context>
</contexts>
<marker>Tsuchiya, Shime, Takagi, Utsuro, Uchimoto, Matsuyoshi, Sato, Nakagawa, 2006</marker>
<rawString>M. Tsuchiya, T. Shime, T. Takagi, T. Utsuro, K. Uchimoto, S. Matsuyoshi, S. Sato, and S. Nakagawa. 2006. Chunking Japanese compound functional expressions by machine learning. In Proc. Workshop on Multi-Word-Expressions in a Multilingual Context, pages 25–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V N Vapnik</author>
</authors>
<title>Statistical Learning Theory.</title>
<date>1998</date>
<publisher>WileyInterscience.</publisher>
<contexts>
<context position="8193" citStr="Vapnik, 1998" startWordPosition="1228" endWordPosition="1229">igure 2: Overall Flow of Processing Compound Functional Expressions in a Japanese Sentence lustrated in Figure 2. First of all, we assume a sequence of morphemes obtained by a variant of ChaSen with all the compound functional expressions removed from its outputs, as an input to our procedure of identifying compound functional expressions and analyzing their dependency relations. We formalize the task of identifying Japanese compound functional expressions in a text as a machine learning based chunking problem (Tsuchiya et al., 2006). We employ the technique of Support Vector Machines (SVMs) (Vapnik, 1998) as the machine learning technique, which has been successfully applied to various natural language processing tasks including chunking tasks such as phrase chunking and named entity chunking. Next, against the results of identifying compound functional expressions, we apply the method of dependency analysis based on the cascaded chunking model (Kudo and Matsumoto, 2002), which is simple and efficient because it parses a sentence deterministically only deciding whether the current bunsetsu segment modifies the one on its immediate right hand side. As we showed in Figure 1, identifying compound</context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>V. N. Vapnik. 1998. Statistical Learning Theory. WileyInterscience.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>