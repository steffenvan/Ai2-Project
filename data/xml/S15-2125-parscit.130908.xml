<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003296">
<title confidence="0.9955875">
ECNU: Extracting Effective Features from Multiple Sequential Sentences
for Target-dependent Sentiment Analysis in Reviews
</title>
<author confidence="0.99972">
Zhihua Zhang, Man Lan*
</author>
<affiliation confidence="0.982821666666667">
Shanghai Key Laboratory of Multidimensional Information Processing
Department of Computer Science and Technology,
East China Normal University, Shanghai 200241, P. R. China
</affiliation>
<email confidence="0.996624">
51131201039@ecnu.cn, mlan@cs.ecnu.edu.cn*
</email>
<sectionHeader confidence="0.995605" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999702">
This paper describes our systems submitted to
the target-dependent sentiment polarity clas-
sification subtask in aspect based sentimen-
t analysis (ABSA) task (i.e., Task 12) in Se-
mEval 2015. To settle this problem, we ex-
tracted several effective features from three se-
quential sentences, including sentiment lexi-
con, linguistic and domain specific features.
Then we employed these features to con-
struct classifiers using supervised classifica-
tion algorithm. In laptop domain, our systems
ranked 2nd out of 6 constrained submissions
and 2nd out of 7 unconstrained submissions.
In restaurant domain, the rankings are 5th out
of 6 and 2nd out of 8 respectively.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999582960784314">
Reviews express opinions of customers towards var-
ious aspects of a product or service. Mining cus-
tomer reviews (i.e., opinion mining) has emerged
as an interesting new research direction in recen-
t years. Since sentiment expressed in reviews usu-
ally adheres to specific categories or target terms, it
is much meaningful to identify the sentiment target
and its orientation, which helps users gain precise
sentiment insights on specific sentiment target.
Unlike most existing sentiment analysis method-
s which try to detect the polarity of a sentence or
a review, the aspect based sentiment analysis task
(ASBA) shared as task 12 in SemEval 2015 is aim-
ing at addressing the category- or target- dependent
sentiment analysis in reviews. There are two types
of subtasks organized in ASBA. The first aspect de-
tection subtask is to identify the sentiment adherent
from reviews, i.e., the category (i.e., entity-attribute
(E-A) pair) or opinion target expression (OTE) in re-
views. In most cases, the customers may not ex-
plicitly indicate the entity and attribute words in re-
views but the opinion target expression is a segment
of review. For example, in a given review: “The
pizza is overpriced and soggy.”, target=“pizza”,
category=“FOOD-QUALITY”. Its category label
FOOD-QUALITY does not exist in reviews, while it-
s OTE word “pizza” is explicitly present in reviews.
The second sentiment polarity classification subtask
is to assign a polarity label (i.e., positive, negative or
neutral) for every E-A pair or OTE identified from
the given reviews. We participated the second type
subtask, i.e., performing sentiment polarity classifi-
cation on reviews. There are two domains in this
sentiment analysis subtask, i.e, laptop and restauran-
t. In laptop domain, only E-A pairs are annotated
and provided in reviews while in restaurant domain,
both E-A pairs and OTE are provided. Comparing
with laptop reviews, the restaurant reviews provide
the annotated surface words adhering to sentimen-
t. Therefore we speculate that the performance in
restaurant domain would be much better than that of
laptop domain.
The study of aspect based sentiment analysis fo-
cuses on discovering the opinions or sentiments ex-
pressed by a customer on different categories or as-
pects (Liu, 2012). In recent years, it has drawn a lot
of attentions. For example, (Branavan et al., 2009;
He et al., 2012; Mei et al., 2007) used topic or cat-
egory information. (Lin and He, 2009; Jo and Oh,
2011) presented LDA-based models, which incorpo-
rate aspect and sentiment analysis together to model
</bodyText>
<page confidence="0.978184">
736
</page>
<bodyText confidence="0.95942924137931">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 736–741,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
sentiments towards different aspects. (Hu and Liu,
2004; Ding et al., 2008) adopted lexicon-based ap-
proaches to detect the sentiment on different aspect-
s. In addition, (Boiy and Moens, 2009; Jiang et al.,
2011) explored the work to determine whether the
reviews contain the aspect information. Unlike the
above study, (Xiang et al., 2014) split the data into
multiple subsets based on category distributions and
then built seperate classifier for each category.
Following previous work (Brun et al., 2014;
Brychcin et al., 2014; Castellucci et al., 2014; Kir-
itchenko et al., 2014), a rich set of features are
adopted in this work: linguistic features (e.g., n-
grams, grammatical relationship, POS, negations),
sentiment lexicon features (e.g., MPQA, General In-
quirer, SentiWordNet, etc) and domain specific fea-
tures (e.g., in-domain word list, punctuation, etc).
We also performed a series of experiments to com-
pare supervised machine learning algorithms with d-
ifferent parameters and to choose effective feature
subsets for performance of classification.
The rest of this paper is structured as follows. In
Section 2, we describe our system in details, includ-
ing preprocessing, feature engineering, evaluation
metrics, etc. Section 3 reports data sets, experiments
and result discussion. Finally, Section 4 concludes
our work.
</bodyText>
<sectionHeader confidence="0.97013" genericHeader="method">
2 System Description
</sectionHeader>
<subsectionHeader confidence="0.976372">
2.1 Motivation
</subsectionHeader>
<bodyText confidence="0.999973583333334">
Unlike tweets with word length limitation, a review
usually consists of several sentences and one single
sentence may contain mixed opinions towards dif-
ferent targets. However, based on our observation
and statistics on the data provided by SemEval 2015
Task 12, we find that most reviews (about 70%) have
consistent opinion in their sentences, even though
these sentences contain different category descrip-
tions. Furthermore, although the E-A pair annota-
tion is provided for each sentence, it is usually in-
ferred by human being based on common knowl-
edge from review rather than a single sentence. That
is, the E-A pair information is supposed to be in-
duced from contextual sentences rather than a single
sentence alone. On the other hand, since one sen-
tence may contain more than one category (i.e. E-A
pair), this sentence alone may not provide enough
information for every E-A pair. In consideration of
above described reasons, we use multiple sentences
rather than one single sentence to extract features for
sentiment analysis. In this work, we used three se-
quential sentences, that is, for one given sentence,
we combined its preceding and subsequent sentence
with this current sentence together to perform senti-
ment analysis.
As we mentioned, one sentence may contain more
than one E-A pair. As a result, for each E-A pair,
not all words in this sentence or review are quite rel-
evant and we need to select out only relevant words
from three sequential sentences in terms of the cor-
responding E-A pair. Unlike the OTE words which
already exist in reviews, most E-A pairs are not
present in the sentence. Thus, for each E-A pair, we
first extracted target words having top tfidf scores
from three sequential sentences and then chose the
relevant words from parse tree. Specifically, in lap-
top domain, the sentences contain only E-A pairs,
so we selected two words having the highest tfid-
f scores from three sequential sentences in terms of
corresponding E-A pair as its target words. Inspired
by (Kiritchenko et al., 2014), for each target word in
E-A pair, we selected the words from parse tree with
distance d =&lt; 2 as relevant words in terms of this
E-A pair. After that, for all words in target words, we
combined all their relevant words as pending words
to extract features for sentiment analysis. While in
restaurant domain since the sentences contain both
E-A pair and opinion target expressions (OTE), we
only combined the words in OTE with two word-
s mentioned before as target words and chose their
relevant words as pending words.
For each domain, each participant can submit two
runs: (1) constrained: only the provided data can be
used; (2) unconstrained: any additional resources
can be used. In this task, we adopted 7 sentiment
lexicons as external resources. Thus, the only differ-
ence of our two systems lies in the sentiment lexicon
score features. For both systems, we extracted many
traditional types of features to build classifiers for
classification.
</bodyText>
<subsectionHeader confidence="0.999165">
2.2 Data Preprocessing
</subsectionHeader>
<bodyText confidence="0.999808">
Four preprocessing operations were performed. We
first removed the XML tags from data and then
transformed the abbreviations to their normal form-
</bodyText>
<page confidence="0.982618">
737
</page>
<bodyText confidence="0.9999364">
s, i.e., “don’t” to “do not”. We used Stanford Parser
tools1 for tokenization, POS tagging and parsing. Fi-
nally, the WordNet-based Lemmatizer implemented
in NLTK2 was adopted to lemmatize words to their
base forms with the aid of their POS tags.
</bodyText>
<subsectionHeader confidence="0.999125">
2.3 Feature Engineering
</subsectionHeader>
<bodyText confidence="0.999498826086956">
In this work, we used three types of features:
sentiment lexicon features, linguistic features and
domain-specific features. All features were extract-
ed from pending words as described above.
Sentiment Lexicon Features: Given pending
words, we first converted them into lowercase and
then calculated five feature values for each senti-
ment lexicon: (1) the ratio of positive words to pend-
ing words, (2) the ratio of negative words to pend-
ing words, (3) the maximum sentiment score, (4) the
minimum sentiment score3, (5) the sum of sentiment
scores. If the pending word does not exist in one sen-
timent lexicon, its corresponding score is set to zero.
The following 8 sentiment lexicons are used in our
systems. Specifically, the first lexicon is employed
to build constrained system and others 7 lexicons for
unconstrained system.
- Constrained PMI: To build constrained system,
we generated two domain-specific sentimen-
t lexicons from the given training data respec-
tively (i.e., laptop and restaurant). Given a term
w, this PMI-based score is calculated from la-
beled reviews as below:
</bodyText>
<equation confidence="0.827341">
score(w) = PMI(w, pos) − PMI(w, neg)
</equation>
<bodyText confidence="0.999243285714286">
where PMI stands for pointwise mutual infor-
mation.
- Bing Liu opinion lexicon4: This sentiment lex-
icon contains two annotated words lists: posi-
tive (about 2, 000) and negative(about 4, 800).
- General Inquirer lexicon5: The General Inquir-
er lexicon tries to classify English words along
</bodyText>
<footnote confidence="0.999234142857143">
1http://nlp.stanford.edu/software/lex-parser.shtml
2http://nltk.org
3We convert the sentiment scores in all sentiment lexicons
to the range of [−1, 1], where “-” denotes negative sentiment.
4http://www.cs.uic.edu/liub/FBS/sentiment-
analysis.html#lexicon
5http://www.wjh.harvard.edu/inquirer/homecat.htm
</footnote>
<bodyText confidence="0.996137647058823">
several dimensions, including sentiment polar-
ity and we selected about 1, 500 positive words
and 2, 000 negative words.
- IMDB6: This lexicon is generated from a large
data set from IMDB which contains 25, 000
positive and 25, 000 negative movie reviews
and the PMI-based sentiment score of each
word is calculated as above.
- MPQA7: MPQA contains about 8, 000 subjec-
tive words with 6 types of label: strong/weak
positive, strong/weak negative, both (having
positive and negative sentiment) and neutral.
Then we transformed these above nominal la-
bels to 1, 0.5, −1, −0.5, 0, 0 respectively.
- SentiWordNet8: The sentiment scores of each
item in SentiWordNet is represented as a tu-
ple i.e., positivity and negativity.We use the d-
ifference between positive and negative score
as its sentiment score. When locating the cor-
responding item, we retrieved the word lemma
and selected the first term in searched results
according to its POS tag.
- NRC Hashtag Sentiment Lexicon9: (Moham-
mad et al., 2013) collected two tweet sets con-
taining hashtags and used the sentiment of its
hashtags as the sentiment label for each tweet.
In this experiment, we used both unigrams and
bigrams sentiment lexicons.
- NRC Sentiment140 Lexicon10: This lexicon
is generated from a collection of 1.6 million
tweets with positive or negative emoticons and
contains about 62, 000 unigrams, 677, 000 bi-
grams and 480, 000 non-contiguous pairs. We
used unigrams and bigrams.
</bodyText>
<subsectionHeader confidence="0.599121">
Linguistic Features
</subsectionHeader>
<bodyText confidence="0.89504825">
- Word n-grams: We converted all pending word-
s into lowercase and removed low frequency
terms (G 5). After that, we extracted word-
level unigram and bigrams.
</bodyText>
<footnote confidence="0.999829666666667">
6http://anthology.aclweb.org//S/S13/S13-2.pdf#page=444
7http://mpqa.cs.pitt.edu/
8http://sentiwordnet.isti.cnr.it/
9http://www.umiacs.umd.edu/saif/WebDocs/NRC-
Hashtag-Sentiment-Lexicon-v0.1.zip
10http://help.sentiment140.com/for-students/
</footnote>
<page confidence="0.991907">
738
</page>
<bodyText confidence="0.993948769230769">
- POS Features: (Pak and Paroubek, 2010)
found that subjective texts often contain more
adjectives or adverbs and less nouns than ob-
jective texts. Therefore, the POS tags are im-
portant features for sentiment analysis. We
recorded the number of nouns (the correspond-
ing POS tags are NN, NNP, NNS and NNPS),
verbs (VB, VBD, VBG, VBN, VBP and VBZ),
adjectives (JJ, JJR and JJS) and adverbs (RB,
RBR and RBS) in pending words.
- Grammatical Relationship: The grammatical
relationship usually expresses the role of words
in phrase and contains certain semantic infor-
mation (Zhao et al., 2014). We obtained de-
pendency information from parse tree and the
grammatical information is denoted as a tuple,
e.g., amod(surprises, great), where amod rep-
resents the dependency relationship between
surprises and great (here great is a modifier).
We presented two types of features: the rela-
tionship with the first word in tuple as Rel1 and
with the second word as Rel2. The size of each
feature set is approximately 150.
- Negation Features: We collected 29 negations
from Internet and designed this binary feature
to record if there is negation in pending words.
</bodyText>
<subsectionHeader confidence="0.62955">
Domain Specifical Features
</subsectionHeader>
<bodyText confidence="0.999916454545455">
- In-domain word list: For different domains, the
words indicative of viewpoints are quite differ-
ent. For example, useful, fast, excellent repre-
sent positive opinion in laptop domain and deli-
cious, cheap, beautiful stand for positive opin-
ion in restaurant domain. Therefore, we manu-
ally built two in-domain word lists from train-
ing instances indicative of positive and nega-
tive for both domains respectively. This fea-
ture records the number of in-domain words in
pending words.
</bodyText>
<listItem confidence="0.8259">
- Punctuation: Exclamation (!) and question
(?) signs often indicate emotions (i.e., surprise,
</listItem>
<bodyText confidence="0.847228">
shock, interrogative, etc.) of users. Thus this
feature counts the number of exclamations and
questions in pending words.
- All-caps: This feature is the number of upper-
case words in pending words.
</bodyText>
<subsectionHeader confidence="0.984484">
2.4 Evaluation Measures
</subsectionHeader>
<bodyText confidence="0.9998635">
To evaluate the performance of different systems,
the official evaluation measure accuracy is adopted.
</bodyText>
<sectionHeader confidence="0.997562" genericHeader="method">
3 Experiment
</sectionHeader>
<subsectionHeader confidence="0.964507">
3.1 Datasets
</subsectionHeader>
<bodyText confidence="0.999920529411765">
The organizers provided two XML format docu-
ments regarding laptop and restaurant domain. In
laptop, the {E-A, P} (i.e., {EntityAttribute, Polari-
ty}) annotations are assigned at the sentence level
taking the context of the whole review into accoun-
t. In restaurant, it is a quadruple, i.e., {E-A, OTE,
P}, where OTE stands for opinion target expres-
sion. In laptop, 22 entities (e.g., LAPTOP, DISPLAY,
CPU, etc.) and 9 attributes (e.g., PORTABILITY,
PRICE, CONNECTIVITY, etc.) are tagged while the
restaurant data contains 6 entities (e.g., SERVICE,
RESTAURANT, FOOD, etc.) and 5 attributes (i.e.,
PRICES, QUALITY, STYLE OPTIONS, etc.). Table
1 shows the statistics of the data sets used in our ex-
periments. Specifically, in restaurant, the opinions
are adhered to OTEs and if the target does not exist
explicitly, the OTE is tagged as NULL.
</bodyText>
<table confidence="0.975754">
Dataset Reviews Sentences Positive Negative Neutral All
Laptop:
train 277 1,739 1,103 765 106 1,974
test 173 725 541 329 79 949
Restaurant:
train 254 1,315 1,198 403 53 1,654
test 96 663 454 346 45 845
</table>
<tableCaption confidence="0.767515333333333">
Table 1: Statistics of training and test dataset in laptop
and restaurant domains. Positive, Negative, Neural and
All stand for the number of corresponding instances.
</tableCaption>
<subsectionHeader confidence="0.999039">
3.2 Experiments on Training data
</subsectionHeader>
<bodyText confidence="0.999923416666667">
To address this task, we adopted similar methods for
both laptop and restaurant domains, i.e, employing
rich features to build classifiers and adopting Con-
strained PMI features as sentiment lexicon feature
for constrained systems while other sentiment lex-
icons for unconstrained systems. The 5-fold cross
validation was performed for system development.
Table 2 shows the results of feature selection ex-
periments for unconstrained and constrained sys-
tems in restaurant and laptop domains.
From Table 2, it is interesting to find: (1) Sen-
tiLexi features are the most effective feature type-
</bodyText>
<page confidence="0.995333">
739
</page>
<table confidence="0.999816090909091">
Restaurant Laptop
Constrained Unconstrained Constrained Unconstrained
Feature Accuracy Feature Accuracy Feature Accuracy Feature Accuracy
ConPMI 79.80 SentiLexi 82.82 ConPMI 80.09 SentiLexi 81.21
+bigram 80.77(+0.97) +Domain 83.49(+0.67) +Domain 80.49(+0.40) +bigram 82.02(+0.81)
+Negation 81.07(+0.30) +Negation 84.28(+0.77) +Negation 81.30(+0.81) +rel2 83.54(+1.52)
+rel2 81.25(+0.18) +rel1 84.52(+0.24) +rel2 81.71(+0.41) +rel1 83.94(+0.40)
+Domain 81.43(+0.18) +rel2 84.34(-0.18) +POS 81.25(-0.46) +Negation 84.19(+0.25)
+rel1 81.07(-0.36) +bigram 84.03(-0.31) +unigram 81.00(-0.25) +unigram 84.04(-0.15)
+POS 80.89(-0.18) +POS 83.67(-0.36) +rel1 79.53(-0.47) +Domain 83.99(-0.05)
+unigram 78.71(-2.18) +unigram 81.63(-2.04) +bigram 79.38(-0.15) +POS 82.77(-0.78)
</table>
<tableCaption confidence="0.989999666666667">
Table 2: Results of feature selection experiments for restaurant and laptop domains on training datasets. The numbers
in the brackets are the performance increments compared with the previous results. ConPMI stands for Constrained
PMI features while SentiLexi is other external sentiment lexicons features.
</tableCaption>
<bodyText confidence="0.999501">
s to detect the polarity regardless of constrained or
unconstrained. (2) POS features are not quite ef-
fective in all systems. The possible reasons may
be that POS aims at identifying the subjective in-
stances from objective ones and it has no discrimi-
nating power for the type of sentiment polarity. (3)
The unigram features are not as effective as expect-
ed because most words are already present in rel1
or rel2 feature. (4) The performances in laptop and
restaurant domain are comparable, which is incon-
sistent with our previous speculation (i.e., the re-
sult of restaurant domain performs better than that of
laptop domain since both A-E pair and OTE are pro-
vided in restaurant). We do a deep analysis and find
that the top two words with tfidf score usually in-
clude the OTE words in restaurant domain. This also
confirmed that this target words selection method is
effective for laptop domain.
Besides, in our preliminary experiments for both
domains, we examined the SVM classifiers with var-
ious parameters implemented in scikit-learn tools11.
Finally we employed the configurations listed in Ta-
ble 3 for test data.
</bodyText>
<subsectionHeader confidence="0.543668">
Domain Constrained Unconstrained
</subsectionHeader>
<table confidence="0.975006">
Restaurant SVM,kernel=linear,c=0.1 SVM,kernel=linear,c=0.5
Laptop SVM,kernel=linear,c=0.1 SVM,kernle=linear,c=1
</table>
<tableCaption confidence="0.997088">
Table 3: System configurations for the constrained and
unconstrained runs in two domains.
</tableCaption>
<subsectionHeader confidence="0.980636">
3.3 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.9973705">
Using the optimum feature set shown in Table 2 and
configurations described in Table 3, we trained sep-
</bodyText>
<footnote confidence="0.470737">
11http://scikit-learn.org/stable/
</footnote>
<bodyText confidence="0.999513227272728">
arate models for each domain and evaluated them
against the SemEval-2015 Task 12 test set.
Table 4 presents the results of our systems and
top-ranked systems on test data provided by orga-
nizer for laptop and restaurant domain. In laptop do-
main, our systems ranked 2nd out of 6 constrained
submissions and 2nd out of 7 unconstrained submis-
sions while in restaurant domain, the rankings are
5th/6 and 2nd/8 respectively.
The results in Table 4 shows that in both domain-
s our unconstrained systems performed comparable
to the best results. It indicated that using the exter-
nal sentiment lexicons as additional resources makes
great contribution although the majority of these ex-
ternal sentiment lexicons are out of domain, e.g., N-
RC lexicons are generated from tweets and IMDB is
about movie reviews. On the other hand, the con-
strained system which calculated the PMI score for
each word from training data only, would involve a
lot of noise due to (1) no sufficient training instances
and (2) without consideration of the relationship be-
tween word sentiment and its opinion adherent.
</bodyText>
<table confidence="0.9799162">
TeamID Restaurant Laptop
Con Uncon Con Uncon
ECNU 69.82(5) 78.11(2) 74.50(2) 78.29(2)
lsislif 75.50(1) - 77.87(1) -
sentiue - 78.70(1) - 79.35(1)
</table>
<tableCaption confidence="0.9799142">
Table 4: Performance of our systems and the top-ranked
system for laptop and restaurant domains in terms of Ac-
curacy(%) on test datasets. Con stands for constrained
and Uncon represents unconstrained. The numbers in the
brackets are the rankings on corresponding submissions.
</tableCaption>
<page confidence="0.995428">
740
</page>
<sectionHeader confidence="0.998951" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999949">
In this paper, we examined several feature types, i.e.,
surface text, syntax feature, sentiment lexicon fea-
ture, etc, to detect sentiment polarity towards cate-
gory or opinion target expression in reviews. More-
over, we extracted features from three sequential
sentences in consideration of the characteristic of re-
view. Our systems perform better than majority of
submissions (e.g., rank 2nd out of 7 and 2nd out of 8
on unconstrained submissions in laptop and restau-
rant domains respectively). For the future work, we
would like to construct domain-specific sentiment
lexicons and present more effective in-domain fea-
tures to settle this problem.
</bodyText>
<sectionHeader confidence="0.999512" genericHeader="acknowledgments">
5 Acknowledgments
</sectionHeader>
<bodyText confidence="0.998615">
This research is supported by grants from Science
and Technology Commission of Shanghai Munici-
pality under research grant no. (14DZ2260800 and
15ZR1410700) and Shanghai Collaborative Innova-
tion Center of Trustworthy Software for Internet of
Things (ZF1213).
</bodyText>
<sectionHeader confidence="0.995812" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.992968232876712">
Erik Boiy and Marie-Francine Moens. 2009. A machine
learning approach to sentiment analysis in multilingual
web texts. Information retrieval, 12(5):526–558.
SRK Branavan, Harr Chen, Jacob Eisenstein, and Regi-
na Barzilay. 2009. Learning document-level semantic
properties from free-text annotations. Journal of Arti-
ficial Intelligence Research, 34(2):569.
Caroline Brun, Diana Nicoleta Popa, and Claude Roux.
2014. XRCE: Hybrid classification for aspect-based
sentiment analysis. SemEval 2014, page 838.
Tom´aˇs Brychc´ın, Michal Konkol, and Josef Steinberger.
2014. UWB: Machine learning approach to aspect-
based sentiment analysis. SemEval 2014, page 817.
Giuseppe Castellucci, Simone Filice, Danilo Croce, and
Roberto Basili. 2014. UNITOR: Aspect based senti-
ment analysis with structured learning. SemEval 2014,
page 761.
Xiaowen Ding, Bing Liu, and Philip S Yu. 2008. A holis-
tic lexicon-based approach to opinion mining. In Pro-
ceedings of the 2008 International Conference on Web
Search and Data Mining, pages 231–240.
Yulan He, Chenghua Lin, Wei Gao, and Kam-Fai Wong.
2012. Tracking sentiment and topic dynamics from
social media. In Sixth International AAAI Conference
on Weblogs and Social Media.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, pages 168–177.
Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun
Zhao. 2011. Target-dependent Twitter sentiment clas-
sification. In Proceedings of the 49th Annual Meeting
of the ACL: Human Language Technologies-Volume 1,
pages 151–160.
Yohan Jo and Alice H Oh. 2011. Aspect and sentiment
unification model for online review analysis. In Pro-
ceedings of the 4th ACM international conference on
Web search and data mining, pages 815–824.
Svetlana Kiritchenko, Xiaodan Zhu, Colin Cherry, and
Saif M Mohammad. 2014. NRC-Canada-2014: De-
tecting aspects and sentiment in customer reviews. Se-
mEval 2014, page 437.
Chenghua Lin and Yulan He. 2009. Joint sentiment/topic
model for sentiment analysis. In Proceedings of the
18th ACM conference on Information and knowledge
management, pages 375–384.
Bing Liu. 2012. Sentiment analysis and opinion min-
ing: synthesis lectures on human language technolo-
gies. Morgan &amp; Claypool Publishers.
Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, and
ChengXiang Zhai. 2007. Topic sentiment mixture:
modeling facets and opinions in weblogs. In Proceed-
ings of the 16th international conference on WWW,
pages 171–180.
Saif Mohammad, Svetlana Kiritchenko, and Xiaodan
Zhu. 2013. NRC-Canada: Building the state-of-the-
art in sentiment analysis of tweets. In Second Joint
Conference on Lexical and Computational Semantics
(*SEM), Volume 2: Proceedings of the Seventh Inter-
national Workshop on Semantic Evaluation (SemEval
2013), pages 321–327, Atlanta, Georgia, USA, June.
Alexander Pak and Patrick Paroubek. 2010. Twitter as a
corpus for sentiment analysis and opinion mining. In
LREC, pages 1320–1326.
Bing Xiang, Liang Zhou, and Thomson Reuters. 2014.
Improving Twitter sentiment analysis with topic-based
mixture modeling and semi-supervised training. In
Proceedings of the 52nd Annual Meeting of the ACL
(Short Papers), pages 434–439.
Jiang Zhao, Tian Tian Zhu, and Man Lan. 2014. ECNU:
One stone two birds: Ensemble of heterogenous mea-
sures for semantic relatedness and textual entailment.
SemEval 2014, page 271.
</reference>
<page confidence="0.99783">
741
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.280888">
<title confidence="0.999056">ECNU: Extracting Effective Features from Multiple Sequential for Target-dependent Sentiment Analysis in Reviews</title>
<author confidence="0.9576265">Man Shanghai Key Laboratory of Multidimensional Information Zhang</author>
<affiliation confidence="0.989082">Department of Computer Science and</affiliation>
<note confidence="0.458644">East China Normal University, Shanghai 200241, P. R.</note>
<abstract confidence="0.997177133333333">This paper describes our systems submitted to the target-dependent sentiment polarity classification subtask in aspect based sentiment analysis (ABSA) task (i.e., Task 12) in SemEval 2015. To settle this problem, we extracted several effective features from three sequential sentences, including sentiment lexicon, linguistic and domain specific features. Then we employed these features to construct classifiers using supervised classification algorithm. In laptop domain, our systems of submissions of submissions. restaurant domain, the rankings are</abstract>
<intro confidence="0.709765">of</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Erik Boiy</author>
<author>Marie-Francine Moens</author>
</authors>
<title>A machine learning approach to sentiment analysis in multilingual web texts. Information retrieval,</title>
<date>2009</date>
<pages>12--5</pages>
<contexts>
<context position="3969" citStr="Boiy and Moens, 2009" startWordPosition="606" endWordPosition="609">ions. For example, (Branavan et al., 2009; He et al., 2012; Mei et al., 2007) used topic or category information. (Lin and He, 2009; Jo and Oh, 2011) presented LDA-based models, which incorporate aspect and sentiment analysis together to model 736 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 736–741, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics sentiments towards different aspects. (Hu and Liu, 2004; Ding et al., 2008) adopted lexicon-based approaches to detect the sentiment on different aspects. In addition, (Boiy and Moens, 2009; Jiang et al., 2011) explored the work to determine whether the reviews contain the aspect information. Unlike the above study, (Xiang et al., 2014) split the data into multiple subsets based on category distributions and then built seperate classifier for each category. Following previous work (Brun et al., 2014; Brychcin et al., 2014; Castellucci et al., 2014; Kiritchenko et al., 2014), a rich set of features are adopted in this work: linguistic features (e.g., ngrams, grammatical relationship, POS, negations), sentiment lexicon features (e.g., MPQA, General Inquirer, SentiWordNet, etc) and</context>
</contexts>
<marker>Boiy, Moens, 2009</marker>
<rawString>Erik Boiy and Marie-Francine Moens. 2009. A machine learning approach to sentiment analysis in multilingual web texts. Information retrieval, 12(5):526–558.</rawString>
</citation>
<citation valid="true">
<authors>
<author>SRK Branavan</author>
<author>Harr Chen</author>
<author>Jacob Eisenstein</author>
<author>Regina Barzilay</author>
</authors>
<title>Learning document-level semantic properties from free-text annotations.</title>
<date>2009</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="3390" citStr="Branavan et al., 2009" startWordPosition="517" endWordPosition="520">ant. In laptop domain, only E-A pairs are annotated and provided in reviews while in restaurant domain, both E-A pairs and OTE are provided. Comparing with laptop reviews, the restaurant reviews provide the annotated surface words adhering to sentiment. Therefore we speculate that the performance in restaurant domain would be much better than that of laptop domain. The study of aspect based sentiment analysis focuses on discovering the opinions or sentiments expressed by a customer on different categories or aspects (Liu, 2012). In recent years, it has drawn a lot of attentions. For example, (Branavan et al., 2009; He et al., 2012; Mei et al., 2007) used topic or category information. (Lin and He, 2009; Jo and Oh, 2011) presented LDA-based models, which incorporate aspect and sentiment analysis together to model 736 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 736–741, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics sentiments towards different aspects. (Hu and Liu, 2004; Ding et al., 2008) adopted lexicon-based approaches to detect the sentiment on different aspects. In addition, (Boiy and Moens, 2009; Jiang et al., 2011)</context>
</contexts>
<marker>Branavan, Chen, Eisenstein, Barzilay, 2009</marker>
<rawString>SRK Branavan, Harr Chen, Jacob Eisenstein, and Regina Barzilay. 2009. Learning document-level semantic properties from free-text annotations. Journal of Artificial Intelligence Research, 34(2):569.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Caroline Brun</author>
<author>Diana Nicoleta Popa</author>
<author>Claude Roux</author>
</authors>
<title>XRCE: Hybrid classification for aspect-based sentiment analysis. SemEval</title>
<date>2014</date>
<pages>838</pages>
<contexts>
<context position="4284" citStr="Brun et al., 2014" startWordPosition="655" endWordPosition="658">SemEval 2015), pages 736–741, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics sentiments towards different aspects. (Hu and Liu, 2004; Ding et al., 2008) adopted lexicon-based approaches to detect the sentiment on different aspects. In addition, (Boiy and Moens, 2009; Jiang et al., 2011) explored the work to determine whether the reviews contain the aspect information. Unlike the above study, (Xiang et al., 2014) split the data into multiple subsets based on category distributions and then built seperate classifier for each category. Following previous work (Brun et al., 2014; Brychcin et al., 2014; Castellucci et al., 2014; Kiritchenko et al., 2014), a rich set of features are adopted in this work: linguistic features (e.g., ngrams, grammatical relationship, POS, negations), sentiment lexicon features (e.g., MPQA, General Inquirer, SentiWordNet, etc) and domain specific features (e.g., in-domain word list, punctuation, etc). We also performed a series of experiments to compare supervised machine learning algorithms with different parameters and to choose effective feature subsets for performance of classification. The rest of this paper is structured as follows. </context>
</contexts>
<marker>Brun, Popa, Roux, 2014</marker>
<rawString>Caroline Brun, Diana Nicoleta Popa, and Claude Roux. 2014. XRCE: Hybrid classification for aspect-based sentiment analysis. SemEval 2014, page 838.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom´aˇs Brychc´ın</author>
<author>Michal Konkol</author>
<author>Josef Steinberger</author>
</authors>
<title>UWB: Machine learning approach to aspectbased sentiment analysis. SemEval</title>
<date>2014</date>
<pages>817</pages>
<marker>Brychc´ın, Konkol, Steinberger, 2014</marker>
<rawString>Tom´aˇs Brychc´ın, Michal Konkol, and Josef Steinberger. 2014. UWB: Machine learning approach to aspectbased sentiment analysis. SemEval 2014, page 817.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giuseppe Castellucci</author>
<author>Simone Filice</author>
<author>Danilo Croce</author>
<author>Roberto Basili</author>
</authors>
<title>UNITOR: Aspect based sentiment analysis with structured learning. SemEval</title>
<date>2014</date>
<pages>761</pages>
<contexts>
<context position="4333" citStr="Castellucci et al., 2014" startWordPosition="663" endWordPosition="666">rado, June 4-5, 2015. c�2015 Association for Computational Linguistics sentiments towards different aspects. (Hu and Liu, 2004; Ding et al., 2008) adopted lexicon-based approaches to detect the sentiment on different aspects. In addition, (Boiy and Moens, 2009; Jiang et al., 2011) explored the work to determine whether the reviews contain the aspect information. Unlike the above study, (Xiang et al., 2014) split the data into multiple subsets based on category distributions and then built seperate classifier for each category. Following previous work (Brun et al., 2014; Brychcin et al., 2014; Castellucci et al., 2014; Kiritchenko et al., 2014), a rich set of features are adopted in this work: linguistic features (e.g., ngrams, grammatical relationship, POS, negations), sentiment lexicon features (e.g., MPQA, General Inquirer, SentiWordNet, etc) and domain specific features (e.g., in-domain word list, punctuation, etc). We also performed a series of experiments to compare supervised machine learning algorithms with different parameters and to choose effective feature subsets for performance of classification. The rest of this paper is structured as follows. In Section 2, we describe our system in details, </context>
</contexts>
<marker>Castellucci, Filice, Croce, Basili, 2014</marker>
<rawString>Giuseppe Castellucci, Simone Filice, Danilo Croce, and Roberto Basili. 2014. UNITOR: Aspect based sentiment analysis with structured learning. SemEval 2014, page 761.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaowen Ding</author>
<author>Bing Liu</author>
<author>Philip S Yu</author>
</authors>
<title>A holistic lexicon-based approach to opinion mining.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 International Conference on Web Search and Data Mining,</booktitle>
<pages>231--240</pages>
<contexts>
<context position="3855" citStr="Ding et al., 2008" startWordPosition="588" endWordPosition="591">ssed by a customer on different categories or aspects (Liu, 2012). In recent years, it has drawn a lot of attentions. For example, (Branavan et al., 2009; He et al., 2012; Mei et al., 2007) used topic or category information. (Lin and He, 2009; Jo and Oh, 2011) presented LDA-based models, which incorporate aspect and sentiment analysis together to model 736 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 736–741, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics sentiments towards different aspects. (Hu and Liu, 2004; Ding et al., 2008) adopted lexicon-based approaches to detect the sentiment on different aspects. In addition, (Boiy and Moens, 2009; Jiang et al., 2011) explored the work to determine whether the reviews contain the aspect information. Unlike the above study, (Xiang et al., 2014) split the data into multiple subsets based on category distributions and then built seperate classifier for each category. Following previous work (Brun et al., 2014; Brychcin et al., 2014; Castellucci et al., 2014; Kiritchenko et al., 2014), a rich set of features are adopted in this work: linguistic features (e.g., ngrams, grammatic</context>
</contexts>
<marker>Ding, Liu, Yu, 2008</marker>
<rawString>Xiaowen Ding, Bing Liu, and Philip S Yu. 2008. A holistic lexicon-based approach to opinion mining. In Proceedings of the 2008 International Conference on Web Search and Data Mining, pages 231–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yulan He</author>
<author>Chenghua Lin</author>
<author>Wei Gao</author>
<author>Kam-Fai Wong</author>
</authors>
<title>Tracking sentiment and topic dynamics from social media.</title>
<date>2012</date>
<booktitle>In Sixth International AAAI Conference on Weblogs and Social Media.</booktitle>
<contexts>
<context position="3407" citStr="He et al., 2012" startWordPosition="521" endWordPosition="524">only E-A pairs are annotated and provided in reviews while in restaurant domain, both E-A pairs and OTE are provided. Comparing with laptop reviews, the restaurant reviews provide the annotated surface words adhering to sentiment. Therefore we speculate that the performance in restaurant domain would be much better than that of laptop domain. The study of aspect based sentiment analysis focuses on discovering the opinions or sentiments expressed by a customer on different categories or aspects (Liu, 2012). In recent years, it has drawn a lot of attentions. For example, (Branavan et al., 2009; He et al., 2012; Mei et al., 2007) used topic or category information. (Lin and He, 2009; Jo and Oh, 2011) presented LDA-based models, which incorporate aspect and sentiment analysis together to model 736 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 736–741, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics sentiments towards different aspects. (Hu and Liu, 2004; Ding et al., 2008) adopted lexicon-based approaches to detect the sentiment on different aspects. In addition, (Boiy and Moens, 2009; Jiang et al., 2011) explored the wor</context>
</contexts>
<marker>He, Lin, Gao, Wong, 2012</marker>
<rawString>Yulan He, Chenghua Lin, Wei Gao, and Kam-Fai Wong. 2012. Tracking sentiment and topic dynamics from social media. In Sixth International AAAI Conference on Weblogs and Social Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="3835" citStr="Hu and Liu, 2004" startWordPosition="584" endWordPosition="587">r sentiments expressed by a customer on different categories or aspects (Liu, 2012). In recent years, it has drawn a lot of attentions. For example, (Branavan et al., 2009; He et al., 2012; Mei et al., 2007) used topic or category information. (Lin and He, 2009; Jo and Oh, 2011) presented LDA-based models, which incorporate aspect and sentiment analysis together to model 736 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 736–741, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics sentiments towards different aspects. (Hu and Liu, 2004; Ding et al., 2008) adopted lexicon-based approaches to detect the sentiment on different aspects. In addition, (Boiy and Moens, 2009; Jiang et al., 2011) explored the work to determine whether the reviews contain the aspect information. Unlike the above study, (Xiang et al., 2014) split the data into multiple subsets based on category distributions and then built seperate classifier for each category. Following previous work (Brun et al., 2014; Brychcin et al., 2014; Castellucci et al., 2014; Kiritchenko et al., 2014), a rich set of features are adopted in this work: linguistic features (e.g</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 168–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Jiang</author>
<author>Mo Yu</author>
<author>Ming Zhou</author>
<author>Xiaohua Liu</author>
<author>Tiejun Zhao</author>
</authors>
<title>Target-dependent Twitter sentiment classification.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the ACL: Human Language Technologies-Volume</booktitle>
<volume>1</volume>
<pages>151--160</pages>
<contexts>
<context position="3990" citStr="Jiang et al., 2011" startWordPosition="610" endWordPosition="613">anavan et al., 2009; He et al., 2012; Mei et al., 2007) used topic or category information. (Lin and He, 2009; Jo and Oh, 2011) presented LDA-based models, which incorporate aspect and sentiment analysis together to model 736 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 736–741, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics sentiments towards different aspects. (Hu and Liu, 2004; Ding et al., 2008) adopted lexicon-based approaches to detect the sentiment on different aspects. In addition, (Boiy and Moens, 2009; Jiang et al., 2011) explored the work to determine whether the reviews contain the aspect information. Unlike the above study, (Xiang et al., 2014) split the data into multiple subsets based on category distributions and then built seperate classifier for each category. Following previous work (Brun et al., 2014; Brychcin et al., 2014; Castellucci et al., 2014; Kiritchenko et al., 2014), a rich set of features are adopted in this work: linguistic features (e.g., ngrams, grammatical relationship, POS, negations), sentiment lexicon features (e.g., MPQA, General Inquirer, SentiWordNet, etc) and domain specific feat</context>
</contexts>
<marker>Jiang, Yu, Zhou, Liu, Zhao, 2011</marker>
<rawString>Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun Zhao. 2011. Target-dependent Twitter sentiment classification. In Proceedings of the 49th Annual Meeting of the ACL: Human Language Technologies-Volume 1, pages 151–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yohan Jo</author>
<author>Alice H Oh</author>
</authors>
<title>Aspect and sentiment unification model for online review analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the 4th ACM international conference on Web search and data mining,</booktitle>
<pages>815--824</pages>
<contexts>
<context position="3498" citStr="Jo and Oh, 2011" startWordPosition="539" endWordPosition="542">pairs and OTE are provided. Comparing with laptop reviews, the restaurant reviews provide the annotated surface words adhering to sentiment. Therefore we speculate that the performance in restaurant domain would be much better than that of laptop domain. The study of aspect based sentiment analysis focuses on discovering the opinions or sentiments expressed by a customer on different categories or aspects (Liu, 2012). In recent years, it has drawn a lot of attentions. For example, (Branavan et al., 2009; He et al., 2012; Mei et al., 2007) used topic or category information. (Lin and He, 2009; Jo and Oh, 2011) presented LDA-based models, which incorporate aspect and sentiment analysis together to model 736 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 736–741, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics sentiments towards different aspects. (Hu and Liu, 2004; Ding et al., 2008) adopted lexicon-based approaches to detect the sentiment on different aspects. In addition, (Boiy and Moens, 2009; Jiang et al., 2011) explored the work to determine whether the reviews contain the aspect information. Unlike the above study, </context>
</contexts>
<marker>Jo, Oh, 2011</marker>
<rawString>Yohan Jo and Alice H Oh. 2011. Aspect and sentiment unification model for online review analysis. In Proceedings of the 4th ACM international conference on Web search and data mining, pages 815–824.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Svetlana Kiritchenko</author>
<author>Xiaodan Zhu</author>
<author>Colin Cherry</author>
<author>Saif M Mohammad</author>
</authors>
<title>NRC-Canada-2014: Detecting aspects and sentiment in customer reviews. SemEval</title>
<date>2014</date>
<pages>437</pages>
<contexts>
<context position="4360" citStr="Kiritchenko et al., 2014" startWordPosition="667" endWordPosition="671">15 Association for Computational Linguistics sentiments towards different aspects. (Hu and Liu, 2004; Ding et al., 2008) adopted lexicon-based approaches to detect the sentiment on different aspects. In addition, (Boiy and Moens, 2009; Jiang et al., 2011) explored the work to determine whether the reviews contain the aspect information. Unlike the above study, (Xiang et al., 2014) split the data into multiple subsets based on category distributions and then built seperate classifier for each category. Following previous work (Brun et al., 2014; Brychcin et al., 2014; Castellucci et al., 2014; Kiritchenko et al., 2014), a rich set of features are adopted in this work: linguistic features (e.g., ngrams, grammatical relationship, POS, negations), sentiment lexicon features (e.g., MPQA, General Inquirer, SentiWordNet, etc) and domain specific features (e.g., in-domain word list, punctuation, etc). We also performed a series of experiments to compare supervised machine learning algorithms with different parameters and to choose effective feature subsets for performance of classification. The rest of this paper is structured as follows. In Section 2, we describe our system in details, including preprocessing, fe</context>
<context position="7170" citStr="Kiritchenko et al., 2014" startWordPosition="1119" endWordPosition="1122"> to select out only relevant words from three sequential sentences in terms of the corresponding E-A pair. Unlike the OTE words which already exist in reviews, most E-A pairs are not present in the sentence. Thus, for each E-A pair, we first extracted target words having top tfidf scores from three sequential sentences and then chose the relevant words from parse tree. Specifically, in laptop domain, the sentences contain only E-A pairs, so we selected two words having the highest tfidf scores from three sequential sentences in terms of corresponding E-A pair as its target words. Inspired by (Kiritchenko et al., 2014), for each target word in E-A pair, we selected the words from parse tree with distance d =&lt; 2 as relevant words in terms of this E-A pair. After that, for all words in target words, we combined all their relevant words as pending words to extract features for sentiment analysis. While in restaurant domain since the sentences contain both E-A pair and opinion target expressions (OTE), we only combined the words in OTE with two words mentioned before as target words and chose their relevant words as pending words. For each domain, each participant can submit two runs: (1) constrained: only the </context>
</contexts>
<marker>Kiritchenko, Zhu, Cherry, Mohammad, 2014</marker>
<rawString>Svetlana Kiritchenko, Xiaodan Zhu, Colin Cherry, and Saif M Mohammad. 2014. NRC-Canada-2014: Detecting aspects and sentiment in customer reviews. SemEval 2014, page 437.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenghua Lin</author>
<author>Yulan He</author>
</authors>
<title>Joint sentiment/topic model for sentiment analysis.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th ACM conference on Information and knowledge management,</booktitle>
<pages>375--384</pages>
<contexts>
<context position="3480" citStr="Lin and He, 2009" startWordPosition="535" endWordPosition="538"> domain, both E-A pairs and OTE are provided. Comparing with laptop reviews, the restaurant reviews provide the annotated surface words adhering to sentiment. Therefore we speculate that the performance in restaurant domain would be much better than that of laptop domain. The study of aspect based sentiment analysis focuses on discovering the opinions or sentiments expressed by a customer on different categories or aspects (Liu, 2012). In recent years, it has drawn a lot of attentions. For example, (Branavan et al., 2009; He et al., 2012; Mei et al., 2007) used topic or category information. (Lin and He, 2009; Jo and Oh, 2011) presented LDA-based models, which incorporate aspect and sentiment analysis together to model 736 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 736–741, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics sentiments towards different aspects. (Hu and Liu, 2004; Ding et al., 2008) adopted lexicon-based approaches to detect the sentiment on different aspects. In addition, (Boiy and Moens, 2009; Jiang et al., 2011) explored the work to determine whether the reviews contain the aspect information. Unlike</context>
</contexts>
<marker>Lin, He, 2009</marker>
<rawString>Chenghua Lin and Yulan He. 2009. Joint sentiment/topic model for sentiment analysis. In Proceedings of the 18th ACM conference on Information and knowledge management, pages 375–384.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment analysis and opinion mining: synthesis lectures on human language technologies.</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="3302" citStr="Liu, 2012" startWordPosition="503" endWordPosition="504">e are two domains in this sentiment analysis subtask, i.e, laptop and restaurant. In laptop domain, only E-A pairs are annotated and provided in reviews while in restaurant domain, both E-A pairs and OTE are provided. Comparing with laptop reviews, the restaurant reviews provide the annotated surface words adhering to sentiment. Therefore we speculate that the performance in restaurant domain would be much better than that of laptop domain. The study of aspect based sentiment analysis focuses on discovering the opinions or sentiments expressed by a customer on different categories or aspects (Liu, 2012). In recent years, it has drawn a lot of attentions. For example, (Branavan et al., 2009; He et al., 2012; Mei et al., 2007) used topic or category information. (Lin and He, 2009; Jo and Oh, 2011) presented LDA-based models, which incorporate aspect and sentiment analysis together to model 736 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 736–741, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics sentiments towards different aspects. (Hu and Liu, 2004; Ding et al., 2008) adopted lexicon-based approaches to detect the</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment analysis and opinion mining: synthesis lectures on human language technologies. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>Xu Ling</author>
<author>Matthew Wondra</author>
<author>Hang Su</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Topic sentiment mixture: modeling facets and opinions in weblogs.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th international conference on WWW,</booktitle>
<pages>171--180</pages>
<contexts>
<context position="3426" citStr="Mei et al., 2007" startWordPosition="525" endWordPosition="528">e annotated and provided in reviews while in restaurant domain, both E-A pairs and OTE are provided. Comparing with laptop reviews, the restaurant reviews provide the annotated surface words adhering to sentiment. Therefore we speculate that the performance in restaurant domain would be much better than that of laptop domain. The study of aspect based sentiment analysis focuses on discovering the opinions or sentiments expressed by a customer on different categories or aspects (Liu, 2012). In recent years, it has drawn a lot of attentions. For example, (Branavan et al., 2009; He et al., 2012; Mei et al., 2007) used topic or category information. (Lin and He, 2009; Jo and Oh, 2011) presented LDA-based models, which incorporate aspect and sentiment analysis together to model 736 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 736–741, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics sentiments towards different aspects. (Hu and Liu, 2004; Ding et al., 2008) adopted lexicon-based approaches to detect the sentiment on different aspects. In addition, (Boiy and Moens, 2009; Jiang et al., 2011) explored the work to determine whet</context>
</contexts>
<marker>Mei, Ling, Wondra, Su, Zhai, 2007</marker>
<rawString>Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, and ChengXiang Zhai. 2007. Topic sentiment mixture: modeling facets and opinions in weblogs. In Proceedings of the 16th international conference on WWW, pages 171–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Svetlana Kiritchenko</author>
<author>Xiaodan Zhu</author>
</authors>
<title>NRC-Canada: Building the state-of-theart in sentiment analysis of tweets.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>321--327</pages>
<location>Atlanta, Georgia, USA,</location>
<contexts>
<context position="11268" citStr="Mohammad et al., 2013" startWordPosition="1763" endWordPosition="1767">ords with 6 types of label: strong/weak positive, strong/weak negative, both (having positive and negative sentiment) and neutral. Then we transformed these above nominal labels to 1, 0.5, −1, −0.5, 0, 0 respectively. - SentiWordNet8: The sentiment scores of each item in SentiWordNet is represented as a tuple i.e., positivity and negativity.We use the difference between positive and negative score as its sentiment score. When locating the corresponding item, we retrieved the word lemma and selected the first term in searched results according to its POS tag. - NRC Hashtag Sentiment Lexicon9: (Mohammad et al., 2013) collected two tweet sets containing hashtags and used the sentiment of its hashtags as the sentiment label for each tweet. In this experiment, we used both unigrams and bigrams sentiment lexicons. - NRC Sentiment140 Lexicon10: This lexicon is generated from a collection of 1.6 million tweets with positive or negative emoticons and contains about 62, 000 unigrams, 677, 000 bigrams and 480, 000 non-contiguous pairs. We used unigrams and bigrams. Linguistic Features - Word n-grams: We converted all pending words into lowercase and removed low frequency terms (G 5). After that, we extracted wordl</context>
</contexts>
<marker>Mohammad, Kiritchenko, Zhu, 2013</marker>
<rawString>Saif Mohammad, Svetlana Kiritchenko, and Xiaodan Zhu. 2013. NRC-Canada: Building the state-of-theart in sentiment analysis of tweets. In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 321–327, Atlanta, Georgia, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Pak</author>
<author>Patrick Paroubek</author>
</authors>
<title>Twitter as a corpus for sentiment analysis and opinion mining.</title>
<date>2010</date>
<booktitle>In LREC,</booktitle>
<pages>1320--1326</pages>
<contexts>
<context position="12176" citStr="Pak and Paroubek, 2010" startWordPosition="1879" endWordPosition="1882">n tweets with positive or negative emoticons and contains about 62, 000 unigrams, 677, 000 bigrams and 480, 000 non-contiguous pairs. We used unigrams and bigrams. Linguistic Features - Word n-grams: We converted all pending words into lowercase and removed low frequency terms (G 5). After that, we extracted wordlevel unigram and bigrams. 6http://anthology.aclweb.org//S/S13/S13-2.pdf#page=444 7http://mpqa.cs.pitt.edu/ 8http://sentiwordnet.isti.cnr.it/ 9http://www.umiacs.umd.edu/saif/WebDocs/NRCHashtag-Sentiment-Lexicon-v0.1.zip 10http://help.sentiment140.com/for-students/ 738 - POS Features: (Pak and Paroubek, 2010) found that subjective texts often contain more adjectives or adverbs and less nouns than objective texts. Therefore, the POS tags are important features for sentiment analysis. We recorded the number of nouns (the corresponding POS tags are NN, NNP, NNS and NNPS), verbs (VB, VBD, VBG, VBN, VBP and VBZ), adjectives (JJ, JJR and JJS) and adverbs (RB, RBR and RBS) in pending words. - Grammatical Relationship: The grammatical relationship usually expresses the role of words in phrase and contains certain semantic information (Zhao et al., 2014). We obtained dependency information from parse tree </context>
</contexts>
<marker>Pak, Paroubek, 2010</marker>
<rawString>Alexander Pak and Patrick Paroubek. 2010. Twitter as a corpus for sentiment analysis and opinion mining. In LREC, pages 1320–1326.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Xiang</author>
<author>Liang Zhou</author>
<author>Thomson Reuters</author>
</authors>
<title>Improving Twitter sentiment analysis with topic-based mixture modeling and semi-supervised training.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the ACL (Short Papers),</booktitle>
<pages>434--439</pages>
<contexts>
<context position="4118" citStr="Xiang et al., 2014" startWordPosition="630" endWordPosition="633">presented LDA-based models, which incorporate aspect and sentiment analysis together to model 736 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 736–741, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics sentiments towards different aspects. (Hu and Liu, 2004; Ding et al., 2008) adopted lexicon-based approaches to detect the sentiment on different aspects. In addition, (Boiy and Moens, 2009; Jiang et al., 2011) explored the work to determine whether the reviews contain the aspect information. Unlike the above study, (Xiang et al., 2014) split the data into multiple subsets based on category distributions and then built seperate classifier for each category. Following previous work (Brun et al., 2014; Brychcin et al., 2014; Castellucci et al., 2014; Kiritchenko et al., 2014), a rich set of features are adopted in this work: linguistic features (e.g., ngrams, grammatical relationship, POS, negations), sentiment lexicon features (e.g., MPQA, General Inquirer, SentiWordNet, etc) and domain specific features (e.g., in-domain word list, punctuation, etc). We also performed a series of experiments to compare supervised machine lear</context>
</contexts>
<marker>Xiang, Zhou, Reuters, 2014</marker>
<rawString>Bing Xiang, Liang Zhou, and Thomson Reuters. 2014. Improving Twitter sentiment analysis with topic-based mixture modeling and semi-supervised training. In Proceedings of the 52nd Annual Meeting of the ACL (Short Papers), pages 434–439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiang Zhao</author>
<author>Tian Tian Zhu</author>
<author>Man Lan</author>
</authors>
<title>ECNU: One stone two birds: Ensemble of heterogenous measures for semantic relatedness and textual entailment. SemEval</title>
<date>2014</date>
<pages>271</pages>
<contexts>
<context position="12723" citStr="Zhao et al., 2014" startWordPosition="1970" endWordPosition="1973">iment140.com/for-students/ 738 - POS Features: (Pak and Paroubek, 2010) found that subjective texts often contain more adjectives or adverbs and less nouns than objective texts. Therefore, the POS tags are important features for sentiment analysis. We recorded the number of nouns (the corresponding POS tags are NN, NNP, NNS and NNPS), verbs (VB, VBD, VBG, VBN, VBP and VBZ), adjectives (JJ, JJR and JJS) and adverbs (RB, RBR and RBS) in pending words. - Grammatical Relationship: The grammatical relationship usually expresses the role of words in phrase and contains certain semantic information (Zhao et al., 2014). We obtained dependency information from parse tree and the grammatical information is denoted as a tuple, e.g., amod(surprises, great), where amod represents the dependency relationship between surprises and great (here great is a modifier). We presented two types of features: the relationship with the first word in tuple as Rel1 and with the second word as Rel2. The size of each feature set is approximately 150. - Negation Features: We collected 29 negations from Internet and designed this binary feature to record if there is negation in pending words. Domain Specifical Features - In-domain</context>
</contexts>
<marker>Zhao, Zhu, Lan, 2014</marker>
<rawString>Jiang Zhao, Tian Tian Zhu, and Man Lan. 2014. ECNU: One stone two birds: Ensemble of heterogenous measures for semantic relatedness and textual entailment. SemEval 2014, page 271.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>