<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.727857">
Wishful Thinking
Finding suggestions and ‘buy’ wishes from product reviews
</title>
<author confidence="0.649285">
J. Ramanand Krishna Bhavsar Niranjan Pedanekar
</author>
<affiliation confidence="0.359072666666667">
BFS Innovations BFS Innovations BFS Innovations
Cognizant Technology Solutions Cognizant Technology Solutions Cognizant Technology Solutions
Pune, India Pune, India Pune, India
</affiliation>
<email confidence="0.6173">
ramanand.janardhanan krishna.bhavsar niranjan.pedanekar
@cognizant.com @cognizant.com @cognizant.com
</email>
<sectionHeader confidence="0.995611" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998996">
This paper describes methods aimed at solv-
ing the novel problem of automatically dis-
covering ‘wishes’ from (English) documents
such as reviews or customer surveys. These
wishes are sentences in which authors make
suggestions (especially for improvements)
about a product or service or show intentions
to purchase a product or service. Such
‘wishes’ are of great use to product managers
and sales personnel, and supplement the area
of sentiment analysis by providing insights
into the minds of consumers. We describe
rules that can help detect these ‘wishes’ from
text. We evaluate these methods on texts from
the electronic and banking industries.
</bodyText>
<sectionHeader confidence="0.998882" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999568933333333">
Various products and business services are used by
millions of customers each day. For the makers of
these products &amp; services, studying these customer
experiences is critical to understanding customer
satisfaction and making decisions about possible
improvements to the products. Thanks to the ad-
vent of weblogs, online consumer forums, and
product comparison sites, consumers are actively
expressing their opinions online. Most of these
reviews are now available on the web, usually at
little or no cost. Moreover, these are available for a
variety of domains, such as financial services, tele-
com services, consumer goods etc.
Automated analysis of opinions using such re-
views could provide a cheaper and faster means of
</bodyText>
<page confidence="0.973782">
54
</page>
<bodyText confidence="0.999152352941177">
obtaining a sense of such customer opinions, thus
supplementing more traditional survey methods. In
addition, automated analysis can significantly
shorten the time taken to find insights into the cus-
tomer&apos;s mind and actions.
Sentiment analysis of texts such as product re-
views, call center notes, and customer surveys
aims to automatically infer opinions expressed by
people with regards to various topics of interest. A
sentiment analysis exercise classifies the overall
opinion of a review document into positive, neu-
tral, or negative classes. It may also identify senti-
ments at a finer granularity, i.e. recognizing the
mix of opinions about the topic(s) expressed in the
text. However, industry analysts (Strickland, 2009)
report some common problems with the results of
these exercises:
</bodyText>
<listItem confidence="0.751662777777778">
1. The results (usually numerical scores split
across positive, negative, neutral classes) are hard
to meaningfully interpret.
2. These results are more useful to certain
roles and domains. Brand, reputation, and service
managers in media and retail industries find senti-
ment analysis more useful than product managers
or sales teams in various industries.
3. The results do not ‘indicate user action’
</listItem>
<bodyText confidence="0.89744875">
i.e. opinions do not help identify a future action of
the author based on the comments. An example of
this is: does the consumer indicate that he intends
to stop using a service after a negative experience?
4. The reader of the report often asks “what
do I do next?” i.e. the results are not always ‘ac-
tionable’. There is a gap between understanding
the results and taking an appropriate action.
</bodyText>
<note confidence="0.9842525">
Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 54–61,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999678307692308">
This has led to interest in identifying aspects in-
directly related to sentiment analysis, such as gaug-
ing possible loss of clientele or tapping into desires
to purchase a product. Many of these methods at-
tempt to identify ‘user intent’.
In this paper, we propose rule-based methods to
identify two kinds of ‘wishes’ – one, the desire to
see improvement in a product, and the other to
purchase a product. These methods have been de-
signed &amp; tested using a variety of corpora contain-
ing product reviews, customer surveys, and
comments from consumer forums in domains such
as electronics and retail banking. From our read-
ing, there has been only one published account of
identifying ‘wishes’ (including suggestions) and no
known work on identifying purchasing wishes. We
hope to build approaches towards more compre-
hensive identification of such content.
The paper is organized as follows. We begin by
discussing some of the work related to this upcom-
ing area. Section 3 details our characterization of
wishes. Section 4 describes the corpora used for
these methods. We discuss our proposed algo-
rithms and rules in Sections 5 &amp; 6, including a dis-
cussion of the results. Finally, we wrap up with our
conclusions and directions for future work.
</bodyText>
<sectionHeader confidence="0.999732" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999886036363637">
The principal context of our work is in the area
of sentiment analysis, which is now a widely re-
searched area because of the abundance of com-
mentaries from weblogs, review sites, and social
networking sites. In particular, we are interested in
the analysis of product reviews (Dave et al., 2003;
Hu and Liu, 2004), as well as its application to
more service-oriented industries such as banks.
We have built a sentiment analyzer that can ana-
lyze product and service reviews from a variety of
domains. This also accepts social networking
commentaries, customer surveys and news articles.
The implementation follows a lexicon-based ap-
proach, similar to the one described in Ding et al.
(2008), using lexicons for product attributes and
opinion words for basic sentiment analysis.
Our work is not a sub-task of sentiment analysis,
but supplements the area. A similar example of a
classification task that works on the sentence level
and is also related to sentiment analysis is Jindal
and Liu (2006) which aims to identify comparisons
between two entities in texts such as product re-
views.
Goldberg et al. (2009) introduced the novel task
of identifying wishes. This used a “WISH” corpus
derived from a web site that collected New Year’s
wishes. Goldberg et al. (2009) studied the corpus
in detail, describing the nature, geography, and
scope of topics found in them. The paper also
looked at building ‘wish detectors’, which were
applied on a corpus of political comments and
product reviews. A mix of manual templates and
SVM-based text classifiers were used. A method to
identify more templates was also discussed.
Our task, though similar to the above problem,
has some novel features. In particular, there are
two significant differences from Goldberg et al.
(2009). We are interested in two specific kinds of
wishes: sentences that make suggestions about ex-
isting products, and sentences that indicate the
writer is interested in purchasing a product. (These
are described in detail in Section 3.) Secondly, our
interest is limited to product reviews, and not to
social or political wishes.
In Requirements Engineering, some methods of
analyzing requirement documents have used lin-
guistic techniques to understand and correlate re-
quirements. These are somewhat related to our
task, aiming to detect desired features in the pro-
ject to be executed. och Dag et al. (2005) has some
useful discussions on this topic.
Kröll and Strohmaier (2009) study the idea of
Intent Analysis, noting a taxonomy of Human In-
tentions, which could be useful in future discus-
sions on the topic.
</bodyText>
<sectionHeader confidence="0.900035" genericHeader="method">
3 What are Wishes
</sectionHeader>
<subsectionHeader confidence="0.999698">
3.1 Defining Wishes
</subsectionHeader>
<bodyText confidence="0.99903125">
A dictionary definition (Goldberg et al. (2009)) of
a “wish” is “a desire or hope for something to
happen.” Goldberg et al. (2009) discuss different
types of wishes, ranging from political to social to
business. In our case, we limit our interest to
comments about products and services. In particu-
lar, we are interested in two specific kinds of wish-
es.
</bodyText>
<page confidence="0.997107">
55
</page>
<subsectionHeader confidence="0.999731">
3.2 Suggestion Wishes
</subsectionHeader>
<bodyText confidence="0.996928166666667">
These are sentences where the commenter wishes
for a change in an existing product or service.
These range from specific requests for new product
features and changes in existing behaviour, or an
indication that the user is unhappy with the current
experience. Examples1:
</bodyText>
<listItem confidence="0.9871195">
1. I&apos;d love for the iPod shuffle to also mirror
as a pedometer.
2. It would be much better if they had more
ATMs in my area.
</listItem>
<bodyText confidence="0.9992325">
We also include sentences that do not fully
elaborate on the required change, but could serve
as a pointer to a nearby region that may contain the
required desire. Examples of these:
</bodyText>
<listItem confidence="0.703039">
1. I wish they’d do this.
2. My wish list would be as follows:
</listItem>
<bodyText confidence="0.9994822">
It is important to note the difference between
our definition of wishes and that in Goldberg et al.
(2009). That study seeks to discover any sentence
expressing any desire. For instance, Goldberg et al.
(2009) marks the following as wishes:
</bodyText>
<listItem confidence="0.975319333333333">
1. I shouldn’t have been cheap, should have
bought a Toshiba.
2. hope to get my refund in a timely manner.
</listItem>
<bodyText confidence="0.936175333333333">
In our approach, we do not treat these as wishes
since they do not suggest any improvements.
In some cases, improvements could be inferred
from a negative opinion about the product. The
implication is that the customer would be happier
if the problem could be fixed. Examples:
</bodyText>
<listItem confidence="0.8069715">
1. “My only gripe is the small size of the
camera body” which implies “I wish the
camera was bigger”.
2. “The rubber flap that covers the usb port
seems flimsy” which implies “I wish the
rubber flap was more robust”.
</listItem>
<bodyText confidence="0.978416">
We do not address such implicit wishes.
</bodyText>
<subsectionHeader confidence="0.999878">
3.3 Purchasing Wishes
</subsectionHeader>
<bodyText confidence="0.785122833333333">
These are sentences where the author explicitly
expresses the desire to purchase a product. In some
cases, a preferred price range is also indicated.
Examples:
1. I have a Canon digital rebel xt, I am look-
ing for a lens that will take sports actions foot-
ball shots at night.
2. I want to purchase a cell phone range 12-
15000/-... please suggest me some good and
stylish phones?
3. We are also thinking of buying a condo in
a few months...
</bodyText>
<sectionHeader confidence="0.627316" genericHeader="method">
4 Corpora for Design and Evaluation
</sectionHeader>
<subsectionHeader confidence="0.880927">
4.1 Suggestion Wishes
</subsectionHeader>
<bodyText confidence="0.90939915625">
As part of building and testing our in-house senti-
ment analyzer, we collected a variety of texts from
different sources such as popular consumer review
sites (such as Epinions.com and MouthShut.com)
and weblogs. These primarily belonged to the do-
mains of electronics and retail banking. Of these,
we chose reviews about the Apple iPod and a col-
lection of banking reviews about five leading US
banks. We also used customer surveys conducted
for two products of a financial services company2.
The sizes of the corpora are summarized in Table
1.
Some observations about these texts:
1. The texts are in American or British English
and are largely well-formed.
2. They cover both reviews of products and de-
scriptions of customer service.
3. The customer surveys consisted of sections
for positives and negatives feedback, with an op-
tional ‘suggestions’ section.
4. Wish sentences in the reviews were infre-
quent (on average, less than 1% of the total sen-
tences). The surveys had a much larger presence of
wishes (about 5% on average).
In addition, Goldberg et al. (2009) has made
available a WISH corpus, which is a sample of
7614 sentences consisting of sentences from politi-
cal discussions and product reviews. Since we are
only interested in the latter, we evaluated our algo-
rithm only on the product review sentences (1235
in number). 3% (41 sentences3) of these have been
labeled as wishes.
</bodyText>
<footnote confidence="0.9899998">
2 Anonymous for confidentiality reasons
3 In the WISH corpus, 149 (12%) are marked as wishes; how-
ever we only chose those wishes that suggest improvements.
1 All sentences are taken from review sites such as epin-
ions.com
</footnote>
<page confidence="0.990552">
56
</page>
<bodyText confidence="0.999576333333333">
In a pre-processing step, individual sentences in
the corpora were identified using GATE’s (Cun-
ningham, 2002) sentence splitter.
</bodyText>
<subsectionHeader confidence="0.998458">
4.2 Purchasing Wishes
</subsectionHeader>
<bodyText confidence="0.9995416">
Similar to our collection of sentences for sugges-
tions, we collected texts from review sites and con-
sumer forums (such as Alibaba.com and Yahoo!
Answers) that not only reviewed products and
shared complaints but also allowed users to post
requests for purchases.
The corpus consisted of 1579 sentences about
the following products: Apple iPhone, Cameras,
Desktop PCs, and a mix of Credit Cards from four
leading Indian and American banks.
</bodyText>
<sectionHeader confidence="0.988871" genericHeader="method">
5 Finding Suggestions
</sectionHeader>
<subsectionHeader confidence="0.928404">
5.1 Approach
</subsectionHeader>
<bodyText confidence="0.998714">
The input to our system consists of the following:
</bodyText>
<listItem confidence="0.963406111111111">
1. Datasets containing sentences.
2. ATTRLEX4: A lexicon of product attributes
for each of the domains. (e.g. the iPod attributes
were words like ‘battery’, ‘interface’ etc.)
3. POSLEX: A lexicon of positive opinions
(words such as ‘good’, ‘better’, ‘fast’).
4. NEGLEX: A lexicon of negation words (these
are words that invert the opinion of a sentence.
e.g: ‘not’, ‘wouldn’t’)
</listItem>
<bodyText confidence="0.999904111111111">
We began by manually classifying sentences in
samples from each of the corpora as ‘wishes’ or
‘non-wishes’. We then looked for common phrases
and words across all these wishes to derive patterns
and rules.
Initial analysis led to some proto-rules. These
rules were then refined by using further analysis
and in some cases, decision trees. The rules are
grouped as follows.
</bodyText>
<listItem confidence="0.6312725">
1. It would be a much more valuable service if they
would fix this flaw.
2. It might be nice if one could drag-and-drop mu-
sic files and have the iPod reconstruct its index on-
</listItem>
<figure confidence="0.902748444444444">
the-fly.
3. I would prefer the unit to have a simple on off
switch.
This led to the following rules:
a. modal verb + auxiliary verb + positive opinion
word
Match sentences which contain the pattern:
&lt;modal verb&gt; &lt;auxiliary verb&gt; {window of size 3}
&lt;positive opinion word&gt;
</figure>
<bodyText confidence="0.815763764705882">
Where
Modal verb belongs to {may, might, could,
would, will, should}
Auxiliary verb belongs to {be, have been}
Positive Opinion word belongs to
POSLEX
The positive word should appear to the right of the
modal verb in a pre-defined window size (usually 3
to 5).
b. modal verb + preference verb
Match sentences which contain the pattern:
&lt;modal verb&gt; {window of size 3} &lt;preference verb&gt;
Where
Modal verb belongs to {may, might, would,
will}
Preference verb belongs to {love, like, pre-
fer, suggest}
</bodyText>
<sectionHeader confidence="0.283091" genericHeader="method">
c. Other rules
</sectionHeader>
<subsectionHeader confidence="0.24525">
Match sentences containing:
</subsectionHeader>
<construct confidence="0.657402666666667">
“should be able” or
“should come with” or
“could come with”
</construct>
<subsubsectionHeader confidence="0.865299">
5.1.1 Rules based on modal verbs
</subsubsectionHeader>
<bodyText confidence="0.980112285714286">
A majority of the wishes had pivotal phrases in-
volving modal verbs such as “would”, “could”,
“should” etc. Examples:
4 These lexicons were built by semi-automated means using
components built for our in-house sentiment analyzer which
help detect opinions and attributes for a domain from related
texts
</bodyText>
<subsubsectionHeader confidence="0.940752">
5.1.2 The “needs to” rule
</subsubsectionHeader>
<bodyText confidence="0.997506">
Sentences containing the phrase “needs to” are
candidate wishes, such as in the examples:
</bodyText>
<listItem confidence="0.9619022">
1. Apple needs to step it up and get better longer
lasting batteries.
2. Their customer service representatives need to
be educated in assisting customers.
3. need to be able to configure the boxes.
</listItem>
<page confidence="0.997863">
57
</page>
<bodyText confidence="0.9992105">
For this pattern, we created a decision tree model
with the following features:
</bodyText>
<listItem confidence="0.953868611111111">
1. Presence of negation word to the left of “needs
to”
2. Presence of a ‘product attribute’ word to the left
3. Whether the sentence is interrogative
4. Subject of the sentence from the list: {I, you, s/he,
we, this, that, those, it, they, one, someone, somebody,
something}
Based on analysis and the combination suggested
by the decision tree experiments, we formulated
rules. Some of these rules are as follows:
1. Interrogative sentences or those with a negation
word to the left of “need to” are not wishes.
2. If the product attribute is present (usually as the
subject), the sentence is a wish.
3. If the subject of the sentence is one of “this, that,
these”, the sentence is likely to be a wish. When the
subject is one of “I, you, one”, the sentence is not a
wish.
</listItem>
<subsubsectionHeader confidence="0.749752">
5.1.3 Other rules
</subsubsectionHeader>
<bodyText confidence="0.900559">
Sentences containing the patterns:
</bodyText>
<listItem confidence="0.988942">
1. “I wish”: along with filters such as the subject
(“they, you, product”) etc. can be matched as
wishes.
2. “hopefully” or “I hope”
3. “should be able to” or “should come with”
</listItem>
<bodyText confidence="0.970490666666667">
These rules match very infrequently in the dataset.
A summary of rule accuracy can be seen in Table
3.
</bodyText>
<subsectionHeader confidence="0.8038375">
5.2 Results
5.2.1 Precision of Rules
</subsectionHeader>
<table confidence="0.994009">
Type Total No. of No. of Precision
sen- predicted correct
tences wishes wishes
iPod 21147 90 53 58.89%
Banking 15408 75 23 30.67%
Product 1 4240 224 187 83.48%
Product 2 6850 355 284 80.00%
WISH 1236 28 16 57.14%
corpus
</table>
<tableCaption confidence="0.9571565">
Table 1 Precision of wish identification for various data
sets
</tableCaption>
<subsectionHeader confidence="0.934947">
5.2.2 Recall of Rules
</subsectionHeader>
<bodyText confidence="0.9743725">
Recall was calculated on a 10% random sample
from each data set, except in case of the WISH
corpus, where all sentences were taken into ac-
count.
</bodyText>
<table confidence="0.986157">
Type No. of No. of actual Recall
correctly wishes in the
predicted sample
wishes in
the sample
iPod 7 14 50.0%
Banking 3 5 60.0%
Product 1 24 45 53.3%
Product 2 28 70 40.0%
WISH corpus 16 41 39.0%
</table>
<tableCaption confidence="0.99859">
Table 2 Recall of wish identification
</tableCaption>
<subsectionHeader confidence="0.76267">
5.2.3 Rule Analysis
</subsectionHeader>
<bodyText confidence="0.99143225">
This table analyses performance of the top 3 most fre-
quently matched rules. For each type of data, the first
row shows the number of wishes predicted by each rule.
The succeeding row shows the corresponding precision.
</bodyText>
<table confidence="0.997303846153846">
Type/Rule Modal, aux, Modal, “Needs Others
positive opinion preference to”
iPod 24 8 7 14
57% 53% 43% 82%
Banking 14 17 7 2
37% 85.0% 50% 28.5%
Product 1 89 56 25 17
87% 83.6% 71% 85%
Product 2 146 25 50 30
90% 71.4% 71% 90.9%
WISH 7 2 3 4
Corpus
63.6% 50% 50% 57.1%
</table>
<tableCaption confidence="0.992819">
Table 3 Rule Analysis
</tableCaption>
<subsectionHeader confidence="0.999258">
5.3 Comments on Results
</subsectionHeader>
<bodyText confidence="0.99985925">
Wishes occur very infrequently in reviews, where
authors may or may not choose to talk about im-
provements. Surveys produced more wishes be-
cause of the design and objectives of the survey.
Also, the language used in suggesting improve-
ments was more consistent across authors, making
it easier to catch them. Wishes could be made
about existing product attributes, but several wish-
</bodyText>
<page confidence="0.995679">
58
</page>
<bodyText confidence="0.976970558823529">
wishes were about newer aspects. This could help
product managers envisage features that their cus-
tomers are asking for.
Experiments on the banking reviews showed the
worst results. The dataset had very few wishes and
the language used was usually part of a narrative,
which threw up a lot of false positives. It could
also be that the nature of the collected dataset was
such that it did not contain sufficient number of
wishes.
Some of the false positives were difficult to
avoid. Take an example such as:
I wish it will be a better year.
Though it is a ‘wish’ in general, this does not fit
our definition of product suggestion though it fits a
rule well. More semantic or contextual analysis
may be required in this case. We do not filter out
sentences that do not refer to already published
product attributes since authors may be talking
about adding completely new features, such as in
the case:
I wish it will be in magazine form next year.
Of the rules, the first rule (modal + auxiliary +
positive opinion word) had the highest contribution
to make. The second rule was more consistent in
detecting correct wishes. Incidentally, the “needs
to” rule for banking reviews outperforms the re-
sults for iPod sentences – the only time this hap-
pens.
Different patterns may be applicable for differ-
ent domains and types of texts. A possible ap-
proach to improving results would be to have a
‘rule selection’ phase were rules that fall below a
certain threshold are discarded.
</bodyText>
<sectionHeader confidence="0.977104" genericHeader="method">
6 Finding Buy Wishes
</sectionHeader>
<subsectionHeader confidence="0.99751">
6.1 Approach
6.2 Results
</subsectionHeader>
<bodyText confidence="0.999300666666667">
We derived proto-rules and refined them by
manual analysis and decision trees. The pattern of
each rule is:
</bodyText>
<figure confidence="0.887364037037037">
...&lt;rule phrase&gt; &lt;common sub-rule&gt;...
If a sentence contains such a pattern, it is
deemed to be a buy wish.
To begin, we describe a common sub-rule that is
used with all rules.
6.1.1 Buy Identification common sub-rule
This depends on the following three aspects:
a. A ‘buy verb’ from among {find, buy, purchase,
get, acquire} should be present
b. Absence of a negation word (from NEGLEX)
to the left of rule phrase
c. Subjects:
The subject should not be one of these:
{you, one, they, someone, those}
The subject could be one of these:
{I, we, me}
6.1.2 Rule phrases
Rule phrases are one of the following
1. “want to”
2. “desire to”
3. “would like to”
4. “where can/do I”
5. “place to”
6. “going to”
7. “looking to/for”
8. “searching to/for”
9. “interested in”
</figure>
<bodyText confidence="0.982153">
Of these, in rules involving phrases 7, 8, and 9, we
also check if there are any past tense verbs preced-
ing rule phrase. In such cases, we do not classify
the sentence as a wish. For phrase 5, interrogative
sentences are also ignored.
Similar to finding suggestions, we assembled a
corpus of sentences for various products and ser-
vices, this time from forums that also contain buy-
sell sections. These may contain comments like:
</bodyText>
<reference confidence="0.6519674">
1. I am trying to find where I can purchase the com-
plete 1st season of Army Wives-can you help me?
2. I am seriously looking for a new bank...
3. I want to give a new year’s present to my 5 year old
nephew. My budget is 1500 Rupees.
</reference>
<table confidence="0.859829625">
6.2.1 Precision
Type Total No. of No. of Precision
sen- predicted correct
tences wishes wishes
iPhone 193 43 41 95.34%
iPod 176 48 37 79.54%
Credit 865 6 4 66.67%
Cards
</table>
<page confidence="0.706882">
59
</page>
<table confidence="0.99901">
Canon 170 40 39 97.50%
Cameras
Desktop 175 36 34 94.44%
PCs
</table>
<tableCaption confidence="0.945339">
Table 4 Precision of wish identification for various data
sets
</tableCaption>
<table confidence="0.9851457">
6.2.2 Recall5
Type No. of ex- No. of cor- Recall
pected rectly pre-
wishes dicted wishes
iPhone 80 41 51.25%
iPod 54 37 68.51%
Canon 65 39 60.00%
Camera
Desktop 66 34 51.52%
PCs
</table>
<tableCaption confidence="0.998808">
Table 5 Recall of wish identification
</tableCaption>
<subsectionHeader confidence="0.871295">
6.2.3 Rule Analysis
</subsectionHeader>
<bodyText confidence="0.988067">
This table analyses the precision of the tope three rules
that matched the most sentences.
</bodyText>
<table confidence="0.955857875">
Rule No. of No. of cor- Precision
Phrase matched rect matches
sentences
Looking 98 85 86.73%
for
Want to 24 22 91.67%
Interested 6 6 100%
In
</table>
<tableCaption confidence="0.992635">
Table 6 Rule Analysis
</tableCaption>
<subsectionHeader confidence="0.998414">
6.3 Comments on Results
</subsectionHeader>
<bodyText confidence="0.978702375">
Buy wishes tend to occur only in forums where
buyers can advertise their search and hope to re-
ceive advice or meet prospective sellers. In addi-
tion to sites dedicated to specific products, social
networks such as Twitter6 also provide such a plat-
form. This is in contrast to regular weblogs.
The results for all the electronic products
showed a precision of about 80% or more. As in
the case of suggestion wishes, wishes were very
rare in the credit cards postings.
The recall in all cases was above 50%. Buy wish
sentences matching The “looking for” and “want
to buy/purchase” rules were common. An observa-
tion was that in some cases, people would simply
5 The credit cards set had very few actual wishes (less than 10)
with which to carry out a meaningful recall exercise
</bodyText>
<sectionHeader confidence="0.600917" genericHeader="evaluation">
6 http://twitter.com
</sectionHeader>
<bodyText confidence="0.999720888888889">
list the expected attributes of the product they were
looking for. Because of the nature of the forum,
other users would interpret it as a buy/sell request.
We could not separate these sentences from other
kinds of sentences in the data set.
In most cases, the sentences were terse and used
phrases like “we need” and “seeking”. Further
expanding the rule phrases &amp; sub-phrases to in-
clude their synonyms is likely to improve recall.
</bodyText>
<sectionHeader confidence="0.996127" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.99997376923077">
This paper described two novel problems in the
world of opinion and intention mining, that of
identifying ‘wishes’ relating to improvements in
products and for purchasing them. These are likely
to be directly useful to business users. We build
approaches towards such detections, by the use of
English-language patterns. To the best of our
knowledge, this is the first attempt at solving such
problems.
The approach for identifying suggestions works
best for texts that contain explicit wishes, espe-
cially customer surveys. They work reasonably
well for (electronic) product reviews. In contrast,
reviews about banking services tend to contain
narratives and have more implicit opinions and
wishes. Similarly, the algorithm to detect buy
wishes works well for electronic product reviews
in comparison to banking products.
Wish statements appear very infrequently in re-
views. Existing sentiment analysis corpora may not
be sufficient to use in creating wish detectors.
Augmenting corpora such as the WISH dataset or
creating even more robust and representative cor-
pora would be a must for such exercises. A possi-
ble source could be the “Make A Wish”
foundation.
One of the possible future directions could be to
look at tense and mood analysis of sentences. Wish
sentences come under the ‘optative’ mood. Tech-
niques that help identify such a mood could pro-
vide additional hints to the nature of the sentence.
More features related to parts of speech and se-
mantic roles could be explored.
We also plan to look at machine learning ap-
proaches, but the availability of good quality train-
ing data is a limiting factor.
The emergence of social networking sites may
provide more challenges for such detectors. Sites
like Twitter are already being used to advertise
</bodyText>
<page confidence="0.993722">
60
</page>
<bodyText confidence="0.999896444444445">
intentions to buy or sell. However, the nature of
discourse in these media is markedly different to
regular reviews and forums due to size restrictions.
Any system that helps business users to identify
new customers or engage with existing ones would
need to tap into all these emerging channels. The
need for such detectors is likely to increase in the
future, thus providing further motivation to study
this nascent area.
</bodyText>
<sectionHeader confidence="0.998876" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997801255813954">
Hamish Cunningham, Diana Maynard, Kalina
Bontcheva, and Tablan, Valentin. GATE: A frame-
work and graphical development environment for ro-
bust NLP tools and applications. 2002
Kushal Dave, Steve Lawrence, and David M. Pennock.
Mining the peanut gallery: Opinion extraction and
semantic classification of product reviews. Proceed-
ings of the 12th international conference on World
Wide Web. 2003.
Minqing Hu and Bing Liu. Mining and summarizing
customer reviews. Proceedings of the tenth ACM
SIGKDD international conference on Knowledge
discovery and data mining. 2004.
Andrew B. Goldberg, Nathanael Fillmore, David
Andrzejewski, Zhiting Xu, Z, Bryan Gibson, and
Xiaojin Zhu. May all your wishes come true: A study
of wishes and how to recognize them. Proceedings of
Human Language Technologies: The 2009 Annual
Conference of the North American Chapter of the
Association for Computational Linguistics. 2009.
Nitin Jindal and Bing Liu. Identifying comparative sen-
tences in text documents. Proceedings of the 29th an-
nual international ACM SIGIR conference on
Research and development in information retrieval.
2006.
Mark Kröll and Markus Strohmaier, M. Analyzing hu-
man intentions in natural language text. Proceedings
of the fifth international conference on Knowledge
capture. 2009.
Johan Natt och Dag, Vincenzo Gervasi, Sjaak Brink-
kemper, and Björn Regnell, B. A linguistic engineer-
ing approach to large-scale requirements
management. Managing Natural Language Require-
ments in Large-Scale Software Development. Vol
22-1. 2005.
Marta Strickland. Five Reasons Sentiment Analysis
Won’t Ever Be Enough.
http://threeminds.organic.com/2009/09/five_reasons_
sentiment_analysi.html. 2009.
Xiaowen Ding, Bing Liu, and Philip S.Yu. A holistic
lexicon-based approach to opinion mining. Proceed-
ings of the international conference on Web search
and web data mining. 2008.
</reference>
<page confidence="0.999259">
61
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.591981">
<title confidence="0.999695">Wishful Thinking Finding suggestions and ‘buy’ wishes from product reviews</title>
<author confidence="0.980447">J Ramanand Krishna Bhavsar Niranjan Pedanekar</author>
<affiliation confidence="0.906567">BFS Innovations BFS Innovations BFS Cognizant Technology Solutions Cognizant Technology Solutions Cognizant Technology Solutions</affiliation>
<address confidence="0.914134">Pune, India Pune, India Pune, India</address>
<email confidence="0.806191">ramanand.janardhanankrishna.bhavsarniranjan.pedanekar@cognizant.com@cognizant.com@cognizant.com</email>
<abstract confidence="0.9993256875">This paper describes methods aimed at solving the novel problem of automatically discovering ‘wishes’ from (English) documents such as reviews or customer surveys. These wishes are sentences in which authors make suggestions (especially for improvements) about a product or service or show intentions to purchase a product or service. Such ‘wishes’ are of great use to product managers and sales personnel, and supplement the area of sentiment analysis by providing insights into the minds of consumers. We describe rules that can help detect these ‘wishes’ from text. We evaluate these methods on texts from the electronic and banking industries.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>I am trying to find where I can purchase the complete 1st season of Army Wives-can you help me? 2. I am seriously looking for a new bank... 3. I want to give a new year’s present to my 5 year old nephew. My budget is 1500 Rupees.</title>
<marker></marker>
<rawString>1. I am trying to find where I can purchase the complete 1st season of Army Wives-can you help me? 2. I am seriously looking for a new bank... 3. I want to give a new year’s present to my 5 year old nephew. My budget is 1500 Rupees.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hamish Cunningham</author>
<author>Diana Maynard</author>
<author>Kalina Bontcheva</author>
<author>Valentin Tablan</author>
</authors>
<title>GATE: A framework and graphical development environment for robust NLP tools and applications.</title>
<date>2002</date>
<marker>Cunningham, Maynard, Bontcheva, Tablan, 2002</marker>
<rawString>Hamish Cunningham, Diana Maynard, Kalina Bontcheva, and Tablan, Valentin. GATE: A framework and graphical development environment for robust NLP tools and applications. 2002</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kushal Dave</author>
<author>Steve Lawrence</author>
<author>David M Pennock</author>
</authors>
<title>Mining the peanut gallery: Opinion extraction and semantic classification of product reviews.</title>
<date>2003</date>
<booktitle>Proceedings of the 12th international conference on World Wide Web.</booktitle>
<contexts>
<context position="5152" citStr="Dave et al., 2003" startWordPosition="799" endWordPosition="802">ed to this upcoming area. Section 3 details our characterization of wishes. Section 4 describes the corpora used for these methods. We discuss our proposed algorithms and rules in Sections 5 &amp; 6, including a discussion of the results. Finally, we wrap up with our conclusions and directions for future work. 2 Related Work The principal context of our work is in the area of sentiment analysis, which is now a widely researched area because of the abundance of commentaries from weblogs, review sites, and social networking sites. In particular, we are interested in the analysis of product reviews (Dave et al., 2003; Hu and Liu, 2004), as well as its application to more service-oriented industries such as banks. We have built a sentiment analyzer that can analyze product and service reviews from a variety of domains. This also accepts social networking commentaries, customer surveys and news articles. The implementation follows a lexicon-based approach, similar to the one described in Ding et al. (2008), using lexicons for product attributes and opinion words for basic sentiment analysis. Our work is not a sub-task of sentiment analysis, but supplements the area. A similar example of a classification tas</context>
</contexts>
<marker>Dave, Lawrence, Pennock, 2003</marker>
<rawString>Kushal Dave, Steve Lawrence, and David M. Pennock. Mining the peanut gallery: Opinion extraction and semantic classification of product reviews. Proceedings of the 12th international conference on World Wide Web. 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining.</booktitle>
<contexts>
<context position="5171" citStr="Hu and Liu, 2004" startWordPosition="803" endWordPosition="806"> area. Section 3 details our characterization of wishes. Section 4 describes the corpora used for these methods. We discuss our proposed algorithms and rules in Sections 5 &amp; 6, including a discussion of the results. Finally, we wrap up with our conclusions and directions for future work. 2 Related Work The principal context of our work is in the area of sentiment analysis, which is now a widely researched area because of the abundance of commentaries from weblogs, review sites, and social networking sites. In particular, we are interested in the analysis of product reviews (Dave et al., 2003; Hu and Liu, 2004), as well as its application to more service-oriented industries such as banks. We have built a sentiment analyzer that can analyze product and service reviews from a variety of domains. This also accepts social networking commentaries, customer surveys and news articles. The implementation follows a lexicon-based approach, similar to the one described in Ding et al. (2008), using lexicons for product attributes and opinion words for basic sentiment analysis. Our work is not a sub-task of sentiment analysis, but supplements the area. A similar example of a classification task that works on the</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. Mining and summarizing customer reviews. Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining. 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew B Goldberg</author>
<author>Nathanael Fillmore</author>
<author>David Andrzejewski</author>
<author>Zhiting Xu</author>
<author>Bryan Gibson Z</author>
<author>Xiaojin Zhu</author>
</authors>
<title>all your wishes come true: A study of wishes and how to recognize them.</title>
<date></date>
<booktitle>Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<marker>Goldberg, Fillmore, Andrzejewski, Xu, Z, Zhu, </marker>
<rawString>Andrew B. Goldberg, Nathanael Fillmore, David Andrzejewski, Zhiting Xu, Z, Bryan Gibson, and Xiaojin Zhu. May all your wishes come true: A study of wishes and how to recognize them. Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics. 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Jindal</author>
<author>Bing Liu</author>
</authors>
<title>Identifying comparative sentences in text documents.</title>
<date>2006</date>
<booktitle>Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval.</booktitle>
<contexts>
<context position="5853" citStr="Jindal and Liu (2006)" startWordPosition="912" endWordPosition="915">ies such as banks. We have built a sentiment analyzer that can analyze product and service reviews from a variety of domains. This also accepts social networking commentaries, customer surveys and news articles. The implementation follows a lexicon-based approach, similar to the one described in Ding et al. (2008), using lexicons for product attributes and opinion words for basic sentiment analysis. Our work is not a sub-task of sentiment analysis, but supplements the area. A similar example of a classification task that works on the sentence level and is also related to sentiment analysis is Jindal and Liu (2006) which aims to identify comparisons between two entities in texts such as product reviews. Goldberg et al. (2009) introduced the novel task of identifying wishes. This used a “WISH” corpus derived from a web site that collected New Year’s wishes. Goldberg et al. (2009) studied the corpus in detail, describing the nature, geography, and scope of topics found in them. The paper also looked at building ‘wish detectors’, which were applied on a corpus of political comments and product reviews. A mix of manual templates and SVM-based text classifiers were used. A method to identify more templates w</context>
</contexts>
<marker>Jindal, Liu, 2006</marker>
<rawString>Nitin Jindal and Bing Liu. Identifying comparative sentences in text documents. Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval. 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Kröll</author>
<author>Markus Strohmaier</author>
<author>M</author>
</authors>
<title>Analyzing human intentions in natural language text.</title>
<date>2009</date>
<booktitle>Proceedings of the fifth international conference on Knowledge capture.</booktitle>
<marker>Kröll, Strohmaier, M, 2009</marker>
<rawString>Mark Kröll and Markus Strohmaier, M. Analyzing human intentions in natural language text. Proceedings of the fifth international conference on Knowledge capture. 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Natt och Dag</author>
<author>Vincenzo Gervasi</author>
<author>Sjaak Brinkkemper</author>
<author>Björn Regnell</author>
<author>B</author>
</authors>
<title>A linguistic engineering approach to large-scale requirements management. Managing Natural Language Requirements in Large-Scale Software Development. Vol</title>
<date>2005</date>
<contexts>
<context position="7228" citStr="Dag et al. (2005)" startWordPosition="1133" endWordPosition="1136">et al. (2009). We are interested in two specific kinds of wishes: sentences that make suggestions about existing products, and sentences that indicate the writer is interested in purchasing a product. (These are described in detail in Section 3.) Secondly, our interest is limited to product reviews, and not to social or political wishes. In Requirements Engineering, some methods of analyzing requirement documents have used linguistic techniques to understand and correlate requirements. These are somewhat related to our task, aiming to detect desired features in the project to be executed. och Dag et al. (2005) has some useful discussions on this topic. Kröll and Strohmaier (2009) study the idea of Intent Analysis, noting a taxonomy of Human Intentions, which could be useful in future discussions on the topic. 3 What are Wishes 3.1 Defining Wishes A dictionary definition (Goldberg et al. (2009)) of a “wish” is “a desire or hope for something to happen.” Goldberg et al. (2009) discuss different types of wishes, ranging from political to social to business. In our case, we limit our interest to comments about products and services. In particular, we are interested in two specific kinds of wishes. 55 3</context>
</contexts>
<marker>Dag, Gervasi, Brinkkemper, Regnell, B, 2005</marker>
<rawString>Johan Natt och Dag, Vincenzo Gervasi, Sjaak Brinkkemper, and Björn Regnell, B. A linguistic engineering approach to large-scale requirements management. Managing Natural Language Requirements in Large-Scale Software Development. Vol 22-1. 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Strickland</author>
</authors>
<title>Five Reasons Sentiment Analysis Won’t Ever Be Enough. http://threeminds.organic.com/2009/09/five_reasons_ sentiment_analysi.html.</title>
<date>2009</date>
<contexts>
<context position="2524" citStr="Strickland, 2009" startWordPosition="368" endWordPosition="369"> automated analysis can significantly shorten the time taken to find insights into the customer&apos;s mind and actions. Sentiment analysis of texts such as product reviews, call center notes, and customer surveys aims to automatically infer opinions expressed by people with regards to various topics of interest. A sentiment analysis exercise classifies the overall opinion of a review document into positive, neutral, or negative classes. It may also identify sentiments at a finer granularity, i.e. recognizing the mix of opinions about the topic(s) expressed in the text. However, industry analysts (Strickland, 2009) report some common problems with the results of these exercises: 1. The results (usually numerical scores split across positive, negative, neutral classes) are hard to meaningfully interpret. 2. These results are more useful to certain roles and domains. Brand, reputation, and service managers in media and retail industries find sentiment analysis more useful than product managers or sales teams in various industries. 3. The results do not ‘indicate user action’ i.e. opinions do not help identify a future action of the author based on the comments. An example of this is: does the consumer ind</context>
</contexts>
<marker>Strickland, 2009</marker>
<rawString>Marta Strickland. Five Reasons Sentiment Analysis Won’t Ever Be Enough. http://threeminds.organic.com/2009/09/five_reasons_ sentiment_analysi.html. 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaowen Ding</author>
<author>Bing Liu</author>
<author>Philip S Yu</author>
</authors>
<title>A holistic lexicon-based approach to opinion mining.</title>
<date>2008</date>
<booktitle>Proceedings of the international conference on Web</booktitle>
<contexts>
<context position="5547" citStr="Ding et al. (2008)" startWordPosition="862" endWordPosition="865"> which is now a widely researched area because of the abundance of commentaries from weblogs, review sites, and social networking sites. In particular, we are interested in the analysis of product reviews (Dave et al., 2003; Hu and Liu, 2004), as well as its application to more service-oriented industries such as banks. We have built a sentiment analyzer that can analyze product and service reviews from a variety of domains. This also accepts social networking commentaries, customer surveys and news articles. The implementation follows a lexicon-based approach, similar to the one described in Ding et al. (2008), using lexicons for product attributes and opinion words for basic sentiment analysis. Our work is not a sub-task of sentiment analysis, but supplements the area. A similar example of a classification task that works on the sentence level and is also related to sentiment analysis is Jindal and Liu (2006) which aims to identify comparisons between two entities in texts such as product reviews. Goldberg et al. (2009) introduced the novel task of identifying wishes. This used a “WISH” corpus derived from a web site that collected New Year’s wishes. Goldberg et al. (2009) studied the corpus in de</context>
</contexts>
<marker>Ding, Liu, Yu, 2008</marker>
<rawString>Xiaowen Ding, Bing Liu, and Philip S.Yu. A holistic lexicon-based approach to opinion mining. Proceedings of the international conference on Web search and web data mining. 2008.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>