<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.226359">
<title confidence="0.980011">
Chinese Word Segmentation at Peking University
</title>
<author confidence="0.974335">
Duan Huiming Bai Xiaojing Chang Baobao Yu Shiwen
</author>
<affiliation confidence="0.995379">
Institute of Computational Linguistics, Peking University
</affiliation>
<email confidence="0.96581">
{duenhm, baixj, chbb, yusw}@pku.edu.cn
</email>
<sectionHeader confidence="0.992211" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.993889333333333">
Word segmentation is the first step in Chinese
information processing, and the performance
of the segmenter, therefore, has a direct and
great influence on the processing steps that
follow. Different segmenters will give
different results when handling issues like
word boundary. And we will present in this
paper that there is no need for an absolute
definition of word boundary for all segmenters,
and that different results of segmentation shall
be acceptable if they can help to reach a
correct syntactic analysis in the end.
Keyword: automatic Chinese word
segmentation, word segmentation evaluation,
corpus, natural language processing
</bodyText>
<sectionHeader confidence="0.99698" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.9997215">
On behalf of the Institute of Computational
Linguistics, Peking University, we would like
to thank ACL-SIGHAN for sponsoring the
First International Chinese Word
Segmentation Bakeoff, which provides us an
opportunity to present our achievement of the
past decade.
We know for sure that it is very difficult to
settle on a scientific and appropriate method
of evaluation, and it might be even more
difficult than word segmentation itself. We are
also clear that each step in Chinese
information processing requires great efforts,
and a satisfactory result in word segmentation,
though critical, does not necessarily guarantee
good results in the following steps.
From the test results of this evaluation, we
are very gratified to see that we have done a
good job both as a test corpus provider and as
a participant. According to the rule, we did not
test on the corpus we provided, but it is quite
encouraging that our supply tops the test
corpus list to be elected by other participants.
Section 2 and Section 3 describes our work
in the Bakeoff as the test corpus provider and
the participant respectively.
</bodyText>
<sectionHeader confidence="0.988155" genericHeader="method">
2. The test corpus provider
</sectionHeader>
<subsectionHeader confidence="0.990933">
2.1 Corpus
</subsectionHeader>
<bodyText confidence="0.9984565">
The corpus we provided to the sponsor
includes:
</bodyText>
<listItem confidence="0.965451">
■ A training set from People’s Daily
(January, 1998)
■ A test set from People’s Daily (Page 4 of
January 1, 1998)
</listItem>
<bodyText confidence="0.979222285714286">
Data from People’s Daily features standard
Chinese, little language error, a wide coverage
of linguistic phenomenon and topics, which
are required for statistic training. Meanwhile,
the corpus we provided is a latest version
manually validated, hence a high level of
correctness and consistency.
</bodyText>
<subsectionHeader confidence="0.810878">
2.2 Specification
</subsectionHeader>
<bodyText confidence="0.9996984">
When processing a corpus, we need a detailed
and carefully designed specification for
guidance. And when using the corpus for NLP
evaluation, we also need such a specification
to ensure a fair contest for different systems
within a common framework.
We provided the latest version of our
specification, which has been published in the
Journal of Chinese Information Processing.
Based on our experience of large-scale corpus
processing in recent years, the current version
gave us different perspectives in a consistent
way, and we hope it will also help others in
this field know better of our segmented and
POS-tagged corpus.
</bodyText>
<sectionHeader confidence="0.980251" genericHeader="method">
3. The participant
</sectionHeader>
<subsectionHeader confidence="0.991967">
3.1 Training and testing
</subsectionHeader>
<bodyText confidence="0.999814263157895">
Our research on word segmentation has been
focusing on People’s Daily. As we are one of
the two providers of Chinese corpora in GB
code in this Bakeoff, we had to test on the
Penn Chinese treebank.
Not all the training and test corpus we got
came from the Mainland China. Some were
GB data converted from BIG5 texts of Taiwan.
It is commonly known that in the Mainland,
Hong Kong and Taiwai, the Chinese langauge
is used diversely not only in the sense of
different coding systems, but in respect of
different wordings as well.
While training our segmenter, we studied
the guidelines and training corpus of Penn
Chinese treebank, tracing the differences and
working on them. The main difference
between the work of U. Penn and that of ours
is notion of “word”. For instance:
</bodyText>
<table confidence="0.99645125">
Differences of “Word” U. Penn PKU
Chinese name 刘卫东,彭少阳 刘 卫东, 彭 少阳
Number + “多|余 ” 11.6 万余,八千七百多万 11.6 万 余,八千七百 多 万
Monosyllabic verb + complement 砌出,填上,读完 砌 出,填 上,读 完
Time word 十时三十分,90年代 十时 三十分,90 年代
Noun + suffix “们” 大学生们,企业家们 大学生 们,企业家 们
Disyllabic verb + “于” 领先于,受命于 领先 于,受命 于
... ...
</table>
<bodyText confidence="0.9987832">
These are different combinations in regard
of words which follow certain patterns, and
can therefore be handled easily by applying
rules to the grogram. The real difficulty for us,
however, is the following items:
</bodyText>
<table confidence="0.993480875">
U. Penn PKU
有线 电视 有线电视
中央 军委 中央军委
中华 民族 中华民族
人民 日报 人民日报
知识 产权 知识产权
一 条 龙 一条龙
... ... ... ...
</table>
<bodyText confidence="0.99927035">
The Open Track allows us to use our own
recourses, so we had to find the lexical
correspondence to reduce the negtive effect
caused by the difference between Penn
Chinese treebank and our own corpus.
However, as the training corpus is small, we
could not remove all the negative effect, and
the untackled problems remained to affect our
test result.
Further, as we have been working on
language data from the Mainland China, the
lexicon of our segmenter does not contain
words used in Taiwan. Such being the case,
we added into our lexicon the entries that were
not known (i.e., not found in the training set)
and could not be handled by the rule-based
makeshift either. But because we are not very
familiar with the Chinese language used in
Taiwan, we could not make a complete patch
due to the limit of time.
</bodyText>
<subsectionHeader confidence="0.998612">
3.2 Result analysis
</subsectionHeader>
<bodyText confidence="0.93452175">
From the test result that the sponsor provided,
we can see our segmenter failed to score when
the notion of “word” and the recognition of
unknown words are involved. 板 。
</bodyText>
<equation confidence="0.998101807692308">
Example 1:
[U. Penn] 实施 初期 将 以 除罪化 与
小额 贸易 合法化 为主 , 在 观察
三通 对 金 马 地区 治安 与 产业 影响
后 , 才 会 考虑 在 第二 阶段 开放
业性 行为 , 至于 大 三通 的 实施 ,
尚 没有 明确 的 时间表 。
[PKU] 实施 初期 将 以 除 罪 化 与
小额 贸易 合法化 为主 , 在 观察
三通 对 金马 地区 治安 与 产业 影响
后 , 才 会 考虑 在 第二 阶段 开放
业性 行为 , 至于 大 三通 的 实施 ,
尚 没有 明确 的 时间表 。
Example 2:
[U. Penn] 一 家 宽频 公司 负责 管理
两 个 大型 鱼缸 的 赖 小姐 更 表示 ,
公司 受 景气 影响 , 不免 人人 节衣缩
食 , 但 每 个 月 五 、 六千 元 的
缸 清理费 可 不 曾 少 过 , 更 别
不时 得 补充 鱼 、 饲料 等 费用 。
[PKU] 一 家 宽 频 公司 负责 管理
个 大型 鱼缸 的 赖 小姐 更 表示 ,
司 受 景气 影响 , 不免 人人 节衣缩
食 , 但 每 个 月 五 、 六千 元 的
缸 清理费 可不 曾 少 过 , 更 别提
不时 得 补充 鱼 、 饲料 等 费用 。
</equation>
<bodyText confidence="0.999746">
In addition, there are also cognitive
differences concerning the objective world,
which did come up to influence our fine score.
</bodyText>
<equation confidence="0.895566090909091">
Example 3:
[U. Penn] 吴思华 则 以 英特尔 为 例 ,
说明 知识 「 点 矽 成 金 」 的 威力 :
一 张 名片 大小 的 CPU , 说穿 了
是 一 块 烧 有 复杂 电路图 的 矽
板 。
[PKU]
吴思华 则 以 英特尔 为 例 ,
说明 知识 「 点 矽 成金 」 的 威力 :
一 张 名片 大小 的 CPU , 说穿 了
是 一 块 烧 有 复杂 电路图 的 矽晶
Example 4:
[U. Penn] 啊 , 外太空人 入侵 ?
紧张 , 这 是 新 车 大展 中 , 观众
着 特制 的 「 虚拟 实 境 」 头盔 ,
会 一下 自己 驾驶 新型 车 的 超炫
快感 。
[PKU] 啊 , 外 太空人 入侵 ? 别
张 , 这 是 新车 大展 中 , 观众
着 特制 的 「 虚拟 实境 」 头盔 ,
会 一下 自己 驾驶 新型 车 的 超
快感 。
</equation>
<bodyText confidence="0.9999354">
The recognition of unknown words has long
been a bottleneck for word segmentation
technique. So far we have not found a good
solution, but we are confident about a progress
in this respect in the near future.
</bodyText>
<sectionHeader confidence="0.996177" genericHeader="method">
4. Conclusion
</sectionHeader>
<bodyText confidence="0.999962541666667">
Word segmentation is the first step yet a key
step in Chinese information processing, but
we have not found a perfect solution up till
now. From an engineering perspective, we
think there is no need for a unique result of
segmentation. All roads lead to Rome. The
approach you take, technical or non-technical,
will be a good one if the expected result is
achieved. And it would be more desirable if
the processing program in each step can
tolerate or even correct the errors made in the
previous step.
We learn from our experience that the
computer processing of natural language is a
complex issue, which requires a solid
fundamental research (on the language itself)
to ensure a higher accuracy of automation. It
is definitely hard to achieve an increase of one
percent or even less in the accuracy of word
segmentation, but we are still confident and
will keep working in this respect.
Finally, we would like to thank Dr. Li Baoli
and Dr. Bing SWEN for their great efforts on
the maintenance of our segmentation program.
</bodyText>
<sectionHeader confidence="0.945193" genericHeader="method">
Reference
</sectionHeader>
<reference confidence="0.997418722222222">
Yu, Shiwen, DUAN, Hui-ming, ZHU, Xue-feng,
Bing SWEN. 2002. The Specification of Basic
Processing of Contemporary Chinese Corpus.
Journal of Chinese Information Processing,
Issue 5 &amp; Issue 6, 2002.
Yu, Shiwen, et al. 2002. The Grammatical
Knowledge-base of Contemporary Chinese –
A Complete Specification (Second Version).
Beijing: Tsinghua University Press.
Liu, Yuan, et al. 1994. Specification and
Automation of Word Segmentation of
Contemporary Chinese for Information
Processing. Beijing: Tsinghua University
Press.
Fie Xia. 2000. The segmentation guidelines for
the Penn Chinese tree bank (3.0). see
http://www.cis.upenn.edu/~chinese/segguide.3
rd.ch.pdf
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.531724">
<title confidence="0.934525">Chinese Word Segmentation at Peking University</title>
<author confidence="0.997763">Duan Huiming Bai Xiaojing Chang Baobao Yu Shiwen</author>
<affiliation confidence="0.999981">Institute of Computational Linguistics, Peking University</affiliation>
<email confidence="0.903935">duenhm@pku.edu.cn</email>
<email confidence="0.903935">baixj@pku.edu.cn</email>
<email confidence="0.903935">chbb@pku.edu.cn</email>
<email confidence="0.903935">yusw@pku.edu.cn</email>
<abstract confidence="0.997851266666667">Word segmentation is the first step in Chinese information processing, and the performance of the segmenter, therefore, has a direct and great influence on the processing steps that follow. Different segmenters will give different results when handling issues like word boundary. And we will present in this paper that there is no need for an absolute definition of word boundary for all segmenters, and that different results of segmentation shall be acceptable if they can help to reach a correct syntactic analysis in the end. Chinese word segmentation, word segmentation evaluation,</abstract>
<intro confidence="0.64102">corpus, natural language processing</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Shiwen Yu</author>
<author>Hui-ming DUAN</author>
<author>Xue-feng ZHU</author>
<author>Bing SWEN</author>
</authors>
<title>The Specification of Basic Processing of Contemporary Chinese Corpus.</title>
<date>2002</date>
<journal>Journal of Chinese Information Processing, Issue 5 &amp; Issue</journal>
<volume>6</volume>
<marker>Yu, DUAN, ZHU, SWEN, 2002</marker>
<rawString>Yu, Shiwen, DUAN, Hui-ming, ZHU, Xue-feng, Bing SWEN. 2002. The Specification of Basic Processing of Contemporary Chinese Corpus. Journal of Chinese Information Processing, Issue 5 &amp; Issue 6, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiwen Yu</author>
</authors>
<title>The Grammatical Knowledge-base of Contemporary Chinese – A Complete Specification (Second Version).</title>
<date>2002</date>
<publisher>Tsinghua University Press.</publisher>
<location>Beijing:</location>
<marker>Yu, 2002</marker>
<rawString>Yu, Shiwen, et al. 2002. The Grammatical Knowledge-base of Contemporary Chinese – A Complete Specification (Second Version). Beijing: Tsinghua University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuan Liu</author>
</authors>
<title>Specification and Automation of Word Segmentation of Contemporary Chinese for Information Processing.</title>
<date>1994</date>
<publisher>Tsinghua University Press.</publisher>
<location>Beijing:</location>
<marker>Liu, 1994</marker>
<rawString>Liu, Yuan, et al. 1994. Specification and Automation of Word Segmentation of Contemporary Chinese for Information Processing. Beijing: Tsinghua University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fie Xia</author>
</authors>
<title>The segmentation guidelines for the Penn Chinese tree bank (3.0). see</title>
<date>2000</date>
<note>http://www.cis.upenn.edu/~chinese/segguide.3 rd.ch.pdf</note>
<marker>Xia, 2000</marker>
<rawString>Fie Xia. 2000. The segmentation guidelines for the Penn Chinese tree bank (3.0). see http://www.cis.upenn.edu/~chinese/segguide.3 rd.ch.pdf</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>