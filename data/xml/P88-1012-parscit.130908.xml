<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.988333">
Interpretation as Abduction
</title>
<author confidence="0.870182">
Jerry R. Hobbs, Mark Stickel,
Paul Martin, and Douglas Edwards
</author>
<sectionHeader confidence="0.666007666666667" genericHeader="abstract">
Artificial Intelligence Center
SRI International
Abstract
</sectionHeader>
<bodyText confidence="0.940176625">
To interpret a sentence:
An approach to abductive inference developed in the TAC-
ITUS project has resulted in a dramatic simplification of
how the problem of interpreting texts is conceptualized. Its
use in solving the local pragmatics problems of reference,
compound nominals, syntactic ambiguity, and metonymy
is described and illustrated. It also suggests an elegant and
thorough integration of syntax, semantics, and pragmatics.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="method">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9571089">
Abductive inference is inference to the best explanation.
The process of interpreting sentences in discourse can be
viewed as the process of providing the best explanation of
why the sentences would be true. In the TACITUS Project
at SRI, we have developed a scheme for abductive inference
that yields a significant simplification in the description of
such interpretation processes and a significant extension
of the range of phenomena that can be captured. It has
been implemented in the TACITUS System (Stickel, 1982;
Hobbs, 1986; Hobbs and Martin, 1987) and has been and
is being used to solve a variety of interpretation problems
in casualty reports, which are messages about breakdowns
in machinery, as well as in other texts.1
It is well-known that people understand discourse so well
because they know so much. Accordingly, the aim of the
TACITUS Project has been to investigate how knowledge
is used in the interpretation of discourse. This has involved
building a large knowledge base of commonsense and do-
main knowledge (see Hobbs et al., 1986), and developing
procedures for using this knowledge for the interpretation
of discourse. In the latter effort, we have concentrated on
problems in local pragmatics, specifically, the problems of
reference resolution, the interpretation of compound nom-
inals, the resolution of some kinds of syntactic ambiguity,
and metonymy resolution. Our approach to these problems
is the focus of this paper.
In the framework we have developed, what the interpre-
tation of a sentence is can be described very concisely:
1Charniak (1986) and Norvig (1987) have also applied abductive
inference techniques to discourse interpretation.
</bodyText>
<sectionHeader confidence="0.501455" genericHeader="method">
(1) Derive the logical form of the sentence,
</sectionHeader>
<bodyText confidence="0.984938621621622">
together with the constraints that predicates
impose on their arguments,
allowing for coercions,
Merging redundancies where possible,
Making assumptions where necessary.
By the first line we mean &amp;quot;derive in the logical sense, or
prove from the predicate calculus axioms in the knowledge
base, the logical form that has been produced by syntactic
analysis and semantic translation of the sentence.&amp;quot;
In a discourse situation, the speaker and hearer both
have their sets of private beliefs, and there is a large over-
lapping set of mutual beliefs. An utterance stands with one
foot in mutual belief and one foot in the speaker&apos;s private
beliefs. It is a bid to extend the area of mutual belief to
include some private beliefs of the speaker&apos;s. It is anchored
referentially in mutual belief, and when we derive the logi-
cal form and the constraints, we are recognizing this refer-
ential anchor. This is the given information, the definite,
the presupposed. Where it is necessary to make assump-
tions, the information comes from the speaker&apos;s private
beliefs, and hence is the new information, the indefinite,
the asserted. Merging redundancies is a way of getting a
minimal, and hence a best, interpretation.2
In Section 2 of this paper, we justify the first clause of
the above characterization by showing that solving local
pragmatics problems is equivalent to proving the logical
form plus the constraints. In Section 3, we justify the last
two clauses by describing our scheme of abductive infer-
ence. In Section 4 we provide several examples. In Section
5 we describe briefly the type hierarchy that is essential
for making abduction work. In Section 6 we discuss future
directions.
2Interpreting indirect speech acts, such as &amp;quot;It&apos;s cold in here,&amp;quot; mean-
ing &amp;quot;Close the window,&amp;quot; is not a counterexample to the principle that
the minimal interpretation is the best interpretation, but rather can
be seen as a matter of achieving the minimal interpretation coherent
with the interests of the speaker.
</bodyText>
<page confidence="0.99824">
95
</page>
<sectionHeader confidence="0.996117" genericHeader="method">
2 Local Pragmatics
</sectionHeader>
<bodyText confidence="0.997311">
The four local pragmatics problems we have addressed can
be illustrated by the following &amp;quot;sentence&amp;quot; from the casualty
reports;
</bodyText>
<listItem confidence="0.690462">
(2) Disengaged compressor after lube-oil alarm.
</listItem>
<bodyText confidence="0.998555">
Identifying the compressor and the alarm are reference
resolution problems. Determining the implicit relation
between &amp;quot;lube-oil&amp;quot; and &amp;quot;alarm&amp;quot; is the problem of com-
pound nominal interpretation. Deciding whether &amp;quot;af-
ter lube-oil alarm&amp;quot; modifies the compressor or the disen-
gaging is a problem in syntactic ambiguity resolution.
The preposition &amp;quot;after&amp;quot; requires an event or condition as
its object and this forces us to coerce &amp;quot;lube-oil alarm&amp;quot; into
&amp;quot;the sounding of the lube-oil alarm&amp;quot;; this is an example
of metonymy resolution. We wish to show that solving
the first three of these problems amounts to deriving the
logical form of the sentence. Solving the fourth amounts to
deriving the constraints predicates impose on their argu-
ments, allowing for coercions. For each of these problems,
our approach is to frame a logical expression whose deriva-
tion, or proof, constitutes an interpretation.
Reference: To resolve the reference of &amp;quot;compressor&amp;quot; in
sentence (1), we need to prove (constructively) the follow-
ing logical expression:
</bodyText>
<listItem confidence="0.453556">
(3) (3 c)compressor(c)
</listItem>
<bodyText confidence="0.998584">
If, for example, we prove this expression by using axioms
that say C1 is a starting air compressor, and that a starting
air compressor is a compressor, then we have resolved the
reference of &amp;quot;compressor&amp;quot; to
In general, we would expect definite noun phrases to
refer to entities the hearer already knows about and can
identify, and indefinite noun phrases to refer to new enti-
ties the speaker is introducing. However, in the casualty
reports most noun phrases have no determiner. There are
sentences, such as
</bodyText>
<subsectionHeader confidence="0.769154">
Retained oil sample and filter for future analysis.
</subsectionHeader>
<bodyText confidence="0.985695777777778">
where &amp;quot;sample&amp;quot; is indefinite, or new information, and &amp;quot;fil-
ter&amp;quot; is definite, or already known to the hearer. In this
case, we try to prove the existence of both the sample and
the filter. When we fail to prove the existence of the sam-
ple, we know that it is new, and we simply assume its
existence.
Elements in a sentence other than nominals can also
function referentially. In
Alarm sounded.
Alarm activated during routine start of
compressor.
one can argue that the activation is the same as. or at least
implicit in, the sounding. Hence, in addition to trying
to derive expressions such as (3) for nominal reference,
for possible non-nominal reference we try to prove similar
expressions.
(3 ... e, a,...)... A activate&apos;(e, a) A ...3
That is, we wish to derive the existence, from background
knowledge or the previous text, of some known or implied
activation. Most, but certainly not all, information con-
veyed non-nominally is new, and hence will be assumed.
Compound Nominals: To resolve the reference of the
noun phrase &amp;quot;lube-oil alarm&amp;quot;, we need to find two entities
o and a with the appropriate properties. The entity o must
be lube oil, a must be an alarm, and there must be some
implicit relation between them. Let us call that implicit
relation nn. Then the expression that must be proved is
</bodyText>
<equation confidence="0.597948">
(30, a, nn)lube-oil(o) A alarm(a) A nn(o, a)
</equation>
<bodyText confidence="0.971601869565217">
In the proof, instantiating nn amounts to interpreting the
implicit relation between the two nouns in the compound
nominal. Compound nominal interpretation is thus just a
special case of reference resolution.
Treating nn as a predicate variable in this way seems to
indicate that the relation between the two nouns can be
anything, and there are good reasons for believing this to
be the case (e.g., Downing, 1977). In &amp;quot;lube-oil alarm&amp;quot;, for
example, the relation is
As, y [y sounds if pressure of x drops too low]
However, in our implementation we use a first-order sim-
ulation of this approach. The symbol nn is treated as a
predicate constant, and the most common possible rela-
tions (see Levi, 1978) are encoded in axioms. The axiom
(V x, y)part(y, D nn(x, y)
allows interpretation of compound nominals of the form
&amp;quot;&lt;whole&gt; &lt;part&gt;&amp;quot;, such as &amp;quot;filter element&amp;quot;. Axioms of
the form
(V z, y)sample(y, nn(x, y)
handle the very common case in which the head noun is
a relational noun and the prenominal noun fills one of its
roles, as in &amp;quot;oil sample&amp;quot;. Complex relations such as the
one in &amp;quot;lube-oil alarm&amp;quot; can sometimes be glossed as &apos;for&amp;quot;.
</bodyText>
<equation confidence="0.55492">
x, y)far(y, x) nn(x, y)
</equation>
<bodyText confidence="0.9909832">
Syntactic Ambiguity: Some of the most com-
mon types of syntactic ambiguity, including prepositional
phrase and other attachment ambiguities and very com-
pound nominal ambiguities, can be converted into con-
strained coreference problems (see Bear and Hobbs, 1988).
</bodyText>
<footnote confidence="0.777733">
3See Hobbs (1985a) for explanation of this notation for events.
</footnote>
<page confidence="0.987256">
96
</page>
<bodyText confidence="0.929144375">
For example, in (2) the first argument of after is taken to
be an existentially quantified variable which is equal to ei-
ther the compressor or the alarm. The logical form would
thus include
(3 ... e, c, y, a, ...)... A a f ter(y, a) A y E {c, e)
That is, however a f ter(y, a) is proved or assumed, y must
be equal to either the compressor c or the disengaging e.
This kind of ambiguity is often solved as a byproduct of the
resolution of metonymy or of the merging of redundancies.
Metonymy: Predicates impose constraints on their
arguments that are often violated. When they are vio-
lated, the arguments must be coerced into something re-
lated which satisfies the constraints. This is the process of
metonymy resolution. Let us suppose, for example, that
in sentence (2), the predicate after requires its arguments
to be events:
</bodyText>
<equation confidence="0.999326">
after(ei,e2) : event(e2) A event(e2)
</equation>
<bodyText confidence="0.9975504">
To allow for coercions, the logical form of the sentence is
altered by replacing the explicit arguments by &amp;quot;coercion
variables&amp;quot; which satisfy the constraints and which are re-
lated somehow to the explicit arguments. Thus the altered
logical form for (2) would include
</bodyText>
<equation confidence="0.930541666666667">
(3 ... k2,y,a,reli,re12,...)... A after(ki,k2)
A event(k2) A reli(ki,y)
A event(k2) A rel2(k2, a) A ...
</equation>
<bodyText confidence="0.9790765">
As in the most general approach to compound nominal
interpretation, this treatment is second-order, and suggests
that any relation at all can hold between the implicit and
explicit arguments. Nunberg (1978), among others, has in
fact argued just this point. However, in our implementa-
tion, we are using a first-order simulation. The symbol rel
is treated as a predicate constant, and there are a num-
ber of axioms that specify what the possible coercions are.
Identity is one possible relation, since the explicit argu-
ments could in fact satisfy the constraints.
(Vx)rel(x,
In general, where this works, it will lead to the best inter-
pretation. We can also coerce from a whole to a part and
from an object to its function. Hence,
</bodyText>
<equation confidence="0.9976335">
(V x, y)part(x, y) rel(x, y)
(V e)function(e, x) rel(e, x)
</equation>
<bodyText confidence="0.96646">
Putting it all together, we find that to solve all the local
pragmatics problems posed by sentence (2), we must derive
the following expression:
</bodyText>
<equation confidence="0.456967">
(3 e, x, c, kl, k2, y, a, o)Past(e)
A disengage&apos;(e, x, c)
</equation>
<bodyText confidence="0.973662796296297">
A compressor(c) A a f ter(ki , ks)
A event(ki) A rel(ki, y) A y E {c, e}
A event(k2) A rel(k2,a) A alarm(a)
A nn(o, a) A lube-oil(o)
But this is just the logical form of the sentence4 together
with the constraints that predicates impose on their ar-
guments, allowing for coercions. That is, it is the first
half of our characterization (1) of what it is to interpret a
sentence.
When parts of this expression cannot be derived, as-
sumptions must be made, and these assumptions are taken
to be the new information. The likelihood of different
atoms in this expression being new information varies ac-
cording to how the information is presented, linguistically.
The main verb is more likely to convey new information
than a definite noun phrase. Thus, we assign a cost to
each of the atoms—the cost of assuming that atom. This
cost is expressed in the same currency in which other fac-
tors involved in the &amp;quot;goodness&amp;quot; of an interpretation are
expressed; among these factors are likely to be the length
of the proofs used and the salience of the axioms they rely
on. Since a definite noun phrase is generally used referen-
tially, an interpretation that simply assumes the existence
of the referent and thus fails to identify it should be an ex-
pensive one. It is therefore given a high assumability cost.
For purposes of concreteness, let&apos;s call this $10. Indefinite
noun phrases are not usually used referentially, so they are
given a low cost, say, $1. Bare noun phrases are given
an intermediate cost, say, $5. Propositions presented non-
nominally are usually new information, so they are given
a low cost, say, $3. One does not usually use selectional
constraints to convey new information, so they are given
the same cost as definite noun phrases. Coercion relations
and the compound nominal relations are given a very high
cost, say, $20, since to assume them is to fail to solve the
interpretation problem. If we superscript the atoms in the
above logical form by their assumability costs, we get the
following expression:
(3e, x, c, kl, k2, y, a, o)Past(e)&amp;quot;
A disengage&apos; (e, x, c)&amp;quot;
A compressor(c)&amp;quot; A after(ki, k2)&amp;quot;
A event(k2 )S1° A rel(ki,y)sss A y E {c, e}
A event( k2)11° A rel(k2, a)s&amp;quot; A alarm(a)55
A nn(o, a)82° A lube-oil(o)55
While this example gives a rough idea of the relative as-
sumability costs, the real costs must mesh well with the in-
ference processes and thus must be determined experimen-
tally. The use of numbers here and throughout the next
section constitutes one possible regime with the needed
properties. We are at present working, and with some
optimism, on a semantics for the numbers and the proce-
dures that operate on them. In the course of this work, we
may modify the procedures to an extent, but we expect to
retain their essential properties.
</bodyText>
<footnote confidence="0.711564333333333">
4For justification for this kind of logical form for sentences with
quantifiers and intensional operators, see Hobbs(1983) and Hobbs
(1985a).
</footnote>
<page confidence="0.999548">
97
</page>
<sectionHeader confidence="0.996931" genericHeader="method">
3 Abduction
</sectionHeader>
<bodyText confidence="0.98920206">
We now argue for the last half of the characterization (1)
of interpretation.
Abduction is the process by which, from (lx)p(s) D
q(r) and q(A), one concludes p(A). One can think of q(A)
as the observable evidence, of ( z)p(s) D q(x) as a gen-
eral principle that could explain q(A)&apos;s occurrence, and of
p(A) as the inferred, underlying cause of q(A). Of course,
this mode of inference is not valid; there may be many
possible such p(A)&apos;s. Therefore, other criteria are needed
to choose among the possibilities. One obvious criterion
is consistency of p(A) with the rest of what one knows.
Two other criteria are what Thagard (1978) has called
consilience and simplicity. Roughly, simplicity is that p(A)
should be as small as possible, and consilience is that q(A)
should be as big as possible. We want to get more bang
for the buck, where q(A) is bang, and p(A) is buck.
There is a property of natural language discourse, no-
ticed by a number of linguists (e.g., Joos (1972), Wilks
(1972)), that suggests a role for simplicity and consilience
in its interpretation—its high degree of redundancy. Con-
sider
Inspection of oil filter revealed metal particles.
An inspection is a looking at that causes one to learn a
property relevant to the function of the inspected object.
The function of a filter is to capture particles from a fluid.
To reveal is to cause one to learn. If we assume the two
causings to learn are identical, the two sets of particles
are identical, and the two functions are identical, then we
have explained the sentence in a minimal fashion. A small
number of inferences and assumptions have explained a
large number of syntactically independent propositions in
the sentence. As a byproduct, we have moreover shown
that the inspector is the one to whom the particles are
revealed and that the particles are in the filter.
Another issue that arises in abduction is what might
be called the &amp;quot;informativeness-correctness tradeoff&amp;quot;. Most
previous uses of abduction in AI from a theorem-proving
perspective have been in diagnostic reasoning (e g., Pople,
1973; Cox and Pietrzykowski, 1986), and they have as-
sumed &amp;quot;most specific abduction&amp;quot;. If we wish to explain
chest pains, it is not sufficient to assume the cause is sim-
ply chest pains. We want something more specific, such as
&amp;quot;pneumonia&amp;quot;. We want the most specific possible expla-
nation. In natural language processing, however, we often
want the least specific assumption. If there is a mention of
a fluid, we do not necessarily want to assume it is lube oil.
Assuming simply the existence of a fluid may be the best
we can do.s However, if there is corroborating evidence,
we may want to make a more specific assumption. In
Alarm sounded. Flow obstructed.
</bodyText>
<subsectionHeader confidence="0.505567">
6Sometimes a cigar is just a cigar.
</subsectionHeader>
<bodyText confidence="0.999952529411765">
we know the alarm is for the lube oil pressure, and this
provides evidence that the flow is not merely of a fluid but
of lube oil. The more specific our assumptions are, the
more informative our interpretation is. The less specific
they are, the more likely they are to be correct.
We therefore need a scheme of abductive inference with
three features. First, it should be possible for goal ex-
pressions to be assumable, at varying costs. Second, there
should be the possibility of making assumptions at vari-
ous levels of specificity. Third, there should be a way of
exploiting the natural redundancy of texts.
We have devised just such an abduction scheme.6 First,
every conjunct in the logical form of the sentence is given
an assumability cost, as described at the end of Section 2.
Second, this cost is passed back to the antecedents in Horn
clauses by assigning weights to them. Axioms are stated
in the form
</bodyText>
<listItem confidence="0.986236">
(4) Pr A Pr D Q
</listItem>
<bodyText confidence="0.9780356875">
This says that P1 and P2 imply Q, but also that if the
cost of assuming Q is c, then the cost of assuming P1 is
wic, and the cost of assuming P2 is W2C. Third, factoring
or synthesis is allowed. That is, goal wffs may be unified,
in which case the resulting wff is given the smaller of the
costs of the input wffs. This feature leads to minimality
through the exploitation of redundancy.
Note that in (4), if to), + w2 &lt; 1, most specific abduction
is favored—why assume Q when it is cheaper to assume Pi
and P2. If w1+ to2 &gt; 1, least specific abduction is favored—
why assume P1 and P2 when it is cheaper to assume Q. But
in
P16 A Pt D Q
if P1 has already been derived, it is cheaper to assume P2
than Q. P1 has provided evidence for Q, and assuming the
&amp;quot;remainder&amp;quot; P2 of the necessary evidence for Q should be
cheaper.
Factoring can also override least specific abduction.
Suppose we have the axioms
Pe A Pt D Qj
Pt A Pt D Q2
and we wish to derive Qi A Q2, where each conjunct has an
assumability cost of $10. Then assuming Qi A Q2 will cost
$20, whereas assuming Pi A P2 A P3 Will cost only $18, since
the two instances of P2 can be unified. Thus, the abduction
scheme allows us to adopt the careful policy of favoring
least specific abduction while also allowing us to exploit
the redundancy of texts for more specific interpretations.
In the above examples we have used equal weights on
the conjuncts in the antecedents. I is more reasonable,
&apos;The abduction scheme is due to Mark Stickel, and it, or a variant
of it, is described at greater length in Stickel (1988).
</bodyText>
<page confidence="0.988361">
98
</page>
<bodyText confidence="0.94455105882353">
however, to assign the weights according to the &amp;quot;seman-
tic contribution&amp;quot; each conjunct makes to the consequent.
Consider, for example, the axiom
(Vz)car(z).° A no-top(x).4 D convertible(x)
We have an intuitive sense that car contributes more to
convertible than no-top does.&apos; In principle, the weights in
(4) should be a function of the probabilities that instances
of the concept P, are instances of the concept Q in the cor-
pus of interest. In practice, all we can do is assign weights
by a rough, intuitive sense of semantic contribution, and
refine them by successive approximation on a representa-
tive sample of the corpus.
One would think that since we are deriving the logical
form of the sentence, rather than determining what can be
inferred from the logical form of the sentence, we could not
use superset information in processing the sentence. That
is, since we are back-chaining from the propositions in the
logical form, the fact that, say, lube oil is a fluid, which
would be expressed as
(5) (V x)lube-oil(x) D fluid(x)
could not play a role in the analysis. Thus, in the text
Flow obstructed. Metal particles in lube oil filter.
we know from the first sentence that there is a fluid. We
would like to identify it with the lube oil mentioned in the
second sentence. In interpreting the second sentence, we
must prove the expression
(3 x)lube-oil(x)
If we had as an axiom
(V x)fluid(x) D lube-oil(x)
then we could establish the identity. But of course we
don&apos;t have such an axiom, for it isn&apos;t true. There are lots
of other kinds of fluids. There would seem to be no way
to use superset information in our scheme.
Fortunately, however, there is a way. We can make use
of this information by converting the axiom into a bicon-
ditional. In general, axioms of the form
species D genus
can be converted into a biconditional axiom of the form
genus A differentiae a species
7To prime this intuition, imagine two doors. Behind one is a car.
Behind the other is something with no top. You pick a door. If there&apos;s
a convertible behind it, you get to keep it. Which door would you
pick?
Often, of course, as in the above example, we will not
be able to prove the differentiae, and in many cases the
differentiae can not even be spelled out. But in our al,-
ductive scheme, this does not matter. They can simply be
assumed. In fact, we need not state them explicitly. We
can simply introduce a predicate which stands for all the
remaining properties. It will never be provable, but it will
be assumable. Thus, we can rewrite (5) as
</bodyText>
<equation confidence="0.551067">
x)fluid(x) A etci(x) lube-oil(x)
</equation>
<bodyText confidence="0.99939875">
Then the fact that something is fluid can be used as evi-
dence for its being lube oil. With the weights distributed
according to semantic contribution, we can go to extremes
and use an axiom like
</bodyText>
<equation confidence="0.68019">
(V x)mammal(x).2 A etc2(x).9 D elephant(x)
</equation>
<bodyText confidence="0.999896111111111">
to allow us to use the fact that something is a mammal as
(weak) evidence that it is an elephant.
In principle, one should try to prove the entire logical
form of the sentence and the constraints at once. In this
global strategy, any heuristic ordering of the individual
problems is done by the theorem prover. From a practi-
cal point of view, however, the global strategy generally
takes longer, sometimes significantly so, since it presents
the theorem-prover with a longer expression to be proved.
We have experimented both with this strategy and with
a bottom-up strategy in which, for example, we try to
identify the lube oil before trying to identify the lube oil
alarm. The latter is quicker since it presents the theorem-
prover with problems in a piecemeal fashion, but the for-
mer frequently results in better interpretations since it is
better able to exploit redundancies. The analysis of the
sentence in Section 4.2 below, for example, requires either
the global strategy or very careful axiomatization. The
bottom-up strategy, with only a view of a small local re-
gion of the sentence, cannot recognize and capitalize on
redundancies among distant elements in the sentence. Ide-
ally, we would like to have detailed control over the proof
process to allow a number of different factors to interact in
determining the allocation of deductive resources. Among
such factors would be word order, lexical form, syntactic
structure, topic-comment structure, and, in speech, pitch
accent.°
</bodyText>
<sectionHeader confidence="0.99983" genericHeader="method">
4 Examples
</sectionHeader>
<subsectionHeader confidence="0.999939">
4.1 Distinguishing the Given and New
</subsectionHeader>
<bodyText confidence="0.995371375">
We will examine two difficult definite reference problems in
which the given and the new information are intertwined
and must be separated. In the first, new and old informa-
tion about the same entity are encoded in a single noun
phrase.
&apos;Pereira and Pollack&apos;s CANDIDE system (1988) is specifically de-
signed to aid investigation of the question of the most effective order
of interpretation.
</bodyText>
<page confidence="0.997157">
99
</page>
<bodyText confidence="0.991279666666667">
There was adequate lube oil.
We know about the lube oil already, and there is a corre-
sponding axiom in the knowledge base.
</bodyText>
<equation confidence="0.7133864">
lube-oil(0)
Its adequacy is new information, however. It is what the
sentence is telling us.
The logical form of the sentence is, roughly,
(3 o)lube-oil(o) A adequate(o)
</equation>
<bodyText confidence="0.9874599">
This is the expression that must be derived. The proof of
the existence of the lube oil is immediate. It is thus old
information. The adequacy can&apos;t be proved, and is hence
assumed as new information.
The second example is from Clark (1975), and illustrates
what happens when the given and new information are
combined into a single lexical item.
John walked into the room.
The chandelier shone brightly.
What chandelier is being referred to?
</bodyText>
<listItem confidence="0.329596333333333">
Let us suppose we have in our knowledge base the fact
that rooms have lights.
(6) (V r)roorri(r) D (3 °lig ht(I) A in(1,r)
</listItem>
<bodyText confidence="0.7398735">
Suppose we also have the fact that lights with numerous
fixtures are chandeliers.
</bodyText>
<equation confidence="0.976203">
(7) (V 1)light(1) A has- f ixtUres(1) D chandelier(1)
</equation>
<bodyText confidence="0.999671272727273">
The first sentence has given us the existence of a room—
roorn(R). To solve the definite reference problem in the
second sentence, we must prove the existence of a chande-
lier. Back-chaining on axiom (7), we see we need to prove
the existence of a light with fixtures. Back-chaining from
light(1) in axiom (6), we see we need to prove the exis-
tence of a room. We have this in room(R). To complete
the derivation, we assume the light 1 has fixtures. The
light is thus given by the room mentioned in the previous
sentence, while the fact that it has fixtures is new infor-
mation.
</bodyText>
<subsectionHeader confidence="0.999119">
4.2 Exploiting Redundancy
</subsectionHeader>
<bodyText confidence="0.9990525">
We next show the use of the abduction scheme in solving
internal coreference problems. Two problems raised by the
sentence
The plain was reduced by erosion to its present
level.
are determining what was eroding and determining what
&amp;quot;it&amp;quot; refers to. Suppose our knowledge base consists of the
following axioms:
</bodyText>
<equation confidence="0.921262857142857">
(Vp, 1, s)decrease(p, I, s) A vertical(s)
A etc3(P, 3) (3 el)reducel(ei,p,1)
or el is a reduction of p to 1 if and only if p decreases to 1
on some vertical scale s (plus some other conditions).
(Vp)/andforrn(p) A f lat(p) A etc4(p) plain(p)
or p is a plain if and only if p is a flat landform (plus some
other conditions).
(V e, y, I, s)ati (e, y , 1) A on(I, s) A vertical(s)
A f lat(y) A etc5(e, y, 1, s) a lever (e, I , y)
or e is the condition of l&apos;s being the level of y if and only
if e is the condition of y&apos;s being at 1 on some vertical scale
s and y is flat (plus some other conditions).
(V x, I, s)decrease(x, 1, s) A landform(x)
A altitude(s) A etc.6(y, I, s) F.. (3 e)erodei (e, x)
</equation>
<bodyText confidence="0.874021666666667">
or e is an eroding of x if and only if x is a landform that
decreases to some point Ion the altitude scale a (plus some
other conditions).
</bodyText>
<equation confidence="0.919845714285714">
(V s)vertical(a) A etc7(p) s altitude(s)
or s is the altitude scale if and only if s is vertical (plus
some other conditions).
Now the analysis. The logical form of the sentence is
roughly
(3 e1, p, I, x, e2, y)reducei(ei , p, 1) A plain(p)
A erode(ei,x) A present(e2) A lever(e2,11Y)
</equation>
<bodyText confidence="0.9397442">
Our characterization of interpretation says that we must
derive this expression from the axioms or from assump-
tions. Back-chaining on reduce&apos; (el, p, I) yields
decrease(p, 1, si) A vertical(s1) A etc3(p, 1, si )
Back-chaining on erode&apos; (el, x) yields
</bodyText>
<equation confidence="0.858573">
decrease(x, 12,32) A landform(r) A altitude(s2)
A etc6(x, 12, 32)
and back-chaining on altitude(32) in turn yields
vertical(s2) A etcr(32)
</equation>
<bodyText confidence="0.9991282">
We unify the goals decrease(p, I, si) and decrease(x , 12, 32),
and thereby identify the object of the erosion with the
plain. The goals vertical(31) and vertical(s2) also unify,
telling us the reduction was on the altitude scale. Back-
chaining on plain(p) yields
</bodyText>
<equation confidence="0.360841">
landform(p) A f lat(p) A etc4(P)
</equation>
<bodyText confidence="0.996847333333333">
and landf orrn(x) unifies with landf orm(p), reinforcing our
identification of the object of the erosion with the plain.
Back-chaining on lever (e2, I, y). yields
</bodyText>
<page confidence="0.795078">
100
</page>
<equation confidence="0.7028645">
at&apos;(e2, y, I) A on(I, 33) A vertical(s3) A flat(y)
A etc5(p)
</equation>
<bodyText confidence="0.999929833333333">
and vertical(33) and vertical(s2) unify, as do flat(y) and
flat(p), thereby identifying &amp;quot;it&amp;quot;, or y, as the plain p. We
have not written out the axioms for this, but note also that
&amp;quot;present&amp;quot; implies the existence of a change of level, or a
change in the location of &amp;quot;it&amp;quot; on a vertical scale, and a
decrease of a plain is a change of the plain&apos;s location on a
vertical scale. Unifying these would provide reinforcement
for our identification of &amp;quot;it&amp;quot; with the plain. Now assum-
ing the most specific atoms we have derived including all
the &amp;quot;et cetera&amp;quot; conditions, we arrive at an interpretation
that is minimal and that solves the internal coreference
problems as a byproduct.
</bodyText>
<subsectionHeader confidence="0.9929205">
4.3 A Thorough Integration of Syntax,
Semantics, and Pragmatics
</subsectionHeader>
<bodyText confidence="0.999981533333333">
By combining the idea of interpretation as abduction with
the older idea of parsing as deduction (Kowalski, 1980, pp.
52-53; Pereira and Warren, 1983), it becomes possible to
integrate syntax, semantics, and pragmatics in a very thor-
ough and elegant way.a Below is a simple grammar written
in Prolog style, but incorporating calls to local pragmatics.
The syntax portion is represented in standard Prolog man-
ner, with nonterminals treated as predicates and having as
two of its arguments the beginning and end points of the
phrase spanned by the nonterminal. The one modification
we would have to make to the abduction scheme is to allow
conjuncts in the antecedents to take costs directly as well
as weights. Constraints on the application of phrase struc-
ture rules have been omitted, but could be incorporated in
the usual way.
</bodyText>
<equation confidence="0.882570708333333">
(V i, j,k,x,p,args,req,e,c,rel)np(i, j, x)
A vp( j, k,p,args,req) A ./1(e, c)53 A rel(c, x)3&amp;quot;
subst(req, cons(c,args))sio Ds(i, k, e)
(Vi, j, k, e, p, ergs, req, el, c,tel)s(i, j, e)
A pp(j, k, p, args, req) A p&apos;(ei , c)&amp;quot; A rel(c, 092o
A subst(req, cons(c,args))sio k,eszeo
(V j, k, w, z, c, rel)v(i, j,w) A np(j, k, x)
A re/(c, z)s2o
vp(i,k, Az[w(z, c)], &lt;c&gt;, Req(w))
(V i,j, k, x)det(i, j,&amp;quot;then) A cn(j, k, x, p)
A p(x)sw np(i, k, x)
(V i, j, k, x)det(i, j,&amp;quot;a&amp;quot;) A cn(j,k,x, p) A p(x)u
np(i, k,x)
(Vi, j,k,w,x,y,p,nn)n(i, j,w) A cn(j,k,x,p)
A w(y)&amp;quot; A nn(y, r)s2o
(V j, k,x,p5,p2,args,req, c,rel)cn(i, j, z, p,)
A pp(j, k,p2,args,req)
°This idea is due to Stuart Shieber.
A subst(req, cons(c, args))m A rel(c, z)52o
D cn(i , k , ).z[pi(z) A p2(z)1)
(Vi, j, w)n(i, j, w) (3 x)cn(i, j, , w)
(V j, k, w, x,c,rel)prep(i, j ,w) A np(j, k, x)
A rel(c. x)s2o
D pp(i, k, )z(w(c, z)j, &lt;c&gt;,Req(w))
</equation>
<bodyText confidence="0.99988575">
For example, the first axiom says that there is a sentence
from point i to point k asserting eventuality e if there
is a noun phrase from i to j referring to x and a verb
phrase from j to Jr denoting predicate p with arguments
args and having an associated requirement req, and there
is (or, for $3, can be assumed to be) an eventuality e of
p&apos;s being true of c, where c is related to or coercible from
x (with an assumability cost of $20), and the requirement
req associated with p can be proved or, for $10, assumed to
hold of the arguments of p. The symbol edzei denotes the
conjunction of eventualities e and ei (See Hobbs (1985b),
p. 35.) The third argument of predicates corresponding to
terminal nodes such as n and det is the word itself, which
then becomes the name of the predicate. The function
Req returns the requirements associated with a predicate,
and subst takes care of substituting the right arguments
into the requirements. &lt;c&gt; is the list consisting of the
single element c, and cons is the LISP function cons. The
relations rel and nn are treated here as predicate variables,
but they could be treated as predicate constants, in which
case we would not have quantified over them.
In this approach, s(0, n, e) can be read as saying there is
an interpretable sentence from point 0 to point is (asserting
e). Syntax is captured in predicates like np, vp, and s.
Compositional semantics is encoded in, for example, the
way the predicate p&apos; is applied to its arguments in the first
axiom, and in the lambda expression in the third argument
of vp in the third axiom. Local pragmatics is captured by
virtue of the fact that in order to prove s(0, n, e), one must
derive the logical form of the sentence together with the
constraints predicates impose on their arguments, allowing
for metonymy.
Implementations of different orders of interpretation,
or different sorts of interaction among syntax, composi-
tional semantics, and local pragmatics, can then be seen
as different orders of search for a proof of s(0, n, e). In
a syntax-first order of interpretation, one would try first
to prove all the &amp;quot;syntactic&amp;quot; atoms, such as np(i, j. x),
before any of the &amp;quot;local pragmatic&amp;quot; atoms, such as
p&apos;(e, c). Verb-driven interpretation would first try to prove
vp(j , k, p, args, req) by proving v(i, j, w) and then using the
information in the requirements associated with the verb
to drive the search for the arguments of the verb, by de-
riving subst(req, cons(c,args)) before trying to prove the
various np atoms. But more fluid orders of interpreta-
tion are obviously possible. This formulation allows one
to prove those things first which are easiest to prove. It is
also easy to see how processing could occur in parallel.
</bodyText>
<page confidence="0.996693">
101
</page>
<bodyText confidence="0.999953333333333">
It is moreover possible to deal with ill-formed or uncleaz
input in this framework, by having axioms such as this
revision of our first axiom above.
</bodyText>
<figure confidence="0.336612">
(V j, k, x ,p, args, req, e, c, re/)np(i, j, x).4
A vp(j , k,p, args, req)-8 A p&apos;(e, c)&amp;quot;
A rel(c, x)s&amp;quot; A subst(req, cons(c,ra g,))sio
D s(i, k,e)
</figure>
<bodyText confidence="0.999261125">
This says that a verb phrase provides more evidence for
a sentence than a noun phrase does, but either one can
constitute a sentence if the string of words is otherwise
interpretable.
It is likely that this approach could be extended to
speech recognition by using Prolog-style rules to decom-
pose morphemes into their phonemes and weighting them
according to their acoustic prominence.
</bodyText>
<sectionHeader confidence="0.9962435" genericHeader="method">
5 Controlling Abduction: Type
Hierarchy
</sectionHeader>
<bodyText confidence="0.995800303030303">
The first example on which we tested the new abductive
scheme was the sentence
There was adequate lube oil.
The system got the correct interpretation, that the lube oil
was the lube oil in the lube oil system of the air compressor,
and it assumed that that lube oil was adequate. But it
also got another interpretation. There is a mention in the
knowledge base of the adequacy of the lube oil pressure, so
it identified that adequacy with the adequacy mentioned
in the sentence. It then assumed that the pressure was
lube oil.
It is clear what went wrong here. Pressure is a magni-
tude whereas lube oil is a material, and magnitudes can&apos;t
be materials. In principle, abduction requires a check for
the consistency of what is assumed, and our knowledge
base should have contained axioms from which it could be
inferred that a magnitude is not a material. In practice,
unconstrained consistency checking is undecidable and, at
best, may take a long time. Nevertheless, one can, through
the use of a type hierarchy, eliminate a very large number
of possible assumptions that are likely to result in an in-
consistency. We have consequently implemented a module
which specifies the types that various predicate-argument
positions can take on, and the likely disjointness relations
among types. This is a way of exploiting the specificity
of the English lexicon for computational purposes. This
addition led to a speed-up of two orders of magnitude.
There is a problem, however. In an ontologically promis-
cuous notation, there is no commitment in a primed propo-
sition to truth or existence in the real world. Thus, lube-
oil&apos; (e, o) does not say that o is lube oil or even that it
exists; rather it says that e is the eventuality of o&apos;s being
lube oil. This eventuality may or may not exist in the real
world. If it does, then we would express this as Rexists( e).
and from that we could derive from axioms the existence
of o and the fact that it is lube oil. But e&apos;s existential
status could be something different. For example, e could
be nonexistent, expressed as not(e) in the notation, and
in English as &amp;quot;The eventuality e of o&apos;s being lube oil does
not exist,&amp;quot; or as &amp;quot;o is not lube oil.&amp;quot; Or e may exist only
in someone&apos;s beliefs. While the axiom
(V x)pressure(x) D ,lube-oil(x)
is certainly true, the axiom
(V ei, x)pressure(ei, x) D e2)lube-oir(e2, x)
would not be true. The fact that a variable occupies the
second argument position of the predicate lube-oil&apos; does
not mean it is lube oil. We cannot properly restrict that
argument position to be lube oil, or fluid, or even a ma-
terial, for that would rule out perfectly true sentences like
&amp;quot;Truth is not lube oil.&amp;quot;
Generally, when one uses a type hierarchy, one assumes
the types to be disjoint sets with cleanly defined bound-
aries, and one assumes that predicates take arguments of
only certain types. There are a lot of problems with this
idea. In any case, in our work, we are not buying into this
notion that the universe is typed. Rather we are using the
type hierarchy strictly as a heuristic, as a set of guesses
not about what could or could not be but about what it
would or would not occur to someone to atty. When two
types are declared to be disjoint, we are saying that they
are certainly disjoint in the real world, and that they are
very probably disjoint everywhere except in certain bizarre
modal contexts. This means, however, that we risk failing
on certain rare examples. We could not, for example, deal
with the sentence, &amp;quot;It then assumed that the pressure was
lube oil.&amp;quot;
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="discussions">
6 Future Directions
</sectionHeader>
<bodyText confidence="0.999914555555556">
Deduction is explosive, and since the abduction scheme
augments deduction with the assumptions, it is even more
explosive. We are currently engaged in an empirical in-
vestigation of the behavior of this abductive scheme on a
very large knowledge base performing sophisticated pro-
cessing. In addition to type checking, we have introduced
two other techniques that are necessary for controlling the
explosion--unwinding recursive axioms and making use of
syntactic noncoreference information. We expect our in-
vestigation to continue to yield techniques for controlling
the abduction process.
We are also looking toward extending the interpretation
processes to cover lexical ambiguity, quantifier scope am-
biguity and metaphor interpretation problems as well. We
will also be investigating the integration proposed in Sec-
tion 4.3 and an approach that integrates all of this with
the recognition of discourse structure and the recognition
of relations between utterances and the hearer&apos;s interests.
</bodyText>
<page confidence="0.99846">
102
</page>
<sectionHeader confidence="0.999139" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9022474">
The authors have profited from discussions with Todd
Davies, John Lowrance, Stuart Shieber, and Mabry Tyson
about this work. The research was funded by the Defense
Advanced Research Projects Agency under Office of Naval
Research contract N00014-85-C-0013.
</bodyText>
<sectionHeader confidence="0.995908" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999973670886076">
[1] Bear, John, and Jerry R.. Hobbs, 1988. &amp;quot;Localizing the
Expression of Ambiguity&amp;quot;, Proceedings, Second Confer-
ence on Applied Natural Language Processing, Austin,
Texas, February, 1988.
[2] Charniak, Eugene, 1986. &amp;quot;A Neat Theory of Markel-
Passing&amp;quot;, Proceedings, AAAI-86, Fifth National Con-
ference on Artificial Intelligence, Philadelphia, Pennsyl-
vania, pp. 584-588.
[3] Clark,Herbert, 1975. &amp;quot;Bridging&amp;quot;. In R.. Schank and
B. Nash-Webber (Eds.), Theoretical Issues in Natu-
ral Language Processing, pp. 169-174. Cambridge, Mas-
sachusetts.
[4] Cox, P. T., and T. Pietrzykowski, 1986. &amp;quot;Causes for
Events: Their Computation and Applications&amp;quot;, Proceed-
ings, CADE-8.
[5] Downing, Pamela, 1977. &amp;quot;On the Creation and Use of
English Compound Nouns&amp;quot;, Language, vol. 53, no. 4,
pp. 810-842.
[6] Hobbs, Jerry R., 1983. &amp;quot;An Improper Treatment of
Quantification in Ordinary English&amp;quot;, Proceedings of the
21st Annual Meeting, Association for Computational
Linguistics, pp. 57-63. Cambridge, Massachusetts, June
1983.
[7] Hobbs, Jerry R.. 1985a. &amp;quot;Ontological promiscuity.&amp;quot; Pro-
ceedings, 23rd Annual Meeting of the Association for
Computational Linguistics, pp. 61-69.
[8] Hobbs, Jerry R., 1985b, &amp;quot;The Logical Notation: Onto-
logical Promiscuity&amp;quot;, manuscript.
[9] Hobbs, Jerry (1986) &amp;quot;Overview of the TACITUS
Project&amp;quot;, CL, Vol. 12, No. 3.
[10] Hobbs, Jerry R., William Croft, Todd Davies, Dou-
glas Edwards, and Kenneth Laws, 1986. &amp;quot;Commonsense
Metaphysics and Lexical Semantics&amp;quot;, Proceedings, 24th
Annual Meeting of the Association for Computational
Linguistics, New York, June 1986., pp. 231-240.
[11] Hobbs, Jerry R.., and Paul Martin 1987. &amp;quot;Local Prag-
matics&amp;quot;. Proceedings, International Joint Conference on
Artificial Intelligence, pp. 520-523. Milano, Italy, Au-
gust 1987.
[12] Jobs, Martin, 1972. &amp;quot;Semantic Axiom Number One&amp;quot;,
Language, pp. 257-265.
[13] Kowalski, Robert, 1980. The Logic of Problem Solt-
ing, North Holland, New York.
[14] Levi, Judith, 1978. The Syntax and Semantics of
Complex Nominal.,, Academic Press, New York.
[15] Norvig, Peter, 1987. &amp;quot;Inference in Text Understand-
ing&amp;quot;, Proceedings, AAAI-87, Sixth National Confer-
ence on Artificial Intelligence, Seattle, Washington, July
1987.
[16] Nunberg, GeOffery, 1978. &amp;quot;The Pragmatics of Refer-
ence&amp;quot;, Ph. D. thesis, City University of New York, New
York.
[17] Pereira, Fernando C. N., and Martha E. Pollack, 1988.
&amp;quot;An Integrated Framework for Semantic and Pragmatic
Interpretation&amp;quot;, to appear in Proceedings, 26th Annual
Meeting of the Association for Computational Linguis-
tics, Buffalo, New York, June 1988.
[18] Pereira, Fernando C. N., and David H. D. Warren,
1983. &amp;quot;Parsing as Deduction&amp;quot;, Proceedings of the 21st
Annual Meeting, Association for Computational Lin-
guistics, pp. 137-144. Cambridge, Massachusetts, June
1983.
[19] Pople, Harry E., Jr., 1973, &amp;quot;On the Mechanization
of Abductive Logic&amp;quot;, Proceedings, Third International
Joint Conference on Artificial Intelligence, pp. 147-152,
Stanford, California, August 1973.
[20] Stickel, Mark E., 1982. &amp;quot;A Nonclausal Connection-
Graph Theorem-Proving Program&amp;quot;, Proceedings, A AAI-
82 National Conference on Artificial Intelligence, Pitts-
burgh, Pennsylvania, pp. 229-233.
[21] Stickel, Mark E., 1988. &amp;quot;A Prolog-like Inference Sys-
tem for Computing Minimum-Cost Abductive Explana-
tions in Natural-Language Interpretation&amp;quot;, forthcoming.
[22] Thagard, Paul R., 1978. &amp;quot;The Best Explanation: Cri-
teria for Theory Choice&amp;quot;, The Journal of Philosophy,
pp. 76-92.
[23] Wilks, Yorick, 1972. Grammar, Meaning, and the Ma-
chine Analysis of Language, Routledge and Kegan Paul,
London.
</reference>
<page confidence="0.999298">
103
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.927837">
<title confidence="0.998287">Interpretation as Abduction</title>
<author confidence="0.9890165">Jerry R Hobbs</author>
<author confidence="0.9890165">Mark Stickel</author>
<author confidence="0.9890165">Paul Martin</author>
<author confidence="0.9890165">Douglas Edwards</author>
<affiliation confidence="0.999275">Artificial Intelligence Center SRI International</affiliation>
<abstract confidence="0.994046111111111">To interpret a sentence: An approach to abductive inference developed in the TAC- ITUS project has resulted in a dramatic simplification of how the problem of interpreting texts is conceptualized. Its use in solving the local pragmatics problems of reference, compound nominals, syntactic ambiguity, and metonymy is described and illustrated. It also suggests an elegant and thorough integration of syntax, semantics, and pragmatics.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Bear</author>
<author>Jerry R Hobbs</author>
</authors>
<title>Localizing the Expression of Ambiguity&amp;quot;,</title>
<date>1988</date>
<booktitle>Proceedings, Second Conference on Applied Natural Language Processing,</booktitle>
<location>Austin, Texas,</location>
<marker>[1]</marker>
<rawString>Bear, John, and Jerry R.. Hobbs, 1988. &amp;quot;Localizing the Expression of Ambiguity&amp;quot;, Proceedings, Second Conference on Applied Natural Language Processing, Austin, Texas, February, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A Neat Theory of MarkelPassing&amp;quot;,</title>
<date>1986</date>
<booktitle>Proceedings, AAAI-86, Fifth National Conference on Artificial Intelligence,</booktitle>
<pages>584--588</pages>
<location>Philadelphia, Pennsylvania,</location>
<marker>[2]</marker>
<rawString>Charniak, Eugene, 1986. &amp;quot;A Neat Theory of MarkelPassing&amp;quot;, Proceedings, AAAI-86, Fifth National Conference on Artificial Intelligence, Philadelphia, Pennsylvania, pp. 584-588.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert Clark</author>
</authors>
<title>Bridging&amp;quot;. In</title>
<date>1975</date>
<booktitle>Theoretical Issues in Natural Language Processing,</booktitle>
<pages>169--174</pages>
<location>Cambridge, Massachusetts.</location>
<marker>[3]</marker>
<rawString>Clark,Herbert, 1975. &amp;quot;Bridging&amp;quot;. In R.. Schank and B. Nash-Webber (Eds.), Theoretical Issues in Natural Language Processing, pp. 169-174. Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P T Cox</author>
<author>T Pietrzykowski</author>
</authors>
<title>Causes for Events: Their Computation and Applications&amp;quot;,</title>
<date>1986</date>
<location>Proceedings, CADE-8.</location>
<marker>[4]</marker>
<rawString>Cox, P. T., and T. Pietrzykowski, 1986. &amp;quot;Causes for Events: Their Computation and Applications&amp;quot;, Proceedings, CADE-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pamela Downing</author>
</authors>
<title>On the Creation and Use of</title>
<date>1977</date>
<journal>English Compound Nouns&amp;quot;, Language,</journal>
<volume>53</volume>
<pages>810--842</pages>
<marker>[5]</marker>
<rawString>Downing, Pamela, 1977. &amp;quot;On the Creation and Use of English Compound Nouns&amp;quot;, Language, vol. 53, no. 4, pp. 810-842.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>An Improper Treatment of Quantification in Ordinary English&amp;quot;,</title>
<date>1983</date>
<booktitle>Proceedings of the 21st Annual Meeting, Association for Computational Linguistics,</booktitle>
<pages>57--63</pages>
<location>Cambridge, Massachusetts,</location>
<marker>[6]</marker>
<rawString>Hobbs, Jerry R., 1983. &amp;quot;An Improper Treatment of Quantification in Ordinary English&amp;quot;, Proceedings of the 21st Annual Meeting, Association for Computational Linguistics, pp. 57-63. Cambridge, Massachusetts, June 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Ontological promiscuity.&amp;quot;</title>
<date>1985</date>
<booktitle>Proceedings, 23rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>61--69</pages>
<marker>[7]</marker>
<rawString>Hobbs, Jerry R.. 1985a. &amp;quot;Ontological promiscuity.&amp;quot; Proceedings, 23rd Annual Meeting of the Association for Computational Linguistics, pp. 61-69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>The Logical Notation: Ontological Promiscuity&amp;quot;,</title>
<date>1985</date>
<note>manuscript.</note>
<marker>[8]</marker>
<rawString>Hobbs, Jerry R., 1985b, &amp;quot;The Logical Notation: Ontological Promiscuity&amp;quot;, manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry Hobbs</author>
</authors>
<title>Overview of the TACITUS Project&amp;quot;,</title>
<date>1986</date>
<journal>CL,</journal>
<volume>12</volume>
<marker>[9]</marker>
<rawString>Hobbs, Jerry (1986) &amp;quot;Overview of the TACITUS Project&amp;quot;, CL, Vol. 12, No. 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>William Croft</author>
<author>Todd Davies</author>
<author>Douglas Edwards</author>
<author>Kenneth Laws</author>
</authors>
<title>Commonsense Metaphysics and Lexical Semantics&amp;quot;,</title>
<date>1986</date>
<booktitle>Proceedings, 24th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>231--240</pages>
<location>New York,</location>
<marker>[10]</marker>
<rawString>Hobbs, Jerry R., William Croft, Todd Davies, Douglas Edwards, and Kenneth Laws, 1986. &amp;quot;Commonsense Metaphysics and Lexical Semantics&amp;quot;, Proceedings, 24th Annual Meeting of the Association for Computational Linguistics, New York, June 1986., pp. 231-240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>Paul Martin</author>
</authors>
<title>Local Pragmatics&amp;quot;.</title>
<date>1987</date>
<booktitle>Proceedings, International Joint Conference on Artificial Intelligence,</booktitle>
<pages>520--523</pages>
<location>Milano, Italy,</location>
<marker>[11]</marker>
<rawString>Hobbs, Jerry R.., and Paul Martin 1987. &amp;quot;Local Pragmatics&amp;quot;. Proceedings, International Joint Conference on Artificial Intelligence, pp. 520-523. Milano, Italy, August 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Jobs</author>
</authors>
<title>Semantic Axiom Number One&amp;quot;, Language,</title>
<date>1972</date>
<pages>257--265</pages>
<marker>[12]</marker>
<rawString>Jobs, Martin, 1972. &amp;quot;Semantic Axiom Number One&amp;quot;, Language, pp. 257-265.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Kowalski</author>
</authors>
<title>The Logic of Problem Solting,</title>
<date>1980</date>
<location>North Holland, New York.</location>
<marker>[13]</marker>
<rawString>Kowalski, Robert, 1980. The Logic of Problem Solting, North Holland, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith Levi</author>
</authors>
<title>The Syntax and Semantics of Complex Nominal.,,</title>
<date>1978</date>
<publisher>Academic Press,</publisher>
<location>New York.</location>
<marker>[14]</marker>
<rawString>Levi, Judith, 1978. The Syntax and Semantics of Complex Nominal.,, Academic Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Norvig</author>
</authors>
<title>Inference in Text Understanding&amp;quot;,</title>
<date>1987</date>
<booktitle>Proceedings, AAAI-87, Sixth National Conference on Artificial Intelligence,</booktitle>
<location>Seattle, Washington,</location>
<marker>[15]</marker>
<rawString>Norvig, Peter, 1987. &amp;quot;Inference in Text Understanding&amp;quot;, Proceedings, AAAI-87, Sixth National Conference on Artificial Intelligence, Seattle, Washington, July 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GeOffery Nunberg</author>
</authors>
<title>The Pragmatics of Reference&amp;quot;,</title>
<date>1978</date>
<tech>Ph. D. thesis,</tech>
<institution>City University of New</institution>
<location>York, New York.</location>
<marker>[16]</marker>
<rawString>Nunberg, GeOffery, 1978. &amp;quot;The Pragmatics of Reference&amp;quot;, Ph. D. thesis, City University of New York, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>Martha E Pollack</author>
</authors>
<title>An Integrated Framework for Semantic and Pragmatic Interpretation&amp;quot;, to appear in</title>
<date>1988</date>
<booktitle>Proceedings, 26th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Buffalo, New York,</location>
<marker>[17]</marker>
<rawString>Pereira, Fernando C. N., and Martha E. Pollack, 1988. &amp;quot;An Integrated Framework for Semantic and Pragmatic Interpretation&amp;quot;, to appear in Proceedings, 26th Annual Meeting of the Association for Computational Linguistics, Buffalo, New York, June 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando C N Pereira</author>
<author>David H D Warren</author>
</authors>
<title>Parsing as Deduction&amp;quot;,</title>
<date>1983</date>
<booktitle>Proceedings of the 21st Annual Meeting, Association for Computational Linguistics,</booktitle>
<pages>137--144</pages>
<location>Cambridge, Massachusetts,</location>
<marker>[18]</marker>
<rawString>Pereira, Fernando C. N., and David H. D. Warren, 1983. &amp;quot;Parsing as Deduction&amp;quot;, Proceedings of the 21st Annual Meeting, Association for Computational Linguistics, pp. 137-144. Cambridge, Massachusetts, June 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harry E Pople</author>
</authors>
<title>On the Mechanization of Abductive Logic&amp;quot;,</title>
<date>1973</date>
<booktitle>Proceedings, Third International Joint Conference on Artificial Intelligence,</booktitle>
<pages>147--152</pages>
<location>Stanford, California,</location>
<marker>[19]</marker>
<rawString>Pople, Harry E., Jr., 1973, &amp;quot;On the Mechanization of Abductive Logic&amp;quot;, Proceedings, Third International Joint Conference on Artificial Intelligence, pp. 147-152, Stanford, California, August 1973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark E Stickel</author>
</authors>
<title>A Nonclausal ConnectionGraph Theorem-Proving Program&amp;quot;,</title>
<date>1982</date>
<booktitle>Proceedings, A AAI82 National Conference on Artificial Intelligence,</booktitle>
<pages>229--233</pages>
<location>Pittsburgh, Pennsylvania,</location>
<marker>[20]</marker>
<rawString>Stickel, Mark E., 1982. &amp;quot;A Nonclausal ConnectionGraph Theorem-Proving Program&amp;quot;, Proceedings, A AAI82 National Conference on Artificial Intelligence, Pittsburgh, Pennsylvania, pp. 229-233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark E Stickel</author>
</authors>
<title>A Prolog-like Inference System for Computing Minimum-Cost Abductive Explanations in Natural-Language Interpretation&amp;quot;,</title>
<date>1988</date>
<location>forthcoming.</location>
<marker>[21]</marker>
<rawString>Stickel, Mark E., 1988. &amp;quot;A Prolog-like Inference System for Computing Minimum-Cost Abductive Explanations in Natural-Language Interpretation&amp;quot;, forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul R Thagard</author>
</authors>
<title>The Best Explanation: Criteria for Theory Choice&amp;quot;,</title>
<date>1978</date>
<journal>The Journal of Philosophy,</journal>
<pages>76--92</pages>
<marker>[22]</marker>
<rawString>Thagard, Paul R., 1978. &amp;quot;The Best Explanation: Criteria for Theory Choice&amp;quot;, The Journal of Philosophy, pp. 76-92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick Wilks</author>
</authors>
<title>Grammar, Meaning, and the Machine Analysis of Language, Routledge and Kegan Paul,</title>
<date>1972</date>
<location>London.</location>
<marker>[23]</marker>
<rawString>Wilks, Yorick, 1972. Grammar, Meaning, and the Machine Analysis of Language, Routledge and Kegan Paul, London.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>