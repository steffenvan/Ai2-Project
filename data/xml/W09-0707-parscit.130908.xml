<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012875">
<title confidence="0.9968325">
Development of an Amharic Text-to-Speech System
Using Cepstral Method
</title>
<author confidence="0.912578">
Tadesse Anberbir Tomio Takara
</author>
<affiliation confidence="0.875553">
ICT Development Office, Addis Faculty of Engineering, University of
Ababa University, Ethiopia the Ryukyus, Okinawa, Japan
</affiliation>
<email confidence="0.997367">
tadanberbir@gmail.com takara@ie.u—ryukyu.ac.jp
</email>
<sectionHeader confidence="0.993853" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998603695652174">
This paper presents a speech synthesis system
for Amharic language and describes and how
the important prosodic features of the lan-
guage were modeled in the system. The devel-
oped Amharic Text-to-Speech system
(AmhTTS) is parametric and rule-based that
employs a cepstral method. The system uses a
source filter model for speech production and
a Log Magnitude Approximation (LMA) filter
as the vocal tract filter. The intelligibility and
naturalness of the system was evaluated by
word and sentence listening tests respectively
and we achieved 98% correct-rates for words
and an average Mean Opinion Score (MOS) of
3.2 (which is categorized as good) for sen-
tences listening tests. The synthesized speech
has high intelligibility and moderate natural-
ness. Comparing with previous similar study,
our system produced considerably similar
quality speech with a fairly good prosody. In
particular our system is mainly suitable for
building new languages with little modifica-
tion.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999984909090909">
Text-to-Speech (TTS) synthesis is a process
which artificially produces synthetic speech for
various applications such as services over tele-
phone, e-document reading, and speaking system
for handicapped people etc.
The two primary technologies for generating
synthetic speech are concatenative synthesis and
formant (Rule-based) synthesis methods. Con-
catenative synthesis produces the most natural-
sounding synthesized speech. However, it re-
quires a large amount of linguistic resources and
generating a various speaking style is a challeng-
ing task. In general the amount of work required
to build a concatenative system is enormous. Par-
ticularly, for languages with limited linguistic
resources, it is more difficult. On the other hand,
formant synthesis method requires small linguis-
tic resources and able to generate various speak-
ing styles. It is also suitable for mobile applica-
tions and easier for customization. However, this
method produced less natural-sounding synthe-
sized speech and the complex rules required to
model the prosody is a big problem.
In general, each method has its own strengths
and weaknesses and there is always a tradeoff.
Therefore, which approach to use will be deter-
mined by the intended applications, the availabil-
ity of linguistic resources of a given language
etc. In our research we used formant (rule-based)
synthesis method because we are intending to
prepare a general framework for Ethiopian Se-
mitic languages and apply it for mobile devices
and web embedded applications.
Currently, many speech synthesis systems are
available mainly for `major&apos; languages such as
English, Japanese etc. and successful results are
obtained in various application areas. However,
thousands of the world&apos;s `minor&apos; languages lack
such technologies, and researches in the area are
quite very few. Although recently many localiza-
tion projects (like the customization of Festvox1)
are being undergoing for many languages, it is
quite inadequate and the localization process is
not an easy task mainly because of the lack of
linguistic resources and absence of similar works
in the area. Therefore, there is a strong demand
for the development of a speech synthesizer for
many of the African minor languages such as
Amharic.
Amharic, the official language of Ethiopia, is
a Semitic language that has the greatest number
of speakers after Arabic. According to the 1998
census, Amharic has 17.4 million speaker as a
mother thong language and 5.1 million speakers
as a second language. However, it is one of the
</bodyText>
<footnote confidence="0.997539666666667">
1 Festvox is a voice building framework which offers gen-
eral tools for building unit selection voices for new lan-
guages.
</footnote>
<note confidence="0.4638395">
Proceedings of the EACL 2009 Workshop on Language Technologies for African Languages – AfLaT 2009, pages 46–52,
Athens, Greece, 31 March 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.998659">
46
</page>
<figure confidence="0.993712666666667">
1st 2nd 3rd 4th 5th 6th 7th
C/e/ C/u/ C/i/ C/a/ C/ie/ C C/o/
ቸ ቹ ቺ Y ቼ T ቾ
</figure>
<figureCaption confidence="0.999955">
Figure 1: Amharic Syllables structure
</figureCaption>
<bodyText confidence="0.999968966666667">
least supported and least researched languages in
the world. Although, recently, the development
of different natural language processing (NLP)
tools for analyzing Amharic text has begun, it is
often very far comparing with other languages
(Alemu et al., 2003). Particularly, researches
conducted on language technologies like speech
synthesis and the application of such technolo-
gies are very limited or unavailable. To the
knowledge of the authors, so far there is only one
published work (Sebsibe, 2004) in the area of
speech synthesis for Amharic. In this study they
tried to describe the issues to be considered in
developing a concatenative speech synthesizer
using Festvox and recommended using syllables
as a basic unit for high quality speech synthesis.
In our research we developed a syllabic based
TTS system with prosodic control method which
is the first rule-based system published for Am-
haric. The designed Amharic TTS (AmhTTS) is
parametric and rule-based system that employs a
Cepstral method and uses a Log Magnitude Ap-
proximation (LMA) filter. Unlike the previous
study, Sebsibe (2004), our study provides a total
solution on prosodic information generation
mainly by modeling the durations. The system is
expected to have a wide range of applications,
for example, in software aids to visually im-
paired people, in mobile phones and can also be
easily customized for other Ethiopian languages.
</bodyText>
<sectionHeader confidence="0.952066" genericHeader="method">
2 Amharic Language&apos;s Overview
</sectionHeader>
<bodyText confidence="0.999956142857143">
Amharic (hoxኛ) is a Semitic language and it is
one of the most widely spoken languages in
Ethiopia. It has its own non Latin based syllabic
script called &amp;quot;Fidel&amp;quot; or &amp;quot;Abugida&amp;quot;. The ortho-
graphic representation of the language is organ-
ized into orders (derivatives) as shown in Fig.1.
Six of them are CV (C is a consonant, V is a
vowel) combinations while the sixth order is the
consonant itself. In total there are 32 consonants
and 7 vowels with 7x32= 224 Syllables. But
since there are redundant sounds that represent
the same sounds, the phonemes are only 28 (see
the Appendix).
Like other languages, Amharic also has its
own typical phonological and morphological fea-
tures that characterize it. The following are some
of the striking features of Amharic phonology
that gives the language its characteristic sound
when one hears it spoken: the weak, indetermi-
nate stress; the presence of glottalic, palatal, and
labialized consonants; the frequent gemination of
consonants and central vowels; and the use of an
automatic helping vowel (Bender et al., 1976).
Gemination in Amharic is one of the most
distinctive characteristics of the cadence of the
speech, and also caries a very heavy semantic
and syntactic functional weight (Bender and Fu-
lass, 1978). Amharic gemination is either lexical
or morphological. Gemination as a lexical fea-
ture cannot be predicted. For instance, hA may
be read as ald meaning &apos;he said&apos;, or alld meaning
&apos;there is&apos;. Although this is not a problem for Am-
haric speakers, it is a challenging problem in
speech synthesis. As a morphological feature
gemination is more predictable in the verb than
in the noun, Bender and Fulass (1978). However,
this is also a challenging problem in speech syn-
thesis because to automatically identify the loca-
tion of geminated syllables, it requires analysis
and modeling of the complex morphology of the
language. The lack of the orthography of Am-
haric to show geminates is the main problem. In
this study, we used our own manual gemination
mark (`) insertion techniques (see Section 3.3.1).
The sixth order syllables are the other impor-
tant features of the language. Like geminates, the
sixth order syllables are also very frequent and
play a key role for proper pronunciation of
speech. In our previous study, (Tadesse and Ta-
kara, 2006) we found that geminates and sixth
order syllables are the two most important fea-
tures that play a key role for proper pronuncia-
tion of words. Therefore, in our study we mainly
consider these language specific features to de-
velop a high quality speech synthesizer for Am-
haric language.
</bodyText>
<sectionHeader confidence="0.995299" genericHeader="method">
3 AmhTTS System
</sectionHeader>
<bodyText confidence="0.999733909090909">
Amharic TTS synthesis system is a parametric
and rule based system designed based on the
general speech synthesis system. Fig.2. shows
the scheme of Amharic speech synthesis system.
The design is based on the general speech syn-
thesis system (Takara and Kochi, 2000). The sys-
tem has three main components, a text analysis
subsystem, prosodic generation module and a
speech synthesis subsystem. The following three
sub-sections discuss the details of each compo-
nent.
</bodyText>
<page confidence="0.999003">
47
</page>
<figureCaption confidence="0.998566">
Figure 2: Amharic Speech Synthesis System
</figureCaption>
<subsectionHeader confidence="0.999249">
3.1 Text Analysis
</subsectionHeader>
<bodyText confidence="0.999958166666667">
The text analysis subsystem extracts the linguis-
tic and prosodic information from the input text.
The program iterates through the input text and
extracts the gemination and other marks, and the
sequences of syllables using the syllabification
rule. The letter-to-sound conversion has simple
one-to-one mapping between orthography and
phonetic transcription (see Apendix). As defined
by (Baye, 2008; Dawkins, 1969) and others,
Amharic can be considered as a phonetic lan-
guage with relatively simple relationship be-
tween orthography and phonology.
</bodyText>
<subsectionHeader confidence="0.999986">
3.2 Speech Analysis and Synthesis systems
</subsectionHeader>
<bodyText confidence="0.99998346875">
First, as a speech database, all Amharic syllables
(196) were collected and their sounds were pre-
pared by recording on digital audio tape (DAT)
at a 48 kHz sampling rate and 16-bit value. After
that, they were down-sampled to 10 kHz for ana-
lyzing. All speech units were recorded with nor-
mal speaking rate.
Then, the speech sounds were analyzed by
the analysis system. The analysis system adopts
short-time cepstral analysis with frame length
25.6 ms and frame shifting time of 10 ms. A
time-domain Hamming window with a length of
25.6 ms is used in analysis. The cepstrum is de-
fined as the inverse Fourier transform of the
short-time logarithm amplitude spectrum (Furui,
2001). Cepstral analysis has the advantage that it
could separate the spectral envelope part and the
excitation part. The resulting parameters of
speech unit include the number of frames and,
for each frame, voiced/unvoiced (V/UV) deci-
sion, pitch period and cepstral coefficients c[m],
0 &lt;_ m &lt;_ 29. The speech database contains these
parameters as shown in fig.2.
Finally, the speech synthesis subsystem gen-
erates speech from pre-stored parameters under
the control of the prosodic rules. For speech syn-
thesis, the general source-filter model is used as
a speech production model as shown in fig.3.
The synthetic sound is produced using Log Mag-
nitude Approximation (LMA) filter (Imai, 1980)
as the system filter, for which cepstral coeffi-
cients are used to characterize the speech sound.
</bodyText>
<figureCaption confidence="0.999039">
Figure 3: Diagram of Speech Synthesis Model
</figureCaption>
<bodyText confidence="0.999964285714286">
The LMA filter presents the vocal tract charac-
teristics that are estimated in 30 lower-order que-
frency elements. The LMA filter is a pole-zero
filter that is able to efficiently represent the vocal
tract features for all speech sounds. The LMA
filter is controlled by cepstrum parameters as
vocal tract parameters, and it is driven by fun-
damental period impulse series for voiced sounds
and by white noise for unvoiced sounds. The
fundamental frequency (F0) of the speech is con-
trolled by the impulse series of the fundamental
period. The gain of the filter or the power of syn-
thesized speech is set by the 0th order cepstral
coefficient, c [0].
</bodyText>
<subsectionHeader confidence="0.996092">
3.3 Prosody Modeling
</subsectionHeader>
<bodyText confidence="0.999928555555555">
For any language, appropriate modeling of pros-
ody is the most important issue for developing a
high quality speech synthesizer.
In Amharic language segments duration is the
most important and useful component in prosody
control. It is shown that, unlike English language
in which the rhythm of the speech is mainly
characterized by stress (loudness), rhythm in
Amharic is mainly marked by longer and shorter
syllables depending on gemination of conso-
nants, and by certain features of phrasing
(Bender et al., 1976). Therefore it is very impor-
tant to model the syllables duration in AmhTTS
system. In this paper we propose a new segmen-
tal duration control methods for synthesizing a
high quality speech. Our rule-based TTS system
uses a compact rule-based prosodic generation
method in three phases:
</bodyText>
<listItem confidence="0.946685">
• modeling geminated consonants duration
</listItem>
<table confidence="0.624222866666667">
Fundamental Voiced/ Cepstral
frequency (F0) Unvoiced Coefficient
Speech database
Text
Input
Text
Analysis
Subsystem
Prosodic
Generation
Speech
Synthesis
Subsys-
Voice
Output
</table>
<page confidence="0.982197">
48
</page>
<listItem confidence="0.999006333333333">
• controlling of sixth order syllables dura-
tion
• assignment of a global intonation contour
</listItem>
<bodyText confidence="0.9956632">
Prosody is modeled by variations of pitch and
relative duration of speech elements. Our study
deals only with the basic aspects of prosody such
as syllables duration and phrase intonation.
Gemination is modeled as lengthened duration in
such a way geminated syllables are modeled on
word level. Phrase level duration is modeled as
well to improve prosodic quality. Prosodic
phrases are determined in simplified way by us-
ing text punctuation. To synthesize F0 contour
Fujisaki pitch model that superimpose both word
level and phrase level prosody modulations is
used (Takara and Jun, 1988).
The following sub-sections discuss the pro-
sodic control methods employed in our system.
</bodyText>
<subsectionHeader confidence="0.539291">
3.3.1 Gemination rule
</subsectionHeader>
<bodyText confidence="0.999927609756098">
Accurate estimation of segmental duration for
different groups of geminate consonants (stops,
nasals, liquids, glides, fricatives) will be crucial
for natural sounding of AmhTTS system. In our
previous study, Tadesse and Takara (2006), we
studied the durational difference between single-
tons vs. geminates of contrastive words and de-
termined the threshold duration for different
groups of consonants. Accordingly the following
rule was implemented based on the threshold
durations we obtained in our previous study.
The gemination rule is programmed in the sys-
tem and generates geminates from singletons by
using a simple durational control method. It gen-
erates geminates by lengthening the duration of
the consonant part of the syllables following the
gemination mark. Two types of rules were pre-
pared for two groups of consonants, continuant
(voiced and unvoiced) and non-continuant (stops
and glottalized) consonants. If a gemination
mark (`) is followed by syllable with voiced or
unvoiced consonant then, the last three frames
of the cepstral parameters (c[0]) of vowel is ad-
justed linearly and then 120 ms of frame 1, 2 and
3 of second syllable is added. Then the second
syllable is connected after frame 4. Totally 90 ms
of cepstral parameters is added. Otherwise, if, a
gemination mark (`) is followed by syllable with
glottal or non-glottal consonant then, the last
three frames of the cepstral parameters (c[0]) of
vowel is adjusted linearly and then 100 ms of
silence is added. Finally the second syllable is
directly connected.
Since Amharic orthography does not use gemi-
nation mark, in our study we used our own
gemination mark and a manual gemination inser-
tion mechanism for input texts. Although some
scholars make use of two dots ( � which is pro-
posed in UNICODE 5.1 version as 135F) over a
consonant to show gemination, so far there is no
software which supports this mark.
</bodyText>
<subsectionHeader confidence="0.986623">
3.3.2 Sixth order syllables rule
</subsectionHeader>
<bodyText confidence="0.9998185">
As mentioned earlier the sixth order syllables are
very frequent and play a major role for proper
pronunciation of words. The sixth order ortho-
graphic syllables, which do not have any vowel
unit associated to it in the written form, may as-
sociate the helping vowel (epenthetic vowel /ix/,
see the Apendix) in its spoken form (Dawkins,
1969). The sixth order syllables are ambiguous;
they can stand for either a consonant in isolation
or a consonant with the short vowel. In our
study we prepared a simple algorithm to control
the sixth order syllables duration. The algorithm
to model the sixth order syllables duration uses
the following rules:
</bodyText>
<listItem confidence="0.9057356">
1. The sixth order syllables at the beginning of
word are always voweled (see /sxix/ in fig 5).
2. The sixth order syllables at the end of a
word are unvoweled (without vowel) but, if
it is geminated, it becomes voweled.
3. The sixth order syllables in the middle of
words are always unvoweled (see /f/ in
fig.5). But, if there is a cluster of three or
more consonants, it is broken up by inserting
helping vowel /ix/.
</listItem>
<bodyText confidence="0.999966166666667">
The following figures shows sample words syn-
thesized by our system by applying the prosodic
rules. Fig.5 and fig.7 shows the waveform and
duration of words synthesized by applying both
the gemination and sixth order syllables rules.
Fig.4 and fig.6 shows the waveform of original
words just for comparison purpose only. The two
synthesized words are comparative words which
differ only by presence or absence of gemination.
In the first word /sxixfta/&apos;ft.,+ meaning `bandit&apos;,
the sixth order syllable /f/ is unvoweled (see
fig.5). However, in the second word /sxixffixta/
&apos;ft.,+ meaning `rash&apos;, the sixth order syllable /f/
is voweled and longer /ffix/ (see fig.7) because it
is geminated. In our previous study, Tadesse and
Takara (2006), we observed that vowels are
needed for singletons to be pronounced as gemi-
nates.
</bodyText>
<page confidence="0.99943">
49
</page>
<figureCaption confidence="0.9997945">
Figure 4: Waveform &amp; duration of original word
*iv..-/sxixfta/, meaning `bandit&apos;
Figure 5: Waveform &amp; duration of synthesized
word *iv..-/sxixfta/, meaning `bandit&apos;
Figure 6: Waveform &amp; duration of original word
*iv..-/sxixffixta/, meaning `rash&apos;
Figure 7: Waveform &amp; duration of synthesized
word *iv..-/sxixffixta/, meaning `rash&apos;
</figureCaption>
<subsectionHeader confidence="0.885509">
3.3.3 Syllables connection rules
</subsectionHeader>
<bodyText confidence="0.9999667">
For syllables connections, we prepared four
types of syllables connection-rules based on the
type of consonants. The syllable units which are
represented by cepstrum parameters and stored in
the database are connected based on the types of
consonants joining with vowels. The connections
are implemented either by smoothing or interpo-
lating the cepstral coefficients, F0 and amplitude
at the boundary. Generally, we drive two types of
syllabic joining patterns. The first pattern is
smoothly continuous linkage where the pitch,
amplitude and spectral assimilation occur at the
boundary. This pattern occurs when the bound-
ary phonemes of joining syllables are unvoiced.
Another joining pattern is interpolation, this pat-
tern occurs when one or both of the boundary
phonemes of joining syllables is voiced. If the
boundary phonemes are plosive or glottal stop
then the pre-plosive or glottal stop closure pauses
with 40ms in length is inserted between them.
</bodyText>
<subsectionHeader confidence="0.667238">
3.3.4 Intonation
</subsectionHeader>
<bodyText confidence="0.999791538461539">
The intonation for a sentence is implemented by
applying a simple declination line in the log fre-
quency domain adopted from similar study for
Japanese TTS system by Takara and Jun (1988).
Fig.8 shows the intonation rule. The time ti is the
initial point of syllable, and the initial value of
F0 (circle mark) is calculated from this value.
This is a simple linear line, which intends to ex-
periment the very first step rule of intonation of
Amharic. In this study, we simply analyzed some
sample sentences and take the average slope = -
0.0011. But as a future work, the sentence pros-
ody should be studied more.
</bodyText>
<figureCaption confidence="0.99545">
Figure 8: Intonation rule
</figureCaption>
<sectionHeader confidence="0.850827" genericHeader="evaluation">
4 Evaluation and Discussion
</sectionHeader>
<bodyText confidence="0.999700111111111">
In order to evaluate the intelligibility and natu-
ralness of our system, we performed two types of
listening tests. The first listening test was per-
formed to evaluate the intelligibility of words
synthesized by the system and the second listen-
ing test was to evaluate the naturalness of syn-
thesized sentences. The listening tests were used
to evaluate the effectiveness of the prosodic rule
employed in our system.
</bodyText>
<subsectionHeader confidence="0.995536">
4.1 Recordings
</subsectionHeader>
<bodyText confidence="0.999772538461539">
For both listening tests the recording was done in
a soundproof room, with a digital audio tape re-
corder (SONY DAT) and SONY ECM-44S Elec-
trets Condenser Microphone. Sampling rate of
DAT was set at 48kHz then from DAT the re-
corded data were transferred to a PC via a digital
audio interface (A/D, D/A) converter. Finally,
the data was converted from stereo to mono;
down sampled to 10 kHz and the amplitude was
normalized using Cool Edit program. All re-
cording was done by male native speaker of the
language who is not included in the listening
tests.
</bodyText>
<figure confidence="0.998669958333333">
/sx ix/
/f/
/t
a/
/sx ix/
/f/
/t
a/
/sx
ix/
/ff
ix/
/t a/
/sx ix/
/ff ix/
/t a/
fn - fO 2
-0.0011t.
ro
f,
fz
0 ti fz is Time [frame]
f3
Log frequency [Hz]
</figure>
<page confidence="0.948756">
50
</page>
<subsectionHeader confidence="0.959596">
4.2 Speech Materials
</subsectionHeader>
<bodyText confidence="0.999714925925926">
The stimuli for the first listening test were con-
sisted of 200 words which were selected from
Amharic-English dictionary. The selected words
are commonly and frequently used words in the
day-to-day activities adopted from (Yasumoto
and Honda, 1978). Among the 200 words we
selected, 80 words (40% of words) contain one
or more geminated syllables and 75% of the
words contain sixth order syllables. This shows
that how geminates and sixth order syllables are
very frequent.
Then, using these words, two types of syn-
thesized speech data were prepared: Analy-
sis/synthesis sounds and rule-based synthesized
sounds using AmhTTS system. The original
speech sounds were also added in the test for
comparison purpose.
For the second listening test we used five
sentences which contains words with either
geminated syllables or sixth order syllables or
both. The sentences were selected from Amharic
grammar book, Baye (2008) which are used as
an example. We prepared three kinds of speech
data: original sentences, analysis/synthesis sen-
tences, and synthesized sentences by our system
by applying prosodic rules. In total we prepared
15 speech sounds.
</bodyText>
<subsectionHeader confidence="0.984746">
4.3 Methods
</subsectionHeader>
<bodyText confidence="0.999990045454546">
Both listening tests were conducted by four
Ethiopian adults who are native speakers of the
language (2 female and 2 male). All listeners are
20-35 years old in age, born and raised in the
capital city of Ethiopia. For both listening tests
we prepared listening test programs and a brief
introduction was given before the listening test.
In the first listening test, each sound was
played once in 4 second interval and the listeners
write the corresponding Amharic scripts to the
word they heard on the given answer sheet.
In the second listening test, for each listener,
we played all 15 sentences together and ran-
domly. And each subject listens to 15 sentences
and gives their judgment score using the listen-
ing test program by giving a measure of quality
as follows: (5 — Excellent, 4 - Good, 3 - Fair, 2 -
Poor, 1 — Bad). They evaluated the system by
considering the naturalness aspect. Each listener
did the listening test fifteen times and we took
the last ten results considering the first five tests
as training.
</bodyText>
<subsectionHeader confidence="0.847281">
4.4 Results and discussion
</subsectionHeader>
<bodyText confidence="0.999991652173913">
After collecting all listeners&apos; response, we calcu-
lated the average values and we found the fol-
lowing results.
In the first listening test, the average correct-
rate for original and analysis-synthesis sounds
were 100% and that of rule-based synthesized
sounds was 98%. We found the synthesized
words to be very intelligible.
In the second listening test the average Mean
opinion score (MOS) for synthesized sentences
were 3.2 and that of original and analy-
sis/synthesis sentences were 5.0 and 4.7 respec-
tively. The result showed that the prosodic con-
trol method employed in our system is effective
and produced fairly good prosody. However, the
durational modeling only may not be enough to
properly generate natural sound. Appropriate
syllable connections rules and proper intonation
modeling are also important. Therefore studying
typical intonation contour by modeling word
level prosody and improving syllables connec-
tion rules by using quality speech units is neces-
sary for synthesizing high quality speech.
</bodyText>
<sectionHeader confidence="0.995275" genericHeader="conclusions">
5 Conclusions and future works
</sectionHeader>
<bodyText confidence="0.999986684210526">
We have presented the development of a syllabic
based AmhTTS system capable of synthesizing
intelligible speech with fairly good prosody. We
have shown that syllables produce reasonably
natural quality speech and durational modeling is
very crucial for naturalness. However the system
still lacks naturalness and needs automatic gemi-
nation assignment mechanisms for better dur-
ational modeling.
Therefore, as a future work, we will mainly
focus on improving the naturalness of the syn-
thesizer. We are planning to improve the dura-
tion model using the data obtained from the an-
notated speech corpus, properly model the co-
articulation effect of geminates and to study the
typical intonation contour. We are also planning
to integrate a morphological analyzer for auto-
matic gemination assignment and sophisticated
generation of prosodic parameters.
</bodyText>
<sectionHeader confidence="0.999466" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998919833333333">
Atelach Alemu, Lars Asker and Mesfin Getachew.
2003. Natural Language Processing For Am-
haric: Overview And Suggestions for a Way
Forward, Proc. 10th Conference `Traitement
Automatique Des Languages Naturalles&apos;, pp. 173-
182, Vol.2, Batz-Sur-Mer, France.
</reference>
<page confidence="0.9797">
51
</page>
<reference confidence="0.992687692307693">
Sebsibe H/Mariam, S P Kishore, Alan W Black, Rohit
Kumar, and Rajeev Sangal. 2004. Unit Selection
Voice for Amharic Using Festvox, 5th ISCA
Speech Synthesis Workshop, Pittsburgh.
M.L Bender, J.D.Bowen, R.L. Cooper and C.A. Fer-
guson. 1976. Language in Ethiopia, London, Ox-
ford University Press.
M. Lionel Bender, Hailu Fulass. 1978. Amharic
Verb Morphology: A Generative Approach,
Carbondale.
Tadesse Anberbir and Tomio Takara. 2006. Amharic
Speech Synthesis Using Cepstral Method with
Stress Generation Rule, INTERSPEECH 2006
ICSLP, Pittsburgh, Pennsylvania, pp. 1340-1343.
T. Takara and T. Kochi. 2000. General speech syn-
thesis system for Japanese Ryukyu dialect,
Proc. of the 7th WestPRAC, pp. 173-176.
Baye Yimam. 2008. VhOXY hThm• (&amp;quot;Amharic
Grammer,), Addis Ababa. (in Amaharic).
C.H DAWKINS. 1969. The Fundamentals of Am-
haric, Bible Based Books, SIM Publishing, Addis
Ababa, Ethiopia, pp.5-7.
S. Furui, Digital Speech Processing, Synthesis,
and Recognition, Second Edition, Marcel Dekker,
Inc., 2001, pp. 266-270.
S. Imai. 1980. Log Magnitude Approximation
(LMA) filter, Trans. of IECE Japan, J63-A, 12,
PP. 886-893. (in Japanese).
Takara, Tomio and Oshiro, Jun. 1988. Continuous
Speech Synthesis by Rule of Ryukyu Dialect,
Trans. IEEE of Japan, Vol. 108-C, No. 10, pp. 773-
780. (in Japanese)
B. Yasumoto and M. Honda. 1978. Birth Of Ja-
panses, pp.352-358, Taishukun-Shoten. (in Japa-
nese).
Appendix
Amharic Phonetic List, IPA Equivalence and its
ASCII Transliteration Table. (Mainly adopted
from (Sebsibe, 2004; Baye, 2008)
</reference>
<page confidence="0.998853">
52
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.714038">
<title confidence="0.994041">Development of an Amharic Text-to-Speech Using Cepstral Method</title>
<author confidence="0.981611">Tadesse Anberbir Tomio Takara</author>
<affiliation confidence="0.9781175">ICT Development Office, Addis Faculty of Engineering, University of Ababa University, Ethiopia the Ryukyus, Okinawa, Japan</affiliation>
<email confidence="0.917552">tadanberbir@gmail.comtakara@ie.u—ryukyu.ac.jp</email>
<abstract confidence="0.992687333333333">This paper presents a speech synthesis system for Amharic language and describes and how the important prosodic features of the language were modeled in the system. The developed Amharic Text-to-Speech system (AmhTTS) is parametric and rule-based that employs a cepstral method. The system uses a source filter model for speech production and a Log Magnitude Approximation (LMA) filter as the vocal tract filter. The intelligibility and naturalness of the system was evaluated by word and sentence listening tests respectively and we achieved 98% correct-rates for words and an average Mean Opinion Score (MOS) of 3.2 (which is categorized as good) for sentences listening tests. The synthesized speech has high intelligibility and moderate naturalness. Comparing with previous similar study, our system produced considerably similar quality speech with a fairly good prosody. In particular our system is mainly suitable for building new languages with little modification.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Atelach Alemu</author>
<author>Lars Asker</author>
<author>Mesfin Getachew</author>
</authors>
<title>Natural Language Processing For Amharic: Overview And Suggestions for a Way Forward,</title>
<date>2003</date>
<booktitle>Proc. 10th Conference `Traitement Automatique Des Languages Naturalles&apos;,</booktitle>
<pages>173--182</pages>
<location>Vol.2, Batz-Sur-Mer, France.</location>
<contexts>
<context position="4483" citStr="Alemu et al., 2003" startWordPosition="683" endWordPosition="686"> building unit selection voices for new languages. Proceedings of the EACL 2009 Workshop on Language Technologies for African Languages – AfLaT 2009, pages 46–52, Athens, Greece, 31 March 2009. c�2009 Association for Computational Linguistics 46 1st 2nd 3rd 4th 5th 6th 7th C/e/ C/u/ C/i/ C/a/ C/ie/ C C/o/ ቸ ቹ ቺ Y ቼ T ቾ Figure 1: Amharic Syllables structure least supported and least researched languages in the world. Although, recently, the development of different natural language processing (NLP) tools for analyzing Amharic text has begun, it is often very far comparing with other languages (Alemu et al., 2003). Particularly, researches conducted on language technologies like speech synthesis and the application of such technologies are very limited or unavailable. To the knowledge of the authors, so far there is only one published work (Sebsibe, 2004) in the area of speech synthesis for Amharic. In this study they tried to describe the issues to be considered in developing a concatenative speech synthesizer using Festvox and recommended using syllables as a basic unit for high quality speech synthesis. In our research we developed a syllabic based TTS system with prosodic control method which is th</context>
</contexts>
<marker>Alemu, Asker, Getachew, 2003</marker>
<rawString>Atelach Alemu, Lars Asker and Mesfin Getachew. 2003. Natural Language Processing For Amharic: Overview And Suggestions for a Way Forward, Proc. 10th Conference `Traitement Automatique Des Languages Naturalles&apos;, pp. 173-182, Vol.2, Batz-Sur-Mer, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebsibe HMariam</author>
<author>S P Kishore</author>
<author>Alan W Black</author>
<author>Rohit Kumar</author>
<author>Rajeev Sangal</author>
</authors>
<title>Unit Selection Voice for Amharic Using Festvox, 5th ISCA Speech Synthesis Workshop,</title>
<date>2004</date>
<location>Pittsburgh.</location>
<marker>HMariam, Kishore, Black, Kumar, Sangal, 2004</marker>
<rawString>Sebsibe H/Mariam, S P Kishore, Alan W Black, Rohit Kumar, and Rajeev Sangal. 2004. Unit Selection Voice for Amharic Using Festvox, 5th ISCA Speech Synthesis Workshop, Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M L Bender</author>
<author>R L Cooper J D Bowen</author>
<author>C A Ferguson</author>
</authors>
<date>1976</date>
<booktitle>Language in Ethiopia,</booktitle>
<publisher>University Press.</publisher>
<location>London, Oxford</location>
<contexts>
<context position="6723" citStr="Bender et al., 1976" startWordPosition="1043" endWordPosition="1046">ls with 7x32= 224 Syllables. But since there are redundant sounds that represent the same sounds, the phonemes are only 28 (see the Appendix). Like other languages, Amharic also has its own typical phonological and morphological features that characterize it. The following are some of the striking features of Amharic phonology that gives the language its characteristic sound when one hears it spoken: the weak, indeterminate stress; the presence of glottalic, palatal, and labialized consonants; the frequent gemination of consonants and central vowels; and the use of an automatic helping vowel (Bender et al., 1976). Gemination in Amharic is one of the most distinctive characteristics of the cadence of the speech, and also caries a very heavy semantic and syntactic functional weight (Bender and Fulass, 1978). Amharic gemination is either lexical or morphological. Gemination as a lexical feature cannot be predicted. For instance, hA may be read as ald meaning &apos;he said&apos;, or alld meaning &apos;there is&apos;. Although this is not a problem for Amharic speakers, it is a challenging problem in speech synthesis. As a morphological feature gemination is more predictable in the verb than in the noun, Bender and Fulass (19</context>
<context position="12068" citStr="Bender et al., 1976" startWordPosition="1912" endWordPosition="1915">the power of synthesized speech is set by the 0th order cepstral coefficient, c [0]. 3.3 Prosody Modeling For any language, appropriate modeling of prosody is the most important issue for developing a high quality speech synthesizer. In Amharic language segments duration is the most important and useful component in prosody control. It is shown that, unlike English language in which the rhythm of the speech is mainly characterized by stress (loudness), rhythm in Amharic is mainly marked by longer and shorter syllables depending on gemination of consonants, and by certain features of phrasing (Bender et al., 1976). Therefore it is very important to model the syllables duration in AmhTTS system. In this paper we propose a new segmental duration control methods for synthesizing a high quality speech. Our rule-based TTS system uses a compact rule-based prosodic generation method in three phases: • modeling geminated consonants duration Fundamental Voiced/ Cepstral frequency (F0) Unvoiced Coefficient Speech database Text Input Text Analysis Subsystem Prosodic Generation Speech Synthesis SubsysVoice Output 48 • controlling of sixth order syllables duration • assignment of a global intonation contour Prosody</context>
</contexts>
<marker>Bender, Bowen, Ferguson, 1976</marker>
<rawString>M.L Bender, J.D.Bowen, R.L. Cooper and C.A. Ferguson. 1976. Language in Ethiopia, London, Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lionel Bender</author>
</authors>
<title>Hailu Fulass.</title>
<date>1978</date>
<location>Carbondale.</location>
<marker>Bender, 1978</marker>
<rawString>M. Lionel Bender, Hailu Fulass. 1978. Amharic Verb Morphology: A Generative Approach, Carbondale.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tadesse Anberbir</author>
<author>Tomio Takara</author>
</authors>
<title>Amharic Speech Synthesis Using Cepstral Method with Stress Generation Rule,</title>
<date>2006</date>
<booktitle>INTERSPEECH 2006 ICSLP,</booktitle>
<pages>1340--1343</pages>
<location>Pittsburgh, Pennsylvania,</location>
<marker>Anberbir, Takara, 2006</marker>
<rawString>Tadesse Anberbir and Tomio Takara. 2006. Amharic Speech Synthesis Using Cepstral Method with Stress Generation Rule, INTERSPEECH 2006 ICSLP, Pittsburgh, Pennsylvania, pp. 1340-1343.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Takara</author>
<author>T Kochi</author>
</authors>
<title>General speech synthesis system for Japanese Ryukyu dialect,</title>
<date>2000</date>
<booktitle>Proc. of the 7th WestPRAC,</booktitle>
<pages>173--176</pages>
<contexts>
<context position="8531" citStr="Takara and Kochi, 2000" startWordPosition="1345" endWordPosition="1348">peech. In our previous study, (Tadesse and Takara, 2006) we found that geminates and sixth order syllables are the two most important features that play a key role for proper pronunciation of words. Therefore, in our study we mainly consider these language specific features to develop a high quality speech synthesizer for Amharic language. 3 AmhTTS System Amharic TTS synthesis system is a parametric and rule based system designed based on the general speech synthesis system. Fig.2. shows the scheme of Amharic speech synthesis system. The design is based on the general speech synthesis system (Takara and Kochi, 2000). The system has three main components, a text analysis subsystem, prosodic generation module and a speech synthesis subsystem. The following three sub-sections discuss the details of each component. 47 Figure 2: Amharic Speech Synthesis System 3.1 Text Analysis The text analysis subsystem extracts the linguistic and prosodic information from the input text. The program iterates through the input text and extracts the gemination and other marks, and the sequences of syllables using the syllabification rule. The letter-to-sound conversion has simple one-to-one mapping between orthography and ph</context>
</contexts>
<marker>Takara, Kochi, 2000</marker>
<rawString>T. Takara and T. Kochi. 2000. General speech synthesis system for Japanese Ryukyu dialect, Proc. of the 7th WestPRAC, pp. 173-176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Baye Yimam</author>
</authors>
<date>2008</date>
<journal>VhOXY hThm• (&amp;quot;Amharic Grammer,), Addis Ababa. (in Amaharic).</journal>
<marker>Yimam, 2008</marker>
<rawString>Baye Yimam. 2008. VhOXY hThm• (&amp;quot;Amharic Grammer,), Addis Ababa. (in Amaharic).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H DAWKINS</author>
</authors>
<title>The Fundamentals of Amharic, Bible Based Books,</title>
<date>1969</date>
<pages>5--7</pages>
<publisher>SIM Publishing,</publisher>
<location>Addis Ababa, Ethiopia,</location>
<marker>DAWKINS, 1969</marker>
<rawString>C.H DAWKINS. 1969. The Fundamentals of Amharic, Bible Based Books, SIM Publishing, Addis Ababa, Ethiopia, pp.5-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Furui</author>
</authors>
<title>Digital Speech Processing, Synthesis, and Recognition, Second Edition,</title>
<date>2001</date>
<pages>266--270</pages>
<publisher>Marcel Dekker, Inc.,</publisher>
<contexts>
<context position="10059" citStr="Furui, 2001" startWordPosition="1587" endWordPosition="1588">llected and their sounds were prepared by recording on digital audio tape (DAT) at a 48 kHz sampling rate and 16-bit value. After that, they were down-sampled to 10 kHz for analyzing. All speech units were recorded with normal speaking rate. Then, the speech sounds were analyzed by the analysis system. The analysis system adopts short-time cepstral analysis with frame length 25.6 ms and frame shifting time of 10 ms. A time-domain Hamming window with a length of 25.6 ms is used in analysis. The cepstrum is defined as the inverse Fourier transform of the short-time logarithm amplitude spectrum (Furui, 2001). Cepstral analysis has the advantage that it could separate the spectral envelope part and the excitation part. The resulting parameters of speech unit include the number of frames and, for each frame, voiced/unvoiced (V/UV) decision, pitch period and cepstral coefficients c[m], 0 &lt;_ m &lt;_ 29. The speech database contains these parameters as shown in fig.2. Finally, the speech synthesis subsystem generates speech from pre-stored parameters under the control of the prosodic rules. For speech synthesis, the general source-filter model is used as a speech production model as shown in fig.3. The s</context>
</contexts>
<marker>Furui, 2001</marker>
<rawString>S. Furui, Digital Speech Processing, Synthesis, and Recognition, Second Edition, Marcel Dekker, Inc., 2001, pp. 266-270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Imai</author>
</authors>
<title>Log Magnitude Approximation (LMA) filter,</title>
<date>1980</date>
<journal>Trans. of IECE Japan,</journal>
<volume>63</volume>
<pages>886--893</pages>
<note>(in Japanese).</note>
<contexts>
<context position="10745" citStr="Imai, 1980" startWordPosition="1695" endWordPosition="1696">nvelope part and the excitation part. The resulting parameters of speech unit include the number of frames and, for each frame, voiced/unvoiced (V/UV) decision, pitch period and cepstral coefficients c[m], 0 &lt;_ m &lt;_ 29. The speech database contains these parameters as shown in fig.2. Finally, the speech synthesis subsystem generates speech from pre-stored parameters under the control of the prosodic rules. For speech synthesis, the general source-filter model is used as a speech production model as shown in fig.3. The synthetic sound is produced using Log Magnitude Approximation (LMA) filter (Imai, 1980) as the system filter, for which cepstral coefficients are used to characterize the speech sound. Figure 3: Diagram of Speech Synthesis Model The LMA filter presents the vocal tract characteristics that are estimated in 30 lower-order quefrency elements. The LMA filter is a pole-zero filter that is able to efficiently represent the vocal tract features for all speech sounds. The LMA filter is controlled by cepstrum parameters as vocal tract parameters, and it is driven by fundamental period impulse series for voiced sounds and by white noise for unvoiced sounds. The fundamental frequency (F0) </context>
</contexts>
<marker>Imai, 1980</marker>
<rawString>S. Imai. 1980. Log Magnitude Approximation (LMA) filter, Trans. of IECE Japan, J63-A, 12, PP. 886-893. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomio Takara</author>
<author>Jun Oshiro</author>
</authors>
<title>Continuous Speech Synthesis by Rule of Ryukyu Dialect, Trans.</title>
<date>1988</date>
<journal>IEEE of Japan,</journal>
<volume>108</volume>
<pages>773--780</pages>
<note>(in Japanese)</note>
<marker>Takara, Oshiro, 1988</marker>
<rawString>Takara, Tomio and Oshiro, Jun. 1988. Continuous Speech Synthesis by Rule of Ryukyu Dialect, Trans. IEEE of Japan, Vol. 108-C, No. 10, pp. 773-780. (in Japanese)</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Yasumoto</author>
<author>M Honda</author>
</authors>
<date>1978</date>
<journal>Birth Of Japanses,</journal>
<pages>352--358</pages>
<note>Taishukun-Shoten. (in Japanese).</note>
<contexts>
<context position="20585" citStr="Yasumoto and Honda, 1978" startWordPosition="3303" endWordPosition="3306">o to mono; down sampled to 10 kHz and the amplitude was normalized using Cool Edit program. All recording was done by male native speaker of the language who is not included in the listening tests. /sx ix/ /f/ /t a/ /sx ix/ /f/ /t a/ /sx ix/ /ff ix/ /t a/ /sx ix/ /ff ix/ /t a/ fn - fO 2 -0.0011t. ro f, fz 0 ti fz is Time [frame] f3 Log frequency [Hz] 50 4.2 Speech Materials The stimuli for the first listening test were consisted of 200 words which were selected from Amharic-English dictionary. The selected words are commonly and frequently used words in the day-to-day activities adopted from (Yasumoto and Honda, 1978). Among the 200 words we selected, 80 words (40% of words) contain one or more geminated syllables and 75% of the words contain sixth order syllables. This shows that how geminates and sixth order syllables are very frequent. Then, using these words, two types of synthesized speech data were prepared: Analysis/synthesis sounds and rule-based synthesized sounds using AmhTTS system. The original speech sounds were also added in the test for comparison purpose. For the second listening test we used five sentences which contains words with either geminated syllables or sixth order syllables or bot</context>
</contexts>
<marker>Yasumoto, Honda, 1978</marker>
<rawString>B. Yasumoto and M. Honda. 1978. Birth Of Japanses, pp.352-358, Taishukun-Shoten. (in Japanese).</rawString>
</citation>
<citation valid="true">
<title>Appendix Amharic Phonetic List, IPA Equivalence and its ASCII Transliteration Table. (Mainly adopted from (Sebsibe,</title>
<date>2004</date>
<contexts>
<context position="5327" citStr="(2004)" startWordPosition="818" endWordPosition="818">e, 2004) in the area of speech synthesis for Amharic. In this study they tried to describe the issues to be considered in developing a concatenative speech synthesizer using Festvox and recommended using syllables as a basic unit for high quality speech synthesis. In our research we developed a syllabic based TTS system with prosodic control method which is the first rule-based system published for Amharic. The designed Amharic TTS (AmhTTS) is parametric and rule-based system that employs a Cepstral method and uses a Log Magnitude Approximation (LMA) filter. Unlike the previous study, Sebsibe (2004), our study provides a total solution on prosodic information generation mainly by modeling the durations. The system is expected to have a wide range of applications, for example, in software aids to visually impaired people, in mobile phones and can also be easily customized for other Ethiopian languages. 2 Amharic Language&apos;s Overview Amharic (hoxኛ) is a Semitic language and it is one of the most widely spoken languages in Ethiopia. It has its own non Latin based syllabic script called &amp;quot;Fidel&amp;quot; or &amp;quot;Abugida&amp;quot;. The orthographic representation of the language is organized into orders (derivatives</context>
</contexts>
<marker>2004</marker>
<rawString>Appendix Amharic Phonetic List, IPA Equivalence and its ASCII Transliteration Table. (Mainly adopted from (Sebsibe, 2004; Baye, 2008)</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>