<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.061145">
<title confidence="0.991296">
Learning Dialogue Strategies from Older and Younger Simulated Users
</title>
<author confidence="0.992447">
Kallirroi Georgila
</author>
<affiliation confidence="0.941387666666667">
Institute for Creative Technologies
University of Southern California
Playa Vista, USA
</affiliation>
<email confidence="0.997149">
kgeorgila@ict.usc.edu
</email>
<author confidence="0.991968">
Maria K. Wolters
</author>
<affiliation confidence="0.906063666666667">
School of Informatics
University of Edinburgh
Edinburgh, UK
</affiliation>
<email confidence="0.995796">
maria.wolters@ed.ac.uk
</email>
<author confidence="0.992284">
Johanna D. Moore
</author>
<affiliation confidence="0.905822">
School of Informatics
University of Edinburgh
Edinburgh, UK
</affiliation>
<email confidence="0.996383">
J.Moore@ed.ac.uk
</email>
<sectionHeader confidence="0.993848" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999989444444445">
Older adults are a challenging user group
because their behaviour can be highly vari-
able. To the best of our knowledge, this
is the first study where dialogue strategies
are learned and evaluated with both sim-
ulated younger users and simulated older
users. The simulated users were derived
from a corpus of interactions with a strict
system-initiative spoken dialogue system
(SDS). Learning from simulated younger
users leads to a policy which is close to
one of the dialogue strategies of the under-
lying SDS, while the simulated older users
allow us to learn more flexible dialogue
strategies that accommodate mixed initia-
tive. We conclude that simulated users are
a useful technique for modelling the be-
haviour of new user groups.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999860631578947">
State-of-the-art statistical approaches to dia-
logue management (Frampton and Lemon, 2006;
Williams and Young, 2007) rely on having ade-
quate training data. Dialogue strategies are typ-
ically inferred from data using Reinforcement
Learning (RL), which requires on the order of
thousands of dialogues to achieve good perfor-
mance. Therefore, it is no longer feasible to rely
on data collected with real users. Instead, training
data is generated through interactions of the sys-
tem with simulated users (SUs) (Georgila et al.,
2006). In order to learn good policies, the be-
haviour of the SUs needs to cover the range of
variation seen in real users (Georgila et al., 2006;
Schatzmann et al., 2006). Furthermore, SUs are
critical for evaluating candidate dialogue policies.
To date, SUs have been used to learn dialogue
strategies for specific domains such as flight reser-
vation, restaurant recommendation, etc., and to
learn both how to collect information from the
user (Frampton and Lemon, 2006) as well as how
to present information to the user (Rieser and
Lemon, 2009; Janarthanam and Lemon, 2009).
In addition to covering different domains, SUs
should also be able to model relevant user at-
tributes (Schatzmann et al., 2006), such as coop-
erativeness vs. non-cooperativeness (L´opez-C´ozar
et al., 2006; Jung et al., 2009), or age (Georgila et
al., 2008). In this paper, we focus on user age.
As the proportion of older people in the popu-
lation increases, it becomes essential to make spo-
ken dialogue systems (SDS) easy to use for this
group of people. Only very few spoken dialogue
systems have been developed for older people (e.g.
Nursebot (Roy et al., 2000)), and we are aware of
no work on learning specific dialogue policies for
older people using SUs and RL.
Older people present special challenges for di-
alogue systems. While cognitive and perceptual
abilities generally decline with age, the spread of
ability in older people is far larger than in any
other segment of the population (Rabbitt and An-
derson, 2005). Older users may also use differ-
ent strategies for interacting with SDS. In our pre-
vious work on studying the interactions between
older and younger users and a simulated appoint-
ment scheduling SDS (Wolters et al., 2009b), we
found that some older users were very “social”,
treating the system like a human, and failing to
adapt to the SDS’s system-initiative dialogue strat-
egy. A third of the older users, however, tended
to be more “factual”, using short commands and
conforming to the system’s dialogue strategy. In
that, they were very similar to the younger users
(Wolters et al., 2009b).
In previous work (Georgila et al., 2008), we
successfully built SUs for both older and younger
</bodyText>
<subsubsectionHeader confidence="0.676174">
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 103–106,
</subsubsectionHeader>
<affiliation confidence="0.890687">
The University of Tokyo, September 24-25, 2010. c�2010 Association for Computational Linguistics
</affiliation>
<page confidence="0.999818">
103
</page>
<bodyText confidence="0.999986">
adults from the corpus used by (Wolters et al.,
2009b) and documented in (Georgila et al., 2010).
When we evaluated the SUs using metrics such as
precision and recall (Georgila et al., 2006; Schatz-
mann et al., 2006), we found that SUs trained on
older users’ data can cover behaviour patterns typ-
ical of younger users, but not the opposite. The
behaviour of older people is too diverse to be cap-
tured by a SU trained on younger users’ data. This
result agrees with the findings of (Wolters et al.,
2009b; Georgila et al., 2010).
In this study, we take our work one step
further—we use the SUs developed in (Georgila
et al., 2008) to learn dialogue policies and evalu-
ate the resulting policies with data from both older
and younger users. Our work is important for two
reasons. First, to the best of our knowledge this
is the first time that people have used SUs and
RL to learn dialogue strategies for the increas-
ingly important population of older users. Sec-
ond, despite the fact that SUs are used for learn-
ing dialogue strategies it is not clear whether they
can learn policies that are appropriate for different
user populations. We show that SUs can be suc-
cessfully used to learn policies for older users that
are adapted to their specific patterns of behaviour,
even though these patterns are far more varied than
the behaviour patterns of younger users. This pro-
vides evidence for the validity of the user simula-
tion methodology for learning and evaluating dia-
logue strategies for different user populations.
The structure of the paper is as follows: In sec-
tion 2 we describe our data set, discuss the dif-
ferences between older and younger users as seen
in our corpus, and describe our user simulations.
In section 3, we present the results of our experi-
ments. Finally, in section 4 we present our conclu-
sions and propose future work.
</bodyText>
<sectionHeader confidence="0.970722" genericHeader="method">
2 The Corpus
</sectionHeader>
<bodyText confidence="0.999976878787879">
In the original dialogue corpus, people were asked
to schedule health care appointments with 9 dif-
ferent simulated SDS in a Wizard-of-Oz setting.
The systems varied in the number of options pre-
sented at each stage of the dialogue (1, 2, 4),
and in the confirmation strategies used (explicit
confirmation, implicit confirmation, no confirma-
tion). System utterances were generated using
a simple template-based algorithm and synthe-
sised using a female Scottish English unit selec-
tion voice. The human Wizard took over the func-
tion of speech recognition (ASR), language under-
standing (NLU), and dialogue management com-
ponents. No ASR or NLU errors were simulated,
because having to deal with ASR and/or NLU er-
rors in addition to task completion would have in-
creased cognitive load (Wolters et al., 2009a).
The system (Wizard) followed a strict policy
which resulted in dialogues with a fixed schema:
First, users arranged to see a specific health care
professional, then they arranged a specific half-
day, and finally, a specific half-hour time slot on
that half-day was agreed. Users were not allowed
to skip any stage of the dialogue. This design en-
sured that all users were presented with the rele-
vant number of options and the relevant confirma-
tion strategy at least three times per dialogue. In a
final step, the Wizard confirmed the appointment.
The full corpus consists of 447 dialogues; 3 di-
alogues were not recorded. A total of 50 partici-
pants were recruited, of which 26 were older, aged
between 50 and 85 years, and 24 were younger,
aged between 18 and 30 years. The older users
contributed 232 dialogues, the younger ones 215.
Older and younger users were matched for level
of education and gender. All dialogues were tran-
scribed orthographically and annotated with dia-
logue acts and dialogue context information. Us-
ing a unique mapping, we associate each dialogue
act with a (speech act, task) pair, where the speech
act is task independent and the task corresponds to
the slot in focus (health professional, half-day or
time slot). For example, (confirm pos, hp) cor-
responds to positive explicit confirmation of the
health professional slot. For each dialogue, de-
tailed measures of dialogue quality were recorded:
objective task completion, perceived task comple-
tion, appointment recall, length (in turns), and ex-
tensive user satisfaction ratings. For a detailed dis-
cussion of the corpus, see (Georgila et al., 2010).
The choice of dialogue strategy did not affect
task completion and appointment recall, but had
significant effects on efficiency (Wolters et al.,
2009a). Task completion and appointment recall
were the same for older and younger users, but
older users took more turns to complete the task
(Wolters et al., 2009a). Clear differences between
the two user groups emerge when we look at in-
teraction patterns in more detail (Wolters et al.,
2009b; Georgila et al., 2010). Older people tend
to “ground” information (using repetitions) and
take the initiative more than younger people. In
our corpus it was very common that the older per-
son would provide information about the half-day
and the time slot of the appointment before hav-
ing been asked by the system. However, due to the
</bodyText>
<page confidence="0.992117">
104
</page>
<table confidence="0.999595833333333">
Experiment 1 Experiment 2
slot filled +50 +50
appointment confirmed +200 +200
dialogue length -5 per turn -5 per turn
slot confirmed +100 not used
wrong order -500 not used
</table>
<tableCaption confidence="0.999884">
Table 1: Reward functions for the experiments.
</tableCaption>
<bodyText confidence="0.999890684210526">
strict policy of the Wizard, this information would
be ignored and the system would later ask for the
information that had already been provided.
In our SUs, each user utterance corresponds to a
user action described by a list of (speech act, task)
pairs. There are 31 distinct system actions and 389
distinct actions for older users. Younger people
used a subset of 125 of the older users’ actions.
Our SUs do not simulate ASR or NLU errors since
such errors were not simulated in the collection of
the corpus.
We built n-grams of system and user actions
with n varying from 2 to 5. Given a history of n-1
actions from system and user, the SU generates an
action based on a probability distribution learned
from the training data (Georgila et al., 2006). In
the present study, n was set to 3, which means that
each user action is predicted based on the previous
user action and the previous system action.
</bodyText>
<sectionHeader confidence="0.968025" genericHeader="method">
3 Learning Dialogue Strategies
</sectionHeader>
<bodyText confidence="0.999957103896104">
We performed two experiments. In Experiment 1,
our goal was to learn the policy of the Wizard, i.e.
the strict system-initiative policy of requesting and
confirming information for each slot before mov-
ing to the next slot, in the following order: health
professional, half-day, time slot. In Experiment
2, our goal was to learn a more flexible policy that
could accommodate some degree of user initiative.
The reward functions for both experiments are
specified in Table 1; they are similar to the reward
functions used in the literature, e.g. (Frampton and
Lemon, 2006). Slots that have been filled success-
fully and confirmed appointments are rewarded,
while long dialogues are penalised. For Experi-
ment 1, policies were rewarded that filled slots in
the correct order and that confirmed each slot af-
ter it had been filled. A large penalty was imposed
when the policy deviated from the strict slot order
(health professional, half-day, time slot). For Ex-
periment 2, these constraints were removed. Slots
could be filled in any order. Confirmations were
not required because there was no speech act in
the corpus for confirming more than one slot at a
time.
In both experiments we used the SARSA-A al-
gorithm (Sutton and Barto, 1998) for RL. 30,000
iterations were used for learning the final pol-
icy for each condition. For each experiment,
we learned two policies, Policy-Old, which was
based on simulated older users, and Policy-Young,
which was based on simulated younger users.
The resulting policies were then tested on simu-
lated older users (Test-Old) and simulated younger
users (Test-Young). To have comparable results
between Experiment 1 and Experiment 2, dur-
ing testing we score our policies using the reward
function of Experiment 2. The best possible score
is 190, i.e. the user fills all the slots in one turn
and then confirms the appointment. (Note that +50
points are given when a slot is only filled, not con-
firmed too.) For each test condition, we gener-
ated 10,000 simulated dialogues. Overall scores
for each combination of policy and SU were es-
tablished using 5-fold cross-validation.
Our results are summarised in Figure 1. While
average rewards were not affected by policy
type (ANOVA, F(1, 68)=1, p=0.3) or training
data set (F(1,185)=3, p=0.09), we found a very
strong interaction between policy type and data
set (F(1, 3098)=51, p=0.000). Learning with
simulated younger users yields better strict poli-
cies than learning with older users (Tukey’s Hon-
est Significant Difference Test, A=20, 95% CI
= [11, 30], p=0.000), while learning with simu-
lated older users yields better flexible policies than
learning with younger users (A=15, 95% CI =
[6,24], p=0.001). This is what we would expect
from our corpus analysis, since the interaction be-
haviour of older users is far more variable than that
of younger users (Wolters et al., 2009b; Georgila
et al., 2010).
The strict policy that was learned from sim-
ulated younger users was as follows, with only
slight variations: first request the type of health
professional, then implicitly confirm the health
professional and request the half-day slot, then im-
plicitly confirm the half-day slot and request the
time slot, and then confirm the appointment. The
strict policy learned from simulated older users
was similar, but less successful, because most
older users do not readily conform to the fixed
structure.
The flexible policy learned from simulated older
users takes into account initiative from the user
and does not always confirm. The score for the
flexible policy learned from simulated younger
users was relatively low, even though the resulting
</bodyText>
<page confidence="0.993514">
105
</page>
<figure confidence="0.971856454545455">
org.uk). Georgila is supported by the U.S. Army Research,
Development, and Engineering Command (RDECOM). The
content does not necessarily reflect the position or the policy
190
of the U.S. Government, and no official endorsement should
180
be inferred.
160
150
170
Score
</figure>
<figureCaption confidence="0.933118">
Figure 1: Mean scores for each combination of
reward function, training set, and test set (5-fold
cross-validation).
</figureCaption>
<bodyText confidence="0.999697875">
policy was very similar to the strict policy learned
from younger users (i.e. a sequence of informa-
tion requests and implicit confirmations), and even
though the behaviour of younger users is far more
predictable than the behaviour of older users. It
appears that the explicit penalty for violating the
order of slots is crucial for fully exploiting the pat-
terns in younger users’ behaviour.
</bodyText>
<sectionHeader confidence="0.999618" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.99997545">
We have shown that SUs can be used to learn ap-
propriate policies for older adults, even though
their interaction behaviour is more complex and
diverse than that of younger adults. Crucially, sim-
ulated older users allowed us to learn a more flex-
ible version of the strict system-initiative dialogue
strategies that were used for creating the original
corpus of interactions. These results are consis-
tent with previous analyses of the original corpus
(Wolters et al., 2009b; Georgila et al., 2010) and
support the validity of the user simulation method-
ology for learning and evaluating dialogue strate-
gies.
In our future work, we will experiment with
more complex SUs, e.g. linear feature combina-
tion models (Georgila et al., 2006), and see if they
can be used to learn similar policies. We also plan
to study the effect of training and testing with dif-
ferent user simulation techniques, such as n-grams
versus linear feature combination models.
</bodyText>
<sectionHeader confidence="0.99522" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<footnote confidence="0.5161645">
This research was partially supported by the MATCH project
(SHEFC-HR04016, http://www.match-project.
</footnote>
<sectionHeader confidence="0.940182" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99986224">
M. Frampton and O. Lemon. 2006. Learning more effective
dialogue strategies using limited dialogue move features.
In Proc. ACL.
K. Georgila, J. Henderson, and O. Lemon. 2006. User simu-
lation for spoken dialogue systems: Learning and evalua-
tion. In Proc. Interspeech.
K. Georgila, M. Wolters, and J. Moore. 2008. Simulating the
behaviour of older versus younger users. In Proc. ACL.
K. Georgila, Maria Wolters, J.D. Moore, and R.H. Logie.
2010. The MATCH corpus: A corpus of older and
younger users’ interactions with spoken dialogue systems.
Language Resources and Evaluation, 44(3):221–261.
S. Janarthanam and O. Lemon. 2009. A two-tier user simula-
tion model for reinforcement learning of adaptive referring
expression generation policies. In Proc. SIGdial.
S. Jung, C. Lee, K. Kim, and G.G. Lee. 2009. Hybrid ap-
proach to user intention modeling for dialog simulation.
In Proc. ACL.
R. L´opez-C´ozar, Z. Callejas, and M. McTear. 2006. Testing
the performance of spoken dialogue systems by means of
an artificially simulated user. Artificial Intelligence Re-
view, 26(4):291–323.
P. Rabbitt and M.M. Anderson. 2005. The lacunae of
loss? Aging and the differentiation of human abilities.
In F.I. Craik and E. Bialystok, editors, Lifespan Cogni-
tion: Mechanisms of Change, chapter 23. Oxford Univer-
sity Press, New York, NY.
V. Rieser and O. Lemon. 2009. Natural language gener-
ation as planning under uncertainty for spoken dialogue
systems. In Proc. EACL.
N. Roy, J. Pineau, and S. Thrun. 2000. Spoken dialog man-
agement for robots. In Proc. ACL.
J. Schatzmann, K. Weilhammer, M. Stuttle, and S. Young.
2006. A survey of statistical user simulation tech-
niques for reinforcement-learning of dialogue manage-
ment strategies. Knowlege Engineering Review, 21(2):97–
126.
R.S. Sutton and A.G. Barto. 1998. Reinforcement Learning:
An Introduction. MIT Press.
J. Williams and S. Young. 2007. Partially observable Markov
decision processes for spoken dialog systems. Computer
Speech and Language, 21(2):393–422.
M. Wolters, K. Georgila, J.D. Moore, R.H. Logie, S.E.
MacPherson, and M. Watson. 2009a. Reducing work-
ing memory load in spoken dialogue systems. Interacting
with Computers, 21(4):276–287.
M. Wolters, K. Georgila, J.D. Moore, and S.E. MacPherson.
2009b. Being old doesn’t mean acting old: How older
users interact with spoken dialog systems. ACM Trans.
Accessible Computing, 2(1).
</reference>
<figure confidence="0.98211525">
190
180
170
160
150
140
Test−Old Test−Young Test−Old Test−Young
Reward−Strict
Reward−Flex
Policy−Old
Policy−Old
Reward−Strict
Policy−Young
Policy−Young
Reward−Flex
140
</figure>
<page confidence="0.956399">
106
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.496344">
<title confidence="0.999899">Learning Dialogue Strategies from Older and Younger Simulated Users</title>
<author confidence="0.949232">Kallirroi</author>
<affiliation confidence="0.93847">Institute for Creative University of Southern Playa Vista,</affiliation>
<email confidence="0.999418">kgeorgila@ict.usc.edu</email>
<author confidence="0.999669">K Maria</author>
<affiliation confidence="0.973090333333333">School of University of Edinburgh,</affiliation>
<email confidence="0.995249">maria.wolters@ed.ac.uk</email>
<author confidence="0.984941">D Johanna</author>
<affiliation confidence="0.909457333333333">School of University of Edinburgh,</affiliation>
<email confidence="0.99924">J.Moore@ed.ac.uk</email>
<abstract confidence="0.998777684210527">Older adults are a challenging user group because their behaviour can be highly variable. To the best of our knowledge, this is the first study where dialogue strategies are learned and evaluated with both simulated younger users and simulated older users. The simulated users were derived from a corpus of interactions with a strict system-initiative spoken dialogue system (SDS). Learning from simulated younger users leads to a policy which is close to one of the dialogue strategies of the underlying SDS, while the simulated older users allow us to learn more flexible dialogue strategies that accommodate mixed initiative. We conclude that simulated users are a useful technique for modelling the behaviour of new user groups.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Frampton</author>
<author>O Lemon</author>
</authors>
<title>Learning more effective dialogue strategies using limited dialogue move features.</title>
<date>2006</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="1235" citStr="Frampton and Lemon, 2006" startWordPosition="177" endWordPosition="180">ted younger users and simulated older users. The simulated users were derived from a corpus of interactions with a strict system-initiative spoken dialogue system (SDS). Learning from simulated younger users leads to a policy which is close to one of the dialogue strategies of the underlying SDS, while the simulated older users allow us to learn more flexible dialogue strategies that accommodate mixed initiative. We conclude that simulated users are a useful technique for modelling the behaviour of new user groups. 1 Introduction State-of-the-art statistical approaches to dialogue management (Frampton and Lemon, 2006; Williams and Young, 2007) rely on having adequate training data. Dialogue strategies are typically inferred from data using Reinforcement Learning (RL), which requires on the order of thousands of dialogues to achieve good performance. Therefore, it is no longer feasible to rely on data collected with real users. Instead, training data is generated through interactions of the system with simulated users (SUs) (Georgila et al., 2006). In order to learn good policies, the behaviour of the SUs needs to cover the range of variation seen in real users (Georgila et al., 2006; Schatzmann et al., 20</context>
<context position="10872" citStr="Frampton and Lemon, 2006" startWordPosition="1794" endWordPosition="1797">previous system action. 3 Learning Dialogue Strategies We performed two experiments. In Experiment 1, our goal was to learn the policy of the Wizard, i.e. the strict system-initiative policy of requesting and confirming information for each slot before moving to the next slot, in the following order: health professional, half-day, time slot. In Experiment 2, our goal was to learn a more flexible policy that could accommodate some degree of user initiative. The reward functions for both experiments are specified in Table 1; they are similar to the reward functions used in the literature, e.g. (Frampton and Lemon, 2006). Slots that have been filled successfully and confirmed appointments are rewarded, while long dialogues are penalised. For Experiment 1, policies were rewarded that filled slots in the correct order and that confirmed each slot after it had been filled. A large penalty was imposed when the policy deviated from the strict slot order (health professional, half-day, time slot). For Experiment 2, these constraints were removed. Slots could be filled in any order. Confirmations were not required because there was no speech act in the corpus for confirming more than one slot at a time. In both expe</context>
</contexts>
<marker>Frampton, Lemon, 2006</marker>
<rawString>M. Frampton and O. Lemon. 2006. Learning more effective dialogue strategies using limited dialogue move features. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Georgila</author>
<author>J Henderson</author>
<author>O Lemon</author>
</authors>
<title>User simulation for spoken dialogue systems: Learning and evaluation.</title>
<date>2006</date>
<booktitle>In Proc. Interspeech.</booktitle>
<contexts>
<context position="1673" citStr="Georgila et al., 2006" startWordPosition="247" endWordPosition="250">ted users are a useful technique for modelling the behaviour of new user groups. 1 Introduction State-of-the-art statistical approaches to dialogue management (Frampton and Lemon, 2006; Williams and Young, 2007) rely on having adequate training data. Dialogue strategies are typically inferred from data using Reinforcement Learning (RL), which requires on the order of thousands of dialogues to achieve good performance. Therefore, it is no longer feasible to rely on data collected with real users. Instead, training data is generated through interactions of the system with simulated users (SUs) (Georgila et al., 2006). In order to learn good policies, the behaviour of the SUs needs to cover the range of variation seen in real users (Georgila et al., 2006; Schatzmann et al., 2006). Furthermore, SUs are critical for evaluating candidate dialogue policies. To date, SUs have been used to learn dialogue strategies for specific domains such as flight reservation, restaurant recommendation, etc., and to learn both how to collect information from the user (Frampton and Lemon, 2006) as well as how to present information to the user (Rieser and Lemon, 2009; Janarthanam and Lemon, 2009). In addition to covering diffe</context>
<context position="4271" citStr="Georgila et al., 2006" startWordPosition="677" endWordPosition="680"> the system’s dialogue strategy. In that, they were very similar to the younger users (Wolters et al., 2009b). In previous work (Georgila et al., 2008), we successfully built SUs for both older and younger Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 103–106, The University of Tokyo, September 24-25, 2010. c�2010 Association for Computational Linguistics 103 adults from the corpus used by (Wolters et al., 2009b) and documented in (Georgila et al., 2010). When we evaluated the SUs using metrics such as precision and recall (Georgila et al., 2006; Schatzmann et al., 2006), we found that SUs trained on older users’ data can cover behaviour patterns typical of younger users, but not the opposite. The behaviour of older people is too diverse to be captured by a SU trained on younger users’ data. This result agrees with the findings of (Wolters et al., 2009b; Georgila et al., 2010). In this study, we take our work one step further—we use the SUs developed in (Georgila et al., 2008) to learn dialogue policies and evaluate the resulting policies with data from both older and younger users. Our work is important for two reasons. First, to th</context>
<context position="10118" citStr="Georgila et al., 2006" startWordPosition="1669" endWordPosition="1672">een provided. In our SUs, each user utterance corresponds to a user action described by a list of (speech act, task) pairs. There are 31 distinct system actions and 389 distinct actions for older users. Younger people used a subset of 125 of the older users’ actions. Our SUs do not simulate ASR or NLU errors since such errors were not simulated in the collection of the corpus. We built n-grams of system and user actions with n varying from 2 to 5. Given a history of n-1 actions from system and user, the SU generates an action based on a probability distribution learned from the training data (Georgila et al., 2006). In the present study, n was set to 3, which means that each user action is predicted based on the previous user action and the previous system action. 3 Learning Dialogue Strategies We performed two experiments. In Experiment 1, our goal was to learn the policy of the Wizard, i.e. the strict system-initiative policy of requesting and confirming information for each slot before moving to the next slot, in the following order: health professional, half-day, time slot. In Experiment 2, our goal was to learn a more flexible policy that could accommodate some degree of user initiative. The reward</context>
</contexts>
<marker>Georgila, Henderson, Lemon, 2006</marker>
<rawString>K. Georgila, J. Henderson, and O. Lemon. 2006. User simulation for spoken dialogue systems: Learning and evaluation. In Proc. Interspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Georgila</author>
<author>M Wolters</author>
<author>J Moore</author>
</authors>
<title>Simulating the behaviour of older versus younger users.</title>
<date>2008</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="2499" citStr="Georgila et al., 2008" startWordPosition="382" endWordPosition="385">luating candidate dialogue policies. To date, SUs have been used to learn dialogue strategies for specific domains such as flight reservation, restaurant recommendation, etc., and to learn both how to collect information from the user (Frampton and Lemon, 2006) as well as how to present information to the user (Rieser and Lemon, 2009; Janarthanam and Lemon, 2009). In addition to covering different domains, SUs should also be able to model relevant user attributes (Schatzmann et al., 2006), such as cooperativeness vs. non-cooperativeness (L´opez-C´ozar et al., 2006; Jung et al., 2009), or age (Georgila et al., 2008). In this paper, we focus on user age. As the proportion of older people in the population increases, it becomes essential to make spoken dialogue systems (SDS) easy to use for this group of people. Only very few spoken dialogue systems have been developed for older people (e.g. Nursebot (Roy et al., 2000)), and we are aware of no work on learning specific dialogue policies for older people using SUs and RL. Older people present special challenges for dialogue systems. While cognitive and perceptual abilities generally decline with age, the spread of ability in older people is far larger than </context>
<context position="3801" citStr="Georgila et al., 2008" startWordPosition="603" endWordPosition="606"> may also use different strategies for interacting with SDS. In our previous work on studying the interactions between older and younger users and a simulated appointment scheduling SDS (Wolters et al., 2009b), we found that some older users were very “social”, treating the system like a human, and failing to adapt to the SDS’s system-initiative dialogue strategy. A third of the older users, however, tended to be more “factual”, using short commands and conforming to the system’s dialogue strategy. In that, they were very similar to the younger users (Wolters et al., 2009b). In previous work (Georgila et al., 2008), we successfully built SUs for both older and younger Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 103–106, The University of Tokyo, September 24-25, 2010. c�2010 Association for Computational Linguistics 103 adults from the corpus used by (Wolters et al., 2009b) and documented in (Georgila et al., 2010). When we evaluated the SUs using metrics such as precision and recall (Georgila et al., 2006; Schatzmann et al., 2006), we found that SUs trained on older users’ data can cover behaviour patterns typical of younger users, </context>
</contexts>
<marker>Georgila, Wolters, Moore, 2008</marker>
<rawString>K. Georgila, M. Wolters, and J. Moore. 2008. Simulating the behaviour of older versus younger users. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Georgila</author>
<author>Maria Wolters</author>
<author>J D Moore</author>
<author>R H Logie</author>
</authors>
<title>The MATCH corpus: A corpus of older and younger users’ interactions with spoken dialogue systems.</title>
<date>2010</date>
<journal>Language Resources and Evaluation,</journal>
<volume>44</volume>
<issue>3</issue>
<contexts>
<context position="4178" citStr="Georgila et al., 2010" startWordPosition="661" endWordPosition="664"> the older users, however, tended to be more “factual”, using short commands and conforming to the system’s dialogue strategy. In that, they were very similar to the younger users (Wolters et al., 2009b). In previous work (Georgila et al., 2008), we successfully built SUs for both older and younger Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 103–106, The University of Tokyo, September 24-25, 2010. c�2010 Association for Computational Linguistics 103 adults from the corpus used by (Wolters et al., 2009b) and documented in (Georgila et al., 2010). When we evaluated the SUs using metrics such as precision and recall (Georgila et al., 2006; Schatzmann et al., 2006), we found that SUs trained on older users’ data can cover behaviour patterns typical of younger users, but not the opposite. The behaviour of older people is too diverse to be captured by a SU trained on younger users’ data. This result agrees with the findings of (Wolters et al., 2009b; Georgila et al., 2010). In this study, we take our work one step further—we use the SUs developed in (Georgila et al., 2008) to learn dialogue policies and evaluate the resulting policies wit</context>
<context position="8362" citStr="Georgila et al., 2010" startWordPosition="1368" endWordPosition="1371">text information. Using a unique mapping, we associate each dialogue act with a (speech act, task) pair, where the speech act is task independent and the task corresponds to the slot in focus (health professional, half-day or time slot). For example, (confirm pos, hp) corresponds to positive explicit confirmation of the health professional slot. For each dialogue, detailed measures of dialogue quality were recorded: objective task completion, perceived task completion, appointment recall, length (in turns), and extensive user satisfaction ratings. For a detailed discussion of the corpus, see (Georgila et al., 2010). The choice of dialogue strategy did not affect task completion and appointment recall, but had significant effects on efficiency (Wolters et al., 2009a). Task completion and appointment recall were the same for older and younger users, but older users took more turns to complete the task (Wolters et al., 2009a). Clear differences between the two user groups emerge when we look at interaction patterns in more detail (Wolters et al., 2009b; Georgila et al., 2010). Older people tend to “ground” information (using repetitions) and take the initiative more than younger people. In our corpus it wa</context>
<context position="13182" citStr="Georgila et al., 2010" startWordPosition="2173" endWordPosition="2176">3, p=0.09), we found a very strong interaction between policy type and data set (F(1, 3098)=51, p=0.000). Learning with simulated younger users yields better strict policies than learning with older users (Tukey’s Honest Significant Difference Test, A=20, 95% CI = [11, 30], p=0.000), while learning with simulated older users yields better flexible policies than learning with younger users (A=15, 95% CI = [6,24], p=0.001). This is what we would expect from our corpus analysis, since the interaction behaviour of older users is far more variable than that of younger users (Wolters et al., 2009b; Georgila et al., 2010). The strict policy that was learned from simulated younger users was as follows, with only slight variations: first request the type of health professional, then implicitly confirm the health professional and request the half-day slot, then implicitly confirm the half-day slot and request the time slot, and then confirm the appointment. The strict policy learned from simulated older users was similar, but less successful, because most older users do not readily conform to the fixed structure. The flexible policy learned from simulated older users takes into account initiative from the user an</context>
</contexts>
<marker>Georgila, Wolters, Moore, Logie, 2010</marker>
<rawString>K. Georgila, Maria Wolters, J.D. Moore, and R.H. Logie. 2010. The MATCH corpus: A corpus of older and younger users’ interactions with spoken dialogue systems. Language Resources and Evaluation, 44(3):221–261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Janarthanam</author>
<author>O Lemon</author>
</authors>
<title>A two-tier user simulation model for reinforcement learning of adaptive referring expression generation policies. In</title>
<date>2009</date>
<booktitle>Proc. SIGdial.</booktitle>
<contexts>
<context position="2242" citStr="Janarthanam and Lemon, 2009" startWordPosition="341" endWordPosition="344">e system with simulated users (SUs) (Georgila et al., 2006). In order to learn good policies, the behaviour of the SUs needs to cover the range of variation seen in real users (Georgila et al., 2006; Schatzmann et al., 2006). Furthermore, SUs are critical for evaluating candidate dialogue policies. To date, SUs have been used to learn dialogue strategies for specific domains such as flight reservation, restaurant recommendation, etc., and to learn both how to collect information from the user (Frampton and Lemon, 2006) as well as how to present information to the user (Rieser and Lemon, 2009; Janarthanam and Lemon, 2009). In addition to covering different domains, SUs should also be able to model relevant user attributes (Schatzmann et al., 2006), such as cooperativeness vs. non-cooperativeness (L´opez-C´ozar et al., 2006; Jung et al., 2009), or age (Georgila et al., 2008). In this paper, we focus on user age. As the proportion of older people in the population increases, it becomes essential to make spoken dialogue systems (SDS) easy to use for this group of people. Only very few spoken dialogue systems have been developed for older people (e.g. Nursebot (Roy et al., 2000)), and we are aware of no work on le</context>
</contexts>
<marker>Janarthanam, Lemon, 2009</marker>
<rawString>S. Janarthanam and O. Lemon. 2009. A two-tier user simulation model for reinforcement learning of adaptive referring expression generation policies. In Proc. SIGdial.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Jung</author>
<author>C Lee</author>
<author>K Kim</author>
<author>G G Lee</author>
</authors>
<title>Hybrid approach to user intention modeling for dialog simulation.</title>
<date>2009</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="2467" citStr="Jung et al., 2009" startWordPosition="376" endWordPosition="379">re, SUs are critical for evaluating candidate dialogue policies. To date, SUs have been used to learn dialogue strategies for specific domains such as flight reservation, restaurant recommendation, etc., and to learn both how to collect information from the user (Frampton and Lemon, 2006) as well as how to present information to the user (Rieser and Lemon, 2009; Janarthanam and Lemon, 2009). In addition to covering different domains, SUs should also be able to model relevant user attributes (Schatzmann et al., 2006), such as cooperativeness vs. non-cooperativeness (L´opez-C´ozar et al., 2006; Jung et al., 2009), or age (Georgila et al., 2008). In this paper, we focus on user age. As the proportion of older people in the population increases, it becomes essential to make spoken dialogue systems (SDS) easy to use for this group of people. Only very few spoken dialogue systems have been developed for older people (e.g. Nursebot (Roy et al., 2000)), and we are aware of no work on learning specific dialogue policies for older people using SUs and RL. Older people present special challenges for dialogue systems. While cognitive and perceptual abilities generally decline with age, the spread of ability in </context>
</contexts>
<marker>Jung, Lee, Kim, Lee, 2009</marker>
<rawString>S. Jung, C. Lee, K. Kim, and G.G. Lee. 2009. Hybrid approach to user intention modeling for dialog simulation. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L´opez-C´ozar</author>
<author>Z Callejas</author>
<author>M McTear</author>
</authors>
<title>Testing the performance of spoken dialogue systems by means of an artificially simulated user.</title>
<date>2006</date>
<journal>Artificial Intelligence Review,</journal>
<volume>26</volume>
<issue>4</issue>
<marker>L´opez-C´ozar, Callejas, McTear, 2006</marker>
<rawString>R. L´opez-C´ozar, Z. Callejas, and M. McTear. 2006. Testing the performance of spoken dialogue systems by means of an artificially simulated user. Artificial Intelligence Review, 26(4):291–323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Rabbitt</author>
<author>M M Anderson</author>
</authors>
<title>The lacunae of loss? Aging and the differentiation of human abilities.</title>
<date>2005</date>
<booktitle>Lifespan Cognition: Mechanisms of Change, chapter 23.</booktitle>
<editor>In F.I. Craik and E. Bialystok, editors,</editor>
<publisher>Oxford University Press,</publisher>
<location>New York, NY.</location>
<contexts>
<context position="3166" citStr="Rabbitt and Anderson, 2005" startWordPosition="496" endWordPosition="500">s the proportion of older people in the population increases, it becomes essential to make spoken dialogue systems (SDS) easy to use for this group of people. Only very few spoken dialogue systems have been developed for older people (e.g. Nursebot (Roy et al., 2000)), and we are aware of no work on learning specific dialogue policies for older people using SUs and RL. Older people present special challenges for dialogue systems. While cognitive and perceptual abilities generally decline with age, the spread of ability in older people is far larger than in any other segment of the population (Rabbitt and Anderson, 2005). Older users may also use different strategies for interacting with SDS. In our previous work on studying the interactions between older and younger users and a simulated appointment scheduling SDS (Wolters et al., 2009b), we found that some older users were very “social”, treating the system like a human, and failing to adapt to the SDS’s system-initiative dialogue strategy. A third of the older users, however, tended to be more “factual”, using short commands and conforming to the system’s dialogue strategy. In that, they were very similar to the younger users (Wolters et al., 2009b). In pr</context>
</contexts>
<marker>Rabbitt, Anderson, 2005</marker>
<rawString>P. Rabbitt and M.M. Anderson. 2005. The lacunae of loss? Aging and the differentiation of human abilities. In F.I. Craik and E. Bialystok, editors, Lifespan Cognition: Mechanisms of Change, chapter 23. Oxford University Press, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Rieser</author>
<author>O Lemon</author>
</authors>
<title>Natural language generation as planning under uncertainty for spoken dialogue systems.</title>
<date>2009</date>
<booktitle>In Proc. EACL.</booktitle>
<contexts>
<context position="2212" citStr="Rieser and Lemon, 2009" startWordPosition="337" endWordPosition="340">rough interactions of the system with simulated users (SUs) (Georgila et al., 2006). In order to learn good policies, the behaviour of the SUs needs to cover the range of variation seen in real users (Georgila et al., 2006; Schatzmann et al., 2006). Furthermore, SUs are critical for evaluating candidate dialogue policies. To date, SUs have been used to learn dialogue strategies for specific domains such as flight reservation, restaurant recommendation, etc., and to learn both how to collect information from the user (Frampton and Lemon, 2006) as well as how to present information to the user (Rieser and Lemon, 2009; Janarthanam and Lemon, 2009). In addition to covering different domains, SUs should also be able to model relevant user attributes (Schatzmann et al., 2006), such as cooperativeness vs. non-cooperativeness (L´opez-C´ozar et al., 2006; Jung et al., 2009), or age (Georgila et al., 2008). In this paper, we focus on user age. As the proportion of older people in the population increases, it becomes essential to make spoken dialogue systems (SDS) easy to use for this group of people. Only very few spoken dialogue systems have been developed for older people (e.g. Nursebot (Roy et al., 2000)), and</context>
</contexts>
<marker>Rieser, Lemon, 2009</marker>
<rawString>V. Rieser and O. Lemon. 2009. Natural language generation as planning under uncertainty for spoken dialogue systems. In Proc. EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Roy</author>
<author>J Pineau</author>
<author>S Thrun</author>
</authors>
<title>Spoken dialog management for robots.</title>
<date>2000</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="2806" citStr="Roy et al., 2000" startWordPosition="437" endWordPosition="440">(Rieser and Lemon, 2009; Janarthanam and Lemon, 2009). In addition to covering different domains, SUs should also be able to model relevant user attributes (Schatzmann et al., 2006), such as cooperativeness vs. non-cooperativeness (L´opez-C´ozar et al., 2006; Jung et al., 2009), or age (Georgila et al., 2008). In this paper, we focus on user age. As the proportion of older people in the population increases, it becomes essential to make spoken dialogue systems (SDS) easy to use for this group of people. Only very few spoken dialogue systems have been developed for older people (e.g. Nursebot (Roy et al., 2000)), and we are aware of no work on learning specific dialogue policies for older people using SUs and RL. Older people present special challenges for dialogue systems. While cognitive and perceptual abilities generally decline with age, the spread of ability in older people is far larger than in any other segment of the population (Rabbitt and Anderson, 2005). Older users may also use different strategies for interacting with SDS. In our previous work on studying the interactions between older and younger users and a simulated appointment scheduling SDS (Wolters et al., 2009b), we found that so</context>
</contexts>
<marker>Roy, Pineau, Thrun, 2000</marker>
<rawString>N. Roy, J. Pineau, and S. Thrun. 2000. Spoken dialog management for robots. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Schatzmann</author>
<author>K Weilhammer</author>
<author>M Stuttle</author>
<author>S Young</author>
</authors>
<title>A survey of statistical user simulation techniques for reinforcement-learning of dialogue management strategies.</title>
<date>2006</date>
<journal>Knowlege Engineering Review,</journal>
<volume>21</volume>
<issue>2</issue>
<pages>126</pages>
<contexts>
<context position="1838" citStr="Schatzmann et al., 2006" startWordPosition="278" endWordPosition="281">mpton and Lemon, 2006; Williams and Young, 2007) rely on having adequate training data. Dialogue strategies are typically inferred from data using Reinforcement Learning (RL), which requires on the order of thousands of dialogues to achieve good performance. Therefore, it is no longer feasible to rely on data collected with real users. Instead, training data is generated through interactions of the system with simulated users (SUs) (Georgila et al., 2006). In order to learn good policies, the behaviour of the SUs needs to cover the range of variation seen in real users (Georgila et al., 2006; Schatzmann et al., 2006). Furthermore, SUs are critical for evaluating candidate dialogue policies. To date, SUs have been used to learn dialogue strategies for specific domains such as flight reservation, restaurant recommendation, etc., and to learn both how to collect information from the user (Frampton and Lemon, 2006) as well as how to present information to the user (Rieser and Lemon, 2009; Janarthanam and Lemon, 2009). In addition to covering different domains, SUs should also be able to model relevant user attributes (Schatzmann et al., 2006), such as cooperativeness vs. non-cooperativeness (L´opez-C´ozar et </context>
<context position="4297" citStr="Schatzmann et al., 2006" startWordPosition="681" endWordPosition="685">strategy. In that, they were very similar to the younger users (Wolters et al., 2009b). In previous work (Georgila et al., 2008), we successfully built SUs for both older and younger Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 103–106, The University of Tokyo, September 24-25, 2010. c�2010 Association for Computational Linguistics 103 adults from the corpus used by (Wolters et al., 2009b) and documented in (Georgila et al., 2010). When we evaluated the SUs using metrics such as precision and recall (Georgila et al., 2006; Schatzmann et al., 2006), we found that SUs trained on older users’ data can cover behaviour patterns typical of younger users, but not the opposite. The behaviour of older people is too diverse to be captured by a SU trained on younger users’ data. This result agrees with the findings of (Wolters et al., 2009b; Georgila et al., 2010). In this study, we take our work one step further—we use the SUs developed in (Georgila et al., 2008) to learn dialogue policies and evaluate the resulting policies with data from both older and younger users. Our work is important for two reasons. First, to the best of our knowledge th</context>
</contexts>
<marker>Schatzmann, Weilhammer, Stuttle, Young, 2006</marker>
<rawString>J. Schatzmann, K. Weilhammer, M. Stuttle, and S. Young. 2006. A survey of statistical user simulation techniques for reinforcement-learning of dialogue management strategies. Knowlege Engineering Review, 21(2):97– 126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R S Sutton</author>
<author>A G Barto</author>
</authors>
<title>Reinforcement Learning: An Introduction.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="11534" citStr="Sutton and Barto, 1998" startWordPosition="1905" endWordPosition="1908">lly and confirmed appointments are rewarded, while long dialogues are penalised. For Experiment 1, policies were rewarded that filled slots in the correct order and that confirmed each slot after it had been filled. A large penalty was imposed when the policy deviated from the strict slot order (health professional, half-day, time slot). For Experiment 2, these constraints were removed. Slots could be filled in any order. Confirmations were not required because there was no speech act in the corpus for confirming more than one slot at a time. In both experiments we used the SARSA-A algorithm (Sutton and Barto, 1998) for RL. 30,000 iterations were used for learning the final policy for each condition. For each experiment, we learned two policies, Policy-Old, which was based on simulated older users, and Policy-Young, which was based on simulated younger users. The resulting policies were then tested on simulated older users (Test-Old) and simulated younger users (Test-Young). To have comparable results between Experiment 1 and Experiment 2, during testing we score our policies using the reward function of Experiment 2. The best possible score is 190, i.e. the user fills all the slots in one turn and then </context>
</contexts>
<marker>Sutton, Barto, 1998</marker>
<rawString>R.S. Sutton and A.G. Barto. 1998. Reinforcement Learning: An Introduction. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Williams</author>
<author>S Young</author>
</authors>
<title>Partially observable Markov decision processes for spoken dialog systems.</title>
<date>2007</date>
<journal>Computer Speech and Language,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="1262" citStr="Williams and Young, 2007" startWordPosition="181" endWordPosition="184">lated older users. The simulated users were derived from a corpus of interactions with a strict system-initiative spoken dialogue system (SDS). Learning from simulated younger users leads to a policy which is close to one of the dialogue strategies of the underlying SDS, while the simulated older users allow us to learn more flexible dialogue strategies that accommodate mixed initiative. We conclude that simulated users are a useful technique for modelling the behaviour of new user groups. 1 Introduction State-of-the-art statistical approaches to dialogue management (Frampton and Lemon, 2006; Williams and Young, 2007) rely on having adequate training data. Dialogue strategies are typically inferred from data using Reinforcement Learning (RL), which requires on the order of thousands of dialogues to achieve good performance. Therefore, it is no longer feasible to rely on data collected with real users. Instead, training data is generated through interactions of the system with simulated users (SUs) (Georgila et al., 2006). In order to learn good policies, the behaviour of the SUs needs to cover the range of variation seen in real users (Georgila et al., 2006; Schatzmann et al., 2006). Furthermore, SUs are c</context>
</contexts>
<marker>Williams, Young, 2007</marker>
<rawString>J. Williams and S. Young. 2007. Partially observable Markov decision processes for spoken dialog systems. Computer Speech and Language, 21(2):393–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Wolters</author>
<author>K Georgila</author>
<author>J D Moore</author>
<author>R H Logie</author>
<author>S E MacPherson</author>
<author>M Watson</author>
</authors>
<title>Reducing working memory load in spoken dialogue systems.</title>
<date>2009</date>
<journal>Interacting with Computers,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="3386" citStr="Wolters et al., 2009" startWordPosition="534" endWordPosition="537">people (e.g. Nursebot (Roy et al., 2000)), and we are aware of no work on learning specific dialogue policies for older people using SUs and RL. Older people present special challenges for dialogue systems. While cognitive and perceptual abilities generally decline with age, the spread of ability in older people is far larger than in any other segment of the population (Rabbitt and Anderson, 2005). Older users may also use different strategies for interacting with SDS. In our previous work on studying the interactions between older and younger users and a simulated appointment scheduling SDS (Wolters et al., 2009b), we found that some older users were very “social”, treating the system like a human, and failing to adapt to the SDS’s system-initiative dialogue strategy. A third of the older users, however, tended to be more “factual”, using short commands and conforming to the system’s dialogue strategy. In that, they were very similar to the younger users (Wolters et al., 2009b). In previous work (Georgila et al., 2008), we successfully built SUs for both older and younger Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 103–106, The U</context>
<context position="6735" citStr="Wolters et al., 2009" startWordPosition="1100" endWordPosition="1103">of options presented at each stage of the dialogue (1, 2, 4), and in the confirmation strategies used (explicit confirmation, implicit confirmation, no confirmation). System utterances were generated using a simple template-based algorithm and synthesised using a female Scottish English unit selection voice. The human Wizard took over the function of speech recognition (ASR), language understanding (NLU), and dialogue management components. No ASR or NLU errors were simulated, because having to deal with ASR and/or NLU errors in addition to task completion would have increased cognitive load (Wolters et al., 2009a). The system (Wizard) followed a strict policy which resulted in dialogues with a fixed schema: First, users arranged to see a specific health care professional, then they arranged a specific halfday, and finally, a specific half-hour time slot on that half-day was agreed. Users were not allowed to skip any stage of the dialogue. This design ensured that all users were presented with the relevant number of options and the relevant confirmation strategy at least three times per dialogue. In a final step, the Wizard confirmed the appointment. The full corpus consists of 447 dialogues; 3 dialog</context>
<context position="8514" citStr="Wolters et al., 2009" startWordPosition="1391" endWordPosition="1394">task corresponds to the slot in focus (health professional, half-day or time slot). For example, (confirm pos, hp) corresponds to positive explicit confirmation of the health professional slot. For each dialogue, detailed measures of dialogue quality were recorded: objective task completion, perceived task completion, appointment recall, length (in turns), and extensive user satisfaction ratings. For a detailed discussion of the corpus, see (Georgila et al., 2010). The choice of dialogue strategy did not affect task completion and appointment recall, but had significant effects on efficiency (Wolters et al., 2009a). Task completion and appointment recall were the same for older and younger users, but older users took more turns to complete the task (Wolters et al., 2009a). Clear differences between the two user groups emerge when we look at interaction patterns in more detail (Wolters et al., 2009b; Georgila et al., 2010). Older people tend to “ground” information (using repetitions) and take the initiative more than younger people. In our corpus it was very common that the older person would provide information about the half-day and the time slot of the appointment before having been asked by the sy</context>
<context position="13157" citStr="Wolters et al., 2009" startWordPosition="2169" endWordPosition="2172">ing data set (F(1,185)=3, p=0.09), we found a very strong interaction between policy type and data set (F(1, 3098)=51, p=0.000). Learning with simulated younger users yields better strict policies than learning with older users (Tukey’s Honest Significant Difference Test, A=20, 95% CI = [11, 30], p=0.000), while learning with simulated older users yields better flexible policies than learning with younger users (A=15, 95% CI = [6,24], p=0.001). This is what we would expect from our corpus analysis, since the interaction behaviour of older users is far more variable than that of younger users (Wolters et al., 2009b; Georgila et al., 2010). The strict policy that was learned from simulated younger users was as follows, with only slight variations: first request the type of health professional, then implicitly confirm the health professional and request the half-day slot, then implicitly confirm the half-day slot and request the time slot, and then confirm the appointment. The strict policy learned from simulated older users was similar, but less successful, because most older users do not readily conform to the fixed structure. The flexible policy learned from simulated older users takes into account in</context>
<context position="15194" citStr="Wolters et al., 2009" startWordPosition="2492" endWordPosition="2495">rs that the explicit penalty for violating the order of slots is crucial for fully exploiting the patterns in younger users’ behaviour. 4 Conclusions We have shown that SUs can be used to learn appropriate policies for older adults, even though their interaction behaviour is more complex and diverse than that of younger adults. Crucially, simulated older users allowed us to learn a more flexible version of the strict system-initiative dialogue strategies that were used for creating the original corpus of interactions. These results are consistent with previous analyses of the original corpus (Wolters et al., 2009b; Georgila et al., 2010) and support the validity of the user simulation methodology for learning and evaluating dialogue strategies. In our future work, we will experiment with more complex SUs, e.g. linear feature combination models (Georgila et al., 2006), and see if they can be used to learn similar policies. We also plan to study the effect of training and testing with different user simulation techniques, such as n-grams versus linear feature combination models. Acknowledgements This research was partially supported by the MATCH project (SHEFC-HR04016, http://www.match-project. Referenc</context>
</contexts>
<marker>Wolters, Georgila, Moore, Logie, MacPherson, Watson, 2009</marker>
<rawString>M. Wolters, K. Georgila, J.D. Moore, R.H. Logie, S.E. MacPherson, and M. Watson. 2009a. Reducing working memory load in spoken dialogue systems. Interacting with Computers, 21(4):276–287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Wolters</author>
<author>K Georgila</author>
<author>J D Moore</author>
<author>S E MacPherson</author>
</authors>
<title>Being old doesn’t mean acting old: How older users interact with spoken dialog systems.</title>
<date>2009</date>
<journal>ACM Trans. Accessible Computing,</journal>
<volume>2</volume>
<issue>1</issue>
<contexts>
<context position="3386" citStr="Wolters et al., 2009" startWordPosition="534" endWordPosition="537">people (e.g. Nursebot (Roy et al., 2000)), and we are aware of no work on learning specific dialogue policies for older people using SUs and RL. Older people present special challenges for dialogue systems. While cognitive and perceptual abilities generally decline with age, the spread of ability in older people is far larger than in any other segment of the population (Rabbitt and Anderson, 2005). Older users may also use different strategies for interacting with SDS. In our previous work on studying the interactions between older and younger users and a simulated appointment scheduling SDS (Wolters et al., 2009b), we found that some older users were very “social”, treating the system like a human, and failing to adapt to the SDS’s system-initiative dialogue strategy. A third of the older users, however, tended to be more “factual”, using short commands and conforming to the system’s dialogue strategy. In that, they were very similar to the younger users (Wolters et al., 2009b). In previous work (Georgila et al., 2008), we successfully built SUs for both older and younger Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 103–106, The U</context>
<context position="6735" citStr="Wolters et al., 2009" startWordPosition="1100" endWordPosition="1103">of options presented at each stage of the dialogue (1, 2, 4), and in the confirmation strategies used (explicit confirmation, implicit confirmation, no confirmation). System utterances were generated using a simple template-based algorithm and synthesised using a female Scottish English unit selection voice. The human Wizard took over the function of speech recognition (ASR), language understanding (NLU), and dialogue management components. No ASR or NLU errors were simulated, because having to deal with ASR and/or NLU errors in addition to task completion would have increased cognitive load (Wolters et al., 2009a). The system (Wizard) followed a strict policy which resulted in dialogues with a fixed schema: First, users arranged to see a specific health care professional, then they arranged a specific halfday, and finally, a specific half-hour time slot on that half-day was agreed. Users were not allowed to skip any stage of the dialogue. This design ensured that all users were presented with the relevant number of options and the relevant confirmation strategy at least three times per dialogue. In a final step, the Wizard confirmed the appointment. The full corpus consists of 447 dialogues; 3 dialog</context>
<context position="8514" citStr="Wolters et al., 2009" startWordPosition="1391" endWordPosition="1394">task corresponds to the slot in focus (health professional, half-day or time slot). For example, (confirm pos, hp) corresponds to positive explicit confirmation of the health professional slot. For each dialogue, detailed measures of dialogue quality were recorded: objective task completion, perceived task completion, appointment recall, length (in turns), and extensive user satisfaction ratings. For a detailed discussion of the corpus, see (Georgila et al., 2010). The choice of dialogue strategy did not affect task completion and appointment recall, but had significant effects on efficiency (Wolters et al., 2009a). Task completion and appointment recall were the same for older and younger users, but older users took more turns to complete the task (Wolters et al., 2009a). Clear differences between the two user groups emerge when we look at interaction patterns in more detail (Wolters et al., 2009b; Georgila et al., 2010). Older people tend to “ground” information (using repetitions) and take the initiative more than younger people. In our corpus it was very common that the older person would provide information about the half-day and the time slot of the appointment before having been asked by the sy</context>
<context position="13157" citStr="Wolters et al., 2009" startWordPosition="2169" endWordPosition="2172">ing data set (F(1,185)=3, p=0.09), we found a very strong interaction between policy type and data set (F(1, 3098)=51, p=0.000). Learning with simulated younger users yields better strict policies than learning with older users (Tukey’s Honest Significant Difference Test, A=20, 95% CI = [11, 30], p=0.000), while learning with simulated older users yields better flexible policies than learning with younger users (A=15, 95% CI = [6,24], p=0.001). This is what we would expect from our corpus analysis, since the interaction behaviour of older users is far more variable than that of younger users (Wolters et al., 2009b; Georgila et al., 2010). The strict policy that was learned from simulated younger users was as follows, with only slight variations: first request the type of health professional, then implicitly confirm the health professional and request the half-day slot, then implicitly confirm the half-day slot and request the time slot, and then confirm the appointment. The strict policy learned from simulated older users was similar, but less successful, because most older users do not readily conform to the fixed structure. The flexible policy learned from simulated older users takes into account in</context>
<context position="15194" citStr="Wolters et al., 2009" startWordPosition="2492" endWordPosition="2495">rs that the explicit penalty for violating the order of slots is crucial for fully exploiting the patterns in younger users’ behaviour. 4 Conclusions We have shown that SUs can be used to learn appropriate policies for older adults, even though their interaction behaviour is more complex and diverse than that of younger adults. Crucially, simulated older users allowed us to learn a more flexible version of the strict system-initiative dialogue strategies that were used for creating the original corpus of interactions. These results are consistent with previous analyses of the original corpus (Wolters et al., 2009b; Georgila et al., 2010) and support the validity of the user simulation methodology for learning and evaluating dialogue strategies. In our future work, we will experiment with more complex SUs, e.g. linear feature combination models (Georgila et al., 2006), and see if they can be used to learn similar policies. We also plan to study the effect of training and testing with different user simulation techniques, such as n-grams versus linear feature combination models. Acknowledgements This research was partially supported by the MATCH project (SHEFC-HR04016, http://www.match-project. Referenc</context>
</contexts>
<marker>Wolters, Georgila, Moore, MacPherson, 2009</marker>
<rawString>M. Wolters, K. Georgila, J.D. Moore, and S.E. MacPherson. 2009b. Being old doesn’t mean acting old: How older users interact with spoken dialog systems. ACM Trans. Accessible Computing, 2(1).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>