<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000013">
<title confidence="0.9972925">
User-Driven Development of Text Mining Resources for Cancer Risk
Assessment
</title>
<author confidence="0.99949">
Lin Sun, Anna Korhonen
</author>
<affiliation confidence="0.9770815">
University of Cambridge
Computer Laboratory
</affiliation>
<address confidence="0.991258">
15 JJ Thomson Avenue
Cambridge CB3 0GD, UK
</address>
<email confidence="0.998806">
ls418,alk23@cl.cam.ac.uk
</email>
<sectionHeader confidence="0.993885" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99991165">
One of the most neglected areas of biomed-
ical Text Mining (TM) is the development
of systems based on carefully assessed user
needs. We investigate the needs of an im-
portant task yet to be tackled by TM — Can-
cer Risk Assessment (CRA) — and take the
first step towards the development of TM for
the task: identifying and organizing the sci-
entific evidence required for CRA in a taxon-
omy. The taxonomy is based on expert annota-
tion of 1297 MEDLINE abstracts. We report
promising results with inter-annotator agree-
ment tests and automatic classification experi-
ments, and a user test which demonstrates that
the resources we have built are well-defined,
accurate, and applicable to a real-world CRA
scenario. We discuss extending and refining
the taxonomy further via manual and machine
learning approaches, and the subsequent steps
required to develop TM for the needs of CRA.
</bodyText>
<sectionHeader confidence="0.99912" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998900428571429">
Biomedical Text Mining (TM) has become increas-
ingly popular due to the pressing need to provide
access to the tremendous body of texts available
in biomedical sciences. Considerable progress has
been made in the development of basic resources
(e.g. ontologies, annotated corpora) and techniques
(e.g. Information Retrieval (IR), Information Ex-
traction (IE)) in this area, and research has began
to focus on increasingly challenging tasks, e.g. sum-
marization and the discovery of novel information in
biomedical literature (Hunter and Cohen 2006, Ana-
niadou et al. 2006, Zweigenbaum et al. 2007).
In recent past, there has been an increasing de-
mand for research which is driven by actual user
</bodyText>
<note confidence="0.606890666666667">
Ilona Silins, Ulla Stenius
Institute of Environmental Medicine
Karolinska Institutet
</note>
<address confidence="0.399314">
S-17177, Stockholm
Sweden
</address>
<email confidence="0.806896">
ilona.silins,ulla.stenius@ki.se
</email>
<bodyText confidence="0.999924361111111">
needs rather than technical developments (Zweigen-
baum et al. 2007). Shared tasks (e.g. BioCreative
and the TREC Genomics track) targeting the work-
flow of biomedical researchers have appeared along
with studies exploring the TM needs of specific tasks
(Karamanis et al. 2008, Demaine et al. 2006). How-
ever, the understanding of user needs is still one of
the neglected areas of BIO-TM, and further user-
centered evaluations and systems grounded in real-
life tasks are required to determine which tools and
services are useful (Cohen et al. 2008).
We investigate the user needs of a challenging
task yet to be tackled by TM but identified as an
important potential application for it (Lewin et al.
2008): Cancer Risk Assessment (CRA). Over the
past years, CRA has become increasingly important
as the link between environmental chemicals and
cancer has become evident. It involves examining
published evidence to determine the relationship be-
tween exposure to a chemical and the likelihood of
developing cancer from that exposure (EPA, 2005).
Performed manually by experts in health related in-
stitutions worldwide, CRA requires searching, lo-
cating and interpreting information in biomedical
journal articles. It can be extremely time-consuming
because the data for a single carcinogen may be scat-
tered across thousands of articles.
Given the exponentially growing volume of
biomedical literature and the rapid development of
molecular biology techniques, the task is now get-
ting too challenging to manage via manual means.
From the perspective of BIO-TM, CRA is an excel-
lent example of real-world task which could greatly
benefit from a dedicated TM tool. However, the de-
velopment of a truly useful tool requires careful in-
vestigation of risk assessors needs.
</bodyText>
<page confidence="0.981127">
108
</page>
<note confidence="0.9061765">
Proceedings of the Workshop on BioNLP, pages 108–116,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.9999238125">
This paper reports our investigation of the user
needs of CRA and the creation of basic TM re-
sources for the task. Expanding on our preliminary
experiments (Lewin et al. 2008), we present a taxon-
omy which specifies the scientific evidence needed
for CRA at the level of detail required for TM. The
taxonomy is based on expert annotation of a corpus
of 1297 MEDLINE abstracts. We report promis-
ing results with inter-annotator agreement tests, au-
tomatic classification of corpus data into taxonomy
classes, and a user test in a near real-world CRA
scenario which shows that the taxonomy is highly
accurate and useful for practical CRA. We discuss
refining and extending it further via manual and ma-
chine learning approaches, and the subsequent steps
required to develop TM for the needs of CRA.
</bodyText>
<sectionHeader confidence="0.940668" genericHeader="method">
2 User Needs of Cancer Risk Assessment
</sectionHeader>
<bodyText confidence="0.999907851851852">
We interviewed 14 experienced risk assessors work-
ing for a number of authorities in Sweden1 asking
a range of questions related to different aspects of
their work. The risk assessors described the follow-
ing steps of CRA: (1) identifying the journal articles
relevant for CRA of the chemical in question, (2)
identifying the scientific evidence in these articles
which help to determine whether/how the chemical
causes cancer, (3) classifying and analysing the re-
sulting (partly conflicting) evidence to build the tox-
icological profile for the chemical, and (4) prepar-
ing the risk assessment report. These steps are con-
ducted manually, relying only on standard literature
search engines (e.g. PubMed) and word processors.
The average time required for CRA of a single
chemical was reported to be two years when done
(as usual) on a part time basis. Risk assessors were
unanimous about the need to increase productivity
to meet the current CRA demand. They reported
that locating and classifying the scientific evidence
in literature is the most time consuming part of their
work and that a tool capable of assisting it and ensur-
ing that all the potentially relevant evidence is found
would be particularly helpful.
It became clear that a prerequisite for the devel-
opment of such a tool would be an extensive spec-
ification of the scientific evidence used for CRA.
</bodyText>
<affiliation confidence="0.611653">
1Institute of Environmental Medicine at Karolinska Insti-
tutet, Swedish Chemical Inspectorate, Scientific Committee on
Occupational Exposure Limits (EU), Swedish Criteria Group.
</affiliation>
<bodyText confidence="0.999887333333333">
This evidence — which forms the basis of all the
subsequent steps of CRA — is described in the
guideline documents of major international CRA
agencies, e.g. European Chemicals Agency (ECHA,
2008) and the United States Environmental Protec-
tion Agency (EPA, 2005). However, although these
documents constitute the main reference material in
CRA, they cover the main types of evidence only,
do not specify the evidence at the level of detail
required for comprehensive data gathering, and are
not updated regularly (i.e. do not incorporate the lat-
est developments in biomedical sciences). The risk
assessors admitted that rather than relying on these
documents, they rely on their experience and expert
knowledge when looking for the evidence. We de-
cided that our starting point should be to compose
a more adequate specification of the scientific evi-
dence needed for CRA.
</bodyText>
<sectionHeader confidence="0.997828" genericHeader="method">
3 Cancer Risk Assessment Taxonomy
</sectionHeader>
<bodyText confidence="0.716265666666666">
We recruited three experienced risk assessors to help
construct the resources described in sections below:
(i) a representative corpus of CRA literature for
parts of hazard identification (i.e. the assessment of
whether a chemical is capable of causing cancer),
(ii) a tool for expert annotation of the corpus, (iii) an
annotated corpus, and (iv) a taxonomy which classi-
fies and organizes the scientific evidence discovered
in the corpus.
</bodyText>
<subsectionHeader confidence="0.996947">
3.1 CRA corpus
</subsectionHeader>
<bodyText confidence="0.909662823529412">
Various human, animal (in vivo), cellular (in vitro)
and other mechanistic data provide evidence for haz-
ard identification and the assessment of the Mode of
Action (MOA) (i.e. the sequence of key events that
result in cancer formation, e.g. mutagenesis and in-
creased cell proliferation) in CRA. The experts se-
lected eight chemicals which are (i) well-researched
using a range of scientific tests and (ii) represent the
two most frequently used MOAs – genotoxic and
non-genotoxic2. 15 journals were identified which
are used frequently for CRA and jointly provide a
good coverage of relevant scientific evidence (e.g.
Cancer Research, Chemico-biological Interaction,
Mutagenesis, Toxicological Sciences). From these
2Chemicals acting by a genotoxic MOA interact with DNA,
while chemicals acting by a nongenotoxic MOA induce cancer
without interfering directly with DNA.
</bodyText>
<page confidence="0.998393">
109
</page>
<figureCaption confidence="0.999908">
Figure 1: Screenshot of the annotation tool
</figureCaption>
<bodyText confidence="0.996699">
journals, all the PubMed abstracts from 1998-2008
which include one of the 8 chemicals were down-
loaded. The resulting corpus of 1297 abstracts is
distributed per chemical as shown in Table 1.
</bodyText>
<subsectionHeader confidence="0.999809">
3.2 Annotation tool
</subsectionHeader>
<bodyText confidence="0.999979142857143">
Risk assessors typically (i) read each abstract re-
trieved by PubMed to determine its relevance for
CRA, and (ii) classify each relevant abstract based
on the type of evidence it provides for CRA. We ex-
tended the tool designed for expert annotation of ab-
stracts in our earlier work (Lewin et al. 2008) so that
imitates this process as closely as possible.
The tool provides two types of functionality. The
first enables the experts to classify abstracts as rele-
vant, irrelevant or unsure. The second enables them
to annotate such keywords (words or phrases) in ab-
stracts and their titles which indicate the scientific
evidence relevant for the task. Keyword annotation
was chosen because the experts found it intuitive, it
did not require linguistic training, and it specifies the
scientific evidence more precisely than larger spans
of text.
Initially a very shallow taxonomy (including only
human, animal, and cellular data) and the two types
of MOA was integrated inside the tool. This was
gradually extended as the annotation progressed.
The tool permits annotating any number of relevant
keywords in the abstracts, attaching them to any
class in the taxonomy, and classifying the same text
in more than one way. It was implemented inside the
familiar Mozilla Firefox browser using its extension
facility. A screenshot illustrating the tool is provided
in Figure 1.
</bodyText>
<subsectionHeader confidence="0.998833">
3.3 Annotation
</subsectionHeader>
<bodyText confidence="0.999993">
Given a set of initial guidelines agreed by the ex-
perts, one of the experts annotated a subset of the
corpus, the other two evaluated the result, disagree-
ments were then discussed, and the guidelines were
improved where needed. This process (crucial for
maintaining quality) was repeated several times.
The guidelines described below are the final result
of this work.
</bodyText>
<subsectionHeader confidence="0.857269">
3.3.1 Relevance annotation
</subsectionHeader>
<bodyText confidence="0.999991833333333">
An abstract is classified as (i) relevant when it (or
its title) contains evidence relevant for CRA and (ii)
irrelevant when it (or its title) contains no evidence
or contains ”negative” evidence (e.g. diseases or
endpoints unrelated to cancer). Abstracts containing
vague, conflicting or complex evidence (e.g. stud-
ies on chemicals in complex mixtures) or evidence
whose association with cancer is currently unclear
were dealt on case by case basis. All the potentially
relevant abstracts were included for further assess-
ment as not to lose data valuable for CRA.
The experts annotated the 1297 abstracts in the
corpus. 89.4% were classified as relevant, 10.1% as
irrelevant, and 0.5% as unsure. We used the Kappa
statistics (Cohen 1960) to measure inter-annotator
agreement on unseen data which two experts an-
notated independently. 208 abstracts were selected
randomly from the 15 journals and from 16 jour-
nals likely to be irrelevant for CRA. The latter were
included to make the task harder as the proportion
of relevant abstracts was high in our corpus. Our
Kappa result is 0.68 — a figure which indicates sub-
stantial agreement (Landis and G.Koch 1977).
The experts disagreed on 24 (11.5% of the) ab-
stracts. Half of the disagreements are due to one
of the annotators failing to notice relevant evidence.
Such cases are likely to decrease when annotators
gain more experience. The other half are caused by
vague or conflicting evidence. Many of these could
be addressed by further development of guidelines.
</bodyText>
<subsectionHeader confidence="0.872623">
3.3.2 Keyword annotation
</subsectionHeader>
<bodyText confidence="0.9998642">
Keyword annotation focussed on the types of sci-
entific evidence experts typically look for in CRA:
carcinogenic activity (human, animal, cellular, and
other mechanistic data), Mode of Action (MOA)
(data for a specific MOA type — genotoxic or non-
</bodyText>
<page confidence="0.992575">
110
</page>
<table confidence="0.9996501">
Chemical Retrieved Relevant
1,3-butadiene 195 187
phenobarbital 270 240
diethylnitrosamine 221 214
diethylstilbestrol 145 110
benzoapyrene 201 192
fumonisin 80 70
chloroform 96 84
styrene 162 132
Total 1297 1164
</table>
<tableCaption confidence="0.999904">
Table 1: Total of abstracts per chemical
</tableCaption>
<bodyText confidence="0.999954166666667">
genotoxic), and relevant parts of toxicokinetics (e.g.
metabolic activation). The experts annotated the
keywords which they considered as the most impor-
tant and which jointly identify the types of scientific
data offered by the abstract. They focussed on new
(rather than previously published) data on the chem-
ical in question.
All the 1164 abstracts deemed relevant were an-
notated. A total of 1742 unique keywords were
identified, both simple nouns and complex nomi-
nals / phrases. Figure 1 shows an example of an
annotated abstract where the keyword chromoso-
mal aberrations is identified as evidence for geno-
toxic MOA. Since the experts were not required to
annotate every relevant keyword, calculating inter-
annotator agreement was not meaningful. However,
the keyword annotation was evaluated jointly with
taxonomy classification (the following section).
</bodyText>
<subsectionHeader confidence="0.999123">
3.4 The taxonomy and the resulting corpus
</subsectionHeader>
<bodyText confidence="0.999388473684211">
During keyword annotation, the initial taxonomy
was extended and refined with new classes and class
members. The resulting taxonomy relies solely on
expert knowledge. Experts were merely advised
on the main principles of taxonomy creation: the
classes should be conceptually coherent and their hi-
erarchical organization should be in terms of coher-
ent sub- and superordinate relations.
The taxonomy contains three top level classes:
1) Carcinogenic activity (CA), 2) Mode of Action
(MOA) and 3) Toxicokinetics (TOX). 1) and 2) are
organized by TYPE-OF relations (leukemia is a type
of carcinogenic evidence) and 3) by PART-OF rela-
tions (biodegradation is apart of Metabolism). Each
top level class divides into sub-classes. Figure 2
shows CA taxonomy with three keyword examples
per class. The taxonomy has 48 classes in total; half
of them under CA. Table 6 shows the total number
of abstracts and keywords per class: 82.4% of the
abstracts include keywords for CA, and 50.3% and
28.1% for MOA and TOX, respectively.
We calculated inter-annotator agreement for as-
signing abstracts to taxonomy classes. For each of
the 8 chemicals, 10 abstracts were randomly cho-
sen from the 15 journals. The average agreement
between two annotators is the highest with CA and
MOA (78%) and the lowest with TOX (62%). The
overall agreement is 76%. This result is good, par-
ticularly considering the high number of classes and
the chance agreement of 1.5%. The disagreements
are mostly due to one of the experts annotating as
many keywords as possible, and the other one an-
notating only the ones that classify each abstract as
precisely as possible. This was not a serious prob-
lem for us, but it demonstrates the importance of de-
tailed guidelines. Also, some of the classes were too
imprecise to yield unique distinctions. Future work
should focus on refining them further.
</bodyText>
<sectionHeader confidence="0.994538" genericHeader="method">
4 Automatic classification
</sectionHeader>
<bodyText confidence="0.9999365">
To examine whether the classification created by ex-
perts provides a good representation of the corpus
data and is machine learnable, we conducted a se-
ries of abstract classification experiments.
</bodyText>
<subsectionHeader confidence="0.6347175">
4.1 Methods
4.1.1 Feature extraction
</subsectionHeader>
<bodyText confidence="0.999735277777778">
The first step of text categorization (TC) is to
transform documents into a feature vector represen-
tation. We experimented with two document rep-
resentation techniques. The first one is the sim-
ple ’bag of words’ approach (BOW) which consid-
ers each word in the document as a separate feature.
BOW was evaluated using three methods which have
proved useful in previous TC work: (i) stemming
(using the Porter (1980) stemmer) which removes
affixes from words, (ii) the TFIDF weighting (Kib-
riya et al. 2004), and (iii) stop word removal.
The second technique is the recent ’bag of sub-
strings’ (BOS) method by (Wang et al. 2008) which
considers the whole abstract as a string and extracts
from it all the length p substrings without affix re-
moval. BOS has proved promising in biomedical
TC (Han et al. 2006, Wang et al. 2008) and un-
like a traditional grammatical stemmer, does not re-
</bodyText>
<page confidence="0.996453">
111
</page>
<figureCaption confidence="0.999834">
Figure 2: Taxonomy of Carcinogenic Activity
</figureCaption>
<bodyText confidence="0.999869857142857">
quire domain tuning for optimal performance. Be-
cause BOS generates substrings with fixed length p,
a word shorter than p−2 can get obscured by its con-
text3. For example, ‘mice‘ would be transformed to
’ mice a’, ’ mice b’, ... , which is less informative
than the original word form. Therefore, we enriched
BOS features with word forms shorter than p − 2.
</bodyText>
<subsectionHeader confidence="0.460103">
4.1.2 Feature selection
</subsectionHeader>
<bodyText confidence="0.999973727272727">
We employed two feature selection methods for
dimensionality reduction. The first is Information
Gain (IG) which has proved useful in TC (Yang
and Pedersen 1997). Given a feature’s distribu-
tion X and class label distribution Y , IG(X) =
H(Y ) − H(Y |X), H(X) is the entropy of X. The
second method fscore optimises the number of fea-
tures (N). Features are first ranked using the simple
fscore criterion (Chen and Lin 2006), and N is se-
lected based on the performance of the SVM classi-
fier using the N features.
</bodyText>
<subsectionHeader confidence="0.574445">
4.1.3 Classification
</subsectionHeader>
<bodyText confidence="0.92840975">
Three classifiers were used: Naive Multino-
mial Bayesian (NMB), Complement Naive Bayesian
(CNB) (Rennie and Karger 2003) and Linear Sup-
port Vector Machines (L-SVM) (Vapnik 1995).
</bodyText>
<footnote confidence="0.732881">
NMB is a widely used classifier in TC (Kib-
riya et al. 2004). It selects the class C with
the maximum probability given the document d:
argmaxc Pr(C) Hw∈d Pr(X = w|C). Pr(C) can
3Minus 2 because of space characters.
</footnote>
<bodyText confidence="0.987925833333333">
be estimated from the frequency of documents in C.
Pr(X = w|C) is estimated as the fraction of tokens
in documents of class C that contain w.
CNB extends NMB by addressing the problems
it has e.g. with imbalanced data and weight
magnitude error. The class c of a document
</bodyText>
<equation confidence="0.8655365">
is: argmaxc[logp(Bc) − Ei filog N˜c•+α•
N˜c+α ]. N˜ci is the
</equation>
<bodyText confidence="0.99509705882353">
number of times term i occurs in classes other than
c. α and αi are the smoothing parameters. p(Bc) is
the prior distribution of class c.
L-SVM is the basic type of SVM which pro-
duces a hyperplane that separates two-class samples
with a maximum margin. It handles high dimen-
sional data efficiently, and has shown to perform
well in TC (Yang and Liu 1999). Given the data
set X = (x1, y1), ... , (xn, yn) yi E 1−1, +11,
L-SVM requires a solution w to the following un-
constrained optimisation problem: min(12wTw +
C i=1 max(1 − yiwTxi, 0)2. Cost parameter C
was estimated within range 22,... , 25 on training
data using cross validation. The C of the posi-
tive class was weighted by class population ratio
negative population
positive population .
</bodyText>
<sectionHeader confidence="0.536437" genericHeader="method">
4.1.4 Evaluation
</sectionHeader>
<bodyText confidence="0.999914">
We used the standard measures of recall (R), pre-
cision (P) and F measure (F) for evaluation. These
are defined as follows:
</bodyText>
<equation confidence="0.993124">
TP TP = 2×R×P
R _ — TP+FN P = TP+FP F R+P
Our random baseline is P+
N+P+ .
r =
</equation>
<page confidence="0.99538">
112
</page>
<bodyText confidence="0.460948">
P+/N: positive/negative population TP: truth positive; FN: false negative, FP: false positive
</bodyText>
<subsectionHeader confidence="0.8773765">
4.2 Experimental evaluation
4.2.1 Data
</subsectionHeader>
<bodyText confidence="0.966657">
Our data was the expert annotated CRA corpus.
</bodyText>
<subsubsectionHeader confidence="0.480996">
4.2.2 Document preprocessing
</subsubsectionHeader>
<bodyText confidence="0.999938266666667">
We first evaluated the BOW preprocessing tech-
nique with and without the use of (i) the Porter
(1980) stemmer, (ii) TFIDF, (iii) stop word removal,
and (iv) their combinations. The evaluation was
done in the context of the binary relevance classifica-
tion of abstracts (not in the context of the main tax-
onomic classification task to avoid overfitting pre-
processing techniques to the taxonomy). Only (iii)
improved all the classifiers and was thus adopted
for the main experiments. The poor performance
of (i) demonstrates that a standard stemmer is not
optimal for our data. As highlighted by (Han et al.
2006, Wang et al. 2008), semantically related bio-
logical terms sharing the same stem are not always
reducible to the stem form.
</bodyText>
<subsectionHeader confidence="0.749707">
4.2.3 Feature selection
</subsectionHeader>
<bodyText confidence="0.999980642857143">
We evaluated the feature selection methods on
two taxonomy classes: the most balanced class ‘An-
imal study‘ (positive/negative 1:1.4) and an imbal-
anced class ‘Adducts‘ (positive/negative 1:6.5). IG
was used for the fixed N setting and fscore for the
dynamic N setting. Each combination of classifiers
(NMB/CNB/SVM), document representations (BOW,
BOS) and settings for N (dynamic, ... , 83098) was
evaluated. The results show that the dynamic setting
yields consistent improvement on all the setups (al-
though the impact on SVM’s is not big). Also the
optimal Nvaries by the data and the classifier. Thus,
we used the dynamic feature selection in the taxo-
nomic classification.
</bodyText>
<subsubsectionHeader confidence="0.69266">
4.2.4 Taxonomic classification
</subsubsectionHeader>
<bodyText confidence="0.9999355">
Experimental setup We ran two sets of experi-
ments on the corpus, using 1) BOW and 2) BOS for
feature extraction. Without feature selection, BOW
had c. 9000 features and BOS c. 83000. Features
were selected using fscore. For each class with
more than 20 abstracts (37 in total)4, three ”one
</bodyText>
<footnote confidence="0.9987865">
4The classes with less than 20 abstracts may have less than
2 positive abstracts in each fold of 10 fold CV, which is not
</footnote>
<table confidence="0.998144571428571">
Method Feature Set P R F
NMB BOW 0.59 0.75 0.66
NMB BOS 0.62 0.82 0.70
CNB BOW 0.52 0.74 0.60
CNB BOS 0.57 0.76 0.64
SVM BOW 0.68 0.76 0.71
SVM BOS 0.71 0.77 0.74
</table>
<tableCaption confidence="0.982622">
Table 2: Performance of classifiers with BOS/BOW
</tableCaption>
<table confidence="0.9997366">
Class Method P R F
CA NMB 0.94 0.89 0.91
CA CNB 0.92 0.94 0.93
CA SVM 0.93 0.93 0.93
MOA NMB 0.88 0.81 0.84
MOA CNB 0.84 0.82 0.83
MOA SVM 0.92 0.80 0.86
TOX NMB 0.66 0.83 0.74
TOX CNB 0.70 0.80 0.75
TOX SVM 0.76 0.79 0.78
</table>
<tableCaption confidence="0.998971">
Table 3: Result for the top level classes
</tableCaption>
<bodyText confidence="0.993730181818182">
against other” classifiers (NMB, CNB and L-SVM)
were trained and tested using 10-fold cross valida-
tion.
Results Table 2 shows the average performance
for the whole taxonomy. The performance of BOS
is better than that of BOW according to all the three
measures. On average, BOS outperforms BOW by
4% in P and F, and 3% in R. SVM yields the best
overall P and F (0.71 and 0.74) with BOS. Surpris-
ingly, NMB outperforms CNB with all the settings.
NMB yields the best overall R with BOS (0.82) but
its P is notably lower than that of SVM.
Table 3 shows the average P, R and F for the top
level classes using the best performing feature set
BOS with the three classifiers. CA has the best F
(0.93). Its positive population is the highest (posi-
tive/negative: 5:1). TOX with a lower positive pop-
ulation (1:2.6) has still good F (0.78). R and P are
balanced with an average difference of 0.06.
Table 4 shows the distribution of F across the
taxonomy. There is a clear correlation between
representative for the class population.
</bodyText>
<table confidence="0.8710945">
No. of abstracts(f) Classes F Random
f &gt; 300 9 0.80 0.38
100 &lt; f &lt; 300 12 0.73 0.13
20 &lt; f &lt; 100 16 0.68 0.04
</table>
<tableCaption confidence="0.9962095">
Table 4: Mean F and random baseline for taxonomic
classes in three frequency ranges.
</tableCaption>
<page confidence="0.999142">
113
</page>
<bodyText confidence="0.999861">
frequency and performance: the average F de-
creases with descending frequency range, revealing
increased classification difficulty. Classes with more
than 300 abstracts have the highest average F (0.80
with standard deviation (SD) 0.08). Classes with
20-100 abstracts have the average F 0.68 (SD 0.11),
which is lower but still fairly good. No class has F
lower than 0.46, which is much higher than the av-
erage random baseline of 0.11.
</bodyText>
<sectionHeader confidence="0.983446" genericHeader="method">
5 User Test
</sectionHeader>
<bodyText confidence="0.999969555555556">
A user test was carried out to examine the practical
usefulness of the automatic classification in a near
real-world scenario. The L-SVM+BOS classifier was
applied to the PubMed abstract data (from 1998-
2008) of five unseen chemicals representing geno-
toxic (geno) and non-genotoxic (non) MOAs (see
table 5). The results were displayed to two experts
in a friendly web interface. The experts were in-
vited to imagine that they have submitted a query to
a system, the system has returned the classification
of relevant abstracts for each chemical, and the task
is to judge whether it is correct. The top 500 BOS
features per class were shown to aid the judgement.
Results were evaluated using precision (P) (re-
call could not be calculated as not all of the positive
polulation was known). Table 5 shows the average
P for chemicals and top level classes. The results
are impressive: the only chemical with P lower than
0.90 is polychlorinated biphenyls (PCB). As PCB
has a well-known neuro-behavioural effect, the data
includes many abstracts irrelevant for CRA. Most
other errors are due to the lack of training data for
low frequency classes. For example, the CRA cor-
pus had only 27 abstracts in ”DNA repair (damage)”
class, while the new corpus has many abstracts on
DNA damage some of which are irrelevant for CRA.
The experts found the tool easy to use and felt
that if such a tool was available to support real-world
CRA, it could significantly increase their productiv-
ity and also lead to more consistent and thorough
CRA. Such a wide range of scientific evidence is dif-
ficult to gather via manual means, and chemical car-
cinogenesis is such a complex process that even the
most experienced risk assessor is incapable of mem-
orizing the full range of relevant evidence without
the support of a thorough specification / taxonomy.
</bodyText>
<table confidence="0.999571333333333">
Name MOA Σ P Class P
Aflatoxin B1 geno 189 0.95 CA 0.94
Benzene geno 461 0.99 MOA 0.95
PCB non 761 0.89 TOX 0.99
Tamoxifen non 382 0.96
TCDD non 641 0.96
</table>
<tableCaption confidence="0.998536">
Table 5: Chemicals and the results of the user test
</tableCaption>
<sectionHeader confidence="0.962218" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999946358974359">
The results of our inter-annotator agreement tests,
automatic classification experiments and the user
test demonstrate that the taxonomy created by risk
assessors is accurate, well-defined, and can be use-
ful in a real-world CRA scenario. This is particu-
larly encouraging considering that the taxonomy is
based on biomedical annotation. As highlighted by
(Kim et al. 2008), expert annotation is more chal-
lenging and prone to inter-annotator disagreement
than better-constrained linguistic annotation. We
believe that we obtained promising results because
we worked in collaboration with risk assessors and
developed technology which imitates their current
practices as closely as possible.
Most related work focuses on binary classifica-
tion, e.g. BioCreative II had a subtask (Krallinger
et al. 2008) on the relevance classification of ab-
stracts for protein interactions. The few works
that have attempted multi-classification include e.g.
that of Aphinyanaphongs et al. (2005) who applied
NMB, SVM and AdaBoost to classify abstracts of
internal medicine into four categories, and that of
Han et al. (2006) who used BOS and NMB/L-SVMto
classify abstracts in five categories of protein post-
translational modifications.
In the future, we plan to refine the taxonomy fur-
ther by careful analysis of keyword types found in
the data and the taxonomic relationships defined by
experts. This will help to transform the taxonomy
into a better-developed knowledge resource. We
also need to extend the taxonomy. Although our
results show that the current taxonomy provides a
good basis for the classification of CRA literature,
it is not comprehensive: more data is required espe-
cially for low frequency classes, and the taxonomy
needs to be extended to cover more specific MOA
types (e.g. further subtypes of non-genotoxic chem-
icals).
The taxonomy can be extended by manual annota-
</bodyText>
<page confidence="0.994434">
114
</page>
<table confidence="0.9996874">
Change in F E Classes Abstracts of class
20-100 100 - 200 200 - 1100
OF &gt; 1% 16 (43%) 75% 33% 8%
|OF |≤ 1% 15 (41%) 6% 44% 75%
OF &lt; −1% 6 (16%) 19% 33% 17%
</table>
<tableCaption confidence="0.7945">
Table 6: F gain(OF) of MeSH compared to BOS
</tableCaption>
<table confidence="0.999972307692308">
Class E F
Carcinogenic activity 1068 92.8
Human study/epidemiology 190 77.7
Animal study 629 80.2
Cell experiments 319 78.5
Study on microorganisms 44 85.2
Mode of Action 653 85.5
Genotoxic 421 89.1
Nongenotoxic 324 76.3
Toxicokinetics 356 77.7
Absorption, ...,excretion 113 69.8
Metabolism 268 76.4
Toxicokinetic modeling 31 84.6
</table>
<tableCaption confidence="0.999735">
Table 7: E abstracts and F of level 1,2 classes.
</tableCaption>
<bodyText confidence="0.998839049180328">
tion, supplementing it with additional information in
knowledge resources and/or by automatic methods.
One knowledge resource potentially useful is the
Medical Subject Headings (MeSH) taxonomy (Nel-
son et al. 2002) which classifies PubMed abstracts
according to manually defined terms. We performed
a small experiment to investigate the usefulness of
MeSH for supplementing our current classification.
MeSH terms were first retrieved for each abstract us-
ing EFetch (NCBI 2005) and then appended to the
BOS feature vector. Best features were then selected
using fscore and classified using L-SVM. The fig-
ures in table 6 show that the results improved sig-
nificantly for 43% of the low frequency classes. Al-
though this demonstrates the potential usefulness of
additional resources, given the rapidly evolving na-
ture of CRA data, the best approach long term is
to develop technology for automatic updating of the
taxonomy from literature. Given the basic resources
we have constructed, the development of such tech-
nology is now realistic and can be done using unsu-
pervised or semi-supervised machine learning tech-
niques, e.g. (Cohen and Hersh 2005, Blaschko and
Gretton 2009).
The automatic classification could be improved
by the use of more sophisticated features extracted
using NLP tools that have been tuned for biomedi-
cal texts, such as parsers, e.g. (Tsuruoka et al. 2005),
and named entity recognizers, e.g. (Corbett et al.
2007), and exploiting resources such as the BioLex-
ion (Sasaki et al. 2008).
Our long term goal is to develop a TM tool
specifically designed for CRA. Some tools have re-
cently been built to assist other critical activities of
biomedicine (e.g. literature curation for genetics).
A few of them have been evaluated for their practi-
cal usefulness in a real-world scenario (Karamanis
et al. 2008, Demaine et al. 2006). Such tools and
evaluations act as an important proof of concept for
biomedical TM and help to develop technology for
the needs of practical applications.
According to the interviews we conducted (Sec-
tion 2), a tool capable of identifying, ranking and
classifying articles based on the evidence they con-
tain, displaying the results to experts, and assisting
also in subsequent steps of CRA would be particu-
larly welcome. Such a tool, if developed in close
collaboration with users, could significantly increase
the productivity of CRA and enable risk assessors
to concentrate on what they are best at: the expert
judgement.
Acknowledgements Our work was funded by the
Royal Society (UK), the Medical Research Council
(G0601766) (UK) and the Swedish Council for Working
Life and Social Research (Sweden). LS was supported
by a Dorothy Hodgkin Postgraduate Award (UK). We
would like to thank Ian Lewin for his assistance at the
early stages of this work and for providing the first ver-
sion of the annotation tool. We are also grateful to Johan
Hogberg for supporting the annotation and the taxonomy
construction work.
</bodyText>
<sectionHeader confidence="0.998621" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998642">
Sophia Ananiadou, Douglas B. Kell, and Jun ichi Tsujii.
Text mining and its potential applications in systems
biology. Trends in Biotechnology, 24(12), 2006.
Y. Aphinyanaphongs, I. Tsamardinos, A. Statnikov,
D. Hardin, and C.F. Aliferis. Text categorization
models for high-quality article retrieval in internal
medicine. JAMIA, 12(2), 2005.
Matthew Blaschko and Arthur Gretton. Learning tax-
onomies by dependence maximization. In 22rd NIPS,
2009.
Yi-Wei Chen and Chih-Jen Lin. Combining SVMs with
various feature selection strategies. In Feature extrac-
tion, foundations and applications. 2006.
Aaron M. Cohen and William R. Hersh. A survey of
</reference>
<page confidence="0.988847">
115
</page>
<reference confidence="0.99989075">
current work in biomedical text mining. Briefings in
Bioinformatics, 6(1), 2005.
Jacob Cohen. A coefficient of agreement for nominal
scales. Educ. Psychol. Meas., 20(1), 1960.
K. Bretonnel Cohen, Hong Yu, Philip E. Bourne, and
Lynette Hirschman. Translating biology:text mining
tools that work. In PSB, 2008.
Peter Corbett, Colin Batchelor, and Simone Teufel. An-
notation of chemical named entities. In Proceedings of
the ACL, 2007.
Jeffrey Demaine, Joel Martin, Lynn Wei, and Berry
de Bruijn. Litminer: integration of library services
within a bio-informatics application. Biomedical Dig-
ital Libraries, 3(1), 2006.
ECHA, 2008. Guidance on Information Requirements
and Chemical Safety Assessment. European Chemicals
Agency, 2008.
Bo Han, Zoran Obradovic, Zhang zhi Hu, Cathy H. Wu,
and Slobodan Vucetic. Substring selection for biomed-
ical document classification. Bioinformatics, 22, 2006.
Lawrence Hunter and K. Bretonnel Cohen. Biomedical
language processing: What’s beyond pubmed? Mol
Cell, 21(5), 2006.
N. Karamanis, R. Seal, I. Lewin, P. McQuilton, A. Vla-
chos, C. Gasperin, R. Drysdale, and T. Briscoe. Nat-
ural language processing in aid of flybase curators.
BMC Bioinformatics, 9(1), 2008.
Ashraf M. Kibriya, Eibe Frank, Bernhard Pfahringer, and
Geoffrey Holmes. Multinomial naive bayes for text
categorization revisited. In Australian Conference on
AI, volume 3339, 2004.
Jin-Dong Kim, Tomoko Ohta, and Jun’ichi Tsujii. Cor-
pus annotation for mining biomedical events from lter-
ature. BMC Bioinformatics, 9, 2008.
Martin Krallinger, Florian Leitner, Carlos Rodriguez-
Penagos, and Alfonso Valencia. Overview of the
protein-protein interaction annotation extraction task
of biocreative ii. Genome Biology, 2008.
J.Richard Landis and Gary G.Koch. The measurement of
observer agreement for categorical data. Biometrics,
33(1), 1977.
Ian Lewin, Ilona Silins, Anna Korhonen, Johan Hogberg,
and Ulla Stenius. A new challenge for text mining:
Cancer risk assessment. In Proceedings of the ISMB
BioLINK Special Interest Group on Text Data Mining.,
2008.
NCBI. Efetch entrez utility, 2005. URL
http://www.ncbi.nlm.nih.gov/entrez/
query/static/efetch_help.html.
Sturart J. Nelson, Tammy Powell, and Besty L.
Humphreys. The Unified Medical Language System
(UMLS) Project. In Encyclopedia of Library and In-
formation Science, pages 369–378. Marcel Dekker,
2002.
M. F. Porter. An algorithm for suffix stripping. Program,
14(3):130–137, 1980.
Jason D. M. Rennie and David Karger. Tackling the poor
assumptions of naive bayes text classifiers. In In Pro-
ceedings of the 20th ICML, 2003.
Y. Sasaki, S. Montemagni, P. Pezik, D. Rebholz-
Schuhmann, J. McNaught, and S. Ananiadou. BioLex-
icon: A Lexical Resource for the Biology Domain.
2008.
Y. Tsuruoka, Y. Tateishi, J. Kim, T. Ohta, J. McNaught,
S. Ananiadou, and J. Tsujii. Developing a Robust Part-
of-Speech Tagger for Biomedical Text. 3746, 2005.
EPA, 2005. Guidelines for carcinogen risk as-
sessment. U.S. Environmental Protection Agency,
2005. URL http://www.epa.gov/iris/
cancer032505.pdf.
Vladimir N. Vapnik. The nature of statistical learning
theory. New York, NY, USA, 1995.
Hongning Wang, Minlie Huang, Shilin Ding, and Xi-
aoyan Zhu. Exploiting and integrating rich features
for biological literature classification. BMC Bioinfor-
matics, 9(Suppl 3), 2008.
Yiming Yang and Xin Liu. A re-examination of text cate-
gorization methods. In Proceedings ofthe 22nd SIGIR,
New York, NY, USA, 1999.
Yiming Yang and Jan O. Pedersen. A comparative study
on feature selection in text categorization. 1997.
Pierre Zweigenbaum, Dina Demner-Fushman, Hong Yu,
and Kevin B. Cohen. Frontiers of biomedical text min-
ing: current progress. Brief Bioinform, 8(5), 2007.
</reference>
<page confidence="0.999026">
116
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.727383">
<title confidence="0.990636">User-Driven Development of Text Mining Resources for Cancer Risk Assessment</title>
<author confidence="0.997956">Lin Sun</author>
<author confidence="0.997956">Anna</author>
<affiliation confidence="0.995357">University of Computer</affiliation>
<address confidence="0.950529">15 JJ Thomson Cambridge CB3 0GD, UK</address>
<email confidence="0.992015">ls418,alk23@cl.cam.ac.uk</email>
<abstract confidence="0.992061095238095">One of the most neglected areas of biomedical Text Mining (TM) is the development of systems based on carefully assessed user needs. We investigate the needs of an important task yet to be tackled by TM — Cancer Risk Assessment (CRA) — and take the first step towards the development of TM for the task: identifying and organizing the scientific evidence required for CRA in a taxonomy. The taxonomy is based on expert annotation of 1297 MEDLINE abstracts. We report promising results with inter-annotator agreement tests and automatic classification experiments, and a user test which demonstrates that the resources we have built are well-defined, accurate, and applicable to a real-world CRA scenario. We discuss extending and refining the taxonomy further via manual and machine learning approaches, and the subsequent steps required to develop TM for the needs of CRA.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sophia Ananiadou</author>
<author>Douglas B Kell</author>
<author>Jun ichi Tsujii</author>
</authors>
<title>Text mining and its potential applications in systems biology.</title>
<date>2006</date>
<journal>Trends in Biotechnology,</journal>
<volume>24</volume>
<issue>12</issue>
<contexts>
<context position="1676" citStr="Ananiadou et al. 2006" startWordPosition="259" endWordPosition="263">ed to develop TM for the needs of CRA. 1 Introduction Biomedical Text Mining (TM) has become increasingly popular due to the pressing need to provide access to the tremendous body of texts available in biomedical sciences. Considerable progress has been made in the development of basic resources (e.g. ontologies, annotated corpora) and techniques (e.g. Information Retrieval (IR), Information Extraction (IE)) in this area, and research has began to focus on increasingly challenging tasks, e.g. summarization and the discovery of novel information in biomedical literature (Hunter and Cohen 2006, Ananiadou et al. 2006, Zweigenbaum et al. 2007). In recent past, there has been an increasing demand for research which is driven by actual user Ilona Silins, Ulla Stenius Institute of Environmental Medicine Karolinska Institutet S-17177, Stockholm Sweden ilona.silins,ulla.stenius@ki.se needs rather than technical developments (Zweigenbaum et al. 2007). Shared tasks (e.g. BioCreative and the TREC Genomics track) targeting the workflow of biomedical researchers have appeared along with studies exploring the TM needs of specific tasks (Karamanis et al. 2008, Demaine et al. 2006). However, the understanding of user n</context>
</contexts>
<marker>Ananiadou, Kell, Tsujii, 2006</marker>
<rawString>Sophia Ananiadou, Douglas B. Kell, and Jun ichi Tsujii. Text mining and its potential applications in systems biology. Trends in Biotechnology, 24(12), 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Aphinyanaphongs</author>
<author>I Tsamardinos</author>
<author>A Statnikov</author>
<author>D Hardin</author>
<author>C F Aliferis</author>
</authors>
<title>Text categorization models for high-quality article retrieval in internal medicine.</title>
<date>2005</date>
<journal>JAMIA,</journal>
<volume>12</volume>
<issue>2</issue>
<contexts>
<context position="26323" citStr="Aphinyanaphongs et al. (2005)" startWordPosition="4319" endWordPosition="4322">ted by (Kim et al. 2008), expert annotation is more challenging and prone to inter-annotator disagreement than better-constrained linguistic annotation. We believe that we obtained promising results because we worked in collaboration with risk assessors and developed technology which imitates their current practices as closely as possible. Most related work focuses on binary classification, e.g. BioCreative II had a subtask (Krallinger et al. 2008) on the relevance classification of abstracts for protein interactions. The few works that have attempted multi-classification include e.g. that of Aphinyanaphongs et al. (2005) who applied NMB, SVM and AdaBoost to classify abstracts of internal medicine into four categories, and that of Han et al. (2006) who used BOS and NMB/L-SVMto classify abstracts in five categories of protein posttranslational modifications. In the future, we plan to refine the taxonomy further by careful analysis of keyword types found in the data and the taxonomic relationships defined by experts. This will help to transform the taxonomy into a better-developed knowledge resource. We also need to extend the taxonomy. Although our results show that the current taxonomy provides a good basis fo</context>
</contexts>
<marker>Aphinyanaphongs, Tsamardinos, Statnikov, Hardin, Aliferis, 2005</marker>
<rawString>Y. Aphinyanaphongs, I. Tsamardinos, A. Statnikov, D. Hardin, and C.F. Aliferis. Text categorization models for high-quality article retrieval in internal medicine. JAMIA, 12(2), 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Blaschko</author>
<author>Arthur Gretton</author>
</authors>
<title>Learning taxonomies by dependence maximization.</title>
<date>2009</date>
<booktitle>In 22rd NIPS,</booktitle>
<contexts>
<context position="28970" citStr="Blaschko and Gretton 2009" startWordPosition="4752" endWordPosition="4755"> selected using fscore and classified using L-SVM. The figures in table 6 show that the results improved significantly for 43% of the low frequency classes. Although this demonstrates the potential usefulness of additional resources, given the rapidly evolving nature of CRA data, the best approach long term is to develop technology for automatic updating of the taxonomy from literature. Given the basic resources we have constructed, the development of such technology is now realistic and can be done using unsupervised or semi-supervised machine learning techniques, e.g. (Cohen and Hersh 2005, Blaschko and Gretton 2009). The automatic classification could be improved by the use of more sophisticated features extracted using NLP tools that have been tuned for biomedical texts, such as parsers, e.g. (Tsuruoka et al. 2005), and named entity recognizers, e.g. (Corbett et al. 2007), and exploiting resources such as the BioLexion (Sasaki et al. 2008). Our long term goal is to develop a TM tool specifically designed for CRA. Some tools have recently been built to assist other critical activities of biomedicine (e.g. literature curation for genetics). A few of them have been evaluated for their practical usefulness </context>
</contexts>
<marker>Blaschko, Gretton, 2009</marker>
<rawString>Matthew Blaschko and Arthur Gretton. Learning taxonomies by dependence maximization. In 22rd NIPS, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi-Wei Chen</author>
<author>Chih-Jen Lin</author>
</authors>
<title>Combining SVMs with various feature selection strategies. In Feature extraction, foundations and applications.</title>
<date>2006</date>
<contexts>
<context position="17252" citStr="Chen and Lin 2006" startWordPosition="2753" endWordPosition="2756">e transformed to ’ mice a’, ’ mice b’, ... , which is less informative than the original word form. Therefore, we enriched BOS features with word forms shorter than p − 2. 4.1.2 Feature selection We employed two feature selection methods for dimensionality reduction. The first is Information Gain (IG) which has proved useful in TC (Yang and Pedersen 1997). Given a feature’s distribution X and class label distribution Y , IG(X) = H(Y ) − H(Y |X), H(X) is the entropy of X. The second method fscore optimises the number of features (N). Features are first ranked using the simple fscore criterion (Chen and Lin 2006), and N is selected based on the performance of the SVM classifier using the N features. 4.1.3 Classification Three classifiers were used: Naive Multinomial Bayesian (NMB), Complement Naive Bayesian (CNB) (Rennie and Karger 2003) and Linear Support Vector Machines (L-SVM) (Vapnik 1995). NMB is a widely used classifier in TC (Kibriya et al. 2004). It selects the class C with the maximum probability given the document d: argmaxc Pr(C) Hw∈d Pr(X = w|C). Pr(C) can 3Minus 2 because of space characters. be estimated from the frequency of documents in C. Pr(X = w|C) is estimated as the fraction of to</context>
</contexts>
<marker>Chen, Lin, 2006</marker>
<rawString>Yi-Wei Chen and Chih-Jen Lin. Combining SVMs with various feature selection strategies. In Feature extraction, foundations and applications. 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aaron M Cohen</author>
<author>William R Hersh</author>
</authors>
<title>A survey of current work in biomedical text mining.</title>
<date>2005</date>
<journal>Briefings in Bioinformatics,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="28942" citStr="Cohen and Hersh 2005" startWordPosition="4748" endWordPosition="4751">est features were then selected using fscore and classified using L-SVM. The figures in table 6 show that the results improved significantly for 43% of the low frequency classes. Although this demonstrates the potential usefulness of additional resources, given the rapidly evolving nature of CRA data, the best approach long term is to develop technology for automatic updating of the taxonomy from literature. Given the basic resources we have constructed, the development of such technology is now realistic and can be done using unsupervised or semi-supervised machine learning techniques, e.g. (Cohen and Hersh 2005, Blaschko and Gretton 2009). The automatic classification could be improved by the use of more sophisticated features extracted using NLP tools that have been tuned for biomedical texts, such as parsers, e.g. (Tsuruoka et al. 2005), and named entity recognizers, e.g. (Corbett et al. 2007), and exploiting resources such as the BioLexion (Sasaki et al. 2008). Our long term goal is to develop a TM tool specifically designed for CRA. Some tools have recently been built to assist other critical activities of biomedicine (e.g. literature curation for genetics). A few of them have been evaluated for</context>
</contexts>
<marker>Cohen, Hersh, 2005</marker>
<rawString>Aaron M. Cohen and William R. Hersh. A survey of current work in biomedical text mining. Briefings in Bioinformatics, 6(1), 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Cohen</author>
</authors>
<title>A coefficient of agreement for nominal scales.</title>
<date>1960</date>
<journal>Educ. Psychol. Meas.,</journal>
<volume>20</volume>
<issue>1</issue>
<contexts>
<context position="11212" citStr="Cohen 1960" startWordPosition="1769" endWordPosition="1770"> (or its title) contains no evidence or contains ”negative” evidence (e.g. diseases or endpoints unrelated to cancer). Abstracts containing vague, conflicting or complex evidence (e.g. studies on chemicals in complex mixtures) or evidence whose association with cancer is currently unclear were dealt on case by case basis. All the potentially relevant abstracts were included for further assessment as not to lose data valuable for CRA. The experts annotated the 1297 abstracts in the corpus. 89.4% were classified as relevant, 10.1% as irrelevant, and 0.5% as unsure. We used the Kappa statistics (Cohen 1960) to measure inter-annotator agreement on unseen data which two experts annotated independently. 208 abstracts were selected randomly from the 15 journals and from 16 journals likely to be irrelevant for CRA. The latter were included to make the task harder as the proportion of relevant abstracts was high in our corpus. Our Kappa result is 0.68 — a figure which indicates substantial agreement (Landis and G.Koch 1977). The experts disagreed on 24 (11.5% of the) abstracts. Half of the disagreements are due to one of the annotators failing to notice relevant evidence. Such cases are likely to decr</context>
</contexts>
<marker>Cohen, 1960</marker>
<rawString>Jacob Cohen. A coefficient of agreement for nominal scales. Educ. Psychol. Meas., 20(1), 1960.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Bretonnel Cohen</author>
<author>Hong Yu</author>
<author>Philip E Bourne</author>
<author>Lynette Hirschman</author>
</authors>
<title>Translating biology:text mining tools that work.</title>
<date>2008</date>
<booktitle>In PSB,</booktitle>
<contexts>
<context position="2485" citStr="Cohen et al. 2008" startWordPosition="384" endWordPosition="387">linska Institutet S-17177, Stockholm Sweden ilona.silins,ulla.stenius@ki.se needs rather than technical developments (Zweigenbaum et al. 2007). Shared tasks (e.g. BioCreative and the TREC Genomics track) targeting the workflow of biomedical researchers have appeared along with studies exploring the TM needs of specific tasks (Karamanis et al. 2008, Demaine et al. 2006). However, the understanding of user needs is still one of the neglected areas of BIO-TM, and further usercentered evaluations and systems grounded in reallife tasks are required to determine which tools and services are useful (Cohen et al. 2008). We investigate the user needs of a challenging task yet to be tackled by TM but identified as an important potential application for it (Lewin et al. 2008): Cancer Risk Assessment (CRA). Over the past years, CRA has become increasingly important as the link between environmental chemicals and cancer has become evident. It involves examining published evidence to determine the relationship between exposure to a chemical and the likelihood of developing cancer from that exposure (EPA, 2005). Performed manually by experts in health related institutions worldwide, CRA requires searching, locatin</context>
</contexts>
<marker>Cohen, Yu, Bourne, Hirschman, 2008</marker>
<rawString>K. Bretonnel Cohen, Hong Yu, Philip E. Bourne, and Lynette Hirschman. Translating biology:text mining tools that work. In PSB, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Corbett</author>
<author>Colin Batchelor</author>
<author>Simone Teufel</author>
</authors>
<title>Annotation of chemical named entities.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<contexts>
<context position="29232" citStr="Corbett et al. 2007" startWordPosition="4794" endWordPosition="4797">of CRA data, the best approach long term is to develop technology for automatic updating of the taxonomy from literature. Given the basic resources we have constructed, the development of such technology is now realistic and can be done using unsupervised or semi-supervised machine learning techniques, e.g. (Cohen and Hersh 2005, Blaschko and Gretton 2009). The automatic classification could be improved by the use of more sophisticated features extracted using NLP tools that have been tuned for biomedical texts, such as parsers, e.g. (Tsuruoka et al. 2005), and named entity recognizers, e.g. (Corbett et al. 2007), and exploiting resources such as the BioLexion (Sasaki et al. 2008). Our long term goal is to develop a TM tool specifically designed for CRA. Some tools have recently been built to assist other critical activities of biomedicine (e.g. literature curation for genetics). A few of them have been evaluated for their practical usefulness in a real-world scenario (Karamanis et al. 2008, Demaine et al. 2006). Such tools and evaluations act as an important proof of concept for biomedical TM and help to develop technology for the needs of practical applications. According to the interviews we conduc</context>
</contexts>
<marker>Corbett, Batchelor, Teufel, 2007</marker>
<rawString>Peter Corbett, Colin Batchelor, and Simone Teufel. Annotation of chemical named entities. In Proceedings of the ACL, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Demaine</author>
<author>Joel Martin</author>
<author>Lynn Wei</author>
<author>Berry de Bruijn</author>
</authors>
<title>Litminer: integration of library services within a bio-informatics application.</title>
<date>2006</date>
<journal>Biomedical Digital Libraries,</journal>
<volume>3</volume>
<issue>1</issue>
<marker>Demaine, Martin, Wei, de Bruijn, 2006</marker>
<rawString>Jeffrey Demaine, Joel Martin, Lynn Wei, and Berry de Bruijn. Litminer: integration of library services within a bio-informatics application. Biomedical Digital Libraries, 3(1), 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ECHA</author>
</authors>
<title>Guidance on Information Requirements and Chemical Safety Assessment. European Chemicals Agency,</title>
<date>2008</date>
<contexts>
<context position="6402" citStr="ECHA, 2008" startWordPosition="1010" endWordPosition="1011">nsuring that all the potentially relevant evidence is found would be particularly helpful. It became clear that a prerequisite for the development of such a tool would be an extensive specification of the scientific evidence used for CRA. 1Institute of Environmental Medicine at Karolinska Institutet, Swedish Chemical Inspectorate, Scientific Committee on Occupational Exposure Limits (EU), Swedish Criteria Group. This evidence — which forms the basis of all the subsequent steps of CRA — is described in the guideline documents of major international CRA agencies, e.g. European Chemicals Agency (ECHA, 2008) and the United States Environmental Protection Agency (EPA, 2005). However, although these documents constitute the main reference material in CRA, they cover the main types of evidence only, do not specify the evidence at the level of detail required for comprehensive data gathering, and are not updated regularly (i.e. do not incorporate the latest developments in biomedical sciences). The risk assessors admitted that rather than relying on these documents, they rely on their experience and expert knowledge when looking for the evidence. We decided that our starting point should be to compos</context>
</contexts>
<marker>ECHA, 2008</marker>
<rawString>ECHA, 2008. Guidance on Information Requirements and Chemical Safety Assessment. European Chemicals Agency, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Zoran Obradovic</author>
<author>Zhang zhi Hu</author>
<author>Cathy H Wu</author>
<author>Slobodan Vucetic</author>
</authors>
<title>Substring selection for biomedical document classification.</title>
<date>2006</date>
<journal>Bioinformatics,</journal>
<volume>22</volume>
<contexts>
<context position="16325" citStr="Han et al. 2006" startWordPosition="2591" endWordPosition="2594">the simple ’bag of words’ approach (BOW) which considers each word in the document as a separate feature. BOW was evaluated using three methods which have proved useful in previous TC work: (i) stemming (using the Porter (1980) stemmer) which removes affixes from words, (ii) the TFIDF weighting (Kibriya et al. 2004), and (iii) stop word removal. The second technique is the recent ’bag of substrings’ (BOS) method by (Wang et al. 2008) which considers the whole abstract as a string and extracts from it all the length p substrings without affix removal. BOS has proved promising in biomedical TC (Han et al. 2006, Wang et al. 2008) and unlike a traditional grammatical stemmer, does not re111 Figure 2: Taxonomy of Carcinogenic Activity quire domain tuning for optimal performance. Because BOS generates substrings with fixed length p, a word shorter than p−2 can get obscured by its context3. For example, ‘mice‘ would be transformed to ’ mice a’, ’ mice b’, ... , which is less informative than the original word form. Therefore, we enriched BOS features with word forms shorter than p − 2. 4.1.2 Feature selection We employed two feature selection methods for dimensionality reduction. The first is Informatio</context>
<context position="19872" citStr="Han et al. 2006" startWordPosition="3211" endWordPosition="3214">essing We first evaluated the BOW preprocessing technique with and without the use of (i) the Porter (1980) stemmer, (ii) TFIDF, (iii) stop word removal, and (iv) their combinations. The evaluation was done in the context of the binary relevance classification of abstracts (not in the context of the main taxonomic classification task to avoid overfitting preprocessing techniques to the taxonomy). Only (iii) improved all the classifiers and was thus adopted for the main experiments. The poor performance of (i) demonstrates that a standard stemmer is not optimal for our data. As highlighted by (Han et al. 2006, Wang et al. 2008), semantically related biological terms sharing the same stem are not always reducible to the stem form. 4.2.3 Feature selection We evaluated the feature selection methods on two taxonomy classes: the most balanced class ‘Animal study‘ (positive/negative 1:1.4) and an imbalanced class ‘Adducts‘ (positive/negative 1:6.5). IG was used for the fixed N setting and fscore for the dynamic N setting. Each combination of classifiers (NMB/CNB/SVM), document representations (BOW, BOS) and settings for N (dynamic, ... , 83098) was evaluated. The results show that the dynamic setting yi</context>
<context position="26452" citStr="Han et al. (2006)" startWordPosition="4341" endWordPosition="4344">annotation. We believe that we obtained promising results because we worked in collaboration with risk assessors and developed technology which imitates their current practices as closely as possible. Most related work focuses on binary classification, e.g. BioCreative II had a subtask (Krallinger et al. 2008) on the relevance classification of abstracts for protein interactions. The few works that have attempted multi-classification include e.g. that of Aphinyanaphongs et al. (2005) who applied NMB, SVM and AdaBoost to classify abstracts of internal medicine into four categories, and that of Han et al. (2006) who used BOS and NMB/L-SVMto classify abstracts in five categories of protein posttranslational modifications. In the future, we plan to refine the taxonomy further by careful analysis of keyword types found in the data and the taxonomic relationships defined by experts. This will help to transform the taxonomy into a better-developed knowledge resource. We also need to extend the taxonomy. Although our results show that the current taxonomy provides a good basis for the classification of CRA literature, it is not comprehensive: more data is required especially for low frequency classes, and </context>
</contexts>
<marker>Han, Obradovic, Hu, Wu, Vucetic, 2006</marker>
<rawString>Bo Han, Zoran Obradovic, Zhang zhi Hu, Cathy H. Wu, and Slobodan Vucetic. Substring selection for biomedical document classification. Bioinformatics, 22, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Hunter</author>
<author>K Bretonnel Cohen</author>
</authors>
<title>Biomedical language processing: What’s beyond pubmed?</title>
<date>2006</date>
<journal>Mol Cell,</journal>
<volume>21</volume>
<issue>5</issue>
<contexts>
<context position="1653" citStr="Hunter and Cohen 2006" startWordPosition="255" endWordPosition="258">subsequent steps required to develop TM for the needs of CRA. 1 Introduction Biomedical Text Mining (TM) has become increasingly popular due to the pressing need to provide access to the tremendous body of texts available in biomedical sciences. Considerable progress has been made in the development of basic resources (e.g. ontologies, annotated corpora) and techniques (e.g. Information Retrieval (IR), Information Extraction (IE)) in this area, and research has began to focus on increasingly challenging tasks, e.g. summarization and the discovery of novel information in biomedical literature (Hunter and Cohen 2006, Ananiadou et al. 2006, Zweigenbaum et al. 2007). In recent past, there has been an increasing demand for research which is driven by actual user Ilona Silins, Ulla Stenius Institute of Environmental Medicine Karolinska Institutet S-17177, Stockholm Sweden ilona.silins,ulla.stenius@ki.se needs rather than technical developments (Zweigenbaum et al. 2007). Shared tasks (e.g. BioCreative and the TREC Genomics track) targeting the workflow of biomedical researchers have appeared along with studies exploring the TM needs of specific tasks (Karamanis et al. 2008, Demaine et al. 2006). However, the </context>
</contexts>
<marker>Hunter, Cohen, 2006</marker>
<rawString>Lawrence Hunter and K. Bretonnel Cohen. Biomedical language processing: What’s beyond pubmed? Mol Cell, 21(5), 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Karamanis</author>
<author>R Seal</author>
<author>I Lewin</author>
<author>P McQuilton</author>
<author>A Vlachos</author>
<author>C Gasperin</author>
<author>R Drysdale</author>
<author>T Briscoe</author>
</authors>
<title>Natural language processing in aid of flybase curators.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<issue>1</issue>
<contexts>
<context position="2216" citStr="Karamanis et al. 2008" startWordPosition="338" endWordPosition="341">nformation in biomedical literature (Hunter and Cohen 2006, Ananiadou et al. 2006, Zweigenbaum et al. 2007). In recent past, there has been an increasing demand for research which is driven by actual user Ilona Silins, Ulla Stenius Institute of Environmental Medicine Karolinska Institutet S-17177, Stockholm Sweden ilona.silins,ulla.stenius@ki.se needs rather than technical developments (Zweigenbaum et al. 2007). Shared tasks (e.g. BioCreative and the TREC Genomics track) targeting the workflow of biomedical researchers have appeared along with studies exploring the TM needs of specific tasks (Karamanis et al. 2008, Demaine et al. 2006). However, the understanding of user needs is still one of the neglected areas of BIO-TM, and further usercentered evaluations and systems grounded in reallife tasks are required to determine which tools and services are useful (Cohen et al. 2008). We investigate the user needs of a challenging task yet to be tackled by TM but identified as an important potential application for it (Lewin et al. 2008): Cancer Risk Assessment (CRA). Over the past years, CRA has become increasingly important as the link between environmental chemicals and cancer has become evident. It invol</context>
<context position="29617" citStr="Karamanis et al. 2008" startWordPosition="4859" endWordPosition="4862">tion could be improved by the use of more sophisticated features extracted using NLP tools that have been tuned for biomedical texts, such as parsers, e.g. (Tsuruoka et al. 2005), and named entity recognizers, e.g. (Corbett et al. 2007), and exploiting resources such as the BioLexion (Sasaki et al. 2008). Our long term goal is to develop a TM tool specifically designed for CRA. Some tools have recently been built to assist other critical activities of biomedicine (e.g. literature curation for genetics). A few of them have been evaluated for their practical usefulness in a real-world scenario (Karamanis et al. 2008, Demaine et al. 2006). Such tools and evaluations act as an important proof of concept for biomedical TM and help to develop technology for the needs of practical applications. According to the interviews we conducted (Section 2), a tool capable of identifying, ranking and classifying articles based on the evidence they contain, displaying the results to experts, and assisting also in subsequent steps of CRA would be particularly welcome. Such a tool, if developed in close collaboration with users, could significantly increase the productivity of CRA and enable risk assessors to concentrate o</context>
</contexts>
<marker>Karamanis, Seal, Lewin, McQuilton, Vlachos, Gasperin, Drysdale, Briscoe, 2008</marker>
<rawString>N. Karamanis, R. Seal, I. Lewin, P. McQuilton, A. Vlachos, C. Gasperin, R. Drysdale, and T. Briscoe. Natural language processing in aid of flybase curators. BMC Bioinformatics, 9(1), 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashraf M Kibriya</author>
<author>Eibe Frank</author>
<author>Bernhard Pfahringer</author>
<author>Geoffrey Holmes</author>
</authors>
<title>Multinomial naive bayes for text categorization revisited.</title>
<date>2004</date>
<booktitle>In Australian Conference on AI,</booktitle>
<volume>3339</volume>
<contexts>
<context position="16027" citStr="Kibriya et al. 2004" startWordPosition="2536" endWordPosition="2540">machine learnable, we conducted a series of abstract classification experiments. 4.1 Methods 4.1.1 Feature extraction The first step of text categorization (TC) is to transform documents into a feature vector representation. We experimented with two document representation techniques. The first one is the simple ’bag of words’ approach (BOW) which considers each word in the document as a separate feature. BOW was evaluated using three methods which have proved useful in previous TC work: (i) stemming (using the Porter (1980) stemmer) which removes affixes from words, (ii) the TFIDF weighting (Kibriya et al. 2004), and (iii) stop word removal. The second technique is the recent ’bag of substrings’ (BOS) method by (Wang et al. 2008) which considers the whole abstract as a string and extracts from it all the length p substrings without affix removal. BOS has proved promising in biomedical TC (Han et al. 2006, Wang et al. 2008) and unlike a traditional grammatical stemmer, does not re111 Figure 2: Taxonomy of Carcinogenic Activity quire domain tuning for optimal performance. Because BOS generates substrings with fixed length p, a word shorter than p−2 can get obscured by its context3. For example, ‘mice‘ </context>
<context position="17599" citStr="Kibriya et al. 2004" startWordPosition="2811" endWordPosition="2815">dersen 1997). Given a feature’s distribution X and class label distribution Y , IG(X) = H(Y ) − H(Y |X), H(X) is the entropy of X. The second method fscore optimises the number of features (N). Features are first ranked using the simple fscore criterion (Chen and Lin 2006), and N is selected based on the performance of the SVM classifier using the N features. 4.1.3 Classification Three classifiers were used: Naive Multinomial Bayesian (NMB), Complement Naive Bayesian (CNB) (Rennie and Karger 2003) and Linear Support Vector Machines (L-SVM) (Vapnik 1995). NMB is a widely used classifier in TC (Kibriya et al. 2004). It selects the class C with the maximum probability given the document d: argmaxc Pr(C) Hw∈d Pr(X = w|C). Pr(C) can 3Minus 2 because of space characters. be estimated from the frequency of documents in C. Pr(X = w|C) is estimated as the fraction of tokens in documents of class C that contain w. CNB extends NMB by addressing the problems it has e.g. with imbalanced data and weight magnitude error. The class c of a document is: argmaxc[logp(Bc) − Ei filog N˜c•+α• N˜c+α ]. N˜ci is the number of times term i occurs in classes other than c. α and αi are the smoothing parameters. p(Bc) is the prio</context>
</contexts>
<marker>Kibriya, Frank, Pfahringer, Holmes, 2004</marker>
<rawString>Ashraf M. Kibriya, Eibe Frank, Bernhard Pfahringer, and Geoffrey Holmes. Multinomial naive bayes for text categorization revisited. In Australian Conference on AI, volume 3339, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Corpus annotation for mining biomedical events from lterature.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<contexts>
<context position="25718" citStr="Kim et al. 2008" startWordPosition="4234" endWordPosition="4237">taxonomy. Name MOA Σ P Class P Aflatoxin B1 geno 189 0.95 CA 0.94 Benzene geno 461 0.99 MOA 0.95 PCB non 761 0.89 TOX 0.99 Tamoxifen non 382 0.96 TCDD non 641 0.96 Table 5: Chemicals and the results of the user test 6 Conclusion and Future Work The results of our inter-annotator agreement tests, automatic classification experiments and the user test demonstrate that the taxonomy created by risk assessors is accurate, well-defined, and can be useful in a real-world CRA scenario. This is particularly encouraging considering that the taxonomy is based on biomedical annotation. As highlighted by (Kim et al. 2008), expert annotation is more challenging and prone to inter-annotator disagreement than better-constrained linguistic annotation. We believe that we obtained promising results because we worked in collaboration with risk assessors and developed technology which imitates their current practices as closely as possible. Most related work focuses on binary classification, e.g. BioCreative II had a subtask (Krallinger et al. 2008) on the relevance classification of abstracts for protein interactions. The few works that have attempted multi-classification include e.g. that of Aphinyanaphongs et al. (</context>
</contexts>
<marker>Kim, Ohta, Tsujii, 2008</marker>
<rawString>Jin-Dong Kim, Tomoko Ohta, and Jun’ichi Tsujii. Corpus annotation for mining biomedical events from lterature. BMC Bioinformatics, 9, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Krallinger</author>
<author>Florian Leitner</author>
<author>Carlos RodriguezPenagos</author>
<author>Alfonso Valencia</author>
</authors>
<title>Overview of the protein-protein interaction annotation extraction task of biocreative ii. Genome Biology,</title>
<date>2008</date>
<contexts>
<context position="26146" citStr="Krallinger et al. 2008" startWordPosition="4294" endWordPosition="4297">well-defined, and can be useful in a real-world CRA scenario. This is particularly encouraging considering that the taxonomy is based on biomedical annotation. As highlighted by (Kim et al. 2008), expert annotation is more challenging and prone to inter-annotator disagreement than better-constrained linguistic annotation. We believe that we obtained promising results because we worked in collaboration with risk assessors and developed technology which imitates their current practices as closely as possible. Most related work focuses on binary classification, e.g. BioCreative II had a subtask (Krallinger et al. 2008) on the relevance classification of abstracts for protein interactions. The few works that have attempted multi-classification include e.g. that of Aphinyanaphongs et al. (2005) who applied NMB, SVM and AdaBoost to classify abstracts of internal medicine into four categories, and that of Han et al. (2006) who used BOS and NMB/L-SVMto classify abstracts in five categories of protein posttranslational modifications. In the future, we plan to refine the taxonomy further by careful analysis of keyword types found in the data and the taxonomic relationships defined by experts. This will help to tra</context>
</contexts>
<marker>Krallinger, Leitner, RodriguezPenagos, Valencia, 2008</marker>
<rawString>Martin Krallinger, Florian Leitner, Carlos RodriguezPenagos, and Alfonso Valencia. Overview of the protein-protein interaction annotation extraction task of biocreative ii. Genome Biology, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Richard Landis</author>
<author>Gary G Koch</author>
</authors>
<title>The measurement of observer agreement for categorical data.</title>
<date>1977</date>
<journal>Biometrics,</journal>
<volume>33</volume>
<issue>1</issue>
<marker>Landis, Koch, 1977</marker>
<rawString>J.Richard Landis and Gary G.Koch. The measurement of observer agreement for categorical data. Biometrics, 33(1), 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Lewin</author>
<author>Ilona Silins</author>
<author>Anna Korhonen</author>
<author>Johan Hogberg</author>
<author>Ulla Stenius</author>
</authors>
<title>A new challenge for text mining: Cancer risk assessment.</title>
<date>2008</date>
<booktitle>In Proceedings of the ISMB BioLINK Special Interest Group on Text Data Mining.,</booktitle>
<contexts>
<context position="2642" citStr="Lewin et al. 2008" startWordPosition="412" endWordPosition="415">(e.g. BioCreative and the TREC Genomics track) targeting the workflow of biomedical researchers have appeared along with studies exploring the TM needs of specific tasks (Karamanis et al. 2008, Demaine et al. 2006). However, the understanding of user needs is still one of the neglected areas of BIO-TM, and further usercentered evaluations and systems grounded in reallife tasks are required to determine which tools and services are useful (Cohen et al. 2008). We investigate the user needs of a challenging task yet to be tackled by TM but identified as an important potential application for it (Lewin et al. 2008): Cancer Risk Assessment (CRA). Over the past years, CRA has become increasingly important as the link between environmental chemicals and cancer has become evident. It involves examining published evidence to determine the relationship between exposure to a chemical and the likelihood of developing cancer from that exposure (EPA, 2005). Performed manually by experts in health related institutions worldwide, CRA requires searching, locating and interpreting information in biomedical journal articles. It can be extremely time-consuming because the data for a single carcinogen may be scattered a</context>
<context position="4011" citStr="Lewin et al. 2008" startWordPosition="622" endWordPosition="625"> the task is now getting too challenging to manage via manual means. From the perspective of BIO-TM, CRA is an excellent example of real-world task which could greatly benefit from a dedicated TM tool. However, the development of a truly useful tool requires careful investigation of risk assessors needs. 108 Proceedings of the Workshop on BioNLP, pages 108–116, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics This paper reports our investigation of the user needs of CRA and the creation of basic TM resources for the task. Expanding on our preliminary experiments (Lewin et al. 2008), we present a taxonomy which specifies the scientific evidence needed for CRA at the level of detail required for TM. The taxonomy is based on expert annotation of a corpus of 1297 MEDLINE abstracts. We report promising results with inter-annotator agreement tests, automatic classification of corpus data into taxonomy classes, and a user test in a near real-world CRA scenario which shows that the taxonomy is highly accurate and useful for practical CRA. We discuss refining and extending it further via manual and machine learning approaches, and the subsequent steps required to develop TM for </context>
<context position="8994" citStr="Lewin et al. 2008" startWordPosition="1416" endWordPosition="1419"> MOA induce cancer without interfering directly with DNA. 109 Figure 1: Screenshot of the annotation tool journals, all the PubMed abstracts from 1998-2008 which include one of the 8 chemicals were downloaded. The resulting corpus of 1297 abstracts is distributed per chemical as shown in Table 1. 3.2 Annotation tool Risk assessors typically (i) read each abstract retrieved by PubMed to determine its relevance for CRA, and (ii) classify each relevant abstract based on the type of evidence it provides for CRA. We extended the tool designed for expert annotation of abstracts in our earlier work (Lewin et al. 2008) so that imitates this process as closely as possible. The tool provides two types of functionality. The first enables the experts to classify abstracts as relevant, irrelevant or unsure. The second enables them to annotate such keywords (words or phrases) in abstracts and their titles which indicate the scientific evidence relevant for the task. Keyword annotation was chosen because the experts found it intuitive, it did not require linguistic training, and it specifies the scientific evidence more precisely than larger spans of text. Initially a very shallow taxonomy (including only human, a</context>
</contexts>
<marker>Lewin, Silins, Korhonen, Hogberg, Stenius, 2008</marker>
<rawString>Ian Lewin, Ilona Silins, Anna Korhonen, Johan Hogberg, and Ulla Stenius. A new challenge for text mining: Cancer risk assessment. In Proceedings of the ISMB BioLINK Special Interest Group on Text Data Mining., 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NCBI</author>
</authors>
<title>Efetch entrez utility,</title>
<date>2005</date>
<note>URL http://www.ncbi.nlm.nih.gov/entrez/ query/static/efetch_help.html.</note>
<contexts>
<context position="28275" citStr="NCBI 2005" startWordPosition="4641" endWordPosition="4642">Absorption, ...,excretion 113 69.8 Metabolism 268 76.4 Toxicokinetic modeling 31 84.6 Table 7: E abstracts and F of level 1,2 classes. tion, supplementing it with additional information in knowledge resources and/or by automatic methods. One knowledge resource potentially useful is the Medical Subject Headings (MeSH) taxonomy (Nelson et al. 2002) which classifies PubMed abstracts according to manually defined terms. We performed a small experiment to investigate the usefulness of MeSH for supplementing our current classification. MeSH terms were first retrieved for each abstract using EFetch (NCBI 2005) and then appended to the BOS feature vector. Best features were then selected using fscore and classified using L-SVM. The figures in table 6 show that the results improved significantly for 43% of the low frequency classes. Although this demonstrates the potential usefulness of additional resources, given the rapidly evolving nature of CRA data, the best approach long term is to develop technology for automatic updating of the taxonomy from literature. Given the basic resources we have constructed, the development of such technology is now realistic and can be done using unsupervised or semi</context>
</contexts>
<marker>NCBI, 2005</marker>
<rawString>NCBI. Efetch entrez utility, 2005. URL http://www.ncbi.nlm.nih.gov/entrez/ query/static/efetch_help.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sturart J Nelson</author>
<author>Tammy Powell</author>
<author>Besty L Humphreys</author>
</authors>
<title>The Unified Medical Language System (UMLS) Project.</title>
<date>2002</date>
<booktitle>In Encyclopedia of Library and Information Science,</booktitle>
<pages>369--378</pages>
<publisher>Marcel Dekker,</publisher>
<contexts>
<context position="28013" citStr="Nelson et al. 2002" startWordPosition="4600" endWordPosition="4604">) of MeSH compared to BOS Class E F Carcinogenic activity 1068 92.8 Human study/epidemiology 190 77.7 Animal study 629 80.2 Cell experiments 319 78.5 Study on microorganisms 44 85.2 Mode of Action 653 85.5 Genotoxic 421 89.1 Nongenotoxic 324 76.3 Toxicokinetics 356 77.7 Absorption, ...,excretion 113 69.8 Metabolism 268 76.4 Toxicokinetic modeling 31 84.6 Table 7: E abstracts and F of level 1,2 classes. tion, supplementing it with additional information in knowledge resources and/or by automatic methods. One knowledge resource potentially useful is the Medical Subject Headings (MeSH) taxonomy (Nelson et al. 2002) which classifies PubMed abstracts according to manually defined terms. We performed a small experiment to investigate the usefulness of MeSH for supplementing our current classification. MeSH terms were first retrieved for each abstract using EFetch (NCBI 2005) and then appended to the BOS feature vector. Best features were then selected using fscore and classified using L-SVM. The figures in table 6 show that the results improved significantly for 43% of the low frequency classes. Although this demonstrates the potential usefulness of additional resources, given the rapidly evolving nature o</context>
</contexts>
<marker>Nelson, Powell, Humphreys, 2002</marker>
<rawString>Sturart J. Nelson, Tammy Powell, and Besty L. Humphreys. The Unified Medical Language System (UMLS) Project. In Encyclopedia of Library and Information Science, pages 369–378. Marcel Dekker, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<volume>14</volume>
<issue>3</issue>
<contexts>
<context position="15937" citStr="Porter (1980)" startWordPosition="2524" endWordPosition="2525">cation created by experts provides a good representation of the corpus data and is machine learnable, we conducted a series of abstract classification experiments. 4.1 Methods 4.1.1 Feature extraction The first step of text categorization (TC) is to transform documents into a feature vector representation. We experimented with two document representation techniques. The first one is the simple ’bag of words’ approach (BOW) which considers each word in the document as a separate feature. BOW was evaluated using three methods which have proved useful in previous TC work: (i) stemming (using the Porter (1980) stemmer) which removes affixes from words, (ii) the TFIDF weighting (Kibriya et al. 2004), and (iii) stop word removal. The second technique is the recent ’bag of substrings’ (BOS) method by (Wang et al. 2008) which considers the whole abstract as a string and extracts from it all the length p substrings without affix removal. BOS has proved promising in biomedical TC (Han et al. 2006, Wang et al. 2008) and unlike a traditional grammatical stemmer, does not re111 Figure 2: Taxonomy of Carcinogenic Activity quire domain tuning for optimal performance. Because BOS generates substrings with fixe</context>
<context position="19364" citStr="Porter (1980)" startWordPosition="3130" endWordPosition="3131"> was weighted by class population ratio negative population positive population . 4.1.4 Evaluation We used the standard measures of recall (R), precision (P) and F measure (F) for evaluation. These are defined as follows: TP TP = 2×R×P R _ — TP+FN P = TP+FP F R+P Our random baseline is P+ N+P+ . r = 112 P+/N: positive/negative population TP: truth positive; FN: false negative, FP: false positive 4.2 Experimental evaluation 4.2.1 Data Our data was the expert annotated CRA corpus. 4.2.2 Document preprocessing We first evaluated the BOW preprocessing technique with and without the use of (i) the Porter (1980) stemmer, (ii) TFIDF, (iii) stop word removal, and (iv) their combinations. The evaluation was done in the context of the binary relevance classification of abstracts (not in the context of the main taxonomic classification task to avoid overfitting preprocessing techniques to the taxonomy). Only (iii) improved all the classifiers and was thus adopted for the main experiments. The poor performance of (i) demonstrates that a standard stemmer is not optimal for our data. As highlighted by (Han et al. 2006, Wang et al. 2008), semantically related biological terms sharing the same stem are not alw</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>M. F. Porter. An algorithm for suffix stripping. Program, 14(3):130–137, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason D M Rennie</author>
<author>David Karger</author>
</authors>
<title>Tackling the poor assumptions of naive bayes text classifiers. In</title>
<date>2003</date>
<booktitle>In Proceedings of the 20th ICML,</booktitle>
<contexts>
<context position="17481" citStr="Rennie and Karger 2003" startWordPosition="2790" endWordPosition="2793">ction methods for dimensionality reduction. The first is Information Gain (IG) which has proved useful in TC (Yang and Pedersen 1997). Given a feature’s distribution X and class label distribution Y , IG(X) = H(Y ) − H(Y |X), H(X) is the entropy of X. The second method fscore optimises the number of features (N). Features are first ranked using the simple fscore criterion (Chen and Lin 2006), and N is selected based on the performance of the SVM classifier using the N features. 4.1.3 Classification Three classifiers were used: Naive Multinomial Bayesian (NMB), Complement Naive Bayesian (CNB) (Rennie and Karger 2003) and Linear Support Vector Machines (L-SVM) (Vapnik 1995). NMB is a widely used classifier in TC (Kibriya et al. 2004). It selects the class C with the maximum probability given the document d: argmaxc Pr(C) Hw∈d Pr(X = w|C). Pr(C) can 3Minus 2 because of space characters. be estimated from the frequency of documents in C. Pr(X = w|C) is estimated as the fraction of tokens in documents of class C that contain w. CNB extends NMB by addressing the problems it has e.g. with imbalanced data and weight magnitude error. The class c of a document is: argmaxc[logp(Bc) − Ei filog N˜c•+α• N˜c+α ]. N˜ci </context>
</contexts>
<marker>Rennie, Karger, 2003</marker>
<rawString>Jason D. M. Rennie and David Karger. Tackling the poor assumptions of naive bayes text classifiers. In In Proceedings of the 20th ICML, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Sasaki</author>
<author>S Montemagni</author>
<author>P Pezik</author>
<author>D RebholzSchuhmann</author>
<author>J McNaught</author>
<author>S Ananiadou</author>
</authors>
<title>BioLexicon: A Lexical Resource for the Biology Domain.</title>
<date>2008</date>
<contexts>
<context position="29301" citStr="Sasaki et al. 2008" startWordPosition="4806" endWordPosition="4809">automatic updating of the taxonomy from literature. Given the basic resources we have constructed, the development of such technology is now realistic and can be done using unsupervised or semi-supervised machine learning techniques, e.g. (Cohen and Hersh 2005, Blaschko and Gretton 2009). The automatic classification could be improved by the use of more sophisticated features extracted using NLP tools that have been tuned for biomedical texts, such as parsers, e.g. (Tsuruoka et al. 2005), and named entity recognizers, e.g. (Corbett et al. 2007), and exploiting resources such as the BioLexion (Sasaki et al. 2008). Our long term goal is to develop a TM tool specifically designed for CRA. Some tools have recently been built to assist other critical activities of biomedicine (e.g. literature curation for genetics). A few of them have been evaluated for their practical usefulness in a real-world scenario (Karamanis et al. 2008, Demaine et al. 2006). Such tools and evaluations act as an important proof of concept for biomedical TM and help to develop technology for the needs of practical applications. According to the interviews we conducted (Section 2), a tool capable of identifying, ranking and classifyi</context>
</contexts>
<marker>Sasaki, Montemagni, Pezik, RebholzSchuhmann, McNaught, Ananiadou, 2008</marker>
<rawString>Y. Sasaki, S. Montemagni, P. Pezik, D. RebholzSchuhmann, J. McNaught, and S. Ananiadou. BioLexicon: A Lexical Resource for the Biology Domain. 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tsuruoka</author>
<author>Y Tateishi</author>
<author>J Kim</author>
<author>T Ohta</author>
<author>J McNaught</author>
<author>S Ananiadou</author>
<author>J Tsujii</author>
</authors>
<title>Developing a Robust Partof-Speech Tagger for Biomedical Text.</title>
<date>2005</date>
<volume>3746</volume>
<contexts>
<context position="29174" citStr="Tsuruoka et al. 2005" startWordPosition="4785" endWordPosition="4788">of additional resources, given the rapidly evolving nature of CRA data, the best approach long term is to develop technology for automatic updating of the taxonomy from literature. Given the basic resources we have constructed, the development of such technology is now realistic and can be done using unsupervised or semi-supervised machine learning techniques, e.g. (Cohen and Hersh 2005, Blaschko and Gretton 2009). The automatic classification could be improved by the use of more sophisticated features extracted using NLP tools that have been tuned for biomedical texts, such as parsers, e.g. (Tsuruoka et al. 2005), and named entity recognizers, e.g. (Corbett et al. 2007), and exploiting resources such as the BioLexion (Sasaki et al. 2008). Our long term goal is to develop a TM tool specifically designed for CRA. Some tools have recently been built to assist other critical activities of biomedicine (e.g. literature curation for genetics). A few of them have been evaluated for their practical usefulness in a real-world scenario (Karamanis et al. 2008, Demaine et al. 2006). Such tools and evaluations act as an important proof of concept for biomedical TM and help to develop technology for the needs of pra</context>
</contexts>
<marker>Tsuruoka, Tateishi, Kim, Ohta, McNaught, Ananiadou, Tsujii, 2005</marker>
<rawString>Y. Tsuruoka, Y. Tateishi, J. Kim, T. Ohta, J. McNaught, S. Ananiadou, and J. Tsujii. Developing a Robust Partof-Speech Tagger for Biomedical Text. 3746, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>EPA</author>
</authors>
<title>Guidelines for carcinogen risk assessment. U.S. Environmental Protection Agency,</title>
<date>2005</date>
<note>URL http://www.epa.gov/iris/ cancer032505.pdf.</note>
<contexts>
<context position="2980" citStr="EPA, 2005" startWordPosition="464" endWordPosition="465">ystems grounded in reallife tasks are required to determine which tools and services are useful (Cohen et al. 2008). We investigate the user needs of a challenging task yet to be tackled by TM but identified as an important potential application for it (Lewin et al. 2008): Cancer Risk Assessment (CRA). Over the past years, CRA has become increasingly important as the link between environmental chemicals and cancer has become evident. It involves examining published evidence to determine the relationship between exposure to a chemical and the likelihood of developing cancer from that exposure (EPA, 2005). Performed manually by experts in health related institutions worldwide, CRA requires searching, locating and interpreting information in biomedical journal articles. It can be extremely time-consuming because the data for a single carcinogen may be scattered across thousands of articles. Given the exponentially growing volume of biomedical literature and the rapid development of molecular biology techniques, the task is now getting too challenging to manage via manual means. From the perspective of BIO-TM, CRA is an excellent example of real-world task which could greatly benefit from a dedi</context>
<context position="6468" citStr="EPA, 2005" startWordPosition="1020" endWordPosition="1021">e particularly helpful. It became clear that a prerequisite for the development of such a tool would be an extensive specification of the scientific evidence used for CRA. 1Institute of Environmental Medicine at Karolinska Institutet, Swedish Chemical Inspectorate, Scientific Committee on Occupational Exposure Limits (EU), Swedish Criteria Group. This evidence — which forms the basis of all the subsequent steps of CRA — is described in the guideline documents of major international CRA agencies, e.g. European Chemicals Agency (ECHA, 2008) and the United States Environmental Protection Agency (EPA, 2005). However, although these documents constitute the main reference material in CRA, they cover the main types of evidence only, do not specify the evidence at the level of detail required for comprehensive data gathering, and are not updated regularly (i.e. do not incorporate the latest developments in biomedical sciences). The risk assessors admitted that rather than relying on these documents, they rely on their experience and expert knowledge when looking for the evidence. We decided that our starting point should be to compose a more adequate specification of the scientific evidence needed </context>
</contexts>
<marker>EPA, 2005</marker>
<rawString>EPA, 2005. Guidelines for carcinogen risk assessment. U.S. Environmental Protection Agency, 2005. URL http://www.epa.gov/iris/ cancer032505.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>The nature of statistical learning theory.</title>
<date>1995</date>
<location>New York, NY, USA,</location>
<contexts>
<context position="17538" citStr="Vapnik 1995" startWordPosition="2801" endWordPosition="2802"> Gain (IG) which has proved useful in TC (Yang and Pedersen 1997). Given a feature’s distribution X and class label distribution Y , IG(X) = H(Y ) − H(Y |X), H(X) is the entropy of X. The second method fscore optimises the number of features (N). Features are first ranked using the simple fscore criterion (Chen and Lin 2006), and N is selected based on the performance of the SVM classifier using the N features. 4.1.3 Classification Three classifiers were used: Naive Multinomial Bayesian (NMB), Complement Naive Bayesian (CNB) (Rennie and Karger 2003) and Linear Support Vector Machines (L-SVM) (Vapnik 1995). NMB is a widely used classifier in TC (Kibriya et al. 2004). It selects the class C with the maximum probability given the document d: argmaxc Pr(C) Hw∈d Pr(X = w|C). Pr(C) can 3Minus 2 because of space characters. be estimated from the frequency of documents in C. Pr(X = w|C) is estimated as the fraction of tokens in documents of class C that contain w. CNB extends NMB by addressing the problems it has e.g. with imbalanced data and weight magnitude error. The class c of a document is: argmaxc[logp(Bc) − Ei filog N˜c•+α• N˜c+α ]. N˜ci is the number of times term i occurs in classes other tha</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>Vladimir N. Vapnik. The nature of statistical learning theory. New York, NY, USA, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongning Wang</author>
<author>Minlie Huang</author>
<author>Shilin Ding</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Exploiting and integrating rich features for biological literature classification.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<contexts>
<context position="16147" citStr="Wang et al. 2008" startWordPosition="2559" endWordPosition="2562">irst step of text categorization (TC) is to transform documents into a feature vector representation. We experimented with two document representation techniques. The first one is the simple ’bag of words’ approach (BOW) which considers each word in the document as a separate feature. BOW was evaluated using three methods which have proved useful in previous TC work: (i) stemming (using the Porter (1980) stemmer) which removes affixes from words, (ii) the TFIDF weighting (Kibriya et al. 2004), and (iii) stop word removal. The second technique is the recent ’bag of substrings’ (BOS) method by (Wang et al. 2008) which considers the whole abstract as a string and extracts from it all the length p substrings without affix removal. BOS has proved promising in biomedical TC (Han et al. 2006, Wang et al. 2008) and unlike a traditional grammatical stemmer, does not re111 Figure 2: Taxonomy of Carcinogenic Activity quire domain tuning for optimal performance. Because BOS generates substrings with fixed length p, a word shorter than p−2 can get obscured by its context3. For example, ‘mice‘ would be transformed to ’ mice a’, ’ mice b’, ... , which is less informative than the original word form. Therefore, we</context>
<context position="19891" citStr="Wang et al. 2008" startWordPosition="3215" endWordPosition="3218">valuated the BOW preprocessing technique with and without the use of (i) the Porter (1980) stemmer, (ii) TFIDF, (iii) stop word removal, and (iv) their combinations. The evaluation was done in the context of the binary relevance classification of abstracts (not in the context of the main taxonomic classification task to avoid overfitting preprocessing techniques to the taxonomy). Only (iii) improved all the classifiers and was thus adopted for the main experiments. The poor performance of (i) demonstrates that a standard stemmer is not optimal for our data. As highlighted by (Han et al. 2006, Wang et al. 2008), semantically related biological terms sharing the same stem are not always reducible to the stem form. 4.2.3 Feature selection We evaluated the feature selection methods on two taxonomy classes: the most balanced class ‘Animal study‘ (positive/negative 1:1.4) and an imbalanced class ‘Adducts‘ (positive/negative 1:6.5). IG was used for the fixed N setting and fscore for the dynamic N setting. Each combination of classifiers (NMB/CNB/SVM), document representations (BOW, BOS) and settings for N (dynamic, ... , 83098) was evaluated. The results show that the dynamic setting yields consistent imp</context>
</contexts>
<marker>Wang, Huang, Ding, Zhu, 2008</marker>
<rawString>Hongning Wang, Minlie Huang, Shilin Ding, and Xiaoyan Zhu. Exploiting and integrating rich features for biological literature classification. BMC Bioinformatics, 9(Suppl 3), 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yiming Yang</author>
<author>Xin Liu</author>
</authors>
<title>A re-examination of text categorization methods.</title>
<date>1999</date>
<booktitle>In Proceedings ofthe 22nd SIGIR,</booktitle>
<location>New York, NY, USA,</location>
<contexts>
<context position="18442" citStr="Yang and Liu 1999" startWordPosition="2965" endWordPosition="2968">imated as the fraction of tokens in documents of class C that contain w. CNB extends NMB by addressing the problems it has e.g. with imbalanced data and weight magnitude error. The class c of a document is: argmaxc[logp(Bc) − Ei filog N˜c•+α• N˜c+α ]. N˜ci is the number of times term i occurs in classes other than c. α and αi are the smoothing parameters. p(Bc) is the prior distribution of class c. L-SVM is the basic type of SVM which produces a hyperplane that separates two-class samples with a maximum margin. It handles high dimensional data efficiently, and has shown to perform well in TC (Yang and Liu 1999). Given the data set X = (x1, y1), ... , (xn, yn) yi E 1−1, +11, L-SVM requires a solution w to the following unconstrained optimisation problem: min(12wTw + C i=1 max(1 − yiwTxi, 0)2. Cost parameter C was estimated within range 22,... , 25 on training data using cross validation. The C of the positive class was weighted by class population ratio negative population positive population . 4.1.4 Evaluation We used the standard measures of recall (R), precision (P) and F measure (F) for evaluation. These are defined as follows: TP TP = 2×R×P R _ — TP+FN P = TP+FP F R+P Our random baseline is P+ N</context>
</contexts>
<marker>Yang, Liu, 1999</marker>
<rawString>Yiming Yang and Xin Liu. A re-examination of text categorization methods. In Proceedings ofthe 22nd SIGIR, New York, NY, USA, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yiming Yang</author>
<author>Jan O Pedersen</author>
</authors>
<title>A comparative study on feature selection in text categorization.</title>
<date>1997</date>
<contexts>
<context position="16991" citStr="Yang and Pedersen 1997" startWordPosition="2704" endWordPosition="2707">l grammatical stemmer, does not re111 Figure 2: Taxonomy of Carcinogenic Activity quire domain tuning for optimal performance. Because BOS generates substrings with fixed length p, a word shorter than p−2 can get obscured by its context3. For example, ‘mice‘ would be transformed to ’ mice a’, ’ mice b’, ... , which is less informative than the original word form. Therefore, we enriched BOS features with word forms shorter than p − 2. 4.1.2 Feature selection We employed two feature selection methods for dimensionality reduction. The first is Information Gain (IG) which has proved useful in TC (Yang and Pedersen 1997). Given a feature’s distribution X and class label distribution Y , IG(X) = H(Y ) − H(Y |X), H(X) is the entropy of X. The second method fscore optimises the number of features (N). Features are first ranked using the simple fscore criterion (Chen and Lin 2006), and N is selected based on the performance of the SVM classifier using the N features. 4.1.3 Classification Three classifiers were used: Naive Multinomial Bayesian (NMB), Complement Naive Bayesian (CNB) (Rennie and Karger 2003) and Linear Support Vector Machines (L-SVM) (Vapnik 1995). NMB is a widely used classifier in TC (Kibriya et a</context>
</contexts>
<marker>Yang, Pedersen, 1997</marker>
<rawString>Yiming Yang and Jan O. Pedersen. A comparative study on feature selection in text categorization. 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Zweigenbaum</author>
<author>Dina Demner-Fushman</author>
<author>Hong Yu</author>
<author>Kevin B Cohen</author>
</authors>
<title>Frontiers of biomedical text mining: current progress.</title>
<date>2007</date>
<journal>Brief Bioinform,</journal>
<volume>8</volume>
<issue>5</issue>
<contexts>
<context position="1702" citStr="Zweigenbaum et al. 2007" startWordPosition="264" endWordPosition="267">e needs of CRA. 1 Introduction Biomedical Text Mining (TM) has become increasingly popular due to the pressing need to provide access to the tremendous body of texts available in biomedical sciences. Considerable progress has been made in the development of basic resources (e.g. ontologies, annotated corpora) and techniques (e.g. Information Retrieval (IR), Information Extraction (IE)) in this area, and research has began to focus on increasingly challenging tasks, e.g. summarization and the discovery of novel information in biomedical literature (Hunter and Cohen 2006, Ananiadou et al. 2006, Zweigenbaum et al. 2007). In recent past, there has been an increasing demand for research which is driven by actual user Ilona Silins, Ulla Stenius Institute of Environmental Medicine Karolinska Institutet S-17177, Stockholm Sweden ilona.silins,ulla.stenius@ki.se needs rather than technical developments (Zweigenbaum et al. 2007). Shared tasks (e.g. BioCreative and the TREC Genomics track) targeting the workflow of biomedical researchers have appeared along with studies exploring the TM needs of specific tasks (Karamanis et al. 2008, Demaine et al. 2006). However, the understanding of user needs is still one of the n</context>
</contexts>
<marker>Zweigenbaum, Demner-Fushman, Yu, Cohen, 2007</marker>
<rawString>Pierre Zweigenbaum, Dina Demner-Fushman, Hong Yu, and Kevin B. Cohen. Frontiers of biomedical text mining: current progress. Brief Bioinform, 8(5), 2007.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>