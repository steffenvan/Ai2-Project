<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000023">
<title confidence="0.97624">
A Lightweight and High Performance Monolingual Word Aligner
</title>
<author confidence="0.899204">
Xuchen Yao and Benjamin Van Durme
</author>
<affiliation confidence="0.855707">
Johns Hopkins University
</affiliation>
<address confidence="0.593508">
Baltimore, MD, USA
</address>
<author confidence="0.671629">
Chris Callison-Burch∗
</author>
<affiliation confidence="0.6929965">
University of Pennsylvania
Philadelphia, PA, USA
</affiliation>
<sectionHeader confidence="0.957032" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999934071428571">
Fast alignment is essential for many nat-
ural language tasks. But in the setting of
monolingual alignment, previous work has
not been able to align more than one sen-
tence pair per second. We describe a dis-
criminatively trained monolingual word
aligner that uses a Conditional Random
Field to globally decode the best align-
ment with features drawn from source and
target sentences. Using just part-of-speech
tags and WordNet as external resources,
our aligner gives state-of-the-art result,
while being an order-of-magnitude faster
than the previous best performing system.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999958772727273">
In statistical machine translation, alignment is typ-
ically done as a one-off task during training. How-
ever for monolingual tasks, like recognizing tex-
tual entailment or question answering, alignment
happens repeatedly: once or multiple times per
test item. Therefore, the efficiency of the aligner is
of utmost importance for monolingual alignment
tasks. Monolingual word alignment also has a va-
riety of distinctions than the bilingual case, for ex-
ample: there is often less training data but more
lexical resources available; semantic relatedness
may be cued by distributional word similarities;
and, both the source and target sentences share the
same grammar.
These distinctions suggest a model design that
utilizes arbitrary features (to make use of word
similarity measure and lexical resources) and ex-
ploits deeper sentence structures (especially in the
case of major languages where robust parsers are
available). In this setting the balance between
precision and speed becomes an issue: while we
might leverage an extensive NLP pipeline for a
</bodyText>
<note confidence="0.319946">
∗Performed while faculty at Johns Hopkins University.
</note>
<author confidence="0.415156">
Peter Clark
</author>
<affiliation confidence="0.467221">
Vulcan Inc.
</affiliation>
<address confidence="0.56789">
Seattle, WA, USA
</address>
<bodyText confidence="0.999802578947369">
language like English, such pipelines can be com-
putationally expensive. One earlier attempt, the
MANLI system (MacCartney et al., 2008), used
roughly 5GB of lexical resources and took 2 sec-
onds per alignment, making it hard to be deployed
and run in large scale. On the other extreme, a sim-
ple non-probabilistic Tree Edit Distance (TED)
model (c.f. §4.2) is able to align 10, 000 pairs
per second when the sentences are pre-parsed, but
with significantly reduced performance. Trying to
embrace the merits of both worlds, we introduce a
discriminative aligner that is able to align tens to
hundreds of sentence pairs per second, and needs
access only to a POS tagger and WordNet.
This aligner gives state-of-the-art performance
on the MSR RTE2 alignment dataset (Brockett,
2007), is faster than previous work, and we re-
lease it publicly as the first open-source monolin-
gual word aligner: Jacana.Align.1
</bodyText>
<sectionHeader confidence="0.999694" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999448888888889">
The MANLI aligner (MacCartney et al., 2008)
was first proposed to align premise and hypothe-
sis sentences for the task of natural language in-
ference. It applies perceptron learning and han-
dles phrase-based alignment of arbitrary phrase
lengths. Thadani and McKeown (2011) opti-
mized this model by decoding via Integer Linear
Programming (ILP). Benefiting from modern ILP
solvers, this led to an order-of-magnitude speedup.
With extra syntactic constraints added, the exact
alignment match rate for whole sentence pairs was
also significantly improved.
Besides the above supervised methods, indirect
supervision has also been explored. Among them,
Wang and Manning (2010) extended the work of
McCallum et al. (2005) and modeled alignment
as latent variables. Heilman and Smith (2010)
used tree kernels to search for the alignment that
</bodyText>
<footnote confidence="0.992957">
1http://code.google.com/p/jacana/
</footnote>
<page confidence="0.934604">
702
</page>
<bodyText confidence="0.694036833333333">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 702–707,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
yields the lowest tree edit distance. Other tree
or graph matching work for alignment includes
that of (Punyakanok et al., 2004; Kouylekov and
Magnini, 2005; Chambers et al., 2007; Mehdad,
2009; Roth and Frank, 2012).
Finally, feature and model design in monolin-
gual alignment is often inspired by bilingual work,
including distortion modeling, phrasal alignment,
syntactic constraints, etc (Och and Ney, 2003;
DeNero and Klein, 2007; Bansal et al., 2011).
</bodyText>
<sectionHeader confidence="0.996549" genericHeader="method">
3 The Alignment Model
</sectionHeader>
<subsectionHeader confidence="0.998779">
3.1 Model Design
</subsectionHeader>
<bodyText confidence="0.9989542">
Our work is heavily influenced by the bilingual
alignment literature, especially the discriminative
model proposed by Blunsom and Cohn (2006).
Given a source sentence s of length M, and a tar-
get sentence t of length N, the alignment from s
to t is a sequence of target word indices a, where
amE[1,M] ∈ [0, N]. We specify that when am = 0,
source word st is aligned to a NULL state, i.e.,
deleted. This models a many-to-one alignment
from source to target. Multiple source words can
be aligned to the same target word, but not vice
versa. One-to-many alignment can be obtained
by running the aligner in the other direction. The
probability of alignment sequence a conditioned
on both s and t is then:
</bodyText>
<equation confidence="0.6432075">
exp(Em,k Akfk(am−1, am, s, t))
Z(s, t)
</equation>
<bodyText confidence="0.999922142857143">
This assumes a first-order Conditional Random
Field (Lafferty et al., 2001). The word alignment
task is evaluated over F1. Instead of directly op-
timizing F1, we employ softmax-margin training
(Gimpel and Smith, 2010) and add a cost function
to the normalizing function Z(s, t) in the denom-
inator, which becomes:
</bodyText>
<equation confidence="0.9524335">
� �exp( Akfk(ˆam−1, ˆam, s, t) + cost(at, ˆa))
aˆ m,k
</equation>
<bodyText confidence="0.997779857142857">
where at is the true alignments. cost(at, ˆa)
can be viewed as special “features” with uniform
weights that encourage consistent with true align-
ments. It is only computed during training in the
denominator because cost(at, at) = 0 in the nu-
merator. Hamming cost is used in practice.
One distinction of this alignment model com-
pared to other commonly defined CRFs is that
the input is two dimensional: at each position m,
the model inspects both the entire sequence of
source words (as the observation) and target words
(whose offset indices are states). The other dis-
tinction is that the size of its state space is not
fixed (e.g., unlike POS tagging, where states are
for instance 45 Penn Treebank tags), but depends
on N, the length of target sentence. Thus we can
not “memorize” what features are mostly associ-
ated with what states. For instance, in the task of
tagging mail addresses, a feature of “5 consecu-
tive digits” is highly indicative of a POSTCODE.
However, in the alignment model, it does not make
sense to design features based on a hard-coded
state, say, a feature of “source word lemma match-
ing target word lemma” fires for state index 6.
To avoid this data sparsity problem, all features
are defined implicitly with respect to the state. For
instance:
Thus this feature fires for, e.g.:
</bodyText>
<equation confidence="0.9828135">
(s3 = sport, t5 = sports, a3 = 5), and:
(s2 = like, t10 = liked, a2 = 10).
</equation>
<subsectionHeader confidence="0.996147">
3.2 Feature Design
</subsectionHeader>
<bodyText confidence="0.998502619047619">
String Similarity Features include the following
similarity measures: Jaro Winkler, Dice Sorensen,
Hamming, Jaccard, Levenshtein, NGram overlap-
ping and common prefix matching.2 Also, two
binary features are added for identical match and
identical match ignoring case.
POS Tags Features are binary indicators of
whether the POS tags of two words match. Also,
a “possrc2postgt” feature fires for each word pair,
with respect to their POS tags. This would capture,
e.g., “vbz2nn”, when a verb such as arrests aligns
with a noun such as custody.
Positional Feature is a real-valued feature for the
positional difference of the source and target word
(abs(mM − am
N )).
WordNet Features indicate whether two words
are of the following relations of each other: hyper-
nym, hyponym, synonym, derived form, entailing,
causing, members of, have member, substances of,
have substances, parts of, have part; or whether
</bodyText>
<footnote confidence="0.647302">
2Of these features the trained aligner preferred Dice
Sorensen and NGram overlapping.
</footnote>
<figure confidence="0.67294425">
p(a  |s,t) =
fk(am−1, am, s, t) = �
1 lemmas match: sm, tam
0 otherwise
</figure>
<page confidence="0.98993">
703
</page>
<bodyText confidence="0.999018052631579">
their lemmas match.3
Distortion Features measure how far apart the
aligned target words of two consecutive source
words are: abs(am + 1 − am−1). This learns a
general pattern of whether these two target words
aligned with two consecutive source words are
usually far away from each other, or very close.
We also added special features for corner cases
where the current word starts or ends the source
sentence, or both the previous and current words
are deleted (a transition from NULL to NULL).
Contextual Features indicate whether the left or
the right neighbor of the source word and aligned
target word are identical or similar. This helps
especially when aligning functional words, which
usually have multiple candidate target functional
words to align to and string similarity features can-
not help. We also added features for neighboring
POS tags matching.
</bodyText>
<subsectionHeader confidence="0.989919">
3.3 Symmetrization
</subsectionHeader>
<bodyText confidence="0.9998164">
To expand from many-to-one alignment to many-
to-many, we ran the model in both directions and
applied the following symmetrization heuristics
(Koehn, 2010): INTERSECTION, UNION, GROW-
DIAG-FINAL.
</bodyText>
<sectionHeader confidence="0.999597" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.922563">
4.1 Setup
</subsectionHeader>
<bodyText confidence="0.999990166666667">
Since no generic off-the-shelf CRF software is de-
signed to handle the special case of dynamic state
indices and feature functions (Blunsom and Cohn,
2006), we implemented this aligner model in the
Scala programming language, which is fully in-
teroperable with Java. We used the L2 regular-
izer and LBFGS for optimization. OpenNLP4 pro-
vided the POS tagger and JWNL5 interfaced with
WordNet (Fellbaum, 1998).
To make results directly comparable, we closely
followed the setup of MacCartney et al. (2008) and
Thadani and McKeown (2011). Training and test
data (Brockett, 2007) each contains 800 manually
aligned premise and hypothesis pairs from RTE2.
Note that the premises contain 29 words on av-
erage, and the hypotheses only 11 words. We take
the premise as the source and hypothesis as the tar-
get, and use S2T to indicate the model aligns from
</bodyText>
<footnote confidence="0.99996725">
3We found that each word has to be POS tagged to get an
accurate relation, otherwise this feature will not help.
4http://opennlp.apache.org/
5http://jwordnet.sf.net/
</footnote>
<note confidence="0.584947">
source to target and T2S from target to source.
</note>
<subsectionHeader confidence="0.946111">
4.2 Simple Baselines
</subsectionHeader>
<bodyText confidence="0.999954555555555">
We additionally used two baseline systems for
comparison. One was GIZA++, with the IN-
TERSECTION tricks post-applied, which worked
the best among all other symmetrization heuris-
tics. The other was a Tree Edit Distance (TED)
model, popularly used in a series of NLP appli-
cations (Punyakanok et al., 2004; Kouylekov and
Magnini, 2005; Heilman and Smith, 2010). We
used uniform cost for deletion, insertion and sub-
stitutions, and applied a dynamic program algo-
rithm (Zhang and Shasha, 1989) to decode the
tree edit sequence with the minimal cost, based
on the Stanford dependency tree (De Marneffe
and Manning, 2008). This non-probabilistic ap-
proach turned out to be extremely fast, processing
about 10,000 sentence pairs per second with pre-
parsed trees, performing quantitatively better than
the Stanford RTE aligner (Chambers et al., 2007).
</bodyText>
<subsectionHeader confidence="0.992758">
4.3 MANLI Baselines
</subsectionHeader>
<bodyText confidence="0.9873505">
MANLI was first developed by MacCartney et al.
(2008), and then improved by Thadani and McKe-
own (2011) with faster and exact decoding via ILP.
There are four versions to be compared here:
MANLI the original version.
MANLI-approx. re-implemented version by
Thadani and McKeown (2011).
MANLI-exact decoding via ILP solvers.
MANLI-constraint MANLI-exact with hard
syntactic constraints, mainly on common “light”
words (determiners, prepositions, etc.) attachment
to boost exact match rate.
</bodyText>
<subsectionHeader confidence="0.661694">
4.4 Results
</subsectionHeader>
<bodyText confidence="0.999844857142857">
Following Thadani and McKeown (2011), perfor-
mance is evaluated by macro-averaged precision,
recall, F1 of aligned token pairs, and exact (per-
fect) match rate for a whole pair, shown in Ta-
ble 1. As our baselines, GIZA++ (with align-
ment intersection of two directions) and TED are
on par with previously reported results using the
Stanford RTE aligner. The MANLI-family of sys-
tems provide stronger baselines, notably MANLI-
constraint, which has the best F1 and exact match
rate among themselves.
We ran our aligner in two directions: S2T and
T2S, then merged the results with INTERSECTION,
UNION and GROW-DIAG-FINAL. Our system beats
</bodyText>
<page confidence="0.996581">
704
</page>
<table confidence="0.999919230769231">
System P % R % F1 % E %
GIZA++, n 82.5 74.4 78.3 14.0
TED 80.6 79.0 79.8 13.5
Stanford RTE* 82.7 75.8 79.1 -
MANLI* 85.4 85.3 85.3 21.3
MANLI-approx.a 87.2 86.3 86.7 24.5
MANLI-exacta 87.2 86.1 86.8 24.8
MANLI-constraints 89.5 86.2 87.8 33.0
this work, S2T 91.8 83.4 87.4 25.9
this work, T2S 93.7 84.0 88.6 35.3
S2T n T2S 95.4 80.8 87.5 31.3
S2T U T2S 90.3 86.6 88.4 29.6
GROW-DIAG-FINAL 94.4 81.8 87.6 30.8
</table>
<tableCaption confidence="0.99526075">
Table 1: Results on the 800 pairs of test data. E% stands
for exact (perfect) match rate. Systems marked with * are
reported by MacCartney et al. (2008), with a by Thadani and
McKeown (2011).
</tableCaption>
<bodyText confidence="0.99989885">
the weak and strong baselines6 in all measures ex-
cept recall. Some patterns are very clearly shown:
Higher precision, lower recall is due to the
higher-quality and lower-coverage of WordNet,
where the MANLI-family systems used addi-
tional, automatically derived lexical resources.
Imbalance of exact match rate between S2T and
T2S with a difference of 9.4% is due to the many-
to-one nature of the aligner. When aligning from
source (longer) to target (shorter), multiple source
words can align to the same target word. This
is not desirable since multiple duplicate “light”
words are aligned to the same “light” word in the
target, which breaks perfect match. When align-
ing T2S, this problem goes away: the shorter tar-
get sentence contains less duplicate words, and in
most cases there is an one-to-one mapping.
MT heuristics help, with INTERSECTION and
UNION respectively improving precision and re-
call.
</bodyText>
<subsectionHeader confidence="0.983099">
4.5 Runtime Test
</subsectionHeader>
<bodyText confidence="0.999926818181818">
Table 2 shows the runtime comparison. Since the
RTE2 corpus is imbalanced, with premise length
(words) of 29 and hypothesis length of 11, we
also compare on the corpus of FUSION (McKeown
et al., 2010), with both sentences in a pair aver-
aging 27. MANLI-approx. is the slowest, with
quadratic growth in the number of edits with sen-
tence length. MANLI-exact is in second place, re-
lying on the ILP solver. This work has a precise
O(MN2) decoding time, with M the source sen-
tence length and N the target sentence length.
</bodyText>
<footnote confidence="0.997967333333333">
6Unfortunately both MacCartney and Thadani no longer
have their original output files (personal communication), so
we cannot run a significance test against their result.
</footnote>
<table confidence="0.95784725">
corpus sent. pair MANLI- MANLI- this
length approx. exact work
RTE2 29/11 1.67 0.08 0.025
FUSION 27/27 61.96 2.45 0.096
</table>
<tableCaption confidence="0.844933272727273">
Table 2: Alignment runtime in seconds per sentence pair on
two corpora: RTE2 (Cohn et al., 2008) and FUSION (McKe-
own et al., 2010). The MANLI-* results are from Thadani
and McKeown (2011), on a Xeon 2.0GHz with 6MB Cache.
The runtime for this work takes the longest timing from S2T
and T2S, on a Xeon 2.2GHz with 4MB cache (the closest
we can find to match their hardware). Horizontally in a real-
world application where sentences have similar length, this
work is roughly 20x faster (0.096 vs. 2.45). Vertically, the
decoding time for our work increases less dramatically when
sentence length increases (0.025-+0.096 vs. 0.08-+2.45).
</tableCaption>
<table confidence="0.9995582">
features P % R % F1 % E %
full (T2S) 93.7 84.0 88.6 35.3
- POS 93.2 83.5 88.1 31.4
- WordNet 93.2 83.7 88.2 33.5
- both 93.1 83.2 87.8 30.1
</table>
<tableCaption confidence="0.9109215">
Table 3: Performance without POS and/or Word-
Net features.
</tableCaption>
<bodyText confidence="0.9949695">
While MANLI-exact is about twenty-fold faster
than MANLI-approx., our aligner is at least an-
other twenty-fold faster than MANLI-exact when
the sentences are longer and balanced. We also
benefit from shallower pre-processing (no parsing)
and can store all resources in main memory.7
</bodyText>
<subsectionHeader confidence="0.997491">
4.6 Ablation Test
</subsectionHeader>
<bodyText confidence="0.99987975">
Since WordNet and the POS tagger is the only used
external resource, we removed them8 from the fea-
ture sets and reported performance in Table 3. This
somehow reflects how the model would perform
for a language without a suitable POS tagger, or
more commonly, WordNet in that language. At
this time, the model falls back to relying on string
similarities, distortion, positional and contextual
features, which are almost language-independent.
A loss of less than 1% in F1 suggests that the
aligner can still run reasonably well without a POS
tagger and WordNet.
</bodyText>
<footnote confidence="0.994272833333333">
7WordNet (˜30MB) is a smaller footprint than the 5GB of
external resources used by MANLI.
8per request of reviewers. Note that WordNet is less pre-
cise without a POS tagger. When we removed the POS tag-
ger, we enumerated all POS tags for a word to find its hyper-
nym/synonym/... synsets.
</footnote>
<page confidence="0.994088">
705
</page>
<subsectionHeader confidence="0.906046">
4.7 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999873">
There were three primary categories of error:9
</bodyText>
<listItem confidence="0.998454666666667">
1. Token-based paraphrases that are not covered
by WordNet, such as program and software,
business and venture. This calls for broader-
coverage paraphrase resources.
2. Words that are semantically related but not
exactly paraphrases, such as married and
wife, beat and victory. This calls for re-
sources of close distributional similarity.
3. Phrases of the above kinds, such as elected
</listItem>
<bodyText confidence="0.9663596">
and won a seat, politician and presidential
candidate. This calls for further work on
phrase-based alignment.10
There is a trade-off using WordNet vs. larger,
noisier resources in exchange of higher preci-
sion vs. recall and memory/disk allocation. We
think this is an application-specific decision; other
resources could be easily incorporated into our
model, which we may explore in the future to ex-
plore the trade-off in addressing items 1 and 2.
</bodyText>
<sectionHeader confidence="0.998835" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999997428571429">
We presented a model for monolingual sentence
alignment that gives state-of-the-art performance,
and is significantly faster than prior work. We re-
lease our implementation as the first open-source
monolingual aligner, which we hope to be of ben-
efit to other researchers in the rapidly expanding
area of natural language inference.
</bodyText>
<sectionHeader confidence="0.96566" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.99995475">
We thank Vulcan Inc. for funding this work. We
also thank Jason Smith, Travis Wolfe, Frank Fer-
raro for various discussion, suggestion, comments
and the three anonymous reviewers.
</bodyText>
<sectionHeader confidence="0.990865" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.728911">
Mohit Bansal, Chris Quirk, and Robert Moore. 2011.
Gappy phrasal alignment by agreement. In Proceed-
ings of ACL, Portland, Oregon, June.
</reference>
<footnote confidence="0.910653">
9We submitted a browser in JavaScript
(AlignmentBrowser.html) in the supporting material
that compares the gold alignment and test output; readers are
encouraged to try it out.
10Note that MacCartney et al. (2008) showed that in the
MANLI system setting phrase size to larger than one there
was only a 0.2% gain in Fl, while the complexity became
much larger.
</footnote>
<reference confidence="0.997477200000001">
P. Blunsom and T. Cohn. 2006. Discriminative word
alignment with conditional random fields. In Pro-
ceedings of ACL2006, pages 65–72.
Chris Brockett. 2007. Aligning the RTE 2006 corpus.
Technical report, Microsoft Research.
N. Chambers, D. Cer, T. Grenager, D. Hall, C. Kid-
don, B. MacCartney, M.C. de Marneffe, D. Ramage,
E. Yeh, and C.D. Manning. 2007. Learning align-
ments and leveraging natural logic. In Proceedings
of the ACL-PASCAL Workshop on Textual Entail-
ment and Paraphrasing, pages 165–170.
Trevor Cohn, Chris Callison-Burch, and Mirella Lap-
ata. 2008. Constructing corpora for the develop-
ment and evaluation of paraphrase systems. Com-
put. Linguist., 34(4):597–614, December.
Marie-Catherine De Marneffe and Christopher D Man-
ning. 2008. The stanford typed dependencies rep-
resentation. In Coling 2008: Proceedings of the
workshop on Cross-Framework and Cross-Domain
Parser Evaluation, pages 1–8.
John DeNero and Dan Klein. 2007. Tailoring word
alignments to syntactic machine translation. In Pro-
ceedings of ACL2007.
C. Fellbaum. 1998. WordNet: An Electronical Lexical
Database.
Kevin Gimpel and Noah A. Smith. 2010. Softmax-
margin crfs: training log-linear models with cost
functions. In NAACL 2010, pages 733–736.
Michael Heilman and Noah A. Smith. 2010. Tree edit
models for recognizing textual entailments, para-
phrases, and answers to questions. In Proceedings of
NAACL 2010, pages 1011–1019, Los Angeles, Cali-
fornia, June.
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press, New York, NY, USA.
Milen Kouylekov and Bernardo Magnini. 2005. Rec-
ognizing textual entailment with tree edit distance
algorithms. In PASCAL Challenges on RTE, pages
17–20.
John D. Lafferty, Andrew McCallum, and Fernando
C. N. Pereira. 2001. Conditional random fields:
Probabilistic models for segmenting and labeling se-
quence data. In Proceedings of the Eighteenth Inter-
national Conference on Machine Learning, ICML
’01, pages 282–289, San Francisco, CA, USA.
B. MacCartney, M. Galley, and C.D. Manning. 2008.
A phrase-based alignment model for natural lan-
guage inference. In Proceedings of EMNLP2008,
pages 802–811.
Andrew McCallum, Kedar Bellare, and Fernando
Pereira. 2005. A Conditional Random Field
for Discriminatively-trained Finite-state String Edit
Distance. In Proceedings of the 21st Conference
on Uncertainty in Artificial Intelligence (UAI 2005),
July.
</reference>
<page confidence="0.982615">
706
</page>
<reference confidence="0.999505567567567">
Kathleen McKeown, Sara Rosenthal, Kapil Thadani,
and Coleman Moore. 2010. Time-efficient creation
of an accurate sentence fusion corpus. In ACL2010
short, pages 317–320.
Y. Mehdad. 2009. Automatic cost estimation for tree
edit distance using particle swarm optimization. In
Proceedings of the ACL-IJCNLP 2009 Conference
Short Papers, pages 289–292.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational linguistics, 29(1):19–51.
Vasin Punyakanok, Dan Roth, and Wen T. Yih. 2004.
Mapping Dependencies Trees: An Application to
Question Answerin. In Proceedings of the 8th In-
ternational Symposium on Artificial Intelligence and
Mathematics, Fort Lauderdale, Florida.
Michael Roth and Anette Frank. 2012. Aligning pred-
icates across monolingual comparable texts using
graph-based clustering. In Proceedings of the 2012
Joint Conference on Empirical Methods in Natu-
ral Language Processing and Computational Natu-
ral Language Learning, pages 171–182, Jeju Island,
Korea, July.
Kapil Thadani and Kathleen McKeown. 2011. Opti-
mal and syntactically-informed decoding for mono-
lingual phrase-based alignment. In Proceedings of
ACL short.
Mengqiu Wang and Christopher D. Manning. 2010.
Probabilistic tree-edit models with structured latent
variables for textual entailment and question an-
swering. In Proceedings of the 23rd International
Conference on Computational Linguistics, COLING
’10, pages 1164–1172, Stroudsburg, PA, USA.
K. Zhang and D. Shasha. 1989. Simple fast algorithms
for the editing distance between trees and related
problems. SIAM J. Comput., 18(6):1245–1262, De-
cember.
</reference>
<page confidence="0.997411">
707
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.692299">
<title confidence="0.999133">A Lightweight and High Performance Monolingual Word Aligner</title>
<author confidence="0.8697295">Yao Van_Johns Hopkins</author>
<address confidence="0.957214">Baltimore, MD, USA</address>
<affiliation confidence="0.999115">University of Pennsylvania</affiliation>
<address confidence="0.999847">Philadelphia, PA, USA</address>
<abstract confidence="0.9993068">Fast alignment is essential for many natural language tasks. But in the setting of monolingual alignment, previous work has not been able to align more than one sentence pair per second. We describe a discriminatively trained monolingual word aligner that uses a Conditional Random Field to globally decode the best alignment with features drawn from source and target sentences. Using just part-of-speech tags and WordNet as external resources, our aligner gives state-of-the-art result, while being an order-of-magnitude faster than the previous best performing system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mohit Bansal</author>
<author>Chris Quirk</author>
<author>Robert Moore</author>
</authors>
<title>Gappy phrasal alignment by agreement.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Portland, Oregon,</location>
<contexts>
<context position="4380" citStr="Bansal et al., 2011" startWordPosition="661" endWordPosition="664">t Annual Meeting of the Association for Computational Linguistics, pages 702–707, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics yields the lowest tree edit distance. Other tree or graph matching work for alignment includes that of (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Chambers et al., 2007; Mehdad, 2009; Roth and Frank, 2012). Finally, feature and model design in monolingual alignment is often inspired by bilingual work, including distortion modeling, phrasal alignment, syntactic constraints, etc (Och and Ney, 2003; DeNero and Klein, 2007; Bansal et al., 2011). 3 The Alignment Model 3.1 Model Design Our work is heavily influenced by the bilingual alignment literature, especially the discriminative model proposed by Blunsom and Cohn (2006). Given a source sentence s of length M, and a target sentence t of length N, the alignment from s to t is a sequence of target word indices a, where amE[1,M] ∈ [0, N]. We specify that when am = 0, source word st is aligned to a NULL state, i.e., deleted. This models a many-to-one alignment from source to target. Multiple source words can be aligned to the same target word, but not vice versa. One-to-many alignment</context>
</contexts>
<marker>Bansal, Quirk, Moore, 2011</marker>
<rawString>Mohit Bansal, Chris Quirk, and Robert Moore. 2011. Gappy phrasal alignment by agreement. In Proceedings of ACL, Portland, Oregon, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Blunsom</author>
<author>T Cohn</author>
</authors>
<title>Discriminative word alignment with conditional random fields.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL2006,</booktitle>
<pages>65--72</pages>
<contexts>
<context position="4562" citStr="Blunsom and Cohn (2006)" startWordPosition="688" endWordPosition="691">est tree edit distance. Other tree or graph matching work for alignment includes that of (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Chambers et al., 2007; Mehdad, 2009; Roth and Frank, 2012). Finally, feature and model design in monolingual alignment is often inspired by bilingual work, including distortion modeling, phrasal alignment, syntactic constraints, etc (Och and Ney, 2003; DeNero and Klein, 2007; Bansal et al., 2011). 3 The Alignment Model 3.1 Model Design Our work is heavily influenced by the bilingual alignment literature, especially the discriminative model proposed by Blunsom and Cohn (2006). Given a source sentence s of length M, and a target sentence t of length N, the alignment from s to t is a sequence of target word indices a, where amE[1,M] ∈ [0, N]. We specify that when am = 0, source word st is aligned to a NULL state, i.e., deleted. This models a many-to-one alignment from source to target. Multiple source words can be aligned to the same target word, but not vice versa. One-to-many alignment can be obtained by running the aligner in the other direction. The probability of alignment sequence a conditioned on both s and t is then: exp(Em,k Akfk(am−1, am, s, t)) Z(s, t) Th</context>
<context position="9244" citStr="Blunsom and Cohn, 2006" startWordPosition="1476" endWordPosition="1479">r. This helps especially when aligning functional words, which usually have multiple candidate target functional words to align to and string similarity features cannot help. We also added features for neighboring POS tags matching. 3.3 Symmetrization To expand from many-to-one alignment to manyto-many, we ran the model in both directions and applied the following symmetrization heuristics (Koehn, 2010): INTERSECTION, UNION, GROWDIAG-FINAL. 4 Experiments 4.1 Setup Since no generic off-the-shelf CRF software is designed to handle the special case of dynamic state indices and feature functions (Blunsom and Cohn, 2006), we implemented this aligner model in the Scala programming language, which is fully interoperable with Java. We used the L2 regularizer and LBFGS for optimization. OpenNLP4 provided the POS tagger and JWNL5 interfaced with WordNet (Fellbaum, 1998). To make results directly comparable, we closely followed the setup of MacCartney et al. (2008) and Thadani and McKeown (2011). Training and test data (Brockett, 2007) each contains 800 manually aligned premise and hypothesis pairs from RTE2. Note that the premises contain 29 words on average, and the hypotheses only 11 words. We take the premise a</context>
</contexts>
<marker>Blunsom, Cohn, 2006</marker>
<rawString>P. Blunsom and T. Cohn. 2006. Discriminative word alignment with conditional random fields. In Proceedings of ACL2006, pages 65–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Brockett</author>
</authors>
<title>Aligning the RTE</title>
<date>2007</date>
<tech>Technical report, Microsoft Research.</tech>
<contexts>
<context position="2728" citStr="Brockett, 2007" startWordPosition="418" endWordPosition="419">al resources and took 2 seconds per alignment, making it hard to be deployed and run in large scale. On the other extreme, a simple non-probabilistic Tree Edit Distance (TED) model (c.f. §4.2) is able to align 10, 000 pairs per second when the sentences are pre-parsed, but with significantly reduced performance. Trying to embrace the merits of both worlds, we introduce a discriminative aligner that is able to align tens to hundreds of sentence pairs per second, and needs access only to a POS tagger and WordNet. This aligner gives state-of-the-art performance on the MSR RTE2 alignment dataset (Brockett, 2007), is faster than previous work, and we release it publicly as the first open-source monolingual word aligner: Jacana.Align.1 2 Related Work The MANLI aligner (MacCartney et al., 2008) was first proposed to align premise and hypothesis sentences for the task of natural language inference. It applies perceptron learning and handles phrase-based alignment of arbitrary phrase lengths. Thadani and McKeown (2011) optimized this model by decoding via Integer Linear Programming (ILP). Benefiting from modern ILP solvers, this led to an order-of-magnitude speedup. With extra syntactic constraints added,</context>
<context position="9661" citStr="Brockett, 2007" startWordPosition="1544" endWordPosition="1545">ON, GROWDIAG-FINAL. 4 Experiments 4.1 Setup Since no generic off-the-shelf CRF software is designed to handle the special case of dynamic state indices and feature functions (Blunsom and Cohn, 2006), we implemented this aligner model in the Scala programming language, which is fully interoperable with Java. We used the L2 regularizer and LBFGS for optimization. OpenNLP4 provided the POS tagger and JWNL5 interfaced with WordNet (Fellbaum, 1998). To make results directly comparable, we closely followed the setup of MacCartney et al. (2008) and Thadani and McKeown (2011). Training and test data (Brockett, 2007) each contains 800 manually aligned premise and hypothesis pairs from RTE2. Note that the premises contain 29 words on average, and the hypotheses only 11 words. We take the premise as the source and hypothesis as the target, and use S2T to indicate the model aligns from 3We found that each word has to be POS tagged to get an accurate relation, otherwise this feature will not help. 4http://opennlp.apache.org/ 5http://jwordnet.sf.net/ source to target and T2S from target to source. 4.2 Simple Baselines We additionally used two baseline systems for comparison. One was GIZA++, with the INTERSECTI</context>
</contexts>
<marker>Brockett, 2007</marker>
<rawString>Chris Brockett. 2007. Aligning the RTE 2006 corpus. Technical report, Microsoft Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chambers</author>
<author>D Cer</author>
<author>T Grenager</author>
<author>D Hall</author>
<author>C Kiddon</author>
<author>B MacCartney</author>
<author>M C de Marneffe</author>
<author>D Ramage</author>
<author>E Yeh</author>
<author>C D Manning</author>
</authors>
<title>Learning alignments and leveraging natural logic.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing,</booktitle>
<pages>165--170</pages>
<marker>Chambers, Cer, Grenager, Hall, Kiddon, MacCartney, de Marneffe, Ramage, Yeh, Manning, 2007</marker>
<rawString>N. Chambers, D. Cer, T. Grenager, D. Hall, C. Kiddon, B. MacCartney, M.C. de Marneffe, D. Ramage, E. Yeh, and C.D. Manning. 2007. Learning alignments and leveraging natural logic. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, pages 165–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Chris Callison-Burch</author>
<author>Mirella Lapata</author>
</authors>
<title>Constructing corpora for the development and evaluation of paraphrase systems.</title>
<date>2008</date>
<journal>Comput. Linguist.,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="14584" citStr="Cohn et al., 2008" startWordPosition="2351" endWordPosition="2354">ratic growth in the number of edits with sentence length. MANLI-exact is in second place, relying on the ILP solver. This work has a precise O(MN2) decoding time, with M the source sentence length and N the target sentence length. 6Unfortunately both MacCartney and Thadani no longer have their original output files (personal communication), so we cannot run a significance test against their result. corpus sent. pair MANLI- MANLI- this length approx. exact work RTE2 29/11 1.67 0.08 0.025 FUSION 27/27 61.96 2.45 0.096 Table 2: Alignment runtime in seconds per sentence pair on two corpora: RTE2 (Cohn et al., 2008) and FUSION (McKeown et al., 2010). The MANLI-* results are from Thadani and McKeown (2011), on a Xeon 2.0GHz with 6MB Cache. The runtime for this work takes the longest timing from S2T and T2S, on a Xeon 2.2GHz with 4MB cache (the closest we can find to match their hardware). Horizontally in a realworld application where sentences have similar length, this work is roughly 20x faster (0.096 vs. 2.45). Vertically, the decoding time for our work increases less dramatically when sentence length increases (0.025-+0.096 vs. 0.08-+2.45). features P % R % F1 % E % full (T2S) 93.7 84.0 88.6 35.3 - POS</context>
</contexts>
<marker>Cohn, Callison-Burch, Lapata, 2008</marker>
<rawString>Trevor Cohn, Chris Callison-Burch, and Mirella Lapata. 2008. Constructing corpora for the development and evaluation of paraphrase systems. Comput. Linguist., 34(4):597–614, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine De Marneffe</author>
<author>Christopher D Manning</author>
</authors>
<title>The stanford typed dependencies representation.</title>
<date>2008</date>
<booktitle>In Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation,</booktitle>
<pages>1--8</pages>
<marker>De Marneffe, Manning, 2008</marker>
<rawString>Marie-Catherine De Marneffe and Christopher D Manning. 2008. The stanford typed dependencies representation. In Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Tailoring word alignments to syntactic machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL2007.</booktitle>
<contexts>
<context position="4358" citStr="DeNero and Klein, 2007" startWordPosition="657" endWordPosition="660">2 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 702–707, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics yields the lowest tree edit distance. Other tree or graph matching work for alignment includes that of (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Chambers et al., 2007; Mehdad, 2009; Roth and Frank, 2012). Finally, feature and model design in monolingual alignment is often inspired by bilingual work, including distortion modeling, phrasal alignment, syntactic constraints, etc (Och and Ney, 2003; DeNero and Klein, 2007; Bansal et al., 2011). 3 The Alignment Model 3.1 Model Design Our work is heavily influenced by the bilingual alignment literature, especially the discriminative model proposed by Blunsom and Cohn (2006). Given a source sentence s of length M, and a target sentence t of length N, the alignment from s to t is a sequence of target word indices a, where amE[1,M] ∈ [0, N]. We specify that when am = 0, source word st is aligned to a NULL state, i.e., deleted. This models a many-to-one alignment from source to target. Multiple source words can be aligned to the same target word, but not vice versa.</context>
</contexts>
<marker>DeNero, Klein, 2007</marker>
<rawString>John DeNero and Dan Klein. 2007. Tailoring word alignments to syntactic machine translation. In Proceedings of ACL2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An Electronical Lexical Database.</title>
<date>1998</date>
<contexts>
<context position="9493" citStr="Fellbaum, 1998" startWordPosition="1518" endWordPosition="1519">pand from many-to-one alignment to manyto-many, we ran the model in both directions and applied the following symmetrization heuristics (Koehn, 2010): INTERSECTION, UNION, GROWDIAG-FINAL. 4 Experiments 4.1 Setup Since no generic off-the-shelf CRF software is designed to handle the special case of dynamic state indices and feature functions (Blunsom and Cohn, 2006), we implemented this aligner model in the Scala programming language, which is fully interoperable with Java. We used the L2 regularizer and LBFGS for optimization. OpenNLP4 provided the POS tagger and JWNL5 interfaced with WordNet (Fellbaum, 1998). To make results directly comparable, we closely followed the setup of MacCartney et al. (2008) and Thadani and McKeown (2011). Training and test data (Brockett, 2007) each contains 800 manually aligned premise and hypothesis pairs from RTE2. Note that the premises contain 29 words on average, and the hypotheses only 11 words. We take the premise as the source and hypothesis as the target, and use S2T to indicate the model aligns from 3We found that each word has to be POS tagged to get an accurate relation, otherwise this feature will not help. 4http://opennlp.apache.org/ 5http://jwordnet.sf</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet: An Electronical Lexical Database.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Noah A Smith</author>
</authors>
<title>Softmaxmargin crfs: training log-linear models with cost functions.</title>
<date>2010</date>
<booktitle>In NAACL 2010,</booktitle>
<pages>733--736</pages>
<contexts>
<context position="5376" citStr="Gimpel and Smith, 2010" startWordPosition="833" endWordPosition="836">m = 0, source word st is aligned to a NULL state, i.e., deleted. This models a many-to-one alignment from source to target. Multiple source words can be aligned to the same target word, but not vice versa. One-to-many alignment can be obtained by running the aligner in the other direction. The probability of alignment sequence a conditioned on both s and t is then: exp(Em,k Akfk(am−1, am, s, t)) Z(s, t) This assumes a first-order Conditional Random Field (Lafferty et al., 2001). The word alignment task is evaluated over F1. Instead of directly optimizing F1, we employ softmax-margin training (Gimpel and Smith, 2010) and add a cost function to the normalizing function Z(s, t) in the denominator, which becomes: � �exp( Akfk(ˆam−1, ˆam, s, t) + cost(at, ˆa)) aˆ m,k where at is the true alignments. cost(at, ˆa) can be viewed as special “features” with uniform weights that encourage consistent with true alignments. It is only computed during training in the denominator because cost(at, at) = 0 in the numerator. Hamming cost is used in practice. One distinction of this alignment model compared to other commonly defined CRFs is that the input is two dimensional: at each position m, the model inspects both the e</context>
</contexts>
<marker>Gimpel, Smith, 2010</marker>
<rawString>Kevin Gimpel and Noah A. Smith. 2010. Softmaxmargin crfs: training log-linear models with cost functions. In NAACL 2010, pages 733–736.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Heilman</author>
<author>Noah A Smith</author>
</authors>
<title>Tree edit models for recognizing textual entailments, paraphrases, and answers to questions.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL 2010,</booktitle>
<pages>1011--1019</pages>
<location>Los Angeles, California,</location>
<contexts>
<context position="3648" citStr="Heilman and Smith (2010)" startWordPosition="556" endWordPosition="559">ies perceptron learning and handles phrase-based alignment of arbitrary phrase lengths. Thadani and McKeown (2011) optimized this model by decoding via Integer Linear Programming (ILP). Benefiting from modern ILP solvers, this led to an order-of-magnitude speedup. With extra syntactic constraints added, the exact alignment match rate for whole sentence pairs was also significantly improved. Besides the above supervised methods, indirect supervision has also been explored. Among them, Wang and Manning (2010) extended the work of McCallum et al. (2005) and modeled alignment as latent variables. Heilman and Smith (2010) used tree kernels to search for the alignment that 1http://code.google.com/p/jacana/ 702 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 702–707, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics yields the lowest tree edit distance. Other tree or graph matching work for alignment includes that of (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Chambers et al., 2007; Mehdad, 2009; Roth and Frank, 2012). Finally, feature and model design in monolingual alignment is often inspired by bilingual work, including</context>
<context position="10524" citStr="Heilman and Smith, 2010" startWordPosition="1683" endWordPosition="1686">o indicate the model aligns from 3We found that each word has to be POS tagged to get an accurate relation, otherwise this feature will not help. 4http://opennlp.apache.org/ 5http://jwordnet.sf.net/ source to target and T2S from target to source. 4.2 Simple Baselines We additionally used two baseline systems for comparison. One was GIZA++, with the INTERSECTION tricks post-applied, which worked the best among all other symmetrization heuristics. The other was a Tree Edit Distance (TED) model, popularly used in a series of NLP applications (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Heilman and Smith, 2010). We used uniform cost for deletion, insertion and substitutions, and applied a dynamic program algorithm (Zhang and Shasha, 1989) to decode the tree edit sequence with the minimal cost, based on the Stanford dependency tree (De Marneffe and Manning, 2008). This non-probabilistic approach turned out to be extremely fast, processing about 10,000 sentence pairs per second with preparsed trees, performing quantitatively better than the Stanford RTE aligner (Chambers et al., 2007). 4.3 MANLI Baselines MANLI was first developed by MacCartney et al. (2008), and then improved by Thadani and McKeown (</context>
</contexts>
<marker>Heilman, Smith, 2010</marker>
<rawString>Michael Heilman and Noah A. Smith. 2010. Tree edit models for recognizing textual entailments, paraphrases, and answers to questions. In Proceedings of NAACL 2010, pages 1011–1019, Los Angeles, California, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical Machine Translation.</title>
<date>2010</date>
<publisher>Cambridge University Press,</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="9027" citStr="Koehn, 2010" startWordPosition="1445" endWordPosition="1446">revious and current words are deleted (a transition from NULL to NULL). Contextual Features indicate whether the left or the right neighbor of the source word and aligned target word are identical or similar. This helps especially when aligning functional words, which usually have multiple candidate target functional words to align to and string similarity features cannot help. We also added features for neighboring POS tags matching. 3.3 Symmetrization To expand from many-to-one alignment to manyto-many, we ran the model in both directions and applied the following symmetrization heuristics (Koehn, 2010): INTERSECTION, UNION, GROWDIAG-FINAL. 4 Experiments 4.1 Setup Since no generic off-the-shelf CRF software is designed to handle the special case of dynamic state indices and feature functions (Blunsom and Cohn, 2006), we implemented this aligner model in the Scala programming language, which is fully interoperable with Java. We used the L2 regularizer and LBFGS for optimization. OpenNLP4 provided the POS tagger and JWNL5 interfaced with WordNet (Fellbaum, 1998). To make results directly comparable, we closely followed the setup of MacCartney et al. (2008) and Thadani and McKeown (2011). Train</context>
</contexts>
<marker>Koehn, 2010</marker>
<rawString>Philipp Koehn. 2010. Statistical Machine Translation. Cambridge University Press, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Milen Kouylekov</author>
<author>Bernardo Magnini</author>
</authors>
<title>Recognizing textual entailment with tree edit distance algorithms.</title>
<date>2005</date>
<booktitle>In PASCAL Challenges on RTE,</booktitle>
<pages>17--20</pages>
<contexts>
<context position="4081" citStr="Kouylekov and Magnini, 2005" startWordPosition="616" endWordPosition="619">, indirect supervision has also been explored. Among them, Wang and Manning (2010) extended the work of McCallum et al. (2005) and modeled alignment as latent variables. Heilman and Smith (2010) used tree kernels to search for the alignment that 1http://code.google.com/p/jacana/ 702 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 702–707, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics yields the lowest tree edit distance. Other tree or graph matching work for alignment includes that of (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Chambers et al., 2007; Mehdad, 2009; Roth and Frank, 2012). Finally, feature and model design in monolingual alignment is often inspired by bilingual work, including distortion modeling, phrasal alignment, syntactic constraints, etc (Och and Ney, 2003; DeNero and Klein, 2007; Bansal et al., 2011). 3 The Alignment Model 3.1 Model Design Our work is heavily influenced by the bilingual alignment literature, especially the discriminative model proposed by Blunsom and Cohn (2006). Given a source sentence s of length M, and a target sentence t of length N, the alignment from s to t is a sequence o</context>
<context position="10498" citStr="Kouylekov and Magnini, 2005" startWordPosition="1679" endWordPosition="1682"> as the target, and use S2T to indicate the model aligns from 3We found that each word has to be POS tagged to get an accurate relation, otherwise this feature will not help. 4http://opennlp.apache.org/ 5http://jwordnet.sf.net/ source to target and T2S from target to source. 4.2 Simple Baselines We additionally used two baseline systems for comparison. One was GIZA++, with the INTERSECTION tricks post-applied, which worked the best among all other symmetrization heuristics. The other was a Tree Edit Distance (TED) model, popularly used in a series of NLP applications (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Heilman and Smith, 2010). We used uniform cost for deletion, insertion and substitutions, and applied a dynamic program algorithm (Zhang and Shasha, 1989) to decode the tree edit sequence with the minimal cost, based on the Stanford dependency tree (De Marneffe and Manning, 2008). This non-probabilistic approach turned out to be extremely fast, processing about 10,000 sentence pairs per second with preparsed trees, performing quantitatively better than the Stanford RTE aligner (Chambers et al., 2007). 4.3 MANLI Baselines MANLI was first developed by MacCartney et al. (2008), and then improve</context>
</contexts>
<marker>Kouylekov, Magnini, 2005</marker>
<rawString>Milen Kouylekov and Bernardo Magnini. 2005. Recognizing textual entailment with tree edit distance algorithms. In PASCAL Challenges on RTE, pages 17–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning, ICML ’01,</booktitle>
<pages>282--289</pages>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="5235" citStr="Lafferty et al., 2001" startWordPosition="811" endWordPosition="814">et sentence t of length N, the alignment from s to t is a sequence of target word indices a, where amE[1,M] ∈ [0, N]. We specify that when am = 0, source word st is aligned to a NULL state, i.e., deleted. This models a many-to-one alignment from source to target. Multiple source words can be aligned to the same target word, but not vice versa. One-to-many alignment can be obtained by running the aligner in the other direction. The probability of alignment sequence a conditioned on both s and t is then: exp(Em,k Akfk(am−1, am, s, t)) Z(s, t) This assumes a first-order Conditional Random Field (Lafferty et al., 2001). The word alignment task is evaluated over F1. Instead of directly optimizing F1, we employ softmax-margin training (Gimpel and Smith, 2010) and add a cost function to the normalizing function Z(s, t) in the denominator, which becomes: � �exp( Akfk(ˆam−1, ˆam, s, t) + cost(at, ˆa)) aˆ m,k where at is the true alignments. cost(at, ˆa) can be viewed as special “features” with uniform weights that encourage consistent with true alignments. It is only computed during training in the denominator because cost(at, at) = 0 in the numerator. Hamming cost is used in practice. One distinction of this al</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning, ICML ’01, pages 282–289, San Francisco, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B MacCartney</author>
<author>M Galley</author>
<author>C D Manning</author>
</authors>
<title>A phrase-based alignment model for natural language inference.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP2008,</booktitle>
<pages>802--811</pages>
<contexts>
<context position="2086" citStr="MacCartney et al., 2008" startWordPosition="309" endWordPosition="312">mmar. These distinctions suggest a model design that utilizes arbitrary features (to make use of word similarity measure and lexical resources) and exploits deeper sentence structures (especially in the case of major languages where robust parsers are available). In this setting the balance between precision and speed becomes an issue: while we might leverage an extensive NLP pipeline for a ∗Performed while faculty at Johns Hopkins University. Peter Clark Vulcan Inc. Seattle, WA, USA language like English, such pipelines can be computationally expensive. One earlier attempt, the MANLI system (MacCartney et al., 2008), used roughly 5GB of lexical resources and took 2 seconds per alignment, making it hard to be deployed and run in large scale. On the other extreme, a simple non-probabilistic Tree Edit Distance (TED) model (c.f. §4.2) is able to align 10, 000 pairs per second when the sentences are pre-parsed, but with significantly reduced performance. Trying to embrace the merits of both worlds, we introduce a discriminative aligner that is able to align tens to hundreds of sentence pairs per second, and needs access only to a POS tagger and WordNet. This aligner gives state-of-the-art performance on the M</context>
<context position="9589" citStr="MacCartney et al. (2008)" startWordPosition="1531" endWordPosition="1534"> applied the following symmetrization heuristics (Koehn, 2010): INTERSECTION, UNION, GROWDIAG-FINAL. 4 Experiments 4.1 Setup Since no generic off-the-shelf CRF software is designed to handle the special case of dynamic state indices and feature functions (Blunsom and Cohn, 2006), we implemented this aligner model in the Scala programming language, which is fully interoperable with Java. We used the L2 regularizer and LBFGS for optimization. OpenNLP4 provided the POS tagger and JWNL5 interfaced with WordNet (Fellbaum, 1998). To make results directly comparable, we closely followed the setup of MacCartney et al. (2008) and Thadani and McKeown (2011). Training and test data (Brockett, 2007) each contains 800 manually aligned premise and hypothesis pairs from RTE2. Note that the premises contain 29 words on average, and the hypotheses only 11 words. We take the premise as the source and hypothesis as the target, and use S2T to indicate the model aligns from 3We found that each word has to be POS tagged to get an accurate relation, otherwise this feature will not help. 4http://opennlp.apache.org/ 5http://jwordnet.sf.net/ source to target and T2S from target to source. 4.2 Simple Baselines We additionally used </context>
<context position="11080" citStr="MacCartney et al. (2008)" startWordPosition="1770" endWordPosition="1773"> et al., 2004; Kouylekov and Magnini, 2005; Heilman and Smith, 2010). We used uniform cost for deletion, insertion and substitutions, and applied a dynamic program algorithm (Zhang and Shasha, 1989) to decode the tree edit sequence with the minimal cost, based on the Stanford dependency tree (De Marneffe and Manning, 2008). This non-probabilistic approach turned out to be extremely fast, processing about 10,000 sentence pairs per second with preparsed trees, performing quantitatively better than the Stanford RTE aligner (Chambers et al., 2007). 4.3 MANLI Baselines MANLI was first developed by MacCartney et al. (2008), and then improved by Thadani and McKeown (2011) with faster and exact decoding via ILP. There are four versions to be compared here: MANLI the original version. MANLI-approx. re-implemented version by Thadani and McKeown (2011). MANLI-exact decoding via ILP solvers. MANLI-constraint MANLI-exact with hard syntactic constraints, mainly on common “light” words (determiners, prepositions, etc.) attachment to boost exact match rate. 4.4 Results Following Thadani and McKeown (2011), performance is evaluated by macro-averaged precision, recall, F1 of aligned token pairs, and exact (perfect) match r</context>
<context position="12721" citStr="MacCartney et al. (2008)" startWordPosition="2043" endWordPosition="2046">h INTERSECTION, UNION and GROW-DIAG-FINAL. Our system beats 704 System P % R % F1 % E % GIZA++, n 82.5 74.4 78.3 14.0 TED 80.6 79.0 79.8 13.5 Stanford RTE* 82.7 75.8 79.1 - MANLI* 85.4 85.3 85.3 21.3 MANLI-approx.a 87.2 86.3 86.7 24.5 MANLI-exacta 87.2 86.1 86.8 24.8 MANLI-constraints 89.5 86.2 87.8 33.0 this work, S2T 91.8 83.4 87.4 25.9 this work, T2S 93.7 84.0 88.6 35.3 S2T n T2S 95.4 80.8 87.5 31.3 S2T U T2S 90.3 86.6 88.4 29.6 GROW-DIAG-FINAL 94.4 81.8 87.6 30.8 Table 1: Results on the 800 pairs of test data. E% stands for exact (perfect) match rate. Systems marked with * are reported by MacCartney et al. (2008), with a by Thadani and McKeown (2011). the weak and strong baselines6 in all measures except recall. Some patterns are very clearly shown: Higher precision, lower recall is due to the higher-quality and lower-coverage of WordNet, where the MANLI-family systems used additional, automatically derived lexical resources. Imbalance of exact match rate between S2T and T2S with a difference of 9.4% is due to the manyto-one nature of the aligner. When aligning from source (longer) to target (shorter), multiple source words can align to the same target word. This is not desirable since multiple duplic</context>
</contexts>
<marker>MacCartney, Galley, Manning, 2008</marker>
<rawString>B. MacCartney, M. Galley, and C.D. Manning. 2008. A phrase-based alignment model for natural language inference. In Proceedings of EMNLP2008, pages 802–811.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Kedar Bellare</author>
<author>Fernando Pereira</author>
</authors>
<title>A Conditional Random Field for Discriminatively-trained Finite-state String Edit Distance.</title>
<date>2005</date>
<booktitle>In Proceedings of the 21st Conference on Uncertainty in Artificial Intelligence (UAI</booktitle>
<contexts>
<context position="3580" citStr="McCallum et al. (2005)" startWordPosition="546" endWordPosition="549">esis sentences for the task of natural language inference. It applies perceptron learning and handles phrase-based alignment of arbitrary phrase lengths. Thadani and McKeown (2011) optimized this model by decoding via Integer Linear Programming (ILP). Benefiting from modern ILP solvers, this led to an order-of-magnitude speedup. With extra syntactic constraints added, the exact alignment match rate for whole sentence pairs was also significantly improved. Besides the above supervised methods, indirect supervision has also been explored. Among them, Wang and Manning (2010) extended the work of McCallum et al. (2005) and modeled alignment as latent variables. Heilman and Smith (2010) used tree kernels to search for the alignment that 1http://code.google.com/p/jacana/ 702 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 702–707, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics yields the lowest tree edit distance. Other tree or graph matching work for alignment includes that of (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Chambers et al., 2007; Mehdad, 2009; Roth and Frank, 2012). Finally, feature and model design in </context>
</contexts>
<marker>McCallum, Bellare, Pereira, 2005</marker>
<rawString>Andrew McCallum, Kedar Bellare, and Fernando Pereira. 2005. A Conditional Random Field for Discriminatively-trained Finite-state String Edit Distance. In Proceedings of the 21st Conference on Uncertainty in Artificial Intelligence (UAI 2005), July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen McKeown</author>
<author>Sara Rosenthal</author>
<author>Kapil Thadani</author>
<author>Coleman Moore</author>
</authors>
<title>Time-efficient creation of an accurate sentence fusion corpus.</title>
<date>2010</date>
<booktitle>In ACL2010 short,</booktitle>
<pages>317--320</pages>
<contexts>
<context position="13881" citStr="McKeown et al., 2010" startWordPosition="2233" endWordPosition="2236">same target word. This is not desirable since multiple duplicate “light” words are aligned to the same “light” word in the target, which breaks perfect match. When aligning T2S, this problem goes away: the shorter target sentence contains less duplicate words, and in most cases there is an one-to-one mapping. MT heuristics help, with INTERSECTION and UNION respectively improving precision and recall. 4.5 Runtime Test Table 2 shows the runtime comparison. Since the RTE2 corpus is imbalanced, with premise length (words) of 29 and hypothesis length of 11, we also compare on the corpus of FUSION (McKeown et al., 2010), with both sentences in a pair averaging 27. MANLI-approx. is the slowest, with quadratic growth in the number of edits with sentence length. MANLI-exact is in second place, relying on the ILP solver. This work has a precise O(MN2) decoding time, with M the source sentence length and N the target sentence length. 6Unfortunately both MacCartney and Thadani no longer have their original output files (personal communication), so we cannot run a significance test against their result. corpus sent. pair MANLI- MANLI- this length approx. exact work RTE2 29/11 1.67 0.08 0.025 FUSION 27/27 61.96 2.45</context>
</contexts>
<marker>McKeown, Rosenthal, Thadani, Moore, 2010</marker>
<rawString>Kathleen McKeown, Sara Rosenthal, Kapil Thadani, and Coleman Moore. 2010. Time-efficient creation of an accurate sentence fusion corpus. In ACL2010 short, pages 317–320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Mehdad</author>
</authors>
<title>Automatic cost estimation for tree edit distance using particle swarm optimization.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers,</booktitle>
<pages>289--292</pages>
<contexts>
<context position="4118" citStr="Mehdad, 2009" startWordPosition="624" endWordPosition="625"> them, Wang and Manning (2010) extended the work of McCallum et al. (2005) and modeled alignment as latent variables. Heilman and Smith (2010) used tree kernels to search for the alignment that 1http://code.google.com/p/jacana/ 702 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 702–707, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics yields the lowest tree edit distance. Other tree or graph matching work for alignment includes that of (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Chambers et al., 2007; Mehdad, 2009; Roth and Frank, 2012). Finally, feature and model design in monolingual alignment is often inspired by bilingual work, including distortion modeling, phrasal alignment, syntactic constraints, etc (Och and Ney, 2003; DeNero and Klein, 2007; Bansal et al., 2011). 3 The Alignment Model 3.1 Model Design Our work is heavily influenced by the bilingual alignment literature, especially the discriminative model proposed by Blunsom and Cohn (2006). Given a source sentence s of length M, and a target sentence t of length N, the alignment from s to t is a sequence of target word indices a, where amE[1,</context>
</contexts>
<marker>Mehdad, 2009</marker>
<rawString>Y. Mehdad. 2009. Automatic cost estimation for tree edit distance using particle swarm optimization. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 289–292.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational linguistics,</journal>
<pages>29--1</pages>
<contexts>
<context position="4334" citStr="Och and Ney, 2003" startWordPosition="653" endWordPosition="656">le.com/p/jacana/ 702 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 702–707, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics yields the lowest tree edit distance. Other tree or graph matching work for alignment includes that of (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Chambers et al., 2007; Mehdad, 2009; Roth and Frank, 2012). Finally, feature and model design in monolingual alignment is often inspired by bilingual work, including distortion modeling, phrasal alignment, syntactic constraints, etc (Och and Ney, 2003; DeNero and Klein, 2007; Bansal et al., 2011). 3 The Alignment Model 3.1 Model Design Our work is heavily influenced by the bilingual alignment literature, especially the discriminative model proposed by Blunsom and Cohn (2006). Given a source sentence s of length M, and a target sentence t of length N, the alignment from s to t is a sequence of target word indices a, where amE[1,M] ∈ [0, N]. We specify that when am = 0, source word st is aligned to a NULL state, i.e., deleted. This models a many-to-one alignment from source to target. Multiple source words can be aligned to the same target w</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wen T Yih</author>
</authors>
<title>Mapping Dependencies Trees: An Application to Question Answerin.</title>
<date>2004</date>
<booktitle>In Proceedings of the 8th International Symposium on Artificial Intelligence and Mathematics,</booktitle>
<location>Fort Lauderdale, Florida.</location>
<contexts>
<context position="4052" citStr="Punyakanok et al., 2004" startWordPosition="612" endWordPosition="615"> above supervised methods, indirect supervision has also been explored. Among them, Wang and Manning (2010) extended the work of McCallum et al. (2005) and modeled alignment as latent variables. Heilman and Smith (2010) used tree kernels to search for the alignment that 1http://code.google.com/p/jacana/ 702 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 702–707, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics yields the lowest tree edit distance. Other tree or graph matching work for alignment includes that of (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Chambers et al., 2007; Mehdad, 2009; Roth and Frank, 2012). Finally, feature and model design in monolingual alignment is often inspired by bilingual work, including distortion modeling, phrasal alignment, syntactic constraints, etc (Och and Ney, 2003; DeNero and Klein, 2007; Bansal et al., 2011). 3 The Alignment Model 3.1 Model Design Our work is heavily influenced by the bilingual alignment literature, especially the discriminative model proposed by Blunsom and Cohn (2006). Given a source sentence s of length M, and a target sentence t of length N, the alignmen</context>
<context position="10469" citStr="Punyakanok et al., 2004" startWordPosition="1675" endWordPosition="1678">the source and hypothesis as the target, and use S2T to indicate the model aligns from 3We found that each word has to be POS tagged to get an accurate relation, otherwise this feature will not help. 4http://opennlp.apache.org/ 5http://jwordnet.sf.net/ source to target and T2S from target to source. 4.2 Simple Baselines We additionally used two baseline systems for comparison. One was GIZA++, with the INTERSECTION tricks post-applied, which worked the best among all other symmetrization heuristics. The other was a Tree Edit Distance (TED) model, popularly used in a series of NLP applications (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Heilman and Smith, 2010). We used uniform cost for deletion, insertion and substitutions, and applied a dynamic program algorithm (Zhang and Shasha, 1989) to decode the tree edit sequence with the minimal cost, based on the Stanford dependency tree (De Marneffe and Manning, 2008). This non-probabilistic approach turned out to be extremely fast, processing about 10,000 sentence pairs per second with preparsed trees, performing quantitatively better than the Stanford RTE aligner (Chambers et al., 2007). 4.3 MANLI Baselines MANLI was first developed by MacCartney et</context>
</contexts>
<marker>Punyakanok, Roth, Yih, 2004</marker>
<rawString>Vasin Punyakanok, Dan Roth, and Wen T. Yih. 2004. Mapping Dependencies Trees: An Application to Question Answerin. In Proceedings of the 8th International Symposium on Artificial Intelligence and Mathematics, Fort Lauderdale, Florida.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Roth</author>
<author>Anette Frank</author>
</authors>
<title>Aligning predicates across monolingual comparable texts using graph-based clustering.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>171--182</pages>
<location>Jeju Island, Korea,</location>
<contexts>
<context position="4141" citStr="Roth and Frank, 2012" startWordPosition="626" endWordPosition="629">d Manning (2010) extended the work of McCallum et al. (2005) and modeled alignment as latent variables. Heilman and Smith (2010) used tree kernels to search for the alignment that 1http://code.google.com/p/jacana/ 702 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 702–707, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics yields the lowest tree edit distance. Other tree or graph matching work for alignment includes that of (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Chambers et al., 2007; Mehdad, 2009; Roth and Frank, 2012). Finally, feature and model design in monolingual alignment is often inspired by bilingual work, including distortion modeling, phrasal alignment, syntactic constraints, etc (Och and Ney, 2003; DeNero and Klein, 2007; Bansal et al., 2011). 3 The Alignment Model 3.1 Model Design Our work is heavily influenced by the bilingual alignment literature, especially the discriminative model proposed by Blunsom and Cohn (2006). Given a source sentence s of length M, and a target sentence t of length N, the alignment from s to t is a sequence of target word indices a, where amE[1,M] ∈ [0, N]. We specify</context>
</contexts>
<marker>Roth, Frank, 2012</marker>
<rawString>Michael Roth and Anette Frank. 2012. Aligning predicates across monolingual comparable texts using graph-based clustering. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 171–182, Jeju Island, Korea, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kapil Thadani</author>
<author>Kathleen McKeown</author>
</authors>
<title>Optimal and syntactically-informed decoding for monolingual phrase-based alignment.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL short.</booktitle>
<contexts>
<context position="3138" citStr="Thadani and McKeown (2011)" startWordPosition="481" endWordPosition="484">at is able to align tens to hundreds of sentence pairs per second, and needs access only to a POS tagger and WordNet. This aligner gives state-of-the-art performance on the MSR RTE2 alignment dataset (Brockett, 2007), is faster than previous work, and we release it publicly as the first open-source monolingual word aligner: Jacana.Align.1 2 Related Work The MANLI aligner (MacCartney et al., 2008) was first proposed to align premise and hypothesis sentences for the task of natural language inference. It applies perceptron learning and handles phrase-based alignment of arbitrary phrase lengths. Thadani and McKeown (2011) optimized this model by decoding via Integer Linear Programming (ILP). Benefiting from modern ILP solvers, this led to an order-of-magnitude speedup. With extra syntactic constraints added, the exact alignment match rate for whole sentence pairs was also significantly improved. Besides the above supervised methods, indirect supervision has also been explored. Among them, Wang and Manning (2010) extended the work of McCallum et al. (2005) and modeled alignment as latent variables. Heilman and Smith (2010) used tree kernels to search for the alignment that 1http://code.google.com/p/jacana/ 702 </context>
<context position="9620" citStr="Thadani and McKeown (2011)" startWordPosition="1536" endWordPosition="1539">rization heuristics (Koehn, 2010): INTERSECTION, UNION, GROWDIAG-FINAL. 4 Experiments 4.1 Setup Since no generic off-the-shelf CRF software is designed to handle the special case of dynamic state indices and feature functions (Blunsom and Cohn, 2006), we implemented this aligner model in the Scala programming language, which is fully interoperable with Java. We used the L2 regularizer and LBFGS for optimization. OpenNLP4 provided the POS tagger and JWNL5 interfaced with WordNet (Fellbaum, 1998). To make results directly comparable, we closely followed the setup of MacCartney et al. (2008) and Thadani and McKeown (2011). Training and test data (Brockett, 2007) each contains 800 manually aligned premise and hypothesis pairs from RTE2. Note that the premises contain 29 words on average, and the hypotheses only 11 words. We take the premise as the source and hypothesis as the target, and use S2T to indicate the model aligns from 3We found that each word has to be POS tagged to get an accurate relation, otherwise this feature will not help. 4http://opennlp.apache.org/ 5http://jwordnet.sf.net/ source to target and T2S from target to source. 4.2 Simple Baselines We additionally used two baseline systems for compar</context>
<context position="11129" citStr="Thadani and McKeown (2011)" startWordPosition="1778" endWordPosition="1782">lman and Smith, 2010). We used uniform cost for deletion, insertion and substitutions, and applied a dynamic program algorithm (Zhang and Shasha, 1989) to decode the tree edit sequence with the minimal cost, based on the Stanford dependency tree (De Marneffe and Manning, 2008). This non-probabilistic approach turned out to be extremely fast, processing about 10,000 sentence pairs per second with preparsed trees, performing quantitatively better than the Stanford RTE aligner (Chambers et al., 2007). 4.3 MANLI Baselines MANLI was first developed by MacCartney et al. (2008), and then improved by Thadani and McKeown (2011) with faster and exact decoding via ILP. There are four versions to be compared here: MANLI the original version. MANLI-approx. re-implemented version by Thadani and McKeown (2011). MANLI-exact decoding via ILP solvers. MANLI-constraint MANLI-exact with hard syntactic constraints, mainly on common “light” words (determiners, prepositions, etc.) attachment to boost exact match rate. 4.4 Results Following Thadani and McKeown (2011), performance is evaluated by macro-averaged precision, recall, F1 of aligned token pairs, and exact (perfect) match rate for a whole pair, shown in Table 1. As our ba</context>
<context position="12759" citStr="Thadani and McKeown (2011)" startWordPosition="2050" endWordPosition="2053">FINAL. Our system beats 704 System P % R % F1 % E % GIZA++, n 82.5 74.4 78.3 14.0 TED 80.6 79.0 79.8 13.5 Stanford RTE* 82.7 75.8 79.1 - MANLI* 85.4 85.3 85.3 21.3 MANLI-approx.a 87.2 86.3 86.7 24.5 MANLI-exacta 87.2 86.1 86.8 24.8 MANLI-constraints 89.5 86.2 87.8 33.0 this work, S2T 91.8 83.4 87.4 25.9 this work, T2S 93.7 84.0 88.6 35.3 S2T n T2S 95.4 80.8 87.5 31.3 S2T U T2S 90.3 86.6 88.4 29.6 GROW-DIAG-FINAL 94.4 81.8 87.6 30.8 Table 1: Results on the 800 pairs of test data. E% stands for exact (perfect) match rate. Systems marked with * are reported by MacCartney et al. (2008), with a by Thadani and McKeown (2011). the weak and strong baselines6 in all measures except recall. Some patterns are very clearly shown: Higher precision, lower recall is due to the higher-quality and lower-coverage of WordNet, where the MANLI-family systems used additional, automatically derived lexical resources. Imbalance of exact match rate between S2T and T2S with a difference of 9.4% is due to the manyto-one nature of the aligner. When aligning from source (longer) to target (shorter), multiple source words can align to the same target word. This is not desirable since multiple duplicate “light” words are aligned to the s</context>
<context position="14675" citStr="Thadani and McKeown (2011)" startWordPosition="2367" endWordPosition="2370">place, relying on the ILP solver. This work has a precise O(MN2) decoding time, with M the source sentence length and N the target sentence length. 6Unfortunately both MacCartney and Thadani no longer have their original output files (personal communication), so we cannot run a significance test against their result. corpus sent. pair MANLI- MANLI- this length approx. exact work RTE2 29/11 1.67 0.08 0.025 FUSION 27/27 61.96 2.45 0.096 Table 2: Alignment runtime in seconds per sentence pair on two corpora: RTE2 (Cohn et al., 2008) and FUSION (McKeown et al., 2010). The MANLI-* results are from Thadani and McKeown (2011), on a Xeon 2.0GHz with 6MB Cache. The runtime for this work takes the longest timing from S2T and T2S, on a Xeon 2.2GHz with 4MB cache (the closest we can find to match their hardware). Horizontally in a realworld application where sentences have similar length, this work is roughly 20x faster (0.096 vs. 2.45). Vertically, the decoding time for our work increases less dramatically when sentence length increases (0.025-+0.096 vs. 0.08-+2.45). features P % R % F1 % E % full (T2S) 93.7 84.0 88.6 35.3 - POS 93.2 83.5 88.1 31.4 - WordNet 93.2 83.7 88.2 33.5 - both 93.1 83.2 87.8 30.1 Table 3: Perf</context>
</contexts>
<marker>Thadani, McKeown, 2011</marker>
<rawString>Kapil Thadani and Kathleen McKeown. 2011. Optimal and syntactically-informed decoding for monolingual phrase-based alignment. In Proceedings of ACL short.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mengqiu Wang</author>
<author>Christopher D Manning</author>
</authors>
<title>Probabilistic tree-edit models with structured latent variables for textual entailment and question answering.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10,</booktitle>
<pages>1164--1172</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="3536" citStr="Wang and Manning (2010)" startWordPosition="538" endWordPosition="541">as first proposed to align premise and hypothesis sentences for the task of natural language inference. It applies perceptron learning and handles phrase-based alignment of arbitrary phrase lengths. Thadani and McKeown (2011) optimized this model by decoding via Integer Linear Programming (ILP). Benefiting from modern ILP solvers, this led to an order-of-magnitude speedup. With extra syntactic constraints added, the exact alignment match rate for whole sentence pairs was also significantly improved. Besides the above supervised methods, indirect supervision has also been explored. Among them, Wang and Manning (2010) extended the work of McCallum et al. (2005) and modeled alignment as latent variables. Heilman and Smith (2010) used tree kernels to search for the alignment that 1http://code.google.com/p/jacana/ 702 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 702–707, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics yields the lowest tree edit distance. Other tree or graph matching work for alignment includes that of (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Chambers et al., 2007; Mehdad, 2009; Roth and Frank, </context>
</contexts>
<marker>Wang, Manning, 2010</marker>
<rawString>Mengqiu Wang and Christopher D. Manning. 2010. Probabilistic tree-edit models with structured latent variables for textual entailment and question answering. In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10, pages 1164–1172, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Zhang</author>
<author>D Shasha</author>
</authors>
<title>Simple fast algorithms for the editing distance between trees and related problems.</title>
<date>1989</date>
<journal>SIAM J. Comput.,</journal>
<volume>18</volume>
<issue>6</issue>
<contexts>
<context position="10654" citStr="Zhang and Shasha, 1989" startWordPosition="1704" endWordPosition="1707">will not help. 4http://opennlp.apache.org/ 5http://jwordnet.sf.net/ source to target and T2S from target to source. 4.2 Simple Baselines We additionally used two baseline systems for comparison. One was GIZA++, with the INTERSECTION tricks post-applied, which worked the best among all other symmetrization heuristics. The other was a Tree Edit Distance (TED) model, popularly used in a series of NLP applications (Punyakanok et al., 2004; Kouylekov and Magnini, 2005; Heilman and Smith, 2010). We used uniform cost for deletion, insertion and substitutions, and applied a dynamic program algorithm (Zhang and Shasha, 1989) to decode the tree edit sequence with the minimal cost, based on the Stanford dependency tree (De Marneffe and Manning, 2008). This non-probabilistic approach turned out to be extremely fast, processing about 10,000 sentence pairs per second with preparsed trees, performing quantitatively better than the Stanford RTE aligner (Chambers et al., 2007). 4.3 MANLI Baselines MANLI was first developed by MacCartney et al. (2008), and then improved by Thadani and McKeown (2011) with faster and exact decoding via ILP. There are four versions to be compared here: MANLI the original version. MANLI-appro</context>
</contexts>
<marker>Zhang, Shasha, 1989</marker>
<rawString>K. Zhang and D. Shasha. 1989. Simple fast algorithms for the editing distance between trees and related problems. SIAM J. Comput., 18(6):1245–1262, December.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>