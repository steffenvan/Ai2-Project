<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000206">
<note confidence="0.9425044">
PERFORMANCE COMPARISON OF COMPONENT ALGORITHMS
FOR THE PHONEMICIZATION OF ORTHOGRAPHY
Jared Bernstein Larry Nessly
Telesensory Speech Systems University of North Carolina
Palo Alto, CA 94304 Chapel Hill, NC 27514
</note>
<bodyText confidence="0.996837">
A system for converting English text
into synthetic speech can be divided into two
processes that operate in series:
</bodyText>
<listItem confidence="0.961148">
1) a text-to-phoneme converter, and
2) a phonemic-input speech synthesizer.
</listItem>
<bodyText confidence="0.980483522727273">
The conversion of orthographic text into a
phonemic form may itself comprise several
processes in series, for instance, formatting
text to expand abbreviations and
non-alphabetic expressions, parsing and word
class determination, segmental phonemicization
of words, word and clause level stress
assignment, word internal and word boundary
allophonic adjustments, and duration and
fundamental frequency settings for
phonological units.
Comparing the accuracy of different
algorithms for text-to-phoneme conversion is
often difficult because authors measure and
report system performance in incommensurable
ways. Furthermore, comparison of the output
speech from two complete systems may not
always provide a good test of the performance
of the corresponding component algorithms in
the two systems, because radical performance
differences in other components can obscure
small differences in the components of
interest. The only reported direct comparison
of two complete text-to-speech systems (MITALK
and TSI&apos;s TTS-X) was conducted by Bernstein
and Pisoni (1980). This paper reports one
study that compared two algorithms for
automatic segmental phonemicization of words,
and a second study that compared two
algorithms for automatic assignment of lexical
stress.
Only three systems for text-to-phoneme
conversion have been reported in detail:
McIlroy&apos;s (1974) Votrax driver, Hunnicutt&apos;s
(1976) rules for the MITALK system, and the
NRL rules developed by Elovitz and associates
(1976). Liberman (1979), Hertz (1981), and
Hunnicutt (1980) have described more recent
systems, but have not published rule sets.
One fairly standard approach to
automatic phonemiczation of words has the
following component parts:
input: &amp;quot;whoever&amp;quot;
LEXICON
</bodyText>
<sectionHeader confidence="0.547948142857143" genericHeader="abstract">
AFFIX
STRIPPER
LETTER
TO SOUND
LEXICAL
STRESS
ALLOPHONICS
</sectionHeader>
<bodyText confidence="0.9467814375">
&apos;
output: /huwev3/
Several research systems are of this general
design, including Allen&apos;s MITALK system, the
TTS-X prototype at Telesensory Systems, and
Liberman&apos;s proper name phonemicizer.
The most popular text-to-phoneme
design is the NRL approach, which has only two
components, of which only the first is
presented in detail and evaluated by Elovitz.
The original NRL system is:
input: &amp;quot;word&amp;quot;
LETTER
TO SOUND
including some
whole morphemes
</bodyText>
<equation confidence="0.18476675">
LEXICAL
STRESS
,
output: /w3d/
</equation>
<page confidence="0.994824">
19
</page>
<bodyText confidence="0.987117126436782">
The very great advantage of the NRL
approach is the unified treatment of letter
sequences, affixes, and whole words. There is
exactly one pass through a word, left to
right, in which the maximum string starting
with the leftmost unphonemicized character is
matched. These strings are sometimes whole
words, sometimes affixes, and sometimes
consonant or vowel sequences or word fragments
like &amp;quot;BUIL&amp;quot;. The main constraint of the
system is its greatest attraction: the unity
and simplicity of the code that scans the word
and accesses a single table of letter strings.
In contrast to this, the MITALK system, for
instance, has one module and associated table
structure for lexical decomposition of whole
words, another module for stripping common
affixes, and a third module for translating
consonant and vowel sequences that remain in
the pseudo-root of the word.
STUDY ONE
Study One reports a comparison of two
routines for translating orthographic letters
into segmental phonemes: Hunnicutt@TSI and
NRLODEC.
Hunnicutt@TSI is the affix stripper
and letter to sound rules as discribed in AJCL
Microfiche 57, and implemented in MACRO-11 in
Telesensory Systems&apos; TTS-X prototype
text-to-speech system. Hunnicutt&apos;s system was
modified only slightly in translation, and
about 20 rules were added. The system starts
from the right end of the word and identifies
as many suffixes as it can from a table of
about 140 suffixes, proceeding toward the
beginning of the word until either the
remainder (pseudo-root) of the word has no
vowel or fewer than three letters, or no more
suffixes can be matched. Next, a similar
proceedure works from the beginning of the
word, matching as many prefixes as it can from
• a table of about 40 prefixes. Finally, the
pseudo-root of the word is scanned left to
right twice, once translating the consonants,
and next translating the vowels.
NRL@DEC is a system implemented by
Martin Minnow at Digital Equiptment Corp. The
whole system is somewhat more elaborate that
the original NAL system, but the letter to
sound module and its mode of operation are
basically as described by Elovitz et alia,
with 20 or 30 rules added. The NAL rules
include about 60 very common whole words, as
well as about 25 rules that handle various
environments for three prefixes and fifteen
suffixes.
A set of 865 words was processed both
by the Hunnicutt@TSI affix stripper and letter
to sound rules, and by the NRL@DEC letter to
sound rules including the affix rules and the
word fragments. The 865 words comprised
approximately every fiftieth word of the Brown
Corpus (Kucera &amp; Francis, 1967) in frequency
order, starting from about the 400th most
frequent word: &amp;quot;position.&amp;quot; The lexicon of the
TSI system was disabled, and none of the whole
words in the NRL rules was in the set of 865.
Since the output from both subsystems
was tapped before stress assignment, vowel
reduction, and any allophonics were performed,
the criterion of correctness was &amp;quot;does this
phonemicization represent any acceptable
pronunciation of the spelled word, assuming
one can assign stress correctly and then
reduce vowels appropriately.&amp;quot; Thus, a
phonemicization consistent with any possible
word class for that spelling, or any &apos;regular&apos;
regional pronunciation was to be accepted.
Three judges (two phoneticians and a
phonologist) were given printed copies of the
two resulting phonemic transcriptions; both
were in fairly transparent broad phonemic
form. The judges chose among three possible
responses to each word: 1 = correct; .5 =
close or questionable; and 0 = wrong. Cross
judge consistency can be seen from the bimodal
distribution of summed scores in Figure 1.
</bodyText>
<figure confidence="0.8276057">
FUR E I
Scumwedt scarez .PreAk 3 Jwtiges
On 86sWeettS
rasealrIrs .z
0 .3&amp;quot; - 1. J. -.2.1&amp;quot; 3
Yu.nm;euilters
137
70
.r-i. is. •&amp;quot;2.5. 3
N RLODEc
</figure>
<page confidence="0.918383">
20
</page>
<bodyText confidence="0.999448857142857">
Another, more diagnostic way to view
the results is to present the number of words
that fall into each cell of a 2X2 grid formed
by the Hunnicutt@TSI rating vs. the NRL@DEC
rating, as shown in Figure 2. Figure 2 omits
the 26 words that had a summed score of 1.5
for either of the two letter to sound systems.
</bodyText>
<figure confidence="0.956079333333334">
FIGURE 2
NRL@DEC
&lt;1.5 &gt;1.5
la 1
&lt;1.5 I 127 1 90 I
Hunnicutt@TSI 1
I c
&gt;1.5 : 69 1 553 1
1
</figure>
<bodyText confidence="0.999033166666667">
If the rule sets were equivalent, the
grid would have zeroes in cells b and c. If
one rule set were a super-set of the other,
you would get a zero in cell b or cell c, but
not both. Most of the 553 words in cell d are
regular, or else are common exceptions (like
&amp;quot;built&amp;quot;). Most of the 127 words in cell a are
obviously exceptional (e.g. &amp;quot;minute, honor,
one, two&amp;quot;).
Examination of the 159 words
distributed between cells b and c yields the
payoff. Of the 69 words that Hunnicutt@TSI
got right and NRL@DEC missed, nearly half are
correct by virtue of the extensive affix
stripping in Hunnicutt&apos;s algorithm. Among
these 69 words in cell c are &amp;quot;mobile, naval,
wallace, likened, coworkers, &amp; reenacted.&amp;quot;
Of the 90 words that NRL@DEC got right
and Hunnicutt@TSI got wrong, only about 15 are
definitely due to NRL&apos;s word fragment rules.
Six of the 90 words are in cell d just because
MRL does not strip suffixes the way that
Hunnicutt&apos;s rules do. These six words are
&amp;quot;november, visited, preferably, presidency,
september, &amp; oven.&amp;quot;
In general, both algorithms get about
25% wrong on this lexically flat sample of 865
word types. About 15% of the words are
incorectly phonemicized by both subsystems.
This might suggest that 15% wrong may be a
state of the art performance level for
segmental phonemicization of word types by
sets of 400 rules.
STUDY TWO
Study Two compared the performance of
two algorithms for assignment of lexical
stress to words. Both of the algorithms were
coded in MACRO-11 and ran in different
versions of TSI&apos;s TTS-X prototype
text-to-speech system. The first algorithm is
Hunnicutt&apos;s lexical stresser, which is
described in detail in AJCL Microfiche 57.
Hunnicutt&apos;s algorithm is an adaptation of
Halle&apos;s cyclic stress rules for English. The
adaptations include adjustments for the less
specified input to the rules (e.g. the part of
speech of the root is unknown), and the number
of stress levels specified in the output is
reduced, presumably because the Klatt
synthesizer it was designed to drive only used
two stress levels. Hunnicutt also added stress
rules that depended on the occurance of
certain classes of suffixes. Hunnicutt&apos;s rules
require several pointers and a suffix table,
they sometimes pass through a word several
times in the manner of Chomsky &amp; Halle&apos;s
(1968) rules, and they occupy about 3K bytes
of executable code in their TSI version.
The second algorithm is a simplified
version of a stress rule proposed in Hill &amp;
Nessly (1973). We will refer to this rule as
Nessly&apos;s default, since it is the default case
of Nessly&apos;s full stress algorithm. Nessly&apos;s
default stress is quite similar to Latin
stress and to the &amp;quot;first approximation&amp;quot; stress
rule discussed twoard the beginning of Chomsky
&amp; Halle&apos;s chapter three (1968, pp.69-77). The
main differences between Nessly&apos;s default rule
and Chomsky &amp; Halle&apos;s &amp;quot;first approximation&amp;quot;
are:
(1) No word class information is used
in Nessly&apos;s default, so verbs are stressed as
nouns.
and (2) What constitutes a &amp;quot;strong
cluster&amp;quot; (which contains a tense vowel or a
closed syllable end) is different. Nessly&apos;s
default is indifferent to vowel length or
tensity.
Nessly&apos;s default rule can be outlined as
follows:
if(number of syllables = 1)
stress it.
if(number of syllables = 2)
stress left syllable.
else
skip the last syllable.
if(next-to-last is closed)
stress it.
else
stress third from last.
(place alternating 2nd stresses
on syllables to the left.)
The MACRO-11 version of this rule requires
about 150 bytes of executable code, and
accepts one pointer to the last vowel in the
word. It passes through the word once, right
to left, and it does very well assigning
correct stresses (in caps) to &amp;quot;LUminant&amp;quot; vs.
&amp;quot;maLIGnant,&amp;quot; for example.
For testing the stress algorithms, a
sample of 430 words was selected. These 430
words were all the items of five or more
characters that had frequencies of 40 ppm
through 34 ppm (inclusive) in the Brown
corpus. The segmental phonemicization was done
by Hunnicutt&apos;s rules in TSI&apos;s TTS-X prototype.
The automatically produced segmental
phonemicizations that the stress algorithms
operated on were rejected only if they did not
have the correct number of syllables.
Thirteen of the 430 words were phonemicized
with the wrong number of syllables. Another
54, or 13%, of the 430 were one syllable
words, which were allways assigned correct
</bodyText>
<page confidence="0.997113">
21
</page>
<bodyText confidence="0.733764666666667">
stress. Stress assignments were judged by the
first author. The results on the remaining
417 words of the sample were:
</bodyText>
<subsectionHeader confidence="0.919493">
Correct Wrong
</subsectionHeader>
<bodyText confidence="0.9407898">
Hunnicutt/Halle 308 109
Nesoly default 303 114
So, on these words, the two algorithms perform
at about the same level of accuracy, which is
about 25% wrong on a lexical sample.
</bodyText>
<sectionHeader confidence="0.985587" genericHeader="discussions">
DISCUSSION
</sectionHeader>
<bodyText confidence="0.993147142857143">
In both studies, very simple
algorithms performed about as well as
algorithms of vastly greater complexity. In
the case of the letter-to-sound algorithms
(Hunnicutt@TSI and NRL@DEC), the difference in
complexity is primarily in the procedure for
checking the rules against the word.
Hunnicutt&apos;s rules themselves are only a little
more complicated than the NRL rules.
Presumably, with some modification, most of
Hunnicutt&apos;s rules could be modified to run
within a one-pass NRL procedure.
The stress algorithms tested in Study
Two present a very great contrast in both
number of rules and procedure for rule
application. If Nessly&apos;s default rule is like
a simplified version of Chomsky &amp; Halle&apos;s
&amp;quot;first approximation&amp;quot; stress rule, and if
Hunnicutt&apos;s algorithm is fairly close to
Chomsky &amp; Halle&apos;s full lexical stress rules
(with noun-root assumed), then our data
suggest that the epicyclic accretion that
produced Chomsky &amp; Halle&apos;s full set of stress
rules from their &amp;quot;first approximation&amp;quot; has
gained almost nothing in lexical coverage.
We have reported performance in terms
of percent wrong on samples of word types from
the Brown corpus. It seems that an
appropriate measure of performance that
reflects what people feel when they hear a
text-to-speech system is AVERAGE WORDS BETWEEN
ERRORS (AWBE). We would like to end this paper
by giving AWBE for a simple text-to-phoneme
system with a 25% error rate in both
letter-to-sound conversion and lexical
stressing, and a lexicon with 1500 words.
If the lexicon is in parallel with the
letter to sound and stress rules, and the
performance of the letter to sound rules and
the stress rules are independant, an overall
error rate of about 7% can be expected. This
would translate into an AWBE of 13.3.
</bodyText>
<sectionHeader confidence="0.944095" genericHeader="acknowledgments">
ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.545571">
The authors gratefully acknowlege valuable
help from Martin Minot&apos;&apos;, Peter Maggs,
Margaret Kahn, and Julie Lovins.
</bodyText>
<sectionHeader confidence="0.651281" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.998706107142857">
J.Bernstein &amp; D.Pisoni (1980) &amp;quot;Unlimited
text-to-speech system: Description and
evaluation of a microprocessor based device,&amp;quot;
IEEE ICASSP-80 Proceedings.
N.Chomsky &amp; M.Halle (1968) THE SOUND PATTERN
OF ENGLISH, Harper-Row, New York.
H.Elovitz, R.Johnson, A.McHugh, &amp; J.Shore
(1976) &amp;quot;Letter-to-sound rules for automatic
translation of English text to phonetics,&amp;quot;
IEEE Trans. on Acoustics, Speech, and Signal
Processing, vol. ASSP-24, no. 6.
S.Hertz (1981) &amp;quot;SRS letter to sound rules,&amp;quot;
IEEE ICASSP-80 Proceedings.
S.Hunnicutt (1976) &amp;quot;Phonological rules for a
text-to-speech system&amp;quot; AJCL Microfiche 57.
S.Hunnicutt (1980) &amp;quot;Grapheme to phoneme rules:
a review&amp;quot; KTH SLT-QPSR 2-3/1980, Stockholm.
H.Kucera &amp; W.Francis (1967) COMPUTATIONAL
ANALYSIS OF PRESENT DAY AMERICAN ENGLISH,
Brown U. Press, Providence.
.M.Liberman (1979) &amp;quot;Text-to-speech conversion
by rule and a practical application,&amp;quot;
Proceedings of the Ninth International
Congress of Phonetic Sciences, Copenhagen.
M.McIlroy (1974) &amp;quot;Synthetic English speech by
rule,&amp;quot; Bell Telephone Laboratories Memo.
K.Hill &amp; L.Nessly (1973) &amp;quot;Review of The Sound
Patten of English,&amp;quot; LINGUISTICS 106: 57-101.
</reference>
<page confidence="0.998982">
22
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.006365">
<title confidence="0.9991135">PERFORMANCE COMPARISON OF COMPONENT ALGORITHMS FOR THE PHONEMICIZATION OF ORTHOGRAPHY</title>
<author confidence="0.999272">Jared Bernstein Larry Nessly</author>
<affiliation confidence="0.683046">Telesensory Speech Systems University of North Carolina</affiliation>
<address confidence="0.925458">Palo Alto, CA 94304 Chapel Hill, NC 27514</address>
<abstract confidence="0.977104267217631">A system for converting English text into synthetic speech can be divided into two processes that operate in series: 1) a text-to-phoneme converter, and 2) a phonemic-input speech synthesizer. The conversion of orthographic text into a phonemic form may itself comprise several processes in series, for instance, formatting text to expand abbreviations and non-alphabetic expressions, parsing and word class determination, segmental phonemicization of words, word and clause level stress assignment, word internal and word boundary allophonic adjustments, and duration and fundamental frequency settings for phonological units. Comparing the accuracy of different algorithms for text-to-phoneme conversion is often difficult because authors measure and report system performance in incommensurable ways. Furthermore, comparison of the output speech from two complete systems may not always provide a good test of the performance of the corresponding component algorithms in the two systems, because radical performance differences in other components can obscure small differences in the components of interest. The only reported direct comparison of two complete text-to-speech systems (MITALK and TSI&apos;s TTS-X) was conducted by Bernstein and Pisoni (1980). This paper reports one study that compared two algorithms for automatic segmental phonemicization of words, and a second study that compared two algorithms for automatic assignment of lexical stress. Only three systems for text-to-phoneme conversion have been reported in detail: McIlroy&apos;s (1974) Votrax driver, Hunnicutt&apos;s (1976) rules for the MITALK system, and the NRL rules developed by Elovitz and associates (1976). Liberman (1979), Hertz (1981), and Hunnicutt (1980) have described more recent systems, but have not published rule sets. One fairly standard approach to automatic phonemiczation of words has the following component parts: input: &amp;quot;whoever&amp;quot; LEXICON AFFIX STRIPPER LETTER TO SOUND LEXICAL STRESS ALLOPHONICS &apos; output: /huwev3/ Several research systems are of this general design, including Allen&apos;s MITALK system, the TTS-X prototype at Telesensory Systems, and Liberman&apos;s proper name phonemicizer. The most popular text-to-phoneme is the NRL approach, only two components, of which only the first is presented in detail and evaluated by Elovitz. The original NRL system is: input: &amp;quot;word&amp;quot; LETTER TO SOUND including some whole morphemes LEXICAL STRESS , output: /w3d/ 19 The very great advantage of the NRL approach is the unified treatment of letter sequences, affixes, and whole words. There is exactly one pass through a word, left to right, in which the maximum string starting with the leftmost unphonemicized character is matched. These strings are sometimes whole words, sometimes affixes, and sometimes consonant or vowel sequences or word fragments like &amp;quot;BUIL&amp;quot;. The main constraint of the system is its greatest attraction: the unity and simplicity of the code that scans the word and accesses a single table of letter strings. In contrast to this, the MITALK system, for instance, has one module and associated table structure for lexical decomposition of whole words, another module for stripping common affixes, and a third module for translating consonant and vowel sequences that remain in the pseudo-root of the word. STUDY ONE Study One reports a comparison of two routines for translating orthographic letters into segmental phonemes: Hunnicutt@TSI and NRLODEC. affix stripper and letter to sound rules as discribed in AJCL Microfiche 57, and implemented in MACRO-11 in Telesensory Systems&apos; TTS-X prototype text-to-speech system. Hunnicutt&apos;s system was modified only slightly in translation, and about 20 rules were added. The system starts from the right end of the word and identifies as many suffixes as it can from a table of about 140 suffixes, proceeding toward the beginning of the word until either the remainder (pseudo-root) of the word has no or three letters, or no more suffixes can be matched. Next, a similar proceedure works from the beginning of the word, matching as many prefixes as it can from • a table of about 40 prefixes. Finally, the pseudo-root of the word is scanned left to right twice, once translating the consonants, and next translating the vowels. NRL@DEC is a system implemented by Martin Minnow at Digital Equiptment Corp. The system more elaborate that the original NAL system, but the letter to sound module and its mode of operation are basically as described by Elovitz et alia, with 20 or 30 rules added. The NAL rules include about 60 very common whole words, as well as about 25 rules that handle various environments for three prefixes and fifteen suffixes. A set of 865 words was processed both by the Hunnicutt@TSI affix stripper and letter to sound rules, and by the NRL@DEC letter to sound rules including the affix rules and the word fragments. The 865 words comprised approximately every fiftieth word of the Brown Corpus (Kucera &amp; Francis, 1967) in frequency order, starting from about the 400th most frequent word: &amp;quot;position.&amp;quot; The lexicon of the TSI system was disabled, and none of the whole in the was in the set of 865. Since the output from both subsystems was tapped before stress assignment, vowel reduction, and any allophonics were performed, the criterion of correctness was &amp;quot;does this phonemicization represent any acceptable pronunciation of the spelled word, assuming one can assign stress correctly and then reduce vowels appropriately.&amp;quot; Thus, a phonemicization consistent with any possible word class for that spelling, or any &apos;regular&apos; regional pronunciation was to be accepted. Three judges (two phoneticians and a phonologist) were given printed copies of the two resulting phonemic transcriptions; both were in fairly transparent broad phonemic form. The judges chose among three possible responses to each word: 1 = correct; .5 = close or questionable; and 0 = wrong. Cross judge consistency can be seen from the bimodal distribution of summed scores in Figure 1. FUR E I 3 - -.2.1&amp;quot; 3 137 70 3 N RLODEc 20 Another, more diagnostic way to view the results is to present the number of words that fall into each cell of a 2X2 grid formed by the Hunnicutt@TSI rating vs. the NRL@DEC rating, as shown in Figure 2. Figure 2 omits the 26 words that had a summed score of 1.5 for either of the two letter to sound systems. FIGURE 2 NRL@DEC &lt;1.5 &gt;1.5 la 1 &lt;1.5 I 127 1 90 I Hunnicutt@TSI 1 I c &gt;1.5 : 69 1 553 1 1 If the rule sets were equivalent, the grid would have zeroes in cells b and c. If one rule set were a super-set of the other, you would get a zero in cell b or cell c, but not both. Most of the 553 words in cell d are regular, or else are common exceptions (like &amp;quot;built&amp;quot;). Most of the 127 words in cell a are obviously exceptional (e.g. &amp;quot;minute, honor, one, two&amp;quot;). Examination of the 159 words distributed between cells b and c yields the payoff. Of the 69 words that Hunnicutt@TSI got right and NRL@DEC missed, nearly half are correct by virtue of the extensive affix stripping in Hunnicutt&apos;s algorithm. Among these 69 words in cell c are &amp;quot;mobile, naval, wallace, likened, coworkers, &amp; reenacted.&amp;quot; Of the 90 words that NRL@DEC got right and Hunnicutt@TSI got wrong, only about 15 are definitely due to NRL&apos;s word fragment rules. Six of the 90 words are in cell d just because MRL does not strip suffixes the way that Hunnicutt&apos;s rules do. These six words are &amp;quot;november, visited, preferably, presidency, september, &amp; oven.&amp;quot; In general, both algorithms get about 25% wrong on this lexically flat sample of 865 word types. About 15% of the words are incorectly phonemicized by both subsystems. This might suggest that 15% wrong may be a state of the art performance level for segmental phonemicization of word types by sets of 400 rules. STUDY TWO Study Two compared the performance of two algorithms for assignment of lexical stress to words. Both of the algorithms were coded in MACRO-11 and ran in different versions of TSI&apos;s TTS-X prototype text-to-speech system. The first algorithm is Hunnicutt&apos;s lexical stresser, which is described in detail in AJCL Microfiche 57. Hunnicutt&apos;s algorithm is an adaptation of Halle&apos;s cyclic stress rules for English. The adaptations include adjustments for the less specified input to the rules (e.g. the part of speech of the root is unknown), and the number of stress levels specified in the output is reduced, presumably because the Klatt synthesizer it was designed to drive only used two stress levels. Hunnicutt also added stress rules that depended on the occurance of certain classes of suffixes. Hunnicutt&apos;s rules require several pointers and a suffix table, they sometimes pass through a word several times in the manner of Chomsky &amp; Halle&apos;s (1968) rules, and they occupy about 3K bytes of executable code in their TSI version. The second algorithm is a simplified version of a stress rule proposed in Hill &amp; Nessly (1973). We will refer to this rule as Nessly&apos;s default, since it is the default case of Nessly&apos;s full stress algorithm. Nessly&apos;s default stress is quite similar to Latin stress and to the &amp;quot;first approximation&amp;quot; stress rule discussed twoard the beginning of Chomsky &amp; Halle&apos;s chapter three (1968, pp.69-77). The main differences between Nessly&apos;s default rule and Chomsky &amp; Halle&apos;s &amp;quot;first approximation&amp;quot; are: (1) No word class information is used in Nessly&apos;s default, so verbs are stressed as nouns. and (2) What constitutes a &amp;quot;strong cluster&amp;quot; (which contains a tense vowel or a closed syllable end) is different. Nessly&apos;s default is indifferent to vowel length or tensity. Nessly&apos;s default rule can be outlined as follows: if(number of syllables = 1) stress it. if(number of syllables = 2) stress left syllable. else skip the last syllable. if(next-to-last is closed) stress it. else stress third from last. (place alternating 2nd stresses on syllables to the left.) The MACRO-11 version of this rule requires about 150 bytes of executable code, and accepts one pointer to the last vowel in the word. It passes through the word once, right to left, and it does very well assigning correct stresses (in caps) to &amp;quot;LUminant&amp;quot; vs. &amp;quot;maLIGnant,&amp;quot; for example. For testing the stress algorithms, a sample of 430 words was selected. These 430 words were all the items of five or more characters that had frequencies of 40 ppm through 34 ppm (inclusive) in the Brown corpus. The segmental phonemicization was done by Hunnicutt&apos;s rules in TSI&apos;s TTS-X prototype. The automatically produced segmental phonemicizations that the stress algorithms operated on were rejected only if they did not have the correct number of syllables. Thirteen of the 430 words were phonemicized with the wrong number of syllables. Another 54, or 13%, of the 430 were one syllable words, which were allways assigned correct 21 stress. Stress assignments were judged by the first author. The results on the remaining 417 words of the sample were: Correct Wrong Hunnicutt/Halle 308 109 default 303 So, on these words, the two algorithms perform about the same level of accuracy, which about 25% wrong on a lexical sample. DISCUSSION In both studies, very simple algorithms performed about as well as algorithms of vastly greater complexity. In the case of the letter-to-sound algorithms (Hunnicutt@TSI and NRL@DEC), the difference in complexity is primarily in the procedure for checking the rules against the word. Hunnicutt&apos;s rules themselves are only a little more complicated than the NRL rules. Presumably, with some modification, most of Hunnicutt&apos;s rules could be modified to run within a one-pass NRL procedure. The stress algorithms tested in Study Two present a very great contrast in both number of rules and procedure for rule application. If Nessly&apos;s default rule is like a simplified version of Chomsky &amp; Halle&apos;s &amp;quot;first approximation&amp;quot; stress rule, and if Hunnicutt&apos;s algorithm is fairly close to Chomsky &amp; Halle&apos;s full lexical stress rules (with noun-root assumed), then our data suggest that the epicyclic accretion that produced Chomsky &amp; Halle&apos;s full set of stress rules from their &amp;quot;first approximation&amp;quot; has gained almost nothing in lexical coverage. We have reported performance in terms of percent wrong on samples of word types from the Brown corpus. It seems that an appropriate measure of performance that reflects what people feel when they hear a text-to-speech system is AVERAGE WORDS BETWEEN ERRORS (AWBE). We would like to end this paper by giving AWBE for a simple text-to-phoneme system with a 25% error rate in both letter-to-sound conversion and lexical stressing, and a lexicon with 1500 words. If the lexicon is in parallel with the letter to sound and stress rules, and the performance of the letter to sound rules and the stress rules are independant, an overall rate of about be expected. This would translate into an AWBE of 13.3. ACKNOWLEDGEMENTS The authors gratefully acknowlege valuable help from Martin Minot&apos;&apos;, Peter Maggs, Margaret Kahn, and Julie Lovins. REFERENCES J.Bernstein &amp; D.Pisoni (1980) &amp;quot;Unlimited text-to-speech system: Description and evaluation of a microprocessor based device,&amp;quot;</abstract>
<note confidence="0.91066744">IEEE ICASSP-80 Proceedings. N.Chomsky &amp; M.Halle (1968) THE SOUND PATTERN OF ENGLISH, Harper-Row, New York. H.Elovitz, R.Johnson, A.McHugh, &amp; J.Shore &amp;quot;Letter-to-sound rules translation of English text to phonetics,&amp;quot; IEEE Trans. on Acoustics, Speech, and Signal Processing, vol. ASSP-24, no. 6. S.Hertz (1981) &amp;quot;SRS letter to sound rules,&amp;quot; IEEE ICASSP-80 Proceedings. S.Hunnicutt (1976) &amp;quot;Phonological rules for a text-to-speech system&amp;quot; AJCL Microfiche 57. S.Hunnicutt (1980) &amp;quot;Grapheme to phoneme rules: a review&amp;quot; KTH SLT-QPSR 2-3/1980, Stockholm. H.Kucera &amp; W.Francis (1967) COMPUTATIONAL ANALYSIS OF PRESENT DAY AMERICAN ENGLISH, Brown U. Press, Providence. .M.Liberman (1979) &amp;quot;Text-to-speech conversion by rule and a practical application,&amp;quot; Proceedings of the Ninth International Congress of Phonetic Sciences, Copenhagen. M.McIlroy (1974) &amp;quot;Synthetic English speech by rule,&amp;quot; Bell Telephone Laboratories Memo. K.Hill &amp; L.Nessly (1973) &amp;quot;Review of The Sound Patten of English,&amp;quot; LINGUISTICS 106: 57-101.</note>
<intro confidence="0.544458">22</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Bernstein</author>
<author>D Pisoni</author>
</authors>
<title>Unlimited text-to-speech system: Description and evaluation of a microprocessor based device,&amp;quot;</title>
<date>1980</date>
<booktitle>IEEE ICASSP-80 Proceedings.</booktitle>
<contexts>
<context position="1469" citStr="Bernstein and Pisoni (1980)" startWordPosition="199" endWordPosition="202">omparing the accuracy of different algorithms for text-to-phoneme conversion is often difficult because authors measure and report system performance in incommensurable ways. Furthermore, comparison of the output speech from two complete systems may not always provide a good test of the performance of the corresponding component algorithms in the two systems, because radical performance differences in other components can obscure small differences in the components of interest. The only reported direct comparison of two complete text-to-speech systems (MITALK and TSI&apos;s TTS-X) was conducted by Bernstein and Pisoni (1980). This paper reports one study that compared two algorithms for automatic segmental phonemicization of words, and a second study that compared two algorithms for automatic assignment of lexical stress. Only three systems for text-to-phoneme conversion have been reported in detail: McIlroy&apos;s (1974) Votrax driver, Hunnicutt&apos;s (1976) rules for the MITALK system, and the NRL rules developed by Elovitz and associates (1976). Liberman (1979), Hertz (1981), and Hunnicutt (1980) have described more recent systems, but have not published rule sets. One fairly standard approach to automatic phonemiczati</context>
</contexts>
<marker>Bernstein, Pisoni, 1980</marker>
<rawString>J.Bernstein &amp; D.Pisoni (1980) &amp;quot;Unlimited text-to-speech system: Description and evaluation of a microprocessor based device,&amp;quot; IEEE ICASSP-80 Proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
<author>M Halle</author>
</authors>
<date>1968</date>
<journal>THE SOUND PATTERN OF</journal>
<publisher>ENGLISH, Harper-Row,</publisher>
<location>New York.</location>
<marker>Chomsky, Halle, 1968</marker>
<rawString>N.Chomsky &amp; M.Halle (1968) THE SOUND PATTERN OF ENGLISH, Harper-Row, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Johnson H Elovitz</author>
<author>A McHugh</author>
<author>J Shore</author>
</authors>
<title>Letter-to-sound rules for automatic translation of English text to phonetics,&amp;quot;</title>
<date>1976</date>
<journal>IEEE Trans. on Acoustics, Speech, and Signal Processing,</journal>
<volume>24</volume>
<marker>Elovitz, McHugh, Shore, 1976</marker>
<rawString>H.Elovitz, R.Johnson, A.McHugh, &amp; J.Shore (1976) &amp;quot;Letter-to-sound rules for automatic translation of English text to phonetics,&amp;quot; IEEE Trans. on Acoustics, Speech, and Signal Processing, vol. ASSP-24, no. 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Hertz</author>
</authors>
<title>SRS letter to sound rules,&amp;quot;</title>
<date>1981</date>
<booktitle>IEEE ICASSP-80 Proceedings.</booktitle>
<contexts>
<context position="1922" citStr="Hertz (1981)" startWordPosition="266" endWordPosition="267">s of interest. The only reported direct comparison of two complete text-to-speech systems (MITALK and TSI&apos;s TTS-X) was conducted by Bernstein and Pisoni (1980). This paper reports one study that compared two algorithms for automatic segmental phonemicization of words, and a second study that compared two algorithms for automatic assignment of lexical stress. Only three systems for text-to-phoneme conversion have been reported in detail: McIlroy&apos;s (1974) Votrax driver, Hunnicutt&apos;s (1976) rules for the MITALK system, and the NRL rules developed by Elovitz and associates (1976). Liberman (1979), Hertz (1981), and Hunnicutt (1980) have described more recent systems, but have not published rule sets. One fairly standard approach to automatic phonemiczation of words has the following component parts: input: &amp;quot;whoever&amp;quot; LEXICON AFFIX STRIPPER LETTER TO SOUND LEXICAL STRESS ALLOPHONICS &apos; output: /huwev3/ Several research systems are of this general design, including Allen&apos;s MITALK system, the TTS-X prototype at Telesensory Systems, and Liberman&apos;s proper name phonemicizer. The most popular text-to-phoneme design is the NRL approach, which has only two components, of which only the first is presented in d</context>
</contexts>
<marker>Hertz, 1981</marker>
<rawString>S.Hertz (1981) &amp;quot;SRS letter to sound rules,&amp;quot; IEEE ICASSP-80 Proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Hunnicutt</author>
</authors>
<title>Phonological rules for a text-to-speech system&amp;quot;</title>
<date>1976</date>
<journal>AJCL Microfiche</journal>
<volume>57</volume>
<location>Stockholm.</location>
<marker>Hunnicutt, 1976</marker>
<rawString>S.Hunnicutt (1976) &amp;quot;Phonological rules for a text-to-speech system&amp;quot; AJCL Microfiche 57. S.Hunnicutt (1980) &amp;quot;Grapheme to phoneme rules: a review&amp;quot; KTH SLT-QPSR 2-3/1980, Stockholm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kucera</author>
<author>W Francis</author>
</authors>
<date>1967</date>
<journal>COMPUTATIONAL ANALYSIS OF PRESENT DAY AMERICAN ENGLISH, Brown</journal>
<publisher>U. Press,</publisher>
<location>Providence.</location>
<contexts>
<context position="5274" citStr="Kucera &amp; Francis, 1967" startWordPosition="801" endWordPosition="804">e elaborate that the original NAL system, but the letter to sound module and its mode of operation are basically as described by Elovitz et alia, with 20 or 30 rules added. The NAL rules include about 60 very common whole words, as well as about 25 rules that handle various environments for three prefixes and fifteen suffixes. A set of 865 words was processed both by the Hunnicutt@TSI affix stripper and letter to sound rules, and by the NRL@DEC letter to sound rules including the affix rules and the word fragments. The 865 words comprised approximately every fiftieth word of the Brown Corpus (Kucera &amp; Francis, 1967) in frequency order, starting from about the 400th most frequent word: &amp;quot;position.&amp;quot; The lexicon of the TSI system was disabled, and none of the whole words in the NRL rules was in the set of 865. Since the output from both subsystems was tapped before stress assignment, vowel reduction, and any allophonics were performed, the criterion of correctness was &amp;quot;does this phonemicization represent any acceptable pronunciation of the spelled word, assuming one can assign stress correctly and then reduce vowels appropriately.&amp;quot; Thus, a phonemicization consistent with any possible word class for that spel</context>
</contexts>
<marker>Kucera, Francis, 1967</marker>
<rawString>H.Kucera &amp; W.Francis (1967) COMPUTATIONAL ANALYSIS OF PRESENT DAY AMERICAN ENGLISH, Brown U. Press, Providence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Liberman</author>
</authors>
<title>Text-to-speech conversion by rule and a practical application,&amp;quot;</title>
<date>1979</date>
<journal>LINGUISTICS</journal>
<booktitle>Proceedings of the Ninth International Congress of Phonetic Sciences, Copenhagen. M.McIlroy</booktitle>
<volume>106</volume>
<pages>57--101</pages>
<contexts>
<context position="1908" citStr="Liberman (1979)" startWordPosition="264" endWordPosition="265"> in the components of interest. The only reported direct comparison of two complete text-to-speech systems (MITALK and TSI&apos;s TTS-X) was conducted by Bernstein and Pisoni (1980). This paper reports one study that compared two algorithms for automatic segmental phonemicization of words, and a second study that compared two algorithms for automatic assignment of lexical stress. Only three systems for text-to-phoneme conversion have been reported in detail: McIlroy&apos;s (1974) Votrax driver, Hunnicutt&apos;s (1976) rules for the MITALK system, and the NRL rules developed by Elovitz and associates (1976). Liberman (1979), Hertz (1981), and Hunnicutt (1980) have described more recent systems, but have not published rule sets. One fairly standard approach to automatic phonemiczation of words has the following component parts: input: &amp;quot;whoever&amp;quot; LEXICON AFFIX STRIPPER LETTER TO SOUND LEXICAL STRESS ALLOPHONICS &apos; output: /huwev3/ Several research systems are of this general design, including Allen&apos;s MITALK system, the TTS-X prototype at Telesensory Systems, and Liberman&apos;s proper name phonemicizer. The most popular text-to-phoneme design is the NRL approach, which has only two components, of which only the first is </context>
</contexts>
<marker>Liberman, 1979</marker>
<rawString>.M.Liberman (1979) &amp;quot;Text-to-speech conversion by rule and a practical application,&amp;quot; Proceedings of the Ninth International Congress of Phonetic Sciences, Copenhagen. M.McIlroy (1974) &amp;quot;Synthetic English speech by rule,&amp;quot; Bell Telephone Laboratories Memo. K.Hill &amp; L.Nessly (1973) &amp;quot;Review of The Sound Patten of English,&amp;quot; LINGUISTICS 106: 57-101.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>