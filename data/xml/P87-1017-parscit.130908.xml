<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000011">
<sectionHeader confidence="0.580475" genericHeader="method">
CONTEXT-FREENESS OF THE LANGUAGE ACCEPTED
BY MARCUS&apos; PARSER
R. Nozohoor-Farshi
</sectionHeader>
<affiliation confidence="0.943937">
School of Computing Science, Simon Fraser University
Burnaby, British Columbia, Canada V5A 1S6
</affiliation>
<sectionHeader confidence="0.552063" genericHeader="method">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.9998846">
In this paper, we prove that the set of sentences parsed
by Marcus&apos; parser constitutes a context-free language. The
proof is carried out by constructing a deterministic pushdown
automaton that recognizes those strings of terminals that are
parsed successfully by the Marcus parser.
</bodyText>
<sectionHeader confidence="0.927808" genericHeader="method">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999835">
While Marcus [4) does not use phrase structure rules as
base grammar in his parser, he points out sonic correspondence
between the use of a base rule and the way packets are
activated to parse a construct. Charniak [2] has also assumed
some phrase structure base grammar in implementing a Marcus
style parser that handles ungrammatical situations. However
neither has suggested a type for such a grammar or the
language accepted by the parser. Berwick [1] relates Marcus&apos;
parser to LR(k.t) context-free grammars. Similarly, in [5] and
[6) we have related this parser to LRRL(k) grammars.
Inevitably, these raise the question of whether the string set
parsed by Marcus&apos; parser is a context-free language.
In this paper, we provide the answer for the above
queLcion by showing formally that the set of sentences accepted
by Marcus&apos; parser constitutes a context-free language. Our
proof is based on simulating a simplified version of the parser
by a pushdown automaton. Then some modifications of the
PDA are suggested in order to ascertain that Marcus&apos; parser,
regardless of the structures it puts on the input sentences,
accepts a context-free set of sentences. Furthermore, since the
resulting PDA is a deterministic one, it confirms the
determinism of the language parsed by this parser. Such a
proof also provides a justification for assuming a context-free
underlying grammar in automatic generation of Marcus type
parsers as discussed in [5] and [6].
</bodyText>
<listItem confidence="0.699466">
2. Assumption of a finite size buffer
</listItem>
<bodyText confidence="0.9998738125">
Marcus&apos; parser employs two data structures: a pushdown
stack which holds the constructs yet to be completed, and a
finite size buffer which holds the lookaheads. The lookaheads
are completed constructs as well as bare terminals. Various
operations are used to manipulate these data structures. An
&amp;quot;attention shift&amp;quot; operation moves a window of size k=3 to a
given position on the buffer. This occurs in parsing some
constructs, e.g., some NP&apos;s, in particular when a buffer node
other than the first indicates start of an NP. &amp;quot;Restore buffer&amp;quot;
restores the window to its previous position before the last
&amp;quot;attention shift&amp;quot;. Marcus suggests that the movements of the
window can be achieved by employing a stack of displacements
from the beginning of the buffer, and in general he suggests
that the buffer could be unbounded on the right. But in
practice, he notes that he has not found a need for more than
five cells, and PARS1FAL does not use a stack to implement
the window or virtual buffer.
A comment regarding an infinite buffer is in place here.
An unbounded buffer would yield a parser with two stacks.
Generally, such parsers characterize context-sensitive languages
and are equivalent to linear bounded automata. They have also
been used for parsing some context-free languages. In this role
they may hide the non-determinism of a context-free language
by storing an unbounded number of lookaheads. For example.
LR-regular [3], BCP(rn,n). IR(k.a.) and FSPA(k) parsers [8] are
such parsers. Furthermore, basing parsing decisions on the
whole left contexts and k lookaheads in them has often resulted
in defining classes of context-free (context-sensitive) grammars
with =decidable membership. LR-regular, LR(k,0) and
FSPA(k) are such classes. The class of GLRRL(k) grammars
with unbounded buffer (defined in (5)) seems to be the known
exception in this category that has decidable membership.
Walters [9] considers context-sensitive grammars with
deterministic two-stack parsers and shows the undecidability of
the membership problem for the class of such grammars.
In this paper we assume that the buffer in a Marcus
style parser can only be of a finite size b (e.g., b=5 in Marcus&apos;
parser). The limitation on the size of the buffer has two
important consequences. First, it allows a proof for the
context-freeness of the language to be given in terms of a
PDA. Second, it facilitates the design of an effective algorithm
for automatic generation of a parser. (However, we should add
that: 1- sonic Marcus style parsers that use an unbounded
buffer in a constrained way. e.g„ by restricting the window to
the k rightmost elements of the buffer, are equivalent to
pushdown automata. 2- Marcus style parsers with unbounded
buffer, similar to GLRRL parsers, can still be constructed for
those languages which are known to be context-free.)
</bodyText>
<page confidence="0.998245">
117
</page>
<sectionHeader confidence="0.890407" genericHeader="method">
3. Simplified parser
</sectionHeader>
<bodyText confidence="0.982543458333333">
A few restrictions on Marcus&apos; parser will prove to be
convenient in outlining a proof for the context—freeness of the
language accepted by it.
(i) Prohibition of features:
Marcus allows syntactic nodes to have features containing the
grammatical properties of the constituents that they represent
For implementation purposes, the type of a node is also
considered as a feature. However, here a distinction will be
made between this feature and others. We consider the type of
a node and the node itself to convey the same concept (i.e., a
non—terminal symbol). Any other feature is disallowed. In
Marcus&apos; parser, the binding of traces is also implemented
through the use of features. A trace is a null deriving
non—terminal (e.g., an NP) that has a feature pointing to
another node. i.e., the binding of the trace. We should stress at
the outset that Marcus&apos; parser outputs the annotated surface
structure of an utterance and traces are intended to be used by
the semantic component to recover the underlying
predicate/argument structure of the utterance. Therefore one
could put aside the issue of trace registers without affecting any
argument that deals with the strings accepted by the parser. i.e.,
frontiers of surface structures. We will reintroduce the features
in the generalized form of PDA for the completeness of the
simulation.
</bodyText>
<subsectionHeader confidence="0.935005">
Non—accessibility of the parse tree:.
</subsectionHeader>
<bodyText confidence="0.9997642">
Although most of the information about the left context is
captured through the use of the packeting mechanism in
Marcus&apos; parser, he nevertheless allows limited access to the
nodes of the partial parse tree (besides the current active node)
in the action pans of the grammar rules. In some rules, after
the initial pattern matches, conditional clauses test for some
property of the parse tree. These tests are limited to the left
daughters of the current active node and the last cyclic node
(NP or S) on the stack and its descendants. It is plausible to
eliminate tree accessibility entirely through adding new packets
and/or simple flags. In the simplified parser, access to the
partial parse tree is disallowed. However, by modifying the
stack symbols of the. PDA we will later show that the proof of
context—freeness carries over to the general parser (that tests
limited nodes of parse tree).
</bodyText>
<subsectionHeader confidence="0.792854">
OM Atomic actions:
</subsectionHeader>
<bodyText confidence="0.996914416666667">
Action segments in Marcus&apos; grammar rules may contain a series
of basic operations. To simplify the simulation, we assume that
in the simplified parser actions are atomic. Breakdown of a
compound action into atomic actions can be achieved by
keeping the first operation in the original rule and introducing
new singleton packets containing a default pattern and a
remaining operation in the action part. These packets will
successively deactivate themselves and activate the next packet
much like &amp;quot;run &lt;rule&gt; next&amp;quot;s in PIDGIN. The last packet will
activate the first if the original rule leaves the packet still
active. Therefore in the simplified parser action segments are of
the following forms:
</bodyText>
<listItem confidence="0.999841545454546">
(1) Activate packetsl; [deactivate packets2].
(2) Deactivate packetsl; (activate packets2).
(3) Attach ith; [deactivate packetsl] ; [activate packets2].
(4) [Deactivate packets1); create node; activate packets2.
(5) [Deactivate packetsl]; cattach node; activate packets2.&apos;
(6) Drop; [deactivate packetsl]; [activate packets2].
(7) Drop into buffer; [deactivate packetsl] ;
[activate packets2].
(8) Attention shift (to ith cell): [deactivate packetsl] ;
[activate packets2].
(9) Restore buffer; [deactivate packetsl]; [activate packets2].
</listItem>
<bodyText confidence="0.999474666666667">
Note that &apos;forward attention ,shift has no explicit command in
Marcus&apos; rules. An &amp;quot;AS&amp;quot; prefix in the name of a rule implies
the operation. Backward window move has an explicit command
&amp;quot;restore buffer&amp;quot;. The square brackets in the above forms
indicate optional parts. Feature assignment operations are
ignored for the obvious reason.
</bodyText>
<listItem confidence="0.435898">
4. Simulation of the simplified parser
</listItem>
<bodyText confidence="0.975716962962963">
In this section we construct a PDA equivalent to the
simplified parser. This PDA recognizes the same string set that
is accepted by the parser. Roughly, the states of the PDA are
symbolized by the contents of the parser&apos;s buffer, and its stack
symbols are ordered pairs consisting of a non—terminal symbol
(i.e., a stack symbol of the parser) and a set of packets
associated with that symboL
Let N be the set of non—terminal symbols, and Z be
the set of terminal symbols of the parser. We assume the top
S node. i.e., the root of a parse tree, is denoted by So, a
distinct element of N. We also assume that a final packet is
added to the PIDGIN grammar. When the parsing of a
sentence is completed, the activation of this packet will cause
the root node So to be dropped into the buffer, rather than
being left on the stack. Furthermore, let P denote the set of
all packets of rules, and 2P the powerset of P. and let
P.13,.P3,... be elements of 2P. When a set of packets P is active,
the pattern segments of the rules in these packets are compared
with the current active node and contents of the virtual buffer
(the window). Then the action segment of a rule with highest
priority that matches is executed. In effect the operation of the
parser can be characterized by a partial function M from active
packets, current active node and contents of the window into
atomic actions, i.e.,
M: 2(N(1))(V(k) 4 ACTIONS
&amp;quot;Cattach&amp;quot; is used as a short notation for &amp;quot;create and
attach&amp;quot;.
</bodyText>
<page confidence="0.992844">
118
</page>
<bodyText confidence="0.98373312">
where V =NU Z. V( k ) VO+V1+-+VIc and ACTIONS is the
set of atomic actions (1) - (9) discussed in the previous section.
Now we can construct the equivalent PDA
,q,,,Zo.f) in the following way.
Z = the set of input symbols of A, is the set of terminal
symbols in the simplified parser.
r = the set of stack symbols [xm, where XeN is a
non-terminal symbol of the parser and P is a set of packets.
Q = the set of states of the PDA, each of the form
&lt;P,,P,,buffer&gt;, where P, and P, are sets of packets. In general
P, and P: are empty sets except for those states that represent
dropping of a current active node in the parser. P, is the set
of packets to be activated explicitly after the drop operation,
and P2 is the set of those packers that are deactivated. &amp;quot;buffer&amp;quot;
is a suing in a (1)V)(m)IV(k), where 0.1m5b-k. The last
vertical bar in &amp;quot;buffer&amp;quot; denotes the position of the current
window in the parser and those on the left indicate former
window positions.
q, = the initial state = &lt;0,0,1 X&gt;, where X denotes the null
string.
f st the final state = &apos;.o4 S,&gt;. This state corresponds to the
outcome of an activation of the final packet in the parser. In
this way, i.e.. by dropping the S, node into the buffer, we can
show the acceptance of a sentence simultaneously by empty
stack and by final state.
Z, = the start symbol = [ So,P0 where P, is the set of initial
packets, e.g., I SS-Start, C-Pool) in Marcus&apos; parser.
6 = the move function of the PDA, defined in the following
way:
Let P denote a set of active packets, X an active node
and Wi • n 5 k, the content of a window. Let
0 I W1W2...Wn 3 be a string (representing the buffer) such that
e (1(1) V)(b-k) and $e V&apos; where Length(a &apos;W1W2...Wn )5b,
and 0 &apos; is the string a in which vertical bars are erased.
Non- x- moves: The non-)-moves of the PDA A correspond to
bringing the input tokens into the buffer for examination by
the parser. In Marcus&apos; parser input tokens come to the
attention of parser as they are needed. Therefore, we can
assume that when a rule tests the contents of n cells of the
window and there are fewer tokens in the buffer, terminal
symbols will be brought into the buffer. More specifically, if
M(P,X,W1 ...Wn) has a defined value (i.e., P contains a packet
with a rule that has pattern segment [X] [W1]...(Wn) ), then
6(&lt;0,0,a1W1...Wj&gt;,Wi+1.[X.11) z
(&lt;0 ,0 ,E, I Wi...Wi Wp.i&gt;.[X,PD for all a, and for j 0, ..., n-1
and
X - moves. By )-moves, the PDA mimics the actions of the
parser on successful matches. Thus the 6-function on X input
corresponding to each individual atomic action is determined
according to one of the following cases.
</bodyText>
<figure confidence="0.957696255813953">
Cases (1) and (2):
If M(P.X,W1W2...Wn) = &amp;quot;activate Pi ; deactivate P2&apos; (or
&amp;quot;deactivate F2; activate P1&apos;), then
6 (&lt;0 ,0 WiW2...Wnfi&gt;,X,EX,P))
(&lt;0 Ai ,a1W1W2...Wnfi&gt;.[X,(P U )-P2]) for all a and
Case (3):
If = &amp;quot;attach ith (normally i is 1);
deactivate Pi; activate P2&amp;quot;, then =
[x.(p u P2 )-P1] ) for all
a ,fi.
Cases (4) and (5):
If M(P,X,W1...Wn)= &amp;quot;deactivate F1; create/cattach Y; activate
P2&amp;quot;, then
6 (&lt;0 ,0 ,a1W1...Wn fi&gt;,X1X,11)
(&lt;0,0 ,a I Wi...Wn 8&gt;, [X,P-P1][Y ,P2)) for all a and # .
Case (6):
If M(P,X,Wi...Wn) = &amp;quot;drop: deactivate F1; activate F2&apos;. then
6 (&lt;0 ,0 ,E, Wi...Wn ) = (&lt;P2 Wi...Wn &gt;,X) for all
a and , and furthermore
6(&lt;P2X1021Wi-Wn0&gt;A1Y,P1)
(&lt;0 .0 . a .-Wn &gt;. ri.(1v U F2)-P13) for all a and 8, and
YEN.
The latter move corresponds to the deactivation of the packets
Pi and activation of the packets P2 that follow the dropping of
a current active node.
Case (7):
If M(P,X,Wi...Wa) = &amp;quot;drop into buffer; deactivate P1; activate
P2&apos;. (where n &lt; k), then
6 (&lt;0 .0 .alWi...Wn 8 &gt;,X,[X,P]) = (&lt;P2.Pi,0 I XWi...Wn &gt;,x ) for
all a and 8, and furthermore
6 (4&apos;2,141XWJ..-Wn8&gt;A.[Y.11)
(&lt;0 ,ii ,E, I XNVI....Wn Et&gt;, [Y.(P&apos; u P2 )-P1] ) for all a and 8, and
for all P&apos;e 2r and YE N.
Case (8):
If M(P,X,Wi...Wi ...Wn) = &amp;quot;shift attention to ith cell; deactivate
; activate F2&apos;, then
6 (&lt;0 .0 .01 Wi...Wi ...Wn &gt;.X.IX.PD
[X,(P u P2 )-131) ) for all a and $.
Case (9):
If M(P,X,W1 ...Wn )2. &amp;quot;restore buffer; deactivate F1; activate F2&apos;,
then
6 (&lt;0 ,0 4, 11 a 21 Wi...Wn 8&gt;,XJX.P] )
(&lt;0 ,0 ,10 ,Wi...Wn #&gt;, [X,(P u P2 )-Pi] ) for all 01,02 and 9
</figure>
<bodyText confidence="0.9746599">
such that 02 contains no vertical bar.
Now from the construction of the PDA, it is obvious
that A accepts those strings of terminals that are parsed
successfully by the simplified parser. The reader may note that
the value of 6 is undefined for the &apos;cases in which
M(X.P.W1-.Wn) has multiple values. This accounts for the fact
that Marcus&apos; parser behaves in a deterministic way.
Furthermore, many of the states of A are unreachable. This is
due to the way we constructed the FDA, in which we
considered activation of every subset of P with any active node
</bodyText>
<page confidence="0.998126">
119
</page>
<bodyText confidence="0.9283648">
and any lookahead window.
5. Simulation of the general parser
It is possible to lift the restrictions on the simplified
parser by modifying the FDA. Here, we describe how Marcus&apos;
parser can be simulated by a generalized form of the FDA.
</bodyText>
<subsectionHeader confidence="0.414744">
(i) Non-atomic actions:
</subsectionHeader>
<bodyText confidence="0.999083">
The behaviour of the parser with non-atomic actions can be
described in terms of M&apos;eMe, a sequence of compositions of
M, which in turn can be specified by a sequence 6&apos; in 6e.
</bodyText>
<subsectionHeader confidence="0.8996655">
fill AccessibilitY of descendants of current active node, and
current cyclic node:
</subsectionHeader>
<bodyText confidence="0.989215">
What parts of the partial parse tree are accessible in Marcus&apos;
parser seems to be a moot point. Marcus [43 states
</bodyText>
<construct confidence="0.607452375">
the parser can modify or directly examine exactly two
nodes in the active node stack... the current active node
and S or NP node closest to the bottom of stack...
called the dominating cyclic node... or... current cyclic
node... The parser is also fire to examine the
descendants of these two nodes..., cdthough the parser
cannot modify them. It does this by specifying the
exact path to the descendant it wishes to examine.&apos;
</construct>
<bodyText confidence="0.998111142857143">
The problem is that whether by descendants of these
two nodes, one means the immediate daughters, or descendants
at arbitrary levels. It seems plausible that accessibility of
immediate descendants is sufficient. To explore this idea, we
need to examine the reason behind partial tree accesses in
Marcus&apos; parser. It could be argued that tree accessibility serves
two purposes:
</bodyText>
<listItem confidence="0.718284666666667">
(1) Examining what daughters are attached to the current active
node considerably reduces the number of packet rules one
needs in write.
</listItem>
<bodyText confidence="0.980497044117647">
(2) Examining the current cyclic node and its daughters serves
the purpose of binding traces. Since transformations are applied
in each transformational cycle to a single cyclic node, it seems
unnecessary to examine descendants of a cyclic node at
arbitrarily lower levels.
If Marcus&apos; parser indeed accesses only the immediate
daughters (a brief examination of the sample grammar [4] does
not seem to contradict this), then the accessible part of the a
parse tree can represented by a pair of nodes and their
daughters. Moreover, the set of such pairs of height-one trees
are finite in a grammar. Furthermore, if we extend the access
to the descendants of these two nodes down to a finite fixed
depth (which, in fact seems to have a supporting evidence from
X theory and C-command), we will still be able to represent
the accessible parts of parse trees with a finite set of finite
sequences of fixed height trees.
A second interpretation of Marcus&apos; statement is that
descendants of the current cyclic node and current active node
at arbitrarily lower levels are accessible to the parser. However,
in the presence of non-cyclic recursive constructs, the notion of
giving an exact path to a descendant of the current active or
current cyclic node would be inconceivable; in fact one can
argue that in such a situation parsing cannot be achieved
through a finite number of rule packets. The reader is
reminded here that PIDGIN (unlike most programming
languages) does not have iterative or recursive constructs to test
the conditions that are needed under the latter interpretation.
Thus, a meaningful assumption in the second case is to
consider every recursive node to be cyclic, and to limit
accessibility to the subtree dominated by the current cyclic node
in which branches are pruned at the lower cyclic nodes. In
general, we may also include cyclic nodes at fixed recursion
depths, but again branches of a cyclic node beyond that must
be pruned. In this manner, we end up with a finite number of
finite sequences (hereafter called forests) of finite trees
representing the accessible segments of partial parse trees.
Our conclusion is that at each stage of parsing the
accessible segment of a parse tree, regardless of how we
interpret Marcus&apos; statement, can be represented by a forest of
trees that belong to a finite set TN,h. TN,h denotes the set of
all trees with non-terminal roots and of a maximum height h.
In the general case, this information is in the form of a forest,
rather than a pair of trees, because we also need to account for
the unattached subtrees that reside in the buffer and may
become an accessible part of an active node in the future.
Obviously, these subtrees will be pruned to a maximum height
h-1. Hence, the operation of the parser can be characterized by
the partial function M from active packets, subtrees rooted at
current active and cyclic nodes, and contents of the window into
compound actions, i.e.,
At 2PX(TN,h U fX1)ATC,h U 1X»XCrN,h-1 U
-■ ACTIONS.
where Tc,h is the subset of TN,h consisting of the trees with
cyclic roots.
In the PDA simulating the general parser, the set of
stack symbols r would be the set of triples [Ty.Tx.11, where
Ty and Tx are the subtrees rooted at current cyclic node Y
and current active node X, and P is the set of packets
associated with X. The states of this PDA will be of the form
&lt;X,PI,P1,buffer&gt;. The last three elements are the same as
before, except that the buffer may now contain subtrees
belonging to TH,h_i. (Note that in the simple case, when h=1.
The first entry is usually ), except that when the
current active node X is dropped, this element is changed to
Tx. The subtree Tx is the tree dominated by X. i.e., Tx.
pruned to the height h-1.
Definition of the move function for this PDA is very
similar to the simplified case. For example, under the
</bodyText>
<page confidence="0.988237">
120
</page>
<bodyText confidence="0.999870142857143">
assumption that the pair of height—one trees rooted at current
cyclic node and current active node is accessible to the parser.
the definition of 6 function would include the following
statement among others:
If g(P.Tx,Ty ...%) • &amp;quot;drop; deactivate P1; activate P2&amp;quot;.
(where Tx and Ty represent the height—one trees rooted at the
current active and cyclic nodes X and Y), then
</bodyText>
<equation confidence="0.998516">
6 (&lt;)•0•0411W1—W1S&gt;. XITY•TX•11)
(&lt;X.P2 INV 1.—W &gt;.x) for all a and ,9. Furthermore,
(&lt;X12,P1 I Wi &gt;, X ,[Ty ,Tz,P1) •
</equation>
<bodyText confidence="0.97048703125">
(4X 0,0 ...Wi 8 &gt;, [Ty ,Tz,(F U P2 )—P1] ) for all (Tz,P&apos;) in
TN, 12&apos; such that Tz has X as its rightmost leaf.
In the more general case (i.e., when h &gt; 1), as we noted in
the above, the first entry in the representation of the state will
be Tx, rather than its root node X. In that case, we will
replace the rightmost leaf node of Tz. i.e.. the nonterminal X.
with the subtree Tx. This mechanism of using the first entry
in the representation of a state allows us to relate attachments.
Also, in the simple case (h=1) the mechanism could be used to
convey feature information to the higher level when the current
aclive node is dropped. More specifically, there would be a
bundle of features associated with each symbol. When the node
X is dropped, its associated features would be copied to the X
symbol appearing in the state of the PDA (via first 6—move).
The second 8—move allows us to copy the features from the X
symbol in the state to the X node dominated by the node Z.
02. Accommodation of features:
The features used in Marcus&apos; parser are syntactic in nature and
have finite domains. Therefore the set of attributed symbols in
that parser constitute a finite set. Hence syntactic features can
be accommodated in the construction of the PDA by allowing
complex non—terminal symbols, i.e., attributed symbols instead of
simple ones.
Feature assignments can be simulated by replacing the
top stack symbol in the FDA. For example, under our previous
assumption that two height—one trees rooted at current active
node and current cyclic node are accessible to the parser, the
definition of 8 function will include the following statement:
If M(1),Tx A•TY : B•Wl—Wn ) &amp;quot;assign features A&apos; to current
active node; assign features B&apos; to current cyclic node; deactivate
P1; activate F2&amp;quot; (where A,A&apos;,B and B&apos; are sets of features),
then
</bodyText>
<sectionHeader confidence="0.95333" genericHeader="method">
6 (&lt;x,0,0411wi...Wi &gt;,X, [Ty ,B,Tx :A.PD =
</sectionHeader>
<bodyText confidence="0.999921272727273">
(&lt;)0S541W1...W18&gt;, [TY :B u 13..TX:A U A&apos;.(P U P2 )41] ) for
all ci and 8.
Now, by lifting all three restrictions introduced on the
simplified parser, it is possible to conclude that Marcus&apos; parser
can be simulated by a pushdown automaton, and thus accepts a
context—free set of strings. Moreover, as one of the reviewers
has suggested to us, we could make our result more general if
we incorporate a finite number of semantic tests (via a finite
oracle set) into the parser. We could still simulate the parser
by a FDA.
Furthermore, the pushdown automaton which we have
constructed here is a deterministic one. Thus, it confirms the
determinism of the language which is parsed by Marcus&apos;
mechanism. We should also point out that our notion of a
context—free language being deterministic differs from the
deterministic behavour of the parser as described by Marcus.
However, since every deterministic language can be parsed by a
deterministic parser, our result adds more evidence to believe
that Marcus&apos; parser does not hide non—determinism in any
form.
It is easy to obtain (through a standard procedure) an
LR(1) grammar describing the language accepted by the
generalized PDA. Although this grammar will be equivalent to
Marcus&apos; PIDGIN grammar (minus any semantic considerations),
and it will be a right cover for any underlying surface grammar
which may be assumed in constructing the Marcus parser, it
will suffer from being an unnatural description of the language.
Not only may the resulting structures be hardly usable by any
reasonable semantic/pragmatics component, but also parsing
would be inefficient because of the huge number of
non—terminals and productions.
In automatic generation of Marcus—style parsers, one can
assume either a context—free or a context—sensitive grammar (as
a base grammar) which one feels is naturally suitable for
describing surface structures. However, if one chooses a
context—sensitive grammar then one needs to make sure that it
only generates a context—free language (which is unsolvable in
general). In 5] and (6).we have proposed a context—free base
grammar which is augmented with syntactic features (e.g.,
person, tense, etc.) much like attributed grammars in compiler
writing systems. An additional advantage with this scheme is
that semantic features can also be added to the nodes without
an extra effort. In this way one is also able to capture the
context—sensitivity of a language.
</bodyText>
<sectionHeader confidence="0.997747" genericHeader="conclusions">
6. Conclusions
</sectionHeader>
<bodyText confidence="0.999989583333333">
We have shown that the information examined or
modified during Marcus parsing (i.e., segments of partial parse
trees, contents of the buffer and active packets) for a PIDGIN
grammar is a finite set. By encoding this information in the
stack symbols and the states of a deterministic pushdown
automaton, we have shown that the resulting PDA is equivalent
to the Marcus parser. In this way we have proved that the set
of surface sentences accepted by this parser is a context—free
set.
An important factor in this simulation has been the
assumption that the buffer in a Marcus style parser is bounded.
It is unlikely that all parsers with unbounded buffers written in
</bodyText>
<page confidence="0.993187">
121
</page>
<bodyText confidence="0.999964">
this style can be simulated by deterministic pushdown automata.
Parsers with unbounded buffers (i.e.. two-stack parsers) are used
either for recognition of context-sensitive languages, or if they
parse context-free languages, possibly to hide the
non-determinism of a language by storing an unlimited number
of lookaheads in the buffer. However. this does not mean that
some Marcus-type parsers that use an unbounded buffer in a
constrained way are not equivalent to pushdown auttimata.
Shipman and Marcus [7] consider a model of Marcus&apos; parser in
which the active node stack and buffer are combined to give a
single data structure that holds both complete and incomplete
subtrees. The original stack nodes and their lookaheads
alternately reside on this structure. Letting an unlimited number
of completed constructs and bare terminals reside on the new
structure is equivalent to having an unbounded buffer in the
original model. Given the restriction that anadiments and drops
are always limited to the k+1 rightmost nodes of this data
strucmre, it is possible to show that a parser in this model with
an unbounded buffer still can be simulated with an ordinary
pushdown automaton. (The equivalent condition in the original
model is to restrict the window to the k rightmost elements of
the buffer. However simulation of the single structure parser is
much more straightforward.)
</bodyText>
<sectionHeader confidence="0.995226" genericHeader="acknowledgments">
ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.999787714285714">
The author is indebted to Dr. Len Schubert for posing
the question and carefully reviewing an early draft of this
paper, and to the referees for their helpful comments. The
research reported here was supported by the Natural Sciences
and Engineering Research Council of Canada operating grants
A8818 and A9203 at the universities of Alberta and Simon
Fraser.
</bodyText>
<sectionHeader confidence="0.998077" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999975318181818">
[1] R.C. Berwick. The Acquistion of Syntactic Knowledge. MIT
Press. 1985.
[2] E. Ovuniak. A parser with something for everyone.
Parsing natural language, ed. M. King, pp. 117-149. Academic
Press, London. 1983.
[3] K. Culik II and R. Cohen. LR-regular grammars: an
extension of LR(k) grammars. Journal of Computer and System
Sciences, vol. 7, pp. 66-96. 1973.
[4] M.P. Marcus. A Theory of Syntactic Recognition for
Natural Language. mrr Press, Cambridge. MA 1980.
[5] It Nozohoor-Fushi. LRRL(k) grammus: a left to right
parsing technique with reduced lookaheads. Ph.D. thesis, Dept.
of Computing Science. University of Alberta- 1986-
[6] R. Nozohoor-Farshi. On formalizations of Marcus&apos; parser.
COLING-86. 1986.
[7] D.W. Shipman and M.P. Marcus. Towards minimal data
=awes for detenninistic parsing. IJCAI-79. 1979.
[8] T.G. Szymanski and LH. Williams. Non-canonical
extensions of bottom-up parsing techniques. SIAM Journal of
Computing, vol. 5, no. 2. pp. 231-250. June 1976.
[9] D.A. Walters. Deterministic context-sensitive languages.
Information and Control. vol. 17, pp. 14-6L 1970.
</reference>
<page confidence="0.997493">
122
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.738450">
<title confidence="0.990183">CONTEXT-FREENESS OF THE LANGUAGE ACCEPTED</title>
<author confidence="0.920242">BY MARCUS&apos; PARSER R Nozohoor-Farshi</author>
<affiliation confidence="0.999992">School of Computing Science, Simon Fraser University</affiliation>
<address confidence="0.993242">Burnaby, British Columbia, Canada V5A 1S6</address>
<abstract confidence="0.981497166666667">In this paper, we prove that the set of sentences parsed by Marcus&apos; parser constitutes a context-free language. The proof is carried out by constructing a deterministic pushdown automaton that recognizes those strings of terminals that are parsed successfully by the Marcus parser.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R C Berwick</author>
</authors>
<title>The Acquistion of Syntactic Knowledge.</title>
<date>1985</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="936" citStr="[1]" startWordPosition="144" endWordPosition="144">ng a deterministic pushdown automaton that recognizes those strings of terminals that are parsed successfully by the Marcus parser. 1. Introduction While Marcus [4) does not use phrase structure rules as base grammar in his parser, he points out sonic correspondence between the use of a base rule and the way packets are activated to parse a construct. Charniak [2] has also assumed some phrase structure base grammar in implementing a Marcus style parser that handles ungrammatical situations. However neither has suggested a type for such a grammar or the language accepted by the parser. Berwick [1] relates Marcus&apos; parser to LR(k.t) context-free grammars. Similarly, in [5] and [6) we have related this parser to LRRL(k) grammars. Inevitably, these raise the question of whether the string set parsed by Marcus&apos; parser is a context-free language. In this paper, we provide the answer for the above queLcion by showing formally that the set of sentences accepted by Marcus&apos; parser constitutes a context-free language. Our proof is based on simulating a simplified version of the parser by a pushdown automaton. Then some modifications of the PDA are suggested in order to ascertain that Marcus&apos; pars</context>
</contexts>
<marker>[1]</marker>
<rawString>R.C. Berwick. The Acquistion of Syntactic Knowledge. MIT Press. 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Ovuniak</author>
</authors>
<title>A parser with something for everyone. Parsing natural language,</title>
<date>1983</date>
<pages>117--149</pages>
<editor>ed. M. King,</editor>
<publisher>Academic Press,</publisher>
<location>London.</location>
<contexts>
<context position="699" citStr="[2]" startWordPosition="107" endWordPosition="107">ng Science, Simon Fraser University Burnaby, British Columbia, Canada V5A 1S6 ABSTRACT In this paper, we prove that the set of sentences parsed by Marcus&apos; parser constitutes a context-free language. The proof is carried out by constructing a deterministic pushdown automaton that recognizes those strings of terminals that are parsed successfully by the Marcus parser. 1. Introduction While Marcus [4) does not use phrase structure rules as base grammar in his parser, he points out sonic correspondence between the use of a base rule and the way packets are activated to parse a construct. Charniak [2] has also assumed some phrase structure base grammar in implementing a Marcus style parser that handles ungrammatical situations. However neither has suggested a type for such a grammar or the language accepted by the parser. Berwick [1] relates Marcus&apos; parser to LR(k.t) context-free grammars. Similarly, in [5] and [6) we have related this parser to LRRL(k) grammars. Inevitably, these raise the question of whether the string set parsed by Marcus&apos; parser is a context-free language. In this paper, we provide the answer for the above queLcion by showing formally that the set of sentences accepted</context>
</contexts>
<marker>[2]</marker>
<rawString>E. Ovuniak. A parser with something for everyone. Parsing natural language, ed. M. King, pp. 117-149. Academic Press, London. 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Culik</author>
<author>R Cohen</author>
</authors>
<title>LR-regular grammars: an extension of LR(k) grammars.</title>
<date>1973</date>
<journal>Journal of Computer and System Sciences,</journal>
<volume>7</volume>
<pages>66--96</pages>
<contexts>
<context position="3406" citStr="[3]" startWordPosition="543" endWordPosition="543">ght. But in practice, he notes that he has not found a need for more than five cells, and PARS1FAL does not use a stack to implement the window or virtual buffer. A comment regarding an infinite buffer is in place here. An unbounded buffer would yield a parser with two stacks. Generally, such parsers characterize context-sensitive languages and are equivalent to linear bounded automata. They have also been used for parsing some context-free languages. In this role they may hide the non-determinism of a context-free language by storing an unbounded number of lookaheads. For example. LR-regular [3], BCP(rn,n). IR(k.a.) and FSPA(k) parsers [8] are such parsers. Furthermore, basing parsing decisions on the whole left contexts and k lookaheads in them has often resulted in defining classes of context-free (context-sensitive) grammars with =decidable membership. LR-regular, LR(k,0) and FSPA(k) are such classes. The class of GLRRL(k) grammars with unbounded buffer (defined in (5)) seems to be the known exception in this category that has decidable membership. Walters [9] considers context-sensitive grammars with deterministic two-stack parsers and shows the undecidability of the membership p</context>
</contexts>
<marker>[3]</marker>
<rawString>K. Culik II and R. Cohen. LR-regular grammars: an extension of LR(k) grammars. Journal of Computer and System Sciences, vol. 7, pp. 66-96. 1973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
</authors>
<title>A Theory of Syntactic Recognition for Natural Language. mrr Press,</title>
<date>1980</date>
<location>Cambridge. MA</location>
<contexts>
<context position="16916" citStr="[4]" startWordPosition="2855" endWordPosition="2855">in Marcus&apos; parser. It could be argued that tree accessibility serves two purposes: (1) Examining what daughters are attached to the current active node considerably reduces the number of packet rules one needs in write. (2) Examining the current cyclic node and its daughters serves the purpose of binding traces. Since transformations are applied in each transformational cycle to a single cyclic node, it seems unnecessary to examine descendants of a cyclic node at arbitrarily lower levels. If Marcus&apos; parser indeed accesses only the immediate daughters (a brief examination of the sample grammar [4] does not seem to contradict this), then the accessible part of the a parse tree can represented by a pair of nodes and their daughters. Moreover, the set of such pairs of height-one trees are finite in a grammar. Furthermore, if we extend the access to the descendants of these two nodes down to a finite fixed depth (which, in fact seems to have a supporting evidence from X theory and C-command), we will still be able to represent the accessible parts of parse trees with a finite set of finite sequences of fixed height trees. A second interpretation of Marcus&apos; statement is that descendants of </context>
</contexts>
<marker>[4]</marker>
<rawString>M.P. Marcus. A Theory of Syntactic Recognition for Natural Language. mrr Press, Cambridge. MA 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>It Nozohoor-Fushi</author>
</authors>
<title>LRRL(k) grammus: a left to right parsing technique with reduced lookaheads.</title>
<date>1986</date>
<tech>Ph.D. thesis,</tech>
<institution>Dept. of Computing Science. University of Alberta-</institution>
<contexts>
<context position="1011" citStr="[5]" startWordPosition="154" endWordPosition="154">inals that are parsed successfully by the Marcus parser. 1. Introduction While Marcus [4) does not use phrase structure rules as base grammar in his parser, he points out sonic correspondence between the use of a base rule and the way packets are activated to parse a construct. Charniak [2] has also assumed some phrase structure base grammar in implementing a Marcus style parser that handles ungrammatical situations. However neither has suggested a type for such a grammar or the language accepted by the parser. Berwick [1] relates Marcus&apos; parser to LR(k.t) context-free grammars. Similarly, in [5] and [6) we have related this parser to LRRL(k) grammars. Inevitably, these raise the question of whether the string set parsed by Marcus&apos; parser is a context-free language. In this paper, we provide the answer for the above queLcion by showing formally that the set of sentences accepted by Marcus&apos; parser constitutes a context-free language. Our proof is based on simulating a simplified version of the parser by a pushdown automaton. Then some modifications of the PDA are suggested in order to ascertain that Marcus&apos; parser, regardless of the structures it puts on the input sentences, accepts a </context>
</contexts>
<marker>[5]</marker>
<rawString>It Nozohoor-Fushi. LRRL(k) grammus: a left to right parsing technique with reduced lookaheads. Ph.D. thesis, Dept. of Computing Science. University of Alberta- 1986-</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Nozohoor-Farshi</author>
</authors>
<title>On formalizations of Marcus&apos;</title>
<date>1986</date>
<pages>86</pages>
<contexts>
<context position="1934" citStr="[6]" startWordPosition="302" endWordPosition="302"> context-free language. Our proof is based on simulating a simplified version of the parser by a pushdown automaton. Then some modifications of the PDA are suggested in order to ascertain that Marcus&apos; parser, regardless of the structures it puts on the input sentences, accepts a context-free set of sentences. Furthermore, since the resulting PDA is a deterministic one, it confirms the determinism of the language parsed by this parser. Such a proof also provides a justification for assuming a context-free underlying grammar in automatic generation of Marcus type parsers as discussed in [5] and [6]. 2. Assumption of a finite size buffer Marcus&apos; parser employs two data structures: a pushdown stack which holds the constructs yet to be completed, and a finite size buffer which holds the lookaheads. The lookaheads are completed constructs as well as bare terminals. Various operations are used to manipulate these data structures. An &amp;quot;attention shift&amp;quot; operation moves a window of size k=3 to a given position on the buffer. This occurs in parsing some constructs, e.g., some NP&apos;s, in particular when a buffer node other than the first indicates start of an NP. &amp;quot;Restore buffer&amp;quot; restores the window</context>
</contexts>
<marker>[6]</marker>
<rawString>R. Nozohoor-Farshi. On formalizations of Marcus&apos; parser. COLING-86. 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D W Shipman</author>
<author>M P Marcus</author>
</authors>
<title>Towards minimal data =awes for detenninistic parsing.</title>
<date>1979</date>
<contexts>
<context position="26384" citStr="[7]" startWordPosition="4456" endWordPosition="4456">tyle parser is bounded. It is unlikely that all parsers with unbounded buffers written in 121 this style can be simulated by deterministic pushdown automata. Parsers with unbounded buffers (i.e.. two-stack parsers) are used either for recognition of context-sensitive languages, or if they parse context-free languages, possibly to hide the non-determinism of a language by storing an unlimited number of lookaheads in the buffer. However. this does not mean that some Marcus-type parsers that use an unbounded buffer in a constrained way are not equivalent to pushdown auttimata. Shipman and Marcus [7] consider a model of Marcus&apos; parser in which the active node stack and buffer are combined to give a single data structure that holds both complete and incomplete subtrees. The original stack nodes and their lookaheads alternately reside on this structure. Letting an unlimited number of completed constructs and bare terminals reside on the new structure is equivalent to having an unbounded buffer in the original model. Given the restriction that anadiments and drops are always limited to the k+1 rightmost nodes of this data strucmre, it is possible to show that a parser in this model with an u</context>
</contexts>
<marker>[7]</marker>
<rawString>D.W. Shipman and M.P. Marcus. Towards minimal data =awes for detenninistic parsing. IJCAI-79. 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Williams</author>
</authors>
<title>Non-canonical extensions of bottom-up parsing techniques.</title>
<date>1976</date>
<journal>SIAM Journal of Computing,</journal>
<volume>5</volume>
<pages>231--250</pages>
<contexts>
<context position="3451" citStr="[8]" startWordPosition="549" endWordPosition="549">t found a need for more than five cells, and PARS1FAL does not use a stack to implement the window or virtual buffer. A comment regarding an infinite buffer is in place here. An unbounded buffer would yield a parser with two stacks. Generally, such parsers characterize context-sensitive languages and are equivalent to linear bounded automata. They have also been used for parsing some context-free languages. In this role they may hide the non-determinism of a context-free language by storing an unbounded number of lookaheads. For example. LR-regular [3], BCP(rn,n). IR(k.a.) and FSPA(k) parsers [8] are such parsers. Furthermore, basing parsing decisions on the whole left contexts and k lookaheads in them has often resulted in defining classes of context-free (context-sensitive) grammars with =decidable membership. LR-regular, LR(k,0) and FSPA(k) are such classes. The class of GLRRL(k) grammars with unbounded buffer (defined in (5)) seems to be the known exception in this category that has decidable membership. Walters [9] considers context-sensitive grammars with deterministic two-stack parsers and shows the undecidability of the membership problem for the class of such grammars. In thi</context>
</contexts>
<marker>[8]</marker>
<rawString>T.G. Szymanski and LH. Williams. Non-canonical extensions of bottom-up parsing techniques. SIAM Journal of Computing, vol. 5, no. 2. pp. 231-250. June 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Walters</author>
</authors>
<title>Deterministic context-sensitive languages.</title>
<date>1970</date>
<journal>Information and Control.</journal>
<volume>17</volume>
<pages>14--6</pages>
<contexts>
<context position="3883" citStr="[9]" startWordPosition="612" endWordPosition="612"> hide the non-determinism of a context-free language by storing an unbounded number of lookaheads. For example. LR-regular [3], BCP(rn,n). IR(k.a.) and FSPA(k) parsers [8] are such parsers. Furthermore, basing parsing decisions on the whole left contexts and k lookaheads in them has often resulted in defining classes of context-free (context-sensitive) grammars with =decidable membership. LR-regular, LR(k,0) and FSPA(k) are such classes. The class of GLRRL(k) grammars with unbounded buffer (defined in (5)) seems to be the known exception in this category that has decidable membership. Walters [9] considers context-sensitive grammars with deterministic two-stack parsers and shows the undecidability of the membership problem for the class of such grammars. In this paper we assume that the buffer in a Marcus style parser can only be of a finite size b (e.g., b=5 in Marcus&apos; parser). The limitation on the size of the buffer has two important consequences. First, it allows a proof for the context-freeness of the language to be given in terms of a PDA. Second, it facilitates the design of an effective algorithm for automatic generation of a parser. (However, we should add that: 1- sonic Marc</context>
</contexts>
<marker>[9]</marker>
<rawString>D.A. Walters. Deterministic context-sensitive languages. Information and Control. vol. 17, pp. 14-6L 1970.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>