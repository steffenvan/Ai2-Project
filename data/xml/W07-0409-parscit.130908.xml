<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000333">
<title confidence="0.997964">
Combining Morphosyntactic Enriched Representation with
n-best Reranking in Statistical Translation
</title>
<author confidence="0.929943">
H. Bonneau-Maynard, A. Allauzen, D. D´echelotte and H. Schwenk
</author>
<affiliation confidence="0.866509">
Spoken Language Processing Group
</affiliation>
<address confidence="0.887742">
LIMSI-CNRS, BP 133
91403 Orsay cedex, FRANCE
</address>
<email confidence="0.998465">
{maynard,allauzen,dechelot,schwenk}@limsi.fr
</email>
<sectionHeader confidence="0.995625" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99995535">
The purpose of this work is to explore
the integration of morphosyntactic infor-
mation into the translation model itself, by
enriching words with their morphosyntac-
tic categories. We investigate word dis-
ambiguation using morphosyntactic cate-
gories, n-best hypotheses reranking, and
the combination of both methods with
word or morphosyntactic n-gram lan-
guage model reranking. Experiments
are carried out on the English-to-Spanish
translation task. Using the morphosyn-
tactic language model alone does not
results in any improvement in perfor-
mance. However, combining morphosyn-
tactic word disambiguation with a word
based 4-gram language model results in a
relative improvement in the BLEU score
of 2.3% on the development set and 1.9%
on the test set.
</bodyText>
<sectionHeader confidence="0.999127" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999592">
Recent works in statistical machine translation
(SMT) shows how phrase-based modeling (Och and
Ney, 2000a; Koehn et al., 2003) significantly out-
perform the historical word-based modeling (Brown
et al., 1993). Using phrases, i.e. sequences of
words, as translation units allows the system to pre-
serve local word order constraints and to improve
the consistency of phrases during the translation pro-
cess. Phrase-based models provide some sort of
</bodyText>
<page confidence="0.997692">
65
</page>
<bodyText confidence="0.999984264705882">
context information as opposed to word-based mod-
els. Training a phrase-based model typically re-
quires aligning a parallel corpus, extracting phrases
and scoring them using word and phrase counts. The
derived statistics capture the structure of natural lan-
guage to some extent, including implicit syntactic
and semantic relations.
The output of a SMT system may be difficult to
understand by humans, requiring re-ordering words
to recover its syntactic structure. Modeling language
generation as a word-based Markovian source (an n-
gram language model) discards linguistic properties
such as long term word dependency and word-order
or phrase-order syntactic constraints. Therefore, ex-
plicit introduction of structure in the language mod-
els becomes a major and promising focus of atten-
tion.
However, as of today, it seems difficult to outper-
form a 4-gram word language model. Several stud-
ies have attempted to use morphosyntactic informa-
tion (also known as part-of-speech or POS informa-
tion) to improve translation. (Och et al., 2004) have
explored many different feature functions. Rerank-
ing n-best lists using POS has also been explored by
(Hasan et al., 2006). In (Kirchhoff and Yang, 2005),
a factored language model using POS information
showed similar performance to a 4-gram word lan-
guage model. Syntax-based language models have
also been investigated in (Charniak et al., 2003). All
these studies use word phrases as translation units
and POS information in just a post-processing step.
This paper explores the integration of morphosyn-
tactic information into the translation model itself
by enriching words with their morphosyntactic cat-
</bodyText>
<subsubsectionHeader confidence="0.528838">
Proceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation, pages 65–71,
</subsubsectionHeader>
<affiliation confidence="0.306791">
Rochester, New York, April 2007. c�2007 Association for Computational Linguistics
</affiliation>
<bodyText confidence="0.993363444444445">
egories. The same idea has already been applied
in (Hwang et al., 2007) to the Basic Travel Ex-
pression Corpus (BTEC). To our knowledge, this
approach has not been evaluated on a large real-
word translation problem. We report results on
the TC-STAR task (public European Parliament Ple-
nary Sessions translation). Furthermore, we pro-
pose to combine this approach with classical n-best
list reranking. Experiments are carried out on the
English-to-Spanish task using a system based on the
publicly available Moses decoder.
This paper is organized as follows: In Section
2 we first describe the baseline statistical machine
translation systems. Section 3 presents the consid-
ered task and the processing of the corpora. The
experimental evaluation is summarized in section 4.
The paper concludes with a discussion of future re-
search directions.
</bodyText>
<sectionHeader confidence="0.9754" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.847298133333333">
The goal of statistical machine translation is to pro-
duce a target sentence e from a source sentence f.
Among all possible target language sentences the
one with the highest probability is chosen. The use
of a maximum entropy approach simplifies the intro-
duction of several additional models explaining the
translation process:
e* = arg maxPr(e|f) Aihi(e,f))} (1)
�
= arg max{exp(
e
i
where the feature functions hi are the system
models characterizing the translation process, and
the coefficients Ai act as weights.
</bodyText>
<subsectionHeader confidence="0.999025">
2.1 Moses decoder
</subsectionHeader>
<bodyText confidence="0.999938">
Moses1 is an open-source, state-of-the-art phrase-
based decoder. It implements an efficient beam-
search algorithm. Scripts are also provided to train a
phrase-based model. The popular Giza++ (Och and
Ney, 2000b) tool is used to align the parallel corpora.
The baseline system uses 8 feature functions hi,
namely phrase translation probabilities in both di-
rections, lexical translation probabilities in both di-
rections, a distortion feature, a word and a phrase
</bodyText>
<footnote confidence="0.939966">
1http://www.statmt.org/moses/
</footnote>
<bodyText confidence="0.9998505">
penalty and a trigram target language model. Ad-
ditional features can be added, as described in the
following sections. The weights Ai are typically op-
timized so as to maximize a scoring function on a
development set (Och and Ney, 2002).
The moses decoder can output n-best lists, pro-
ducing either distinct target sentences or not (as
different segmentations may lead to the same sen-
tence). In this work, distinct sentences were always
used.
These n-best lists can be rescored using higher
order language models (word- or syntactic-based).
There are two ways to carry out the rescoring: one,
by replacing the language model score or by adding
a new feature function; two, by performing a log-
linear interpolation of the language model used for
decoding and the new language model. This latter
approach was used in all the experiments described
in this paper. The set of weights is systematically
re-optimized using the algorithm presented below.
</bodyText>
<subsectionHeader confidence="0.999207">
2.2 Weight optimization
</subsectionHeader>
<bodyText confidence="0.9729985">
A common criterion to optimize the coefficients of
the log-linear combination of feature functions is to
maximize the BLEU score (Papineni et al., 2002)
on a development set (Och and Ney, 2002). For
this purpose, the public numerical optimization tool
Condor (Berghen and Bersini, 2005) is integrated in
the following iterative algorithm:
0. Using good general purpose weights, the
Moses decoder is used to generate 1000-best
lists.
</bodyText>
<listItem confidence="0.917566875">
1. The 1000-best lists are reranked using the cur-
rent set of weights.
2. The current hypothesis is extracted and scored.
3. This BLEU score is passed to Condor, which
either computes a new set of weights (the al-
gorithm then proceeds to step 1) or detects that
a local maxima has been reached and the algo-
rithm stops iterating.
</listItem>
<bodyText confidence="0.9980535">
The solution is usually found after about 100 itera-
tions. It is stressed that the n-best lists are generated
only once and that the whole tuning operates only
on the n-best lists.
</bodyText>
<page confidence="0.665222">
66
</page>
<figure confidence="0.613525">
English: IPP declareV VP resumedV VD theDT sessionNN ofIN theDT EuropeanNP ParliamentNP
Spanish: declaroVLfin reanudadoV Ladj elART perodoNC dePREP sesionesNC
delPDEL ParlamentoNC EuropeoADJ
</figure>
<figureCaption confidence="0.998722">
Figure 1: Example of POS-tag enriched bi-text used to train the translation models
</figureCaption>
<subsectionHeader confidence="0.993284">
2.3 POS disambiguation
</subsectionHeader>
<bodyText confidence="0.999993064516129">
It is well-known that syntactic structures vary
greatly across languages. Spanish, for example,
can be considered as a highly inflectional language,
whereas inflection plays only a marginal role in En-
glish.
POS language models can be used to rerank the
translation hypothesis, but this requires tagging the
n-best lists generated by the SMT system. This can
be difficult since POS taggers are not well suited for
ill-formed or incorrect sentences. Finding a method
in which morphosyntactic information is used di-
rectly in the translation model could help overcome
this drawback but also takes account for the syntac-
tic specificities of both source and target languages.
It seems likely that the morphosyntactic informa-
tion of each word will be useful to encode linguis-
tic characteristics, resulting in a sort of word disam-
biguation by considering its morphosyntactic cate-
gory. Therefore, in this work we investigate a trans-
lation model which enriches every word with its syn-
tactic category. The enriched translation units are a
combination of the original word and the POS tag, as
shown in Figure 1. The translation system takes a se-
quence of enriched units as inputs and outputs. This
implies that the test data must be POS tagged before
translation. Likewise, the POS tags in the enriched
output are removed at the end of the process to pro-
vide the final translation hypothesis which contain
only a word sequence. This approach also allows
to carry out a n-best reranking step using either a
word-based or a POS-based language model.
</bodyText>
<sectionHeader confidence="0.887965" genericHeader="method">
3 Task, corpus and tools
</sectionHeader>
<bodyText confidence="0.99986675">
The experimental results reported in this article were
obtained in the framework of an international evalu-
ation organized by the European TC-STAR project2
in February 2006. This project is envisaged as a
</bodyText>
<footnote confidence="0.7481">
2http://www.tc-star.org/
</footnote>
<bodyText confidence="0.996245181818182">
long-term effort to advance research in all core tech-
nologies for speech-to-speech translation.
The main goal of this evaluation is to trans-
late public European Parliament Plenary Sessions
(EPPS). The training material consists of the sum-
mary edited by the European Parliament in several
languages, which is also known as the Final Text
Editions (Gollan et al., 2005). These texts were
aligned at the sentence level and they are used to
train the statistical translation models (see Table 1
for some statistics).
</bodyText>
<table confidence="0.999644363636364">
Spanish English
Whole parallel corpus
Sentence Pairs 1.2M
Total # Words 34.1M 32.7M
Vocabulary size 129k 74k
Sentence length G 40
Sentence Pairs 0.91M
Total # Words 18.5M 18.0M
Word vocabulary 104k 71k
POS vocabulary 69 59
Enriched units vocab. 115k 77.6k
</table>
<tableCaption confidence="0.998236">
Table 1: Statistics of the parallel texts used to train
</tableCaption>
<bodyText confidence="0.952322785714286">
the statistical machine translation system.
Three different conditions are considered in the
TC-STAR evaluation: translation of the Final Text
Edition (text), translation of the transcriptions of the
acoustic development data (verbatim) and transla-
tion of speech recognizer output (ASR). Here we
only consider the verbatim condition, translating
from English to Spanish. For this task, the develop-
ment and test data consists of about 30k words. The
test data is partially collected in the Spanish parlia-
ment. This results in a small mismatch between de-
velopment and test data. Two reference translations
are provided. The scoring is case sensitive and in-
cludes punctuation symbols.
</bodyText>
<page confidence="0.996881">
67
</page>
<subsectionHeader confidence="0.991891">
3.1 Text normalization
</subsectionHeader>
<bodyText confidence="0.999956454545455">
The training data used for normalization differs sig-
nificantly from the development and test data. The
Final Text Edition corpus follows common ortho-
graphic rules (for instance, the first letter of the word
following a full stop or a column is capitalized) and
represents most of the dates, quantities, article refer-
ences and other numbers in digits. Thus the text had
to be “true-cased” and all numbers were verbalized
using in-house language-specific tools. Numbers are
not tagged as such at this stage; this is entirely left
to the POS tagger.
</bodyText>
<subsectionHeader confidence="0.974316">
3.2 Translation model training corpus
</subsectionHeader>
<bodyText confidence="0.999808181818182">
Long sentences (more than 40 words) greatly slow
down the training process, especially at the align-
ment step with Giza++. As shown in Figure 2, the
histogram of the length of Spanish sentences in the
training corpus decreases steadily after a length of
20 to 25 words, and English sentences exhibit a sim-
ilar behavior. Suppressing long sentences from the
corpus reduces the number of aligned sentences by
roughly 25% (see Table 1) but speeds the whole
training procedure by a factor of 3. The impact on
performance is discussed in the next section.
</bodyText>
<figure confidence="0.9776868">
Histogram or Spanish sentences’ lengths (training set)
35000
30000
25000
20000
15000
10000
5000
0
0 10 20 30 40 50 60 70 80 90 100
</figure>
<figureCaption confidence="0.999924">
Figure 2: Histogram of the sentence length (Spanish
</figureCaption>
<bodyText confidence="0.964142">
part of the parallel corpus).
</bodyText>
<subsectionHeader confidence="0.986322">
3.3 Language model training corpus
</subsectionHeader>
<bodyText confidence="0.999960571428571">
In the experiments reported below, a trigram word
language model is used during decoding. This
model is trained on the Spanish part of the parallel
corpus using only sentences shorter than 40 words
(total of 18.5M of language model training data).
Second pass language models were trained on all
available monolingual data (34.1M words).
</bodyText>
<subsectionHeader confidence="0.943808">
3.4 Tools
</subsectionHeader>
<bodyText confidence="0.999927733333333">
POS tagging was performed with the TreeTagger
(Schmid, 1994). This software provides resources
for both of the considered languages and it is freely
available. TreeTagger is a Markovian tagger that
uses decision trees to estimate trigram transition
probabilities. The English version is trained on the
PENN treebank corpus3 and the Spanish version on
the CRATER corpus.4
Language models are built using the SRI-LM
toolkit (Stolcke, 2002). Modified Knesser-Ney dis-
counting was used for all models. In (Goodman,
2001), a systematic description and comparison of
the usual smoothing methods is reported. Modified
Knesser-Ney discounting appears to be the most ef-
ficient method.
</bodyText>
<sectionHeader confidence="0.998417" genericHeader="evaluation">
4 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999905">
Two baseline English-to-Spanish translation mod-
els were created with Moses. The first model was
trained on the whole parallel text – note that sen-
tences with more than 100 words are excluded by
Giza++. The second model was trained on the cor-
pus using only sentences with at most 40 words. The
BLEU score on the development set using good gen-
eral purpose weights is 48.0 for the first model and
47.0 for the second. Because training on the whole
bi-text is much slower, we decided to perform our
experiments on the bi-texts restricted to the “short”
sentences.
</bodyText>
<subsectionHeader confidence="0.991316">
4.1 Language model generation
</subsectionHeader>
<bodyText confidence="0.999844666666667">
The reranking experiments presented below use the
following language models trained on the Spanish
part of the whole training corpus:
</bodyText>
<listItem confidence="0.998888333333333">
• word language models,
• POS language model,
• POS language model, with a stop list used to
remove the 100 most frequent words (POS-
stop100 LM),
• language model of enriched units.
</listItem>
<footnote confidence="0.9995455">
3http://www.cis.upenn.edu/ treebank
4http://www.comp.lancs.ac.uk/linguistics/crater/corpus.html
</footnote>
<page confidence="0.997844">
68
</page>
<note confidence="0.611702166666667">
English: you will be aware President that over the last few sessions in Strasbourg...
Baseline: usted sabe que el Presidente durante los ´ultimos sesiones en Estrasburgo ...
Enriched units: usted sabe que el Presidente en los ´ultimos periodos de sesiones en Estrasburgo ...
English: ... in this house there might be some recognition ...
Baseline: ... en esta asamblea no puede ser un cierto reconocimiento ...
Enriched units: ... en esta asamblea existe un cierto reconocimiento ...
</note>
<figureCaption confidence="0.998687">
Figure 3: Comparative translations using the baseline word system and the enriched unit system.
</figureCaption>
<bodyText confidence="0.999637647058824">
For each of these four models, various orders
were tested (n = 3, 4, 5), but in this paper we only
report those orders that yielded the greatest improve-
ments. POS language models were obtained by first
extracting POS sequences from the previously POS-
tagged training corpus and then by estimating stan-
dard back-off language models.
As shown in Table 1, the vocabulary size of the
word language model is 104k for Spanish and 74k
for English. The number of POS is small: 69 for
Spanish and 59 for English. We emphasize that
the tagset provided by TreeTagger does include nei-
ther gender nor number distinction. The vocabulary
size of the enriched-unit language model is 115k for
Spanish and 77.6k for English. The syntactical am-
biguity of words is low: the mean ambiguity ratio is
1.14 for Spanish and 1.12 for English.
</bodyText>
<subsectionHeader confidence="0.998759">
4.2 Reranking the word n-best lists
</subsectionHeader>
<bodyText confidence="0.9999784">
The results concerning reranking experiments of the
n-best lists provided by the translation model based
on words as units are summarized in Table 2. The
baseline result, with trigram word LM reranking,
gives a BLEU score of 47.0 (1rst row). From the
n-best lists provided by this translation model, we
compared reranking performances with different tar-
get language models. As observed in the literature,
an improvement can be obtained by reranking with
a 4-gram word language model (47.0 —* 47.5, 2d
row). By post-tagging this n-best list, a POS lan-
guage model reranking can be performed. However,
reranking with a 5-gram POS language model alone
does not give any improvement from the baseline
(BLEU score of 46.9, 3rd row). This result corre-
sponds to known work in the literature (Kirchhoff
and Yang, 2005; Hasan et al., 2006), when using
POS only as a post-processing step during rerank-
ing. As suggested in section 2.3, this lack of per-
formance can be due to the fact that the tagger is
not able to provide a usefull tagging of sentences
included in the n-best lists. This observation is
also available when reranking of the word n-best is
done with a language model based on enriched units
(BLEU score of 47.6, not reported in Table 2).
</bodyText>
<subsectionHeader confidence="0.998127">
4.3 POS disambiguation and reranking
</subsectionHeader>
<bodyText confidence="0.9999706">
The results concerning reranking experiments of the
n-best lists provided by the translation model based
on enriched units are summarized in Table 3. Us-
ing a trigram language model of enriched transla-
tion units leads to a BLEU score of 47.4, a 0.4 in-
crease over the baseline presented in section 4.2.
Figure 3 shows comparative translation examples
from the baseline and the enriched translation sys-
tems. In the first example, the baseline system out-
puts “durante los ´ultimos sesiones” where the en-
riched translation system produces “en los ´ultimos
periodos de sesiones”, a better translation that may
be attributed to the introduction of the masculine
word “periodos”, allowing the system to build a
syntactically correct sentence. In the second exam-
ple, the syntactical error “no puede ser un cierto re-
conocimiento” produced by the baseline system in-
duces an incorrect meaning of the sentence, whereas
the enriched translation system hypothesis “existe un
cierto reconocimiento” is both syntactically and se-
mantically correct.
Reranking the enriched n-best with POS language
models (either with or without a stop list) does not
seem to be efficient (0.3 BLEU increasing with the
POS-stop100 language model).
A better improvement is obtained when reranking
is performed with the 4-gram word language model.
This results in a BLEU score of 47.9, correspond-
ing to a 0.9 improvement over the word baseline. It
is interesting to observe that reranking a n-best list
</bodyText>
<page confidence="0.997532">
69
</page>
<table confidence="0.99904875">
Dev. Test
3g word LM baseline 47.0 46.0
4g word LM reranking 47.5 46.5
5g POS reranking 46.9 46.1
</table>
<tableCaption confidence="0.8462355">
Table 2: BLEU scores using words as translation
units.
</tableCaption>
<bodyText confidence="0.994031785714286">
obtained with a translation model based on enriched
units with a word LM results in better performances
than a enriched units LM reranking of a n-best list
obtained with a translation model based on words.
The last two rows of Table 3 give results when
combining word and POS language models to rerank
the enriched n-best lists. In both cases, 10 features
are used for reranking (8 Moses features + word
language model probability + POS language model
probability). The best result is obtained by com-
bining the 5-gram word language model with the 5-
gram POS-stop100 language model. In that case,
the best BLEU score is observed (48.1), with a 2.3%
relative increase over the trigram word baseline.
</bodyText>
<subsectionHeader confidence="0.922906">
4.4 Results on the test set
</subsectionHeader>
<bodyText confidence="0.999961833333333">
The results on the test set are given in the second
column of Tables 2 and 3. Although the enriched
translation system is only 0.1 BLEU over the base-
line system (46.0 -* 46.1) when using a trigram lan-
guage model, the best condition observed on the de-
velopment set (word and POS-stop100 LMs rerank-
ing) results in a 46.8 BLEU score, corresponding to
a 0.8 increasing.
It can be observed that rescoring with a 4-gram
word language model leads to same score resulting
in a 1.9% relative increase over the trigram word
baseline.
</bodyText>
<sectionHeader confidence="0.974185" genericHeader="conclusions">
5 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.9997312">
Combining word language model reranking of n-
best lists based on syntactically enriched units seems
to produce more consistent hypotheses. Using en-
riched translation units results in a relative 2.3%
improvement in BLEU on the development set and
1.9% on the test over the trigram baseline. Over a
standard translation model with 4-gram rescoring,
the enriched unit translation model leads to an abso-
lute increase in BLEU score of 0.4 both on the devel-
opment and the test sets. These first results are en-
</bodyText>
<table confidence="0.999014375">
Dev. Test
3g enriched units LM baseline 47.4 46.1
4g enriched units LM reranking 47.8 46.8
4g word LM reranking 47.9 46.9
5g POS LM reranking 47.5 46.2
5g POS-stop100 LM reranking 47.7 46.3
word + POS LMs reranking 47.9 46.9
word + POS-stop100 LMs rerank. 48.1 46.8
</table>
<tableCaption confidence="0.9111885">
Table 3: BLEU scores using enriched translation
units.
</tableCaption>
<bodyText confidence="0.999533181818182">
couraging enough to further investigate the integra-
tion of syntactic information in the translation model
itself, rather than to restrict it to the post-processing
pass. As follow-up experiments, it is planned to in-
clude gender and number information in the tagset,
as well as the word stems to the enriched units.
This work should be considered as preliminary
experiments for the investigation of factored trans-
lation models, which Moses is able to handle. POS
factorization is indeed a way to add some general-
ization capability to the enriched translation models.
</bodyText>
<sectionHeader confidence="0.999297" genericHeader="acknowledgments">
6 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999917666666667">
This work has been partially funded by the European
Union under the integrated project TC-STAR (IST-
2002-FP6-506738), and by the French Government
under the project INSTAR (ANR JCJC06 143038).
We would like to thanks Marc Ferras for his help
concerning the Spanish language.
</bodyText>
<sectionHeader confidence="0.998563" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.984419857142857">
Frank Vanden Berghen and Hugues Bersini. 2005. CON-
DOR, a new parallel, constrained extension of powell’s
UOBYQA algorithm: Experimental results and com-
parison with the DFO algorithm. Journal of Computa-
tional and Applied Mathematics, 181:157–175.
Peter F Brown, Stephen A Della Pietra, Vincent J Della
Pietra, and Robert L Mercer. 1993. The mathematics
of statistical machine translation: Parameter estima-
tion. Computational Linguistics, 19(2):263–311.
E. Charniak, K. Knight, and K. Yamada. 2003. Syntax-
based language models for machine translation. In
Proceedings ofMT Summit IX.
C. Gollan, M. Bisani, S. Kanthak, R. Schlueter, and ˜H.
Ney. 2005. Cross domain automatic transcription on
</reference>
<page confidence="0.967066">
70
</page>
<reference confidence="0.999737826923077">
the TC-STAR epps corpus. In Proceedings ofICASSP
2005.
Joshua T. Goodman. 2001. A bit of progress in lan-
guage modeling. Computer Speech and Language,
15(4):403–434, October.
S. Hasan, O. Bender, and H. Ney. 2006. Reranking trans-
lation hypothesis using structural properties. In Pro-
ceedings of EACL 2006.
Y.S. Hwang, A. Finch, and Y. Sasaki. 2007. Improving
statistical machine translation using shallow linguistic
knoledge. to be published in Computer, Speech and
Language.
Katrin Kirchhoff and Mei Yang. 2005. Improved lan-
guage modeling for statistical machine translation. In
Proceedings ofACL ’05 workshop on Building and Us-
ing Parallel Text, pages 125–128.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proceed-
ings of the Human Language Technology Conference
2003 (HLT-NAACL 2003), Edmonton, Canada, May.
Franz Josef Och and Hermann Ney. 2000a. Improved
statistical alignment models. In Proc. of the 38th An-
nual Meeting of the Association for Computational
Linguistics, pages 440–447, Hongkong, China, Octo-
ber.
Franz Josef Och and Hermann Ney. 2000b. Improved
statistical alignment models. In Proceedings of the
38th Annual Meeting of the Association for Computa-
tional Linguistics, pages 440–447, Hong Kong, China,
October.
Franz Josef Och and Hermann Ney. 2002. Discrimina-
tive training and maximum entropy models for statisti-
cal machine translation. In Proceedings ofACL 2002,
pages 295–302.
F.-J. Och, D. Gildea, S. Khudanpur, A. Sarkar, K. Ya-
mada, A. Fraser, S. Kumar, L. Shen, D. Smith, K. Eng,
V. Jain, Z. Jin, and D. Radev. 2004. A smorgasbord of
features for statistical machine translation. In NAACL,
pages 161–168.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic evalua-
tion of machine translation. In Proceedings of the 40th
Annual Meeting of the Association for Computational
Linguistics, pages 311–318, University of Pennsylva-
nia.
Helmut Schmid. 1994. Probabilistic part-of-speech tag-
ging using decision trees. In Proceedings of Interna-
tional Conference on New Methods in Language Pro-
cessing, September.
Andreas Stolcke. 2002. SRILM - an extensible language
modeling toolkit. In Proceedings of ICSLP, pages II:
901–904.
</reference>
<page confidence="0.999143">
71
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.626209">
<title confidence="0.9118055">Combining Morphosyntactic Enriched Representation Reranking in Statistical Translation H. Bonneau-Maynard, A. Allauzen, D. D´echelotte and H. Spoken Language Processing</title>
<address confidence="0.8656205">LIMSI-CNRS, BP 91403 Orsay cedex,</address>
<abstract confidence="0.999666666666667">The purpose of this work is to explore the integration of morphosyntactic infortranslation model itself, by enriching words with their morphosyntactic categories. We investigate word disambiguation using morphosyntactic catehypotheses reranking, and the combination of both methods with or morphosyntactic language model reranking. Experiments are carried out on the English-to-Spanish translation task. Using the morphosyntactic language model alone does not results in any improvement in performance. However, combining morphosyntactic word disambiguation with a word based 4-gram language model results in a relative improvement in the BLEU score of 2.3% on the development set and 1.9% on the test set.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Frank Vanden Berghen</author>
<author>Hugues Bersini</author>
</authors>
<title>CONDOR, a new parallel, constrained extension of powell’s UOBYQA algorithm: Experimental results and comparison with the DFO algorithm.</title>
<date>2005</date>
<journal>Journal of Computational and Applied Mathematics,</journal>
<pages>181--157</pages>
<contexts>
<context position="6488" citStr="Berghen and Bersini, 2005" startWordPosition="984" endWordPosition="987"> or by adding a new feature function; two, by performing a loglinear interpolation of the language model used for decoding and the new language model. This latter approach was used in all the experiments described in this paper. The set of weights is systematically re-optimized using the algorithm presented below. 2.2 Weight optimization A common criterion to optimize the coefficients of the log-linear combination of feature functions is to maximize the BLEU score (Papineni et al., 2002) on a development set (Och and Ney, 2002). For this purpose, the public numerical optimization tool Condor (Berghen and Bersini, 2005) is integrated in the following iterative algorithm: 0. Using good general purpose weights, the Moses decoder is used to generate 1000-best lists. 1. The 1000-best lists are reranked using the current set of weights. 2. The current hypothesis is extracted and scored. 3. This BLEU score is passed to Condor, which either computes a new set of weights (the algorithm then proceeds to step 1) or detects that a local maxima has been reached and the algorithm stops iterating. The solution is usually found after about 100 iterations. It is stressed that the n-best lists are generated only once and tha</context>
</contexts>
<marker>Berghen, Bersini, 2005</marker>
<rawString>Frank Vanden Berghen and Hugues Bersini. 2005. CONDOR, a new parallel, constrained extension of powell’s UOBYQA algorithm: Experimental results and comparison with the DFO algorithm. Journal of Computational and Applied Mathematics, 181:157–175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1266" citStr="Brown et al., 1993" startWordPosition="173" endWordPosition="176">uage model reranking. Experiments are carried out on the English-to-Spanish translation task. Using the morphosyntactic language model alone does not results in any improvement in performance. However, combining morphosyntactic word disambiguation with a word based 4-gram language model results in a relative improvement in the BLEU score of 2.3% on the development set and 1.9% on the test set. 1 Introduction Recent works in statistical machine translation (SMT) shows how phrase-based modeling (Och and Ney, 2000a; Koehn et al., 2003) significantly outperform the historical word-based modeling (Brown et al., 1993). Using phrases, i.e. sequences of words, as translation units allows the system to preserve local word order constraints and to improve the consistency of phrases during the translation process. Phrase-based models provide some sort of 65 context information as opposed to word-based models. Training a phrase-based model typically requires aligning a parallel corpus, extracting phrases and scoring them using word and phrase counts. The derived statistics capture the structure of natural language to some extent, including implicit syntactic and semantic relations. The output of a SMT system may</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F Brown, Stephen A Della Pietra, Vincent J Della Pietra, and Robert L Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>K Knight</author>
<author>K Yamada</author>
</authors>
<title>Syntaxbased language models for machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings ofMT Summit IX.</booktitle>
<contexts>
<context position="2890" citStr="Charniak et al., 2003" startWordPosition="423" endWordPosition="426">mising focus of attention. However, as of today, it seems difficult to outperform a 4-gram word language model. Several studies have attempted to use morphosyntactic information (also known as part-of-speech or POS information) to improve translation. (Och et al., 2004) have explored many different feature functions. Reranking n-best lists using POS has also been explored by (Hasan et al., 2006). In (Kirchhoff and Yang, 2005), a factored language model using POS information showed similar performance to a 4-gram word language model. Syntax-based language models have also been investigated in (Charniak et al., 2003). All these studies use word phrases as translation units and POS information in just a post-processing step. This paper explores the integration of morphosyntactic information into the translation model itself by enriching words with their morphosyntactic catProceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation, pages 65–71, Rochester, New York, April 2007. c�2007 Association for Computational Linguistics egories. The same idea has already been applied in (Hwang et al., 2007) to the Basic Travel Expression Corpus (BTEC). To our knowledge, this </context>
</contexts>
<marker>Charniak, Knight, Yamada, 2003</marker>
<rawString>E. Charniak, K. Knight, and K. Yamada. 2003. Syntaxbased language models for machine translation. In Proceedings ofMT Summit IX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Gollan</author>
<author>M Bisani</author>
<author>S Kanthak</author>
<author>R Schlueter</author>
<author>˜H Ney</author>
</authors>
<title>Cross domain automatic transcription on the TC-STAR epps corpus.</title>
<date>2005</date>
<booktitle>In Proceedings ofICASSP</booktitle>
<contexts>
<context position="9599" citStr="Gollan et al., 2005" startWordPosition="1486" endWordPosition="1489"> Task, corpus and tools The experimental results reported in this article were obtained in the framework of an international evaluation organized by the European TC-STAR project2 in February 2006. This project is envisaged as a 2http://www.tc-star.org/ long-term effort to advance research in all core technologies for speech-to-speech translation. The main goal of this evaluation is to translate public European Parliament Plenary Sessions (EPPS). The training material consists of the summary edited by the European Parliament in several languages, which is also known as the Final Text Editions (Gollan et al., 2005). These texts were aligned at the sentence level and they are used to train the statistical translation models (see Table 1 for some statistics). Spanish English Whole parallel corpus Sentence Pairs 1.2M Total # Words 34.1M 32.7M Vocabulary size 129k 74k Sentence length G 40 Sentence Pairs 0.91M Total # Words 18.5M 18.0M Word vocabulary 104k 71k POS vocabulary 69 59 Enriched units vocab. 115k 77.6k Table 1: Statistics of the parallel texts used to train the statistical machine translation system. Three different conditions are considered in the TC-STAR evaluation: translation of the Final Text</context>
</contexts>
<marker>Gollan, Bisani, Kanthak, Schlueter, Ney, 2005</marker>
<rawString>C. Gollan, M. Bisani, S. Kanthak, R. Schlueter, and ˜H. Ney. 2005. Cross domain automatic transcription on the TC-STAR epps corpus. In Proceedings ofICASSP 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joshua T Goodman</author>
</authors>
<title>A bit of progress in language modeling.</title>
<date>2001</date>
<journal>Computer Speech and Language,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="13010" citStr="Goodman, 2001" startWordPosition="2038" endWordPosition="2039">econd pass language models were trained on all available monolingual data (34.1M words). 3.4 Tools POS tagging was performed with the TreeTagger (Schmid, 1994). This software provides resources for both of the considered languages and it is freely available. TreeTagger is a Markovian tagger that uses decision trees to estimate trigram transition probabilities. The English version is trained on the PENN treebank corpus3 and the Spanish version on the CRATER corpus.4 Language models are built using the SRI-LM toolkit (Stolcke, 2002). Modified Knesser-Ney discounting was used for all models. In (Goodman, 2001), a systematic description and comparison of the usual smoothing methods is reported. Modified Knesser-Ney discounting appears to be the most efficient method. 4 Experiments and Results Two baseline English-to-Spanish translation models were created with Moses. The first model was trained on the whole parallel text – note that sentences with more than 100 words are excluded by Giza++. The second model was trained on the corpus using only sentences with at most 40 words. The BLEU score on the development set using good general purpose weights is 48.0 for the first model and 47.0 for the second.</context>
</contexts>
<marker>Goodman, 2001</marker>
<rawString>Joshua T. Goodman. 2001. A bit of progress in language modeling. Computer Speech and Language, 15(4):403–434, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Hasan</author>
<author>O Bender</author>
<author>H Ney</author>
</authors>
<title>Reranking translation hypothesis using structural properties.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL</booktitle>
<contexts>
<context position="2666" citStr="Hasan et al., 2006" startWordPosition="389" endWordPosition="392">ge model) discards linguistic properties such as long term word dependency and word-order or phrase-order syntactic constraints. Therefore, explicit introduction of structure in the language models becomes a major and promising focus of attention. However, as of today, it seems difficult to outperform a 4-gram word language model. Several studies have attempted to use morphosyntactic information (also known as part-of-speech or POS information) to improve translation. (Och et al., 2004) have explored many different feature functions. Reranking n-best lists using POS has also been explored by (Hasan et al., 2006). In (Kirchhoff and Yang, 2005), a factored language model using POS information showed similar performance to a 4-gram word language model. Syntax-based language models have also been investigated in (Charniak et al., 2003). All these studies use word phrases as translation units and POS information in just a post-processing step. This paper explores the integration of morphosyntactic information into the translation model itself by enriching words with their morphosyntactic catProceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation, pages 65–71,</context>
<context position="16461" citStr="Hasan et al., 2006" startWordPosition="2598" endWordPosition="2601"> BLEU score of 47.0 (1rst row). From the n-best lists provided by this translation model, we compared reranking performances with different target language models. As observed in the literature, an improvement can be obtained by reranking with a 4-gram word language model (47.0 —* 47.5, 2d row). By post-tagging this n-best list, a POS language model reranking can be performed. However, reranking with a 5-gram POS language model alone does not give any improvement from the baseline (BLEU score of 46.9, 3rd row). This result corresponds to known work in the literature (Kirchhoff and Yang, 2005; Hasan et al., 2006), when using POS only as a post-processing step during reranking. As suggested in section 2.3, this lack of performance can be due to the fact that the tagger is not able to provide a usefull tagging of sentences included in the n-best lists. This observation is also available when reranking of the word n-best is done with a language model based on enriched units (BLEU score of 47.6, not reported in Table 2). 4.3 POS disambiguation and reranking The results concerning reranking experiments of the n-best lists provided by the translation model based on enriched units are summarized in Table 3. </context>
</contexts>
<marker>Hasan, Bender, Ney, 2006</marker>
<rawString>S. Hasan, O. Bender, and H. Ney. 2006. Reranking translation hypothesis using structural properties. In Proceedings of EACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y S Hwang</author>
<author>A Finch</author>
<author>Y Sasaki</author>
</authors>
<title>Improving statistical machine translation using shallow linguistic knoledge. to be published in Computer, Speech and Language.</title>
<date>2007</date>
<contexts>
<context position="3420" citStr="Hwang et al., 2007" startWordPosition="501" endWordPosition="504">odel. Syntax-based language models have also been investigated in (Charniak et al., 2003). All these studies use word phrases as translation units and POS information in just a post-processing step. This paper explores the integration of morphosyntactic information into the translation model itself by enriching words with their morphosyntactic catProceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation, pages 65–71, Rochester, New York, April 2007. c�2007 Association for Computational Linguistics egories. The same idea has already been applied in (Hwang et al., 2007) to the Basic Travel Expression Corpus (BTEC). To our knowledge, this approach has not been evaluated on a large realword translation problem. We report results on the TC-STAR task (public European Parliament Plenary Sessions translation). Furthermore, we propose to combine this approach with classical n-best list reranking. Experiments are carried out on the English-to-Spanish task using a system based on the publicly available Moses decoder. This paper is organized as follows: In Section 2 we first describe the baseline statistical machine translation systems. Section 3 presents the consider</context>
</contexts>
<marker>Hwang, Finch, Sasaki, 2007</marker>
<rawString>Y.S. Hwang, A. Finch, and Y. Sasaki. 2007. Improving statistical machine translation using shallow linguistic knoledge. to be published in Computer, Speech and Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Kirchhoff</author>
<author>Mei Yang</author>
</authors>
<title>Improved language modeling for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL ’05 workshop on Building and Using Parallel Text,</booktitle>
<pages>125--128</pages>
<contexts>
<context position="2697" citStr="Kirchhoff and Yang, 2005" startWordPosition="394" endWordPosition="397">stic properties such as long term word dependency and word-order or phrase-order syntactic constraints. Therefore, explicit introduction of structure in the language models becomes a major and promising focus of attention. However, as of today, it seems difficult to outperform a 4-gram word language model. Several studies have attempted to use morphosyntactic information (also known as part-of-speech or POS information) to improve translation. (Och et al., 2004) have explored many different feature functions. Reranking n-best lists using POS has also been explored by (Hasan et al., 2006). In (Kirchhoff and Yang, 2005), a factored language model using POS information showed similar performance to a 4-gram word language model. Syntax-based language models have also been investigated in (Charniak et al., 2003). All these studies use word phrases as translation units and POS information in just a post-processing step. This paper explores the integration of morphosyntactic information into the translation model itself by enriching words with their morphosyntactic catProceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation, pages 65–71, Rochester, New York, April 200</context>
<context position="16440" citStr="Kirchhoff and Yang, 2005" startWordPosition="2594" endWordPosition="2597">word LM reranking, gives a BLEU score of 47.0 (1rst row). From the n-best lists provided by this translation model, we compared reranking performances with different target language models. As observed in the literature, an improvement can be obtained by reranking with a 4-gram word language model (47.0 —* 47.5, 2d row). By post-tagging this n-best list, a POS language model reranking can be performed. However, reranking with a 5-gram POS language model alone does not give any improvement from the baseline (BLEU score of 46.9, 3rd row). This result corresponds to known work in the literature (Kirchhoff and Yang, 2005; Hasan et al., 2006), when using POS only as a post-processing step during reranking. As suggested in section 2.3, this lack of performance can be due to the fact that the tagger is not able to provide a usefull tagging of sentences included in the n-best lists. This observation is also available when reranking of the word n-best is done with a language model based on enriched units (BLEU score of 47.6, not reported in Table 2). 4.3 POS disambiguation and reranking The results concerning reranking experiments of the n-best lists provided by the translation model based on enriched units are su</context>
</contexts>
<marker>Kirchhoff, Yang, 2005</marker>
<rawString>Katrin Kirchhoff and Mei Yang. 2005. Improved language modeling for statistical machine translation. In Proceedings ofACL ’05 workshop on Building and Using Parallel Text, pages 125–128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Language Technology Conference</booktitle>
<location>Edmonton, Canada,</location>
<contexts>
<context position="1185" citStr="Koehn et al., 2003" startWordPosition="162" endWordPosition="165">ing, and the combination of both methods with word or morphosyntactic n-gram language model reranking. Experiments are carried out on the English-to-Spanish translation task. Using the morphosyntactic language model alone does not results in any improvement in performance. However, combining morphosyntactic word disambiguation with a word based 4-gram language model results in a relative improvement in the BLEU score of 2.3% on the development set and 1.9% on the test set. 1 Introduction Recent works in statistical machine translation (SMT) shows how phrase-based modeling (Och and Ney, 2000a; Koehn et al., 2003) significantly outperform the historical word-based modeling (Brown et al., 1993). Using phrases, i.e. sequences of words, as translation units allows the system to preserve local word order constraints and to improve the consistency of phrases during the translation process. Phrase-based models provide some sort of 65 context information as opposed to word-based models. Training a phrase-based model typically requires aligning a parallel corpus, extracting phrases and scoring them using word and phrase counts. The derived statistics capture the structure of natural language to some extent, in</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the Human Language Technology Conference 2003 (HLT-NAACL 2003), Edmonton, Canada, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In Proc. of the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>440--447</pages>
<location>Hongkong, China,</location>
<contexts>
<context position="1163" citStr="Och and Ney, 2000" startWordPosition="158" endWordPosition="161">st hypotheses reranking, and the combination of both methods with word or morphosyntactic n-gram language model reranking. Experiments are carried out on the English-to-Spanish translation task. Using the morphosyntactic language model alone does not results in any improvement in performance. However, combining morphosyntactic word disambiguation with a word based 4-gram language model results in a relative improvement in the BLEU score of 2.3% on the development set and 1.9% on the test set. 1 Introduction Recent works in statistical machine translation (SMT) shows how phrase-based modeling (Och and Ney, 2000a; Koehn et al., 2003) significantly outperform the historical word-based modeling (Brown et al., 1993). Using phrases, i.e. sequences of words, as translation units allows the system to preserve local word order constraints and to improve the consistency of phrases during the translation process. Phrase-based models provide some sort of 65 context information as opposed to word-based models. Training a phrase-based model typically requires aligning a parallel corpus, extracting phrases and scoring them using word and phrase counts. The derived statistics capture the structure of natural langu</context>
<context position="4952" citStr="Och and Ney, 2000" startWordPosition="741" endWordPosition="744">get language sentences the one with the highest probability is chosen. The use of a maximum entropy approach simplifies the introduction of several additional models explaining the translation process: e* = arg maxPr(e|f) Aihi(e,f))} (1) � = arg max{exp( e i where the feature functions hi are the system models characterizing the translation process, and the coefficients Ai act as weights. 2.1 Moses decoder Moses1 is an open-source, state-of-the-art phrasebased decoder. It implements an efficient beamsearch algorithm. Scripts are also provided to train a phrase-based model. The popular Giza++ (Och and Ney, 2000b) tool is used to align the parallel corpora. The baseline system uses 8 feature functions hi, namely phrase translation probabilities in both directions, lexical translation probabilities in both directions, a distortion feature, a word and a phrase 1http://www.statmt.org/moses/ penalty and a trigram target language model. Additional features can be added, as described in the following sections. The weights Ai are typically optimized so as to maximize a scoring function on a development set (Och and Ney, 2002). The moses decoder can output n-best lists, producing either distinct target sente</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz Josef Och and Hermann Ney. 2000a. Improved statistical alignment models. In Proc. of the 38th Annual Meeting of the Association for Computational Linguistics, pages 440–447, Hongkong, China, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>440--447</pages>
<location>Hong Kong, China,</location>
<contexts>
<context position="1163" citStr="Och and Ney, 2000" startWordPosition="158" endWordPosition="161">st hypotheses reranking, and the combination of both methods with word or morphosyntactic n-gram language model reranking. Experiments are carried out on the English-to-Spanish translation task. Using the morphosyntactic language model alone does not results in any improvement in performance. However, combining morphosyntactic word disambiguation with a word based 4-gram language model results in a relative improvement in the BLEU score of 2.3% on the development set and 1.9% on the test set. 1 Introduction Recent works in statistical machine translation (SMT) shows how phrase-based modeling (Och and Ney, 2000a; Koehn et al., 2003) significantly outperform the historical word-based modeling (Brown et al., 1993). Using phrases, i.e. sequences of words, as translation units allows the system to preserve local word order constraints and to improve the consistency of phrases during the translation process. Phrase-based models provide some sort of 65 context information as opposed to word-based models. Training a phrase-based model typically requires aligning a parallel corpus, extracting phrases and scoring them using word and phrase counts. The derived statistics capture the structure of natural langu</context>
<context position="4952" citStr="Och and Ney, 2000" startWordPosition="741" endWordPosition="744">get language sentences the one with the highest probability is chosen. The use of a maximum entropy approach simplifies the introduction of several additional models explaining the translation process: e* = arg maxPr(e|f) Aihi(e,f))} (1) � = arg max{exp( e i where the feature functions hi are the system models characterizing the translation process, and the coefficients Ai act as weights. 2.1 Moses decoder Moses1 is an open-source, state-of-the-art phrasebased decoder. It implements an efficient beamsearch algorithm. Scripts are also provided to train a phrase-based model. The popular Giza++ (Och and Ney, 2000b) tool is used to align the parallel corpora. The baseline system uses 8 feature functions hi, namely phrase translation probabilities in both directions, lexical translation probabilities in both directions, a distortion feature, a word and a phrase 1http://www.statmt.org/moses/ penalty and a trigram target language model. Additional features can be added, as described in the following sections. The weights Ai are typically optimized so as to maximize a scoring function on a development set (Och and Ney, 2002). The moses decoder can output n-best lists, producing either distinct target sente</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz Josef Och and Hermann Ney. 2000b. Improved statistical alignment models. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 440–447, Hong Kong, China, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL 2002,</booktitle>
<pages>295--302</pages>
<contexts>
<context position="5469" citStr="Och and Ney, 2002" startWordPosition="822" endWordPosition="825">rithm. Scripts are also provided to train a phrase-based model. The popular Giza++ (Och and Ney, 2000b) tool is used to align the parallel corpora. The baseline system uses 8 feature functions hi, namely phrase translation probabilities in both directions, lexical translation probabilities in both directions, a distortion feature, a word and a phrase 1http://www.statmt.org/moses/ penalty and a trigram target language model. Additional features can be added, as described in the following sections. The weights Ai are typically optimized so as to maximize a scoring function on a development set (Och and Ney, 2002). The moses decoder can output n-best lists, producing either distinct target sentences or not (as different segmentations may lead to the same sentence). In this work, distinct sentences were always used. These n-best lists can be rescored using higher order language models (word- or syntactic-based). There are two ways to carry out the rescoring: one, by replacing the language model score or by adding a new feature function; two, by performing a loglinear interpolation of the language model used for decoding and the new language model. This latter approach was used in all the experiments des</context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>Franz Josef Och and Hermann Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In Proceedings ofACL 2002, pages 295–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F-J Och</author>
<author>D Gildea</author>
<author>S Khudanpur</author>
<author>A Sarkar</author>
<author>K Yamada</author>
<author>A Fraser</author>
<author>S Kumar</author>
<author>L Shen</author>
<author>D Smith</author>
<author>K Eng</author>
<author>V Jain</author>
<author>Z Jin</author>
<author>D Radev</author>
</authors>
<title>A smorgasbord of features for statistical machine translation. In</title>
<date>2004</date>
<booktitle>NAACL,</booktitle>
<pages>161--168</pages>
<contexts>
<context position="2538" citStr="Och et al., 2004" startWordPosition="368" endWordPosition="371">ering words to recover its syntactic structure. Modeling language generation as a word-based Markovian source (an ngram language model) discards linguistic properties such as long term word dependency and word-order or phrase-order syntactic constraints. Therefore, explicit introduction of structure in the language models becomes a major and promising focus of attention. However, as of today, it seems difficult to outperform a 4-gram word language model. Several studies have attempted to use morphosyntactic information (also known as part-of-speech or POS information) to improve translation. (Och et al., 2004) have explored many different feature functions. Reranking n-best lists using POS has also been explored by (Hasan et al., 2006). In (Kirchhoff and Yang, 2005), a factored language model using POS information showed similar performance to a 4-gram word language model. Syntax-based language models have also been investigated in (Charniak et al., 2003). All these studies use word phrases as translation units and POS information in just a post-processing step. This paper explores the integration of morphosyntactic information into the translation model itself by enriching words with their morphos</context>
</contexts>
<marker>Och, Gildea, Khudanpur, Sarkar, Yamada, Fraser, Kumar, Shen, Smith, Eng, Jain, Jin, Radev, 2004</marker>
<rawString>F.-J. Och, D. Gildea, S. Khudanpur, A. Sarkar, K. Yamada, A. Fraser, S. Kumar, L. Shen, D. Smith, K. Eng, V. Jain, Z. Jin, and D. Radev. 2004. A smorgasbord of features for statistical machine translation. In NAACL, pages 161–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="6354" citStr="Papineni et al., 2002" startWordPosition="963" endWordPosition="966">guage models (word- or syntactic-based). There are two ways to carry out the rescoring: one, by replacing the language model score or by adding a new feature function; two, by performing a loglinear interpolation of the language model used for decoding and the new language model. This latter approach was used in all the experiments described in this paper. The set of weights is systematically re-optimized using the algorithm presented below. 2.2 Weight optimization A common criterion to optimize the coefficients of the log-linear combination of feature functions is to maximize the BLEU score (Papineni et al., 2002) on a development set (Och and Ney, 2002). For this purpose, the public numerical optimization tool Condor (Berghen and Bersini, 2005) is integrated in the following iterative algorithm: 0. Using good general purpose weights, the Moses decoder is used to generate 1000-best lists. 1. The 1000-best lists are reranked using the current set of weights. 2. The current hypothesis is extracted and scored. 3. This BLEU score is passed to Condor, which either computes a new set of weights (the algorithm then proceeds to step 1) or detects that a local maxima has been reached and the algorithm stops ite</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Proceedings of International Conference on New Methods in Language Processing,</booktitle>
<contexts>
<context position="12555" citStr="Schmid, 1994" startWordPosition="1969" endWordPosition="1970">aining set) 35000 30000 25000 20000 15000 10000 5000 0 0 10 20 30 40 50 60 70 80 90 100 Figure 2: Histogram of the sentence length (Spanish part of the parallel corpus). 3.3 Language model training corpus In the experiments reported below, a trigram word language model is used during decoding. This model is trained on the Spanish part of the parallel corpus using only sentences shorter than 40 words (total of 18.5M of language model training data). Second pass language models were trained on all available monolingual data (34.1M words). 3.4 Tools POS tagging was performed with the TreeTagger (Schmid, 1994). This software provides resources for both of the considered languages and it is freely available. TreeTagger is a Markovian tagger that uses decision trees to estimate trigram transition probabilities. The English version is trained on the PENN treebank corpus3 and the Spanish version on the CRATER corpus.4 Language models are built using the SRI-LM toolkit (Stolcke, 2002). Modified Knesser-Ney discounting was used for all models. In (Goodman, 2001), a systematic description and comparison of the usual smoothing methods is reported. Modified Knesser-Ney discounting appears to be the most eff</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Proceedings of International Conference on New Methods in Language Processing, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of ICSLP,</booktitle>
<pages>901--904</pages>
<contexts>
<context position="12932" citStr="Stolcke, 2002" startWordPosition="2026" endWordPosition="2027">nces shorter than 40 words (total of 18.5M of language model training data). Second pass language models were trained on all available monolingual data (34.1M words). 3.4 Tools POS tagging was performed with the TreeTagger (Schmid, 1994). This software provides resources for both of the considered languages and it is freely available. TreeTagger is a Markovian tagger that uses decision trees to estimate trigram transition probabilities. The English version is trained on the PENN treebank corpus3 and the Spanish version on the CRATER corpus.4 Language models are built using the SRI-LM toolkit (Stolcke, 2002). Modified Knesser-Ney discounting was used for all models. In (Goodman, 2001), a systematic description and comparison of the usual smoothing methods is reported. Modified Knesser-Ney discounting appears to be the most efficient method. 4 Experiments and Results Two baseline English-to-Spanish translation models were created with Moses. The first model was trained on the whole parallel text – note that sentences with more than 100 words are excluded by Giza++. The second model was trained on the corpus using only sentences with at most 40 words. The BLEU score on the development set using goo</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an extensible language modeling toolkit. In Proceedings of ICSLP, pages II: 901–904.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>