<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000102">
<title confidence="0.996162">
Graph-Based Keyword Extraction for Single-Document Summarization
</title>
<author confidence="0.993379">
Marina Litvak
</author>
<affiliation confidence="0.86219675">
Department of
Information System Engineering
Ben-Gurion University of the Negev
Beer-Sheva 84105, Israel
</affiliation>
<email confidence="0.983878">
litvakm@bgu.ac.il
</email>
<author confidence="0.992092">
Mark Last
</author>
<affiliation confidence="0.86155925">
Department of
Information System Engineering
Ben-Gurion University of the Negev
Beer-Sheva 84105, Israel
</affiliation>
<email confidence="0.994726">
mlast@bgu.ac.il
</email>
<sectionHeader confidence="0.997352" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999902071428571">
In this paper, we introduce and compare
between two novel approaches, supervised
and unsupervised, for identifying the key-
words to be used in extractive summa-
rization of text documents. Both our ap-
proaches are based on the graph-based
syntactic representation of text and web
documents, which enhances the traditional
vector-space model by taking into account
some structural document features. In the
supervised approach, we train classifica-
tion algorithms on a summarized collec-
tion of documents with the purpose of
inducing a keyword identification model.
In the unsupervised approach, we run the
HITS algorithm on document graphs under
the assumption that the top-ranked nodes
should represent the document keywords.
Our experiments on a collection of bench-
mark summaries show that given a set of
summarized training documents, the su-
pervised classification provides the highest
keyword identification accuracy, while the
highest F-measure is reached with a sim-
ple degree-based ranking. In addition, it is
sufficient to perform only the first iteration
of HITS rather than running it to its con-
vergence.
</bodyText>
<sectionHeader confidence="0.999228" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.8541075">
Document summarization is aimed at all types of
electronic documents including HTML files with
</bodyText>
<footnote confidence="0.9098635">
© 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
</footnote>
<bodyText confidence="0.999083526315789">
the purpose of generating the summary - main doc-
ument information expressed in ”a few words”.
In this paper, we introduce and compare be-
tween two approaches: supervised and unsuper-
vised, for the cross-lingual keyword extraction to
be used as the first step in extractive summarization
of text documents. Thus, according to our problem
statement, the keyword is a word presenting in the
document summary.
The supervised learning approach for keywords
extraction was first suggested in (Turney, 2000),
where parametrized heuristic rules were combined
with a genetic algorithm into a system - GenEx -
that automatically identified keywords in a docu-
ment.
For both our approaches, we utilize a graph-
based representation for text documents. Such rep-
resentations may vary from very simple, syntactic
ones like words connected by edges representing
co-occurrence relation (Mihalcea and Tarau, 2004)
to more complex ones like concepts connected by
semantic relations (Leskovec et al., 2004). The
main advantage of a syntactic representation is its
language independency, while the semantic graphs
representation provide new characteristics of text
such as its captured semantic structure that it-
self can serve as a document surrogate and pro-
vide means for document navigation. Authors of
(Leskovec et al., 2004) reduce the problem of sum-
marization to acquiring machine learning models
for mapping between the document graph and the
graph of a summary. Using deep linguistic anal-
ysis, they extract sub-structures (subjectpredica-
teobject triples) from document semantic graphs in
order to get a summary. Contrary to (Leskovec et
al., 2004), both our approaches work with a syn-
tactic representation that does not require almost
any language-specific linguistic processing. In
</bodyText>
<page confidence="0.990827">
17
</page>
<note confidence="0.60402">
Coling 2008: Proceedings of the workshop on Multi-source Multilingual Information Extraction and Summarization, pages 17–24
</note>
<bodyText confidence="0.9879578">
Manchester, August 2008
this paper, we perform experiments with directed
graphs, where the nodes stand for words/phrases
and the edges represent syntactic relationships be-
tween them, meaning ¨followed by¨ (Schenker et
al., 2005).
Some of the most successful approaches to ex-
tractive summarization utilize supervised learn-
ing algorithms that are trained on collections of
”ground truth” summaries built for a relatively
large number of documents (Mani and Maybury,
1999). However, in spite of the reasonable perfor-
mance of such algorithms they cannot be adapted
to new languages or domains without training
on each new type of data. Our first approach
also utilizes classification algorithms, but, thanks
to the language-independent graph representation
of documents, it can be applied to various lan-
guages and domains without any modifications of
the graph construction procedure (except for the
technical upgrade of implementation for multi-
lingual processing of text, like reading Unicode or
language-specific encodings, etc.) (Markov et al.,
2007; Last and Markov, 2005). Of course, as a su-
pervised approach it requires high-quality training
labeled data.
Our second approach uses a technique that does
not require any training data. To extract the sum-
mary keywords, we apply a ranking algorithm
called HITS (Kleinberg, 1999) to directed graphs
representing source documents. Authors of (Mi-
halcea and Tarau, 2004) applied the PageRank al-
gorithm (Brin and Page, 1998) for keyword extrac-
tion using a simpler graph representation (undi-
rected unweighted graphs), and show that their re-
sults compare favorably with results on established
benchmarks of manually assigned keywords. (Mi-
halcea and Tarau, 2004) are also using the HITS
algorithm for automatic sentence extraction from
documents represented by graphs built from sen-
tences connected by similarity relationships. Since
we work with directed graphs, HITS is the most
appropriate algorithm for our task as it takes into
account both in-degree and out-degree of nodes.
We show in our experiments that running HITS till
convergence is not necessary, and initial weights
that we get after the first iteration of algorithm
are good enough for rank-based extraction of sum-
mary keywords. Another important conclusion
that was infered from our experimental results is
that, given the training data in the form of anno-
tated syntactic graphs, supervised classification is
the most accurate option for identifying the salient
nodes in a document graph, while a simple degree-
based ranking provides the highest F-measure.
</bodyText>
<sectionHeader confidence="0.947384" genericHeader="method">
2 Document representation
</sectionHeader>
<bodyText confidence="0.999996926829269">
Currently, we use the ”simple” graph representa-
tion defined in (Schenker et al., 2005) that holds
unlabeled edges representing order-relationship
between the the words represented by nodes. The
stemming and stopword removal operations of ba-
sic text preprocessing are done before graph build-
ing. Only a single vertex for each distinct word
is created even if it appears more than once in
the text. Thus each vertex label in the graph is
unique. If a word a immediately precedes a word
b in the same sentence somewhere in the docu-
ment, then there is a directed edge from the ver-
tex corresponding to term a to the vertex corre-
sponding to term b. Sentence terminating punctu-
ation marks (periods, question marks, and excla-
mation points) are taken by us into account and
an edge is not created when these are present be-
tween two words. This definition of graph edges
is slightly different from co-occurrence relations
used in (Mihalcea and Tarau, 2004) for building
undirected document graphs, where the order of
word occurrence is ignored and the size of the co-
occurrence window is varied between 2 and 10.
Sections defined for HTML documents are: title,
which contains the text related to the document’s
title and any provided keywords (meta-data) and
text, which comprises any of the readable text in
the document. This simple representation can be
extended to many different variations like a se-
mantic graph where nodes stand for concepts and
edges represent semantic relations between them
or a more detailed syntactic graph where edges and
nodes are labeled by significant information like
frequency, location, similarity, distance, etc. The
syntactic graph-based representations were shown
in (Schenker et al., 2005) to outperform the clas-
sical vector-space model on several clustering and
classification tasks. We choose the ”simple” repre-
sentation as a representation that saves processing
time and memory resources as well as gives nearly
the best results for the two above text mining tasks.
</bodyText>
<sectionHeader confidence="0.997039" genericHeader="method">
3 Keywords extraction
</sectionHeader>
<bodyText confidence="0.999706333333333">
In this paper, we deal with the first stage of extrac-
tive summarization where the most salient words
(”keywords”) are extracted in order to generate a
</bodyText>
<page confidence="0.995202">
18
</page>
<bodyText confidence="0.9988515">
summary. Since each distinct word in a text is rep-
resented by a node in the document graph, the key-
words extraction problem is reduced to the salient
nodes extraction in graphs.
</bodyText>
<subsectionHeader confidence="0.999301">
3.1 The Supervised approach
</subsectionHeader>
<bodyText confidence="0.999812142857143">
In this approach, we try to identify the salient
nodes of document graphs by training a classifi-
cation algorithm on a repository of summarized
documents such as (DUC, 2002) with the purpose
of inducing a keyword identification model. Each
node of every document graph belongs to one of
two classes: YES if the corresponding word is in-
cluded in the document extractive summary and
NO otherwise. We consider the graph-based fea-
tures (e.g., degree) characterizing graph structure
as well as statistic-based features (Nobata et al.,
2001) characterizing text content represented by a
node. The complete list of features, along with
their formal definitions, is provided below:
</bodyText>
<listItem confidence="0.999427875">
• In Degree - number of incoming edges
• Out Degree - number of outcoming edges
• Degree - total number of edges
• Frequency - term frequency of word repre-
sented by node1
• Frequent words distribution E {0, 1},
equals to 1 iff Frequency≥threshold2
• Location Score - calculates an average of lo-
</listItem>
<bodyText confidence="0.779710666666667">
cation scores between all sentences3 contain-
ing the word N represented by node (denote
these sentences as S(N)):
</bodyText>
<equation confidence="0.966022">
Score (N) = ESi∈S(N) Score (Si)
|S (N)|
</equation>
<listItem confidence="0.99865">
• Tfidf Score - calculates the tf-idf
score (Salton, 1975) of the word repre-
sented by node4.
</listItem>
<footnote confidence="0.993670875">
1The term frequency (TF) is the number of times the word
appears in a document divided by the number of total words
in the document.
2In our experiment the threshold is set to 0.05
3There are many variants for calculating sentence location
score (Nobata et al., 2001). In this paper, we calculate it as an
reciprocal of the sentence location in text: Score (Si) = 1 i
4There are many different formulas used to calculate tfidf.
</footnote>
<bodyText confidence="0.91217775">
We use the next formula: tf |D|
tf+1 loge df , where tf -term fre-
quency (as defined above), IDI - total number of documents in
the corpus, df - number of documents where the term appears.
</bodyText>
<listItem confidence="0.996637666666667">
• Headline Score E {0, 1}, equals to 1 iff doc-
ument headline contains word represented by
node.
</listItem>
<subsectionHeader confidence="0.998244">
3.2 The Unsupervised approach
</subsectionHeader>
<bodyText confidence="0.99989728">
Ranking algorithms, such as Kleinberg’s HITS
algorithm (Kleinberg, 1999) or Google’s PageR-
ank (Brin and Page, 1998) have been elaborated
and used in Web-link analysis for the purpose of
optimizating the search performance on the Web.
These algorithms recursively assign a numerical
weight to each element of a hyperlinked set of doc-
uments, determining how important each page is.
A hyperlink to a page counts as a vote of support.
A page that is linked to by many important pages
(with high rank) receives a high rank itself. A
similar idea can be applied to lexical or seman-
tic graphs extracted from text documents, in or-
der to extract the most significant blocks (words,
phrases, sentences, etc.) for the summary (Mi-
halcea and Tarau, 2004; Mihalcea, 2004). In this
paper, we apply the HITS algorithm to document
graphs and evaluate its performance on automatic
unsupervised text unit extraction in the context of
the text summarization task. The HITS algorithm
distinguishes between ”authorities” (pages with a
large number of incoming links) and ”hubs” (pages
with a large number of outgoing links). For each
node, HITS produces two sets of scores - an ”au-
thority” score, and a ”hub” score:
</bodyText>
<equation confidence="0.99879775">
HITSA (Vi) = � HITSH (Vj) (1)
Vj∈In(Vi)
HITSH (Vi) = � HITSA (Vj) (2)
Vj∈Out(Vi)
</equation>
<bodyText confidence="0.9994255">
For the total rank (H) calculation we used the
following four functions:
</bodyText>
<listItem confidence="0.965786888888889">
1. rank equals to the authority score
H (Vi) = HITSA (Vi)
2. rank equals to the hub score
H (Vi) = HITSH (Vi)
3. rank equals to the average between two scores
H (Vi) = avg {HITSA (Vi) , HITSH (Vi)}
4. rank equals to the maximum between two
scores
H (Vi) = max {HITSA (Vi) , HITSH (Vi)}
</listItem>
<page confidence="0.989035">
19
</page>
<table confidence="0.999744666666667">
average merit rank feature
0.192 +- 0.005 1 Frequent words distribution
0.029 +- 0 2 In Degree
0.029 +- 0 3 Out Degree
0.025 +- 0 4 Frequency
0.025 +- 0 5 Degree
0.017 +- 0 6 Headline Score
0.015 +- 0 7 Location Score
0.015 +- 0.001 8 Tfidf Score
</table>
<tableCaption confidence="0.99905">
Table 1: Feature selection results according to GainRatio value
</tableCaption>
<figure confidence="0.992570230769231">
0.842
0.840
0.838
0.836
0.834
0.832
0.830
0.828
0.826
0.824
8 7 6 5 4
size of the featu
cy
</figure>
<figureCaption confidence="0.999936">
Figure 1: Accuracy for NaiveBayes classifier (NBC) and Majority Rule (MR)
</figureCaption>
<sectionHeader confidence="0.997465" genericHeader="method">
4 Experimental results
</sectionHeader>
<bodyText confidence="0.99995375">
All experiments have been performed on the
collection of summarized news articles pro-
vided by the Document Understanding Conference
2002 (DUC, 2002). This collection contains 566
English texts along with 2-3 summaries per doc-
ument on average. The size5 of syntactic graphs
extracted from these texts is 196 on average, vary-
ing from 62 to 876.
</bodyText>
<subsectionHeader confidence="0.997922">
4.1 Supervised approach
</subsectionHeader>
<bodyText confidence="0.982074703703704">
We utilized several classification algorithms im-
plemented in Weka’s software (Witten and Frank,
2005) : J48 (known as C4.5), SMO (Support Vec-
tor Machine) and NaiveBayes for building binary
classification models (a word belongs to summary
/ does not belong to the summary). For the training
we built dataset with two classes: YES for nodes
belonging to at least one summary of the docu-
5We define the size of a graph as the number of its vertices.
ment, and NO for those that do not belong to any
summary. The accuracy of the default (majority)
rule over all nodes is equal to the percentage of
non-salient nodes (83.17%). For better classifica-
tion results we examined the importance of each
one of the features, described in Section 3.1 using
automated feature selection. Table 1 presents the
average GainRatio6 values (”merits”) and the aver-
age rank of the features calculated from the DUC
2002 document collection, based on 10-fold cross
validation.
As expected, the results of J48 and SMO (these
algorithms perform feature selection while build-
ing the model) did not vary on different feature
sets, while NaiveBayes gave the best accuracy on
the reduced set. Figure 1 demonstrates the accu-
racy variations of NaiveBayes classifier on the dif-
ferent feature sets relative to the confidence inter-
</bodyText>
<footnote confidence="0.461046666666667">
6Gain Ratio(A) = Information Gain(A) where
Intrinsic Info(A)
Intrinsic Info(A) = −� x N log N
</footnote>
<page confidence="0.856937">
20
</page>
<figureCaption confidence="0.991141">
Figure 2: Sample ROC curve for one of the DUC’02 documents
</figureCaption>
<table confidence="0.999383">
Ranking function Degree vectors Converged vectors
Authority 0.625 0.600
Hub 0.620 0.601
Avg(Authority, Hub) 0.651 0.622
Max(Authority, Hub) 0.651 0.624
</table>
<tableCaption confidence="0.999398">
Table 2: Average AUC for each rank calculating function
</tableCaption>
<bodyText confidence="0.999835285714286">
val for the majority rule accuracy according to the
normal approximation of the binomial distribution
with α = 0.05. Table 3 presents classification
results for supervised algorithms (for NaiveBayes
the results shown on the top 2 features) based on
10-fold cross validation as well as results of unsu-
pervised learning.
</bodyText>
<subsectionHeader confidence="0.996049">
4.2 Unsupervised approach
</subsectionHeader>
<bodyText confidence="0.999573">
We have studied the following research questions:
</bodyText>
<listItem confidence="0.998762666666667">
1. Is it possible to induce some classification
model based on HITS scores?
2. Is it necessary to run HITS until convergence?
</listItem>
<bodyText confidence="0.97816472972973">
In order to answer these questions we performed
the following two experiments:
1. In the first one, we run HITS only one it-
eration. Note, that the ranks resulted from
the first iteration are just in-degree and out-
degree scores for each node in graph, and
may be easily computed without even starting
HITS7.
7Initially, both authority and hub vectors (a and h respec-
tively) are set to u = (1, 1, ... ,1). At each iteration HITS
sets an authority vector to a = AT h, and the hub vector to
h = Aa, where A is an adjacency matrix of a graph. So, after
the first iteration, a = AT u and h = Au, that are the vec-
tors containing in-degree and out-degree scores for nodes in a
graph respectively.
2. In the second experiment we run HITS until
convergence8 (different number of steps for
different graphs) and compare the results with
the results of the first experiment.
After each experiment we sorted the nodes of
each graph by rank for each function (see the rank
calculating functions described in Section 3.2).
After the sorting we built an ROC (Receiver Op-
erating Characteristic) curve for each one of the
graphs. Figure 2 demonstrates a sample ROC
curve for one of the documents from DUC 2002
collection.
In order to compare between ranking functions
(see Section 3.2) we calculated the average of AUC
(Area Under Curve) for the 566 ROC curves for
each function. Table 2 presents the average AUC
results for the four functions. According to these
results, functions that take into account both scores
(average and maximum between two scores) are
optimal. We use the average function for compar-
ing and reporting the following results. Also, we
can see that degree vectors give better AUC results
</bodyText>
<footnote confidence="0.998175">
8There are many techniques to evaluate the convergence
achievement. We say that convergence is achieved when for
any vertex i in the graph the difference between the scores
computed at two successive iterations falls below a given
</footnote>
<equation confidence="0.6604596">
|xk+1−xki|
threshold:ixk
i
Tarau,2004)
&lt; 10−3 (Kamvar, 2003; Mihalcea and
</equation>
<page confidence="0.9978">
21
</page>
<figure confidence="0.975326555555556">
35
30
25
20
15
10
5
0
1 29
</figure>
<figureCaption confidence="0.999493">
Figure 3: Cumulative AUC curves for degree and converged vectors
</figureCaption>
<table confidence="0.999581888888889">
Method Accuracy TP FP Precision Recall F-Measure
Classification J48 0.847 0.203 0.022 0.648 0.203 0.309
NaiveBayes 0.839 0.099 0.011 0.648 0.099 0.172
SMO 0.839 0.053 0.002 0.867 0.053 0.100
Degree-based N = 10 0.813 0.186 0.031 0.602 0.186 0.282
Ranking
N = 20 0.799 0.296 0.080 0.480 0.296 0.362
N = 30 0.772 0.377 0.138 0.409 0.377 0.388
N = 40 0.739 0.440 0.200 0.360 0.440 0.392
</table>
<tableCaption confidence="0.998542">
Table 3: Results for each supervised and unsupervised method
</tableCaption>
<bodyText confidence="0.976912117647059">
than converged ones.
In order to compare between the degree-based
vectors and the converged ones we calculated
the precision curves9 for each graph in both ex-
periments. Then for each ranking method the
curve representing an average cumulative AUC
over the 566 precision curves was calculated. Fig-
ure 3 demonstrates the difference between result-
ing curves. As we can conclude from this chart,
the degree-based vectors have a slight advantage
over the converged ones. The ”optimum” point
where the average AUC is maximum for both
methods is 111 words with the average AUC of
28.4 for degree-based words and 33 for HITS-
ranked words. That does not have much signifi-
cance because each document has a different ”op-
timum” point.
</bodyText>
<footnote confidence="0.8824895">
9For each number of top ranked words the percentage of
positive words (belonging to summary) is shown.
</footnote>
<bodyText confidence="0.9999781">
Finally, we compared the results of unsuper-
vised method against the supervised one. For this
purpose, we consider unsupervised model based
on extracting top N ranked words for four differ-
ent values of N: 10, 20, 30 and 40. Table 3 rep-
resents the values for such commonly used met-
rics as: Accuracy, True Positive Rate, False Posi-
tive Rate, Precision, Recall and F-Measure respec-
tively for each one of the tested methods. The op-
timal values are signed in bold.
Despite the relatively poor accuracy perfor-
mance of both approaches, the precision and re-
call results for the unsupervised methods show
that the classification model, where we choose
the top most ranked words, definitely succeeds
compared to the similar keyword extraction meth-
ods. (Leskovec et al., 2004) that is about ”logical
triples” extraction rather than single keyword ex-
traction, presents results on DUC 2002 data, which
are similar to ours in terms of the F-measure (40%
</bodyText>
<page confidence="0.986668">
22
</page>
<bodyText confidence="0.999941777777778">
against 39%) though our method requires much
less linguistic pre-processing and uses a much
smaller feature set (466 features against 8). (Mi-
halcea and Tarau, 2004) includes a more similar
task to ours (single keyword extraction) though
the definition of a keyword is different (”keywords
manually assigned by the indexers” against the
”summary keywords”) and a different dataset (In-
spec) was used for results presentation.
</bodyText>
<sectionHeader confidence="0.999497" genericHeader="evaluation">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999389681818182">
In this paper we have proposed and evaluated two
graph-based approaches: supervised and unsuper-
vised, for the cross-lingual keyword extraction to
be used in extractive summarization of text docu-
ments. The empirical results suggest the follow-
ing. When a large labeled training set of summa-
rized documents is available, the supervised classi-
fication is the most accurate option for identifying
the salient keywords in a document graph. When
there is no high-quality training set of significant
size, it is recommended to use the unsupervised
method based on the node degree ranking, which
also provides a higher F-measure than the super-
vised approach. The intuition behind this conclu-
sion is very simple: most words that are highly
”interconnected” with other words in text (except
stop-words) should contribute to the summary. Ac-
cording to our experimental results, we can extract
up to 15 words with an average precision above
50%. Running HITS to its convergence is redun-
dant, since it does not improve the initial results of
the degree ranking.
</bodyText>
<sectionHeader confidence="0.999917" genericHeader="conclusions">
6 Future work
</sectionHeader>
<bodyText confidence="0.999988304347826">
The next stage of our extractive summarization
methodology is generation of larger units from the
selected keywords. At each step, we are going
to reduce document graphs to contain larger units
(subgraphs) as nodes and apply some ranking al-
gorithms to the reduced graphs. This algorithm is
iterative, where graph reduction steps are repeated
until maximal subgraph size is exceeded or another
constraint is met. Also, we plan to work on the su-
pervised classification of sub-graphs, where many
graph-based features will be extracted and evalu-
ated.
In the future, we also intend to evaluate our
method on additional graph representations of doc-
uments, especially on the concept-based represen-
tation where the graphs are built from the con-
cepts fused from the texts. Once completed, the
graph-based summarization methodology will be
compared to previously developed state-of-the-
art summarization methods and tools. All ex-
periments will include collections of English and
non-English documents to demonstrate the cross-
linguality of our approach.
</bodyText>
<sectionHeader confidence="0.999428" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999897904761905">
S. Brin and L. Page. 1998. The anatomy of a large-
scale hypertextual Web search engine. Computer
Networks and ISDN Systems, 30:1–7.
Document Understanding Documents 2002
[http://www-nlpir.nist.gov/projects/duc/index.html]
Sepandar D. Kamvar, Taher H. Haveliwala, and Gene
H. Golub. Adaptive methods for the computation of
pagerank. Technical report, Stanford University.
Kleinberg, J.M. 1999. Authoritative sources in a
hyperlinked environment. Journal of the ACM,
46(5):604-632.
Last, M. and Markov A. 2005. Identification of terror-
ist web sites with cross-lingual classiffication tools.
In Last, M. and Kandel, A. (Editors), Fighting Terror
in Cyberspace. World Scientific, Series in Machine
Perception and Artificial Intelligence, 65:117–143.
Leskovec, J., Grobelnik, M. and Milic-Frayling, N.
2004. Learning Semantic Graph Mapping for
Document Summarization. In Proceedings of
ECML/PKDD-2004 Workshop on Knowledge Dis-
covery and Ontologies.
Mani, I. and Maybury, M.T. 1999. Advances in Auto-
matic Text Summarization. MIT Press, Cambridge,
MA.
Markov A., Last, M. and Kandel, A. 2007. Fast
Categorization of Web Documents Represented by
Graphs. Advances in Web Mining and Web Usage
Analysis - 8th International Workshop on Knowl-
edge Discovery on the Web, WEBKDD 2006, Re-
vised Papers, O. Nasraoui, et al. (Eds). Springer
Lecture Notes in Computer Science 4811:56–71.
Mihalcea R. 2004. Graph-based ranking algorithms
for sentence extraction, applied to text summariza-
tion. In Proceedings of the 42nd Annual Meeting
of the Association for Computational Lingusitics,
Barcelona, Spain.
Mihalcea and P. Tarau. 2004. TextRank - bringing or-
der into texts. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing,
Barcelona, Spain.
Martin F. Porter. 1980. An algorithm for suffix strip-
ping. Program, 14(3):130137, July.
</reference>
<page confidence="0.970174">
23
</page>
<reference confidence="0.995678166666667">
Nobata, C., Sekine, S., Murata, M., Uchimoto, K.,
Utiyama, M. and Isahara, H. 2001. Sentence extrac-
tion system assembling multiple evidence. In Pro-
ceedings of the Second NTCIR Workshop Meeting,
5–213–218.
Salton, G., Wong, A. and Yang, C. S. 1975. A Vector
Space Model for Automatic Indexing Communica-
tions of the ACM, 18(11):613-620.
Schenker, A., Bunke, H., Last, M., Kandel, A. 2005.
Graph-Theoretic Techniques for Web Content Min-
ing, volume 62. World Scientific, Series in Machine
Perception and Artificial Intelligence.
Peter D. Turney. 2000. Learning Algorithms
for Keyphrase Extraction. Information Retrieval,
2(4):303–336.
Ian H. Witten and Eibe Frank 2005. Data Mining:
Practical machine learning tools and techniques,
2nd Edition, Morgan Kaufmann, San Francisco.
</reference>
<page confidence="0.999157">
24
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.413285">
<title confidence="0.999463">Graph-Based Keyword Extraction for Single-Document Summarization</title>
<author confidence="0.995425">Marina</author>
<affiliation confidence="0.959703666666667">Department Information System Ben-Gurion University of the</affiliation>
<address confidence="0.864157">Beer-Sheva 84105,</address>
<email confidence="0.995902">litvakm@bgu.ac.il</email>
<author confidence="0.992266">Mark</author>
<affiliation confidence="0.974119333333333">Department Information System Ben-Gurion University of the</affiliation>
<address confidence="0.716434">Beer-Sheva 84105,</address>
<email confidence="0.992626">mlast@bgu.ac.il</email>
<abstract confidence="0.990289">In this paper, we introduce and compare between two novel approaches, supervised and unsupervised, for identifying the keywords to be used in extractive summarization of text documents. Both our approaches are based on the graph-based syntactic representation of text and web documents, which enhances the traditional vector-space model by taking into account some structural document features. In the supervised approach, we train classification algorithms on a summarized collection of documents with the purpose of inducing a keyword identification model. In the unsupervised approach, we run the HITS algorithm on document graphs under the assumption that the top-ranked nodes should represent the document keywords. Our experiments on a collection of benchmark summaries show that given a set of summarized training documents, the supervised classification provides the highest keyword identification accuracy, while the highest F-measure is reached with a simple degree-based ranking. In addition, it is sufficient to perform only the first iteration of HITS rather than running it to its convergence.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Brin</author>
<author>L Page</author>
</authors>
<title>The anatomy of a largescale hypertextual Web search engine.</title>
<date>1998</date>
<journal>Computer Networks and ISDN Systems,</journal>
<pages>30--1</pages>
<contexts>
<context position="5098" citStr="Brin and Page, 1998" startWordPosition="744" endWordPosition="747">he graph construction procedure (except for the technical upgrade of implementation for multilingual processing of text, like reading Unicode or language-specific encodings, etc.) (Markov et al., 2007; Last and Markov, 2005). Of course, as a supervised approach it requires high-quality training labeled data. Our second approach uses a technique that does not require any training data. To extract the summary keywords, we apply a ranking algorithm called HITS (Kleinberg, 1999) to directed graphs representing source documents. Authors of (Mihalcea and Tarau, 2004) applied the PageRank algorithm (Brin and Page, 1998) for keyword extraction using a simpler graph representation (undirected unweighted graphs), and show that their results compare favorably with results on established benchmarks of manually assigned keywords. (Mihalcea and Tarau, 2004) are also using the HITS algorithm for automatic sentence extraction from documents represented by graphs built from sentences connected by similarity relationships. Since we work with directed graphs, HITS is the most appropriate algorithm for our task as it takes into account both in-degree and out-degree of nodes. We show in our experiments that running HITS t</context>
<context position="10669" citStr="Brin and Page, 1998" startWordPosition="1663" endWordPosition="1666">on score (Nobata et al., 2001). In this paper, we calculate it as an reciprocal of the sentence location in text: Score (Si) = 1 i 4There are many different formulas used to calculate tfidf. We use the next formula: tf |D| tf+1 loge df , where tf -term frequency (as defined above), IDI - total number of documents in the corpus, df - number of documents where the term appears. • Headline Score E {0, 1}, equals to 1 iff document headline contains word represented by node. 3.2 The Unsupervised approach Ranking algorithms, such as Kleinberg’s HITS algorithm (Kleinberg, 1999) or Google’s PageRank (Brin and Page, 1998) have been elaborated and used in Web-link analysis for the purpose of optimizating the search performance on the Web. These algorithms recursively assign a numerical weight to each element of a hyperlinked set of documents, determining how important each page is. A hyperlink to a page counts as a vote of support. A page that is linked to by many important pages (with high rank) receives a high rank itself. A similar idea can be applied to lexical or semantic graphs extracted from text documents, in order to extract the most significant blocks (words, phrases, sentences, etc.) for the summary </context>
</contexts>
<marker>Brin, Page, 1998</marker>
<rawString>S. Brin and L. Page. 1998. The anatomy of a largescale hypertextual Web search engine. Computer Networks and ISDN Systems, 30:1–7.</rawString>
</citation>
<citation valid="false">
<date>2002</date>
<institution>Document Understanding Documents</institution>
<note>[http://www-nlpir.nist.gov/projects/duc/index.html]</note>
<marker>2002</marker>
<rawString>Document Understanding Documents 2002 [http://www-nlpir.nist.gov/projects/duc/index.html]</rawString>
</citation>
<citation valid="false">
<authors>
<author>Sepandar D Kamvar</author>
<author>Taher H Haveliwala</author>
<author>Gene H Golub</author>
</authors>
<title>Adaptive methods for the computation of pagerank.</title>
<tech>Technical report,</tech>
<institution>Stanford University.</institution>
<marker>Kamvar, Haveliwala, Golub, </marker>
<rawString>Sepandar D. Kamvar, Taher H. Haveliwala, and Gene H. Golub. Adaptive methods for the computation of pagerank. Technical report, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Kleinberg</author>
</authors>
<title>Authoritative sources in a hyperlinked environment.</title>
<date>1999</date>
<journal>Journal of the ACM,</journal>
<pages>46--5</pages>
<contexts>
<context position="4957" citStr="Kleinberg, 1999" startWordPosition="724" endWordPosition="725">language-independent graph representation of documents, it can be applied to various languages and domains without any modifications of the graph construction procedure (except for the technical upgrade of implementation for multilingual processing of text, like reading Unicode or language-specific encodings, etc.) (Markov et al., 2007; Last and Markov, 2005). Of course, as a supervised approach it requires high-quality training labeled data. Our second approach uses a technique that does not require any training data. To extract the summary keywords, we apply a ranking algorithm called HITS (Kleinberg, 1999) to directed graphs representing source documents. Authors of (Mihalcea and Tarau, 2004) applied the PageRank algorithm (Brin and Page, 1998) for keyword extraction using a simpler graph representation (undirected unweighted graphs), and show that their results compare favorably with results on established benchmarks of manually assigned keywords. (Mihalcea and Tarau, 2004) are also using the HITS algorithm for automatic sentence extraction from documents represented by graphs built from sentences connected by similarity relationships. Since we work with directed graphs, HITS is the most appro</context>
<context position="10626" citStr="Kleinberg, 1999" startWordPosition="1657" endWordPosition="1658">ariants for calculating sentence location score (Nobata et al., 2001). In this paper, we calculate it as an reciprocal of the sentence location in text: Score (Si) = 1 i 4There are many different formulas used to calculate tfidf. We use the next formula: tf |D| tf+1 loge df , where tf -term frequency (as defined above), IDI - total number of documents in the corpus, df - number of documents where the term appears. • Headline Score E {0, 1}, equals to 1 iff document headline contains word represented by node. 3.2 The Unsupervised approach Ranking algorithms, such as Kleinberg’s HITS algorithm (Kleinberg, 1999) or Google’s PageRank (Brin and Page, 1998) have been elaborated and used in Web-link analysis for the purpose of optimizating the search performance on the Web. These algorithms recursively assign a numerical weight to each element of a hyperlinked set of documents, determining how important each page is. A hyperlink to a page counts as a vote of support. A page that is linked to by many important pages (with high rank) receives a high rank itself. A similar idea can be applied to lexical or semantic graphs extracted from text documents, in order to extract the most significant blocks (words,</context>
</contexts>
<marker>Kleinberg, 1999</marker>
<rawString>Kleinberg, J.M. 1999. Authoritative sources in a hyperlinked environment. Journal of the ACM, 46(5):604-632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Last</author>
<author>A Markov</author>
</authors>
<title>Identification of terrorist web sites with cross-lingual classiffication tools. In</title>
<date>2005</date>
<booktitle>Series in Machine Perception and Artificial Intelligence,</booktitle>
<pages>65--117</pages>
<contexts>
<context position="4702" citStr="Last and Markov, 2005" startWordPosition="681" endWordPosition="684"> and Maybury, 1999). However, in spite of the reasonable performance of such algorithms they cannot be adapted to new languages or domains without training on each new type of data. Our first approach also utilizes classification algorithms, but, thanks to the language-independent graph representation of documents, it can be applied to various languages and domains without any modifications of the graph construction procedure (except for the technical upgrade of implementation for multilingual processing of text, like reading Unicode or language-specific encodings, etc.) (Markov et al., 2007; Last and Markov, 2005). Of course, as a supervised approach it requires high-quality training labeled data. Our second approach uses a technique that does not require any training data. To extract the summary keywords, we apply a ranking algorithm called HITS (Kleinberg, 1999) to directed graphs representing source documents. Authors of (Mihalcea and Tarau, 2004) applied the PageRank algorithm (Brin and Page, 1998) for keyword extraction using a simpler graph representation (undirected unweighted graphs), and show that their results compare favorably with results on established benchmarks of manually assigned keywo</context>
</contexts>
<marker>Last, Markov, 2005</marker>
<rawString>Last, M. and Markov A. 2005. Identification of terrorist web sites with cross-lingual classiffication tools. In Last, M. and Kandel, A. (Editors), Fighting Terror in Cyberspace. World Scientific, Series in Machine Perception and Artificial Intelligence, 65:117–143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Leskovec</author>
<author>M Grobelnik</author>
<author>N Milic-Frayling</author>
</authors>
<title>Learning Semantic Graph Mapping for Document Summarization.</title>
<date>2004</date>
<booktitle>In Proceedings of ECML/PKDD-2004 Workshop on Knowledge Discovery and Ontologies.</booktitle>
<contexts>
<context position="2720" citStr="Leskovec et al., 2004" startWordPosition="388" endWordPosition="391"> a word presenting in the document summary. The supervised learning approach for keywords extraction was first suggested in (Turney, 2000), where parametrized heuristic rules were combined with a genetic algorithm into a system - GenEx - that automatically identified keywords in a document. For both our approaches, we utilize a graphbased representation for text documents. Such representations may vary from very simple, syntactic ones like words connected by edges representing co-occurrence relation (Mihalcea and Tarau, 2004) to more complex ones like concepts connected by semantic relations (Leskovec et al., 2004). The main advantage of a syntactic representation is its language independency, while the semantic graphs representation provide new characteristics of text such as its captured semantic structure that itself can serve as a document surrogate and provide means for document navigation. Authors of (Leskovec et al., 2004) reduce the problem of summarization to acquiring machine learning models for mapping between the document graph and the graph of a summary. Using deep linguistic analysis, they extract sub-structures (subjectpredicateobject triples) from document semantic graphs in order to get</context>
<context position="19364" citStr="Leskovec et al., 2004" startWordPosition="3149" endWordPosition="3152">extracting top N ranked words for four different values of N: 10, 20, 30 and 40. Table 3 represents the values for such commonly used metrics as: Accuracy, True Positive Rate, False Positive Rate, Precision, Recall and F-Measure respectively for each one of the tested methods. The optimal values are signed in bold. Despite the relatively poor accuracy performance of both approaches, the precision and recall results for the unsupervised methods show that the classification model, where we choose the top most ranked words, definitely succeeds compared to the similar keyword extraction methods. (Leskovec et al., 2004) that is about ”logical triples” extraction rather than single keyword extraction, presents results on DUC 2002 data, which are similar to ours in terms of the F-measure (40% 22 against 39%) though our method requires much less linguistic pre-processing and uses a much smaller feature set (466 features against 8). (Mihalcea and Tarau, 2004) includes a more similar task to ours (single keyword extraction) though the definition of a keyword is different (”keywords manually assigned by the indexers” against the ”summary keywords”) and a different dataset (Inspec) was used for results presentation</context>
</contexts>
<marker>Leskovec, Grobelnik, Milic-Frayling, 2004</marker>
<rawString>Leskovec, J., Grobelnik, M. and Milic-Frayling, N. 2004. Learning Semantic Graph Mapping for Document Summarization. In Proceedings of ECML/PKDD-2004 Workshop on Knowledge Discovery and Ontologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mani</author>
<author>M T Maybury</author>
</authors>
<date>1999</date>
<booktitle>Advances in Automatic Text Summarization.</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="4099" citStr="Mani and Maybury, 1999" startWordPosition="591" endWordPosition="594"> linguistic processing. In 17 Coling 2008: Proceedings of the workshop on Multi-source Multilingual Information Extraction and Summarization, pages 17–24 Manchester, August 2008 this paper, we perform experiments with directed graphs, where the nodes stand for words/phrases and the edges represent syntactic relationships between them, meaning ¨followed by¨ (Schenker et al., 2005). Some of the most successful approaches to extractive summarization utilize supervised learning algorithms that are trained on collections of ”ground truth” summaries built for a relatively large number of documents (Mani and Maybury, 1999). However, in spite of the reasonable performance of such algorithms they cannot be adapted to new languages or domains without training on each new type of data. Our first approach also utilizes classification algorithms, but, thanks to the language-independent graph representation of documents, it can be applied to various languages and domains without any modifications of the graph construction procedure (except for the technical upgrade of implementation for multilingual processing of text, like reading Unicode or language-specific encodings, etc.) (Markov et al., 2007; Last and Markov, 20</context>
</contexts>
<marker>Mani, Maybury, 1999</marker>
<rawString>Mani, I. and Maybury, M.T. 1999. Advances in Automatic Text Summarization. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Markov</author>
<author>M Last</author>
<author>A Kandel</author>
</authors>
<title>Fast Categorization of Web Documents Represented by Graphs. Advances in Web Mining and Web Usage Analysis</title>
<date>2007</date>
<journal>Lecture Notes in Computer Science</journal>
<booktitle>8th International Workshop on Knowledge Discovery on the Web, WEBKDD 2006, Revised</booktitle>
<pages>4811--56</pages>
<publisher>Springer</publisher>
<contexts>
<context position="4678" citStr="Markov et al., 2007" startWordPosition="677" endWordPosition="680">er of documents (Mani and Maybury, 1999). However, in spite of the reasonable performance of such algorithms they cannot be adapted to new languages or domains without training on each new type of data. Our first approach also utilizes classification algorithms, but, thanks to the language-independent graph representation of documents, it can be applied to various languages and domains without any modifications of the graph construction procedure (except for the technical upgrade of implementation for multilingual processing of text, like reading Unicode or language-specific encodings, etc.) (Markov et al., 2007; Last and Markov, 2005). Of course, as a supervised approach it requires high-quality training labeled data. Our second approach uses a technique that does not require any training data. To extract the summary keywords, we apply a ranking algorithm called HITS (Kleinberg, 1999) to directed graphs representing source documents. Authors of (Mihalcea and Tarau, 2004) applied the PageRank algorithm (Brin and Page, 1998) for keyword extraction using a simpler graph representation (undirected unweighted graphs), and show that their results compare favorably with results on established benchmarks of</context>
</contexts>
<marker>Markov, Last, Kandel, 2007</marker>
<rawString>Markov A., Last, M. and Kandel, A. 2007. Fast Categorization of Web Documents Represented by Graphs. Advances in Web Mining and Web Usage Analysis - 8th International Workshop on Knowledge Discovery on the Web, WEBKDD 2006, Revised Papers, O. Nasraoui, et al. (Eds). Springer Lecture Notes in Computer Science 4811:56–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
</authors>
<title>Graph-based ranking algorithms for sentence extraction, applied to text summarization.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Lingusitics,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="11311" citStr="Mihalcea, 2004" startWordPosition="1775" endWordPosition="1776">sed in Web-link analysis for the purpose of optimizating the search performance on the Web. These algorithms recursively assign a numerical weight to each element of a hyperlinked set of documents, determining how important each page is. A hyperlink to a page counts as a vote of support. A page that is linked to by many important pages (with high rank) receives a high rank itself. A similar idea can be applied to lexical or semantic graphs extracted from text documents, in order to extract the most significant blocks (words, phrases, sentences, etc.) for the summary (Mihalcea and Tarau, 2004; Mihalcea, 2004). In this paper, we apply the HITS algorithm to document graphs and evaluate its performance on automatic unsupervised text unit extraction in the context of the text summarization task. The HITS algorithm distinguishes between ”authorities” (pages with a large number of incoming links) and ”hubs” (pages with a large number of outgoing links). For each node, HITS produces two sets of scores - an ”authority” score, and a ”hub” score: HITSA (Vi) = � HITSH (Vj) (1) Vj∈In(Vi) HITSH (Vi) = � HITSA (Vj) (2) Vj∈Out(Vi) For the total rank (H) calculation we used the following four functions: 1. rank e</context>
</contexts>
<marker>Mihalcea, 2004</marker>
<rawString>Mihalcea R. 2004. Graph-based ranking algorithms for sentence extraction, applied to text summarization. In Proceedings of the 42nd Annual Meeting of the Association for Computational Lingusitics, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihalcea</author>
<author>P Tarau</author>
</authors>
<title>TextRank - bringing order into texts.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="2629" citStr="Mihalcea and Tarau, 2004" startWordPosition="374" endWordPosition="377">tive summarization of text documents. Thus, according to our problem statement, the keyword is a word presenting in the document summary. The supervised learning approach for keywords extraction was first suggested in (Turney, 2000), where parametrized heuristic rules were combined with a genetic algorithm into a system - GenEx - that automatically identified keywords in a document. For both our approaches, we utilize a graphbased representation for text documents. Such representations may vary from very simple, syntactic ones like words connected by edges representing co-occurrence relation (Mihalcea and Tarau, 2004) to more complex ones like concepts connected by semantic relations (Leskovec et al., 2004). The main advantage of a syntactic representation is its language independency, while the semantic graphs representation provide new characteristics of text such as its captured semantic structure that itself can serve as a document surrogate and provide means for document navigation. Authors of (Leskovec et al., 2004) reduce the problem of summarization to acquiring machine learning models for mapping between the document graph and the graph of a summary. Using deep linguistic analysis, they extract su</context>
<context position="5045" citStr="Mihalcea and Tarau, 2004" startWordPosition="734" endWordPosition="738">rious languages and domains without any modifications of the graph construction procedure (except for the technical upgrade of implementation for multilingual processing of text, like reading Unicode or language-specific encodings, etc.) (Markov et al., 2007; Last and Markov, 2005). Of course, as a supervised approach it requires high-quality training labeled data. Our second approach uses a technique that does not require any training data. To extract the summary keywords, we apply a ranking algorithm called HITS (Kleinberg, 1999) to directed graphs representing source documents. Authors of (Mihalcea and Tarau, 2004) applied the PageRank algorithm (Brin and Page, 1998) for keyword extraction using a simpler graph representation (undirected unweighted graphs), and show that their results compare favorably with results on established benchmarks of manually assigned keywords. (Mihalcea and Tarau, 2004) are also using the HITS algorithm for automatic sentence extraction from documents represented by graphs built from sentences connected by similarity relationships. Since we work with directed graphs, HITS is the most appropriate algorithm for our task as it takes into account both in-degree and out-degree of </context>
<context position="7166" citStr="Mihalcea and Tarau, 2004" startWordPosition="1078" endWordPosition="1081">ach distinct word is created even if it appears more than once in the text. Thus each vertex label in the graph is unique. If a word a immediately precedes a word b in the same sentence somewhere in the document, then there is a directed edge from the vertex corresponding to term a to the vertex corresponding to term b. Sentence terminating punctuation marks (periods, question marks, and exclamation points) are taken by us into account and an edge is not created when these are present between two words. This definition of graph edges is slightly different from co-occurrence relations used in (Mihalcea and Tarau, 2004) for building undirected document graphs, where the order of word occurrence is ignored and the size of the cooccurrence window is varied between 2 and 10. Sections defined for HTML documents are: title, which contains the text related to the document’s title and any provided keywords (meta-data) and text, which comprises any of the readable text in the document. This simple representation can be extended to many different variations like a semantic graph where nodes stand for concepts and edges represent semantic relations between them or a more detailed syntactic graph where edges and nodes </context>
<context position="11294" citStr="Mihalcea and Tarau, 2004" startWordPosition="1770" endWordPosition="1774">have been elaborated and used in Web-link analysis for the purpose of optimizating the search performance on the Web. These algorithms recursively assign a numerical weight to each element of a hyperlinked set of documents, determining how important each page is. A hyperlink to a page counts as a vote of support. A page that is linked to by many important pages (with high rank) receives a high rank itself. A similar idea can be applied to lexical or semantic graphs extracted from text documents, in order to extract the most significant blocks (words, phrases, sentences, etc.) for the summary (Mihalcea and Tarau, 2004; Mihalcea, 2004). In this paper, we apply the HITS algorithm to document graphs and evaluate its performance on automatic unsupervised text unit extraction in the context of the text summarization task. The HITS algorithm distinguishes between ”authorities” (pages with a large number of incoming links) and ”hubs” (pages with a large number of outgoing links). For each node, HITS produces two sets of scores - an ”authority” score, and a ”hub” score: HITSA (Vi) = � HITSH (Vj) (1) Vj∈In(Vi) HITSH (Vi) = � HITSA (Vj) (2) Vj∈Out(Vi) For the total rank (H) calculation we used the following four fun</context>
<context position="19706" citStr="Mihalcea and Tarau, 2004" startWordPosition="3204" endWordPosition="3208"> poor accuracy performance of both approaches, the precision and recall results for the unsupervised methods show that the classification model, where we choose the top most ranked words, definitely succeeds compared to the similar keyword extraction methods. (Leskovec et al., 2004) that is about ”logical triples” extraction rather than single keyword extraction, presents results on DUC 2002 data, which are similar to ours in terms of the F-measure (40% 22 against 39%) though our method requires much less linguistic pre-processing and uses a much smaller feature set (466 features against 8). (Mihalcea and Tarau, 2004) includes a more similar task to ours (single keyword extraction) though the definition of a keyword is different (”keywords manually assigned by the indexers” against the ”summary keywords”) and a different dataset (Inspec) was used for results presentation. 5 Conclusions In this paper we have proposed and evaluated two graph-based approaches: supervised and unsupervised, for the cross-lingual keyword extraction to be used in extractive summarization of text documents. The empirical results suggest the following. When a large labeled training set of summarized documents is available, the supe</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>Mihalcea and P. Tarau. 2004. TextRank - bringing order into texts. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin F Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<volume>14</volume>
<issue>3</issue>
<marker>Porter, 1980</marker>
<rawString>Martin F. Porter. 1980. An algorithm for suffix stripping. Program, 14(3):130137, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Nobata</author>
<author>S Sekine</author>
<author>M Murata</author>
<author>K Uchimoto</author>
<author>M Utiyama</author>
<author>H Isahara</author>
</authors>
<title>Sentence extraction system assembling multiple evidence.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second NTCIR Workshop Meeting,</booktitle>
<pages>5--213</pages>
<contexts>
<context position="9133" citStr="Nobata et al., 2001" startWordPosition="1393" endWordPosition="1396">lem is reduced to the salient nodes extraction in graphs. 3.1 The Supervised approach In this approach, we try to identify the salient nodes of document graphs by training a classification algorithm on a repository of summarized documents such as (DUC, 2002) with the purpose of inducing a keyword identification model. Each node of every document graph belongs to one of two classes: YES if the corresponding word is included in the document extractive summary and NO otherwise. We consider the graph-based features (e.g., degree) characterizing graph structure as well as statistic-based features (Nobata et al., 2001) characterizing text content represented by a node. The complete list of features, along with their formal definitions, is provided below: • In Degree - number of incoming edges • Out Degree - number of outcoming edges • Degree - total number of edges • Frequency - term frequency of word represented by node1 • Frequent words distribution E {0, 1}, equals to 1 iff Frequency≥threshold2 • Location Score - calculates an average of location scores between all sentences3 containing the word N represented by node (denote these sentences as S(N)): Score (N) = ESi∈S(N) Score (Si) |S (N)| • Tfidf Score </context>
</contexts>
<marker>Nobata, Sekine, Murata, Uchimoto, Utiyama, Isahara, 2001</marker>
<rawString>Nobata, C., Sekine, S., Murata, M., Uchimoto, K., Utiyama, M. and Isahara, H. 2001. Sentence extraction system assembling multiple evidence. In Proceedings of the Second NTCIR Workshop Meeting, 5–213–218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>A Wong</author>
<author>C S Yang</author>
</authors>
<title>A Vector Space Model for Automatic Indexing</title>
<date>1975</date>
<journal>Communications of the ACM,</journal>
<pages>18--11</pages>
<marker>Salton, Wong, Yang, 1975</marker>
<rawString>Salton, G., Wong, A. and Yang, C. S. 1975. A Vector Space Model for Automatic Indexing Communications of the ACM, 18(11):613-620.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Schenker</author>
<author>H Bunke</author>
<author>M Last</author>
<author>A Kandel</author>
</authors>
<title>Graph-Theoretic Techniques for Web Content Mining, volume 62. World Scientific,</title>
<date>2005</date>
<booktitle>Series in Machine Perception and Artificial Intelligence.</booktitle>
<contexts>
<context position="3858" citStr="Schenker et al., 2005" startWordPosition="555" endWordPosition="558">tures (subjectpredicateobject triples) from document semantic graphs in order to get a summary. Contrary to (Leskovec et al., 2004), both our approaches work with a syntactic representation that does not require almost any language-specific linguistic processing. In 17 Coling 2008: Proceedings of the workshop on Multi-source Multilingual Information Extraction and Summarization, pages 17–24 Manchester, August 2008 this paper, we perform experiments with directed graphs, where the nodes stand for words/phrases and the edges represent syntactic relationships between them, meaning ¨followed by¨ (Schenker et al., 2005). Some of the most successful approaches to extractive summarization utilize supervised learning algorithms that are trained on collections of ”ground truth” summaries built for a relatively large number of documents (Mani and Maybury, 1999). However, in spite of the reasonable performance of such algorithms they cannot be adapted to new languages or domains without training on each new type of data. Our first approach also utilizes classification algorithms, but, thanks to the language-independent graph representation of documents, it can be applied to various languages and domains without an</context>
<context position="6306" citStr="Schenker et al., 2005" startWordPosition="930" endWordPosition="933">running HITS till convergence is not necessary, and initial weights that we get after the first iteration of algorithm are good enough for rank-based extraction of summary keywords. Another important conclusion that was infered from our experimental results is that, given the training data in the form of annotated syntactic graphs, supervised classification is the most accurate option for identifying the salient nodes in a document graph, while a simple degreebased ranking provides the highest F-measure. 2 Document representation Currently, we use the ”simple” graph representation defined in (Schenker et al., 2005) that holds unlabeled edges representing order-relationship between the the words represented by nodes. The stemming and stopword removal operations of basic text preprocessing are done before graph building. Only a single vertex for each distinct word is created even if it appears more than once in the text. Thus each vertex label in the graph is unique. If a word a immediately precedes a word b in the same sentence somewhere in the document, then there is a directed edge from the vertex corresponding to term a to the vertex corresponding to term b. Sentence terminating punctuation marks (per</context>
<context position="7937" citStr="Schenker et al., 2005" startWordPosition="1197" endWordPosition="1200">nd 10. Sections defined for HTML documents are: title, which contains the text related to the document’s title and any provided keywords (meta-data) and text, which comprises any of the readable text in the document. This simple representation can be extended to many different variations like a semantic graph where nodes stand for concepts and edges represent semantic relations between them or a more detailed syntactic graph where edges and nodes are labeled by significant information like frequency, location, similarity, distance, etc. The syntactic graph-based representations were shown in (Schenker et al., 2005) to outperform the classical vector-space model on several clustering and classification tasks. We choose the ”simple” representation as a representation that saves processing time and memory resources as well as gives nearly the best results for the two above text mining tasks. 3 Keywords extraction In this paper, we deal with the first stage of extractive summarization where the most salient words (”keywords”) are extracted in order to generate a 18 summary. Since each distinct word in a text is represented by a node in the document graph, the keywords extraction problem is reduced to the sa</context>
</contexts>
<marker>Schenker, Bunke, Last, Kandel, 2005</marker>
<rawString>Schenker, A., Bunke, H., Last, M., Kandel, A. 2005. Graph-Theoretic Techniques for Web Content Mining, volume 62. World Scientific, Series in Machine Perception and Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Learning Algorithms for Keyphrase Extraction.</title>
<date>2000</date>
<journal>Information Retrieval,</journal>
<volume>2</volume>
<issue>4</issue>
<contexts>
<context position="2236" citStr="Turney, 2000" startWordPosition="317" endWordPosition="318">ercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. the purpose of generating the summary - main document information expressed in ”a few words”. In this paper, we introduce and compare between two approaches: supervised and unsupervised, for the cross-lingual keyword extraction to be used as the first step in extractive summarization of text documents. Thus, according to our problem statement, the keyword is a word presenting in the document summary. The supervised learning approach for keywords extraction was first suggested in (Turney, 2000), where parametrized heuristic rules were combined with a genetic algorithm into a system - GenEx - that automatically identified keywords in a document. For both our approaches, we utilize a graphbased representation for text documents. Such representations may vary from very simple, syntactic ones like words connected by edges representing co-occurrence relation (Mihalcea and Tarau, 2004) to more complex ones like concepts connected by semantic relations (Leskovec et al., 2004). The main advantage of a syntactic representation is its language independency, while the semantic graphs represent</context>
</contexts>
<marker>Turney, 2000</marker>
<rawString>Peter D. Turney. 2000. Learning Algorithms for Keyphrase Extraction. Information Retrieval, 2(4):303–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
</authors>
<title>Data Mining: Practical machine learning tools and techniques, 2nd Edition,</title>
<date>2005</date>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco.</location>
<contexts>
<context position="13158" citStr="Witten and Frank, 2005" startWordPosition="2100" endWordPosition="2103">32 0.830 0.828 0.826 0.824 8 7 6 5 4 size of the featu cy Figure 1: Accuracy for NaiveBayes classifier (NBC) and Majority Rule (MR) 4 Experimental results All experiments have been performed on the collection of summarized news articles provided by the Document Understanding Conference 2002 (DUC, 2002). This collection contains 566 English texts along with 2-3 summaries per document on average. The size5 of syntactic graphs extracted from these texts is 196 on average, varying from 62 to 876. 4.1 Supervised approach We utilized several classification algorithms implemented in Weka’s software (Witten and Frank, 2005) : J48 (known as C4.5), SMO (Support Vector Machine) and NaiveBayes for building binary classification models (a word belongs to summary / does not belong to the summary). For the training we built dataset with two classes: YES for nodes belonging to at least one summary of the docu5We define the size of a graph as the number of its vertices. ment, and NO for those that do not belong to any summary. The accuracy of the default (majority) rule over all nodes is equal to the percentage of non-salient nodes (83.17%). For better classification results we examined the importance of each one of the </context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>Ian H. Witten and Eibe Frank 2005. Data Mining: Practical machine learning tools and techniques, 2nd Edition, Morgan Kaufmann, San Francisco.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>