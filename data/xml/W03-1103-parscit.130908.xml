<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<title confidence="0.999089">
An Approach for Combining Content-based and Collaborative Filters
</title>
<author confidence="0.999486">
Qing Li
</author>
<affiliation confidence="0.9972985">
Dept. of Computer Sciences
Kumoh National Institute of Technology
</affiliation>
<address confidence="0.607573">
Kumi, kyungpook, 730-701,South Korea
</address>
<email confidence="0.996154">
liqing@se.Kumoh.ac.kr
</email>
<author confidence="0.991599">
Byeong Man Kim
</author>
<affiliation confidence="0.9965485">
Dept. of Computer Sciences
Kumoh National Institute of Technology
</affiliation>
<address confidence="0.607806">
Kumi, kyungpook, 730-701,South Korea
</address>
<email confidence="0.997338">
bmkim@se.Kumoh.ac.kr
</email>
<sectionHeader confidence="0.998586" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999804">
In this work, we apply a clustering tech-
nique to integrate the contents of items
into the item-based collaborative filtering
framework. The group rating information
that is obtained from the clustering result
provides a way to introduce content in-
formation into collaborative recommenda-
tion and solves the cold start problem.
Extensive experiments have been con-
ducted on MovieLens data to analyze the
characteristics of our technique. The re-
sults show that our approach contributes
to the improvement of prediction quality
of the item-based collaborative filtering,
especially for the cold start problem.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9768839375">
There are two dominant research paradigms of in-
formation filtering: content-based and collabora-
tive filtering. Content-based filtering selects the
right information for users by comparing represen-
tations of searching information to representations
of contents of user profiles which express interests
of users. Content-based information filtering has
proven to be effective in locating textual items
relevant to a topic using techniques, such as Boo-
lean queries (Anick et al., 1990; Lee et al., 1993;
Verhoeff et al., 1961), vector-space queries (Salton
and Buckley, 1998), probabilistic model (Robert-
son and Sparck, 1976), neural network (Kim and
Raghavan, 2000) and fuzzy set model (Ogawa et
This work was supported by Korea Research Foundation
Grant (KRF-2002-041-D00459).
</bodyText>
<listItem confidence="0.943969625">
al., 1991). However, content-based filtering has
some limitations:
• It is hard for content-based filtering to pro-
vide serendipitous recommendations, be-
cause all the information is selected and
recommended based on the content.
• It is hard for novices to use content-based
systems effectively.
</listItem>
<bodyText confidence="0.998319785714285">
Collaborative filtering is the technique of using
peer opinions to predict the interests of others. A
target user is matched against the database to dis-
cover neighbors, who have historically had similar
interests to target user. Items that neighbors like
are then recommended to the target user. The Tap-
estry text filtering system, developed by Nichols
and others at the Xerox Palo Alto Research Center
(PARC), applied collaborative filtering (Douglas,
1993; Harman, 1994). The GroupLens project at
the University of Minnesota is a popular collabora-
tive system. Collaborative systems have been
widely used in so many areas, such as Ringo sys-
tem recommends music albums (Upendar and Patti,
1995), MovieLens system recommends movies,
Jeter system recommends jokes (Gupta et al., 1999)
and Flycasting recommends online radio (Hauver,
2001).
Collaborative filtering system overcomes some
limitations of content-based filtering. The system
can suggest items (the things to be recommended,
such as books, music etc.) to users and recommen-
dations are based on the ratings of items, instead of
the contents of the items, which can improve the
quality of recommendations. Although collabora-
tive filtering has been successfully used in both
research and practice, there still remain some chal-
lenges for it as an efficient information filtering.
</bodyText>
<listItem confidence="0.958375714285714">
• Cold start problem, where recommendations
are required for items that no user has yet
rated.
• Although collaborative filtering can improve
the quality of recommendations based on the
user ratings, it completely denies any infor-
mation that can be extracted from contents.
</listItem>
<bodyText confidence="0.9998820625">
It is obvious that the content-based filtering
does not suffer the above problems. So it is a natu-
ral way to combine them in order to achieve a bet-
ter performance of filtering, and take the
advantages of each.
The rest of the paper is organized as follows.
The next section provides a brief describing of re-
lated work. In section 3, we present the detail algo-
rithmic components of our approach, and look into
the methods of grouping items, calculating the
similarities between items and solving the cold
start problem. Section 4 describes our experimental
work. It provides details of our data sets, evalua-
tion metrics, results of our experiment and discus-
sion of the results. The final section provides some
concluding remarks.
</bodyText>
<sectionHeader confidence="0.999849" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.976458923076923">
Proposed approaches to hybrid system, which
combines content-based and collaborative filters
together, can be categorized into two groups.
One group is the linear combination of results
of collaborative and content-based filtering, such
as systems that are described by Claypool (1999)
and Wasfi (1999). ProfBuilder (Wasfi, 1999) rec-
ommends web pages using both content-based and
collaborative filters, and each creates a recommen-
dation list without combining them to make a
combined prediction. Claypool (1999) describes a
hybrid approach for an online newspaper domain,
combining the two predictions using an adaptive
weighted average: as the number of users access-
ing an item increases, the weight of the collabora-
tive component tends to increase. But how to
decide the weights of collaborative and content-
based components is unclearly given by the author.
The other group is the sequential combination
of content-based filtering and collaborative filter-
ing. In this system, firstly, content-based filtering
algorithm is applied to find users, who share simi-
lar interests. Secondly, collaborative algorithm is
applied to make predictions, such as RAAP
(Delgado et al., 1998) and Fab filtering systems
(Balabanovic and Shoham, 1990). RAAP is a con-
tent-based collaborative information filtering for
helping the user to classify domain specific infor-
mation found in the WWW, and also recommends
these URLs to other users with similar interests. To
decide the similar interests of users is using scal-
able Pearson correlation algorithm based on web
page category. Fab system, which uses content-
based techniques instead of user ratings to create
profiles of users. So the quality of predictions is
fully depended on the content-based techniques,
inaccurate profiles result in inaccurate correlations
with other users and thus make poor predictions.
As for collaborative recommendation, there are
two ways to calculate the similarity for clique rec-
ommendation – item-based and user-based. Sarwar
(Sarwar et al, 2001) has proved that item-based
collaborative filtering is better than user-based col-
laborative filtering at precision and computation
complexity.
Item
group
vector
rater
Group Clustering Item
content
Figure1. Overview of the our approach
</bodyText>
<sectionHeader confidence="0.853736" genericHeader="method">
3 Overview of our approach
</sectionHeader>
<bodyText confidence="0.999913">
In this paper, we suggest a technique that intro-
duces the contents of items into the item-based
collaborative filtering to improve its prediction
quality and solve the cold start problem. Shortly,
we call the technique ICHM (Item-based Cluster-
ing Hybrid Method).
In ICHM, we integrate the item information and
user ratings to calculate the item-item similarity.
Figure 1 shows this procedure. The detail proce-
dure of our approach is described as follows:
</bodyText>
<listItem confidence="0.997472111111111">
• Apply clustering algorithm to group the
items, then use the result, which is repre-
sented by the fuzzy set, to create a group-
rating matrix.
• Compute the similarity: firstly, calculate the
similarity of group-rating matrix using ad-
justed-cosine algorithm, then calculate the
similarity of item-rating matrix using Pear-
son correlation-based algorithm. At last, the
</listItem>
<figure confidence="0.99459">
Rating Data
+
Item
rating
Group
rating
Collaborative
filter
</figure>
<bodyText confidence="0.763293">
total similarity is the linear combination of
the above two.
</bodyText>
<listItem confidence="0.824486333333333">
• Make a prediction for an item by perform-
ing a weighted average of deviations from
the neighbour’s mean.
</listItem>
<subsectionHeader confidence="0.999577">
3.1 Group rating
</subsectionHeader>
<bodyText confidence="0.999514294117647">
The goal of grouping ratings is to group the items
into several cliques and provides content-based
information for collaborative similarity calculation.
Each item has it’s own attribute features, such as
movie item, which may have actor, actress, direc-
tor, genre, and synopsis as its attribute features.
Thus, we can group the items based on them.
The algorithm that is applied for grouping rat-
ings is derived from K-means Clustering Algo-
rithm (Han and Kamber, 2000). The difference is
that we apply the fuzzy set theory to represent the
affiliation between object and cluster. As shown in
Figure 2, firstly, items are grouped into a given
number of clusters. After completion of grouping,
the probability of one object j (here one object
means one item) to be assigned to a certain cluster
is calculated as follows.
</bodyText>
<equation confidence="0.995519">
Pro(j,k)=1- CS(j,k) (1)
MaxCS(i,k)
</equation>
<bodyText confidence="0.999404272727273">
where Pro(j,k) means the probability of object j to
be assigned to cluster k ; The CS(j,k) means the
function to calculate the counter-similarity be-
tween object j and cluster k ; Max CS(i,k) means
the maximum counter-similarity between an object
and cluster k .
Input : the number of clusters k and item attributes
Output: a set of k clusters that minimizes the squared-
error criterion, and the probability of each item to be
assigned to each cluster center, which are represented as
a fuzzy set.
</bodyText>
<listItem confidence="0.990791">
(1) Arbitrarily choose k objects as the initial cluster
centers
(2) Repeat (a) and (b) until no change
(a) (Re) assign each object to the cluster to which the
object is the most similar, based on the mean value of
the objects in the cluster
(b) Update the cluster means, i.e., calculate the mean
value of the objects of each cluster;
(3) Compute the probability between objects and each
cluster center.
</listItem>
<figureCaption confidence="0.998131">
Figure 2. Algorithm for grouping ratings
</figureCaption>
<bodyText confidence="0.969093">
The counter-similarity CS(j,k) can be calcu-
lated by Euclidean distance or Cosine method.
</bodyText>
<subsectionHeader confidence="0.999596">
3.2 Similarity computation
</subsectionHeader>
<bodyText confidence="0.999968428571429">
As we can see, after grouping the items, we get a
new rating matrix. We can use the item-based col-
laborative algorithm to calculate the similarity and
make the predictions for users.
There are many ways to compute the similarity.
In our approach, we use two of them, and make a
linear combination of their results.
</bodyText>
<subsubsectionHeader confidence="0.989054">
3.2.1 Pearson correlation-based similarity
</subsubsectionHeader>
<bodyText confidence="0.999096833333334">
The most common measure for calculating the
similarity is the Pearson correlation algorithm.
Pearson correlation measures the degree to which a
linear relationship exists between two variables.
The Pearson correlation coefficient is derived from
a linear regression model, which relies on a set of
assumptions regarding the data, namely that the
relationship must be linear, and the errors must be
independent and have a probability distribution
with mean 0 and constant variance for every set-
ting of the independent variable (McClave and
Dietrich, 1998).
</bodyText>
<equation confidence="0.992468533333333">
m
∑ ( R R R R
− )( − )
u = 1 u k
, k u l
, l
=
2 2
∑ m m
( R R
− ) ∑ (R R
− )
u = 1 u k
, k i = 1 u l
, l
</equation>
<bodyText confidence="0.998257166666667">
where sim(k,l) means the similarity between item
k and l ; m means the total number of users, who
rated on both item k and l ; Rk , Rl are the average
ratings of item k and l , respectively;
Ru,k , Ru,l mean the rating of user u on item k and l
respectively.
</bodyText>
<subsubsectionHeader confidence="0.965944">
3.2.2 Adjust cosine similarity
</subsubsectionHeader>
<bodyText confidence="0.999986923076923">
Cosine similarity once has been used to calculate
the similarity of users but it has one shortcoming.
The difference in rating scale between different
users will result in a quite different similarity. For
instance, if Bob only rates score 4 on the best
movie, he never rates 5 on any movie; and he rates
1 on the bad movie, instead of the standard level
score 2. But Oliver always rates according to the
standard level. He rates score 5 on the best movie,
and 2 on the bad movie. If we use traditional co-
sine similarity, both of them are quite different.
The adjusted cosine similarity (Sarwar et al., 2001)
was provided to offset this drawback.
</bodyText>
<equation confidence="0.996525133333334">
cov(k,l)
sim(k,l) =
σ σ
k l
(2)
m
sim
2 2
∑ m m
(R R
− ) ∑ ( R R
− )
u = 1 u k
, u u = 1 u l
, u
</equation>
<bodyText confidence="0.9994718">
where sim(k,l) means the similarity between item
k andl ; m means the total number of users, who
rates on both item k and l ; Ru are the average rat-
ings of user u ; Ru,k , Ru,l mean the rating of user u on
item k andl respectively.
</bodyText>
<subsubsectionHeader confidence="0.989868">
3.2.3 Linear combination of similarity
</subsubsectionHeader>
<bodyText confidence="0.999922888888889">
Due to difference in value range between item-
rating matrix and group-rating matrix, we use dif-
ferent methods to calculate the similarity. As for
item-ratings matrix, the rating value is integer; As
for group-rating matrix, it is the real value ranging
from 0 to 1. The natural way is to enlarge the con-
tinuous data range from [0 1] to [1 5] or reduce the
discrete data range from [1 5] to [0 1] and then ap-
ply Pearson correlation-based algorithm or ad-
justed cosine algorithm to calculate similarity. We
call this enlarged ICHM. We also propose another
method: firstly, use Pearson correlation-based al-
gorithm to calculate the similarity from item-rating
matrix, and then calculate the similarity from
group-rating matrix by adjusted cosine algorithm,
at last, the total user similarity is linear combina-
tion of the above two, we call this combination
ICHM.
</bodyText>
<equation confidence="0.978892">
sim k l = sim k l × c + sim k l group × c
( , ) ( , )item (1- ) ( , ) (4)
</equation>
<bodyText confidence="0.952903857142857">
where sim(k,l) means the similarity between item
k and l ; c means the combination coefficient;
sim(k,l)item means that the similarity between item
k and l , which is calculated from item-rating ma-
trix; sim(k,l)group means that the similarity between
item k and l , which is calculated from group-
rating matrix.
</bodyText>
<subsectionHeader confidence="0.996908">
3.3 Collaborative prediction
</subsectionHeader>
<bodyText confidence="0.994711692307692">
Prediction for an item is then computed by per-
forming a weighted average of deviations from the
neighbour’s mean. Here we use top N rule to se-
lect the nearest N neighbours based on the simi-
larities of items. The general formula for a
prediction on item k of user u (Resnick et al., 1994)
is:
where Pu,k represents the predication for the user
u on item k ; n means the total neighbours of item
k ; Ru,i means the user u rating on item i ; Rk is the
average ratings on item k ; sim(k,i) means the simi-
larity between item k and its’ neighbour i ; Ri
means the average ratings on item i .
</bodyText>
<subsectionHeader confidence="0.962063">
3.4 Cold start problem
</subsectionHeader>
<bodyText confidence="0.966560882352941">
In traditional collaborative filtering approach, it is
hard for pure collaborative filtering to recommend
a new item to user since no user made any rating
on this new item. However, in our approach, based
on the information from group-rating matrix, we
can make predictions for the new item. In our ex-
periment, it shows a good recommendation per-
formance for the new items. In Equation 5, Rk is
the average rating of all ratings on item k . As for
the new item, no user makes any rating on it, Rk
should be the zero. Since Rk is the standard base-
line of user ratings and it is zero, it is unreasonable
for us to apply Equation 5 to new item. Therefore,
for a new item, we use the Rneighbors , the average rat-
ing of all ratings on the new item’s nearest
neighbour instead of Rk , which is inferred by the
group-rating matrix.
</bodyText>
<listItem confidence="0.9198056">
3.5 A scenario of our approach
• Users:
Number of users: three
User name: Tom, Jack, and Oliver
• Items:
</listItem>
<table confidence="0.963619333333333">
Item category: movie
Number of items: five
Title of items: Gone with the Wind, Pearl
Harbour, Swordfish, Hero, The Sound of Music
• Ratings: 1~5 integer score
Too bad:1 Bad:2 Common:3 Good:4 too good:5
</table>
<tableCaption confidence="0.995698">
Table 1: Item-ratin
</tableCaption>
<table confidence="0.9976605">
Tom Jack Olive
Gone with the Wind 5 3
Swordfish 5 2 4
Pearl Harbour 2 5
Hero 4 2
The Sound of Music
</table>
<tableCaption confidence="0.997916">
Table 2. Group-ratin
</tableCaption>
<table confidence="0.995733333333333">
(k l)= u=1(Ru k−Ru)(R,l−Ru) (3)
∑
Cluster1 Cluster2
Gone with the Wind 98% 0.13%
Swordfish 100% 0.02%
Pearl Harbour 1.0% 95%
</table>
<equation confidence="0.9751192">
(R R sim k i
− ×
) ( , )
u i
, i
sim(k,i)
∑
+
n
i
=
1
n
∑
i
=
1
Pu,k = Rk
(5)
Hero 95% 1.2%
</equation>
<subsectionHeader confidence="0.636415">
The Sound of Music 0.12% 98%
</subsectionHeader>
<bodyText confidence="0.961424">
The following is a procedure of our approach.
</bodyText>
<listItem confidence="0.982503">
• Based on the item contents, such as movie
genre, director, actor, actress, even synopsis,
we apply clustering algorithm to group the
items. Here, we use fuzzy set to represent
the clustering result. Assume the result is as
follows: Cluster 1: {Gone with the Wind
(98%), Swordfish (100%), Pearl Harbour
(1.0%), Hero (95%), The Sound of Music
(0.12%)}, Cluster 2: {Gone with the Wind
(0.13%), Swordfish (0.02%), Pearl Harbour
(95%), Hero (1.2%), The Sound of Music
(98%)}, the number in the parenthesis fol-
lowing the movie name means the probabil-
ity of the movie belonging to the cluster.
• We use group-rating engine to make a
group-rating matrix. As Table 2 shows.
Then combine the group-rating matrix and
item-rating matrix to form a new rating ma-
trix.
• Now, we can calculate the similarity be-
tween items based on this new unified rating
data matrix. The similarity between items
</listItem>
<bodyText confidence="0.954995722222222">
consists of two parts. The first part calcu-
lates the similarity based on user ratings, us-
ing the Pearson correlation-based algorithm.
The second part calculates the similarity
based on the clustering result by using ad-
justed cosine algorithm. The total similarity
between items is the linear combination of
them. For example, when we calculate the
similarity between Gone with the Wind and
Swordfish, firstly, sim(G,S)item and sim(G,S)group
are calculated based on Equation 2 and 3
separately.
Secondly, sim(G,S) is calculated based on
Formula 4, here the combination coefficient
is 0.4.
sim(G,S)=1 x (1-0.4)+0.9999x 0.4=0.9999
• Then, predictions for items are calculated by
performing a weighted average of deviations
from the neighbour’s mean.
In the example, we can observe, the item - The
Sound of Music, which no one make any rating on,
can be treated as a new item. In traditional item-
based collaborative method, which makes predic-
tion only based on item-based matrix (Table 1), it
is impossible to make predictions on this item.
However, in our approach, we can make prediction
for users, based on group rating (Table 2).
From the description of our approach, we can
observe that this approach can fully realize the
strengths of content-based filtering, mitigating the
effects of the new user problem. In addition, when
calculating the similarity, our approach considers
the information not only from personal tastes but
also from the contents, which provides a latent
ability for better prediction and makes serendipi-
tous recommendation.
</bodyText>
<figure confidence="0.885299692307692">
3.6 UCHM
UCHM
Movie 1 Movie 2 Movie 3 Cluster 1 Cluster 2
User 1 ... ... ... ... ...
User 2 ... ... ... ... ...
User 3 ... ... ... ... ...
Item-rating Matrix Group-rating Matrix
ICHM
ICHM User 1 User 2 User 3 Cluster 1 Cluster 2
Movie 1 ... ... ... ... ...
Movie 2 ... ... ... ... ...
Movie 3 ... ... ... ... ...
User-rating Matrix Group-rating Matrix
</figure>
<figureCaption confidence="0.998949">
Figure 3. UCHM &amp; ICHM
</figureCaption>
<bodyText confidence="0.999220333333333">
Clustering technique not only can be applied to
item-based collaborative recommenders but also
can be applied to user-based collaborative recom-
menders. Shortly we call the late one UCHM
(User-based Clustering Hybrid Method)
In UCHM, clustering is based on the attributes
of user profiles and clustering result is treated as
items. However, in ICHM, clustering is based on
the attributes of items and clustering result is
treated as users, as Figure 3 shows.
In Combination UCHM, we apply Equation 2 to
calculate the similarity in user-rating matrix, and
</bodyText>
<equation confidence="0.987830125">
sim(G,S)item= (5-4)x (5-3.5)+(3-4)x (2-3.5) = 1
(5-4)2+(3-4)2 x (5-3.5)2+(3.5-2)2
sim(G,S) =
group
(0.98-0.59) (1-0.59)+(0.013-0.39) (0.002-0.39)
x x
(0.98-0.59) +(0.013-0.39) (1-0.59) +(0.002-0.39)
2 2 2 2
</equation>
<page confidence="0.833112">
0.9999
</page>
<bodyText confidence="0.999982642857143">
Equation 3 to calculate the similarity in group-
rating matrix. Then make a linear combination of
them. When we apply Equation 2 and 3 to UCHM,
k and l mean the user and u means the item, in-
stead the original meaning.
As for UCHM, clustering is based on the user
profiles. User profiles indicate the information
needs or preferences on items that users are inter-
ested in. A user profile can consist of several pro-
file vectors and each profile vector represents an
aspect of his preferences, such as movie genre,
director, actor, actress and synopsis. The profile
vectors are automatically constructed from rating
data by the following simple equation.
</bodyText>
<equation confidence="0.996715">
A = m n
/ ( 8)
</equation>
<bodyText confidence="0.999946454545454">
where, n is the number of items whose ranking
value is lager than a given threshold, m is the num-
ber of items containing attribute A among n items
and its ranking is larger than threshold. In our ex-
periment, we set the value of the threshold as 3.
For example, in Section 3.5, Tom makes ratings on
four movies, and three of them lager than the
threshold 3. From the genre information, we know
Gone with the Wind belongs to love genre, sword-
fish and Hero belong to action genre. So Tom’s
profile is as follows. Tom {love (1/3), action (2/3)}.
</bodyText>
<sectionHeader confidence="0.990981" genericHeader="method">
4 Experimental evaluations
</sectionHeader>
<subsectionHeader confidence="0.997542">
4.1 Data set
</subsectionHeader>
<bodyText confidence="0.999992833333333">
Currently, we perform experiment on a subset of
movie rating data collected from the MovieLens
web-based recommender. The data set contained
100,000 ratings from 943 users and 1,682 movies,
with each user rating at least 20 items. We divide
data set into a training set and a test data set.
</bodyText>
<subsectionHeader confidence="0.987046">
4.2 Evaluation metrics
</subsectionHeader>
<bodyText confidence="0.999851428571429">
MAE (Mean Absolute Error) has widely been used
in evaluating the accuracy of a recommender sys-
tem by comparing the numerical recommendation
scores against the actual user ratings in the test
data. The MAE is calculated by summing these
absolute errors of the corresponding rating-
prediction pairs and then computing the average.
</bodyText>
<equation confidence="0.583920666666667">
=
MAE Ld
n
</equation>
<bodyText confidence="0.9999128">
where Pu,i means the user u prediction on item i ;
Ru,i means the user u rating on item i in the test
data; n is the number of rating-prediction pairs be-
tween the test data and the prediction result. The
lower the MAE, the more accurate.
</bodyText>
<subsectionHeader confidence="0.944933">
4.3 Behaviours of our method
</subsectionHeader>
<figureCaption confidence="0.953183">
Figure 4. Sensitivity of the cluster size
</figureCaption>
<bodyText confidence="0.999440166666667">
We implement group-rating method described in
section 3.1 and test them on MovieLens data with
the different number of clusters. Figure 4 shows
the experimental results. It can be observed that the
number of clusters does affect the quality of pre-
diction, no matter in UCHM or ICHM.
</bodyText>
<figureCaption confidence="0.982031">
Figure 5. Coefficient
</figureCaption>
<bodyText confidence="0.999918166666667">
In order to find the optimal combination coeffi-
cient c in the Equation 4, we conducted a series of
experiments by changing combination coefficient
from 0 to 1 with a constant step 0.1. Figure 5
shows that when the coefficient arrives at 0.4, an
optimal recommendation performance is achieved.
</bodyText>
<figureCaption confidence="0.848803">
Figure 6. Grouping items
</figureCaption>
<bodyText confidence="0.9983485">
As described in Section 3.2, our grouping rat-
ings method needs to calculate similarity between
</bodyText>
<figure confidence="0.928471027777778">
MAE
0.775
0.765
0.755
0.745
0.735
0 5 10 20 30 40 50 60 70
No. of Clusters
ICHM UCHM
MAE
0.78
0.77
0.76
0.75
0.74
0.73
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Coefficient
ICHM UCHM
MAE
0.755
0.745
0.735
0.76
0.75
0.74
0.73
10 20 30 40 50 60
NO.of Neigbors
Cosine Angle Euclidean Distance
(7)
n
= −
1 ,
P u i R u i
u ,
</figure>
<bodyText confidence="0.997942">
objects and clusters. So, we try two methods – one
is Euclidean distance and the other cosine angle. It
can be observed in Figure 6 that the approach of
cosine angle method has a trend to show better per-
formance than the Euclidean Distance method, but
the difference is negligible.
</bodyText>
<figureCaption confidence="0.996675">
Figure 7. Comparison
</figureCaption>
<bodyText confidence="0.999851857142857">
From the Figure 7, it can be observed that the
performance of combination ICHM is the best, and
the second is the enlarged ICHM, which is fol-
lowed by the item-based collaborative method, the
last is UCHM (User-based Clustering Hybrid
Method) which applies the clustering technique
described in Section 3 to user-based collaborative
filtering, where user profiles are clustered instead
of item contents.
We also can observe that the size of neighbour-
hood does affect the quality of prediction (Her-
locker et al., 1999). The performance improves as
we increase the neighbourhood size from 10 to 30,
then tends to be flat.
</bodyText>
<figureCaption confidence="0.955502">
Figure 8. Cold start problem
</figureCaption>
<tableCaption confidence="0.380639">
Table 3. MAE of new item
</tableCaption>
<table confidence="0.5884995">
10 20 30 40 50 100
MAE 0.743 0.755 0.812 0.732 0.762 0.757
</table>
<bodyText confidence="0.999842846153846">
As for cold start problem, we choose the items
from the training data set and delete all the ratings
of those items, thus we can treat them as new items.
First, we randomly selected item No.946. In the
test data, user No.946 has 11 ratings, which is de-
scribed by bar real value in Figure 8. We can ob-
serve that the prediction for a new item can
partially reflect the user preference. To generalize
the observation, we randomly select the number of
items from 10 to 50 with the step of 10 and 100
from the test data, and delete all the ratings of
those items and treat them as new items. Table 3
shows that ICHM can solve the cold start problem.
</bodyText>
<figureCaption confidence="0.995617">
Figure 9. Item attribute
</figureCaption>
<bodyText confidence="0.999987">
When we apply clustering method to movie
items, we use the item attribute – movie genre.
However, our approach can consider more dimen-
sion of item attribute, such as actor, actress, and
director, even the synopsis. In order to observe the
effect of the high dimension item attributes, we
collect the 100 movie synopsis from Internet
Movie Database (http://www.imdb.com) to provide
attribute information for clustering movies. In our
experiment, it shows that the correct attributes of
movies can further improve the performance of
recommender system, as Figure 9 shows.
</bodyText>
<subsectionHeader confidence="0.985461">
4.4 Our method versus the classic one
</subsectionHeader>
<bodyText confidence="0.999960869565217">
Although some hybrid recommender systems have
already exited, it is hard to make an evaluation
among them. Some systems (Delgado et al., 1998)
use Boolean value (relevant or irrelevant) to repre-
sent user preferences, while others use numeric
value. The same evaluation metrics cannot make a
fair comparison. Further more, the quality of some
systems depends on the time, in which system pa-
rameters are changed with user feedback (Claypool
et al., 1999), and Claypool does not clearly de-
scribe how to change the weight with time passed.
However, we can make a simple concept compari-
son. In Fab system, the similarity for prediction is
only based on the user profiles. As for UCHM,
which groups the content information of user pro-
files and uses user-based collaborative algorithm
instead of ICHM, the impact of combination coef-
ficient can be observed in Figure 5. In UCHM,
when the value of coefficient equals to 1, it de-
scribes condition that Fab applied, which means
the similarity between users is only calculated
from the group-rating matrix. In that condition, the
MAE shows the worst quality of recommendation.
</bodyText>
<figure confidence="0.99422775862069">
MAE
0.775
0.765
0.755
0.745
0.735
10 20 30 40 50 60 70 80 90 100
No. of neighbors
Combination ICHM
Item-based Collaborative
Enlarged ICHM
Combination UCHM
Ratings
4
2
1
5
3
1 2 3 4 5 6 7 8 9 10 11
Movie items
Real Value Predict Value
MAE
0.75
0.74
0.73
0.72
Synopsis Genre
5 Conclusions ACM-SIGIR Workshop on Mathematical/Formal
Methods in IR.
</figure>
<bodyText confidence="0.999864285714286">
We apply clustering technique to the item content
information to complement the user rating infor-
mation, which improves the correctness of collabo-
rative similarity, and solves the cold start problem.
Our work indicates that the correct application of
the item information can improve the
recommendation performance.
</bodyText>
<sectionHeader confidence="0.999433" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999905523809524">
Anick, P. G., Brennan, J. D., Flynn, R. A., Hanssen, D.
R., Alvey, B. and Robbins, J.M.. 1990. A Direct Ma-
nipulation Interface for Boolean Information Re-
trieval via Natural Language Query, In Proc. ACM-
SIGIR Conf., pp.135-150.
Balabanovic, M. and Shoham, Y.. 1997. Fab: Content-
Based, Collaborative Recommendation, Communica-
tions of the ACM, 40(3), pp.66-72.
Claypool, M., Gokhale, A., Miranda, T., Murnikov, P.,
Netes, D. and Sartin, M.. 1999. Combining content-
based and collaborative filters in an online newspa-
per , In Proc. ACM-SIGIR Workshop on Recom-
mender Systems: Algorithms and Evaluation.
Delgado, J., Ishii, N. and Ura, T.. 1998. Content-based
Collaborative Information Filtering: Actively Learn-
ing to Classify and Recommend Documents, In Proc.
Second Int. Workshop, CIA&apos;98, pp.206-215.
Douglas B. Terry. 1993. A tour through tapestry, In
Proc. ACM Conf. on Organizational Computing Sys-
tems (COOCS). pp.21—30.
Gupta, D., Digiovanni, M., Narita, H. and Goldberg, K..
1999. Jester 2.0: A New Linear-Time Collaborative
Filtering Algorithm Applied to Jokes, In Proc. ACM-
SIGIR Workshop on Recommender Systems: Algo-
rithms and Evaluation.
Han, J., and Kamber, M.. 2000. Data mining: Concepts
and Techniques. New York: Morgan-Kaufman.
Harman D.. 1994. Overview of TREC-3, In Proc.TREC-
3, pp.1-19.
Hauver, D. B.. 2001. Flycasting: Using Collaborative
Filtering to Generate a Play list for Online Radio, In
Int. Conf. on Web Delivery of Music.
Herlocker, J., Konstan, J., Borchers A., and Riedl, J..
1999. An algorithmic framework for performing col-
laborative Filtering, In Proc. ACM-SIGIR Conf.,
1999, pp. 230-237.
Kim, M. and Raghavan, V.V.. 2000. Adaptive concept-
based retrieval using a neural network, In Proc. Of
McClave, J. T. and Dietrich, F. H.. 1998. Statistics. San
Francisco: Ellen Publishing Company.
Lee, J.H., Kim, M.H. and Lee, Y.H.. 1993. Ranking
documents in thesaurus-based Boolean retrieval sys-
tems, Information Processing and Management, 30(1),
pp.79-91.
Oard, D.W. and Marchionini, G.. 1996. A conceptual
framework for text filtering, Technical Report EE-
TR-96-25, CAR-TR-830, CS-TR3643.
Ogawa, Y., Morita, T. and Kobayashi, K.. 1991. A fuzzy
document retrieval system using the keyword connec-
tion matrix and a learning method, Fuzzy sets and
Systems, 1991, pp.39, pp.163-179.
O&apos;Conner, M. and Herlocker, J.. 1999. Clustering items
for collaborative filtering, In Proc. ACM-SIGIR
Workshop on Recommender Systems.
Resnick, P., Iacovou, N., Suchak, M., Bergstorm, P. and
Riedl, J.. 1994. GroupLens: An open architecture for
collaborative filtering of Netnews, In Proc. ACM
Conf. on Computer-Supported Cooperative Work.
pp.175-186.
Ricardo Baeza-Yates, Berthier Riberio-Neto. 1999.
Modern Information Retrieval. New York:Addison-
Wesley Publishers.
Robertson S. E. and Sparck Jones K.. 1976. Relevance
weighting of search terms, J. of the American Society
for Information Science, 1976, pp.27, pp.129-146.
Salton, G. and Buckley, C.. 1988. Term-weight ap-
proaches in automatic retrieval, Information Proc-
essing and Management, 24(5), 1988, pp.513-523.
Sarwar, B. M., Karypis, G., Konstan, J. A. and Riedl, J..
2001. Item-based Collaborative Filtering Recom-
mendation Algorithms, In Proc. Tenth Int. WWW
Conf. 2001, pp. 285-295.
Upendra, S. and Patti, M.. 1995. Social Information
Filtering: Algorithms for Automating &amp;quot;Word of
Mouth&amp;quot;, In Proc. ACM CHI&apos;95 Conf. on Human Fac-
tors in Computing Systems. pp.210—217.
Verhoeff, J., Goffman, W. and Belzer, J.. 1961. Ineffi-
ciency of the use of the boolean functions for infor-
mation retrieval systems, Communications of the
ACM, 4, pp.557--558, pp.594.
Wasfi, A. M. A.. 1999. Collecting User Access Patterns
for Building user Profiles and Collaborative Filter-
ing, In Int. Conf. on Intelligent User Interfaces.
pp.57- 64.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.479353">
<title confidence="0.99805">An Approach for Combining Content-based and Collaborative Filters</title>
<author confidence="0.765616">Qing</author>
<affiliation confidence="0.93015">Dept. of Computer Kumoh National Institute of</affiliation>
<address confidence="0.95067">Kumi, kyungpook, 730-701,South Korea</address>
<email confidence="0.980006">liqing@se.Kumoh.ac.kr</email>
<author confidence="0.943776">Byeong Man</author>
<affiliation confidence="0.933315">Dept. of Computer Kumoh National Institute of</affiliation>
<address confidence="0.95486">Kumi, kyungpook, 730-701,South Korea</address>
<email confidence="0.984127">bmkim@se.Kumoh.ac.kr</email>
<abstract confidence="0.9959570625">In this work, we apply a clustering technique to integrate the contents of items into the item-based collaborative filtering framework. The group rating information that is obtained from the clustering result provides a way to introduce content information into collaborative recommendation and solves the cold start problem. Extensive experiments have been conducted on MovieLens data to analyze the characteristics of our technique. The results show that our approach contributes to the improvement of prediction quality of the item-based collaborative filtering, especially for the cold start problem.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P G Anick</author>
<author>J D Brennan</author>
<author>R A Flynn</author>
<author>D R Hanssen</author>
<author>B Alvey</author>
<author>J M Robbins</author>
</authors>
<title>A Direct Manipulation Interface for Boolean Information Retrieval via Natural Language Query,</title>
<date>1990</date>
<booktitle>In Proc. ACMSIGIR Conf.,</booktitle>
<pages>135--150</pages>
<contexts>
<context position="1448" citStr="Anick et al., 1990" startWordPosition="200" endWordPosition="203">o the improvement of prediction quality of the item-based collaborative filtering, especially for the cold start problem. 1 Introduction There are two dominant research paradigms of information filtering: content-based and collaborative filtering. Content-based filtering selects the right information for users by comparing representations of searching information to representations of contents of user profiles which express interests of users. Content-based information filtering has proven to be effective in locating textual items relevant to a topic using techniques, such as Boolean queries (Anick et al., 1990; Lee et al., 1993; Verhoeff et al., 1961), vector-space queries (Salton and Buckley, 1998), probabilistic model (Robertson and Sparck, 1976), neural network (Kim and Raghavan, 2000) and fuzzy set model (Ogawa et This work was supported by Korea Research Foundation Grant (KRF-2002-041-D00459). al., 1991). However, content-based filtering has some limitations: • It is hard for content-based filtering to provide serendipitous recommendations, because all the information is selected and recommended based on the content. • It is hard for novices to use content-based systems effectively. Collaborat</context>
</contexts>
<marker>Anick, Brennan, Flynn, Hanssen, Alvey, Robbins, 1990</marker>
<rawString>Anick, P. G., Brennan, J. D., Flynn, R. A., Hanssen, D. R., Alvey, B. and Robbins, J.M.. 1990. A Direct Manipulation Interface for Boolean Information Retrieval via Natural Language Query, In Proc. ACMSIGIR Conf., pp.135-150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Balabanovic</author>
<author>Y Shoham</author>
</authors>
<title>Fab: ContentBased, Collaborative Recommendation,</title>
<date>1997</date>
<journal>Communications of the ACM,</journal>
<volume>40</volume>
<issue>3</issue>
<pages>66--72</pages>
<marker>Balabanovic, Shoham, 1997</marker>
<rawString>Balabanovic, M. and Shoham, Y.. 1997. Fab: ContentBased, Collaborative Recommendation, Communications of the ACM, 40(3), pp.66-72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Claypool</author>
<author>A Gokhale</author>
<author>T Miranda</author>
<author>P Murnikov</author>
<author>D Netes</author>
<author>M Sartin</author>
</authors>
<title>Combining contentbased and collaborative filters in an online newspaper ,</title>
<date>1999</date>
<booktitle>In Proc. ACM-SIGIR Workshop on Recommender Systems: Algorithms and Evaluation.</booktitle>
<contexts>
<context position="24987" citStr="Claypool et al., 1999" startWordPosition="4259" endWordPosition="4262">iment, it shows that the correct attributes of movies can further improve the performance of recommender system, as Figure 9 shows. 4.4 Our method versus the classic one Although some hybrid recommender systems have already exited, it is hard to make an evaluation among them. Some systems (Delgado et al., 1998) use Boolean value (relevant or irrelevant) to represent user preferences, while others use numeric value. The same evaluation metrics cannot make a fair comparison. Further more, the quality of some systems depends on the time, in which system parameters are changed with user feedback (Claypool et al., 1999), and Claypool does not clearly describe how to change the weight with time passed. However, we can make a simple concept comparison. In Fab system, the similarity for prediction is only based on the user profiles. As for UCHM, which groups the content information of user profiles and uses user-based collaborative algorithm instead of ICHM, the impact of combination coefficient can be observed in Figure 5. In UCHM, when the value of coefficient equals to 1, it describes condition that Fab applied, which means the similarity between users is only calculated from the group-rating matrix. In that</context>
</contexts>
<marker>Claypool, Gokhale, Miranda, Murnikov, Netes, Sartin, 1999</marker>
<rawString>Claypool, M., Gokhale, A., Miranda, T., Murnikov, P., Netes, D. and Sartin, M.. 1999. Combining contentbased and collaborative filters in an online newspaper , In Proc. ACM-SIGIR Workshop on Recommender Systems: Algorithms and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Delgado</author>
<author>N Ishii</author>
<author>T Ura</author>
</authors>
<title>Content-based Collaborative Information Filtering: Actively Learning to Classify and Recommend Documents,</title>
<date>1998</date>
<booktitle>In Proc. Second Int. Workshop, CIA&apos;98,</booktitle>
<pages>206--215</pages>
<contexts>
<context position="5568" citStr="Delgado et al., 1998" startWordPosition="836" endWordPosition="839">wspaper domain, combining the two predictions using an adaptive weighted average: as the number of users accessing an item increases, the weight of the collaborative component tends to increase. But how to decide the weights of collaborative and contentbased components is unclearly given by the author. The other group is the sequential combination of content-based filtering and collaborative filtering. In this system, firstly, content-based filtering algorithm is applied to find users, who share similar interests. Secondly, collaborative algorithm is applied to make predictions, such as RAAP (Delgado et al., 1998) and Fab filtering systems (Balabanovic and Shoham, 1990). RAAP is a content-based collaborative information filtering for helping the user to classify domain specific information found in the WWW, and also recommends these URLs to other users with similar interests. To decide the similar interests of users is using scalable Pearson correlation algorithm based on web page category. Fab system, which uses contentbased techniques instead of user ratings to create profiles of users. So the quality of predictions is fully depended on the content-based techniques, inaccurate profiles result in inac</context>
<context position="24677" citStr="Delgado et al., 1998" startWordPosition="4209" endWordPosition="4212">dimension of item attribute, such as actor, actress, and director, even the synopsis. In order to observe the effect of the high dimension item attributes, we collect the 100 movie synopsis from Internet Movie Database (http://www.imdb.com) to provide attribute information for clustering movies. In our experiment, it shows that the correct attributes of movies can further improve the performance of recommender system, as Figure 9 shows. 4.4 Our method versus the classic one Although some hybrid recommender systems have already exited, it is hard to make an evaluation among them. Some systems (Delgado et al., 1998) use Boolean value (relevant or irrelevant) to represent user preferences, while others use numeric value. The same evaluation metrics cannot make a fair comparison. Further more, the quality of some systems depends on the time, in which system parameters are changed with user feedback (Claypool et al., 1999), and Claypool does not clearly describe how to change the weight with time passed. However, we can make a simple concept comparison. In Fab system, the similarity for prediction is only based on the user profiles. As for UCHM, which groups the content information of user profiles and uses</context>
</contexts>
<marker>Delgado, Ishii, Ura, 1998</marker>
<rawString>Delgado, J., Ishii, N. and Ura, T.. 1998. Content-based Collaborative Information Filtering: Actively Learning to Classify and Recommend Documents, In Proc. Second Int. Workshop, CIA&apos;98, pp.206-215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas B Terry</author>
</authors>
<title>A tour through tapestry,</title>
<date>1993</date>
<booktitle>In Proc. ACM Conf. on Organizational Computing Systems (COOCS).</booktitle>
<pages>21--30</pages>
<marker>Terry, 1993</marker>
<rawString>Douglas B. Terry. 1993. A tour through tapestry, In Proc. ACM Conf. on Organizational Computing Systems (COOCS). pp.21—30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gupta</author>
<author>M Digiovanni</author>
<author>H Narita</author>
<author>K Goldberg</author>
</authors>
<title>Jester 2.0: A New Linear-Time Collaborative Filtering Algorithm Applied to Jokes,</title>
<date>1999</date>
<booktitle>In Proc. ACMSIGIR Workshop on Recommender Systems: Algorithms and Evaluation.</booktitle>
<contexts>
<context position="2820" citStr="Gupta et al., 1999" startWordPosition="408" endWordPosition="411">bors, who have historically had similar interests to target user. Items that neighbors like are then recommended to the target user. The Tapestry text filtering system, developed by Nichols and others at the Xerox Palo Alto Research Center (PARC), applied collaborative filtering (Douglas, 1993; Harman, 1994). The GroupLens project at the University of Minnesota is a popular collaborative system. Collaborative systems have been widely used in so many areas, such as Ringo system recommends music albums (Upendar and Patti, 1995), MovieLens system recommends movies, Jeter system recommends jokes (Gupta et al., 1999) and Flycasting recommends online radio (Hauver, 2001). Collaborative filtering system overcomes some limitations of content-based filtering. The system can suggest items (the things to be recommended, such as books, music etc.) to users and recommendations are based on the ratings of items, instead of the contents of the items, which can improve the quality of recommendations. Although collaborative filtering has been successfully used in both research and practice, there still remain some challenges for it as an efficient information filtering. • Cold start problem, where recommendations are</context>
</contexts>
<marker>Gupta, Digiovanni, Narita, Goldberg, 1999</marker>
<rawString>Gupta, D., Digiovanni, M., Narita, H. and Goldberg, K.. 1999. Jester 2.0: A New Linear-Time Collaborative Filtering Algorithm Applied to Jokes, In Proc. ACMSIGIR Workshop on Recommender Systems: Algorithms and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Han</author>
<author>M Kamber</author>
</authors>
<title>Data mining: Concepts and Techniques.</title>
<date>2000</date>
<publisher>Morgan-Kaufman.</publisher>
<location>New York:</location>
<contexts>
<context position="8195" citStr="Han and Kamber, 2000" startWordPosition="1244" endWordPosition="1247">r combination of the above two. • Make a prediction for an item by performing a weighted average of deviations from the neighbour’s mean. 3.1 Group rating The goal of grouping ratings is to group the items into several cliques and provides content-based information for collaborative similarity calculation. Each item has it’s own attribute features, such as movie item, which may have actor, actress, director, genre, and synopsis as its attribute features. Thus, we can group the items based on them. The algorithm that is applied for grouping ratings is derived from K-means Clustering Algorithm (Han and Kamber, 2000). The difference is that we apply the fuzzy set theory to represent the affiliation between object and cluster. As shown in Figure 2, firstly, items are grouped into a given number of clusters. After completion of grouping, the probability of one object j (here one object means one item) to be assigned to a certain cluster is calculated as follows. Pro(j,k)=1- CS(j,k) (1) MaxCS(i,k) where Pro(j,k) means the probability of object j to be assigned to cluster k ; The CS(j,k) means the function to calculate the counter-similarity between object j and cluster k ; Max CS(i,k) means the maximum count</context>
</contexts>
<marker>Han, Kamber, 2000</marker>
<rawString>Han, J., and Kamber, M.. 2000. Data mining: Concepts and Techniques. New York: Morgan-Kaufman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Harman</author>
</authors>
<title>Overview of TREC-3, In</title>
<date>1994</date>
<booktitle>Proc.TREC3,</booktitle>
<pages>1--19</pages>
<contexts>
<context position="2510" citStr="Harman, 1994" startWordPosition="362" endWordPosition="363">use all the information is selected and recommended based on the content. • It is hard for novices to use content-based systems effectively. Collaborative filtering is the technique of using peer opinions to predict the interests of others. A target user is matched against the database to discover neighbors, who have historically had similar interests to target user. Items that neighbors like are then recommended to the target user. The Tapestry text filtering system, developed by Nichols and others at the Xerox Palo Alto Research Center (PARC), applied collaborative filtering (Douglas, 1993; Harman, 1994). The GroupLens project at the University of Minnesota is a popular collaborative system. Collaborative systems have been widely used in so many areas, such as Ringo system recommends music albums (Upendar and Patti, 1995), MovieLens system recommends movies, Jeter system recommends jokes (Gupta et al., 1999) and Flycasting recommends online radio (Hauver, 2001). Collaborative filtering system overcomes some limitations of content-based filtering. The system can suggest items (the things to be recommended, such as books, music etc.) to users and recommendations are based on the ratings of item</context>
</contexts>
<marker>Harman, 1994</marker>
<rawString>Harman D.. 1994. Overview of TREC-3, In Proc.TREC3, pp.1-19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D B Hauver</author>
</authors>
<title>Flycasting: Using Collaborative Filtering to Generate a Play list for Online Radio,</title>
<date>2001</date>
<booktitle>In Int. Conf. on Web Delivery of Music.</booktitle>
<contexts>
<context position="2874" citStr="Hauver, 2001" startWordPosition="417" endWordPosition="418">user. Items that neighbors like are then recommended to the target user. The Tapestry text filtering system, developed by Nichols and others at the Xerox Palo Alto Research Center (PARC), applied collaborative filtering (Douglas, 1993; Harman, 1994). The GroupLens project at the University of Minnesota is a popular collaborative system. Collaborative systems have been widely used in so many areas, such as Ringo system recommends music albums (Upendar and Patti, 1995), MovieLens system recommends movies, Jeter system recommends jokes (Gupta et al., 1999) and Flycasting recommends online radio (Hauver, 2001). Collaborative filtering system overcomes some limitations of content-based filtering. The system can suggest items (the things to be recommended, such as books, music etc.) to users and recommendations are based on the ratings of items, instead of the contents of the items, which can improve the quality of recommendations. Although collaborative filtering has been successfully used in both research and practice, there still remain some challenges for it as an efficient information filtering. • Cold start problem, where recommendations are required for items that no user has yet rated. • Alth</context>
</contexts>
<marker>Hauver, 2001</marker>
<rawString>Hauver, D. B.. 2001. Flycasting: Using Collaborative Filtering to Generate a Play list for Online Radio, In Int. Conf. on Web Delivery of Music.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Herlocker</author>
<author>J Konstan</author>
<author>A Borchers</author>
<author>J Riedl</author>
</authors>
<title>An algorithmic framework for performing collaborative Filtering,</title>
<date>1999</date>
<booktitle>In Proc. ACM-SIGIR Conf.,</booktitle>
<pages>230--237</pages>
<contexts>
<context position="23041" citStr="Herlocker et al., 1999" startWordPosition="3919" endWordPosition="3923">ter performance than the Euclidean Distance method, but the difference is negligible. Figure 7. Comparison From the Figure 7, it can be observed that the performance of combination ICHM is the best, and the second is the enlarged ICHM, which is followed by the item-based collaborative method, the last is UCHM (User-based Clustering Hybrid Method) which applies the clustering technique described in Section 3 to user-based collaborative filtering, where user profiles are clustered instead of item contents. We also can observe that the size of neighbourhood does affect the quality of prediction (Herlocker et al., 1999). The performance improves as we increase the neighbourhood size from 10 to 30, then tends to be flat. Figure 8. Cold start problem Table 3. MAE of new item 10 20 30 40 50 100 MAE 0.743 0.755 0.812 0.732 0.762 0.757 As for cold start problem, we choose the items from the training data set and delete all the ratings of those items, thus we can treat them as new items. First, we randomly selected item No.946. In the test data, user No.946 has 11 ratings, which is described by bar real value in Figure 8. We can observe that the prediction for a new item can partially reflect the user preference. </context>
</contexts>
<marker>Herlocker, Konstan, Borchers, Riedl, 1999</marker>
<rawString>Herlocker, J., Konstan, J., Borchers A., and Riedl, J.. 1999. An algorithmic framework for performing collaborative Filtering, In Proc. ACM-SIGIR Conf., 1999, pp. 230-237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kim</author>
<author>V V Raghavan</author>
</authors>
<title>Adaptive conceptbased retrieval using a neural network, In</title>
<date>2000</date>
<booktitle>Proc. Of</booktitle>
<contexts>
<context position="1630" citStr="Kim and Raghavan, 2000" startWordPosition="227" endWordPosition="230">s of information filtering: content-based and collaborative filtering. Content-based filtering selects the right information for users by comparing representations of searching information to representations of contents of user profiles which express interests of users. Content-based information filtering has proven to be effective in locating textual items relevant to a topic using techniques, such as Boolean queries (Anick et al., 1990; Lee et al., 1993; Verhoeff et al., 1961), vector-space queries (Salton and Buckley, 1998), probabilistic model (Robertson and Sparck, 1976), neural network (Kim and Raghavan, 2000) and fuzzy set model (Ogawa et This work was supported by Korea Research Foundation Grant (KRF-2002-041-D00459). al., 1991). However, content-based filtering has some limitations: • It is hard for content-based filtering to provide serendipitous recommendations, because all the information is selected and recommended based on the content. • It is hard for novices to use content-based systems effectively. Collaborative filtering is the technique of using peer opinions to predict the interests of others. A target user is matched against the database to discover neighbors, who have historically h</context>
</contexts>
<marker>Kim, Raghavan, 2000</marker>
<rawString>Kim, M. and Raghavan, V.V.. 2000. Adaptive conceptbased retrieval using a neural network, In Proc. Of</rawString>
</citation>
<citation valid="true">
<authors>
<author>J T McClave</author>
<author>F H Dietrich</author>
</authors>
<date>1998</date>
<publisher>Ellen Publishing Company.</publisher>
<location>Statistics. San Francisco:</location>
<contexts>
<context position="10549" citStr="McClave and Dietrich, 1998" startWordPosition="1632" endWordPosition="1635">combination of their results. 3.2.1 Pearson correlation-based similarity The most common measure for calculating the similarity is the Pearson correlation algorithm. Pearson correlation measures the degree to which a linear relationship exists between two variables. The Pearson correlation coefficient is derived from a linear regression model, which relies on a set of assumptions regarding the data, namely that the relationship must be linear, and the errors must be independent and have a probability distribution with mean 0 and constant variance for every setting of the independent variable (McClave and Dietrich, 1998). m ∑ ( R R R R − )( − ) u = 1 u k , k u l , l = 2 2 ∑ m m ( R R − ) ∑ (R R − ) u = 1 u k , k i = 1 u l , l where sim(k,l) means the similarity between item k and l ; m means the total number of users, who rated on both item k and l ; Rk , Rl are the average ratings of item k and l , respectively; Ru,k , Ru,l mean the rating of user u on item k and l respectively. 3.2.2 Adjust cosine similarity Cosine similarity once has been used to calculate the similarity of users but it has one shortcoming. The difference in rating scale between different users will result in a quite different similarity. </context>
</contexts>
<marker>McClave, Dietrich, 1998</marker>
<rawString>McClave, J. T. and Dietrich, F. H.. 1998. Statistics. San Francisco: Ellen Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Lee</author>
<author>M H Kim</author>
<author>Y H Lee</author>
</authors>
<title>Ranking documents in thesaurus-based Boolean retrieval systems,</title>
<date>1993</date>
<booktitle>Information Processing and Management,</booktitle>
<volume>30</volume>
<issue>1</issue>
<pages>79--91</pages>
<contexts>
<context position="1466" citStr="Lee et al., 1993" startWordPosition="204" endWordPosition="207"> prediction quality of the item-based collaborative filtering, especially for the cold start problem. 1 Introduction There are two dominant research paradigms of information filtering: content-based and collaborative filtering. Content-based filtering selects the right information for users by comparing representations of searching information to representations of contents of user profiles which express interests of users. Content-based information filtering has proven to be effective in locating textual items relevant to a topic using techniques, such as Boolean queries (Anick et al., 1990; Lee et al., 1993; Verhoeff et al., 1961), vector-space queries (Salton and Buckley, 1998), probabilistic model (Robertson and Sparck, 1976), neural network (Kim and Raghavan, 2000) and fuzzy set model (Ogawa et This work was supported by Korea Research Foundation Grant (KRF-2002-041-D00459). al., 1991). However, content-based filtering has some limitations: • It is hard for content-based filtering to provide serendipitous recommendations, because all the information is selected and recommended based on the content. • It is hard for novices to use content-based systems effectively. Collaborative filtering is t</context>
</contexts>
<marker>Lee, Kim, Lee, 1993</marker>
<rawString>Lee, J.H., Kim, M.H. and Lee, Y.H.. 1993. Ranking documents in thesaurus-based Boolean retrieval systems, Information Processing and Management, 30(1), pp.79-91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D W Oard</author>
<author>G Marchionini</author>
</authors>
<title>A conceptual framework for text filtering,</title>
<date>1996</date>
<tech>Technical Report EETR-96-25, CAR-TR-830, CS-TR3643.</tech>
<marker>Oard, Marchionini, 1996</marker>
<rawString>Oard, D.W. and Marchionini, G.. 1996. A conceptual framework for text filtering, Technical Report EETR-96-25, CAR-TR-830, CS-TR3643.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Ogawa</author>
<author>T Morita</author>
<author>K Kobayashi</author>
</authors>
<title>A fuzzy document retrieval system using the keyword connection matrix and a learning method, Fuzzy sets and Systems,</title>
<date>1991</date>
<pages>39--163</pages>
<marker>Ogawa, Morita, Kobayashi, 1991</marker>
<rawString>Ogawa, Y., Morita, T. and Kobayashi, K.. 1991. A fuzzy document retrieval system using the keyword connection matrix and a learning method, Fuzzy sets and Systems, 1991, pp.39, pp.163-179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M O&apos;Conner</author>
<author>J Herlocker</author>
</authors>
<title>Clustering items for collaborative filtering,</title>
<date>1999</date>
<booktitle>In Proc. ACM-SIGIR Workshop on Recommender Systems.</booktitle>
<marker>O&apos;Conner, Herlocker, 1999</marker>
<rawString>O&apos;Conner, M. and Herlocker, J.. 1999. Clustering items for collaborative filtering, In Proc. ACM-SIGIR Workshop on Recommender Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnick</author>
<author>N Iacovou</author>
<author>M Suchak</author>
<author>P Bergstorm</author>
<author>J Riedl</author>
</authors>
<title>GroupLens: An open architecture for collaborative filtering of Netnews, In</title>
<date>1994</date>
<booktitle>Proc. ACM Conf. on Computer-Supported Cooperative Work.</booktitle>
<pages>175--186</pages>
<contexts>
<context position="13520" citStr="Resnick et al., 1994" startWordPosition="2235" endWordPosition="2238">sim(k,l) means the similarity between item k and l ; c means the combination coefficient; sim(k,l)item means that the similarity between item k and l , which is calculated from item-rating matrix; sim(k,l)group means that the similarity between item k and l , which is calculated from grouprating matrix. 3.3 Collaborative prediction Prediction for an item is then computed by performing a weighted average of deviations from the neighbour’s mean. Here we use top N rule to select the nearest N neighbours based on the similarities of items. The general formula for a prediction on item k of user u (Resnick et al., 1994) is: where Pu,k represents the predication for the user u on item k ; n means the total neighbours of item k ; Ru,i means the user u rating on item i ; Rk is the average ratings on item k ; sim(k,i) means the similarity between item k and its’ neighbour i ; Ri means the average ratings on item i . 3.4 Cold start problem In traditional collaborative filtering approach, it is hard for pure collaborative filtering to recommend a new item to user since no user made any rating on this new item. However, in our approach, based on the information from group-rating matrix, we can make predictions for </context>
</contexts>
<marker>Resnick, Iacovou, Suchak, Bergstorm, Riedl, 1994</marker>
<rawString>Resnick, P., Iacovou, N., Suchak, M., Bergstorm, P. and Riedl, J.. 1994. GroupLens: An open architecture for collaborative filtering of Netnews, In Proc. ACM Conf. on Computer-Supported Cooperative Work. pp.175-186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ricardo Baeza-Yates</author>
<author>Berthier Riberio-Neto</author>
</authors>
<title>Modern Information Retrieval.</title>
<date>1999</date>
<publisher>New York:AddisonWesley Publishers.</publisher>
<marker>Baeza-Yates, Riberio-Neto, 1999</marker>
<rawString>Ricardo Baeza-Yates, Berthier Riberio-Neto. 1999. Modern Information Retrieval. New York:AddisonWesley Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S E Robertson</author>
<author>Sparck Jones K</author>
</authors>
<title>Relevance weighting of search terms,</title>
<date>1976</date>
<journal>J. of the American Society for Information Science,</journal>
<pages>27--129</pages>
<marker>Robertson, K, 1976</marker>
<rawString>Robertson S. E. and Sparck Jones K.. 1976. Relevance weighting of search terms, J. of the American Society for Information Science, 1976, pp.27, pp.129-146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>C Buckley</author>
</authors>
<title>Term-weight approaches in automatic retrieval,</title>
<date>1988</date>
<booktitle>Information Processing and Management,</booktitle>
<volume>24</volume>
<issue>5</issue>
<pages>513--523</pages>
<marker>Salton, Buckley, 1988</marker>
<rawString>Salton, G. and Buckley, C.. 1988. Term-weight approaches in automatic retrieval, Information Processing and Management, 24(5), 1988, pp.513-523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B M Sarwar</author>
<author>G Karypis</author>
<author>J A Konstan</author>
<author>J Riedl</author>
</authors>
<title>Item-based Collaborative Filtering Recommendation Algorithms,</title>
<date>2001</date>
<booktitle>In Proc. Tenth Int. WWW Conf.</booktitle>
<pages>285--295</pages>
<contexts>
<context position="6403" citStr="Sarwar et al, 2001" startWordPosition="963" endWordPosition="966">s these URLs to other users with similar interests. To decide the similar interests of users is using scalable Pearson correlation algorithm based on web page category. Fab system, which uses contentbased techniques instead of user ratings to create profiles of users. So the quality of predictions is fully depended on the content-based techniques, inaccurate profiles result in inaccurate correlations with other users and thus make poor predictions. As for collaborative recommendation, there are two ways to calculate the similarity for clique recommendation – item-based and user-based. Sarwar (Sarwar et al, 2001) has proved that item-based collaborative filtering is better than user-based collaborative filtering at precision and computation complexity. Item group vector rater Group Clustering Item content Figure1. Overview of the our approach 3 Overview of our approach In this paper, we suggest a technique that introduces the contents of items into the item-based collaborative filtering to improve its prediction quality and solve the cold start problem. Shortly, we call the technique ICHM (Item-based Clustering Hybrid Method). In ICHM, we integrate the item information and user ratings to calculate th</context>
<context position="11555" citStr="Sarwar et al., 2001" startWordPosition="1854" endWordPosition="1857"> similarity Cosine similarity once has been used to calculate the similarity of users but it has one shortcoming. The difference in rating scale between different users will result in a quite different similarity. For instance, if Bob only rates score 4 on the best movie, he never rates 5 on any movie; and he rates 1 on the bad movie, instead of the standard level score 2. But Oliver always rates according to the standard level. He rates score 5 on the best movie, and 2 on the bad movie. If we use traditional cosine similarity, both of them are quite different. The adjusted cosine similarity (Sarwar et al., 2001) was provided to offset this drawback. cov(k,l) sim(k,l) = σ σ k l (2) m sim 2 2 ∑ m m (R R − ) ∑ ( R R − ) u = 1 u k , u u = 1 u l , u where sim(k,l) means the similarity between item k andl ; m means the total number of users, who rates on both item k and l ; Ru are the average ratings of user u ; Ru,k , Ru,l mean the rating of user u on item k andl respectively. 3.2.3 Linear combination of similarity Due to difference in value range between itemrating matrix and group-rating matrix, we use different methods to calculate the similarity. As for item-ratings matrix, the rating value is integer</context>
</contexts>
<marker>Sarwar, Karypis, Konstan, Riedl, 2001</marker>
<rawString>Sarwar, B. M., Karypis, G., Konstan, J. A. and Riedl, J.. 2001. Item-based Collaborative Filtering Recommendation Algorithms, In Proc. Tenth Int. WWW Conf. 2001, pp. 285-295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Upendra</author>
<author>M Patti</author>
</authors>
<title>Social Information Filtering: Algorithms for Automating &amp;quot;Word of Mouth&amp;quot;,</title>
<date>1995</date>
<booktitle>In Proc. ACM CHI&apos;95 Conf. on Human Factors in Computing Systems.</booktitle>
<pages>210--217</pages>
<marker>Upendra, Patti, 1995</marker>
<rawString>Upendra, S. and Patti, M.. 1995. Social Information Filtering: Algorithms for Automating &amp;quot;Word of Mouth&amp;quot;, In Proc. ACM CHI&apos;95 Conf. on Human Factors in Computing Systems. pp.210—217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Verhoeff</author>
<author>W Goffman</author>
<author>J Belzer</author>
</authors>
<title>Inefficiency of the use of the boolean functions for information retrieval systems,</title>
<date>1961</date>
<journal>Communications of the ACM,</journal>
<volume>4</volume>
<pages>557--558</pages>
<contexts>
<context position="1490" citStr="Verhoeff et al., 1961" startWordPosition="208" endWordPosition="211">y of the item-based collaborative filtering, especially for the cold start problem. 1 Introduction There are two dominant research paradigms of information filtering: content-based and collaborative filtering. Content-based filtering selects the right information for users by comparing representations of searching information to representations of contents of user profiles which express interests of users. Content-based information filtering has proven to be effective in locating textual items relevant to a topic using techniques, such as Boolean queries (Anick et al., 1990; Lee et al., 1993; Verhoeff et al., 1961), vector-space queries (Salton and Buckley, 1998), probabilistic model (Robertson and Sparck, 1976), neural network (Kim and Raghavan, 2000) and fuzzy set model (Ogawa et This work was supported by Korea Research Foundation Grant (KRF-2002-041-D00459). al., 1991). However, content-based filtering has some limitations: • It is hard for content-based filtering to provide serendipitous recommendations, because all the information is selected and recommended based on the content. • It is hard for novices to use content-based systems effectively. Collaborative filtering is the technique of using pe</context>
</contexts>
<marker>Verhoeff, Goffman, Belzer, 1961</marker>
<rawString>Verhoeff, J., Goffman, W. and Belzer, J.. 1961. Inefficiency of the use of the boolean functions for information retrieval systems, Communications of the ACM, 4, pp.557--558, pp.594.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M A Wasfi</author>
</authors>
<title>Collecting User Access Patterns for Building user Profiles and Collaborative Filtering,</title>
<date>1999</date>
<booktitle>In Int. Conf. on Intelligent User Interfaces. pp.57-</booktitle>
<pages>64</pages>
<contexts>
<context position="4693" citStr="Wasfi (1999)" startWordPosition="706" endWordPosition="707">tems, calculating the similarities between items and solving the cold start problem. Section 4 describes our experimental work. It provides details of our data sets, evaluation metrics, results of our experiment and discussion of the results. The final section provides some concluding remarks. 2 Related work Proposed approaches to hybrid system, which combines content-based and collaborative filters together, can be categorized into two groups. One group is the linear combination of results of collaborative and content-based filtering, such as systems that are described by Claypool (1999) and Wasfi (1999). ProfBuilder (Wasfi, 1999) recommends web pages using both content-based and collaborative filters, and each creates a recommendation list without combining them to make a combined prediction. Claypool (1999) describes a hybrid approach for an online newspaper domain, combining the two predictions using an adaptive weighted average: as the number of users accessing an item increases, the weight of the collaborative component tends to increase. But how to decide the weights of collaborative and contentbased components is unclearly given by the author. The other group is the sequential combinat</context>
</contexts>
<marker>Wasfi, 1999</marker>
<rawString>Wasfi, A. M. A.. 1999. Collecting User Access Patterns for Building user Profiles and Collaborative Filtering, In Int. Conf. on Intelligent User Interfaces. pp.57- 64.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>