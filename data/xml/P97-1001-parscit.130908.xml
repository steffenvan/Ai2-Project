<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.9990695">
Interleaving Universal Principles And Relational
Constraints Over Typed Feature Logic
</title>
<author confidence="0.828597">
Thilo Gotz and Detmar Meurers
</author>
<affiliation confidence="0.473575">
SFB 340, Universitat Tubingen, Kleine WilhelmstraBe 113,
</affiliation>
<address confidence="0.801121">
72074 Tubingen, Germany.
</address>
<email confidence="0.793129">
Itg,dmlOsfs.nphil.uni-tuebingen.de
</email>
<sectionHeader confidence="0.987105" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999813">
We introduce a typed feature logic system providing
both universal implicational principles as well as defi-
nite clauses over feature terms. We show that such an
architecture supports a modular encoding of linguistic
theories and allows for a compact representation using
underspecification. The system is fully implemented
and has been used as a workbench to develop and test
large HPSG grammars. The techniques described in
this paper are not restricted to a specific implementa-
tion, but could be added to many current feature-based
grammar development systems.
</bodyText>
<sectionHeader confidence="0.959643" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999919545454545">
A significant part of the development of formalisms for
computational linguistics has been concerned with find-
ing the appropriate data structures to model the lin-
guistic entities. The first order terms of Prolog and
DcGs were replaced by feature structures in PATR style
systems,&apos; and in recent years systems using typed fea-
ture structures have been developed.
Following the tradition of DCG and PATR, these typed
feature systems are generally definite clause based, e.g.,
CUF (D8rre and Dorna 1993), or phrase structure based,
e.g., ALE (Carpenter and Penn 1994). Instead of per-
mitting the grammar writer to express universal well-
formedness constraints directly, the systems require the
grammar writer to express relational constraints and
attach them locally at the appropriate places in the
grammax.2
We believe there are several reasons why the advances
in the linguistic data structures should entail the de-
velopment of systems offering more expressive means
for designing grammars. Using universal implicative
constraints, or universal principles as they are usually
called in the linguistic literature, grammatical generali-
</bodyText>
<footnote confidence="0.677736666666667">
1Cf. Shieber (1986) for a discussion of these formalisms.
2ALE has a restricted form of universal constraints, see
the comparison section.
</footnote>
<bodyText confidence="0.999770064516129">
sations can be expressed in a more compact and modu-
lar way. Another advantage of an architecture includ-
ing principles is that it computationally realizes the ar-
chitecture assumed in Pollard and Sag (1994) for HPSG.
It thus becomes possible to develop and test HPSG gram-
mars in a computational system without having to re-
code them as phrase structure or definite clause gram-
mars. The architecture can also serve as extended ar-
chitecture for principle based parsing (e.g., Stabler and
Johnson 1993) since it facilitates the implementation of
GB-style universal principles. Offering both more per-
spicuous grammar code and closeness to linguistic the-
ory, it seems well motivated to explore an architecture
which allows both relational constraints and universal
restrictions to be expressed.
Our implementation is based on the idea to compile
implicational constraints into a relational representa-
tion (Gotz and Meurers 1995) where calls to the con-
straint solver are made explicit. This allows for an
integration of implicational and relational constraints
and a uniform evaluation strategy. Efficient processing
is achieved through user-supplied delay patterns that
work on both relations and implicational constraints,
as well as preferred execution of deterministic goals at
run-time.
The paper is organised as follows. We will start out
by illustrating our architecture with an example. We
then go on to describe the key aspects of the imple-
mentation. We compare our work to other approaches
before presenting some conclusions and open issues in
the last section.
</bodyText>
<subsectionHeader confidence="0.858138">
Motivating the architecture
</subsectionHeader>
<bodyText confidence="0.9997838">
Consider the Head Feature Principle (HFP) of Pollard
and Sag (1994) as an introductory example for a gram-
matical principle. The HFP requires that in a headed
construction the head features of the mother are iden-
tified with the head features of the head daughter. In a
</bodyText>
<page confidence="0.900015">
1
</page>
<figure confidence="0.976862222222222">
typed feature logic3 this may be expressed by the prin-
ciple shown in Fig. 1.
phrase A dtrs: headed-struc
synsem : loc : cat: head: X A
dtrs: head-dtr : synsem : loc : cat: head: X
wf-phrase := phrase A dtrs : headed-struc
A hfpA OAP
wf-phrase := phrase A dtrs : -,headed-struc
A OAP
</figure>
<figureCaption confidence="0.997413">
Figure 4: Splitting up the wf-phrase relation to accom-
modate the HFP call
Figure 1: A Head-Feature Principle
</figureCaption>
<bodyText confidence="0.9665375">
In CUF, we can encode the HFP as a clause defining a
unary relation hfp as shown in Fig. 2.4
</bodyText>
<figure confidence="0.683874">
hfp := synsem : loc : cat: head: X A
dtrs: head-dtr : synsem : loc : cat: head: X
</figure>
<figureCaption confidence="0.99887">
Figure 2: A relation encoding the HFP
</figureCaption>
<bodyText confidence="0.999096666666667">
For the relation hfp to take effect, calls to it need
to be attached at the appropriate places. Expressing
grammatical constraints in such a way is both time con-
suming and error prone.
Suppose we want to define the unary relation wf-
phrase to hold of all grammatical phrases. In case all
grammatical phrases are constrained by a term 4) and
some relation P, we can define the relation wf-phrase
shown in Fig. 3.
</bodyText>
<equation confidence="0.694456">
wf-phrase := phrase A ck A P
</equation>
<figureCaption confidence="0.987347">
Figure 3: Defining the relation wf-phrase
</figureCaption>
<bodyText confidence="0.935833674418605">
To specify that A P holds for all phrases while the
HFP only holds for headed phrases, we now have to man-
ually split the definition into two clauses, the subcase
we want to attach the HFP to and the other one.
This is both inelegant and, barring a clever indexing
scheme, inefficient. Using universal principles on the
other hand, the global grammar organisation does not
need to account for every possible distinction. The or-
ganisation of the data structure as typed feature struc-
tures already provides the necessary structure and the
grammatical constraints only need to enforce additional
constraints on the relevant subsets. Thus, the implica-
3Following King (1989) and Carpenter (1992), we use
a typed feature logic with appropriateness restrictions for
the domains and ranges of features. For space reasons we
cannot provide a formal definition of the logic here, but
the interested reader is referred to Carpenter (1992) for an
exposition.
4Throughout the paper and as syntax for the system
discussed here we use the functional style notation of CUF
(Dorre and Dorna 1993) for our relations, where a desig-
nated result argument is made explicit. The denotation of
a relation thus is a set of objects just like the denotation of
any other feature term.
tional constraint encoding the HFP shown in Fig. 1 con-
strains only the headed phrases, and the non-headed
ones do not need to be considered.
Finally, a system providing both universal principles
and relational constraints at the same level offers a
large degree of flexibility. While in HPSG theories the
principles usually form the main part of the grammar
and relations such as append are used as auxiliary con-
straints called by the principles, a more traditional kind
of grammar for which one prefers a relational organisa-
tion can also be expressed more compactly by adding
some universal principles constraining the arguments of
the relations to the relational core. Both kinds of inter-
action are possible in the non-layered architecture we
propose.
With respect to our example, the first kind of inter-
action would be obtained by also expressing the general
restriction on phrase as a universal constraint as shown
in Fig. 5, while the more traditional kind of grammar
</bodyText>
<figure confidence="0.283512">
phrase -4 4)AP
</figure>
<figureCaption confidence="0.999275">
Figure 5: A universal constraint on phrases
</figureCaption>
<bodyText confidence="0.9998785">
would keep the relation defining well-formed phrases
shown in Fig. 3 and combine it with the universal con-
straint of Fig. 1 in order to avoid splitting up the re-
lation as was shown in Fig. 4. The proper interaction
of relational and universal constraints then needs to be
taken care of by the system.
</bodyText>
<subsectionHeader confidence="0.914698">
An example grammar
</subsectionHeader>
<bodyText confidence="0.999951666666667">
To further motivate our approach, we now show how
to code a simple principle based grammar in our frame-
work. Figure 6 shows the inheritance hierarchy of types
which we will use for our example with the appropri-
ateness conditions attached.
Our example grammar consists of some universal
principles, phrase structure rules and a lexicon. The
lexicon and phrase structure rules are encoded in the
wfs (well-formed sign) relation shown in Fig. 7 and the
implicational principles in Fig. 8. The wfs predicate
takes three arguments: a difference list pair threading
the string through the tree in the style of DcGs, and
</bodyText>
<page confidence="0.990585">
2
</page>
<figure confidence="0.731476333333333">
level list
zero one two [
e-list ne-list
hd atom
tl list
cat
verb noun adj prep
atom
[sign
head
bar
subcat
cat
level
list
arthur sleeps loves tinta gel
[word [
phon atom] phrase
head-dtr sign
comp-dtr sign
1. wfs(PO,P) :=
phrase A head: verb A subcat: [] A
bar: two A comp-dtr : wfs(PO, P1) A
head-dtr : wfs(P1, P)
2. wfs(PO, P) :=
phrase A head: verb A subcat: ne-list A
head- dtr : wfs(PO, Pl) A
comp- dtr : wfs(P1, P)
3. wfs([XIY], Y) :=
word A head: verb A bar: zero A
subcat: [head: noun, head: noun] A
phon : (loves A X)
4. wfs(PCIY1,Y) :=
word A head: verb A bar: zero A
subcat: [head: noun] A phon : (sleeps A X)
5. wfs([XIY],Y) :=
word A head: noun A
bar: two A subcat: [] A
phon : ((arthur V tintagel) AX)
</figure>
<figureCaption confidence="0.999662">
Figure 6: A type hierarchy
</figureCaption>
<bodyText confidence="0.9986266">
the syntactic category (sign) as functional style result
argument.5 The analysis tree is encoded in two daugh-
ters features as part of the syntactic categories in the
style of HPSG. Clause 1 of wfs combines a verbal projec-
tion with its subject, and clause 2 with its complements.
The lexical entries for the verbs &amp;quot;loves&amp;quot; and &amp;quot;sleeps&amp;quot; are
specified in clauses 3 and 4, respectively. Finally, clause
5 defines lexical entries for the proper names &amp;quot;Arthur&amp;quot;
and &amp;quot;Tintagel&amp;quot; .
Now consider the principles defined in Fig. 8.
Constraints 1-4 encode a simple version of X-bar theory,
constraint 5 ensures the propagation of categorial infor-
mation along the head path, and constraint 6 ensures
that complements obey the subcategorization require-
ments of the heads.
We may now ask the system for a solution to queries
like wfs([arthur, sleeps], B). The solution in this case is
the AVM in Fig. 9.
We can also query for a term like word A subcat :
ne-list and check it against the implications alone, as
it contains no relational goals. The result in Fig. 10
shows that our X-bar principles have applied: bar level
two requires that the subcat list must be empty, and bar
level one can only appear on phrases. The system thus
correctly infers that only bar level zero is possible.
</bodyText>
<footnote confidence="0.744022">
5We use standard abbreviatory bracket notation for lists.
</footnote>
<figureCaption confidence="0.991957">
Figure 7: Phrase structure rules and the lexicon
</figureCaption>
<listItem confidence="0.997198428571429">
1. bar: zero word
2. bar: one --&gt; head-dtr : bar: (-&apos;two)
3. bar: two —&gt; subcat: []
4. phrase —&gt; comp-dtr : bar: two
5. phrase -4 head: X A head-dtr : head: X
6. phrase -+ comp-dtr : X A subcat: YA
head- dtr : subcat: [X117]
</listItem>
<figureCaption confidence="0.925912">
Figure 8: X-bar theory, head feature principle and sub-
cat principle
</figureCaption>
<bodyText confidence="0.999944454545455">
The advantages of such a modular encoding of gram-
matical principles are obvious. The intuition behind
the constraints is clear, and new rules are easily added,
since the principles apply to any rule. On the other
hand, one can experiment with individual principles
without having to change the other principles or rules.
Finally, the option of encoding grammatical constraints
as either implicational constraints or relations opens the
possibility to chose the encoding most naturally suited
to the specific problem. We feel that this improves on
earlier, purely definite-clause-based approaches.
</bodyText>
<sectionHeader confidence="0.808218" genericHeader="acknowledgments">
Implementation
</sectionHeader>
<bodyText confidence="0.956555">
Compilation Building on the compilation method
described in Glitz and Meurers (1995), our compiler
</bodyText>
<page confidence="0.994822">
3
</page>
<figureCaption confidence="0.999772">
Figure 9: Solution to the query wfs([arthur, sleeps], 9)
</figureCaption>
<figure confidence="0.993405666666667">
[word
BAR zero
SUBCAT ne-list
</figure>
<figureCaption confidence="0.998251">
Figure 10: Solution for the query word A subcat : ne-list
</figureCaption>
<bodyText confidence="0.999855">
collects the types for which principles are formulated,
defines a relational encoding of the principles, and at-
taches calls to the relations at the places in the gram-
mar where a constrained type can occur. We assume
that the grammar writer guarantees that each type in
the grammar is consistent (for a grammar G and ev-
ery type t there is a model of G that satisfies t). One
therefore does not need to attach calls to each possible
occurrence of a constrained type, but only to those oc-
currences where the grammar contains additional spec-
ifications which might lead to an inconsistency (G8tz
and Meurers 1996). The interpretation of the resulting
program is lazy in the sense that we do not enumer-
ate fully specific solutions but compute more general
answers for which a grammatical instantiation is guar-
anteed to exist. A good example for this behaviour was
shown in Fig. 10: the system does not instantiate the
PHON and the HEAD values of the solution, since the
existence of grammatical values for these attributes is
independent of the query.
A way in which we deviate from the compilation
method of G6tz and Meurers (1995) is that our sys-
tem performs all constraint inheritance at compile-time.
While inheriting all principles to the most specific types
and transforming the resulting constraints to a disjunc-
tive normal form can significantly slow down compile
times, the advantage is that no inheritance needs to
be done on-line. To influence this trade-off, the user
can instruct the system to hide a disjunctive principle
in an auxiliary relation in order to keep it from being
multiplied out with the other constraints. Such auxil-
iary relations, which will be discussed further in con-
nection with the delay mechanism, have turned out to
be especially useful in conjunction with principles with
complex antecedents. The reason is that our compiler
transforms an implication with complex antecedents to
an implication with a type antecedent. The negation
of the complex antecedent is added to the consequent,
which can result in highly disjunctive specifications.
Interpretation As a guiding principle, the inter-
preter follows the ideas of the Andorra Model&apos; in
that it always executes deterministic goals before non-
deterministic ones. We consider determinacy only with
respect to head unification: a goal is recognised to be
determinate if there is at most one clause head that
unifies with it. This evaluation strategy has two ad-
vantages: it reduces the number of choice points to a
minimum, and it leads to early failure detection. In
our implementation, the overhead of determining which
goals are determinate has turned out to be by far out-
weighed by the reduction in search space for our lin-
guistic applications. An additional speed-up can be ex-
pected from applying known pre-processing techniques
(Santos Costa, Warren, and Yang 1991) to automati-
cally extract so-called determinacy code.
The execution order of non-determinate goals can be
influenced by the user with wait declarations (Naish
1985). The execution of some goal is postponed un-
til the call is more specific than a user-specified term.
Speculative computation may thus be reduced to a nec-
essary minimum. For our previous example, we might
define the delay statements in Fig. 11. The first state-
</bodyText>
<figure confidence="0.378106333333333">
delay(wfs,argl:list)
delay(phrase,subcat:list)
delay_deterministic(sign)
</figure>
<figureCaption confidence="0.985575">
Figure 11: Control statement examples
</figureCaption>
<bodyText confidence="0.999761125">
ment says that calls to wfs must be delayed until the
first argument is instantiated to some list value. Sim-
ilarly, the second statement delays the principles on
phrase until the subcat information is known. The
third statement is of a slightly different form, based on
the preferred treatment of determinate goals described
above. Instead of specifying the instantiation state re-
quired for execution, the delay_deterministic statement
</bodyText>
<footnote confidence="0.515145">
6Cf. Haridi and Janson (1990) and references cited
therein.
</footnote>
<figure confidence="0.9873915">
-phrase
BAR two
HEAD El verb
SUBCAT El word arthur
PHON
COMP-DTR BAR two
HEAD noun
SUBCAT e-list _
word
PHON sleeps
BAR zero
HEAD 0
me-list
SUBCAT HD El
TL El e-list _
HEAD-DTR
</figure>
<page confidence="0.984598">
4
</page>
<bodyText confidence="0.997850234567901">
specifies that the universal principles about signs can
only be executed in case they are determinate.
The delay mechanism for relational goals is very close
to the one used in CUF. We extended this mechanism
to the universal principles: the constraints on a certain
type were only checked, once certain attributes were
sufficiently instantiated (w.r.t. the delay statement).
Our experience has shown, however, that delaying uni-
versal principles in such a way turns out to be too weak.
Instead of delaying all constraints on a type until some
condition is met, one wants to be able to postpone the
application of some particular universal principle. A
subcategorization principle applying to phrases, for ex-
ample, should be delayed until the valence requirements
of the mother or the daughters are known. We therefore
allow the user to name a principle and supply it with a
specific delay. Internally, this corresponds to introduc-
ing an auxiliary relation under the name supplied by
the user and delaying it accordingly so that the choice
points introduced by the principle are hidden.
Let us illustrate the problem and its solution with a
schematic example. Suppose the grammar writer writes
a principle 0 -4 0. Our compiler will generate from this
a constraint t (-,0) V (q5 A 0), for some appropriate
type t. If 0 is a complex conjunctive description, then
the result of normalising -0 might be highly disjunc-
tive. This has two undesirable consequences. Firstly,
if there is another constraint t with disjunctive
then the compiler will need to normalise the expression
((-10)V(0M,b))A. This is the appropriate thing to do in
those cases where many of the generated disjuncts are
inconsistent and the resulting disjunction thus turns out
to be small. If, however, these constraints talk about
different parts of t&apos;s structure, then the resulting dis-
junction will be big and the expansion at compile-time
should be avoided.
The other problem is that we can only specify delays
on all constraints on t at once, and cannot delay indi-
vidual principles. In other words, the control for the
execution of principles is not fine-grained enough.
We solved these problems by offering the user the
possibility to name constraints, e.g., principlel :
This prohibits the compile-time cross-multiplication de-
scribed above, and it allows the user to specify delays
for such a principle, e.g. delay (principlel , . . . )
or even delay_deterministic (principle1), if that is
appropriate.
Debugging Having addressed the key issues behind
compilation and interpretation, we now turn to a prac-
tical problem which quickly arises once one tries to im-
plement larger grammars. On the one hand, the com-
plex data structures of such grammars contain an over-
whelming number of specifications which are difficult
to present to the user. On the other hand, the in-
teraction of universal principles and relations tends to
get very complex for realistic linguistic theories. While
a powerful graphical user interface&apos; solves the presen-
tation problem, a sophisticated tracing and debugging
tool was developed to allow stepwise inspection of the
complex constraint resolution process. The debugger
displays the feature structure(s) to be checked for gram-
maticality and marks the nodes on which constraints
still have to be checked. As a result of the determinacy
check, each such node can also be marked as failed,
delayed or deterministic. Similar to standard Prolog
debuggers, the user can step, skip, or fail a constraint
on a node, or request all deterministic processing to
be undertaken. An interesting additional possibility for
non-deterministic goals is that the user can inspect the
matching defining clauses and chose which one the sys-
tem should try. Figure 12 below shows a screen shot of
the debugger.
The debugger has turned out to be an indispensable
tool for grammar development. As grammar size in-
creases, it becomes very difficult to track down bugs
or termination problems without it, since these prob-
lems are often the result of some global interaction and
thus cannot be reduced to a manageable sub-part of the
grammar.
The reader interested in further practical aspects of
our system is referred to (G8tz and Meurers 1997)
</bodyText>
<subsectionHeader confidence="0.894962">
Comparison with previous work
</subsectionHeader>
<bodyText confidence="0.881728136363636">
There are quite a number of typed feature systems
available today, among them ALE (Carpenter and Penn
1994), CUF (Done and Dorna 1993) and TFS (Emele
and Zajac 1990; Emele 1994).
TFS also offered type constraints and relations and to
our knowledge was the first working typed feature sys-
tems. However, it had some serious drawbacks. TFS
did not allow universal principles with complex an-
tecedents, but only type constraints. And the system
did not include a delay mechanism, so that it was often
impossible to ensure termination or efficient processing.
The addition of a delay mechanism as described in this
paper would certainly increase the efficiency of TFS.
ALE provides relations and type constraints (i.e., only
types as antecedents), but their unfolding is neither
lazy, nor can it be controlled by the user in any way.
7To view grammars and computations our system uses
a GUI which allows the user to interactively view (parts of)
AVMS, compare and search AVMS, etc. The GUI comes with a
clean backend interface and has already been used as front-
end for other natural language applications, e.g., in VERB-
MOBIL. The GUI was developed by Carsten Hess.
</bodyText>
<page confidence="0.98967">
5
</page>
<bodyText confidence="0.988336490196079">
This can lead to severe termination problems with re-
cursive constraints. The ALE type constraints were de-
signed to enhance the typing system, and not for recur-
sive computation. This should be done in the phrase
structure or procedural attachment part. However, we
believe that the addition of delaying and an interpre-
tation strategy as described in this paper would add to
the attractiveness of ALE as a constraint-based gram-
mar development platform.
The definite clause part of our system is very similar
to the one of CUF: both use delay statements and pre-
ferred execution of deterministic goals. Although CUF
does not offer universal principles, their addition should
be relatively simple. Given that CUF already offers the
control strategies required by our scheme, the changes
to the run-time system would be minimal.
Conclusion and future research
We have presented an architecture that integrates rela-
tional and implicational constraints over typed feature
logic. We showed how such an architecture facilitates
the modular and compact encoding of principle based
grammars.
Our implementation has been tested with several
smaller and one large (&gt; 5000 lines) grammar, a
lineaxisation-based grammar of a sizeable fragment of
German (Hinrichs et al. 1997). As the grammar
constraints combine sub-strings in a non-concatenative
fashion, we use a preprocessor that &amp;quot;chunks&amp;quot; the input
string into lineaxisation domains, which are then fed
to the constraint solver. With our Prolog based inter-
preter, parse times are around 1-5 sec. for 5 word sen-
tences and 10-60 sec. for 12 word sentences. It should
be pointed out that parsing with such a grammar would
be difficult with any system, as it does neither have nor
allow the addition of a context-free backbone.
We are currently experimenting with a C based com-
piler (Zahnert 1997) using an abstract machine with a
specialised set of instructions based on the WAM (War-
ren 1983; AI-Kaci 1991). This compiler is still under
development, but it is reasonable to expect speed im-
provements of at least an order of magnitude. Abstract-
machine-based compilation of typed feature logic lan-
guages has recently received much attention (Carpenter
and Qu 1995, Wintner 1997, Penn in prep.). True com-
pilation is the logical development in a maturing field
that has hitherto relied on interpreters in high-level pro-
gramming languages such as Prolog and Lisp.
We also plan to investigate a specialised constraint
language for linearisation grammars, to be able to opti-
mise the processing of freer word order languages such
as German.
</bodyText>
<sectionHeader confidence="0.977626" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.662422857142857">
AI-Kaci, H. (1991). Warren&apos;s Abstract Machine. MIT
Press.
Carpenter, B. (1992). The logic of typed feature struc-
tures, Volume 32 of Cambridge Tracts in Theo-
retical Computer Science. Cambridge University
Press.
Carpenter, B. and G. Penn (1994). ALE — The At-
tribute Logic Engine, User&apos;s Guide, Version 2.0.1,
December 1994. Technical report, Carnegie Mel-
lon University.
Carpenter, B. and Y. Qu (1995). An abstract ma-
chine for attribute-value logics. In Proceedings of
the Fourth International Workshop on Parsing
Technology. Prague.
Dorre, J. and M. Dorna (1993, August). CUF -
a formalism for linguistic knowledge representa-
tion. In J. D8rre (Ed.), Computational aspects of
constraint based linguistic descriptions I, pp. 1-
22. Universitat Stuttgart: DYANA-2 Deliverable
R1.2.A.
Emele, M. C. (1994). The typed feature structure
representation formalism. In Proceedings of the
International Workshop on Sharable Natural Lan-
guage Resources, Ikoma, Nara, Japan.
Emele, M. C. and R. Zajac (1990). Typed unifica-
tion grammars. In Proceedings of the 13th Inter-
national Conference on Computational Linguis-
tics.
G8tz, T. and W. D. Meurers (1995). Compiling
HPSG type constraints into definite clause pro-
grams. In Proceedings of the Thrirty- Third An-
nual Meeting of the ACL, Boston. Association for
Computational Linguistics.
G8tz, T. and W. D. Meurers (1996). The importance
of being lazy - using lazy evaluation to process
queries to HPSG grammars. In P. Blache (Ed.),
Actes de la troisieme conference anuelle sur le
traitment automatique du langage naturel.
Gotz, T. and W. D. Meurers (1997). The ConTroll
system as large grammar development platform.
In Proceedings of the A CL/EACL post-conference
workshop on Computational Environments for
Grammar Development and Linguistic Engineer-
ing, Madrid, Spain.
Haridi, S. and S. Janson (1990). Kernel Andorra Pro-
log and its computation model. In D. H. D. War-
ren and P. Szeredi (Eds.), Proceedings of the sev-
enth international conference on logic program-
ming, pp. 31-46. MIT Press.
</bodyText>
<page confidence="0.995036">
6
</page>
<reference confidence="0.949904371428571">
Hinrichs, E., D. Meurers, F. Richter, M. Sailer,
and H. Winhart (1997). Ein HPSG-Fragment des
Deutschen, Teil 1: Theorie. Arbeitspapiere des
SFB 340 Nr. 95, Universitat Tübingen.
King, P. J. (1989). A logical formalism for head-
driven phrase structure grammar. Ph. D. thesis,
University of Manchester.
Naish, L. (1985). Negation and Control in Prolog.
Springer-Verlag.
Penn, G. (in prep.). Statistical Optimizations in a
Feature Structure Abstract Machine. Ph. D. the-
sis, Carnegie Mellon University.
Pollard, C. and I. A. Sag (1994). Head-Driven
Phrase Structure Grammar. Chicago: University
of Chicago Press.
Santos Costa, V., D. H. D. Warren, and R. Yang
(1991). The Andorra-I preprocessor: Supporting
full Prolog on the Basic Andorra model. In Pro-
ceedings of the Eighth International Conference
on Logic Programming, pp. 443-456.
Shieber, S. M. (1986). An Introduction to Unifi-
cation-Based Approaches to Grammar. Number 4
in CSLI Lecture Notes. Center for the Study of
Language and Information.
Stabler, E. P. and M. Johnson (1993). Topics in prin-
ciple based parsing. Course notes for the 1993
LSA Summer Institute.
Warren, D. H. D. (1983). An abstract Prolog instruc-
tion set. Technical note 309, SRI International.
Wintner, S. (1997). An Abstract Machine for Unifi-
cation Grammars. Ph. D. thesis, Technion, Haifa,
Israel.
Zahnert, A. (1997). fl2c — em n Compiler fiir
CLP(TFS). Diplomarbeit, Fakultat fur Infor-
matik, Universitut Tubingen.
</reference>
<page confidence="0.999524">
7
</page>
<figureCaption confidence="0.981458">
Figure 12: A screen shot of the graphical debugger
</figureCaption>
<figure confidence="0.999693963636363">
Functions Options
Drawing done
Port: 3 CALL
ALL Fail 1
hc_phrase hs_phrase hspr_phrase)
phon J List
_DEBUGGER_
is
• :•ri.1,
5,1,145NWR
10 C 10C
cat cat
he ad
siwie word
phon Er&lt; maria
synsem
moved
const
E2
synsem
ion El[loc
cat[ cat
head fen sy_covntii
status complete
syns em
status
nonhe ad_dtr
cerowlete
phrase
syns em synsem
cat cat
val[ al
evomps &lt; I &gt;
status confolete
s2mple word
phon I List
[
syns em synsem
loproc
c at cat
[head
head dtr
IJ
app end_s tring (
app end_s tring (
Ipp_adj vlp (
[
&lt; 0 simple word
phon Er
synsem[synsel
I.boc EI
1021
4111 creep skip
verla2
fronted
</figure>
<page confidence="0.943285">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.516974">
<title confidence="0.9732275">Interleaving Universal Principles And Relational Constraints Over Typed Feature Logic</title>
<author confidence="0.533627">Thilo Gotz</author>
<author confidence="0.533627">Detmar Meurers</author>
<affiliation confidence="0.936161">Universitat Tubingen, Kleine WilhelmstraBe 113,</affiliation>
<address confidence="0.99503">72074 Tubingen, Germany.</address>
<abstract confidence="0.999429166666667">We introduce a typed feature logic system providing both universal implicational principles as well as definite clauses over feature terms. We show that such an architecture supports a modular encoding of linguistic theories and allows for a compact representation using underspecification. The system is fully implemented and has been used as a workbench to develop and test The techniques described in this paper are not restricted to a specific implementation, but could be added to many current feature-based grammar development systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Hinrichs</author>
<author>D Meurers</author>
<author>F Richter</author>
<author>M Sailer</author>
<author>H Winhart</author>
</authors>
<date>1997</date>
<booktitle>Ein HPSG-Fragment des Deutschen, Teil 1: Theorie. Arbeitspapiere des SFB 340 Nr. 95,</booktitle>
<institution>Universitat Tübingen.</institution>
<contexts>
<context position="22250" citStr="Hinrichs et al. 1997" startWordPosition="3661" endWordPosition="3664">rinciples, their addition should be relatively simple. Given that CUF already offers the control strategies required by our scheme, the changes to the run-time system would be minimal. Conclusion and future research We have presented an architecture that integrates relational and implicational constraints over typed feature logic. We showed how such an architecture facilitates the modular and compact encoding of principle based grammars. Our implementation has been tested with several smaller and one large (&gt; 5000 lines) grammar, a lineaxisation-based grammar of a sizeable fragment of German (Hinrichs et al. 1997). As the grammar constraints combine sub-strings in a non-concatenative fashion, we use a preprocessor that &amp;quot;chunks&amp;quot; the input string into lineaxisation domains, which are then fed to the constraint solver. With our Prolog based interpreter, parse times are around 1-5 sec. for 5 word sentences and 10-60 sec. for 12 word sentences. It should be pointed out that parsing with such a grammar would be difficult with any system, as it does neither have nor allow the addition of a context-free backbone. We are currently experimenting with a C based compiler (Zahnert 1997) using an abstract machine wi</context>
</contexts>
<marker>Hinrichs, Meurers, Richter, Sailer, Winhart, 1997</marker>
<rawString>Hinrichs, E., D. Meurers, F. Richter, M. Sailer, and H. Winhart (1997). Ein HPSG-Fragment des Deutschen, Teil 1: Theorie. Arbeitspapiere des SFB 340 Nr. 95, Universitat Tübingen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J King</author>
</authors>
<title>A logical formalism for headdriven phrase structure grammar.</title>
<date>1989</date>
<tech>Ph. D. thesis,</tech>
<institution>University of Manchester.</institution>
<contexts>
<context position="5703" citStr="King (1989)" startWordPosition="915" endWordPosition="916">nly holds for headed phrases, we now have to manually split the definition into two clauses, the subcase we want to attach the HFP to and the other one. This is both inelegant and, barring a clever indexing scheme, inefficient. Using universal principles on the other hand, the global grammar organisation does not need to account for every possible distinction. The organisation of the data structure as typed feature structures already provides the necessary structure and the grammatical constraints only need to enforce additional constraints on the relevant subsets. Thus, the implica3Following King (1989) and Carpenter (1992), we use a typed feature logic with appropriateness restrictions for the domains and ranges of features. For space reasons we cannot provide a formal definition of the logic here, but the interested reader is referred to Carpenter (1992) for an exposition. 4Throughout the paper and as syntax for the system discussed here we use the functional style notation of CUF (Dorre and Dorna 1993) for our relations, where a designated result argument is made explicit. The denotation of a relation thus is a set of objects just like the denotation of any other feature term. tional cons</context>
</contexts>
<marker>King, 1989</marker>
<rawString>King, P. J. (1989). A logical formalism for headdriven phrase structure grammar. Ph. D. thesis, University of Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Naish</author>
</authors>
<title>Negation and Control in Prolog.</title>
<date>1985</date>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="14542" citStr="Naish 1985" startWordPosition="2417" endWordPosition="2418">. This evaluation strategy has two advantages: it reduces the number of choice points to a minimum, and it leads to early failure detection. In our implementation, the overhead of determining which goals are determinate has turned out to be by far outweighed by the reduction in search space for our linguistic applications. An additional speed-up can be expected from applying known pre-processing techniques (Santos Costa, Warren, and Yang 1991) to automatically extract so-called determinacy code. The execution order of non-determinate goals can be influenced by the user with wait declarations (Naish 1985). The execution of some goal is postponed until the call is more specific than a user-specified term. Speculative computation may thus be reduced to a necessary minimum. For our previous example, we might define the delay statements in Fig. 11. The first statedelay(wfs,argl:list) delay(phrase,subcat:list) delay_deterministic(sign) Figure 11: Control statement examples ment says that calls to wfs must be delayed until the first argument is instantiated to some list value. Similarly, the second statement delays the principles on phrase until the subcat information is known. The third statement i</context>
</contexts>
<marker>Naish, 1985</marker>
<rawString>Naish, L. (1985). Negation and Control in Prolog. Springer-Verlag.</rawString>
</citation>
<citation valid="false">
<authors>
<author>G Penn</author>
</authors>
<title>(in prep.). Statistical Optimizations in a Feature Structure Abstract Machine.</title>
<tech>Ph. D. thesis,</tech>
<institution>Carnegie Mellon University.</institution>
<marker>Penn, </marker>
<rawString>Penn, G. (in prep.). Statistical Optimizations in a Feature Structure Abstract Machine. Ph. D. thesis, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
<author>I A Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>University of Chicago Press.</publisher>
<location>Chicago:</location>
<contexts>
<context position="2291" citStr="Pollard and Sag (1994)" startWordPosition="335" endWordPosition="338">vances in the linguistic data structures should entail the development of systems offering more expressive means for designing grammars. Using universal implicative constraints, or universal principles as they are usually called in the linguistic literature, grammatical generali1Cf. Shieber (1986) for a discussion of these formalisms. 2ALE has a restricted form of universal constraints, see the comparison section. sations can be expressed in a more compact and modular way. Another advantage of an architecture including principles is that it computationally realizes the architecture assumed in Pollard and Sag (1994) for HPSG. It thus becomes possible to develop and test HPSG grammars in a computational system without having to recode them as phrase structure or definite clause grammars. The architecture can also serve as extended architecture for principle based parsing (e.g., Stabler and Johnson 1993) since it facilitates the implementation of GB-style universal principles. Offering both more perspicuous grammar code and closeness to linguistic theory, it seems well motivated to explore an architecture which allows both relational constraints and universal restrictions to be expressed. Our implementatio</context>
<context position="3745" citStr="Pollard and Sag (1994)" startWordPosition="558" endWordPosition="561">nal constraints and a uniform evaluation strategy. Efficient processing is achieved through user-supplied delay patterns that work on both relations and implicational constraints, as well as preferred execution of deterministic goals at run-time. The paper is organised as follows. We will start out by illustrating our architecture with an example. We then go on to describe the key aspects of the implementation. We compare our work to other approaches before presenting some conclusions and open issues in the last section. Motivating the architecture Consider the Head Feature Principle (HFP) of Pollard and Sag (1994) as an introductory example for a grammatical principle. The HFP requires that in a headed construction the head features of the mother are identified with the head features of the head daughter. In a 1 typed feature logic3 this may be expressed by the principle shown in Fig. 1. phrase A dtrs: headed-struc synsem : loc : cat: head: X A dtrs: head-dtr : synsem : loc : cat: head: X wf-phrase := phrase A dtrs : headed-struc A hfpA OAP wf-phrase := phrase A dtrs : -,headed-struc A OAP Figure 4: Splitting up the wf-phrase relation to accommodate the HFP call Figure 1: A Head-Feature Principle In CU</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Pollard, C. and I. A. Sag (1994). Head-Driven Phrase Structure Grammar. Chicago: University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Santos Costa</author>
<author>D H D Warren V</author>
<author>R Yang</author>
</authors>
<title>The Andorra-I preprocessor: Supporting full Prolog on the Basic Andorra model.</title>
<date>1991</date>
<booktitle>In Proceedings of the Eighth International Conference on Logic Programming,</booktitle>
<pages>443--456</pages>
<marker>Costa, V, Yang, 1991</marker>
<rawString>Santos Costa, V., D. H. D. Warren, and R. Yang (1991). The Andorra-I preprocessor: Supporting full Prolog on the Basic Andorra model. In Proceedings of the Eighth International Conference on Logic Programming, pp. 443-456.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>An Introduction to Unification-Based Approaches to Grammar. Number 4 in CSLI Lecture Notes. Center for the Study of Language and Information.</title>
<date>1986</date>
<contexts>
<context position="1967" citStr="Shieber (1986)" startWordPosition="285" endWordPosition="286">LE (Carpenter and Penn 1994). Instead of permitting the grammar writer to express universal wellformedness constraints directly, the systems require the grammar writer to express relational constraints and attach them locally at the appropriate places in the grammax.2 We believe there are several reasons why the advances in the linguistic data structures should entail the development of systems offering more expressive means for designing grammars. Using universal implicative constraints, or universal principles as they are usually called in the linguistic literature, grammatical generali1Cf. Shieber (1986) for a discussion of these formalisms. 2ALE has a restricted form of universal constraints, see the comparison section. sations can be expressed in a more compact and modular way. Another advantage of an architecture including principles is that it computationally realizes the architecture assumed in Pollard and Sag (1994) for HPSG. It thus becomes possible to develop and test HPSG grammars in a computational system without having to recode them as phrase structure or definite clause grammars. The architecture can also serve as extended architecture for principle based parsing (e.g., Stabler a</context>
</contexts>
<marker>Shieber, 1986</marker>
<rawString>Shieber, S. M. (1986). An Introduction to Unification-Based Approaches to Grammar. Number 4 in CSLI Lecture Notes. Center for the Study of Language and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E P Stabler</author>
<author>M Johnson</author>
</authors>
<title>Topics in principle based parsing. Course notes for the</title>
<date>1993</date>
<journal>LSA Summer Institute.</journal>
<contexts>
<context position="2583" citStr="Stabler and Johnson 1993" startWordPosition="384" endWordPosition="387">er (1986) for a discussion of these formalisms. 2ALE has a restricted form of universal constraints, see the comparison section. sations can be expressed in a more compact and modular way. Another advantage of an architecture including principles is that it computationally realizes the architecture assumed in Pollard and Sag (1994) for HPSG. It thus becomes possible to develop and test HPSG grammars in a computational system without having to recode them as phrase structure or definite clause grammars. The architecture can also serve as extended architecture for principle based parsing (e.g., Stabler and Johnson 1993) since it facilitates the implementation of GB-style universal principles. Offering both more perspicuous grammar code and closeness to linguistic theory, it seems well motivated to explore an architecture which allows both relational constraints and universal restrictions to be expressed. Our implementation is based on the idea to compile implicational constraints into a relational representation (Gotz and Meurers 1995) where calls to the constraint solver are made explicit. This allows for an integration of implicational and relational constraints and a uniform evaluation strategy. Efficient</context>
</contexts>
<marker>Stabler, Johnson, 1993</marker>
<rawString>Stabler, E. P. and M. Johnson (1993). Topics in principle based parsing. Course notes for the 1993 LSA Summer Institute.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D H D Warren</author>
</authors>
<title>An abstract Prolog instruction set. Technical note 309,</title>
<date>1983</date>
<publisher>SRI International.</publisher>
<contexts>
<context position="22916" citStr="Warren 1983" startWordPosition="3775" endWordPosition="3777">on-concatenative fashion, we use a preprocessor that &amp;quot;chunks&amp;quot; the input string into lineaxisation domains, which are then fed to the constraint solver. With our Prolog based interpreter, parse times are around 1-5 sec. for 5 word sentences and 10-60 sec. for 12 word sentences. It should be pointed out that parsing with such a grammar would be difficult with any system, as it does neither have nor allow the addition of a context-free backbone. We are currently experimenting with a C based compiler (Zahnert 1997) using an abstract machine with a specialised set of instructions based on the WAM (Warren 1983; AI-Kaci 1991). This compiler is still under development, but it is reasonable to expect speed improvements of at least an order of magnitude. Abstractmachine-based compilation of typed feature logic languages has recently received much attention (Carpenter and Qu 1995, Wintner 1997, Penn in prep.). True compilation is the logical development in a maturing field that has hitherto relied on interpreters in high-level programming languages such as Prolog and Lisp. We also plan to investigate a specialised constraint language for linearisation grammars, to be able to optimise the processing of f</context>
</contexts>
<marker>Warren, 1983</marker>
<rawString>Warren, D. H. D. (1983). An abstract Prolog instruction set. Technical note 309, SRI International.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Wintner</author>
</authors>
<title>An Abstract Machine for Unification Grammars.</title>
<date>1997</date>
<tech>Ph. D. thesis,</tech>
<location>Technion, Haifa,</location>
<contexts>
<context position="23200" citStr="Wintner 1997" startWordPosition="3820" endWordPosition="3821">ould be pointed out that parsing with such a grammar would be difficult with any system, as it does neither have nor allow the addition of a context-free backbone. We are currently experimenting with a C based compiler (Zahnert 1997) using an abstract machine with a specialised set of instructions based on the WAM (Warren 1983; AI-Kaci 1991). This compiler is still under development, but it is reasonable to expect speed improvements of at least an order of magnitude. Abstractmachine-based compilation of typed feature logic languages has recently received much attention (Carpenter and Qu 1995, Wintner 1997, Penn in prep.). True compilation is the logical development in a maturing field that has hitherto relied on interpreters in high-level programming languages such as Prolog and Lisp. We also plan to investigate a specialised constraint language for linearisation grammars, to be able to optimise the processing of freer word order languages such as German. References AI-Kaci, H. (1991). Warren&apos;s Abstract Machine. MIT Press. Carpenter, B. (1992). The logic of typed feature structures, Volume 32 of Cambridge Tracts in Theoretical Computer Science. Cambridge University Press. Carpenter, B. and G. </context>
</contexts>
<marker>Wintner, 1997</marker>
<rawString>Wintner, S. (1997). An Abstract Machine for Unification Grammars. Ph. D. thesis, Technion, Haifa, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Zahnert</author>
</authors>
<title>fl2c — em n Compiler fiir CLP(TFS). Diplomarbeit, Fakultat fur Informatik, Universitut Tubingen.</title>
<date>1997</date>
<contexts>
<context position="22821" citStr="Zahnert 1997" startWordPosition="3759" endWordPosition="3760"> fragment of German (Hinrichs et al. 1997). As the grammar constraints combine sub-strings in a non-concatenative fashion, we use a preprocessor that &amp;quot;chunks&amp;quot; the input string into lineaxisation domains, which are then fed to the constraint solver. With our Prolog based interpreter, parse times are around 1-5 sec. for 5 word sentences and 10-60 sec. for 12 word sentences. It should be pointed out that parsing with such a grammar would be difficult with any system, as it does neither have nor allow the addition of a context-free backbone. We are currently experimenting with a C based compiler (Zahnert 1997) using an abstract machine with a specialised set of instructions based on the WAM (Warren 1983; AI-Kaci 1991). This compiler is still under development, but it is reasonable to expect speed improvements of at least an order of magnitude. Abstractmachine-based compilation of typed feature logic languages has recently received much attention (Carpenter and Qu 1995, Wintner 1997, Penn in prep.). True compilation is the logical development in a maturing field that has hitherto relied on interpreters in high-level programming languages such as Prolog and Lisp. We also plan to investigate a special</context>
</contexts>
<marker>Zahnert, 1997</marker>
<rawString>Zahnert, A. (1997). fl2c — em n Compiler fiir CLP(TFS). Diplomarbeit, Fakultat fur Informatik, Universitut Tubingen.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>