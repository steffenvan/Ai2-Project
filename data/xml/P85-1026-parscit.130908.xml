<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<sectionHeader confidence="0.924368857142857" genericHeader="method">
REPAIRING REFERENCE IDENTIFICATION FAILURES
BY RELAXATION
Bradley A. Goodman
BBN Laboratories
10 Moulton Street
Cambridge, Mass. 02238
ABSTRACT
</sectionHeader>
<bodyText confidence="0.998991681818182">
The goal of this work is the enrichment of
human-machine interactions in a natural language
environment.&apos; We want to provide a framework less
restrictive than earlier ones by allowing a speaker
leeway in forming an utterance about a task and in
determining the conversational vehicle to deliver it. A
speaker and listener cannot be assured to have the
same beliefs, contexts, backgrounds or goals at each
point in a conversation. As a result, difficulties and
mistakes arise when a listener interprets a speaker&apos;s
utterance. These mistakes can lead to various kinds of
misunderstandings between speaker and listener.
including reference failures or failure to understand
the speaker&apos;s intention. We call these
misunderstandings miscommunication Such mistakes
constitute a kind of &amp;quot;ill-formed&amp;quot; input that can slow
down and possibly break down communication. Our goal
is to recognize and isolate such miscommunications and
circumvent them. This paper will highlight a particular
class of miscommunication - reference problems - by
describing a case study, including techniques for
avoiding failures of reference
</bodyText>
<sectionHeader confidence="0.977195" genericHeader="method">
1 liatroduction
</sectionHeader>
<bodyText confidence="0.998706857142857">
Cohen. Perrault and Allen showed in their paper
&amp;quot;Beyond Question Answering&amp;quot; [6] that &amp;quot;.. users of
question-answering systems expect them to do more
than just answer isolated questions -- they expect
systems to engage in conversation In doing so. the
system is expected to allow users to be less than
meticulously literal in conveying their intentions, and it
is expected to make linguistic and pragmatic use of the
previous discourse.&amp;quot; Following in their footsteps, we
want to build robust natural language processing
systems that can detect and recover from
miscommunication. The development of such systems
requires a study on how people communicate and how
tney recover from problems in communication. This
paper summarizes the results of a dissertation (131
that investigates the kinds of miscommunication that
occur in human communication with a special emphasis
on reference problems. i.e.. problems a listener has
determining whom or what a speaker is talking about.
We have written computer programs and algorithms that
demonstrate how one could handle such problems in
</bodyText>
<footnote confidence="0.812276">
1This ,esearcn wig supported in part by the Defense
Advanced Research Project Agency under contract N00014-77—
</footnote>
<note confidence="0.461792">
C—e378.
</note>
<bodyText confidence="0.99989252631579">
the context of a natural language understanding
system. The study of miscommunication is a necessary
task within such a context since any computer capable
of communicating with humans in natural language must
be tolerant of the imprecise, ill-devised or complex
utterances that people often use.
Our current research [25, 28] views most
dialogues as being cooperative and goal directed. i.e.. a
speaker and listener work together to achieve a
common goal. The interpretation of an utterance
involves identifying the underlying plan or goal that
the utterance reflects [5. 1. 231. This plan, however, is
rarely, if ever, obvious at the surface sentence level.
A central issue in the interpretation of utterances is
the transformation of sequences of imprecise, ill-
devised or complex utterances into well-specified plans
that might be carried out by dialogue participants.
Within this context, miscommunication can occur.
We are particularly concerned with cases of
miscommunication from the hearer&apos;s viewpoint, such as
when the hearer is inattentive to, confused about, or
misled about the intentions of the speaker. In
ordinary exchanges speakers usually make assumptions
regarding what their listeners know about a topic of
discussion. They will leave out details thought to be
superfluous [2. 19]. Since the speaker really does not
know exactly what a listener knows about a topic, it is
easy to make statements that can be misinterpreted or
not understood by the listener because not enough
details were presented. One principal source of trouble
is the description constructed by the speaker to refer
to an actual object in the world. The description can
be imprecise, confused, ambiguous or overly specific, it
might be interpreted under the wrong context. This
leads to difficulty for the listener when figuring out
what object is being described, that is. reference
identification errors. Such descriptions are &amp;quot;ill-
formed&amp;quot; input. The blame for ill-formedness may lie
partly with the speaker and partly with the listener
The speaker may have been sloppy or not taken the
hearer into consideration, the listener may be either
remiss or unwilling to admit he can&apos;t understand the
speaker and to ask the speaker for clarification, or
may simply feel that he has understood when he in fact
has not.
This work is part of an on-going effort to
develop a reference identification and plan recognition
mechanism that can exhibit more &amp;quot;human-like&apos;
tolerance of such utterances. Our goal is to build a
more robust system that can handle errorful
utterances, and that can be incorporated in existing
systems. As a start. we have concentrated on
reference identification. In conversation people use
imperfect descriptions to communicate about objects,
sometimes their partners succeed in understanding and
occasionally they fail. Any computer hoping to play the
part of a listener must be capable of taking what the
</bodyText>
<page confidence="0.997187">
204
</page>
<bodyText confidence="0.999289704225352">
speaker says and either deleting, adapting or clarifying A. 1. Now there&apos;s a blue cap
it. We are developing a theory of the use of [J grabs the TUBEBASE]
extensional descriptions that will help explain how 2. that has two little teeth sticking
people successfully use such imperfect descriptions. 3. out of the bottom of it.
We call this the theory of reference miscommunication.
Section 2 of this paper highlights some aspects of 3: 4. Yeah.
normal communication and then provides a general
discussion on the types of miscommunication that occur
in conversation, concentrating primarily on reference
problems and motivating many of them with illustrative
protocols. Section 3 presents possible ways around
some of the problems of miscommunication in reference.
Motivated there is a partial implementation of a
reference mechanism that attempts to overcome many
reference problems.
We are following the task—oriented paradigm of
Grosz [14] since it is easy to study (through
videotapes), it places the world in front of you (a
primarily extensional world), and it limits the
discussion while still providing a rich environment for
complex descriptions. The task chosen as the target
for the system is the assembly of a toy water pump.
The water pump is reasonably complex, containing four
subassemblies that are built from plastic tubes,
nozzles, valves, plungers, and caps that can be screwed
or pushed together. A large corpus of dialogues
concerning this task was collected by Cohen (see
[7, 8. 9]). These dialogues contained instructions from
an &amp;quot;expert&amp;quot; to an &amp;quot;apprentice- that explain the
assembly of the toy water pump. Both participants
were working to achieve a common goal — the
successful assembly of the pump This domain is rich
in perceptual information, allowing for complex
descriptions of elements in it. The data provide
examples of imprecision. confusion. and ambiguity as
well as attempts to correct these problems.
The following exchange exemplifies one such
situation. Here A is instructing J to assemble part of
the water pump. Refer to Figure Ha) for a picture of
the pump. A and J are communicating verbally but
neither can see the other. (The bracketed text in the
excerpt tells what was actually occurring while each
utterance was spoken.) Notice the complexity of the
speaker&apos;s descriptions and the resultant processing
required by the listener. This dialogue illustrates when
listeners repair the speaker&apos;s description in order to
find a referent, when they repair their initial reference
choice once they are given more information. and when
they fail to choose a proper referent In Line 7, A
describes the two holes on the BASEVALVE as &amp;quot;the Ilttle
hole &amp;quot; i must repair the description. realizing that A
doesn t really mean &amp;quot;one &apos; hole but is referring to the
&apos;two &apos; holes. 1 apparently does this since he doesn t 1 23 All right.
complain about As description and correctly attaches
the BASEVALVE to the TUBEBASE Figure 1(b) shows
the configuration of the pump after the TUBEBASE is
attached to the MA1N7&apos;UBE In Line 10. In Line 13. J
interprets &amp;quot;a red plastic piece&amp;quot; to refer to the .VOZZLE.
When A adds the relative ciause &amp;quot;that has four gizmos
on it.&amp;quot; J is forced to drop the NOZZLE as the referent
and to select the SLIDEVALVE. In Lines 17 and 18. As
description the other--the open part of the main
tube, the lower valve&amp;quot; is ambiguous, and J selects the
wrong site, namely the TUBEBASE, in which to insert
the SUDEVALVE. Since the SL1DEVALVE fits, J doesn&apos;t
detect any trouble. Lines 20 and 21 keep J from
thinking that something is wrong because the part fits
loosely. In Lines 27 and 28, J indicates that A did not
give him enough information to perform the requested
action. In Line 30. J further compounds the error in
Line 18 by putting the SPOUT on the TUBEBASE.
</bodyText>
<figure confidence="0.977781585365853">
Excerpt 1 (Telephone)
A. 5. Okay On that take the
6. bright shocking pink piece of plastic
takes BASEVALVE]
7. and stick the little hole over the
teeth.
[3 starts to install the BASEVALVE, backs off, looks
at it again and then goes ahead and
installs it]
J. 8 Okay
A. 9 Now screw that blue cap onto
10. the bottom of the main tube.
[3 screws TUBEBASE onto MAINTUBE]
J. 11. Okay.
A. 12 Now, there&apos;s a--
13. a red plastic piece
[3 starts for NOZZLE]
14 that has four gizmos on it.
[3 switches to SLIDEVALVE]
J. 15. Yes.
A 16 Okay Put the ungizmoed end in the
uh
17 the other--the open
18. part of the main tube, the lower
valve.
puts SLIDEVALVE into hole in TUBEBASE, but A
meant OUTLET2 of MAINTUBE]
1 19 All right
A 20 It Just fits loosely It doesn&apos;t
21 have to fit right. Okay, then take
22 the clear plastic elbow Joint
[J takes SPOUT]
A 24 And put it over the bottom opening,
too.
[3 tries installing SPOUT on TUBEBASE]
1 25 Okay
A. 26. Okay Now, take the--
27 Which end am I supposed to put it
over&apos;
28 Do you know&apos;
A. 29 Put the--put the--the big end--
</figure>
<footnote confidence="0.916042333333333">
30. the big end over it.
[3 pushes big end of SPOUT on TUBEBASE, twisting
it to force it on]
</footnote>
<page confidence="0.995758">
205
</page>
<table confidence="0.9380264375">
C;:)I ted I
cLudt Plunger bZue
NO:Z le CZD
14&amp;quot;} Ibtuel &apos;12:1
Ar CAP 0 .
Choicer
Outlet1 :: Miu.n clez,
c Is&apos;be
gout .4=1 C&apos;ED, i gteen1
leleatl Slade delve
WWI
Plug Ie.41
Base Valve puit
0-Itgrtc C=3 btack 1
Tat* Base ••••••■•••&amp;quot;&apos;
STAnd (clean
</table>
<figure confidence="0.911631">
(a) (b)
</figure>
<figureCaption confidence="0.999567">
Figure 1: The Toy Water Pump
</figureCaption>
<sectionHeader confidence="0.943432" genericHeader="method">
2 Miscommunication
</sectionHeader>
<bodyText confidence="0.994955347826087">
People must and do manage to resolve lots of
(potential) miscommunication in everyday conversation.
Much of It is resolved subconsciously - with the
listener unaware that anything is wrong. Other
miscommunication is resolved with the listener actively
deleting or replacing information in the speaker&apos;s
utterance until It fits the current context. Sometimes
this resolution is postponed until the questionable part
of the utterance is actually needed. Still, when all
these fail, the listener can ask the speaker to clarify
what was said.2
There are many aspects of an utterance that the
listener can become confused about and that can lead
to miscommunication. The listener can become
confused about what the speaker intends for the
referents, the actions, and the goals described by the
utterance. Confusions often appear to result from
conflict between the current state of the conversation.
the overall goal of the speaker, or the manner in which
the speaker presented the information. However, when
the listener steps back and is able to discover what
kind of confusion is occurring, then the confusion can
quite possibly be resolved.
</bodyText>
<subsectionHeader confidence="0.998628">
2.1 Causes of miscommunication
</subsectionHeader>
<bodyText confidence="0.99939475">
This section attempts to motivate a paradigm for
the kinds of conversation that we studied and tries to
point out places in the paradigm that leave room for
miscommunication.
</bodyText>
<footnote confidence="0.830468">
2An analysis of clarification suodiologues can be found
in [17].
</footnote>
<subsectionHeader confidence="0.5842535">
2.1.1 Effects of the structure of task-oriented
dialogues
</subsectionHeader>
<bodyText confidence="0.99313258">
Task-oriented conversations have a specific goal
to be achieved: the performance of a task (e.g.. [14]).
The participants in the dialogue can have the same
skill level and they can simply work together to
accomplish the task; or one of them, the expert, could
know more and could direct the other, the apprentice,
to perform the task. We have concentrated primarily
on the latter case - due to the protocols that we
examined - but many of our observations can be
generalized to the former case, too. We will refer to
this as the apprentice-expert domain.
The viewpoints of the expert and apprentice differ
greatly in apprentice-expert exchanges. The expert,
having an understanding of the functionality of the
elements in the task, has more of a feel for how the
elements work together, how they go together, and how
the individual elements can be used. The apprentice
normally has no such knowledge and must base his
decisions on perceptual features such as shape [15].
The structure of the task affects the structure of
the dialogue [14]. particularly through the center of
attention of the expert and apprentice. This is the
phenomenon called focus [14. 20, 24]. which, in task-
oriented dialogues is a very real and operational thing
(e.g., focus is used in resolving anaphoric references).
Shifts in focus correspond directly to the task. its
subtasks. the objects in a task and the subpleces of
each object Focus and focus shifts are governed by
many rules [14. 20, 24] Confusion may result when
expected shifts do not take place. For example, if the
expert changes focus to an object but never discusses
its subpieces (such as an obvious attachment surface)
or never bothers to talk about the object reasonably
soon after its introduction (i.e., between the time of its
introduction and its use, without digressing in a well-
structured way in between (see [20])). then the
apprentice may become confused, leaving him ripe for
miscommunication. The reverse influence between focus
and objects can lead to trouble. too. A shift in focus
by the expert that does not have a manifestation in
the apprentice&apos;s world will also perplex the apprentice.
Focus also influences how descriptions are
formed (15, 2]. The level of detail required in a
description depends directly on the elements currently
highlighted by the focus. If the object to be described
is similar to other elements in focus, the expert must
be more specific in the formulation of the description
or may consider shifting focus away from the possibly
ambiguous objects to one where the ambiguity won t
occur.
</bodyText>
<subsectionHeader confidence="0.999927">
2.2 Consequences of miscommunication
</subsectionHeader>
<bodyText confidence="0.999937285714286">
In this section we will make it clear that people
do miscommunicate and yet they often manage to fix
things. We will look at specific forms of
miscommunication and describe ways to detect them.
We will highlight relationships between different
miscommunication problems but won&apos;t necessarily
demonstrate ways to resolve each of them.
</bodyText>
<page confidence="0.997371">
206
</page>
<subsectionHeader confidence="0.931449">
2.2.1 Instances of miscommunication
</subsectionHeader>
<bodyText confidence="0.995589233333333">
There are many ways hearers can get confused
during a conversation. Figure 2 outlines some of them
that were derived from analyzing the water pump
protocols. This section defines and illustrates many of
them through numerous excerpts. Each excerpt is
marked in parentheses to show what modality of
communication was used (see [9] for a. description
about the collection of these excerpts). Each
bracketed portion of the excerpt explains what was
occurring at that point in the dialogue. The confusions
themselves, coupled with the description at the end of
this section on how to recognize when one of them is
occurring, provides motivation for the use of the
algorithm outlined in Section 3 as a means for
repairing communication problems. We will only discuss
referent confusion in this paper. The other forms of
confusion - Action. Goal, and Cognitive Load - are
described in [11. 13]. Another categorization of
confusions that lead to conversation failure can be
found in [22].
. Figure 2: A taxonomy of confusions
Referent confusion occurs when the listener is
unable to correctly determine what the speaker is
referring to with a particular description. It occurs
when the descriptions in the utterance are ambiguous
or imprecise, when there is confusion between the
speaker and listener about what the current focus or
context is, or when the descriptions in the utterance
are either incorrect or incompatible with the current
or global context.
</bodyText>
<subsectionHeader confidence="0.981174">
Erroneous Specificity
</subsectionHeader>
<bodyText confidence="0.9997004">
Ambiguous (and, thus, imprecise) descriptions can
cause confusion about the referent. Excerpt 2 below
illustrates a case where the speaker&apos;s description is
underspecified - it does not provide enough detail to
prune the set of possible referents down to one.
</bodyText>
<subsectionHeader confidence="0.338059">
Excerpt 2 (Face-to-Face)
</subsectionHeader>
<author confidence="0.258488">
S. 1. And now take the little red
</author>
<sectionHeader confidence="0.740173142857143" genericHeader="method">
2. peg.
[P takes PLUG]
3. Yes.
4. and place it in the hole at the
5. green end.
[P starts to put PLUG into OUTLET2 of MAINT&apos;UBE]
6. no
</sectionHeader>
<bodyText confidence="0.957189461538462">
7. the--in the green thing
[P puts PLUG into green part of PLUNGER]
P: a. Okay.
In Line 4 and 5. S describes the location to place a peg
into a hole by giving spatial information. Since the
location is given relative to another location by &amp;quot;in the
hole at the green end&amp;quot;, it defines a region where the
peg might go instead of a specific location. In this
particular case, there are three possible holes to
choose from that are near the green end. The listener
chooses one - the wrong one - and inserts the peg
into it. Because this dialogue took place face to face,
S is able to correct the ambiguity in Lines 6 and 7.
A speaker&apos;s description can be imprecise in
1 possible ways. (1) It may contain features that
do not readily apply in the domain. In Line 3, Excerpt
3. the feature &amp;quot;funny&amp;quot; has no relevance to the listener.
It is not until A provides a fuller description in Lines 5
to 8 that E is able to select the proper piece. (2) It
may use a vague head noun coupled with few or no
feature values (and context alone does not necessarily
suffice to distinguish the object). In Excerpt 4. Line 9.
&amp;quot;attachment&amp;quot; is vague because all objects in the
domain are attachable parts. The expert&apos;s use of
&amp;quot;attachment&amp;quot; was most likely to signal the action the
apprentice can expect to take next. The use of the
feature value &amp;quot;clear&amp;quot; provides little benefit either
because three clear, unused parts exist. The size
descriptor &amp;quot;little&amp;quot; prunes this set of possible referents
down to two contenders. (3) Enough feature values are
provided but at least one value is too vague leading to
trouble. In Excerpt 5, Line 3. the use of the attribute
value &amp;quot;rounded&amp;quot; to describe the shape does not
sufficiently reduce the set of four possible referents
(though, in this particular instance. A correctly
identifies it) because the term is applicable to
numerous parts in the domain. A more precise shape
descriptor such as &amp;quot;bell-shaped&amp;quot; or &amp;quot;cylindrical&amp;quot; would
have been more beneficial to the listener.
</bodyText>
<subsectionHeader confidence="0.561309">
Excerpt 3 (Telephone)
</subsectionHeader>
<bodyText confidence="0.674639">
E: 1. All right.
</bodyText>
<listItem confidence="0.945944333333333">
2. Now.
3. There&apos;s another funny little
4. red thing. a
</listItem>
<bodyText confidence="0.54674">
[A is confused, examines both NOZZLE and
SLIDEVALVE]
</bodyText>
<listItem confidence="0.946611666666667">
5. little teeny red thing that&apos;s
6. some--should be somewhere on
7. the desk, that has um--there&apos;s
</listItem>
<bodyText confidence="0.909197166666667">
8. like teeth on one end.
[E takes SLIDEVALVE]
A: 9. Okay.
E: 10. It&apos;s a funny-loo-hollow,
11. hollow projection on one end
12. and then teeth on the other.
</bodyText>
<subsectionHeader confidence="0.571477">
Excerpt 4 (Teletype)
</subsectionHeader>
<bodyText confidence="0.907271">
A: 1. take the red thing with the
</bodyText>
<listItem confidence="0.9519878">
2. prongs on it
3. and fit it onto the other hole
4. of the cylinder
5. so that the prongs are
6. sticking out
</listItem>
<figure confidence="0.99720925">
istwsw Cathassa
COOKIM LIM/ COOMIIII
ANN
SiomMINO
.1•11111•111,
_u •■■■•• I
011■IIIMM
AYOr 0.104
taimmatafet, law
&lt;4.1.1.1 0■■•••..
twesoror /Mime
=
</figure>
<page confidence="0.643239">
207
</page>
<figureCaption confidence="0.935513096774194">
R: 7. ok 7. on the cylinder,
[P lays down TUBEBASE]
8. the side hole that is farthest
13. front the green end.
[P puts CAP on OUTLET1 of MAINTUBE]
P: 7. Okay.
S. 8. And take the nozzle-looking
9. piece.
[P grabs NOZZLE]
10. no
A: 8. now take the clear little
9. attachment
10. and put on the hole where you
11. Just put the red cap on
12. make sure it points
13. upward
R: 14. ok
Excerpt 5 (Teletype) 14. I mean the clear plastic one,
[P takes SPOUT]
15. and place it on the other hole
[P identifies OUTLET2 of MAINTUBE]
16. that&apos;s left.
17. so that nozzle points away
18. from the
[P installs SPOUT on OUTLET2 of MAINTUBE]
113. right.
P: 17. Okay.
S. 18. Now
19. take the
20. cap base thing
[P takes TUBEBASE]
</figureCaption>
<bodyText confidence="0.833886433333333">
21. and screw it onto the bottom.
[P screws TUBEBASE on MAINTUBE]
22. 000ps,
[S realizes she has forgotten to have P put
SLIDEVALVE into OUTLET2 of MAINTUBE]
23. un-undo the pies
[P starts to take TUBEBASE off MALNTUBE]
24. no
25. the clear plastic thing that I
26. told you to put on
[P removes SPOUT]
27. sorry.
28. And place the little red thing
(11 takes SLIDEVALVE]
29. in there first.
[P inserts SLIDEVALVE into OUTLET2 of MAINTUBE]
30. It fits loosely in there.
Excerpt 7 below demonstrates the latter type of
focus confusion that occurs when the speaker (S) sets
up one focus - the MAINTUBE, which is the correct
focus in this case - but then proceeds in such a
manner that the listener (J) thinks a focus shift to
another piece. the TUBEBASE. has occurred. Thus.
Line 15 refers to &amp;quot;the lower side hole in the
MAINTUBE&amp;quot; for S and &amp;quot;the hole in the TUBEBASE&amp;quot; for
J. .1 has no way of realizing that he has focused
incorrectly unless the description as he interprets it
doesn&apos;t have a real world correlate (here something
does satisfy the description so .1 doesn&apos;t sense any
problem) or it. later in the exchange, a conflict arises
</bodyText>
<listItem confidence="0.7723945">
5: 1. Ok.
2. put the red nozzle on the outlet
3. of the rounded clear chamber
4. ok?
</listItem>
<figureCaption confidence="0.927321">
A; 5. got it.
Improper Focus
Focus confusion can occur when the speaker sets
up one focus and then proceeds with another one
without letting the listener know of the switch (i.e.. a
focus shift occurs without any indication). An opposite
phenomenon can also happen - the listener may feel
that a focus shift has taken place when the speaker
actually never intended one. These really are very
similar - one is viewed more strongly from the
perspective of the speaker and the other from the
listener.
Excerpt 6 below illustrates an instance of the
first type of focus confusion. In the excerpt, the
speaker (S) shifts focus without notifying the listener
(P) of the switch. As the excerpt begins. P is holding
the TUBEBASE. S provides in Lines 1 to 16
instructions for P to attach the CAP and the SPOUT to
outlets OUTLET1 and OUTLET2, respectively, on the
MAINTUBE. Upon P&apos;s successful completion of these
attachments. S switches focus in Lines 17 to 20 to the
TUBEBASE assembly and requests P to screw it on to
the bottom of the MAINTUBE. While P completes the
task. S realizes she left out a step in the assembly -
the placement of the SLIDEVALVE into OUTLET2 of the
MAINTUBE before the SPOUT is placed over the same
outlet. S attempts to correct her mistake by
requesting P to remove &amp;quot;the plas&amp;quot;3 piece in Lines 22
and 23. Since S never indicated a shift in focus from
the TUBEBASE back to the SPOUT. P interprets &amp;quot;the
plas&amp;quot; to refer to the TUBEBASE.
Excerpt 8 (Face-to-Face)
S. 1. And place
2. the blue cap that&apos;s left
DI&apos; takes CAP]
3. on the side holes that are
3The whole word here is &amp;quot;plastic.&amp;quot; People in general
tend to be good at proceeding before hearing the whole
utterance or even the whole word.
</figureCaption>
<bodyText confidence="0.999949875">
due to the mistake (e.g., a requested action can not be
performed). In Line 31, J inserts a piece into the
wrong hole because of the misunderstanding in Line 15.
Line 31 hints that J may have become suspicious that
an ambiguity existed but since the task was
successfully completed (i.e., the red piece fit into the
hole in the base), and since S did not provide any
clarification. he assumed he was correct.
</bodyText>
<figure confidence="0.811670833333334">
Excerpt 7 (Telephone)
S: 1. Um now.
2. Now we&apos;re getting a little
3. more difficult.
3: 4. (laughs)
S: 5. Pick out the large air tube
El picks up STAND]
8. that has the plunger in it.
puts down STAND. takes PLUNGER/MAINTUBE
assembly]
.1: 7. Okay.
S. 8. And set it on its base.
El puts down MAINTUBE, standing vertically, on the
TABLE]
9. which is blue now,
10. right?
[3 has shifted focus to the TUBEBASE]
J: 11. Yeah.
S. 12. Base is blue.
13. Okay.
14. Now
15. You&apos;ve got a bottom hole still
16. to be filled,
17. correct?
</figure>
<bodyText confidence="0.844092414634146">
J: 18. Yeah.
[J answers this with MAINTUBE still sitting on the
TABLE; he shows no indication of what
hole he thinks is meant - the one on
the MAINTUBE, OUTLETS, or the one in
the TUBEBASE]
S. 19. Okay.
20. You have one red piece
21. remaining?
picks up MAINTUBE assembly and looks at
TUBEBASE, rotating the MAINTUBE so
that TUBEBASE is pointed up, and
sees the hole in it; he then looks at
the SLIDEVALVEI
J. 22. Yeah.
S. 23. Okay.
24. Take that red piece.
[3 takes SLIDEVALVE]
25. It&apos;s got four little feet on
28. it?
J: 27. Yeah.
3: 28. And put the small end into
29. that hole on the air tube--
30. on the big tube.
J: 31. On the very bottom?
[3 starts to put it into the bottom hole of
TUBEBASE - though he indicates he is
unsure of himself]
S: 32. On the bottom,
33. Yes.
Misfocus can also occur when the speaker
inadvertently fails to distinguish the proper focus
because he did not notice a possible ambiguity; or
when, through no fault of the speaker, the listener just
fails to recognize a switch in focus indicated by the
speaker. Excerpt 7 above is an example of the first
type because S failed to notice that an ambiguity
existed since he never explicitly brought the TUBEBASE
either into or out of focus. He just assumed that J
had the same perspective as him - a perspective in
which no ambiguity occurred.
</bodyText>
<subsectionHeader confidence="0.902188">
Wrong Context
</subsectionHeader>
<bodyText confidence="0.998544862068966">
Context differs from focus. The context of a
portion of a conversation is concerned with the point
of the discussion in that fragment and with the set of
objects relevant to that discussion. though not
attended to currently. Focus pertains to the elements
which are currently being attended to in the context.
For example, two people can share the same context
but have different focus assignments within it - were
both talking about the water pump but you&apos;re
describing the MAINTUBE and I&apos;m describing the
AIRCHAMBER. Alternatively, we could just be using
different contexts - I think you&apos;re talking about taking
the pump apart but you&apos;re talking about replienng the
pump with new parts - in both cases we m,..y be
sharing the same focus - the pump - but our conte....s
are totally off from one another.4 The kinds of
misunderstandings that can occur because of context
problems are similar to those for focus problems: (1)
the speaker might set up or be in one context for a
discussion and then proceed in another one without
effectively letting the listener know of the change, (2)
the listener may feel a change in context has taken
place when in fact the speaker never intended one, or
(3) the listener fails to recognize an indicated context
switch by the speaker. Context affects reference
because it helps define the set of available objects that
are possible contenders for the referent of the
speaker&apos;s descriptions. If the contexts of the speaker
and listener differ, then misreference might result.
</bodyText>
<subsectionHeader confidence="0.976177">
Bad Analogy
</subsectionHeader>
<bodyText confidence="0.9999503">
An analogy (see (10] for a discussion on
analogies) is a useful way to help describe an object by
attempting to be more precise by using shared past
experience and knowledge - especially shape and
functional information. If that past experience or
knowledge doesn&apos;t contain the information the speaker
assumes it does or isn&apos;t there, then trouble occurs.
Thus, one more way referent confusion can occur is by
describing an object using a poor analogy. An analogy
used to describe an object might not be specific
</bodyText>
<footnote confidence="0.424794666666667">
4Grosz (14. 15) would describe this as a difference in
&apos;tosk plans&apos; while Reichmen (20. 21) would soy that the
&amp;quot;communicative podia differed.
</footnote>
<bodyText confidence="0.998811333333333">
enough — confusing the listener because several pieces
might conform to the analogy or. in fact, none at all
appear to fit because discovering a mapping between
the analogous object and some piece in the
environment is too difficult. In Excerpt 8. .1 at first
has trouble correctly satisfying As functional analogy
&amp;quot;stopper&amp;quot; in &amp;quot;the big blue stopper&amp;quot;, but finally selects
what he considers to be the closest match to
&amp;quot;stopper&amp;quot;.
</bodyText>
<subsectionHeader confidence="0.347176">
Excerpt 8 (Telephone)
</subsectionHeader>
<bodyText confidence="0.476808">
A: 1. Okay. Now,
</bodyText>
<listItem confidence="0.759866090909091">
2. take the big blue
3. stopper that&apos;s laying around
P grabs AIRCHAMBER]
4. .. and take the black
5. ring--
J. 6. The big blue stopper?
(.1 is confused and tries to communicate it to A: he
is holding the AINCHAMBER here)
A. 7 Yeah.
8. the big blue stopper
9. and the black ring
</listItem>
<bodyText confidence="0.969503185185185">
[J drops AIRCHAMBER and takes the 0—RING and
the TUBEBASEj
In other cases it might be too specific —
confusing the listener because none of the available
referents appear to fit it. In Line 8 of Excerpt 8.
&amp;quot;nozzle—looking&amp;quot; forms a poor shape analogy because
the object being referred to actually is an elbow—
shaped spout. The &amp;quot;nozzle—looking&amp;quot; part of the
description convinced the listener that what he was
looking for was something specific like a nozzle (which
is a small spout). Sometimes, when an object is a clear
representative of a specified analogy class, the
apprentice may become confused, wondering why the
expert bothered to form an analogy instead of just
directly describing the object as a member of the class.
Hence, it would not be surprising if the apprentice
ignored the best representative of the class for some
less obvious exemplar. Thus, for example, it is better to
say &amp;quot;nozzle&amp;quot; instead of &amp;quot;nozzle—looking.&amp;quot; In Excerpt 9,
the description &amp;quot;hippopotamus face shape&amp;quot; (a shape
analogy) in Lines 2 and 3. and &amp;quot;champagne top&amp;quot; (a
shape analogy) in Line 9. are too specific and the
listener is unable to easily find something close enough
to match either of them. He can&apos;t discover a mapping
between the object in the analogy and one in the real
world.
Excerpt 9 (Audiotape)
</bodyText>
<listItem confidence="0.857453461538461">
14: 1. take the bright pink flat
2. piece of hippopotamus face
3. shape piece of plastic
4. and you notice that the two
5. holes on it
is trying to refer to BASEVALVE]
6. match
7. along with the two
8. peg holes on the
9. champagne top sort of
10. looking bottom that had
11. threads on it
N is trying to refer to TUBEBASEj
</listItem>
<sectionHeader confidence="0.353543" genericHeader="method">
Description Incompatibility
</sectionHeader>
<bodyText confidence="0.99971">
Incompatible descriptions can lead to confusion
also. A description is incompatible when (1) one or
more of the specified conditions, i.e., the feature
values, do not satisfy nu of the pieces; (2) when one
or more specified constraints do not hold (e.g., saying
&amp;quot;the loose one&amp;quot; when all objects are tightly attached),
or (37-11— no one object satisfies all of the features
specified in the description. In Lines 7 and 8 of
Excerpt 9 above. les use of &amp;quot;the two peg holes&amp;quot; leads
to bewilderment for the listener because the described
object has no holes in it. /4 actually meant &amp;quot;two pegs&amp;quot;.
</bodyText>
<subsubsectionHeader confidence="0.68294">
2.2.2 Detecting miscommunication
</subsubsectionHeader>
<bodyText confidence="0.999726142857143">
Part of our research has been to examine how a
listener discovers the need for a repair of an
utterance or a description during communication. The
incompatibility of a referent or action is one signal of
possible trouble. The appearance of an obstacle that
blocks one from achieving a goal is another indication
of a problem.
</bodyText>
<sectionHeader confidence="0.445736" genericHeader="method">
Incompatibility
</sectionHeader>
<bodyText confidence="0.999962454545455">
Two kinds of incompatibility, action or referent.
appear in the taxonomy of confusions. The strongest
hint that there is a reference problem occurs when the
listener finds no real world object to correspond to the
speaker&apos;s description. This can occur when (1) one or
more of the specified feature values in the description
are not satisfied by au of the pieces (e.g saying &amp;quot;the
orange cap&amp;quot; when none of the objects are orange), (2)
when one or more specified constraints do not hold
(e.g.. saying &amp;quot;the red plug that fits loosely&amp;quot; when all
the red plugs attach tightly), or (3) if no one object
satisfies all of the features specified in the description
(i.e.. there is, for each feature, an object that exhibits
the specified feature value, but no one object exhibits
all of the values). An action problem is likely if (1) the
listener cannot perform the action specified by the
speaker because of some obstacle; (2) the listener
performs the action but does not arrive at its intended
effect (i.e.. a specified or default constraint isn&apos;t
satisfied); or (3) the current action affects a previous
action in an adverse way, yet the speaker has given no
sign of any importance to this side—effect.
</bodyText>
<subsectionHeader confidence="0.821718">
Goal obstacle
</subsectionHeader>
<bodyText confidence="0.99818">
A goal obstacle occurs when a goal (or subgoal)
one is trying to achieve is blocked. This blockage can
result in confusion for the listener because he did not
expect the speaker to give him tasks that could not be
achieved. Often, though, it points out for the listener
that some miscommunication (such as misreference) has
occurred.
</bodyText>
<subsectionHeader confidence="0.801558">
Goal redundancy
</subsectionHeader>
<bodyText confidence="0.9997295">
Goal redundancy occurs when the requested goal
(or subgoal) is already satisfied. In some sense, it is a
special kind of goal obstacle where the goal to be
fulfilled is blocked because it is already satisfied. It is
a simple goal obstacle because nothing has to be done
to get around it. However, it can lead to confusion on
</bodyText>
<page confidence="0.991122">
210
</page>
<bodyText confidence="0.999086">
the part of listeners because they may suspect they
misunderstood what the speaker has requested since
they wouldn&apos;t expect a reasonable speaker to request
the performance of an already completed action. It
provides a hint that miscommunication has occurred.
</bodyText>
<sectionHeader confidence="0.952115" genericHeader="method">
3 Repairing Reference Failures
</sectionHeader>
<subsectionHeader confidence="0.978498">
3.1 Introduction
</subsectionHeader>
<bodyText confidence="0.968335666666666">
The previous section illustrated how task-
oriented natural language interactions in the real
world can induce contextually poor utterances. Given
all the possibilities for confusion, when confusions do
occur, they must be resolved if the task is to be
performed. This section explores the problem of fixing
reference failures.
Reference identification is a search process where
a listener looks for something in the world that
satisfies a speaker&apos;s uttered description. A
computational scheme for performing reference has
evolved from work by other artificial intelligence
researchers (e.g.. see [14]). That traditional approach
succeeds if a referent is found, or fails if no referent
is found (see Figure 3(a)). However, a reference
identification component must be more versatile than
those constructed in the traditional manner. The
excerpts provided in the previous section show that
the traditional approach is wrong because people&apos;s real
behavior is much more elaborate. In particular.
listeners often find the correct referent even when the
speaker&apos;s description does not describe any object in
the world. For example, a speaker could describe a
blue block as the &amp;quot;turquoise block.&amp;quot; Most listeners
would go ahead and assume that the blue block was the
one the speaker meant.
A key feature to reference identification is
&amp;quot;negotiation.&amp;quot; Negotiation in reference identification
comes in two forms. First, it can occur between the
listener and the speaker. The listener can step back,
expand greatly on the speaker&apos;s description of a
plausible referent, and ask for confirmation that he
has indeed found the correct referent. For example, a
listener could initiate negotiation with &amp;quot;I&apos;m confused.
Are you talking about the thing that is kind of flared
at the top? Couple inches long. It&apos;s kind of blue.&amp;quot;
Second. negotiation can be with oneself. This type of
negotiation, called self-negotiation, is the one that we
are most concerned with in this research. The listener
considers aspects of the speaker&apos;s description, the
context of the communication, and the listener&apos;s own
abilities. He then applies that deliberation to determine
whether one referent candidate is better than another
or. if no candidate is found, what are the most likely
places for error or confusion. Such negotiation can
result in the listener testing whetner or not a
particular referent works. For example, linguistic
descriptions can influence a listener&apos;s perception of
the world. The listener must ask himself whether he
can perceive one of the objects in the world the way
the speaker described it. In some cases, the listener&apos;s
perception may overrule the description because the
listener can&apos;t perceive It the way the speaker
described It.
To repair the traditional approach we have
developed an algorithm that captures for certain cases
the listener&apos;s ability to negotiate with himself for a
referent. It can look for a referent and, if it doesn&apos;t
find one, it can try to find possible referent candidates
that might work, and then loosen the speaker&apos;s
description using knowledge about the speaker, the
conversation, and the listener himself. Thus, the
reference process becomes multi-step and resumable.
This computational model, which I call &amp;quot;FWIM&amp;quot; for &amp;quot;Find
What I Mean&amp;quot;, is more faithful to the data than the
traditional model (see Figure 3(b)).
</bodyText>
<figure confidence="0.992046666666667">
Current
Reference 55
Component
Vmdure
fnaurf
(a) Traditional (0) rwim
</figure>
<figureCaption confidence="0.999943">
Figure 3: Approaches to reference identification
</figureCaption>
<bodyText confidence="0.9993055625">
One means of making sense of an approximate
description is to delete or replace portions of It that
don&apos;t match objects in the hearer&apos;s world. In our
program we are using &amp;quot;relaxation&amp;quot; techniques to
capture this behavior. Our reference identification
module treats descriptions as approximate. It relaxes
a description in order to find a referent when the
literal content of the description fails to provide the
needed information. Relaxation, however, is not
performed blindly on the description. We try to model
a person&apos;s behavior by drawing on sources of
knowledge used by people. We have developed a
computational model that can relax aspects of a
description using many of these sources of knowledge.
Relaxation then becomes a form of communication
repair [4] that hearers can use.
</bodyText>
<subsectionHeader confidence="0.999861">
3.2 The relaxation component
</subsectionHeader>
<bodyText confidence="0.998432333333333">
When a description fails to denote a referent in
the real world properly, it is possible to repair It by a
relaxation process that ignores or modifies parts of the
description. Since a description can specify many
features of an object, the order in which parts of it
are relaxed is crucial (i.e.. relaxing in different orders
could yield matches to different objects) There are
several kinds of relaxation possible. One can Ignore a
constituent, replace it with something close, replace it
with a related value, or change focus (i.e.. consider a
different group of objects.). This section describes the
overall relaxation component that draws on knowledge
sources about descriptions and the real world as it
tries to relax an errorful description to one for which
a referent can be identified.
</bodyText>
<subsectionHeader confidence="0.956201">
3.2.1 Find a referent using a reference mechanism
</subsectionHeader>
<bodyText confidence="0.997944">
Identifying the referent of a description requires
finding an element in the world that corresponds to the
speaker&apos;s description (where every feature specified in
the description is present in the element in the world
but not necessarily vice versa). The initial task of our
</bodyText>
<figure confidence="0.992613571428571">
\
Current
Reference
Component
Fail..,.
Relaxation
Component 11.-irt,
</figure>
<page confidence="0.997808">
211
</page>
<bodyText confidence="0.997708114285714">
reference mechanism is to determine whether or not a
search of the (taxonomic) knowledge base that we use
to model the world is necessary. For example, the
reference component should not bother searching -
unless specifically requested to do so - for a referent
for indefinite noun phrases (which usually describe new
or hypothetical objects) or extremely vague
descriptions (which do not clearly describe an object
because they are composed of imprecise feature
values). A number of aspects of discourse pragmatics
can be used in that determination (e.g.. the use of a
deictic in a definite noun phrase, such as &amp;quot;this X&amp;quot; or
&amp;quot;the last X&amp;quot;, hints that the object was either mentioned
previously or that it probably was evoked by some
previous reference, and that it is searchable) but we
will not examine them here.
The knowledge base contains linguistic
descriptions and a description of the listener&apos;s visual
scene itself. In our implementation and algorithms, we
assume It is represented in KL-One (3], a system for
describing taxonomic knowledge. KL-One is composed
of CONCEPTs. ROLEs on concepts. and links between
them. A CONCEPT is like a set, representing those
elements described by it. A SUPERC link (&amp;quot;==&gt;&amp;quot;) is
used between concepts to show set inclusion. For
example. consider Figure 3. The SuperC from Concept B
to Concept A is like stating BCA for two sets A and
B. An INDIVIDUAL CONCEPT is used to guarantee that the
subset specified by a concept is unique. The Individual
Concept D shown in the figure is defined to be a
unique member of the subset specified by Concept
C. ROLEs on concepts are like normal attributes and
slot fillers in other knowledge representation
languages. They define a functional relationship
between the concept and other concepts.
</bodyText>
<figure confidence="0.9004545">
Individual
Concept
</figure>
<figureCaption confidence="0.999958">
Figure 4: A KL-One Taxonomy
</figureCaption>
<bodyText confidence="0.995049157894737">
Assuming that a search of the knowledge base is
considered necessary, then a reference search
mechanism is Invoked. The search mechanism uses the
KL-One Classifier (16] to search the knowledge base
taxonomy. This search is constrained by a focus
mechanism based on the one developed by Grosz (14].
&amp;quot;he Classifiers purpose is to discover all appropriate
subsumption relationships between a newly formed
description and an other descriptions in a given
taxonomy. With respect to reference, this means that
an possible (descriptions of) referents of the
description will be subsumed by it after It has been
classdied into the knowledge base taxonomy. U more
than one candidate referent is below (when a
description A is subsumed by B. we say A is &amp;quot;below&amp;quot; B)
the classified description, then, unless a quantifier in
the description specified more than one element, the
speaker&apos;s description is ambiguous. If exactly one
description is below it. then the intended referent is
assumed to have been hound. Finally, if no referent is
found below the classified description, the relaxation
component is invoked. We will only consider the last
case in the rest of the paper.
12.2 Collect votes for or against relaxing the
description
It is necessary to determine whether or not the
lack of a referent for a description has to do with the
description itself (i.e.. reference failure) or outside
forces that are causing reference confusion. For
example, the problem may be with the flow of the
conversation and the speaker&apos;s and listener&apos;s
perspectives on it; it may be due to Incorrect
attachment of a modifier: it may be due to the action
requested; and so on. Pragmatic rules are invoked to
decide whether or not the description should be
relaxed. These rules will not be discussed here so we
will assume that the problem lies in the speaker&apos;s
description.
</bodyText>
<subsectionHeader confidence="0.582182">
3.2.3 Perform the relaxation of the description
</subsectionHeader>
<bodyText confidence="0.999769625">
If relaxation is demanded, then the system must
(1) find potential referent candidates. (21 determine
which features in the speaker&apos;s description to relax
and in what order, and use those ordered features to
order the potential candidates with respect to the
preferred ordering of features. and (31 determine the
proper relaxation techniques to use and apply them to
the description.
</bodyText>
<subsectionHeader confidence="0.830686">
Find potential referent candidates
</subsectionHeader>
<bodyText confidence="0.99980095">
Before relaxation can take place. potential
candidates for referents (which denote elements in the
listener&apos;s visual scene) must first be found. These
candidates are discovered by performing a &amp;quot;walk&amp;quot; in
the knowledge base taxonomy in the general vicinity of
the speaker&apos;s classified description. A KL-One partial
matcher is used to determine how close the candidate
descriptions found during the walk are to the speaker&apos;s
description. The partial matcher generates a numerical
score to represent how well the descriptions match
(after first generating scores at the feature level to
help determine how the features are to be aligned and
how well they match). This score is based on
information about KL-One and does not take into
account any information about the task domain. The
ordering of features and candidates for relaxation
described below takes into account the task domain.
The set of best descriptions returned by the matcher
(as determined by some cutoff score) are selected as
referent candidates.
</bodyText>
<subsectionHeader confidence="0.844119">
Order the features and candidates for relaxation
</subsectionHeader>
<bodyText confidence="0.9989883">
At this point the reference system inspects the
speaker&apos;s description and the candidates, decides which
features to relax and in what order.5 and generates a
master ordering of features for relaxation. Once the
feature order is created, the reference system uses
Of course, ones one particular candidate is selected,
then deciding which features to relax is relatively trivial
- one simply compares feature by feature between the
candidate description (the target) and the speaker&apos;s
description (the pattern) and notes any discrepancies.
</bodyText>
<page confidence="0.996034">
212
</page>
<bodyText confidence="0.998752404761905">
that ordering to determine the order in which to try
relaxing the candidates.
We draw primarily on sources of linguistic
knowledge, pragmatic knowledge, discourse knowledge.
domain knowledge, perceptual knowledge, hierarchical
knowledge, and trial and error knowledge during this
repair process. A detailed treatment of all of them can
be found in [12, 27, 13]. These knowledge sources are
consulted to determine the feature ordering for
relaxation. We represent information from each
knowledge source as a set of relaxation rules. These
rules are written in a PROLOG—like language. Figure 5
illustrates one such linguistic knowledge relaxation
rule. This rule is motivated by the observation in the
excerpts that speakers typically add more important
information at the end of a description (where they are
separated from the main part of the description and
thus provided more emphasis). Since the syntactic
constituents often at the end are relative clauses or
predicate complements, we created this more specific
relaxation rule. However, a more general and more
applicable rule is that information presented at the
end of a description is usually more prominent.
Relax the features in the speaker&apos;s description in the
order: adjectives, then prepositional phrases, and
finally relative clauses and predicate complements.
each box correspond to the set of features that
describe that object. The speaker&apos;s description is
represented in the center of the figure. The set of
specified features and their assigned feature value
(e.g., the pair Color—Maroon) are also shown there. A
set of partial orderings are generated that suggest
which features in the speaker&apos;s description should be
relaxed first — one ordering for each knowledge source
(shown as &amp;quot;Linguistic.&amp;quot; &amp;quot;Perceptual,&amp;quot; and &amp;quot;Hierarchical&amp;quot;
in the figure). These are put together to form a
directed graph that represents the possible, reasonable
ways to relax the features specified in the speaker&apos;s
description. Finally, the referent candidates are
reordered using the information expressed in the
speaker&apos;s description and in the directed graph of
features.
</bodyText>
<subsectionHeader confidence="0.741696">
Peslial adoring of foaitoor
</subsectionHeader>
<figure confidence="0.797725925925926">
Ifroadlike &amp;noes.
PerGeOtudbi
b -/ Linguistic
c niorarchitol
=2;11incier
TPlastIC
•
bad Waft&apos; C1 C&apos;.
&apos;Worn I, II or ft VI
I -0 Color ft f3 ft or 13 or F.
ft Shoo. 13 fa
ft -1 Function fa
I. Sit•
E.g..
Relax —Feature—Elefore(yl.v2)
&lt;— ObjectOescr(d).
FeatureOescriptor(y1),
FecitureOescriptor(v2).
FeatureinOescription(yl.d).
FeaturelnDescription(v2.d).
Equal(syntactic—form(vl.d).&amp;quot;k0J&amp;quot;).
Equal(syntoctic—form(y2.d).&amp;quot;REL—CLS&amp;quot;)
&apos;VW intoohoi -Cal or-naroon
man. Cavaco 3paallae, .-Shao•-nocavdoci
Mot 41 large Dosett000n -0•%,nc1 ion-bootee
■SI co-Largo
Oinel&amp;Ignifat of *tufts jot Illesatan
</figure>
<figureCaption confidence="0.997064">
Figure 5: A sample relaxation rule Ci
</figureCaption>
<bodyText confidence="0.99892703125">
Each knowledge source produces its own partial
ordering of features. The partial orderings are then
integrated to form a directed graph. For example.
perceptual knowledge may say to relax color. However.
if the color value was asserted in a relative clause,
linguistic knowledge would rank color lower. i.e..
placing it later in the list of things to relax.
Since different knowledge sources generally have
different partial orderings of features, these
differences can lead to a conflict over which features
to relax. It is the job of the best candidate algorithm
to resolve the disagreements among knowledge sources.
It&apos;s goal is to order the referent candidates. C. so
that relaxation is attempted on the best candidates
first. Those candidates are the ones that conform best
to a proposed feature ordering. To start, the algorithm
examines pairs of candidates and the feature orderings
from each knowledge source. For each candidate C.
the algorithm scores the effect of relaxing the
speaker&apos;s original description to Ci, using the feature
ordering from one knowledge source. The score
reflects the goal of minimizing the number of features
relaxed while trying to relax the features that are
&amp;quot;earliest&amp;quot; in the feature ordering. It repeats its
scoring of Ci for each knowledge source, and sums up
its scores to form Cs total score. The C i&apos;s are then
ordered by that score.
Figure 8 provides a graphic description of this
process. A set of objects in the real world are
selected by the partial matcher as potential candidates
for the referent. These candidates are shown across
the top of the figure. The lines on the right side of
</bodyText>
<figureCaption confidence="0.994575">
Figure 8: Reordering referent candidates
</figureCaption>
<bodyText confidence="0.979461666666666">
Once a set of ordered, potential candidates are
selected, the relaxation mechanism begins step 3 of
relaxation, it tries to find proper relaxation methods to
relax the features that have just been ordered ■success
in finding such methods &amp;quot;justifies&amp;quot; relaxing the
description). It stops at the first candidate which is
reasonable.
Determine which relaxation methods to apply
Relaxation can take place with many aspects of a
speaker&apos;s description: with complex relations specified
in the description, with individual features of a
referent specified by the description. and with the
focus of attention in the real world where one attempts
to find a match. Complex relations specified in a
speaker&apos;s description include spatial relations (e.g..
&amp;quot;the outlet near the top of the tube&amp;quot;). comparatives
(e.g.. &amp;quot;the larger tube&amp;quot;) and superlatives (e.g.. &amp;quot;the
longest tube&amp;quot;). These can be relaxed. The simpler
features of an object (such as size or color) that are
specified in the speaker&apos;s description are also open to
relaxation.
Often the objects in focus in the real world
implicitly cause other objects to be in focus [14. 28].
The subparts of an object in focus, for example, are
reasonable candidates for the referent of a failing
description and should be checked. At other times, the
speaker might attribute features of a subpart of an
</bodyText>
<page confidence="0.99802">
213
</page>
<bodyText confidence="0.984005115384615">
object to the whole object (e.g.. describing a plunger
that is composed of a red handle, a metal rod, a blue
cap, and a green cup as &amp;quot;the green plunger&amp;quot;). In
these cases, the relaxation mechanism utilizes the
part-whole relation in object descriptions to suggest a
way to relax the speaker&apos;s description.
Relaxation of a description has a few global
strategies that can be followed for each part of the
description: (1) drop the errorful feature value from
the description altogether. (2) weaken or tighten the
feature value but keep its new value close to the
specified one, or (3) try some other feature value.
These strategies are realized through a set of
procedures (or relaxation methods) that are organized
hierarchically. Each procedure is an expert at relaxing
its particular type of feature. For example, a
Generate-Similar-Feature-Values procedure IS
composed of procedures like Generate-Similar-Shape-
Values. Generate-Similar-Color-Values and Generate-
Similar-Size-Values. Each of those procedures are
specialists that attempt to first relax the feature value
to one &amp;quot;near&amp;quot; the current one (e.g.. one would prefer
to first relax the color &amp;quot;red&amp;quot; to &amp;quot;pink&amp;quot; before relaxing
it to &amp;quot;blue&amp;quot;) and then, if that fails, to try relaxing it
to any of the other possible values. If those fail, the
feature would simply be ignored.
</bodyText>
<subsectionHeader confidence="0.999509">
3.3 An example on handling a misreference
</subsectionHeader>
<bodyText confidence="0.997357695652174">
This section describes how a referent
identification system can handle a misreference using
the scheme outlined in the previous section. For the
purposes of this example, assume that the water pump
objects currently in focus include the CAP. the
MAINTUBE. the AIRCHAMBER and the STAND (see Figure
1(a) for a picture of these parts). Assume also that
the speaker tries to describe two of the objects.
&amp;quot; . two devices that are clear plastic. One of them has
two openings on the outside with threads on the end.
and its about five inches long. The other one is a
rounded piece with a turquoise base on it. Both are
tubular. The rounded piece fits loosely over...&amp;quot;. The
reference system can find a unique referent for the
first object but not for the second. The relaxation
algorithm will be shown below to reduce the set of
referent candidates for the second description down to
two. It, then, requires the system/listener to try out
those candidates to determine if one, or both, fits
loosely. The protocols exhibit a similar result when the
Listener uses &amp;quot;fits loosely&amp;quot; to get the correct referent
(e g.. Excerpt 6 exemplifies where the &amp;quot;fit&amp;quot; can confirm
that the proper referent was found).
</bodyText>
<figureCaption confidence="0.71917375">
Figure 7 provides a simplified and linearized view
of the actual KL-One representation of the speaker&apos;s
descriptions after they have been parsed and
semantically interpreted. A representation of each of
</figureCaption>
<bodyText confidence="0.961057545454545">
the water pump objects that are currently under
consideration is presented in Figure 8. Each provides a
physical description of the object - in terms of its
dimensions, the basic 3-0 shapes composing it, and its
physical features - and a basic functional description
of the object. The first entry in each representation
In Figure 8 (that entry is shown in uppercase) defines
the basic kind of entity being described (e.g.. &amp;quot;TUBE&amp;quot;
means that the object being described is some kind of
tube). The words in mixed case refer to the names of
features and the words in uppercase refer to possible
fillers of those features from things in the water pump
world. The &amp;quot;Subpart&amp;quot; feature provides a place for an
embedded description of an object that is a subpart of
a parent object. Such subparts can be referred to on
their own or as part of the parent object. The
&amp;quot;Orientation&amp;quot; feature, used in the representations in
Figure 8. provides a rotation and translation of the
object from some standard orientation to the object&apos;s
current orientation in 3-0 space. The standard
orientation provides a way to define relative positions
such as &amp;quot;top,&amp;quot; &amp;quot;bottom,&amp;quot; or &amp;quot;side.&amp;quot;
</bodyText>
<figure confidence="0.936620866666667">
Descrl:
)DEVICE Ii&apos; CLEAR)
oCompassilan PLASTIC)
iSubpert IOPENINGI I
&apos;Subpart (OPENING))
&apos;Subpart ■THREADs (RoI-PaaltIon ENDIII
iEhmenssahs (Length 5.011
(aamleateal-Shape TUBULAR(&apos;
IPIT-INTO (Outer (DEVICE (rearm&apos; ***** v CLEAR)
iCompastt,on PLASTIC(
(Shape ROUND)
Iknaloalcal-ihape TVBULARi
IS 1 &apos;EWE (color TL&apos;RQUOISE(1111
(Inner
IFIICondtlson LOOSE&apos;,
</figure>
<figureCaption confidence="0.999982">
Figure 7: The speaker&apos;s descriptions
</figureCaption>
<bodyText confidence="0.9962409">
The first step in the reference process is the
actual search for a referent in the knowledge base
The reference identification process is incremental in
nature. i.e.. the listener can begin the search process
before he hears the complete description This was
observed throughout the videotape excerpts and the
algorithm presented here is actually designed to be
incremental. The KL-One Classifier compares the
features specified in the speaker&apos;s descriptions (Descr 1
and the &amp;quot;Outer&apos; feature of Descr2 in Figure 71 with the
features specified for each element in the KL -One
taxonomy that corresponds to one of the current
objects of interest in the real world. Notice that some
features are directly comparable. For example. the
&amp;quot;Transparency&amp;quot; feature of Descrl and the
&amp;quot;Transparency&amp;quot; feature of MAINTUBE are both equal to
&amp;quot;CLEAR.&amp;quot; Other features require further processing
before they can be compared. The OPENING value of
&amp;quot;Subpart&amp;quot; in Descrl is thought of primarily as a 2-D
cross-section (such as a &amp;quot;hole&amp;quot;). while two CYLINDER
subparts of MAINTUBE are viewed as 13-D) cylinders
that have the &amp;quot;Function&amp;quot; of being outlets. e.. OUTLET-
ATTACHMENT-POINTS. To compare OPENING and
CYLINDER, the inference must be made that both things
can describe the same thing (similar Inferences are
developed in (181). One way this inference can occur
is by recursively examining the subparts of MAINTUBE
with the partial matcher until the cylinders are
examined at the 2-D level. At that level, an end of the
cylinder will be defined as an OPENING. With that
examination, the MAINTUBE can be seen as described
by Deserl.
Descr2 presents different problems. Descr2 refers
to an object that is supposed to have a subpart that is
TURQUOISE. The Classifier determines that Descr2 could
not describe either the CAP or STAND because both are
BLUE. It also could not describe the MAINTUBE6 or .4IR
CHAMBER since each has subparts that are either
VIOLET or BLUE. The Classifier places Descr2 as best it
can in the taxonomy, showing no connections between
</bodyText>
<footnote confidence="0.9001935">
6S i nee Desert refers to MAINTUBE. MAINTUBE could be
dropped as a potential referent candidate for Descr2. We
will, however, leave it as a potential candidate to make
this example more complex.
</footnote>
<page confidence="0.992195">
214
</page>
<table confidence="0.995134216216216">
(LAP Color FiLLE)
(Composotion PLASTIC)
CAP (Transp o OPAQUE)
ODiernston. a.enetn .291 (Diameter .511
lOrtentalson atotatIon 10.0 0.0 90.011
ITrenslatton 0.0 0.0 0.011))
MAIL (Color VIOLET/
ICompoeltton PLASTIC)
T LEARs
ahmensson. ,Length 4.1251)
(CYLINDER IDImensions ;Length .251 alienator 1.125))
lOrientotion iRotation 0.0 0.0 0.0a
Lip iTransiotion 10.0 0.0 3.75)))
trunctton 0UTLET-ATTACKHENT-POINT111
ISubpert 1CYLINDER 101ms...sloes .Length 3.51 attameger 1.01)
MAIN ThetOody lOriontetton (Rotation 0.0 0.0 0.0)1
TUBE (Translation (0.0 0.0 .29/11))
(Subpart )CYLINDER ahmensions IL .25) 1Diamoter 1.125))
(Orientation IRotation 10.0 0.0 0.011
Threads ITranslotton 10.0 0.0 0.0)))
(runctoon THREADED-ATTACHMENT-POI/all)
I (CYLINDER (Dimension. Itangth .3751 allameter .5))
(Or) ion iRotetion 10.0 0.0 90.0))
00110)) IT lotion 10.0 .5 3.00)))
Ifunction OUTLET-ATTACHMENT-POINT)))
1 (CYLINDER Otmensionv (Length .3751 aliemeter .0))
(Ortentataon 1Rotation 10.0 0.0 90.0))
10.41e42 1 TTTTT lotion 10.0 .5 .6291)
(Function OUTLET-ATTACNMENT-POINT)1))
(CONTAINER 1Dimenstens (LENGTH 2.101)
(Com0o.stion PLASTIC)
1Subport INEMISPMERt 1Color VIOLET)
IT LEAR1
Chem**, alimenstons (Diameter 1.011
lop 10oientetson tRotation 0.0 0.0 0.011
trranstatton i0.0 0.0 2..25111)1
(Subpart (CYLINDER iColor VIOLET)
I TTTTTTTTT nso CLEAR)
Chem., (Dimensions a.ength 1.01 (Diameter 2.251)
Body lOrientatien atotetton 10.0 0.0 0.01)
(Translation 0.0 0.0 .375)1)11
(Subpert (CYLINDER (Color BLUE)
IT TTTTTTTTT cy OPAQUE)
(Dimension. a-teeth .3TS) 1Diamater 1.291)
AIR (Orientation (Rotation 10.0 0.0 0.0)1
CHAMBER Chemaeo (Trensletton 10.0 0.0 0.0))1
Ele1com Irunction CAP OU1&apos;LET-ATTACHMENT-POINT1
(Subport tCYLINDER (Color BLUE)
Oinenslons iLen(10-.375)
(Dtemeter .9))
(Or, Ion
tRotetion 10.0 0.0 0.0)1
1TransiatIon 10.0 0.0 0.01/)
(Function
OUTLET-ATTACHMENT-POINT) ) 1 ))
IS 1CYLINDER (Color VIOLET)
IT LEAR1
Chmmeer (Dinen.tons a.ensth .51 Oiameter .37511
Gullet (Ort ion (Rotation 10.0 0.0 00.0))
(Transietton 1.620 .029 .62911)
(Function OUTLET-ATTACHMENT-POI/all&amp;quot;
:TUBE .binensiont (Lens&amp;quot;) 2.73))
aonpositton PLAiT1C)
(Suoper) ICYLINDER tColor BLUE)
iTronsperency CLEAR)
Top 1lLmensions 1Length 2.20) (Diameter .3731)
lOrlentetson iRotstion 10.0 0.0 0.0))
STAND IT00001atton 14 0.0 .375)))
trunction OUTLET-ATTACHMENT-POINTI),
1Subpart (CYLINDER tColor BLUE)
(Trees!) TTTTT y CLEAR)
Oast iLonete .3751 telemeter 1.011
lOreentation Iliototion 0.0 0.0 0.011
ITrenslolion 10.0 0.0 0.01))
</table>
<sectionHeader confidence="0.494826" genericHeader="method">
Irunetton OUTLET-ATTACHMENT-POINTWI
</sectionHeader>
<figureCaption confidence="0.998518">
Figure 8: The objects in focus
</figureCaption>
<bodyText confidence="0.99983975">
it and any of the objects currently in focus. At this
point, a probable misreference is noted. The reference
mechanism now tries to find potential referent
candidates, using the taxonomy exploration routine
described in Section 3.2.3. by examining the elements
closest to Descr2 in the taxonomy and using the partial
matcher to score how close each element is to Descr2.7
The matcher determines MAINTUBE. STAND, and AIR
</bodyText>
<footnote confidence="0.5235745">
7The partial matcher scores are numerical scores computed
from a set of role scores that indicate how well each
</footnote>
<bodyText confidence="0.895747095238095">
feature of the two descriptions match. Those feature
scores are represented as a scale: HIGHEST 1+1, I&gt; &lt;I.
Iwi. PI, 4-1 LOWEST.
CHAMBER as reasonable candidates by aligning and
comparing their features to Descr2.
Scoring Descr2 to MAINTUBE.
o a TUBE is a kind of DEVICE, (&gt;)
o the Transparency of each is CLEAR. (,-)
o the Composition of each is PLASTIC. (+)
o a TUBE implies Analogical-Shape TUBULAR.
which implies Shape CYLINDRICAL. which is a
kind of Shape ROUND: (&gt;)
o the recursive partial matching of subparts: A
BASE is viewed as a kind of BOTTOM.
Therefore. BASE in Descr2 could match to the
subpart in MAINTUBE that has a Translation
of (0.0 0.0 0.0) - i.e., Threads of MAINTUBE.
However, they mismatch since color
TURQUOISE in Descr2 differs from color VIOLET
of MAINTUBE. (-)
Scoring Descr2 to STAND:
</bodyText>
<listItem confidence="0.748605833333333">
o a TUBE is a kind of DEVICE, (&gt;)
o the Transparency of each is CLEAR.
o the Composition of each is PLASTIC.
o a TUBE implies Analogical-Shape TUBULAR.
which implies Shape CYLINDRICAL. which is a
kind of Shape ROUND; (&gt;)
</listItem>
<bodyText confidence="0.907899774193548">
o the recursive partial matching of subparts.
BASE in Descr2 could match to the subpart in
STAND that has a Translation of 40.0 0.0 0.0)
- i.e.. Base of STAND. However. they
mismatch since color TURQUOISE in Descr2
differs from color BLUE of STAND (-)
Scoring Descr2 to AIR CHAMBER:
o a CONTAINER is a kind of DEVICE. I&gt;)
o the Transparency of Descr2. CLEAR. matches
the Transparency of Chamberrop.
ChamberOutlet and ChamberBody of .4IR
CHAMBER but mismatches the Transparency
of ChamberBottom of AIR CHAMBER
Therefore, the partial match is uncertain, (&apos;)
o the Composition of each is PLASTIC, (+)
o the subparts of AIR CHAMBER have Shape
HEMISPHERICAL and CYLINDRICAL which are
each a kind of Shape ROUND, (&gt;)
o the recursive partial matching of subparts.
BASE in Descr2 could match to the subpart in
AIR CHAMBER that has a translation of (0.0
0.0 0.0) - i.e.. ChamberBottom of .41R
CHAMBER. However, they mismatch since
color TURQUOISE in Descr2 differs from color
BLUE of AIR CHAMBER. (-)
The above analysis using the partial matcher
provides no clear winner since the differences are so
close causing the scores generated for the candidates
to be almost exactly the same (i.e.. the only difference
was in the score for Transparency). All candidates,
hence, will be retained for now.
</bodyText>
<page confidence="0.996197">
215
</page>
<bodyText confidence="0.999899">
At this point, the knowledge sources and their
associated rules that were mentioned earlier apply.
These rules attempt to order the feature values in the
speaker&apos;s description for relaxation. First. we&apos;ll order
the features in Descr2 using linguistic knowledge.
Linguistic analysis of Descr2, &amp;quot;... are clear plastic ... a
rounded piece with a turquoise base ... Both are
tubular ... fits loosely over ....&apos;&apos; tells us that the
features were specified using the following modifiers.
</bodyText>
<listItem confidence="0.65827075">
o Adjective: (Shape ROUND)
o Prepositional Phrase: (Subpart (BASE (Color
TURQUOISE)))
o Predicate Complement: (Transparency CLEAR).
</listItem>
<sectionHeader confidence="0.5058225" genericHeader="method">
(Composition PLASTIC). (Analogical-Shape
TUBULAR). (Fit LOOSE)
</sectionHeader>
<bodyText confidence="0.996278666666667">
Observations from the protocols (as described by the
rules developed in [13]) has shown that people tend to
relax first features specified as adjectives, then as
prepositional phrases and finally as relative clauses or
predicate complements. This suggests relaxation of
Descr2 in the order:
</bodyText>
<subsectionHeader confidence="0.33001">
IShop0 &lt; Kolor.Subparti
</subsectionHeader>
<bodyText confidence="0.960243409090909">
&lt; ITransparency.Composition.Anological-Shape.Fitl.
The set of features on the left side of a &amp;quot;&lt;&amp;quot; symbol is
relaxed before the set on the right side The order
that the features inside the braces. &apos;&apos;) 3&amp;quot;, are relaxed
is left unspecified (i.e.. any order of relaxation is
alright) Perceptual Information about the domain also
provides suggestions. Whenever a feature has feature
values that are close, then one should be prepared to
relax any of them to any of the others (we call this
the &amp;quot;clustered feature value rule&amp;quot;) in this example.
since the colors are all very close - BLUE. TURQUOISE.
and VIOLET - then Color may be a reasonable thing to
relax. Hierarchical information about how closely
related one feature value is to another can also be
used to determine what to relax. The Shape values are
a good example. A CYLINDRICAL shape is also a CONICAL
shape, which is also a 3-D ROUND shape. Hence, it is
very reasonable to match ROUNDED to CYLINDRICAL. All
of these suggestions can be put together to form the
order.
1Shop*.Colorl &lt; 1Subporti
&lt; rronsparency,Composition.
</bodyText>
<subsectionHeader confidence="0.906195">
Analogical -Shope.Fiti.
</subsectionHeader>
<bodyText confidence="0.999949923076923">
The referent candidates MAINTUBE. STAND, and
AIR CHAMBER can be examined and possibly ordered for
relaxation using the above feature ordering For this
example, the relaxation of Descr2 to any of the
candidates requires relaxing their SHAPE and COLOR
features. Since they each require relaxing the same
features, the candidates can not be ordered with
respect to each other (i.e., none of the possible feature
orders is better for relaxing the candidates). Hence.
no one candidate stands out as the most likely
referent.
While no ordering of the candidates was possible.
the order generated to relax the features in the
speaker&apos;s description can be used to guide the
relaxation, of each candidate. The relaxation methods
mentioned at the end of the last section come into use
here. Generate-Similar-Shape-Values can determine
that HEMISPHERICAL and CYLINDRICAL shapes of the AIR
CHAMBER are close to the 3D-ROUND shape This holds
equally true for the cylindrical shapes of the
MAINTUBE and the STAND. Generate-Similar-Color-
Values next tries relaxing the Color TURQUOISE. It
determines the colors BLUE and GREEN as the best
alternates. Here only two clear winners exist - the
AIR CHAMBER and the STAND - while the MAINTUBE is
dropped as a candidate since it is reasonable to relax
TURQUOISE to BLUE or to GREEN but not to VIOLET
Subpart, Transparency. Analogical-Shape, and
Composition provide no further help (though, the fact
that the AIR CHAMBER has both CLEAR and OPAQUE
subparts might put it slightly lower than the STAND
whose subparts are all CLEAR. This difference.
however, is not significant.). This leaves trial and
error attempts to try to complete the FIT action. The
one (if any) that fits - and fits loosely - is selected
as the referent. The protocols showed that people
often do just that - reducing their set of choices down
as best they can and then taking each of the remaining
choices and trying out the requested action on them
</bodyText>
<sectionHeader confidence="0.999689" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.99996512">
Our goal in this work is to build robust natural
language understanding systems, allowing them to
detect and avoid miscommunication. The goal is not to
make a perfect listener but a more tolerant one that
could avoid many mistakes, though still wrong on
occasion. In Section 2. we introduced a taxonomy of
miscommunication problems that occur in expert-
apprentice dialogues. We showed that reference
mistakes are one kind of obstacle to robust
communication. To tackle reference problems, we
described how to extend the succeed/fail paradigm
followed by previous natural language researchers.
We represented real world objects hierarchically
in a knowledge base using a representation language,
KL-One, that follows in the tradition of semantic
networks and frames. In such a representation
framework, the reference identification task looks for a
referent by comparing the representation of the
speakers Input to elements in the knowledge base by
using a matching procedure. Failure to find a referent
in previous reference identification systems resulted in
the unsuccessful termination of the reference task. We
claim that people behave better than this and explicitly
illustrated such cases in an expert-apprentice domain
about toy water pumps.
We developed a theory of relaxation for
recovering from reference failures that provides a
much better model for human performance. When
people are asked to identify objects, they go about it
in a certain way, find candidates, adjust as necessary,
re-try, and, if necessary, give up and ask for help. We
claim that relaxation is an integral part of this process
and that the particular parameters of relaxation differ
from task to task and person to person. Our work
models the relaxation process and provides a
computational model for experimenting with the
different parameters. The theory incorporates the
same language and physical knowledge that people use
in performing reference identification to guide the
relaxation process. This knowledge is represented as a
set of rules and as data in a hierarchical knowledge
base. Rule-based relaxation provided a methodical way
to use knowledge about language and the world to find
a referent. The hierarchical representation made it
possible to tackle issues of imprecision and over-
specification in a speaker&apos;s description. It allows one
to check the position of a description in the hierarchy
and to use that position to judge imprecision and
over-specification and to suggest possible repairs to
the description.
</bodyText>
<page confidence="0.995314">
216
</page>
<bodyText confidence="0.999939333333333">
Interestingly. one would expect that &amp;quot;closest&amp;quot;
match would suffice to solve the problem of finding a
referent. We showed, however, that it doesn&apos;t usually
provide you with the correct referent. Closest match
isn&apos;t sufficient because there are many features
associated with an object and, thus, determining which
of those features to keep and which to drop is a
difficult problem due to the combinatorics and the
effects of context. The relaxation method described
circumvents the problem by using the knowledge that
people have about language and the physical world to
prune down the search space.
</bodyText>
<sectionHeader confidence="0.997843" genericHeader="acknowledgments">
ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.999284875">
I want to thank especially Candy Sidner for her
insightful comments and suggestions during the course
of this work. I&apos;d also like to acknowledge the helpful
comments of George Hadden. Diane Litman. Marc Vilain.
Dave Waltz, Bonnie Webber and Bill Woods on this paper.
Many thanks also to Phil Cohen, Scott Fertig and Kathy
Starr for providing me with their water pump dialogues
and for their invaluable observations on them.
</bodyText>
<sectionHeader confidence="0.99955" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999989435185186">
[1] Allen. James F. A Plan-Based Approach to Speech
Act Recognition. Ph.D. Th.. University of Toronto. 1979.
[2] Appelt. Douglas E. Planning Natural Language
Utterances to Satisfy Multiple Goals. Ph.D. Th..
Stanford University. 1981.
[3] Brachman. Ronald J. A Structural Paradigm for
Representing Knowledge. Ph.D. Th.. Harvard University,
1977. Also, Technical Report No. 3605. Bolt Beranek
and Newman Inc.
[4] Brown, John Seely and Kurt VanLehn. &amp;quot;Repair
Theory A Generative Theory of Bugs in Procedural
Skills.&amp;quot; Cognitive Science 4. 4 (1980), 379-426.
[5] Cohen. Philip R On Knowing What to Say.
Planning Speech Acts. Ph.D. Th., University of Toronto.
1978.
[8] Cohen. P.. C Perrault and J. Allen. Beyond
Question Answering. In Knowledge Representation and
Natural Language Processing. W. Lehnart and M. RingIe.
Ed..Lawrence Erlbaum Associates, 1981.
[7] Cohen. Philip R. The need for Referent
Identification as a Planned Action. Proceedings of
IJCAI-81. Vancouver, B.C.. Canada. August. 1981, pp.
31-35.
[8] Cohen. Philip R.. Scott Fertig and Kathy Starr.
Dependencies of Discourse Structure on the Modality of
Communication. Telephone vs. Teletype. Proceedings of
ACL. Toronto, Ont., Canada. June, 1982, pp. 28-35.
[9] Cohen. Philip R. &amp;quot;The Pragmatics of Referring and
the Modality of Communication.&amp;quot; Computational
Linguistics 10. 2 (April-June 1984), 97-146.
[10] Gentner, Dedre. The Structure of Analogical
Models in Science. Bolt Beranek and Newman Inc.. July.
1980.
[11] Goodman. Bradley A. Miscommunication in Task-
Oriented Dialogues. KRNL Group Working Paper, Bolt
Beranek( and Newman Inc., April 1982.
[12] Goodman. Bradley A. Repairing Miscommunication:
Relaxation in Reference. Proceedings of AAAI-83.
Washington, D.C.. August, 1983. pp. 134-138.
[13] Goodman. Bradley A. Communication and
Miscommunication. Ph.D. Th., University of Illinois,
Urbana. 1984.
[14] Grosz, Barbara J. The Representation and Use of
Focus in Dialogue Understanding. Ph.D. Th., University
of California. Berkeley. 1977. Also, Technical Note 151.
Stanford Research Institute.
[15] Grosz. Barbara J. Focusing and descriptions in
natural language dialogues. In Elements of Discourse
Understanding, Joshi. Webber and Sags, Ed. Cambridge
University Press. 1981. pp. 84-105.
[18] Lipkis, Thomas. A KL-ONE Classifier. Proceedings
of the 1981 KL-One Workshop, June, 1982. pp. 128-145.
Report No. 4842. Bolt Beranek and Newman Inc. Also
Consul Note # 5, USC/Information Sciences Institute,
October 1981.
[17] Litman. Diane J. and James F. Allen. A Plan
Recognition Model for Clarification Subdialogues.
Proceedings of Coling84, Stanford University, Stanford.
CA.. July, 1984. pp. 302-311.
[18] Mark. William. Realization. Proceedings of the
1981 KL-One Workshop. June, 1982. pp. 78-89. Report
No. 4842, Bolt Beranek and Newman Inc.
[19] McKeown, Kathleen R. Recursion in Text and Its
Use in Language Generation. Proceedings of AAAI-83.
Washington, D.C.. August. 1983. pp. 270-273.
[20] Reichman, Rachel. &amp;quot;Conversational Coherency.&amp;quot;
Cognitive Science 2. 4 (1978). 283-327.
[21] Reichman. Rachel. Plain Speaking: A Theory and
Grammar of Spontaneous Discourse. Ph.D. Th.. Harvard
University, 1981. Also, Technical Report No. 4861, Bolt
Beranek and Newman Inc.
[22] Ringle. Martin and Bertram Bruce. Conversation
Failure. In Knowledge Representation and Natural
Language Processing. W. Lehnart and M. Ringle,
Ed..Lawrence Erlbaum Associates, 1981.
[23] Sidner. C. L.. and Israel, D.J. Recognizing
intended meaning and speaker&apos;s plans. Proceedings of
the International Joint Conference in Artificial
Intelligence. The International Joint Conferences on
Artificai Intelligence. Vancouver, B.C.. August, 1981, pp.
203-208.
[24] Sidner, Candace Lee. Towards a Computational
Theory of Definite Anaphora Comprehension in English
Discourse. Ph.D. Th., Massachusetts Institute of
Technology, 1979. Also, Report No. TR-537. MIT Al Lab.
[25] Sidner. C. L.. M. Bates, R. J. Bobrow,
R. J. Brachman, P. R. Cohen, D. J. Israel, J. Schmolze.
B. L. Webber. W. A. Woods. Research in Knowledge
Representation for Natural Language Understanding.
Report No. 4785, Bolt Beranek and Newman Inc.,
November, 1981.
[28] Sidner, C. L.. Bates, M., Bobrow, R.. Goodman, B..
Haas. A.. Ingria. R.. Israel, D., McAllester. D., Moser, M.,
Schmolze, J., Vilain. M. Research in Knowledge
Representation for Natural Language Understanding -
Annual Report. 1 September 1982 - 31 August 1983.
Technical Report 5421. BBN Laboratories. Cambridge.
MA, 1983.
[27] Sidner. C., Goodman. B.. Haas, A., Moser. M.,
Stallard. D.. Vilain. M. Research in Knowledge
Representation for Natural Language Understanding -
Annual Report. 1 September 1983 - 31 August 1984.
Technical Report 5694. BBN Laboratories Inc.,
Cambridge, MA. 1984.
[28] Webber, Bonnie Lynn. A Formal Approach to
Discourse Anaphora. Ph.D. Th., Harvard University,
1978. Also, Technical Report No. 3761. Bolt Beranek
and Newman Inc.
</reference>
<page confidence="0.998404">
217
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.036435">
<title confidence="0.962885">REPAIRING REFERENCE IDENTIFICATION FAILURES BY RELAXATION</title>
<author confidence="0.999985">Bradley A Goodman</author>
<affiliation confidence="0.99801">BBN Laboratories</affiliation>
<address confidence="0.9992755">10 Moulton Street Cambridge, Mass. 02238</address>
<abstract confidence="0.999712022222222">The goal of this work is the enrichment of human-machine interactions in a natural language environment.&apos; We want to provide a framework less restrictive than earlier ones by allowing a speaker leeway in forming an utterance about a task and in determining the conversational vehicle to deliver it. A speaker and listener cannot be assured to have the same beliefs, contexts, backgrounds or goals at each point in a conversation. As a result, difficulties and mistakes arise when a listener interprets a speaker&apos;s utterance. These mistakes can lead to various kinds of misunderstandings between speaker and listener. including reference failures or failure to understand the speaker&apos;s intention. We call these misunderstandings miscommunication Such mistakes constitute a kind of &amp;quot;ill-formed&amp;quot; input that can slow down and possibly break down communication. Our goal is to recognize and isolate such miscommunications and circumvent them. This paper will highlight a particular class of miscommunication reference problems by describing a case study, including techniques for avoiding failures of reference 1 liatroduction Cohen. Perrault and Allen showed in their paper &amp;quot;Beyond Question Answering&amp;quot; [6] that &amp;quot;.. users of question-answering systems expect them to do more than just answer isolated questions -they expect systems to engage in conversation In doing so. the system is expected to allow users to be less than meticulously literal in conveying their intentions, and it is expected to make linguistic and pragmatic use of the previous discourse.&amp;quot; Following in their footsteps, we want to build robust natural language processing systems that can detect and recover from miscommunication. The development of such systems requires a study on how people communicate and how tney recover from problems in communication. This paper summarizes the results of a dissertation (131 that investigates the kinds of miscommunication that occur in human communication with a special emphasis problems.i.e.. problems a listener has determining whom or what a speaker is talking about. We have written computer programs and algorithms that demonstrate how one could handle such problems in</abstract>
<note confidence="0.84561275">Defense Advanced Research Project Agency under contract N00014-77— C—e378. the context of a natural language understanding</note>
<abstract confidence="0.992784825842697">system. The study of miscommunication is a necessary task within such a context since any computer capable of communicating with humans in natural language must of the imprecise, ill-devised or complex utterances that people often use. Our current research [25, 28] views most dialogues as being cooperative and goal directed. i.e.. a speaker and listener work together to achieve a common goal. The interpretation of an utterance involves identifying the underlying plan or goal that the utterance reflects [5. 1. 231. This plan, however, is rarely, if ever, obvious at the surface sentence level. A central issue in the interpretation of utterances is the transformation of sequences of imprecise, illor complex utterances into well-specifiedplans that might be carried out by dialogue participants. Within this context, miscommunication can occur. We are particularly concerned with cases of from the hearer&apos;s such when the hearer is inattentive to, confused about, or misled about the intentions of the speaker. In ordinary exchanges speakers usually make assumptions what their listeners know about topic of discussion. They will leave out details thought to be superfluous [2. 19]. Since the speaker really does not exactly a listener knows about a topic, it easy to make statements that can be misinterpreted or not understood by the listener because not enough details were presented. One principal source of trouble is the description constructed by the speaker to refer to an actual object in the world. The description can be imprecise, confused, ambiguous or overly specific, it might be interpreted under the wrong context. This leads to difficulty for the listener when figuring out what object is being described, that is. reference errors. Such descriptions are &amp;quot;illformed&amp;quot; input. The blame for ill-formedness may lie partly with the speaker and partly with the listener The speaker may have been sloppy or not taken the hearer into consideration, the listener may be either remiss or unwilling to admit he can&apos;t understand the speaker and to ask the speaker for clarification, or may simply feel that he has understood when he in fact has not. This work is part of an on-going effort to develop a reference identification and plan recognition mechanism that can exhibit more &amp;quot;human-like&apos; tolerance of such utterances. Our goal is to build a more robust system that can handle errorful utterances, and that can be incorporated in existing systems. As a start. we have concentrated on reference identification. In conversation people use imperfect descriptions to communicate about objects, sometimes their partners succeed in understanding and they fail. Any computer hoping to play a listener must be capable of taking what the 204 speaker says and either deleting, adapting or clarifying A. 1. Now there&apos;s a blue cap We are developing a theory of the use of [J the TUBEBASE] extensional descriptions that will help explain how 2. that has two little teeth sticking people successfully use such imperfect descriptions. 3. out of the bottom of it. We call this the theory of reference miscommunication. Section 2 of this paper highlights some aspects of 4. normal communication and then provides a general discussion on the types of miscommunication that occur in conversation, concentrating primarily on reference problems and motivating many of them with illustrative protocols. Section 3 presents possible ways around some of the problems of miscommunication in reference. Motivated there is a partial implementation of a reference mechanism that attempts to overcome many reference problems. We are following the task—oriented paradigm of Grosz [14] since it is easy to study (through videotapes), it places the world in front of you (a primarily extensional world), and it limits the discussion while still providing a rich environment for complex descriptions. The task chosen as the target for the system is the assembly of a toy water pump. The water pump is reasonably complex, containing four subassemblies that are built from plastic tubes, nozzles, valves, plungers, and caps that can be screwed or pushed together. A large corpus of dialogues concerning this task was collected by Cohen (see [7, 8. 9]). These dialogues contained instructions from &amp;quot;expert&amp;quot; to an that explain the assembly of the toy water pump. Both participants were working to achieve a common goal — the successful assembly of the pump This domain is rich in perceptual information, allowing for complex descriptions of elements in it. The data provide examples of imprecision. confusion. and ambiguity as well as attempts to correct these problems. The following exchange exemplifies one such situation. Here A is instructing J to assemble part of water pump. Refer Figure for a picture of the pump. A and J are communicating verbally but neither can see the other. (The bracketed text in the excerpt tells what was actually occurring while each utterance was spoken.) Notice the complexity of the speaker&apos;s descriptions and the resultant processing required by the listener. This dialogue illustrates when listeners repair the speaker&apos;s description in order to a referent, when they repair their initial once they are given information. and when fail to choose a proper referent In A the holes on the &amp;quot;the Ilttle &amp;quot; i the description. realizing that A doesn t really mean &amp;quot;one &apos; hole but is referring to the &apos; holes. 1 apparently does this since he doesn t 1 23 right. complain about As description and correctly attaches the 1(b) shows configuration of the pump after the to the In 10. In Line 13. J &amp;quot;a red plastic piece&amp;quot; to refer to the A the relative ciause &amp;quot;that has four gizmos it.&amp;quot; J is forced to drop the the to select the Lines and 18. As description the other--the open part of the main the lower is ambiguous, and J selects the site, namely the which to insert the J doesn&apos;t detect any trouble. Lines 20 and 21 keep J from thinking that something is wrong because the part fits In Lines 27 and 28, J that A did not give him enough information to perform the requested action. In Line 30. J further compounds the error in 18 by putting the the Excerpt 1 (Telephone) A. 5. Okay On that take the 6. bright shocking pink piece of plastic takes BASEVALVE] and stick little hole over the teeth. [3 starts to install the BASEVALVE, backs off, looks at it again and then goes ahead and installs it] J. 8 Okay Now screw that blue cap onto 10. the bottom of the main tube. [3 screws TUBEBASE onto MAINTUBE] Okay. 12 Now, there&apos;s a-- 13. a red plastic piece [3 starts for NOZZLE] 14 that has four gizmos on it. [3 switches to SLIDEVALVE] Yes. 16 Put the ungizmoed end in the uh 17 the other--the open 18. part of the main tube, the lower valve. puts SLIDEVALVE into hole in TUBEBASE, but A meant OUTLET2 of MAINTUBE] All It Just fits loosely doesn&apos;t have to right. Okay, then take the clear plastic SPOUT] 24 And put it over bottom too. [3 tries installing SPOUT on TUBEBASE] 1 25 Okay Okay Now, take the-- 27 Which end am I supposed to put it over&apos; 28 Do you know&apos; 29 Put the--put the--the big end-- 30. the big end over it. [3 pushes big end of SPOUT on TUBEBASE, twisting force it on] 205 I cLudt Plunger NO:Z le CZD 14&amp;quot;}Ibtuel .</abstract>
<note confidence="0.8422456">Choicer :: Miu.n c C&apos;ED, gteen1 Figure 1: The Toy Water Pump</note>
<abstract confidence="0.989784815384615">2 Miscommunication People must and do manage to resolve lots of (potential) miscommunication in everyday conversation. Much of It is resolved subconsciously with the listener unaware that anything is wrong. Other is resolved with the listener actively deleting or replacing information in the speaker&apos;s utterance until It fits the current context. Sometimes this resolution is postponed until the questionable part of the utterance is actually needed. Still, when all these fail, the listener can ask the speaker to clarify was There are many aspects of an utterance that the listener can become confused about and that can lead to miscommunication. The listener can become confused about what the speaker intends for the referents, the actions, and the goals described by the utterance. Confusions often appear to result from conflict between the current state of the conversation. the overall goal of the speaker, or the manner in which the speaker presented the information. However, when the listener steps back and is able to discover what kind of confusion is occurring, then the confusion can quite possibly be resolved. 2.1 Causes of miscommunication attempts to motivate a paradigm for the kinds of conversation that we studied and tries to point out places in the paradigm that leave room for miscommunication. analysis of clarification suodiologues can be found in [17]. of the structure of task-oriented dialogues Task-oriented conversations have a specific goal to be achieved: the performance of a task (e.g.. [14]). The participants in the dialogue can have the same skill level and they can simply work together to accomplish the task; or one of them, the expert, could know more and could direct the other, the apprentice, to perform the task. We have concentrated primarily on the latter case due to the protocols that we examined but many of our observations can be generalized to the former case, too. We will refer to this as the apprentice-expert domain. The viewpoints of the expert and apprentice differ greatly in apprentice-expert exchanges. The expert, having an understanding of the functionality of the elements in the task, has more of a feel for how the elements work together, how they go together, and how the individual elements can be used. The apprentice normally has no such knowledge and must base his decisions on perceptual features such as shape [15]. The structure of the task affects the structure of the dialogue [14]. particularly through the center of attention of the expert and apprentice. This is the phenomenon called focus [14. 20, 24]. which, in taskoriented dialogues is a very real and operational thing (e.g., focus is used in resolving anaphoric references). Shifts in focus correspond directly to the task. its subtasks. the objects in a task and the subpleces of each object Focus and focus shifts are governed by many rules [14. 20, 24] Confusion may result when expected shifts do not take place. For example, if the expert changes focus to an object but never discusses its subpieces (such as an obvious attachment surface)</abstract>
<intro confidence="0.584538">or never bothers to talk about the object reasonably</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>F James</author>
</authors>
<title>A Plan-Based Approach to Speech Act Recognition.</title>
<date>1979</date>
<institution>Ph.D. Th.. University of Toronto.</institution>
<marker>[1]</marker>
<rawString>Allen. James F. A Plan-Based Approach to Speech Act Recognition. Ph.D. Th.. University of Toronto. 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Douglas</author>
</authors>
<title>Planning Natural Language Utterances to Satisfy Multiple Goals.</title>
<date>1981</date>
<tech>Ph.D. Th..</tech>
<institution>Stanford University.</institution>
<marker>[2]</marker>
<rawString>Appelt. Douglas E. Planning Natural Language Utterances to Satisfy Multiple Goals. Ph.D. Th.. Stanford University. 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ronald</author>
</authors>
<title>A Structural Paradigm for Representing Knowledge.</title>
<date>1977</date>
<tech>Ph.D. Th..</tech>
<institution>Harvard University,</institution>
<marker>[3]</marker>
<rawString>Brachman. Ronald J. A Structural Paradigm for Representing Knowledge. Ph.D. Th.. Harvard University, 1977. Also, Technical Report No. 3605. Bolt Beranek and Newman Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Seely Brown</author>
<author>Kurt VanLehn</author>
</authors>
<title>Repair Theory A Generative Theory of Bugs in Procedural Skills.&amp;quot;</title>
<date>1980</date>
<journal>Cognitive Science</journal>
<volume>4</volume>
<pages>379--426</pages>
<contexts>
<context position="37580" citStr="[4]" startWordPosition="6367" endWordPosition="6367">are using &amp;quot;relaxation&amp;quot; techniques to capture this behavior. Our reference identification module treats descriptions as approximate. It relaxes a description in order to find a referent when the literal content of the description fails to provide the needed information. Relaxation, however, is not performed blindly on the description. We try to model a person&apos;s behavior by drawing on sources of knowledge used by people. We have developed a computational model that can relax aspects of a description using many of these sources of knowledge. Relaxation then becomes a form of communication repair [4] that hearers can use. 3.2 The relaxation component When a description fails to denote a referent in the real world properly, it is possible to repair It by a relaxation process that ignores or modifies parts of the description. Since a description can specify many features of an object, the order in which parts of it are relaxed is crucial (i.e.. relaxing in different orders could yield matches to different objects) There are several kinds of relaxation possible. One can Ignore a constituent, replace it with something close, replace it with a related value, or change focus (i.e.. consider a d</context>
</contexts>
<marker>[4]</marker>
<rawString>Brown, John Seely and Kurt VanLehn. &amp;quot;Repair Theory A Generative Theory of Bugs in Procedural Skills.&amp;quot; Cognitive Science 4. 4 (1980), 379-426.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Philip</author>
</authors>
<title>On Knowing What to Say. Planning Speech Acts.</title>
<date>1978</date>
<tech>Ph.D. Th.,</tech>
<institution>University of Toronto.</institution>
<marker>[5]</marker>
<rawString>Cohen. Philip R On Knowing What to Say. Planning Speech Acts. Ph.D. Th., University of Toronto. 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P C Perrault</author>
<author>J Allen</author>
</authors>
<title>Beyond Question Answering.</title>
<date>1981</date>
<booktitle>In Knowledge Representation and Natural Language Processing. W. Lehnart</booktitle>
<marker>[8]</marker>
<rawString>Cohen. P.. C Perrault and J. Allen. Beyond Question Answering. In Knowledge Representation and Natural Language Processing. W. Lehnart and M. RingIe. Ed..Lawrence Erlbaum Associates, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Philip</author>
</authors>
<title>The need for Referent Identification as a Planned Action.</title>
<date>1981</date>
<booktitle>Proceedings of IJCAI-81.</booktitle>
<pages>31--35</pages>
<location>Vancouver, B.C.. Canada.</location>
<marker>[7]</marker>
<rawString>Cohen. Philip R. The need for Referent Identification as a Planned Action. Proceedings of IJCAI-81. Vancouver, B.C.. Canada. August. 1981, pp. 31-35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip R Scott Fertig</author>
<author>Kathy Starr</author>
</authors>
<date>1982</date>
<booktitle>Dependencies of Discourse Structure on the Modality of Communication. Telephone vs. Teletype. Proceedings of ACL.</booktitle>
<pages>28--35</pages>
<location>Toronto, Ont., Canada.</location>
<marker>[8]</marker>
<rawString>Cohen. Philip R.. Scott Fertig and Kathy Starr. Dependencies of Discourse Structure on the Modality of Communication. Telephone vs. Teletype. Proceedings of ACL. Toronto, Ont., Canada. June, 1982, pp. 28-35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Philip</author>
</authors>
<title>The Pragmatics of Referring and the Modality of Communication.&amp;quot;</title>
<date>1984</date>
<journal>Computational Linguistics</journal>
<volume>10</volume>
<pages>97--146</pages>
<contexts>
<context position="15422" citStr="[9]" startWordPosition="2528" endWordPosition="2528"> things. We will look at specific forms of miscommunication and describe ways to detect them. We will highlight relationships between different miscommunication problems but won&apos;t necessarily demonstrate ways to resolve each of them. 206 2.2.1 Instances of miscommunication There are many ways hearers can get confused during a conversation. Figure 2 outlines some of them that were derived from analyzing the water pump protocols. This section defines and illustrates many of them through numerous excerpts. Each excerpt is marked in parentheses to show what modality of communication was used (see [9] for a. description about the collection of these excerpts). Each bracketed portion of the excerpt explains what was occurring at that point in the dialogue. The confusions themselves, coupled with the description at the end of this section on how to recognize when one of them is occurring, provides motivation for the use of the algorithm outlined in Section 3 as a means for repairing communication problems. We will only discuss referent confusion in this paper. The other forms of confusion - Action. Goal, and Cognitive Load - are described in [11. 13]. Another categorization of confusions tha</context>
</contexts>
<marker>[9]</marker>
<rawString>Cohen. Philip R. &amp;quot;The Pragmatics of Referring and the Modality of Communication.&amp;quot; Computational Linguistics 10. 2 (April-June 1984), 97-146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dedre Gentner</author>
</authors>
<title>The Structure of Analogical Models in Science. Bolt Beranek and Newman Inc..</title>
<date>1980</date>
<marker>[10]</marker>
<rawString>Gentner, Dedre. The Structure of Analogical Models in Science. Bolt Beranek and Newman Inc.. July. 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bradley</author>
</authors>
<title>Miscommunication in TaskOriented Dialogues.</title>
<date>1982</date>
<institution>KRNL Group Working Paper, Bolt Beranek( and Newman Inc.,</institution>
<marker>[11]</marker>
<rawString>Goodman. Bradley A. Miscommunication in TaskOriented Dialogues. KRNL Group Working Paper, Bolt Beranek( and Newman Inc., April 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bradley</author>
</authors>
<title>Repairing Miscommunication: Relaxation in Reference.</title>
<date>1983</date>
<booktitle>Proceedings of AAAI-83.</booktitle>
<pages>134--138</pages>
<location>Washington, D.C..</location>
<contexts>
<context position="44920" citStr="[12, 27, 13]" startWordPosition="7542" endWordPosition="7544">lar candidate is selected, then deciding which features to relax is relatively trivial - one simply compares feature by feature between the candidate description (the target) and the speaker&apos;s description (the pattern) and notes any discrepancies. 212 that ordering to determine the order in which to try relaxing the candidates. We draw primarily on sources of linguistic knowledge, pragmatic knowledge, discourse knowledge. domain knowledge, perceptual knowledge, hierarchical knowledge, and trial and error knowledge during this repair process. A detailed treatment of all of them can be found in [12, 27, 13]. These knowledge sources are consulted to determine the feature ordering for relaxation. We represent information from each knowledge source as a set of relaxation rules. These rules are written in a PROLOG—like language. Figure 5 illustrates one such linguistic knowledge relaxation rule. This rule is motivated by the observation in the excerpts that speakers typically add more important information at the end of a description (where they are separated from the main part of the description and thus provided more emphasis). Since the syntactic constituents often at the end are relative clauses</context>
</contexts>
<marker>[12]</marker>
<rawString>Goodman. Bradley A. Repairing Miscommunication: Relaxation in Reference. Proceedings of AAAI-83. Washington, D.C.. August, 1983. pp. 134-138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bradley A Communication</author>
<author>Miscommunication Ph D</author>
</authors>
<date>1984</date>
<institution>Th., University of Illinois,</institution>
<location>Urbana.</location>
<contexts>
<context position="44920" citStr="[12, 27, 13]" startWordPosition="7542" endWordPosition="7544">lar candidate is selected, then deciding which features to relax is relatively trivial - one simply compares feature by feature between the candidate description (the target) and the speaker&apos;s description (the pattern) and notes any discrepancies. 212 that ordering to determine the order in which to try relaxing the candidates. We draw primarily on sources of linguistic knowledge, pragmatic knowledge, discourse knowledge. domain knowledge, perceptual knowledge, hierarchical knowledge, and trial and error knowledge during this repair process. A detailed treatment of all of them can be found in [12, 27, 13]. These knowledge sources are consulted to determine the feature ordering for relaxation. We represent information from each knowledge source as a set of relaxation rules. These rules are written in a PROLOG—like language. Figure 5 illustrates one such linguistic knowledge relaxation rule. This rule is motivated by the observation in the excerpts that speakers typically add more important information at the end of a description (where they are separated from the main part of the description and thus provided more emphasis). Since the syntactic constituents often at the end are relative clauses</context>
<context position="63048" citStr="[13]" startWordPosition="10353" endWordPosition="10353">n the speaker&apos;s description for relaxation. First. we&apos;ll order the features in Descr2 using linguistic knowledge. Linguistic analysis of Descr2, &amp;quot;... are clear plastic ... a rounded piece with a turquoise base ... Both are tubular ... fits loosely over ....&apos;&apos; tells us that the features were specified using the following modifiers. o Adjective: (Shape ROUND) o Prepositional Phrase: (Subpart (BASE (Color TURQUOISE))) o Predicate Complement: (Transparency CLEAR). (Composition PLASTIC). (Analogical-Shape TUBULAR). (Fit LOOSE) Observations from the protocols (as described by the rules developed in [13]) has shown that people tend to relax first features specified as adjectives, then as prepositional phrases and finally as relative clauses or predicate complements. This suggests relaxation of Descr2 in the order: IShop0 &lt; Kolor.Subparti &lt; ITransparency.Composition.Anological-Shape.Fitl. The set of features on the left side of a &amp;quot;&lt;&amp;quot; symbol is relaxed before the set on the right side The order that the features inside the braces. &apos;&apos;) 3&amp;quot;, are relaxed is left unspecified (i.e.. any order of relaxation is alright) Perceptual Information about the domain also provides suggestions. Whenever a featu</context>
</contexts>
<marker>[13]</marker>
<rawString>Goodman. Bradley A. Communication and Miscommunication. Ph.D. Th., University of Illinois, Urbana. 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
</authors>
<title>The Representation and Use of Focus in Dialogue Understanding.</title>
<date>1977</date>
<journal>Also, Technical Note</journal>
<tech>Ph.D. Th.,</tech>
<volume>151</volume>
<institution>University of California. Berkeley.</institution>
<contexts>
<context position="6320" citStr="[14]" startWordPosition="974" endWordPosition="974">is the theory of reference miscommunication. Section 2 of this paper highlights some aspects of 3: 4. Yeah. normal communication and then provides a general discussion on the types of miscommunication that occur in conversation, concentrating primarily on reference problems and motivating many of them with illustrative protocols. Section 3 presents possible ways around some of the problems of miscommunication in reference. Motivated there is a partial implementation of a reference mechanism that attempts to overcome many reference problems. We are following the task—oriented paradigm of Grosz [14] since it is easy to study (through videotapes), it places the world in front of you (a primarily extensional world), and it limits the discussion while still providing a rich environment for complex descriptions. The task chosen as the target for the system is the assembly of a toy water pump. The water pump is reasonably complex, containing four subassemblies that are built from plastic tubes, nozzles, valves, plungers, and caps that can be screwed or pushed together. A large corpus of dialogues concerning this task was collected by Cohen (see [7, 8. 9]). These dialogues contained instructio</context>
<context position="12210" citStr="[14]" startWordPosition="2000" endWordPosition="2000">ented the information. However, when the listener steps back and is able to discover what kind of confusion is occurring, then the confusion can quite possibly be resolved. 2.1 Causes of miscommunication This section attempts to motivate a paradigm for the kinds of conversation that we studied and tries to point out places in the paradigm that leave room for miscommunication. 2An analysis of clarification suodiologues can be found in [17]. 2.1.1 Effects of the structure of task-oriented dialogues Task-oriented conversations have a specific goal to be achieved: the performance of a task (e.g.. [14]). The participants in the dialogue can have the same skill level and they can simply work together to accomplish the task; or one of them, the expert, could know more and could direct the other, the apprentice, to perform the task. We have concentrated primarily on the latter case - due to the protocols that we examined - but many of our observations can be generalized to the former case, too. We will refer to this as the apprentice-expert domain. The viewpoints of the expert and apprentice differ greatly in apprentice-expert exchanges. The expert, having an understanding of the functionality</context>
<context position="33960" citStr="[14]" startWordPosition="5795" endWordPosition="5795">tion The previous section illustrated how taskoriented natural language interactions in the real world can induce contextually poor utterances. Given all the possibilities for confusion, when confusions do occur, they must be resolved if the task is to be performed. This section explores the problem of fixing reference failures. Reference identification is a search process where a listener looks for something in the world that satisfies a speaker&apos;s uttered description. A computational scheme for performing reference has evolved from work by other artificial intelligence researchers (e.g.. see [14]). That traditional approach succeeds if a referent is found, or fails if no referent is found (see Figure 3(a)). However, a reference identification component must be more versatile than those constructed in the traditional manner. The excerpts provided in the previous section show that the traditional approach is wrong because people&apos;s real behavior is much more elaborate. In particular. listeners often find the correct referent even when the speaker&apos;s description does not describe any object in the world. For example, a speaker could describe a blue block as the &amp;quot;turquoise block.&amp;quot; Most list</context>
</contexts>
<marker>[14]</marker>
<rawString>Grosz, Barbara J. The Representation and Use of Focus in Dialogue Understanding. Ph.D. Th., University of California. Berkeley. 1977. Also, Technical Note 151. Stanford Research Institute.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Barbara</author>
</authors>
<title>Focusing and descriptions in natural language dialogues.</title>
<date>1981</date>
<booktitle>In Elements of Discourse Understanding, Joshi. Webber and Sags, Ed.</booktitle>
<pages>84--105</pages>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="13077" citStr="[15]" startWordPosition="2148" endWordPosition="2148"> on the latter case - due to the protocols that we examined - but many of our observations can be generalized to the former case, too. We will refer to this as the apprentice-expert domain. The viewpoints of the expert and apprentice differ greatly in apprentice-expert exchanges. The expert, having an understanding of the functionality of the elements in the task, has more of a feel for how the elements work together, how they go together, and how the individual elements can be used. The apprentice normally has no such knowledge and must base his decisions on perceptual features such as shape [15]. The structure of the task affects the structure of the dialogue [14]. particularly through the center of attention of the expert and apprentice. This is the phenomenon called focus [14. 20, 24]. which, in taskoriented dialogues is a very real and operational thing (e.g., focus is used in resolving anaphoric references). Shifts in focus correspond directly to the task. its subtasks. the objects in a task and the subpleces of each object Focus and focus shifts are governed by many rules [14. 20, 24] Confusion may result when expected shifts do not take place. For example, if the expert changes</context>
</contexts>
<marker>[15]</marker>
<rawString>Grosz. Barbara J. Focusing and descriptions in natural language dialogues. In Elements of Discourse Understanding, Joshi. Webber and Sags, Ed. Cambridge University Press. 1981. pp. 84-105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Lipkis</author>
</authors>
<title>A KL-ONE Classifier.</title>
<date>1982</date>
<booktitle>Proceedings of the 1981 KL-One Workshop,</booktitle>
<tech>Report No. 4842.</tech>
<pages>128--145</pages>
<marker>[18]</marker>
<rawString>Lipkis, Thomas. A KL-ONE Classifier. Proceedings of the 1981 KL-One Workshop, June, 1982. pp. 128-145. Report No. 4842. Bolt Beranek and Newman Inc. Also Consul Note # 5, USC/Information Sciences Institute, October 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Diane</author>
<author>James F Allen</author>
</authors>
<title>A Plan Recognition Model for Clarification Subdialogues.</title>
<date>1984</date>
<booktitle>Proceedings of Coling84,</booktitle>
<pages>302--311</pages>
<location>Stanford University, Stanford. CA..</location>
<contexts>
<context position="12048" citStr="[17]" startWordPosition="1976" endWordPosition="1976">sions often appear to result from conflict between the current state of the conversation. the overall goal of the speaker, or the manner in which the speaker presented the information. However, when the listener steps back and is able to discover what kind of confusion is occurring, then the confusion can quite possibly be resolved. 2.1 Causes of miscommunication This section attempts to motivate a paradigm for the kinds of conversation that we studied and tries to point out places in the paradigm that leave room for miscommunication. 2An analysis of clarification suodiologues can be found in [17]. 2.1.1 Effects of the structure of task-oriented dialogues Task-oriented conversations have a specific goal to be achieved: the performance of a task (e.g.. [14]). The participants in the dialogue can have the same skill level and they can simply work together to accomplish the task; or one of them, the expert, could know more and could direct the other, the apprentice, to perform the task. We have concentrated primarily on the latter case - due to the protocols that we examined - but many of our observations can be generalized to the former case, too. We will refer to this as the apprentice-</context>
</contexts>
<marker>[17]</marker>
<rawString>Litman. Diane J. and James F. Allen. A Plan Recognition Model for Clarification Subdialogues. Proceedings of Coling84, Stanford University, Stanford. CA.. July, 1984. pp. 302-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Realization</author>
</authors>
<date>1982</date>
<booktitle>Proceedings of the 1981 KL-One Workshop.</booktitle>
<tech>Report No. 4842,</tech>
<pages>78--89</pages>
<institution>Bolt Beranek and Newman Inc.</institution>
<marker>[18]</marker>
<rawString>Mark. William. Realization. Proceedings of the 1981 KL-One Workshop. June, 1982. pp. 78-89. Report No. 4842, Bolt Beranek and Newman Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen R McKeown</author>
</authors>
<title>Recursion in Text and Its Use in Language Generation.</title>
<date>1983</date>
<booktitle>Proceedings of AAAI-83.</booktitle>
<pages>270--273</pages>
<location>Washington, D.C..</location>
<marker>[19]</marker>
<rawString>McKeown, Kathleen R. Recursion in Text and Its Use in Language Generation. Proceedings of AAAI-83. Washington, D.C.. August. 1983. pp. 270-273.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rachel Reichman</author>
</authors>
<title>Conversational Coherency.&amp;quot;</title>
<date>1978</date>
<journal>Cognitive Science</journal>
<volume>2</volume>
<pages>283--327</pages>
<contexts>
<context position="13972" citStr="[20]" startWordPosition="2298" endWordPosition="2298">resolving anaphoric references). Shifts in focus correspond directly to the task. its subtasks. the objects in a task and the subpleces of each object Focus and focus shifts are governed by many rules [14. 20, 24] Confusion may result when expected shifts do not take place. For example, if the expert changes focus to an object but never discusses its subpieces (such as an obvious attachment surface) or never bothers to talk about the object reasonably soon after its introduction (i.e., between the time of its introduction and its use, without digressing in a wellstructured way in between (see [20])). then the apprentice may become confused, leaving him ripe for miscommunication. The reverse influence between focus and objects can lead to trouble. too. A shift in focus by the expert that does not have a manifestation in the apprentice&apos;s world will also perplex the apprentice. Focus also influences how descriptions are formed (15, 2]. The level of detail required in a description depends directly on the elements currently highlighted by the focus. If the object to be described is similar to other elements in focus, the expert must be more specific in the formulation of the description or</context>
</contexts>
<marker>[20]</marker>
<rawString>Reichman, Rachel. &amp;quot;Conversational Coherency.&amp;quot; Cognitive Science 2. 4 (1978). 283-327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rachel</author>
</authors>
<title>Plain Speaking: A Theory and Grammar of Spontaneous Discourse.</title>
<date>1981</date>
<tech>Ph.D. Th..</tech>
<institution>Harvard University,</institution>
<marker>[21]</marker>
<rawString>Reichman. Rachel. Plain Speaking: A Theory and Grammar of Spontaneous Discourse. Ph.D. Th.. Harvard University, 1981. Also, Technical Report No. 4861, Bolt Beranek and Newman Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin</author>
<author>Bertram Bruce</author>
</authors>
<title>Conversation Failure.</title>
<date>1981</date>
<booktitle>In Knowledge Representation and Natural Language Processing. W. Lehnart</booktitle>
<contexts>
<context position="16073" citStr="[22]" startWordPosition="2635" endWordPosition="2635">se excerpts). Each bracketed portion of the excerpt explains what was occurring at that point in the dialogue. The confusions themselves, coupled with the description at the end of this section on how to recognize when one of them is occurring, provides motivation for the use of the algorithm outlined in Section 3 as a means for repairing communication problems. We will only discuss referent confusion in this paper. The other forms of confusion - Action. Goal, and Cognitive Load - are described in [11. 13]. Another categorization of confusions that lead to conversation failure can be found in [22]. . Figure 2: A taxonomy of confusions Referent confusion occurs when the listener is unable to correctly determine what the speaker is referring to with a particular description. It occurs when the descriptions in the utterance are ambiguous or imprecise, when there is confusion between the speaker and listener about what the current focus or context is, or when the descriptions in the utterance are either incorrect or incompatible with the current or global context. Erroneous Specificity Ambiguous (and, thus, imprecise) descriptions can cause confusion about the referent. Excerpt 2 below ill</context>
</contexts>
<marker>[22]</marker>
<rawString>Ringle. Martin and Bertram Bruce. Conversation Failure. In Knowledge Representation and Natural Language Processing. W. Lehnart and M. Ringle, Ed..Lawrence Erlbaum Associates, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L</author>
<author>D J Israel</author>
</authors>
<title>Recognizing intended meaning and speaker&apos;s plans.</title>
<date>1981</date>
<booktitle>Proceedings of the International Joint Conference in Artificial Intelligence. The International Joint Conferences on Artificai Intelligence.</booktitle>
<pages>203--208</pages>
<location>Vancouver, B.C..</location>
<marker>[23]</marker>
<rawString>Sidner. C. L.. and Israel, D.J. Recognizing intended meaning and speaker&apos;s plans. Proceedings of the International Joint Conference in Artificial Intelligence. The International Joint Conferences on Artificai Intelligence. Vancouver, B.C.. August, 1981, pp. 203-208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Candace Lee Sidner</author>
</authors>
<title>Towards a Computational Theory of Definite Anaphora Comprehension in English Discourse.</title>
<date>1979</date>
<tech>Ph.D. Th.,</tech>
<publisher>MIT Al Lab.</publisher>
<institution>Massachusetts Institute of Technology,</institution>
<marker>[24]</marker>
<rawString>Sidner, Candace Lee. Towards a Computational Theory of Definite Anaphora Comprehension in English Discourse. Ph.D. Th., Massachusetts Institute of Technology, 1979. Also, Report No. TR-537. MIT Al Lab.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L M Bates</author>
<author>R J Bobrow</author>
<author>R J Brachman</author>
<author>P R Cohen</author>
<author>D J Israel</author>
<author>J Schmolze B L Webber W A Woods</author>
</authors>
<title>Research in Knowledge Representation for Natural Language Understanding.</title>
<date>1981</date>
<tech>Report No. 4785,</tech>
<institution>Bolt Beranek and Newman Inc.,</institution>
<contexts>
<context position="2792" citStr="[25, 28]" startWordPosition="418" endWordPosition="419">er has determining whom or what a speaker is talking about. We have written computer programs and algorithms that demonstrate how one could handle such problems in 1This ,esearcn wig supported in part by the Defense Advanced Research Project Agency under contract N00014-77— C—e378. the context of a natural language understanding system. The study of miscommunication is a necessary task within such a context since any computer capable of communicating with humans in natural language must be tolerant of the imprecise, ill-devised or complex utterances that people often use. Our current research [25, 28] views most dialogues as being cooperative and goal directed. i.e.. a speaker and listener work together to achieve a common goal. The interpretation of an utterance involves identifying the underlying plan or goal that the utterance reflects [5. 1. 231. This plan, however, is rarely, if ever, obvious at the surface sentence level. A central issue in the interpretation of utterances is the transformation of sequences of imprecise, illdevised or complex utterances into well-specified plans that might be carried out by dialogue participants. Within this context, miscommunication can occur. We ar</context>
</contexts>
<marker>[25]</marker>
<rawString>Sidner. C. L.. M. Bates, R. J. Bobrow, R. J. Brachman, P. R. Cohen, D. J. Israel, J. Schmolze. B. L. Webber. W. A. Woods. Research in Knowledge Representation for Natural Language Understanding. Report No. 4785, Bolt Beranek and Newman Inc., November, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ingria R Israel</author>
<author>D D McAllester</author>
<author>M Moser</author>
<author>J Schmolze</author>
<author>M Vilain</author>
</authors>
<date>1982</date>
<journal>Research in Knowledge Representation for Natural Language Understanding -Annual Report.</journal>
<booktitle>31</booktitle>
<tech>Technical Report 5421. BBN</tech>
<volume>1</volume>
<institution>Laboratories.</institution>
<location>Cambridge. MA,</location>
<contexts>
<context position="2792" citStr="[25, 28]" startWordPosition="418" endWordPosition="419">er has determining whom or what a speaker is talking about. We have written computer programs and algorithms that demonstrate how one could handle such problems in 1This ,esearcn wig supported in part by the Defense Advanced Research Project Agency under contract N00014-77— C—e378. the context of a natural language understanding system. The study of miscommunication is a necessary task within such a context since any computer capable of communicating with humans in natural language must be tolerant of the imprecise, ill-devised or complex utterances that people often use. Our current research [25, 28] views most dialogues as being cooperative and goal directed. i.e.. a speaker and listener work together to achieve a common goal. The interpretation of an utterance involves identifying the underlying plan or goal that the utterance reflects [5. 1. 231. This plan, however, is rarely, if ever, obvious at the surface sentence level. A central issue in the interpretation of utterances is the transformation of sequences of imprecise, illdevised or complex utterances into well-specified plans that might be carried out by dialogue participants. Within this context, miscommunication can occur. We ar</context>
</contexts>
<marker>[28]</marker>
<rawString>Sidner, C. L.. Bates, M., Bobrow, R.. Goodman, B.. Haas. A.. Ingria. R.. Israel, D., McAllester. D., Moser, M., Schmolze, J., Vilain. M. Research in Knowledge Representation for Natural Language Understanding -Annual Report. 1 September 1982 - 31 August 1983. Technical Report 5421. BBN Laboratories. Cambridge. MA, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Goodman B Haas C</author>
<author>M A Moser</author>
<author>Stallard D Vilain M</author>
</authors>
<title>Research in Knowledge Representation for Natural Language Understanding -Annual Report.</title>
<date>1983</date>
<tech>Technical Report 5694.</tech>
<volume>1</volume>
<pages>31</pages>
<institution>BBN Laboratories Inc.,</institution>
<location>Cambridge, MA.</location>
<contexts>
<context position="44920" citStr="[12, 27, 13]" startWordPosition="7542" endWordPosition="7544">lar candidate is selected, then deciding which features to relax is relatively trivial - one simply compares feature by feature between the candidate description (the target) and the speaker&apos;s description (the pattern) and notes any discrepancies. 212 that ordering to determine the order in which to try relaxing the candidates. We draw primarily on sources of linguistic knowledge, pragmatic knowledge, discourse knowledge. domain knowledge, perceptual knowledge, hierarchical knowledge, and trial and error knowledge during this repair process. A detailed treatment of all of them can be found in [12, 27, 13]. These knowledge sources are consulted to determine the feature ordering for relaxation. We represent information from each knowledge source as a set of relaxation rules. These rules are written in a PROLOG—like language. Figure 5 illustrates one such linguistic knowledge relaxation rule. This rule is motivated by the observation in the excerpts that speakers typically add more important information at the end of a description (where they are separated from the main part of the description and thus provided more emphasis). Since the syntactic constituents often at the end are relative clauses</context>
</contexts>
<marker>[27]</marker>
<rawString>Sidner. C., Goodman. B.. Haas, A., Moser. M., Stallard. D.. Vilain. M. Research in Knowledge Representation for Natural Language Understanding -Annual Report. 1 September 1983 - 31 August 1984. Technical Report 5694. BBN Laboratories Inc., Cambridge, MA. 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Lynn Webber</author>
</authors>
<title>A Formal Approach to Discourse Anaphora.</title>
<date>1978</date>
<tech>Ph.D. Th.,</tech>
<institution>Harvard University,</institution>
<contexts>
<context position="2792" citStr="[25, 28]" startWordPosition="418" endWordPosition="419">er has determining whom or what a speaker is talking about. We have written computer programs and algorithms that demonstrate how one could handle such problems in 1This ,esearcn wig supported in part by the Defense Advanced Research Project Agency under contract N00014-77— C—e378. the context of a natural language understanding system. The study of miscommunication is a necessary task within such a context since any computer capable of communicating with humans in natural language must be tolerant of the imprecise, ill-devised or complex utterances that people often use. Our current research [25, 28] views most dialogues as being cooperative and goal directed. i.e.. a speaker and listener work together to achieve a common goal. The interpretation of an utterance involves identifying the underlying plan or goal that the utterance reflects [5. 1. 231. This plan, however, is rarely, if ever, obvious at the surface sentence level. A central issue in the interpretation of utterances is the transformation of sequences of imprecise, illdevised or complex utterances into well-specified plans that might be carried out by dialogue participants. Within this context, miscommunication can occur. We ar</context>
</contexts>
<marker>[28]</marker>
<rawString>Webber, Bonnie Lynn. A Formal Approach to Discourse Anaphora. Ph.D. Th., Harvard University, 1978. Also, Technical Report No. 3761. Bolt Beranek and Newman Inc.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>