<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000105">
<title confidence="0.9967595">
Unsupervised Domain Relevance Estimation
for Word Sense Disambiguation
</title>
<note confidence="0.7089745">
Alfio Gliozzo and Bernardo Magnini and Carlo Strapparava
ITC-irst, Istituto per la Ricerca Scientifica e Tecnologica, I-38050 Trento, ITALY
</note>
<email confidence="0.936743">
{gliozzo, magnini, strappa}@itc.it
</email>
<sectionHeader confidence="0.996533" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999930304347826">
This paper presents Domain Relevance Estima-
tion (DRE), a fully unsupervised text categorization
technique based on the statistical estimation of the
relevance of a text with respect to a certain cate-
gory. We use a pre-defined set of categories (we
call them domains) which have been previously as-
sociated to WORDNET word senses. Given a cer-
tain domain, DRE distinguishes between relevant
and non-relevant texts by means of a Gaussian Mix-
ture model that describes the frequency distribution
of domain words inside a large-scale corpus. Then,
an Expectation Maximization algorithm computes
the parameters that maximize the likelihood of the
model on the empirical data.
The correct identification of the domain of the
text is a crucial point for Domain Driven Dis-
ambiguation, an unsupervised Word Sense Disam-
biguation (WSD) methodology that makes use of
only domain information. Therefore, DRE has been
exploited and evaluated in the context of a WSD
task. Results are comparable to those of state-of-
the-art unsupervised WSD systems and show that
DRE provides an important contribution.
</bodyText>
<sectionHeader confidence="0.998881" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9993975">
A fundamental issue in text processing and under-
standing is the ability to detect the topic (i.e. the do-
main) of a text or of a portion of it. Indeed, domain
detection allows a number of useful simplifications
in text processing applications, such as, for instance,
in Word Sense Disambiguation (WSD).
In this paper we introduce Domain Relevance Es-
timation (DRE) a fully unsupervised technique for
domain detection. Roughly speaking, DRE can be
viewed as a text categorization (TC) problem (Se-
bastiani, 2002), even if we do not approach the
problem in the standard supervised setting requir-
ing category labeled training data. In fact, recently,
unsupervised approaches to TC have received more
and more attention in the literature (see for example
(Ko and Seo, 2000).
We assume a pre-defined set of categories, each
defined by means of a list of related terms. We
call such categories domains and we consider them
as a set of general topics (e.g. SPORT, MEDICINE,
POLITICS) that cover the main disciplines and ar-
eas of human activity. For each domain, the list
of related words is extracted from WORDNET DO-
MAINS (Magnini and Cavagli`a, 2000), an extension
of WORDNET in which synsets are annotated with
domain labels. We have identified about 40 domains
(out of 200 present in WORDNET DOMAINS) and
we will use them for experiments throughout the pa-
per (see Table 1).
DRE focuses on the problem of estimating a de-
gree of relatedness of a certain text with respect to
the domains in WORDNET DOMAINS.
The basic idea underlying DRE is to combine the
knowledge in WORDNET DOMAINS and a proba-
bilistic framework which makes use of a large-scale
corpus to induce domain frequency distributions.
Specifically, given a certain domain, DRE considers
frequency scores for both relevant and non-relevant
texts (i.e. texts which introduce noise) and represent
them by means of a Gaussian Mixture model. Then,
an Expectation Maximization algorithm computes
the parameters that maximize the likelihood of the
empirical data.
DRE methodology originated from the effort to
improve the performance of Domain Driven Dis-
ambiguation (DDD) system (Magnini et al., 2002).
DDD is an unsupervised WSD methodology that
makes use of only domain information. DDD as-
signes the right sense of a word in its context com-
paring the domain of the context to the domain of
each sense of the word. This methodology exploits
WORDNET DOMAINS information to estimate both
</bodyText>
<table confidence="0.9915435">
Domain #Syn Domain #Syn Domain #Syn
Factotum 36820 Biology 21281 Earth 4637
Psychology 3405 Architecture 3394 Medicine 3271
Economy 3039 Alimentation 2998 Administration 2975
Chemistry 2472 Transport 2443 Art 2365
Physics 2225 Sport 2105 Religion 2055
Linguistics 1771 Military 1491 Law 1340
History 1264 Industry 1103 Politics 1033
Play 1009 Anthropology 963 Fashion 937
Mathematics 861 Literature 822 Engineering 746
Sociology 679 Commerce 637 Pedagogy 612
Publishing 532 Tourism 511 Computer Science 509
Telecommunication 493 Astronomy 477 Philosophy 381
Agriculture 334 Sexuality 272 Body Care 185
Artisanship 149 Archaeology 141 Veterinary 92
Astrology 90
</table>
<tableCaption confidence="0.999845">
Table 1: Domain distribution over WORDNET synsets.
</tableCaption>
<bodyText confidence="0.999675761904762">
the domain of the textual context and the domain of
the senses of the word to disambiguate. The former
operation is intrinsically an unsupervised TC task,
and the category set used has to be the same used
for representing the domain of word senses.
Since DRE makes use of a fixed set of target cat-
egories (i.e. domains) and since a document col-
lection annotated with such categories is not avail-
able, evaluating the performance of the approach is
a problem in itself. We have decided to perform an
indirect evaluation using the DDD system, where
unsupervised TC plays a crucial role.
The paper is structured as follows. Section 2
introduces WORDNET DOMAINS, the lexical re-
source that provides the underlying knowledge to
the DRE technique. In Section 3 the problem of es-
timating domain relevance for a text is introduced.
In particular, Section 4 briefly sketchs the WSD sys-
tem used for evaluation. Finally, Section 5 describes
a number of evaluation experiments we have carried
out.
</bodyText>
<sectionHeader confidence="0.889571" genericHeader="method">
2 Domains, WORDNET and Texts
</sectionHeader>
<bodyText confidence="0.999769043478261">
DRE heavily relies on domain information as its
main knowledge source. Domains show interesting
properties both from a lexical and a textual point of
view. Among these properties there are: (i) lexi-
cal coherence, since part of the lexicon of a text is
composed of words belonging to the same domain;
(ii) polysemy reduction, because the potential am-
biguity of terms is sensibly lower if the domain of
the text is specified; and (iii) lexical identifiability
of text’s domain, because it is always possible to as-
sign one or more domains to a given text by consid-
ering term distributions in a bag-of-words approach.
Experimental evidences of these properties are re-
ported in (Magnini et al., 2002).
In this section we describe WORDNET DO-
MAINS1 (Magnini and Cavagli`a, 2000), a lexical re-
source that attempts a systematization of relevant
aspects in domain organization and representation.
WORDNET DOMAINS is an extension of WORD-
NET (version 1.6) (Fellbaum, 1998), in which each
synset is annotated with one or more domain la-
bels, selected from a hierarchically organized set of
about two hundred labels. In particular, issues con-
cerning the “completeness” of the domain set, the
“balancing” among domains and the “granularity”
of domain distinctions, have been addressed. The
domain set used in WORDNET DOMAINS has been
extracted from the Dewey Decimal Classification
(Comaroni et al., 1989), and a mapping between the
two taxonomies has been computed in order to en-
sure completeness. Table 2 shows how the senses
for a word (i.e. the noun bank) have been associated
to domain label; the last column reports the number
of occurrences of each sense in Semcor2.
Domain labeling is complementary to informa-
tion already present in WORDNET. First of all,
a domain may include synsets of different syn-
tactic categories: for instance MEDICINE groups
together senses from nouns, such as doctor#1
and hospital#1, and from verbs, such as
operate#7. Second, a domain may include
senses from different WORDNET sub-hierarchies
(i.e. deriving from different “unique beginners” or
from different “lexicographer files”). For example,
SPORT contains senses such as athlete#1, deriv-
ing from life form#1, game equipment#1
</bodyText>
<footnote confidence="0.9013186">
from physical object#1, sport#1
1WORDNET DOMAINS is freely available at
http://wndomains.itc.it
2SemCor is a portion of the Brown corpus in which words
are annotated with WORDNET senses.
</footnote>
<note confidence="0.597055">
Sense Synset and Gloss Domains Semcor frequencies
</note>
<tableCaption confidence="0.795185">
#1 depository financial institution, bank, banking con- ECONOMY 20
cern, banking company (a financial institution... )
#2 bank (sloping land... ) GEOGRAPHY, GEOLOGY 14
#3 bank (a supply or stock held in reserve... ) ECONOMY -
#4 bank, bank building (a building... ) ARCHITECTURE, ECONOMY -
#5 bank (an arrangement of similar objects...) FACTOTUM 1
#6 savings bank, coin bank, money box, bank (a con- ECONOMY -
tainer...)
#7 bank (a long ridge or pile... ) GEOGRAPHY, GEOLOGY 2
#8 bank (the funds held by a gambling house...) ECONOMY, PLAY
#9 bank, cant, camber (a slope in the turn of a road... ) ARCHITECTURE -
#10 bank (a flight maneuver... ) TRANSPORT -
Table 2: WORDNET senses and domains for the word “bank”.
</tableCaption>
<bodyText confidence="0.988323095238095">
from act#2, and playing field#1 from
location#1.
Domains may group senses of the same word
into thematic clusters, which has the important side-
effect of reducing the level of ambiguity when we
are disambiguating to a domain. Table 2 shows
an example. The word “bank” has ten differ-
ent senses in WORDNET 1.6: three of them (i.e.
bank#1, bank#3 and bank#6) can be grouped
under the ECONOMY domain, while bank#2 and
bank#7 both belong to GEOGRAPHY and GEOL-
OGY. Grouping related senses is an emerging topic
in WSD (see, for instance (Palmer et al., 2001)).
Finally, there are WORDNET synsets that do not
belong to a specific domain, but rather appear in
texts associated with any domain. For this reason,
a FACTOTUM label has been created that basically
includes generic synsets, which appear frequently
in different contexts. Thus the FACTOTUM domain
can be thought of as a “placeholder” for all other
domains.
</bodyText>
<sectionHeader confidence="0.97725" genericHeader="method">
3 Domain Relevance Estimation for Texts
</sectionHeader>
<bodyText confidence="0.999956807692308">
The basic idea of domain relevance estimation for
texts is to exploit lexical coherence inside texts.
From the domain point of view lexical coherence
is equivalent to domain coherence, i.e. the fact that
a great part of the lexicon inside a text belongs to
the same domain.
From this observation follows that a simple
heuristic to approach this problem is counting the
occurrences of domain words for every domain in-
side the text: the higher the percentage of domain
words for a certain domain, the more relevant the
domain will be for the text. In order to perform this
operation the WORDNET DOMAINS information is
exploited, and each word is assigned a weighted list
of domains considering the domain annotation of
its synsets. In addition, we would like to estimate
the domain of the text locally. Local estimation
of domain relevance is very important in order to
take into account domain shifts inside the text. The
methodology used to estimate domain frequency is
described in subsection 3.1.
Unfortunately the simple local frequency count
is not a good domain relevance measure for sev-
eral reasons. The most significant one is that very
frequent words have, in general, many senses be-
longing to different domains. When words are used
in texts, ambiguity tends to disappear, but it is not
possible to assume knowing their actual sense (i.e.
the sense in which they are used in the context) in
advance, especially in a WSD framework. The sim-
ple frequency count is then inadequate for relevance
estimation: irrelevant senses of ambiguous words
contribute to augment the final score of irrelevant
domains, introducing noise. The level of noise is
different for different domains because of their dif-
ferent sizes and possible differences in the ambigu-
ity level of their vocabularies.
In subsection 3.2 we propose a solution for that
problem, namely the Gaussian Mixture (GM) ap-
proach. This constitutes an unsupervised way to es-
timate how to differentiate relevant domain infor-
mation in texts from noise, because it requires only
a large-scale corpus to estimate parameters in an
Expectation Maximization (EM) framework. Using
the estimated parameters it is possible to describe
the distributions of both relevant and non-relevant
texts, converting the DRE problem into the problem
of estimating the probability of each domain given
its frequency score in the text, in analogy to the
bayesian classification framework. Details about
the EM algorithm for GM model are provided in
subsection 3.3.
</bodyText>
<subsectionHeader confidence="0.998814">
3.1 Domain Frequency Score
</subsectionHeader>
<bodyText confidence="0.999781">
Let t E T, be a text in a corpus T composed by a list
of words wt1,... , wtq. Let D = {D1, D2, ..., Dd} be
</bodyText>
<equation confidence="0.62601775">
1/|Dom(s) |if D E Dom(s)
1/d if Dom(s) = {FACTOTUM}
0 otherwise
(2)
</equation>
<bodyText confidence="0.99973675">
the set of domains used. For each domain Dk the
domain “frequency” score is computed in a window
of c words around wtj. The domain frequency score
is defined by formula (1).
</bodyText>
<equation confidence="0.533146">
Rword(Dk, wt i)G(i, j, ( c2)2) (1)
</equation>
<bodyText confidence="0.9999476">
where the weight factor G(x, µ, Q2) is the density
of the normal distribution with mean µ and standard
deviation Q at point x and Rword(D, w) is a function
that return the relevance of a domain D for a word
w (see formula 3). In the rest of the paper we use the
notation F(Dk, t) to refer to F(Dk, t, m), where m
is the integer part of q/2 (i.e. the “central” point of
the text - q is the text length).
Here below we see that the information contained
in WORDNET DOMAINS can be used to estimate
Rword(Dk, w), i.e. domain relevance for the word
w, which is derived from the domain relevance of
the synsets in which w appears.
As far as synsets are concerned, domain informa-
tion is represented by the function Dom : 5 ==&gt;-
P(D)3 that returns, for each synset s E 5, where
S is the set of synsets in WORDNET DOMAINS, the
set of the domains associated to it. Formula (2) de-
fines the domain relevance estimation function (re-
member that d is the cardinality of D):
</bodyText>
<equation confidence="0.851981">
Rsyn(D, s) =
</equation>
<bodyText confidence="0.9684545">
Intuitively, Rsyn(D, s) can be perceived as an es-
timated prior for the probability of the domain given
the concept, as expressed by the WORDNET DO-
MAINS annotation. Under these settings FACTO-
TUM (generic) concepts have uniform and low rel-
evance values for each domain while domain con-
cepts have high relevance values for a particular do-
main.
The definition of domain relevance for a word is
derived directly from the one given for concepts. In-
tuitively a domain D is relevant for a word w if D
is relevant for one or more senses c of w. More
formally let V = {w1, w2, ...w|V |} be the vocab-
ulary, let senses(w) = {s|s E 5, s is a sense of
w} (e.g. any synset in WORDNET containing the
word w). The domain relevance function for a word
</bodyText>
<equation confidence="0.96171775">
R : D x V ==&gt;. [0, 1] is defined as follows:
1
Rword(Di, w) =
|senses(w)|
</equation>
<bodyText confidence="0.928844">
3P(D) denotes the power set of D
</bodyText>
<subsectionHeader confidence="0.998587">
3.2 The Gaussian Mixture Algorithm
</subsectionHeader>
<bodyText confidence="0.999948326530613">
As explained at the beginning of this section, the
simple local frequency count expressed by formula
(1) is not a good domain relevance measure.
In order to discriminate between noise and rel-
evant information, a supervised framework is typ-
ically used and significance levels for frequency
counts are estimated from labeled training data. Un-
fortunately this is not our case, since no domain
labeled text corpora are available. In this section
we propose a solution for that problem, namely the
Gaussian Mixture approach, that constitutes an un-
supervised way to estimate how to differentiate rel-
evant domain information in texts from noise. The
Gaussian Mixture approach consists of a parameter
estimation technique based on statistics of word dis-
tribution in a large-scale corpus.
The underlying assumption of the Gaussian Mix-
ture approach is that frequency scores for a cer-
tain domain are obtained from an underlying mix-
ture of relevant and non-relevant texts, and that the
scores for relevant texts are significantly higher than
scores obtained for the non-relevant ones. In the
corpus these scores are distributed according to two
distinct components. The domain frequency distri-
bution which corresponds to relevant texts has the
higher value expectation, while the one pertaining to
non relevant texts has the lower expectation. Figure
1 describes the probability density function (PDF)
for domain frequency scores of the SPORT domain
estimated on the BNC corpus4 (BNC-Consortium,
2000) using formula (1). The “empirical” PDF,
describing the distribution of frequency scores eval-
uated on the corpus, is represented by the continu-
ous line.
From the graph it is possible to see that the empir-
ical PDF can be decomposed into the sum of two
distributions, D = SPORT and D = “non-SPORT”.
Most of the probability is concentrated on the left,
describing the distribution for the majority of non
relevant texts; the smaller distribution on the right
is assumed to be the distribution of frequency scores
for the minority of relevant texts.
Thus, the distribution on the left describes the
noise present in frequency estimation counts, which
is produced by the impact of polysemous words
and of occasional occurrences of terms belonging
to SPORT in non-relevant texts. The goal of the
technique is to estimate parameters describing the
distribution of the noise along texts, in order to as-
</bodyText>
<footnote confidence="0.963018">
4The British National Corpus is a very large (over 100 mil-
lion words) corpus of modern English, both spoken and written.
</footnote>
<equation confidence="0.88077425">
j+c
F(Dk, t, j) = E
i=j−c
E Rsyn(Di, s) (3)
</equation>
<page confidence="0.397092">
sEsenses(w)
</page>
<figure confidence="0.997134818181818">
0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04
F(D, t)
density function
200
150
100
50
0
Density
Non-relevant
Relevant
</figure>
<figureCaption confidence="0.999983">
Figure 1: Gaussian mixture for D = SPORT
</figureCaption>
<bodyText confidence="0.999926058823529">
sociate high relevance values only to relevant fre-
quency scores (i.e. frequency scores that are not re-
lated to noise). It is reasonable to assume that such
noise is normally distributed because it can be de-
scribed by a binomial distribution in which the prob-
ability of the positive event is very low and the num-
ber of events is very high. On the other hand, the
distribution on the right is the one describing typical
frequency values for relevant texts. This distribution
is also assumed to be normal.
A probabilistic interpretation permits the evalu-
ation of the relevance value R(D, t, j) of a certain
domain D for a new text t in a position j only by
considering the domain frequency F (D, t, j). The
relevance value is defined as the conditional prob-
ability P(D|F(D, t, j)). Using Bayes theorem we
estimate this probability by equation (4).
</bodyText>
<subsectionHeader confidence="0.998106">
3.3 The EM Algorithm for the GM model
</subsectionHeader>
<bodyText confidence="0.999918333333333">
In this section some details about the algorithm for
parameter estimation are reported.
It is well known that a Gaussian mixture (GM)
allows to represent every smooth PDF as a linear
combination of normal distributions of the type in
formula 5
</bodyText>
<equation confidence="0.920855">
p(x|0) = �m ajG(x, µj, Qj) (5)
j=1
with
aj &gt; 0 and �m aj = 1 (6)
j=1
and
(7)
.\/27rQ
</equation>
<bodyText confidence="0.9995171875">
and 0 = (a1, µ1, Q1, ... , am, µm, Qm) is a pa-
rameter list describing the gaussian mixture. The
number of components required by the Gaussian
Mixture algorithm for domain relevance estimation
is m = 2.
Each component j is univocally determined by its
weight aj, its mean µj and its variance Qj. Weights
represent also the areas of each component, i.e. its
total probability.
The Gaussian Mixture algorithm for domain rele-
vance estimation exploits a Gaussian Mixture to ap-
proximate the empirical PDF of domain frequency
scores. The goal of the Gaussian Mixture algorithm
is to find the GM that maximize the likelihood on
the empirical data, where the likelihood function is
evaluated by formula (8).
</bodyText>
<equation confidence="0.999701285714286">
1 − (x−µ)2
G(x, µ, Q) =
e 22
R(D, t, j) = P(DjF(D, t, j)) = (4) L(T , D, 0) = � p(F(D,t)|0) (8)
tET
= P(F(D,t, j)jD)P(D)
P(F(D, t, j)ID)P(D) + P(F(D, t, j)ID)P(D)
</equation>
<bodyText confidence="0.993251666666667">
where P(F(D, t, j)|D) is the value of the PDF
describing D calculated in the point F(D, t, j),
P(F(D, t, j)|D) is the value of the PDF describ-
ing D, P(D) is the area of the distribution describ-
ing D and P(D) is the area of the distribution for
D.
In order to estimate the parameters describing the
PDF of D and D the Expectation Maximization
(EM) algorithm for the Gaussian Mixture Model
(Redner and Walker, 1984) is exploited. Assuming
to model the empirical distribution of domain fre-
quencies using a Gaussian mixture of two compo-
nents, the estimated parameters can be used to eval-
uate domain relevance by equation (4).
More formally, the EM algorithm for GM models
explores the space of parameters in order to find the
set of parameters 0 such that the maximum likeli-
hood criterion (see formula 9) is satisfied.
</bodyText>
<equation confidence="0.9991245">
0D = argmax
0/ L(T , D, 0&apos;) (9)
</equation>
<bodyText confidence="0.999956636363637">
This condition ensures that the obtained model
fits the original data as much as possible. Estima-
tion of parameters is the only information required
in order to evaluate domain relevance for texts us-
ing the Gaussian Mixture algorithm. The Expecta-
tion Maximization Algorithm for Gaussian Mixture
Models (Redner and Walker, 1984) allows to effi-
ciently perform this operation.
The strategy followed by the EM algorithm is
to start from a random set of parameters 00, that
has a certain initial likelihood value L0, and then
iteratively change them in order to augment like-
lihood at each step. To this aim the EM algo-
rithm exploits a growth transformation of the like-
lihood function () =  such that L(T , D, ) S
L(T , D, ). Applying iteratively this transforma-
tion starting from 0 a sequence of parameters is
produced, until the likelihood function achieve a
stable value (i.e. Li+1 − Li S ). In our settings
the transformation function  is defined by the fol-
lowing set of equations, in which all the parameters
have to be solved together.
</bodyText>
<equation confidence="0.971390066666667">
() = ((a1, µ1, 1, a2, µ2, 2)) (10)
= (a1, µ1, 1, a2, µ2, 2)
a = 1 |T  |ajG(F(D,tk),µj,j) (11)
|T  |� p(F(D, tk), )
|T  |ajG(F(D,tk),µj,j)
FD t
Ek=1 F( D, p(F(D,tk),) 12
µj =|T  |ajG(F(D,tk),µj,j) ( )
�k=1 p(F(D,tk),)
�|T |
k=1 (F(D, tk) − µj)2 aiG(F (D,tk),µi,i)
p(F (D,tk),)
�|T  |ajG(F(D,tk),µj,j)
k=1 p(F(D,tk),)
(13)
</equation>
<bodyText confidence="0.999831181818182">
As said before, in order to estimate distribu-
tion parameters the British National Corpus (BNC-
Consortium, 2000) was used. Domain frequency
scores have been evaluated on the central position
of each text (using equation 1, with c = 50).
In conclusion, the EM algorithm was used to es-
timate parameters to describe distributions for rele-
vant and non-relevant texts. This learning method
is totally unsupervised. Estimated parameters has
been used to estimate relevance values by formula
(4).
</bodyText>
<sectionHeader confidence="0.994852" genericHeader="method">
4 Domain Driven Disambiguation
</sectionHeader>
<bodyText confidence="0.994252542857143">
DRE originates to improve the performance of Do-
main Driven Disambiguation (DDD). In this sec-
tion, a brief overview of DDD is given. DDD is a
WSD methodology that only makes use of domain
information. Originally developed to test the role of
domain information for WSD, the system is capable
to achieve a good precision disambiguation. Its re-
sults are affected by a low recall, motivated by the
fact that domain information is sufficient to disam-
biguate only “domain words”. The disambiguation
process is done comparing the domain of the con-
text and the domains of each sense of the lemma to
disambiguate. The selected sense is the one whose
domain is relevant for the context5.
In order to represent domain information we in-
troduced the notion of Domain Vectors (DV), that
are data structures that collect domain information.
These vectors are defined in a multidimensional
space, in which each domain represents a dimen-
sion of the space. We distinguish between two kinds
of DVs: (i) synset vectors, which represent the rel-
evance of a synset with respect to each considered
domain and (ii) text vectors, which represent the rel-
evance of a portion of text with respect to each do-
main in the considered set.
More formally let D = {D1, D2,..., Dd} be the
set of domains, the domain vector s for a synset s
is defined as (R(D1, s), R(D2, s), ... , R(Dd, s))
where R(Di, s) is evaluated using equation
(2). In analogy the domain vector tj for
a text t in a given position j is defined as
(R(D1, t, j), R(D2, t, j), ... , R(Dd, t, j)) where
R(Di, t, j) is evaluated using equation (4).
The DDD methodology is performed basically in
three steps:
</bodyText>
<listItem confidence="0.916871666666667">
1. Compute t� for the context t of the word w to be disam-
biguated
2. Compute sˆ = argmaxsESenses(w)score(s, w, t) where
</listItem>
<equation confidence="0.985455">
P(s|w) · sim(s,�t)
score(s,w, t) =
</equation>
<bodyText confidence="0.984357846153846">
5Recent works in WSD demonstrate that an automatic es-
timation of domain relevance for texts can be profitable used
to disambiguate words in their contexts. For example, (Escud-
ero et al., 2001) used domain relevance extraction techniques
to extract features for a supervised WSD algorithm presented
at the Senseval-2 competion, improving the system accuracy of
about 4 points for nouns, 1 point for verbs and 2 points for ad-
jectives, confirming the original intuition that domain informa-
tion is very useful to disambiguate “domain words”, i.e. words
which are strongly related to the domain of the text.
6Admittedly, this may be regarded as a supervised compo-
nent of the generally unsupervised system. Yet, we considered
this component as legitimate within an unsupervised frame-
</bodyText>
<equation confidence="0.8718755">
j =
EsESenses(w) P(s|w) · sim(S,t�
</equation>
<bodyText confidence="0.968228619047619">
3. if score(ˆs, w, t) &gt;, k (where k E [0, 1] is a confidence
threshold) select sense ˆs, else do not provide any answer
The similarity metric used is the cosine vector
similarity, which takes into account only the direc-
tion of the vector (i.e. the information regarding the
domain).
P(s|w) describes the prior probability of sense
s for word w, and depends on the distribution of
the sense annotations in the corpus. It is esti-
mated by statistics from a sense tagged corpus (we
used SemCor)6 or considering the sense order in
WORDNET, which roughly corresponds to sense
frequency order, when no example of the word
to disambiguate are contained in SemCor. In the
former case the estimation of P(slw) is based on
smoothed statistics from the corpus (P(slw) =
occ(s,w)+
occ(w)+|senses(w)|·, where A is a smoothing fac-
tor empirically determined). In the latter case
P(slw) can be estimated in an unsupervised way
considering the order of senses in WORDNET
</bodyText>
<equation confidence="0.932264">
(P(s|w) = 2(|senses(w)|−sensenumber(s,w)+1)
|senses(w)|(|senses(w)|+1) where
</equation>
<bodyText confidence="0.6975575">
sensenumber(s, w) returns the position of sense
s of word w in the sense list for w provided by
WORDNET.
Precision
</bodyText>
<sectionHeader confidence="0.94779" genericHeader="evaluation">
5 Evaluation in a WSD task
</sectionHeader>
<bodyText confidence="0.99934852631579">
We used the WSD framework to perform an evalu-
ation of the DRE technique by itself.
As explained in Section 1 Domain Relevance Es-
timation is not a common Text Categorization task.
In the standard framework of TC, categories are
learned form examples, that are used also for test.
In our case information in WORDNET DOMAINS is
used to discriminate, and a test set, i.e. a corpus of
texts categorized using the domain of WORDNET
DOMAINS, is not available. To evaluate the accu-
racy of the domain relevance estimation technique
described above is thus necessary to perform an in-
direct evaluation.
We evaluated the DDD algorithm described in
Section 4 using the dataset of the Senseval-2 all-
words task (Senseval-2, 2001; Preiss and Yarowsky,
2002). In order to estimate domain vectors for the
contexts of the words to disambiguate we used the
DRE methodology described in Section 3. Varying
the confidence threshold k, as described in Section
4, it is possible to change the tradeoff between preci-
sion and recall. The obtained precision-recall curve
of the system is reported in Figure 2.
In addition we evaluated separately the perfor-
mance on nouns and verbs, suspecting that nouns
are more “domain oriented” than verbs. The effec-
tiveness of DDD to disambiguate domain words is
confirmed by results reported in Figure 3, in which
the precision recall curve is reported separately for
both nouns and verbs. The performances obtained
for nouns are sensibly higher than the one obtained
for verbs, confirming the claim that domain infor-
mation is crucial to disambiguate domain words.
In Figure 2 we also compare the results ob-
tained by the DDD system that make use of the
DRE technique described in Section 3 with the re-
work since it relies on a general resource (SemCor) that does
not correspond to the test data (Senseval all-words task).
</bodyText>
<figure confidence="0.9187455">
0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6
Recall
</figure>
<figureCaption confidence="0.975502">
Figure 2: Performances of the system for all POS
</figureCaption>
<figure confidence="0.987527">
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7
Recall
</figure>
<figureCaption confidence="0.9487255">
Figure 3: Performances of the system for Nouns and
Verbs
</figureCaption>
<bodyText confidence="0.999915368421053">
sults obtained by the DDD system presented at the
Senseval-2 competition described in (Magnini et al.,
2002), that is based on the same DDD methodol-
ogy and exploit a DRE technique that consists ba-
sically on the simply domain frequency scores de-
scribed in subsection 3.1 (we refer to this system
using the expression old-DDD, in contrast to the ex-
pression new-DDD that refers to the implementation
described in this paper).
Old-DDD obtained 75% precision and 35% re-
call on the official evaluation at the Senseval-2 En-
glish all words task. At 35% of recall the new-DDD
achieves a precision of 79%, improving precision
by 4 points with respect to old-DDD. At 75% pre-
cision the recall of new-DDD is 40%. In both cases
the new domain relevance estimation technique im-
proves the performance of the DDD methodology,
demonstrating the usefulness of the DRE technique
proposed in this paper.
</bodyText>
<figure confidence="0.9995165">
DDD new
DDD old
Precision
0.85
0.75
0.65
0.55
0.45
0.8
0.7
0.6
0.5
0.4
Nouns
Verbs
0.95
0.9
0.85
0.8
0.75
0.7
0.65
0.6
0.55
</figure>
<sectionHeader confidence="0.945696" genericHeader="conclusions">
6 Conclusions and Future Works
</sectionHeader>
<bodyText confidence="0.999079411764706">
Domain Relevance Estimation, an unsupervised TC
technique, has been proposed and evaluated in-
side the Domain Driven Disambiguation frame-
work, showing a significant improvement on the
overall system performances. This technique also
allows a clear probabilistic interpretation providing
an operative definition of the concept of domain rel-
evance. During the learning phase annotated re-
sources are not required, allowing a low cost imple-
mentation. The portability of the technique to other
languages is allowed by the usage of synset-aligned
wordnets, being domain annotation language inde-
pendent.
As far as the evaluation of DRE is concerned, for
the moment we have tested its usefulness in the con-
text of a WSD task, but we are going deeper, con-
sidering a pure TC framework.
</bodyText>
<sectionHeader confidence="0.999024" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999809">
We would like to thank Ido Dagan and Marcello
Federico for many useful discussions and sugges-
tions.
</bodyText>
<sectionHeader confidence="0.999429" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999825688888889">
BNC-Consortium. 2000. British national corpus,
http://www.hcu.ox.ac.uk/BNC/.
J. P. Comaroni, J. Beall, W. E. Matthews, and G. R.
New, editors. 1989. Dewey Decimal Classifica-
tion and Relative Index. Forest Press, Albany,
New York, 20th edition.
G. Escudero, L. M`arquez, and G. Rigau. 2001.
Using lazy boosting for word sense disambigua-
tion. In Proc. of SENSEUAL-2 Second Inter-
national Workshop on Evaluating Word Sense
Disambiguation System, pages 71–74, Toulose,
France, July.
C. Fellbaum. 1998. WordNet. An Electronic Lexical
Database. The MIT Press.
Y. Ko and J. Seo. 2000. Automatic text categoriza-
tion by unsupervised learning. In Proceedings of
COLING-00, the 18th International Conference
on Computational Linguistics, Saarbr¨ucken, Ger-
many.
B. Magnini and G. Cavagli`a. 2000. Integrating sub-
ject field codes into WordNet. In Proceedings
of LREC-2000, Second International Conference
on Language Resources and Evaluation, Athens,
Greece, June.
B. Magnini, C. Strapparava, G. Pezzulo, and
A. Gliozzo. 2002. The role of domain informa-
tion in word sense disambiguation. Natural Lan-
guage Engineering, 8(4):359–373.
M. Palmer, C. Fellbaum, S. Cotton, L. Delfs, and
H.T. Dang. 2001. English tasks: All-words
and verb lexical sample. In Proceedings of
SENSEUAL-2, Second International Workshop on
Evaluating Word Sense Disambiguation Systems,
Toulouse, France, July.
J. Preiss and D. Yarowsky, editors. 2002. Pro-
ceedings of SENSEUAL-2: Second International
Workshop on Evaluating Word Sense Disam-
biguation Systems, Toulouse, France.
R. Redner and H. Walker. 1984. Mixture densi-
ties, maximum likelihood and the EM algorithm.
SIAM Review, 26(2):195–239, April.
F. Sebastiani. 2002. Machine learning in auto-
mated text categorization. ACM Computing Sur-
veys, 34(1):1–47.
Senseval-2. 2001. http://www.senseval.org.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.710830">
<title confidence="0.9971165">Unsupervised Domain Relevance for Word Sense Disambiguation</title>
<author confidence="0.968051">Alfio Gliozzo</author>
<author confidence="0.968051">Bernardo Magnini</author>
<author confidence="0.968051">Carlo</author>
<affiliation confidence="0.958069">ITC-irst, Istituto per la Ricerca Scientifica e Tecnologica, I-38050 Trento,</affiliation>
<email confidence="0.778686">magnini,</email>
<abstract confidence="0.999261083333333">paper presents Relevance Estimaa fully unsupervised text categorization technique based on the statistical estimation of the relevance of a text with respect to a certain category. We use a pre-defined set of categories (we them which have been previously asto senses. Given a certain domain, DRE distinguishes between relevant and non-relevant texts by means of a Gaussian Mixture model that describes the frequency distribution of domain words inside a large-scale corpus. Then, an Expectation Maximization algorithm computes the parameters that maximize the likelihood of the model on the empirical data. The correct identification of the domain of the text is a crucial point for Domain Driven Disambiguation, an unsupervised Word Sense Disambiguation (WSD) methodology that makes use of only domain information. Therefore, DRE has been exploited and evaluated in the context of a WSD task. Results are comparable to those of state-ofthe-art unsupervised WSD systems and show that DRE provides an important contribution.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>BNC-Consortium</author>
</authors>
<date>2000</date>
<note>British national corpus, http://www.hcu.ox.ac.uk/BNC/.</note>
<contexts>
<context position="15856" citStr="BNC-Consortium, 2000" startWordPosition="2618" endWordPosition="2619">a certain domain are obtained from an underlying mixture of relevant and non-relevant texts, and that the scores for relevant texts are significantly higher than scores obtained for the non-relevant ones. In the corpus these scores are distributed according to two distinct components. The domain frequency distribution which corresponds to relevant texts has the higher value expectation, while the one pertaining to non relevant texts has the lower expectation. Figure 1 describes the probability density function (PDF) for domain frequency scores of the SPORT domain estimated on the BNC corpus4 (BNC-Consortium, 2000) using formula (1). The “empirical” PDF, describing the distribution of frequency scores evaluated on the corpus, is represented by the continuous line. From the graph it is possible to see that the empirical PDF can be decomposed into the sum of two distributions, D = SPORT and D = “non-SPORT”. Most of the probability is concentrated on the left, describing the distribution for the majority of non relevant texts; the smaller distribution on the right is assumed to be the distribution of frequency scores for the minority of relevant texts. Thus, the distribution on the left describes the noise</context>
</contexts>
<marker>BNC-Consortium, 2000</marker>
<rawString>BNC-Consortium. 2000. British national corpus, http://www.hcu.ox.ac.uk/BNC/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J P Comaroni</author>
<author>J Beall</author>
<author>W E Matthews</author>
<author>G R</author>
</authors>
<title>Dewey Decimal Classification and Relative Index.</title>
<date>1989</date>
<editor>New, editors.</editor>
<publisher>Forest Press,</publisher>
<location>Albany, New York,</location>
<contexts>
<context position="6901" citStr="Comaroni et al., 1989" startWordPosition="1096" endWordPosition="1099">000), a lexical resource that attempts a systematization of relevant aspects in domain organization and representation. WORDNET DOMAINS is an extension of WORDNET (version 1.6) (Fellbaum, 1998), in which each synset is annotated with one or more domain labels, selected from a hierarchically organized set of about two hundred labels. In particular, issues concerning the “completeness” of the domain set, the “balancing” among domains and the “granularity” of domain distinctions, have been addressed. The domain set used in WORDNET DOMAINS has been extracted from the Dewey Decimal Classification (Comaroni et al., 1989), and a mapping between the two taxonomies has been computed in order to ensure completeness. Table 2 shows how the senses for a word (i.e. the noun bank) have been associated to domain label; the last column reports the number of occurrences of each sense in Semcor2. Domain labeling is complementary to information already present in WORDNET. First of all, a domain may include synsets of different syntactic categories: for instance MEDICINE groups together senses from nouns, such as doctor#1 and hospital#1, and from verbs, such as operate#7. Second, a domain may include senses from different W</context>
</contexts>
<marker>Comaroni, Beall, Matthews, R, 1989</marker>
<rawString>J. P. Comaroni, J. Beall, W. E. Matthews, and G. R. New, editors. 1989. Dewey Decimal Classification and Relative Index. Forest Press, Albany, New York, 20th edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Escudero</author>
<author>L M`arquez</author>
<author>G Rigau</author>
</authors>
<title>Using lazy boosting for word sense disambiguation.</title>
<date>2001</date>
<booktitle>In Proc. of SENSEUAL-2 Second International Workshop on Evaluating Word Sense Disambiguation System,</booktitle>
<pages>71--74</pages>
<location>Toulose, France,</location>
<marker>Escudero, M`arquez, Rigau, 2001</marker>
<rawString>G. Escudero, L. M`arquez, and G. Rigau. 2001. Using lazy boosting for word sense disambiguation. In Proc. of SENSEUAL-2 Second International Workshop on Evaluating Word Sense Disambiguation System, pages 71–74, Toulose, France, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet. An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="6472" citStr="Fellbaum, 1998" startWordPosition="1031" endWordPosition="1032">l ambiguity of terms is sensibly lower if the domain of the text is specified; and (iii) lexical identifiability of text’s domain, because it is always possible to assign one or more domains to a given text by considering term distributions in a bag-of-words approach. Experimental evidences of these properties are reported in (Magnini et al., 2002). In this section we describe WORDNET DOMAINS1 (Magnini and Cavagli`a, 2000), a lexical resource that attempts a systematization of relevant aspects in domain organization and representation. WORDNET DOMAINS is an extension of WORDNET (version 1.6) (Fellbaum, 1998), in which each synset is annotated with one or more domain labels, selected from a hierarchically organized set of about two hundred labels. In particular, issues concerning the “completeness” of the domain set, the “balancing” among domains and the “granularity” of domain distinctions, have been addressed. The domain set used in WORDNET DOMAINS has been extracted from the Dewey Decimal Classification (Comaroni et al., 1989), and a mapping between the two taxonomies has been computed in order to ensure completeness. Table 2 shows how the senses for a word (i.e. the noun bank) have been associ</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet. An Electronic Lexical Database. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Ko</author>
<author>J Seo</author>
</authors>
<title>Automatic text categorization by unsupervised learning.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING-00, the 18th International Conference on Computational Linguistics, Saarbr¨ucken,</booktitle>
<location>Germany.</location>
<contexts>
<context position="2121" citStr="Ko and Seo, 2000" startWordPosition="324" endWordPosition="327">, domain detection allows a number of useful simplifications in text processing applications, such as, for instance, in Word Sense Disambiguation (WSD). In this paper we introduce Domain Relevance Estimation (DRE) a fully unsupervised technique for domain detection. Roughly speaking, DRE can be viewed as a text categorization (TC) problem (Sebastiani, 2002), even if we do not approach the problem in the standard supervised setting requiring category labeled training data. In fact, recently, unsupervised approaches to TC have received more and more attention in the literature (see for example (Ko and Seo, 2000). We assume a pre-defined set of categories, each defined by means of a list of related terms. We call such categories domains and we consider them as a set of general topics (e.g. SPORT, MEDICINE, POLITICS) that cover the main disciplines and areas of human activity. For each domain, the list of related words is extracted from WORDNET DOMAINS (Magnini and Cavagli`a, 2000), an extension of WORDNET in which synsets are annotated with domain labels. We have identified about 40 domains (out of 200 present in WORDNET DOMAINS) and we will use them for experiments throughout the paper (see Table 1).</context>
</contexts>
<marker>Ko, Seo, 2000</marker>
<rawString>Y. Ko and J. Seo. 2000. Automatic text categorization by unsupervised learning. In Proceedings of COLING-00, the 18th International Conference on Computational Linguistics, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>G Cavagli`a</author>
</authors>
<title>Integrating subject field codes into WordNet.</title>
<date>2000</date>
<booktitle>In Proceedings of LREC-2000, Second International Conference on Language Resources and Evaluation,</booktitle>
<location>Athens, Greece,</location>
<marker>Magnini, Cavagli`a, 2000</marker>
<rawString>B. Magnini and G. Cavagli`a. 2000. Integrating subject field codes into WordNet. In Proceedings of LREC-2000, Second International Conference on Language Resources and Evaluation, Athens, Greece, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>C Strapparava</author>
<author>G Pezzulo</author>
<author>A Gliozzo</author>
</authors>
<title>The role of domain information in word sense disambiguation.</title>
<date>2002</date>
<journal>Natural Language Engineering,</journal>
<volume>8</volume>
<issue>4</issue>
<contexts>
<context position="3501" citStr="Magnini et al., 2002" startWordPosition="549" endWordPosition="552">RE is to combine the knowledge in WORDNET DOMAINS and a probabilistic framework which makes use of a large-scale corpus to induce domain frequency distributions. Specifically, given a certain domain, DRE considers frequency scores for both relevant and non-relevant texts (i.e. texts which introduce noise) and represent them by means of a Gaussian Mixture model. Then, an Expectation Maximization algorithm computes the parameters that maximize the likelihood of the empirical data. DRE methodology originated from the effort to improve the performance of Domain Driven Disambiguation (DDD) system (Magnini et al., 2002). DDD is an unsupervised WSD methodology that makes use of only domain information. DDD assignes the right sense of a word in its context comparing the domain of the context to the domain of each sense of the word. This methodology exploits WORDNET DOMAINS information to estimate both Domain #Syn Domain #Syn Domain #Syn Factotum 36820 Biology 21281 Earth 4637 Psychology 3405 Architecture 3394 Medicine 3271 Economy 3039 Alimentation 2998 Administration 2975 Chemistry 2472 Transport 2443 Art 2365 Physics 2225 Sport 2105 Religion 2055 Linguistics 1771 Military 1491 Law 1340 History 1264 Industry </context>
<context position="6207" citStr="Magnini et al., 2002" startWordPosition="989" endWordPosition="992">ains show interesting properties both from a lexical and a textual point of view. Among these properties there are: (i) lexical coherence, since part of the lexicon of a text is composed of words belonging to the same domain; (ii) polysemy reduction, because the potential ambiguity of terms is sensibly lower if the domain of the text is specified; and (iii) lexical identifiability of text’s domain, because it is always possible to assign one or more domains to a given text by considering term distributions in a bag-of-words approach. Experimental evidences of these properties are reported in (Magnini et al., 2002). In this section we describe WORDNET DOMAINS1 (Magnini and Cavagli`a, 2000), a lexical resource that attempts a systematization of relevant aspects in domain organization and representation. WORDNET DOMAINS is an extension of WORDNET (version 1.6) (Fellbaum, 1998), in which each synset is annotated with one or more domain labels, selected from a hierarchically organized set of about two hundred labels. In particular, issues concerning the “completeness” of the domain set, the “balancing” among domains and the “granularity” of domain distinctions, have been addressed. The domain set used in WO</context>
<context position="27834" citStr="Magnini et al., 2002" startWordPosition="4690" endWordPosition="4693"> domain information is crucial to disambiguate domain words. In Figure 2 we also compare the results obtained by the DDD system that make use of the DRE technique described in Section 3 with the rework since it relies on a general resource (SemCor) that does not correspond to the test data (Senseval all-words task). 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6 Recall Figure 2: Performances of the system for all POS 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 Recall Figure 3: Performances of the system for Nouns and Verbs sults obtained by the DDD system presented at the Senseval-2 competition described in (Magnini et al., 2002), that is based on the same DDD methodology and exploit a DRE technique that consists basically on the simply domain frequency scores described in subsection 3.1 (we refer to this system using the expression old-DDD, in contrast to the expression new-DDD that refers to the implementation described in this paper). Old-DDD obtained 75% precision and 35% recall on the official evaluation at the Senseval-2 English all words task. At 35% of recall the new-DDD achieves a precision of 79%, improving precision by 4 points with respect to old-DDD. At 75% precision the recall of new-DDD is 40%. In both </context>
</contexts>
<marker>Magnini, Strapparava, Pezzulo, Gliozzo, 2002</marker>
<rawString>B. Magnini, C. Strapparava, G. Pezzulo, and A. Gliozzo. 2002. The role of domain information in word sense disambiguation. Natural Language Engineering, 8(4):359–373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>C Fellbaum</author>
<author>S Cotton</author>
<author>L Delfs</author>
<author>H T Dang</author>
</authors>
<title>English tasks: All-words and verb lexical sample.</title>
<date>2001</date>
<booktitle>In Proceedings of SENSEUAL-2, Second International Workshop on Evaluating Word Sense Disambiguation Systems,</booktitle>
<location>Toulouse, France,</location>
<contexts>
<context position="9214" citStr="Palmer et al., 2001" startWordPosition="1475" endWordPosition="1478"> TRANSPORT - Table 2: WORDNET senses and domains for the word “bank”. from act#2, and playing field#1 from location#1. Domains may group senses of the same word into thematic clusters, which has the important sideeffect of reducing the level of ambiguity when we are disambiguating to a domain. Table 2 shows an example. The word “bank” has ten different senses in WORDNET 1.6: three of them (i.e. bank#1, bank#3 and bank#6) can be grouped under the ECONOMY domain, while bank#2 and bank#7 both belong to GEOGRAPHY and GEOLOGY. Grouping related senses is an emerging topic in WSD (see, for instance (Palmer et al., 2001)). Finally, there are WORDNET synsets that do not belong to a specific domain, but rather appear in texts associated with any domain. For this reason, a FACTOTUM label has been created that basically includes generic synsets, which appear frequently in different contexts. Thus the FACTOTUM domain can be thought of as a “placeholder” for all other domains. 3 Domain Relevance Estimation for Texts The basic idea of domain relevance estimation for texts is to exploit lexical coherence inside texts. From the domain point of view lexical coherence is equivalent to domain coherence, i.e. the fact tha</context>
</contexts>
<marker>Palmer, Fellbaum, Cotton, Delfs, Dang, 2001</marker>
<rawString>M. Palmer, C. Fellbaum, S. Cotton, L. Delfs, and H.T. Dang. 2001. English tasks: All-words and verb lexical sample. In Proceedings of SENSEUAL-2, Second International Workshop on Evaluating Word Sense Disambiguation Systems, Toulouse, France, July.</rawString>
</citation>
<citation valid="true">
<date>2002</date>
<booktitle>Proceedings of SENSEUAL-2: Second International Workshop on Evaluating Word Sense Disambiguation Systems,</booktitle>
<editor>J. Preiss and D. Yarowsky, editors.</editor>
<location>Toulouse, France.</location>
<marker>2002</marker>
<rawString>J. Preiss and D. Yarowsky, editors. 2002. Proceedings of SENSEUAL-2: Second International Workshop on Evaluating Word Sense Disambiguation Systems, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Redner</author>
<author>H Walker</author>
</authors>
<title>Mixture densities, maximum likelihood and the EM algorithm.</title>
<date>1984</date>
<journal>SIAM Review,</journal>
<volume>26</volume>
<issue>2</issue>
<contexts>
<context position="19574" citStr="Redner and Walker, 1984" startWordPosition="3282" endWordPosition="3285">kelihood function is evaluated by formula (8). 1 − (x−µ)2 G(x, µ, Q) = e 22 R(D, t, j) = P(DjF(D, t, j)) = (4) L(T , D, 0) = � p(F(D,t)|0) (8) tET = P(F(D,t, j)jD)P(D) P(F(D, t, j)ID)P(D) + P(F(D, t, j)ID)P(D) where P(F(D, t, j)|D) is the value of the PDF describing D calculated in the point F(D, t, j), P(F(D, t, j)|D) is the value of the PDF describing D, P(D) is the area of the distribution describing D and P(D) is the area of the distribution for D. In order to estimate the parameters describing the PDF of D and D the Expectation Maximization (EM) algorithm for the Gaussian Mixture Model (Redner and Walker, 1984) is exploited. Assuming to model the empirical distribution of domain frequencies using a Gaussian mixture of two components, the estimated parameters can be used to evaluate domain relevance by equation (4). More formally, the EM algorithm for GM models explores the space of parameters in order to find the set of parameters 0 such that the maximum likelihood criterion (see formula 9) is satisfied. 0D = argmax 0/ L(T , D, 0&apos;) (9) This condition ensures that the obtained model fits the original data as much as possible. Estimation of parameters is the only information required in order to evalu</context>
</contexts>
<marker>Redner, Walker, 1984</marker>
<rawString>R. Redner and H. Walker. 1984. Mixture densities, maximum likelihood and the EM algorithm. SIAM Review, 26(2):195–239, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sebastiani</author>
</authors>
<title>Machine learning in automated text categorization.</title>
<date>2002</date>
<journal>ACM Computing Surveys,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="1863" citStr="Sebastiani, 2002" startWordPosition="283" endWordPosition="285">tate-ofthe-art unsupervised WSD systems and show that DRE provides an important contribution. 1 Introduction A fundamental issue in text processing and understanding is the ability to detect the topic (i.e. the domain) of a text or of a portion of it. Indeed, domain detection allows a number of useful simplifications in text processing applications, such as, for instance, in Word Sense Disambiguation (WSD). In this paper we introduce Domain Relevance Estimation (DRE) a fully unsupervised technique for domain detection. Roughly speaking, DRE can be viewed as a text categorization (TC) problem (Sebastiani, 2002), even if we do not approach the problem in the standard supervised setting requiring category labeled training data. In fact, recently, unsupervised approaches to TC have received more and more attention in the literature (see for example (Ko and Seo, 2000). We assume a pre-defined set of categories, each defined by means of a list of related terms. We call such categories domains and we consider them as a set of general topics (e.g. SPORT, MEDICINE, POLITICS) that cover the main disciplines and areas of human activity. For each domain, the list of related words is extracted from WORDNET DOMA</context>
</contexts>
<marker>Sebastiani, 2002</marker>
<rawString>F. Sebastiani. 2002. Machine learning in automated text categorization. ACM Computing Surveys, 34(1):1–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Senseval-2</author>
</authors>
<date>2001</date>
<note>http://www.senseval.org.</note>
<marker>Senseval-2, 2001</marker>
<rawString>Senseval-2. 2001. http://www.senseval.org.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>