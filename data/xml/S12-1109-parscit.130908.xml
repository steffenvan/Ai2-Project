<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.026131">
<title confidence="0.993819">
SAGAN: A Machine Translation Approach for
Cross-Lingual Textual Entailment
</title>
<author confidence="0.937604">
Julio Castillo1,2 and Marina Cardenas2
</author>
<affiliation confidence="0.688731">
1UNC-FaMAF, Argentina
</affiliation>
<address confidence="0.442974">
2UTN-FRC, Argentina
</address>
<email confidence="0.96225">
{jotacastillo, ing.marinacardenas}@gmail.com
</email>
<sectionHeader confidence="0.995555" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997691">
This paper describes our participation in the
task denominated Cross-Lingual Textual En-
tailment (CLTE) for content synchronization.
We represent an approach to CLTE using
machine translation to tackle the problem of
multilinguality. Our system resides on ma-
chine learning and in the use of WordNet as
semantic source knowledge. Results are very
promising always achieving results above
mean score.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.952380272727273">
This paper describes the participation of Sagan, a
TE and CLTE system, in the new task of Cross
Lingual Textual Entailment for Content Synchro-
nization.
The objective of the Recognizing Textual En-
tailment (RTE) task (Dagan et al., 2006) is deter-
mining whether the meaning of a text fragment that
we call hypothesis H can be inferred from another
text fragment T. In this manner, we say that T en-
tails H, if a person reading T would infer that H is
most likely true. Thus, this definition assumes
common human understanding of language and
common background knowledge.
In that context, Cross-Lingual Textual Entail-
ment addresses textual entailment recognition in
the challenging application scenario of content
synchronization. Thus, CLTE constitutes a gener-
alization of Textual Entailment task (also Mono-
lingual Textual Entailment) , but envisioning a
larger number of application areas in NLP, includ-
ing question answering, information retrieval, in-
formation extraction, and document summariza-
tion, across different languages.
Content synchronization could be used to keep
consistence among documents written in different
languages. For example, a CLTE system can be
used in Wikipedia articles to inform lectors which
information is absent or inconsistent in comparison
to other page in a different language.
This new task has to face more additional issues
than monolingual TE. Among them, we emphasize
the ambiguity, polysemy, and coverage of the re-
sources. Another additional problem is the necessi-
ty for semantic inference across languages, and the
limited availability of multilingual knowledge
resources.
The CLTE for content synchronization specifi-
cally consist on determining the entailment rela-
tionship between two text fragment T1 and T2
which are assumed belong a related topic.
Four alternatives are possible in this relation-
ship:
- Bidirectional : It is a semantic equivalence be-
tween T1 and T2.
- Forward : It is an unidirectional entailment
from T1 to T2.
- Backward: It is an unidirectional entailment
from T2 to T1.
- No Entailment: It means that there is no en-
tailment between T1 and T2.
The paper is organized as follows: Section 2 de-
scribes the relevant work done on cross-lingual
textual entailment and related tasks, Section 3 de-
scribes the architecture of the system, then Section
4 shows experiments and results; and finally Sec-
</bodyText>
<page confidence="0.967219">
721
</page>
<note confidence="0.5284815">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 721–726,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.9882835">
tion 5 summarize some conclusions and future
work.
</bodyText>
<sectionHeader confidence="0.998667" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999711">
In this section we briefly describe two tasks that
are closely related to CLTE.
</bodyText>
<subsectionHeader confidence="0.992805">
2.1 Textual Entailment
</subsectionHeader>
<bodyText confidence="0.99996415625">
The objective of the recognizing textual entail-
ment (RTE) task (Dagan et al., 2006) is determin-
ing whether or not the meaning of a “hypothesis”
(H) can be inferred from a “text” (T).
The two-way RTE task consists of deciding
whether: T entails H, in which case the pair will be
marked as “Entailment”, otherwise the pair will
be marked as “No Entailment”. This definition of
entailment is based on (and assumes) average hu-
man understanding of language as well as average
background knowledge.
Recently the RTE4 Challenge has changed to a
three-way task (Bentivogli et al, 2009) that consists
in distinguishing among “Entailment”, “Contra-
diction” and “Unknown” when there is no infor-
mation to accept or reject the hypothesis.
The RTE challenge has mutated over the years,
aiming at accomplishing more accurate and specif-
ic solutions; in 2009 the organizers proposed a
pilot task, the Textual Entailment Search
(Bentivogli et al, 2009), consisting in finding all
the sentences in a set of documents that entail a
given Hypothesis and since 2010 there is a Novelty
Detection Task, which means that RTE systems are
required to judge whether the information con-
tained in each H is novel with respect to (i.e., not
entailed by) the information contained in the cor-
pus.
Thus, the new CLTE task can be thought as a
generalized problem of RTE, which has to face
new challenges as scarcity of resources to multi-
lingual scenario, among others issues.
</bodyText>
<subsectionHeader confidence="0.999688">
2.2 Semantic Textual Similarity
</subsectionHeader>
<bodyText confidence="0.9997547">
The pilot task STS was recently defined in
Semeval 2012 (Aguirre et al., 2012) and has as
main objective measuring the degree of semantic
equivalence between two text fragments. STS is
related to both Recognizing Textual Entailment
(RTE) and Paraphrase Recognition, but has the
advantage of being a more suitable model for mul-
tiple NLP applications.
As mentioned before, the goal of the RTE task
(Bentivogli et al, 2009) is determining whether the
meaning of a hypothesis H can be inferred from a
text T. The main difference with STS is that STS
consists in determining how similar two text frag-
ments are, in a range from 5 (total semantic
equivalence) to 0 (no relation). Thus, STS mainly
differs from TE and Paraphrasing in that the classi-
fication is graded instead of binary and also STS
assumes bidirectional equivalence but in TE the
equivalence is only directional. In this manner,
STS is filling the gap between TE and Paraphrase.
</bodyText>
<subsectionHeader confidence="0.999141">
2.3 Cross-Lingual Textual Entailment
</subsectionHeader>
<bodyText confidence="0.999988">
There are a few previous works on CLTE, the
first one was the definition of this new task
(Mehdad et al., 2010). Afterwards, the creation of
CLTE corpus by using Mechanical Turk is de-
scribed on (Negri et al., 2011) and a corpus freely
available for CLTE is published (Castillo, 2011).
To our knowledge, two approach are proposed
to address this new challenging task, one consist of
using machine translation to move on towards
monolingual textual entailment scenario and then
apply classic techniques for RTE (Mehdad et al.,
2010; Castillo and Cardenas, 2011), and the other
is based on exploit databases of paraphrases
(Mehdad et al., 2011). Both techniques obtained
similar results and the accuracy achieved by them
is not a statically significant difference.
In previous work (Castillo, 2010; Castillo and
Cardenas, 2011) we addressed the CLTE focusing
on English-Spanish language pair and released a
bilingual textual entailment corpus. This paper is
based on that work in order to tackling the problem
across different language pairs Spanish-English
(SPA-ENG), Italian-English (ITA-ENG), French-
English (FRA-ENG) and German-English (GER-
ENG) and we also used an approach based on ma-
chine translation.
</bodyText>
<sectionHeader confidence="0.960142" genericHeader="method">
3 System architecture
</sectionHeader>
<bodyText confidence="0.9983065">
Sagan is a CLTE system (Castillo and Cardenas,
2010) which has taken part of several challenges,
including the Textual Analysis Conference 2009
and TAC 2010, and the Semantic Textual Similari-
</bodyText>
<page confidence="0.983748">
722
</page>
<bodyText confidence="0.999549037037037">
ty Semeval 2012 (Aguirre et al., 2012; Castillo and
Estrella, 2012) and Cross Lingual Textual Entail-
ment for content synchronization as part of the
Semeval 2012 (Negri et al., 2012).
The system is based on a machine learning ap-
proach and it utilizes eight WordNet-based
(Fellbaum, 1998) similarity measures with the
purpose of obtaining the maximum similarity be-
tween two concepts. We used SVM as classifier
with polynomial kernel. The system determines the
entailment based on the semantic similarity of two
texts (T,H) viewed as a function of the semantic
similarity of the constituent words of both phrases.
Thereby, we expect that combining word to word
similarity metrics to text level would be a good
indicator of text to text similarity.
These text-to-text similarity measures are based
on the following word-to-word similarity metrics:
(Resnik, 1995), (Lin, 1997), (Jiang and Conrath,
1997), (Pirrò and Seco, 2008), (Wu and Palmer,
1994), Path Metric, (Leacock and Chodorow,
1998), and a semantic similarity to sentence level
named SemSim (Castillo and Cardenas, 2010).
Additional information about how to produce
feature vectors as well as each word- and sentence-
level metric can be found in (Castillo, 2011). The
architecture of the system is shown in Figure 1.
</bodyText>
<subsectionHeader confidence="0.52963">
Fig.1. System architecture
</subsectionHeader>
<bodyText confidence="0.999661571428571">
In the preprocessing module we performed
string normalization across different languages by
using a lookup table for lexical entries, and then
date and time normalization is carried out.
CLTE adaption layer is composed by four ma-
chine translation sub-modules that bring back each
&lt;Ti ,H&gt; pair into the monolingual case ENG-ENG.
Where Ti can be given in Spanish, German, Italian
or French.
The training set used to the submitted runs are
whose provided by the organizers of the CLTE for
Content Synchronization Task and a combination
of RTE datasets, such as it is described in the Sec-
tion Experiments and Results.
</bodyText>
<sectionHeader confidence="0.99875" genericHeader="evaluation">
4 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999851176470588">
The dataset provided by the organizers consists of
500 CLTE pairs translated to four languages fol-
lowing the crowdsourcing-based methodology
proposed in (Negri et al., 2011). Also, for test pur-
pose additional 500 pairs are provided. Both da-
tasets are balanced with respect to the four
entailment judgments (bidirectional, forward,
backward, and no entailment).
We also performed experiments using traditional
RTE datasets. Because of the RTE datasets are
binary classified as NO (no-entailment) and YES
(entailment), then we assumed that NO class is
&amp;quot;no-entailment&amp;quot; and YES class is &amp;quot;forward&amp;quot; in the
CLTE task. Certainly, the corpus tagged in this
way will have contradictory information, since
several pairs classified as forward should be classi-
fied as bidirectional, and also several pairs classi-
fied as no-entailment could be backwards, but the
objective is experimenting whether we can gain
accuracy in our RTE system despite of these (few)
contradictory cases.
Additionally, in our experiments we used an al-
gorithm (Castillo,2010) to generate additional
training data, in other words to expand a data set. It
is based on a Double Translation Process (dtp) or
round-trip translation. Double translation process
can be defined as the process of starting with an S
(String in English), translating it to a foreign lan-
guage F(S), for example Spanish, and finally back
into the English source language F-1(S).
We applied the algorithm starting with RTE3
and RTE4 datasets. Thus, the augmented corpus is
denoted RTE3-4C which is tagged according to the
three-way task composed of: 340 pairs Contradic-
</bodyText>
<figure confidence="0.999381441176471">
Knowledge Resources
Entailment
Result
Training Sets
Pre-Processing
CLTE
Adaptation Layer
TE
engine
Bidirectional Forward Backward
No
Entailment
Web Resources
Google
Traslate
&apos; CLTE_DEU-ENG,
&apos;
CLTE_FRA-ENG,
&apos; CLTE_SPA-ENG,
&apos;CLTE_ITA-ENG,
&apos; CLTE_DEU+FRA+SPA+ITA-
ENG,
&apos;CLTE_DEU+FRA+SPA+ITA-
ENG+RTE3-TS-CL
RTE3-4C+RTE4-4C
RTE3-4C
Training Sets
Test Sets
&apos; CLTE_DEU-ENG,
&apos;
CLTE_FRA-ENG,
&apos; CLTE_SPA-ENG,
&apos;CLTE_ITA-ENG
WordNet
</figure>
<page confidence="0.997348">
723
</page>
<bodyText confidence="0.999947">
tion, 1520 pairs Yes, and 1114 pairs Unknown. In
the case of the two-way task, it is composed by
1454 pairs No, and 1520 pairs Yes.
The other dataset augmented is denoted RTE4-
4C, and has the following composition: 546 pairs
Contradiction, 1812 pairs Entailment, and 1272
pairs Unknown. Therefore, in the two-way task,
there are 1818 pairs No (No Entailment), and 1812
pairs Yes (Entailment) in this data set.
The idea behind using RTE3-4C and RTE3-4C
is providing to our system an increased dataset
aiming to acquire more semantic variability.
In our system submission we report the experi-
ments performed with the test sets provided by
CLTE organizers which is composed by four da-
tasets of 500 pairs each one.
</bodyText>
<subsectionHeader confidence="0.988805">
4.1 Submission to the CLTE shared task
</subsectionHeader>
<bodyText confidence="0.981847727272727">
With the aims of applying the monolingual textual
entailment techniques, in the CLTE domain, we
utilized the Google translate as MT system to bring
back the &lt;T,H&gt; pairs into the monolingual case.
Then we generated a feature vector for every
&lt;T,H&gt; pair with both training and test sets, and
used monolingual textual entailment engine to
classify the pairs. First we described the dataset
used and then explain each submitted run.
The datasets used are listed below:
- CLTE_Esp+Fra+Ita+Ger: dataset composed
by all language pairs.
- RTE3-TS-CL: a ENG-SPA cross lingual tex-
tual entailment corpus (Castillo,2011) composed
by 200 pairs (108 Entailment, 32 Contradiction, 60
Unknown).
- RTE3-4C: an augmented dataset based on
- RTE4-4C: an augmented dataset based on
Our participation in the shared task consisted of
four different runs produced with the same feature
set, and the main differences rely on the amount
and type of training data. Each run is described
below:
- RUN1: system trained on CLTE_Esp+
Fra+Ger+Ita corpus in addition to the RTE3-TS-
CL dataset.
- RUN2: system trained on CLTE_Esp,
CLTE_Fra, CLTE_Ger and CLTE_Ita corpus. At
testing phase, the system chooses the right dataset
according to the language that it is processing.
- RUN3: system trained using all training data
that came from different language pairs.
We remark that we can combine the training da-
ta because of we used a machine translation sub-
module that bring back each &lt;T,H&gt; pair into the
monolingual case ENG-ENG.
- RUN4: In RUN4 the training set is com-
posed by all pairs of CLTE_Esp+Fra+Ita+Ger and
RTE3-4C+ RTE4-4C datasets.
Ten teams participated in this CLTE task, eight
submitting runs to all language pairs. For Spanish
28 runs were submitted and 20 runs were submit-
ted for the other languages. The results achieved
by our system is showed in Table 1.
</bodyText>
<table confidence="0.996994909090909">
Team id Team Score (Accuracy) Run Rank
system
id
SPA- ITA- FRA- DEU- SPA ITA FRA DEU
ENG ENG ENG ENG
Sagan runt 0.342 0.352 0.346 0.342 16 6 9 9
Sagan run2 0.328 0.352 0.336 0.310 19 7 11 13
Sagan run3 0.346 0.356 0.330 0.332 14 5 12 12
Sagan run4 0.340 0.330 0.310 0.310 17 12 13 14
System 7 4 5 6
Rank
</table>
<bodyText confidence="0.999644826086957">
The results reported show that our best run is
ranking above the average for all languages. The
same situation occurs when ranking the systems,
except for Spanish where the system is placed on
7th among 10 teams.
We achieved the highest result of 0.356 with
RUN3 in the pair ITA-ENG which is placed fourth
among participating systems.
We also note that, in general, training the system
with the pairs of all datasets achieved better results
than training separately for each dataset. Further-
more, if we analyze RUN4 vs. RUN3 we can con-
clude that incorporating additional RTE dataset
produces a very unbalanced dataset resulting in a
decrease in performance. In (Castillo, 2011) we
experimented with these expanded datasets over
monolingual RTE and CLTE tasks and we showed
gain in performance, thus we suspect that the de-
crease is more due to unbalanced dataset than to
noise introduced by the double translation process.
Interesting, the Corpus RTE3-TS-CL dataset uti-
lized in the RUN1 helps to improve the results in
FRA-ENG and DEU-ENG language pairs.
</bodyText>
<page confidence="0.995049">
724
</page>
<bodyText confidence="0.999511444444445">
The Table 2 shows that our system predict with
high F-measure to bidirectional and no-entailment
entailment judgments in all language pairs, but has
problems to distinguish the forward and backward
entailment judgments.
It is probably due to our systems is based on
semantic overlap between T and H, resulting the
backwards particularly difficult to predict to our
system.
</bodyText>
<table confidence="0.999391714285714">
Run Language Precision Recall F-measure Score Mean Score-
id pair (Accuracy) all runs
F 8 NE 8I F 8 NE 8I F 8 NE 8I
Run3 SPA-ENG 0.23 0.27 0.42 0.42 0.20 0.22 0.45 0.51 0.21 0.25 0.43 0.46 0.346 0.346
Run3 ITA-ENG 0.31 0.25 0.40 0.46 0.30 0.22 0.51 0.40 0.30 0.23 0.45 0.43 0.356 0.336
Runt FRA-ENG 0.24 0.30 0.39 0.43 0.17 0.34 0.57 0.30 0.20 0.32 0.47 0.36 0.346 0.336
Run1 DEU-ENG 0.25 0.23 0.41 0.44 0.17 0.26 0.60 0.34 0.20 0.25 0.49 0.39 0.342 0.336
</table>
<tableCaption confidence="0.999306">
Table 2. Official results for Precision, Recall and F-measure
</tableCaption>
<sectionHeader confidence="0.989807" genericHeader="conclusions">
5 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.99973652173913">
In this paper we explained our participation in the
new challenging task of Cross-Lingual Textual
Entailment (CLTE) for Content Synchronization.
This task also could presents benefit as a metric for
machine translation evaluation, as reported in
(Castillo and Estrella, 2012).
This work focuses on CLTE based on Machine
translation to bring back the problem into the mon-
olingual Textual Entailment (TE) scenario. This
decoupled approach between Textual Entailment
and Machine Translation has several advantages,
such as taking benefits of the most recent advances
in machine translation, the ability to test the effi-
ciency of different MT systems, as well as the abil-
ity to scale the system easily to any language pair.
Results achieved are promising and additional
work is needed in order to address the problem of
distinguish among forward, backward and bidirec-
tional entailment judgments.
Future work will be oriented to tackle the prob-
lem with backwards. Finally, we remark the neces-
sity of bigger corpus tagged in four-way
classification, for all language pairs.
</bodyText>
<sectionHeader confidence="0.99849" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99902238">
Ido Dagan, Oren Glickman and Bernardo Magnini.
2006. The PASCAL Recognising Textual Entailment
Challenge. In Quiñonero-Candela, J.; Dagan, I.;
Magnini, B.; d&apos;Alché-Buc, F. (Eds.) Machine Learn-
ing Challenges. Lecture Notes in Computer Science ,
Vol. 3944, pp. 177-190, Springer.
M. Negri, A. Marchetti, Y. Mehdad, L. Bentivogli, and
D. Giampiccolo. 2012. Semeval-2012 Task 8: Cross-
lingual Textual Entailment for Content Synchroniza-
tion. In Proceedings of the 6th International Work-
shop on Semantic Evaluation (SemEval 2012).
L. Bentivogli, P. Clark, I. Dagan, H. T. Dang, and D.
Giampiccolo. 2010. The Sixth PASCAL Recognizing
Textual Entailment Challenge. In TAC 2010 Work-
shop Proceedings, NIST, Gaithersburg, MD, USA.
Y. Mehdad, M. Negri, and M. Federico. 2010. Towards
Cross-Lingual Textual Entailment. In Proceedings of
NAACL-HLT 2010.
Eneko Agirre, Daniel Cer, Mona Diab and Aitor Gonza-
lez-Agirre. 2012. SemEval-2012 Task 6: A Pilot on
Semantic Textual Similarity. In Proceedings of the
6th International Workshop on Semantic Evalua-tion
(SemEval 2012), in conjunction with the First Joint
Conference on Lexical and Computational Semantics
(*SEM 2012).
Bentivogli, Luisa, Dagan Ido, Dang Hoa, Giampiccolo,
Danilo, Magnini Bernardo.2009.The Fifth PASCAL
RTE Challenge. In: Proceedings of the Text Analysis
Conference.
Fellbaum C. 1998. WordNet: An Electronic Lexical
Database, volume 1. MIT Press.
Castillo Julio. 2011. A WordNet-based semantic ap-
proach to textual entailment and cross-lingual textu-
al entailment. International Journal of Machine
Learning and Cybernetics - Springer, Volume 2,
Number 3.
Castillo Julio and Cardenas Marina. 2010. Using sen-
tence semantic similarity based onWordNet in recog-
nizing textual entailment. Iberamia 2010. In LNCS,
vol 6433. Springer, Heidelberg, pp 366–375.
Castillo Julio. 2010. A semantic oriented approach to
textual entailment using WordNet-based measures.
MICAI 2010. LNCS, vol 6437. Springer, Heidelberg,
pp 44–55.
Castillo Julio. 2010. Using machine translation systems
to expand a corpus in textual entailment. In: Proceed-
ings of the Icetal 2010. LNCS, vol 6233, pp 97–102.
M. Negri, L. Bentivogli, Y. Mehdad, D. Giampiccolo,
and A. Marchetti. 2011. Divide and Conquer:
Crowdsourcing the Creation of Cross-Lingual Textu-
</reference>
<page confidence="0.979383">
725
</page>
<reference confidence="0.999881">
al Entailment Corpora. In Proceedings of the Con-
ference on Empirical Methods in Natural. EMNLP
2011.
Resnik P. 1995. Information content to evaluate seman-
tic similarity in a taxonomy. In: Proceedings of IJCAI
1995, pp 448–453.
Castillo Julio, Cardenas Marina. 2011. An Approach to
Cross-Lingual Textual Entailment using Online Ma-
chine Translation Systems. Polibits Journal. Vol 44.
Castillo Julio and Estrella Paula. 2012. Semantic Textu-
al Similarity for MT evaluation. NAACL 2012 Sev-
enth Workshop on Statistical Machine Translation.
WMT 2012, Montreal, Canada.
Lin D. 1997.An information-theoretic definition of simi-
larity. In: Proceedings of Conference on Machine
Learning, pp 296–304.
Jiang J, Conrath D.1997. Semantic similarity based on
corpus statistics and lexical taxonomy. In: Proceed-
ings of the ROCLINGX.
Pirro G., Seco N. 2008. Design, implementation and
evaluation of a new similarity metric combining fea-
ture and intrinsic information content. In: ODBASE
2008, Springer LNCS.
Wu Z, Palmer M. 1994. Verb semantics and lexical
selection. In: Proceedings of the 32nd ACL 916.
Leacock C, Chodorow M. 1998. Combining local con-
text and WordNet similarity for word sense identifi-
cation. MIT Press, pp 265–283.
Hirst G, St-Onge D . 1998. Lexical chains as represen-
tations of context for the detection and correction of
malapropisms. MIT Press, pp 305–332.
Banerjee S, Pedersen T. 2002. An adapted lesk algo-
rithm for word sense disambiguation using WordNet.
In: Proceeding of CICLING-02.
William B. Dolan and Chris Brockett.2005. Automati-
cally Constructing a Corpus of Sentential Para-
phrases. Third International Workshop on
Paraphrasing (IWP2005). Asia Federation of Natural
Language Processing.
Castillo Julio and Estrella Paula. 2012. SAGAN: An
approach to Semantic Textual Similarity based on
Textual Entailment. In Proceedings of the 6th Inter-
national Workshop on Semantic Evaluation
(SemEval 2012), in conjunction with the First Joint
Conference on Lexical and Computational Semantics
(*SEM 2012).
Mehdad Y., M. Negri, and M. Federico. 2011. Using
Parallel Corpora for Cross-lingual Textual Entail-
ment. In Proceedings of ACL-HLT 2011.
</reference>
<page confidence="0.998411">
726
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.402366">
<title confidence="0.738299">SAGAN: A Machine Translation Approach Cross-Lingual Textual Entailment</title>
<author confidence="0.495516">Marina</author>
<email confidence="0.998743">jotacastillo@gmail.com</email>
<email confidence="0.998743">ing.marinacardenas@gmail.com</email>
<abstract confidence="0.999419181818182">This paper describes our participation in the task denominated Cross-Lingual Textual Entailment (CLTE) for content synchronization. We represent an approach to CLTE using machine translation to tackle the problem of multilinguality. Our system resides on machine learning and in the use of WordNet as semantic source knowledge. Results are very promising always achieving results above mean score.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
<author>Bernardo Magnini</author>
</authors>
<title>The PASCAL Recognising Textual Entailment Challenge. In</title>
<date>2006</date>
<journal>Lecture Notes in Computer Science ,</journal>
<volume>3944</volume>
<pages>177--190</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="858" citStr="Dagan et al., 2006" startWordPosition="117" endWordPosition="120">icipation in the task denominated Cross-Lingual Textual Entailment (CLTE) for content synchronization. We represent an approach to CLTE using machine translation to tackle the problem of multilinguality. Our system resides on machine learning and in the use of WordNet as semantic source knowledge. Results are very promising always achieving results above mean score. 1 Introduction This paper describes the participation of Sagan, a TE and CLTE system, in the new task of Cross Lingual Textual Entailment for Content Synchronization. The objective of the Recognizing Textual Entailment (RTE) task (Dagan et al., 2006) is determining whether the meaning of a text fragment that we call hypothesis H can be inferred from another text fragment T. In this manner, we say that T entails H, if a person reading T would infer that H is most likely true. Thus, this definition assumes common human understanding of language and common background knowledge. In that context, Cross-Lingual Textual Entailment addresses textual entailment recognition in the challenging application scenario of content synchronization. Thus, CLTE constitutes a generalization of Textual Entailment task (also Monolingual Textual Entailment) , bu</context>
<context position="3400" citStr="Dagan et al., 2006" startWordPosition="516" endWordPosition="519">es the relevant work done on cross-lingual textual entailment and related tasks, Section 3 describes the architecture of the system, then Section 4 shows experiments and results; and finally Sec721 First Joint Conference on Lexical and Computational Semantics (*SEM), pages 721–726, Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics tion 5 summarize some conclusions and future work. 2 Related work In this section we briefly describe two tasks that are closely related to CLTE. 2.1 Textual Entailment The objective of the recognizing textual entailment (RTE) task (Dagan et al., 2006) is determining whether or not the meaning of a “hypothesis” (H) can be inferred from a “text” (T). The two-way RTE task consists of deciding whether: T entails H, in which case the pair will be marked as “Entailment”, otherwise the pair will be marked as “No Entailment”. This definition of entailment is based on (and assumes) average human understanding of language as well as average background knowledge. Recently the RTE4 Challenge has changed to a three-way task (Bentivogli et al, 2009) that consists in distinguishing among “Entailment”, “Contradiction” and “Unknown” when there is no inform</context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2006</marker>
<rawString>Ido Dagan, Oren Glickman and Bernardo Magnini. 2006. The PASCAL Recognising Textual Entailment Challenge. In Quiñonero-Candela, J.; Dagan, I.; Magnini, B.; d&apos;Alché-Buc, F. (Eds.) Machine Learning Challenges. Lecture Notes in Computer Science , Vol. 3944, pp. 177-190, Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Negri</author>
<author>A Marchetti</author>
<author>Y Mehdad</author>
<author>L Bentivogli</author>
<author>D Giampiccolo</author>
</authors>
<title>Semeval-2012 Task 8: Crosslingual Textual Entailment for Content Synchronization.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="7366" citStr="Negri et al., 2012" startWordPosition="1163" endWordPosition="1166">to tackling the problem across different language pairs Spanish-English (SPA-ENG), Italian-English (ITA-ENG), FrenchEnglish (FRA-ENG) and German-English (GERENG) and we also used an approach based on machine translation. 3 System architecture Sagan is a CLTE system (Castillo and Cardenas, 2010) which has taken part of several challenges, including the Textual Analysis Conference 2009 and TAC 2010, and the Semantic Textual Similari722 ty Semeval 2012 (Aguirre et al., 2012; Castillo and Estrella, 2012) and Cross Lingual Textual Entailment for content synchronization as part of the Semeval 2012 (Negri et al., 2012). The system is based on a machine learning approach and it utilizes eight WordNet-based (Fellbaum, 1998) similarity measures with the purpose of obtaining the maximum similarity between two concepts. We used SVM as classifier with polynomial kernel. The system determines the entailment based on the semantic similarity of two texts (T,H) viewed as a function of the semantic similarity of the constituent words of both phrases. Thereby, we expect that combining word to word similarity metrics to text level would be a good indicator of text to text similarity. These text-to-text similarity measur</context>
</contexts>
<marker>Negri, Marchetti, Mehdad, Bentivogli, Giampiccolo, 2012</marker>
<rawString>M. Negri, A. Marchetti, Y. Mehdad, L. Bentivogli, and D. Giampiccolo. 2012. Semeval-2012 Task 8: Crosslingual Textual Entailment for Content Synchronization. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Bentivogli</author>
<author>P Clark</author>
<author>I Dagan</author>
<author>H T Dang</author>
<author>D Giampiccolo</author>
</authors>
<title>The Sixth PASCAL Recognizing Textual Entailment Challenge.</title>
<date>2010</date>
<booktitle>In TAC 2010 Workshop Proceedings,</booktitle>
<location>NIST, Gaithersburg, MD, USA.</location>
<marker>Bentivogli, Clark, Dagan, Dang, Giampiccolo, 2010</marker>
<rawString>L. Bentivogli, P. Clark, I. Dagan, H. T. Dang, and D. Giampiccolo. 2010. The Sixth PASCAL Recognizing Textual Entailment Challenge. In TAC 2010 Workshop Proceedings, NIST, Gaithersburg, MD, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Mehdad</author>
<author>M Negri</author>
<author>M Federico</author>
</authors>
<title>Towards Cross-Lingual Textual Entailment.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL-HLT</booktitle>
<contexts>
<context position="5875" citStr="Mehdad et al., 2010" startWordPosition="933" endWordPosition="936">hesis H can be inferred from a text T. The main difference with STS is that STS consists in determining how similar two text fragments are, in a range from 5 (total semantic equivalence) to 0 (no relation). Thus, STS mainly differs from TE and Paraphrasing in that the classification is graded instead of binary and also STS assumes bidirectional equivalence but in TE the equivalence is only directional. In this manner, STS is filling the gap between TE and Paraphrase. 2.3 Cross-Lingual Textual Entailment There are a few previous works on CLTE, the first one was the definition of this new task (Mehdad et al., 2010). Afterwards, the creation of CLTE corpus by using Mechanical Turk is described on (Negri et al., 2011) and a corpus freely available for CLTE is published (Castillo, 2011). To our knowledge, two approach are proposed to address this new challenging task, one consist of using machine translation to move on towards monolingual textual entailment scenario and then apply classic techniques for RTE (Mehdad et al., 2010; Castillo and Cardenas, 2011), and the other is based on exploit databases of paraphrases (Mehdad et al., 2011). Both techniques obtained similar results and the accuracy achieved b</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2010</marker>
<rawString>Y. Mehdad, M. Negri, and M. Federico. 2010. Towards Cross-Lingual Textual Entailment. In Proceedings of NAACL-HLT 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Daniel Cer</author>
<author>Mona Diab</author>
<author>Aitor Gonzalez-Agirre</author>
</authors>
<title>SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evalua-tion (SemEval 2012), in conjunction with the First Joint Conference on Lexical and Computational Semantics (*SEM</booktitle>
<marker>Agirre, Cer, Diab, Gonzalez-Agirre, 2012</marker>
<rawString>Eneko Agirre, Daniel Cer, Mona Diab and Aitor Gonzalez-Agirre. 2012. SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity. In Proceedings of the 6th International Workshop on Semantic Evalua-tion (SemEval 2012), in conjunction with the First Joint Conference on Lexical and Computational Semantics (*SEM 2012).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Luisa Bentivogli</author>
<author>Dagan Ido</author>
<author>Dang Hoa</author>
<author>Danilo Giampiccolo</author>
</authors>
<title>Magnini Bernardo.2009.The Fifth PASCAL RTE Challenge. In:</title>
<booktitle>Proceedings of the Text Analysis Conference.</booktitle>
<marker>Bentivogli, Ido, Hoa, Giampiccolo, </marker>
<rawString>Bentivogli, Luisa, Dagan Ido, Dang Hoa, Giampiccolo, Danilo, Magnini Bernardo.2009.The Fifth PASCAL RTE Challenge. In: Proceedings of the Text Analysis Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database,</title>
<date>1998</date>
<volume>1</volume>
<publisher>MIT Press.</publisher>
<contexts>
<context position="7471" citStr="Fellbaum, 1998" startWordPosition="1182" endWordPosition="1183"> FrenchEnglish (FRA-ENG) and German-English (GERENG) and we also used an approach based on machine translation. 3 System architecture Sagan is a CLTE system (Castillo and Cardenas, 2010) which has taken part of several challenges, including the Textual Analysis Conference 2009 and TAC 2010, and the Semantic Textual Similari722 ty Semeval 2012 (Aguirre et al., 2012; Castillo and Estrella, 2012) and Cross Lingual Textual Entailment for content synchronization as part of the Semeval 2012 (Negri et al., 2012). The system is based on a machine learning approach and it utilizes eight WordNet-based (Fellbaum, 1998) similarity measures with the purpose of obtaining the maximum similarity between two concepts. We used SVM as classifier with polynomial kernel. The system determines the entailment based on the semantic similarity of two texts (T,H) viewed as a function of the semantic similarity of the constituent words of both phrases. Thereby, we expect that combining word to word similarity metrics to text level would be a good indicator of text to text similarity. These text-to-text similarity measures are based on the following word-to-word similarity metrics: (Resnik, 1995), (Lin, 1997), (Jiang and Co</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Fellbaum C. 1998. WordNet: An Electronic Lexical Database, volume 1. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Castillo Julio</author>
</authors>
<title>A WordNet-based semantic approach to textual entailment and cross-lingual textual entailment.</title>
<date>2011</date>
<journal>International Journal of Machine Learning and Cybernetics - Springer,</journal>
<volume>2</volume>
<marker>Julio, 2011</marker>
<rawString>Castillo Julio. 2011. A WordNet-based semantic approach to textual entailment and cross-lingual textual entailment. International Journal of Machine Learning and Cybernetics - Springer, Volume 2, Number 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Castillo Julio</author>
<author>Cardenas Marina</author>
</authors>
<title>Using sentence semantic similarity based onWordNet in recognizing textual entailment. Iberamia</title>
<date>2010</date>
<booktitle>In LNCS, vol 6433.</booktitle>
<pages>366--375</pages>
<publisher>Springer,</publisher>
<location>Heidelberg,</location>
<marker>Julio, Marina, 2010</marker>
<rawString>Castillo Julio and Cardenas Marina. 2010. Using sentence semantic similarity based onWordNet in recognizing textual entailment. Iberamia 2010. In LNCS, vol 6433. Springer, Heidelberg, pp 366–375.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Castillo Julio</author>
</authors>
<title>A semantic oriented approach to textual entailment using WordNet-based measures. MICAI</title>
<date>2010</date>
<volume>LNCS, vol</volume>
<pages>6437</pages>
<publisher>Springer,</publisher>
<location>Heidelberg,</location>
<marker>Julio, 2010</marker>
<rawString>Castillo Julio. 2010. A semantic oriented approach to textual entailment using WordNet-based measures. MICAI 2010. LNCS, vol 6437. Springer, Heidelberg, pp 44–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Castillo Julio</author>
</authors>
<title>Using machine translation systems to expand a corpus in textual entailment. In:</title>
<date>2010</date>
<booktitle>Proceedings of the Icetal 2010. LNCS,</booktitle>
<volume>vol</volume>
<pages>6233--97</pages>
<marker>Julio, 2010</marker>
<rawString>Castillo Julio. 2010. Using machine translation systems to expand a corpus in textual entailment. In: Proceedings of the Icetal 2010. LNCS, vol 6233, pp 97–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Negri</author>
<author>L Bentivogli</author>
<author>Y Mehdad</author>
<author>D Giampiccolo</author>
<author>A Marchetti</author>
</authors>
<title>Divide and Conquer: Crowdsourcing the Creation of Cross-Lingual Textual Entailment Corpora.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural. EMNLP</booktitle>
<contexts>
<context position="5978" citStr="Negri et al., 2011" startWordPosition="951" endWordPosition="954">how similar two text fragments are, in a range from 5 (total semantic equivalence) to 0 (no relation). Thus, STS mainly differs from TE and Paraphrasing in that the classification is graded instead of binary and also STS assumes bidirectional equivalence but in TE the equivalence is only directional. In this manner, STS is filling the gap between TE and Paraphrase. 2.3 Cross-Lingual Textual Entailment There are a few previous works on CLTE, the first one was the definition of this new task (Mehdad et al., 2010). Afterwards, the creation of CLTE corpus by using Mechanical Turk is described on (Negri et al., 2011) and a corpus freely available for CLTE is published (Castillo, 2011). To our knowledge, two approach are proposed to address this new challenging task, one consist of using machine translation to move on towards monolingual textual entailment scenario and then apply classic techniques for RTE (Mehdad et al., 2010; Castillo and Cardenas, 2011), and the other is based on exploit databases of paraphrases (Mehdad et al., 2011). Both techniques obtained similar results and the accuracy achieved by them is not a statically significant difference. In previous work (Castillo, 2010; Castillo and Carde</context>
<context position="9297" citStr="Negri et al., 2011" startWordPosition="1468" endWordPosition="1471">aption layer is composed by four machine translation sub-modules that bring back each &lt;Ti ,H&gt; pair into the monolingual case ENG-ENG. Where Ti can be given in Spanish, German, Italian or French. The training set used to the submitted runs are whose provided by the organizers of the CLTE for Content Synchronization Task and a combination of RTE datasets, such as it is described in the Section Experiments and Results. 4 Experiments and Results The dataset provided by the organizers consists of 500 CLTE pairs translated to four languages following the crowdsourcing-based methodology proposed in (Negri et al., 2011). Also, for test purpose additional 500 pairs are provided. Both datasets are balanced with respect to the four entailment judgments (bidirectional, forward, backward, and no entailment). We also performed experiments using traditional RTE datasets. Because of the RTE datasets are binary classified as NO (no-entailment) and YES (entailment), then we assumed that NO class is &amp;quot;no-entailment&amp;quot; and YES class is &amp;quot;forward&amp;quot; in the CLTE task. Certainly, the corpus tagged in this way will have contradictory information, since several pairs classified as forward should be classified as bidirectional, and</context>
</contexts>
<marker>Negri, Bentivogli, Mehdad, Giampiccolo, Marchetti, 2011</marker>
<rawString>M. Negri, L. Bentivogli, Y. Mehdad, D. Giampiccolo, and A. Marchetti. 2011. Divide and Conquer: Crowdsourcing the Creation of Cross-Lingual Textual Entailment Corpora. In Proceedings of the Conference on Empirical Methods in Natural. EMNLP 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Information content to evaluate semantic similarity in a taxonomy. In:</title>
<date>1995</date>
<booktitle>Proceedings of IJCAI</booktitle>
<pages>448--453</pages>
<contexts>
<context position="8043" citStr="Resnik, 1995" startWordPosition="1270" endWordPosition="1271">izes eight WordNet-based (Fellbaum, 1998) similarity measures with the purpose of obtaining the maximum similarity between two concepts. We used SVM as classifier with polynomial kernel. The system determines the entailment based on the semantic similarity of two texts (T,H) viewed as a function of the semantic similarity of the constituent words of both phrases. Thereby, we expect that combining word to word similarity metrics to text level would be a good indicator of text to text similarity. These text-to-text similarity measures are based on the following word-to-word similarity metrics: (Resnik, 1995), (Lin, 1997), (Jiang and Conrath, 1997), (Pirrò and Seco, 2008), (Wu and Palmer, 1994), Path Metric, (Leacock and Chodorow, 1998), and a semantic similarity to sentence level named SemSim (Castillo and Cardenas, 2010). Additional information about how to produce feature vectors as well as each word- and sentencelevel metric can be found in (Castillo, 2011). The architecture of the system is shown in Figure 1. Fig.1. System architecture In the preprocessing module we performed string normalization across different languages by using a lookup table for lexical entries, and then date and time no</context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Resnik P. 1995. Information content to evaluate semantic similarity in a taxonomy. In: Proceedings of IJCAI 1995, pp 448–453.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Castillo Julio</author>
<author>Cardenas Marina</author>
</authors>
<title>An Approach to Cross-Lingual Textual Entailment using Online Machine Translation Systems.</title>
<date>2011</date>
<journal>Polibits Journal. Vol</journal>
<volume>44</volume>
<marker>Julio, Marina, 2011</marker>
<rawString>Castillo Julio, Cardenas Marina. 2011. An Approach to Cross-Lingual Textual Entailment using Online Machine Translation Systems. Polibits Journal. Vol 44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Castillo Julio</author>
<author>Estrella Paula</author>
</authors>
<date>2012</date>
<booktitle>Semantic Textual Similarity for MT evaluation. NAACL 2012 Seventh Workshop on Statistical Machine Translation. WMT 2012,</booktitle>
<location>Montreal, Canada.</location>
<marker>Julio, Paula, 2012</marker>
<rawString>Castillo Julio and Estrella Paula. 2012. Semantic Textual Similarity for MT evaluation. NAACL 2012 Seventh Workshop on Statistical Machine Translation. WMT 2012, Montreal, Canada.</rawString>
</citation>
<citation valid="false">
<authors>
<author>D Lin</author>
</authors>
<title>1997.An information-theoretic definition of similarity. In:</title>
<booktitle>Proceedings of Conference on Machine Learning,</booktitle>
<pages>296--304</pages>
<marker>Lin, </marker>
<rawString>Lin D. 1997.An information-theoretic definition of similarity. In: Proceedings of Conference on Machine Learning, pp 296–304.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Jiang</author>
</authors>
<title>Conrath D.1997. Semantic similarity based on corpus statistics and lexical taxonomy. In:</title>
<booktitle>Proceedings of the ROCLINGX.</booktitle>
<marker>Jiang, </marker>
<rawString>Jiang J, Conrath D.1997. Semantic similarity based on corpus statistics and lexical taxonomy. In: Proceedings of the ROCLINGX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Pirro</author>
<author>N Seco</author>
</authors>
<title>Design, implementation and evaluation of a new similarity metric combining feature and intrinsic information content. In:</title>
<date>2008</date>
<booktitle>ODBASE 2008, Springer LNCS.</booktitle>
<marker>Pirro, Seco, 2008</marker>
<rawString>Pirro G., Seco N. 2008. Design, implementation and evaluation of a new similarity metric combining feature and intrinsic information content. In: ODBASE 2008, Springer LNCS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Wu</author>
<author>M Palmer</author>
</authors>
<title>Verb semantics and lexical selection. In:</title>
<date>1994</date>
<booktitle>Proceedings of the 32nd ACL 916.</booktitle>
<contexts>
<context position="8130" citStr="Wu and Palmer, 1994" startWordPosition="1282" endWordPosition="1285">f obtaining the maximum similarity between two concepts. We used SVM as classifier with polynomial kernel. The system determines the entailment based on the semantic similarity of two texts (T,H) viewed as a function of the semantic similarity of the constituent words of both phrases. Thereby, we expect that combining word to word similarity metrics to text level would be a good indicator of text to text similarity. These text-to-text similarity measures are based on the following word-to-word similarity metrics: (Resnik, 1995), (Lin, 1997), (Jiang and Conrath, 1997), (Pirrò and Seco, 2008), (Wu and Palmer, 1994), Path Metric, (Leacock and Chodorow, 1998), and a semantic similarity to sentence level named SemSim (Castillo and Cardenas, 2010). Additional information about how to produce feature vectors as well as each word- and sentencelevel metric can be found in (Castillo, 2011). The architecture of the system is shown in Figure 1. Fig.1. System architecture In the preprocessing module we performed string normalization across different languages by using a lookup table for lexical entries, and then date and time normalization is carried out. CLTE adaption layer is composed by four machine translation</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Wu Z, Palmer M. 1994. Verb semantics and lexical selection. In: Proceedings of the 32nd ACL 916.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Leacock</author>
<author>M Chodorow</author>
</authors>
<title>Combining local context and WordNet similarity for word sense identification.</title>
<date>1998</date>
<pages>265--283</pages>
<publisher>MIT Press,</publisher>
<contexts>
<context position="8173" citStr="Leacock and Chodorow, 1998" startWordPosition="1288" endWordPosition="1291">etween two concepts. We used SVM as classifier with polynomial kernel. The system determines the entailment based on the semantic similarity of two texts (T,H) viewed as a function of the semantic similarity of the constituent words of both phrases. Thereby, we expect that combining word to word similarity metrics to text level would be a good indicator of text to text similarity. These text-to-text similarity measures are based on the following word-to-word similarity metrics: (Resnik, 1995), (Lin, 1997), (Jiang and Conrath, 1997), (Pirrò and Seco, 2008), (Wu and Palmer, 1994), Path Metric, (Leacock and Chodorow, 1998), and a semantic similarity to sentence level named SemSim (Castillo and Cardenas, 2010). Additional information about how to produce feature vectors as well as each word- and sentencelevel metric can be found in (Castillo, 2011). The architecture of the system is shown in Figure 1. Fig.1. System architecture In the preprocessing module we performed string normalization across different languages by using a lookup table for lexical entries, and then date and time normalization is carried out. CLTE adaption layer is composed by four machine translation sub-modules that bring back each &lt;Ti ,H&gt; p</context>
</contexts>
<marker>Leacock, Chodorow, 1998</marker>
<rawString>Leacock C, Chodorow M. 1998. Combining local context and WordNet similarity for word sense identification. MIT Press, pp 265–283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hirst</author>
<author>D St-Onge</author>
</authors>
<title>Lexical chains as representations of context for the detection and correction of malapropisms.</title>
<date>1998</date>
<pages>305--332</pages>
<publisher>MIT Press,</publisher>
<marker>Hirst, St-Onge, 1998</marker>
<rawString>Hirst G, St-Onge D . 1998. Lexical chains as representations of context for the detection and correction of malapropisms. MIT Press, pp 305–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Banerjee</author>
<author>T Pedersen</author>
</authors>
<title>An adapted lesk algorithm for word sense disambiguation using WordNet. In: Proceeding of CICLING-02.</title>
<date>2002</date>
<marker>Banerjee, Pedersen, 2002</marker>
<rawString>Banerjee S, Pedersen T. 2002. An adapted lesk algorithm for word sense disambiguation using WordNet. In: Proceeding of CICLING-02.</rawString>
</citation>
<citation valid="false">
<authors>
<author>William B Dolan</author>
<author>Chris Brockett 2005</author>
</authors>
<title>Automatically Constructing a Corpus of Sentential Paraphrases.</title>
<booktitle>Third International Workshop on Paraphrasing (IWP2005). Asia Federation of Natural Language Processing.</booktitle>
<marker>Dolan, 2005, </marker>
<rawString>William B. Dolan and Chris Brockett.2005. Automatically Constructing a Corpus of Sentential Paraphrases. Third International Workshop on Paraphrasing (IWP2005). Asia Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Castillo Julio</author>
<author>Estrella Paula</author>
</authors>
<title>SAGAN: An approach to Semantic Textual Similarity based on Textual Entailment.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012), in conjunction with the First Joint Conference on Lexical and Computational Semantics (*SEM</booktitle>
<marker>Julio, Paula, 2012</marker>
<rawString>Castillo Julio and Estrella Paula. 2012. SAGAN: An approach to Semantic Textual Similarity based on Textual Entailment. In Proceedings of the 6th International Workshop on Semantic Evaluation (SemEval 2012), in conjunction with the First Joint Conference on Lexical and Computational Semantics (*SEM 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Mehdad</author>
<author>M Negri</author>
<author>M Federico</author>
</authors>
<title>Using Parallel Corpora for Cross-lingual Textual Entailment.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT</booktitle>
<contexts>
<context position="6405" citStr="Mehdad et al., 2011" startWordPosition="1018" endWordPosition="1021">ous works on CLTE, the first one was the definition of this new task (Mehdad et al., 2010). Afterwards, the creation of CLTE corpus by using Mechanical Turk is described on (Negri et al., 2011) and a corpus freely available for CLTE is published (Castillo, 2011). To our knowledge, two approach are proposed to address this new challenging task, one consist of using machine translation to move on towards monolingual textual entailment scenario and then apply classic techniques for RTE (Mehdad et al., 2010; Castillo and Cardenas, 2011), and the other is based on exploit databases of paraphrases (Mehdad et al., 2011). Both techniques obtained similar results and the accuracy achieved by them is not a statically significant difference. In previous work (Castillo, 2010; Castillo and Cardenas, 2011) we addressed the CLTE focusing on English-Spanish language pair and released a bilingual textual entailment corpus. This paper is based on that work in order to tackling the problem across different language pairs Spanish-English (SPA-ENG), Italian-English (ITA-ENG), FrenchEnglish (FRA-ENG) and German-English (GERENG) and we also used an approach based on machine translation. 3 System architecture Sagan is a CLTE</context>
</contexts>
<marker>Mehdad, Negri, Federico, 2011</marker>
<rawString>Mehdad Y., M. Negri, and M. Federico. 2011. Using Parallel Corpora for Cross-lingual Textual Entailment. In Proceedings of ACL-HLT 2011.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>