<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000594">
<title confidence="0.851074">
Combining labelled and unlabelled data: a case study on Fisher
kernels and transductive inference for biological entity recognition
</title>
<author confidence="0.963743">
Cyril Goutte, Herve Dejean, Eric Gaussier,
Nicola Cancedda and Jean-Michel Renders
</author>
<affiliation confidence="0.951049">
Xerox Research Center Europe
</affiliation>
<address confidence="0.8068335">
6, chemin de Maupertuis
38240 Meylan, France
</address>
<sectionHeader confidence="0.94616" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999633117647059">
We address the problem of using partially la-
belled data, eg large collections were only little
data is annotated, for extracting biological en-
tities. Our approach relies on a combination of
probabilistic models, which we use to model the
generation of entities and their context, and ker-
nel machines, which implement powerful cate-
gorisers based on a similarity measure and some
labelled data. This combination takes the form
of the so-called Fisher kernels which implement
a similarity based on an underlying probabilistic
model. Such kernels are compared with trans-
ductive inference, an alternative approach to
combining labelled and unlabelled data, again
coupled with Support Vector Machines. Exper-
iments are performed on a database of abstracts
extracted from Medline.
</bodyText>
<sectionHeader confidence="0.998522" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999477082352942">
The availability of electronic databases of ra-
pidly increasing sizes has encouraged the de-
velopment of methods that can tap into these
databases to automatically generate knowledge,
for example by retrieving relevant information
or extracting entities and their relationships.
Machine learning seems especially relevant in
this context, because it helps performing these
tasks with a minimum of user interaction.
A number of problems like entity extraction
or filtering can be mapped to supervised tech-
niques like categorisation. In addition, modern
supervised classification methods like Support
Vector Machines have proven to be efficient and
versatile. They do, however, rely on the avail-
ability of labelled data, where labels indicate
eg whether a document is relevant or whether
a candidate expression is an interesting entity.
This causes two important problems that mo-
tivate our work: 1) annotating data is often a
difficult and costly task involving a lot of hu-
man work&apos;, such that large collections of la-
belled data are difficult to obtain, and 2) inter-
annotator agreement tends to be low in eg ge-
nomics collections (Krauthammer et al., 2000),
thus calling for methods that are able to deal
with noise and incomplete data.
On the other hand, unsupervised techniques
do not require labelled data and can thus be
applied regardless of the annotation problems.
Unsupervised learning, however, tend to be less
data-efficient than its supervised counterpart,
requiring many more examples to discover sig-
nificant features in the data, and is incapable
of solving the same kinds of problems. For ex-
ample, an efficient clustering technique may be
able to distribute documents in a number of
well-defined clusters. However, it will be unable
to decide which clusters are relevant without a
minimum of supervision.
This motivates our study of techniques that
rely on a combination of supervised and unsu-
pervised learning, in order to leverage the avail-
ability of large collections of unlabelled data and
use a limited amount of labelled documents.
The focus of this study is on a particular
application to the genomics literature. In ge-
nomics, a vast amount of knowledge still resides
in large collections of scientific papers such as
Medline, and several approaches have been pro-
posed to extract, (semi-)automatically, informa-
tion from such papers. These approaches range
from purely statistical ones to symbolic ones
relying on linguistic and knowledge processing
tools (Ohta et al., 1997; Thomas et al., 2000;
Proux et al., 2000, for example). Furthermore,
due to the nature of the problem at hand, meth-
&apos;If automatic annotation was available, we would ba-
sically have solved our Machine Learning problem
ods derived from machine learning are called
for, (Craven and Kumlien, 1999), whether su-
pervised, unsupervised or relying on a combi-
nation of both.
Let us insist on the fact that our work is pri-
marily concerned with combining labelled and
unlabelled data, and entity extraction is used
as an application in this context. As a conse-
quence, it is not our purpose at this point to
compare our experimental results to those ob-
tained by specific machine learning techniques
applied to entity extraction (Califf, 1999). Al-
though we certainly hope that our work can be
useful for entity extraction, we rather think of
it as a methodological study which can hope-
fully be applied to different applications where
unlabelled data may be used to improve the re-
sults of supervised learning algorithms. In addi-
tion, performing a fair comparison of our work
on standard information extraction benchmarks
is not straightforward: either we would need to
obtain a large amount of unlabelled data that is
comparable to the benchmark, or we would need
to &amp;quot;un-label&amp;quot; a portion of the data. In both
cases, comparing to existing results is difficult
as the amount of information used is different.
</bodyText>
<sectionHeader confidence="0.988942" genericHeader="introduction">
2 Classification for entity extraction
</sectionHeader>
<bodyText confidence="0.968724103448276">
We formulate the following (binary) classifica-
tion problem: given an input space X, and from
a dataset of N input-output pairs (xk; yk) E
X x {-1; +11, we want to learn a classifier
h : X —� {-1; +11 so as to maximise the proba-
bility P (h(x) = y) over the fixed but unknown
joint input-output distribution of (x; y) pairs.
In this setting, binary classification is essentially
a supervised learning problem.
In order to map this to the biological en-
tity recognition problem, we consider for each
candidate term, the following binary decision
problem: is the candidate a biological entity
(y = 1) or not (y = -1). The input space is a
high dimensional feature space containing lexi-
cal, morpho-syntactic and contextual features.
In order to assess the validity of combining
labelled and unlabelled data for the particular
task of biological entity extraction, we use the
following tools. First we rely on Suport Vec-
tor Machines together with transductive infer-
ence (Vapnik, 1998; Joachims, 1999), a train-
ing technique that takes both labelled and unla-
belled data into account. Secondly, we develop
a Fisher kernel (Jaakkola and Haussler, 1999),
which derives the similarity from an underlying
(unsupervised) model of the data, used as a sim-
ilarity measure (aka kernel) within SVMs. The
learning process involves the following steps:
</bodyText>
<listItem confidence="0.998966">
• Transductive inference: learn a SVM classi-
fier h(x) using the combined (labelled and
unlabelled) dataset, using traditional ker-
nels.
• Fisher kernels:
1. Learn a probabilistic model of the data
P(xIB) using combined unlabelled and
labelled data;
2. Derive the Fisher kernel K(x; z) ex-
pressing the similarity in X-space;
3. Learn a SVM classifier h(x) using this
Fisher kernel and inductive inference.
</listItem>
<sectionHeader confidence="0.508337" genericHeader="method">
3 Probabilistic models for
co-occurence data
</sectionHeader>
<bodyText confidence="0.999807642857143">
In (Gaussier et al., 2002) we presented a gen-
eral hierarchical probabilistic model which gen-
eralises several established models like Naive
Bayes (Yang and Liu, 1999), probabilistic latent
semantic analysis (PLSA) (Hofmann, 1999) or
hierarchical mixtures (Toutanova et al., 2001).
In this model, data result from the observation
of co-occuring objects. For example, a docu-
ment collection is expressed as co-occurences
between documents and words; in entity extrac-
tion, co-occuring objects may be potential en-
tities and their context, for example. For co-
occuring objects i and j, the model is expressed
as follows:
</bodyText>
<equation confidence="0.960151">
P(i; j) =X P(a) P(iIa)X P(vIa) P(jIv)
(1)
</equation>
<bodyText confidence="0.9969178">
where a are latent classes for co-occurrences
(i; j) and v are latent nodes in a hierarchy gener-
ating objects j. In the case where no hierarchy
is needed (ie P(vIa) = 8(v = a)), the model
reduces to PLSA:
</bodyText>
<footnote confidence="0.8955565">
2In our case, biological entities are proteins, genes
and RNA, cf. section 6.
</footnote>
<equation confidence="0.872401">
P(i; j) =X P(a) P(iIa) P(jIa) (2)
</equation>
<bodyText confidence="0.999931833333333">
where a are now latent concepts over both i and
j. Parameters of the model (class probabilities
P(a) and class-conditional P(iIa) and P(jIa))
are learned using a deterministic annealing ver-
sion of the expectation-maximisation (EM) al-
gorithm (Hofmann, 1999; Gaussier et al., 2002).
</bodyText>
<sectionHeader confidence="0.98858" genericHeader="method">
4 Fisher kernels
</sectionHeader>
<bodyText confidence="0.999843043478261">
Probabilistic generative models like PLSA and
hierarchical extensions (Gaussier et al., 2002)
provide a natural way to model the generation
of the data, and allow the use of well-founded
statistical tools to learn and use the model.
In addition, they may be used to derive a
model-based measure of similarity between ex-
amples, using the so-called Fisher kernels pro-
posed by Jaakkola and Haussler (1999). The
idea behind this kernel is that using the struc-
ture implied by the generative model will give
a more relevant similarity estimate, and allow
kernel methods like the support vector machines
or nearest neighbours to leverage the probabilis-
tic model and yield improved performance (Hof-
mann, 2000).
The Fisher kernel is obtained using the log-
likelihood of the model and the Fisher informa-
tion matrix. Let us consider our collection of
documents {xk}k_1...N, and denote by `(x) =
log P(xIB) the log-likelihood of the model for
data x. The expression of the Fisher kernel
(Jaakkola and Haussler, 1999) is then:
</bodyText>
<equation confidence="0.995955">
K(x1; x2) = V`(x1)T IF —1 V`(x2) (3)
</equation>
<bodyText confidence="0.99749225">
The Fisher information matrix IF can be seen
as a way to keep the kernel expression inde-
pendent of parameterisation and is defined as
IF = E(V`(x) V`(x)T), where the gradient
is w.r.t. 0 and the expectation is taken over
P(xIB). With a suitable parameterization, the
information matrix I is usually approximated by
the identity matrix (Hofmann, 2000), leading
to the simpler kernel expression: K(x1; x2) =
V`(x1)TV`(x2).
Depending on the model, the various log-
likelihoods and their derivatives will yield dif-
ferent Fisher kernel expressions. For PLSA (2),
the parameters are 0 = [P(a); P(iIa); P(jIa)].
From the derivatives of the likelihood `(x) =
P(�j)Ex log P(i; j), we derive the following sim-
</bodyText>
<equation confidence="0.9341398">
ilarity (Hofmann, 2000):
K(x1; x2) =X P(aIdi) P(aIdj) (4)
P(a)
P(aIdi; w) P(aIdj; w)
P(wIa)
</equation>
<bodyText confidence="0.99736">
bPwdj the empirical word distributions
in documents di, dj.
</bodyText>
<sectionHeader confidence="0.985773" genericHeader="method">
5 Transductive inference
</sectionHeader>
<bodyText confidence="0.999530461538461">
In standard, inductive SVM inference, the an-
notated data is used to infer a model, which is
then applied to unannotated test data. The in-
ference consists in a trade-off between the size
of the margin (linked to generalisation abilities)
and the number of training errors. Transductive
inference (Gammerman et al., 1998; Joachims,
1999) aims at maximising the margin between
positives and negatives, while minimising not
only the actual number of incorrect predictions
on labelled examples, but also the expected
number of incorrect predictions on the set of
unannotated examples.
This is done by including the unknown la-
bels as extra variables in the original optimisa-
tion problem. In the linearly separable case, the
new optimisation problem amounts now to find
a labelling of the unannotated examples and a
hyperplane which separates all examples (anno-
tated and unannotated) with maximum margin.
In the non-separable case, slack variables are
also associated to unannotated examples and
the optimisation problem is now to find a la-
belling and a hyperplane which optimally solves
the trade-off between maximising the margin
and minimising the number of misclassified ex-
amples (annotated and unannotated).
With the introduction of unknown labels as
supplementary optimisation variables, the con-
straints of the quadratic optimisation problem
are now nonlinear, which makes solving more
difficult. However, approximated iterative algo-
rithms exist which can efficiently train Trans-
ductive SVMs. They are based on the principle
of gradually improving the solution by switching
the labels of unnannotated examples which are
misclassified at the current iteration, starting
from an initial labelling given by the standard
(inductive) SVM.
</bodyText>
<equation confidence="0.7176952">
+ X
w
with
bPwdi,
bPwdi bPwdjX
</equation>
<bodyText confidence="0.912190666666667">
WUp Is the word capitalized?
WAllUp Is the word alls capitals?
WNum Does the word contain digits?
</bodyText>
<tableCaption confidence="0.953076">
Table 1: Spelling features
</tableCaption>
<sectionHeader confidence="0.962652" genericHeader="method">
6 E xperiments
</sectionHeader>
<bodyText confidence="0.9998505">
For our experiments, we used 184 abstracts from
the Medline site. In these articles, genes, pro-
teins and RNAs were manually annotated by a
biologist as part of the BioMIRE project. These
articles contain 1405 occurrences of gene names,
792 of protein names and 81 of RNA names. All
these entities are considered relevant biological
entities. We focus here on the task of identify-
ing names corresponding to such entities in run-
ning texts, without differentiating genes from
proteins or RNAs. Once candidates for bio-
logical entity names have been identified, this
task amounts to a binary categorisation, rele-
vant candidates corresponding to biological en-
tity names. We divided these abstracts in a
training and development set (122 abstracts),
and a test set (62 abstracts). We then retained
different portions of the training labels, to be
used as labelled data, whereas the rest of the
data is considered unlabelled.
</bodyText>
<subsectionHeader confidence="0.998347">
6.1 Definition of features
</subsectionHeader>
<bodyText confidence="0.999911818181818">
First of all, the abstracts are tokenised, tagged
and lemmatized. Candidates for biological en-
tity names are then selected on the basis of the
following heuristics: a token is considered a can-
didate if it appears in one of the biological lexicons
we have at our diposal, or if it does not belong to
our general English lexicon. This simple heuris-
tics allows us to retain 93% (1521 out of 1642)
of biological names in the training set (90% in
the test set), while considering only 21% of all
possible candidates (5845 out of 27350 tokens).
It thus provides a good pre-filter which signif-
icantly improves the performance, in terms of
speed, of our system. The biological lexicons
we use were provided by the BioMIRE project,
and were derived from the resources available
at: http://iubio.bio.indiana.edu/.
For each candidate, three types of features
were considered. We first retained the part-of-
speech and some spelling information (table 1).
These features were chosen based on the inspec-
tion of gene and protein names in our lexicons.
</bodyText>
<table confidence="0.98966125">
LexPROTEIN Protein lexicon
LexGENE Gene lexicon
LexSPECIES Biological species lexicon
LEXENGLISH General English lexicon
</table>
<tableCaption confidence="0.995972">
Table 2: Features provided by lexicons.
</tableCaption>
<bodyText confidence="0.999201725">
The second type of features relates to the pres-
ence of the candidate in our lexical resources
(table 2). Lastly, the third type of features de-
scribes contextual information. The context we
consider contains the four preceding and the
four following words. However, we did not take
into account the position of the words in the
context, but only their presence in the right or
left context, and in addition we replaced, when-
ever possible, each word by a feature indicating
(a) whether the word was part of the gene lex-
icon, (b) if not whether it was part of the pro-
tein lexicon, (c) if not whether it was part of
the species lexicon, (d) and if not, whenever the
candidate was neither a noun, an adjective nor
a verb, we replaced it by its part-of-speech.
For example, the word hairless is associated
with the features given in Table 3, when en-
countered in the following sentence: Inhibition
of the DNA-binding activity of Drosophila sup-
pressor of hairless and of its human homolog,
KBF2/RBP-J kappa, by direct proteinprotein
interaction with Drosophila hairless. The word
hairless appears in the gene lexicon and is
wrongly recognized as an adjective by our tag-
ger.4 The word human, the fourth word of
the right context of hairless, belongs to the
species lexicon, ans is thus replaced by the fea-
ture RC SPECIES. Neither Drosophila nor sup-
pressor belong to the specialized lexicons we
use, and, since they are both tagged as nouns,
they are left unchanged. Prepositions and con-
junctions are replaced by their part-of-speech,
and prefixes LC and RC indicate whether they
were found in left or right context. Note that
since two prepositions appear in the left context
of hairless, the value of the LC PREP feature
is 2.
Altogether, this amounts to a total of 3690
possible features in the input space X.
</bodyText>
<footnote confidence="0.595163">
3Using these lexicons alone, the same task with the
same test data, yields: precision = 22%, recall = 76%.
¢Note that no adaptaion work has been conducted on
our tagger, which explains this error.
</footnote>
<table confidence="0.9869534">
Feature Value
LexGENE 1
ADJ 1
LC drosophila 1
LC suppressor 1
LC PREP 2
RC CONJ 1
RC SPECIES 1
RC PRON 1
RC PREP 1
</table>
<tableCaption confidence="0.722515">
Table 3: Features of hairless in \...of Drosophila
suppressor of hairless and of its human...&amp;quot;.
</tableCaption>
<subsectionHeader confidence="0.65192">
6.2 Results
</subsectionHeader>
<bodyText confidence="0.99106">
In our experiments, we have used the following
methods:
</bodyText>
<listItem confidence="0.955092692307692">
• SVM trained with inductive inference, and
using a linear kernel, a polynomial kernel of
degree d = 2 and the so-called &amp;quot;radial ba-
sis function&amp;quot; kernel (Scholkopf and Smola,
2002).
• SVM trained with transductive inference,
and using a linear kernel or a polynomial
kernel of degree d = 2.
• SVM trained with inductive inference us-
ing Fisher kernels estimated from the whole
training data (without using labels), with
different number of classes c in the PLSA
model (4).
</listItem>
<bodyText confidence="0.9999754">
The proportion of labelled data is indicated
in the tables of results. For SVM with induc-
tive inference, only the labelled portion is used.
For transductive SVM (TSVM), the remaining,
unlabelled portion is used (without the labels).
For the Fisher kernels (FK), an unsupervised
model is estimated on the full dataset using
PLSA, and a SVM is trained with inductive
inference on the labelled data only, using the
Fisher kernel as similarity measure.
</bodyText>
<subsectionHeader confidence="0.993408">
6.3 Transductive inference
</subsectionHeader>
<bodyText confidence="0.997988166666667">
Table 4 gives interesting insight into the ef-
fect of transductive inference. As expected, in
the limit where little unannotated data is used
(100% in the table), there is little to gain from
using transductive inference. Accordingly, per-
formance is roughly equivalent&apos;for SVM and
</bodyText>
<table confidence="0.999299666666667">
% annotated: 1.5% 6% 24% 100%
SVM (lin) 41.22 45.34 49.67 62.97
SVM (d=2) 40.97 46.78 52.12 62.69
SVM (rbf) 42.51 49.53 51.11 63.96
TSVM (lin) 38.63 51.64 61.84 62.91
TSVM (d=2) 43.88 52.38 55.36 62.72
</table>
<tableCaption confidence="0.997521">
Table 4: F1 scores(in %) using different propor-
</tableCaption>
<bodyText confidence="0.969846583333333">
tions of annotated data for the following models:
SVM with inductive inference (SVM) and lin-
ear (lin) kernel, second degree polynomial ker-
nel (d=2), and RBF kernel (rbf); SVM with
transductive inference (TSVM) and linear (lin)
kernel or second degree polynomial (d=2) ker-
nel.
TSVM, with a slight advantage for RBF kernel
trained with inductive inference. Interestingly,
in the other limit, ie when very little annotated
data is used, transductive inference does not
seem to yield a marked improvement over in-
ductive learning. This finding seems somehow
at odds with the results reported by Joachims
(1999) on a different task (text categorisation).
We interpret this result as a side-effect of the
search strategy, where one tries to optimise
both the size of the margin and the labelling
of the unannotated examples. In practice, an
exact optimisation over this labelling is imprac-
tical, and when a large amount of unlabelled
data is used, there is a risk that the approxi-
mate, sub-optimal search strategy described by
Joachims (1999) may fail to yield a solution that
is markedly better that the result of inductive
inference.
For the two intermediate situation, however,
transductive inference seems to provide a size-
able performance improvement. Using only 24%
of annotated data, transductive learning is able
to train a linear kernel SVM that yields approxi-
mately the same performance as inductive infer-
ence on the full annotated dataset. This means
that we get comparable performance using only
what corresponds to about 30 abstracts, com-
pared to the 122 of the full training set.
</bodyText>
<subsectionHeader confidence="0.944589">
6.4 Fisher kernels
</subsectionHeader>
<bodyText confidence="0.933956">
The situation is somewhat different for SVM
trained with inductive inference, but using
</bodyText>
<footnote confidence="0.983075">
5Performance is not strictly equivalent because SVM
and TSVM use the data differently when optimising the
trade-off parameter C over a validation set.
</footnote>
<table confidence="0.998895666666667">
% annotated: 1.5% 6% 24% 100%
SVM (lin) 41.22 45.34 49.67 62.97
SVM (d=2) 40.97 46.78 52.12 62.69
lin+FK8 46.08 42.83 54.59 63.92
lin+FK16 44.43 40.92 55.70 63.76
lin+combi 46.38 38.10 52.74 63.08
</table>
<tableCaption confidence="0.996089">
Table 5: F1 scores(in %) using different propor-
</tableCaption>
<bodyText confidence="0.965335833333334">
tions of annotated data for the following mod-
els: standard SVM with linear (lin) and second
degree polynomial kernel (d=2); Combination
of linear kernel and Fisher kernel obtained from
a PLSA with 4 classes (lin+FK4) or 8 classes
(lin+FK8), and combination of linear and all
Fisher kernels obtained from PLSA using 4, 8,
12 and 16 classes (lin+combi).
Fisher kernels obtained from a model of the
entire (non-annotated) dataset. As the use
of Fisher kernels alone was unable to consis-
tently achieve acceptable results, the similarity
we used is a combination of the standard lin-
ear kernel and the Fisher kernel (a similar solu-
tion was advocate by Hofmann (2000)). Table 5
summarises the results obtained using several
types of Fisher kernels, depending on how many
classes were used in PLSA. FK8 (resp. FK16)
indicates the model using 8 (resp. 16) classes,
while combi is a combination of the Fisher ker-
nels obtained using 4, 8, 12 and 16 classes.
The effect of Fisher kernels is not as clear-cut
as that of transductive inference. For fully an-
notated data, we obtain results that are similar
to the standard kernels, although often better
than the linear kernel. Results obtained using
1.5% and 6% annotated data seem somewhat in-
consistent, whith a large improvement for 1.5%,
but a marked degradation for 6%, suggesting
that in that case, adding labels actually hurts
performance. We conjecture that this may be
an artifact of the specific annotated set we se-
lected. For 24% annotated data, the Fisher ker-
nel provides results that are inbetween induc-
tive and transductive inference using standard
kernels.
</bodyText>
<sectionHeader confidence="0.995771" genericHeader="evaluation">
7 Discussion
</sectionHeader>
<bodyText confidence="0.993749271186441">
The results of our experiments are encouraging
in that they suggest that both transductive in-
ference and the use of Fisher kernels are poten-
tially effective way of taking unannotated data
into account to improve performance.
These experimental results suggest the follow-
ing remark. Note that Fisher kernels can be
implemented by a simple scalar product (lin-
ear kernel) between Fisher scores Vf(x) (equa-
tion 3). The question arises naturally as to
whether using non-linear kernels may improve
results. One one hand, Fisher kernels are
derived from information-geometric arguments
(Jaakkola and Haussler, 1999) which require
that the kernel reduces to an inner-product of
Fisher scores. On the other hand, polynomial
and RBF kernels often display better perfor-
mance than a simple dot-product. In order to
test this, we have performed experiments using
the same features as in section 6.4, but with a
second degree polynomial kernel. Overall, re-
sults are consistently worse than before, which
suggest that the expression of the Fisher kernel
as the inner product of Fisher scores is theoret-
ically well-founded and empirically justified.
Among possible future work, let us mention
the following technical points:
1. Optimising the weight of the contributions
of the linear kernel and Fisher kernel, eg
as K(x, y) = a (x, y) + (1 — a)FK(x, y),
a E [0, 1].
2. Understanding why the Fisher kernel alone
(ie without interpolation with the linear
kernel) is unable to provide a performance
boost, despite attractive theoretical prop-
erties.
In addition, the performance improvement
obtained by both transductive inference and
Fisher kernels suggest to use both in cunjunc-
tion. To our knowledge, the question of whether
this would allow to &amp;quot;bootstrap&amp;quot; the unlabelled
data by using them twice (once for estimating
the kernel, once in transductive learning) is still
an open research question.
Finally, regarding the application that we
have targeted, namely entity recognition, the
use of additional unlabelled data may help us
to overcome the current performance limit on
our database. None of the additional experi-
ments conducted internally using probabilisitc
models and symbolic, rule-based methods have
been able to yield F1 scores higher than 63-64%
on the same data. In order to improve on this,
we have collected several hundred additional
abstracts by querying the MedLine database.
After pre-processing, this yields more than a
hundred thousand (unlabelled) candidates that
we may use with transductive inference and/or
Fisher kernels.
</bodyText>
<sectionHeader confidence="0.994878" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999972266666667">
In this paper, we presented a comparison be-
tween two state-of-the-art methods to combine
labelled and unlabelled data: Fisher kernels and
transductive inference. Our experimental re-
sults suggest that both method are able to yield
a sizeable improvement in performance. For ex-
ample transductive learning yields performance
similar to inductive learning with only about a
quarter of the data. These results are very en-
couraging for tasks where annotation is costly
while unannotated data is easy to obtain, like
our task of biological entity recognition. In ad-
dition, it provides a way to benefit from the
availability of large electronic databases in or-
der to automatically extract knowledge.
</bodyText>
<sectionHeader confidence="0.993924" genericHeader="acknowledgments">
9 Acknowledgement
</sectionHeader>
<bodyText confidence="0.99985">
We thank Anne Schiller, Agnes Sandor and Vi-
olaine Pillet for help with the data and re-
lated experimental results. This research was
supported by the European Commission un-
der the KerMIT project no. IST-2001-25431
and the French Ministry of Research under the
BioMIRE project, grant 00S0356.
</bodyText>
<sectionHeader confidence="0.999381" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999685338709678">
M. E. Califf, editor. 1999. Proc. AAAI Work-
shop on Machine Learning for Information
Extraction. AAAI Press.
M. Craven and J. Kumlien. 1999. Construct-
ing biological knowledge bases by extract-
ing information from text sources. In Proc.
ISMB&apos;99.
A. Gammerman, V. Vovk, and V. Vapnik. 1998.
Learning by transduction. In Cooper and
Morla, eds, Proc. Uncertainty in Artificial In-
telligence, pages 145{155. Morgan Kaufmann.
Eric Gaussier, Cyril Goutte, Kris Popat, and
Francine Chen. 2002. A hierarchical model
for clustering and categorising documents.
In Crestani, Girolami, and van Rijsbergen,
eds, Advances in Information Retrieval
Proc. ECIR&apos;02, pages 229{247. Springer.
Thomas Hofmann. 1999. Probabilistic latent
semantic analysis. In Proc. Uncertainty in
Artificial Intelligence, pages 289{296. Morgan
Kaufmann.
Thomas Hofmann. 2000. Learning the similar-
ity of documents: An information-geometric
approach to document retrieval and catego-
rization. In NIPS*12, page 914. MIT Press.
Tommi S. Jaakkola and David Haussler. 1999.
Exploiting generative models in discrimina-
tive classifiers. In NIPS*11, pages 487{493.
MIT Press.
Thorsten Joachims. 1999. Transductive in-
ference for text classification using support
vector machine. In Bratko and Dzeroski,
eds, Proc. ICML&apos;99, pages 200{209. Morgan
Kaufmann.
M. Krauthammer, A. Rzhetsky, P. Morozov,
and C. Friedman. 2000. Using blast for iden-
tifying gene and protein names in journal ar-
ticles. Gene.
Y. Ohta, Y. Yamamoto, T. Okazaki,
I. Uchiyama, and T. Takagi. 1997. Au-
tomatic constructing of knowledge base from
biological papers. In Proc. ISMB&apos;97.
D. Proux, F. Reichemann, and L. Julliard.
2000. A pragmatic information extraction
strategy for gathering data on genetic inter-
actions. In Proc. ISMB&apos;00.
Bernhard Scholkopf and Alexander J. Smola.
2002. Learning with Kernels. MIT Press.
J. Thomas, D. Milward, C. Ouzounis, S. Pul-
man, and M. Caroll. 2000. Automatic ex-
traction of protein interactions from scientific
abstracts. In Proc. PSB 2000.
Kristina Toutanova, Francine Chen, Kris Popat,
and Thomas Hofmann. 2001. Text classifica-
tion in a hierarchical mixture model for small
training sets. In Proc. ACM Conf. Informa-
tion and Knowledge Management.
Vladimir N. Vapnik. 1998. Statistical Learning
Theory. Wiley.
Yiming Yang and Xin Liu. 1999. A re-
examination of text categorization methods.
In Proc. 22nd ACM SIGIR, pages 42{49.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.628227">
<title confidence="0.99882">Combining labelled and unlabelled data: a case study on kernels and transductive inference for biological entity recognition</title>
<author confidence="0.99694">Cyril Goutte</author>
<author confidence="0.99694">Herve Dejean</author>
<author confidence="0.99694">Eric</author>
<affiliation confidence="0.9103265">Cancedda Xerox Research Center</affiliation>
<address confidence="0.989247">6, chemin de 38240 Meylan, France</address>
<abstract confidence="0.982000666666667">We address the problem of using partially labelled data, eg large collections were only little data is annotated, for extracting biological entities. Our approach relies on a combination of probabilistic models, which we use to model the generation of entities and their context, and kernel machines, which implement powerful categorisers based on a similarity measure and some labelled data. This combination takes the form the so-called kernels implement a similarity based on an underlying probabilistic model. Such kernels are compared with transductive inference, an alternative approach to combining labelled and unlabelled data, again coupled with Support Vector Machines. Experiments are performed on a database of abstracts extracted from Medline.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<date>1999</date>
<booktitle>Proc. AAAI Workshop on Machine Learning for Information Extraction.</booktitle>
<editor>M. E. Califf, editor.</editor>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="8456" citStr="(1999)" startWordPosition="1354" endWordPosition="1354">s P(a) and class-conditional P(iIa) and P(jIa)) are learned using a deterministic annealing version of the expectation-maximisation (EM) algorithm (Hofmann, 1999; Gaussier et al., 2002). 4 Fisher kernels Probabilistic generative models like PLSA and hierarchical extensions (Gaussier et al., 2002) provide a natural way to model the generation of the data, and allow the use of well-founded statistical tools to learn and use the model. In addition, they may be used to derive a model-based measure of similarity between examples, using the so-called Fisher kernels proposed by Jaakkola and Haussler (1999). The idea behind this kernel is that using the structure implied by the generative model will give a more relevant similarity estimate, and allow kernel methods like the support vector machines or nearest neighbours to leverage the probabilistic model and yield improved performance (Hofmann, 2000). The Fisher kernel is obtained using the loglikelihood of the model and the Fisher information matrix. Let us consider our collection of documents {xk}k_1...N, and denote by `(x) = log P(xIB) the log-likelihood of the model for data x. The expression of the Fisher kernel (Jaakkola and Haussler, 1999</context>
<context position="18384" citStr="(1999)" startWordPosition="2984" endWordPosition="2984">rtions of annotated data for the following models: SVM with inductive inference (SVM) and linear (lin) kernel, second degree polynomial kernel (d=2), and RBF kernel (rbf); SVM with transductive inference (TSVM) and linear (lin) kernel or second degree polynomial (d=2) kernel. TSVM, with a slight advantage for RBF kernel trained with inductive inference. Interestingly, in the other limit, ie when very little annotated data is used, transductive inference does not seem to yield a marked improvement over inductive learning. This finding seems somehow at odds with the results reported by Joachims (1999) on a different task (text categorisation). We interpret this result as a side-effect of the search strategy, where one tries to optimise both the size of the margin and the labelling of the unannotated examples. In practice, an exact optimisation over this labelling is impractical, and when a large amount of unlabelled data is used, there is a risk that the approximate, sub-optimal search strategy described by Joachims (1999) may fail to yield a solution that is markedly better that the result of inductive inference. For the two intermediate situation, however, transductive inference seems to</context>
</contexts>
<marker>1999</marker>
<rawString>M. E. Califf, editor. 1999. Proc. AAAI Workshop on Machine Learning for Information Extraction. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Craven</author>
<author>J Kumlien</author>
</authors>
<title>Constructing biological knowledge bases by extracting information from text sources.</title>
<date>1999</date>
<booktitle>In Proc. ISMB&apos;99.</booktitle>
<contexts>
<context position="3867" citStr="Craven and Kumlien, 1999" startWordPosition="596" endWordPosition="599"> of knowledge still resides in large collections of scientific papers such as Medline, and several approaches have been proposed to extract, (semi-)automatically, information from such papers. These approaches range from purely statistical ones to symbolic ones relying on linguistic and knowledge processing tools (Ohta et al., 1997; Thomas et al., 2000; Proux et al., 2000, for example). Furthermore, due to the nature of the problem at hand, meth&apos;If automatic annotation was available, we would basically have solved our Machine Learning problem ods derived from machine learning are called for, (Craven and Kumlien, 1999), whether supervised, unsupervised or relying on a combination of both. Let us insist on the fact that our work is primarily concerned with combining labelled and unlabelled data, and entity extraction is used as an application in this context. As a consequence, it is not our purpose at this point to compare our experimental results to those obtained by specific machine learning techniques applied to entity extraction (Califf, 1999). Although we certainly hope that our work can be useful for entity extraction, we rather think of it as a methodological study which can hopefully be applied to di</context>
</contexts>
<marker>Craven, Kumlien, 1999</marker>
<rawString>M. Craven and J. Kumlien. 1999. Constructing biological knowledge bases by extracting information from text sources. In Proc. ISMB&apos;99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gammerman</author>
<author>V Vovk</author>
<author>V Vapnik</author>
</authors>
<title>Learning by transduction.</title>
<date>1998</date>
<booktitle>In Cooper and Morla, eds, Proc. Uncertainty in Artificial Intelligence,</booktitle>
<pages>145--155</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="10296" citStr="Gammerman et al., 1998" startWordPosition="1653" endWordPosition="1656"> are 0 = [P(a); P(iIa); P(jIa)]. From the derivatives of the likelihood `(x) = P(�j)Ex log P(i; j), we derive the following similarity (Hofmann, 2000): K(x1; x2) =X P(aIdi) P(aIdj) (4) P(a) P(aIdi; w) P(aIdj; w) P(wIa) bPwdj the empirical word distributions in documents di, dj. 5 Transductive inference In standard, inductive SVM inference, the annotated data is used to infer a model, which is then applied to unannotated test data. The inference consists in a trade-off between the size of the margin (linked to generalisation abilities) and the number of training errors. Transductive inference (Gammerman et al., 1998; Joachims, 1999) aims at maximising the margin between positives and negatives, while minimising not only the actual number of incorrect predictions on labelled examples, but also the expected number of incorrect predictions on the set of unannotated examples. This is done by including the unknown labels as extra variables in the original optimisation problem. In the linearly separable case, the new optimisation problem amounts now to find a labelling of the unannotated examples and a hyperplane which separates all examples (annotated and unannotated) with maximum margin. In the non-separable</context>
</contexts>
<marker>Gammerman, Vovk, Vapnik, 1998</marker>
<rawString>A. Gammerman, V. Vovk, and V. Vapnik. 1998. Learning by transduction. In Cooper and Morla, eds, Proc. Uncertainty in Artificial Intelligence, pages 145{155. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Gaussier</author>
<author>Cyril Goutte</author>
<author>Kris Popat</author>
<author>Francine Chen</author>
</authors>
<title>A hierarchical model for clustering and categorising documents.</title>
<date>2002</date>
<booktitle>In Crestani, Girolami, and van Rijsbergen, eds, Advances in Information Retrieval Proc. ECIR&apos;02,</booktitle>
<pages>229--247</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="6810" citStr="Gaussier et al., 2002" startWordPosition="1083" endWordPosition="1086">erlying (unsupervised) model of the data, used as a similarity measure (aka kernel) within SVMs. The learning process involves the following steps: • Transductive inference: learn a SVM classifier h(x) using the combined (labelled and unlabelled) dataset, using traditional kernels. • Fisher kernels: 1. Learn a probabilistic model of the data P(xIB) using combined unlabelled and labelled data; 2. Derive the Fisher kernel K(x; z) expressing the similarity in X-space; 3. Learn a SVM classifier h(x) using this Fisher kernel and inductive inference. 3 Probabilistic models for co-occurence data In (Gaussier et al., 2002) we presented a general hierarchical probabilistic model which generalises several established models like Naive Bayes (Yang and Liu, 1999), probabilistic latent semantic analysis (PLSA) (Hofmann, 1999) or hierarchical mixtures (Toutanova et al., 2001). In this model, data result from the observation of co-occuring objects. For example, a document collection is expressed as co-occurences between documents and words; in entity extraction, co-occuring objects may be potential entities and their context, for example. For cooccuring objects i and j, the model is expressed as follows: P(i; j) =X P(</context>
<context position="8035" citStr="Gaussier et al., 2002" startWordPosition="1283" endWordPosition="1286">P(iIa)X P(vIa) P(jIv) (1) where a are latent classes for co-occurrences (i; j) and v are latent nodes in a hierarchy generating objects j. In the case where no hierarchy is needed (ie P(vIa) = 8(v = a)), the model reduces to PLSA: 2In our case, biological entities are proteins, genes and RNA, cf. section 6. P(i; j) =X P(a) P(iIa) P(jIa) (2) where a are now latent concepts over both i and j. Parameters of the model (class probabilities P(a) and class-conditional P(iIa) and P(jIa)) are learned using a deterministic annealing version of the expectation-maximisation (EM) algorithm (Hofmann, 1999; Gaussier et al., 2002). 4 Fisher kernels Probabilistic generative models like PLSA and hierarchical extensions (Gaussier et al., 2002) provide a natural way to model the generation of the data, and allow the use of well-founded statistical tools to learn and use the model. In addition, they may be used to derive a model-based measure of similarity between examples, using the so-called Fisher kernels proposed by Jaakkola and Haussler (1999). The idea behind this kernel is that using the structure implied by the generative model will give a more relevant similarity estimate, and allow kernel methods like the support </context>
</contexts>
<marker>Gaussier, Goutte, Popat, Chen, 2002</marker>
<rawString>Eric Gaussier, Cyril Goutte, Kris Popat, and Francine Chen. 2002. A hierarchical model for clustering and categorising documents. In Crestani, Girolami, and van Rijsbergen, eds, Advances in Information Retrieval Proc. ECIR&apos;02, pages 229{247. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Probabilistic latent semantic analysis.</title>
<date>1999</date>
<booktitle>In Proc. Uncertainty in Artificial Intelligence,</booktitle>
<pages>289--296</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="7012" citStr="Hofmann, 1999" startWordPosition="1113" endWordPosition="1114">e combined (labelled and unlabelled) dataset, using traditional kernels. • Fisher kernels: 1. Learn a probabilistic model of the data P(xIB) using combined unlabelled and labelled data; 2. Derive the Fisher kernel K(x; z) expressing the similarity in X-space; 3. Learn a SVM classifier h(x) using this Fisher kernel and inductive inference. 3 Probabilistic models for co-occurence data In (Gaussier et al., 2002) we presented a general hierarchical probabilistic model which generalises several established models like Naive Bayes (Yang and Liu, 1999), probabilistic latent semantic analysis (PLSA) (Hofmann, 1999) or hierarchical mixtures (Toutanova et al., 2001). In this model, data result from the observation of co-occuring objects. For example, a document collection is expressed as co-occurences between documents and words; in entity extraction, co-occuring objects may be potential entities and their context, for example. For cooccuring objects i and j, the model is expressed as follows: P(i; j) =X P(a) P(iIa)X P(vIa) P(jIv) (1) where a are latent classes for co-occurrences (i; j) and v are latent nodes in a hierarchy generating objects j. In the case where no hierarchy is needed (ie P(vIa) = 8(v = </context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Thomas Hofmann. 1999. Probabilistic latent semantic analysis. In Proc. Uncertainty in Artificial Intelligence, pages 289{296. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Learning the similarity of documents: An information-geometric approach to document retrieval and categorization.</title>
<date>2000</date>
<booktitle>In NIPS*12,</booktitle>
<pages>914</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="8755" citStr="Hofmann, 2000" startWordPosition="1400" endWordPosition="1402"> 2002) provide a natural way to model the generation of the data, and allow the use of well-founded statistical tools to learn and use the model. In addition, they may be used to derive a model-based measure of similarity between examples, using the so-called Fisher kernels proposed by Jaakkola and Haussler (1999). The idea behind this kernel is that using the structure implied by the generative model will give a more relevant similarity estimate, and allow kernel methods like the support vector machines or nearest neighbours to leverage the probabilistic model and yield improved performance (Hofmann, 2000). The Fisher kernel is obtained using the loglikelihood of the model and the Fisher information matrix. Let us consider our collection of documents {xk}k_1...N, and denote by `(x) = log P(xIB) the log-likelihood of the model for data x. The expression of the Fisher kernel (Jaakkola and Haussler, 1999) is then: K(x1; x2) = V`(x1)T IF —1 V`(x2) (3) The Fisher information matrix IF can be seen as a way to keep the kernel expression independent of parameterisation and is defined as IF = E(V`(x) V`(x)T), where the gradient is w.r.t. 0 and the expectation is taken over P(xIB). With a suitable parame</context>
<context position="20528" citStr="Hofmann (2000)" startWordPosition="3333" endWordPosition="3334">ls: standard SVM with linear (lin) and second degree polynomial kernel (d=2); Combination of linear kernel and Fisher kernel obtained from a PLSA with 4 classes (lin+FK4) or 8 classes (lin+FK8), and combination of linear and all Fisher kernels obtained from PLSA using 4, 8, 12 and 16 classes (lin+combi). Fisher kernels obtained from a model of the entire (non-annotated) dataset. As the use of Fisher kernels alone was unable to consistently achieve acceptable results, the similarity we used is a combination of the standard linear kernel and the Fisher kernel (a similar solution was advocate by Hofmann (2000)). Table 5 summarises the results obtained using several types of Fisher kernels, depending on how many classes were used in PLSA. FK8 (resp. FK16) indicates the model using 8 (resp. 16) classes, while combi is a combination of the Fisher kernels obtained using 4, 8, 12 and 16 classes. The effect of Fisher kernels is not as clear-cut as that of transductive inference. For fully annotated data, we obtain results that are similar to the standard kernels, although often better than the linear kernel. Results obtained using 1.5% and 6% annotated data seem somewhat inconsistent, whith a large impro</context>
</contexts>
<marker>Hofmann, 2000</marker>
<rawString>Thomas Hofmann. 2000. Learning the similarity of documents: An information-geometric approach to document retrieval and categorization. In NIPS*12, page 914. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tommi S Jaakkola</author>
<author>David Haussler</author>
</authors>
<title>Exploiting generative models in discriminative classifiers.</title>
<date>1999</date>
<booktitle>In NIPS*11,</booktitle>
<pages>487--493</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="6146" citStr="Jaakkola and Haussler, 1999" startWordPosition="979" endWordPosition="982">he following binary decision problem: is the candidate a biological entity (y = 1) or not (y = -1). The input space is a high dimensional feature space containing lexical, morpho-syntactic and contextual features. In order to assess the validity of combining labelled and unlabelled data for the particular task of biological entity extraction, we use the following tools. First we rely on Suport Vector Machines together with transductive inference (Vapnik, 1998; Joachims, 1999), a training technique that takes both labelled and unlabelled data into account. Secondly, we develop a Fisher kernel (Jaakkola and Haussler, 1999), which derives the similarity from an underlying (unsupervised) model of the data, used as a similarity measure (aka kernel) within SVMs. The learning process involves the following steps: • Transductive inference: learn a SVM classifier h(x) using the combined (labelled and unlabelled) dataset, using traditional kernels. • Fisher kernels: 1. Learn a probabilistic model of the data P(xIB) using combined unlabelled and labelled data; 2. Derive the Fisher kernel K(x; z) expressing the similarity in X-space; 3. Learn a SVM classifier h(x) using this Fisher kernel and inductive inference. 3 Proba</context>
<context position="8456" citStr="Jaakkola and Haussler (1999)" startWordPosition="1351" endWordPosition="1354">el (class probabilities P(a) and class-conditional P(iIa) and P(jIa)) are learned using a deterministic annealing version of the expectation-maximisation (EM) algorithm (Hofmann, 1999; Gaussier et al., 2002). 4 Fisher kernels Probabilistic generative models like PLSA and hierarchical extensions (Gaussier et al., 2002) provide a natural way to model the generation of the data, and allow the use of well-founded statistical tools to learn and use the model. In addition, they may be used to derive a model-based measure of similarity between examples, using the so-called Fisher kernels proposed by Jaakkola and Haussler (1999). The idea behind this kernel is that using the structure implied by the generative model will give a more relevant similarity estimate, and allow kernel methods like the support vector machines or nearest neighbours to leverage the probabilistic model and yield improved performance (Hofmann, 2000). The Fisher kernel is obtained using the loglikelihood of the model and the Fisher information matrix. Let us consider our collection of documents {xk}k_1...N, and denote by `(x) = log P(xIB) the log-likelihood of the model for data x. The expression of the Fisher kernel (Jaakkola and Haussler, 1999</context>
<context position="22096" citStr="Jaakkola and Haussler, 1999" startWordPosition="3583" endWordPosition="3586">rnels. 7 Discussion The results of our experiments are encouraging in that they suggest that both transductive inference and the use of Fisher kernels are potentially effective way of taking unannotated data into account to improve performance. These experimental results suggest the following remark. Note that Fisher kernels can be implemented by a simple scalar product (linear kernel) between Fisher scores Vf(x) (equation 3). The question arises naturally as to whether using non-linear kernels may improve results. One one hand, Fisher kernels are derived from information-geometric arguments (Jaakkola and Haussler, 1999) which require that the kernel reduces to an inner-product of Fisher scores. On the other hand, polynomial and RBF kernels often display better performance than a simple dot-product. In order to test this, we have performed experiments using the same features as in section 6.4, but with a second degree polynomial kernel. Overall, results are consistently worse than before, which suggest that the expression of the Fisher kernel as the inner product of Fisher scores is theoretically well-founded and empirically justified. Among possible future work, let us mention the following technical points:</context>
</contexts>
<marker>Jaakkola, Haussler, 1999</marker>
<rawString>Tommi S. Jaakkola and David Haussler. 1999. Exploiting generative models in discriminative classifiers. In NIPS*11, pages 487{493. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Transductive inference for text classification using support vector machine.</title>
<date>1999</date>
<booktitle>In Bratko and Dzeroski, eds, Proc. ICML&apos;99,</booktitle>
<pages>200--209</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="5998" citStr="Joachims, 1999" startWordPosition="957" endWordPosition="958"> supervised learning problem. In order to map this to the biological entity recognition problem, we consider for each candidate term, the following binary decision problem: is the candidate a biological entity (y = 1) or not (y = -1). The input space is a high dimensional feature space containing lexical, morpho-syntactic and contextual features. In order to assess the validity of combining labelled and unlabelled data for the particular task of biological entity extraction, we use the following tools. First we rely on Suport Vector Machines together with transductive inference (Vapnik, 1998; Joachims, 1999), a training technique that takes both labelled and unlabelled data into account. Secondly, we develop a Fisher kernel (Jaakkola and Haussler, 1999), which derives the similarity from an underlying (unsupervised) model of the data, used as a similarity measure (aka kernel) within SVMs. The learning process involves the following steps: • Transductive inference: learn a SVM classifier h(x) using the combined (labelled and unlabelled) dataset, using traditional kernels. • Fisher kernels: 1. Learn a probabilistic model of the data P(xIB) using combined unlabelled and labelled data; 2. Derive the </context>
<context position="10313" citStr="Joachims, 1999" startWordPosition="1657" endWordPosition="1658">P(jIa)]. From the derivatives of the likelihood `(x) = P(�j)Ex log P(i; j), we derive the following similarity (Hofmann, 2000): K(x1; x2) =X P(aIdi) P(aIdj) (4) P(a) P(aIdi; w) P(aIdj; w) P(wIa) bPwdj the empirical word distributions in documents di, dj. 5 Transductive inference In standard, inductive SVM inference, the annotated data is used to infer a model, which is then applied to unannotated test data. The inference consists in a trade-off between the size of the margin (linked to generalisation abilities) and the number of training errors. Transductive inference (Gammerman et al., 1998; Joachims, 1999) aims at maximising the margin between positives and negatives, while minimising not only the actual number of incorrect predictions on labelled examples, but also the expected number of incorrect predictions on the set of unannotated examples. This is done by including the unknown labels as extra variables in the original optimisation problem. In the linearly separable case, the new optimisation problem amounts now to find a labelling of the unannotated examples and a hyperplane which separates all examples (annotated and unannotated) with maximum margin. In the non-separable case, slack vari</context>
<context position="18384" citStr="Joachims (1999)" startWordPosition="2983" endWordPosition="2984">ent proportions of annotated data for the following models: SVM with inductive inference (SVM) and linear (lin) kernel, second degree polynomial kernel (d=2), and RBF kernel (rbf); SVM with transductive inference (TSVM) and linear (lin) kernel or second degree polynomial (d=2) kernel. TSVM, with a slight advantage for RBF kernel trained with inductive inference. Interestingly, in the other limit, ie when very little annotated data is used, transductive inference does not seem to yield a marked improvement over inductive learning. This finding seems somehow at odds with the results reported by Joachims (1999) on a different task (text categorisation). We interpret this result as a side-effect of the search strategy, where one tries to optimise both the size of the margin and the labelling of the unannotated examples. In practice, an exact optimisation over this labelling is impractical, and when a large amount of unlabelled data is used, there is a risk that the approximate, sub-optimal search strategy described by Joachims (1999) may fail to yield a solution that is markedly better that the result of inductive inference. For the two intermediate situation, however, transductive inference seems to</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Transductive inference for text classification using support vector machine. In Bratko and Dzeroski, eds, Proc. ICML&apos;99, pages 200{209. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Krauthammer</author>
<author>A Rzhetsky</author>
<author>P Morozov</author>
<author>C Friedman</author>
</authors>
<title>Using blast for identifying gene and protein names in journal articles.</title>
<date>2000</date>
<publisher>Gene.</publisher>
<contexts>
<context position="2237" citStr="Krauthammer et al., 2000" startWordPosition="337" endWordPosition="340">on. In addition, modern supervised classification methods like Support Vector Machines have proven to be efficient and versatile. They do, however, rely on the availability of labelled data, where labels indicate eg whether a document is relevant or whether a candidate expression is an interesting entity. This causes two important problems that motivate our work: 1) annotating data is often a difficult and costly task involving a lot of human work&apos;, such that large collections of labelled data are difficult to obtain, and 2) interannotator agreement tends to be low in eg genomics collections (Krauthammer et al., 2000), thus calling for methods that are able to deal with noise and incomplete data. On the other hand, unsupervised techniques do not require labelled data and can thus be applied regardless of the annotation problems. Unsupervised learning, however, tend to be less data-efficient than its supervised counterpart, requiring many more examples to discover significant features in the data, and is incapable of solving the same kinds of problems. For example, an efficient clustering technique may be able to distribute documents in a number of well-defined clusters. However, it will be unable to decide</context>
</contexts>
<marker>Krauthammer, Rzhetsky, Morozov, Friedman, 2000</marker>
<rawString>M. Krauthammer, A. Rzhetsky, P. Morozov, and C. Friedman. 2000. Using blast for identifying gene and protein names in journal articles. Gene.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Ohta</author>
<author>Y Yamamoto</author>
<author>T Okazaki</author>
<author>I Uchiyama</author>
<author>T Takagi</author>
</authors>
<title>Automatic constructing of knowledge base from biological papers.</title>
<date>1997</date>
<booktitle>In Proc. ISMB&apos;97.</booktitle>
<contexts>
<context position="3575" citStr="Ohta et al., 1997" startWordPosition="548" endWordPosition="551">ination of supervised and unsupervised learning, in order to leverage the availability of large collections of unlabelled data and use a limited amount of labelled documents. The focus of this study is on a particular application to the genomics literature. In genomics, a vast amount of knowledge still resides in large collections of scientific papers such as Medline, and several approaches have been proposed to extract, (semi-)automatically, information from such papers. These approaches range from purely statistical ones to symbolic ones relying on linguistic and knowledge processing tools (Ohta et al., 1997; Thomas et al., 2000; Proux et al., 2000, for example). Furthermore, due to the nature of the problem at hand, meth&apos;If automatic annotation was available, we would basically have solved our Machine Learning problem ods derived from machine learning are called for, (Craven and Kumlien, 1999), whether supervised, unsupervised or relying on a combination of both. Let us insist on the fact that our work is primarily concerned with combining labelled and unlabelled data, and entity extraction is used as an application in this context. As a consequence, it is not our purpose at this point to compar</context>
</contexts>
<marker>Ohta, Yamamoto, Okazaki, Uchiyama, Takagi, 1997</marker>
<rawString>Y. Ohta, Y. Yamamoto, T. Okazaki, I. Uchiyama, and T. Takagi. 1997. Automatic constructing of knowledge base from biological papers. In Proc. ISMB&apos;97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Proux</author>
<author>F Reichemann</author>
<author>L Julliard</author>
</authors>
<title>A pragmatic information extraction strategy for gathering data on genetic interactions.</title>
<date>2000</date>
<booktitle>In Proc. ISMB&apos;00.</booktitle>
<contexts>
<context position="3616" citStr="Proux et al., 2000" startWordPosition="556" endWordPosition="559">earning, in order to leverage the availability of large collections of unlabelled data and use a limited amount of labelled documents. The focus of this study is on a particular application to the genomics literature. In genomics, a vast amount of knowledge still resides in large collections of scientific papers such as Medline, and several approaches have been proposed to extract, (semi-)automatically, information from such papers. These approaches range from purely statistical ones to symbolic ones relying on linguistic and knowledge processing tools (Ohta et al., 1997; Thomas et al., 2000; Proux et al., 2000, for example). Furthermore, due to the nature of the problem at hand, meth&apos;If automatic annotation was available, we would basically have solved our Machine Learning problem ods derived from machine learning are called for, (Craven and Kumlien, 1999), whether supervised, unsupervised or relying on a combination of both. Let us insist on the fact that our work is primarily concerned with combining labelled and unlabelled data, and entity extraction is used as an application in this context. As a consequence, it is not our purpose at this point to compare our experimental results to those obtai</context>
</contexts>
<marker>Proux, Reichemann, Julliard, 2000</marker>
<rawString>D. Proux, F. Reichemann, and L. Julliard. 2000. A pragmatic information extraction strategy for gathering data on genetic interactions. In Proc. ISMB&apos;00.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernhard Scholkopf</author>
<author>Alexander J Smola</author>
</authors>
<title>Learning with Kernels.</title>
<date>2002</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="16482" citStr="Scholkopf and Smola, 2002" startWordPosition="2671" endWordPosition="2674">the same task with the same test data, yields: precision = 22%, recall = 76%. ¢Note that no adaptaion work has been conducted on our tagger, which explains this error. Feature Value LexGENE 1 ADJ 1 LC drosophila 1 LC suppressor 1 LC PREP 2 RC CONJ 1 RC SPECIES 1 RC PRON 1 RC PREP 1 Table 3: Features of hairless in \...of Drosophila suppressor of hairless and of its human...&amp;quot;. 6.2 Results In our experiments, we have used the following methods: • SVM trained with inductive inference, and using a linear kernel, a polynomial kernel of degree d = 2 and the so-called &amp;quot;radial basis function&amp;quot; kernel (Scholkopf and Smola, 2002). • SVM trained with transductive inference, and using a linear kernel or a polynomial kernel of degree d = 2. • SVM trained with inductive inference using Fisher kernels estimated from the whole training data (without using labels), with different number of classes c in the PLSA model (4). The proportion of labelled data is indicated in the tables of results. For SVM with inductive inference, only the labelled portion is used. For transductive SVM (TSVM), the remaining, unlabelled portion is used (without the labels). For the Fisher kernels (FK), an unsupervised model is estimated on the full</context>
</contexts>
<marker>Scholkopf, Smola, 2002</marker>
<rawString>Bernhard Scholkopf and Alexander J. Smola. 2002. Learning with Kernels. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Thomas</author>
<author>D Milward</author>
<author>C Ouzounis</author>
<author>S Pulman</author>
<author>M Caroll</author>
</authors>
<title>Automatic extraction of protein interactions from scientific abstracts.</title>
<date>2000</date>
<booktitle>In Proc. PSB</booktitle>
<contexts>
<context position="3596" citStr="Thomas et al., 2000" startWordPosition="552" endWordPosition="555">ed and unsupervised learning, in order to leverage the availability of large collections of unlabelled data and use a limited amount of labelled documents. The focus of this study is on a particular application to the genomics literature. In genomics, a vast amount of knowledge still resides in large collections of scientific papers such as Medline, and several approaches have been proposed to extract, (semi-)automatically, information from such papers. These approaches range from purely statistical ones to symbolic ones relying on linguistic and knowledge processing tools (Ohta et al., 1997; Thomas et al., 2000; Proux et al., 2000, for example). Furthermore, due to the nature of the problem at hand, meth&apos;If automatic annotation was available, we would basically have solved our Machine Learning problem ods derived from machine learning are called for, (Craven and Kumlien, 1999), whether supervised, unsupervised or relying on a combination of both. Let us insist on the fact that our work is primarily concerned with combining labelled and unlabelled data, and entity extraction is used as an application in this context. As a consequence, it is not our purpose at this point to compare our experimental re</context>
</contexts>
<marker>Thomas, Milward, Ouzounis, Pulman, Caroll, 2000</marker>
<rawString>J. Thomas, D. Milward, C. Ouzounis, S. Pulman, and M. Caroll. 2000. Automatic extraction of protein interactions from scientific abstracts. In Proc. PSB 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Francine Chen</author>
<author>Kris Popat</author>
<author>Thomas Hofmann</author>
</authors>
<title>Text classification in a hierarchical mixture model for small training sets.</title>
<date>2001</date>
<booktitle>In Proc. ACM Conf. Information and Knowledge Management.</booktitle>
<contexts>
<context position="7062" citStr="Toutanova et al., 2001" startWordPosition="1118" endWordPosition="1121">set, using traditional kernels. • Fisher kernels: 1. Learn a probabilistic model of the data P(xIB) using combined unlabelled and labelled data; 2. Derive the Fisher kernel K(x; z) expressing the similarity in X-space; 3. Learn a SVM classifier h(x) using this Fisher kernel and inductive inference. 3 Probabilistic models for co-occurence data In (Gaussier et al., 2002) we presented a general hierarchical probabilistic model which generalises several established models like Naive Bayes (Yang and Liu, 1999), probabilistic latent semantic analysis (PLSA) (Hofmann, 1999) or hierarchical mixtures (Toutanova et al., 2001). In this model, data result from the observation of co-occuring objects. For example, a document collection is expressed as co-occurences between documents and words; in entity extraction, co-occuring objects may be potential entities and their context, for example. For cooccuring objects i and j, the model is expressed as follows: P(i; j) =X P(a) P(iIa)X P(vIa) P(jIv) (1) where a are latent classes for co-occurrences (i; j) and v are latent nodes in a hierarchy generating objects j. In the case where no hierarchy is needed (ie P(vIa) = 8(v = a)), the model reduces to PLSA: 2In our case, biol</context>
</contexts>
<marker>Toutanova, Chen, Popat, Hofmann, 2001</marker>
<rawString>Kristina Toutanova, Francine Chen, Kris Popat, and Thomas Hofmann. 2001. Text classification in a hierarchical mixture model for small training sets. In Proc. ACM Conf. Information and Knowledge Management.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>Statistical Learning Theory.</title>
<date>1998</date>
<publisher>Wiley.</publisher>
<contexts>
<context position="5981" citStr="Vapnik, 1998" startWordPosition="955" endWordPosition="956"> essentially a supervised learning problem. In order to map this to the biological entity recognition problem, we consider for each candidate term, the following binary decision problem: is the candidate a biological entity (y = 1) or not (y = -1). The input space is a high dimensional feature space containing lexical, morpho-syntactic and contextual features. In order to assess the validity of combining labelled and unlabelled data for the particular task of biological entity extraction, we use the following tools. First we rely on Suport Vector Machines together with transductive inference (Vapnik, 1998; Joachims, 1999), a training technique that takes both labelled and unlabelled data into account. Secondly, we develop a Fisher kernel (Jaakkola and Haussler, 1999), which derives the similarity from an underlying (unsupervised) model of the data, used as a similarity measure (aka kernel) within SVMs. The learning process involves the following steps: • Transductive inference: learn a SVM classifier h(x) using the combined (labelled and unlabelled) dataset, using traditional kernels. • Fisher kernels: 1. Learn a probabilistic model of the data P(xIB) using combined unlabelled and labelled dat</context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>Vladimir N. Vapnik. 1998. Statistical Learning Theory. Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yiming Yang</author>
<author>Xin Liu</author>
</authors>
<title>A reexamination of text categorization methods.</title>
<date>1999</date>
<booktitle>In Proc. 22nd ACM SIGIR,</booktitle>
<pages>42--49</pages>
<contexts>
<context position="6949" citStr="Yang and Liu, 1999" startWordPosition="1104" endWordPosition="1107">teps: • Transductive inference: learn a SVM classifier h(x) using the combined (labelled and unlabelled) dataset, using traditional kernels. • Fisher kernels: 1. Learn a probabilistic model of the data P(xIB) using combined unlabelled and labelled data; 2. Derive the Fisher kernel K(x; z) expressing the similarity in X-space; 3. Learn a SVM classifier h(x) using this Fisher kernel and inductive inference. 3 Probabilistic models for co-occurence data In (Gaussier et al., 2002) we presented a general hierarchical probabilistic model which generalises several established models like Naive Bayes (Yang and Liu, 1999), probabilistic latent semantic analysis (PLSA) (Hofmann, 1999) or hierarchical mixtures (Toutanova et al., 2001). In this model, data result from the observation of co-occuring objects. For example, a document collection is expressed as co-occurences between documents and words; in entity extraction, co-occuring objects may be potential entities and their context, for example. For cooccuring objects i and j, the model is expressed as follows: P(i; j) =X P(a) P(iIa)X P(vIa) P(jIv) (1) where a are latent classes for co-occurrences (i; j) and v are latent nodes in a hierarchy generating objects </context>
</contexts>
<marker>Yang, Liu, 1999</marker>
<rawString>Yiming Yang and Xin Liu. 1999. A reexamination of text categorization methods. In Proc. 22nd ACM SIGIR, pages 42{49.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>