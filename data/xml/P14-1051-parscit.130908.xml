<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.99723">
ReNew: A Semi-Supervised Framework for Generating Domain-Specific
Lexicons and Sentiment Analysis
</title>
<author confidence="0.998991">
Zhe Zhang
</author>
<affiliation confidence="0.824441">
Department of Computer Science
North Carolina State University
</affiliation>
<address confidence="0.83531">
Raleigh, NC 27695-8206
</address>
<email confidence="0.997098">
zzhang13@ncsu.edu
</email>
<sectionHeader confidence="0.99385" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999861409090909">
The sentiment captured in opinionated text
provides interesting and valuable informa-
tion for social media services. However,
due to the complexity and diversity of
linguistic representations, it is challeng-
ing to build a framework that accurately
extracts such sentiment. We propose a
semi-supervised framework for generat-
ing a domain-specific sentiment lexicon
and inferring sentiments at the segment
level. Our framework can greatly reduce
the human effort for building a domain-
specific sentiment lexicon with high qual-
ity. Specifically, in our evaluation, work-
ing with just 20 manually labeled reviews,
it generates a domain-specific sentiment
lexicon that yields weighted average F-
Measure gains of 3%. Our sentiment clas-
sification model achieves approximately
1% greater accuracy than a state-of-the-art
approach based on elementary discourse
units.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99861125">
Automatically extracting sentiments from user-
generated opinionated text is important in build-
ing social media services. However, the complex-
ity and diversity of the linguistic representations
of sentiments make this problem challenging.
High-quality sentiment lexicons can improve
the performance of sentiment analysis models over
general-purpose lexicons (Choi and Cardie, 2009).
More advanced methods such as (Kanayama and
Nasukawa, 2006) adopt domain knowledge by ex-
tracting sentiment words from the domain-specific
corpus. However, depending on the context, the
same word can have different polarities even in the
same domain (Liu, 2012).
In respect to sentiment classification, Pang et
al. (2002) infer the sentiments using basic features,
</bodyText>
<author confidence="0.51443">
Munindar P. Singh
</author>
<affiliation confidence="0.773827">
Department of Computer Science
North Carolina State University
</affiliation>
<address confidence="0.554654">
Raleigh, NC 27695-8206
</address>
<email confidence="0.96845">
singh@ncsu.edu
</email>
<bodyText confidence="0.999876346153846">
such as bag-of-words. To capture more complex
linguistic phenomena, leading approaches (Naka-
gawa et al., 2010; Jo and Oh, 2011; Kim et al.,
2013) apply more advanced models but assume
one document or sentence holds one sentiment.
However, this is often not the case. Sentiments
can change within one document, one sentence,
or even one clause. Also, existing approaches in-
fer sentiments without considering the changes of
sentiments within or between clauses. However,
these changes can be successfully exploited for in-
ferring fine-grained sentiments.
To address the above shortcomings of lexicon
and granularity, we propose a semi-supervised
framework named ReNew. (1) Instead of us-
ing sentences, ReNew uses segments as the basic
units for sentiment classification. Segments can
be shorter than sentences and therefore help cap-
ture fine-grained sentiments. (2) ReNew leverages
the relationships between consecutive segments to
infer their sentiments and automatically generates
a domain-specific sentiment lexicon in a semi-su-
pervised fashion. (3) To capture the contextual
sentiment of words, ReNew uses dependency re-
lation pairs as the basic elements in the generated
sentiment lexicon.
</bodyText>
<figureCaption confidence="0.999072">
Figure 1: Segments in a Tripadvisor review.
</figureCaption>
<bodyText confidence="0.9812885">
Consider a part of a review from Tripadvisor.1
We split it into six segments with sentiment labels.
</bodyText>
<footnote confidence="0.9334045">
1http://www.tripadvisor.com/ShowUserReviews-g32655-
d81765-r100000013
</footnote>
<figure confidence="0.953105285714286">
transition cue transition cue
Sentiment
NEG
POS
NEU
1 2 3 4 5
Segment
</figure>
<page confidence="0.962035">
542
</page>
<note confidence="0.8326815">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 542–551,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.996219594594595">
“... (1: POS) The hotel was clean and
comfortable. (2: POS) Service was
friendly (3: POS) even providing us a
late-morning check-in. (4: POS) The
room was quiet and comfortable, (5:
NEG) but it was beginning to show a
few small signs of wear and tear.... ”
Figure 1 visualizes the sentiment changes
within the text. The sentiment remains the same
across Segments 1 to 4. The sentiment transi-
tion between Segments 4 and 5 is indicated by the
transition cue “but”—which signals conflict and
contradiction. Assuming we know Segment 4 is
positive, given the fact that Segment 5 starts with
“but,” we can infer with high confidence that the
sentiment in Segment 5 changes to neutral or nega-
tive even without looking at its content. After clas-
sifying the sentiment of Segment 5 as NEG, we
associate the dependency relation pairs {“sign”,
“wear”} and {“sign”, “tear”} with that sentiment.
ReNew can greatly reduce the human effort for
building a domain-specific sentiment lexicon with
high quality. Specifically, in our evaluation on
two real datasets, working with just 20 manu-
ally labeled reviews, ReNew generates a domain-
specific sentiment lexicon that yields weighted av-
erage F-Measure gains of 3%. Additionally, our
sentiment classification model achieves approxi-
mately 1% greater accuracy than a state-of-the-
art approach based on elementary discourse units
(Lazaridou et al., 2013).
The rest of this paper is structured as follows.
Section 2 introduces some essential background.
Section 3 illustrates ReNew. Section 4 presents
our experiments and results. Section 5 reviews
some related work. Section 6 concludes this pa-
per and outlines some directions for future work.
</bodyText>
<sectionHeader confidence="0.899128" genericHeader="introduction">
2 Background
</sectionHeader>
<listItem confidence="0.994354833333333">
Let us introduce some of the key terminology used
in ReNew. A segment is a sequence of words
that represents at most one sentiment. A seg-
ment can consist of multiple consecutive clauses,
up to a whole sentence. Or, it can be shorter
than a clause. A dependency relation defines a
binary relation that describes whether a pairwise
syntactic relation among two words holds in a sen-
tence. In ReNew, we exploit the Stanford typed
dependency representations (de Marneffe et al.,
2006) that use triples to formalize dependency re-
lations. A domain-specific sentiment lexicon con-
</listItem>
<bodyText confidence="0.992177571428571">
tains three lists of dependency relations, associ-
ated respectvely with positive, neutral, or negative
sentiment.
Given a set of reviews, the tasks of senti-
ment analysis in ReNew are (1) splitting each re-
view into segments, (2) associating each segment
with a sentiment label (positive, neutral, nega-
tive), and (3) automatically generating a domain-
specific sentiment lexicon. We employ Condi-
tional Random Fields (Lafferty et al., 2001) to pre-
dict the sentiment label for each segment. Given a
sequence of segments x¯ = (x1, · · · , xn) and a se-
quence of sentiment labels y¯ = (y1, · · · , yn), the
CRFs model p(¯y|¯x) as follows.
</bodyText>
<equation confidence="0.999182833333333">
1 J
p(¯y|¯x) = Z(¯x) exp (wj · Fj(¯x, ¯y))
j
n
Fj(¯x, ¯y) = fj(yZ−1, yZ, ¯x, i)
Z=1
</equation>
<bodyText confidence="0.999956">
where w is a set of weights learned in the train-
ing process to maximize p(¯y|¯x). Z(¯x) is a nor-
malization constant that is the sum of all possible
label sequences. And, Fj is a feature function that
sums fj over i E (1, n), where n is the length of
¯y, and fj can have arbitrary dependencies on the
observation sequence x¯ and neighboring labels.
</bodyText>
<sectionHeader confidence="0.986071" genericHeader="method">
3 Framework
</sectionHeader>
<figureCaption confidence="0.999999">
Figure 2: The ReNew framework schematically.
Figure 2 illustrates ReNew. Its inputs include
</figureCaption>
<figure confidence="0.999019235294118">
Seed Information
Labeled
Data
General
Lexicon
Sentiment Labeling
or
Learner Retraining
Bootstrapping Process
Segmentation
Unlabeled
Data
Lexicon
Generator
Domain
Specific
Lexicon
</figure>
<page confidence="0.997999">
543
</page>
<bodyText confidence="0.999494666666667">
a general sentiment lexicon and a small labeled
training dataset. We use a general sentiment lexi-
con and the training dataset as prior knowledge to
build the initial learners.
On each iteration in the bootstrapping process,
additional unlabeled data is first segmented. Sec-
ond, the learners predict labels for segments based
on current knowledge. Third, the lexicon gener-
ator determines which newly learned dependency
relation triples to promote to the lexicon. At the
end of each iteration, the learners are retrained via
the updated lexicon so as to classify better on the
next iteration. After labeling all of the data, we
obtain the final version of our learners along with
a domain-specific lexicon.
</bodyText>
<subsectionHeader confidence="0.992521">
3.1 Rule-Based Segmentation Algorithm
</subsectionHeader>
<bodyText confidence="0.286104">
Algorithm 1 Rule-based segmentation.
</bodyText>
<listItem confidence="0.953610058823529">
Require: Review dataset T
1: for all review r in T do
2: Remove HTML tags
3: Expand typical abbreviations
4: Mark special name-entities
5: for all sentence m in r do
6: while m contains a transition cue and m
is not empty do
7: Extract subclause p that contains the
transition cue
8: Add p as segment s into segment list
9: Remove p from m
10: end while
11: Add the remaining part in m as segment
s into segment list
12: end for
13: end for
</listItem>
<bodyText confidence="0.99695125">
The algorithm starts with a review dataset T.
Each review r from dataset T is first normalized
by a set of hard-coded rules (lines 2–4) to remove
unnecessary punctuations and HTML tags, expand
typical abbreviations, and mark special name enti-
ties (e.g., replace a URL by #LINK# and replace a
monetary amount “$78.99” by #MONEY#).
After the normalization step, it splits each re-
view r into sentences, and each sentence into sub-
clauses (lines 6–10) provided transition cues oc-
cur. In effect, the algorithm converts each review
into a set of segments.
Note that ReNew captures and uses the senti-
ment changes. Therefore, our segmentation algo-
rithm considers only two specific types of transi-
tion cues including contradiction and emphasis.
</bodyText>
<subsectionHeader confidence="0.999946">
3.2 Sentiment Labeling
</subsectionHeader>
<bodyText confidence="0.9996715">
ReNew starts with a small labeled training set.
Knowledge from this initial training set is not suf-
ficient to build an accurate sentiment classification
model or to generate a domain-specific sentiment
lexicon. Unlabeled data contains rich knowledge,
and it can be easily obtained. To exploit this re-
source, on each iteration, the sentiment labeling
component, as shown in Figure 3, labels the data
by using multiple learners and a label integrator.
We have developed a forward (FR) and a back-
ward relationship (BR) learner to learn relation-
ships among segments.
</bodyText>
<figureCaption confidence="0.883793">
Figure 3: Sentiment labeling.
3.2.1 FR and BR Learners
</figureCaption>
<bodyText confidence="0.946001444444444">
The FR learner learns the relationship between the
current segment and the next. Given the senti-
ment label and content of a segment, it tries to find
the best possible sentiment label of the next seg-
ment. The FR Learner tackles the following situa-
tion where two segments are connected by a tran-
sition word, but existing knowledge is insufficient
to infer the sentiment of the second segment. For
instance, consider the following review sentence.2
(1) The location is great, (2) but the staff was
pretty ho-hum about everything from checking in,
to AM hot coffee, to PM bar.
The sentence contains two segments. We can
easily infer the sentiment polarity of Segment 1
based on the word “great” that is commonly in-
cluded in many general sentiment lexicons. For
Segment 2, without any context information, it
is difficult to infer its sentiment. Although the
</bodyText>
<footnote confidence="0.71758">
2http://www.tripadvisor.com/ShowUserReviews-g60763-
d93589-r10006597
</footnote>
<figure confidence="0.9984958">
Unlabeled
segments
reverse
order
Sentiment Labeling
Forward
Relationship
Backward
Relationship
Learner
Learner
Labeled
segments
Label
Integrator
</figure>
<page confidence="0.993441">
544
</page>
<bodyText confidence="0.99993225">
word “ho-hum” indicates a negative polarity, it
is not a frequent word. However, the conjunc-
tion “but” clearly signals a contrast. So, given
the fact that the former segment is positive, a pre-
trained FR learner can classify the latter as neg-
ative. The Backward Relationship (BR) learner
does the same but with the segments in each re-
view in reverse order.
</bodyText>
<subsectionHeader confidence="0.712028">
3.2.2 Label Integrator
</subsectionHeader>
<bodyText confidence="0.9999765">
Given the candidate sentiment labels suggested by
the two learners, the label integrator first selects
the label with confidence greater than or equal to
a preset threshold. Segments are left unlabeled if
their candidate labels belong to mutually exclusive
categories with the same confidence.
</bodyText>
<subsectionHeader confidence="0.999641">
3.3 Lexicon Generator
</subsectionHeader>
<bodyText confidence="0.999844636363636">
In each iteration, after labeling a segment, the lexi-
con generator identifies new triples automatically.
As shown in Figure 4, this module contains two
parts: a Triple Extractor and a Lexicon Integra-
tor. For each sentiment, the Triple Extractor (TE)
extracts candidate dependency relation triples us-
ing a novel rule-based approach. The Lexicon
Integrator (LI) evaluates the proposed candidates
and promotes the most supported candidates to the
corresponding sentiment category in the domain-
specific lexicon.
</bodyText>
<figureCaption confidence="0.994156">
Figure 4: Lexicon generator module.
</figureCaption>
<subsectionHeader confidence="0.652763">
3.3.1 Triple Extractor (TE)
</subsectionHeader>
<bodyText confidence="0.998778833333333">
The TE follows the steps below, for segments
that contain only one clause, as demonstrated
in Figure 5 for “The staff was slow and defi-
nitely not very friendly.” The extracted triples are
root nsubj(slow, staff), nsubj(slow, staff), and
nsubj(not friendly, staff).
</bodyText>
<listItem confidence="0.914480181818182">
1. Generate a segment’s dependency parse tree.
2. Identify the root node of each clause in the
segment.
3. Remove all triples except those marked E in
Table 1.
4. Apply the rules in Table 2 to add or modify
triples.
5. Suggest the types of triples marked L in Ta-
ble 1 to the lexicon integrator.
Table 1: Dependency relation types used in ex-
tracting (E) and domain-specific lexicon (L).
</listItem>
<subsectionHeader confidence="0.836274">
Types Explanation E L
</subsectionHeader>
<bodyText confidence="0.958147432432432">
√ √
amod adjectival modifier
conj and words coordinated by “and” √
or similar
prep with words coordinated by “with” √
root root node √
root amod amod root node
root acomp acomp root node
root nsubj nsubj root node
neg pattern “neg” pattern √
√
√
√
Table 1 describes all seven types of triples used
in the domain-specific lexicon. Among them,
amod, acomp, and nsubj are as in (de Marneffe
et al., 2006). And, root amod captures the root
node of a sentence when it also appears in the ad-
jectival modifier triple, similarly for root acomp
and root nsubj. We observe that the word of the
root node is often related to the sentiment of a sen-
tence and this is especially true when this word
also appears in the adjectival modifier, adjectival
complement, or negation modifier triple.
Zhang et al. (2010) propose the no pattern that
describes a word pair whose first word is “No”
followed by a noun or noun phrase. They show
that this pattern is a useful indicator for sentiment
analysis. In our dataset, in addition to “No,” we
observe the frequent usage of “Nothing” followed
by an adjective. For example, users may express a
negative feeling about a hotel using sentence such
as “Nothing special.” Therefore, we create the
neg pattern to capture a larger range of possible
word pairs. In ReNew, neg pattern is “No” or
“Nothing” followed by a noun or noun phrase or
an adjective.
</bodyText>
<subsectionHeader confidence="0.650933">
3.3.2 Lexicon Integrator (LI)
</subsectionHeader>
<bodyText confidence="0.9987545">
The Lexicon Integrator promotes candidate triples
with a frequency greater than or equal to a preset
</bodyText>
<figure confidence="0.987590107142857">
Labeled
segments
Triple
Extractor
Lexicon Generator
Lexicon
Integrator
Domain
Specific
Lexicon
√ √
√ √
nsubj nominal subject
neg
acomp adjectival complement
negation modifier √
545
root
Table 2: Rules for extracting sentiment triples.
not very
root
friendly
root
not_friendly
root
slow
(d) staff
not_friendly
</figure>
<figureCaption confidence="0.9580838">
Figure 5: Extracting sentiment triples from a seg-
ment that contains one clause. (a) The initial de-
pendency parse tree. (b) Remove nonsentiment
triples. (c) Handle negation triples. (d) Build rela-
tionships.
</figureCaption>
<bodyText confidence="0.998839157894737">
threshold. The frequency list is updated in each
iteration. The LI first examines the prior knowl-
edge represented as an ordered list of the gover-
nors of all triples, each is attached with an ordered
list of its dependents. Then, based on the triples
promoted in this iteration, the order of the gover-
nors and their dependents is updated. Triples are
not promoted if their governors or dependents ap-
pear in a predetermined list of stopwords.
The LI promotes triples by respecting mutual
exclusion and the existing lexicon. In particular,
it does not promote triples if they exist in multiple
sentiment categories or if they already belong to a
different sentiment category.
Finally, for each sentiment, we obtain seven
sorted lists corresponding to amod, acomp,
nsubj, root amod, root acomp, root nsubj, and
neg pattern. These lists form the domain-specific
sentiment lexicon.
</bodyText>
<table confidence="0.897224769230769">
Rule Function Condition Result
R1 Handle Negation word wi; wi = wdep + “
neg(wgov, wdep); + wi
wi = wgov;
R2 Build Relationships word wi and wj; amod(wgov, wi)
(conj and, amod) conj and(wi,wj); amod(wgov,wj)
amod(wgov, wi);
R3 Build Relationships word wi and wj; acomp(wgov, wi)
(conj and, acomp) conj and(wi,wj); acomp(wgov,wj)
acomp(wgov, wi);
R4 Build Relationships word wi and wj; nsubj(wi, wdep)
(conj and, nsubj) conj and(wi,wj); nsubj(wj, wdep)
nsubj(wi, wdep);
</table>
<subsectionHeader confidence="0.951216">
3.4 Learner Retraining
</subsectionHeader>
<bodyText confidence="0.9999895">
At the end of each iteration, ReNew retrains each
learner as shown in Figure 6. Newly labeled seg-
ments are selected by a filter. Then, given an up-
dated lexicon, learners are retrained to perform
better on the next iteration. Detailed description
of the filter and learner are presented below.
</bodyText>
<sectionHeader confidence="0.554273" genericHeader="method">
3.4.1 Filter
</sectionHeader>
<bodyText confidence="0.998706375">
The filter seeks to prevent labeling errors from
accumulating during bootstrapping. In ReNew,
newly acquired training samples are segments
with labels that are predicted by old learners. Each
predicted label is associated with a confidence
value. The filter is applied to select those labeled
segments with confidence greater than or equal to
a preset threshold.
</bodyText>
<figureCaption confidence="0.838573">
Figure 6: Retrain a relationship learner.
</figureCaption>
<sectionHeader confidence="0.530846" genericHeader="method">
3.4.2 Learner
</sectionHeader>
<bodyText confidence="0.998493">
As Section 3.2 describes, ReNew uses learners to
capture different types of relationships among seg-
ments to classify sentiment by leveraging these
relationships. Each learner contains two com-
ponents: a feature extractor and a classification
model. To train a learner, the feature extractor
first converts labeled segments into feature vectors
</bodyText>
<figure confidence="0.999395945945946">
nsubj slow
staff
det cop advmod
(a)
conj_and
The
was
definitely
neg
friendly
advmod
slow
nsubj
(b)
staff
conj_and
neg
not
slow
nsubj
(c)
staff
conj_and
Labeled
segments
Filter
Learner Retraining
Feature
Extractor
Domain
Specific
Lexicon
Learner
Classification
Model
nsubj
nsubj
</figure>
<page confidence="0.996265">
546
</page>
<tableCaption confidence="0.8533985">
Table 3: A list of transition types used in ReNew.
Transition Types Examples
</tableCaption>
<note confidence="0.809066">
Agreement, Addition, and Similarity also, similarly, as well as, ...
Opposition, Limitation, and Contradiction but, although, in contrast, ...
Cause, Condition, and Purpose if, since, as/so long as, ...
Examples, Support, and Emphasis including, especially, such as, ...
Effect, Consequence, and Result therefore, thus, as a result ...
Conclusion, Summary, and Restatement overall, all in all, to sum up, ...
Time, Chronology, and Sequence until, eventually, as soon as, ...
</note>
<bodyText confidence="0.998626782608696">
for training a CRF-based sentiment classification
model. The feature extractor generates five kinds
of features as below.
Grammar: part-of-speech tag of every word, the
type of phrases and clauses (if known).
Opinion word: To exploit a general sentiment
lexicon, we use two binary features indicat-
ing the presence or absence of a word in the
positive or negative list in a general sentiment
lexicon.
Dependency relation: The lexicon generated by
ReNew uses the Stanford typed dependency
representation as its structure.
Transition cue: For tracking the changes of the
sentiment, we exploit seven types of transi-
tion cues, as shown in Table 3.
Punctuation, special name-entity, and seg-
ment position: Some punctuation symbols,
such as “!”, are reliable carriers of senti-
ments. We mark special named-entities, such
as time, money, and so on. In addition,
we use segment positions (beginning, middle,
and end) in reviews as features.
</bodyText>
<sectionHeader confidence="0.99965" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999986909090909">
To assess ReNew’s effectiveness, we prepare two
hotel review datasets crawled from Tripadvisor.
One dataset contains a total of 4,017 unlabeled re-
views regarding 802 hotels from seven US cities.
The reviews are posted by 340 users, each of
whom contributes at least ten reviews. The other
dataset contains 200 reviews randomly selected
from Tripadvisor. We collected ground-truth la-
bels for this dataset by inviting six annotators
in two groups of three. Each group labeled the
same 100 reviews. We obtained the labels for
each segment consist as positive, neutral, or nega-
tive. Fleiss’ kappa scores for the two groups were
0.70 and 0.68, respectively, indicating substantial
agreement between our annotators.
The results we present in the remainder of this
section rely upon the following parameter values.
The confidence thresholds used in the Label In-
tegrator and filter are both set to 0.9 for positive
labels and 0.7 for negative and neutral labels. The
minimum frequency used in the Lexicon Integra-
tor for selecting triples is set to 4.
</bodyText>
<subsectionHeader confidence="0.989135">
4.1 Feature Function Evaluation
</subsectionHeader>
<bodyText confidence="0.999884583333333">
Our first experiment evaluates the effects of dif-
ferent combinations of features. To do this, we
first divide all features into four basic feature sets:
T (transition cues), P (punctuations, special name-
entities, and segment positions), G (grammar), and
OD (opinion words and dependency relations).
We train 15 sentiment classification models using
all basic features and their combinations. Figure 7
shows the results of a 10-fold cross validation on
the 200-review dataset (light grey bars show the
accuracy of the model trained without using tran-
sition cue features).
</bodyText>
<figure confidence="0.405191">
Accuracy
</figure>
<figureCaption confidence="0.99987">
Figure 7: Accuracy using different features.
</figureCaption>
<bodyText confidence="0.999840125">
The feature OD yields the best accuracy, fol-
lowed by G, P, and T. Although T yields the worst
accuracy, incorporating it improves the resulting
accuracy of the other features, as shown by the
dark grey bars. In particular, the accuracy of OD
is markedly improved by adding T. The model
trained using all the feature sets yields the best ac-
curacy.
</bodyText>
<subsectionHeader confidence="0.952496">
4.2 Relationship Learners Evaluation
</subsectionHeader>
<bodyText confidence="0.999558875">
Our second experiment evaluates the impact of the
relationship learners and the label integrator. To
this end, we train and compare sentiment classifi-
cation models using three configurations. The first
configuration (FW-L) uses only the FR learner; the
second (BW-L) only the BR learner. ALL-L uses
both the FR and BR learners, together with a label
integrator. We evaluate them with 10-fold cross
</bodyText>
<figure confidence="0.960379714285714">
0.5 0.52 0.54 0.56 0.58 0.6 0.62 0.64 0.66 0.68
Feature
OD+G+P
OD+G
OD+P
G+P
OD
G
T
P
w/o transition cues (T)
w/ transition cues (T)
547
Accuracy Macro F-score Micro F-score
</figure>
<figureCaption confidence="0.9218505">
Figure 8: Comparison among the learners.
Figure 8 reports the accuracy, macro F-score,
and micro F-score. It shows that the BR learner
produces better accuracy and a micro F-score than
</figureCaption>
<bodyText confidence="0.9298838">
the FR learner but a slightly worse macro F-score.
Jointly considering both learners with the label in-
tegrator achieves better results than either alone.
The results demonstrate the effectiveness of our
sentiment labeling component.
</bodyText>
<subsectionHeader confidence="0.99637">
4.3 Domain-Specific Lexicon Assessment
</subsectionHeader>
<bodyText confidence="0.999994325581395">
Our third experiment evaluates the quality of the
domain-specific lexicon automatically generated
by ReNew. To do this, we first transform each
of the 200 labeled reviews into feature vectors.
Then we retrain Logistic Regression models us-
ing WEKA (Hall et al., 2009). Note that we use
only the features extracted from the lexicons them-
selves. This is important because to compare only
the lexicons’ impact on sentiment classification,
we need to avoid the effect of other factors, such
as syntax, transition cues, and so on. We com-
pare models trained using (1) our domain-specific
lexicon, (2) Affective Norms for English Words
(ANEW) (Bradley and Lang, 1999), and (3) Lin-
guistic Inquiry and Word Count (LIWC) (Tausczik
and Pennebaker, 2010). ANEW and LIWC are
well-known general sentiment lexicons.
Table 4 shows the results obtained by 10-fold
cross validation. Each weighted average is com-
puted according to the number of segments in
each class. The table shows the significant advan-
tages of the lexicon generated by ReNew. ANEW
achieves the highest recall for the positive class,
but the lowest recalls in the negative and neutral
classes. Regarding the neutral class, both ANEW
and LIWC achieve poor results. The weighted av-
erage measures indicate our lexicon has the high-
est overall quality.
Our domain-specific lexicon contains dis-
tinguishable aspects associated with sentiment
words. For example, the aspect “staff” is associ-
ated with positive words (e.g., “nice,” “friendli,”
“help,” “great,” and so on) and negative words
(e.g., “okai,” “anxiou,” “moodi,” “effici,” and so
on). We notice that some positive words also occur
on the negative side. This may be for two reasons.
First, some sentences that contain positive words
may convey a negative sentiment, such as “The
staff should be more efficient.” Second, the boot-
strapping process in ReNew may introduce some
wrong words by mistakenly labeling the sentiment
of the segments. These challenges suggest useful
directions for the future work.
</bodyText>
<subsectionHeader confidence="0.9944325">
4.4 Lexicon Generation and Sentiment
Classification
</subsectionHeader>
<bodyText confidence="0.999790848484848">
Our fourth experiment evaluates the robustness of
ReNew’s lexicon generation process as well as the
performance of the sentiment classification mod-
els using these lexicons. We first generate ten
domain-specific lexicons by repeatedly following
these steps: For the first iteration, (1) build a train-
ing dataset by randomly selecting 20 labeled re-
views (about 220 segments) and (2) train the learn-
ers using the training dataset and LIWC. For each
iteration thereafter, (1) label 400 reviews from the
unlabeled dataset (4,071 reviews) and (2) update
the lexicon and retrain the learners. After labeling
all of the data, output a domain-specific lexicon.
To evaluate the benefit of using domain-specific
sentiment lexicons, we train ten sentiment classifi-
cation models using the ten lexicons and then com-
pare them, pairwise, against models trained with
the general sentiment lexicon LIWC. Each model
consists of an FR learner, a BR learner, and a la-
bel integrator. Each pairwise comparison is eval-
uated on a testing dataset with 10-fold cross vali-
dation. Each testing dataset consists of 180 ran-
domly selected reviews (about 1,800 segments).
For each of the pairwise comparisons, we conduct
a paired t-test to determine if the domain-specific
sentiment lexicon can yield better results.
Figure 9 shows the pairwise comparisons of ac-
curacy between the two lexicons. Each group
of bars represents the accuracy of two sentiment
classification models trained using LIWC (CRFs-
General) and the generated domain-specific lexi-
con (CRFs-Domain), respectively. The solid line
corresponds to a baseline model that takes the ma-
</bodyText>
<figure confidence="0.99360725">
validation on the 200-review dataset.
0.68
0.66
0.64
0.62
0.6
0.58
0.56
0.54
0.52
0.5
0.48
0.46
FW-L
BW-L
Both
</figure>
<page confidence="0.991471">
548
</page>
<tableCaption confidence="0.999751">
Table 4: Comparison results of different lexicons.
</tableCaption>
<table confidence="0.972934666666667">
ANEW LIWC ReNew
Precision Recall F-Measure Precision Recall F-Measure Precision Recall F-Measure
Positive 0.59 0.994 0.741 0.606 0.975 0.747 0.623 0.947 0.752
Negative 0.294 0.011 0.021 0.584 0.145 0.232 0.497 0.202 0.288
Neutral 0 0 0 0 0 0 0.395 0.04 0.073
Weighted average 0.41 0.587 0.44 0.481 0.605 0.489 0.551 0.608 0.518
</table>
<bodyText confidence="0.997439888888889">
jority classification strategy. Based on the dis-
tribution of the datasets, the majority class of all
datasets is positive. We can see that models using
either the general lexicon or the domain-specific
lexicon achieve higher accuracy than the baseline
model. Domain-specific lexicons produce signif-
icantly higher accuracy than general lexicons. In
the figures below, we indicate significance to 10%,
5%, and 1% as ‘·’, ‘∗’, and ‘∗∗’, respectively.
</bodyText>
<figure confidence="0.977770416666667">
P1(∗∗) P2(∗∗) P3(∗) P4(·) P5(∗) P6(·) P7(∗∗) P8(·) P9(∗) P10(∗∗)
Micro F-score
0.59
0.58
0.57
0.56
0.55
0.54
0.6
CRFs-General
CRFs-Domain
Comparing Pairs
</figure>
<figureCaption confidence="0.997258">
Figure 9: Accuracy with different lexicons.
</figureCaption>
<figure confidence="0.586279">
Comparing Pairs
</figure>
<figureCaption confidence="0.732868">
Figure 10: Macro F-score with different lexicons.
</figureCaption>
<bodyText confidence="0.9981544">
Figure 10 and 11 show the pairwise compar-
isons of macro and micro F-score together with
the results of the paired t-tests. We can see that the
domain-specific lexicons (dark-grey bars) consis-
tently yield better results than their corresponding
general lexicons (light-grey bars).
ReNew starts with LIWC and a labeled dataset
and generates ten lexicons and sentiment classifi-
cation models by iteratively learning 4,017 unla-
beled reviews without any human guidance. The
above results show that the generated lexicons
contain more domain-related information than the
general sentiment lexicons. Also, note that the la-
beled datasets we used contain only 20 labeled re-
views. This is an easy requirement to meet.
</bodyText>
<subsectionHeader confidence="0.998182">
4.5 Comparison with Previous Work
</subsectionHeader>
<bodyText confidence="0.999704055555556">
Our fifth experiment compares ReNew with
Lazaridou et al.’s (2013) approach for sentiment
classification using discourse relations. Like Re-
New, Lazaridou et al.’s approach works on the
sub sentential level. However, it differs from Re-
New in three aspects. First, the basic units of
their model are elementary discourse units (EDUs)
from Rhetorical Structure Theory (RST) (Mann
and Thompson, 1988). Second, their model con-
siders the forward relationship between EDUs,
whereas ReNew captures both forward and back-
ward relationship between segments. Third, they
use a generative model to capture the transition
distributions over EDUs whereas ReNew uses a
discriminative model to capture the transition se-
quences of segments.
EDUs are defined as minimal units of text and
consider many more relations than the two types
</bodyText>
<figure confidence="0.999637826086957">
Accuracy 0.69
0.67
0.65
0.63
0.61
0.59
0.57
P1(∗∗) P2(∗∗) P3(∗) P4(·) P5(∗) P6(·) P7(∗∗) P8(·) P9(∗) P10(∗∗)
CRFs-General
CRFs-Domain
Baseline
P1(∗) P2(∗∗) P3(∗) P4() P5(·) P6(·) P7(∗∗) P8(·) P9() P10(∗∗)
Macro F-score
0.48
0.47
0.46
0.45
0.44
0.43
0.42
CRFs-General
CRFs-Domain
Comparing Pairs
</figure>
<figureCaption confidence="0.996061">
Figure 11: Micro F-score with different lexicons.
</figureCaption>
<page confidence="0.998183">
549
</page>
<tableCaption confidence="0.9881025">
Table 5: Comparison of our framework with pre-
vious work on sentiment classification.
</tableCaption>
<subsectionHeader confidence="0.796737">
Method Accuracy
</subsectionHeader>
<bodyText confidence="0.933608379310345">
EDU-Model (Lazaridou et al.) 0.594
ReNew (our method) 0.605
of transition cues underlying our segments. We
posit that EDUs are too fine-grained for sentiment
analysis. Consider the following sentence from
Lazaridou et al.’s dataset with its EDUs identified.
(1) My husband called the front desk (2) to com-
plain.
Unfortunately, EDU (1) lacks sentiment and
EDU (2) lacks the topic. Although Lazaridou et
al.’s model can capture the forward relationship
between any two consecutive EDUs, it cannot han-
dle such cases because their model assumes that
each EDU is associated with a topic and a senti-
ment. In contrast, ReNew finds just one segment
in the above sentence.
Just to compare with Lazaridou et al., we ap-
ply our sentiment labeling component at the level
of EDUs. Their labeled dataset contains 65 re-
views, corresponding to 1,541 EDUs. Since this
dataset is also extracted from Tripadvisor, we use
the domain-specific lexicon automatically learned
by ReNew based on our 4,071 unlabeled reviews.
Follow the same training and testing regimen (10-
fold cross validation), we compare ReNew with
their model. As shown in Table 5, ReNew outper-
forms their approach on their dataset: Although
ReNew is not optimized for EDUs, it achieves bet-
ter accuracy.
</bodyText>
<sectionHeader confidence="0.999971" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999964472222222">
Two bodies of work are relevant. First, to gener-
ate sentiment lexicons, existing approaches com-
monly generate a sentiment lexicon by extend-
ing dictionaries or sentiment lexicons. Hu and
Liu (2004), manually collect a small set of sen-
timent words and expand it iteratively by search-
ing synonyms and antonyms in WordNet (Miller,
1995). Rao and Ravichandran (2009) formalize
the problem of sentiment detection as a semi-
supervised label propagation problem in a graph.
Each node represents a word, and a weighted edge
between any two nodes indicates the strength of
the relationship between them. Esuli and Sebas-
tiani (2006) use a set of classifiers in a semi-
supervised fashion to iteratively expand a manu-
ally defined lexicon. Their lexicon, named Senti-
WordNet, comprises the synset of each word ob-
tained from WordNet. Each synset is associated
with three sentiment scores: positive, negative,
and objective.
Second, for sentiment classification, Nakagawa
et al. (2010) introduce a probabilistic model that
uses the interactions between words within one
sentence for inferring sentiments. Socher et al.
(2011) introduce a semi-supervised approach that
uses recursive autoencoders to learn the hierarchi-
cal structure and sentiment distribution of a sen-
tence. Jo and Oh (2011) propose a probabilis-
tic generative model named ASUM that can ex-
tract aspects coupled with sentiments. Kim et al.
(2013) extend ASUM by enabling its probabilis-
tic model to discover a hierarchical structure of
the aspect-based sentiments. The above works
apply sentence-level sentiment classification and
their models are not able to capture the relation-
ships between or among clauses.
</bodyText>
<sectionHeader confidence="0.998494" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999984928571429">
The leading lexical approaches to sentiment anal-
ysis from text are based on fixed lexicons that are
painstakingly built by hand. There is little a priori
justification that such lexicons would port across
application domains. In contrast, ReNew seeks
to automate the building of domain-specific lexi-
cons beginning from a general sentiment lexicon
and the iterative application of CRFs. Our results
are promising. ReNew greatly reduces the human
effort for generating high-quality sentiment lexi-
cons together with a classification model. In fu-
ture work, we plan to apply ReNew to additional
sentiment analysis problems such as review qual-
ity analysis and sentiment summarization.
</bodyText>
<sectionHeader confidence="0.998364" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998652">
Thanks to Chung-Wei Hang, Chris Healey, James
Lester, Steffen Heber, and the anonymous review-
ers for helpful comments. This work is supported
by the Army Research Laboratory in its Net-
work Sciences Collaborative Technology Alliance
(NS-CTA) under Cooperative Agreement Number
W911NF-09-2-0053 and by an IBM Ph.D. Schol-
arship and an IBM Ph.D. fellowship.
</bodyText>
<page confidence="0.993308">
550
</page>
<sectionHeader confidence="0.995838" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999590247619047">
Margaret M. Bradley and Peter J. Lang. 1999. Affec-
tive norms for English words (ANEW): Instruction
manual and affective ratings. Technical Report C-1,
The Center for Research in Psychophysiology, Uni-
versity of Florida, Gainesville, FL.
Yejin Choi and Claire Cardie. 2009. Adapting a po-
larity lexicon using integer linear programming for
domain-specific sentiment classification. In Pro-
ceedings of the 14th Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP),
pages 590–598, Singapore.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
Proceedings of the 5th Conference on Language
Resources and Evaluation (LREC), pages 449–454,
Genoa, Italy.
Andrea Esuli and Fabrizio Sebastiani. 2006. Senti-
WordNet: A publicly available lexical resource for
opinion mining. In Proceedings of the 5th Con-
ference on Language Resources and Evaluation
(LREC), pages 417–422, Genoa, Italy.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA data mining software: An up-
date. SIGKDD Explorations Newsletter, 11(1):10–
18, November.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the 10th
International Conference on Knowledge Discovery
and Data Mining (KDD), pages 168–177, Seattle.
Yohan Jo and Alice Haeyun Oh. 2011. Aspect and sen-
timent unification model for online review analysis.
In Proceedings of the 4th ACM International Con-
ference on Web Search and Data Mining (WSDM),
pages 815–824, Hong Kong.
Hiroshi Kanayama and Tetsuya Nasukawa. 2006.
Fully automatic lexicon expansion for domain-
oriented sentiment analysis. In Proceedings of the
11th Conference on Empirical Methods in Natu-
ral Language Processing (EMNLP), pages 355–363,
Sydney.
Suin Kim, Jianwen Zhang, Zheng Chen, Alice H.
Oh, and Shixia Liu. 2013. A hierarchical aspect-
sentiment model for online reviews. In Proceed-
ings of the 27th AAAI Conference on Artificial In-
telligence (AAAI), pages 804–812, Bellevue.
John D. Lafferty, Andrew McCallum, and Fernando
C. N. Pereira. 2001. Conditional random fields:
Probabilistic models for segmenting and labeling
sequence data. In Proceedings of the 18th Inter-
national Conference on Machine Learning (ICML),
pages 282–289, San Francisco.
Angeliki Lazaridou, Ivan Titov, and Caroline
Sporleder. 2013. A Bayesian model for joint
unsupervised induction of sentiment, aspect and
discourse representations. In Proceedings of the
51st Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 1630–1639, Sofia,
Bulgaria.
Bing Liu. 2012. Sentiment Analysis and Opinion
Mining. Synthesis Lectures on Human Language
Technologies. Morgan &amp; Claypool Publishers, San
Rafael, CA.
William C. Mann and Sandra A. Thompson. 1988.
Rhetorical structure theory: Toward a functional the-
ory of text organization. Text, 8(3):243–281.
George A. Miller. 1995. WordNet: A lexical
database for English. Communications of the ACM,
38(11):39–41.
Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi.
2010. Dependency tree-based sentiment classifica-
tion using CRFs with hidden variables. In Proceed-
ings of the 11th Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies
(NAACL-HLT), pages 786–794, Los Angeles.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: Sentiment classification us-
ing machine learning techniques. In Proceedings of
the 7th Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP), pages 79–86,
Philadelphia.
Delip Rao and Deepak Ravichandran. 2009. Semi-
supervised polarity lexicon induction. In Proceed-
ings of the 12th Conference of the European Chap-
ter of the Association for Computational Linguistics
(EACL), pages 675–682, Athens.
Richard Socher, Jeffrey Pennington, Eric H. Huang,
Andrew Y. Ng, and Christopher D. Manning. 2011.
Semi-supervised recursive autoencoders for predict-
ing sentiment distributions. In Proceedings of the
16th Conference on Empirical Methods in Natu-
ral Language Processing (EMNLP), pages 151–161,
Edinburgh.
Yla R. Tausczik and James W. Pennebaker. 2010. The
psychological meaning of words: LIWC and com-
puterized text analysis methods. Journal of Lan-
guage and Social Psychology, 29(1):24–54, March.
Lei Zhang, Bing Liu, Suk Hwan Lim, and Eamonn
O’Brien-Strain. 2010. Extracting and ranking prod-
uct features in opinion documents. In Proceedings
of the 23rd International Conference on Compu-
tational Linguistics (COLING), pages 1462–1470,
Beijing.
</reference>
<page confidence="0.998043">
551
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.435124">
<title confidence="0.999419">ReNew: A Semi-Supervised Framework for Generating Domain-Specific Lexicons and Sentiment Analysis</title>
<author confidence="0.844762">Zhe</author>
<affiliation confidence="0.910954">Department of Computer</affiliation>
<author confidence="0.702168">North Carolina State Raleigh</author>
<author confidence="0.702168">NC</author>
<email confidence="0.992693">zzhang13@ncsu.edu</email>
<abstract confidence="0.997088565217391">The sentiment captured in opinionated text provides interesting and valuable information for social media services. However, due to the complexity and diversity of linguistic representations, it is challenging to build a framework that accurately extracts such sentiment. We propose a semi-supervised framework for generating a domain-specific sentiment lexicon inferring sentiments at the level. Our framework can greatly reduce the human effort for building a domainspecific sentiment lexicon with high quality. Specifically, in our evaluation, working with just 20 manually labeled reviews, it generates a domain-specific sentiment lexicon that yields weighted average F- Measure gains of 3%. Our sentiment classification model achieves approximately 1% greater accuracy than a state-of-the-art approach based on elementary discourse units.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Margaret M Bradley</author>
<author>Peter J Lang</author>
</authors>
<title>Affective norms for English words (ANEW): Instruction manual and affective ratings.</title>
<date>1999</date>
<tech>Technical Report C-1,</tech>
<institution>The Center for Research in Psychophysiology, University of Florida,</institution>
<location>Gainesville, FL.</location>
<contexts>
<context position="22847" citStr="Bradley and Lang, 1999" startWordPosition="3620" endWordPosition="3623">uality of the domain-specific lexicon automatically generated by ReNew. To do this, we first transform each of the 200 labeled reviews into feature vectors. Then we retrain Logistic Regression models using WEKA (Hall et al., 2009). Note that we use only the features extracted from the lexicons themselves. This is important because to compare only the lexicons’ impact on sentiment classification, we need to avoid the effect of other factors, such as syntax, transition cues, and so on. We compare models trained using (1) our domain-specific lexicon, (2) Affective Norms for English Words (ANEW) (Bradley and Lang, 1999), and (3) Linguistic Inquiry and Word Count (LIWC) (Tausczik and Pennebaker, 2010). ANEW and LIWC are well-known general sentiment lexicons. Table 4 shows the results obtained by 10-fold cross validation. Each weighted average is computed according to the number of segments in each class. The table shows the significant advantages of the lexicon generated by ReNew. ANEW achieves the highest recall for the positive class, but the lowest recalls in the negative and neutral classes. Regarding the neutral class, both ANEW and LIWC achieve poor results. The weighted average measures indicate our le</context>
</contexts>
<marker>Bradley, Lang, 1999</marker>
<rawString>Margaret M. Bradley and Peter J. Lang. 1999. Affective norms for English words (ANEW): Instruction manual and affective ratings. Technical Report C-1, The Center for Research in Psychophysiology, University of Florida, Gainesville, FL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Adapting a polarity lexicon using integer linear programming for domain-specific sentiment classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the 14th Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>590--598</pages>
<contexts>
<context position="1469" citStr="Choi and Cardie, 2009" startWordPosition="197" endWordPosition="200">n-specific sentiment lexicon that yields weighted average FMeasure gains of 3%. Our sentiment classification model achieves approximately 1% greater accuracy than a state-of-the-art approach based on elementary discourse units. 1 Introduction Automatically extracting sentiments from usergenerated opinionated text is important in building social media services. However, the complexity and diversity of the linguistic representations of sentiments make this problem challenging. High-quality sentiment lexicons can improve the performance of sentiment analysis models over general-purpose lexicons (Choi and Cardie, 2009). More advanced methods such as (Kanayama and Nasukawa, 2006) adopt domain knowledge by extracting sentiment words from the domain-specific corpus. However, depending on the context, the same word can have different polarities even in the same domain (Liu, 2012). In respect to sentiment classification, Pang et al. (2002) infer the sentiments using basic features, Munindar P. Singh Department of Computer Science North Carolina State University Raleigh, NC 27695-8206 singh@ncsu.edu such as bag-of-words. To capture more complex linguistic phenomena, leading approaches (Nakagawa et al., 2010; Jo a</context>
</contexts>
<marker>Choi, Cardie, 2009</marker>
<rawString>Yejin Choi and Claire Cardie. 2009. Adapting a polarity lexicon using integer linear programming for domain-specific sentiment classification. In Proceedings of the 14th Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 590–598, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>449--454</pages>
<location>Genoa, Italy.</location>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC), pages 449–454, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>SentiWordNet: A publicly available lexical resource for opinion mining.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>417--422</pages>
<location>Genoa, Italy.</location>
<contexts>
<context position="30957" citStr="Esuli and Sebastiani (2006)" startWordPosition="4887" endWordPosition="4891">d Work Two bodies of work are relevant. First, to generate sentiment lexicons, existing approaches commonly generate a sentiment lexicon by extending dictionaries or sentiment lexicons. Hu and Liu (2004), manually collect a small set of sentiment words and expand it iteratively by searching synonyms and antonyms in WordNet (Miller, 1995). Rao and Ravichandran (2009) formalize the problem of sentiment detection as a semisupervised label propagation problem in a graph. Each node represents a word, and a weighted edge between any two nodes indicates the strength of the relationship between them. Esuli and Sebastiani (2006) use a set of classifiers in a semisupervised fashion to iteratively expand a manually defined lexicon. Their lexicon, named SentiWordNet, comprises the synset of each word obtained from WordNet. Each synset is associated with three sentiment scores: positive, negative, and objective. Second, for sentiment classification, Nakagawa et al. (2010) introduce a probabilistic model that uses the interactions between words within one sentence for inferring sentiments. Socher et al. (2011) introduce a semi-supervised approach that uses recursive autoencoders to learn the hierarchical structure and sen</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. SentiWordNet: A publicly available lexical resource for opinion mining. In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC), pages 417–422, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The WEKA data mining software: An update.</title>
<date>2009</date>
<journal>SIGKDD Explorations Newsletter,</journal>
<volume>11</volume>
<issue>1</issue>
<pages>18</pages>
<contexts>
<context position="22454" citStr="Hall et al., 2009" startWordPosition="3556" endWordPosition="3559"> It shows that the BR learner produces better accuracy and a micro F-score than the FR learner but a slightly worse macro F-score. Jointly considering both learners with the label integrator achieves better results than either alone. The results demonstrate the effectiveness of our sentiment labeling component. 4.3 Domain-Specific Lexicon Assessment Our third experiment evaluates the quality of the domain-specific lexicon automatically generated by ReNew. To do this, we first transform each of the 200 labeled reviews into feature vectors. Then we retrain Logistic Regression models using WEKA (Hall et al., 2009). Note that we use only the features extracted from the lexicons themselves. This is important because to compare only the lexicons’ impact on sentiment classification, we need to avoid the effect of other factors, such as syntax, transition cues, and so on. We compare models trained using (1) our domain-specific lexicon, (2) Affective Norms for English Words (ANEW) (Bradley and Lang, 1999), and (3) Linguistic Inquiry and Word Count (LIWC) (Tausczik and Pennebaker, 2010). ANEW and LIWC are well-known general sentiment lexicons. Table 4 shows the results obtained by 10-fold cross validation. Ea</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The WEKA data mining software: An update. SIGKDD Explorations Newsletter, 11(1):10– 18, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the 10th International Conference on Knowledge Discovery and Data Mining (KDD),</booktitle>
<pages>168--177</pages>
<location>Seattle.</location>
<contexts>
<context position="30533" citStr="Hu and Liu (2004)" startWordPosition="4819" endWordPosition="4822"> this dataset is also extracted from Tripadvisor, we use the domain-specific lexicon automatically learned by ReNew based on our 4,071 unlabeled reviews. Follow the same training and testing regimen (10- fold cross validation), we compare ReNew with their model. As shown in Table 5, ReNew outperforms their approach on their dataset: Although ReNew is not optimized for EDUs, it achieves better accuracy. 5 Related Work Two bodies of work are relevant. First, to generate sentiment lexicons, existing approaches commonly generate a sentiment lexicon by extending dictionaries or sentiment lexicons. Hu and Liu (2004), manually collect a small set of sentiment words and expand it iteratively by searching synonyms and antonyms in WordNet (Miller, 1995). Rao and Ravichandran (2009) formalize the problem of sentiment detection as a semisupervised label propagation problem in a graph. Each node represents a word, and a weighted edge between any two nodes indicates the strength of the relationship between them. Esuli and Sebastiani (2006) use a set of classifiers in a semisupervised fashion to iteratively expand a manually defined lexicon. Their lexicon, named SentiWordNet, comprises the synset of each word obt</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the 10th International Conference on Knowledge Discovery and Data Mining (KDD), pages 168–177, Seattle.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yohan Jo</author>
<author>Alice Haeyun Oh</author>
</authors>
<title>Aspect and sentiment unification model for online review analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the 4th ACM International Conference on Web Search and Data Mining (WSDM),</booktitle>
<pages>815--824</pages>
<location>Hong Kong.</location>
<contexts>
<context position="2080" citStr="Jo and Oh, 2011" startWordPosition="287" endWordPosition="290">009). More advanced methods such as (Kanayama and Nasukawa, 2006) adopt domain knowledge by extracting sentiment words from the domain-specific corpus. However, depending on the context, the same word can have different polarities even in the same domain (Liu, 2012). In respect to sentiment classification, Pang et al. (2002) infer the sentiments using basic features, Munindar P. Singh Department of Computer Science North Carolina State University Raleigh, NC 27695-8206 singh@ncsu.edu such as bag-of-words. To capture more complex linguistic phenomena, leading approaches (Nakagawa et al., 2010; Jo and Oh, 2011; Kim et al., 2013) apply more advanced models but assume one document or sentence holds one sentiment. However, this is often not the case. Sentiments can change within one document, one sentence, or even one clause. Also, existing approaches infer sentiments without considering the changes of sentiments within or between clauses. However, these changes can be successfully exploited for inferring fine-grained sentiments. To address the above shortcomings of lexicon and granularity, we propose a semi-supervised framework named ReNew. (1) Instead of using sentences, ReNew uses segments as the b</context>
<context position="31608" citStr="Jo and Oh (2011)" startWordPosition="4986" endWordPosition="4989">supervised fashion to iteratively expand a manually defined lexicon. Their lexicon, named SentiWordNet, comprises the synset of each word obtained from WordNet. Each synset is associated with three sentiment scores: positive, negative, and objective. Second, for sentiment classification, Nakagawa et al. (2010) introduce a probabilistic model that uses the interactions between words within one sentence for inferring sentiments. Socher et al. (2011) introduce a semi-supervised approach that uses recursive autoencoders to learn the hierarchical structure and sentiment distribution of a sentence. Jo and Oh (2011) propose a probabilistic generative model named ASUM that can extract aspects coupled with sentiments. Kim et al. (2013) extend ASUM by enabling its probabilistic model to discover a hierarchical structure of the aspect-based sentiments. The above works apply sentence-level sentiment classification and their models are not able to capture the relationships between or among clauses. 6 Conclusions and Future Work The leading lexical approaches to sentiment analysis from text are based on fixed lexicons that are painstakingly built by hand. There is little a priori justification that such lexicon</context>
</contexts>
<marker>Jo, Oh, 2011</marker>
<rawString>Yohan Jo and Alice Haeyun Oh. 2011. Aspect and sentiment unification model for online review analysis. In Proceedings of the 4th ACM International Conference on Web Search and Data Mining (WSDM), pages 815–824, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Kanayama</author>
<author>Tetsuya Nasukawa</author>
</authors>
<title>Fully automatic lexicon expansion for domainoriented sentiment analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>355--363</pages>
<location>Sydney.</location>
<contexts>
<context position="1530" citStr="Kanayama and Nasukawa, 2006" startWordPosition="206" endWordPosition="209">ge FMeasure gains of 3%. Our sentiment classification model achieves approximately 1% greater accuracy than a state-of-the-art approach based on elementary discourse units. 1 Introduction Automatically extracting sentiments from usergenerated opinionated text is important in building social media services. However, the complexity and diversity of the linguistic representations of sentiments make this problem challenging. High-quality sentiment lexicons can improve the performance of sentiment analysis models over general-purpose lexicons (Choi and Cardie, 2009). More advanced methods such as (Kanayama and Nasukawa, 2006) adopt domain knowledge by extracting sentiment words from the domain-specific corpus. However, depending on the context, the same word can have different polarities even in the same domain (Liu, 2012). In respect to sentiment classification, Pang et al. (2002) infer the sentiments using basic features, Munindar P. Singh Department of Computer Science North Carolina State University Raleigh, NC 27695-8206 singh@ncsu.edu such as bag-of-words. To capture more complex linguistic phenomena, leading approaches (Nakagawa et al., 2010; Jo and Oh, 2011; Kim et al., 2013) apply more advanced models but</context>
</contexts>
<marker>Kanayama, Nasukawa, 2006</marker>
<rawString>Hiroshi Kanayama and Tetsuya Nasukawa. 2006. Fully automatic lexicon expansion for domainoriented sentiment analysis. In Proceedings of the 11th Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 355–363, Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suin Kim</author>
<author>Jianwen Zhang</author>
<author>Zheng Chen</author>
<author>Alice H Oh</author>
<author>Shixia Liu</author>
</authors>
<title>A hierarchical aspectsentiment model for online reviews.</title>
<date>2013</date>
<booktitle>In Proceedings of the 27th AAAI Conference on Artificial Intelligence (AAAI),</booktitle>
<pages>804--812</pages>
<location>Bellevue.</location>
<contexts>
<context position="2099" citStr="Kim et al., 2013" startWordPosition="291" endWordPosition="294">ed methods such as (Kanayama and Nasukawa, 2006) adopt domain knowledge by extracting sentiment words from the domain-specific corpus. However, depending on the context, the same word can have different polarities even in the same domain (Liu, 2012). In respect to sentiment classification, Pang et al. (2002) infer the sentiments using basic features, Munindar P. Singh Department of Computer Science North Carolina State University Raleigh, NC 27695-8206 singh@ncsu.edu such as bag-of-words. To capture more complex linguistic phenomena, leading approaches (Nakagawa et al., 2010; Jo and Oh, 2011; Kim et al., 2013) apply more advanced models but assume one document or sentence holds one sentiment. However, this is often not the case. Sentiments can change within one document, one sentence, or even one clause. Also, existing approaches infer sentiments without considering the changes of sentiments within or between clauses. However, these changes can be successfully exploited for inferring fine-grained sentiments. To address the above shortcomings of lexicon and granularity, we propose a semi-supervised framework named ReNew. (1) Instead of using sentences, ReNew uses segments as the basic units for sent</context>
<context position="31728" citStr="Kim et al. (2013)" startWordPosition="5006" endWordPosition="5009">ynset of each word obtained from WordNet. Each synset is associated with three sentiment scores: positive, negative, and objective. Second, for sentiment classification, Nakagawa et al. (2010) introduce a probabilistic model that uses the interactions between words within one sentence for inferring sentiments. Socher et al. (2011) introduce a semi-supervised approach that uses recursive autoencoders to learn the hierarchical structure and sentiment distribution of a sentence. Jo and Oh (2011) propose a probabilistic generative model named ASUM that can extract aspects coupled with sentiments. Kim et al. (2013) extend ASUM by enabling its probabilistic model to discover a hierarchical structure of the aspect-based sentiments. The above works apply sentence-level sentiment classification and their models are not able to capture the relationships between or among clauses. 6 Conclusions and Future Work The leading lexical approaches to sentiment analysis from text are based on fixed lexicons that are painstakingly built by hand. There is little a priori justification that such lexicons would port across application domains. In contrast, ReNew seeks to automate the building of domain-specific lexicons b</context>
</contexts>
<marker>Kim, Zhang, Chen, Oh, Liu, 2013</marker>
<rawString>Suin Kim, Jianwen Zhang, Zheng Chen, Alice H. Oh, and Shixia Liu. 2013. A hierarchical aspectsentiment model for online reviews. In Proceedings of the 27th AAAI Conference on Artificial Intelligence (AAAI), pages 804–812, Bellevue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the 18th International Conference on Machine Learning (ICML),</booktitle>
<pages>282--289</pages>
<location>San Francisco.</location>
<contexts>
<context position="6316" citStr="Lafferty et al., 2001" startWordPosition="941" endWordPosition="944">e. In ReNew, we exploit the Stanford typed dependency representations (de Marneffe et al., 2006) that use triples to formalize dependency relations. A domain-specific sentiment lexicon contains three lists of dependency relations, associated respectvely with positive, neutral, or negative sentiment. Given a set of reviews, the tasks of sentiment analysis in ReNew are (1) splitting each review into segments, (2) associating each segment with a sentiment label (positive, neutral, negative), and (3) automatically generating a domainspecific sentiment lexicon. We employ Conditional Random Fields (Lafferty et al., 2001) to predict the sentiment label for each segment. Given a sequence of segments x¯ = (x1, · · · , xn) and a sequence of sentiment labels y¯ = (y1, · · · , yn), the CRFs model p(¯y|¯x) as follows. 1 J p(¯y|¯x) = Z(¯x) exp (wj · Fj(¯x, ¯y)) j n Fj(¯x, ¯y) = fj(yZ−1, yZ, ¯x, i) Z=1 where w is a set of weights learned in the training process to maximize p(¯y|¯x). Z(¯x) is a normalization constant that is the sum of all possible label sequences. And, Fj is a feature function that sums fj over i E (1, n), where n is the length of ¯y, and fj can have arbitrary dependencies on the observation sequence </context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the 18th International Conference on Machine Learning (ICML), pages 282–289, San Francisco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angeliki Lazaridou</author>
<author>Ivan Titov</author>
<author>Caroline Sporleder</author>
</authors>
<title>A Bayesian model for joint unsupervised induction of sentiment, aspect and discourse representations.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>1630--1639</pages>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="5008" citStr="Lazaridou et al., 2013" startWordPosition="732" endWordPosition="735">t of Segment 5 as NEG, we associate the dependency relation pairs {“sign”, “wear”} and {“sign”, “tear”} with that sentiment. ReNew can greatly reduce the human effort for building a domain-specific sentiment lexicon with high quality. Specifically, in our evaluation on two real datasets, working with just 20 manually labeled reviews, ReNew generates a domainspecific sentiment lexicon that yields weighted average F-Measure gains of 3%. Additionally, our sentiment classification model achieves approximately 1% greater accuracy than a state-of-theart approach based on elementary discourse units (Lazaridou et al., 2013). The rest of this paper is structured as follows. Section 2 introduces some essential background. Section 3 illustrates ReNew. Section 4 presents our experiments and results. Section 5 reviews some related work. Section 6 concludes this paper and outlines some directions for future work. 2 Background Let us introduce some of the key terminology used in ReNew. A segment is a sequence of words that represents at most one sentiment. A segment can consist of multiple consecutive clauses, up to a whole sentence. Or, it can be shorter than a clause. A dependency relation defines a binary relation t</context>
</contexts>
<marker>Lazaridou, Titov, Sporleder, 2013</marker>
<rawString>Angeliki Lazaridou, Ivan Titov, and Caroline Sporleder. 2013. A Bayesian model for joint unsupervised induction of sentiment, aspect and discourse representations. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL), pages 1630–1639, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining. Synthesis Lectures on Human Language Technologies.</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool Publishers,</publisher>
<location>San Rafael, CA.</location>
<contexts>
<context position="1731" citStr="Liu, 2012" startWordPosition="239" endWordPosition="240">ents from usergenerated opinionated text is important in building social media services. However, the complexity and diversity of the linguistic representations of sentiments make this problem challenging. High-quality sentiment lexicons can improve the performance of sentiment analysis models over general-purpose lexicons (Choi and Cardie, 2009). More advanced methods such as (Kanayama and Nasukawa, 2006) adopt domain knowledge by extracting sentiment words from the domain-specific corpus. However, depending on the context, the same word can have different polarities even in the same domain (Liu, 2012). In respect to sentiment classification, Pang et al. (2002) infer the sentiments using basic features, Munindar P. Singh Department of Computer Science North Carolina State University Raleigh, NC 27695-8206 singh@ncsu.edu such as bag-of-words. To capture more complex linguistic phenomena, leading approaches (Nakagawa et al., 2010; Jo and Oh, 2011; Kim et al., 2013) apply more advanced models but assume one document or sentence holds one sentiment. However, this is often not the case. Sentiments can change within one document, one sentence, or even one clause. Also, existing approaches infer s</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment Analysis and Opinion Mining. Synthesis Lectures on Human Language Technologies. Morgan &amp; Claypool Publishers, San Rafael, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical structure theory: Toward a functional theory of text organization.</title>
<date>1988</date>
<tech>Text, 8(3):243–281.</tech>
<contexts>
<context position="28201" citStr="Mann and Thompson, 1988" startWordPosition="4450" endWordPosition="4453">s contain more domain-related information than the general sentiment lexicons. Also, note that the labeled datasets we used contain only 20 labeled reviews. This is an easy requirement to meet. 4.5 Comparison with Previous Work Our fifth experiment compares ReNew with Lazaridou et al.’s (2013) approach for sentiment classification using discourse relations. Like ReNew, Lazaridou et al.’s approach works on the sub sentential level. However, it differs from ReNew in three aspects. First, the basic units of their model are elementary discourse units (EDUs) from Rhetorical Structure Theory (RST) (Mann and Thompson, 1988). Second, their model considers the forward relationship between EDUs, whereas ReNew captures both forward and backward relationship between segments. Third, they use a generative model to capture the transition distributions over EDUs whereas ReNew uses a discriminative model to capture the transition sequences of segments. EDUs are defined as minimal units of text and consider many more relations than the two types Accuracy 0.69 0.67 0.65 0.63 0.61 0.59 0.57 P1(∗∗) P2(∗∗) P3(∗) P4(·) P5(∗) P6(·) P7(∗∗) P8(·) P9(∗) P10(∗∗) CRFs-General CRFs-Domain Baseline P1(∗) P2(∗∗) P3(∗) P4() P5(·) P6(·) </context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>William C. Mann and Sandra A. Thompson. 1988. Rhetorical structure theory: Toward a functional theory of text organization. Text, 8(3):243–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>WordNet: A lexical database for English.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="30669" citStr="Miller, 1995" startWordPosition="4844" endWordPosition="4845">eled reviews. Follow the same training and testing regimen (10- fold cross validation), we compare ReNew with their model. As shown in Table 5, ReNew outperforms their approach on their dataset: Although ReNew is not optimized for EDUs, it achieves better accuracy. 5 Related Work Two bodies of work are relevant. First, to generate sentiment lexicons, existing approaches commonly generate a sentiment lexicon by extending dictionaries or sentiment lexicons. Hu and Liu (2004), manually collect a small set of sentiment words and expand it iteratively by searching synonyms and antonyms in WordNet (Miller, 1995). Rao and Ravichandran (2009) formalize the problem of sentiment detection as a semisupervised label propagation problem in a graph. Each node represents a word, and a weighted edge between any two nodes indicates the strength of the relationship between them. Esuli and Sebastiani (2006) use a set of classifiers in a semisupervised fashion to iteratively expand a manually defined lexicon. Their lexicon, named SentiWordNet, comprises the synset of each word obtained from WordNet. Each synset is associated with three sentiment scores: positive, negative, and objective. Second, for sentiment clas</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. WordNet: A lexical database for English. Communications of the ACM, 38(11):39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuji Nakagawa</author>
<author>Kentaro Inui</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Dependency tree-based sentiment classification using CRFs with hidden variables.</title>
<date>2010</date>
<booktitle>In Proceedings of the 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</booktitle>
<pages>786--794</pages>
<location>Los Angeles.</location>
<contexts>
<context position="2063" citStr="Nakagawa et al., 2010" startWordPosition="282" endWordPosition="286">ons (Choi and Cardie, 2009). More advanced methods such as (Kanayama and Nasukawa, 2006) adopt domain knowledge by extracting sentiment words from the domain-specific corpus. However, depending on the context, the same word can have different polarities even in the same domain (Liu, 2012). In respect to sentiment classification, Pang et al. (2002) infer the sentiments using basic features, Munindar P. Singh Department of Computer Science North Carolina State University Raleigh, NC 27695-8206 singh@ncsu.edu such as bag-of-words. To capture more complex linguistic phenomena, leading approaches (Nakagawa et al., 2010; Jo and Oh, 2011; Kim et al., 2013) apply more advanced models but assume one document or sentence holds one sentiment. However, this is often not the case. Sentiments can change within one document, one sentence, or even one clause. Also, existing approaches infer sentiments without considering the changes of sentiments within or between clauses. However, these changes can be successfully exploited for inferring fine-grained sentiments. To address the above shortcomings of lexicon and granularity, we propose a semi-supervised framework named ReNew. (1) Instead of using sentences, ReNew uses </context>
<context position="31303" citStr="Nakagawa et al. (2010)" startWordPosition="4941" endWordPosition="4944">vichandran (2009) formalize the problem of sentiment detection as a semisupervised label propagation problem in a graph. Each node represents a word, and a weighted edge between any two nodes indicates the strength of the relationship between them. Esuli and Sebastiani (2006) use a set of classifiers in a semisupervised fashion to iteratively expand a manually defined lexicon. Their lexicon, named SentiWordNet, comprises the synset of each word obtained from WordNet. Each synset is associated with three sentiment scores: positive, negative, and objective. Second, for sentiment classification, Nakagawa et al. (2010) introduce a probabilistic model that uses the interactions between words within one sentence for inferring sentiments. Socher et al. (2011) introduce a semi-supervised approach that uses recursive autoencoders to learn the hierarchical structure and sentiment distribution of a sentence. Jo and Oh (2011) propose a probabilistic generative model named ASUM that can extract aspects coupled with sentiments. Kim et al. (2013) extend ASUM by enabling its probabilistic model to discover a hierarchical structure of the aspect-based sentiments. The above works apply sentence-level sentiment classifica</context>
</contexts>
<marker>Nakagawa, Inui, Kurohashi, 2010</marker>
<rawString>Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi. 2010. Dependency tree-based sentiment classification using CRFs with hidden variables. In Proceedings of the 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), pages 786–794, Los Angeles.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the 7th Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>79--86</pages>
<location>Philadelphia.</location>
<contexts>
<context position="1791" citStr="Pang et al. (2002)" startWordPosition="246" endWordPosition="249">t in building social media services. However, the complexity and diversity of the linguistic representations of sentiments make this problem challenging. High-quality sentiment lexicons can improve the performance of sentiment analysis models over general-purpose lexicons (Choi and Cardie, 2009). More advanced methods such as (Kanayama and Nasukawa, 2006) adopt domain knowledge by extracting sentiment words from the domain-specific corpus. However, depending on the context, the same word can have different polarities even in the same domain (Liu, 2012). In respect to sentiment classification, Pang et al. (2002) infer the sentiments using basic features, Munindar P. Singh Department of Computer Science North Carolina State University Raleigh, NC 27695-8206 singh@ncsu.edu such as bag-of-words. To capture more complex linguistic phenomena, leading approaches (Nakagawa et al., 2010; Jo and Oh, 2011; Kim et al., 2013) apply more advanced models but assume one document or sentence holds one sentiment. However, this is often not the case. Sentiments can change within one document, one sentence, or even one clause. Also, existing approaches infer sentiments without considering the changes of sentiments with</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up?: Sentiment classification using machine learning techniques. In Proceedings of the 7th Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 79–86, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delip Rao</author>
<author>Deepak Ravichandran</author>
</authors>
<title>Semisupervised polarity lexicon induction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>675--682</pages>
<location>Athens.</location>
<contexts>
<context position="30698" citStr="Rao and Ravichandran (2009)" startWordPosition="4846" endWordPosition="4849">ollow the same training and testing regimen (10- fold cross validation), we compare ReNew with their model. As shown in Table 5, ReNew outperforms their approach on their dataset: Although ReNew is not optimized for EDUs, it achieves better accuracy. 5 Related Work Two bodies of work are relevant. First, to generate sentiment lexicons, existing approaches commonly generate a sentiment lexicon by extending dictionaries or sentiment lexicons. Hu and Liu (2004), manually collect a small set of sentiment words and expand it iteratively by searching synonyms and antonyms in WordNet (Miller, 1995). Rao and Ravichandran (2009) formalize the problem of sentiment detection as a semisupervised label propagation problem in a graph. Each node represents a word, and a weighted edge between any two nodes indicates the strength of the relationship between them. Esuli and Sebastiani (2006) use a set of classifiers in a semisupervised fashion to iteratively expand a manually defined lexicon. Their lexicon, named SentiWordNet, comprises the synset of each word obtained from WordNet. Each synset is associated with three sentiment scores: positive, negative, and objective. Second, for sentiment classification, Nakagawa et al. (</context>
</contexts>
<marker>Rao, Ravichandran, 2009</marker>
<rawString>Delip Rao and Deepak Ravichandran. 2009. Semisupervised polarity lexicon induction. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL), pages 675–682, Athens.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Jeffrey Pennington</author>
<author>Eric H Huang</author>
<author>Andrew Y Ng</author>
<author>Christopher D Manning</author>
</authors>
<title>Semi-supervised recursive autoencoders for predicting sentiment distributions.</title>
<date>2011</date>
<booktitle>In Proceedings of the 16th Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>151--161</pages>
<location>Edinburgh.</location>
<contexts>
<context position="31443" citStr="Socher et al. (2011)" startWordPosition="4961" endWordPosition="4964">a word, and a weighted edge between any two nodes indicates the strength of the relationship between them. Esuli and Sebastiani (2006) use a set of classifiers in a semisupervised fashion to iteratively expand a manually defined lexicon. Their lexicon, named SentiWordNet, comprises the synset of each word obtained from WordNet. Each synset is associated with three sentiment scores: positive, negative, and objective. Second, for sentiment classification, Nakagawa et al. (2010) introduce a probabilistic model that uses the interactions between words within one sentence for inferring sentiments. Socher et al. (2011) introduce a semi-supervised approach that uses recursive autoencoders to learn the hierarchical structure and sentiment distribution of a sentence. Jo and Oh (2011) propose a probabilistic generative model named ASUM that can extract aspects coupled with sentiments. Kim et al. (2013) extend ASUM by enabling its probabilistic model to discover a hierarchical structure of the aspect-based sentiments. The above works apply sentence-level sentiment classification and their models are not able to capture the relationships between or among clauses. 6 Conclusions and Future Work The leading lexical </context>
</contexts>
<marker>Socher, Pennington, Huang, Ng, Manning, 2011</marker>
<rawString>Richard Socher, Jeffrey Pennington, Eric H. Huang, Andrew Y. Ng, and Christopher D. Manning. 2011. Semi-supervised recursive autoencoders for predicting sentiment distributions. In Proceedings of the 16th Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 151–161, Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yla R Tausczik</author>
<author>James W Pennebaker</author>
</authors>
<title>The psychological meaning of words: LIWC and computerized text analysis methods.</title>
<date>2010</date>
<journal>Journal of Language and Social Psychology,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="22929" citStr="Tausczik and Pennebaker, 2010" startWordPosition="3633" endWordPosition="3636">do this, we first transform each of the 200 labeled reviews into feature vectors. Then we retrain Logistic Regression models using WEKA (Hall et al., 2009). Note that we use only the features extracted from the lexicons themselves. This is important because to compare only the lexicons’ impact on sentiment classification, we need to avoid the effect of other factors, such as syntax, transition cues, and so on. We compare models trained using (1) our domain-specific lexicon, (2) Affective Norms for English Words (ANEW) (Bradley and Lang, 1999), and (3) Linguistic Inquiry and Word Count (LIWC) (Tausczik and Pennebaker, 2010). ANEW and LIWC are well-known general sentiment lexicons. Table 4 shows the results obtained by 10-fold cross validation. Each weighted average is computed according to the number of segments in each class. The table shows the significant advantages of the lexicon generated by ReNew. ANEW achieves the highest recall for the positive class, but the lowest recalls in the negative and neutral classes. Regarding the neutral class, both ANEW and LIWC achieve poor results. The weighted average measures indicate our lexicon has the highest overall quality. Our domain-specific lexicon contains distin</context>
</contexts>
<marker>Tausczik, Pennebaker, 2010</marker>
<rawString>Yla R. Tausczik and James W. Pennebaker. 2010. The psychological meaning of words: LIWC and computerized text analysis methods. Journal of Language and Social Psychology, 29(1):24–54, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Zhang</author>
<author>Bing Liu</author>
<author>Suk Hwan Lim</author>
<author>Eamonn O’Brien-Strain</author>
</authors>
<title>Extracting and ranking product features in opinion documents.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING),</booktitle>
<pages>1462--1470</pages>
<location>Beijing.</location>
<marker>Zhang, Liu, Lim, O’Brien-Strain, 2010</marker>
<rawString>Lei Zhang, Bing Liu, Suk Hwan Lim, and Eamonn O’Brien-Strain. 2010. Extracting and ranking product features in opinion documents. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING), pages 1462–1470, Beijing.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>