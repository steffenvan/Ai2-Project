<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000090">
<title confidence="0.980418">
Modeling sentence processing in ACT-R
</title>
<author confidence="0.990536">
Shravan Vasishth
</author>
<affiliation confidence="0.87129">
Department of Computational Linguistics
Saarland University, PO Box 15 11 05
</affiliation>
<address confidence="0.628853">
66041 Saarbr¨ucken, Germany
</address>
<email confidence="0.994479">
vasishth@acm.org
</email>
<author confidence="0.989204">
Richard L. Lewis
</author>
<affiliation confidence="0.9979145">
Department of Psychology
University of Michigan
</affiliation>
<address confidence="0.707919">
Ann Arbor, MI, USA
</address>
<email confidence="0.999212">
rickl@umich.edu
</email>
<sectionHeader confidence="0.993907" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998312">
We present a series of simulations of behavioral data
by casting a simple parsing model in the cognitive
architecture ACT-R. We show that constraints de-
fined in ACT-R, specifically those relating to acti-
vation, can account for a range of facts about hu-
man sentence processing. In doing so, we argue
that resource limitation in working memory is bet-
ter defined as an artefact of very general and in-
dependently motivated principles of cognitive pro-
cessing.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99994596875">
Although language processing may be a specialized
cognitive faculty, it is possible that it is nevertheless
shaped by general constraints on the human cog-
nitive architecture. This point has been addressed
extensively in the connectionist literature, but we
present a somewhat different approach to this prob-
lem by casting parsing within the cognitive architec-
ture ACT-R (Anderson et al., 2002) and directly us-
ing the constraints provided in ACT-R to account for
several interesting cross-linguistic facts: the well-
known sentential complement/relative clause asym-
metry (Gibson, 2000; Grodner and Gibson, 2003)
and the subject/object relative clause asymmetry in
English (Homes and O’Regan, 1981); and some re-
cent results (Vasishth, 2003) involving Hindi center
embeddings, including a principled account of indi-
vidual variation in subject behavior.
In developing this approach, we argue that re-
source limitation in working memory is better de-
fined as an artefact of very general constraints on
information processing – specifically, rehearsal and
activation – rather than as an inherent numerical
bound on memory capacity (cf. (Gibson, 2000;
Hawkins, 1994); also see Section 3.5).
In the rest of this paper, we first introduce the
ACT-R architecture. Then we present the results
of several simulations of experiments available in
the psycholinguistic literature. The paper concludes
with a discussion of the potential advantages and
shortcomings of this approach, and of the broader
consequences of modeling parsing within a cogni-
tive architecture.
</bodyText>
<sectionHeader confidence="0.910388" genericHeader="method">
2 A brief introduction to the cognitive
architecture ACT-R
</sectionHeader>
<bodyText confidence="0.99994045945946">
ACT-R is a theory of the human cognitive archi-
tecture. It allows the development of computa-
tional models that can closely simulate experimental
methodologies such as eye-tracking and self-paced
reading, and has been used to model a wide array of
behavioral data from learning and memory, problem
solving and decision making, language and commu-
nication, perception and attention, cognitive devel-
opment, and individual differences (Anderson et al.,
2002).
The ACT-R architecture is attractive as a model-
ing tool for three reasons. First, it is based on a wide
array of empirical results in various domains of cog-
nitive psychology. Second, it is flexible enough to
permit the modeler to add their own assumptions
and theories about the specific task to be modeled.
Finally, ACT-R models yield dependent measures
such as reading time in much the same way as hu-
mans performing the experiment; e.g., the system
can easily be programmed to simulate key presses
after it processes material presented on the screen.
As shown in Figure 1, the architecture consists of
several MODULES such as Declarative, Visual, and
Manual. Each module is associated with a BUFFER
which temporarily stores information for a given ac-
tion. For example, the visual buffer is used to store
an item “seen” by the system in the environment be-
fore it is used in the service of some task.
The module that is especially important for the
present paper is the Declarative (henceforth, DM).
DM represents permanent memory: every fact that
is assumed to be known is encoded as a CHUNK in
declarative memory. A chunk is an attribute-value
list structure with a special attribute, ISA, which de-
fines its type. The attributes are also referred to as
slots. The value of a chunk’s slot is also (by defi-
nition) a chunk, unless it is double-quoted or is the
</bodyText>
<subsectionHeader confidence="0.832911">
Environment
</subsectionHeader>
<bodyText confidence="0.9705238">
Figure 1: This is a schematic view of the ACT-R
system. “Environment” is the outside world that
ACT-R is programmed to interact with. The arrows
show the possible flows of information. Productions
and the central box with the boxes labeled “Match-
ing”, “Selection”, and “Execution” are intended to
represent a set of central executive mechanisms and
processes.
lisp primitive “nil”.
Each DM chunk has an activation that determines
its speed of retrieval, and the probability that it will
be retrieved; the initial activation for a given chunk
can be set manually.
There is a GOAL BUFFER that holds a current goal
under consideration (there can be only one goal at
one time); this goal is a chunk with a given type and
possibly instantiated slots.
The control structure for modeling a sequence of
events is a set of PRODUCTIONS; a production is
simply an if-then statement of the following general
form: for a given state of one or more buffers and/or
DM, execute some actions. Examples of executing
actions are retrieving something from DM; chang-
ing a value in one of the goal’s slots; repositioning
the hand over a keyboard; a visual shift of attention;
changing the goal to a new one, etc. If the goal is
changed, then this new goal now occupies the goal
buffer.
Building an ACT-R model is essentially a defi-
nition of possible sequences of actions for a given
state of affairs. Events like retrievals from DM are
triggered by looking at the contents of one or more
buffers. For example, the ACT-R system “sees” an
item/object on the screen and then encodes it as a vi-
sual chunk. This chunk can then be harvested from
the visual buffer; it includes (as slot-value specifi-
cations) information about the content of the item
seen, its x-y coordinates, etc. One can define an ac-
tion based on this information, such as retrieving a
chunk from DM.
</bodyText>
<sectionHeader confidence="0.843439" genericHeader="method">
3 Modeling sentence parsing in ACT-R
</sectionHeader>
<bodyText confidence="0.999907583333333">
Previous research suggests that humans employ
some variant of left-corner parsing (see, e.g.,
(Resnik, 1992)), which in essence involves a
bottom-up and a top-down (predictive) step. We
adopt this parsing strategy in the simulations. In
order to model the prediction of syntactic struc-
ture based on incrementally appearing input, we as-
sume that sentence structure templates are available
in declarative memory as underspecified chunks.
These chunks are retrieved every time a new word is
integrated into the structure, as are prior arguments
necessary for semantic integration.
We illustrate the parsing process with a simple
example (Figure 2). Suppose that the sentence to be
parsed is The girl ran, and suppose that we are sim-
ulating self-paced reading (Just et al., 1982). When
the word the is seen, a bottom-up and top-down
structure building step results in a sentence with an
intransitive verb being predicted. This structure be-
comes the current goal. Then the word girl is seen
and processed, i.e., its lexical entry is retrieved from
declarative memory. The noun slot in the goal is
then instantiated with that lexical entry. In the next
step, if the word ran is seen the relevant lexical item
for the verb is retrieved and instantiated with the
verb slot of the goal; here, the verb’s argument is
also retrieved and integrated with the subcategoriza-
tion frame of the verb. If, instead of ran the word
that appears, a new goal is created, with any pre-
viously instantiated slots of the preceding goal be-
ing passed on to the new goal, and parsing proceeds
from there.
Each retrieval of a goal from memory results in
a surge in its activation, so that repeated retrievals
result in increased activation; and the higher the ac-
tivation of an item the faster it is processed. At the
same time, activation decays according to the power
law of forgetting (Anderson et al., 2002). In the
same way that the goals undergo decay and reacti-
vation, so do the previously seen words. This means
that the speed of retrieval of a previously seen argu-
ment at a verb will be determined by the activation
level of that argument. Thus, the activation of both
the goals (predicted structures) and the arguments
affect processing.
In our simulations, for simplicity we code in the
exact steps that ACT-R takes for particular sen-
tences. Although it is feasible to build a very gen-
</bodyText>
<figure confidence="0.999802086956522">
Intentional Module
Visual buffer
Visual module
Productions
Goal buffer
Matching
Execution
Selection
Declarative module
Manual module
Retrieval buffer
Manual buffer
S
S
the
girl
ran
Mean Reading Time (msec)
300 400 500 600 700 800 900 1000
NP NP
Det N V1
the
S
NP
Det N
the
t V2
S’
S
V1
girl
that
Det N V1
the girl
S
Det N V1
NP
1 2 3 4 5 6 7 8 9 10 11 12 13
Position
sent
sent
reporterwho
The The reporterwho the
photographer
Object Relative
Subject Relative
</figure>
<figureCaption confidence="0.9984185">
Figure 2: A simple illustration of parsing steps in
the ACT-R simulations presented.
</figureCaption>
<bodyText confidence="0.9972584">
eral parser in pure ACT-R, before doing this we
wanted to first establish whether ACT-R’s reacti-
vation mechanisms can account for a reasonable
array of facts from the sentence processing litera-
ture. In (Lewis and Vasishth, An activation-based
model of sentence processing as skilled memory re-
trieval, (tentative title; in preparation)) we provide
a detailed description of a model employing mech-
anisms similar to those described here, but one that
behaves more like a standard parser.
</bodyText>
<subsectionHeader confidence="0.6732555">
3.1 English subject versus object relative
clauses
</subsectionHeader>
<bodyText confidence="0.984621294117647">
It is well known (Homes and O’Regan, 1981) that
English subject relatives are easier to process that
object relatives (1). In the parsing model outlined
above, we can model this result without changing
any ACT-R parameters at all (i.e., we use the default
settings for the parameters).
(1) a. The reporter who sent the photographer
to the editor hoped for a good story.
b. The reporter who the photographer sent
to the editor hoped for a good story.
The explanation comes from the decay of the ar-
guments of the verb sent: in object relatives the
argument reporter decays much more than in the
subject relative by the time it is integrated with the
verb’s subcategorization frame (Figure 3). This is
because more time elapses between the argument
being first seen and its retrieval at the verb.1
</bodyText>
<footnote confidence="0.928119">
1A reviewer points out that several head-final languages
such as German and Dutch also have a subject relative pref-
erence and in these languages the activation level cannot be the
explanation. We do not claim that decay is the only constraint
operating in parsing; frequency effects (greater preference for
</footnote>
<figureCaption confidence="0.945556666666667">
Figure 3: The reading times provided by the model.
Retrieval of reporter at sent is harder in the object
relative because of increased argument decay.
</figureCaption>
<subsectionHeader confidence="0.992957">
3.2 The SC/RC asymmetry in English
</subsectionHeader>
<bodyText confidence="0.976313823529412">
It is also well-known (Gibson, 2000) that a senten-
tial complement (SC) followed by a relative clause
(RC) is easier to process than an RC followed by an
SC:
(2) a. The fact that the employee who the
manager hired stole office supplies wor-
ried the executive.
b. #The executive who the fact that the
employee stole office supplies worried
hired the manager.
As in the previous discussion about relative
clauses, in the harder case the decay of the argument
executive at the verb worried is greater compared
to the decay of the argument employee at hired in
the easier-to-process sentence. In addition, the to-
tal reading time for the harder sentence is about 120
msec longer.2
</bodyText>
<subsectionHeader confidence="0.999134">
3.3 Hindi center embeddings
</subsectionHeader>
<bodyText confidence="0.998097764705882">
Previous work (Hakes, 1972), (Konieczny, 2000)
has shown that if argument-verb distance is in-
creased, processing is easier at the verb. (Vasishth,
more frequently occurring subject relatives) etc. could certainly
dominate where the amount of decay is constant in subject and
object relatives. It is an open empirical question whether fre-
quency alone can account for the subject/object asymmetry in
English, but given that we have independent empirical justi-
fication for decay (see Section 3.5), the above is a plausible
explanation.
2As a reviewer points out, “the account in terms of acti-
vation decay suggests that the SC/RC asymmetry can be an-
nihilated or even reversed by inserting longer or shorter NPs
between the critical verbs (worried, hired) and their arguments
(executive, employee). This seems unrealistic.” This is surely
an empirical question that needs to be verified experimentally;
we intend to pursue this very interesting issue in future work.
</bodyText>
<figure confidence="0.979080416666667">
bol-neko kahaa
RC/SC (hard); total RT = 7605 msec tell-inf told
Reading Time (msec)
900
800
700
600
500
400
RC/SC
SC/RC
SC/RC (easy); total RT = 7482 msec
</figure>
<figureCaption confidence="0.988079">
Figure 4: Model’s behavior in the complement-
clause/relative-clause contrast.
</figureCaption>
<bodyText confidence="0.999675333333333">
2003) presented similar results in Hindi. The Hindi
experiment manipulated distance by comparing the
baseline condition (3a) with the case where an ad-
verb intervened (3b), a verb-modifying PP inter-
vened (3c), and relative clause intervened that mod-
ified the preceding NP (3d).
</bodyText>
<listItem confidence="0.766275">
(3) a. Siitaa-ne Hari-ko Ravi-ko [kitaab-ko
Sita-erg Hari-dat Ravi-dat book-acc
khariid-neko] bol-neko kahaa
</listItem>
<bodyText confidence="0.97544652631579">
buy-inf tell-inf told
‘Sita told Hari to tell Ravi to buy the
book.’
‘Sita told Hari to tell Ravi to buy the
book that was lying on a/the table.’
In all the “insertion” cases a statistically signifi-
cant speedup was observed at the verb, compared to
the baseline condition.
This experiment’s results were replicated in the
ACT-R system; the replication is based on the as-
sumption that the goal (predicted syntactic struc-
ture) is reactivated each time it (i.e., the entire pre-
dicted structure) is modified. The intervening items
result in an extra retrieval compared to the base-
line, resulting in faster processing at the verb. In
this model, one parameter was changed: the rate of
decay of items. We justify this change in the next
sub-section.
The modeling results are shown in Figure 5.
</bodyText>
<figure confidence="0.94610825">
Reading times (msec)
0 200 400 600 800 1000
Reading times (msec)
0 200 400 600 800 1000
− Adv PP RC − Adv PP RC
Data Model
b. Siitaa-ne Hari-ko Ravi-ko [kitaab-ko Figure 5: Reading times from data versus model, at
Sita-erg Hari-dat Ravi-dat book-acc the first verb.
</figure>
<bodyText confidence="0.759399166666667">
jitnii-jaldii-ho-sake khariid-neko]
as-soon-as-possible buy-inf
bol-neko kahaa
tell-inf told
‘Sita told Hari to tell Ravi to buy the
book as soon as possible.’
</bodyText>
<listItem confidence="0.991134666666667">
c. Siitaa-ne Hari-ko Ravi-ko [kitaab-ko
Sita-erg Hari-dat Ravi-dat book-acc
ek bar.hiya dukaan se khariid-neko]
</listItem>
<bodyText confidence="0.726907">
from-a-good-shop buy-inf
bol-neko kahaa
tell-inf told
‘Sita told Hari to tell Ravi to buy the
book from a good shop.’
</bodyText>
<listItem confidence="0.93680025">
d. Siitaa-ne Hari-ko Ravi-ko [kitaab-ko
Sita-erg Hari-dat Ravi-dat book-acc
jo-mez-par-thii khariid-neko]
that-was-on-a-table buy-inf
</listItem>
<subsectionHeader confidence="0.988904">
3.4 Individual variation in Hindi center
embedding data
</subsectionHeader>
<bodyText confidence="0.99525525">
In the Hindi experiment, there was a further varia-
tion in the data when individual subjects’ data were
considered: only about 48% of subjects showed a
speedup at the verb. About 21% showed a slow-
down and there was only a few milliseconds differ-
ence (essentially no difference) in the reading times
for about 31% of the subjects. The observed varia-
tion was a systematic trend in the sense that the 47%
of the subjects who showed a speedup or slowdown
in adverb-insertion case also showed the same trend
in the PP- and RC-inserted cases – the probability of
this happening is considerably below chance level.
The rate of decay defined in ACT-R’s rehearsal
equation can systematically explain this variation.
Consider the situation where a chunk with an ini-
tial activation of is retrieved. The activation is
</bodyText>
<figure confidence="0.960375">
Reading Time at first verb (msec)
0 200 400 600 800 1000 1200 1400
Reading Time at first verb (msec)
0 200 400 600 800 1000 1200 1400
Reading Time at first verb (msec)
0 200 400 600 800 1000 1200 1400
d=0.01
No Adverb
Adverb
Data Model
</figure>
<figureCaption confidence="0.998714">
Figure 6: Modeling speedup.
</figureCaption>
<figure confidence="0.980535">
d=0.5
No Adverb
Adverb
Data Model
</figure>
<figureCaption confidence="0.999453">
Figure 7: Modeling slowdown.
</figureCaption>
<table confidence="0.592158333333333">
d=0.16
No Adverb
Adverb
</table>
<bodyText confidence="0.9781995">
that a chunk would reoccur as function of how it has
appeared in the past (Anderson et al., 2002, 17).
It turns out that the parameter take us beyond
boolean predictions: results in a speedup;
results in a slowdown; and results in
no difference in RT at the verb; see Figures 6 to 8.3
</bodyText>
<subsectionHeader confidence="0.999038">
3.5 Comparison with other models
</subsectionHeader>
<bodyText confidence="0.9707108125">
The model presented here is very different in con-
ception from existing models of sentence process-
ing. For example, consider Early Immediate Con-
sistuents (Hawkins, 1994) and Discourse Locality
Theory (Gibson, 2000), two theories with signif-
icant empirical coverage. Both theories propose
variants of what we will call the distance hypothe-
sis: increasing the distance between arguments and
a subsequently appearing verb (head) that selects
for them results in increased processing difficulty at
the verb. Distance here is quantified in terms of the
number of words in a constituent (EIC) or the num-
ber of new discourse referents introduced between
the arguments and head (DLT).
The present model claims that distance effects
are actually a result of argument decay. Prelimi-
nary evidence that it is really decay and not EIC-
or DLT-defined distance comes from a recent self-
paced listening experiment (Vasishth et al., 2004) in
which two conditions were contrasted: arguments
and verbs with (a) an adjunct intervening, (b) si-
lence:
(5) a. vo-kaagaz /jisko us-lar.ke-ne / mez
that-paper which that-boy-erg table
ke-piiche gire-hue /dekhaa /
behind fallen saw
bahut-puraanaa thaa
very-old was
‘That paper which that boy saw fallen
behind a/the table was very old.’
Data Model b. vo-kaagaz / jisko us-lar.ke-ne /
that-paper which that-boy-erg
</bodyText>
<figureCaption confidence="0.988778">
Figure 8: Modeling no difference in reading time.
</figureCaption>
<bodyText confidence="0.9805262">
recalculated each time a retrieval occurs, according
to the following equation.
(4)
Here, is the number of times the chunk was
successfully retrieved, is the time elapsed since
the -th retrieval, and is a decay rate that defaults
to in ACT-R. This equation reflects the log odds
SILENCE / dekhaa / bahut-puraanaa
saw very-old
thaa
was
‘That paper which that boy saw was
very old.’
In (5), the arguments kaagaz, ‘paper’, and lar.kaa,
‘boy’ are separated from the verb dekhaa, ‘saw’ by
</bodyText>
<footnote confidence="0.6521862">
3Of course, modeling individual variation in terms of differ-
ing rates of decay assumes that subjects exhibit varying degrees
of decay rates. An experiment is currently in progress that at-
tempts to correlate varying verbal sentence span with subject
behavior in the insertion cases.
</footnote>
<bodyText confidence="0.999975315789474">
an adjunct containing two discourse referents (5a);
or by silence (5b). Subjects were allowed to inter-
rupt the silence and continue listening to the rest of
the sentence whenever they wanted to. Subjects in-
terruped the silence (on an average) after about 1.4
seconds.
Distance based theories predict that having an in-
tervening adjunct that introduces discourse referents
should result in greater processing difficulty at the
verb dekhaa, ‘saw’, compared to when silence in-
tervenes. If decay rather than distance is the critical
factor here that affects processing, then there should
be greater difficulty at the verb in the silence con-
dition than when in the items intervene (see Sec-
tion 3.3 for why intervening items may facilitate
processing). The results support the activation ac-
count: introducing silence results in significantly
longer reading times at the verb dekhaa than when
intervening items occur.
</bodyText>
<sectionHeader confidence="0.999296" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999920857142857">
These modeling efforts suggest that very general
constraints on information processing can provide
a principled account of parsing phenomena, and
also brings human sentence parsing in closer con-
tact with models of human working memory in cog-
nitive psychology (Miyake and Shah, 1999).
There are of course certain potential limitations
in the work presented here. Several alternative hy-
potheses remain to be explored, e.g., the role of
competence grammar and its own (possibly theory-
internal) operations on processing; the role of expe-
rience (Crocker and Brants, 2000), etc. However,
the present research is a necessary first step since it
provides a basis for such a comparison.
Secondly, there are specific assumptions in the
model that may be controversial. For example, we
assume that entire sentence structures are predicted
as goal chunks, and not verb-types (cf. (Konieczny,
2000)). We are conducting further experiments to
explore the predictions made by different assump-
tions.
Finally, we have used toy simulations to ex-
plore the ACT-R constraint-interaction space, the
task of scaling up such a model to parse essentially
any kind of input is necessary, but still in the fu-
ture. However, we believe that the results presented
are suggestive of the way in which a cognitively-
oriented parser could be constructed.
</bodyText>
<footnote confidence="0.9251035">
4In DLT finite verbs also assumed to introduce a discourse
referent.
</footnote>
<sectionHeader confidence="0.996792" genericHeader="acknowledgments">
5 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999833">
We thank the two anonymous reviewers. This re-
search was partly funded by the Sonderforschungs-
bereich 378 (EM6, NEGRA).
</bodyText>
<sectionHeader confidence="0.996425" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999836936170213">
J.R. Anderson, D. Bothell, M.D. Byrne, and
C. Lebiere. 2002. An integrated theory of
the mind. MS, available from http://www.act-
r.psy.cmu.edu/papers/403/IntegratedTheory.pdf.
M. W. Crocker and T. Brants. 2000. Wide-coverage
probabilistic sentence processing. Journal of
Psycholinguistic Research, 29(6):647–669.
Edward Gibson. 2000. Dependency locality theory:
A distance-based theory of linguistic complexity.
In Alec Marantz, Yasushi Miyashita, and Wayne
O’Neil, editors, Image, Language, Brain: Papers
from the First Mind Articulation Project Sympo-
sium. MIT Press, Cambridge, MA.
Daniel Grodner and Edward Gibson. 2003. Con-
sequences of the serial nature of linguistic input.
MS.
David T. Hakes. 1972. On understanding sen-
tences: In search of a theory of sentence compre-
hension. Microfilm, University of Texas, Austin.
John A. Hawkins. 1994. A Performance Theory of
Order and Constituency. Cambridge University
Press, New York.
V.M. Homes and J.K. O’Regan. 1981. Eye fixation
patterns during the reading of relative clause sen-
tences. Journal of Verbal Learning and Verbal
Behavior, 20:417–430.
M. A. Just, P. A. Carpenter, and J. D. Woolley.
1982. Paradigms and processes in reading com-
prehension. Journal of Experimental Psychol-
ogy: General, 111(2):228–238.
Lars Konieczny. 2000. Locality and parsing com-
plexity. Journal of Psycholinguistic Research,
29(6):627–645.
Akira Miyake and Priti Shah, editors. 1999. Mod-
els of Working Memory. Cambridge University
Press, New York.
Philip Resnik. 1992. Left–corner parsing and psy-
chological plausibility. In Proceedings of COL-
ING, pages 191–197.
Shravan Vasishth, Richard L. Lewis, Rama Kant
Agnihotri, and Hans Uszkoreit. 2004. Distin-
guishing distance and decay. Submitted.
Shravan Vasishth. 2003. Quantifying processing
difficulty in human sentence parsing: The role
of decay, activation, and similarity-based interfer-
ence. In Proceedings of the EuroCogSci confer-
ence, Osnabrueck, Germany.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.302934">
<title confidence="0.999964">Modeling sentence processing in ACT-R</title>
<author confidence="0.989228">Shravan</author>
<affiliation confidence="0.984363">Department of Computational Saarland University, PO Box 15 11</affiliation>
<address confidence="0.933386">66041 Saarbr¨ucken,</address>
<email confidence="0.989622">vasishth@acm.org</email>
<author confidence="0.999648">L Richard</author>
<affiliation confidence="0.9957885">Department of University of</affiliation>
<author confidence="0.437797">Ann Arbor</author>
<author confidence="0.437797">MI</author>
<email confidence="0.999635">rickl@umich.edu</email>
<abstract confidence="0.980868454545454">We present a series of simulations of behavioral data by casting a simple parsing model in the cognitive architecture ACT-R. We show that constraints defined in ACT-R, specifically those relating to activation, can account for a range of facts about human sentence processing. In doing so, we argue that resource limitation in working memory is better defined as an artefact of very general and independently motivated principles of cognitive processing.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J R Anderson</author>
<author>D Bothell</author>
<author>Byrne</author>
<author>C Lebiere</author>
</authors>
<title>An integrated theory of the mind. MS, available from http://www.actr.psy.cmu.edu/papers/403/IntegratedTheory.pdf.</title>
<date>2002</date>
<contexts>
<context position="1149" citStr="Anderson et al., 2002" startWordPosition="171" endWordPosition="174">ts about human sentence processing. In doing so, we argue that resource limitation in working memory is better defined as an artefact of very general and independently motivated principles of cognitive processing. 1 Introduction Although language processing may be a specialized cognitive faculty, it is possible that it is nevertheless shaped by general constraints on the human cognitive architecture. This point has been addressed extensively in the connectionist literature, but we present a somewhat different approach to this problem by casting parsing within the cognitive architecture ACT-R (Anderson et al., 2002) and directly using the constraints provided in ACT-R to account for several interesting cross-linguistic facts: the wellknown sentential complement/relative clause asymmetry (Gibson, 2000; Grodner and Gibson, 2003) and the subject/object relative clause asymmetry in English (Homes and O’Regan, 1981); and some recent results (Vasishth, 2003) involving Hindi center embeddings, including a principled account of individual variation in subject behavior. In developing this approach, we argue that resource limitation in working memory is better defined as an artefact of very general constraints on </context>
<context position="2815" citStr="Anderson et al., 2002" startWordPosition="419" endWordPosition="422">comings of this approach, and of the broader consequences of modeling parsing within a cognitive architecture. 2 A brief introduction to the cognitive architecture ACT-R ACT-R is a theory of the human cognitive architecture. It allows the development of computational models that can closely simulate experimental methodologies such as eye-tracking and self-paced reading, and has been used to model a wide array of behavioral data from learning and memory, problem solving and decision making, language and communication, perception and attention, cognitive development, and individual differences (Anderson et al., 2002). The ACT-R architecture is attractive as a modeling tool for three reasons. First, it is based on a wide array of empirical results in various domains of cognitive psychology. Second, it is flexible enough to permit the modeler to add their own assumptions and theories about the specific task to be modeled. Finally, ACT-R models yield dependent measures such as reading time in much the same way as humans performing the experiment; e.g., the system can easily be programmed to simulate key presses after it processes material presented on the screen. As shown in Figure 1, the architecture consis</context>
<context position="7947" citStr="Anderson et al., 2002" startWordPosition="1296" endWordPosition="1299">rb slot of the goal; here, the verb’s argument is also retrieved and integrated with the subcategorization frame of the verb. If, instead of ran the word that appears, a new goal is created, with any previously instantiated slots of the preceding goal being passed on to the new goal, and parsing proceeds from there. Each retrieval of a goal from memory results in a surge in its activation, so that repeated retrievals result in increased activation; and the higher the activation of an item the faster it is processed. At the same time, activation decays according to the power law of forgetting (Anderson et al., 2002). In the same way that the goals undergo decay and reactivation, so do the previously seen words. This means that the speed of retrieval of a previously seen argument at a verb will be determined by the activation level of that argument. Thus, the activation of both the goals (predicted structures) and the arguments affect processing. In our simulations, for simplicity we code in the exact steps that ACT-R takes for particular sentences. Although it is feasible to build a very genIntentional Module Visual buffer Visual module Productions Goal buffer Matching Execution Selection Declarative mod</context>
<context position="15968" citStr="Anderson et al., 2002" startWordPosition="2632" endWordPosition="2635">d in ACT-R’s rehearsal equation can systematically explain this variation. Consider the situation where a chunk with an initial activation of is retrieved. The activation is Reading Time at first verb (msec) 0 200 400 600 800 1000 1200 1400 Reading Time at first verb (msec) 0 200 400 600 800 1000 1200 1400 Reading Time at first verb (msec) 0 200 400 600 800 1000 1200 1400 d=0.01 No Adverb Adverb Data Model Figure 6: Modeling speedup. d=0.5 No Adverb Adverb Data Model Figure 7: Modeling slowdown. d=0.16 No Adverb Adverb that a chunk would reoccur as function of how it has appeared in the past (Anderson et al., 2002, 17). It turns out that the parameter take us beyond boolean predictions: results in a speedup; results in a slowdown; and results in no difference in RT at the verb; see Figures 6 to 8.3 3.5 Comparison with other models The model presented here is very different in conception from existing models of sentence processing. For example, consider Early Immediate Consistuents (Hawkins, 1994) and Discourse Locality Theory (Gibson, 2000), two theories with significant empirical coverage. Both theories propose variants of what we will call the distance hypothesis: increasing the distance between argu</context>
</contexts>
<marker>Anderson, Bothell, Byrne, Lebiere, 2002</marker>
<rawString>J.R. Anderson, D. Bothell, M.D. Byrne, and C. Lebiere. 2002. An integrated theory of the mind. MS, available from http://www.actr.psy.cmu.edu/papers/403/IntegratedTheory.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M W Crocker</author>
<author>T Brants</author>
</authors>
<title>Wide-coverage probabilistic sentence processing.</title>
<date>2000</date>
<journal>Journal of Psycholinguistic Research,</journal>
<volume>29</volume>
<issue>6</issue>
<contexts>
<context position="19829" citStr="Crocker and Brants, 2000" startWordPosition="3246" endWordPosition="3249">erb dekhaa than when intervening items occur. 4 Conclusion These modeling efforts suggest that very general constraints on information processing can provide a principled account of parsing phenomena, and also brings human sentence parsing in closer contact with models of human working memory in cognitive psychology (Miyake and Shah, 1999). There are of course certain potential limitations in the work presented here. Several alternative hypotheses remain to be explored, e.g., the role of competence grammar and its own (possibly theoryinternal) operations on processing; the role of experience (Crocker and Brants, 2000), etc. However, the present research is a necessary first step since it provides a basis for such a comparison. Secondly, there are specific assumptions in the model that may be controversial. For example, we assume that entire sentence structures are predicted as goal chunks, and not verb-types (cf. (Konieczny, 2000)). We are conducting further experiments to explore the predictions made by different assumptions. Finally, we have used toy simulations to explore the ACT-R constraint-interaction space, the task of scaling up such a model to parse essentially any kind of input is necessary, but </context>
</contexts>
<marker>Crocker, Brants, 2000</marker>
<rawString>M. W. Crocker and T. Brants. 2000. Wide-coverage probabilistic sentence processing. Journal of Psycholinguistic Research, 29(6):647–669.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Gibson</author>
</authors>
<title>Dependency locality theory: A distance-based theory of linguistic complexity.</title>
<date>2000</date>
<contexts>
<context position="1337" citStr="Gibson, 2000" startWordPosition="199" endWordPosition="200">ive processing. 1 Introduction Although language processing may be a specialized cognitive faculty, it is possible that it is nevertheless shaped by general constraints on the human cognitive architecture. This point has been addressed extensively in the connectionist literature, but we present a somewhat different approach to this problem by casting parsing within the cognitive architecture ACT-R (Anderson et al., 2002) and directly using the constraints provided in ACT-R to account for several interesting cross-linguistic facts: the wellknown sentential complement/relative clause asymmetry (Gibson, 2000; Grodner and Gibson, 2003) and the subject/object relative clause asymmetry in English (Homes and O’Regan, 1981); and some recent results (Vasishth, 2003) involving Hindi center embeddings, including a principled account of individual variation in subject behavior. In developing this approach, we argue that resource limitation in working memory is better defined as an artefact of very general constraints on information processing – specifically, rehearsal and activation – rather than as an inherent numerical bound on memory capacity (cf. (Gibson, 2000; Hawkins, 1994); also see Section 3.5). I</context>
<context position="10836" citStr="Gibson, 2000" startWordPosition="1793" endWordPosition="1794"> time elapses between the argument being first seen and its retrieval at the verb.1 1A reviewer points out that several head-final languages such as German and Dutch also have a subject relative preference and in these languages the activation level cannot be the explanation. We do not claim that decay is the only constraint operating in parsing; frequency effects (greater preference for Figure 3: The reading times provided by the model. Retrieval of reporter at sent is harder in the object relative because of increased argument decay. 3.2 The SC/RC asymmetry in English It is also well-known (Gibson, 2000) that a sentential complement (SC) followed by a relative clause (RC) is easier to process than an RC followed by an SC: (2) a. The fact that the employee who the manager hired stole office supplies worried the executive. b. #The executive who the fact that the employee stole office supplies worried hired the manager. As in the previous discussion about relative clauses, in the harder case the decay of the argument executive at the verb worried is greater compared to the decay of the argument employee at hired in the easier-to-process sentence. In addition, the total reading time for the harde</context>
<context position="16403" citStr="Gibson, 2000" startWordPosition="2706" endWordPosition="2707"> No Adverb Adverb Data Model Figure 7: Modeling slowdown. d=0.16 No Adverb Adverb that a chunk would reoccur as function of how it has appeared in the past (Anderson et al., 2002, 17). It turns out that the parameter take us beyond boolean predictions: results in a speedup; results in a slowdown; and results in no difference in RT at the verb; see Figures 6 to 8.3 3.5 Comparison with other models The model presented here is very different in conception from existing models of sentence processing. For example, consider Early Immediate Consistuents (Hawkins, 1994) and Discourse Locality Theory (Gibson, 2000), two theories with significant empirical coverage. Both theories propose variants of what we will call the distance hypothesis: increasing the distance between arguments and a subsequently appearing verb (head) that selects for them results in increased processing difficulty at the verb. Distance here is quantified in terms of the number of words in a constituent (EIC) or the number of new discourse referents introduced between the arguments and head (DLT). The present model claims that distance effects are actually a result of argument decay. Preliminary evidence that it is really decay and </context>
</contexts>
<marker>Gibson, 2000</marker>
<rawString>Edward Gibson. 2000. Dependency locality theory: A distance-based theory of linguistic complexity.</rawString>
</citation>
<citation valid="false">
<booktitle>Papers from the First Mind Articulation Project Symposium.</booktitle>
<editor>In Alec Marantz, Yasushi Miyashita, and Wayne O’Neil, editors, Image, Language, Brain:</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker></marker>
<rawString>In Alec Marantz, Yasushi Miyashita, and Wayne O’Neil, editors, Image, Language, Brain: Papers from the First Mind Articulation Project Symposium. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Grodner</author>
<author>Edward Gibson</author>
</authors>
<title>Consequences of the serial nature of linguistic input.</title>
<date>2003</date>
<publisher>MS.</publisher>
<contexts>
<context position="1364" citStr="Grodner and Gibson, 2003" startWordPosition="201" endWordPosition="204">. 1 Introduction Although language processing may be a specialized cognitive faculty, it is possible that it is nevertheless shaped by general constraints on the human cognitive architecture. This point has been addressed extensively in the connectionist literature, but we present a somewhat different approach to this problem by casting parsing within the cognitive architecture ACT-R (Anderson et al., 2002) and directly using the constraints provided in ACT-R to account for several interesting cross-linguistic facts: the wellknown sentential complement/relative clause asymmetry (Gibson, 2000; Grodner and Gibson, 2003) and the subject/object relative clause asymmetry in English (Homes and O’Regan, 1981); and some recent results (Vasishth, 2003) involving Hindi center embeddings, including a principled account of individual variation in subject behavior. In developing this approach, we argue that resource limitation in working memory is better defined as an artefact of very general constraints on information processing – specifically, rehearsal and activation – rather than as an inherent numerical bound on memory capacity (cf. (Gibson, 2000; Hawkins, 1994); also see Section 3.5). In the rest of this paper, w</context>
</contexts>
<marker>Grodner, Gibson, 2003</marker>
<rawString>Daniel Grodner and Edward Gibson. 2003. Consequences of the serial nature of linguistic input. MS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David T Hakes</author>
</authors>
<title>On understanding sentences: In search of a theory of sentence comprehension.</title>
<date>1972</date>
<institution>Microfilm, University of Texas,</institution>
<location>Austin.</location>
<contexts>
<context position="11529" citStr="Hakes, 1972" startWordPosition="1912" endWordPosition="1913">o process than an RC followed by an SC: (2) a. The fact that the employee who the manager hired stole office supplies worried the executive. b. #The executive who the fact that the employee stole office supplies worried hired the manager. As in the previous discussion about relative clauses, in the harder case the decay of the argument executive at the verb worried is greater compared to the decay of the argument employee at hired in the easier-to-process sentence. In addition, the total reading time for the harder sentence is about 120 msec longer.2 3.3 Hindi center embeddings Previous work (Hakes, 1972), (Konieczny, 2000) has shown that if argument-verb distance is increased, processing is easier at the verb. (Vasishth, more frequently occurring subject relatives) etc. could certainly dominate where the amount of decay is constant in subject and object relatives. It is an open empirical question whether frequency alone can account for the subject/object asymmetry in English, but given that we have independent empirical justification for decay (see Section 3.5), the above is a plausible explanation. 2As a reviewer points out, “the account in terms of activation decay suggests that the SC/RC a</context>
</contexts>
<marker>Hakes, 1972</marker>
<rawString>David T. Hakes. 1972. On understanding sentences: In search of a theory of sentence comprehension. Microfilm, University of Texas, Austin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Hawkins</author>
</authors>
<title>A Performance Theory of Order and Constituency.</title>
<date>1994</date>
<publisher>Cambridge University Press,</publisher>
<location>New York.</location>
<contexts>
<context position="1911" citStr="Hawkins, 1994" startWordPosition="285" endWordPosition="286">/relative clause asymmetry (Gibson, 2000; Grodner and Gibson, 2003) and the subject/object relative clause asymmetry in English (Homes and O’Regan, 1981); and some recent results (Vasishth, 2003) involving Hindi center embeddings, including a principled account of individual variation in subject behavior. In developing this approach, we argue that resource limitation in working memory is better defined as an artefact of very general constraints on information processing – specifically, rehearsal and activation – rather than as an inherent numerical bound on memory capacity (cf. (Gibson, 2000; Hawkins, 1994); also see Section 3.5). In the rest of this paper, we first introduce the ACT-R architecture. Then we present the results of several simulations of experiments available in the psycholinguistic literature. The paper concludes with a discussion of the potential advantages and shortcomings of this approach, and of the broader consequences of modeling parsing within a cognitive architecture. 2 A brief introduction to the cognitive architecture ACT-R ACT-R is a theory of the human cognitive architecture. It allows the development of computational models that can closely simulate experimental meth</context>
<context position="16358" citStr="Hawkins, 1994" startWordPosition="2700" endWordPosition="2701">b Data Model Figure 6: Modeling speedup. d=0.5 No Adverb Adverb Data Model Figure 7: Modeling slowdown. d=0.16 No Adverb Adverb that a chunk would reoccur as function of how it has appeared in the past (Anderson et al., 2002, 17). It turns out that the parameter take us beyond boolean predictions: results in a speedup; results in a slowdown; and results in no difference in RT at the verb; see Figures 6 to 8.3 3.5 Comparison with other models The model presented here is very different in conception from existing models of sentence processing. For example, consider Early Immediate Consistuents (Hawkins, 1994) and Discourse Locality Theory (Gibson, 2000), two theories with significant empirical coverage. Both theories propose variants of what we will call the distance hypothesis: increasing the distance between arguments and a subsequently appearing verb (head) that selects for them results in increased processing difficulty at the verb. Distance here is quantified in terms of the number of words in a constituent (EIC) or the number of new discourse referents introduced between the arguments and head (DLT). The present model claims that distance effects are actually a result of argument decay. Prel</context>
</contexts>
<marker>Hawkins, 1994</marker>
<rawString>John A. Hawkins. 1994. A Performance Theory of Order and Constituency. Cambridge University Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V M Homes</author>
<author>J K O’Regan</author>
</authors>
<title>Eye fixation patterns during the reading of relative clause sentences.</title>
<date>1981</date>
<journal>Journal of Verbal Learning and Verbal Behavior,</journal>
<pages>20--417</pages>
<marker>Homes, O’Regan, 1981</marker>
<rawString>V.M. Homes and J.K. O’Regan. 1981. Eye fixation patterns during the reading of relative clause sentences. Journal of Verbal Learning and Verbal Behavior, 20:417–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Just</author>
<author>P A Carpenter</author>
<author>J D Woolley</author>
</authors>
<title>Paradigms and processes in reading comprehension.</title>
<date>1982</date>
<journal>Journal of Experimental Psychology: General,</journal>
<volume>111</volume>
<issue>2</issue>
<contexts>
<context position="6843" citStr="Just et al., 1982" startWordPosition="1102" endWordPosition="1105">p-down (predictive) step. We adopt this parsing strategy in the simulations. In order to model the prediction of syntactic structure based on incrementally appearing input, we assume that sentence structure templates are available in declarative memory as underspecified chunks. These chunks are retrieved every time a new word is integrated into the structure, as are prior arguments necessary for semantic integration. We illustrate the parsing process with a simple example (Figure 2). Suppose that the sentence to be parsed is The girl ran, and suppose that we are simulating self-paced reading (Just et al., 1982). When the word the is seen, a bottom-up and top-down structure building step results in a sentence with an intransitive verb being predicted. This structure becomes the current goal. Then the word girl is seen and processed, i.e., its lexical entry is retrieved from declarative memory. The noun slot in the goal is then instantiated with that lexical entry. In the next step, if the word ran is seen the relevant lexical item for the verb is retrieved and instantiated with the verb slot of the goal; here, the verb’s argument is also retrieved and integrated with the subcategorization frame of th</context>
</contexts>
<marker>Just, Carpenter, Woolley, 1982</marker>
<rawString>M. A. Just, P. A. Carpenter, and J. D. Woolley. 1982. Paradigms and processes in reading comprehension. Journal of Experimental Psychology: General, 111(2):228–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lars Konieczny</author>
</authors>
<title>Locality and parsing complexity.</title>
<date>2000</date>
<journal>Journal of Psycholinguistic Research,</journal>
<volume>29</volume>
<issue>6</issue>
<contexts>
<context position="11548" citStr="Konieczny, 2000" startWordPosition="1914" endWordPosition="1915">an RC followed by an SC: (2) a. The fact that the employee who the manager hired stole office supplies worried the executive. b. #The executive who the fact that the employee stole office supplies worried hired the manager. As in the previous discussion about relative clauses, in the harder case the decay of the argument executive at the verb worried is greater compared to the decay of the argument employee at hired in the easier-to-process sentence. In addition, the total reading time for the harder sentence is about 120 msec longer.2 3.3 Hindi center embeddings Previous work (Hakes, 1972), (Konieczny, 2000) has shown that if argument-verb distance is increased, processing is easier at the verb. (Vasishth, more frequently occurring subject relatives) etc. could certainly dominate where the amount of decay is constant in subject and object relatives. It is an open empirical question whether frequency alone can account for the subject/object asymmetry in English, but given that we have independent empirical justification for decay (see Section 3.5), the above is a plausible explanation. 2As a reviewer points out, “the account in terms of activation decay suggests that the SC/RC asymmetry can be ann</context>
<context position="20148" citStr="Konieczny, 2000" startWordPosition="3298" endWordPosition="3299">d Shah, 1999). There are of course certain potential limitations in the work presented here. Several alternative hypotheses remain to be explored, e.g., the role of competence grammar and its own (possibly theoryinternal) operations on processing; the role of experience (Crocker and Brants, 2000), etc. However, the present research is a necessary first step since it provides a basis for such a comparison. Secondly, there are specific assumptions in the model that may be controversial. For example, we assume that entire sentence structures are predicted as goal chunks, and not verb-types (cf. (Konieczny, 2000)). We are conducting further experiments to explore the predictions made by different assumptions. Finally, we have used toy simulations to explore the ACT-R constraint-interaction space, the task of scaling up such a model to parse essentially any kind of input is necessary, but still in the future. However, we believe that the results presented are suggestive of the way in which a cognitivelyoriented parser could be constructed. 4In DLT finite verbs also assumed to introduce a discourse referent. 5 Acknowledgements We thank the two anonymous reviewers. This research was partly funded by the </context>
</contexts>
<marker>Konieczny, 2000</marker>
<rawString>Lars Konieczny. 2000. Locality and parsing complexity. Journal of Psycholinguistic Research, 29(6):627–645.</rawString>
</citation>
<citation valid="true">
<title>Models of Working Memory.</title>
<date>1999</date>
<editor>Akira Miyake and Priti Shah, editors.</editor>
<publisher>Cambridge University Press,</publisher>
<location>New York.</location>
<marker>1999</marker>
<rawString>Akira Miyake and Priti Shah, editors. 1999. Models of Working Memory. Cambridge University Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Left–corner parsing and psychological plausibility.</title>
<date>1992</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>191--197</pages>
<contexts>
<context position="6176" citStr="Resnik, 1992" startWordPosition="998" endWordPosition="999">irs. Events like retrievals from DM are triggered by looking at the contents of one or more buffers. For example, the ACT-R system “sees” an item/object on the screen and then encodes it as a visual chunk. This chunk can then be harvested from the visual buffer; it includes (as slot-value specifications) information about the content of the item seen, its x-y coordinates, etc. One can define an action based on this information, such as retrieving a chunk from DM. 3 Modeling sentence parsing in ACT-R Previous research suggests that humans employ some variant of left-corner parsing (see, e.g., (Resnik, 1992)), which in essence involves a bottom-up and a top-down (predictive) step. We adopt this parsing strategy in the simulations. In order to model the prediction of syntactic structure based on incrementally appearing input, we assume that sentence structure templates are available in declarative memory as underspecified chunks. These chunks are retrieved every time a new word is integrated into the structure, as are prior arguments necessary for semantic integration. We illustrate the parsing process with a simple example (Figure 2). Suppose that the sentence to be parsed is The girl ran, and su</context>
</contexts>
<marker>Resnik, 1992</marker>
<rawString>Philip Resnik. 1992. Left–corner parsing and psychological plausibility. In Proceedings of COLING, pages 191–197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shravan Vasishth</author>
<author>Richard L Lewis</author>
<author>Rama Kant Agnihotri</author>
<author>Hans Uszkoreit</author>
</authors>
<date>2004</date>
<note>Distinguishing distance and decay. Submitted.</note>
<contexts>
<context position="17108" citStr="Vasishth et al., 2004" startWordPosition="2817" endWordPosition="2820">of what we will call the distance hypothesis: increasing the distance between arguments and a subsequently appearing verb (head) that selects for them results in increased processing difficulty at the verb. Distance here is quantified in terms of the number of words in a constituent (EIC) or the number of new discourse referents introduced between the arguments and head (DLT). The present model claims that distance effects are actually a result of argument decay. Preliminary evidence that it is really decay and not EICor DLT-defined distance comes from a recent selfpaced listening experiment (Vasishth et al., 2004) in which two conditions were contrasted: arguments and verbs with (a) an adjunct intervening, (b) silence: (5) a. vo-kaagaz /jisko us-lar.ke-ne / mez that-paper which that-boy-erg table ke-piiche gire-hue /dekhaa / behind fallen saw bahut-puraanaa thaa very-old was ‘That paper which that boy saw fallen behind a/the table was very old.’ Data Model b. vo-kaagaz / jisko us-lar.ke-ne / that-paper which that-boy-erg Figure 8: Modeling no difference in reading time. recalculated each time a retrieval occurs, according to the following equation. (4) Here, is the number of times the chunk was success</context>
</contexts>
<marker>Vasishth, Lewis, Agnihotri, Uszkoreit, 2004</marker>
<rawString>Shravan Vasishth, Richard L. Lewis, Rama Kant Agnihotri, and Hans Uszkoreit. 2004. Distinguishing distance and decay. Submitted.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shravan Vasishth</author>
</authors>
<title>Quantifying processing difficulty in human sentence parsing: The role of decay, activation, and similarity-based interference.</title>
<date>2003</date>
<booktitle>In Proceedings of the EuroCogSci conference,</booktitle>
<location>Osnabrueck, Germany.</location>
<contexts>
<context position="1492" citStr="Vasishth, 2003" startWordPosition="222" endWordPosition="223">eral constraints on the human cognitive architecture. This point has been addressed extensively in the connectionist literature, but we present a somewhat different approach to this problem by casting parsing within the cognitive architecture ACT-R (Anderson et al., 2002) and directly using the constraints provided in ACT-R to account for several interesting cross-linguistic facts: the wellknown sentential complement/relative clause asymmetry (Gibson, 2000; Grodner and Gibson, 2003) and the subject/object relative clause asymmetry in English (Homes and O’Regan, 1981); and some recent results (Vasishth, 2003) involving Hindi center embeddings, including a principled account of individual variation in subject behavior. In developing this approach, we argue that resource limitation in working memory is better defined as an artefact of very general constraints on information processing – specifically, rehearsal and activation – rather than as an inherent numerical bound on memory capacity (cf. (Gibson, 2000; Hawkins, 1994); also see Section 3.5). In the rest of this paper, we first introduce the ACT-R architecture. Then we present the results of several simulations of experiments available in the psy</context>
</contexts>
<marker>Vasishth, 2003</marker>
<rawString>Shravan Vasishth. 2003. Quantifying processing difficulty in human sentence parsing: The role of decay, activation, and similarity-based interference. In Proceedings of the EuroCogSci conference, Osnabrueck, Germany.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>