<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000901">
<title confidence="0.999225">
Machine Transliteration using Target-Language Grapheme and
Phoneme: Multi-engine Transliteration Approach
</title>
<author confidence="0.995867">
Jong-Hoon Oh, Kiyotaka Uchimoto, and Kentaro Torisawa
</author>
<affiliation confidence="0.991972">
Language Infrastructure Group, MASTAR Project,
National Institute of Information and Communications Technology (NICT)
</affiliation>
<address confidence="0.910831">
3-5 Hikaridai Seika-cho, Soraku-gun, Kyoto 619-0289 Japan
</address>
<email confidence="0.999391">
{rovellia,uchimoto,torisawa}@nict.go.jp
</email>
<sectionHeader confidence="0.993909" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999919785714286">
This paper describes our approach to
“NEWS 2009 Machine Transliteration
Shared Task.” We built multiple translit-
eration engines based on different combi-
nations of two transliteration models and
three machine learning algorithms. Then,
the outputs from these transliteration en-
gines were combined using re-ranking
functions. Our method was applied to all
language pairs in “NEWS 2009 Machine
Transliteration Shared Task.” The official
results of our standard runs were ranked
the best for four language pairs and the
second best for three language pairs.
</bodyText>
<sectionHeader confidence="0.998529" genericHeader="keywords">
1 Outline
</sectionHeader>
<bodyText confidence="0.99994025">
This paper describes our approach to “NEWS
2009 Machine Transliteration Shared Task.”
Our approach was based on two transliteration
models – TM-G (Transliteration model based
on target-language Graphemes) and TM-GP
(Transliteration model based on target-language
Graphemes and Phonemes). The difference
between the two models lies in whether or
not a machine transliteration process depends
on target-language phonemes. TM-G directly
converts source-language graphemes into target-
language graphemes, while TM-GP first trans-
forms source language graphemes into target-
language phonemes and then target-language
phonemes coupled with their corresponding
source-language graphemes are converted into
target-language graphemes. We used three dif-
ferent machine learning algorithms (conditional
random fields (CRFs), margin infused relaxed al-
gorithm (MIRA), and maximum entropy model
(MEM)) (Berger et al., 1996; Crammer and
Singer, 2003; Lafferty et al., 2001) for build-
ing multiple machine transliteration engines. We
attempted to improve the transliteration quality
by combining the outputs of different machine
transliteration engines operating on the same in-
put. Our approach was applied to all language
pairs in “NEWS 2009 Machine Transliteration
Shared Task.” The official results of our approach
were ranked as the best for four language pairs and
the second best for three language pairs (Li et al.,
2009a).
</bodyText>
<sectionHeader confidence="0.995202" genericHeader="introduction">
2 Transliteration Model
</sectionHeader>
<bodyText confidence="0.9998387">
Let S be a source-language word and T be a target-
language transliteration of S. T is represented in
two ways – TG, a sequence of target-language
graphemes, and TP, a sequence of target-language
phonemes. Here, a target-language grapheme is
defined as a target-language character. We regard
consonant and vowel parts in the romanized form
of a target language grapheme as a target-language
phoneme. Then TM-G and TM-GP are formu-
lated as Eq (1) and (2), respectively.
</bodyText>
<table confidence="0.981832">
En S C l i n t o n
Ch TP KE L I N D U N
TG 克:B 林:B 林:I 林:I *:B *:I *:I
Ja TP KU R I N T O N
TG ク:B リ:B リ:I ン:B ト:B ト:I ン:B
</table>
<figureCaption confidence="0.976555">
Figure 1: Illustration of the two transliteration
models
</figureCaption>
<figure confidence="0.6914957">
Clinton
克林* クリントン
TM-G
Clinton
KELINDUN
Clinton
克林* クリントン
TM-GP
KURINTON
Clinton
</figure>
<equation confidence="0.9085425">
PTM−G(T |S) = P(TG|S) (1)
PTM−GP (T |S) (2)
1: = P(TP|S) X P(TG|TP,S)
∀TP
</equation>
<page confidence="0.99263">
36
</page>
<note confidence="0.984811">
Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 36–39,
Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.950916285714286">
Figure 1 illustrates the two transliteration mod-
els with examples, Clinton and its Chinese
and Japanese transliterations. Target language
graphemes are represented in terms of the BIO no-
tation. This makes it easier to represent many-
to-one correspondence between target language
phoneme and grapheme.
</bodyText>
<sectionHeader confidence="0.993727" genericHeader="method">
3 Machine Learning Algorithms
</sectionHeader>
<bodyText confidence="0.999903">
A machine transliteration problem can be con-
verted into a sequential labeling problem, where
each source-language grapheme is tagged with its
corresponding target-language grapheme. This
section briefly describes the machine learning al-
gorithms used for building multiple transliteration
engines.
</bodyText>
<subsectionHeader confidence="0.995027">
3.1 Maximum Entropy Model
</subsectionHeader>
<bodyText confidence="0.999956166666667">
Machine transliteration based on the maximum
entropy model was described in detail in Oh et al.
(2006) along with comprehensive evaluation of its
performance. We used the same way as that pro-
posed by Oh et al. (2006), thus its full description
is not presented here.
</bodyText>
<subsectionHeader confidence="0.999607">
3.2 Conditional Random Fields (CRFs)
</subsectionHeader>
<bodyText confidence="0.999887333333333">
CRFs, a statistical sequence modeling framework,
was first introduced by Lafferty et al. (2001).
CRFs has been used for sequential labeling prob-
lems such as text chunking and named entity
recognition (McCallum and Li, 2003). CRF++1
was used in our experiment.
</bodyText>
<subsectionHeader confidence="0.998161">
3.3 Margin Infused Relaxed Algorithm
</subsectionHeader>
<bodyText confidence="0.999389333333333">
The Margin Infused Relaxed Algorithm (MIRA)
has been introduced by Crammer and Singer
(2003) for large-margin multi-class classification.
Kruengkrai et al. (2008) proposed a discriminative
model for joint Chinese segmentation and POS
tagging, where MIRA was used as their machine
learning algorithm. We used the same model for
our machine transliteration, exactly joint syllabi-
cation2 and transliteration.
</bodyText>
<subsectionHeader confidence="0.687659">
3.4 Features
</subsectionHeader>
<bodyText confidence="0.998668">
We used the following features within the f3 con-
text window3 for the above mentioned three ma-
</bodyText>
<footnote confidence="0.8948162">
1Available at http://crfpp.sourceforge.net/
2A syllable in English is defined as a sequence of English
grapheme corresponding to one target-language grapheme.
3The unit of context window is source-language
grapheme or syllable.
</footnote>
<listItem confidence="0.95759525">
chine learning algorithms.
• Left-three and right-three source-language
graphemes (or syllables)
• Left-three and right-three target-language
phonemes
• Target-language graphemes assigned to the
previous three source-language graphemes
(or syllables)
</listItem>
<sectionHeader confidence="0.997113" genericHeader="method">
4 Multi-engine Transliteration
</sectionHeader>
<subsectionHeader confidence="0.995454">
4.1 Individual Transliteration Engine
</subsectionHeader>
<bodyText confidence="0.9979958125">
The main aim of the multi-engine transliteration
approach is to combine the outputs of multiple en-
gines so that the final output is better in quality
than the output of each individual engine. We
designed four transliteration engines using dif-
ferent combinations of source-language translit-
eration units, transliteration models, and machine
learning algorithms as listed in Table 1. We named
four transliteration engines as CRF-G, MEM-G,
MEM-GP, and MIRA-G. Here, the prefixes rep-
resent applied machine learning algorithms (max-
imum entropy model (MEM), CRFs, and MIRA),
while G and GP in the suffix represent the translit-
eration models, TM-G and TM-GP, respectively.
Each individual engine produces 30-best translit-
erations for a given source-language word.
</bodyText>
<table confidence="0.99887975">
Source-language transliteration unit
Grapheme Syllable
TM-G ME-G, CRF-G MIRA-G
TM-GP ME-GP N/A
</table>
<tableCaption confidence="0.980696">
Table 1: Design strategy for multiple translitera-
tion engines
</tableCaption>
<subsectionHeader confidence="0.994734">
4.2 Combining Methodology
</subsectionHeader>
<bodyText confidence="0.999873125">
We combined the outputs of multiple translitera-
tion engines by means of a re-ranking function,
g(x). Let X be a set of transliterations gener-
ated by multiple transliteration engines for source-
language word s and ref be a reference translit-
eration of s. A re-ranking function is defined as
Eq. (3), where it ranks ref in X higher and the
others lower (Oh and Isahara, 2007).
</bodyText>
<equation confidence="0.99928">
g(x) : X → {r : r is ordering of x E X} (3)
</equation>
<bodyText confidence="0.999140666666667">
We designed two types of re-ranking functions by
using the rank of each individual engine and ma-
chine learning algorithm.
</bodyText>
<page confidence="0.99708">
37
</page>
<subsectionHeader confidence="0.6475835">
4.2.1 Re-ranking Based on the Rank of
Individual Engines
</subsectionHeader>
<bodyText confidence="0.997048272727273">
Two re-ranking functions based on the rank of
each individual engine, grank and gFscore(x),
are used for combining the outputs of multiple
transliteration engines. Let X be a set of outputs
of N transliteration engines for the same input.
grank(x) re-ranks x E X in the manner shown
in Eq. (4), where Ranki(x) is the position of x in
the n-best list generated by the ith transliteration
engine. grank(x) can be interpreted as the average
rank of x over outputs of each individual engine.
If x is not in the n-best list of the ith transliteration
</bodyText>
<equation confidence="0.96539525">
engine, 1
Ranki(x) = 0.
1
Ranki(x) (4)
</equation>
<bodyText confidence="0.990463153846154">
gFscore(x) is based on grank(x) and the F-
score measure, which is one of the evaluation met-
rics in the “NEWS 2009 Machine Transliteration
Shared Task” (Li et al., 2009b). We considered
the top three outputs of each individual engine
as reference transliterations and defined them as
virtual reference transliterations. We calculated
the F-score measure between the virtual reference
transliteration and each output of multiple translit-
eration engines. gFscore(x) is defined by Eq. (5),
where VRef is a set of virtual reference transliter-
ations, and Fscore(vr, x) is a function that restores
the F-score measure between vr and x.
</bodyText>
<equation confidence="0.996157">
gFscore(x) = grank(x) x MF(x) (5)
1
MF(x) = |V Ref|
vr∈V Ref
</equation>
<bodyText confidence="0.9995035">
Since the F-score measure is calculated in terms of
string similarity, x gets a high score from gMF (x)
when it is orthographically similar to virtual refer-
ence transliterations.
</bodyText>
<subsectionHeader confidence="0.7431775">
4.2.2 Re-ranking based on Machine Learning
Algorithm
</subsectionHeader>
<bodyText confidence="0.999935714285714">
We used the maximum entropy model for learn-
ing re-ranking function gME(x). Let ref be a ref-
erence transliteration of source-language word s,
feature(x) be a feature vector of x E X, and
y E {ref, wrong} be the training label for x.
gME(x) assigns a probability to x E X as shown
in Eq. (6).
</bodyText>
<equation confidence="0.991804">
gME(x) = P(ref|feature(x)) (6)
</equation>
<bodyText confidence="0.87046">
A feature vector of x is composed of
</bodyText>
<equation confidence="0.773269">
• (grank(x), gFscore(x), 1
Ranki(x), P(T |S))
</equation>
<bodyText confidence="0.727301">
where 1
</bodyText>
<equation confidence="0.746716">
Ranki(x) and P(T |S) of each individual en-
</equation>
<bodyText confidence="0.933823">
gine are used as a feature.
We estimated P(ref|feature(x)) by using the
development data.
</bodyText>
<sectionHeader confidence="0.989386" genericHeader="method">
5 Our Results
</sectionHeader>
<subsectionHeader confidence="0.963912">
5.1 Individual Engine
</subsectionHeader>
<table confidence="0.999763777777778">
CRF-G MEM-G MEM-GP MIRA-G
EnCh 0.628 0.686 0.715 0.684
EnHi 0.455 0.469 0.469 0.412
EnJa 0.514 0.517 0.519 0.490
EnKa 0.386 0.380 0.380 0.338
EnKo 0.460 0.438 0.447 0.367
EnRu 0.600 0.561 0.566 0.568
EnTa 0.453 0.459 0.459 0.412
JnJk N/A 0.532 N/A 0.571
</table>
<tableCaption confidence="0.999485">
Table 2: ACC of individual engines on the test data
</tableCaption>
<bodyText confidence="0.997654192307692">
Table 2 presents ACC4 of individual translit-
eration engines, which was applied to all lan-
guage pairs in “NEWS 2009 Machine Translit-
eration Shared Task” (Li et al., 2004; Kumaran
and Kellner, 2007; The CJK Dictionary Institute,
2009). CRF-G was the best transliteration engine
in EnKa, EnKo, and EnRu. Owing to the high
training costs of CRFs, we trained CRF-G in EnCh
with a very small number of iterations5. Hence,
the performance of CRF-G was poorer than that
of the other engines in EnCh. MEM-GP was the
best transliteration engine in EnCh, EnHi, EnJa,
and EnTa. These results indicate that joint use
of source language graphemes and target language
phonemes were very useful for improving perfor-
mance. MIRA-G was sensitive to the training data
size, because it was based on joint syllabication
and transliteration. Therefore, the performance of
MIRA-G was relatively better in EnCh and EnJa,
whose training data size is bigger than other lan-
guage pairs. CRF-G could not be applied to JnJk,
mainly due to too long training time. Further,
MEM-GP could not be applied to JnJk, because
transliteration in JnJk can be regarded as conver-
sion of target language phonemes to target lan-
guage graphemes. MEM-G and MIRA-G were
</bodyText>
<footnote confidence="0.968907">
4Word accuracy in Top-1 (Li et al., 2009b)
5We applied over 100 iterations to other language pairs
but only 30 iterations to EnCh.
</footnote>
<equation confidence="0.9966348">
�N
1
grank(x) = 1V
i=1
Fscore(vr, x)
</equation>
<page confidence="0.99138">
38
</page>
<bodyText confidence="0.8873852">
applied to JnJk and MIRA-G showed the best per-
formance in JnJK.6
graphemes and phonemes, and our multi-engine
transliteration approach are effective, regardless of
the nature of the language pairs.
</bodyText>
<table confidence="0.9707948">
5.2 Combining Multiple Engines
grank gFscore gME I-BEST
EnCh 0.730 0.731 0.731 0.715
EnHi 0.481 0.475 0.483 0.469
EnJa 0.535 0.535 0.537 0.519
EnKa 0.393 0.399 0.398 0.386
EnKo 0.461 0.444 0.473 0.460
EnRu 0.602 0.605 0.600 0.600
EnTa 0.470 0.478 0.474 0.459
JnJk 0.597 0.593 0.590 0.571
</table>
<tableCaption confidence="0.997376">
Table 3: Multi-engine transliteration results on the
</tableCaption>
<bodyText confidence="0.971217652173913">
test data: the underlined figures are our official re-
sult
Table 3 presents the ACC of our multi-engine
transliteration approach and that of the best in-
dividual engine (I-BEST) in each language pair.
gME gave the best performance in EnCh, EnHi,
EnJa, and EnKo, while gFscore did in EnCh, EnKa,
EnRu, and EnTa. Comparison between the best
individual transliteration engine and our multi-
engine transliteration showed that grank and gME
consistently showed better performance except in
EnRu, while gFscore showed the poorer perfor-
mance in EnKo. The results to be submitted as
“the standard run” were selected among the re-
sults listed in Table 3 by using cross-validation on
the development data. We submitted the results of
gME as the standard run to “NEWS 2009 Machine
Transliteration Shared Task” for the six language
pairs in Table 3, while the result of gFscore is sub-
mitted as the standard run for EnRu. The official
results of our standard runs were ranked the best
for EnCh, EnJa, EnKa, and EnTa, and the second
best for EnHi, EnKo, and EnRu (Li et al., 2009a).
</bodyText>
<sectionHeader confidence="0.999249" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999935142857143">
In conclusion, we have applied multi-engine
transliteration approach to “NEWS 2009 Machine
Transliteration Shared Task.” We built multiple
transliteration engines based on different com-
binations of transliteration models and machine
learning algorithms. We showed that the translit-
eration model, which is based on target language
</bodyText>
<footnote confidence="0.94554125">
6We submitted the results of MEM-G as a standard run for
JnJk because we had only one transliteration engine for JnJK
before the submission deadline of the NEWS 2009 machine
transliteration shared task.
</footnote>
<sectionHeader confidence="0.964566" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999455860465116">
A. L. Berger, S. D. Pietra, and V. J. D. Pietra. 1996. A
maximum entropy approach to natural language pro-
cessing. Computational Linguistics, 22(1):39–71.
Koby Crammer and Yoram Singer. 2003. Ultracon-
servative online algorithms for multiclass problems.
Journal ofMachine Learning Research, 3:951–991.
Canasai Kruengkrai, Jun’ichi Kazama, Kiyotaka Uchi-
moto, Kentaro Torisawa, and Hitoshi Isahara. 2008.
A discriminative hybrid model for joint Chinese
word segmentation and pos tagging. In Proc. of The
11th Oriental COCOSDA Workshop.
A. Kumaran and Tobias Kellner. 2007. A generic
framework for machine transliteration. In Proc. of
SIGIR ’07, pages 721–722.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proc. ofICML01, pages 282–289.
Haizhou Li, Min Zhang, and Su Jian. 2004. A joint
source-channel model for machine transliteration.
In Proc. ofACL ’04, pages 160–167.
Haizhou Li, A Kumaran, Vladimir Pervouchine, and
Min Zhang. 2009a. Report on NEWS 2009 machine
transliteration shared task. In Proc. ofACL-IJCNLP
2009 Named Entities Workshop.
Haizhou Li, A Kumaran, Min Zhang, and Vladimir
Pervouchine. 2009b. Whitepaper of NEWS 2009
machine transliteration shared task. In Proc. of
ACL-IJCNLP 2009 Named Entities Workshop.
Andrew McCallum and Wei Li. 2003. Early results for
named entity recognition with conditional random
fields, feature induction and web-enhanced lexicons.
In Proc. of CoNLL ’03, pages 188–191.
Jong-Hoon Oh and Hitoshi Isahara. 2007. Machine
transliteration using multiple transliteration engines
and hypothesis re-ranking. In Proc. of the 11th Ma-
chine Translation Summit, pages 353–360.
Jong-Hoon Oh, Key-Sun Choi, and Hitoshi Isahara.
2006. A comparison of different machine transliter-
ation models. Journal of Artificial Intelligence Re-
search (JAIR), 27:119–151.
The CJK Dictionary Institute. 2009. http://www.
cjk.org.
</reference>
<page confidence="0.999523">
39
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000065">
<title confidence="0.9977565">Machine Transliteration using Target-Language Grapheme Phoneme: Multi-engine Transliteration Approach</title>
<author confidence="0.918903">Jong-Hoon Oh</author>
<author confidence="0.918903">Kiyotaka Uchimoto</author>
<author confidence="0.918903">Kentaro</author>
<affiliation confidence="0.970401">Language Infrastructure Group, MASTAR National Institute of Information and Communications Technology</affiliation>
<address confidence="0.951826">3-5 Hikaridai Seika-cho, Soraku-gun, Kyoto 619-0289</address>
<abstract confidence="0.98752868161435">This paper describes our approach to “NEWS 2009 Machine Transliteration Shared Task.” We built multiple transliteration engines based on different combinations of two transliteration models and three machine learning algorithms. Then, the outputs from these transliteration engines were combined using re-ranking functions. Our method was applied to all language pairs in “NEWS 2009 Machine Transliteration Shared Task.” The official results of our standard runs were ranked the best for four language pairs and the second best for three language pairs. 1 Outline This paper describes our approach to “NEWS 2009 Machine Transliteration Shared Task.” Our approach was based on two transliteration – based target-language and based on target-language and The difference between the two models lies in whether or not a machine transliteration process depends on target-language phonemes. TM-G directly converts source-language graphemes into targetlanguage graphemes, while TM-GP first transforms source language graphemes into targetlanguage phonemes and then target-language phonemes coupled with their corresponding source-language graphemes are converted into target-language graphemes. We used three different machine learning algorithms (conditional random fields (CRFs), margin infused relaxed algorithm (MIRA), and maximum entropy model (MEM)) (Berger et al., 1996; Crammer and Singer, 2003; Lafferty et al., 2001) for building multiple machine transliteration engines. We attempted to improve the transliteration quality by combining the outputs of different machine transliteration engines operating on the same input. Our approach was applied to all language pairs in “NEWS 2009 Machine Transliteration Shared Task.” The official results of our approach were ranked as the best for four language pairs and the second best for three language pairs (Li et al., 2009a). 2 Transliteration Model a source-language word and a targettransliteration of represented in ways – a sequence of target-language and a sequence of target-language phonemes. Here, a target-language grapheme is defined as a target-language character. We regard consonant and vowel parts in the romanized form of a target language grapheme as a target-language Then formulated as Eq (1) and (2), respectively. En S C l i n t o n Ch KE L I N D U N Ja KU R I N T O N Figure 1: Illustration of the two transliteration models Clinton 克林* クリントン TM-G Clinton KELINDUN Clinton 克林* クリントン TM-GP KURINTON Clinton = 1:= 36 of the 2009 Named Entities Workshop, ACL-IJCNLP pages Singapore, 7 August 2009. ACL and AFNLP Figure 1 illustrates the two transliteration modwith examples, its Chinese and Japanese transliterations. Target language graphemes are represented in terms of the BIO notation. This makes it easier to represent manyto-one correspondence between target language phoneme and grapheme. 3 Machine Learning Algorithms A machine transliteration problem can be converted into a sequential labeling problem, where each source-language grapheme is tagged with its corresponding target-language grapheme. This section briefly describes the machine learning algorithms used for building multiple transliteration engines. 3.1 Maximum Entropy Model Machine transliteration based on the maximum entropy model was described in detail in Oh et al. (2006) along with comprehensive evaluation of its performance. We used the same way as that proposed by Oh et al. (2006), thus its full description is not presented here. 3.2 Conditional Random Fields (CRFs) CRFs, a statistical sequence modeling framework, was first introduced by Lafferty et al. (2001). CRFs has been used for sequential labeling problems such as text chunking and named entity (McCallum and Li, 2003). was used in our experiment. 3.3 Margin Infused Relaxed Algorithm The Margin Infused Relaxed Algorithm (MIRA) has been introduced by Crammer and Singer (2003) for large-margin multi-class classification. Kruengkrai et al. (2008) proposed a discriminative model for joint Chinese segmentation and POS tagging, where MIRA was used as their machine learning algorithm. We used the same model for our machine transliteration, exactly joint syllabiand transliteration. 3.4 Features used the following features within the confor the above mentioned three maat syllable in English is defined as a sequence of English grapheme corresponding to one target-language grapheme. unit of context window is source-language grapheme or syllable. chine learning algorithms. • Left-three and right-three source-language graphemes (or syllables) • Left-three and right-three target-language phonemes • Target-language graphemes assigned to the previous three source-language graphemes (or syllables) 4 Multi-engine Transliteration 4.1 Individual Transliteration Engine The main aim of the multi-engine transliteration approach is to combine the outputs of multiple engines so that the final output is better in quality than the output of each individual engine. We designed four transliteration engines using different combinations of source-language transliteration units, transliteration models, and machine learning algorithms as listed in Table 1. We named four transliteration engines as CRF-G, MEM-G, MEM-GP, and MIRA-G. Here, the prefixes represent applied machine learning algorithms (maximum entropy model (MEM), CRFs, and MIRA), while G and GP in the suffix represent the translitmodels, respectively. Each individual engine produces 30-best transliterations for a given source-language word. Source-language transliteration unit Grapheme Syllable TM-G ME-G, CRF-G MIRA-G TM-GP ME-GP N/A Table 1: Design strategy for multiple transliteration engines 4.2 Combining Methodology We combined the outputs of multiple transliteration engines by means of a re-ranking function, Let a set of transliterations generated by multiple transliteration engines for sourceword a reference translitof A re-ranking function is defined as (3), where it ranks and the others lower (Oh and Isahara, 2007). : is ordering of x We designed two types of re-ranking functions by using the rank of each individual engine and machine learning algorithm. 37 4.2.1 Re-ranking Based on the Rank of Individual Engines Two re-ranking functions based on the rank of individual engine, and are used for combining the outputs of multiple engines. Let a set of outputs engines for the same input. the manner shown Eq. (4), where the position of n-best list generated by the transliteration can be interpreted as the average of outputs of each individual engine. not in the n-best list of the transliteration 1 1 based on and the Fscore measure, which is one of the evaluation metrics in the “NEWS 2009 Machine Transliteration Shared Task” (Li et al., 2009b). We considered the top three outputs of each individual engine as reference transliterations and defined them as reference We calculated the F-score measure between the virtual reference transliteration and each output of multiple translitengines. is defined by Eq. (5), where VRef is a set of virtual reference transliterand a function that restores F-score measure between = = Ref Since the F-score measure is calculated in terms of similarity, a high score from when it is orthographically similar to virtual reference transliterations. 4.2.2 Re-ranking based on Machine Learning Algorithm We used the maximum entropy model for learnre-ranking function Let a reftransliteration of source-language word a feature vector of and the training label for a probability to shown in Eq. (6). = feature vector of composed of • each individual engine are used as a feature. estimated using the development data.</abstract>
<note confidence="0.827352454545454">5 Our Results 5.1 Individual Engine CRF-G MEM-G MEM-GP MIRA-G EnCh 0.628 0.686 0.715 0.684 EnHi 0.455 0.469 0.469 0.412 EnJa 0.514 0.517 0.519 0.490 EnKa 0.386 0.380 0.380 0.338 EnKo 0.460 0.438 0.447 0.367 EnRu 0.600 0.561 0.566 0.568 EnTa 0.453 0.459 0.459 0.412 JnJk N/A N/A 0.571</note>
<abstract confidence="0.991581052631579">Table 2: ACC of individual engines on the test data 2 presents of individual transliteration engines, which was applied to all language pairs in “NEWS 2009 Machine Transliteration Shared Task” (Li et al., 2004; Kumaran and Kellner, 2007; The CJK Dictionary Institute, 2009). CRF-G was the best transliteration engine in EnKa, EnKo, and EnRu. Owing to the high training costs of CRFs, we trained CRF-G in EnCh a very small number of Hence, the performance of CRF-G was poorer than that of the other engines in EnCh. MEM-GP was the best transliteration engine in EnCh, EnHi, EnJa, and EnTa. These results indicate that joint use of source language graphemes and target language phonemes were very useful for improving performance. MIRA-G was sensitive to the training data size, because it was based on joint syllabication and transliteration. Therefore, the performance of MIRA-G was relatively better in EnCh and EnJa, whose training data size is bigger than other language pairs. CRF-G could not be applied to JnJk, mainly due to too long training time. Further, MEM-GP could not be applied to JnJk, because transliteration in JnJk can be regarded as conversion of target language phonemes to target language graphemes. MEM-G and MIRA-G were accuracy in Top-1 (Li et al., 2009b) applied over 100 iterations to other language pairs but only 30 iterations to EnCh. 1 = 38 applied to JnJk and MIRA-G showed the best perin graphemes and phonemes, and our multi-engine transliteration approach are effective, regardless of the nature of the language pairs.</abstract>
<note confidence="0.7037397">5.2 Combining Multiple Engines EnCh 0.730 0.731 0.731 0.715 EnHi 0.481 0.475 0.483 0.469 EnJa 0.535 0.535 0.537 0.519 EnKa 0.393 0.399 0.398 0.386 EnKo 0.461 0.444 0.473 0.460 EnRu 0.602 0.605 0.600 0.600 EnTa 0.470 0.478 0.474 0.459 JnJk 0.597 0.593 0.590 0.571 Table 3: Multi-engine transliteration results on the</note>
<abstract confidence="0.989098166666667">test data: the underlined figures are our official result Table 3 presents the ACC of our multi-engine transliteration approach and that of the best inengine in each language pair. the best performance in EnCh, EnHi, and EnKo, while did in EnCh, EnKa, EnRu, and EnTa. Comparison between the best individual transliteration engine and our multitransliteration showed that and consistently showed better performance except in while showed the poorer performance in EnKo. The results to be submitted as “the standard run” were selected among the results listed in Table 3 by using cross-validation on the development data. We submitted the results of the standard run to “NEWS 2009 Machine Transliteration Shared Task” for the six language in Table 3, while the result of is submitted as the standard run for EnRu. The official results of our standard runs were ranked the best for EnCh, EnJa, EnKa, and EnTa, and the second best for EnHi, EnKo, and EnRu (Li et al., 2009a). 6 Conclusion In conclusion, we have applied multi-engine transliteration approach to “NEWS 2009 Machine Transliteration Shared Task.” We built multiple transliteration engines based on different combinations of transliteration models and machine learning algorithms. We showed that the transliteration model, which is based on target language submitted the results of MEM-G as a standard run for JnJk because we had only one transliteration engine for JnJK before the submission deadline of the NEWS 2009 machine transliteration shared task. References A. L. Berger, S. D. Pietra, and V. J. D. Pietra. 1996. A maximum entropy approach to natural language pro- 22(1):39–71. Koby Crammer and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. ofMachine Learning 3:951–991.</abstract>
<note confidence="0.7313772">Canasai Kruengkrai, Jun’ichi Kazama, Kiyotaka Uchimoto, Kentaro Torisawa, and Hitoshi Isahara. 2008. A discriminative hybrid model for joint Chinese segmentation and pos tagging. In of The Oriental COCOSDA A. Kumaran and Tobias Kellner. 2007. A generic for machine transliteration. In of pages 721–722. John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Prob-</note>
<abstract confidence="0.697252">abilistic models for segmenting and labeling sedata. In pages 282–289. Haizhou Li, Min Zhang, and Su Jian. 2004. A joint source-channel model for machine transliteration.</abstract>
<note confidence="0.637138714285714">ofACL pages 160–167. Haizhou Li, A Kumaran, Vladimir Pervouchine, and Min Zhang. 2009a. Report on NEWS 2009 machine shared task. In ofACL-IJCNLP Named Entities Haizhou Li, A Kumaran, Min Zhang, and Vladimir Pervouchine. 2009b. Whitepaper of NEWS 2009</note>
<title confidence="0.824922">transliteration shared task. In of 2009 Named Entities</title>
<author confidence="0.902663">Early results for</author>
<abstract confidence="0.83611325">named entity recognition with conditional random fields, feature induction and web-enhanced lexicons. of CoNLL pages 188–191. Jong-Hoon Oh and Hitoshi Isahara. 2007. Machine transliteration using multiple transliteration engines hypothesis re-ranking. In of the 11th Ma- Translation pages 353–360. Jong-Hoon Oh, Key-Sun Choi, and Hitoshi Isahara. 2006. A comparison of different machine translitermodels. of Artificial Intelligence Re- 27:119–151. CJK Dictionary Institute. 2009.</abstract>
<intro confidence="0.740388">39</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A L Berger</author>
<author>S D Pietra</author>
<author>V J D Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="1853" citStr="Berger et al., 1996" startWordPosition="240" endWordPosition="243">). The difference between the two models lies in whether or not a machine transliteration process depends on target-language phonemes. TM-G directly converts source-language graphemes into targetlanguage graphemes, while TM-GP first transforms source language graphemes into targetlanguage phonemes and then target-language phonemes coupled with their corresponding source-language graphemes are converted into target-language graphemes. We used three different machine learning algorithms (conditional random fields (CRFs), margin infused relaxed algorithm (MIRA), and maximum entropy model (MEM)) (Berger et al., 1996; Crammer and Singer, 2003; Lafferty et al., 2001) for building multiple machine transliteration engines. We attempted to improve the transliteration quality by combining the outputs of different machine transliteration engines operating on the same input. Our approach was applied to all language pairs in “NEWS 2009 Machine Transliteration Shared Task.” The official results of our approach were ranked as the best for four language pairs and the second best for three language pairs (Li et al., 2009a). 2 Transliteration Model Let S be a source-language word and T be a targetlanguage transliterat</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>A. L. Berger, S. D. Pietra, and V. J. D. Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>Journal ofMachine Learning Research,</journal>
<pages>3--951</pages>
<contexts>
<context position="1879" citStr="Crammer and Singer, 2003" startWordPosition="244" endWordPosition="247">ween the two models lies in whether or not a machine transliteration process depends on target-language phonemes. TM-G directly converts source-language graphemes into targetlanguage graphemes, while TM-GP first transforms source language graphemes into targetlanguage phonemes and then target-language phonemes coupled with their corresponding source-language graphemes are converted into target-language graphemes. We used three different machine learning algorithms (conditional random fields (CRFs), margin infused relaxed algorithm (MIRA), and maximum entropy model (MEM)) (Berger et al., 1996; Crammer and Singer, 2003; Lafferty et al., 2001) for building multiple machine transliteration engines. We attempted to improve the transliteration quality by combining the outputs of different machine transliteration engines operating on the same input. Our approach was applied to all language pairs in “NEWS 2009 Machine Transliteration Shared Task.” The official results of our approach were ranked as the best for four language pairs and the second best for three language pairs (Li et al., 2009a). 2 Transliteration Model Let S be a source-language word and T be a targetlanguage transliteration of S. T is represented</context>
<context position="4667" citStr="Crammer and Singer (2003)" startWordPosition="700" endWordPosition="703">ibed in detail in Oh et al. (2006) along with comprehensive evaluation of its performance. We used the same way as that proposed by Oh et al. (2006), thus its full description is not presented here. 3.2 Conditional Random Fields (CRFs) CRFs, a statistical sequence modeling framework, was first introduced by Lafferty et al. (2001). CRFs has been used for sequential labeling problems such as text chunking and named entity recognition (McCallum and Li, 2003). CRF++1 was used in our experiment. 3.3 Margin Infused Relaxed Algorithm The Margin Infused Relaxed Algorithm (MIRA) has been introduced by Crammer and Singer (2003) for large-margin multi-class classification. Kruengkrai et al. (2008) proposed a discriminative model for joint Chinese segmentation and POS tagging, where MIRA was used as their machine learning algorithm. We used the same model for our machine transliteration, exactly joint syllabication2 and transliteration. 3.4 Features We used the following features within the f3 context window3 for the above mentioned three ma1Available at http://crfpp.sourceforge.net/ 2A syllable in English is defined as a sequence of English grapheme corresponding to one target-language grapheme. 3The unit of context </context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>Koby Crammer and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. Journal ofMachine Learning Research, 3:951–991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Canasai Kruengkrai</author>
<author>Jun’ichi Kazama</author>
<author>Kiyotaka Uchimoto</author>
<author>Kentaro Torisawa</author>
<author>Hitoshi Isahara</author>
</authors>
<title>A discriminative hybrid model for joint Chinese word segmentation and pos tagging.</title>
<date>2008</date>
<booktitle>In Proc. of The 11th Oriental COCOSDA Workshop.</booktitle>
<contexts>
<context position="4737" citStr="Kruengkrai et al. (2008)" startWordPosition="708" endWordPosition="711">of its performance. We used the same way as that proposed by Oh et al. (2006), thus its full description is not presented here. 3.2 Conditional Random Fields (CRFs) CRFs, a statistical sequence modeling framework, was first introduced by Lafferty et al. (2001). CRFs has been used for sequential labeling problems such as text chunking and named entity recognition (McCallum and Li, 2003). CRF++1 was used in our experiment. 3.3 Margin Infused Relaxed Algorithm The Margin Infused Relaxed Algorithm (MIRA) has been introduced by Crammer and Singer (2003) for large-margin multi-class classification. Kruengkrai et al. (2008) proposed a discriminative model for joint Chinese segmentation and POS tagging, where MIRA was used as their machine learning algorithm. We used the same model for our machine transliteration, exactly joint syllabication2 and transliteration. 3.4 Features We used the following features within the f3 context window3 for the above mentioned three ma1Available at http://crfpp.sourceforge.net/ 2A syllable in English is defined as a sequence of English grapheme corresponding to one target-language grapheme. 3The unit of context window is source-language grapheme or syllable. chine learning algorit</context>
</contexts>
<marker>Kruengkrai, Kazama, Uchimoto, Torisawa, Isahara, 2008</marker>
<rawString>Canasai Kruengkrai, Jun’ichi Kazama, Kiyotaka Uchimoto, Kentaro Torisawa, and Hitoshi Isahara. 2008. A discriminative hybrid model for joint Chinese word segmentation and pos tagging. In Proc. of The 11th Oriental COCOSDA Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kumaran</author>
<author>Tobias Kellner</author>
</authors>
<title>A generic framework for machine transliteration.</title>
<date>2007</date>
<booktitle>In Proc. of SIGIR ’07,</booktitle>
<pages>721--722</pages>
<contexts>
<context position="9764" citStr="Kumaran and Kellner, 2007" startWordPosition="1520" endWordPosition="1523">ne are used as a feature. We estimated P(ref|feature(x)) by using the development data. 5 Our Results 5.1 Individual Engine CRF-G MEM-G MEM-GP MIRA-G EnCh 0.628 0.686 0.715 0.684 EnHi 0.455 0.469 0.469 0.412 EnJa 0.514 0.517 0.519 0.490 EnKa 0.386 0.380 0.380 0.338 EnKo 0.460 0.438 0.447 0.367 EnRu 0.600 0.561 0.566 0.568 EnTa 0.453 0.459 0.459 0.412 JnJk N/A 0.532 N/A 0.571 Table 2: ACC of individual engines on the test data Table 2 presents ACC4 of individual transliteration engines, which was applied to all language pairs in “NEWS 2009 Machine Transliteration Shared Task” (Li et al., 2004; Kumaran and Kellner, 2007; The CJK Dictionary Institute, 2009). CRF-G was the best transliteration engine in EnKa, EnKo, and EnRu. Owing to the high training costs of CRFs, we trained CRF-G in EnCh with a very small number of iterations5. Hence, the performance of CRF-G was poorer than that of the other engines in EnCh. MEM-GP was the best transliteration engine in EnCh, EnHi, EnJa, and EnTa. These results indicate that joint use of source language graphemes and target language phonemes were very useful for improving performance. MIRA-G was sensitive to the training data size, because it was based on joint syllabicati</context>
</contexts>
<marker>Kumaran, Kellner, 2007</marker>
<rawString>A. Kumaran and Tobias Kellner. 2007. A generic framework for machine transliteration. In Proc. of SIGIR ’07, pages 721–722.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In</title>
<date>2001</date>
<booktitle>Proc. ofICML01,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="1903" citStr="Lafferty et al., 2001" startWordPosition="248" endWordPosition="251">n whether or not a machine transliteration process depends on target-language phonemes. TM-G directly converts source-language graphemes into targetlanguage graphemes, while TM-GP first transforms source language graphemes into targetlanguage phonemes and then target-language phonemes coupled with their corresponding source-language graphemes are converted into target-language graphemes. We used three different machine learning algorithms (conditional random fields (CRFs), margin infused relaxed algorithm (MIRA), and maximum entropy model (MEM)) (Berger et al., 1996; Crammer and Singer, 2003; Lafferty et al., 2001) for building multiple machine transliteration engines. We attempted to improve the transliteration quality by combining the outputs of different machine transliteration engines operating on the same input. Our approach was applied to all language pairs in “NEWS 2009 Machine Transliteration Shared Task.” The official results of our approach were ranked as the best for four language pairs and the second best for three language pairs (Li et al., 2009a). 2 Transliteration Model Let S be a source-language word and T be a targetlanguage transliteration of S. T is represented in two ways – TG, a seq</context>
<context position="4373" citStr="Lafferty et al. (2001)" startWordPosition="654" endWordPosition="657">urce-language grapheme is tagged with its corresponding target-language grapheme. This section briefly describes the machine learning algorithms used for building multiple transliteration engines. 3.1 Maximum Entropy Model Machine transliteration based on the maximum entropy model was described in detail in Oh et al. (2006) along with comprehensive evaluation of its performance. We used the same way as that proposed by Oh et al. (2006), thus its full description is not presented here. 3.2 Conditional Random Fields (CRFs) CRFs, a statistical sequence modeling framework, was first introduced by Lafferty et al. (2001). CRFs has been used for sequential labeling problems such as text chunking and named entity recognition (McCallum and Li, 2003). CRF++1 was used in our experiment. 3.3 Margin Infused Relaxed Algorithm The Margin Infused Relaxed Algorithm (MIRA) has been introduced by Crammer and Singer (2003) for large-margin multi-class classification. Kruengkrai et al. (2008) proposed a discriminative model for joint Chinese segmentation and POS tagging, where MIRA was used as their machine learning algorithm. We used the same model for our machine transliteration, exactly joint syllabication2 and translite</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proc. ofICML01, pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haizhou Li</author>
<author>Min Zhang</author>
<author>Su Jian</author>
</authors>
<title>A joint source-channel model for machine transliteration.</title>
<date>2004</date>
<booktitle>In Proc. ofACL ’04,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="9737" citStr="Li et al., 2004" startWordPosition="1516" endWordPosition="1519">h individual engine are used as a feature. We estimated P(ref|feature(x)) by using the development data. 5 Our Results 5.1 Individual Engine CRF-G MEM-G MEM-GP MIRA-G EnCh 0.628 0.686 0.715 0.684 EnHi 0.455 0.469 0.469 0.412 EnJa 0.514 0.517 0.519 0.490 EnKa 0.386 0.380 0.380 0.338 EnKo 0.460 0.438 0.447 0.367 EnRu 0.600 0.561 0.566 0.568 EnTa 0.453 0.459 0.459 0.412 JnJk N/A 0.532 N/A 0.571 Table 2: ACC of individual engines on the test data Table 2 presents ACC4 of individual transliteration engines, which was applied to all language pairs in “NEWS 2009 Machine Transliteration Shared Task” (Li et al., 2004; Kumaran and Kellner, 2007; The CJK Dictionary Institute, 2009). CRF-G was the best transliteration engine in EnKa, EnKo, and EnRu. Owing to the high training costs of CRFs, we trained CRF-G in EnCh with a very small number of iterations5. Hence, the performance of CRF-G was poorer than that of the other engines in EnCh. MEM-GP was the best transliteration engine in EnCh, EnHi, EnJa, and EnTa. These results indicate that joint use of source language graphemes and target language phonemes were very useful for improving performance. MIRA-G was sensitive to the training data size, because it was</context>
</contexts>
<marker>Li, Zhang, Jian, 2004</marker>
<rawString>Haizhou Li, Min Zhang, and Su Jian. 2004. A joint source-channel model for machine transliteration. In Proc. ofACL ’04, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haizhou Li</author>
<author>A Kumaran</author>
<author>Vladimir Pervouchine</author>
<author>Min Zhang</author>
</authors>
<title>machine transliteration shared task.</title>
<date>2009</date>
<booktitle>In Proc. ofACL-IJCNLP 2009 Named Entities Workshop.</booktitle>
<tech>2009a. Report on NEWS</tech>
<contexts>
<context position="2355" citStr="Li et al., 2009" startWordPosition="319" endWordPosition="322">dom fields (CRFs), margin infused relaxed algorithm (MIRA), and maximum entropy model (MEM)) (Berger et al., 1996; Crammer and Singer, 2003; Lafferty et al., 2001) for building multiple machine transliteration engines. We attempted to improve the transliteration quality by combining the outputs of different machine transliteration engines operating on the same input. Our approach was applied to all language pairs in “NEWS 2009 Machine Transliteration Shared Task.” The official results of our approach were ranked as the best for four language pairs and the second best for three language pairs (Li et al., 2009a). 2 Transliteration Model Let S be a source-language word and T be a targetlanguage transliteration of S. T is represented in two ways – TG, a sequence of target-language graphemes, and TP, a sequence of target-language phonemes. Here, a target-language grapheme is defined as a target-language character. We regard consonant and vowel parts in the romanized form of a target language grapheme as a target-language phoneme. Then TM-G and TM-GP are formulated as Eq (1) and (2), respectively. En S C l i n t o n Ch TP KE L I N D U N TG 克:B 林:B 林:I 林:I *:B *:I *:I Ja TP KU R I N T O N TG ク:B リ:B リ:I</context>
<context position="7927" citStr="Li et al., 2009" startWordPosition="1210" endWordPosition="1213">le transliteration engines. Let X be a set of outputs of N transliteration engines for the same input. grank(x) re-ranks x E X in the manner shown in Eq. (4), where Ranki(x) is the position of x in the n-best list generated by the ith transliteration engine. grank(x) can be interpreted as the average rank of x over outputs of each individual engine. If x is not in the n-best list of the ith transliteration engine, 1 Ranki(x) = 0. 1 Ranki(x) (4) gFscore(x) is based on grank(x) and the Fscore measure, which is one of the evaluation metrics in the “NEWS 2009 Machine Transliteration Shared Task” (Li et al., 2009b). We considered the top three outputs of each individual engine as reference transliterations and defined them as virtual reference transliterations. We calculated the F-score measure between the virtual reference transliteration and each output of multiple transliteration engines. gFscore(x) is defined by Eq. (5), where VRef is a set of virtual reference transliterations, and Fscore(vr, x) is a function that restores the F-score measure between vr and x. gFscore(x) = grank(x) x MF(x) (5) 1 MF(x) = |V Ref| vr∈V Ref Since the F-score measure is calculated in terms of string similarity, x gets</context>
<context position="10829" citStr="Li et al., 2009" startWordPosition="1697" endWordPosition="1700">anguage phonemes were very useful for improving performance. MIRA-G was sensitive to the training data size, because it was based on joint syllabication and transliteration. Therefore, the performance of MIRA-G was relatively better in EnCh and EnJa, whose training data size is bigger than other language pairs. CRF-G could not be applied to JnJk, mainly due to too long training time. Further, MEM-GP could not be applied to JnJk, because transliteration in JnJk can be regarded as conversion of target language phonemes to target language graphemes. MEM-G and MIRA-G were 4Word accuracy in Top-1 (Li et al., 2009b) 5We applied over 100 iterations to other language pairs but only 30 iterations to EnCh. �N 1 grank(x) = 1V i=1 Fscore(vr, x) 38 applied to JnJk and MIRA-G showed the best performance in JnJK.6 graphemes and phonemes, and our multi-engine transliteration approach are effective, regardless of the nature of the language pairs. 5.2 Combining Multiple Engines grank gFscore gME I-BEST EnCh 0.730 0.731 0.731 0.715 EnHi 0.481 0.475 0.483 0.469 EnJa 0.535 0.535 0.537 0.519 EnKa 0.393 0.399 0.398 0.386 EnKo 0.461 0.444 0.473 0.460 EnRu 0.602 0.605 0.600 0.600 EnTa 0.470 0.478 0.474 0.459 JnJk 0.597 0</context>
</contexts>
<marker>Li, Kumaran, Pervouchine, Zhang, 2009</marker>
<rawString>Haizhou Li, A Kumaran, Vladimir Pervouchine, and Min Zhang. 2009a. Report on NEWS 2009 machine transliteration shared task. In Proc. ofACL-IJCNLP 2009 Named Entities Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haizhou Li</author>
<author>A Kumaran</author>
<author>Min Zhang</author>
<author>Vladimir Pervouchine</author>
</authors>
<title>machine transliteration shared task.</title>
<date>2009</date>
<journal>Whitepaper of NEWS</journal>
<booktitle>In Proc. of ACL-IJCNLP 2009 Named Entities Workshop.</booktitle>
<contexts>
<context position="2355" citStr="Li et al., 2009" startWordPosition="319" endWordPosition="322">dom fields (CRFs), margin infused relaxed algorithm (MIRA), and maximum entropy model (MEM)) (Berger et al., 1996; Crammer and Singer, 2003; Lafferty et al., 2001) for building multiple machine transliteration engines. We attempted to improve the transliteration quality by combining the outputs of different machine transliteration engines operating on the same input. Our approach was applied to all language pairs in “NEWS 2009 Machine Transliteration Shared Task.” The official results of our approach were ranked as the best for four language pairs and the second best for three language pairs (Li et al., 2009a). 2 Transliteration Model Let S be a source-language word and T be a targetlanguage transliteration of S. T is represented in two ways – TG, a sequence of target-language graphemes, and TP, a sequence of target-language phonemes. Here, a target-language grapheme is defined as a target-language character. We regard consonant and vowel parts in the romanized form of a target language grapheme as a target-language phoneme. Then TM-G and TM-GP are formulated as Eq (1) and (2), respectively. En S C l i n t o n Ch TP KE L I N D U N TG 克:B 林:B 林:I 林:I *:B *:I *:I Ja TP KU R I N T O N TG ク:B リ:B リ:I</context>
<context position="7927" citStr="Li et al., 2009" startWordPosition="1210" endWordPosition="1213">le transliteration engines. Let X be a set of outputs of N transliteration engines for the same input. grank(x) re-ranks x E X in the manner shown in Eq. (4), where Ranki(x) is the position of x in the n-best list generated by the ith transliteration engine. grank(x) can be interpreted as the average rank of x over outputs of each individual engine. If x is not in the n-best list of the ith transliteration engine, 1 Ranki(x) = 0. 1 Ranki(x) (4) gFscore(x) is based on grank(x) and the Fscore measure, which is one of the evaluation metrics in the “NEWS 2009 Machine Transliteration Shared Task” (Li et al., 2009b). We considered the top three outputs of each individual engine as reference transliterations and defined them as virtual reference transliterations. We calculated the F-score measure between the virtual reference transliteration and each output of multiple transliteration engines. gFscore(x) is defined by Eq. (5), where VRef is a set of virtual reference transliterations, and Fscore(vr, x) is a function that restores the F-score measure between vr and x. gFscore(x) = grank(x) x MF(x) (5) 1 MF(x) = |V Ref| vr∈V Ref Since the F-score measure is calculated in terms of string similarity, x gets</context>
<context position="10829" citStr="Li et al., 2009" startWordPosition="1697" endWordPosition="1700">anguage phonemes were very useful for improving performance. MIRA-G was sensitive to the training data size, because it was based on joint syllabication and transliteration. Therefore, the performance of MIRA-G was relatively better in EnCh and EnJa, whose training data size is bigger than other language pairs. CRF-G could not be applied to JnJk, mainly due to too long training time. Further, MEM-GP could not be applied to JnJk, because transliteration in JnJk can be regarded as conversion of target language phonemes to target language graphemes. MEM-G and MIRA-G were 4Word accuracy in Top-1 (Li et al., 2009b) 5We applied over 100 iterations to other language pairs but only 30 iterations to EnCh. �N 1 grank(x) = 1V i=1 Fscore(vr, x) 38 applied to JnJk and MIRA-G showed the best performance in JnJK.6 graphemes and phonemes, and our multi-engine transliteration approach are effective, regardless of the nature of the language pairs. 5.2 Combining Multiple Engines grank gFscore gME I-BEST EnCh 0.730 0.731 0.731 0.715 EnHi 0.481 0.475 0.483 0.469 EnJa 0.535 0.535 0.537 0.519 EnKa 0.393 0.399 0.398 0.386 EnKo 0.461 0.444 0.473 0.460 EnRu 0.602 0.605 0.600 0.600 EnTa 0.470 0.478 0.474 0.459 JnJk 0.597 0</context>
</contexts>
<marker>Li, Kumaran, Zhang, Pervouchine, 2009</marker>
<rawString>Haizhou Li, A Kumaran, Min Zhang, and Vladimir Pervouchine. 2009b. Whitepaper of NEWS 2009 machine transliteration shared task. In Proc. of ACL-IJCNLP 2009 Named Entities Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Wei Li</author>
</authors>
<title>Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons.</title>
<date>2003</date>
<booktitle>In Proc. of CoNLL ’03,</booktitle>
<pages>188--191</pages>
<contexts>
<context position="4501" citStr="McCallum and Li, 2003" startWordPosition="675" endWordPosition="678">rning algorithms used for building multiple transliteration engines. 3.1 Maximum Entropy Model Machine transliteration based on the maximum entropy model was described in detail in Oh et al. (2006) along with comprehensive evaluation of its performance. We used the same way as that proposed by Oh et al. (2006), thus its full description is not presented here. 3.2 Conditional Random Fields (CRFs) CRFs, a statistical sequence modeling framework, was first introduced by Lafferty et al. (2001). CRFs has been used for sequential labeling problems such as text chunking and named entity recognition (McCallum and Li, 2003). CRF++1 was used in our experiment. 3.3 Margin Infused Relaxed Algorithm The Margin Infused Relaxed Algorithm (MIRA) has been introduced by Crammer and Singer (2003) for large-margin multi-class classification. Kruengkrai et al. (2008) proposed a discriminative model for joint Chinese segmentation and POS tagging, where MIRA was used as their machine learning algorithm. We used the same model for our machine transliteration, exactly joint syllabication2 and transliteration. 3.4 Features We used the following features within the f3 context window3 for the above mentioned three ma1Available at </context>
</contexts>
<marker>McCallum, Li, 2003</marker>
<rawString>Andrew McCallum and Wei Li. 2003. Early results for named entity recognition with conditional random fields, feature induction and web-enhanced lexicons. In Proc. of CoNLL ’03, pages 188–191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jong-Hoon Oh</author>
<author>Hitoshi Isahara</author>
</authors>
<title>Machine transliteration using multiple transliteration engines and hypothesis re-ranking.</title>
<date>2007</date>
<booktitle>In Proc. of the 11th Machine Translation Summit,</booktitle>
<pages>353--360</pages>
<contexts>
<context position="6948" citStr="Oh and Isahara, 2007" startWordPosition="1032" endWordPosition="1035">oduces 30-best transliterations for a given source-language word. Source-language transliteration unit Grapheme Syllable TM-G ME-G, CRF-G MIRA-G TM-GP ME-GP N/A Table 1: Design strategy for multiple transliteration engines 4.2 Combining Methodology We combined the outputs of multiple transliteration engines by means of a re-ranking function, g(x). Let X be a set of transliterations generated by multiple transliteration engines for sourcelanguage word s and ref be a reference transliteration of s. A re-ranking function is defined as Eq. (3), where it ranks ref in X higher and the others lower (Oh and Isahara, 2007). g(x) : X → {r : r is ordering of x E X} (3) We designed two types of re-ranking functions by using the rank of each individual engine and machine learning algorithm. 37 4.2.1 Re-ranking Based on the Rank of Individual Engines Two re-ranking functions based on the rank of each individual engine, grank and gFscore(x), are used for combining the outputs of multiple transliteration engines. Let X be a set of outputs of N transliteration engines for the same input. grank(x) re-ranks x E X in the manner shown in Eq. (4), where Ranki(x) is the position of x in the n-best list generated by the ith t</context>
</contexts>
<marker>Oh, Isahara, 2007</marker>
<rawString>Jong-Hoon Oh and Hitoshi Isahara. 2007. Machine transliteration using multiple transliteration engines and hypothesis re-ranking. In Proc. of the 11th Machine Translation Summit, pages 353–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jong-Hoon Oh</author>
<author>Key-Sun Choi</author>
<author>Hitoshi Isahara</author>
</authors>
<title>A comparison of different machine transliteration models.</title>
<date>2006</date>
<journal>Journal of Artificial Intelligence Research (JAIR),</journal>
<pages>27--119</pages>
<contexts>
<context position="4076" citStr="Oh et al. (2006)" startWordPosition="606" endWordPosition="609">raphemes are represented in terms of the BIO notation. This makes it easier to represent manyto-one correspondence between target language phoneme and grapheme. 3 Machine Learning Algorithms A machine transliteration problem can be converted into a sequential labeling problem, where each source-language grapheme is tagged with its corresponding target-language grapheme. This section briefly describes the machine learning algorithms used for building multiple transliteration engines. 3.1 Maximum Entropy Model Machine transliteration based on the maximum entropy model was described in detail in Oh et al. (2006) along with comprehensive evaluation of its performance. We used the same way as that proposed by Oh et al. (2006), thus its full description is not presented here. 3.2 Conditional Random Fields (CRFs) CRFs, a statistical sequence modeling framework, was first introduced by Lafferty et al. (2001). CRFs has been used for sequential labeling problems such as text chunking and named entity recognition (McCallum and Li, 2003). CRF++1 was used in our experiment. 3.3 Margin Infused Relaxed Algorithm The Margin Infused Relaxed Algorithm (MIRA) has been introduced by Crammer and Singer (2003) for larg</context>
</contexts>
<marker>Oh, Choi, Isahara, 2006</marker>
<rawString>Jong-Hoon Oh, Key-Sun Choi, and Hitoshi Isahara. 2006. A comparison of different machine transliteration models. Journal of Artificial Intelligence Research (JAIR), 27:119–151.</rawString>
</citation>
<citation valid="true">
<title>The CJK Dictionary Institute.</title>
<date>2009</date>
<note>http://www. cjk.org.</note>
<marker>2009</marker>
<rawString>The CJK Dictionary Institute. 2009. http://www. cjk.org.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>