<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.9994365">
Modeling Vocal Interaction for Text-Independent
Participant Characterization in Multi-Party Conversation
</title>
<author confidence="0.944733">
Kornel Laskowski
</author>
<affiliation confidence="0.843474666666667">
Cognitive Systems Labs
Universit¨at Karlsruhe
Karlsruhe, Germany
</affiliation>
<email confidence="0.976773">
kornel@ira.uka.de
</email>
<author confidence="0.99181">
Mari Ostendorf
</author>
<affiliation confidence="0.9981535">
Dept. of Electrical Engineering
University of Washington
</affiliation>
<address confidence="0.77795">
Seattle WA, USA
</address>
<email confidence="0.998001">
mo@ee.washington.edu
</email>
<note confidence="0.572725">
Tanja Schultz
</note>
<title confidence="0.284398">
Cognitive Systems Labs
</title>
<author confidence="0.593959">
Universit¨at Karlsruhe
</author>
<affiliation confidence="0.655229">
Karlsruhe, Germany
</affiliation>
<email confidence="0.984739">
tanja@ira.uka.de
</email>
<sectionHeader confidence="0.996515" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999813428571429">
An important task in automatic conversation
understanding is the inference of social struc-
ture governing participant behavior. We ex-
plore the dependence between several social
dimensions, including assigned role, gender,
and seniority, and a set of low-level features
descriptive of talkspurt deployment in a mul-
tiparticipant context. Experiments conducted
on two large, publicly available meeting cor-
pora suggest that our features are quite useful
in predicting these dimensions, excepting gen-
der. The classification experiments we present
exhibit a relative error rate reduction of 37% to
67% compared to choosing the majority class.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999979076923077">
An important task in automatic conversation under-
standing is the inference of social structure govern-
ing participant behavior; in many conversations, the
maintenance or expression of that structure is an
implicit goal, and may be more important than the
propositional content of what is said.
There are many social dimensions along which
participants may differ (Berger, Rosenholtz and
Zelditch, 1980). Research in social psychology has
shown that such differences among participants en-
tail systematic differences in observed turn-taking
and floor-control patterns (e.g. (Bales, 1950), (Tan-
nen, 1996), (Carletta, Garrod and Fraser-Krauss,
1998)), and that participant types are not indepen-
dent of the types and sizes of conversations in which
they appear. In the present work, we consider the
dimensions of assigned role, gender, and senior-
ity level. We explore the predictability of these
dimensions from a set of low-level speech activ-
ity features, namely the probabilities of initiating
and continuing talkspurts in specific multipartici-
pant contexts, estimated from entire conversations.
For our purposes, talkspurts (Norwine and Murphy,
1938) are contiguous intervals of speech, with in-
ternal pauses no longer than 0.3 seconds. Features
derived from talkspurts are not only easier to com-
pute than higher-level lexical, prosodic, or dialogue
act features, they are also applicable to scenarios in
which only privacy-sensitive data (Wyatt et al, 2007)
is available. At the current time, relatively little is
known about the predictive power of talkspurt tim-
ing in the context of large multi-party corpora.
As stated, our primary goal is to quantify the de-
pendence between specific types of speech activity
features and specific social dimensions; however,
doing so offers several additional benefits. Most
importantly, the existence of significant dependence
would suggest that multiparticipant speech activity
detectors (Laskowski, F¨ugen and Schultz, 2007) re-
lying on models conditioned on such attributes may
outperform those relying on general models. Fur-
thermore, conversational dialogue systems deployed
in multi-party scenarios may be perceived as more
human-like, by humans, if their talkspurt deploy-
ment strategies are tailored to the personalities they
are designed to embody.
Computational work which is most similar to that
presented here includes the inference of static dom-
inance (Rienks and Heylen, 2005) and influence
(Rienks et al., 2006) rankings. In that work, the au-
thors employed several speech activity features dif-
fering from ours in temporal scale and normaliza-
</bodyText>
<page confidence="0.963948">
148
</page>
<note confidence="0.8700915">
Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 148–155,
Columbus, June 2008. c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.999943291666667">
tion. Notably, their features are not probabilities
which are directly employable in a speech activity
detection system. In addition, several higher-level
features were included, such as topic changes, par-
ticipant roles, and rates of phenomena such as turns
and interruptions, and these were shown to yield the
most robust performance. Our aim is also similar
to that in (Vinciarelli, 2007) on radio shows, where
the proposed approach relies on the relatively fixed
temporal structure of production broadcasts, a prop-
erty which is absent in spontaneous conversation.
Although (Vinciarelli, 2007) also performs single-
channel speaker diarization, he does not explore be-
havior during vocalization overlap.
Aside from the above, the focus of the major-
ity of existing research characterizing participants
is the detection of dynamic rather than static roles
(i.e. (Banerjee and Rudnicky, 2004), (Zancanaro et
al, 2006), (Rienks et al., 2006)). From a mathe-
matical perspective, the research presented here is
a continuation of our earlier work on meeting types
(Laskowski, Ostendorf and Schultz, 2007), and we
rely on much of that material in the presentation
which follows.
</bodyText>
<sectionHeader confidence="0.895387" genericHeader="introduction">
2 Characterizing Participants
</sectionHeader>
<bodyText confidence="0.9958844">
Importantly, we characterize participants in entire
groups, rather than characterizing each participant
independently. Doing so allows us to apply con-
straints on the group as a whole, eliminating the
need for hypothesis recombination (in the event that
more than one participant is assigned a role which
was meant to be unique). Additionally, treating
groups holistically allows for modeling the interac-
tions between specific pairs of participant types.
For each conversation or meeting1 of K partici-
pants, we compute a feature vector F, in which all
one-participant and two-participant speech activity
features are found in a particular order, typically im-
posed by microphone channel or seating assignment
(the specific features are described in Section 4).
The goal is to find the most likely group assignment
of participant labels that account for the observed
F. In (Laskowski, Ostendorf and Schultz, 2007), it
was shown that meeting types in a large meeting cor-
1“Conversation” and “meeting” will be used interchange-
ably in the current work.
pus can be successfully inferred from F using this
approach; here, we employ the same framework to
classify participant types in the K-length vector g,
for the group as a whole:
</bodyText>
<equation confidence="0.9859322">
g* = arg max
9 E 9
P (F|g )
 |{z }
BM
</equation>
<bodyText confidence="0.999978888888889">
where MM and BM are the membership and behav-
ior models, respectively, and !g is the set of all pos-
sible assignments of g.
In the remainder of this section, we define the
participant characteristics we explore, which include
assigned role, gender, and seniority. We treat these
as separate tasks, applying the same classification
framework. We also show how our definitions pro-
vide search space constraints on Equation 1.
</bodyText>
<subsectionHeader confidence="0.99967">
2.1 Conversations with Unique Roles
</subsectionHeader>
<bodyText confidence="0.999818230769231">
Given a meeting of K participants, we consider a set
of roles R = {R1, R2, · · · , RK} and assign to each
participant k, 1&lt;k&lt;K, exactly one role in R. An
example group assignment is the vector r1 of length
K, where r1 [k] = Rk. The set R of group assign-
ment alternatives r E R is given by permutations
α : R H R, where α E SK, the symmetric group on
K symbols2. The number of elements in R is iden-
tically the number of unique permutations in SK, a
quantity known as its order |SK |= K!.
To identify the most likely group assignment r* =
α* (r1) given the set F of observables, we iterate
over the K! elements ofSK using
</bodyText>
<equation confidence="0.9743175">
α* = arg max P (F|α (r1)) , (2)
α ESx
</equation>
<bodyText confidence="0.998830666666667">
where we have elided the prior P ( α) assuming that
it is uniform. Following the application of Equa-
tion 2, the most likely role of participant k is given
by α* (r1) [k].
Alternately, we may be interested in identifying
only a subset of the roles in R, namely a leader, or
a manager. In this case, participant roles are drawn
from L = {L, -,L}, under the constraint that exactly
one participant is assigned the role L. The setLof
</bodyText>
<footnote confidence="0.990636">
2For an overview of group theoretic notions and notation,
we refer the reader to (Rotman, 1995).
</footnote>
<equation confidence="0.996051714285714">
= arg max
9 E 9
P (g |F)
P ( g )
 |{z }
MM
, (1)
</equation>
<page confidence="0.994714">
149
</page>
<bodyText confidence="0.99878175">
alternative group assignments has K indicator vec-
tor members lj, 1≤j≤K, where lj [k] is L for k = j
and ¬L otherwise.3 We iterate over the indicator
vectors to obtain
</bodyText>
<equation confidence="0.9940405">
j* = arg max P ( F|lj ) , (3)
jE{1,···,K}
</equation>
<bodyText confidence="0.99605525">
assuming uniform priors P ( lj ). Following the ap-
plication of Equation 3, j* is the index of the most
likely L participant.
We note that this framework for unique role clas-
sification is applicable to classifying unique ranks,
without first having to collapse them into non-
unique rank classes as was necessary in (Rienks et
al., 2006).
</bodyText>
<subsectionHeader confidence="0.999883">
2.2 Conversations with Non-Unique Roles
</subsectionHeader>
<bodyText confidence="0.9999935">
The second type of inference we consider is for di-
mensions in which roles are not unique, i.e. where
participants are in principle drawn independently
from a set of alternatives. This naturally includes
dimensions such as gender, seniority, age, etc.
As an example, we treat the case of gender. Par-
ticipant genders are drawn independently from H =
{�, d}. The set of group assignment alternatives h
is given by the Cartesian product HK, of 2K unique
elements. We search for the most likely group as-
signment h*, given the observables F, by iterating
over these elements using
</bodyText>
<equation confidence="0.986654">
h* = arg max P (h) P ( F|h) . (4)
hEWK
</equation>
<bodyText confidence="0.991218">
Once h* is found, the gender of each participant k is
available in h* [k].
A similar scenario is found for seniority, when
it is not uniquely ranked. We assume a set of
NS mutually exclusive seniority levels Si ∈ S =
{S1, S2, · · · , SNS}, 1≤i≤NS. During search, each
participant’s seniority level is drawn independently
from S, leading to group assignments s ∈ SK, of
which there are NKS . As for gender, we iterate over
these to find
</bodyText>
<equation confidence="0.9816175">
s* = arg max P ( s) P (F|s) . (5)
sESK
</equation>
<bodyText confidence="0.821848">
The seniority of participant k, following the applica-
tion of Equation 5, is s* [k].
3For completeness, we note that each 1j corresponds to a
permutation Q :L →Lof 11, and that Q E (T), the cyclic sub-
group generated by T, where T is the permutation (1, 2, · · · , K).
</bodyText>
<sectionHeader confidence="0.987802" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.999983096774194">
In the current work, we use two different corpora of
multi-party meetings. The first, the scenario subset
of the AMI Meeting Corpus (Carletta, 2007), con-
sists of meetings involving K = 4 participants who
play different specialist roles in a product design
team. We have observed the recommended division
of this data into: AMITRAINSET of 98 meetings;
AMIDEVSET of 20 meetings; and AMIEVALSET,
also of 20 meetings. Although each participant takes
part in approximately 4 meetings, the 3 sets are dis-
joint in participants. We use only the provided word
alignments of these meetings. The corpus is accom-
panied by metadata which specifies the gender and
assigned role of each participant.
The second corpus consists of the Bed, Bmr,
and Bro meeting types in the ICSI Meeting Cor-
pus (Janin et al., 2003). Each meeting is identified
by one of {Bed, Bmr, Bro}, as well as a numerical
identifier d. We have divided these meetings into:
ICSITRAINSET, consisting of the 33 meetings for
which d mod 4 ∈ {1, 2}; ICSIDEVSET, consist-
ing of the 18 meetings for which d mod 4 ≡ 3;
and ICSIEVALSET, consisting of the 16 meetings for
which d mod 4 ≡ 0. These three sets are not dis-
joint in participants, and the number of instrumented
participants K varies from meeting to meeting, be-
tween 3 and 9. The corpus is accompanied by meta-
data specifying the gender, age, and education level
of each participant. We use only the forced align-
ments of these meetings, available in the accompa-
nying MRDA Corpus (Shriberg et al, 2004).
</bodyText>
<sectionHeader confidence="0.999274" genericHeader="method">
4 Features
</sectionHeader>
<bodyText confidence="0.999066727272727">
Our observation space is the complete K-participant
vocal interaction on-off pattern description for a
meeting C, a discretized version of which we denote
as qt ∈ {0,1}K for 1≤t≤T, where T is the dura-
tion of C in terms of the number of 100 ms frames.
Details regarding the discretization (and subsequent
feature computation) can be found in (Laskowski,
Ostendorf and Schultz, 2007).
We compute from qt the following features4
which are the elements of F: f� I
� , the probabil-
</bodyText>
<footnote confidence="0.801606">
4Feature type superscripts indicate talkspurt initiation (I) or
continuation (G), for either single-participant vocalization (V)
or vocalization overlap (O).
</footnote>
<page confidence="0.995497">
150
</page>
<bodyText confidence="0.998729388888889">
ity that participant k initiates vocalization at time t
when no-one else was speaking at t − 1; fV C
k , the
probability that participant k continues vocalization
at time t when no-one else was speaking at t − 1;
fOI
k,j , the probability that participant k initiates vo-
calization at time t when participant j was speaking
at t − 1; and fOC
k,j the probability that participant k
continues vocalization at time t when participant j
was speaking at t − 1. Values of the features, which
are time-independent probabilities, are estimated us-
ing a variant of the Ising model (cf. (Laskowski, Os-
tendorf and Schultz, 2007)). Additionally, we com-
pute a feature fVk , the probability that participant
k vocalizes at time t, and single-participant aver-
ages of the two-participant features: (fOI
</bodyText>
<equation confidence="0.83378125">
k,j �j, (fOI
j,k )j,
(fOC
k,j �j, and (fOC
</equation>
<figureCaption confidence="0.5933745">
j,k �j. The complete feature vector
for a conversation of K participants then consists of
7K one-participant features, and 2(K2 − K) two-
participant features.
</figureCaption>
<bodyText confidence="0.999241">
We note that multiple phenomena contribute to
the overlap features. The features fOI
k,j are based
on counts from interruptions, backchannels, and pre-
cise floor handoffs. The features fOC
k,j are based on
counts from interruptions, attempts to hold the floor,
and backchannels. Both feature types also contain
counts incurred during schism, when the conversa-
tion splits into two sub-conversations.
</bodyText>
<sectionHeader confidence="0.996598" genericHeader="method">
5 Models
</sectionHeader>
<bodyText confidence="0.999992928571429">
Since K may change from meeting to meeting, the
size of the feature vector F must be considered vari-
able. We therefore factor the behavior model, as-
suming that all features are mutually independent
and that each is described by its own univariate
Gaussian model N (µ,Q2). These parameters are
maximum likelihood estimates from the fk and fk,j
values in a training set of conversations. In most of
these experiments, where the number of classes is
small, no parameter smoothing is needed.
For the cases where the group prior is not uniform
and participant types are not unique, the member-
ship model assumes independent participant types
and has the general form
</bodyText>
<equation confidence="0.978216">
K
P (g ) = H P (g [k]) , (6)
k=1
</equation>
<bodyText confidence="0.9991794">
where P (g [k] ) is the probability that the k-th par-
ticipant is type g [k]. This model is used for gen-
der (P(h)) and seniority (P(s)). The probabilities
of specific types are maximum likelihood estimates
from the training data.
</bodyText>
<sectionHeader confidence="0.994975" genericHeader="method">
6 Assigned Role Classification
</sectionHeader>
<subsectionHeader confidence="0.999799">
6.1 Classifying Unique Roles
</subsectionHeader>
<bodyText confidence="0.999077564102564">
For unique role classification, we use the AMI Meet-
ing Corpus. All meetings consist of K = 4 par-
ticipants, and each participant is assigned one of
four roles: project manager (PM), marketing expert
(ME), user interface designer (UI), or industrial de-
signer (ID).
As mentioned in Section 2.1, classifying the
unique role of all participants, jointly, involves
enumerating over the possible permutations of
{PM, ME, UI, ID}. We use AMITRAINSET to train
the behavior model, and then classify AMIDEVSET
using Equation 2, one feature type at a time, to iden-
tify the best 3 feature types for this task; develop-
ment experiments suggest that classification rates
level off after a small handful of the best perform-
ing feature types is included. Those feature types
were found to be fV I
k , (fOI
k,j )j, and fOI
k,j , capturing
the probability of initiating a talkspurt in silence, of
initiating a talkspurt when someone else is speak-
ing, and of initiating a talkspurt when a participant
in a specific other role is speaking, respectively. On
AMIEVALSET, these feature types lead to single-
feature-type 4-way classification rates of 41%, 29%,
and 53%, respectively. When all three types are used
together (3K+K2 features in total), the rate is 53%.
Accuracy when all feature types are used is 46%, in-
dicating that some feature types are detrimental to
this task.
The confusion matrix for classification using the
three best feature types is shown in Table 1. The
matrix shows that association between the reference
assignment of PM, as well as of UI, and the hypoth-
esized assignment based on the three feature types
mentioned is statistically significant. On the other
hand, assignment of ID and ME does not deviate
significantly from chance.
</bodyText>
<subsectionHeader confidence="0.998605">
6.2 Finding the Manager
</subsectionHeader>
<bodyText confidence="0.958774">
Using the same data as above, we explore the sim-
plified task of finding a specific participant type. We
</bodyText>
<page confidence="0.981494">
151
</page>
<table confidence="0.998491285714286">
feature fOI
Ref Hyp
ID ME PM UI
ID 8 6 4 2
ME 5 8 4 3
PM 3 4 ++12 − 1
UI 4 2 −− 0 ++14
</table>
<tableCaption confidence="0.820431333333333">
Table 1: Confusion matrix for role classification on
AMIEVALSET; reference assignment is found in the rows,
hypothesized assignment in columns. Correctly classified
</tableCaption>
<bodyText confidence="0.910264976744186">
roles, along the diagonal, are highlighted in bold. Statis-
tical significance of association at the p &lt; 0.005 level
per class, using a 2x2 x2-test, is shown using “++” and
“−−”, for above chance and below chance values, re-
spectively; the same is true of “+” and “−”, for signifi-
cance at the 0.005 &lt; p &lt; 0.05 level.
equate the project manager role with L, and the re-
maining roles with -,L. This is justified by the AMI
meeting scenario, in which participant groups take a
product design from start to prototype, and in which
the project manager is expected to make the group
run smoothly.
The behavior model, trained on AMITRAINSET,
is applied using Equation 3 to determine the most
likely index j* of the leader L, given the observed
F, from among the K = 4 alternatives. To select
the best 3 feature types, we once again use AMIDE-
VSET; these turn out to be the same as those for role
OI)
classification, namely fkI, (f ,j j, and fOI. Using
k,j
these three feature types individually, we are able
to identify the leader PM in 12 of the 20 meetings
in AMIEVALSET. When all three are used together,
the identification rate is 60%. However, when all
feature types are used, the identification rate climbs
to 75%. Since all participants are equally likely to
be the leader, the baseline for comparison is random
guessing (25% accuracy).
Figure 1 shows the distribution of two of the se-
lected features, fV I
k and fOI
k,j , for the data in AMI-
TRAINSET; we also show the first standard de-
viation of the single-Gaussian diagonal-covariance
models induced. We first note that fV I
k and fOI
k,j
are correlated, i.e. that the probability of beginning
a talkspurt in silence is correlated with the proba-
bility of beginning a talkspurt when someone else
is speaking. L consistently begins more talkspurts,
both in silence and during other people’s speech. It
</bodyText>
<figure confidence="0.993548615384615">
0.025
(¬L,¬L)
(¬L,L)
(L,¬L)
0.02
0.015
(¬L,¬L)
0.01
0.005
(¬L,L)
0
0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04
feature fVI
</figure>
<figureCaption confidence="0.999998">
Figure 1: Distribution of (fV I
</figureCaption>
<bodyText confidence="0.985102666666667">
k , fOI
k,j ) pairs for each of
(-,L, -,L),(-,L, L), and (L, -,L). Ellipses are centered
on AMITRAINSET means and encompass one standard
deviation.
is also interesting that -,L is slightly less likely to
initiate a talkspurt when L is already speaking than
when another -,L is. This suggests that -,L partic-
ipants consistently observe the L-status of the al-
ready speaking party when contemplating talkspurt
production. Finally, we note that neither the proba-
bility of continuing a talkspurt fV C
k (related to talk-
spurt duration) nor fVk (related to overall amount of
talk) are by themselves good L/-,L discriminators.
</bodyText>
<sectionHeader confidence="0.994979" genericHeader="method">
7 Gender Classification
</sectionHeader>
<bodyText confidence="0.989484222222222">
Gender classification is an example of a task with a
Cartesian search space. For these experiments, we
use the AMI Meeting Corpus and the ICSI Meet-
ing Corpus. In both corpora, gender is encoded in
the first letter of each participant’s unique identifier.
The ratio of male to female occurrences is 2 : 1
in AMITRAINSET, and 4 : 1 in ICSITRAINSET.
Choosing the majority class leads to gender classi-
fication rates of 65% and 81% on AMIEVALSET and
ICSIEVALSET, respectively.
We enumerate alternative group assignments us-
ing Equation 4. Somewhat surprisingly, no single
feature type leads to AMIEVALSET or ICSIEVALSET
classification rates higher than those obtained by hy-
pothesizing all participants to be male. On AMIDE-
VSET, one feature type (fk,j
O) yields negligibly bet-
ter accuracy, but does not generalize to the corre-
</bodyText>
<equation confidence="0.458329">
(L,¬L)
</equation>
<page confidence="0.988177">
152
</page>
<bodyText confidence="0.999984444444444">
sponding evaluation data. Furthermore, the associ-
ation between reference gender labels and hypothe-
sized gender labels, on both evaluation sets, does not
appear to be statistically significant at the p &lt; 0.05
level. This finding that males and females do not
differ significantly in their deployment of talkspurts
is likely a consequence of the social structure of the
particular groups studied. The fact that AMI roles
are acted may also have an effect.
</bodyText>
<sectionHeader confidence="0.907616" genericHeader="method">
8 Seniority Classification
</sectionHeader>
<bodyText confidence="0.999878">
As a second example of non-unique roles, we at-
tempt to classify participant seniority. For these
experiments, we use the ICSI Meeting corpus, in
which each participant’s education level appears as
an optional, self-reported attribute. We have man-
ually clustered these attributes into NS = 3 mu-
tually exclusive seniority categories.5 Each partic-
ipant’s seniority is drawn independently from S =
{GRAD, PHD, PROF}; a breakdown for ICSITRAIN-
SET is shown in Table 2. Choosing the majority
class (P (PHD) = 0.444 on ICSITRAINSET) yields
a classification accuracy of 45% on ICSIEVALSET.
We note that in this data, education level is closely
correlated with age group.
</bodyText>
<table confidence="0.9915995">
Seniority Number of
spkrs occur meets
GRAD 15 81 33
PHD 13 87 29
PROF 3 28 28
all 31 196 33
</table>
<tableCaption confidence="0.995841">
Table 2: Breakdown by seniority S in ICSITRAINSET by
</tableCaption>
<bodyText confidence="0.673747666666667">
the number of unique participants (spkrs), the number of
occurrences (occur), and the number of meetings (meets)
in which each seniority occurs.
</bodyText>
<subsectionHeader confidence="0.938547">
8.1 Classifying Participant Types
Independently of Conversation Types
</subsectionHeader>
<bodyText confidence="0.999560333333333">
We first treat the problem of classifying participant
seniority levels independently of the type of conver-
sation being studied. We identify the most likely se-
</bodyText>
<footnote confidence="0.52234025">
5GRAD includes “Grad”, as well as “Undergrad”,
“B.A.”, and “Finished BA in 2001”, due to their small
number of exemplars; PHD includes “PhD” and “Postdoc”;
and PROF includes “Professor” only.
</footnote>
<bodyText confidence="0.9993078">
niority assignment for all participants using Equa-
tion 5. The best three feature types, determined
using ICSIDEVSET, are fk , fOI
��� , and fOC
��� (repre-
senting the probability of speaking, of beginning a
talkspurt when a specific seniority participant is al-
ready speaking, and of continuing a talkspurt when
a specific seniority participant is speaking), yield-
ing single-feature-type classification rates of 52%,
59%, and 59%, respectively. When used together,
these three feature types produce the confusion ma-
trix shown in Table 3 and a rate of 61%, better than
when all feature types are used (58%). This rep-
resents a 28% relative error reduction over chance.
As can be seen in the table, association between the
reference and hypothesized seniority assignments is
statistically significant on unseen data. It is also
evident that confusion between GRAD and PROF is
lower than between more proximate seniority levels.
</bodyText>
<table confidence="0.998664">
Ref Hyp
GRAD PHD PROF
GRAD ++11 26 3
PHD − 2 ++41 − 3
PROF 0 −− 6 ++10
</table>
<tableCaption confidence="0.98152975">
Table 3: Confusion matrix for seniority classification on
ICSIEVALSET; reference assignment is found in the rows,
hypothesized assignment in columns. Highlighting and
use of “++”, “+”, “−”, and “−−” as in Table 1.
</tableCaption>
<figureCaption confidence="0.749322">
Figure 2 shows the distribution of (fk , fOC
</figureCaption>
<bodyText confidence="0.998737210526316">
��� )
pairs in ICSITRAINSET, together with the first stan-
dard deviation, for each combination of the al-
ready speaking seniority participant and the senior-
ity participant initiating a new talkspurt (except for
(PROF, PROF), since there is at most one PROF in
each ICSITRAINSET meeting).
As is clear from the figure, PROF participants in
this data talk more than either of the two other se-
niority types. The figure also demonstrates a differ-
ence of behavior during speech overlap. The four
ellipses describing GRAD behavior when overlap-
ping with any of the other three classes, as well as
PHD behavior when overlapping with GRAD partic-
ipants, are relatively broad and indicate the absence
of strong tendency or preference. However, PHD
participants are more likely to continue vocalizing in
overlap with other PHD participants, and even more
likely to continue through overlap with PROF partic-
</bodyText>
<page confidence="0.993674">
153
</page>
<figure confidence="0.887531">
feature fOC
feature fV
</figure>
<figureCaption confidence="0.999443">
Figure 2: Distribution of (fl , f O°) feature value pairs
</figureCaption>
<equation confidence="0.536950333333333">
kj
for each of the (k, j) participant pairs (GRAD, GRAD),
(GRAD, PHD), (GRAD, PROF), (PHD, GRAD),
</equation>
<bodyText confidence="0.945719">
(PHD, PHD), (PHD, PROF), (PROF, GRAD), and
(PROF, PHD). Ellipses are centered on ICSITRAIN-
SET means and encompass one standard deviation.
ipants. A similar trend is apparent for PROF partici-
pants: the mean likelihood that they continue vocal-
izing in overlap with GRAD participants lies below
p − Q (bottom 17%) of their model with PHD partic-
ipants. We believe that the senior researchers in this
data are consciously minimizing their overlap with
students, who talk less, to make it easier for the lat-
ter to speak up.
</bodyText>
<subsectionHeader confidence="0.999011">
8.2 Conditioning on Conversation Type
</subsectionHeader>
<bodyText confidence="0.999978333333333">
We now repeat the experiments in the previous sec-
tion, but condition the behavior and membership
models on meeting type t:
</bodyText>
<equation confidence="0.913021666666667">
�
s� = arg max P ( t) P ( s|t)
SESK tET P (F|s, t) , (7)
</equation>
<bodyText confidence="0.9994631">
where t E T = {Bed, Bmr, Bro}.
Performance using maximum likelihood esti-
mates for the behavior model P ( F |s, t ) results
in a seniority classification rate on ICSIEVALSET of
61%, i.e. no improvement over conversation-type-
independent classification. We suspect this is due
to the smaller amounts of training material. To ver-
ify this assumption, we smooth the maximum like-
lihood estimates, pSi,t, Q2Si,t, towards the maximum
likelihood conversation-type-independent estimates,
</bodyText>
<equation confidence="0.9240615">
pSi, QSi, using
µSi,t = αpSi,t + (1 − α) pSi , (8)
2 = 2 9
�Si,t αQSi,t + (1 − α) QSi , ( )
</equation>
<bodyText confidence="0.999416545454545">
where the value of α = 0.7 was selected using
ICSIDEVSET. This leads to a rate of 63% on IC-
SIEVALSET. Furthermore, if instead of estimating
the prior on conversation type P (t) from the train-
ing data, we use our meeting type estimates from
(Laskowski, Ostendorf and Schultz, 2007), the clas-
sification rate increases to 67%. A control experi-
ment in which the true type ttest of each test meeting
is known, i.e. P (t) = 1 if ttest = t and 0 otherwise,
shows that the maximum accuracy achievable under
optimal P (t) estimation is 73%.
</bodyText>
<sectionHeader confidence="0.998201" genericHeader="conclusions">
9 Conclusions
</sectionHeader>
<bodyText confidence="0.999954233333333">
We have explored several socially meaningful parti-
tions of participant populations in two large multi-
party meeting corpora. These include assigned role,
leadership (embodied by a manager position), gen-
der, and seniority. Our proposed classifier, which
can represent participants in groups rather than in-
dependently, is able to leverage the observed differ-
ences between specific pairs of participant classes.
Using only low-level features capturing when partic-
ipants choose to vocalize relative to one another, it
attains relative error rate reductions on unseen data
of 37%, 67%, and 40% over chance on classifying
role, leadership, and seniority, respectively. We have
also shown that the same classifier, using the same
features, cannot discriminate between genders in ei-
ther corpus.
A comparison of the proposed feature types and
their performance on the tasks we have explored is
shown in Table 4. Consistently, the most useful fea-
ture types appear to be the probability of initiating
a talkspurt in silence, and the probability of initiat-
ing a talkspurt when a participant of a specific type
is already speaking. Additionally, on the ICSI Meet-
ing Corpus, the probability of speaking appears to be
dependent on seniority, and the probability of con-
tinuing to vocalize in overlap with another partici-
pant appears to depend on the seniority of the lat-
ter. Finally, we note that, for seniority classification
on the unseen ICSIEVALSET, the top 3 feature types
outperform the best single feature type, indicating a
</bodyText>
<figure confidence="0.999892173913044">
0 0.2 0.4
0.9
0.8
0.7
0.6
0.5
0.4
0.3
1
(GRAD,,*)
(PHD,GRAD)
(PHD,PHD)
(PHD,PROF)
(PROF,GRAD)
(PROF,PHD)
(GRAD,GRAD)
(GRAD,PHD)
(GRAD,PROF)
(PHD,GRAD)
(PHD,PHD)
(PHD,PROF)
(PROF,GRAD)
(PROF,PHD)
</figure>
<page confidence="0.999725">
154
</page>
<bodyText confidence="0.99891325">
degree of feature type complementarity; this is also
true for L-detection on AMIEVALSET when all fea-
ture types, as opposed to the single best feature type,
are used.
</bodyText>
<table confidence="0.99939715">
Feature AMI ICSI
Type
R L x x S S|t*
fV 44 — — — *52 *57
k
fV I *41 *60 — — 52 56
k
fV C 34 — — — — 62
k
(f °k )j 44 — — — 47 56
(f b) j *29 *60 — — 49 59
fOI *53 *60 64 — *59 *59
k,j
( f °k )j 24 — — — — 57
(k ) J — - — 54 59
—
fk,j — — — — *59 *63
top 3* 53 60 — — 61 67
all 46 75 43 47 58 57
priors 25 25 65 81 45 45
</table>
<tableCaption confidence="0.995931">
Table 4: Comparative classification performance for 3
</tableCaption>
<bodyText confidence="0.98926865">
experiments on AMIEVALSET and 3 experiments on IC-
SIEVALSET, per feature type; R, L, x, and S as defined
in Section 2. Also shown is performance on the best three
feature types (selected using development data) and all
feature types, as well as that when choosing the major-
ity class (“prior”), informed by training data priors; for
R and L classification, “prior” performance is equal to
random guessing. “—” indicates that a feature type, by
itself, did not perform above the corresponding “prior”
rate; top-3 feature type selection indicated by “*”.
Our results not only suggest new, easy-to-
compute, low-level features for the automatic clas-
sification of participants into socially meaningful
types, but also offer scope for informing turn-taking
or talkspurt-deployment policies in conversational
agents deployed in multi-party settings. Addition-
ally, they suggest that implicit models of certain
equivalence classes may lead to improved perfor-
mance on other tasks, such as multi-participant vo-
cal activity detection.
</bodyText>
<sectionHeader confidence="0.998822" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9975515">
We would like to thank Jean Carletta for help-
ful comments during the final preparation of this
manuscript, and Liz Shriberg for access to the ICSI
MRDA Corpus.
</bodyText>
<sectionHeader confidence="0.994107" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999974518518518">
R. Bales. 1950. Interaction Process Analysis. Addison-
Wesley Press, Inc.
S. Banerjee and A. Rudnicky. 2004. Using simple speech
based features to detect the state of a meeting and
the roles of the meeting participants. Proc. INTER-
SPEECH, pp.2189-2192.
J. Berger, S. Rosenholtz, M. Zelditch Jr. 1980. Status
Organizing Processes. Annual Review of Sociology,
6:479-508.
J. Carletta, S. Garrod, and H. Fraser-Krauss. 1998. Com-
munication and placement of authority in workplace
groups — The consequences for innovation. Small
Group Research, 29(5):531-559.
J. Carletta. 2007. Unleashing the killer corpus: Expe-
riences in creating the multi-everything AMI Meeting
Corpus. Language Resources and Evaluation Journal,
41(2):181–190.
A. Janin, D. Baron, J. Edwards, D. Ellis, D. Gelbart, N.
Morgan, B. Peskin, T. Pfau, E. Shriberg, A. Stolcke,
and C. Wooters. 2003. The ICSI Meeting Corpus.
Proc. ICASSP, pp.364–367.
K. Laskowski, M. Ostendorf, and T. Schultz. 2007. Mod-
eling vocal interaction for text-independent classifica-
tion of conversation type. Proc. SIGdial, pp.194-201.
K. Laskowski, C. F¨ugen, and T. Schultz. 2007. Simulta-
neous multispeaker segmentation for automatic meet-
ing recognition. Proc. EUSIPCO, pp.1294-1298.
A. Norwine and O. Murphy. 1938. Characteristic time
intervals in telephonic conversation. Bell System Tech-
nical Journal, 17:281-291.
R. Rienks and D. Heylen. 2005. Dominance detection
in meetings using easily obtainable features. Proc.
MLMI.
R. Rienks, D. Zhang, D. Gatica-Perez, and W. Post.
2006. Detection and application of influence rankings
in small-group meetings. Proc. ICMI.
J. Rotman. 1995. An Introduction to the Theory of
Groups. Springer-Verlag New York, Inc.
E. Shriberg, R. Dhillon, S. Bhagat, J. Ang, and H. Car-
vey. 2004. The ICSI Meeting Recorder Dialog Act
(MRDA) Corpus. Proc. SIGdial, pp.97–100.
D. Tannen. 1996. Gender &amp; Discourse. Oxford Univer-
sity Press, USA.
A. Vinciarelli. 2007. Speakers role recognition in mul-
tiparty audio recordings using social network analysis
and duration distribution modeling. IEEE Trans. Mul-
timedia, 9(6):1215-1226.
D. Wyatt, J. Bilmes, T. Choudhury, and H. Kautz.
2007. A privacy-sensitive approach to modeling
multi-person conversations. Proc. IJCAI, pp.1769–
1775.
M. Zancanaro, B. Lepri, and F. Pianesi. 2006. Automatic
detection of group functional roles in face to face in-
teractions. Proc. ICMI.
</reference>
<page confidence="0.999015">
155
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.216933">
<title confidence="0.9992075">Modeling Vocal Interaction for Participant Characterization in Multi-Party Conversation</title>
<author confidence="0.656769">Kornel</author>
<affiliation confidence="0.9139215">Cognitive Systems Universit¨at</affiliation>
<address confidence="0.65487">Karlsruhe,</address>
<email confidence="0.992197">kornel@ira.uka.de</email>
<author confidence="0.981319">Mari</author>
<affiliation confidence="0.985979333333333">Dept. of Electrical University of Seattle WA,</affiliation>
<email confidence="0.999764">mo@ee.washington.edu</email>
<author confidence="0.6883">Tanja</author>
<affiliation confidence="0.9950095">Cognitive Systems Labs Universit¨at Karlsruhe</affiliation>
<address confidence="0.907912">Karlsruhe,</address>
<email confidence="0.998759">tanja@ira.uka.de</email>
<abstract confidence="0.991155666666667">An important task in automatic conversation understanding is the inference of social structure governing participant behavior. We explore the dependence between several social dimensions, including assigned role, gender, and seniority, and a set of low-level features descriptive of talkspurt deployment in a multiparticipant context. Experiments conducted on two large, publicly available meeting corpora suggest that our features are quite useful in predicting these dimensions, excepting gender. The classification experiments we present exhibit a relative error rate reduction of 37% to 67% compared to choosing the majority class.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Bales</author>
</authors>
<title>Interaction Process Analysis.</title>
<date>1950</date>
<publisher>AddisonWesley Press, Inc.</publisher>
<contexts>
<context position="1654" citStr="Bales, 1950" startWordPosition="220" endWordPosition="221">ority class. 1 Introduction An important task in automatic conversation understanding is the inference of social structure governing participant behavior; in many conversations, the maintenance or expression of that structure is an implicit goal, and may be more important than the propositional content of what is said. There are many social dimensions along which participants may differ (Berger, Rosenholtz and Zelditch, 1980). Research in social psychology has shown that such differences among participants entail systematic differences in observed turn-taking and floor-control patterns (e.g. (Bales, 1950), (Tannen, 1996), (Carletta, Garrod and Fraser-Krauss, 1998)), and that participant types are not independent of the types and sizes of conversations in which they appear. In the present work, we consider the dimensions of assigned role, gender, and seniority level. We explore the predictability of these dimensions from a set of low-level speech activity features, namely the probabilities of initiating and continuing talkspurts in specific multiparticipant contexts, estimated from entire conversations. For our purposes, talkspurts (Norwine and Murphy, 1938) are contiguous intervals of speech, </context>
</contexts>
<marker>Bales, 1950</marker>
<rawString>R. Bales. 1950. Interaction Process Analysis. AddisonWesley Press, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Banerjee</author>
<author>A Rudnicky</author>
</authors>
<title>Using simple speech based features to detect the state of a meeting and the roles of the meeting participants.</title>
<date>2004</date>
<booktitle>Proc. INTERSPEECH,</booktitle>
<pages>2189--2192</pages>
<contexts>
<context position="4702" citStr="Banerjee and Rudnicky, 2004" startWordPosition="673" endWordPosition="676">d interruptions, and these were shown to yield the most robust performance. Our aim is also similar to that in (Vinciarelli, 2007) on radio shows, where the proposed approach relies on the relatively fixed temporal structure of production broadcasts, a property which is absent in spontaneous conversation. Although (Vinciarelli, 2007) also performs singlechannel speaker diarization, he does not explore behavior during vocalization overlap. Aside from the above, the focus of the majority of existing research characterizing participants is the detection of dynamic rather than static roles (i.e. (Banerjee and Rudnicky, 2004), (Zancanaro et al, 2006), (Rienks et al., 2006)). From a mathematical perspective, the research presented here is a continuation of our earlier work on meeting types (Laskowski, Ostendorf and Schultz, 2007), and we rely on much of that material in the presentation which follows. 2 Characterizing Participants Importantly, we characterize participants in entire groups, rather than characterizing each participant independently. Doing so allows us to apply constraints on the group as a whole, eliminating the need for hypothesis recombination (in the event that more than one participant is assigne</context>
</contexts>
<marker>Banerjee, Rudnicky, 2004</marker>
<rawString>S. Banerjee and A. Rudnicky. 2004. Using simple speech based features to detect the state of a meeting and the roles of the meeting participants. Proc. INTERSPEECH, pp.2189-2192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Berger</author>
<author>S Rosenholtz</author>
<author>M Zelditch Jr</author>
</authors>
<title>Status Organizing Processes. Annual Review of Sociology,</title>
<date>1980</date>
<pages>6--479</pages>
<marker>Berger, Rosenholtz, Jr, 1980</marker>
<rawString>J. Berger, S. Rosenholtz, M. Zelditch Jr. 1980. Status Organizing Processes. Annual Review of Sociology, 6:479-508.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carletta</author>
<author>S Garrod</author>
<author>H Fraser-Krauss</author>
</authors>
<title>Communication and placement of authority in workplace groups — The consequences for innovation.</title>
<date>1998</date>
<journal>Small Group Research,</journal>
<pages>29--5</pages>
<marker>Carletta, Garrod, Fraser-Krauss, 1998</marker>
<rawString>J. Carletta, S. Garrod, and H. Fraser-Krauss. 1998. Communication and placement of authority in workplace groups — The consequences for innovation. Small Group Research, 29(5):531-559.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carletta</author>
</authors>
<title>Unleashing the killer corpus: Experiences in creating the multi-everything AMI Meeting Corpus.</title>
<date>2007</date>
<journal>Language Resources and Evaluation Journal,</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="10064" citStr="Carletta, 2007" startWordPosition="1650" endWordPosition="1651">seniority level is drawn independently from S, leading to group assignments s ∈ SK, of which there are NKS . As for gender, we iterate over these to find s* = arg max P ( s) P (F|s) . (5) sESK The seniority of participant k, following the application of Equation 5, is s* [k]. 3For completeness, we note that each 1j corresponds to a permutation Q :L →Lof 11, and that Q E (T), the cyclic subgroup generated by T, where T is the permutation (1, 2, · · · , K). 3 Data In the current work, we use two different corpora of multi-party meetings. The first, the scenario subset of the AMI Meeting Corpus (Carletta, 2007), consists of meetings involving K = 4 participants who play different specialist roles in a product design team. We have observed the recommended division of this data into: AMITRAINSET of 98 meetings; AMIDEVSET of 20 meetings; and AMIEVALSET, also of 20 meetings. Although each participant takes part in approximately 4 meetings, the 3 sets are disjoint in participants. We use only the provided word alignments of these meetings. The corpus is accompanied by metadata which specifies the gender and assigned role of each participant. The second corpus consists of the Bed, Bmr, and Bro meeting typ</context>
</contexts>
<marker>Carletta, 2007</marker>
<rawString>J. Carletta. 2007. Unleashing the killer corpus: Experiences in creating the multi-everything AMI Meeting Corpus. Language Resources and Evaluation Journal, 41(2):181–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Janin</author>
<author>D Baron</author>
<author>J Edwards</author>
<author>D Ellis</author>
<author>D Gelbart</author>
<author>N Morgan</author>
<author>B Peskin</author>
<author>T Pfau</author>
<author>E Shriberg</author>
<author>A Stolcke</author>
<author>C Wooters</author>
</authors>
<title>The ICSI Meeting Corpus.</title>
<date>2003</date>
<booktitle>Proc. ICASSP,</booktitle>
<pages>364--367</pages>
<contexts>
<context position="10714" citStr="Janin et al., 2003" startWordPosition="1757" endWordPosition="1760">g K = 4 participants who play different specialist roles in a product design team. We have observed the recommended division of this data into: AMITRAINSET of 98 meetings; AMIDEVSET of 20 meetings; and AMIEVALSET, also of 20 meetings. Although each participant takes part in approximately 4 meetings, the 3 sets are disjoint in participants. We use only the provided word alignments of these meetings. The corpus is accompanied by metadata which specifies the gender and assigned role of each participant. The second corpus consists of the Bed, Bmr, and Bro meeting types in the ICSI Meeting Corpus (Janin et al., 2003). Each meeting is identified by one of {Bed, Bmr, Bro}, as well as a numerical identifier d. We have divided these meetings into: ICSITRAINSET, consisting of the 33 meetings for which d mod 4 ∈ {1, 2}; ICSIDEVSET, consisting of the 18 meetings for which d mod 4 ≡ 3; and ICSIEVALSET, consisting of the 16 meetings for which d mod 4 ≡ 0. These three sets are not disjoint in participants, and the number of instrumented participants K varies from meeting to meeting, between 3 and 9. The corpus is accompanied by metadata specifying the gender, age, and education level of each participant. We use onl</context>
</contexts>
<marker>Janin, Baron, Edwards, Ellis, Gelbart, Morgan, Peskin, Pfau, Shriberg, Stolcke, Wooters, 2003</marker>
<rawString>A. Janin, D. Baron, J. Edwards, D. Ellis, D. Gelbart, N. Morgan, B. Peskin, T. Pfau, E. Shriberg, A. Stolcke, and C. Wooters. 2003. The ICSI Meeting Corpus. Proc. ICASSP, pp.364–367.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Laskowski</author>
<author>M Ostendorf</author>
<author>T Schultz</author>
</authors>
<title>Modeling vocal interaction for text-independent classification of conversation type.</title>
<date>2007</date>
<booktitle>Proc. SIGdial,</booktitle>
<pages>194--201</pages>
<marker>Laskowski, Ostendorf, Schultz, 2007</marker>
<rawString>K. Laskowski, M. Ostendorf, and T. Schultz. 2007. Modeling vocal interaction for text-independent classification of conversation type. Proc. SIGdial, pp.194-201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Laskowski</author>
<author>C F¨ugen</author>
<author>T Schultz</author>
</authors>
<title>Simultaneous multispeaker segmentation for automatic meeting recognition.</title>
<date>2007</date>
<booktitle>Proc. EUSIPCO,</booktitle>
<pages>1294--1298</pages>
<marker>Laskowski, F¨ugen, Schultz, 2007</marker>
<rawString>K. Laskowski, C. F¨ugen, and T. Schultz. 2007. Simultaneous multispeaker segmentation for automatic meeting recognition. Proc. EUSIPCO, pp.1294-1298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Norwine</author>
<author>O Murphy</author>
</authors>
<title>Characteristic time intervals in telephonic conversation.</title>
<date>1938</date>
<journal>Bell System Technical Journal,</journal>
<pages>17--281</pages>
<contexts>
<context position="2217" citStr="Norwine and Murphy, 1938" startWordPosition="302" endWordPosition="305">ved turn-taking and floor-control patterns (e.g. (Bales, 1950), (Tannen, 1996), (Carletta, Garrod and Fraser-Krauss, 1998)), and that participant types are not independent of the types and sizes of conversations in which they appear. In the present work, we consider the dimensions of assigned role, gender, and seniority level. We explore the predictability of these dimensions from a set of low-level speech activity features, namely the probabilities of initiating and continuing talkspurts in specific multiparticipant contexts, estimated from entire conversations. For our purposes, talkspurts (Norwine and Murphy, 1938) are contiguous intervals of speech, with internal pauses no longer than 0.3 seconds. Features derived from talkspurts are not only easier to compute than higher-level lexical, prosodic, or dialogue act features, they are also applicable to scenarios in which only privacy-sensitive data (Wyatt et al, 2007) is available. At the current time, relatively little is known about the predictive power of talkspurt timing in the context of large multi-party corpora. As stated, our primary goal is to quantify the dependence between specific types of speech activity features and specific social dimension</context>
</contexts>
<marker>Norwine, Murphy, 1938</marker>
<rawString>A. Norwine and O. Murphy. 1938. Characteristic time intervals in telephonic conversation. Bell System Technical Journal, 17:281-291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rienks</author>
<author>D Heylen</author>
</authors>
<title>Dominance detection in meetings using easily obtainable features.</title>
<date>2005</date>
<booktitle>Proc. MLMI.</booktitle>
<contexts>
<context position="3492" citStr="Rienks and Heylen, 2005" startWordPosition="492" endWordPosition="495">fits. Most importantly, the existence of significant dependence would suggest that multiparticipant speech activity detectors (Laskowski, F¨ugen and Schultz, 2007) relying on models conditioned on such attributes may outperform those relying on general models. Furthermore, conversational dialogue systems deployed in multi-party scenarios may be perceived as more human-like, by humans, if their talkspurt deployment strategies are tailored to the personalities they are designed to embody. Computational work which is most similar to that presented here includes the inference of static dominance (Rienks and Heylen, 2005) and influence (Rienks et al., 2006) rankings. In that work, the authors employed several speech activity features differing from ours in temporal scale and normaliza148 Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 148–155, Columbus, June 2008. c�2008 Association for Computational Linguistics tion. Notably, their features are not probabilities which are directly employable in a speech activity detection system. In addition, several higher-level features were included, such as topic changes, participant roles, and rates of phenomena such as turns and interruptions, a</context>
</contexts>
<marker>Rienks, Heylen, 2005</marker>
<rawString>R. Rienks and D. Heylen. 2005. Dominance detection in meetings using easily obtainable features. Proc. MLMI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rienks</author>
<author>D Zhang</author>
<author>D Gatica-Perez</author>
<author>W Post</author>
</authors>
<title>Detection and application of influence rankings in small-group meetings.</title>
<date>2006</date>
<booktitle>Proc. ICMI.</booktitle>
<contexts>
<context position="3528" citStr="Rienks et al., 2006" startWordPosition="498" endWordPosition="501"> significant dependence would suggest that multiparticipant speech activity detectors (Laskowski, F¨ugen and Schultz, 2007) relying on models conditioned on such attributes may outperform those relying on general models. Furthermore, conversational dialogue systems deployed in multi-party scenarios may be perceived as more human-like, by humans, if their talkspurt deployment strategies are tailored to the personalities they are designed to embody. Computational work which is most similar to that presented here includes the inference of static dominance (Rienks and Heylen, 2005) and influence (Rienks et al., 2006) rankings. In that work, the authors employed several speech activity features differing from ours in temporal scale and normaliza148 Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 148–155, Columbus, June 2008. c�2008 Association for Computational Linguistics tion. Notably, their features are not probabilities which are directly employable in a speech activity detection system. In addition, several higher-level features were included, such as topic changes, participant roles, and rates of phenomena such as turns and interruptions, and these were shown to yield the mos</context>
<context position="4750" citStr="Rienks et al., 2006" startWordPosition="681" endWordPosition="684">robust performance. Our aim is also similar to that in (Vinciarelli, 2007) on radio shows, where the proposed approach relies on the relatively fixed temporal structure of production broadcasts, a property which is absent in spontaneous conversation. Although (Vinciarelli, 2007) also performs singlechannel speaker diarization, he does not explore behavior during vocalization overlap. Aside from the above, the focus of the majority of existing research characterizing participants is the detection of dynamic rather than static roles (i.e. (Banerjee and Rudnicky, 2004), (Zancanaro et al, 2006), (Rienks et al., 2006)). From a mathematical perspective, the research presented here is a continuation of our earlier work on meeting types (Laskowski, Ostendorf and Schultz, 2007), and we rely on much of that material in the presentation which follows. 2 Characterizing Participants Importantly, we characterize participants in entire groups, rather than characterizing each participant independently. Doing so allows us to apply constraints on the group as a whole, eliminating the need for hypothesis recombination (in the event that more than one participant is assigned a role which was meant to be unique). Addition</context>
<context position="8511" citStr="Rienks et al., 2006" startWordPosition="1358" endWordPosition="1361">eader to (Rotman, 1995). = arg max 9 E 9 P (g |F) P ( g ) |{z } MM , (1) 149 alternative group assignments has K indicator vector members lj, 1≤j≤K, where lj [k] is L for k = j and ¬L otherwise.3 We iterate over the indicator vectors to obtain j* = arg max P ( F|lj ) , (3) jE{1,···,K} assuming uniform priors P ( lj ). Following the application of Equation 3, j* is the index of the most likely L participant. We note that this framework for unique role classification is applicable to classifying unique ranks, without first having to collapse them into nonunique rank classes as was necessary in (Rienks et al., 2006). 2.2 Conversations with Non-Unique Roles The second type of inference we consider is for dimensions in which roles are not unique, i.e. where participants are in principle drawn independently from a set of alternatives. This naturally includes dimensions such as gender, seniority, age, etc. As an example, we treat the case of gender. Participant genders are drawn independently from H = {�, d}. The set of group assignment alternatives h is given by the Cartesian product HK, of 2K unique elements. We search for the most likely group assignment h*, given the observables F, by iterating over thes</context>
</contexts>
<marker>Rienks, Zhang, Gatica-Perez, Post, 2006</marker>
<rawString>R. Rienks, D. Zhang, D. Gatica-Perez, and W. Post. 2006. Detection and application of influence rankings in small-group meetings. Proc. ICMI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Rotman</author>
</authors>
<title>An Introduction to the Theory of Groups.</title>
<date>1995</date>
<publisher>Springer-Verlag</publisher>
<location>New York, Inc.</location>
<contexts>
<context position="7914" citStr="Rotman, 1995" startWordPosition="1240" endWordPosition="1241">ables, we iterate over the K! elements ofSK using α* = arg max P (F|α (r1)) , (2) α ESx where we have elided the prior P ( α) assuming that it is uniform. Following the application of Equation 2, the most likely role of participant k is given by α* (r1) [k]. Alternately, we may be interested in identifying only a subset of the roles in R, namely a leader, or a manager. In this case, participant roles are drawn from L = {L, -,L}, under the constraint that exactly one participant is assigned the role L. The setLof 2For an overview of group theoretic notions and notation, we refer the reader to (Rotman, 1995). = arg max 9 E 9 P (g |F) P ( g ) |{z } MM , (1) 149 alternative group assignments has K indicator vector members lj, 1≤j≤K, where lj [k] is L for k = j and ¬L otherwise.3 We iterate over the indicator vectors to obtain j* = arg max P ( F|lj ) , (3) jE{1,···,K} assuming uniform priors P ( lj ). Following the application of Equation 3, j* is the index of the most likely L participant. We note that this framework for unique role classification is applicable to classifying unique ranks, without first having to collapse them into nonunique rank classes as was necessary in (Rienks et al., 2006). 2</context>
</contexts>
<marker>Rotman, 1995</marker>
<rawString>J. Rotman. 1995. An Introduction to the Theory of Groups. Springer-Verlag New York, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Shriberg</author>
<author>R Dhillon</author>
<author>S Bhagat</author>
<author>J Ang</author>
<author>H Carvey</author>
</authors>
<title>The ICSI Meeting Recorder Dialog Act (MRDA) Corpus.</title>
<date>2004</date>
<booktitle>Proc. SIGdial,</booktitle>
<pages>97--100</pages>
<contexts>
<context position="11421" citStr="Shriberg et al, 2004" startWordPosition="1886" endWordPosition="1889">ier d. We have divided these meetings into: ICSITRAINSET, consisting of the 33 meetings for which d mod 4 ∈ {1, 2}; ICSIDEVSET, consisting of the 18 meetings for which d mod 4 ≡ 3; and ICSIEVALSET, consisting of the 16 meetings for which d mod 4 ≡ 0. These three sets are not disjoint in participants, and the number of instrumented participants K varies from meeting to meeting, between 3 and 9. The corpus is accompanied by metadata specifying the gender, age, and education level of each participant. We use only the forced alignments of these meetings, available in the accompanying MRDA Corpus (Shriberg et al, 2004). 4 Features Our observation space is the complete K-participant vocal interaction on-off pattern description for a meeting C, a discretized version of which we denote as qt ∈ {0,1}K for 1≤t≤T, where T is the duration of C in terms of the number of 100 ms frames. Details regarding the discretization (and subsequent feature computation) can be found in (Laskowski, Ostendorf and Schultz, 2007). We compute from qt the following features4 which are the elements of F: f� I � , the probabil4Feature type superscripts indicate talkspurt initiation (I) or continuation (G), for either single-participant</context>
</contexts>
<marker>Shriberg, Dhillon, Bhagat, Ang, Carvey, 2004</marker>
<rawString>E. Shriberg, R. Dhillon, S. Bhagat, J. Ang, and H. Carvey. 2004. The ICSI Meeting Recorder Dialog Act (MRDA) Corpus. Proc. SIGdial, pp.97–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Tannen</author>
</authors>
<title>Gender &amp; Discourse.</title>
<date>1996</date>
<publisher>Oxford University Press, USA.</publisher>
<contexts>
<context position="1670" citStr="Tannen, 1996" startWordPosition="222" endWordPosition="224">Introduction An important task in automatic conversation understanding is the inference of social structure governing participant behavior; in many conversations, the maintenance or expression of that structure is an implicit goal, and may be more important than the propositional content of what is said. There are many social dimensions along which participants may differ (Berger, Rosenholtz and Zelditch, 1980). Research in social psychology has shown that such differences among participants entail systematic differences in observed turn-taking and floor-control patterns (e.g. (Bales, 1950), (Tannen, 1996), (Carletta, Garrod and Fraser-Krauss, 1998)), and that participant types are not independent of the types and sizes of conversations in which they appear. In the present work, we consider the dimensions of assigned role, gender, and seniority level. We explore the predictability of these dimensions from a set of low-level speech activity features, namely the probabilities of initiating and continuing talkspurts in specific multiparticipant contexts, estimated from entire conversations. For our purposes, talkspurts (Norwine and Murphy, 1938) are contiguous intervals of speech, with internal pa</context>
</contexts>
<marker>Tannen, 1996</marker>
<rawString>D. Tannen. 1996. Gender &amp; Discourse. Oxford University Press, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Vinciarelli</author>
</authors>
<title>Speakers role recognition in multiparty audio recordings using social network analysis and duration distribution modeling.</title>
<date>2007</date>
<journal>IEEE Trans. Multimedia,</journal>
<pages>9--6</pages>
<contexts>
<context position="4204" citStr="Vinciarelli, 2007" startWordPosition="602" endWordPosition="603">ch activity features differing from ours in temporal scale and normaliza148 Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue, pages 148–155, Columbus, June 2008. c�2008 Association for Computational Linguistics tion. Notably, their features are not probabilities which are directly employable in a speech activity detection system. In addition, several higher-level features were included, such as topic changes, participant roles, and rates of phenomena such as turns and interruptions, and these were shown to yield the most robust performance. Our aim is also similar to that in (Vinciarelli, 2007) on radio shows, where the proposed approach relies on the relatively fixed temporal structure of production broadcasts, a property which is absent in spontaneous conversation. Although (Vinciarelli, 2007) also performs singlechannel speaker diarization, he does not explore behavior during vocalization overlap. Aside from the above, the focus of the majority of existing research characterizing participants is the detection of dynamic rather than static roles (i.e. (Banerjee and Rudnicky, 2004), (Zancanaro et al, 2006), (Rienks et al., 2006)). From a mathematical perspective, the research prese</context>
</contexts>
<marker>Vinciarelli, 2007</marker>
<rawString>A. Vinciarelli. 2007. Speakers role recognition in multiparty audio recordings using social network analysis and duration distribution modeling. IEEE Trans. Multimedia, 9(6):1215-1226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wyatt</author>
<author>J Bilmes</author>
<author>T Choudhury</author>
<author>H Kautz</author>
</authors>
<title>A privacy-sensitive approach to modeling multi-person conversations.</title>
<date>2007</date>
<booktitle>Proc. IJCAI, pp.1769–</booktitle>
<pages>1775</pages>
<contexts>
<context position="2524" citStr="Wyatt et al, 2007" startWordPosition="350" endWordPosition="353">niority level. We explore the predictability of these dimensions from a set of low-level speech activity features, namely the probabilities of initiating and continuing talkspurts in specific multiparticipant contexts, estimated from entire conversations. For our purposes, talkspurts (Norwine and Murphy, 1938) are contiguous intervals of speech, with internal pauses no longer than 0.3 seconds. Features derived from talkspurts are not only easier to compute than higher-level lexical, prosodic, or dialogue act features, they are also applicable to scenarios in which only privacy-sensitive data (Wyatt et al, 2007) is available. At the current time, relatively little is known about the predictive power of talkspurt timing in the context of large multi-party corpora. As stated, our primary goal is to quantify the dependence between specific types of speech activity features and specific social dimensions; however, doing so offers several additional benefits. Most importantly, the existence of significant dependence would suggest that multiparticipant speech activity detectors (Laskowski, F¨ugen and Schultz, 2007) relying on models conditioned on such attributes may outperform those relying on general mod</context>
</contexts>
<marker>Wyatt, Bilmes, Choudhury, Kautz, 2007</marker>
<rawString>D. Wyatt, J. Bilmes, T. Choudhury, and H. Kautz. 2007. A privacy-sensitive approach to modeling multi-person conversations. Proc. IJCAI, pp.1769– 1775.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Zancanaro</author>
<author>B Lepri</author>
<author>F Pianesi</author>
</authors>
<title>Automatic detection of group functional roles in face to face interactions.</title>
<date>2006</date>
<booktitle>Proc. ICMI.</booktitle>
<contexts>
<context position="4727" citStr="Zancanaro et al, 2006" startWordPosition="677" endWordPosition="680"> shown to yield the most robust performance. Our aim is also similar to that in (Vinciarelli, 2007) on radio shows, where the proposed approach relies on the relatively fixed temporal structure of production broadcasts, a property which is absent in spontaneous conversation. Although (Vinciarelli, 2007) also performs singlechannel speaker diarization, he does not explore behavior during vocalization overlap. Aside from the above, the focus of the majority of existing research characterizing participants is the detection of dynamic rather than static roles (i.e. (Banerjee and Rudnicky, 2004), (Zancanaro et al, 2006), (Rienks et al., 2006)). From a mathematical perspective, the research presented here is a continuation of our earlier work on meeting types (Laskowski, Ostendorf and Schultz, 2007), and we rely on much of that material in the presentation which follows. 2 Characterizing Participants Importantly, we characterize participants in entire groups, rather than characterizing each participant independently. Doing so allows us to apply constraints on the group as a whole, eliminating the need for hypothesis recombination (in the event that more than one participant is assigned a role which was meant </context>
</contexts>
<marker>Zancanaro, Lepri, Pianesi, 2006</marker>
<rawString>M. Zancanaro, B. Lepri, and F. Pianesi. 2006. Automatic detection of group functional roles in face to face interactions. Proc. ICMI.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>