<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000312">
<title confidence="0.998625">
Syntactic Transfer Patterns of German Particle Verbs and their Impact on
Lexical Semantics
</title>
<author confidence="0.981525">
Stefan Bott Sabine Schulte im Walde
</author>
<affiliation confidence="0.67786">
Institut f¨ur Maschinelle Sprachverabeitung
Universit¨at Stuttgart
</affiliation>
<address confidence="0.907065">
Pfaffenwaldring 5b, 70569 Stuttgart, Germany
</address>
<email confidence="0.998469">
{stefan.bott,schulte}@ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.997379" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999962458333333">
German particle verbs, like anblicken (to
gaze at) combine a base verb (blicken)
with a particle (an) to form a special
kind of Multi Word Expression. Parti-
cle verbs may share the semantics of the
base verb and the particle to a variable de-
gree. However, while syntactic subcate-
gorization frames tend to be good predic-
tor for the semantics of verbs in general
(verbs that are similar in meaning also tend
to have similar subcategorization frames
and selectional preferences), there are reg-
ular changes in subcategorization frames
by particle verbs with regard to the corre-
sponding base verbs. This paper demon-
strates that the syntactic behavior of par-
ticle verbs and base verbs together (mod-
eling regular changes in subcategorization
frames by particle verbs and correspond-
ing base verbs) and applying clustering
techniques allows us to distinguish parti-
cle verb meaning and shows the tight con-
nection between transfer patterns and the
semantic classes of particle verbs.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999928444444445">
In German, particle verbs (PVs), like anblicken in
(1), are a highly productive class. PVs present
challenges for a both theoretical analysis and their
computational treatment. One of the central prob-
lems is the prediction of their meaning from their
constituent parts: the base verb (BV, e.g. blicken
in (1)) and the particle (e.g. an). Many PVs de-
rive their meaning from the corresponding BVs –
with a varying degree of transparency. It is often
</bodyText>
<footnote confidence="0.81025125">
This work is licensed under a Creative Commons Attribution
4.0 International Licence. Page numbers and proceedings
footer are added by the organisers. Licence details: http:
//creativecommons.org/licenses/by/4.0/
</footnote>
<bodyText confidence="0.998978285714286">
not clear, however, how to interpret the semantics
of the particles and their contribution to the mean-
ing of the PVs. Since particles never occur iso-
lated, without the context of the verb, it is difficult
to assign them a lexical semantic entry on their
own. Even more, German particles are a notori-
ously ambiguous word class.
</bodyText>
<listItem confidence="0.645452">
(1) Das
</listItem>
<bodyText confidence="0.991967148148148">
The
The child looks at his mother.
One way to approximate the meaning of parti-
cles is to group together the particle verbs which
share the same particle into semantic groups (such
as anblicken, anstarren, anschauen ‘to stare/look
at’), such that both the meaning of the PV and the
meaning of the BV is similar in each group. This
allows us to make inferences like ”taking a BV
from semantic group α and particle β, we will de-
rive a PV from semantic group δ”. Such groups
can be established and they represent productive
paradigms. Springorum et al. (2013) have shown
in a generation experiment setup that subjects are
able to associate a meaning to artificially created,
previously unattested PVs and to construct exam-
ple sentences for them.1 Different subjects also
agree to a large degree on the meaning they at-
tribute to the newly formed lexical items.
But this approach also rises a series of ques-
tions, especially concerning the way in which such
groups can be distinguished, both from a theoreti-
cal and a corpus-based perspective. For example,
which kinds of linguistic features allow us to dis-
criminate such semantic classes? In this paper we
investigate the influence of syntax, which repre-
sents one of the possible feature sources. Syn-
</bodyText>
<footnote confidence="0.9283742">
1For example for the neologism anlauschen, referring to a
partitive meaning of the particle, senentence like the follow-
ing could be found: Er hatte an der Wand angelauscht und
wusste Bescheid. (‘He had listened at the wall and knew
everything.’)
</footnote>
<figure confidence="0.9972055">
seine
his-acc
Mutter
mother
an.
PRT.
Kind
child
blickt
gazes
</figure>
<page confidence="0.968441">
182
</page>
<note confidence="0.980428">
Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 182–192,
Dublin, Ireland, August 23-24 2014.
</note>
<bodyText confidence="0.993723783783784">
tactic subcategorization frames tend to be good
predictors for the semantics of verbs in general:
verbs that are similar in meaning also tend to have
similar subcategorization frames and selectional
preferences (Schulte im Walde, 2000; Merlo and
Stevenson, 2001; Korhonen et al., 2003; Schulte
im Walde, 2006a; Joanis et al., 2008). But, as
we will show below, PV-BV pairs tend to have a
special behavior with respect to their subcatego-
rization, even if their meanings are closely related.
Because we are interested in pairs of PVs and their
BVs, we thus have to look at pairs of subcatego-
rization preferences, and rely on the concept of
syntactic transfer. We use syntactic transfer as
a technical term here, which we define as regular
changes in subcategorization frames by PVs and
corresponding BVs, e.g., the incorporation or ad-
dition of complements of PVs in comparison to
their BVs (Stiebels, 1996; L¨udeling, 2001; Fleis-
cher and Barz, 2012a). We claim that the syntac-
tic behavior of PVs and BVs together allows us to
distinguish semantic classes.
A better understanding of the nature of the con-
nection between syntactic transfer patterns and se-
mantic classes may be beneficial for both theoret-
ical and computational linguistics. On the theo-
retical side we can hope to find new arguments to
guide and justify lexical semantic classifications.
We may also shed light on what particles actu-
ally mean, a topic which is not trivial by itself.
In computational semantics, a better understand-
ing of syntactic transfer patterns can potentially
contribute to a better treatment of PVs in meaning-
related areas, such as machine translation and in-
formation retrieval.
In sum, this paper makes the following contri-
butions:
</bodyText>
<listItem confidence="0.988952928571429">
• We show that the meaning of verb particles
can be modeled as classes of pairs of PVs and
their corresponding BVs, where both PVs
and BVs in each class are closely related in
meaning. In addition, the PV-BV pairs in
each class undergo the same syntactic trans-
fers, i.e. the selectional preferences of PV-
BV pairs within each class tend to be very
similar, even if the subcategorization pref-
erences may be different between PVs and
BVs.
• We show that automatic clustering can repli-
cate a gold standard classification of PV-BV
pairs to a large degree when clustering only
</listItem>
<bodyText confidence="0.991051">
relies on syntax and the gold standard reflects
semantic regularities.
The rest of this paper is organized as follows: In
section 2 we describe the task and our goals. Here
we also define the term syntactic transfer pattern,
which is central to our discussion. Section 3 is
dedicated to related work relevant for our study.
In section 4 we describe the experimental setup,
while sections 5 and 6 present the experiment re-
sults and discuss them.
</bodyText>
<sectionHeader confidence="0.968071" genericHeader="introduction">
2 Goal and Motivation
</sectionHeader>
<bodyText confidence="0.999798307692308">
The work we describe here centers around the con-
cept of semantic classes and syntactic transfer pat-
terns. As concerning the semantic side, the PVs
which share the same particle may be grouped into
different classes according to their meaning. For
example, among the PVs incorporating the parti-
cle an we find a group of verbs whose meanings
center around the concept of ”to look at some-
one/something in manner X”, ”to attach something
somewhere in manner X”, ”to make an unpleasant
sound towards someone in a manner X” and ”to
start an action X on something which starts con-
suming it”, as exemplified in (2) a-d.
</bodyText>
<figure confidence="0.922979125">
(2) a. A blickt/schaut/starrt/stiert/ B an.
A looks/stares/gazes B PRT.
A looks/stares/gazes at B.
b. A klebt/heftet/schraubt/nagelt B
A glues/affixes/screws B
an C an.
at/onto C PRT.
A glues/affixes/screws B onto C.
</figure>
<listItem confidence="0.65835575">
c. A br¨ullt/faucht/bellt/meckert
A roars/hisses/bleats
A brawls/hisses/scolds at B.
d. A schneidet/bricht/reißt B an.
</listItem>
<bodyText confidence="0.98933575">
A cuts/breaks/tears B PRT.
A cuts/breaks/tears the first
slice/piece of B.
Such semantic classes are not easy to define and
they are also difficult to induce automatically. Al-
though there is general agreement in the theo-
retical literature that such semantic classes for
PVs exist (cf. Lechler and Roßdeutscher (2009),
Kliche (2011) and Springorum (2011)) the agree-
ment on the number and nature of such classes is
not very high. For example, Springorum (2011)
(who develops her analysis within Discourse Rep-
</bodyText>
<figure confidence="0.9760015">
B
B
an.
PRT.
</figure>
<page confidence="0.998262">
183
</page>
<bodyText confidence="0.9999005">
resentation Theory (Kamp and Reyle, 1993)) dis-
tinguishes between 11 classes of PVs with the par-
ticle an, while Fleischer and Barz (2012b) only
distinguish 3 major de-verbal classes, based on
their aktionsart, which can be divided into some
9 minor classes.2 It should be noted that all the
PVs and BVs in (2) a-d are not only quite homo-
geneous in their semantics; they also form coher-
ent syntactic classes. The PVs and BVs of these
examples are quite similar in the way they typi-
cally select their syntactic complements. For ex-
ample, the BVs of (2-a) typically take a PP argu-
ment that expresses the direction of gaze using a
prepositional phrases with one of the prepositions
auf, zu, nach or in subcategorizing a dative noun
phrase. The corresponding PVs, however, typi-
cally express this semantic role by an accusative
object. The type of change from the typical frame
of a BV to the typical frame of a PV is an example
of what we mean by a syntactic transfer pattern.
So, while similar syntactic behavior of two
verbs in general may indicate that the verbs are
also semantically similar, this is typically not the
case for PV-BV pairs. Compare (1) to (3), which
are nearly synonymous but (3) uses the BV blicken
instead of the PV anblicken in (1). We can only in-
duce the similarity of the PV and the BV if we take
the syntactic transfer into consideration.
</bodyText>
<listItem confidence="0.736493">
(3) a. Das
</listItem>
<bodyText confidence="0.967007157894737">
The
b. Das Kind stiert/starrt/schaut zu
The child stares/stares/looks at
seiner Mutter.
his-dat Mother.
Looking at the class to which this PV belongs, all
the variants of (3-b) are semantically very similar
to (3-a). This also corresponds to a syntactic sim-
ilarity: all the verbs of this group share the same
preferred syntactic subcategorization frames. The
dominant frame of theses verbs is ”NPnom+PP-
dat” (the head preposition of the PP may vary, but
within well-defined limits). But this is not the case
for the PV anblicken in (1). (1) is nearly synony-
mous to (3-a), but the PV in this example has a to-
tally different frame, namely the simple transitive
”NPnom+NP-acc”. It may not come as a surprise
that all of the verbs in (3-b) have PV counterparts
(anstieren, anstarren, etc.), which all behave syn-
</bodyText>
<footnote confidence="0.6553865">
2The subdivision is, however not fully spelled out and
only implicit in their description.
</footnote>
<bodyText confidence="0.997820428571428">
tactically like anblicken.
In sum, we part from the hypothesis that there
is a tight connection between transfer patterns and
the semantic classes of PVs. There is only one
more point to make: the classes shown in (2),
could actually be seen as reflecting different mean-
ings of the particle an itself.
</bodyText>
<sectionHeader confidence="0.999949" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.99989830952381">
Particle verbs have been studied from the theo-
retical perspective and, to a more limited extend,
from the aspect of the computational predictabil-
ity of the degree of semantic compositionality (the
transparency of their meaning with respect to the
meaning of the base verb and the particle) and the
semantic classifiabilty of PVs.
For English, there is work on the automatic
extraction of PVs from corpora (Baldwin and
Villavicencio, 2002; Baldwin, 2005; Villavicen-
cio, 2005) and the determination of composition-
ality (McCarthy et al., 2003; Baldwin et al., 2003;
Bannard, 2005).
To the best of our knowledge Aldinger (2004)
is the first work that studies German PVs from a
corpus based perspective, with an emphasis on the
syntactic behavior and syntactic change. Schulte
im Walde (2004), Schulte im Walde (2005) and
Schulte im Walde (2006b) present preliminary dis-
tributional studies to explore salient features at the
syntax-semantics interface that determine the se-
mantic nearest neighbours of German PVs. Re-
lying on the insights of those studies, Schulte
im Walde (2006b) and Hartmann (2008) describe
experiments which model the subcategorization
transfer of German PVs with respect to their BVs
in order to strengthen PV-BV distributional simi-
larity. The main goal for them is to use transfer in-
formation in order to predict the degree of seman-
tic compositionality of PVs. K¨uhner and Schulte
im Walde (2010) use clustering to determine the
degree of compositionality of German PVs, via
common PV-BV cluster membership. They are,
again, mainly interested in the assessment of com-
positionality, which is done on the basis of lexi-
cal information. They use syntactic information,
but only as a filter and for lexical heads as cooc-
currence features in order to limit the selected ar-
gument slots to certain syntactic functions. They
conclude that the best results can be obtained with
information stemming from direct objects and PP-
objects. The incorporation of syntactic informa-
</bodyText>
<figure confidence="0.8011519">
seiner
his-dat
Mutter.
mother.
zu
at
blickt
looks
Kind
child
</figure>
<page confidence="0.993311">
184
</page>
<bodyText confidence="0.999994464285714">
tion in the form of dependency arc labels (concate-
nated with the head nouns) does not yield satisfac-
tory results, putting the syntactic transfer problem
in evidence, again. They conclude that an incor-
poration of syntactic transfer information between
BVs and PVs could possibly improve the results.
Based on a theoretical study (Springorum,
2011), which explains particle meanings in terms
of Discourse Representation Theory (Kamp and
Reyle, 1993), Springorum et al. (2012) show that
four classes of PVs with the particle an can be
classified automatically. They take a supervised
approach using decision trees. The use of decision
trees also allows them to manually inspect and an-
alyze the decisions made by the classifier. As pre-
dictive features they use the head nouns of objects,
generalized classes of these nouns and PP types.
The approach we take here is not fully compa-
rable to any of the former approaches, since we
try to derive a semantic classification BV-PP pairs
in an unsupervised manner and we only use syn-
tactic features, stemming from corpus instances of
both the BVs and the PVs. In other words, we do
not attempt to classify PVs, but we try to classify
syntactic transfers and, by doing so, we identify
syntactic transfer patterns which we hypothesize
to have a close relation to semantic PV classes and
the semantics of the particles.
</bodyText>
<sectionHeader confidence="0.999761" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.999637">
4.1 Gold Standard Classification
</subsectionHeader>
<bodyText confidence="0.997424383561644">
For testing our hypothesis, we created a gold stan-
dard of 32 PVs, including 14 with the particle an
and 18 with the particle auf. We concentrated on
two particles here in order to have a small and con-
trolled test bed which allows us to study the syn-
tactic transfers.
We based the creation of the gold standard on
the classification by Fleischer and Barz (2012b),
but we further distinguished the classes based
on the meanings of the BVs. For example, we
grouped all the BVs with the meaning of ’looking
in a manner X’ or ’tying X to Y in a manner Z’.
From these classes we selected those which had
a clear subcategorization pattern for both the BVs
and the PVs. We discarded such PVs where ei-
ther the PV itself or its underlying BV was clearly
ambiguous. The full gold standard can be seen in
table 2. The table also lists the expected dominant
subcategorization frames for the BVs and PVs of
each category.
While the gold standard was based on theo-
retic considerations, we expected it to correlate
with human intuitions. To test this, we presented
the gold standard verbs to 6 human raters. These
raters were all German native speakers with work-
ing practice in various areas of linguistics or lan-
guage didactics. The raters were not directly asked
to group PVs into categories. Instead the PVs were
presented in pairs3 and raters had to make a deci-
sion on whether or not the pairs belong to the same
semantic category (even if they could not think
of a name or description of that category). No
pre-defined categories were given, nor were raters
asked to provide a name or description for these
categories. The annotators were asked to take the
similarity of the BVs and the similarity of the PVs
into consideration for their judgements. In order
to avoid possible bias, the verbs were presented
without given context. What is important here is
that we did not ask them to take any syntactic cri-
terion into consideration, the criterion we used for
the initial compilation of the gold standard.
The inter-annotator agreement was substantial
with a Fleiss’ Kappa score of 0.68 (Fleiss, 1971).4
As a measure of agreement between raters and the
previously created gold standard, we performed
pair-wise calculations between the ratings of each
annotator and the gold standard. For the compar-
ison, the gold standard was transformed into PV
pairs and the value true was assigned if the two
verbs of a pairs belonged to the same category, and
false otherwise. We calculated the Kappa scores
for each annotator and took the average of the
agreement scores. Table 1 resumes the compari-
son. Values are given for the parts of the gold stan-
dard corresponding to PVs with an and auf sepa-
rately and also for the gold standard as a whole.
It can clearly be seen that humans agreement
with the gold standard is as high as the agree-
ment among different annotators. This shows that
the gold standard used here is a valid represen-
tation of human language intuition. Most impor-
tantly, the annotators did not use syntactic criteria
3All possible PV combinations were generated, but the
PVs with an were kept separate from those with auf in order
to avoid an unnecessary explosion of the number of pairs to
be rated.
4One of the 6 raters showed less agreement with the other
raters. If we eliminate this rater from the calculation of agree-
ment, we achieve an even higher Kappa score of 0.76 and also
agreement scores with the gold standard improved. Two of
the annotators even achieved Kappa scores of over 0.80 when
compared to the gold standard.
</bodyText>
<page confidence="0.995551">
185
</page>
<bodyText confidence="0.999885777777778">
and still validated a gold standard whose creation
was explicitly based on syntactic subcategoriza-
tion frames. In other words: there is an apparent
tight interrelation between syntax and semantics
for PVs, at least in the sense that semantic dis-
tinctions can be used to predict different syntactic
behaviour. The inverse case - predicting semantic
classes from syntactic information - will be dis-
cussed below.
</bodyText>
<subsectionHeader confidence="0.997967">
4.2 Corpus Data
</subsectionHeader>
<bodyText confidence="0.999892333333333">
We used a lemmatized and tagged version of the
SdeWaC corpus (Faaß and Eckart, 2013), a web
corpus of 880 million words. For linguistic pre-
processing we used the MATE parser (Bohnet,
2010), which allowed us to extract syntactic sub-
categorization frames.
</bodyText>
<subsectionHeader confidence="0.996541">
4.3 Feature Selection
</subsectionHeader>
<bodyText confidence="0.999957">
For each PV-BV pair we extracted two parallel sets
of features, one pertaining to the BV and one for
the PV. This allows us to model the syntactic trans-
fer. For example, we expected that an ideal trans-
fer from a group of transitive BVs to a group of
intransitive PVs should be reflected in high values
for the features BV:transitive and PV:intransitive5
and, in turn, low values for BV:intransitive and
PV:transitive.
We had two ways of selecting the feature types:
manually and automatically. For the manual fea-
ture selection we extracted only those features
from the parsed frames which we already used in
the creation of the gold standard and which are
listed in table 2. This resulted in a small feature
set of 30 features (15 features for PVs and BVs,
respectively). For the automatic feature selection
we simply used the n most frequent frames which
could be observed in the corpus for the set of verbs
of the gold standard.
From the syntactic dependency representation
provided by the parser, we excluded subjects and
modifiers (except for PP-modifiers) in the repre-
sentation of subcat frames. We did not use infor-
mation on subjects, because in German all verbs
have subjects, which may be implicit in the case
of subordinate clauses. We found that for this
reason that with the representation of subjects in
the extracted features no relevant information was
</bodyText>
<footnote confidence="0.479167">
5Note that transitive and transitive are only convenient
abreviations for the labels NPnom and NPnom+NPacc, which
are used in table2.
</footnote>
<bodyText confidence="0.999922714285714">
gained, but some distortion was introduced. Mod-
ifiers in the MATE parser represent information
which is too general to be good predictors. Based
on theoretical considerations on the best lexico-
graphic representation of verbs, we included PP-
modifiers, however, because quantitative informa-
tion on PP-adjuncts has proven successful next to
that of PP-arguments (Schulte im Walde, 2006a;
Joanis et al., 2008), and in addition the parser of-
ten distinguishes poorly between PP-modifiers and
PP-arguments.
In order to create an idealized artificial upper
bound, we also created a set of idealized ”lexico-
graphic” descriptions in the form of manually in-
stantiated feature vectors and feature values, us-
ing the manually selected feature configuration
we just described (and ultimately based on the
gold standard description represented by table 2).
These idealized vectors were also used for clus-
tering experiments in order to estimate an upper
bound.
</bodyText>
<subsectionHeader confidence="0.968419">
4.4 Clustering Methods
</subsectionHeader>
<bodyText confidence="0.999957733333333">
For the clustering experiments we used two dif-
ferent clustering algorithms: K-means and La-
tent Semantic Classes (LSC). K-means is a stan-
dard flat, hard-clustering algorithm; we used the
Weka implementation (Witten and Frank, 2005).
LSC (Rooth, 1998; Rooth et al., 1999) is a
two-dimensional soft-clustering algorithm which
learns three probability distributions: one for the
clusters, and one for the output probabilities of
each element and for each feature type with regard
to a cluster. The latter two (elements and features)
correspond to the two dimensions of the cluster-
ing. In our case the elements are the PV-BV pairs,
and the features are normalized counts of the sub-
categorization frames.
</bodyText>
<subsectionHeader confidence="0.972322">
4.5 Evaluation
</subsectionHeader>
<bodyText confidence="0.9992015">
Our feature vectors are a combination of the fea-
ture vector for the BV and the feature vector for
the PV of each PV-BV pair. Since the length of
each vector depends on the base frequency of each
verb we need to apply a feature normalization: we
simply reduce each feature to its unit vector of
length 1. Because the frequency ratio between BV
and PV may vary strongly, we need to normalize
PV vectors and BV vectors separately before they
can be combined.
The vector combination for each PV-BV pair is
done by simply adding the dimensions (and not the
</bodyText>
<page confidence="0.996529">
186
</page>
<table confidence="0.98499025">
an auf an+auf
Inter-annotator agreement 0.79 0.64 0.70
Average agreement between 0.73 0.74 0.73
annotators and gold standard
</table>
<tableCaption confidence="0.845588">
Table 1: Inter-annotator agreement and comparison of the gold standard to the ratings of 6 human anno-
tators (Fleiss’ Kappa Scores).
</tableCaption>
<figureCaption confidence="0.897804666666667">
Particle Typical frames Typical frames Semantic Verbs in Class
for the BV for the PV Class
an NPnom NPnom locative/ an|binden to tie at
+NPacc +NPacc relational an|ketten to chain at
+PP-an +PP-an tying
NPnom NPnom locative/ an|blicken to glance at
+PP-zu/in/ +NPacc relational an|gucken to look at
nach/auf gaze an|starren to stare at
NPnom NPnom ingressive an|brechen start to break
+NPacc +NPacc consump- an|reißen start to tear
+PP-mit +PP-mit tion an|schneiden start to cut
NPnom NPnom locative/ an|br¨ullen to roar at
+NPacc relational an|fauchen to hiss at
sound an|meckern to bleat at
NPnom NPnom locative/ an|heften to stick at
+NPacc +NPacc relational an|kleben to glue at
+PP-an fixation an|schrauben to screw at
auf NPnom NPnom locative auf|brodeln to bubble up
blaze- auf|flammen to light up
bubble auf|lodern to blaze up
auf|spudeln to bubble up
NPnom nach/auf locative auf|blicken to glance up
+PP-zu/in/ NPnom gaze auf|schauen to look up
auf|sehen to look up
NPnom NPnom locative/ auf|hetzen to instigate
+NPacc +NPacc dimensional auf|scheuchen to rouse
instigate
NPnom NPnom locative/ auf|heften to staple on
+NPacc +NPacc relational auf|kleben to glue on
+PP-auf fixation auf|pressen to press on
NPnom NPnom ingressive auf|br¨ullen suddenly roar
sound auf|heulen suddenly howl
auf|klingen suddenly sound
auf|kreischen suddenly scream
auf|schluchzen suddenly sob
auf|st¨ohnen suddenly moan
</figureCaption>
<tableCaption confidence="0.996268">
Table 2: The gold standard classes for the experiments, with subcategorization patterns.
</tableCaption>
<page confidence="0.939121">
187
</page>
<table confidence="0.999564466666667">
an auf an+auf
Purity RI ARI Purity RI ARI Purity RI ARI
Human 0.93 0.92 0.92
ratings
idealized features 0.83 0.91 0.70 0.88 0.92 0.72 0.93 0.97 8.2
(manually set)
K-means selected features 0.67 0.82 0.29 0.75 0.87 0.52 0.46 0.88 0.32
(extracted)
20 feat 0.58 0.74 0.18 0.69 0.69 0.40 0.43 0.88 0.14
50 feat 0.67 0.80 0.20 0.75 0.83 0.38 0.43 0.90 0.19
100 feat 0.67 0.79 0.18 0.75 0.83 0.40 0.49 0.90 0.21
200 feat 0.58 0.74 0.13 0.81 0.86 0.52 0.43 0.88 0.18
LSC selected features 0.63 0.78 0.22 0.80 0.85 0.55 0.85 0.92 0.59
(extracted)
Cutoff: 0.1
</table>
<tableCaption confidence="0.999967">
Table 3: Comparison of the results from different clustering methods and feature configurations.
</tableCaption>
<bodyText confidence="0.999807461538462">
dimension extensions) of the two vectors. In this
way, each subcategorization frame is represented
separately for the BV and the PV. For example,
the vectors for the intransitive frame will be repre-
sented as BV-intransitive and PV-intransitive.
We evaluated the clusterings in terms of Pu-
rity (Manning et al., 2008), Rand Index and Ad-
justed Rand Index (Rand, 1971; Hubert and Ara-
bie, 1985). Purity is a measure with values be-
tween 0 and 1 which captures the purity of indi-
vidual clusters in terms of the ratio between the
number of elements of the majority class in each
cluster and the total of elements in the cluster. A
perfect clustering will have a purity of 1. What Pu-
rity does not capture is the amount of clusters over
which each target class is distributed. That means
that also non-perfect clusters may achieve a Purity
of 1 if there are more clusters than target classes.
As long as the number of clusters is constant, how-
ever, purity is a good and intuitive approximation
to clustering evaluation.
The Rand Index (RI) looks at pairs of ele-
ments and assesses whether they have been cor-
rectly placed in the same cluster (which is correct
if they pertain to the same target class) or in dif-
ferent clusters (correct if they belong to different
target classes). RI is sensitive to the number of
non-empty clusters and can capture both the qual-
ity of individual clusters and the amount to which
elements of target categories have been grouped
together. RI looks as pair-wise decisions, which
makes it also applicable to the human ratings de-
scribed in section 4.1. The Adjusted Rand Index
(ARI) is a version of RI which is corrected for
chance. While RI has values between 0 and 1, ARI
can have negative values; 1 still represents a per-
fect clustering.
The Adjusted Rand Index (ARI) is a version of
RI which is corrected for chance. While RI has
values between 0 and 1, ARI can have negative
values; 1 still represents a perfect clustering.
We evaluated the clustering of the verbs with the
particles an and auf separately from each other,
since we have to expect that there is a different set
of semantic classes for each verb particle. We also
ran the same experiments for the gold standard as
a whole (an+auf), in order to test if we could find
some tendencies across clusters.
We set the number of clusters equal to the num-
ber of target categories from the gold standard.
This gave us 5 clusters for both the an-set and the
auf-set and 10 clusters for the classification of the
whole gold standard.
Note that LSC is a soft clustering algorithm. For
the evaluation of LSC clusters with respect to pu-
rity and RI and ARI, a conversion to hard clus-
tering must be done. We did this conversion by
simply applying a cutoff value for the output prob-
abilities for cluster membership. We tried out var-
ious cut-off levels and found that for the sets of an
and auf PVs the value of 0.1 gave a good trade-off
between coverage (the total number of elements
retained in all clusters) and ARI (cf also Table 4
below). This value is also the one used in K¨uhner
and Schulte im Walde (2010).
</bodyText>
<page confidence="0.998436">
188
</page>
<sectionHeader confidence="0.999878" genericHeader="method">
5 Results
</sectionHeader>
<bodyText confidence="0.984344307692308">
The comparison of the results from different meth-
ods can be seen in table 3. The strongest automati-
cally obtained results are printed in bold face. The
human rating scores are given in the first row and
allow for a direct comparison between automatic
clustering and human decisions.6 The second row
shows the artificial upper bound represented by the
manually set feature vectors as lexicographic en-
tries. Note that this is an artificial upper bound
and not an experimental result, even if obtained
by clustering.
The third row corresponds to the evaluation re-
sults for the manually selected corpus-based fea-
ture configuration used within K-means. They are
to be compared with the following rows concern-
ing the results based on automatically selected n
most frequent features. The last row shows the
results obtained with the LSC soft clustering al-
gorithm, applying a cutoff of 0.1 output probabil-
ity for cluster membership, again for the manu-
ally selected feature configuration. This result is
not fully comparable to the rows above, which are
obained with K-means or human ratings. Since
LSC is a soft clustering algorithm, there is a trade-
off between coverage and accuracy which depends
on the cutoff point selected for the conversion into
hard clusters.
Note that the Purity values are comparable
among each other since the number of clusters was
held constant. We always chose a number of clus-
ters equal to the number of target categories (5 cat-
egories for an, 5 for auf and 10 for an+auf).
Table 4 shows the results for LSC clustering
in more detail. The soft clusterings have to be
converted to hard clusterings. Because of this
the cut-off point within the conversion becomes
an important parameter. We chose here cut-off
points which correspond to the output probabil-
ity of cluster-elements (e.g. PV-BV pairs) with
regard to each cluster. The table shows a clear ten-
dency towards better ARI scores when higher cut-
off points are chosen. But this is counterbalanced
by the fact that for higher cutoff points less ele-
ments are retained. Below a certain cutoff-point
the total number of elements retaind is smaller
6RI is a measure which is based on pair-wise clustering
decisions, we were able to calculate these scores for the hu-
man ratings described in section 4.1. Since purity is not based
on a pair-wise decision, it was not applicable to the human
ratings. For the same reason ARI was also not adaptable to
the human rating scenario.
than the target set of verbs in the gold standard.
</bodyText>
<sectionHeader confidence="0.99772" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999948270833334">
It is not surprising that the manually defined fea-
ture configuration in our ”lexicographic” setting
perform best. These results are also similar to
those obtained by the human validation of the gold
standard. They do not get perfect scores of 1 be-
cause of small lexicographic differences concern-
ing individual entries. The automatic clustering
results relying on corpus-based features are worse,
as expected, but they still represent a very strong
tendency to group together PV-BV pairs into se-
mantic classes. We can achieve relatively high pu-
rity scores, thus demonstrating that our approach
is generally valid.
Concerning the feature selection for the corpus-
based data, the manually selected set seems to per-
form slightly better than the automatic feature se-
lection settings. Moreover, the manual selection
represents a more stable setting since automatic
selection seems to vary with the number n of fea-
tures. There appears to be no optimal setting for n
which gives the best results for all sets. For the an
set the local maximum is reached with the selec-
tion of the 50 or 100 most frequent subcat frames.
The selection of more or less features leads to
worse evaluation scores. For the auf set this lo-
cal maximum is reach with much higher values for
n. The manually created feature set, on the other
hand, always results in a relatively good perfor-
mance. This is also an expected result since the
feature selection already contains human linguis-
tic knowledge on which syntactic arguments rep-
resent the core set of the semantic roles which the
verbs can realize.
It is apparently surprising that for the joint gold
standard set an+auf LSC performs much better
than K-means. But this high ARI value comes at
the cost of a very low coverage. If we compare
this value to table 4, it can be seen that the cutoff
point of 0.1, which works very well for sets of an
and auf is inadequate for the set an+auf: only 20
verbs are retained in the converted clusters while
the target size is 32. While we can observe the
general tendency of LSC to perform on a roughly
comparable level to K-means, an exact compari-
son is hard to obtain with the used evaluation met-
rics. There are, nevertheless, possible problem set-
tings where soft clusters are more adequate, which
justifies to include LSC in this comparison.
</bodyText>
<page confidence="0.994783">
189
</page>
<table confidence="0.988059888888889">
an auf an+auf
Cutoff ARI nclust ARI nclust ARI nclust
0.07 0.17 25 0.39 22 0.31 40
0.08 0.18 23 0.55 20 0.39 32
0.09 0.19 21 0.55 20 0.56 23
0.10 0.22 19 0.55 20 0.59 20
0.11 0.30 16 0.5 19 0.48 17
0.12 0.30 16 0.41 16 0.56 16
nclasses 14 18 32
</table>
<tableCaption confidence="0.738784666666667">
Table 4: Evaluation with LSC using extracted selected features for different cutoff points (probabilities
of class membership) when creating hard clusters from soft clusters. (nclasses refers to the number of
elements across target classes, nclust refers to the number of elements across hard clusters.)
</tableCaption>
<bodyText confidence="0.999534052631579">
The class of anketten/anbinden tends to end up
in singleton clusters, especially anketten. We first
suspected that this is due to the fact that anket-
ten is a relatively infrequent verb and is repre-
sented by a sparse vector. But a comparison to
the human ratings reveals that human raters show
a similar and quite consistent disagreement with
the gold standad with respect to this the locative
relational tying and fixation classes. All 6 raters
judged anheften (a fixation verb) and anbinden
(a tying verb) as pertaining to the same category,
contrary to the gold standard. Interestingly, this
fixation-tying distinction is the only one, where
a majority of raters deviated in their judgements
from the gold standard at the same point. On the
other hand some of the raters were confused by the
fact the class of aufbrodeln combines two different
elements: water and fire. This did not affect the
majority of raters, nor was the disagreement con-
sistent, but it is reflected in the somewhat lower
inter-annotator agreement for the auf set (cf. table
1). These findings strongly suggest that the prob-
lem should be located in the gold standard rather
than in the clustering method.
Finally, is interesting to compare the automatic
clustering results to the human ratings from sec-
tion 4.1. The human annotation task was com-
plementary to the automatic clustering because
clustering was done on the basis of corpus-based
purely syntactic features while for the human rat-
ing the annotators focused on purely semantic in-
formation. Apart from the expectably worse per-
formance of an automatic clustering it can be con-
cluded that both information from the semantic
and the syntactic perspectives ultimately lead to
the creation of quite similar clusters, which is
probably the most important conclusion we can
draw from the experiment.
</bodyText>
<sectionHeader confidence="0.999286" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999754833333333">
In this paper we have shown that a pairwise clus-
tering of particle verbs in combination with their
base verbs can be done with success if syntac-
tic subcategorization frames for PVs and BVs are
taken as features separately. By combining the ex-
tracted subcategorization frame count from base
verbs and particle verbs as separate dimensions
in a common vector space, we are able to model
syntactic transfer patterns. We can also show that
within our setting we are able to replicate a gold
standard classification with a reasonable degree of
success when we apply various clustering algo-
rithms. The gold standard by itself can be vali-
dated by human judgements to a high degree. Hu-
man judges based their annotations on semantic
factors and still they converge largely with an au-
tomatic clustering which is purely based on syn-
tactic subcategorization.
In future work we plan to adress the problem
of finding correspondences between the syntactic
subcategorization slots, hence model the syntactic
transfer proper, and to investigate if the syntactic
transfer information can be used to predict the de-
gree of semantic compositionality of PVs.
</bodyText>
<sectionHeader confidence="0.997751" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999880714285714">
This work was funded by the DFG Research
Project ”Distributional Approaches to Semantic
Relatedness” (Stefan Bott, Sabine Schulte im
Walde), and the DFG Heisenberg Fellowship
SCHU-2580/1-1 (Sabine Schulte im Walde). We
would also like to thank the participants of the hu-
man rating experiment.
</bodyText>
<page confidence="0.996467">
190
</page>
<sectionHeader confidence="0.996338" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999949626168224">
Nadine Aldinger. 2004. Towards a Dynamic Lexi-
con: Predicting the Syntactic Argument Structure
of Complex Verbs. In Proceedings of the 4th In-
ternational Conference on Language Resources and
Evaluation, Lisbon, Portugal.
Timothy Baldwin and Aline Villavicencio. 2002. Ex-
tracting the Unextractable: A Case Study on Verb
Particles. In Proceedings of the Sixth Conference on
Computational Natural Language Learning, pages
98–104, Taipei, Taiwan.
Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and
Dominic Widdows. 2003. An Empirical Model
of Multiword Expression Decomposability. In Pro-
ceedings of the ACL-2003 Workshop on Multiword
Expressions: Analysis, Acquisition and Treatment,
pages 89–96, Sapporo, Japan.
Timothy Baldwin. 2005. Deep Lexical Acquisition of
Verb–Particle Constructions. Computer Speech and
Language, 19:398–414.
Collin Bannard. 2005. Learning about the Meaning of
Verb–Particle Constructions from Corpora. Com-
puter Speech and Language, 19:467–478.
Gertrud FaaB and Kerstin Eckart. 2013. SdeWaC –
a Corpus of Parsable Sentences from the Web. In
Proceedings of the International Conference of the
German Society for Computational Linguistics and
Language Technology, Darmstadt, Germany. To ap-
pear.
Wolfgang Fleischer and Irmhild Barz. 2012a. Wort-
bildung der deutschen Gegenwartssprache. de
Gruyter.
Wolfgang Fleischer and Irmhild Barz. 2012b. Wortbil-
dung der deutschen Gegenwartssprache. Walter de
Gruyter, 4th edition.
Joseph L. Fleiss. 1971. Measuring nominal scale
agreement among many raters. Psychological Bul-
letin, 76(5):378–382.
Silvana Hartmann. 2008. Einfluss syntaktischer und
semantischer Subkategorisierung auf die Komposi-
tionalit¨at von Partikelverben. Studienarbeit. Insti-
tut f¨ur Maschinelle Sprachverarbeitung, Universit¨at
Stuttgart. Supervision: Sabine Schulte im Walde and
Hans Kamp.
Lawrence Hubert and Phipps Arabie. 1985. Compar-
ing Partitions. Journal of Classification, 2:193–218.
Eric Joanis, Suzanne Stevenson, and David James.
2008. A General Feature Space for Automatic
Verb Classification. Natural Language Engineer-
ing, 14(3):337–367.
Hans Kamp and Uwe Reyle. 1993. From discourse to
logic: Introduction to modeltheoretic semantics of
natural language, formal logic and discourse repre-
sentation theory. Number 42. Springer.
Fritz Kliche. 2011. Semantic Variants of German Par-
ticle Verbs with ”ab”. Leuvense Bijdragen, 97:3–
27.
Anna Korhonen, Yuval Krymolowski, and Zvika Marx.
2003. Clustering Polysemic Subcategorization
Frame Distributions Semantically. In Proceedings
of the 41st Annual Meeting of the Association for
Computational Linguistics, pages 64–71, Sapporo,
Japan.
Natalie K¨uhner and Sabine Schulte im Walde. 2010.
Determining the Degree of Compositionality of Ger-
man Particle Verbs by Clustering Approaches. In
Proceedings of the 10th Conference on Natural Lan-
guage Processing, pages 47–56, Saarbr¨ucken, Ger-
many.
Andrea Lechler and Antje RoBdeutscher. 2009. Ger-
man Particle Verbs with auf. Reconstructing their
Composition in a DRT-based Framework. Linguis-
tische Berichte, 220.
Anke L¨udeling. 2001. On German Particle Verbs and
Similar Constructions in German. Dissertations in
Linguistics. CSLI Publications, Stanford, CA.
Christopher D Manning, Prabhakar Raghavan, and
Hinrich Sch¨utze. 2008. Introduction to informa-
tion retrieval, volume 1. Cambridge university press
Cambridge.
Diana McCarthy, Bill Keller, and John Carroll. 2003.
Detecting a Continuum of Compositionality in
Phrasal Verbs. In Proceedings of the ACL-SIGLEX
Workshop on Multiword Expressions: Analysis, Ac-
quisition and Treatment, Sapporo, Japan.
Paola Merlo and Suzanne Stevenson. 2001. Auto-
matic Verb Classification Based on Statistical Distri-
butions of Argument Structure. Computational Lin-
guistics, 27(3):373–408.
William M. Rand. 1971. Objective Criteria for the
Evaluation of Clustering Methods. Journal of the
American Statistical Association, 66(336):846–850.
Mats Rooth, Stefan Riezler, Detlef Prescher,
Glenn Carr oll, and Franz Beil. 1999. Inducing
a Semantically Annotated Lexicon via EM-Based
Clustering. In Proceedings of the 37th Annual
Meeting of the Association for Co mputational
Linguistics, Maryland, MD.
Mats Rooth. 1998. Two-Dimensional Clusters
in Grammatical Relations. In Inducing Lexicons
with the EM Algorithm, AIMS Report 4(3). Insti-
tut f¨ur Maschinelle Sprachverarbeitung, Universit¨at
Stuttgart.
Sabine Schulte im Walde. 2000. Clustering Verbs
Semantically According to their Alternation Be-
haviour. In Proceedings of the 18th International
Conference on Computational Linguistics, pages
747–753, Saarbr¨ucken, Germany.
</reference>
<page confidence="0.97879">
191
</page>
<reference confidence="0.999719891304348">
Sabine Schulte im Walde. 2004. Identification, Quan-
titative Description, and Preliminary Distributional
Analysis of German Particle Verbs. In Proceedings
of the COLING Workshop on Enhancing and Us-
ing Electronic Dictionaries, pages 85–88, Geneva,
Switzerland.
Sabine Schulte im Walde. 2005. Exploring Features
to Identify Semantic Nearest Neighbours: A Case
Study on German Particle Verbs. In Proceedings
of the International Conference on Recent Advances
in Natural Language Processing, pages 608–614,
Borovets, Bulgaria.
Sabine Schulte im Walde. 2006a. Experiments on
the Automatic Induction of German Semantic Verb
Classes. Computational Linguistics, 32(2):159–
194.
Sabine Schulte im Walde. 2006b. The Syntax-
Semantics Interface of German Particle Verbs.
Panel discussion at the 3rd ACL-SIGSEM Work-
shop on Prepositions at the 11th Conference of the
European Chapter of the Association for Computa-
tional Linguistics.
Sylvia Springorum, Sabine Schulte im Walde, and An-
tje Rol3deutscher. 2012. Automatic Classification of
German an Particle Verbs. In Proceedings of the 8th
International Conference on Language Resources
and Evaluation, pages 73–80, Istanbul, Turkey.
Sylvia Springorum, Sabine Schulte im Walde, and An-
tje Rol3deutscher. 2013. Sentence Generation and
Compositionality of Systematic Neologisms of Ger-
man Particle Verbs. Talk at the 5th Conference on
Quantitative Investigations in Theoretical Linguis-
tics.
Sylvia Springorum. 2011. DRT-based Analysis of the
German Verb Particle ”an”. Leuvense Bijdragen,
97:80–105.
Barbara Stiebels. 1996. Lexikalische Argumente und
Adjunkte. Zum semantischen Beitrag von verbalen
Pr¨afixen und Partikeln. Akademie Verlag, Berlin.
Aline Villavicencio. 2005. The Availability of Verb-
Particle Constructions in Lexical Resources: How
much is enough? Computer Speech &amp; Language,
19(4):415–432.
Ian H. Witten and Eibe Frank. 2005. Data Mining:
Practical Machine Learning Tools and Techniques
wi th Java Implementations. Morgan Kaufmann.
</reference>
<page confidence="0.998176">
192
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.415750">
<title confidence="0.9989205">Syntactic Transfer Patterns of German Particle Verbs and their Impact on Lexical Semantics</title>
<author confidence="0.999592">Stefan Bott Sabine Schulte im Walde</author>
<affiliation confidence="0.93365">Institut f¨ur Maschinelle Universit¨at</affiliation>
<address confidence="0.425079">Pfaffenwaldring 5b, 70569 Stuttgart,</address>
<abstract confidence="0.99958916">particle verbs, like combine a base verb a particle to form a special kind of Multi Word Expression. Particle verbs may share the semantics of the base verb and the particle to a variable degree. However, while syntactic subcategorization frames tend to be good predictor for the semantics of verbs in general (verbs that are similar in meaning also tend to have similar subcategorization frames and selectional preferences), there are regular changes in subcategorization frames by particle verbs with regard to the corresponding base verbs. This paper demonstrates that the syntactic behavior of particle verbs and base verbs together (modeling regular changes in subcategorization frames by particle verbs and corresponding base verbs) and applying clustering techniques allows us to distinguish particle verb meaning and shows the tight connection between transfer patterns and the semantic classes of particle verbs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nadine Aldinger</author>
</authors>
<title>Towards a Dynamic Lexicon: Predicting the Syntactic Argument Structure of Complex Verbs.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation,</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="11407" citStr="Aldinger (2004)" startWordPosition="1883" endWordPosition="1884"> verbs have been studied from the theoretical perspective and, to a more limited extend, from the aspect of the computational predictability of the degree of semantic compositionality (the transparency of their meaning with respect to the meaning of the base verb and the particle) and the semantic classifiabilty of PVs. For English, there is work on the automatic extraction of PVs from corpora (Baldwin and Villavicencio, 2002; Baldwin, 2005; Villavicencio, 2005) and the determination of compositionality (McCarthy et al., 2003; Baldwin et al., 2003; Bannard, 2005). To the best of our knowledge Aldinger (2004) is the first work that studies German PVs from a corpus based perspective, with an emphasis on the syntactic behavior and syntactic change. Schulte im Walde (2004), Schulte im Walde (2005) and Schulte im Walde (2006b) present preliminary distributional studies to explore salient features at the syntax-semantics interface that determine the semantic nearest neighbours of German PVs. Relying on the insights of those studies, Schulte im Walde (2006b) and Hartmann (2008) describe experiments which model the subcategorization transfer of German PVs with respect to their BVs in order to strengthen </context>
</contexts>
<marker>Aldinger, 2004</marker>
<rawString>Nadine Aldinger. 2004. Towards a Dynamic Lexicon: Predicting the Syntactic Argument Structure of Complex Verbs. In Proceedings of the 4th International Conference on Language Resources and Evaluation, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Aline Villavicencio</author>
</authors>
<title>Extracting the Unextractable: A Case Study on Verb Particles.</title>
<date>2002</date>
<booktitle>In Proceedings of the Sixth Conference on Computational Natural Language Learning,</booktitle>
<pages>98--104</pages>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="11221" citStr="Baldwin and Villavicencio, 2002" startWordPosition="1852" endWordPosition="1855">nd the semantic classes of PVs. There is only one more point to make: the classes shown in (2), could actually be seen as reflecting different meanings of the particle an itself. 3 Related Work Particle verbs have been studied from the theoretical perspective and, to a more limited extend, from the aspect of the computational predictability of the degree of semantic compositionality (the transparency of their meaning with respect to the meaning of the base verb and the particle) and the semantic classifiabilty of PVs. For English, there is work on the automatic extraction of PVs from corpora (Baldwin and Villavicencio, 2002; Baldwin, 2005; Villavicencio, 2005) and the determination of compositionality (McCarthy et al., 2003; Baldwin et al., 2003; Bannard, 2005). To the best of our knowledge Aldinger (2004) is the first work that studies German PVs from a corpus based perspective, with an emphasis on the syntactic behavior and syntactic change. Schulte im Walde (2004), Schulte im Walde (2005) and Schulte im Walde (2006b) present preliminary distributional studies to explore salient features at the syntax-semantics interface that determine the semantic nearest neighbours of German PVs. Relying on the insights of t</context>
</contexts>
<marker>Baldwin, Villavicencio, 2002</marker>
<rawString>Timothy Baldwin and Aline Villavicencio. 2002. Extracting the Unextractable: A Case Study on Verb Particles. In Proceedings of the Sixth Conference on Computational Natural Language Learning, pages 98–104, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Colin Bannard</author>
<author>Takaaki Tanaka</author>
<author>Dominic Widdows</author>
</authors>
<title>An Empirical Model of Multiword Expression Decomposability.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment,</booktitle>
<pages>89--96</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="11345" citStr="Baldwin et al., 2003" startWordPosition="1871" endWordPosition="1874">fferent meanings of the particle an itself. 3 Related Work Particle verbs have been studied from the theoretical perspective and, to a more limited extend, from the aspect of the computational predictability of the degree of semantic compositionality (the transparency of their meaning with respect to the meaning of the base verb and the particle) and the semantic classifiabilty of PVs. For English, there is work on the automatic extraction of PVs from corpora (Baldwin and Villavicencio, 2002; Baldwin, 2005; Villavicencio, 2005) and the determination of compositionality (McCarthy et al., 2003; Baldwin et al., 2003; Bannard, 2005). To the best of our knowledge Aldinger (2004) is the first work that studies German PVs from a corpus based perspective, with an emphasis on the syntactic behavior and syntactic change. Schulte im Walde (2004), Schulte im Walde (2005) and Schulte im Walde (2006b) present preliminary distributional studies to explore salient features at the syntax-semantics interface that determine the semantic nearest neighbours of German PVs. Relying on the insights of those studies, Schulte im Walde (2006b) and Hartmann (2008) describe experiments which model the subcategorization transfer o</context>
</contexts>
<marker>Baldwin, Bannard, Tanaka, Widdows, 2003</marker>
<rawString>Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and Dominic Widdows. 2003. An Empirical Model of Multiword Expression Decomposability. In Proceedings of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, pages 89–96, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
</authors>
<title>Deep Lexical Acquisition of Verb–Particle Constructions. Computer Speech and Language,</title>
<date>2005</date>
<contexts>
<context position="11236" citStr="Baldwin, 2005" startWordPosition="1856" endWordPosition="1857">here is only one more point to make: the classes shown in (2), could actually be seen as reflecting different meanings of the particle an itself. 3 Related Work Particle verbs have been studied from the theoretical perspective and, to a more limited extend, from the aspect of the computational predictability of the degree of semantic compositionality (the transparency of their meaning with respect to the meaning of the base verb and the particle) and the semantic classifiabilty of PVs. For English, there is work on the automatic extraction of PVs from corpora (Baldwin and Villavicencio, 2002; Baldwin, 2005; Villavicencio, 2005) and the determination of compositionality (McCarthy et al., 2003; Baldwin et al., 2003; Bannard, 2005). To the best of our knowledge Aldinger (2004) is the first work that studies German PVs from a corpus based perspective, with an emphasis on the syntactic behavior and syntactic change. Schulte im Walde (2004), Schulte im Walde (2005) and Schulte im Walde (2006b) present preliminary distributional studies to explore salient features at the syntax-semantics interface that determine the semantic nearest neighbours of German PVs. Relying on the insights of those studies, S</context>
</contexts>
<marker>Baldwin, 2005</marker>
<rawString>Timothy Baldwin. 2005. Deep Lexical Acquisition of Verb–Particle Constructions. Computer Speech and Language, 19:398–414.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin Bannard</author>
</authors>
<title>Learning about the Meaning of Verb–Particle Constructions from Corpora. Computer Speech and Language,</title>
<date>2005</date>
<contexts>
<context position="11361" citStr="Bannard, 2005" startWordPosition="1875" endWordPosition="1876">e particle an itself. 3 Related Work Particle verbs have been studied from the theoretical perspective and, to a more limited extend, from the aspect of the computational predictability of the degree of semantic compositionality (the transparency of their meaning with respect to the meaning of the base verb and the particle) and the semantic classifiabilty of PVs. For English, there is work on the automatic extraction of PVs from corpora (Baldwin and Villavicencio, 2002; Baldwin, 2005; Villavicencio, 2005) and the determination of compositionality (McCarthy et al., 2003; Baldwin et al., 2003; Bannard, 2005). To the best of our knowledge Aldinger (2004) is the first work that studies German PVs from a corpus based perspective, with an emphasis on the syntactic behavior and syntactic change. Schulte im Walde (2004), Schulte im Walde (2005) and Schulte im Walde (2006b) present preliminary distributional studies to explore salient features at the syntax-semantics interface that determine the semantic nearest neighbours of German PVs. Relying on the insights of those studies, Schulte im Walde (2006b) and Hartmann (2008) describe experiments which model the subcategorization transfer of German PVs wit</context>
</contexts>
<marker>Bannard, 2005</marker>
<rawString>Collin Bannard. 2005. Learning about the Meaning of Verb–Particle Constructions from Corpora. Computer Speech and Language, 19:467–478.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertrud FaaB</author>
<author>Kerstin Eckart</author>
</authors>
<title>SdeWaC – a Corpus of Parsable Sentences from the Web.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Conference of the German Society for Computational Linguistics and Language Technology,</booktitle>
<location>Darmstadt, Germany.</location>
<note>To appear.</note>
<marker>FaaB, Eckart, 2013</marker>
<rawString>Gertrud FaaB and Kerstin Eckart. 2013. SdeWaC – a Corpus of Parsable Sentences from the Web. In Proceedings of the International Conference of the German Society for Computational Linguistics and Language Technology, Darmstadt, Germany. To appear.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Wolfgang Fleischer</author>
<author>Irmhild Barz</author>
</authors>
<booktitle>2012a. Wortbildung der deutschen Gegenwartssprache. de Gruyter.</booktitle>
<marker>Fleischer, Barz, </marker>
<rawString>Wolfgang Fleischer and Irmhild Barz. 2012a. Wortbildung der deutschen Gegenwartssprache. de Gruyter.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Wolfgang Fleischer</author>
<author>Irmhild Barz</author>
</authors>
<booktitle>2012b. Wortbildung der deutschen Gegenwartssprache. Walter de Gruyter, 4th edition.</booktitle>
<marker>Fleischer, Barz, </marker>
<rawString>Wolfgang Fleischer and Irmhild Barz. 2012b. Wortbildung der deutschen Gegenwartssprache. Walter de Gruyter, 4th edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph L Fleiss</author>
</authors>
<title>Measuring nominal scale agreement among many raters.</title>
<date>1971</date>
<journal>Psychological Bulletin,</journal>
<volume>76</volume>
<issue>5</issue>
<contexts>
<context position="16328" citStr="Fleiss, 1971" startWordPosition="2711" endWordPosition="2712">that category). No pre-defined categories were given, nor were raters asked to provide a name or description for these categories. The annotators were asked to take the similarity of the BVs and the similarity of the PVs into consideration for their judgements. In order to avoid possible bias, the verbs were presented without given context. What is important here is that we did not ask them to take any syntactic criterion into consideration, the criterion we used for the initial compilation of the gold standard. The inter-annotator agreement was substantial with a Fleiss’ Kappa score of 0.68 (Fleiss, 1971).4 As a measure of agreement between raters and the previously created gold standard, we performed pair-wise calculations between the ratings of each annotator and the gold standard. For the comparison, the gold standard was transformed into PV pairs and the value true was assigned if the two verbs of a pairs belonged to the same category, and false otherwise. We calculated the Kappa scores for each annotator and took the average of the agreement scores. Table 1 resumes the comparison. Values are given for the parts of the gold standard corresponding to PVs with an and auf separately and also </context>
</contexts>
<marker>Fleiss, 1971</marker>
<rawString>Joseph L. Fleiss. 1971. Measuring nominal scale agreement among many raters. Psychological Bulletin, 76(5):378–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silvana Hartmann</author>
</authors>
<title>Einfluss syntaktischer und semantischer Subkategorisierung auf die Kompositionalit¨at von Partikelverben. Studienarbeit. Institut f¨ur Maschinelle Sprachverarbeitung, Universit¨at Stuttgart. Supervision: Sabine Schulte im Walde and</title>
<date>2008</date>
<contexts>
<context position="11879" citStr="Hartmann (2008)" startWordPosition="1957" endWordPosition="1958">he determination of compositionality (McCarthy et al., 2003; Baldwin et al., 2003; Bannard, 2005). To the best of our knowledge Aldinger (2004) is the first work that studies German PVs from a corpus based perspective, with an emphasis on the syntactic behavior and syntactic change. Schulte im Walde (2004), Schulte im Walde (2005) and Schulte im Walde (2006b) present preliminary distributional studies to explore salient features at the syntax-semantics interface that determine the semantic nearest neighbours of German PVs. Relying on the insights of those studies, Schulte im Walde (2006b) and Hartmann (2008) describe experiments which model the subcategorization transfer of German PVs with respect to their BVs in order to strengthen PV-BV distributional similarity. The main goal for them is to use transfer information in order to predict the degree of semantic compositionality of PVs. K¨uhner and Schulte im Walde (2010) use clustering to determine the degree of compositionality of German PVs, via common PV-BV cluster membership. They are, again, mainly interested in the assessment of compositionality, which is done on the basis of lexical information. They use syntactic information, but only as a</context>
</contexts>
<marker>Hartmann, 2008</marker>
<rawString>Silvana Hartmann. 2008. Einfluss syntaktischer und semantischer Subkategorisierung auf die Kompositionalit¨at von Partikelverben. Studienarbeit. Institut f¨ur Maschinelle Sprachverarbeitung, Universit¨at Stuttgart. Supervision: Sabine Schulte im Walde and Hans Kamp.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Hubert</author>
<author>Phipps Arabie</author>
</authors>
<title>Comparing Partitions.</title>
<date>1985</date>
<journal>Journal of Classification,</journal>
<pages>2--193</pages>
<contexts>
<context position="25002" citStr="Hubert and Arabie, 1985" startWordPosition="4124" endWordPosition="4128">t 0.58 0.74 0.13 0.81 0.86 0.52 0.43 0.88 0.18 LSC selected features 0.63 0.78 0.22 0.80 0.85 0.55 0.85 0.92 0.59 (extracted) Cutoff: 0.1 Table 3: Comparison of the results from different clustering methods and feature configurations. dimension extensions) of the two vectors. In this way, each subcategorization frame is represented separately for the BV and the PV. For example, the vectors for the intransitive frame will be represented as BV-intransitive and PV-intransitive. We evaluated the clusterings in terms of Purity (Manning et al., 2008), Rand Index and Adjusted Rand Index (Rand, 1971; Hubert and Arabie, 1985). Purity is a measure with values between 0 and 1 which captures the purity of individual clusters in terms of the ratio between the number of elements of the majority class in each cluster and the total of elements in the cluster. A perfect clustering will have a purity of 1. What Purity does not capture is the amount of clusters over which each target class is distributed. That means that also non-perfect clusters may achieve a Purity of 1 if there are more clusters than target classes. As long as the number of clusters is constant, however, purity is a good and intuitive approximation to cl</context>
</contexts>
<marker>Hubert, Arabie, 1985</marker>
<rawString>Lawrence Hubert and Phipps Arabie. 1985. Comparing Partitions. Journal of Classification, 2:193–218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Joanis</author>
<author>Suzanne Stevenson</author>
<author>David James</author>
</authors>
<title>A General Feature Space for Automatic Verb Classification.</title>
<date>2008</date>
<journal>Natural Language Engineering,</journal>
<volume>14</volume>
<issue>3</issue>
<contexts>
<context position="4305" citStr="Joanis et al., 2008" startWordPosition="682" endWordPosition="685">scht und wusste Bescheid. (‘He had listened at the wall and knew everything.’) seine his-acc Mutter mother an. PRT. Kind child blickt gazes 182 Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 182–192, Dublin, Ireland, August 23-24 2014. tactic subcategorization frames tend to be good predictors for the semantics of verbs in general: verbs that are similar in meaning also tend to have similar subcategorization frames and selectional preferences (Schulte im Walde, 2000; Merlo and Stevenson, 2001; Korhonen et al., 2003; Schulte im Walde, 2006a; Joanis et al., 2008). But, as we will show below, PV-BV pairs tend to have a special behavior with respect to their subcategorization, even if their meanings are closely related. Because we are interested in pairs of PVs and their BVs, we thus have to look at pairs of subcategorization preferences, and rely on the concept of syntactic transfer. We use syntactic transfer as a technical term here, which we define as regular changes in subcategorization frames by PVs and corresponding BVs, e.g., the incorporation or addition of complements of PVs in comparison to their BVs (Stiebels, 1996; L¨udeling, 2001; Fleischer</context>
<context position="20376" citStr="Joanis et al., 2008" startWordPosition="3386" endWordPosition="3389">representation of subjects in the extracted features no relevant information was 5Note that transitive and transitive are only convenient abreviations for the labels NPnom and NPnom+NPacc, which are used in table2. gained, but some distortion was introduced. Modifiers in the MATE parser represent information which is too general to be good predictors. Based on theoretical considerations on the best lexicographic representation of verbs, we included PPmodifiers, however, because quantitative information on PP-adjuncts has proven successful next to that of PP-arguments (Schulte im Walde, 2006a; Joanis et al., 2008), and in addition the parser often distinguishes poorly between PP-modifiers and PP-arguments. In order to create an idealized artificial upper bound, we also created a set of idealized ”lexicographic” descriptions in the form of manually instantiated feature vectors and feature values, using the manually selected feature configuration we just described (and ultimately based on the gold standard description represented by table 2). These idealized vectors were also used for clustering experiments in order to estimate an upper bound. 4.4 Clustering Methods For the clustering experiments we used</context>
</contexts>
<marker>Joanis, Stevenson, James, 2008</marker>
<rawString>Eric Joanis, Suzanne Stevenson, and David James. 2008. A General Feature Space for Automatic Verb Classification. Natural Language Engineering, 14(3):337–367.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
<author>Uwe Reyle</author>
</authors>
<title>From discourse to logic: Introduction to modeltheoretic semantics of natural language, formal logic and discourse representation theory.</title>
<date>1993</date>
<journal>Number</journal>
<volume>42</volume>
<publisher>Springer.</publisher>
<contexts>
<context position="8241" citStr="Kamp and Reyle, 1993" startWordPosition="1337" endWordPosition="1340">ls/hisses/scolds at B. d. A schneidet/bricht/reißt B an. A cuts/breaks/tears B PRT. A cuts/breaks/tears the first slice/piece of B. Such semantic classes are not easy to define and they are also difficult to induce automatically. Although there is general agreement in the theoretical literature that such semantic classes for PVs exist (cf. Lechler and Roßdeutscher (2009), Kliche (2011) and Springorum (2011)) the agreement on the number and nature of such classes is not very high. For example, Springorum (2011) (who develops her analysis within Discourse RepB B an. PRT. 183 resentation Theory (Kamp and Reyle, 1993)) distinguishes between 11 classes of PVs with the particle an, while Fleischer and Barz (2012b) only distinguish 3 major de-verbal classes, based on their aktionsart, which can be divided into some 9 minor classes.2 It should be noted that all the PVs and BVs in (2) a-d are not only quite homogeneous in their semantics; they also form coherent syntactic classes. The PVs and BVs of these examples are quite similar in the way they typically select their syntactic complements. For example, the BVs of (2-a) typically take a PP argument that expresses the direction of gaze using a prepositional ph</context>
<context position="13275" citStr="Kamp and Reyle, 1993" startWordPosition="2176" endWordPosition="2179"> obtained with information stemming from direct objects and PPobjects. The incorporation of syntactic informaseiner his-dat Mutter. mother. zu at blickt looks Kind child 184 tion in the form of dependency arc labels (concatenated with the head nouns) does not yield satisfactory results, putting the syntactic transfer problem in evidence, again. They conclude that an incorporation of syntactic transfer information between BVs and PVs could possibly improve the results. Based on a theoretical study (Springorum, 2011), which explains particle meanings in terms of Discourse Representation Theory (Kamp and Reyle, 1993), Springorum et al. (2012) show that four classes of PVs with the particle an can be classified automatically. They take a supervised approach using decision trees. The use of decision trees also allows them to manually inspect and analyze the decisions made by the classifier. As predictive features they use the head nouns of objects, generalized classes of these nouns and PP types. The approach we take here is not fully comparable to any of the former approaches, since we try to derive a semantic classification BV-PP pairs in an unsupervised manner and we only use syntactic features, stemming</context>
</contexts>
<marker>Kamp, Reyle, 1993</marker>
<rawString>Hans Kamp and Uwe Reyle. 1993. From discourse to logic: Introduction to modeltheoretic semantics of natural language, formal logic and discourse representation theory. Number 42. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fritz Kliche</author>
</authors>
<title>Semantic Variants of German Particle Verbs with ”ab”.</title>
<date>2011</date>
<journal>Leuvense Bijdragen,</journal>
<volume>97</volume>
<pages>27</pages>
<contexts>
<context position="8008" citStr="Kliche (2011)" startWordPosition="1299" endWordPosition="1300">ares/gazes B PRT. A looks/stares/gazes at B. b. A klebt/heftet/schraubt/nagelt B A glues/affixes/screws B an C an. at/onto C PRT. A glues/affixes/screws B onto C. c. A br¨ullt/faucht/bellt/meckert A roars/hisses/bleats A brawls/hisses/scolds at B. d. A schneidet/bricht/reißt B an. A cuts/breaks/tears B PRT. A cuts/breaks/tears the first slice/piece of B. Such semantic classes are not easy to define and they are also difficult to induce automatically. Although there is general agreement in the theoretical literature that such semantic classes for PVs exist (cf. Lechler and Roßdeutscher (2009), Kliche (2011) and Springorum (2011)) the agreement on the number and nature of such classes is not very high. For example, Springorum (2011) (who develops her analysis within Discourse RepB B an. PRT. 183 resentation Theory (Kamp and Reyle, 1993)) distinguishes between 11 classes of PVs with the particle an, while Fleischer and Barz (2012b) only distinguish 3 major de-verbal classes, based on their aktionsart, which can be divided into some 9 minor classes.2 It should be noted that all the PVs and BVs in (2) a-d are not only quite homogeneous in their semantics; they also form coherent syntactic classes. T</context>
</contexts>
<marker>Kliche, 2011</marker>
<rawString>Fritz Kliche. 2011. Semantic Variants of German Particle Verbs with ”ab”. Leuvense Bijdragen, 97:3– 27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Korhonen</author>
<author>Yuval Krymolowski</author>
<author>Zvika Marx</author>
</authors>
<title>Clustering Polysemic Subcategorization Frame Distributions Semantically.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>64--71</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="4258" citStr="Korhonen et al., 2003" startWordPosition="674" endWordPosition="677">ing could be found: Er hatte an der Wand angelauscht und wusste Bescheid. (‘He had listened at the wall and knew everything.’) seine his-acc Mutter mother an. PRT. Kind child blickt gazes 182 Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 182–192, Dublin, Ireland, August 23-24 2014. tactic subcategorization frames tend to be good predictors for the semantics of verbs in general: verbs that are similar in meaning also tend to have similar subcategorization frames and selectional preferences (Schulte im Walde, 2000; Merlo and Stevenson, 2001; Korhonen et al., 2003; Schulte im Walde, 2006a; Joanis et al., 2008). But, as we will show below, PV-BV pairs tend to have a special behavior with respect to their subcategorization, even if their meanings are closely related. Because we are interested in pairs of PVs and their BVs, we thus have to look at pairs of subcategorization preferences, and rely on the concept of syntactic transfer. We use syntactic transfer as a technical term here, which we define as regular changes in subcategorization frames by PVs and corresponding BVs, e.g., the incorporation or addition of complements of PVs in comparison to their </context>
</contexts>
<marker>Korhonen, Krymolowski, Marx, 2003</marker>
<rawString>Anna Korhonen, Yuval Krymolowski, and Zvika Marx. 2003. Clustering Polysemic Subcategorization Frame Distributions Semantically. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 64–71, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Natalie K¨uhner</author>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Determining the Degree of Compositionality of German Particle Verbs by Clustering Approaches.</title>
<date>2010</date>
<booktitle>In Proceedings of the 10th Conference on Natural Language Processing,</booktitle>
<pages>47--56</pages>
<location>Saarbr¨ucken, Germany.</location>
<marker>K¨uhner, Walde, 2010</marker>
<rawString>Natalie K¨uhner and Sabine Schulte im Walde. 2010. Determining the Degree of Compositionality of German Particle Verbs by Clustering Approaches. In Proceedings of the 10th Conference on Natural Language Processing, pages 47–56, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Lechler</author>
<author>Antje RoBdeutscher</author>
</authors>
<title>German Particle Verbs with auf. Reconstructing their Composition in a DRT-based Framework. Linguistische Berichte,</title>
<date>2009</date>
<pages>220</pages>
<marker>Lechler, RoBdeutscher, 2009</marker>
<rawString>Andrea Lechler and Antje RoBdeutscher. 2009. German Particle Verbs with auf. Reconstructing their Composition in a DRT-based Framework. Linguistische Berichte, 220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anke L¨udeling</author>
</authors>
<title>On German Particle Verbs and Similar Constructions in German. Dissertations in Linguistics.</title>
<date>2001</date>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA.</location>
<marker>L¨udeling, 2001</marker>
<rawString>Anke L¨udeling. 2001. On German Particle Verbs and Similar Constructions in German. Dissertations in Linguistics. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Introduction to information retrieval, volume 1. Cambridge university press Cambridge.</title>
<date>2008</date>
<marker>Manning, Raghavan, Sch¨utze, 2008</marker>
<rawString>Christopher D Manning, Prabhakar Raghavan, and Hinrich Sch¨utze. 2008. Introduction to information retrieval, volume 1. Cambridge university press Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Bill Keller</author>
<author>John Carroll</author>
</authors>
<title>Detecting a Continuum of Compositionality in Phrasal Verbs.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL-SIGLEX Workshop on Multiword Expressions: Analysis, Acquisition and Treatment,</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="11323" citStr="McCarthy et al., 2003" startWordPosition="1867" endWordPosition="1870">e seen as reflecting different meanings of the particle an itself. 3 Related Work Particle verbs have been studied from the theoretical perspective and, to a more limited extend, from the aspect of the computational predictability of the degree of semantic compositionality (the transparency of their meaning with respect to the meaning of the base verb and the particle) and the semantic classifiabilty of PVs. For English, there is work on the automatic extraction of PVs from corpora (Baldwin and Villavicencio, 2002; Baldwin, 2005; Villavicencio, 2005) and the determination of compositionality (McCarthy et al., 2003; Baldwin et al., 2003; Bannard, 2005). To the best of our knowledge Aldinger (2004) is the first work that studies German PVs from a corpus based perspective, with an emphasis on the syntactic behavior and syntactic change. Schulte im Walde (2004), Schulte im Walde (2005) and Schulte im Walde (2006b) present preliminary distributional studies to explore salient features at the syntax-semantics interface that determine the semantic nearest neighbours of German PVs. Relying on the insights of those studies, Schulte im Walde (2006b) and Hartmann (2008) describe experiments which model the subcat</context>
</contexts>
<marker>McCarthy, Keller, Carroll, 2003</marker>
<rawString>Diana McCarthy, Bill Keller, and John Carroll. 2003. Detecting a Continuum of Compositionality in Phrasal Verbs. In Proceedings of the ACL-SIGLEX Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Merlo</author>
<author>Suzanne Stevenson</author>
</authors>
<date>2001</date>
<booktitle>Automatic Verb Classification Based on Statistical Distributions of Argument Structure. Computational Linguistics,</booktitle>
<pages>27--3</pages>
<contexts>
<context position="4235" citStr="Merlo and Stevenson, 2001" startWordPosition="670" endWordPosition="673"> senentence like the following could be found: Er hatte an der Wand angelauscht und wusste Bescheid. (‘He had listened at the wall and knew everything.’) seine his-acc Mutter mother an. PRT. Kind child blickt gazes 182 Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 182–192, Dublin, Ireland, August 23-24 2014. tactic subcategorization frames tend to be good predictors for the semantics of verbs in general: verbs that are similar in meaning also tend to have similar subcategorization frames and selectional preferences (Schulte im Walde, 2000; Merlo and Stevenson, 2001; Korhonen et al., 2003; Schulte im Walde, 2006a; Joanis et al., 2008). But, as we will show below, PV-BV pairs tend to have a special behavior with respect to their subcategorization, even if their meanings are closely related. Because we are interested in pairs of PVs and their BVs, we thus have to look at pairs of subcategorization preferences, and rely on the concept of syntactic transfer. We use syntactic transfer as a technical term here, which we define as regular changes in subcategorization frames by PVs and corresponding BVs, e.g., the incorporation or addition of complements of PVs </context>
</contexts>
<marker>Merlo, Stevenson, 2001</marker>
<rawString>Paola Merlo and Suzanne Stevenson. 2001. Automatic Verb Classification Based on Statistical Distributions of Argument Structure. Computational Linguistics, 27(3):373–408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William M Rand</author>
</authors>
<title>Objective Criteria for the Evaluation of Clustering Methods.</title>
<date>1971</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>66</volume>
<issue>336</issue>
<contexts>
<context position="24976" citStr="Rand, 1971" startWordPosition="4122" endWordPosition="4123">0.21 200 feat 0.58 0.74 0.13 0.81 0.86 0.52 0.43 0.88 0.18 LSC selected features 0.63 0.78 0.22 0.80 0.85 0.55 0.85 0.92 0.59 (extracted) Cutoff: 0.1 Table 3: Comparison of the results from different clustering methods and feature configurations. dimension extensions) of the two vectors. In this way, each subcategorization frame is represented separately for the BV and the PV. For example, the vectors for the intransitive frame will be represented as BV-intransitive and PV-intransitive. We evaluated the clusterings in terms of Purity (Manning et al., 2008), Rand Index and Adjusted Rand Index (Rand, 1971; Hubert and Arabie, 1985). Purity is a measure with values between 0 and 1 which captures the purity of individual clusters in terms of the ratio between the number of elements of the majority class in each cluster and the total of elements in the cluster. A perfect clustering will have a purity of 1. What Purity does not capture is the amount of clusters over which each target class is distributed. That means that also non-perfect clusters may achieve a Purity of 1 if there are more clusters than target classes. As long as the number of clusters is constant, however, purity is a good and int</context>
</contexts>
<marker>Rand, 1971</marker>
<rawString>William M. Rand. 1971. Objective Criteria for the Evaluation of Clustering Methods. Journal of the American Statistical Association, 66(336):846–850.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Rooth</author>
<author>Stefan Riezler</author>
<author>Detlef Prescher</author>
<author>Glenn Carr oll</author>
<author>Franz Beil</author>
</authors>
<title>Inducing a Semantically Annotated Lexicon via EM-Based Clustering.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Co mputational Linguistics,</booktitle>
<location>Maryland, MD.</location>
<contexts>
<context position="21207" citStr="Rooth et al., 1999" startWordPosition="3514" endWordPosition="3517">ns in the form of manually instantiated feature vectors and feature values, using the manually selected feature configuration we just described (and ultimately based on the gold standard description represented by table 2). These idealized vectors were also used for clustering experiments in order to estimate an upper bound. 4.4 Clustering Methods For the clustering experiments we used two different clustering algorithms: K-means and Latent Semantic Classes (LSC). K-means is a standard flat, hard-clustering algorithm; we used the Weka implementation (Witten and Frank, 2005). LSC (Rooth, 1998; Rooth et al., 1999) is a two-dimensional soft-clustering algorithm which learns three probability distributions: one for the clusters, and one for the output probabilities of each element and for each feature type with regard to a cluster. The latter two (elements and features) correspond to the two dimensions of the clustering. In our case the elements are the PV-BV pairs, and the features are normalized counts of the subcategorization frames. 4.5 Evaluation Our feature vectors are a combination of the feature vector for the BV and the feature vector for the PV of each PV-BV pair. Since the length of each vecto</context>
</contexts>
<marker>Rooth, Riezler, Prescher, oll, Beil, 1999</marker>
<rawString>Mats Rooth, Stefan Riezler, Detlef Prescher, Glenn Carr oll, and Franz Beil. 1999. Inducing a Semantically Annotated Lexicon via EM-Based Clustering. In Proceedings of the 37th Annual Meeting of the Association for Co mputational Linguistics, Maryland, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Rooth</author>
</authors>
<title>Two-Dimensional Clusters in Grammatical Relations.</title>
<date>1998</date>
<booktitle>In Inducing Lexicons with the EM Algorithm, AIMS Report 4(3). Institut f¨ur Maschinelle Sprachverarbeitung,</booktitle>
<location>Universit¨at Stuttgart.</location>
<contexts>
<context position="21186" citStr="Rooth, 1998" startWordPosition="3512" endWordPosition="3513">c” descriptions in the form of manually instantiated feature vectors and feature values, using the manually selected feature configuration we just described (and ultimately based on the gold standard description represented by table 2). These idealized vectors were also used for clustering experiments in order to estimate an upper bound. 4.4 Clustering Methods For the clustering experiments we used two different clustering algorithms: K-means and Latent Semantic Classes (LSC). K-means is a standard flat, hard-clustering algorithm; we used the Weka implementation (Witten and Frank, 2005). LSC (Rooth, 1998; Rooth et al., 1999) is a two-dimensional soft-clustering algorithm which learns three probability distributions: one for the clusters, and one for the output probabilities of each element and for each feature type with regard to a cluster. The latter two (elements and features) correspond to the two dimensions of the clustering. In our case the elements are the PV-BV pairs, and the features are normalized counts of the subcategorization frames. 4.5 Evaluation Our feature vectors are a combination of the feature vector for the BV and the feature vector for the PV of each PV-BV pair. Since the</context>
</contexts>
<marker>Rooth, 1998</marker>
<rawString>Mats Rooth. 1998. Two-Dimensional Clusters in Grammatical Relations. In Inducing Lexicons with the EM Algorithm, AIMS Report 4(3). Institut f¨ur Maschinelle Sprachverarbeitung, Universit¨at Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Clustering Verbs Semantically According to their Alternation Behaviour.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics,</booktitle>
<pages>747--753</pages>
<location>Saarbr¨ucken, Germany.</location>
<contexts>
<context position="4208" citStr="Walde, 2000" startWordPosition="668" endWordPosition="669">the particle, senentence like the following could be found: Er hatte an der Wand angelauscht und wusste Bescheid. (‘He had listened at the wall and knew everything.’) seine his-acc Mutter mother an. PRT. Kind child blickt gazes 182 Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 182–192, Dublin, Ireland, August 23-24 2014. tactic subcategorization frames tend to be good predictors for the semantics of verbs in general: verbs that are similar in meaning also tend to have similar subcategorization frames and selectional preferences (Schulte im Walde, 2000; Merlo and Stevenson, 2001; Korhonen et al., 2003; Schulte im Walde, 2006a; Joanis et al., 2008). But, as we will show below, PV-BV pairs tend to have a special behavior with respect to their subcategorization, even if their meanings are closely related. Because we are interested in pairs of PVs and their BVs, we thus have to look at pairs of subcategorization preferences, and rely on the concept of syntactic transfer. We use syntactic transfer as a technical term here, which we define as regular changes in subcategorization frames by PVs and corresponding BVs, e.g., the incorporation or addi</context>
</contexts>
<marker>Walde, 2000</marker>
<rawString>Sabine Schulte im Walde. 2000. Clustering Verbs Semantically According to their Alternation Behaviour. In Proceedings of the 18th International Conference on Computational Linguistics, pages 747–753, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Identification, Quantitative Description, and Preliminary Distributional Analysis of German Particle Verbs.</title>
<date>2004</date>
<booktitle>In Proceedings of the COLING Workshop on Enhancing and Using Electronic Dictionaries,</booktitle>
<pages>85--88</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="11571" citStr="Walde (2004)" startWordPosition="1910" endWordPosition="1911">compositionality (the transparency of their meaning with respect to the meaning of the base verb and the particle) and the semantic classifiabilty of PVs. For English, there is work on the automatic extraction of PVs from corpora (Baldwin and Villavicencio, 2002; Baldwin, 2005; Villavicencio, 2005) and the determination of compositionality (McCarthy et al., 2003; Baldwin et al., 2003; Bannard, 2005). To the best of our knowledge Aldinger (2004) is the first work that studies German PVs from a corpus based perspective, with an emphasis on the syntactic behavior and syntactic change. Schulte im Walde (2004), Schulte im Walde (2005) and Schulte im Walde (2006b) present preliminary distributional studies to explore salient features at the syntax-semantics interface that determine the semantic nearest neighbours of German PVs. Relying on the insights of those studies, Schulte im Walde (2006b) and Hartmann (2008) describe experiments which model the subcategorization transfer of German PVs with respect to their BVs in order to strengthen PV-BV distributional similarity. The main goal for them is to use transfer information in order to predict the degree of semantic compositionality of PVs. K¨uhner a</context>
</contexts>
<marker>Walde, 2004</marker>
<rawString>Sabine Schulte im Walde. 2004. Identification, Quantitative Description, and Preliminary Distributional Analysis of German Particle Verbs. In Proceedings of the COLING Workshop on Enhancing and Using Electronic Dictionaries, pages 85–88, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Exploring Features to Identify Semantic Nearest Neighbours: A Case Study on German Particle Verbs.</title>
<date>2005</date>
<booktitle>In Proceedings of the International Conference on Recent Advances in Natural Language Processing,</booktitle>
<pages>608--614</pages>
<location>Borovets, Bulgaria.</location>
<contexts>
<context position="11596" citStr="Walde (2005)" startWordPosition="1914" endWordPosition="1915">nsparency of their meaning with respect to the meaning of the base verb and the particle) and the semantic classifiabilty of PVs. For English, there is work on the automatic extraction of PVs from corpora (Baldwin and Villavicencio, 2002; Baldwin, 2005; Villavicencio, 2005) and the determination of compositionality (McCarthy et al., 2003; Baldwin et al., 2003; Bannard, 2005). To the best of our knowledge Aldinger (2004) is the first work that studies German PVs from a corpus based perspective, with an emphasis on the syntactic behavior and syntactic change. Schulte im Walde (2004), Schulte im Walde (2005) and Schulte im Walde (2006b) present preliminary distributional studies to explore salient features at the syntax-semantics interface that determine the semantic nearest neighbours of German PVs. Relying on the insights of those studies, Schulte im Walde (2006b) and Hartmann (2008) describe experiments which model the subcategorization transfer of German PVs with respect to their BVs in order to strengthen PV-BV distributional similarity. The main goal for them is to use transfer information in order to predict the degree of semantic compositionality of PVs. K¨uhner and Schulte im Walde (2010</context>
</contexts>
<marker>Walde, 2005</marker>
<rawString>Sabine Schulte im Walde. 2005. Exploring Features to Identify Semantic Nearest Neighbours: A Case Study on German Particle Verbs. In Proceedings of the International Conference on Recent Advances in Natural Language Processing, pages 608–614, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>Experiments on the Automatic Induction of German Semantic Verb Classes.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>2</issue>
<pages>194</pages>
<contexts>
<context position="4282" citStr="Walde, 2006" startWordPosition="680" endWordPosition="681">r Wand angelauscht und wusste Bescheid. (‘He had listened at the wall and knew everything.’) seine his-acc Mutter mother an. PRT. Kind child blickt gazes 182 Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 182–192, Dublin, Ireland, August 23-24 2014. tactic subcategorization frames tend to be good predictors for the semantics of verbs in general: verbs that are similar in meaning also tend to have similar subcategorization frames and selectional preferences (Schulte im Walde, 2000; Merlo and Stevenson, 2001; Korhonen et al., 2003; Schulte im Walde, 2006a; Joanis et al., 2008). But, as we will show below, PV-BV pairs tend to have a special behavior with respect to their subcategorization, even if their meanings are closely related. Because we are interested in pairs of PVs and their BVs, we thus have to look at pairs of subcategorization preferences, and rely on the concept of syntactic transfer. We use syntactic transfer as a technical term here, which we define as regular changes in subcategorization frames by PVs and corresponding BVs, e.g., the incorporation or addition of complements of PVs in comparison to their BVs (Stiebels, 1996; L¨u</context>
<context position="11623" citStr="Walde (2006" startWordPosition="1919" endWordPosition="1920">ith respect to the meaning of the base verb and the particle) and the semantic classifiabilty of PVs. For English, there is work on the automatic extraction of PVs from corpora (Baldwin and Villavicencio, 2002; Baldwin, 2005; Villavicencio, 2005) and the determination of compositionality (McCarthy et al., 2003; Baldwin et al., 2003; Bannard, 2005). To the best of our knowledge Aldinger (2004) is the first work that studies German PVs from a corpus based perspective, with an emphasis on the syntactic behavior and syntactic change. Schulte im Walde (2004), Schulte im Walde (2005) and Schulte im Walde (2006b) present preliminary distributional studies to explore salient features at the syntax-semantics interface that determine the semantic nearest neighbours of German PVs. Relying on the insights of those studies, Schulte im Walde (2006b) and Hartmann (2008) describe experiments which model the subcategorization transfer of German PVs with respect to their BVs in order to strengthen PV-BV distributional similarity. The main goal for them is to use transfer information in order to predict the degree of semantic compositionality of PVs. K¨uhner and Schulte im Walde (2010) use clustering to determi</context>
<context position="20353" citStr="Walde, 2006" startWordPosition="3384" endWordPosition="3385">that with the representation of subjects in the extracted features no relevant information was 5Note that transitive and transitive are only convenient abreviations for the labels NPnom and NPnom+NPacc, which are used in table2. gained, but some distortion was introduced. Modifiers in the MATE parser represent information which is too general to be good predictors. Based on theoretical considerations on the best lexicographic representation of verbs, we included PPmodifiers, however, because quantitative information on PP-adjuncts has proven successful next to that of PP-arguments (Schulte im Walde, 2006a; Joanis et al., 2008), and in addition the parser often distinguishes poorly between PP-modifiers and PP-arguments. In order to create an idealized artificial upper bound, we also created a set of idealized ”lexicographic” descriptions in the form of manually instantiated feature vectors and feature values, using the manually selected feature configuration we just described (and ultimately based on the gold standard description represented by table 2). These idealized vectors were also used for clustering experiments in order to estimate an upper bound. 4.4 Clustering Methods For the cluster</context>
</contexts>
<marker>Walde, 2006</marker>
<rawString>Sabine Schulte im Walde. 2006a. Experiments on the Automatic Induction of German Semantic Verb Classes. Computational Linguistics, 32(2):159– 194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>The SyntaxSemantics Interface of German Particle Verbs.</title>
<date>2006</date>
<booktitle>Panel discussion at the 3rd ACL-SIGSEM Workshop on Prepositions at the 11th Conference of the European Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="4282" citStr="Walde, 2006" startWordPosition="680" endWordPosition="681">r Wand angelauscht und wusste Bescheid. (‘He had listened at the wall and knew everything.’) seine his-acc Mutter mother an. PRT. Kind child blickt gazes 182 Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 182–192, Dublin, Ireland, August 23-24 2014. tactic subcategorization frames tend to be good predictors for the semantics of verbs in general: verbs that are similar in meaning also tend to have similar subcategorization frames and selectional preferences (Schulte im Walde, 2000; Merlo and Stevenson, 2001; Korhonen et al., 2003; Schulte im Walde, 2006a; Joanis et al., 2008). But, as we will show below, PV-BV pairs tend to have a special behavior with respect to their subcategorization, even if their meanings are closely related. Because we are interested in pairs of PVs and their BVs, we thus have to look at pairs of subcategorization preferences, and rely on the concept of syntactic transfer. We use syntactic transfer as a technical term here, which we define as regular changes in subcategorization frames by PVs and corresponding BVs, e.g., the incorporation or addition of complements of PVs in comparison to their BVs (Stiebels, 1996; L¨u</context>
<context position="11623" citStr="Walde (2006" startWordPosition="1919" endWordPosition="1920">ith respect to the meaning of the base verb and the particle) and the semantic classifiabilty of PVs. For English, there is work on the automatic extraction of PVs from corpora (Baldwin and Villavicencio, 2002; Baldwin, 2005; Villavicencio, 2005) and the determination of compositionality (McCarthy et al., 2003; Baldwin et al., 2003; Bannard, 2005). To the best of our knowledge Aldinger (2004) is the first work that studies German PVs from a corpus based perspective, with an emphasis on the syntactic behavior and syntactic change. Schulte im Walde (2004), Schulte im Walde (2005) and Schulte im Walde (2006b) present preliminary distributional studies to explore salient features at the syntax-semantics interface that determine the semantic nearest neighbours of German PVs. Relying on the insights of those studies, Schulte im Walde (2006b) and Hartmann (2008) describe experiments which model the subcategorization transfer of German PVs with respect to their BVs in order to strengthen PV-BV distributional similarity. The main goal for them is to use transfer information in order to predict the degree of semantic compositionality of PVs. K¨uhner and Schulte im Walde (2010) use clustering to determi</context>
<context position="20353" citStr="Walde, 2006" startWordPosition="3384" endWordPosition="3385">that with the representation of subjects in the extracted features no relevant information was 5Note that transitive and transitive are only convenient abreviations for the labels NPnom and NPnom+NPacc, which are used in table2. gained, but some distortion was introduced. Modifiers in the MATE parser represent information which is too general to be good predictors. Based on theoretical considerations on the best lexicographic representation of verbs, we included PPmodifiers, however, because quantitative information on PP-adjuncts has proven successful next to that of PP-arguments (Schulte im Walde, 2006a; Joanis et al., 2008), and in addition the parser often distinguishes poorly between PP-modifiers and PP-arguments. In order to create an idealized artificial upper bound, we also created a set of idealized ”lexicographic” descriptions in the form of manually instantiated feature vectors and feature values, using the manually selected feature configuration we just described (and ultimately based on the gold standard description represented by table 2). These idealized vectors were also used for clustering experiments in order to estimate an upper bound. 4.4 Clustering Methods For the cluster</context>
</contexts>
<marker>Walde, 2006</marker>
<rawString>Sabine Schulte im Walde. 2006b. The SyntaxSemantics Interface of German Particle Verbs. Panel discussion at the 3rd ACL-SIGSEM Workshop on Prepositions at the 11th Conference of the European Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sylvia Springorum</author>
<author>Sabine Schulte im Walde</author>
<author>Antje Rol3deutscher</author>
</authors>
<title>Automatic Classification of German an Particle Verbs.</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th International Conference on Language Resources and Evaluation,</booktitle>
<pages>73--80</pages>
<location>Istanbul, Turkey.</location>
<marker>Springorum, Walde, Rol3deutscher, 2012</marker>
<rawString>Sylvia Springorum, Sabine Schulte im Walde, and Antje Rol3deutscher. 2012. Automatic Classification of German an Particle Verbs. In Proceedings of the 8th International Conference on Language Resources and Evaluation, pages 73–80, Istanbul, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sylvia Springorum</author>
<author>Sabine Schulte im Walde</author>
<author>Antje Rol3deutscher</author>
</authors>
<date>2013</date>
<booktitle>Sentence Generation and Compositionality of Systematic Neologisms of German Particle Verbs. Talk at the 5th Conference on Quantitative Investigations in Theoretical Linguistics.</booktitle>
<marker>Springorum, Walde, Rol3deutscher, 2013</marker>
<rawString>Sylvia Springorum, Sabine Schulte im Walde, and Antje Rol3deutscher. 2013. Sentence Generation and Compositionality of Systematic Neologisms of German Particle Verbs. Talk at the 5th Conference on Quantitative Investigations in Theoretical Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sylvia Springorum</author>
</authors>
<title>DRT-based Analysis of the German Verb Particle ”an”. Leuvense Bijdragen,</title>
<date>2011</date>
<pages>97--80</pages>
<contexts>
<context position="8030" citStr="Springorum (2011)" startWordPosition="1302" endWordPosition="1303">A looks/stares/gazes at B. b. A klebt/heftet/schraubt/nagelt B A glues/affixes/screws B an C an. at/onto C PRT. A glues/affixes/screws B onto C. c. A br¨ullt/faucht/bellt/meckert A roars/hisses/bleats A brawls/hisses/scolds at B. d. A schneidet/bricht/reißt B an. A cuts/breaks/tears B PRT. A cuts/breaks/tears the first slice/piece of B. Such semantic classes are not easy to define and they are also difficult to induce automatically. Although there is general agreement in the theoretical literature that such semantic classes for PVs exist (cf. Lechler and Roßdeutscher (2009), Kliche (2011) and Springorum (2011)) the agreement on the number and nature of such classes is not very high. For example, Springorum (2011) (who develops her analysis within Discourse RepB B an. PRT. 183 resentation Theory (Kamp and Reyle, 1993)) distinguishes between 11 classes of PVs with the particle an, while Fleischer and Barz (2012b) only distinguish 3 major de-verbal classes, based on their aktionsart, which can be divided into some 9 minor classes.2 It should be noted that all the PVs and BVs in (2) a-d are not only quite homogeneous in their semantics; they also form coherent syntactic classes. The PVs and BVs of thes</context>
<context position="13174" citStr="Springorum, 2011" startWordPosition="2164" endWordPosition="2165">elected argument slots to certain syntactic functions. They conclude that the best results can be obtained with information stemming from direct objects and PPobjects. The incorporation of syntactic informaseiner his-dat Mutter. mother. zu at blickt looks Kind child 184 tion in the form of dependency arc labels (concatenated with the head nouns) does not yield satisfactory results, putting the syntactic transfer problem in evidence, again. They conclude that an incorporation of syntactic transfer information between BVs and PVs could possibly improve the results. Based on a theoretical study (Springorum, 2011), which explains particle meanings in terms of Discourse Representation Theory (Kamp and Reyle, 1993), Springorum et al. (2012) show that four classes of PVs with the particle an can be classified automatically. They take a supervised approach using decision trees. The use of decision trees also allows them to manually inspect and analyze the decisions made by the classifier. As predictive features they use the head nouns of objects, generalized classes of these nouns and PP types. The approach we take here is not fully comparable to any of the former approaches, since we try to derive a seman</context>
</contexts>
<marker>Springorum, 2011</marker>
<rawString>Sylvia Springorum. 2011. DRT-based Analysis of the German Verb Particle ”an”. Leuvense Bijdragen, 97:80–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Stiebels</author>
</authors>
<title>Lexikalische Argumente und Adjunkte. Zum semantischen Beitrag von verbalen Pr¨afixen und Partikeln.</title>
<date>1996</date>
<publisher>Akademie Verlag,</publisher>
<location>Berlin.</location>
<contexts>
<context position="4877" citStr="Stiebels, 1996" startWordPosition="781" endWordPosition="782">ulte im Walde, 2006a; Joanis et al., 2008). But, as we will show below, PV-BV pairs tend to have a special behavior with respect to their subcategorization, even if their meanings are closely related. Because we are interested in pairs of PVs and their BVs, we thus have to look at pairs of subcategorization preferences, and rely on the concept of syntactic transfer. We use syntactic transfer as a technical term here, which we define as regular changes in subcategorization frames by PVs and corresponding BVs, e.g., the incorporation or addition of complements of PVs in comparison to their BVs (Stiebels, 1996; L¨udeling, 2001; Fleischer and Barz, 2012a). We claim that the syntactic behavior of PVs and BVs together allows us to distinguish semantic classes. A better understanding of the nature of the connection between syntactic transfer patterns and semantic classes may be beneficial for both theoretical and computational linguistics. On the theoretical side we can hope to find new arguments to guide and justify lexical semantic classifications. We may also shed light on what particles actually mean, a topic which is not trivial by itself. In computational semantics, a better understanding of synt</context>
</contexts>
<marker>Stiebels, 1996</marker>
<rawString>Barbara Stiebels. 1996. Lexikalische Argumente und Adjunkte. Zum semantischen Beitrag von verbalen Pr¨afixen und Partikeln. Akademie Verlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aline Villavicencio</author>
</authors>
<title>The Availability of VerbParticle Constructions in Lexical Resources: How much is enough?</title>
<date>2005</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>19</volume>
<issue>4</issue>
<contexts>
<context position="11258" citStr="Villavicencio, 2005" startWordPosition="1858" endWordPosition="1860">e more point to make: the classes shown in (2), could actually be seen as reflecting different meanings of the particle an itself. 3 Related Work Particle verbs have been studied from the theoretical perspective and, to a more limited extend, from the aspect of the computational predictability of the degree of semantic compositionality (the transparency of their meaning with respect to the meaning of the base verb and the particle) and the semantic classifiabilty of PVs. For English, there is work on the automatic extraction of PVs from corpora (Baldwin and Villavicencio, 2002; Baldwin, 2005; Villavicencio, 2005) and the determination of compositionality (McCarthy et al., 2003; Baldwin et al., 2003; Bannard, 2005). To the best of our knowledge Aldinger (2004) is the first work that studies German PVs from a corpus based perspective, with an emphasis on the syntactic behavior and syntactic change. Schulte im Walde (2004), Schulte im Walde (2005) and Schulte im Walde (2006b) present preliminary distributional studies to explore salient features at the syntax-semantics interface that determine the semantic nearest neighbours of German PVs. Relying on the insights of those studies, Schulte im Walde (2006b</context>
</contexts>
<marker>Villavicencio, 2005</marker>
<rawString>Aline Villavicencio. 2005. The Availability of VerbParticle Constructions in Lexical Resources: How much is enough? Computer Speech &amp; Language, 19(4):415–432.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
</authors>
<date>2005</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques wi th Java Implementations.</booktitle>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="21168" citStr="Witten and Frank, 2005" startWordPosition="3507" endWordPosition="3510">set of idealized ”lexicographic” descriptions in the form of manually instantiated feature vectors and feature values, using the manually selected feature configuration we just described (and ultimately based on the gold standard description represented by table 2). These idealized vectors were also used for clustering experiments in order to estimate an upper bound. 4.4 Clustering Methods For the clustering experiments we used two different clustering algorithms: K-means and Latent Semantic Classes (LSC). K-means is a standard flat, hard-clustering algorithm; we used the Weka implementation (Witten and Frank, 2005). LSC (Rooth, 1998; Rooth et al., 1999) is a two-dimensional soft-clustering algorithm which learns three probability distributions: one for the clusters, and one for the output probabilities of each element and for each feature type with regard to a cluster. The latter two (elements and features) correspond to the two dimensions of the clustering. In our case the elements are the PV-BV pairs, and the features are normalized counts of the subcategorization frames. 4.5 Evaluation Our feature vectors are a combination of the feature vector for the BV and the feature vector for the PV of each PV-</context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>Ian H. Witten and Eibe Frank. 2005. Data Mining: Practical Machine Learning Tools and Techniques wi th Java Implementations. Morgan Kaufmann.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>