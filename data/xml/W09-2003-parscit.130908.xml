<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000989">
<title confidence="0.950687">
Understanding Eggcorns
</title>
<author confidence="0.991002">
Sravana Reddy
</author>
<affiliation confidence="0.9979925">
Department of Computer Science
The University of Chicago
</affiliation>
<email confidence="0.998459">
sravana@cs.uchicago.edu
</email>
<sectionHeader confidence="0.993878" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9980815">
An eggcorn is a type of linguistic error where
a word is substituted with one that is seman-
tically plausible – that is, the substitution is
a semantic reanalysis of what may be a rare,
archaic, or otherwise opaque term. We build
a system that, given the original word and its
eggcorn form, finds a semantic path between
the two. Based on these paths, we derive a ty-
pology that reflects the different classes of se-
mantic reinterpretation underlying eggcorns.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999963290909091">
The term “eggcorn” was coined in 2003 by Geof-
frey Pullum (Liberman, 2003) to refer to a certain
type of linguistic error where a word or phrase is
replaced with one that is phonetically similar and
semantically justifiable. The eponymous example is
acorn —* eggcorn, the meaning of the latter form be-
ing derived from the acorn’s egg-like shape and the
fact that it is a seed (giving rise to corn). These er-
rors are distinct from mere misspellings or mispro-
nunciations in that the changed form is an alternate
interpretation of the original.
The reinterpretation may be related to either the
word’s perceived meaning or etymology (as in the
case of acorn), or some context in which the word is
commonly used. In this sense, eggcorns are similar
to folk etymologies – errors arising from the misin-
terpretation of borrowed or archaic words – with the
difference being that the latter are adopted by an en-
tire culture or linguistic community, while eggcorns
are errors made by one or more individual speakers.
The formation of eggcorns and folk etymolo-
gies, mistakes though they are, involves a creative
leap within phonetic and semantic constraints (much
like what is required for puns or certain classes of
jokes). Eggcorns range from simple reshapings of
foreign words (paprika —* pepperika) and substitu-
tions from similar domains (marshal —* martial), to
the subtly clever (integrate —* intergrade), the tech-
nological (sound bite —* sound byte), or the funny
(stark-raving mad —* star-craving mad). The source
of reinterpretation may be a weak imagined link
(wind turbine —* wind turban), or an invented myth
(give up the ghost —* give up the goat1). And often,
it is not clear what the exact link is between the de-
rived and the original forms, although it is usually
obvious (to the human eye) that there is a connec-
tion.
This paper explores some ways of automatically
tracing the link between a word and its eggcorn.
In reality, we are chiefly concerned with comput-
ing the connections between a word and its rein-
terpreted form. Such pairs may also occur as folk
etymologies, puns, riddles, or get used as a poetic
device. However, we use eggcorns as a testbed
for three main reasons: there are a number of doc-
umented examples, the reanalyses are accidental
(meaning the semantic links are more unpredictable
and tenuous than in the cases of deliberate reshap-
ings), and the errors are idiosyncratic and relatively
modern – and hence have not been fossilized in the
lexicon – making them transparent to analysis (as
opposed to many folk etymologies and other histor-
ical errors). That said, much of the work described
here can be potentially applied to other instances of
semantic reinterpretation as well.
</bodyText>
<footnote confidence="0.999301">
1http://eggcorns.lascribe.net/english/
714/goat/
</footnote>
<page confidence="0.983976">
17
</page>
<note confidence="0.8173415">
Proceedings of the NAACL HLT Workshop on Computational Approaches to Linguistic Creativity, pages 17–23,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999803">
The first part of the paper describes an algorithm
(the “Cornalyzer”) for finding a semantic path be-
tween the original and reinterpreted forms of an
eggcorn pair. We then proceed to use the results
of this algorithm to cluster the eggcorn examples
into 5 classes, with a view to learning a typology
of eggcorns.
</bodyText>
<sectionHeader confidence="0.999725" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999864739130435">
One work related to this area (Nelken and Ya-
mangil, 2008) uses Wikipedia to automatically mine
eggcorns by searching for pairs of phonemically
similar words that occur in the same sentence con-
text in different revisions. However, the mined ex-
amples are reported to contain many false positives
since the algorithm does not include a notion of se-
mantic similarity.
Folk etymologies, the closest cousin to eggcorns,
have been studied from a linguistic point of view, in-
cluding some of the same questions we tackle here
(only, not from a computational side) – how is an
new word derived from the original, and what are
the different categories of folk etymologies? (Rund-
blad and Kronenfeld, 1998), (Scholfield, 1988). To
the best of our knowledge, there has been no pre-
vious work in inducing or computationally under-
standing properties of neologisms and errors de-
rived through misinterpretation. However, there is
a substantial literature on algorithmic humor, some
of which uses semantic relationships – (Stock and
Strapparava, 2006), (Manurung et al., 2008), among
others.
</bodyText>
<sectionHeader confidence="0.996383" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.999358666666667">
The list of eggcorns is taken directly from the
Eggcorn Database2 as of the submission date. To
assure soundness of the data, we include only those
examples whose usage is attested and which are con-
firmed to be valid and contemporary reanalyses3,
giving a total of 509 instances. Table 1 shows a sam-
ple of the data.
Every example can be denoted by the tuple
(w, e, c) where c is the list of obligatory contexts in
</bodyText>
<footnote confidence="0.9063845">
2http://eggcorns.lascribe.net/
3In other words, all examples that are classified as ‘ques-
tionable’ (or otherwise indicated as being questionable), ‘not an
eggcorn’, ‘citational’ or ‘nearly-mainstream’ are eliminated.
</footnote>
<tableCaption confidence="0.989371">
Table 1: A few eggcorns. ‘X’ can be replaced for w or
e to give the original form in context, or the eggcorn in
context respectively.
</tableCaption>
<table confidence="0.995180125">
Original Changed Context
form w form e c
bludgeon bloodgeon X
few view name a X
entree ontray X
praying preying X mantis
jaw jar X-dropping
dissonance dissidence cognitive X
</table>
<bodyText confidence="0.9964712">
which the reanalysis takes place, w is the original
form, and e is the modified (eggcorned) form.
The Cornalyzer uses WordNet (Fellbaum, 1998)
version 3.0, including the built-in morphological
tools for lemmatization and dictionary definitions4.
</bodyText>
<sectionHeader confidence="0.988254" genericHeader="method">
4 Automated Understanding of Eggcorn
Generation
</sectionHeader>
<bodyText confidence="0.710163">
Broadly speaking, there are two types of eggcorns:
</bodyText>
<listItem confidence="0.987851285714286">
1. Ones where e or a part of e is semantically re-
lated to the original word w (lost → loss in
‘no love lost’) or the context c (pied → pipe
in ‘pied-piper’).
2. Eggcorns where e is related to an image or ob-
ject that is connected to or evoked by the origi-
nal (like ‘song’ in lip-sync → lip-sing).
</listItem>
<bodyText confidence="0.959629">
For the first, a database of semantic relations be-
tween words (like WordNet) can be used to find a
semantic connection between w and e. The sec-
ond type is more difficult since external knowledge
is needed to make the connection. To this end, we
make use of the “glosses” – dictionary definitions of
word senses – included in WordNet. For instance,
the ‘lip-sing’ eggcorn is difficult to analyze using
only semantic relations, since neither ‘sync’ nor ‘lip’
are connected closely to the word ‘sing’. However,
the presence of the word song in the gloss of lip-
sync:
move the lips in synchronization
(with recorded speech or song)
</bodyText>
<footnote confidence="0.998884">
4From http://wordnet.princeton.edu/
</footnote>
<page confidence="0.998961">
18
</page>
<bodyText confidence="0.997161">
makes the semantic connection fairly transparent.
The Cornalyzer first attempts to analyze an
eggcorn tuple (w, e, c) using semantic relations
(§4.1). If no sufficiently short semantic path is
found, the eggcorn is presumed to be of the second
type, and is analyzed using a combination of seman-
tic relations and dictionary glosses (§4.2).
</bodyText>
<subsectionHeader confidence="0.9996415">
4.1 Analysis using Word Relations
4.1.1 Building the Semantic Graph
</subsectionHeader>
<bodyText confidence="0.993833473684211">
WordNet is a semantic dictionary of English, con-
taining a list of synsets. Each synset consists of a
set of synonymous words or collocations, and its re-
lations (like hypernymy, antonymy, or meronymy)
with other synsets. The dictionary also includes lex-
ical relations – relations between words rather than
synsets (for instance, a pertainym of a noun is an
adjective that is derived from the noun).
WordNet relations have been used to quantify se-
mantic similarity between words for a variety of ap-
plications (see Budanitsky and Hirst (2001) for a re-
view of similarity measures). The Cornalyzer uses
the same basic idea as most existing measures – find-
ing the shortest path between the two words – with
some modifications to fit our problem.
We adopt the convention that two words w1 and
w2 have the relation R if they are in different synsets
51 and 52, and R(51, 52) is true. We also define two
new lexical relations that are not directly indicated
in the dictionary: w1 and w2 are synonyms if they
are in the same synset, and homographs if they have
identical orthographic forms and lexical categories
but are in different synsets. 5
This relational network can hence be used to de-
fine a graph Gs over words, where there is an edge
of type tR from w1 to w2 if R(w1, w2) holds. Some
of the relations in WordNet (like antonymy) are ig-
nored, either because they invert semantic similarity,
or are not sufficiently informative. Table 2 summa-
rizes the relations used.
This graph can be used to find the semantic re-
lationships between an original word w and its
5This paper uses ‘word’ to include sense – i.e, ‘bank’ as in
slope beside a body of water and ‘bank’ as in financial institu-
tion are distinct. When required for disambiguation, the Word-
Net sense number, which is the index of the sense in the list of
the word’s senses, is added in parenthesis; e.g. bank (2) for the
financial institution sense.
</bodyText>
<tableCaption confidence="0.9671715">
Table 2: WordNet relations used to build the semantic
graph.
</tableCaption>
<table confidence="0.999643083333333">
Relation Parts of Reflexive Example
Speech Relation
Synonym (N, N) Synonym (forest, wood)
(V, V) (move, displace)
(Adj, Adj) (direct, lineal)
(Adv, Adv) (directly, at once)
Homograph (All, All) Homograph (call [greet],
call [order])
Hypernym (V, V) Troponym/ (move, jump)
(N, N) Hyponym (canine, fox)
Meronym (N, N) Holonym (forest, tree)
Has Instance (N, N) Instance Of (city, Dresden)
Cause (V, V) Caused by (affect, feel)
Entails (V, V) not specified (watch, look)
Similar To (Adj, Adj) Similar To (lucid, clear)
Related (V, V) Related (few, some)
(Adj, Ad)
Same Group (V, V) Same Group (displace, travel)
Has Attribute (Adj, N) Attribute Of (few, numerousness)
Derivational (N, V) Derivational (movement, move)
Relation (N, Adj) Relation (movement, motional)
(V, Adj) (move, movable)
Pertainym (Adj, N) not specified (direct, directness)
(Adv, Adj) (directly, direct)
</table>
<bodyText confidence="0.9929452">
eggcorn form e, if both forms are in the dictionary,
and there exists a path from w to e. However, it is
often the case that e or w are not in the dictionary,
or that a path does not exist. This could be because
one of the forms is an inflected form or compound,
or that some substring of e – rather than the whole
word or collocation – is the reinterpreted segment.
It is also essential to consider the strings in c, since
many eggcorns result from semantic reinterpretation
of the contexts.
Hence, three new non-semantic relations are de-
fined: w1 is a substring of w2 if the orthographic
form of w1 is a substring of that of w2, and w1 and
w2 are contextually linked if they occur in the same
collocation or compound. If w2 can be derived from
w1 using WordNet’s lemmatizer, w2 is an inflected
form of w1.
A new graph Ge is constructed by adding edges
of types tsubstring, tcontext, and tinflect to Gs. For
all eggcorn tuples (w, e, c):
</bodyText>
<listItem confidence="0.9989452">
1. If e or w are not in the dictionary, add them to
Ge as a vertex
2. Add edges of type inflect between e and its base
form.
3. Add edges of type substring from e to every
</listItem>
<page confidence="0.964836">
19
</page>
<bodyText confidence="0.75793275">
substring of length ≥ 3 that is in the dictionary
(except those substrings which are base forms
of e), and edges of type supstring in the other
direction.
</bodyText>
<listItem confidence="0.992184">
4. Extract a set of ‘context words’ from c by split-
ting it along spaces and hyphenation. Select
those words which are in the dictionary.
5. Add edges of type context from w and e to each
extracted context word.
</listItem>
<bodyText confidence="0.866645214285714">
For example, given the data in table 1, the follow-
ing vertices and edges will be added to Ge:
Vertices bloodgeon, ontray, preying, praying
Substring edges (bloodgeon, blood), (bloodgeon, loo),
(bloodgeon, eon), (view, vie), (entree, tree), (ontray,
ray), (ontray, tray)
Superstring edges above edges in the other direction
Inflectional edges (preying, prey), (praying, pray).
These edges are bidirectional.
Context edges (few, name), (view, name), (few, a),
(view, a), (praying, mantis), (preying, mantis), (jaw,
dropping), (jar, dropping), (dissonance, cognitive),
(dissidence, cognitive). These edges are also bidi-
rectional.
</bodyText>
<subsectionHeader confidence="0.770648">
4.1.2 Tracing the Semantic Path
</subsectionHeader>
<bodyText confidence="0.999869333333333">
Given the semantic graph, our working assump-
tion is that e is generated from w by following the
shortest path from w to e (denoted by P(w, e, c)).
</bodyText>
<listItem confidence="0.99133375">
1. If w and e are both in the dictionary, find
P1(w, e) = the shortest path from w to e in Gs
2. Find P2(w, e, c) = the shortest path using sub-
strings of e and/or c in Ge
</listItem>
<bodyText confidence="0.987640153846154">
(Since the edges are unweighted, the shortest path
from w to e is found simply by performing breadth-
first search starting at w.)
P(w, e, c) is simply the shorter of P1(w, e) (if it
exists) and P2(w, e, c). Note that there may be sev-
eral shortest paths, especially since words that are
synonymous have almost the same incident semantic
edges. Since the candidate shortest paths generally
do not differ much from one another (as far as their
semantic implications), an arbitrary path is chosen
to be P.
Table 3 shows the paths found by the algorithm
for some eggcorns.
</bodyText>
<subsectionHeader confidence="0.997423">
4.2 Analysis using Dictionary Definitions
</subsectionHeader>
<bodyText confidence="0.999758894736842">
As described in §4, the source of many eggcorns
is knowledge external to the original word or con-
texts through some concept or object suggested by
the original. In such cases, a semantic network will
not suffice to find the reinterpretation path. One pos-
sible way of accessing the additional information is
to search for w and e in a large corpus, and extract
the key words that appear in conjunction with these
forms.
However, filtering and extracting the represen-
tative information can quickly become a complex
problem beyond the scope of this paper. Hence, as a
first approximation, we use the dictionary definitions
(glosses) that accompany synsets in WordNet. To
optimize efficiency and to avoid having noise added
by the definitions, the Cornalyzer only resorts to this
step if a sufficiently short path – that is, a path of
length ≤ k for some threshold k – is not found when
only using word relations. (The results suggest 7
as a good threshold, since most of discovered paths
that are longer than 7 tend not to reflect the semantic
relationships between the eggcorn and the original
form.)
Every gloss from all senses of a lexical item6 x
(for all x in the dictionary) is first tokenized, and
punctuation stripped. All tokens are stemmed using
the built-in lemmatizer. Only those tokens t that are
already present as vertices in Ge are taken into con-
sideration. However, it should be clear that not all
tokens t are equally relevant to x. For instance, con-
sider one gloss of the noun “move”:
the act of changing location from one
place to another
which gives the tokens act, changing, location,
one, place, another. Clearly, the tokens changing,
location, and place rank higher than the others in
terms of how indicative they are of the meaning of
the noun.
</bodyText>
<footnote confidence="0.7924955">
6A lexical item is a word independent of sense, e.g, all
senses of ‘bank’ constitute a single lexical item.
</footnote>
<page confidence="0.996339">
20
</page>
<tableCaption confidence="0.955236">
Table 3: A sample of semantic similarity paths. x R −→ y means “y is an R of x”. When relevant, WordNet sense
numbers are indicated.
</tableCaption>
<table confidence="0.999147136363636">
Eggcorn tuple Path from word to eggcorn
(word, eggcorn, context)
(mince, mix, ‘X words’) mince −−−−−−−→ change hyponym
hypernym −−−−−−→ mix
(few, view, ‘name a X’) few deriv−−−→fewnesshypernym
− number hypes amount
−−−−−−−→ hypernym hyponym hyponym hyponym
magnitude−−−−−−→ extent−−−−−−→ scope−−−−−−→ view
(dissonance, dissidence, dissonance synonym
cognitive X) −−−−−−→ disagreement (1) homograph −−−−−−−→ disagreement (3)
hyponym
−−−−−−→ dissidence
(ado, [to-do, to do], [‘much X ado −−−−−−→stir (3) homograph
about nothing’, ‘without further X’]) synonym−−−−−−−→ stir (1) hypernym−−−−−−−→ to-do
(jaw, jar, X-dropping) context inflect hypernym hyponym
jaw −−−−−→ dropping−−−−→drop−−−−−−−→displace −−−−−−→jar
(ruckus, raucous, X) homograph deriv similar
ruckus −−−−−−−→ din −−−→ cacophonous −−−−−→raucous
(segue, segway, X) hypernym homograph hypernym
segue −−−−−−−→ passage (1)−−−−−−−→ passage (3) −−−−−−−→
supstring
way −−−−−−→ segway
</table>
<bodyText confidence="0.9966454">
One way of reflecting these distinctions in the
Cornalyzer is to weight these terms appropriately,
with something resembling the TF-IDF (Salton and
Buckley, 1988) measure used in information re-
trieval. Let tf(t, x) = the frequency of the to-
</bodyText>
<equation confidence="0.944799">
ken t in the glosses of x, and idf(t) = log N
df(t)
</equation>
<bodyText confidence="0.99997">
where N = the number of lexical items in the dic-
tionary and df(t) = the number of lexical items
in the dictionary whose glosses contain t. Define
</bodyText>
<equation confidence="0.50766">
W (t, x) = tf(t, x) · idf(t).
</equation>
<bodyText confidence="0.99996076">
A new graph Gd is constructed from Ge by adding
edges of type hasdef from every lexical item x to
tokens t in its glosses with the edge-weight 1 +
1/W (t, x), and reflexive edges of type indef from
t to x with the same weight. All existing edges in
the original graph Ge are assigned the weight 1.
The semantic path from w to e is found by the
process similar to what was described in §4.1.2:
first find P1(w, e) and P2(w, e, c) as well as
P3(w, e, c) = the shortest path from w to e in Gd,
and let P(w, e, c) be the shortest of the three. Since
Gd has weighted edges, the shortest path P3 is com-
puted using Dijkstra’s algorithm.
Dictionary-definition-based paths P2 for some
eggcorns are shown in Table 4. The shortest P2 paths
are also shown for comparison. The P3 paths gener-
ally appear to be closer to a human judgment of what
the semantic reinterpretation constitutes. In the case
of (bludgeon → bloodgeon), for example, P2 shows
no indication of the key connection (bleeding due to
being bludgeoned), whereas P3 captures it perfectly.
Of the 509 eggcorns, paths were found for 238
instances by using only Gs or Ge as the relational
graph. Paths for a total of 372 eggcorns were found
when using dictionary glosses in the graph Gd.
</bodyText>
<sectionHeader confidence="0.906892" genericHeader="method">
5 From Generation to Typology
</sectionHeader>
<bodyText confidence="0.999986454545455">
A quick glance at tables 3 and 4 shows that the paths
vary in shape and structure: some paths move up
and down the hypernym/homonym tree, while oth-
ers move laterally along synonyms and polysemes;
some use no external knowledge, while others make
primary use of context information and dictionary
glosses. A natural next step, therefore, is to group
the eggcorns into some number of classes that rep-
resent general categories of semantic reanalysis. We
can achieve this by clustering eggcorns based on
their semantic shortest paths.
</bodyText>
<subsectionHeader confidence="0.999961">
5.1 Clustering of Paths
</subsectionHeader>
<bodyText confidence="0.999636833333333">
One natural choice for a feature space is the set of all
24 relations (edge-types) used in Gd. An eggcorn
(w, e, c) is represented as a vector [v1, v2,... v24]
where vi = the number of times that relation Ri (or
the reflexive relation of Ri) appears in P(w, e, c).
These vectors are then clustered using k-means
</bodyText>
<page confidence="0.999675">
21
</page>
<tableCaption confidence="0.998971">
Table 4: Some semantic paths using dictionary glosses. As before, x R −+ y stands for “y is an R of x”, and the numbers
in parentheses following a lexical item are the WordNet sense numbers corresponding to that word.
</tableCaption>
<table confidence="0.9993791875">
Eggcorn tuple Path from word to eggcorn
(bludgeon, bloodgeon, X) hypernym −−−−−−−+ hit (6) hypernym
P3 (length 6): bludgeon −−−−−−−+ hit (3) homograph −−−−−−−+ wound
supstring
−−−−+ indef hypernymblood
gore−−−−−−−+ blood � bloodgeon
hypernym hypernym hypernym
P2 (length 11): bludgeon −−−−−−−+ club −−−−−−−+ stick −−−−−−−+ implement
−−−−−−−+ hypernym hypernym hyponym hyponym
instrumentality −−−−−−−+ artefact −−−−−−+ structure −−−−−−+ area
hyponym hyponym hyponym supstring�
−−−−−−+room−−−−−−+lavatory + loo bloodgeon
(entree, [ontray, on-tray], X) indef indef hasdef supstring
P3 (length 4): entree −−−−+ meal −−−−+ food −−−−+ tray −−−−−−+ ontray
hyponym homograph hypernym
P2 (length 8): entree + plate (8)−−−−−−−+ plate (4)+ flatware
−−−−−−−+ hypernym hyponym meronym hypernym
tableware−−−−−−+ tea set−−−−−−+ tea tray−−−−−−−+ tray
supstring
−−−−−−+ on-tray
npreying, X mantis) context
(praying, P3 (length 6): praying−−−−−+ mantis indef−−−−+predacious synonym
−−−−−−+ predatory (3)
−−−−−−−+ homograph indef inflect
predatory (2)−−−−+ prey −−−−+ preying
−−−−−+ mantis hypernym
P2 (length 8): praying context −−−−−−−+ty p
dic o terous insect
−−−−−−−+ hypernym hypernym hypernym hypernym
insect −−−−−−−+ arthropod −−−−−−−+ invertebrate −−−−−−−+ animal
−−−−−−+ prey inflect
hyponym −−−−+ preying
</table>
<bodyText confidence="0.98991225">
and a Euclidean distance metric. We experimented
with a few different values of k and found that k =
5 produces clusters that are the most semantically
coherent.
</bodyText>
<subsectionHeader confidence="0.534283">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.9998935">
The five clusters roughly correspond to the each of
the following characteristic paths P(w, e, c):
</bodyText>
<listItem confidence="0.977462875">
1. Independent of dictionary glosses and of con-
text, and mostly contain synonym, homograph,
related, or similar to types of edges.
2. Contain several hypernym and hyponym edges.
3. Contain several substring, supstring, and inflect
or derivational edges.
4. Heavily dependent on context edges.
5. Heavily dependent on dictionary glosses.
</listItem>
<bodyText confidence="0.682871111111111">
Eggcorns in these clusters can be interpreted to
be (1) Near-synonyms, (2) Semantic cousins – de-
riving from a common general concept or entity,
(3) Segmentally related – being linked by morpho-
logical operations, (4) Contextually similar, or (5)
Linked by implication – deriving from an implicit
concept.
A sample of the cluster membership is shown in
Table 5.
</bodyText>
<sectionHeader confidence="0.999603" genericHeader="discussions">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999986772727273">
This paper presents a procedure for computationally
understanding the semantic reanalyses of words. We
identified the two general types of eggcorns, and
built the appropriate networks overlying the Word-
Net graph and dictionary in order to trace the se-
mantic path from a word to its eggcorn.
An obvious drawback to our method stems from
the fact that the semantic dictionary is not perfect,
or fully reflective of human information. Similarly,
dictionary glosses are a limited source of external in-
formation. It would hence be worth exploring data-
driven methods to augment a source like WordNet,
such as building a word graph from co-occurrences
in text, or using corpora to derive distributional sim-
ilarity measures.
The Cornalyzer is only an exploratory first step
– there are a wealth of other possible computa-
tional problems related to eggcorns. Semantic path-
finding can be extended to defining some measure of
eggcorn strength or plausibility. The algorithm can
also be used to mine for new eggcorns – a thresh-
old or a set of criteria for an ‘eggcornish’ path can
</bodyText>
<page confidence="0.999138">
22
</page>
<tableCaption confidence="0.999409">
Table 5: A look at the clustered eggcorns.
</tableCaption>
<table confidence="0.956289272727273">
Cluster Examples
1 (cognitive dissonance → cognitive dissidence), (ado → to-do), (slake thirst → slack thirst),
(ruckus → raucous), (sparkle (protests, etc) → spark), (poise to do → pose to do), ...
2 (sow wild oats → sow wild oaks), (name a few → name a view), (whet, wet),
(curb hunger → curve hunger), (entree → ontray), (mince words → mix words), ...
3 (utmost → upmost), (valedictorian → valevictorian), (quote unquote → quote on quote),
(playwright → playwrite), (no love lost → no love loss), (snub → snob),...
4 (pied piper → pipe piper), (powerhouse → powerhorse), (jaw-dropping → jar-dropping),
(sell (something) down the river → sail (something) down the river), ...
5 (renowned, reknowned), (praying mantis → preying mantis), (expatriate → expatriot),
(skim milk → skimp milk), (sopping wet → soaping wet), (pique → peak),...
</table>
<bodyText confidence="0.99962725">
be set based on the paths found for known eggcorns,
thus helping separate them from false positives (ty-
pos and misspellings).
Another possible line of work is finding general-
izations in pronunciation changes from the original.
“The Eggcorn Database” website includes a partial
catalogue of phonetic changes like t-flapping and
cot/caught merger – it would be interesting to see if
such patterns and categories can be learnt. The basic
model of the Cornalyzer can potentially also be ex-
tended to applications in other domains of semantic
reanalysis like folk etymologies and puns.
</bodyText>
<sectionHeader confidence="0.99823" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996017">
We would like to thank the anonymous reviewers for
their excellent and insightful comments.
</bodyText>
<reference confidence="0.984295941176471">
the AAAI Workshop on Wikipedia and Artificial Intel-
ligence.
Gabriella Rundblad and David B Kronenfeld. 1998.
Folk-etymology: Haphazard perversion or shrewd
analogy? In Julie Coleman and Christian Kay, edi-
tors, Lexicology, Semantics, and Lexicography. John
Benjamins, Manchester.
Gerard Salton and Christopher Buckley. 1988. Term
weighting approaches in automatic text retrieval. In-
formation Processing and Management, 24(5):513–
523.
Phil Scholfield. 1988. Documenting folk etymological
change in progress. English Studies, 69:341–347.
Oliviero Stock and Carlo Strapparava. 2006. Laughing
with hahacronym, a computational humor system. In
Proceedings of the 21st AAAI Conference on Artificial
Intelligence.
</reference>
<sectionHeader confidence="0.919962" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999035058823529">
Alexander Budanitsky and Graeme Hirst. 2001. Seman-
tic distance in wordnet:an experimental, application-
oriented evaluation of five measures. In Proceedings
of the ACL Workshop on WordNet and Other Lexical
Resources.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge, MA.
Mark Liberman. 2003. Egg corns: folk et-
ymology, malapropism, mondegreen, ???
http://158.130.17.5/ myl/languagelog/archives/000019.html.
Ruli Manurung, Graeme Ritchie, Helen Pain, Annalu
Waller, Dave O’Mara, and Rolf Black. 2008. The con-
struction of a pun generator for language skills devel-
opment. Applied Artificial Intelligence, 22:841–869.
Rani Nelken and Elif Yamangil. 2008. Mining
Wikipedia’s article revision history for training com-
putational linguistics algorithms. In Proceedings of
</reference>
<page confidence="0.998932">
23
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.939219">
<title confidence="0.99988">Understanding Eggcorns</title>
<author confidence="0.951201">Sravana</author>
<affiliation confidence="0.9994805">Department of Computer The University of</affiliation>
<email confidence="0.998799">sravana@cs.uchicago.edu</email>
<abstract confidence="0.999042181818182">An eggcorn is a type of linguistic error where word is substituted with one that is semanplausible that is, the substitution is a semantic reanalysis of what may be a rare, archaic, or otherwise opaque term. We build a system that, given the original word and its eggcorn form, finds a semantic path between the two. Based on these paths, we derive a typology that reflects the different classes of semantic reinterpretation underlying eggcorns.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>the AAAI Workshop on Wikipedia and Artificial Intelligence.</booktitle>
<marker></marker>
<rawString>the AAAI Workshop on Wikipedia and Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriella Rundblad</author>
<author>David B Kronenfeld</author>
</authors>
<title>Folk-etymology: Haphazard perversion or shrewd analogy?</title>
<date>1998</date>
<editor>In Julie Coleman and Christian Kay, editors, Lexicology, Semantics, and Lexicography. John Benjamins,</editor>
<location>Manchester.</location>
<contexts>
<context position="4562" citStr="Rundblad and Kronenfeld, 1998" startWordPosition="748" endWordPosition="752">Wikipedia to automatically mine eggcorns by searching for pairs of phonemically similar words that occur in the same sentence context in different revisions. However, the mined examples are reported to contain many false positives since the algorithm does not include a notion of semantic similarity. Folk etymologies, the closest cousin to eggcorns, have been studied from a linguistic point of view, including some of the same questions we tackle here (only, not from a computational side) – how is an new word derived from the original, and what are the different categories of folk etymologies? (Rundblad and Kronenfeld, 1998), (Scholfield, 1988). To the best of our knowledge, there has been no previous work in inducing or computationally understanding properties of neologisms and errors derived through misinterpretation. However, there is a substantial literature on algorithmic humor, some of which uses semantic relationships – (Stock and Strapparava, 2006), (Manurung et al., 2008), among others. 3 Data The list of eggcorns is taken directly from the Eggcorn Database2 as of the submission date. To assure soundness of the data, we include only those examples whose usage is attested and which are confirmed to be val</context>
</contexts>
<marker>Rundblad, Kronenfeld, 1998</marker>
<rawString>Gabriella Rundblad and David B Kronenfeld. 1998. Folk-etymology: Haphazard perversion or shrewd analogy? In Julie Coleman and Christian Kay, editors, Lexicology, Semantics, and Lexicography. John Benjamins, Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>Christopher Buckley</author>
</authors>
<title>Term weighting approaches in automatic text retrieval.</title>
<date>1988</date>
<booktitle>Information Processing and Management,</booktitle>
<volume>24</volume>
<issue>5</issue>
<pages>523</pages>
<contexts>
<context position="16613" citStr="Salton and Buckley, 1988" startWordPosition="2776" endWordPosition="2779">much X ado −−−−−−→stir (3) homograph about nothing’, ‘without further X’]) synonym−−−−−−−→ stir (1) hypernym−−−−−−−→ to-do (jaw, jar, X-dropping) context inflect hypernym hyponym jaw −−−−−→ dropping−−−−→drop−−−−−−−→displace −−−−−−→jar (ruckus, raucous, X) homograph deriv similar ruckus −−−−−−−→ din −−−→ cacophonous −−−−−→raucous (segue, segway, X) hypernym homograph hypernym segue −−−−−−−→ passage (1)−−−−−−−→ passage (3) −−−−−−−→ supstring way −−−−−−→ segway One way of reflecting these distinctions in the Cornalyzer is to weight these terms appropriately, with something resembling the TF-IDF (Salton and Buckley, 1988) measure used in information retrieval. Let tf(t, x) = the frequency of the token t in the glosses of x, and idf(t) = log N df(t) where N = the number of lexical items in the dictionary and df(t) = the number of lexical items in the dictionary whose glosses contain t. Define W (t, x) = tf(t, x) · idf(t). A new graph Gd is constructed from Ge by adding edges of type hasdef from every lexical item x to tokens t in its glosses with the edge-weight 1 + 1/W (t, x), and reflexive edges of type indef from t to x with the same weight. All existing edges in the original graph Ge are assigned the weight</context>
</contexts>
<marker>Salton, Buckley, 1988</marker>
<rawString>Gerard Salton and Christopher Buckley. 1988. Term weighting approaches in automatic text retrieval. Information Processing and Management, 24(5):513– 523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phil Scholfield</author>
</authors>
<title>Documenting folk etymological change in progress.</title>
<date>1988</date>
<journal>English Studies,</journal>
<pages>69--341</pages>
<contexts>
<context position="4582" citStr="Scholfield, 1988" startWordPosition="753" endWordPosition="754">ggcorns by searching for pairs of phonemically similar words that occur in the same sentence context in different revisions. However, the mined examples are reported to contain many false positives since the algorithm does not include a notion of semantic similarity. Folk etymologies, the closest cousin to eggcorns, have been studied from a linguistic point of view, including some of the same questions we tackle here (only, not from a computational side) – how is an new word derived from the original, and what are the different categories of folk etymologies? (Rundblad and Kronenfeld, 1998), (Scholfield, 1988). To the best of our knowledge, there has been no previous work in inducing or computationally understanding properties of neologisms and errors derived through misinterpretation. However, there is a substantial literature on algorithmic humor, some of which uses semantic relationships – (Stock and Strapparava, 2006), (Manurung et al., 2008), among others. 3 Data The list of eggcorns is taken directly from the Eggcorn Database2 as of the submission date. To assure soundness of the data, we include only those examples whose usage is attested and which are confirmed to be valid and contemporary </context>
</contexts>
<marker>Scholfield, 1988</marker>
<rawString>Phil Scholfield. 1988. Documenting folk etymological change in progress. English Studies, 69:341–347.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliviero Stock</author>
<author>Carlo Strapparava</author>
</authors>
<title>Laughing with hahacronym, a computational humor system.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st AAAI Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="4900" citStr="Stock and Strapparava, 2006" startWordPosition="799" endWordPosition="802"> eggcorns, have been studied from a linguistic point of view, including some of the same questions we tackle here (only, not from a computational side) – how is an new word derived from the original, and what are the different categories of folk etymologies? (Rundblad and Kronenfeld, 1998), (Scholfield, 1988). To the best of our knowledge, there has been no previous work in inducing or computationally understanding properties of neologisms and errors derived through misinterpretation. However, there is a substantial literature on algorithmic humor, some of which uses semantic relationships – (Stock and Strapparava, 2006), (Manurung et al., 2008), among others. 3 Data The list of eggcorns is taken directly from the Eggcorn Database2 as of the submission date. To assure soundness of the data, we include only those examples whose usage is attested and which are confirmed to be valid and contemporary reanalyses3, giving a total of 509 instances. Table 1 shows a sample of the data. Every example can be denoted by the tuple (w, e, c) where c is the list of obligatory contexts in 2http://eggcorns.lascribe.net/ 3In other words, all examples that are classified as ‘questionable’ (or otherwise indicated as being questi</context>
</contexts>
<marker>Stock, Strapparava, 2006</marker>
<rawString>Oliviero Stock and Carlo Strapparava. 2006. Laughing with hahacronym, a computational humor system. In Proceedings of the 21st AAAI Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Budanitsky</author>
<author>Graeme Hirst</author>
</authors>
<title>Semantic distance in wordnet:an experimental, applicationoriented evaluation of five measures.</title>
<date>2001</date>
<booktitle>In Proceedings of the ACL Workshop on WordNet and Other Lexical Resources.</booktitle>
<contexts>
<context position="8140" citStr="Budanitsky and Hirst (2001)" startWordPosition="1341" endWordPosition="1344">ary glosses (§4.2). 4.1 Analysis using Word Relations 4.1.1 Building the Semantic Graph WordNet is a semantic dictionary of English, containing a list of synsets. Each synset consists of a set of synonymous words or collocations, and its relations (like hypernymy, antonymy, or meronymy) with other synsets. The dictionary also includes lexical relations – relations between words rather than synsets (for instance, a pertainym of a noun is an adjective that is derived from the noun). WordNet relations have been used to quantify semantic similarity between words for a variety of applications (see Budanitsky and Hirst (2001) for a review of similarity measures). The Cornalyzer uses the same basic idea as most existing measures – finding the shortest path between the two words – with some modifications to fit our problem. We adopt the convention that two words w1 and w2 have the relation R if they are in different synsets 51 and 52, and R(51, 52) is true. We also define two new lexical relations that are not directly indicated in the dictionary: w1 and w2 are synonyms if they are in the same synset, and homographs if they have identical orthographic forms and lexical categories but are in different synsets. 5 This</context>
</contexts>
<marker>Budanitsky, Hirst, 2001</marker>
<rawString>Alexander Budanitsky and Graeme Hirst. 2001. Semantic distance in wordnet:an experimental, applicationoriented evaluation of five measures. In Proceedings of the ACL Workshop on WordNet and Other Lexical Resources.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Liberman</author>
</authors>
<title>Egg corns: folk etymology,</title>
<date>2003</date>
<note>malapropism, mondegreen, ??? http://158.130.17.5/ myl/languagelog/archives/000019.html.</note>
<contexts>
<context position="673" citStr="Liberman, 2003" startWordPosition="107" endWordPosition="108">r Science The University of Chicago sravana@cs.uchicago.edu Abstract An eggcorn is a type of linguistic error where a word is substituted with one that is semantically plausible – that is, the substitution is a semantic reanalysis of what may be a rare, archaic, or otherwise opaque term. We build a system that, given the original word and its eggcorn form, finds a semantic path between the two. Based on these paths, we derive a typology that reflects the different classes of semantic reinterpretation underlying eggcorns. 1 Introduction The term “eggcorn” was coined in 2003 by Geoffrey Pullum (Liberman, 2003) to refer to a certain type of linguistic error where a word or phrase is replaced with one that is phonetically similar and semantically justifiable. The eponymous example is acorn —* eggcorn, the meaning of the latter form being derived from the acorn’s egg-like shape and the fact that it is a seed (giving rise to corn). These errors are distinct from mere misspellings or mispronunciations in that the changed form is an alternate interpretation of the original. The reinterpretation may be related to either the word’s perceived meaning or etymology (as in the case of acorn), or some context i</context>
</contexts>
<marker>Liberman, 2003</marker>
<rawString>Mark Liberman. 2003. Egg corns: folk etymology, malapropism, mondegreen, ??? http://158.130.17.5/ myl/languagelog/archives/000019.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruli Manurung</author>
<author>Graeme Ritchie</author>
<author>Helen Pain</author>
<author>Annalu Waller</author>
<author>Dave O’Mara</author>
<author>Rolf Black</author>
</authors>
<title>The construction of a pun generator for language skills development.</title>
<date>2008</date>
<journal>Applied Artificial Intelligence,</journal>
<pages>22--841</pages>
<marker>Manurung, Ritchie, Pain, Waller, O’Mara, Black, 2008</marker>
<rawString>Ruli Manurung, Graeme Ritchie, Helen Pain, Annalu Waller, Dave O’Mara, and Rolf Black. 2008. The construction of a pun generator for language skills development. Applied Artificial Intelligence, 22:841–869.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rani Nelken</author>
<author>Elif Yamangil</author>
</authors>
<title>Mining Wikipedia’s article revision history for training computational linguistics algorithms.</title>
<date>2008</date>
<booktitle>In Proceedings of</booktitle>
<contexts>
<context position="3926" citStr="Nelken and Yamangil, 2008" startWordPosition="643" endWordPosition="647">well. 1http://eggcorns.lascribe.net/english/ 714/goat/ 17 Proceedings of the NAACL HLT Workshop on Computational Approaches to Linguistic Creativity, pages 17–23, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics The first part of the paper describes an algorithm (the “Cornalyzer”) for finding a semantic path between the original and reinterpreted forms of an eggcorn pair. We then proceed to use the results of this algorithm to cluster the eggcorn examples into 5 classes, with a view to learning a typology of eggcorns. 2 Related Work One work related to this area (Nelken and Yamangil, 2008) uses Wikipedia to automatically mine eggcorns by searching for pairs of phonemically similar words that occur in the same sentence context in different revisions. However, the mined examples are reported to contain many false positives since the algorithm does not include a notion of semantic similarity. Folk etymologies, the closest cousin to eggcorns, have been studied from a linguistic point of view, including some of the same questions we tackle here (only, not from a computational side) – how is an new word derived from the original, and what are the different categories of folk etymolog</context>
</contexts>
<marker>Nelken, Yamangil, 2008</marker>
<rawString>Rani Nelken and Elif Yamangil. 2008. Mining Wikipedia’s article revision history for training computational linguistics algorithms. In Proceedings of</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>