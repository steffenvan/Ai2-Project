<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000006">
<note confidence="0.5040075">
THE REPRESENTATION OF CONSTITUENT STRUCTURES FOR FINITE—STATE PARSING
D. Terence Langendoen
</note>
<author confidence="0.925602">
Yedidyah Langsam
</author>
<affiliation confidence="0.9695055">
Departments of English and Computer &amp; Information Science
Brooklyn College of the City University of New York
</affiliation>
<address confidence="0.693348">
Brooklyn, New York 11210 U.S.A.
</address>
<email confidence="0.549359">
ABSTRACT
</email>
<bodyText confidence="0.999949298969072">
A mixed prefix—postfix notation for repre—
sentations of the constituent structures of the
expressions of natural languages is proposed,
which are of limited degree of center embedding if
the original expressions are noncenter—embedding.
The method of constructing these representations
is applicable to expressions with center embed—
ding, and results in representations which seem to
reflect the ways in which people actually parse
those expressions. Both the representations and
their interpretations can be computed from the ex—
pressions from left to right by finite—state de—
vices.
The class of acceptable expressions of a na—
tural language L all manifest no more than a
small, fixed, finite degree n of center embedding.
From this observation, it follows that the ability
of human beings to parse the expressions of L can
be modeled by a finite transducer that associates
with the acceptable expressions of L representa—
tions of the structural descriptions of those ex—
pressions. This paper considers some initial
steps in the construction of such a model. The
first step is to determine a method of represen—
ting the class of constituent structures of the
expressions of L without center embedding in such
a way that the members of that class themselves
have no more than a small fixed finite degree of
center embedding. Given a grammar that directly
generates that class of constituent structures, it
is not difficult to construct a deterministic fi—
nite—state transducer (parser) that assigns the
appropriate members of that class to the noncen—
ter—embedded expressions of L from left to right.
The second step is to extend the method so that it
is capable of representing the class of constitu—
ent structures of expressions of L with no more
than degree n of center embedding in a manner
which appears to accord with the way in which hu—
man beings actually parse those sentences. Given
certain reasonable assumptions about the character
of the rules of grammar of natural languages, we
show how this step can also be taken.
*This work was partly supported by a grant from
the PSC—CUNY Faculty Research Award Program.
Let G be a context—free phrase—structure
grammar (CFPSG). First, suppose that the category
A in G is right—recursive; i.e., that there are
subderivations with respect to G such that
A X A, where X is a nonnull string of symbols
(terminal, nonterminal, or mixed). We seek a new
CFPSG G*, derived from G, that contains the cate—
gory A* (corresponding to A), such that there are
subderivations with respect to G* of the form
A* == X* A*, where X* represents the constituent
structure of X with respect to G. Next, suppose
that the category B in G is left—recursive; i.e.,
that there are subderivations with respect to G
such that B ==4. B Y, where Y is nonnull. We seek
a new CFPSG G*, derived from G, that contains the
category B* (corresponding to B), such that there
are subderivations with respect to G* of the form
13* ==4 13* Y*, where Y* represents the constituent
structure of Y with respect to G. In other words,
given a grammar G, we seek a grammar G* that di—
rectly generates strings that represent the con—
stituent structures of the noncenter—embedded ex—
pressions generated by G, that is right—recursive
wherever G is right—recursive and is left—recur—
sive wherever G is left—recursive.
In order to find such a G*, we must first de—
termine what kinds of strings are available that
can represent constituent structures and at the
same time can be directly generated by noncenter—
embedding grammars. Full bracketing diagrams are
not suitable, since grammars that generate them
are center embedding whenever the original gram—
mars are left— or right—recursive (Langendoen
1975). Suppose, however, that we leave off right
brackets in right—recursive structures and left
brackets in left—recursive structures. In right—
recursive structures, the positions of the left
brackets that remain indicate where each constitu—
ent begins; the position where each constituent
ends can be determined by a simple counting pro—
cedure provided that the number of daughters of
that constituent is known (e.g., when the original
grammar is in Chomsky—normal—form). Similarly,
in left—recursive structures, the positions of the
right brackets that remain indicate where each
constituent ends, and the position where each con—
stituent begins can also be determined simply by
counting. Moreover, since brackets no longer oc—
cur in matched pairs, the brackets themselves can
be omitted, leaving only the category labels. In
left—recursive structures, these category symbols
occur as postfixes; in right—recursive structures,
</bodyText>
<page confidence="0.992273">
24
</page>
<bodyText confidence="0.999683">
they occur as prefixes. Let us call any symbol
which occurs as a prefix or a postfix in a string
that represents the constituent structure of an
expression an affix; the strings themselves af-
fixed strings; and the grammars that generate
those strings affix grammars.
To see how affix grammars may be constructed,
consider the noncenter-embedding CFPSG Ci, which
generates the artificial language Ll = a(b*a)*b*a.
</bodyText>
<equation confidence="0.474216666666667">
(Cl) a.S-4.SA b.A-4.BA
c. A a d. B b
e. S -4 a
</equation>
<bodyText confidence="0.881299333333333">
A noncenter-embedding affix grammar that generates
the affixed strings that represent the constituent
structures of the expressions of LI with respect
</bodyText>
<equation confidence="0.60742775">
to G1 is given in G1*.
(G1*) a. S* S* A* S b. A* A B* A*
c. A* A a d. B* B b
e. S* S a
</equation>
<bodyText confidence="0.952311933333333">
Among the expressions generated by G1 is El; the
affixed string generated by Gl* that represents
its structural description is El*.
(El) abbaba
(E1*) SaABbABbAaSABbAaS
Let us say that an affix covers elements in
an affixed string which correspond to its consti-
tuents (not necessarily immediate). Then El* may
be interpreted as a structural description of El
with respect to Cl according to the rules in R,
in which J, K, and L are affixes; k is a word; x
and y are substrings of affixed strings; and G is
a CFPSG (in this case, Cl).
(R) a. If K k is a rule of G, then in
the configuration ... K k K is
a prefix which covers k.
b. IfJ-4.KLisarule of G, then
in the configuration ... J K x L
in which x does not contain L, J is
a prefix which covers K L.
c. IfJ—I4 KLisarule of G, then in
the configuration ... KxLyJ
in which x does not contain L and y
does not contain K, J is a postfix
which covers K L.
Coverage of constituents by the rules in R may be
thought to be assigned dynamically from left to
right.
A postfix is used in rule Gl*a because the
category S is left-recursive in Gl, whereas a pre-
fix is used in rule Gl*b because the category A is
right-recursive in Gl. The use of prefixes in
rules Gl*c-e, on the other hand, is unmotivated if
the only criteria for choosing an affix type have
to do with direction of recursion. For affix
grammars of natural languages, however, one can
motivate the decision to use a particular type of
affix by principles other than those having to do
with direction of recursion.
The use of a prefix can be interpreted as in-
dicating a decision (or guess) on the part of the
language user as to the identity of a particular
constituent on the basis of the identity of the
first constituent in it. Since lexical items are
assigned to lexical categories essentially as soon
as they are recognized (Forster 1976), we may sup-
pose first that prefixes are used for rules such
as those in Gl*c-e that assign lexical items to
lexical categories. Second, if, as seems reason-
able, a decision about the identity of constitu-
ents is always made as soon as possible, then we
may suppose that prefixes are used for all rules
in which the leftmost daughter of a particular
constituent provides sufficient evidence for the
identification of that constituent; e.g., if the
leftmost daughter is either the specifier or the
head of that constituent in the sense of Jacken-
doff (1977). Third, we may suppose that even if
the leftmost daughter of a particular constituent
does not provide sufficient evidence for the iden-
tification of that constituent, a prefix may still
be used if that constituent is the left sister of
a constituent that provides sufficient evidence
for its identification. Fourth, we may suppose
that postfixes are used in all other cases.
To illustrate the use of these four prin-
ciples, consider the noncenter-embedding partial
grammar G2 that generates a fragment of English
that we call L2.
(G2) a. S —* NP VP b. NP ---* D R
c. NP—. a d. U NP G
e. N f. VP V (iNP, el)
g. C S h. C --* that
i. D the j. G &apos;s
k. N {boss, child ...I
</bodyText>
<sectionHeader confidence="0.67933" genericHeader="abstract">
1. V iknew, saw,
</sectionHeader>
<bodyText confidence="0.998218636363637">
Among the expressions of L2 are those with both
right-recursion and left-recursion, such as E2.
(E2) the boss knew that the teacher&apos;s sis-
ter&apos;s neighbor&apos;s friend believed that
the student saw the child
We now give an affix grammar G2* that direct-
ly generates affixed strings that represent the
structural descriptions of the expressions of L2
with respect to G2, and that has been constructed
in accordance with the four principles described
above.
</bodyText>
<page confidence="0.9934">
25
</page>
<figure confidence="0.919747461538462">
(G2*) a. i. S* S NP* VP* / C that
S* --4 NP* VP* S / elsewhere
b. NP* NP D* R*
c. NP* --4 d* NP
d. d* NP* G* d
e. R* R N*
f. VP* VP v* atm*, U*1)
S. a* c* s*
h. C* C that
i. D* D the
j. G* G &apos;s
k. N* N tchild, house,
1. V* —IP. V iknew, saw, ...i
</figure>
<bodyText confidence="0.998172281690141">
Rules G2*h-1 conform to the first principle,
according to which lexical categories generally
appear as prefixes. Rules G2*b,e-g conform to the
second principle, according to which a category
appears as a prefix if its leftmost daughter in
the corresponding rule of G2 is its head or speci-
fier. Rule G2*ai conforms to the third principle,
according to which a category appears as a prefix
if its presence can be predicted from its right
sister in G2. Finally, rules G2*aii,c,d conform
to the fourth principle, according to which a ca-
tegory appears as a postfix if it cannot appear as
a prefix according to the preceding three prin-
ciples.
The affixed string that G2* generates as the
representation of the structural description of E2
with respect to G2 is given in E2*.
(E2*) NP D the R N boss VP V knew C C that S
NP D the N teacher G &apos;s d N N sister
NP G &apos;s R N neighbor NP G &apos;s R N
friend NP VP V believed t- C that S NP D
the R N student VP V saw NP D the R N
child S
E2* can be interpreted as the structural descrip-
tion of E2 with respect to G2 by the rules in R,
with the addition of a rule to handle unary non-
lexical branching (as in G2e), and a modification
of Rc to prevent a postfix from simply covering a
sequence of affixes already covered by a prefix.
(This restriction is needed to prevent the postfix
S in E2* from simply covering any of the subordi-
nate clauses in that expression.) It is worth
noting how the application of those rules dynami-
cally enlarges the NP that is covered by the S prefix
that follows the words knew that. First the tea-
cher is covered; then the teacher&apos;s sister; then
the teacher&apos;s sister&apos;s neighbor; and finally the
teacher&apos;s sister&apos;s neighbor&apos;s friend.
The derivation of E2* manifests first-degree
center embedding of the category S*, as a result
of the treatment of S as both a prefix and a suf-
fix in G2*. However, no derivation of an affixed
string generated by G2* manifests any greater de-
gree of center embedding; hence, the affixed
strings associated with the expressions of L2 can
still be assigned to them by a finite-state parser.
The added complexity involved in interpreting E2*
results from the fact that all but the first of
the NP-VP sequences in E2* are covered by prefix
Ss, so that the constituents covered by the post-
fix S in E2* according to rule Rc are considerably
far away from it.
It will be noted that we have provided two
logically independent sets of principles by which
affixed grammars may be constructed from a given
CFPSG. The first set is explicitly designed to
preserve the property of noncenter-embedding. The
second is designed to maximize the use of prefixes
on the basis of being able to predict the identity
of a constituent by the time its leftmost descen-
dent has been identified. There is no reason to
believe a priori that affixed grammars constructed
according to the second set of principles should
preserve noncenter-embedding, and indeed as we
have just seen, they don&apos;t. However, we conjec-
ture that natural languages are designed so that
representations of the structural descriptions of
acceptable expressions of those languages can be
assigned to them by finite-state parsers that op-
erate by identifying constituents as quickly as
possible. We call this the Efficient Finite-
</bodyText>
<subsectionHeader confidence="0.865391">
State Parser Hypothesis.
</subsectionHeader>
<bodyText confidence="0.999943428571428">
The four principles for determining whether
to use a prefix or a postfix to mark the presence
of a particular constituent apply to grammars that
are center embedding as well as to those that are
not. Suppose we extend the grammar G2 by replac-
ing rules G2e and f by rules G2e&apos; and f&apos; respec-
tively, and adding rules G2m-s as follows:
</bodyText>
<figure confidence="0.170943">
(G2) e&apos;. N (PP1)
f&apos;. VP V (NP) ({PP2. 0)
m. NP NP PP2
n. PPI P1 NP
o. PP2 P2 NP
p. VP —9. VP IA, PP2i
q. A yesterday
r. P1 --4 of
</figure>
<figureCaption confidence="0.133122">
s. P2 lin, on, ...3
</figureCaption>
<bodyText confidence="0.9926438">
Among the expressions generated by the extended
grammar G2 are those in E3.
(E3) a. the boss knew that the teacher saw
the child yesterday
b. the friend of the teacher&apos;s sister
</bodyText>
<page confidence="0.984078">
26
</page>
<bodyText confidence="0.999914117647059">
Although each of the expressions in E3 is am-
biguous with respect to G2, each has a strongly
preferred interpretation. Moreover, under each
interpretation, each of these sentences manifests
first-degree center embedding. In E3, the includ-
ed VP saw the child is wholly contained in the in-
cluding VP knew that the teacher saw the child
yesterday; and in E3b, the included NP the teacher
is wholly contained in the including NP the friend
of the teacher&apos;s sister.
Curiously enough, the extension of the affix
grammar that our principles derive from the exten-
sion of the grammar G2 just given associates only
one affixed string with each of the expressions in
E3. That grammar is obtained by replacing rules
G2*e and F with G2*e&apos; and f&apos; respectively, and ad-
ding the rules C2*m-s as follows.
</bodyText>
<figure confidence="0.519225833333333">
(C2*) e&apos;. R* R N* (PP1*)
f&apos;. VP* --A. VP V* (NP*) (fPP2*, 6*})
m. NP* NP* PP2* NP
n. PP1* --* PP1 P1* NP*
o. PP2* --* PP2 P2* NP*
p. VP* --* VP* iA*, PP2*} VP
</figure>
<bodyText confidence="0.975657576271186">
Next, consider E3b and its associated affixed
string E3b. According to rule Rc, the is a
postfix that covers the affixes NP and G. Two oc-
currences of the prefix NP are available to be
covered; again, we may suppose that rule Rc picks
out the nearer one. If so, then automatically the
complex NP, the teacher&apos;s sister, is covered by
PP1, again in accordance with the natural inter-
pretation of the expression as a whole.
This completes our demonstration of the abil-
ity of affixed strings to represent the structural
descriptions of the acceptable sentences of a na-
tural language in a manner which enables them to
be parsed by a finite-state device, and which also
predicts the way in which (at least) certain ex-
pressions with center embedding are actually in-
terpreted. Much more could be said about the sys-
tem of representation we propose, but time and
space limitations preclude further discussion
here. We leave as exercises to the reader the
demonstration that the expression E4a has a single
affixed string associated with it by G2*, and that
the left-branching (stacked) interpretation of E4b
is predicted to be preferred over the right-
branching interpretation.
(E4) a. the student saw the teacher in the
house
b. the house in the woods near the
q. A* --* A yesterday stream
r. P1*# P1 of
s. P2* P2 fin, on, ...3
The affix strings that the extended affix grammar
G2* associates with the expressions in E3 are
given in E3*.
(E3*) a. NP D the R N boss VP V knew C C that
S NPD the R N teacher VP V saw NP D
the R N child A yesterday VP S
b. NP D the R N friend PP1 P1 of NP D
the R N teacher G &apos;s .G&amp;quot; R N sister NP
We contend that the fact that the expressions
in E3 have a single strongly preferred interpreta-
tion results from the fact that those expressions
have a single affixed string associated with them.
Consider first E3a and its associated affixed
string E3*a. According to rule Rc, the affix VP
following yesterday is a postfix which covers the
affixes VP and A. Now, there is only one occur-
rence of A in E3*a, namely the one that immediate-
ly precedes yesterday; hence that must be the oc-
currence which is covered by the postfix VP. On
the other hand, there are two occurrences of pre-
fix VP in E3*a that can legitimately be covered by
the postfix, the one before saw and the one before
knew. Suppose in such circumstances, rule Rc
picks out the nearer prefix. Then automatically
the complex VP, saw the child yesterday, is co-
vered by the subordinate S prefix, in accordance
with the natural interpretation of the expression
as a whole.
</bodyText>
<sectionHeader confidence="0.998688" genericHeader="acknowledgments">
ACKNOWLEDGMENT
</sectionHeader>
<bodyText confidence="0.999835">
We thank Maria Edelstein for her invaluable
help in developing the work presented here.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.7894801">
Forster, Kenneth I. (1976) Accessing the mental
lexicon. In R.J. Wales and E.T. Walker,
eds., New Approaches to Language Mechanisms.
Amsterdam: North-Holland.
Jackendoff, Ray S. (1977) X-Bar Syntax. Cam-
bridge, Mass.: MIT Press.
Langendoen, D. Terence (1975) Finite-state par-
sing of phrase-structure languages and the
status of readjustment rules in grammar.
Linguistic Inquiry 6.533-54.
</reference>
<page confidence="0.998603">
27
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.012651">
<title confidence="0.999674">THE REPRESENTATION OF CONSTITUENT STRUCTURES FOR FINITE—STATE PARSING</title>
<author confidence="0.744761">D Terence Langendoen Yedidyah Langsam</author>
<affiliation confidence="0.999926">Departments of English and Computer &amp; Information Science</affiliation>
<address confidence="0.8062895">Brooklyn College of the City University of New York Brooklyn, New York 11210 U.S.A.</address>
<abstract confidence="0.988857226130653">A mixed prefix—postfix notation for repre— sentations of the constituent structures of the expressions of natural languages is proposed, which are of limited degree of center embedding if the original expressions are noncenter—embedding. The method of constructing these representations is applicable to expressions with center embed— ding, and results in representations which seem to reflect the ways in which people actually parse those expressions. Both the representations and their interpretations can be computed from the ex— pressions from left to right by finite—state de— vices. The class of acceptable expressions of a na— tural language L all manifest no more than a small, fixed, finite degree n of center embedding. From this observation, it follows that the ability of human beings to parse the expressions of L can be modeled by a finite transducer that associates with the acceptable expressions of L representa— tions of the structural descriptions of those ex— pressions. This paper considers some initial steps in the construction of such a model. The first step is to determine a method of represen— ting the class of constituent structures of the expressions of L without center embedding in such a way that the members of that class themselves have no more than a small fixed finite degree of center embedding. Given a grammar that directly generates that class of constituent structures, it is not difficult to construct a deterministic fi— nite—state transducer (parser) that assigns the appropriate members of that class to the noncen— ter—embedded expressions of L from left to right. The second step is to extend the method so that it is capable of representing the class of constitu— ent structures of expressions of L with no more than degree n of center embedding in a manner which appears to accord with the way in which hu— man beings actually parse those sentences. Given certain reasonable assumptions about the character of the rules of grammar of natural languages, we show how this step can also be taken. *This work was partly supported by a grant from the PSC—CUNY Faculty Research Award Program. Let G be a context—free phrase—structure grammar (CFPSG). First, suppose that the category A in G is right—recursive; i.e., that there are subderivations with respect to G such that A X A, where X is a nonnull string of symbols (terminal, nonterminal, or mixed). We seek a new CFPSG G*, derived from G, that contains the cate— gory A* (corresponding to A), such that there are subderivations with respect to G* of the form A* == X* A*, where X* represents the constituent structure of X with respect to G. Next, suppose that the category B in G is left—recursive; i.e., that there are subderivations with respect to G such that B ==4. B Y, where Y is nonnull. We seek a new CFPSG G*, derived from G, that contains the category B* (corresponding to B), such that there are subderivations with respect to G* of the form Y*, where Y* represents the constituent structure of Y with respect to G. In other words, given a grammar G, we seek a grammar G* that di— rectly generates strings that represent the con— stituent structures of the noncenter—embedded ex— pressions generated by G, that is right—recursive wherever G is right—recursive and is left—recur— sive wherever G is left—recursive. In order to find such a G*, we must first de— termine what kinds of strings are available that can represent constituent structures and at the same time can be directly generated by noncenter— embedding grammars. Full bracketing diagrams are not suitable, since grammars that generate them are center embedding whenever the original gram— mars are left— or right—recursive (Langendoen 1975). Suppose, however, that we leave off right brackets in right—recursive structures and left brackets in left—recursive structures. In right— recursive structures, the positions of the left brackets that remain indicate where each constitu— ent begins; the position where each constituent ends can be determined by a simple counting pro— cedure provided that the number of daughters of that constituent is known (e.g., when the original is in Chomsky—normal—form). in left—recursive structures, the positions of the right brackets that remain indicate where each constituent ends, and the position where each con— stituent begins can also be determined simply by counting. Moreover, since brackets no longer oc— cur in matched pairs, the brackets themselves can be omitted, leaving only the category labels. In left—recursive structures, these category symbols as right—recursive structures, 24 occur as us call any symbol which occurs as a prefix or a postfix in a string that represents the constituent structure of an an strings themselves afstrings; the grammars that generate strings grammars. To see how affix grammars may be constructed, consider the noncenter-embedding CFPSG Ci, which generates the artificial language Ll = a(b*a)*b*a. (Cl) a.S-4.SA b.A-4.BA c. A a d. B b S affix grammar that generates the affixed strings that represent the constituent structures of the expressions of LI with respect to G1 is given in G1*. (G1*) a. S* S* A* S b. A* A B* A* c. A* A a d. B* B b e. S* S a Among the expressions generated by G1 is El; the affixed string generated by Gl* that represents its structural description is El*. (El) abbaba (E1*) SaABbABbAaSABbAaS us say that an affix in an affixed string which correspond to its constituents (not necessarily immediate). Then El* may be interpreted as a structural description of El with respect to Cl according to the rules in R, in which J, K, and L are affixes; k is a word; x and y are substrings of affixed strings; and G is a CFPSG (in this case, Cl). (R) a. If K k is a rule of G, then in the configuration ... K k K is a prefix which covers k. b. IfJ-4.KLisarule of G, then in the configuration ... J K x L in which x does not contain L, J is a prefix which covers K L. c. IfJ—I4 KLisarule of G, then in the configuration ... KxLyJ in which x does not contain L and y does not contain K, J is a postfix which covers K L. Coverage of constituents by the rules in R may be thought to be assigned dynamically from left to right. A postfix is used in rule Gl*a because the category S is left-recursive in Gl, whereas a prefix is used in rule Gl*b because the category A is right-recursive in Gl. The use of prefixes in rules Gl*c-e, on the other hand, is unmotivated if the only criteria for choosing an affix type have to do with direction of recursion. For affix grammars of natural languages, however, one can motivate the decision to use a particular type of affix by principles other than those having to do with direction of recursion. The use of a prefix can be interpreted as indicating a decision (or guess) on the part of the language user as to the identity of a particular constituent on the basis of the identity of the first constituent in it. Since lexical items are assigned to lexical categories essentially as soon as they are recognized (Forster 1976), we may suppose first that prefixes are used for rules such as those in Gl*c-e that assign lexical items to lexical categories. Second, if, as seems reasonable, a decision about the identity of constituents is always made as soon as possible, then we may suppose that prefixes are used for all rules in which the leftmost daughter of a particular constituent provides sufficient evidence for the identification of that constituent; e.g., if the leftmost daughter is either the specifier or the head of that constituent in the sense of Jackendoff (1977). Third, we may suppose that even if the leftmost daughter of a particular constituent does not provide sufficient evidence for the identification of that constituent, a prefix may still be used if that constituent is the left sister of a constituent that provides sufficient evidence for its identification. Fourth, we may suppose that postfixes are used in all other cases. To illustrate the use of these four principles, consider the noncenter-embedding partial grammar G2 that generates a fragment of English that we call L2. a. S —* VP ---* D NP—. U V (iNP, el) C S h. C --* the j. G &apos;s k. N {boss, child ...I 1. V iknew, saw, Among the expressions of L2 are those with both right-recursion and left-recursion, such as E2. (E2) the boss knew that the teacher&apos;s sister&apos;s neighbor&apos;s friend believed that the student saw the child We now give an affix grammar G2* that directly generates affixed strings that represent the structural descriptions of the expressions of L2 with respect to G2, and that has been constructed in accordance with the four principles described above. 25 (G2*) a. S VP* / C --4 NP* VP* S elsewhere NP* NP R* NP* d* d* G* R* R VP* VP v* U*1) s* C* that i. D* D the j. G* G &apos;s N* N house, 1. V* —IP. V iknew, saw, ...i Rules G2*h-1 conform to the first principle, according to which lexical categories generally appear as prefixes. Rules G2*b,e-g conform to the second principle, according to which a category appears as a prefix if its leftmost daughter in the corresponding rule of G2 is its head or specifier. Rule G2*ai conforms to the third principle, according to which a category appears as a prefix if its presence can be predicted from its right sister in G2. Finally, rules G2*aii,c,d conform to the fourth principle, according to which a category appears as a postfix if it cannot appear as a prefix according to the preceding three principles. The affixed string that G2* generates as the representation of the structural description of E2 with respect to G2 is given in E2*. the VP V knew C C that S the G &apos;s &apos;s &apos;s N VP V C that NP student VP V saw the child S E2* can be interpreted as the structural description of E2 with respect to G2 by the rules in R, with the addition of a rule to handle unary nonlexical branching (as in G2e), and a modification of Rc to prevent a postfix from simply covering a sequence of affixes already covered by a prefix. (This restriction is needed to prevent the postfix S in E2* from simply covering any of the subordinate clauses in that expression.) It is worth noting how the application of those rules dynamienlarges the is covered by the S prefix follows the words knew that. First teais covered; then teacher&apos;s sister;then teacher&apos;s sister&apos;s neighbor;and finally the teacher&apos;s sister&apos;s neighbor&apos;s friend. The derivation of E2* manifests first-degree center embedding of the category S*, as a result of the treatment of S as both a prefix and a suffix in G2*. However, no derivation of an affixed string generated by G2* manifests any greater degree of center embedding; hence, the affixed strings associated with the expressions of L2 can still be assigned to them by a finite-state parser. The added complexity involved in interpreting E2* results from the fact that all but the first of sequences in E2* are covered by prefix Ss, so that the constituents covered by the postfix S in E2* according to rule Rc are considerably far away from it. It will be noted that we have provided two logically independent sets of principles by which affixed grammars may be constructed from a given CFPSG. The first set is explicitly designed to preserve the property of noncenter-embedding. The second is designed to maximize the use of prefixes on the basis of being able to predict the identity of a constituent by the time its leftmost descendent has been identified. There is no reason to believe a priori that affixed grammars constructed according to the second set of principles should preserve noncenter-embedding, and indeed as we have just seen, they don&apos;t. However, we conjecture that natural languages are designed so that representations of the structural descriptions of acceptable expressions of those languages can be assigned to them by finite-state parsers that operate by identifying constituents as quickly as We call this the Finite- State Parser Hypothesis. The four principles for determining whether to use a prefix or a postfix to mark the presence of a particular constituent apply to grammars that are center embedding as well as to those that are not. Suppose we extend the grammar G2 by replacing rules G2e and f by rules G2e&apos; and f&apos; respectively, and adding rules G2m-s as follows: (PP1) (NP) 0) NP NP PPI P1 PP2 P2 VP —9. VP IA, A r. P1 --4 of P2 on, Among the expressions generated by the extended grammar G2 are those in E3. a. the boss knew that the teacher the child yesterday b. the friend of the teacher&apos;s sister 26 Although each of the expressions in E3 is ambiguous with respect to G2, each has a strongly preferred interpretation. Moreover, under each interpretation, each of these sentences manifests first-degree center embedding. In E3, the includ- VP the childis wholly contained in the in- VP that the teacher saw the child yesterday;and in E3b, the included NP teacher wholly contained in the including NP friend of the teacher&apos;s sister. Curiously enough, the extension of the affix grammar that our principles derive from the extension of the grammar G2 just given associates only one affixed string with each of the expressions in E3. That grammar is obtained by replacing rules G2*e and F with G2*e&apos; and f&apos; respectively, and adding the rules C2*m-s as follows. (C2*) e&apos;. R (PP1*) --A. VP V* (NP*) (fPP2*, 6*}) m. NP* NP* PP2* NP n. PP1* --* PP1 P1* NP* o. PP2* --* PP2 P2* NP* p. VP* --* VP* iA*, PP2*} VP Next, consider E3b and its associated affixed string E3b. According to rule Rc, the is a postfix that covers the affixes NP and G. Two occurrences of the prefix NP are available to be covered; again, we may suppose that rule Rc picks out the nearer one. If so, then automatically the NP, teacher&apos;s sister,is covered by PP1, again in accordance with the natural interpretation of the expression as a whole. This completes our demonstration of the ability of affixed strings to represent the structural descriptions of the acceptable sentences of a natural language in a manner which enables them to be parsed by a finite-state device, and which also predicts the way in which (at least) certain expressions with center embedding are actually interpreted. Much more could be said about the system of representation we propose, but time and space limitations preclude further discussion here. We leave as exercises to the reader the demonstration that the expression E4a has a single affixed string associated with it by G2*, and that the left-branching (stacked) interpretation of E4b is predicted to be preferred over the rightbranching interpretation. (E4) a. the student saw the teacher in the house b. the house in the woods near the --* A yesterday r. P1*#P1 of s. P2* P2 fin, on, ...3 The affix strings that the extended affix grammar G2* associates with the expressions in E3 are given in E3*. a. NP D the boss VP V knew C C that NPD the teacher VP V saw NP D child A yesterday VP S NP D the friend PP1 P1 of NP D teacher G &apos;s sister NP We contend that the fact that the expressions in E3 have a single strongly preferred interpretation results from the fact that those expressions have a single affixed string associated with them. Consider first E3a and its associated affixed string E3*a. According to rule Rc, the affix VP following yesterday is a postfix which covers the affixes VP and A. Now, there is only one occurrence of A in E3*a, namely the one that immediateprecedes yesterday;hence that must be the occurrence which is covered by the postfix VP. On the other hand, there are two occurrences of prefix VP in E3*a that can legitimately be covered by the postfix, the one before saw and the one before knew. Suppose in such circumstances, rule Rc picks out the nearer prefix. Then automatically complex VP, the child yesterday,is covered by the subordinate S prefix, in accordance with the natural interpretation of the expression as a whole. ACKNOWLEDGMENT We thank Maria Edelstein for her invaluable help in developing the work presented here.</abstract>
<note confidence="0.797835833333333">REFERENCES Forster, Kenneth I. (1976) Accessing the mental lexicon. In R.J. Wales and E.T. Walker, Approaches to Language Mechanisms. Amsterdam: North-Holland. Ray S. (1977) Syntax.Cambridge, Mass.: MIT Press. Langendoen, D. Terence (1975) Finite-state parsing of phrase-structure languages and the status of readjustment rules in grammar. Inquiry6.533-54. 27</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kenneth I Forster</author>
</authors>
<title>Accessing the mental lexicon.</title>
<date>1976</date>
<editor>In R.J. Wales and E.T. Walker, eds.,</editor>
<publisher>North-Holland.</publisher>
<location>New</location>
<contexts>
<context position="7469" citStr="Forster 1976" startWordPosition="1265" endWordPosition="1266">motivated if the only criteria for choosing an affix type have to do with direction of recursion. For affix grammars of natural languages, however, one can motivate the decision to use a particular type of affix by principles other than those having to do with direction of recursion. The use of a prefix can be interpreted as indicating a decision (or guess) on the part of the language user as to the identity of a particular constituent on the basis of the identity of the first constituent in it. Since lexical items are assigned to lexical categories essentially as soon as they are recognized (Forster 1976), we may suppose first that prefixes are used for rules such as those in Gl*c-e that assign lexical items to lexical categories. Second, if, as seems reasonable, a decision about the identity of constituents is always made as soon as possible, then we may suppose that prefixes are used for all rules in which the leftmost daughter of a particular constituent provides sufficient evidence for the identification of that constituent; e.g., if the leftmost daughter is either the specifier or the head of that constituent in the sense of Jackendoff (1977). Third, we may suppose that even if the leftmo</context>
</contexts>
<marker>Forster, 1976</marker>
<rawString>Forster, Kenneth I. (1976) Accessing the mental lexicon. In R.J. Wales and E.T. Walker, eds., New Approaches to Language Mechanisms. Amsterdam: North-Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray S Jackendoff</author>
</authors>
<title>X-Bar Syntax.</title>
<date>1977</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, Mass.:</location>
<contexts>
<context position="8022" citStr="Jackendoff (1977)" startWordPosition="1359" endWordPosition="1361">gories essentially as soon as they are recognized (Forster 1976), we may suppose first that prefixes are used for rules such as those in Gl*c-e that assign lexical items to lexical categories. Second, if, as seems reasonable, a decision about the identity of constituents is always made as soon as possible, then we may suppose that prefixes are used for all rules in which the leftmost daughter of a particular constituent provides sufficient evidence for the identification of that constituent; e.g., if the leftmost daughter is either the specifier or the head of that constituent in the sense of Jackendoff (1977). Third, we may suppose that even if the leftmost daughter of a particular constituent does not provide sufficient evidence for the identification of that constituent, a prefix may still be used if that constituent is the left sister of a constituent that provides sufficient evidence for its identification. Fourth, we may suppose that postfixes are used in all other cases. To illustrate the use of these four principles, consider the noncenter-embedding partial grammar G2 that generates a fragment of English that we call L2. (G2) a. S —* NP VP b. NP ---* D R c. NP—. a d. U NP G e. N f. VP V (iN</context>
</contexts>
<marker>Jackendoff, 1977</marker>
<rawString>Jackendoff, Ray S. (1977) X-Bar Syntax. Cambridge, Mass.: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Terence Langendoen</author>
</authors>
<title>Finite-state parsing of phrase-structure languages and the status of readjustment rules in grammar.</title>
<date>1975</date>
<journal>Linguistic Inquiry</journal>
<pages>6--533</pages>
<contexts>
<context position="3989" citStr="Langendoen 1975" startWordPosition="651" endWordPosition="652">generates strings that represent the con— stituent structures of the noncenter—embedded ex— pressions generated by G, that is right—recursive wherever G is right—recursive and is left—recur— sive wherever G is left—recursive. In order to find such a G*, we must first de— termine what kinds of strings are available that can represent constituent structures and at the same time can be directly generated by noncenter— embedding grammars. Full bracketing diagrams are not suitable, since grammars that generate them are center embedding whenever the original gram— mars are left— or right—recursive (Langendoen 1975). Suppose, however, that we leave off right brackets in right—recursive structures and left brackets in left—recursive structures. In right— recursive structures, the positions of the left brackets that remain indicate where each constitu— ent begins; the position where each constituent ends can be determined by a simple counting pro— cedure provided that the number of daughters of that constituent is known (e.g., when the original grammar is in Chomsky—normal—form). Similarly, in left—recursive structures, the positions of the right brackets that remain indicate where each constituent ends, a</context>
</contexts>
<marker>Langendoen, 1975</marker>
<rawString>Langendoen, D. Terence (1975) Finite-state parsing of phrase-structure languages and the status of readjustment rules in grammar. Linguistic Inquiry 6.533-54.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>