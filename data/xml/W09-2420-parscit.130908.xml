<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000310">
<title confidence="0.9795895">
SemEval-2010 Task 17: All-words Word Sense Disambiguation
on a Specific Domain
</title>
<author confidence="0.44255">
Eneko Agirre
</author>
<note confidence="0.766096">
IXA NLP group
UBC
</note>
<address confidence="0.388684">
Donostia, Basque Country
</address>
<email confidence="0.989439">
e.agirre@ehu.es
</email>
<note confidence="0.928773333333333">
Oier Lopez de Lacalle
IXA NLP group
UBC
</note>
<address confidence="0.427011">
Donostia, Basque Country
</address>
<email confidence="0.979597">
oier.lopezdelacalle@ehu.es
</email>
<author confidence="0.98661">
Christiane Fellbaum
</author>
<affiliation confidence="0.843435">
Department of Computer Science
Princeton University
Princeton, USA
</affiliation>
<email confidence="0.998004">
fellbaum@princeton.edu
</email>
<author confidence="0.985047">
Andrea Marchetti
</author>
<affiliation confidence="0.749460333333333">
IIT
CNR
Pisa, Italy
</affiliation>
<email confidence="0.957329">
andrea.marchetti@iit.cnr.it
</email>
<author confidence="0.917191">
Antonio Toral
</author>
<affiliation confidence="0.672666333333333">
ILC
CNR
Pisa, Italy
</affiliation>
<email confidence="0.958826">
antonio.toral@ilc.cnr.it
</email>
<author confidence="0.964847">
Piek Vossen
</author>
<affiliation confidence="0.780989">
Faculteit der Letteren
Vrije Universiteit Amsterdam
</affiliation>
<address confidence="0.680783">
Amsterdam, Netherlands
</address>
<email confidence="0.986164">
p.vossen@let.vu.nl
</email>
<sectionHeader confidence="0.99551" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999732538461538">
Domain portability and adaptation of NLP
components and Word Sense Disambiguation
systems present new challenges. The diffi-
culties found by supervised systems to adapt
might change the way we assess the strengths
and weaknesses of supervised and knowledge-
based WSD systems. Unfortunately, all ex-
isting evaluation datasets for specific domains
are lexical-sample corpora. With this paper
we want to motivate the creation of an all-
words test dataset for WSD on the environ-
ment domain in several languages, and present
the overall design of this SemEval task.
</bodyText>
<sectionHeader confidence="0.999067" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998276822222222">
Word Sense Disambiguation (WSD) competitions
have focused on general domain texts, as attested
in the last Senseval and Semeval competitions (Kil-
garriff, 2001; Mihalcea et al., 2004; Pradhan et al.,
2007). Specific domains pose fresh challenges to
WSD systems: the context in which the senses occur
might change, distributions and predominant senses
vary, some words tend to occur in fewer senses in
specific domains, and new senses and terms might
be involved. Both supervised and knowledge-based
systems are affected by these issues: while the first
suffer from different context and sense priors, the
later suffer from lack of coverage of domain-related
words and information.
Domain adaptation of supervised techniques is a
hot issue in Natural Language Processing, includ-
ing Word Sense Disambiguation. Supervised Word
Sense Disambiguation systems trained on general
corpora are known to perform worse when applied
to specific domains (Escudero et al., 2000; Martinez
and Agirre, 2000), and domain adaptation tech-
niques have been proposed as a solution to this prob-
lem with mixed results.
Current research on applying WSD to specific do-
mains has been evaluated on three available lexical-
sample datasets (Ng and Lee, 1996; Weeber et al.,
2001; Koeling et al., 2005). This kind of dataset
contains hand-labeled examples for a handful of se-
lected target words. As the systems are evaluated on
a few words, the actual performance of the systems
over complete texts can not be measured. Differ-
ences in behavior of WSD systems when applied to
lexical-sample and all-words datasets have been ob-
served on previous Senseval and Semeval competi-
tions (Kilgarriff, 2001; Mihalcea et al., 2004; Prad-
han et al., 2007): supervised systems attain results
on the high 80’s and beat the most frequent base-
line by a large margin for lexical-sample datasets,
but results on the all-words datasets were much more
modest, on the low 70’s, and a few points above the
most frequent baseline.
Thus, the behaviour of WSD systems on domain-
specific texts is largely unknown. While some words
could be supposed to behave in similar ways, and
thus be amenable to be properly treated by a generic
</bodyText>
<page confidence="0.985069">
123
</page>
<note confidence="0.799728">
Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 123–128,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.99919">
WSD algorithm, other words have senses closely
linked to the domain, and might be disambiguated
using purpose-built domain adaptation strategies (cf.
Section 4). While it seems that domain-specific
WSD might be a tougher problem than generic
WSD, it might well be that domain-related words
are easier to disambiguate.
The main goal of this task is to provide a mul-
tilingual testbed to evaluate WSD systems when
faced with full-texts from a specific domain, that of
environment-related texts. The paper is structured
as follows. The next section presents current lexi-
cal sample datasets for domain-specific WSD. Sec-
tion 3 presents some possible settings for domain
adaptation. Section 4 reviews the state-of-the art in
domain-specific WSD. Section 5 presents the design
of our task, and finally, Section 6 draws some con-
clusions.
</bodyText>
<sectionHeader confidence="0.875126" genericHeader="method">
2 Specific domain datasets available
</sectionHeader>
<bodyText confidence="0.999989661290323">
We will briefly present the three existing datasets
for domain-related studies in WSD, which are all
lexical-sample.
The most commonly used dataset is the Defense
Science Organization (DSO) corpus (Ng and Lee,
1996), which comprises sentences from two differ-
ent corpora. The first is the Wall Street Journal
(WSJ), which belongs to the financial domain, and
the second is the Brown Corpus (BC) which is a bal-
anced corpora of English usage. 191 polysemous
words (nouns and verbs) of high frequency in WSJ
and BC were selected and a total of 192,800 occur-
rences of these words were tagged with WordNet 1.5
senses, more than 1,000 instances per word in aver-
age. The examples from BC comprise 78,080 oc-
currences of word senses, and examples from WSJ
consist on 114,794 occurrences. In domain adapta-
tion experiments, the Brown Corpus examples play
the role of general corpora, and the examples from
the WSJ play the role of domain-specific examples.
Koeling et al. (2005) present a corpus were the
examples are drawn from the balanced BNC cor-
pus (Leech, 1992) and the SPORTS and FINANCES
sections of the newswire Reuters corpus (Rose et al.,
2002), comprising around 300 examples (roughly
100 from each of those corpora) for each of the 41
nouns. The nouns were selected because they were
salient in either the SPORTS or FINANCES domains,
or because they had senses linked to those domains.
The occurrences were hand-tagged with the senses
from WordNet version 1.7.1 (Fellbaum, 1998). In
domain adaptation experiments the BNC examples
play the role of general corpora, and the FINANCES
and SPORTS examples the role of two specific do-
main corpora.
Finally, a dataset for biomedicine was developed
by Weeber et al. (2001), and has been used as
a benchmark by many independent groups. The
UMLS Metathesaurus was used to provide a set of
possible meanings for terms in biomedical text. 50
ambiguous terms which occur frequently in MED-
LINE were chosen for inclusion in the test set. 100
instances of each term were selected from citations
added to the MEDLINE database in 1998 and man-
ually disambiguated by 11 annotators. Twelve terms
were flagged as ”problematic” due to substantial dis-
agreement between the annotators. In addition to the
meanings defined in UMLS, annotators had the op-
tion of assigning a special tag (”none”) when none
of the UMLS meanings seemed appropriate.
Although these three corpora are useful for WSD
research, it is difficult to infer which would be the
performance of a WSD system on full texts. The
corpus of Koeling et al., for instance, only includes
words which where salient for the target domains,
but the behavior of WSD systems on other words
cannot be explored. We would also like to note that
while the biomedicine corpus tackles scholarly text
of a very specific domain, the WSJ part of the DSO
includes texts from a financially oriented newspaper,
but also includes news of general interest which have
no strict relation to the finance domain.
</bodyText>
<sectionHeader confidence="0.831422" genericHeader="method">
3 Possible settings for domain adaptation
</sectionHeader>
<bodyText confidence="0.9994848">
When performing supervised WSD on specific do-
mains the first setting is to train on a general domain
data set and to test on the specific domain (source
setting). If performance would be optimal, this
would be the ideal solution, as it would show that a
generic WSD system is robust enough to tackle texts
from new domains, and domain adaptation would
not be necessary.
The second setting (target setting) would be to
train the WSD systems only using examples from
</bodyText>
<page confidence="0.991964">
124
</page>
<bodyText confidence="0.99997425">
the target domain. If this would be the optimal set-
ting, it would show that there is no cost-effective
method for domain adaptation. WSD systems would
need fresh examples every time they were deployed
in new domains, and examples from general do-
mains could be discarded.
In the third setting, the WSD system is trained
with examples coming from both the general domain
and the specific domain. Good results in this setting
would show that supervised domain adaptation is
working, and that generic WSD systems can be sup-
plemented with hand-tagged examples from the tar-
get domain.
There is an additional setting, where a generic
WSD system is supplemented with untagged exam-
ples from the domain. Good results in this setting
would show that semi-supervised domain adapta-
tion works, and that generic WSD systems can be
supplemented with untagged examples from the tar-
get domain in order to improve their results.
Most of current all-words generic supervised
WSD systems take SemCor (Miller et al., 1993) as
their source corpus, i.e. they are trained on SemCor
examples and then applied to new examples. Sem-
Cor is the largest publicly available annotated cor-
pus. It’s mainly a subset of the Brown Corpus, plus
the novel The Red Badge of Courage. The Brown
corpus is balanced, yet not from the general domain,
as it comprises 500 documents drawn from differ-
ent domains, each approximately 2000 words long.
Although the Brown corpus is balanced, SemCor is
not, as the documents were not chosen at random.
</bodyText>
<sectionHeader confidence="0.98929" genericHeader="method">
4 State-of-the-art in WSD for specific
domains
</sectionHeader>
<bodyText confidence="0.999959757575758">
Initial work on domain adaptation for WSD sys-
tems showed that WSD systems were not able to
obtain better results on the source or adaptation set-
tings compared to the target settings (Escudero et
al., 2000), showing that a generic WSD system (i.e.
based on hand-annotated examples from a generic
corpus) would not be useful when moved to new do-
mains.
Escudero et al. (2000) tested the supervised adap-
tation scenario on the DSO corpus, which had exam-
ples from the Brown Corpus and Wall Street Journal
corpus. They found that the source corpus did not
help when tagging the target corpus, showing that
tagged corpora from each domain would suffice, and
concluding that hand tagging a large general corpus
would not guarantee robust broad-coverage WSD.
Agirre and Martinez (2000) used the same DSO cor-
pus and showed that training on the subset of the
source corpus that is topically related to the target
corpus does allow for domain adaptation, obtaining
better results than training on the target data alone.
In (Agirre and Lopez de Lacalle, 2008), the au-
thors also show that state-of-the-art WSD systems
are not able to adapt to the domains in the context
of the Koeling et al. (2005) dataset. While WSD
systems trained on the target domain obtained 85.1
and 87.0 of precision on the sports and finances do-
mains, respectively, the same systems trained on the
BNC corpus (considered as a general domain cor-
pus) obtained 53.9 and 62.9 of precision on sports
and finances, respectively. Training on both source
and target was inferior that using the target examples
alone.
</bodyText>
<subsectionHeader confidence="0.743859">
Supervised adaptation
</subsectionHeader>
<bodyText confidence="0.99984904">
Supervised adaptation for other NLP tasks has been
widely reported. For instance, (Daum´e III, 2007)
shows that a simple feature augmentation method
for SVM is able to effectively use both labeled tar-
get and source data to provide the best domain-
adaptation results in a number of NLP tasks. His
method improves or equals over previously explored
more sophisticated methods (Daum´e III and Marcu,
2006; Chelba and Acero, 2004). In contrast, (Agirre
and Lopez de Lacalle, 2009) reimplemented this
method and showed that the improvement on WSD
in the (Koeling et al., 2005) data was marginal.
Better results have been obtained using purpose-
built adaptation methods. Chan and Ng (2007) per-
formed supervised domain adaptation on a manu-
ally selected subset of 21 nouns from the DSO cor-
pus. They used active learning, count-merging, and
predominant sense estimation in order to save tar-
get annotation effort. They showed that adding just
30% of the target data to the source examples the
same precision as the full combination of target and
source data could be achieved. They also showed
that using the source corpus significantly improved
results when only 10%-30% of the target corpus
was used for training. In followup work (Zhong et
</bodyText>
<page confidence="0.997304">
125
</page>
<bodyText confidence="0.994311666666667">
Projections for 2100 suggest that temperature in Europe will have risen by between 2 to 6.3 C above 1990
levels. The sea level is projected to rise, and a greater frequency and intensity of extreme weather events are
expected. Even if emissions of greenhouse gases stop today, these changes would continue for many decades
and in the case of sea level for centuries. This is due to the historical build up of the gases in the atmosphere
and time lags in the response of climatic and oceanic systems to changes in the atmospheric concentration
of the gases.
</bodyText>
<figureCaption confidence="0.999405">
Figure 1: Sample text from the environment domain.
</figureCaption>
<bodyText confidence="0.997228176470588">
al., 2008), the feature augmentation approach was
combined with active learning and tested on the
OntoNotes corpus, on a large domain-adaptation ex-
periment. They significantly reduced the effort of
hand-tagging, but only obtained positive domain-
adaptation results for smaller fractions of the target
corpus.
In (Agirre and Lopez de Lacalle, 2009) the au-
thors report successful adaptation on the (Koeling
et al., 2005) dataset on supervised setting. Their
method is based on the use of unlabeled data, re-
ducing the feature space with SVD, and combina-
tion of features using an ensemble of kernel meth-
ods. They report 22% error reduction when using
both source and target data compared to a classifier
trained on target the target data alone, even when the
full dataset is used.
</bodyText>
<subsectionHeader confidence="0.525438">
Semi-supervised adaptation
</subsectionHeader>
<bodyText confidence="0.999936615384615">
There are less works on semi-supervised domain
adaptation in NLP tasks, and fewer in WSD task.
Blitzer et al. (2006) used Structural Correspondence
Learning and unlabeled data to adapt a Part-of-
Speech tagger. They carefully select so-called pivot
features to learn linear predictors, perform SVD on
the weights learned by the predictor, and thus learn
correspondences among features in both source and
target domains. Agirre and Lopez de Lacalle (2008)
show that methods based on SVD with unlabeled
data and combination of distinct feature spaces pro-
duce positive semi-supervised domain adaptation re-
sults for WSD.
</bodyText>
<subsectionHeader confidence="0.642178">
Unsupervised adaptation
</subsectionHeader>
<bodyText confidence="0.9998955">
In this context, we take unsupervised to mean
Knowledge-Based methods which do not require
hand-tagged corpora. The predominant sense acqui-
sition method was succesfully applied to specific do-
mains in (Koeling et al., 2005). The methos has two
steps: In the first, a corpus of untagged text from the
target domain is used to construct a thesaurus of sim-
ilar words. In the second, each target word is disam-
biguated using pairwise WordNet-based similarity
measures, taking as pairs the target word and each of
the most related words according to the thesaurus up
to a certain threshold. This method aims to obtain,
for each target word, the sense which is the most
predominant for the target corpus. When a general
corpus is used, the most predominant sense in gen-
eral is obtained, and when a domain-specific corpus
is used, the most predominant sense for that corpus
is obtained (Koeling et al., 2005). The main motiva-
tion of the authors is that the most frequent sense is a
very powerful baseline, but it is one which requires
hand-tagging text, while their method yields simi-
lar information automatically. The results show that
they are able to obtain good results. In related work,
(Agirre et al., 2009) report improved results using
the same strategy but applying a graph-based WSD
method, and highlight the domain-adaptation poten-
tial of unsupervised knowledge-based WSD systems
compared to supervised WSD.
</bodyText>
<sectionHeader confidence="0.897474" genericHeader="method">
5 Design of the WSD-domain task
</sectionHeader>
<bodyText confidence="0.999780416666667">
This task was designed in the context of Ky-
oto (Piek Vossen and VanGent, 2008)1, an Asian-
European project that develops a community plat-
form for modeling knowledge and finding facts
across languages and cultures. The platform op-
erates as a Wiki system with an ontological sup-
port that social communities can use to agree on the
meaning of terms in specific domains of their inter-
est. Kyoto will focus on the environmental domain
because it poses interesting challenges for informa-
tion sharing, but the techniques and platforms will
be independent of the application domain. Kyoto
</bodyText>
<footnote confidence="0.99213">
1http://www.kyoto-project.eu/
</footnote>
<page confidence="0.997342">
126
</page>
<bodyText confidence="0.999975771428571">
will make use of semantic technologies based on
ontologies and WSD in order to extract and repre-
sent relevant information for the domain, and is thus
interested on measuring the performance of WSD
techniques on this domain.
The WSD-domain task will comprise comparable
all-words test corpora on the environment domain.
Texts from the European Center for Nature Con-
servation2 and Worldwide Wildlife Forum3 will be
used in order to build domain specific test corpora.
We will select documents that are written for a gen-
eral but interested public and that involve specific
terms from the domain. The document content will
be comparable across languages. Figure 1 shows an
example in English related to global warming.
The data will be available in a number of lan-
guages: English, Dutch, Italian and Chinese. The
sense inventories will be based on wordnets of the
respective languages, which will be updated to in-
clude new vocabulary and senses. The test data will
comprise three documents of around 2000 words
each for each language. The annotation procedure
will involve double-blind annotation plus adjudica-
tion, and inter-tagger agreement data will be pro-
vided. The formats and scoring software will fol-
low those of Senseval-34 and SemEval-20075 En-
glish all-words tasks.
There will not be training data available, but par-
ticipants are free to use existing hand-tagged cor-
pora and lexical resources (e.g. SemCor and pre-
vious Senseval and SemEval data). We plan to make
available a corpus of documents from the same do-
main as the selected documents, as well as wordnets
updated to include the terms and senses in the se-
lected documents.
</bodyText>
<sectionHeader confidence="0.996468" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999849">
Domain portability and adaptation of NLP com-
ponents and Word Sense Disambiguation systems
present new challenges. The difficulties found by
supervised systems to adapt might change the way
we assess the strengths and weaknesses of super-
vised and knowledge-based WSD systems. Unfor-
tunately, all existing evaluation datasets for specific
</bodyText>
<footnote confidence="0.99996475">
2http://www.ecnc.org
3http://www.wwf.org
4http://www.senseval.org/senseval3
5http://nlp.cs.swarthmore.edu/semeval/
</footnote>
<bodyText confidence="0.99938625">
domains are lexical-sample corpora. With this paper
we have motivated the creation of an all-words test
dataset for WSD on the environment domain in sev-
eral languages, and presented the overall design of
this SemEval task.
Further details can be obtained from the Semeval-
20106 website, our task website7, and in our distri-
bution list8
</bodyText>
<sectionHeader confidence="0.998645" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.99984125">
The organization of the task is partially funded
by the European Commission (KYOTO FP7 ICT-
2007-211423) and the Spanish Research Depart-
ment (KNOW TIN2006-15049-C03-01).
</bodyText>
<sectionHeader confidence="0.998841" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997303258064516">
Eneko Agirre and Oier Lopez de Lacalle. 2008. On ro-
bustness and domain adaptation using SVD for word
sense disambiguation. In Proceedings of the 22nd In-
ternational Conference on Computational Linguistics
(Coling 2008), pages 17–24, Manchester, UK, August.
Coling 2008 Organizing Committee.
Eneko Agirre and Oier Lopez de Lacalle. 2009. Super-
vised domain adaptation for wsd. In Proceedings of
the 12th Conference of the European Chapter of the
Association for Computational Linguistics (EACL-09).
E. Agirre, O. Lopez de Lacalle, and A. Soroa. 2009.
Knowledge-based WSD and specific domains: Per-
forming over supervised WSD. In Proceedings of IJ-
CAI, Pasadena, USA.
John Blitzer, Ryan McDonald, and Fernando Pereira.
2006. Domain adaptation with structural correspon-
dence learning. In Proceedings of the 2006 Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 120–128, Sydney, Australia, July. As-
sociation for Computational Linguistics.
Yee Seng Chan and Hwee Tou Ng. 2007. Domain adap-
tation with active learning for word sense disambigua-
tion. In Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics, pages
49–56, Prague, Czech Republic, June. Association for
Computational Linguistics.
Ciprian Chelba and Alex Acero. 2004. Adaptation of
maximum entropy classifier: Little data can help a
lot. In Proceedings of the Conference on Empirical
Methods in Natural Language Processing (EMNLP),
Barcelona, Spain.
</reference>
<footnote confidence="0.999618333333333">
6http://semeval2.fbk.eu/
7http://xmlgroup.iit.cnr.it/SemEval2010/
8http://groups.google.com/groups/wsd-domain
</footnote>
<page confidence="0.989617">
127
</page>
<reference confidence="0.999283481481482">
Hal Daum´e III and Daniel Marcu. 2006. Domain adap-
tation for statistical classifiers. Journal of Artificial
Intelligence Research, 26:101–126.
Hal Daum´e III. 2007. Frustratingly easy domain adapta-
tion. In Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics, pages
256–263, Prague, Czech Republic, June. Association
for Computational Linguistics.
Gerard Escudero, Lluiz M´arquez, and German Rigau.
2000. An Empirical Study of the Domain Dependence
of Supervised Word Sense Disambiguation Systems.
Proceedings of the joint SIGDAT Conference on Em-
pirical Methods in Natural Language Processing and
Very Large Corpora, EMNLP/VLC.
C. Fellbaum. 1998. WordNet: An Electronic Lexical
Database. MIT Press.
A. Kilgarriff. 2001. English Lexical Sample Task De-
scription. In Proceedings of the Second International
Workshop on evaluating Word Sense Disambiguation
Systems, Toulouse, France.
R. Koeling, D. McCarthy, and J. Carroll. 2005. Domain-
specific sense distributions and predominant sense
acquisition. In Proceedings of the Human Lan-
guage Technology Conference and Conference on
Empirical Methods in Natural Language Processing.
HLT/EMNLP, pages 419–426, Ann Arbor, Michigan.
G. Leech. 1992. 100 million words of English:
the British National Corpus. Language Research,
28(1):1–13.
David Martinez and Eneko Agirre. 2000. One Sense per
Collocation and Genre/Topic Variations. Conference
on Empirical Method in Natural Language.
R. Mihalcea, T. Chklovski, and Adam Killgariff. 2004.
The Senseval-3 English lexical sample task. In Pro-
ceedings of the 3rd ACL workshop on the Evaluation
of Systems for the Semantic Analysis of Text (SENSE-
VAL), Barcelona, Spain.
G.A. Miller, C. Leacock, R. Tengi, and R.Bunker. 1993.
A Semantic Concordance. In Proceedings of the
ARPA Human Language Technology Workshop. Dis-
tributed as Human Language Technology by San Ma-
teo, CA: Morgan Kaufmann Publishers., pages 303–
308, Princeton, NJ.
Hwee Tou Ng and Hian Beng Lee. 1996. Integrat-
ing multiple knowledge sources to disambiguate word
sense: An exemplar-based approach. In Proceedings
of the 34th Annual Meeting of the Association for
Computationla Linguistics (ACL), pages 40–47.
Nicoletta Calzolari Christiane Fellbaum Shu-kai Hsieh
Chu-Ren Huang Hitoshi Isahara Kyoko Kanzaki An-
drea Marchetti Monica Monachini Federico Neri
Remo Raffaelli German Rigau Maurizio Tescon
Piek Vossen, Eneko Agirre and Joop VanGent. 2008.
Kyoto: a system for mining, structuring and distribut-
ing knowledge across languages and cultures. In
European Language Resources Association (ELRA),
editor, Proceedings of the Sixth International Lan-
guage Resources and Evaluation (LREC’08), Mar-
rakech, Morocco, may.
Sameer Pradhan, Edward Loper, Dmitriy Dligach, and
Martha Palmer. 2007. Semeval-2007 task-17: English
lexical sample, srl and all words. In Proceedings of
the Fourth International Workshop on Semantic Eval-
uations (SemEval-2007), pages 87–92, Prague, Czech
Republic.
Tony G. Rose, Mark Stevenson, and Miles Whitehead.
2002. The Reuters Corpus Volumen 1: from Yes-
terday’s News to Tomorrow’s Language Resources.
In Proceedings of the Third International Conference
on Language Resources and Evaluation (LREC-2002),
pages 827–832, Las Palmas, Canary Islands.
Marc Weeber, James G. Mork, and Alan R. Aronson.
2001. Developing a test collection for biomedical
word sense disambiguation. In Proceedings of the
AMAI Symposium, pages 746–750, Washington, DC.
Zhi Zhong, Hwee Tou Ng, and Yee Seng Chan. 2008.
Word sense disambiguation using OntoNotes: An em-
pirical study. In Proceedings of the 2008 Conference
on Empirical Methods in Natural Language Process-
ing, pages 1002–1010, Honolulu, Hawaii, October.
Association for Computational Linguistics.
</reference>
<page confidence="0.996747">
128
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.015130">
<title confidence="0.9879175">SemEval-2010 Task 17: All-words Word Sense on a Specific Domain</title>
<author confidence="0.671664">Eneko</author>
<affiliation confidence="0.809284">IXA NLP</affiliation>
<address confidence="0.657541">Donostia, Basque Country</address>
<email confidence="0.827467">e.agirre@ehu.es</email>
<author confidence="0.860971">Oier Lopez de</author>
<affiliation confidence="0.916159">IXA NLP</affiliation>
<address confidence="0.670755">Donostia, Basque Country</address>
<email confidence="0.729349">oier.lopezdelacalle@ehu.es</email>
<author confidence="0.890855">Christiane</author>
<affiliation confidence="0.7897515">Department of Computer Princeton</affiliation>
<address confidence="0.890927">Princeton, USA</address>
<email confidence="0.999755">fellbaum@princeton.edu</email>
<author confidence="0.82191">Andrea</author>
<address confidence="0.875238">Pisa, Italy</address>
<email confidence="0.985836">andrea.marchetti@iit.cnr.it</email>
<affiliation confidence="0.375523">Antonio</affiliation>
<address confidence="0.841814">Pisa, Italy</address>
<email confidence="0.98803">antonio.toral@ilc.cnr.it</email>
<author confidence="0.790201">Piek Faculteit der</author>
<affiliation confidence="0.989304">Vrije Universiteit</affiliation>
<address confidence="0.996021">Amsterdam, Netherlands</address>
<email confidence="0.996866">p.vossen@let.vu.nl</email>
<abstract confidence="0.990112928571429">Domain portability and adaptation of NLP components and Word Sense Disambiguation systems present new challenges. The difficulties found by supervised systems to adapt might change the way we assess the strengths and weaknesses of supervised and knowledgebased WSD systems. Unfortunately, all existing evaluation datasets for specific domains are lexical-sample corpora. With this paper we want to motivate the creation of an allwords test dataset for WSD on the environment domain in several languages, and present the overall design of this SemEval task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Oier Lopez de Lacalle</author>
</authors>
<title>On robustness and domain adaptation using SVD for word sense disambiguation.</title>
<date>2008</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (Coling</booktitle>
<pages>17--24</pages>
<location>Manchester, UK,</location>
<marker>Agirre, de Lacalle, 2008</marker>
<rawString>Eneko Agirre and Oier Lopez de Lacalle. 2008. On robustness and domain adaptation using SVD for word sense disambiguation. In Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 17–24, Manchester, UK, August. Coling 2008 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Oier Lopez de Lacalle</author>
</authors>
<title>Supervised domain adaptation for wsd.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL-09).</booktitle>
<marker>Agirre, de Lacalle, 2009</marker>
<rawString>Eneko Agirre and Oier Lopez de Lacalle. 2009. Supervised domain adaptation for wsd. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL-09).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>O Lopez de Lacalle</author>
<author>A Soroa</author>
</authors>
<title>Knowledge-based WSD and specific domains: Performing over supervised WSD.</title>
<date>2009</date>
<booktitle>In Proceedings of IJCAI,</booktitle>
<location>Pasadena, USA.</location>
<marker>Agirre, de Lacalle, Soroa, 2009</marker>
<rawString>E. Agirre, O. Lopez de Lacalle, and A. Soroa. 2009. Knowledge-based WSD and specific domains: Performing over supervised WSD. In Proceedings of IJCAI, Pasadena, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Domain adaptation with structural correspondence learning.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>120--128</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="13788" citStr="Blitzer et al. (2006)" startWordPosition="2235" endWordPosition="2238">t corpus. In (Agirre and Lopez de Lacalle, 2009) the authors report successful adaptation on the (Koeling et al., 2005) dataset on supervised setting. Their method is based on the use of unlabeled data, reducing the feature space with SVD, and combination of features using an ensemble of kernel methods. They report 22% error reduction when using both source and target data compared to a classifier trained on target the target data alone, even when the full dataset is used. Semi-supervised adaptation There are less works on semi-supervised domain adaptation in NLP tasks, and fewer in WSD task. Blitzer et al. (2006) used Structural Correspondence Learning and unlabeled data to adapt a Part-ofSpeech tagger. They carefully select so-called pivot features to learn linear predictors, perform SVD on the weights learned by the predictor, and thus learn correspondences among features in both source and target domains. Agirre and Lopez de Lacalle (2008) show that methods based on SVD with unlabeled data and combination of distinct feature spaces produce positive semi-supervised domain adaptation results for WSD. Unsupervised adaptation In this context, we take unsupervised to mean Knowledge-Based methods which d</context>
</contexts>
<marker>Blitzer, McDonald, Pereira, 2006</marker>
<rawString>John Blitzer, Ryan McDonald, and Fernando Pereira. 2006. Domain adaptation with structural correspondence learning. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 120–128, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Seng Chan</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Domain adaptation with active learning for word sense disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>49--56</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="11707" citStr="Chan and Ng (2007)" startWordPosition="1889" endWordPosition="1892">ted. For instance, (Daum´e III, 2007) shows that a simple feature augmentation method for SVM is able to effectively use both labeled target and source data to provide the best domainadaptation results in a number of NLP tasks. His method improves or equals over previously explored more sophisticated methods (Daum´e III and Marcu, 2006; Chelba and Acero, 2004). In contrast, (Agirre and Lopez de Lacalle, 2009) reimplemented this method and showed that the improvement on WSD in the (Koeling et al., 2005) data was marginal. Better results have been obtained using purposebuilt adaptation methods. Chan and Ng (2007) performed supervised domain adaptation on a manually selected subset of 21 nouns from the DSO corpus. They used active learning, count-merging, and predominant sense estimation in order to save target annotation effort. They showed that adding just 30% of the target data to the source examples the same precision as the full combination of target and source data could be achieved. They also showed that using the source corpus significantly improved results when only 10%-30% of the target corpus was used for training. In followup work (Zhong et 125 Projections for 2100 suggest that temperature </context>
</contexts>
<marker>Chan, Ng, 2007</marker>
<rawString>Yee Seng Chan and Hwee Tou Ng. 2007. Domain adaptation with active learning for word sense disambiguation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 49–56, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ciprian Chelba</author>
<author>Alex Acero</author>
</authors>
<title>Adaptation of maximum entropy classifier: Little data can help a lot.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="11451" citStr="Chelba and Acero, 2004" startWordPosition="1848" endWordPosition="1851"> domain corpus) obtained 53.9 and 62.9 of precision on sports and finances, respectively. Training on both source and target was inferior that using the target examples alone. Supervised adaptation Supervised adaptation for other NLP tasks has been widely reported. For instance, (Daum´e III, 2007) shows that a simple feature augmentation method for SVM is able to effectively use both labeled target and source data to provide the best domainadaptation results in a number of NLP tasks. His method improves or equals over previously explored more sophisticated methods (Daum´e III and Marcu, 2006; Chelba and Acero, 2004). In contrast, (Agirre and Lopez de Lacalle, 2009) reimplemented this method and showed that the improvement on WSD in the (Koeling et al., 2005) data was marginal. Better results have been obtained using purposebuilt adaptation methods. Chan and Ng (2007) performed supervised domain adaptation on a manually selected subset of 21 nouns from the DSO corpus. They used active learning, count-merging, and predominant sense estimation in order to save target annotation effort. They showed that adding just 30% of the target data to the source examples the same precision as the full combination of ta</context>
</contexts>
<marker>Chelba, Acero, 2004</marker>
<rawString>Ciprian Chelba and Alex Acero. 2004. Adaptation of maximum entropy classifier: Little data can help a lot. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Daniel Marcu</author>
</authors>
<title>Domain adaptation for statistical classifiers.</title>
<date>2006</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>26--101</pages>
<marker>Daum´e, Marcu, 2006</marker>
<rawString>Hal Daum´e III and Daniel Marcu. 2006. Domain adaptation for statistical classifiers. Journal of Artificial Intelligence Research, 26:101–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
</authors>
<title>Frustratingly easy domain adaptation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>256--263</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<marker>Daum´e, 2007</marker>
<rawString>Hal Daum´e III. 2007. Frustratingly easy domain adaptation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 256–263, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Escudero</author>
<author>Lluiz M´arquez</author>
<author>German Rigau</author>
</authors>
<title>An Empirical Study of the Domain Dependence of Supervised Word Sense Disambiguation Systems.</title>
<date>2000</date>
<booktitle>Proceedings of the joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, EMNLP/VLC.</booktitle>
<marker>Escudero, M´arquez, Rigau, 2000</marker>
<rawString>Gerard Escudero, Lluiz M´arquez, and German Rigau. 2000. An Empirical Study of the Domain Dependence of Supervised Word Sense Disambiguation Systems. Proceedings of the joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, EMNLP/VLC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="5882" citStr="Fellbaum, 1998" startWordPosition="915" endWordPosition="916">corpora, and the examples from the WSJ play the role of domain-specific examples. Koeling et al. (2005) present a corpus were the examples are drawn from the balanced BNC corpus (Leech, 1992) and the SPORTS and FINANCES sections of the newswire Reuters corpus (Rose et al., 2002), comprising around 300 examples (roughly 100 from each of those corpora) for each of the 41 nouns. The nouns were selected because they were salient in either the SPORTS or FINANCES domains, or because they had senses linked to those domains. The occurrences were hand-tagged with the senses from WordNet version 1.7.1 (Fellbaum, 1998). In domain adaptation experiments the BNC examples play the role of general corpora, and the FINANCES and SPORTS examples the role of two specific domain corpora. Finally, a dataset for biomedicine was developed by Weeber et al. (2001), and has been used as a benchmark by many independent groups. The UMLS Metathesaurus was used to provide a set of possible meanings for terms in biomedical text. 50 ambiguous terms which occur frequently in MEDLINE were chosen for inclusion in the test set. 100 instances of each term were selected from citations added to the MEDLINE database in 1998 and manuall</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilgarriff</author>
</authors>
<title>English Lexical Sample Task Description.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second International Workshop on evaluating Word Sense Disambiguation Systems,</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="1322" citStr="Kilgarriff, 2001" startWordPosition="179" endWordPosition="181">The difficulties found by supervised systems to adapt might change the way we assess the strengths and weaknesses of supervised and knowledgebased WSD systems. Unfortunately, all existing evaluation datasets for specific domains are lexical-sample corpora. With this paper we want to motivate the creation of an allwords test dataset for WSD on the environment domain in several languages, and present the overall design of this SemEval task. 1 Introduction Word Sense Disambiguation (WSD) competitions have focused on general domain texts, as attested in the last Senseval and Semeval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Pradhan et al., 2007). Specific domains pose fresh challenges to WSD systems: the context in which the senses occur might change, distributions and predominant senses vary, some words tend to occur in fewer senses in specific domains, and new senses and terms might be involved. Both supervised and knowledge-based systems are affected by these issues: while the first suffer from different context and sense priors, the later suffer from lack of coverage of domain-related words and information. Domain adaptation of supervised techniques is a hot issue in Natural Language </context>
<context position="2825" citStr="Kilgarriff, 2001" startWordPosition="418" endWordPosition="419"> a solution to this problem with mixed results. Current research on applying WSD to specific domains has been evaluated on three available lexicalsample datasets (Ng and Lee, 1996; Weeber et al., 2001; Koeling et al., 2005). This kind of dataset contains hand-labeled examples for a handful of selected target words. As the systems are evaluated on a few words, the actual performance of the systems over complete texts can not be measured. Differences in behavior of WSD systems when applied to lexical-sample and all-words datasets have been observed on previous Senseval and Semeval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Pradhan et al., 2007): supervised systems attain results on the high 80’s and beat the most frequent baseline by a large margin for lexical-sample datasets, but results on the all-words datasets were much more modest, on the low 70’s, and a few points above the most frequent baseline. Thus, the behaviour of WSD systems on domainspecific texts is largely unknown. While some words could be supposed to behave in similar ways, and thus be amenable to be properly treated by a generic 123 Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and </context>
</contexts>
<marker>Kilgarriff, 2001</marker>
<rawString>A. Kilgarriff. 2001. English Lexical Sample Task Description. In Proceedings of the Second International Workshop on evaluating Word Sense Disambiguation Systems, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Koeling</author>
<author>D McCarthy</author>
<author>J Carroll</author>
</authors>
<title>Domainspecific sense distributions and predominant sense acquisition.</title>
<date>2005</date>
<booktitle>In Proceedings of the Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing. HLT/EMNLP,</booktitle>
<pages>419--426</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="2432" citStr="Koeling et al., 2005" startWordPosition="352" endWordPosition="355">n-related words and information. Domain adaptation of supervised techniques is a hot issue in Natural Language Processing, including Word Sense Disambiguation. Supervised Word Sense Disambiguation systems trained on general corpora are known to perform worse when applied to specific domains (Escudero et al., 2000; Martinez and Agirre, 2000), and domain adaptation techniques have been proposed as a solution to this problem with mixed results. Current research on applying WSD to specific domains has been evaluated on three available lexicalsample datasets (Ng and Lee, 1996; Weeber et al., 2001; Koeling et al., 2005). This kind of dataset contains hand-labeled examples for a handful of selected target words. As the systems are evaluated on a few words, the actual performance of the systems over complete texts can not be measured. Differences in behavior of WSD systems when applied to lexical-sample and all-words datasets have been observed on previous Senseval and Semeval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Pradhan et al., 2007): supervised systems attain results on the high 80’s and beat the most frequent baseline by a large margin for lexical-sample datasets, but results on the all-wo</context>
<context position="5370" citStr="Koeling et al. (2005)" startWordPosition="828" endWordPosition="831"> domain, and the second is the Brown Corpus (BC) which is a balanced corpora of English usage. 191 polysemous words (nouns and verbs) of high frequency in WSJ and BC were selected and a total of 192,800 occurrences of these words were tagged with WordNet 1.5 senses, more than 1,000 instances per word in average. The examples from BC comprise 78,080 occurrences of word senses, and examples from WSJ consist on 114,794 occurrences. In domain adaptation experiments, the Brown Corpus examples play the role of general corpora, and the examples from the WSJ play the role of domain-specific examples. Koeling et al. (2005) present a corpus were the examples are drawn from the balanced BNC corpus (Leech, 1992) and the SPORTS and FINANCES sections of the newswire Reuters corpus (Rose et al., 2002), comprising around 300 examples (roughly 100 from each of those corpora) for each of the 41 nouns. The nouns were selected because they were salient in either the SPORTS or FINANCES domains, or because they had senses linked to those domains. The occurrences were hand-tagged with the senses from WordNet version 1.7.1 (Fellbaum, 1998). In domain adaptation experiments the BNC examples play the role of general corpora, an</context>
<context position="10618" citStr="Koeling et al. (2005)" startWordPosition="1714" endWordPosition="1717">ging the target corpus, showing that tagged corpora from each domain would suffice, and concluding that hand tagging a large general corpus would not guarantee robust broad-coverage WSD. Agirre and Martinez (2000) used the same DSO corpus and showed that training on the subset of the source corpus that is topically related to the target corpus does allow for domain adaptation, obtaining better results than training on the target data alone. In (Agirre and Lopez de Lacalle, 2008), the authors also show that state-of-the-art WSD systems are not able to adapt to the domains in the context of the Koeling et al. (2005) dataset. While WSD systems trained on the target domain obtained 85.1 and 87.0 of precision on the sports and finances domains, respectively, the same systems trained on the BNC corpus (considered as a general domain corpus) obtained 53.9 and 62.9 of precision on sports and finances, respectively. Training on both source and target was inferior that using the target examples alone. Supervised adaptation Supervised adaptation for other NLP tasks has been widely reported. For instance, (Daum´e III, 2007) shows that a simple feature augmentation method for SVM is able to effectively use both lab</context>
<context position="13286" citStr="Koeling et al., 2005" startWordPosition="2150" endWordPosition="2153">p of the gases in the atmosphere and time lags in the response of climatic and oceanic systems to changes in the atmospheric concentration of the gases. Figure 1: Sample text from the environment domain. al., 2008), the feature augmentation approach was combined with active learning and tested on the OntoNotes corpus, on a large domain-adaptation experiment. They significantly reduced the effort of hand-tagging, but only obtained positive domainadaptation results for smaller fractions of the target corpus. In (Agirre and Lopez de Lacalle, 2009) the authors report successful adaptation on the (Koeling et al., 2005) dataset on supervised setting. Their method is based on the use of unlabeled data, reducing the feature space with SVD, and combination of features using an ensemble of kernel methods. They report 22% error reduction when using both source and target data compared to a classifier trained on target the target data alone, even when the full dataset is used. Semi-supervised adaptation There are less works on semi-supervised domain adaptation in NLP tasks, and fewer in WSD task. Blitzer et al. (2006) used Structural Correspondence Learning and unlabeled data to adapt a Part-ofSpeech tagger. They </context>
<context position="14533" citStr="Koeling et al., 2005" startWordPosition="2346" endWordPosition="2349"> pivot features to learn linear predictors, perform SVD on the weights learned by the predictor, and thus learn correspondences among features in both source and target domains. Agirre and Lopez de Lacalle (2008) show that methods based on SVD with unlabeled data and combination of distinct feature spaces produce positive semi-supervised domain adaptation results for WSD. Unsupervised adaptation In this context, we take unsupervised to mean Knowledge-Based methods which do not require hand-tagged corpora. The predominant sense acquisition method was succesfully applied to specific domains in (Koeling et al., 2005). The methos has two steps: In the first, a corpus of untagged text from the target domain is used to construct a thesaurus of similar words. In the second, each target word is disambiguated using pairwise WordNet-based similarity measures, taking as pairs the target word and each of the most related words according to the thesaurus up to a certain threshold. This method aims to obtain, for each target word, the sense which is the most predominant for the target corpus. When a general corpus is used, the most predominant sense in general is obtained, and when a domain-specific corpus is used, </context>
</contexts>
<marker>Koeling, McCarthy, Carroll, 2005</marker>
<rawString>R. Koeling, D. McCarthy, and J. Carroll. 2005. Domainspecific sense distributions and predominant sense acquisition. In Proceedings of the Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing. HLT/EMNLP, pages 419–426, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Leech</author>
</authors>
<title>100 million words of English:</title>
<date>1992</date>
<journal>the British National Corpus. Language Research,</journal>
<volume>28</volume>
<issue>1</issue>
<contexts>
<context position="5458" citStr="Leech, 1992" startWordPosition="846" endWordPosition="847">1 polysemous words (nouns and verbs) of high frequency in WSJ and BC were selected and a total of 192,800 occurrences of these words were tagged with WordNet 1.5 senses, more than 1,000 instances per word in average. The examples from BC comprise 78,080 occurrences of word senses, and examples from WSJ consist on 114,794 occurrences. In domain adaptation experiments, the Brown Corpus examples play the role of general corpora, and the examples from the WSJ play the role of domain-specific examples. Koeling et al. (2005) present a corpus were the examples are drawn from the balanced BNC corpus (Leech, 1992) and the SPORTS and FINANCES sections of the newswire Reuters corpus (Rose et al., 2002), comprising around 300 examples (roughly 100 from each of those corpora) for each of the 41 nouns. The nouns were selected because they were salient in either the SPORTS or FINANCES domains, or because they had senses linked to those domains. The occurrences were hand-tagged with the senses from WordNet version 1.7.1 (Fellbaum, 1998). In domain adaptation experiments the BNC examples play the role of general corpora, and the FINANCES and SPORTS examples the role of two specific domain corpora. Finally, a d</context>
</contexts>
<marker>Leech, 1992</marker>
<rawString>G. Leech. 1992. 100 million words of English: the British National Corpus. Language Research, 28(1):1–13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Martinez</author>
<author>Eneko Agirre</author>
</authors>
<date>2000</date>
<booktitle>One Sense per Collocation and Genre/Topic Variations. Conference on Empirical Method in Natural Language.</booktitle>
<contexts>
<context position="2153" citStr="Martinez and Agirre, 2000" startWordPosition="304" endWordPosition="307">rds tend to occur in fewer senses in specific domains, and new senses and terms might be involved. Both supervised and knowledge-based systems are affected by these issues: while the first suffer from different context and sense priors, the later suffer from lack of coverage of domain-related words and information. Domain adaptation of supervised techniques is a hot issue in Natural Language Processing, including Word Sense Disambiguation. Supervised Word Sense Disambiguation systems trained on general corpora are known to perform worse when applied to specific domains (Escudero et al., 2000; Martinez and Agirre, 2000), and domain adaptation techniques have been proposed as a solution to this problem with mixed results. Current research on applying WSD to specific domains has been evaluated on three available lexicalsample datasets (Ng and Lee, 1996; Weeber et al., 2001; Koeling et al., 2005). This kind of dataset contains hand-labeled examples for a handful of selected target words. As the systems are evaluated on a few words, the actual performance of the systems over complete texts can not be measured. Differences in behavior of WSD systems when applied to lexical-sample and all-words datasets have been </context>
</contexts>
<marker>Martinez, Agirre, 2000</marker>
<rawString>David Martinez and Eneko Agirre. 2000. One Sense per Collocation and Genre/Topic Variations. Conference on Empirical Method in Natural Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>T Chklovski</author>
<author>Adam Killgariff</author>
</authors>
<title>The Senseval-3 English lexical sample task.</title>
<date>2004</date>
<booktitle>In Proceedings of the 3rd ACL workshop on the Evaluation of Systems for the Semantic Analysis of Text (SENSEVAL),</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="1345" citStr="Mihalcea et al., 2004" startWordPosition="182" endWordPosition="185">ound by supervised systems to adapt might change the way we assess the strengths and weaknesses of supervised and knowledgebased WSD systems. Unfortunately, all existing evaluation datasets for specific domains are lexical-sample corpora. With this paper we want to motivate the creation of an allwords test dataset for WSD on the environment domain in several languages, and present the overall design of this SemEval task. 1 Introduction Word Sense Disambiguation (WSD) competitions have focused on general domain texts, as attested in the last Senseval and Semeval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Pradhan et al., 2007). Specific domains pose fresh challenges to WSD systems: the context in which the senses occur might change, distributions and predominant senses vary, some words tend to occur in fewer senses in specific domains, and new senses and terms might be involved. Both supervised and knowledge-based systems are affected by these issues: while the first suffer from different context and sense priors, the later suffer from lack of coverage of domain-related words and information. Domain adaptation of supervised techniques is a hot issue in Natural Language Processing, including W</context>
<context position="2848" citStr="Mihalcea et al., 2004" startWordPosition="420" endWordPosition="423">s problem with mixed results. Current research on applying WSD to specific domains has been evaluated on three available lexicalsample datasets (Ng and Lee, 1996; Weeber et al., 2001; Koeling et al., 2005). This kind of dataset contains hand-labeled examples for a handful of selected target words. As the systems are evaluated on a few words, the actual performance of the systems over complete texts can not be measured. Differences in behavior of WSD systems when applied to lexical-sample and all-words datasets have been observed on previous Senseval and Semeval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Pradhan et al., 2007): supervised systems attain results on the high 80’s and beat the most frequent baseline by a large margin for lexical-sample datasets, but results on the all-words datasets were much more modest, on the low 70’s, and a few points above the most frequent baseline. Thus, the behaviour of WSD systems on domainspecific texts is largely unknown. While some words could be supposed to behave in similar ways, and thus be amenable to be properly treated by a generic 123 Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, page</context>
</contexts>
<marker>Mihalcea, Chklovski, Killgariff, 2004</marker>
<rawString>R. Mihalcea, T. Chklovski, and Adam Killgariff. 2004. The Senseval-3 English lexical sample task. In Proceedings of the 3rd ACL workshop on the Evaluation of Systems for the Semantic Analysis of Text (SENSEVAL), Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>C Leacock</author>
<author>R Tengi</author>
<author>R Bunker</author>
</authors>
<title>A Semantic Concordance.</title>
<date>1993</date>
<booktitle>In Proceedings of the ARPA Human Language Technology Workshop. Distributed as Human Language Technology by</booktitle>
<pages>303--308</pages>
<publisher>Morgan Kaufmann Publishers.,</publisher>
<location>San Mateo, CA:</location>
<contexts>
<context position="8889" citStr="Miller et al., 1993" startWordPosition="1418" endWordPosition="1421">cific domain. Good results in this setting would show that supervised domain adaptation is working, and that generic WSD systems can be supplemented with hand-tagged examples from the target domain. There is an additional setting, where a generic WSD system is supplemented with untagged examples from the domain. Good results in this setting would show that semi-supervised domain adaptation works, and that generic WSD systems can be supplemented with untagged examples from the target domain in order to improve their results. Most of current all-words generic supervised WSD systems take SemCor (Miller et al., 1993) as their source corpus, i.e. they are trained on SemCor examples and then applied to new examples. SemCor is the largest publicly available annotated corpus. It’s mainly a subset of the Brown Corpus, plus the novel The Red Badge of Courage. The Brown corpus is balanced, yet not from the general domain, as it comprises 500 documents drawn from different domains, each approximately 2000 words long. Although the Brown corpus is balanced, SemCor is not, as the documents were not chosen at random. 4 State-of-the-art in WSD for specific domains Initial work on domain adaptation for WSD systems show</context>
</contexts>
<marker>Miller, Leacock, Tengi, Bunker, 1993</marker>
<rawString>G.A. Miller, C. Leacock, R. Tengi, and R.Bunker. 1993. A Semantic Concordance. In Proceedings of the ARPA Human Language Technology Workshop. Distributed as Human Language Technology by San Mateo, CA: Morgan Kaufmann Publishers., pages 303– 308, Princeton, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hwee Tou Ng</author>
<author>Hian Beng Lee</author>
</authors>
<title>Integrating multiple knowledge sources to disambiguate word sense: An exemplar-based approach.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting of the Association for Computationla Linguistics (ACL),</booktitle>
<pages>40--47</pages>
<contexts>
<context position="2388" citStr="Ng and Lee, 1996" startWordPosition="344" endWordPosition="347">r suffer from lack of coverage of domain-related words and information. Domain adaptation of supervised techniques is a hot issue in Natural Language Processing, including Word Sense Disambiguation. Supervised Word Sense Disambiguation systems trained on general corpora are known to perform worse when applied to specific domains (Escudero et al., 2000; Martinez and Agirre, 2000), and domain adaptation techniques have been proposed as a solution to this problem with mixed results. Current research on applying WSD to specific domains has been evaluated on three available lexicalsample datasets (Ng and Lee, 1996; Weeber et al., 2001; Koeling et al., 2005). This kind of dataset contains hand-labeled examples for a handful of selected target words. As the systems are evaluated on a few words, the actual performance of the systems over complete texts can not be measured. Differences in behavior of WSD systems when applied to lexical-sample and all-words datasets have been observed on previous Senseval and Semeval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Pradhan et al., 2007): supervised systems attain results on the high 80’s and beat the most frequent baseline by a large margin for lexica</context>
<context position="4619" citStr="Ng and Lee, 1996" startWordPosition="699" endWordPosition="702"> environment-related texts. The paper is structured as follows. The next section presents current lexical sample datasets for domain-specific WSD. Section 3 presents some possible settings for domain adaptation. Section 4 reviews the state-of-the art in domain-specific WSD. Section 5 presents the design of our task, and finally, Section 6 draws some conclusions. 2 Specific domain datasets available We will briefly present the three existing datasets for domain-related studies in WSD, which are all lexical-sample. The most commonly used dataset is the Defense Science Organization (DSO) corpus (Ng and Lee, 1996), which comprises sentences from two different corpora. The first is the Wall Street Journal (WSJ), which belongs to the financial domain, and the second is the Brown Corpus (BC) which is a balanced corpora of English usage. 191 polysemous words (nouns and verbs) of high frequency in WSJ and BC were selected and a total of 192,800 occurrences of these words were tagged with WordNet 1.5 senses, more than 1,000 instances per word in average. The examples from BC comprise 78,080 occurrences of word senses, and examples from WSJ consist on 114,794 occurrences. In domain adaptation experiments, the</context>
</contexts>
<marker>Ng, Lee, 1996</marker>
<rawString>Hwee Tou Ng and Hian Beng Lee. 1996. Integrating multiple knowledge sources to disambiguate word sense: An exemplar-based approach. In Proceedings of the 34th Annual Meeting of the Association for Computationla Linguistics (ACL), pages 40–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicoletta Calzolari</author>
</authors>
<title>Christiane Fellbaum Shu-kai Hsieh Chu-Ren Huang Hitoshi Isahara Kyoko Kanzaki Andrea Marchetti Monica Monachini Federico Neri Remo Raffaelli German Rigau Maurizio Tescon Piek Vossen, Eneko Agirre and Joop VanGent.</title>
<date>2008</date>
<marker>Calzolari, 2008</marker>
<rawString>Nicoletta Calzolari Christiane Fellbaum Shu-kai Hsieh Chu-Ren Huang Hitoshi Isahara Kyoko Kanzaki Andrea Marchetti Monica Monachini Federico Neri Remo Raffaelli German Rigau Maurizio Tescon Piek Vossen, Eneko Agirre and Joop VanGent. 2008.</rawString>
</citation>
<citation valid="true">
<title>Kyoto: a system for mining, structuring and distributing knowledge across languages and cultures.</title>
<date></date>
<booktitle>In European Language Resources Association (ELRA), editor, Proceedings of the Sixth International Language Resources and Evaluation (LREC’08),</booktitle>
<location>Marrakech, Morocco,</location>
<marker></marker>
<rawString>Kyoto: a system for mining, structuring and distributing knowledge across languages and cultures. In European Language Resources Association (ELRA), editor, Proceedings of the Sixth International Language Resources and Evaluation (LREC’08), Marrakech, Morocco, may.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Edward Loper</author>
<author>Dmitriy Dligach</author>
<author>Martha Palmer</author>
</authors>
<title>Semeval-2007 task-17: English lexical sample, srl and all words.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<pages>87--92</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="1368" citStr="Pradhan et al., 2007" startWordPosition="186" endWordPosition="189">ems to adapt might change the way we assess the strengths and weaknesses of supervised and knowledgebased WSD systems. Unfortunately, all existing evaluation datasets for specific domains are lexical-sample corpora. With this paper we want to motivate the creation of an allwords test dataset for WSD on the environment domain in several languages, and present the overall design of this SemEval task. 1 Introduction Word Sense Disambiguation (WSD) competitions have focused on general domain texts, as attested in the last Senseval and Semeval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Pradhan et al., 2007). Specific domains pose fresh challenges to WSD systems: the context in which the senses occur might change, distributions and predominant senses vary, some words tend to occur in fewer senses in specific domains, and new senses and terms might be involved. Both supervised and knowledge-based systems are affected by these issues: while the first suffer from different context and sense priors, the later suffer from lack of coverage of domain-related words and information. Domain adaptation of supervised techniques is a hot issue in Natural Language Processing, including Word Sense Disambiguatio</context>
<context position="2871" citStr="Pradhan et al., 2007" startWordPosition="424" endWordPosition="428">sults. Current research on applying WSD to specific domains has been evaluated on three available lexicalsample datasets (Ng and Lee, 1996; Weeber et al., 2001; Koeling et al., 2005). This kind of dataset contains hand-labeled examples for a handful of selected target words. As the systems are evaluated on a few words, the actual performance of the systems over complete texts can not be measured. Differences in behavior of WSD systems when applied to lexical-sample and all-words datasets have been observed on previous Senseval and Semeval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Pradhan et al., 2007): supervised systems attain results on the high 80’s and beat the most frequent baseline by a large margin for lexical-sample datasets, but results on the all-words datasets were much more modest, on the low 70’s, and a few points above the most frequent baseline. Thus, the behaviour of WSD systems on domainspecific texts is largely unknown. While some words could be supposed to behave in similar ways, and thus be amenable to be properly treated by a generic 123 Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 123–128, Boulder, Col</context>
</contexts>
<marker>Pradhan, Loper, Dligach, Palmer, 2007</marker>
<rawString>Sameer Pradhan, Edward Loper, Dmitriy Dligach, and Martha Palmer. 2007. Semeval-2007 task-17: English lexical sample, srl and all words. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), pages 87–92, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony G Rose</author>
<author>Mark Stevenson</author>
<author>Miles Whitehead</author>
</authors>
<title>The Reuters Corpus Volumen 1: from Yesterday’s News to Tomorrow’s Language Resources.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC-2002),</booktitle>
<pages>827--832</pages>
<location>Las Palmas, Canary Islands.</location>
<contexts>
<context position="5546" citStr="Rose et al., 2002" startWordPosition="859" endWordPosition="862"> and a total of 192,800 occurrences of these words were tagged with WordNet 1.5 senses, more than 1,000 instances per word in average. The examples from BC comprise 78,080 occurrences of word senses, and examples from WSJ consist on 114,794 occurrences. In domain adaptation experiments, the Brown Corpus examples play the role of general corpora, and the examples from the WSJ play the role of domain-specific examples. Koeling et al. (2005) present a corpus were the examples are drawn from the balanced BNC corpus (Leech, 1992) and the SPORTS and FINANCES sections of the newswire Reuters corpus (Rose et al., 2002), comprising around 300 examples (roughly 100 from each of those corpora) for each of the 41 nouns. The nouns were selected because they were salient in either the SPORTS or FINANCES domains, or because they had senses linked to those domains. The occurrences were hand-tagged with the senses from WordNet version 1.7.1 (Fellbaum, 1998). In domain adaptation experiments the BNC examples play the role of general corpora, and the FINANCES and SPORTS examples the role of two specific domain corpora. Finally, a dataset for biomedicine was developed by Weeber et al. (2001), and has been used as a ben</context>
</contexts>
<marker>Rose, Stevenson, Whitehead, 2002</marker>
<rawString>Tony G. Rose, Mark Stevenson, and Miles Whitehead. 2002. The Reuters Corpus Volumen 1: from Yesterday’s News to Tomorrow’s Language Resources. In Proceedings of the Third International Conference on Language Resources and Evaluation (LREC-2002), pages 827–832, Las Palmas, Canary Islands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Weeber</author>
<author>James G Mork</author>
<author>Alan R Aronson</author>
</authors>
<title>Developing a test collection for biomedical word sense disambiguation.</title>
<date>2001</date>
<booktitle>In Proceedings of the AMAI Symposium,</booktitle>
<pages>746--750</pages>
<location>Washington, DC.</location>
<contexts>
<context position="2409" citStr="Weeber et al., 2001" startWordPosition="348" endWordPosition="351"> of coverage of domain-related words and information. Domain adaptation of supervised techniques is a hot issue in Natural Language Processing, including Word Sense Disambiguation. Supervised Word Sense Disambiguation systems trained on general corpora are known to perform worse when applied to specific domains (Escudero et al., 2000; Martinez and Agirre, 2000), and domain adaptation techniques have been proposed as a solution to this problem with mixed results. Current research on applying WSD to specific domains has been evaluated on three available lexicalsample datasets (Ng and Lee, 1996; Weeber et al., 2001; Koeling et al., 2005). This kind of dataset contains hand-labeled examples for a handful of selected target words. As the systems are evaluated on a few words, the actual performance of the systems over complete texts can not be measured. Differences in behavior of WSD systems when applied to lexical-sample and all-words datasets have been observed on previous Senseval and Semeval competitions (Kilgarriff, 2001; Mihalcea et al., 2004; Pradhan et al., 2007): supervised systems attain results on the high 80’s and beat the most frequent baseline by a large margin for lexical-sample datasets, bu</context>
<context position="6118" citStr="Weeber et al. (2001)" startWordPosition="952" endWordPosition="955"> the newswire Reuters corpus (Rose et al., 2002), comprising around 300 examples (roughly 100 from each of those corpora) for each of the 41 nouns. The nouns were selected because they were salient in either the SPORTS or FINANCES domains, or because they had senses linked to those domains. The occurrences were hand-tagged with the senses from WordNet version 1.7.1 (Fellbaum, 1998). In domain adaptation experiments the BNC examples play the role of general corpora, and the FINANCES and SPORTS examples the role of two specific domain corpora. Finally, a dataset for biomedicine was developed by Weeber et al. (2001), and has been used as a benchmark by many independent groups. The UMLS Metathesaurus was used to provide a set of possible meanings for terms in biomedical text. 50 ambiguous terms which occur frequently in MEDLINE were chosen for inclusion in the test set. 100 instances of each term were selected from citations added to the MEDLINE database in 1998 and manually disambiguated by 11 annotators. Twelve terms were flagged as ”problematic” due to substantial disagreement between the annotators. In addition to the meanings defined in UMLS, annotators had the option of assigning a special tag (”non</context>
</contexts>
<marker>Weeber, Mork, Aronson, 2001</marker>
<rawString>Marc Weeber, James G. Mork, and Alan R. Aronson. 2001. Developing a test collection for biomedical word sense disambiguation. In Proceedings of the AMAI Symposium, pages 746–750, Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhi Zhong</author>
<author>Hwee Tou Ng</author>
<author>Yee Seng Chan</author>
</authors>
<title>Word sense disambiguation using OntoNotes: An empirical study.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1002--1010</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii,</location>
<marker>Zhong, Ng, Chan, 2008</marker>
<rawString>Zhi Zhong, Hwee Tou Ng, and Yee Seng Chan. 2008. Word sense disambiguation using OntoNotes: An empirical study. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 1002–1010, Honolulu, Hawaii, October. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>