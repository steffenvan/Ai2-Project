<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.980873">
Finding Optimal 1-Endpoint-Crossing Trees
</title>
<author confidence="0.998994">
Emily Pitler, Sampath Kannan, Mitchell Marcus
</author>
<affiliation confidence="0.997761">
Computer and Information Science
University of Pennsylvania
</affiliation>
<address confidence="0.791808">
Philadelphia, PA 19104
</address>
<email confidence="0.999303">
epitler,kannan,mitch@seas.upenn.edu
</email>
<sectionHeader confidence="0.995667" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9990334375">
Dependency parsing algorithms capable of
producing the types of crossing dependencies
seen in natural language sentences have tra-
ditionally been orders of magnitude slower
than algorithms for projective trees. For 95.8-
99.8% of dependency parses in various nat-
ural language treebanks, whenever an edge
is crossed, the edges that cross it all have a
common vertex. The optimal dependency tree
that satisfies this 1-Endpoint-Crossing prop-
erty can be found with an O(n4) parsing al-
gorithm that recursively combines forests over
intervals with one exterior point. 1-Endpoint-
Crossing trees also have natural connections
to linguistics and another class of graphs that
has been studied in NLP.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99991872">
Dependency parsing is one of the fundamental prob-
lems in natural language processing today, with ap-
plications such as machine translation (Ding and
Palmer, 2005), information extraction (Culotta and
Sorensen, 2004), and question answering (Cui et
al., 2005). Most high-accuracy graph-based depen-
dency parsers (Koo and Collins, 2010; Rush and
Petrov, 2012; Zhang and McDonald, 2012) find the
highest-scoring projective trees (in which no edges
cross), despite the fact that a large proportion of nat-
ural language sentences are non-projective. Projec-
tive trees can be found in O(n3) time (Eisner, 2000),
but cover only 63.6% of sentences in some natural
language treebanks (Table 1).
The class of directed spanning trees covers all
treebank trees and can be parsed in O(n2) with
edge-based features (McDonald et al., 2005), but it
is NP-hard to find the maximum scoring such tree
with grandparent or sibling features (McDonald and
Pereira, 2006; McDonald and Satta, 2007).
There are various existing definitions of mildly
non-projective trees with better empirical coverage
than projective trees that do not have the hardness of
extensibility that spanning trees do. However, these
have had parsing algorithms that are orders of mag-
nitude slower than the projective case or the edge-
based spanning tree case. For example, well-nested
dependency trees with block degree 2 (Kuhlmann,
2013) cover at least 95.4% of natural language struc-
tures, but have a parsing time of O(n7) (Gómez-
Rodríguez et al., 2011).
No previously defined class of trees simultane-
ously has high coverage and low-degree polynomial
algorithms for parsing, allowing grandparent or sib-
ling features.
We propose 1-Endpoint-Crossing trees, in which
for any edge that is crossed, all other edges that
cross that edge share an endpoint. While simple
to state, this property covers 95.8% or more of de-
pendency parses in natural language treebanks (Ta-
ble 1). The optimal 1-Endpoint-Crossing tree can
be found in faster asymptotic time than any previ-
ously proposed mildly non-projective dependency
parsing algorithm. We show how any 1-Endpoint-
Crossing tree can be decomposed into isolated sets
of intervals with one exterior point (Section 3). This
is the key insight that allows efficient parsing; the
O(n4) parsing algorithm is presented in Section 4.
1-Endpoint-Crossing trees are a subclass of 2-planar
graphs (Section 5.1), a class that has been studied
</bodyText>
<page confidence="0.996742">
13
</page>
<bodyText confidence="0.7445144">
Transactions of the Association for Computational Linguistics, 1 (2013) 13–24. Action Editor: Giorgio Satta.
Submitted 11/2012; Published 3/2013. c�2013 Association for Computational Linguistics.
in NLP. 1-Endpoint-Crossing trees also have some
linguistic interpretation (pairs of cross serial verbs
produce 1-Endpoint-Crossing trees, Section 5.2).
</bodyText>
<note confidence="0.406391">
2 Definitions of Non-Projectivity
</note>
<construct confidence="0.984628833333333">
Definition 1. Edges e and f cross if e and f have
distinct endpoints and exactly one of the endpoints
of f lies between the endpoints of e.
Definition 2. A dependency tree is 1-Endpoint-
Crossing if for any edge e, all edges that cross e
share an endpoint p.
</construct>
<bodyText confidence="0.930936514285714">
Table 1 shows the percentage of dependency
parses in the CoNLL-X training sets that are 1-
Endpoint-Crossing trees. Across six languages with
varying amounts of non-projectivity, 95.8-99.8%
of dependency parses in treebanks are 1-Endpoint-
Crossing trees.1
We next review and compare other relevant def-
initions of non-projectivity from prior work: well-
nested with block degree 2, gap-minding, projective,
and 2-planar.
The definitions of block degree and well-
nestedness are given below:
Definition 3. For each node u in the tree, a block of
the node is “a longest segment consisting of descen-
dants of u.” (Kuhlmann, 2013). The block-degree of
u is “the number of distinct blocks of u”. The block
degree of a tree is the maximum block degree of any
of its nodes. The gap degree is the number of gaps
between these blocks, and so by definition is one less
than the block degree. (Kuhlmann, 2013)
Definition 4. Two trees “T1 and T2 interleave iff
there are nodes l1,r1 E T1 and l2,r2 E T2 such that
l1 &lt; l2 &lt; r1 &lt; r2.” A tree is well-nested if no two
disjoint subtrees interleave. (Bodirsky et al., 2005)
As can be seen in Table 1, 95.4%-99.9% of depen-
dency parses across treebanks are both well-nested
and have block degree 2. The optimal such tree can
be found in O(n7) time and O(n5) space (Gómez-
Rodríguez et al., 2011).
1Conventional edges from the artificial root node to the
root(s) of the sentence reduce the empirical coverage of 1-
Endpoint-Crossing trees. Excluding these artificial root edges,
the empirical coverage for Dutch rises to 12949 (97.0%). These
edges have no effect on the coverage of well-nested trees with
block degree at most 2, gap-minding trees, or projective trees.
</bodyText>
<figureCaption confidence="0.993927">
Figure 1: 1a is 1-Endpoint-Crossing, but is neither
block degree 2 nor well-nested; 1b is gap-minding
but not 2-planar.
</figureCaption>
<bodyText confidence="0.852054777777778">
Definition 5. A tree is gap-minding if it is well-
nested, has gap degree at most 1, and has gap inher-
itance degree 0. Gap inheritance degree 0 requires
that there are no child nodes with descendants in
more than one of their parent’s blocks. (Pitler et
al., 2012)
Gap-minding trees can be parsed in O(n5) (Pitler
et al., 2012). They have slightly less empirical cov-
erage, however: 90.4-97.7% (Table 1).
</bodyText>
<construct confidence="0.9195695">
Definition 6. A tree is projective if it has block de-
gree 1 (gap degree 0).
</construct>
<bodyText confidence="0.851836333333333">
This definition has the least coverage (as low as
63.6% for Dutch), but can be parsed in O(n3) (Eis-
ner, 2000).
Definition 7. A tree is 2-planar if each edge can be
drawn either above or below the sentence such that
no edges cross (Gómez-Rodríguez and Nivre, 2010).
Gómez-Rodríguez and Nivre (2010) presented a
transition-based parser for 2-planar trees, but there
is no known globally optimal parsing algorithm for
2-planar trees.
Clearly projective C gap-minding C well-nested
with block degree at most 2. In Section 5.1, we
prove the somewhat surprising fact that 1-Endpoint-
Crossing C 2-planar. These are two distinct hi-
erarchies capturing different dimensions of non-
projectivity: 1-Endpoint-Crossing V= well-nested
with block degree 2 (Figure 1a), and gap-minding
V= 2-planar (Figure 1b).
</bodyText>
<sectionHeader confidence="0.869224" genericHeader="method">
3 Edges (and their Crossing Point) Define
Isolated Crossing Regions
</sectionHeader>
<bodyText confidence="0.993142">
We introduce notation to facilitate the discussion:
</bodyText>
<figure confidence="0.99969175">
a b c d e f g h
a b c d e f g
(b)
(a)
</figure>
<page confidence="0.993844">
14
</page>
<table confidence="0.998421166666667">
Arabic Czech Danish Dutch Portuguese Swedish Parsing
1-Endpoint-Crossing 1457 (99.8) 71810 (98.8) 5144 (99.1) 12785 (95.8) 9007 (99.3) 10902 (98.7)
Well-nested, block degree 2 1458 (99.9) 72321 (99.5) 5175 (99.7) 12896 (96.6) 8650 (95.4) 10955 (99.2) O(n7)
Gap-Minding 1394 (95.5) 70695 (97.2) 4985 (96.1) 12068 (90.4) 8481 (93.5) 10787 (97.7)
Projective 1297 (88.8) 55872 (76.8) 4379 (84.4) 8484 (63.6) 7353 (81.1) 9963 (90.2) O(n3)
Sentences 1460 72703 5190 13349 9071 11042
</table>
<tableCaption confidence="0.9680405">
Table 1: Over 95% of the dependency parse trees in the CoNLL-X training sets are 1-Endpoint-Crossing
trees. Coverage statistics and parsing times of previously proposed properties are shown for comparison.
</tableCaption>
<bodyText confidence="0.950199392857143">
Definition 8. Within a 1-Endpoint-Crossing tree,
the (crossing) pencil2 of an edge e (P(e)) is defined
as the set of edges (sharing an endpoint) that cross e.
The (crossing pencil) point of an edge e (Pt(e)) is
defined as the endpoint that all edges in P(e) share.
We will use euv to indicate an edge in either direc-
tion between u and v, i.e., either u → v or u ← v.
Before defining the parsing algorithm, we first
give some intuition by analogy to parsing for pro-
jective trees. (This argument mirrors that of Eisner
(2000, pps.38-39).) Projective trees can be produced
using dynamic programming over intervals. Inter-
vals are sufficient for projective trees: consider any
edge euv in a projective tree.
The vertices in (u, v) must only have edges to
vertices in [u, v]. If there were an edge between a
vertex in (u, v) and a vertex outside [u, v], such an
edge would cross euv, which would contradict the
assumption of projectivity. Thus every edge in a
projective tree creates one interior interval isolated
from the rest of the tree, allowing dynamic program-
ming over intervals. We can analyze the case of 1-
Endpoint-Crossing trees in a similar fashion:
Definition 9. An isolated interval [i, j] has no edges
between the vertices in (i, j) and the vertices out-
side of [i, j]. An interval and one exterior vertex
[i, j] U {x} is called an isolated crossing region if
the following two conditions are satisfied:
</bodyText>
<listItem confidence="0.9828998">
1. There are no edges between the vertices E (i, j)
and vertices E/ [i, j] U {x}
2. None of the edges between x and vertices E
(i, j) are crossed by any edges with both end-
points E (i, j)
</listItem>
<footnote confidence="0.49463075">
2This notation comes from an analogy to geometry: “A set
of distinct, coplanar, concurrent lines is a pencil of lines” (Rin-
genberg, 1967, p. 221); concurrent lines all intersect at the same
single point.
</footnote>
<figureCaption confidence="0.9260765">
Figure 2: An edge euv and Pt(euv) = p form two
sets of isolated crossing regions (Lemma 1). 2a and
</figureCaption>
<footnote confidence="0.346913">
2b show p E/ (u, v); 2c and 2d show p E (u, v).
</footnote>
<construct confidence="0.9895835">
Lemma 1. Consider any edge euv and Pt(euv) = p
in a 1-Endpoint-Crossing forest F. Let l, r, and m
denote the leftmost, rightmost, and middle point out
of {u, v, p}, respectively. Then the three points u,
v, and p define two isolated crossing regions: (1)
[l, m] U {r}, and (2) [m, r] U {l}.
</construct>
<listItem confidence="0.5349705">
Proof. First note that as p = Pt(euv), P(euv) is
non-empty: there must be at least one edge between
</listItem>
<equation confidence="0.91669825">
vertices E (u, v) and vertices E/ [u, v]. p is either
E/ [u, v] (i.e., p = lVp = r) or E (u, v) (i.e., p = m):
Case 1: p = l V p = r: Assume without loss of
generality that u &lt; v &lt; p (i.e., p = r).
</equation>
<bodyText confidence="0.96266875">
(a) [u, v] U {p} is an isolated crossing region
(Figure 2a): Condition 1: Assume for the sake of
contradiction that there were an edge between a ver-
tex E (u, v) and a vertex E/ [u, v]U{p}. Then such an
edge would cross euv without having an endpoint at
p, which contradicts the 1-Endpoint-Crossing prop-
erty for euv.
Condition 2: Assume that for some epa such that
a E (u, v), epa was crossed by an edge in the interior
of (u, v). The interior edge would not share an end-
point with euv; since euv also crosses epa, this con-
tradicts the 1-Endpoint-Crossing property for epa.
</bodyText>
<figure confidence="0.9995068">
(a) [u, v] U {p}
(c) [u, p] U {v}
u p
u v p
v
(b) [v, p] U {u}
(d) [p, v] U {u}
u
u v p
p v
</figure>
<page confidence="0.871593">
15
</page>
<bodyText confidence="0.959886">
(b) [v, p] ∪ {u} is an isolated crossing region
(Figure 2b): Condition 1: Assume there were an
edge eab with a ∈ (v, p) and b ∈/ [v, p] ∪ {u}. b
cannot be in (u, v) (by above). Thus, b ∈/ [u, p],
which implies that eab crosses the edges in P(euv);
as euv does not share a vertex with eab, this contra-
dicts the 1-Endpoint-Crossing property for all edges
in P(euv).
Condition 2: Assume that for some eua such that
a ∈ (v, p), eua was crossed by an edge in the interior
of (v, p). eua would also be crossed by all the edges
in P(euv); as the interior edge would not share an
endpoint with any of the edges in P(euv), this would
contradict the 1-Endpoint-Crossing property for eua.
</bodyText>
<equation confidence="0.457772">
Case 2: p = m :
(a) [u, p] ∪ {v} is an isolated crossing region
(Figure 2c): Condition 1: Assume there were an
edge eab with a ∈ (u, p) and b ∈/ [u, p] ∪ {v}
(b ∈ (p, v) ∨ b ∈/ [u, v]). First assume b ∈ (p, v).
</equation>
<bodyText confidence="0.998779416666667">
Then eab crosses all edges in P(euv); as eab does not
share an endpoint with euv, this contradicts the 1-
Endpoint-Crossing property for the edges in P(euv).
Next assume b ∈/ [u, v]. Then eab crosses euv; since
a =6 p∧b =6 p, this violates the 1-Endpoint-Crossing
property for euv.
Condition 2: Assume that for some eva with a ∈
(u, p), eva was crossed by an edge in the interior of
(u, v). eva is also crossed by all the edges in P(euv);
as the interior edge will not share an endpoint with
the edges in P(euv), this contradicts the 1-Endpoint-
Crossing property for eva.
</bodyText>
<listItem confidence="0.828006">
(b) [p, v] ∪ {u} is an isolated crossing region
(Figure 2d): Symmetric to the above.
</listItem>
<sectionHeader confidence="0.93781" genericHeader="method">
4 Parsing Algorithm
</sectionHeader>
<bodyText confidence="0.999565375">
The optimal 1-Endpoint-Crossing tree can be found
using a dynamic programming algorithm that ex-
ploits the fact that edges and their crossing points
define intervals and isolated crossing regions. This
section assumes an arc-factored model, in which the
score of a tree is defined as the sum of the scores of
its edges; scoring functions for edges are generally
learned from data.
</bodyText>
<figureCaption confidence="0.998147">
Figure 3: Isolated crossing region sub-problems.
</figureCaption>
<bodyText confidence="0.999201675675675">
The dynamic program uses five types of sub-
problems: interval sub-problems for each interval
[i, j], denoted Int[i, j], and four types of isolated
crossing region sub-problems for each interval and
exterior point [i, j] ∪ {x}, which differ in whether
edges from the exterior point may be crossed by
edges with an endpoint at the Left point of the inter-
val, the Right point, both LR, or Neither (Figure 3).
L[i, j, x], for example, refers to an isolated crossing
region over the interval [i, j] with an exterior point
of x, in which edges incident to i (the left boundary
point) can cross edges between x and (i, j).
These distinctions allow the 1-Endpoint-Crossing
property to be globally enforced; crossing edges in
one region may constrain edges in another. For ex-
ample, consider that Figure 2a allows edges with an
endpoint at v to cross the edges from p, while Figure
2b allows edges from u into (v, p). Both simultane-
ously would cause a 1-Endpoint-Crossing violation
for the edges in P(euv). Figures 4 and 5 show valid
combinations of the sub-problems in Figure 3.
The full dynamic program is shown in Appendix
A. The final answer must be a valid dependency tree,
which requires each word to have exactly one parent
and prohibits cycles. We use booleans (bi, bj, bx) for
each sub-problem, in which the boolean is set to true
if and only if the solution to the sub-problem must
contain the incoming (parent) edge for the corre-
sponding boundary point. We use the suffix AFromB
for a sub-problem to enforce that a boundary point A
must be descended from boundary point B (to avoid
cycles). We will occasionally mention these issues,
(a) Only edges inci-
dent to the Left point
of the interval may
cross the edges from
the exterior point
</bodyText>
<figure confidence="0.571542310344828">
(c) both (LR) (d) Neither
(b) Only edges in-
cident to the Right
point of the inter-
val may cross the
edges from the exte-
rior point
16
(a) If l E (k, j]: (b) If l E (i, k):
i k l j
(i) If the dashed edge exists:
All the edges from l into (i, k) must choose k
as their Pt. The interval decomposes into
S[eik] + R[i, k, l] + Int[k, l] + L[l, j, k]:
i l k j
(i) If dashed edge exists: All the edges from l into
(k, j] must choose i as their Pt. The interval decom-
poses into S[eik] + Int[i, l] + L[l, k, i] + N[k, j, l]:
i k l j
(ii) If no edges like the dashed edge exist:
All edges from l into (i, k) may choose either i
or k as their Pt. The interval decomposes into
S[eik] + LR[i, k, l] + Int[k, l] + Int[l, j]:
i k l j
i l k j
(ii) If no edges like the dashed edge exist: All edges
from l may choose k as their Pt. The interval decom-
poses into S[eik] + R[i,l, k] + Int[l, k] + L[k, j, l]:
i l k j
</figure>
<figureCaption confidence="0.995351">
Figure 4: Decomposing an Int[i, j] sub-problem, with Pt(eik) = l
</figureCaption>
<bodyText confidence="0.999990260869565">
but for simplicity focus the discussion on the decom-
position into crossing regions and the maintenance
of the 1-Endpoint-Crossing property. Edge direction
does not affect these points of focus, and so we will
refer simply to S[euv] to mean the score of either the
edge from u to v or vice-versa.
In the following subsections, we show that the op-
timal parse for each type of sub-problem can be de-
composed into smaller valid sub-problems. If we
take the maximum over all these possible combina-
tions of smaller solutions, we can find the maximum
scoring parse for that sub-problem. Note that the
overall tree is a valid sub-problem (over the inter-
val [0, n]), so the argument will also hold for finding
the optimal overall tree. Each individual vertex and
each pair of adjacent vertices (with no edges) triv-
ially form isolated intervals (as there is no interior);
this forms the base case of the dynamic program.
The overall dynamic program takes O(n4) time:
there are O(n2) interval sub-problems, each of
which needs two free split points to find the max-
imum, and O(n3) region sub-problems, each of
which is a maximization over one free split point.
</bodyText>
<subsectionHeader confidence="0.99837">
4.1 Decomposing an Int sub-problem
</subsectionHeader>
<bodyText confidence="0.981064954545455">
Consider an isolated interval sub-problem Int[i, j].
There are three cases: (1) there are no edges between
i and the rest of the interval, (2) the longest edge in-
cident to i is not crossed, (3) the longest edge inci-
dent to i is crossed. An Int sub-problem can be de-
composed into smaller valid sub-problems in each of
these three cases. Finding the optimal Int forest can
be done by taking the maximum over these cases:
No edges between i and [i + 1, j]: The same set
of edges is also a valid Int[i + 1, j] sub-problem.
bi must be true for the Int[i + 1, j] sub-problem to
ensure i + 1 receives a parent.
Furthest edge from i is not crossed: If the furthest
edge is to j, the problem can be decomposed into
S[eij] + Int[i, j], as that edge has no effect on the
interior of the interval. Clearly, this is only appli-
cable if the boundary point needed a parent (as in-
dicated by the booleans) and the boolean must then
be updated accordingly. If the furthest edge is to
some k in (i, j), the problem is decomposed into
S[eik] + Int[i, k] + Int[k, j].
Furthest edge from i is crossed: This is the most
</bodyText>
<page confidence="0.995624">
17
</page>
<bodyText confidence="0.981092375">
interesting case, which uses two split points: the
other endpoint of the edge (k), and l = Pt(eik). The
dynamic program depends on the order of k and l.
l E/ (i, k) (Figure 4a): By Lemma 1, [i, k] U {l} and
[k, l]U{i} form isolated regions. (l, j] is the remain-
der of the interval, and the only vertex from [i, l) that
can have edges into (l, j] is k: (i, k) and (k, l) are
part of isolated regions, and i is ruled out because k
was i’s furthest neighbor.
If at least one edge from k into (l, j] (the dashed
line in Figure 4a) exists, the decomposition is as in
Figure 4a, Case i; otherwise, it is as in Figure 4a,
Case ii. In Case i, eik and the edge(s) between k and
(l, j] force all of the edges between l and (i, k) to
have k as their Pt. Thus, the region [i, k] U {l} must
be a sub-problem of type R (Figure 3b), as these
edges from l can only be crossed by edges with an
endpoint at k (the right endpoint of [i, k]). All of the
edges between k and (l, j] have l as their Pt, as they
are crossed by all the edges in P(eik), and so the
sub-problem corresponding to the region [l, j] U {k}
is of type L (Figure 3a). In Case ii, each of the edges
in P(eik) may choose either i or k as their Pt, so the
sub-problem [i, k] U {l} is of type LR (Figure 3c).
Note that l = j is a special case of Case ii in which
the rightmost interval Int[l, j] is empty.
l E (i, k) (Figure 4b): [i, l] U {k} and [l, k] U {i}
form isolated crossing regions by Lemma 1. There
cannot both be edges between i and (l, k) and be-
tween k and (i, l), as this would violate 1-Endpoint-
Crossing for the edges in P(eik). If there are any
edges between i and (l, k) (i.e., Case i in Figure 4b),
then all of the edges in P(eik) must choose i as their
Pt, and so these edges cannot be crossed at all in
the region [k, j]U{l}, and there cannot be any edges
from k into (i, l). If there are no such edges (Case
ii in 4b), then k must be a valid Pt for all edges in
P(eik), and so there can both be edges from k into
(i, l) and [k, j] U {l} may be of type L (allowing
crossings with an endpoint at k).
</bodyText>
<subsectionHeader confidence="0.995023">
4.2 Decomposing an LR sub-problem
</subsectionHeader>
<bodyText confidence="0.998477923076923">
An LR sub-problem is over an isolated crossing re-
gion [i, j] U {x}, such that edges from x into (i, j)
may be crossed by edges with an endpoint at either i
or j. This sub-problem is only defined when neither
i nor j get their parent from this sub-problem. From
a top-down perspective, this case is only used when
there will be an edge between i and j (as in one of
the sub-problems in Figure 4a, Case ii).
If none of the edges from x are crossed by any
edges with an endpoint at i, this can be considered
an R problem. Similarly, if none are crossed by any
edges with an endpoint at j, this may be considered
an L sub-problem. The only case which needs dis-
cussion is when both edges with an endpoint at i and
also at j cross edges from x; see Figure 3c for a
schematic. In that scenario, there must exist a split
point such that: (1) to the left of the point, all edges
crossing x-edges have an endpoint at i, and to the
right of the point, all such edges have an endpoint at
j, and (2) no edges in the region cross the split point.
Let ri be i’s rightmost child in (i, j); let lj be
j’s leftmost child in (i, j). Every edge from x into
(i, ri) is crossed by eiri; every edge between x and
(lj, j) is crossed by eljj. eiri cannot cross eljj, as
that would either violate 1-Endpoint-Crossing (be-
cause of the x-interior edges) or create a cycle (if
both children are also connected by an edge to x). ri
and lj also cannot be equal: as neither i nor j may
be assigned a parent, they must both be in the direc-
tion of the child, and the child cannot have multiple
parents. Thus, ri is to the left of lj.
Any split point between ri and lj clearly satis-
fies (1). There is at least one point within [ri, lj]
that satisfies (2) as long as there is not a chain
of crossing edges from eiri to eljj. The proof is
omitted for space reasons, but such a chain can be
ruled out using a counting argument similar to that
in the proof in Section 5.1. The decomposition is:
L[i, k, x] + R[k, j, x] for some k E (i, j).
</bodyText>
<subsectionHeader confidence="0.997743">
4.3 Decomposing an N sub-problem
</subsectionHeader>
<bodyText confidence="0.999925">
Consider the maximum scoring forest of type N
over [i, j] U {x} (Figure 3d; no edges from x are
crossed in this sub-problem). If there are no edges
from x, then it is also a valid Int[i, j] sub-problem.
If there are edges between x and the endpoints i or j,
then the forest with that edge removed is still a valid
N sub-problem (with the ancestor and parent book-
keeping updated). Otherwise, if there are edges be-
tween x and (i, j), choose the neighbor of x closest
to j (call it k). Since the edge exk is not crossed,
there are no edges from [i, k) into (k, j]; since k was
the neighbor of x closest to j, there are no edges
from x into (k, j]. Thus, the region decomposes into
</bodyText>
<page confidence="0.998755">
18
</page>
<figureCaption confidence="0.996147">
Figure 5: An L sub-problem over [i, j] U {x}, k is
the neighbor of x furthest from i in the interval.
</figureCaption>
<equation confidence="0.811105">
S[eik] + Int[k, j] + N[i, k, x].
</equation>
<bodyText confidence="0.99996775">
As an aside, if bx was true (x needed a parent
from this sub-problem), and k was a child of x,
then x’s parent must come from the [i, k] U {x} sub-
problem. However, it cannot be a descendant of k,
as that would cause a cycle. Thus in this case, we
call the sub-problem a N_XFromI problem, to in-
dicate that x needs a parent, i and k do not, and x
must be descended from i, not k.
</bodyText>
<subsectionHeader confidence="0.999107">
4.4 Decomposing an L or R sub-problem
</subsectionHeader>
<bodyText confidence="0.999906333333333">
An L sub-problem over [i, j] U {x} requires that any
edges in this region that cross an edge with an end-
point at x have an endpoint at i (the left endpoint). If
there are no edges between x and [i, j] in an L sub-
problem, then it is also a valid Int sub-problem over
[i, j]. If there are edges between x and i or j, then
the sub-problem can be decomposed into that edge
plus the rest of the forest with that edge removed.
The interesting case is when there are edges be-
tween x and the interior (Figure 5). Let k be the
neighbor of x within (i, j) that is furthest from i. As
all edges that cross exk will have an endpoint at i,
there are no edges between (i, k) and (k, j]. Com-
bined with the fact that k was the neighbor of x clos-
est to j, we have that [i, k] U {x} must form an iso-
</bodyText>
<figureCaption confidence="0.978691">
Figure 6: 2-planar but not 1-Endpoint-Crossing
</figureCaption>
<bodyText confidence="0.999143764705882">
lated crossing region, as must [k, j] U {i}.
If there are additional edges between x and the in-
terior (Case i in 5), all of the edges from i into (k, j]
cross both the edge exk and the other edges from x
into (i, k). The Pt for all these edges must there-
fore be x, and as x is not in the region [k, j] U {i},
those edges cannot be crossed at all in that region
(i.e., [k, j] U {i} must be of type N). If there are no
additional edges from x into (i, k) (Case ii in Fig-
ure 5), then all of the edges from i into (k, j) must
choose either x or k as their Pt. As there will be no
more edges from x, choosing k as their Pt allows
strictly more trees, and so [k, j] U {i} can be of type
L (allowing edges from i to be crossed in that region
by edges with an endpoint at k).
An R sub-problem is identical, with k instead
chosen to be the neighbor of x furthest from j.
</bodyText>
<sectionHeader confidence="0.999219" genericHeader="evaluation">
5 Connections
</sectionHeader>
<subsectionHeader confidence="0.9992905">
5.1 Graph Theory: All 1-Endpoint-Crossing
Trees are 2-Planar
</subsectionHeader>
<bodyText confidence="0.99924105">
The 2-planar characterization of dependency struc-
tures in Gómez-Rodríguez and Nivre (2010) exactly
correspond to 2-page book embeddings in graph the-
ory: an embedding of the vertices in a graph onto
a line (by analogy, along the spine of a book), and
the edges of the graph onto one of 2 (more gener-
ally, k) half-planes (pages of the book) such that no
edges on the same page cross (Bernhart and Kainen,
1979). The problem of finding an embedding that
minimizes the number of pages required is a natural
formulation of many problems arising in disparate
areas of computer science, for example, sorting a se-
quence using the minimum number of stacks (Even
and Itai, 1971), or constructing fault-tolerant layouts
in VLSI design (Chung et al., 1987).
In this section we prove 1-Endpoint-Crossing C
2-planar. These classes are not equal (Figure 6).
We first prove some properties about the crossings
graphs (Gómez-Rodríguez and Nivre, 2010) of 1-
Endpoint-Crossing trees. The crossings graph of a
</bodyText>
<figure confidence="0.9573746">
x i k j
(i) If dashed edge exists: All the edges from i into
(k, j] must choose x as their Pt. The interval decom-
poses into S[exk] + L[i, k, x] + N[k, j, i]:
x i k j
(ii) If no edges like the dashed edge exist: Edges
from i into (k, j] may choose k as their Pt. The in-
terval decomposes into S[exk]+Int[i, k]+L[k, j, i]:
x i k j
a b c d e f
</figure>
<page confidence="0.82231">
19
</page>
<figureCaption confidence="0.999862">
Figure 7: The crossing graphs for Figures 1a and 1b.
</figureCaption>
<bodyText confidence="0.953286228070175">
graph has a vertex corresponding to each edge in
the original, and an edge between two vertices if the
two edges they correspond to cross. The crossings
graphs for the dependency trees in Figures 1a and
1b are shown in Figures 7a and 7b, respectively.
Lemma 2. No 1-Endpoint-Crossing tree has a cycle
of length 3 in its crossings graph.
Proof. Assume there existed a cycle e1, e2, e3. e1
and e3 must share an endpoint, as they both cross
e2. Since e1 and e3 share an endpoint, e1 and e3 do
not cross. Contradiction.
Lemma 3. Any odd cycle of size n (n &gt; 4) in a
crossings graph of a 1-Endpoint-Crossing tree uses
at most n distinct vertices in the original graph.
Proof. Let e1, e2, ..., en be an odd cycle in a cross-
ings graph of a 1-Endpoint-Crossing tree with n &gt;
4. Since n &gt; 4, e1, e2, en_1, and en are distinct
edges. Let a be the vertex that e1 and en_1 share
(because they both cross en) and let b be the vertex
that e2 and en share (both cross e1). Note that e1
and en_1 cannot contain b and that e2 and en cannot
contain a (otherwise they would not cross an edge
adjacent to them along the cycle).
We will now consider how many vertices each
edge can introduce that are distinct from all vertices
previously seen in the cycle. e1 and e2 necessarily
introduce two distinct vertices each.
Let eo be the first odd edge that contains b (we
know one exists since en contains b). (o is at least 3,
since e1 does not contain b.) eo’s other vertex must
be the one shared with eo_2 (eo_2 does not contain b,
since eo was the first odd edge to contain b). There-
fore, both of eo’s vertices have already been seen
along the cycle.
Similarly, let ee be the first even edge that con-
tains an a. By the same reasoning, ee must not in-
troduce any new vertices.
All other edges ei such that i &gt; 2 and ei =� eo and
ei =� ee introduce at most one new vertex, since one
must be shared with the edge ei_2. There are n − 4
such edges.
Counting up all possibilities, the maximum num-
ber of distinct vertices is 4 + (n − 4) = n.
Theorem 1. 1-Endpoint-Crossing trees C 2-planar.
Proof. Assume there existed an odd cycle in the
crossings graph of a 1-Endpoint-Crossing tree. The
cycle has size at least 5 (by Lemma 2). There are
at least as many edges as vertices in the subgraph of
the forest induced by the vertices used in the cycle
(by Lemma 3). That implies the existence of a cycle
in the original graph, contradicting that the original
graph was a tree.
Since there are no odd cycles in the crossings
graph, the crossings graph of edges is bipartite. Each
side of the bipartite graph can be assigned to a page,
such that no two edges on the same page cross.
Therefore, the original graph was 2-planar.
</bodyText>
<subsectionHeader confidence="0.887845">
5.2 Linguistics: Cross-serial Verb
Constructions and Successive Cyclicity
</subsectionHeader>
<bodyText confidence="0.998605555555556">
Cross-serial verb constructions were used to provide
evidence for the “non-context-freeness” of natural
language (Shieber, 1985). Cross-serial verb con-
structions with two verbs form 1-Endpoint-Crossing
trees. Below is a cross-serial sentence from Swiss-
German, from (1) in Shieber (1985):
das mer em Hans es huus hälfed aastriiche
that we HansDAT the houseACC helped paint
The edges (that, helped), (helped, we), and
(helped, Hans) are each only crossed by an edge
with an endpoint at paint; the edge (paint, house)
is only crossed by edges with an endpoint at helped.
More generally, with a set of two cross serial verbs
in a subordinate clause, each verb should suffice as
the crossing point for all edges incident to the other
verb that are crossed.
Cross-serial constructions with three or more
verbs would have dependency trees that violate 1-
</bodyText>
<figure confidence="0.979357166666667">
(a)
(b)
(a,b) (a,c)
(b,d) (c,e)
(d,f)
(g,h)
(a,b) (a,c)
(g,d)
(b,g)
(h,f)
(b,e)
20
</figure>
<figureCaption confidence="0.959804">
Figure 8: An example of wh-movement over a poten-
</figureCaption>
<bodyText confidence="0.978282342857143">
tially unbounded number of clauses. The edges be-
tween the heads of each clause cross the edges from
trace to trace, but all obey 1-Endpoint-Crossing.
Endpoint-Crossing. Psycholinguistically, between
two and three verbs is exactly where there is a large
change in the sentence processing abilities of human
listeners (based on both grammatical judgments and
scores on a comprehension task) (Bach et al., 1986).
More speculatively, there may be a connection
between the form of 1-Endpoint-Crossing trees and
phases (roughly, propositional units such as clauses)
in Minimalism (Chomsky et al., 1998). Figure 8
shows an example of wh-movement over a poten-
tially unbounded number of clauses. The phase-
impenetrability condition (PIC) states that only the
head of the phase and elements that have moved to
its edge are accessible to the rest of the sentence
(Chomsky et al., 1998, p.22). Movement is there-
fore required to be successive cyclic, with a moved
element leaving a chain of traces at the edge of
each clause on its way to its final pronounced loca-
tion (Chomsky, 1981). In Figure 8, notice that the
crossing edges form a repeated pattern that obeys
the 1-Endpoint-Crossing property. More generally,
we suspect that trees satisfying the PIC will tend to
also be 1-Endpoint-Crossing. Furthermore, if the
traces were not at the edge of each clause, and in-
stead were positioned between a head and one of
its arguments, 1-Endpoint-Crossing would be vio-
lated. For example, if t2 in Figure 8 were be-
tween C and said2, then the edge (t1, t2) would cross
(say, said1), (said1, said2), and (C, said2), which
do not all share an endpoint. An exploration of these
linguistic connections may be an interesting avenue
for further research.
</bodyText>
<sectionHeader confidence="0.997688" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.9997775">
1-Endpoint-Crossing trees characterize over 95% of
structures found in natural language treebank, and
can be parsed in only a factor of n more time than
projective trees. The dynamic programming algo-
rithm for projective trees (Eisner, 2000) has been
extended to handle higher order factors (McDonald
and Pereira, 2006; Carreras, 2007; Koo and Collins,
2010), adding at most a factor of n to the edge-
based running time; it would be interesting to ex-
tend the algorithm presented here to include higher
order factors. 1-Endpoint-Crossing is a condition
on edges, while properties such as well-nestedness
or block degree are framed in terms of subtrees.
Three edges will always suffice as a certificate of a
1-Endpoint-Crossing violation (two vertex-disjoint
edges that both cross a third). In contrast, for a
property like ill-nestedness, two nodes might have
a least common ancestor arbitrarily far away, and so
one might need the entire graph to verify whether
the sub-trees rooted at those nodes are disjoint and
ill-nested. We have discussed cross-serial depen-
dencies; a further exploration of which linguistic
phenomena would and would not have 1-Endpoint-
Crossing dependency trees may be revealing.
</bodyText>
<sectionHeader confidence="0.985628" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.890763545454546">
We would like to thank Julie Legate for an in-
teresting discussion. This material is based upon
work supported under a National Science Foun-
dation Graduate Research Fellowship, NSF Award
CCF 1137084, and Army Research Office MURI
grant W911NF-07-1-0216.
A Dynamic Program to find the maximum
scoring 1-Endpoint-Crossing Tree
Input: Matrix S: S[i, j] is the score of the directed edge (i, j)
Output: Maximum score of a 1-Endpoint-Crossing tree over
vertices [0, n], rooted at 0
</bodyText>
<construct confidence="0.983002166666667">
Init: ∀i Int[i, i, F, F] = Int[i, i + 1, F, F] = 0
Int[i, i, T, F] = Int[i, i, F, T] = Int[i, i, T, T] = −oo
Final: Int[0, n, F, T]
Shorthand for booleans: TF(x, S) :=
if x = T, exactly one of the set S is true
if x = F, all of the set S must be false
</construct>
<bodyText confidence="0.986946375">
bi, bj, bx are true iff the corresponding boundary point has its
incoming edge (parent) in that sub-problem. For the LR sub-
problem, bi and bj are always false, and so omitted. For all
sub-problems with the suffix AFromB, the boundary point A
has its parent edge in the sub-problem solution; the other two
boundary points do not. For example, L_XFromI would cor-
respond to having booleans bi = bj = F and bx = T, with the
restriction that x must be a descendant of i.
</bodyText>
<figure confidence="0.795393545454546">
What did A say t, B said, t2 C said2 ... Z ate to?
21
�
������������������ �
�������������������
Int[i, j, F, bj] �-- max
Int[i + 1, j, T, F] if bj = F L[i, j, x, bi, bj, F] �-- max
S[i, j] + Int[i, j, F, F] if bj = T
S[i, k]+
Int[i, k, F, F] + Int[k, j, F, bj]
TF(bj,{bl,br})
</figure>
<construct confidence="0.8637008">
max LR[i, k, j, bl] + Int[k, j, F, br]
maxlE(k,j),TF(T,{bl,bm,br})
�R[i,k, l, F,F, bl] + Int[k, l, F, b,,,,] + L[l, j, k, br, bj, F]
LR[i, k, l, bl] + Int[k, l, F, b,,,,] + Int[l, j, br, bj]
maxlE(i,k),TF(T,{bl,bm,br})
�Int[i, l, F, bl] + L[l, k, i, b,,,,, F, F] + N[k, j, l, F, bj, br]
R[i, l, k, F, bl, F] + Int[l, k, b,,,,, F] + L[k, j, l, F, bj, br]
Int[i, j, T, F] symmetric to Int[i, j, F, T]
Int[i, j, T, T] −oo
LR[i, j, x, bx] +- max
L[i, j, x, F, F, bx]
R[i, j, x, F, F, bx]
maxkE(i,j),TF(bx,{bxl,bxr}),T F(T,{bkl,bkr})
L[i, k, x, F, bkl, bxl] + R[k, j, x, bkr, F, bxr]
N[i, j, x, bi, bj, F] +- max
</construct>
<figure confidence="0.993702528301887">
max
kE(i,j)
{
L[i, j, x, F, bj, T] �-- max
I
Int[i, j, bi, bj]
S[x, i] + L[i, j, x, F, bj, F] if bi = T
S[x, j] + L[i, j, x, bi, F, F] if bj = T
max
kE(i,j),TF(bi,{bl,br})
�L[i, k, x, bl, F, F] + N[k, j, i, F, bj, br]
Int[i, k, bl, F] + L[k, j, i, F, bj, br]
{
S[x, k]+
S[i, x] + L[i, j, x, F, bj, F]
S[x, j] + L_XFromI[i, j, x] if bj = T
S[j, x] + L[i, j, x, F, F, F] ifbj=F
S[j, x] + L_JFromI[i, j, x] if bj = T
S[x, k] + L_XFromI[i, k, x] + N[k, j, i, F, bj, F]
S[k, x]+
L_JFromI[i, k, x] + N[k, j, i, F, bj, F]
L[i, k, x, F, F, F] + N[k, j, i, T, bj, F]
Int[i, k, F, bl] + L[k, j, i, br, bj, F]
{
max
kE(i,j)
max
kE(i,j)
{
max
T F(T,{bl,br})
L[i, j, x, T, bj, T] +- not reachable
{ Int[i, j, bi, bj]
S[x, i] + N[i, j, x, F, bj, F] if bi = T
S[x, j] + N[i, j, x, bi, F, F] if bj = T
kE(i,j)
max S[x, k] + N[i, k, x, bi, F, F] + Int[k, j, F, bj]
N[i, j, x, F, bj, T] +- max
S[i, x] + N[i, j, x, F, bj, F]
S[x, j] + N_XFromI[i, j, x] if bj = T
S[j, x] + N[i, j, x, F, F, F] if bj = F
S[j, x] + Int[i, j, F, T] if bj = T
S[x, k] + N_XFromI[i, k, x] + Int[k, j, F, bj]
S[k, x]+
�Int[i,k,F,T]+Int[k,j,F,bj]
N[i, k, x, F, F, F] + Int[k, j, T, bj]
N[i, j, x, T, F, T] symmetric to N[i, j, x, F, T, T]
N[i, j, x, T, T, T] −oo
{
max
kE(i,j)
max
kE(i,j)
</figure>
<construct confidence="0.992543333333333">
L_XFromI[i, j, x] +- max
S[i, x] + L[i, j, x, F, F, F]
S[x, k] + L_XFromI[i, k, x] + N[k, j, i, F, F, F]
S[k, x]+
{ L_JFromI[i, k, x] + N[k, j, i, F, F, F]
L[i, k, x, F, F, F] + N_IFromX[k, j, i]
Int[i, k, F, T] + L[k, j, i, F, F, F]
Int[i, k, F, F] + L_IFromX[k, j, i]
L_IFromX[i, j, x] +- max
S[x, i] + L[i, j, x, F, F, F]
S[x, k]+
L[i, k, x, T, F, F] + N[k, j, i, F, F, F]
L[i, k, x, F, F, F] + N_XFromI[k, j, i]
Int[i, k, T, F] + L[k, j, i, F, F, F]
Int[i, k, F, F] + L_XFromI[k, j, i]
</construct>
<figure confidence="0.93869704">
{
max
kE(i,j)
max
kE(i,j)
I
max
kE(i,j)
I
N_XFromI[i, j, x] �-- max
{ S[i, x] + N[i, j, x, F, F, F]
maxkE(i,j)
�
S[x, k] + N_XFromI[i, k, x] + Int[k, j, F, F]
S[k, x] + Int[i, k, F, T] + Int[k, j, F, F]
L_JFromX[i, j, x] �-- max
S[x, j] + L[i, j, x, F, F, F]
S[x, k]+
�L[i, k, x, F, F, F] + Int[k, j, F, T]
Int[i, k, F, F] + L_JFromI[k, j, i]
�
��� �
����
max
kE(i,j)
</figure>
<reference confidence="0.855898142857143">
N_IFromX[i, j, x] �-- max
�S[x, i] + N[i, j, x, F, F, F]
max S[x, k] + N[i, k, x, T, F, F] + Int[k, j, F, F]
kE(i,j)
N_XFromJ[i, j, x] symmetric to N_XFromI[i, j, x]
N_JFromX[i, j, x] symmetric to N_IFromX[i, j, x]
L_JFromI[i, j, x] �-- max
</reference>
<page confidence="0.512347">
{
</page>
<bodyText confidence="0.828120666666667">
Int[i, j, F, T]
max
kE(i,j)
�L[i, k, x, F, F, F] + N_JFromX[k, j, i]
Int[i, k, F, F] + L_JFromX[k, j, i]
S[x, k]+
</bodyText>
<page confidence="0.987211">
22
</page>
<reference confidence="0.982645142857143">
R[i, j, x, ba, bj, F] symmetric to L[i, j, x, ba, bj, F]
R[i, j, x, ba, F, T] symmetric to L[i, j, x, F, bj, T]
R[i, j, x, ba, T, T] not reachable
R_XFromJ[i, j, x] symmetric to L_XFromI[i, j, x]
R_JFromX[i, j, x] symmetric to L_IFromX[i, j, x]
R_IFromX[i, j, x] symmetric to L_JFromX[i, j, x]
R_IFromJ[i, j, x] symmetric to L_JFromI[i, j, x]
</reference>
<sectionHeader confidence="0.921555" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999806931818182">
E. Bach, C. Brown, and W. Marslen-Wilson. 1986.
Crossed and nested dependencies in german and dutch:
A psycholinguistic study. Language and Cognitive
Processes, 1(4):249–262.
F. Bernhart and P.C. Kainen. 1979. The book thickness
of a graph. Journal of Combinatorial Theory, Series
B, 27(3):320 – 331.
M. Bodirsky, M. Kuhlmann, and M. Möhl. 2005. Well-
nested drawings as models of syntactic structure. In
In Tenth Conference on Formal Grammar and Ninth
Meeting on Mathematics of Language, pages 88–1.
University Press.
X. Carreras. 2007. Experiments with a higher-order
projective dependency parser. In Proceedings of the
CoNLL Shared Task Session of EMNLP-CoNLL, vol-
ume 7, pages 957–961.
N. Chomsky, Massachusetts Institute of Technology.
Dept. of Linguistics, and Philosophy. 1998. Minimal-
ist inquiries: the framework. MIT occasional papers
in linguistics. Distributed by MIT Working Papers in
Linguistics, MIT, Dept. of Linguistics.
N. Chomsky. 1981. Lectures on Government and Bind-
ing. Dordrecht: Foris.
F. Chung, F. Leighton, and A. Rosenberg. 1987. Em-
bedding graphs in books: A layout problem with ap-
plications to VLSI design. SIAM Journal on Algebraic
Discrete Methods, 8(1):33–58.
H. Cui, R. Sun, K. Li, M.Y. Kan, and T.S. Chua. 2005.
Question answering passage retrieval using depen-
dency relations. In Proceedings of the 28th annual
international ACM SIGIR conference on Research and
development in information retrieval, pages 400–407.
ACM.
A. Culotta and J. Sorensen. 2004. Dependency tree
kernels for relation extraction. In Proceedings of the
42nd Annual Meeting on Association for Computa-
tional Linguistics, page 423. Association for Compu-
tational Linguistics.
Y. Ding and M. Palmer. 2005. Machine translation using
probabilistic synchronous dependency insertion gram-
mars. In Proceedings of the 43rd Annual Meeting
on Association for Computational Linguistics, pages
541–548. Association for Computational Linguistics.
J. Eisner. 2000. Bilexical grammars and their cubic-
time parsing algorithms. In Harry Bunt and Anton
Nijholt, editors, Advances in Probabilistic and Other
Parsing Technologies, pages 29–62. Kluwer Academic
Publishers, October.
S. Even and A. Itai. 1971. Queues, stacks, and graphs.
In Proc. International Symp. on Theory of Machines
and Computations, pages 71–86.
C. Gómez-Rodríguez and J. Nivre. 2010. A transition-
based parser for 2-planar dependency structures. In
Proceedings of ACL, pages 1492–1501.
C. Gómez-Rodríguez, J. Carroll, and D. Weir. 2011. De-
pendency parsing schemata and mildly non-projective
dependency parsing. Computational Linguistics,
37(3):541–586.
T. Koo and M. Collins. 2010. Efficient third-order de-
pendency parsers. In Proceedings ofACL, pages 1–11.
M. Kuhlmann. 2013. Mildly non-projective dependency
grammar. Computational Linguistics, 39(2).
R. McDonald and F. Pereira. 2006. Online learning of
approximate dependency parsing algorithms. In Pro-
ceedings of EACL, pages 81–88.
R. McDonald and G. Satta. 2007. On the complexity
of non-projective data-driven dependency parsing. In
Proceedings of the 10th International Conference on
Parsing Technologies, pages 121–132.
R. McDonald, F. Pereira, K. Ribarov, and J. Hajiˇc. 2005.
Non-projective dependency parsing using spanning
tree algorithms. In Proceedings of the conference on
Human Language Technology and Empirical Methods
in Natural Language Processing, pages 523–530. As-
sociation for Computational Linguistics.
E. Pitler, S. Kannan, and M. Marcus. 2012. Dynamic
programming for higher order parsing of gap-minding
trees. In Proceedings of EMNLP, pages 478–488.
L.A. Ringenberg. 1967. College geometry. Wiley.
A. Rush and S. Petrov. 2012. Vine pruning for effi-
cient multi-pass dependency parsing. In Proceedings
of NAACL, pages 498–507.
S.M. Shieber. 1985. Evidence against the context-
freeness of natural language. Linguistics and Philoso-
phy, 8(3):333–343.
H. Zhang and R. McDonald. 2012. Generalized higher-
order dependency parsing with cube pruning. In Pro-
ceedings of EMNLP, pages 320–331.
</reference>
<page confidence="0.9996595">
23
24
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.798162">
<title confidence="0.999818">Finding Optimal 1-Endpoint-Crossing Trees</title>
<author confidence="0.999005">Emily Pitler</author>
<author confidence="0.999005">Sampath Kannan</author>
<author confidence="0.999005">Mitchell</author>
<affiliation confidence="0.9960535">Computer and Information University of</affiliation>
<address confidence="0.811345">Philadelphia, PA</address>
<email confidence="0.999686">epitler,kannan,mitch@seas.upenn.edu</email>
<abstract confidence="0.999529588235294">Dependency parsing algorithms capable of producing the types of crossing dependencies seen in natural language sentences have traditionally been orders of magnitude slower than algorithms for projective trees. For 95.8- 99.8% of dependency parses in various natural language treebanks, whenever an edge is crossed, the edges that cross it all have a common vertex. The optimal dependency tree that satisfies this 1-Endpoint-Crossing propcan be found with an algorithm that recursively combines forests over intervals with one exterior point. 1-Endpoint- Crossing trees also have natural connections to linguistics and another class of graphs that has been studied in NLP.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>NIFromX</author>
</authors>
<note>x] �-- max</note>
<marker>NIFromX, </marker>
<rawString>N_IFromX[i, j, x] �-- max</rawString>
</citation>
<citation valid="false">
<authors>
<author>N �S</author>
</authors>
<journal>F, F, F] max S[x, k] + N[i, k, x, T, F, F] + Int[k, j, F, F] kE(i,j)</journal>
<marker>�S, </marker>
<rawString>�S[x, i] + N[i, j, x, F, F, F] max S[x, k] + N[i, k, x, T, F, F] + Int[k, j, F, F] kE(i,j)</rawString>
</citation>
<citation valid="false">
<authors>
<author>NXFromJ</author>
</authors>
<title>x] symmetric to N_XFromI[i, j, x] N_JFromX[i, j, x] symmetric to N_IFromX[i, j, x] L_JFromI[i, j, x] �-- max R[i, j, x, ba, bj, F] symmetric to L[i, j, x, ba, bj, F] R[i, j, x, ba, F, T] symmetric to L[i, j,</title>
<journal>x, F, bj, T] R[i, j, x, ba, T, T] not</journal>
<note>j, x</note>
<marker>NXFromJ, </marker>
<rawString>N_XFromJ[i, j, x] symmetric to N_XFromI[i, j, x] N_JFromX[i, j, x] symmetric to N_IFromX[i, j, x] L_JFromI[i, j, x] �-- max R[i, j, x, ba, bj, F] symmetric to L[i, j, x, ba, bj, F] R[i, j, x, ba, F, T] symmetric to L[i, j, x, F, bj, T] R[i, j, x, ba, T, T] not reachable R_XFromJ[i, j, x] symmetric to L_XFromI[i, j, x] R_JFromX[i, j, x] symmetric to L_IFromX[i, j, x] R_IFromX[i, j, x] symmetric to L_JFromX[i, j, x] R_IFromJ[i, j, x] symmetric to L_JFromI[i, j, x]</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Bach</author>
<author>C Brown</author>
<author>W Marslen-Wilson</author>
</authors>
<title>Crossed and nested dependencies in german and dutch: A psycholinguistic study.</title>
<date>1986</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>1--4</pages>
<contexts>
<context position="30751" citStr="Bach et al., 1986" startWordPosition="5703" endWordPosition="5706">tructions with three or more verbs would have dependency trees that violate 1- (a) (b) (a,b) (a,c) (b,d) (c,e) (d,f) (g,h) (a,b) (a,c) (g,d) (b,g) (h,f) (b,e) 20 Figure 8: An example of wh-movement over a potentially unbounded number of clauses. The edges between the heads of each clause cross the edges from trace to trace, but all obey 1-Endpoint-Crossing. Endpoint-Crossing. Psycholinguistically, between two and three verbs is exactly where there is a large change in the sentence processing abilities of human listeners (based on both grammatical judgments and scores on a comprehension task) (Bach et al., 1986). More speculatively, there may be a connection between the form of 1-Endpoint-Crossing trees and phases (roughly, propositional units such as clauses) in Minimalism (Chomsky et al., 1998). Figure 8 shows an example of wh-movement over a potentially unbounded number of clauses. The phaseimpenetrability condition (PIC) states that only the head of the phase and elements that have moved to its edge are accessible to the rest of the sentence (Chomsky et al., 1998, p.22). Movement is therefore required to be successive cyclic, with a moved element leaving a chain of traces at the edge of each clau</context>
</contexts>
<marker>Bach, Brown, Marslen-Wilson, 1986</marker>
<rawString>E. Bach, C. Brown, and W. Marslen-Wilson. 1986. Crossed and nested dependencies in german and dutch: A psycholinguistic study. Language and Cognitive Processes, 1(4):249–262.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Bernhart</author>
<author>P C Kainen</author>
</authors>
<title>The book thickness of a graph.</title>
<date>1979</date>
<journal>Journal of Combinatorial Theory, Series B,</journal>
<volume>27</volume>
<issue>3</issue>
<pages>331</pages>
<contexts>
<context position="25621" citStr="Bernhart and Kainen, 1979" startWordPosition="4770" endWordPosition="4773"> in that region by edges with an endpoint at k). An R sub-problem is identical, with k instead chosen to be the neighbor of x furthest from j. 5 Connections 5.1 Graph Theory: All 1-Endpoint-Crossing Trees are 2-Planar The 2-planar characterization of dependency structures in Gómez-Rodríguez and Nivre (2010) exactly correspond to 2-page book embeddings in graph theory: an embedding of the vertices in a graph onto a line (by analogy, along the spine of a book), and the edges of the graph onto one of 2 (more generally, k) half-planes (pages of the book) such that no edges on the same page cross (Bernhart and Kainen, 1979). The problem of finding an embedding that minimizes the number of pages required is a natural formulation of many problems arising in disparate areas of computer science, for example, sorting a sequence using the minimum number of stacks (Even and Itai, 1971), or constructing fault-tolerant layouts in VLSI design (Chung et al., 1987). In this section we prove 1-Endpoint-Crossing C 2-planar. These classes are not equal (Figure 6). We first prove some properties about the crossings graphs (Gómez-Rodríguez and Nivre, 2010) of 1- Endpoint-Crossing trees. The crossings graph of a x i k j (i) If da</context>
</contexts>
<marker>Bernhart, Kainen, 1979</marker>
<rawString>F. Bernhart and P.C. Kainen. 1979. The book thickness of a graph. Journal of Combinatorial Theory, Series B, 27(3):320 – 331.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Bodirsky</author>
<author>M Kuhlmann</author>
<author>M Möhl</author>
</authors>
<title>Wellnested drawings as models of syntactic structure.</title>
<date>2005</date>
<booktitle>In In Tenth Conference on Formal Grammar and Ninth Meeting on Mathematics of Language,</booktitle>
<pages>88--1</pages>
<publisher>University Press.</publisher>
<contexts>
<context position="5078" citStr="Bodirsky et al., 2005" startWordPosition="790" endWordPosition="793"> below: Definition 3. For each node u in the tree, a block of the node is “a longest segment consisting of descendants of u.” (Kuhlmann, 2013). The block-degree of u is “the number of distinct blocks of u”. The block degree of a tree is the maximum block degree of any of its nodes. The gap degree is the number of gaps between these blocks, and so by definition is one less than the block degree. (Kuhlmann, 2013) Definition 4. Two trees “T1 and T2 interleave iff there are nodes l1,r1 E T1 and l2,r2 E T2 such that l1 &lt; l2 &lt; r1 &lt; r2.” A tree is well-nested if no two disjoint subtrees interleave. (Bodirsky et al., 2005) As can be seen in Table 1, 95.4%-99.9% of dependency parses across treebanks are both well-nested and have block degree 2. The optimal such tree can be found in O(n7) time and O(n5) space (GómezRodríguez et al., 2011). 1Conventional edges from the artificial root node to the root(s) of the sentence reduce the empirical coverage of 1- Endpoint-Crossing trees. Excluding these artificial root edges, the empirical coverage for Dutch rises to 12949 (97.0%). These edges have no effect on the coverage of well-nested trees with block degree at most 2, gap-minding trees, or projective trees. Figure 1:</context>
</contexts>
<marker>Bodirsky, Kuhlmann, Möhl, 2005</marker>
<rawString>M. Bodirsky, M. Kuhlmann, and M. Möhl. 2005. Wellnested drawings as models of syntactic structure. In In Tenth Conference on Formal Grammar and Ninth Meeting on Mathematics of Language, pages 88–1. University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
</authors>
<title>Experiments with a higher-order projective dependency parser.</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL,</booktitle>
<volume>7</volume>
<pages>957--961</pages>
<contexts>
<context position="32418" citStr="Carreras, 2007" startWordPosition="5979" endWordPosition="5980">xample, if t2 in Figure 8 were between C and said2, then the edge (t1, t2) would cross (say, said1), (said1, said2), and (C, said2), which do not all share an endpoint. An exploration of these linguistic connections may be an interesting avenue for further research. 6 Conclusions 1-Endpoint-Crossing trees characterize over 95% of structures found in natural language treebank, and can be parsed in only a factor of n more time than projective trees. The dynamic programming algorithm for projective trees (Eisner, 2000) has been extended to handle higher order factors (McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010), adding at most a factor of n to the edgebased running time; it would be interesting to extend the algorithm presented here to include higher order factors. 1-Endpoint-Crossing is a condition on edges, while properties such as well-nestedness or block degree are framed in terms of subtrees. Three edges will always suffice as a certificate of a 1-Endpoint-Crossing violation (two vertex-disjoint edges that both cross a third). In contrast, for a property like ill-nestedness, two nodes might have a least common ancestor arbitrarily far away, and so one might need the enti</context>
</contexts>
<marker>Carreras, 2007</marker>
<rawString>X. Carreras. 2007. Experiments with a higher-order projective dependency parser. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL, volume 7, pages 957–961.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<title>Massachusetts Institute of Technology. Dept. of Linguistics, and Philosophy.</title>
<date>1998</date>
<booktitle>Distributed by MIT Working Papers in Linguistics, MIT, Dept. of Linguistics.</booktitle>
<marker>Chomsky, 1998</marker>
<rawString>N. Chomsky, Massachusetts Institute of Technology. Dept. of Linguistics, and Philosophy. 1998. Minimalist inquiries: the framework. MIT occasional papers in linguistics. Distributed by MIT Working Papers in Linguistics, MIT, Dept. of Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<date>1981</date>
<booktitle>Lectures on Government and Binding.</booktitle>
<location>Dordrecht: Foris.</location>
<contexts>
<context position="31413" citStr="Chomsky, 1981" startWordPosition="5816" endWordPosition="5817">between the form of 1-Endpoint-Crossing trees and phases (roughly, propositional units such as clauses) in Minimalism (Chomsky et al., 1998). Figure 8 shows an example of wh-movement over a potentially unbounded number of clauses. The phaseimpenetrability condition (PIC) states that only the head of the phase and elements that have moved to its edge are accessible to the rest of the sentence (Chomsky et al., 1998, p.22). Movement is therefore required to be successive cyclic, with a moved element leaving a chain of traces at the edge of each clause on its way to its final pronounced location (Chomsky, 1981). In Figure 8, notice that the crossing edges form a repeated pattern that obeys the 1-Endpoint-Crossing property. More generally, we suspect that trees satisfying the PIC will tend to also be 1-Endpoint-Crossing. Furthermore, if the traces were not at the edge of each clause, and instead were positioned between a head and one of its arguments, 1-Endpoint-Crossing would be violated. For example, if t2 in Figure 8 were between C and said2, then the edge (t1, t2) would cross (say, said1), (said1, said2), and (C, said2), which do not all share an endpoint. An exploration of these linguistic conne</context>
</contexts>
<marker>Chomsky, 1981</marker>
<rawString>N. Chomsky. 1981. Lectures on Government and Binding. Dordrecht: Foris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Chung</author>
<author>F Leighton</author>
<author>A Rosenberg</author>
</authors>
<title>Embedding graphs in books: A layout problem with applications to VLSI design.</title>
<date>1987</date>
<journal>SIAM Journal on Algebraic Discrete Methods,</journal>
<volume>8</volume>
<issue>1</issue>
<contexts>
<context position="25957" citStr="Chung et al., 1987" startWordPosition="4824" endWordPosition="4827">embeddings in graph theory: an embedding of the vertices in a graph onto a line (by analogy, along the spine of a book), and the edges of the graph onto one of 2 (more generally, k) half-planes (pages of the book) such that no edges on the same page cross (Bernhart and Kainen, 1979). The problem of finding an embedding that minimizes the number of pages required is a natural formulation of many problems arising in disparate areas of computer science, for example, sorting a sequence using the minimum number of stacks (Even and Itai, 1971), or constructing fault-tolerant layouts in VLSI design (Chung et al., 1987). In this section we prove 1-Endpoint-Crossing C 2-planar. These classes are not equal (Figure 6). We first prove some properties about the crossings graphs (Gómez-Rodríguez and Nivre, 2010) of 1- Endpoint-Crossing trees. The crossings graph of a x i k j (i) If dashed edge exists: All the edges from i into (k, j] must choose x as their Pt. The interval decomposes into S[exk] + L[i, k, x] + N[k, j, i]: x i k j (ii) If no edges like the dashed edge exist: Edges from i into (k, j] may choose k as their Pt. The interval decomposes into S[exk]+Int[i, k]+L[k, j, i]: x i k j a b c d e f 19 Figure 7: </context>
</contexts>
<marker>Chung, Leighton, Rosenberg, 1987</marker>
<rawString>F. Chung, F. Leighton, and A. Rosenberg. 1987. Embedding graphs in books: A layout problem with applications to VLSI design. SIAM Journal on Algebraic Discrete Methods, 8(1):33–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cui</author>
<author>R Sun</author>
<author>K Li</author>
<author>M Y Kan</author>
<author>T S Chua</author>
</authors>
<title>Question answering passage retrieval using dependency relations.</title>
<date>2005</date>
<booktitle>In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>400--407</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1177" citStr="Cui et al., 2005" startWordPosition="163" endWordPosition="166">ave a common vertex. The optimal dependency tree that satisfies this 1-Endpoint-Crossing property can be found with an O(n4) parsing algorithm that recursively combines forests over intervals with one exterior point. 1-EndpointCrossing trees also have natural connections to linguistics and another class of graphs that has been studied in NLP. 1 Introduction Dependency parsing is one of the fundamental problems in natural language processing today, with applications such as machine translation (Ding and Palmer, 2005), information extraction (Culotta and Sorensen, 2004), and question answering (Cui et al., 2005). Most high-accuracy graph-based dependency parsers (Koo and Collins, 2010; Rush and Petrov, 2012; Zhang and McDonald, 2012) find the highest-scoring projective trees (in which no edges cross), despite the fact that a large proportion of natural language sentences are non-projective. Projective trees can be found in O(n3) time (Eisner, 2000), but cover only 63.6% of sentences in some natural language treebanks (Table 1). The class of directed spanning trees covers all treebank trees and can be parsed in O(n2) with edge-based features (McDonald et al., 2005), but it is NP-hard to find the maxim</context>
</contexts>
<marker>Cui, Sun, Li, Kan, Chua, 2005</marker>
<rawString>H. Cui, R. Sun, K. Li, M.Y. Kan, and T.S. Chua. 2005. Question answering passage retrieval using dependency relations. In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 400–407. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Culotta</author>
<author>J Sorensen</author>
</authors>
<title>Dependency tree kernels for relation extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>423</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1134" citStr="Culotta and Sorensen, 2004" startWordPosition="156" endWordPosition="159">ver an edge is crossed, the edges that cross it all have a common vertex. The optimal dependency tree that satisfies this 1-Endpoint-Crossing property can be found with an O(n4) parsing algorithm that recursively combines forests over intervals with one exterior point. 1-EndpointCrossing trees also have natural connections to linguistics and another class of graphs that has been studied in NLP. 1 Introduction Dependency parsing is one of the fundamental problems in natural language processing today, with applications such as machine translation (Ding and Palmer, 2005), information extraction (Culotta and Sorensen, 2004), and question answering (Cui et al., 2005). Most high-accuracy graph-based dependency parsers (Koo and Collins, 2010; Rush and Petrov, 2012; Zhang and McDonald, 2012) find the highest-scoring projective trees (in which no edges cross), despite the fact that a large proportion of natural language sentences are non-projective. Projective trees can be found in O(n3) time (Eisner, 2000), but cover only 63.6% of sentences in some natural language treebanks (Table 1). The class of directed spanning trees covers all treebank trees and can be parsed in O(n2) with edge-based features (McDonald et al.,</context>
</contexts>
<marker>Culotta, Sorensen, 2004</marker>
<rawString>A. Culotta and J. Sorensen. 2004. Dependency tree kernels for relation extraction. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 423. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Ding</author>
<author>M Palmer</author>
</authors>
<title>Machine translation using probabilistic synchronous dependency insertion grammars.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>541--548</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1081" citStr="Ding and Palmer, 2005" startWordPosition="150" endWordPosition="153">ses in various natural language treebanks, whenever an edge is crossed, the edges that cross it all have a common vertex. The optimal dependency tree that satisfies this 1-Endpoint-Crossing property can be found with an O(n4) parsing algorithm that recursively combines forests over intervals with one exterior point. 1-EndpointCrossing trees also have natural connections to linguistics and another class of graphs that has been studied in NLP. 1 Introduction Dependency parsing is one of the fundamental problems in natural language processing today, with applications such as machine translation (Ding and Palmer, 2005), information extraction (Culotta and Sorensen, 2004), and question answering (Cui et al., 2005). Most high-accuracy graph-based dependency parsers (Koo and Collins, 2010; Rush and Petrov, 2012; Zhang and McDonald, 2012) find the highest-scoring projective trees (in which no edges cross), despite the fact that a large proportion of natural language sentences are non-projective. Projective trees can be found in O(n3) time (Eisner, 2000), but cover only 63.6% of sentences in some natural language treebanks (Table 1). The class of directed spanning trees covers all treebank trees and can be parse</context>
</contexts>
<marker>Ding, Palmer, 2005</marker>
<rawString>Y. Ding and M. Palmer. 2005. Machine translation using probabilistic synchronous dependency insertion grammars. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 541–548. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisner</author>
</authors>
<title>Bilexical grammars and their cubictime parsing algorithms.</title>
<date>2000</date>
<booktitle>Advances in Probabilistic and Other Parsing Technologies,</booktitle>
<pages>29--62</pages>
<editor>In Harry Bunt and Anton Nijholt, editors,</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<contexts>
<context position="1520" citStr="Eisner, 2000" startWordPosition="218" endWordPosition="219">Introduction Dependency parsing is one of the fundamental problems in natural language processing today, with applications such as machine translation (Ding and Palmer, 2005), information extraction (Culotta and Sorensen, 2004), and question answering (Cui et al., 2005). Most high-accuracy graph-based dependency parsers (Koo and Collins, 2010; Rush and Petrov, 2012; Zhang and McDonald, 2012) find the highest-scoring projective trees (in which no edges cross), despite the fact that a large proportion of natural language sentences are non-projective. Projective trees can be found in O(n3) time (Eisner, 2000), but cover only 63.6% of sentences in some natural language treebanks (Table 1). The class of directed spanning trees covers all treebank trees and can be parsed in O(n2) with edge-based features (McDonald et al., 2005), but it is NP-hard to find the maximum scoring such tree with grandparent or sibling features (McDonald and Pereira, 2006; McDonald and Satta, 2007). There are various existing definitions of mildly non-projective trees with better empirical coverage than projective trees that do not have the hardness of extensibility that spanning trees do. However, these have had parsing alg</context>
<context position="6376" citStr="Eisner, 2000" startWordPosition="1015" endWordPosition="1017">minding but not 2-planar. Definition 5. A tree is gap-minding if it is wellnested, has gap degree at most 1, and has gap inheritance degree 0. Gap inheritance degree 0 requires that there are no child nodes with descendants in more than one of their parent’s blocks. (Pitler et al., 2012) Gap-minding trees can be parsed in O(n5) (Pitler et al., 2012). They have slightly less empirical coverage, however: 90.4-97.7% (Table 1). Definition 6. A tree is projective if it has block degree 1 (gap degree 0). This definition has the least coverage (as low as 63.6% for Dutch), but can be parsed in O(n3) (Eisner, 2000). Definition 7. A tree is 2-planar if each edge can be drawn either above or below the sentence such that no edges cross (Gómez-Rodríguez and Nivre, 2010). Gómez-Rodríguez and Nivre (2010) presented a transition-based parser for 2-planar trees, but there is no known globally optimal parsing algorithm for 2-planar trees. Clearly projective C gap-minding C well-nested with block degree at most 2. In Section 5.1, we prove the somewhat surprising fact that 1-EndpointCrossing C 2-planar. These are two distinct hierarchies capturing different dimensions of nonprojectivity: 1-Endpoint-Crossing V= wel</context>
<context position="8425" citStr="Eisner (2000" startWordPosition="1352" endWordPosition="1353"> statistics and parsing times of previously proposed properties are shown for comparison. Definition 8. Within a 1-Endpoint-Crossing tree, the (crossing) pencil2 of an edge e (P(e)) is defined as the set of edges (sharing an endpoint) that cross e. The (crossing pencil) point of an edge e (Pt(e)) is defined as the endpoint that all edges in P(e) share. We will use euv to indicate an edge in either direction between u and v, i.e., either u → v or u ← v. Before defining the parsing algorithm, we first give some intuition by analogy to parsing for projective trees. (This argument mirrors that of Eisner (2000, pps.38-39).) Projective trees can be produced using dynamic programming over intervals. Intervals are sufficient for projective trees: consider any edge euv in a projective tree. The vertices in (u, v) must only have edges to vertices in [u, v]. If there were an edge between a vertex in (u, v) and a vertex outside [u, v], such an edge would cross euv, which would contradict the assumption of projectivity. Thus every edge in a projective tree creates one interior interval isolated from the rest of the tree, allowing dynamic programming over intervals. We can analyze the case of 1- Endpoint-Cr</context>
<context position="32325" citStr="Eisner, 2000" startWordPosition="5965" endWordPosition="5966">tioned between a head and one of its arguments, 1-Endpoint-Crossing would be violated. For example, if t2 in Figure 8 were between C and said2, then the edge (t1, t2) would cross (say, said1), (said1, said2), and (C, said2), which do not all share an endpoint. An exploration of these linguistic connections may be an interesting avenue for further research. 6 Conclusions 1-Endpoint-Crossing trees characterize over 95% of structures found in natural language treebank, and can be parsed in only a factor of n more time than projective trees. The dynamic programming algorithm for projective trees (Eisner, 2000) has been extended to handle higher order factors (McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010), adding at most a factor of n to the edgebased running time; it would be interesting to extend the algorithm presented here to include higher order factors. 1-Endpoint-Crossing is a condition on edges, while properties such as well-nestedness or block degree are framed in terms of subtrees. Three edges will always suffice as a certificate of a 1-Endpoint-Crossing violation (two vertex-disjoint edges that both cross a third). In contrast, for a property like ill-nestedness, two </context>
</contexts>
<marker>Eisner, 2000</marker>
<rawString>J. Eisner. 2000. Bilexical grammars and their cubictime parsing algorithms. In Harry Bunt and Anton Nijholt, editors, Advances in Probabilistic and Other Parsing Technologies, pages 29–62. Kluwer Academic Publishers, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Even</author>
<author>A Itai</author>
</authors>
<title>Queues, stacks, and graphs.</title>
<date>1971</date>
<booktitle>In Proc. International Symp. on Theory of Machines and Computations,</booktitle>
<pages>71--86</pages>
<contexts>
<context position="25881" citStr="Even and Itai, 1971" startWordPosition="4813" endWordPosition="4816">ctures in Gómez-Rodríguez and Nivre (2010) exactly correspond to 2-page book embeddings in graph theory: an embedding of the vertices in a graph onto a line (by analogy, along the spine of a book), and the edges of the graph onto one of 2 (more generally, k) half-planes (pages of the book) such that no edges on the same page cross (Bernhart and Kainen, 1979). The problem of finding an embedding that minimizes the number of pages required is a natural formulation of many problems arising in disparate areas of computer science, for example, sorting a sequence using the minimum number of stacks (Even and Itai, 1971), or constructing fault-tolerant layouts in VLSI design (Chung et al., 1987). In this section we prove 1-Endpoint-Crossing C 2-planar. These classes are not equal (Figure 6). We first prove some properties about the crossings graphs (Gómez-Rodríguez and Nivre, 2010) of 1- Endpoint-Crossing trees. The crossings graph of a x i k j (i) If dashed edge exists: All the edges from i into (k, j] must choose x as their Pt. The interval decomposes into S[exk] + L[i, k, x] + N[k, j, i]: x i k j (ii) If no edges like the dashed edge exist: Edges from i into (k, j] may choose k as their Pt. The interval de</context>
</contexts>
<marker>Even, Itai, 1971</marker>
<rawString>S. Even and A. Itai. 1971. Queues, stacks, and graphs. In Proc. International Symp. on Theory of Machines and Computations, pages 71–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Gómez-Rodríguez</author>
<author>J Nivre</author>
</authors>
<title>A transitionbased parser for 2-planar dependency structures.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1492--1501</pages>
<contexts>
<context position="6530" citStr="Gómez-Rodríguez and Nivre, 2010" startWordPosition="1041" endWordPosition="1044">gree 0. Gap inheritance degree 0 requires that there are no child nodes with descendants in more than one of their parent’s blocks. (Pitler et al., 2012) Gap-minding trees can be parsed in O(n5) (Pitler et al., 2012). They have slightly less empirical coverage, however: 90.4-97.7% (Table 1). Definition 6. A tree is projective if it has block degree 1 (gap degree 0). This definition has the least coverage (as low as 63.6% for Dutch), but can be parsed in O(n3) (Eisner, 2000). Definition 7. A tree is 2-planar if each edge can be drawn either above or below the sentence such that no edges cross (Gómez-Rodríguez and Nivre, 2010). Gómez-Rodríguez and Nivre (2010) presented a transition-based parser for 2-planar trees, but there is no known globally optimal parsing algorithm for 2-planar trees. Clearly projective C gap-minding C well-nested with block degree at most 2. In Section 5.1, we prove the somewhat surprising fact that 1-EndpointCrossing C 2-planar. These are two distinct hierarchies capturing different dimensions of nonprojectivity: 1-Endpoint-Crossing V= well-nested with block degree 2 (Figure 1a), and gap-minding V= 2-planar (Figure 1b). 3 Edges (and their Crossing Point) Define Isolated Crossing Regions We </context>
<context position="25303" citStr="Gómez-Rodríguez and Nivre (2010)" startWordPosition="4709" endWordPosition="4712">e N). If there are no additional edges from x into (i, k) (Case ii in Figure 5), then all of the edges from i into (k, j) must choose either x or k as their Pt. As there will be no more edges from x, choosing k as their Pt allows strictly more trees, and so [k, j] U {i} can be of type L (allowing edges from i to be crossed in that region by edges with an endpoint at k). An R sub-problem is identical, with k instead chosen to be the neighbor of x furthest from j. 5 Connections 5.1 Graph Theory: All 1-Endpoint-Crossing Trees are 2-Planar The 2-planar characterization of dependency structures in Gómez-Rodríguez and Nivre (2010) exactly correspond to 2-page book embeddings in graph theory: an embedding of the vertices in a graph onto a line (by analogy, along the spine of a book), and the edges of the graph onto one of 2 (more generally, k) half-planes (pages of the book) such that no edges on the same page cross (Bernhart and Kainen, 1979). The problem of finding an embedding that minimizes the number of pages required is a natural formulation of many problems arising in disparate areas of computer science, for example, sorting a sequence using the minimum number of stacks (Even and Itai, 1971), or constructing faul</context>
</contexts>
<marker>Gómez-Rodríguez, Nivre, 2010</marker>
<rawString>C. Gómez-Rodríguez and J. Nivre. 2010. A transitionbased parser for 2-planar dependency structures. In Proceedings of ACL, pages 1492–1501.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Gómez-Rodríguez</author>
<author>J Carroll</author>
<author>D Weir</author>
</authors>
<title>Dependency parsing schemata and mildly non-projective dependency parsing.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>3</issue>
<marker>Gómez-Rodríguez, Carroll, Weir, 2011</marker>
<rawString>C. Gómez-Rodríguez, J. Carroll, and D. Weir. 2011. Dependency parsing schemata and mildly non-projective dependency parsing. Computational Linguistics, 37(3):541–586.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Koo</author>
<author>M Collins</author>
</authors>
<title>Efficient third-order dependency parsers.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<booktitle>In Proceedings ofACL,</booktitle>
<volume>39</volume>
<issue>2</issue>
<pages>1--11</pages>
<contexts>
<context position="1251" citStr="Koo and Collins, 2010" startWordPosition="173" endWordPosition="176">-Endpoint-Crossing property can be found with an O(n4) parsing algorithm that recursively combines forests over intervals with one exterior point. 1-EndpointCrossing trees also have natural connections to linguistics and another class of graphs that has been studied in NLP. 1 Introduction Dependency parsing is one of the fundamental problems in natural language processing today, with applications such as machine translation (Ding and Palmer, 2005), information extraction (Culotta and Sorensen, 2004), and question answering (Cui et al., 2005). Most high-accuracy graph-based dependency parsers (Koo and Collins, 2010; Rush and Petrov, 2012; Zhang and McDonald, 2012) find the highest-scoring projective trees (in which no edges cross), despite the fact that a large proportion of natural language sentences are non-projective. Projective trees can be found in O(n3) time (Eisner, 2000), but cover only 63.6% of sentences in some natural language treebanks (Table 1). The class of directed spanning trees covers all treebank trees and can be parsed in O(n2) with edge-based features (McDonald et al., 2005), but it is NP-hard to find the maximum scoring such tree with grandparent or sibling features (McDonald and Pe</context>
<context position="32442" citStr="Koo and Collins, 2010" startWordPosition="5981" endWordPosition="5984"> Figure 8 were between C and said2, then the edge (t1, t2) would cross (say, said1), (said1, said2), and (C, said2), which do not all share an endpoint. An exploration of these linguistic connections may be an interesting avenue for further research. 6 Conclusions 1-Endpoint-Crossing trees characterize over 95% of structures found in natural language treebank, and can be parsed in only a factor of n more time than projective trees. The dynamic programming algorithm for projective trees (Eisner, 2000) has been extended to handle higher order factors (McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010), adding at most a factor of n to the edgebased running time; it would be interesting to extend the algorithm presented here to include higher order factors. 1-Endpoint-Crossing is a condition on edges, while properties such as well-nestedness or block degree are framed in terms of subtrees. Three edges will always suffice as a certificate of a 1-Endpoint-Crossing violation (two vertex-disjoint edges that both cross a third). In contrast, for a property like ill-nestedness, two nodes might have a least common ancestor arbitrarily far away, and so one might need the entire graph to verify wheth</context>
</contexts>
<marker>Koo, Collins, 2010</marker>
<rawString>T. Koo and M. Collins. 2010. Efficient third-order dependency parsers. In Proceedings ofACL, pages 1–11. M. Kuhlmann. 2013. Mildly non-projective dependency grammar. Computational Linguistics, 39(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>81--88</pages>
<contexts>
<context position="1862" citStr="McDonald and Pereira, 2006" startWordPosition="272" endWordPosition="275">d Collins, 2010; Rush and Petrov, 2012; Zhang and McDonald, 2012) find the highest-scoring projective trees (in which no edges cross), despite the fact that a large proportion of natural language sentences are non-projective. Projective trees can be found in O(n3) time (Eisner, 2000), but cover only 63.6% of sentences in some natural language treebanks (Table 1). The class of directed spanning trees covers all treebank trees and can be parsed in O(n2) with edge-based features (McDonald et al., 2005), but it is NP-hard to find the maximum scoring such tree with grandparent or sibling features (McDonald and Pereira, 2006; McDonald and Satta, 2007). There are various existing definitions of mildly non-projective trees with better empirical coverage than projective trees that do not have the hardness of extensibility that spanning trees do. However, these have had parsing algorithms that are orders of magnitude slower than the projective case or the edgebased spanning tree case. For example, well-nested dependency trees with block degree 2 (Kuhlmann, 2013) cover at least 95.4% of natural language structures, but have a parsing time of O(n7) (GómezRodríguez et al., 2011). No previously defined class of trees sim</context>
<context position="32402" citStr="McDonald and Pereira, 2006" startWordPosition="5975" endWordPosition="5978">ing would be violated. For example, if t2 in Figure 8 were between C and said2, then the edge (t1, t2) would cross (say, said1), (said1, said2), and (C, said2), which do not all share an endpoint. An exploration of these linguistic connections may be an interesting avenue for further research. 6 Conclusions 1-Endpoint-Crossing trees characterize over 95% of structures found in natural language treebank, and can be parsed in only a factor of n more time than projective trees. The dynamic programming algorithm for projective trees (Eisner, 2000) has been extended to handle higher order factors (McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010), adding at most a factor of n to the edgebased running time; it would be interesting to extend the algorithm presented here to include higher order factors. 1-Endpoint-Crossing is a condition on edges, while properties such as well-nestedness or block degree are framed in terms of subtrees. Three edges will always suffice as a certificate of a 1-Endpoint-Crossing violation (two vertex-disjoint edges that both cross a third). In contrast, for a property like ill-nestedness, two nodes might have a least common ancestor arbitrarily far away, and so one mig</context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>R. McDonald and F. Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proceedings of EACL, pages 81–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>G Satta</author>
</authors>
<title>On the complexity of non-projective data-driven dependency parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of the 10th International Conference on Parsing Technologies,</booktitle>
<pages>121--132</pages>
<contexts>
<context position="1889" citStr="McDonald and Satta, 2007" startWordPosition="276" endWordPosition="279">trov, 2012; Zhang and McDonald, 2012) find the highest-scoring projective trees (in which no edges cross), despite the fact that a large proportion of natural language sentences are non-projective. Projective trees can be found in O(n3) time (Eisner, 2000), but cover only 63.6% of sentences in some natural language treebanks (Table 1). The class of directed spanning trees covers all treebank trees and can be parsed in O(n2) with edge-based features (McDonald et al., 2005), but it is NP-hard to find the maximum scoring such tree with grandparent or sibling features (McDonald and Pereira, 2006; McDonald and Satta, 2007). There are various existing definitions of mildly non-projective trees with better empirical coverage than projective trees that do not have the hardness of extensibility that spanning trees do. However, these have had parsing algorithms that are orders of magnitude slower than the projective case or the edgebased spanning tree case. For example, well-nested dependency trees with block degree 2 (Kuhlmann, 2013) cover at least 95.4% of natural language structures, but have a parsing time of O(n7) (GómezRodríguez et al., 2011). No previously defined class of trees simultaneously has high covera</context>
</contexts>
<marker>McDonald, Satta, 2007</marker>
<rawString>R. McDonald and G. Satta. 2007. On the complexity of non-projective data-driven dependency parsing. In Proceedings of the 10th International Conference on Parsing Technologies, pages 121–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
<author>K Ribarov</author>
<author>J Hajiˇc</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>523--530</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>McDonald, Pereira, Ribarov, Hajiˇc, 2005</marker>
<rawString>R. McDonald, F. Pereira, K. Ribarov, and J. Hajiˇc. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 523–530. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Pitler</author>
<author>S Kannan</author>
<author>M Marcus</author>
</authors>
<title>Dynamic programming for higher order parsing of gap-minding trees.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>478--488</pages>
<contexts>
<context position="6051" citStr="Pitler et al., 2012" startWordPosition="955" endWordPosition="958">g trees. Excluding these artificial root edges, the empirical coverage for Dutch rises to 12949 (97.0%). These edges have no effect on the coverage of well-nested trees with block degree at most 2, gap-minding trees, or projective trees. Figure 1: 1a is 1-Endpoint-Crossing, but is neither block degree 2 nor well-nested; 1b is gap-minding but not 2-planar. Definition 5. A tree is gap-minding if it is wellnested, has gap degree at most 1, and has gap inheritance degree 0. Gap inheritance degree 0 requires that there are no child nodes with descendants in more than one of their parent’s blocks. (Pitler et al., 2012) Gap-minding trees can be parsed in O(n5) (Pitler et al., 2012). They have slightly less empirical coverage, however: 90.4-97.7% (Table 1). Definition 6. A tree is projective if it has block degree 1 (gap degree 0). This definition has the least coverage (as low as 63.6% for Dutch), but can be parsed in O(n3) (Eisner, 2000). Definition 7. A tree is 2-planar if each edge can be drawn either above or below the sentence such that no edges cross (Gómez-Rodríguez and Nivre, 2010). Gómez-Rodríguez and Nivre (2010) presented a transition-based parser for 2-planar trees, but there is no known globally</context>
</contexts>
<marker>Pitler, Kannan, Marcus, 2012</marker>
<rawString>E. Pitler, S. Kannan, and M. Marcus. 2012. Dynamic programming for higher order parsing of gap-minding trees. In Proceedings of EMNLP, pages 478–488.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Ringenberg</author>
</authors>
<title>College geometry.</title>
<date>1967</date>
<publisher>Wiley.</publisher>
<contexts>
<context position="9640" citStr="Ringenberg, 1967" startWordPosition="1570" endWordPosition="1572">rossing trees in a similar fashion: Definition 9. An isolated interval [i, j] has no edges between the vertices in (i, j) and the vertices outside of [i, j]. An interval and one exterior vertex [i, j] U {x} is called an isolated crossing region if the following two conditions are satisfied: 1. There are no edges between the vertices E (i, j) and vertices E/ [i, j] U {x} 2. None of the edges between x and vertices E (i, j) are crossed by any edges with both endpoints E (i, j) 2This notation comes from an analogy to geometry: “A set of distinct, coplanar, concurrent lines is a pencil of lines” (Ringenberg, 1967, p. 221); concurrent lines all intersect at the same single point. Figure 2: An edge euv and Pt(euv) = p form two sets of isolated crossing regions (Lemma 1). 2a and 2b show p E/ (u, v); 2c and 2d show p E (u, v). Lemma 1. Consider any edge euv and Pt(euv) = p in a 1-Endpoint-Crossing forest F. Let l, r, and m denote the leftmost, rightmost, and middle point out of {u, v, p}, respectively. Then the three points u, v, and p define two isolated crossing regions: (1) [l, m] U {r}, and (2) [m, r] U {l}. Proof. First note that as p = Pt(euv), P(euv) is non-empty: there must be at least one edge be</context>
</contexts>
<marker>Ringenberg, 1967</marker>
<rawString>L.A. Ringenberg. 1967. College geometry. Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Rush</author>
<author>S Petrov</author>
</authors>
<title>Vine pruning for efficient multi-pass dependency parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<pages>498--507</pages>
<contexts>
<context position="1274" citStr="Rush and Petrov, 2012" startWordPosition="177" endWordPosition="180">erty can be found with an O(n4) parsing algorithm that recursively combines forests over intervals with one exterior point. 1-EndpointCrossing trees also have natural connections to linguistics and another class of graphs that has been studied in NLP. 1 Introduction Dependency parsing is one of the fundamental problems in natural language processing today, with applications such as machine translation (Ding and Palmer, 2005), information extraction (Culotta and Sorensen, 2004), and question answering (Cui et al., 2005). Most high-accuracy graph-based dependency parsers (Koo and Collins, 2010; Rush and Petrov, 2012; Zhang and McDonald, 2012) find the highest-scoring projective trees (in which no edges cross), despite the fact that a large proportion of natural language sentences are non-projective. Projective trees can be found in O(n3) time (Eisner, 2000), but cover only 63.6% of sentences in some natural language treebanks (Table 1). The class of directed spanning trees covers all treebank trees and can be parsed in O(n2) with edge-based features (McDonald et al., 2005), but it is NP-hard to find the maximum scoring such tree with grandparent or sibling features (McDonald and Pereira, 2006; McDonald a</context>
</contexts>
<marker>Rush, Petrov, 2012</marker>
<rawString>A. Rush and S. Petrov. 2012. Vine pruning for efficient multi-pass dependency parsing. In Proceedings of NAACL, pages 498–507.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>Evidence against the contextfreeness of natural language.</title>
<date>1985</date>
<journal>Linguistics and Philosophy,</journal>
<volume>8</volume>
<issue>3</issue>
<contexts>
<context position="29492" citStr="Shieber, 1985" startWordPosition="5498" endWordPosition="5499">uced by the vertices used in the cycle (by Lemma 3). That implies the existence of a cycle in the original graph, contradicting that the original graph was a tree. Since there are no odd cycles in the crossings graph, the crossings graph of edges is bipartite. Each side of the bipartite graph can be assigned to a page, such that no two edges on the same page cross. Therefore, the original graph was 2-planar. 5.2 Linguistics: Cross-serial Verb Constructions and Successive Cyclicity Cross-serial verb constructions were used to provide evidence for the “non-context-freeness” of natural language (Shieber, 1985). Cross-serial verb constructions with two verbs form 1-Endpoint-Crossing trees. Below is a cross-serial sentence from SwissGerman, from (1) in Shieber (1985): das mer em Hans es huus hälfed aastriiche that we HansDAT the houseACC helped paint The edges (that, helped), (helped, we), and (helped, Hans) are each only crossed by an edge with an endpoint at paint; the edge (paint, house) is only crossed by edges with an endpoint at helped. More generally, with a set of two cross serial verbs in a subordinate clause, each verb should suffice as the crossing point for all edges incident to the other</context>
</contexts>
<marker>Shieber, 1985</marker>
<rawString>S.M. Shieber. 1985. Evidence against the contextfreeness of natural language. Linguistics and Philosophy, 8(3):333–343.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zhang</author>
<author>R McDonald</author>
</authors>
<title>Generalized higherorder dependency parsing with cube pruning.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>320--331</pages>
<contexts>
<context position="1301" citStr="Zhang and McDonald, 2012" startWordPosition="181" endWordPosition="184">an O(n4) parsing algorithm that recursively combines forests over intervals with one exterior point. 1-EndpointCrossing trees also have natural connections to linguistics and another class of graphs that has been studied in NLP. 1 Introduction Dependency parsing is one of the fundamental problems in natural language processing today, with applications such as machine translation (Ding and Palmer, 2005), information extraction (Culotta and Sorensen, 2004), and question answering (Cui et al., 2005). Most high-accuracy graph-based dependency parsers (Koo and Collins, 2010; Rush and Petrov, 2012; Zhang and McDonald, 2012) find the highest-scoring projective trees (in which no edges cross), despite the fact that a large proportion of natural language sentences are non-projective. Projective trees can be found in O(n3) time (Eisner, 2000), but cover only 63.6% of sentences in some natural language treebanks (Table 1). The class of directed spanning trees covers all treebank trees and can be parsed in O(n2) with edge-based features (McDonald et al., 2005), but it is NP-hard to find the maximum scoring such tree with grandparent or sibling features (McDonald and Pereira, 2006; McDonald and Satta, 2007). There are </context>
</contexts>
<marker>Zhang, McDonald, 2012</marker>
<rawString>H. Zhang and R. McDonald. 2012. Generalized higherorder dependency parsing with cube pruning. In Proceedings of EMNLP, pages 320–331.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>