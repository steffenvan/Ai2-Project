<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.998237">
A Knowledge-Intensive Model for Prepositional Phrase Attachment
</title>
<author confidence="0.981655">
Ndapandula Nakashole
</author>
<affiliation confidence="0.980749">
Carnegie Mellon University
</affiliation>
<address confidence="0.829612">
5000 Forbes Avenue
Pittsburgh, PA, 15213
</address>
<email confidence="0.999169">
ndapa@cs.cmu.edu
</email>
<sectionHeader confidence="0.993903" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999852933333333">
Prepositional phrases (PPs) express cru-
cial information that knowledge base con-
struction methods need to extract. How-
ever, PPs are a major source of syntactic
ambiguity and still pose problems in pars-
ing. We present a method for resolving
ambiguities arising from PPs, making ex-
tensive use of semantic knowledge from
various resources. As training data, we use
both labeled and unlabeled data, utilizing
an expectation maximization algorithm for
parameter estimation. Experiments show
that our method yields improvements over
existing methods including a state of the
art dependency parser.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999522421052632">
Machine reading and information extraction (IE)
projects have produced large resources with many
millions of facts (Suchanek et al., 2007; Mitchell
et al., 2015). This wealth of knowledge creates
a positive feedback loop for automatic knowledge
base construction efforts: the accumulated knowl-
edge can be leveraged to improve machine read-
ing; in turn, improved reading methods can be
used to better extract knowledge expressed using
complex and potentially ambiguous language. For
example, prepositional phrases (PPs) express cru-
cial information that IE methods need to extract.
However, PPs are a major source of syntactic am-
biguity. In this paper, we propose to use semantic
knowledge to improve PP attachment disambigua-
tion. PPs such as “in”, “at”, and “for” express de-
tails about the where, when, and why of relations
and events. PPs also state attributes of nouns.
As an example, consider the following sen-
</bodyText>
<note confidence="0.7768655">
tences: S1.) Alice caught the butterfly with the
spots. S2.) Alice caught the butterfly with the net.
Tom M. Mitchell
Carnegie Mellon University
5000 Forbes Avenue
Pittsburgh, PA, 15213
</note>
<email confidence="0.987828">
tom.mitchell@cs.cmu.edu
</email>
<figureCaption confidence="0.9887725">
Figure 1: Parse trees where the prepositional
phrase (PP) attaches to the noun, and to the verb.
</figureCaption>
<table confidence="0.999054083333333">
Relations Noun-Noun binary relations
(Paris, located in, France)
(net, caught, butterfly)
Nouns Noun semantic categories
(butterfly, isA, animal)
Verbs Verb roles
caught(agent, patient, instrument)
Prepositions Preposition definitions
f(for)= used for, has purpose, ...
f(with)= has, contains, ...
Discourse Context
n0 ∈ {n0, v, n1, p, n2}
</table>
<tableCaption confidence="0.95294">
Table 1: Types of background knowledge used in
this paper to determine PP attachment.
</tableCaption>
<bodyText confidence="0.993451">
S1 and S2 are syntactically different, this is evi-
dent from their corresponding parse trees in Fig-
ure 1. Specifically, S1 and S2 differ in where their
PPs attach. In S1, the butterfly has spots and there-
fore the PP, “with the spots”, attaches to the noun.
For relation extraction, we obtain a binary relation
of the form: (Alice) caught (butterfly with spots).
However, in S2, the net is the instrument used for
catching and therefore the PP, “with the net”, at-
taches to the verb. For relation extraction, we get
a ternary extraction of the form: (Alice) caught
(butterfly) with (net).
The PP attachment problem is often defined as
follows: given a PP occurring within a sentence
where there are multiple possible attachment sites
</bodyText>
<figure confidence="0.997307882352941">
S1.) Noun attachment
S2.) Verb attachment
S
S
NP VP
VP
NP
Alice
VP NP
caught butterfly
PP
with
spots
caught butterfly with
net
Alice
VP NP PP
</figure>
<page confidence="0.985751">
365
</page>
<note confidence="0.984842">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 365–375,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<figure confidence="0.985645071428571">
Noun attachments
0.9 Verb attachments
0.8
0.7
0.6
0.5
0.4
1
0.75
0.5
0.25
WITH AT FROM FOR AS IN
ON
0
</figure>
<figureCaption confidence="0.998769">
Figure 2: Dependency parser PP attachment accu-
</figureCaption>
<bodyText confidence="0.983403695652174">
racy for various frequent prepositions.
for the PP, choose the most plausible attachment
site. In the literature, prior work going as far back
as (Brill and Resnik, 1994; Ratnaparkhi et al.,
1994; Collins and Brooks, 1995) has focused on
the language pattern that causes most PP ambigui-
ties, which is the 4-word sequence: {v, n1, p, n2}
(e.g., {caught, butterfly, with, spots}). The task is
to determine if the prepositional phrase (p, n2) at-
taches to the verb v or to the first noun n1. Follow-
ing common practice, we focus on PPs occurring
as {v, n1, p, n2} quadruples — we shall refer to
these as PP quads.
The approach we present here differs from prior
work in two main ways. First, we make ex-
tensive use of semantic knowledge about nouns,
verbs, prepositions, pairs of nouns, and the dis-
course context in which a PP quad occurs. Table 1
summarizes the types of knowledge we considered
in our work. Second, in training our model, we
rely on both labeled and unlabeled data, employ-
ing an expectation maximization (EM) algorithm
(Dempster et al., 1977).
</bodyText>
<listItem confidence="0.90665175">
Contributions. In summary, our main contribu-
tions are:
1) Semantic Knowledge: Previous methods
largely rely on corpus statistics. Our approach
draws upon diverse sources of background knowl-
edge, leading to performance improvements.
2) Unlabeled Data: In addition to training on la-
beled data, we also make use of a large amount of
unlabeled data. This enhances our method’s abil-
ity to generalize to diverse data sets.
3) Datasets: In addition to the standard Wall
Street Journal corpus (WSJ) (Ratnaparkhi et al.,
</listItem>
<bodyText confidence="0.5770855">
1994), we labeled two new datasets for testing
purposes, one from Wikipedia (WKP), and an-
other from the New York Times Corpus (NYTC).
We make these datasets freely available for fu-
</bodyText>
<note confidence="0.295154">
IN FROM WITH FOR OF As AT ON
</note>
<figureCaption confidence="0.760913333333333">
Figure 3: Noun vs. verb attachment proportions
for frequent prepositions in the labeled NYTC
dataset.
</figureCaption>
<bodyText confidence="0.979007">
ture research. In addition, we have applied our
model to over 4 million 5-tuples of the form
{n0, v, n1, p, n2}, and we also make this dataset
available1 for research into ternary relation extrac-
tion beyond spatial and temporal scoping.
2 State of the Art
To quantitatively assess existing tools, we ana-
lyzed performance of the widely used Stanford
parser2 as of 2014, and the established baseline
algorithm (Collins and Brooks, 1995), which has
stood the test of time. We first manually labeled
PP quads from the NYTC dataset, then prepended
the noun phrase appearing before the quad, ef-
fectively creating sentences made up of 5 lexi-
cal items (n0 v n1 p n2). We then applied the
Stanford parser, obtaining the results summarized
in Figure 2. The parser performs well on some
prepositions, for example, “of”, which tends to oc-
cur with noun attaching PPs as can be seen in Fig-
ure 3. However, for prepositions with an even dis-
tribution over verb and noun attachments, such as
“on”, precision is as low as 50%. The Collins
baseline achieves 84% accuracy on the bench-
mark Wall Street Journal PP dataset. However,
drawing a distinction in the precision of different
prepositions provides useful insights on its per-
formance. We re-implemented this baseline and
found that when we remove the trivial preposi-
tion, “of”, whose PPs are by default attached to
the noun by this baseline, precision drops to 78%.
This analysis suggests there is substantial room for
improvement.
</bodyText>
<footnote confidence="0.9999755">
1http://rtw.ml.cmu.edu/resources/ppa
2http://nlp.stanford.edu:8080/parser/
</footnote>
<page confidence="0.99904">
366
</page>
<sectionHeader confidence="0.999912" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.998458142857143">
Statistics-based Methods. Prominent prior meth-
ods learn to perform PP attachment based on
corpus co-occurrence statistics, gathered either
from manually annotated training data (Collins
and Brooks, 1995; Brill and Resnik, 1994) or
from automatically acquired training data that may
be noisy (Ratnaparkhi, 1998; Pantel and Lin,
2000). These models collect statistics on how of-
ten a given quadruple, {v, n1, p, n2}, occurs in the
training data as a verb attachment as opposed to a
noun attachment. The issue with this approach is
sparsity, that is, many quadruples occuring in the
test data might not have been seen in the training
data. Smoothing techniques are often employed
to overcome sparsity. For example, (Collins and
Brooks, 1995) proposed a back-off model that uses
subsets of the words in the quadruple, by also
keeping frequency counts of triples, pairs and sin-
gle words. Another approach to overcoming spar-
sity has been to use WordNet (Fellbaum, 1998)
classes, by replacing nouns with their WordNet
classes (Stetina and Nagao, 1997; Toutanova et
al., 2004) to obtain less sparse corpus statistics.
Corpus-derived clusters of similar nouns and verbs
have also been used (Pantel and Lin, 2000).
Hindle and Rooth proposed a lexical associa-
tion approach based on how words are associated
with each other (Hindle and Rooth, 1993). Lexi-
cal preference is used by computing co-occurrence
frequencies (lexical associations) of verbs and
nouns, with prepositions. In this manner, they
would discover that, for example, the verb “send”
is highly associated with the preposition from, in-
dicating that in this case, the PP is likely to be a
verb attachment.
Structure-based Methods. These methods are
based on high-level observations that are then gen-
eralized into heuristics for PP attachment deci-
sions. (Kimball, 1988) proposed a right associa-
tion method, whose premise is that a word tends
to attach to another word immediately to its right.
(Frazier, 1978) introduced a minimal attachment
method, which posits that words attach to an ex-
isting non-terminal word using the fewest addi-
tional syntactic nodes. While simple, in practice
these methods have been found to perform poorly
(Whittemore et al., 1990).
Rule-based Methods. (Brill and Resnik, 1994)
proposed methods that learn a set of transforma-
tion rules from a corpus. The rules can be too spe-
cific to have broad applicability, resulting in low
recall. To address low recall, knowledge about
nouns, as found in WordNet, is used to replace cer-
tain words in rules with their WordNet classes.
Parser Correction Methods. The quadruples for-
mulation of the PP problem can be seen as a
simplified setting. This is because, with quadru-
ples, there is no need to deal with complex sen-
tences but only well-defined quadruples of the
form {v, n1, p, n2}. Thus in the quadruples set-
ting, there are only two possible attachment sites
for the PP, the v and n1. An alternative setting is
to work in the context of full sentences. In this
setting the problem is cast as a dependency parser
correction problem (Atterer and Sch¨utze, 2007;
Agirre et al., 2008; Anguiano and Candito, 2011).
That is, given a dependency parse of a sentence,
with potentially incorrect PP attachments, rectify
it such that the prepositional phrases attach to the
correct sites. Unlike our approach, these methods
do not take semantic knowledge into account.
Sense Disambiguation. In addition to prior work
on prepositional phrase attachment, a highly re-
lated problem is preposition sense disambiguation
(Hovy et al., 2011; Srikumar and Roth, 2013).
Even a syntactically correctly attached PP can still
be semantically ambiguous with respect to ques-
tions of machine reading such as where, when, and
why. Therefore, when extracting information from
prepositions, the problem of preposition sense dis-
ambiguation (semantics) has to be addressed in ad-
dition to prepositional phrase attachment disam-
biguation (syntax). In this paper, our focus is on
the latter.
</bodyText>
<sectionHeader confidence="0.998046" genericHeader="method">
4 Methodology
</sectionHeader>
<bodyText confidence="0.999985428571429">
Our approach consists of first generating features
from background knowledge and then training a
model to learn with these features. The types of
features considered in our experiments are sum-
marized in Table 2. The choice of features was
motivated by our empirically driven characteriza-
tion of the problem as follows:
</bodyText>
<construct confidence="0.750188333333333">
(Verb attach) −→ v (has-slot-filler) n2
(Noun attach a.) −→ n1 (described-by) n2
(Noun attach b.) −→ n2 (described-by) n1
</construct>
<page confidence="0.989757">
367
</page>
<table confidence="0.99988956">
Feature Type # Feature Example
Noun-Noun Binary Relations Source: SVOs
svo(n2, v, n1) For q1; (net, caught, butterfly)
Vi : Isvio; svo(n1, vi, n2) For q2; (butterfly, has, spots)
For q2; (butterfly, can see, spots)
Noun Semantic Categories Source: T
Vti E T ; isA(n1, ti) For q1 isA(butterlfy, animal)
Vti E T ; isA(n2, ti) For q2 isA(net, device)
Verb Role Fillers Source: VerbNet
hasRole(n2, ri) For q1; (net, instrument)
Preposition Relational Source: M
Definitions def(prep, vi) Vi :
Isvio; vi E M n For q2; def(with, has)
svo(n1, vi, n2)
Discourse Features Source: Sentence(s), T
Vti E T ; isA(n0, ti) n0 E {n0, v, n1, p, n2}
Lexical Features Source: PP quads For q1;
(v, n1, p, n2) (caught, butterfly, with, net)
(v, n1, p) (caught, butterfly, with)
(v, p, n2) (caught, with, net)
(n1, p, n2) (butterfly, with, net)
(v, p) (caught, with)
(n1, p) (butterfly, with)
(p, n2) (with, net)
(p) (with)
</table>
<tableCaption confidence="0.811064">
Table 2: Types of features considered in our experiments. All features have values of 1 or 0.
The PP quads used as running examples are: q1 = {caught, butterfly, with, net} : V , q2 =
{caught, butterfly, with, spots} : N.
</tableCaption>
<bodyText confidence="0.999966909090909">
That is, we found that for verb-attaching PPs,
n2 is usually a role filler for the verb, e.g., the net
fills the role of an instrument for the verb catch.
On the other hand, for noun-attaching PPs, one
noun describes or elaborates on the other. In par-
ticular, we found two kinds of noun attachments.
For the first kind of noun attachment, the second
noun n2 describes the first noun n1, for exam-
ple n2 might be an attribute or property of n1,
as in the spots(n2) are an attribute of the butter-
fly (n1). And for the second kind of noun attach-
ment, the first noun n1 describes the second noun
n2, as in the PP quad {expect, decline, in, rates},
where the PP “in rates”, attaches to the noun. The
decline:n1 that is expected:v is in the rates:n2. We
sampled 50 PP quads from the WSJ dataset and
found that every labeling could be explained using
our characterization. We make this labeling avail-
able with the rest of the datasets.
We next describe in more detail how each type
of feature is derived from the background knowl-
edge in Table 1.
</bodyText>
<subsectionHeader confidence="0.99652">
4.1 Feature Generation
</subsectionHeader>
<bodyText confidence="0.999999">
We generate boolean-valued features for all the
feature types we describe in this section.
</bodyText>
<subsectionHeader confidence="0.552426">
4.1.1 Noun-Noun Binary Relations
</subsectionHeader>
<bodyText confidence="0.999977083333333">
The noun-noun binary relation features, F1-2
in Table 2, are boolean features svo(n1, vi, n2)
(where vi is any verb) and svo(n2, v, n1) (where
v is the verb in the PP quad, and the roles of
n2 and n1 are reversed). These features de-
scribe diverse semantic relations between pairs of
nouns (e.g., butterfly-has-spots, clapton-played-
guitar). To obtain this type of knowledge, we
dependency parsed all sentences in the 500 mil-
lion English web pages of the ClueWeb09 corpus,
then extracted subject-verb-object (SVO) triples
from these parses, along with the frequency of
</bodyText>
<page confidence="0.993588">
368
</page>
<bodyText confidence="0.999718785714286">
each SVO triple in the corpus. The value of
any given feature svo(n1, vi, n2) is defined to be
1 if that SVO triple was found at least 3 times
in these SVO triples, and 0 otherwise. To see
why these relations are relevant, let us suppose
that we have the knowledge that butterfly-has-
spots, svo(n1, vi, n2). From this, we can infer
that the PP in {caught, butterfly, with, spots}
is likely to attach to the noun. Similarly, suppose
we know that net-caught-butterfly, svo(n2, v, n1).
The fact that a net can be used to catch a but-
terfly can be used to predict that the PP in
{caught, butterfly, with, net} is likely to attach
to the verb.
</bodyText>
<subsectionHeader confidence="0.647424">
4.1.2 Noun Semantic Categories
</subsectionHeader>
<bodyText confidence="0.999940461538462">
Noun semantic type features, F3-4, are boolean
features isA(n1, ti) and isA(n2, ti) where ti is a
noun category in a noun categorization scheme T
such as WordNet classes. Knowledge about se-
mantic types of nouns, for example that a butter-
fly is an animal, enables extrapolating predictions
to other PP quads that contain nouns of the same
type. We ran experiments with several noun cat-
egorizations including WordNet classes, knowl-
edge base ontological types, and an unsupervised
noun categorization produced by clustering nouns
based on the verbs and adjectives with which they
co-occur (distributional similarity).
</bodyText>
<subsectionHeader confidence="0.916641">
4.1.3 Verb Role Fillers
</subsectionHeader>
<bodyText confidence="0.999869">
The verb role feature, F5, is a boolean fea-
ture hasRole(n2, ri) where ri is a role that
n2 can fulfill for the verb v in the PP quad,
according to background knowledge. Notice
that if n2 fills a role for the verb, then the
PP is a verb attachment. Consider the quad
{caught, butterfly, with, net}, if we know that
a net can play the role of an instrument for the
verb catch, this suggests a likely verb attachment.
We obtained background knowledge of verbs and
their possible roles from the VerbNet lexical re-
source (Kipper et al., 2008). From VerbNet we
obtained 2,573 labeled sentences containing PP
quads (verbs in the same VerbNet group are con-
sidered synonymous), and the labeled semantic
roles filled by the second noun n2 in the PP quad.
We use these example sentences to label similar
PP quads, where similarity of PP quads is defined
by verbs from the same VerbNet group.
</bodyText>
<subsubsectionHeader confidence="0.497805">
4.1.4 Preposition Definitions
</subsubsectionHeader>
<bodyText confidence="0.999544954545455">
The preposition definition feature, F6, is a
boolean feature def(prep, vi) = 1 if Ivi E
M n svo(n1, vi, n2) = 1, where M is a def-
inition mapping of prepositions to verb phrases.
This mapping defines prepositions, using verbs
in our ClueWeb09 derived SVO corpus, in or-
der to capture their senses using verbs; it con-
tains definitions such as def(with, *) = contains,
accompanied by, ... . If “with” is used in the
sense of “contains” , then the PP is a likely
noun attachment, as in n1 contains n2 in the
quad ate, cookies, with, cranberries. However,
if “with” is used in the sense of “accompanied
by”, then the PP is a likely verb attachment, as
in the quad visted, Paris, with, Sue. To obtain
the mapping, we took the labeled PP quads (WSJ,
(Ratnaparkhi et al., 1994)) and computed a ranked
list of verbs from SVOs, that appear frequently
between pairs of nouns for a given preposition.
Other sample mappings are: def(for,*)= used for,
def(in,*)= located in. Notice that this feature F6
is a selective, more targeted version of F2.
</bodyText>
<subsectionHeader confidence="0.766896">
4.1.5 Discourse and Lexical Features
</subsectionHeader>
<bodyText confidence="0.999888222222222">
The discourse feature, F7, is a boolean feature
isA(n0, ti), for each noun category ti found in a
noun category ontology T such as WordNet se-
mantic types. The context of the PP quad can
contain relevant information for attachment deci-
sions. We take into account the noun preceding
a PP quad, in particular, its semantic type. This
in effect makes the PP quad into a PP 5-tuple:
{n0, v, n1, p, n2}, where the n0 provides addi-
tional context.
Finally, we use lexical features in the form of
PP quads, features F8-15. To overcome sparsity
of occurrences of PP quads, we also use counts
of shorter sub-sequences, including triples, pairs
and singles. We only use sub-sequences that con-
tain the preposition, as the preposition has been
found to be highly crucial in PP attachment deci-
sions (Collins and Brooks, 1995).
</bodyText>
<subsectionHeader confidence="0.978746">
4.2 Disambiguation Algorithm
</subsectionHeader>
<bodyText confidence="0.970319">
We use the described features to train a model
for making PP attachment decisions. Our goal
is to compute P(y|x), the probability that the PP
(p, n2) in the tuple {v, n1, p, n2} attaches to the
verb (v) , y = 1 or to the noun(n1), y = 0, given
</bodyText>
<page confidence="0.994957">
369
</page>
<bodyText confidence="0.999477888888889">
a feature vector x describing that tuple. As input to
training the model, we are given a collection of PP
quads, D where di E D : di = {v, n1, p, n2}. A
small subset, Dl C D is labeled data, thus for each
di E Dl we know the corresponding yi. The rest
of the quads, Du, are unlabeled, hence their corre-
sponding yis are unknown. From each PP quad di,
we extract a feature vector xi according to the fea-
ture generation process discussed in Section 4.1.
</bodyText>
<subsectionHeader confidence="0.839555">
4.2.1 Model
</subsectionHeader>
<bodyText confidence="0.999993">
To model P(y|x), there a various possibilities.
One could use a generative model (e.g., Naive
Bayes) or a discriminative model ( e.g., logistic re-
gression). In our experiments we used both kinds
of models, but found the discriminative model per-
formed better. Therefore, we present details only
for our discriminative model. We use the logistic
</bodyText>
<equation confidence="0.94126">
e~θx
~θ) = 1+e~θx, where θ~ is a vec-
</equation>
<bodyText confidence="0.9997848">
tor of model parameters. To estimate these pa-
rameters, we could use the labeled data as training
data and use standard gradient descent to minimize
the logistic regression cost function. However, we
also leverage the unlabeled data.
</bodyText>
<subsubsectionHeader confidence="0.858201">
4.2.2 Parameter Estimation
</subsubsectionHeader>
<bodyText confidence="0.999795625">
To estimate model parameters based on both la-
beled and unlabeled data, we use an Expecta-
tion Maximization (EM) algorithm. EM estimates
model parameters that maximize the expected log
likelihood of the full (observed and unobserved)
data. Since we are using a discriminative model,
our likelihood function is a conditional likelihood
function:
</bodyText>
<equation confidence="0.996142166666667">
N
G(θ) = ln P(yi|xi)
i=1
N
yiθTxi − ln (1 + exp(θTxi)) (1)
i=1
</equation>
<bodyText confidence="0.998217153846154">
where i indexes over the N training examples.
The EM algorithm produces parameter esti-
mates that correspond to a local maximum in
the expected log likelihood of the data under
the posterior distribution of the labels, given by:
arg max Ep(y|x,θ)[ln P(y|x, θ)]. In the E-step, we
θ
use the current parameters θt−1 to compute the
posterior distribution over the y labels, give by
P(y|x, θt−1). We then use this posterior distri-
bution to find the expectation of the log of the
complete-data conditional likelihood, this expec-
tation is given by 2(θ, θt−1), defined as:
</bodyText>
<equation confidence="0.761351625">
N
2(θ, θt−1) = Eθt−1[ln P(y|x, θ)] (2)
i=1
In the M-step, a new estimate θt is then pro-
duced, by maximizing this Q function with respect
to θ:
(3)
θ
</equation>
<bodyText confidence="0.86840425">
EM iteratively computes parameters
θ0, θ1, ...θt, using the above update rule at
each iteration t, halting when there is no further
improvement in the value of the Q function. Our
algorithm is summarized in Algorithm 1. The
M-step solution for θt is obtained using gradient
ascent to maximize the Q function.
Algorithm 1 The EM algorithm for PP attachment
</bodyText>
<equation confidence="0.9301285">
Input: X, D = Dl U Du
Output: θT
for t = 1 ... T do
E-Step:
Compute p(y|xi, θt−1)
xi : di E Du; p(y|xi,
xi : di E Dl; p(y|xi) = 1 if y = yi, else 0
M-Step:
Compute new parameters, θt
θt = arg max 2(θ, θt−1)
θ
p(y|xi, θt−1)x
(yθTxi − ln(1 + exp(θTxi)))
if convergence(G(θ), G(θt−1)) then
break
end if
end for
return θT
</equation>
<sectionHeader confidence="0.998148" genericHeader="method">
5 Experimental Evaluation
</sectionHeader>
<bodyText confidence="0.99998375">
We evaluated our method on several datasets con-
taining PP quads of the form {v, n1, p, n2}. The
task is to predict if the PP (p, n2) attaches to the
verb v or to the first noun n1.
</bodyText>
<subsectionHeader confidence="0.934506">
5.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.998479">
Datasets. Table 3 shows the datasets used in our
experiments. As labeled training data, we used the
</bodyText>
<equation confidence="0.994795875">
function: P(y|x,
θt = arg max 2(θ, θt−1)
~θx
~θ) = e
~θx
1+ e
2(θ, θt−1) = N �
i=1 yE10,11
</equation>
<page confidence="0.994319">
370
</page>
<table confidence="0.999148">
DataSet # Training quads # Test quads
Labeled data
WSJ 20,801 3,097
NYTC 0 293
WKP 0 381
Unlabeled data
WKP 100,000 4,473,072
</table>
<tableCaption confidence="0.9822055">
Table 3: Training and test datasets used in our ex-
periments.
</tableCaption>
<table confidence="0.999870727272727">
PPAD PPAD- Coll- Stan-
NB ins ford
WKP 0.793 0.740 0.727 0.701
WKP 0.759 0.698 0.683 0.652
\of
NYTC 0.843 0.792 0.809 0.679
NYTC 0.815 0.754 0.774 0.621
\of
WSJ 0.843 0.816 0.841 N\A
WSJ 0.779 0.741 0.778 N\A
\of
</table>
<tableCaption confidence="0.999468">
Table 4: PPAD vs. baselines.
</tableCaption>
<bodyText confidence="0.98900788">
Wall Street Journal (WSJ) dataset. For the unla-
beled training data, we extracted PP quads from
Wikipedia (WKP) and randomly selected 100, 000
which we found to be a sufficient amount of un-
labeled data. The largest labeled test dataset is
WSJ but it is also made up of a large fraction, of
“of” PP quads, 30% , which trivially attach to the
noun, as already seen in Figure 3. The New York
Times (NYTC) and Wikipedia (WKP) datasets are
smaller but contain fewer proportions of “of” PP
quads, 15%, and 14%, respectively. Addition-
ally, we applied our model to over 4 million un-
labeled 5-tuples from Wikipedia. We make this
data available for download, along with our man-
ually labeled NYTC and WKP datasets. For the
WKP &amp; NYTC corpora, each quad has a preced-
ing noun, n0, as context, resulting in PP 5-tuples
of the form: {n0, v, n1, p, n2}. The WSJ dataset
was only available to us in the form of PP quads
with no other sentence information.
Methods Under Comparison. 1) PPAD (Prepo-
sitional Phrase Attachment Disambiguator) is our
proposed method. It uses diverse types of seman-
tic knowledge, a mixture of labeled and unlabeled
data for training data, a logistic regression classi-
</bodyText>
<figure confidence="0.943525">
PPAD - WordNet Types PPAD - KB Types
PPAD - Unsupervised Types PPAD - WordNet Verbs
PPAD - Naive Bayes Collins Baseline
Stanford Parser
0.82
0.74
0.66
0.58
0.5
WKP WKP\of NYTC NYTC\of WSJ WSJ\of
</figure>
<figureCaption confidence="0.999901">
Figure 4: PPAD variations vs. baselines.
</figureCaption>
<bodyText confidence="0.99997675">
fier, and expectation maximization (EM) for pa-
rameter estimation 2) Collins is the established
baseline among PP attachment algorithms (Collins
and Brooks, 1995). 3) Stanford Parser is a state-
of-the-art dependency parser, the 2014 online ver-
sion. 4) PPAD Naive Bayes(NB) is the same as
PPAD but uses a generative model, as opposed to
the discriminative model used in PPAD.
</bodyText>
<subsectionHeader confidence="0.998335">
5.2 PPAD vs. Baselines
</subsectionHeader>
<bodyText confidence="0.99984048">
Comparison results of our method to the three
baselines are shown in Table 4. For each dataset,
we also show results when the “of” quads are re-
moved, shown as “WKP\of”, “NYTC\of”, and
“WSJ\of”. Our method yields improvements over
the baselines. Improvements are especially sig-
nificant on the datasets for which no labeled data
was available (NYTC and WKP). On WKP, our
method is 7% and 9% ahead of the Collins base-
line and the Stanford parser, respectively. On
NYTC, our method is 4% and 6% ahead of the
Collins baseline and the Stanford parser, respec-
tively. On WSJ, which is the source of the labeled
data, our method is not significantly better than
the Collins baseline. We could not evaluate the
Stanford parser on the WSJ dataset. The parser re-
quires well-formed sentences which we could not
generate from the WSJ dataset as it was only avail-
able to us in the form of PP quads with no other
sentence information. For the same reason, we
could not generate discourse features,F7, for the
WSJ PP quads. For the NYTC and WKP datasets,
we generated well-formed short sentences con-
taining only the PP quad and the noun preceding
it.
</bodyText>
<page confidence="0.745593">
0.9
371
</page>
<table confidence="0.999369142857143">
Feature Type Precision Recall F1
Noun-Noun Binary Relations (F1-2) low high low
Noun Semantic Categories (F3-4) high high high
Verb Role Fillers (F5) high low low
Preposition Definitions (F6) low low low
Discourse Features (F7) high low high
Lexical Features (F8-15) high high high
</table>
<tableCaption confidence="0.999732">
Table 5: An approximate characterization of feature knowledge sources in terms of precision/recall/F1
</tableCaption>
<subsectionHeader confidence="0.99924">
5.3 Feature Analysis
</subsectionHeader>
<bodyText confidence="0.999629571428571">
We found that features F2 and F6 did not im-
prove performance, therefore we excluded them
from the final model, PPAD. This means that bi-
nary noun-noun relations were not useful when
used permissively, feature F2, but when used se-
lectively, feature F1, we found them to be useful.
Our attempt at mapping prepositions to verb def-
initions produced some noisy mappings, resulting
in feature F6 producing mixed results. To ana-
lyze the impact of the unlabeled data, we inspected
the features and their weights as produced by the
PPAD model. From the unlabeled data, new lex-
ical features were discovered that were not in the
original labeled data. Some sample new features
with high weights for verb attachments are: (per-
form,song,for,*), (lose,*,by,*), (buy,property,in,*).
And for noun attachments: (*, conference, on,
*),
(obtain, degree, in, *), (abolish, taxes, on, *).
We evaluated several variations of PPAD, the
results are shown in Figure 4. For “PPAD-
WordNet Verbs”, we expanded the data by replac-
ing verbs in PP quads with synonymous WordNet
verbs, ignoring verb senses. This resulted in more
instances of features F1, F8-10, &amp; F12.
We also used different types of noun categoriza-
tions: WordNet classes, semantic types from the
NELL knowledge base (Mitchell et al., 2015) and
unsupervised types. The KB types and the unsu-
pervised types did not perform well, possibly due
to the noise found in these categorizations. Word-
Net classes showed the best results, hence they
were used in the final PPAD model for features
F3-4 &amp; F7. In Section 5.1, PPAD corresponds to
the best model.
</bodyText>
<subsectionHeader confidence="0.896534">
5.4 Discussion: The F1 Score of Knowledge
</subsectionHeader>
<bodyText confidence="0.999982534883721">
Why did we not reach 100% accuracy? Should re-
lational knowledge not be providing a much big-
ger performance boost than we have seen in the re-
sults? To answer these questions, we characterize
our features in terms precision and recall, and F1
measure of their knowledge sources in Table 5. A
low recall feature means that the feature does not
fire on many examples, the feature’s knowledge
source suffers from low coverage. A low preci-
sion feature means that when it fires, the feature
could be incorrect, the feature’s knowledge source
contains a lot of errors.
From Table 5, the noun-noun binary relation
features (F1 − 2) have low precision, but high
recall. This is because the SVO data, extracted
from the ClueWeb09 corpus, that we used as our
relational knowledge source is very noisy but it is
high coverage. The low precision of the SVO data
causes these features to be detrimental to perfor-
mance. Notice that when we used a filtered ver-
sion of the data, in feature F2, the data was no
longer detrimental to performance. However, the
F2 feature is low recall, and therefore it’s impact
on performance is also limited. The noun seman-
tic category features (F3−4) have high recall and
precision, hence it to be expected that their im-
pact on performance is significant. The verb role
filler features (F5), obtained from VerbNet have
high precision but low recall, hence their marginal
impact on performance is also to be expected. The
preposition definition features (F6) poor precision
made them unusable. The discourse features (F7)
are based noun semantic types and lexical features
(F8 −15), both of which have high recall and pre-
cision, hence they useful impact on performance.
In summary, low precision in knowledge is
detrimental to performance. In order for knowl-
edge to make even more significant contributions
to language understanding, high precision, high
recall knowledge sources are required for all fea-
tures types. Success in ongoing efforts in knowl-
edge base construction projects, will make perfor-
mance of our algorithm better.
</bodyText>
<page confidence="0.993776">
372
</page>
<table confidence="0.9985132">
Relation Prep. Attachment accuracy Example(s)
acquired from 99.97 BNY Mellon acquired Insight from Lloyds.
hasSpouse in 91.54 David married Victoria in Ireland.
worksFor as 99.98 Shubert joined CNN as reporter.
playsInstrument with 98.40 Kushner played guitar with rock band Weezer.
</table>
<tableCaption confidence="0.98762">
Table 6: Binary relations extended to ternary relations by mapping to verb-preposition pairs in PP 5-
tuples. PPAD predicted verb attachments with accuracy &gt;90% in all relations.
</tableCaption>
<subsectionHeader confidence="0.989957">
5.5 Application to Ternary Relations
</subsectionHeader>
<bodyText confidence="0.999975145833334">
Through the application of ternary relation extrac-
tion, we further tested PPAD’s PP disambiguation
accuracy and illustrated its usefulness for knowl-
edge base population. Recall that a PP 5-tuple of
the form {n0, v, n1, p, n2}, whose enclosed PP at-
taches to the verb v, denotes a ternary relation with
arguments n0, n1, &amp; n2. Therefore, we can extract
a ternary relation from every 5-tuple for which our
method predicts a verb attachment. If we have a
mapping between verbs and binary relations from
a knowledge base (KB), we can extend KB rela-
tions to ternary relations by augmenting the KB
relations with a third argument n2.
We considered four KB binary re-
lations and their instances such as
worksFor(TimCook, Apple), from the NELL
KB. We then took the collection of 4 million
5-tuples that we extracted from Wikipedia. We
mapped verbs in 5-tuples to KB relations, based
on significant overlaps in the instances of the KB
relations, noun pairs such as (TimCook, Apple)
with the n0, n1 pairs in the Wikipedia PP 5-tuple
collection. We found that, for example, instances
of the noun-noun KB relation “worksFor” match
n0, n1 pairs in tuples where v = joined and
p = as , with n2 referring to the job title. Other
binary relations extended are: “hasSpouse” ex-
tended by “in” with wedding location, “acquired”
extended by “from” with the seller of the company
being acquired. Examples are shown in Table
6. In all these mappings, the proportion of verb
attachments in the corresponding PP quads is
significantly high ( &gt; 90%). PPAD is overwhelm-
ing making the right attachment decisions in this
setting.
Efforts in temporal and spatial relation extrac-
tion have shown that higher N-ary relation extrac-
tion is challenging. Since prepositions specify de-
tails that transform binary relations to higher N-
ary relations, our method can be used to read infor-
mation that can augment binary relations already
in KBs. As future work, we would like to incor-
porate our method into a pipeline for reading be-
yond binary relations. One possible direction is
to read details about the where,why, who of events
and relations, effectively moving from extracting
only binary relations to reading at a more general
level.
</bodyText>
<sectionHeader confidence="0.999561" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999982631578948">
We have presented a knowledge-intensive ap-
proach to prepositional phrase (PP) attachment
disambiguation, which is a type of syntactic ambi-
guity. Our method incorporates knowledge about
verbs, nouns, discourse, and noun-noun binary re-
lations. We trained a model using labeled data and
unlabeled data, making use of expectation max-
imization for parameter estimation. Our method
can be seen as an example of tapping into a pos-
itive feedback loop for machine reading, which
has only become possible in recent years due to
the progress made by information extraction and
knowledge base construction techniques. That
is, using background knowledge from existing re-
sources to read better in order to further populate
knowledge bases with otherwise difficult to extract
knowledge. As future work, we would like to use
our method to extract more than just binary rela-
tions.
</bodyText>
<sectionHeader confidence="0.997486" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99987425">
We thank Shashank Srivastava and members of the
NELL team at CMU for helpful comments. This
research was supported by DARPA under contract
number FA8750-13-2-0005.
</bodyText>
<page confidence="0.998859">
373
</page>
<sectionHeader confidence="0.99009" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999583122641509">
Eneko Agirre, Timothy Baldwin, and David Martinez.
2008. Improving parsing and PP attachment perfor-
mance with sense information. In Proceedings of
ACL-08: HLT, pages 317–325.
Gerry Altmann and Mark Steedman. 1988. Interac-
tion with context during human sentence processing.
Cognition, 30:191–238.
Enrique Henestroza Anguiano and Marie Candito.
2011. Parse correction with specialized models for
difficult attachment types. In Proceedings of the
2011 Conference on Empirical Methods in Natural
Language Processing, EMNLP, pages 1222–1233.
Michaela Atterer and Hinrich Sch¨utze. 2007. Preposi-
tional phrase attachment without oracles. Computa-
tional Linguistics, 33(4):469–476.
S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens
Lehmann, Richard Cyganiak, and Zachary G. Ives.
2007. Dbpedia: A nucleus for a web of open data.
In The Semantic Web, 6th International Semantic
Web Conference, 2nd Asian Semantic Web Confer-
ence, ISWC 2007 + ASWC 2007, Busan, Korea,
November 11-15, 2007., pages 722–735.
Michele Banko, Michael J Cafarella, Stephen Soder-
land, Matthew Broadhead, and Oren Etzioni. 2007.
Open information extraction for the web. In IJCAI,
volume 7, pages 2670–2676.
Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim
Sturge, and Jamie Taylor. 2008. Freebase: A col-
laboratively created graph database for structuring
human knowledge. In Proceedings of the 2008 ACM
SIGMOD International Conference on Management
of Data, SIGMOD ’08, pages 1247–1250.
Eric Brill and Philip Resnik. 1994. A rule-based
approach to prepositional phrase attachment disam-
biguation. In 15th International Conference on
Computational Linguistics, COLING, pages 1198–
1204.
Andrew Carlson, Justin Betteridge, Richard C. Wang,
Estevam R. Hruschka, Jr., and Tom M. Mitchell.
2010. Coupled semi-supervised learning for infor-
mation extraction. In Proceedings of the Third ACM
International Conference on Web Search and Data
Mining, WSDM ’10, pages 101–110.
Michael Collins and James Brooks. 1995. Prepo-
sitional phrase attachment through a backed-off
model. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, pages
27–38.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses.
In Proceedings of the International Conference on
Language Recources and Evaluation (LREC, pages
449–454.
Luciano Del Corro and Rainer Gemulla. 2013.
Clausie: Clause-based open information extraction.
In Proceedings of the 22Nd International Confer-
ence on World Wide Web, WWW ’13, pages 355–
366.
A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977.
Maximum likelihood from incomplete data via the
em algorithm. Journal of the Royal Statistical Soci-
ety, Series B, 39(1):1–38.
Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011a. Identifying relations for open information
extraction. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP ’11, pages 1535–1545.
Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011b. Identifying relations for open information
extraction. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing, pages 1535–1545. Association for Computa-
tional Linguistics.
Christiane Fellbaum, editor. 1998. WordNet: an elec-
tronic lexical database. MIT Press.
Lyn Frazier. 1978. On comprehending sentences: Syn-
tactic parsing strategies. Ph.D. thesis, University of
Connecticut.
Sanda M. Harabagiu and Marius Pasca. 1999. Inte-
grating symbolic and statistical methods for prepo-
sitional phrase attachment. In Proceedings of the
Twelfth International Florida Artificial Intelligence
Research Society ConferenceFLAIRS, pages 303–
307.
Donald Hindle and Mats Rooth. 1993. Structural am-
biguity and lexical relations. Computational Lin-
guistics, 19(1):103–120.
Dirk Hovy, Ashish Vaswani, Stephen Tratz, David Chi-
ang, and Eduard Hovy. 2011. Models and training
for unsupervised preposition sense disambiguation.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies: Short Papers - Volume 2,
pages 323–328.
John Kimball. 1988. Seven principles of surface struc-
ture parsing in natural language. Cognition, 2:15–
47.
Karin Kipper, Anna Korhonen, Neville Ryant, and
Martha Palmer. 2008. A large-scale classification
of english verbs. Language Resources and Evalua-
tion, 42(1):21–40.
Dan Klein and Christopher D. Manning. 2003. Ac-
curate unlexicalized parsing. In Proceedings of the
41st Annual Meeting of the Association for Compu-
tational Linguistics,ACL, pages 423–430.
</reference>
<page confidence="0.988572">
374
</page>
<reference confidence="0.999733317307692">
Ni Lao, Tom Mitchell, and William W Cohen. 2011.
Random walk inference and learning in a large scale
knowledge base. In Proceedings of the Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 529–539. Association for Computa-
tional Linguistics.
Jeff Mitchell and Mirella Lapata. 2008. Vector-based
models of semantic composition. In Proceedings of
the 46th Annual Meeting of the Association for Com-
putational Linguistics, ACL, pages 236–244.
Tom M. Mitchell, William W. Cohen, Estevam R. Hr-
uschka Jr., Partha Pratim Talukdar, Justin Bet-
teridge, Andrew Carlson, Bhavana Dalvi Mishra,
Matthew Gardner, Bryan Kisiel, Jayant Krishna-
murthy, Ni Lao, Kathryn Mazaitis, Thahir Mo-
hamed, Ndapandula Nakashole, Emmanouil Anto-
nios Platanios, Alan Ritter, Mehdi Samadi, Burr Set-
tles, Richard C. Wang, Derry Tanti Wijaya, Abhi-
nav Gupta, Xinlei Chen, Abulhair Saparov, Malcolm
Greaves, and Joel Welling. 2015. Never-ending
learning. In Proceedings of the Twenty-Ninth AAAI
Conference on Artificial Intelligence, January 25-
30, 2015, Austin, Texas, USA., pages 2302–2310.
Ndapandula Nakashole and Tom M. Mitchell. 2014.
Language-aware truth assessment of fact candidates.
In Proceedings of the 52nd Annual Meeting of
the Association for Computational Linguistics, ACL
2014, June 22-27, 2014, Baltimore, MD, USA, Vol-
ume 1: Long Papers, pages 1009–1019.
Ndapandula Nakashole and Gerhard Weikum. 2012.
Real-time population of knowledge bases: opportu-
nities and challenges. In Proceedings of the Joint
Workshop on Automatic Knowledge Base Construc-
tion and Web-scale Knowledge Extraction, pages
41–45. Association for Computational Linguistics.
Ndapandula Nakashole, Martin Theobald, and Gerhard
Weikum. 2011. Scalable knowledge harvesting
with high precision and high recall. In Proceedings
of the Fourth ACM International Conference on Web
Search and Data Mining, WSDM ’11, pages 227–
236.
Ndapandula Nakashole, Tomasz Tylenda, and Gerhard
Weikum. 2013. Fine-grained semantic typing of
emerging entities. In Proceedings of the 51st An-
nual Meeting of the Association for Computational
Linguistics, ACL, pages 1488–1497.
Kamal Nigam, Andrew McCallum, Sebastian Thrun,
and Tom M. Mitchell. 2000. Text classification
from labeled and unlabeled documents using EM.
Machine Learning, 39(2/3):103–134.
Patrick Pantel and Dekang Lin. 2000. An unsuper-
vised approach to prepositional phrase attachment
using contextually similar words. In 38th Annual
Meeting of the Association for Computational Lin-
guistics, ACL.
Adwait Ratnaparkhi, Jeff Reynar, and Salim Roukos.
1994. A maximum entropy model for prepositional
phrase attachment. In Proceedings of the Workshop
on Human Language Technology, HLT ’94, pages
250–255.
Adwait Ratnaparkhi. 1998. Statistical models for
unsupervised prepositional phrase attachement. In
36th Annual Meeting of the Association for Compu-
tational Linguistics and 17th International Confer-
ence on Computational Linguistics, COLING-ACL,
pages 1079–1085.
Vivek Srikumar and Dan Roth. 2013. Modeling se-
mantic relations expressed by prepositions. TACL,
1:231–242.
Jiri Stetina and Makoto Nagao. 1997. Prepositional
phrase attachment through a backed-off model. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing, pages 66–80.
Fabian M Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. Yago: a core of semantic knowl-
edge. In Proceedings of the 16th international con-
ference on World Wide Web, pages 697–706. ACM.
Kristina Toutanova, Christopher D. Manning, and An-
drew Y. Ng. 2004. Learning random walk models
for inducing word dependency distributions. In Ma-
chine Learning, Proceedings of the Twenty-first In-
ternational Conference, ICML.
Olga van Herwijnen, Antal van den Bosch, Jacques
M. B. Terken, and Erwin Marsi. 2003. Learning PP
attachment for filtering prosodic phrasing. In 10th
Conference of the European Chapter of the Asso-
ciation for Computational Linguistics,EACL, pages
139–146.
Greg Whittemore, Kathleen Ferrara, and Hans Brun-
ner. 1990. Empirical study of predictive powers od
simple attachment schemes for post-modifier prepo-
sitional phrases. In 28th Annual Meeting of the As-
sociation for Computational Linguistics,ACL, pages
23–30.
Derry Wijaya, Ndapandula Nakashole, and Tom
Mitchell. 2014. Ctps: Contextual temporal profiles
for time scoping facts via entity state change detec-
tion. In Proceedings of the Conference on Empirical
Methods in Natural Language Processing. Associa-
tion for Computational Linguistics.
Shaojun Zhao and Dekang Lin. 2004. A nearest-
neighbor method for resolving pp-attachment ambi-
guity. In Natural Language Processing - First Inter-
national Joint Conference, IJCNLP, pages 545–554.
</reference>
<page confidence="0.99912">
375
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.839606">
<title confidence="0.999231">A Knowledge-Intensive Model for Prepositional Phrase Attachment</title>
<author confidence="0.935051">Ndapandula</author>
<affiliation confidence="0.991163">Carnegie Mellon</affiliation>
<address confidence="0.954367">5000 Forbes Pittsburgh, PA,</address>
<email confidence="0.999494">ndapa@cs.cmu.edu</email>
<abstract confidence="0.99950425">Prepositional phrases (PPs) express crucial information that knowledge base construction methods need to extract. However, PPs are a major source of syntactic ambiguity and still pose problems in parsing. We present a method for resolving ambiguities arising from PPs, making extensive use of semantic knowledge from various resources. As training data, we use both labeled and unlabeled data, utilizing an expectation maximization algorithm for parameter estimation. Experiments show that our method yields improvements over existing methods including a state of the art dependency parser.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Timothy Baldwin</author>
<author>David Martinez</author>
</authors>
<title>Improving parsing and PP attachment performance with sense information.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>317--325</pages>
<contexts>
<context position="10251" citStr="Agirre et al., 2008" startWordPosition="1655" endWordPosition="1658">is used to replace certain words in rules with their WordNet classes. Parser Correction Methods. The quadruples formulation of the PP problem can be seen as a simplified setting. This is because, with quadruples, there is no need to deal with complex sentences but only well-defined quadruples of the form {v, n1, p, n2}. Thus in the quadruples setting, there are only two possible attachment sites for the PP, the v and n1. An alternative setting is to work in the context of full sentences. In this setting the problem is cast as a dependency parser correction problem (Atterer and Sch¨utze, 2007; Agirre et al., 2008; Anguiano and Candito, 2011). That is, given a dependency parse of a sentence, with potentially incorrect PP attachments, rectify it such that the prepositional phrases attach to the correct sites. Unlike our approach, these methods do not take semantic knowledge into account. Sense Disambiguation. In addition to prior work on prepositional phrase attachment, a highly related problem is preposition sense disambiguation (Hovy et al., 2011; Srikumar and Roth, 2013). Even a syntactically correctly attached PP can still be semantically ambiguous with respect to questions of machine reading such a</context>
</contexts>
<marker>Agirre, Baldwin, Martinez, 2008</marker>
<rawString>Eneko Agirre, Timothy Baldwin, and David Martinez. 2008. Improving parsing and PP attachment performance with sense information. In Proceedings of ACL-08: HLT, pages 317–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerry Altmann</author>
<author>Mark Steedman</author>
</authors>
<title>Interaction with context during human sentence processing.</title>
<date>1988</date>
<journal>Cognition,</journal>
<pages>30--191</pages>
<marker>Altmann, Steedman, 1988</marker>
<rawString>Gerry Altmann and Mark Steedman. 1988. Interaction with context during human sentence processing. Cognition, 30:191–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Enrique Henestroza Anguiano</author>
<author>Marie Candito</author>
</authors>
<title>Parse correction with specialized models for difficult attachment types.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, EMNLP,</booktitle>
<pages>1222--1233</pages>
<contexts>
<context position="10280" citStr="Anguiano and Candito, 2011" startWordPosition="1659" endWordPosition="1662">rtain words in rules with their WordNet classes. Parser Correction Methods. The quadruples formulation of the PP problem can be seen as a simplified setting. This is because, with quadruples, there is no need to deal with complex sentences but only well-defined quadruples of the form {v, n1, p, n2}. Thus in the quadruples setting, there are only two possible attachment sites for the PP, the v and n1. An alternative setting is to work in the context of full sentences. In this setting the problem is cast as a dependency parser correction problem (Atterer and Sch¨utze, 2007; Agirre et al., 2008; Anguiano and Candito, 2011). That is, given a dependency parse of a sentence, with potentially incorrect PP attachments, rectify it such that the prepositional phrases attach to the correct sites. Unlike our approach, these methods do not take semantic knowledge into account. Sense Disambiguation. In addition to prior work on prepositional phrase attachment, a highly related problem is preposition sense disambiguation (Hovy et al., 2011; Srikumar and Roth, 2013). Even a syntactically correctly attached PP can still be semantically ambiguous with respect to questions of machine reading such as where, when, and why. There</context>
</contexts>
<marker>Anguiano, Candito, 2011</marker>
<rawString>Enrique Henestroza Anguiano and Marie Candito. 2011. Parse correction with specialized models for difficult attachment types. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, EMNLP, pages 1222–1233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michaela Atterer</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Prepositional phrase attachment without oracles.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>4</issue>
<marker>Atterer, Sch¨utze, 2007</marker>
<rawString>Michaela Atterer and Hinrich Sch¨utze. 2007. Prepositional phrase attachment without oracles. Computational Linguistics, 33(4):469–476.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S¨oren Auer</author>
<author>Christian Bizer</author>
<author>Georgi Kobilarov</author>
<author>Jens Lehmann</author>
<author>Richard Cyganiak</author>
<author>Zachary G Ives</author>
</authors>
<title>Dbpedia: A nucleus for a web of open data.</title>
<date>2007</date>
<booktitle>In The Semantic Web, 6th International Semantic Web Conference, 2nd Asian Semantic Web Conference, ISWC 2007 + ASWC 2007, Busan, Korea,</booktitle>
<pages>722--735</pages>
<marker>Auer, Bizer, Kobilarov, Lehmann, Cyganiak, Ives, 2007</marker>
<rawString>S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary G. Ives. 2007. Dbpedia: A nucleus for a web of open data. In The Semantic Web, 6th International Semantic Web Conference, 2nd Asian Semantic Web Conference, ISWC 2007 + ASWC 2007, Busan, Korea, November 11-15, 2007., pages 722–735.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Michael J Cafarella</author>
<author>Stephen Soderland</author>
<author>Matthew Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<title>Open information extraction for the web. In</title>
<date>2007</date>
<booktitle>IJCAI,</booktitle>
<volume>7</volume>
<pages>2670--2676</pages>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Michele Banko, Michael J Cafarella, Stephen Soderland, Matthew Broadhead, and Oren Etzioni. 2007. Open information extraction for the web. In IJCAI, volume 7, pages 2670–2676.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kurt Bollacker</author>
<author>Colin Evans</author>
<author>Praveen Paritosh</author>
<author>Tim Sturge</author>
<author>Jamie Taylor</author>
</authors>
<title>Freebase: A collaboratively created graph database for structuring human knowledge.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, SIGMOD ’08,</booktitle>
<pages>1247--1250</pages>
<marker>Bollacker, Evans, Paritosh, Sturge, Taylor, 2008</marker>
<rawString>Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: A collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data, SIGMOD ’08, pages 1247–1250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>Philip Resnik</author>
</authors>
<title>A rule-based approach to prepositional phrase attachment disambiguation.</title>
<date>1994</date>
<booktitle>In 15th International Conference on Computational Linguistics, COLING,</booktitle>
<pages>1198--1204</pages>
<contexts>
<context position="3884" citStr="Brill and Resnik, 1994" startWordPosition="602" endWordPosition="605">aught butterfly with net Alice VP NP PP 365 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 365–375, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Noun attachments 0.9 Verb attachments 0.8 0.7 0.6 0.5 0.4 1 0.75 0.5 0.25 WITH AT FROM FOR AS IN ON 0 Figure 2: Dependency parser PP attachment accuracy for various frequent prepositions. for the PP, choose the most plausible attachment site. In the literature, prior work going as far back as (Brill and Resnik, 1994; Ratnaparkhi et al., 1994; Collins and Brooks, 1995) has focused on the language pattern that causes most PP ambiguities, which is the 4-word sequence: {v, n1, p, n2} (e.g., {caught, butterfly, with, spots}). The task is to determine if the prepositional phrase (p, n2) attaches to the verb v or to the first noun n1. Following common practice, we focus on PPs occurring as {v, n1, p, n2} quadruples — we shall refer to these as PP quads. The approach we present here differs from prior work in two main ways. First, we make extensive use of semantic knowledge about nouns, verbs, prepositions, pair</context>
<context position="7381" citStr="Brill and Resnik, 1994" startWordPosition="1180" endWordPosition="1183">positions provides useful insights on its performance. We re-implemented this baseline and found that when we remove the trivial preposition, “of”, whose PPs are by default attached to the noun by this baseline, precision drops to 78%. This analysis suggests there is substantial room for improvement. 1http://rtw.ml.cmu.edu/resources/ppa 2http://nlp.stanford.edu:8080/parser/ 366 3 Related Work Statistics-based Methods. Prominent prior methods learn to perform PP attachment based on corpus co-occurrence statistics, gathered either from manually annotated training data (Collins and Brooks, 1995; Brill and Resnik, 1994) or from automatically acquired training data that may be noisy (Ratnaparkhi, 1998; Pantel and Lin, 2000). These models collect statistics on how often a given quadruple, {v, n1, p, n2}, occurs in the training data as a verb attachment as opposed to a noun attachment. The issue with this approach is sparsity, that is, many quadruples occuring in the test data might not have been seen in the training data. Smoothing techniques are often employed to overcome sparsity. For example, (Collins and Brooks, 1995) proposed a back-off model that uses subsets of the words in the quadruple, by also keepin</context>
<context position="9407" citStr="Brill and Resnik, 1994" startWordPosition="1505" endWordPosition="1508"> to be a verb attachment. Structure-based Methods. These methods are based on high-level observations that are then generalized into heuristics for PP attachment decisions. (Kimball, 1988) proposed a right association method, whose premise is that a word tends to attach to another word immediately to its right. (Frazier, 1978) introduced a minimal attachment method, which posits that words attach to an existing non-terminal word using the fewest additional syntactic nodes. While simple, in practice these methods have been found to perform poorly (Whittemore et al., 1990). Rule-based Methods. (Brill and Resnik, 1994) proposed methods that learn a set of transformation rules from a corpus. The rules can be too specific to have broad applicability, resulting in low recall. To address low recall, knowledge about nouns, as found in WordNet, is used to replace certain words in rules with their WordNet classes. Parser Correction Methods. The quadruples formulation of the PP problem can be seen as a simplified setting. This is because, with quadruples, there is no need to deal with complex sentences but only well-defined quadruples of the form {v, n1, p, n2}. Thus in the quadruples setting, there are only two po</context>
</contexts>
<marker>Brill, Resnik, 1994</marker>
<rawString>Eric Brill and Philip Resnik. 1994. A rule-based approach to prepositional phrase attachment disambiguation. In 15th International Conference on Computational Linguistics, COLING, pages 1198– 1204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carlson</author>
<author>Justin Betteridge</author>
<author>Richard C Wang</author>
<author>Estevam R Hruschka</author>
<author>Tom M Mitchell</author>
</authors>
<title>Coupled semi-supervised learning for information extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the Third ACM International Conference on Web Search and Data Mining, WSDM ’10,</booktitle>
<pages>101--110</pages>
<marker>Carlson, Betteridge, Wang, Hruschka, Mitchell, 2010</marker>
<rawString>Andrew Carlson, Justin Betteridge, Richard C. Wang, Estevam R. Hruschka, Jr., and Tom M. Mitchell. 2010. Coupled semi-supervised learning for information extraction. In Proceedings of the Third ACM International Conference on Web Search and Data Mining, WSDM ’10, pages 101–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>James Brooks</author>
</authors>
<title>Prepositional phrase attachment through a backed-off model.</title>
<date>1995</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>27--38</pages>
<contexts>
<context position="3937" citStr="Collins and Brooks, 1995" startWordPosition="610" endWordPosition="613">dings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 365–375, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Noun attachments 0.9 Verb attachments 0.8 0.7 0.6 0.5 0.4 1 0.75 0.5 0.25 WITH AT FROM FOR AS IN ON 0 Figure 2: Dependency parser PP attachment accuracy for various frequent prepositions. for the PP, choose the most plausible attachment site. In the literature, prior work going as far back as (Brill and Resnik, 1994; Ratnaparkhi et al., 1994; Collins and Brooks, 1995) has focused on the language pattern that causes most PP ambiguities, which is the 4-word sequence: {v, n1, p, n2} (e.g., {caught, butterfly, with, spots}). The task is to determine if the prepositional phrase (p, n2) attaches to the verb v or to the first noun n1. Following common practice, we focus on PPs occurring as {v, n1, p, n2} quadruples — we shall refer to these as PP quads. The approach we present here differs from prior work in two main ways. First, we make extensive use of semantic knowledge about nouns, verbs, prepositions, pairs of nouns, and the discourse context in which a PP q</context>
<context position="6028" citStr="Collins and Brooks, 1995" startWordPosition="967" endWordPosition="970">orpus (NYTC). We make these datasets freely available for fuIN FROM WITH FOR OF As AT ON Figure 3: Noun vs. verb attachment proportions for frequent prepositions in the labeled NYTC dataset. ture research. In addition, we have applied our model to over 4 million 5-tuples of the form {n0, v, n1, p, n2}, and we also make this dataset available1 for research into ternary relation extraction beyond spatial and temporal scoping. 2 State of the Art To quantitatively assess existing tools, we analyzed performance of the widely used Stanford parser2 as of 2014, and the established baseline algorithm (Collins and Brooks, 1995), which has stood the test of time. We first manually labeled PP quads from the NYTC dataset, then prepended the noun phrase appearing before the quad, effectively creating sentences made up of 5 lexical items (n0 v n1 p n2). We then applied the Stanford parser, obtaining the results summarized in Figure 2. The parser performs well on some prepositions, for example, “of”, which tends to occur with noun attaching PPs as can be seen in Figure 3. However, for prepositions with an even distribution over verb and noun attachments, such as “on”, precision is as low as 50%. The Collins baseline achie</context>
<context position="7356" citStr="Collins and Brooks, 1995" startWordPosition="1176" endWordPosition="1179">precision of different prepositions provides useful insights on its performance. We re-implemented this baseline and found that when we remove the trivial preposition, “of”, whose PPs are by default attached to the noun by this baseline, precision drops to 78%. This analysis suggests there is substantial room for improvement. 1http://rtw.ml.cmu.edu/resources/ppa 2http://nlp.stanford.edu:8080/parser/ 366 3 Related Work Statistics-based Methods. Prominent prior methods learn to perform PP attachment based on corpus co-occurrence statistics, gathered either from manually annotated training data (Collins and Brooks, 1995; Brill and Resnik, 1994) or from automatically acquired training data that may be noisy (Ratnaparkhi, 1998; Pantel and Lin, 2000). These models collect statistics on how often a given quadruple, {v, n1, p, n2}, occurs in the training data as a verb attachment as opposed to a noun attachment. The issue with this approach is sparsity, that is, many quadruples occuring in the test data might not have been seen in the training data. Smoothing techniques are often employed to overcome sparsity. For example, (Collins and Brooks, 1995) proposed a back-off model that uses subsets of the words in the </context>
<context position="18564" citStr="Collins and Brooks, 1995" startWordPosition="3085" endWordPosition="3088"> contain relevant information for attachment decisions. We take into account the noun preceding a PP quad, in particular, its semantic type. This in effect makes the PP quad into a PP 5-tuple: {n0, v, n1, p, n2}, where the n0 provides additional context. Finally, we use lexical features in the form of PP quads, features F8-15. To overcome sparsity of occurrences of PP quads, we also use counts of shorter sub-sequences, including triples, pairs and singles. We only use sub-sequences that contain the preposition, as the preposition has been found to be highly crucial in PP attachment decisions (Collins and Brooks, 1995). 4.2 Disambiguation Algorithm We use the described features to train a model for making PP attachment decisions. Our goal is to compute P(y|x), the probability that the PP (p, n2) in the tuple {v, n1, p, n2} attaches to the verb (v) , y = 1 or to the noun(n1), y = 0, given 369 a feature vector x describing that tuple. As input to training the model, we are given a collection of PP quads, D where di E D : di = {v, n1, p, n2}. A small subset, Dl C D is labeled data, thus for each di E Dl we know the corresponding yi. The rest of the quads, Du, are unlabeled, hence their corresponding yis are un</context>
<context position="24165" citStr="Collins and Brooks, 1995" startWordPosition="4095" endWordPosition="4098">der Comparison. 1) PPAD (Prepositional Phrase Attachment Disambiguator) is our proposed method. It uses diverse types of semantic knowledge, a mixture of labeled and unlabeled data for training data, a logistic regression classiPPAD - WordNet Types PPAD - KB Types PPAD - Unsupervised Types PPAD - WordNet Verbs PPAD - Naive Bayes Collins Baseline Stanford Parser 0.82 0.74 0.66 0.58 0.5 WKP WKP\of NYTC NYTC\of WSJ WSJ\of Figure 4: PPAD variations vs. baselines. fier, and expectation maximization (EM) for parameter estimation 2) Collins is the established baseline among PP attachment algorithms (Collins and Brooks, 1995). 3) Stanford Parser is a stateof-the-art dependency parser, the 2014 online version. 4) PPAD Naive Bayes(NB) is the same as PPAD but uses a generative model, as opposed to the discriminative model used in PPAD. 5.2 PPAD vs. Baselines Comparison results of our method to the three baselines are shown in Table 4. For each dataset, we also show results when the “of” quads are removed, shown as “WKP\of”, “NYTC\of”, and “WSJ\of”. Our method yields improvements over the baselines. Improvements are especially significant on the datasets for which no labeled data was available (NYTC and WKP). On WKP, </context>
</contexts>
<marker>Collins, Brooks, 1995</marker>
<rawString>Michael Collins and James Brooks. 1995. Prepositional phrase attachment through a backed-off model. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 27–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of the International Conference on Language Recources and Evaluation (LREC,</booktitle>
<pages>449--454</pages>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of the International Conference on Language Recources and Evaluation (LREC, pages 449–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luciano Del Corro</author>
<author>Rainer Gemulla</author>
</authors>
<title>Clausie: Clause-based open information extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of the 22Nd International Conference on World Wide Web, WWW ’13,</booktitle>
<pages>355--366</pages>
<marker>Corro, Gemulla, 2013</marker>
<rawString>Luciano Del Corro and Rainer Gemulla. 2013. Clausie: Clause-based open information extraction. In Proceedings of the 22Nd International Conference on World Wide Web, WWW ’13, pages 355– 366.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A P Dempster</author>
<author>N M Laird</author>
<author>D B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the em algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society, Series B,</journal>
<volume>39</volume>
<issue>1</issue>
<contexts>
<context position="4769" citStr="Dempster et al., 1977" startWordPosition="759" endWordPosition="762">(p, n2) attaches to the verb v or to the first noun n1. Following common practice, we focus on PPs occurring as {v, n1, p, n2} quadruples — we shall refer to these as PP quads. The approach we present here differs from prior work in two main ways. First, we make extensive use of semantic knowledge about nouns, verbs, prepositions, pairs of nouns, and the discourse context in which a PP quad occurs. Table 1 summarizes the types of knowledge we considered in our work. Second, in training our model, we rely on both labeled and unlabeled data, employing an expectation maximization (EM) algorithm (Dempster et al., 1977). Contributions. In summary, our main contributions are: 1) Semantic Knowledge: Previous methods largely rely on corpus statistics. Our approach draws upon diverse sources of background knowledge, leading to performance improvements. 2) Unlabeled Data: In addition to training on labeled data, we also make use of a large amount of unlabeled data. This enhances our method’s ability to generalize to diverse data sets. 3) Datasets: In addition to the standard Wall Street Journal corpus (WSJ) (Ratnaparkhi et al., 1994), we labeled two new datasets for testing purposes, one from Wikipedia (WKP), and</context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Maximum likelihood from incomplete data via the em algorithm. Journal of the Royal Statistical Society, Series B, 39(1):1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fader</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Identifying relations for open information extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>1535--1545</pages>
<marker>Fader, Soderland, Etzioni, 2011</marker>
<rawString>Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011a. Identifying relations for open information extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 1535–1545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fader</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Identifying relations for open information extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1535--1545</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Fader, Soderland, Etzioni, 2011</marker>
<rawString>Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011b. Identifying relations for open information extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1535–1545. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<title>WordNet: an electronic lexical database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: an electronic lexical database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lyn Frazier</author>
</authors>
<title>On comprehending sentences: Syntactic parsing strategies.</title>
<date>1978</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Connecticut.</institution>
<contexts>
<context position="9112" citStr="Frazier, 1978" startWordPosition="1462" endWordPosition="1463"> preference is used by computing co-occurrence frequencies (lexical associations) of verbs and nouns, with prepositions. In this manner, they would discover that, for example, the verb “send” is highly associated with the preposition from, indicating that in this case, the PP is likely to be a verb attachment. Structure-based Methods. These methods are based on high-level observations that are then generalized into heuristics for PP attachment decisions. (Kimball, 1988) proposed a right association method, whose premise is that a word tends to attach to another word immediately to its right. (Frazier, 1978) introduced a minimal attachment method, which posits that words attach to an existing non-terminal word using the fewest additional syntactic nodes. While simple, in practice these methods have been found to perform poorly (Whittemore et al., 1990). Rule-based Methods. (Brill and Resnik, 1994) proposed methods that learn a set of transformation rules from a corpus. The rules can be too specific to have broad applicability, resulting in low recall. To address low recall, knowledge about nouns, as found in WordNet, is used to replace certain words in rules with their WordNet classes. Parser Cor</context>
</contexts>
<marker>Frazier, 1978</marker>
<rawString>Lyn Frazier. 1978. On comprehending sentences: Syntactic parsing strategies. Ph.D. thesis, University of Connecticut.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda M Harabagiu</author>
<author>Marius Pasca</author>
</authors>
<title>Integrating symbolic and statistical methods for prepositional phrase attachment.</title>
<date>1999</date>
<booktitle>In Proceedings of the Twelfth International Florida Artificial Intelligence Research Society ConferenceFLAIRS,</booktitle>
<pages>303--307</pages>
<marker>Harabagiu, Pasca, 1999</marker>
<rawString>Sanda M. Harabagiu and Marius Pasca. 1999. Integrating symbolic and statistical methods for prepositional phrase attachment. In Proceedings of the Twelfth International Florida Artificial Intelligence Research Society ConferenceFLAIRS, pages 303– 307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
<author>Mats Rooth</author>
</authors>
<title>Structural ambiguity and lexical relations.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="8489" citStr="Hindle and Rooth, 1993" startWordPosition="1362" endWordPosition="1365">Collins and Brooks, 1995) proposed a back-off model that uses subsets of the words in the quadruple, by also keeping frequency counts of triples, pairs and single words. Another approach to overcoming sparsity has been to use WordNet (Fellbaum, 1998) classes, by replacing nouns with their WordNet classes (Stetina and Nagao, 1997; Toutanova et al., 2004) to obtain less sparse corpus statistics. Corpus-derived clusters of similar nouns and verbs have also been used (Pantel and Lin, 2000). Hindle and Rooth proposed a lexical association approach based on how words are associated with each other (Hindle and Rooth, 1993). Lexical preference is used by computing co-occurrence frequencies (lexical associations) of verbs and nouns, with prepositions. In this manner, they would discover that, for example, the verb “send” is highly associated with the preposition from, indicating that in this case, the PP is likely to be a verb attachment. Structure-based Methods. These methods are based on high-level observations that are then generalized into heuristics for PP attachment decisions. (Kimball, 1988) proposed a right association method, whose premise is that a word tends to attach to another word immediately to its</context>
</contexts>
<marker>Hindle, Rooth, 1993</marker>
<rawString>Donald Hindle and Mats Rooth. 1993. Structural ambiguity and lexical relations. Computational Linguistics, 19(1):103–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dirk Hovy</author>
<author>Ashish Vaswani</author>
<author>Stephen Tratz</author>
<author>David Chiang</author>
<author>Eduard Hovy</author>
</authors>
<title>Models and training for unsupervised preposition sense disambiguation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers -</booktitle>
<volume>2</volume>
<pages>323--328</pages>
<contexts>
<context position="10693" citStr="Hovy et al., 2011" startWordPosition="1721" endWordPosition="1724">ing is to work in the context of full sentences. In this setting the problem is cast as a dependency parser correction problem (Atterer and Sch¨utze, 2007; Agirre et al., 2008; Anguiano and Candito, 2011). That is, given a dependency parse of a sentence, with potentially incorrect PP attachments, rectify it such that the prepositional phrases attach to the correct sites. Unlike our approach, these methods do not take semantic knowledge into account. Sense Disambiguation. In addition to prior work on prepositional phrase attachment, a highly related problem is preposition sense disambiguation (Hovy et al., 2011; Srikumar and Roth, 2013). Even a syntactically correctly attached PP can still be semantically ambiguous with respect to questions of machine reading such as where, when, and why. Therefore, when extracting information from prepositions, the problem of preposition sense disambiguation (semantics) has to be addressed in addition to prepositional phrase attachment disambiguation (syntax). In this paper, our focus is on the latter. 4 Methodology Our approach consists of first generating features from background knowledge and then training a model to learn with these features. The types of featu</context>
</contexts>
<marker>Hovy, Vaswani, Tratz, Chiang, Hovy, 2011</marker>
<rawString>Dirk Hovy, Ashish Vaswani, Stephen Tratz, David Chiang, and Eduard Hovy. 2011. Models and training for unsupervised preposition sense disambiguation. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: Short Papers - Volume 2, pages 323–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Kimball</author>
</authors>
<title>Seven principles of surface structure parsing in natural language.</title>
<date>1988</date>
<journal>Cognition,</journal>
<volume>2</volume>
<pages>47</pages>
<contexts>
<context position="8972" citStr="Kimball, 1988" startWordPosition="1438" endWordPosition="1439">Hindle and Rooth proposed a lexical association approach based on how words are associated with each other (Hindle and Rooth, 1993). Lexical preference is used by computing co-occurrence frequencies (lexical associations) of verbs and nouns, with prepositions. In this manner, they would discover that, for example, the verb “send” is highly associated with the preposition from, indicating that in this case, the PP is likely to be a verb attachment. Structure-based Methods. These methods are based on high-level observations that are then generalized into heuristics for PP attachment decisions. (Kimball, 1988) proposed a right association method, whose premise is that a word tends to attach to another word immediately to its right. (Frazier, 1978) introduced a minimal attachment method, which posits that words attach to an existing non-terminal word using the fewest additional syntactic nodes. While simple, in practice these methods have been found to perform poorly (Whittemore et al., 1990). Rule-based Methods. (Brill and Resnik, 1994) proposed methods that learn a set of transformation rules from a corpus. The rules can be too specific to have broad applicability, resulting in low recall. To addr</context>
</contexts>
<marker>Kimball, 1988</marker>
<rawString>John Kimball. 1988. Seven principles of surface structure parsing in natural language. Cognition, 2:15– 47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper</author>
<author>Anna Korhonen</author>
<author>Neville Ryant</author>
<author>Martha Palmer</author>
</authors>
<title>A large-scale classification of english verbs.</title>
<date>2008</date>
<journal>Language Resources and Evaluation,</journal>
<volume>42</volume>
<issue>1</issue>
<contexts>
<context position="16310" citStr="Kipper et al., 2008" startWordPosition="2692" endWordPosition="2695">ives with which they co-occur (distributional similarity). 4.1.3 Verb Role Fillers The verb role feature, F5, is a boolean feature hasRole(n2, ri) where ri is a role that n2 can fulfill for the verb v in the PP quad, according to background knowledge. Notice that if n2 fills a role for the verb, then the PP is a verb attachment. Consider the quad {caught, butterfly, with, net}, if we know that a net can play the role of an instrument for the verb catch, this suggests a likely verb attachment. We obtained background knowledge of verbs and their possible roles from the VerbNet lexical resource (Kipper et al., 2008). From VerbNet we obtained 2,573 labeled sentences containing PP quads (verbs in the same VerbNet group are considered synonymous), and the labeled semantic roles filled by the second noun n2 in the PP quad. We use these example sentences to label similar PP quads, where similarity of PP quads is defined by verbs from the same VerbNet group. 4.1.4 Preposition Definitions The preposition definition feature, F6, is a boolean feature def(prep, vi) = 1 if Ivi E M n svo(n1, vi, n2) = 1, where M is a definition mapping of prepositions to verb phrases. This mapping defines prepositions, using verbs i</context>
</contexts>
<marker>Kipper, Korhonen, Ryant, Palmer, 2008</marker>
<rawString>Karin Kipper, Anna Korhonen, Neville Ryant, and Martha Palmer. 2008. A large-scale classification of english verbs. Language Resources and Evaluation, 42(1):21–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,ACL,</booktitle>
<pages>423--430</pages>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,ACL, pages 423–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ni Lao</author>
<author>Tom Mitchell</author>
<author>William W Cohen</author>
</authors>
<title>Random walk inference and learning in a large scale knowledge base.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>529--539</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Lao, Mitchell, Cohen, 2011</marker>
<rawString>Ni Lao, Tom Mitchell, and William W Cohen. 2011. Random walk inference and learning in a large scale knowledge base. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 529–539. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Vector-based models of semantic composition.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics, ACL,</booktitle>
<pages>236--244</pages>
<marker>Mitchell, Lapata, 2008</marker>
<rawString>Jeff Mitchell and Mirella Lapata. 2008. Vector-based models of semantic composition. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics, ACL, pages 236–244.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Tom M Mitchell</author>
<author>William W Cohen</author>
<author>Estevam R Hruschka Jr</author>
<author>Partha Pratim Talukdar</author>
<author>Justin Betteridge</author>
<author>Andrew Carlson</author>
<author>Bhavana Dalvi Mishra</author>
<author>Matthew Gardner</author>
<author>Bryan Kisiel</author>
<author>Jayant Krishnamurthy</author>
<author>Ni Lao</author>
</authors>
<title>Kathryn Mazaitis, Thahir Mohamed, Ndapandula Nakashole, Emmanouil Antonios Platanios,</title>
<date>2015</date>
<booktitle>In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence,</booktitle>
<pages>2302--2310</pages>
<institution>Derry Tanti Wijaya, Abhinav Gupta, Xinlei Chen, Abulhair</institution>
<location>Alan Ritter, Mehdi</location>
<contexts>
<context position="946" citStr="Mitchell et al., 2015" startWordPosition="131" endWordPosition="134"> of syntactic ambiguity and still pose problems in parsing. We present a method for resolving ambiguities arising from PPs, making extensive use of semantic knowledge from various resources. As training data, we use both labeled and unlabeled data, utilizing an expectation maximization algorithm for parameter estimation. Experiments show that our method yields improvements over existing methods including a state of the art dependency parser. 1 Introduction Machine reading and information extraction (IE) projects have produced large resources with many millions of facts (Suchanek et al., 2007; Mitchell et al., 2015). This wealth of knowledge creates a positive feedback loop for automatic knowledge base construction efforts: the accumulated knowledge can be leveraged to improve machine reading; in turn, improved reading methods can be used to better extract knowledge expressed using complex and potentially ambiguous language. For example, prepositional phrases (PPs) express crucial information that IE methods need to extract. However, PPs are a major source of syntactic ambiguity. In this paper, we propose to use semantic knowledge to improve PP attachment disambiguation. PPs such as “in”, “at”, and “for”</context>
<context position="27220" citStr="Mitchell et al., 2015" startWordPosition="4605" endWordPosition="4608"> new features with high weights for verb attachments are: (perform,song,for,*), (lose,*,by,*), (buy,property,in,*). And for noun attachments: (*, conference, on, *), (obtain, degree, in, *), (abolish, taxes, on, *). We evaluated several variations of PPAD, the results are shown in Figure 4. For “PPADWordNet Verbs”, we expanded the data by replacing verbs in PP quads with synonymous WordNet verbs, ignoring verb senses. This resulted in more instances of features F1, F8-10, &amp; F12. We also used different types of noun categorizations: WordNet classes, semantic types from the NELL knowledge base (Mitchell et al., 2015) and unsupervised types. The KB types and the unsupervised types did not perform well, possibly due to the noise found in these categorizations. WordNet classes showed the best results, hence they were used in the final PPAD model for features F3-4 &amp; F7. In Section 5.1, PPAD corresponds to the best model. 5.4 Discussion: The F1 Score of Knowledge Why did we not reach 100% accuracy? Should relational knowledge not be providing a much bigger performance boost than we have seen in the results? To answer these questions, we characterize our features in terms precision and recall, and F1 measure of</context>
</contexts>
<marker>Mitchell, Cohen, Jr, Talukdar, Betteridge, Carlson, Mishra, Gardner, Kisiel, Krishnamurthy, Lao, 2015</marker>
<rawString>Tom M. Mitchell, William W. Cohen, Estevam R. Hruschka Jr., Partha Pratim Talukdar, Justin Betteridge, Andrew Carlson, Bhavana Dalvi Mishra, Matthew Gardner, Bryan Kisiel, Jayant Krishnamurthy, Ni Lao, Kathryn Mazaitis, Thahir Mohamed, Ndapandula Nakashole, Emmanouil Antonios Platanios, Alan Ritter, Mehdi Samadi, Burr Settles, Richard C. Wang, Derry Tanti Wijaya, Abhinav Gupta, Xinlei Chen, Abulhair Saparov, Malcolm Greaves, and Joel Welling. 2015. Never-ending learning. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, January 25-30, 2015, Austin, Texas, USA., pages 2302–2310.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ndapandula Nakashole</author>
<author>Tom M Mitchell</author>
</authors>
<title>Language-aware truth assessment of fact candidates.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL</booktitle>
<volume>Volume</volume>
<pages>1009--1019</pages>
<location>Baltimore, MD, USA,</location>
<marker>Nakashole, Mitchell, 2014</marker>
<rawString>Ndapandula Nakashole and Tom M. Mitchell. 2014. Language-aware truth assessment of fact candidates. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014, June 22-27, 2014, Baltimore, MD, USA, Volume 1: Long Papers, pages 1009–1019.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ndapandula Nakashole</author>
<author>Gerhard Weikum</author>
</authors>
<title>Real-time population of knowledge bases: opportunities and challenges.</title>
<date>2012</date>
<booktitle>In Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction,</booktitle>
<pages>41--45</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Nakashole, Weikum, 2012</marker>
<rawString>Ndapandula Nakashole and Gerhard Weikum. 2012. Real-time population of knowledge bases: opportunities and challenges. In Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction, pages 41–45. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ndapandula Nakashole</author>
<author>Martin Theobald</author>
<author>Gerhard Weikum</author>
</authors>
<title>Scalable knowledge harvesting with high precision and high recall.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fourth ACM International Conference on Web Search and Data Mining, WSDM ’11,</booktitle>
<pages>227--236</pages>
<marker>Nakashole, Theobald, Weikum, 2011</marker>
<rawString>Ndapandula Nakashole, Martin Theobald, and Gerhard Weikum. 2011. Scalable knowledge harvesting with high precision and high recall. In Proceedings of the Fourth ACM International Conference on Web Search and Data Mining, WSDM ’11, pages 227– 236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ndapandula Nakashole</author>
<author>Tomasz Tylenda</author>
<author>Gerhard Weikum</author>
</authors>
<title>Fine-grained semantic typing of emerging entities.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, ACL,</booktitle>
<pages>1488--1497</pages>
<marker>Nakashole, Tylenda, Weikum, 2013</marker>
<rawString>Ndapandula Nakashole, Tomasz Tylenda, and Gerhard Weikum. 2013. Fine-grained semantic typing of emerging entities. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, ACL, pages 1488–1497.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kamal Nigam</author>
<author>Andrew McCallum</author>
<author>Sebastian Thrun</author>
<author>Tom M Mitchell</author>
</authors>
<title>Text classification from labeled and unlabeled documents using EM.</title>
<date>2000</date>
<booktitle>Machine Learning,</booktitle>
<pages>39--2</pages>
<marker>Nigam, McCallum, Thrun, Mitchell, 2000</marker>
<rawString>Kamal Nigam, Andrew McCallum, Sebastian Thrun, and Tom M. Mitchell. 2000. Text classification from labeled and unlabeled documents using EM. Machine Learning, 39(2/3):103–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Dekang Lin</author>
</authors>
<title>An unsupervised approach to prepositional phrase attachment using contextually similar words.</title>
<date>2000</date>
<booktitle>In 38th Annual Meeting of the Association for Computational Linguistics, ACL.</booktitle>
<contexts>
<context position="7486" citStr="Pantel and Lin, 2000" startWordPosition="1196" endWordPosition="1199">we remove the trivial preposition, “of”, whose PPs are by default attached to the noun by this baseline, precision drops to 78%. This analysis suggests there is substantial room for improvement. 1http://rtw.ml.cmu.edu/resources/ppa 2http://nlp.stanford.edu:8080/parser/ 366 3 Related Work Statistics-based Methods. Prominent prior methods learn to perform PP attachment based on corpus co-occurrence statistics, gathered either from manually annotated training data (Collins and Brooks, 1995; Brill and Resnik, 1994) or from automatically acquired training data that may be noisy (Ratnaparkhi, 1998; Pantel and Lin, 2000). These models collect statistics on how often a given quadruple, {v, n1, p, n2}, occurs in the training data as a verb attachment as opposed to a noun attachment. The issue with this approach is sparsity, that is, many quadruples occuring in the test data might not have been seen in the training data. Smoothing techniques are often employed to overcome sparsity. For example, (Collins and Brooks, 1995) proposed a back-off model that uses subsets of the words in the quadruple, by also keeping frequency counts of triples, pairs and single words. Another approach to overcoming sparsity has been t</context>
</contexts>
<marker>Pantel, Lin, 2000</marker>
<rawString>Patrick Pantel and Dekang Lin. 2000. An unsupervised approach to prepositional phrase attachment using contextually similar words. In 38th Annual Meeting of the Association for Computational Linguistics, ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
<author>Jeff Reynar</author>
<author>Salim Roukos</author>
</authors>
<title>A maximum entropy model for prepositional phrase attachment.</title>
<date>1994</date>
<booktitle>In Proceedings of the Workshop on Human Language Technology, HLT ’94,</booktitle>
<pages>250--255</pages>
<contexts>
<context position="3910" citStr="Ratnaparkhi et al., 1994" startWordPosition="606" endWordPosition="609"> Alice VP NP PP 365 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 365–375, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Noun attachments 0.9 Verb attachments 0.8 0.7 0.6 0.5 0.4 1 0.75 0.5 0.25 WITH AT FROM FOR AS IN ON 0 Figure 2: Dependency parser PP attachment accuracy for various frequent prepositions. for the PP, choose the most plausible attachment site. In the literature, prior work going as far back as (Brill and Resnik, 1994; Ratnaparkhi et al., 1994; Collins and Brooks, 1995) has focused on the language pattern that causes most PP ambiguities, which is the 4-word sequence: {v, n1, p, n2} (e.g., {caught, butterfly, with, spots}). The task is to determine if the prepositional phrase (p, n2) attaches to the verb v or to the first noun n1. Following common practice, we focus on PPs occurring as {v, n1, p, n2} quadruples — we shall refer to these as PP quads. The approach we present here differs from prior work in two main ways. First, we make extensive use of semantic knowledge about nouns, verbs, prepositions, pairs of nouns, and the discou</context>
<context position="5288" citStr="Ratnaparkhi et al., 1994" startWordPosition="841" endWordPosition="844">h labeled and unlabeled data, employing an expectation maximization (EM) algorithm (Dempster et al., 1977). Contributions. In summary, our main contributions are: 1) Semantic Knowledge: Previous methods largely rely on corpus statistics. Our approach draws upon diverse sources of background knowledge, leading to performance improvements. 2) Unlabeled Data: In addition to training on labeled data, we also make use of a large amount of unlabeled data. This enhances our method’s ability to generalize to diverse data sets. 3) Datasets: In addition to the standard Wall Street Journal corpus (WSJ) (Ratnaparkhi et al., 1994), we labeled two new datasets for testing purposes, one from Wikipedia (WKP), and another from the New York Times Corpus (NYTC). We make these datasets freely available for fuIN FROM WITH FOR OF As AT ON Figure 3: Noun vs. verb attachment proportions for frequent prepositions in the labeled NYTC dataset. ture research. In addition, we have applied our model to over 4 million 5-tuples of the form {n0, v, n1, p, n2}, and we also make this dataset available1 for research into ternary relation extraction beyond spatial and temporal scoping. 2 State of the Art To quantitatively assess existing tool</context>
<context position="17452" citStr="Ratnaparkhi et al., 1994" startWordPosition="2896" endWordPosition="2899">g of prepositions to verb phrases. This mapping defines prepositions, using verbs in our ClueWeb09 derived SVO corpus, in order to capture their senses using verbs; it contains definitions such as def(with, *) = contains, accompanied by, ... . If “with” is used in the sense of “contains” , then the PP is a likely noun attachment, as in n1 contains n2 in the quad ate, cookies, with, cranberries. However, if “with” is used in the sense of “accompanied by”, then the PP is a likely verb attachment, as in the quad visted, Paris, with, Sue. To obtain the mapping, we took the labeled PP quads (WSJ, (Ratnaparkhi et al., 1994)) and computed a ranked list of verbs from SVOs, that appear frequently between pairs of nouns for a given preposition. Other sample mappings are: def(for,*)= used for, def(in,*)= located in. Notice that this feature F6 is a selective, more targeted version of F2. 4.1.5 Discourse and Lexical Features The discourse feature, F7, is a boolean feature isA(n0, ti), for each noun category ti found in a noun category ontology T such as WordNet semantic types. The context of the PP quad can contain relevant information for attachment decisions. We take into account the noun preceding a PP quad, in par</context>
</contexts>
<marker>Ratnaparkhi, Reynar, Roukos, 1994</marker>
<rawString>Adwait Ratnaparkhi, Jeff Reynar, and Salim Roukos. 1994. A maximum entropy model for prepositional phrase attachment. In Proceedings of the Workshop on Human Language Technology, HLT ’94, pages 250–255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>Statistical models for unsupervised prepositional phrase attachement.</title>
<date>1998</date>
<booktitle>In 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, COLING-ACL,</booktitle>
<pages>1079--1085</pages>
<contexts>
<context position="7463" citStr="Ratnaparkhi, 1998" startWordPosition="1194" endWordPosition="1195">nd found that when we remove the trivial preposition, “of”, whose PPs are by default attached to the noun by this baseline, precision drops to 78%. This analysis suggests there is substantial room for improvement. 1http://rtw.ml.cmu.edu/resources/ppa 2http://nlp.stanford.edu:8080/parser/ 366 3 Related Work Statistics-based Methods. Prominent prior methods learn to perform PP attachment based on corpus co-occurrence statistics, gathered either from manually annotated training data (Collins and Brooks, 1995; Brill and Resnik, 1994) or from automatically acquired training data that may be noisy (Ratnaparkhi, 1998; Pantel and Lin, 2000). These models collect statistics on how often a given quadruple, {v, n1, p, n2}, occurs in the training data as a verb attachment as opposed to a noun attachment. The issue with this approach is sparsity, that is, many quadruples occuring in the test data might not have been seen in the training data. Smoothing techniques are often employed to overcome sparsity. For example, (Collins and Brooks, 1995) proposed a back-off model that uses subsets of the words in the quadruple, by also keeping frequency counts of triples, pairs and single words. Another approach to overcom</context>
</contexts>
<marker>Ratnaparkhi, 1998</marker>
<rawString>Adwait Ratnaparkhi. 1998. Statistical models for unsupervised prepositional phrase attachement. In 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, COLING-ACL, pages 1079–1085.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivek Srikumar</author>
<author>Dan Roth</author>
</authors>
<title>Modeling semantic relations expressed by prepositions.</title>
<date>2013</date>
<tech>TACL,</tech>
<pages>1--231</pages>
<contexts>
<context position="10719" citStr="Srikumar and Roth, 2013" startWordPosition="1725" endWordPosition="1728">he context of full sentences. In this setting the problem is cast as a dependency parser correction problem (Atterer and Sch¨utze, 2007; Agirre et al., 2008; Anguiano and Candito, 2011). That is, given a dependency parse of a sentence, with potentially incorrect PP attachments, rectify it such that the prepositional phrases attach to the correct sites. Unlike our approach, these methods do not take semantic knowledge into account. Sense Disambiguation. In addition to prior work on prepositional phrase attachment, a highly related problem is preposition sense disambiguation (Hovy et al., 2011; Srikumar and Roth, 2013). Even a syntactically correctly attached PP can still be semantically ambiguous with respect to questions of machine reading such as where, when, and why. Therefore, when extracting information from prepositions, the problem of preposition sense disambiguation (semantics) has to be addressed in addition to prepositional phrase attachment disambiguation (syntax). In this paper, our focus is on the latter. 4 Methodology Our approach consists of first generating features from background knowledge and then training a model to learn with these features. The types of features considered in our expe</context>
</contexts>
<marker>Srikumar, Roth, 2013</marker>
<rawString>Vivek Srikumar and Dan Roth. 2013. Modeling semantic relations expressed by prepositions. TACL, 1:231–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiri Stetina</author>
<author>Makoto Nagao</author>
</authors>
<title>Prepositional phrase attachment through a backed-off model.</title>
<date>1997</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>66--80</pages>
<contexts>
<context position="8196" citStr="Stetina and Nagao, 1997" startWordPosition="1315" endWordPosition="1318">s in the training data as a verb attachment as opposed to a noun attachment. The issue with this approach is sparsity, that is, many quadruples occuring in the test data might not have been seen in the training data. Smoothing techniques are often employed to overcome sparsity. For example, (Collins and Brooks, 1995) proposed a back-off model that uses subsets of the words in the quadruple, by also keeping frequency counts of triples, pairs and single words. Another approach to overcoming sparsity has been to use WordNet (Fellbaum, 1998) classes, by replacing nouns with their WordNet classes (Stetina and Nagao, 1997; Toutanova et al., 2004) to obtain less sparse corpus statistics. Corpus-derived clusters of similar nouns and verbs have also been used (Pantel and Lin, 2000). Hindle and Rooth proposed a lexical association approach based on how words are associated with each other (Hindle and Rooth, 1993). Lexical preference is used by computing co-occurrence frequencies (lexical associations) of verbs and nouns, with prepositions. In this manner, they would discover that, for example, the verb “send” is highly associated with the preposition from, indicating that in this case, the PP is likely to be a ver</context>
</contexts>
<marker>Stetina, Nagao, 1997</marker>
<rawString>Jiri Stetina and Makoto Nagao. 1997. Prepositional phrase attachment through a backed-off model. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 66–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian M Suchanek</author>
<author>Gjergji Kasneci</author>
<author>Gerhard Weikum</author>
</authors>
<title>Yago: a core of semantic knowledge.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th international conference on World Wide Web,</booktitle>
<pages>697--706</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="922" citStr="Suchanek et al., 2007" startWordPosition="127" endWordPosition="130"> PPs are a major source of syntactic ambiguity and still pose problems in parsing. We present a method for resolving ambiguities arising from PPs, making extensive use of semantic knowledge from various resources. As training data, we use both labeled and unlabeled data, utilizing an expectation maximization algorithm for parameter estimation. Experiments show that our method yields improvements over existing methods including a state of the art dependency parser. 1 Introduction Machine reading and information extraction (IE) projects have produced large resources with many millions of facts (Suchanek et al., 2007; Mitchell et al., 2015). This wealth of knowledge creates a positive feedback loop for automatic knowledge base construction efforts: the accumulated knowledge can be leveraged to improve machine reading; in turn, improved reading methods can be used to better extract knowledge expressed using complex and potentially ambiguous language. For example, prepositional phrases (PPs) express crucial information that IE methods need to extract. However, PPs are a major source of syntactic ambiguity. In this paper, we propose to use semantic knowledge to improve PP attachment disambiguation. PPs such </context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Fabian M Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: a core of semantic knowledge. In Proceedings of the 16th international conference on World Wide Web, pages 697–706. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Learning random walk models for inducing word dependency distributions.</title>
<date>2004</date>
<booktitle>In Machine Learning, Proceedings of the Twenty-first International Conference, ICML.</booktitle>
<contexts>
<context position="8221" citStr="Toutanova et al., 2004" startWordPosition="1319" endWordPosition="1322"> a verb attachment as opposed to a noun attachment. The issue with this approach is sparsity, that is, many quadruples occuring in the test data might not have been seen in the training data. Smoothing techniques are often employed to overcome sparsity. For example, (Collins and Brooks, 1995) proposed a back-off model that uses subsets of the words in the quadruple, by also keeping frequency counts of triples, pairs and single words. Another approach to overcoming sparsity has been to use WordNet (Fellbaum, 1998) classes, by replacing nouns with their WordNet classes (Stetina and Nagao, 1997; Toutanova et al., 2004) to obtain less sparse corpus statistics. Corpus-derived clusters of similar nouns and verbs have also been used (Pantel and Lin, 2000). Hindle and Rooth proposed a lexical association approach based on how words are associated with each other (Hindle and Rooth, 1993). Lexical preference is used by computing co-occurrence frequencies (lexical associations) of verbs and nouns, with prepositions. In this manner, they would discover that, for example, the verb “send” is highly associated with the preposition from, indicating that in this case, the PP is likely to be a verb attachment. Structure-b</context>
</contexts>
<marker>Toutanova, Manning, Ng, 2004</marker>
<rawString>Kristina Toutanova, Christopher D. Manning, and Andrew Y. Ng. 2004. Learning random walk models for inducing word dependency distributions. In Machine Learning, Proceedings of the Twenty-first International Conference, ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olga van Herwijnen</author>
<author>Antal van den Bosch</author>
<author>Jacques M B Terken</author>
<author>Erwin Marsi</author>
</authors>
<title>Learning PP attachment for filtering prosodic phrasing.</title>
<date>2003</date>
<booktitle>In 10th Conference of the European Chapter of the Association for Computational Linguistics,EACL,</booktitle>
<pages>139--146</pages>
<marker>van Herwijnen, van den Bosch, Terken, Marsi, 2003</marker>
<rawString>Olga van Herwijnen, Antal van den Bosch, Jacques M. B. Terken, and Erwin Marsi. 2003. Learning PP attachment for filtering prosodic phrasing. In 10th Conference of the European Chapter of the Association for Computational Linguistics,EACL, pages 139–146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Whittemore</author>
<author>Kathleen Ferrara</author>
<author>Hans Brunner</author>
</authors>
<title>Empirical study of predictive powers od simple attachment schemes for post-modifier prepositional phrases.</title>
<date>1990</date>
<booktitle>In 28th Annual Meeting of the Association for Computational Linguistics,ACL,</booktitle>
<pages>23--30</pages>
<contexts>
<context position="9361" citStr="Whittemore et al., 1990" startWordPosition="1499" endWordPosition="1502"> indicating that in this case, the PP is likely to be a verb attachment. Structure-based Methods. These methods are based on high-level observations that are then generalized into heuristics for PP attachment decisions. (Kimball, 1988) proposed a right association method, whose premise is that a word tends to attach to another word immediately to its right. (Frazier, 1978) introduced a minimal attachment method, which posits that words attach to an existing non-terminal word using the fewest additional syntactic nodes. While simple, in practice these methods have been found to perform poorly (Whittemore et al., 1990). Rule-based Methods. (Brill and Resnik, 1994) proposed methods that learn a set of transformation rules from a corpus. The rules can be too specific to have broad applicability, resulting in low recall. To address low recall, knowledge about nouns, as found in WordNet, is used to replace certain words in rules with their WordNet classes. Parser Correction Methods. The quadruples formulation of the PP problem can be seen as a simplified setting. This is because, with quadruples, there is no need to deal with complex sentences but only well-defined quadruples of the form {v, n1, p, n2}. Thus in</context>
</contexts>
<marker>Whittemore, Ferrara, Brunner, 1990</marker>
<rawString>Greg Whittemore, Kathleen Ferrara, and Hans Brunner. 1990. Empirical study of predictive powers od simple attachment schemes for post-modifier prepositional phrases. In 28th Annual Meeting of the Association for Computational Linguistics,ACL, pages 23–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Derry Wijaya</author>
<author>Ndapandula Nakashole</author>
<author>Tom Mitchell</author>
</authors>
<title>Ctps: Contextual temporal profiles for time scoping facts via entity state change detection.</title>
<date>2014</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.</booktitle>
<marker>Wijaya, Nakashole, Mitchell, 2014</marker>
<rawString>Derry Wijaya, Ndapandula Nakashole, and Tom Mitchell. 2014. Ctps: Contextual temporal profiles for time scoping facts via entity state change detection. In Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shaojun Zhao</author>
<author>Dekang Lin</author>
</authors>
<title>A nearestneighbor method for resolving pp-attachment ambiguity.</title>
<date>2004</date>
<booktitle>In Natural Language Processing - First International Joint Conference, IJCNLP,</booktitle>
<pages>545--554</pages>
<marker>Zhao, Lin, 2004</marker>
<rawString>Shaojun Zhao and Dekang Lin. 2004. A nearestneighbor method for resolving pp-attachment ambiguity. In Natural Language Processing - First International Joint Conference, IJCNLP, pages 545–554.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>