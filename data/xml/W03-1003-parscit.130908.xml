<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001257">
<title confidence="0.971044">
Cross-Lingual Lexical Triggers in Statistical Language Modeling
</title>
<author confidence="0.991096">
Woosung Kim
</author>
<affiliation confidence="0.919106">
The Johns Hopkins University
3400 N. Charles St., Baltimore, MD
</affiliation>
<email confidence="0.997031">
woosung@cs.jhu.edu
</email>
<author confidence="0.942585">
Sanjeev Khudanpur
</author>
<affiliation confidence="0.88301">
The Johns Hopkins University
3400 N. Charles St., Baltimore, MD
</affiliation>
<email confidence="0.998549">
khudanpur@jhu.edu
</email>
<sectionHeader confidence="0.995643" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999881130434783">
We propose new methods to take advan-
tage of text in resource-rich languages
to sharpen statistical language models in
resource-deficient languages. We achieve
this through an extension of the method
of lexical triggers to the cross-language
problem, and by developing a likelihood-
based adaptation scheme for combining
a trigger model with an -gram model.
We describe the application of such lan-
guage models for automatic speech recog-
nition. By exploiting a side-corpus of con-
temporaneous English news articles for
adapting a static Chinese language model
to transcribe Mandarin news stories, we
demonstrate significant reductions in both
perplexity and recognition errors. We
also compare our cross-lingual adaptation
scheme to monolingual language model
adaptation, and to an alternate method for
exploiting cross-lingual cues, via cross-
lingual information retrieval and machine
translation, proposed elsewhere.
</bodyText>
<sectionHeader confidence="0.887507" genericHeader="method">
1 Data Sparseness in Language Modeling
</sectionHeader>
<bodyText confidence="0.994702">
Statistical techniques have been remarkably suc-
cessful in automatic speech recognition (ASR) and
natural language processing (NLP) over the last two
decades. This success, however, depends crucially
</bodyText>
<footnote confidence="0.990779666666667">
✂This research was supported by the National Science Foun-
dation (via Grant No¯ ITR-0225656 and IIS-9982329) and the
Office ofNaval Research (via Contract No¯N00014-01-1-0685).
</footnote>
<bodyText confidence="0.999914787878788">
on the availability of accurate and large amounts
of suitably annotated training data and it is difficult
to build a usable statistical model in their absence.
Most of the success, therefore, has been witnessed
in the so called resource-rich languages. More re-
cently, there has been an increasing interest in lan-
guages such as Mandarin and Arabic for ASR and
NLP, and data resources are being created for them
at considerable cost. The data-resource bottleneck,
however, is likely to remain for a majority of the
world’s languages in the foreseeable future.
Methods have been proposed to bootstrap acous-
tic models for ASR in resource deficient languages
by reusing acoustic models from resource-rich lan-
guages (Schultz and Waibel, 1998; Byrne et al.,
2000). Morphological analyzers, noun-phrase chun-
kers, POS taggers, etc., have also been developed
for resource deficient languages by exploiting trans-
lated or parallel text (Yarowsky et al., 2001). Khu-
danpur and Kim (2002) recently proposed using
cross-lingual information retrieval (CLIR) and ma-
chine translation (MT) to improve a statistical lan-
guage model (LM) in a resource-deficient language
by exploiting copious amounts of text available in
resource-rich languages. When transcribing a news
story in a resource-deficient language, their core
idea is to use the first pass output of a rudimentary
ASR system as a query for CLIR, identify a contem-
poraneous English document on that news topic, fol-
lowed by MT to provide a rough translation which,
even if not fluent, is adequate to update estimates of
word frequencies and the LM vocabulary. They re-
port up to a 28% reduction in perplexity on Chinese
text from the Hong Kong News corpus.
In spite of their considerable success, some short-
comings remain in the method used by Khudanpur
and Kim (2002). Specifically, stochastic translation
lexicons estimated using the IBM method (Brown
et al., 1993) from a fairly large sentence-aligned
Chinese-English parallel corpus are used in their ap-
proach a considerable demand for a resource-
deficient language. It is suggested that an easier-
to-obtain document-aligned comparable corpus may
suffice, but no results are reported. Furthermore, for
each Mandarin news story, the single best match-
ing English article obtained via CLIR is translated
and used for priming the Chinese LM, no matter
how good the CLIR similarity, nor are other well-
matching English articles considered. This issue
clearly deserves further attention. Finally, ASR re-
sults are not reported in their work, though their pro-
posed solution is clearly motivated by an ASR task.
We address these three issues in this paper.
Section 2 begins, for the sake of completeness,
with a review of the cross-lingual story-specific LM
proposed by Khudanpur and Kim (2002). A notion
of cross-lingual lexical triggers is proposed in Sec-
tion 3, which overcomes the need for a sentence-
aligned parallel corpus for obtaining translation lex-
icons. After a brief detour to describe topic-
dependent LMs in Section 4, a description of the
ASR task is provided in Section 5, and ASR results
on Mandarin Broadcast News are presented in Sec-
tion 6. The issue of how many English articles to
retrieve and translate into Chinese is resolved by a
likelihood-based scheme proposed in Section 6.1.
</bodyText>
<sectionHeader confidence="0.899947" genericHeader="method">
2 Cross-Lingual Story-Specific LMs
</sectionHeader>
<bodyText confidence="0.994517741935484">
For the sake of illustration, consider the task of
sharpening a Chinese language model for transcrib-
ing Mandarin news stories by using a large corpus
of contemporaneous English newswire text. Man-
darin Chinese is, of course, not resource-deficient
for language modeling 100s of millions of words
are available on-line. However, we choose it for our
experiments partly because it is sufficiently different
from English to pose a real challenge, and because
the availability of large text corpora in fact permits
us to simulate controlled resource deficiency.
Let denote the text of test sto-
ries to be transcribed by an ASR system, and let
denote their corresponding or aligned
English newswire articles. Correspondence here
does not imply that the English document needs
to be an exact translation of the Mandarin story .
It is quite adequate, for instance, if the two stories re-
port the same news event. This approach is expected
to be helpful even when the English document is
merely on the same general topic as the Mandarin
story, although the closer the content of a pair of ar-
ticles the better the proposed methods are likely to
work. Assume for the time being that a sufficiently
good Chinese-English story alignment is given.
Assume further that we have at our disposal a
stochastic translation dictionary a probabilistic
model of the form which provides the
Chinese translation of each English word
, where and respectively denote our Chi-
nese and English vocabularies.
</bodyText>
<subsectionHeader confidence="0.999298">
2.1 Computing a Cross-Lingual Unigram LM
</subsectionHeader>
<bodyText confidence="0.971128142857143">
Let denote the relative frequency of a word
in the document , , . It seems
plausible that, ,
would be a good unigram model for the -th Man-
darin story . We use this cross-lingual unigram
statistic to sharpen a statistical Chinese LM used for
processing the test story . One way to do this is
via linear interpolation
of the cross-lingual unigram model (1) with a static
trigram model for Chinese, where the interpolation
weight may be chosen off-line to maximize the
likelihood of some held-out Mandarin stories. The
improvement in (2) is expected from the fact that
unlike the static text from which the Chinese trigram
LM is estimated, is semantically close to and
even the adjustment of unigram statistics, based on
a stochastic translation model, may help.
Figure 1 shows the data flow in this cross-lingual
LM adaptation approach, where the output of the
first pass of an ASR system is used by a CLIR sys-
tem to find an English document , an MT system
</bodyText>
<figureCaption confidence="0.959998">
Figure 1: Story-Specific Cross-Lingual Adaptation
of a Chinese Language Model using English Text.
computes the statistic of (1), and the ASR system
uses the LM of (2) in a second pass.
</figureCaption>
<subsectionHeader confidence="0.999546">
2.2 Obtaining Matching English Documents
</subsectionHeader>
<bodyText confidence="0.9803375">
To illustrate how one may obtain the English doc-
ument to match a Mandarin story , let us
assume that we also have a stochastic reverse-
translation lexicon . One obtains from the
first pass ASR output, cf. Figure 1, the relative fre-
quency estimate of Chinese words in ,
, and uses the translation lexicon to
compute, ,
(3)
an English bag-of-words representation of the Man-
darin story as used in standard vector-based in-
formation retrieval. The document with the highest
TF-IDF weighted cosine-similarity to is selected:
Readers familiar with information retrieval litera-
ture will recognize this to be the standard query-
translation approach to CLIR.
</bodyText>
<subsectionHeader confidence="0.999005">
2.3 Obtaining Stochastic Translation Lexicons
</subsectionHeader>
<bodyText confidence="0.9993635">
The translation lexicons and may
be created out of an available electronic translation
lexicon, with multiple translations of a word being
treated as equally likely. Stemming and other mor-
phological analyses may be applied to increase the
vocabulary-coverage of the translation lexicons.
Alternately, they may also be obtained auto-
matically from a parallel corpus of translated and
sentence-aligned Chinese-English text using statisti-
cal machine translation techniques, such as the pub-
licly available GIZA++ tools (Och and Ney, 2000),
as done by Khudanpur and Kim (2002). Unlike stan-
dard MT systems, however, we apply the translation
models to entire articles, one word at a time, to get a
bag of translated words — cf. (1) and (3).
Finally, for truly resource deficient languages, one
may obtain a translation lexicon via optical character
recognition from a printed bilingual dictionary (cf.
Doerman et al (2002)). This task is arguably easier
than obtaining a large LM training corpus.
</bodyText>
<sectionHeader confidence="0.939311" genericHeader="method">
3 Cross-Lingual Lexical Triggers
</sectionHeader>
<bodyText confidence="0.998678535714286">
It seems plausible that most of the information one
gets from the cross-lingual unigram LM of (1) is
in the form of the altered statistics of topic-specific
Chinese words conveyed by the statistics of content-
bearing English words in the matching story. The
translation lexicon used for obtaining the informa-
tion, however, is an expensive resource. Yet, if one
were only interested in the conditional distribution
of Chinese words given some English words, there
is no reason to require translation as an intermedi-
ate step. In a monolingual setting, the mutual infor-
mation between lexical pairs co-occurring anywhere
within a long “window” of each-other has been used
to capture statistical dependencies not covered by
-gram LMs (Rosenfeld, 1996; Tillmann and Ney,
1997). We use this inspiration to propose the follow-
ing notion of cross-lingual lexical triggers.
In a monolingual setting, a pair of words is
considered a trigger-pair if, given a word-position in
a sentence, the occurrence of in any of the pre-
ceding word-positions significantly alters the (con-
ditional) probability that the following word in the
sentence is : is said to trigger . E.g. the occur-
rence of either significantly increases the proba-
bility of or subsequently in the sentence. The set of
preceding word-positions is variably defined to in-
clude all words from the beginning of the sentence,
paragraph or document, or is limited to a fixed num-
</bodyText>
<figure confidence="0.983281619047619">
Baseline Chinese
Acoustic Model
ASR
Mandarin Story
Automatic Transcription
Contemporaneous
English Articles
Baseline Chinese
Language Model
Chinese
Dictionary
Cross−Language Information Retrieval
English Article Aligned with
Mandarin Story
Machine Translation
Statistical
Translation
lexicon
Cross−Language
Unigram Model
sim
</figure>
<bodyText confidence="0.998781947368421">
ber of preceding words, limited of course by the be-
ginning of the sentence, paragraph or document.
In the cross-lingual setting, we consider a pair of
words ,and , to be a trigger-pair
if, given an English-Chinese pair of aligned docu-
ments, the occurrence of in the English document
significantly alters the (conditional) probability that
the word appears in the Chinese document: is
said to trigger . It is plausible that translation-pairs
will be natural candidates for trigger-pairs. It is,
however, not necessary for a trigger-pair to also be a
translation-pair. E.g., the occurrence of Belgrade
in the English document may trigger the Chinese
transliterations of Serbia and Kosovo, and pos-
sibly the translations of China, embassy and
bomb! By infering trigger-pairs from a document-
aligned corpus of Chinese-English articles, we ex-
pect to be able to discover semantically- or topically-
related pairs in addition to translation equivalences.
</bodyText>
<subsectionHeader confidence="0.99927">
3.1 Identification of Cross-Lingual Triggers
</subsectionHeader>
<bodyText confidence="0.997397538461538">
Average mutual information, which measures how
much knowing the value of one random variable
reduces the uncertainty of about another, has been
used to identify trigger-pairs. We compute the av-
erage mutual information for every English-Chinese
word pair as follows.
Let , , now be a document-
aligned training corpus of English-Chinese article
pairs. Let denote the document frequency,
i.e., the number of aligned article-pairs, in which
occurs in the English article and in the Chinese.
Let denote the number of aligned article-
pairs in which occurs in the English articles but
does not occur in the Chinese article. Let
The quantities and are similarly de-
fined. Next let denote the number of English
articles in which occurs, and define
We propose to select word pairs with high mutual
information as cross-lingual lexical triggers.
There are possible English-Chinese word
pairs which may be prohibitively large to search
for the pairs with the highest mutual information.
We filter out infrequent words in each language,
say, words appearing less than 5 times, then mea-
sure for all possible pairs from the remaining
words, sort them by , and select, say, the top
</bodyText>
<listItem confidence="0.452395">
1 million pairs.
</listItem>
<subsectionHeader confidence="0.999416">
3.2 Estimating Trigger LM Probabilities
</subsectionHeader>
<bodyText confidence="0.9982479375">
Once we have chosen a set of trigger-pairs, the next
step is to estimate a probability in lieu
of the translation probability in (1), and a
probability in (3).
Following the maximum likelihood approach pro-
posed by Tillman and Ney (1997), one could choose
the trigger probability to be based on the
unigram frequency of among Chinese word tokens
in that subset of aligned documents which have
in , namely
As an ad hoc alternative to (4), we also use
where we set whenever is not a
trigger-pair, and find it to be somewhat more effec-
tive (cf. Section 6.2). Thus (5) is used henceforth in
this paper. Analogous to (1), we set
and, again, we build the interpolated model
</bodyText>
<sectionHeader confidence="0.988944" genericHeader="method">
4 Topic-Dependent Language Models
</sectionHeader>
<bodyText confidence="0.997805">
The linear interpolation of the story-dependent un-
igram models (1) and (6) with a story-independent
; define via the
quency
and
Similarly define ,via the document fre-
document frequency , etc. Finally, let
trigram model, as described above, is very reminis-
cent of monolingual topic-dependent language mod-
els (cf. e.g. (Iyer and Ostendorf, 1999)). This moti-
vates us to construct topic-dependent LMs and con-
trast their performance with these models.
To this end, we represent each Chinese article in
the training corpus by a bag-of-words vector, and
cluster the vectors using a standard K-means algo-
rithm. We use random initialization to seed the al-
gorithm, and a standard TF-IDF weighted cosine-
similarity as the “metric” for clustering. We per-
form a few iterations of the K-means algorithm, and
deem the resulting clusters as representing differ-
ent topics. We then use a bag-of-words centroid
created from all the articles in a cluster to repre-
sent each topic. Topic-dependent trigram LMs, de-
noted , are also computed for each
topic exclusively from the articles in the -th cluster,
.
Each Mandarin test story is represented by a bag-
of-words vector generated from the first-
pass ASR output, and the topic-centroid having
the highest TF-IDF weighted cosine-similarity to it
is chosen as the topic of . Topic-dependent LMs
are then constructed for each story as
</bodyText>
<equation confidence="0.569013">
(8)
</equation>
<bodyText confidence="0.9393754">
and used in a second pass of recognition.
Alternatives to topic-dependent LMs for exploit-
ing long-range dependencies include cache LMs and
monolingual lexical triggers; both unlikely to be as
effective in the presence of significant ASR errors.
</bodyText>
<sectionHeader confidence="0.820512" genericHeader="method">
5 ASR Training and Test Corpora
</sectionHeader>
<bodyText confidence="0.997848576923077">
We investigate the use of the techniques described
above for improving ASR performance on Man-
darin news broadcasts using English newswire texts.
We have chosen the experimental ASR setup cre-
ated in the 2000 Johns Hopkins Summer Workshop
to study Mandarin pronunciation modeling, exten-
sive details about which are available in Fung et
al (2000). The acoustic training data ( 10 hours)
for their ASR system was obtained from the 1997
Mandarin Broadcast News distribution, and context-
dependent state-clustered models were estimated us-
ing initials and finals as subword units. Two Chinese
text corpora and an English corpus are used to esti-
mate LMs in our experiments. A vocabulary of
51K Chinese words, used in the ASR system, is also
used to segment the training text. This vocabulary
gives an OOV rate of 5% on the test data.
XINHUA: We use the Xinhua News corpus of
about 13 million words to represent the scenario
when the amount of available LM training text bor-
ders on adequate, and estimate a baseline trigram
LM for one set of experiments.
HUB-4NE: We also estimate a trigram model
from only the 96K words in the transcriptions used
for training acoustic models in our ASR system.
This corpus represents the scenario when little or no
additional text is available to train LMs.
NAB-TDT: English text contemporaneous with
the test data is often easily available. For our test set,
described below, we select (from the North Ameri-
can News Text corpus) articles published in 1997 in
The Los Angeles Times and The Washington Post,
and articles from 1998 in the New York Times and
the Associated Press news service (from TDT-2 cor-
pus). This amounts to a collection of roughly 45,000
articles containing about 30-million words of En-
glish text; a modest collection by CLIR standards.
Our ASR test set is a subset (Fung et al (2000))
of the NIST 1997 and 1998 HUB-4NE bench-
mark tests, containing Mandarin news broadcasts
from three sources for a total of about 9800 words.
We generate two sets of lattices using the baseline
acoustic models and bigram LMs estimated from
XINHUA and HUB-4NE. All our LMs are evaluated
by rescoring -best lists extracted from these two
sets of lattices. The -best lists from the XINHUA
bigram LM are used in all XINHUA experiments,
and those from the HUB-4NE bigram LM in all
HUB-4NE experiments. We report both word error
rates (WER) and character error rates (CER), the lat-
ter being independent of any difference in segmenta-
tion of the ASR output and reference transcriptions.
</bodyText>
<sectionHeader confidence="0.958014" genericHeader="method">
6 ASR Performance of Cross-Lingual LMs
</sectionHeader>
<bodyText confidence="0.9949321">
We begin by rescoring the -best lists from the
bigram lattices with trigram models. For each test
story , we perform CLIR using the first pass ASR
output to choose the most similar English docu-
ment from NAB-TDT. Then we create the cross-
lingual unigram model of (1). We also find the inter-
polation weight which maximizes the likelihood
of the 1-best hypotheses of all test utterances from
the first ASR pass. Table 1 shows the perplexity and
WER for XINHUA and HUB-4NE.
</bodyText>
<table confidence="0.9979164">
Language model Perp WER -value
XINHUA trigram 426 49.9% –
CL-interpolated 375 49.5% 0.208
HUB-4NE trigram 1195 60.1% –
CL-interpolated 750 59.3% 0.001
</table>
<tableCaption confidence="0.9704125">
Table 1: Word-Perplexity and ASR WER of LMs
based on single English document and global .
</tableCaption>
<bodyText confidence="0.9933629">
All -values reported in this paper are based on
the standard NIST MAPSSWE test (Pallett et al.,
1990), and indicate the statistical significance of a
WER improvement over the corresponding trigram
baseline, unless otherwise specified.
Evidently, the improvement brought by CL-
interpolated LM is not statistically significant on
XINHUA. On HUB-4NE however, where Chinese
text is scarce, the CL-interpolated LM delivers con-
siderable benefits via the large English corpus.
</bodyText>
<subsectionHeader confidence="0.916179">
6.1 Likelihood-Based Story-Specific Selection
of Interpolation Weights and the Number
of English Documents per Mandarin Story
</subsectionHeader>
<bodyText confidence="0.999366617647059">
The experiments above naively used the one most
similar English document for each Mandarin story,
and a global in (2), no matter how similar the best
matching English document is to a given Mandarin
news story. Rather than choosing one most simi-
lar English document from NAB-TDT, it stands to
reason that choosing more than one English docu-
ment may be helpful if many have a high similarity
score, and perhaps not using even the best matching
document may be fruitful if the match is sufficiently
poor. It may also help to have a greater interpola-
tion weight for stories with good matches, and a
smaller for others. For experiments in this sub-
section, we select a different for each test story,
again based on maximizing the likelihood of the -
best output given a CL-Unigram model. The other
issue then is the choice and the number of English
documents to translate.
-best documents: One could choose a predeter-
mined number of the best matching English doc-
uments for each Mandarin story. We experimented
with values of , , , , and , and found
that gave us the best LM performance,
but only marginally better than as described
above. Details are omitted, as they are uninteresting.
All documents above a similarity threshold:
The argument against always taking a predetermined
number of the best matching documents may be that
it ignores the goodness of the match. An alternative
is to take all English documents whose similarity to
a Mandarin story exceeds a certain predetermined
threshold. As this threshold is lowered, starting from
a high value, the order in which English documents
are selected for a particular Mandarin story is the
same as the order when choosing the -best docu-
ments, but the number of documents selected now
varies from story to story. It is possible that for
some stories, even the best matching English doc-
ument falls below the threshold at which other sto-
ries have found more than one good match. We ex-
perimented with various thresholds, and found that
while a threshold of gives us the lowest per-
plexity on the test set, the reduction is insignificant.
This points to the need for a story-specific strategy
for choosing the number of English documents, in-
stead of a global threshold.
Likelihood-based selection of the number of
English documents: Figure 2 shows the perplex-
ity of the reference transcriptions of one typical test
story under the LM (2) as a function of the number
of English documents chosen for creating (1). For
each choice of the number of English documents,
the interpolation weight in (2) is chosen to max-
imize the likelihood (also shown) of the first pass
output. This suggests that choosing the number of
English documents to maximize the likelihood of the
first pass ASR output is a good strategy.
For each Mandarin test story, we choose the
1000-best-matching English documents and divide
the dynamic range of their similarity scores evenly
into 10 intervals. Next, we choose the documents
in the top -th of the range of similarity scores,
not necessarily the top- documents, compute
, determine the in (2) that max-
imizes the likelihood of the first pass output of only
the utterances in that story, and record this likeli-
hood. We repeat this with documents in the top -th
of the range of similarity scores, the top -th, etc.,
</bodyText>
<figure confidence="0.966398071428571">
580 6.2 Comparison of Cross-Lingual Triggers
with Stochastic Translation Dictionaries
Perplexity of Reference
500
400
600
1−Best List
Reference
Once we select cross-lingual trigger-pairs as de-
570Besscribed in Section 3, in (1) is replaced by
of (5), and in (3) by List
− Log Likelihood of 1−Best List
550
150
</figure>
<figureCaption confidence="0.876057333333333">
Figure 2: Perplexity of the Reference Transcription
and the Likelihood of the ASR Output v/s Number
of for a Typical Test Story.
</figureCaption>
<bodyText confidence="0.99650285915493">
and obtain the likelihood as a function of the simi-
larity threshold. We choose the threshold that max-
imizes the likelihood of the first pass output. Thus
the number of English documents in (1), as well
as the interpolation weight in (2), are chosen dy-
namically for each Mandarin story to maximize the
likelihood of the ASR output. Table 2 shows ASR
results for this likelihood-based story-specific adap-
tation scheme.
Note that significant WER improvements are
obtained from the CL-interpolated LM using
likelihood-based story-specific adaptation even for
the case of the XINHUA LM. Furthermore, the per-
formance of the CL-interpolated LM is even better
than the topic-dependent LM. This is remarkable,
since the CL-interpolated LM is based on unigram
statistics from English documents, while the topic-
trigram LM is based on trigram statistics. We be-
lieve that the contemporaneous and story-specific
nature of the English document leads to its rela-
tively higher effectiveness. Our conjecture, that the
contemporaneous cross-lingual statistics and static
topic-trigram statistics are complementary, is sup-
ported by the significant further improvement in
WER obtained by the interpolation of the two LMs,
as shown on the last line for XINHUA.
The significant gain in ASR performance in the
resource deficient HUB-4NE case are obvious. The
small size of the HUB-4NE corpus makes topic-
models ineffective.
.
Therefore, given a set of cross-lingual trigger-pairs,
the trigger-based models are free from requiring
a translation lexicon. Furthermore, a document-
aligned comparable corpus is all that is required to
construct the set of trigger-pairs. We otherwise fol-
low the same experimental procedure as above.
As Table 2 shows, the trigger-based model (Trig-
interpolated) performs only slightly worse than the
CL-interpolated model. One explanation for this
degradation is that the CL-interpolated model is
trained from the sentence-aligned corpus while the
trigger-based model is from the document-aligned
corpus. There are two steps which could be affected
by this difference, one being CLIR and the other be-
ing the translation of the ’s into Chinese. Some
errors in CLIR may however be masked by our
likelihood-based story-specific adaptation scheme,
since it finds optimal retrieval settings, dynamically
adjusting the number of English documents as well
as the interpolation weight, even if CLIR performs
somewhat suboptimally. Furthermore, a document-
aligned corpus is much easier to build. Thus a much
bigger and more reliable comparable corpus may be
used, and eventually more accurate trigger-pairs will
be acquired.
We note with some satisfaction that even simple
trigger-pairs selected on the basis of mutual infor-
mation are able to achieve perplexity and WER re-
ductions comparable to a stochastic translation lex-
icon: the smallest -value at which the difference
between the WERs of the CL-interpolated LM and
the Trig-interpolated LM in Table 2 would be signif-
icant is for XINHUA and for HUB-4NE.
Triggers (4) vs (5): We compare the alternative
definitions (4) and (5) for replacing
in (1). The resulting CL-interpolated LM (2) yields a
perplexity of 370 on the XINHUA test set using (4),
compared to 367 using (5). Similarly, on the HUB-
4NE test set, using (4) yields 736, while (5) yields
727. Therefore, (5) has been used throughout.
</bodyText>
<page confidence="0.577983">
560
</page>
<table confidence="0.923292909090909">
3000 50 100
# En Doc (dE i )
XINHUA HUB-4NE
Perp WER CER -value Language model Perp WER CER -value
426 49.9% 28.8% – Baseline Trigram 1195 60.1% 44.1% –
381 49.1% 28.4% 0.003 Topic-trigram 1122 60.0% 44.1% 0.660
367 49.1% 28.6% 0.004 Trig-interpolated 727 58.8% 43.3% 0.001
346 48.8% 28.4% 0.001 CL-interpolated 630 58.8% 43.1% 0.001
340 48.7% 28.4% 0.001 Topic + Trig-interpolated 730 59.2% 43.5% 0.002
326 48.5% 28.2% 0.001 Topic + CL-interpolated 631 59.0% 43.3% 0.001
320 48.3% 28.1% 0.001 Topic + Trig- + CL-interp. 627 59.0% 43.3% 0.001
</table>
<tableCaption confidence="0.8023755">
Table 2: Perplexity and ASR Performance with a Likelihood-Based Story-Specific Selection of the Number
of English Documents ’s and Interpolation Weight for Each Mandarin Story.
</tableCaption>
<sectionHeader confidence="0.996058" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999997619047619">
We have demonstrated a statistically significant im-
provement in ASR WER (1.4% absolute) and in
perplexity (23%) by exploiting cross-lingual side-
information even when nontrivial amount of train-
ing data is available, as seen on the XINHUA cor-
pus. Our methods are even more effective when LM
training text is hard to come by in the language of
interest: 47% reduction in perplexity and 1.3% ab-
solute in WER as seen on the HUB-4NE corpus.
Most of these gains come from the optimal choice of
adaptation parameters. The ASR test data we used
in our experiments is derived from a different source
than the corpus on which the translation and trigger
models are trained, and the techniques work even
when the bilingual corpus is only document-aligned,
which is a realistic reflection of the situation in a
resource-deficient language.
We are developing maximum entropy models to
more effectively combine the multiple information
sources we have used in our experiments, and expect
to report the results in the near future.
</bodyText>
<sectionHeader confidence="0.999479" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999906533333333">
P. Brown, S. Della Pietra, V. Della Pietra, and R. Mercer.
1993. The mathematics of statistical machine trans-
lation: Parameter estimation. Computational Linguis-
tics, 19(2):269 – 311.
W. Byrne, P. Beyerlein, J. Huerta, S. Khudanpur,
B. Marthi, J. Morgan, N. Peterek, J. Picone, D. Ver-
gyri, and W. Wang. 2000. Towards language indepen-
dent acoustic modeling. In Proc. ICASSP, volume 2,
pages 1029 – 1032.
P. Fung et al. 2000. Pronunciation modeling of mandarin
casual speech. 2000 Johns Hopkins Summer Work-
shop.
D. Doermann et al. 2002. Lexicon acquisition from
bilingual dictionaries. In Proc. SPIE Photonic West
Article Imaging Conference, pages 37–48, San Jose,
CA.
R. Iyer and M. Ostendorf. 1999. Modeling long-distance
dependence in language: topic-mixtures vs dynamic
cache models. IEEE Transactions on Speech and Au-
dio Processing, 7:30–39.
S. Khudanpur and W. Kim. 2002. Using cross-language
cues for story-specific language modeling. In Proc.
ICSLP, volume 1, pages 513–516, Denver, CO.
F. J. Och and H. Ney. 2000. Improved statistical align-
ment models. In ACL00, pages 440–447, Hongkong,
China, October.
D. Pallett, W. Fisher, and J. Fiscus. 1990. Tools for
the analysis of benchmark speech recognition tests.
In Proc. ICASSP, volume 1, pages 97–100, Albur-
querque, NM.
R. Rosenfeld. 1996. A maximum entropy approach
to adaptive statistical language modeling. Computer,
Speech and Language, 10:187–228.
T. Schultz and A. Waibel. 1998. Language independent
and language adaptive large vocabulary speech recog-
nition. In Proc. ICSLP, volume 5, pages 1819–1822,
Sydney, Australia.
C. Tillmann and H. Ney. 1997. Word trigger and the em
algorithm. In Proceedings of the Workshop Computa-
tional Natural Language Learning (CoNLL 97), pages
117–124, Madrid, Spain.
D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. In-
ducing multilingual text analysis tools via robust pro-
jection across aligned corpora. In Proc. HLT 2001,
pages 109 – 116, San Francisco CA, USA.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.805097333333333">Cross-Lingual Lexical Triggers in Statistical Language Modeling Woosung The Johns Hopkins</title>
<address confidence="0.734267">3400 N. Charles St., Baltimore,</address>
<email confidence="0.999919">woosung@cs.jhu.edu</email>
<author confidence="0.673893">Sanjeev</author>
<affiliation confidence="0.612935">The Johns Hopkins</affiliation>
<address confidence="0.936582">3400 N. Charles St., Baltimore,</address>
<email confidence="0.999942">khudanpur@jhu.edu</email>
<abstract confidence="0.99921091440501">We propose new methods to take advantage of text in resource-rich languages to sharpen statistical language models in resource-deficient languages. We achieve this through an extension of the method of lexical triggers to the cross-language problem, and by developing a likelihoodbased adaptation scheme for combining a trigger model with an -gram model. We describe the application of such language models for automatic speech recognition. By exploiting a side-corpus of contemporaneous English news articles for adapting a static Chinese language model to transcribe Mandarin news stories, we demonstrate significant reductions in both perplexity and recognition errors. We also compare our cross-lingual adaptation scheme to monolingual language model adaptation, and to an alternate method for exploiting cross-lingual cues, via crosslingual information retrieval and machine translation, proposed elsewhere. 1 Data Sparseness in Language Modeling Statistical techniques have been remarkably successful in automatic speech recognition (ASR) and natural language processing (NLP) over the last two decades. This success, however, depends crucially research was supported by the National Science Foun- (via Grant ITR-0225656 and IIS-9982329) and the ofNaval Research (via Contract on the availability of accurate and large amounts of suitably annotated training data and it is difficult to build a usable statistical model in their absence. Most of the success, therefore, has been witnessed the so called More recently, there has been an increasing interest in languages such as Mandarin and Arabic for ASR and NLP, and data resources are being created for them at considerable cost. The data-resource bottleneck, however, is likely to remain for a majority of the world’s languages in the foreseeable future. Methods have been proposed to bootstrap acoustic models for ASR in resource deficient languages by reusing acoustic models from resource-rich languages (Schultz and Waibel, 1998; Byrne et al., 2000). Morphological analyzers, noun-phrase chunkers, POS taggers, etc., have also been developed for resource deficient languages by exploiting transor (Yarowsky et al., 2001). Khudanpur and Kim (2002) recently proposed using cross-lingual information retrieval (CLIR) and machine translation (MT) to improve a statistical language model (LM) in a resource-deficient language by exploiting copious amounts of text available in resource-rich languages. When transcribing a news story in a resource-deficient language, their core idea is to use the first pass output of a rudimentary ASR system as a query for CLIR, identify a contemporaneous English document on that news topic, followed by MT to provide a rough translation which, even if not fluent, is adequate to update estimates of word frequencies and the LM vocabulary. They report up to a 28% reduction in perplexity on Chinese text from the Hong Kong News corpus. In spite of their considerable success, some shortcomings remain in the method used by Khudanpur and Kim (2002). Specifically, stochastic translation lexicons estimated using the IBM method (Brown al., 1993) from a fairly large parallel corpus are used in their apa considerable demand for a deficient language. It is suggested that an easiercorpus may suffice, but no results are reported. Furthermore, for each Mandarin news story, the single best matching English article obtained via CLIR is translated and used for priming the Chinese LM, no matter how good the CLIR similarity, nor are other wellmatching English articles considered. This issue clearly deserves further attention. Finally, ASR results are not reported in their work, though their proposed solution is clearly motivated by an ASR task. We address these three issues in this paper. Section 2 begins, for the sake of completeness, with a review of the cross-lingual story-specific LM proposed by Khudanpur and Kim (2002). A notion of cross-lingual lexical triggers is proposed in Section 3, which overcomes the need for a sentencealigned parallel corpus for obtaining translation lexicons. After a brief detour to describe topicdependent LMs in Section 4, a description of the ASR task is provided in Section 5, and ASR results on Mandarin Broadcast News are presented in Section 6. The issue of how many English articles to retrieve and translate into Chinese is resolved by a likelihood-based scheme proposed in Section 6.1. 2 Cross-Lingual Story-Specific LMs For the sake of illustration, consider the task of sharpening a Chinese language model for transcribing Mandarin news stories by using a large corpus of contemporaneous English newswire text. Mandarin Chinese is, of course, not resource-deficient for language modeling 100s of millions of words are available on-line. However, we choose it for our experiments partly because it is sufficiently different from English to pose a real challenge, and because the availability of large text corpora in fact permits us to simulate controlled resource deficiency. denote the text of be transcribed by an ASR system, and let their corresponding or English newswire articles. Correspondence here does not imply that the English document needs to be an exact translation of the Mandarin story . It is quite adequate, for instance, if the two stories report the same news event. This approach is expected to be helpful even when the English document is merely on the same general topic as the Mandarin story, although the closer the content of a pair of articles the better the proposed methods are likely to work. Assume for the time being that a sufficiently good Chinese-English story alignment is given. Assume further that we have at our disposal a stochastic translation dictionary a probabilistic model of the form which provides the Chinese translation of each English word , where and respectively denote our Chinese and English vocabularies. 2.1 Computing a Cross-Lingual Unigram LM Let denote the relative frequency of a word in the document , , . It seems plausible that, , would be a good unigram model for the -th Mandarin story . We use this cross-lingual unigram statistic to sharpen a statistical Chinese LM used for processing the test story . One way to do this is via linear interpolation of the cross-lingual unigram model (1) with a static trigram model for Chinese, where the interpolation weight may be chosen off-line to maximize the likelihood of some held-out Mandarin stories. The improvement in (2) is expected from the fact that unlike the static text from which the Chinese trigram LM is estimated, is semantically close to even the adjustment of unigram statistics, based on a stochastic translation model, may help. Figure 1 shows the data flow in this cross-lingual LM adaptation approach, where the output of the first pass of an ASR system is used by a CLIR system to find an English document , an MT system Figure 1: Story-Specific Cross-Lingual Adaptation of a Chinese Language Model using English Text. computes the statistic of (1), and the ASR system uses the LM of (2) in a second pass. 2.2 Obtaining Matching English Documents illustrate how one may obtain the English document to match a Mandarin story , let that we also have a stochastic reversetranslation lexicon . One obtains from pass ASR output, cf. Figure 1, the relative frequency estimate of Chinese words in , , and uses the translation lexicon to compute, , (3) English bag-of-words representation of the Manstory as used in standard vector-based formation retrieval. The document with the highest TF-IDF weighted cosine-similarity to is selected: Readers familiar with information retrieval literawill recognize this to be the standard queryto CLIR. 2.3 Obtaining Stochastic Translation Lexicons The translation lexicons and may be created out of an available electronic translation lexicon, with multiple translations of a word being treated as equally likely. Stemming and other morphological analyses may be applied to increase the vocabulary-coverage of the translation lexicons. Alternately, they may also be obtained automatically from a parallel corpus of translated and sentence-aligned Chinese-English text using statistical machine translation techniques, such as the publicly available GIZA++ tools (Och and Ney, 2000), as done by Khudanpur and Kim (2002). Unlike standard MT systems, however, we apply the translation models to entire articles, one word at a time, to get a of translated words cf. (1) and (3). Finally, for truly resource deficient languages, one may obtain a translation lexicon via optical character recognition from a printed bilingual dictionary (cf. Doerman et al (2002)). This task is arguably easier than obtaining a large LM training corpus. 3 Cross-Lingual Lexical Triggers It seems plausible that most of the information one gets from the cross-lingual unigram LM of (1) is in the form of the altered statistics of topic-specific Chinese words conveyed by the statistics of contentbearing English words in the matching story. The translation lexicon used for obtaining the information, however, is an expensive resource. Yet, if one were only interested in the conditional distribution of Chinese words given some English words, there is no reason to require translation as an intermediate step. In a monolingual setting, the mutual information between lexical pairs co-occurring anywhere within a long “window” of each-other has been used to capture statistical dependencies not covered by -gram LMs (Rosenfeld, 1996; Tillmann and Ney, 1997). We use this inspiration to propose the following notion of cross-lingual lexical triggers. In a monolingual setting, a pair of words is considered a trigger-pair if, given a word-position in a sentence, the occurrence of in any of the preceding word-positions significantly alters the (conditional) probability that the following word in the is : is said to E.g. the occurof increases the probaof in the sentence. The set of preceding word-positions is variably defined to include all words from the beginning of the sentence, or document, or is limited to a fixed numsim ber of preceding words, limited of course by the beginning of the sentence, paragraph or document. In the cross-lingual setting, we consider a pair of words ,and , to be a if, given an English-Chinese pair of aligned documents, the occurrence of in the English document significantly alters the (conditional) probability that the word appears in the Chinese document: is said to trigger . It is plausible that translation-pairs will be natural candidates for trigger-pairs. It is, however, not necessary for a trigger-pair to also be a E.g., the occurrence of in the English document may trigger the Chinese of and posthe translations of By infering trigger-pairs from a documentaligned corpus of Chinese-English articles, we expect to be able to discover semanticallyor topicallyrelated pairs in addition to translation equivalences. 3.1 Identification of Cross-Lingual Triggers Average mutual information, which measures how much knowing the value of one random variable reduces the uncertainty of about another, has been used to identify trigger-pairs. We compute the average mutual information for every English-Chinese word pair as follows. , , now be a aligned training corpus of English-Chinese article Let denote the i.e., the number of aligned article-pairs, in which occurs in the English article and in the Chinese. denote the number of aligned articlepairs in which occurs in the English articles but not in the Chinese article. Let quantities and are similarly defined. Next let denote the number of articles in which occurs, and define We propose to select word pairs with high mutual information as cross-lingual lexical triggers. There are possible English-Chinese pairs which may be prohibitively large to search for the pairs with the highest mutual information. We filter out infrequent words in each language, words appearing less than 5 times, then measure for all possible pairs from the remaining words, sort them by , and select, say, the top 1 million pairs. 3.2 Estimating Trigger LM Probabilities Once we have chosen a set of trigger-pairs, the next step is to estimate a probability in lieu of the translation probability in (1), and a probability in (3). Following the maximum likelihood approach proposed by Tillman and Ney (1997), one could choose the trigger probability to be based on unigram frequency of among Chinese word tokens in that subset of aligned documents which in , namely As an ad hoc alternative to (4), we also use where we set whenever is not a trigger-pair, and find it to be somewhat more effective (cf. Section 6.2). Thus (5) is used henceforth in this paper. Analogous to (1), we set and, again, we build the interpolated model 4 Topic-Dependent Language Models The linear interpolation of the story-dependent unigram models (1) and (6) with a story-independent ; define via the quency and define ,via the document fredocument frequency , etc. Finally, let trigram model, as described above, is very reminiscent of monolingual topic-dependent language models (cf. e.g. (Iyer and Ostendorf, 1999)). This motivates us to construct topic-dependent LMs and contrast their performance with these models. To this end, we represent each Chinese article in the training corpus by a bag-of-words vector, and cluster the vectors using a standard K-means algorithm. We use random initialization to seed the algorithm, and a standard TF-IDF weighted cosinesimilarity as the “metric” for clustering. We perform a few iterations of the K-means algorithm, and deem the resulting clusters as representing differ- We then use a bag-of-words created from all the articles in a cluster to repreeach topic. Topic-dependent trigram LMs, denoted , are also computed for topic exclusively from the articles in the -th cluster, . Mandarin test story is represented by a bagvector generated from the pass ASR output, and the topic-centroid having the highest TF-IDF weighted cosine-similarity to it is chosen as the topic of . Topic-dependent LMs are then constructed for each story as (8) and used in a second pass of recognition. Alternatives to topic-dependent LMs for exploiting long-range dependencies include cache LMs and monolingual lexical triggers; both unlikely to be as effective in the presence of significant ASR errors. 5 ASR Training and Test Corpora We investigate the use of the techniques described above for improving ASR performance on Mandarin news broadcasts using English newswire texts. We have chosen the experimental ASR setup created in the 2000 Johns Hopkins Summer Workshop to study Mandarin pronunciation modeling, extensive details about which are available in Fung et al (2000). The acoustic training data ( 10 hours) for their ASR system was obtained from the 1997 Mandarin Broadcast News distribution, and contextdependent state-clustered models were estimated using initials and finals as subword units. Two Chinese text corpora and an English corpus are used to estimate LMs in our experiments. A vocabulary of 51K Chinese words, used in the ASR system, is also used to segment the training text. This vocabulary gives an OOV rate of 5% on the test data. We use the Xinhua News corpus of about 13 million words to represent the scenario when the amount of available LM training text borders on adequate, and estimate a baseline trigram LM for one set of experiments. We also estimate a trigram model 96K words in the transcriptions used for training acoustic models in our ASR system. This corpus represents the scenario when little or no additional text is available to train LMs. English text contemporaneous with the test data is often easily available. For our test set, below, we select (from the North American News Text corpus) articles published in 1997 in The Los Angeles Times and The Washington Post, and articles from 1998 in the New York Times and the Associated Press news service (from TDT-2 corpus). This amounts to a collection of roughly 45,000 articles containing about 30-million words of English text; a modest collection by CLIR standards. Our ASR test set is a subset (Fung et al (2000)) the NIST 1997 and 1998 HUB-4NE benchmark tests, containing Mandarin news broadcasts from three sources for a total of about 9800 words. We generate two sets of lattices using the baseline models and estimated from XINHUA and HUB-4NE. All our LMs are evaluated by rescoring -best lists extracted from these two sets of lattices. The -best lists from the XINHUA bigram LM are used in all XINHUA experiments, and those from the HUB-4NE bigram LM in all HUB-4NE experiments. We report both word error rates (WER) and character error rates (CER), the latter being independent of any difference in segmentation of the ASR output and reference transcriptions. 6 ASR Performance of Cross-Lingual LMs We begin by rescoring the -best lists from the bigram lattices with trigram models. For each test story , we perform CLIR using the first pass ASR output to choose the most similar English docufrom NAB-TDT. Then we create the crosslingual unigram model of (1). We also find the interpolation weight which maximizes the likelihood of the 1-best hypotheses of all test utterances from the first ASR pass. Table 1 shows the perplexity and WER for XINHUA and HUB-4NE. Language model Perp WER -value XINHUA trigram 426 49.9% – CL-interpolated 375 49.5% 0.208 HUB-4NE trigram 1195 60.1% – CL-interpolated 750 59.3% 0.001 Table 1: Word-Perplexity and ASR WER of LMs based on single English document and global . All -values reported in this paper are based on the standard NIST MAPSSWE test (Pallett et al., 1990), and indicate the statistical significance of a WER improvement over the corresponding trigram baseline, unless otherwise specified. Evidently, the improvement brought by CLinterpolated LM is not statistically significant on XINHUA. On HUB-4NE however, where Chinese text is scarce, the CL-interpolated LM delivers considerable benefits via the large English corpus. 6.1 Likelihood-Based Story-Specific Selection of Interpolation Weights and the Number of English Documents per Mandarin Story The experiments above naively used the one most similar English document for each Mandarin story, and a global in (2), no matter how similar the best matching English document is to a given Mandarin news story. Rather than choosing one most similar English document from NAB-TDT, it stands to reason that choosing more than one English document may be helpful if many have a high similarity score, and perhaps not using even the best matching document may be fruitful if the match is sufficiently poor. It may also help to have a greater interpolation weight for stories with good matches, and a smaller for others. For experiments in this subsection, we select a different for each test story, again based on maximizing the likelihood of the best output given a CL-Unigram model. The other issue then is the choice and the number of English documents to translate. One could choose a predeternumber of the best matching English documents for each Mandarin story. We experimented with values of , , , , and , and found that gave us the best LM performance, but only marginally better than as described above. Details are omitted, as they are uninteresting. documents above a similarity The argument against always taking a predetermined number of the best matching documents may be that it ignores the goodness of the match. An alternative is to take all English documents whose similarity to a Mandarin story exceeds a certain predetermined threshold. As this threshold is lowered, starting from high value, the which English documents are selected for a particular Mandarin story is the same as the order when choosing the -best documents, but the number of documents selected now varies from story to story. It is possible that for some stories, even the best matching English document falls below the threshold at which other stories have found more than one good match. We experimented with various thresholds, and found that a threshold of gives us the lowest plexity on the test set, the reduction is insignificant. This points to the need for a story-specific strategy for choosing the number of English documents, instead of a global threshold. Likelihood-based selection of the number of Figure 2 shows the perplexity of the reference transcriptions of one typical test story under the LM (2) as a function of the number of English documents chosen for creating (1). For each choice of the number of English documents, the interpolation weight in (2) is chosen to maximize the likelihood (also shown) of the first pass output. This suggests that choosing the number of English documents to maximize the likelihood of the first pass ASR output is a good strategy. For each Mandarin test story, we choose the 1000-best-matching English documents and divide range their similarity scores evenly into 10 intervals. Next, we choose the documents the top -th of the of similarity not necessarily the topdocuments, , determine the in (2) that maximizes the likelihood of the first pass output of only the utterances in that story, and record this likelihood. We repeat this with documents in the top -th of the range of similarity scores, the top -th, etc.,</abstract>
<title confidence="0.8203745">Comparison of Cross-Lingual Triggers with Stochastic Translation Dictionaries</title>
<note confidence="0.517414923076923">Perplexity of Reference 500 400 600 1−Best List Reference we select cross-lingual trigger-pairs as dein Section 3, in (1) is replaced by of (5), and in (3) by List − Log Likelihood of 1−Best List 550 150 Figure 2: Perplexity of the Reference Transcription</note>
<abstract confidence="0.984819180555555">and the Likelihood of the ASR Output v/s Number of for a Typical Test Story. and obtain the likelihood as a function of the similarity threshold. We choose the threshold that maximizes the likelihood of the first pass output. Thus the number of English documents in (1), as as the interpolation weight in (2), are chosen dynamically for each Mandarin story to maximize the likelihood of the ASR output. Table 2 shows ASR for this story-specific adap- Note that significant WER improvements are obtained from the CL-interpolated LM using likelihood-based story-specific adaptation even for the case of the XINHUA LM. Furthermore, the performance of the CL-interpolated LM is even better than the topic-dependent LM. This is remarkable, since the CL-interpolated LM is based on unigram statistics from English documents, while the topictrigram LM is based on trigram statistics. We believe that the contemporaneous and story-specific nature of the English document leads to its relatively higher effectiveness. Our conjecture, that the statistics and topic-trigram statistics are complementary, is supported by the significant further improvement in WER obtained by the interpolation of the two LMs, as shown on the last line for XINHUA. The significant gain in ASR performance in the resource deficient HUB-4NE case are obvious. The small size of the HUB-4NE corpus makes topicmodels ineffective. . Therefore, given a set of cross-lingual trigger-pairs, the trigger-based models are free from requiring a translation lexicon. Furthermore, a documentaligned comparable corpus is all that is required to construct the set of trigger-pairs. We otherwise follow the same experimental procedure as above. As Table 2 shows, the trigger-based model (Triginterpolated) performs only slightly worse than the CL-interpolated model. One explanation for this degradation is that the CL-interpolated model is trained from the sentence-aligned corpus while the trigger-based model is from the document-aligned corpus. There are two steps which could be affected this difference, one being CLIR and the other being the translation of the ’s into Chinese. errors in CLIR may however be masked by our story-specific adaptation since it finds optimal retrieval settings, dynamically adjusting the number of English documents as well as the interpolation weight, even if CLIR performs somewhat suboptimally. Furthermore, a documentaligned corpus is much easier to build. Thus a much bigger and more reliable comparable corpus may be used, and eventually more accurate trigger-pairs will be acquired. We note with some satisfaction that even simple trigger-pairs selected on the basis of mutual information are able to achieve perplexity and WER reductions comparable to a stochastic translation lexicon: the smallest -value at which the difference between the WERs of the CL-interpolated LM and the Trig-interpolated LM in Table 2 would be significant is for XINHUA and for HUB-4NE. (4) vs (5): compare the alternative definitions (4) and (5) for replacing in (1). The resulting CL-interpolated LM (2) yields a perplexity of 370 on the XINHUA test set using (4), compared to 367 using (5). Similarly, on the HUB- 4NE test set, using (4) yields 736, while (5) yields 727. Therefore, (5) has been used throughout.</abstract>
<address confidence="0.382938">560</address>
<phone confidence="0.658814">50 100</phone>
<affiliation confidence="0.544455333333333">En Doc i) XINHUA HUB-4NE Perp WER CER -value Language model Perp WER CER -value</affiliation>
<address confidence="0.944556">426 49.9% 28.8% – Baseline Trigram 1195 60.1% 44.1% – 381 49.1% 28.4% 0.003 Topic-trigram 1122 60.0% 44.1% 0.660 367 49.1% 28.6% 0.004 Trig-interpolated 727 58.8% 43.3% 0.001 346 48.8% 28.4% 0.001 CL-interpolated 630 58.8% 43.1% 0.001 340 48.7% 28.4% 0.001 Topic + Trig-interpolated 730 59.2% 43.5% 0.002 326 48.5% 28.2% 0.001 Topic + CL-interpolated 631 59.0% 43.3% 0.001</address>
<phone confidence="0.485683">320 48.3% 28.1% 0.001 Topic + Trig- + CL-interp. 627 59.0% 43.3% 0.001</phone>
<abstract confidence="0.991752">Table 2: Perplexity and ASR Performance with a Likelihood-Based Story-Specific Selection of the Number of English Documents ’s and Interpolation Weight for Each Mandarin Story. 7 Conclusions and Future Work We have demonstrated a statistically significant improvement in ASR WER (1.4% absolute) and in perplexity (23%) by exploiting cross-lingual sideinformation even when nontrivial amount of training data is available, as seen on the XINHUA corpus. Our methods are even more effective when LM training text is hard to come by in the language of interest: 47% reduction in perplexity and 1.3% absolute in WER as seen on the HUB-4NE corpus. Most of these gains come from the optimal choice of adaptation parameters. The ASR test data we used in our experiments is derived from a different source than the corpus on which the translation and trigger models are trained, and the techniques work even when the bilingual corpus is only document-aligned, which is a realistic reflection of the situation in a resource-deficient language. We are developing maximum entropy models to more effectively combine the multiple information sources we have used in our experiments, and expect to report the results in the near future.</abstract>
<note confidence="0.4736836">References P. Brown, S. Della Pietra, V. Della Pietra, and R. Mercer. 1993. The mathematics of statistical machine trans- Parameter estimation. Linguis- 19(2):269 – 311.</note>
<author confidence="0.7363775">W Byrne</author>
<author confidence="0.7363775">P Beyerlein</author>
<author confidence="0.7363775">J Huerta</author>
<author confidence="0.7363775">S Khudanpur</author>
<author confidence="0.7363775">B Marthi</author>
<author confidence="0.7363775">J Morgan</author>
<author confidence="0.7363775">N Peterek</author>
<author confidence="0.7363775">J Picone</author>
<author confidence="0.7363775">D Ver-</author>
<abstract confidence="0.855631">gyri, and W. Wang. 2000. Towards language indepenacoustic modeling. In volume 2, pages 1029 – 1032. P. Fung et al. 2000. Pronunciation modeling of mandarin speech. Johns Hopkins Summer Work- D. Doermann et al. 2002. Lexicon acquisition from dictionaries. In SPIE Photonic West Imaging pages 37–48, San Jose, CA. R. Iyer and M. Ostendorf. 1999. Modeling long-distance dependence in language: topic-mixtures vs dynamic models. Transactions on Speech and Au- 7:30–39. S. Khudanpur and W. Kim. 2002. Using cross-language for story-specific language modeling. In</abstract>
<note confidence="0.709763666666667">volume 1, pages 513–516, Denver, CO. F. J. Och and H. Ney. 2000. Improved statistical alignmodels. In pages 440–447, Hongkong,</note>
<address confidence="0.650611">China, October.</address>
<author confidence="0.425899">Tools for</author>
<abstract confidence="0.97932775">the analysis of benchmark speech recognition tests. volume 1, pages 97–100, Alburquerque, NM. R. Rosenfeld. 1996. A maximum entropy approach adaptive statistical language modeling. and 10:187–228. T. Schultz and A. Waibel. 1998. Language independent and language adaptive large vocabulary speech recog-</abstract>
<note confidence="0.626600285714286">In volume 5, pages 1819–1822, Sydney, Australia. C. Tillmann and H. Ney. 1997. Word trigger and the em In of the Workshop Computa- Natural Language Learning (CoNLL pages 117–124, Madrid, Spain. D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. In-</note>
<abstract confidence="0.574173">ducing multilingual text analysis tools via robust proacross aligned corpora. In HLT</abstract>
<address confidence="0.841996">pages 109 – 116, San Francisco CA, USA.</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Brown</author>
<author>S Della Pietra</author>
<author>V Della Pietra</author>
<author>R Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>311</pages>
<contexts>
<context position="3499" citStr="Brown et al., 1993" startWordPosition="522" endWordPosition="525">ge, their core idea is to use the first pass output of a rudimentary ASR system as a query for CLIR, identify a contemporaneous English document on that news topic, followed by MT to provide a rough translation which, even if not fluent, is adequate to update estimates of word frequencies and the LM vocabulary. They report up to a 28% reduction in perplexity on Chinese text from the Hong Kong News corpus. In spite of their considerable success, some shortcomings remain in the method used by Khudanpur and Kim (2002). Specifically, stochastic translation lexicons estimated using the IBM method (Brown et al., 1993) from a fairly large sentence-aligned Chinese-English parallel corpus are used in their approach a considerable demand for a resourcedeficient language. It is suggested that an easierto-obtain document-aligned comparable corpus may suffice, but no results are reported. Furthermore, for each Mandarin news story, the single best matching English article obtained via CLIR is translated and used for priming the Chinese LM, no matter how good the CLIR similarity, nor are other wellmatching English articles considered. This issue clearly deserves further attention. Finally, ASR results are not repor</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. Brown, S. Della Pietra, V. Della Pietra, and R. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):269 – 311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Byrne</author>
<author>P Beyerlein</author>
<author>J Huerta</author>
<author>S Khudanpur</author>
<author>B Marthi</author>
<author>J Morgan</author>
<author>N Peterek</author>
<author>J Picone</author>
<author>D Vergyri</author>
<author>W Wang</author>
</authors>
<title>Towards language independent acoustic modeling.</title>
<date>2000</date>
<booktitle>In Proc. ICASSP,</booktitle>
<volume>2</volume>
<pages>1029--1032</pages>
<contexts>
<context position="2351" citStr="Byrne et al., 2000" startWordPosition="340" endWordPosition="343">odel in their absence. Most of the success, therefore, has been witnessed in the so called resource-rich languages. More recently, there has been an increasing interest in languages such as Mandarin and Arabic for ASR and NLP, and data resources are being created for them at considerable cost. The data-resource bottleneck, however, is likely to remain for a majority of the world’s languages in the foreseeable future. Methods have been proposed to bootstrap acoustic models for ASR in resource deficient languages by reusing acoustic models from resource-rich languages (Schultz and Waibel, 1998; Byrne et al., 2000). Morphological analyzers, noun-phrase chunkers, POS taggers, etc., have also been developed for resource deficient languages by exploiting translated or parallel text (Yarowsky et al., 2001). Khudanpur and Kim (2002) recently proposed using cross-lingual information retrieval (CLIR) and machine translation (MT) to improve a statistical language model (LM) in a resource-deficient language by exploiting copious amounts of text available in resource-rich languages. When transcribing a news story in a resource-deficient language, their core idea is to use the first pass output of a rudimentary AS</context>
</contexts>
<marker>Byrne, Beyerlein, Huerta, Khudanpur, Marthi, Morgan, Peterek, Picone, Vergyri, Wang, 2000</marker>
<rawString>W. Byrne, P. Beyerlein, J. Huerta, S. Khudanpur, B. Marthi, J. Morgan, N. Peterek, J. Picone, D. Vergyri, and W. Wang. 2000. Towards language independent acoustic modeling. In Proc. ICASSP, volume 2, pages 1029 – 1032.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Fung</author>
</authors>
<title>Pronunciation modeling of mandarin casual speech.</title>
<date>2000</date>
<marker>Fung, 2000</marker>
<rawString>P. Fung et al. 2000. Pronunciation modeling of mandarin casual speech. 2000 Johns Hopkins Summer Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Doermann</author>
</authors>
<title>Lexicon acquisition from bilingual dictionaries.</title>
<date>2002</date>
<booktitle>In Proc. SPIE Photonic West Article Imaging Conference,</booktitle>
<pages>37--48</pages>
<location>San Jose, CA.</location>
<marker>Doermann, 2002</marker>
<rawString>D. Doermann et al. 2002. Lexicon acquisition from bilingual dictionaries. In Proc. SPIE Photonic West Article Imaging Conference, pages 37–48, San Jose, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Iyer</author>
<author>M Ostendorf</author>
</authors>
<title>Modeling long-distance dependence in language: topic-mixtures vs dynamic cache models.</title>
<date>1999</date>
<booktitle>IEEE Transactions on Speech and Audio Processing,</booktitle>
<pages>7--30</pages>
<contexts>
<context position="14319" citStr="Iyer and Ostendorf, 1999" startWordPosition="2269" endWordPosition="2272">ternative to (4), we also use where we set whenever is not a trigger-pair, and find it to be somewhat more effective (cf. Section 6.2). Thus (5) is used henceforth in this paper. Analogous to (1), we set and, again, we build the interpolated model 4 Topic-Dependent Language Models The linear interpolation of the story-dependent unigram models (1) and (6) with a story-independent ; define via the quency and Similarly define ,via the document fredocument frequency , etc. Finally, let trigram model, as described above, is very reminiscent of monolingual topic-dependent language models (cf. e.g. (Iyer and Ostendorf, 1999)). This motivates us to construct topic-dependent LMs and contrast their performance with these models. To this end, we represent each Chinese article in the training corpus by a bag-of-words vector, and cluster the vectors using a standard K-means algorithm. We use random initialization to seed the algorithm, and a standard TF-IDF weighted cosinesimilarity as the “metric” for clustering. We perform a few iterations of the K-means algorithm, and deem the resulting clusters as representing different topics. We then use a bag-of-words centroid created from all the articles in a cluster to repres</context>
</contexts>
<marker>Iyer, Ostendorf, 1999</marker>
<rawString>R. Iyer and M. Ostendorf. 1999. Modeling long-distance dependence in language: topic-mixtures vs dynamic cache models. IEEE Transactions on Speech and Audio Processing, 7:30–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Khudanpur</author>
<author>W Kim</author>
</authors>
<title>Using cross-language cues for story-specific language modeling.</title>
<date>2002</date>
<booktitle>In Proc. ICSLP,</booktitle>
<volume>1</volume>
<pages>513--516</pages>
<location>Denver, CO.</location>
<contexts>
<context position="2568" citStr="Khudanpur and Kim (2002)" startWordPosition="371" endWordPosition="375">r ASR and NLP, and data resources are being created for them at considerable cost. The data-resource bottleneck, however, is likely to remain for a majority of the world’s languages in the foreseeable future. Methods have been proposed to bootstrap acoustic models for ASR in resource deficient languages by reusing acoustic models from resource-rich languages (Schultz and Waibel, 1998; Byrne et al., 2000). Morphological analyzers, noun-phrase chunkers, POS taggers, etc., have also been developed for resource deficient languages by exploiting translated or parallel text (Yarowsky et al., 2001). Khudanpur and Kim (2002) recently proposed using cross-lingual information retrieval (CLIR) and machine translation (MT) to improve a statistical language model (LM) in a resource-deficient language by exploiting copious amounts of text available in resource-rich languages. When transcribing a news story in a resource-deficient language, their core idea is to use the first pass output of a rudimentary ASR system as a query for CLIR, identify a contemporaneous English document on that news topic, followed by MT to provide a rough translation which, even if not fluent, is adequate to update estimates of word frequencie</context>
<context position="4368" citStr="Khudanpur and Kim (2002)" startWordPosition="659" endWordPosition="662">no results are reported. Furthermore, for each Mandarin news story, the single best matching English article obtained via CLIR is translated and used for priming the Chinese LM, no matter how good the CLIR similarity, nor are other wellmatching English articles considered. This issue clearly deserves further attention. Finally, ASR results are not reported in their work, though their proposed solution is clearly motivated by an ASR task. We address these three issues in this paper. Section 2 begins, for the sake of completeness, with a review of the cross-lingual story-specific LM proposed by Khudanpur and Kim (2002). A notion of cross-lingual lexical triggers is proposed in Section 3, which overcomes the need for a sentencealigned parallel corpus for obtaining translation lexicons. After a brief detour to describe topicdependent LMs in Section 4, a description of the ASR task is provided in Section 5, and ASR results on Mandarin Broadcast News are presented in Section 6. The issue of how many English articles to retrieve and translate into Chinese is resolved by a likelihood-based scheme proposed in Section 6.1. 2 Cross-Lingual Story-Specific LMs For the sake of illustration, consider the task of sharpen</context>
<context position="8871" citStr="Khudanpur and Kim (2002)" startWordPosition="1400" endWordPosition="1403">o CLIR. 2.3 Obtaining Stochastic Translation Lexicons The translation lexicons and may be created out of an available electronic translation lexicon, with multiple translations of a word being treated as equally likely. Stemming and other morphological analyses may be applied to increase the vocabulary-coverage of the translation lexicons. Alternately, they may also be obtained automatically from a parallel corpus of translated and sentence-aligned Chinese-English text using statistical machine translation techniques, such as the publicly available GIZA++ tools (Och and Ney, 2000), as done by Khudanpur and Kim (2002). Unlike standard MT systems, however, we apply the translation models to entire articles, one word at a time, to get a bag of translated words — cf. (1) and (3). Finally, for truly resource deficient languages, one may obtain a translation lexicon via optical character recognition from a printed bilingual dictionary (cf. Doerman et al (2002)). This task is arguably easier than obtaining a large LM training corpus. 3 Cross-Lingual Lexical Triggers It seems plausible that most of the information one gets from the cross-lingual unigram LM of (1) is in the form of the altered statistics of topic-</context>
</contexts>
<marker>Khudanpur, Kim, 2002</marker>
<rawString>S. Khudanpur and W. Kim. 2002. Using cross-language cues for story-specific language modeling. In Proc. ICSLP, volume 1, pages 513–516, Denver, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In ACL00,</booktitle>
<pages>440--447</pages>
<location>Hongkong, China,</location>
<contexts>
<context position="8834" citStr="Och and Ney, 2000" startWordPosition="1393" endWordPosition="1396">ard querytranslation approach to CLIR. 2.3 Obtaining Stochastic Translation Lexicons The translation lexicons and may be created out of an available electronic translation lexicon, with multiple translations of a word being treated as equally likely. Stemming and other morphological analyses may be applied to increase the vocabulary-coverage of the translation lexicons. Alternately, they may also be obtained automatically from a parallel corpus of translated and sentence-aligned Chinese-English text using statistical machine translation techniques, such as the publicly available GIZA++ tools (Och and Ney, 2000), as done by Khudanpur and Kim (2002). Unlike standard MT systems, however, we apply the translation models to entire articles, one word at a time, to get a bag of translated words — cf. (1) and (3). Finally, for truly resource deficient languages, one may obtain a translation lexicon via optical character recognition from a printed bilingual dictionary (cf. Doerman et al (2002)). This task is arguably easier than obtaining a large LM training corpus. 3 Cross-Lingual Lexical Triggers It seems plausible that most of the information one gets from the cross-lingual unigram LM of (1) is in the for</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F. J. Och and H. Ney. 2000. Improved statistical alignment models. In ACL00, pages 440–447, Hongkong, China, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Pallett</author>
<author>W Fisher</author>
<author>J Fiscus</author>
</authors>
<title>Tools for the analysis of benchmark speech recognition tests.</title>
<date>1990</date>
<booktitle>In Proc. ICASSP,</booktitle>
<volume>1</volume>
<pages>97--100</pages>
<location>Alburquerque, NM.</location>
<contexts>
<context position="18971" citStr="Pallett et al., 1990" startWordPosition="3052" endWordPosition="3055">ocument from NAB-TDT. Then we create the crosslingual unigram model of (1). We also find the interpolation weight which maximizes the likelihood of the 1-best hypotheses of all test utterances from the first ASR pass. Table 1 shows the perplexity and WER for XINHUA and HUB-4NE. Language model Perp WER -value XINHUA trigram 426 49.9% – CL-interpolated 375 49.5% 0.208 HUB-4NE trigram 1195 60.1% – CL-interpolated 750 59.3% 0.001 Table 1: Word-Perplexity and ASR WER of LMs based on single English document and global . All -values reported in this paper are based on the standard NIST MAPSSWE test (Pallett et al., 1990), and indicate the statistical significance of a WER improvement over the corresponding trigram baseline, unless otherwise specified. Evidently, the improvement brought by CLinterpolated LM is not statistically significant on XINHUA. On HUB-4NE however, where Chinese text is scarce, the CL-interpolated LM delivers considerable benefits via the large English corpus. 6.1 Likelihood-Based Story-Specific Selection of Interpolation Weights and the Number of English Documents per Mandarin Story The experiments above naively used the one most similar English document for each Mandarin story, and a gl</context>
</contexts>
<marker>Pallett, Fisher, Fiscus, 1990</marker>
<rawString>D. Pallett, W. Fisher, and J. Fiscus. 1990. Tools for the analysis of benchmark speech recognition tests. In Proc. ICASSP, volume 1, pages 97–100, Alburquerque, NM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rosenfeld</author>
</authors>
<title>A maximum entropy approach to adaptive statistical language modeling.</title>
<date>1996</date>
<journal>Computer, Speech and Language,</journal>
<pages>10--187</pages>
<contexts>
<context position="10067" citStr="Rosenfeld, 1996" startWordPosition="1593" endWordPosition="1594">tatistics of topic-specific Chinese words conveyed by the statistics of contentbearing English words in the matching story. The translation lexicon used for obtaining the information, however, is an expensive resource. Yet, if one were only interested in the conditional distribution of Chinese words given some English words, there is no reason to require translation as an intermediate step. In a monolingual setting, the mutual information between lexical pairs co-occurring anywhere within a long “window” of each-other has been used to capture statistical dependencies not covered by -gram LMs (Rosenfeld, 1996; Tillmann and Ney, 1997). We use this inspiration to propose the following notion of cross-lingual lexical triggers. In a monolingual setting, a pair of words is considered a trigger-pair if, given a word-position in a sentence, the occurrence of in any of the preceding word-positions significantly alters the (conditional) probability that the following word in the sentence is : is said to trigger . E.g. the occurrence of either significantly increases the probability of or subsequently in the sentence. The set of preceding word-positions is variably defined to include all words from the begi</context>
</contexts>
<marker>Rosenfeld, 1996</marker>
<rawString>R. Rosenfeld. 1996. A maximum entropy approach to adaptive statistical language modeling. Computer, Speech and Language, 10:187–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Schultz</author>
<author>A Waibel</author>
</authors>
<title>Language independent and language adaptive large vocabulary speech recognition.</title>
<date>1998</date>
<booktitle>In Proc. ICSLP,</booktitle>
<volume>5</volume>
<pages>1819--1822</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="2330" citStr="Schultz and Waibel, 1998" startWordPosition="336" endWordPosition="339">ild a usable statistical model in their absence. Most of the success, therefore, has been witnessed in the so called resource-rich languages. More recently, there has been an increasing interest in languages such as Mandarin and Arabic for ASR and NLP, and data resources are being created for them at considerable cost. The data-resource bottleneck, however, is likely to remain for a majority of the world’s languages in the foreseeable future. Methods have been proposed to bootstrap acoustic models for ASR in resource deficient languages by reusing acoustic models from resource-rich languages (Schultz and Waibel, 1998; Byrne et al., 2000). Morphological analyzers, noun-phrase chunkers, POS taggers, etc., have also been developed for resource deficient languages by exploiting translated or parallel text (Yarowsky et al., 2001). Khudanpur and Kim (2002) recently proposed using cross-lingual information retrieval (CLIR) and machine translation (MT) to improve a statistical language model (LM) in a resource-deficient language by exploiting copious amounts of text available in resource-rich languages. When transcribing a news story in a resource-deficient language, their core idea is to use the first pass outpu</context>
</contexts>
<marker>Schultz, Waibel, 1998</marker>
<rawString>T. Schultz and A. Waibel. 1998. Language independent and language adaptive large vocabulary speech recognition. In Proc. ICSLP, volume 5, pages 1819–1822, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Tillmann</author>
<author>H Ney</author>
</authors>
<title>Word trigger and the em algorithm.</title>
<date>1997</date>
<booktitle>In Proceedings of the Workshop Computational Natural Language Learning (CoNLL 97),</booktitle>
<pages>117--124</pages>
<location>Madrid,</location>
<contexts>
<context position="10092" citStr="Tillmann and Ney, 1997" startWordPosition="1595" endWordPosition="1598">c-specific Chinese words conveyed by the statistics of contentbearing English words in the matching story. The translation lexicon used for obtaining the information, however, is an expensive resource. Yet, if one were only interested in the conditional distribution of Chinese words given some English words, there is no reason to require translation as an intermediate step. In a monolingual setting, the mutual information between lexical pairs co-occurring anywhere within a long “window” of each-other has been used to capture statistical dependencies not covered by -gram LMs (Rosenfeld, 1996; Tillmann and Ney, 1997). We use this inspiration to propose the following notion of cross-lingual lexical triggers. In a monolingual setting, a pair of words is considered a trigger-pair if, given a word-position in a sentence, the occurrence of in any of the preceding word-positions significantly alters the (conditional) probability that the following word in the sentence is : is said to trigger . E.g. the occurrence of either significantly increases the probability of or subsequently in the sentence. The set of preceding word-positions is variably defined to include all words from the beginning of the sentence, pa</context>
</contexts>
<marker>Tillmann, Ney, 1997</marker>
<rawString>C. Tillmann and H. Ney. 1997. Word trigger and the em algorithm. In Proceedings of the Workshop Computational Natural Language Learning (CoNLL 97), pages 117–124, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>G Ngai</author>
<author>R Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora. In</title>
<date>2001</date>
<booktitle>Proc. HLT</booktitle>
<pages>109--116</pages>
<location>San Francisco CA, USA.</location>
<contexts>
<context position="2542" citStr="Yarowsky et al., 2001" startWordPosition="367" endWordPosition="370">s Mandarin and Arabic for ASR and NLP, and data resources are being created for them at considerable cost. The data-resource bottleneck, however, is likely to remain for a majority of the world’s languages in the foreseeable future. Methods have been proposed to bootstrap acoustic models for ASR in resource deficient languages by reusing acoustic models from resource-rich languages (Schultz and Waibel, 1998; Byrne et al., 2000). Morphological analyzers, noun-phrase chunkers, POS taggers, etc., have also been developed for resource deficient languages by exploiting translated or parallel text (Yarowsky et al., 2001). Khudanpur and Kim (2002) recently proposed using cross-lingual information retrieval (CLIR) and machine translation (MT) to improve a statistical language model (LM) in a resource-deficient language by exploiting copious amounts of text available in resource-rich languages. When transcribing a news story in a resource-deficient language, their core idea is to use the first pass output of a rudimentary ASR system as a query for CLIR, identify a contemporaneous English document on that news topic, followed by MT to provide a rough translation which, even if not fluent, is adequate to update es</context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proc. HLT 2001, pages 109 – 116, San Francisco CA, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>