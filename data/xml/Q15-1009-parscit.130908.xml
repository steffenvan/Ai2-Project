<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.982407">
Exploiting Parallel News Streams for Unsupervised Event Extraction
</title>
<author confidence="0.979288">
Congle Zhang, Stephen Soderland &amp; Daniel S. Weld
</author>
<affiliation confidence="0.9905155">
Computer Science &amp; Engineering
University of Washington
</affiliation>
<address confidence="0.582641">
Seattle, WA 98195, USA
</address>
<email confidence="0.987556">
{clzhang, soderlan, weld}@cs.washington.edu
</email>
<sectionHeader confidence="0.993757" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999892037037037">
Most approaches to relation extraction, the
task of extracting ground facts from natural
language text, are based on machine learning
and thus starved by scarce training data. Man-
ual annotation is too expensive to scale to a
comprehensive set of relations. Distant super-
vision, which automatically creates training
data, only works with relations that already
populate a knowledge base (KB). Unfortu-
nately, KBs such as FreeBase rarely cover
event relations (e.g. “person travels to loca-
tion”). Thus, the problem of extracting a wide
range of events — e.g., from news streams —
is an important, open challenge.
This paper introduces NEWSSPIKE-RE, a
novel, unsupervised algorithm that discovers
event relations and then learns to extract them.
NEWSSPIKE-RE uses a novel probabilistic
graphical model to cluster sentences describ-
ing similar events from parallel news streams.
These clusters then comprise training data
for the extractor. Our evaluation shows that
NEWSSPIKE-RE generates high quality train-
ing sentences and learns extractors that per-
form much better than rival approaches, more
than doubling the area under a precision-recall
curve compared to Universal Schemas.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999783865384615">
Relation extraction, the process of extracting struc-
tured information from natural language text, grows
increasingly important for Web search and ques-
tion answering. Traditional supervised approaches,
which can achieve high precision and recall, are lim-
ited by the cost of labeling training data and are un-
likely to scale to the thousands of relations on the
Web. Another approach, distant supervision (Craven
and Kumlien, 1999; Wu and Weld, 2007), creates its
own training data by matching the ground instances
of a Knowledge base (KB) (e.g. Freebase) to the un-
labeled text.
Unfortunately, while distant supervision can work
well in some situations, the method is limited to rela-
tively static facts (e.g., born-in(person, location) or
capital-of(location,location)) where there is a cor-
responding knowledge base. But what about dy-
namic event relations (also known as fluents), such
as travel-to(person, location) or fire(organization,
person)? Since these time-dependent facts are
ephemeral, they are rarely stored in a pre-existing
KB. At the same time, knowledge of real-time
events is crucial for making informed decisions in
fields like finance and politics. Indeed, news stories
report events almost exclusively, so learning to ex-
tract events is an important open problem.
This paper develops a new unsupervised tech-
nique, NEWSSPIKE-RE, to both discover event rela-
tions and extract them with high precision. The in-
tuition underlying NEWSSPIKE-RE is that the text
of articles from two different news sources are not
independent, since they are each conditioned on the
same real-world events. By looking for rarely de-
scribed entities that suddenly “spike” in popularity
on a given date, one can identify paraphrases. Such
temporal correspondence (Zhang and Weld, 2013)
allow one to cluster diverse sentences, and the re-
sulting clusters may be used to form training data in
order to learn event extractors. Furthermore, one can
also exploit parallel news to obtain direct negative
evidence. To see this, suppose one day the news in-
cludes the following: (a) “Snowden travels to Hong
Kong, off southeastern China.” (b) “Snowden can-
not stay in Hong Kong as Chinese officials will not
allow ...” Since news stories are usually coherent, it
is highly unlikely that travel to and stay in (which is
negated) are synonymous. By leveraging such direct
negative phrases, we can learn extractors capable of
distinguishing heavily co-occurring but semantically
different phrases, thereby avoiding many extraction
errors. Our NEWSSPIKE-RE system encapuslates
these intuitions in a novel graphical model making
</bodyText>
<page confidence="0.986308">
117
</page>
<bodyText confidence="0.795828090909091">
Transactions of the Association for Computational Linguistics, vol. 3, pp. 117–129, 2015. Action Editor: Hal Daum´e III.
Submission batch: 10/2014; Revision batch 1/2015; Published 2/2015. c�2015 Association for Computational Linguistics.
the following contributions:
• We develop a method to discover a set of dis-
tinct, salient event relations from news streams.
• We describe an algorithm to exploit paral-
lel news streams to cluster sentences that be-
long to the same event relations. In particu-
lar, we propose the temporal negation heuris-
tic to avoid conflating co-occurring but non-
synonymous phrases.
</bodyText>
<listItem confidence="0.9521591">
• We introduce a probabilistic graphical model to
generate training for a sentential event extractor
without requiring any human annotations.
• We present detailed experiments demonstrating
that the event extractors, learned from the gener-
ated training data, significantly outperform sev-
eral competitive baselines, e.g. our system more
than doubles the area under the micro-averaged,
PR curve (0.80 vs. 0.30) compared to Riedel’s
Universal Schema (Riedel et al., 2013).
</listItem>
<sectionHeader confidence="0.986142" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999968881578948">
Supervised learning approaches have been widely
developed for event extraction tasks such as MUC-4
and ACE. They often focus on a hand-crafted on-
tology and train the extractor with manually created
training data. While they can offer high precision
and recall, they are often domain-specific (e.g. bio-
logical events (Riedel et al., 2011; McClosky et al.,
2011) and entertainment events (Benson et al., 2011;
Reichart and Barzilay, 2012)), and are hard to scale
over the events on the Web.
Open IE systems extract open domain relations
(e.g. (Banko et al., 2007; Fader et al., 2011)) and
events (e.g. (Ritter et al., 2012)). They often perform
self-supervised learning of relation-independent ex-
tractions. It allows them to scale but makes them
unable to output canonicalized relations.
Distant supervised approaches have been devel-
oped to learn extractors by exploiting the facts exis-
ting in a knowledge base, thus avoiding human an-
notation. Wu et al. (2007) and Reschke et al. (2014)
learned Infobox relations from Wikipedia, while
Mintz et al. (2009) heuristically matched Freebase
facts to texts. Since the training data generated
by the heuristic matching is often imperfect, multi-
instance learning approaches (Riedel et al., 2010;
Hoffmann et al., 2011; Surdeanu et al., 2012) have
been developed to combat this problem. Unfortu-
nately, most facts existing in the KBs are static facts
like geographical or biographical data. They fall
short of learning extractors for fluent facts such as
sports results or travel and meetings by a person.
Bootstrapping is another common extraction
technique (Brin, 1999; Agichtein and Gravano,
2000; Carlson et al., 2010; Nakashole et al., 2011;
Huang and Riloff, 2013). This typically takes a set
of seeds as input, which can be ground instances or
key phrases. The algorithms then iteratively gener-
ate more positive instances and phrases. While there
are many successful examples of bootstrapping, the
challenge is to avoid semantic drift. Large-scale sys-
tems, therefore, often require extra processing such
as manual validation between the iterations or addi-
tional negative seeds as the input.
Unsupervised approaches have been developed
for relation discovery and extractions. These algo-
rithms are usually based on some clustering assump-
tions over a large unlabeled corpus. Common as-
sumptions include the distributional hypothesis used
by (Hasegawa et al., 2004; Shinyama and Sekine,
2006), latent topic assumption by (Yao et al., 2012;
Yao et al., 2011), and low rank assumption by (Taka-
matsu et al., 2011; Riedel et al., 2013). Since the
assumptions largely rely on co-occurrence, previous
unsupervised approaches tend to confuse correlated
but semantically different phrases during extraction.
In contrast to this, our work largely avoids these er-
rors by exploiting the temporal negation heuristic
in parallel news streams. In addition, unlike many
unsupervised algorithms requiring human effort to
canonicalize the clusters, our work automatically
discovers events with readable names.
Paraphrasing techniques inspire our work. Some
techniques, such as DIRT (Lin and Pantel, 2001)
and Resolver (Yates and Etzioni, 2009), are based
on the distributional hypothesis. Another common
approach is to use parallel corpora, including news
streams (Barzilay and Lee, 2003; Dolan et al., 2004;
Zhang and Weld, 2013), multiple translations of the
same story (Barzilay and McKeown, 2001) and
bilingual sentence pairs (Ganitkevitch et al., 2013)
to generate the paraphrases. Although these algo-
rithms create many good paraphrases, they can not
be directly used to generate enough training data to
train a relation extractor for two reasons: first, the
semantics of the paraphrases is often context depen-
dent; second, the generated paraphrases are often in
</bodyText>
<page confidence="0.995296">
118
</page>
<subsectionHeader confidence="0.765891">
Training Phase Testing Phase
</subsectionHeader>
<figureCaption confidence="0.905215">
Figure 1: During its training phase, NEWSSPIKE-RE
</figureCaption>
<bodyText confidence="0.953684857142857">
first groups parallel sentences as NewsSpikes. Next, the
system automatically discovers a set of event relations.
Then, a probabilistic graphical model clusters sentences
from the NewsSpike as training data for each discovered
relation, which is used to learn sentential event extrac-
tors. During the testing phase, the extractor takes test
sentences as input and predicts event extractions.
small clusters and it remains challenging to merge
them for the purpose of training an extractor. Our
work extends previous paraphrasing techniques, no-
tably that of Zhang and Weld (2013), but we fo-
cus on generating high-quality, positive and negative
training sentences for the discovered events in order
to learn extractors with high precision and recall.
</bodyText>
<sectionHeader confidence="0.979859" genericHeader="method">
3 System Overview
</sectionHeader>
<bodyText confidence="0.980071462686567">
News articles report an enormous number of events
every day. Our system, NEWSSPIKE-RE, aligns
paralel news streams to indentify and extract these
events as shown in Figure 1. NEWSSPIKE-RE
has both training and test phases. Its training
phase has two main steps: event-relation discov-
ery and training-set generation. Section 4 describes
our event relation discovery algorithm, which pro-
cesses time-stamped news articles to discern a set
of salient, distinct event relations in the form of
E = e(t1, t2), where e is a representative event
phrase and ti are types of the two arguments.
NEWSSPIKE-RE generates the event phrases using
an Open Information Extraction (IE) system (Fader
et al., 2011), and uses a fine-grained entity recogni-
tion system FIGER (Ling and Weld, 2012) to gen-
erate type descriptors such as “company ”, “politi-
cian”, and “medical treatment”.
The second part of NEWSSPIKE-RE’s training
phase, described in Section 5, is a method for build-
ing extractors for the discovered event relations. Our
approach is motivated by the intuition, adapted from
Zhang and Weld (2013), that articles from different
news sources typically use different sentences to de-
scribe the same event, and that corresponding sen-
tences can be identified when they mention a unique
pair of real-world entities. For example, when an un-
usual entity pair (Selena, Norway) is suddenly seen
in three articles on a single day:
Selena traveled to Norway to see her ex-boyfriend.
Selena arrived in Norway for a rendezvous with Justin.
Selena’s trip to Norway was no coincidence.
It is likely that all three refer to the same event re-
lation, travel-to(person, location)1, and can be used
as positive training examples for the relation. As in
Zhang &amp; Weld (2013), we group parallel sentences
sharing the same argument pair and date in a struc-
ture called a NewsSpike. However, we include all
sentences mentioning the arguments (e.g. Selena’s
trip to Norway) in the NewsSpike (not just those
yielding OpenIE extractions), and use the lexical-
ized dependency path between the arguments (e.g.
&lt;-[poss]-trip-[prep-to]-&gt;2, as the event phrase. In
this way, we can generalize extractors beyond the
scope of OpenIE. Formally, a NewsSpike is a tu-
ple, (a1, a2, d, S), where a1 and a2 are arguments
(e.g. Selena), d is a date, and S is a set of argument-
labeled sentences {(s, a1, a2, p) ...} in which s is a
sentence with arguments ai and event phrase p.
It’s important that non-synonomous sentences
like “Selena stays in Norway” should be excluded
from the training data for travel-to(person, loca-
tion) even if a travel-to event did apply to that argu-
ment pair. In order to select only the synonomous
sentences, we develop a probabilistic graphical
model, described in Section 5.2, to accurately as-
sign sentences from NewsSpikes to each discov-
ered event relation E. Given this annotated data,
NEWSSPIKE-RE trains extractors using a multi-
class logistic regression classfier.
During the testing phase, NEWSSPIKE-RE ac-
cepts arbitrary sentences (no date-stamp required),
uses FIGER to identify possible arguments, and uses
the classifier to predicts which events (if any) hold
between an argument pair. We describe the extrac-
tion process in Section 6.
Note that NEWSSPIKE-RE is an unsupervised al-
</bodyText>
<footnote confidence="0.9979152">
1For clarity in the paper, we refer to this relation as travel-to,
even though the phrase arrive in is actually more frequent and
is selected as the name of this relation by our event discovery
algorithm, as shown in Table 2.
2This dependency path will be referred to as “’s trip to”.
</footnote>
<figure confidence="0.9006869">
NewsSpike w/
Parallel sentences
Group
Parallel news
streams
NS=(a1,2,d,S)
(a1,at)
S={s1, s2 ,s3}
r r2 r
r1 r2 r3
r r r
Discover
event
relations
Training sentences
s→E(a1,a2)
1 r1 r2 r3
3
s’→E(a’1,a’2)
r1 r2 r3
r4 r5
E=e(t1,t2)
(a1a2t)
E=e(t1,t2)
Event
Generate
training data
learn
input extract
Test
sentences
s
Event
Extractor
s→ E(a1,a2)
Extractions
119
E1 E2
17h 172 173
E3
</figure>
<figureCaption confidence="0.9996232">
Figure 2: A simple example of the edge-cover algo-
rithm with K=2, where Ei are event relations and ηj are
NewsSpikes. The optimal solution selects E1 with edges
to η1 and η2, and E3 with edge to η3. These two event
relations cover all the NewsSpikes.
</figureCaption>
<bodyText confidence="0.999840454545454">
gorithm that requires no manual labelling of the
training instances. Like distant supervision, the
key is to automatically generate the training data,
at which point a traditional supervised classifier
may be applied to learn an extractor. Because dis-
tant supervision creates very noisy annotations, re-
searchers often use specialized learners that model
the correctness of a training example with a la-
tent variable (Riedel et al., 2010; Hoffmann et
al., 2011), but we found this unnecessary, because
NEWSSPIKE-RE creates high quality training data.
</bodyText>
<sectionHeader confidence="0.981637" genericHeader="method">
4 Discovering Salient Events
</sectionHeader>
<bodyText confidence="0.999993961538462">
The first step of NEWSSPIKE-RE is to discover a
set of event relations in the form of E = e(t1, t2),
where e is an event phrase, and ti are fine-grained ar-
gument types generated by FIGER, augmented with
the important types “number” and “money”, which
are recognized by the Stanford name entity recogni-
tion system (Finkel et al., 2005). To be most useful,
the discovered event relations should cover salient
events that are frequently reported in the news ar-
ticles. Formally, we say that a NewsSpike η =
(a1, a2, d, S) mentions E = e(t1, t2) if the types
of ai are ti for each i, and one of its sentence has e
as the event phrase between the arguments. To max-
imize the salience of the events, NEWSSPIKE-RE
will prefer event relations that are “mentioned” by
more NewsSpikes.
In addition, the set of event relations should be
distict. For example, if the relation travel-to(person,
location) is already in the set, then visit(person, lo-
cation) should not be selected as a separate relation.
To reduce overlap, discovered event relations should
not be mentioned by the same NewsSpike.
Let £ be all candidate event relations, N be all
NewsSpikes. Our goal is to select the K most salient
relations from £, minimizing overlap between re-
lations. We can frame this task as a variant of the
bipartite graph edge-cover problem. Let a bipartite
graph G have one node Ei for each event relation in
£ and one node ηj for each NewsSpike in N. There
is an edge between Ei and ηj if ηj mentions Ei. The
edge-cover problem is to select a largest subset of
edges subject to (1) at most K nodes of Ei are cho-
sen and all edges incident to them are chosen as the
covered edges; (2) each node of ηj is incident to at
most one edge. The first constraint guarantees that
there are exactly K event relations discovered; the
second constraint ensures that no NewsSpike partic-
ipates in two event relations. Figure 2 shows the
optimized solution of a simple graph with K = 2,
which can cover 3 edges with 2 event relations that
have no overlapping NewsSpikes.
Since both the objective function and constraints
are linear, we can optimize this edge-cover problem
with integer linear programming (Nemhauser and
Wolsey, 1988). By solving the optimization prob-
lem, NEWSSPIKE-RE finds a salient set of event re-
lations incident to the covered edges. The discov-
ered relations with K set to 30 are shown in Table 2
in Section 7. In addition, the covered edges bring
us the initial mapping between the event types and
NewsSpikes, which is used to train the probablistic
model in Section 5.3.
</bodyText>
<sectionHeader confidence="0.968042" genericHeader="method">
5 Generating the Training Sentences
</sectionHeader>
<bodyText confidence="0.999881625">
After NEWSSPIKE-RE has discovered a set of event
relations, it then generates training instances to learn
an extractor for each relation. In this section, we
present our algorithm for generating the training
sentences. As shown in Figure 1, the generator takes
N NewsSpikes {ηi = (a1i, a2i, di, Si)|i = 1... N}
and K event relations {Ek = ek(t1k, t2k)|k =
1... K} as input. For every event relation, Ek,
the generator identifies a subset of sentences from
UNi=1Si expressing the event relation as training sen-
tences. In this section, we first characterize the
paraphrased event phrases and the parallel sentences
in NewsSpikes. Then we show how to encode
this heuristic in a probabilistic graphical model that
jointly paraphrases the event phrases and identifies a
set of training sentences.
</bodyText>
<subsectionHeader confidence="0.991151">
5.1 Exploiting Properties of Parallel News
</subsectionHeader>
<bodyText confidence="0.99902075">
Previous work (Zhang and Weld, 2013) proposed
several heuristics that are useful to find similar sen-
tences in a NewsSpike. For example, the tempo-
ral functionality heuristic says that sentences in a
</bodyText>
<page confidence="0.970603">
120
</page>
<bodyText confidence="0.999864014705882">
NewsSpike with the same tense tend to be para-
phrases. Unfortunately, these methods are too weak
to generate enough data for training high quality
event extractors: (1) they are “in-spike heuristics”
that tend to generate small clusters from individual
NewsSpikes. It remains unclear how to merge sim-
ilar events occuring on different days and between
different entities to increase cluster size. (2) they in-
cluded heuristics to “gain precision at the expense
of recall” (e.g. news articles do not state the same
fact twice), because it is hard to obtain direct nega-
tive phrases inside one NewsSpike. In this paper, we
exploit news streams in a cross-spike, global man-
ner to obtain accurate positive and negative signals.
This allows us to dramatically improve recall while
maintaining high precision.
Our system starts from the basic observation that
the parallel sentences tend to be coherent. So if a
NewsSpike η = (a1, a2, d, S) is an instance of an
event relation E = e(t1, t2), the event phrases in its
parallel sentences tend to be paraphrases. But some-
times the sentences in the NewsSpike are related but
not paraphrases. For example, one day “Snowden
will stay in Hong Kong ...” appears together with
“Snowden travels to Hong Kong ...”. Although the
fact stay-in(Snowden, Hong Kong) is true, it is harm-
ful to include “Snowden will stay in Hong Kong” in
the training for travel-to(person, location).
Detecting paraphrases remains a challenge to
most unsupervised approaches because they tend
to cluster heavily co-occurring phrases which may
turn out to be semantically different or even antony-
mous. (Zhang and Weld, 2013) presented a method
to avoid confusion between antonym and synonyms
in NewsSpikes, but did not address the problem of
related but different phrases like travel to and stay
in in a NewsSpike.
To handle this, our method rests on a simple ob-
servation: when you read “Snowden travels to Hong
Kong” and “Snowden cannot stay in Hong Kong
as Chinese officials do not allow ...” in the same
NewsSpike, it is unlike that travel to and stay in are
synonymous event phrases because otherwise the
two news stories are describing the opposite event.
This observation leads to:
Temporal Negation Heuristic. Two event phrases
p and q tend to be semantically different if they co-
occur in the NewsSpike but one of them is in negated
form.
The temporal negation heuristic helps in two
ways: (1) it provides some direct negative phrases
for the event relations; NEWSSPIKE-RE uses these
to heuristically label some variables in the model.
(2) It creates some useful features to implement a
form of transitvity. For example, if we find that live
in and stay in are frequently co-occurring and the
temporal negation heuristic tells us that travel to and
stay in are not paraphrases, this is evidence that live
in is unlikely to be a paraphrase of travel to, even if
they are heavily co-occurring.
The following section describes our implementa-
tion that uses these properties to generate high qual-
ity training. Our goal is the following: a sentence
(s, a1, a2, p) from NewsSpike η = (a1, a2, d, S)
should be included in the training data for event re-
lation E = e(t1, t2) if the event phrase p is a para-
phrase of e and the event relation E happens to the
argument pair (a1, a2) at time d.
</bodyText>
<subsectionHeader confidence="0.995306">
5.2 Joint Cluster Model
</subsectionHeader>
<bodyText confidence="0.999998625">
As discussed above, to identify a high quality set of
training sentences from NewsSpikes, one needs to
combine evidence that event phrases are paraphrases
with evidence from NewsSpikes. For this purpose,
we define an undirected graphical model to jointly
reason about paraphrasing the event phrases and
identifying the training sentences from NewsSpikes.
We first list the notation used in this section:
</bodyText>
<equation confidence="0.9862345">
E event relation
p ∈ P event phrases
s ∈ Sp sentences w/ the event phrase p
Yp Is p a paraphrase for E?
Zs p Is s w/ p good training for E?
Φ factors
</equation>
<bodyText confidence="0.999738214285714">
Let P be the union of all the event phrases from
every NewsSpike. For each p E P, let Sp be the set
of sentences having p as its event phrase.
Figure 3(a) shows the model in plate form. There
are two kinds of random variables corresponding to
phrases and sentences, respectively. For each event
relation E = e(t1, t2), there exists a connected com-
ponent for every event phrase p E P that models (1)
whether p is a paraphrase of e or not (modeled us-
ing Boolean phrase variables, Yp); and (2) whether
each sentence of Sp is a good training sentence for
E (modeled using |Sp |Boolean sentence variables
{Zsp|s E Sp}. Intuitively, the goal of the model
is to find the set of good training sentences, with
</bodyText>
<page confidence="0.955916">
121
</page>
<figure confidence="0.999442914285714">
𝑌 ′s trip to
𝑌stay in
1
Φphrase
Φjoint
0
Φjoint
Φphrase
Z1
1
Φin
Tsarnaev’s six-month trip to
Russia escapes the FBI’s attention
Z2 1 ZB 0
Z1
0
Φin
Z2
0
Selena Gomez’s trip to
Norway
Φcross
(b)
... for UCLA’s trip to
Nebraska
Snowden plans to stay in
Hongkong
Manziel stays in Austin to
attend a fraternity party
(c)
Sp
P
Zi
(a)
Y
</figure>
<figureCaption confidence="0.999906">
Figure 3: (a) The connected components depicted as plate model, where each Y is a Boolean variable for a relation
</figureCaption>
<bodyText confidence="0.545152">
phrase and each Z is a Boolean variable for a training sentence for with that phrase; (b) and (c) are example connected
components for the event phrases ’s trip to and stay in respectively. The goal of the model is to set Y = 1 for good
paraphrases of a relation and to set Z = 1 for good training sentences.
</bodyText>
<equation confidence="0.581909">
Zs
p
</equation>
<bodyText confidence="0.997042829268293">
ferent phrases, ∪p{s|Zsp = 1}, defines the training
sentences for the event. Figure 3(b) and 3(c) show
two example connected-components for the event
phrases ’s trip to and stay in respectively.
Now, we can define the joint distribution over
the event phrases and the sentences. The joint dis-
tribution is a function defined on factors that en-
code our observations about NewsSpikes as features
and constraints. The phrase factor Φphrase is a log-
linear function attaching to Yp with the paraphras-
ing features, such as whether p and e co-occur in
the NewsSpikes, or whether p shares the same head
word with e. They are used to distinguish whether p
is a good event phrase.
A sentence should not be identified as a good
training sentence if it does not contain a positive
event phrase. For example, if Y stay in in Figure 3(b)
takes the value of 0, thus all sentences with the event
phrase stay in should also take the value of 0. We
implement this constraint with a joint factor Φjoint
among Yp and Zsp variable.
In addition, good training sentences occur when
the NewsSpike is an event instance. To encode this
observation, we need to featurize the NewsSpikes
and let them bias the assignments. Our model im-
plements this with two types of log-linear factors:
(1) the unary in-spike factor Φin depends on the sen-
tence variables and contains features about the cor-
responding NewsSpike. The factor is used to dis-
tinguish whether the NewsSpike is an instance of
e(t1, t2), such as whether the argument types of the
NewsSpike match the designated types t1, t2; (2) the
pairwise cross-spike factors Φcross connect pairs of
sentences. This uses features such as whether the
pair of NewsSpikes for the two sentences have high
textual similarity, and whether two NewsSpikes con-
tain negated event phrases.
We define the joint distribution for the connected
component for p as follows. Let Z be the vector of
sentence variables, let x be the features. The joint
distribution is:
</bodyText>
<equation confidence="0.989271333333333">
p(Y = y, Z = Z|x; Θ) =def Zx1Φphrase(y, x)
�XΦjoint(y, z) �Φin(zs, x) Φcross(zs, zsy, x)
s s,sy
</equation>
<bodyText confidence="0.999988714285714">
where the parameter vector O is the weight vec-
tor of the features in Φin and Φcross, which are log-
linear functions. The joint factors Φjoint is zero when
Yp = 0 but some Zsp = 1. Otherwise, it is set to 1.
We use integer linear programming to perform MAP
inference on the model, finding the predictions y, z
that maximize the probability.
</bodyText>
<subsectionHeader confidence="0.9984">
5.3 Learning from Heuristic Labels
</subsectionHeader>
<bodyText confidence="0.977563333333333">
We now present the learning algorithm for our joint
cluster model. The goal of the learning algorithm
is to set O for the log-linear functions in the factors
in a way that maximizes the likelihood estimation.
We do this in a totally unsupervised manner, since
manual annotation is expensive and not scalable to
large numbers of event relations.
The weights are learned in three steps: (1)
NEWSSPIKE-RE creates a set of heuristic labels for
a subset of variables in the graphical model; (2)
it uses the heuristic labels as supervision for the
model; (3) it updates O with the perceptron learning
algorithm. The weights are used to infer the values
of the variables that don’t have heuristic labels. The
procedure is summarized in Figure 4.
For each event relation E = e(t1, t2),
NEWSSPIKE-RE creates heuristic labels as follows:
= 1. The union of such sentences over the dif-
</bodyText>
<page confidence="0.920474">
122
</page>
<figure confidence="0.4272229">
Input: NewsSpikes and the connected components of
the model;
Heuristic Labels:
1. find positive and negative phrases and sentences
P+, P−, S+, S−;
2. label the connected componenets accordingly
and create {(Y ilabel ,Zlabel
i ) |M i=1}.
Learning: Update O with the perceptron learning al-
gorithm.
</figure>
<figureCaption confidence="0.864071">
Output: the values of all variables in the connected
components with the MAP inference.
Figure 4: Learning from Heuristic Labels
</figureCaption>
<bodyText confidence="0.92519690625">
(1) P+: the temporal functionality heuristic (Zhang
and Weld, 2013) says that if an event phrase p co-
occurs with e in the NewsSpikes, it tends to be a
paraphrase of e. We add the most frequently co-
occurring event phrases to P+. P+ also includes e
itself. (2) P−: the temporal negation heuristic says
that if p and e co-occur in the NewsSpike but one
of them is in its negated form, p should be nega-
tively labeled. We add those event phrases to P−.
If a phrase p appears in both P+ and P−, we re-
move it from both sets. (3) S+: we first get the
positive NewsSpikes from the solution of the edge-
cover problem in section 4. We treat the NewsSpike
η as positive if the edge between η and E is cov-
ered. Next, every sentence with p E P+ is added
into S+. (4) S−: since the event relations discovered
in section 4 tend to be distinct relations, a sentence
is treated as negative sentence for E if it is heuris-
tically labeled as positive for E0 =� E. In addition,
S− includes all sentences with p E P−.
With P+, P−, S+, S−, we define the heuristic la-
beled set to be {(Y label
i , Zlabel
i ) |M i=1}, where M
is the number of the connected components with
the corresponding event phrases p E P+ U P−;
Y label = 1 ifE P+ d Y label =
i p and
is labeled similarly, but note that if the sentence in
the connected component doesn’t exist in S+ U S−,
NEWSSPIKE-RE doesn’t include the corresponding
variable in Zlabel
</bodyText>
<equation confidence="0.600061333333333">
i .With {(Y label
i , Zlabel
i ) |M i=1}, learn-
</equation>
<bodyText confidence="0.8995663">
ing can be done with maximum likelihood estima-
tion as L(O) = log Hi p(Yi = ylabel
i ,Zi = zlabel
i |
xi, O). Following (Collins, 2002), we use a fast per-
ceptron learning approach to update O. It consists
of iterating two steps: (1) MAP inference given the
current weight; (2) penalizing the weights if the in-
ferred assignments are different from the heuristic
labeled assignments.
</bodyText>
<sectionHeader confidence="0.992249" genericHeader="method">
6 Sentential Event Extraction
</sectionHeader>
<bodyText confidence="0.999972318181818">
As shown in Figure 1, we learn the extractors from
the generated training sentences. Note that most dis-
tant supervised (Hoffmann et al., 2011; Surdeanu et
al., 2012) approaches use multi-instance, aggregate-
level training (i.e. the supervision comes from la-
beled sets of instances instead of individually la-
beled sentences). Coping with the noise inherent
in these multi-instance bags remains a big challenge
for distant supervision. In contrast, our sentence-
level training data is more direct and minimizes
noise. Therefore, we implement the event extrac-
tor as a simple multi-class, L2-regularized logistic
regression classifier.
For features of the classifier, we use the lexi-
calized dependency paths, the OpenIE phrases, the
minimal subtree of the dependency parse and the
bag-of-words between the arguments. We also aug-
ment them with fine grained argument types pro-
duced by FIGER (Ling and Weld, 2012). The event
extractor that is learned can take individual test sen-
tences (s, a1, a2) as input and predict whether that
sentence expresses the event between (a1, a2).
</bodyText>
<sectionHeader confidence="0.992791" genericHeader="method">
7 Empirical Evaluation
</sectionHeader>
<bodyText confidence="0.999909333333333">
Our evaluation addresses two questions. Section 7.2
considers whether our training generation algorithm
identifies accurate and diverse sentences. Then,
Section 7.3 investigates whether the event extrac-
tor, learned from the training sentences, outperforms
other extraction approaches.
</bodyText>
<subsectionHeader confidence="0.96927">
7.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.9998088125">
We follow the procedure described in (Zhang and
Weld, 2013) to collect parallel news streams and
generate the NewsSpikes: first, we get news seeds
and query the Bing newswire search engine to gather
additional, time-stamped, news articles on a simi-
lar topic; next, we extract OpenIE tuples from the
news articles and group the sentences that share the
same arguments and date into NewsSpikes. We col-
lected the news stream corpus from March 1st 2013
to July 1st 2014. We split the dataset into two parts:
in the training phrase, we use the news streams in
2013 (named NS13) to generate the training sen-
tences. NS13 has 33k NewsSpikes containing 173k
sentences.
We evaluated the extraction performance on news
articles collected in 2014 (named NS14). In this
</bodyText>
<equation confidence="0.821764">
0 if p E P−. Zi
</equation>
<page confidence="0.993724">
123
</page>
<bodyText confidence="0.999969790697675">
way, we make sure the test sentences are unseen
during training. There are 15 million sentences in
NS14. We randomly sample 100k unique sentences
having two different arguments recognized by the
name entity recognition system.
For our event discovery algorithm, we set the
number of event relations to be 30 and ran the al-
gorithm on NS13. The algorithm takes 6 seconds
to run on a 2.3GHz CPU. Note that most previous
unsupervised relation discovery algorithms require
additional manual post-processing to assign names
to the output clusters. In contrast, NEWSSPIKE-RE
discovers the event relations fully automatically and
the output is self-explanatory. We list them together
with the by-event extraction performance in Table 2.
From the table, we can see that most of the discov-
ered event relations are salient with little overlap be-
tween relations.
While we arbitrarily set K to 30 in our experi-
ments, there is no inherent limit to the number of
relation phrases as long as the news corpus provides
sufficient support to learn an extractor for each rela-
tion. In future, we plan to explore much larger sets
of event relations to see if the extraction accuracy is
maintained.
The joint cluster model that identifies training
sentences for each event relation E = e(t1, t2) uses
cosine similarity between the event phrase p of a
sentence and the canonical phrases of each relation
as features in the phrase factors in Figure 3(a). It
also includes the cosine similarity between p and a
set of “anti-phrases” for the event relation which are
recognized by the temporal negation heuristic.
For the in-spike factor, we measure whether the
fine-grained argument types of the sentence returned
from the FIGER system matches the required ti
respectively. In addition, we implement the fea-
tures from (Zhang and Weld, 2013) to measure
whether the sentence is describing the event of the
NewsSpike. For the cross-spike factors, we use tex-
tual similarity features between the two sets of par-
allel sentences to measure the distance between the
pair of NewsSpikes.
</bodyText>
<subsectionHeader confidence="0.998327">
7.2 Quality of the Generated Training Set
</subsectionHeader>
<bodyText confidence="0.99986425">
The key to a good learning system is a high-quality
training set. In this section, we compare our joint
model against pipeline systems that consider para-
phrases and argument type matching sequentially,
</bodyText>
<table confidence="0.971721111111111">
system # all ma. # diverse ma.
mi. mi.
Basic 43,718 .50 .62 12,701 .38 .51
Yates09 15,212 .78 .76 586 .48 .50
Ganit13 14,420 .74 .71 1,210 .53 .53
Zhang13 14,804 .76 .75 890 .63 .61
NEWSSPIKE-RE 20,105 .88 .89 2,156 .71 .72
w/o cross 16,463 .86 .86 1,883 .67 .69
w/o neg 33,548 .76 .81 4,019 .64 .68
</table>
<tableCaption confidence="0.9818425">
Table 1: Quality of the generated training sentences
(count, micro- and macro- accuracy), where “all” in-
cludes sentences with all event phrases and “diverse” are
those with distinct event phrases.
</tableCaption>
<bodyText confidence="0.999880444444444">
based on the following paraphrasing techniques.
Basic is based on the temporal functionality
heuristic of (Zhang and Weld, 2013). It treats all
event phrases appearing in the same NewsSpike
as paraphrases. Yates09 uses Resolver (Yates and
Etzioni, 2009) to create clusters of phrases. Re-
solver measures the similarity between the phrases
by means of both distributional features and textual
features. We convert the sentences in NewsSpikes
into tuples in the form of (a1,p, a2), and run Re-
solver on these tuples to generate the paraphrases.
Zhang13: We used the generated paraphrase set
from (Zhang and Weld, 2013). Ganit13: Gan-
itkevitch et al. (2013) released a large paraphrase
database (PPDB) based on exploiting the bilingual
parallel corpora. Note that some of these para-
phrasing systems do not handle dependency paths.
So when p is a dependency path, we use the sur-
face string between the arguments as the phrase.
NewsSpike-RE: We also conduct ablation testing
on NEWSSPIKE-RE to measure the effect of the
cross-spike factors and the temporal negation heuris-
tic: w/o Cross uses a simpler model by remov-
ing the cross-spike factors of NEWSSPIKE-RE; w/o
Negation uses the same joint cluster model as
NEWSSPIKE-RE but removes the features and the
heuristic labels coming from the temporal negation
heuristic.
We measured the micro- and macro- accuracy of
each system by manually labeling 1000 randomly
chosen output from each system3. Annotators read
each training sentence, and decided if it was a good
example for a particular event. We also report the
number of generated sentences. Since the extrac-
tor should generalize over sentences with dissimilar
expressions, it is crucial to identify sentences with
</bodyText>
<footnote confidence="0.946734">
3Two Odesk workers were asked to label the dataset, a grad-
uate student then reconciled any disagreements.
</footnote>
<page confidence="0.987148">
124
</page>
<table confidence="0.99987430882353">
Event # F1 @ max recall N-RE area u/ PR curve
R13 R13P R13 R13P N-RE
acquire(organization,person) 59 0.34 0.33 0.58 0.26 0.26 0.57
arrive in(organization,location) 95 0.11 0.40 0.56 0.01 0.12 0.42
arrive in(person,location) 130 0.61 0.86 0.86 0.35 0.67 0.93
beat(organization,organization) 178 0.42 0.85 0.90 0.14 0.64 0.84
beat(person,person) 107 0.57 0.82 0.94 0.21 0.53 0.91
buy(organization,organization) 84 0.47 0.47 0.78 0.25 0.50 0.82
defend(person,person) 41 0.37 0.38 0.52 0.36 0.47 0.65
die at(person,number) 158 0.53 0.97 0.98 0.31 0.93 0.97
die(person,time) 179 0.85 0.91 0.97 0.66 0.80 0.96
fire(organization,person) 39 0.36 0.33 0.53 0.32 0.45 0.88
hit(event,location) 33 0.00 0.42 0.64 0.00 0.51 0.48
lead(person,organization/sports team) 119 0.77 0.86 0.87 0.57 0.73 0.77
leave(person,organization) 61 0.40 0.52 0.59 0.14 0.38 0.57
meet with(person,person) 137 0.74 0.86 0.92 0.48 0.73 0.88
nominate(person/politician,person) 44 0.12 0.38 0.54 0.13 0.44 0.77
pay(organization,money) 134 0.77 0.91 0.93 0.52 0.85 0.90
place(organization,person) 34 0.17 0.28 0.50 0.24 0.23 0.95
play(person/artist,person) 173 0.92 0.89 0.87 0.88 0.79 0.73
release(organization,person) 30 0.18 0.22 0.60 0.08 0.25 0.72
replace(person,person) 115 0.82 0.89 0.94 0.62 0.75 0.87
report(government agency,time) 140 0.37 0.84 0.91 0.09 0.74 0.83
report(written work,time) 130 0.64 0.85 0.83 0.43 0.82 0.74
return to(person/athlete,location) 45 0.14 0.34 0.50 0.03 0.30 0.49
shoot(person,number) 101 0.71 0.89 0.92 0.49 0.74 0.84
sign with(person,organization) 129 0.47 0.62 0.89 0.25 0.46 0.85
sign(organization,person) 110 0.45 0.71 0.85 0.26 0.63 0.79
unveil(organization,product) 88 0.43 0.71 0.44 0.26 0.52 0.30
vote(government,time) 32 0.29 0.24 0.74 0.32 0.25 0.77
win at(person,location) 100 0.24 0.68 0.85 0.08 0.60 0.90
win(person,event) 107 0.54 0.77 0.86 0.22 0.63 0.77
micro average 2,903 0.53 0.70 0.81 0.30 0.59 0.80
macro average 97 0.46 0.64 0.76 0.30 0.56 0.76
area u/ diverse PR curve
# R13 R13P N-RE
20 0.26 0.17 0.58
18 0.01 0.02 0.50
18 0.26 0.33 0.80
24 0.06 0.53 0.58
14 0.08 0.25 0.77
34 0.19 0.40 0.79
12 0.13 0.06 0.47
17 0.33 0.83 0.94
16 0.22 0.63 0.87
8 0.20 0.10 0.66
24 0.00 0.45 0.50
14 0.30 0.36 0.62
14 0.07 0.13 0.38
14 0.28 0.56 0.93
27 0.11 0.53 0.75
17 0.33 0.90 0.56
16 0.19 0.21 0.94
15 0.63 0.56 0.47
16 0.06 0.15 0.81
18 0.46 0.58 0.89
35 0.06 0.52 0.70
22 0.38 0.58 0.51
21 0.08 0.23 0.78
8 0.35 0.37 0.48
44 0.15 0.17 0.91
26 0.15 0.27 0.66
22 0.31 0.22 0.63
19 0.35 0.22 0.83
40 0.01 0.42 0.90
19 0.03 0.26 0.78
609 0.15 0.31 0.71
20 0.20 0.37 0.70
</table>
<tableCaption confidence="0.7258516">
Table 2: Performance of extractors by event relation, reporting both precision and the area under the PR curve. The
# column shows the number of true extractions in the pool of sampled output. NEWSSPIKE-RE (labeled N-RE)
outperforms two implementations of Riedel’s Universal Schemas (See Section 7.3 for details). The advantage of
NEWSSPIKE-RE over Universal Schemas is greatest on a diverse test set where each sentence has a distinct event
phrase.
</tableCaption>
<bodyText confidence="0.9998479">
diverse event phrases. Therefore we also measured
the accuracy and the count of a “diverse” condition:
only consider the subset of sentences with distinct
event phrases.
Table 1 shows the accuracy and the number
of training examples. The basic temporal system
brings us 0.50/0.62 micro- and macro- accuracy
overall and 0.38/0.51 in the diverse condition. It
shows that NewsSpikes are promising resources to
generate the training set, but that elaboration is nec-
essary. Yates09 gets 0.78/0.76 accuracy overall be-
cause its textual features help it to recognize many
good sentences with similar phrases. But for the di-
verse condition, it gets lower precision because the
distributional hypothesis fails to distinguish those
correlated but different phrases.
Although Ganitkevitch13 and Zhang13 leverage
existing paraphrase databases, it is interesting that
their accuracy is still not good. It is largely because
many times the paraphrasing must depend on the
context: e.g. “Cutler hits Martellus Bennett with TD
in closing seconds.” is not good for the beat(team,
team) relation, even though hit is a synonym for beat
in general. These two systems show that it is not
enough to use an off-the-shelf paraphrasing database
for extraction.
The ablation test shows the effectiveness of the
temporal negation hypothesis: after turning off the
relevant features and heuristic labels, the precision
drops about 10 percentage points. In addition,
the cross-spike factors bring NEWSSPIKE-RE about
22% more training sentences and also increase the
accuracy.
We did bootstrap sampling to test the statistical
significance of NEWSSPIKE-RE’s improvement in
accuracy over each comparison system and abla-
tion of NEWSSPIKE-RE. For each system we com-
puted the accuracy of 10 samples of 100 labeled
outputs. We then ran the paired t-test over the ac-
curacy numbers of each other system compared to
</bodyText>
<page confidence="0.997042">
125
</page>
<bodyText confidence="0.999689">
NEWSSPIKE-RE. For all but w/o cross the improve-
ment is strongly significant with p-value less than
1%. The increase in accuracy compared to w/o cross
has borderline significance (p-value 5.5%), but is a
clear win with its 22% increase in training size.
</bodyText>
<subsectionHeader confidence="0.998001">
7.3 Performance of the Event Extractors
</subsectionHeader>
<bodyText confidence="0.999908364705883">
Most previous relation extraction approaches either
require a manually labeled training set, or work
only on a pre-defined set of relations that have
ground instances from KBs. The closest work to
NEWSSPIKE-RE is Universal Schemas (Riedel et
al., 2013), which addresses the limitation of dis-
tant supervision that the relations must exist in KBs.
Their solution is to treat the surface strings, de-
pendency paths, and relations from KBs as equal
“schemas”, and then to exploit the correlation be-
tween the instances and the schemas from a very
large unlabeled corpus. In their paper, Riedel et al.
evaluated only on static relations from Freebase and
achieve state-of-the-art performance. But Universal
Schemas can be adapted to handle events, by intro-
ducing the events as schemas and heuristically find-
ing seed instances.
We set up a competing system (R13) as follows:
(1) We take the NYTimes corpus published between
1987 and 2007 (Sandhaus, 2008), the dataset used
by Riedel et al. (2013) containing 1.8 million NY
Times articles; (2) The instances (i.e. the rows of the
matrix) come from the entity pairs from the news ar-
ticles; (3) There are two types of columns: some are
the extraction features used by NEWSSPIKE-RE, in-
cluding the lexicalized dependency paths described
in Riedel et al.; others are event relations E =
e(t1, t2); (4) For an entity pair (a1, a2), if there is
an OpenIE extraction (a1, e, a2) and the entity types
of (a1, a2) match (t1, t2), we assume the event rela-
tion E is observed on that instance.
As shown in Table 1, parallel news streams are
a promising resource for clustering because of the
strong correlation between the instances and the
event phrases. We train another version of Universal
Schemas R13P on the parallel news streams NS13.
In particular, entity pairs from different NewsSpikes
are used as different rows in the matrix.
We would like to measure the precision and re-
call of the extractors. But note that it is impos-
sible to fully label all the sentences, so we follow
the “pooling” technique described in (Riedel et al.,
2013) to create the labeled dataset. For every com-
peting system, we sample 100 top outputs for every
event relation and add this to the pool. The anno-
tators are shown these sentences and asked to judge
whether the sentence expresses the event relation or
not. After that, the labeled set become “gold” and
can be used to measure the precision and pseudo-
recall. There are in all 6,178 distinct sentences in
the pool, since some outputs are produced by mul-
tiple systems. Among them, 2,903 sentences are la-
beled as positive. In Table 2, the # columns show
the number of true extractions in the pool for every
event relation.
Similar to the diverse condition in Table 1, it is
important that the extractor can correctly predict on
diverse sentences that are dissimilar to each other.
Thus we conducted a “diverse pooling”: for each
system, we report numbers for the sentences with
different dependency paths between the arguments
for every discovered event.
Figure 5(a) shows the precision pseudo-recall
curve for all sentences for the three systems.
NEWSSPIKE-RE outperforms the competing sys-
tems by a large margin. For example, the area un-
der the curve (AUC) of NEWSSPIKE-RE for all sen-
tences is 0.80 while that of R13P and R13 are 0.59
and 0.30. This is a 35% increase over R13P and 2.7
times the area compared to R13. Similar increases
in AUC are observed on diverse sentences. Table 2
further lists the breakdown numbers for each event
relation, as well as the micro and macro average.
Although Universal Schemas had some success for
several relations, NEWSSPIKE-RE achieved the best
F1 for 26 out of 30 event relations; best AUC for 26
out of 30. The advantage is even greater in the di-
verse condition. It is interesting to see that R13P
performs much better than R13, since the data com-
ing from NYTimes is much noisier.
A closer look shows that Universal Schemas
tends to confuse correlated but different phrases.
NEWSSPIKE-RE, however, rarely made these errors
because our model can effectively exploit negative
evidence to distinguish them.
</bodyText>
<subsectionHeader confidence="0.885963">
7.3.1 Comparing to Distant Supervision
</subsectionHeader>
<bodyText confidence="0.99919375">
Although the most event relations in Table 2 can-
not be handled by the distant supervised approach,
it is possible to match buy(org,org) to Freebase re-
lations with appropriate database operators such as
</bodyText>
<page confidence="0.985368">
126
</page>
<figure confidence="0.998843851851852">
Precision
Pseudo Recall
(a)
Pseudo Recall
(b)
1.0
0.8
0.6
NewsSpike-RE on NS13
Precision
R13P: Uschema on NS13
R13: Uschema on NYT
0.0 0.2 0.4 0.6 0.8 1.0
0.4
0.2
0.0
NewsSpike-RE on NS13
R13P: Uschema on NS13
R13: Uschema on NYT
DS on NYT
0.0 0.2 0.4 0.6 0.8 1.0
1.0
0.8
0.6
0.4
0.2
0.0
</figure>
<figureCaption confidence="0.902701">
Figure 5: Precision pseudo-recall curves for (a) all event relations; (b) buy(org, org), this figure includes the distant
supervision algorithm MIML learned from matching the Freebase relation5 to The New York Times. NEWSSPIKE-RE
has AUC 0.80, more than doubling R13 (0.30) and 35% higher than R13P (0.59) for all event relations.
</figureCaption>
<bodyText confidence="0.999936647058824">
join and select (Zhang et al., 2012). To evaluate
how distant supervision performs, we introduce the
system DS on NYT based on a manual mapping of
buy(org,org) to the join relation4 in Freebase. Then
we match its instances to NYTimes articles and fol-
low the steps of Surdeanu et al. (2012) to train the
extractor.
The matching to NYTimes brings us 264 positive
instances having 5,333 sentences, but unfortunately
the sentence-level accuracy is only 13% based on
examination of 100 random sentences. Figure 5(b)
shows the PR curves for all the competing systems.
Distant supervision predicts the top extractions cor-
rectly because the multi-instance technique recog-
nizes some common expressions (e.g. buy, acquire),
but the precision drops dramatically since most pos-
itive expressions are overwhelmed by the noise.
</bodyText>
<sectionHeader confidence="0.995821" genericHeader="conclusions">
8 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.966928625">
Popular distant supervised approaches have limited
ability to handle event extraction, since fluent facts
are highly time dependent and often do not exist in
any KB. This paper presents a novel unsupervised
approach for event extraction that exploits parallel
news streams. Our NEWSSPIKE-RE system auto-
matically identifies a set of argument-typed events
from a news corpus, and then learns a sentential
(micro-reading) extractor for each event.
We introduced a novel, temporal negation heuris-
tic for parallel news streams that identifies event
phrases that are correlated, but are not paraphrases.
We encoded this in a probabilistic graphical model
4/organization/organization/companies_
acquired✶/business/acquisition/company_acquired
to cluster sentences, generating high quality training
data to learn a sentential extractor. This provides
negative evidence crucial to achieving high preci-
sion training data.
Experiments show the high quality of the gener-
ated training sentences and confirm the importance
of our negation heuristic. Our most important exper-
iment shows that we can learn accurate event extrac-
tors from this training data. NEWSSPIKE-RE out-
performs comparable extractors by a wide margin,
more than doubling the area under a precision-recall
curve compared to Universal Schemas.
In future work we plan to implement our system
as an end-to-end online service. This would allow
users to conveniently define events of interest, learn
extractors for each event, and return extracted facts
from news streams.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999769454545454">
We thank Hal Daume III, Xiao Ling, Luke Zettle-
moyer and the reviewers. This work was supported
by ONR grant N00014-12-1-0211, the WRF/Cable
Professorship, a gift from Google, and the Defense
Advanced Research Projects Agency (DARPA) Ma-
chine Reading Program under Air Force Research
Laboratory (AFRL) prime contract no. FA8750-09-
C-0181. Any opinions, findings, and conclusions
or recommendations expressed in this material are
those of the author(s) and do not necessarily reflect
the view of DARPA, AFRL, or the US government.
</bodyText>
<page confidence="0.996178">
127
</page>
<sectionHeader confidence="0.988651" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997918942307692">
Eugene Agichtein and Luis Gravano. 2000. Snowball:
extracting relations from large plain-text collections.
In ACM DL, pages 85–94.
Michele Banko, Michael J. Cafarella, Stephen Soderland,
Matthew Broadhead, and Oren Etzioni. 2007. Open
information extraction from the web. In Proceedings
of the 20th International Joint Conference on Artificial
Intelligence (IJCAI-07), pages 2670–2676.
Regina Barzilay and Lillian Lee. 2003. Learning to
paraphrase: an unsupervised approach using multiple-
sequence alignment. In Proceedings of the 2003 Con-
ference of the North American Chapter of the Associ-
ation for Computational Linguistics on Human Lan-
guage Technology (HLT-NAACL), pages 16–23.
Regina Barzilay and Kathleen R McKeown. 2001. Ex-
tracting paraphrases from a parallel corpus. In Pro-
ceedings of the 39th Annual Meeting on Association
for Computational Linguistics (ACL), pages 50–57.
Edward Benson, Aria Haghighi, and Regina Barzilay.
2011. Event discovery in social media feeds. In Pro-
ceedings of the 49th Annual Meeting of the Associa-
tion for Computational Linguistics: Human Language
Technologies (HLT-NAACL), pages 389–398.
Sergey Brin. 1999. Extracting patterns and relations
from the world wide web. In The World Wide Web
and Databases, pages 172–183.
Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr
Settles, Estevam R. Hruschka Jr., and Tom M.
Mitchell. 2010. Toward an architecture for never-
ending language learning. In Proceedings of the AAAI
Conference on Artificial Intelligence (AAAI-10).
Michael Collins. 2002. Discriminative training meth-
ods for hidden Markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings of
the ACL-02 conference on Empirical methods in natu-
ral language processing-Volume 10, pages 1–8.
Mark Craven and Johan Kumlien. 1999. Constructing
biological knowledge bases by extracting information
from text sources. In Proceedings of the Seventh Inter-
national Conference on Intelligent Systems for Molec-
ular Biology (ISMB), pages 77–86.
Bill Dolan, Chris Quirk, and Chris Brockett. 2004. Un-
supervised construction of large paraphrase corpora:
Exploiting massively parallel news sources. In Com-
putational Linguistics, page 350.
Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011. Identifying relations for open information
extraction. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 1535–1545.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by Gibbs sam-
pling. In Proceedings of the 43rd Annual Meeting
on Association for Computational Linguistics (ACL),
pages 363–370.
Juri Ganitkevitch, Benjamin Van Durme, and Chris
Callison-Burch. 2013. PPDB: The paraphrase
database. In Joint Human Language Technology Con-
ference/Annual Meeting of the North American Chap-
ter of the Association for Computational Linguistics
(HLT-NAACL 2013), pages 758–764.
Takaaki Hasegawa, Satoshi Sekine, and Ralph Grishman.
2004. Discovering relations among named entities
from large corpora. In Proceedings of the 42nd Annual
Meeting on Association for Computational Linguistics
(ACL), page 415.
Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke
Zettlemoyer, and Daniel S Weld. 2011. Knowledge-
based weak supervision for information extraction of
overlapping relations. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies (HLT-
ACL), pages 541–550.
Ruihong Huang and Ellen Riloff. 2013. Multi-faceted
event recognition with bootstrapped dictionaries. In
the Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies (HLT-NAACL), pages 41–51.
Dekang Lin and Patrick Pantel. 2001. Discovery of infer-
ence rules for question-answering. Natural Language
Engineering, 7(4):343–360.
Xiao Ling and Daniel S Weld. 2012. Fine-grained entity
recognition. In Association for the Advancement of
Artificial Intelligence (AAAI).
David McClosky, Mihai Surdeanu, and Christopher D
Manning. 2011. Event extraction as dependency pars-
ing. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies (HLT-ACL), pages 1626–
1635.
Mike Mintz, Steven Bills, Rion Snow, and Daniel Juraf-
sky. 2009. Distant supervision for relation extrac-
tion without labeled data. In Proceedings of the 47th
Annual Meeting of the Association for Computational
Linguistics (ACL), pages 1003–1011.
Ndapandula Nakashole, Martin Theobald, and Gerhard
Weikum. 2011. Scalable knowledge harvesting with
high precision and high recall. In Proceedings of the
fourth ACM international conference on Web search
and data mining (WSDM), pages 227–236.
George L Nemhauser and Laurence A Wolsey. 1988. In-
teger and combinatorial optimization, volume 18. Wi-
ley New York.
</reference>
<page confidence="0.976176">
128
</page>
<reference confidence="0.999066202531646">
Roi Reichart and Regina Barzilay. 2012. Multi event ex-
traction guided by global constraints. In Proceedings
of the 2012 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies (HLT-NAACL), pages
70–79.
Kevin Reschke, Martin Jankowiak, Mihai Surdeanu,
Christopher D Manning, and Daniel Jurafsky. 2014.
Event extraction using distant supervision. In Lan-
guage Resources and Evaluation Conference (LREC).
Sebastian Riedel, Limin Yao, and Andrew McCallum.
2010. Modeling relations and their mentions with-
out labeled text. In Machine Learning and Knowledge
Discovery in Databases (ECML), pages 148–163.
Sebastian Riedel, David McClosky, Mihai Surdeanu, An-
drew McCallum, and Christopher D Manning. 2011.
Model combination for event extraction in BioNLP
2011. In Proceedings of the BioNLP Shared Task 2011
Workshop, pages 51–55.
Sebastian Riedel, Limin Yao, Benjamin M. Mar-
lin, and Andrew McCallum. 2013. Relation
extraction with matrix factorization and universal
schemas. In Joint Human Language Technology Con-
ference/Annual Meeting of the North American Chap-
ter of the Association for Computational Linguistics
(HLT-NAACL).
Alan Ritter, Oren Etzioni, Sam Clark, et al. 2012. Open
domain event extraction from twitter. In Proceedings
of the 18th ACM SIGKDD international conference on
Knowledge discovery and data mining (KDD), pages
1104–1112.
Evan Sandhaus. 2008. The New York Times annotated
corpus. Linguistic Data Consortium.
Yusuke Shinyama and Satoshi Sekine. 2006. Preemp-
tive information extraction using unrestricted relation
discovery. In Proceedings of the main conference
on Human Language Technology Conference of the
North American Chapter of the Association of Com-
putational Linguistics (HLT-NAACL), pages 304–311.
Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and
Christopher D Manning. 2012. Multi-instance multi-
label learning for relation extraction. In Proceedings
of the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning (EMNLP), pages 455–
465.
Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa.
2011. Probabilistic matrix factorization leveraging
contexts for unsupervised relation extraction. In Ad-
vances in Knowledge Discovery and Data Mining,
pages 87–99.
Fei Wu and Daniel S. Weld. 2007. Autonomously se-
mantifying wikipedia. In Proceedings of the Inter-
national Conference on Information and Knowledge
Management (CIKM), pages 41–50.
Limin Yao, Aria Haghighi, Sebastian Riedel, and Andrew
McCallum. 2011. Structured relation discovery using
generative models. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing (EMNLP), pages 1456–1466.
Limin Yao, Sebastian Riedel, and Andrew McCallum.
2012. Unsupervised relation discovery with sense dis-
ambiguation. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 712–720.
Alexander Yates and Oren Etzioni. 2009. Unsupervised
methods for determining object and relation synonyms
on the web. Journal ofArtificial Intelligence Research,
34(1):255.
Congle Zhang and Daniel S Weld. 2013. Harvesting par-
allel news streams to generate paraphrases of event re-
lations. In Proceedings of the 2013 Joint Conference
on Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP), pages 455–465.
Congle Zhang, Raphael Hoffmann, and Daniel S Weld.
2012. Ontological smoothing for relation extraction
with minimal supervision. In Association for the Ad-
vancement of Artificial Intelligence (AAAI).
</reference>
<page confidence="0.999238">
129
130
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.855482">
<title confidence="0.999873">Exploiting Parallel News Streams for Unsupervised Event Extraction</title>
<author confidence="0.962832">Congle Zhang</author>
<author confidence="0.962832">Stephen Soderland</author>
<author confidence="0.962832">S Daniel</author>
<affiliation confidence="0.9997995">Computer Science &amp; University of</affiliation>
<address confidence="0.999742">Seattle, WA 98195,</address>
<email confidence="0.979448">soderlan,</email>
<abstract confidence="0.996692928571429">approaches to the task of extracting ground facts from natural language text, are based on machine learning and thus starved by scarce training data. Manual annotation is too expensive to scale to a comprehensive set of relations. Distant supervision, which automatically creates training data, only works with relations that already populate a knowledge base (KB). Unfortunately, KBs such as FreeBase rarely cover relations “person travels to loca- Thus, the problem of extracting a wide range of events — e.g., from news streams — is an important, open challenge. paper introduces a novel, unsupervised algorithm that discovers event relations and then learns to extract them. uses a novel probabilistic graphical model to cluster sentences describing similar events from parallel news streams. These clusters then comprise training data for the extractor. Our evaluation shows that generates high quality training sentences and learns extractors that perform much better than rival approaches, more than doubling the area under a precision-recall curve compared to Universal Schemas.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eugene Agichtein</author>
<author>Luis Gravano</author>
</authors>
<title>Snowball: extracting relations from large plain-text collections.</title>
<date>2000</date>
<booktitle>In ACM DL,</booktitle>
<pages>85--94</pages>
<contexts>
<context position="6770" citStr="Agichtein and Gravano, 2000" startWordPosition="1025" endWordPosition="1028"> from Wikipedia, while Mintz et al. (2009) heuristically matched Freebase facts to texts. Since the training data generated by the heuristic matching is often imperfect, multiinstance learning approaches (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) have been developed to combat this problem. Unfortunately, most facts existing in the KBs are static facts like geographical or biographical data. They fall short of learning extractors for fluent facts such as sports results or travel and meetings by a person. Bootstrapping is another common extraction technique (Brin, 1999; Agichtein and Gravano, 2000; Carlson et al., 2010; Nakashole et al., 2011; Huang and Riloff, 2013). This typically takes a set of seeds as input, which can be ground instances or key phrases. The algorithms then iteratively generate more positive instances and phrases. While there are many successful examples of bootstrapping, the challenge is to avoid semantic drift. Large-scale systems, therefore, often require extra processing such as manual validation between the iterations or additional negative seeds as the input. Unsupervised approaches have been developed for relation discovery and extractions. These algorithms </context>
</contexts>
<marker>Agichtein, Gravano, 2000</marker>
<rawString>Eugene Agichtein and Luis Gravano. 2000. Snowball: extracting relations from large plain-text collections. In ACM DL, pages 85–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Michael J Cafarella</author>
<author>Stephen Soderland</author>
<author>Matthew Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<title>Open information extraction from the web.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI-07),</booktitle>
<pages>2670--2676</pages>
<contexts>
<context position="5693" citStr="Banko et al., 2007" startWordPosition="859" endWordPosition="862">s Universal Schema (Riedel et al., 2013). 2 Previous Work Supervised learning approaches have been widely developed for event extraction tasks such as MUC-4 and ACE. They often focus on a hand-crafted ontology and train the extractor with manually created training data. While they can offer high precision and recall, they are often domain-specific (e.g. biological events (Riedel et al., 2011; McClosky et al., 2011) and entertainment events (Benson et al., 2011; Reichart and Barzilay, 2012)), and are hard to scale over the events on the Web. Open IE systems extract open domain relations (e.g. (Banko et al., 2007; Fader et al., 2011)) and events (e.g. (Ritter et al., 2012)). They often perform self-supervised learning of relation-independent extractions. It allows them to scale but makes them unable to output canonicalized relations. Distant supervised approaches have been developed to learn extractors by exploiting the facts existing in a knowledge base, thus avoiding human annotation. Wu et al. (2007) and Reschke et al. (2014) learned Infobox relations from Wikipedia, while Mintz et al. (2009) heuristically matched Freebase facts to texts. Since the training data generated by the heuristic matching </context>
</contexts>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Michele Banko, Michael J. Cafarella, Stephen Soderland, Matthew Broadhead, and Oren Etzioni. 2007. Open information extraction from the web. In Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI-07), pages 2670–2676.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Learning to paraphrase: an unsupervised approach using multiplesequence alignment.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (HLT-NAACL),</booktitle>
<pages>16--23</pages>
<contexts>
<context position="8443" citStr="Barzilay and Lee, 2003" startWordPosition="1275" endWordPosition="1278">t semantically different phrases during extraction. In contrast to this, our work largely avoids these errors by exploiting the temporal negation heuristic in parallel news streams. In addition, unlike many unsupervised algorithms requiring human effort to canonicalize the clusters, our work automatically discovers events with readable names. Paraphrasing techniques inspire our work. Some techniques, such as DIRT (Lin and Pantel, 2001) and Resolver (Yates and Etzioni, 2009), are based on the distributional hypothesis. Another common approach is to use parallel corpora, including news streams (Barzilay and Lee, 2003; Dolan et al., 2004; Zhang and Weld, 2013), multiple translations of the same story (Barzilay and McKeown, 2001) and bilingual sentence pairs (Ganitkevitch et al., 2013) to generate the paraphrases. Although these algorithms create many good paraphrases, they can not be directly used to generate enough training data to train a relation extractor for two reasons: first, the semantics of the paraphrases is often context dependent; second, the generated paraphrases are often in 118 Training Phase Testing Phase Figure 1: During its training phase, NEWSSPIKE-RE first groups parallel sentences as N</context>
</contexts>
<marker>Barzilay, Lee, 2003</marker>
<rawString>Regina Barzilay and Lillian Lee. 2003. Learning to paraphrase: an unsupervised approach using multiplesequence alignment. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (HLT-NAACL), pages 16–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Extracting paraphrases from a parallel corpus.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting on Association for Computational Linguistics (ACL),</booktitle>
<pages>50--57</pages>
<contexts>
<context position="8556" citStr="Barzilay and McKeown, 2001" startWordPosition="1293" endWordPosition="1296">s by exploiting the temporal negation heuristic in parallel news streams. In addition, unlike many unsupervised algorithms requiring human effort to canonicalize the clusters, our work automatically discovers events with readable names. Paraphrasing techniques inspire our work. Some techniques, such as DIRT (Lin and Pantel, 2001) and Resolver (Yates and Etzioni, 2009), are based on the distributional hypothesis. Another common approach is to use parallel corpora, including news streams (Barzilay and Lee, 2003; Dolan et al., 2004; Zhang and Weld, 2013), multiple translations of the same story (Barzilay and McKeown, 2001) and bilingual sentence pairs (Ganitkevitch et al., 2013) to generate the paraphrases. Although these algorithms create many good paraphrases, they can not be directly used to generate enough training data to train a relation extractor for two reasons: first, the semantics of the paraphrases is often context dependent; second, the generated paraphrases are often in 118 Training Phase Testing Phase Figure 1: During its training phase, NEWSSPIKE-RE first groups parallel sentences as NewsSpikes. Next, the system automatically discovers a set of event relations. Then, a probabilistic graphical mod</context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>Regina Barzilay and Kathleen R McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proceedings of the 39th Annual Meeting on Association for Computational Linguistics (ACL), pages 50–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Benson</author>
<author>Aria Haghighi</author>
<author>Regina Barzilay</author>
</authors>
<title>Event discovery in social media feeds.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),</booktitle>
<pages>389--398</pages>
<contexts>
<context position="5539" citStr="Benson et al., 2011" startWordPosition="832" endWordPosition="835">outperform several competitive baselines, e.g. our system more than doubles the area under the micro-averaged, PR curve (0.80 vs. 0.30) compared to Riedel’s Universal Schema (Riedel et al., 2013). 2 Previous Work Supervised learning approaches have been widely developed for event extraction tasks such as MUC-4 and ACE. They often focus on a hand-crafted ontology and train the extractor with manually created training data. While they can offer high precision and recall, they are often domain-specific (e.g. biological events (Riedel et al., 2011; McClosky et al., 2011) and entertainment events (Benson et al., 2011; Reichart and Barzilay, 2012)), and are hard to scale over the events on the Web. Open IE systems extract open domain relations (e.g. (Banko et al., 2007; Fader et al., 2011)) and events (e.g. (Ritter et al., 2012)). They often perform self-supervised learning of relation-independent extractions. It allows them to scale but makes them unable to output canonicalized relations. Distant supervised approaches have been developed to learn extractors by exploiting the facts existing in a knowledge base, thus avoiding human annotation. Wu et al. (2007) and Reschke et al. (2014) learned Infobox relat</context>
</contexts>
<marker>Benson, Haghighi, Barzilay, 2011</marker>
<rawString>Edward Benson, Aria Haghighi, and Regina Barzilay. 2011. Event discovery in social media feeds. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL), pages 389–398.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
</authors>
<title>Extracting patterns and relations from the world wide web. In The World Wide Web and Databases,</title>
<date>1999</date>
<pages>172--183</pages>
<contexts>
<context position="6741" citStr="Brin, 1999" startWordPosition="1023" endWordPosition="1024">ox relations from Wikipedia, while Mintz et al. (2009) heuristically matched Freebase facts to texts. Since the training data generated by the heuristic matching is often imperfect, multiinstance learning approaches (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) have been developed to combat this problem. Unfortunately, most facts existing in the KBs are static facts like geographical or biographical data. They fall short of learning extractors for fluent facts such as sports results or travel and meetings by a person. Bootstrapping is another common extraction technique (Brin, 1999; Agichtein and Gravano, 2000; Carlson et al., 2010; Nakashole et al., 2011; Huang and Riloff, 2013). This typically takes a set of seeds as input, which can be ground instances or key phrases. The algorithms then iteratively generate more positive instances and phrases. While there are many successful examples of bootstrapping, the challenge is to avoid semantic drift. Large-scale systems, therefore, often require extra processing such as manual validation between the iterations or additional negative seeds as the input. Unsupervised approaches have been developed for relation discovery and e</context>
</contexts>
<marker>Brin, 1999</marker>
<rawString>Sergey Brin. 1999. Extracting patterns and relations from the world wide web. In The World Wide Web and Databases, pages 172–183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carlson</author>
<author>Justin Betteridge</author>
<author>Bryan Kisiel</author>
<author>Burr Settles</author>
<author>Estevam R Hruschka Jr</author>
<author>Tom M Mitchell</author>
</authors>
<title>Toward an architecture for neverending language learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI-10).</booktitle>
<contexts>
<context position="6792" citStr="Carlson et al., 2010" startWordPosition="1029" endWordPosition="1032">et al. (2009) heuristically matched Freebase facts to texts. Since the training data generated by the heuristic matching is often imperfect, multiinstance learning approaches (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) have been developed to combat this problem. Unfortunately, most facts existing in the KBs are static facts like geographical or biographical data. They fall short of learning extractors for fluent facts such as sports results or travel and meetings by a person. Bootstrapping is another common extraction technique (Brin, 1999; Agichtein and Gravano, 2000; Carlson et al., 2010; Nakashole et al., 2011; Huang and Riloff, 2013). This typically takes a set of seeds as input, which can be ground instances or key phrases. The algorithms then iteratively generate more positive instances and phrases. While there are many successful examples of bootstrapping, the challenge is to avoid semantic drift. Large-scale systems, therefore, often require extra processing such as manual validation between the iterations or additional negative seeds as the input. Unsupervised approaches have been developed for relation discovery and extractions. These algorithms are usually based on s</context>
</contexts>
<marker>Carlson, Betteridge, Kisiel, Settles, Jr, Mitchell, 2010</marker>
<rawString>Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R. Hruschka Jr., and Tom M. Mitchell. 2010. Toward an architecture for neverending language learning. In Proceedings of the AAAI Conference on Artificial Intelligence (AAAI-10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="28805" citStr="Collins, 2002" startWordPosition="4790" endWordPosition="4791">ll sentences with p E P−. With P+, P−, S+, S−, we define the heuristic labeled set to be {(Y label i , Zlabel i ) |M i=1}, where M is the number of the connected components with the corresponding event phrases p E P+ U P−; Y label = 1 ifE P+ d Y label = i p and is labeled similarly, but note that if the sentence in the connected component doesn’t exist in S+ U S−, NEWSSPIKE-RE doesn’t include the corresponding variable in Zlabel i .With {(Y label i , Zlabel i ) |M i=1}, learning can be done with maximum likelihood estimation as L(O) = log Hi p(Yi = ylabel i ,Zi = zlabel i | xi, O). Following (Collins, 2002), we use a fast perceptron learning approach to update O. It consists of iterating two steps: (1) MAP inference given the current weight; (2) penalizing the weights if the inferred assignments are different from the heuristic labeled assignments. 6 Sentential Event Extraction As shown in Figure 1, we learn the extractors from the generated training sentences. Note that most distant supervised (Hoffmann et al., 2011; Surdeanu et al., 2012) approaches use multi-instance, aggregatelevel training (i.e. the supervision comes from labeled sets of instances instead of individually labeled sentences).</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Craven</author>
<author>Johan Kumlien</author>
</authors>
<title>Constructing biological knowledge bases by extracting information from text sources.</title>
<date>1999</date>
<booktitle>In Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology (ISMB),</booktitle>
<pages>77--86</pages>
<contexts>
<context position="1866" citStr="Craven and Kumlien, 1999" startWordPosition="271" endWordPosition="274">ty training sentences and learns extractors that perform much better than rival approaches, more than doubling the area under a precision-recall curve compared to Universal Schemas. 1 Introduction Relation extraction, the process of extracting structured information from natural language text, grows increasingly important for Web search and question answering. Traditional supervised approaches, which can achieve high precision and recall, are limited by the cost of labeling training data and are unlikely to scale to the thousands of relations on the Web. Another approach, distant supervision (Craven and Kumlien, 1999; Wu and Weld, 2007), creates its own training data by matching the ground instances of a Knowledge base (KB) (e.g. Freebase) to the unlabeled text. Unfortunately, while distant supervision can work well in some situations, the method is limited to relatively static facts (e.g., born-in(person, location) or capital-of(location,location)) where there is a corresponding knowledge base. But what about dynamic event relations (also known as fluents), such as travel-to(person, location) or fire(organization, person)? Since these time-dependent facts are ephemeral, they are rarely stored in a pre-ex</context>
</contexts>
<marker>Craven, Kumlien, 1999</marker>
<rawString>Mark Craven and Johan Kumlien. 1999. Constructing biological knowledge bases by extracting information from text sources. In Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology (ISMB), pages 77–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill Dolan</author>
<author>Chris Quirk</author>
<author>Chris Brockett</author>
</authors>
<title>Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources.</title>
<date>2004</date>
<booktitle>In Computational Linguistics,</booktitle>
<pages>350</pages>
<contexts>
<context position="8463" citStr="Dolan et al., 2004" startWordPosition="1279" endWordPosition="1282"> phrases during extraction. In contrast to this, our work largely avoids these errors by exploiting the temporal negation heuristic in parallel news streams. In addition, unlike many unsupervised algorithms requiring human effort to canonicalize the clusters, our work automatically discovers events with readable names. Paraphrasing techniques inspire our work. Some techniques, such as DIRT (Lin and Pantel, 2001) and Resolver (Yates and Etzioni, 2009), are based on the distributional hypothesis. Another common approach is to use parallel corpora, including news streams (Barzilay and Lee, 2003; Dolan et al., 2004; Zhang and Weld, 2013), multiple translations of the same story (Barzilay and McKeown, 2001) and bilingual sentence pairs (Ganitkevitch et al., 2013) to generate the paraphrases. Although these algorithms create many good paraphrases, they can not be directly used to generate enough training data to train a relation extractor for two reasons: first, the semantics of the paraphrases is often context dependent; second, the generated paraphrases are often in 118 Training Phase Testing Phase Figure 1: During its training phase, NEWSSPIKE-RE first groups parallel sentences as NewsSpikes. Next, the</context>
</contexts>
<marker>Dolan, Quirk, Brockett, 2004</marker>
<rawString>Bill Dolan, Chris Quirk, and Chris Brockett. 2004. Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources. In Computational Linguistics, page 350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fader</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Identifying relations for open information extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1535--1545</pages>
<contexts>
<context position="5714" citStr="Fader et al., 2011" startWordPosition="863" endWordPosition="866">Riedel et al., 2013). 2 Previous Work Supervised learning approaches have been widely developed for event extraction tasks such as MUC-4 and ACE. They often focus on a hand-crafted ontology and train the extractor with manually created training data. While they can offer high precision and recall, they are often domain-specific (e.g. biological events (Riedel et al., 2011; McClosky et al., 2011) and entertainment events (Benson et al., 2011; Reichart and Barzilay, 2012)), and are hard to scale over the events on the Web. Open IE systems extract open domain relations (e.g. (Banko et al., 2007; Fader et al., 2011)) and events (e.g. (Ritter et al., 2012)). They often perform self-supervised learning of relation-independent extractions. It allows them to scale but makes them unable to output canonicalized relations. Distant supervised approaches have been developed to learn extractors by exploiting the facts existing in a knowledge base, thus avoiding human annotation. Wu et al. (2007) and Reschke et al. (2014) learned Infobox relations from Wikipedia, while Mintz et al. (2009) heuristically matched Freebase facts to texts. Since the training data generated by the heuristic matching is often imperfect, m</context>
<context position="10466" citStr="Fader et al., 2011" startWordPosition="1588" endWordPosition="1591">EWSSPIKE-RE, aligns paralel news streams to indentify and extract these events as shown in Figure 1. NEWSSPIKE-RE has both training and test phases. Its training phase has two main steps: event-relation discovery and training-set generation. Section 4 describes our event relation discovery algorithm, which processes time-stamped news articles to discern a set of salient, distinct event relations in the form of E = e(t1, t2), where e is a representative event phrase and ti are types of the two arguments. NEWSSPIKE-RE generates the event phrases using an Open Information Extraction (IE) system (Fader et al., 2011), and uses a fine-grained entity recognition system FIGER (Ling and Weld, 2012) to generate type descriptors such as “company ”, “politician”, and “medical treatment”. The second part of NEWSSPIKE-RE’s training phase, described in Section 5, is a method for building extractors for the discovered event relations. Our approach is motivated by the intuition, adapted from Zhang and Weld (2013), that articles from different news sources typically use different sentences to describe the same event, and that corresponding sentences can be identified when they mention a unique pair of real-world entit</context>
</contexts>
<marker>Fader, Soderland, Etzioni, 2011</marker>
<rawString>Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations for open information extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1535–1545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by Gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics (ACL),</booktitle>
<pages>363--370</pages>
<contexts>
<context position="14855" citStr="Finkel et al., 2005" startWordPosition="2315" endWordPosition="2318">ations, researchers often use specialized learners that model the correctness of a training example with a latent variable (Riedel et al., 2010; Hoffmann et al., 2011), but we found this unnecessary, because NEWSSPIKE-RE creates high quality training data. 4 Discovering Salient Events The first step of NEWSSPIKE-RE is to discover a set of event relations in the form of E = e(t1, t2), where e is an event phrase, and ti are fine-grained argument types generated by FIGER, augmented with the important types “number” and “money”, which are recognized by the Stanford name entity recognition system (Finkel et al., 2005). To be most useful, the discovered event relations should cover salient events that are frequently reported in the news articles. Formally, we say that a NewsSpike η = (a1, a2, d, S) mentions E = e(t1, t2) if the types of ai are ti for each i, and one of its sentence has e as the event phrase between the arguments. To maximize the salience of the events, NEWSSPIKE-RE will prefer event relations that are “mentioned” by more NewsSpikes. In addition, the set of event relations should be distict. For example, if the relation travel-to(person, location) is already in the set, then visit(person, lo</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by Gibbs sampling. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics (ACL), pages 363–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juri Ganitkevitch</author>
<author>Benjamin Van Durme</author>
<author>Chris Callison-Burch</author>
</authors>
<title>PPDB: The paraphrase database.</title>
<date>2013</date>
<booktitle>In Joint Human Language Technology Conference/Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL</booktitle>
<pages>758--764</pages>
<marker>Ganitkevitch, Van Durme, Callison-Burch, 2013</marker>
<rawString>Juri Ganitkevitch, Benjamin Van Durme, and Chris Callison-Burch. 2013. PPDB: The paraphrase database. In Joint Human Language Technology Conference/Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 2013), pages 758–764.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takaaki Hasegawa</author>
<author>Satoshi Sekine</author>
<author>Ralph Grishman</author>
</authors>
<title>Discovering relations among named entities from large corpora.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics (ACL),</booktitle>
<pages>415</pages>
<contexts>
<context position="7537" citStr="Hasegawa et al., 2004" startWordPosition="1142" endWordPosition="1145">es or key phrases. The algorithms then iteratively generate more positive instances and phrases. While there are many successful examples of bootstrapping, the challenge is to avoid semantic drift. Large-scale systems, therefore, often require extra processing such as manual validation between the iterations or additional negative seeds as the input. Unsupervised approaches have been developed for relation discovery and extractions. These algorithms are usually based on some clustering assumptions over a large unlabeled corpus. Common assumptions include the distributional hypothesis used by (Hasegawa et al., 2004; Shinyama and Sekine, 2006), latent topic assumption by (Yao et al., 2012; Yao et al., 2011), and low rank assumption by (Takamatsu et al., 2011; Riedel et al., 2013). Since the assumptions largely rely on co-occurrence, previous unsupervised approaches tend to confuse correlated but semantically different phrases during extraction. In contrast to this, our work largely avoids these errors by exploiting the temporal negation heuristic in parallel news streams. In addition, unlike many unsupervised algorithms requiring human effort to canonicalize the clusters, our work automatically discovers</context>
</contexts>
<marker>Hasegawa, Sekine, Grishman, 2004</marker>
<rawString>Takaaki Hasegawa, Satoshi Sekine, and Ralph Grishman. 2004. Discovering relations among named entities from large corpora. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics (ACL), page 415.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raphael Hoffmann</author>
<author>Congle Zhang</author>
<author>Xiao Ling</author>
<author>Luke Zettlemoyer</author>
<author>Daniel S Weld</author>
</authors>
<title>Knowledgebased weak supervision for information extraction of overlapping relations.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (HLTACL),</booktitle>
<pages>541--550</pages>
<contexts>
<context position="6390" citStr="Hoffmann et al., 2011" startWordPosition="966" endWordPosition="969">erform self-supervised learning of relation-independent extractions. It allows them to scale but makes them unable to output canonicalized relations. Distant supervised approaches have been developed to learn extractors by exploiting the facts existing in a knowledge base, thus avoiding human annotation. Wu et al. (2007) and Reschke et al. (2014) learned Infobox relations from Wikipedia, while Mintz et al. (2009) heuristically matched Freebase facts to texts. Since the training data generated by the heuristic matching is often imperfect, multiinstance learning approaches (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) have been developed to combat this problem. Unfortunately, most facts existing in the KBs are static facts like geographical or biographical data. They fall short of learning extractors for fluent facts such as sports results or travel and meetings by a person. Bootstrapping is another common extraction technique (Brin, 1999; Agichtein and Gravano, 2000; Carlson et al., 2010; Nakashole et al., 2011; Huang and Riloff, 2013). This typically takes a set of seeds as input, which can be ground instances or key phrases. The algorithms then iteratively generate more positive </context>
<context position="14402" citStr="Hoffmann et al., 2011" startWordPosition="2239" endWordPosition="2242">ations and ηj are NewsSpikes. The optimal solution selects E1 with edges to η1 and η2, and E3 with edge to η3. These two event relations cover all the NewsSpikes. gorithm that requires no manual labelling of the training instances. Like distant supervision, the key is to automatically generate the training data, at which point a traditional supervised classifier may be applied to learn an extractor. Because distant supervision creates very noisy annotations, researchers often use specialized learners that model the correctness of a training example with a latent variable (Riedel et al., 2010; Hoffmann et al., 2011), but we found this unnecessary, because NEWSSPIKE-RE creates high quality training data. 4 Discovering Salient Events The first step of NEWSSPIKE-RE is to discover a set of event relations in the form of E = e(t1, t2), where e is an event phrase, and ti are fine-grained argument types generated by FIGER, augmented with the important types “number” and “money”, which are recognized by the Stanford name entity recognition system (Finkel et al., 2005). To be most useful, the discovered event relations should cover salient events that are frequently reported in the news articles. Formally, we say</context>
<context position="29223" citStr="Hoffmann et al., 2011" startWordPosition="4856" endWordPosition="4859">ng variable in Zlabel i .With {(Y label i , Zlabel i ) |M i=1}, learning can be done with maximum likelihood estimation as L(O) = log Hi p(Yi = ylabel i ,Zi = zlabel i | xi, O). Following (Collins, 2002), we use a fast perceptron learning approach to update O. It consists of iterating two steps: (1) MAP inference given the current weight; (2) penalizing the weights if the inferred assignments are different from the heuristic labeled assignments. 6 Sentential Event Extraction As shown in Figure 1, we learn the extractors from the generated training sentences. Note that most distant supervised (Hoffmann et al., 2011; Surdeanu et al., 2012) approaches use multi-instance, aggregatelevel training (i.e. the supervision comes from labeled sets of instances instead of individually labeled sentences). Coping with the noise inherent in these multi-instance bags remains a big challenge for distant supervision. In contrast, our sentencelevel training data is more direct and minimizes noise. Therefore, we implement the event extractor as a simple multi-class, L2-regularized logistic regression classifier. For features of the classifier, we use the lexicalized dependency paths, the OpenIE phrases, the minimal subtre</context>
</contexts>
<marker>Hoffmann, Zhang, Ling, Zettlemoyer, Weld, 2011</marker>
<rawString>Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S Weld. 2011. Knowledgebased weak supervision for information extraction of overlapping relations. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (HLTACL), pages 541–550.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruihong Huang</author>
<author>Ellen Riloff</author>
</authors>
<title>Multi-faceted event recognition with bootstrapped dictionaries.</title>
<date>2013</date>
<booktitle>In the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),</booktitle>
<pages>41--51</pages>
<contexts>
<context position="6841" citStr="Huang and Riloff, 2013" startWordPosition="1037" endWordPosition="1040">acts to texts. Since the training data generated by the heuristic matching is often imperfect, multiinstance learning approaches (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) have been developed to combat this problem. Unfortunately, most facts existing in the KBs are static facts like geographical or biographical data. They fall short of learning extractors for fluent facts such as sports results or travel and meetings by a person. Bootstrapping is another common extraction technique (Brin, 1999; Agichtein and Gravano, 2000; Carlson et al., 2010; Nakashole et al., 2011; Huang and Riloff, 2013). This typically takes a set of seeds as input, which can be ground instances or key phrases. The algorithms then iteratively generate more positive instances and phrases. While there are many successful examples of bootstrapping, the challenge is to avoid semantic drift. Large-scale systems, therefore, often require extra processing such as manual validation between the iterations or additional negative seeds as the input. Unsupervised approaches have been developed for relation discovery and extractions. These algorithms are usually based on some clustering assumptions over a large unlabeled</context>
</contexts>
<marker>Huang, Riloff, 2013</marker>
<rawString>Ruihong Huang and Ellen Riloff. 2013. Multi-faceted event recognition with bootstrapped dictionaries. In the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL), pages 41–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Discovery of inference rules for question-answering.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="8260" citStr="Lin and Pantel, 2001" startWordPosition="1248" endWordPosition="1251"> rank assumption by (Takamatsu et al., 2011; Riedel et al., 2013). Since the assumptions largely rely on co-occurrence, previous unsupervised approaches tend to confuse correlated but semantically different phrases during extraction. In contrast to this, our work largely avoids these errors by exploiting the temporal negation heuristic in parallel news streams. In addition, unlike many unsupervised algorithms requiring human effort to canonicalize the clusters, our work automatically discovers events with readable names. Paraphrasing techniques inspire our work. Some techniques, such as DIRT (Lin and Pantel, 2001) and Resolver (Yates and Etzioni, 2009), are based on the distributional hypothesis. Another common approach is to use parallel corpora, including news streams (Barzilay and Lee, 2003; Dolan et al., 2004; Zhang and Weld, 2013), multiple translations of the same story (Barzilay and McKeown, 2001) and bilingual sentence pairs (Ganitkevitch et al., 2013) to generate the paraphrases. Although these algorithms create many good paraphrases, they can not be directly used to generate enough training data to train a relation extractor for two reasons: first, the semantics of the paraphrases is often co</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Discovery of inference rules for question-answering. Natural Language Engineering, 7(4):343–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Ling</author>
<author>Daniel S Weld</author>
</authors>
<title>Fine-grained entity recognition.</title>
<date>2012</date>
<booktitle>In Association for the Advancement of Artificial Intelligence (AAAI).</booktitle>
<contexts>
<context position="10545" citStr="Ling and Weld, 2012" startWordPosition="1601" endWordPosition="1604"> as shown in Figure 1. NEWSSPIKE-RE has both training and test phases. Its training phase has two main steps: event-relation discovery and training-set generation. Section 4 describes our event relation discovery algorithm, which processes time-stamped news articles to discern a set of salient, distinct event relations in the form of E = e(t1, t2), where e is a representative event phrase and ti are types of the two arguments. NEWSSPIKE-RE generates the event phrases using an Open Information Extraction (IE) system (Fader et al., 2011), and uses a fine-grained entity recognition system FIGER (Ling and Weld, 2012) to generate type descriptors such as “company ”, “politician”, and “medical treatment”. The second part of NEWSSPIKE-RE’s training phase, described in Section 5, is a method for building extractors for the discovered event relations. Our approach is motivated by the intuition, adapted from Zhang and Weld (2013), that articles from different news sources typically use different sentences to describe the same event, and that corresponding sentences can be identified when they mention a unique pair of real-world entities. For example, when an unusual entity pair (Selena, Norway) is suddenly seen</context>
<context position="29986" citStr="Ling and Weld, 2012" startWordPosition="4972" endWordPosition="4975">ead of individually labeled sentences). Coping with the noise inherent in these multi-instance bags remains a big challenge for distant supervision. In contrast, our sentencelevel training data is more direct and minimizes noise. Therefore, we implement the event extractor as a simple multi-class, L2-regularized logistic regression classifier. For features of the classifier, we use the lexicalized dependency paths, the OpenIE phrases, the minimal subtree of the dependency parse and the bag-of-words between the arguments. We also augment them with fine grained argument types produced by FIGER (Ling and Weld, 2012). The event extractor that is learned can take individual test sentences (s, a1, a2) as input and predict whether that sentence expresses the event between (a1, a2). 7 Empirical Evaluation Our evaluation addresses two questions. Section 7.2 considers whether our training generation algorithm identifies accurate and diverse sentences. Then, Section 7.3 investigates whether the event extractor, learned from the training sentences, outperforms other extraction approaches. 7.1 Experimental Setup We follow the procedure described in (Zhang and Weld, 2013) to collect parallel news streams and genera</context>
</contexts>
<marker>Ling, Weld, 2012</marker>
<rawString>Xiao Ling and Daniel S Weld. 2012. Fine-grained entity recognition. In Association for the Advancement of Artificial Intelligence (AAAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McClosky</author>
<author>Mihai Surdeanu</author>
<author>Christopher D Manning</author>
</authors>
<title>Event extraction as dependency parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (HLT-ACL),</booktitle>
<pages>1626--1635</pages>
<contexts>
<context position="5493" citStr="McClosky et al., 2011" startWordPosition="825" endWordPosition="828"> from the generated training data, significantly outperform several competitive baselines, e.g. our system more than doubles the area under the micro-averaged, PR curve (0.80 vs. 0.30) compared to Riedel’s Universal Schema (Riedel et al., 2013). 2 Previous Work Supervised learning approaches have been widely developed for event extraction tasks such as MUC-4 and ACE. They often focus on a hand-crafted ontology and train the extractor with manually created training data. While they can offer high precision and recall, they are often domain-specific (e.g. biological events (Riedel et al., 2011; McClosky et al., 2011) and entertainment events (Benson et al., 2011; Reichart and Barzilay, 2012)), and are hard to scale over the events on the Web. Open IE systems extract open domain relations (e.g. (Banko et al., 2007; Fader et al., 2011)) and events (e.g. (Ritter et al., 2012)). They often perform self-supervised learning of relation-independent extractions. It allows them to scale but makes them unable to output canonicalized relations. Distant supervised approaches have been developed to learn extractors by exploiting the facts existing in a knowledge base, thus avoiding human annotation. Wu et al. (2007) a</context>
</contexts>
<marker>McClosky, Surdeanu, Manning, 2011</marker>
<rawString>David McClosky, Mihai Surdeanu, and Christopher D Manning. 2011. Event extraction as dependency parsing. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (HLT-ACL), pages 1626– 1635.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>1003--1011</pages>
<contexts>
<context position="6185" citStr="Mintz et al. (2009)" startWordPosition="936" endWordPosition="939">12)), and are hard to scale over the events on the Web. Open IE systems extract open domain relations (e.g. (Banko et al., 2007; Fader et al., 2011)) and events (e.g. (Ritter et al., 2012)). They often perform self-supervised learning of relation-independent extractions. It allows them to scale but makes them unable to output canonicalized relations. Distant supervised approaches have been developed to learn extractors by exploiting the facts existing in a knowledge base, thus avoiding human annotation. Wu et al. (2007) and Reschke et al. (2014) learned Infobox relations from Wikipedia, while Mintz et al. (2009) heuristically matched Freebase facts to texts. Since the training data generated by the heuristic matching is often imperfect, multiinstance learning approaches (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) have been developed to combat this problem. Unfortunately, most facts existing in the KBs are static facts like geographical or biographical data. They fall short of learning extractors for fluent facts such as sports results or travel and meetings by a person. Bootstrapping is another common extraction technique (Brin, 1999; Agichtein and Gravano, 2000; Carlson et al</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Daniel Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics (ACL), pages 1003–1011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ndapandula Nakashole</author>
<author>Martin Theobald</author>
<author>Gerhard Weikum</author>
</authors>
<title>Scalable knowledge harvesting with high precision and high recall.</title>
<date>2011</date>
<booktitle>In Proceedings of the fourth ACM international conference on Web search and data mining (WSDM),</booktitle>
<pages>227--236</pages>
<contexts>
<context position="6816" citStr="Nakashole et al., 2011" startWordPosition="1033" endWordPosition="1036">cally matched Freebase facts to texts. Since the training data generated by the heuristic matching is often imperfect, multiinstance learning approaches (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) have been developed to combat this problem. Unfortunately, most facts existing in the KBs are static facts like geographical or biographical data. They fall short of learning extractors for fluent facts such as sports results or travel and meetings by a person. Bootstrapping is another common extraction technique (Brin, 1999; Agichtein and Gravano, 2000; Carlson et al., 2010; Nakashole et al., 2011; Huang and Riloff, 2013). This typically takes a set of seeds as input, which can be ground instances or key phrases. The algorithms then iteratively generate more positive instances and phrases. While there are many successful examples of bootstrapping, the challenge is to avoid semantic drift. Large-scale systems, therefore, often require extra processing such as manual validation between the iterations or additional negative seeds as the input. Unsupervised approaches have been developed for relation discovery and extractions. These algorithms are usually based on some clustering assumptio</context>
</contexts>
<marker>Nakashole, Theobald, Weikum, 2011</marker>
<rawString>Ndapandula Nakashole, Martin Theobald, and Gerhard Weikum. 2011. Scalable knowledge harvesting with high precision and high recall. In Proceedings of the fourth ACM international conference on Web search and data mining (WSDM), pages 227–236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George L Nemhauser</author>
<author>Laurence A Wolsey</author>
</authors>
<title>Integer and combinatorial optimization, volume 18.</title>
<date>1988</date>
<publisher>Wiley</publisher>
<location>New York.</location>
<contexts>
<context position="16716" citStr="Nemhauser and Wolsey, 1988" startWordPosition="2645" endWordPosition="2648"> K nodes of Ei are chosen and all edges incident to them are chosen as the covered edges; (2) each node of ηj is incident to at most one edge. The first constraint guarantees that there are exactly K event relations discovered; the second constraint ensures that no NewsSpike participates in two event relations. Figure 2 shows the optimized solution of a simple graph with K = 2, which can cover 3 edges with 2 event relations that have no overlapping NewsSpikes. Since both the objective function and constraints are linear, we can optimize this edge-cover problem with integer linear programming (Nemhauser and Wolsey, 1988). By solving the optimization problem, NEWSSPIKE-RE finds a salient set of event relations incident to the covered edges. The discovered relations with K set to 30 are shown in Table 2 in Section 7. In addition, the covered edges bring us the initial mapping between the event types and NewsSpikes, which is used to train the probablistic model in Section 5.3. 5 Generating the Training Sentences After NEWSSPIKE-RE has discovered a set of event relations, it then generates training instances to learn an extractor for each relation. In this section, we present our algorithm for generating the trai</context>
</contexts>
<marker>Nemhauser, Wolsey, 1988</marker>
<rawString>George L Nemhauser and Laurence A Wolsey. 1988. Integer and combinatorial optimization, volume 18. Wiley New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roi Reichart</author>
<author>Regina Barzilay</author>
</authors>
<title>Multi event extraction guided by global constraints.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL),</booktitle>
<pages>70--79</pages>
<contexts>
<context position="5569" citStr="Reichart and Barzilay, 2012" startWordPosition="836" endWordPosition="839">mpetitive baselines, e.g. our system more than doubles the area under the micro-averaged, PR curve (0.80 vs. 0.30) compared to Riedel’s Universal Schema (Riedel et al., 2013). 2 Previous Work Supervised learning approaches have been widely developed for event extraction tasks such as MUC-4 and ACE. They often focus on a hand-crafted ontology and train the extractor with manually created training data. While they can offer high precision and recall, they are often domain-specific (e.g. biological events (Riedel et al., 2011; McClosky et al., 2011) and entertainment events (Benson et al., 2011; Reichart and Barzilay, 2012)), and are hard to scale over the events on the Web. Open IE systems extract open domain relations (e.g. (Banko et al., 2007; Fader et al., 2011)) and events (e.g. (Ritter et al., 2012)). They often perform self-supervised learning of relation-independent extractions. It allows them to scale but makes them unable to output canonicalized relations. Distant supervised approaches have been developed to learn extractors by exploiting the facts existing in a knowledge base, thus avoiding human annotation. Wu et al. (2007) and Reschke et al. (2014) learned Infobox relations from Wikipedia, while Min</context>
</contexts>
<marker>Reichart, Barzilay, 2012</marker>
<rawString>Roi Reichart and Regina Barzilay. 2012. Multi event extraction guided by global constraints. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (HLT-NAACL), pages 70–79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Reschke</author>
<author>Martin Jankowiak</author>
<author>Mihai Surdeanu</author>
<author>Christopher D Manning</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Event extraction using distant supervision.</title>
<date>2014</date>
<booktitle>In Language Resources and Evaluation Conference (LREC).</booktitle>
<contexts>
<context position="6117" citStr="Reschke et al. (2014)" startWordPosition="926" endWordPosition="929">d entertainment events (Benson et al., 2011; Reichart and Barzilay, 2012)), and are hard to scale over the events on the Web. Open IE systems extract open domain relations (e.g. (Banko et al., 2007; Fader et al., 2011)) and events (e.g. (Ritter et al., 2012)). They often perform self-supervised learning of relation-independent extractions. It allows them to scale but makes them unable to output canonicalized relations. Distant supervised approaches have been developed to learn extractors by exploiting the facts existing in a knowledge base, thus avoiding human annotation. Wu et al. (2007) and Reschke et al. (2014) learned Infobox relations from Wikipedia, while Mintz et al. (2009) heuristically matched Freebase facts to texts. Since the training data generated by the heuristic matching is often imperfect, multiinstance learning approaches (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) have been developed to combat this problem. Unfortunately, most facts existing in the KBs are static facts like geographical or biographical data. They fall short of learning extractors for fluent facts such as sports results or travel and meetings by a person. Bootstrapping is another common extracti</context>
</contexts>
<marker>Reschke, Jankowiak, Surdeanu, Manning, Jurafsky, 2014</marker>
<rawString>Kevin Reschke, Martin Jankowiak, Mihai Surdeanu, Christopher D Manning, and Daniel Jurafsky. 2014. Event extraction using distant supervision. In Language Resources and Evaluation Conference (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Andrew McCallum</author>
</authors>
<title>Modeling relations and their mentions without labeled text.</title>
<date>2010</date>
<booktitle>In Machine Learning and Knowledge Discovery in Databases (ECML),</booktitle>
<pages>148--163</pages>
<contexts>
<context position="6367" citStr="Riedel et al., 2010" startWordPosition="962" endWordPosition="965"> 2012)). They often perform self-supervised learning of relation-independent extractions. It allows them to scale but makes them unable to output canonicalized relations. Distant supervised approaches have been developed to learn extractors by exploiting the facts existing in a knowledge base, thus avoiding human annotation. Wu et al. (2007) and Reschke et al. (2014) learned Infobox relations from Wikipedia, while Mintz et al. (2009) heuristically matched Freebase facts to texts. Since the training data generated by the heuristic matching is often imperfect, multiinstance learning approaches (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) have been developed to combat this problem. Unfortunately, most facts existing in the KBs are static facts like geographical or biographical data. They fall short of learning extractors for fluent facts such as sports results or travel and meetings by a person. Bootstrapping is another common extraction technique (Brin, 1999; Agichtein and Gravano, 2000; Carlson et al., 2010; Nakashole et al., 2011; Huang and Riloff, 2013). This typically takes a set of seeds as input, which can be ground instances or key phrases. The algorithms then iteratively </context>
<context position="14378" citStr="Riedel et al., 2010" startWordPosition="2235" endWordPosition="2238">here Ei are event relations and ηj are NewsSpikes. The optimal solution selects E1 with edges to η1 and η2, and E3 with edge to η3. These two event relations cover all the NewsSpikes. gorithm that requires no manual labelling of the training instances. Like distant supervision, the key is to automatically generate the training data, at which point a traditional supervised classifier may be applied to learn an extractor. Because distant supervision creates very noisy annotations, researchers often use specialized learners that model the correctness of a training example with a latent variable (Riedel et al., 2010; Hoffmann et al., 2011), but we found this unnecessary, because NEWSSPIKE-RE creates high quality training data. 4 Discovering Salient Events The first step of NEWSSPIKE-RE is to discover a set of event relations in the form of E = e(t1, t2), where e is an event phrase, and ti are fine-grained argument types generated by FIGER, augmented with the important types “number” and “money”, which are recognized by the Stanford name entity recognition system (Finkel et al., 2005). To be most useful, the discovered event relations should cover salient events that are frequently reported in the news ar</context>
</contexts>
<marker>Riedel, Yao, McCallum, 2010</marker>
<rawString>Sebastian Riedel, Limin Yao, and Andrew McCallum. 2010. Modeling relations and their mentions without labeled text. In Machine Learning and Knowledge Discovery in Databases (ECML), pages 148–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>David McClosky</author>
<author>Mihai Surdeanu</author>
<author>Andrew McCallum</author>
<author>Christopher D Manning</author>
</authors>
<title>Model combination for event extraction in BioNLP</title>
<date>2011</date>
<booktitle>In Proceedings of the BioNLP Shared Task 2011 Workshop,</booktitle>
<pages>51--55</pages>
<contexts>
<context position="5469" citStr="Riedel et al., 2011" startWordPosition="821" endWordPosition="824">t extractors, learned from the generated training data, significantly outperform several competitive baselines, e.g. our system more than doubles the area under the micro-averaged, PR curve (0.80 vs. 0.30) compared to Riedel’s Universal Schema (Riedel et al., 2013). 2 Previous Work Supervised learning approaches have been widely developed for event extraction tasks such as MUC-4 and ACE. They often focus on a hand-crafted ontology and train the extractor with manually created training data. While they can offer high precision and recall, they are often domain-specific (e.g. biological events (Riedel et al., 2011; McClosky et al., 2011) and entertainment events (Benson et al., 2011; Reichart and Barzilay, 2012)), and are hard to scale over the events on the Web. Open IE systems extract open domain relations (e.g. (Banko et al., 2007; Fader et al., 2011)) and events (e.g. (Ritter et al., 2012)). They often perform self-supervised learning of relation-independent extractions. It allows them to scale but makes them unable to output canonicalized relations. Distant supervised approaches have been developed to learn extractors by exploiting the facts existing in a knowledge base, thus avoiding human annota</context>
</contexts>
<marker>Riedel, McClosky, Surdeanu, McCallum, Manning, 2011</marker>
<rawString>Sebastian Riedel, David McClosky, Mihai Surdeanu, Andrew McCallum, and Christopher D Manning. 2011. Model combination for event extraction in BioNLP 2011. In Proceedings of the BioNLP Shared Task 2011 Workshop, pages 51–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Benjamin M Marlin</author>
<author>Andrew McCallum</author>
</authors>
<title>Relation extraction with matrix factorization and universal schemas.</title>
<date>2013</date>
<booktitle>In Joint Human Language Technology Conference/Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL).</booktitle>
<contexts>
<context position="5115" citStr="Riedel et al., 2013" startWordPosition="765" endWordPosition="768">long to the same event relations. In particular, we propose the temporal negation heuristic to avoid conflating co-occurring but nonsynonymous phrases. • We introduce a probabilistic graphical model to generate training for a sentential event extractor without requiring any human annotations. • We present detailed experiments demonstrating that the event extractors, learned from the generated training data, significantly outperform several competitive baselines, e.g. our system more than doubles the area under the micro-averaged, PR curve (0.80 vs. 0.30) compared to Riedel’s Universal Schema (Riedel et al., 2013). 2 Previous Work Supervised learning approaches have been widely developed for event extraction tasks such as MUC-4 and ACE. They often focus on a hand-crafted ontology and train the extractor with manually created training data. While they can offer high precision and recall, they are often domain-specific (e.g. biological events (Riedel et al., 2011; McClosky et al., 2011) and entertainment events (Benson et al., 2011; Reichart and Barzilay, 2012)), and are hard to scale over the events on the Web. Open IE systems extract open domain relations (e.g. (Banko et al., 2007; Fader et al., 2011))</context>
<context position="7704" citStr="Riedel et al., 2013" startWordPosition="1172" endWordPosition="1175">e is to avoid semantic drift. Large-scale systems, therefore, often require extra processing such as manual validation between the iterations or additional negative seeds as the input. Unsupervised approaches have been developed for relation discovery and extractions. These algorithms are usually based on some clustering assumptions over a large unlabeled corpus. Common assumptions include the distributional hypothesis used by (Hasegawa et al., 2004; Shinyama and Sekine, 2006), latent topic assumption by (Yao et al., 2012; Yao et al., 2011), and low rank assumption by (Takamatsu et al., 2011; Riedel et al., 2013). Since the assumptions largely rely on co-occurrence, previous unsupervised approaches tend to confuse correlated but semantically different phrases during extraction. In contrast to this, our work largely avoids these errors by exploiting the temporal negation heuristic in parallel news streams. In addition, unlike many unsupervised algorithms requiring human effort to canonicalize the clusters, our work automatically discovers events with readable names. Paraphrasing techniques inspire our work. Some techniques, such as DIRT (Lin and Pantel, 2001) and Resolver (Yates and Etzioni, 2009), are</context>
<context position="41336" citStr="Riedel et al., 2013" startWordPosition="6800" endWordPosition="6803">ired t-test over the accuracy numbers of each other system compared to 125 NEWSSPIKE-RE. For all but w/o cross the improvement is strongly significant with p-value less than 1%. The increase in accuracy compared to w/o cross has borderline significance (p-value 5.5%), but is a clear win with its 22% increase in training size. 7.3 Performance of the Event Extractors Most previous relation extraction approaches either require a manually labeled training set, or work only on a pre-defined set of relations that have ground instances from KBs. The closest work to NEWSSPIKE-RE is Universal Schemas (Riedel et al., 2013), which addresses the limitation of distant supervision that the relations must exist in KBs. Their solution is to treat the surface strings, dependency paths, and relations from KBs as equal “schemas”, and then to exploit the correlation between the instances and the schemas from a very large unlabeled corpus. In their paper, Riedel et al. evaluated only on static relations from Freebase and achieve state-of-the-art performance. But Universal Schemas can be adapted to handle events, by introducing the events as schemas and heuristically finding seed instances. We set up a competing system (R1</context>
<context position="43155" citStr="Riedel et al., 2013" startWordPosition="7111" endWordPosition="7114">(t1, t2), we assume the event relation E is observed on that instance. As shown in Table 1, parallel news streams are a promising resource for clustering because of the strong correlation between the instances and the event phrases. We train another version of Universal Schemas R13P on the parallel news streams NS13. In particular, entity pairs from different NewsSpikes are used as different rows in the matrix. We would like to measure the precision and recall of the extractors. But note that it is impossible to fully label all the sentences, so we follow the “pooling” technique described in (Riedel et al., 2013) to create the labeled dataset. For every competing system, we sample 100 top outputs for every event relation and add this to the pool. The annotators are shown these sentences and asked to judge whether the sentence expresses the event relation or not. After that, the labeled set become “gold” and can be used to measure the precision and pseudorecall. There are in all 6,178 distinct sentences in the pool, since some outputs are produced by multiple systems. Among them, 2,903 sentences are labeled as positive. In Table 2, the # columns show the number of true extractions in the pool for every</context>
</contexts>
<marker>Riedel, Yao, Marlin, McCallum, 2013</marker>
<rawString>Sebastian Riedel, Limin Yao, Benjamin M. Marlin, and Andrew McCallum. 2013. Relation extraction with matrix factorization and universal schemas. In Joint Human Language Technology Conference/Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Oren Etzioni</author>
<author>Sam Clark</author>
</authors>
<title>Open domain event extraction from twitter.</title>
<date>2012</date>
<booktitle>In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD),</booktitle>
<pages>1104--1112</pages>
<contexts>
<context position="5754" citStr="Ritter et al., 2012" startWordPosition="870" endWordPosition="873">upervised learning approaches have been widely developed for event extraction tasks such as MUC-4 and ACE. They often focus on a hand-crafted ontology and train the extractor with manually created training data. While they can offer high precision and recall, they are often domain-specific (e.g. biological events (Riedel et al., 2011; McClosky et al., 2011) and entertainment events (Benson et al., 2011; Reichart and Barzilay, 2012)), and are hard to scale over the events on the Web. Open IE systems extract open domain relations (e.g. (Banko et al., 2007; Fader et al., 2011)) and events (e.g. (Ritter et al., 2012)). They often perform self-supervised learning of relation-independent extractions. It allows them to scale but makes them unable to output canonicalized relations. Distant supervised approaches have been developed to learn extractors by exploiting the facts existing in a knowledge base, thus avoiding human annotation. Wu et al. (2007) and Reschke et al. (2014) learned Infobox relations from Wikipedia, while Mintz et al. (2009) heuristically matched Freebase facts to texts. Since the training data generated by the heuristic matching is often imperfect, multiinstance learning approaches (Riedel</context>
</contexts>
<marker>Ritter, Etzioni, Clark, 2012</marker>
<rawString>Alan Ritter, Oren Etzioni, Sam Clark, et al. 2012. Open domain event extraction from twitter. In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining (KDD), pages 1104–1112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evan Sandhaus</author>
</authors>
<title>The New York Times annotated corpus. Linguistic Data Consortium.</title>
<date>2008</date>
<contexts>
<context position="42030" citStr="Sandhaus, 2008" startWordPosition="6915" endWordPosition="6916"> exist in KBs. Their solution is to treat the surface strings, dependency paths, and relations from KBs as equal “schemas”, and then to exploit the correlation between the instances and the schemas from a very large unlabeled corpus. In their paper, Riedel et al. evaluated only on static relations from Freebase and achieve state-of-the-art performance. But Universal Schemas can be adapted to handle events, by introducing the events as schemas and heuristically finding seed instances. We set up a competing system (R13) as follows: (1) We take the NYTimes corpus published between 1987 and 2007 (Sandhaus, 2008), the dataset used by Riedel et al. (2013) containing 1.8 million NY Times articles; (2) The instances (i.e. the rows of the matrix) come from the entity pairs from the news articles; (3) There are two types of columns: some are the extraction features used by NEWSSPIKE-RE, including the lexicalized dependency paths described in Riedel et al.; others are event relations E = e(t1, t2); (4) For an entity pair (a1, a2), if there is an OpenIE extraction (a1, e, a2) and the entity types of (a1, a2) match (t1, t2), we assume the event relation E is observed on that instance. As shown in Table 1, par</context>
</contexts>
<marker>Sandhaus, 2008</marker>
<rawString>Evan Sandhaus. 2008. The New York Times annotated corpus. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Shinyama</author>
<author>Satoshi Sekine</author>
</authors>
<title>Preemptive information extraction using unrestricted relation discovery.</title>
<date>2006</date>
<booktitle>In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics (HLT-NAACL),</booktitle>
<pages>304--311</pages>
<contexts>
<context position="7565" citStr="Shinyama and Sekine, 2006" startWordPosition="1146" endWordPosition="1149">algorithms then iteratively generate more positive instances and phrases. While there are many successful examples of bootstrapping, the challenge is to avoid semantic drift. Large-scale systems, therefore, often require extra processing such as manual validation between the iterations or additional negative seeds as the input. Unsupervised approaches have been developed for relation discovery and extractions. These algorithms are usually based on some clustering assumptions over a large unlabeled corpus. Common assumptions include the distributional hypothesis used by (Hasegawa et al., 2004; Shinyama and Sekine, 2006), latent topic assumption by (Yao et al., 2012; Yao et al., 2011), and low rank assumption by (Takamatsu et al., 2011; Riedel et al., 2013). Since the assumptions largely rely on co-occurrence, previous unsupervised approaches tend to confuse correlated but semantically different phrases during extraction. In contrast to this, our work largely avoids these errors by exploiting the temporal negation heuristic in parallel news streams. In addition, unlike many unsupervised algorithms requiring human effort to canonicalize the clusters, our work automatically discovers events with readable names.</context>
</contexts>
<marker>Shinyama, Sekine, 2006</marker>
<rawString>Yusuke Shinyama and Satoshi Sekine. 2006. Preemptive information extraction using unrestricted relation discovery. In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics (HLT-NAACL), pages 304–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Julie Tibshirani</author>
<author>Ramesh Nallapati</author>
<author>Christopher D Manning</author>
</authors>
<title>Multi-instance multilabel learning for relation extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP),</booktitle>
<pages>455--465</pages>
<contexts>
<context position="6414" citStr="Surdeanu et al., 2012" startWordPosition="970" endWordPosition="973">learning of relation-independent extractions. It allows them to scale but makes them unable to output canonicalized relations. Distant supervised approaches have been developed to learn extractors by exploiting the facts existing in a knowledge base, thus avoiding human annotation. Wu et al. (2007) and Reschke et al. (2014) learned Infobox relations from Wikipedia, while Mintz et al. (2009) heuristically matched Freebase facts to texts. Since the training data generated by the heuristic matching is often imperfect, multiinstance learning approaches (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) have been developed to combat this problem. Unfortunately, most facts existing in the KBs are static facts like geographical or biographical data. They fall short of learning extractors for fluent facts such as sports results or travel and meetings by a person. Bootstrapping is another common extraction technique (Brin, 1999; Agichtein and Gravano, 2000; Carlson et al., 2010; Nakashole et al., 2011; Huang and Riloff, 2013). This typically takes a set of seeds as input, which can be ground instances or key phrases. The algorithms then iteratively generate more positive instances and phrases. W</context>
<context position="29247" citStr="Surdeanu et al., 2012" startWordPosition="4860" endWordPosition="4863"> .With {(Y label i , Zlabel i ) |M i=1}, learning can be done with maximum likelihood estimation as L(O) = log Hi p(Yi = ylabel i ,Zi = zlabel i | xi, O). Following (Collins, 2002), we use a fast perceptron learning approach to update O. It consists of iterating two steps: (1) MAP inference given the current weight; (2) penalizing the weights if the inferred assignments are different from the heuristic labeled assignments. 6 Sentential Event Extraction As shown in Figure 1, we learn the extractors from the generated training sentences. Note that most distant supervised (Hoffmann et al., 2011; Surdeanu et al., 2012) approaches use multi-instance, aggregatelevel training (i.e. the supervision comes from labeled sets of instances instead of individually labeled sentences). Coping with the noise inherent in these multi-instance bags remains a big challenge for distant supervision. In contrast, our sentencelevel training data is more direct and minimizes noise. Therefore, we implement the event extractor as a simple multi-class, L2-regularized logistic regression classifier. For features of the classifier, we use the lexicalized dependency paths, the OpenIE phrases, the minimal subtree of the dependency pars</context>
<context position="46349" citStr="Surdeanu et al. (2012)" startWordPosition="7656" endWordPosition="7659">0 Figure 5: Precision pseudo-recall curves for (a) all event relations; (b) buy(org, org), this figure includes the distant supervision algorithm MIML learned from matching the Freebase relation5 to The New York Times. NEWSSPIKE-RE has AUC 0.80, more than doubling R13 (0.30) and 35% higher than R13P (0.59) for all event relations. join and select (Zhang et al., 2012). To evaluate how distant supervision performs, we introduce the system DS on NYT based on a manual mapping of buy(org,org) to the join relation4 in Freebase. Then we match its instances to NYTimes articles and follow the steps of Surdeanu et al. (2012) to train the extractor. The matching to NYTimes brings us 264 positive instances having 5,333 sentences, but unfortunately the sentence-level accuracy is only 13% based on examination of 100 random sentences. Figure 5(b) shows the PR curves for all the competing systems. Distant supervision predicts the top extractions correctly because the multi-instance technique recognizes some common expressions (e.g. buy, acquire), but the precision drops dramatically since most positive expressions are overwhelmed by the noise. 8 Conclusions and Future Work Popular distant supervised approaches have lim</context>
</contexts>
<marker>Surdeanu, Tibshirani, Nallapati, Manning, 2012</marker>
<rawString>Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and Christopher D Manning. 2012. Multi-instance multilabel learning for relation extraction. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP), pages 455– 465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shingo Takamatsu</author>
<author>Issei Sato</author>
<author>Hiroshi Nakagawa</author>
</authors>
<title>Probabilistic matrix factorization leveraging contexts for unsupervised relation extraction.</title>
<date>2011</date>
<booktitle>In Advances in Knowledge Discovery and Data Mining,</booktitle>
<pages>87--99</pages>
<contexts>
<context position="7682" citStr="Takamatsu et al., 2011" startWordPosition="1167" endWordPosition="1171">tstrapping, the challenge is to avoid semantic drift. Large-scale systems, therefore, often require extra processing such as manual validation between the iterations or additional negative seeds as the input. Unsupervised approaches have been developed for relation discovery and extractions. These algorithms are usually based on some clustering assumptions over a large unlabeled corpus. Common assumptions include the distributional hypothesis used by (Hasegawa et al., 2004; Shinyama and Sekine, 2006), latent topic assumption by (Yao et al., 2012; Yao et al., 2011), and low rank assumption by (Takamatsu et al., 2011; Riedel et al., 2013). Since the assumptions largely rely on co-occurrence, previous unsupervised approaches tend to confuse correlated but semantically different phrases during extraction. In contrast to this, our work largely avoids these errors by exploiting the temporal negation heuristic in parallel news streams. In addition, unlike many unsupervised algorithms requiring human effort to canonicalize the clusters, our work automatically discovers events with readable names. Paraphrasing techniques inspire our work. Some techniques, such as DIRT (Lin and Pantel, 2001) and Resolver (Yates a</context>
</contexts>
<marker>Takamatsu, Sato, Nakagawa, 2011</marker>
<rawString>Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa. 2011. Probabilistic matrix factorization leveraging contexts for unsupervised relation extraction. In Advances in Knowledge Discovery and Data Mining, pages 87–99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Daniel S Weld</author>
</authors>
<title>Autonomously semantifying wikipedia.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Conference on Information and Knowledge Management (CIKM),</booktitle>
<pages>41--50</pages>
<contexts>
<context position="1886" citStr="Wu and Weld, 2007" startWordPosition="275" endWordPosition="278">learns extractors that perform much better than rival approaches, more than doubling the area under a precision-recall curve compared to Universal Schemas. 1 Introduction Relation extraction, the process of extracting structured information from natural language text, grows increasingly important for Web search and question answering. Traditional supervised approaches, which can achieve high precision and recall, are limited by the cost of labeling training data and are unlikely to scale to the thousands of relations on the Web. Another approach, distant supervision (Craven and Kumlien, 1999; Wu and Weld, 2007), creates its own training data by matching the ground instances of a Knowledge base (KB) (e.g. Freebase) to the unlabeled text. Unfortunately, while distant supervision can work well in some situations, the method is limited to relatively static facts (e.g., born-in(person, location) or capital-of(location,location)) where there is a corresponding knowledge base. But what about dynamic event relations (also known as fluents), such as travel-to(person, location) or fire(organization, person)? Since these time-dependent facts are ephemeral, they are rarely stored in a pre-existing KB. At the sa</context>
</contexts>
<marker>Wu, Weld, 2007</marker>
<rawString>Fei Wu and Daniel S. Weld. 2007. Autonomously semantifying wikipedia. In Proceedings of the International Conference on Information and Knowledge Management (CIKM), pages 41–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Limin Yao</author>
<author>Aria Haghighi</author>
<author>Sebastian Riedel</author>
<author>Andrew McCallum</author>
</authors>
<title>Structured relation discovery using generative models.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1456--1466</pages>
<contexts>
<context position="7630" citStr="Yao et al., 2011" startWordPosition="1158" endWordPosition="1161">While there are many successful examples of bootstrapping, the challenge is to avoid semantic drift. Large-scale systems, therefore, often require extra processing such as manual validation between the iterations or additional negative seeds as the input. Unsupervised approaches have been developed for relation discovery and extractions. These algorithms are usually based on some clustering assumptions over a large unlabeled corpus. Common assumptions include the distributional hypothesis used by (Hasegawa et al., 2004; Shinyama and Sekine, 2006), latent topic assumption by (Yao et al., 2012; Yao et al., 2011), and low rank assumption by (Takamatsu et al., 2011; Riedel et al., 2013). Since the assumptions largely rely on co-occurrence, previous unsupervised approaches tend to confuse correlated but semantically different phrases during extraction. In contrast to this, our work largely avoids these errors by exploiting the temporal negation heuristic in parallel news streams. In addition, unlike many unsupervised algorithms requiring human effort to canonicalize the clusters, our work automatically discovers events with readable names. Paraphrasing techniques inspire our work. Some techniques, such </context>
</contexts>
<marker>Yao, Haghighi, Riedel, McCallum, 2011</marker>
<rawString>Limin Yao, Aria Haghighi, Sebastian Riedel, and Andrew McCallum. 2011. Structured relation discovery using generative models. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1456–1466.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Limin Yao</author>
<author>Sebastian Riedel</author>
<author>Andrew McCallum</author>
</authors>
<title>Unsupervised relation discovery with sense disambiguation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>712--720</pages>
<contexts>
<context position="7611" citStr="Yao et al., 2012" startWordPosition="1154" endWordPosition="1157">nces and phrases. While there are many successful examples of bootstrapping, the challenge is to avoid semantic drift. Large-scale systems, therefore, often require extra processing such as manual validation between the iterations or additional negative seeds as the input. Unsupervised approaches have been developed for relation discovery and extractions. These algorithms are usually based on some clustering assumptions over a large unlabeled corpus. Common assumptions include the distributional hypothesis used by (Hasegawa et al., 2004; Shinyama and Sekine, 2006), latent topic assumption by (Yao et al., 2012; Yao et al., 2011), and low rank assumption by (Takamatsu et al., 2011; Riedel et al., 2013). Since the assumptions largely rely on co-occurrence, previous unsupervised approaches tend to confuse correlated but semantically different phrases during extraction. In contrast to this, our work largely avoids these errors by exploiting the temporal negation heuristic in parallel news streams. In addition, unlike many unsupervised algorithms requiring human effort to canonicalize the clusters, our work automatically discovers events with readable names. Paraphrasing techniques inspire our work. Som</context>
</contexts>
<marker>Yao, Riedel, McCallum, 2012</marker>
<rawString>Limin Yao, Sebastian Riedel, and Andrew McCallum. 2012. Unsupervised relation discovery with sense disambiguation. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL), pages 712–720.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yates</author>
<author>Oren Etzioni</author>
</authors>
<title>Unsupervised methods for determining object and relation synonyms on the web.</title>
<date>2009</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="8299" citStr="Yates and Etzioni, 2009" startWordPosition="1254" endWordPosition="1257">., 2011; Riedel et al., 2013). Since the assumptions largely rely on co-occurrence, previous unsupervised approaches tend to confuse correlated but semantically different phrases during extraction. In contrast to this, our work largely avoids these errors by exploiting the temporal negation heuristic in parallel news streams. In addition, unlike many unsupervised algorithms requiring human effort to canonicalize the clusters, our work automatically discovers events with readable names. Paraphrasing techniques inspire our work. Some techniques, such as DIRT (Lin and Pantel, 2001) and Resolver (Yates and Etzioni, 2009), are based on the distributional hypothesis. Another common approach is to use parallel corpora, including news streams (Barzilay and Lee, 2003; Dolan et al., 2004; Zhang and Weld, 2013), multiple translations of the same story (Barzilay and McKeown, 2001) and bilingual sentence pairs (Ganitkevitch et al., 2013) to generate the paraphrases. Although these algorithms create many good paraphrases, they can not be directly used to generate enough training data to train a relation extractor for two reasons: first, the semantics of the paraphrases is often context dependent; second, the generated </context>
<context position="34306" citStr="Yates and Etzioni, 2009" startWordPosition="5680" endWordPosition="5683">74 .71 1,210 .53 .53 Zhang13 14,804 .76 .75 890 .63 .61 NEWSSPIKE-RE 20,105 .88 .89 2,156 .71 .72 w/o cross 16,463 .86 .86 1,883 .67 .69 w/o neg 33,548 .76 .81 4,019 .64 .68 Table 1: Quality of the generated training sentences (count, micro- and macro- accuracy), where “all” includes sentences with all event phrases and “diverse” are those with distinct event phrases. based on the following paraphrasing techniques. Basic is based on the temporal functionality heuristic of (Zhang and Weld, 2013). It treats all event phrases appearing in the same NewsSpike as paraphrases. Yates09 uses Resolver (Yates and Etzioni, 2009) to create clusters of phrases. Resolver measures the similarity between the phrases by means of both distributional features and textual features. We convert the sentences in NewsSpikes into tuples in the form of (a1,p, a2), and run Resolver on these tuples to generate the paraphrases. Zhang13: We used the generated paraphrase set from (Zhang and Weld, 2013). Ganit13: Ganitkevitch et al. (2013) released a large paraphrase database (PPDB) based on exploiting the bilingual parallel corpora. Note that some of these paraphrasing systems do not handle dependency paths. So when p is a dependency pa</context>
</contexts>
<marker>Yates, Etzioni, 2009</marker>
<rawString>Alexander Yates and Oren Etzioni. 2009. Unsupervised methods for determining object and relation synonyms on the web. Journal ofArtificial Intelligence Research, 34(1):255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Congle Zhang</author>
<author>Daniel S Weld</author>
</authors>
<title>Harvesting parallel news streams to generate paraphrases of event relations.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP),</booktitle>
<pages>455--465</pages>
<contexts>
<context position="3211" citStr="Zhang and Weld, 2013" startWordPosition="476" endWordPosition="479">nd politics. Indeed, news stories report events almost exclusively, so learning to extract events is an important open problem. This paper develops a new unsupervised technique, NEWSSPIKE-RE, to both discover event relations and extract them with high precision. The intuition underlying NEWSSPIKE-RE is that the text of articles from two different news sources are not independent, since they are each conditioned on the same real-world events. By looking for rarely described entities that suddenly “spike” in popularity on a given date, one can identify paraphrases. Such temporal correspondence (Zhang and Weld, 2013) allow one to cluster diverse sentences, and the resulting clusters may be used to form training data in order to learn event extractors. Furthermore, one can also exploit parallel news to obtain direct negative evidence. To see this, suppose one day the news includes the following: (a) “Snowden travels to Hong Kong, off southeastern China.” (b) “Snowden cannot stay in Hong Kong as Chinese officials will not allow ...” Since news stories are usually coherent, it is highly unlikely that travel to and stay in (which is negated) are synonymous. By leveraging such direct negative phrases, we can l</context>
<context position="8486" citStr="Zhang and Weld, 2013" startWordPosition="1283" endWordPosition="1286">action. In contrast to this, our work largely avoids these errors by exploiting the temporal negation heuristic in parallel news streams. In addition, unlike many unsupervised algorithms requiring human effort to canonicalize the clusters, our work automatically discovers events with readable names. Paraphrasing techniques inspire our work. Some techniques, such as DIRT (Lin and Pantel, 2001) and Resolver (Yates and Etzioni, 2009), are based on the distributional hypothesis. Another common approach is to use parallel corpora, including news streams (Barzilay and Lee, 2003; Dolan et al., 2004; Zhang and Weld, 2013), multiple translations of the same story (Barzilay and McKeown, 2001) and bilingual sentence pairs (Ganitkevitch et al., 2013) to generate the paraphrases. Although these algorithms create many good paraphrases, they can not be directly used to generate enough training data to train a relation extractor for two reasons: first, the semantics of the paraphrases is often context dependent; second, the generated paraphrases are often in 118 Training Phase Testing Phase Figure 1: During its training phase, NEWSSPIKE-RE first groups parallel sentences as NewsSpikes. Next, the system automatically d</context>
<context position="10858" citStr="Zhang and Weld (2013)" startWordPosition="1651" endWordPosition="1654">elations in the form of E = e(t1, t2), where e is a representative event phrase and ti are types of the two arguments. NEWSSPIKE-RE generates the event phrases using an Open Information Extraction (IE) system (Fader et al., 2011), and uses a fine-grained entity recognition system FIGER (Ling and Weld, 2012) to generate type descriptors such as “company ”, “politician”, and “medical treatment”. The second part of NEWSSPIKE-RE’s training phase, described in Section 5, is a method for building extractors for the discovered event relations. Our approach is motivated by the intuition, adapted from Zhang and Weld (2013), that articles from different news sources typically use different sentences to describe the same event, and that corresponding sentences can be identified when they mention a unique pair of real-world entities. For example, when an unusual entity pair (Selena, Norway) is suddenly seen in three articles on a single day: Selena traveled to Norway to see her ex-boyfriend. Selena arrived in Norway for a rendezvous with Justin. Selena’s trip to Norway was no coincidence. It is likely that all three refer to the same event relation, travel-to(person, location)1, and can be used as positive trainin</context>
<context position="17984" citStr="Zhang and Weld, 2013" startWordPosition="2855" endWordPosition="2858">ator takes N NewsSpikes {ηi = (a1i, a2i, di, Si)|i = 1... N} and K event relations {Ek = ek(t1k, t2k)|k = 1... K} as input. For every event relation, Ek, the generator identifies a subset of sentences from UNi=1Si expressing the event relation as training sentences. In this section, we first characterize the paraphrased event phrases and the parallel sentences in NewsSpikes. Then we show how to encode this heuristic in a probabilistic graphical model that jointly paraphrases the event phrases and identifies a set of training sentences. 5.1 Exploiting Properties of Parallel News Previous work (Zhang and Weld, 2013) proposed several heuristics that are useful to find similar sentences in a NewsSpike. For example, the temporal functionality heuristic says that sentences in a 120 NewsSpike with the same tense tend to be paraphrases. Unfortunately, these methods are too weak to generate enough data for training high quality event extractors: (1) they are “in-spike heuristics” that tend to generate small clusters from individual NewsSpikes. It remains unclear how to merge similar events occuring on different days and between different entities to increase cluster size. (2) they included heuristics to “gain p</context>
<context position="19778" citStr="Zhang and Weld, 2013" startWordPosition="3149" endWordPosition="3152">parallel sentences tend to be paraphrases. But sometimes the sentences in the NewsSpike are related but not paraphrases. For example, one day “Snowden will stay in Hong Kong ...” appears together with “Snowden travels to Hong Kong ...”. Although the fact stay-in(Snowden, Hong Kong) is true, it is harmful to include “Snowden will stay in Hong Kong” in the training for travel-to(person, location). Detecting paraphrases remains a challenge to most unsupervised approaches because they tend to cluster heavily co-occurring phrases which may turn out to be semantically different or even antonymous. (Zhang and Weld, 2013) presented a method to avoid confusion between antonym and synonyms in NewsSpikes, but did not address the problem of related but different phrases like travel to and stay in in a NewsSpike. To handle this, our method rests on a simple observation: when you read “Snowden travels to Hong Kong” and “Snowden cannot stay in Hong Kong as Chinese officials do not allow ...” in the same NewsSpike, it is unlike that travel to and stay in are synonymous event phrases because otherwise the two news stories are describing the opposite event. This observation leads to: Temporal Negation Heuristic. Two eve</context>
<context position="27290" citStr="Zhang and Weld, 2013" startWordPosition="4480" endWordPosition="4483">event relation E = e(t1, t2), NEWSSPIKE-RE creates heuristic labels as follows: = 1. The union of such sentences over the dif122 Input: NewsSpikes and the connected components of the model; Heuristic Labels: 1. find positive and negative phrases and sentences P+, P−, S+, S−; 2. label the connected componenets accordingly and create {(Y ilabel ,Zlabel i ) |M i=1}. Learning: Update O with the perceptron learning algorithm. Output: the values of all variables in the connected components with the MAP inference. Figure 4: Learning from Heuristic Labels (1) P+: the temporal functionality heuristic (Zhang and Weld, 2013) says that if an event phrase p cooccurs with e in the NewsSpikes, it tends to be a paraphrase of e. We add the most frequently cooccurring event phrases to P+. P+ also includes e itself. (2) P−: the temporal negation heuristic says that if p and e co-occur in the NewsSpike but one of them is in its negated form, p should be negatively labeled. We add those event phrases to P−. If a phrase p appears in both P+ and P−, we remove it from both sets. (3) S+: we first get the positive NewsSpikes from the solution of the edgecover problem in section 4. We treat the NewsSpike η as positive if the edg</context>
<context position="30542" citStr="Zhang and Weld, 2013" startWordPosition="5052" endWordPosition="5055">ne grained argument types produced by FIGER (Ling and Weld, 2012). The event extractor that is learned can take individual test sentences (s, a1, a2) as input and predict whether that sentence expresses the event between (a1, a2). 7 Empirical Evaluation Our evaluation addresses two questions. Section 7.2 considers whether our training generation algorithm identifies accurate and diverse sentences. Then, Section 7.3 investigates whether the event extractor, learned from the training sentences, outperforms other extraction approaches. 7.1 Experimental Setup We follow the procedure described in (Zhang and Weld, 2013) to collect parallel news streams and generate the NewsSpikes: first, we get news seeds and query the Bing newswire search engine to gather additional, time-stamped, news articles on a similar topic; next, we extract OpenIE tuples from the news articles and group the sentences that share the same arguments and date into NewsSpikes. We collected the news stream corpus from March 1st 2013 to July 1st 2014. We split the dataset into two parts: in the training phrase, we use the news streams in 2013 (named NS13) to generate the training sentences. NS13 has 33k NewsSpikes containing 173k sentences.</context>
<context position="33074" citStr="Zhang and Weld, 2013" startWordPosition="5474" endWordPosition="5477"> model that identifies training sentences for each event relation E = e(t1, t2) uses cosine similarity between the event phrase p of a sentence and the canonical phrases of each relation as features in the phrase factors in Figure 3(a). It also includes the cosine similarity between p and a set of “anti-phrases” for the event relation which are recognized by the temporal negation heuristic. For the in-spike factor, we measure whether the fine-grained argument types of the sentence returned from the FIGER system matches the required ti respectively. In addition, we implement the features from (Zhang and Weld, 2013) to measure whether the sentence is describing the event of the NewsSpike. For the cross-spike factors, we use textual similarity features between the two sets of parallel sentences to measure the distance between the pair of NewsSpikes. 7.2 Quality of the Generated Training Set The key to a good learning system is a high-quality training set. In this section, we compare our joint model against pipeline systems that consider paraphrases and argument type matching sequentially, system # all ma. # diverse ma. mi. mi. Basic 43,718 .50 .62 12,701 .38 .51 Yates09 15,212 .78 .76 586 .48 .50 Ganit13 </context>
<context position="34667" citStr="Zhang and Weld, 2013" startWordPosition="5739" endWordPosition="5742">rases. based on the following paraphrasing techniques. Basic is based on the temporal functionality heuristic of (Zhang and Weld, 2013). It treats all event phrases appearing in the same NewsSpike as paraphrases. Yates09 uses Resolver (Yates and Etzioni, 2009) to create clusters of phrases. Resolver measures the similarity between the phrases by means of both distributional features and textual features. We convert the sentences in NewsSpikes into tuples in the form of (a1,p, a2), and run Resolver on these tuples to generate the paraphrases. Zhang13: We used the generated paraphrase set from (Zhang and Weld, 2013). Ganit13: Ganitkevitch et al. (2013) released a large paraphrase database (PPDB) based on exploiting the bilingual parallel corpora. Note that some of these paraphrasing systems do not handle dependency paths. So when p is a dependency path, we use the surface string between the arguments as the phrase. NewsSpike-RE: We also conduct ablation testing on NEWSSPIKE-RE to measure the effect of the cross-spike factors and the temporal negation heuristic: w/o Cross uses a simpler model by removing the cross-spike factors of NEWSSPIKE-RE; w/o Negation uses the same joint cluster model as NEWSSPIKE-R</context>
<context position="11512" citStr="Zhang &amp; Weld (2013)" startWordPosition="1760" endWordPosition="1763"> sources typically use different sentences to describe the same event, and that corresponding sentences can be identified when they mention a unique pair of real-world entities. For example, when an unusual entity pair (Selena, Norway) is suddenly seen in three articles on a single day: Selena traveled to Norway to see her ex-boyfriend. Selena arrived in Norway for a rendezvous with Justin. Selena’s trip to Norway was no coincidence. It is likely that all three refer to the same event relation, travel-to(person, location)1, and can be used as positive training examples for the relation. As in Zhang &amp; Weld (2013), we group parallel sentences sharing the same argument pair and date in a structure called a NewsSpike. However, we include all sentences mentioning the arguments (e.g. Selena’s trip to Norway) in the NewsSpike (not just those yielding OpenIE extractions), and use the lexicalized dependency path between the arguments (e.g. &lt;-[poss]-trip-[prep-to]-&gt;2, as the event phrase. In this way, we can generalize extractors beyond the scope of OpenIE. Formally, a NewsSpike is a tuple, (a1, a2, d, S), where a1 and a2 are arguments (e.g. Selena), d is a date, and S is a set of argumentlabeled sentences {(s</context>
</contexts>
<marker>Zhang, Weld, 2013</marker>
<rawString>Congle Zhang and Daniel S Weld. 2013. Harvesting parallel news streams to generate paraphrases of event relations. In Proceedings of the 2013 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP), pages 455–465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Congle Zhang</author>
<author>Raphael Hoffmann</author>
<author>Daniel S Weld</author>
</authors>
<title>Ontological smoothing for relation extraction with minimal supervision.</title>
<date>2012</date>
<booktitle>In Association for the Advancement of Artificial Intelligence (AAAI).</booktitle>
<contexts>
<context position="46096" citStr="Zhang et al., 2012" startWordPosition="7612" endWordPosition="7615">ecall (b) 1.0 0.8 0.6 NewsSpike-RE on NS13 Precision R13P: Uschema on NS13 R13: Uschema on NYT 0.0 0.2 0.4 0.6 0.8 1.0 0.4 0.2 0.0 NewsSpike-RE on NS13 R13P: Uschema on NS13 R13: Uschema on NYT DS on NYT 0.0 0.2 0.4 0.6 0.8 1.0 1.0 0.8 0.6 0.4 0.2 0.0 Figure 5: Precision pseudo-recall curves for (a) all event relations; (b) buy(org, org), this figure includes the distant supervision algorithm MIML learned from matching the Freebase relation5 to The New York Times. NEWSSPIKE-RE has AUC 0.80, more than doubling R13 (0.30) and 35% higher than R13P (0.59) for all event relations. join and select (Zhang et al., 2012). To evaluate how distant supervision performs, we introduce the system DS on NYT based on a manual mapping of buy(org,org) to the join relation4 in Freebase. Then we match its instances to NYTimes articles and follow the steps of Surdeanu et al. (2012) to train the extractor. The matching to NYTimes brings us 264 positive instances having 5,333 sentences, but unfortunately the sentence-level accuracy is only 13% based on examination of 100 random sentences. Figure 5(b) shows the PR curves for all the competing systems. Distant supervision predicts the top extractions correctly because the mul</context>
</contexts>
<marker>Zhang, Hoffmann, Weld, 2012</marker>
<rawString>Congle Zhang, Raphael Hoffmann, and Daniel S Weld. 2012. Ontological smoothing for relation extraction with minimal supervision. In Association for the Advancement of Artificial Intelligence (AAAI).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>