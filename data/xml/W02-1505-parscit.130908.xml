<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9590795">
Encoding and reusing linguistic information expressed by
Linguistic Properties
</title>
<author confidence="0.845775">
Caroline Hagege
</author>
<affiliation confidence="0.728983">
Xerox Research Centre Europe (XRCE)
</affiliation>
<address confidence="0.571148">
6 Chemin de Maupertuis
38240 Meylan - France
Caroline.Hagege©xrce.xerox.corn
Gabriel G. Bes
GRIL Universite Blaise Pascal
34 Avenue Carnot
63000 Clermont Ferrand - France
</address>
<email confidence="0.715569">
Gabriel.Bes©univ-bpclermont.fr
</email>
<sectionHeader confidence="0.987322" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999650222222222">
This paper presents a way to express linguistic
knowledge independently of any algorithmic machi-
nery and of any particular grammatical formalism.
This is performed through Linguistic Properties,
that will be presented. First, the status of linguistic
knowledge in grammars is discussed, then the Lin-
guistic Properties are presented and two experiments
are mentioned. They illustrate the reusability of the
linguistic information enclosed in these Properties.
</bodyText>
<sectionHeader confidence="0.7276995" genericHeader="categories and subject descriptors">
1 Grammar and reusability of
linguistic knowledge
</sectionHeader>
<bodyText confidence="0.999897607142857">
One of the central points in linguistically-motivated
natural language processing is the notion of gram-
mar. It is commonly accepted that a grammar (see
(TM90)) is intended, among other things, to be both
a precise tool of natural languages&apos; description and
the declarative data source which must be inter-
preted by a computer.
This means that the same metalanguage (the gram-
matical formalism) is used to encode the declarative
linguistic informations and the rules that will feed a
parser.
We consider that this double function of a gram-
mar is a disadvantage from the point of view of the
reusability of linguistic knowledge. Indeed, the same
device (the grammar) contains both linguistic infor-
mation and some information adapted to a specific
goal (parsing (shallow or not), generation, etc.) and
to a specific algorithmic machinery. In order to be
reusable and suitable for different goals, we hold that
linguistic knowledge must be free from any specific
requirements, while being, nevertheless, formally ex-
pressed. Furthermore, it must be modularly organ-
ised within different levels of explicit granularity in
order to offer a taylorisable access. Linguistic Prop-
erties, which we distinguished from Processes - i.e.
effective computational procedures on strings of NL
expressions - are a possible way to fulfill these re-
quirements.
</bodyText>
<sectionHeader confidence="0.992051" genericHeader="method">
2 Linguistic Properties
</sectionHeader>
<bodyText confidence="0.99404429032258">
Linguistic Properties (or simply Properties) were
originally developed in the late 90&apos;s within the 5P
Paradigm. The 5 Ps stand for Protocole, system-
atic observations on sentences, Properties, linguistic
declarative knowledge, Projections, generalizations
on Properties of some natural language, Principles,
cross-linguistic constraints on Projections or Princi-
ples and Processes that are efffective computational
procedures. We present in this section the kernel of
Properties 1.
The following example introduces intuitively Prop-
erties and their potential of modularity.
Given the following French expression in (i), it is
possible to distinguish, in its metalanguage, different
layers or aspects, illustrated by (i-a) to (i-c).
i les trois fleurs
i-a { les-[art, def], trois-[card], fleurs-[n] }
i-b ( les-[art, def]i trois-[card], fleurs-[n]3)N,
i-c &lt; ( les-[art, def]i trois-[card], fleurs-[n]3)N, ,
{&lt;1, 3&gt;, &lt;2, 3&gt;, &lt;3, 3&gt;}&gt;
(i) is a string of expressions; (i-a) is a set, each mem-
ber of which is an expression of (i) associated to a
category (or cat, see below), e.g. [art, def]; (i-b) is a
parenthetised list obtained applying order relations
to (i-a), and indexing it with the identifier Nu (for
Nominal nuclear phrase); (i-c) is obtained associat-
ing (i-b) to a set of pairs &lt; p, q &gt;, where p and q
are positions in (i-b); the pair links the element in
position p to the element in position q2.
We will say that (i-b) is a basic model reduced to
its model string, namely (i-b), that (i-a) is a pack
</bodyText>
<footnote confidence="0.995231">
1For a complete and more formalised version, see (BH01).
The 5P Paradigm was presented as such in (B99) and (BH01 )
though antecedents, cited in (BH01 ), go back to a 89 report
to the ESPRIT 393 ACORD european Project, where the
notion of descriptive metalanguage, today&apos;s Properties, were
explicitely introduced. For published work, see (BHC99),
(HB98). For a different but related approach, see (BB99)
and (Bla00) which remain &amp;quot;grammar oriented&amp;quot;.
2 Another layer, expressing a semantic representation, can
be added, but it is not discussed in this paper.
</footnote>
<bodyText confidence="0.98294114893617">
associated to (i-b), that pairs &lt;p, q &gt; are Arrowing
pairs, that (i-c) is an arrowed model incorporating
the model string (i-b).
We distinguish three basic kinds of Properties : Ex-
istence Properties, Linearity Properties, Arrowing
Properties. Packs as in (i-a) are specified by Exis-
tence Properties; order relations, by Linearity prop-
erties; Arrowing pairs, by Arrowing Properties.
Each identifier - e.g. Nu - has its associated set
of Properties, e.g. Properties-Nn, M-Nn being the
set of all and only the models m-Nu satisfying
Properties-Nn. Properties are expressed on symbols
which are cat&apos;s or identifiers. From hereafter we use
Sm as a metavariable on identifiers, and Sy as a
metavariable on cat&apos;s and Sm&apos;s.
A cat is a set of label/value pairs, or, in reduced no-
tation, a set of values (as in previuos examples). A
maximum categoric (mc) is a cat to which no other
value can be added. The assumed Lexicon is a set
of lexical entries, each one being an expression asso-
ciated to one or more mc&apos;s ; cats subsumes cati , if
cats C cati.
The whole system can be viewed as a modular ax-
iomatic system in which models are the objects sat-
isfying different kinds of Properties3. A basic model,
as in (i-b), with its associated pack, as in (i-a), satis-
fies Existence and Linearity Properties; an arrowed
model, as in (i-c) satisfies also Arrowing Properties.
Furthermore, giving a set of Properties, a model can
satisfy some, but not all of them. Properties can be
expressed independently the ones from the others,
and in any order. The set of features from which
cat&apos;s are build can be more or less extended, and,
consequently, the granularity of cat&apos;s, and of Prop-
erties expresed on them, more or less refined.
The model substitution rule relates the identifiers
, Sinn, each one with its associated M-
Smi. In a m-Smi with a Smk, it substitutes some
m-Smk for Smk. E.g., assuming (nem_ adj,)ADJn as
a French m-ADJn (underliyng, e.g. the string pas
belles), the model substitution rule obtains (2) from
the following (1).
&lt; (art, ADJn2 n3)Ain, {&lt;1, 3&gt;, &lt;2, 3&gt;, &lt;3,
3&gt;}&gt;
&lt; (art, neg2 adj3 n4)Ain, {&lt;1, 4&gt;, &lt;2, 3&gt;, &lt;3,
4&gt;, &lt;4, 4&gt;}&gt;
In an optimal situation, Properties associated to the
</bodyText>
<footnote confidence="0.683871">
3 The system benefits from the concept of factorizing rela-
tions of standard production rules of now traditional gram-
mars. See in particular the LP statements of GPSG disso-
ciated from dominance ID rule, and dependency grammar
((Tes69)), early HPSG in (PA87).The system tries to push
this basic idea to its limits, disolving thus the concept of pro-
duction rules. An analog of what the system of Properties is
expected to express compared to production rules, can be seen
in regular expressions as compared to production grammars
of type 3 in the Chomsky&apos;s hierarchy.
</footnote>
<bodyText confidence="0.999422176470588">
Sm&apos;s of some NL, together with a Lexicon and the
model substitution rule, specific the whole set of
models required to describe the strings of expressions
of the NL. We concentrate in the following in the in-
tuitive presentation of Properties specifying models
obtained without the model substitution rule. Given
the different kinds of Properties, we will intuitively
characterise the conditions that must be fulfilled by
a model in order to satisfy each one them 4.
Subsumption is the basic relation linking models and
Properties. We already defined above subsumption
between cat&apos;s. As a shorthand, we say here that
Sm i subsumes Smi if Sm i = Smi. Furthermore,
given sets Si and Si of Sy symbols, we say that Si
subsumes Si if there is a bijective function between
Si and Si such that each Sym in Si subsumes its
corrresponding Syn in Si.
</bodyText>
<subsectionHeader confidence="0.939349">
2.1 Existence Properties
</subsectionHeader>
<bodyText confidence="0.998198653846154">
Existence Properties associated to some M-Sm spec-
ific the set of packs from which any m-Sm is ob-
tained. We distinguish five kinds: Vocabulary prop-
erty, Unicity property, Nucleus Property, Exigency
Property, Exclusion Property.
The Vocabulary Property, spelled by
says that each symbol in the pack associated to a
m — Sm i is subsumed by some symbol in Vsm, and
each symbol in Vs, subsumes some symbol in the
pack of some m-5m3. E.g. (singleton categories are
spelled with their value) French Vivo {det, poss,
card, noun...} is the vocabulary for Nn (nominal
nuclear) French phrases (roughly, nominal chunks),
assuming mc&apos;s: [det, art, def...], [det, art, id...],
[det, dem...], which are associated in the Lexicon to,
respectively, the expressions {les, la, le..}, {un, une,
des...}, {ce, ces, cette...}.
The Unicity Property, spelled by
Unsm = {Sy&amp;quot; , Syn }
says that there are no two symbols in the pack asso-
ciated to a m — Sm subsumed by one and the same
symbol in Unsm . E.g. French UnArn = {At, card...}
express that there are no two articles, or two demon-
stratives or an article and a demonstrative in a Nn
phrase.
The Nucleus Property, spelled by
</bodyText>
<equation confidence="0.882349">
Nusm = I5Y1,
</equation>
<bodyText confidence="0.96807204">
says that in each m — Sm there is one and only one
position with a nucleus symbol - spelled ° Sy - sub-
sumed by some symbol in Num. E.g. French Nusm
{card, quant, noun...} express that Nu phrases
can have as a Nucleus either a cardinal (e.g. i/ a vu
trois)Nn, or a quantifier (e.g. i/ a vu tous)Nn ),
or a noun (e.g. i/ a vu (les ° fieurs)Nn).
The Exigency Property, spelled by
so _&gt;.sm {si, so}
4 For a more formal and complete presentation, see BH-01.
says (remember that S&apos;s spell sets of Sy) that if in
the pack of a m — Sm there is included a set of
symbols Sk subsumed by S° there must be also some
Sr included in the pack such that Sr is subsumed by
Si?&amp;quot;. E.g. French {[u, ci} —)-Nn {{det}, {card}...},
where [n, c] stands for common nouns, express that
common nouns require a determiner or a cardinal.
The Exclusion Property, spelled by
so osm {si, so}
says that if in the pack of a m— Sm there is included
a set of symbols Sk subsumed by 50, then there is
not included a set Sr such that Sr is subsumed by
. E.g. French {[quant, PlJf&gt; Nn Wart, id]}
express that the quantifier tous cannot coexist with
an indefinite article in a Nu phrase.
</bodyText>
<subsectionHeader confidence="0.990295">
2.2 Linearity Properties
</subsectionHeader>
<bodyText confidence="0.99887375">
Linearity Properties express order relations. A Lin-
earity Property is spelled by
says that if in a m — Sm there is a symbol subsumed
by Sy° and a symbol subsumed by 5yi?1, the for-
mer precedes the latter.
E.g. : in French trt-Nn&apos;s, a quantifier tout(e,-s) pre-
cedes all other cat&apos;s, which is expressed by quart
Nn u, det, poss, card...
</bodyText>
<subsectionHeader confidence="0.99934">
2.3 Arrowing Properties
</subsectionHeader>
<bodyText confidence="0.956538826086957">
The basic role of Arrowing Properties is to specify
the graph - i.e. the set of Arrowing pairs - that is
the backbone from which the semantic representa-
tion is build. An arrowing pair (Ar) is a pair
where p and q are positions in the model string, and
which can be understood as &amp;quot;the Sy in position p ar-
rows to the Sy in position q&amp;quot;. An Ar is thus an arc
between two Sy&apos;s. Ar&apos;s are expressed by arrowing
formulae, which, in their simplest formulation, are
spelled Syi Sy-1. It is also possible to spell dis-
jonctive arrowing, expressing that some Sy arrows
to either Syi or to Sy3. By a general convention, a
nucleus °Sy arrows to himself. General conditions
limit the expressive power of Arrowing formulae, as-
suring, among others, that the resulting graph must
be connected, and, with the exception of the reflex-
ive arrowing of °Sy, acyclic.
E.g., among French Arrowing formulae, there is
quant —s-Nn °Sy , where °Sy is a variable on
the Nucleus and which express that the quanti-
fier tous arrows to any Nucleurs in a Nu phrase:
&lt;(tousi ° troisz)Nn, {&lt;1, 2&gt;, &lt;2, 2&gt;}&gt;, &lt;(tousi
les2 ° garons3)Nn, {&lt;1, 3&gt;, &lt;2, 3&gt;, &lt;3, 3&gt;}.
</bodyText>
<sectionHeader confidence="0.962953" genericHeader="method">
3 Exploring properties
</sectionHeader>
<bodyText confidence="0.995537666666667">
Two experiments have been carried out in the ex-
ploration of Existence and Linearity properties. In
the first experiment, Linguistic Properties were used
to derive the linguistic data structures used by a
chunker and a NP extractor for Portuguese (see
(BHC99)). In the second experiment, Linguistic
</bodyText>
<figure confidence="0.933589666666667">
raw text
4
1 SMORPH (Tokenizat on and morphological analysis)
2 MPS (Recomposition of tokens and partial disambiguation)
3 AF (Chunking)
4 NP extraction
</figure>
<figureCaption confidence="0.999982">
Figure 1: The processing chain for NP extraction
</figureCaption>
<bodyText confidence="0.99680475">
Properties were used to structure lexical entries in
an HPSG-style grammar (see (HB98) and (Hag00)).
In both cases, the basic idea is the same: associate
to each category declared for a given model the com-
binatorial information attached to this category in a
certain grammatical context.
We describe here these two experiments in more de-
tails
</bodyText>
<subsectionHeader confidence="0.9433215">
3.1 First experiment
3.1.1 Context
</subsectionHeader>
<bodyText confidence="0.972348592592593">
A fine grained description of the Portuguese NP has
been accomplished with Linguistic Properties and
we wanted to use this linguistic description in or-
der to extract NPs from Portuguese running texts.
In a first step, the input text is tokenized and mor-
phologically analyzed (SMORPH (AM98)). Then,
the tokenized and morphologically analyzed text is
pre-processed, eliminating partially some ambiguity
and grouping or ungrouping some tokens previously
delimited (MPS). Then the text is chunked and fi-
nally, NPs (defined as regular expressions of chunks)
are extracted. Figure 1 summarizes the processing
chain for NP extraction.
Our chunker (called AF) consists in a very simple
algorithm (see (BHC99)) which uses linguistic struc-
tures (called leaves) associated to each token of the
text and tries to concatenate these structures from
left to right until the end of the text. Each concate-
nation introduces constraints for the next concate-
nation and, during parsing, part of the ambiguity is
solved as a side effect when concatenation fails.
To illustrate intuitively how our chunker works, as-
sume we want to analyze the following string with
the following leaves.
As dancas
(The dances)
Leaf 1 This leaf is associated to As
</bodyText>
<listItem confidence="0.99643175">
• The lemma associated to As is o
• The category is a definite article
• The model where this category appears is nom-
inal chunk
</listItem>
<figure confidence="0.538878">
syo Sy&apos; ...syn. It
2
3
NPs
</figure>
<listItem confidence="0.990317666666667">
• This category never starts a model of nominal
chunk
• This category never ends a model of nominal
chunk
• The set of categories that can follows this cate-
gory in this model contains noun
</listItem>
<bodyText confidence="0.9032795">
Token dancas is ambiguous plural-noun and verb
(dances and dance) and have the following two as-
sociated leaves.
Leaf 2
</bodyText>
<listItem confidence="0.9986747">
• The lemma associated to dancas is &amp;Inca
• The category is noun
• The model where this category appears is nom-
inal chunk
• This category can start a model of nominal
chunk
• This category always ends a model of nominal
chunk
• The set of categories that can follows this cate-
gory in this model is empty
</listItem>
<bodyText confidence="0.514197">
and
Leaf 3
</bodyText>
<listItem confidence="0.991622875">
• The lemma associated to dancas is clangor
• The category is verb
• The model where this category appears is verbal
chunk
• This category can start a model of verbal chunk
• This category can end a model of verbal chunk
• The set of categories that can follow this cate-
gory in this model contains clitic pronouns.
</listItem>
<bodyText confidence="0.999405266666667">
After the concatenation of the leaf 1 associated to
As, the only possibility is to concatenate leaf 2 be-
cause the model string on the right of As cannot be
closed (leaf 1 never ends a nominal chunk) and leaf
3 is not a possible successor of leaf 1.
The process of chunking is reduced to perform all the
possible concatenations of leaves from left to right,
each concatenation being restricted by the previous
concatenation.
Our chunker was used to process Portuguese text
and was evaluated on the task of NP extraction with
the results of 88% precision and 81,5% recall on the
NP detection5 (No exact match was required but
the NP head detected in the reference corpus is ex-
tracted)
</bodyText>
<page confidence="0.493966">
5 See (Hag00) for more details.
</page>
<subsubsectionHeader confidence="0.381822">
3.1.2 Leaves and Leaf Patterns
</subsubsectionHeader>
<bodyText confidence="0.9485045">
A leaf is thus a structure of the following form (We
represent it as a Prolog predicate).
leaf(WF, L, Cat, ModId, BStat, EStat, Foil).
Where:
</bodyText>
<listItem confidence="0.998684">
• WF(Word Form) is the token found in the text
to analyze
• L (Lemma) is the corresponding lemma
• Cat(egory) is the corresponding category
• ModId (Model Identifier) identifies the model in
which this category can appear
• BStat (Begin Status) is the integer 0, 1 or 2
meaning respectively that this category never,
always of sometimes starts the model identified
by ModelIdentifier
• EStat (End Status) is the integer 0, 1 or 2 mean-
ing respectively that this category never, al-
ways or sometimes ends the model indentified
by ModelIdentifier
• Foll (Followings) is the set of categories that can
follow the category Cat in the model identified
by ModId (The empty set when EndStatus is 1)
</listItem>
<bodyText confidence="0.9645543125">
We call a Leaf Pattern a leaf structure in which the
first argument (the word form) is not instantiated.
Our problem here is to deduce, from the Properties,
all the Leaves Patterns that are necessary to analyze
one text.
3.1.3 Relations between categories
appearing in a given model string
Given the vocabulary V of some model identifier
Sm, it is possible, using Existence Properties and
and Linearity Properties to define the following re-
lations in V x V6.
a and b being elements of V.
precedel: a precedel b if in any m—Sm containing
a and b, a always precedes b
order: a order b if there is at least a m — Sm in
which it is possible to say that a precedes b or that
</bodyText>
<figure confidence="0.5760068">
b precedes a.
exige: a exige b if for each m—Sm where a appears,
b also appears.
exctu: a exclu b if there is no m — Sm with a and
b.
</figure>
<footnote confidence="0.31937525">
It is also possible to define two subsets of V, So and
51. So consists of the elements of V that are always
alone in a model string and is defined the following
way:
61n the following section, we make two simplifications: the
notion of sumbsumption between categories in not taken into
account and we do not consider models within models, but
the general idea keeps the same
</footnote>
<note confidence="0.333301">
3.2.1 What we have to consider
</note>
<bodyText confidence="0.998065285714286">
We have to take into account the structuration of lin-
guistic signs that HPSG formalism stipulates. That
is:
So ={a E V I Vh E V exclu(a,b)}
Si is the complementary of So in V
For each category a of V, it is also possible to define
the set LP,„ as the set of all categories that possibly
follow a in at least one model string.
Having these relations and these sets, one can de-
fine the subsets of V that always, sometimes and
never start a model string and the subsets of V that
always, sometimes and never end a model string,
which is precisely what is needed to define the leaves
together with LP,„.
We called these subsets AS (Always start), SS
(Sometimes start), NS (Never start), AE (Always
end), SE (Sometimes end) and NE (Never end)
With these definitions and considering the set of
Properties that define the models identified by m-
Sm we can then construct a set of leaf patterns the
following way:
</bodyText>
<listItem confidence="0.9919656875">
• The first argument is a variable (that will be
then instantiate with a linguistic form present
in the text)
• The second argument of the leaf predicate is
instantiated to an element of V
• The third argument of the leaf predicate is in-
stantiated to m-Sm.
• The fourth argument of the leaf predicate is in-
stantiated to 1, 2, 0 according to the fact that
this element is member of AS, SS or NS.
• The fifth argument of the leaf predicate is in-
stantiated to 1, 2 or 0 according to the fact that
this element is member of AE, SE of NE.
• The sixth argument corresponds to the set
LPeat being cat the category that is present in
the second argument.
</listItem>
<subsectionHeader confidence="0.999909">
3.2 Second experiment
</subsectionHeader>
<bodyText confidence="0.999603909090909">
In this second experiment, we want to use the Prop-
erties defined for the nominal chunk in order to
construct lexical entries that can enable to ana-
lyze nominal chunks in an HPSG-style (see (C594)
and (5W99)) .The HPSG grammar was then imple-
mented in ALE (Attribute Logic Engine, developped
by B. Carpenter and G. Penn). Only the syntactic
part of the lexical entries is taken into account.
We decided that for our grammar a nominal chunk
has to be a saturated sign with a nominal head. The
analysis fails if:
</bodyText>
<listItem confidence="0.985226666666667">
• No analysis is produced
• A linguistic sign is obtained but it is not satu-
rated
</listItem>
<bodyText confidence="0.963530833333333">
In the type hierarchy A linguistic sign has in
the path SYNSEM: SYN: LOC: CAT: HEAD (from
now on the whole path is designed by HEAD) a value
of type head that has the following subtypes.
head
subst
noun
verb
ady
func
det
mark
In the structuration of lexical signs If the
value of HEAD is noun then there is a value for
the path SYNSEM:SYN:LOC:CAT:VAL:SPR (from
now on just VAL:SPR) which is of type list of lin-
guistic signs
If the value of HEAD is det then the value of the path
SYNSEM:SYN:LOC:CAT:HEAD:SPEC (from now
on just SPEC) is of type non-empty list of linguistic
signs.
Finally, if the value of HEAD is ady then the value
of VAL:SPR is the empty list and the value of SPEC
is the empty list
</bodyText>
<subsectionHeader confidence="0.9853645">
3.2.2 What we can infer from Linguistic
Properties
</subsectionHeader>
<bodyText confidence="0.985416105263158">
Definition of the set of categories that never
can be alone in a nominal chunk model Con-
sidering the set of Properties modelling nominal
chunks, we can define the subset S2 of the vocab-
ulary V consisting in the set of categories that never
can be alone in a model.
S2 ={a E V I 3h E V exige(a,b)}
Rule 1 All the categories that are members of the
above defined sets AE U SE must have the value
noun for HEAD. Nouns and nominalized adjectives
that can be the head of a nominal chunks are con-
cerned by this rule.
Rule 2 All the categories that are member of the
set So (defined above) must be associated to a lexical
entry with the value empty list for VAL:SPR. Plural
nouns and pronouns that can be used alone in a
nominal chunk are concerned by this rule. Note that
Rule 2 applies to all the categories for which Rule 1
applies too as So is included in AE.
Rule 3 All the categories that are members of
(AS U Ss) n S2 and that are not considered tradi-
tionnaly as adjectives have the value det for HEAD
and have for SPEC a value of type sign that is sub-
sumed by SYNSEM:SYN:LOC:CAT:HEAD:noun.
Determiners are concerned with this rule
Rule 4 This rule handles with possible combina-
tion of determiners (or determiners and quantifiers)
and gives one possibility to combine them together.
It stipulates that if a category treated in Rule 3
can preceed another category treated in Rule 37 (we
know that through the relation order defined above),
then it is necessary to provide either a complex de-
terminer structure, or to add to the VAL:SPR value
of all the categories treated in Rule 1 the whole list
of determiners.
Rule 5 Any category of S2 that has not be con-
sidered by Rule 3 are taken as adjective and have
the value adj for HEAD.
</bodyText>
<subsectionHeader confidence="0.930606">
3.3 Extensions
</subsectionHeader>
<bodyText confidence="0.999974970588236">
It is well known that there are different kinds and
different sources of ambiguity. We point here two
of them and how they can be treated within our
framework.
A linguistic expression can be associated in the Lex-
icon to more than one mc : it is, e.g., the case for
Leafs 2 and 3 of the first experiment in Section 3.1.
The ambiguity is there resolved thanks to Leave 1.
Suppose that, as in French, there is a string of ex-
pressions in a related pattern - as le juge - where
both expressions are ambiguous (le being an arti-
cle and a clitic, juge a noun or a verb). In this
situation,the ambiguity is maintained, the system
specyfing both m-Nu and m- Vu for the le juge (re-
spectively, a nominal and a verbal chunk). This am-
biguity will be resolved in a context - e.g. to the
right of a preposition Leaf - in which the expression
can follow if it is specified as m-Nu but not if it is
as m- Vu.
As an important side-effect of the first experiment
(Section 3.1), it is remarked in 1100 (these) that ap-
plying the processing chain (see Figure 1) to previ-
ously and independently disambiguated expressions
improves very little the final results. We think that
observations as this one indicate that the incremen-
tal tactic of bottom-up parsing and that the require-
ment of a disambituation layer before parsing is not
the only possible way.
In the experiments presented in this paper we work
on model strings build with cat&apos;s, not with Sm sym-
bols (identifiers). Two basic types of identifiers
are recognize :the one related to nuclear phrases or
chunks, which are spelled Xu, X being a variable
on N, V, ADJ...and the ones related to not nuclear
</bodyText>
<footnote confidence="0.9266225">
7In Portuguese, combination of determiners and quanti-
fiers.
</footnote>
<bodyText confidence="0.9998333">
phrase, spelled with the bare X and its possible in-
stantiations. In general, a X&apos;rt in the model string of
some X”tz are not ambiguously related. But attache-
ment of Xx uto the right of a pattern X1 n....Xn
can be ambiguous.
Properties here presented apply exactly the same on
models strings with or without Sm&apos;s. So the pre-
viously characterised ambiguity can be expresed by
disjonctive arrowing in arrowing formula (see Sec-
tion 2.3).
</bodyText>
<sectionHeader confidence="0.99872" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.900315739130435">
In current work on syntax (heuristics for robust pars-
ing (see (AMCR01), (TJ97)) or unification-based
grammatical formalisms), it is quite difficult to ac-
cess pure linguistic information since the same syn-
tax is used both for the linguistic description and
the rules for the parsers. We believe that the ex-
pression of linguistic information by means of Lin-
guistic Properties is a possible step in the direction
of the centralization of linguistic knowledge with the
following benefits:
• Syntacticians would spend less time rewriting
rules carrying the same information for different
formalisms or for different parsers.
• The construction of a grammatical reference,
expressed in a formalized and non-ambiguous
way.
The notion of a grammar as a source of linguistic
knowledge is thus revisited in favor of a notion of
linguistic knowledge base&apos; from which syntactic in-
formation could be extracted for one or another spe-
cific grammar or application. The two experiments
that we described above seem to be a step in this
direction.
</bodyText>
<sectionHeader confidence="0.998699" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997433461538462">
S. Xit-Mokhtar. L&apos;analyse presyntaxique en une seul
etape. PhD thesis, Universite Blaise Pascal, 1998.
S. Nit-Mokhtar, J-P Chanod, and C. Roux. A multi-
input dual-entry dependency parser. In Proceedings
of IWPT 2001, Beijing, 2001.
G. Bes. La phrase verbale noyau en francais.
Recherches sur le francais pane, 15, 1999.
G Bes and P. Blache. Proprietes et analyse d&apos;un
langage. In Actes de TALN 99, July Cargese, 1999.
G Bes and C. Hagege. Properties in 5p. Techni-
cal report, Groupe de Recherche dans les Industries
de la Langue (GRIL), URL: lgril.univ-bpclermont.fr,
2001.
8The idea of a linguistic knowledge base was originally
mentioned by G. G. Bes in a project proposal (Cale) submit-
ted in 1991.
G Bes, C. Hagege, and L. Coheur. Des proprietes
linguistiques a l&apos;analyse d&apos;une langue. In Proceed-
ings of the VEXTAL Conference, November Venice,
1999.
P. Blache. Constraints, linguistic theories and
natural language processing. In Dimitris N.
Christodoulakis, editor, Natural Language Process-
ing - NLP 2000, pages 221-232. Springer-Verlag,
2000.
Pollard C. and I. Sag. Head-Driven Phrase Struc-
ture Grammar. CSLI Lecture Notes. Center for the
Study of Language and Information, 1994.
C. Hagege. Analyse syntaxique automatique du por-
tugais. PhD thesis, Universite Blaise Pascal, 2000.
C. Hagege and G. Bes. Da observacio de pro-
priedades linguisticas a sua formalizacio numa
gramatica do processamento da lingua. In Actas do
III Encontro para o Processamento Computacional
da Lingua Portuguesa (PROPOR&apos;98), Porto Alegre,
1998.
C. Pollard and Sag I. A. Information-Based Syntax
and Semantics, Volume I:Fundamentals. CSLI Lec-
ture Notes N. 13. Center for the Study of Language
and Information, 1987.
I. Sag and T. Wasow. Syntactic Theory: A formal
Introduction. Center for the Study of Language and
Information, Stanford University, 1999.
L. Tesniere. Elements de syntaxe structurale.
Klincksiek, 1969.
P. Tapanainen and T. Jarvinen. A non-rojective de-
pendency parser. In Proceedings of the 5th Con-
ference on Applied Natural Languages, Washington
D.C., 1997.
T. Torris and P. Miller. Formalismes syntaxiques
pour le traitement automatique du langage naturel.
Hermes, 1990.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.002645">
<title confidence="0.9940545">Encoding and reusing linguistic information expressed Linguistic Properties</title>
<author confidence="0.878096">Caroline</author>
<affiliation confidence="0.839635">Xerox Research Centre Europe</affiliation>
<address confidence="0.898446">6 Chemin de 38240 Meylan -</address>
<title confidence="0.70888">Caroline.Hagege©xrce.xerox.corn</title>
<author confidence="0.994729">G Gabriel</author>
<affiliation confidence="0.994574">GRIL Universite Blaise</affiliation>
<address confidence="0.994335">34 Avenue 63000 Clermont Ferrand -</address>
<email confidence="0.874474">Gabriel.Bes©univ-bpclermont.fr</email>
<abstract confidence="0.994200552495697">This paper presents a way to express linguistic knowledge independently of any algorithmic machinery and of any particular grammatical formalism. is performed through Properties, that will be presented. First, the status of linguistic knowledge in grammars is discussed, then the Linguistic Properties are presented and two experiments are mentioned. They illustrate the reusability of the linguistic information enclosed in these Properties. 1 Grammar and reusability of linguistic knowledge One of the central points in linguistically-motivated natural language processing is the notion of grammar. It is commonly accepted that a grammar (see (TM90)) is intended, among other things, to be both a precise tool of natural languages&apos; description and the declarative data source which must be interpreted by a computer. This means that the same metalanguage (the grammatical formalism) is used to encode the declarative linguistic informations and the rules that will feed a parser. We consider that this double function of a grammar is a disadvantage from the point of view of the reusability of linguistic knowledge. Indeed, the same device (the grammar) contains both linguistic information and some information adapted to a specific goal (parsing (shallow or not), generation, etc.) and to a specific algorithmic machinery. In order to be reusable and suitable for different goals, we hold that linguistic knowledge must be free from any specific requirements, while being, nevertheless, formally expressed. Furthermore, it must be modularly organised within different levels of explicit granularity in order to offer a taylorisable access. Linguistic Properties, which we distinguished from Processes i.e. effective computational procedures on strings of NL expressions are a possible way to fulfill these requirements. 2 Linguistic Properties Linguistic Properties (or simply Properties) were originally developed in the late 90&apos;s within the 5P The 5 Ps stand for systemobservations on sentences, knowledge, Properties of some natural language, cross-linguistic constraints on Projections or Princiand are efffective computational procedures. We present in this section the kernel of The following example introduces intuitively Properties and their potential of modularity. Given the following French expression in (i), it is possible to distinguish, in its metalanguage, different layers or aspects, illustrated by (i-a) to (i-c). i les trois fleurs i-a { les-[art, def], trois-[card], fleurs-[n] } ( les-[art, trois-[card], &lt; ( les-[art, trois-[card], , {&lt;1, 3&gt;, &lt;2, 3&gt;, &lt;3, 3&gt;}&gt; (i) is a string of expressions; (i-a) is a set, each member of which is an expression of (i) associated to a (or below), e.g. [art, def]; (i-b) is a parenthetised list obtained applying order relations to (i-a), and indexing it with the identifier Nu (for Nominal nuclear phrase); (i-c) is obtained associat- (i-b) to a set of pairs &lt; q &gt;, are positions in (i-b); the pair links the element in the element in position will say that (i-b) is a model to string, (i-b), that (i-a) is a a complete and more formalised version, see (BH01). The 5P Paradigm was presented as such in (B99) and (BH01 ) though antecedents, cited in (BH01 ), go back to a 89 report to the ESPRIT 393 ACORD european Project, where the notion of descriptive metalanguage, today&apos;s Properties, were explicitely introduced. For published work, see (BHC99), (HB98). For a different but related approach, see (BB99) and (Bla00) which remain &amp;quot;grammar oriented&amp;quot;. 2Another layer, expressing a semantic representation, can be added, but it is not discussed in this paper. to (i-b), that pairs q &gt; (i-c) is an model the model string (i-b). We distinguish three basic kinds of Properties : Existence Properties, Linearity Properties, Arrowing Properties. Packs as in (i-a) are specified by Existence Properties; order relations, by Linearity properties; Arrowing pairs, by Arrowing Properties. Each identifier e.g. Nu has its associated set Properties, e.g. M-Nn the set of all and only the models m-Nu satisfying Properties-Nn. Properties are expressed on symbols are identifiers. From hereafter we use a metavariable on identifiers, and a on a set of label/value pairs, or, in reduced notation, a set of values (as in previuos examples). A categoric a which no other value can be added. The assumed Lexicon is a set of lexical entries, each one being an expression assoto one or more cats subsumes cati , if cats C cati. The whole system can be viewed as a modular axiomatic system in which models are the objects satdifferent kinds of A basic model, as in (i-b), with its associated pack, as in (i-a), satisfies Existence and Linearity Properties; an arrowed model, as in (i-c) satisfies also Arrowing Properties. Furthermore, giving a set of Properties, a model can satisfy some, but not all of them. Properties can be expressed independently the ones from the others, and in any order. The set of features from which cat&apos;s are build can be more or less extended, and, the granularity of of Properties expresed on them, more or less refined. The model substitution rule relates the identifiers , Sinn, each one with its associated M- In a with a it substitutes some for E.g., assuming adj,)ADJn French m-ADJn (underliyng, e.g. the string model substitution rule obtains (2) from the following (1). (art, {&lt;1, 3&gt;, 3&gt;}&gt; &lt;2, 3&gt;, &lt;3, (art, {&lt;1, 4&gt;, &lt;2, 3&gt;, &lt;3, 4&gt;, &lt;4, 4&gt;}&gt; an optimal situation, Properties associated to 3The system benefits from the concept of factorizing relations of standard production rules of now traditional grammars. See in particular the LP statements of GPSG dissociated from dominance ID rule, and dependency grammar ((Tes69)), early HPSG in (PA87).The system tries to push this basic idea to its limits, disolving thus the concept of production rules. An analog of what the system of Properties is expected to express compared to production rules, can be seen in regular expressions as compared to production grammars of type 3 in the Chomsky&apos;s hierarchy. some NL, together with a Lexicon and the model substitution rule, specific the whole set of models required to describe the strings of expressions of the NL. We concentrate in the following in the intuitive presentation of Properties specifying models obtained without the model substitution rule. Given the different kinds of Properties, we will intuitively characterise the conditions that must be fulfilled by model in order to satisfy each one them Subsumption is the basic relation linking models and Properties. We already defined above subsumption a shorthand, we say here that isubsumes Smi if i= Smi. Furthermore, sets and Si of Sy symbols, we say that there is a bijective function between and Si such that each Sym in subsumes its corrresponding Syn in Si. 2.1 Existence Properties Existence Properties associated to some M-Sm specific the set of packs from which any m-Sm is obtained. We distinguish five kinds: Vocabulary property, Unicity property, Nucleus Property, Exigency Property, Exclusion Property. The Vocabulary Property, spelled by says that each symbol in the pack associated to a — iis subsumed by some symbol in and each symbol in Vs, subsumes some symbol in the of some (singleton categories are with their value) French Vivo{det, noun...} the vocabulary for Nn (nominal nuclear) French phrases (roughly, nominal chunks), art, def...], [det, art, id...], [det, dem...], which are associated in the Lexicon to, the expressions la, le..}, {un, une, des...}, {ce, ces, cette...}. The Unicity Property, spelled by = {Sy&amp;quot; , Syn } says that there are no two symbols in the pack assoto a m — by one and the same in . E.g. French = {At, express that there are no two articles, or two demonstratives or an article and a demonstrative in a Nn phrase. The Nucleus Property, spelled by = that in each m — is one and only one with a nucleus symbol spelled Sy subby some symbol in French quant, noun...} that Nu phrases have as a Nucleus either a cardinal (e.g. vu a quantifier (e.g. vu a noun (e.g. vu ° The Exigency Property, spelled by so} 4For a more formal and complete presentation, see BH-01. (remember that sets of Sy) that if in pack of a m — is included a set of subsumed by there must be also some Sr included in the pack such that Sr is subsumed by E.g. French {[u, ci} —)-Nn{{det}, {card}...}, where [n, c] stands for common nouns, express that common nouns require a determiner or a cardinal. The Exclusion Property, spelled by so} that if in the pack of a m— is included set of symbols subsumed by then there is not included a set Sr such that Sr is subsumed by E.g. French that the quantifier coexist with an indefinite article in a Nu phrase. 2.2 Linearity Properties Linearity Properties express order relations. A Linearity Property is spelled by that if in a m — is a symbol subsumed and a symbol subsumed by the former precedes the latter. : in French quantifier preall other is expressed by poss, card... 2.3 Arrowing Properties The basic role of Arrowing Properties is to specify the graph i.e. the set of Arrowing pairs that is the backbone from which the semantic representation is build. An arrowing pair (Ar) is a pair positions in the model string, and can be understood as &amp;quot;the position arto the position Ar is thus an arc two Ar&apos;s expressed by arrowing formulae, which, in their simplest formulation, are is also possible to spell jonctive arrowing, expressing that some Sy arrows either Syi or to By a general convention, a nucleus °Sy arrows to himself. General conditions limit the expressive power of Arrowing formulae, assuring, among others, that the resulting graph must be connected, and, with the exception of the reflexive arrowing of °Sy, acyclic. E.g., among French Arrowing formulae, there is , where °Sy is a variable on the Nucleus and which express that the quantito any Nucleurs in a Nu phrase: ° &lt;2, 2&gt;}&gt;, ° {&lt;1, 3&gt;, &lt;2, 3&gt;, &lt;3, 3&gt;}. 3 Exploring properties Two experiments have been carried out in the exploration of Existence and Linearity properties. In the first experiment, Linguistic Properties were used to derive the linguistic data structures used by a chunker and a NP extractor for Portuguese (see (BHC99)). In the second experiment, Linguistic raw text 4 1 SMORPH (Tokenizat on and morphological analysis) 2 MPS (Recomposition of tokens and partial disambiguation) 3 AF (Chunking) 4 NP extraction Figure 1: The processing chain for NP extraction Properties were used to structure lexical entries in an HPSG-style grammar (see (HB98) and (Hag00)). In both cases, the basic idea is the same: associate to each category declared for a given model the combinatorial information attached to this category in a certain grammatical context. We describe here these two experiments in more details 3.1 First experiment 3.1.1 Context A fine grained description of the Portuguese NP has been accomplished with Linguistic Properties and we wanted to use this linguistic description in order to extract NPs from Portuguese running texts. In a first step, the input text is tokenized and moranalyzed Then, the tokenized and morphologically analyzed text is pre-processed, eliminating partially some ambiguity and grouping or ungrouping some tokens previously delimited (MPS). Then the text is chunked and finally, NPs (defined as regular expressions of chunks) are extracted. Figure 1 summarizes the processing chain for NP extraction. Our chunker (called AF) consists in a very simple algorithm (see (BHC99)) which uses linguistic struc- (called to each token of the text and tries to concatenate these structures from left to right until the end of the text. Each concatenation introduces constraints for the next concatenation and, during parsing, part of the ambiguity is solved as a side effect when concatenation fails. To illustrate intuitively how our chunker works, assume we want to analyze the following string with the following leaves. As dancas (The dances) 1 leaf is associated to The lemma associated to is o • The category is a definite article • The model where this category appears is nominal chunk Sy&apos;It 2 3 NPs • This category never starts a model of nominal chunk • This category never ends a model of nominal chunk • The set of categories that can follows this category in this model contains noun ambiguous plural-noun and verb (dances and dance) and have the following two associated leaves. Leaf 2 The lemma associated to is &amp;Inca • The category is noun • The model where this category appears is nominal chunk • This category can start a model of nominal chunk • This category always ends a model of nominal chunk • The set of categories that can follows this category in this model is empty and Leaf 3 The lemma associated to is clangor • The category is verb • The model where this category appears is verbal chunk • This category can start a model of verbal chunk • This category can end a model of verbal chunk • The set of categories that can follow this category in this model contains clitic pronouns. After the concatenation of the leaf 1 associated to only possibility is to concatenate leaf 2 bethe model string on the right of be closed (leaf 1 never ends a nominal chunk) and leaf 3 is not a possible successor of leaf 1. The process of chunking is reduced to perform all the possible concatenations of leaves from left to right, each concatenation being restricted by the previous concatenation. Our chunker was used to process Portuguese text and was evaluated on the task of NP extraction with the results of 88% precision and 81,5% recall on the (No exact match was required but the NP head detected in the reference corpus is extracted) 5See (Hag00) for more details. 3.1.2 Leaves and Leaf Patterns A leaf is thus a structure of the following form (We represent it as a Prolog predicate). leaf(WF, L, Cat, ModId, BStat, EStat, Foil). Where: WF(Word Form) the token found in the text to analyze L (Lemma) the corresponding lemma Cat(egory) the corresponding category ModId (Model Identifier) the model in which this category can appear BStat (Begin Status) the integer 0, 1 or 2 respectively that this category the model identified EStat (End Status) the integer 0, 1 or 2 meanrespectively that this category althe model indentified Foll (Followings) the set of categories that can the category the model identified empty set when is call a Pattern leaf structure in which the first argument (the word form) is not instantiated. Our problem here is to deduce, from the Properties, the Patterns are necessary to analyze one text. 3.1.3 Relations between categories appearing in a given model string Given the vocabulary V of some model identifier is possible, using Existence Properties and and Linearity Properties to define the following rein V x and elements of V. precedel in any and always precedes order there is at least a m — it is possible to say that a precedes that exige for each a appears, appears. exclu there is no m — a and b. is also possible to define two subsets of V, of the elements of V that are always alone in a model string and is defined the following way: the following section, we make two simplifications: the notion of sumbsumption between categories in not taken into account and we do not consider models within models, but the general idea keeps the same 3.2.1 What we have to consider We have to take into account the structuration of linsigns that stipulates. That is: ={a V I Vh E exclu(a,b)} the complementary of V For each category a of V, it is also possible to define set the set of all categories that possibly follow a in at least one model string. Having these relations and these sets, one can define the subsets of V that always, sometimes and never start a model string and the subsets of V that always, sometimes and never end a model string, which is precisely what is needed to define the leaves with called these subsets start), start), start), end) and end) With these definitions and considering the set of that define the models identified by mcan then construct a set of leaf patterns the following way: • The first argument is a variable (that will be then instantiate with a linguistic form present in the text) • The second argument of the leaf predicate is instantiated to an element of V • The third argument of the leaf predicate is instantiated to m-Sm. • The fourth argument of the leaf predicate is instantiated to 1, 2, 0 according to the fact that element is member of SS • The fifth argument of the leaf predicate is instantiated to 1, 2 or 0 according to the fact that element is member of SE • The sixth argument corresponds to the set category that is present in the second argument. 3.2 Second experiment In this second experiment, we want to use the Properties defined for the nominal chunk in order to construct lexical entries that can enable to analyze nominal chunks in an HPSG-style (see (C594) (5W99)) .The was then implemented in ALE (Attribute Logic Engine, developped by B. Carpenter and G. Penn). Only the syntactic part of the lexical entries is taken into account. We decided that for our grammar a nominal chunk has to be a saturated sign with a nominal head. The analysis fails if: • No analysis is produced • A linguistic sign is obtained but it is not saturated the type hierarchy linguistic sign has in path SYNSEM: SYN: LOC: CAT: now on the whole path is designed by HEAD) a value type has the following subtypes. head subst noun verb ady func det mark the structuration of lexical signs the of there is a value for the path SYNSEM:SYN:LOC:CAT:VAL:SPR (from now on just VAL:SPR) which is of type list of linguistic signs the value of the value of the path SYNSEM:SYN:LOC:CAT:HEAD:SPEC (from now on just SPEC) is of type non-empty list of linguistic signs. if the value of the value of VAL:SPR is the empty list and the value of SPEC is the empty list 3.2.2 What we can infer from Linguistic Properties Definition of the set of categories that never be alone in a nominal chunk model Considering the set of Properties modelling nominal chunks, we can define the subset S2 of the vocabulary V consisting in the set of categories that never can be alone in a model. ={a E V I 3h E exige(a,b)} 1 the categories that are members of the defined sets U SE have the value and nominalized adjectives that can be the head of a nominal chunks are concerned by this rule. 2 the categories that are member of the above) must be associated to a lexical with the value list VAL:SPR. Plural nouns and pronouns that can be used alone in a nominal chunk are concerned by this rule. Note that Rule 2 applies to all the categories for which Rule 1 too as included in Rule 3 All the categories that are members of n and that are not considered tradias adjectives have the value HEAD have for SPEC a value of type is subsumed by SYNSEM:SYN:LOC:CAT:HEAD:noun. Determiners are concerned with this rule Rule 4 This rule handles with possible combination of determiners (or determiners and quantifiers) and gives one possibility to combine them together. It stipulates that if a category treated in Rule 3 preceed another category treated in Rule (we that through the relation above), then it is necessary to provide either a complex determiner structure, or to add to the VAL:SPR value of all the categories treated in Rule 1 the whole list of determiners. Rule 5 Any category of S2 that has not be considered by Rule 3 are taken as adjective and have value HEAD. 3.3 Extensions It is well known that there are different kinds and different sources of ambiguity. We point here two of them and how they can be treated within our framework. A linguistic expression can be associated in the Lexto more than one : is, e.g., the case for Leafs 2 and 3 of the first experiment in Section 3.1. The ambiguity is there resolved thanks to Leave 1. Suppose that, as in French, there is a string of exin a related pattern as juge expressions are ambiguous an artiand a clitic, noun or a verb). In this situation,the ambiguity is maintained, the system both m-Nu and m- Vu for the juge (respectively, a nominal and a verbal chunk). This ambiguity will be resolved in a context e.g. to the right of a preposition Leaf in which the expression can follow if it is specified as m-Nu but not if it is as m- Vu. As an important side-effect of the first experiment (Section 3.1), it is remarked in 1100 (these) that applying the processing chain (see Figure 1) to previously and independently disambiguated expressions improves very little the final results. We think that observations as this one indicate that the incremental tactic of bottom-up parsing and that the requirement of a disambituation layer before parsing is not the only possible way. In the experiments presented in this paper we work model strings build with with Sm symbols (identifiers). Two basic types of identifiers are recognize :the one related to nuclear phrases or chunks, which are spelled Xu, X being a variable N, V, ones related to not nuclear Portuguese, combination of determiners and quantifiers. phrase, spelled with the bare X and its possible in- In general, a the model string of some X”tz are not ambiguously related. But attacheof Xx uto the right of a pattern n....Xn can be ambiguous. Properties here presented apply exactly the same on strings with or without the previously characterised ambiguity can be expresed by disjonctive arrowing in arrowing formula (see Section 2.3). 4 Conclusion In current work on syntax (heuristics for robust parsing (see (AMCR01), (TJ97)) or unification-based grammatical formalisms), it is quite difficult to access pure linguistic information since the same syntax is used both for the linguistic description and the rules for the parsers. We believe that the expression of linguistic information by means of Linguistic Properties is a possible step in the direction of the centralization of linguistic knowledge with the following benefits: • Syntacticians would spend less time rewriting rules carrying the same information for different formalisms or for different parsers. • The construction of a grammatical reference, expressed in a formalized and non-ambiguous way. The notion of a grammar as a source of linguistic knowledge is thus revisited in favor of a notion of linguistic knowledge base&apos; from which syntactic information could be extracted for one or another specific grammar or application. The two experiments that we described above seem to be a step in this direction.</abstract>
<note confidence="0.621018416666667">References Xit-Mokhtar. presyntaxique en une seul thesis, Universite Blaise Pascal, 1998. S. Nit-Mokhtar, J-P Chanod, and C. Roux. A multidual-entry dependency parser. In IWPT 2001, 2001. G. Bes. La phrase verbale noyau en francais. sur le francais pane, 1999. G Bes and P. Blache. Proprietes et analyse d&apos;un In de TALN 99, Cargese, 1999. G Bes and C. Hagege. Properties in 5p. Technical report, Groupe de Recherche dans les Industries</note>
<abstract confidence="0.87808625">de la Langue (GRIL), URL: lgril.univ-bpclermont.fr, 2001. idea of a linguistic knowledge base was originally mentioned by G. G. Bes in a project proposal (Cale) submitin G Bes, C. Hagege, and L. Coheur. Des proprietes a l&apos;analyse d&apos;une langue. In Proceedof the VEXTAL Conference, Venice, 1999. P. Blache. Constraints, linguistic theories and natural language processing. In Dimitris N. editor, Language Process-</abstract>
<note confidence="0.904077551724138">NLP 2000, 221-232. Springer-Verlag, 2000. C. and I. Sag. Phrase Struc- Grammar. Lecture Notes. Center for the Study of Language and Information, 1994. Hagege. syntaxique automatique du porthesis, Universite Blaise Pascal, 2000. C. Hagege and G. Bes. Da observacio de propriedades linguisticas a sua formalizacio numa do processamento da lingua. In do para o Processamento Computacional Lingua Portuguesa (PROPOR&apos;98), Alegre, 1998. Pollard and Sag I. A. Syntax Semantics, Volume I:Fundamentals. Lecture Notes N. 13. Center for the Study of Language and Information, 1987. Sag and T. Wasow. Theory: A formal for the Study of Language and Information, Stanford University, 1999. Tesniere. de syntaxe structurale. Klincksiek, 1969. P. Tapanainen and T. Jarvinen. A non-rojective deparser. In of the 5th Conon Applied Natural Languages, D.C., 1997. Torris and P. Miller. syntaxiques pour le traitement automatique du langage naturel. Hermes, 1990.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Xit-Mokhtar</author>
</authors>
<title>L&apos;analyse presyntaxique en une seul etape.</title>
<date>1998</date>
<booktitle>In Proceedings of IWPT 2001,</booktitle>
<tech>PhD thesis,</tech>
<institution>Universite Blaise Pascal,</institution>
<location>Beijing,</location>
<marker>Xit-Mokhtar, 1998</marker>
<rawString>S. Xit-Mokhtar. L&apos;analyse presyntaxique en une seul etape. PhD thesis, Universite Blaise Pascal, 1998. S. Nit-Mokhtar, J-P Chanod, and C. Roux. A multiinput dual-entry dependency parser. In Proceedings of IWPT 2001, Beijing, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Bes</author>
</authors>
<title>La phrase verbale noyau en francais. Recherches sur le francais pane,</title>
<date>1999</date>
<volume>15</volume>
<marker>Bes, 1999</marker>
<rawString>G. Bes. La phrase verbale noyau en francais. Recherches sur le francais pane, 15, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Bes</author>
<author>P Blache</author>
</authors>
<title>Proprietes et analyse d&apos;un langage.</title>
<date>1999</date>
<booktitle>In Actes de TALN 99, July Cargese,</booktitle>
<marker>Bes, Blache, 1999</marker>
<rawString>G Bes and P. Blache. Proprietes et analyse d&apos;un langage. In Actes de TALN 99, July Cargese, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Bes</author>
<author>C Hagege</author>
</authors>
<date>2001</date>
<booktitle>Properties in 5p. Technical report, Groupe de Recherche dans les Industries de la Langue (GRIL), URL: lgril.univ-bpclermont.fr,</booktitle>
<marker>Bes, Hagege, 2001</marker>
<rawString>G Bes and C. Hagege. Properties in 5p. Technical report, Groupe de Recherche dans les Industries de la Langue (GRIL), URL: lgril.univ-bpclermont.fr, 2001.</rawString>
</citation>
<citation valid="true">
<title>8The idea of a linguistic knowledge base was originally mentioned by G. G. Bes in a project proposal (Cale) submitted in</title>
<date>1991</date>
<marker>1991</marker>
<rawString>8The idea of a linguistic knowledge base was originally mentioned by G. G. Bes in a project proposal (Cale) submitted in 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Bes</author>
<author>C Hagege</author>
<author>L Coheur</author>
</authors>
<title>Des proprietes linguistiques a l&apos;analyse d&apos;une langue.</title>
<date>1999</date>
<booktitle>In Proceedings of the VEXTAL Conference, November</booktitle>
<location>Venice,</location>
<marker>Bes, Hagege, Coheur, 1999</marker>
<rawString>G Bes, C. Hagege, and L. Coheur. Des proprietes linguistiques a l&apos;analyse d&apos;une langue. In Proceedings of the VEXTAL Conference, November Venice, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Blache</author>
</authors>
<title>Constraints, linguistic theories and natural language processing.</title>
<date>2000</date>
<booktitle>Natural Language Processing - NLP 2000,</booktitle>
<pages>221--232</pages>
<editor>In Dimitris N. Christodoulakis, editor,</editor>
<publisher>Springer-Verlag,</publisher>
<marker>Blache, 2000</marker>
<rawString>P. Blache. Constraints, linguistic theories and natural language processing. In Dimitris N. Christodoulakis, editor, Natural Language Processing - NLP 2000, pages 221-232. Springer-Verlag, 2000.</rawString>
</citation>
<citation valid="false">
<authors>
<author>C Pollard</author>
<author>I Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar. CSLI Lecture Notes. Center for the Study of Language and Information,</title>
<date>1994</date>
<journal>C. Hagege</journal>
<booktitle>In Actas do III Encontro para o Processamento Computacional da Lingua Portuguesa (PROPOR&apos;98),</booktitle>
<tech>PhD thesis,</tech>
<institution>Universite Blaise Pascal,</institution>
<location>Porto Alegre,</location>
<marker>Pollard, Sag, 1994</marker>
<rawString>Pollard C. and I. Sag. Head-Driven Phrase Structure Grammar. CSLI Lecture Notes. Center for the Study of Language and Information, 1994. C. Hagege. Analyse syntaxique automatique du portugais. PhD thesis, Universite Blaise Pascal, 2000. C. Hagege and G. Bes. Da observacio de propriedades linguisticas a sua formalizacio numa gramatica do processamento da lingua. In Actas do III Encontro para o Processamento Computacional da Lingua Portuguesa (PROPOR&apos;98), Porto Alegre, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
<author>I A Sag</author>
</authors>
<title>Information-Based Syntax and Semantics, Volume I:Fundamentals.</title>
<date>1987</date>
<booktitle>CSLI Lecture Notes N. 13. Center for the Study of Language and Information,</booktitle>
<marker>Pollard, Sag, 1987</marker>
<rawString>C. Pollard and Sag I. A. Information-Based Syntax and Semantics, Volume I:Fundamentals. CSLI Lecture Notes N. 13. Center for the Study of Language and Information, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Sag</author>
<author>T Wasow</author>
</authors>
<title>Syntactic Theory: A formal Introduction. Center for the Study of Language and Information,</title>
<date>1999</date>
<location>Stanford University,</location>
<marker>Sag, Wasow, 1999</marker>
<rawString>I. Sag and T. Wasow. Syntactic Theory: A formal Introduction. Center for the Study of Language and Information, Stanford University, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Tesniere</author>
</authors>
<title>Elements de syntaxe structurale.</title>
<date>1969</date>
<location>Klincksiek,</location>
<marker>Tesniere, 1969</marker>
<rawString>L. Tesniere. Elements de syntaxe structurale. Klincksiek, 1969.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Tapanainen</author>
<author>T Jarvinen</author>
</authors>
<title>A non-rojective dependency parser.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th Conference on Applied Natural Languages,</booktitle>
<location>Washington D.C.,</location>
<marker>Tapanainen, Jarvinen, 1997</marker>
<rawString>P. Tapanainen and T. Jarvinen. A non-rojective dependency parser. In Proceedings of the 5th Conference on Applied Natural Languages, Washington D.C., 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Torris</author>
<author>P Miller</author>
</authors>
<title>Formalismes syntaxiques pour le traitement automatique du langage naturel. Hermes,</title>
<date>1990</date>
<marker>Torris, Miller, 1990</marker>
<rawString>T. Torris and P. Miller. Formalismes syntaxiques pour le traitement automatique du langage naturel. Hermes, 1990.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>