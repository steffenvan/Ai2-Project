<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.016380">
<title confidence="0.991053">
Does Korean defeat phonotactic word segmentation?
</title>
<author confidence="0.977056">
Robert Daland
</author>
<affiliation confidence="0.9856295">
Department of Linguistics
University of California, Los Angeles
</affiliation>
<address confidence="0.921055">
3125 Campbell Hall, Box 951543
Los Angeles, CA 90095-1543, USA
</address>
<email confidence="0.999016">
r.daland@gmail.com
</email>
<author confidence="0.919346">
Kie Zuraw
</author>
<affiliation confidence="0.9777795">
Department of Linguistics
University of California, Los Angeles
</affiliation>
<address confidence="0.918946">
3125 Campbell Hall, Box 951543
Los Angeles, CA 90095-1543, USA
</address>
<email confidence="0.999701">
kie@ucla.edu
</email>
<sectionHeader confidence="0.99861" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999227">
Computational models of infant word
segmentation have not been tested on a
wide range of languages. This paper ap-
plies a phonotactic segmentation model
to Korean. In contrast to the underseg-
mentation pattern previously found in
English and Russian, the model exhibited
more oversegmentation errors and more
errors overall. Despite the high error rate,
analysis suggested that lexical acquisition
might not be problematic, provided that
infants attend only to frequently seg-
mented items.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998978125">
The process by which infants learn to parse the
acoustic signal into word-sized units—word
segmentation—is an active area of research in
developmental psychology (Polka and Sundara
2012; Saffran et al. 1996) and cognitive model-
ing (Daland and Pierrehumbert 2011 [DP11],
Goldwater et al. 2009 [GGJ09]). Word segmen-
tation is a classic bootstrapping problem: to learn
words, infants must segment the input, because
around 90% of the novel word types they hear
are never uttered in isolation (Aslin et al. 1996;
van de Weijer 1998). However, in order to seg-
ment infants must know some words, or gener-
alizations about the properties of words. How
can infants form generalizations about words
before learning words themselves?
</bodyText>
<subsectionHeader confidence="0.766838">
1.1 DiBS
</subsectionHeader>
<bodyText confidence="0.9999099">
Two approaches in the literature might be termed
lexical and phonotactic. Under the lexical ap-
proach, exemplified by GGJ09, infants are as-
sumed to exploit the Zipfian distribution of lan-
guage, identifying frequently recurring and mu-
tually predictive sequences as words. In the pho-
notactic approach, infants are assumed to lever-
age universal and/or language-specific knowl-
edge about the phonological content of se-
quences to infer the optimal segmentation. The
present study focuses on the phonotactic ap-
proach outlined in DP11, termed DiBS. For other
examples of approaches that use phonotactics,
see Fleck 2008, Blanchard et al. 2010.
A (Di)phone-(B)ased (S)egmentation model
consists of an inventory of segment-segment se-
quences, with an estimated probability that a
word boundary falls between the two segments.
For example, when [pd] occurs in English, the
probability of an intervening word boundary is
very high: Pr(#  |[pd]) z 1. These probabilities
are the parameters of the model to be learned. In
the supervised setting (baseline model), these
parameters may be estimated directly from data
in which the word boundaries are labeled: Pr(# |
pd) = Fr(# ^ pd) / (Fr(# ^ pd) + Fr(–# ^ pd))
where Fr(# ^ pd) is the number of [pd] sequences
separated by a word boundary, and Fr(–# ^ pd)
the number of [pd]’s not separated by a word
boundary. For assessment purposes, these prob-
abilities are converted to hard decisions.
DP11 describe an unsupervised learning algo-
rithm for DiBS that exploits a positional inde-
pendence assumption, treating phrase edges as a
proxy for word edges (phrasal model). This
learning model’s performance on English is on
par with state-of-the-art lexical models (GGJ09),
reflecting the high positional informativeness of
diphones in English. We apply the baseline and
phrasal models to Korean.
</bodyText>
<subsectionHeader confidence="0.989353">
1.2 Linguistic properties of Korean
</subsectionHeader>
<bodyText confidence="0.8560575">
Korean is unrelated to languages previously
modeled (English, Dutch, French, Spanish, Ara-
</bodyText>
<page confidence="0.983402">
873
</page>
<bodyText confidence="0.937675217391304">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 873–877,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
bic, Greek, Russian), and it is an interesting test
case for both phonotactic and lexical approaches.
Korean syntax and morphology (Sohn 1999)
present a particular challenge for unsupervised
learning. Most noun phrases are marked with a
limited set of case suffixes, and clauses generally
end in a verb, inflected with suffixes ending in a
limited set of sounds ([a,A,i,jo]). Thus, the
phrase-final distribution may not reflect the
overall word-final distribution—problematic for
some phonotactic approaches. Similarly, the high
frequency and positional predictability of affixes
could lead a lexical model to treat them as words.
A range of phonological processes apply in Ko-
rean, even across word boundaries (Sohn 1999),
yielding extensive allomorphy. Phonotactic
models may be robust to this kind of variation,
but it is challenging for current lexical models
(see DP11).
Korean consonantal phonology gives diphones
several informative properties, including:
</bodyText>
<listItem confidence="0.987194666666667">
• Various consonant clusters (obstruent-
lenis, lenis-nasal, et al.) are possible only
if they span a word boundary
• Various consonants cannot precede a
word boundary
• [q] cannot follow a word boundary
</listItem>
<bodyText confidence="0.99867825">
Conversely, unlike in previously studied lan-
guages, vowel-vowel sequences are common
word-internally. This is likely to be problematic
for phonotactic models, but not for lexical ones.
</bodyText>
<sectionHeader confidence="0.988491" genericHeader="introduction">
2 Methods
</sectionHeader>
<bodyText confidence="0.999959928571429">
We obtained a phonetic corpus representing Ko-
rean speech by applying a grapheme-to-phonetic
converter to a text corpus. First, we conducted an
analysis of this phonetic corpus, with results in
Table 1. Next, for comparability with previous
studies, two 750,000-word samples (representing
approximately one month of child input each)
were randomly drawn from the phonetic cor-
pus—the training and test corpora. The phrasal
and baseline DiBS models described above were
trained and tested on these corpora; results are
reported in Table 2. Finally, we inspected one
‘day’ worth of segmentations, and offer a quali-
tative assessment of errors.
</bodyText>
<subsectionHeader confidence="0.993858">
2.1 Corpus and phonetic conversion
</subsectionHeader>
<bodyText confidence="0.998396684210526">
The Korean Advanced Institute of Science and
Technology Raw Corpus, available from the Se-
mantic Web Research Center, semantic-
web.kaist.ac.kr/home/index.php/KAIST_Corpus
contains approximately 70,000,000 words from
speeches, novels, newspapers, and more. The
corpus was preprocessed to supply phrase breaks
at punctuation marks and strip XML.
The grapheme-to-phonetic conversion system
of Kim et al. (2002) was generously shared by its
creators. It includes morphosyntactic processing,
phrase-break detection, and a dictionary of pho-
netic exceptions. It applies regular and lexically-
conditioned phonological rules, but not optional
rules. Kim et al. reported per-grapheme accuracy
of 99.7% in one corpus and 99.98% in another.
An example of original text and the phonetic
conversion is given below, with phonological
changes in bold:
</bodyText>
<figure confidence="0.951455">
phonetic: 2
13 # 4
5
6
IPA: k jA g k i t o1 jAt;uesA2 tl;&apos;&apos;uls*e
133 # t;ugagte4 mune tl;haxlt;aVak
k*walil5 t901Aphett*a6
(the * diacritic indicates tense consonants)
</figure>
<bodyText confidence="0.830594833333333">
gloss: Born3 in Yeoju2, Gyeonggi-do1.
Graduated6 from Jungang University4
Department of Creative Writing5.
We relied on spaces in the corpus to indicate
word boundaries, although, as in all languages,
there can be inconsistencies in written Korean.
</bodyText>
<subsectionHeader confidence="0.99392">
2.2 Error analysis
</subsectionHeader>
<bodyText confidence="0.999879470588235">
An under-researched issue is the nature of the
errors that segmentation algorithms make. For a
given input word in the test corpus, we defined
the output projection as the minimal sequence of
segmented words containing the entire input
word. For example, if the#kitty were segmented
as thekitty, then thekitty would be the output pro-
jection for both the and kitty. Similarly, for a
posited word in the segmentation/output of the
test corpus, we defined the input projection. For
example, if the#kitty were segmented as
theki#tty, then the the#kitty would be the input
projection of both theki and tty. For each word,
we examined the input-output relationship. Sev-
eral questions were of interest. Are highly fre-
quent items segmented frequently enough that
the child is likely to be able to learn them? Is it
</bodyText>
<figure confidence="0.756698333333333">
orthographic: 3.
1 2
4 5 6.
</figure>
<page confidence="0.991174">
874
</page>
<bodyText confidence="0.99981425">
the case that all or most items which are seg-
mented frequently are themselves words? Are
there predicted errors which seem especially se-
rious or difficult to overcome?
</bodyText>
<sectionHeader confidence="0.999043" genericHeader="related work">
3 Results and discussion
</sectionHeader>
<bodyText confidence="0.99994275">
The 1350 distinct diphones found in the phonetic
corpus were grouped into phonological classes.
Table 1 indicates the probabilities (percentage)
that a word boundary falls inside the diphone;
when the class contains 3 or more diphones, the
median and range are shown. Because of various
phonological processes, some sequences cannot
exist (blank cells), some can occur only word-
internally (marked int), and some can occur only
across word boundaries (marked span). For ex-
ample, the velar nasal [q] cannot begin a word,
so diphones of the form Xy must be word-
internal. Conversely, a lenis-/h/ sequence indi-
cates a word boundary, because within a word a
lenis stop merges with following /h/ to become
an aspirated stop. If all diphones in a cell have a
spanning rate above 90%, the cell says span*,
and if below 10%, int*. This means that all the
diphones in that class are highly informative;
other classes contain a mix of more and less in-
formative diphones.
The performance of the DiBS models is
shown in Table 2. An undersegmentation error is
a true word boundary which the segmentation
algorithm fails to find (miss), while an overseg-
mentation error is a falsely posited boundary
(false alarm). The under- and over-segmentation
error rates are defined as the number of such er-
rors per word (percent). We also report the preci-
sion, recall, and F scores for boundary detection,
word token segmentation, and type segmentation
(for details see DP11, GGJ09).
</bodyText>
<table confidence="0.996323833333333">
model baseline phrasal
under (errs per wd) 43.4 72.5
over (errs per wd) 17.7 22.0
prec (bdry/tok/type) 68/36/34 28/11/12
recall (bdry/tok/type) 46/27/29 11/6/8
F (bdry/tok/type) 55/31/31 15/8/9
</table>
<tableCaption confidence="0.999693">
Table 2: Results of DiBS models
</tableCaption>
<bodyText confidence="0.9998915">
On the basis of the fact that the oversegmenta-
tion error rate in English and Russian was con-
sistently below 10% (&lt;1 error/10 wds), DP11
conjectured that phonotactic segmenters will,
cross-linguistically, avoid significant overseg-
mentation. The results in Table 2 provide a coun-
terexample: oversegmentation is distinctly higher
than in English and Russian. Indeed, Korean is a
more challenging language for purely phonotac-
tic segmentation.
</bodyText>
<subsectionHeader confidence="0.997561">
3.1 Phonotactic cues to word segmentation
</subsectionHeader>
<bodyText confidence="0.9990396">
Because phonological processes are more likely
to apply word-internally, word-internal se-
quences are more predictable (Aslin et al. 1996;
DP11; GGJ09; Saffran et al. 1996; van de Weijer
1998). The phonology of Korean is a potentially
</bodyText>
<table confidence="0.961262619047619">
seg. 2 lenis lenis tense asp. h n m 9 liquid vowel diphth.
seg. 1 stop non-stop
lenis stop span 100 int* 27 span 100 span 100 int* 7
4-100 5-53 98-100 10-100 0-100
lenis int int
non-stop
tense int int
aspirated int int
h int int
n 65 46, 57 38 45 35 32 61 span* 12 53
29-66 18-82 32-67 1-37 20-99
m 19 18, 18 14 14 14 int* 21 span int* 12
14-21 4-57 12-26 1-92
9 12 10, 12 9 11 int* int* 10 span 6 18
11-13 6-55 10-15 0-64 4-86
liquid 55 84, 88 71 53 42 90 53 int* 3 39
43-63 6-90 17-68 0-14 7-95
vowel 16 32 36 18 38 5 13 int int* 44 51
6-87 12-82 4-97 3-88 9-84 1-31 2-70 1-90 3-100
diphthong 10 12 21 11 16 3 19 int int* 26 31
0-79 0-55 0-100 0-87 0-88 0-15 0-74 0-100 0-100
</table>
<tableCaption confidence="0.999525">
Table 1: Diphone behavior
</tableCaption>
<page confidence="0.998395">
875
</page>
<bodyText confidence="0.999848166666667">
rich source of information for word segmenta-
tion: obstruent-initial diphones are generally in-
formative as to the presence/absence of word
boundaries. However, as we suspected, vowel-
vowel sequences are problematic, since they oc-
cur freely both within words and across word
boundaries. Korean differs from English in that
most English diphones occur nearly exclusively
within words, or nearly exclusively across word
boundaries (DP11), while in Korean most sono-
rant-obstruent sequences occur both within and
across words.
</bodyText>
<subsectionHeader confidence="0.999798">
3.2 Errors and word-learning
</subsectionHeader>
<bodyText confidence="0.999981684210526">
It seems reasonable to assume that word-learning
is best facilitated by seeing multiple occurrences
of a word. A segmentation that is produced only
once might be ignored; thus we defined an input
or output projection as frequent if it occurred
more than once in the test sample.
A word learner relying on a phonotactic model
could expect to successfully identify many fre-
quent words. For 73 of the 100 most frequent
input words, the only frequent output projection
in the baseline model was the input word itself,
meaning that the word was segmented correctly
in most contexts. For 20 there was no frequent
output projection, meaning that the word was not
segmented consistently across contexts, which
we assume is noise to the learner. In the phrasal
model, for 16 items the most frequent output pro-
jection was the input word itself and for 64 there
was no frequent output projection.
Conversely, of the 100 most frequent potential
words identified by the baseline model, in 26
cases the most frequent input projection was the
output word itself: a real word was correctly
identified. In 26 cases there was no frequent in-
put projection, and in 48 another input projection
was at least as frequent as the output word. One
such example is [mjnn] ‘cotton’, frequently seg-
mented out when it was a bound morpheme (‘if’
or ‘how many’). The most frequently segmented
item was [ke], which can be a freestanding word
(‘there/thing’), but was often segmented out from
words suffixed with [-ke] ‘-ly/to’ and [-eke] ‘to’.
What do these results mean for a child using a
phonotactic strategy? First, many of the types
segmented in a day would be experienced only
once (and presumably ignored). Second, infants
would not go far astray if they learned fre-
quently-segmented items as words.
</bodyText>
<subsectionHeader confidence="0.999813">
3.3 Phrase edges and independence
</subsectionHeader>
<bodyText confidence="0.999996083333333">
We suspected the reason that the phrasal DiBS
model performed so much worse than baseline
was its assumption that phrase-edge distributions
approximate word-edge distributions. Phrase be-
ginnings were a good proxy for word beginnings,
but there were mismatches phrase-finally. For
example, [a] is much more frequent phrase-
finally than word-finally (because of common
verb suffixes ending in [a]), while [n] is much
more frequent word-finally (because of non-
sentence-final suffixes ending in [n]). The posi-
tional independence assumption is too strong.
</bodyText>
<sectionHeader confidence="0.999267" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.9999708">
This paper extends previous studies by applying
a computational learning model of phonotactic
word segmentation to Korean. Various properties
of Korean led us to believe it would challenge
both unsupervised phonotactic and lexical ap-
proaches.
Phonological and morphological analysis of
errors yielded novel insights. For example, the
generally greater error rate in Korean is partly
caused by a high tolerance for vowel-vowel se-
quences within words. Interactions between
morphology and word order result in violations
of a key positional independence assumption.
Phonotactic segmentation was distinctly worse
than in previous languages (English, Russian),
particularly for oversegmentation errors. This
implies the segmentation of simplistic diphone
models is not cross-linguistically stable, a find-
ing that aligns with other cross-linguistic com-
parisons of segmentation algorithms. In general,
distinctly worse performance is found for lan-
guages other than English (Sesotho: Blanchard et
al. 2010; Arabic and Spanish: Fleck 2008). These
facts suggest that the successful segmentation
model must incorporate richer phonotactics, or
integrate some lexical processing. On the bright
side, we found that frequently segmented items
were mostly words, so a high segmentation error
rate does not necessarily translate to a high error
rate for word-learning.
</bodyText>
<sectionHeader confidence="0.999274" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.985827428571429">
Aslin, R. N., Woodward, J. Z., LaMendola, N. P., &amp;
Bever, T. G. (1996). Models of word segmentation
in fluent maternal speech to infants. In J. L. Mor-
gan &amp; K. Demuth (Eds.). Signal to syntax. Mah-
wah, NJ: LEA, pp. 117–134.
Blanchard, D., Heinz, J., &amp; Golinkoff, R. (2010).
Modeling the contribution of phonotactic cues to
</reference>
<page confidence="0.987857">
876
</page>
<reference confidence="0.997714214285714">
the problem of word segmentation. Journal of
Child Language 37(3), 487-511.
Daland, R. &amp; Pierrehumbert, J.B. (2011). Learnability
of diphone-based segmentation. Cognitive Science
35(1), 119-155.
Fleck, M. (2008). Lexicalized phonotactic word seg-
mentation. Proceedings of ACL-08: HLT, 130-138.
Goldwater, S., Griffiths, T. L., &amp; Johnson, M. (2009).
A Bayesian framework for word segmentation:
Exploring the effects of context. Cognition 112(1),
21-54.
Kim, B., Lee, G., &amp; Lee, J.-H. (2002). Morpheme-
based grapheme to phoneme conversion using
phonetic patterns and morphophonemic connec-
tivity information. ACM Trans. Asian Lang. Inf.
Process. 1(1), 65-82.
Polka, L. &amp; Sundara, M. (2012). Word segmentation
in monolingual infants acquiring Canadian-English
and Canadian-French: Native language, cross-
language and cross-dialect comparisons. Infancy
17(2), 198-232.
Saffran, J. R., Aslin, R. N., &amp; Newport, E. L. (1996).
Statistical learning by 8-month-old infants. Science
275(5294), 1926-1928.
Sohn, H.-M. (1999). The Korean Language. Cam-
bridge: Cambridge University Press.
van de Weijer, J. (1998). Language input for word
discovery. MPI series in psycholinguistics (No. 9).
</reference>
<page confidence="0.997989">
877
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.872207">
<title confidence="0.996018">Does Korean defeat phonotactic word segmentation?</title>
<author confidence="0.997811">Robert</author>
<affiliation confidence="0.9979035">Department of University of California, Los</affiliation>
<address confidence="0.9994555">3125 Campbell Hall, Box Los Angeles, CA 90095-1543, USA</address>
<email confidence="0.999789">r.daland@gmail.com</email>
<author confidence="0.948793">Kie</author>
<affiliation confidence="0.99774">Department of University of California, Los</affiliation>
<address confidence="0.999094">3125 Campbell Hall, Box Los Angeles, CA 90095-1543, USA</address>
<email confidence="0.999828">kie@ucla.edu</email>
<abstract confidence="0.995386571428571">Computational models of infant word segmentation have not been tested on a wide range of languages. This paper applies a phonotactic segmentation model to Korean. In contrast to the undersegmentation pattern previously found in English and Russian, the model exhibited more oversegmentation errors and more errors overall. Despite the high error rate, analysis suggested that lexical acquisition might not be problematic, provided that infants attend only to frequently segmented items.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R N Aslin</author>
<author>J Z Woodward</author>
<author>N P LaMendola</author>
<author>T G Bever</author>
</authors>
<title>Models of word segmentation in fluent maternal speech to infants. In</title>
<date>1996</date>
<pages>117--134</pages>
<publisher>LEA,</publisher>
<location>Mahwah, NJ:</location>
<contexts>
<context position="1377" citStr="Aslin et al. 1996" startWordPosition="200" endWordPosition="203">tion might not be problematic, provided that infants attend only to frequently segmented items. 1 Introduction The process by which infants learn to parse the acoustic signal into word-sized units—word segmentation—is an active area of research in developmental psychology (Polka and Sundara 2012; Saffran et al. 1996) and cognitive modeling (Daland and Pierrehumbert 2011 [DP11], Goldwater et al. 2009 [GGJ09]). Word segmentation is a classic bootstrapping problem: to learn words, infants must segment the input, because around 90% of the novel word types they hear are never uttered in isolation (Aslin et al. 1996; van de Weijer 1998). However, in order to segment infants must know some words, or generalizations about the properties of words. How can infants form generalizations about words before learning words themselves? 1.1 DiBS Two approaches in the literature might be termed lexical and phonotactic. Under the lexical approach, exemplified by GGJ09, infants are assumed to exploit the Zipfian distribution of language, identifying frequently recurring and mutually predictive sequences as words. In the phonotactic approach, infants are assumed to leverage universal and/or language-specific knowledge </context>
<context position="10372" citStr="Aslin et al. 1996" startWordPosition="1596" endWordPosition="1599">On the basis of the fact that the oversegmentation error rate in English and Russian was consistently below 10% (&lt;1 error/10 wds), DP11 conjectured that phonotactic segmenters will, cross-linguistically, avoid significant oversegmentation. The results in Table 2 provide a counterexample: oversegmentation is distinctly higher than in English and Russian. Indeed, Korean is a more challenging language for purely phonotactic segmentation. 3.1 Phonotactic cues to word segmentation Because phonological processes are more likely to apply word-internally, word-internal sequences are more predictable (Aslin et al. 1996; DP11; GGJ09; Saffran et al. 1996; van de Weijer 1998). The phonology of Korean is a potentially seg. 2 lenis lenis tense asp. h n m 9 liquid vowel diphth. seg. 1 stop non-stop lenis stop span 100 int* 27 span 100 span 100 int* 7 4-100 5-53 98-100 10-100 0-100 lenis int int non-stop tense int int aspirated int int h int int n 65 46, 57 38 45 35 32 61 span* 12 53 29-66 18-82 32-67 1-37 20-99 m 19 18, 18 14 14 14 int* 21 span int* 12 14-21 4-57 12-26 1-92 9 12 10, 12 9 11 int* int* 10 span 6 18 11-13 6-55 10-15 0-64 4-86 liquid 55 84, 88 71 53 42 90 53 int* 3 39 43-63 6-90 17-68 0-14 7-95 vowel</context>
</contexts>
<marker>Aslin, Woodward, LaMendola, Bever, 1996</marker>
<rawString>Aslin, R. N., Woodward, J. Z., LaMendola, N. P., &amp; Bever, T. G. (1996). Models of word segmentation in fluent maternal speech to infants. In J. L. Morgan &amp; K. Demuth (Eds.). Signal to syntax. Mahwah, NJ: LEA, pp. 117–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Blanchard</author>
<author>J Heinz</author>
<author>R Golinkoff</author>
</authors>
<title>Modeling the contribution of phonotactic cues to the problem of word segmentation.</title>
<date>2010</date>
<journal>Journal of Child Language</journal>
<volume>37</volume>
<issue>3</issue>
<pages>487--511</pages>
<contexts>
<context position="2234" citStr="Blanchard et al. 2010" startWordPosition="334" endWordPosition="337">es in the literature might be termed lexical and phonotactic. Under the lexical approach, exemplified by GGJ09, infants are assumed to exploit the Zipfian distribution of language, identifying frequently recurring and mutually predictive sequences as words. In the phonotactic approach, infants are assumed to leverage universal and/or language-specific knowledge about the phonological content of sequences to infer the optimal segmentation. The present study focuses on the phonotactic approach outlined in DP11, termed DiBS. For other examples of approaches that use phonotactics, see Fleck 2008, Blanchard et al. 2010. A (Di)phone-(B)ased (S)egmentation model consists of an inventory of segment-segment sequences, with an estimated probability that a word boundary falls between the two segments. For example, when [pd] occurs in English, the probability of an intervening word boundary is very high: Pr(# |[pd]) z 1. These probabilities are the parameters of the model to be learned. In the supervised setting (baseline model), these parameters may be estimated directly from data in which the word boundaries are labeled: Pr(# | pd) = Fr(# ^ pd) / (Fr(# ^ pd) + Fr(–# ^ pd)) where Fr(# ^ pd) is the number of [pd] </context>
</contexts>
<marker>Blanchard, Heinz, Golinkoff, 2010</marker>
<rawString>Blanchard, D., Heinz, J., &amp; Golinkoff, R. (2010). Modeling the contribution of phonotactic cues to the problem of word segmentation. Journal of Child Language 37(3), 487-511.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Daland</author>
<author>J B Pierrehumbert</author>
</authors>
<title>Learnability of diphone-based segmentation.</title>
<date>2011</date>
<journal>Cognitive Science</journal>
<volume>35</volume>
<issue>1</issue>
<pages>119--155</pages>
<contexts>
<context position="1132" citStr="Daland and Pierrehumbert 2011" startWordPosition="159" endWordPosition="162">egmentation model to Korean. In contrast to the undersegmentation pattern previously found in English and Russian, the model exhibited more oversegmentation errors and more errors overall. Despite the high error rate, analysis suggested that lexical acquisition might not be problematic, provided that infants attend only to frequently segmented items. 1 Introduction The process by which infants learn to parse the acoustic signal into word-sized units—word segmentation—is an active area of research in developmental psychology (Polka and Sundara 2012; Saffran et al. 1996) and cognitive modeling (Daland and Pierrehumbert 2011 [DP11], Goldwater et al. 2009 [GGJ09]). Word segmentation is a classic bootstrapping problem: to learn words, infants must segment the input, because around 90% of the novel word types they hear are never uttered in isolation (Aslin et al. 1996; van de Weijer 1998). However, in order to segment infants must know some words, or generalizations about the properties of words. How can infants form generalizations about words before learning words themselves? 1.1 DiBS Two approaches in the literature might be termed lexical and phonotactic. Under the lexical approach, exemplified by GGJ09, infants</context>
</contexts>
<marker>Daland, Pierrehumbert, 2011</marker>
<rawString>Daland, R. &amp; Pierrehumbert, J.B. (2011). Learnability of diphone-based segmentation. Cognitive Science 35(1), 119-155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Fleck</author>
</authors>
<title>Lexicalized phonotactic word segmentation.</title>
<date>2008</date>
<booktitle>Proceedings of ACL-08: HLT,</booktitle>
<pages>130--138</pages>
<contexts>
<context position="2211" citStr="Fleck 2008" startWordPosition="332" endWordPosition="333">Two approaches in the literature might be termed lexical and phonotactic. Under the lexical approach, exemplified by GGJ09, infants are assumed to exploit the Zipfian distribution of language, identifying frequently recurring and mutually predictive sequences as words. In the phonotactic approach, infants are assumed to leverage universal and/or language-specific knowledge about the phonological content of sequences to infer the optimal segmentation. The present study focuses on the phonotactic approach outlined in DP11, termed DiBS. For other examples of approaches that use phonotactics, see Fleck 2008, Blanchard et al. 2010. A (Di)phone-(B)ased (S)egmentation model consists of an inventory of segment-segment sequences, with an estimated probability that a word boundary falls between the two segments. For example, when [pd] occurs in English, the probability of an intervening word boundary is very high: Pr(# |[pd]) z 1. These probabilities are the parameters of the model to be learned. In the supervised setting (baseline model), these parameters may be estimated directly from data in which the word boundaries are labeled: Pr(# | pd) = Fr(# ^ pd) / (Fr(# ^ pd) + Fr(–# ^ pd)) where Fr(# ^ pd)</context>
</contexts>
<marker>Fleck, 2008</marker>
<rawString>Fleck, M. (2008). Lexicalized phonotactic word segmentation. Proceedings of ACL-08: HLT, 130-138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Goldwater</author>
<author>T L Griffiths</author>
<author>M Johnson</author>
</authors>
<title>A Bayesian framework for word segmentation: Exploring the effects of context.</title>
<date>2009</date>
<journal>Cognition</journal>
<volume>112</volume>
<issue>1</issue>
<pages>21--54</pages>
<contexts>
<context position="1162" citStr="Goldwater et al. 2009" startWordPosition="164" endWordPosition="167">st to the undersegmentation pattern previously found in English and Russian, the model exhibited more oversegmentation errors and more errors overall. Despite the high error rate, analysis suggested that lexical acquisition might not be problematic, provided that infants attend only to frequently segmented items. 1 Introduction The process by which infants learn to parse the acoustic signal into word-sized units—word segmentation—is an active area of research in developmental psychology (Polka and Sundara 2012; Saffran et al. 1996) and cognitive modeling (Daland and Pierrehumbert 2011 [DP11], Goldwater et al. 2009 [GGJ09]). Word segmentation is a classic bootstrapping problem: to learn words, infants must segment the input, because around 90% of the novel word types they hear are never uttered in isolation (Aslin et al. 1996; van de Weijer 1998). However, in order to segment infants must know some words, or generalizations about the properties of words. How can infants form generalizations about words before learning words themselves? 1.1 DiBS Two approaches in the literature might be termed lexical and phonotactic. Under the lexical approach, exemplified by GGJ09, infants are assumed to exploit the Zi</context>
</contexts>
<marker>Goldwater, Griffiths, Johnson, 2009</marker>
<rawString>Goldwater, S., Griffiths, T. L., &amp; Johnson, M. (2009). A Bayesian framework for word segmentation: Exploring the effects of context. Cognition 112(1), 21-54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Kim</author>
<author>G Lee</author>
<author>J-H Lee</author>
</authors>
<title>Morphemebased grapheme to phoneme conversion using phonetic patterns and morphophonemic connectivity information.</title>
<date>2002</date>
<journal>ACM Trans. Asian Lang. Inf. Process.</journal>
<volume>1</volume>
<issue>1</issue>
<pages>65--82</pages>
<contexts>
<context position="6176" citStr="Kim et al. (2002)" startWordPosition="925" endWordPosition="928">were trained and tested on these corpora; results are reported in Table 2. Finally, we inspected one ‘day’ worth of segmentations, and offer a qualitative assessment of errors. 2.1 Corpus and phonetic conversion The Korean Advanced Institute of Science and Technology Raw Corpus, available from the Semantic Web Research Center, semanticweb.kaist.ac.kr/home/index.php/KAIST_Corpus contains approximately 70,000,000 words from speeches, novels, newspapers, and more. The corpus was preprocessed to supply phrase breaks at punctuation marks and strip XML. The grapheme-to-phonetic conversion system of Kim et al. (2002) was generously shared by its creators. It includes morphosyntactic processing, phrase-break detection, and a dictionary of phonetic exceptions. It applies regular and lexicallyconditioned phonological rules, but not optional rules. Kim et al. reported per-grapheme accuracy of 99.7% in one corpus and 99.98% in another. An example of original text and the phonetic conversion is given below, with phonological changes in bold: phonetic: 2 13 # 4 5 6 IPA: k jA g k i t o1 jAt;uesA2 tl;&apos;&apos;uls*e 133 # t;ugagte4 mune tl;haxlt;aVak k*walil5 t901Aphett*a6 (the * diacritic indicates tense consonants) glos</context>
</contexts>
<marker>Kim, Lee, Lee, 2002</marker>
<rawString>Kim, B., Lee, G., &amp; Lee, J.-H. (2002). Morphemebased grapheme to phoneme conversion using phonetic patterns and morphophonemic connectivity information. ACM Trans. Asian Lang. Inf. Process. 1(1), 65-82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Polka</author>
<author>M Sundara</author>
</authors>
<title>Word segmentation in monolingual infants acquiring Canadian-English and Canadian-French: Native language, crosslanguage and cross-dialect comparisons.</title>
<date>2012</date>
<journal>Infancy</journal>
<volume>17</volume>
<issue>2</issue>
<pages>198--232</pages>
<contexts>
<context position="1056" citStr="Polka and Sundara 2012" startWordPosition="147" endWordPosition="150">sted on a wide range of languages. This paper applies a phonotactic segmentation model to Korean. In contrast to the undersegmentation pattern previously found in English and Russian, the model exhibited more oversegmentation errors and more errors overall. Despite the high error rate, analysis suggested that lexical acquisition might not be problematic, provided that infants attend only to frequently segmented items. 1 Introduction The process by which infants learn to parse the acoustic signal into word-sized units—word segmentation—is an active area of research in developmental psychology (Polka and Sundara 2012; Saffran et al. 1996) and cognitive modeling (Daland and Pierrehumbert 2011 [DP11], Goldwater et al. 2009 [GGJ09]). Word segmentation is a classic bootstrapping problem: to learn words, infants must segment the input, because around 90% of the novel word types they hear are never uttered in isolation (Aslin et al. 1996; van de Weijer 1998). However, in order to segment infants must know some words, or generalizations about the properties of words. How can infants form generalizations about words before learning words themselves? 1.1 DiBS Two approaches in the literature might be termed lexica</context>
</contexts>
<marker>Polka, Sundara, 2012</marker>
<rawString>Polka, L. &amp; Sundara, M. (2012). Word segmentation in monolingual infants acquiring Canadian-English and Canadian-French: Native language, crosslanguage and cross-dialect comparisons. Infancy 17(2), 198-232.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Saffran</author>
<author>R N Aslin</author>
<author>E L Newport</author>
</authors>
<title>Statistical learning by 8-month-old infants.</title>
<date>1996</date>
<journal>Science</journal>
<volume>275</volume>
<issue>5294</issue>
<pages>1926--1928</pages>
<contexts>
<context position="1078" citStr="Saffran et al. 1996" startWordPosition="151" endWordPosition="154">languages. This paper applies a phonotactic segmentation model to Korean. In contrast to the undersegmentation pattern previously found in English and Russian, the model exhibited more oversegmentation errors and more errors overall. Despite the high error rate, analysis suggested that lexical acquisition might not be problematic, provided that infants attend only to frequently segmented items. 1 Introduction The process by which infants learn to parse the acoustic signal into word-sized units—word segmentation—is an active area of research in developmental psychology (Polka and Sundara 2012; Saffran et al. 1996) and cognitive modeling (Daland and Pierrehumbert 2011 [DP11], Goldwater et al. 2009 [GGJ09]). Word segmentation is a classic bootstrapping problem: to learn words, infants must segment the input, because around 90% of the novel word types they hear are never uttered in isolation (Aslin et al. 1996; van de Weijer 1998). However, in order to segment infants must know some words, or generalizations about the properties of words. How can infants form generalizations about words before learning words themselves? 1.1 DiBS Two approaches in the literature might be termed lexical and phonotactic. Und</context>
<context position="10406" citStr="Saffran et al. 1996" startWordPosition="1602" endWordPosition="1605">e oversegmentation error rate in English and Russian was consistently below 10% (&lt;1 error/10 wds), DP11 conjectured that phonotactic segmenters will, cross-linguistically, avoid significant oversegmentation. The results in Table 2 provide a counterexample: oversegmentation is distinctly higher than in English and Russian. Indeed, Korean is a more challenging language for purely phonotactic segmentation. 3.1 Phonotactic cues to word segmentation Because phonological processes are more likely to apply word-internally, word-internal sequences are more predictable (Aslin et al. 1996; DP11; GGJ09; Saffran et al. 1996; van de Weijer 1998). The phonology of Korean is a potentially seg. 2 lenis lenis tense asp. h n m 9 liquid vowel diphth. seg. 1 stop non-stop lenis stop span 100 int* 27 span 100 span 100 int* 7 4-100 5-53 98-100 10-100 0-100 lenis int int non-stop tense int int aspirated int int h int int n 65 46, 57 38 45 35 32 61 span* 12 53 29-66 18-82 32-67 1-37 20-99 m 19 18, 18 14 14 14 int* 21 span int* 12 14-21 4-57 12-26 1-92 9 12 10, 12 9 11 int* int* 10 span 6 18 11-13 6-55 10-15 0-64 4-86 liquid 55 84, 88 71 53 42 90 53 int* 3 39 43-63 6-90 17-68 0-14 7-95 vowel 16 32 36 18 38 5 13 int int* 44 5</context>
</contexts>
<marker>Saffran, Aslin, Newport, 1996</marker>
<rawString>Saffran, J. R., Aslin, R. N., &amp; Newport, E. L. (1996). Statistical learning by 8-month-old infants. Science 275(5294), 1926-1928.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H-M Sohn</author>
</authors>
<title>The Korean Language. Cambridge:</title>
<date>1999</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="3880" citStr="Sohn 1999" startWordPosition="592" endWordPosition="593">-art lexical models (GGJ09), reflecting the high positional informativeness of diphones in English. We apply the baseline and phrasal models to Korean. 1.2 Linguistic properties of Korean Korean is unrelated to languages previously modeled (English, Dutch, French, Spanish, Ara873 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 873–877, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics bic, Greek, Russian), and it is an interesting test case for both phonotactic and lexical approaches. Korean syntax and morphology (Sohn 1999) present a particular challenge for unsupervised learning. Most noun phrases are marked with a limited set of case suffixes, and clauses generally end in a verb, inflected with suffixes ending in a limited set of sounds ([a,A,i,jo]). Thus, the phrase-final distribution may not reflect the overall word-final distribution—problematic for some phonotactic approaches. Similarly, the high frequency and positional predictability of affixes could lead a lexical model to treat them as words. A range of phonological processes apply in Korean, even across word boundaries (Sohn 1999), yielding extensive </context>
</contexts>
<marker>Sohn, 1999</marker>
<rawString>Sohn, H.-M. (1999). The Korean Language. Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J van de Weijer</author>
</authors>
<title>Language input for word discovery. MPI series in psycholinguistics</title>
<date>1998</date>
<marker>van de Weijer, 1998</marker>
<rawString>van de Weijer, J. (1998). Language input for word discovery. MPI series in psycholinguistics (No. 9).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>