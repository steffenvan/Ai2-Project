<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001826">
<title confidence="0.998805">
Handling Named Entities and Compound Verbs in
Phrase-Based Statistical Machine Translation
</title>
<author confidence="0.908159">
Santanu Pal*, Sudip Kumar Naskar†, Pavel Pecina†,
</author>
<affiliation confidence="0.915034">
Sivaji Bandyopadhyay* and Andy Way†
*Dept. of Comp. Sc. &amp; Engg.
Jadavpur University
</affiliation>
<email confidence="0.979651">
santanupersonal1@gmail.com, sivaji_cse_ju@yahoo.com
</email>
<affiliation confidence="0.959897">
†CNGL, School of Computing
Dublin City University
</affiliation>
<email confidence="0.990989">
{snaskar, ppecina, away}@computing.dcu.ie
</email>
<sectionHeader confidence="0.998591" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99954152">
Data preprocessing plays a crucial role in
phrase-based statistical machine transla-
tion (PB-SMT). In this paper, we show
how single-tokenization of two types of
multi-word expressions (MWE), namely
named entities (NE) and compound
verbs, as well as their prior alignment
can boost the performance of PB-SMT.
Single-tokenization of compound verbs
and named entities (NE) provides sig-
nificant gains over the baseline PB-SMT
system. Automatic alignment of NEs
substantially improves the overall MT
performance, and thereby the word
alignment quality indirectly. For estab-
lishing NE alignments, we transliterate
source NEs into the target language and
then compare them with the target NEs.
Target language NEs are first converted
into a canonical form before the com-
parison takes place. Our best system
achieves statistically significant im-
provements (4.59 BLEU points absolute,
52.5% relative improvement) on an Eng-
lish—Bangla translation task.
</bodyText>
<sectionHeader confidence="0.999632" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999858119047619">
Statistical machine translation (SMT) heavily
relies on good quality word alignment and
phrase alignment tables comprising translation
knowledge acquired from a bilingual corpus.
Multi-word expressions (MWE) are defined
as “idiosyncratic interpretations that cross word
boundaries (or spaces)” (Sag et al., 2002). Tradi-
tional approaches to word alignment following
IBM Models (Brown et al., 1993) do not work
well with multi-word expressions, especially
with NEs, due to their inability to handle many-
to-many alignments. Firstly, they only carry out
alignment between words and do not consider
the case of complex expressions, such as multi-
word NEs. Secondly, the IBM Models only al-
low at most one word in the source language to
correspond to a word in the target language
(Marcu, 2001, Koehn et al., 2003).
In another well-known word alignment ap-
proach, Hidden Markov Model (HMM: Vogel et
al., 1996), the alignment probabilities depend on
the alignment position of the previous word. It
does not explicitly consider many-to-many
alignment either.
We address this many-to-many alignment
problem indirectly. Our objective is to see how
to best handle the MWEs in SMT. In this work,
two types of MWEs, namely NEs and compound
verbs, are automatically identified on both sides
of the parallel corpus. Then, source and target
language NEs are aligned using a statistical
transliteration method. We rely on these auto-
matically aligned NEs and treat them as transla-
tion examples. Adding bilingual dictionaries,
which in effect are instances of atomic transla-
tion pairs, to the parallel corpus is a well-known
practice in domain adaptation in SMT (Eck et
al., 2004; Wu et al., 2008). We modify the paral-
lel corpus by converting the MWEs into single
tokens and adding the aligned NEs in the parallel
corpus in a bid to improve the word alignment,
and hence the phrase alignment quality. This
</bodyText>
<page confidence="0.994118">
46
</page>
<note confidence="0.8643415">
Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 46–54,
Beijing, August 2010
</note>
<bodyText confidence="0.999091875">
preprocessing results in improved MT quality in
terms of automatic MT evaluation metrics.
The remainder of the paper is organized as
follows. In section 2 we discuss related work.
The System is described in Section 3. Section 4
includes the results obtained, together with some
analysis. Section 5 concludes, and provides ave-
nues for further work.
</bodyText>
<sectionHeader confidence="0.999929" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999948757142857">
Moore (2003) presented an approach for si-
multaneous NE identification and translation. He
uses capitalization cues for identifying NEs on
the English side, and then he applies statistical
techniques to decide which portion of the target
language corresponds to the specified English
NE. Feng et al. (2004) proposed a Maximum
Entropy model based approach for English—
Chinese NE alignment which significantly out-
performs IBM Model4 and HMM. They consid-
ered 4 features: translation score, transliteration
score, source NE and target NE&apos;s co-occurrence
score, and the distortion score for distinguishing
identical NEs in the same sentence. Huang et al.
(2003) proposed a method for automatically ex-
tracting NE translingual equivalences between
Chinese and English based on multi-feature cost
minimization. The costs considered are translit-
eration cost, word-based translation cost, and NE
tagging cost.
Venkatapathy and Joshi (2006) reported a dis-
criminative approach of using the compositional-
ity information about verb-based multi-word
expressions to improve word alignment quality.
(Ren et al., 2009) presented log likelihood ratio-
based hierarchical reducing algorithm to auto-
matically extract bilingual MWEs, and investi-
gated the usefulness of these bilingual MWEs in
SMT by integrating bilingual MWEs into Moses
(Koehn et al., 2007) in three ways. They ob-
served the highest improvement when they used
an additional feature to represent whether or not
a bilingual phrase contains bilingual MWEs.
This approach was generalized in Carpuat and
Diab (2010). In their work, the binary feature
was replaced by a count feature representing the
number of MWEs in the source language phrase.
Intuitively, MWEs should be both aligned in
the parallel corpus and translated as a whole.
However, in the state-of-the-art PB-SMT, it
could well be the case that constituents of an
MWE are marked and aligned as parts of con-
secutive phrases, since PB-SMT (or any other
approaches to SMT) does not generally treat
MWEs as special tokens. Another problem SMT
suffers from is that verb phrases are often
wrongly translated, or even sometimes deleted in
the output in order to produce a target sentence
considered good by the language model. More-
over, the words inside verb phrases seldom show
the tendency of being aligned one-to-one; the
alignments of the words inside source and target
verb phrases are mostly many-to-many, particu-
larly so for the English—Bangla language pair.
These are the motivations behind considering
NEs and compound verbs for special treatment
in this work.
By converting the MWEs into single tokens,
we make sure that PB-SMT also treats them as a
whole. The objective of the present work is two-
fold; firstly to see how treatment of NEs and
compound verbs as a single unit affects the
overall MT quality, and secondly whether prior
automatic alignment of these single-tokenized
MWEs can bring about any further improvement
on top of that.
We carried out our experiments on an Eng-
lish—Bangla translation task, a relatively hard
task with Bangla being a morphologically richer
language.
</bodyText>
<sectionHeader confidence="0.999027" genericHeader="method">
3 System Description
</sectionHeader>
<subsectionHeader confidence="0.999584">
3.1 PB-SMT
</subsectionHeader>
<bodyText confidence="0.9993835">
Translation is modeled in SMT as a decision
process, in which the translation I
</bodyText>
<equation confidence="0.939237470588235">
e1 = e1 . . . ei . .
. eI of a source sentence J
f1 = f1 . . . fj . . . fJ is
chosen to maximize (1):
arg max (  |) arg max (  |) . ( )
P e f =
I J P f e P e
J I I (1)
1 1 1 1
I eI
, I eI
,
1 1
where (1  |1 )
P f J e I and ( 1 )
P e denote respec-
I
</equation>
<bodyText confidence="0.993775666666667">
tively the translation model and the target lan-
guage model (Brown et al., 1993). In log-linear
phrase-based SMT, the posterior probability
</bodyText>
<equation confidence="0.739566">
P e I f J is directly modeled as a log-linear
( 1  |1 )
</equation>
<bodyText confidence="0.998714333333333">
combination of features (Och and Ney, 2002),
that usually comprise M translational features,
and the language model, as in (2):
</bodyText>
<page confidence="0.943783">
47
</page>
<equation confidence="0.998630333333333">
M
log P(e I 1  |f1J) = ZAm hm(f1J,e1 ,sK)
m=1
+ALM P e (2)
log ( 1 )
I
</equation>
<bodyText confidence="0.813055">
where s1k = s1...sk denotes a segmentation of the
source and target sentences respectively into the
ˆ ˆ
sequences of phrases (eˆ1 ,..., ˆek) and (f1,..., fk)
such that (we set i0 = 0) (3):
</bodyText>
<equation confidence="0.993769666666667">
V1 ≤ k ≤ K, sk = (ik, bk, jk),
ˆ
ek e i k − 1 + 1 ... e i k
= ,
ˆ
fk = fbk ...fjk . (3)
ˆ
and each feature hm in (2) can be rewritten as in
(4):
K
((�.�&apos;&apos;
J I K _
hm (f , e1 , s1 ) — Z hm (fk, ek, sk
k=1
ˆ
</equation>
<bodyText confidence="0.8624035">
where hm is a feature that applies to a single
phrase-pair. It thus follows (5):
</bodyText>
<equation confidence="0.9993664">
K K
//
AmZ hm lfk , ek , sk) = Z h(fk , ek , sk) (5)
m=1 k=1 k=1
M
</equation>
<bodyText confidence="0.647355">
where h ˆ = A
</bodyText>
<equation confidence="0.976431666666667">
Z mh ˆ m .
m
=1
</equation>
<subsectionHeader confidence="0.999579">
3.2 Preprocessing of the Parallel Corpus
</subsectionHeader>
<bodyText confidence="0.999958864864865">
The initial English—Bangla parallel corpus is
cleaned and filtered using a semi-automatic
process. We employed two kinds of multi-word
information: compound verbs and NEs. Com-
pound verbs are first identified on both sides of
the parallel corpus. Chakrabarty et al. (2008)
analyzed and identified a category of V+V com-
plex predicates called lexical compound verbs
for Hindi. We adapted their strategy for identifi-
cation of compound verbs in Bangla. In addition
to V+V construction, we also consider N+V and
ADJ+V structures.
NEs are also identified on both sides of trans-
lation pairs. NEs in Bangla are much harder to
identify than in English (Ekbal and Bandyop-
adhyay, 2009). This can be attributed to the fact
that (i) there is no concept of capitalization in
Bangla; and (ii) Bangla common nouns are often
used as proper names. In Bangla, the problem is
compounded by the fact that suffixes (case
markers, plural markers, emphasizers, specifiers)
are also added to proper names, just like to any
other common nouns. As a consequence, the ac-
curacy of Bangla NE recognizers (NER) is much
poorer compared to that for English. Once the
compound verbs and the NEs are identified on
both sides of the parallel corpus, they are con-
verted into and replaced by single tokens. When
converting these MWEs into single tokens, we
replace the spaces with underscores (‘_’). Since
there are already some hyphenated words in the
corpus, we do not use hyphenation for this pur-
pose; besides, the use of a special word separator
(underscore in our case) facilitates the job of
deciding which single-token (target language)
MWEs to detokenize into words comprising
them, before evaluation.
</bodyText>
<subsectionHeader confidence="0.9976655">
3.3 Transliteration Using Modified Joint
Source-Channel Model
</subsectionHeader>
<bodyText confidence="0.999986785714286">
Li et al. (2004) proposed a generative framework
allowing direct orthographical mapping of trans-
literation units through a joint source-channel
model, which is also called n-gram translitera-
tion model. They modeled the segmentation of
names into transliteration units (TU) and their
alignment preferences using maximum likeli-
hood via EM algorithm (Dempster et al., 1977).
Unlike the noisy-channel model, the joint
source-channel model tries to capture how
source and target names can be generated simul-
taneously by means of contextual n-grams of the
transliteration units. For K aligned TUs, they
define the bigram model as in (6):
</bodyText>
<equation confidence="0.933864857142857">
)
P(&lt;e,b&gt;1,&lt;e,b&gt;2 ... &lt;e,b&gt;K )
K
∏P(&lt;e,b&gt;k|&lt;e,b&gt;
k=1
P E B = P e e e K b b b K
( , ) ( 1 , 2 . . . , 1 , 2 . . .
</equation>
<bodyText confidence="0.999994583333333">
where E refers to the English name and B the
transliteration in Bengali, while ei and bi refer to
the ith English and Bangla segment (TU) respec-
tively.
Ekbal et al. (2006) presented a modification to
the joint source-channel model to incorporate
different contextual information into the model
for Indian languages. They used regular expres-
sions and language-specific heuristics based on
consonant and vowel patterns to segment names
into TUs. Their modified joint source-channel
model, for which they obtained improvement
</bodyText>
<equation confidence="0.999694666666667">
) (4)
M
Z
k-1
1
) (6)
</equation>
<page confidence="0.983891">
48
</page>
<bodyText confidence="0.99922875">
over the original joint source-channel model,
essentially considers a trigram model for the
source language and a bigram model for the tar-
get, as in (7).
</bodyText>
<equation confidence="0.99872025">
K
P E B
( , )=∏ P(&lt; e, b &gt;k |&lt; e, b &gt;k-1 , ek+1) (7)
k=1
</equation>
<bodyText confidence="0.999690666666667">
Ekbal et al. (2006) reported a word agreement
ratio of 67.9% on an English—Bangla translit-
eration task. In the present work, we use the
modified joint source-channel model of (Ekbal
et al., 2006) to translate names for establishing
NE alignments in the parallel corpus.
</bodyText>
<subsectionHeader confidence="0.838468">
3.4 Automatic Alignment of NEs through
Transliteration
</subsectionHeader>
<bodyText confidence="0.999997714285714">
We first create an NE parallel corpus by extract-
ing the source and target (single token) NEs
from the NE-tagged parallel translations in
which both sides contain at least one NE. For
example, we extract the NE translation pairs
given in (9) from the sentence pair shown in (8),
where the NEs are shown as italicized.
</bodyText>
<listItem confidence="0.952690142857143">
(8a) Kirti_Mandir , where Mahatma_Gandhi
was born , today houses a photo exhibition on
the life and times of the Mahatma , a library, a
prayer hall and other memorabilia .
(8b) িকতর্ী_মিnর , েযখােন মহাtা_গাnী জেnিছেলন ,
(9a) Kirti_Mandir Mahatma_Gandhi Mahatma
(9b) িকতর্ী_মিnর মহাtা_গাnী মহাtার
</listItem>
<bodyText confidence="0.999895647058824">
Then we try to align the source and target NEs
extracted from a parallel sentence, as illustrated
in (9). If both sides contain only one NE then the
alignment is trivial, and we add such NE pairs to
seed another parallel NE corpus that contains
examples having only one token in both side.
Otherwise, we establish alignments between the
source and target NEs using transliteration. We
use the joint source-channel model of translitera-
tion (Ekbal et al., 2006) for this purpose.
If both the source and target side contains n
number of NEs, and the alignments of n-1 NEs
can be established through transliteration or by
means of already existing alignments, then the
nth alignment is trivial. However, due to the rela-
tive performance difference of the NERs for the
source and target language, the number of NEs
identified on the source and target sides is al-
most always unequal (see Section 4). Accord-
ingly, we always use transliteration to establish
alignments even when it is assumed to be trivial.
Similarly, for multi-word NEs, intra-NE word
alignments are established through translitera-
tion or by means of already existing alignments.
For a multi-word source NE, if we can align all
the words inside the NE with words inside a tar-
get NE, then we assume they are translations of
each other. Due to the relatively poor perform-
ance of the Bangla NER, we also store the im-
mediate left and right neighbouring words for
every NE in Bangla, just in case the left or the
right word is a valid part of the NE but is not
properly tagged by the NER.
As mentioned earlier, since the source side
NER is much more reliable than the target side
NER, we transliterate the English NEs, and try
to align them with the Bangla NEs. For aligning
(capitalized) English words to Bangla words, we
take the 5 best transliterations produced by the
transliteration system for an English word, and
compare them against the Bangla words. Bangla
NEs often differ in their choice of matras (vowel
modifiers). Thus we first normalize the Bangla
words, both in the target NEs and the transliter-
ated ones, to a canonical form by dropping the
matras, and then compare the results. In effect,
therefore, we just compare the consonant se-
quences of every transliteration candidate with
that of a target side Bangla word; if they match,
then we align the English word with the Bangla
word.
</bodyText>
<equation confidence="0.985082">
িনরজ (ন + ি◌+ র + জ) -- নীরাজ (ন + ◌ী + র + ◌া + জ)
(10)
</equation>
<bodyText confidence="0.996097307692308">
The example in (10) illustrates the procedure.
Assume, we are trying to align “Niraj” with
“নীরাজ”. The transliteration system produces
“িনরজ” from the English word “Niraj” and we
compare “িনরজ” with “নীরাজ”. Since the conso-
nant sequences match in both words, “িনরজ” is
considered a spelling variation of “নীরাজ”, and
the English word “Niraj” is aligned to the
Bangla word “নীরাজ”.
In this way, we achieve word-level align-
ments, as well as NE-level alignments. (11)
shows the alignments established from (8). The
word-level alignments help to establish new
</bodyText>
<equation confidence="0.67232925">
বতর্মােন েসখােন মহাtার জীবন o েসi সমেয়র
ঘটনাসমূেহর eকিট িচmpদশর্নশালা , eকিট লাiেbরী o
eকিট pাথর্না ঘর eবং aন1/2ান1/2 sৃিতিবজিড়ত িজিনসপm
আেছ ।
</equation>
<page confidence="0.976218">
49
</page>
<bodyText confidence="0.993254666666667">
word / NE alignments. Word and NE alignments
obtained in this way are added to the parallel
corpus as additional training data.
</bodyText>
<listItem confidence="0.998855428571429">
(11a) Kirti-Mandir ― িকতর্ী-মিnর
(11b) Kirti ― িকতর্ী
(11c) Mandir ― মিnর
(11d) Mahatma-Gandhi ― মহাtা-গাnী
(11e) Mahatma ― মহাtা
(11f) Gandhi ― গাnী
(11g) Mahatma ― মহাtার
</listItem>
<subsectionHeader confidence="0.956131">
3.5 Tools and Resources Used
</subsectionHeader>
<bodyText confidence="0.949683457142857">
A sentence-aligned English—Bangla parallel
corpus containing 14,187 parallel sentences from
a travel and tourism domain was used in the pre-
sent work. The corpus was obtained from the
consortium-mode project “Development of Eng-
lish to Indian Languages Machine Translation
(EILMT) System” 1.
The Stanford Parser2 and the CRF chunker3
were used for identifying compound verbs in the
source side of the parallel corpus. The Stanford
NER4 was used to identify NEs on the source
side (English) of the parallel corpus.
The sentences on the target side (Bangla)
were POS-tagged by using the tools obtained
from the consortium mode project “Develop-
ment of Indian Languages to Indian Languages
Machine Translation (ILILMT) System”. NEs in
Bangla are identified using the NER system of
Ekbal and Bandyopadhyay (2008). We use the
Stanford Parser, Stanford NER and the NER for
Bangla along with the default model files pro-
vided, i.e., with no additional training.
The effectiveness of the MWE-aligned paral-
lel corpus developed in the work is demonstrated
by using the standard log-linear PB-SMT model
as our baseline system: GIZA++ implementation
of IBM word alignment model 4, phrase-
extraction heuristics described in (Koehn et al.,
2003), minimum-error-rate training (Och, 2003)
on a held-out development set, target language
model with Kneser-Ney smoothing (Kneser and
1 The EILMT and ILILMT projects are funded by the De-
partment of Information Technology (DIT), Ministry of
Communications and Information Technology (MCIT),
Government of India.
</bodyText>
<footnote confidence="0.971038666666666">
2 http://nlp.stanford.edu/software/lex-parser.shtml
3 http://crfchunker.sourceforge.net/
4 http://nlp.stanford.edu/software/CRF-NER.shtml
</footnote>
<bodyText confidence="0.986059">
Ney, 1995) trained with SRILM (Stolcke, 2002),
and Moses decoder (Koehn et al., 2007).
</bodyText>
<sectionHeader confidence="0.997168" genericHeader="evaluation">
4 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999430705882353">
We randomly extracted 500 sentences each for
the development set and testset from the initial
parallel corpus, and treated the rest as the train-
ing corpus. After filtering on maximum allow-
able sentence length of 100 and sentence length
ratio of 1:2 (either way), the training corpus con-
tained 13,176 sentences. In addition to the target
side of the parallel corpus, a monolingual Bangla
corpus containing 293,207 words from the tour-
ism domain was used for the target language
model. We experimented with different n-gram
settings for the language model and the maxi-
mum phrase length, and found that a 4-gram
language model and a maximum phrase length
of 4 produced the optimum baseline result. We
therefore carried out the rest of the experiments
using these settings.
</bodyText>
<table confidence="0.974922375">
In training set English Bangla
T U T U
Compound verbs 4,874 2,289 14,174 7,154
Single-word NEs 4,720 1,101 5,068 1,175
2-word NEs 4,330 2,961 4,147 3,417
&gt;2 word NEs 1,555 1,271 1,390 1,278
Total NEs 10,605 5,333 10,605 5,870
Total NE words 22,931 8,273 17,107 9,106
</table>
<tableCaption confidence="0.808488">
Table 1. MWE statistics (T - Total occur-
rence, U – Unique).
</tableCaption>
<bodyText confidence="0.9998718125">
Of the 13,676 sentences in the training and
development set, 13,675 sentences had at least
one NE on both sides, only 22 sentences had
equal number of NEs on both sides, and 13,654
sentences had an unequal number of NEs. Simi-
larly, for the testset, all the sentences had at least
one NE on both sides, and none had an equal
number of NEs on both sides. It gives an indica-
tion of the relative performance differences of
the NERs. 6.6% and 6.58% of the source tokens
belong to NEs in the training and testset respec-
tively. These statistics reveal the high degree of
NEs in the tourism domain data that demands
special treatment. Of the 225 unique NEs ap-
pearing on the source side of the testset, only 65
NEs are found in the training set.
</bodyText>
<page confidence="0.969217">
50
</page>
<table confidence="0.999938214285714">
Experiments Exp BLEU METEOR NIST WER PER TER
Baseline 1 8.74 20.39 3.98 77.89 62.95 74.60
NEs as Single NEs of any length as Single 2 9.15 18.19 3.88 77.81 63.85 74.61
Tokens Token (New-MWNEaST)
(NEaST)
NEs of length &gt;2 as 3 8.76 18.78 3.86 78.31 63.78 75.15
Single Tokens (MWNE-
aST)
2-Word NEs as Single To- 4 9.13 17.28 3.92 78.12 63.15 74.85
kens (2WNEaST)
Compound Verbs as Single Tokens 5 9.56 15.35 3.96 77.60 63.06 74.46
(CVaST) †
NE Alignment Alignment of NEs of any 6 13.33 24.06 4.44 74.79 60.10 71.25
(NEA) length (New-MWNEA) †
Alignment of NEs of length 7 10.35 20.93 4.11 76.49 62.20 73.05
upto 2 (New-2WNEA) †
Alignment of NEs of length 8 12.39 23.13 4.36 75.51 60.58 72.06
&gt;2 (MWNEA) †
Alignment of NEs of length 9 11.2 23.14 4.26 76.13 60.72 72.57
2 (2WNEA) †
CVaST New-MWNEaST 10 8.62 16.64 3.73 78.41 65.21 75.47
+NEaST
MWNEaST 11 8.74 14.68 3.84 78.40 64.05 75.40
2WNEaST 12 8.85 16.60 3.86 78.17 63.90 75.33
CVaST +NEA New-MWNEA† 13 11.22 21.02 4.16 75.99 61.96 73.06
New-2WNEA† 14 10.07 17.67 3.98 77.08 63.35 74.18
MWNEA† 15 10.34 16.34 4.07 77.12 62.38 73.88
2WNEA† 16 10.51 18.92 4.08 76.77 62.28 73.56
</table>
<tableCaption confidence="0.937752">
Table 2. Evaluation results for different experimental setups (The ‘†’ marked systems produce
statistically significant improvements on BLEU over the baseline system).
</tableCaption>
<bodyText confidence="0.999432">
Table 1 shows the MWE statistics of the
parallel corpus as identified by the NERs. The
average NE length in the training corpus is
2.16 for English and 1.61 for Bangla. As can
be seen from Table 1, 44.5% and 47.8% of the
NEs are single-word NEs in English and
Bangla respectively, which suggests that prior
alignment of the single-word NEs, in addition
to multi-word NE alignment, should also be
beneficial to word and phrase alignment.
Of all the NEs in the training and develop-
ment sets, the transliteration-based alignment
process was able to establish alignments of
4,711 single-word NEs, 4,669 two-word NEs
and 1,745 NEs having length more than two.
It is to be noted that, some of the single-word
NE alignments, as well as two-word NE
alignments, result from multi-word NE align-
ment.
We analyzed the output of the NE align-
ment module and observed that longer NEs
were aligned better than the shorter ones,
which is quite intuitive, as longer NEs have
more tokens to be considered for intra-NE
alignment. Since the NE alignment process is
based on transliteration, the alignment method
does not work where NEs involve translation
or acronyms. We also observed that English
multi-word NEs are sometimes fused together
into single-word NEs.
We performed three sets of experiments:
treating compound verbs as single tokens,
treating NEs as single tokens, and the combi-
nation thereof. Again for NEs, we carried out
three types of preprocessing: single-
tokenization of (i) two-word NEs, (ii) more
than two-word NEs, and (iii) NEs of any
length. We make distinctions among these
three to see their relative effects. The devel-
opment and test sets, as well as the target lan-
guage monolingual corpus (for language mod-
eling), are also subjected to the same preproc-
essing of single-tokenizing the MWEs. For
NE alignment, we performed experiments us-
ing 4 different settings: alignment of (i) NEs
of length up to two, (ii) NEs of length two,
</bodyText>
<page confidence="0.996565">
51
</page>
<bodyText confidence="0.999930634615385">
(iii) NEs of length greater than two, and (iv)
NEs of any length. Before evaluation, the sin-
gle-token (target language) underscored
MWEs are expanded back to words compris-
ing the MWEs.
Since we did not have the gold-standard
word alignment, we could not perform intrin-
sic evaluation of the word alignment. Instead
we carry out extrinsic evaluation on the MT
quality using the well known automatic MT
evaluation metrics: BLEU (Papineni et al.,
2002), METEOR (Banerjee and Lavie, 2005),
NIST (Doddington, 2002), WER, PER and
TER (Snover et al., 2006). As can be seen
from the evaluation results reported in Table
2, baseline Moses without any preprocessing
of the dataset produces a BLEU score of 8.74.
The low score can be attributed to the fact that
Bangla, a morphologically rich language, is
hard to translate into. Moreover, Bangla being
a relatively free phrase order language (Ekbal
and Bandyopadhyay, 2009) ideally requires
multiple set of references for proper evalua-
tion. Hence using a single reference set does
not justify evaluating translations in Bangla.
Also the training set was not sufficiently large
enough for SMT. Treating only longer than 2-
word NEs as single tokens does not help im-
prove the overall performance much, while
single tokenization of two-word NEs as single
tokens produces some improvements (.39
BLEU points absolute, 4.5% relative). Con-
sidering compound verbs as single tokens
(CVaST) produces a .82 BLEU point im-
provement (9.4% relative) over the baseline.
Strangely, when both compound verbs and
NEs together are counted as single tokens,
there is hardly any improvement. By contrast,
automatic NE alignment (NEA) gives a huge
impetus to system performance, the best of
them (4.59 BLEU points absolute, 52.5% rela-
tive improvement) being the alignment of NEs
of any length that produces the best scores
across all metrics. When NEA is combined
with CVaST, the improvements are substan-
tial, but it can not beat the individual im-
provement on NEA. The (†) marked systems
produce statistically significant improvements
as measured by bootstrap resampling method
(Koehn, 2004) on BLEU over the baseline
system. Metric-wise individual best scores are
shown in bold in Table 2.
</bodyText>
<sectionHeader confidence="0.987863" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999989212765957">
In this paper, we have successfully shown
how the simple yet effective preprocessing of
treating two types of MWEs, namely NEs and
compound verbs, as single-tokens, in conjunc-
tion with prior NE alignment can boost the
performance of PB-SMT system on an Eng-
lish—Bangla translation task. Treating com-
pound verbs as single-tokens provides signifi-
cant gains over the baseline PB-SMT system.
Amongst the MWEs, NEs perhaps play the
most important role in MT, as we have clearly
demonstrated through experiments that auto-
matic alignment of NEs by means of translit-
eration improves the overall MT performance
substantially across all automatic MT evalua-
tion metrics. Our best system yields 4.59
BLEU points improvement over the baseline,
a 52.5% relative increase. We compared a
subset of the output of our best system with
that of the baseline system, and the output of
our best system almost always looks better in
terms of either lexical choice or word order-
ing. The fact that only 28.5% of the testset
NEs appear in the training set, yet prior auto-
matic alignment of the NEs brings about so
much improvement in terms of MT quality,
suggests that it not only improves the NE
alignment quality in the phrase table, but word
alignment and phrase alignment quality must
have also been improved significantly. At the
same time, single-tokenization of MWEs
makes the dataset sparser, but yet improves
the quality of MT output to some extent. Data-
driven approaches to MT, specifically for
scarce-resource language pairs for which very
little parallel texts are available, should benefit
from these preprocessing methods. Data
sparseness is perhaps the reason why single-
tokenization of NEs and compound verbs,
both individually and in collaboration, did not
add significantly to the scores. However, a
significantly large parallel corpus can take
care of the data sparseness problem introduced
by the single-tokenization of MWEs.
The present work offers several avenues for
further work. In future, we will investigate
how these automatically aligned NEs can be
</bodyText>
<page confidence="0.994532">
52
</page>
<bodyText confidence="0.999815642857143">
used as anchor words to directly influence the
word alignment process. We will look into
whether similar kinds of improvements can be
achieved for larger datasets, corpora from dif-
ferent domains and for other language pairs.
We will also investigate how NE alignment
quality can be improved, especially where
NEs involve translation and acronyms. We
will also try to perform morphological analy-
sis or stemming on the Bangla side before NE
alignment. We will also explore whether dis-
criminative approaches to word alignment can
be employed to improve the precision of the
NE alignment.
</bodyText>
<sectionHeader confidence="0.998378" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999556857142857">
This research is partially supported by the Sci-
ence Foundation Ireland (Grant 07/CE/I1142)
as part of the Centre for Next Generation Lo-
calisation (www.cngl.ie) at Dublin City Uni-
versity, and EU projects PANACEA (Grant
7FP-ITC-248064) and META-NET (Grant
FP7-ICT-249119).
</bodyText>
<sectionHeader confidence="0.998874" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999685064102564">
Banerjee, Satanjeev, and Alon Lavie. 2005. An
Automatic Metric for MT Evaluation with Im-
proved Correlation with Human Judgments. In
proceedings of the ACL-2005 Workshop on In-
trinsic and Extrinsic Evaluation Measures for
MT and/or Summarization, pp. 65-72. Ann Ar-
bor, Michigan., pp. 65-72.
Brown, Peter F., Stephen A. Della Pietra, Vincent
J. Della Pietra, and Robert L. Mercer. 1993. The
mathematics of statistical machine translation:
parameter estimation. Computational Linguis-
tics, 19(2):263-311.
Carpuat, Marine, and Mona Diab. 2010. Task-
based Evaluation of Multiword Expressions: a
Pilot Study in Statistical Machine Translation.
In Proceedings of Human Language Technology
conference and the North American Chapter of
the Association for Computational Linguistics
conference (HLT-NAACL 2010), Los Angeles,
CA, pp. 242-245.
Chakrabarti, Debasri, Hemang Mandalia, Ritwik
Priya, Vaijayanthi Sarma, and Pushpak Bhat-
tacharyya. 2008. Hindi compound verbs and
their automatic extraction. In Proceedings
of the 22nd International Conference on Com-
putational Linguistics (Coling 2008), Posters
and demonstrations, Manchester, UK, pp. 27-
30.
Dempster, A.P., N.M. Laird, and D.B. Rubin.
1977). Maximum Likelihood from Incomplete
Data via the EM Algorithm. Journal of the
Royal Statistical Society, Series B (Methodo-
logical) 39 (1): 1–38.
Doddington, George. 2002. Automatic evaluation
of machine translation quality using n-gram
cooccurrence statistics. In Proceedings of the
Second International Conference on Human
Language Technology Research (HLT-2002),
San Diego, CA, pp. 128-132.
Eck, Matthias, Stephan Vogel, and Alex Waibel.
2004. Improving statistical machine translation
in the medical domain using the Unified Medi-
cal Language System. In Proceedings of the
20th International Conference on Computational
Linguistics (COLING 2004), Ge-
neva, Switzerland, pp. 792-798.
Ekbal, Asif, and Sivaji Bandyopadhyay. 2009.
Voted NER system using appropriate unlabeled
data. In proceedings of the ACL-IJCNLP-2009
Named Entities Workshop (NEWS 2009),
Suntec, Singapore, pp. 202-210.
Ekbal, Asif, and Sivaji Bandyopadhyay. 2008.
Maximum Entropy Approach for Named Entity
Recognition in Indian Languages. International
Journal for Computer Processing of Lan-
guages (IJCPOL), Vol. 21(3):205-237.
Feng, Donghui, Yajuan Lv, and Ming Zhou. 2004.
A new approach for English-Chinese named en-
tity alignment. In Proceedings of the 2004 Con-
ference on Empirical Methods in Natural Lan-
guage Processing (EMNLP-2004), Barcelona,
Spain, pp. 372-379.
Huang, Fei, Stephan Vogel, and Alex Waibel.
2003. Automatic extraction of named entity
translingual equivalence based on multi-feature
cost minimization. In Proceedings of the ACL-
2003 Workshop on Multilingual and Mixed-
language Named Entity Recognition, 2003,
Sapporo, Japan, pp. 9-16.
Kneser, Reinhard, and Hermann Ney. 1995. Im-
proved backing-off for m-gram language model-
ing. In Proceedings of the IEEE Internation
Conference on Acoustics, Speech, and Signal
Processing (ICASSP), vol. 1, pp. 181-184. De-
troit, MI.
Koehn, Philipp, Franz Josef Och, and Daniel
Marcu. 2003. Statistical phrase-based transla-
tion. In Proceedings of HLT-NAACL 2003:
</reference>
<page confidence="0.987337">
53
</page>
<reference confidence="0.998328595238095">
conference combining Human Language Tech-
nology conference series and the North Ameri-
can Chapter of the Association for Computa-
tional Linguistics conference series, Edmonton,
Canada, pp. 48-54.
Koehn, Philipp, Hieu Hoang, Alexandra Birch,
Chris Callison-Burch, Marcello Federico, Ni-
cola Bertoldi, Brooke Cowan, Wade Shen,
Christine Moran, Richard Zens, Chris Dyer,
Ondřej Bojar, Alexandra Constantin, and Evan
Herbst. 2007. Moses: open source toolkit for
statistical machine translation. In Proceedings of
the 45th Annual meeting of the Association for
Computational Linguistics (ACL 2007): Pro-
ceedings of demo and poster sessions, Prague,
Czech Republic, pp. 177-180.
Koehn, Philipp. 2004. Statistical significance tests
for machine translation evaluation. In EMNLP-
2004: Proceedings of the 2004 Conference on
Empirical Methods in Natural Language Proc-
essing, 25-26 July 2004, Barcelona, Spain, pp.
388-395.
Marcu, Daniel. 2001. Towards a Unified Approach
to Memory- and Statistical-Based Machine
Translation. In Proceedings of the 39th Annual
Meeting of the Association for Computational
Linguistics (ACL 2001), Toulouse, France, pp.
386-393.
Moore, Robert C. 2003. Learning translations of
named-entity phrases from parallel corpora. In
Proceedings of 10th Conference of the Euro-
pean Chapter of the Association for Computa-
tional Linguistics (EACL 2003), Budapest,
Hungary; pp. 259-266.
Och, Franz J. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of
the 41st Annual Meeting of the Association for
Computational Linguistics (ACL-2003), Sap-
poro, Japan, pp. 160-167.
Papineni, Kishore, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. BLEU: a method for
automatic evaluation of machine translation. In
Proceedings of the 40th Annual Meeting of the
Association for Computational Linguistics
(ACL-2002), Philadelphia, PA, pp. 311-318.
Ren, Zhixiang, Yajuan Lü, Jie Cao, Qun Liu, and
Yun Huang. 2009. Improving statistical ma-
chine translation using domain bilingual multi-
word expressions. In Proceedings of the 2009
Workshop on Multiword Expressions, ACL-
IJCNLP 2009, Suntec, Singapore, pp. 47-54.
Sag, Ivan A., Timothy Baldwin, Francis Bond,
Ann Copestake and Dan Flickinger. 2002. Mul-
tiword expressions: A pain in the neck for NLP.
In Proceedings of the 3rd International Confer-
ence on Intelligent Text Processing and Compu-
tational Linguistics (CICLing-2002), Mexico
City, Mexico, pp. 1-15.
Snover, Matthew, Bonnie Dorr, Richard Schwartz,
Linnea Micciulla, and John Makhoul. 2006. A
study of translation edit rate with targeted hu-
man annotation. In Proceedings of the 7th Con-
ference of the Association for Machine Transla-
tion in the Americas (AMTA 2006), Cambridge,
MA, pp. 223-231.
Vogel, Stephan, Hermann Ney, and Christoph
Tillmann. 1996. HMM-based word alignment in
statistical translation. In Proceedings of the 16th
International Conference on Computational
Linguistics (COLING 1996), Copenhagen, pp.
836-841.
Venkatapathy, Sriram, and Aravind K. Joshi. 2006.
Using information about multi-word expres-
sions for the word-alignment task. In Proceed-
ings of Coling-ACL 2006: Workshop on Multi-
word Expressions: Identifying and Exploiting
Underlying Properties, Sydney, pp. 20-27.
Wu, Hua Haifeng Wang, and Chengqing Zong.
2008. Domain adaptation for statistical machine
translation with domain dictionary and mono-
lingual corpora. In Proceedings of the 22nd In-
ternational Conference on Computational Lin-
guistics (COLING 2008), Manchester, UK, pp.
993-1000.
</reference>
<page confidence="0.99902">
54
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.469133">
<title confidence="0.9970095">Handling Named Entities and Compound Verbs Phrase-Based Statistical Machine Translation</title>
<author confidence="0.983223">Sudip Kumar Pavel</author>
<affiliation confidence="0.824152666666667">and of Comp. Sc. &amp; Jadavpur University</affiliation>
<email confidence="0.912999">santanupersonal1@gmail.com,sivaji_cse_ju@yahoo.com</email>
<affiliation confidence="0.997016">School of Computing Dublin City University</affiliation>
<email confidence="0.895251">snaskar@computing.dcu.ie</email>
<email confidence="0.895251">ppecina@computing.dcu.ie</email>
<email confidence="0.895251">away@computing.dcu.ie</email>
<abstract confidence="0.999072384615385">Data preprocessing plays a crucial role in phrase-based statistical machine translation (PB-SMT). In this paper, we show how single-tokenization of two types of multi-word expressions (MWE), namely named entities (NE) and compound verbs, as well as their prior alignment can boost the performance of PB-SMT. Single-tokenization of compound verbs and named entities (NE) provides significant gains over the baseline PB-SMT system. Automatic alignment of NEs substantially improves the overall MT performance, and thereby the word alignment quality indirectly. For establishing NE alignments, we transliterate source NEs into the target language and then compare them with the target NEs. Target language NEs are first converted into a canonical form before the comparison takes place. Our best system achieves statistically significant improvements (4.59 BLEU points absolute, 52.5% relative improvement) on an English—Bangla translation task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Alon Lavie</author>
</authors>
<title>An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments.</title>
<date>2005</date>
<booktitle>In proceedings of the ACL-2005 Workshop on Intrinsic and Extrinsic Evaluation Measures for MT and/or Summarization,</booktitle>
<pages>65--72</pages>
<location>Ann Arbor, Michigan.,</location>
<contexts>
<context position="23116" citStr="Banerjee and Lavie, 2005" startWordPosition="3889" endWordPosition="3892">. For NE alignment, we performed experiments using 4 different settings: alignment of (i) NEs of length up to two, (ii) NEs of length two, 51 (iii) NEs of length greater than two, and (iv) NEs of any length. Before evaluation, the single-token (target language) underscored MWEs are expanded back to words comprising the MWEs. Since we did not have the gold-standard word alignment, we could not perform intrinsic evaluation of the word alignment. Instead we carry out extrinsic evaluation on the MT quality using the well known automatic MT evaluation metrics: BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), NIST (Doddington, 2002), WER, PER and TER (Snover et al., 2006). As can be seen from the evaluation results reported in Table 2, baseline Moses without any preprocessing of the dataset produces a BLEU score of 8.74. The low score can be attributed to the fact that Bangla, a morphologically rich language, is hard to translate into. Moreover, Bangla being a relatively free phrase order language (Ekbal and Bandyopadhyay, 2009) ideally requires multiple set of references for proper evaluation. Hence using a single reference set does not justify evaluating translations in Bangla. Also the trainin</context>
</contexts>
<marker>Banerjee, Lavie, 2005</marker>
<rawString>Banerjee, Satanjeev, and Alon Lavie. 2005. An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments. In proceedings of the ACL-2005 Workshop on Intrinsic and Extrinsic Evaluation Measures for MT and/or Summarization, pp. 65-72. Ann Arbor, Michigan., pp. 65-72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--2</pages>
<contexts>
<context position="1732" citStr="Brown et al., 1993" startWordPosition="234" endWordPosition="237">anonical form before the comparison takes place. Our best system achieves statistically significant improvements (4.59 BLEU points absolute, 52.5% relative improvement) on an English—Bangla translation task. 1 Introduction Statistical machine translation (SMT) heavily relies on good quality word alignment and phrase alignment tables comprising translation knowledge acquired from a bilingual corpus. Multi-word expressions (MWE) are defined as “idiosyncratic interpretations that cross word boundaries (or spaces)” (Sag et al., 2002). Traditional approaches to word alignment following IBM Models (Brown et al., 1993) do not work well with multi-word expressions, especially with NEs, due to their inability to handle manyto-many alignments. Firstly, they only carry out alignment between words and do not consider the case of complex expressions, such as multiword NEs. Secondly, the IBM Models only allow at most one word in the source language to correspond to a word in the target language (Marcu, 2001, Koehn et al., 2003). In another well-known word alignment approach, Hidden Markov Model (HMM: Vogel et al., 1996), the alignment probabilities depend on the alignment position of the previous word. It does not</context>
<context position="7230" citStr="Brown et al., 1993" startWordPosition="1161" endWordPosition="1164"> further improvement on top of that. We carried out our experiments on an English—Bangla translation task, a relatively hard task with Bangla being a morphologically richer language. 3 System Description 3.1 PB-SMT Translation is modeled in SMT as a decision process, in which the translation I e1 = e1 . . . ei . . . eI of a source sentence J f1 = f1 . . . fj . . . fJ is chosen to maximize (1): arg max ( |) arg max ( |) . ( ) P e f = I J P f e P e J I I (1) 1 1 1 1 I eI , I eI , 1 1 where (1 |1 ) P f J e I and ( 1 ) P e denote respecI tively the translation model and the target language model (Brown et al., 1993). In log-linear phrase-based SMT, the posterior probability P e I f J is directly modeled as a log-linear ( 1 |1 ) combination of features (Och and Ney, 2002), that usually comprise M translational features, and the language model, as in (2): 47 M log P(e I 1 |f1J) = ZAm hm(f1J,e1 ,sK) m=1 +ALM P e (2) log ( 1 ) I where s1k = s1...sk denotes a segmentation of the source and target sentences respectively into the ˆ ˆ sequences of phrases (eˆ1 ,..., ˆek) and (f1,..., fk) such that (we set i0 = 0) (3): V1 ≤ k ≤ K, sk = (ik, bk, jk), ˆ ek e i k − 1 + 1 ... e i k = , ˆ fk = fbk ...fjk . (3) ˆ and e</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Brown, Peter F., Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Computational Linguistics, 19(2):263-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Mona Diab</author>
</authors>
<title>Taskbased Evaluation of Multiword Expressions: a Pilot Study in Statistical Machine Translation.</title>
<date>2010</date>
<booktitle>In Proceedings of Human Language Technology conference and the North American Chapter of the Association for Computational Linguistics conference (HLT-NAACL 2010),</booktitle>
<pages>242--245</pages>
<location>Los Angeles, CA,</location>
<contexts>
<context position="5255" citStr="Carpuat and Diab (2010)" startWordPosition="787" endWordPosition="790">reported a discriminative approach of using the compositionality information about verb-based multi-word expressions to improve word alignment quality. (Ren et al., 2009) presented log likelihood ratiobased hierarchical reducing algorithm to automatically extract bilingual MWEs, and investigated the usefulness of these bilingual MWEs in SMT by integrating bilingual MWEs into Moses (Koehn et al., 2007) in three ways. They observed the highest improvement when they used an additional feature to represent whether or not a bilingual phrase contains bilingual MWEs. This approach was generalized in Carpuat and Diab (2010). In their work, the binary feature was replaced by a count feature representing the number of MWEs in the source language phrase. Intuitively, MWEs should be both aligned in the parallel corpus and translated as a whole. However, in the state-of-the-art PB-SMT, it could well be the case that constituents of an MWE are marked and aligned as parts of consecutive phrases, since PB-SMT (or any other approaches to SMT) does not generally treat MWEs as special tokens. Another problem SMT suffers from is that verb phrases are often wrongly translated, or even sometimes deleted in the output in order</context>
</contexts>
<marker>Carpuat, Diab, 2010</marker>
<rawString>Carpuat, Marine, and Mona Diab. 2010. Taskbased Evaluation of Multiword Expressions: a Pilot Study in Statistical Machine Translation. In Proceedings of Human Language Technology conference and the North American Chapter of the Association for Computational Linguistics conference (HLT-NAACL 2010), Los Angeles, CA, pp. 242-245.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Debasri Chakrabarti</author>
<author>Hemang Mandalia</author>
<author>Ritwik Priya</author>
<author>Vaijayanthi Sarma</author>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>Hindi compound verbs and their automatic extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), Posters and demonstrations,</booktitle>
<pages>27--30</pages>
<location>Manchester, UK,</location>
<marker>Chakrabarti, Mandalia, Priya, Sarma, Bhattacharyya, 2008</marker>
<rawString>Chakrabarti, Debasri, Hemang Mandalia, Ritwik Priya, Vaijayanthi Sarma, and Pushpak Bhattacharyya. 2008. Hindi compound verbs and their automatic extraction. In Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), Posters and demonstrations, Manchester, UK, pp. 27-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A P Dempster</author>
<author>N M Laird</author>
<author>D B Rubin</author>
</authors>
<title>Maximum Likelihood from Incomplete Data via the EM Algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society, Series B (Methodological)</journal>
<volume>39</volume>
<issue>1</issue>
<pages>1--38</pages>
<contexts>
<context position="10263" citStr="Dempster et al., 1977" startWordPosition="1715" endWordPosition="1718">e of a special word separator (underscore in our case) facilitates the job of deciding which single-token (target language) MWEs to detokenize into words comprising them, before evaluation. 3.3 Transliteration Using Modified Joint Source-Channel Model Li et al. (2004) proposed a generative framework allowing direct orthographical mapping of transliteration units through a joint source-channel model, which is also called n-gram transliteration model. They modeled the segmentation of names into transliteration units (TU) and their alignment preferences using maximum likelihood via EM algorithm (Dempster et al., 1977). Unlike the noisy-channel model, the joint source-channel model tries to capture how source and target names can be generated simultaneously by means of contextual n-grams of the transliteration units. For K aligned TUs, they define the bigram model as in (6): ) P(&lt;e,b&gt;1,&lt;e,b&gt;2 ... &lt;e,b&gt;K ) K ∏P(&lt;e,b&gt;k|&lt;e,b&gt; k=1 P E B = P e e e K b b b K ( , ) ( 1 , 2 . . . , 1 , 2 . . . where E refers to the English name and B the transliteration in Bengali, while ei and bi refer to the ith English and Bangla segment (TU) respectively. Ekbal et al. (2006) presented a modification to the joint source-channel </context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>Dempster, A.P., N.M. Laird, and D.B. Rubin. 1977). Maximum Likelihood from Incomplete Data via the EM Algorithm. Journal of the Royal Statistical Society, Series B (Methodological) 39 (1): 1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Doddington</author>
</authors>
<title>Automatic evaluation of machine translation quality using n-gram cooccurrence statistics.</title>
<date>2002</date>
<booktitle>In Proceedings of the Second International Conference on Human Language Technology Research (HLT-2002),</booktitle>
<pages>128--132</pages>
<location>San Diego, CA,</location>
<contexts>
<context position="23141" citStr="Doddington, 2002" startWordPosition="3894" endWordPosition="3895">experiments using 4 different settings: alignment of (i) NEs of length up to two, (ii) NEs of length two, 51 (iii) NEs of length greater than two, and (iv) NEs of any length. Before evaluation, the single-token (target language) underscored MWEs are expanded back to words comprising the MWEs. Since we did not have the gold-standard word alignment, we could not perform intrinsic evaluation of the word alignment. Instead we carry out extrinsic evaluation on the MT quality using the well known automatic MT evaluation metrics: BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), NIST (Doddington, 2002), WER, PER and TER (Snover et al., 2006). As can be seen from the evaluation results reported in Table 2, baseline Moses without any preprocessing of the dataset produces a BLEU score of 8.74. The low score can be attributed to the fact that Bangla, a morphologically rich language, is hard to translate into. Moreover, Bangla being a relatively free phrase order language (Ekbal and Bandyopadhyay, 2009) ideally requires multiple set of references for proper evaluation. Hence using a single reference set does not justify evaluating translations in Bangla. Also the training set was not sufficientl</context>
</contexts>
<marker>Doddington, 2002</marker>
<rawString>Doddington, George. 2002. Automatic evaluation of machine translation quality using n-gram cooccurrence statistics. In Proceedings of the Second International Conference on Human Language Technology Research (HLT-2002), San Diego, CA, pp. 128-132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Eck</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Improving statistical machine translation in the medical domain using the Unified Medical Language System.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics (COLING 2004),</booktitle>
<pages>792--798</pages>
<location>Geneva,</location>
<contexts>
<context position="2993" citStr="Eck et al., 2004" startWordPosition="440" endWordPosition="443">ither. We address this many-to-many alignment problem indirectly. Our objective is to see how to best handle the MWEs in SMT. In this work, two types of MWEs, namely NEs and compound verbs, are automatically identified on both sides of the parallel corpus. Then, source and target language NEs are aligned using a statistical transliteration method. We rely on these automatically aligned NEs and treat them as translation examples. Adding bilingual dictionaries, which in effect are instances of atomic translation pairs, to the parallel corpus is a well-known practice in domain adaptation in SMT (Eck et al., 2004; Wu et al., 2008). We modify the parallel corpus by converting the MWEs into single tokens and adding the aligned NEs in the parallel corpus in a bid to improve the word alignment, and hence the phrase alignment quality. This 46 Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 46–54, Beijing, August 2010 preprocessing results in improved MT quality in terms of automatic MT evaluation metrics. The remainder of the paper is organized as follows. In section 2 we discuss related work. The System is described in Section 3. Section 4 includes the results obtai</context>
</contexts>
<marker>Eck, Vogel, Waibel, 2004</marker>
<rawString>Eck, Matthias, Stephan Vogel, and Alex Waibel. 2004. Improving statistical machine translation in the medical domain using the Unified Medical Language System. In Proceedings of the 20th International Conference on Computational Linguistics (COLING 2004), Geneva, Switzerland, pp. 792-798.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asif Ekbal</author>
<author>Sivaji Bandyopadhyay</author>
</authors>
<title>Voted NER system using appropriate unlabeled data.</title>
<date>2009</date>
<booktitle>In proceedings of the ACL-IJCNLP-2009 Named Entities Workshop (NEWS 2009), Suntec, Singapore,</booktitle>
<pages>202--210</pages>
<contexts>
<context position="8833" citStr="Ekbal and Bandyopadhyay, 2009" startWordPosition="1487" endWordPosition="1491">is cleaned and filtered using a semi-automatic process. We employed two kinds of multi-word information: compound verbs and NEs. Compound verbs are first identified on both sides of the parallel corpus. Chakrabarty et al. (2008) analyzed and identified a category of V+V complex predicates called lexical compound verbs for Hindi. We adapted their strategy for identification of compound verbs in Bangla. In addition to V+V construction, we also consider N+V and ADJ+V structures. NEs are also identified on both sides of translation pairs. NEs in Bangla are much harder to identify than in English (Ekbal and Bandyopadhyay, 2009). This can be attributed to the fact that (i) there is no concept of capitalization in Bangla; and (ii) Bangla common nouns are often used as proper names. In Bangla, the problem is compounded by the fact that suffixes (case markers, plural markers, emphasizers, specifiers) are also added to proper names, just like to any other common nouns. As a consequence, the accuracy of Bangla NE recognizers (NER) is much poorer compared to that for English. Once the compound verbs and the NEs are identified on both sides of the parallel corpus, they are converted into and replaced by single tokens. When </context>
<context position="23545" citStr="Ekbal and Bandyopadhyay, 2009" startWordPosition="3959" endWordPosition="3962"> of the word alignment. Instead we carry out extrinsic evaluation on the MT quality using the well known automatic MT evaluation metrics: BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), NIST (Doddington, 2002), WER, PER and TER (Snover et al., 2006). As can be seen from the evaluation results reported in Table 2, baseline Moses without any preprocessing of the dataset produces a BLEU score of 8.74. The low score can be attributed to the fact that Bangla, a morphologically rich language, is hard to translate into. Moreover, Bangla being a relatively free phrase order language (Ekbal and Bandyopadhyay, 2009) ideally requires multiple set of references for proper evaluation. Hence using a single reference set does not justify evaluating translations in Bangla. Also the training set was not sufficiently large enough for SMT. Treating only longer than 2- word NEs as single tokens does not help improve the overall performance much, while single tokenization of two-word NEs as single tokens produces some improvements (.39 BLEU points absolute, 4.5% relative). Considering compound verbs as single tokens (CVaST) produces a .82 BLEU point improvement (9.4% relative) over the baseline. Strangely, when bot</context>
</contexts>
<marker>Ekbal, Bandyopadhyay, 2009</marker>
<rawString>Ekbal, Asif, and Sivaji Bandyopadhyay. 2009. Voted NER system using appropriate unlabeled data. In proceedings of the ACL-IJCNLP-2009 Named Entities Workshop (NEWS 2009), Suntec, Singapore, pp. 202-210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asif Ekbal</author>
<author>Sivaji Bandyopadhyay</author>
</authors>
<title>Maximum Entropy Approach for Named Entity Recognition in Indian Languages.</title>
<date>2008</date>
<journal>International Journal for Computer Processing of Languages (IJCPOL),</journal>
<volume>Vol.</volume>
<pages>21--3</pages>
<contexts>
<context position="16585" citStr="Ekbal and Bandyopadhyay (2008)" startWordPosition="2801" endWordPosition="2804">rom the consortium-mode project “Development of English to Indian Languages Machine Translation (EILMT) System” 1. The Stanford Parser2 and the CRF chunker3 were used for identifying compound verbs in the source side of the parallel corpus. The Stanford NER4 was used to identify NEs on the source side (English) of the parallel corpus. The sentences on the target side (Bangla) were POS-tagged by using the tools obtained from the consortium mode project “Development of Indian Languages to Indian Languages Machine Translation (ILILMT) System”. NEs in Bangla are identified using the NER system of Ekbal and Bandyopadhyay (2008). We use the Stanford Parser, Stanford NER and the NER for Bangla along with the default model files provided, i.e., with no additional training. The effectiveness of the MWE-aligned parallel corpus developed in the work is demonstrated by using the standard log-linear PB-SMT model as our baseline system: GIZA++ implementation of IBM word alignment model 4, phraseextraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003) on a held-out development set, target language model with Kneser-Ney smoothing (Kneser and 1 The EILMT and ILILMT projects are funded by </context>
</contexts>
<marker>Ekbal, Bandyopadhyay, 2008</marker>
<rawString>Ekbal, Asif, and Sivaji Bandyopadhyay. 2008. Maximum Entropy Approach for Named Entity Recognition in Indian Languages. International Journal for Computer Processing of Languages (IJCPOL), Vol. 21(3):205-237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donghui Feng</author>
<author>Yajuan Lv</author>
<author>Ming Zhou</author>
</authors>
<title>A new approach for English-Chinese named entity alignment.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP-2004),</booktitle>
<pages>372--379</pages>
<location>Barcelona,</location>
<contexts>
<context position="4007" citStr="Feng et al. (2004)" startWordPosition="604" endWordPosition="607">rms of automatic MT evaluation metrics. The remainder of the paper is organized as follows. In section 2 we discuss related work. The System is described in Section 3. Section 4 includes the results obtained, together with some analysis. Section 5 concludes, and provides avenues for further work. 2 Related Work Moore (2003) presented an approach for simultaneous NE identification and translation. He uses capitalization cues for identifying NEs on the English side, and then he applies statistical techniques to decide which portion of the target language corresponds to the specified English NE. Feng et al. (2004) proposed a Maximum Entropy model based approach for English— Chinese NE alignment which significantly outperforms IBM Model4 and HMM. They considered 4 features: translation score, transliteration score, source NE and target NE&apos;s co-occurrence score, and the distortion score for distinguishing identical NEs in the same sentence. Huang et al. (2003) proposed a method for automatically extracting NE translingual equivalences between Chinese and English based on multi-feature cost minimization. The costs considered are transliteration cost, word-based translation cost, and NE tagging cost. Venka</context>
</contexts>
<marker>Feng, Lv, Zhou, 2004</marker>
<rawString>Feng, Donghui, Yajuan Lv, and Ming Zhou. 2004. A new approach for English-Chinese named entity alignment. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP-2004), Barcelona, Spain, pp. 372-379.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Huang</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Automatic extraction of named entity translingual equivalence based on multi-feature cost minimization.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL2003 Workshop on Multilingual and Mixedlanguage Named Entity Recognition,</booktitle>
<pages>9--16</pages>
<location>Sapporo,</location>
<contexts>
<context position="4358" citStr="Huang et al. (2003)" startWordPosition="656" endWordPosition="659">r simultaneous NE identification and translation. He uses capitalization cues for identifying NEs on the English side, and then he applies statistical techniques to decide which portion of the target language corresponds to the specified English NE. Feng et al. (2004) proposed a Maximum Entropy model based approach for English— Chinese NE alignment which significantly outperforms IBM Model4 and HMM. They considered 4 features: translation score, transliteration score, source NE and target NE&apos;s co-occurrence score, and the distortion score for distinguishing identical NEs in the same sentence. Huang et al. (2003) proposed a method for automatically extracting NE translingual equivalences between Chinese and English based on multi-feature cost minimization. The costs considered are transliteration cost, word-based translation cost, and NE tagging cost. Venkatapathy and Joshi (2006) reported a discriminative approach of using the compositionality information about verb-based multi-word expressions to improve word alignment quality. (Ren et al., 2009) presented log likelihood ratiobased hierarchical reducing algorithm to automatically extract bilingual MWEs, and investigated the usefulness of these bilin</context>
</contexts>
<marker>Huang, Vogel, Waibel, 2003</marker>
<rawString>Huang, Fei, Stephan Vogel, and Alex Waibel. 2003. Automatic extraction of named entity translingual equivalence based on multi-feature cost minimization. In Proceedings of the ACL2003 Workshop on Multilingual and Mixedlanguage Named Entity Recognition, 2003, Sapporo, Japan, pp. 9-16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Kneser</author>
<author>Hermann Ney</author>
</authors>
<title>Improved backing-off for m-gram language modeling.</title>
<date>1995</date>
<booktitle>In Proceedings of the IEEE Internation Conference on Acoustics, Speech, and Signal Processing (ICASSP),</booktitle>
<volume>1</volume>
<pages>181--184</pages>
<location>Detroit, MI.</location>
<marker>Kneser, Ney, 1995</marker>
<rawString>Kneser, Reinhard, and Hermann Ney. 1995. Improved backing-off for m-gram language modeling. In Proceedings of the IEEE Internation Conference on Acoustics, Speech, and Signal Processing (ICASSP), vol. 1, pp. 181-184. Detroit, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL 2003: conference combining Human Language Technology conference series and the North American Chapter of the Association for Computational Linguistics conference series,</booktitle>
<pages>48--54</pages>
<location>Edmonton, Canada,</location>
<contexts>
<context position="2142" citStr="Koehn et al., 2003" startWordPosition="305" endWordPosition="308">rd expressions (MWE) are defined as “idiosyncratic interpretations that cross word boundaries (or spaces)” (Sag et al., 2002). Traditional approaches to word alignment following IBM Models (Brown et al., 1993) do not work well with multi-word expressions, especially with NEs, due to their inability to handle manyto-many alignments. Firstly, they only carry out alignment between words and do not consider the case of complex expressions, such as multiword NEs. Secondly, the IBM Models only allow at most one word in the source language to correspond to a word in the target language (Marcu, 2001, Koehn et al., 2003). In another well-known word alignment approach, Hidden Markov Model (HMM: Vogel et al., 1996), the alignment probabilities depend on the alignment position of the previous word. It does not explicitly consider many-to-many alignment either. We address this many-to-many alignment problem indirectly. Our objective is to see how to best handle the MWEs in SMT. In this work, two types of MWEs, namely NEs and compound verbs, are automatically identified on both sides of the parallel corpus. Then, source and target language NEs are aligned using a statistical transliteration method. We rely on thes</context>
<context position="17006" citStr="Koehn et al., 2003" startWordPosition="2868" endWordPosition="2871">consortium mode project “Development of Indian Languages to Indian Languages Machine Translation (ILILMT) System”. NEs in Bangla are identified using the NER system of Ekbal and Bandyopadhyay (2008). We use the Stanford Parser, Stanford NER and the NER for Bangla along with the default model files provided, i.e., with no additional training. The effectiveness of the MWE-aligned parallel corpus developed in the work is demonstrated by using the standard log-linear PB-SMT model as our baseline system: GIZA++ implementation of IBM word alignment model 4, phraseextraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003) on a held-out development set, target language model with Kneser-Ney smoothing (Kneser and 1 The EILMT and ILILMT projects are funded by the Department of Information Technology (DIT), Ministry of Communications and Information Technology (MCIT), Government of India. 2 http://nlp.stanford.edu/software/lex-parser.shtml 3 http://crfchunker.sourceforge.net/ 4 http://nlp.stanford.edu/software/CRF-NER.shtml Ney, 1995) trained with SRILM (Stolcke, 2002), and Moses decoder (Koehn et al., 2007). 4 Experiments and Results We randomly extracted 500 sentences eac</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Koehn, Philipp, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of HLT-NAACL 2003: conference combining Human Language Technology conference series and the North American Chapter of the Association for Computational Linguistics conference series, Edmonton, Canada, pp. 48-54.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondřej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual meeting of the Association for Computational Linguistics (ACL 2007): Proceedings of demo and poster sessions,</booktitle>
<pages>177--180</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="5036" citStr="Koehn et al., 2007" startWordPosition="752" endWordPosition="755">gual equivalences between Chinese and English based on multi-feature cost minimization. The costs considered are transliteration cost, word-based translation cost, and NE tagging cost. Venkatapathy and Joshi (2006) reported a discriminative approach of using the compositionality information about verb-based multi-word expressions to improve word alignment quality. (Ren et al., 2009) presented log likelihood ratiobased hierarchical reducing algorithm to automatically extract bilingual MWEs, and investigated the usefulness of these bilingual MWEs in SMT by integrating bilingual MWEs into Moses (Koehn et al., 2007) in three ways. They observed the highest improvement when they used an additional feature to represent whether or not a bilingual phrase contains bilingual MWEs. This approach was generalized in Carpuat and Diab (2010). In their work, the binary feature was replaced by a count feature representing the number of MWEs in the source language phrase. Intuitively, MWEs should be both aligned in the parallel corpus and translated as a whole. However, in the state-of-the-art PB-SMT, it could well be the case that constituents of an MWE are marked and aligned as parts of consecutive phrases, since PB</context>
<context position="17539" citStr="Koehn et al., 2007" startWordPosition="2931" endWordPosition="2934"> word alignment model 4, phraseextraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003) on a held-out development set, target language model with Kneser-Ney smoothing (Kneser and 1 The EILMT and ILILMT projects are funded by the Department of Information Technology (DIT), Ministry of Communications and Information Technology (MCIT), Government of India. 2 http://nlp.stanford.edu/software/lex-parser.shtml 3 http://crfchunker.sourceforge.net/ 4 http://nlp.stanford.edu/software/CRF-NER.shtml Ney, 1995) trained with SRILM (Stolcke, 2002), and Moses decoder (Koehn et al., 2007). 4 Experiments and Results We randomly extracted 500 sentences each for the development set and testset from the initial parallel corpus, and treated the rest as the training corpus. After filtering on maximum allowable sentence length of 100 and sentence length ratio of 1:2 (either way), the training corpus contained 13,176 sentences. In addition to the target side of the parallel corpus, a monolingual Bangla corpus containing 293,207 words from the tourism domain was used for the target language model. We experimented with different n-gram settings for the language model and the maximum phr</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Koehn, Philipp, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondřej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of the 45th Annual meeting of the Association for Computational Linguistics (ACL 2007): Proceedings of demo and poster sessions, Prague, Czech Republic, pp. 177-180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In EMNLP2004: Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>25--26</pages>
<location>Barcelona,</location>
<contexts>
<context position="24740" citStr="Koehn, 2004" startWordPosition="4149" endWordPosition="4150">rangely, when both compound verbs and NEs together are counted as single tokens, there is hardly any improvement. By contrast, automatic NE alignment (NEA) gives a huge impetus to system performance, the best of them (4.59 BLEU points absolute, 52.5% relative improvement) being the alignment of NEs of any length that produces the best scores across all metrics. When NEA is combined with CVaST, the improvements are substantial, but it can not beat the individual improvement on NEA. The (†) marked systems produce statistically significant improvements as measured by bootstrap resampling method (Koehn, 2004) on BLEU over the baseline system. Metric-wise individual best scores are shown in bold in Table 2. 5 Conclusions and Future Work In this paper, we have successfully shown how the simple yet effective preprocessing of treating two types of MWEs, namely NEs and compound verbs, as single-tokens, in conjunction with prior NE alignment can boost the performance of PB-SMT system on an English—Bangla translation task. Treating compound verbs as single-tokens provides significant gains over the baseline PB-SMT system. Amongst the MWEs, NEs perhaps play the most important role in MT, as we have clearl</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Koehn, Philipp. 2004. Statistical significance tests for machine translation evaluation. In EMNLP2004: Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, 25-26 July 2004, Barcelona, Spain, pp. 388-395.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>Towards a Unified Approach to Memory- and Statistical-Based Machine Translation.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL 2001),</booktitle>
<pages>386--393</pages>
<location>Toulouse, France,</location>
<contexts>
<context position="2121" citStr="Marcu, 2001" startWordPosition="303" endWordPosition="304">pus. Multi-word expressions (MWE) are defined as “idiosyncratic interpretations that cross word boundaries (or spaces)” (Sag et al., 2002). Traditional approaches to word alignment following IBM Models (Brown et al., 1993) do not work well with multi-word expressions, especially with NEs, due to their inability to handle manyto-many alignments. Firstly, they only carry out alignment between words and do not consider the case of complex expressions, such as multiword NEs. Secondly, the IBM Models only allow at most one word in the source language to correspond to a word in the target language (Marcu, 2001, Koehn et al., 2003). In another well-known word alignment approach, Hidden Markov Model (HMM: Vogel et al., 1996), the alignment probabilities depend on the alignment position of the previous word. It does not explicitly consider many-to-many alignment either. We address this many-to-many alignment problem indirectly. Our objective is to see how to best handle the MWEs in SMT. In this work, two types of MWEs, namely NEs and compound verbs, are automatically identified on both sides of the parallel corpus. Then, source and target language NEs are aligned using a statistical transliteration me</context>
</contexts>
<marker>Marcu, 2001</marker>
<rawString>Marcu, Daniel. 2001. Towards a Unified Approach to Memory- and Statistical-Based Machine Translation. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL 2001), Toulouse, France, pp. 386-393.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>Learning translations of named-entity phrases from parallel corpora.</title>
<date>2003</date>
<booktitle>In Proceedings of 10th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2003),</booktitle>
<pages>259--266</pages>
<location>Budapest, Hungary;</location>
<contexts>
<context position="3714" citStr="Moore (2003)" startWordPosition="561" endWordPosition="562">igned NEs in the parallel corpus in a bid to improve the word alignment, and hence the phrase alignment quality. This 46 Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 46–54, Beijing, August 2010 preprocessing results in improved MT quality in terms of automatic MT evaluation metrics. The remainder of the paper is organized as follows. In section 2 we discuss related work. The System is described in Section 3. Section 4 includes the results obtained, together with some analysis. Section 5 concludes, and provides avenues for further work. 2 Related Work Moore (2003) presented an approach for simultaneous NE identification and translation. He uses capitalization cues for identifying NEs on the English side, and then he applies statistical techniques to decide which portion of the target language corresponds to the specified English NE. Feng et al. (2004) proposed a Maximum Entropy model based approach for English— Chinese NE alignment which significantly outperforms IBM Model4 and HMM. They considered 4 features: translation score, transliteration score, source NE and target NE&apos;s co-occurrence score, and the distortion score for distinguishing identical N</context>
</contexts>
<marker>Moore, 2003</marker>
<rawString>Moore, Robert C. 2003. Learning translations of named-entity phrases from parallel corpora. In Proceedings of 10th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2003), Budapest, Hungary; pp. 259-266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL-2003),</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan,</location>
<contexts>
<context position="17047" citStr="Och, 2003" startWordPosition="2874" endWordPosition="2875">guages to Indian Languages Machine Translation (ILILMT) System”. NEs in Bangla are identified using the NER system of Ekbal and Bandyopadhyay (2008). We use the Stanford Parser, Stanford NER and the NER for Bangla along with the default model files provided, i.e., with no additional training. The effectiveness of the MWE-aligned parallel corpus developed in the work is demonstrated by using the standard log-linear PB-SMT model as our baseline system: GIZA++ implementation of IBM word alignment model 4, phraseextraction heuristics described in (Koehn et al., 2003), minimum-error-rate training (Och, 2003) on a held-out development set, target language model with Kneser-Ney smoothing (Kneser and 1 The EILMT and ILILMT projects are funded by the Department of Information Technology (DIT), Ministry of Communications and Information Technology (MCIT), Government of India. 2 http://nlp.stanford.edu/software/lex-parser.shtml 3 http://crfchunker.sourceforge.net/ 4 http://nlp.stanford.edu/software/CRF-NER.shtml Ney, 1995) trained with SRILM (Stolcke, 2002), and Moses decoder (Koehn et al., 2007). 4 Experiments and Results We randomly extracted 500 sentences each for the development set and testset fro</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Och, Franz J. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL-2003), Sapporo, Japan, pp. 160-167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-2002),</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="23081" citStr="Papineni et al., 2002" startWordPosition="3884" endWordPosition="3887">ng of single-tokenizing the MWEs. For NE alignment, we performed experiments using 4 different settings: alignment of (i) NEs of length up to two, (ii) NEs of length two, 51 (iii) NEs of length greater than two, and (iv) NEs of any length. Before evaluation, the single-token (target language) underscored MWEs are expanded back to words comprising the MWEs. Since we did not have the gold-standard word alignment, we could not perform intrinsic evaluation of the word alignment. Instead we carry out extrinsic evaluation on the MT quality using the well known automatic MT evaluation metrics: BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), NIST (Doddington, 2002), WER, PER and TER (Snover et al., 2006). As can be seen from the evaluation results reported in Table 2, baseline Moses without any preprocessing of the dataset produces a BLEU score of 8.74. The low score can be attributed to the fact that Bangla, a morphologically rich language, is hard to translate into. Moreover, Bangla being a relatively free phrase order language (Ekbal and Bandyopadhyay, 2009) ideally requires multiple set of references for proper evaluation. Hence using a single reference set does not justify evaluating trans</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Papineni, Kishore, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL-2002), Philadelphia, PA, pp. 311-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhixiang Ren</author>
<author>Yajuan Lü</author>
<author>Jie Cao</author>
<author>Qun Liu</author>
<author>Yun Huang</author>
</authors>
<title>Improving statistical machine translation using domain bilingual multiword expressions.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Workshop on Multiword Expressions, ACLIJCNLP 2009, Suntec, Singapore,</booktitle>
<pages>47--54</pages>
<contexts>
<context position="4802" citStr="Ren et al., 2009" startWordPosition="717" endWordPosition="720">re, transliteration score, source NE and target NE&apos;s co-occurrence score, and the distortion score for distinguishing identical NEs in the same sentence. Huang et al. (2003) proposed a method for automatically extracting NE translingual equivalences between Chinese and English based on multi-feature cost minimization. The costs considered are transliteration cost, word-based translation cost, and NE tagging cost. Venkatapathy and Joshi (2006) reported a discriminative approach of using the compositionality information about verb-based multi-word expressions to improve word alignment quality. (Ren et al., 2009) presented log likelihood ratiobased hierarchical reducing algorithm to automatically extract bilingual MWEs, and investigated the usefulness of these bilingual MWEs in SMT by integrating bilingual MWEs into Moses (Koehn et al., 2007) in three ways. They observed the highest improvement when they used an additional feature to represent whether or not a bilingual phrase contains bilingual MWEs. This approach was generalized in Carpuat and Diab (2010). In their work, the binary feature was replaced by a count feature representing the number of MWEs in the source language phrase. Intuitively, MWE</context>
</contexts>
<marker>Ren, Lü, Cao, Liu, Huang, 2009</marker>
<rawString>Ren, Zhixiang, Yajuan Lü, Jie Cao, Qun Liu, and Yun Huang. 2009. Improving statistical machine translation using domain bilingual multiword expressions. In Proceedings of the 2009 Workshop on Multiword Expressions, ACLIJCNLP 2009, Suntec, Singapore, pp. 47-54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan A Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2002),</booktitle>
<pages>1--15</pages>
<location>Mexico City, Mexico,</location>
<contexts>
<context position="1648" citStr="Sag et al., 2002" startWordPosition="221" endWordPosition="224">compare them with the target NEs. Target language NEs are first converted into a canonical form before the comparison takes place. Our best system achieves statistically significant improvements (4.59 BLEU points absolute, 52.5% relative improvement) on an English—Bangla translation task. 1 Introduction Statistical machine translation (SMT) heavily relies on good quality word alignment and phrase alignment tables comprising translation knowledge acquired from a bilingual corpus. Multi-word expressions (MWE) are defined as “idiosyncratic interpretations that cross word boundaries (or spaces)” (Sag et al., 2002). Traditional approaches to word alignment following IBM Models (Brown et al., 1993) do not work well with multi-word expressions, especially with NEs, due to their inability to handle manyto-many alignments. Firstly, they only carry out alignment between words and do not consider the case of complex expressions, such as multiword NEs. Secondly, the IBM Models only allow at most one word in the source language to correspond to a word in the target language (Marcu, 2001, Koehn et al., 2003). In another well-known word alignment approach, Hidden Markov Model (HMM: Vogel et al., 1996), the alignm</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Sag, Ivan A., Timothy Baldwin, Francis Bond, Ann Copestake and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Proceedings of the 3rd International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-2002), Mexico City, Mexico, pp. 1-15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas (AMTA 2006),</booktitle>
<pages>223--231</pages>
<location>Cambridge, MA,</location>
<contexts>
<context position="23181" citStr="Snover et al., 2006" startWordPosition="3900" endWordPosition="3903">s: alignment of (i) NEs of length up to two, (ii) NEs of length two, 51 (iii) NEs of length greater than two, and (iv) NEs of any length. Before evaluation, the single-token (target language) underscored MWEs are expanded back to words comprising the MWEs. Since we did not have the gold-standard word alignment, we could not perform intrinsic evaluation of the word alignment. Instead we carry out extrinsic evaluation on the MT quality using the well known automatic MT evaluation metrics: BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), NIST (Doddington, 2002), WER, PER and TER (Snover et al., 2006). As can be seen from the evaluation results reported in Table 2, baseline Moses without any preprocessing of the dataset produces a BLEU score of 8.74. The low score can be attributed to the fact that Bangla, a morphologically rich language, is hard to translate into. Moreover, Bangla being a relatively free phrase order language (Ekbal and Bandyopadhyay, 2009) ideally requires multiple set of references for proper evaluation. Hence using a single reference set does not justify evaluating translations in Bangla. Also the training set was not sufficiently large enough for SMT. Treating only lo</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Snover, Matthew, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas (AMTA 2006), Cambridge, MA, pp. 223-231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillmann</author>
</authors>
<title>HMM-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (COLING</booktitle>
<pages>836--841</pages>
<location>Copenhagen,</location>
<contexts>
<context position="2236" citStr="Vogel et al., 1996" startWordPosition="320" endWordPosition="323">(or spaces)” (Sag et al., 2002). Traditional approaches to word alignment following IBM Models (Brown et al., 1993) do not work well with multi-word expressions, especially with NEs, due to their inability to handle manyto-many alignments. Firstly, they only carry out alignment between words and do not consider the case of complex expressions, such as multiword NEs. Secondly, the IBM Models only allow at most one word in the source language to correspond to a word in the target language (Marcu, 2001, Koehn et al., 2003). In another well-known word alignment approach, Hidden Markov Model (HMM: Vogel et al., 1996), the alignment probabilities depend on the alignment position of the previous word. It does not explicitly consider many-to-many alignment either. We address this many-to-many alignment problem indirectly. Our objective is to see how to best handle the MWEs in SMT. In this work, two types of MWEs, namely NEs and compound verbs, are automatically identified on both sides of the parallel corpus. Then, source and target language NEs are aligned using a statistical transliteration method. We rely on these automatically aligned NEs and treat them as translation examples. Adding bilingual dictionar</context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>Vogel, Stephan, Hermann Ney, and Christoph Tillmann. 1996. HMM-based word alignment in statistical translation. In Proceedings of the 16th International Conference on Computational Linguistics (COLING 1996), Copenhagen, pp. 836-841.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sriram Venkatapathy</author>
<author>Aravind K Joshi</author>
</authors>
<title>Using information about multi-word expressions for the word-alignment task.</title>
<date>2006</date>
<booktitle>In Proceedings of Coling-ACL 2006: Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties,</booktitle>
<pages>20--27</pages>
<location>Sydney,</location>
<contexts>
<context position="4631" citStr="Venkatapathy and Joshi (2006)" startWordPosition="693" endWordPosition="696">2004) proposed a Maximum Entropy model based approach for English— Chinese NE alignment which significantly outperforms IBM Model4 and HMM. They considered 4 features: translation score, transliteration score, source NE and target NE&apos;s co-occurrence score, and the distortion score for distinguishing identical NEs in the same sentence. Huang et al. (2003) proposed a method for automatically extracting NE translingual equivalences between Chinese and English based on multi-feature cost minimization. The costs considered are transliteration cost, word-based translation cost, and NE tagging cost. Venkatapathy and Joshi (2006) reported a discriminative approach of using the compositionality information about verb-based multi-word expressions to improve word alignment quality. (Ren et al., 2009) presented log likelihood ratiobased hierarchical reducing algorithm to automatically extract bilingual MWEs, and investigated the usefulness of these bilingual MWEs in SMT by integrating bilingual MWEs into Moses (Koehn et al., 2007) in three ways. They observed the highest improvement when they used an additional feature to represent whether or not a bilingual phrase contains bilingual MWEs. This approach was generalized in</context>
</contexts>
<marker>Venkatapathy, Joshi, 2006</marker>
<rawString>Venkatapathy, Sriram, and Aravind K. Joshi. 2006. Using information about multi-word expressions for the word-alignment task. In Proceedings of Coling-ACL 2006: Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties, Sydney, pp. 20-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua Haifeng Wang Wu</author>
<author>Chengqing Zong</author>
</authors>
<title>Domain adaptation for statistical machine translation with domain dictionary and monolingual corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING 2008),</booktitle>
<pages>993--1000</pages>
<location>Manchester, UK,</location>
<marker>Wu, Zong, 2008</marker>
<rawString>Wu, Hua Haifeng Wang, and Chengqing Zong. 2008. Domain adaptation for statistical machine translation with domain dictionary and monolingual corpora. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING 2008), Manchester, UK, pp. 993-1000.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>