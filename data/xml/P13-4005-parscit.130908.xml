<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001413">
<title confidence="0.97935">
Detecting Event-Related Links and Sentiments from Social Media Texts
</title>
<author confidence="0.838755">
Alexandra Balahur and Hristo Tanev
</author>
<affiliation confidence="0.785197">
European Commission Joint Research Centre
</affiliation>
<address confidence="0.902471">
Via E. Fermi 2749, T.P. 267
21027 Ispra (VA), Italy
</address>
<email confidence="0.99894">
{alexandra.balahur, hristo.tanev}@jrc.ec.europa.eu
</email>
<sectionHeader confidence="0.993896" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999845769230769">
Nowadays, the importance of Social Me-
dia is constantly growing, as people often
use such platforms to share mainstream
media news and comment on the events
that they relate to. As such, people no
loger remain mere spectators to the events
that happen in the world, but become part
of them, commenting on their develop-
ments and the entities involved, sharing
their opinions and distributing related con-
tent. This paper describes a system that
links the main events detected from clus-
ters of newspaper articles to tweets related
to them, detects complementary informa-
tion sources from the links they contain
and subsequently applies sentiment analy-
sis to classify them into positive, negative
and neutral. In this manner, readers can
follow the main events happening in the
world, both from the perspective of main-
stream as well as social media and the pub-
lic’s perception on them.
This system will be part of the EMM me-
dia monitoring framework working live
and it will be demonstrated using Google
Earth.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999984139534884">
In the context of the Web 2.0, the importance
of Social Media has been constantly growing in
the past years. People use Twitter, Facebook,
LinkedIn, Pinterest, blogs and Web forums to give
and get advice, share information on products,
opinions and real-time information about ongoing
and future events. In particular Twitter, with its
half a billion active members, was used during dis-
asters, protests, elections, and other events to share
updates, opinions, comments and post links to on-
line resources (e.g. news, videos, pictures, blog
posts, etc.). As such, Twitter can be used as a com-
plementary source of information, from which we
can retrieve additional facts, but also learn about
the attitude of the people towards certain events.
On the one hand, news from the traditional me-
dia focus on the factual side of events, important
for the society or at least large groups of people.
On the other hand, social media reflects subjec-
tive interpretations of facts, with different levels of
relevance (societal or only individual). Therefore,
the events reported in online news can be consid-
ered a point of intersection for both types of me-
dia, which are able to offer complementary views
on these events.
In this context, we describe a system that we
developed as an additonal component to the EMM
(Europe Media Monitor)1 news monitoring frame-
work, linking mainstream news to related texts
from social media and detecting the opinion (sen-
timent) users express on these topics.
In the EMM news monitoring system, the dif-
ferent news sites are monitored and new articles
are scraped from them, with a refresh rate of 10
minutes. Subsequently, news items are clustered
and the most important ones are displayed (top
10). These are called “stories”. Our system subse-
quently links these stories to messages from Twit-
ter (tweets) and extracts the related URLs they
contain. Finally, it analyzes the sentiments ex-
pressed in the tweets by using a hybrid knowledge-
based and statistical sentiment detection module.
The overview of the system is depicted in Figure
</bodyText>
<footnote confidence="0.989278">
1http://emm.jrc.it/NewsBrief/clusteredition/en/latest.html
</footnote>
<page confidence="0.979931">
25
</page>
<note confidence="0.4602835">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 25–30,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<figure confidence="0.850284">
1.
</figure>
<figureCaption confidence="0.9161475">
Figure 1: Overview of the news clusters-Twitter
linking and sentiment analysis system.
</figureCaption>
<bodyText confidence="0.999379272727273">
The system will be demonstrated using the
Google Earth interface (Figure 2), presenting the
characteristics of the event described in the story
(type, date, location, the first words in the arti-
cle that is the centroid of the news cluster for that
story). In addition, we present new information
that we extract from Twitter - links (URLs) that
we find from the tweets we retrieved linked to the
story and positive, negative and neutral sentiment,
respectively, as a proportion of the total number of
tweets retrieved.
</bodyText>
<figureCaption confidence="0.8268495">
Figure 2: Demo interface for the event-Twitter
linking and sentiment analysis.
</figureCaption>
<sectionHeader confidence="0.997086" genericHeader="related work">
2 Related Work and Contribution
</sectionHeader>
<bodyText confidence="0.999944690909091">
The work presented herein is mostly related to the
linking of events with social media texts and sen-
timent analysis from Twitter.
Although Twitter was used as an information
source in the context of different crisis events, rel-
atively little work focused on linking and extract-
ing content about events which are known a priori,
e.g., Becker et al. [2011].
In this context, the main challenge is to deter-
mine relevant keywords to search for event-related
tweets and rank them according to their relevance.
Related approaches (e.g., Verma et al. [2011]) re-
port on the use of semantic features (e.g., objec-
tivity, impersonality, formality, etc.) for detecting
tweets with content relevant to situational aware-
ness during mass emergencies. Other approaches
elaborate on machine learning-based techniques
for Named Entity Recognition (NER) from tweets,
which are subsequently employed as search query
terms ( Ritter et al. [2011], Liu et al. [2011]).
Related research on sentiment analysis from
Twitter was done by Alec Go and Huang [2009],
Pak and Paroubek [2010] and Agarwal et al.
[2011]. Alec Go and Huang [2009] and Pak and
Paroubek [2010] exploit the presence of emoticons
that represent positive or negative feelings to build
a training set of tweets with sentiment labels, using
which they build models based on n-gram features
and part-of-speech tags. Agarwal et al. [2011] em-
ploy emoticons dictionaries and replace certain el-
ements such as URLs and topics with predefinded
labels. They employ syntactic features and spe-
cialized tree kernels and obtain around 75% to
80% accuracy for the sentiment classification.
The main contributions of our system reside in
the linking of mainstream news to the complemen-
tary content found in social media (tweets and,
through them, to the links to additional informa-
tion sources like blogs, flickr, youtube, etc.) and
the analysis of sentiment on these important news.
For events such as “The Arab Spring”, protests, fi-
nancial news (e.g. the fluctuations of the Euro, the
bailout of different European countries, the rise in
unemployment rate, etc.), it was seen that the sen-
timent expressed in social media has a high impact
on the subsequent development of the story2 (Saif
et al. [2012], Bollen et al. [2011]). The impact of
sentiment expressed in social media is also visi-
ble for topics which apparently have an apriori va-
lence (e.g. disasters, crisis, etc.). Nevertheless, in
these cases, people communicate using the social
media platforms not only to express their negative
feelings, but also their will to help, their situation,
their messages of encouragement, their grateful-
ness for the help and so on.
</bodyText>
<footnote confidence="0.834908666666667">
2http://cs229.stanford.edu/proj2011/ChenLazer-
SentimentAnalysisOfTwitterFeedsForThePrediction
OfStockMarketMovement.pdf
</footnote>
<page confidence="0.993086">
26
</page>
<bodyText confidence="0.9998555">
Secondly, the methods employed in our system
are simple, work fast and efficient and can be eas-
ily adapted to other languages.
Finally, the methods presented take into account
the specificity of social media languages, applying
methods to normalize the language and adapting
the features considered for the supervised learning
process.
</bodyText>
<sectionHeader confidence="0.879152" genericHeader="method">
3 Linking News Clusters to Twitter
</sectionHeader>
<bodyText confidence="0.999677444444445">
The first step in our system involves linking the
news stories detected by EMM to related tweets.
The linking system employs the Twitter Search
API3. For each news story, our application detects
relevant URLs by finding tweets that are lexically
similar to the news story, represented by a cluster
of news, and are mentioned frequently in Twitter.
In Figure 3, we provide an example of the top six
stories on the afternoon of April 2nd, 2013.
</bodyText>
<figureCaption confidence="0.7898905">
Figure 3: Top six clusters of news in the afternoon
of April 2nd, 2013.
</figureCaption>
<bodyText confidence="0.999873538461539">
In order to detect lexically similar tweets, we
use vector similarity: We build a term vector for
both the news story and the tweet and then we
consider as a similarity measure the projection
of the tweet vector on the story vector. We do
not calculate cosine similarity, since this would
give an advantage to short tweets. We experi-
mentally set a similarity threshold above which
the tweets with URL are accepted. To define
the similarity threshold and the coefficients in the
URL ranking formula, we used a development set
of about 100 randomly selected English-language
news clusters, downloaded during a week. The
</bodyText>
<footnote confidence="0.714384">
3https://dev.twitter.com/docs/api/1/get/search
</footnote>
<bodyText confidence="0.999684714285714">
threshold and the coefficients were derived empir-
ically. We consider experimenting with SVM and
other machine-learning approaches to define these
parameters in a more consistent way.
Once the tweets that relate to the news story are
retrieved, we evaluate each URL taking into ac-
count the following parameters:
</bodyText>
<listItem confidence="0.987560333333333">
• Number of mentions, which we will desig-
nate as Mentions.
• Number of retweets, designated Retweet.
• Number of mentions in conversations, desig-
nated InConv.
• Number of times the URL was favortited,
designated Favorited.
• Number of tweets which replied to tweets,
mentioning the URL, designated ReplyTo.
</listItem>
<bodyText confidence="0.99982625">
The score of the URL is calculated using the
following empirically derived formula. The coef-
ficients were defined based on the empirical anal-
ysis described above.
</bodyText>
<equation confidence="0.998796">
score(URL) = ((Mentions−1)+Retweets.1,3
+Favorited * 4).(InConv + 2 * ReplyTo + 1)
</equation>
<bodyText confidence="0.999928166666667">
In this formula we give slight preference to the
retweets with respect to the mentions. We made
this choice, since retweets happen inside Twitter
and reflect the dynamics of the information spread
inside this social media. On the other hand, multi-
ple mentions of news-related tweets (which are not
retweeted) are due to clicking the “Share in Twit-
ter” button, which nowadays is present on most
of the news sites. In this way, news from visited
web sites appear more often in Twitter. This phe-
nomena is to be further explored. It should also be
noted that our formula boosts significantly URLs,
which are mentioned inside a conversation thread
and even more the ones, to which there were “re-
ply to” tweets. Conversations tend to be cen-
tered around topics which are of interest to Twit-
ter users and in this way they are a good indica-
tor of how interesting an URL is. Replying to a
tweet requires more time and attention than just
pressing the “Retweet” button, therefore conversa-
tions show more interest to an URL, with respect
to retweeting. Examples of tweets extracted that
complement information from mainstream media
are presented in Figure 4.
</bodyText>
<page confidence="0.996655">
27
</page>
<figureCaption confidence="0.9858615">
Figure 4: Examples of tweets extracted on the
North Korea crisis (anonimized).
</figureCaption>
<sectionHeader confidence="0.531807" genericHeader="method">
4 Sentiment Analysis on Tweets Related
to Events Reported in News
</sectionHeader>
<bodyText confidence="0.999945619047619">
After extracting the tweets related to the main
news clusters detected by the media monitoring
system, we pass them onto the sentiment analy-
sis system, where they are classified according to
their polarity (into positive, negative and neutral).
In order to classify the tweet’s sentiment, we
employ a hybrid approach based on supervised
learning with a Support Vector Machines Sequen-
tial Minimal Optimization (SVM SMO - Platt
[1998]) linear kernel, on unigram and bigram fea-
tures, but exploiting as features sentiment dictio-
naries, emoticon lists, slang lists and other social
media-specific features. We do not employ any
specific language analysis software. The aim is to
be able to apply, in a straightforward manner, the
same approach to as many languages as possible.
The approach can be extended to other languages
by using similar dictionaries that have been cre-
ated in our team.
The sentiment analysis process contains two
stages: preprocessing and sentiment classification.
</bodyText>
<subsectionHeader confidence="0.995378">
4.1 Tweet Preprocessing
</subsectionHeader>
<bodyText confidence="0.999967368421053">
The language employed in Social Media sites is
different from the one found in mainstream me-
dia and the form of the words employed is some-
times not the one we may find in a dictionary. Fur-
ther on, users of Social Media platforms employ a
special “slang” (i.e. informal language, with spe-
cial expressions, such as “lol”, “omg”), emoticons,
and often emphasize words by repeating some of
their letters. Additionally, the language employed
in Twitter has specific characteristics, such as the
markup of tweets that were reposted by other users
with “RT”, the markup of topics using the “#”
(hash sign) and of the users using the “@” sign.
All these aspects must be considered at the time
of processing tweets. As such, before applying su-
pervised learning to classify the sentiment of the
tweets, we preprocess them, to normalize the lan-
guage they contain. The preprocessing stage con-
tains the following steps:
</bodyText>
<listItem confidence="0.960874285714286">
• Repeated punctuation sign normalization.
In the first step of the preprocessing, we de-
tect repetitions of punctuation signs (“.”, “!”
and “?”). Multiple consecutive punctuation
signs are replaced with the labels “multi-
stop”, for the fullstops, “multiexclamation”
in the case of exclamation sign and “multi-
question” for the question mark and spaces
before and after.
• Emoticon replacement. In the second step
of the preprocessing, we employ the anno-
tated list of emoticons from SentiStrength4
and match the content of the tweets against
this list. The emoticons found are replaced
with their polarity (“positive” or “negative”)
and the “neutral” ones are deleted.
• Lower casing and tokenization. Subse-
quently, the tweets are lower cased and split
into tokens, based on spaces and punctuation
signs.
• Slang replacement. The next step involves
</listItem>
<bodyText confidence="0.9100316">
the normalization of the language employed.
In order to be able to include the semantics
of the expressions frequently used in Social
Media, we employed the list of slang from a
specialized site 5.
</bodyText>
<listItem confidence="0.9975325">
• Word normalization. At this stage, the to-
kens are compared to entries in Roget’s The-
saurus. If no match is found, repeated
letters are sequentially reduced to two or
one until a match is found in the dictio-
nary (e.g. “perrrrrrrrrrrrrrrrrrfeeect” becomes
“perrfeect”, “perfeect”, “perrfect” and subse-
quently “perfect”). The words used in this
form are maked as “stressed”.
• Affect word matching. Further on, the tokens
in the tweet are matched against three dif-
ferent sentiment lexicons: General Inquirer,
LIWC and MicroWNOp, which were pre-
viously split into four different categories
</listItem>
<footnote confidence="0.999748">
4http://sentistrength.wlv.ac.uk/
5http://www.chatslang.com/terms/social media
</footnote>
<page confidence="0.998579">
28
</page>
<bodyText confidence="0.936934333333333">
(“positive”, “high positive”, “negative” and
“high negative”). Matched words are re-
placed with their sentiment label - i.e. “pos-
itive”, “negative”, “hpositive” and “hnega-
tive”.
• Modifier word matching. Similar to the
previous step, we employ a list of expres-
sions that negate, intensify or diminish the
intensity of the sentiment expressed to detect
such words in the tweets. If such a word is
matched, it is replaced with “negator”, “in-
tensifier” or “diminisher”, respectively.
</bodyText>
<listItem confidence="0.900958">
• User and topic labeling. Finally, the users
</listItem>
<bodyText confidence="0.93191625">
mentioned in the tweet, which are marked
with “@”, are replaced with “PERSON” and
the topics which the tweet refers to (marked
with “#”) are replaced with “TOPIC”.
</bodyText>
<subsectionHeader confidence="0.995153">
4.2 Sentiment Classification of Tweets
</subsectionHeader>
<bodyText confidence="0.9998756">
Once the tweets are preprocessed, they are passed
on to the sentiment classification module. We em-
ployed supervised learning using SVM SMO with
a linear kernel, employing boolean features - the
presence or absence of unigrams and bigrams de-
termined from the training data (tweets that were
previousely preprocessed as described above) that
appeared at least twice. Bigrams are used espe-
cially to spot the influence of modifiers (nega-
tions, intensifiers, diminishers) on the polarity of
the sentiment-bearing words. We tested the ap-
proach on different datasets and dataset splits, us-
ing the Weka data mining software 6. The training
models are built on a cluster of computers (4 cores,
5000MB of memory each).
</bodyText>
<sectionHeader confidence="0.993428" genericHeader="evaluation">
5 Evaluation and Discussion
</sectionHeader>
<subsectionHeader confidence="0.9982755">
5.1 Evaluation of the News-Twitter Linking
Component
</subsectionHeader>
<bodyText confidence="0.9848089">
The algorithm employed to retrieve tweets simi-
lar to news clusters was evaluated by Tanev et al.
[2012]. The precision attained was 75%. Recall
cannot be computed, as the use of the Twitter API
allows only the retrieval of a subset of tweets.
In order to evaluate the link extraction compo-
nent, we randomly chose 68 URLs, extracted from
10 different news stories. For each URL, we eval-
uated its relevance to the news story in the follow-
ing way: A URL is considered relevant only if it
</bodyText>
<footnote confidence="0.881802">
6http://www.cs.waikato.ac.nz/ml/weka/
</footnote>
<bodyText confidence="0.9999638">
reports about the same news story or talks about
facts, like effects, post developments and motiva-
tions, directly related to this news story. It turned
out that 66 out of the 68 were relevant, which gives
accuracy of 97%.
</bodyText>
<subsectionHeader confidence="0.947374">
5.2 Evaluation of the Sentiment Analysis
System
</subsectionHeader>
<bodyText confidence="0.999792611111111">
In order to evaluate the sentiment analysis sys-
tem on external resources, we employed the data
provided for training in the SemEval 2013 Task
2 “Sentiment Analysis from Twitter” 7. The ini-
tial training data has been provided in two stages:
1) sample datasets for the first task and the sec-
ond task and 2) additional training data for the two
tasks. We employ the joint sample datasets as test
data (denoted as t*) and the data released subse-
quently as training data (denoted as T*). We em-
ploy the union of these two datasets to perform
cross-validation experiments (the joint dataset is
denoted as T * +t*. The characteristics of the
dataset are described in Table 1. On the last col-
umn, we also include the baseline in terms of ac-
curacy, which is computed as the number of ex-
amples of the majoritary class over the total num-
ber of examples. The results of the experiments
</bodyText>
<table confidence="0.99850225">
Data #Tweet #Pos #Neg #Neu B%
T* 19241 4779 2343 12119 62
t* 2597 700 393 1504 57
T*+t* 21838 5479 2736 13623 62
</table>
<tableCaption confidence="0.939689666666667">
Table 1: Characteristics of the training (T*), test-
ing (t*) and joint training and testing datasets.
are presented in Table 2. Given the difficulty of
</tableCaption>
<table confidence="0.999977">
Measure Train(T*) &amp; test(t*) 10-fold CV
Acc. 0.74 0.93
Ppos 0.66 0.91
Rpos 0.88 0.69
Pneg 0.94 0.62
Rneg 0.81 0.49
Pneu 0.93 0.80
Rneg 0.97 0.82
</table>
<tableCaption confidence="0.998938">
Table 2: Results in terms of accuracy and preci-
</tableCaption>
<bodyText confidence="0.553717">
sion and recall per polarity class on training and
test sets evaluation and 10-fold cross-validation.
language in social media, the results are good and
</bodyText>
<footnote confidence="0.97198">
7http://www.cs.york.ac.uk/semeval-2013/task2/
</footnote>
<page confidence="0.99862">
29
</page>
<bodyText confidence="0.946851">
useful in the context of our application (Figure 2).
</bodyText>
<sectionHeader confidence="0.99365" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999911153846154">
In this demo paper, we presented a system that
links mainstream media stories to tweets that com-
ment on the events covered. The system retrieves
relevant tweets, extracts the links they contain and
subsequently performs sentiment analysis. The
system works at a good level, giving an accurate
picture of the social media reaction to the main-
stream media stories.
As future work, we would like to extend the sys-
tem to more languages and analyze and include
new features that are particular to social media to
improve the performance of both the retrieval and
sentiment analysis components.
</bodyText>
<sectionHeader confidence="0.997598" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999826333333333">
We would like to thank the EMM team of the OP-
TIMA action at the European Commission Joint
Research Centre for the technical support.
</bodyText>
<sectionHeader confidence="0.999098" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999876529411765">
Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen
Rambow, and Rebecca Passonneau. Sentiment
analysis of twitter data. In Proceedings of LSM
2011, LSM ’11, pages 30–38, 2011.
Richa Bhayani Alec Go and Lei Huang. Twit-
ter sentiment classication using distant supervi-
sion. Technical report, Technical report, Stan-
ford University, 2009.
Hila Becker, Feiyang Chen, Dan Iter, Mor Naa-
man, and Luis Gravano. Automatic identifi-
cation and presentation of twitter content for
planned events. In Proceedings of ICWSM
2011, 2011.
J. Bollen, H. Mao, and X. Zeng. Twitter mood
predicts the stock market. Journal of Computa-
tional Science, 2011.
Xiaohua Liu, Shaodian Zhang, Furu Wei, and
Ming Zhou. Recognizing Named Entities in
Tweets. In Proceedings of ACL 2011, pages
359–367, Stroudsburg, PA, USA, 2011.
Alexander Pak and Patrick Paroubek. Twitter
based system: Using twitter for disambiguat-
ing sentiment ambiguous adjectives. In Pro-
ceedings of SemEval 2010, SemEval ’10, pages
436–439, 2010.
John C. Platt. Sequential minimal optimization:
A fast algorithm for training support vector ma-
chines. Technical report, Advances in Kernel
Methods - Support Vector Learning, 1998.
Alan Ritter, Sam Clark, Mausam, and Oren Et-
zioni. Named Entity Recognition in Tweets: An
Experimental Study. In Proceedings of EMNLP
2011, pages 1524–1534, Edinburgh, Scotland,
UK., 2011.
Hassan Saif, Yulan He, and Harith Alani. Alleviat-
ing data sparsity for twitter sentiment analysis.
In Making Sense of Microposts (#MSM2012),
pages 2–9, 2012.
Hristo Tanev, Maud Ehrmann, Jakub Piskorski,
and Vanni Zavarella. Enhancing event descrip-
tions through twitter mining. In John G. Bres-
lin, Nicole B. Ellison, James G. Shanahan, and
Zeynep Tufekci, editors, ICWSM. The AAAI
Press, 2012.
Sudha Verma, Sarah Vieweg, William Corvey,
Leysia Palen, James Martin, Martha Palmer,
Aaron Schram, and Kenneth Anderson. Natural
Language Processing to the Rescue? Extracting
”Situational Awareness”’ Tweets During Mass
Emergency. In Proceedings of ICWSM 2011,
pages 385–392. AAAI, 2011.
</reference>
<page confidence="0.998812">
30
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.209888">
<title confidence="0.99688">Detecting Event-Related Links and Sentiments from Social Media Texts</title>
<author confidence="0.544025">Balahur</author>
<affiliation confidence="0.734578">European Commission Joint Research</affiliation>
<address confidence="0.7476255">Via E. Fermi 2749, T.P. 21027 Ispra (VA),</address>
<abstract confidence="0.999037038461538">Nowadays, the importance of Social Media is constantly growing, as people often use such platforms to share mainstream media news and comment on the events that they relate to. As such, people no loger remain mere spectators to the events that happen in the world, but become part of them, commenting on their developments and the entities involved, sharing their opinions and distributing related content. This paper describes a system that links the main events detected from clusters of newspaper articles to tweets related to them, detects complementary information sources from the links they contain and subsequently applies sentiment analysis to classify them into positive, negative and neutral. In this manner, readers can follow the main events happening in the world, both from the perspective of mainstream as well as social media and the public’s perception on them. This system will be part of the EMM media monitoring framework working live and it will be demonstrated using Google</abstract>
<intro confidence="0.489781">Earth.</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Apoorv Agarwal</author>
<author>Boyi Xie</author>
<author>Ilia Vovsha</author>
<author>Owen Rambow</author>
<author>Rebecca Passonneau</author>
</authors>
<title>Sentiment analysis of twitter data.</title>
<date>2011</date>
<booktitle>In Proceedings of LSM 2011, LSM ’11,</booktitle>
<pages>30--38</pages>
<marker>Agarwal, Xie, Vovsha, Rambow, Passonneau, 2011</marker>
<rawString>Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Rambow, and Rebecca Passonneau. Sentiment analysis of twitter data. In Proceedings of LSM 2011, LSM ’11, pages 30–38, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richa Bhayani Alec Go</author>
<author>Lei Huang</author>
</authors>
<title>Twitter sentiment classication using distant supervision.</title>
<date>2009</date>
<tech>Technical report, Technical report,</tech>
<institution>Stanford University,</institution>
<marker>Go, Huang, 2009</marker>
<rawString>Richa Bhayani Alec Go and Lei Huang. Twitter sentiment classication using distant supervision. Technical report, Technical report, Stanford University, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hila Becker</author>
<author>Feiyang Chen</author>
<author>Dan Iter</author>
<author>Mor Naaman</author>
<author>Luis Gravano</author>
</authors>
<title>Automatic identification and presentation of twitter content for planned events.</title>
<date>2011</date>
<booktitle>In Proceedings of ICWSM</booktitle>
<marker>Becker, Chen, Iter, Naaman, Gravano, 2011</marker>
<rawString>Hila Becker, Feiyang Chen, Dan Iter, Mor Naaman, and Luis Gravano. Automatic identification and presentation of twitter content for planned events. In Proceedings of ICWSM 2011, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bollen</author>
<author>H Mao</author>
<author>X Zeng</author>
</authors>
<title>Twitter mood predicts the stock market.</title>
<date>2011</date>
<journal>Journal of Computational Science,</journal>
<marker>Bollen, Mao, Zeng, 2011</marker>
<rawString>J. Bollen, H. Mao, and X. Zeng. Twitter mood predicts the stock market. Journal of Computational Science, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaohua Liu</author>
<author>Shaodian Zhang</author>
<author>Furu Wei</author>
<author>Ming Zhou</author>
</authors>
<title>Recognizing Named Entities in Tweets.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL 2011,</booktitle>
<pages>359--367</pages>
<location>Stroudsburg, PA, USA,</location>
<marker>Liu, Zhang, Wei, Zhou, 2011</marker>
<rawString>Xiaohua Liu, Shaodian Zhang, Furu Wei, and Ming Zhou. Recognizing Named Entities in Tweets. In Proceedings of ACL 2011, pages 359–367, Stroudsburg, PA, USA, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Pak</author>
<author>Patrick Paroubek</author>
</authors>
<title>Twitter based system: Using twitter for disambiguating sentiment ambiguous adjectives.</title>
<date>2010</date>
<booktitle>In Proceedings of SemEval 2010, SemEval ’10,</booktitle>
<pages>436--439</pages>
<marker>Pak, Paroubek, 2010</marker>
<rawString>Alexander Pak and Patrick Paroubek. Twitter based system: Using twitter for disambiguating sentiment ambiguous adjectives. In Proceedings of SemEval 2010, SemEval ’10, pages 436–439, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John C Platt</author>
</authors>
<title>Sequential minimal optimization: A fast algorithm for training support vector machines.</title>
<date>1998</date>
<booktitle>Advances in Kernel Methods - Support Vector Learning,</booktitle>
<tech>Technical report,</tech>
<marker>Platt, 1998</marker>
<rawString>John C. Platt. Sequential minimal optimization: A fast algorithm for training support vector machines. Technical report, Advances in Kernel Methods - Support Vector Learning, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Sam Clark</author>
<author>Mausam</author>
<author>Oren Etzioni</author>
</authors>
<title>Named Entity Recognition in Tweets: An Experimental Study.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP 2011,</booktitle>
<pages>1524--1534</pages>
<location>Edinburgh, Scotland, UK.,</location>
<marker>Ritter, Clark, Mausam, Etzioni, 2011</marker>
<rawString>Alan Ritter, Sam Clark, Mausam, and Oren Etzioni. Named Entity Recognition in Tweets: An Experimental Study. In Proceedings of EMNLP 2011, pages 1524–1534, Edinburgh, Scotland, UK., 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hassan Saif</author>
</authors>
<title>Yulan He, and Harith Alani. Alleviating data sparsity for twitter sentiment analysis.</title>
<date>2012</date>
<booktitle>In Making Sense of Microposts (#MSM2012),</booktitle>
<pages>2--9</pages>
<marker>Saif, 2012</marker>
<rawString>Hassan Saif, Yulan He, and Harith Alani. Alleviating data sparsity for twitter sentiment analysis. In Making Sense of Microposts (#MSM2012), pages 2–9, 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hristo Tanev</author>
<author>Maud Ehrmann</author>
<author>Jakub Piskorski</author>
<author>Vanni Zavarella</author>
</authors>
<title>Enhancing event descriptions through twitter mining. In</title>
<date>2012</date>
<editor>John G. Breslin, Nicole B. Ellison, James G. Shanahan, and Zeynep Tufekci, editors, ICWSM.</editor>
<publisher>The AAAI Press,</publisher>
<marker>Tanev, Ehrmann, Piskorski, Zavarella, 2012</marker>
<rawString>Hristo Tanev, Maud Ehrmann, Jakub Piskorski, and Vanni Zavarella. Enhancing event descriptions through twitter mining. In John G. Breslin, Nicole B. Ellison, James G. Shanahan, and Zeynep Tufekci, editors, ICWSM. The AAAI Press, 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sudha Verma</author>
<author>Sarah Vieweg</author>
<author>William Corvey</author>
<author>Leysia Palen</author>
<author>James Martin</author>
<author>Martha Palmer</author>
<author>Aaron Schram</author>
<author>Kenneth Anderson</author>
</authors>
<title>Natural Language Processing to the Rescue? Extracting ”Situational Awareness”’ Tweets During Mass Emergency.</title>
<date>2011</date>
<booktitle>In Proceedings of ICWSM 2011,</booktitle>
<pages>385--392</pages>
<publisher>AAAI,</publisher>
<marker>Verma, Vieweg, Corvey, Palen, Martin, Palmer, Schram, Anderson, 2011</marker>
<rawString>Sudha Verma, Sarah Vieweg, William Corvey, Leysia Palen, James Martin, Martha Palmer, Aaron Schram, and Kenneth Anderson. Natural Language Processing to the Rescue? Extracting ”Situational Awareness”’ Tweets During Mass Emergency. In Proceedings of ICWSM 2011, pages 385–392. AAAI, 2011.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>