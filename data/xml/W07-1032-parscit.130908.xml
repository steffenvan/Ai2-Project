<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.9871365">
Unsupervised Learning of the Morpho-Semantic Relationship in
MEDLINE®
</title>
<author confidence="0.964484">
W. John Wilbur
</author>
<affiliation confidence="0.76831425">
National Center for Biotechnology
Information / National Library of
Medicine, National Institutes of
Health, Bethesda, MD, U.S.A.
</affiliation>
<email confidence="0.997336">
wilbur@ncbi.nlm.nih.gov
</email>
<sectionHeader confidence="0.996635" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999894684210526">
Morphological analysis as applied to Eng-
lish has generally involved the study of
rules for inflections and derivations. Recent
work has attempted to derive such rules
from automatic analysis of corpora. Here
we study similar issues, but in the context
of the biological literature. We introduce a
new approach which allows us to assign
probabilities of the semantic relatedness of
pairs of tokens that occur in text in conse-
quence of their relatedness as character
strings. Our analysis is based on over 84
million sentences that compose the MED-
LINE database and over 2.3 million token
types that occur in MEDLINE and enables
us to identify over 36 million token type
pairs which have assigned probabilities of
semantic relatedness of at least 0.7 based
on their similarity as strings.
</bodyText>
<sectionHeader confidence="0.998882" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999166468085106">
Morphological analysis is an important element
in natural language processing. Jurafsky and
Martin (2000) define morphology as the study of
the way words are built up from smaller meaning
bearing units, called morphemes. Robust tools
for morphological analysis enable one to predict
the root of a word and its syntactic class or part
of speech in a sentence. A good deal of work has
been done toward the automatic acquisition of
rules, morphemes, and analyses of words from
large corpora (Freitag, 2005; Jacquemin, 1997;
Monson, 2004; Schone and Jurafsky, 2000;
Wicentowski, 2004; Xu and Croft, 1998;
Yarowsky and Wicentowski, 2000). While this
work is important it is mostly concerned with
inflectional and derivational rules that can be
derived from the study of texts in a language.
While our interest is related to this work, we are
concerned with the multitude of tokens that ap-
pear in English texts on the subject of biology.
We believe it is clear to anyone who has exam-
ined the literature on biology that there are many
tokens that appear in textual material that are
related to each other, but not in any standard way
or by any simple rules that have general applica-
bility even in biology. It is our goal here to
achieve some understanding of when two tokens
can be said to be semantically related based on
their similarity as strings of characters.
Thus for us morphological relationship will be a
bit more general in that we wish to infer the re-
latedness of two strings based on the fact that
they have a certain substring of characters on
which they match. But we do not require to say
exactly on what part of the matching substring
their semantic relationship depends. In other
words we do not insist on the identification of
the smaller meaning bearing units or mor-
phemes. Key to our approach is the ability to
measure the contextual similarity between two
token types as well as their similarity as strings.
Neither kind of measurement is unique to our
application. Contextual similarity has been stud-
ied and applied in morphology (Jacquemin,
1997; Schone and Jurafsky, 2000; Xu and Croft,
1998; Yarowsky and Wicentowski, 2000) and
more generally (Means and others, 2004). String
</bodyText>
<page confidence="0.989059">
201
</page>
<note confidence="0.746895">
BioNLP 2007: Biological, translational, and clinical language processing, pages 201–208,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.994928842105263">
similarity has also received much attention
(Adamson and Boreham, 1974; Alberga, 1967;
Damashek, 1995; Findler and Leeuwen, 1979;
Hall and Dowling, 1980; Wilbur and Kim, 2001;
Willett, 1979; Zobel and Dart, 1995). However,
the way we use these two measurements is, to
our knowledge, new. Our approach is based on a
simple postulate: If two token types are similar
as strings, but they are not semantically related
because of their similarity, then their contextual
similarity is no greater than would be expected
for two randomly chosen token types. Based on
this observation we carry out an analysis which
allows us to assign a probability of relatedness to
pairs of token types. This proves sufficient to
generate a large repository of related token type
pairs among which are the expected inflectional
and derivationally related pairs and much more
besides.
</bodyText>
<sectionHeader confidence="0.99276" genericHeader="introduction">
2 Methodology
</sectionHeader>
<bodyText confidence="0.995522714285714">
We work with a set of 2,341,917 token types
which are the unique token types that occurred
throughout MEDLINE in the title and abstract re-
cord fields in November of 2006. These token
types do not include a set of 313 token types that
represent stop words and are removed from con-
sideration. Our analysis consists of several steps.
</bodyText>
<subsectionHeader confidence="0.999653">
2.1 Measuring Contextual Similarity
</subsectionHeader>
<bodyText confidence="0.999847147058823">
In considering the context of a token in a MED-
LINE record we do not consider all the text of
the record. In those cases when there are multi-
ple sentences in the record the text that does not
occur in the same sentence as the token may be
too distant to have any direct bearing on the in-
terpretation of the token and will in such cases
add noise to our considerations. Thus we break
the whole of MEDLINE into sentences and con-
sider the context of a token to be the additional
tokens of the sentence in which it occurs. Like-
wise the context of a token type consists of all
the additional token types that occur in all the
sentences in which it occurs. We used our own
software to identify sentence boundaries (unpub-
lished), but suspect that published and freely
available methods could equally be used for this
purpose. This produced 84,475,092 sentences
over all of MEDLINE. While there is an advan-
tage in the specificity that comes from consider-
ing context at the sentence level, this approach
also gives rise to a problem. It is not uncommon
for two terms to be related semantically, but to
never occur in the same sentence. This will hap-
pen, for example, if one term is a misspelling of
the other or if the two terms are alternate names
for the same object. Because of this we must es-
timate the context of each term without regard to
the occurrence of the other term. Then the two
estimates can be compared to compute a similar-
ity of context. This we accomplish using formu-
las of probability theory applied to our setting.
Let T denote the set of 2,341,917 token types
we consider and let t1 and t2 be two token types
</bodyText>
<equation confidence="0.946185111111111">
we wish to compare. Then we define
p t = ∑ p t i p i
c ( ) (  |) ( ) and
1 i T 1
∈p t
( ) = ∑ p t i p i
(  |) ( )
c 2 i T 2
∈
</equation>
<bodyText confidence="0.999838777777778">
Here we refer to pc (t1 ) and pc (t2) as contextual
probabilities for t1 and t2, respectively. The ex-
pressions on the right sides in (1) are given the
standard interpretations. Thus p(i) is the frac-
tion of tokens in MEDLINE that are equal to i
and p(t1  |i) is the fraction of sentences in
MEDLINE that contain i that also contain t1.
We make a similar computation for the pair of
token types
</bodyText>
<equation confidence="0.990607833333333">
pc(t1 ∧ t2) = ∑i∈Tp(t1 ∧ t2  |i)p(i)
.
=∑ p t i p t i p i
(  |) (  |) ( )
i T 1 2
∈
</equation>
<bodyText confidence="0.893781545454545">
Here we have made use of an additional assump-
tion, that given i , t1 and t2 are independent in
their probability of occurrence. While inde-
pendence is not true, this seems to be just the
right assumption for our purposes. It allows our
estimate of pc (t1 ∧ t2) to be nonzero even
though t1 and t2 may never occur together in a
sentence. In other words it allows our estimate to
reflect what context would imply if there were
no rule that says the same intended word will
almost never occur twice in a single sentence,
</bodyText>
<equation confidence="0.637922">
.
</equation>
<page confidence="0.990052">
202
</page>
<bodyText confidence="0.996944">
etc. Our contextual similarity is then the mutual
information based on contextual probabilities
&amp;quot;aaab&amp;quot; and &amp;quot;aaaaab&amp;quot; , can be represented by
the same set of features.
</bodyText>
<equation confidence="0.99742">
⎛conSim(t1, t2) = log⎜pc (t1 ∧ t2)⎞ ⎟(3)
⎝pc (t1 c 2 ⎠
</equation>
<bodyText confidence="0.91701675">
There is one minor practical difficulty with this
definition. There are many cases where pc (t1 ∧ t2)
is zero. In any such case we define conSim(t1, t2)
to be -1000.
</bodyText>
<subsectionHeader confidence="0.999979">
2.2 Measuring Lexical Similarity
</subsectionHeader>
<bodyText confidence="0.99214944">
Here we treat the two token types, t1 and t2 of
the previous section, as two ASCII strings and
ask how similar they are as strings. String simi-
larity has been studied from a number of view-
points (Adamson and Boreham, 1974; Alberga,
1967; Damashek, 1995; Findler and Leeuwen,
1979; Hall and Dowling, 1980; Wilbur and Kim,
2001; Willett, 1979; Zobel and Dart, 1995). We
avoided approaches based on edit distance or
other measures designed for spell checking be-
cause our problem requires the recognition of
relationships more distant than simple misspell-
ings. Our method is based on letter ngrams as
features to represent any string (Adamson and
Boreham, 1974; Damashek, 1995; Wilbur and
Kim, 2001; Willett, 1979). If t = &amp;quot;abcdefgh&amp;quot;
represents a token type, then we define F(t) to
be the feature set associated with t and we take
F(t) to be composed of i) all the contiguous
three character substrings “abc”, “bcd”, “cde”,
“def”, “efg”, “fgh”; ii) the specially marked first
trigram &amp;quot;abc!&amp;quot; ; and iii) the specially marked
first letter &amp;quot; a #&amp;quot; . This is the form of F(t) for
any t at least three characters long. If t consists
of only two characters, say &amp;quot; ab&amp;quot; , we take i)
&amp;quot; ab&amp;quot;; ii) &amp;quot; ab! &amp;quot;; and iii) is unchanged. If t con-
sists of only a single character &amp;quot; a&amp;quot;, we likewise
take i) “a”; ii) “a!”; and iii) is again unchanged.
Here ii) and iii) are included to allow the empha-
sis of the beginning of strings as more important
for their recognition than the remainder. We em-
phasize that F(t) is a set of features, not a “bag-
of-words”, and any duplication of features is ig-
nored. While this is a simplification, it does have
the minor drawback that different strings, e.g.,
Given that each string is represented by a set of
features, it remains to define how we compute
the similarity between two such representations.
Our basic assumption here is that the probability
p(t2 |t1), that the semantic implications of t1 are
also represented at some level in t2 , should be
represented by the fraction of the features repre-
senting t1 that also appear in t2. Of course there
is no reason that all features should be consid-
ered of equal value. Let F denote the set of all
features coming from all 2.34 million strings we
are considering. We will make the assumption
that there exists a set of weights w(f) defined
over all of f ∈ F and representing their seman-
tic importance. Then we have
</bodyText>
<equation confidence="0.9918955">
{
p(t2  |t1) = ∑ f∈ F(t1)∩F(t2) w(f)/ ∑ f∈ F(t1)w(J) . (4)
</equation>
<bodyText confidence="0.6598245">
Based on (4) we define the lexical similarity of
two token types as
</bodyText>
<equation confidence="0.983419">
lexSim(t1,t2)=(p(t2 |t1)+p(t1 |t2))/2 (5)
</equation>
<bodyText confidence="0.999833375">
In our initial application of lexSim we take as
weights the so-called inverse document fre-
quency weights that are commonly used in in-
formation retrieval (Sparck Jones, 1972). If
N = 2,341,917, the number of token types, and
for any feature f , n f represents the number of
token types with the feature f , the inverse
document frequency weight is
</bodyText>
<equation confidence="0.9698018">
⎛ ⎞
N . (6)
⎜ ⎟
⎝ ⎠
nf
</equation>
<bodyText confidence="0.99627875">
This weight is based on the observation that very
frequent features tend not to be very important, but
importance increases on the average as frequency
decreases.
</bodyText>
<subsectionHeader confidence="0.999733">
2.3 Estimating Semantic Relatedness
</subsectionHeader>
<bodyText confidence="0.96684025">
The first step is to compute the distribution of
conSim(t1, t2) over a large random sample of
pairs of token types t1 and t 2. For this purpose
we computed conSim(t1, t2) over a random
</bodyText>
<equation confidence="0.779557333333333">
w f
( ) log
=
</equation>
<page confidence="0.988062">
203
</page>
<bodyText confidence="0.954881">
sample of 302,515 pairs. This resulted in the
value -1000, 180,845 times (60% of values).
The remainder of the values, based on nonzero
pc (t1 ∧ t2) are distributed as shown in Figure 1.
Let τ denote the probability density for
conSim(t1, t2) over random pairs t1 and t2 . Let
Sem(t1,t2) denote the predicate that asserts that t1
and t2 are semantically related. Then our main
assumption which underlies the method is
Postulate. For any nonnegative real number r
</bodyText>
<figure confidence="0.9628217">
Q ={ conSim(t„t2)  |lexSim(t„t2) &gt; r ∧ ¬Sem(t1,t2)} (7)
Distribution of conSim Values
10000
8000
6000
4000
2000
0
-3 -1 1 3 5 7
conSim
</figure>
<figureCaption confidence="0.94821">
Figure 1. Distribution of conSim values for the
40% of randomly selected token type pairs
which gave values above -1000, i.e., for which
</figureCaption>
<equation confidence="0.657694">
pc (t1 ∧ t2) &gt; 0.
</equation>
<bodyText confidence="0.650306875">
has probability density function equal to τ .
This postulate says that if you have two token
types that have some level of similarity as strings
( lexSim(t1, t2) &gt; r ) but which are not semantically
related, then lexSim(t1,t2) &gt; r is just an accident
and it provides no information about
conSim(t1, t2) .
The next step is to consider a pair of real numbers
</bodyText>
<equation confidence="0.924231333333333">
0 ≤ r1 &lt; r2 and the set
S(r1,r2) = ( t 1,t 2 )  |r 1 ≤ lexSim(t1,t 2 ) &lt; r2} (8)
{
</equation>
<bodyText confidence="0.992025923076923">
they define. We will refer to such a set as a lexSim
slice. According to our postulate the subset of
S(r1,r2) which are pairs of tokens without a se-
mantic relationship will produce conSim values
obeying the τ density. We compute the conSim
values and assume that all of those pairs that pro-
duce a conSim value of -1000 represent pairs that
are unrelated semantically. As an example, in one
of our computations we computed a slice
S(0.7,0.725) and found the lexSim value -1000
produced 931,042 times. In comparing this with
the random sample which produced 180,845 values
of -1000, we see that
</bodyText>
<equation confidence="0.877362">
931,042 180,845 = 5.148 (9)
</equation>
<bodyText confidence="0.999817954545455">
So we need to multiply the frequency distribution
for the random sample (shown in Figure 1) by
5.148 to represent the part of the slice
S(0.7,0.725) that represents pairs not semantically
related. This situation is illustrated in Figure 2.
Two observations are important here. First, the two
curves match almost perfectly along their left
edges for conSim values below zero. This suggests
that sematically related pairs do not produce con-
Sim scores below about -1 and adds some credibil-
ity to our assumption that semantically related
pairs do not produce conSim values of -1000. The
second observation is that while the higher graph
in Figure 2 represents all pairs in the lexSim slice
and the lower graph all pairs that are not semanti-
cally related, we do not know which pairs are not
semantically related. We can only estimate the
probability of any pair at a particular conSim score
level being semantically related. If we let Ψ rep-
resent the upper curve coming from the lexSim
slice and Φ the lower curve coming from the ran-
dom sample, then (10) represents the probability
</bodyText>
<equation confidence="0.999922">
p(x) = Ψ(x)− Φ(x) (10)
Ψ ( x)
</equation>
<bodyText confidence="0.996004571428571">
that a token type pair with a conSim score of x is a
semantically related pair. Curve fitting or regres-
sion methods can be used to estimate p . Since it is
reasonable to expect p to be a nondecreasing
function of its argument, we use isotonic regres-
sion to make our estimates. For a full analysis we
set
</bodyText>
<equation confidence="0.84049">
ri=0.5+i× 0.025 (11)
Frequency
</equation>
<page confidence="0.986585">
204
</page>
<bodyText confidence="0.933985">
and consider the set of lexSim slices { ( i , i ) i
</bodyText>
<equation confidence="0.920013">
}20
S r r+
1 = 0
</equation>
<bodyText confidence="0.987603">
and determine the corresponding set of probability
</bodyText>
<equation confidence="0.978683">
functions { }20
p = .
i i 0
</equation>
<subsectionHeader confidence="0.997742">
2.4 Learned Weights
</subsectionHeader>
<bodyText confidence="0.957407833333333">
Our initial step was to use the IDF weights defined
in equation (6) and compute a database of all non-
identical token type pairs among the 2,341,917
token types occurring in MEDLINE for which
lexSim(t1,t2) ≥ 0.5. We focus on the value 0.5 be-
cause the similarity measure lexSim has the
</bodyText>
<subsectionHeader confidence="0.542265">
Comparison of Histograms
</subsectionHeader>
<figureCaption confidence="0.9976492">
Figure 2. The distribution based on the random sample
of pairs represents those pairs in the slice that are not
semantically related, while the portion between the two
curves represents the number of semantically related
pairs.
</figureCaption>
<bodyText confidence="0.96360845">
property that if one of t1 or t2 is an initial seg-
ment of the other (e.g., ‘glucuron’ is an initial
segment of ‘glucuronidase’) then
lexSim(t1,t2) ≥ 0.5 will be satisfied regardless of
the set of weights used. The resulting data in-
cluded the lexSim and the conSim scores and
consisted of 141,164,755 pairs. We performed a
complete slice analysis of this data and based on
the resulting probability estimates 20,681,478
pairs among the 141,164,755 total had a prob-
ability of being semantically related which was
greater than or equal to 0.7. While this seems
like a very useful result, there is reason to be-
lieve the IDF weights used to compute lexSim
are far from optimal. In an attempt to improve
the weighting we divided the 141,164,755 pairs
into C−1 consisting of 68,912,915 pairs with a
conSim score of -1000 and C1 consisting of the
remaining 72,251,839 pairs. Letting wG denote
the vector of weights we defined a cost function
</bodyText>
<equation confidence="0.9997919">
Λ(w) = ∑ −log
( , )
t t C
1 2 1
∈ ( lexSim t t
( , ))
1 2
( 1 − lexSim t t
( , ))
1 2
</equation>
<bodyText confidence="0.980846184210526">
and carried out a minimization of Λ to obtain a
set of learned weights which we will denote by
w0 . The minimization was done using the L-
BFGS algorithm (Nash and Nocedal, 1991).
Since it is important to avoid negative weights
we associate a potential v(f) with each ngram
feature f and set
w(f ) = exp(v(f )) . (13)
The optimization is carried out using the poten-
tials.
The optimization can be understood as an at-
tempt to make lexSim as close to zero as possible
on the large set C−1 where conSim = −1000 and
we have assumed there are no semantically re-
lated pairs, while at the same time making lex-
Sim large on the remainder. While this seems
reasonable as a first step it is not conservative as
many pairs in C1 will not be semantically re-
lated. Because of this we would expect that
there are ngrams for which we have learned
weights that are not really appropriate outside of
the set of 141,164,755 pairs on which we
trained. If there are such, presumably the most
important cases would be those where we would
score pairs with inappropriately high lexSim
scores. Our approach to correct for this possibil-
ity is to add to the initial database of
141,164,755 pairs all additional pairs which pro-
duced a lexSim(t1,t2)≥0.5 based on the new
weight set w0
G . This augmented the data to a new
set of 223,051,360 pairs with conSim scores. We
then applied our learning scheme based on
minimization of the function Λ to learn a new
set of weights w1
G . There was one difference.
Here and in all subsequent rounds we chose to
define C−1 as all those pairs with
</bodyText>
<figure confidence="0.97445825">
-4 -2 0 2 4 6 8 10
conSim
Frequency
80000
60000
40000
20000
0
Random Sample x 5.148
lexSim Slice S(0.7,0.725)
+ ∑ ( , )
t t C
∈
1 2 − 1
log
(12)
</figure>
<page confidence="0.954878">
205
</page>
<bodyText confidence="0.935436588235294">
conSim(t1,t2)&lt;_0 and C1 those pairs with
conSim(t1,t2) &gt; 0. We take this to be a conserva-
tive approach as one would expect semantically
related pairs to have a similar context and satisfy
conSim(t1, t2) &gt; 0 and graphs such as Figure 2
support this. In any case we view this as a con-
servative move and calculated to produce fewer
false positives based on lexSim score recommen-
dations of semantic relatedness. We actually go
through repeated rounds of training and adding
new pairs to the set of pairs. This process is con-
vergent as we reach a point where the weights
learned on the set of pairs does not result in the
addition of a significant amount of new material.
This happened with weight set w4
� and a total
accumulation of 440.4 million token type pairs.
</bodyText>
<tableCaption confidence="0.964660666666667">
Table 1. Number of token pairs and the level of
their predicted probability of semantic related-
ness found with three different weight sets.
</tableCaption>
<table confidence="0.999430428571429">
Weight Prob. Se- Prob. Se- Prob. Se-
Set mantically mantically mantically
Related Related Related
&gt;_ 0.7 &gt;_ 0.8 &gt;_ 0.9
_rV4 36,173,520 22,381,318 10,805,085
Constant 34,667,988 20,282,976 8,607,863
IDF 31,617,441 18,769,424 8,516,329
</table>
<sectionHeader confidence="0.960434" genericHeader="method">
3 Probability Predictions
</sectionHeader>
<bodyText confidence="0.9943949">
Based on the learned weight set w4
� we per-
formed a slice analysis of the 440 million token
pairs on which the weights were learned and ob-
tained a set of 36,173,520 token pairs with pre-
dicted probabilities of being semantically related
of 0.7 or greater. We performed the same slice
analysis on this 440 million token pair set with
the IDF weights and the set of constant weights
all equal to 1. The results are given in Table 1.
Here it is interesting to note that the constant
weights perform substantially better than the IDF
weights and come close to the performance of
the w4 weights. While the w4 predicted about
1.5 million more relationships at the 0.7 prob-
ability level, it is also interesting to note that the
difference between the w4
� and constant weights
actually increases as one goes to higher probabil-
ity levels so that the learned weights allow us to
</bodyText>
<tableCaption confidence="0.992835833333333">
Table 2. A table showing 30 out of a total of 379
tokens predicted to be semantically related to
‘lacz’ and the estimated probabilities. Ten en-
tries are from the beginning of the list, ten from
the middle, and ten from the end. Breaks where
data was omitted are marked with asterisks.
</tableCaption>
<table confidence="0.999750742857143">
Probability Token 1 Token 2
Semantic
Relation
0.973028 lacz &apos;lacz
0.975617 lacz 010cblacz
0.963364 lacz 010cmvlacz
0.935771 lacz 07lacz
0.847727 lacz 110cmvlacz
0.851617 lacz 1716lacz
0.90737 lacz 1acz
0.9774 lacz 1hsplacz
0.762373 lacz 27lacz
0.974001 lacz 2hsplacz
*** *** ***
0.95951 lacz laczalone
0.95951 lacz laczalpha
0.989079 lacz laczam
0.920344 lacz laczam15
0.903068 lacz laczamber
0.911691 lacz laczatttn7
0.975162 lacz laczbg
0.953791 lacz laczbgi
0.995333 lacz laczbla
0.991714 lacz laczc141
*** *** ***
0.979416 lacz ul42lacz
0.846753 lacz veroicp6lacz
0.985656 lacz vglacz1
0.987626 lacz vm5lacz
0.856636 lacz vm5neolacz
0.985475 lacz vtkgpedeltab8rlacz
0.963028 lacz vttdeltab8rlacz
0.993296 lacz wlacz
0.990673 lacz xlacz
0.946067 lacz zflacz
</table>
<bodyText confidence="0.84140825">
predict over 2 million more relationships at the
0.9 level of reliability. This is more than a 25%
increase at this high reliability level and justifies
the extra effort in learning the weights.
</bodyText>
<page confidence="0.999118">
206
</page>
<tableCaption confidence="0.960341857142857">
Table 3. A table showing 30 out of a total of 96
tokens predicted to be semantically related to
‘nociception’ and the estimated probabilities.
Ten entries are from the beginning of the list,
ten from the middle, and ten from the end.
Breaks where data was omitted are marked
with asterisks.
</tableCaption>
<table confidence="0.999566628571429">
Probability Token 1 Token 2
Semantic
Relation
0.727885 nociception actinociception
0.90132 nociception actinociceptive
0.848615 nociception anticociception
0.89437 nociception anticociceptive
0.880249 nociception antincociceptive
0.82569 nociception antinoceiception
0.923254 nociception antinociceptic
0.953812 nociception antinociceptin
0.920291 nociception antinociceptio
0.824706 nociception antinociceptions
*** *** ***
0.802133 nociception nociceptice
0.985352 nociception nociceptin
0.940022 nociception nociceptin&apos;s
0.930218 nociception nociceptine
0.944004 nociception nociceptinerg
0.882768 nociception nociceptinergic
0.975783 nociception nociceptinnh2
0.921745 nociception nociceptins
0.927747 nociception nociceptiometric
0.976135 nociception nociceptions
*** *** ***
0.88983 nociception subnociceptive
0.814733 nociception thermoantinociception
0.939505 nociception thermonociception
0.862587 nociception thermonociceptive
0.810878 nociception thermonociceptor
0.947374 nociception thermonociceptors
0.81756 nociception tyr14nociceptin
0.981115 nociception visceronociception
0.957359 nociception visceronociceptive
0.862587 nociception withnociceptin
</table>
<bodyText confidence="0.993429772727273">
A sample of the learned relationships based on
the w4
G weights is contained in
Table 2 and Table 3. The symbol ‘lacz’ stands
for a well known and much studied gene in the
E. coli bacterium. Due to its many uses it has
given rise to myriad strings representing differ-
ent aspects of molecules, systems, or method-
ologies derived from or related to it. The results
are not typical of the inflectional or derivational
methods generally found useful in studying the
morphology of English. Some might represent
misspellings, but this is not readily apparent by
examining them. On the other hand ‘nocicep-
tion’ is an English word found in a dictionary
and meaning “a measurable physiological event
of a type usually associated with pain and agony
and suffering” (Wikepedia). The data in Table 3
shows that ‘nociception’ is related to the
expected inflectional and derivational forms,
forms with affixes unique to biology, readily
apparent misspellings, and foreign analogs.
</bodyText>
<sectionHeader confidence="0.998527" genericHeader="method">
4 Discussion &amp; Conclusions
</sectionHeader>
<bodyText confidence="0.999961606060606">
There are several possible uses for the type of
data produced by our analysis. Words semanti-
cally related to a query term or terms typed by a
search engine user can provide a useful query
expansion in either an automatic mode or with
the user selecting from a displayed list of options
for query expansion. Many misspellings occur in
the literature and are disambiguated in the token
pairs produced by the analysis. They can be rec-
ognized as closely related low frequency-high
frequency pairs. They may allow better curation
of the literature on the one hand or improved
spelling correction of user queries on the other.
In the area of more typical language analysis, a
large repository of semantically related pairs can
contribute to semantic tagging of text and ulti-
mately to better performance on the semantic
aspects of parsing. Also the material we have
produced can serve as a rich source of morpho-
logical information. For example, inflectional
and derivational transformations applicable to
the technical language of biology are well repre-
sented in the data.
There is the possibility of improving on the
methods we have used, while still applying the
general approach. Either a more sensitive con-
Sim or ZexSim measure or both could lead to su-
perior results. While it is unclear to us how con-
Sim might be improved, it seems there is more
potential with ZexSim. ZexSim treats features as
basically independent contributors to the similar-
ity of token types and this is not ideal. For ex-
ample the feature ‘hiv’ usually refers to the hu-
</bodyText>
<page confidence="0.990985">
207
</page>
<bodyText confidence="0.8963160625">
man immunodeficiency virus. However, if ‘ive’
is also a feature of the token we may well be
dealing with the word ‘hive’ which has no rela-
tion to a human immunodeficiency virus. Thus a
more complicated model of the lexical similarity
of strings could result in improved recognition of
semantically related strings.
In future work we hope to investigate the applica-
tion of the approach we have developed to multi-
token terms. We also hope to investigate the possi-
bility of more sensitive lexSim measures for im-
proved performance.
Acknowledgment This research was supported by
the Intramural Research Program of the National Center
for Biotechnology Information, National Library of
Medicine, NIH, Bethesda, MD, USA.
</bodyText>
<sectionHeader confidence="0.975753" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999885443037975">
Adamson, G. W., and Boreham, J. 1974. The use of an
association measure based on character structure to
identify semantically related pairs of words and
document titles. Information Storage and Retrieval,
10: 253-260.
Alberga, C. N. 1967. String similarity and misspellings.
Communications of the ACM, 10: 302-313.
Damashek, M. 1995. Gauging similarity with n-grams:
Language-independent categorization of text. Sci-
ence, 267: 843-848.
Findler, N. V., and Leeuwen, J. v. 1979. A family of
similarity measures between two strings. IEEE
Transactions on Pattern Analysis and Machine Intel-
ligence, PAMI-1: 116-119.
Freitag, D. 2005. Morphology Induction From Term
Clusters, 9th Conference on Computational Natural
Language Learning (CoNLL): Ann Arbor, Michigan,
Association for Computational Linguistics.
Hall, P. A., and Dowling, G. R. 1980. Approximate
string matching. Computing Surveys, 12: 381-402.
Jacquemin, C. 1997. Guessing morphology from terms
and corpora, in Belkin, N. J., Narasimhalu, A. D.,
and Willett, P., editors, 20th Annual International
ACM SIGIR Conference on Research and Develop-
ment in Information Retrieval: Philadelphia, PA,
ACM Press, p. 156-165.
Jurafsky, D., and Martin, J. H. 2000. Speech and Lan-
guage Processing: Upper Saddle River, New Jersey,
Prentice Hall.
Means, R. W., Nemat-Nasser, S. C., Fan, A. T., and
Hecht-Nielsen, R. 2004. A Powerful and General
Approach to Context Exploitation in Natural Lan-
guage Processing, HLT-NAACL 2004: Workshop on
Computational Lexical Semantics Boston, Massachu-
setts, USA, Association for Computational Linguis-
tics.
Monson, C. 2004. A framework for unsupervised natu-
ral language morphology induction, Proceedings of
the ACL 2004 on Student research workshop: Barce-
lona, Spain, Association for Computational Linguis-
tics.
Nash, S. G., and Nocedal, J. 1991. A numerical study of
hte limited memory BFGS method and hte truncated-
Newton method for large scale optimization. SIAM
Journal of Optimization, 1: 358-372.
Schone, P., and Jurafsky, D. 2000. Knowledge-free in-
duction of morphology using latent semantic analy-
sis, Proceedings of the 2nd workshop on Learning
language in logic and the 4th conference on Compu-
tational natural language learning - Volume 7: Lis-
bon, Portugal, Association for Computational Lin-
guistics.
Sparck Jones, K. 1972. A statistical interpretation of
term specificity and its application in retrieval. The
Journal of Documentation, 28: 11-21.
Wicentowski, R. 2004. Multilingual Noise-Robust Su-
pervised Morphological Analysis using the Word-
Frame Model, SIGPHON: Barcelona, Spain, Asso-
ciation for Computational Linguistics.
Wilbur, W. J., and Kim, W. 2001. Flexible phrase based
query handling algorithms, in Aversa, E., and Man-
ley, C., editors, Proceedings of the ASIST 2001 An-
nual Meeting: Washington, D.C., Information Today,
Inc., p. 438-449.
Willett, P. 1979. Document retrieval experiments using
indexing vocabularies of varying size. II. Hashing,
truncation, digram and trigram encoding of index
terms. Journal of Documentation, 35: 296-305.
Xu, J., and Croft, W. B. 1998. Corpus-based stemming
using cooccurrence of word variants. ACM TOIS,
16: 61-81.
Yarowsky, D., and Wicentowski, R. 2000. Minimally
supervised morphological analysis by multimodal
alignment, Proceedings of the 38th Annual Meeting
on Association for Computational Linguistics: Hong
Kong, Association for Computational Linguistics.
Zobel, J., and Dart, P. 1995. Finding approximate
matches in large lexicons. Software-Practice and Ex-
perience, 25: 331-345.
</reference>
<page confidence="0.997783">
208
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.829613">
<title confidence="0.998146">Unsupervised Learning of the Morpho-Semantic Relationship in</title>
<author confidence="0.99859">W John</author>
<affiliation confidence="0.944479666666667">National Center for Information / National Library Medicine, National Institutes</affiliation>
<address confidence="0.998698">Health, Bethesda, MD, U.S.A.</address>
<email confidence="0.998863">wilbur@ncbi.nlm.nih.gov</email>
<abstract confidence="0.9996218">Morphological analysis as applied to English has generally involved the study of rules for inflections and derivations. Recent work has attempted to derive such rules from automatic analysis of corpora. Here we study similar issues, but in the context of the biological literature. We introduce a new approach which allows us to assign probabilities of the semantic relatedness of pairs of tokens that occur in text in consequence of their relatedness as character strings. Our analysis is based on over 84 million sentences that compose the MED- LINE database and over 2.3 million token types that occur in MEDLINE and enables us to identify over 36 million token type pairs which have assigned probabilities of semantic relatedness of at least 0.7 based on their similarity as strings.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G W Adamson</author>
<author>J Boreham</author>
</authors>
<title>The use of an association measure based on character structure to identify semantically related pairs of words and document titles.</title>
<date>1974</date>
<journal>Information Storage and Retrieval,</journal>
<volume>10</volume>
<pages>253--260</pages>
<contexts>
<context position="3475" citStr="Adamson and Boreham, 1974" startWordPosition="558" endWordPosition="561">roach is the ability to measure the contextual similarity between two token types as well as their similarity as strings. Neither kind of measurement is unique to our application. Contextual similarity has been studied and applied in morphology (Jacquemin, 1997; Schone and Jurafsky, 2000; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000) and more generally (Means and others, 2004). String 201 BioNLP 2007: Biological, translational, and clinical language processing, pages 201–208, Prague, June 2007. c�2007 Association for Computational Linguistics similarity has also received much attention (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). However, the way we use these two measurements is, to our knowledge, new. Our approach is based on a simple postulate: If two token types are similar as strings, but they are not semantically related because of their similarity, then their contextual similarity is no greater than would be expected for two randomly chosen token types. Based on this observation we carry out an analysis which allows us to assign a probability of relatedness to pairs of to</context>
<context position="8028" citStr="Adamson and Boreham, 1974" startWordPosition="1422" endWordPosition="1425">ual similarity is then the mutual information based on contextual probabilities &amp;quot;aaab&amp;quot; and &amp;quot;aaaaab&amp;quot; , can be represented by the same set of features. ⎛conSim(t1, t2) = log⎜pc (t1 ∧ t2)⎞ ⎟(3) ⎝pc (t1 c 2 ⎠ There is one minor practical difficulty with this definition. There are many cases where pc (t1 ∧ t2) is zero. In any such case we define conSim(t1, t2) to be -1000. 2.2 Measuring Lexical Similarity Here we treat the two token types, t1 and t2 of the previous section, as two ASCII strings and ask how similar they are as strings. String similarity has been studied from a number of viewpoints (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). We avoided approaches based on edit distance or other measures designed for spell checking because our problem requires the recognition of relationships more distant than simple misspellings. Our method is based on letter ngrams as features to represent any string (Adamson and Boreham, 1974; Damashek, 1995; Wilbur and Kim, 2001; Willett, 1979). If t = &amp;quot;abcdefgh&amp;quot; represents a token type, then we define F(t) to be the feature set associated with t and we</context>
</contexts>
<marker>Adamson, Boreham, 1974</marker>
<rawString>Adamson, G. W., and Boreham, J. 1974. The use of an association measure based on character structure to identify semantically related pairs of words and document titles. Information Storage and Retrieval, 10: 253-260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C N Alberga</author>
</authors>
<title>String similarity and misspellings.</title>
<date>1967</date>
<journal>Communications of the ACM,</journal>
<volume>10</volume>
<pages>302--313</pages>
<contexts>
<context position="3490" citStr="Alberga, 1967" startWordPosition="562" endWordPosition="563">sure the contextual similarity between two token types as well as their similarity as strings. Neither kind of measurement is unique to our application. Contextual similarity has been studied and applied in morphology (Jacquemin, 1997; Schone and Jurafsky, 2000; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000) and more generally (Means and others, 2004). String 201 BioNLP 2007: Biological, translational, and clinical language processing, pages 201–208, Prague, June 2007. c�2007 Association for Computational Linguistics similarity has also received much attention (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). However, the way we use these two measurements is, to our knowledge, new. Our approach is based on a simple postulate: If two token types are similar as strings, but they are not semantically related because of their similarity, then their contextual similarity is no greater than would be expected for two randomly chosen token types. Based on this observation we carry out an analysis which allows us to assign a probability of relatedness to pairs of token types. This</context>
<context position="8043" citStr="Alberga, 1967" startWordPosition="1426" endWordPosition="1427">mutual information based on contextual probabilities &amp;quot;aaab&amp;quot; and &amp;quot;aaaaab&amp;quot; , can be represented by the same set of features. ⎛conSim(t1, t2) = log⎜pc (t1 ∧ t2)⎞ ⎟(3) ⎝pc (t1 c 2 ⎠ There is one minor practical difficulty with this definition. There are many cases where pc (t1 ∧ t2) is zero. In any such case we define conSim(t1, t2) to be -1000. 2.2 Measuring Lexical Similarity Here we treat the two token types, t1 and t2 of the previous section, as two ASCII strings and ask how similar they are as strings. String similarity has been studied from a number of viewpoints (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). We avoided approaches based on edit distance or other measures designed for spell checking because our problem requires the recognition of relationships more distant than simple misspellings. Our method is based on letter ngrams as features to represent any string (Adamson and Boreham, 1974; Damashek, 1995; Wilbur and Kim, 2001; Willett, 1979). If t = &amp;quot;abcdefgh&amp;quot; represents a token type, then we define F(t) to be the feature set associated with t and we take F(t) to b</context>
</contexts>
<marker>Alberga, 1967</marker>
<rawString>Alberga, C. N. 1967. String similarity and misspellings. Communications of the ACM, 10: 302-313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Damashek</author>
</authors>
<title>Gauging similarity with n-grams: Language-independent categorization of text.</title>
<date>1995</date>
<journal>Science,</journal>
<volume>267</volume>
<pages>843--848</pages>
<contexts>
<context position="3506" citStr="Damashek, 1995" startWordPosition="564" endWordPosition="565">tual similarity between two token types as well as their similarity as strings. Neither kind of measurement is unique to our application. Contextual similarity has been studied and applied in morphology (Jacquemin, 1997; Schone and Jurafsky, 2000; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000) and more generally (Means and others, 2004). String 201 BioNLP 2007: Biological, translational, and clinical language processing, pages 201–208, Prague, June 2007. c�2007 Association for Computational Linguistics similarity has also received much attention (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). However, the way we use these two measurements is, to our knowledge, new. Our approach is based on a simple postulate: If two token types are similar as strings, but they are not semantically related because of their similarity, then their contextual similarity is no greater than would be expected for two randomly chosen token types. Based on this observation we carry out an analysis which allows us to assign a probability of relatedness to pairs of token types. This proves sufficie</context>
<context position="8059" citStr="Damashek, 1995" startWordPosition="1428" endWordPosition="1429">ion based on contextual probabilities &amp;quot;aaab&amp;quot; and &amp;quot;aaaaab&amp;quot; , can be represented by the same set of features. ⎛conSim(t1, t2) = log⎜pc (t1 ∧ t2)⎞ ⎟(3) ⎝pc (t1 c 2 ⎠ There is one minor practical difficulty with this definition. There are many cases where pc (t1 ∧ t2) is zero. In any such case we define conSim(t1, t2) to be -1000. 2.2 Measuring Lexical Similarity Here we treat the two token types, t1 and t2 of the previous section, as two ASCII strings and ask how similar they are as strings. String similarity has been studied from a number of viewpoints (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). We avoided approaches based on edit distance or other measures designed for spell checking because our problem requires the recognition of relationships more distant than simple misspellings. Our method is based on letter ngrams as features to represent any string (Adamson and Boreham, 1974; Damashek, 1995; Wilbur and Kim, 2001; Willett, 1979). If t = &amp;quot;abcdefgh&amp;quot; represents a token type, then we define F(t) to be the feature set associated with t and we take F(t) to be composed of i)</context>
</contexts>
<marker>Damashek, 1995</marker>
<rawString>Damashek, M. 1995. Gauging similarity with n-grams: Language-independent categorization of text. Science, 267: 843-848.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N V Findler</author>
<author>J v Leeuwen</author>
</authors>
<title>A family of similarity measures between two strings.</title>
<date>1979</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>1</volume>
<pages>116--119</pages>
<contexts>
<context position="3533" citStr="Findler and Leeuwen, 1979" startWordPosition="566" endWordPosition="569">between two token types as well as their similarity as strings. Neither kind of measurement is unique to our application. Contextual similarity has been studied and applied in morphology (Jacquemin, 1997; Schone and Jurafsky, 2000; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000) and more generally (Means and others, 2004). String 201 BioNLP 2007: Biological, translational, and clinical language processing, pages 201–208, Prague, June 2007. c�2007 Association for Computational Linguistics similarity has also received much attention (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). However, the way we use these two measurements is, to our knowledge, new. Our approach is based on a simple postulate: If two token types are similar as strings, but they are not semantically related because of their similarity, then their contextual similarity is no greater than would be expected for two randomly chosen token types. Based on this observation we carry out an analysis which allows us to assign a probability of relatedness to pairs of token types. This proves sufficient to generate a large repo</context>
<context position="8086" citStr="Findler and Leeuwen, 1979" startWordPosition="1430" endWordPosition="1433">textual probabilities &amp;quot;aaab&amp;quot; and &amp;quot;aaaaab&amp;quot; , can be represented by the same set of features. ⎛conSim(t1, t2) = log⎜pc (t1 ∧ t2)⎞ ⎟(3) ⎝pc (t1 c 2 ⎠ There is one minor practical difficulty with this definition. There are many cases where pc (t1 ∧ t2) is zero. In any such case we define conSim(t1, t2) to be -1000. 2.2 Measuring Lexical Similarity Here we treat the two token types, t1 and t2 of the previous section, as two ASCII strings and ask how similar they are as strings. String similarity has been studied from a number of viewpoints (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). We avoided approaches based on edit distance or other measures designed for spell checking because our problem requires the recognition of relationships more distant than simple misspellings. Our method is based on letter ngrams as features to represent any string (Adamson and Boreham, 1974; Damashek, 1995; Wilbur and Kim, 2001; Willett, 1979). If t = &amp;quot;abcdefgh&amp;quot; represents a token type, then we define F(t) to be the feature set associated with t and we take F(t) to be composed of i) all the contiguous three c</context>
</contexts>
<marker>Findler, Leeuwen, 1979</marker>
<rawString>Findler, N. V., and Leeuwen, J. v. 1979. A family of similarity measures between two strings. IEEE Transactions on Pattern Analysis and Machine Intelligence, PAMI-1: 116-119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Freitag</author>
</authors>
<title>Morphology Induction From Term Clusters,</title>
<date>2005</date>
<booktitle>9th Conference on Computational Natural Language Learning (CoNLL): Ann Arbor,</booktitle>
<institution>Michigan, Association for Computational Linguistics.</institution>
<contexts>
<context position="1551" citStr="Freitag, 2005" startWordPosition="241" endWordPosition="242">ned probabilities of semantic relatedness of at least 0.7 based on their similarity as strings. 1 Introduction Morphological analysis is an important element in natural language processing. Jurafsky and Martin (2000) define morphology as the study of the way words are built up from smaller meaning bearing units, called morphemes. Robust tools for morphological analysis enable one to predict the root of a word and its syntactic class or part of speech in a sentence. A good deal of work has been done toward the automatic acquisition of rules, morphemes, and analyses of words from large corpora (Freitag, 2005; Jacquemin, 1997; Monson, 2004; Schone and Jurafsky, 2000; Wicentowski, 2004; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000). While this work is important it is mostly concerned with inflectional and derivational rules that can be derived from the study of texts in a language. While our interest is related to this work, we are concerned with the multitude of tokens that appear in English texts on the subject of biology. We believe it is clear to anyone who has examined the literature on biology that there are many tokens that appear in textual material that are related to each other, but</context>
</contexts>
<marker>Freitag, 2005</marker>
<rawString>Freitag, D. 2005. Morphology Induction From Term Clusters, 9th Conference on Computational Natural Language Learning (CoNLL): Ann Arbor, Michigan, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P A Hall</author>
<author>G R Dowling</author>
</authors>
<title>Approximate string matching.</title>
<date>1980</date>
<journal>Computing Surveys,</journal>
<volume>12</volume>
<pages>381--402</pages>
<contexts>
<context position="3557" citStr="Hall and Dowling, 1980" startWordPosition="570" endWordPosition="573">well as their similarity as strings. Neither kind of measurement is unique to our application. Contextual similarity has been studied and applied in morphology (Jacquemin, 1997; Schone and Jurafsky, 2000; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000) and more generally (Means and others, 2004). String 201 BioNLP 2007: Biological, translational, and clinical language processing, pages 201–208, Prague, June 2007. c�2007 Association for Computational Linguistics similarity has also received much attention (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). However, the way we use these two measurements is, to our knowledge, new. Our approach is based on a simple postulate: If two token types are similar as strings, but they are not semantically related because of their similarity, then their contextual similarity is no greater than would be expected for two randomly chosen token types. Based on this observation we carry out an analysis which allows us to assign a probability of relatedness to pairs of token types. This proves sufficient to generate a large repository of related token </context>
<context position="8110" citStr="Hall and Dowling, 1980" startWordPosition="1434" endWordPosition="1437">&amp;quot; and &amp;quot;aaaaab&amp;quot; , can be represented by the same set of features. ⎛conSim(t1, t2) = log⎜pc (t1 ∧ t2)⎞ ⎟(3) ⎝pc (t1 c 2 ⎠ There is one minor practical difficulty with this definition. There are many cases where pc (t1 ∧ t2) is zero. In any such case we define conSim(t1, t2) to be -1000. 2.2 Measuring Lexical Similarity Here we treat the two token types, t1 and t2 of the previous section, as two ASCII strings and ask how similar they are as strings. String similarity has been studied from a number of viewpoints (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). We avoided approaches based on edit distance or other measures designed for spell checking because our problem requires the recognition of relationships more distant than simple misspellings. Our method is based on letter ngrams as features to represent any string (Adamson and Boreham, 1974; Damashek, 1995; Wilbur and Kim, 2001; Willett, 1979). If t = &amp;quot;abcdefgh&amp;quot; represents a token type, then we define F(t) to be the feature set associated with t and we take F(t) to be composed of i) all the contiguous three character substrings “abc</context>
</contexts>
<marker>Hall, Dowling, 1980</marker>
<rawString>Hall, P. A., and Dowling, G. R. 1980. Approximate string matching. Computing Surveys, 12: 381-402.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Jacquemin</author>
</authors>
<title>Guessing morphology from terms and corpora,</title>
<date>1997</date>
<booktitle>20th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval:</booktitle>
<pages>156--165</pages>
<editor>in Belkin, N. J., Narasimhalu, A. D., and Willett, P., editors,</editor>
<publisher>ACM Press,</publisher>
<location>Philadelphia, PA,</location>
<contexts>
<context position="1568" citStr="Jacquemin, 1997" startWordPosition="243" endWordPosition="244">es of semantic relatedness of at least 0.7 based on their similarity as strings. 1 Introduction Morphological analysis is an important element in natural language processing. Jurafsky and Martin (2000) define morphology as the study of the way words are built up from smaller meaning bearing units, called morphemes. Robust tools for morphological analysis enable one to predict the root of a word and its syntactic class or part of speech in a sentence. A good deal of work has been done toward the automatic acquisition of rules, morphemes, and analyses of words from large corpora (Freitag, 2005; Jacquemin, 1997; Monson, 2004; Schone and Jurafsky, 2000; Wicentowski, 2004; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000). While this work is important it is mostly concerned with inflectional and derivational rules that can be derived from the study of texts in a language. While our interest is related to this work, we are concerned with the multitude of tokens that appear in English texts on the subject of biology. We believe it is clear to anyone who has examined the literature on biology that there are many tokens that appear in textual material that are related to each other, but not in any stand</context>
<context position="3111" citStr="Jacquemin, 1997" startWordPosition="511" endWordPosition="512">er the relatedness of two strings based on the fact that they have a certain substring of characters on which they match. But we do not require to say exactly on what part of the matching substring their semantic relationship depends. In other words we do not insist on the identification of the smaller meaning bearing units or morphemes. Key to our approach is the ability to measure the contextual similarity between two token types as well as their similarity as strings. Neither kind of measurement is unique to our application. Contextual similarity has been studied and applied in morphology (Jacquemin, 1997; Schone and Jurafsky, 2000; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000) and more generally (Means and others, 2004). String 201 BioNLP 2007: Biological, translational, and clinical language processing, pages 201–208, Prague, June 2007. c�2007 Association for Computational Linguistics similarity has also received much attention (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). However, the way we use these two measurements is, to our knowledge, new. Our approach is ba</context>
</contexts>
<marker>Jacquemin, 1997</marker>
<rawString>Jacquemin, C. 1997. Guessing morphology from terms and corpora, in Belkin, N. J., Narasimhalu, A. D., and Willett, P., editors, 20th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval: Philadelphia, PA, ACM Press, p. 156-165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Jurafsky</author>
<author>J H Martin</author>
</authors>
<title>Speech and Language Processing: Upper Saddle River,</title>
<date>2000</date>
<publisher>Prentice Hall.</publisher>
<location>New Jersey,</location>
<contexts>
<context position="1154" citStr="Jurafsky and Martin (2000)" startWordPosition="171" endWordPosition="174">. We introduce a new approach which allows us to assign probabilities of the semantic relatedness of pairs of tokens that occur in text in consequence of their relatedness as character strings. Our analysis is based on over 84 million sentences that compose the MEDLINE database and over 2.3 million token types that occur in MEDLINE and enables us to identify over 36 million token type pairs which have assigned probabilities of semantic relatedness of at least 0.7 based on their similarity as strings. 1 Introduction Morphological analysis is an important element in natural language processing. Jurafsky and Martin (2000) define morphology as the study of the way words are built up from smaller meaning bearing units, called morphemes. Robust tools for morphological analysis enable one to predict the root of a word and its syntactic class or part of speech in a sentence. A good deal of work has been done toward the automatic acquisition of rules, morphemes, and analyses of words from large corpora (Freitag, 2005; Jacquemin, 1997; Monson, 2004; Schone and Jurafsky, 2000; Wicentowski, 2004; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000). While this work is important it is mostly concerned with inflectional a</context>
</contexts>
<marker>Jurafsky, Martin, 2000</marker>
<rawString>Jurafsky, D., and Martin, J. H. 2000. Speech and Language Processing: Upper Saddle River, New Jersey, Prentice Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R W Means</author>
<author>S C Nemat-Nasser</author>
<author>A T Fan</author>
<author>R Hecht-Nielsen</author>
</authors>
<title>A Powerful and General Approach to Context Exploitation</title>
<date>2004</date>
<booktitle>in Natural Language Processing, HLT-NAACL 2004: Workshop on Computational Lexical Semantics</booktitle>
<institution>Association for Computational Linguistics.</institution>
<location>Boston, Massachusetts, USA,</location>
<marker>Means, Nemat-Nasser, Fan, Hecht-Nielsen, 2004</marker>
<rawString>Means, R. W., Nemat-Nasser, S. C., Fan, A. T., and Hecht-Nielsen, R. 2004. A Powerful and General Approach to Context Exploitation in Natural Language Processing, HLT-NAACL 2004: Workshop on Computational Lexical Semantics Boston, Massachusetts, USA, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Monson</author>
</authors>
<title>A framework for unsupervised natural language morphology induction,</title>
<date>2004</date>
<booktitle>Proceedings of the ACL 2004 on Student research workshop:</booktitle>
<institution>Association for Computational Linguistics.</institution>
<location>Barcelona, Spain,</location>
<contexts>
<context position="1582" citStr="Monson, 2004" startWordPosition="245" endWordPosition="246">latedness of at least 0.7 based on their similarity as strings. 1 Introduction Morphological analysis is an important element in natural language processing. Jurafsky and Martin (2000) define morphology as the study of the way words are built up from smaller meaning bearing units, called morphemes. Robust tools for morphological analysis enable one to predict the root of a word and its syntactic class or part of speech in a sentence. A good deal of work has been done toward the automatic acquisition of rules, morphemes, and analyses of words from large corpora (Freitag, 2005; Jacquemin, 1997; Monson, 2004; Schone and Jurafsky, 2000; Wicentowski, 2004; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000). While this work is important it is mostly concerned with inflectional and derivational rules that can be derived from the study of texts in a language. While our interest is related to this work, we are concerned with the multitude of tokens that appear in English texts on the subject of biology. We believe it is clear to anyone who has examined the literature on biology that there are many tokens that appear in textual material that are related to each other, but not in any standard way or by </context>
</contexts>
<marker>Monson, 2004</marker>
<rawString>Monson, C. 2004. A framework for unsupervised natural language morphology induction, Proceedings of the ACL 2004 on Student research workshop: Barcelona, Spain, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S G Nash</author>
<author>J Nocedal</author>
</authors>
<title>A numerical study of hte limited memory BFGS method and hte truncatedNewton method for large scale optimization.</title>
<date>1991</date>
<journal>SIAM Journal of Optimization,</journal>
<volume>1</volume>
<pages>358--372</pages>
<contexts>
<context position="16283" citStr="Nash and Nocedal, 1991" startWordPosition="2931" endWordPosition="2934">ful result, there is reason to believe the IDF weights used to compute lexSim are far from optimal. In an attempt to improve the weighting we divided the 141,164,755 pairs into C−1 consisting of 68,912,915 pairs with a conSim score of -1000 and C1 consisting of the remaining 72,251,839 pairs. Letting wG denote the vector of weights we defined a cost function Λ(w) = ∑ −log ( , ) t t C 1 2 1 ∈ ( lexSim t t ( , )) 1 2 ( 1 − lexSim t t ( , )) 1 2 and carried out a minimization of Λ to obtain a set of learned weights which we will denote by w0 . The minimization was done using the LBFGS algorithm (Nash and Nocedal, 1991). Since it is important to avoid negative weights we associate a potential v(f) with each ngram feature f and set w(f ) = exp(v(f )) . (13) The optimization is carried out using the potentials. The optimization can be understood as an attempt to make lexSim as close to zero as possible on the large set C−1 where conSim = −1000 and we have assumed there are no semantically related pairs, while at the same time making lexSim large on the remainder. While this seems reasonable as a first step it is not conservative as many pairs in C1 will not be semantically related. Because of this we would exp</context>
</contexts>
<marker>Nash, Nocedal, 1991</marker>
<rawString>Nash, S. G., and Nocedal, J. 1991. A numerical study of hte limited memory BFGS method and hte truncatedNewton method for large scale optimization. SIAM Journal of Optimization, 1: 358-372.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Schone</author>
<author>D Jurafsky</author>
</authors>
<title>Knowledge-free induction of morphology using latent semantic analysis,</title>
<date>2000</date>
<booktitle>Proceedings of the 2nd workshop on Learning language in logic and the 4th conference on Computational natural language learning -</booktitle>
<volume>7</volume>
<institution>Lisbon, Portugal, Association for Computational Linguistics.</institution>
<contexts>
<context position="1609" citStr="Schone and Jurafsky, 2000" startWordPosition="247" endWordPosition="250">t least 0.7 based on their similarity as strings. 1 Introduction Morphological analysis is an important element in natural language processing. Jurafsky and Martin (2000) define morphology as the study of the way words are built up from smaller meaning bearing units, called morphemes. Robust tools for morphological analysis enable one to predict the root of a word and its syntactic class or part of speech in a sentence. A good deal of work has been done toward the automatic acquisition of rules, morphemes, and analyses of words from large corpora (Freitag, 2005; Jacquemin, 1997; Monson, 2004; Schone and Jurafsky, 2000; Wicentowski, 2004; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000). While this work is important it is mostly concerned with inflectional and derivational rules that can be derived from the study of texts in a language. While our interest is related to this work, we are concerned with the multitude of tokens that appear in English texts on the subject of biology. We believe it is clear to anyone who has examined the literature on biology that there are many tokens that appear in textual material that are related to each other, but not in any standard way or by any simple rules that have </context>
<context position="3138" citStr="Schone and Jurafsky, 2000" startWordPosition="513" endWordPosition="516">s of two strings based on the fact that they have a certain substring of characters on which they match. But we do not require to say exactly on what part of the matching substring their semantic relationship depends. In other words we do not insist on the identification of the smaller meaning bearing units or morphemes. Key to our approach is the ability to measure the contextual similarity between two token types as well as their similarity as strings. Neither kind of measurement is unique to our application. Contextual similarity has been studied and applied in morphology (Jacquemin, 1997; Schone and Jurafsky, 2000; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000) and more generally (Means and others, 2004). String 201 BioNLP 2007: Biological, translational, and clinical language processing, pages 201–208, Prague, June 2007. c�2007 Association for Computational Linguistics similarity has also received much attention (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). However, the way we use these two measurements is, to our knowledge, new. Our approach is based on a simple postulate: </context>
</contexts>
<marker>Schone, Jurafsky, 2000</marker>
<rawString>Schone, P., and Jurafsky, D. 2000. Knowledge-free induction of morphology using latent semantic analysis, Proceedings of the 2nd workshop on Learning language in logic and the 4th conference on Computational natural language learning - Volume 7: Lisbon, Portugal, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sparck Jones</author>
<author>K</author>
</authors>
<title>A statistical interpretation of term specificity and its application in retrieval.</title>
<date>1972</date>
<journal>The Journal of Documentation,</journal>
<volume>28</volume>
<pages>11--21</pages>
<marker>Jones, K, 1972</marker>
<rawString>Sparck Jones, K. 1972. A statistical interpretation of term specificity and its application in retrieval. The Journal of Documentation, 28: 11-21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Wicentowski</author>
</authors>
<title>Multilingual Noise-Robust Supervised Morphological Analysis using the WordFrame Model,</title>
<date>2004</date>
<institution>Association for Computational Linguistics.</institution>
<location>SIGPHON: Barcelona, Spain,</location>
<contexts>
<context position="1628" citStr="Wicentowski, 2004" startWordPosition="251" endWordPosition="252">similarity as strings. 1 Introduction Morphological analysis is an important element in natural language processing. Jurafsky and Martin (2000) define morphology as the study of the way words are built up from smaller meaning bearing units, called morphemes. Robust tools for morphological analysis enable one to predict the root of a word and its syntactic class or part of speech in a sentence. A good deal of work has been done toward the automatic acquisition of rules, morphemes, and analyses of words from large corpora (Freitag, 2005; Jacquemin, 1997; Monson, 2004; Schone and Jurafsky, 2000; Wicentowski, 2004; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000). While this work is important it is mostly concerned with inflectional and derivational rules that can be derived from the study of texts in a language. While our interest is related to this work, we are concerned with the multitude of tokens that appear in English texts on the subject of biology. We believe it is clear to anyone who has examined the literature on biology that there are many tokens that appear in textual material that are related to each other, but not in any standard way or by any simple rules that have general applicabili</context>
</contexts>
<marker>Wicentowski, 2004</marker>
<rawString>Wicentowski, R. 2004. Multilingual Noise-Robust Supervised Morphological Analysis using the WordFrame Model, SIGPHON: Barcelona, Spain, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W J Wilbur</author>
<author>W Kim</author>
</authors>
<title>Flexible phrase based query handling algorithms,</title>
<date>2001</date>
<booktitle>Proceedings of the ASIST 2001 Annual Meeting: Washington, D.C., Information Today, Inc.,</booktitle>
<pages>438--449</pages>
<editor>in Aversa, E., and Manley, C., editors,</editor>
<contexts>
<context position="3579" citStr="Wilbur and Kim, 2001" startWordPosition="574" endWordPosition="577"> as strings. Neither kind of measurement is unique to our application. Contextual similarity has been studied and applied in morphology (Jacquemin, 1997; Schone and Jurafsky, 2000; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000) and more generally (Means and others, 2004). String 201 BioNLP 2007: Biological, translational, and clinical language processing, pages 201–208, Prague, June 2007. c�2007 Association for Computational Linguistics similarity has also received much attention (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). However, the way we use these two measurements is, to our knowledge, new. Our approach is based on a simple postulate: If two token types are similar as strings, but they are not semantically related because of their similarity, then their contextual similarity is no greater than would be expected for two randomly chosen token types. Based on this observation we carry out an analysis which allows us to assign a probability of relatedness to pairs of token types. This proves sufficient to generate a large repository of related token type pairs among which</context>
<context position="8132" citStr="Wilbur and Kim, 2001" startWordPosition="1438" endWordPosition="1441">represented by the same set of features. ⎛conSim(t1, t2) = log⎜pc (t1 ∧ t2)⎞ ⎟(3) ⎝pc (t1 c 2 ⎠ There is one minor practical difficulty with this definition. There are many cases where pc (t1 ∧ t2) is zero. In any such case we define conSim(t1, t2) to be -1000. 2.2 Measuring Lexical Similarity Here we treat the two token types, t1 and t2 of the previous section, as two ASCII strings and ask how similar they are as strings. String similarity has been studied from a number of viewpoints (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). We avoided approaches based on edit distance or other measures designed for spell checking because our problem requires the recognition of relationships more distant than simple misspellings. Our method is based on letter ngrams as features to represent any string (Adamson and Boreham, 1974; Damashek, 1995; Wilbur and Kim, 2001; Willett, 1979). If t = &amp;quot;abcdefgh&amp;quot; represents a token type, then we define F(t) to be the feature set associated with t and we take F(t) to be composed of i) all the contiguous three character substrings “abc”, “bcd”, “cde”, “def”</context>
</contexts>
<marker>Wilbur, Kim, 2001</marker>
<rawString>Wilbur, W. J., and Kim, W. 2001. Flexible phrase based query handling algorithms, in Aversa, E., and Manley, C., editors, Proceedings of the ASIST 2001 Annual Meeting: Washington, D.C., Information Today, Inc., p. 438-449.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Willett</author>
</authors>
<title>Document retrieval experiments using indexing vocabularies of varying size. II. Hashing, truncation, digram and trigram encoding of index terms.</title>
<date>1979</date>
<journal>Journal of Documentation,</journal>
<volume>35</volume>
<pages>296--305</pages>
<contexts>
<context position="3594" citStr="Willett, 1979" startWordPosition="578" endWordPosition="579">ind of measurement is unique to our application. Contextual similarity has been studied and applied in morphology (Jacquemin, 1997; Schone and Jurafsky, 2000; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000) and more generally (Means and others, 2004). String 201 BioNLP 2007: Biological, translational, and clinical language processing, pages 201–208, Prague, June 2007. c�2007 Association for Computational Linguistics similarity has also received much attention (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). However, the way we use these two measurements is, to our knowledge, new. Our approach is based on a simple postulate: If two token types are similar as strings, but they are not semantically related because of their similarity, then their contextual similarity is no greater than would be expected for two randomly chosen token types. Based on this observation we carry out an analysis which allows us to assign a probability of relatedness to pairs of token types. This proves sufficient to generate a large repository of related token type pairs among which are the expect</context>
<context position="8147" citStr="Willett, 1979" startWordPosition="1442" endWordPosition="1443">e set of features. ⎛conSim(t1, t2) = log⎜pc (t1 ∧ t2)⎞ ⎟(3) ⎝pc (t1 c 2 ⎠ There is one minor practical difficulty with this definition. There are many cases where pc (t1 ∧ t2) is zero. In any such case we define conSim(t1, t2) to be -1000. 2.2 Measuring Lexical Similarity Here we treat the two token types, t1 and t2 of the previous section, as two ASCII strings and ask how similar they are as strings. String similarity has been studied from a number of viewpoints (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). We avoided approaches based on edit distance or other measures designed for spell checking because our problem requires the recognition of relationships more distant than simple misspellings. Our method is based on letter ngrams as features to represent any string (Adamson and Boreham, 1974; Damashek, 1995; Wilbur and Kim, 2001; Willett, 1979). If t = &amp;quot;abcdefgh&amp;quot; represents a token type, then we define F(t) to be the feature set associated with t and we take F(t) to be composed of i) all the contiguous three character substrings “abc”, “bcd”, “cde”, “def”, “efg”, “fgh”;</context>
</contexts>
<marker>Willett, 1979</marker>
<rawString>Willett, P. 1979. Document retrieval experiments using indexing vocabularies of varying size. II. Hashing, truncation, digram and trigram encoding of index terms. Journal of Documentation, 35: 296-305.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Xu</author>
<author>W B Croft</author>
</authors>
<title>Corpus-based stemming using cooccurrence of word variants.</title>
<date>1998</date>
<journal>ACM TOIS,</journal>
<volume>16</volume>
<pages>61--81</pages>
<contexts>
<context position="1648" citStr="Xu and Croft, 1998" startWordPosition="253" endWordPosition="256">gs. 1 Introduction Morphological analysis is an important element in natural language processing. Jurafsky and Martin (2000) define morphology as the study of the way words are built up from smaller meaning bearing units, called morphemes. Robust tools for morphological analysis enable one to predict the root of a word and its syntactic class or part of speech in a sentence. A good deal of work has been done toward the automatic acquisition of rules, morphemes, and analyses of words from large corpora (Freitag, 2005; Jacquemin, 1997; Monson, 2004; Schone and Jurafsky, 2000; Wicentowski, 2004; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000). While this work is important it is mostly concerned with inflectional and derivational rules that can be derived from the study of texts in a language. While our interest is related to this work, we are concerned with the multitude of tokens that appear in English texts on the subject of biology. We believe it is clear to anyone who has examined the literature on biology that there are many tokens that appear in textual material that are related to each other, but not in any standard way or by any simple rules that have general applicability even in biology. </context>
<context position="3158" citStr="Xu and Croft, 1998" startWordPosition="517" endWordPosition="520">he fact that they have a certain substring of characters on which they match. But we do not require to say exactly on what part of the matching substring their semantic relationship depends. In other words we do not insist on the identification of the smaller meaning bearing units or morphemes. Key to our approach is the ability to measure the contextual similarity between two token types as well as their similarity as strings. Neither kind of measurement is unique to our application. Contextual similarity has been studied and applied in morphology (Jacquemin, 1997; Schone and Jurafsky, 2000; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000) and more generally (Means and others, 2004). String 201 BioNLP 2007: Biological, translational, and clinical language processing, pages 201–208, Prague, June 2007. c�2007 Association for Computational Linguistics similarity has also received much attention (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). However, the way we use these two measurements is, to our knowledge, new. Our approach is based on a simple postulate: If two token types a</context>
</contexts>
<marker>Xu, Croft, 1998</marker>
<rawString>Xu, J., and Croft, W. B. 1998. Corpus-based stemming using cooccurrence of word variants. ACM TOIS, 16: 61-81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>R Wicentowski</author>
</authors>
<title>Minimally supervised morphological analysis by multimodal alignment,</title>
<date>2000</date>
<booktitle>Proceedings of the 38th Annual Meeting on Association for Computational Linguistics: Hong Kong, Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1681" citStr="Yarowsky and Wicentowski, 2000" startWordPosition="257" endWordPosition="260">orphological analysis is an important element in natural language processing. Jurafsky and Martin (2000) define morphology as the study of the way words are built up from smaller meaning bearing units, called morphemes. Robust tools for morphological analysis enable one to predict the root of a word and its syntactic class or part of speech in a sentence. A good deal of work has been done toward the automatic acquisition of rules, morphemes, and analyses of words from large corpora (Freitag, 2005; Jacquemin, 1997; Monson, 2004; Schone and Jurafsky, 2000; Wicentowski, 2004; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000). While this work is important it is mostly concerned with inflectional and derivational rules that can be derived from the study of texts in a language. While our interest is related to this work, we are concerned with the multitude of tokens that appear in English texts on the subject of biology. We believe it is clear to anyone who has examined the literature on biology that there are many tokens that appear in textual material that are related to each other, but not in any standard way or by any simple rules that have general applicability even in biology. It is our goal here to achieve so</context>
<context position="3191" citStr="Yarowsky and Wicentowski, 2000" startWordPosition="521" endWordPosition="524">ve a certain substring of characters on which they match. But we do not require to say exactly on what part of the matching substring their semantic relationship depends. In other words we do not insist on the identification of the smaller meaning bearing units or morphemes. Key to our approach is the ability to measure the contextual similarity between two token types as well as their similarity as strings. Neither kind of measurement is unique to our application. Contextual similarity has been studied and applied in morphology (Jacquemin, 1997; Schone and Jurafsky, 2000; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000) and more generally (Means and others, 2004). String 201 BioNLP 2007: Biological, translational, and clinical language processing, pages 201–208, Prague, June 2007. c�2007 Association for Computational Linguistics similarity has also received much attention (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). However, the way we use these two measurements is, to our knowledge, new. Our approach is based on a simple postulate: If two token types are similar as strings, but they a</context>
</contexts>
<marker>Yarowsky, Wicentowski, 2000</marker>
<rawString>Yarowsky, D., and Wicentowski, R. 2000. Minimally supervised morphological analysis by multimodal alignment, Proceedings of the 38th Annual Meeting on Association for Computational Linguistics: Hong Kong, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Zobel</author>
<author>P Dart</author>
</authors>
<title>Finding approximate matches in large lexicons.</title>
<date>1995</date>
<journal>Software-Practice and Experience,</journal>
<volume>25</volume>
<pages>331--345</pages>
<contexts>
<context position="3617" citStr="Zobel and Dart, 1995" startWordPosition="580" endWordPosition="583">ent is unique to our application. Contextual similarity has been studied and applied in morphology (Jacquemin, 1997; Schone and Jurafsky, 2000; Xu and Croft, 1998; Yarowsky and Wicentowski, 2000) and more generally (Means and others, 2004). String 201 BioNLP 2007: Biological, translational, and clinical language processing, pages 201–208, Prague, June 2007. c�2007 Association for Computational Linguistics similarity has also received much attention (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). However, the way we use these two measurements is, to our knowledge, new. Our approach is based on a simple postulate: If two token types are similar as strings, but they are not semantically related because of their similarity, then their contextual similarity is no greater than would be expected for two randomly chosen token types. Based on this observation we carry out an analysis which allows us to assign a probability of relatedness to pairs of token types. This proves sufficient to generate a large repository of related token type pairs among which are the expected inflectional and der</context>
<context position="8170" citStr="Zobel and Dart, 1995" startWordPosition="1444" endWordPosition="1447">es. ⎛conSim(t1, t2) = log⎜pc (t1 ∧ t2)⎞ ⎟(3) ⎝pc (t1 c 2 ⎠ There is one minor practical difficulty with this definition. There are many cases where pc (t1 ∧ t2) is zero. In any such case we define conSim(t1, t2) to be -1000. 2.2 Measuring Lexical Similarity Here we treat the two token types, t1 and t2 of the previous section, as two ASCII strings and ask how similar they are as strings. String similarity has been studied from a number of viewpoints (Adamson and Boreham, 1974; Alberga, 1967; Damashek, 1995; Findler and Leeuwen, 1979; Hall and Dowling, 1980; Wilbur and Kim, 2001; Willett, 1979; Zobel and Dart, 1995). We avoided approaches based on edit distance or other measures designed for spell checking because our problem requires the recognition of relationships more distant than simple misspellings. Our method is based on letter ngrams as features to represent any string (Adamson and Boreham, 1974; Damashek, 1995; Wilbur and Kim, 2001; Willett, 1979). If t = &amp;quot;abcdefgh&amp;quot; represents a token type, then we define F(t) to be the feature set associated with t and we take F(t) to be composed of i) all the contiguous three character substrings “abc”, “bcd”, “cde”, “def”, “efg”, “fgh”; ii) the specially mark</context>
</contexts>
<marker>Zobel, Dart, 1995</marker>
<rawString>Zobel, J., and Dart, P. 1995. Finding approximate matches in large lexicons. Software-Practice and Experience, 25: 331-345.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>