<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<note confidence="0.988511">
Second ACL Workshop on Multiword Expressions: Integrating Processing, July 2004, pp. 24-31
</note>
<title confidence="0.995333">
Translation by Machine of Complex Nominals: Getting it Right
</title>
<author confidence="0.989717">
Timothy Baldwin
</author>
<affiliation confidence="0.961484">
CSLI
Stanford University
</affiliation>
<address confidence="0.840397">
Stanford, CA 94305 USA
</address>
<email confidence="0.997458">
tbaldwin@csli.stanford.edu
</email>
<author confidence="0.377444">
TakaakiTanaka
</author>
<affiliation confidence="0.372604666666667">
Communication Science Laboratories
Nippon Telephone and Telegraph Corporation
Kyoto, Japan
</affiliation>
<email confidence="0.984026">
takaaki@cslab.kecl.ntt.co.jp
</email>
<sectionHeader confidence="0.993488" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999752363636364">
We present a method for compositionally translating
noun-noun (NN) compounds, using a word-level
bilingual dictionary and syntactic templates for can-
didate generation, and corpus and dictionary statis-
tics for selection. We propose a support vector
learning-based method employing target language
corpus and bilingual dictionary data, and evaluate it
over a English Japanese machine translation task.
We show the proposed method to be superior to pre-
vious methods and also robust over low-frequency
NN compounds.
</bodyText>
<sectionHeader confidence="0.996496" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.970355769230769">
Noun-noun (NN) compounds (e.g. web server,
kikaihoNyaku “machine translation”,1 the
elements of which we will refer to as N and N in
linear order of occurrence) are a very real problem
for both machine translation (MT) systems and hu-
man translators due to:
constructional variability in the translations:
kikaihoNyaku “machine transla-
tion” (N-N) vs. miNkaNkigyou
“private company” (Adj-N) vs.
kaNkeikaizeN “improvement in relations” (N
in N);
lexical divergences in Japanese and English:
haifukeikaku “distribution
“economic plan/programme” vs.
shuyoukeikaku “major project”;
semantic underspecification: compounds gener-
ally have multiple interpretations, and can only
be reliably interpreted in context (Levi, 1978);
the existence of non-compositional NN compounds:
idobatakaigi “(lit.) well-side
meeting”, which translates most naturally into
English as “idle gossip”;
high productivity and frequency
In order to quantify the high productivity and
frequency of NN compounds, we carried out a
</bodyText>
<footnote confidence="0.974143">
1With all Japanese NN compound examples, we segment
the compound into its component nouns through the use of the
“” symbol. No such segmentation boundary is indicated in the
original Japanese.
</footnote>
<table confidence="0.9971068">
BNC Reuters Mainichi
Token coverage 2.6% 3.9% 2.9%
Total no. types 265K 166K 889K
Ave. token freq. 4.2 12.7 11.1
Singletons 60.3% 44.9% 45.9%
</table>
<tableCaption confidence="0.999898">
Table 1: Corpus occurrence of NN compounds
</tableCaption>
<bodyText confidence="0.998434338709678">
basic study of corpus occurrence in English and
Japanese. For English, we based our analysis
over: (1) the written portion of the British Na-
tional Corpus (BNC, 84M words: Burnard (2000)),
and (2) the Reuters corpus (108M words: Rose et
al. (2002)). For Japanese, we focused exclusively
on the Mainichi Shimbun Corpus (340M words:
Mainichi Newspaper Co. (2001)). We identified
NN compounds in each corpus using the method de-
scribed in 2.2 below, and from this, derived the
statistics of occurrence presented in Table 1. The
token coverage of NN compounds in each corpus
refers to the percentage of words which are con-
tained in NN compounds; based on our corpora, we
estimate this figure to be as high as 3-5%. If we
then look at the average token frequency of each
distinct NN compound type, we see that it is a rel-
atively modest figure given the size of each of the
corpora, the reason for which is seen in the huge
number of distinct NN compound types. Combin-
ing these observations, we see that a translator or
MT system attempting to translate one of these cor-
pora will run across NN compounds with high fre-
quency, but that each individual NN compound will
occur only a few times (with around 45-60% occur-
ing only once). The upshot of this for MT systems
and translators is that NN compounds are too var-
ied to be able to pre-compile an exhaustive list of
translated NN compounds, and must instead be able
to deal with novel NN compounds on the fly. This
claim is supported by Tanaka and Baldwin (2003a),
who found that static bilingual dictionaries had a
type coverage of around 84% and 94% over the top-
250 most frequent English and Japanese NN com-
pounds, respectively, but only 27% and 60%, re-
spectively, over a random sample of NN compounds
occurring more than 10 times in the corpus.
We develop and test a method for translating NN
compounds based on Japanese English MT. The
method can act as a standalone module in an MT
schedule” vs. keizaikeikaku
system, translating NN compounds according to the
best-scoring translation candidate produced by the
method, and it is primarly in this context that we
present and evaluate the method. This is congruent
with the findings of Koehn and Knight (2003) that,
in the context of statistical MT, overall translation
performance improves when source language noun
phrases are prescriptively translated as noun phrases
in the target language. Alternatively, the proposed
method can be used to generate a list of plausible
translation candidates for each NN compound, for
a human translator or MT system to select between
based on the full translation context.
In the remainder of the paper, we describe the
translation procedure and resources used in this re-
search ( 2), and outline the translation candidate se-
lection method, a benchmark selection method and
pre-processors our method relies on ( 3). We then
evaluate the method using a variety of data sources
( 4), and finally compare our method to related re-
search( 5).
</bodyText>
<sectionHeader confidence="0.995872" genericHeader="introduction">
2 Preliminaries
</sectionHeader>
<subsectionHeader confidence="0.999651">
2.1 Translation procedure
</subsectionHeader>
<bodyText confidence="0.999789137931035">
We translate NN compounds by way of a two-phase
procedure, incorporating generation and selection
(similarly to Cao and Li (2002) and Langkilde and
Knight (1998)).
Generation consists of looking up word-level
translations for each word in the NN compound
to be translated, and running them through a set
of constructional translation templates to generate
translation candidates. In order to translate
kaNkeikaizeN “improvement in relations”, for
example, possible word-level translations for
are relation, connection and relationship, and trans-
lations for are improvement and betterment.
Constructional templates are of the form [N✁ in N✁ ]
(where N✁ indicates that the word is a noun (N) in
English ( ) and corresponds to the th-occurring
noun in the original Japanese; see Table 3 for fur-
ther example templates and Kageura et al. (2004)
for discussion of templates of this type). Each slot in
the translation template is indexed for part of speech
(POS), and derivational morphology is optionally
used to convert a given word-level translation into
a form appropriate for a given template. Example
translation candidates for , therefore, are
relation improvement, betterment of relationship,
improvement connection and relational betterment.
Generation fails in the instance that we are unable
to find a word-level translation for N and/or N .
Selection consists of selecting the most likely
translation for the original NN compound from the
generated translation candidates. Selection is per-
formed based on a combination of monolingual tar-
get language and crosslingual evidence, obtained
from corpus or web data.
Ignoring the effects of POS constraints for the
moment, the number of generated translations is
where and are the fertility of Japanese
nouns N✏ and N✏ , respectively, and is the number
of translation templates. As a result, there is often
a large number of translation candidates to select
between, and the selection method crucially deter-
mines the efficacy of the method.
This translation procedure has the obvious advan-
tage that it can generate a translation for any NN
compound input assuming that there are word-level
translations for each of the component nouns; that
is it has high coverage. It is based on the assump-
tion that NN compounds translate compositional-
ity between Japanese and English, which Tanaka
and Baldwin (2003a) found to be the case 43.1% of
the time for Japanese–English (JE) MT and 48.7%
of the time for English–Japanese (EJ) MT. In this
paper, we focus primarily on selecting the cor-
rect translation for those NN compounds which can
be translated compositionally, but we also inves-
tigate what happens when non-compositional NN
compounds are translated using a compositional
method.
</bodyText>
<subsectionHeader confidence="0.999355">
2.2 Translation data
</subsectionHeader>
<bodyText confidence="0.99673444">
In order to generate English and Japanese NN com-
pound testdata, we first extracted out all NN bi-
grams from the Reuters Corpus and Mainichi Shim-
bun Corpus. The Reuters Copus was first tagged
and chunked using fnTBL (Ngai and Florian, 2001),
and lemmatised using morph (Minnen et al., 2001),
while the Mainichi Shimbun was segmented and
tagged using ChaSen (Matsumoto et al., 1999). For
both English and Japanese, we took only those NN
bigrams adjoined by non-nouns to ensure that they
were not part of a larger compound nominal. We ad-
ditionally measured the entropy of the left and right
contexts for each NN type, and filtered out all com-
pounds where either entropy value was .2 This
was done in an attempt to, once again, exclude NNs
which were embedded in larger MWEs, such as ser-
vice department in social service department.
We next calculated the frequency of occurrence
of each NN compound type identified in the English
and Japanese corpora, and ranked the NN com-
pound types in order of corpus frequency. Based on
this ranking, we split the NN compound types into
three partitions of equal token frequency, and from
each partition, randomly selected 250 NN com-
pounds. In doing so, we produced NN compound
</bodyText>
<footnote confidence="0.9983612">
2For the left token entropy, if the most-probable left context
was the, a or a sentence boundary, the threshold was switched
off. Similarly for the right token entropy, if the most-probable
right context was a punctuation mark or sentence boundary, the
threshold was switched off.
</footnote>
<table confidence="0.999097142857143">
Band English Japanese
HIGH Freq. range 346–24,025 336–64,835
Types 791 4,009
MED Freq.range 44–345 37–336
Types 6,576 32,283
LOW Freq. range 1–44 1–37
Types 158,215 852,328
</table>
<tableCaption confidence="0.997962">
Table 2: Frequency bands
</tableCaption>
<bodyText confidence="0.999960710526316">
data representative of three disjoint frequency bands
of equal token size, as detailed in Table 2. This al-
lows us to analyse the robustness of our method over
data of different frequencies.
Our motivation in testing the proposed method
over NN compounds according to the three fre-
quency bands is to empirically determine: (a)
whether there is any difference in translation-
compositionality for NN compounds of different
frequency, and (b) whether our method is robust
over NN compounds of different frequency. We re-
turn to these questions in 4.1.
In order to evaluate basic translation accuracy
over the test data, we generated a unique gold-
standard translation for each NN compound to
represent its optimally-general default translation.
This was done with reference to two bilingual
Japanese-English dictionaries: the ALTDIC dictio-
nary and the on-line EDICT dictionary. The ALT-
DIC dictionary was compiled from the ALT-J/E
MT system (Ikehara et al., 1991), and has approxi-
mately 400,000 entries including more than 200,000
proper nouns; EDICT (Breen, 1995) has approxi-
mately 150,000 entries. The existence of a trans-
lation for a given NN compound in one of the
dictionaries does not guarantee that we used it as
our gold-standard, and 35% of JE translations and
25% of EJ translations were rejected in favour of
a manually-generated translation. In generating the
gold-standard translation data, we checked the va-
lidity of each of the randomly-extracted NN com-
pounds, and rejected a total of 0.5% of the initial
random sample of Japanese strings, and 6.6% of the
English strings, on the grounds of: (1) not being
NN compounds, (2) being proper nouns, or (3) be-
ing part of a larger MWE. In each case, the rejected
string was replaced with an alternate randomly-
selected NN compound.
</bodyText>
<subsectionHeader confidence="0.998184">
2.3 Translation templates
</subsectionHeader>
<bodyText confidence="0.999900636363636">
The generation phase of translation relies on trans-
lation templates to recast the source language NN
compound into the target language. The transla-
tion templates were obtained by way of word align-
ment over the JE and EJ gold-standard translation
datasets, generating a total of 28 templates for the
JE task and 4 templates for the EJ task. The rea-
son for the large number of templates in the JE task
is that they are used to introduce prepositions and
possessive markers, as well as indicating word class
conversions (see Table 3).
</bodyText>
<sectionHeader confidence="0.944847" genericHeader="method">
3 Selection methodology
</sectionHeader>
<bodyText confidence="0.9999025">
In this section, we describe a benchmark selection
method based on monoligual corpus data, and a
novel selection method combining monolingual cor-
pus data and crosslingual data derived from bilin-
gual dictionaries. Each method takes the list of gen-
erated translation candidates and scores each, re-
turning the highest-scoring translation candidate as
our final translation.
</bodyText>
<subsectionHeader confidence="0.998085">
3.1 Benchmark monolingual method
</subsectionHeader>
<bodyText confidence="0.973348435897436">
The monolingual selection method we benchmark
ourselves against is the corpus-based transla-
tion quality (CTQ) method of Tanaka and Bald-
win (2003b). It rates a given translation candidate
according to corpus evidence for both the fully-
specified translation and its parts in the context of
the translation template in question. This is calcu-
lated as:3
where and are the word-level translations
of the source language N★ and N★ , respectively,
and is the translation template.4 Each probabil-
ity is calculated according to a maximum likelihood
estimate based on relative corpus occurrence. The
formulation of CTQ is based on linear interpolation
over and , where and .
We set to and to throughout evaluation.
The basic intuition behind decomposing the
translation candidate into its two parts within the
context of the translation template (✽ and
) is to capture the subcategorisation prop-
erties of and relative to . For example,
if and were Bandersnatch and relation,
respectively, and for all , we
would hope to score relation to (the) Bandersnatch
as being more likely than relation on (the) Bander-
snatch. We could hope to achieve this by virtue of
the fact that relation occurs in the form relation to
... much more frequently than relation on ..., mak-
ing the value of greater for the template
[N to N ] than [N on N ].
In evaluation, Tanaka and Baldwin (2003b) found
the principal failing of this method to be its treat-
ment of all translations contained in the transfer
dictionary as being equally likely, where in fact
3In the original formulation, the product
was included as a third term, but
Tanaka and Baldwin (2003b) found it to have negligible impact
on translation accuracy, so we omit it here.
4 and are assumed to be POS-compatible with .
</bodyText>
<equation confidence="0.863754">
Template (JE) Example
[N N ]J [N N ]E shijoukeizai “market economy”
[N N ]J [N N ]E saNseitasuu “majority agreement”
[N N ]J [N of (the) N ]E seikeNkoutai “change of government”
Template (EJ) Example
[N N ]E [N N ]J exchange rate “kawasereeto”
[N N ]E [N teki N ]J world leader “sekaitekileader”
[N N ]E [N no N ]J baby girl “oNnanoakachaN”
</equation>
<tableCaption confidence="0.994023">
Table 3: Example translation templates (N = noun and Adj = adjective)
</tableCaption>
<bodyText confidence="0.997205846153846">
there is considerable variability in their applicatil-
ity. One example of this is the simplex kiji
which is translated as either article or item (in the
sense of a newspaper) in ALTDIC, of which the for-
mer is clearly the more general translation. Lack-
ing knowledge of this conditional probability, the
method considers the two translations to be equally
probable, giving rise to the preferred translation of
related item for kaNreNkiji “related ar-
ticle” due to the markedly greater corpus occurrence
of related item over related article. It is this as-
pect of selection that we focus on in our proposed
method.
</bodyText>
<subsectionHeader confidence="0.995177">
3.2 Proposed selection method
</subsectionHeader>
<bodyText confidence="0.9995976">
The proposed method uses the corpus-based mono-
lingual probability terms of CTQ above, but also
mono- and crosslingual terms derived from bilin-
gual dictionary data. In doing so, it attempts to pre-
serve the ability of CTQ to model target language
expressional preferences, while incorporating more
direct translation preferences at various levels of
lexical specification. For ease of feature expandabil-
ity, and to avoid interpolation over excessively many
terms, the backbone of the method is the TinySVM
support vector machine (SVM) learner.5
The way we use TinySVM is to take all source
language inputs where the gold-standard translation
is included among the generated translation candi-
dates, and construct a single feature vector for each
translation candidate. We treat those feature vec-
tors which correspond to the (unique) gold-standard
translation as positive exemplars, and all other fea-
ture vectors as negative exemplars. We then run
TinySVM over the training exemplars using the
ANOVA kernel (the only kernel which was found to
converge). Strictly speaking, SVMs produce a bi-
nary classification, by returning a continuous value
and determining whether it is closest to (the pos-
itive class) or (the negative class). We treat
this value as a translation quality rating, and rank
the translation candidates accordingly. To select the
best translation candidate, we simply take the best-
scoring exemplar, breaking ties through random se-
lection.
</bodyText>
<footnote confidence="0.9328925">
5http://chasen.aist-nara.ac.jp/˜taku/
software/TinySVM/
</footnote>
<bodyText confidence="0.9997064">
The selection method makes use of three basic
feature types in generating a feature vector for each
source language–translation candidate pair: corpus-
based features, bilingual dictionary-based features
and template-based features.
</bodyText>
<sectionHeader confidence="0.628573" genericHeader="method">
Corpus-based features
</sectionHeader>
<bodyText confidence="0.992137804878049">
Each source language–translation pair is mapped
onto a total of 8 corpus-based feature types, in line
with the CTQ formulation above:
and
, and
is a normalisation parameter
used to estimate the frequency of occurrence of mul-
tiword expression (MWE) translations from that of
the head. E.g., in generating translations for
fudousaNgaisha “real estate company”,
we get two word-level translations for : real
estate and real property. In each case, we identify
the final word as the head, and calculate the num-
ber of times the MWEs (i.e. real estate and real
property) occur in the overall corpus as compared
to the head (i.e. estate and property, respectively).
In calculating the values of each of the frequency-
based features involving these translations, we de-
termine the frequency of the head in the given con-
text, and multiply this by the normalisation param-
eter. The reason for doing this is for ease of cal-
culation and, wherever possible, to avoid zero val-
ues for frequencies involving MWEs. The feature
is generated by multiplying the
MWE parameters for each of and (which
are set to 1.0 in the case that the translation is sim-
plex) and intended to model the tendency to pre-
fer simplex translations over MWEs when given a
choice.
We construct an additional feature from each of
these values, by normalising (by simple division to
generate a value in the range ) relative to the
maximum value for that feature among the trans-
lation candidates generated for a given source lan-
guage input. For each corpus, therefore, the total
number of corpus-based features is .
In EJ translation, the corpus-based feature values
were derived from the Mainichi Shimbun Corpus,
whereas in JE translation, we used the BNC and
Reuters Corpus, and concatenated the feature val-
ues from each.
</bodyText>
<subsectionHeader confidence="0.497655">
Bilingual dictionary-based features
</subsectionHeader>
<bodyText confidence="0.986818040816327">
Bilingual dictionary data is used to generate 6 fea-
tures:
and
and
is the total
number of times the given translation candidate oc-
curs as a translation for the source language NN
compound across all dictionaries. While this fea-
ture may seem to give our method an unfair ad-
vantage over CTQ, it is important to realise that
only limited numbers of NN compounds are listed
in the dictionaries (12% for English and 28%
for Japanese), and that the gold-standard accuracy
when the dictionary translation is selected is not as
high as one would expect (65% for English and 75%
for Japanese). describes
the total occurrences of the translation candidate
across all dictionaries (irrespective of the source
language expression it translates), and is considered
to be an indication of conventionalisation of the can-
didate.
The remaining features are intended to capture
word-level translation probabilities, optionally in
the context of the template used in the translation
candidate. Returning to our kaNreNkiji
“related article” example from above, of the transla-
tions article and item for , article occurs as the
translation of for 42% of NN entries with
as the N , and within 18% of translations for com-
plex entries involving (irrespective of the form
or alignment between article and ). For item,
the respective statistics are 9% and 4%. From this,
we can conclude that article is the more appropri-
ate translation, particularly for the given translation
template.
As with the corpus-based features, we addition-
ally construct a normalised variant of each fea-
ture value, such that the total number of bilingual
dictionary-based features is .
In both JE and EJ translation, we derived bilin-
gual dictionary-based features from the EDICT and
ALTDIC dictionaries independently, and concate-
nated the features derived from each.
Template-based features
We use a total of two template-based features: the
template type and the target language head (N1 or
N2). For template [N N ]J [N N ]E (see 2.3),
e.g., the template type is N-N and the target lan-
guage head is N1.
</bodyText>
<subsectionHeader confidence="0.99915">
3.3 Corpus data
</subsectionHeader>
<bodyText confidence="0.999980434782609">
The corpus frequencies were extracted from the
same three corpora as were described in 1: the
BNC and Reuters Corpus for English, and Mainichi
Shimbun Corpus for Japanese. We chose to use the
BNC and Reuters Corpus because of their comple-
mentary nature: the BNC is a balanced corpus and
hence has a rounded coverage of NN compounds
(see Table 1), whereas the Reuters Corpus contains
newswire data which aligns relatively well in con-
tent with the newspaper articles in the Mainichi
Shimbun Corpus.
We calculated the corpus frequencies based on
the tag and dependency output of RASP (Briscoe
and Carroll, 2002) for English, and CaboCha (Kudo
and Matsumoto, 2002) for Japanese. RASP is a tag
sequence grammar-based stochastic parser which
attempts to exhaustively resolve inter-word depen-
dencies in the input. CaboCha, on the other hand,
chunks the input into head-annotated “bunsetsu” or
base phrases, and resolves only inter-phrase depen-
dencies. We thus independently determined the
intra-phrasal structure from the CaboCha output
based on POS-conditioned templates.
</bodyText>
<sectionHeader confidence="0.998873" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999761178571429">
We evaluate the method over both JE and EJ trans-
lation selection, using the two sets of 750 NN com-
pounds described in 2.2. In each case, we first
evaluate system performance according to gold-
standard accuracy, i.e. the proportion of inputs
for which the (unique) gold-standard translation is
ranked top amongst the translation candidates. For
the method to have a chance at selecting the gold-
standard translation, we clearly must be able to
generate it. The first step is thus to identify in-
puts which have translation-compositional gold-
standard translations, and generate the translation
candidates for each. The translation-compositional
data has the distribution given in Table 4. The over-
all proportion of translation-compositional inputs
is somewhat lower than suggested by Tanaka and
Baldwin (2003a), although this is conditional on the
coverage of the particular dictionaries we use. The
degree of translation-compositionality appears to be
relatively constant across the three frequency bands,
a somewhat surprising finding as we had expected
the lower frequency NN compounds to be less con-
ventionalised and therefore have more straightfor-
wardly compositional translations.
We use the translation-compositional test data to
evaluate the proposed method (SVM ) against
CTQ and a simple baseline derived from CTQ, which
takes the most probable fully-specified translation
</bodyText>
<table confidence="0.902587625">
JE EJ
ALL 297/750 272/750
HIGH 99/250 108/250
MED 98/250 81/250
LOW 100/250 83/250
Baseline CTQ SVM SVM SVM
JE .616 .721 .764 .693 .839
EJ .621 .654 .721 .419 .783
</table>
<tableCaption confidence="0.9906495">
Table 6: Silver-standard translation accuracies
Table 4: Analysis of translation compositionality
</tableCaption>
<table confidence="0.999326333333333">
Baseline CTQ SVM SVM SVM
JE .317 .367 .390 .382 .434
EJ .400 .416 .441 .296 .514
</table>
<tableCaption confidence="0.732214">
Table 5: Gold-standard translation accuracies
</tableCaption>
<table confidence="0.94412775">
Band Training Baseline CTQ SVM
data G S G S G
HIGH All .425 .789 .445 .806 .464
Local .462
MED All .315 .665 .368 .797 .474
Local .480
LOW All 210 .393 .280 .569 .332
Local .320
</table>
<figure confidence="0.966560857142857">
S
.879
.857
.878
.889
.742
.720
</figure>
<figureCaption confidence="0.45118">
candidate (i.e. is equivalent to setting and
</figureCaption>
<bodyText confidence="0.987639064102564">
). We additionally tested the proposed method
using just corpus-based features (SVM ) and bilin-
gual dictionary-based features (SVM ) to get a bet-
ter sense for the relative impact of each on overall
performance. In the case of the proposed method
and its derivants, evaluation is according to 10-fold
stratified cross-validation, with stratification taking
place across the three frequency bands. The average
number of translations generated for the JE dataset
was 205.6, and that for the EJ dataset was 847.5.
We were unable to generate any translations for 17
(2.3%) and 57 (7.6%) of the NN compounds in the
JE and EJ datasets, respectively, due to there being
no word-level translations for N and/or N in the
combined ALTDIC/EDICT dictionaries.
The gold-standard accuracies are presented in Ta-
ble 5, with figures in boldface indicating a statis-
tically significant improvement over both CTQ and
the baseline.6 Except for SVM in the EJ task, all
evaluated methods surpass the baseline, and all vari-
ants of SVM surpassed CTQ. SVM appears to
successfully consolidate on SVM and SVM , in-
dicating that our modelling of target language cor-
pus and crosslingual data is complementary. Over-
all, the results for the EJ task are higher than those
for the JE task. Part of the reason for this is that
Japanese has less translation variability for a given
pair of word translations, as discussed below.
In looking through the examples where a gold-
standard translation was not returned by the dif-
ferent methods, we often find that the unique-
ness of gold-standard translation has meant that
equally good translations (e.g. dollar note vs. the
gold-standard translation dollar bill for
dorushihei) or marginally lower-quality but per-
fectly acceptable translations (e.g. territorial issue
vs. the gold-standard translation of territorial dis-
pute for ryoudomoNdai) are adjudged
incorrect. To rate the utility of these near-miss
translations, we rated each non-gold-standard first-
ranking translation according to source language-
recoverability (L1-recoverability). L1-recoverable
Table 7: JE translation accuracies across different
frequency bands
translations are defined to be syntactically un-
marked, capture the basic semantics of the source
language expression and allow the source language
expression to be recovered with reasonable confi-
dence. While evaluation of L1-recoverability is in-
evitably subjective, we minimise bias towards any
given system by performing the L1-recoverability
annotation for all methods in a single batch, without
giving the annotator any indication of which method
selected which translation. The average number
of English and Japanese L1-recoverable translations
were 1.9 and 0.94, respectively. The principle rea-
son for the English data being more forgiving is the
existence of possessive- and PP-based paraphrases
of NN gold-standard translations (e.g. ammendment
of rule(s) as an L1-recoverable paraphrase of rule
ammendment).
We combine the gold-standard data and L1-
recoverable translation data together into a sin-
gle silver standard translation dataset, based upon
which we calculate silver-standard translation accu-
racy. The results for the translation-compositional
data are given in Table 6. Once again, we find
that the proposed method is superior to the base-
line and CTQ, and that the combination of crosslin-
gual and target language corpus data is superior
to the individual data sources. SVM fares par-
ticularly badly under silver-standard evaluation as
it is unable to capture the target language lexi-
cal and constructional preferences as are needed to
generate syntactically-unmarked, natural-sounding
translations. Unsurprisingly, the increment between
gold-standard accuracy and silver-standard accu-
racy is greater for English than Japanese.
</bodyText>
<subsectionHeader confidence="0.998775">
4.1 Accuracy over each frequency band
</subsectionHeader>
<bodyText confidence="0.9992242">
We next analyse the breakdown in gold- and silver-
standard accuracies across the three frequency
bands. In doing this, we test the hypothesis that
training over only translation data from the same
frequency band will produce better results than
</bodyText>
<footnote confidence="0.804661">
6Based on the paired test,
</footnote>
<table confidence="0.875140888888889">
Band Training Baseline CTQ SVM
data
Local
All
HIGH
MED Local
All
Local
.374 .708
</table>
<tableCaption confidence="0.9924">
Table 8: EJ translation accuracies across different
frequency bands
</tableCaption>
<table confidence="0.999886666666667">
Baseline CTQ SVM SVM SVM
JE .358 .515 .490 .308 .549
EJ .208 .285 .350 .162 .277
</table>
<tableCaption confidence="0.9699235">
Table 9: Silver-standard translation accuracies over
non-translation-compositional data
</tableCaption>
<bodyText confidence="0.999604346153846">
training over all the translation data. The results
for the JE and EJ translation tasks are presented
in Tables 7 and 8, respectively. The results based
on training over data from all frequency bands are
labelled All and those based on training over data
from only the same frequency band are labelled Lo-
cal; G is the gold-standard accuracy and S is the
silver-standard accuracy.
For each of the methods tested, we find that the
gold- and silver-standard accuracies drop as we go
down through the frequency bands, although the
drop off is markedly greater for gold-standard ac-
curacy. Indeed, silver-standard accuracy is con-
stant between the high and medium bands for the
JE task, and the medium and low frequency bands
for the EJ task. SVM appears to be robust over
low-frequency data for both tasks, with the abso-
lute difference in silver-standard accuracy between
the high and low frequency bands around only 0.10,
and never dropping below 0.70 for either the EJ or
JE task. There was very little difference between
training over data from all frequency bands as com-
pared to only the local frequency band, suggesting
that there is little to be gained from conditioning
training data on the relative frequency of the NN
compound we are seeking to translate.
</bodyText>
<subsectionHeader confidence="0.9909275">
4.2 Accuracy over non-translation-
compositional data
</subsectionHeader>
<bodyText confidence="0.999978304347826">
Finally, we evaluate the performance of the meth-
ods over the non-translation compositional data. We
are unable to give gold-standard accuracies here
as, by definition, the gold-standard translation is
not amongst the translation candidates generated
for any of the inputs. We are, however, able
to evaluate according to silver-standard accuracy,
constructing L1-recoverable translation data as for
the translation-compositional case described above.
The classifier is learned from all the translation-
compositional data, treating the gold-standard trans-
lations as positive exemplars as before.
The results are presented in Table 9. A large
disparity is observable here between the JE and
EJ accuracies, which is, once again, a direct re-
sult of Japanese being less forgiving when it comes
to L1-recoverable translations. For the translation-
compositional data, the EJ task displayed a simi-
larly diminished accuracy increment when the L1-
recoverable translation data was incorporated, but
this was masked by the higher gold-standard ac-
curacy for the task. The relative results for the
JE task largely mirror those for the translation-
compositonal data. In contrast, SVM actually
performs marginally worse than CTQ over the EJ
task, despite SVM performing above CTQ. That
is, the addition of dictionary data diminishes overall
accuracy, a slightly surprising result given the com-
plementary of corpus and dictionary data in all other
aspects of evaluation. It is possible that we could
get better results by treating both L1-recoverable
and gold-standard translations in the training data
as positive exemplars, which we leave as an item
for future research.
Combining the results from Table 9 with those
from Table 6, the overall silver-standard accuracy
over the JE data is 0.671 for SVM (compared to
0.602 for CTQ), and that over the EJ data is 0.461
(compared to 0.419 for CTQ).
In summary, we have shown our method to be su-
perior to both the baseline and CTQ over EJ and JE
translation tasks in terms of both gold- and silver-
standard accuracy. We also demonstrated that the
method successfully combines crosslingual and tar-
get language corpus data, and is relatively robust
over low frequency inputs.
</bodyText>
<sectionHeader confidence="0.999963" genericHeader="method">
5 Related work
</sectionHeader>
<bodyText confidence="0.997843578947368">
One piece of research relatively closely related to
our method is that of Cao and Li (2002), who use
bilingual bootstrapping over Chinese and English
web data in various forms to translate Chinese NN
compounds into English. While we rely on bilin-
gual dictionaries to determine crosslingual similar-
ity, their method is based on contextual similarity
in the two languages, without assuming parallelism
or comparability in the corpus data. They report an
impressive F-score of 0.73 over a dataset of 1000
instances, although they also cite a prior-based F-
score (equivalent to our Baseline) of 0.70 for the
task, such that the particular data set they are deal-
ing with would appear to be less complex than that
which we have targeted. Having said this, contex-
tual similarity is an orthogonal data source to those
used in this research, and has the potential to further
improve the accuracy of our method.
Nagata et al. (2001) use “partially bilingual” web
</bodyText>
<figure confidence="0.95689875">
All
LOW
G S G S G S
.451 .641 .463 .657 .630 .842
.657 .850
.420 .655 .452 .674 .532 .762
.546 .776
.314 .561 .341 .633 .396 .755
</figure>
<bodyText confidence="0.999926958333333">
pages, that is web pages which are predominantly
Japanese, say, but interspersed with English words,
to extract translation pairs. They do this by access-
ing web pages containing a given Japanese expres-
sion, and looking for the English expression which
occurs most reliably in its immediate vicinity. The
method achieves an impressive gold-standard accu-
racy of 0.62, at a recall of 0.68, over a combination
of simplex nouns and compound nominals.
Grefenstette (1999) uses web data to select En-
glish translations for compositional German and
Spanish noun compounds, and achieves an impres-
sive accuracy of 0.86–0.87. The translation task
Grefenstette targets is intrinsically simpler than that
described in this paper, however, in that he consid-
ers only those compounds which translate into NN
compounds in English. It is also possible that the
historical relatedness of languages has an effect on
the difficulty of the translation task, although fur-
ther research would be required to confirm this pre-
diction. Having said this, the successful use of web
data by a variety of researchers suggests an avenue
for future research in comparing our results with
those obtained using web data.
</bodyText>
<sectionHeader confidence="0.989611" genericHeader="conclusions">
6 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999964888888889">
We have proposed a method for translating NN
compounds which compositionally generates trans-
lation candidates and selects among them using a
target language model based on corpus statistics and
a translation model based on bilingual dictionaries.
Our SVM-based implementation was shown to out-
perform previous methods and be robust over low-
frequency NN compounds for JE and EJ translation
tasks.
</bodyText>
<sectionHeader confidence="0.998277" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<reference confidence="0.578456888888889">
This material is based upon work supported by the
National Science Foundation under Grant No. BCS-
0094638 and also the Research Collaboration between
NTT Communication Science Laboratories, Nippon
Telegraph and Telephone Corporation and CSLI, Stan-
ford University. We would like to thank Emily Bender,
Francis Bond, Dan Flickinger, Stephan Oepen, Ivan Sag
and the anonymous reviewers for their valuable input on
this research.
</reference>
<sectionHeader confidence="0.975842" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999174123287671">
Jim Breen. 1995. Building an electronic Japanese-English dic-
tionary. Japanese Studies Association of Australia Confer-
ence.
Ted Briscoe and John Carroll. 2002. Robust accurate statistical
annotation of general text. In Proc. of the 3rd International
Conference on Language Resources and Evaluation (LREC
2002), pages 1499–1504, Las Palmas, Canary Islands.
Lou Burnard. 2000. User Reference Guide for the British Na-
tional Corpus. Technical report, Oxford University Com-
puting Services.
Yunbo Cao and Hang Li. 2002. Base noun phrase transla-
tion using Web data and the EM algorithm. In Proc. of the
19th International Conference on Computational Linguis-
tics (COLING 2002), Taipei, Taiwan.
Gregory Grefenstette. 1999. The World Wide Web as a re-
source for example-based machine translation tasks. In
Translating and the Computer 21: ASLIB’99, London, UK.
Satoru Ikehara, Satoshi Shirai, Akio Yokoo, and Hiromi
Nakaiwa. 1991. Toward an MT system without pre-editing
– effects of new methods in ALT-J/E–. In Proc. of the Third
Machine Translation Summit (MT Summit III), pages 101–
106, Washington DC, USA.
Kyo Kageura, Fuyuki Yoshikane, and Takayuki Nozawa. 2004.
Parallel bilingual paraphrase rules for noun compounds:
Concepts and rules for exploring Web language resources.
In Proc. of the Fourth Workshop on Asian Language Re-
sources, pages 54–61, Sanya, China.
Philipp Koehn and Kevin Knight. 2003. Feature-rich statisti-
cal translation of noun phrases. In Proc. of the 41st Annual
Meeting of the ACL, Sapporo, Japan.
Taku Kudo and Yuji Matsumoto. 2002. Japanese dependency
analysis using cascaded chunking. In Proc. of the 6th
Conference on Natural Language Learning (CoNLL-2002),
pages 63–9, Taipei, Taiwan.
Irene Langkilde and Kevin Knight. 1998. Generation that ex-
ploits corpus-based statistical knowledge. In Proc. of the
36th Annual Meeting of the ACL and 17th International
Conference on Computational Linguistics (COLING/ACL-
98), pages 704–710, Montreal, Canada.
Judith N. Levi. 1978. The Syntax and Semantics of Complex
Nominals. Academic Press, New York, USA.
Mainichi Newspaper Co. 2001. Mainichi Shimbun CD-ROM
2001.
Yuji Matsumoto, Akira Kitauchi, Tatsuo Yamashita, and Yoshi-
taka Hirano. 1999. Japanese Morphological Analysis Sys-
tem ChaSen Version 2.0 Manual. Technical Report NAIST-
IS-TR99009, NAIST.
Guido Minnen, John Carroll, and Darren Pearce. 2001. Ap-
plied morphological processing of English. Natural Lan-
guage Engineering, 7(3):207–23.
Masaaki Nagata, Teruka Saito, and Kenji Suzuki. 2001. Using
the Web as a bilingual dictionary. In Proc. of the ACL/EACL
2001 Workshop on Data-Driven Methods in Machine Trans-
lation, pages 95–102, Toulouse, France.
Grace Ngai and Radu Florian. 2001. Transformation-based
learning in the fast lane. In Proc. of the 2nd Annual Meeting
of the North American Chapter of Association for Compu-
tational Linguistics (NAACL2001), pages 40–7, Pittsburgh,
USA.
Tony Rose, Mark Stevenson, and Miles Whitehead. 2002. The
Reuters Corpus volume 1 – from yesterday’s news to tomor-
row’s language resources. In Proc. of the 3rd International
Conference on Language Resources and Evaluation (LREC
2002), pages 827–33, Las Palmas, Canary Islands.
Takaaki Tanaka and Timothy Baldwin. 2003a. Noun-noun
compound machine translation: A feasibility study on shal-
low processing. In Proc. of the ACL-2003 Workshop on
Multiword Expressions: Analysis, Acquisition and Treat-
ment, pages 17–24, Sapporo, Japan.
Takaaki Tanaka and Timothy Baldwin. 2003b. Translation
selection for Japanese-English noun-noun compounds. In
Proc. of the Ninth Machine Translation Summit (MT Sum-
mit IX), pages 89–96, New Orleans, USA.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.205960">
<note confidence="0.911542">Second ACL Workshop on Multiword Expressions: Integrating Processing, July 2004, pp. 24-31</note>
<title confidence="0.947329">Translation by Machine of Complex Nominals: Getting it Right</title>
<author confidence="0.923074">Timothy</author>
<affiliation confidence="0.88824">Stanford</affiliation>
<address confidence="0.997328">Stanford, CA 94305</address>
<email confidence="0.999648">tbaldwin@csli.stanford.edu</email>
<affiliation confidence="0.8288775">Communication Science Nippon Telephone and Telegraph</affiliation>
<address confidence="0.392972">Kyoto,</address>
<email confidence="0.967279">takaaki@cslab.kecl.ntt.co.jp</email>
<abstract confidence="0.977128416666667">We present a method for compositionally translating noun-noun (NN) compounds, using a word-level bilingual dictionary and syntactic templates for candidate generation, and corpus and dictionary statistics for selection. We propose a support vector learning-based method employing target language corpus and bilingual dictionary data, and evaluate it over a English Japanese machine translation task. We show the proposed method to be superior to previous methods and also robust over low-frequency NN compounds.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Emily Bender</author>
<author>Francis Bond</author>
<author>Dan Flickinger</author>
<author>Stephan Oepen</author>
</authors>
<title>This material is based upon work supported by the National Science Foundation under Grant No.</title>
<booktitle>BCS0094638 and also the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI,</booktitle>
<institution>Stanford University.</institution>
<note>We would like to thank</note>
<marker>Bender, Bond, Flickinger, Oepen, </marker>
<rawString>This material is based upon work supported by the National Science Foundation under Grant No. BCS0094638 and also the Research Collaboration between NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation and CSLI, Stanford University. We would like to thank Emily Bender, Francis Bond, Dan Flickinger, Stephan Oepen, Ivan Sag and the anonymous reviewers for their valuable input on this research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jim Breen</author>
</authors>
<title>Building an electronic Japanese-English dictionary.</title>
<date>1995</date>
<booktitle>Japanese Studies Association of Australia Conference.</booktitle>
<contexts>
<context position="10791" citStr="Breen, 1995" startWordPosition="1713" endWordPosition="1714">r our method is robust over NN compounds of different frequency. We return to these questions in 4.1. In order to evaluate basic translation accuracy over the test data, we generated a unique goldstandard translation for each NN compound to represent its optimally-general default translation. This was done with reference to two bilingual Japanese-English dictionaries: the ALTDIC dictionary and the on-line EDICT dictionary. The ALTDIC dictionary was compiled from the ALT-J/E MT system (Ikehara et al., 1991), and has approximately 400,000 entries including more than 200,000 proper nouns; EDICT (Breen, 1995) has approximately 150,000 entries. The existence of a translation for a given NN compound in one of the dictionaries does not guarantee that we used it as our gold-standard, and 35% of JE translations and 25% of EJ translations were rejected in favour of a manually-generated translation. In generating the gold-standard translation data, we checked the validity of each of the randomly-extracted NN compounds, and rejected a total of 0.5% of the initial random sample of Japanese strings, and 6.6% of the English strings, on the grounds of: (1) not being NN compounds, (2) being proper nouns, or (3</context>
</contexts>
<marker>Breen, 1995</marker>
<rawString>Jim Breen. 1995. Building an electronic Japanese-English dictionary. Japanese Studies Association of Australia Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>Robust accurate statistical annotation of general text.</title>
<date>2002</date>
<booktitle>In Proc. of the 3rd International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>1499--1504</pages>
<location>Las Palmas, Canary Islands.</location>
<contexts>
<context position="21548" citStr="Briscoe and Carroll, 2002" startWordPosition="3475" endWordPosition="3478">. 3.3 Corpus data The corpus frequencies were extracted from the same three corpora as were described in 1: the BNC and Reuters Corpus for English, and Mainichi Shimbun Corpus for Japanese. We chose to use the BNC and Reuters Corpus because of their complementary nature: the BNC is a balanced corpus and hence has a rounded coverage of NN compounds (see Table 1), whereas the Reuters Corpus contains newswire data which aligns relatively well in content with the newspaper articles in the Mainichi Shimbun Corpus. We calculated the corpus frequencies based on the tag and dependency output of RASP (Briscoe and Carroll, 2002) for English, and CaboCha (Kudo and Matsumoto, 2002) for Japanese. RASP is a tag sequence grammar-based stochastic parser which attempts to exhaustively resolve inter-word dependencies in the input. CaboCha, on the other hand, chunks the input into head-annotated “bunsetsu” or base phrases, and resolves only inter-phrase dependencies. We thus independently determined the intra-phrasal structure from the CaboCha output based on POS-conditioned templates. 4 Evaluation We evaluate the method over both JE and EJ translation selection, using the two sets of 750 NN compounds described in 2.2. In eac</context>
</contexts>
<marker>Briscoe, Carroll, 2002</marker>
<rawString>Ted Briscoe and John Carroll. 2002. Robust accurate statistical annotation of general text. In Proc. of the 3rd International Conference on Language Resources and Evaluation (LREC 2002), pages 1499–1504, Las Palmas, Canary Islands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lou Burnard</author>
</authors>
<title>User Reference Guide for the British National Corpus.</title>
<date>2000</date>
<tech>Technical report,</tech>
<institution>Oxford University Computing Services.</institution>
<contexts>
<context position="2470" citStr="Burnard (2000)" startWordPosition="348" endWordPosition="349">ty and frequency of NN compounds, we carried out a 1With all Japanese NN compound examples, we segment the compound into its component nouns through the use of the “” symbol. No such segmentation boundary is indicated in the original Japanese. BNC Reuters Mainichi Token coverage 2.6% 3.9% 2.9% Total no. types 265K 166K 889K Ave. token freq. 4.2 12.7 11.1 Singletons 60.3% 44.9% 45.9% Table 1: Corpus occurrence of NN compounds basic study of corpus occurrence in English and Japanese. For English, we based our analysis over: (1) the written portion of the British National Corpus (BNC, 84M words: Burnard (2000)), and (2) the Reuters corpus (108M words: Rose et al. (2002)). For Japanese, we focused exclusively on the Mainichi Shimbun Corpus (340M words: Mainichi Newspaper Co. (2001)). We identified NN compounds in each corpus using the method described in 2.2 below, and from this, derived the statistics of occurrence presented in Table 1. The token coverage of NN compounds in each corpus refers to the percentage of words which are contained in NN compounds; based on our corpora, we estimate this figure to be as high as 3-5%. If we then look at the average token frequency of each distinct NN compound </context>
</contexts>
<marker>Burnard, 2000</marker>
<rawString>Lou Burnard. 2000. User Reference Guide for the British National Corpus. Technical report, Oxford University Computing Services.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunbo Cao</author>
<author>Hang Li</author>
</authors>
<title>Base noun phrase translation using Web data and the EM algorithm.</title>
<date>2002</date>
<booktitle>In Proc. of the 19th International Conference on Computational Linguistics (COLING</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="5426" citStr="Cao and Li (2002)" startWordPosition="851" endWordPosition="854"> translator or MT system to select between based on the full translation context. In the remainder of the paper, we describe the translation procedure and resources used in this research ( 2), and outline the translation candidate selection method, a benchmark selection method and pre-processors our method relies on ( 3). We then evaluate the method using a variety of data sources ( 4), and finally compare our method to related research( 5). 2 Preliminaries 2.1 Translation procedure We translate NN compounds by way of a two-phase procedure, incorporating generation and selection (similarly to Cao and Li (2002) and Langkilde and Knight (1998)). Generation consists of looking up word-level translations for each word in the NN compound to be translated, and running them through a set of constructional translation templates to generate translation candidates. In order to translate kaNkeikaizeN “improvement in relations”, for example, possible word-level translations for are relation, connection and relationship, and translations for are improvement and betterment. Constructional templates are of the form [N✁ in N✁ ] (where N✁ indicates that the word is a noun (N) in English ( ) and corresponds to the t</context>
<context position="32058" citStr="Cao and Li (2002)" startWordPosition="5116" endWordPosition="5119">ith those from Table 6, the overall silver-standard accuracy over the JE data is 0.671 for SVM (compared to 0.602 for CTQ), and that over the EJ data is 0.461 (compared to 0.419 for CTQ). In summary, we have shown our method to be superior to both the baseline and CTQ over EJ and JE translation tasks in terms of both gold- and silverstandard accuracy. We also demonstrated that the method successfully combines crosslingual and target language corpus data, and is relatively robust over low frequency inputs. 5 Related work One piece of research relatively closely related to our method is that of Cao and Li (2002), who use bilingual bootstrapping over Chinese and English web data in various forms to translate Chinese NN compounds into English. While we rely on bilingual dictionaries to determine crosslingual similarity, their method is based on contextual similarity in the two languages, without assuming parallelism or comparability in the corpus data. They report an impressive F-score of 0.73 over a dataset of 1000 instances, although they also cite a prior-based Fscore (equivalent to our Baseline) of 0.70 for the task, such that the particular data set they are dealing with would appear to be less co</context>
</contexts>
<marker>Cao, Li, 2002</marker>
<rawString>Yunbo Cao and Hang Li. 2002. Base noun phrase translation using Web data and the EM algorithm. In Proc. of the 19th International Conference on Computational Linguistics (COLING 2002), Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Grefenstette</author>
</authors>
<title>The World Wide Web as a resource for example-based machine translation tasks.</title>
<date>1999</date>
<booktitle>In Translating and the Computer 21: ASLIB’99,</booktitle>
<location>London, UK.</location>
<contexts>
<context position="33514" citStr="Grefenstette (1999)" startWordPosition="5363" endWordPosition="5364">artially bilingual” web All LOW G S G S G S .451 .641 .463 .657 .630 .842 .657 .850 .420 .655 .452 .674 .532 .762 .546 .776 .314 .561 .341 .633 .396 .755 pages, that is web pages which are predominantly Japanese, say, but interspersed with English words, to extract translation pairs. They do this by accessing web pages containing a given Japanese expression, and looking for the English expression which occurs most reliably in its immediate vicinity. The method achieves an impressive gold-standard accuracy of 0.62, at a recall of 0.68, over a combination of simplex nouns and compound nominals. Grefenstette (1999) uses web data to select English translations for compositional German and Spanish noun compounds, and achieves an impressive accuracy of 0.86–0.87. The translation task Grefenstette targets is intrinsically simpler than that described in this paper, however, in that he considers only those compounds which translate into NN compounds in English. It is also possible that the historical relatedness of languages has an effect on the difficulty of the translation task, although further research would be required to confirm this prediction. Having said this, the successful use of web data by a vari</context>
</contexts>
<marker>Grefenstette, 1999</marker>
<rawString>Gregory Grefenstette. 1999. The World Wide Web as a resource for example-based machine translation tasks. In Translating and the Computer 21: ASLIB’99, London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoru Ikehara</author>
<author>Satoshi Shirai</author>
<author>Akio Yokoo</author>
<author>Hiromi Nakaiwa</author>
</authors>
<title>Toward an MT system without pre-editing – effects of new methods in ALT-J/E–.</title>
<date>1991</date>
<booktitle>In Proc. of the Third Machine Translation Summit (MT Summit III),</booktitle>
<pages>101--106</pages>
<location>Washington DC, USA.</location>
<contexts>
<context position="10690" citStr="Ikehara et al., 1991" startWordPosition="1696" endWordPosition="1699">there is any difference in translationcompositionality for NN compounds of different frequency, and (b) whether our method is robust over NN compounds of different frequency. We return to these questions in 4.1. In order to evaluate basic translation accuracy over the test data, we generated a unique goldstandard translation for each NN compound to represent its optimally-general default translation. This was done with reference to two bilingual Japanese-English dictionaries: the ALTDIC dictionary and the on-line EDICT dictionary. The ALTDIC dictionary was compiled from the ALT-J/E MT system (Ikehara et al., 1991), and has approximately 400,000 entries including more than 200,000 proper nouns; EDICT (Breen, 1995) has approximately 150,000 entries. The existence of a translation for a given NN compound in one of the dictionaries does not guarantee that we used it as our gold-standard, and 35% of JE translations and 25% of EJ translations were rejected in favour of a manually-generated translation. In generating the gold-standard translation data, we checked the validity of each of the randomly-extracted NN compounds, and rejected a total of 0.5% of the initial random sample of Japanese strings, and 6.6%</context>
</contexts>
<marker>Ikehara, Shirai, Yokoo, Nakaiwa, 1991</marker>
<rawString>Satoru Ikehara, Satoshi Shirai, Akio Yokoo, and Hiromi Nakaiwa. 1991. Toward an MT system without pre-editing – effects of new methods in ALT-J/E–. In Proc. of the Third Machine Translation Summit (MT Summit III), pages 101– 106, Washington DC, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kyo Kageura</author>
<author>Fuyuki Yoshikane</author>
<author>Takayuki Nozawa</author>
</authors>
<title>Parallel bilingual paraphrase rules for noun compounds: Concepts and rules for exploring Web language resources.</title>
<date>2004</date>
<booktitle>In Proc. of the Fourth Workshop on Asian Language Resources,</booktitle>
<pages>54--61</pages>
<location>Sanya, China.</location>
<contexts>
<context position="6136" citStr="Kageura et al. (2004)" startWordPosition="961" endWordPosition="964">ons for each word in the NN compound to be translated, and running them through a set of constructional translation templates to generate translation candidates. In order to translate kaNkeikaizeN “improvement in relations”, for example, possible word-level translations for are relation, connection and relationship, and translations for are improvement and betterment. Constructional templates are of the form [N✁ in N✁ ] (where N✁ indicates that the word is a noun (N) in English ( ) and corresponds to the th-occurring noun in the original Japanese; see Table 3 for further example templates and Kageura et al. (2004) for discussion of templates of this type). Each slot in the translation template is indexed for part of speech (POS), and derivational morphology is optionally used to convert a given word-level translation into a form appropriate for a given template. Example translation candidates for , therefore, are relation improvement, betterment of relationship, improvement connection and relational betterment. Generation fails in the instance that we are unable to find a word-level translation for N and/or N . Selection consists of selecting the most likely translation for the original NN compound fro</context>
</contexts>
<marker>Kageura, Yoshikane, Nozawa, 2004</marker>
<rawString>Kyo Kageura, Fuyuki Yoshikane, and Takayuki Nozawa. 2004. Parallel bilingual paraphrase rules for noun compounds: Concepts and rules for exploring Web language resources. In Proc. of the Fourth Workshop on Asian Language Resources, pages 54–61, Sanya, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Feature-rich statistical translation of noun phrases.</title>
<date>2003</date>
<booktitle>In Proc. of the 41st Annual Meeting of the ACL,</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="4488" citStr="Koehn and Knight (2003)" startWordPosition="702" endWordPosition="705"> 84% and 94% over the top250 most frequent English and Japanese NN compounds, respectively, but only 27% and 60%, respectively, over a random sample of NN compounds occurring more than 10 times in the corpus. We develop and test a method for translating NN compounds based on Japanese English MT. The method can act as a standalone module in an MT schedule” vs. keizaikeikaku system, translating NN compounds according to the best-scoring translation candidate produced by the method, and it is primarly in this context that we present and evaluate the method. This is congruent with the findings of Koehn and Knight (2003) that, in the context of statistical MT, overall translation performance improves when source language noun phrases are prescriptively translated as noun phrases in the target language. Alternatively, the proposed method can be used to generate a list of plausible translation candidates for each NN compound, for a human translator or MT system to select between based on the full translation context. In the remainder of the paper, we describe the translation procedure and resources used in this research ( 2), and outline the translation candidate selection method, a benchmark selection method a</context>
</contexts>
<marker>Koehn, Knight, 2003</marker>
<rawString>Philipp Koehn and Kevin Knight. 2003. Feature-rich statistical translation of noun phrases. In Proc. of the 41st Annual Meeting of the ACL, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Japanese dependency analysis using cascaded chunking.</title>
<date>2002</date>
<booktitle>In Proc. of the 6th Conference on Natural Language Learning (CoNLL-2002),</booktitle>
<pages>63--9</pages>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="21600" citStr="Kudo and Matsumoto, 2002" startWordPosition="3483" endWordPosition="3486">ed from the same three corpora as were described in 1: the BNC and Reuters Corpus for English, and Mainichi Shimbun Corpus for Japanese. We chose to use the BNC and Reuters Corpus because of their complementary nature: the BNC is a balanced corpus and hence has a rounded coverage of NN compounds (see Table 1), whereas the Reuters Corpus contains newswire data which aligns relatively well in content with the newspaper articles in the Mainichi Shimbun Corpus. We calculated the corpus frequencies based on the tag and dependency output of RASP (Briscoe and Carroll, 2002) for English, and CaboCha (Kudo and Matsumoto, 2002) for Japanese. RASP is a tag sequence grammar-based stochastic parser which attempts to exhaustively resolve inter-word dependencies in the input. CaboCha, on the other hand, chunks the input into head-annotated “bunsetsu” or base phrases, and resolves only inter-phrase dependencies. We thus independently determined the intra-phrasal structure from the CaboCha output based on POS-conditioned templates. 4 Evaluation We evaluate the method over both JE and EJ translation selection, using the two sets of 750 NN compounds described in 2.2. In each case, we first evaluate system performance accordi</context>
</contexts>
<marker>Kudo, Matsumoto, 2002</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2002. Japanese dependency analysis using cascaded chunking. In Proc. of the 6th Conference on Natural Language Learning (CoNLL-2002), pages 63–9, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde</author>
<author>Kevin Knight</author>
</authors>
<title>Generation that exploits corpus-based statistical knowledge.</title>
<date>1998</date>
<booktitle>In Proc. of the 36th Annual Meeting of the ACL and 17th International Conference on Computational Linguistics (COLING/ACL98),</booktitle>
<pages>704--710</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="5458" citStr="Langkilde and Knight (1998)" startWordPosition="856" endWordPosition="859">em to select between based on the full translation context. In the remainder of the paper, we describe the translation procedure and resources used in this research ( 2), and outline the translation candidate selection method, a benchmark selection method and pre-processors our method relies on ( 3). We then evaluate the method using a variety of data sources ( 4), and finally compare our method to related research( 5). 2 Preliminaries 2.1 Translation procedure We translate NN compounds by way of a two-phase procedure, incorporating generation and selection (similarly to Cao and Li (2002) and Langkilde and Knight (1998)). Generation consists of looking up word-level translations for each word in the NN compound to be translated, and running them through a set of constructional translation templates to generate translation candidates. In order to translate kaNkeikaizeN “improvement in relations”, for example, possible word-level translations for are relation, connection and relationship, and translations for are improvement and betterment. Constructional templates are of the form [N✁ in N✁ ] (where N✁ indicates that the word is a noun (N) in English ( ) and corresponds to the th-occurring noun in the original</context>
</contexts>
<marker>Langkilde, Knight, 1998</marker>
<rawString>Irene Langkilde and Kevin Knight. 1998. Generation that exploits corpus-based statistical knowledge. In Proc. of the 36th Annual Meeting of the ACL and 17th International Conference on Computational Linguistics (COLING/ACL98), pages 704–710, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith N Levi</author>
</authors>
<title>The Syntax and Semantics of Complex Nominals.</title>
<date>1978</date>
<publisher>Academic Press,</publisher>
<location>New York, USA.</location>
<contexts>
<context position="1629" citStr="Levi, 1978" startWordPosition="216" endWordPosition="217">will refer to as N and N in linear order of occurrence) are a very real problem for both machine translation (MT) systems and human translators due to: constructional variability in the translations: kikaihoNyaku “machine translation” (N-N) vs. miNkaNkigyou “private company” (Adj-N) vs. kaNkeikaizeN “improvement in relations” (N in N); lexical divergences in Japanese and English: haifukeikaku “distribution “economic plan/programme” vs. shuyoukeikaku “major project”; semantic underspecification: compounds generally have multiple interpretations, and can only be reliably interpreted in context (Levi, 1978); the existence of non-compositional NN compounds: idobatakaigi “(lit.) well-side meeting”, which translates most naturally into English as “idle gossip”; high productivity and frequency In order to quantify the high productivity and frequency of NN compounds, we carried out a 1With all Japanese NN compound examples, we segment the compound into its component nouns through the use of the “” symbol. No such segmentation boundary is indicated in the original Japanese. BNC Reuters Mainichi Token coverage 2.6% 3.9% 2.9% Total no. types 265K 166K 889K Ave. token freq. 4.2 12.7 11.1 Singletons 60.3%</context>
</contexts>
<marker>Levi, 1978</marker>
<rawString>Judith N. Levi. 1978. The Syntax and Semantics of Complex Nominals. Academic Press, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mainichi Newspaper Co</author>
</authors>
<date>2001</date>
<booktitle>Mainichi Shimbun CD-ROM</booktitle>
<marker>Co, 2001</marker>
<rawString>Mainichi Newspaper Co. 2001. Mainichi Shimbun CD-ROM 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuji Matsumoto</author>
<author>Akira Kitauchi</author>
<author>Tatsuo Yamashita</author>
<author>Yoshitaka Hirano</author>
</authors>
<date>1999</date>
<journal>Japanese Morphological Analysis System ChaSen Version</journal>
<tech>Technical Report NAISTIS-TR99009, NAIST.</tech>
<volume>2</volume>
<contexts>
<context position="8424" citStr="Matsumoto et al., 1999" startWordPosition="1325" endWordPosition="1328">ily on selecting the correct translation for those NN compounds which can be translated compositionally, but we also investigate what happens when non-compositional NN compounds are translated using a compositional method. 2.2 Translation data In order to generate English and Japanese NN compound testdata, we first extracted out all NN bigrams from the Reuters Corpus and Mainichi Shimbun Corpus. The Reuters Copus was first tagged and chunked using fnTBL (Ngai and Florian, 2001), and lemmatised using morph (Minnen et al., 2001), while the Mainichi Shimbun was segmented and tagged using ChaSen (Matsumoto et al., 1999). For both English and Japanese, we took only those NN bigrams adjoined by non-nouns to ensure that they were not part of a larger compound nominal. We additionally measured the entropy of the left and right contexts for each NN type, and filtered out all compounds where either entropy value was .2 This was done in an attempt to, once again, exclude NNs which were embedded in larger MWEs, such as service department in social service department. We next calculated the frequency of occurrence of each NN compound type identified in the English and Japanese corpora, and ranked the NN compound type</context>
</contexts>
<marker>Matsumoto, Kitauchi, Yamashita, Hirano, 1999</marker>
<rawString>Yuji Matsumoto, Akira Kitauchi, Tatsuo Yamashita, and Yoshitaka Hirano. 1999. Japanese Morphological Analysis System ChaSen Version 2.0 Manual. Technical Report NAISTIS-TR99009, NAIST.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guido Minnen</author>
<author>John Carroll</author>
<author>Darren Pearce</author>
</authors>
<title>Applied morphological processing of English.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="8333" citStr="Minnen et al., 2001" startWordPosition="1311" endWordPosition="1314">E) MT and 48.7% of the time for English–Japanese (EJ) MT. In this paper, we focus primarily on selecting the correct translation for those NN compounds which can be translated compositionally, but we also investigate what happens when non-compositional NN compounds are translated using a compositional method. 2.2 Translation data In order to generate English and Japanese NN compound testdata, we first extracted out all NN bigrams from the Reuters Corpus and Mainichi Shimbun Corpus. The Reuters Copus was first tagged and chunked using fnTBL (Ngai and Florian, 2001), and lemmatised using morph (Minnen et al., 2001), while the Mainichi Shimbun was segmented and tagged using ChaSen (Matsumoto et al., 1999). For both English and Japanese, we took only those NN bigrams adjoined by non-nouns to ensure that they were not part of a larger compound nominal. We additionally measured the entropy of the left and right contexts for each NN type, and filtered out all compounds where either entropy value was .2 This was done in an attempt to, once again, exclude NNs which were embedded in larger MWEs, such as service department in social service department. We next calculated the frequency of occurrence of each NN co</context>
</contexts>
<marker>Minnen, Carroll, Pearce, 2001</marker>
<rawString>Guido Minnen, John Carroll, and Darren Pearce. 2001. Applied morphological processing of English. Natural Language Engineering, 7(3):207–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaaki Nagata</author>
<author>Teruka Saito</author>
<author>Kenji Suzuki</author>
</authors>
<title>Using the Web as a bilingual dictionary.</title>
<date>2001</date>
<booktitle>In Proc. of the ACL/EACL 2001 Workshop on Data-Driven Methods in Machine Translation,</booktitle>
<pages>95--102</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="32888" citStr="Nagata et al. (2001)" startWordPosition="5254" endWordPosition="5257"> their method is based on contextual similarity in the two languages, without assuming parallelism or comparability in the corpus data. They report an impressive F-score of 0.73 over a dataset of 1000 instances, although they also cite a prior-based Fscore (equivalent to our Baseline) of 0.70 for the task, such that the particular data set they are dealing with would appear to be less complex than that which we have targeted. Having said this, contextual similarity is an orthogonal data source to those used in this research, and has the potential to further improve the accuracy of our method. Nagata et al. (2001) use “partially bilingual” web All LOW G S G S G S .451 .641 .463 .657 .630 .842 .657 .850 .420 .655 .452 .674 .532 .762 .546 .776 .314 .561 .341 .633 .396 .755 pages, that is web pages which are predominantly Japanese, say, but interspersed with English words, to extract translation pairs. They do this by accessing web pages containing a given Japanese expression, and looking for the English expression which occurs most reliably in its immediate vicinity. The method achieves an impressive gold-standard accuracy of 0.62, at a recall of 0.68, over a combination of simplex nouns and compound nom</context>
</contexts>
<marker>Nagata, Saito, Suzuki, 2001</marker>
<rawString>Masaaki Nagata, Teruka Saito, and Kenji Suzuki. 2001. Using the Web as a bilingual dictionary. In Proc. of the ACL/EACL 2001 Workshop on Data-Driven Methods in Machine Translation, pages 95–102, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grace Ngai</author>
<author>Radu Florian</author>
</authors>
<title>Transformation-based learning in the fast lane.</title>
<date>2001</date>
<booktitle>In Proc. of the 2nd Annual Meeting of the North American Chapter of Association for Computational Linguistics (NAACL2001),</booktitle>
<pages>40--7</pages>
<location>Pittsburgh, USA.</location>
<contexts>
<context position="8283" citStr="Ngai and Florian, 2001" startWordPosition="1303" endWordPosition="1306">be the case 43.1% of the time for Japanese–English (JE) MT and 48.7% of the time for English–Japanese (EJ) MT. In this paper, we focus primarily on selecting the correct translation for those NN compounds which can be translated compositionally, but we also investigate what happens when non-compositional NN compounds are translated using a compositional method. 2.2 Translation data In order to generate English and Japanese NN compound testdata, we first extracted out all NN bigrams from the Reuters Corpus and Mainichi Shimbun Corpus. The Reuters Copus was first tagged and chunked using fnTBL (Ngai and Florian, 2001), and lemmatised using morph (Minnen et al., 2001), while the Mainichi Shimbun was segmented and tagged using ChaSen (Matsumoto et al., 1999). For both English and Japanese, we took only those NN bigrams adjoined by non-nouns to ensure that they were not part of a larger compound nominal. We additionally measured the entropy of the left and right contexts for each NN type, and filtered out all compounds where either entropy value was .2 This was done in an attempt to, once again, exclude NNs which were embedded in larger MWEs, such as service department in social service department. We next ca</context>
</contexts>
<marker>Ngai, Florian, 2001</marker>
<rawString>Grace Ngai and Radu Florian. 2001. Transformation-based learning in the fast lane. In Proc. of the 2nd Annual Meeting of the North American Chapter of Association for Computational Linguistics (NAACL2001), pages 40–7, Pittsburgh, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Rose</author>
<author>Mark Stevenson</author>
<author>Miles Whitehead</author>
</authors>
<title>The Reuters Corpus volume 1 – from yesterday’s news to tomorrow’s language resources.</title>
<date>2002</date>
<booktitle>In Proc. of the 3rd International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>827--33</pages>
<location>Las Palmas, Canary Islands.</location>
<contexts>
<context position="2531" citStr="Rose et al. (2002)" startWordPosition="357" endWordPosition="360">all Japanese NN compound examples, we segment the compound into its component nouns through the use of the “” symbol. No such segmentation boundary is indicated in the original Japanese. BNC Reuters Mainichi Token coverage 2.6% 3.9% 2.9% Total no. types 265K 166K 889K Ave. token freq. 4.2 12.7 11.1 Singletons 60.3% 44.9% 45.9% Table 1: Corpus occurrence of NN compounds basic study of corpus occurrence in English and Japanese. For English, we based our analysis over: (1) the written portion of the British National Corpus (BNC, 84M words: Burnard (2000)), and (2) the Reuters corpus (108M words: Rose et al. (2002)). For Japanese, we focused exclusively on the Mainichi Shimbun Corpus (340M words: Mainichi Newspaper Co. (2001)). We identified NN compounds in each corpus using the method described in 2.2 below, and from this, derived the statistics of occurrence presented in Table 1. The token coverage of NN compounds in each corpus refers to the percentage of words which are contained in NN compounds; based on our corpora, we estimate this figure to be as high as 3-5%. If we then look at the average token frequency of each distinct NN compound type, we see that it is a relatively modest figure given the </context>
</contexts>
<marker>Rose, Stevenson, Whitehead, 2002</marker>
<rawString>Tony Rose, Mark Stevenson, and Miles Whitehead. 2002. The Reuters Corpus volume 1 – from yesterday’s news to tomorrow’s language resources. In Proc. of the 3rd International Conference on Language Resources and Evaluation (LREC 2002), pages 827–33, Las Palmas, Canary Islands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takaaki Tanaka</author>
<author>Timothy Baldwin</author>
</authors>
<title>Noun-noun compound machine translation: A feasibility study on shallow processing.</title>
<date>2003</date>
<booktitle>In Proc. of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment,</booktitle>
<pages>17--24</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="3787" citStr="Tanaka and Baldwin (2003" startWordPosition="584" endWordPosition="587"> reason for which is seen in the huge number of distinct NN compound types. Combining these observations, we see that a translator or MT system attempting to translate one of these corpora will run across NN compounds with high frequency, but that each individual NN compound will occur only a few times (with around 45-60% occuring only once). The upshot of this for MT systems and translators is that NN compounds are too varied to be able to pre-compile an exhaustive list of translated NN compounds, and must instead be able to deal with novel NN compounds on the fly. This claim is supported by Tanaka and Baldwin (2003a), who found that static bilingual dictionaries had a type coverage of around 84% and 94% over the top250 most frequent English and Japanese NN compounds, respectively, but only 27% and 60%, respectively, over a random sample of NN compounds occurring more than 10 times in the corpus. We develop and test a method for translating NN compounds based on Japanese English MT. The method can act as a standalone module in an MT schedule” vs. keizaikeikaku system, translating NN compounds according to the best-scoring translation candidate produced by the method, and it is primarly in this context th</context>
<context position="7648" citStr="Tanaka and Baldwin (2003" startWordPosition="1198" endWordPosition="1201">the fertility of Japanese nouns N✏ and N✏ , respectively, and is the number of translation templates. As a result, there is often a large number of translation candidates to select between, and the selection method crucially determines the efficacy of the method. This translation procedure has the obvious advantage that it can generate a translation for any NN compound input assuming that there are word-level translations for each of the component nouns; that is it has high coverage. It is based on the assumption that NN compounds translate compositionality between Japanese and English, which Tanaka and Baldwin (2003a) found to be the case 43.1% of the time for Japanese–English (JE) MT and 48.7% of the time for English–Japanese (EJ) MT. In this paper, we focus primarily on selecting the correct translation for those NN compounds which can be translated compositionally, but we also investigate what happens when non-compositional NN compounds are translated using a compositional method. 2.2 Translation data In order to generate English and Japanese NN compound testdata, we first extracted out all NN bigrams from the Reuters Corpus and Mainichi Shimbun Corpus. The Reuters Copus was first tagged and chunked u</context>
<context position="12646" citStr="Tanaka and Baldwin (2003" startWordPosition="2014" endWordPosition="2018">as indicating word class conversions (see Table 3). 3 Selection methodology In this section, we describe a benchmark selection method based on monoligual corpus data, and a novel selection method combining monolingual corpus data and crosslingual data derived from bilingual dictionaries. Each method takes the list of generated translation candidates and scores each, returning the highest-scoring translation candidate as our final translation. 3.1 Benchmark monolingual method The monolingual selection method we benchmark ourselves against is the corpus-based translation quality (CTQ) method of Tanaka and Baldwin (2003b). It rates a given translation candidate according to corpus evidence for both the fullyspecified translation and its parts in the context of the translation template in question. This is calculated as:3 where and are the word-level translations of the source language N★ and N★ , respectively, and is the translation template.4 Each probability is calculated according to a maximum likelihood estimate based on relative corpus occurrence. The formulation of CTQ is based on linear interpolation over and , where and . We set to and to throughout evaluation. The basic intuition behind decomposing </context>
<context position="14123" citStr="Tanaka and Baldwin (2003" startWordPosition="2267" endWordPosition="2270">ould hope to score relation to (the) Bandersnatch as being more likely than relation on (the) Bandersnatch. We could hope to achieve this by virtue of the fact that relation occurs in the form relation to ... much more frequently than relation on ..., making the value of greater for the template [N to N ] than [N on N ]. In evaluation, Tanaka and Baldwin (2003b) found the principal failing of this method to be its treatment of all translations contained in the transfer dictionary as being equally likely, where in fact 3In the original formulation, the product was included as a third term, but Tanaka and Baldwin (2003b) found it to have negligible impact on translation accuracy, so we omit it here. 4 and are assumed to be POS-compatible with . Template (JE) Example [N N ]J [N N ]E shijoukeizai “market economy” [N N ]J [N N ]E saNseitasuu “majority agreement” [N N ]J [N of (the) N ]E seikeNkoutai “change of government” Template (EJ) Example [N N ]E [N N ]J exchange rate “kawasereeto” [N N ]E [N teki N ]J world leader “sekaitekileader” [N N ]E [N no N ]J baby girl “oNnanoakachaN” Table 3: Example translation templates (N = noun and Adj = adjective) there is considerable variability in their applicatility. On</context>
<context position="22822" citStr="Tanaka and Baldwin (2003" startWordPosition="3666" endWordPosition="3669">ding to goldstandard accuracy, i.e. the proportion of inputs for which the (unique) gold-standard translation is ranked top amongst the translation candidates. For the method to have a chance at selecting the goldstandard translation, we clearly must be able to generate it. The first step is thus to identify inputs which have translation-compositional goldstandard translations, and generate the translation candidates for each. The translation-compositional data has the distribution given in Table 4. The overall proportion of translation-compositional inputs is somewhat lower than suggested by Tanaka and Baldwin (2003a), although this is conditional on the coverage of the particular dictionaries we use. The degree of translation-compositionality appears to be relatively constant across the three frequency bands, a somewhat surprising finding as we had expected the lower frequency NN compounds to be less conventionalised and therefore have more straightforwardly compositional translations. We use the translation-compositional test data to evaluate the proposed method (SVM ) against CTQ and a simple baseline derived from CTQ, which takes the most probable fully-specified translation JE EJ ALL 297/750 272/750</context>
</contexts>
<marker>Tanaka, Baldwin, 2003</marker>
<rawString>Takaaki Tanaka and Timothy Baldwin. 2003a. Noun-noun compound machine translation: A feasibility study on shallow processing. In Proc. of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, pages 17–24, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takaaki Tanaka</author>
<author>Timothy Baldwin</author>
</authors>
<title>Translation selection for Japanese-English noun-noun compounds.</title>
<date>2003</date>
<booktitle>In Proc. of the Ninth Machine Translation Summit (MT Summit IX),</booktitle>
<pages>89--96</pages>
<location>New Orleans, USA.</location>
<contexts>
<context position="3787" citStr="Tanaka and Baldwin (2003" startWordPosition="584" endWordPosition="587"> reason for which is seen in the huge number of distinct NN compound types. Combining these observations, we see that a translator or MT system attempting to translate one of these corpora will run across NN compounds with high frequency, but that each individual NN compound will occur only a few times (with around 45-60% occuring only once). The upshot of this for MT systems and translators is that NN compounds are too varied to be able to pre-compile an exhaustive list of translated NN compounds, and must instead be able to deal with novel NN compounds on the fly. This claim is supported by Tanaka and Baldwin (2003a), who found that static bilingual dictionaries had a type coverage of around 84% and 94% over the top250 most frequent English and Japanese NN compounds, respectively, but only 27% and 60%, respectively, over a random sample of NN compounds occurring more than 10 times in the corpus. We develop and test a method for translating NN compounds based on Japanese English MT. The method can act as a standalone module in an MT schedule” vs. keizaikeikaku system, translating NN compounds according to the best-scoring translation candidate produced by the method, and it is primarly in this context th</context>
<context position="7648" citStr="Tanaka and Baldwin (2003" startWordPosition="1198" endWordPosition="1201">the fertility of Japanese nouns N✏ and N✏ , respectively, and is the number of translation templates. As a result, there is often a large number of translation candidates to select between, and the selection method crucially determines the efficacy of the method. This translation procedure has the obvious advantage that it can generate a translation for any NN compound input assuming that there are word-level translations for each of the component nouns; that is it has high coverage. It is based on the assumption that NN compounds translate compositionality between Japanese and English, which Tanaka and Baldwin (2003a) found to be the case 43.1% of the time for Japanese–English (JE) MT and 48.7% of the time for English–Japanese (EJ) MT. In this paper, we focus primarily on selecting the correct translation for those NN compounds which can be translated compositionally, but we also investigate what happens when non-compositional NN compounds are translated using a compositional method. 2.2 Translation data In order to generate English and Japanese NN compound testdata, we first extracted out all NN bigrams from the Reuters Corpus and Mainichi Shimbun Corpus. The Reuters Copus was first tagged and chunked u</context>
<context position="12646" citStr="Tanaka and Baldwin (2003" startWordPosition="2014" endWordPosition="2018">as indicating word class conversions (see Table 3). 3 Selection methodology In this section, we describe a benchmark selection method based on monoligual corpus data, and a novel selection method combining monolingual corpus data and crosslingual data derived from bilingual dictionaries. Each method takes the list of generated translation candidates and scores each, returning the highest-scoring translation candidate as our final translation. 3.1 Benchmark monolingual method The monolingual selection method we benchmark ourselves against is the corpus-based translation quality (CTQ) method of Tanaka and Baldwin (2003b). It rates a given translation candidate according to corpus evidence for both the fullyspecified translation and its parts in the context of the translation template in question. This is calculated as:3 where and are the word-level translations of the source language N★ and N★ , respectively, and is the translation template.4 Each probability is calculated according to a maximum likelihood estimate based on relative corpus occurrence. The formulation of CTQ is based on linear interpolation over and , where and . We set to and to throughout evaluation. The basic intuition behind decomposing </context>
<context position="14123" citStr="Tanaka and Baldwin (2003" startWordPosition="2267" endWordPosition="2270">ould hope to score relation to (the) Bandersnatch as being more likely than relation on (the) Bandersnatch. We could hope to achieve this by virtue of the fact that relation occurs in the form relation to ... much more frequently than relation on ..., making the value of greater for the template [N to N ] than [N on N ]. In evaluation, Tanaka and Baldwin (2003b) found the principal failing of this method to be its treatment of all translations contained in the transfer dictionary as being equally likely, where in fact 3In the original formulation, the product was included as a third term, but Tanaka and Baldwin (2003b) found it to have negligible impact on translation accuracy, so we omit it here. 4 and are assumed to be POS-compatible with . Template (JE) Example [N N ]J [N N ]E shijoukeizai “market economy” [N N ]J [N N ]E saNseitasuu “majority agreement” [N N ]J [N of (the) N ]E seikeNkoutai “change of government” Template (EJ) Example [N N ]E [N N ]J exchange rate “kawasereeto” [N N ]E [N teki N ]J world leader “sekaitekileader” [N N ]E [N no N ]J baby girl “oNnanoakachaN” Table 3: Example translation templates (N = noun and Adj = adjective) there is considerable variability in their applicatility. On</context>
<context position="22822" citStr="Tanaka and Baldwin (2003" startWordPosition="3666" endWordPosition="3669">ding to goldstandard accuracy, i.e. the proportion of inputs for which the (unique) gold-standard translation is ranked top amongst the translation candidates. For the method to have a chance at selecting the goldstandard translation, we clearly must be able to generate it. The first step is thus to identify inputs which have translation-compositional goldstandard translations, and generate the translation candidates for each. The translation-compositional data has the distribution given in Table 4. The overall proportion of translation-compositional inputs is somewhat lower than suggested by Tanaka and Baldwin (2003a), although this is conditional on the coverage of the particular dictionaries we use. The degree of translation-compositionality appears to be relatively constant across the three frequency bands, a somewhat surprising finding as we had expected the lower frequency NN compounds to be less conventionalised and therefore have more straightforwardly compositional translations. We use the translation-compositional test data to evaluate the proposed method (SVM ) against CTQ and a simple baseline derived from CTQ, which takes the most probable fully-specified translation JE EJ ALL 297/750 272/750</context>
</contexts>
<marker>Tanaka, Baldwin, 2003</marker>
<rawString>Takaaki Tanaka and Timothy Baldwin. 2003b. Translation selection for Japanese-English noun-noun compounds. In Proc. of the Ninth Machine Translation Summit (MT Summit IX), pages 89–96, New Orleans, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>