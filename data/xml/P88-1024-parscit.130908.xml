<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<sectionHeader confidence="0.825048" genericHeader="method">
ATOMIZATION IN GRAMMAR SHARING
</sectionHeader>
<email confidence="0.304647">
ABSTRACT
</email>
<note confidence="0.484466">
Megumi Kameyama
Microelectronics and Computer Technology Cooperation (MCC)
3500 West Balcones Center Drive, Austin, Texas 78759
megumi@mcc.com
</note>
<bodyText confidence="0.984499207920792">
new insights with which to account for certain linguistic
problems. Before we go into more detail, the following is
our view of what general components and mechanisms
constitute a shared grammatical system.
We describe a prototype SHARED GRAMMAR for the
syntax of simple nominal expressions in Arabic, English,
French, German, and Japanese implemented at MCC. In
this grammar, a complex inheritance lattice of shared
grammatical templates provides parts that each language
can put together to form language-specific grammatkal
templates. We conclude that grammar sharing is not only
possible but also desirable. It forces us to reveal cross-
linguistically invariant gammatical primitives that may
otherwise remain conflated with other primitives if we deal
only with a single language or language type. We call this
the process of GRAMMATICAL ATOMIZATION. The specific
implementation reported here uses categorial unification
grammar. The topics include the mono-level nominal
category N, the functional distinction between
ARGUMENT and NON-ARGUMENT of norninals,
grammatical agreement, and word order types.
Is grammar sharing possible?
The multilingual project of MCC attempts to build a
grammatical system hierarchically shared by multiple
languages (Slocum &amp; Justus 1985). GRAMMAR SHARING as
proposed should have an advantage over a system with
separate grammars for different languages: It should reduce
the size of a multilingual rule base, and facilitate the
addition of new languages. Before presenting evidence for
such advantages, however, there is the basic question to be
answered: Is grammar sharing at all possible? Although it
is well known that languages possess similarities based on
genetic, typological, or areal grounds, the question remains
whether and how these similarities translate into
computational techniques.
In this paper, we will describe a prototype shared
grammar for simple nominal expressions in Arabic,
English, French, German, and Japanese.I We conclude that
grammar sharing is not only possible but also desirable. It
forces us to reveal cross-linguistically invariant
grammatical primitives that may otherwise remain
conflated with other primitives if we deal only with a single
language or language type. We call this the process of
GRAMMATICAL KrourzAmoN2 forced by grammar sharing.
Each language or language type is then characterized by
particular combinations of such primitives, often providing
1Preliminary investigations have also been made on
Spanish, Russian, and Chinese.
2The verb atomize means &amp;quot;to separate or be separated
into free atoms&amp;quot; (The Collins English Dictionary, 2nd
edition, 1986).
Bask mechanisms in a shared grammar: The
process of building a shared grammar, in our view, requires
(i) linguistic description of a set of languages in a common
theoretical framework, (ii) a mechanism for EXTRACTING a
common grammatical assertion from two or more
assertions, and (iii) a mechanism for MERGING grammatical
assertions. The linguistic description should define certain
string-combination operations (defined on string TYPES)
associated with information structures. Then what we do is
identify sharable packages of common string-types and
information structures among independently motivated
language-specific grammatical assertaions. These
packages are then put into the shared part of the grammar,
and the remaining language-specifics are potential sources
for more sharing. This extraction is essential in what we
call ATOMIZATION, which is basically &amp;quot;breaking up of
grammatical assertions into smaller independent parts&amp;quot; (i.e.
decomposition). If we assume that all grammatical
assertions are expressed in terms of FEATURE sraucruaEs
(Shieber 1986), the atomization process would be defined
around the notion of GENERALIZATION (i.e. reverse of
UNIFICATION) as follows:
bade atomization: Given two feature
structures, Xa for category X in language A and
Xb for category X in language B, the shared
structure Xa for category X is the
GENERALIZATION Of Xa and Xb (i.e., the most
specific feature structure in common with both
Xa and Xb). Xa is separated out of either Xa or
Xb, and placed into the shared space.
Consequently, a partial ordering is established
wherein Xa SUBSUMES Xa and Xb, respectively.
There is an underlying assumption that two language-
specific definitions of a common grammatical category
share something in common no matter how small it is. This
means that the linguistic descriptive basis is questionable if
the content of Xa above is null. Conversely, if clearly
common information structures appear under language-
specific definitions of distinct grammatical categories, we
may suspect a basis for a new common grammatical
category.
Once the shared and language-specific parts are
separated out, a mechanism for merging them is necessary
for successfully incorporating the shared assertion into the
language-specific assertion. UNIFICATION by INHERITANCE
is such a merging mechanism that we employ in our system
(see below). The shared space is a complex inheritance
lattice that provides various predefined grammatical
assertions that can be freely merged to create language-
specific ones.
</bodyText>
<page confidence="0.997839">
194
</page>
<bodyText confidence="0.9992068">
Shared inheritance lattice: Let us now take a look at
a grossly simplified shared inheritance lattice that results
from the process described above. See Figure 1. There is a
universal notion N(ominal) in all five languages under
consideration. This common notion is part of the N
definition of each language by inheritance. There are some
nominals that are &apos;complete&apos; in the sense that they can be
used as subjects or objects (e.g.! saw cat:slaw cat.). Some
others are &apos;incomplete&apos; in that they cannot be used as such
(e.g. I saw &amp;quot;cat.). General notions Complete and
Incomplete are thereby defined for characterizing relevant
nominal classes of each language (see the discussion on
ARG vs. NON-ARG below). Since Determiners in
English, German, and French make such incomplete
nominals complete, the Determiner definition inherits (i.e.
includes) the definition of Complete. Lexical items in these
languages are defined by multiply inheriting relevant
assertions:
In what follows, we will first describe the specific
linguistic and computational approaches that we employed
to build our first shared grammar. We will then discuss the
grammatical primitives for characterizing general
nominals, adnominal modifiers, agreement, and word order
types, illustrating solutions to specific cross-linguistic
problems. We will end with prospects for further work.
</bodyText>
<subsectionHeader confidence="0.778918">
Framework
</subsectionHeader>
<bodyText confidence="0.99915619047619">
Grammatical framework: We use a categorial
unification grammar (CUG) (Wittenburg 1986a; Karttunen
1986; Uzkoreit 1986b). The one described here is a non-
directional categorial system (e.g. Montague 1974;
Schmerling 1983; van Benthem 1986:Ch.7) with a non-
directed functional application rule as the only reduction
rule (i.e., a functor XIY may combine with adjacent Y in
either direction to build X). Non-directionality allows for
desired flexibility in the shared part of the grammar. A
separate component constrains the linear order of elements
in each language (see Aristar 1988 for motivation).
Unification and template inheritance: CUG&apos;s lexical
orientation and unification are employed. In the upacoN of
each language, lexical items are defined to be the
unification of language-specific GRAMMATICAL TEMPLATES
(Shieber 1984, 1986; Flickenger et al. 1985; Pollard &amp; Sag
1987). These language-specific templates, prefixed with
AR(abic), EN(glish), FR(ench), GE(rman), and JA(panese),
are feature structures composed by multiple inheritance
from shared graminatical templates prefixed with SG (for
&amp;quot;Shared Grammar&amp;quot;). SG-templates are themselves
composed by multiple inheritance in a complex
INHERruarcz LArricE, whose bottom-end feeds into
language-specific templates. The CUG parser (MCC&apos;s
Astro, Wittenburg 1986b) applies reduction rules to the
feature structures of words in the input string.3 Arabic and
Japanese strings are currently represented in Roman letters
(augmented for Arabic) with spaces between &apos;words &apos;.4
3Tbe parser is linked to an independently developed
morphology analyzer (Slocum 1988). This enables each
word to undergo a morphological analysis including a
dictionary look-up of the root morpheme, and to output a
list (or alternative lists) of grammatical template names
that, when their contents are unified, produce a single
feature structure (or more than one if the word is
ambiguous) for that particular token word.
4If we were to process Japanese texts directly, the system
would have to perform morphological and syntactic
analyses simultaneously since there is no explicit word
boundaries. (This is one of the strong motivations for our
recent movement toward building a new CUG-based
morphology system.)
</bodyText>
<page confidence="0.998062">
195
</page>
<subsectionHeader confidence="0.96826">
Present linguistic coverage
</subsectionHeader>
<bodyText confidence="0.9995314375">
Simple nominals: The present linguistic coverage is
the syntax of SIMPLE Nommis: nouns and nominal
expressions with lexical or phrasal modifiers such as
attributive adjectives (e.g. long), demonstratives (e.g. this),
articles (e.g. the), quantifiers (e.g. all), numerals (e.g.
three), genitives (e.g. of the Sun), and pp-modifiers (e.g. in
the ocean). Complex nominals including conjunctions,
derived nominals, gerunds, nominal compounds, and
relative clause modification have not been handled yet.
Data analysis: We first analyzed a data chart of simple
nominals in each language. The chart focused on the
syntactic well-formedness of nominal expressions, in
particular, the order and dispensability of elements when
the nominal expression acts as an argument (e.g. subject,
object) to a verb or an adposition (i.e. preposition or
postposition).
</bodyText>
<subsectionHeader confidence="0.950844">
Shared templates overview
</subsectionHeader>
<bodyText confidence="0.993820545454546">
By design, the so-LATricE captures shared grammatical
features in the given set of languages, whether they are due
to universal, typological, genetic, or areal bases. As our
research proceeded, we observed an atomization process
whereby more and more grammatical properties were
distinguished. This was because certain grammatical
characterizations that seemed most natural for some
language(s) were only partially relevant to others, which
forced us to break them down into smaller parts so that
other languages can use only the relevant parts.
Modules In the SG-lattice: As the shared templates
underwent atomization, we created sublattices
corresponding to independent grammatical modules so that
a grammar writer can make a language-specific
combination of shared templates by consciously selecting
one or more from each group. The existing subgroups are:
(i) categorial grammar categories (the theory-dependent
aspect of the shared grammar), (ii) common syntactic
categories (theory-independent linguistic notions), (iii)
grammatical agreement (to handle grammatical agreement
within nominals), (iv) reference types (semantic features of
the nominals, e.g. definite, indefinite, specific), (v)
determiner types (to handle co-occurrence and order
restrictions among determiners), and (vi) attributive
modifier types (to handle order restrictions among
attributive modifiers). We will focus on (i)-(iii) in this
paper.
Kinds of SG-templates: SG-templates as they exist
fall under the following types. The most general distinction
can be made between ATOMIC and comaosrrE templates.
Atomic templates inherit from no other template. They
result from the atomiration process, and are primitive parts
that a grammar writer can put together to create more
complex templates. A composite template inherits from at
least one other, to which a partial structure defined for
itself may be added. We may also distinguish between
trriurr and sunsrAt•rrivE templates. Utility templates
contribute integral parts of categorial grammar categories
such as how many arguments they need to combine with—
none for a BASIC CATFJ3ORY, and one OT more for a
FUNCTOR CATEGORY. Substantive templates supply
grammatical categories and features expressed in terms of
various linguistic notions. Specific examples are discussed
below.
</bodyText>
<subsectionHeader confidence="0.9918085">
Highlights of shared grammatical atoms
The basic graph structure
</subsectionHeader>
<bodyText confidence="0.995553407407407">
Each word must be associated with a complete CUG
feature structure. The current implementation uses a
matrix notation for ACYCUC DIRECTED GRAPH. See Figure
2:
A category is either SATURATED (looking for no
argument) or UNSATURATED (needing to combine with one
or more arguments). It is saturated when the value of
ARGUMENTS is &apos;closed&apos; with symbol #. An unsaturated
category may seek one or more arguments, each of which
is either unspecified ([ ]) or typed (e.g. [cat: N]). Overall
saturation is sought in parsing. The parser assigns index
numbers to words in the input string from left to right, and
coindexes corresponding substructures under ELEMENTS.
The ELEMENTS component currently has A for the word
for which this structure is defined, B for the first argument,
and C for the second argument. These labels simply flag
PATHS for accessing particular elements. There can be any
number of order-relevant labels corresponding to an
element. These labels, with coindices with respective
elements, are in the ORDER component, which is subject
to the Word Order Constraint (discussed later). TYPE is
the slot for assigning the pseudo-functional category ARG
or NON-ARG that we found significant in the present
cross-linguistic treatment of nominals (see below).
AGR(eement) and FEATS subgraphs contain grammatical
and pragmatic agreement features, respectively (discussed
later).
</bodyText>
<figure confidence="0.847834076923077">
[result: [cat: [1 &lt;- the syntactic type of a
index: [ ] &lt;- relative linear position of a
agr: [ I &lt;- grammatical agreement features of a
(optional)
feats: ( I &lt;- pragmatic agreement features of a
type: [ &lt;- the functional type of a (see below)
elements: [ I &lt;- elements within a
order: [ ] &lt;- order of elements (see below)
arguments: [II &lt;- arguments sought (see below)
IFigure2. The notation for a word whose resulting structure Is a
196
atomic templates
%SG-NO-ARGUMENTS: [arguments: #] &lt;- saturates the category
SSG-LEX: [result: [elements: [a: [lex: [ 1)111 &lt;- has a slot for the word form
%SG-WORD-FEATS-ARE-TOP-FEATS: &lt;- passes the word&apos;s own features to the top
[result: [feats: &lt;1&gt;
elements: [a: [feats: 1[ JIM
Inheritance of composite templates
%SG-WORD-FEATS-ARE-TOP-FEATS SSG-LEX
JA-N EN-N FR-N GE-N AR-N
Figtire 3. General N
%SG-NO-ARGUMENTS SSG-N: [result: [cat: NJ
SSG-N-WITH-NO-ARGUMENTS
/
(relevant agreement templates)
(see below)
</figure>
<bodyText confidence="0.991851378787879">
A few more remarks about the notation follow. A
value can be either atomic (e.g N), a disjunction of atomic
values enclosed in curly brackets (e.g. {N P}), or a
complex feature structure. It can also be unspecified a D.
The identity of two or more values is forced by reentrant
structures indicated by coindexing (e.g. 1[ ] and &lt;1&gt;).
Such coreferring value slots automatically point to a single
data structure entered through any one of the slots.
Universal mono-level category N
Category N: We posit the universal category N for
nominals. Nominals here are those that realize ARGUMENTS
such as subjects and objects. Nominals are more
commonly labeled NP, a phrase typically built around N or
CN (common noun), as in phrase structure NP-&gt;DET N as
well as in the categorial grammar characterization of DET
as a functor NP/CN (i.e. combines with CN and builds NP)
(e.g. Ades &amp; Steadman 1982; Wittenburg 1986a). This
BI-LEVEL view of nominals is motivated by facts in western
European languages. In English, for instance, while cat or
white cat cannot fin a subject position, a cat and this cat
can. In contrast, while he can be a subject, it cannot be
modified as this he or strange he. This motivates the
following category-assignments with a constraint that only
NPs can be arguments: cat is CN, he is NP, a and this are
NP/CN, and white and strange are CN/CN. This, however,
requires that plurals and mass nouns be CN and NP at the
same time since cats, gold, white cats, white gold, these
cats, and this gold can all be arguments. The count/mass
distinction is also often blurred since a singular count noun
like cat may be used as a mass noun referring to the meat
of the cat, and a mass noun like gold may be used as a
singular count noun referring to a uNrr of gold or a KIND of
gold (see e.g. Bach 1986). The boundary between NP and
CN is at best FUZZY.
When we turn to other languages, the basis for the
bi-level view vanishes. In Japanese, for instance., neko &apos;cat&apos;
can be an argument on its own, and pronoun here &apos;he&apos; can
be modified as in ano here &apos;that he&apos; and okasina kare
&apos;strange he&apos;. In short, there is no basic syntactic difference
among count nouns, pronouns, and mass nouns (and no
singular/plural distinction on a &apos;count&apos; noun). All of them
behave hire plural and mass nouns in English. This
supports a mono-level view of nominals, which we intend
to capture with category N. Figure 3 shows the SG-
templates relevant to the most general characterization of N
in each language. SG-templates in the following
illustrations are marked as follows: atomic templates SG-x
(boldface), utility templates %SG-x, and substantive
templates SSG-x.
At the most general level, the basic nominals in
German (GE-N) and Arabic (AR-N) must be unsaturated
because genitive-inflected Ns may take arguments. The
basic nominals in Japanese (JA-N), English (EN-N), and
French (FR-141), on the other hand, are basic categories that
are saturated? In addition, all but JA-N inherit relevant
AGR(eement) templates (see below). Crucially, note that
what looks lie a reasonable characterization of N in each
language actually consists of a particular selection from the
common set of primitives.
ARGUMENT and NON-ARGUMENT: We posit a
pseudo-functional level of description in terms of
ARG(ument) and NON-ARG for category N instead of the
category-level distinction between NP and CN. ARG may
function as an argument alone, and NON-ARG cannot
sNote that English possessive marker &apos;s is not treated as
an inflection here.
</bodyText>
<page confidence="0.992099">
197
</page>
<bodyText confidence="0.998878221153847">
NON-ARG becomes ARG only by being combined with a
certain modifier or by undergoing a semantic change (e.g
massifying). In this view, the ARG/NON-ARG distinction
is &apos;grounded on a complex interaction of morphology,
semantics, and syntax.
In English and German, singular count nouns (e.g. tree,
Baum) are NON-ARG while plurals, mass (singular)
nouns, proper names, and pronouns are ARG. The NON-
ARG nouns become &apos;complete&apos; ARG nominals either by
being modified with determiners or by changing into mass
nouns (typically changing an object reference into a
property/substance reference, e.g., I used apple in my
pie.).6 In French, all forms of common nouns (i.e. singular,
plural, and mass) are NON-ARG, in need of determiners to
become ARG (e.g, ai vu *arbresges arbres &apos;I saw trees&apos;;
*AmourIL: amour est delicat &apos;Love is delicate&apos;).
In Japanese, there are few NON-ARG nouns (e.g., kata
&apos;person&apos; (HONORIFIC)), which can become ARG with
any modifier such as a relative clause or an adjective (e.g.
himana kata &apos;free person (HON.)..7 In Arabic, the
morphological distinction of nouns between ANNEXED VS.
UNANNE/CED corresponds to NON-ARG and ARG statuses,
respectively.8 For instance, the unannexed form qiffami
CAT-DUAL NOM-UNANNEX &apos;two cats&apos; may occur as subject
alone whereas the annexed form qiitp: CAT-DUAL NOM
cannot The latter must be modified with a noun-based
modifier such as a genitive phrase, and this modifier must
be unannexed (e.g. with rajulin MAN-OEN-UNANNEX,
rajulin `man&apos;s two cats&apos;). These facts in Japanese and
Arabic show that the proposed functional distinction for
nominals is motivated independently from the syntactic
role of determiners since neither language has modifiers of
category DET that we find in English, French, and German
(more discussed later).
We realize that the ARG/NON-ARG distinction itself
is not a fmal solution until fine-grained syntactic-semantic
interdependence is fleshed out. For now, we simply posit
pseudo-functional types ARG and NON-ARG, which are
either changed or passed up within the nominal structure:9
SSG-ARG: [result [type: ari]]
$SG-NON-ARG:[result: [type: non-arg]]
Category NIN: Adnominal modifiers (N-MODS) are
now universally NIN (Le. a functor that combines with N
and builds N). This includes both determiners and
attributive modifiers. Figure 4 shows the SG-templates for
the basic N-MOD. Different kinds of N-MOD must then
distinguish whether it takes one or two arguments and
whether the resulting nominal with modification is ARG or
NON-ARG. Each distinction is briefly illustrated below.
Two kinds of genitive: Genitive N-MOD functors
may take different numbers of arguments cross-
linguistically. An inflected genitive nominal (e.g. GE:
Marias, AR: rajulin &apos;man&apos;s&apos;) takes one, while a genitive
adposition (e.g. EN: of) takes two. The former is captured
with SG-INFLECTIONAL-GENITIVE-CASE-MOD, and
the latter, with SG-PARTICLE-GENITIVE-CASE-MOD.
See Figure S.
Non-universal determiner category: In the present
approach, DET(erminer) is a modifier type (including
articles, demonstratives, quantifiers, numerals, and
possessives) such that at least one of its members is needed
for making an ARG nominal out of a NON-ARG. The fact
that a nominal with a determiner is always ARG translates
into SG-DET inheriting from SG-ARG among others.
DET is present in English, German, and French, but not in
Japanese or Arabic (or Russian or Chinese).
Demonstratives, quantifiers, numerals, and possessives in
the latter languages do not share the syntactic function of
DET. We suspect that the presence of DET is an meal
property of western European languages.
The sublattice in Figure 6 highlights two aspects of
DEL One is the difference between DET and ADJ(ective)
in English, German, and French with respect to the ARG
status of the resulting nominal. DET always builds ARG
cancelling whatever the type of the incoming nominal
whereas ADJ passes the type of the incoming nominal to
the top. The other is the place of demonstratives in relation
to DET. Every language has demonstratives encoding two
or three degrees of speaker proximity (e.g. JAPANESE:
kono (close to the speaker), sono (close to the addressee),
6In implementation, this latter process may be triggered
by a unary rule COUNT-&gt;MASS.
7They are assigned a NON-ARG category MN (for
&apos;modified noun&apos;) separate from the ARG category N. Any
modifier changes it into ARG.
ANNEXED here means &apos;needing to be annexed to a noun-
based modifier&apos;, and UNANNEXED means &apos;completed&apos;.
These are also called NONNUNATED and NUNATED forms,
respectively, in Semitic linguistics (Arista, personal
communication).
9An intriging direction is shown in Krifka&apos;s (1987)
categorial grammar treatment He assigns the singular
count noun in English (i.e. our NON-ARG) an unsaturated
nominal category looking for its numerical value both in
syntax and semantics. The significance of determiners is
here as suppliers of numerical values. How this approach
can be extended to cover the NON-ARG nominals in
Arabic and Japanese (which are not in need of numerical
values per se) remains to be seen. Although it makes sense
to see NON-ARG as a functor looking for more semantic
determination, implementing it would require a reduction
rule for TWO FUNCTORS LOOXING FOR EACH OTHER. The
current system would cause an infinite regression with such
a zule.
</bodyText>
<page confidence="0.996697">
198
</page>
<table confidence="0.9441105625">
atomic templates
%SG-HEAD-FEATS-ARE-TOP-FEATS: &lt;- passes the features of the second
[result: [feats: &lt;1&gt; element to the top
elements: [b: [feats: 1[ 111]]
%SG-FIRST-ARGUMENT: &lt;- slot for the first argument
[result: [elements: [b: &lt;1&gt;]]
arguments: [first: [result: 1[ 11111
%SG-GET-ORDER: &lt;- passes the ORDER content of the first argument to the top
[result: [order: (l&lt;1&gt;]]
arguments: [first: [result: [order: 1(J)]]]
SSG-MOD: &lt;- for a category-constant functor MOD (see below)
[result: [cat: 4[ ]
elements: (a: [index: &lt;1&gt;]
b: &lt;3&gt;)
order: [(mod: 1(J) [head: 2[ 11]
arguments: [first: [result: 3Icat: &lt;4&gt;
</table>
<figure confidence="0.8871464">
index: &lt;2&gt;]]]
Inheritance of composite templates
SSG-N (above) %SG-HEAD-FEATS-ARE-TONFEATS
%SG-FIRST-ARG %SG-GET-ORD SG-MOD
SSG-N-MOD&lt;- for the general acinominal modifier
</figure>
<figureCaption confidence="0.968148">
Figure 4. General N-MOD
</figureCaption>
<figure confidence="0.935587625">
atomic templates
%SG-ARGUMENTS-REST-SATURATED:
[arguments: [rest: it]]
%SG-ONLY-TWO-ARGUMENTS:
[arguments: [rest: [first: [arguments: it]
rest: 0]]]
&lt;- saturates the second argument
&lt;- no more than two arguments sought
SSG-GENITIVE: &lt;- assigns the genitive case feature
[result: [elements: [a: [feats: [case: genitive)]])]
Inheritance of composite templates
SSG-N-MOD (above)
SSG-CASE-MOD: &lt;- for the general case-mod
[result: [elements: [a: [cat: (P N) &lt;- P or N
feats: [mod-type: case-mod]]]]]
%SG-INFLECTIONAL -CASE-MOD SSG-GENITIVE SSG-PARTICLE -CASE-MOD -CASE
(chooses Tory N) / \\\ (chooses category P) -MOD
%SG-INFLECTIONAL-GENITIVE -CASE -MOD SSG-PARTICLE-GENITIVE
AR-N
(above)
GE-N / i
WIF
(above)
GE: Merles AR: rajulin `man&apos;s EN: of JA: no
</figure>
<figureCaption confidence="0.999552">
Figure 5. Genitive Case MOD
</figureCaption>
<page confidence="0.997019">
199
</page>
<bodyText confidence="0.998992">
and ano (away from either)), but they belong to the class of
determiners only if the language has DET.
</bodyText>
<subsectionHeader confidence="0.792556">
Grammatical agreement (AGR)
</subsectionHeader>
<bodyText confidence="0.977776480519481">
Two kinds of features are distinguished, linguistic
features relevant to GRAMMATICAL AGREEMENT (e.g. French
grammatical gender unel*un table &apos;a table&apos; f.), and referent
features relevant to PRAGMATIC AGREEMENT (e.g. using she
to refer to a female person; using appropriate numeral
classifiers for counting objects in Japanese). The former is
under attribute AGR, and the latter is under FEATS. The
N-internal grammatical agreement (AGR) requires that
certain features of the HEAD Nominal must agree with
those of MOD. For instance, English has number
agreement (e.g. this book *those book, this books).
Among the five languages under consideration, all but
Japanese have AGR.
Although there is cross-linguistic variation in AGR
features, it is not random (Moravcsllr 1978). Table 1 sums
up the N-internal AGR features in the four languages. All
AGR features go under attribute AGR so that its presence
simply corresponds to the presence of grammatical
agreement in a language. EN-N, for instance, inherits the
shared template for number agreement, and FR-N inherits
those for number and gender agreements. See below:
$SG-NBR-AGR:
[result [agr: [nbr: &lt;1&gt;]
elements: [a: [feats: [nbr: 1 [J]]]]]
$SG-GDR-AGR:
[result [agr: [gdr: &lt;1&gt;]
elements: [a: [feats: [gdr: 10Bm
Separating AGR and FEATS enables us to create SG-
templates that impose the most general agreement
constraint regardless of the precise content of agreement
features. Three agreement templates produce the combined
effect of N-internal agreement constraint, SG-AGR, SG-
AGR-ARGUMENTS, and the composite of the two, SG-
AGR-WITH-ARGUMENTS. See Figure 7.
The reentrancies impose the strict identity of AGR
features: (i) SSG-AGR--between the topmost structure
and the element that the graph is defined for, (ii)
$SG-AGR-ARGUMENTS—between the topmost
structure and the first argument, and (iii) SSG-AGR-
WITH-ARGUMENTS—among all the three. (i) goes into
ALL NOMINAIS, passing the nominal&apos;s AGR features to the
top level This is because the AGR features must always be
available at the top level of a nominal so that they can be
used when the nominal is further modified. (ii) goes into
ALL ADNOMINAL MODIFIERS, passing the head nominal&apos;s
AGR features to the top level (ill) goes into ONLY THOSE
ADNOMINAL MODIFIERS SUBJECT TO THE AGE CONSTRAINT,
for instance, demonstratives (e.g. these) but not attributive
adjectives (e.g. small) in English, and both demonstratives
and adjectives in French (see this difference in the above
inheritance).
This is an example where a better language-specific
treatment is obtained from the grammar-sharing
perspective. If only English is handled, one may simply
force the identity of NBR features amidst all kinds of other
features, but in the light of cross-linguistic variation and
invariants, it lends itself naturally to separating out two
kinds of features that correspond to different semantic
interpretation processes.
Category constancy and word order
typology
In connecting word order typology and categorial
grammar, we have benefited from work of Greenberg
(1966), Lehmann (1973), Vennemann (1974, 1976, 1981),
Keenan (1979), Flynn (1982), and Hawkins (1984).
Among these, we have a first-cut implementation of
Vennemann&apos;s (1981) and Flynn&apos;s (1982) view that the
functor types based on CATEGORY CONSTANCY have a
significant relation to the default word order of a language.
A functor is CATEGORY-CONSTANT if it builds the same
category as its argument(s). It is CATEGORY-NON-CONSTANT
if it builds a different category from its argument(s). These
notions are also called ENIXYTYPIC and Exaratc,
respectively, by Bar-Hille,1 (1953), and are crucially used in
Flynn&apos;s high-level word order convention statements. The
definitions of the notions MOD (modifier), HEAD (head),
FN (function), and ARG (argument) follow:
</bodyText>
<listItem confidence="0.9907218">
• MOD is a category-constant functor (XIX) that
combines with HEAD (X). (see above for SG-
MOD)
• FN is a category-non-constant functor (YIX)
that combines with ARG (X).
</listItem>
<table confidence="0.981933363636364">
category category
constant non-constant
X /
/
XIX X Y IX X
1 1
MOD HEAD TN ARG
•.g.
NIN N PPIN N
adj noun prep noun
red roof for Max
</table>
<bodyText confidence="0.994504">
There is cross-linguistic evidence that MOD-HEAD
and FN-ARG orders tend to go in opposite directions. This
amounts to two basic word order types in languages:
</bodyText>
<sectionHeader confidence="0.93982525" genericHeader="method">
ORDER TYPE 1: ARG &lt; Pll
MOD &lt; READ
ORDER TYPE 2: TN &lt; ARG
READ &lt; MOD
</sectionHeader>
<bodyText confidence="0.991161181818182">
(where &lt; reads as &apos;precedes&apos;)
The N-level default word order in a language is determined
as follows: Every language has ADPOSTTIONS (prepositions
and postpositions), universally a category-non-constant
functor PPIN. A postpositional language (i.e. a language
that uses only or predominantly postpositions) then belongs
to TYPE 1 (ARG &lt; FN), and a prepositional language
belongs to TYPE 2 (FN &lt; ARG). In the present case, EN,
GE, FR, and AR are prepositional while JA is
postpositionaL
The default MOD order is most faithfully observed in
</bodyText>
<page confidence="0.971404">
200
</page>
<figure confidence="0.53139705">
czInheritance of composite templates
SSG-ARG (see above)
%SG-ARGUMENTS-REST-SATURATED (see above)
ss DET
{various templates
e cooccurrence
for constraining
the
i
and order inside DET) SSG-DEM(onstrative)
EN-DEM FR-DEM GE-DEM JA-DEM AR-DEM
1 1
this ce dieser kono ha Ba:
(these inherit SSG-PROX1 (proximate to speaker))
SSG-HEAD-TYPE-IS-TOP-TYPE:
[result: [type: &lt;1&gt;
elements: Ib: [type: 1[ 11])]
EN-ATI7RB-ADJ GE-ATTRIB-ADJ FR-ATTRIB-ADJ AR-ATTRIB-ADJ JA-ATTRIB-AD.1
11&apos; kabiyr ookil
big gross grand •
</figure>
<figureCaption confidence="0.479751">
Figure 6. DEM and ATTRIB-ADJ in relation to DET
</figureCaption>
<table confidence="0.891102411764706">
SSG-N-MOD (see above)
DEFINITE: ANNEXED
NUMBER: GENDER: CASE:
ARABIC: SG DU P1.3 M F NOM ACC GEN
GERMAN: SG PL M F N NOM ACC GEN DAT
FRENCH: SG PL M F
ENGLISH: SG PL
chiens
JA-N EN-N
11
mu dogs
Table 1. N-internal Agreement Features
atomic templates .
%SG-AGR: [result: [agr: &lt;1&gt;
elements: [a: [agr: 1[ 1]1))
SSG-AGR-ARGUMENTS: [result: [agr: &lt;1&gt;]
arguments: [first: [result: [AGR: 1[ )111]
</table>
<figure confidence="0.960823555555555">
Inheritance of composite templates
small
SSG-AGR-ARGUMENTS
SSG -N-MOD (above)
$SG-NBR-AGR (above)
$SG-AGR- ITH-ARGUMENTS
SG-GDR-AGR (above)
etc.
if
-N-MOD FR-N-MOD
FR-DEM
FR-ATTR1B-ADJ
vir
ces petits
EN-DEM
EN-A
these
%SG-N (see above) SSG-AG \
</figure>
<figureCaption confidence="0.999196">
Figure 7. AGREEMENT
</figureCaption>
<page confidence="0.987687">
201
</page>
<bodyText confidence="0.9974305">
Arabic (HEAD &lt; MOD) and Japanese (MOD &lt; HEAD),
with few exceptions. The three European languages,
however, observe the default order only with &apos;heavier&apos; (i.e.
phrasal or clausal) modifiers, namely, genitives, pp-
modifiers, and relative clauses. Lexical modifiers,
including numerals, demonstratives, and adjectives (more
or less), go in the opposite ordering. The exceptionally
ordered MODs of the five languages revealed an
implicational chain among modifiers: Numerals &lt;
Demonstratives &lt; Adjectives &lt; Genitives &lt;
Relative clauses. Exceptional order was found with those
MODs starting from the left-end of this hierarchy: JA:
marked use of Numerals, AR: unmarked use of Numerals
and Demonstratives, FR: Numerals, Demonstratives, and
marked used of Adjectives, EN&amp;GE: Numerals,
Demonstratives, and Adjectives. The generalization is that
a non-default order for a modifier type x implies the non-
default order for other types located to the LEFT of z in the
given chain. What we found supports the general
implicational hierarchy that Hawkins (1984) found in his
cross-linguistic study. We can still maintain, therefore, that
there is such a thing as the default ordering with a
qualification that it may • be ovetridden by non-random
subclasses. In our current implementation, we simply
assign another category MOD2 on those &apos;exceptional&apos;
modifiers in order to free them from the general order
constraint on MOD, which we hope to improve in the
future.io
</bodyText>
<subsectionHeader confidence="0.543659">
Potential problems and solutions
</subsectionHeader>
<bodyText confidence="0.989839673076923">
There are two potential problems in an effort to
develop a shared grammar as described here. One is the
need for serious cooperation among the developers. A
small change in shared templates can always affect
language-specific templates that someone else is working
on. The other problem is the sheer complexity of the
inheritance lattice. Both problems can be most effectively
reduced by a sophisticated editing tool.
I°We envision using a data structure of type inheritance
lattice defined for each language to express word order
constraints in order to handle non-default ordering. The
basic idea is that an order constraint stated on a descendant
(e.g. DEM &lt; head) overrides that stated on its ancestors
(e.g. head &lt; MOD). This differs from GPSG&apos;s LP rules
(Gazdar &amp; Pullum 1981; Gazdar at al. 1985; Uzkoreit
1986) in that the order constraints apply to items located
anywhere in the derivational tree structrue, not limited to
sister constituents, and the pieces of an item can be
scattered in the tree. It is in spirit similar to LFG&apos;s
functional precedence constraints (Kaplan 1988;
Kameyama forthcoming).
Conclusions and future prospects
We have shown a specific implementation of grammar
sharing using graph unification by inheritance. Although
the case discussed covets only simple nominals in five
languages, we believe that the fundamental process that we
call GRAMMATICAL ATOMIZATION will remain crucial in
developing a shared grammar of any structural complexity
and linguistic coverage. The specific merits of this process
is that (a) it tends to prevent the grammar writer from
implementing treatments that work only for a language or a
language type, and that (b) it provides insights as to how
certain conflated properties in a language actually consist
of smaller independent parts. In the end, when a prototype
shared grammar attains a reasonable scale, we hope to
verify the prediction that it will facilitate adding coverage
for new languages.
The purpose of this work at MCC was to demonstrate
the feasibility of a shared syntactic rule base for dissimilar
languages. We only assumed that languages are used to
convey information contents that can be represented in a
common knowledge base. As the next step, therefore, we
have chosen to connect syntax with &apos;deeper&apos; levels of
information processing (i.e. semantics, discourse, and
knowledge base) rather than continuing to increase the
syntactic coverage alone. Our current effort is on
developing a blackboard-like system for controlling various
knowledge sources (i.e. morphology, syntax, semantics,
discourse, and a commonsense knowledge base (MCC&apos;s
CYC, Least and Feigenbaum 1987)). In the future, we
hope to see a shared grammar integrated in a full-blown
interface tool for man-machine communication.
</bodyText>
<sectionHeader confidence="0.997637" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999931833333333">
This shared grammar work is a collaborative effort of a
team at MCC. I am especially indebted to my fellow
linguists, Anthony Ann&amp; and Carol Justus, for their
insights into multilingual facts and numerous discussions.
I would also like, to thank Rich Cohen, Martha Morgan,
Elaine Rich, Jonathan Slocum, Krystyna Wachowicr, and
Kent Wittenburg for valuable comments and discussions at
various phases of the work. Thanks also go to Al Mendell
and Michael O&apos;Leary for implementing the interface tool,
and to anonymous ACL reviewers for helpful comments. I
am responsible, however, for this particular exposition of
the work and remaining shortcomings.
</bodyText>
<sectionHeader confidence="0.998821" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.991429666666667">
Ades, Anthony and Mark Steedman. 1982. On the order of
words. Lingusitics and Philosophy, 4,517-558.
Aristar, Anthony. 1988. Word-order constraints in a
multilingual categorial grammar. To appear in the
Proceedings for the 12th International Conference on
Computational Linguistics, Budapest
Bach, Emmon. 1986. The algebra of events. Linguistics
and Philosophy, 9,5-16.
Bar-Hillel, Y. 1953. A quasi-arithmetical notation for
</reference>
<page confidence="0.990623">
202
</page>
<reference confidence="0.997103313043478">
syntactic description. Language, 29(1), 47-58.
van Benthem, Johan. 1986. Categorial grammar. Essays in
Logical Semantics (Chapter 7). Dordrecht Reidel,
123-150.
Flickenger, Daniel, Carl Pollard, and Thomas Wasow.
1985. Structure-sharing in lexical representation.
The Proceedings for the 24th Annual Meeting of the
Association for Computational Linguistics.
Flynn, Michael. 1982. A categorial theory of structure
building. In G. Gazdar, G. Pullum, and E. Klein
(eds), Order, Concord, and Constituency. Dordrecht:
Foris.
Gander, Gerald and Geoffrey K. Pullum. 1981.
Subcategorization, constituent order, and the notion
&apos;head&apos;. In Moortgat, M., H. vd. Hu1st, and
T. Hoekstra (eds), The Scope of Lexical Rules.
Dordrecht, Holland: Foris, 107-123.
; Ewen Klein; Geoffrey K. Pullum; and Ivan A. Sag.
1985. Generalized Phrase Structure Grammar.
Oxford, England: Blackwell Publishing and
Cambridge, Mass.: Harvard University Press.
Greenberg, Joseph. 1966. Some universals of grammar
with particular reference to the order of meaningful
elements. In J. Greenberg (ed.), Universals of
Language (2nd edition). Cambridge, Mass.: The MIT
Press, 73-113.
Hawkins, John. 1984. Modifier-head or function-argument
relations in phrase structure? The evidence of some
word order universals. Lingua, 63, 107-138.
ICameyama, Megumi. forthcoming. Functional precedence
conditions on overt and zero pronominals.
Manuscript
Kaplan, Ronald M. 1988. Three seductions of
computational psycholinguistics. In Whitelodc,
Peter; Harold Somers, Paul Bennett, Rod Johnson,
and Mary McGee Wood (eds), Linguistic Theory and
Computer Applications. Academic Press.
Karttunen, Lauri. 1986. Radical lexicalism. Paper
presented at the Workshop on Alternative
Conceptions of Phrase Structure at the Summer
Linguistic Institute, New York. [To appear in
ICroch, Anthony et al (eds), Alternative Conceptions
of Phrase Structure.]
Keenan, Edward. 1979. On surface form and logical form.
Studies in the Linguistic Sciences (special issue),
8(2).
Krifka, Manfred. 1987. Nominal reference and temporal
constitution: towards a semantics of quantity. In
J. Groenendijk, M. Stokhof, and F. Veltman (eds),
Proceedings of the Sixth Amsterdam Colloquium,
University of Amsterdam, Institute for Language,
Logic, and Information, 153-173.
Lehmann, Winfred P. 1973. A structural principle of
language and its implications. Language, 49,47-66.
Lenat, Douglas B. and Edward A. Feigenbaum. 1987. On
the thresholds of knowledge. Paper presented at the
Workshop on Foundations of Al, MIT, June. Also in
the Proceedings for the International Joint
Conference on Artificial Intelligence, Milan.
Montague, Richard. 1974. The proper treatment of
quantification in English. In Rich Thomason (ed.),
Formal Philosophy: Selected Papers of Richard
Montague. New Haven: Yale, 247-279.
Moravcsik, Edith. 1978. Agreement In J. H. Greenberg et
al. (eds), Universals of Human Language, Vol. 3.
Stanford: Stanford University Press.
Pollard, Carl and Ivan Sag. 1987. Head-driven Phrase
Structure Grammar. The course material for the
Linguistic Institute at Stanford University.
Sdimerling, Susan. 1983. Two theories of syntactic
categories. Linguistics and Philosophy, 6,393-421.
Shieber, Stuart. 1984. The design of a computer language
for linguistic information. The Proceedings for the
10th International Conference on Computational
Linguistics, 362-366.
1986. An Introduction to Unification-based
Approaches to Grammar. CSU Lecture Notes 4.
Stanford: CSU. (available from the University of
Chicago Press)
Slocum, Jonathan. 1988. Morphological processing in the
Nabu system. In the Proceedings for the 2nd
Conference on Applied Natural Language
Processing. ACL
and Carol Justus. 1985. Transprtability to other
languages: the natural language processing project in
the Al program at MCC. ACM Transactions on
Office Information Systems, 3(2), 204-230.
Uzkoreit, Hans. 1986a. Constraints on order. Stanford, CA:
CSLI Report No. CSU-86-46.
. 1986b. Categorial unification grammars. The
Proceedings for the 11th International Conference on
Computational Linguistics, 187-194.
Theo. 1974. Topics, subjects and word order
From SXV to SVX via TVX. In J. M. Anderson and
C. Jones (eds), Historical Linguistics, I. Amsterdam:
North-Holland, 339-376.
. 1976. Categorial grammar and the order of
meaningful elements. In A. Juilland (ed.), Linguistic
studies offered to Joseph Greenberg on the occasion
of his sixtieth birthday. California: Saratoga,
615-634.
. 1981. Typology, universals and change of language.
Paper presented at the International Conference on
Historical Syntax, Porrian.
and Ray Harlow. 1977. Categorial grammar and
consistent basic VX serialization. Theoretical
linguistics, 4(3), 227-254.
Wittenburg, Kent. 1986a. Natural language processing with
combinatory categorial grammar in a graph-
unification-based formalism. Doctoral Dissertation,
University of Texas at Austin.
. 1986b. A parser for portable NL interfaces using
graph-unification-based grammars. The Proceedings
for the 5th National Conference on Artificial
Intelligence, 1053-1058.
</reference>
<page confidence="0.999196">
203
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.967719">ATOMIZATION IN GRAMMAR SHARING ABSTRACT</title>
<author confidence="0.868207">Megumi Kameyama</author>
<affiliation confidence="0.865434">Microelectronics and Computer Technology Cooperation (MCC)</affiliation>
<address confidence="0.993949">3500 West Balcones Center Drive, Austin, Texas 78759</address>
<email confidence="0.97113">megumi@mcc.com</email>
<abstract confidence="0.988509464843752">new insights with which to account for certain linguistic problems. Before we go into more detail, the following is our view of what general components and mechanisms constitute a shared grammatical system. describe a prototype GRAMMAR the syntax of simple nominal expressions in Arabic, English, French, German, and Japanese implemented at MCC. In this grammar, a complex inheritance lattice of shared grammatical templates provides parts that each language can put together to form language-specific grammatkal templates. We conclude that grammar sharing is not only possible but also desirable. It forces us to reveal crosslinguistically invariant gammatical primitives that may otherwise remain conflated with other primitives if we deal only with a single language or language type. We call this process GRAMMATICAL ATOMIZATION. specific implementation reported here uses categorial unification grammar. The topics include the mono-level nominal category N, the functional distinction between ARGUMENT and NON-ARGUMENT of norninals, grammatical agreement, and word order types. Is grammar sharing possible? The multilingual project of MCC attempts to build a grammatical system hierarchically shared by multiple (Slocum &amp; Justus 1985). SHARING proposed should have an advantage over a system with separate grammars for different languages: It should reduce the size of a multilingual rule base, and facilitate the addition of new languages. Before presenting evidence for such advantages, however, there is the basic question to be answered: Is grammar sharing at all possible? Although it is well known that languages possess similarities based on genetic, typological, or areal grounds, the question remains whether and how these similarities translate into computational techniques. In this paper, we will describe a prototype shared grammar for simple nominal expressions in Arabic, English, French, German, and Japanese.I We conclude that grammar sharing is not only possible but also desirable. It forces us to reveal cross-linguistically invariant grammatical primitives that may otherwise remain conflated with other primitives if we deal only with a single language or language type. We call this the process of forced by grammar sharing. Each language or language type is then characterized by particular combinations of such primitives, often providing investigations have also been made on Spanish, Russian, and Chinese. verb &amp;quot;to separate or be separated into free atoms&amp;quot; (The Collins English Dictionary, 2nd edition, 1986). Bask mechanisms in a shared grammar: The process of building a shared grammar, in our view, requires (i) linguistic description of a set of languages in a common framework, (ii) a mechanism for common grammatical assertion from two or more and (iii) a mechanism for assertions. The linguistic description should define certain operations (defined on string associated with information structures. Then what we do is identify sharable packages of common string-types and information structures among independently motivated language-specific grammatical assertaions. These packages are then put into the shared part of the grammar, and the remaining language-specifics are potential sources for more sharing. This extraction is essential in what we which basically &amp;quot;breaking up of grammatical assertions into smaller independent parts&amp;quot; (i.e. decomposition). If we assume that all grammatical are expressed in terms of (Shieber 1986), the atomization process would be defined the notion of reverse of follows: atomization: two feature structures, Xa for category X in language A and Xb for category X in language B, the shared Xa for category X is Of Xb (i.e., the most specific feature structure in common with both Xa and Xb). Xa is separated out of either Xa or Xb, and placed into the shared space. Consequently, a partial ordering is established Xa and Xb, respectively. There is an underlying assumption that two languagespecific definitions of a common grammatical category share something in common no matter how small it is. This means that the linguistic descriptive basis is questionable if the content of Xa above is null. Conversely, if clearly common information structures appear under languagespecific definitions of distinct grammatical categories, we may suspect a basis for a new common grammatical category. Once the shared and language-specific parts are separated out, a mechanism for merging them is necessary for successfully incorporating the shared assertion into the assertion. is such a merging mechanism that we employ in our system (see below). The shared space is a complex inheritance lattice that provides various predefined grammatical assertions that can be freely merged to create languagespecific ones. 194 Shared inheritance lattice: Let us now take a look at a grossly simplified shared inheritance lattice that results from the process described above. See Figure 1. There is a universal notion N(ominal) in all five languages under consideration. This common notion is part of the N definition of each language by inheritance. There are some nominals that are &apos;complete&apos; in the sense that they can be as subjects or objects saw cat:slaw cat.). others are &apos;incomplete&apos; in that they cannot be used as such saw &amp;quot;cat.). notions Complete and Incomplete are thereby defined for characterizing relevant nominal classes of each language (see the discussion on ARG vs. NON-ARG below). Since Determiners in English, German, and French make such incomplete nominals complete, the Determiner definition inherits (i.e. includes) the definition of Complete. Lexical items in these languages are defined by multiply inheriting relevant assertions: In what follows, we will first describe the specific linguistic and computational approaches that we employed to build our first shared grammar. We will then discuss the grammatical primitives for characterizing general nominals, adnominal modifiers, agreement, and word order types, illustrating solutions to specific cross-linguistic problems. We will end with prospects for further work. Framework Grammatical framework: We use a categorial unification grammar (CUG) (Wittenburg 1986a; Karttunen 1986; Uzkoreit 1986b). The one described here is a nondirectional categorial system (e.g. Montague 1974; Schmerling 1983; van Benthem 1986:Ch.7) with a nondirected functional application rule as the only reduction rule (i.e., a functor XIY may combine with adjacent Y in either direction to build X). Non-directionality allows for desired flexibility in the shared part of the grammar. A separate component constrains the linear order of elements in each language (see Aristar 1988 for motivation). Unification and template inheritance: CUG&apos;s lexical and unification are employed. In the each language, lexical items are defined to be the of language-specific TEMPLATES (Shieber 1984, 1986; Flickenger et al. 1985; Pollard &amp; Sag 1987). These language-specific templates, prefixed with AR(abic), EN(glish), FR(ench), GE(rman), and JA(panese), are feature structures composed by multiple inheritance from shared graminatical templates prefixed with SG (for &amp;quot;Shared Grammar&amp;quot;). SG-templates are themselves composed by multiple inheritance in a complex whose bottom-end feeds into language-specific templates. The CUG parser (MCC&apos;s Astro, Wittenburg 1986b) applies reduction rules to the structures of words in the input Arabic and Japanese strings are currently represented in Roman letters for Arabic) with spaces between &apos;words parser is linked to an independently developed morphology analyzer (Slocum 1988). This enables each word to undergo a morphological analysis including a dictionary look-up of the root morpheme, and to output a list (or alternative lists) of grammatical template names that, when their contents are unified, produce a single feature structure (or more than one if the word is ambiguous) for that particular token word. we were to process Japanese texts directly, the system would have to perform morphological and syntactic analyses simultaneously since there is no explicit word boundaries. (This is one of the strong motivations for our recent movement toward building a new CUG-based morphology system.) 195 Present linguistic coverage Simple nominals: The present linguistic coverage is syntax of nouns and nominal expressions with lexical or phrasal modifiers such as adjectives (e.g. (e.g. the), (e.g. all), numerals (e.g. (e.g. the Sun), pp-modifiers (e.g. ocean). nominals including conjunctions, derived nominals, gerunds, nominal compounds, and relative clause modification have not been handled yet. Data analysis: We first analyzed a data chart of simple nominals in each language. The chart focused on the syntactic well-formedness of nominal expressions, in particular, the order and dispensability of elements when the nominal expression acts as an argument (e.g. subject, object) to a verb or an adposition (i.e. preposition or postposition). Shared templates overview By design, the so-LATricE captures shared grammatical features in the given set of languages, whether they are due to universal, typological, genetic, or areal bases. As our research proceeded, we observed an atomization process whereby more and more grammatical properties were distinguished. This was because certain grammatical characterizations that seemed most natural for some language(s) were only partially relevant to others, which forced us to break them down into smaller parts so that other languages can use only the relevant parts. In the SG-lattice: the shared templates atomization, created sublattices corresponding to independent grammatical modules so that a grammar writer can make a language-specific combination of shared templates by consciously selecting one or more from each group. The existing subgroups are: (i) categorial grammar categories (the theory-dependent aspect of the shared grammar), (ii) common syntactic categories (theory-independent linguistic notions), (iii) grammatical agreement (to handle grammatical agreement within nominals), (iv) reference types (semantic features of the nominals, e.g. definite, indefinite, specific), (v) determiner types (to handle co-occurrence and order restrictions among determiners), and (vi) attributive modifier types (to handle order restrictions among attributive modifiers). We will focus on (i)-(iii) in this paper. Kinds of SG-templates: SG-templates as they exist fall under the following types. The most general distinction be made between comaosrrE templates. Atomic templates inherit from no other template. They result from the atomiration process, and are primitive parts that a grammar writer can put together to create more complex templates. A composite template inherits from at least one other, to which a partial structure defined for itself may be added. We may also distinguish between trriurr and sunsrAt•rrivE templates. Utility templates contribute integral parts of categorial grammar categories such as how many arguments they need to combine with— BASIC CATFJ3ORY, one for CATEGORY. templates supply grammatical categories and features expressed in terms of various linguistic notions. Specific examples are discussed below. Highlights of shared grammatical atoms The basic graph structure Each word must be associated with a complete CUG feature structure. The current implementation uses a notation for DIRECTED GRAPH. Figure 2: category either for no or to combine with one or more arguments). It is saturated when the value of ARGUMENTS is &apos;closed&apos; with symbol #. An unsaturated category may seek one or more arguments, each of which is either unspecified ([ ]) or typed (e.g. [cat: N]). Overall saturation is sought in parsing. The parser assigns index numbers to words in the input string from left to right, and coindexes corresponding substructures under ELEMENTS. The ELEMENTS component currently has A for the word for which this structure is defined, B for the first argument, and C for the second argument. These labels simply flag accessing particular elements. There can be any number of order-relevant labels corresponding to an These labels, with coindices with are in the ORDER component, which is the Word Order Constraint later). TYPE is the slot for assigning the pseudo-functional category ARG NON-ARG that we found in present cross-linguistic treatment of nominals (see below). AGR(eement) and FEATS subgraphs contain grammatical pragmatic agreement features, respectively later). [result: [cat: [1 &lt;the syntactic type of a index: [ ] &lt;relative linear position of a agr: [ I &lt;grammatical agreement features of a (optional) feats: ( I &lt;pragmatic agreement features of a type: [ &lt;the functional type of a (see below) elements: [ I &lt;elements within a order: [ ] &lt;order of elements (see below) arguments: [II &lt;arguments sought (see below) The notation a word whose resulting structure Is a 196 atomic templates [arguments: #] &lt;- [result: [elements: [a: [lex: [ 1)111 &lt;a slot for the word form &lt;the word&apos;s own features the top [result: [feats: &lt;1&gt; elements: [a: [feats: 1[ JIM Inheritance of composite templates %SG-WORD-FEATS-ARE-TOP-FEATS SSG-LEX JA-N EN-N FR-N GE-N AR-N 3. N %SG-NO-ARGUMENTS SSG-N: [result: [cat: NJ SSG-N-WITH-NO-ARGUMENTS / (relevant agreement templates) (see below) A few more remarks about the notation follow. A value can be either atomic (e.g N), a disjunction of atomic values enclosed in curly brackets (e.g. {N P}), or a complex feature structure. It can also be unspecified a D. The identity of two or more values is forced by reentrant structures indicated by coindexing (e.g. 1[ ] and &lt;1&gt;). Such coreferring value slots automatically point to a single data structure entered through any one of the slots. Universal mono-level category N Category N: We posit the universal category N for Nominals here are those that realize such as subjects and objects. Nominals are more commonly labeled NP, a phrase typically built around N or CN (common noun), as in phrase structure NP-&gt;DET N as well as in the categorial grammar characterization of DET as a functor NP/CN (i.e. combines with CN and builds NP) (e.g. Ades &amp; Steadman 1982; Wittenburg 1986a). This of nominals is motivated by facts in western languages. In English, for instance, while cat subject position, cat In contrast, while be a subject, it cannot be as he he. motivates the following category-assignments with a constraint that only can be arguments: CN, NP, CN/CN. This, however, requires that plurals and mass nouns be CN and NP at the time since gold, white cats, white gold, these gold all be arguments. The count/mass distinction is also often blurred since a singular count noun be used as a mass noun referring to the meat the cat, and a mass noun like be used as a singular count noun referring to a uNrr of gold or a KIND of gold (see e.g. Bach 1986). The boundary between NP and is at best When we turn to other languages, the basis for the view vanishes. In Japanese, for instance., be an argument on its own, and pronoun can modified as in here he&apos; and kare &apos;strange he&apos;. In short, there is no basic syntactic difference among count nouns, pronouns, and mass nouns (and no singular/plural distinction on a &apos;count&apos; noun). All of them behave hire plural and mass nouns in English. This supports a mono-level view of nominals, which we intend to capture with category N. Figure 3 shows the SGtemplates relevant to the most general characterization of N in each language. SG-templates in the following illustrations are marked as follows: atomic templates SG-x (boldface), utility templates %SG-x, and substantive templates SSG-x. At the most general level, the basic nominals in Arabic (AR-N) must be unsaturated because genitive-inflected Ns may take arguments. The basic nominals in Japanese (JA-N), English (EN-N), and French (FR-141), on the other hand, are basic categories that are saturated? In addition, all but JA-N inherit relevant AGR(eement) templates (see below). Crucially, note that what looks lie a reasonable characterization of N in each language actually consists of a particular selection from the common set of primitives. We posit a pseudo-functional level of description in terms of ARG(ument) and NON-ARG for category N instead of the category-level distinction between NP and CN. ARG may function as an argument alone, and NON-ARG cannot that English possessive marker not treated as an inflection here. 197 NON-ARG becomes ARG only by being combined with a certain modifier or by undergoing a semantic change (e.g massifying). In this view, the ARG/NON-ARG distinction is &apos;grounded on a complex interaction of morphology, semantics, and syntax. English and German, singular count nouns (e.g. NON-ARG while plurals, mass (singular) nouns, proper names, and pronouns are ARG. The NON- ARG nouns become &apos;complete&apos; ARG nominals either by being modified with determiners or by changing into mass nouns (typically changing an object reference into a reference, e.g., used apple my In French, all forms of common nouns (i.e. singular, plural, and mass) are NON-ARG, in need of determiners to ARG (e.g, vu *arbresges arbres saw trees&apos;; amour est delicat is delicate&apos;). Japanese, there are few NON-ARG nouns (e.g., &apos;person&apos; (HONORIFIC)), which can become ARG with any modifier such as a relative clause or an adjective (e.g. kata person In Arabic, the distinction of nouns between VS. to NON-ARG and ARG statuses, For instance, the unannexed form NOM-UNANNEX cats&apos; may occur as subject whereas the annexed form NOM cannot The latter must be modified with a noun-based modifier such as a genitive phrase, and this modifier must unannexed (e.g. with two cats&apos;). These facts in Japanese and Arabic show that the proposed functional distinction for nominals is motivated independently from the syntactic role of determiners since neither language has modifiers of category DET that we find in English, French, and German (more discussed later). We realize that the ARG/NON-ARG distinction itself is not a fmal solution until fine-grained syntactic-semantic interdependence is fleshed out. For now, we simply posit pseudo-functional types ARG and NON-ARG, which are changed or passed up within the nominal SSG-ARG: [result [type: ari]] $SG-NON-ARG:[result: [type: non-arg]] Category NIN: Adnominal modifiers (N-MODS) are now universally NIN (Le. a functor that combines with N and builds N). This includes both determiners and attributive modifiers. Figure 4 shows the SG-templates for the basic N-MOD. Different kinds of N-MOD must then distinguish whether it takes one or two arguments and whether the resulting nominal with modification is ARG or NON-ARG. Each distinction is briefly illustrated below. Two kinds of genitive: Genitive N-MOD functors may take different numbers of arguments crosslinguistically. An inflected genitive nominal (e.g. GE: takes one, while a genitive (e.g. EN: two. The former is captured with SG-INFLECTIONAL-GENITIVE-CASE-MOD, and the latter, with SG-PARTICLE-GENITIVE-CASE-MOD. Figure Non-universal determiner category: In the present approach, DET(erminer) is a modifier type (including articles, demonstratives, quantifiers, numerals, and possessives) such that at least one of its members is needed for making an ARG nominal out of a NON-ARG. The fact that a nominal with a determiner is always ARG translates into SG-DET inheriting from SG-ARG among others. DET is present in English, German, and French, but not in Japanese or Arabic (or Russian or Chinese). Demonstratives, quantifiers, numerals, and possessives in the latter languages do not share the syntactic function of DET. We suspect that the presence of DET is an meal property of western European languages. The sublattice in Figure 6 highlights two aspects of DEL One is the difference between DET and ADJ(ective) in English, German, and French with respect to the ARG status of the resulting nominal. DET always builds ARG cancelling whatever the type of the incoming nominal whereas ADJ passes the type of the incoming nominal to the top. The other is the place of demonstratives in relation to DET. Every language has demonstratives encoding two or three degrees of speaker proximity (e.g. JAPANESE: to the speaker), to the addressee), implementation, this latter process may be triggered by a unary rule COUNT-&gt;MASS. are assigned a NON-ARG category MN (for &apos;modified noun&apos;) separate from the ARG category N. Any modifier changes it into ARG. ANNEXED here means &apos;needing to be annexed to a nounmodifier&apos;, and &apos;completed&apos;. also respectively, in Semitic linguistics (Arista, personal communication). intriging direction is shown in Krifka&apos;s (1987) categorial grammar treatment He assigns the singular count noun in English (i.e. our NON-ARG) an unsaturated nominal category looking for its numerical value both in syntax and semantics. The significance of determiners is here as suppliers of numerical values. How this approach can be extended to cover the NON-ARG nominals in Arabic and Japanese (which are not in need of numerical values per se) remains to be seen. Although it makes sense to see NON-ARG as a functor looking for more semantic determination, implementing it would require a reduction for FUNCTORS LOOXING FOR EACH OTHER. current system would cause an infinite regression with such a zule. 198 atomic templates %SG-HEAD-FEATS-ARE-TOP-FEATS: &lt;passes the features of the second [result: [feats: &lt;1&gt; element to the top elements: [b: [feats: 1[ 111]] %SG-FIRST-ARGUMENT: &lt;slot for the first argument [result: [elements: [b: &lt;1&gt;]] arguments: [first: [result: 1[ 11111 the ORDER content of the first argument to the [result: [order: (l&lt;1&gt;]] arguments: [first: [result: [order: 1(J)]]] functor MOD (see below) [result: [cat: 4[ ] elements: (a: [index: &lt;1&gt;] b: &lt;3&gt;) order: [(mod: 1(J) [head: 2[ 11] arguments: [first: [result: 3Icat: &lt;4&gt; index: &lt;2&gt;]]] Inheritance of composite templates SSG-N (above) %SG-HEAD-FEATS-ARE-TONFEATS %SG-FIRST-ARG %SG-GET-ORD SG-MOD SSG-N-MOD&lt;for the general acinominal modifier Figure 4. General N-MOD atomic templates %SG-ARGUMENTS-REST-SATURATED: [rest: %SG-ONLY-TWO-ARGUMENTS: [rest: [first: [arguments: rest: 0]]] &lt;saturates the second argument &lt;no more than two arguments sought the genitive case feature [result: [elements: [a: [feats: [case: genitive)]])] Inheritance of composite templates SSG-N-MOD (above) SSG-CASE-MOD: &lt;for the general case-mod [result: [elements: [a: [cat: (P N) &lt;- P or N feats: [mod-type: case-mod]]]]] %SG-INFLECTIONAL(chooses Tory -CASE-MOD N) SSG-GENITIVE SSG-PARTICLE -CASE-MOD category P) -CASE %SG-INFLECTIONAL-GENITIVE -CASE / \\\ (chooses -MOD -MOD SSG-PARTICLE-GENITIVE AR-N (above) GE-N / i WIF GE: Merles AR: rajulin `man&apos;s EN: of JA: no Figure 5. Genitive Case MOD 199 from either)), but they belong to the class of determiners only if the language has DET. Grammatical agreement (AGR) Two kinds of features are distinguished, linguistic relevant to AGREEMENT French gender table table&apos; referent relevant to AGREEMENT using to refer to a female person; using appropriate numeral classifiers for counting objects in Japanese). The former is under attribute AGR, and the latter is under FEATS. The N-internal grammatical agreement (AGR) requires that certain features of the HEAD Nominal must agree with those of MOD. For instance, English has number (e.g. book *those book, this books). Among the five languages under consideration, all but Japanese have AGR. Although there is cross-linguistic variation in AGR it is not random (Moravcsllr 1978). 1 up the N-internal AGR features in the four languages. All AGR features go under attribute AGR so that its presence simply corresponds to the presence of grammatical agreement in a language. EN-N, for instance, inherits the shared template for number agreement, and FR-N inherits those for number and gender agreements. See below: $SG-NBR-AGR: [result [agr: [nbr: &lt;1&gt;] elements: [a: [feats: [nbr: 1 [J]]]]] $SG-GDR-AGR: [result [agr: [gdr: &lt;1&gt;] [a: [feats: [gdr: Separating AGR and FEATS enables us to create SGtemplates that impose the most general agreement constraint regardless of the precise content of agreement features. Three agreement templates produce the combined effect of N-internal agreement constraint, SG-AGR, SG- AGR-ARGUMENTS, and the composite of the two, SG- AGR-WITH-ARGUMENTS. See Figure 7. The reentrancies impose the strict identity of AGR features: (i) SSG-AGR--between the topmost structure and the element that the graph is defined for, (ii) $SG-AGR-ARGUMENTS—between the topmost structure and the first argument, and (iii) SSG-AGR- WITH-ARGUMENTS—among all the three. (i) goes into NOMINAIS, the nominal&apos;s AGR features to the top level This is because the AGR features must always be available at the top level of a nominal so that they can be when the nominal further modified. (ii) goes into ADNOMINAL MODIFIERS, the head nominal&apos;s features to the top level (ill) goes into ADNOMINAL MODIFIERS SUBJECT TO THE AGE CONSTRAINT, instance, demonstratives (e.g. not attributive (e.g. English, and both demonstratives and adjectives in French (see this difference in the above inheritance). This is an example where a better language-specific treatment is obtained from the grammar-sharing perspective. If only English is handled, one may simply force the identity of NBR features amidst all kinds of other features, but in the light of cross-linguistic variation and invariants, it lends itself naturally to separating out two kinds of features that correspond to different semantic interpretation processes. Category constancy and word order typology In connecting word order typology and categorial grammar, we have benefited from work of Greenberg (1966), Lehmann (1973), Vennemann (1974, 1976, 1981), Keenan (1979), Flynn (1982), and Hawkins (1984). Among these, we have a first-cut implementation of Vennemann&apos;s (1981) and Flynn&apos;s (1982) view that the types based on CONSTANCY a significant relation to the default word order of a language. functor CATEGORY-CONSTANT it builds the argument(s). It is CATEGORY-NON-CONSTANT if it builds a different category from its argument(s). These are also called Exaratc, respectively, by Bar-Hille,1 (1953), and are crucially used in Flynn&apos;s high-level word order convention statements. The definitions of the notions MOD (modifier), HEAD (head), FN (function), and ARG (argument) follow: • MOD is a category-constant functor (XIX) that combines with HEAD (X). (see above for SG- MOD) • FN is a category-non-constant functor (YIX) that combines with ARG (X). category category non-constant constant / X / XIX X Y IX X 1 1 MOD HEAD TN ARG •.g. NIN N PPIN N adj noun prep noun red roof for Max There is cross-linguistic evidence that MOD-HEAD and FN-ARG orders tend to go in opposite directions. This amounts to two basic word order types in languages: ORDER TYPE 1: ARG &lt; Pll MOD &lt; READ ORDER TYPE 2: TN &lt; ARG READ &lt; MOD (where &lt; reads as &apos;precedes&apos;) The N-level default word order in a language is determined follows: Every language has and postpositions), universally a category-non-constant functor PPIN. A postpositional language (i.e. a language that uses only or predominantly postpositions) then belongs to TYPE 1 (ARG &lt; FN), and a prepositional language belongs to TYPE 2 (FN &lt; ARG). In the present case, EN, GE, FR, and AR are prepositional while JA is postpositionaL The default MOD order is most faithfully observed in 200 of composite templates SSG-ARG (see above) %SG-ARGUMENTS-REST-SATURATED (see above) ss DET {various templates e cooccurrence for constraining the i and order inside DET) SSG-DEM(onstrative) EN-DEM FR-DEM GE-DEM JA-DEM AR-DEM 1 1 kono ha Ba: (these inherit SSG-PROX1 (proximate to speaker)) SSG-HEAD-TYPE-IS-TOP-TYPE: [result: [type: &lt;1&gt; elements: Ib: [type: 1[ 11])] EN-ATI7RB-ADJ GE-ATTRIB-ADJ FR-ATTRIB-ADJ kabiyr ookil big gross grand • Figure 6. DEM and ATTRIB-ADJ in relation to DET SSG-N-MOD (see above) DEFINITE: ANNEXED NUMBER: GENDER: CASE: ARABIC: SG DU P1.3 M F NOM ACC GEN GERMAN: SG PL M F N NOM ACC GEN DAT FRENCH: SG PL M F ENGLISH: SG PL chiens 11 mu dogs Table 1. N-internal Agreement Features atomic templates . %SG-AGR: [result: [agr: &lt;1&gt; elements: [a: [agr: 1[ 1]1)) SSG-AGR-ARGUMENTS: [result: [agr: &lt;1&gt;] arguments: [first: [result: [AGR: 1[ )111] Inheritance of composite templates small SSG-AGR-ARGUMENTS SSG -N-MOD (above) $SG-NBR-AGR (above) $SG-AGR- ITH-ARGUMENTS etc. -N-MOD FR-N-MOD FR-DEM FR-ATTR1B-ADJ ces petits EN-DEM EN-A these %SG-N (see above) SSG-AG \ Figure 7. AGREEMENT 201 Arabic (HEAD &lt; MOD) and Japanese (MOD &lt; HEAD), with few exceptions. The three European languages, however, observe the default order only with &apos;heavier&apos; (i.e. or clausal) modifiers, namely, genitives, ppmodifiers, and relative clauses. Lexical modifiers, including numerals, demonstratives, and adjectives (more or less), go in the opposite ordering. The exceptionally ordered MODs of the five languages revealed an implicational chain among modifiers: Numerals &lt; Demonstratives &lt; Adjectives &lt; Genitives &lt; Relative clauses. Exceptional order was found with those MODs starting from the left-end of this hierarchy: JA: marked use of Numerals, AR: unmarked use of Numerals and Demonstratives, FR: Numerals, Demonstratives, and marked used of Adjectives, EN&amp;GE: Numerals, Demonstratives, and Adjectives. The generalization is that a non-default order for a modifier type x implies the nonorder for other types located to the z in the given chain. What we found supports the general implicational hierarchy that Hawkins (1984) found in his cross-linguistic study. We can still maintain, therefore, that there is such a thing as the default ordering with a qualification that it may • be ovetridden by non-random subclasses. In our current implementation, we simply assign another category MOD2 on those &apos;exceptional&apos; modifiers in order to free them from the general order constraint on MOD, which we hope to improve in the Potential problems and solutions There are two potential problems in an effort to develop a shared grammar as described here. One is the need for serious cooperation among the developers. A small change in shared templates can always affect language-specific templates that someone else is working on. The other problem is the sheer complexity of the inheritance lattice. Both problems can be most effectively reduced by a sophisticated editing tool. I°We envision using a data structure of type inheritance lattice defined for each language to express word order constraints in order to handle non-default ordering. The basic idea is that an order constraint stated on a descendant (e.g. DEM &lt; head) overrides that stated on its ancestors (e.g. head &lt; MOD). This differs from GPSG&apos;s LP rules &amp; Pullum 1981; Gazdar 1985; Uzkoreit 1986) in that the order constraints apply to items located anywhere in the derivational tree structrue, not limited to sister constituents, and the pieces of an item can be scattered in the tree. It is in spirit similar to LFG&apos;s functional precedence constraints (Kaplan 1988; Kameyama forthcoming). Conclusions and future prospects We have shown a specific implementation of grammar sharing using graph unification by inheritance. Although the case discussed covets only simple nominals in five languages, we believe that the fundamental process that we ATOMIZATION remain crucial in developing a shared grammar of any structural complexity and linguistic coverage. The specific merits of this process is that (a) it tends to prevent the grammar writer from implementing treatments that work only for a language or a language type, and that (b) it provides insights as to how certain conflated properties in a language actually consist of smaller independent parts. In the end, when a prototype shared grammar attains a reasonable scale, we hope to verify the prediction that it will facilitate adding coverage for new languages. The purpose of this work at MCC was to demonstrate the feasibility of a shared syntactic rule base for dissimilar languages. We only assumed that languages are used to convey information contents that can be represented in a common knowledge base. As the next step, therefore, we have chosen to connect syntax with &apos;deeper&apos; levels of information processing (i.e. semantics, discourse, and knowledge base) rather than continuing to increase the syntactic coverage alone. Our current effort is on developing a blackboard-like system for controlling various knowledge sources (i.e. morphology, syntax, semantics, discourse, and a commonsense knowledge base (MCC&apos;s CYC, Least and Feigenbaum 1987)). In the future, we hope to see a shared grammar integrated in a full-blown interface tool for man-machine communication. Acknowledgments This shared grammar work is a collaborative effort of a team at MCC. I am especially indebted to my fellow linguists, Anthony Ann&amp; and Carol Justus, for their insights into multilingual facts and numerous discussions. I would also like, to thank Rich Cohen, Martha Morgan, Elaine Rich, Jonathan Slocum, Krystyna Wachowicr, and Kent Wittenburg for valuable comments and discussions at various phases of the work. Thanks also go to Al Mendell and Michael O&apos;Leary for implementing the interface tool, and to anonymous ACL reviewers for helpful comments. I am responsible, however, for this particular exposition of the work and remaining shortcomings.</abstract>
<note confidence="0.9822149">References Ades, Anthony and Mark Steedman. 1982. On the order of words. Lingusitics and Philosophy, 4,517-558. Aristar, Anthony. 1988. Word-order constraints in a multilingual categorial grammar. To appear in the Proceedings for the 12th International Conference on Computational Linguistics, Budapest Bach, Emmon. 1986. The algebra of events. Linguistics and Philosophy, 9,5-16. Bar-Hillel, Y. 1953. A quasi-arithmetical notation for 202 syntactic description. Language, 29(1), 47-58. van Benthem, Johan. 1986. Categorial grammar. Essays in Logical Semantics (Chapter 7). Dordrecht Reidel, 123-150. Flickenger, Daniel, Carl Pollard, and Thomas Wasow. 1985. Structure-sharing in lexical representation. The Proceedings for the 24th Annual Meeting of the Association for Computational Linguistics. Flynn, Michael. 1982. A categorial theory of structure</note>
<author confidence="0.822097">In G Gazdar</author>
<author confidence="0.822097">G Pullum</author>
<author confidence="0.822097">E Klein</author>
<note confidence="0.8671965625">(eds), Order, Concord, and Constituency. Dordrecht: Foris. Gander, Gerald and Geoffrey K. Pullum. 1981. Subcategorization, constituent order, and the notion &apos;head&apos;. In Moortgat, M., H. vd. Hu1st, and T. Hoekstra (eds), The Scope of Lexical Rules. Dordrecht, Holland: Foris, 107-123. ; Ewen Klein; Geoffrey K. Pullum; and Ivan A. Sag. 1985. Generalized Phrase Structure Grammar. Oxford, England: Blackwell Publishing and Cambridge, Mass.: Harvard University Press. Greenberg, Joseph. 1966. Some universals of grammar with particular reference to the order of meaningful elements. In J. Greenberg (ed.), Universals of Language (2nd edition). Cambridge, Mass.: The MIT Press, 73-113.</note>
<abstract confidence="0.68680975">Hawkins, John. 1984. Modifier-head or function-argument relations in phrase structure? The evidence of some word order universals. Lingua, 63, 107-138. ICameyama, Megumi. forthcoming. Functional precedence conditions on overt and zero pronominals. Manuscript Kaplan, Ronald M. 1988. Three seductions of computational psycholinguistics. In Whitelodc,</abstract>
<author confidence="0.999455">Harold Somers Peter</author>
<author confidence="0.999455">Paul Bennett</author>
<author confidence="0.999455">Rod Johnson</author>
<affiliation confidence="0.8376995">and Mary McGee Wood (eds), Linguistic Theory and Computer Applications. Academic Press.</affiliation>
<address confidence="0.711341">Karttunen, Lauri. 1986. Radical lexicalism. Paper</address>
<note confidence="0.776069027027027">presented at the Workshop on Alternative Conceptions of Phrase Structure at the Summer Linguistic Institute, New York. [To appear in ICroch, Anthony et al (eds), Alternative Conceptions of Phrase Structure.] Keenan, Edward. 1979. On surface form and logical form. Studies in the Linguistic Sciences (special issue), 8(2). Krifka, Manfred. 1987. Nominal reference and temporal constitution: towards a semantics of quantity. In J. Groenendijk, M. Stokhof, and F. Veltman (eds), Proceedings of the Sixth Amsterdam Colloquium, University of Amsterdam, Institute for Language, Logic, and Information, 153-173. Lehmann, Winfred P. 1973. A structural principle of language and its implications. Language, 49,47-66. Lenat, Douglas B. and Edward A. Feigenbaum. 1987. On the thresholds of knowledge. Paper presented at the Workshop on Foundations of Al, MIT, June. Also in the Proceedings for the International Joint Conference on Artificial Intelligence, Milan. Montague, Richard. 1974. The proper treatment of quantification in English. In Rich Thomason (ed.), Formal Philosophy: Selected Papers of Richard Montague. New Haven: Yale, 247-279. Moravcsik, Edith. 1978. Agreement In J. H. Greenberg et al. (eds), Universals of Human Language, Vol. 3. Stanford: Stanford University Press. Pollard, Carl and Ivan Sag. 1987. Head-driven Phrase Structure Grammar. The course material for the Linguistic Institute at Stanford University. Sdimerling, Susan. 1983. Two theories of syntactic categories. Linguistics and Philosophy, 6,393-421. Shieber, Stuart. 1984. The design of a computer language for linguistic information. The Proceedings for the 10th International Conference on Computational Linguistics, 362-366.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anthony Ades</author>
<author>Mark Steedman</author>
</authors>
<title>On the order of words.</title>
<date>1982</date>
<journal>Lingusitics and Philosophy,</journal>
<pages>4--517</pages>
<marker>Ades, Steedman, 1982</marker>
<rawString>Ades, Anthony and Mark Steedman. 1982. On the order of words. Lingusitics and Philosophy, 4,517-558.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Aristar</author>
</authors>
<title>Word-order constraints in a multilingual categorial grammar.</title>
<date>1988</date>
<booktitle>the Proceedings for the 12th International Conference on Computational Linguistics,</booktitle>
<location>Budapest</location>
<note>To appear in</note>
<contexts>
<context position="7302" citStr="Aristar 1988" startWordPosition="1074" endWordPosition="1075">ects for further work. Framework Grammatical framework: We use a categorial unification grammar (CUG) (Wittenburg 1986a; Karttunen 1986; Uzkoreit 1986b). The one described here is a nondirectional categorial system (e.g. Montague 1974; Schmerling 1983; van Benthem 1986:Ch.7) with a nondirected functional application rule as the only reduction rule (i.e., a functor XIY may combine with adjacent Y in either direction to build X). Non-directionality allows for desired flexibility in the shared part of the grammar. A separate component constrains the linear order of elements in each language (see Aristar 1988 for motivation). Unification and template inheritance: CUG&apos;s lexical orientation and unification are employed. In the upacoN of each language, lexical items are defined to be the unification of language-specific GRAMMATICAL TEMPLATES (Shieber 1984, 1986; Flickenger et al. 1985; Pollard &amp; Sag 1987). These language-specific templates, prefixed with AR(abic), EN(glish), FR(ench), GE(rman), and JA(panese), are feature structures composed by multiple inheritance from shared graminatical templates prefixed with SG (for &amp;quot;Shared Grammar&amp;quot;). SG-templates are themselves composed by multiple inheritance </context>
</contexts>
<marker>Aristar, 1988</marker>
<rawString>Aristar, Anthony. 1988. Word-order constraints in a multilingual categorial grammar. To appear in the Proceedings for the 12th International Conference on Computational Linguistics, Budapest</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emmon Bach</author>
</authors>
<title>The algebra of events.</title>
<date>1986</date>
<journal>Linguistics and Philosophy,</journal>
<pages>9--5</pages>
<contexts>
<context position="16382" citStr="Bach 1986" startWordPosition="2464" endWordPosition="2465"> the following category-assignments with a constraint that only NPs can be arguments: cat is CN, he is NP, a and this are NP/CN, and white and strange are CN/CN. This, however, requires that plurals and mass nouns be CN and NP at the same time since cats, gold, white cats, white gold, these cats, and this gold can all be arguments. The count/mass distinction is also often blurred since a singular count noun like cat may be used as a mass noun referring to the meat of the cat, and a mass noun like gold may be used as a singular count noun referring to a uNrr of gold or a KIND of gold (see e.g. Bach 1986). The boundary between NP and CN is at best FUZZY. When we turn to other languages, the basis for the bi-level view vanishes. In Japanese, for instance., neko &apos;cat&apos; can be an argument on its own, and pronoun here &apos;he&apos; can be modified as in ano here &apos;that he&apos; and okasina kare &apos;strange he&apos;. In short, there is no basic syntactic difference among count nouns, pronouns, and mass nouns (and no singular/plural distinction on a &apos;count&apos; noun). All of them behave hire plural and mass nouns in English. This supports a mono-level view of nominals, which we intend to capture with category N. Figure 3 shows</context>
</contexts>
<marker>Bach, 1986</marker>
<rawString>Bach, Emmon. 1986. The algebra of events. Linguistics and Philosophy, 9,5-16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Bar-Hillel</author>
</authors>
<title>A quasi-arithmetical notation for syntactic description.</title>
<date>1953</date>
<journal>Language,</journal>
<volume>29</volume>
<issue>1</issue>
<pages>47--58</pages>
<marker>Bar-Hillel, 1953</marker>
<rawString>Bar-Hillel, Y. 1953. A quasi-arithmetical notation for syntactic description. Language, 29(1), 47-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan van Benthem</author>
</authors>
<date>1986</date>
<booktitle>Categorial grammar. Essays in Logical Semantics (Chapter 7). Dordrecht Reidel,</booktitle>
<pages>123--150</pages>
<marker>van Benthem, 1986</marker>
<rawString>van Benthem, Johan. 1986. Categorial grammar. Essays in Logical Semantics (Chapter 7). Dordrecht Reidel, 123-150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Flickenger</author>
<author>Carl Pollard</author>
<author>Thomas Wasow</author>
</authors>
<title>Structure-sharing in lexical representation.</title>
<date>1985</date>
<booktitle>The Proceedings for the 24th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="7580" citStr="Flickenger et al. 1985" startWordPosition="1110" endWordPosition="1113">6:Ch.7) with a nondirected functional application rule as the only reduction rule (i.e., a functor XIY may combine with adjacent Y in either direction to build X). Non-directionality allows for desired flexibility in the shared part of the grammar. A separate component constrains the linear order of elements in each language (see Aristar 1988 for motivation). Unification and template inheritance: CUG&apos;s lexical orientation and unification are employed. In the upacoN of each language, lexical items are defined to be the unification of language-specific GRAMMATICAL TEMPLATES (Shieber 1984, 1986; Flickenger et al. 1985; Pollard &amp; Sag 1987). These language-specific templates, prefixed with AR(abic), EN(glish), FR(ench), GE(rman), and JA(panese), are feature structures composed by multiple inheritance from shared graminatical templates prefixed with SG (for &amp;quot;Shared Grammar&amp;quot;). SG-templates are themselves composed by multiple inheritance in a complex INHERruarcz LArricE, whose bottom-end feeds into language-specific templates. The CUG parser (MCC&apos;s Astro, Wittenburg 1986b) applies reduction rules to the feature structures of words in the input string.3 Arabic and Japanese strings are currently represented in Ro</context>
</contexts>
<marker>Flickenger, Pollard, Wasow, 1985</marker>
<rawString>Flickenger, Daniel, Carl Pollard, and Thomas Wasow. 1985. Structure-sharing in lexical representation. The Proceedings for the 24th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Flynn</author>
</authors>
<title>A categorial theory of structure building. In</title>
<date>1982</date>
<location>Dordrecht: Foris.</location>
<contexts>
<context position="28281" citStr="Flynn (1982)" startWordPosition="4267" endWordPosition="4268">ter language-specific treatment is obtained from the grammar-sharing perspective. If only English is handled, one may simply force the identity of NBR features amidst all kinds of other features, but in the light of cross-linguistic variation and invariants, it lends itself naturally to separating out two kinds of features that correspond to different semantic interpretation processes. Category constancy and word order typology In connecting word order typology and categorial grammar, we have benefited from work of Greenberg (1966), Lehmann (1973), Vennemann (1974, 1976, 1981), Keenan (1979), Flynn (1982), and Hawkins (1984). Among these, we have a first-cut implementation of Vennemann&apos;s (1981) and Flynn&apos;s (1982) view that the functor types based on CATEGORY CONSTANCY have a significant relation to the default word order of a language. A functor is CATEGORY-CONSTANT if it builds the same category as its argument(s). It is CATEGORY-NON-CONSTANT if it builds a different category from its argument(s). These notions are also called ENIXYTYPIC and Exaratc, respectively, by Bar-Hille,1 (1953), and are crucially used in Flynn&apos;s high-level word order convention statements. The definitions of the notio</context>
</contexts>
<marker>Flynn, 1982</marker>
<rawString>Flynn, Michael. 1982. A categorial theory of structure building. In G. Gazdar, G. Pullum, and E. Klein (eds), Order, Concord, and Constituency. Dordrecht: Foris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Gander</author>
<author>Geoffrey K Pullum</author>
</authors>
<title>Subcategorization, constituent order, and the notion &apos;head&apos;. In</title>
<date>1981</date>
<pages>107--123</pages>
<location>Dordrecht, Holland: Foris,</location>
<marker>Gander, Pullum, 1981</marker>
<rawString>Gander, Gerald and Geoffrey K. Pullum. 1981. Subcategorization, constituent order, and the notion &apos;head&apos;. In Moortgat, M., H. vd. Hu1st, and T. Hoekstra (eds), The Scope of Lexical Rules. Dordrecht, Holland: Foris, 107-123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ewen Klein</author>
<author>Geoffrey K Pullum</author>
<author>Ivan A Sag</author>
</authors>
<date>1985</date>
<booktitle>Generalized Phrase Structure Grammar.</booktitle>
<publisher>Blackwell Publishing</publisher>
<location>Oxford, England:</location>
<marker>Klein, Pullum, Sag, 1985</marker>
<rawString>; Ewen Klein; Geoffrey K. Pullum; and Ivan A. Sag. 1985. Generalized Phrase Structure Grammar. Oxford, England: Blackwell Publishing and Cambridge, Mass.: Harvard University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Greenberg</author>
</authors>
<title>Some universals of grammar with particular reference to the order of meaningful elements.</title>
<date>1966</date>
<booktitle>Universals of Language (2nd edition).</booktitle>
<pages>73--113</pages>
<editor>In J. Greenberg (ed.),</editor>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Mass.:</location>
<contexts>
<context position="28206" citStr="Greenberg (1966)" startWordPosition="4257" endWordPosition="4258"> (see this difference in the above inheritance). This is an example where a better language-specific treatment is obtained from the grammar-sharing perspective. If only English is handled, one may simply force the identity of NBR features amidst all kinds of other features, but in the light of cross-linguistic variation and invariants, it lends itself naturally to separating out two kinds of features that correspond to different semantic interpretation processes. Category constancy and word order typology In connecting word order typology and categorial grammar, we have benefited from work of Greenberg (1966), Lehmann (1973), Vennemann (1974, 1976, 1981), Keenan (1979), Flynn (1982), and Hawkins (1984). Among these, we have a first-cut implementation of Vennemann&apos;s (1981) and Flynn&apos;s (1982) view that the functor types based on CATEGORY CONSTANCY have a significant relation to the default word order of a language. A functor is CATEGORY-CONSTANT if it builds the same category as its argument(s). It is CATEGORY-NON-CONSTANT if it builds a different category from its argument(s). These notions are also called ENIXYTYPIC and Exaratc, respectively, by Bar-Hille,1 (1953), and are crucially used in Flynn&apos;</context>
</contexts>
<marker>Greenberg, 1966</marker>
<rawString>Greenberg, Joseph. 1966. Some universals of grammar with particular reference to the order of meaningful elements. In J. Greenberg (ed.), Universals of Language (2nd edition). Cambridge, Mass.: The MIT Press, 73-113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Hawkins</author>
</authors>
<title>Modifier-head or function-argument relations in phrase structure? The evidence of some word order universals.</title>
<date>1984</date>
<journal>Lingua,</journal>
<volume>63</volume>
<pages>107--138</pages>
<contexts>
<context position="28301" citStr="Hawkins (1984)" startWordPosition="4270" endWordPosition="4271">fic treatment is obtained from the grammar-sharing perspective. If only English is handled, one may simply force the identity of NBR features amidst all kinds of other features, but in the light of cross-linguistic variation and invariants, it lends itself naturally to separating out two kinds of features that correspond to different semantic interpretation processes. Category constancy and word order typology In connecting word order typology and categorial grammar, we have benefited from work of Greenberg (1966), Lehmann (1973), Vennemann (1974, 1976, 1981), Keenan (1979), Flynn (1982), and Hawkins (1984). Among these, we have a first-cut implementation of Vennemann&apos;s (1981) and Flynn&apos;s (1982) view that the functor types based on CATEGORY CONSTANCY have a significant relation to the default word order of a language. A functor is CATEGORY-CONSTANT if it builds the same category as its argument(s). It is CATEGORY-NON-CONSTANT if it builds a different category from its argument(s). These notions are also called ENIXYTYPIC and Exaratc, respectively, by Bar-Hille,1 (1953), and are crucially used in Flynn&apos;s high-level word order convention statements. The definitions of the notions MOD (modifier), H</context>
<context position="32282" citStr="Hawkins (1984)" startWordPosition="4888" endWordPosition="4889">ional chain among modifiers: Numerals &lt; Demonstratives &lt; Adjectives &lt; Genitives &lt; Relative clauses. Exceptional order was found with those MODs starting from the left-end of this hierarchy: JA: marked use of Numerals, AR: unmarked use of Numerals and Demonstratives, FR: Numerals, Demonstratives, and marked used of Adjectives, EN&amp;GE: Numerals, Demonstratives, and Adjectives. The generalization is that a non-default order for a modifier type x implies the nondefault order for other types located to the LEFT of z in the given chain. What we found supports the general implicational hierarchy that Hawkins (1984) found in his cross-linguistic study. We can still maintain, therefore, that there is such a thing as the default ordering with a qualification that it may • be ovetridden by non-random subclasses. In our current implementation, we simply assign another category MOD2 on those &apos;exceptional&apos; modifiers in order to free them from the general order constraint on MOD, which we hope to improve in the future.io Potential problems and solutions There are two potential problems in an effort to develop a shared grammar as described here. One is the need for serious cooperation among the developers. A sma</context>
</contexts>
<marker>Hawkins, 1984</marker>
<rawString>Hawkins, John. 1984. Modifier-head or function-argument relations in phrase structure? The evidence of some word order universals. Lingua, 63, 107-138.</rawString>
</citation>
<citation valid="false">
<authors>
<author>forthcoming</author>
</authors>
<title>Functional precedence conditions on overt and zero pronominals.</title>
<journal>Manuscript</journal>
<marker>forthcoming, </marker>
<rawString>ICameyama, Megumi. forthcoming. Functional precedence conditions on overt and zero pronominals. Manuscript</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
</authors>
<title>Three seductions of computational psycholinguistics. In</title>
<date>1988</date>
<publisher>Academic Press.</publisher>
<contexts>
<context position="33809" citStr="Kaplan 1988" startWordPosition="5135" endWordPosition="5136">attice defined for each language to express word order constraints in order to handle non-default ordering. The basic idea is that an order constraint stated on a descendant (e.g. DEM &lt; head) overrides that stated on its ancestors (e.g. head &lt; MOD). This differs from GPSG&apos;s LP rules (Gazdar &amp; Pullum 1981; Gazdar at al. 1985; Uzkoreit 1986) in that the order constraints apply to items located anywhere in the derivational tree structrue, not limited to sister constituents, and the pieces of an item can be scattered in the tree. It is in spirit similar to LFG&apos;s functional precedence constraints (Kaplan 1988; Kameyama forthcoming). Conclusions and future prospects We have shown a specific implementation of grammar sharing using graph unification by inheritance. Although the case discussed covets only simple nominals in five languages, we believe that the fundamental process that we call GRAMMATICAL ATOMIZATION will remain crucial in developing a shared grammar of any structural complexity and linguistic coverage. The specific merits of this process is that (a) it tends to prevent the grammar writer from implementing treatments that work only for a language or a language type, and that (b) it prov</context>
</contexts>
<marker>Kaplan, 1988</marker>
<rawString>Kaplan, Ronald M. 1988. Three seductions of computational psycholinguistics. In Whitelodc, Peter; Harold Somers, Paul Bennett, Rod Johnson, and Mary McGee Wood (eds), Linguistic Theory and Computer Applications. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
</authors>
<title>Radical lexicalism. Paper presented at the Workshop on Alternative Conceptions of Phrase Structure at the Summer Linguistic Institute,</title>
<date>1986</date>
<location>New York.</location>
<note>To appear in ICroch, Anthony et al (eds), Alternative Conceptions of Phrase Structure.</note>
<contexts>
<context position="6825" citStr="Karttunen 1986" startWordPosition="1000" endWordPosition="1001">finition of Complete. Lexical items in these languages are defined by multiply inheriting relevant assertions: In what follows, we will first describe the specific linguistic and computational approaches that we employed to build our first shared grammar. We will then discuss the grammatical primitives for characterizing general nominals, adnominal modifiers, agreement, and word order types, illustrating solutions to specific cross-linguistic problems. We will end with prospects for further work. Framework Grammatical framework: We use a categorial unification grammar (CUG) (Wittenburg 1986a; Karttunen 1986; Uzkoreit 1986b). The one described here is a nondirectional categorial system (e.g. Montague 1974; Schmerling 1983; van Benthem 1986:Ch.7) with a nondirected functional application rule as the only reduction rule (i.e., a functor XIY may combine with adjacent Y in either direction to build X). Non-directionality allows for desired flexibility in the shared part of the grammar. A separate component constrains the linear order of elements in each language (see Aristar 1988 for motivation). Unification and template inheritance: CUG&apos;s lexical orientation and unification are employed. In the upac</context>
</contexts>
<marker>Karttunen, 1986</marker>
<rawString>Karttunen, Lauri. 1986. Radical lexicalism. Paper presented at the Workshop on Alternative Conceptions of Phrase Structure at the Summer Linguistic Institute, New York. [To appear in ICroch, Anthony et al (eds), Alternative Conceptions of Phrase Structure.]</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Keenan</author>
</authors>
<title>On surface form and logical form.</title>
<date>1979</date>
<booktitle>Studies in the Linguistic Sciences (special issue),</booktitle>
<pages>8--2</pages>
<contexts>
<context position="28267" citStr="Keenan (1979)" startWordPosition="4265" endWordPosition="4266">ple where a better language-specific treatment is obtained from the grammar-sharing perspective. If only English is handled, one may simply force the identity of NBR features amidst all kinds of other features, but in the light of cross-linguistic variation and invariants, it lends itself naturally to separating out two kinds of features that correspond to different semantic interpretation processes. Category constancy and word order typology In connecting word order typology and categorial grammar, we have benefited from work of Greenberg (1966), Lehmann (1973), Vennemann (1974, 1976, 1981), Keenan (1979), Flynn (1982), and Hawkins (1984). Among these, we have a first-cut implementation of Vennemann&apos;s (1981) and Flynn&apos;s (1982) view that the functor types based on CATEGORY CONSTANCY have a significant relation to the default word order of a language. A functor is CATEGORY-CONSTANT if it builds the same category as its argument(s). It is CATEGORY-NON-CONSTANT if it builds a different category from its argument(s). These notions are also called ENIXYTYPIC and Exaratc, respectively, by Bar-Hille,1 (1953), and are crucially used in Flynn&apos;s high-level word order convention statements. The definition</context>
</contexts>
<marker>Keenan, 1979</marker>
<rawString>Keenan, Edward. 1979. On surface form and logical form. Studies in the Linguistic Sciences (special issue), 8(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Krifka</author>
</authors>
<title>Nominal reference and temporal constitution: towards a semantics of quantity. In</title>
<date>1987</date>
<booktitle>Proceedings of the Sixth</booktitle>
<pages>153--173</pages>
<institution>Amsterdam Colloquium, University of Amsterdam, Institute for Language, Logic, and Information,</institution>
<marker>Krifka, 1987</marker>
<rawString>Krifka, Manfred. 1987. Nominal reference and temporal constitution: towards a semantics of quantity. In J. Groenendijk, M. Stokhof, and F. Veltman (eds), Proceedings of the Sixth Amsterdam Colloquium, University of Amsterdam, Institute for Language, Logic, and Information, 153-173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Winfred P Lehmann</author>
</authors>
<title>A structural principle of language and its implications.</title>
<date>1973</date>
<journal>Language,</journal>
<pages>49--47</pages>
<contexts>
<context position="28222" citStr="Lehmann (1973)" startWordPosition="4259" endWordPosition="4260">nce in the above inheritance). This is an example where a better language-specific treatment is obtained from the grammar-sharing perspective. If only English is handled, one may simply force the identity of NBR features amidst all kinds of other features, but in the light of cross-linguistic variation and invariants, it lends itself naturally to separating out two kinds of features that correspond to different semantic interpretation processes. Category constancy and word order typology In connecting word order typology and categorial grammar, we have benefited from work of Greenberg (1966), Lehmann (1973), Vennemann (1974, 1976, 1981), Keenan (1979), Flynn (1982), and Hawkins (1984). Among these, we have a first-cut implementation of Vennemann&apos;s (1981) and Flynn&apos;s (1982) view that the functor types based on CATEGORY CONSTANCY have a significant relation to the default word order of a language. A functor is CATEGORY-CONSTANT if it builds the same category as its argument(s). It is CATEGORY-NON-CONSTANT if it builds a different category from its argument(s). These notions are also called ENIXYTYPIC and Exaratc, respectively, by Bar-Hille,1 (1953), and are crucially used in Flynn&apos;s high-level wor</context>
</contexts>
<marker>Lehmann, 1973</marker>
<rawString>Lehmann, Winfred P. 1973. A structural principle of language and its implications. Language, 49,47-66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas B Lenat</author>
<author>Edward A Feigenbaum</author>
</authors>
<title>On the thresholds of knowledge.</title>
<date>1987</date>
<booktitle>Paper presented at the Workshop on Foundations of Al, MIT, June. Also in the Proceedings for the International Joint Conference on Artificial Intelligence,</booktitle>
<location>Milan.</location>
<marker>Lenat, Feigenbaum, 1987</marker>
<rawString>Lenat, Douglas B. and Edward A. Feigenbaum. 1987. On the thresholds of knowledge. Paper presented at the Workshop on Foundations of Al, MIT, June. Also in the Proceedings for the International Joint Conference on Artificial Intelligence, Milan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Montague</author>
</authors>
<title>The proper treatment of quantification</title>
<date>1974</date>
<booktitle>Formal Philosophy: Selected Papers of</booktitle>
<pages>247--279</pages>
<editor>in English. In Rich Thomason (ed.),</editor>
<contexts>
<context position="6924" citStr="Montague 1974" startWordPosition="1015" endWordPosition="1016">ssertions: In what follows, we will first describe the specific linguistic and computational approaches that we employed to build our first shared grammar. We will then discuss the grammatical primitives for characterizing general nominals, adnominal modifiers, agreement, and word order types, illustrating solutions to specific cross-linguistic problems. We will end with prospects for further work. Framework Grammatical framework: We use a categorial unification grammar (CUG) (Wittenburg 1986a; Karttunen 1986; Uzkoreit 1986b). The one described here is a nondirectional categorial system (e.g. Montague 1974; Schmerling 1983; van Benthem 1986:Ch.7) with a nondirected functional application rule as the only reduction rule (i.e., a functor XIY may combine with adjacent Y in either direction to build X). Non-directionality allows for desired flexibility in the shared part of the grammar. A separate component constrains the linear order of elements in each language (see Aristar 1988 for motivation). Unification and template inheritance: CUG&apos;s lexical orientation and unification are employed. In the upacoN of each language, lexical items are defined to be the unification of language-specific GRAMMATIC</context>
</contexts>
<marker>Montague, 1974</marker>
<rawString>Montague, Richard. 1974. The proper treatment of quantification in English. In Rich Thomason (ed.), Formal Philosophy: Selected Papers of Richard Montague. New Haven: Yale, 247-279.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edith Moravcsik</author>
</authors>
<title>Agreement In</title>
<date>1978</date>
<journal>Universals of Human Language,</journal>
<volume>3</volume>
<publisher>Stanford University Press.</publisher>
<location>Stanford:</location>
<marker>Moravcsik, 1978</marker>
<rawString>Moravcsik, Edith. 1978. Agreement In J. H. Greenberg et al. (eds), Universals of Human Language, Vol. 3. Stanford: Stanford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan Sag</author>
</authors>
<title>Head-driven Phrase Structure Grammar. The course material for the Linguistic Institute at</title>
<date>1987</date>
<institution>Stanford University.</institution>
<contexts>
<context position="7601" citStr="Pollard &amp; Sag 1987" startWordPosition="1114" endWordPosition="1117">ed functional application rule as the only reduction rule (i.e., a functor XIY may combine with adjacent Y in either direction to build X). Non-directionality allows for desired flexibility in the shared part of the grammar. A separate component constrains the linear order of elements in each language (see Aristar 1988 for motivation). Unification and template inheritance: CUG&apos;s lexical orientation and unification are employed. In the upacoN of each language, lexical items are defined to be the unification of language-specific GRAMMATICAL TEMPLATES (Shieber 1984, 1986; Flickenger et al. 1985; Pollard &amp; Sag 1987). These language-specific templates, prefixed with AR(abic), EN(glish), FR(ench), GE(rman), and JA(panese), are feature structures composed by multiple inheritance from shared graminatical templates prefixed with SG (for &amp;quot;Shared Grammar&amp;quot;). SG-templates are themselves composed by multiple inheritance in a complex INHERruarcz LArricE, whose bottom-end feeds into language-specific templates. The CUG parser (MCC&apos;s Astro, Wittenburg 1986b) applies reduction rules to the feature structures of words in the input string.3 Arabic and Japanese strings are currently represented in Roman letters (augmente</context>
</contexts>
<marker>Pollard, Sag, 1987</marker>
<rawString>Pollard, Carl and Ivan Sag. 1987. Head-driven Phrase Structure Grammar. The course material for the Linguistic Institute at Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Sdimerling</author>
</authors>
<title>Two theories of syntactic categories.</title>
<date>1983</date>
<journal>Linguistics and Philosophy,</journal>
<pages>6--393</pages>
<marker>Sdimerling, 1983</marker>
<rawString>Sdimerling, Susan. 1983. Two theories of syntactic categories. Linguistics and Philosophy, 6,393-421.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
</authors>
<title>The design of a computer language for linguistic information.</title>
<date>1984</date>
<booktitle>The Proceedings for the 10th International Conference on Computational Linguistics,</booktitle>
<pages>362--366</pages>
<contexts>
<context position="7550" citStr="Shieber 1984" startWordPosition="1107" endWordPosition="1108">983; van Benthem 1986:Ch.7) with a nondirected functional application rule as the only reduction rule (i.e., a functor XIY may combine with adjacent Y in either direction to build X). Non-directionality allows for desired flexibility in the shared part of the grammar. A separate component constrains the linear order of elements in each language (see Aristar 1988 for motivation). Unification and template inheritance: CUG&apos;s lexical orientation and unification are employed. In the upacoN of each language, lexical items are defined to be the unification of language-specific GRAMMATICAL TEMPLATES (Shieber 1984, 1986; Flickenger et al. 1985; Pollard &amp; Sag 1987). These language-specific templates, prefixed with AR(abic), EN(glish), FR(ench), GE(rman), and JA(panese), are feature structures composed by multiple inheritance from shared graminatical templates prefixed with SG (for &amp;quot;Shared Grammar&amp;quot;). SG-templates are themselves composed by multiple inheritance in a complex INHERruarcz LArricE, whose bottom-end feeds into language-specific templates. The CUG parser (MCC&apos;s Astro, Wittenburg 1986b) applies reduction rules to the feature structures of words in the input string.3 Arabic and Japanese strings a</context>
</contexts>
<marker>Shieber, 1984</marker>
<rawString>Shieber, Stuart. 1984. The design of a computer language for linguistic information. The Proceedings for the 10th International Conference on Computational Linguistics, 362-366.</rawString>
</citation>
<citation valid="true">
<title>An Introduction to Unification-based Approaches to Grammar.</title>
<date>1986</date>
<booktitle>CSU Lecture Notes 4. Stanford: CSU. (available from the University of</booktitle>
<publisher>Chicago Press</publisher>
<marker>1986</marker>
<rawString>1986. An Introduction to Unification-based Approaches to Grammar. CSU Lecture Notes 4. Stanford: CSU. (available from the University of Chicago Press)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Slocum</author>
</authors>
<title>Morphological processing in the Nabu system.</title>
<date>1988</date>
<booktitle>In the Proceedings for the 2nd Conference on Applied Natural Language Processing.</booktitle>
<publisher>ACL</publisher>
<contexts>
<context position="8331" citStr="Slocum 1988" startWordPosition="1212" endWordPosition="1213">e structures composed by multiple inheritance from shared graminatical templates prefixed with SG (for &amp;quot;Shared Grammar&amp;quot;). SG-templates are themselves composed by multiple inheritance in a complex INHERruarcz LArricE, whose bottom-end feeds into language-specific templates. The CUG parser (MCC&apos;s Astro, Wittenburg 1986b) applies reduction rules to the feature structures of words in the input string.3 Arabic and Japanese strings are currently represented in Roman letters (augmented for Arabic) with spaces between &apos;words &apos;.4 3Tbe parser is linked to an independently developed morphology analyzer (Slocum 1988). This enables each word to undergo a morphological analysis including a dictionary look-up of the root morpheme, and to output a list (or alternative lists) of grammatical template names that, when their contents are unified, produce a single feature structure (or more than one if the word is ambiguous) for that particular token word. 4If we were to process Japanese texts directly, the system would have to perform morphological and syntactic analyses simultaneously since there is no explicit word boundaries. (This is one of the strong motivations for our recent movement toward building a new </context>
</contexts>
<marker>Slocum, 1988</marker>
<rawString>Slocum, Jonathan. 1988. Morphological processing in the Nabu system. In the Proceedings for the 2nd Conference on Applied Natural Language Processing. ACL</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carol Justus</author>
</authors>
<title>Transprtability to other languages: the natural language processing project in the Al program at MCC.</title>
<date>1985</date>
<journal>ACM Transactions on Office Information Systems,</journal>
<volume>3</volume>
<issue>2</issue>
<pages>204--230</pages>
<contexts>
<context position="1457" citStr="Justus 1985" startWordPosition="204" endWordPosition="205">nt gammatical primitives that may otherwise remain conflated with other primitives if we deal only with a single language or language type. We call this the process of GRAMMATICAL ATOMIZATION. The specific implementation reported here uses categorial unification grammar. The topics include the mono-level nominal category N, the functional distinction between ARGUMENT and NON-ARGUMENT of norninals, grammatical agreement, and word order types. Is grammar sharing possible? The multilingual project of MCC attempts to build a grammatical system hierarchically shared by multiple languages (Slocum &amp; Justus 1985). GRAMMAR SHARING as proposed should have an advantage over a system with separate grammars for different languages: It should reduce the size of a multilingual rule base, and facilitate the addition of new languages. Before presenting evidence for such advantages, however, there is the basic question to be answered: Is grammar sharing at all possible? Although it is well known that languages possess similarities based on genetic, typological, or areal grounds, the question remains whether and how these similarities translate into computational techniques. In this paper, we will describe a pro</context>
</contexts>
<marker>Justus, 1985</marker>
<rawString>and Carol Justus. 1985. Transprtability to other languages: the natural language processing project in the Al program at MCC. ACM Transactions on Office Information Systems, 3(2), 204-230.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Uzkoreit</author>
</authors>
<title>Constraints on order.</title>
<date>1986</date>
<tech>CSLI Report No. CSU-86-46.</tech>
<location>Stanford, CA:</location>
<contexts>
<context position="6840" citStr="Uzkoreit 1986" startWordPosition="1002" endWordPosition="1003">lete. Lexical items in these languages are defined by multiply inheriting relevant assertions: In what follows, we will first describe the specific linguistic and computational approaches that we employed to build our first shared grammar. We will then discuss the grammatical primitives for characterizing general nominals, adnominal modifiers, agreement, and word order types, illustrating solutions to specific cross-linguistic problems. We will end with prospects for further work. Framework Grammatical framework: We use a categorial unification grammar (CUG) (Wittenburg 1986a; Karttunen 1986; Uzkoreit 1986b). The one described here is a nondirectional categorial system (e.g. Montague 1974; Schmerling 1983; van Benthem 1986:Ch.7) with a nondirected functional application rule as the only reduction rule (i.e., a functor XIY may combine with adjacent Y in either direction to build X). Non-directionality allows for desired flexibility in the shared part of the grammar. A separate component constrains the linear order of elements in each language (see Aristar 1988 for motivation). Unification and template inheritance: CUG&apos;s lexical orientation and unification are employed. In the upacoN of each lang</context>
<context position="33539" citStr="Uzkoreit 1986" startWordPosition="5091" endWordPosition="5092">fect language-specific templates that someone else is working on. The other problem is the sheer complexity of the inheritance lattice. Both problems can be most effectively reduced by a sophisticated editing tool. I°We envision using a data structure of type inheritance lattice defined for each language to express word order constraints in order to handle non-default ordering. The basic idea is that an order constraint stated on a descendant (e.g. DEM &lt; head) overrides that stated on its ancestors (e.g. head &lt; MOD). This differs from GPSG&apos;s LP rules (Gazdar &amp; Pullum 1981; Gazdar at al. 1985; Uzkoreit 1986) in that the order constraints apply to items located anywhere in the derivational tree structrue, not limited to sister constituents, and the pieces of an item can be scattered in the tree. It is in spirit similar to LFG&apos;s functional precedence constraints (Kaplan 1988; Kameyama forthcoming). Conclusions and future prospects We have shown a specific implementation of grammar sharing using graph unification by inheritance. Although the case discussed covets only simple nominals in five languages, we believe that the fundamental process that we call GRAMMATICAL ATOMIZATION will remain crucial i</context>
</contexts>
<marker>Uzkoreit, 1986</marker>
<rawString>Uzkoreit, Hans. 1986a. Constraints on order. Stanford, CA: CSLI Report No. CSU-86-46.</rawString>
</citation>
<citation valid="false">
<authors>
<author>1986b</author>
</authors>
<title>Categorial unification grammars.</title>
<booktitle>The Proceedings for the 11th International Conference on Computational Linguistics,</booktitle>
<pages>187--194</pages>
<marker>1986b, </marker>
<rawString>. 1986b. Categorial unification grammars. The Proceedings for the 11th International Conference on Computational Linguistics, 187-194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theo</author>
</authors>
<title>Topics, subjects and word order From SXV to SVX via TVX. In</title>
<date>1974</date>
<booktitle>Historical Linguistics, I.</booktitle>
<pages>339--376</pages>
<publisher>North-Holland,</publisher>
<location>Amsterdam:</location>
<marker>Theo, 1974</marker>
<rawString>Theo. 1974. Topics, subjects and word order From SXV to SVX via TVX. In J. M. Anderson and C. Jones (eds), Historical Linguistics, I. Amsterdam: North-Holland, 339-376.</rawString>
</citation>
<citation valid="true">
<title>Categorial grammar and the order of meaningful elements.</title>
<date>1976</date>
<booktitle>Linguistic studies offered to Joseph Greenberg on the occasion of his sixtieth birthday.</booktitle>
<pages>615--634</pages>
<editor>In A. Juilland (ed.),</editor>
<location>California: Saratoga,</location>
<contexts>
<context position="28252" citStr="(1974, 1976, 1981)" startWordPosition="4262" endWordPosition="4264">ce). This is an example where a better language-specific treatment is obtained from the grammar-sharing perspective. If only English is handled, one may simply force the identity of NBR features amidst all kinds of other features, but in the light of cross-linguistic variation and invariants, it lends itself naturally to separating out two kinds of features that correspond to different semantic interpretation processes. Category constancy and word order typology In connecting word order typology and categorial grammar, we have benefited from work of Greenberg (1966), Lehmann (1973), Vennemann (1974, 1976, 1981), Keenan (1979), Flynn (1982), and Hawkins (1984). Among these, we have a first-cut implementation of Vennemann&apos;s (1981) and Flynn&apos;s (1982) view that the functor types based on CATEGORY CONSTANCY have a significant relation to the default word order of a language. A functor is CATEGORY-CONSTANT if it builds the same category as its argument(s). It is CATEGORY-NON-CONSTANT if it builds a different category from its argument(s). These notions are also called ENIXYTYPIC and Exaratc, respectively, by Bar-Hille,1 (1953), and are crucially used in Flynn&apos;s high-level word order convention statements.</context>
</contexts>
<marker>1976</marker>
<rawString>. 1976. Categorial grammar and the order of meaningful elements. In A. Juilland (ed.), Linguistic studies offered to Joseph Greenberg on the occasion of his sixtieth birthday. California: Saratoga, 615-634.</rawString>
</citation>
<citation valid="true">
<title>Typology, universals and change of language.</title>
<date>1981</date>
<booktitle>Paper presented at the International Conference on Historical Syntax, Porrian.</booktitle>
<contexts>
<context position="28252" citStr="(1974, 1976, 1981)" startWordPosition="4262" endWordPosition="4264">ce). This is an example where a better language-specific treatment is obtained from the grammar-sharing perspective. If only English is handled, one may simply force the identity of NBR features amidst all kinds of other features, but in the light of cross-linguistic variation and invariants, it lends itself naturally to separating out two kinds of features that correspond to different semantic interpretation processes. Category constancy and word order typology In connecting word order typology and categorial grammar, we have benefited from work of Greenberg (1966), Lehmann (1973), Vennemann (1974, 1976, 1981), Keenan (1979), Flynn (1982), and Hawkins (1984). Among these, we have a first-cut implementation of Vennemann&apos;s (1981) and Flynn&apos;s (1982) view that the functor types based on CATEGORY CONSTANCY have a significant relation to the default word order of a language. A functor is CATEGORY-CONSTANT if it builds the same category as its argument(s). It is CATEGORY-NON-CONSTANT if it builds a different category from its argument(s). These notions are also called ENIXYTYPIC and Exaratc, respectively, by Bar-Hille,1 (1953), and are crucially used in Flynn&apos;s high-level word order convention statements.</context>
</contexts>
<marker>1981</marker>
<rawString>. 1981. Typology, universals and change of language. Paper presented at the International Conference on Historical Syntax, Porrian.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Harlow</author>
</authors>
<title>Categorial grammar and consistent basic VX serialization.</title>
<date>1977</date>
<journal>Theoretical linguistics,</journal>
<volume>4</volume>
<issue>3</issue>
<pages>227--254</pages>
<marker>Harlow, 1977</marker>
<rawString>and Ray Harlow. 1977. Categorial grammar and consistent basic VX serialization. Theoretical linguistics, 4(3), 227-254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kent Wittenburg</author>
</authors>
<title>Natural language processing with combinatory categorial grammar in a graphunification-based formalism. Doctoral Dissertation,</title>
<date>1986</date>
<institution>University of Texas at Austin.</institution>
<contexts>
<context position="6808" citStr="Wittenburg 1986" startWordPosition="998" endWordPosition="999">. includes) the definition of Complete. Lexical items in these languages are defined by multiply inheriting relevant assertions: In what follows, we will first describe the specific linguistic and computational approaches that we employed to build our first shared grammar. We will then discuss the grammatical primitives for characterizing general nominals, adnominal modifiers, agreement, and word order types, illustrating solutions to specific cross-linguistic problems. We will end with prospects for further work. Framework Grammatical framework: We use a categorial unification grammar (CUG) (Wittenburg 1986a; Karttunen 1986; Uzkoreit 1986b). The one described here is a nondirectional categorial system (e.g. Montague 1974; Schmerling 1983; van Benthem 1986:Ch.7) with a nondirected functional application rule as the only reduction rule (i.e., a functor XIY may combine with adjacent Y in either direction to build X). Non-directionality allows for desired flexibility in the shared part of the grammar. A separate component constrains the linear order of elements in each language (see Aristar 1988 for motivation). Unification and template inheritance: CUG&apos;s lexical orientation and unification are empl</context>
<context position="8037" citStr="Wittenburg 1986" startWordPosition="1169" endWordPosition="1170">pacoN of each language, lexical items are defined to be the unification of language-specific GRAMMATICAL TEMPLATES (Shieber 1984, 1986; Flickenger et al. 1985; Pollard &amp; Sag 1987). These language-specific templates, prefixed with AR(abic), EN(glish), FR(ench), GE(rman), and JA(panese), are feature structures composed by multiple inheritance from shared graminatical templates prefixed with SG (for &amp;quot;Shared Grammar&amp;quot;). SG-templates are themselves composed by multiple inheritance in a complex INHERruarcz LArricE, whose bottom-end feeds into language-specific templates. The CUG parser (MCC&apos;s Astro, Wittenburg 1986b) applies reduction rules to the feature structures of words in the input string.3 Arabic and Japanese strings are currently represented in Roman letters (augmented for Arabic) with spaces between &apos;words &apos;.4 3Tbe parser is linked to an independently developed morphology analyzer (Slocum 1988). This enables each word to undergo a morphological analysis including a dictionary look-up of the root morpheme, and to output a list (or alternative lists) of grammatical template names that, when their contents are unified, produce a single feature structure (or more than one if the word is ambiguous) </context>
<context position="15478" citStr="Wittenburg 1986" startWordPosition="2293" endWordPosition="2294">ndicated by coindexing (e.g. 1[ ] and &lt;1&gt;). Such coreferring value slots automatically point to a single data structure entered through any one of the slots. Universal mono-level category N Category N: We posit the universal category N for nominals. Nominals here are those that realize ARGUMENTS such as subjects and objects. Nominals are more commonly labeled NP, a phrase typically built around N or CN (common noun), as in phrase structure NP-&gt;DET N as well as in the categorial grammar characterization of DET as a functor NP/CN (i.e. combines with CN and builds NP) (e.g. Ades &amp; Steadman 1982; Wittenburg 1986a). This BI-LEVEL view of nominals is motivated by facts in western European languages. In English, for instance, while cat or white cat cannot fin a subject position, a cat and this cat can. In contrast, while he can be a subject, it cannot be modified as this he or strange he. This motivates the following category-assignments with a constraint that only NPs can be arguments: cat is CN, he is NP, a and this are NP/CN, and white and strange are CN/CN. This, however, requires that plurals and mass nouns be CN and NP at the same time since cats, gold, white cats, white gold, these cats, and this</context>
</contexts>
<marker>Wittenburg, 1986</marker>
<rawString>Wittenburg, Kent. 1986a. Natural language processing with combinatory categorial grammar in a graphunification-based formalism. Doctoral Dissertation, University of Texas at Austin.</rawString>
</citation>
<citation valid="false">
<authors>
<author>1986b</author>
</authors>
<title>A parser for portable NL interfaces using graph-unification-based grammars.</title>
<booktitle>The Proceedings for the 5th National Conference on Artificial Intelligence,</booktitle>
<pages>1053--1058</pages>
<marker>1986b, </marker>
<rawString>. 1986b. A parser for portable NL interfaces using graph-unification-based grammars. The Proceedings for the 5th National Conference on Artificial Intelligence, 1053-1058.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>