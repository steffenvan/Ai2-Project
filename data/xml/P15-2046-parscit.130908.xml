<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.020170">
<title confidence="0.998366">
A Lexicalized Tree Kernel for Open Information Extraction
</title>
<author confidence="0.9953775">
Ying Xu†, Christoph Ringlstetter‡, Mi-Young Kim†, Randy Goebel†,
Grzegorz Kondrak†, Yusuke Miyao§
</author>
<affiliation confidence="0.986077666666667">
†Department of Computing Science, University of Alberta
‡Gini, Muenchen
§National Institute of Informatics / JST, PRESTO
</affiliation>
<email confidence="0.967186">
†{yx2,miyoung2,rgoebel,gkondrak}@ualberta.ca
‡c.ringlstetter@gini.net
§yusuke@nii.ac.jp
</email>
<sectionHeader confidence="0.997329" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9843557">
In contrast with traditional relation ex-
traction, which only considers a fixed set
of relations, Open Information Extraction
(Open IE) aims at extracting all types
of relations from text. Because of data
sparseness, Open IE systems typically ig-
nore lexical information, and instead em-
ploy parse trees and Part-of-Speech (POS)
tags. However, the same syntactic struc-
ture may correspond to different relations.
In this paper, we propose to use a lexical-
ized tree kernel based on the word embed-
dings created by a neural network model.
We show that the lexicalized tree kernel
model surpasses the unlexicalized model.
Experiments on three datasets indicate that
our Open IE system performs better on the
task of relation extraction than the state-
of-the-art Open IE systems of Xu et al.
(2013) and Mesquita et al. (2013).
</bodyText>
<sectionHeader confidence="0.999411" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999859119047619">
Relation Extraction (RE) is the task of recognizing
relationships between entities mentioned in text.
In contrast with traditional relation extraction, for
which a target set of relations is fixed a priori,
Open Information Extraction (Open IE) is a gen-
eralization of RE that attempts to extract all re-
lations (Banko et al., 2007). Although Open IE
models that extract N-ary relations have been pro-
posed, here we concentrate on binary relations.
Most Open IE systems employ syntactic infor-
mation such as parse trees and part of speech
(POS) tags, but ignore lexical information. How-
ever, previous work suggests that Open IE would
benefit from lexical information because the same
syntactic structure may correspond to different re-
lations. For instance, the relation &lt;Annacone,
coach of, Federer&gt; is correct for the sentence
“Federer hired Annacone as a coach”, but not for
the sentence “Federer considered Annacone as a
coach,” even though they have the same depen-
dency path structure (Mausam et al., 2012). Lex-
ical information is required to distinguish the two
cases.
Here we propose a lexicalized tree kernel model
that combines both syntactic and lexical informa-
tion. In order to avoid lexical sparsity issues, we
investigate two smoothing methods that use word
vector representations: Brown clustering (Brown
et al., 1992) and word embeddings created by
a neural network model (Collobert and Weston,
2008). To our knowledge, we are the first to ap-
ply word embeddings and to use lexicalized tree
kernel models for Open IE.
Experiments on three datasets demonstrate that
our Open IE system achieves absolute improve-
ments in F-measure of up to 16% over the cur-
rent state-of-the-art systems of Xu et al. (2013)
and Mesquita et al. (2013). In addition, we ex-
amine alternative approaches for including lexical
information, and find that excluding named enti-
ties from the lexical information results in an im-
proved F-score.
</bodyText>
<sectionHeader confidence="0.930271" genericHeader="method">
2 System Architecture
</sectionHeader>
<bodyText confidence="0.999572636363636">
The goal of the Open IE task is to extract from
text a set of triples {&lt; E1, R, E2 &gt;}, where E1
and E2 are two named entities, and R is a textual
fragment that indicates the semantic relation be-
tween the two entities. We concentrate on binary,
single-word relations between named entities. The
candidate relation words are extracted from depen-
dency structures, and then filtered by a supervised
tree kernel model.
Our system consists of three modules: entity
extraction, relation candidate extraction, and tree
</bodyText>
<page confidence="0.887338">
279
</page>
<note confidence="0.372043">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 279–284,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<figureCaption confidence="0.997891">
Figure 1: Our Open IE system structure.
</figureCaption>
<bodyText confidence="0.997930266666667">
kernel filtering. The system structure is outlined
in Figure 1. We identify named entities, parse sen-
tences, and convert constituency trees into depen-
dency structures using the Stanford tools (Man-
ning et al., 2014). Entities within a fixed token dis-
tance (set to 20 according to development results)
are extracted as pairs I&lt; E1, E2 &gt;1. We then
identify relation candidates R for each entity pair
in a sentence, using dependency paths. Finally,
the candidate triples I&lt; E1, R, E2 &gt;I are paired
with their corresponding tree structures, and pro-
vided as input to the SVM tree kernel. Our Open
IE system outputs the triples that are classified as
positive. In the following sections, we describe the
components of the system in more detail.
</bodyText>
<sectionHeader confidence="0.996962" genericHeader="method">
3 Relation Candidates
</sectionHeader>
<bodyText confidence="0.99965148">
Relation candidates are words that may repre-
sent a relation between two entities. We consider
only lemmatized nouns, verbs and adjectives that
are within two dependency links from either of
the entities. Following Wu and Weld (2010) and
Mausam et al. (2012), we use dependency pat-
terns rather than POS patterns, which allows us to
identify relation candidates which are farther away
from entities in terms of token distance.
We extract the first two content words along the
dependency path between E1 and E2. In the fol-
lowing example, the path is E1 —* encounter —*
build —* E2, and the two relation word candidates
between “Mr. Wathen” and “Plant Security Ser-
vice” are encounter and build, of which the latter
is the correct one.
If there are no content words on the dependency
path between the two entities, we instead consider
words that are directly linked to either of them.
In the following example, the only relation candi-
date is the word battle, which is directly linked to
“Edelman.”
The relation candidates are manually annotated
as correct/incorrect in the training data for the tree
kernel models described in the following section.
</bodyText>
<sectionHeader confidence="0.993525" genericHeader="method">
4 Lexicalized Tree Kernel
</sectionHeader>
<bodyText confidence="0.9999965">
We use a supervised lexicalized tree kernel to filter
negative relation candidates from the results of the
candidate extraction module. For semantic tasks,
the design of input structures to tree kernels is as
important as the design of the tree kernels them-
selves. In this section, we introduce our tree struc-
ture, describe the prior basic tree kernel, and fi-
nally present our lexicalized tree kernel function.
</bodyText>
<subsectionHeader confidence="0.9993">
4.1 Tree Structure
</subsectionHeader>
<bodyText confidence="0.99948215">
In order to formulate the input for tree kernel
models, we need to convert the dependency path
to a tree-like structure with unlabelled edges.
The target dependency path is the shortest path
that includes the triple and other content words
along the path. Consider the following example,
which is a simplified representation of the sen-
tence “Georgia-Pacific Corp.’s unsolicited $3.9
billion bid for Great Northern Nekoosa Corp. was
hailed by Wall Street.” The candidate triple iden-
tified by the relation candidate extraction module
is &lt;Georgia-Pacific Corp., bid, Great Northern
Nekoosa Corp.&gt;.
Our unlexicalized tree representation model is
similar to the unlexicalized representations of Xu
et al. (2013), except that instead of using the POS
tag of the path’s head word as the root, we cre-
ate an abstract Root node. We preserve the depen-
dency labels, POS tags, and entity information as
tree nodes: (a) the top dependency labels are in-
</bodyText>
<page confidence="0.96967">
280
</page>
<figure confidence="0.990569">
(a) An un-lexicalized dependency tree. (b) A lexicalized dependency tree.
</figure>
<figureCaption confidence="0.998403">
Figure 2: An unlexicalized tree and the corresponding lexicalized tree.
</figureCaption>
<bodyText confidence="0.9998838125">
cluded as children of the abstract Root node, other
labels are attached to the corresponding parent la-
bels; (b) the POS tag of the head word of the de-
pendence path is a child of the Root; (c) other POS
tags are attached as children of the dependency la-
bels; and (d) the relation tag ‘R’ and the entity tags
‘NE’ are the terminal nodes attached to their re-
spective POS tags. Figure 2(a) shows the unlexi-
calized dependency tree for our example sentence.
Our lexicalized tree representation is derived
from the unlexicalized representation by attaching
words as terminal nodes. In order to reduce the
number of nodes, we collapse the relation and en-
tity tags with their corresponding POS tags. Fig-
ure 2(b) shows the resulting tree for the example
sentence.
</bodyText>
<subsectionHeader confidence="0.992581">
4.2 Tree Kernels
</subsectionHeader>
<bodyText confidence="0.999974090909091">
Tree kernel models extract features from parse
trees by comparing pairs of tree structures. The
essential distinction between different tree kernel
functions is the ∆ function that calculates simi-
larity of subtrees. Our modified kernel is based on
the SubSet Tree (SST) Kernel proposed by Collins
and Duffy (2002). What follows is a simplified de-
scription of the kernel; a more detailed description
can be found in the original paper.
The general function for a tree kernel model
over trees T1 and T2 is:
</bodyText>
<equation confidence="0.963219333333333">
∑
K(T1,T2) =
n1ET1
</equation>
<bodyText confidence="0.9995795">
where n1 and n2 are tree nodes. The ∆ function
of SST kernel is defined recursively:
</bodyText>
<listItem confidence="0.9971352">
1. ∆(n1, n2) = 0 if the productions (context-
free rules) of n1 and n2 are different.
2. Otherwise, ∆(n1, n2) = 1 if n1 and n2 are
matching pre-terminals (POS tags).
3. Otherwise,
</listItem>
<equation confidence="0.775287">
∆(n1, n2) = ∏j(1 + ∆(c(n1,j), c(n2,j)),
</equation>
<bodyText confidence="0.994337">
where c(n, j) is the jth child of n.
</bodyText>
<subsectionHeader confidence="0.99795">
4.3 Lexicalized Tree Kernel
</subsectionHeader>
<bodyText confidence="0.9999565">
Since simply adding words to lexicalize a tree ker-
nel leads to sparsity problems, a type of smoothing
must be applied. Bloehdorn and Moschitti (2007)
measure the similarity of words using WordNet.
Croce et al. (2011) employ word vectors created
by Singular Value Decomposition (Golub and Ka-
han., 1965) from a word co-occurrence matrix.
Plank and Moschitti (2013) use word vectors cre-
ated by Brown clustering algorithm (Brown et al.,
1992), which is another smoothed word represen-
tation that represents words as binary vectors. Sri-
vastava et al. (2013) use word embeddings of Col-
lobert and Weston (2008), but their tree kernel
does not incorporate POS tags or dependency la-
bels.
We propose using word embeddings created
by a neural network model (Collobert and We-
ston, 2008), in which words are represented by
n-dimensional real valued vectors. Each dimen-
sion represents a latent feature of the word that re-
flects its semantic and syntactic properties. Next,
we describe how we embed these vectors into tree
kernels.
Our lexicalized tree kernel model is the same as
SST, except in the following case: if n1 and n2 are
matching pre-terminals (POS tags), then
</bodyText>
<equation confidence="0.991742">
∆(n1, n2) = 1 + G(c(n1), c(n2)), (2)
</equation>
<bodyText confidence="0.999124230769231">
where c(n) denotes the word w that is the unique
child of n, and G(w1, w2) = exp(−ry∥w1 −w2∥2)
is a Gaussian function for two word vectors, which
is a valid kernel.
We examine the contribution of different types
of words by comparing three methods of including
lexical information: (1) relation words only; (2) all
words (relation words, named entities, and other
words along the dependency path fragment); and
(3) all words, except named entities. The words
that are excluded are assumed to be different; for
example, in the third method, G(E1, E2) is always
zero, even if the entities, E1 and E2, are the same.
</bodyText>
<equation confidence="0.9872815">
∑ ∆(n1, n2), (1)
n2ET2
</equation>
<page confidence="0.995289">
281
</page>
<sectionHeader confidence="0.999574" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.9997191875">
Here we evaluate alternative tree kernel configura-
tions, and compare our Open IE system to previ-
ous work.
We perform experiments on three datasets (Ta-
ble 1): the Penn Treebank set (Xu et al., 2013),
the New York Times set (Mesquita et al., 2013),
and the ClueWeb set which we created for this
project from a large collection of web pages.1 The
models are trained on the Penn Treebank training
set and tested on the three test sets, of which the
Penn Treebank set is in-domain, and the other two
sets are out-of-domain. For word embedding and
Brown clustering representations, we use the data
provided by Turian et al. (2010). The SVM param-
eters, as well as the Brown cluster size and code
length, are tuned on the development set.
</bodyText>
<table confidence="0.9957835">
Set train dev test
Penn Treebank 750 100 100
New York Times — 300 500
ClueWeb — 450 250
</table>
<tableCaption confidence="0.8308775">
Table 1: Data sets and their size (number of sen-
tences).
</tableCaption>
<bodyText confidence="0.993622666666667">
Table 2 shows the effect of different smooth-
ing and lexicalization techniques on the tree ker-
nels. In order to focus on tree kernel functions,
we use the relation candidate extraction (Section
3) and tree structure (Section 4.1) proposed in
this paper. The results in the first two rows indi-
cate that adding unsmoothed lexical information
to the method of Xu et al. (2013) is not help-
ful, which we attribute to data sparsity. On the
other hand, smoothed word representations do im-
prove F-measure. Surprisingly, a neural network
approach of creating word embeddings actually
achieves a lower recall than the method of Plank
and Moschitti (2013) that uses Brown clustering;
the difference in F-measure is not statistically sig-
nificant according to compute-intensive random-
ization test (Pad´o, 2006).
With regards to lexicalization, the inclusion of
relation words is important. However, unlike
Plank and Moschitti (2013), we found that it is
better to exclude the lexical information of entities
themselves, which confirms the findings of Riedel
et al. (2013). We hypothesize that the correctness
of a relation triple in Open IE is not closely re-
</bodyText>
<footnote confidence="0.9550455">
1The Treebank set of (Xu et al., 2013), with minor correc-
tions, and the ClueWeb set are appended to this publication.
</footnote>
<table confidence="0.999084555555556">
Smoothing Lexical info P R Fl
none (Xu13) none 85.7 72.7 78.7
none all words 89.8 66.7 76.5
Brown (PM13) relation only 88.7 71.2 79.0
Brown (PM13) all words 84.5 74.2 79.0
Brown (PM13) excl. entities 86.2 75.8 80.7
embedding relation only 93.9 69.7 80.0
embedding all words 93.8 68.2 79.0
embedding excl. entities 95.9 71.2 81.7
</table>
<tableCaption confidence="0.985924">
Table 2: The results of relation extraction with al-
</tableCaption>
<bodyText confidence="0.997623926829268">
ternative smoothing and lexicalization techniques
on the Penn Treebank set (with our relation candi-
date extraction and tree structure).
lated to entities. Consider the example mentioned
in (Riedel et al., 2013): for relations like “X vis-
its Y”, X could be a person or organization, and Y
could be a location, organization, or person.
Our final set of experiments evaluates the best-
performing version of our system (the last row
in Table 2) against two state-of-the-art Open IE
systems: Mesquita et al. (2013), which is based
on several hand-crafted dependency patterns; and
Xu et al. (2013), which uses POS-based relation
candidate extraction and an unlexicalized tree ker-
nel. Tree kernel systems are all trained on the
Penn Treebank training set, and tuned on the cor-
responding development sets.
The results in Table 3 show that our system con-
sistently outperforms the other two systems, with
absolute gains in F-score between 4 and 16%. We
include the reported results of (Xu et al., 2013)
on the Penn Treebank set, and of (Mesquita et al.,
2013) on the New York Times set. The ClueWeb
results were obtained by running the respective
systems on the test set, except that we used our
relation candidate extraction method for the tree
kernel of (Xu et al., 2013). We conclude that the
substantial improvement on the Penn Treebank set
can be partly attributed to a superior tree kernel,
and not only to a better relation candidate extrac-
tion method. We also note that word embeddings
statistically outperform Brown clustering on the
ClueWeb set, but not on the other two sets.
The ClueWeb set is quite challenging because
it contains web pages which can be quite noisy.
As a result we’ve found that a number of Open IE
errors are caused by parsing. Conjunction struc-
tures are especially difficult for both parsing and
relation extraction. For example, our system ex-
tracts the relation triple &lt;Scotland, base, Scott&gt;
from the sentence “Set in 17th century Scotland
</bodyText>
<page confidence="0.990967">
282
</page>
<table confidence="0.999893642857143">
P R F1
Penn Treebank set
Xu et al. (2013)* 66.1 50.7 57.4
Brown (PM13) 82.8 65.8 73.3
Ours (embedding) 91.8 61.6 73.8
New York Times set
Mesquita et al. (2013)* 72.8 39.3 51.1
Brown (PM13) 83.5 44.0 57.6
Ours (embedding) 85.9 40.7 55.2
ClueWeb set
Xu et al. (2013) 54.3 35.8 43.2
Mesquita et al. (2013) 63.3 29.2 40.0
Brown (PM13) 54.1 31.1 39.5
Ours (embedding) 45.8 51.9 48.7
</table>
<tableCaption confidence="0.709926">
Table 3: Comparison of complete Open IE sys-
tems. The asterisks denote results reported in pre-
vious work.
</tableCaption>
<bodyText confidence="0.974795875">
and based on a novel by Sir Walter Scott, its high
drama...” with the wrong dependency path Scot-
land c°nand
� based prep by
� Scott. In the future, we
will investigate whether adding information from
context words that are not on the dependency path
between two entities may alleviate this problem.
</bodyText>
<sectionHeader confidence="0.996171" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999849375">
We have proposed a lexicalized tree kernel model
for Open IE, which incorporates word embeddings
learned from a neural network model. Our sys-
tem combines a dependency-based relation candi-
date extraction method with a lexicalized tree ker-
nel, and achieves state-of-the-art results on three
datasets. Our experiments on different configu-
rations of the smoothing and lexicalization tech-
niques show that excluding named entity informa-
tion is a better strategy for Open IE.
In the future, we plan to mitigate the perfor-
mance drop on the ClueWeb set by adding in-
formation about context words around relation
words. We will also investigate other ways of col-
lapsing different types of tags in the lexicalized
tree representation.
</bodyText>
<sectionHeader confidence="0.998812" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997577">
We would like to thank the anonymous review-
ers for their helpful suggestions. This work was
funded in part by Alberta Innovates Center for
Machine Learning (AICML), Natural Sciences
and Engineering Research Council of Canada
(NSERC), Alberta Innovates Technology Futures
(AITF), and National Institute of Informatics (NII)
International Internship Program.
</bodyText>
<sectionHeader confidence="0.995942" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999646814814815">
Michele Banko, Michael J Cafarella, Stephen Soderl,
Matt Broadhead, and Oren Etzioni. 2007. Open in-
formation extraction from the web. In International
Joint Conference on Artificial Intelligence, pages
2670–2676.
Stephan Bloehdorn and Alessandro Moschitti. 2007.
Structure and semantics for expressive text kernels.
In Proceedings of the Sixteenth ACM Conference
on Conference on Information and Knowledge Man-
agement, CIKM ’07, pages 861–864, New York,
NY, USA. ACM.
Peter F. Brown, Peter V. deSouza, Robert L. Mer-
cer, Vincent J. Della Pietra, and Jenifer C. Lai.
1992. Class-based n-gram models of natural lan-
guage. Comput. Linguist., 18(4):467–479, Decem-
ber.
Michael Collins and Nigel Duffy. 2002. New rank-
ing algorithms for parsing and tagging: kernels over
discrete structures, and the voted perceptron. In Pro-
ceedings of the 40th Annual Meeting on Association
for Computational Linguistics, ACL ’02, pages 263–
270, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Ronan Collobert and Jason Weston. 2008. A unified
architecture for natural language processing: Deep
neural networks with multitask learning. In Interna-
tional Conference on Machine Learning, ICML.
Danilo Croce, Alessandro Moschitti, and Roberto
Basili. 2011. Structured lexical similarity via con-
volution kernels on dependency trees. In Proceed-
ings of the Conference on Empirical Methods in
Natural Language Processing, EMNLP ’11, pages
1034–1046, Stroudsburg, PA, USA. Association for
Computational Linguistics.
G. Golub and W. Kahan. 1965. Calculating the singu-
lar values and pseudo-inverse of a matrix. Journal of
the Society for Industrial and Applied Mathematics:
Series B, Numerical Analysis, page 205224.
Christopher D. Manning, Mihai Surdeanu, John Bauer,
Jenny Finkel, Steven J. Bethard, and David Mc-
Closky. 2014. The Stanford CoreNLP natural lan-
guage processing toolkit. In Proceedings of 52nd
Annual Meeting of the Association for Computa-
tional Linguistics: System Demonstrations, pages
55–60.
Mausam, Michael Schmitz, Robert Bart, Stephen
Soderland, and Oren Etzioni. 2012. Open language
learning for information extraction. In Proceedings
of the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, pages 523–534. Asso-
ciation for Computational Linguistics.
Filipe Mesquita, Jordan Schmidek, and Denilson Bar-
bosa. 2013. Effectiveness and efficiency of open
</reference>
<page confidence="0.98144">
283
</page>
<reference confidence="0.999718270833333">
relation extraction. In Proceedings of the 2013 Con-
ference on Empirical Methods in Natural Language
Processing, pages 447–457. Association for Com-
putational Linguistics.
Sebastian Pad´o, 2006. User’s guide to sigf: Signifi-
cance testing by approximate randomisation.
Barbara Plank and Alessandro Moschitti. 2013. Em-
bedding semantic similarity in tree kernels for do-
main adaptation of relation extraction. In Proceed-
ings of the 51st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 1498–1507, Sofia, Bulgaria, August.
Association for Computational Linguistics.
Sebastian Riedel, Limin Yao, Benjamin M. Marlin, and
Andrew McCallum. 2013. Relation extraction with
matrix factorization and universal schemas. In Joint
Human Language Technology Conference/Annual
Meeting of the North American Chapter of the Asso-
ciation for Computational Linguistics (HLT-NAACL
’13), June.
Shashank Srivastava, Dirk Hovy, and Eduard Hovy.
2013. A walk-based semantically enriched tree ker-
nel over distributed word representations. In Pro-
ceedings of the 2013 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1411–
1416, Seattle, Washington, USA, October. Associa-
tion for Computational Linguistics.
Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning. In Proceedings of the
48th Annual Meeting of the Association for Com-
putational Linguistics, ACL ’10, pages 384–394,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Fei Wu and Daniel S. Weld. 2010. Open information
extraction using wikipedia. In Proceedings of the
48th Annual Meeting of the Association for Com-
putational Linguistics, ACL ’10, pages 118–127,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Ying Xu, Mi-Young Kim, Kevin Quinn, Randy Goebel,
and Denilson Barbosa. 2013. Open information
extraction with tree kernels. In Proceedings of the
2013 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 868–877, At-
lanta, Georgia, June. Association for Computational
Linguistics.
</reference>
<page confidence="0.998376">
284
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.380414">
<title confidence="0.999956">A Lexicalized Tree Kernel for Open Information Extraction</title>
<author confidence="0.960875">Christoph Mi-Young Randy Yusuke</author>
<affiliation confidence="0.9921895">of Computing Science, University of Institute of Informatics / JST,</affiliation>
<abstract confidence="0.99974605">In contrast with traditional relation extraction, which only considers a fixed set of relations, Open Information Extraction (Open IE) aims at extracting all types of relations from text. Because of data sparseness, Open IE systems typically ignore lexical information, and instead employ parse trees and Part-of-Speech (POS) tags. However, the same syntactic structure may correspond to different relations. In this paper, we propose to use a lexicalized tree kernel based on the word embeddings created by a neural network model. We show that the lexicalized tree kernel model surpasses the unlexicalized model. Experiments on three datasets indicate that our Open IE system performs better on the task of relation extraction than the stateof-the-art Open IE systems of Xu et al.</abstract>
<note confidence="0.419353">(2013) and Mesquita et al. (2013).</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Michael J Cafarella</author>
<author>Stephen Soderl</author>
<author>Matt Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<title>Open information extraction from the web.</title>
<date>2007</date>
<booktitle>In International Joint Conference on Artificial Intelligence,</booktitle>
<pages>2670--2676</pages>
<contexts>
<context position="1536" citStr="Banko et al., 2007" startWordPosition="224" endWordPosition="227">t the lexicalized tree kernel model surpasses the unlexicalized model. Experiments on three datasets indicate that our Open IE system performs better on the task of relation extraction than the stateof-the-art Open IE systems of Xu et al. (2013) and Mesquita et al. (2013). 1 Introduction Relation Extraction (RE) is the task of recognizing relationships between entities mentioned in text. In contrast with traditional relation extraction, for which a target set of relations is fixed a priori, Open Information Extraction (Open IE) is a generalization of RE that attempts to extract all relations (Banko et al., 2007). Although Open IE models that extract N-ary relations have been proposed, here we concentrate on binary relations. Most Open IE systems employ syntactic information such as parse trees and part of speech (POS) tags, but ignore lexical information. However, previous work suggests that Open IE would benefit from lexical information because the same syntactic structure may correspond to different relations. For instance, the relation &lt;Annacone, coach of, Federer&gt; is correct for the sentence “Federer hired Annacone as a coach”, but not for the sentence “Federer considered Annacone as a coach,” ev</context>
</contexts>
<marker>Banko, Cafarella, Soderl, Broadhead, Etzioni, 2007</marker>
<rawString>Michele Banko, Michael J Cafarella, Stephen Soderl, Matt Broadhead, and Oren Etzioni. 2007. Open information extraction from the web. In International Joint Conference on Artificial Intelligence, pages 2670–2676.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Bloehdorn</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Structure and semantics for expressive text kernels.</title>
<date>2007</date>
<booktitle>In Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management, CIKM ’07,</booktitle>
<pages>861--864</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="9242" citStr="Bloehdorn and Moschitti (2007)" startWordPosition="1496" endWordPosition="1499"> in the original paper. The general function for a tree kernel model over trees T1 and T2 is: ∑ K(T1,T2) = n1ET1 where n1 and n2 are tree nodes. The ∆ function of SST kernel is defined recursively: 1. ∆(n1, n2) = 0 if the productions (contextfree rules) of n1 and n2 are different. 2. Otherwise, ∆(n1, n2) = 1 if n1 and n2 are matching pre-terminals (POS tags). 3. Otherwise, ∆(n1, n2) = ∏j(1 + ∆(c(n1,j), c(n2,j)), where c(n, j) is the jth child of n. 4.3 Lexicalized Tree Kernel Since simply adding words to lexicalize a tree kernel leads to sparsity problems, a type of smoothing must be applied. Bloehdorn and Moschitti (2007) measure the similarity of words using WordNet. Croce et al. (2011) employ word vectors created by Singular Value Decomposition (Golub and Kahan., 1965) from a word co-occurrence matrix. Plank and Moschitti (2013) use word vectors created by Brown clustering algorithm (Brown et al., 1992), which is another smoothed word representation that represents words as binary vectors. Srivastava et al. (2013) use word embeddings of Collobert and Weston (2008), but their tree kernel does not incorporate POS tags or dependency labels. We propose using word embeddings created by a neural network model (Col</context>
</contexts>
<marker>Bloehdorn, Moschitti, 2007</marker>
<rawString>Stephan Bloehdorn and Alessandro Moschitti. 2007. Structure and semantics for expressive text kernels. In Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management, CIKM ’07, pages 861–864, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Peter V deSouza</author>
<author>Robert L Mercer</author>
<author>Vincent J Della Pietra</author>
<author>Jenifer C Lai</author>
</authors>
<title>Class-based n-gram models of natural language.</title>
<date>1992</date>
<journal>Comput. Linguist.,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="2533" citStr="Brown et al., 1992" startWordPosition="381" endWordPosition="384">espond to different relations. For instance, the relation &lt;Annacone, coach of, Federer&gt; is correct for the sentence “Federer hired Annacone as a coach”, but not for the sentence “Federer considered Annacone as a coach,” even though they have the same dependency path structure (Mausam et al., 2012). Lexical information is required to distinguish the two cases. Here we propose a lexicalized tree kernel model that combines both syntactic and lexical information. In order to avoid lexical sparsity issues, we investigate two smoothing methods that use word vector representations: Brown clustering (Brown et al., 1992) and word embeddings created by a neural network model (Collobert and Weston, 2008). To our knowledge, we are the first to apply word embeddings and to use lexicalized tree kernel models for Open IE. Experiments on three datasets demonstrate that our Open IE system achieves absolute improvements in F-measure of up to 16% over the current state-of-the-art systems of Xu et al. (2013) and Mesquita et al. (2013). In addition, we examine alternative approaches for including lexical information, and find that excluding named entities from the lexical information results in an improved F-score. 2 Sys</context>
<context position="9531" citStr="Brown et al., 1992" startWordPosition="1542" endWordPosition="1545">, n2) = 1 if n1 and n2 are matching pre-terminals (POS tags). 3. Otherwise, ∆(n1, n2) = ∏j(1 + ∆(c(n1,j), c(n2,j)), where c(n, j) is the jth child of n. 4.3 Lexicalized Tree Kernel Since simply adding words to lexicalize a tree kernel leads to sparsity problems, a type of smoothing must be applied. Bloehdorn and Moschitti (2007) measure the similarity of words using WordNet. Croce et al. (2011) employ word vectors created by Singular Value Decomposition (Golub and Kahan., 1965) from a word co-occurrence matrix. Plank and Moschitti (2013) use word vectors created by Brown clustering algorithm (Brown et al., 1992), which is another smoothed word representation that represents words as binary vectors. Srivastava et al. (2013) use word embeddings of Collobert and Weston (2008), but their tree kernel does not incorporate POS tags or dependency labels. We propose using word embeddings created by a neural network model (Collobert and Weston, 2008), in which words are represented by n-dimensional real valued vectors. Each dimension represents a latent feature of the word that reflects its semantic and syntactic properties. Next, we describe how we embed these vectors into tree kernels. Our lexicalized tree k</context>
</contexts>
<marker>Brown, deSouza, Mercer, Pietra, Lai, 1992</marker>
<rawString>Peter F. Brown, Peter V. deSouza, Robert L. Mercer, Vincent J. Della Pietra, and Jenifer C. Lai. 1992. Class-based n-gram models of natural language. Comput. Linguist., 18(4):467–479, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Nigel Duffy</author>
</authors>
<title>New ranking algorithms for parsing and tagging: kernels over discrete structures, and the voted perceptron.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>263--270</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="8514" citStr="Collins and Duffy (2002)" startWordPosition="1362" endWordPosition="1365">calized tree representation is derived from the unlexicalized representation by attaching words as terminal nodes. In order to reduce the number of nodes, we collapse the relation and entity tags with their corresponding POS tags. Figure 2(b) shows the resulting tree for the example sentence. 4.2 Tree Kernels Tree kernel models extract features from parse trees by comparing pairs of tree structures. The essential distinction between different tree kernel functions is the ∆ function that calculates similarity of subtrees. Our modified kernel is based on the SubSet Tree (SST) Kernel proposed by Collins and Duffy (2002). What follows is a simplified description of the kernel; a more detailed description can be found in the original paper. The general function for a tree kernel model over trees T1 and T2 is: ∑ K(T1,T2) = n1ET1 where n1 and n2 are tree nodes. The ∆ function of SST kernel is defined recursively: 1. ∆(n1, n2) = 0 if the productions (contextfree rules) of n1 and n2 are different. 2. Otherwise, ∆(n1, n2) = 1 if n1 and n2 are matching pre-terminals (POS tags). 3. Otherwise, ∆(n1, n2) = ∏j(1 + ∆(c(n1,j), c(n2,j)), where c(n, j) is the jth child of n. 4.3 Lexicalized Tree Kernel Since simply adding w</context>
</contexts>
<marker>Collins, Duffy, 2002</marker>
<rawString>Michael Collins and Nigel Duffy. 2002. New ranking algorithms for parsing and tagging: kernels over discrete structures, and the voted perceptron. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02, pages 263– 270, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
</authors>
<title>A unified architecture for natural language processing: Deep neural networks with multitask learning.</title>
<date>2008</date>
<booktitle>In International Conference on Machine Learning, ICML.</booktitle>
<contexts>
<context position="2616" citStr="Collobert and Weston, 2008" startWordPosition="394" endWordPosition="397">of, Federer&gt; is correct for the sentence “Federer hired Annacone as a coach”, but not for the sentence “Federer considered Annacone as a coach,” even though they have the same dependency path structure (Mausam et al., 2012). Lexical information is required to distinguish the two cases. Here we propose a lexicalized tree kernel model that combines both syntactic and lexical information. In order to avoid lexical sparsity issues, we investigate two smoothing methods that use word vector representations: Brown clustering (Brown et al., 1992) and word embeddings created by a neural network model (Collobert and Weston, 2008). To our knowledge, we are the first to apply word embeddings and to use lexicalized tree kernel models for Open IE. Experiments on three datasets demonstrate that our Open IE system achieves absolute improvements in F-measure of up to 16% over the current state-of-the-art systems of Xu et al. (2013) and Mesquita et al. (2013). In addition, we examine alternative approaches for including lexical information, and find that excluding named entities from the lexical information results in an improved F-score. 2 System Architecture The goal of the Open IE task is to extract from text a set of trip</context>
<context position="9695" citStr="Collobert and Weston (2008)" startWordPosition="1568" endWordPosition="1572"> Lexicalized Tree Kernel Since simply adding words to lexicalize a tree kernel leads to sparsity problems, a type of smoothing must be applied. Bloehdorn and Moschitti (2007) measure the similarity of words using WordNet. Croce et al. (2011) employ word vectors created by Singular Value Decomposition (Golub and Kahan., 1965) from a word co-occurrence matrix. Plank and Moschitti (2013) use word vectors created by Brown clustering algorithm (Brown et al., 1992), which is another smoothed word representation that represents words as binary vectors. Srivastava et al. (2013) use word embeddings of Collobert and Weston (2008), but their tree kernel does not incorporate POS tags or dependency labels. We propose using word embeddings created by a neural network model (Collobert and Weston, 2008), in which words are represented by n-dimensional real valued vectors. Each dimension represents a latent feature of the word that reflects its semantic and syntactic properties. Next, we describe how we embed these vectors into tree kernels. Our lexicalized tree kernel model is the same as SST, except in the following case: if n1 and n2 are matching pre-terminals (POS tags), then ∆(n1, n2) = 1 + G(c(n1), c(n2)), (2) where c(</context>
</contexts>
<marker>Collobert, Weston, 2008</marker>
<rawString>Ronan Collobert and Jason Weston. 2008. A unified architecture for natural language processing: Deep neural networks with multitask learning. In International Conference on Machine Learning, ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Croce</author>
<author>Alessandro Moschitti</author>
<author>Roberto Basili</author>
</authors>
<title>Structured lexical similarity via convolution kernels on dependency trees.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>1034--1046</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="9309" citStr="Croce et al. (2011)" startWordPosition="1507" endWordPosition="1510">s T1 and T2 is: ∑ K(T1,T2) = n1ET1 where n1 and n2 are tree nodes. The ∆ function of SST kernel is defined recursively: 1. ∆(n1, n2) = 0 if the productions (contextfree rules) of n1 and n2 are different. 2. Otherwise, ∆(n1, n2) = 1 if n1 and n2 are matching pre-terminals (POS tags). 3. Otherwise, ∆(n1, n2) = ∏j(1 + ∆(c(n1,j), c(n2,j)), where c(n, j) is the jth child of n. 4.3 Lexicalized Tree Kernel Since simply adding words to lexicalize a tree kernel leads to sparsity problems, a type of smoothing must be applied. Bloehdorn and Moschitti (2007) measure the similarity of words using WordNet. Croce et al. (2011) employ word vectors created by Singular Value Decomposition (Golub and Kahan., 1965) from a word co-occurrence matrix. Plank and Moschitti (2013) use word vectors created by Brown clustering algorithm (Brown et al., 1992), which is another smoothed word representation that represents words as binary vectors. Srivastava et al. (2013) use word embeddings of Collobert and Weston (2008), but their tree kernel does not incorporate POS tags or dependency labels. We propose using word embeddings created by a neural network model (Collobert and Weston, 2008), in which words are represented by n-dimen</context>
</contexts>
<marker>Croce, Moschitti, Basili, 2011</marker>
<rawString>Danilo Croce, Alessandro Moschitti, and Roberto Basili. 2011. Structured lexical similarity via convolution kernels on dependency trees. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 1034–1046, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Golub</author>
<author>W Kahan</author>
</authors>
<title>Calculating the singular values and pseudo-inverse of a matrix.</title>
<date>1965</date>
<journal>Journal of the Society for Industrial and Applied Mathematics: Series B, Numerical Analysis,</journal>
<pages>205224</pages>
<marker>Golub, Kahan, 1965</marker>
<rawString>G. Golub and W. Kahan. 1965. Calculating the singular values and pseudo-inverse of a matrix. Journal of the Society for Industrial and Applied Mathematics: Series B, Numerical Analysis, page 205224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Mihai Surdeanu</author>
<author>John Bauer</author>
<author>Jenny Finkel</author>
<author>Steven J Bethard</author>
<author>David McClosky</author>
</authors>
<title>The Stanford CoreNLP natural language processing toolkit.</title>
<date>2014</date>
<booktitle>In Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations,</booktitle>
<pages>55--60</pages>
<contexts>
<context position="4195" citStr="Manning et al., 2014" startWordPosition="646" endWordPosition="650"> consists of three modules: entity extraction, relation candidate extraction, and tree 279 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 279–284, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics Figure 1: Our Open IE system structure. kernel filtering. The system structure is outlined in Figure 1. We identify named entities, parse sentences, and convert constituency trees into dependency structures using the Stanford tools (Manning et al., 2014). Entities within a fixed token distance (set to 20 according to development results) are extracted as pairs I&lt; E1, E2 &gt;1. We then identify relation candidates R for each entity pair in a sentence, using dependency paths. Finally, the candidate triples I&lt; E1, R, E2 &gt;I are paired with their corresponding tree structures, and provided as input to the SVM tree kernel. Our Open IE system outputs the triples that are classified as positive. In the following sections, we describe the components of the system in more detail. 3 Relation Candidates Relation candidates are words that may represent a rel</context>
</contexts>
<marker>Manning, Surdeanu, Bauer, Finkel, Bethard, McClosky, 2014</marker>
<rawString>Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J. Bethard, and David McClosky. 2014. The Stanford CoreNLP natural language processing toolkit. In Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 55–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Schmitz Mausam</author>
<author>Robert Bart</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Open language learning for information extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>523--534</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2212" citStr="Mausam et al., 2012" startWordPosition="332" endWordPosition="335">ave been proposed, here we concentrate on binary relations. Most Open IE systems employ syntactic information such as parse trees and part of speech (POS) tags, but ignore lexical information. However, previous work suggests that Open IE would benefit from lexical information because the same syntactic structure may correspond to different relations. For instance, the relation &lt;Annacone, coach of, Federer&gt; is correct for the sentence “Federer hired Annacone as a coach”, but not for the sentence “Federer considered Annacone as a coach,” even though they have the same dependency path structure (Mausam et al., 2012). Lexical information is required to distinguish the two cases. Here we propose a lexicalized tree kernel model that combines both syntactic and lexical information. In order to avoid lexical sparsity issues, we investigate two smoothing methods that use word vector representations: Brown clustering (Brown et al., 1992) and word embeddings created by a neural network model (Collobert and Weston, 2008). To our knowledge, we are the first to apply word embeddings and to use lexicalized tree kernel models for Open IE. Experiments on three datasets demonstrate that our Open IE system achieves abso</context>
<context position="4998" citStr="Mausam et al. (2012)" startWordPosition="782" endWordPosition="785">in a sentence, using dependency paths. Finally, the candidate triples I&lt; E1, R, E2 &gt;I are paired with their corresponding tree structures, and provided as input to the SVM tree kernel. Our Open IE system outputs the triples that are classified as positive. In the following sections, we describe the components of the system in more detail. 3 Relation Candidates Relation candidates are words that may represent a relation between two entities. We consider only lemmatized nouns, verbs and adjectives that are within two dependency links from either of the entities. Following Wu and Weld (2010) and Mausam et al. (2012), we use dependency patterns rather than POS patterns, which allows us to identify relation candidates which are farther away from entities in terms of token distance. We extract the first two content words along the dependency path between E1 and E2. In the following example, the path is E1 —* encounter —* build —* E2, and the two relation word candidates between “Mr. Wathen” and “Plant Security Service” are encounter and build, of which the latter is the correct one. If there are no content words on the dependency path between the two entities, we instead consider words that are directly lin</context>
</contexts>
<marker>Mausam, Bart, Soderland, Etzioni, 2012</marker>
<rawString>Mausam, Michael Schmitz, Robert Bart, Stephen Soderland, and Oren Etzioni. 2012. Open language learning for information extraction. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 523–534. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Filipe Mesquita</author>
<author>Jordan Schmidek</author>
<author>Denilson Barbosa</author>
</authors>
<title>Effectiveness and efficiency of open relation extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>447--457</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1189" citStr="Mesquita et al. (2013)" startWordPosition="169" endWordPosition="172">se of data sparseness, Open IE systems typically ignore lexical information, and instead employ parse trees and Part-of-Speech (POS) tags. However, the same syntactic structure may correspond to different relations. In this paper, we propose to use a lexicalized tree kernel based on the word embeddings created by a neural network model. We show that the lexicalized tree kernel model surpasses the unlexicalized model. Experiments on three datasets indicate that our Open IE system performs better on the task of relation extraction than the stateof-the-art Open IE systems of Xu et al. (2013) and Mesquita et al. (2013). 1 Introduction Relation Extraction (RE) is the task of recognizing relationships between entities mentioned in text. In contrast with traditional relation extraction, for which a target set of relations is fixed a priori, Open Information Extraction (Open IE) is a generalization of RE that attempts to extract all relations (Banko et al., 2007). Although Open IE models that extract N-ary relations have been proposed, here we concentrate on binary relations. Most Open IE systems employ syntactic information such as parse trees and part of speech (POS) tags, but ignore lexical information. Howe</context>
<context position="2944" citStr="Mesquita et al. (2013)" startWordPosition="452" endWordPosition="455">l that combines both syntactic and lexical information. In order to avoid lexical sparsity issues, we investigate two smoothing methods that use word vector representations: Brown clustering (Brown et al., 1992) and word embeddings created by a neural network model (Collobert and Weston, 2008). To our knowledge, we are the first to apply word embeddings and to use lexicalized tree kernel models for Open IE. Experiments on three datasets demonstrate that our Open IE system achieves absolute improvements in F-measure of up to 16% over the current state-of-the-art systems of Xu et al. (2013) and Mesquita et al. (2013). In addition, we examine alternative approaches for including lexical information, and find that excluding named entities from the lexical information results in an improved F-score. 2 System Architecture The goal of the Open IE task is to extract from text a set of triples {&lt; E1, R, E2 &gt;}, where E1 and E2 are two named entities, and R is a textual fragment that indicates the semantic relation between the two entities. We concentrate on binary, single-word relations between named entities. The candidate relation words are extracted from dependency structures, and then filtered by a supervised</context>
<context position="11186" citStr="Mesquita et al., 2013" startWordPosition="1828" endWordPosition="1831">ion: (1) relation words only; (2) all words (relation words, named entities, and other words along the dependency path fragment); and (3) all words, except named entities. The words that are excluded are assumed to be different; for example, in the third method, G(E1, E2) is always zero, even if the entities, E1 and E2, are the same. ∑ ∆(n1, n2), (1) n2ET2 281 5 Experiments Here we evaluate alternative tree kernel configurations, and compare our Open IE system to previous work. We perform experiments on three datasets (Table 1): the Penn Treebank set (Xu et al., 2013), the New York Times set (Mesquita et al., 2013), and the ClueWeb set which we created for this project from a large collection of web pages.1 The models are trained on the Penn Treebank training set and tested on the three test sets, of which the Penn Treebank set is in-domain, and the other two sets are out-of-domain. For word embedding and Brown clustering representations, we use the data provided by Turian et al. (2010). The SVM parameters, as well as the Brown cluster size and code length, are tuned on the development set. Set train dev test Penn Treebank 750 100 100 New York Times — 300 500 ClueWeb — 450 250 Table 1: Data sets and the</context>
<context position="13967" citStr="Mesquita et al. (2013)" startWordPosition="2298" endWordPosition="2301">l words 93.8 68.2 79.0 embedding excl. entities 95.9 71.2 81.7 Table 2: The results of relation extraction with alternative smoothing and lexicalization techniques on the Penn Treebank set (with our relation candidate extraction and tree structure). lated to entities. Consider the example mentioned in (Riedel et al., 2013): for relations like “X visits Y”, X could be a person or organization, and Y could be a location, organization, or person. Our final set of experiments evaluates the bestperforming version of our system (the last row in Table 2) against two state-of-the-art Open IE systems: Mesquita et al. (2013), which is based on several hand-crafted dependency patterns; and Xu et al. (2013), which uses POS-based relation candidate extraction and an unlexicalized tree kernel. Tree kernel systems are all trained on the Penn Treebank training set, and tuned on the corresponding development sets. The results in Table 3 show that our system consistently outperforms the other two systems, with absolute gains in F-score between 4 and 16%. We include the reported results of (Xu et al., 2013) on the Penn Treebank set, and of (Mesquita et al., 2013) on the New York Times set. The ClueWeb results were obtaine</context>
<context position="15585" citStr="Mesquita et al. (2013)" startWordPosition="2575" endWordPosition="2578">orm Brown clustering on the ClueWeb set, but not on the other two sets. The ClueWeb set is quite challenging because it contains web pages which can be quite noisy. As a result we’ve found that a number of Open IE errors are caused by parsing. Conjunction structures are especially difficult for both parsing and relation extraction. For example, our system extracts the relation triple &lt;Scotland, base, Scott&gt; from the sentence “Set in 17th century Scotland 282 P R F1 Penn Treebank set Xu et al. (2013)* 66.1 50.7 57.4 Brown (PM13) 82.8 65.8 73.3 Ours (embedding) 91.8 61.6 73.8 New York Times set Mesquita et al. (2013)* 72.8 39.3 51.1 Brown (PM13) 83.5 44.0 57.6 Ours (embedding) 85.9 40.7 55.2 ClueWeb set Xu et al. (2013) 54.3 35.8 43.2 Mesquita et al. (2013) 63.3 29.2 40.0 Brown (PM13) 54.1 31.1 39.5 Ours (embedding) 45.8 51.9 48.7 Table 3: Comparison of complete Open IE systems. The asterisks denote results reported in previous work. and based on a novel by Sir Walter Scott, its high drama...” with the wrong dependency path Scotland c°nand � based prep by � Scott. In the future, we will investigate whether adding information from context words that are not on the dependency path between two entities may a</context>
</contexts>
<marker>Mesquita, Schmidek, Barbosa, 2013</marker>
<rawString>Filipe Mesquita, Jordan Schmidek, and Denilson Barbosa. 2013. Effectiveness and efficiency of open relation extraction. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 447–457. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
</authors>
<title>User’s guide to sigf: Significance testing by approximate randomisation.</title>
<date>2006</date>
<marker>Pad´o, 2006</marker>
<rawString>Sebastian Pad´o, 2006. User’s guide to sigf: Significance testing by approximate randomisation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Plank</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Embedding semantic similarity in tree kernels for domain adaptation of relation extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>1498--1507</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="9455" citStr="Plank and Moschitti (2013)" startWordPosition="1529" endWordPosition="1532"> the productions (contextfree rules) of n1 and n2 are different. 2. Otherwise, ∆(n1, n2) = 1 if n1 and n2 are matching pre-terminals (POS tags). 3. Otherwise, ∆(n1, n2) = ∏j(1 + ∆(c(n1,j), c(n2,j)), where c(n, j) is the jth child of n. 4.3 Lexicalized Tree Kernel Since simply adding words to lexicalize a tree kernel leads to sparsity problems, a type of smoothing must be applied. Bloehdorn and Moschitti (2007) measure the similarity of words using WordNet. Croce et al. (2011) employ word vectors created by Singular Value Decomposition (Golub and Kahan., 1965) from a word co-occurrence matrix. Plank and Moschitti (2013) use word vectors created by Brown clustering algorithm (Brown et al., 1992), which is another smoothed word representation that represents words as binary vectors. Srivastava et al. (2013) use word embeddings of Collobert and Weston (2008), but their tree kernel does not incorporate POS tags or dependency labels. We propose using word embeddings created by a neural network model (Collobert and Weston, 2008), in which words are represented by n-dimensional real valued vectors. Each dimension represents a latent feature of the word that reflects its semantic and syntactic properties. Next, we d</context>
<context position="12460" citStr="Plank and Moschitti (2013)" startWordPosition="2051" endWordPosition="2054"> effect of different smoothing and lexicalization techniques on the tree kernels. In order to focus on tree kernel functions, we use the relation candidate extraction (Section 3) and tree structure (Section 4.1) proposed in this paper. The results in the first two rows indicate that adding unsmoothed lexical information to the method of Xu et al. (2013) is not helpful, which we attribute to data sparsity. On the other hand, smoothed word representations do improve F-measure. Surprisingly, a neural network approach of creating word embeddings actually achieves a lower recall than the method of Plank and Moschitti (2013) that uses Brown clustering; the difference in F-measure is not statistically significant according to compute-intensive randomization test (Pad´o, 2006). With regards to lexicalization, the inclusion of relation words is important. However, unlike Plank and Moschitti (2013), we found that it is better to exclude the lexical information of entities themselves, which confirms the findings of Riedel et al. (2013). We hypothesize that the correctness of a relation triple in Open IE is not closely re1The Treebank set of (Xu et al., 2013), with minor corrections, and the ClueWeb set are appended to</context>
</contexts>
<marker>Plank, Moschitti, 2013</marker>
<rawString>Barbara Plank and Alessandro Moschitti. 2013. Embedding semantic similarity in tree kernels for domain adaptation of relation extraction. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1498–1507, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Benjamin M Marlin</author>
<author>Andrew McCallum</author>
</authors>
<title>Relation extraction with matrix factorization and universal schemas.</title>
<date>2013</date>
<booktitle>In Joint Human Language Technology Conference/Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL ’13),</booktitle>
<contexts>
<context position="12874" citStr="Riedel et al. (2013)" startWordPosition="2112" endWordPosition="2115">r hand, smoothed word representations do improve F-measure. Surprisingly, a neural network approach of creating word embeddings actually achieves a lower recall than the method of Plank and Moschitti (2013) that uses Brown clustering; the difference in F-measure is not statistically significant according to compute-intensive randomization test (Pad´o, 2006). With regards to lexicalization, the inclusion of relation words is important. However, unlike Plank and Moschitti (2013), we found that it is better to exclude the lexical information of entities themselves, which confirms the findings of Riedel et al. (2013). We hypothesize that the correctness of a relation triple in Open IE is not closely re1The Treebank set of (Xu et al., 2013), with minor corrections, and the ClueWeb set are appended to this publication. Smoothing Lexical info P R Fl none (Xu13) none 85.7 72.7 78.7 none all words 89.8 66.7 76.5 Brown (PM13) relation only 88.7 71.2 79.0 Brown (PM13) all words 84.5 74.2 79.0 Brown (PM13) excl. entities 86.2 75.8 80.7 embedding relation only 93.9 69.7 80.0 embedding all words 93.8 68.2 79.0 embedding excl. entities 95.9 71.2 81.7 Table 2: The results of relation extraction with alternative smoot</context>
</contexts>
<marker>Riedel, Yao, Marlin, McCallum, 2013</marker>
<rawString>Sebastian Riedel, Limin Yao, Benjamin M. Marlin, and Andrew McCallum. 2013. Relation extraction with matrix factorization and universal schemas. In Joint Human Language Technology Conference/Annual Meeting of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL ’13), June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shashank Srivastava</author>
<author>Dirk Hovy</author>
<author>Eduard Hovy</author>
</authors>
<title>A walk-based semantically enriched tree kernel over distributed word representations.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1411--1416</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="9644" citStr="Srivastava et al. (2013)" startWordPosition="1559" endWordPosition="1563">n2,j)), where c(n, j) is the jth child of n. 4.3 Lexicalized Tree Kernel Since simply adding words to lexicalize a tree kernel leads to sparsity problems, a type of smoothing must be applied. Bloehdorn and Moschitti (2007) measure the similarity of words using WordNet. Croce et al. (2011) employ word vectors created by Singular Value Decomposition (Golub and Kahan., 1965) from a word co-occurrence matrix. Plank and Moschitti (2013) use word vectors created by Brown clustering algorithm (Brown et al., 1992), which is another smoothed word representation that represents words as binary vectors. Srivastava et al. (2013) use word embeddings of Collobert and Weston (2008), but their tree kernel does not incorporate POS tags or dependency labels. We propose using word embeddings created by a neural network model (Collobert and Weston, 2008), in which words are represented by n-dimensional real valued vectors. Each dimension represents a latent feature of the word that reflects its semantic and syntactic properties. Next, we describe how we embed these vectors into tree kernels. Our lexicalized tree kernel model is the same as SST, except in the following case: if n1 and n2 are matching pre-terminals (POS tags),</context>
</contexts>
<marker>Srivastava, Hovy, Hovy, 2013</marker>
<rawString>Shashank Srivastava, Dirk Hovy, and Eduard Hovy. 2013. A walk-based semantically enriched tree kernel over distributed word representations. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1411– 1416, Seattle, Washington, USA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: a simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>384--394</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="11565" citStr="Turian et al. (2010)" startWordPosition="1894" endWordPosition="1897"> we evaluate alternative tree kernel configurations, and compare our Open IE system to previous work. We perform experiments on three datasets (Table 1): the Penn Treebank set (Xu et al., 2013), the New York Times set (Mesquita et al., 2013), and the ClueWeb set which we created for this project from a large collection of web pages.1 The models are trained on the Penn Treebank training set and tested on the three test sets, of which the Penn Treebank set is in-domain, and the other two sets are out-of-domain. For word embedding and Brown clustering representations, we use the data provided by Turian et al. (2010). The SVM parameters, as well as the Brown cluster size and code length, are tuned on the development set. Set train dev test Penn Treebank 750 100 100 New York Times — 300 500 ClueWeb — 450 250 Table 1: Data sets and their size (number of sentences). Table 2 shows the effect of different smoothing and lexicalization techniques on the tree kernels. In order to focus on tree kernel functions, we use the relation candidate extraction (Section 3) and tree structure (Section 4.1) proposed in this paper. The results in the first two rows indicate that adding unsmoothed lexical information to the me</context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010. Word representations: a simple and general method for semi-supervised learning. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 384–394, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Daniel S Weld</author>
</authors>
<title>Open information extraction using wikipedia.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>118--127</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4973" citStr="Wu and Weld (2010)" startWordPosition="777" endWordPosition="780">R for each entity pair in a sentence, using dependency paths. Finally, the candidate triples I&lt; E1, R, E2 &gt;I are paired with their corresponding tree structures, and provided as input to the SVM tree kernel. Our Open IE system outputs the triples that are classified as positive. In the following sections, we describe the components of the system in more detail. 3 Relation Candidates Relation candidates are words that may represent a relation between two entities. We consider only lemmatized nouns, verbs and adjectives that are within two dependency links from either of the entities. Following Wu and Weld (2010) and Mausam et al. (2012), we use dependency patterns rather than POS patterns, which allows us to identify relation candidates which are farther away from entities in terms of token distance. We extract the first two content words along the dependency path between E1 and E2. In the following example, the path is E1 —* encounter —* build —* E2, and the two relation word candidates between “Mr. Wathen” and “Plant Security Service” are encounter and build, of which the latter is the correct one. If there are no content words on the dependency path between the two entities, we instead consider wo</context>
</contexts>
<marker>Wu, Weld, 2010</marker>
<rawString>Fei Wu and Daniel S. Weld. 2010. Open information extraction using wikipedia. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 118–127, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Xu</author>
<author>Mi-Young Kim</author>
<author>Kevin Quinn</author>
<author>Randy Goebel</author>
<author>Denilson Barbosa</author>
</authors>
<title>Open information extraction with tree kernels.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>868--877</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia,</location>
<contexts>
<context position="1162" citStr="Xu et al. (2013)" startWordPosition="164" endWordPosition="167">ions from text. Because of data sparseness, Open IE systems typically ignore lexical information, and instead employ parse trees and Part-of-Speech (POS) tags. However, the same syntactic structure may correspond to different relations. In this paper, we propose to use a lexicalized tree kernel based on the word embeddings created by a neural network model. We show that the lexicalized tree kernel model surpasses the unlexicalized model. Experiments on three datasets indicate that our Open IE system performs better on the task of relation extraction than the stateof-the-art Open IE systems of Xu et al. (2013) and Mesquita et al. (2013). 1 Introduction Relation Extraction (RE) is the task of recognizing relationships between entities mentioned in text. In contrast with traditional relation extraction, for which a target set of relations is fixed a priori, Open Information Extraction (Open IE) is a generalization of RE that attempts to extract all relations (Banko et al., 2007). Although Open IE models that extract N-ary relations have been proposed, here we concentrate on binary relations. Most Open IE systems employ syntactic information such as parse trees and part of speech (POS) tags, but ignor</context>
<context position="2917" citStr="Xu et al. (2013)" startWordPosition="447" endWordPosition="450">ized tree kernel model that combines both syntactic and lexical information. In order to avoid lexical sparsity issues, we investigate two smoothing methods that use word vector representations: Brown clustering (Brown et al., 1992) and word embeddings created by a neural network model (Collobert and Weston, 2008). To our knowledge, we are the first to apply word embeddings and to use lexicalized tree kernel models for Open IE. Experiments on three datasets demonstrate that our Open IE system achieves absolute improvements in F-measure of up to 16% over the current state-of-the-art systems of Xu et al. (2013) and Mesquita et al. (2013). In addition, we examine alternative approaches for including lexical information, and find that excluding named entities from the lexical information results in an improved F-score. 2 System Architecture The goal of the Open IE task is to extract from text a set of triples {&lt; E1, R, E2 &gt;}, where E1 and E2 are two named entities, and R is a textual fragment that indicates the semantic relation between the two entities. We concentrate on binary, single-word relations between named entities. The candidate relation words are extracted from dependency structures, and th</context>
<context position="7048" citStr="Xu et al. (2013)" startWordPosition="1113" endWordPosition="1116">path to a tree-like structure with unlabelled edges. The target dependency path is the shortest path that includes the triple and other content words along the path. Consider the following example, which is a simplified representation of the sentence “Georgia-Pacific Corp.’s unsolicited $3.9 billion bid for Great Northern Nekoosa Corp. was hailed by Wall Street.” The candidate triple identified by the relation candidate extraction module is &lt;Georgia-Pacific Corp., bid, Great Northern Nekoosa Corp.&gt;. Our unlexicalized tree representation model is similar to the unlexicalized representations of Xu et al. (2013), except that instead of using the POS tag of the path’s head word as the root, we create an abstract Root node. We preserve the dependency labels, POS tags, and entity information as tree nodes: (a) the top dependency labels are in280 (a) An un-lexicalized dependency tree. (b) A lexicalized dependency tree. Figure 2: An unlexicalized tree and the corresponding lexicalized tree. cluded as children of the abstract Root node, other labels are attached to the corresponding parent labels; (b) the POS tag of the head word of the dependence path is a child of the Root; (c) other POS tags are attache</context>
<context position="11138" citStr="Xu et al., 2013" startWordPosition="1819" endWordPosition="1822">hree methods of including lexical information: (1) relation words only; (2) all words (relation words, named entities, and other words along the dependency path fragment); and (3) all words, except named entities. The words that are excluded are assumed to be different; for example, in the third method, G(E1, E2) is always zero, even if the entities, E1 and E2, are the same. ∑ ∆(n1, n2), (1) n2ET2 281 5 Experiments Here we evaluate alternative tree kernel configurations, and compare our Open IE system to previous work. We perform experiments on three datasets (Table 1): the Penn Treebank set (Xu et al., 2013), the New York Times set (Mesquita et al., 2013), and the ClueWeb set which we created for this project from a large collection of web pages.1 The models are trained on the Penn Treebank training set and tested on the three test sets, of which the Penn Treebank set is in-domain, and the other two sets are out-of-domain. For word embedding and Brown clustering representations, we use the data provided by Turian et al. (2010). The SVM parameters, as well as the Brown cluster size and code length, are tuned on the development set. Set train dev test Penn Treebank 750 100 100 New York Times — 300 </context>
<context position="12999" citStr="Xu et al., 2013" startWordPosition="2136" endWordPosition="2139">ctually achieves a lower recall than the method of Plank and Moschitti (2013) that uses Brown clustering; the difference in F-measure is not statistically significant according to compute-intensive randomization test (Pad´o, 2006). With regards to lexicalization, the inclusion of relation words is important. However, unlike Plank and Moschitti (2013), we found that it is better to exclude the lexical information of entities themselves, which confirms the findings of Riedel et al. (2013). We hypothesize that the correctness of a relation triple in Open IE is not closely re1The Treebank set of (Xu et al., 2013), with minor corrections, and the ClueWeb set are appended to this publication. Smoothing Lexical info P R Fl none (Xu13) none 85.7 72.7 78.7 none all words 89.8 66.7 76.5 Brown (PM13) relation only 88.7 71.2 79.0 Brown (PM13) all words 84.5 74.2 79.0 Brown (PM13) excl. entities 86.2 75.8 80.7 embedding relation only 93.9 69.7 80.0 embedding all words 93.8 68.2 79.0 embedding excl. entities 95.9 71.2 81.7 Table 2: The results of relation extraction with alternative smoothing and lexicalization techniques on the Penn Treebank set (with our relation candidate extraction and tree structure). late</context>
<context position="14450" citStr="Xu et al., 2013" startWordPosition="2378" endWordPosition="2381">e bestperforming version of our system (the last row in Table 2) against two state-of-the-art Open IE systems: Mesquita et al. (2013), which is based on several hand-crafted dependency patterns; and Xu et al. (2013), which uses POS-based relation candidate extraction and an unlexicalized tree kernel. Tree kernel systems are all trained on the Penn Treebank training set, and tuned on the corresponding development sets. The results in Table 3 show that our system consistently outperforms the other two systems, with absolute gains in F-score between 4 and 16%. We include the reported results of (Xu et al., 2013) on the Penn Treebank set, and of (Mesquita et al., 2013) on the New York Times set. The ClueWeb results were obtained by running the respective systems on the test set, except that we used our relation candidate extraction method for the tree kernel of (Xu et al., 2013). We conclude that the substantial improvement on the Penn Treebank set can be partly attributed to a superior tree kernel, and not only to a better relation candidate extraction method. We also note that word embeddings statistically outperform Brown clustering on the ClueWeb set, but not on the other two sets. The ClueWeb set</context>
<context position="15690" citStr="Xu et al. (2013)" startWordPosition="2594" endWordPosition="2597">cause it contains web pages which can be quite noisy. As a result we’ve found that a number of Open IE errors are caused by parsing. Conjunction structures are especially difficult for both parsing and relation extraction. For example, our system extracts the relation triple &lt;Scotland, base, Scott&gt; from the sentence “Set in 17th century Scotland 282 P R F1 Penn Treebank set Xu et al. (2013)* 66.1 50.7 57.4 Brown (PM13) 82.8 65.8 73.3 Ours (embedding) 91.8 61.6 73.8 New York Times set Mesquita et al. (2013)* 72.8 39.3 51.1 Brown (PM13) 83.5 44.0 57.6 Ours (embedding) 85.9 40.7 55.2 ClueWeb set Xu et al. (2013) 54.3 35.8 43.2 Mesquita et al. (2013) 63.3 29.2 40.0 Brown (PM13) 54.1 31.1 39.5 Ours (embedding) 45.8 51.9 48.7 Table 3: Comparison of complete Open IE systems. The asterisks denote results reported in previous work. and based on a novel by Sir Walter Scott, its high drama...” with the wrong dependency path Scotland c°nand � based prep by � Scott. In the future, we will investigate whether adding information from context words that are not on the dependency path between two entities may alleviate this problem. 6 Conclusion We have proposed a lexicalized tree kernel model for Open IE, which i</context>
</contexts>
<marker>Xu, Kim, Quinn, Goebel, Barbosa, 2013</marker>
<rawString>Ying Xu, Mi-Young Kim, Kevin Quinn, Randy Goebel, and Denilson Barbosa. 2013. Open information extraction with tree kernels. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 868–877, Atlanta, Georgia, June. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>