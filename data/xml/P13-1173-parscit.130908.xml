<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000063">
<title confidence="0.986157">
Mining Opinion Words and Opinion Targets in a Two-Stage Framework
</title>
<author confidence="0.998332">
Liheng Xu, Kang Liu, Siwei Lai, Yubo Chen and Jun Zhao
</author>
<affiliation confidence="0.99269">
National Laboratory of Pattern Recognition
Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China
</affiliation>
<email confidence="0.969591">
{lhxu, kliu, swlai, ybchen, jzhao}@nlpr.ia.ac.cn
</email>
<sectionHeader confidence="0.993659" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99949445">
This paper proposes a novel two-stage
method for mining opinion words and
opinion targets. In the first stage, we
propose a Sentiment Graph Walking algo-
rithm, which naturally incorporates syn-
tactic patterns in a Sentiment Graph to ex-
tract opinion word/target candidates. Then
random walking is employed to estimate
confidence of candidates, which improves
extraction accuracy by considering confi-
dence of patterns. In the second stage, we
adopt a self-learning strategy to refine the
results from the first stage, especially for
filtering out high-frequency noise terms
and capturing the long-tail terms, which
are not investigated by previous meth-
ods. The experimental results on three real
world datasets demonstrate the effective-
ness of our approach compared with state-
of-the-art unsupervised methods.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999883482758621">
Opinion mining not only assists users to make in-
formed purchase decisions, but also helps busi-
ness organizations understand and act upon cus-
tomer feedbacks on their products or services in
real-time. Extracting opinion words and opinion
targets are two key tasks in opinion mining. Opin-
ion words refer to those terms indicating positive
or negative sentiment. Opinion targets represent
aspects or attributes of objects toward which opin-
ions are expressed. Mining these terms from re-
views of a specific domain allows a more thorough
understanding of customers’ opinions.
Opinion words and opinion targets often co-
occur in reviews and there exist modified relations
(called opinion relation in this paper) between
them. For example, in the sentence “It has a clear
screen”, “clear” is an opinion word and “screen” is
an opinion target, and there is an opinion relation
between the two words. It is natural to identify
such opinion relations through common syntactic
patterns (also called opinion patterns in this pa-
per) between opinion words and targets. For ex-
ample, we can extract “clear” and “screen” by us-
ing a syntactic pattern “Adj-{mod}-Noun”, which
captures the opinion relation between them. Al-
though previous works have shown the effective-
ness of syntactic patterns for this task (Qiu et al.,
2009; Zhang et al., 2010), they still have some lim-
itations as follows.
False Opinion Relations: As an example, the
phrase “everyday at school” can be matched by
a pattern “Adj-{mod}-(Prep)-{pcomp-n}-Noun”,
but it doesn’t bear any sentiment orientation. We
call such relations that match opinion patterns but
express no opinion false opinion relations. Pre-
vious pattern learning algorithms (Zhuang et al.,
2006; Kessler and Nicolov, 2009; Jijkoun et al.,
2010) often extract opinion patterns by frequency.
However, some high-frequency syntactic patterns
can have very poor precision (Kessler and Nicolov,
2009).
False Opinion Targets: In another case, the
phrase “wonderful time” can be matched by
an opinion pattern “Adj-{mod}-Noun”, which is
widely used in previous works (Popescu and Et-
zioni, 2005; Qiu et al., 2009). As can be seen, this
phrase does express a positive opinion but unfortu-
nately “time” is not a valid opinion target for most
domains such as MP3. Thus, false opinion targets
are extracted. Due to the lack of ground-truth
knowledge for opinion targets, non-target terms
introduced in this way can be hardly filtered out.
Long-tail Opinion Targets: We further no-
tice that previous works prone to extract opinion
targets with high frequency (Hu and Liu, 2004;
Popescu and Etzioni, 2005; Qiu et al., 2009; Zhu
et al., 2009), and they often have difficulty in iden-
tifying the infrequent or long-tail opinion targets.
</bodyText>
<page confidence="0.950856">
1764
</page>
<note confidence="0.9135365">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1764–1773,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.997998617647059">
To address the problems stated above, this pa-
per proposes a two-stage framework for mining
opinion words and opinion targets. The under-
lying motivation is analogous to the novel idea
“Mine the Easy, Classify the Hard” (Dasgupta and
Ng, 2009). In our first stage, we propose a Senti-
ment Graph Walking algorithm to cope with the
false opinion relation problem, which mines easy
cases of opinion words/targets. We speculate that
it may be helpful to introduce a confidence score
for each pattern. Concretely, we create a Sen-
timent Graph to model opinion relations among
opinion word/target/pattern candidates and apply
random walking to estimate confidence of them.
Thus, confidence of pattern is considered in a uni-
fied process. Patterns that often extract false opin-
ion relations will have low confidence, and terms
introduced by low-confidence patterns will also
have low confidence accordingly. This could po-
tentially improve the extraction accuracy.
In the second stage, we identify the hard cases,
which aims to filter out false opinion targets and
extract long-tail opinion targets. Previous super-
vised methods have been shown to achieve state-
of-the-art results for this task (Wu et al., 2009; Jin
and Ho, 2009; Li et al., 2010). However, the big
challenge for fully supervised method is the lack
of annotated training data. Therefore, we adopt a
self-learning strategy. Specifically, we employ a
semi-supervised classifier to refine the target re-
sults from the first stage, which uses some highly
confident target candidates as the initial labeled
examples. Then opinion words are also refined.
Our main contributions are as follows:
</bodyText>
<listItem confidence="0.995749066666667">
• We propose a Sentiment Graph Walking al-
gorithm to mine opinion words and opinion
targets from reviews, which naturally incor-
porates confidence of syntactic pattern in a
graph to improve extraction performance. To
our best knowledge, the incorporation of pat-
tern confidence in such a Sentiment Graph
has never been studied before for opinion
words/targets mining task (Section 3).
• We adopt a self-learning method for refining
opinion words/targets generated by Sentiment
Graph Walking. Specifically, it can remove
high-frequency noise terms and capture long-
tail opinion targets in corpora (Section 4).
• We perform experiments on three real world
</listItem>
<bodyText confidence="0.861847333333333">
datasets, which demonstrate the effectiveness
of our method compared with state-of-the-art
unsupervised methods (Section 5).
</bodyText>
<sectionHeader confidence="0.999145" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99998452">
In opinion words/targets mining task, most unsu-
pervised methods rely on identifying opinion rela-
tions between opinion words and opinion targets.
Hu and Liu (2004) proposed an association mining
technique to extract opinion words/targets. The
simple heuristic rules they used may potentially
introduce many false opinion words/targets. To
identify opinion relations more precisely, subse-
quent research work exploited syntax information.
Popescu and Etzioni (2005) used manually com-
plied syntactic patterns and Pointwise Mutual In-
formation (PMI) to extract opinion words/targets.
Qiu et al. (2009) proposed a bootstrapping frame-
work called Double Propagation which intro-
duced eight heuristic syntactic rules. While man-
ually defining syntactic patterns could be time-
consuming and error-prone, we learn syntactic
patterns automatically from data.
There have been extensive works on mining
opinion words and opinion targets by syntac-
tic pattern learning. Riloff and Wiebe (2003)
performed pattern learning through bootstrapping
while extracting subjective expressions. Zhuang
et al. (2006) obtained various dependency re-
lationship templates from an annotated movie
corpus and applied them to supervised opinion
words/targets extraction. Kobayashi et al. (2007)
adopted a supervised learning technique to search
for useful syntactic patterns as contextual clues.
Our approach is similar to (Wiebe and Riloff,
2005) and (Xu et al., 2013), all of which apply
syntactic pattern learning and adopt self-learning
strategy. However, the task of (Wiebe and Riloff,
2005) was to classify sentiment orientations in
sentence level, while ours needs to extract more
detailed information in term level. In addition,
our method extends (Xu et al., 2013), and we
give a more complete and in-depth analysis on
the aforementioned problems in the first section.
There were also many works employed graph-
based method (Li et al., 2012; Zhang et al., 2010;
Hassan and Radev, 2010; Liu et al., 2012), but
none of previous works considered confidence of
patterns in the graph.
In supervised approaches, various kinds of
models were applied, such as HMM (Jin and Ho,
2009), SVM (Wu et al., 2009) and CRFs (Li et al.,
2010). The downside of supervised methods was
the difficulty of obtaining annotated training data
in practical applications. Also, classifiers trained
</bodyText>
<page confidence="0.982849">
1765
</page>
<bodyText confidence="0.999669333333333">
on one domain often fail to give satisfactory re-
sults when shifted to another domain. Our method
does not rely on annotated training data.
</bodyText>
<sectionHeader confidence="0.932244" genericHeader="method">
3 The First Stage: Sentiment Graph
</sectionHeader>
<subsectionHeader confidence="0.773994">
Walking Algorithm
</subsectionHeader>
<bodyText confidence="0.999852333333333">
In the first stage, we propose a graph-based al-
gorithm called Sentiment Graph Walking to mine
opinion words and opinion targets from reviews.
</bodyText>
<subsectionHeader confidence="0.991247">
3.1 Opinion Pattern Learning for Candidates
Generation
</subsectionHeader>
<bodyText confidence="0.9528205">
For a given sentence, we first obtain its depen-
dency tree. Following (Hu and Liu, 2004; Popescu
and Etzioni, 2005; Qiu et al., 2009), we regard all
adjectives as opinion word candidates (OC) and
all nouns or noun phrases as opinion target can-
didates (TC). A statistic-based method in (Zhu et
al., 2009) is used to detect noun phrases. Then
candidates are replaced by wildcards “&lt;OC&gt;” or
“&lt;TC&gt;”. Figure 1 gives a dependency tree exam-
ple generated by Minipar (Lin, 1998).
</bodyText>
<figureCaption confidence="0.988146">
Figure 1: The dependency tree of the sentence
“The style of the screen is gorgeous”.
</figureCaption>
<bodyText confidence="0.999993125">
We extract two kinds of opinion patterns: “OC-
TC” pattern and “TC-TC” pattern. The “OC-
TC” pattern is the shortest path between an OC
wildcard and a TC wildcard in dependency tree,
which captures opinion relation between an opin-
ion word candidate and an opinion target can-
didate. Similarly, the “TC-TC” pattern cap-
tures opinion relation between two opinion tar-
get candidates.1 Words in opinion patterns are
replaced by their POS tags, and we constrain
that there are at most two words other than
wildcards in each pattern. In Figure 1, there
are two opinion patterns marked out by dash
lines: “&lt;OC&gt;{pred}(VBE){s}&lt;TC&gt;” for the
“OC-TC” type and “&lt;TC&gt;{mod}(Prep){pcomp-
n}&lt;TC&gt;” for the “TC-TC” type. After all pat-
</bodyText>
<footnote confidence="0.497217">
1We do not identify the opinion relation “OC-OC” be-
cause this relation is often unreliable.
</footnote>
<bodyText confidence="0.993868">
terns are generated, we drop those patterns with
frequency lower than a threshold F.
</bodyText>
<subsectionHeader confidence="0.999921">
3.2 Sentiment Graph Construction
</subsectionHeader>
<bodyText confidence="0.9999665">
To model the opinion relations among opinion
words/targets and opinion patterns, a graph named
as Sentiment Graph is constructed, which is a
weighted, directed graph G = (V, E, W), where
</bodyText>
<listItem confidence="0.989394555555556">
• V = {Voc U Vtc U Vp} is the set of vertices in
G, where Voc, Vtc and Vp represent the set of
opinion word candidates, opinion target can-
didates and opinion patterns, respectively.
• E = {Epo UEpt} C {Vp xVoc}U{Vp xVtc}
is the weighted, bi-directional edge set in G,
where Epo and Ept are mutually exclusive
sets of edges connecting opinion word/target
vertices to opinion pattern vertices. Note that
there are no edges between Voc and Vtc.
• W : E → R+ is the weight function which
assigns non-negative weight to each edge.
For each (e : va → vb) E E, where
va, vb E V , the weight function w(va, vb) =
freq(va, vb)/freq(va), where freq(·) is the
frequency of a candidate extracted by opinion
patterns or co-occurrence frequency between
two candidates.
</listItem>
<figureCaption confidence="0.989118">
Figure 2 shows an example of Sentiment Graph.
Figure 2: An example of Sentiment Graph.
</figureCaption>
<subsectionHeader confidence="0.9984375">
3.3 Confidence Estimation by Random
Walking with Restart
</subsectionHeader>
<bodyText confidence="0.999929777777778">
We believe that considering confidence of patterns
can potentially improve the extraction accuracy.
Our intuitive idea is: (i) If an opinion word/target
is with higher confidence, the syntactic patterns
containing this term are more likely to be used to
express customers’ opinion. (ii) If an opinion pat-
tern has higher confidence, terms extracted by this
pattern are more likely to be correct. It’s a rein-
forcement process.
</bodyText>
<figure confidence="0.997550783783784">
gorgeo
us
&lt;OC&gt;
pred s det
is
(VBE)
style
&lt;TC&gt;
mod
the
(Det)
of
(Prep)
pcomp-n
the
(Det)
det
screen
&lt;TC&gt;
&lt;OC&gt;{mod}&lt;TC&gt;
0.8
1
screen display
large
0.4
0.2 0.2
0.2
0.2
&lt;OC&gt;{mod}&lt;TC&gt;{con j}&lt;TC&gt;
0.7
0.33
0.6
nice
0.3
0.4
0.33
0.33
</figure>
<page confidence="0.980574">
1766
</page>
<bodyText confidence="0.99991575">
We use Random Walking with Restart (RWR)
algorithm to implement our idea described above.
Let Moc p denotes the transition matrix from Voc
to Vp, for vo E Voc, vp E Vp, Moc p(vo, vp) =
w(vo, vp). Similarly, we have Mtc p, Mp oc,
Mp tc. Let c denotes confidence vector of candi-
dates so ctoc, cttc and ctp are confidence vectors for
opinion word/target/pattern candidates after walk-
ing t steps. Initially c0oc is uniformly distributed
on a few domain-independent opinion word seeds,
then the following formula are updated iteratively
until cttc and ctoc converge:
</bodyText>
<equation confidence="0.994936166666667">
T t T t ( )
= Moc p x coc + Mtc p x ctc 1
ct+1
oc = (1 � A)MT p oc x ctp + Ac0 oc (2)
t+1T t
ctc = Mp tc x cp ( 3)
</equation>
<bodyText confidence="0.9999798">
where MT is the transpose of matrix M and A is
a small probability of teleporting back to the seed
vertices which prevents us from walking too far
away from the seeds. In the experiments below, A
is set 0.1 empirically.
</bodyText>
<sectionHeader confidence="0.7737305" genericHeader="method">
4 The Second Stage: Refining Extracted
Results Using Self-Learning
</sectionHeader>
<bodyText confidence="0.898795285714286">
At the end of the first stage, we obtain a ranked
list of opinion words and opinion targets, in which
higher ranked terms are more likely to be correct.
Nevertheless, there are still some issues needed to
be addressed:
1) In the target candidate list, some high-
frequency frivolous general nouns such as
“thing” and “people” are also highly ranked.
This is because there exist many opinion ex-
pressions containing non-target terms such as
“good thing”, “nice people”, etc. in reviews.
Due to the lack of ground-truth knowledge
for opinion targets, the false opinion target
problem still remains unsolved.
</bodyText>
<listItem confidence="0.904082555555556">
2) In another aspect, long-tail opinion targets
may have low degree in Sentiment Graph.
Hence their confidence will be low although
they may be extracted by some high qual-
ity patterns. Therefore, the first stage is in-
capable of dealing with the long-tail opinion
target problem.
3) Furthermore, the first stage also extracts
some high-frequency false opinion words
</listItem>
<bodyText confidence="0.985177923076923">
such as “every”, “many”, etc. Many terms
of this kind are introduced by high-frequency
false opinion targets, for there are large
amounts of phrases like “every time” and
“many people”. So this issue is a side effect
of the false opinion target problem.
To address these issues, we exploit a self-
learning strategy. For opinion targets, we use a
semi-supervised binary classifier called target re-
fining classifier to refine target candidates. For
opinion words, we use the classified list of opin-
ion targets to further refine the extracted opinion
word candidates.
</bodyText>
<subsectionHeader confidence="0.966656">
4.1 Opinion Targets Refinement
</subsectionHeader>
<bodyText confidence="0.996517305555556">
There are two keys for opinion target refinement:
(i) How to generate the initial labeled data for tar-
get refining classifier. (ii) How to properly repre-
sent a long-tail opinion target candidate other than
comparing frequency between different targets.
For the first key, it is clearly improper to select
high-confidence targets as positive examples and
choose low-confidence targets as negative exam-
ples2, for there are noise with high confidence and
long-tail targets with low confidence. Fortunately,
a large proportion of general noun noises are the
most frequent words in common texts. Therefore,
we can generate a small domain-independent gen-
eral noun (GN) corpus from large web corpora to
cover some most frequently used general noun ex-
amples. Then labeled examples can be drawn from
the target candidate list and the GN corpus.
For the second key, we utilize opinion words
and opinion patterns with their confidence scores
to represent an opinion target. By this means, a
long-tail opinion target can be determined by its
own contexts, whose weights are learnt from con-
texts of frequent opinion targets. Thus, if a long-
tail opinion target candidate has high contextual
support, it will have higher probability to be found
out in despite of its low frequency.
Creation of General Noun Corpora. 1000
most frequent nouns in Google-1-gram3 were se-
lected as general noun candidates. On the other
hand, we added all nouns in the top three levels of
hyponyms in four WordNet (Miller, 1995) synsets
“object”, “person”, “group” and “measure” into
the GN corpus. Our idea was based on the fact that
a term is more general when it sits in higher level
in the WordNet hierarchy. Then inapplicable can-
didates were discarded and a 3071-word English
</bodyText>
<footnote confidence="0.9969785">
2Note that the “positive” and “negative” here denote opin-
ion targets and non-target terms respectively and they do not
indicate sentiment polarities.
3http://books.google.com/ngrams.
</footnote>
<table confidence="0.4098155">
ct+1
p
</table>
<page confidence="0.952371">
1767
</page>
<bodyText confidence="0.99744205882353">
GN corpus was created. Another Chinese GN cor-
pus with 3493 words was generated in the similar
way from HowNet (Gan and Wong, 2000).
Generation of Labeled Examples. Let T =
{Y+1, Y−1} denotes the initial labeled set, where
N most highly confident target candidates but not
in our GN corpora are regarded as the positive ex-
ample set Y+1, other N terms from GN corpora
which are also top ranked in the target list are se-
lected as the negative example set Y−1. The re-
minder unlabeled candidates are denoted by T *.
Feature Representation for Classifier. Given
T and T * in the form of {(xi, yi)}. For a target
candidate ti, xi = (o1, . . . , on, p1, . . . , pm)T rep-
resents its feature vector, where oj is the opinion
word feature and pk is the opinion pattern feature.
The value of feature is defined as follows,
</bodyText>
<equation confidence="0.997408375">
P
pk freq(ti, oj, pk)
x(oj) = conf(oj) × (4)
freq(oj)
P
oj freq(ti, oj, pk)
x(pk) = conf(pk) × (5)
freq(pk)
</equation>
<bodyText confidence="0.999831636363636">
where conf(·) denotes confidence score estimated
by RWR, freq(·) has the same meaning as in Sec-
tion 3.2. Particularly, freq(ti, oj, pk) represents
the frequency of pattern pk extracting opinion tar-
get ti and opinion word oj.
Target Refinement Classifier: We use support
vector machine as the binary classifier. Hence, the
classification problem can be formulated as to find
a hyperplane &lt; w, b &gt; that separates both labeled
set T and unlabeled set T * with maximum mar-
gin. The optimization goal is tto minimize over
</bodyText>
<equation confidence="0.952382285714286">
(T , , T *, w, b,ξ1, ..., ξn, ξ*1, ..., Sk):
2||w||2 + C
1
subject to : ∀ni=1 : yi[w · xi + b] ≥ 1 − ξi
∀kj=1 : y*j [w · x*j + b] ≥ 1 −ξ*j
∀ni=1 : ξi &gt; 0
∀kj=1 : ξ*j &gt; 0
</equation>
<bodyText confidence="0.9989436">
where yi, y*j ∈ {+1, −1}, xi and x*j represent
feature vectors, C and C* are parameters set by
user. This optimization problem can be imple-
mented by a typical Transductive Support Vector
Machine (TSVM) (Joachims, 1999).
</bodyText>
<subsectionHeader confidence="0.924163">
4.2 Opinion Words Refinement
</subsectionHeader>
<bodyText confidence="0.99997">
We use the classified opinion target results to re-
fine opinion words by the following equation,
</bodyText>
<equation confidence="0.943977">
s(ti)conf(pk)freq(ti, oj, pk)
freq(ti)
</equation>
<bodyText confidence="0.97756925">
where T is the opinion target set in which each el-
ement is classified as positive during opinion tar-
get refinement, s(ti) denotes confidence score ex-
ported by the target refining classifier. Particularly,
</bodyText>
<equation confidence="0.9707975">
freq(ti) = P Ppk freq(ti, oj, pk). A higher
oj
</equation>
<bodyText confidence="0.995755">
score of s(oj) means that candidate oj is more
likely to be an opinion word.
</bodyText>
<sectionHeader confidence="0.999859" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.99214">
5.1 Datasets and Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.99997552631579">
Datasets: We select three real world datasets to
evaluate our approach. The first one is called
Customer Review Dataset (CRD) (Hu and Liu,
2004) which contains reviews on five different
products (represented by D1 to D5) in English.
The second dataset is pre-annotated and published
in COAE084, where two domains of Chinese re-
views are selected. At last, we employ a bench-
mark dataset in (Wang et al., 2011) and named it
as Large. We manually annotated opinion words
and opinion targets as the gold standard. Three
annotators were involved. Firstly, two annotators
were required to annotate out opinion words and
opinion targets in sentences. When conflicts hap-
pened, the third annotator would make the final
judgment. The average Kappa-values of the two
domains were 0.71 for opinion words and 0.66
for opinion targets. Detailed information of our
datasets is shown in Table 1.
</bodyText>
<table confidence="0.996616428571429">
Dataset Domain #Sentences #OW #OT
Large Hotel 10,000 434 1,015
(English)
MP3 10,000 559 1,158
COAE08 Camera 2,075 351 892
(Chinese)
Car 4,783 622 1,179
</table>
<tableCaption confidence="0.987143">
Table 1: The detailed information of datasets. OW
stands for opinion words and OT stands for targets.
</tableCaption>
<footnote confidence="0.364483">
Pre-processing: Firstly, HTML tags are re-
moved from texts. Then Minipar (Lin, 1998)
is used to parse English corpora, and Standford
Parser (Chang et al., 2009) is used for Chinese
4http://ir-china.org.cn/coae2008.html
</footnote>
<equation confidence="0.994177625">
ξ*j
ξi + C*
Xn
i=0
Xk
j=0
Xs(oj) = X
tiET pk
</equation>
<page confidence="0.96684">
1768
</page>
<table confidence="0.999532">
Methods D1 D2 D3 D4 D5 Avg.
P R F P R F P R F P R F P R F F
Hu 0.75 0.82 0.78 0.71 0.79 0.75 0.72 0.76 0.74 0.69 0.82 0.75 0.74 0.80 0.77 0.76
DP 0.87 0.81 0.84 0.90 0.81 0.85 0.90 0.86 0.88 0.81 0.84 0.82 0.92 0.86 0.89 0.86
Zhang 0.83 0.84 0.83 0.86 0.85 0.85 0.86 0.88 0.87 0.80 0.85 0.82 0.86 0.86 0.86 0.85
Ours-Stage1 0.79 0.85 0.82 0.82 0.87 0.84 0.83 0.87 0.85 0.78 0.88 0.83 0.82 0.88 0.85 0.84
Ours-Full 0.86 0.82 0.84 0.88 0.83 0.85 0.89 0.86 0.87 0.83 0.86 0.84 0.89 0.85 0.87 0.86
</table>
<tableCaption confidence="0.9832">
Table 2: Results of opinion target extraction on the Customer Review Dataset.
</tableCaption>
<table confidence="0.999966333333333">
Methods D1 D2 D3 D4 D5 Avg.
P R F P R F P R F P R F P R F F
Hu 0.57 0.75 0.65 0.51 0.76 0.61 0.57 0.73 0.64 0.54 0.62 0.58 0.62 0.67 0.64 0.62
DP 0.64 0.73 0.68 0.57 0.79 0.66 0.65 0.70 0.67 0.61 0.65 0.63 0.70 0.68 0.69 0.67
Ours-Stage1 0.61 0.75 0.67 0.55 0.80 0.65 0.63 0.75 0.68 0.60 0.69 0.64 0.68 0.70 0.69 0.67
Ours-Full 0.64 0.74 0.69 0.59 0.79 0.68 0.66 0.71 0.68 0.65 0.67 0.66 0.72 0.67 0.69 0.68
</table>
<tableCaption confidence="0.999941">
Table 3: Results of opinion word extraction on the Customer Review Dataset.
</tableCaption>
<bodyText confidence="0.994745">
corpora. Stemming and fuzzy matching are also
performed following previous work (Hu and Liu,
2004).
Evaluation Metrics: We evaluate our method
by precision(P), recall(R) and F-measure(F).
</bodyText>
<subsectionHeader confidence="0.996768">
5.2 Our Method vs. the State-of-the-art
</subsectionHeader>
<bodyText confidence="0.999952166666667">
Three state-of-the-art unsupervised methods are
used as competitors to compare with our method.
Hu extracts opinion words/targets by using ad-
jacency rules (Hu and Liu, 2004).
DP uses a bootstrapping algorithm named as
Double Propagation (Qiu et al., 2009).
Zhang is an enhanced version of DP and em-
ploys HITS algorithm (Kleinberg, 1999) to rank
opinion targets (Zhang et al., 2010).
Ours-Full is the full implementation of our
method. We employ SVMlight (Joachims, 1999)
as the target refining classifier. Default parameters
are used except the bias item is set 0.
Ours-Stage1 only uses Sentiment Graph Walk-
ing algorithm which does’t have opinion word and
opinion target refinement.
All of the above approaches use same five
common opinion word seeds. The choice of opin-
ion seeds seems reasonable, as most people can
easily come up with 5 opinion words such as
“good”, “bad”, etc. The performance on five prod-
ucts of CRD dataset is shown in Table 2 and Ta-
ble 3. Zhang does not extract opinion words so
their results for opinion words are not taken into
account. We can see that Ours-Stage] achieves
superior recall but has some loss in precision com-
pared with DP and Zhang. This may be because
the CRD dataset is too small and our statistic-
based method may suffer from data sparseness.
In spite of this, Ours-Full achieves comparable F-
measure with DP, which is a well-designed rule-
based method.
The results on two larger datasets are shown
in Table 4 and Table 5, from which we can have
the following observation: (i) All syntax-based-
methods outperform Hu, showing the importance
of syntactic information in opinion relation identi-
fication. (ii) Ours-Full outperforms the three com-
petitors on all domains provided. (iii) Ours-Stage]
outperforms Zhang, especially in terms of recall.
We believe it benefits from our automatical pattern
learning algorithm. Moreover, Ours-Stage] do
not loss much in precision compared with Zhang,
which indicates the applicability to estimate pat-
tern confidence in Sentiment Graph. (iv) Ours-
Full achieves 4-9% improvement in precision over
the most accurate method, which shows the effec-
tiveness of our second stage.
</bodyText>
<subsectionHeader confidence="0.997632">
5.3 Detailed Discussions
</subsectionHeader>
<bodyText confidence="0.999548333333333">
This section gives several variants of our method
to have a more detailed analysis.
Ours-Bigraph constructs a bi-graph between
opinion words and targets, so opinion patterns
are not included in the graph. Then RWR algo-
rithm is used to only assign confidence to opinion
word/target candidates.
Ours-Stage2 only contains the second stage,
which doesn’t apply Sentiment Graph Walking al-
gorithm. Hence the confidence score conf(·) in
Equations (4) and (5) have no values and they are
set to 1. The initial labeled examples are exactly
the same as Ours-Full. Due to the limitation of
space, we only give analysis on opinion target ex-
traction results in Figure 3.
</bodyText>
<page confidence="0.976588">
1769
</page>
<table confidence="0.990022285714286">
Methods MP3 Hotel Camera Car Avg.
P R F P R F P R F P R F F
Hu 0.53 0.55 0.54 0.55 0.57 0.56 0.63 0.65 0.64 0.62 0.58 0.60 0.58
DP 0.66 0.57 0.61 0.66 0.60 0.63 0.71 0.70 0.70 0.72 0.65 0.68 0.66
Zhang 0.65 0.62 0.63 0.64 0.66 0.65 0.71 0.78 0.74 0.69 0.68 0.68 0.68
Ours-Stage1 0.62 0.68 0.65 0.63 0.71 0.67 0.69 0.80 0.74 0.66 0.71 0.68 0.69
Ours-Full 0.73 0.71 0.72 0.75 0.73 0.74 0.78 0.81 0.79 0.76 0.73 0.74 0.75
</table>
<tableCaption confidence="0.995232">
Table 4: Results of opinion targets extraction on Large and COAE08.
</tableCaption>
<table confidence="0.999569">
Methods MP3 Hotel Camera Car Avg.
P R F P R F P R F P R F F
Hu 0.48 0.65 0.55 0.51 0.68 0.58 0.72 0.74 0.73 0.70 0.71 0.70 0.64
DP 0.58 0.62 0.60 0.60 0.66 0.63 0.80 0.73 0.76 0.79 0.71 0.75 0.68
Ours-Stage1 0.59 0.69 0.64 0.61 0.71 0.66 0.79 0.78 0.78 0.77 0.77 0.77 0.71
Ours-Full 0.64 0.67 0.65 0.67 0.69 0.68 0.82 0.78 0.80 0.80 0.76 0.78 0.73
</table>
<tableCaption confidence="0.997249">
Table 5: Results of opinion words extraction on Large and COAE08.
</tableCaption>
<figureCaption confidence="0.859004">
Figure 3: Opinion target extraction results.
</figureCaption>
<subsectionHeader confidence="0.613322">
5.3.1 The Effect of Sentiment Graph Walking
</subsectionHeader>
<bodyText confidence="0.999675352941176">
We can see that our graph-based methods (Ours-
Bigraph and Ours-Stage]) achieve higher recall
than Zhang. By learning patterns automatically,
our method captures opinion relations more ef-
ficiently. Also, Ours-Stage] outperforms Ours-
Bigraph, especially in precision. We believe it is
because Ours-Stage] estimated confidence of pat-
terns so false opinion relations are reduced. There-
fore, the consideration of pattern confidence is
beneficial as expected, which alleviates the false
opinion relation problem. On another hand, we
find that Ours-Stage2 has much worse perfor-
mance than Ours-Full. This shows the effective-
ness of Sentiment Graph Walking algorithm since
the confidence scores estimated in the first stage
are indispensable and indeed key to the learning
of the second stage.
</bodyText>
<subsectionHeader confidence="0.813777">
5.3.2 The Effect of Self-Learning
</subsectionHeader>
<bodyText confidence="0.999283466666667">
Figure 4 shows the average Precision@N curve of
four domains on opinion target extraction. Ours-
GN-Only is implemented by only removing 50
initial negative examples found by our GN cor-
pora. We can see that the GN corpora work quite
well, which find out most top-ranked false opin-
ion targets. At the same time, Ours-Full has much
better performance than Ours-GN-Only which in-
dicates that Ours-Full can filter out more noises
other than the initial negative examples. There-
fore, our self-learning strategy alleviates the short-
coming of false opinion target problem. More-
over, Table 5 shows that the performance of opin-
ion word extraction is also improved based on the
classified results of opinion targets.
</bodyText>
<figureCaption confidence="0.8077255">
Figure 4: The average precision@N curve of the
four domains on opinion target extraction.
</figureCaption>
<page confidence="0.989817">
1770
</page>
<note confidence="0.969698">
ID Pattern Example #Ext. Conf. PrO PrT
#1 &lt;OC&gt;{mod}&lt;TC&gt; it has a clear screen 7344 0.3938 0.59 0.66
#2 &lt;TC&gt;{subj}&lt;OC&gt; the sound quality is excellent 2791 0.0689 0.62 0.70
#3 &lt;TC&gt;{conj}&lt;TC&gt; the size and weight make it convenient 3620 0.0208 N/A 0.67
#4 &lt;TC&gt;{subj}&lt;TC&gt; the button layout is a simplistic plus 1615 0.0096 N/A 0.67
#5 &lt;OC&gt;{pnmod}&lt;TC&gt; the buttons easier to use 128 0.0014 0.61 0.34
#6 &lt;TC&gt;{subj}(V){s}(VBE){subj}&lt;OC&gt; software provided is simple 189 0.0015 0.54 0.33
#7 &lt;OC&gt;{mod}(Prep){pcomp-c}(V){obj}&lt;TC&gt; great for playing audible books 211 0.0013 0.43 0.48
</note>
<figureCaption confidence="0.6221572">
Table 6: Examples of English patterns. #Ext. represent number of terms extracted, Conf. denotes confi-
dence score estimated by RWR and PrO/PrT stand for precisions of extraction on opinion words/targets
of a pattern respectively. Opinion words in examples are in bold and opinion targets are in italic.
Figure 5 gives the recall of long-tail opinion
targets5 extracted, where Ours-Full is shown to
have much better performance than Ours-Stage1
and the three competitors. This observation proves
that our method can improve the limitation of
long-tail opinion target problem.
Figure 5: The recall of long-tail opinion targets.
</figureCaption>
<subsectionHeader confidence="0.91218">
5.3.3 Analysis on Opinion Patterns
</subsectionHeader>
<bodyText confidence="0.999785411764706">
Table 6 shows some examples of opinion pattern
and their extraction accuracy on MP3 reviews in
the first stage. Pattern #1 and #2 are the two
most high-confidence opinion patterns of “OC-
TC” type, and Pattern #3 and #4 demonstrate two
typical “TC-TC” patterns. As these patterns ex-
tract too many terms, the overall precision is very
low. We give Precision@400 of them, which is
more meaningful because only top listed terms
in the extracted results are regarded as opinion
targets. Pattern #5 and #6 have high precision
on opinion words but low precision on opinion
targets. This observation demonstrates the false
opinion target problem. Pattern #7 is a pattern ex-
ample that extracts many false opinion relations
and it has low precision for both opinion words
and opinion targets. We can see that Pattern #7 has
</bodyText>
<footnote confidence="0.947622">
5Since there is no explicit definition for the notion “long-
tail”, we conservatively regard 60% opinion targets with the
lowest frequency as the “long-tail” terms.
</footnote>
<bodyText confidence="0.9977625">
a lower confidence compared with Pattern #5 and
#6 although it extracts more words. It’s because
it has a low probability of walking from opinion
seeds to this pattern. This further proves that our
method can reduce the confidence of low-quality
patterns.
</bodyText>
<subsectionHeader confidence="0.974341">
5.3.4 Sensitivity of Parameters
</subsectionHeader>
<bodyText confidence="0.999789444444444">
Finally, we study the sensitivity of parameters
when recall is fixed at 0.70. Figure 6 shows the
precision curves at different N initial training ex-
amples and F filtering frequency. We can see that
the performance saturates when N is set to 50 and
it does not vary much under different F, showing
the robustness of our method. We thus set N to
50, and F to 3 for CRD, 5 for COAE08 and 10 for
Large accordingly.
</bodyText>
<figureCaption confidence="0.994474">
Figure 6: Influence of parameters.
</figureCaption>
<page confidence="0.98335">
1771
</page>
<sectionHeader confidence="0.99121" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999963466666667">
This paper proposes a novel two-stage framework
for mining opinion words and opinion targets. In
the first stage, we propose a Sentiment Graph
Walking algorithm, which incorporates syntactic
patterns in a Sentiment Graph to improve the ex-
traction performance. In the second stage, we pro-
pose a self-learning method to refine the result of
first stage. The experimental results show that our
method achieves superior performance over state-
of-the-art unsupervised methods.
We further notice that opinion words are not
limited to adjectives but can also be other type of
word such as verbs or nouns. Identifying all kinds
of opinion words is a more challenging task. We
plan to study this problem in our future work.
</bodyText>
<sectionHeader confidence="0.978716" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999839307692308">
Thanks to Prof. Yulan He for her insightful
advices. This work was supported by the Na-
tional Natural Science Foundation of China (No.
61070106, No. 61272332 and No. 61202329),
the National High Technology Development 863
Program of China (No. 2012AA011102), the
National Basic Research Program of China (No.
2012CB316300), Tsinghua National Laboratory
for Information Science and Technology (TNList)
Cross-discipline Foundation and the Opening
Project of Beijing Key Laboratory of Inter-
net Culture and Digital Dissemination Research
(ICDD201201).
</bodyText>
<sectionHeader confidence="0.998553" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997490513157895">
Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, and
Christopher D. Manning. 2009. Discriminative
reordering with chinese grammatical relations fea-
tures. In Proceedings of the Third Workshop on Syn-
tax and Structure in Statistical Translation, SSST
’09, pages 51–59.
Sajib Dasgupta and Vincent Ng. 2009. Mine the easy,
classify the hard: a semi-supervised approach to au-
tomatic sentiment classification. In Proceedings of
the Joint Conference of the 47th Annual Meeting of
the ACL and the 4th International Joint Conference
on Natural Language Processing of the AFNLP: Vol-
ume 2 - Volume 2, ACL ’09, pages 701–709.
Kok Wee Gan and Ping Wai Wong. 2000. Anno-
tating information structures in chinese texts using
hownet. In Proceedings of the second workshop on
Chinese language processing: held in conjunction
with the 38th Annual Meeting of the Association for
Computational Linguistics - Volume 12, CLPW ’00,
pages 85–92, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Ahmed Hassan and Dragomir Radev. 2010. Identify-
ing text polarity using random walks. In Proceed-
ings of the 48th Annual Meeting of the Association
for Computational Linguistics, ACL ’10, pages 395–
403, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, KDD ’04, pages
168–177, New York, NY, USA. ACM.
Valentin Jijkoun, Maarten de Rijke, and Wouter
Weerkamp. 2010. Generating focused topic-
specific sentiment lexicons. In Proceedings of the
48th Annual Meeting of the Association for Com-
putational Linguistics, ACL ’10, pages 585–594,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Wei Jin and Hung Hay Ho. 2009. A novel lexical-
ized hmm-based learning framework for web opin-
ion mining. In Proceedings of the 26th Annual Inter-
national Conference on Machine Learning, ICML
’09, pages 465–472.
Thorsten Joachims. 1999. Transductive inference for
text classification using support vector machines. In
Proceedings of the Sixteenth International Confer-
ence on Machine Learning, pages 200–209.
Jason Kessler and Nicolas Nicolov. 2009. Targeting
sentiment expressions through supervised ranking
of linguistic configurations. In Proceedings of the
Third International AAAI Conference on Weblogs
and Social Media.
Jon M. Kleinberg. 1999. Authoritative sources in a
hyperlinked environment. J. ACM, 46(5):604–632,
September.
Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto.
2007. Extracting aspect-evaluation and aspect-
of relations in opinion mining. In Proceedings
of the 2007 Joint Conference on Empirical Meth-
ods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL), pages 1065–1074, June.
Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu,
Ying-Ju Xia, Shu Zhang, and Hao Yu. 2010.
Structure-aware review mining and summarization.
In Proceedings of the 23rd International Conference
on Computational Linguistics, COLING ’10, pages
653–661, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Fangtao Li, Sinno Jialin Pan, Ou Jin, Qiang Yang, and
Xiaoyan Zhu. 2012. Cross-domain co-extraction of
sentiment and topic lexicons. In Proceedings of the
50th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
410–419, July.
</reference>
<page confidence="0.853978">
1772
</page>
<reference confidence="0.999673984615385">
Dekang Lin. 1998. Dependency-based evaluation of
minipar. In Workshop on Evaluation of Parsing Sys-
tems at ICLRE.
Kang Liu, Liheng Xu, and Jun Zhao. 2012. Opin-
ion target extraction using word-based translation
model. In Proceedings of the 2012 Joint Confer-
ence on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning, EMNLP-CoNLL ’12, pages 1346–1356,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
George A. Miller. 1995. Wordnet: a lexical database
for english. Commun. ACM, 38(11):39–41.
Ana-Maria Popescu and Oren Etzioni. 2005. Extract-
ing product features and opinions from reviews. In
Proceedings of the conference on Human Language
Technology and Empirical Methods in Natural Lan-
guage Processing, HLT ’05, pages 339–346.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2009. Expanding domain sentiment lexicon through
double propagation. In Proceedings of the 21st in-
ternational jont conference on Artifical intelligence,
IJCAI’09, pages 1199–1204.
Ellen Riloff and Janyce Wiebe. 2003. Learning ex-
traction patterns for subjective expressions. In Pro-
ceedings of the 2003 conference on Empirical meth-
ods in natural language processing, EMNLP ’03,
pages 105–112, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Hongning Wang, Yue Lu, and ChengXiang Zhai. 2011.
Latent aspect rating analysis without aspect key-
word supervision. In Proceedings of the 17th ACM
SIGKDD international conference on Knowledge
discovery and data mining, KDD ’11, pages 618–
626, New York, NY, USA. ACM.
Janyce Wiebe and Ellen Riloff. 2005. Creating subjec-
tive and objective sentence classifiers from unanno-
tated texts. In Proceedings of the 6th international
conference on Computational Linguistics and Intel-
ligent Text Processing, CICLing’05, pages 486–497.
Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu.
2009. Phrase dependency parsing for opinion min-
ing. In Proceedings of the 2009 Conference on Em-
pirical Methods in Natural Language Processing:
Volume 3 - Volume 3, pages 1533–1541.
Liheng Xu, Kang Liu, Siwei Lai, Yubo Chen, and Jun
Zhao. 2013. Walk and learn: A two-stage approach
for opinion words and opinion targets co-extraction.
In Proceedings of the 22nd International World Wide
Web Conference, WWW ’13.
Lei Zhang, Bing Liu, Suk Hwan Lim, and Eamonn
O’Brien-Strain. 2010. Extracting and ranking prod-
uct features in opinion documents. In Proceedings
of the 23rd International Conference on Computa-
tional Linguistics: Posters, pages 1462–1470.
Jingbo Zhu, Huizhen Wang, Benjamin K. Tsou, and
Muhua Zhu. 2009. Multi-aspect opinion polling
from textual reviews. In Proceedings of the 18th
ACM conference on Information and knowledge
management, CIKM ’09, pages 1799–1802.
Li Zhuang, Feng Jing, and Xiao-Yan Zhu. 2006.
Movie review mining and summarization. In Pro-
ceedings of the 15th ACM international conference
on Information and knowledge management, CIKM
’06, pages 43–50.
</reference>
<page confidence="0.984057">
1773
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.514141">
<title confidence="0.999676">Mining Opinion Words and Opinion Targets in a Two-Stage Framework</title>
<author confidence="0.975608">Liheng Xu</author>
<author confidence="0.975608">Kang Liu</author>
<author confidence="0.975608">Siwei Lai</author>
<author confidence="0.975608">Yubo Chen</author>
<author confidence="0.975608">Jun</author>
<affiliation confidence="0.996686">National Laboratory of Pattern</affiliation>
<address confidence="0.564281">Institute of Automation, Chinese Academy of Sciences, Beijing, 100190,</address>
<email confidence="0.923223">kliu,swlai,ybchen,</email>
<abstract confidence="0.998799047619048">This paper proposes a novel two-stage method for mining opinion words and opinion targets. In the first stage, we a Graph Walking algorithm, which naturally incorporates syntactic patterns in a Sentiment Graph to extract opinion word/target candidates. Then random walking is employed to estimate confidence of candidates, which improves extraction accuracy by considering confidence of patterns. In the second stage, we adopt a self-learning strategy to refine the results from the first stage, especially for filtering out high-frequency noise terms and capturing the long-tail terms, which are not investigated by previous methods. The experimental results on three real world datasets demonstrate the effectiveness of our approach compared with stateof-the-art unsupervised methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Pi-Chuan Chang</author>
<author>Huihsin Tseng</author>
<author>Dan Jurafsky</author>
<author>Christopher D Manning</author>
</authors>
<title>Discriminative reordering with chinese grammatical relations features.</title>
<date>2009</date>
<booktitle>In Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation, SSST ’09,</booktitle>
<pages>51--59</pages>
<contexts>
<context position="20545" citStr="Chang et al., 2009" startWordPosition="3360" endWordPosition="3363">hird annotator would make the final judgment. The average Kappa-values of the two domains were 0.71 for opinion words and 0.66 for opinion targets. Detailed information of our datasets is shown in Table 1. Dataset Domain #Sentences #OW #OT Large Hotel 10,000 434 1,015 (English) MP3 10,000 559 1,158 COAE08 Camera 2,075 351 892 (Chinese) Car 4,783 622 1,179 Table 1: The detailed information of datasets. OW stands for opinion words and OT stands for targets. Pre-processing: Firstly, HTML tags are removed from texts. Then Minipar (Lin, 1998) is used to parse English corpora, and Standford Parser (Chang et al., 2009) is used for Chinese 4http://ir-china.org.cn/coae2008.html ξ*j ξi + C* Xn i=0 Xk j=0 Xs(oj) = X tiET pk 1768 Methods D1 D2 D3 D4 D5 Avg. P R F P R F P R F P R F P R F F Hu 0.75 0.82 0.78 0.71 0.79 0.75 0.72 0.76 0.74 0.69 0.82 0.75 0.74 0.80 0.77 0.76 DP 0.87 0.81 0.84 0.90 0.81 0.85 0.90 0.86 0.88 0.81 0.84 0.82 0.92 0.86 0.89 0.86 Zhang 0.83 0.84 0.83 0.86 0.85 0.85 0.86 0.88 0.87 0.80 0.85 0.82 0.86 0.86 0.86 0.85 Ours-Stage1 0.79 0.85 0.82 0.82 0.87 0.84 0.83 0.87 0.85 0.78 0.88 0.83 0.82 0.88 0.85 0.84 Ours-Full 0.86 0.82 0.84 0.88 0.83 0.85 0.89 0.86 0.87 0.83 0.86 0.84 0.89 0.85 0.87 0.</context>
</contexts>
<marker>Chang, Tseng, Jurafsky, Manning, 2009</marker>
<rawString>Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, and Christopher D. Manning. 2009. Discriminative reordering with chinese grammatical relations features. In Proceedings of the Third Workshop on Syntax and Structure in Statistical Translation, SSST ’09, pages 51–59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sajib Dasgupta</author>
<author>Vincent Ng</author>
</authors>
<title>Mine the easy, classify the hard: a semi-supervised approach to automatic sentiment classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume</booktitle>
<volume>2</volume>
<pages>701--709</pages>
<contexts>
<context position="4287" citStr="Dasgupta and Ng, 2009" startWordPosition="660" endWordPosition="663">gh frequency (Hu and Liu, 2004; Popescu and Etzioni, 2005; Qiu et al., 2009; Zhu et al., 2009), and they often have difficulty in identifying the infrequent or long-tail opinion targets. 1764 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1764–1773, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics To address the problems stated above, this paper proposes a two-stage framework for mining opinion words and opinion targets. The underlying motivation is analogous to the novel idea “Mine the Easy, Classify the Hard” (Dasgupta and Ng, 2009). In our first stage, we propose a Sentiment Graph Walking algorithm to cope with the false opinion relation problem, which mines easy cases of opinion words/targets. We speculate that it may be helpful to introduce a confidence score for each pattern. Concretely, we create a Sentiment Graph to model opinion relations among opinion word/target/pattern candidates and apply random walking to estimate confidence of them. Thus, confidence of pattern is considered in a unified process. Patterns that often extract false opinion relations will have low confidence, and terms introduced by low-confiden</context>
</contexts>
<marker>Dasgupta, Ng, 2009</marker>
<rawString>Sajib Dasgupta and Vincent Ng. 2009. Mine the easy, classify the hard: a semi-supervised approach to automatic sentiment classification. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2 - Volume 2, ACL ’09, pages 701–709.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kok Wee Gan</author>
<author>Ping Wai Wong</author>
</authors>
<title>Annotating information structures in chinese texts using hownet.</title>
<date>2000</date>
<booktitle>In Proceedings of the second workshop on Chinese language processing: held in conjunction with the 38th Annual Meeting of the Association for Computational Linguistics - Volume 12, CLPW ’00,</booktitle>
<pages>85--92</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="17016" citStr="Gan and Wong, 2000" startWordPosition="2731" endWordPosition="2734">f hyponyms in four WordNet (Miller, 1995) synsets “object”, “person”, “group” and “measure” into the GN corpus. Our idea was based on the fact that a term is more general when it sits in higher level in the WordNet hierarchy. Then inapplicable candidates were discarded and a 3071-word English 2Note that the “positive” and “negative” here denote opinion targets and non-target terms respectively and they do not indicate sentiment polarities. 3http://books.google.com/ngrams. ct+1 p 1767 GN corpus was created. Another Chinese GN corpus with 3493 words was generated in the similar way from HowNet (Gan and Wong, 2000). Generation of Labeled Examples. Let T = {Y+1, Y−1} denotes the initial labeled set, where N most highly confident target candidates but not in our GN corpora are regarded as the positive example set Y+1, other N terms from GN corpora which are also top ranked in the target list are selected as the negative example set Y−1. The reminder unlabeled candidates are denoted by T *. Feature Representation for Classifier. Given T and T * in the form of {(xi, yi)}. For a target candidate ti, xi = (o1, . . . , on, p1, . . . , pm)T represents its feature vector, where oj is the opinion word feature and</context>
</contexts>
<marker>Gan, Wong, 2000</marker>
<rawString>Kok Wee Gan and Ping Wai Wong. 2000. Annotating information structures in chinese texts using hownet. In Proceedings of the second workshop on Chinese language processing: held in conjunction with the 38th Annual Meeting of the Association for Computational Linguistics - Volume 12, CLPW ’00, pages 85–92, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Hassan</author>
<author>Dragomir Radev</author>
</authors>
<title>Identifying text polarity using random walks.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>395--403</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="8428" citStr="Hassan and Radev, 2010" startWordPosition="1285" endWordPosition="1288">erns as contextual clues. Our approach is similar to (Wiebe and Riloff, 2005) and (Xu et al., 2013), all of which apply syntactic pattern learning and adopt self-learning strategy. However, the task of (Wiebe and Riloff, 2005) was to classify sentiment orientations in sentence level, while ours needs to extract more detailed information in term level. In addition, our method extends (Xu et al., 2013), and we give a more complete and in-depth analysis on the aforementioned problems in the first section. There were also many works employed graphbased method (Li et al., 2012; Zhang et al., 2010; Hassan and Radev, 2010; Liu et al., 2012), but none of previous works considered confidence of patterns in the graph. In supervised approaches, various kinds of models were applied, such as HMM (Jin and Ho, 2009), SVM (Wu et al., 2009) and CRFs (Li et al., 2010). The downside of supervised methods was the difficulty of obtaining annotated training data in practical applications. Also, classifiers trained 1765 on one domain often fail to give satisfactory results when shifted to another domain. Our method does not rely on annotated training data. 3 The First Stage: Sentiment Graph Walking Algorithm In the first stag</context>
</contexts>
<marker>Hassan, Radev, 2010</marker>
<rawString>Ahmed Hassan and Dragomir Radev. 2010. Identifying text polarity using random walks. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 395– 403, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’04,</booktitle>
<pages>168--177</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="3695" citStr="Hu and Liu, 2004" startWordPosition="569" endWordPosition="572">ase “wonderful time” can be matched by an opinion pattern “Adj-{mod}-Noun”, which is widely used in previous works (Popescu and Etzioni, 2005; Qiu et al., 2009). As can be seen, this phrase does express a positive opinion but unfortunately “time” is not a valid opinion target for most domains such as MP3. Thus, false opinion targets are extracted. Due to the lack of ground-truth knowledge for opinion targets, non-target terms introduced in this way can be hardly filtered out. Long-tail Opinion Targets: We further notice that previous works prone to extract opinion targets with high frequency (Hu and Liu, 2004; Popescu and Etzioni, 2005; Qiu et al., 2009; Zhu et al., 2009), and they often have difficulty in identifying the infrequent or long-tail opinion targets. 1764 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1764–1773, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics To address the problems stated above, this paper proposes a two-stage framework for mining opinion words and opinion targets. The underlying motivation is analogous to the novel idea “Mine the Easy, Classify the Hard” (Dasgupta and Ng, 2009). In our</context>
<context position="6637" citStr="Hu and Liu (2004)" startWordPosition="1022" endWordPosition="1025">opinion words/targets mining task (Section 3). • We adopt a self-learning method for refining opinion words/targets generated by Sentiment Graph Walking. Specifically, it can remove high-frequency noise terms and capture longtail opinion targets in corpora (Section 4). • We perform experiments on three real world datasets, which demonstrate the effectiveness of our method compared with state-of-the-art unsupervised methods (Section 5). 2 Related Work In opinion words/targets mining task, most unsupervised methods rely on identifying opinion relations between opinion words and opinion targets. Hu and Liu (2004) proposed an association mining technique to extract opinion words/targets. The simple heuristic rules they used may potentially introduce many false opinion words/targets. To identify opinion relations more precisely, subsequent research work exploited syntax information. Popescu and Etzioni (2005) used manually complied syntactic patterns and Pointwise Mutual Information (PMI) to extract opinion words/targets. Qiu et al. (2009) proposed a bootstrapping framework called Double Propagation which introduced eight heuristic syntactic rules. While manually defining syntactic patterns could be tim</context>
<context position="9294" citStr="Hu and Liu, 2004" startWordPosition="1426" endWordPosition="1429">side of supervised methods was the difficulty of obtaining annotated training data in practical applications. Also, classifiers trained 1765 on one domain often fail to give satisfactory results when shifted to another domain. Our method does not rely on annotated training data. 3 The First Stage: Sentiment Graph Walking Algorithm In the first stage, we propose a graph-based algorithm called Sentiment Graph Walking to mine opinion words and opinion targets from reviews. 3.1 Opinion Pattern Learning for Candidates Generation For a given sentence, we first obtain its dependency tree. Following (Hu and Liu, 2004; Popescu and Etzioni, 2005; Qiu et al., 2009), we regard all adjectives as opinion word candidates (OC) and all nouns or noun phrases as opinion target candidates (TC). A statistic-based method in (Zhu et al., 2009) is used to detect noun phrases. Then candidates are replaced by wildcards “&lt;OC&gt;” or “&lt;TC&gt;”. Figure 1 gives a dependency tree example generated by Minipar (Lin, 1998). Figure 1: The dependency tree of the sentence “The style of the screen is gorgeous”. We extract two kinds of opinion patterns: “OCTC” pattern and “TC-TC” pattern. The “OCTC” pattern is the shortest path between an OC</context>
<context position="19397" citStr="Hu and Liu, 2004" startWordPosition="3172" endWordPosition="3175">lts to refine opinion words by the following equation, s(ti)conf(pk)freq(ti, oj, pk) freq(ti) where T is the opinion target set in which each element is classified as positive during opinion target refinement, s(ti) denotes confidence score exported by the target refining classifier. Particularly, freq(ti) = P Ppk freq(ti, oj, pk). A higher oj score of s(oj) means that candidate oj is more likely to be an opinion word. 5 Experiments 5.1 Datasets and Evaluation Metrics Datasets: We select three real world datasets to evaluate our approach. The first one is called Customer Review Dataset (CRD) (Hu and Liu, 2004) which contains reviews on five different products (represented by D1 to D5) in English. The second dataset is pre-annotated and published in COAE084, where two domains of Chinese reviews are selected. At last, we employ a benchmark dataset in (Wang et al., 2011) and named it as Large. We manually annotated opinion words and opinion targets as the gold standard. Three annotators were involved. Firstly, two annotators were required to annotate out opinion words and opinion targets in sentences. When conflicts happened, the third annotator would make the final judgment. The average Kappa-values </context>
<context position="21808" citStr="Hu and Liu, 2004" startWordPosition="3617" endWordPosition="3620">on on the Customer Review Dataset. Methods D1 D2 D3 D4 D5 Avg. P R F P R F P R F P R F P R F F Hu 0.57 0.75 0.65 0.51 0.76 0.61 0.57 0.73 0.64 0.54 0.62 0.58 0.62 0.67 0.64 0.62 DP 0.64 0.73 0.68 0.57 0.79 0.66 0.65 0.70 0.67 0.61 0.65 0.63 0.70 0.68 0.69 0.67 Ours-Stage1 0.61 0.75 0.67 0.55 0.80 0.65 0.63 0.75 0.68 0.60 0.69 0.64 0.68 0.70 0.69 0.67 Ours-Full 0.64 0.74 0.69 0.59 0.79 0.68 0.66 0.71 0.68 0.65 0.67 0.66 0.72 0.67 0.69 0.68 Table 3: Results of opinion word extraction on the Customer Review Dataset. corpora. Stemming and fuzzy matching are also performed following previous work (Hu and Liu, 2004). Evaluation Metrics: We evaluate our method by precision(P), recall(R) and F-measure(F). 5.2 Our Method vs. the State-of-the-art Three state-of-the-art unsupervised methods are used as competitors to compare with our method. Hu extracts opinion words/targets by using adjacency rules (Hu and Liu, 2004). DP uses a bootstrapping algorithm named as Double Propagation (Qiu et al., 2009). Zhang is an enhanced version of DP and employs HITS algorithm (Kleinberg, 1999) to rank opinion targets (Zhang et al., 2010). Ours-Full is the full implementation of our method. We employ SVMlight (Joachims, 1999)</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’04, pages 168–177, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valentin Jijkoun</author>
<author>Maarten de Rijke</author>
<author>Wouter Weerkamp</author>
</authors>
<title>Generating focused topicspecific sentiment lexicons.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>585--594</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Jijkoun, de Rijke, Weerkamp, 2010</marker>
<rawString>Valentin Jijkoun, Maarten de Rijke, and Wouter Weerkamp. 2010. Generating focused topicspecific sentiment lexicons. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 585–594, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Jin</author>
<author>Hung Hay Ho</author>
</authors>
<title>A novel lexicalized hmm-based learning framework for web opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of the 26th Annual International Conference on Machine Learning, ICML ’09,</booktitle>
<pages>465--472</pages>
<contexts>
<context position="5260" citStr="Jin and Ho, 2009" startWordPosition="814" endWordPosition="817">didates and apply random walking to estimate confidence of them. Thus, confidence of pattern is considered in a unified process. Patterns that often extract false opinion relations will have low confidence, and terms introduced by low-confidence patterns will also have low confidence accordingly. This could potentially improve the extraction accuracy. In the second stage, we identify the hard cases, which aims to filter out false opinion targets and extract long-tail opinion targets. Previous supervised methods have been shown to achieve stateof-the-art results for this task (Wu et al., 2009; Jin and Ho, 2009; Li et al., 2010). However, the big challenge for fully supervised method is the lack of annotated training data. Therefore, we adopt a self-learning strategy. Specifically, we employ a semi-supervised classifier to refine the target results from the first stage, which uses some highly confident target candidates as the initial labeled examples. Then opinion words are also refined. Our main contributions are as follows: • We propose a Sentiment Graph Walking algorithm to mine opinion words and opinion targets from reviews, which naturally incorporates confidence of syntactic pattern in a grap</context>
<context position="8618" citStr="Jin and Ho, 2009" startWordPosition="1317" endWordPosition="1320">ask of (Wiebe and Riloff, 2005) was to classify sentiment orientations in sentence level, while ours needs to extract more detailed information in term level. In addition, our method extends (Xu et al., 2013), and we give a more complete and in-depth analysis on the aforementioned problems in the first section. There were also many works employed graphbased method (Li et al., 2012; Zhang et al., 2010; Hassan and Radev, 2010; Liu et al., 2012), but none of previous works considered confidence of patterns in the graph. In supervised approaches, various kinds of models were applied, such as HMM (Jin and Ho, 2009), SVM (Wu et al., 2009) and CRFs (Li et al., 2010). The downside of supervised methods was the difficulty of obtaining annotated training data in practical applications. Also, classifiers trained 1765 on one domain often fail to give satisfactory results when shifted to another domain. Our method does not rely on annotated training data. 3 The First Stage: Sentiment Graph Walking Algorithm In the first stage, we propose a graph-based algorithm called Sentiment Graph Walking to mine opinion words and opinion targets from reviews. 3.1 Opinion Pattern Learning for Candidates Generation For a give</context>
</contexts>
<marker>Jin, Ho, 2009</marker>
<rawString>Wei Jin and Hung Hay Ho. 2009. A novel lexicalized hmm-based learning framework for web opinion mining. In Proceedings of the 26th Annual International Conference on Machine Learning, ICML ’09, pages 465–472.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Transductive inference for text classification using support vector machines.</title>
<date>1999</date>
<booktitle>In Proceedings of the Sixteenth International Conference on Machine Learning,</booktitle>
<pages>200--209</pages>
<contexts>
<context position="18708" citStr="Joachims, 1999" startWordPosition="3061" endWordPosition="3062">he binary classifier. Hence, the classification problem can be formulated as to find a hyperplane &lt; w, b &gt; that separates both labeled set T and unlabeled set T * with maximum margin. The optimization goal is tto minimize over (T , , T *, w, b,ξ1, ..., ξn, ξ*1, ..., Sk): 2||w||2 + C 1 subject to : ∀ni=1 : yi[w · xi + b] ≥ 1 − ξi ∀kj=1 : y*j [w · x*j + b] ≥ 1 −ξ*j ∀ni=1 : ξi &gt; 0 ∀kj=1 : ξ*j &gt; 0 where yi, y*j ∈ {+1, −1}, xi and x*j represent feature vectors, C and C* are parameters set by user. This optimization problem can be implemented by a typical Transductive Support Vector Machine (TSVM) (Joachims, 1999). 4.2 Opinion Words Refinement We use the classified opinion target results to refine opinion words by the following equation, s(ti)conf(pk)freq(ti, oj, pk) freq(ti) where T is the opinion target set in which each element is classified as positive during opinion target refinement, s(ti) denotes confidence score exported by the target refining classifier. Particularly, freq(ti) = P Ppk freq(ti, oj, pk). A higher oj score of s(oj) means that candidate oj is more likely to be an opinion word. 5 Experiments 5.1 Datasets and Evaluation Metrics Datasets: We select three real world datasets to evalua</context>
<context position="22408" citStr="Joachims, 1999" startWordPosition="3710" endWordPosition="3711"> and Liu, 2004). Evaluation Metrics: We evaluate our method by precision(P), recall(R) and F-measure(F). 5.2 Our Method vs. the State-of-the-art Three state-of-the-art unsupervised methods are used as competitors to compare with our method. Hu extracts opinion words/targets by using adjacency rules (Hu and Liu, 2004). DP uses a bootstrapping algorithm named as Double Propagation (Qiu et al., 2009). Zhang is an enhanced version of DP and employs HITS algorithm (Kleinberg, 1999) to rank opinion targets (Zhang et al., 2010). Ours-Full is the full implementation of our method. We employ SVMlight (Joachims, 1999) as the target refining classifier. Default parameters are used except the bias item is set 0. Ours-Stage1 only uses Sentiment Graph Walking algorithm which does’t have opinion word and opinion target refinement. All of the above approaches use same five common opinion word seeds. The choice of opinion seeds seems reasonable, as most people can easily come up with 5 opinion words such as “good”, “bad”, etc. The performance on five products of CRD dataset is shown in Table 2 and Table 3. Zhang does not extract opinion words so their results for opinion words are not taken into account. We can s</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Transductive inference for text classification using support vector machines. In Proceedings of the Sixteenth International Conference on Machine Learning, pages 200–209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Kessler</author>
<author>Nicolas Nicolov</author>
</authors>
<title>Targeting sentiment expressions through supervised ranking of linguistic configurations.</title>
<date>2009</date>
<booktitle>In Proceedings of the Third International AAAI Conference on Weblogs and Social Media.</booktitle>
<contexts>
<context position="2857" citStr="Kessler and Nicolov, 2009" startWordPosition="435" endWordPosition="438">syntactic pattern “Adj-{mod}-Noun”, which captures the opinion relation between them. Although previous works have shown the effectiveness of syntactic patterns for this task (Qiu et al., 2009; Zhang et al., 2010), they still have some limitations as follows. False Opinion Relations: As an example, the phrase “everyday at school” can be matched by a pattern “Adj-{mod}-(Prep)-{pcomp-n}-Noun”, but it doesn’t bear any sentiment orientation. We call such relations that match opinion patterns but express no opinion false opinion relations. Previous pattern learning algorithms (Zhuang et al., 2006; Kessler and Nicolov, 2009; Jijkoun et al., 2010) often extract opinion patterns by frequency. However, some high-frequency syntactic patterns can have very poor precision (Kessler and Nicolov, 2009). False Opinion Targets: In another case, the phrase “wonderful time” can be matched by an opinion pattern “Adj-{mod}-Noun”, which is widely used in previous works (Popescu and Etzioni, 2005; Qiu et al., 2009). As can be seen, this phrase does express a positive opinion but unfortunately “time” is not a valid opinion target for most domains such as MP3. Thus, false opinion targets are extracted. Due to the lack of ground-tr</context>
</contexts>
<marker>Kessler, Nicolov, 2009</marker>
<rawString>Jason Kessler and Nicolas Nicolov. 2009. Targeting sentiment expressions through supervised ranking of linguistic configurations. In Proceedings of the Third International AAAI Conference on Weblogs and Social Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon M Kleinberg</author>
</authors>
<title>Authoritative sources in a hyperlinked environment.</title>
<date>1999</date>
<journal>J. ACM,</journal>
<volume>46</volume>
<issue>5</issue>
<contexts>
<context position="22274" citStr="Kleinberg, 1999" startWordPosition="3689" endWordPosition="3690">ion word extraction on the Customer Review Dataset. corpora. Stemming and fuzzy matching are also performed following previous work (Hu and Liu, 2004). Evaluation Metrics: We evaluate our method by precision(P), recall(R) and F-measure(F). 5.2 Our Method vs. the State-of-the-art Three state-of-the-art unsupervised methods are used as competitors to compare with our method. Hu extracts opinion words/targets by using adjacency rules (Hu and Liu, 2004). DP uses a bootstrapping algorithm named as Double Propagation (Qiu et al., 2009). Zhang is an enhanced version of DP and employs HITS algorithm (Kleinberg, 1999) to rank opinion targets (Zhang et al., 2010). Ours-Full is the full implementation of our method. We employ SVMlight (Joachims, 1999) as the target refining classifier. Default parameters are used except the bias item is set 0. Ours-Stage1 only uses Sentiment Graph Walking algorithm which does’t have opinion word and opinion target refinement. All of the above approaches use same five common opinion word seeds. The choice of opinion seeds seems reasonable, as most people can easily come up with 5 opinion words such as “good”, “bad”, etc. The performance on five products of CRD dataset is show</context>
</contexts>
<marker>Kleinberg, 1999</marker>
<rawString>Jon M. Kleinberg. 1999. Authoritative sources in a hyperlinked environment. J. ACM, 46(5):604–632, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nozomi Kobayashi</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Extracting aspect-evaluation and aspectof relations in opinion mining.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL),</booktitle>
<pages>1065--1074</pages>
<contexts>
<context position="7730" citStr="Kobayashi et al. (2007)" startWordPosition="1172" endWordPosition="1175">alled Double Propagation which introduced eight heuristic syntactic rules. While manually defining syntactic patterns could be timeconsuming and error-prone, we learn syntactic patterns automatically from data. There have been extensive works on mining opinion words and opinion targets by syntactic pattern learning. Riloff and Wiebe (2003) performed pattern learning through bootstrapping while extracting subjective expressions. Zhuang et al. (2006) obtained various dependency relationship templates from an annotated movie corpus and applied them to supervised opinion words/targets extraction. Kobayashi et al. (2007) adopted a supervised learning technique to search for useful syntactic patterns as contextual clues. Our approach is similar to (Wiebe and Riloff, 2005) and (Xu et al., 2013), all of which apply syntactic pattern learning and adopt self-learning strategy. However, the task of (Wiebe and Riloff, 2005) was to classify sentiment orientations in sentence level, while ours needs to extract more detailed information in term level. In addition, our method extends (Xu et al., 2013), and we give a more complete and in-depth analysis on the aforementioned problems in the first section. There were also </context>
</contexts>
<marker>Kobayashi, Inui, Matsumoto, 2007</marker>
<rawString>Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto. 2007. Extracting aspect-evaluation and aspectof relations in opinion mining. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 1065–1074, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
<author>Chao Han</author>
<author>Minlie Huang</author>
<author>Xiaoyan Zhu</author>
<author>Ying-Ju Xia</author>
<author>Shu Zhang</author>
<author>Hao Yu</author>
</authors>
<title>Structure-aware review mining and summarization.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10,</booktitle>
<pages>653--661</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="5278" citStr="Li et al., 2010" startWordPosition="818" endWordPosition="821">random walking to estimate confidence of them. Thus, confidence of pattern is considered in a unified process. Patterns that often extract false opinion relations will have low confidence, and terms introduced by low-confidence patterns will also have low confidence accordingly. This could potentially improve the extraction accuracy. In the second stage, we identify the hard cases, which aims to filter out false opinion targets and extract long-tail opinion targets. Previous supervised methods have been shown to achieve stateof-the-art results for this task (Wu et al., 2009; Jin and Ho, 2009; Li et al., 2010). However, the big challenge for fully supervised method is the lack of annotated training data. Therefore, we adopt a self-learning strategy. Specifically, we employ a semi-supervised classifier to refine the target results from the first stage, which uses some highly confident target candidates as the initial labeled examples. Then opinion words are also refined. Our main contributions are as follows: • We propose a Sentiment Graph Walking algorithm to mine opinion words and opinion targets from reviews, which naturally incorporates confidence of syntactic pattern in a graph to improve extra</context>
<context position="8668" citStr="Li et al., 2010" startWordPosition="1328" endWordPosition="1331">timent orientations in sentence level, while ours needs to extract more detailed information in term level. In addition, our method extends (Xu et al., 2013), and we give a more complete and in-depth analysis on the aforementioned problems in the first section. There were also many works employed graphbased method (Li et al., 2012; Zhang et al., 2010; Hassan and Radev, 2010; Liu et al., 2012), but none of previous works considered confidence of patterns in the graph. In supervised approaches, various kinds of models were applied, such as HMM (Jin and Ho, 2009), SVM (Wu et al., 2009) and CRFs (Li et al., 2010). The downside of supervised methods was the difficulty of obtaining annotated training data in practical applications. Also, classifiers trained 1765 on one domain often fail to give satisfactory results when shifted to another domain. Our method does not rely on annotated training data. 3 The First Stage: Sentiment Graph Walking Algorithm In the first stage, we propose a graph-based algorithm called Sentiment Graph Walking to mine opinion words and opinion targets from reviews. 3.1 Opinion Pattern Learning for Candidates Generation For a given sentence, we first obtain its dependency tree. F</context>
</contexts>
<marker>Li, Han, Huang, Zhu, Xia, Zhang, Yu, 2010</marker>
<rawString>Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu, Ying-Ju Xia, Shu Zhang, and Hao Yu. 2010. Structure-aware review mining and summarization. In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10, pages 653–661, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
<author>Sinno Jialin Pan</author>
<author>Ou Jin</author>
<author>Qiang Yang</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Cross-domain co-extraction of sentiment and topic lexicons.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>410--419</pages>
<contexts>
<context position="8384" citStr="Li et al., 2012" startWordPosition="1277" endWordPosition="1280">e to search for useful syntactic patterns as contextual clues. Our approach is similar to (Wiebe and Riloff, 2005) and (Xu et al., 2013), all of which apply syntactic pattern learning and adopt self-learning strategy. However, the task of (Wiebe and Riloff, 2005) was to classify sentiment orientations in sentence level, while ours needs to extract more detailed information in term level. In addition, our method extends (Xu et al., 2013), and we give a more complete and in-depth analysis on the aforementioned problems in the first section. There were also many works employed graphbased method (Li et al., 2012; Zhang et al., 2010; Hassan and Radev, 2010; Liu et al., 2012), but none of previous works considered confidence of patterns in the graph. In supervised approaches, various kinds of models were applied, such as HMM (Jin and Ho, 2009), SVM (Wu et al., 2009) and CRFs (Li et al., 2010). The downside of supervised methods was the difficulty of obtaining annotated training data in practical applications. Also, classifiers trained 1765 on one domain often fail to give satisfactory results when shifted to another domain. Our method does not rely on annotated training data. 3 The First Stage: Sentime</context>
</contexts>
<marker>Li, Pan, Jin, Yang, Zhu, 2012</marker>
<rawString>Fangtao Li, Sinno Jialin Pan, Ou Jin, Qiang Yang, and Xiaoyan Zhu. 2012. Cross-domain co-extraction of sentiment and topic lexicons. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 410–419, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Dependency-based evaluation of minipar.</title>
<date>1998</date>
<booktitle>In Workshop on Evaluation of Parsing Systems at ICLRE.</booktitle>
<contexts>
<context position="9676" citStr="Lin, 1998" startWordPosition="1493" endWordPosition="1494">called Sentiment Graph Walking to mine opinion words and opinion targets from reviews. 3.1 Opinion Pattern Learning for Candidates Generation For a given sentence, we first obtain its dependency tree. Following (Hu and Liu, 2004; Popescu and Etzioni, 2005; Qiu et al., 2009), we regard all adjectives as opinion word candidates (OC) and all nouns or noun phrases as opinion target candidates (TC). A statistic-based method in (Zhu et al., 2009) is used to detect noun phrases. Then candidates are replaced by wildcards “&lt;OC&gt;” or “&lt;TC&gt;”. Figure 1 gives a dependency tree example generated by Minipar (Lin, 1998). Figure 1: The dependency tree of the sentence “The style of the screen is gorgeous”. We extract two kinds of opinion patterns: “OCTC” pattern and “TC-TC” pattern. The “OCTC” pattern is the shortest path between an OC wildcard and a TC wildcard in dependency tree, which captures opinion relation between an opinion word candidate and an opinion target candidate. Similarly, the “TC-TC” pattern captures opinion relation between two opinion target candidates.1 Words in opinion patterns are replaced by their POS tags, and we constrain that there are at most two words other than wildcards in each p</context>
<context position="20469" citStr="Lin, 1998" startWordPosition="3349" endWordPosition="3350">ds and opinion targets in sentences. When conflicts happened, the third annotator would make the final judgment. The average Kappa-values of the two domains were 0.71 for opinion words and 0.66 for opinion targets. Detailed information of our datasets is shown in Table 1. Dataset Domain #Sentences #OW #OT Large Hotel 10,000 434 1,015 (English) MP3 10,000 559 1,158 COAE08 Camera 2,075 351 892 (Chinese) Car 4,783 622 1,179 Table 1: The detailed information of datasets. OW stands for opinion words and OT stands for targets. Pre-processing: Firstly, HTML tags are removed from texts. Then Minipar (Lin, 1998) is used to parse English corpora, and Standford Parser (Chang et al., 2009) is used for Chinese 4http://ir-china.org.cn/coae2008.html ξ*j ξi + C* Xn i=0 Xk j=0 Xs(oj) = X tiET pk 1768 Methods D1 D2 D3 D4 D5 Avg. P R F P R F P R F P R F P R F F Hu 0.75 0.82 0.78 0.71 0.79 0.75 0.72 0.76 0.74 0.69 0.82 0.75 0.74 0.80 0.77 0.76 DP 0.87 0.81 0.84 0.90 0.81 0.85 0.90 0.86 0.88 0.81 0.84 0.82 0.92 0.86 0.89 0.86 Zhang 0.83 0.84 0.83 0.86 0.85 0.85 0.86 0.88 0.87 0.80 0.85 0.82 0.86 0.86 0.86 0.85 Ours-Stage1 0.79 0.85 0.82 0.82 0.87 0.84 0.83 0.87 0.85 0.78 0.88 0.83 0.82 0.88 0.85 0.84 Ours-Full 0</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Dependency-based evaluation of minipar. In Workshop on Evaluation of Parsing Systems at ICLRE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kang Liu</author>
<author>Liheng Xu</author>
<author>Jun Zhao</author>
</authors>
<title>Opinion target extraction using word-based translation model.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL ’12,</booktitle>
<pages>1346--1356</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="8447" citStr="Liu et al., 2012" startWordPosition="1289" endWordPosition="1292">. Our approach is similar to (Wiebe and Riloff, 2005) and (Xu et al., 2013), all of which apply syntactic pattern learning and adopt self-learning strategy. However, the task of (Wiebe and Riloff, 2005) was to classify sentiment orientations in sentence level, while ours needs to extract more detailed information in term level. In addition, our method extends (Xu et al., 2013), and we give a more complete and in-depth analysis on the aforementioned problems in the first section. There were also many works employed graphbased method (Li et al., 2012; Zhang et al., 2010; Hassan and Radev, 2010; Liu et al., 2012), but none of previous works considered confidence of patterns in the graph. In supervised approaches, various kinds of models were applied, such as HMM (Jin and Ho, 2009), SVM (Wu et al., 2009) and CRFs (Li et al., 2010). The downside of supervised methods was the difficulty of obtaining annotated training data in practical applications. Also, classifiers trained 1765 on one domain often fail to give satisfactory results when shifted to another domain. Our method does not rely on annotated training data. 3 The First Stage: Sentiment Graph Walking Algorithm In the first stage, we propose a gra</context>
</contexts>
<marker>Liu, Xu, Zhao, 2012</marker>
<rawString>Kang Liu, Liheng Xu, and Jun Zhao. 2012. Opinion target extraction using word-based translation model. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL ’12, pages 1346–1356, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Wordnet: a lexical database for english.</title>
<date>1995</date>
<journal>Commun. ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="16438" citStr="Miller, 1995" startWordPosition="2640" endWordPosition="2641">rds and opinion patterns with their confidence scores to represent an opinion target. By this means, a long-tail opinion target can be determined by its own contexts, whose weights are learnt from contexts of frequent opinion targets. Thus, if a longtail opinion target candidate has high contextual support, it will have higher probability to be found out in despite of its low frequency. Creation of General Noun Corpora. 1000 most frequent nouns in Google-1-gram3 were selected as general noun candidates. On the other hand, we added all nouns in the top three levels of hyponyms in four WordNet (Miller, 1995) synsets “object”, “person”, “group” and “measure” into the GN corpus. Our idea was based on the fact that a term is more general when it sits in higher level in the WordNet hierarchy. Then inapplicable candidates were discarded and a 3071-word English 2Note that the “positive” and “negative” here denote opinion targets and non-target terms respectively and they do not indicate sentiment polarities. 3http://books.google.com/ngrams. ct+1 p 1767 GN corpus was created. Another Chinese GN corpus with 3493 words was generated in the similar way from HowNet (Gan and Wong, 2000). Generation of Labele</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. Wordnet: a lexical database for english. Commun. ACM, 38(11):39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05,</booktitle>
<pages>339--346</pages>
<contexts>
<context position="3220" citStr="Popescu and Etzioni, 2005" startWordPosition="488" endWordPosition="492">j-{mod}-(Prep)-{pcomp-n}-Noun”, but it doesn’t bear any sentiment orientation. We call such relations that match opinion patterns but express no opinion false opinion relations. Previous pattern learning algorithms (Zhuang et al., 2006; Kessler and Nicolov, 2009; Jijkoun et al., 2010) often extract opinion patterns by frequency. However, some high-frequency syntactic patterns can have very poor precision (Kessler and Nicolov, 2009). False Opinion Targets: In another case, the phrase “wonderful time” can be matched by an opinion pattern “Adj-{mod}-Noun”, which is widely used in previous works (Popescu and Etzioni, 2005; Qiu et al., 2009). As can be seen, this phrase does express a positive opinion but unfortunately “time” is not a valid opinion target for most domains such as MP3. Thus, false opinion targets are extracted. Due to the lack of ground-truth knowledge for opinion targets, non-target terms introduced in this way can be hardly filtered out. Long-tail Opinion Targets: We further notice that previous works prone to extract opinion targets with high frequency (Hu and Liu, 2004; Popescu and Etzioni, 2005; Qiu et al., 2009; Zhu et al., 2009), and they often have difficulty in identifying the infrequen</context>
<context position="6937" citStr="Popescu and Etzioni (2005)" startWordPosition="1061" endWordPosition="1064">nts on three real world datasets, which demonstrate the effectiveness of our method compared with state-of-the-art unsupervised methods (Section 5). 2 Related Work In opinion words/targets mining task, most unsupervised methods rely on identifying opinion relations between opinion words and opinion targets. Hu and Liu (2004) proposed an association mining technique to extract opinion words/targets. The simple heuristic rules they used may potentially introduce many false opinion words/targets. To identify opinion relations more precisely, subsequent research work exploited syntax information. Popescu and Etzioni (2005) used manually complied syntactic patterns and Pointwise Mutual Information (PMI) to extract opinion words/targets. Qiu et al. (2009) proposed a bootstrapping framework called Double Propagation which introduced eight heuristic syntactic rules. While manually defining syntactic patterns could be timeconsuming and error-prone, we learn syntactic patterns automatically from data. There have been extensive works on mining opinion words and opinion targets by syntactic pattern learning. Riloff and Wiebe (2003) performed pattern learning through bootstrapping while extracting subjective expressions</context>
<context position="9321" citStr="Popescu and Etzioni, 2005" startWordPosition="1430" endWordPosition="1433"> methods was the difficulty of obtaining annotated training data in practical applications. Also, classifiers trained 1765 on one domain often fail to give satisfactory results when shifted to another domain. Our method does not rely on annotated training data. 3 The First Stage: Sentiment Graph Walking Algorithm In the first stage, we propose a graph-based algorithm called Sentiment Graph Walking to mine opinion words and opinion targets from reviews. 3.1 Opinion Pattern Learning for Candidates Generation For a given sentence, we first obtain its dependency tree. Following (Hu and Liu, 2004; Popescu and Etzioni, 2005; Qiu et al., 2009), we regard all adjectives as opinion word candidates (OC) and all nouns or noun phrases as opinion target candidates (TC). A statistic-based method in (Zhu et al., 2009) is used to detect noun phrases. Then candidates are replaced by wildcards “&lt;OC&gt;” or “&lt;TC&gt;”. Figure 1 gives a dependency tree example generated by Minipar (Lin, 1998). Figure 1: The dependency tree of the sentence “The style of the screen is gorgeous”. We extract two kinds of opinion patterns: “OCTC” pattern and “TC-TC” pattern. The “OCTC” pattern is the shortest path between an OC wildcard and a TC wildcard</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05, pages 339–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Expanding domain sentiment lexicon through double propagation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 21st international jont conference on Artifical intelligence, IJCAI’09,</booktitle>
<pages>1199--1204</pages>
<contexts>
<context position="2424" citStr="Qiu et al., 2009" startWordPosition="370" endWordPosition="373">in this paper) between them. For example, in the sentence “It has a clear screen”, “clear” is an opinion word and “screen” is an opinion target, and there is an opinion relation between the two words. It is natural to identify such opinion relations through common syntactic patterns (also called opinion patterns in this paper) between opinion words and targets. For example, we can extract “clear” and “screen” by using a syntactic pattern “Adj-{mod}-Noun”, which captures the opinion relation between them. Although previous works have shown the effectiveness of syntactic patterns for this task (Qiu et al., 2009; Zhang et al., 2010), they still have some limitations as follows. False Opinion Relations: As an example, the phrase “everyday at school” can be matched by a pattern “Adj-{mod}-(Prep)-{pcomp-n}-Noun”, but it doesn’t bear any sentiment orientation. We call such relations that match opinion patterns but express no opinion false opinion relations. Previous pattern learning algorithms (Zhuang et al., 2006; Kessler and Nicolov, 2009; Jijkoun et al., 2010) often extract opinion patterns by frequency. However, some high-frequency syntactic patterns can have very poor precision (Kessler and Nicolov,</context>
<context position="3740" citStr="Qiu et al., 2009" startWordPosition="577" endWordPosition="580">nion pattern “Adj-{mod}-Noun”, which is widely used in previous works (Popescu and Etzioni, 2005; Qiu et al., 2009). As can be seen, this phrase does express a positive opinion but unfortunately “time” is not a valid opinion target for most domains such as MP3. Thus, false opinion targets are extracted. Due to the lack of ground-truth knowledge for opinion targets, non-target terms introduced in this way can be hardly filtered out. Long-tail Opinion Targets: We further notice that previous works prone to extract opinion targets with high frequency (Hu and Liu, 2004; Popescu and Etzioni, 2005; Qiu et al., 2009; Zhu et al., 2009), and they often have difficulty in identifying the infrequent or long-tail opinion targets. 1764 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1764–1773, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics To address the problems stated above, this paper proposes a two-stage framework for mining opinion words and opinion targets. The underlying motivation is analogous to the novel idea “Mine the Easy, Classify the Hard” (Dasgupta and Ng, 2009). In our first stage, we propose a Sentiment Graph Wa</context>
<context position="7070" citStr="Qiu et al. (2009)" startWordPosition="1081" endWordPosition="1084">on 5). 2 Related Work In opinion words/targets mining task, most unsupervised methods rely on identifying opinion relations between opinion words and opinion targets. Hu and Liu (2004) proposed an association mining technique to extract opinion words/targets. The simple heuristic rules they used may potentially introduce many false opinion words/targets. To identify opinion relations more precisely, subsequent research work exploited syntax information. Popescu and Etzioni (2005) used manually complied syntactic patterns and Pointwise Mutual Information (PMI) to extract opinion words/targets. Qiu et al. (2009) proposed a bootstrapping framework called Double Propagation which introduced eight heuristic syntactic rules. While manually defining syntactic patterns could be timeconsuming and error-prone, we learn syntactic patterns automatically from data. There have been extensive works on mining opinion words and opinion targets by syntactic pattern learning. Riloff and Wiebe (2003) performed pattern learning through bootstrapping while extracting subjective expressions. Zhuang et al. (2006) obtained various dependency relationship templates from an annotated movie corpus and applied them to supervis</context>
<context position="9340" citStr="Qiu et al., 2009" startWordPosition="1434" endWordPosition="1437"> of obtaining annotated training data in practical applications. Also, classifiers trained 1765 on one domain often fail to give satisfactory results when shifted to another domain. Our method does not rely on annotated training data. 3 The First Stage: Sentiment Graph Walking Algorithm In the first stage, we propose a graph-based algorithm called Sentiment Graph Walking to mine opinion words and opinion targets from reviews. 3.1 Opinion Pattern Learning for Candidates Generation For a given sentence, we first obtain its dependency tree. Following (Hu and Liu, 2004; Popescu and Etzioni, 2005; Qiu et al., 2009), we regard all adjectives as opinion word candidates (OC) and all nouns or noun phrases as opinion target candidates (TC). A statistic-based method in (Zhu et al., 2009) is used to detect noun phrases. Then candidates are replaced by wildcards “&lt;OC&gt;” or “&lt;TC&gt;”. Figure 1 gives a dependency tree example generated by Minipar (Lin, 1998). Figure 1: The dependency tree of the sentence “The style of the screen is gorgeous”. We extract two kinds of opinion patterns: “OCTC” pattern and “TC-TC” pattern. The “OCTC” pattern is the shortest path between an OC wildcard and a TC wildcard in dependency tree</context>
<context position="22193" citStr="Qiu et al., 2009" startWordPosition="3673" endWordPosition="3676">79 0.68 0.66 0.71 0.68 0.65 0.67 0.66 0.72 0.67 0.69 0.68 Table 3: Results of opinion word extraction on the Customer Review Dataset. corpora. Stemming and fuzzy matching are also performed following previous work (Hu and Liu, 2004). Evaluation Metrics: We evaluate our method by precision(P), recall(R) and F-measure(F). 5.2 Our Method vs. the State-of-the-art Three state-of-the-art unsupervised methods are used as competitors to compare with our method. Hu extracts opinion words/targets by using adjacency rules (Hu and Liu, 2004). DP uses a bootstrapping algorithm named as Double Propagation (Qiu et al., 2009). Zhang is an enhanced version of DP and employs HITS algorithm (Kleinberg, 1999) to rank opinion targets (Zhang et al., 2010). Ours-Full is the full implementation of our method. We employ SVMlight (Joachims, 1999) as the target refining classifier. Default parameters are used except the bias item is set 0. Ours-Stage1 only uses Sentiment Graph Walking algorithm which does’t have opinion word and opinion target refinement. All of the above approaches use same five common opinion word seeds. The choice of opinion seeds seems reasonable, as most people can easily come up with 5 opinion words su</context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2009</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2009. Expanding domain sentiment lexicon through double propagation. In Proceedings of the 21st international jont conference on Artifical intelligence, IJCAI’09, pages 1199–1204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Janyce Wiebe</author>
</authors>
<title>Learning extraction patterns for subjective expressions.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 conference on Empirical methods in natural language processing, EMNLP ’03,</booktitle>
<pages>105--112</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="7448" citStr="Riloff and Wiebe (2003)" startWordPosition="1136" endWordPosition="1139">nion relations more precisely, subsequent research work exploited syntax information. Popescu and Etzioni (2005) used manually complied syntactic patterns and Pointwise Mutual Information (PMI) to extract opinion words/targets. Qiu et al. (2009) proposed a bootstrapping framework called Double Propagation which introduced eight heuristic syntactic rules. While manually defining syntactic patterns could be timeconsuming and error-prone, we learn syntactic patterns automatically from data. There have been extensive works on mining opinion words and opinion targets by syntactic pattern learning. Riloff and Wiebe (2003) performed pattern learning through bootstrapping while extracting subjective expressions. Zhuang et al. (2006) obtained various dependency relationship templates from an annotated movie corpus and applied them to supervised opinion words/targets extraction. Kobayashi et al. (2007) adopted a supervised learning technique to search for useful syntactic patterns as contextual clues. Our approach is similar to (Wiebe and Riloff, 2005) and (Xu et al., 2013), all of which apply syntactic pattern learning and adopt self-learning strategy. However, the task of (Wiebe and Riloff, 2005) was to classify</context>
</contexts>
<marker>Riloff, Wiebe, 2003</marker>
<rawString>Ellen Riloff and Janyce Wiebe. 2003. Learning extraction patterns for subjective expressions. In Proceedings of the 2003 conference on Empirical methods in natural language processing, EMNLP ’03, pages 105–112, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongning Wang</author>
<author>Yue Lu</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Latent aspect rating analysis without aspect keyword supervision.</title>
<date>2011</date>
<booktitle>In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’11,</booktitle>
<pages>618--626</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="19660" citStr="Wang et al., 2011" startWordPosition="3217" endWordPosition="3220">t refining classifier. Particularly, freq(ti) = P Ppk freq(ti, oj, pk). A higher oj score of s(oj) means that candidate oj is more likely to be an opinion word. 5 Experiments 5.1 Datasets and Evaluation Metrics Datasets: We select three real world datasets to evaluate our approach. The first one is called Customer Review Dataset (CRD) (Hu and Liu, 2004) which contains reviews on five different products (represented by D1 to D5) in English. The second dataset is pre-annotated and published in COAE084, where two domains of Chinese reviews are selected. At last, we employ a benchmark dataset in (Wang et al., 2011) and named it as Large. We manually annotated opinion words and opinion targets as the gold standard. Three annotators were involved. Firstly, two annotators were required to annotate out opinion words and opinion targets in sentences. When conflicts happened, the third annotator would make the final judgment. The average Kappa-values of the two domains were 0.71 for opinion words and 0.66 for opinion targets. Detailed information of our datasets is shown in Table 1. Dataset Domain #Sentences #OW #OT Large Hotel 10,000 434 1,015 (English) MP3 10,000 559 1,158 COAE08 Camera 2,075 351 892 (Chine</context>
</contexts>
<marker>Wang, Lu, Zhai, 2011</marker>
<rawString>Hongning Wang, Yue Lu, and ChengXiang Zhai. 2011. Latent aspect rating analysis without aspect keyword supervision. In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’11, pages 618– 626, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Ellen Riloff</author>
</authors>
<title>Creating subjective and objective sentence classifiers from unannotated texts.</title>
<date>2005</date>
<booktitle>In Proceedings of the 6th international conference on Computational Linguistics and Intelligent Text Processing, CICLing’05,</booktitle>
<pages>486--497</pages>
<contexts>
<context position="7883" citStr="Wiebe and Riloff, 2005" startWordPosition="1195" endWordPosition="1198">one, we learn syntactic patterns automatically from data. There have been extensive works on mining opinion words and opinion targets by syntactic pattern learning. Riloff and Wiebe (2003) performed pattern learning through bootstrapping while extracting subjective expressions. Zhuang et al. (2006) obtained various dependency relationship templates from an annotated movie corpus and applied them to supervised opinion words/targets extraction. Kobayashi et al. (2007) adopted a supervised learning technique to search for useful syntactic patterns as contextual clues. Our approach is similar to (Wiebe and Riloff, 2005) and (Xu et al., 2013), all of which apply syntactic pattern learning and adopt self-learning strategy. However, the task of (Wiebe and Riloff, 2005) was to classify sentiment orientations in sentence level, while ours needs to extract more detailed information in term level. In addition, our method extends (Xu et al., 2013), and we give a more complete and in-depth analysis on the aforementioned problems in the first section. There were also many works employed graphbased method (Li et al., 2012; Zhang et al., 2010; Hassan and Radev, 2010; Liu et al., 2012), but none of previous works conside</context>
</contexts>
<marker>Wiebe, Riloff, 2005</marker>
<rawString>Janyce Wiebe and Ellen Riloff. 2005. Creating subjective and objective sentence classifiers from unannotated texts. In Proceedings of the 6th international conference on Computational Linguistics and Intelligent Text Processing, CICLing’05, pages 486–497.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanbin Wu</author>
<author>Qi Zhang</author>
<author>Xuanjing Huang</author>
<author>Lide Wu</author>
</authors>
<title>Phrase dependency parsing for opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>3</volume>
<pages>1533--1541</pages>
<contexts>
<context position="5242" citStr="Wu et al., 2009" startWordPosition="810" endWordPosition="813">arget/pattern candidates and apply random walking to estimate confidence of them. Thus, confidence of pattern is considered in a unified process. Patterns that often extract false opinion relations will have low confidence, and terms introduced by low-confidence patterns will also have low confidence accordingly. This could potentially improve the extraction accuracy. In the second stage, we identify the hard cases, which aims to filter out false opinion targets and extract long-tail opinion targets. Previous supervised methods have been shown to achieve stateof-the-art results for this task (Wu et al., 2009; Jin and Ho, 2009; Li et al., 2010). However, the big challenge for fully supervised method is the lack of annotated training data. Therefore, we adopt a self-learning strategy. Specifically, we employ a semi-supervised classifier to refine the target results from the first stage, which uses some highly confident target candidates as the initial labeled examples. Then opinion words are also refined. Our main contributions are as follows: • We propose a Sentiment Graph Walking algorithm to mine opinion words and opinion targets from reviews, which naturally incorporates confidence of syntactic</context>
<context position="8641" citStr="Wu et al., 2009" startWordPosition="1322" endWordPosition="1325">, 2005) was to classify sentiment orientations in sentence level, while ours needs to extract more detailed information in term level. In addition, our method extends (Xu et al., 2013), and we give a more complete and in-depth analysis on the aforementioned problems in the first section. There were also many works employed graphbased method (Li et al., 2012; Zhang et al., 2010; Hassan and Radev, 2010; Liu et al., 2012), but none of previous works considered confidence of patterns in the graph. In supervised approaches, various kinds of models were applied, such as HMM (Jin and Ho, 2009), SVM (Wu et al., 2009) and CRFs (Li et al., 2010). The downside of supervised methods was the difficulty of obtaining annotated training data in practical applications. Also, classifiers trained 1765 on one domain often fail to give satisfactory results when shifted to another domain. Our method does not rely on annotated training data. 3 The First Stage: Sentiment Graph Walking Algorithm In the first stage, we propose a graph-based algorithm called Sentiment Graph Walking to mine opinion words and opinion targets from reviews. 3.1 Opinion Pattern Learning for Candidates Generation For a given sentence, we first ob</context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2009</marker>
<rawString>Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu. 2009. Phrase dependency parsing for opinion mining. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 3 - Volume 3, pages 1533–1541.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liheng Xu</author>
<author>Kang Liu</author>
<author>Siwei Lai</author>
<author>Yubo Chen</author>
<author>Jun Zhao</author>
</authors>
<title>Walk and learn: A two-stage approach for opinion words and opinion targets co-extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of the 22nd International World Wide Web Conference, WWW ’13.</booktitle>
<contexts>
<context position="7905" citStr="Xu et al., 2013" startWordPosition="1200" endWordPosition="1203">rns automatically from data. There have been extensive works on mining opinion words and opinion targets by syntactic pattern learning. Riloff and Wiebe (2003) performed pattern learning through bootstrapping while extracting subjective expressions. Zhuang et al. (2006) obtained various dependency relationship templates from an annotated movie corpus and applied them to supervised opinion words/targets extraction. Kobayashi et al. (2007) adopted a supervised learning technique to search for useful syntactic patterns as contextual clues. Our approach is similar to (Wiebe and Riloff, 2005) and (Xu et al., 2013), all of which apply syntactic pattern learning and adopt self-learning strategy. However, the task of (Wiebe and Riloff, 2005) was to classify sentiment orientations in sentence level, while ours needs to extract more detailed information in term level. In addition, our method extends (Xu et al., 2013), and we give a more complete and in-depth analysis on the aforementioned problems in the first section. There were also many works employed graphbased method (Li et al., 2012; Zhang et al., 2010; Hassan and Radev, 2010; Liu et al., 2012), but none of previous works considered confidence of patt</context>
</contexts>
<marker>Xu, Liu, Lai, Chen, Zhao, 2013</marker>
<rawString>Liheng Xu, Kang Liu, Siwei Lai, Yubo Chen, and Jun Zhao. 2013. Walk and learn: A two-stage approach for opinion words and opinion targets co-extraction. In Proceedings of the 22nd International World Wide Web Conference, WWW ’13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Zhang</author>
<author>Bing Liu</author>
<author>Suk Hwan Lim</author>
<author>Eamonn O’Brien-Strain</author>
</authors>
<title>Extracting and ranking product features in opinion documents.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics: Posters,</booktitle>
<pages>1462--1470</pages>
<marker>Zhang, Liu, Lim, O’Brien-Strain, 2010</marker>
<rawString>Lei Zhang, Bing Liu, Suk Hwan Lim, and Eamonn O’Brien-Strain. 2010. Extracting and ranking product features in opinion documents. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, pages 1462–1470.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jingbo Zhu</author>
<author>Huizhen Wang</author>
<author>Benjamin K Tsou</author>
<author>Muhua Zhu</author>
</authors>
<title>Multi-aspect opinion polling from textual reviews.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th ACM conference on Information and knowledge management, CIKM ’09,</booktitle>
<pages>1799--1802</pages>
<contexts>
<context position="3759" citStr="Zhu et al., 2009" startWordPosition="581" endWordPosition="584">{mod}-Noun”, which is widely used in previous works (Popescu and Etzioni, 2005; Qiu et al., 2009). As can be seen, this phrase does express a positive opinion but unfortunately “time” is not a valid opinion target for most domains such as MP3. Thus, false opinion targets are extracted. Due to the lack of ground-truth knowledge for opinion targets, non-target terms introduced in this way can be hardly filtered out. Long-tail Opinion Targets: We further notice that previous works prone to extract opinion targets with high frequency (Hu and Liu, 2004; Popescu and Etzioni, 2005; Qiu et al., 2009; Zhu et al., 2009), and they often have difficulty in identifying the infrequent or long-tail opinion targets. 1764 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1764–1773, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics To address the problems stated above, this paper proposes a two-stage framework for mining opinion words and opinion targets. The underlying motivation is analogous to the novel idea “Mine the Easy, Classify the Hard” (Dasgupta and Ng, 2009). In our first stage, we propose a Sentiment Graph Walking algorithm to </context>
<context position="9510" citStr="Zhu et al., 2009" startWordPosition="1463" endWordPosition="1466">her domain. Our method does not rely on annotated training data. 3 The First Stage: Sentiment Graph Walking Algorithm In the first stage, we propose a graph-based algorithm called Sentiment Graph Walking to mine opinion words and opinion targets from reviews. 3.1 Opinion Pattern Learning for Candidates Generation For a given sentence, we first obtain its dependency tree. Following (Hu and Liu, 2004; Popescu and Etzioni, 2005; Qiu et al., 2009), we regard all adjectives as opinion word candidates (OC) and all nouns or noun phrases as opinion target candidates (TC). A statistic-based method in (Zhu et al., 2009) is used to detect noun phrases. Then candidates are replaced by wildcards “&lt;OC&gt;” or “&lt;TC&gt;”. Figure 1 gives a dependency tree example generated by Minipar (Lin, 1998). Figure 1: The dependency tree of the sentence “The style of the screen is gorgeous”. We extract two kinds of opinion patterns: “OCTC” pattern and “TC-TC” pattern. The “OCTC” pattern is the shortest path between an OC wildcard and a TC wildcard in dependency tree, which captures opinion relation between an opinion word candidate and an opinion target candidate. Similarly, the “TC-TC” pattern captures opinion relation between two </context>
</contexts>
<marker>Zhu, Wang, Tsou, Zhu, 2009</marker>
<rawString>Jingbo Zhu, Huizhen Wang, Benjamin K. Tsou, and Muhua Zhu. 2009. Multi-aspect opinion polling from textual reviews. In Proceedings of the 18th ACM conference on Information and knowledge management, CIKM ’09, pages 1799–1802.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Zhuang</author>
<author>Feng Jing</author>
<author>Xiao-Yan Zhu</author>
</authors>
<title>Movie review mining and summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of the 15th ACM international conference on Information and knowledge management, CIKM ’06,</booktitle>
<pages>43--50</pages>
<contexts>
<context position="2830" citStr="Zhuang et al., 2006" startWordPosition="431" endWordPosition="434"> “screen” by using a syntactic pattern “Adj-{mod}-Noun”, which captures the opinion relation between them. Although previous works have shown the effectiveness of syntactic patterns for this task (Qiu et al., 2009; Zhang et al., 2010), they still have some limitations as follows. False Opinion Relations: As an example, the phrase “everyday at school” can be matched by a pattern “Adj-{mod}-(Prep)-{pcomp-n}-Noun”, but it doesn’t bear any sentiment orientation. We call such relations that match opinion patterns but express no opinion false opinion relations. Previous pattern learning algorithms (Zhuang et al., 2006; Kessler and Nicolov, 2009; Jijkoun et al., 2010) often extract opinion patterns by frequency. However, some high-frequency syntactic patterns can have very poor precision (Kessler and Nicolov, 2009). False Opinion Targets: In another case, the phrase “wonderful time” can be matched by an opinion pattern “Adj-{mod}-Noun”, which is widely used in previous works (Popescu and Etzioni, 2005; Qiu et al., 2009). As can be seen, this phrase does express a positive opinion but unfortunately “time” is not a valid opinion target for most domains such as MP3. Thus, false opinion targets are extracted. D</context>
<context position="7559" citStr="Zhuang et al. (2006)" startWordPosition="1149" endWordPosition="1152">sed manually complied syntactic patterns and Pointwise Mutual Information (PMI) to extract opinion words/targets. Qiu et al. (2009) proposed a bootstrapping framework called Double Propagation which introduced eight heuristic syntactic rules. While manually defining syntactic patterns could be timeconsuming and error-prone, we learn syntactic patterns automatically from data. There have been extensive works on mining opinion words and opinion targets by syntactic pattern learning. Riloff and Wiebe (2003) performed pattern learning through bootstrapping while extracting subjective expressions. Zhuang et al. (2006) obtained various dependency relationship templates from an annotated movie corpus and applied them to supervised opinion words/targets extraction. Kobayashi et al. (2007) adopted a supervised learning technique to search for useful syntactic patterns as contextual clues. Our approach is similar to (Wiebe and Riloff, 2005) and (Xu et al., 2013), all of which apply syntactic pattern learning and adopt self-learning strategy. However, the task of (Wiebe and Riloff, 2005) was to classify sentiment orientations in sentence level, while ours needs to extract more detailed information in term level.</context>
</contexts>
<marker>Zhuang, Jing, Zhu, 2006</marker>
<rawString>Li Zhuang, Feng Jing, and Xiao-Yan Zhu. 2006. Movie review mining and summarization. In Proceedings of the 15th ACM international conference on Information and knowledge management, CIKM ’06, pages 43–50.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>