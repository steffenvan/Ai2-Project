<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.574524">
INFORMATION RETRIEVAL USING ROBUST NATURAL LANGUAGE PROCESSING
</title>
<author confidence="0.415154">
Tomek Strzalkowski and Barbara Vautheyt
</author>
<affiliation confidence="0.376428">
Courant Institute of Mathematical Sciences
</affiliation>
<address confidence="0.584185333333333">
New York University
715 Broadway, rm. 704
New York, NY 10003
</address>
<email confidence="0.990367">
tomek@cs.nyu.edu
</email>
<sectionHeader confidence="0.970706" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999832666666667">
We developed a prototype information retrieval sys-
tem which uses advanced natural language process-
ing techniques to enhance the effectiveness of tradi-
tional key-word based document retrieval. The back-
bone of our system is a statistical retrieval engine
which performs automated indexing of documents,
then search and ranking in response to user queries.
This core architecture is augmented with advanced
natural language processing tools which are both
robust and efficient. In early experiments, the aug-
mented system has displayed capabilities that appear
to make it superior to the purely statistical base.
</bodyText>
<sectionHeader confidence="0.989" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.998281545454546">
A typical information retrieval (IR) task is to
select documents from a database in response to a
user&apos;s query, and rank these documents according to
relevance. This has been usually accomplished using
statistical methods (often coupled with manual
encoding), but it is now widely believed that these
traditional methods have reached their limits! These
limits are particularly acute for text databases, where
natural language processing (NLP) has long been
considered necessary for further progress. Unfor-
tunately, the difficulties encountered in applying
computational linguistics technologies to text pro-
cessing have contributed to a wide-spread belief that
automated NLP may not be suitable in IR. These
difficulties included inefficiency, limited coverage,
and prohibitive cost of manual effort required to
build lexicons and knowledge bases for each new
text domain. On the other hand, while numerous
f Current address: Laboratoire d&apos;Informatique, Universite
de Fribourg, ch. du Musee 3, 1700 Fribourg, Switzerland:
vauthey@cfnmi51.bitnet.
I As far as the automatic document retrieval is concerned.
Techniques involving various forms of relevance feedback are usu-
ally far more effective, but they require user&apos;s manual intervention
in the retrieval process. In this paper, we are concerned with fully
automated retrieval only.
experiments did not establish the usefulness of NLP,
they cannot be considered conclusive because of their
very limited scale.
Another reason is the limited scale at which
NLP was used. Syntactic parsing of the database con-
tents, for example, has been attempted in order to
extract linguistically motivated &amp;quot;syntactic phrases&amp;quot;,
which presumably were better indicators of contents
than &amp;quot;statistical phrases&amp;quot; where words were grouped
solely on the basis of physical proximity (eg. &amp;quot;college
junior&amp;quot; is not the same as &amp;quot;junior college&amp;quot;). These
intuitions, however, were not confirmed by experi-
ments; worse still, statistical phrases regularly out-
performed syntactic phrases (Fagan, 1987). Attempts
to overcome the poor statistical behavior of syntactic
phrases has led to various clustering techniques that
grouped synonymous or near synonymous phrases
into &amp;quot;clusters&amp;quot; and replaced these by single &amp;quot;meta-
terms&amp;quot;. Clustering techniques were somewhat suc-
cessful in upgrading overall system performance, but
their effectiveness was diminished by frequently poor
quality of syntactic analysis. Since full-analysis
wide-coverage syntactic parsers were either unavail-
able or inefficient, various partial parsing methods
have been used. Partial parsing was usually fast
enough, but it also generated noisy data: as many as
50% of all generated phrases could be incorrect
(Lewis and Croft, 1990). Other efforts concentrated
on processing of user queries (eg. Speck Jones and
Tait, 1984; Smeaton and van Rijsbergen, 1988).
Since queries were usually short and few, even rela-
tively inefficient NLP techniques could be of benefit
to the system. None of these attempts proved con-
clusive, and some were never properly evaluated
either.
2 Standard IR benchmark collections are statistically too
small and the experiments can easily produce counterintuitive
results. For example, Cranfield collection is only approx. 180,000
English words, while CACM-3204 collection used in the present
experiments is approx. 200,000 words.
</bodyText>
<page confidence="0.998172">
104
</page>
<bodyText confidence="0.9996374">
We believe that linguistic processing of both
the database and the user&apos;s queries need to be done
for a maximum benefit, and moreover, the two
processes must be appropriately coordinated. This
prognosis is supported by the experiments performed
by the NYU group (Strzalkowski and Vauthey, 1991;
Grishman and Strzalkowski, 1991), and by the group
at the University of Massachussetts (Croft et al.,
1991). We explore this possibility further in this
paper.
</bodyText>
<sectionHeader confidence="0.973349" genericHeader="method">
OVERALL DESIGN
</sectionHeader>
<bodyText confidence="0.99998304">
Our information retrieval system consists of a
traditional statistical backbone (Harman and Candela,
1989) augmented with various natural language pro-
cessing components that assist the system in database
processing (stemming, indexing, word and phrase
clustering, selectional restrictions), and translate a
user&apos;s information request into an effective query.
This design is a careful compromise between purely
statistical non-linguistic approaches and those requir-
ing rather accomplished (and expensive) semantic
analysis of data, often referred to as &apos;conceptual
retrieval&apos;. The conceptual retrieval systems, though
quite effective, are not yet mature enough to be con-
sidered in serious information retrieval applications,
the major problems being their extreme inefficiency
and the need for manual encoding of domain
knowledge (Mauldin, 1991).
In our system the database text is first pro-
cessed with a fast syntactic parser. Subsequently cer-
tain types of phrases are extracted from the parse
trees and used as compound indexing terms in addi-
tion to single-word terms. The extracted phrases are
statistically analyzed as syntactic contexts in order to
discover a variety of similarity links between smaller
subphrases and words occurring in them. A further
filtering process maps these similarity links onto
semantic relations (generalization, specialization,
synonymy, etc.) after which they are used to
transform user&apos;s request into a search query.
The user&apos;s natural language request is also
parsed, and all indexing terms occurring in them are
identified. Next, certain highly ambiguous (usually
single-word) terms are dropped, provided that they
also occur as elements in some compound terms. For
example, &amp;quot;natural&amp;quot; is deleted from a query already
containing &amp;quot;natural language&amp;quot; because &amp;quot;natural&amp;quot;
occurs in many unrelated contexts: &amp;quot;natural number&amp;quot;,
&amp;quot;natural logarithm&amp;quot;, &amp;quot;natural approach&amp;quot;, etc. At the
same time, other terms may be added, namely those
which are linked to some query term through admis-
sible similarity relations. For example, &amp;quot;fortran&amp;quot; is
added to a query containing the compound term
&amp;quot;program language&amp;quot; via a specification link. After the
final query is constructed, the database search fol-
lows, and a ranked list of documents is returned.
It should be noted that all the processing steps,
those performed by the backbone system, and these
performed by the natural language processing com-
ponents, are fully automated, and no human interven-
tion or manual encoding is required.
</bodyText>
<sectionHeader confidence="0.852784" genericHeader="method">
FAST PARSING WITH 1TP PARSER
</sectionHeader>
<bodyText confidence="0.985994731707317">
TTP (Tagged Text Parser) is based on the
Linguistic String Grammar developed by Sager
(1981). Written in Quintus Prolog, the parser
currently encompasses more than 400 grammar pro-
ductions. It produces regularized parse tree represen-
tations for each sentence that reflect the sentence&apos;s
logical structure. The parser is equipped with a
powerful skip-and-fit recovery mechanism that
allows it to operate effectively in the face of ill-
formed input or under a severe time pressure. In the
recent experiments with approximately 6 million
words of English texts,3 the parser&apos;s speed averaged
between 0.45 and 0.5 seconds per sentence, or up to
2600 words per minute, on a 21 MIPS SparcStation
ELC. Some details of the parser are discussed
below.4
TT? is a full grammar parser, and initially, it
attempts to generate a complete analysis for each
sentence. However, unlike an ordinary parser, it has a
built-in timer which regulates the amount of time
allowed for parsing any one sentence. If a parse is not
returned before the allotted time elapses, the parser
enters the skip-and-fit mode in which it will try to
&amp;quot;fit&amp;quot; the parse. While in the skip-and-fit mode, the
parser will attempt to forcibly reduce incomplete
constituents, possibly skipping portions of input in
order to restart processing at a next unattempted con-
stituent. In other words, the parser will favor reduc-
tion to backtracking while in the skip-and-fit mode.
The result of this strategy is an approximate parse,
partially fitted using top-down predictions. The frag-
ments skipped in the first pass are not thrown out,
instead they are analyzed by a simple phrasal parser
that looks for noun phrases and relative clauses and
then attaches the recovered material to the main parse
structure. As an illustration, consider the following
sentence taken from the CACM-3204 corpus:
3 These include CACM-3204, MUC-3, and a selection of
nearly 6,000 technical articles extracted from Computer Library
database (a Ziff Communications Inc. CD-ROM).
A complete description can be found in (Strzalkowski,
</bodyText>
<page confidence="0.7883685">
1992).
105
</page>
<bodyText confidence="0.997885592592592">
The method is illustrated by the automatic con-
struction of both recursive and iterative pro-
grams operating on natural numbers, lists, and
trees, in order to construct a program satisfying
certain specifications a theorem induced by
those specifications is proved, and the desired
program is extracted from the proof.
The italicized fragment is likely to cause additional
complications in parsing this lengthy string, and the
parser may be better off ignoring this fragment alto-
gether. To do so successfully, the parser must close
the currently open constituent (i.e., reduce a program
satisfying certain specifications to NP), and possibly
a few of its parent constituents, removing
corresponding productions from further considera-
tion, until an appropriate production is reactivated.
In this case, TTP may force the following reductions:
SI —) to V NP; SA —) SI; S --) NP V NP SA, until the
production S S and S is reached. Next, the parser
skips input to find and, and resumes normal process-
ing.
As may be expected, the skip-and-fit strategy
will only be effective if the input skipping can be per-
formed with a degree of determinism. This means
that most of the lexical level ambiguity must be
removed from the input text, prior to parsing. We
achieve this using a stochastic parts of speech tagger
</bodyText>
<sectionHeader confidence="0.9014525" genericHeader="method">
5 to preprocess the text.
WORD SUFFIX TRIMMER
</sectionHeader>
<bodyText confidence="0.9983479">
Word stemming has been an effective way of
improving document recall since it reduces words to
their common morphological root, thus allowing
more successful matches. On the other hand, stem-
ming tends to decrease retrieval precision, if care is
not taken to prevent situations where otherwise unre-
lated words are reduced to the same stem. In our sys-
tem we replaced a traditional morphological stemmer
with a conservative dictionary-assisted suffix trim-
mer.6 The suffix trimmer performs essentially two
tasks: (1) it reduces inflected word forms to their root
forms as specified in the dictionary, and (2) it con-
verts nominalized verb forms (eg. &amp;quot;implementation&amp;quot;,
&amp;quot;storage&amp;quot;) to the root forms of corresponding verbs
(i.e., &amp;quot;implement&amp;quot;, &amp;quot;store&amp;quot;). This is accomplished by
removing a standard suffix, eg. &amp;quot;stor+age&amp;quot;, replacing
it with a standard root ending (&amp;quot;+e&amp;quot;), and checking
the newly created word against the dictionary, i.e.,
we check whether the new root (&amp;quot;store&amp;quot;) is indeed a
legal word, and whether the original root (&amp;quot;storage&amp;quot;)
</bodyText>
<subsectionHeader confidence="0.881124">
Courtesy of Bolt Beranek and Newman.
6We use Oxford Advanced Learner&apos;s Dictionary (OALD).
</subsectionHeader>
<bodyText confidence="0.988315368421052">
is defined using the new root (&amp;quot;store&amp;quot;) or one of its
standard inflexional forms (e.g., &amp;quot;storing&amp;quot;). For
example, the following definitions are excerpted from
the Oxford Advanced Learner&apos;s Dictionary (OALD):
storage n [1.1] (space used for, money paid for)
the storing of goods ...
diversion is [LI] diverting ...
procession n [C] number of persons, vehicles,
etc moving forward and following each other in
an orderly way.
Therefore, we can reduce &amp;quot;diversion&amp;quot; to &amp;quot;divert&amp;quot; by
removing the suffix &amp;quot;+sion&amp;quot; and adding root form
suffix &amp;quot;+t&amp;quot;. On the other hand, &amp;quot;process+ion&amp;quot; is not
reduced to &amp;quot;process&amp;quot;.
Experiments with CACM-3204 collection
show an improvement in retrieval precision by 6% to
8% over the base system equipped with a standard
morphological stemmer (in our case, the SMART
stemmer).
</bodyText>
<sectionHeader confidence="0.906682" genericHeader="method">
HEAD-MODIFIER STRUCTURES
</sectionHeader>
<bodyText confidence="0.86044115625">
Syntactic phrases extracted from TrP parse
trees are head-modifier pairs: from simple word pairs
to complex nested structures. The head in such a pair
is a central element of a phrase (verb, main noun,
etc.) while the modifier is one of the adjunct argu-
ments of the head.7 For example, the phrase fast
algorithm for parsing context-free languages yields
the following pairs: algorithm+fast,
algorithm+parse, parse+language,
language+context free. The following types of pairs
were considered: (1) a head noun and its left adjec-
tive or noun adjunct, (2) a head noun and the head of
its right adjunct, (3) the main verb of a clause and the
head of its object phrase, and (4) the head of the sub-
ject phrase and the main verb, These types of pairs
account for most of the syntactic variants for relating
two words (or simple phrases) into pairs carrying
compatible semantic content. For example, the pair
retrieve+information is extracted from any of the fol-
lowing fragments: information retrieval system;
retrieval of information from databases; and informa-
tion that can be retrieved by a user-controlled
interactive search process. An example is shown in
Figure 1.8 One difficulty in obtaining head-modifier
7 In the experiments reported here we extracted head-
modifier word pairs only. CACM collection is too small to warrant
generation of larger compounds, because of their low frequencies.
Note that working with the parsed text ensures a high de-
gree of precision in capturing the meaningful phrases, which is
especially evident when compared with the results usually obtained
from either unprocessed or only partially processed text (Lewis and
Croft, 1990).
</bodyText>
<page confidence="0.993882">
106
</page>
<bodyText confidence="0.882742">
SENTENCE:
The techniques are discussed and related to a general
tape manipulation routine.
</bodyText>
<equation confidence="0.290646333333333">
PARSE STRUCTURE:
De],
[[verb,[and,[discuss],[relate]]],
[subject,anyone],
[object,[np,[n,technique],[t_pos,the]]],
[to,[np,[n,routine],[t_pos,a],[adj,[general]],
[n_posanpin,manipulation]]],
[n_pos,[np,[n,tapefi]]]]].
EXTRACTED PAIRS:
[discuss,technique], [relate,technique],
[routine,general], [routine,m anipulate] ,
[manipulatettape]
</equation>
<figureCaption confidence="0.999484">
Figure 1. Extraction of syntactic pairs.
</figureCaption>
<bodyText confidence="0.999955636363636">
pairs of highest accuracy is the notorious ambiguity
of nominal compounds. For example, the phrase
natural language processing should generate
language+natural and processing+language, while
dynamic information processing is expected to yield
processing+dynamic and processing+information.
Since our parser has no knowledge about the text
domain, and uses no semantic preferences, it does not
attempt to guess any internal associations within such
phrases. Instead, this task is passed to the pair extrac-
tor module which processes ambiguous parse struc-
tures in two phases. In phase one, all and only unam-
biguous head-modifier pairs are extracted, and fre-
quencies of their occurrence are recorded. In phase
two, frequency information of pairs generated in the
first pass is used to form associations from ambigu-
ous structures. For example, if language+natural has
occurred unambiguously a number times in contexts
such as parser for natural language, while
processing+natural has occurred significantly fewer
times or perhaps none at all, then we will prefer the
former association as valid.
</bodyText>
<sectionHeader confidence="0.998611" genericHeader="method">
TERM CORRELATIONS FROM TEXT
</sectionHeader>
<bodyText confidence="0.999978783333333">
Head-modifier pairs form compound terms
used in database indexing. They also serve as
occurrence contexts for smaller terms, including
single-word terms. In order to determine whether
such pairs signify any important association between
terms, we calculate the value of the Informational
Contribution (IC) function for each element in a pair.
Higher values indicate stronger association, and the
element having the largest value is considered
semantically dominant.
The connection between the terms co-
occurrences and the information they are transmitting
(or otherwise, their meaning) was established and
discussed in detail by Harris (1968, 1982, 1991) as
fundamental for his mathematical theory of language.
This theory is related to mathematical information
theory, which formalizes the dependencies between
the information and the probability distribution of the
given code (alphabet or language). As stated by
Shannon (1948), information is measured by entropy
which gives the capacity of the given code, in terms
of the probabilities of its particular signs, to transmit
information. It should be emphasized that, according
to the information theory, there is no direct relation
between information and meaning, entropy giving
only a measure of what possible choices of messages
are offered by a particular language. However, it
offers theoretic foundations of the correlation
between the probability of an event and transmitted
information, and it can be further developed in order
to capture the meaning of a message. There is indeed
an inverse relation between information contributed
by a word and its probability of occurrence p, that is,
rare words carry more information than common
ones. This relation can be given by the function
—log p(x) which corresponds to information which a
single word is contributing to the entropy of the
entire language.
In contrast to information theory, the goal of
the present study is not to calculate informational
capacities of a language, but to measure the relative
strength of connection between the words in syntactic
pairs. This connection corresponds to Harris&apos; likeli-
hood constraint, where the likelihood of an operator
with respect to its argument words (or of an argument
word in respect to different operators) is defined
using word-combination frequencies within the
linguistic dependency structures. Further, the likeli-
hood of a given word being paired with another
word, within one operator-argument structure, can be
expressed in statistical terms as a conditional proba-
bility. In our present approach, the required measure
had to be uniform for all word occurrences, covering
a number of different operator-argument structures.
This is reflected by an additional dispersion parame-
ter, introduced to evaluate the heterogeneity of word
associations. The resulting new formula IC (x, [x,y])
is based on (an estimate of) the conditional probabil-
ity of seeing a word y to the right of the word x,
modified with a dispersion parameter for X.
</bodyText>
<equation confidence="0.992691">
(x,[x,y]) — nx + dx — 1
</equation>
<bodyText confidence="0.998952333333333">
where fx,y is the frequency of [x,y I in the corpus, nx
is the number of pairs in which x occurs at the same
position as in [x,y], and d(x) is the dispersion
</bodyText>
<page confidence="0.997741">
107
</page>
<bodyText confidence="0.999827111111111">
parameter understood as the number of distinct words
with which x is paired. When IC (x, [x,y1) = 0, x and
y never occur together (i.e., = 0); when
IC (x, fx,y])= 1, x occurs only with y (i.e., f, =
and dx = 1).
So defined, IC function is asymmetric, a pro-
perty found desirable by Wilks et al. (1990) in their
study of word co-occurrences in the Longman dic-
tionary. In addition, IC is stable even for relatively
low frequency words, which can be contrasted with
Fano&apos;s mutual information formula recently used by
Church and Hanks (1990) to compute word co-
occurrence patterns in a 44 million word corpus of
Associated Press news stories. They noted that while
generally satisfactory, the mutual information for-
mula often produces counterintuitive results for low-
frequency data. This is particularly worrisome for
relatively smaller IR collections since many impor-
tant indexing terms would be eliminated from con-
sideration. A few examples obtained from CACM-
3204 corpus are listed in Table 1. IC values for terms
become the basis for calculating term-to-term simi-
larity coefficients. If two terms tend to be modified
with a number of common modifiers and otherwise
appear in few distinct contexts, we assign them a
similarity coefficient, a real number between 0 and 1.
The similarity is determined by comparing distribu-
tion characteristics for both terms within the corpus:
how much information contents do they carry, do
their information contribution over contexts vary
greatly, are the common contexts in which these
terms occur specific enough? In general we will
credit high-contents terms appearing in identical con-
texts, especially if these contexts are not too com-
monplace.9 The relative similarity between two
words x1 and x2 is obtained using the following for-
</bodyText>
<equation confidence="0.9972835">
mula (a is a large constant): 10
S/M(x1,x2) = log (cc Z simy(x 1,x 2))
</equation>
<bodyText confidence="0.861258333333333">
where
simy(xi,x 2) = MIN (IC (x , [x 1 ,y (x2, [x 2,y ]))
* (IC (y,[x 1,y]) + IC (y,[x2,y]))
The similarity function is further normalized with
respect to SIM (x1,x 1). It may be worth pointing out
that the similarities are calculated using term co-
It would not be appropriate to predict similarity between
language and logarithm on the basis of their co-occurrence with
natural.
</bodyText>
<footnote confidence="0.886925666666667">
19 This is inspired by a formula used by Hindle (1990), and
subsequently modified to take into account the asymmetry of IC
measure.
</footnote>
<table confidence="0.99977432">
word head+modifier IC coeff.
distribute distribute +normal 0.040
normal distribute +normal 0.115
minimum minimum+relative 0.200
relative minimum+relative 0.016
retrieve retrieve +inform 0.086
inform retrieve +inform 0.004
size size +medium 0.009
medium size+medium 0.250
editor editor+text 0.142
text editor+text 0.025
system system+parallel 0.001
parallel system+parallel 0.014
read read-i- character 0.023
character read+character 0.007
implicate implicate+ legal 0.035
legal implicate+legal 0.083
system system+distribute 0.002
distribute system+distribute 0.037
make make +recommend 0.024
recommend make+recommend 0.142
infer infer+deductive 0.095
deductive infer+deductive 0.142
share share +resource 0.054
resource share +resource 0.042
</table>
<tableCaption confidence="0.999838">
Table 1. IC coefficients obtained from CACM-3204
</tableCaption>
<bodyText confidence="0.9956592">
occurrences in syntactic rather than in document-size
contexts, the latter being the usual practice in non-
linguistic clustering (eg. Sparck Jones and Barber,
1971; Crouch, 1988; Lewis and Croft, 1990).
Although the two methods of term clustering may be
considered mutually complementary in certain situa-
tions, we believe that more and stronger associations
can be obtained through syntactic-context clustering,
given sufficient amount of data and a reasonably
accurate syntactic parser.11
</bodyText>
<sectionHeader confidence="0.955657" genericHeader="method">
QUERY EXPANSION
</sectionHeader>
<bodyText confidence="0.9963745">
Similarity relations are used to expand user
queries with new terms, in an attempt to make the
</bodyText>
<footnote confidence="0.84763875">
11 Non-syntactic contexts cross sentence boundaries with no
fuss, which is helpful with short, succinct documents (such as
CACM abstracts), but less so with longer texts; see also (Grishman
et a., 1986).
</footnote>
<page confidence="0.998258">
108
</page>
<bodyText confidence="0.999994025">
final search query more comprehensive (adding
synonyms) and/or more pointed (adding specializa-
tions).12 It follows that not all similarity relations will
be equally useful in query expansion, for instance,
complementary relations like the one between algol
and fortran may actually harm system&apos;s performance,
since we may end up retrieving many irrelevant
documents. Similarly, the effectiveness of a query
containing fortran is likely to diminish if we add a
similar but far more general term such as language.
On the other hand, database search is likely to miss
relevant documents if we overlook the fact that for-
tran is a programming language, or that interpolate
is a specification of approximate. We noted that an
average set of similarities generated from a text
corpus contains about as many &amp;quot;good&amp;quot; relations
(synonymy, specialization) as &amp;quot;bad&amp;quot; relations (anto-
nymy, complementation, generalization), as seen
from the query expansion viewpoint. Therefore any
attempt to separate these two classes and to increase
the proportion of &amp;quot;good&amp;quot; relations should result in
improved retrieval. This has indeed been confirmed
in our experiments where a relatively crude filter has
visibly increased retrieval precision.
In order to create an appropriate filter, we
expanded the IC function into a global specificity
measure called the cumulative informational contri-
bution function (ICW). ICW is calculated for each
term across all contexts in which it occurs. The gen-
eral philosophy here is that a more specific
word/phrase would have a more limited use, i.e.,
would appear in fewer distinct contexts. ICW is simi-
lar to the standard inverted document frequency (id&apos;)
measure except that term frequency is measured over
syntactic units rather than document size units.13
Terms with higher ICW values are generally con-
sidered more specific, but the specificity comparison
is only meaningful for terms which are already
known to be similar. The new function is calculated
according to the following formula:
</bodyText>
<equation confidence="0.778376">
{/CL(w) * ICR(w) if both exist
ICW (w)= ICR(w) if only ICR(w) exists
0 otherwise
</equation>
<footnote confidence="0.824902833333333">
12 Query expansion (in the sense considered here, though not
quite in the same way) has been used in information retrieval
research before (eg. Sparck Jones and Tait, 1984; Hannan, 1988),
usually with mixed results. An alternative is to use term clusters to
create new terms, &amp;quot;metaterms&amp;quot;, and use them to index the database
instead (eg. Crouch, 1988; Lewis and Croft, 1990). We found that
the query expansion approach gives the system more flexibility, for
instance, by making room for hypertext-style topic exploration via
user feedback.
13 We believe that measuring term specificity over
document-size contexts (eg. Sparck Jones, 1972) may not be ap-
propriate in this case. In particular, syntax-based contexts allow for
</footnote>
<bodyText confidence="0.951699555555556">
where (with nw, db„, &gt;
dw(nw+4-1)
For any two terms w1 and w2, and a constant 6&gt; 1,
if ICW(w2) 8 * /CW(w ) then w2 is considered
more specific than &apos; w1. In addition, if
S/M,(w ,w2) = a&gt; 0, where 0 is an empirically
established threshold, then w2 can be added to the
query containing term w1 with weight a.14 In the
CACM-3204 collection:
</bodyText>
<table confidence="0.988584">
ICW (algol) = 0.0020923
ICW (language) = 0.0000145
ICW (approximate) =0.0000218
ICW (interpolate) = 0.0042410
</table>
<bodyText confidence="0.999403266666667">
Therefore interpolate can be used to specialize
approximate, while language cannot be used to
expand algol. Note that if 8 is well chosen (we used
6=10), then the above filter will also help to reject
antonymous and complementary relations, such as
SIM„1(pl_i,cobol)=0.685 with ICW (p/i).0175
and ICW (cobol).0289. We continue working to
develop more effective filters. Examples of filtered
similarity relations obtained from CACM-3204
corpus (and their sim values): abstract graphical
0.612; approximate interpolate 0.655; linear ordi-
nary 0.743; program translate 0.5%; storage buffer
0.622. Some (apparent?) failures: active digital
0.633; efficient new 0.580; gamma beta 0.720. More
similarities are listed in Table 2.
</bodyText>
<sectionHeader confidence="0.990893" genericHeader="conclusions">
SUMMARY OF RESULTS
</sectionHeader>
<bodyText confidence="0.989587058823529">
The preliminary series of experiments with the
CACM-3204 collection of computer science abstracts
showed a consistent improvement in performance:
the average precision increased from 32.8% to 37.1%
(a 13% increase), while the normalized recall went
from 74.3% to 84.5% (a 14% increase), in com-
parison with the statistics of the base NIST system.
This improvement is a combined effect of the new
stemmer, compound terms, term selection in queries,
and query expansion using filtered similarity rela-
tions. The choice of similarity relation filter has been
found critical in improving retrieval precision
through query expansion. It should also be pointed
out that only about 1.5% of all similarity relations
originally generated from CACM-3204 were found
processing texts without any internal document structure.
14 The filter was most effective at a = 0.57.
</bodyText>
<equation confidence="0.978071666666667">
/CL(w) = /C aw,_ — dw(nw+4-1)
nw
ICR(w) = IC ([_,w]) —
</equation>
<page confidence="0.996418">
109
</page>
<table confidence="0.999902230769231">
wordl word2 SIMnorm
*aim purpose 0.434
algorithm method 0.529
*adjacency pair 0.499
*algebraic symbol 0.514
*amen* can standard 0.719
assert infer 0.783
*buddy time-share 0.622
committee *symposium 0.469
critical final 0.680
best-fit first-fit 0.871
*duplex reliable 0.437
earlier previous 0.550
encase minimum-area 0.991
give present 0.458
incomplete miss 0.850
lead *trail 0.890
mean *standard 0.634
method technique 0.571
memory storage 0.613
match recognize 0.563
lower upper 0.841
progress *trend 0.444
range variety 0.600
round-off truncate 0.918
remote teletype 0.509
</table>
<tableCaption confidence="0.8277045">
Table 2. Filtered word similarities (* indicates the
more specific term).
</tableCaption>
<bodyText confidence="0.931936153846154">
admissible after filtering, contributing only 1.2
expansion on average per query. It is quite evident
significantly larger corpora are required to produce
more dramatic results.15 16 A detailed summary is
given in Table 3 below.
These results, while quite modest by IR stan-
dards, are significant for another reason as well. They
were obtained without any manual intervention into
the database or queries, and without using any other
&amp;quot; KL Kwok (private communication) has suggested that the
low percentage of admissible relations might be similar to the
phenomenon of &apos;tight dusters&apos; which while meaningful are so few
that their impact is small.
</bodyText>
<footnote confidence="0.77335825">
&amp;quot; A sufficiently large text corpus is 20 million words or
more. This has been partially confirmed by experiments performed
at the University of Massachussetts (B. Croft, private communica-
tion).
</footnote>
<table confidence="0.999926294117647">
Tests base I suff.trim I query exp.
Recall Precision
0.00 0.764 0.775 0.793
0.10 0.674 0.688 0.700
0.20 0.547 0.547 0.573
0.30 0.449 0.479 0.486
0.40 0.387 0.421 0.421
0.50 0.329 0.356 0.372
0.60 0.273 0.280 0.304
0.70 0.198 0.222 0.226
0.80 0.146 0.170 0.174
0.90 0.093 0.112 0.114
1.00 0.079 0.087 0.090
Avg. Prec. 0.328 0.356 0.371
% change 8.3 13.1
Norm Rec. 0.743 0.841 0.842
Queries 50 50 50
</table>
<tableCaption confidence="0.999763">
Table 3. Recall/precision statistics for CACM-3204
</tableCaption>
<bodyText confidence="0.99987675">
information about the database except for the text of
the documents (i.e., not even the hand generated key-
word fields enclosed with most documents were
used). Lewis and Croft (1990), and Croft et al. (1991)
report results similar to ours but they take advantage
of Computer Reviews categories manually assigned
to some documents. The purpose of this research is to
explore the potential of automated NLP in dealing
with large scale IR problems, and not necessarily to
obtain the best possible results on any particular data
collection. One of our goals is to point a feasible
direction for integrating NLP into the traditional M.
</bodyText>
<sectionHeader confidence="0.99784" genericHeader="acknowledgments">
ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.999828928571429">
We would like to thank Donna Harman of
NIST for making her IR system available to us. We
would also like to thank Ralph Weischedel, Marie
Meteer and Heidi Fox of BBN for providing and
assisting in the use of the part of speech tagger. KL
Kwok has offered many helpful comments on an ear-
lier draft of this paper. In addition, ACM has gen-
erously provided us with text data from the Computer
Library database distributed by Ziff Communications
Inc. This paper is based upon work supported by the
Defense Advanced Research Project Agency under
Contract N00014-9044851 from the Office of Naval
Research, the National Science Foundation under
Grant IRI-89-02304, and a grant from the Swiss
</bodyText>
<page confidence="0.993423">
110
</page>
<note confidence="0.888686">
National Foundation for Scientific Research. We also
acknowledge a support from Canadian Institute for
Robotics and Intelligent Systems (IRIS).
</note>
<sectionHeader confidence="0.975558" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.995149551020409">
Church, Kenneth Ward and Hanks, Patrick. 1990.
&amp;quot;Word association norms, mutual informa-
tion, and lexicography.&amp;quot; Computational
Linguistics, 16(1), MIT Press, pp. 22-29.
Croft, W. Bruce, Howard R. Turtle, and David D.
Lewis. 1991. &amp;quot;The Use of Phrases and Struc-
tured Queries in Information Retrieval.&amp;quot;
Proceedings of ACM SIGIR-91, pp. 32-45.
Crouch, Carolyn J. 1988. &amp;quot;A cluster-based approach
to thesaurus construction.&amp;quot; Proceedings of
ACM SIGIR-88, pp. 309-320.
Fagan, Joel L. 1987. Experiments in Automated
Phrase Indexing for Document Retrieval: A
Comparison of Syntactic and Non-Syntactic
Methods. Ph.D. Thesis, Department of Com-
puter Science, Cornell University.
Grishman, Ralph, Lynette Hirschman, and Ngo T.
Nhan. 1986. &amp;quot;Discovery procedures for sub-
language selectional patterns: initial experi-
ments&amp;quot;. Computational Linguistics, 12(3), pp.
205-215.
Grishtnan, Ralph and Tomek Strzalkowski. 1991.
&amp;quot;Information Retrieval and Natural Language
Processing.&amp;quot; Position paper at the workshop
on Future Directions in Natural Language Pro-
cessing in Information Retrieval, Chicago.
Harman, Donna. 1988. &amp;quot;Towards interactive query
expansion.&amp;quot; Proceedings of ACM SIGIR-88,
pp. 321-331.
Harman, Donna and Gerald Candela. 1989.
&amp;quot;Retrieving Records from a Gigabyte of text
on a Minicomputer Using Statistical Rank-
ing.&amp;quot; Journal of the American Society for
Information Science, 41(8), pp. 581-589.
Harris, Zelig S. 1991. A Theory of language and
Information. A Mathematical Approach.
Cladendon Press. Oxford.
Harris, Zelig S. 1982. A Grammar of English on
Mathematical Principles. Wiley.
Harris, Zelig S. 1968. Mathematical Structures of
Language. Wiley.
Hindle, Donald. 1990. &amp;quot;Noun classification from
predicate-argument structures.&amp;quot; Proc. 28
Meeting of the ACL, Pittsburgh, PA, pp. 268-
275.
Lewis, David D. and W. Bruce Croft. 1990. &amp;quot;Term
Clustering of Syntactic Phrases&amp;quot;. Proceedings
of ACM SIGIR-90, pp. 385-405.
Mauldin, Michael. 1991. &amp;quot;Retrieval Performance in
Ferret: A Conceptual Information Retrieval
System.&amp;quot; Proceedings of ACM SIGIR-91, pp.
347-355.
Sager, Naomi. 1981. Natural Language Information
Processing. Addison-Wesley.
Salton, Gerard. 1989. Automatic Text Processing:
the transformation, analysis, and retrieval of
information by computer. Addison-Wesley,
Reading, MA.
Shannon, C. E. 1948. &amp;quot;A mathematical theory of
communication.&amp;quot; Bell System Technical
Journal, vol. 27, July-October.
Smeaton, A. F. and C. J. van Rijsbergen. 1988.
&amp;quot;Experiments on incorporating syntactic pro-
cessing of user queries into a document
retrieval strategy.&amp;quot; Proceedings of ACM
SIG1R-88, pp. 31-51.
Sparck Jones, Karen. 1972. &amp;quot;Statistical interpreta-
tion of term specificity and its application in
retrieval.&amp;quot; Journal of Documentation, 28(1),
pp. 11-20.
Sparck Jones, K. and E. 0. Barber. 1971. &amp;quot;What
makes automatic keyword classification effec-
tive?&amp;quot; Journal of the American Society for
Information Science, May-June, pp. 166-175.
Sparck Jones, K. and J. I. Tait. 1984. &amp;quot;Automatic
search term variant generation.&amp;quot; Journal of
Documentation, 40(1), pp. 50-66.
Strzalkowski, Tomek and Barbara Vauthey. 1991.
&amp;quot;Fast Text Processing for Information
Retrieval.&amp;quot; Proceedings of the 4th DARPA
Speech and Natural Language Workshop,
Morgan-Kaufman, pp. 346-351.
Strzalkowski, Tomek and Barbara Vauthey. 1991.
&amp;quot;Natural Language Processing in Automated
Information Retrieval.&amp;quot; Proteus Project
Memo #42, Courant Institute of Mathematical
Science, New York University.
Strzalkowski, Tomek. 1992. &amp;quot;TTP: A Fast and
Robust Parser for Natural Language.&amp;quot;
Proceedings of the 14th International Confer-
ence on Computational Linguistics (COL-
ING), Nantes, France, July 1992.
Wilks, Yorick A., Dan Fass, Cheng-Ming Guo,
James E. McDonald, Tony Plate, and Brian M.
Slator. 1990. &amp;quot;Providing machine tractable
dictionary tools.&amp;quot; Machine Translation, 5, pp.
99-154.
1 1 1
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.933147">
<title confidence="0.996379">INFORMATION RETRIEVAL USING ROBUST NATURAL LANGUAGE PROCESSING</title>
<author confidence="0.999296">Tomek Strzalkowski</author>
<author confidence="0.999296">Barbara Vautheyt</author>
<affiliation confidence="0.996896">Courant Institute of Mathematical Sciences New York University</affiliation>
<address confidence="0.9981165">715 Broadway, rm. 704 New York, NY 10003</address>
<email confidence="0.999329">tomek@cs.nyu.edu</email>
<abstract confidence="0.995345615384615">We developed a prototype information retrieval system which uses advanced natural language processing techniques to enhance the effectiveness of traditional key-word based document retrieval. The backbone of our system is a statistical retrieval engine which performs automated indexing of documents, then search and ranking in response to user queries. This core architecture is augmented with advanced natural language processing tools which are both robust and efficient. In early experiments, the augmented system has displayed capabilities that appear to make it superior to the purely statistical base.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kenneth Ward Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.&amp;quot;</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<pages>22--29</pages>
<publisher>MIT Press,</publisher>
<contexts>
<context position="19520" citStr="Church and Hanks (1990)" startWordPosition="2972" endWordPosition="2975">irs in which x occurs at the same position as in [x,y], and d(x) is the dispersion 107 parameter understood as the number of distinct words with which x is paired. When IC (x, [x,y1) = 0, x and y never occur together (i.e., = 0); when IC (x, fx,y])= 1, x occurs only with y (i.e., f, = and dx = 1). So defined, IC function is asymmetric, a property found desirable by Wilks et al. (1990) in their study of word co-occurrences in the Longman dictionary. In addition, IC is stable even for relatively low frequency words, which can be contrasted with Fano&apos;s mutual information formula recently used by Church and Hanks (1990) to compute word cooccurrence patterns in a 44 million word corpus of Associated Press news stories. They noted that while generally satisfactory, the mutual information formula often produces counterintuitive results for lowfrequency data. This is particularly worrisome for relatively smaller IR collections since many important indexing terms would be eliminated from consideration. A few examples obtained from CACM3204 corpus are listed in Table 1. IC values for terms become the basis for calculating term-to-term similarity coefficients. If two terms tend to be modified with a number of commo</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Church, Kenneth Ward and Hanks, Patrick. 1990. &amp;quot;Word association norms, mutual information, and lexicography.&amp;quot; Computational Linguistics, 16(1), MIT Press, pp. 22-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Bruce Croft</author>
<author>Howard R Turtle</author>
<author>David D Lewis</author>
</authors>
<title>The Use of Phrases and Structured Queries in Information Retrieval.&amp;quot;</title>
<date>1991</date>
<booktitle>Proceedings of ACM SIGIR-91,</booktitle>
<pages>32--45</pages>
<contexts>
<context position="4598" citStr="Croft et al., 1991" startWordPosition="668" endWordPosition="671">periments can easily produce counterintuitive results. For example, Cranfield collection is only approx. 180,000 English words, while CACM-3204 collection used in the present experiments is approx. 200,000 words. 104 We believe that linguistic processing of both the database and the user&apos;s queries need to be done for a maximum benefit, and moreover, the two processes must be appropriately coordinated. This prognosis is supported by the experiments performed by the NYU group (Strzalkowski and Vauthey, 1991; Grishman and Strzalkowski, 1991), and by the group at the University of Massachussetts (Croft et al., 1991). We explore this possibility further in this paper. OVERALL DESIGN Our information retrieval system consists of a traditional statistical backbone (Harman and Candela, 1989) augmented with various natural language processing components that assist the system in database processing (stemming, indexing, word and phrase clustering, selectional restrictions), and translate a user&apos;s information request into an effective query. This design is a careful compromise between purely statistical non-linguistic approaches and those requiring rather accomplished (and expensive) semantic analysis of data, o</context>
<context position="29988" citStr="Croft et al. (1991)" startWordPosition="4589" endWordPosition="4592">Recall Precision 0.00 0.764 0.775 0.793 0.10 0.674 0.688 0.700 0.20 0.547 0.547 0.573 0.30 0.449 0.479 0.486 0.40 0.387 0.421 0.421 0.50 0.329 0.356 0.372 0.60 0.273 0.280 0.304 0.70 0.198 0.222 0.226 0.80 0.146 0.170 0.174 0.90 0.093 0.112 0.114 1.00 0.079 0.087 0.090 Avg. Prec. 0.328 0.356 0.371 % change 8.3 13.1 Norm Rec. 0.743 0.841 0.842 Queries 50 50 50 Table 3. Recall/precision statistics for CACM-3204 information about the database except for the text of the documents (i.e., not even the hand generated keyword fields enclosed with most documents were used). Lewis and Croft (1990), and Croft et al. (1991) report results similar to ours but they take advantage of Computer Reviews categories manually assigned to some documents. The purpose of this research is to explore the potential of automated NLP in dealing with large scale IR problems, and not necessarily to obtain the best possible results on any particular data collection. One of our goals is to point a feasible direction for integrating NLP into the traditional M. ACKNOWLEDGEMENTS We would like to thank Donna Harman of NIST for making her IR system available to us. We would also like to thank Ralph Weischedel, Marie Meteer and Heidi Fox </context>
</contexts>
<marker>Croft, Turtle, Lewis, 1991</marker>
<rawString>Croft, W. Bruce, Howard R. Turtle, and David D. Lewis. 1991. &amp;quot;The Use of Phrases and Structured Queries in Information Retrieval.&amp;quot; Proceedings of ACM SIGIR-91, pp. 32-45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carolyn J Crouch</author>
</authors>
<title>A cluster-based approach to thesaurus construction.&amp;quot;</title>
<date>1988</date>
<booktitle>Proceedings of ACM SIGIR-88,</booktitle>
<pages>309--320</pages>
<contexts>
<context position="22302" citStr="Crouch, 1988" startWordPosition="3392" endWordPosition="3393"> system+parallel 0.014 read read-i- character 0.023 character read+character 0.007 implicate implicate+ legal 0.035 legal implicate+legal 0.083 system system+distribute 0.002 distribute system+distribute 0.037 make make +recommend 0.024 recommend make+recommend 0.142 infer infer+deductive 0.095 deductive infer+deductive 0.142 share share +resource 0.054 resource share +resource 0.042 Table 1. IC coefficients obtained from CACM-3204 occurrences in syntactic rather than in document-size contexts, the latter being the usual practice in nonlinguistic clustering (eg. Sparck Jones and Barber, 1971; Crouch, 1988; Lewis and Croft, 1990). Although the two methods of term clustering may be considered mutually complementary in certain situations, we believe that more and stronger associations can be obtained through syntactic-context clustering, given sufficient amount of data and a reasonably accurate syntactic parser.11 QUERY EXPANSION Similarity relations are used to expand user queries with new terms, in an attempt to make the 11 Non-syntactic contexts cross sentence boundaries with no fuss, which is helpful with short, succinct documents (such as CACM abstracts), but less so with longer texts; see a</context>
<context position="25367" citStr="Crouch, 1988" startWordPosition="3869" endWordPosition="3870"> more specific, but the specificity comparison is only meaningful for terms which are already known to be similar. The new function is calculated according to the following formula: {/CL(w) * ICR(w) if both exist ICW (w)= ICR(w) if only ICR(w) exists 0 otherwise 12 Query expansion (in the sense considered here, though not quite in the same way) has been used in information retrieval research before (eg. Sparck Jones and Tait, 1984; Hannan, 1988), usually with mixed results. An alternative is to use term clusters to create new terms, &amp;quot;metaterms&amp;quot;, and use them to index the database instead (eg. Crouch, 1988; Lewis and Croft, 1990). We found that the query expansion approach gives the system more flexibility, for instance, by making room for hypertext-style topic exploration via user feedback. 13 We believe that measuring term specificity over document-size contexts (eg. Sparck Jones, 1972) may not be appropriate in this case. In particular, syntax-based contexts allow for where (with nw, db„, &gt; dw(nw+4-1) For any two terms w1 and w2, and a constant 6&gt; 1, if ICW(w2) 8 * /CW(w ) then w2 is considered more specific than &apos; w1. In addition, if S/M,(w ,w2) = a&gt; 0, where 0 is an empirically established</context>
</contexts>
<marker>Crouch, 1988</marker>
<rawString>Crouch, Carolyn J. 1988. &amp;quot;A cluster-based approach to thesaurus construction.&amp;quot; Proceedings of ACM SIGIR-88, pp. 309-320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel L Fagan</author>
</authors>
<title>Experiments in Automated Phrase Indexing for Document Retrieval: A Comparison of Syntactic and Non-Syntactic Methods.</title>
<date>1987</date>
<tech>Ph.D. Thesis,</tech>
<institution>Department of Computer Science, Cornell University.</institution>
<contexts>
<context position="2871" citStr="Fagan, 1987" startWordPosition="414" endWordPosition="415">sidered conclusive because of their very limited scale. Another reason is the limited scale at which NLP was used. Syntactic parsing of the database contents, for example, has been attempted in order to extract linguistically motivated &amp;quot;syntactic phrases&amp;quot;, which presumably were better indicators of contents than &amp;quot;statistical phrases&amp;quot; where words were grouped solely on the basis of physical proximity (eg. &amp;quot;college junior&amp;quot; is not the same as &amp;quot;junior college&amp;quot;). These intuitions, however, were not confirmed by experiments; worse still, statistical phrases regularly outperformed syntactic phrases (Fagan, 1987). Attempts to overcome the poor statistical behavior of syntactic phrases has led to various clustering techniques that grouped synonymous or near synonymous phrases into &amp;quot;clusters&amp;quot; and replaced these by single &amp;quot;metaterms&amp;quot;. Clustering techniques were somewhat successful in upgrading overall system performance, but their effectiveness was diminished by frequently poor quality of syntactic analysis. Since full-analysis wide-coverage syntactic parsers were either unavailable or inefficient, various partial parsing methods have been used. Partial parsing was usually fast enough, but it also genera</context>
</contexts>
<marker>Fagan, 1987</marker>
<rawString>Fagan, Joel L. 1987. Experiments in Automated Phrase Indexing for Document Retrieval: A Comparison of Syntactic and Non-Syntactic Methods. Ph.D. Thesis, Department of Computer Science, Cornell University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
<author>Lynette Hirschman</author>
<author>Ngo T Nhan</author>
</authors>
<title>Discovery procedures for sublanguage selectional patterns: initial experiments&amp;quot;.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<pages>205--215</pages>
<marker>Grishman, Hirschman, Nhan, 1986</marker>
<rawString>Grishman, Ralph, Lynette Hirschman, and Ngo T. Nhan. 1986. &amp;quot;Discovery procedures for sublanguage selectional patterns: initial experiments&amp;quot;. Computational Linguistics, 12(3), pp. 205-215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishtnan</author>
<author>Tomek Strzalkowski</author>
</authors>
<title>Information Retrieval and Natural Language Processing.&amp;quot; Position paper at the workshop on</title>
<date>1991</date>
<booktitle>Future Directions in Natural Language Processing in Information Retrieval,</booktitle>
<location>Chicago.</location>
<marker>Grishtnan, Strzalkowski, 1991</marker>
<rawString>Grishtnan, Ralph and Tomek Strzalkowski. 1991. &amp;quot;Information Retrieval and Natural Language Processing.&amp;quot; Position paper at the workshop on Future Directions in Natural Language Processing in Information Retrieval, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donna Harman</author>
</authors>
<title>Towards interactive query expansion.&amp;quot;</title>
<date>1988</date>
<booktitle>Proceedings of ACM SIGIR-88,</booktitle>
<pages>321--331</pages>
<marker>Harman, 1988</marker>
<rawString>Harman, Donna. 1988. &amp;quot;Towards interactive query expansion.&amp;quot; Proceedings of ACM SIGIR-88, pp. 321-331.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donna Harman</author>
<author>Gerald Candela</author>
</authors>
<title>Retrieving Records from a Gigabyte of text on a Minicomputer Using Statistical Ranking.&amp;quot;</title>
<date>1989</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>41</volume>
<issue>8</issue>
<pages>581--589</pages>
<contexts>
<context position="4772" citStr="Harman and Candela, 1989" startWordPosition="692" endWordPosition="695">resent experiments is approx. 200,000 words. 104 We believe that linguistic processing of both the database and the user&apos;s queries need to be done for a maximum benefit, and moreover, the two processes must be appropriately coordinated. This prognosis is supported by the experiments performed by the NYU group (Strzalkowski and Vauthey, 1991; Grishman and Strzalkowski, 1991), and by the group at the University of Massachussetts (Croft et al., 1991). We explore this possibility further in this paper. OVERALL DESIGN Our information retrieval system consists of a traditional statistical backbone (Harman and Candela, 1989) augmented with various natural language processing components that assist the system in database processing (stemming, indexing, word and phrase clustering, selectional restrictions), and translate a user&apos;s information request into an effective query. This design is a careful compromise between purely statistical non-linguistic approaches and those requiring rather accomplished (and expensive) semantic analysis of data, often referred to as &apos;conceptual retrieval&apos;. The conceptual retrieval systems, though quite effective, are not yet mature enough to be considered in serious information retrie</context>
</contexts>
<marker>Harman, Candela, 1989</marker>
<rawString>Harman, Donna and Gerald Candela. 1989. &amp;quot;Retrieving Records from a Gigabyte of text on a Minicomputer Using Statistical Ranking.&amp;quot; Journal of the American Society for Information Science, 41(8), pp. 581-589.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zelig S Harris</author>
</authors>
<title>A Theory of language and Information. A Mathematical Approach.</title>
<date>1991</date>
<publisher>Cladendon Press.</publisher>
<location>Oxford.</location>
<marker>Harris, 1991</marker>
<rawString>Harris, Zelig S. 1991. A Theory of language and Information. A Mathematical Approach. Cladendon Press. Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zelig S Harris</author>
</authors>
<date>1982</date>
<journal>A Grammar of English on Mathematical</journal>
<publisher>Principles. Wiley.</publisher>
<marker>Harris, 1982</marker>
<rawString>Harris, Zelig S. 1982. A Grammar of English on Mathematical Principles. Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zelig S Harris</author>
</authors>
<date>1968</date>
<booktitle>Mathematical Structures of Language.</booktitle>
<publisher>Wiley.</publisher>
<contexts>
<context position="16439" citStr="Harris (1968" startWordPosition="2468" endWordPosition="2469">pound terms used in database indexing. They also serve as occurrence contexts for smaller terms, including single-word terms. In order to determine whether such pairs signify any important association between terms, we calculate the value of the Informational Contribution (IC) function for each element in a pair. Higher values indicate stronger association, and the element having the largest value is considered semantically dominant. The connection between the terms cooccurrences and the information they are transmitting (or otherwise, their meaning) was established and discussed in detail by Harris (1968, 1982, 1991) as fundamental for his mathematical theory of language. This theory is related to mathematical information theory, which formalizes the dependencies between the information and the probability distribution of the given code (alphabet or language). As stated by Shannon (1948), information is measured by entropy which gives the capacity of the given code, in terms of the probabilities of its particular signs, to transmit information. It should be emphasized that, according to the information theory, there is no direct relation between information and meaning, entropy giving only a </context>
</contexts>
<marker>Harris, 1968</marker>
<rawString>Harris, Zelig S. 1968. Mathematical Structures of Language. Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
</authors>
<title>Noun classification from predicate-argument structures.&amp;quot;</title>
<date>1990</date>
<booktitle>Proc. 28 Meeting of the ACL,</booktitle>
<pages>268--275</pages>
<location>Pittsburgh, PA,</location>
<contexts>
<context position="21256" citStr="Hindle (1990)" startWordPosition="3261" endWordPosition="3262">not too commonplace.9 The relative similarity between two words x1 and x2 is obtained using the following formula (a is a large constant): 10 S/M(x1,x2) = log (cc Z simy(x 1,x 2)) where simy(xi,x 2) = MIN (IC (x , [x 1 ,y (x2, [x 2,y ])) * (IC (y,[x 1,y]) + IC (y,[x2,y])) The similarity function is further normalized with respect to SIM (x1,x 1). It may be worth pointing out that the similarities are calculated using term coIt would not be appropriate to predict similarity between language and logarithm on the basis of their co-occurrence with natural. 19 This is inspired by a formula used by Hindle (1990), and subsequently modified to take into account the asymmetry of IC measure. word head+modifier IC coeff. distribute distribute +normal 0.040 normal distribute +normal 0.115 minimum minimum+relative 0.200 relative minimum+relative 0.016 retrieve retrieve +inform 0.086 inform retrieve +inform 0.004 size size +medium 0.009 medium size+medium 0.250 editor editor+text 0.142 text editor+text 0.025 system system+parallel 0.001 parallel system+parallel 0.014 read read-i- character 0.023 character read+character 0.007 implicate implicate+ legal 0.035 legal implicate+legal 0.083 system system+distribu</context>
</contexts>
<marker>Hindle, 1990</marker>
<rawString>Hindle, Donald. 1990. &amp;quot;Noun classification from predicate-argument structures.&amp;quot; Proc. 28 Meeting of the ACL, Pittsburgh, PA, pp. 268-275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D Lewis</author>
<author>W Bruce Croft</author>
</authors>
<title>Term Clustering of Syntactic Phrases&amp;quot;.</title>
<date>1990</date>
<booktitle>Proceedings of ACM SIGIR-90,</booktitle>
<pages>385--405</pages>
<contexts>
<context position="3569" citStr="Lewis and Croft, 1990" startWordPosition="512" endWordPosition="515">s led to various clustering techniques that grouped synonymous or near synonymous phrases into &amp;quot;clusters&amp;quot; and replaced these by single &amp;quot;metaterms&amp;quot;. Clustering techniques were somewhat successful in upgrading overall system performance, but their effectiveness was diminished by frequently poor quality of syntactic analysis. Since full-analysis wide-coverage syntactic parsers were either unavailable or inefficient, various partial parsing methods have been used. Partial parsing was usually fast enough, but it also generated noisy data: as many as 50% of all generated phrases could be incorrect (Lewis and Croft, 1990). Other efforts concentrated on processing of user queries (eg. Speck Jones and Tait, 1984; Smeaton and van Rijsbergen, 1988). Since queries were usually short and few, even relatively inefficient NLP techniques could be of benefit to the system. None of these attempts proved conclusive, and some were never properly evaluated either. 2 Standard IR benchmark collections are statistically too small and the experiments can easily produce counterintuitive results. For example, Cranfield collection is only approx. 180,000 English words, while CACM-3204 collection used in the present experiments is </context>
<context position="14205" citStr="Lewis and Croft, 1990" startWordPosition="2171" endWordPosition="2174">abases; and information that can be retrieved by a user-controlled interactive search process. An example is shown in Figure 1.8 One difficulty in obtaining head-modifier 7 In the experiments reported here we extracted headmodifier word pairs only. CACM collection is too small to warrant generation of larger compounds, because of their low frequencies. Note that working with the parsed text ensures a high degree of precision in capturing the meaningful phrases, which is especially evident when compared with the results usually obtained from either unprocessed or only partially processed text (Lewis and Croft, 1990). 106 SENTENCE: The techniques are discussed and related to a general tape manipulation routine. PARSE STRUCTURE: De], [[verb,[and,[discuss],[relate]]], [subject,anyone], [object,[np,[n,technique],[t_pos,the]]], [to,[np,[n,routine],[t_pos,a],[adj,[general]], [n_posanpin,manipulation]]], [n_pos,[np,[n,tapefi]]]]]. EXTRACTED PAIRS: [discuss,technique], [relate,technique], [routine,general], [routine,m anipulate] , [manipulatettape] Figure 1. Extraction of syntactic pairs. pairs of highest accuracy is the notorious ambiguity of nominal compounds. For example, the phrase natural language processin</context>
<context position="22326" citStr="Lewis and Croft, 1990" startWordPosition="3394" endWordPosition="3397">el 0.014 read read-i- character 0.023 character read+character 0.007 implicate implicate+ legal 0.035 legal implicate+legal 0.083 system system+distribute 0.002 distribute system+distribute 0.037 make make +recommend 0.024 recommend make+recommend 0.142 infer infer+deductive 0.095 deductive infer+deductive 0.142 share share +resource 0.054 resource share +resource 0.042 Table 1. IC coefficients obtained from CACM-3204 occurrences in syntactic rather than in document-size contexts, the latter being the usual practice in nonlinguistic clustering (eg. Sparck Jones and Barber, 1971; Crouch, 1988; Lewis and Croft, 1990). Although the two methods of term clustering may be considered mutually complementary in certain situations, we believe that more and stronger associations can be obtained through syntactic-context clustering, given sufficient amount of data and a reasonably accurate syntactic parser.11 QUERY EXPANSION Similarity relations are used to expand user queries with new terms, in an attempt to make the 11 Non-syntactic contexts cross sentence boundaries with no fuss, which is helpful with short, succinct documents (such as CACM abstracts), but less so with longer texts; see also (Grishman et a., 198</context>
<context position="25391" citStr="Lewis and Croft, 1990" startWordPosition="3871" endWordPosition="3874">, but the specificity comparison is only meaningful for terms which are already known to be similar. The new function is calculated according to the following formula: {/CL(w) * ICR(w) if both exist ICW (w)= ICR(w) if only ICR(w) exists 0 otherwise 12 Query expansion (in the sense considered here, though not quite in the same way) has been used in information retrieval research before (eg. Sparck Jones and Tait, 1984; Hannan, 1988), usually with mixed results. An alternative is to use term clusters to create new terms, &amp;quot;metaterms&amp;quot;, and use them to index the database instead (eg. Crouch, 1988; Lewis and Croft, 1990). We found that the query expansion approach gives the system more flexibility, for instance, by making room for hypertext-style topic exploration via user feedback. 13 We believe that measuring term specificity over document-size contexts (eg. Sparck Jones, 1972) may not be appropriate in this case. In particular, syntax-based contexts allow for where (with nw, db„, &gt; dw(nw+4-1) For any two terms w1 and w2, and a constant 6&gt; 1, if ICW(w2) 8 * /CW(w ) then w2 is considered more specific than &apos; w1. In addition, if S/M,(w ,w2) = a&gt; 0, where 0 is an empirically established threshold, then w2 can </context>
<context position="29963" citStr="Lewis and Croft (1990)" startWordPosition="4584" endWordPosition="4587">se I suff.trim I query exp. Recall Precision 0.00 0.764 0.775 0.793 0.10 0.674 0.688 0.700 0.20 0.547 0.547 0.573 0.30 0.449 0.479 0.486 0.40 0.387 0.421 0.421 0.50 0.329 0.356 0.372 0.60 0.273 0.280 0.304 0.70 0.198 0.222 0.226 0.80 0.146 0.170 0.174 0.90 0.093 0.112 0.114 1.00 0.079 0.087 0.090 Avg. Prec. 0.328 0.356 0.371 % change 8.3 13.1 Norm Rec. 0.743 0.841 0.842 Queries 50 50 50 Table 3. Recall/precision statistics for CACM-3204 information about the database except for the text of the documents (i.e., not even the hand generated keyword fields enclosed with most documents were used). Lewis and Croft (1990), and Croft et al. (1991) report results similar to ours but they take advantage of Computer Reviews categories manually assigned to some documents. The purpose of this research is to explore the potential of automated NLP in dealing with large scale IR problems, and not necessarily to obtain the best possible results on any particular data collection. One of our goals is to point a feasible direction for integrating NLP into the traditional M. ACKNOWLEDGEMENTS We would like to thank Donna Harman of NIST for making her IR system available to us. We would also like to thank Ralph Weischedel, Ma</context>
</contexts>
<marker>Lewis, Croft, 1990</marker>
<rawString>Lewis, David D. and W. Bruce Croft. 1990. &amp;quot;Term Clustering of Syntactic Phrases&amp;quot;. Proceedings of ACM SIGIR-90, pp. 385-405.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Mauldin</author>
</authors>
<title>Retrieval Performance in Ferret: A Conceptual Information Retrieval System.&amp;quot;</title>
<date>1991</date>
<booktitle>Proceedings of ACM SIGIR-91,</booktitle>
<pages>347--355</pages>
<contexts>
<context position="5510" citStr="Mauldin, 1991" startWordPosition="795" endWordPosition="796">xing, word and phrase clustering, selectional restrictions), and translate a user&apos;s information request into an effective query. This design is a careful compromise between purely statistical non-linguistic approaches and those requiring rather accomplished (and expensive) semantic analysis of data, often referred to as &apos;conceptual retrieval&apos;. The conceptual retrieval systems, though quite effective, are not yet mature enough to be considered in serious information retrieval applications, the major problems being their extreme inefficiency and the need for manual encoding of domain knowledge (Mauldin, 1991). In our system the database text is first processed with a fast syntactic parser. Subsequently certain types of phrases are extracted from the parse trees and used as compound indexing terms in addition to single-word terms. The extracted phrases are statistically analyzed as syntactic contexts in order to discover a variety of similarity links between smaller subphrases and words occurring in them. A further filtering process maps these similarity links onto semantic relations (generalization, specialization, synonymy, etc.) after which they are used to transform user&apos;s request into a search</context>
</contexts>
<marker>Mauldin, 1991</marker>
<rawString>Mauldin, Michael. 1991. &amp;quot;Retrieval Performance in Ferret: A Conceptual Information Retrieval System.&amp;quot; Proceedings of ACM SIGIR-91, pp. 347-355.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naomi Sager</author>
</authors>
<title>Natural Language Information Processing.</title>
<date>1981</date>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="7286" citStr="Sager (1981)" startWordPosition="1069" endWordPosition="1070">ible similarity relations. For example, &amp;quot;fortran&amp;quot; is added to a query containing the compound term &amp;quot;program language&amp;quot; via a specification link. After the final query is constructed, the database search follows, and a ranked list of documents is returned. It should be noted that all the processing steps, those performed by the backbone system, and these performed by the natural language processing components, are fully automated, and no human intervention or manual encoding is required. FAST PARSING WITH 1TP PARSER TTP (Tagged Text Parser) is based on the Linguistic String Grammar developed by Sager (1981). Written in Quintus Prolog, the parser currently encompasses more than 400 grammar productions. It produces regularized parse tree representations for each sentence that reflect the sentence&apos;s logical structure. The parser is equipped with a powerful skip-and-fit recovery mechanism that allows it to operate effectively in the face of illformed input or under a severe time pressure. In the recent experiments with approximately 6 million words of English texts,3 the parser&apos;s speed averaged between 0.45 and 0.5 seconds per sentence, or up to 2600 words per minute, on a 21 MIPS SparcStation ELC. </context>
</contexts>
<marker>Sager, 1981</marker>
<rawString>Sager, Naomi. 1981. Natural Language Information Processing. Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
</authors>
<title>Automatic Text Processing: the transformation, analysis, and retrieval of information by computer.</title>
<date>1989</date>
<publisher>Addison-Wesley,</publisher>
<location>Reading, MA.</location>
<marker>Salton, 1989</marker>
<rawString>Salton, Gerard. 1989. Automatic Text Processing: the transformation, analysis, and retrieval of information by computer. Addison-Wesley, Reading, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C E Shannon</author>
</authors>
<title>A mathematical theory of communication.&amp;quot;</title>
<date>1948</date>
<journal>Bell System Technical Journal,</journal>
<volume>27</volume>
<pages>July-October.</pages>
<contexts>
<context position="16728" citStr="Shannon (1948)" startWordPosition="2509" endWordPosition="2510">for each element in a pair. Higher values indicate stronger association, and the element having the largest value is considered semantically dominant. The connection between the terms cooccurrences and the information they are transmitting (or otherwise, their meaning) was established and discussed in detail by Harris (1968, 1982, 1991) as fundamental for his mathematical theory of language. This theory is related to mathematical information theory, which formalizes the dependencies between the information and the probability distribution of the given code (alphabet or language). As stated by Shannon (1948), information is measured by entropy which gives the capacity of the given code, in terms of the probabilities of its particular signs, to transmit information. It should be emphasized that, according to the information theory, there is no direct relation between information and meaning, entropy giving only a measure of what possible choices of messages are offered by a particular language. However, it offers theoretic foundations of the correlation between the probability of an event and transmitted information, and it can be further developed in order to capture the meaning of a message. The</context>
</contexts>
<marker>Shannon, 1948</marker>
<rawString>Shannon, C. E. 1948. &amp;quot;A mathematical theory of communication.&amp;quot; Bell System Technical Journal, vol. 27, July-October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A F Smeaton</author>
<author>C J van Rijsbergen</author>
</authors>
<title>Experiments on incorporating syntactic processing of user queries into a document retrieval strategy.&amp;quot;</title>
<date>1988</date>
<booktitle>Proceedings of ACM SIG1R-88,</booktitle>
<pages>31--51</pages>
<marker>Smeaton, van Rijsbergen, 1988</marker>
<rawString>Smeaton, A. F. and C. J. van Rijsbergen. 1988. &amp;quot;Experiments on incorporating syntactic processing of user queries into a document retrieval strategy.&amp;quot; Proceedings of ACM SIG1R-88, pp. 31-51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sparck Jones</author>
<author>Karen</author>
</authors>
<title>Statistical interpretation of term specificity and its application in retrieval.&amp;quot;</title>
<date>1972</date>
<journal>Journal of Documentation,</journal>
<volume>28</volume>
<issue>1</issue>
<pages>11--20</pages>
<marker>Jones, Karen, 1972</marker>
<rawString>Sparck Jones, Karen. 1972. &amp;quot;Statistical interpretation of term specificity and its application in retrieval.&amp;quot; Journal of Documentation, 28(1), pp. 11-20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sparck Jones</author>
<author>K</author>
<author>E</author>
</authors>
<title>What makes automatic keyword classification effective?&amp;quot;</title>
<date>1971</date>
<journal>Journal of the American Society for Information Science, May-June,</journal>
<pages>166--175</pages>
<marker>Jones, K, E, 1971</marker>
<rawString>Sparck Jones, K. and E. 0. Barber. 1971. &amp;quot;What makes automatic keyword classification effective?&amp;quot; Journal of the American Society for Information Science, May-June, pp. 166-175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sparck Jones</author>
<author>K</author>
<author>J I Tait</author>
</authors>
<title>Automatic search term variant generation.&amp;quot;</title>
<date>1984</date>
<journal>Journal of Documentation,</journal>
<volume>40</volume>
<issue>1</issue>
<pages>50--66</pages>
<marker>Jones, K, Tait, 1984</marker>
<rawString>Sparck Jones, K. and J. I. Tait. 1984. &amp;quot;Automatic search term variant generation.&amp;quot; Journal of Documentation, 40(1), pp. 50-66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomek Strzalkowski</author>
<author>Barbara Vauthey</author>
</authors>
<title>Fast Text Processing for Information Retrieval.&amp;quot;</title>
<date>1991</date>
<booktitle>Proceedings of the 4th DARPA Speech and Natural Language Workshop, Morgan-Kaufman,</booktitle>
<pages>346--351</pages>
<contexts>
<context position="4489" citStr="Strzalkowski and Vauthey, 1991" startWordPosition="651" endWordPosition="654">nd some were never properly evaluated either. 2 Standard IR benchmark collections are statistically too small and the experiments can easily produce counterintuitive results. For example, Cranfield collection is only approx. 180,000 English words, while CACM-3204 collection used in the present experiments is approx. 200,000 words. 104 We believe that linguistic processing of both the database and the user&apos;s queries need to be done for a maximum benefit, and moreover, the two processes must be appropriately coordinated. This prognosis is supported by the experiments performed by the NYU group (Strzalkowski and Vauthey, 1991; Grishman and Strzalkowski, 1991), and by the group at the University of Massachussetts (Croft et al., 1991). We explore this possibility further in this paper. OVERALL DESIGN Our information retrieval system consists of a traditional statistical backbone (Harman and Candela, 1989) augmented with various natural language processing components that assist the system in database processing (stemming, indexing, word and phrase clustering, selectional restrictions), and translate a user&apos;s information request into an effective query. This design is a careful compromise between purely statistical n</context>
</contexts>
<marker>Strzalkowski, Vauthey, 1991</marker>
<rawString>Strzalkowski, Tomek and Barbara Vauthey. 1991. &amp;quot;Fast Text Processing for Information Retrieval.&amp;quot; Proceedings of the 4th DARPA Speech and Natural Language Workshop, Morgan-Kaufman, pp. 346-351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomek Strzalkowski</author>
<author>Barbara Vauthey</author>
</authors>
<title>Natural Language Processing in Automated Information Retrieval.&amp;quot;</title>
<date>1991</date>
<booktitle>Proteus Project Memo #42, Courant Institute of Mathematical Science,</booktitle>
<location>New York University.</location>
<contexts>
<context position="4489" citStr="Strzalkowski and Vauthey, 1991" startWordPosition="651" endWordPosition="654">nd some were never properly evaluated either. 2 Standard IR benchmark collections are statistically too small and the experiments can easily produce counterintuitive results. For example, Cranfield collection is only approx. 180,000 English words, while CACM-3204 collection used in the present experiments is approx. 200,000 words. 104 We believe that linguistic processing of both the database and the user&apos;s queries need to be done for a maximum benefit, and moreover, the two processes must be appropriately coordinated. This prognosis is supported by the experiments performed by the NYU group (Strzalkowski and Vauthey, 1991; Grishman and Strzalkowski, 1991), and by the group at the University of Massachussetts (Croft et al., 1991). We explore this possibility further in this paper. OVERALL DESIGN Our information retrieval system consists of a traditional statistical backbone (Harman and Candela, 1989) augmented with various natural language processing components that assist the system in database processing (stemming, indexing, word and phrase clustering, selectional restrictions), and translate a user&apos;s information request into an effective query. This design is a careful compromise between purely statistical n</context>
</contexts>
<marker>Strzalkowski, Vauthey, 1991</marker>
<rawString>Strzalkowski, Tomek and Barbara Vauthey. 1991. &amp;quot;Natural Language Processing in Automated Information Retrieval.&amp;quot; Proteus Project Memo #42, Courant Institute of Mathematical Science, New York University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomek Strzalkowski</author>
</authors>
<title>TTP: A Fast and Robust Parser for Natural Language.&amp;quot;</title>
<date>1992</date>
<booktitle>Proceedings of the 14th International Conference on Computational Linguistics (COLING),</booktitle>
<location>Nantes, France,</location>
<contexts>
<context position="9253" citStr="Strzalkowski, 1992" startWordPosition="1382" endWordPosition="1383"> strategy is an approximate parse, partially fitted using top-down predictions. The fragments skipped in the first pass are not thrown out, instead they are analyzed by a simple phrasal parser that looks for noun phrases and relative clauses and then attaches the recovered material to the main parse structure. As an illustration, consider the following sentence taken from the CACM-3204 corpus: 3 These include CACM-3204, MUC-3, and a selection of nearly 6,000 technical articles extracted from Computer Library database (a Ziff Communications Inc. CD-ROM). A complete description can be found in (Strzalkowski, 1992). 105 The method is illustrated by the automatic construction of both recursive and iterative programs operating on natural numbers, lists, and trees, in order to construct a program satisfying certain specifications a theorem induced by those specifications is proved, and the desired program is extracted from the proof. The italicized fragment is likely to cause additional complications in parsing this lengthy string, and the parser may be better off ignoring this fragment altogether. To do so successfully, the parser must close the currently open constituent (i.e., reduce a program satisfyin</context>
</contexts>
<marker>Strzalkowski, 1992</marker>
<rawString>Strzalkowski, Tomek. 1992. &amp;quot;TTP: A Fast and Robust Parser for Natural Language.&amp;quot; Proceedings of the 14th International Conference on Computational Linguistics (COLING), Nantes, France, July 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick A Wilks</author>
<author>Dan Fass</author>
<author>Cheng-Ming Guo</author>
<author>James E McDonald</author>
<author>Tony Plate</author>
<author>Brian M Slator</author>
</authors>
<title>Providing machine tractable dictionary tools.&amp;quot;</title>
<date>1990</date>
<journal>Machine Translation,</journal>
<volume>5</volume>
<pages>99--154</pages>
<contexts>
<context position="19284" citStr="Wilks et al. (1990)" startWordPosition="2934" endWordPosition="2937"> estimate of) the conditional probability of seeing a word y to the right of the word x, modified with a dispersion parameter for X. (x,[x,y]) — nx + dx — 1 where fx,y is the frequency of [x,y I in the corpus, nx is the number of pairs in which x occurs at the same position as in [x,y], and d(x) is the dispersion 107 parameter understood as the number of distinct words with which x is paired. When IC (x, [x,y1) = 0, x and y never occur together (i.e., = 0); when IC (x, fx,y])= 1, x occurs only with y (i.e., f, = and dx = 1). So defined, IC function is asymmetric, a property found desirable by Wilks et al. (1990) in their study of word co-occurrences in the Longman dictionary. In addition, IC is stable even for relatively low frequency words, which can be contrasted with Fano&apos;s mutual information formula recently used by Church and Hanks (1990) to compute word cooccurrence patterns in a 44 million word corpus of Associated Press news stories. They noted that while generally satisfactory, the mutual information formula often produces counterintuitive results for lowfrequency data. This is particularly worrisome for relatively smaller IR collections since many important indexing terms would be eliminate</context>
</contexts>
<marker>Wilks, Fass, Guo, McDonald, Plate, Slator, 1990</marker>
<rawString>Wilks, Yorick A., Dan Fass, Cheng-Ming Guo, James E. McDonald, Tony Plate, and Brian M. Slator. 1990. &amp;quot;Providing machine tractable dictionary tools.&amp;quot; Machine Translation, 5, pp. 99-154.</rawString>
</citation>
<citation valid="false">
<volume>1</volume>
<marker></marker>
<rawString>1 1 1</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>