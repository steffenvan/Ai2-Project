<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.049531">
<title confidence="0.9178515">
SemEval-2015 Task 13: Multilingual All-Words Sense Disambiguation and
Entity Linking
</title>
<author confidence="0.889063">
Andrea Moro and Roberto Navigli
</author>
<affiliation confidence="0.734747">
Dipartimento di Informatica,
</affiliation>
<address confidence="0.500417">
Sapienza Universit`a di Roma,
Viale Regina Elena 295, 00161 Roma, Italy
</address>
<email confidence="0.99815">
{moro,navigli}@di.uniroma1.it
</email>
<sectionHeader confidence="0.998554" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.807763823529412">
In this paper we present the Multilingual All-
Words Sense Disambiguation and Entity Link-
ing task. Word Sense Disambiguation (WSD)
and Entity Linking (EL) are well-known prob-
lems in the Natural Language Processing field
and both address the lexical ambiguity of lan-
guage. Their main difference lies in the kind
of meaning inventories that are used: EL uses
encyclopedic knowledge, while WSD uses
lexicographic information. Our aim with this
task is to analyze whether, and if so, how, us-
ing a resource that integrates both kinds of in-
ventories (i.e., BabelNet 2.5.1) might enable
WSD and EL to be solved by means of similar
(even, the same) methods. Moreover, we in-
vestigate this task in a multilingual setting and
for some specific domains.
</bodyText>
<sectionHeader confidence="0.999389" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999897957446809">
The Senseval and SemEval evaluation series rep-
resent key moments in the community of compu-
tational linguistics and related areas. Their focus
has been to provide objective evaluations of methods
within the wide spectrum of semantic techniques for
tasks mainly related to automatic text understanding.
Through SemEval-2015 task 13 we both continue
and renew the longstanding tradition of disambigua-
tion tasks, by addressing multilingual WSD and EL
in a joint manner. WSD (Navigli, 2009; Navigli,
2012) is a historical task aimed at explicitly assign-
ing meanings to single-word and multi-word occur-
rences within text, a task which today is more alive
than ever in the research community. EL (Erbs et
al., 2011; Cornolti et al., 2013; Rao et al., 2013) is
a more recent task which aims at discovering men-
tions of entities within a text and linking them to
the most suitable entry in a knowledge base. Both
these tasks aim at handling the inherent ambiguity
of natural language, however WSD tackles it from a
lexicographic perspective, while EL tackles it from
an encyclopedic one. Specifically, the main differ-
ence between the two tasks lies in the kind of inven-
tory they use. For instance, WordNet (Miller et al.,
1990), a manually curated semantic network for the
English language, has become the main reference in-
ventory for English WSD systems thanks to its wide
coverage of verbs, adverbs, adjectives and common
nouns. More recently, Wikipedia has been shown to
be an optimal resource for recovering named enti-
ties, and has consequently become - together with
all its semi-automatic derivations such as DBpedia
(Auer et al., 2007) and Freebase (Bollacker et al.,
2008) - the main reference inventory for EL systems.
Over the years, the research community has typi-
cally focused on each of these tasks separately. Re-
cently, however, joint approaches have been pro-
posed (Moro et al., 2014b). One of the reasons for
pursuing the unification of these tasks derives from
the current trend in knowledge acquisition which
consists of the seamless integration of encyclopedic
and lexicographic knowledge within structured lan-
guage resources (Hovy et al., 2013). A case in point
here is BabelNet1, a multilingual semantic network
and encyclopedic dictionary (Navigli and Ponzetto,
2012). Resources like BabelNet provide a common
ground for the tasks of WSD and EL.
</bodyText>
<footnote confidence="0.995974">
1http://babelnet.org
</footnote>
<page confidence="0.861359">
288
</page>
<note confidence="0.955704">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 288–297,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.999970230769231">
In this task our goal is to promote research in the
direction of joint word sense and named entity dis-
ambiguation, so as to concentrate research efforts on
the aspects that differentiate these two tasks with-
out duplicating research on common problems such
as identifying the right meaning in context. How-
ever, we are also interested in systems that perform
only one of the two tasks, and even systems which
tackle one particular setting of WSD, such as all-
words sense disambiguation vs. any subset of part-
of-speech tags. Moreover, given the recent upsurge
of interest in multilingual approaches, we developed
the task dataset in three different languages (En-
glish, Italian and Spanish) on parallel texts which
have been independently and manually annotated by
different native/fluent speakers. In contrast to the
SemEval-2013 task 12 on Multilingual Word Sense
Disambiguation (Navigli et al., 2013), our focus in
task 13 is to present a dataset containing both kinds
of inventories (i.e., named entities and word senses)
in different specific domains (biomedical domain,
maths and computer domain, and a broader domain
about social issues). Our goal is to further investi-
gate the distance between research efforts regarding
the dichotomy EL vs. WSD and those regarding the
dichotomy open domain vs. closed domain.
</bodyText>
<sectionHeader confidence="0.995483" genericHeader="method">
2 Task Setup
</sectionHeader>
<bodyText confidence="0.999103333333333">
The task setup consists of annotating four tokenized
and part-of-speech tagged documents for which par-
allel versions in three languages (English, Italian
and Spanish) have been provided. Differently from
previous editions (Navigli et al., 2013; Lefever and
Hoste, 2013; Manandhar et al., 2010; Lefever and
Hoste, 2010; Pradhan et al., 2007; Navigli et al.,
2007; Snyder and Palmer, 2004; Palmer et al., 2001),
in this task we do not make explicit to the participat-
ing systems which fragments of the input text should
be disambiguated, so as to have, on the one hand,
a more realistic scenario, and, on the other hand,
to follow the recent trend in EL challenges such as
TAC KBP (Ji et al., 2014), MicroPost (Basave et al.,
2013) and ERD (Carmel et al., 2014).
</bodyText>
<subsectionHeader confidence="0.98016">
2.1 Corpora
</subsectionHeader>
<bodyText confidence="0.999613266666667">
The documents considered in this task are taken
from the OPUS project (http://opus.lingfil.uu.se/),
more specifically from the EMEA (European
Medicines Agency documents), KDEdoc (the KDE
manual corpus) and “The EU bookshop corpus”,
which make available parallel and POS-tagged doc-
uments. We took four documents from these reposi-
tories. Two documents contain medical information
about drugs. One document consists of the man-
ual of a mathematical graph calculator (i.e., KAlge-
bra). The remaining document contains a formal dis-
cussion about social issues, like supporting elderly
workers and, more in general, about issues and so-
lutions to unemployment discussed by the members
of the European Commission.
</bodyText>
<subsectionHeader confidence="0.99942">
2.2 Sense Inventory
</subsectionHeader>
<bodyText confidence="0.999994210526316">
As our sense inventory we use the BabelNet 2.5.1
(http://babelnet.org) multilingual semantic network
and encyclopedic dictionary (Navigli and Ponzetto,
2012), which is the result of the automatic in-
tegration of multiple language resources: Prince-
ton WordNet, Wikipedia, Wiktionary, OmegaWiki,
Wikidata, Open Multi WordNet and automatic trans-
lations. The meanings contained within this re-
source are organized in Babel synsets. Each of
these synsets can contain Wikipedia pages, Word-
Net synsets and items from the other integrated re-
sources. For instance, in BabelNet it is possible to
find the concept “medicine” (bn:00054128n), which
is represented by both the second word sense of
medicine in WordNet and the Wikipedia page Phar-
maceutical drug, among others, together with syn-
onyms such as drug and medication in English and
lexicalizations in other languages, such as farmaco
in Italian and medicamento in Spanish.
</bodyText>
<subsectionHeader confidence="0.998498">
2.3 Dataset Creation
</subsectionHeader>
<bodyText confidence="0.999829916666667">
The manual annotation of documents was performed
in a language-specific manner, i.e., different taggers
worked on the various translated versions of the in-
put documents. More precisely, we had two taggers
for each language, who annotated each fragment
of text recognized as linkable with all the senses
deemed appropriate. During the annotation proce-
dure, for all languages, each tagger was shown an
HTML page containing the sentence within which
the target fragment was boldfaced. Then a table of
checkable meanings identified by their glosses (in
English or, if not available, in Spanish or Italian), to-
</bodyText>
<page confidence="0.997653">
289
</page>
<table confidence="0.999908214285714">
Domain Language Instances Single Multi Named Mean senses Mean senses Mean senses per POS A Wikipedia WordNet
words words Entities per instance per lemma N V R pages keys
EN 623 534 41 48 8.0 7.0 8.8 10.0 2.4 3.8 295 549
Biomedical ES 628 552 30 46 6.2 6.5 5.6 9.0 3.1 5.9 251 -
IT 610 545 29 36 5.4 5.7 5.8 6.0 3.1 3.5 254 -
EN 325 292 11 22 9.0 9.5 10.1 10.3 2.9 5.9 135 276
Maths and ES 308 277 10 21 7.5 7.6 7.9 8.0 3.8 6.0 120 -
computer IT 313 275 15 23 6.9 6.8 7.3 7.6 3.3 4.4 136 -
EN 313 268 29 16 7.4 6.9 9.1 6.3 1.5 4.1 119 294
Social ES 303 259 27 17 7.4 7.4 8.1 7.3 3.2 5.9 102 -
issues IT 302 265 22 15 6.6 6.5 7.7 6.8 1.7 3.0 101 -
EN 1261 1094 81 86 8.1 7.6 9.1 9.5 2.4 4.4 549 1119
All ES 1239 1088 67 84 6.8 6.8 6.8 8.4 3.2 5.9 473 -
IT 1225 1085 66 74 6.1 5.9 6.6 6.7 2.8 3.5 491 -
</table>
<tableCaption confidence="0.99992">
Table 1: Statistics of the datasets.
</tableCaption>
<bodyText confidence="0.999976851851852">
gether with the available synonyms and hypernyms
(as found in WordNet and the Wikipedia Bitaxon-
omy (Flati et al., 2014)). The taggers agreed on
at least one meaning for 68% of the instances. A
third tagger acted as judge by going through all the
items and discarding overly general or irrelevant an-
notations, especially in the case of disagreement be-
tween the two taggers. To enforce coherence and
spot missing annotations, we projected the English
annotations to the other two languages. Finally, the
third tagger determined if the projected English an-
notations that were missing in one of the other two
languages were either correctly not included, or if
the taggers had actually missed a correct annotation.
As a result of this procedure we obtained a dataset
with around 1.2k items, but with only around 80
named entity mentions per language. Please refer
to Table 1 for general statistics about the dataset:
we show the number of annotated instances per lan-
guage and domain, together with their classification
as single- or multi-word expressions and named en-
tities. We then show the degree of ambiguity both
per POS and per instance and lemma (i.e., multiple
instances with the same lemma count as a single in-
stance) and, finally, we show how many of the in-
stances have Wikipedia pages or WordNet keys as
annotations2.
</bodyText>
<subsectionHeader confidence="0.988949">
2.4 Evaluation Measures
</subsectionHeader>
<bodyText confidence="0.997426666666667">
To evaluate the performance of the participating sys-
tems we used the classical precision, recall and F1
measures:
</bodyText>
<footnote confidence="0.97550375">
2Please note that the sum of Wikipedia pages and WordNet
keys does not amount to the number of instances, as BabelNet
can have integrated synsets that contain both WordNet keys and
Wikipedia pages.
</footnote>
<equation confidence="0.991656222222222">
Precision = T P (3 )
Recall =
F1
=
T P + F P
TP
TP + FN
2 · Precision · Recall
Precision + Recall
</equation>
<bodyText confidence="0.999887888888889">
To handle systems that output multiple answers for
a single instance we followed the standard scorer of
previous Senseval and SemEval challenges in uni-
formly weighting the multiple answers when com-
puting the TP counts. Moreover, we decided not to
take into account fragments annotated by the sys-
tems which were not contained in the gold standard,
similarly to the D2KB setting of the GERBIL eval-
uation framework for EL (Usbeck et al., 2015).
</bodyText>
<subsectionHeader confidence="0.937202">
2.5 Baseline
</subsectionHeader>
<bodyText confidence="0.999788352941176">
As baseline we considered the performance of a
simple heuristic (called BabelNet first sense or
BFS) that exploits the default comparator integrated
within the BabelNet 2.5.1 API (i.e., the Babel-
SynsetComparator Java class). Babel synsets in Ba-
belNet can be viewed as nodes of a semantic net-
work and each of them can contain Wikipedia pages,
WordNet synsets and items from the other integrated
resources. The comparator takes as input the lemma
of the word for which we are ranking the Babel
synsets. There are three main cases managed by
the comparator. The first case is when both Babel
synsets contain a WordNet synset for the considered
word. If this is the case, then the WordNet sense
numbers are used to rank the synsets. The second
case is when only one of the Babel synsets contains
a WordNet synset: in this case the Babel synset that
</bodyText>
<page confidence="0.96441">
290
</page>
<bodyText confidence="0.999909">
contains the WordNet synset gets ranked first. The
last case is when no WordNet synsets are contained
within the two Babel synsets. In this case a lexico-
graphic ordering of the Wikipedia pages contained
within the Babel synsets is taken into account. As is
well known, the first sense heuristic based on Word-
Net has always proved a really hard to beat baseline,
outperforming all the developed systems for the En-
glish language over almost all settings and system
combinations. In contrast, the BFS heuristic in the
other languages shows itself to be weaker, achieving
lower performances in almost all settings and system
combinations.
</bodyText>
<sectionHeader confidence="0.950842" genericHeader="method">
3 Participating Systems
</sectionHeader>
<bodyText confidence="0.998649358974359">
DFKI (Supervised). This system exploits Babel-
Net as reference inventory and a CRF-based named
entity recognizer. The disambiguation system is
divided in two parts: one for nouns and another
for verbs. For nouns the approach is based on the
idea of maximizing multiple objectives at the same
time. Similarly to (Hoffart et al., 2011), the disam-
biguation objectives consist of a global (coherence,
unsupervised) part and a local (supervised) part.
The global objective makes sure that disambiguation
maximizes coherence of the selected synsets and it is
based on the semantic signature graph (Moro et al.,
2014b). The local objective ensures that the Word-
Net synset type fits the local context of the noun to
be disambiguated. One important aspect of this ap-
proach is that, unlike previous work (Hoffart et al.,
2011; Moro et al., 2014b), it does not apply dis-
crete optimization, but continuous optimization on
the normalized sum of all objectives. The disam-
biguation procedure aims to optimize the objective
function by iteratively updating the candidate prob-
abilities for each fragment. As far as verbs are con-
cerned, a feed-forward neural network is trained us-
ing local features such as arguments of the semantic
roles of a verb in a sentence, context words, and the
verb and its lemma.
EBL-Hope (Unsupervised + Sense relevance).
This approach uses a modified version of the Lesk
algorithm and the Jiang &amp; Conrath similarity mea-
sure (Jiang and Conrath, 1997). It validates the out-
put from both techniques for enhanced accuracy and
exploits semantic relations and corpus (SemCor) in-
formation available in BabelNet and WordNet in an
unsupervised manner.
el92 (Systems mix). This system is a general-
domain system for entity detection and linking. It
does not perform WSD. The system combines, via
a weighted voting, Entity Linking outputs from four
publicly available services: Tagme (Ferragina and
Scaiella, 2010), DBpedia Spotlight (Mendes et al.,
2011), Wikipedia Miner (Milne and Witten, 2008)
and Babelfy (Moro et al., 2014b; Moro et al.,
2014a). The different runs correspond to different
settings in the weighting formula (De La Clergerie
et al., 2008; Fiscus, 1997).
LIMSI (Unsupervised + Sense relevance). The
system performs WSD by taking advantage of the
parallelism of the test data, a feature that was
not exploited by the systems that participated in
the SemEval-2013 Multilingual Word Sense Dis-
ambiguation task 12 (Navigli et al., 2013). The
system needs no training and is applied directly to
the test dataset, nor does it use distributional (con-
text) information. The texts are sentence- and word-
aligned pairwise, and content words are tagged by
their translations in another language. The align-
ments serve to retrieve the BabelNet synsets that are
relevant for each instance of a word in the texts (i.e.,
synsets that contain both the disambiguation target
and its aligned translation). If a Babel synset is re-
tained, this is used to annotate the instance of the
word in the test set. If more than one synset is
retained, these are ranked using the BabelSynset-
Comparator Java class available in the BabelNet API
(please refer to Section 2.5 for a detailed explana-
tion). The highest ranked synset among the ones that
contain the aligned translation is used to annotate the
instance. The system falls back to the BabelNet first
sense (BFS) provided by the BabelSynsetCompara-
tor for instances with no aligned translation, or in
cases where the translation was not found in any of
the synsets available for the word in BabelNet.
SUDOKU (Unsupervised). This deterministic
constraint-based approach relies on a reasonable
degree of “document monosemy” (percentage of
unique monosemous lemmas in a document) and ex-
ploits Personalised PageRank (Agirre et al., 2014)
to select the best candidate. The PPR is started with
</bodyText>
<page confidence="0.987324">
291
</page>
<bodyText confidence="0.990014362068965">
a surfing vector biased towards monosemous words
(i.e., their respective sense). Each submission dif-
fers by its imposed constraints: Run1 is the plain
approach (Manion and Sainudiin, 2014) applied at
the document level; Run2 is the iterative version of
the previous approach applied at the document level
and with words disambiguated in order of increasing
polysemy; Run3 is like Run2, but it is first applied
to nouns and then to verbs, adjectives, and adverbs.
TeamUFAL (Unsupervised). This system ex-
ploits Apache Lucene search engine to index
Wikipedia documents, Wiktionary entries and
WordNet senses. Then, to perform disambiguation,
the Lucene ranking method is used to query the
index with multiple queries (consisting of the text
fragment and context words). Finally, all query re-
sults are merged and the disambiguated meaning is
selected thanks to a simple threshold heuristic.
UNIBA (Unsupervised + Sense relevance). This
system3 extends two well-known variations of the
Lesk WSD method. The main contribution of the
approach relies on the use of a word similarity
function defined on a distributional semantic space
(Word2vec tool (Mikolov et al., 2013)) to compute
the gloss-context overlap. Entities are identified by
exploiting a list of possible surface forms extracted
from BabelNet synsets. Moreover, each synset has a
prior probability computed over an annotated cor-
pus. For WordNet synsets, SemCor is exploited,
while for Wikipedia entities the number of citations
in Wikipedia internal links is counted.
vua-background (Partially supervised). This
approach exploits the Named Entities contained in
the test data to generate a background corpus. This
is done by finding similar DBpedia entities for the
entities in the input documents. Using this back-
ground corpus, the system tries to find the predomi-
nant sense of the words in the test data (McCarthy et
al., 2004). If a predominant sense is recognized for
a specific lemma, then it is used, otherwise the sys-
tem falls back to the “It Makes Sense” WSD system
(Zhong and Ng, 2010).
3During the evaluation period the system did not return any
annotation for adjectives due to a misinterpretation of the POS
tag set. For full evaluations see the system paper.
WSD-games (Unsupervised). This approach is
formulated in terms of Evolutionary Game Theory,
where each word to be disambiguated is represented
as a node in a graph and each sense as a class. The
proposed algorithm performs a consistent class as-
signment of senses according to the similarity infor-
mation of each word with the others, so that sim-
ilar words are constrained to similar classes. The
propagation of the information over the graph is for-
mulated in terms of a non-cooperative multi-player
game, where the players are the data points, in or-
der to decide their class memberships, and equilibria
correspond to consistent labeling of the data.
</bodyText>
<sectionHeader confidence="0.999878" genericHeader="evaluation">
4 Results and Discussion
</sectionHeader>
<bodyText confidence="0.99991075">
The results obtained by the participating systems
are shown in Tables 2-6. In Table 2 we show the
precision, recall and F1 scores of the participating
systems that annotated all classes of items (named
entities, nouns, verbs, adverbs, adjectives) over the
whole dataset. Six out of the nine participating
teams annotated the full set of items. We also show
the F1 performance on each considered domain in-
dependently and for different kinds of subsets of the
item classes (i.e., we show the F1 score over all
items, then only on named entities, all open-class
word senses and individually).
</bodyText>
<subsectionHeader confidence="0.993166">
4.1 Overall Performance
</subsectionHeader>
<bodyText confidence="0.999934">
From Table 2 we can see that the best system for En-
glish (i.e., LIMSI) is able to obtain a performance
more than five percentage points higher than the
second ranked system. This is due to the good-
quality indirect supervision provided by the align-
ments combined with the use of the BabelSynset-
Comparator. However, on the other two languages
this system obtains lower performance than the other
competing systems. The performance of the SU-
DOKU system is of a particular interest, as it obtains
the second best scores on the English part of the
dataset and the top scores overall on the other two
languages. It exploits monosemous words within
the input documents to run Personalized PageRank.
The three runs differ mainly in respect of the order
in which the words get disambiguated.
In Table 3 we show the F1 scores of all the sys-
tems over the whole dataset for each class of the
</bodyText>
<page confidence="0.975735">
292
</page>
<table confidence="0.999905714285714">
EN ES IT
System P R F1 P R F1 P R F1
LIMSI 68.7 63.1 65.8 47.9 42.4 45.0 51.3 45.7 48.4
SUDOKU-Run2 62.9 60.4 61.6 59.9 54.6 57.1 59.7 54.3 56.9
SUDOKU-Run3 61.9 59.4 60.7 59.5 54.2 56.8 59.7 54.3 56.9
vua-background 67.5 51.5 58.4 - - - - - -
SUDOKU-Run1 60.1 52.1 55.8 60.2 52.3 56.0 64.4 55.9 59.9
WSD-games-Run2 58.8 50.0 54.1 - - - - - -
WSD-games-Run1 57.4 48.9 52.8 - - - - - -
WSD-games-Run3 53.5 45.4 49.1 - - - - - -
EBL-Hope 48.4 44.4 46.3 - - - - - -
TeamUFAL 40.4 36.5 38.3 - - - - - -
BFS 67.9 67.2 67.5 38.9 36.2 37.5 41.7 38.8 40.2
# items 1261 1239 1225
</table>
<tableCaption confidence="0.999097">
Table 2: Precision, Recall and F1 on all domains.
</tableCaption>
<bodyText confidence="0.999931666666667">
manually annotated items and for each language.
In the English part of the datasets the DFKI sys-
tem performs best for verb, noun and named en-
tity disambiguation, thanks to precomputed random
walks called semantic signatures, along the lines of
Babelfy (Moro et al., 2014b), and supervised tech-
niques. The UNIBA system on the English dataset
obtains the best result on adverbs. Finally, in the
Spanish dataset the EBL-Hope system based on a
combination of a Lesk-based measure together with
the Jiang &amp; Conrath similarity measure shows the
best performance for named entities.
</bodyText>
<subsectionHeader confidence="0.942604">
4.2 Domain-based Evaluation
</subsectionHeader>
<bodyText confidence="0.999434509803922">
In Tables 4-6 we show the detailed performances
of all the systems over different classes of items,
and on different domains. One of the main goals
of this task is to investigate the performance of dis-
ambiguation methods over different domains. Our
documents derive from the biomedical domain, the
maths and computer domain, and a broader domain
(a document discussing social issues, especially for
elderly workers and possible solutions).
Biomedical domain. In Table 4 we show the per-
formance of the systems on the biomedical docu-
ments. The first thing to notice is the much higher
best score of the first ranked system (i.e., LIMSI),
which attains an F1 score of 71.3%. This is due
to the lower ambiguity of nouns and named enti-
ties (see Table 1) resulting from the greater num-
bers of domain-specific concepts used within this
kind of documents. This can also be seen from
the higher scores obtained by the BFS. Overall, all
systems obtained a better performance than in the
other domains, with a gain of more than four per-
centage points each. The second ranked system
(i.e., SUDOKU) shows its ability to exploit monose-
mous words obtaining a 0.1 difference from the first
ranked system and a 0.9 point distance from the BFS
baseline. This is of particular interest as the sys-
tem does not explicitly exploit any sense relevance
information. Moreover, the DFKI system obtains
the best scores for nouns and verbs, and is the only
system able to obtain a 100% F1 score on NE dis-
ambiguation. However, several other systems per-
formed above 90%, showing that in this particular
set of documents named entities are easy to disam-
biguate.
On the other two languages the performances are
a little bit lower, but the SUDOKU system confirms
its ability to exploit monosemous words at a qual-
ity comparable to the one obtained in the English
dataset. The LIMSI system, instead, obtains a re-
duction of around 20% due to its exploitation of the
BabelSynsetComparator, which performs badly in
these languages (see the BFS scores).
Maths and computer domain. In Table 5 we
show the results for the maths and computer do-
main. As can be seen in Table 1, this is the most am-
biguous domain and the best systems obtain much
lower performances than in the other domains. In-
terestingly, the DFKI system is not able to achieve
the best performance on any of the considered item
classes, while UNIBA and SUDOKU show the best
results for nouns and verbs. As regards named en-
</bodyText>
<page confidence="0.997346">
293
</page>
<table confidence="0.999801380952381">
EN
System All Named Word Senses
Entities All N V R A
LIMSI 65.8 82.9 64.7 64.8 56.0 76.5 79.5
SUDOKU-Run2 61.6 87.0 59.9 62.5 49.6 70.4 71.7
SUDOKU-Run3 60.7 87.0 58.9 62.7 46.0 71.7 68.1
vua-background 58.4 14.9 60.3 53.8 55.2 77.2 72.5
SUDOKU-Run1 55.8 16.8 57.5 53.4 52.2 48.9 74.4
WSD-games-Run2 54.1 12.6 55.8 51.4 43.7 75.3 69.9
WSD-games-Run1 52.8 12.6 54.5 49.6 42.5 75.3 69.9
WSD-games-Run3 49.1 12.6 50.7 47.4 35.8 74.1 64.0
EBL-Hope 46.3 84.2 43.8 45.7 30.6 76.5 57.8
TeamUFAL 38.3 79.8 35.5 46.4 18.8 45.8 28.8
DFKI - 88.9 - 70.3 57.7 - -
el92-Run1 - 86.1 - - - - -
UNIBA-Run1 - 84.4 - 63.3 57.1 79.0 -
UNIBA-Run2 - 82.9 - 63.2 57.1 79.0 -
UNIBA-Run3 - 82.9 - 63.2 57.1 79.0 -
el92-Run3 - 79.7 - - - - -
el92-Run2 - 79.2 - - - - -
BFS 67.5 85.7 66.3 66.7 55.1 82.1 82.5
ES
System All Named Word Senses
Entities All N V R A
SUDOKU-Run2 57.1 36.9 58.0 56.3 55.6 61.9 61.1
SUDOKU-Run3 56.8 36.9 57.7 54.9 57.9 60.3 61.5
SUDOKU-Run1 56.0 17.4 57.6 54.0 56.4 61.4 62.0
LIMSI 45.0 30.8 45.6 48.3 28.6 64.6 49.7
EBL-Hope - 70.8 - 48.2 - - -
BFS 37.5 37.0 37.6 40.6 19.8 55.1 46.2
IT
System All Named Word Senses
Entities All N V R A
SUDOKU-Run1 59.9 21.7 61.3 56.6 62.7 62.5 68.3
SUDOKU-Run3 56.9 54.9 57.0 56.3 51.5 57.1 65.8
SUDOKU-Run2 56.9 54.9 57.0 54.1 60.9 61.2 62.0
LIMSI 48.4 46.5 48.4 43.9 44.2 56.0 69.6
UNIBA-Run3 - 50.0 - 53.7 61.1 60.0 -
UNIBA-Run2 - 48.5 - 53.8 61.1 60.0 -
UNIBA-Run1 - 48.5 - 53.7 61.1 60.0 -
EBL-Hope - 48.5 - 38.8 - - -
BFS 40.2 50.0 39.8 35.4 38.3 48.0 61.0
</table>
<tableCaption confidence="0.9953325">
Table 3: F1 performance by item class and language on
all domains.
</tableCaption>
<table confidence="0.999957761904762">
EN
System All Named Word Senses
Entities All N V R A
LIMSI 71.3 98.9 68.9 76.5 50.6 77.5 75.0
SUDOKU-Run3 71.2 98.9 68.8 75.8 50.6 75.3 77.8
SUDOKU-Run2 68.9 98.9 66.4 71.9 47.3 77.9 83.3
vua-background 63.6 4.1 66.4 62.7 53.8 76.9 77.4
SUDOKU-Run1 62.4 4.1 65.0 62.8 52.5 50.7 82.3
WSD-games-Run2 58.4 4.1 60.8 55.8 45.8 80.0 79.2
WSD-games-Run1 56.3 4.1 58.6 52.2 45.8 80.0 79.2
WSD-games-Run3 54.4 4.1 56.6 54.1 35.0 72.5 77.8
EBL-Hope 52.0 98.9 48.0 54.1 28.2 80.0 65.3
TeamUFAL 45.6 93.5 41.6 57.2 18.6 39.7 30.9
DFKI - 100.0 - 79.1 58.3 - -
UNIBA-Run3 - 98.9 - 72.1 52.3 80.0 -
UNIBA-Run1 - 98.9 - 71.9 52.3 80.0 -
UNIBA-Run2 - 98.9 - 71.9 52.3 80.0 -
el92-Run1 - 90.9 - - - --
el92-Run2 - 81.5 - - - - -
el92-Run3 - 81.5 - - - - -
BFS 72.1 98.9 69.9 75.3 52.5 82.9 81.9
ES
System All Named Word Senses
Entities All N V R A
SUDOKU-Run1 62.7 8.3 65.1 65.5 54.3 65.7 62.1
SUDOKU-Run3 62.6 12.2 64.7 64.3 56.7 52.6 71.2
SUDOKU-Run2 60.8 12.2 62.9 64.5 51.2 52.6 63.2
LIMSI 51.0 12.2 52.7 59.6 28.3 59.7 40.7
EBL-Hope - 77.3 - 59.6 - - -
BFS 43.7 12.2 45.1 51.7 20.5 49.4 39.0
IT
System All Named Word Senses
Entities All N V R A
SUDOKU-Run1 65.1 10.5 67.0 65.9 64.2 48.0 64.3
SUDOKU-Run3 61.4 28.6 62.7 62.3 52.3 48.0 70.6
SUDOKU-Run2 58.8 28.6 60.0 56.7 61.5 56.0 64.7
LIMSI 53.1 24.4 54.1 54.2 42.2 38.5 63.5
UNIBA-Run3 - 28.6 - 62.4 63.6 46.2 -
UNIBA-Run1 - 24.4 - 62.2 63.6 46.2 -
UNIBA-Run2 - 24.4 - 62.2 63.6 46.2 -
EBL-Hope - 24.4 - 50.5 - - -
BFS 44.3 28.6 44.9 43.3 38.7 38.5 56.8
</table>
<tableCaption confidence="0.9960745">
Table 4: F1 performance by item class and language on
biomedical domain.
</tableCaption>
<bodyText confidence="0.999970956521739">
tities, the system EBL-Hope obtains the best results
in all languages. This system, in addition to exploit-
ing a Lesk-based measure combined with the Jiang
&amp; Conrath similarity measure, uses the BabelNet se-
mantic relations, which have already been shown to
be useful for attaining state-of-the-art performances
in EL (Moro et al., 2014b). Interestingly, in the Ital-
ian dataset the system UNIBA (which is based on
an extended version of the Lesk measure and a se-
mantic relatedness measure) obtains the same per-
formance for NE as the EBL-Hope system.
Social issues domain. In Table 6 we show the per-
formance on our last domain. In this social issues
domain DFKI confirms its quality on disambiguat-
ing nouns and named entities, while for verbs the
best system is vua-background, which is based on
the predominant sense algorithm (McCarthy et al.,
2004) and, as a fallback routine, on the “It Makes
Sense” supervised WSD system (Zhong and Ng,
2010). For the other two languages the SUDOKU
system obtains the best scores, with the exception
of adverbs in the Italian dataset where the UNIBA
system is able to reach an F1 score of 100%.
</bodyText>
<sectionHeader confidence="0.991047" genericHeader="conclusions">
5 Conclusion and Future Directions
</sectionHeader>
<bodyText confidence="0.996600428571429">
In this paper we described the organization and re-
sults obtained within the SemEval 2015 task 13:
Multilingual Word Sense Disambiguation. Our anal-
ysis of the results revealed interesting aspects of the
integration of WSD and EL tasks, such as the effec-
tiveness of techniques like semantic signatures, PPR
and similarity measures for noun and named entity
</bodyText>
<page confidence="0.994461">
294
</page>
<table confidence="0.99979130952381">
EN
System All Named Word Senses
Entities All N V R A
LIMSI 54.1 57.1 53.9 39.3 59.4 71.7 90.0
SUDOKU-Run2 53.2 56.3 53.1 51.4 49.1 56.6 67.5
SUDOKU-Run3 49.4 56.3 49.1 48.9 42.3 64.2 57.5
EBL-Hope 41.7 74.3 39.8 42.5 28.6 67.9 50.0
TeamUFAL 29.8 54.5 28.4 35.8 12.6 37.8 39.2
el92-Run1 - 70.6 - - - - -
el92-Run3 - 66.7 - - - - -
el92-Run2 - 64.7 - - - - -
DFKI - 57.1 - 44.9 52.3 - -
UNIBA-Run1 - 57.1 - 44.1 60.6 75.5 -
UNIBA-Run2 - 57.1 - 44.1 60.6 75.5 -
UNIBA-Run3 - 57.1 - 44.1 60.6 75.5 -
WSD-games-Run2 - - 48.5 39.6 37.7 64.2 80.0
vua-background - - 47.7 30.5 49.7 70.6 73.0
WSD-games-Run1 - - 47.4 39.6 34.3 64.2 80.0
SUDOKU-Run1 - - 44.7 28.5 51.4 52.0 75.0
WSD-games-Run3 - - 43.4 36.2 35.4 67.9 58.2
BFS 55.3 57.1 55.2 43.6 55.7 77.8 87.5
ES
System All Named Word Senses
Entities All N V R A
SUDOKU-Run2 49.7 50.0 49.7 42.4 60.9 66.7 44.1
SUDOKU-Run3 48.4 50.0 48.3 39.2 58.7 66.7 52.9
SUDOKU-Run1 44.2 - 45.9 32.0 58.7 56.0 52.9
LIMSI 34.8 56.3 33.6 32.2 27.2 81.5 47.1
EBL-Hope - 68.8 - 45.4 - - -
BFS 28.7 62.5 26.8 27.1 16.3 74.1 50.0
IT
System All Named Word Senses
Entities All N V R A
SUDOKU-Run2 52.1 68.6 51.1 46.6 59.0 66.7 58.5
SUDOKU-Run3 49.1 68.6 47.9 43.0 53.0 66.7 63.4
SUDOKU-Run1 48.4 - 50.5 35.8 60.2 66.7 70.7
LIMSI 44.6 64.9 43.3 33.4 45.8 66.7 85.4
UNIBA-Run1 - 75.7 - 43.4 57.8 50.0 -
UNIBA-Run2 - 75.7 - 43.4 57.8 50.0 -
UNIBA-Run3 - 75.7 - 42.2 57.8 50.0 -
EBL-Hope - 75.7 - 37.1 - - -
BFS 36.7 64.9 34.8 27.4 37.3 66.7 70.7
</table>
<tableCaption confidence="0.9981005">
Table 5: F1 performance by item class and language on
maths and computer domain.
</tableCaption>
<table confidence="0.999955761904762">
EN
System All Named Word Senses
Entities All N V R A
LIMSI 67.2 54.5 67.7 63.7 63.6 82.8 77.8
vua-background 60.8 54.5 61.1 54.8 70.6 89.7 65.3
SUDOKU-Run1 56.4 60.9 56.2 56.4 52.9 36.4 63.6
SUDOKU-Run2 55.6 81.5 54.5 52.8 56.8 75.9 59.3
WSD-games-Run1 53.5 45.5 53.8 53.0 50.0 82.8 50.0
WSD-games-Run2 53.5 45.5 53.8 53.0 50.0 82.8 50.0
SUDOKU-Run3 51.1 81.5 49.7 48.2 40.9 75.9 63.0
WSD-games-Run3 46.7 45.5 46.7 44.2 38.6 89.7 50.0
EBL-Hope 39.5 36.4 39.6 31.5 40.9 82.8 53.7
TeamUFAL 32.5 64.2 31.0 33.6 31.8 72.4 18.4
DFKI - 90.3 - 73.4 66.7 - -
el92-Run1 - 89.7 - - - - -
el92-Run2 - 89.7 - - - - -
el92-Run3 - 89.7 - - - - -
UNIBA-Run1 - 66.7 - 63.0 63.6 82.8 -
UNIBA-Run2 - 54.5 - 62.3 63.6 82.8 -
UNIBA-Run3 - 54.5 - 61.9 63.6 82.8 -
BFS 70.8 77.4 70.5 69.2 61.4 87.5 79.6
ES
System All Named Word Senses
Entities All N V R A
SUDOKU-Run2 57.0 69.2 56.5 51.6 57.5 87.0 70.0
SUDOKU-Run1 54.2 52.2 54.3 49.7 57.5 52.6 68.0
SUDOKU-Run3 53.3 69.2 52.5 49.5 59.8 78.3 56.0
LIMSI 43.1 34.8 43.5 39.3 32.2 60.9 62.0
EBL-Hope - 52.2 - 26.6 - - -
BFS 34.0 51.9 33.1 30.2 25.0 52.2 52.0
IT
System All Named Word Senses
Entities All N V R A
SUDOKU-Run1 61.0 63.6 60.9 56.0 63.4 90.9 72.4
SUDOKU-Run2 57.9 80.0 56.9 55.6 63.4 66.7 60.3
SUDOKU-Run3 55.8 80.0 54.7 56.1 46.3 66.7 60.3
LIMSI 42.9 57.1 42.4 33.1 46.3 83.3 67.2
UNIBA-Run3 - 47.6 - 47.1 61.0 100.0 -
UNIBA-Run2 - 47.6 - 46.7 61.0 100.0 -
UNIBA-Run1 - 47.6 - 46.3 61.0 100.0 -
EBL-Hope - 47.6 - 16.7 - - -
BFS 35.7 64.0 34.5 27.0 39.0 50.0 60.3
</table>
<tableCaption confidence="0.992019">
Table 6: F1 performance by item class and language on
social issues domain.
</tableCaption>
<bodyText confidence="0.999782555555556">
disambiguation, and Lesk-based measures for verb,
adjective and adverb disambiguation. Another inter-
esting outcome that emerges from this task is that
supervised approaches are difficult to generalize in
a multilingual setting. In fact, the supervised sys-
tems that participated in this task took into account
only the English language. Moreover, the task con-
firms yet again that the WordNet first sense heuristic
is a hard baseline to beat. Unfortunately, no domain-
specific disambiguation system participated in the
task. However, in the biomedical domain, the par-
ticipating systems show higher quality performances
than in the other considered domains.
As future directions, we would like to continue to
investigate the nature of this novel joint task, and to
concentrate on the differences between named entity
disambiguation and word sense disambiguation with
a special focus on non-European languages.
</bodyText>
<sectionHeader confidence="0.998137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999861">
The authors gratefully acknowl-
edge the support of the ERC Start-
ing Grant MultiJEDI No. 259234.
The organization of this task could not have been
possible without the help of many people. In partic-
ular, we would like to thank Jos´e Camacho Collados,
Claudio Delli Bovi, Tiziano Flati, Dario Garigliotti,
Ignacio Iacobacci, Luca Matteis, Mohammad Taher
Pilehvar, Alessandro Raganato, Daniele Vannella for
the help provided with the annotations, all the par-
ticipating teams for the useful discussions and Jim
McManus for his comments on the manuscript.
</bodyText>
<page confidence="0.997361">
295
</page>
<sectionHeader confidence="0.996281" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999877952380953">
Eneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa.
2014. Random Walks for Knowledge-Based Word
Sense Disambiguation. Computational Linguistics,
40(1):57–84.
S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens
Lehmann, Richard Cyganiak, and Zachary Ives. 2007.
DBpedia: A Nucleus for a Web of Open Data. In Proc.
of ISWC/ASWC, pages 722–735.
Amparo Elizabeth Cano Basave, Andrea Varga, Matthew
Rowe, Milan Stankovic, and Aba-Sah Dadzie. 2013.
Making Sense of Microposts (# MSM2013) Concept
Extraction Challenge. In Proc. of # MSM, pages 1–15.
Kurt D. Bollacker, Colin Evans, Praveen Paritosh, Tim
Sturge, and Jamie Taylor. 2008. Freebase: a collabo-
ratively created graph database for structuring human
knowledge. In Proc. of SIGMOD, pages 1247–1250.
David Carmel, Ming-Wei Chang, Evgeniy Gabrilovich,
Bo-June (Paul) Hsu, and Kuansan Wang. 2014.
ERD’14: Entity Recognition and Disambiguation
Challenge. SIGIR Forum, 48(2):63–77.
Marco Cornolti, Paolo Ferragina, and Massimiliano Cia-
ramita. 2013. A framework for benchmarking entity-
annotation systems. In Proc. of WWW, pages 249–
260.
´Eric Villemonte De La Clergerie, Olivier Hamon, Djamel
Mostefa, Christelle Ayache, Patrick Paroubek, and
Anne Vilnat. 2008. Passage: from french parser eval-
uation to large sized treebank. Proc. of LREC.
Nicolai Erbs, Torsten Zesch, and Iryna Gurevych. 2011.
Link Discovery: A Comprehensive Analysis. In Proc.
of ICSC, pages 83–86.
Paolo Ferragina and Ugo Scaiella. 2010. TAGME:
on-the-fly annotation of short text fragments (by
wikipedia entities). In Proc. of CIKM, pages 1625–
1628.
Jonathan G. Fiscus. 1997. A post-processing system
to yield reduced word error rates: Recognizer output
voting error reduction (rover). In Proc. of Automatic
Speech Recognition and Understanding, pages 347–
354.
Tiziano Flati, Daniele Vannella, Tommaso Pasini, and
Roberto Navigli. 2014. Two Is Bigger (and Better)
Than One: the Wikipedia Bitaxonomy Project. In
Proc. of the 52nd Annual Meeting of the Association
for Computational Linguistics, pages 945–955.
Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino,
Hagen F¨urstenau, Manfred Pinkal, Marc Spaniol,
Bilyana Taneva, Stefan Thater, and Gerhard Weikum.
2011. Robust Disambiguation of Named Entities in
Text. In Proc. of EMNLP, pages 782–792.
Eduard H. Hovy, Roberto Navigli, and Simone P.
Ponzetto. 2013. Collaboratively built semi-structured
content and Artificial Intelligence: The story so far.
Artificial Intelligence, 194:2–27.
Heng Ji, Joel Nothman, and Ben Hachey. 2014.
Overview of TAC-KBP2014 Entity Discovery and
Linking Tasks. In Proc. Text Analysis Conference
(TAC2014).
Jay J. Jiang and David W. Conrath. 1997. Semantic sim-
ilarity based on corpus statistics and lexical taxonomy.
In Proc. of the International Conference on Research
in Computational Linguistics, pages 19–33.
Els Lefever and Veronique Hoste. 2010. Semeval-2010
task 3: Cross-lingual word sense disambiguation. In
Proc. of SemEval, pages 15–20.
Els Lefever and V´eronique Hoste. 2013. SemEval-2013
Task 10: Cross-lingual Word Sense Disambiguation.
In Proc. of SemEval, pages 158–166.
Suresh Manandhar, Ioannis P. Klapaftis, Dmitriy Dli-
gach, and Sameer S. Pradhan. 2010. SemEval-2010
task 14: Word sense induction &amp; disambiguation. In
Proc. of SemEval, pages 63–68.
Steve L. Manion and Raazesh Sainudiin. 2014. An itera-
tive ‘sudoku style’ approach to subgraph-based word
sense disambiguation. In Proceedings of the Third
Joint Conference on Lexical and Computational Se-
mantics (*SEM 2014), pages 40–50, Dublin, Ireland,
August.
Diana McCarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2004. Finding predominant word senses in
untagged text. In Proceedings of the 42nd Annual
Meeting on Association for Computational Linguis-
tics, pages 279–286.
Pablo N. Mendes, Max Jakob, Andr´es Garc´ıa-Silva, and
Christian Bizer. 2011. DBpedia spotlight: shed-
ding light on the web of documents. In Proc. of I-
Semantics, pages 1–8.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representations
of words and phrases and their compositionality. In
Proc. of Advances in Neural Information Processing
Systems, pages 3111–3119.
George A. Miller, Richard Beckwith, Christiane Fell-
baum, Derek Gross, and Katherine Miller. 1990. In-
troduction to WordNet: An On-Line Lexical Database.
Int. Journal of Lexicography, 3(4):235–244.
David Milne and Ian H. Witten. 2008. Learning to link
with wikipedia. In Proc. of CIKM, pages 509–518.
Andrea Moro, Francesco Cecconi, and Roberto Navigli.
2014a. Multilingual word sense disambiguation and
entity linking for everybody. In Proc. of ISWC (P&amp;D),
pages 25–28.
Andrea Moro, Alessandro Raganato, and Roberto Nav-
igli. 2014b. Entity Linking meets Word Sense Dis-
ambiguation: A Unified Approach. Transactions of
</reference>
<page confidence="0.97728">
296
</page>
<reference confidence="0.998283333333333">
the Association for Computational Linguistics, 2:231–
244.
Roberto Navigli and Simone Paolo Ponzetto. 2012. Ba-
belNet: The automatic construction, evaluation and
application of a wide-coverage multilingual semantic
network. Artificial Intelligence, 193:217–250.
Roberto Navigli, Kenneth C. Litkowski, and Orin Har-
graves. 2007. SemEval-2007 Task 07: Coarse-
Grained English All-Words Task. In Proc. of
SemEval-2007, pages 30–35.
Roberto Navigli, David Jurgens, and Daniele Vannella.
2013. SemEval-2013 Task 12: Multilingual Word
Sense Disambiguation. In Second Joint Conference
on Lexical and Computational Semantics (*SEM), Vol-
ume 2: Proc. of the Seventh International Workshop on
Semantic Evaluation (SemEval 2013), pages 222–231,
Atlanta, Georgia, USA.
Roberto Navigli. 2009. Word sense disambiguation: A
survey. ACM Comput. Surv., 41(2):1–69.
Roberto Navigli. 2012. A quick tour of word sense
disambiguation, induction and related approaches. In
Proceedings of the 38th Conference on Current Trends
in Theory and Practice of Computer Science (SOF-
SEM), pages 115–129.
Martha Palmer, Christiane Fellbaum, Scott Cotton, Lau-
ren Delfs, and Hoa Trang Dang. 2001. English
tasks: All-words and verb lexical sample. In Proc. of
Senseval-2, pages 21–24.
Sameer S. Pradhan, Edward Loper, Dmitriy Dligach, and
Martha Palmer. 2007. SemEval-2007 task 17: En-
glish lexical sample, SRL and all words. In Proc. of
SemEval-2007, pages 87–92.
Delip Rao, Paul McNamee, and Mark Dredze. 2013. En-
tity linking: Finding extracted entities in a knowledge
base. In Multi-source, Multilingual Information Ex-
traction and Summarization, pages 93–115.
Benjamin Snyder and Martha Palmer. 2004. The English
all-words task. In Proc. of Senseval-3, pages 41–43.
Ricardo Usbeck, Michael R¨oder, Axel-Cyrille Ngonga
Ngomo, Ciro Baron, Andreas Both, Martin Br¨ummer,
Diego Ceccarelli, Marco Cornolti, Didier Cherix,
Bernd Eickmann, Paolo Ferragina, Christiane Lemke,
Andrea Moro, Roberto Navigli, Francesco Piccinno,
Giuseppe Rizzo, Harald Sack, Ren´e Speck, Rapha¨el
Troncy, J¨org Waitelonis, and Lars Wesemann. 2015.
GERBIL - General Entity Annotator Benchmark. In
Proc. of WWW.
Zhi Zhong and Hwee Tou Ng. 2010. It Makes Sense:
A Wide-Coverage Word Sense Disambiguation Sys-
tem for Free Text. In Proc. of the ACL 2010 System
Demonstrations, pages 78–83, Uppsala, Sweden, July.
</reference>
<page confidence="0.997414">
297
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.824221">
<title confidence="0.933587">SemEval-2015 Task 13: Multilingual All-Words Sense Disambiguation and Entity Linking</title>
<author confidence="0.973761">Moro Navigli</author>
<affiliation confidence="0.99076">Dipartimento di Informatica, Sapienza Universit`a di Roma,</affiliation>
<address confidence="0.994406">Viale Regina Elena 295, 00161 Roma, Italy</address>
<abstract confidence="0.9981785">In this paper we present the Multilingual All- Words Sense Disambiguation and Entity Linking task. Word Sense Disambiguation (WSD) and Entity Linking (EL) are well-known problems in the Natural Language Processing field and both address the lexical ambiguity of language. Their main difference lies in the kind of meaning inventories that are used: EL uses encyclopedic knowledge, while WSD uses lexicographic information. Our aim with this task is to analyze whether, and if so, how, using a resource that integrates both kinds of inventories (i.e., BabelNet 2.5.1) might enable WSD and EL to be solved by means of similar (even, the same) methods. Moreover, we investigate this task in a multilingual setting and for some specific domains.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
</authors>
<title>Oier Lopez de Lacalle, and Aitor Soroa.</title>
<date>2014</date>
<journal>Computational Linguistics,</journal>
<volume>40</volume>
<issue>1</issue>
<marker>Agirre, 2014</marker>
<rawString>Eneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa. 2014. Random Walks for Knowledge-Based Word Sense Disambiguation. Computational Linguistics, 40(1):57–84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S¨oren Auer</author>
<author>Christian Bizer</author>
<author>Georgi Kobilarov</author>
<author>Jens Lehmann</author>
<author>Richard Cyganiak</author>
<author>Zachary Ives</author>
</authors>
<title>DBpedia: A Nucleus for a Web of Open Data.</title>
<date>2007</date>
<booktitle>In Proc. of ISWC/ASWC,</booktitle>
<pages>722--735</pages>
<contexts>
<context position="2644" citStr="Auer et al., 2007" startWordPosition="419" endWordPosition="422">phic perspective, while EL tackles it from an encyclopedic one. Specifically, the main difference between the two tasks lies in the kind of inventory they use. For instance, WordNet (Miller et al., 1990), a manually curated semantic network for the English language, has become the main reference inventory for English WSD systems thanks to its wide coverage of verbs, adverbs, adjectives and common nouns. More recently, Wikipedia has been shown to be an optimal resource for recovering named entities, and has consequently become - together with all its semi-automatic derivations such as DBpedia (Auer et al., 2007) and Freebase (Bollacker et al., 2008) - the main reference inventory for EL systems. Over the years, the research community has typically focused on each of these tasks separately. Recently, however, joint approaches have been proposed (Moro et al., 2014b). One of the reasons for pursuing the unification of these tasks derives from the current trend in knowledge acquisition which consists of the seamless integration of encyclopedic and lexicographic knowledge within structured language resources (Hovy et al., 2013). A case in point here is BabelNet1, a multilingual semantic network and encycl</context>
</contexts>
<marker>Auer, Bizer, Kobilarov, Lehmann, Cyganiak, Ives, 2007</marker>
<rawString>S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives. 2007. DBpedia: A Nucleus for a Web of Open Data. In Proc. of ISWC/ASWC, pages 722–735.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amparo Elizabeth Cano Basave</author>
<author>Andrea Varga</author>
<author>Matthew Rowe</author>
<author>Milan Stankovic</author>
<author>Aba-Sah Dadzie</author>
</authors>
<date>2013</date>
<booktitle>Making Sense of Microposts (# MSM2013) Concept Extraction Challenge. In Proc. of # MSM,</booktitle>
<pages>1--15</pages>
<contexts>
<context position="5632" citStr="Basave et al., 2013" startWordPosition="893" endWordPosition="896">versions in three languages (English, Italian and Spanish) have been provided. Differently from previous editions (Navigli et al., 2013; Lefever and Hoste, 2013; Manandhar et al., 2010; Lefever and Hoste, 2010; Pradhan et al., 2007; Navigli et al., 2007; Snyder and Palmer, 2004; Palmer et al., 2001), in this task we do not make explicit to the participating systems which fragments of the input text should be disambiguated, so as to have, on the one hand, a more realistic scenario, and, on the other hand, to follow the recent trend in EL challenges such as TAC KBP (Ji et al., 2014), MicroPost (Basave et al., 2013) and ERD (Carmel et al., 2014). 2.1 Corpora The documents considered in this task are taken from the OPUS project (http://opus.lingfil.uu.se/), more specifically from the EMEA (European Medicines Agency documents), KDEdoc (the KDE manual corpus) and “The EU bookshop corpus”, which make available parallel and POS-tagged documents. We took four documents from these repositories. Two documents contain medical information about drugs. One document consists of the manual of a mathematical graph calculator (i.e., KAlgebra). The remaining document contains a formal discussion about social issues, lik</context>
</contexts>
<marker>Basave, Varga, Rowe, Stankovic, Dadzie, 2013</marker>
<rawString>Amparo Elizabeth Cano Basave, Andrea Varga, Matthew Rowe, Milan Stankovic, and Aba-Sah Dadzie. 2013. Making Sense of Microposts (# MSM2013) Concept Extraction Challenge. In Proc. of # MSM, pages 1–15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kurt D Bollacker</author>
<author>Colin Evans</author>
<author>Praveen Paritosh</author>
<author>Tim Sturge</author>
<author>Jamie Taylor</author>
</authors>
<title>Freebase: a collaboratively created graph database for structuring human knowledge.</title>
<date>2008</date>
<booktitle>In Proc. of SIGMOD,</booktitle>
<pages>1247--1250</pages>
<contexts>
<context position="2682" citStr="Bollacker et al., 2008" startWordPosition="425" endWordPosition="428">s it from an encyclopedic one. Specifically, the main difference between the two tasks lies in the kind of inventory they use. For instance, WordNet (Miller et al., 1990), a manually curated semantic network for the English language, has become the main reference inventory for English WSD systems thanks to its wide coverage of verbs, adverbs, adjectives and common nouns. More recently, Wikipedia has been shown to be an optimal resource for recovering named entities, and has consequently become - together with all its semi-automatic derivations such as DBpedia (Auer et al., 2007) and Freebase (Bollacker et al., 2008) - the main reference inventory for EL systems. Over the years, the research community has typically focused on each of these tasks separately. Recently, however, joint approaches have been proposed (Moro et al., 2014b). One of the reasons for pursuing the unification of these tasks derives from the current trend in knowledge acquisition which consists of the seamless integration of encyclopedic and lexicographic knowledge within structured language resources (Hovy et al., 2013). A case in point here is BabelNet1, a multilingual semantic network and encyclopedic dictionary (Navigli and Ponzett</context>
</contexts>
<marker>Bollacker, Evans, Paritosh, Sturge, Taylor, 2008</marker>
<rawString>Kurt D. Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proc. of SIGMOD, pages 1247–1250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Carmel</author>
<author>Ming-Wei Chang</author>
<author>Evgeniy Gabrilovich</author>
<author>Bo-June Hsu</author>
<author>Kuansan Wang</author>
</authors>
<title>ERD’14: Entity Recognition and Disambiguation Challenge.</title>
<date>2014</date>
<journal>SIGIR Forum,</journal>
<volume>48</volume>
<issue>2</issue>
<contexts>
<context position="5662" citStr="Carmel et al., 2014" startWordPosition="899" endWordPosition="902">nglish, Italian and Spanish) have been provided. Differently from previous editions (Navigli et al., 2013; Lefever and Hoste, 2013; Manandhar et al., 2010; Lefever and Hoste, 2010; Pradhan et al., 2007; Navigli et al., 2007; Snyder and Palmer, 2004; Palmer et al., 2001), in this task we do not make explicit to the participating systems which fragments of the input text should be disambiguated, so as to have, on the one hand, a more realistic scenario, and, on the other hand, to follow the recent trend in EL challenges such as TAC KBP (Ji et al., 2014), MicroPost (Basave et al., 2013) and ERD (Carmel et al., 2014). 2.1 Corpora The documents considered in this task are taken from the OPUS project (http://opus.lingfil.uu.se/), more specifically from the EMEA (European Medicines Agency documents), KDEdoc (the KDE manual corpus) and “The EU bookshop corpus”, which make available parallel and POS-tagged documents. We took four documents from these repositories. Two documents contain medical information about drugs. One document consists of the manual of a mathematical graph calculator (i.e., KAlgebra). The remaining document contains a formal discussion about social issues, like supporting elderly workers a</context>
</contexts>
<marker>Carmel, Chang, Gabrilovich, Hsu, Wang, 2014</marker>
<rawString>David Carmel, Ming-Wei Chang, Evgeniy Gabrilovich, Bo-June (Paul) Hsu, and Kuansan Wang. 2014. ERD’14: Entity Recognition and Disambiguation Challenge. SIGIR Forum, 48(2):63–77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Cornolti</author>
<author>Paolo Ferragina</author>
<author>Massimiliano Ciaramita</author>
</authors>
<title>A framework for benchmarking entityannotation systems.</title>
<date>2013</date>
<booktitle>In Proc. of WWW,</booktitle>
<pages>249--260</pages>
<contexts>
<context position="1742" citStr="Cornolti et al., 2013" startWordPosition="268" endWordPosition="271">s and related areas. Their focus has been to provide objective evaluations of methods within the wide spectrum of semantic techniques for tasks mainly related to automatic text understanding. Through SemEval-2015 task 13 we both continue and renew the longstanding tradition of disambiguation tasks, by addressing multilingual WSD and EL in a joint manner. WSD (Navigli, 2009; Navigli, 2012) is a historical task aimed at explicitly assigning meanings to single-word and multi-word occurrences within text, a task which today is more alive than ever in the research community. EL (Erbs et al., 2011; Cornolti et al., 2013; Rao et al., 2013) is a more recent task which aims at discovering mentions of entities within a text and linking them to the most suitable entry in a knowledge base. Both these tasks aim at handling the inherent ambiguity of natural language, however WSD tackles it from a lexicographic perspective, while EL tackles it from an encyclopedic one. Specifically, the main difference between the two tasks lies in the kind of inventory they use. For instance, WordNet (Miller et al., 1990), a manually curated semantic network for the English language, has become the main reference inventory for Engli</context>
</contexts>
<marker>Cornolti, Ferragina, Ciaramita, 2013</marker>
<rawString>Marco Cornolti, Paolo Ferragina, and Massimiliano Ciaramita. 2013. A framework for benchmarking entityannotation systems. In Proc. of WWW, pages 249– 260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>´Eric Villemonte</author>
</authors>
<title>De La Clergerie, Olivier Hamon, Djamel Mostefa, Christelle Ayache, Patrick Paroubek, and Anne Vilnat.</title>
<date>2008</date>
<booktitle>Proc. of LREC.</booktitle>
<marker>Villemonte, 2008</marker>
<rawString>´Eric Villemonte De La Clergerie, Olivier Hamon, Djamel Mostefa, Christelle Ayache, Patrick Paroubek, and Anne Vilnat. 2008. Passage: from french parser evaluation to large sized treebank. Proc. of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicolai Erbs</author>
<author>Torsten Zesch</author>
<author>Iryna Gurevych</author>
</authors>
<title>Link Discovery: A Comprehensive Analysis.</title>
<date>2011</date>
<booktitle>In Proc. of ICSC,</booktitle>
<pages>83--86</pages>
<contexts>
<context position="1719" citStr="Erbs et al., 2011" startWordPosition="264" endWordPosition="267">tational linguistics and related areas. Their focus has been to provide objective evaluations of methods within the wide spectrum of semantic techniques for tasks mainly related to automatic text understanding. Through SemEval-2015 task 13 we both continue and renew the longstanding tradition of disambiguation tasks, by addressing multilingual WSD and EL in a joint manner. WSD (Navigli, 2009; Navigli, 2012) is a historical task aimed at explicitly assigning meanings to single-word and multi-word occurrences within text, a task which today is more alive than ever in the research community. EL (Erbs et al., 2011; Cornolti et al., 2013; Rao et al., 2013) is a more recent task which aims at discovering mentions of entities within a text and linking them to the most suitable entry in a knowledge base. Both these tasks aim at handling the inherent ambiguity of natural language, however WSD tackles it from a lexicographic perspective, while EL tackles it from an encyclopedic one. Specifically, the main difference between the two tasks lies in the kind of inventory they use. For instance, WordNet (Miller et al., 1990), a manually curated semantic network for the English language, has become the main refere</context>
</contexts>
<marker>Erbs, Zesch, Gurevych, 2011</marker>
<rawString>Nicolai Erbs, Torsten Zesch, and Iryna Gurevych. 2011. Link Discovery: A Comprehensive Analysis. In Proc. of ICSC, pages 83–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paolo Ferragina</author>
<author>Ugo Scaiella</author>
</authors>
<title>TAGME: on-the-fly annotation of short text fragments (by wikipedia entities).</title>
<date>2010</date>
<booktitle>In Proc. of CIKM,</booktitle>
<pages>1625--1628</pages>
<contexts>
<context position="14417" citStr="Ferragina and Scaiella, 2010" startWordPosition="2384" endWordPosition="2387">mma. EBL-Hope (Unsupervised + Sense relevance). This approach uses a modified version of the Lesk algorithm and the Jiang &amp; Conrath similarity measure (Jiang and Conrath, 1997). It validates the output from both techniques for enhanced accuracy and exploits semantic relations and corpus (SemCor) information available in BabelNet and WordNet in an unsupervised manner. el92 (Systems mix). This system is a generaldomain system for entity detection and linking. It does not perform WSD. The system combines, via a weighted voting, Entity Linking outputs from four publicly available services: Tagme (Ferragina and Scaiella, 2010), DBpedia Spotlight (Mendes et al., 2011), Wikipedia Miner (Milne and Witten, 2008) and Babelfy (Moro et al., 2014b; Moro et al., 2014a). The different runs correspond to different settings in the weighting formula (De La Clergerie et al., 2008; Fiscus, 1997). LIMSI (Unsupervised + Sense relevance). The system performs WSD by taking advantage of the parallelism of the test data, a feature that was not exploited by the systems that participated in the SemEval-2013 Multilingual Word Sense Disambiguation task 12 (Navigli et al., 2013). The system needs no training and is applied directly to the t</context>
</contexts>
<marker>Ferragina, Scaiella, 2010</marker>
<rawString>Paolo Ferragina and Ugo Scaiella. 2010. TAGME: on-the-fly annotation of short text fragments (by wikipedia entities). In Proc. of CIKM, pages 1625– 1628.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan G Fiscus</author>
</authors>
<title>A post-processing system to yield reduced word error rates: Recognizer output voting error reduction (rover).</title>
<date>1997</date>
<booktitle>In Proc. of Automatic Speech Recognition and Understanding,</booktitle>
<pages>347--354</pages>
<contexts>
<context position="14676" citStr="Fiscus, 1997" startWordPosition="2427" endWordPosition="2428">s and corpus (SemCor) information available in BabelNet and WordNet in an unsupervised manner. el92 (Systems mix). This system is a generaldomain system for entity detection and linking. It does not perform WSD. The system combines, via a weighted voting, Entity Linking outputs from four publicly available services: Tagme (Ferragina and Scaiella, 2010), DBpedia Spotlight (Mendes et al., 2011), Wikipedia Miner (Milne and Witten, 2008) and Babelfy (Moro et al., 2014b; Moro et al., 2014a). The different runs correspond to different settings in the weighting formula (De La Clergerie et al., 2008; Fiscus, 1997). LIMSI (Unsupervised + Sense relevance). The system performs WSD by taking advantage of the parallelism of the test data, a feature that was not exploited by the systems that participated in the SemEval-2013 Multilingual Word Sense Disambiguation task 12 (Navigli et al., 2013). The system needs no training and is applied directly to the test dataset, nor does it use distributional (context) information. The texts are sentence- and wordaligned pairwise, and content words are tagged by their translations in another language. The alignments serve to retrieve the BabelNet synsets that are relevan</context>
</contexts>
<marker>Fiscus, 1997</marker>
<rawString>Jonathan G. Fiscus. 1997. A post-processing system to yield reduced word error rates: Recognizer output voting error reduction (rover). In Proc. of Automatic Speech Recognition and Understanding, pages 347– 354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tiziano Flati</author>
<author>Daniele Vannella</author>
<author>Tommaso Pasini</author>
<author>Roberto Navigli</author>
</authors>
<title>Two Is Bigger (and Better) Than One: the Wikipedia Bitaxonomy Project.</title>
<date>2014</date>
<booktitle>In Proc. of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>945--955</pages>
<contexts>
<context position="8902" citStr="Flati et al., 2014" startWordPosition="1463" endWordPosition="1466">1 22 9.0 9.5 10.1 10.3 2.9 5.9 135 276 Maths and ES 308 277 10 21 7.5 7.6 7.9 8.0 3.8 6.0 120 - computer IT 313 275 15 23 6.9 6.8 7.3 7.6 3.3 4.4 136 - EN 313 268 29 16 7.4 6.9 9.1 6.3 1.5 4.1 119 294 Social ES 303 259 27 17 7.4 7.4 8.1 7.3 3.2 5.9 102 - issues IT 302 265 22 15 6.6 6.5 7.7 6.8 1.7 3.0 101 - EN 1261 1094 81 86 8.1 7.6 9.1 9.5 2.4 4.4 549 1119 All ES 1239 1088 67 84 6.8 6.8 6.8 8.4 3.2 5.9 473 - IT 1225 1085 66 74 6.1 5.9 6.6 6.7 2.8 3.5 491 - Table 1: Statistics of the datasets. gether with the available synonyms and hypernyms (as found in WordNet and the Wikipedia Bitaxonomy (Flati et al., 2014)). The taggers agreed on at least one meaning for 68% of the instances. A third tagger acted as judge by going through all the items and discarding overly general or irrelevant annotations, especially in the case of disagreement between the two taggers. To enforce coherence and spot missing annotations, we projected the English annotations to the other two languages. Finally, the third tagger determined if the projected English annotations that were missing in one of the other two languages were either correctly not included, or if the taggers had actually missed a correct annotation. As a res</context>
</contexts>
<marker>Flati, Vannella, Pasini, Navigli, 2014</marker>
<rawString>Tiziano Flati, Daniele Vannella, Tommaso Pasini, and Roberto Navigli. 2014. Two Is Bigger (and Better) Than One: the Wikipedia Bitaxonomy Project. In Proc. of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 945–955.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Hoffart</author>
<author>Mohamed Amir Yosef</author>
<author>Ilaria Bordino</author>
<author>Hagen F¨urstenau</author>
<author>Manfred Pinkal</author>
<author>Marc Spaniol</author>
<author>Bilyana Taneva</author>
<author>Stefan Thater</author>
<author>Gerhard Weikum</author>
</authors>
<title>Robust Disambiguation of Named Entities in Text.</title>
<date>2011</date>
<booktitle>In Proc. of EMNLP,</booktitle>
<pages>782--792</pages>
<marker>Hoffart, Yosef, Bordino, F¨urstenau, Pinkal, Spaniol, Taneva, Thater, Weikum, 2011</marker>
<rawString>Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen F¨urstenau, Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, and Gerhard Weikum. 2011. Robust Disambiguation of Named Entities in Text. In Proc. of EMNLP, pages 782–792.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard H Hovy</author>
<author>Roberto Navigli</author>
<author>Simone P Ponzetto</author>
</authors>
<title>Collaboratively built semi-structured content and Artificial Intelligence: The story so far.</title>
<date>2013</date>
<journal>Artificial Intelligence,</journal>
<pages>194--2</pages>
<contexts>
<context position="3165" citStr="Hovy et al., 2013" startWordPosition="501" endWordPosition="504">tly become - together with all its semi-automatic derivations such as DBpedia (Auer et al., 2007) and Freebase (Bollacker et al., 2008) - the main reference inventory for EL systems. Over the years, the research community has typically focused on each of these tasks separately. Recently, however, joint approaches have been proposed (Moro et al., 2014b). One of the reasons for pursuing the unification of these tasks derives from the current trend in knowledge acquisition which consists of the seamless integration of encyclopedic and lexicographic knowledge within structured language resources (Hovy et al., 2013). A case in point here is BabelNet1, a multilingual semantic network and encyclopedic dictionary (Navigli and Ponzetto, 2012). Resources like BabelNet provide a common ground for the tasks of WSD and EL. 1http://babelnet.org 288 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 288–297, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics In this task our goal is to promote research in the direction of joint word sense and named entity disambiguation, so as to concentrate research efforts on the aspects that differentiate t</context>
</contexts>
<marker>Hovy, Navigli, Ponzetto, 2013</marker>
<rawString>Eduard H. Hovy, Roberto Navigli, and Simone P. Ponzetto. 2013. Collaboratively built semi-structured content and Artificial Intelligence: The story so far. Artificial Intelligence, 194:2–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Joel Nothman</author>
<author>Ben Hachey</author>
</authors>
<title>Overview of TAC-KBP2014 Entity Discovery and Linking Tasks.</title>
<date>2014</date>
<booktitle>In Proc. Text Analysis Conference (TAC2014).</booktitle>
<contexts>
<context position="5599" citStr="Ji et al., 2014" startWordPosition="888" endWordPosition="891">documents for which parallel versions in three languages (English, Italian and Spanish) have been provided. Differently from previous editions (Navigli et al., 2013; Lefever and Hoste, 2013; Manandhar et al., 2010; Lefever and Hoste, 2010; Pradhan et al., 2007; Navigli et al., 2007; Snyder and Palmer, 2004; Palmer et al., 2001), in this task we do not make explicit to the participating systems which fragments of the input text should be disambiguated, so as to have, on the one hand, a more realistic scenario, and, on the other hand, to follow the recent trend in EL challenges such as TAC KBP (Ji et al., 2014), MicroPost (Basave et al., 2013) and ERD (Carmel et al., 2014). 2.1 Corpora The documents considered in this task are taken from the OPUS project (http://opus.lingfil.uu.se/), more specifically from the EMEA (European Medicines Agency documents), KDEdoc (the KDE manual corpus) and “The EU bookshop corpus”, which make available parallel and POS-tagged documents. We took four documents from these repositories. Two documents contain medical information about drugs. One document consists of the manual of a mathematical graph calculator (i.e., KAlgebra). The remaining document contains a formal di</context>
</contexts>
<marker>Ji, Nothman, Hachey, 2014</marker>
<rawString>Heng Ji, Joel Nothman, and Ben Hachey. 2014. Overview of TAC-KBP2014 Entity Discovery and Linking Tasks. In Proc. Text Analysis Conference (TAC2014).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay J Jiang</author>
<author>David W Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1997</date>
<booktitle>In Proc. of the International Conference on Research in Computational Linguistics,</booktitle>
<pages>pages</pages>
<contexts>
<context position="13964" citStr="Jiang and Conrath, 1997" startWordPosition="2315" endWordPosition="2318">, it does not apply discrete optimization, but continuous optimization on the normalized sum of all objectives. The disambiguation procedure aims to optimize the objective function by iteratively updating the candidate probabilities for each fragment. As far as verbs are concerned, a feed-forward neural network is trained using local features such as arguments of the semantic roles of a verb in a sentence, context words, and the verb and its lemma. EBL-Hope (Unsupervised + Sense relevance). This approach uses a modified version of the Lesk algorithm and the Jiang &amp; Conrath similarity measure (Jiang and Conrath, 1997). It validates the output from both techniques for enhanced accuracy and exploits semantic relations and corpus (SemCor) information available in BabelNet and WordNet in an unsupervised manner. el92 (Systems mix). This system is a generaldomain system for entity detection and linking. It does not perform WSD. The system combines, via a weighted voting, Entity Linking outputs from four publicly available services: Tagme (Ferragina and Scaiella, 2010), DBpedia Spotlight (Mendes et al., 2011), Wikipedia Miner (Milne and Witten, 2008) and Babelfy (Moro et al., 2014b; Moro et al., 2014a). The diffe</context>
</contexts>
<marker>Jiang, Conrath, 1997</marker>
<rawString>Jay J. Jiang and David W. Conrath. 1997. Semantic similarity based on corpus statistics and lexical taxonomy. In Proc. of the International Conference on Research in Computational Linguistics, pages 19–33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Els Lefever</author>
<author>Veronique Hoste</author>
</authors>
<title>Semeval-2010 task 3: Cross-lingual word sense disambiguation.</title>
<date>2010</date>
<booktitle>In Proc. of SemEval,</booktitle>
<pages>15--20</pages>
<contexts>
<context position="5221" citStr="Lefever and Hoste, 2010" startWordPosition="817" endWordPosition="820">in different specific domains (biomedical domain, maths and computer domain, and a broader domain about social issues). Our goal is to further investigate the distance between research efforts regarding the dichotomy EL vs. WSD and those regarding the dichotomy open domain vs. closed domain. 2 Task Setup The task setup consists of annotating four tokenized and part-of-speech tagged documents for which parallel versions in three languages (English, Italian and Spanish) have been provided. Differently from previous editions (Navigli et al., 2013; Lefever and Hoste, 2013; Manandhar et al., 2010; Lefever and Hoste, 2010; Pradhan et al., 2007; Navigli et al., 2007; Snyder and Palmer, 2004; Palmer et al., 2001), in this task we do not make explicit to the participating systems which fragments of the input text should be disambiguated, so as to have, on the one hand, a more realistic scenario, and, on the other hand, to follow the recent trend in EL challenges such as TAC KBP (Ji et al., 2014), MicroPost (Basave et al., 2013) and ERD (Carmel et al., 2014). 2.1 Corpora The documents considered in this task are taken from the OPUS project (http://opus.lingfil.uu.se/), more specifically from the EMEA (European Med</context>
</contexts>
<marker>Lefever, Hoste, 2010</marker>
<rawString>Els Lefever and Veronique Hoste. 2010. Semeval-2010 task 3: Cross-lingual word sense disambiguation. In Proc. of SemEval, pages 15–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Els Lefever</author>
<author>V´eronique Hoste</author>
</authors>
<date>2013</date>
<booktitle>SemEval-2013 Task 10: Cross-lingual Word Sense Disambiguation. In Proc. of SemEval,</booktitle>
<pages>158--166</pages>
<contexts>
<context position="5172" citStr="Lefever and Hoste, 2013" startWordPosition="809" endWordPosition="812">ventories (i.e., named entities and word senses) in different specific domains (biomedical domain, maths and computer domain, and a broader domain about social issues). Our goal is to further investigate the distance between research efforts regarding the dichotomy EL vs. WSD and those regarding the dichotomy open domain vs. closed domain. 2 Task Setup The task setup consists of annotating four tokenized and part-of-speech tagged documents for which parallel versions in three languages (English, Italian and Spanish) have been provided. Differently from previous editions (Navigli et al., 2013; Lefever and Hoste, 2013; Manandhar et al., 2010; Lefever and Hoste, 2010; Pradhan et al., 2007; Navigli et al., 2007; Snyder and Palmer, 2004; Palmer et al., 2001), in this task we do not make explicit to the participating systems which fragments of the input text should be disambiguated, so as to have, on the one hand, a more realistic scenario, and, on the other hand, to follow the recent trend in EL challenges such as TAC KBP (Ji et al., 2014), MicroPost (Basave et al., 2013) and ERD (Carmel et al., 2014). 2.1 Corpora The documents considered in this task are taken from the OPUS project (http://opus.lingfil.uu.se</context>
</contexts>
<marker>Lefever, Hoste, 2013</marker>
<rawString>Els Lefever and V´eronique Hoste. 2013. SemEval-2013 Task 10: Cross-lingual Word Sense Disambiguation. In Proc. of SemEval, pages 158–166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suresh Manandhar</author>
<author>Ioannis P Klapaftis</author>
<author>Dmitriy Dligach</author>
<author>Sameer S Pradhan</author>
</authors>
<date>2010</date>
<booktitle>SemEval-2010 task 14: Word sense induction &amp; disambiguation. In Proc. of SemEval,</booktitle>
<pages>63--68</pages>
<contexts>
<context position="5196" citStr="Manandhar et al., 2010" startWordPosition="813" endWordPosition="816">tities and word senses) in different specific domains (biomedical domain, maths and computer domain, and a broader domain about social issues). Our goal is to further investigate the distance between research efforts regarding the dichotomy EL vs. WSD and those regarding the dichotomy open domain vs. closed domain. 2 Task Setup The task setup consists of annotating four tokenized and part-of-speech tagged documents for which parallel versions in three languages (English, Italian and Spanish) have been provided. Differently from previous editions (Navigli et al., 2013; Lefever and Hoste, 2013; Manandhar et al., 2010; Lefever and Hoste, 2010; Pradhan et al., 2007; Navigli et al., 2007; Snyder and Palmer, 2004; Palmer et al., 2001), in this task we do not make explicit to the participating systems which fragments of the input text should be disambiguated, so as to have, on the one hand, a more realistic scenario, and, on the other hand, to follow the recent trend in EL challenges such as TAC KBP (Ji et al., 2014), MicroPost (Basave et al., 2013) and ERD (Carmel et al., 2014). 2.1 Corpora The documents considered in this task are taken from the OPUS project (http://opus.lingfil.uu.se/), more specifically fr</context>
</contexts>
<marker>Manandhar, Klapaftis, Dligach, Pradhan, 2010</marker>
<rawString>Suresh Manandhar, Ioannis P. Klapaftis, Dmitriy Dligach, and Sameer S. Pradhan. 2010. SemEval-2010 task 14: Word sense induction &amp; disambiguation. In Proc. of SemEval, pages 63–68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve L Manion</author>
<author>Raazesh Sainudiin</author>
</authors>
<title>An iterative ‘sudoku style’ approach to subgraph-based word sense disambiguation.</title>
<date>2014</date>
<booktitle>In Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014),</booktitle>
<pages>40--50</pages>
<location>Dublin, Ireland,</location>
<contexts>
<context position="16525" citStr="Manion and Sainudiin, 2014" startWordPosition="2723" endWordPosition="2726">or instances with no aligned translation, or in cases where the translation was not found in any of the synsets available for the word in BabelNet. SUDOKU (Unsupervised). This deterministic constraint-based approach relies on a reasonable degree of “document monosemy” (percentage of unique monosemous lemmas in a document) and exploits Personalised PageRank (Agirre et al., 2014) to select the best candidate. The PPR is started with 291 a surfing vector biased towards monosemous words (i.e., their respective sense). Each submission differs by its imposed constraints: Run1 is the plain approach (Manion and Sainudiin, 2014) applied at the document level; Run2 is the iterative version of the previous approach applied at the document level and with words disambiguated in order of increasing polysemy; Run3 is like Run2, but it is first applied to nouns and then to verbs, adjectives, and adverbs. TeamUFAL (Unsupervised). This system exploits Apache Lucene search engine to index Wikipedia documents, Wiktionary entries and WordNet senses. Then, to perform disambiguation, the Lucene ranking method is used to query the index with multiple queries (consisting of the text fragment and context words). Finally, all query re</context>
</contexts>
<marker>Manion, Sainudiin, 2014</marker>
<rawString>Steve L. Manion and Raazesh Sainudiin. 2014. An iterative ‘sudoku style’ approach to subgraph-based word sense disambiguation. In Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 40–50, Dublin, Ireland, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Rob Koeling</author>
<author>Julie Weeds</author>
<author>John Carroll</author>
</authors>
<title>Finding predominant word senses in untagged text.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>279--286</pages>
<contexts>
<context position="18222" citStr="McCarthy et al., 2004" startWordPosition="2987" endWordPosition="2990">rface forms extracted from BabelNet synsets. Moreover, each synset has a prior probability computed over an annotated corpus. For WordNet synsets, SemCor is exploited, while for Wikipedia entities the number of citations in Wikipedia internal links is counted. vua-background (Partially supervised). This approach exploits the Named Entities contained in the test data to generate a background corpus. This is done by finding similar DBpedia entities for the entities in the input documents. Using this background corpus, the system tries to find the predominant sense of the words in the test data (McCarthy et al., 2004). If a predominant sense is recognized for a specific lemma, then it is used, otherwise the system falls back to the “It Makes Sense” WSD system (Zhong and Ng, 2010). 3During the evaluation period the system did not return any annotation for adjectives due to a misinterpretation of the POS tag set. For full evaluations see the system paper. WSD-games (Unsupervised). This approach is formulated in terms of Evolutionary Game Theory, where each word to be disambiguated is represented as a node in a graph and each sense as a class. The proposed algorithm performs a consistent class assignment of s</context>
<context position="28393" citStr="McCarthy et al., 2004" startWordPosition="4838" endWordPosition="4841">ch have already been shown to be useful for attaining state-of-the-art performances in EL (Moro et al., 2014b). Interestingly, in the Italian dataset the system UNIBA (which is based on an extended version of the Lesk measure and a semantic relatedness measure) obtains the same performance for NE as the EBL-Hope system. Social issues domain. In Table 6 we show the performance on our last domain. In this social issues domain DFKI confirms its quality on disambiguating nouns and named entities, while for verbs the best system is vua-background, which is based on the predominant sense algorithm (McCarthy et al., 2004) and, as a fallback routine, on the “It Makes Sense” supervised WSD system (Zhong and Ng, 2010). For the other two languages the SUDOKU system obtains the best scores, with the exception of adverbs in the Italian dataset where the UNIBA system is able to reach an F1 score of 100%. 5 Conclusion and Future Directions In this paper we described the organization and results obtained within the SemEval 2015 task 13: Multilingual Word Sense Disambiguation. Our analysis of the results revealed interesting aspects of the integration of WSD and EL tasks, such as the effectiveness of techniques like sem</context>
</contexts>
<marker>McCarthy, Koeling, Weeds, Carroll, 2004</marker>
<rawString>Diana McCarthy, Rob Koeling, Julie Weeds, and John Carroll. 2004. Finding predominant word senses in untagged text. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, pages 279–286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pablo N Mendes</author>
<author>Max Jakob</author>
<author>Andr´es Garc´ıa-Silva</author>
<author>Christian Bizer</author>
</authors>
<title>DBpedia spotlight: shedding light on the web of documents.</title>
<date>2011</date>
<booktitle>In Proc. of ISemantics,</booktitle>
<pages>1--8</pages>
<marker>Mendes, Jakob, Garc´ıa-Silva, Bizer, 2011</marker>
<rawString>Pablo N. Mendes, Max Jakob, Andr´es Garc´ıa-Silva, and Christian Bizer. 2011. DBpedia spotlight: shedding light on the web of documents. In Proc. of ISemantics, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Greg S Corrado</author>
<author>Jeff Dean</author>
</authors>
<title>Distributed representations of words and phrases and their compositionality.</title>
<date>2013</date>
<booktitle>In Proc. of Advances in Neural Information Processing Systems,</booktitle>
<pages>3111--3119</pages>
<contexts>
<context position="17501" citStr="Mikolov et al., 2013" startWordPosition="2875" endWordPosition="2878">ex Wikipedia documents, Wiktionary entries and WordNet senses. Then, to perform disambiguation, the Lucene ranking method is used to query the index with multiple queries (consisting of the text fragment and context words). Finally, all query results are merged and the disambiguated meaning is selected thanks to a simple threshold heuristic. UNIBA (Unsupervised + Sense relevance). This system3 extends two well-known variations of the Lesk WSD method. The main contribution of the approach relies on the use of a word similarity function defined on a distributional semantic space (Word2vec tool (Mikolov et al., 2013)) to compute the gloss-context overlap. Entities are identified by exploiting a list of possible surface forms extracted from BabelNet synsets. Moreover, each synset has a prior probability computed over an annotated corpus. For WordNet synsets, SemCor is exploited, while for Wikipedia entities the number of citations in Wikipedia internal links is counted. vua-background (Partially supervised). This approach exploits the Named Entities contained in the test data to generate a background corpus. This is done by finding similar DBpedia entities for the entities in the input documents. Using thi</context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Proc. of Advances in Neural Information Processing Systems, pages 3111–3119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Richard Beckwith</author>
<author>Christiane Fellbaum</author>
<author>Derek Gross</author>
<author>Katherine Miller</author>
</authors>
<title>Introduction to WordNet: An On-Line Lexical Database.</title>
<date>1990</date>
<journal>Int. Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="2229" citStr="Miller et al., 1990" startWordPosition="353" endWordPosition="356">ences within text, a task which today is more alive than ever in the research community. EL (Erbs et al., 2011; Cornolti et al., 2013; Rao et al., 2013) is a more recent task which aims at discovering mentions of entities within a text and linking them to the most suitable entry in a knowledge base. Both these tasks aim at handling the inherent ambiguity of natural language, however WSD tackles it from a lexicographic perspective, while EL tackles it from an encyclopedic one. Specifically, the main difference between the two tasks lies in the kind of inventory they use. For instance, WordNet (Miller et al., 1990), a manually curated semantic network for the English language, has become the main reference inventory for English WSD systems thanks to its wide coverage of verbs, adverbs, adjectives and common nouns. More recently, Wikipedia has been shown to be an optimal resource for recovering named entities, and has consequently become - together with all its semi-automatic derivations such as DBpedia (Auer et al., 2007) and Freebase (Bollacker et al., 2008) - the main reference inventory for EL systems. Over the years, the research community has typically focused on each of these tasks separately. Rec</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1990</marker>
<rawString>George A. Miller, Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine Miller. 1990. Introduction to WordNet: An On-Line Lexical Database. Int. Journal of Lexicography, 3(4):235–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Milne</author>
<author>Ian H Witten</author>
</authors>
<title>Learning to link with wikipedia.</title>
<date>2008</date>
<booktitle>In Proc. of CIKM,</booktitle>
<pages>509--518</pages>
<contexts>
<context position="14500" citStr="Milne and Witten, 2008" startWordPosition="2396" endWordPosition="2399">the Lesk algorithm and the Jiang &amp; Conrath similarity measure (Jiang and Conrath, 1997). It validates the output from both techniques for enhanced accuracy and exploits semantic relations and corpus (SemCor) information available in BabelNet and WordNet in an unsupervised manner. el92 (Systems mix). This system is a generaldomain system for entity detection and linking. It does not perform WSD. The system combines, via a weighted voting, Entity Linking outputs from four publicly available services: Tagme (Ferragina and Scaiella, 2010), DBpedia Spotlight (Mendes et al., 2011), Wikipedia Miner (Milne and Witten, 2008) and Babelfy (Moro et al., 2014b; Moro et al., 2014a). The different runs correspond to different settings in the weighting formula (De La Clergerie et al., 2008; Fiscus, 1997). LIMSI (Unsupervised + Sense relevance). The system performs WSD by taking advantage of the parallelism of the test data, a feature that was not exploited by the systems that participated in the SemEval-2013 Multilingual Word Sense Disambiguation task 12 (Navigli et al., 2013). The system needs no training and is applied directly to the test dataset, nor does it use distributional (context) information. The texts are se</context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>David Milne and Ian H. Witten. 2008. Learning to link with wikipedia. In Proc. of CIKM, pages 509–518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Moro</author>
<author>Francesco Cecconi</author>
<author>Roberto Navigli</author>
</authors>
<title>Multilingual word sense disambiguation and entity linking for everybody.</title>
<date>2014</date>
<booktitle>In Proc. of ISWC (P&amp;D),</booktitle>
<pages>25--28</pages>
<contexts>
<context position="2899" citStr="Moro et al., 2014" startWordPosition="462" endWordPosition="465"> language, has become the main reference inventory for English WSD systems thanks to its wide coverage of verbs, adverbs, adjectives and common nouns. More recently, Wikipedia has been shown to be an optimal resource for recovering named entities, and has consequently become - together with all its semi-automatic derivations such as DBpedia (Auer et al., 2007) and Freebase (Bollacker et al., 2008) - the main reference inventory for EL systems. Over the years, the research community has typically focused on each of these tasks separately. Recently, however, joint approaches have been proposed (Moro et al., 2014b). One of the reasons for pursuing the unification of these tasks derives from the current trend in knowledge acquisition which consists of the seamless integration of encyclopedic and lexicographic knowledge within structured language resources (Hovy et al., 2013). A case in point here is BabelNet1, a multilingual semantic network and encyclopedic dictionary (Navigli and Ponzetto, 2012). Resources like BabelNet provide a common ground for the tasks of WSD and EL. 1http://babelnet.org 288 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 288–297, Denve</context>
<context position="13113" citStr="Moro et al., 2014" startWordPosition="2173" endWordPosition="2176"> Systems DFKI (Supervised). This system exploits BabelNet as reference inventory and a CRF-based named entity recognizer. The disambiguation system is divided in two parts: one for nouns and another for verbs. For nouns the approach is based on the idea of maximizing multiple objectives at the same time. Similarly to (Hoffart et al., 2011), the disambiguation objectives consist of a global (coherence, unsupervised) part and a local (supervised) part. The global objective makes sure that disambiguation maximizes coherence of the selected synsets and it is based on the semantic signature graph (Moro et al., 2014b). The local objective ensures that the WordNet synset type fits the local context of the noun to be disambiguated. One important aspect of this approach is that, unlike previous work (Hoffart et al., 2011; Moro et al., 2014b), it does not apply discrete optimization, but continuous optimization on the normalized sum of all objectives. The disambiguation procedure aims to optimize the objective function by iteratively updating the candidate probabilities for each fragment. As far as verbs are concerned, a feed-forward neural network is trained using local features such as arguments of the sem</context>
<context position="14531" citStr="Moro et al., 2014" startWordPosition="2402" endWordPosition="2405">nrath similarity measure (Jiang and Conrath, 1997). It validates the output from both techniques for enhanced accuracy and exploits semantic relations and corpus (SemCor) information available in BabelNet and WordNet in an unsupervised manner. el92 (Systems mix). This system is a generaldomain system for entity detection and linking. It does not perform WSD. The system combines, via a weighted voting, Entity Linking outputs from four publicly available services: Tagme (Ferragina and Scaiella, 2010), DBpedia Spotlight (Mendes et al., 2011), Wikipedia Miner (Milne and Witten, 2008) and Babelfy (Moro et al., 2014b; Moro et al., 2014a). The different runs correspond to different settings in the weighting formula (De La Clergerie et al., 2008; Fiscus, 1997). LIMSI (Unsupervised + Sense relevance). The system performs WSD by taking advantage of the parallelism of the test data, a feature that was not exploited by the systems that participated in the SemEval-2013 Multilingual Word Sense Disambiguation task 12 (Navigli et al., 2013). The system needs no training and is applied directly to the test dataset, nor does it use distributional (context) information. The texts are sentence- and wordaligned pairwis</context>
<context position="21628" citStr="Moro et al., 2014" startWordPosition="3598" endWordPosition="3601">2 52.3 56.0 64.4 55.9 59.9 WSD-games-Run2 58.8 50.0 54.1 - - - - - - WSD-games-Run1 57.4 48.9 52.8 - - - - - - WSD-games-Run3 53.5 45.4 49.1 - - - - - - EBL-Hope 48.4 44.4 46.3 - - - - - - TeamUFAL 40.4 36.5 38.3 - - - - - - BFS 67.9 67.2 67.5 38.9 36.2 37.5 41.7 38.8 40.2 # items 1261 1239 1225 Table 2: Precision, Recall and F1 on all domains. manually annotated items and for each language. In the English part of the datasets the DFKI system performs best for verb, noun and named entity disambiguation, thanks to precomputed random walks called semantic signatures, along the lines of Babelfy (Moro et al., 2014b), and supervised techniques. The UNIBA system on the English dataset obtains the best result on adverbs. Finally, in the Spanish dataset the EBL-Hope system based on a combination of a Lesk-based measure together with the Jiang &amp; Conrath similarity measure shows the best performance for named entities. 4.2 Domain-based Evaluation In Tables 4-6 we show the detailed performances of all the systems over different classes of items, and on different domains. One of the main goals of this task is to investigate the performance of disambiguation methods over different domains. Our documents derive </context>
<context position="27879" citStr="Moro et al., 2014" startWordPosition="4750" endWordPosition="4753"> 24.4 54.1 54.2 42.2 38.5 63.5 UNIBA-Run3 - 28.6 - 62.4 63.6 46.2 - UNIBA-Run1 - 24.4 - 62.2 63.6 46.2 - UNIBA-Run2 - 24.4 - 62.2 63.6 46.2 - EBL-Hope - 24.4 - 50.5 - - - BFS 44.3 28.6 44.9 43.3 38.7 38.5 56.8 Table 4: F1 performance by item class and language on biomedical domain. tities, the system EBL-Hope obtains the best results in all languages. This system, in addition to exploiting a Lesk-based measure combined with the Jiang &amp; Conrath similarity measure, uses the BabelNet semantic relations, which have already been shown to be useful for attaining state-of-the-art performances in EL (Moro et al., 2014b). Interestingly, in the Italian dataset the system UNIBA (which is based on an extended version of the Lesk measure and a semantic relatedness measure) obtains the same performance for NE as the EBL-Hope system. Social issues domain. In Table 6 we show the performance on our last domain. In this social issues domain DFKI confirms its quality on disambiguating nouns and named entities, while for verbs the best system is vua-background, which is based on the predominant sense algorithm (McCarthy et al., 2004) and, as a fallback routine, on the “It Makes Sense” supervised WSD system (Zhong and </context>
</contexts>
<marker>Moro, Cecconi, Navigli, 2014</marker>
<rawString>Andrea Moro, Francesco Cecconi, and Roberto Navigli. 2014a. Multilingual word sense disambiguation and entity linking for everybody. In Proc. of ISWC (P&amp;D), pages 25–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Moro</author>
<author>Alessandro Raganato</author>
<author>Roberto Navigli</author>
</authors>
<title>Entity Linking meets Word Sense Disambiguation: A Unified Approach.</title>
<date>2014</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<volume>2</volume>
<pages>244</pages>
<contexts>
<context position="2899" citStr="Moro et al., 2014" startWordPosition="462" endWordPosition="465"> language, has become the main reference inventory for English WSD systems thanks to its wide coverage of verbs, adverbs, adjectives and common nouns. More recently, Wikipedia has been shown to be an optimal resource for recovering named entities, and has consequently become - together with all its semi-automatic derivations such as DBpedia (Auer et al., 2007) and Freebase (Bollacker et al., 2008) - the main reference inventory for EL systems. Over the years, the research community has typically focused on each of these tasks separately. Recently, however, joint approaches have been proposed (Moro et al., 2014b). One of the reasons for pursuing the unification of these tasks derives from the current trend in knowledge acquisition which consists of the seamless integration of encyclopedic and lexicographic knowledge within structured language resources (Hovy et al., 2013). A case in point here is BabelNet1, a multilingual semantic network and encyclopedic dictionary (Navigli and Ponzetto, 2012). Resources like BabelNet provide a common ground for the tasks of WSD and EL. 1http://babelnet.org 288 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 288–297, Denve</context>
<context position="13113" citStr="Moro et al., 2014" startWordPosition="2173" endWordPosition="2176"> Systems DFKI (Supervised). This system exploits BabelNet as reference inventory and a CRF-based named entity recognizer. The disambiguation system is divided in two parts: one for nouns and another for verbs. For nouns the approach is based on the idea of maximizing multiple objectives at the same time. Similarly to (Hoffart et al., 2011), the disambiguation objectives consist of a global (coherence, unsupervised) part and a local (supervised) part. The global objective makes sure that disambiguation maximizes coherence of the selected synsets and it is based on the semantic signature graph (Moro et al., 2014b). The local objective ensures that the WordNet synset type fits the local context of the noun to be disambiguated. One important aspect of this approach is that, unlike previous work (Hoffart et al., 2011; Moro et al., 2014b), it does not apply discrete optimization, but continuous optimization on the normalized sum of all objectives. The disambiguation procedure aims to optimize the objective function by iteratively updating the candidate probabilities for each fragment. As far as verbs are concerned, a feed-forward neural network is trained using local features such as arguments of the sem</context>
<context position="14531" citStr="Moro et al., 2014" startWordPosition="2402" endWordPosition="2405">nrath similarity measure (Jiang and Conrath, 1997). It validates the output from both techniques for enhanced accuracy and exploits semantic relations and corpus (SemCor) information available in BabelNet and WordNet in an unsupervised manner. el92 (Systems mix). This system is a generaldomain system for entity detection and linking. It does not perform WSD. The system combines, via a weighted voting, Entity Linking outputs from four publicly available services: Tagme (Ferragina and Scaiella, 2010), DBpedia Spotlight (Mendes et al., 2011), Wikipedia Miner (Milne and Witten, 2008) and Babelfy (Moro et al., 2014b; Moro et al., 2014a). The different runs correspond to different settings in the weighting formula (De La Clergerie et al., 2008; Fiscus, 1997). LIMSI (Unsupervised + Sense relevance). The system performs WSD by taking advantage of the parallelism of the test data, a feature that was not exploited by the systems that participated in the SemEval-2013 Multilingual Word Sense Disambiguation task 12 (Navigli et al., 2013). The system needs no training and is applied directly to the test dataset, nor does it use distributional (context) information. The texts are sentence- and wordaligned pairwis</context>
<context position="21628" citStr="Moro et al., 2014" startWordPosition="3598" endWordPosition="3601">2 52.3 56.0 64.4 55.9 59.9 WSD-games-Run2 58.8 50.0 54.1 - - - - - - WSD-games-Run1 57.4 48.9 52.8 - - - - - - WSD-games-Run3 53.5 45.4 49.1 - - - - - - EBL-Hope 48.4 44.4 46.3 - - - - - - TeamUFAL 40.4 36.5 38.3 - - - - - - BFS 67.9 67.2 67.5 38.9 36.2 37.5 41.7 38.8 40.2 # items 1261 1239 1225 Table 2: Precision, Recall and F1 on all domains. manually annotated items and for each language. In the English part of the datasets the DFKI system performs best for verb, noun and named entity disambiguation, thanks to precomputed random walks called semantic signatures, along the lines of Babelfy (Moro et al., 2014b), and supervised techniques. The UNIBA system on the English dataset obtains the best result on adverbs. Finally, in the Spanish dataset the EBL-Hope system based on a combination of a Lesk-based measure together with the Jiang &amp; Conrath similarity measure shows the best performance for named entities. 4.2 Domain-based Evaluation In Tables 4-6 we show the detailed performances of all the systems over different classes of items, and on different domains. One of the main goals of this task is to investigate the performance of disambiguation methods over different domains. Our documents derive </context>
<context position="27879" citStr="Moro et al., 2014" startWordPosition="4750" endWordPosition="4753"> 24.4 54.1 54.2 42.2 38.5 63.5 UNIBA-Run3 - 28.6 - 62.4 63.6 46.2 - UNIBA-Run1 - 24.4 - 62.2 63.6 46.2 - UNIBA-Run2 - 24.4 - 62.2 63.6 46.2 - EBL-Hope - 24.4 - 50.5 - - - BFS 44.3 28.6 44.9 43.3 38.7 38.5 56.8 Table 4: F1 performance by item class and language on biomedical domain. tities, the system EBL-Hope obtains the best results in all languages. This system, in addition to exploiting a Lesk-based measure combined with the Jiang &amp; Conrath similarity measure, uses the BabelNet semantic relations, which have already been shown to be useful for attaining state-of-the-art performances in EL (Moro et al., 2014b). Interestingly, in the Italian dataset the system UNIBA (which is based on an extended version of the Lesk measure and a semantic relatedness measure) obtains the same performance for NE as the EBL-Hope system. Social issues domain. In Table 6 we show the performance on our last domain. In this social issues domain DFKI confirms its quality on disambiguating nouns and named entities, while for verbs the best system is vua-background, which is based on the predominant sense algorithm (McCarthy et al., 2004) and, as a fallback routine, on the “It Makes Sense” supervised WSD system (Zhong and </context>
</contexts>
<marker>Moro, Raganato, Navigli, 2014</marker>
<rawString>Andrea Moro, Alessandro Raganato, and Roberto Navigli. 2014b. Entity Linking meets Word Sense Disambiguation: A Unified Approach. Transactions of the Association for Computational Linguistics, 2:231– 244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network.</title>
<date>2012</date>
<journal>Artificial Intelligence,</journal>
<pages>193--217</pages>
<contexts>
<context position="3290" citStr="Navigli and Ponzetto, 2012" startWordPosition="519" endWordPosition="522">acker et al., 2008) - the main reference inventory for EL systems. Over the years, the research community has typically focused on each of these tasks separately. Recently, however, joint approaches have been proposed (Moro et al., 2014b). One of the reasons for pursuing the unification of these tasks derives from the current trend in knowledge acquisition which consists of the seamless integration of encyclopedic and lexicographic knowledge within structured language resources (Hovy et al., 2013). A case in point here is BabelNet1, a multilingual semantic network and encyclopedic dictionary (Navigli and Ponzetto, 2012). Resources like BabelNet provide a common ground for the tasks of WSD and EL. 1http://babelnet.org 288 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 288–297, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics In this task our goal is to promote research in the direction of joint word sense and named entity disambiguation, so as to concentrate research efforts on the aspects that differentiate these two tasks without duplicating research on common problems such as identifying the right meaning in context. However, we </context>
<context position="6556" citStr="Navigli and Ponzetto, 2012" startWordPosition="1028" endWordPosition="1031">parallel and POS-tagged documents. We took four documents from these repositories. Two documents contain medical information about drugs. One document consists of the manual of a mathematical graph calculator (i.e., KAlgebra). The remaining document contains a formal discussion about social issues, like supporting elderly workers and, more in general, about issues and solutions to unemployment discussed by the members of the European Commission. 2.2 Sense Inventory As our sense inventory we use the BabelNet 2.5.1 (http://babelnet.org) multilingual semantic network and encyclopedic dictionary (Navigli and Ponzetto, 2012), which is the result of the automatic integration of multiple language resources: Princeton WordNet, Wikipedia, Wiktionary, OmegaWiki, Wikidata, Open Multi WordNet and automatic translations. The meanings contained within this resource are organized in Babel synsets. Each of these synsets can contain Wikipedia pages, WordNet synsets and items from the other integrated resources. For instance, in BabelNet it is possible to find the concept “medicine” (bn:00054128n), which is represented by both the second word sense of medicine in WordNet and the Wikipedia page Pharmaceutical drug, among other</context>
</contexts>
<marker>Navigli, Ponzetto, 2012</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2012. BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network. Artificial Intelligence, 193:217–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Kenneth C Litkowski</author>
<author>Orin Hargraves</author>
</authors>
<title>SemEval-2007 Task 07: CoarseGrained English All-Words Task.</title>
<date>2007</date>
<booktitle>In Proc. of SemEval-2007,</booktitle>
<pages>30--35</pages>
<contexts>
<context position="5265" citStr="Navigli et al., 2007" startWordPosition="825" endWordPosition="828">n, maths and computer domain, and a broader domain about social issues). Our goal is to further investigate the distance between research efforts regarding the dichotomy EL vs. WSD and those regarding the dichotomy open domain vs. closed domain. 2 Task Setup The task setup consists of annotating four tokenized and part-of-speech tagged documents for which parallel versions in three languages (English, Italian and Spanish) have been provided. Differently from previous editions (Navigli et al., 2013; Lefever and Hoste, 2013; Manandhar et al., 2010; Lefever and Hoste, 2010; Pradhan et al., 2007; Navigli et al., 2007; Snyder and Palmer, 2004; Palmer et al., 2001), in this task we do not make explicit to the participating systems which fragments of the input text should be disambiguated, so as to have, on the one hand, a more realistic scenario, and, on the other hand, to follow the recent trend in EL challenges such as TAC KBP (Ji et al., 2014), MicroPost (Basave et al., 2013) and ERD (Carmel et al., 2014). 2.1 Corpora The documents considered in this task are taken from the OPUS project (http://opus.lingfil.uu.se/), more specifically from the EMEA (European Medicines Agency documents), KDEdoc (the KDE ma</context>
</contexts>
<marker>Navigli, Litkowski, Hargraves, 2007</marker>
<rawString>Roberto Navigli, Kenneth C. Litkowski, and Orin Hargraves. 2007. SemEval-2007 Task 07: CoarseGrained English All-Words Task. In Proc. of SemEval-2007, pages 30–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>David Jurgens</author>
<author>Daniele Vannella</author>
</authors>
<title>SemEval-2013 Task 12: Multilingual Word Sense Disambiguation.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proc. of the Seventh International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>222--231</pages>
<location>Atlanta, Georgia, USA.</location>
<contexts>
<context position="4475" citStr="Navigli et al., 2013" startWordPosition="701" endWordPosition="704">ght meaning in context. However, we are also interested in systems that perform only one of the two tasks, and even systems which tackle one particular setting of WSD, such as allwords sense disambiguation vs. any subset of partof-speech tags. Moreover, given the recent upsurge of interest in multilingual approaches, we developed the task dataset in three different languages (English, Italian and Spanish) on parallel texts which have been independently and manually annotated by different native/fluent speakers. In contrast to the SemEval-2013 task 12 on Multilingual Word Sense Disambiguation (Navigli et al., 2013), our focus in task 13 is to present a dataset containing both kinds of inventories (i.e., named entities and word senses) in different specific domains (biomedical domain, maths and computer domain, and a broader domain about social issues). Our goal is to further investigate the distance between research efforts regarding the dichotomy EL vs. WSD and those regarding the dichotomy open domain vs. closed domain. 2 Task Setup The task setup consists of annotating four tokenized and part-of-speech tagged documents for which parallel versions in three languages (English, Italian and Spanish) have</context>
<context position="14954" citStr="Navigli et al., 2013" startWordPosition="2469" endWordPosition="2472"> outputs from four publicly available services: Tagme (Ferragina and Scaiella, 2010), DBpedia Spotlight (Mendes et al., 2011), Wikipedia Miner (Milne and Witten, 2008) and Babelfy (Moro et al., 2014b; Moro et al., 2014a). The different runs correspond to different settings in the weighting formula (De La Clergerie et al., 2008; Fiscus, 1997). LIMSI (Unsupervised + Sense relevance). The system performs WSD by taking advantage of the parallelism of the test data, a feature that was not exploited by the systems that participated in the SemEval-2013 Multilingual Word Sense Disambiguation task 12 (Navigli et al., 2013). The system needs no training and is applied directly to the test dataset, nor does it use distributional (context) information. The texts are sentence- and wordaligned pairwise, and content words are tagged by their translations in another language. The alignments serve to retrieve the BabelNet synsets that are relevant for each instance of a word in the texts (i.e., synsets that contain both the disambiguation target and its aligned translation). If a Babel synset is retained, this is used to annotate the instance of the word in the test set. If more than one synset is retained, these are r</context>
</contexts>
<marker>Navigli, Jurgens, Vannella, 2013</marker>
<rawString>Roberto Navigli, David Jurgens, and Daniele Vannella. 2013. SemEval-2013 Task 12: Multilingual Word Sense Disambiguation. In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proc. of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 222–231, Atlanta, Georgia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word sense disambiguation: A survey.</title>
<date>2009</date>
<journal>ACM Comput. Surv.,</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="1496" citStr="Navigli, 2009" startWordPosition="228" endWordPosition="229">n, the same) methods. Moreover, we investigate this task in a multilingual setting and for some specific domains. 1 Introduction The Senseval and SemEval evaluation series represent key moments in the community of computational linguistics and related areas. Their focus has been to provide objective evaluations of methods within the wide spectrum of semantic techniques for tasks mainly related to automatic text understanding. Through SemEval-2015 task 13 we both continue and renew the longstanding tradition of disambiguation tasks, by addressing multilingual WSD and EL in a joint manner. WSD (Navigli, 2009; Navigli, 2012) is a historical task aimed at explicitly assigning meanings to single-word and multi-word occurrences within text, a task which today is more alive than ever in the research community. EL (Erbs et al., 2011; Cornolti et al., 2013; Rao et al., 2013) is a more recent task which aims at discovering mentions of entities within a text and linking them to the most suitable entry in a knowledge base. Both these tasks aim at handling the inherent ambiguity of natural language, however WSD tackles it from a lexicographic perspective, while EL tackles it from an encyclopedic one. Specif</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word sense disambiguation: A survey. ACM Comput. Surv., 41(2):1–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>A quick tour of word sense disambiguation, induction and related approaches.</title>
<date>2012</date>
<booktitle>In Proceedings of the 38th Conference on Current Trends in Theory and Practice of Computer Science (SOFSEM),</booktitle>
<pages>115--129</pages>
<contexts>
<context position="1512" citStr="Navigli, 2012" startWordPosition="230" endWordPosition="231">thods. Moreover, we investigate this task in a multilingual setting and for some specific domains. 1 Introduction The Senseval and SemEval evaluation series represent key moments in the community of computational linguistics and related areas. Their focus has been to provide objective evaluations of methods within the wide spectrum of semantic techniques for tasks mainly related to automatic text understanding. Through SemEval-2015 task 13 we both continue and renew the longstanding tradition of disambiguation tasks, by addressing multilingual WSD and EL in a joint manner. WSD (Navigli, 2009; Navigli, 2012) is a historical task aimed at explicitly assigning meanings to single-word and multi-word occurrences within text, a task which today is more alive than ever in the research community. EL (Erbs et al., 2011; Cornolti et al., 2013; Rao et al., 2013) is a more recent task which aims at discovering mentions of entities within a text and linking them to the most suitable entry in a knowledge base. Both these tasks aim at handling the inherent ambiguity of natural language, however WSD tackles it from a lexicographic perspective, while EL tackles it from an encyclopedic one. Specifically, the main</context>
</contexts>
<marker>Navigli, 2012</marker>
<rawString>Roberto Navigli. 2012. A quick tour of word sense disambiguation, induction and related approaches. In Proceedings of the 38th Conference on Current Trends in Theory and Practice of Computer Science (SOFSEM), pages 115–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Christiane Fellbaum</author>
<author>Scott Cotton</author>
<author>Lauren Delfs</author>
<author>Hoa Trang Dang</author>
</authors>
<title>English tasks: All-words and verb lexical sample.</title>
<date>2001</date>
<booktitle>In Proc. of Senseval-2,</booktitle>
<pages>21--24</pages>
<contexts>
<context position="5312" citStr="Palmer et al., 2001" startWordPosition="833" endWordPosition="836">ain about social issues). Our goal is to further investigate the distance between research efforts regarding the dichotomy EL vs. WSD and those regarding the dichotomy open domain vs. closed domain. 2 Task Setup The task setup consists of annotating four tokenized and part-of-speech tagged documents for which parallel versions in three languages (English, Italian and Spanish) have been provided. Differently from previous editions (Navigli et al., 2013; Lefever and Hoste, 2013; Manandhar et al., 2010; Lefever and Hoste, 2010; Pradhan et al., 2007; Navigli et al., 2007; Snyder and Palmer, 2004; Palmer et al., 2001), in this task we do not make explicit to the participating systems which fragments of the input text should be disambiguated, so as to have, on the one hand, a more realistic scenario, and, on the other hand, to follow the recent trend in EL challenges such as TAC KBP (Ji et al., 2014), MicroPost (Basave et al., 2013) and ERD (Carmel et al., 2014). 2.1 Corpora The documents considered in this task are taken from the OPUS project (http://opus.lingfil.uu.se/), more specifically from the EMEA (European Medicines Agency documents), KDEdoc (the KDE manual corpus) and “The EU bookshop corpus”, whic</context>
</contexts>
<marker>Palmer, Fellbaum, Cotton, Delfs, Dang, 2001</marker>
<rawString>Martha Palmer, Christiane Fellbaum, Scott Cotton, Lauren Delfs, and Hoa Trang Dang. 2001. English tasks: All-words and verb lexical sample. In Proc. of Senseval-2, pages 21–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer S Pradhan</author>
<author>Edward Loper</author>
<author>Dmitriy Dligach</author>
<author>Martha Palmer</author>
</authors>
<date>2007</date>
<booktitle>SemEval-2007 task 17: English lexical sample, SRL and all words. In Proc. of SemEval-2007,</booktitle>
<pages>87--92</pages>
<contexts>
<context position="5243" citStr="Pradhan et al., 2007" startWordPosition="821" endWordPosition="824">ains (biomedical domain, maths and computer domain, and a broader domain about social issues). Our goal is to further investigate the distance between research efforts regarding the dichotomy EL vs. WSD and those regarding the dichotomy open domain vs. closed domain. 2 Task Setup The task setup consists of annotating four tokenized and part-of-speech tagged documents for which parallel versions in three languages (English, Italian and Spanish) have been provided. Differently from previous editions (Navigli et al., 2013; Lefever and Hoste, 2013; Manandhar et al., 2010; Lefever and Hoste, 2010; Pradhan et al., 2007; Navigli et al., 2007; Snyder and Palmer, 2004; Palmer et al., 2001), in this task we do not make explicit to the participating systems which fragments of the input text should be disambiguated, so as to have, on the one hand, a more realistic scenario, and, on the other hand, to follow the recent trend in EL challenges such as TAC KBP (Ji et al., 2014), MicroPost (Basave et al., 2013) and ERD (Carmel et al., 2014). 2.1 Corpora The documents considered in this task are taken from the OPUS project (http://opus.lingfil.uu.se/), more specifically from the EMEA (European Medicines Agency document</context>
</contexts>
<marker>Pradhan, Loper, Dligach, Palmer, 2007</marker>
<rawString>Sameer S. Pradhan, Edward Loper, Dmitriy Dligach, and Martha Palmer. 2007. SemEval-2007 task 17: English lexical sample, SRL and all words. In Proc. of SemEval-2007, pages 87–92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delip Rao</author>
<author>Paul McNamee</author>
<author>Mark Dredze</author>
</authors>
<title>Entity linking: Finding extracted entities in a knowledge base.</title>
<date>2013</date>
<booktitle>In Multi-source, Multilingual Information Extraction and Summarization,</booktitle>
<pages>93--115</pages>
<contexts>
<context position="1761" citStr="Rao et al., 2013" startWordPosition="272" endWordPosition="275">eir focus has been to provide objective evaluations of methods within the wide spectrum of semantic techniques for tasks mainly related to automatic text understanding. Through SemEval-2015 task 13 we both continue and renew the longstanding tradition of disambiguation tasks, by addressing multilingual WSD and EL in a joint manner. WSD (Navigli, 2009; Navigli, 2012) is a historical task aimed at explicitly assigning meanings to single-word and multi-word occurrences within text, a task which today is more alive than ever in the research community. EL (Erbs et al., 2011; Cornolti et al., 2013; Rao et al., 2013) is a more recent task which aims at discovering mentions of entities within a text and linking them to the most suitable entry in a knowledge base. Both these tasks aim at handling the inherent ambiguity of natural language, however WSD tackles it from a lexicographic perspective, while EL tackles it from an encyclopedic one. Specifically, the main difference between the two tasks lies in the kind of inventory they use. For instance, WordNet (Miller et al., 1990), a manually curated semantic network for the English language, has become the main reference inventory for English WSD systems than</context>
</contexts>
<marker>Rao, McNamee, Dredze, 2013</marker>
<rawString>Delip Rao, Paul McNamee, and Mark Dredze. 2013. Entity linking: Finding extracted entities in a knowledge base. In Multi-source, Multilingual Information Extraction and Summarization, pages 93–115.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Martha Palmer</author>
</authors>
<title>The English all-words task.</title>
<date>2004</date>
<booktitle>In Proc. of Senseval-3,</booktitle>
<pages>41--43</pages>
<contexts>
<context position="5290" citStr="Snyder and Palmer, 2004" startWordPosition="829" endWordPosition="832">domain, and a broader domain about social issues). Our goal is to further investigate the distance between research efforts regarding the dichotomy EL vs. WSD and those regarding the dichotomy open domain vs. closed domain. 2 Task Setup The task setup consists of annotating four tokenized and part-of-speech tagged documents for which parallel versions in three languages (English, Italian and Spanish) have been provided. Differently from previous editions (Navigli et al., 2013; Lefever and Hoste, 2013; Manandhar et al., 2010; Lefever and Hoste, 2010; Pradhan et al., 2007; Navigli et al., 2007; Snyder and Palmer, 2004; Palmer et al., 2001), in this task we do not make explicit to the participating systems which fragments of the input text should be disambiguated, so as to have, on the one hand, a more realistic scenario, and, on the other hand, to follow the recent trend in EL challenges such as TAC KBP (Ji et al., 2014), MicroPost (Basave et al., 2013) and ERD (Carmel et al., 2014). 2.1 Corpora The documents considered in this task are taken from the OPUS project (http://opus.lingfil.uu.se/), more specifically from the EMEA (European Medicines Agency documents), KDEdoc (the KDE manual corpus) and “The EU </context>
</contexts>
<marker>Snyder, Palmer, 2004</marker>
<rawString>Benjamin Snyder and Martha Palmer. 2004. The English all-words task. In Proc. of Senseval-3, pages 41–43.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ricardo Usbeck</author>
<author>Michael R¨oder</author>
<author>Axel-Cyrille Ngonga Ngomo</author>
<author>Ciro Baron</author>
<author>Andreas Both</author>
<author>Martin Br¨ummer</author>
<author>Diego Ceccarelli</author>
<author>Marco Cornolti</author>
<author>Didier Cherix</author>
<author>Bernd Eickmann</author>
<author>Paolo Ferragina</author>
</authors>
<title>GERBIL - General Entity Annotator Benchmark.</title>
<date>2015</date>
<booktitle>In Proc. of WWW.</booktitle>
<location>Christiane Lemke, Andrea Moro, Roberto Navigli, Francesco Piccinno, Giuseppe Rizzo, Harald Sack, Ren´e</location>
<marker>Usbeck, R¨oder, Ngomo, Baron, Both, Br¨ummer, Ceccarelli, Cornolti, Cherix, Eickmann, Ferragina, 2015</marker>
<rawString>Ricardo Usbeck, Michael R¨oder, Axel-Cyrille Ngonga Ngomo, Ciro Baron, Andreas Both, Martin Br¨ummer, Diego Ceccarelli, Marco Cornolti, Didier Cherix, Bernd Eickmann, Paolo Ferragina, Christiane Lemke, Andrea Moro, Roberto Navigli, Francesco Piccinno, Giuseppe Rizzo, Harald Sack, Ren´e Speck, Rapha¨el Troncy, J¨org Waitelonis, and Lars Wesemann. 2015. GERBIL - General Entity Annotator Benchmark. In Proc. of WWW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhi Zhong</author>
<author>Hwee Tou Ng</author>
</authors>
<title>It Makes Sense: A Wide-Coverage Word Sense Disambiguation System for Free Text.</title>
<date>2010</date>
<booktitle>In Proc. of the ACL 2010 System Demonstrations,</booktitle>
<pages>78--83</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="18387" citStr="Zhong and Ng, 2010" startWordPosition="3018" endWordPosition="3021">while for Wikipedia entities the number of citations in Wikipedia internal links is counted. vua-background (Partially supervised). This approach exploits the Named Entities contained in the test data to generate a background corpus. This is done by finding similar DBpedia entities for the entities in the input documents. Using this background corpus, the system tries to find the predominant sense of the words in the test data (McCarthy et al., 2004). If a predominant sense is recognized for a specific lemma, then it is used, otherwise the system falls back to the “It Makes Sense” WSD system (Zhong and Ng, 2010). 3During the evaluation period the system did not return any annotation for adjectives due to a misinterpretation of the POS tag set. For full evaluations see the system paper. WSD-games (Unsupervised). This approach is formulated in terms of Evolutionary Game Theory, where each word to be disambiguated is represented as a node in a graph and each sense as a class. The proposed algorithm performs a consistent class assignment of senses according to the similarity information of each word with the others, so that similar words are constrained to similar classes. The propagation of the informat</context>
<context position="28488" citStr="Zhong and Ng, 2010" startWordPosition="4855" endWordPosition="4858"> al., 2014b). Interestingly, in the Italian dataset the system UNIBA (which is based on an extended version of the Lesk measure and a semantic relatedness measure) obtains the same performance for NE as the EBL-Hope system. Social issues domain. In Table 6 we show the performance on our last domain. In this social issues domain DFKI confirms its quality on disambiguating nouns and named entities, while for verbs the best system is vua-background, which is based on the predominant sense algorithm (McCarthy et al., 2004) and, as a fallback routine, on the “It Makes Sense” supervised WSD system (Zhong and Ng, 2010). For the other two languages the SUDOKU system obtains the best scores, with the exception of adverbs in the Italian dataset where the UNIBA system is able to reach an F1 score of 100%. 5 Conclusion and Future Directions In this paper we described the organization and results obtained within the SemEval 2015 task 13: Multilingual Word Sense Disambiguation. Our analysis of the results revealed interesting aspects of the integration of WSD and EL tasks, such as the effectiveness of techniques like semantic signatures, PPR and similarity measures for noun and named entity 294 EN System All Named</context>
</contexts>
<marker>Zhong, Ng, 2010</marker>
<rawString>Zhi Zhong and Hwee Tou Ng. 2010. It Makes Sense: A Wide-Coverage Word Sense Disambiguation System for Free Text. In Proc. of the ACL 2010 System Demonstrations, pages 78–83, Uppsala, Sweden, July.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>