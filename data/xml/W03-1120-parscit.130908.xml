<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000055">
<title confidence="0.998673">
Cross-Language Information Retrieval Based on
Category Matching Between Language Versions of a Web Directory
</title>
<author confidence="0.995759">
Fuminori Kimura
</author>
<affiliation confidence="0.90171875">
Graduate School of
Information Science,
Nara Institute of
Science and Technology
</affiliation>
<address confidence="0.7364585">
8916-5 Takayama,
Ikoma, Nara, Japan
</address>
<author confidence="0.969861">
Akira Maeda
</author>
<affiliation confidence="0.991953666666667">
Department of
Computer Science,
Ritsumeikan University
</affiliation>
<address confidence="0.6042095">
1-1-1 Noji-Higashi,
Kusatsu, Shiga, Japan
</address>
<author confidence="0.870166">
Masatoshi Yoshikawa
</author>
<affiliation confidence="0.78316825">
Information Technology
Center, Nagoya University
Furo-cho, Chigusa-ku,
Nagoya, Aichi, Japan
</affiliation>
<author confidence="0.973384">
Shunsuke Uemura
</author>
<affiliation confidence="0.89673625">
Graduate School of
Information Science,
Nara Institute of
Science and Technology
</affiliation>
<address confidence="0.775025">
8916-5 Takayama,
Ikoma, Nara, Japan
</address>
<sectionHeader confidence="0.974423" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998092">
Since the Web consists of documents in
various domains or genres, the method
for Cross-Language Information Retrieval
(CLIR) of Web documents should be in-
dependent of a particular domain. In this
paper, we propose a CLIR method which
employs a Web directory provided in mul-
tiple language versions (such as Yahoo!).
In the proposed method, feature terms are
first extracted from Web documents for
each category in the source and the tar-
get languages. Then, one or more corre-
sponding categories in another language
are determined beforehand by comparing
similarities between categories across lan-
guages. Using these category pairs, we in-
tend to resolve ambiguities of simple dic-
tionary translation by narrowing the cat-
egories to be retrieved in the target lan-
guage.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99998916">
With the popularity of the Internet, more and more
languages are becoming to be used for Web docu-
ments, and it is now much easier to access docu-
ments written in foreign languages. However, exist-
ing Web search engines only support the retrieval of
documents which are written in the same language
as the query, so the monolingual users are not able to
retrieve documents written in non-native languages
efficiently. Also, there might be cases, depending
on the user’s demand, where information written in
a language other than the user’s native language is
rich. Needs for retrieving such information must
be large. In order to satisfy such needs on a usual
monolingual retrieval system, the user him-/herself
has to manually translate the query by using a dic-
tionary, etc. This process not only imposes a burden
to the user but also might choose incorrect transla-
tions for the query, especially for languages that are
unfamiliar to the user.
To fulfill such needs, researches on Cross-
Language Information Retrieval (CLIR), a tech-
nique to retrieve documents written in a certain lan-
guage using a query written in another language,
have been active in recent years. A variety of meth-
ods, including employing corpus statistics for the
translation of terms and the disambiguation of trans-
lated terms, are studied and a certain results has
been obtained. However, corpus-based disambigua-
tion methods are heavily affected by the domain of
the training corpus, so the retrieval effectiveness for
other domains might drop significantly. Besides,
since the Web consists of documents in various do-
mains or genres, the method for CLIR of Web docu-
ments should be independent of a particular domain.
In this paper, we propose a CLIR method which
employs Web directories provided in multiple lan-
guage versions (such as Yahoo!). Our system uses
two or more language versions of a Web directory.
One version is the query language, and others are
the target languages. From these language versions,
category correspondences between languages are es-
timated in advance. First, feature terms are extracted
from Web documents for each category in the source
and the target languages. Then, one or more cor-
responding categories in another language are de-
termined beforehand by comparing similarities be-
tween categories across languages. Using these cat-
egory pairs, we intend to resolve ambiguities of
simple dictionary translation by narrowing the cat-
egories to be retrieved in the target language.
</bodyText>
<sectionHeader confidence="0.999722" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999876047619048">
Approaches to CLIR can be classified into three cat-
egories; document translation, query translation, and
the use of inter-lingual representation. The approach
based on translation of target documents has the ad-
vantage of utilizing existing machine translation sys-
tems, in which more content information can be used
for disambiguation. Thus, in general, it achieves
a better retrieval effectiveness than those based on
query translation(Sakai, 2000). However, since it is
impractical to translate a huge document collection
beforehand and it is difficult to extend this method to
new languages, this approach is not suitable for mul-
tilingual, large-scale, and frequently-updated collec-
tion of the Web. The second approach transfers both
documents and queries into an inter-lingual repre-
sentation, such as bilingual thesaurus classes or a
language-independent vector space. The latter ap-
proach requires a training phase using a bilingual
(parallel or comparable) corpus as a training data.
The major problem in the approach based on the
translation and disambiguation of queries is that the
queries submitted from ordinary users of Web search
engines tend to be very short (approximately two
words on average (Jansen et al., 2000)) and usually
consist of just an enumeration of keywords (i.e. no
context). However, this approach has an advantage
that the translated queries can simply be fed into ex-
isting monolingual search engines. In this approach,
a source language query is first translated into target
language using a bilingual dictionary, and translated
query is disambiguated. Our method falls into this
category.
It is pointed out that corpus-based disambiguation
methods are heavily affected by the difference in do-
main between query and corpus. Hull suggests that
the difference between query and corpus may cause
bad influence on retrieval effectiveness in the meth-
ods that use parallel or comparable corpora (Hull,
1997). Lin et al. conducted comparative experi-
ments among three monolingual corpora that have
different domains and sizes, and has concluded that
large-scale and domain-consistent corpus is needed
for obtaining useful co-occurrence data (Lin et al.,
1999).
On the Web retrieval, which is the target of our re-
search, the system has to cope with queries in many
different kinds of topics. However, it is impracti-
cal to prepare corpora that cover any possible do-
mains. In our previous paper(Kimura et al., 2003),
we proposed a CLIR method which uses documents
in a Web directory that has several language versions
(such as Yahoo!), instead of using existing corpora,
in order to improve the retrieval effectiveness. In
this paper, we propose an extension of our method
which takes account of the hierarchical structure of
Web directories. Dumais et al.(Dumais and Chen,
2000) suggests that the precision of Web document
classification could be improved to a certain extent
by limiting the target categories to compare by us-
ing the hierarchical structure of a Web directory. In
this paper, we try to improve our proposed method
by incorporating the hierarchical structure of a Web
directory for merging categories.
</bodyText>
<sectionHeader confidence="0.995125" genericHeader="method">
3 Proposed System
</sectionHeader>
<subsectionHeader confidence="0.999718">
3.1 Outline of the System
</subsectionHeader>
<bodyText confidence="0.99969435483871">
Our system uses two or more language versions of
a Web directory. One version is the query language
(language A in Figure 1), others are the target lan-
guages to be retrieved (language B in Figure 1).
From these language versions, category correspon-
dences between languages are estimated in advance.
The preprocessing consists of the following four
steps: 1) term extraction from Web documents in
each category, 2) feature term extraction, 3) transla-
tion of feature terms, and 4) estimation of category
correspondences between different languages. Fig-
ure 1 illustrates the flow of the preprocessing. This
example shows a case that category a in language A
corresponds to a category in language B. First, the
system extracts terms from Web documents which
belong to category a (1). Secondly, the system cal-
culates the weights of the extracted terms. Then
higher-weighted terms are extracted as the feature
term set fa of category a (2). Thirdly, the system
translates the feature term set fa into language B
(3). Lastly, the system compares the translated fea-
ture term set of category a with feature term sets of
all categories in language B, and estimates the cor-
responding category of category a from language B
These category pairs are used on retrieval. First,
the system estimates appropriate category for the
query in the query language. Next, the system se-
lects the corresponding category in the target lan-
guage using the pre-estimated category pairs. Fi-
nally, the system retrieves Web documents in the se-
lected corresponding category.
</bodyText>
<figureCaption confidence="0.992023">
Figure 1: Preprocessing.
</figureCaption>
<subsectionHeader confidence="0.959899">
3.2 Preprocessing
3.2.1 Feature Term Extraction
</subsectionHeader>
<bodyText confidence="0.99959952631579">
The feature of each category is represented by
its feature term set. Feature term set is a set of
terms that seem to distinguish the category. The
feature term set of each category is extracted in the
following steps: First, the system extracts terms
from Web documents that belong to a given cate-
gory. In this time, system also collect term fre-
quency of each word in each category and normal-
ize these frequency for each category. Second, the
system calculates the weights of the extracted terms
using TF·ICF (term frequency · inverse category fre-
quency). Lastly, top n ranked terms are extracted as
the feature term set of the category.
Weights of feature terms are calculated by
TF·ICF. TF·ICF is a variation of TF·IDF (term fre-
quency · inverse document frequency). Instead of
using a document as the unit, TF·ICF calculates
weights by category. TF·ICF is calculated as fol-
lows:
</bodyText>
<equation confidence="0.926228">
tf · icf(ti, c) = f(ti) · log N + 1
Nc ni
</equation>
<bodyText confidence="0.999845">
where ti is the term appearing in the category c,
f(ti) is the term frequency of term ti, Nc is the total
number of terms in the category c, ni is number of
the categories that contain the term ti,and N is the
number of all categories in the directory.
</bodyText>
<subsubsectionHeader confidence="0.531119">
3.2.2 Category Matching Between Languages
</subsubsectionHeader>
<bodyText confidence="0.998698684210527">
For estimating category correspondences between
languages, we compare each feature term set of a
category which is extracted in section 3.2.1, and cal-
culates similarities between categories across lan-
guages.
In order to compare two categories between lan-
guages, feature term set must be translated into the
target language. First, for each feature term, the
system looks up the term in a bilingual dictionary
and extracts all translation candidates for the feature
term. Next, the system checks whether each trans-
lation candidate exists in the feature term set of the
target category. If the translation candidate exists,
the system checks the candidate’s weight in the tar-
get category. Lastly, the highest-weighted transla-
tion candidate in the feature term set of the target
category is selected as the translation of the feature
term. Thus, translation candidates are determined
for each category, and translation ambiguity is re-
</bodyText>
<figure confidence="0.958044">
language A
language B
category a
category a
feature term
set fa
feature
term DB
feature term
set fb
...
compare among languages
solved.
</figure>
<bodyText confidence="0.998745409090909">
If no translation candidate for a feature term ex-
ists in the feature term set of the target category, that
term is ignored in the comparison. However, there
are some cases that the source language term itself
is useful as a feature term in the target language. For
example, some English terms (mostly abbreviations)
are commonly used in documents written in other
languages (e.g. “WWW”, “HTM”, etc.). Therefore,
in case that no translation candidate for a feature
term exists in the feature term set of the target cat-
egory, the feature term itself is checked whether it
exists in the feature term set of the target category.
If it exists, the feature term itself is treated as the
translation of the feature term in the target category.
As an example, we consider that an English term
“system” is translated into Japanese for the cate-
gory “コンピュータとインターネット &gt;ソフトウェ
ア &gt;セキュリティ (Computers and Internet &gt;Soft-
ware &gt;Security)” (hereafter called “セキュリティ”
for short). The English term “system” has the fol-
lowing translation candidates in a dictionary; “宇宙
(universe/space)”,“方法 (method)”,“組織 (orga-
nization)”,“器官 (organ)”,“システム (system)”,
etc. We check each of these translation candidates in
the feature term set of the category “セキュリティ.”
Then the highest-weighted term of these translation
candidates in the category “セキュリティ” is deter-
mined as the translation of the English term “sys-
tem” in this category. If no translation candidate ex-
ists in the feature term set of the category “セキュリ
ティ,” the English term “system” itself is treated as
the translation.
Once all the feature terms are translated, the sys-
tem calculates the similarities between categories
across languages. The similarity between the source
category a and the target category b is calculated as
the total of multiplying the weights of each feature
term in the category a by the weight of its transla-
tion in the category b. The similarity of the category
a for the category b is calculated as follows:
sim(a, b) = 1] w(f, a) · w(t, b)
f∈fa
where f is a feature term, fa is the feature term set
of category a, t is the translation of f in the category
</bodyText>
<figure confidence="0.51877725">
feature term set translation
of category a candidates
translation term
in category b
</figure>
<figureCaption confidence="0.9367935">
Figure 2: Feature term translation.
b, and w(f, a) is the weight of f in a.
</figureCaption>
<bodyText confidence="0.99995735">
The system calculates the similarities of category
a for each category in the target language using the
above-mentioned method. Then, a category with the
highest similarity in the target language is selected
as the correspondent of category a.
As an example, we consider an example of
calculating the similarity of an English category
“Computers and Internet &gt;Security and Encryption”
(hereafter called “Encryption” for short) for the cat-
egory “セキュリティ” which is mentioned above.
Suppose that the feature term set of the category
“Encryption” has the following feature terms; “pri-
vacy”, “system”, etc., and the weights of these terms
are 0.007110, 0.006327, · · ·. Also suppose that the
Japanese translations of these terms are “プライバ
シー (privacy)”, “システム (system)”, etc., and the
weights of these terms are 0.023999, 0.047117, · · ·.
In this case, the similarity of the category “Encryp-
tion” (s1) for the category “セキュリティ” (s2) is
calculated as follows:
</bodyText>
<equation confidence="0.980506333333333">
sim(s1, s2) = 0.007110 x 0.023999
+0.006327 x 0.047117
+ · · ·
</equation>
<sectionHeader confidence="0.443271" genericHeader="method">
3.2.3 Retrieval
</sectionHeader>
<figureCaption confidence="0.609482333333333">
Figure 3 illustrates the processing flow of a re-
trieval. When the user submits a query, the follow-
ing steps are processed.
</figureCaption>
<figure confidence="0.979976090909091">
t1
t2
t3
compare
feature term set
of category b
dictionary
feature term f
.
.
.
</figure>
<bodyText confidence="0.998578666666667">
In our system, a query consists of some keywords,
not of a sentence. We define the query vector q~ as
follows:
</bodyText>
<equation confidence="0.985779">
q~ = (q1,q2,...,qn)
</equation>
<bodyText confidence="0.979986419354839">
where qk is the weight of the k-th keyword in the
query. We define the values of all qk are 1.
First, the system calculates the relevance between
the query and each category in the source language,
and determines the relevant category of the query in
the source language (1). The relevance between the
query and each category is calculated by multiply-
ing the inner product between query terms and the
feature term set of the target category by the angle
of these two vectors. The relevance between query
q and category c is calculated as follows:
|~q|·|~c|
where c~is a vector of category c defined as follows:
c~ = (w1, w2, ... , wn)
where wk is the weight of the k-th keyword in the
feature term set of c.
If there is more than one category whose rele-
vance for the query exceeds a certain threshold, all
of them are selected as the relevant categories of the
query. It is because there might be some cases that,
for example, documents in the same domain belong
to different categories, or a query concept belongs to
multiple domains.
Second, the corresponding category in the tar-
get language is selected by using category corre-
spondences between languages mentioned in section
3.2.2 (2). Third, the query is translated into the tar-
get language by using a dictionary and the feature
term set of the corresponding category (3). Finally,
the system retrieves documents in the corresponding
category (4).
</bodyText>
<sectionHeader confidence="0.983089" genericHeader="method">
4 Category Merging
</sectionHeader>
<subsectionHeader confidence="0.992256">
4.1 Previous Experiments
</subsectionHeader>
<bodyText confidence="0.999023666666667">
In our previous paper(Kimura et al., 2003), we con-
ducted experiments of category matching using the
subsets of English and Japanese versions of Yahoo!.
</bodyText>
<figureCaption confidence="0.998023">
Figure 3: Processing in retrieval.
</figureCaption>
<bodyText confidence="0.9999174">
The English subset is 559 categories under the cat-
egory “Computers and Internet” and the Japanese
subset is 654 categories under the corresponding
category “--I;/1=° 3rL-f;/3r--*J� (Com-
puters and Internet).” Total size of English web
pages in each category after eliminating HTML tags
are 45,905 bytes on average, ranging from 476 to
1,084,676 bytes. Total size of Japanese web pages
are 22,770 bytes on average, ranging from 467 to
409,576 bytes.
In our previous experiments, we could not match
categories across languages with adequate accuracy.
It may have been caused by the following reasons;
one possible reason is that the size of Web docu-
ments was not enough for statistics in some cate-
gories, and another is that some categories are ex-
cessively divided as a distinct domain.
For the former observation, we eliminated the cat-
egories whose total bytes of Web documents are less
than 30KB, but the results were not improved.
</bodyText>
<subsectionHeader confidence="0.999919">
4.2 Method of Category Merging
</subsectionHeader>
<bodyText confidence="0.999989916666667">
Considering the result of the above experiments, we
need to solve the problem of excessive division of
categories in order to accurately match categories
between languages.
The problem might be caused by the following
reasons; one possible reason is that there are some
categories which are too close in topic, and it might
cause poor accuracy. Another possible reason is that
some categories have insufficient amount of text in
order to obtain statistically significant values for fea-
ture term extraction. Considering the above observa-
tions, we might expect that the accuracy will be im-
</bodyText>
<figure confidence="0.975490666666667">
query
(language A)
(1)
feature
term DB language B
language A
(3)
(2)
query
(language B)
(4)
(4)
rel(q, c) = q~ · c~ ·
c
q·
</figure>
<bodyText confidence="0.997658333333333">
proved by merging child categories at some level in
the category hierarchy in order to merge some cate-
gories similar in topic and to increase the amount of
text in a category.
Accordingly, we solve the problem by merging
child categories into the parent category at some
level using the directory hierarchy. As child cate-
gories are specialized ones of the parent category,
we can assume that these categories have similar
topic. Besides, even if two categories have no direct
link from each other, we can assume that categories
that have same parent category might also have sim-
ilar topic.
However, we still need further investigation on at
which level categories should be merged.
</bodyText>
<figureCaption confidence="0.998523">
Figure 4: Category merging.
</figureCaption>
<sectionHeader confidence="0.999614" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.987575216216216">
We are conducting experiments of the proposed
method to detect relevance category of a query. In
this experiment, we used the same subsets men-
tioned in section 4.1. We merged the categories three
levels below the category “Computers and Internet”
into the parent. The number of categories after cate-
gory merging is 342 in English and 265 in Japanese.
At first, we have done the experiment using the
following formula that uses only inner product,
before using the calculation mentioned in section
3.2.3.
relinner(q, c) = q� · c�
In this experiment, the query has three
terms: “encryption”(=q1), “security”(=q2), and
“system”(=q3).
Table 1 is the list of top 10 relevant categories in
first experiment. Almost all the categories in the Ta-
ble 1 are relevant to the query. Thus, the relevance
calculation method by only inner product is regarded
as an effective method. However, this method has
the following problem. The category that has few
query terms might be given high relevance when the
category has the only one query term whose weight
in the category is extremely high.
In order to reduce this effect, we propose the im-
proved method mentioned in section 3.2.3. The
method is revised to take account of the angle be-
tween q� and c. Ultimately, the most relevant cate-
gory has the vector whose length is long and whose
factors are flat. The length is considered by inner
product, on the other hand, flatness is considered by
the angle between q� and c.
Table 2 is the list of top 10 relevant categories in
the second experiment using revised method. Al-
though noticeable improvement does not appear, the
relevance of the categories which matches few query
terms are ranked lower than the first experiment.
</bodyText>
<sectionHeader confidence="0.999625" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999963533333333">
In this paper, we proposed a method using a Web
directory for CLIR. The proposed method is inde-
pendent of a particular domain because it uses docu-
ments in a Web directory as the corpus. Our method
is particularly effective for the case that the docu-
ment collection covers wide range of domains such
as the Web. Besides, our method does not require
expensive linguistic resources except for a dictio-
nary. Therefore, our method can easily be extended
to other languages as long as the language versions
of a Web directory exist and the dictionary can be
obtained.
Future work includes improving the category
matching method and the evaluation of retrieval ef-
fectiveness.
</bodyText>
<sectionHeader confidence="0.999259" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998938615384615">
Susan Dumais and Hao Chen. 2000. Hierarchical clas-
sification of Web content. Proceedings of the 23rd
ACM International Conference on Research and De-
velopment in Information Retrieval(SIGIR2000).
David A. Hull. 1997. Using structured queries for dis-
ambiguation in cross-language information retrieval.
Electronic Working Notes of the AAAI Symposium on
Cross-Language Text and Speech Retrieval.
Bernard J. Jansen, Amanda Spink, and Tefko Saracevic.
2000. Real life, real user queries on the Web. Infor-
mation Processing &amp; Management, 36(2).
Fuminori Kimura, Akira Maeda, Masatoshi Yoshikawa,
and Shunsuke Uemura. 2003. Cross-Language Infor-
mation Retrieval using Web Directory Structure. The
14th Data Engineering Workshop, (in Japanese).
Chuan-Jie Lin, Wen-Cheng Lin, Guo-Wei Bian, and
Hsin-Hsi Chen. 1999. Description of the NTU
Japanese-English cross-lingual information retrieval
system used for NTCIR workshop. First NTCIR Work-
shop on Research in Japanese Text Retrieval and Term
Recognition.
Tetsuya Sakai. 2000. MT-based Japanese-English cross-
language IR experiments using the TREC test collec-
tions. Proceedings of The Fifth International Work-
shop on Information Retrieval with Asian Languages
(IRAL2000).
</reference>
<tableCaption confidence="0.994257">
Table 1: The list of top 10 relevant category calculated by inner product.
</tableCaption>
<table confidence="0.950062857142857">
category name relevance weight(q1/q2/q3)
Computers and Internet/Security and Encryp- 0.166845 0.112607/0.054238/0.000000
tion/Challenges/
Computers and Internet/Security and Encryp- 0.126984 0.000000/0.126984/0.000000
tion/Conferences/
Computers and Internet/Security and Encryp- 0.106283 0.012577/0.093706/0.000000
tion/Web Directories/
Computers and Internet/Security and Encryp- 0.089169 0.006647/0.076520/0.006002
tion/Organizations/
Business and Economy/Business to Busi- 0.087314 0.006391/0.074656/0.006267
ness/Computers/Security and Encryption/
Computers and Internet/Security and Encryp- 0.086271 0.075185/0.011086/0.000000
tion/Encryption Policy/
Computers and Internet/Security and Encryp- 0.075399 0.017247/0.058152/0.000000
tion/Mailing Lists/
Computers and Internet/Software/Operating 0.075088 0.027648/0.024968/0.022472
Systems/File Systems/
Computers and Internet/Internet/World Wide 0.073100 0.005671/0.05612/0.011309
Web/Security and Encryption/
Computers and Internet/Software/Operating 0.070922 0.000000/0.000000/0.070922
Systems/Inferno/
</table>
<tableCaption confidence="0.980505">
Table 2: The list of the top 10 relevance category calculated by proposed method in section 3.2.3.
</tableCaption>
<reference confidence="0.926824333333333">
category name relevance weight(q1/q2/q3)
Computers and Internet/Security and Encryp- 0.128587 0.112607/0.054238/0.000000
tion/Challenges/
Computers and Internet/Software/Operating 0.074822 0.027648/0.024968/0.022472
Systems/File Systems/
Computers and Internet/Security and Encryp- 0.073314 0.00000/0.126984/0.000000
tion/Conferences/
Computers and Internet/Security and Encryp- 0.068980 0.012577/0.093706/0.000000
tion/Web Directories/
Computers and Internet/Security and Encryp- 0.059585 0.006647/0.07652/0.006002
tion/Organizations/
Business and Economy/Business to Busi- 0.058539 0.006391/0.074656/0.006267
ness/Computers/Security and Encryption/
Computers and Internet/Security and Encryp- 0.056542 0.075185/0.011086/0.000000
tion/Encryption Policy/
Computers and Internet/Security and Encryp- 0.054113 0.017247/0.058152/0.000000
tion/Mailing Lists/
Computers and Internet/Internet/World Wide 0.053628 0.005671/0.05612/0.011309
Web/Security and Encryption/
Computers and Internet/Programming and De- 0.046474 0.000000/0.054276/0.01271
velopment/Languages/Java/Security/
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.006984">
<title confidence="0.9460765">Cross-Language Information Retrieval Based Category Matching Between Language Versions of a Web Directory</title>
<author confidence="0.671185">Fuminori</author>
<affiliation confidence="0.9164845">Graduate School Information Nara Institute Science and</affiliation>
<address confidence="0.962802">8916-5 Ikoma, Nara, Japan</address>
<email confidence="0.710255">Akira</email>
<affiliation confidence="0.590829666666667">Department Computer Ritsumeikan</affiliation>
<address confidence="0.520213">1-1-1 Kusatsu, Shiga, Japan</address>
<email confidence="0.446578">Masatoshi</email>
<affiliation confidence="0.9228">Information</affiliation>
<address confidence="0.679387">Center, Nagoya Furo-cho, Nagoya, Aichi, Japan</address>
<email confidence="0.56742">Shunsuke</email>
<affiliation confidence="0.94062225">Graduate School Information Nara Institute Science and</affiliation>
<address confidence="0.963746">8916-5 Ikoma, Nara, Japan</address>
<abstract confidence="0.990058095238095">Since the Web consists of documents in various domains or genres, the method for Cross-Language Information Retrieval (CLIR) of Web documents should be independent of a particular domain. In this paper, we propose a CLIR method which employs a Web directory provided in multiple language versions (such as Yahoo!). In the proposed method, feature terms are first extracted from Web documents for each category in the source and the target languages. Then, one or more corresponding categories in another language are determined beforehand by comparing similarities between categories across languages. Using these category pairs, we intend to resolve ambiguities of simple dictionary translation by narrowing the categories to be retrieved in the target language.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Susan Dumais</author>
<author>Hao Chen</author>
</authors>
<title>Hierarchical classification of Web content.</title>
<date>2000</date>
<booktitle>Proceedings of the 23rd ACM International Conference on Research and Development in Information Retrieval(SIGIR2000).</booktitle>
<contexts>
<context position="6675" citStr="Dumais and Chen, 2000" startWordPosition="1036" endWordPosition="1039">1999). On the Web retrieval, which is the target of our research, the system has to cope with queries in many different kinds of topics. However, it is impractical to prepare corpora that cover any possible domains. In our previous paper(Kimura et al., 2003), we proposed a CLIR method which uses documents in a Web directory that has several language versions (such as Yahoo!), instead of using existing corpora, in order to improve the retrieval effectiveness. In this paper, we propose an extension of our method which takes account of the hierarchical structure of Web directories. Dumais et al.(Dumais and Chen, 2000) suggests that the precision of Web document classification could be improved to a certain extent by limiting the target categories to compare by using the hierarchical structure of a Web directory. In this paper, we try to improve our proposed method by incorporating the hierarchical structure of a Web directory for merging categories. 3 Proposed System 3.1 Outline of the System Our system uses two or more language versions of a Web directory. One version is the query language (language A in Figure 1), others are the target languages to be retrieved (language B in Figure 1). From these langua</context>
</contexts>
<marker>Dumais, Chen, 2000</marker>
<rawString>Susan Dumais and Hao Chen. 2000. Hierarchical classification of Web content. Proceedings of the 23rd ACM International Conference on Research and Development in Information Retrieval(SIGIR2000).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Hull</author>
</authors>
<title>Using structured queries for disambiguation in cross-language information retrieval.</title>
<date>1997</date>
<booktitle>Electronic Working Notes of the AAAI Symposium on Cross-Language Text and Speech Retrieval.</booktitle>
<contexts>
<context position="5808" citStr="Hull, 1997" startWordPosition="898" endWordPosition="899">roach has an advantage that the translated queries can simply be fed into existing monolingual search engines. In this approach, a source language query is first translated into target language using a bilingual dictionary, and translated query is disambiguated. Our method falls into this category. It is pointed out that corpus-based disambiguation methods are heavily affected by the difference in domain between query and corpus. Hull suggests that the difference between query and corpus may cause bad influence on retrieval effectiveness in the methods that use parallel or comparable corpora (Hull, 1997). Lin et al. conducted comparative experiments among three monolingual corpora that have different domains and sizes, and has concluded that large-scale and domain-consistent corpus is needed for obtaining useful co-occurrence data (Lin et al., 1999). On the Web retrieval, which is the target of our research, the system has to cope with queries in many different kinds of topics. However, it is impractical to prepare corpora that cover any possible domains. In our previous paper(Kimura et al., 2003), we proposed a CLIR method which uses documents in a Web directory that has several language ver</context>
</contexts>
<marker>Hull, 1997</marker>
<rawString>David A. Hull. 1997. Using structured queries for disambiguation in cross-language information retrieval. Electronic Working Notes of the AAAI Symposium on Cross-Language Text and Speech Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard J Jansen</author>
<author>Amanda Spink</author>
<author>Tefko Saracevic</author>
</authors>
<title>Real life, real user queries on the Web. Information Processing &amp;</title>
<date>2000</date>
<journal>Management,</journal>
<volume>36</volume>
<issue>2</issue>
<contexts>
<context position="5104" citStr="Jansen et al., 2000" startWordPosition="787" endWordPosition="790">is not suitable for multilingual, large-scale, and frequently-updated collection of the Web. The second approach transfers both documents and queries into an inter-lingual representation, such as bilingual thesaurus classes or a language-independent vector space. The latter approach requires a training phase using a bilingual (parallel or comparable) corpus as a training data. The major problem in the approach based on the translation and disambiguation of queries is that the queries submitted from ordinary users of Web search engines tend to be very short (approximately two words on average (Jansen et al., 2000)) and usually consist of just an enumeration of keywords (i.e. no context). However, this approach has an advantage that the translated queries can simply be fed into existing monolingual search engines. In this approach, a source language query is first translated into target language using a bilingual dictionary, and translated query is disambiguated. Our method falls into this category. It is pointed out that corpus-based disambiguation methods are heavily affected by the difference in domain between query and corpus. Hull suggests that the difference between query and corpus may cause bad </context>
</contexts>
<marker>Jansen, Spink, Saracevic, 2000</marker>
<rawString>Bernard J. Jansen, Amanda Spink, and Tefko Saracevic. 2000. Real life, real user queries on the Web. Information Processing &amp; Management, 36(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fuminori Kimura</author>
<author>Akira Maeda</author>
<author>Masatoshi Yoshikawa</author>
<author>Shunsuke Uemura</author>
</authors>
<title>Cross-Language Information Retrieval using Web Directory Structure. The 14th Data Engineering Workshop,</title>
<date>2003</date>
<location>(in Japanese).</location>
<contexts>
<context position="6311" citStr="Kimura et al., 2003" startWordPosition="978" endWordPosition="981">ay cause bad influence on retrieval effectiveness in the methods that use parallel or comparable corpora (Hull, 1997). Lin et al. conducted comparative experiments among three monolingual corpora that have different domains and sizes, and has concluded that large-scale and domain-consistent corpus is needed for obtaining useful co-occurrence data (Lin et al., 1999). On the Web retrieval, which is the target of our research, the system has to cope with queries in many different kinds of topics. However, it is impractical to prepare corpora that cover any possible domains. In our previous paper(Kimura et al., 2003), we proposed a CLIR method which uses documents in a Web directory that has several language versions (such as Yahoo!), instead of using existing corpora, in order to improve the retrieval effectiveness. In this paper, we propose an extension of our method which takes account of the hierarchical structure of Web directories. Dumais et al.(Dumais and Chen, 2000) suggests that the precision of Web document classification could be improved to a certain extent by limiting the target categories to compare by using the hierarchical structure of a Web directory. In this paper, we try to improve our </context>
<context position="16081" citStr="Kimura et al., 2003" startWordPosition="2619" endWordPosition="2622">t is because there might be some cases that, for example, documents in the same domain belong to different categories, or a query concept belongs to multiple domains. Second, the corresponding category in the target language is selected by using category correspondences between languages mentioned in section 3.2.2 (2). Third, the query is translated into the target language by using a dictionary and the feature term set of the corresponding category (3). Finally, the system retrieves documents in the corresponding category (4). 4 Category Merging 4.1 Previous Experiments In our previous paper(Kimura et al., 2003), we conducted experiments of category matching using the subsets of English and Japanese versions of Yahoo!. Figure 3: Processing in retrieval. The English subset is 559 categories under the category “Computers and Internet” and the Japanese subset is 654 categories under the corresponding category “--I;/1=° 3rL-f;/3r--*J� (Computers and Internet).” Total size of English web pages in each category after eliminating HTML tags are 45,905 bytes on average, ranging from 476 to 1,084,676 bytes. Total size of Japanese web pages are 22,770 bytes on average, ranging from 467 to 409,576 bytes. In our </context>
</contexts>
<marker>Kimura, Maeda, Yoshikawa, Uemura, 2003</marker>
<rawString>Fuminori Kimura, Akira Maeda, Masatoshi Yoshikawa, and Shunsuke Uemura. 2003. Cross-Language Information Retrieval using Web Directory Structure. The 14th Data Engineering Workshop, (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chuan-Jie Lin</author>
<author>Wen-Cheng Lin</author>
<author>Guo-Wei Bian</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Description of the NTU Japanese-English cross-lingual information retrieval system used for NTCIR workshop.</title>
<date>1999</date>
<booktitle>First NTCIR Workshop on Research in Japanese Text Retrieval and Term Recognition.</booktitle>
<contexts>
<context position="6058" citStr="Lin et al., 1999" startWordPosition="932" endWordPosition="935"> is disambiguated. Our method falls into this category. It is pointed out that corpus-based disambiguation methods are heavily affected by the difference in domain between query and corpus. Hull suggests that the difference between query and corpus may cause bad influence on retrieval effectiveness in the methods that use parallel or comparable corpora (Hull, 1997). Lin et al. conducted comparative experiments among three monolingual corpora that have different domains and sizes, and has concluded that large-scale and domain-consistent corpus is needed for obtaining useful co-occurrence data (Lin et al., 1999). On the Web retrieval, which is the target of our research, the system has to cope with queries in many different kinds of topics. However, it is impractical to prepare corpora that cover any possible domains. In our previous paper(Kimura et al., 2003), we proposed a CLIR method which uses documents in a Web directory that has several language versions (such as Yahoo!), instead of using existing corpora, in order to improve the retrieval effectiveness. In this paper, we propose an extension of our method which takes account of the hierarchical structure of Web directories. Dumais et al.(Dumai</context>
</contexts>
<marker>Lin, Lin, Bian, Chen, 1999</marker>
<rawString>Chuan-Jie Lin, Wen-Cheng Lin, Guo-Wei Bian, and Hsin-Hsi Chen. 1999. Description of the NTU Japanese-English cross-lingual information retrieval system used for NTCIR workshop. First NTCIR Workshop on Research in Japanese Text Retrieval and Term Recognition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuya Sakai</author>
</authors>
<title>MT-based Japanese-English crosslanguage IR experiments using the TREC test collections.</title>
<date>2000</date>
<booktitle>Proceedings of The Fifth International Workshop on Information Retrieval with Asian Languages (IRAL2000).</booktitle>
<contexts>
<context position="4324" citStr="Sakai, 2000" startWordPosition="668" endWordPosition="669">ategory pairs, we intend to resolve ambiguities of simple dictionary translation by narrowing the categories to be retrieved in the target language. 2 Related Work Approaches to CLIR can be classified into three categories; document translation, query translation, and the use of inter-lingual representation. The approach based on translation of target documents has the advantage of utilizing existing machine translation systems, in which more content information can be used for disambiguation. Thus, in general, it achieves a better retrieval effectiveness than those based on query translation(Sakai, 2000). However, since it is impractical to translate a huge document collection beforehand and it is difficult to extend this method to new languages, this approach is not suitable for multilingual, large-scale, and frequently-updated collection of the Web. The second approach transfers both documents and queries into an inter-lingual representation, such as bilingual thesaurus classes or a language-independent vector space. The latter approach requires a training phase using a bilingual (parallel or comparable) corpus as a training data. The major problem in the approach based on the translation a</context>
</contexts>
<marker>Sakai, 2000</marker>
<rawString>Tetsuya Sakai. 2000. MT-based Japanese-English crosslanguage IR experiments using the TREC test collections. Proceedings of The Fifth International Workshop on Information Retrieval with Asian Languages (IRAL2000).</rawString>
</citation>
<citation valid="false">
<booktitle>category name relevance weight(q1/q2/q3) Computers and Internet/Security and Encryp- tion/Challenges/ 0.128587 0.112607/0.054238/0.000000 Computers and Internet/Software/Operating Systems/File Systems/ 0.074822 0.027648/0.024968/0.022472 Computers and Internet/Security and Encryp- tion/Conferences/ 0.073314 0.00000/0.126984/0.000000 Computers and Internet/Security and Encryp- tion/Web Directories/ Computers and Internet/Security and Encryp- tion/Organizations/ 0.059585 0.006647/0.07652/0.006002 Business and Economy/Business to Busi- ness/Computers/Security and Encryption/</booktitle>
<volume>0</volume>
<pages>0--006391</pages>
<marker></marker>
<rawString>category name relevance weight(q1/q2/q3) Computers and Internet/Security and Encryp- tion/Challenges/ 0.128587 0.112607/0.054238/0.000000 Computers and Internet/Software/Operating Systems/File Systems/ 0.074822 0.027648/0.024968/0.022472 Computers and Internet/Security and Encryp- tion/Conferences/ 0.073314 0.00000/0.126984/0.000000 Computers and Internet/Security and Encryp- tion/Web Directories/ Computers and Internet/Security and Encryp- tion/Organizations/ 0.059585 0.006647/0.07652/0.006002 Business and Economy/Business to Busi- ness/Computers/Security and Encryption/ 0.058539 0.006391/0.074656/0.006267</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>