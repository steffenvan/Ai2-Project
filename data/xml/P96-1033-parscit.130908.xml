<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.914348">
Magic for Filter Optimization in Dynamic Bottom-up Processing
</title>
<author confidence="0.959157">
Guido Minnen*
</author>
<affiliation confidence="0.824859">
SFB 340, University of Tübingen
</affiliation>
<address confidence="0.840926666666667">
Kleine Wilhelmstraf3e. 113
D-72074 Tubingen,
Germany
</address>
<email confidence="0.997373">
e—mail:minnen@sfs.nphil.uni—tuebingen.de
</email>
<sectionHeader confidence="0.993851" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999809916666667">
Off-line compilation of logic grammars us-
ing Magic allows an incorporation of fil-
tering into the logic underlying the gram-
mar. The explicit definite clause charac-
terization of filtering resulting from Magic
compilation allows processor independent
and logically clean optimizations of dy-
namic bottom-up processing with respect to
goal-directedness. Two filter optimizations
based on the program transformation tech-
nique of Unfolding are discussed which are
of practical and theoretical interest.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999870739130435">
In natural language processing filtering is used to
weed out those search paths that are redundant, i.e.,
are not going to be used in the proof tree corre-
sponding to the natural language expression to be
generated or parsed. Filter optimization often com-
prises an extension of a specific processing strategy
such that it exploits specific knowledge about gram-
mars and/or the computational task(s) that one is
using them for. At the same time it often remains
unclear how these optimizations relate to each other
and what they actually mean. In this paper I show
how starting from a definite clause characterization
of filtering derived automatically from a logic gram-
mar using Magic compilation, filter optimizations
can be performed in a processor independent and
logically clean fashion.
Magic (templates) is a general compilation tech-
nique for efficient bottom-up evaluation of logic pro-
grams developed in the deductive database commu-
nity (Ramakrishnan et al., 1992). Given a logic pro-
gram, Magic produces a new program in which the
filtering as normally resulting from top-down eval-
uation is explicitly characterized through, so-called,
</bodyText>
<footnote confidence="0.389025">
*url: http://www.sfs.nphil.uni-tuebingenrminnen
</footnote>
<bodyText confidence="0.999932925">
magic predicates, which produce variable bindings
for filtering when evaluated bottom-up. The origi-
nal rules of the program are extended such that these
bindings can be made effective.
As a result of the definite clause characterization
of filtering, Magic brings filtering into the logic un-
derlying the grammar. I discuss two filter optimiza-
tions. These optimizations are direction indepen-
dent in the sense that they are useful for both gen-
eration and parsing. For expository reasons, though,
they are presented merely on the basis of examples
of generation.
Magic compilation does not limit the informa-
tion that can be used for filtering. This can lead
to nontermination as the tree fragments enumer-
ated in bottom-up evaluation of magic compiled
grammars are connected (Johnson, forthcoming).
More specifically, &apos;magic generation&apos; falls prey to
non-termination in the face of head recursion, i.e.,
the generation analog of left recursion in parsing.
This necessitates a dynamic processing strategy, i.e.,
memoization, extended with an abstraction function
like, e.g., restriction (Shieber, 1985), to weaken fil-
tering and a subsumption check to discard redun-
dant results. It is shown that for a large class of
grammars the subsumption check which often influ-
ences processing efficiency rather dramatically can
be eliminated through fine-tuning of the magic pred-
icates derived for a particular grammar after apply-
ing an abstraction function in an off-line fashion.
Unfolding can be used to eliminate superfluous fil-
tering steps. Given an off-line optimization of the
order in which the right-hand side categories in the
rules of a logic grammar are processed (Minnen et
al., 1996) the resulting processing behavior can be
considered a generalization of the head corner gen-
eration approach (Shieber et al., 1990): Without the
need to rely on notions such as semantic head and
chain rule, a head corner behavior can be mimicked
in a strict bottom-up fashion.
</bodyText>
<page confidence="0.998227">
247
</page>
<sectionHeader confidence="0.966207" genericHeader="method">
2 Definite Clause Characterization
</sectionHeader>
<subsectionHeader confidence="0.885001">
of Filtering
</subsectionHeader>
<bodyText confidence="0.999989421052632">
Many approaches focus on exploiting specific knowl-
edge about grammars and/or the computational
task(s) that one is using them for by making filter-
ing explicit and extending the processing strategy
such that this information can be made effective.
In generation, examples of such extended process-
ing strategies are head corner generation with its
semantic linking (Shieber et al., 1990) or bottom-up
(Earley) generation with a semantic filter (Shieber,
1988). Even though these approaches often accom-
plish considerable improvements with respect to ef-
ficiency or termination behavior, it remains unclear
how these optimizations relate to each other and
what comprises the logic behind these specialized
forms of filtering. By bringing filtering into the logic
underlying the grammar it is possible to show in a
perspicuous and logically clean way how and why fil-
tering can be optimized in a particular fashion and
how various approaches relate to each other.
</bodyText>
<subsectionHeader confidence="0.995222">
2.1 Magic Compilation
</subsectionHeader>
<bodyText confidence="0.997048909090909">
Magic makes filtering explicit through characterizing
it as definite clauses. Intuitively understood, filter-
ing is reversed as binding information that normally
becomes available as a result of top-down evaluation
is derived by bottom-up evaluation of the definite
clause characterization of filtering. The following is
the basic Magic algorithm taken from Ramakrishnan
et al. (1992).
Let P be a program and g(Z) a query on
the program. We construct a new program
Pmg. Initially Pmg is empty.
</bodyText>
<listItem confidence="0.9363484375">
1. Create a new predicate magic_p for
each predicate p in P. The arity is that
of p.
2. For each rule in P, add the modified
version of the rule to Pmg. If rule r
has head, say, p(i), the modified ver-
sion is obtained by adding the literal
magic_p(i) to the body.
3. For each rule r in P with head, say,
p(i), and for each literal gi(ii) in its
body, add a magic rule to Pmg. The
head is magie_gi(). The body con-
tains the literal magic_p(1), and all the
literals that precede gi in the rule.
4. Create a seed fact magic_g(o) from the
query.
</listItem>
<bodyText confidence="0.954518790697674">
To illustrate the algorithm I zoom in on the applica-
tion of the above algorithm to one particular gram-
mar rule. Suppose the original grammar rule looks
as follows:
s(PO,P,VForm,SSem):-
vp(P1,P,VForm,[CSem],SSem),
np(PO,P1,CSem).
Step 2 of the algorithm results in the following mod-
ified version of the original grammar rule:
s(PO,P,VForm,SSem):-
magic_s(PO,P,VForm,SSem),
vp(P1,P,VFormJCSem],SSem),
np(PO,P1,CSem).
A magic literal is added to the right-hand side of
the rule which &apos;guards&apos; the application of the rule.
This does not change the semantics of the original
grammar as it merely serves as a way to incorpo-
rate the relevant bindings derived with the magic
predicates to avoid redundant applications of a rule.
Corresponding to the first right-hand side literal in
the original rule step 3 derives the following magic
rule:
magic_vp(P1,P,VFormJCSem],SSem):-
magic_s(PO,P,VForm,SSem).
It is used to derive from the guard for the original
rule a guard for the rules defining the first right-hand
side literal. The second right-hand side literal in the
original rule leads to the following magic rule:
magic_np(PO,P1,CSsm):-
magic_s(PO,P,VForm,SSem),
vp(P1,P,VFormJCSem],SSem).
Finally, step 4 of the algorithm ensures that a seed is
created. Assuming that the original rule is defining
the start category, the query corresponding to the
generation of the s &amp;quot;John buys Mary a book&amp;quot; leads
to the following seed:
magic_s(PO,P,finite,buys(john,a(book),mary)).
The seed constitutes a representation of the initial
bindings provided by the query that is used by the
magic predicates to derive guards. Note that the
creation of the seed can be delayed until run-time,
i.e., the grammar does not need to be recompiled for
every possible query.
</bodyText>
<subsectionHeader confidence="0.995434">
2.2 Example
</subsectionHeader>
<bodyText confidence="0.999596555555555">
Magic compilation is illustrated on the basis of the
simple logic grammar extract in figure 1. This gram-
mar has been optimized automatically for generation
(Minnen et al., 1996): The right-hand sides of the
rules are reordered such that a simple left-to-right
evaluation order constitutes the optimal evaluation
order. With this grammar a simple top-down gen-
eration strategy does not terminate as a result of
the head recursion in rule 3. It is necessary to use
</bodyText>
<page confidence="0.990787">
248
</page>
<table confidence="0.9745741">
sentence (PO , P , decl (SSem) ) : (5) np (PO ,P ,NPSem) : - ,buys(S,D,I)).
(PO , P , f inite ,SSem) . pn (PO , P ,NPSem)
s (PO ,P ,VForm,SSem) : - (6) np (PO ,P ,NPSem)
vp (P1,P , VForm, [CSeml ,SSem) • det (PO , P1 , NSem, NPSem) ,
np (PO , P1 , CSem) , n (P1 , P ,NSem) .
vp (PO , P , VForm,Args ,SSem) : - (7) det ( [alP] ,P ,NSem, a (NSem) ) .
vp (PO , P1 , VForm, [CSemjArgs] ,SSem) , (8) v ( EbuysIP1 ,P,finite,
np(P1,P ,CSem) . (9) pn(EmaryIPJ ,P,mary)
vp (PO , P , VForm,Args , SSem) : - (10)n( [bookIP] ,P,book) .
v (PO , P , VForm,Args ,SSem) .
</table>
<figureCaption confidence="0.998819">
Figure 1: Simple head-recursive grammar.
</figureCaption>
<bodyText confidence="0.972716311688312">
memoization extended with an abstraction function
and a subsumption check. Strict bottom-up gener-
ation is not attractive either as it is extremely in-
efficient: One is forced to generate all possible nat-
ural language expressions licensed by the grammar
and subsequently check them against the start cate-
gory. It is possible to make the process more efficient
through excluding specific lexical entries with a se-
mantic filter. The use of such a semantic filter in
bottom-up evaluation requires the grammar to obey
the semantic monotonicity constraint in order to en-
sure completeness(Shieber, 1988) (see below).
The &apos;magic-compiled grammar&apos; in figure 2 is the
result of applying the algorithm in the previous sec-
tion to the head-recursive example grammar and
subsequently performing two optimizations (Beeni
and Ramakrishnan, 1991): All (calls to) magic pred-
icates corresponding to lexical entries are removed.
Furthermore, data-flow analysis is used to fine-tune
the magic predicates for the specific processing task
at hand, i.e., generation.&apos; Given a user-specified
abstract query, i.e., a specification of the intended
input (Been i and Ramakrishnan, 1991) those argu-
ments which are not bound and which therefore
serve no filtering purpose are removed. The modi-
fied versions of the original rules in the grammar are
adapted accordingly. The effect of taking data-flow
into account can be observed by comparing the rules
for magic_vp and magi c_np in the previous section
with rule 12 and 14 in figure 2, respectively.
Figure 3 shows the results from generation of the
sentence &amp;quot;John buys Mary a book&amp;quot;. In the case of
this example the seed looks as follows:
magic_sentence (decl (buys (j ohn , a (book) ,mary) ) ) •
The facts, i.e., passive edges/items, in figure 3 re-
sulted from semi-naive bottom-up evaluation (Ra-
-
&apos;For
iFor expository reasons some data-flow information
that does restrict processing is not taken into account.
E.g., the fact that the vp literal in rule 2 is always
called with a one-element list is ignored here, but see
section 3.1.
makrishnan et al., 1992) which constitutes a dy-
namic bottom-up evaluation, where repeated deriva-
tion of facts from the same earlier derived facts (as in
naive evaluation; Bancilhon, 1985) is blocked. (Ac-
tive edges are not memoized.) The figure2 consist of
two tree structures (connected through dotted lines)
of which the left one corresponds to the filtering
part of the derivation. The filtering tree is reversed
and derives magic facts starting from the seed in a
bottom-up fashion. The tree on the right is the proof
tree for the example sentence which is built up as a
result of unifying in the derived magic facts when
applying a particular rule. E.g., in order to derive
fact 13, magic fact 2 is unified with the magic literal
in the modified version of rule 2 (in addition to the
facts 12 and 10). This, however, is not represented
in order to keep the figure clear. Dotted lines are
used to represent when &apos;normal&apos; facts are combined
with magic facts to derive new magic facts.
As can be reconstructed from the numbering of
the facts in figure 3 the resulting processing behav-
ior is identical to the behavior that would result
from Earley generation as in Gerdemann (1991) ex-
cept that the different filtering steps are performed
in a bottom-up fashion. In order to obtain a gen-
erator similar to the bottom-up generator as de-
scribed in Shieber (1988) the compilation process
can be modified such that only lexical entries are
extended with magic literals. Just like in case of
Shieber&apos;s bottom-up generator, bottom-up evalua-
tion of magic-compiled grammars produced with this
Magic variant is only guaranteed to be complete in
case the original grammar obeys the semantic mono-
tonicity constraint.
</bodyText>
<footnote confidence="0.99763825">
2The numbering of the facts corresponds to the order
in which they are derived. A number of lexical entries
have been added to the example grammar. The facts cor-
responding to lexical entries are ignored. For expository
reasons the phonology and semantics of lexical entries
(except for vs) are abbreviated by the first letter. Fur-
thermore the fact corresponding to the vp &amp;quot;buys Mary a
book John&amp;quot; is not included.
</footnote>
<page confidence="0.993441">
249
</page>
<listItem confidence="0.663514378378378">
(1) sentence(PO,P,decl(SSem)):-
magic_sentence(decl(SSem)),
s(PO,P,finite,SSem).
(2) s(PO,P,VForm,SSem):-
magic_s(VForm,SSem),
vp(P1,P,VFormJCSemi,SSem),
np(P0,P1,CSem).
(3) vp(PO,P,VForm,Args,SSem):-
magic_vp(VForm,SSem),
vp(P0,P1,VFormJCSemlArgs],SSem),
np(P1,P,CSem).
(4) vp(PO,P,VForm,Args,SSem):-
magic_vp(VForm,SSem),
v(PO,P,VForm,Args,SSem).
(5) np (PO ,P ,NPSem) :-
magic_np(NPSem) ,
pn(PO,P,NPSem).
(6) np(PO,P,NPSem):-
magic_np(NPSem),
det(P0,P1,NSem,NPSem),
n(P1,P,NSem).
(7) detUalPl,P,NSem,a(NSem)).
(8) v(CbuysIP),P,finite,[I,D,S],buys(S,D,I)).
(9) pn( [marYIP] ,P,marY)
(10) n([bookIPLP,book).
(11) magic_s(finite,SSem):-
magic_sentence(decl(SSem)
(12) magic_vp(VForm,SSem):-
magic_s(VForm,SSem).
(13) magic_vp(VForm,SSem):-
magic_vp(VForm,SSem).
(14) magic_np(CSem):-
magic_s(VForm,SSem),
vp(P1,P,VForm,(CSeml,SSem).
(15) magic_np(CSem):-
magic_vp(VForm,SSem),
vp(P0,P1,VFormJCSemlArgs],SSem).
</listItem>
<figureCaption confidence="0.949081">
Figure 2: Magic compiled version 1 of the grammar in figure 1.
</figureCaption>
<figure confidence="0.421686375">
&apos;FILTERING TREE&apos; &apos;PROOF TREE&apos;
II.magic_np(j).
8.magic_np(a(b)).. &apos; • 15.sentenceabuys,m,a,b1A1,A,decl(buys(j,a(b),m))).
5.magic_np(m). 3.magic_vP(finite,buys(j,a(b),m)).&amp;quot;
13.saj,buys,m,a,b1A1,A,finite,buys(j,a(b),m)).
3.magic:vp(finite,buys(j,a(b),m)). • 10..xpabuys,m,a,blA1,A,finite,[j],buYs(i•a(b),m)).
12.np(jlAI,A,j). 4.vp([buyslAI,A,finite,[m,a(b),j1,buys(j,a(b),m)). 6.npamiAl,A,m). 9.npaa,b1A1,A,a(b)).
1.magic_sentence(decl(buys(j,a(b),m))).
</figure>
<figureCaption confidence="0.997654">
Figure 3: &apos;Connecting up&apos; facts resulting from semi-naive generation of the sentence &amp;quot;John buys Mary a
book&amp;quot; with the magic-compiled grammar from figure 2.
</figureCaption>
<figure confidence="0.816746857142857">
2.magic_s(finite,buys(i•a(b)411)).
••••••.
&apos; typabuys,m1A[,A,finite,[a(b),j1,buys(j,a(b),m)).
• •-..
250
3 Filter Optimization through many magic_vp facts. This &apos;cyclic&apos; magic rule is de-
Program Transformation rived from the head-recursive vp rule in the example
</figure>
<bodyText confidence="0.552418846153846">
As a result of characterizing filtering by a definite grammar. There is however no reason to keep this
clause representation Magic brings filtering inside of rule in the magic-compiled grammar. It influences
the logic underlying the grammar. This allows it to neither the efficiency of processing with the gram-
be optimized in a processor independent and logi- mar nor the completeness of the evaluation process.
cally clean fashion. I discuss two possible filter opti- 3.1.1 Off-line Abstraction
mizations based on a program transformation tech- Finding these types of cycles in the magic part of
nique called unfolding (Tamaki and Sato, 1984) also the compiled grammar is in general undecidable. It
referred to as partial execution, e.g., in Pereira and is possible though to &apos;trim&apos; the magic predicates by
Shieber (1987) . applying an abstraction function. As a result of the
3.1 Subsumption Checking explicit representation of filtering we do not need to
Just like top-down evaluation of the original gram- postpone abstraction until run-time, but can trim
mar bottom-up evaluation of its magic compiled ver- the magic predicates off-line. One can consider this
sion falls prey to non-termination in the face of head as bringing abstraction into the logic as the definite
recursion. It is however possible to eliminate the clause representation of filtering is weakened such
subsumption check through fine-tuning the magic that only a mild form of connectedness results which
predicates derived for a particular grammar in an does not affect completeness (Shieber, 1985). Con-
off-line fashion. In order to illustrate how the magic sider the following magic rule:
predicates can be adapted such that the subsump- magic_vp(VForm,[0enOrgsJ,SSem):-
tion check can be eliminated it is necessary to take a magic_vp(VForm,Args,SSem).
closer look at the relation between the magic pred- This is the rule that is derived from the head-
icates and the facts they derive. In figure 4 the re- recursive vp rule when the partially specified sub-
lation between the magic predicates for the example categorization list is considered as filtering informa-
grammar is represented by an unfolding tree (Pet- tion (cf., fn. 1). The rule builds up infinitely large
torossi and Proietti, 1994). This, however, is not an subcategorization lists of which eventually only one
ordinary unfolding tree as it is constructed on the is to be matched against the subcategorization list
basis of an abstract seed, i.e., a seed adorned with of, e.g., the lexical entry for &amp;quot;buys&amp;quot;. Though this
</bodyText>
<figureCaption confidence="0.94701196969697">
a specification of which arguments are to be con- rule is not cyclic, it becomes cyclic upon off-line ab-
sidered bound. Note that an abstract seed can be straction:
derived from the user-specified abstract query. Only magic_vp(VForm,(CSemW,SSem):-
the magic part of the abstract unfolding tree is rep- magic_vp(VFormJCSem20,SSem).
resented. Through trimming this magic rule, e.g., given a
ABSTRACT SEED bounded term depth (Sato and Tamaki, 1984) or a
magic-sentence(SSem),••• restrictor (Shieber, 1985), constructing an abstract
...4— magic_s(finite,SSem),... unfolding tree reveals the fact that a cycle results
from the magic rule. This information can then be
used to discard the culprit.
3.1.2 Indexing
Removing the direct or indirect cycles from the
magic part of the compiled grammar does eliminate
the necessity of subsumption checking in many cases.
However, consider the magic rules 14 and 15 in fig-
ure 2. Rule 15 is more general than rule 14. Without
subsumption checking this leads to spurious ambigu-
ity: Both rules produce a magic fact with which a
subject np can be built. A possible solution to this
problem is to couple magic rules with the modified
version of the original grammar rule that instigated
it. To accomplish this I propose a technique that
can be considered the off-line variant of an index-
...1— magic_vp(VForm,SSem),...
ci
...&lt;— magic_np(CSem),...
Figure 4: Abstract unfolding tree representing the
relation between the magic predicates in the compiled
grammar.
The abstract unfolding tree in figure 4 clearly
shows why there exists the need for subsumption
checking: Rule 13 in figure 2 produces infinitely
251
</figureCaption>
<bodyText confidence="0.963499">
ing technique described in Gerdemann (1991).3 The
indexing technique is illustrated on the basis of the
running example: Rule 14 in figure 1 is coupled to
the modified version of the original s rule that insti-
gated it, i.e., rule 2. Both rules receive an index:
</bodyText>
<construct confidence="0.518846857142857">
s (PO ,P ,VForm,SSem) : -
magic_s (PO , P ,VForm,SSem) ,
vp (P1 ,P ,VForm, [CSem] ,SSem) ,
np (PO ,P1 , CSem, index_1) .
magic_np(CSem, index_1) : -
magic_s (PO , P ,VForm, SSem) ,
vp (P1,P ,VForm, ECSem.1 ,SSem) .
</construct>
<bodyText confidence="0.972393090909091">
The modified versions of the rules defining nps are
adapted such that they percolate up the index of
the guarding magic fact that licensed its application.
This is illustrated on the basis of the adapted version
of rule 14:
np (PO , P , NPSem, INDEX) : -
magic_np (NPSem, INDEX) ,
pn (PO ,P ,NPSem) .
As is illustrated in section 3.3 this allows the avoid-
ance of spurious ambiguities in the absence of sub-
sumption check in case of the example grammar.
</bodyText>
<subsectionHeader confidence="0.999636">
3.2 Redundant Filtering Steps
</subsectionHeader>
<bodyText confidence="0.912745230769231">
Unfolding can also be used to collapse filtering steps.
As becomes apparent upon closer investigation of the
abstract unfolding tree in figure 4 the magic predi-
cates magic_sentence, magic_s and magic_vp pro-
vide virtually identical variable bindings to guard
bottom-up application of the modified versions of
the original grammar rules. Unfolding can be used to
reduce the number of magic facts that are produced
during processing. E.g., in figure 2 the magic_s rule:
magic_s (f inite ,SSem) : -
magic_sentence (decl (SSem) ) .
can be eliminated by unfolding the magic_s literal
in the modified s rule:
</bodyText>
<construct confidence="0.963058">
s (PO , P ,VFOR14, SSem) : -
magic_s (VFORM,SSem) ,
vp (P1 ,P , VFORM „ [CSem] ,SSem) ,
np (PO ,P1,CSem) .
</construct>
<bodyText confidence="0.952701333333333">
This results in the following new rule which uses the
seed for filtering directly without the need for an
intermediate filtering step:
</bodyText>
<footnote confidence="0.9968842">
3This technique resembles an extension of Magic
called Counting (Been i and Ramakrishnan, 1991). How-
ever, Counting is more refined as it allows to distinguish
between different levels of recursion and serves entirely
different purposes.
</footnote>
<construct confidence="0.6742285">
s (PO,P,finite,SSem) :-
magic_sentence (decl (SSem) ) ,
vp (P1 ,P , f inite , [CSem] , SSem) ,
np (PO ,P1,CSem) .
</construct>
<bodyText confidence="0.999972733333333">
Note that the unfolding of the magic_s literal
leads to the instantiation of the argument VFORM
to finite. As a result of the fact that there are
no other magic_s literals in the remainder of the
magic-compiled grammar the magic_s rule can be
discarded.
This filter optimization is reminiscent of comput-
ing the deterministic closure over the magic part of
a compiled grammar (Dorre, 1993) at compile time.
Performing this optimization throughout the magic
part of the grammar in figure 2 not only leads to a
more succinct grammar, but brings about a different
processing behavior. Generation with the resulting
grammar can be compared best with head corner
generation (Shieber et al., 1990) (see next section).
</bodyText>
<subsectionHeader confidence="0.996333">
3.3 Example
</subsectionHeader>
<bodyText confidence="0.999994791666667">
After cycle removal, incorporating relevant indexing
and the collapsing of redundant magic predicates the
magic-compiled grammar from figure 2 looks as dis-
played in figure 5. Figure 6 shows the chart resulting
from generation of the sentence &amp;quot;John buys Mary a
book&amp;quot; .4 The seed is identical to the one used for the
example in the previous section. The facts in the
chart resulted from not-so-naive bottom-up evalu-
ation: semi-naive evaluation without subsumption
checking (Ramakrishnan et al., 1992). The result-
ing processing behavior is similar to the behavior
that would result from head corner generation ex-
cept that the different filtering steps are performed
in a bottom-up fashion. The head corner approach
jumps top-down from pivot to pivot in order to sat-
isfy its assumptions concerning the flow of seman-
tic information, i.e., semantic chaining, and subse-
quently generates starting from the semantic head
in a bottom-up fashion. In the example, the seed is
used without any delay to apply the base case of the
vp-procedure, thereby jumping over all intermediate
chain and non-chain rules. In this respect the initial
reordering of rule 2 which led to rule 2 in the final
grammar in figure 5 is crucial (see section 4).
</bodyText>
<sectionHeader confidence="0.966499" genericHeader="method">
4 Dependency Constraint on
Grammar
</sectionHeader>
<bodyText confidence="0.8086258">
To which extent it is useful to collapse magic predi-
cates using unfolding depends on whether the gram-
mar has been optimized through reordering the
41n addition to the conventions already described re-
garding figure 3, indices are abbreviated.
</bodyText>
<page confidence="0.993298">
252
</page>
<bodyText confidence="0.883968352941177">
sentence(PO,P,decl(SSem)):-
magic_sentence(decl(SSem)),
s(PO,P,finite,SSem).
s(PO,P,finite,SSem):-
magic_sentence(decl(SSem)),
vp(P1,P,finiteJCSem],SSem),
np(P0,P1,CSem,index_1).
vp(PO,P,finite,Args,SSem):-
magic_sentence(decl(SSem)),
vp(P0,P1,finite,(CSemlArgs],SSem),
np(P1,P,CSem,index_2).
vp(PO,P,finite,Args,SSem):-
magic_sentence(decl(SSem)),
v(PO,P,finite,Args,SSem).
np(PO,P,NPSem,INDEX):-
magic_np(NPSem,INDEX),
pn(PO,P,NPSem).
</bodyText>
<figure confidence="0.599678071428572">
(6) np(PO,P,NPSem,INDEX):-
magic_np(NPSem,INDEX),
det(P0,P1,NSem,NPSem),
n(P1,P,NSem).
(7) det(EalP),P,NSem,a(NSem)).
(8) v ( [buys IP] ,P,f inite , [I,D,S] , buys (S ,D , I) ) .
(9) pn ( CmarylP] ,P,marY)
(10) n(Cbook1P),P,book).
(14) magic_np(CSem,index_1):-
magic_sentence(decl(SSem)),
vp(P1,P,finite,CCSem),SSem).
(15) magic_np(CSem,index_2):-
magic_sentence(decl(SSem)),
vp(P0,P1,finite,[CSemlArgs],SSem).
</figure>
<figureCaption confidence="0.982513">
Figure 5: Magic compiled version 2 of the grammar in figure 1.
</figureCaption>
<figure confidence="0.766696">
1.magic...sentence(decl(buys(j,a(b),m))).
</figure>
<figureCaption confidence="0.996008">
Figure 6: &apos;Connecting up&apos; facts resulting from not-so-naive generation of the sentence &amp;quot;John buys Mary a
book&amp;quot; with the magic-compiled grammar from figure 5.
</figureCaption>
<figure confidence="0.998478875">
15.sentenceaj,buys,m,a,b1AbA,decl(buys(j ,a(b),m)))-
13.8W,buys,m,a,b1A1,A,finite,buys(j,a(b),m)).
.............
10.vp([buys,m,a,10],A,finitedj],buys(j,a(b),m)).
5.vpabuys,mlAbA,finite,[a(b)abuys(La(b),In))•
11.magic_np(j,i1).
• •
6.magic_rip(a(b),i..2). • •
</figure>
<figureCaption confidence="0.857882">
11•nP(UlAbAj,E1). 2.vpabuyslAbA,finitedm,a(b),Lbuys(j,a(b),m)). 4•11P(ImIALA,m,i_2). 7.npaa,b1AbA,a(b),L2).
</figureCaption>
<bodyText confidence="0.99908947826087">
right-hand sides of the rules in the grammar as dis-
cussed in section 3.3. If the s rule in the running
example is not optimized, the resulting processing
behavior would not have fallen out so nicely: In this
case it leads either to an intermediate filtering step
for the non-chaining sentence rule or to the addi-
tion of the literal corresponding to the subject np to
all chain and non-chain rules along the path to the
semantic head.
Even when cycles are removed from the magic part
of a compiled grammar and indexing is used to avoid
spurious ambiguities as discussed in the previous sec-
tion, subsumption checking can not always be elim-
inated. The grammar must be finitely ambiguous,
i.e., fulfill the off-line parsability constraint (Shieber,
1989). Furthermore, the grammar is required to
obey what I refer to as the dependency constraint:
When a particular right-hand side literal can not be
evaluated deterministically, the results of its evalu-
ation must uniquely determine the remainder of the
right-hand side of the rule in which it appears. Fig-
ure 7 gives a schematic example of a grammar that
does not obey the dependency constraint. Given
</bodyText>
<figure confidence="0.720018333333333">
cat_1(...):-
magic_cat_1(Filter),
cat_2(Filter,Dependency,...),
cat_3(Dependency).
magic_cat_3(Filter):-
magic_cat_1(Filter),
cat_2(Filter,Dependency,...).
cat_2(property_1,property_2,...).
cat_2(property_1,property_2,...).
</figure>
<figureCaption confidence="0.993771">
Figure 7: Abstract example grammar not obeying the
dependency constraint.
</figureCaption>
<page confidence="0.992291">
253
</page>
<bodyText confidence="0.999008">
a derived fact or seed magic_cat_1 (property-1)
bottom-up evaluation of the abstract grammar in
figure 7 leads to spurious ambiguity. There are two
possible solutions for cat_2 as a result of the fact
that the filtering resulting from the magic literal in
rule 1 is too unspecific. This is not problematic as
long as this nondeterminism will eventually disap-
pear, e.g., by combining these solutions with the so-
lutions to cat_3. The problem arises as a result of
the fact that these solutions lead to identical filters
for the evaluation of the cat_3 literal, i.e., the solu-
tions to cat_2 do not uniquely determine cat_3.
Also with respect to the dependency constraint an
optimization of the rules in the grammar is impor-
tant. Through reordering the right-hand sides of the
rules in the grammar the amount of nondeterminism
can be drastically reduced as shown in Minnen et al.
(1996). This way of following the intended semantic
dependencies the dependency constraint is satisfied
automatically for a large class of grammars.
</bodyText>
<sectionHeader confidence="0.992728" genericHeader="method">
5 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.999814909090909">
Magic evaluation constitutes an interesting combi-
nation of the advantages of top-down and bottom-
up evaluation. It allows bottom-up filtering that
achieves a goal-directedness which corresponds to
dynamic top-down evaluation with abstraction and
subsumption checking. For a large class of grammars
in effect identical operations can be performed off-
line thereby allowing for more efficient processing.
Furthermore, it enables a reduction of the number
of edges that need to be stored through unfolding
magic predicates.
</bodyText>
<sectionHeader confidence="0.999594" genericHeader="conclusions">
6 Acknowledgments
</sectionHeader>
<bodyText confidence="0.99997525">
The presented research was sponsored by Teilprojekt
B4 &amp;quot;From Constraints to Rules: Efficient Compila-
tion of HPSG Grammars&amp;quot; of the Sonderforschungs-
bereich 340 of the Deutsche Forschungsgemeinschaft.
The author wishes to thank Dale Gerdemann, Mark
Johnson, Thilo Gotz and the anonymous reviewers
for valuable comments and discussion. Of course,
the author is responsible for all remaining errors.
</bodyText>
<sectionHeader confidence="0.999477" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999808350877193">
Francois Bancilhon. 1985. Naive Evaluation of Re-
cursively Defined Relations. In Brodie and My-
lopoulos, editors, On Knowledge Base Manage-
ment Systems - Integrating Database and AT Sys-
tems. Springer-Verlag.
Catriel Been i and Raghu Ramakrishnan. 1991. On
the Power of Magic. Journal of Logic Program-
ming 10.
Jochen Done. 1993. Generalizing Earley De-
duction for Constraint-based Grammars. Dorre
and Dorna, editors, Computational Aspects
of Constraint-Based Linguistic Description I,
DYANA-2, Deliverable R1.2.A.
Dale Gerdemann. 1991. Parsing and Generation of
Unification Grammars. Ph.D. thesis, University
of Illinois, USA.
Mark Johnson. forthcoming. Constraint-based Nat-
ural Language Parsing. Brown University, Rich-
mond, USA. Draft of 6 August 1995.
Guido Minnen, Dale Gerdemann, and Erhard Hin-
richs. 1996. Direct Automated Inversion of Logic
Grammars. New Generation Computing 14.
Fernando Pereira and Stuart Shieber. 1987. Pro-
log and Natural Language Analysis. CSLI Lecture
Notes, No. 10. Center for the Study of Language
and Information, Chicago, USA.
Alberto Pettorossi and Maurizio Proietti. 1994.
Transformations of Logic Programs: Foundations
and Techniques. Journal of Logic Programming
19/20.
Raghu Ramakrishnan, Divesh Srivastava, and S. Su-
darshan. 1992. Efficient Bottom-up Evaluation of
Logic Programs. In Vandewalle, editor, The State
of the Art in Computer Systems and Software En-
gineering. Kluwer Academic Publishers.
Taisuke Sato and Hisao Tamaki. 1984. Enumeration
of Success Patterns in Logic Programs. Theoreti-
cal Computer Sience 34.
Stuart Shieber, Gertjan van Noord, Robert Moore,
and Fernando Pereira. 1990. Semantic Head-
driven Generation. Computational Linguistics 16.
Stuart Shieber. 1985. Using Restriction to Extend
Parsing Algorithms for Complex Feature-based
Formalisms. In Proceedings of the 23rd Annual
Meeting Association for Computational Linguis-
tics, Chicago, USA.
Stuart Shieber. 1988. A Uniform Architecture
for Parsing and Generation. In Proceedings of
the 12th Conference on Computational Linguis-
tics, Budapest, Hungary.
Stuart Shieber. 1989. Parsing and Type Inference
for Natural and Computer Languages. Ph.D. the-
sis, Stanford University, USA.
Hisao Tamaki and Taisuke Sato. 1984. Unfold/Fold
Transformation of Logic Programs. In Proceed-
ings of the 2nd International Conference on Logic
Programming, Uppsala, Sweden.
</reference>
<page confidence="0.998641">
254
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.867424">
<title confidence="0.999904">Magic for Filter Optimization in Dynamic Bottom-up Processing</title>
<author confidence="0.9996">Guido Minnen</author>
<affiliation confidence="0.999853">University of Tübingen</affiliation>
<address confidence="0.956012666666667">Kleine Wilhelmstraf3e. 113 D-72074 Tubingen, Germany</address>
<email confidence="0.999609">e—mail:minnen@sfs.nphil.uni—tuebingen.de</email>
<abstract confidence="0.998924692307692">Off-line compilation of logic grammars usan incorporation of filtering into the logic underlying the grammar. The explicit definite clause characterization of filtering resulting from Magic compilation allows processor independent logically clean optimizations of dybottom-up processing respect to Two optimizations based on the program transformation technique of Unfolding are discussed which are of practical and theoretical interest.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Francois Bancilhon</author>
</authors>
<title>Naive Evaluation of Recursively Defined Relations.</title>
<date>1985</date>
<booktitle>In Brodie and Mylopoulos, editors, On Knowledge Base Management Systems - Integrating Database and AT Systems.</booktitle>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="10990" citStr="Bancilhon, 1985" startWordPosition="1756" endWordPosition="1757">example the seed looks as follows: magic_sentence (decl (buys (j ohn , a (book) ,mary) ) ) • The facts, i.e., passive edges/items, in figure 3 resulted from semi-naive bottom-up evaluation (Ra&apos;For iFor expository reasons some data-flow information that does restrict processing is not taken into account. E.g., the fact that the vp literal in rule 2 is always called with a one-element list is ignored here, but see section 3.1. makrishnan et al., 1992) which constitutes a dynamic bottom-up evaluation, where repeated derivation of facts from the same earlier derived facts (as in naive evaluation; Bancilhon, 1985) is blocked. (Active edges are not memoized.) The figure2 consist of two tree structures (connected through dotted lines) of which the left one corresponds to the filtering part of the derivation. The filtering tree is reversed and derives magic facts starting from the seed in a bottom-up fashion. The tree on the right is the proof tree for the example sentence which is built up as a result of unifying in the derived magic facts when applying a particular rule. E.g., in order to derive fact 13, magic fact 2 is unified with the magic literal in the modified version of rule 2 (in addition to the</context>
</contexts>
<marker>Bancilhon, 1985</marker>
<rawString>Francois Bancilhon. 1985. Naive Evaluation of Recursively Defined Relations. In Brodie and Mylopoulos, editors, On Knowledge Base Management Systems - Integrating Database and AT Systems. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catriel Been i</author>
<author>Raghu Ramakrishnan</author>
</authors>
<title>On the Power of Magic.</title>
<date>1991</date>
<journal>Journal of Logic Programming</journal>
<volume>10</volume>
<contexts>
<context position="9579" citStr="i and Ramakrishnan, 1991" startWordPosition="1521" endWordPosition="1524">ral language expressions licensed by the grammar and subsequently check them against the start category. It is possible to make the process more efficient through excluding specific lexical entries with a semantic filter. The use of such a semantic filter in bottom-up evaluation requires the grammar to obey the semantic monotonicity constraint in order to ensure completeness(Shieber, 1988) (see below). The &apos;magic-compiled grammar&apos; in figure 2 is the result of applying the algorithm in the previous section to the head-recursive example grammar and subsequently performing two optimizations (Beeni and Ramakrishnan, 1991): All (calls to) magic predicates corresponding to lexical entries are removed. Furthermore, data-flow analysis is used to fine-tune the magic predicates for the specific processing task at hand, i.e., generation.&apos; Given a user-specified abstract query, i.e., a specification of the intended input (Been i and Ramakrishnan, 1991) those arguments which are not bound and which therefore serve no filtering purpose are removed. The modified versions of the original rules in the grammar are adapted accordingly. The effect of taking data-flow into account can be observed by comparing the rules for mag</context>
<context position="20862" citStr="i and Ramakrishnan, 1991" startWordPosition="3224" endWordPosition="3227">iginal grammar rules. Unfolding can be used to reduce the number of magic facts that are produced during processing. E.g., in figure 2 the magic_s rule: magic_s (f inite ,SSem) : - magic_sentence (decl (SSem) ) . can be eliminated by unfolding the magic_s literal in the modified s rule: s (PO , P ,VFOR14, SSem) : - magic_s (VFORM,SSem) , vp (P1 ,P , VFORM „ [CSem] ,SSem) , np (PO ,P1,CSem) . This results in the following new rule which uses the seed for filtering directly without the need for an intermediate filtering step: 3This technique resembles an extension of Magic called Counting (Been i and Ramakrishnan, 1991). However, Counting is more refined as it allows to distinguish between different levels of recursion and serves entirely different purposes. s (PO,P,finite,SSem) :- magic_sentence (decl (SSem) ) , vp (P1 ,P , f inite , [CSem] , SSem) , np (PO ,P1,CSem) . Note that the unfolding of the magic_s literal leads to the instantiation of the argument VFORM to finite. As a result of the fact that there are no other magic_s literals in the remainder of the magic-compiled grammar the magic_s rule can be discarded. This filter optimization is reminiscent of computing the deterministic closure over the ma</context>
</contexts>
<marker>i, Ramakrishnan, 1991</marker>
<rawString>Catriel Been i and Raghu Ramakrishnan. 1991. On the Power of Magic. Journal of Logic Programming 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jochen Done</author>
</authors>
<title>Generalizing Earley Deduction for Constraint-based Grammars.</title>
<date>1993</date>
<booktitle>Dorre and Dorna, editors, Computational Aspects of Constraint-Based Linguistic Description I, DYANA-2, Deliverable R1.2.A.</booktitle>
<marker>Done, 1993</marker>
<rawString>Jochen Done. 1993. Generalizing Earley Deduction for Constraint-based Grammars. Dorre and Dorna, editors, Computational Aspects of Constraint-Based Linguistic Description I, DYANA-2, Deliverable R1.2.A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dale Gerdemann</author>
</authors>
<title>Parsing and Generation of Unification Grammars.</title>
<date>1991</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Illinois, USA.</institution>
<contexts>
<context position="11984" citStr="Gerdemann (1991)" startWordPosition="1932" endWordPosition="1933"> up as a result of unifying in the derived magic facts when applying a particular rule. E.g., in order to derive fact 13, magic fact 2 is unified with the magic literal in the modified version of rule 2 (in addition to the facts 12 and 10). This, however, is not represented in order to keep the figure clear. Dotted lines are used to represent when &apos;normal&apos; facts are combined with magic facts to derive new magic facts. As can be reconstructed from the numbering of the facts in figure 3 the resulting processing behavior is identical to the behavior that would result from Earley generation as in Gerdemann (1991) except that the different filtering steps are performed in a bottom-up fashion. In order to obtain a generator similar to the bottom-up generator as described in Shieber (1988) the compilation process can be modified such that only lexical entries are extended with magic literals. Just like in case of Shieber&apos;s bottom-up generator, bottom-up evaluation of magic-compiled grammars produced with this Magic variant is only guaranteed to be complete in case the original grammar obeys the semantic monotonicity constraint. 2The numbering of the facts corresponds to the order in which they are derive</context>
<context position="19007" citStr="Gerdemann (1991)" startWordPosition="2898" endWordPosition="2899"> np can be built. A possible solution to this problem is to couple magic rules with the modified version of the original grammar rule that instigated it. To accomplish this I propose a technique that can be considered the off-line variant of an index...1— magic_vp(VForm,SSem),... ci ...&lt;— magic_np(CSem),... Figure 4: Abstract unfolding tree representing the relation between the magic predicates in the compiled grammar. The abstract unfolding tree in figure 4 clearly shows why there exists the need for subsumption checking: Rule 13 in figure 2 produces infinitely 251 ing technique described in Gerdemann (1991).3 The indexing technique is illustrated on the basis of the running example: Rule 14 in figure 1 is coupled to the modified version of the original s rule that instigated it, i.e., rule 2. Both rules receive an index: s (PO ,P ,VForm,SSem) : - magic_s (PO , P ,VForm,SSem) , vp (P1 ,P ,VForm, [CSem] ,SSem) , np (PO ,P1 , CSem, index_1) . magic_np(CSem, index_1) : - magic_s (PO , P ,VForm, SSem) , vp (P1,P ,VForm, ECSem.1 ,SSem) . The modified versions of the rules defining nps are adapted such that they percolate up the index of the guarding magic fact that licensed its application. This is il</context>
</contexts>
<marker>Gerdemann, 1991</marker>
<rawString>Dale Gerdemann. 1991. Parsing and Generation of Unification Grammars. Ph.D. thesis, University of Illinois, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>forthcoming</author>
</authors>
<title>Constraint-based Natural Language Parsing.</title>
<date>1995</date>
<journal>Draft of</journal>
<volume>6</volume>
<institution>Brown University,</institution>
<location>Richmond, USA.</location>
<marker>forthcoming, 1995</marker>
<rawString>Mark Johnson. forthcoming. Constraint-based Natural Language Parsing. Brown University, Richmond, USA. Draft of 6 August 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guido Minnen</author>
<author>Dale Gerdemann</author>
<author>Erhard Hinrichs</author>
</authors>
<title>Direct Automated Inversion of Logic Grammars.</title>
<date>1996</date>
<journal>New Generation Computing</journal>
<volume>14</volume>
<contexts>
<context position="3591" citStr="Minnen et al., 1996" startWordPosition="533" endWordPosition="536">ke, e.g., restriction (Shieber, 1985), to weaken filtering and a subsumption check to discard redundant results. It is shown that for a large class of grammars the subsumption check which often influences processing efficiency rather dramatically can be eliminated through fine-tuning of the magic predicates derived for a particular grammar after applying an abstraction function in an off-line fashion. Unfolding can be used to eliminate superfluous filtering steps. Given an off-line optimization of the order in which the right-hand side categories in the rules of a logic grammar are processed (Minnen et al., 1996) the resulting processing behavior can be considered a generalization of the head corner generation approach (Shieber et al., 1990): Without the need to rely on notions such as semantic head and chain rule, a head corner behavior can be mimicked in a strict bottom-up fashion. 247 2 Definite Clause Characterization of Filtering Many approaches focus on exploiting specific knowledge about grammars and/or the computational task(s) that one is using them for by making filtering explicit and extending the processing strategy such that this information can be made effective. In generation, examples </context>
<context position="7865" citStr="Minnen et al., 1996" startWordPosition="1211" endWordPosition="1214"> the query corresponding to the generation of the s &amp;quot;John buys Mary a book&amp;quot; leads to the following seed: magic_s(PO,P,finite,buys(john,a(book),mary)). The seed constitutes a representation of the initial bindings provided by the query that is used by the magic predicates to derive guards. Note that the creation of the seed can be delayed until run-time, i.e., the grammar does not need to be recompiled for every possible query. 2.2 Example Magic compilation is illustrated on the basis of the simple logic grammar extract in figure 1. This grammar has been optimized automatically for generation (Minnen et al., 1996): The right-hand sides of the rules are reordered such that a simple left-to-right evaluation order constitutes the optimal evaluation order. With this grammar a simple top-down generation strategy does not terminate as a result of the head recursion in rule 3. It is necessary to use 248 sentence (PO , P , decl (SSem) ) : (5) np (PO ,P ,NPSem) : - ,buys(S,D,I)). (PO , P , f inite ,SSem) . pn (PO , P ,NPSem) s (PO ,P ,VForm,SSem) : - (6) np (PO ,P ,NPSem) vp (P1,P , VForm, [CSeml ,SSem) • det (PO , P1 , NSem, NPSem) , np (PO , P1 , CSem) , n (P1 , P ,NSem) . vp (PO , P , VForm,Args ,SSem) : - (</context>
<context position="27159" citStr="Minnen et al. (1996)" startWordPosition="4104" endWordPosition="4107"> is too unspecific. This is not problematic as long as this nondeterminism will eventually disappear, e.g., by combining these solutions with the solutions to cat_3. The problem arises as a result of the fact that these solutions lead to identical filters for the evaluation of the cat_3 literal, i.e., the solutions to cat_2 do not uniquely determine cat_3. Also with respect to the dependency constraint an optimization of the rules in the grammar is important. Through reordering the right-hand sides of the rules in the grammar the amount of nondeterminism can be drastically reduced as shown in Minnen et al. (1996). This way of following the intended semantic dependencies the dependency constraint is satisfied automatically for a large class of grammars. 5 Concluding Remarks Magic evaluation constitutes an interesting combination of the advantages of top-down and bottomup evaluation. It allows bottom-up filtering that achieves a goal-directedness which corresponds to dynamic top-down evaluation with abstraction and subsumption checking. For a large class of grammars in effect identical operations can be performed offline thereby allowing for more efficient processing. Furthermore, it enables a reduction</context>
</contexts>
<marker>Minnen, Gerdemann, Hinrichs, 1996</marker>
<rawString>Guido Minnen, Dale Gerdemann, and Erhard Hinrichs. 1996. Direct Automated Inversion of Logic Grammars. New Generation Computing 14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Stuart Shieber</author>
</authors>
<title>Prolog and Natural Language Analysis.</title>
<date>1987</date>
<booktitle>CSLI Lecture Notes, No. 10. Center for the Study of Language and Information,</booktitle>
<location>Chicago, USA.</location>
<marker>Pereira, Shieber, 1987</marker>
<rawString>Fernando Pereira and Stuart Shieber. 1987. Prolog and Natural Language Analysis. CSLI Lecture Notes, No. 10. Center for the Study of Language and Information, Chicago, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alberto Pettorossi</author>
<author>Maurizio Proietti</author>
</authors>
<title>Transformations of Logic Programs: Foundations and Techniques.</title>
<date>1994</date>
<journal>Journal of Logic Programming</journal>
<marker>Pettorossi, Proietti, 1994</marker>
<rawString>Alberto Pettorossi and Maurizio Proietti. 1994. Transformations of Logic Programs: Foundations and Techniques. Journal of Logic Programming 19/20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raghu Ramakrishnan</author>
<author>Divesh Srivastava</author>
<author>S Sudarshan</author>
</authors>
<title>Efficient Bottom-up Evaluation of Logic Programs.</title>
<date>1992</date>
<booktitle>The State of the Art in Computer Systems and Software Engineering.</booktitle>
<editor>In Vandewalle, editor,</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="1691" citStr="Ramakrishnan et al., 1992" startWordPosition="245" endWordPosition="248">ledge about grammars and/or the computational task(s) that one is using them for. At the same time it often remains unclear how these optimizations relate to each other and what they actually mean. In this paper I show how starting from a definite clause characterization of filtering derived automatically from a logic grammar using Magic compilation, filter optimizations can be performed in a processor independent and logically clean fashion. Magic (templates) is a general compilation technique for efficient bottom-up evaluation of logic programs developed in the deductive database community (Ramakrishnan et al., 1992). Given a logic program, Magic produces a new program in which the filtering as normally resulting from top-down evaluation is explicitly characterized through, so-called, *url: http://www.sfs.nphil.uni-tuebingenrminnen magic predicates, which produce variable bindings for filtering when evaluated bottom-up. The original rules of the program are extended such that these bindings can be made effective. As a result of the definite clause characterization of filtering, Magic brings filtering into the logic underlying the grammar. I discuss two filter optimizations. These optimizations are directi</context>
<context position="5282" citStr="Ramakrishnan et al. (1992)" startWordPosition="791" endWordPosition="794">tering into the logic underlying the grammar it is possible to show in a perspicuous and logically clean way how and why filtering can be optimized in a particular fashion and how various approaches relate to each other. 2.1 Magic Compilation Magic makes filtering explicit through characterizing it as definite clauses. Intuitively understood, filtering is reversed as binding information that normally becomes available as a result of top-down evaluation is derived by bottom-up evaluation of the definite clause characterization of filtering. The following is the basic Magic algorithm taken from Ramakrishnan et al. (1992). Let P be a program and g(Z) a query on the program. We construct a new program Pmg. Initially Pmg is empty. 1. Create a new predicate magic_p for each predicate p in P. The arity is that of p. 2. For each rule in P, add the modified version of the rule to Pmg. If rule r has head, say, p(i), the modified version is obtained by adding the literal magic_p(i) to the body. 3. For each rule r in P with head, say, p(i), and for each literal gi(ii) in its body, add a magic rule to Pmg. The head is magie_gi(). The body contains the literal magic_p(1), and all the literals that precede gi in the rule.</context>
<context position="22339" citStr="Ramakrishnan et al., 1992" startWordPosition="3464" endWordPosition="3467">h the resulting grammar can be compared best with head corner generation (Shieber et al., 1990) (see next section). 3.3 Example After cycle removal, incorporating relevant indexing and the collapsing of redundant magic predicates the magic-compiled grammar from figure 2 looks as displayed in figure 5. Figure 6 shows the chart resulting from generation of the sentence &amp;quot;John buys Mary a book&amp;quot; .4 The seed is identical to the one used for the example in the previous section. The facts in the chart resulted from not-so-naive bottom-up evaluation: semi-naive evaluation without subsumption checking (Ramakrishnan et al., 1992). The resulting processing behavior is similar to the behavior that would result from head corner generation except that the different filtering steps are performed in a bottom-up fashion. The head corner approach jumps top-down from pivot to pivot in order to satisfy its assumptions concerning the flow of semantic information, i.e., semantic chaining, and subsequently generates starting from the semantic head in a bottom-up fashion. In the example, the seed is used without any delay to apply the base case of the vp-procedure, thereby jumping over all intermediate chain and non-chain rules. In</context>
</contexts>
<marker>Ramakrishnan, Srivastava, Sudarshan, 1992</marker>
<rawString>Raghu Ramakrishnan, Divesh Srivastava, and S. Sudarshan. 1992. Efficient Bottom-up Evaluation of Logic Programs. In Vandewalle, editor, The State of the Art in Computer Systems and Software Engineering. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taisuke Sato</author>
<author>Hisao Tamaki</author>
</authors>
<title>Enumeration of Success Patterns in Logic Programs.</title>
<date>1984</date>
<journal>Theoretical Computer Sience</journal>
<volume>34</volume>
<contexts>
<context position="17768" citStr="Sato and Tamaki, 1984" startWordPosition="2701" endWordPosition="2704">s constructed on the is to be matched against the subcategorization list basis of an abstract seed, i.e., a seed adorned with of, e.g., the lexical entry for &amp;quot;buys&amp;quot;. Though this a specification of which arguments are to be con- rule is not cyclic, it becomes cyclic upon off-line absidered bound. Note that an abstract seed can be straction: derived from the user-specified abstract query. Only magic_vp(VForm,(CSemW,SSem):- the magic part of the abstract unfolding tree is rep- magic_vp(VFormJCSem20,SSem). resented. Through trimming this magic rule, e.g., given a ABSTRACT SEED bounded term depth (Sato and Tamaki, 1984) or a magic-sentence(SSem),••• restrictor (Shieber, 1985), constructing an abstract ...4— magic_s(finite,SSem),... unfolding tree reveals the fact that a cycle results from the magic rule. This information can then be used to discard the culprit. 3.1.2 Indexing Removing the direct or indirect cycles from the magic part of the compiled grammar does eliminate the necessity of subsumption checking in many cases. However, consider the magic rules 14 and 15 in figure 2. Rule 15 is more general than rule 14. Without subsumption checking this leads to spurious ambiguity: Both rules produce a magic fa</context>
</contexts>
<marker>Sato, Tamaki, 1984</marker>
<rawString>Taisuke Sato and Hisao Tamaki. 1984. Enumeration of Success Patterns in Logic Programs. Theoretical Computer Sience 34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
<author>Gertjan van Noord</author>
<author>Robert Moore</author>
<author>Fernando Pereira</author>
</authors>
<date>1990</date>
<journal>Semantic Headdriven Generation. Computational Linguistics</journal>
<volume>16</volume>
<marker>Shieber, van Noord, Moore, Pereira, 1990</marker>
<rawString>Stuart Shieber, Gertjan van Noord, Robert Moore, and Fernando Pereira. 1990. Semantic Headdriven Generation. Computational Linguistics 16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
</authors>
<title>Using Restriction to Extend Parsing Algorithms for Complex Feature-based Formalisms.</title>
<date>1985</date>
<booktitle>In Proceedings of the 23rd Annual Meeting Association for Computational Linguistics,</booktitle>
<location>Chicago, USA.</location>
<contexts>
<context position="3008" citStr="Shieber, 1985" startWordPosition="440" endWordPosition="441">s, though, they are presented merely on the basis of examples of generation. Magic compilation does not limit the information that can be used for filtering. This can lead to nontermination as the tree fragments enumerated in bottom-up evaluation of magic compiled grammars are connected (Johnson, forthcoming). More specifically, &apos;magic generation&apos; falls prey to non-termination in the face of head recursion, i.e., the generation analog of left recursion in parsing. This necessitates a dynamic processing strategy, i.e., memoization, extended with an abstraction function like, e.g., restriction (Shieber, 1985), to weaken filtering and a subsumption check to discard redundant results. It is shown that for a large class of grammars the subsumption check which often influences processing efficiency rather dramatically can be eliminated through fine-tuning of the magic predicates derived for a particular grammar after applying an abstraction function in an off-line fashion. Unfolding can be used to eliminate superfluous filtering steps. Given an off-line optimization of the order in which the right-hand side categories in the rules of a logic grammar are processed (Minnen et al., 1996) the resulting pr</context>
<context position="16339" citStr="Shieber, 1985" startWordPosition="2478" endWordPosition="2479">ust like top-down evaluation of the original gram- postpone abstraction until run-time, but can trim mar bottom-up evaluation of its magic compiled ver- the magic predicates off-line. One can consider this sion falls prey to non-termination in the face of head as bringing abstraction into the logic as the definite recursion. It is however possible to eliminate the clause representation of filtering is weakened such subsumption check through fine-tuning the magic that only a mild form of connectedness results which predicates derived for a particular grammar in an does not affect completeness (Shieber, 1985). Conoff-line fashion. In order to illustrate how the magic sider the following magic rule: predicates can be adapted such that the subsump- magic_vp(VForm,[0enOrgsJ,SSem):- tion check can be eliminated it is necessary to take a magic_vp(VForm,Args,SSem). closer look at the relation between the magic pred- This is the rule that is derived from the headicates and the facts they derive. In figure 4 the re- recursive vp rule when the partially specified sublation between the magic predicates for the example categorization list is considered as filtering informagrammar is represented by an unfoldi</context>
<context position="17825" citStr="Shieber, 1985" startWordPosition="2709" endWordPosition="2710">on list basis of an abstract seed, i.e., a seed adorned with of, e.g., the lexical entry for &amp;quot;buys&amp;quot;. Though this a specification of which arguments are to be con- rule is not cyclic, it becomes cyclic upon off-line absidered bound. Note that an abstract seed can be straction: derived from the user-specified abstract query. Only magic_vp(VForm,(CSemW,SSem):- the magic part of the abstract unfolding tree is rep- magic_vp(VFormJCSem20,SSem). resented. Through trimming this magic rule, e.g., given a ABSTRACT SEED bounded term depth (Sato and Tamaki, 1984) or a magic-sentence(SSem),••• restrictor (Shieber, 1985), constructing an abstract ...4— magic_s(finite,SSem),... unfolding tree reveals the fact that a cycle results from the magic rule. This information can then be used to discard the culprit. 3.1.2 Indexing Removing the direct or indirect cycles from the magic part of the compiled grammar does eliminate the necessity of subsumption checking in many cases. However, consider the magic rules 14 and 15 in figure 2. Rule 15 is more general than rule 14. Without subsumption checking this leads to spurious ambiguity: Both rules produce a magic fact with which a subject np can be built. A possible solut</context>
</contexts>
<marker>Shieber, 1985</marker>
<rawString>Stuart Shieber. 1985. Using Restriction to Extend Parsing Algorithms for Complex Feature-based Formalisms. In Proceedings of the 23rd Annual Meeting Association for Computational Linguistics, Chicago, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
</authors>
<title>A Uniform Architecture for Parsing and Generation.</title>
<date>1988</date>
<booktitle>In Proceedings of the 12th Conference on Computational Linguistics,</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="4377" citStr="Shieber, 1988" startWordPosition="657" endWordPosition="658">h as semantic head and chain rule, a head corner behavior can be mimicked in a strict bottom-up fashion. 247 2 Definite Clause Characterization of Filtering Many approaches focus on exploiting specific knowledge about grammars and/or the computational task(s) that one is using them for by making filtering explicit and extending the processing strategy such that this information can be made effective. In generation, examples of such extended processing strategies are head corner generation with its semantic linking (Shieber et al., 1990) or bottom-up (Earley) generation with a semantic filter (Shieber, 1988). Even though these approaches often accomplish considerable improvements with respect to efficiency or termination behavior, it remains unclear how these optimizations relate to each other and what comprises the logic behind these specialized forms of filtering. By bringing filtering into the logic underlying the grammar it is possible to show in a perspicuous and logically clean way how and why filtering can be optimized in a particular fashion and how various approaches relate to each other. 2.1 Magic Compilation Magic makes filtering explicit through characterizing it as definite clauses. </context>
<context position="9346" citStr="Shieber, 1988" startWordPosition="1489" endWordPosition="1490">recursive grammar. memoization extended with an abstraction function and a subsumption check. Strict bottom-up generation is not attractive either as it is extremely inefficient: One is forced to generate all possible natural language expressions licensed by the grammar and subsequently check them against the start category. It is possible to make the process more efficient through excluding specific lexical entries with a semantic filter. The use of such a semantic filter in bottom-up evaluation requires the grammar to obey the semantic monotonicity constraint in order to ensure completeness(Shieber, 1988) (see below). The &apos;magic-compiled grammar&apos; in figure 2 is the result of applying the algorithm in the previous section to the head-recursive example grammar and subsequently performing two optimizations (Beeni and Ramakrishnan, 1991): All (calls to) magic predicates corresponding to lexical entries are removed. Furthermore, data-flow analysis is used to fine-tune the magic predicates for the specific processing task at hand, i.e., generation.&apos; Given a user-specified abstract query, i.e., a specification of the intended input (Been i and Ramakrishnan, 1991) those arguments which are not bound a</context>
<context position="12161" citStr="Shieber (1988)" startWordPosition="1963" endWordPosition="1964">ified version of rule 2 (in addition to the facts 12 and 10). This, however, is not represented in order to keep the figure clear. Dotted lines are used to represent when &apos;normal&apos; facts are combined with magic facts to derive new magic facts. As can be reconstructed from the numbering of the facts in figure 3 the resulting processing behavior is identical to the behavior that would result from Earley generation as in Gerdemann (1991) except that the different filtering steps are performed in a bottom-up fashion. In order to obtain a generator similar to the bottom-up generator as described in Shieber (1988) the compilation process can be modified such that only lexical entries are extended with magic literals. Just like in case of Shieber&apos;s bottom-up generator, bottom-up evaluation of magic-compiled grammars produced with this Magic variant is only guaranteed to be complete in case the original grammar obeys the semantic monotonicity constraint. 2The numbering of the facts corresponds to the order in which they are derived. A number of lexical entries have been added to the example grammar. The facts corresponding to lexical entries are ignored. For expository reasons the phonology and semantics</context>
</contexts>
<marker>Shieber, 1988</marker>
<rawString>Stuart Shieber. 1988. A Uniform Architecture for Parsing and Generation. In Proceedings of the 12th Conference on Computational Linguistics, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
</authors>
<title>Parsing and Type Inference for Natural and Computer Languages.</title>
<date>1989</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University, USA.</institution>
<contexts>
<context position="25576" citStr="Shieber, 1989" startWordPosition="3871" endWordPosition="3872">ulting processing behavior would not have fallen out so nicely: In this case it leads either to an intermediate filtering step for the non-chaining sentence rule or to the addition of the literal corresponding to the subject np to all chain and non-chain rules along the path to the semantic head. Even when cycles are removed from the magic part of a compiled grammar and indexing is used to avoid spurious ambiguities as discussed in the previous section, subsumption checking can not always be eliminated. The grammar must be finitely ambiguous, i.e., fulfill the off-line parsability constraint (Shieber, 1989). Furthermore, the grammar is required to obey what I refer to as the dependency constraint: When a particular right-hand side literal can not be evaluated deterministically, the results of its evaluation must uniquely determine the remainder of the right-hand side of the rule in which it appears. Figure 7 gives a schematic example of a grammar that does not obey the dependency constraint. Given cat_1(...):- magic_cat_1(Filter), cat_2(Filter,Dependency,...), cat_3(Dependency). magic_cat_3(Filter):- magic_cat_1(Filter), cat_2(Filter,Dependency,...). cat_2(property_1,property_2,...). cat_2(prope</context>
</contexts>
<marker>Shieber, 1989</marker>
<rawString>Stuart Shieber. 1989. Parsing and Type Inference for Natural and Computer Languages. Ph.D. thesis, Stanford University, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hisao Tamaki</author>
<author>Taisuke Sato</author>
</authors>
<title>Unfold/Fold Transformation of Logic Programs.</title>
<date>1984</date>
<booktitle>In Proceedings of the 2nd International Conference on Logic Programming,</booktitle>
<location>Uppsala, Sweden.</location>
<contexts>
<context position="15409" citStr="Tamaki and Sato, 1984" startWordPosition="2331" endWordPosition="2334">terizing filtering by a definite grammar. There is however no reason to keep this clause representation Magic brings filtering inside of rule in the magic-compiled grammar. It influences the logic underlying the grammar. This allows it to neither the efficiency of processing with the grambe optimized in a processor independent and logi- mar nor the completeness of the evaluation process. cally clean fashion. I discuss two possible filter opti- 3.1.1 Off-line Abstraction mizations based on a program transformation tech- Finding these types of cycles in the magic part of nique called unfolding (Tamaki and Sato, 1984) also the compiled grammar is in general undecidable. It referred to as partial execution, e.g., in Pereira and is possible though to &apos;trim&apos; the magic predicates by Shieber (1987) . applying an abstraction function. As a result of the 3.1 Subsumption Checking explicit representation of filtering we do not need to Just like top-down evaluation of the original gram- postpone abstraction until run-time, but can trim mar bottom-up evaluation of its magic compiled ver- the magic predicates off-line. One can consider this sion falls prey to non-termination in the face of head as bringing abstraction</context>
</contexts>
<marker>Tamaki, Sato, 1984</marker>
<rawString>Hisao Tamaki and Taisuke Sato. 1984. Unfold/Fold Transformation of Logic Programs. In Proceedings of the 2nd International Conference on Logic Programming, Uppsala, Sweden.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>