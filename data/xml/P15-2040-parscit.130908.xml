<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.8436385">
KLcpos3 – a Language Similarity Measure
for Delexicalized Parser Transfer
</title>
<author confidence="0.989266">
Rudolf Rosa and Zdenˇek ˇZabokrtsk´y
</author>
<affiliation confidence="0.967272">
Charles University in Prague, Faculty of Mathematics and Physics
Institute of Formal and Applied Linguistics
</affiliation>
<address confidence="0.752934">
Malostransk´e n´amˇest´ı 25, Prague, Czech Republic
</address>
<email confidence="0.994741">
{rosa, zabokrtsky}@ufal.mff.cuni.cz
</email>
<sectionHeader confidence="0.993688" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999957076923077">
We present KLcpos3, a language similar-
ity measure based on Kullback-Leibler di-
vergence of coarse part-of-speech tag tri-
gram distributions in tagged corpora. It
has been designed for multilingual delexi-
calized parsing, both for source treebank
selection in single-source parser trans-
fer, and for source treebank weighting in
multi-source transfer. In the selection task,
KLcpos3 identifies the best source treebank
in 8 out of 18 cases. In the weighting task,
it brings +4.5% UAS absolute, compared
to unweighted parse tree combination.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999939615384615">
The approach of delexicalized dependency parser
transfer is to train a parser on a treebank for a
source language (src), using only non-lexical fea-
tures, most notably part-of-speech (POS) tags, and
to apply that parser to POS-tagged sentences of a
target language (tgt) to obtain dependency parse
trees. Delexicalized transfer yields worse results
than a supervised lexicalized parser trained on a
target language treebank. However, for languages
with no treebanks available, it may be useful to
obtain at least a lower-quality parse tree for tasks
such as information retrieval.
Usually, multiple source treebanks are avail-
able, and it is non-trivial to select the best one for a
given target language. As a solution, we present a
language similarity measure based on KL diver-
gence (Kullback and Leibler, 1951) of distribu-
tions of coarse POS tag trigrams in POS-tagged
corpora, which we call KLcpos3. The measure has
been designed and tuned specifically for multilin-
gual delexicalized parser transfer, and it often suc-
ceeds in selecting the best source treebank in a
single-source setting, as well as in appropriately
weighting the source treebanks by similarity to the
target language in a multi-source parse tree com-
bination approach.
</bodyText>
<sectionHeader confidence="0.99978" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99926327027027">
Delexicalized parser transfer was conceived by
Zeman and Resnik (2008), who also introduced
two important preprocessing steps – mapping
treebank-specific POS tagsets to a common set
using Interset (Zeman, 2008), and harmonizing
treebank annotation styles into a common style,
which later developed into the HamleDT harmo-
nized treebank collection (Zeman et al., 2012).
McDonald et al. (2011) applied delexicalized
transfer in a setting with multiple source treebanks
available, finding that the problem of selecting the
best source treebank without access to a target lan-
guage treebank for evaluation is non-trivial. They
combined all source treebanks by concatenating
them but noted that this yields worse results than
using only the best source treebank.
An alternative is the (monolingual) parse tree
combination method of Sagae and Lavie (2006),
who apply several independent parsers to the in-
put sentence and combine the resulting parse trees
using a maximum spanning tree algorithm. Sur-
deanu and Manning (2010) enrich tree combi-
nation with weighting, assigning each parser a
weight based on its Unlabelled Attachment Score
(UAS). In our work, we introduce an extension of
this method to a crosslingual setting by combining
parsers for different languages and using source-
target language similarity to weight them.
Several authors (Naseem et al., 2012; Søgaard
and Wulff, 2012; T¨ackstr¨om et al., 2013b) em-
ployed WALS (Dryer and Haspelmath, 2013)
to estimate source-target language similarity for
delexicalized transfer, focusing on genealogy dis-
tance and word-order features. Søgaard and Wulff
(2012) also introduced weighting into the tree-
bank concatenation approach, using a POS n-
gram model trained on a target-language corpus
</bodyText>
<page confidence="0.950141">
243
</page>
<bodyText confidence="0.961488484848485">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 243–249,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
to weight source sentences in a weighted percep-
tron learning scenario (Cavallanti et al., 2010). KL
divergence (Kullback and Leibler, 1951) of POS
tag distributions, as well as several other measures,
was used by Plank and Van Noord (2011) to esti-
mate monolingual domain similarity.
As is quite common in parsing papers, includ-
ing those dealing with semi-supervised and unsu-
pervised parsing, we use gold POS tags in all our
experiments. This enables us to evaluate the ef-
fectiveness of our parsing method alone, not influ-
enced by errors stemming from the POS tagging.
Based on the published results, it seems to be con-
siderably easier to induce POS tags than syntactic
structure for under-resourced languages, as there
are several high-performance weakly-supervised
POS taggers. Das and Petrov (2011) report an av-
erage accuracy of 83% using word-aligned texts,
compared to 97% reached by a supervised tag-
ger. T¨ackstr¨om et al. (2013a) further improve this
to 89% by leveraging Wiktionary. For some lan-
guages, there are even less resources available;
Agi´c et al. (2015b) were able to reach accuracies
around 70% by using partial or full Bible transla-
tion. Our methods could thus be applied even in
a more realistic scenario, where gold POS tags are
not available for the target text, by using a weakly-
supervised POS tagger. We intend to evaluate the
performance of our approach in such a setting in
future.
</bodyText>
<sectionHeader confidence="0.995592" genericHeader="method">
3 Delexicalized Parser Transfer
</sectionHeader>
<bodyText confidence="0.999744857142857">
Throughout this work, we use MSTperl (Rosa,
2015b), an implementation of the unlabelled
single-best MSTParser of McDonald et al.
(2005b), with first-order features and non-
projective parsing, trained using 3 iterations of
MIRA (Crammer and Singer, 2003).1
Our delexicalized feature set is based on the set
of McDonald et al. (2005a) with lexical features
removed. It consists of combinations of signed
edge length (distance of head and parent, bucketed
for values above 4 and for values above 10) with
POS tag of the head, dependent, their neighbours,
and all nodes between them.2 We use the Univer-
sal POS Tagset (UPOS) of Petrov et al. (2012).
</bodyText>
<footnote confidence="0.8744048">
1Note that while our approach does not depend in princi-
ple on the actual parser used, our results and conclusions may
not be valid for other parsers.
2The feature set, as well as scripts and configuration files
for the presented experiments, are available in (Rosa, 2015a).
</footnote>
<subsectionHeader confidence="0.999078">
3.1 Single-source Delexicalized Transfer
</subsectionHeader>
<bodyText confidence="0.9999798">
In the single-source parser transfer, the delexical-
ized parser is trained on a single source treebank,
and applied to the target corpus. The problem thus
reduces to selecting a source treebank that will
lead to a high performance on the target language.
</bodyText>
<subsectionHeader confidence="0.999811">
3.2 Multi-source Delexicalized Transfer
</subsectionHeader>
<bodyText confidence="0.999565333333333">
In our work, we extend the monolingual parse tree
combination method to a multi-source crosslin-
gual delexicalized parser transfer setting:
</bodyText>
<listItem confidence="0.9896168125">
1. Train a delexicalized parser on each source
treebank.
2. Apply each of the parsers to the target sen-
tence, obtaining a set of parse trees.
3. Construct a weighted directed graph as a
complete graph over all tokens of the target
sentence, where each edge is assigned a score
equal to the number of parse trees in which it
appears (each parse tree contributes by either
0 or 1 to the edge score). In the weighted vari-
ant of the method, the contribution of each
parse tree is multiplied by its weight.
4. Find the final dependency parse tree as the
maximum spanning tree over the graph, us-
ing the algorithm of Chu and Liu (1965) and
Edmonds (1967).
</listItem>
<sectionHeader confidence="0.531162" genericHeader="method">
4 KLcpos3 Language Similarity
</sectionHeader>
<bodyText confidence="0.981409714285714">
We introduce KLcpos3, a language similarity mea-
sure based on distributions of coarse POS tags in
source and target POS-tagged corpora. This is mo-
tivated by the fact that POS tags constitute a key
feature for delexicalized parsing.
The distributions are estimated as frequencies of
UPOS trigrams3 in the treebank training sections:
</bodyText>
<equation confidence="0.907437">
f(cposz−1, cposz, cposz+1) =
count(cposz−1, cposz, cposz+1)
= EVcposa,b,c count(cposa, cposb, cposz) ; (1)
</equation>
<bodyText confidence="0.950303428571429">
we use a special value for cposz−1 or cposz+1 if
cposz appears at sentence beginning or end.
We then apply the Kullback-Leibler divergence
3Bigrams and tetragrams performed comparably on the
weighting task, but worse on the selection task. Using more
fine-grained POS tags led to worse results as fine-grained fea-
tures tend to be less shared across languages.
</bodyText>
<page confidence="0.960503">
244
</page>
<equation confidence="0.68514375">
DKL(tgt||src) to compute language similarity:4
KLcpos3(tgt, src) =
ftgt(cpos3) · log ftgt(cpos3)
fsrc(cpos3) , (2)
</equation>
<table confidence="0.587044">
Measure Avg SD Best
KL−4 51.0 16.7 6
cpos3(tgt, src) 50.6 17.4 4
KL−4 49.6 18.0 2
cpos3(src, tgt) 49.0 17.7 1
JS−4cpos3(tgt, src)
coscpos3(tgt, src)
�=
dcpos3Etgt
</table>
<bodyText confidence="0.999921666666667">
where cpos3 is a coarse POS tag trigram. For
the KL divergence to be well-defined, we set the
source count of each unseen trigram to 1.
</bodyText>
<subsectionHeader confidence="0.770245">
4.1 KLcpos3 for Source Selection
</subsectionHeader>
<bodyText confidence="0.99969825">
For the single-source parser transfer, we compute
KLcpos3 distance of the target corpus to each of
the source treebanks and choose the closest source
treebank to use for the transfer.
</bodyText>
<subsectionHeader confidence="0.347212">
4.2 KL−4os3 for Source Weighting
</subsectionHeader>
<bodyText confidence="0.941740125">
cp
To convert KLcpos3 from a negative measure of
language similarity to a positive source parser
weight for the multi-source tree combination
method, we take the fourth power of its inverted
value.5 The parse tree produced by each source
parser is then weighted by KL−4
cpos3(tgt, src).
</bodyText>
<sectionHeader confidence="0.995067" genericHeader="method">
5 Dataset
</sectionHeader>
<bodyText confidence="0.998081625">
We carry out our experiments using HamleDT 2.0
of Rosa et al. (2014), a collection of 30 treebanks
converted into Universal Stanford Dependencies
(de Marneffe et al., 2014), with POS tags con-
verted into UPOS; we use gold-standard POS tags
in all experiments. We use the treebank training
sections for parser training and language similarity
estimation, and the test sections for evaluation.6
</bodyText>
<subsectionHeader confidence="0.995727">
5.1 Tuning
</subsectionHeader>
<bodyText confidence="0.866249052631579">
To avoid overfitting the exact definition of KLcpos3
and KL −4os3 to the 30 treebanks, we used only 12
cp
4The KL divergence is non-symmetric; DKL(P||Q) ex-
presses the amount of information lost when a distribution Q
is used to approximate the true distribution P. Thus, in our
setting, we use DKL(tgt||src), as we try to minimize the loss
of using a src parser as an approximation of a tgt parser.
5A high value of the exponent strongly promotes the most
similar source language, giving minimal power to the other
languages, which is good if there is a very similar source lan-
guage. A low value enables combining information from a
larger number of source languages. We chose a compromise
value of 4 based on performance on the development data.
6Contrary to the motivation, we do not evaluate our
method on truly underresourced languages, since automatic
intrinsic evaluation is not possible on languages without tree-
banks. Still, e.g., Bengali and Telugu can be considered low-
resourced, since their treebanks are very small.
</bodyText>
<tableCaption confidence="0.901111">
Table 1: Weighted multi-source transfer using var-
</tableCaption>
<bodyText confidence="0.5221082">
ious similarity measures. Evaluation using aver-
age UAS on the development set.
Avg = Average UAS.
SD = Standard sample deviation of UAS, serving as an indi-
cation of robustness of the measure.
</bodyText>
<subsectionHeader confidence="0.511564">
Best = Number of targets for which the measure scored best.
</subsectionHeader>
<bodyText confidence="0.999775266666667">
development treebanks for hyperparameter tuning:
ar, bg, ca, el, es, et, fa, fi, hi, hu, it, ja.7
Table 1 contains evaluation of several lan-
guage similarity measures considered in the tuning
phase, applied to weighted multi-source transfer
and evaluated using average UAS on the develop-
ment set. We evaluated KL divergences computed
in both directions, as well as Jenses-Shannon di-
vergence (Lee, 2001) and cosine similarity. Based
on the results, KL−4 cpos3 was selected, as it per-
formed best in all aspects.
Once the hyperparameters were fixed, we ap-
plied the parser transfer methods to the full set of
30 treebanks; our final evaluation is based on the
results on the 18 test treebanks as targets.
</bodyText>
<subsectionHeader confidence="0.99339">
5.2 Other datasets
</subsectionHeader>
<bodyText confidence="0.999966857142857">
Additionally, we also report preliminary results on
the Prague style conversion of HamleDT, which
loosely follows the style of the Prague Depen-
dency Treebank of B¨ohmov´a et al. (2003), and on
the subset of CoNLL 2006 and 2007 shared tasks
(Buchholz and Marsi, 2006; Nilsson et al., 2007)
that was used by McDonald et al. (2011).8
</bodyText>
<sectionHeader confidence="0.816612" genericHeader="method">
6 Evaluation
6.1 Results
</sectionHeader>
<bodyText confidence="0.998915">
Table 2 contains the results of our methods both on
the test languages and the development languages.
</bodyText>
<footnote confidence="0.5634696">
7We tuned the choice of the similarity measure, POS n-
gram length, and the way of turning KLcpos3 into KL−4
cpos3.
To tune our method to perform well in many different situa-
tions, we chose the development set to contain both smaller
and larger treebanks, a pair of very close languages (ca, es), a
very solitary language (ja), multiple members of several lan-
guage families (Uralic, Romance), and both primarily left-
branching (bg, el) and right-branching (ar, ja) languages.
8The CoNLL subset is: da, de, el, en, es, it, nl, pt, sv.
</footnote>
<page confidence="0.996774">
245
</page>
<bodyText confidence="0.999975555555556">
For each target language, we used all remaining 29
source languages for training (in the single-source
method, only one of them is selected and applied).
Our baseline is the treebank concatenation
method of McDonald et al. (2011), i.e., a single
delexicalized parser trained on the concatenation
of the 29 source treebanks.
As an upper bound,9 we report the results of
the oracle single-source delexicalized transfer: for
each target language, the oracle source parser is
the one that achieves the highest UAS on the target
treebank test section.10 For space reasons, we do
not include results of a higher upper bound of a su-
pervised delexicalized parser (trained on the target
treebank), which has an average UAS of 68.5%. It
was not surpassed by our methods for any target
language, although it was reached for Telugu, and
approached within 5% for Czech and Latin.
</bodyText>
<subsectionHeader confidence="0.94126">
6.2 Discussion
</subsectionHeader>
<bodyText confidence="0.999989384615385">
The results show that KLcpos3 performs well
both in the selection task and in the weighting
task, as both the single-source and the weighted
multi-source transfer methods outperform the un-
weighted tree combination on average, as well as
the treebank concatenation baseline. In 8 of 18
cases, KLcpos3 is able to correctly identify the ora-
cle source treebank for the single-source approach.
In two of these cases, weighted tree combination
further improves upon the result of the single-
source transfer, i.e., surpasses the oracle; in the
remaining 6 cases, it performs identically to the
single-source method. This proves KLcpos3 to be a
successful language similarity measure for delex-
icalized parser transfer, and the weighted multi-
source transfer to be a better performing approach
than the single-source transfer.
The weighted tree combination is better than its
unweighted variant only for half of the target lan-
guages, but it is more stable, as indicated by its
lower standard deviation, and achieves an average
UAS higher by 4.5% absolute. The unweighted
tree combination, as well as treebank concatena-
tion, perform especially poorly for English, Ger-
man, Tamil, and Turkish, which are rich in deter-
miners, unlike the rest of the treebanks;11 there-
</bodyText>
<footnote confidence="0.985956428571429">
9This is a hard upper-bound for the single-source transfer,
but can be surpassed by the multi-source transfer.
10We do not report the matrix of all source/target combina-
tion results, as this amounts to 870 numbers.
11In the treebanks for these four languages, determiners
constitute around 5-10% of all tokens, while most other tree-
banks contain no determiners at all; in some cases, this is
</footnote>
<table confidence="0.999945119047619">
Tgt TB Oracle Single-src Multi-src
lang conc del trans KL x1 xw
bn 61.0 te 66.7 0.5 te 66.7 63.2 66.7
cs 60.5 sk 65.8 0.3 sk 65.8 60.4 65.8
da 56.2 en 55.4 0.5 sl 42.1 54.4 50.3
de 12.6 en 56.8 0.7 en 56.8 27.6 56.8
en 12.3 de 42.6 0.8 de 42.6 21.1 42.6
eu 41.2 da 42.1 0.7 tr 29.1 40.8 30.6
grc 43.2 et 42.2 1.0 sl 34.0 44.7 42.6
la 38.1 grc 40.3 1.2 cs 35.0 40.3 39.7
nl 55.0 da 57.9 0.7 da 57.9 56.2 58.7
pt 62.8 en 64.2 0.2 es 62.7 67.2 62.7
ro 44.2 it 66.4 1.6 la 30.8 51.2 50.0
ru 55.5 sk 57.7 0.9 la 40.4 57.8 57.2
sk 52.2 cs 61.7 0.2 sl 58.4 59.6 58.4
sl 45.9 sk 53.9 0.2 sk 53.9 47.1 53.9
sv 45.4 de 61.6 0.6 da 49.8 52.3 50.8
ta 27.9 hi 53.5 1.1 tr 31.1 28.0 40.0
te 67.8 bn 77.4 0.4 bn 77.4 68.7 77.4
tr 18.8 ta 40.3 0.7 ta 40.3 23.2 41.1
Test 44.5 55.9 0.7 48.6 48.0 52.5
SD 16.9 10.8 14.4 15.0 11.8
ar 37.0 ro 43.1 1.7 sk 41.2 35.3 41.3
bg 64.4 sk 66.8 0.4 sk 66.8 66.0 67.4
ca 56.3 es 72.4 0.1 es 72.4 61.5 72.4
el 63.1 sk 61.4 0.7 cs 60.7 62.3 63.8
es 59.9 ca 72.7 0.0 ca 72.7 64.3 72.7
et 67.5 hu 71.8 0.9 da 64.9 70.5 72.0
fa 30.9 ar 35.6 1.1 cs 34.7 32.5 33.3
fi 41.9 et 44.2 1.1 et 44.2 41.7 47.1
hi 24.1 ta 56.3 1.1 fa 20.8 24.6 27.2
hu 55.1 et 52.0 0.7 cs 46.0 56.5 51.2
it 52.5 ca 59.8 0.3 pt 54.9 59.5 59.6
ja 29.2 tr 49.2 2.2 ta 44.9 28.8 34.1
Dev 48.5 57.1 0.9 52.0 50.3 53.5
SD 15.2 12.5 16.1 16.5 16.7
All 46.1 56.4 0.8 50.0 48.9 52.9
SD 16.1 11.3 15.0 15.4 13.7
PRG test 60.0 49.7 55.7 58.1
PRG dev 64.0 57.5 58.0 61.1
PRG all 61.5 52.8 56.6 59.3
CoNLL 58.3 53.1 58.1 55.7
</table>
<tableCaption confidence="0.930655333333333">
Table 2: Evaluation using UAS on test target tree-
banks (upper part of the table) and development
target treebanks (lower part).
</tableCaption>
<bodyText confidence="0.8031172">
For each target language, all 29 remaining non-target tree-
banks were used for training the parsers. The best score
among our transfer methods is marked in bold; the base-
line and upper bound scores are marked in bold if equal to
or higher than that.
</bodyText>
<figure confidence="0.956075363636363">
Legend:
Tgt lang = Target treebank language.
TB conc = Treebank concatenation.
Oracle del trans = Single-source delexicalized transfer using
the oracle source language.
Single-src = Single-source delexicalized transfer using source
language with lowest KLcpos3 distance to the target language
(language bold if identical to oracle).
Multi-src = Multi-source delexicalized transfer, unweighted
(x1) and KL−4
cpos3 weighted (xw).
</figure>
<figureCaption confidence="0.2915494">
Test, Dev, All, SD = Average on test/development/all, and its
standard sample deviation.
PRG, CoNLL = Preliminary results (average UAS) on Prague
conversion of HamleDT, and on subset of CoNLL used by
McDonald et al. (2011).
</figureCaption>
<page confidence="0.997436">
246
</page>
<bodyText confidence="0.99997584375">
fore, determiners are parsed rather randomly.12 In
the weighted methods, this is not the case any-
more, as for a determiner-rich target language,
determiner-rich source languages are given a high
weight.
For target languages for which KLcpos3 of the
closest source language was lower or equal to its
average value of 0.7, the oracle treebank was iden-
tified in 7 cases out of 12 and a different but com-
petitive one in 2 cases; when higher than 0.7, an
appropriate treebank was only chosen in 1 case out
of 6. When KLcpos3 failed to identify the oracle,
weighted tree combination was always better or
equal to single-source transfer but mostly worse
than unweighted tree combination. This shows
that for distant languages, KLcpos3 does not per-
form as good as for close languages.
We believe that taking multiple characteristics
of the languages into account would improve the
results on distant languages. A good approach
might be to use an empirical measure, such as
KLcpos3, combined with supervised information
from other sources, such as WALS. Alternatively,
a backoff approach, i.e. combining KLcpos3 with
e.g. KLcpos2, might help to tackle the issue.
Still, for target languages dissimilar to any
source language, a better similarity measure will
not help much, as even the oracle results are usu-
ally poor. More fine-grained resource combination
methods are probably needed there, such as selec-
tively ignoring word order, or using different sets
of weights based on POS of the dependent node.
</bodyText>
<subsectionHeader confidence="0.999465">
6.3 Evaluation on Other Datasets
</subsectionHeader>
<bodyText confidence="0.971133609756098">
In (Rosa, 2015c), we show that the accuracies ob-
tained when parsing HamleDT treebanks in the
Universal Stanford Dependencies annotation style
are significantly lower than when using the Prague
style. Preliminary experiments using the Prague
style conversion of HamleDT generally show our
methods to be effective even on that dataset, al-
though the performance of KLcpos3 is lower in
source selection – it achieves lower UAS than un-
weighted tree combination, and only identifies the
oracle source treebank in 30% cases. This may be
due to us having used only the Stanfordized tree-
banks for tuning the exact definition of the mea-
sure.
related to properties of the treebank annotation or its harmo-
nization rather than properties of the language.
12UAS of determiner attachment tends to be lower than
5%, which is several times less than for any other POS.
Preliminary trials on the subset of CoNLL used
by McDonald et al. (2011) indicated that our meth-
ods do not perform well on this dataset. The best
results by far are achieved by the unweighted com-
bination, i.e., it is best not to use KLcpos3 at all
on this dataset. We believe this to be a deficiency
of the dataset rather than of our methods – it is
rather small, and there is low diversity in the lan-
guages involved, most of them being either Ger-
manic or Romanic. The HamleDT dataset is larger
and more diverse, and we believe it to correspond
better to the real-life motivation for our methods,
thus providing a more trustworthy evaluation.
In the near future, we intend to reevaluate our
methods using the Universal Dependencies tree-
bank collection (Nivre et al., 2015; Agi´c et al.,
2015a), which currently contains 18 languages of
various types and seems to be steadily growing. A
potential benefit of this collection is the fact that
the annotation style harmonization seems to be
done with more care and in a more principled way
than in HamleDT, presumably leading to a higher
quality of the dataset.
</bodyText>
<sectionHeader confidence="0.991016" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999988176470588">
We presented KLcpos3, an efficient language sim-
ilarity measure designed for delexicalized depen-
dency parser transfer. We evaluated it on a large
set of treebanks, and showed that it performs well
in selecting the source treebank for single-source
transfer, as well as in weighting the source tree-
banks in multi-source parse tree combination.
Our method achieves good results when applied
to similar languages, but its performance drops for
distant languages. In future, we plan to explore
combinations of KLcpos3 with other language sim-
ilarity measures, so that similarity of distant lan-
guages is estimated more reliably.
In this work, we only used the unlabelled first-
order MSTParser. We intend to also employ other
parsers in future, possibly in combination, and in
a labelled as well as unlabelled setting.
</bodyText>
<sectionHeader confidence="0.989775" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996146142857143">
This research was supported by the grants GAUK
1572314, SVV 260 224, and FP7-ICT-2013-10-
610516 (QTLeap). This work has been using lan-
guage resources developed, stored and distributed
by the LINDAT/CLARIN project of the Ministry
of Education, Youth and Sports of the Czech Re-
public (project LM2010013).
</bodyText>
<page confidence="0.997026">
247
</page>
<sectionHeader confidence="0.951503" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999094636363636">
ˇZeljko Agi´c, Maria Jesus Aranzabe, Aitziber Atutxa,
Cristina Bosco, Jinho Choi, Marie-Catherine
de Marneffe, Timothy Dozat, Rich´ard Farkas,
Jennifer Foster, Filip Ginter, Iakes Goenaga,
Koldo Gojenola, Yoav Goldberg, Jan Hajiˇc, An-
ders Trærup Johannsen, Jenna Kanerva, Juha
Kuokkala, Veronika Laippala, Alessandro Lenci,
Krister Lind´en, Nikola Ljubeˇsi´c, Teresa Lynn,
Christopher Manning, H´ector Alonso Martinez,
Ryan McDonald, Anna Missil¨a, Simonetta Monte-
magni, Joakim Nivre, Hanna Nurmi, Petya Osen-
ova, Slav Petrov, Jussi Piitulainen, Barbara Plank,
Prokopis Prokopidis, Sampo Pyysalo, Wolfgang
Seeker, Mojgan Seraji, Natalia Silveira, Maria Simi,
Kiril Simov, Aaron Smith, Reut Tsarfaty, Veronika
Vincze, and Daniel Zeman. 2015a. Universal De-
pendencies 1.1. http://hdl.handle.net/
11234/LRT-1478.
ˇZeljko Agi´c, Dirk Hovy, and Anders Søgaard. 2015b.
If all you have is a bit of the bible: Learning POS
taggers for truly low-resource languages. In The
53rd Annual Meeting of the Association for Compu-
tational Linguistics and the 7th International Joint
Conference of the Asian Federation of Natural Lan-
guage Processing (ACL-IJCNLP 2015). Hrvatska
znanstvena bibliografija i MZOS-Svibor.
Alena B¨ohmov´a, Jan Hajiˇc, Eva Hajiˇcov´a, and Barbora
Hladk´a. 2003. The Prague dependency treebank. In
Treebanks, pages 103–127. Springer.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proceedings of the Tenth Conference on Computa-
tional Natural Language Learning, pages 149–164.
Association for Computational Linguistics.
Giovanni Cavallanti, Nicolo Cesa-Bianchi, and Clau-
dio Gentile. 2010. Linear algorithms for online
multitask classification. The Journal of Machine
Learning Research, 11:2901–2934.
Yoeng-Jin Chu and Tseng-Hong Liu. 1965. On
shortest arborescence of a directed graph. Scientia
Sinica, 14(10):1396.
Koby Crammer and Yoram Singer. 2003. Ultracon-
servative online algorithms for multiclass problems.
The Journal of Machine Learning Research, 3:951–
991.
Dipanjan Das and Slav Petrov. 2011. Unsupervised
part-of-speech tagging with bilingual graph-based
projections. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies-Volume 1,
pages 600–609. Association for Computational Lin-
guistics.
Marie-Catherine de Marneffe, Natalia Silveira, Tim-
othy Dozat, Katri Haverinen, Filip Ginter, Joakim
Nivre, and Christopher D. Manning. 2014. Uni-
versal Stanford dependencies: A cross-linguistic ty-
pology. In Proc. of LREC’14, Reykjavik, Iceland.
ELRA.
Matthew S. Dryer and Martin Haspelmath, editors.
2013. WALS Online. Max Planck Institute for Evo-
lutionary Anthropology, Leipzig.
Jack Edmonds. 1967. Optimum branchings. Journal
of Research of the National Bureau of Standards B,
71(4):233–240.
Solomon Kullback and Richard A Leibler. 1951. On
information and sufficiency. The annals of mathe-
matical statistics, pages 79–86.
Lillian Lee. 2001. On the effectiveness of the skew
divergence for statistical language analysis. In Arti-
ficial intelligence and statistics, volume 2001, pages
65–72.
Ryan McDonald, Koby Crammer, and Fernando
Pereira. 2005a. Online large-margin training of de-
pendency parsers. In Proceedings of the 43rd an-
nual meeting on ACL, pages 91–98. ACL.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajiˇc. 2005b. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceedings
of the conference on Human Language Technology
and Empirical Methods in Natural Language Pro-
cessing, pages 523–530. ACL.
Ryan McDonald, Slav Petrov, and Keith Hall. 2011.
Multi-source transfer of delexicalized dependency
parsers. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP ’11, pages 62–72, Stroudsburg, PA, USA.
ACL.
Tahira Naseem, Regina Barzilay, and Amir Globerson.
2012. Selective sharing for multilingual dependency
parsing. In Proceedings of the 50th Annual Meeting
of theACL: Long Papers - Volume 1, ACL ’12, pages
629–637, Stroudsburg, PA, USA. ACL.
Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007.
The CoNLL 2007 shared task on dependency pars-
ing. In Proceedings of the CoNLL shared task ses-
sion of EMNLP-CoNLL, pages 915–932. sn.
Joakim Nivre, Cristina Bosco, Jinho Choi, Marie-
Catherine de Marneffe, Timothy Dozat, Rich´ard
Farkas, Jennifer Foster, Filip Ginter, Yoav Gold-
berg, Jan Hajiˇc, Jenna Kanerva, Veronika Laippala,
Alessandro Lenci, Teresa Lynn, Christopher Man-
ning, Ryan McDonald, Anna Missil¨a, Simonetta
Montemagni, Slav Petrov, Sampo Pyysalo, Natalia
Silveira, Maria Simi, Aaron Smith, Reut Tsarfaty,
Veronika Vincze, and Daniel Zeman. 2015. Univer-
sal Dependencies 1.0. http://hdl.handle.
net/11234/1-1464.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A universal part-of-speech tagset. In Proc. ofLREC-
2012, pages 2089–2096, Istanbul, Turkey. ELRA.
</reference>
<page confidence="0.96588">
248
</page>
<reference confidence="0.99977396923077">
Barbara Plank and Gertjan Van Noord. 2011. Effec-
tive measures of domain similarity for parsing. In
Proceedings of the 49th Annual Meeting of the ACL:
Human Language Technologies-Volume 1, pages
1566–1576. ACL.
Rudolf Rosa, Jan Maˇsek, David Mareˇcek, Martin
Popel, Daniel Zeman, and Zdenˇek ˇZabokrtsk´y.
2014. HamleDT 2.0: Thirty dependency treebanks
Stanfordized. In Proceedings of the 9th Interna-
tional Conference on Language Resources and Eval-
uation (LREC 2014), pages 2334–2341, Reykjavik,
Iceland. ELRA.
Rudolf Rosa. 2015a. MSTperl delexicalized parser
transfer scripts and configuration files. http://
hdl.handle.net/11234/1-1485.
Rudolf Rosa. 2015b. MSTperl parser (2015-05-19).
http://hdl.handle.net/11234/1-1480.
Rudolf Rosa. 2015c. Multi-source cross-lingual delex-
icalized parser transfer: Prague or Stanford? In Eva
Hajiˇcov´a and Joakim Nivre, editors, Proceedings of
the Third International Conference on Dependency
Linguistics, Depling 2015, Uppsala, Sweden. Upp-
sala University.
Kenji Sagae and Alon Lavie. 2006. Parser combi-
nation by reparsing. In Proceedings of the Human
Language Technology Conference of the NAACL,
Companion Volume: Short Papers, pages 129–132.
ACL.
Anders Søgaard and Julie Wulff. 2012. An empiri-
cal study of non-lexical extensions to delexicalized
transfer. In COLING (Posters), pages 1181–1190.
Mihai Surdeanu and Christopher D. Manning. 2010.
Ensemble models for dependency parsing: Cheap
and good? In Human Language Technologies:
The 2010 Annual Conference of the North Ameri-
can Chapter of the ACL, HLT ’10, pages 649–652,
Stroudsburg, PA, USA. ACL.
Oscar T¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan
McDonald, and Joakim Nivre. 2013a. Token and
type constraints for cross-lingual part-of-speech tag-
ging. Transactions of the Association for Computa-
tional Linguistics, 1:1–12.
Oscar T¨ackstr¨om, Ryan McDonald, and Joakim Nivre.
2013b. Target language adaptation of discrimina-
tive transfer parsers. In Proceedings of NAACL-HLT
2013, pages 1061–1071.
Daniel Zeman and Philip Resnik. 2008. Cross-
language parser adaptation between related lan-
guages. In IJCNLP 2008 Workshop on NLP for Less
Privileged Languages, pages 35–42, Hyderabad, In-
dia. Asian Federation of Natural Language Process-
ing, International Institute of Information Technol-
ogy.
Daniel Zeman, David Mareˇcek, Martin Popel,
Loganathan Ramasamy, Jan ˇStˇep´anek, Zdenˇek
ˇZabokrtsk´y, and Jan Hajiˇc. 2012. HamleDT: To
parse or not to parse? In Proceedings of the Eight
International Conference on Language Resources
and Evaluation (LREC’12), Istanbul, Turkey, May.
ELRA.
Daniel Zeman. 2008. Reusable tagset conversion us-
ing tagset drivers. In Proceedings of the 6th Interna-
tional Conference on Language Resources and Eval-
uation (LREC 2008), pages 213–218, Marrakech,
Morocco. ELRA.
</reference>
<page confidence="0.99891">
249
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.701722">
<title confidence="0.995601">a Language Similarity for Delexicalized Parser Transfer</title>
<author confidence="0.987106">Rosa</author>
<affiliation confidence="0.9296345">Charles University in Prague, Faculty of Mathematics and Institute of Formal and Applied</affiliation>
<address confidence="0.764317">Malostransk´e n´amˇest´ı 25, Prague, Czech</address>
<abstract confidence="0.994911857142857">present a language similarity measure based on Kullback-Leibler divergence of coarse part-of-speech tag trigram distributions in tagged corpora. It has been designed for multilingual delexicalized parsing, both for source treebank selection in single-source parser transfer, and for source treebank weighting in multi-source transfer. In the selection task, identifies the best source treebank in 8 out of 18 cases. In the weighting task, it brings +4.5% UAS absolute, compared to unweighted parse tree combination.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>ˇZeljko Agi´c</author>
<author>Maria Jesus Aranzabe</author>
<author>Aitziber Atutxa</author>
<author>Cristina Bosco</author>
<author>Jinho Choi</author>
<author>Marie-Catherine de Marneffe</author>
<author>Timothy Dozat</author>
<author>Rich´ard Farkas</author>
<author>Jennifer Foster</author>
<author>Filip Ginter</author>
</authors>
<title>Iakes Goenaga, Koldo Gojenola, Yoav Goldberg, Jan Hajiˇc, Anders Trærup Johannsen, Jenna Kanerva, Juha Kuokkala, Veronika Laippala, Alessandro Lenci, Krister Lind´en, Nikola Ljubeˇsi´c,</title>
<date>2015</date>
<journal>Universal Dependencies</journal>
<volume>1</volume>
<pages>11234--1478</pages>
<location>Teresa Lynn, Christopher Manning, H´ector Alonso Martinez, Ryan McDonald, Anna Missil¨a, Simonetta Montemagni, Joakim Nivre, Hanna</location>
<marker>Agi´c, Aranzabe, Atutxa, Bosco, Choi, de Marneffe, Dozat, Farkas, Foster, Ginter, 2015</marker>
<rawString>ˇZeljko Agi´c, Maria Jesus Aranzabe, Aitziber Atutxa, Cristina Bosco, Jinho Choi, Marie-Catherine de Marneffe, Timothy Dozat, Rich´ard Farkas, Jennifer Foster, Filip Ginter, Iakes Goenaga, Koldo Gojenola, Yoav Goldberg, Jan Hajiˇc, Anders Trærup Johannsen, Jenna Kanerva, Juha Kuokkala, Veronika Laippala, Alessandro Lenci, Krister Lind´en, Nikola Ljubeˇsi´c, Teresa Lynn, Christopher Manning, H´ector Alonso Martinez, Ryan McDonald, Anna Missil¨a, Simonetta Montemagni, Joakim Nivre, Hanna Nurmi, Petya Osenova, Slav Petrov, Jussi Piitulainen, Barbara Plank, Prokopis Prokopidis, Sampo Pyysalo, Wolfgang Seeker, Mojgan Seraji, Natalia Silveira, Maria Simi, Kiril Simov, Aaron Smith, Reut Tsarfaty, Veronika Vincze, and Daniel Zeman. 2015a. Universal Dependencies 1.1. http://hdl.handle.net/ 11234/LRT-1478.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ˇZeljko Agi´c</author>
<author>Dirk Hovy</author>
<author>Anders Søgaard</author>
</authors>
<title>If all you have is a bit of the bible: Learning POS taggers for truly low-resource languages.</title>
<date>2015</date>
<booktitle>In The 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference of the Asian Federation of Natural Language Processing (ACL-IJCNLP</booktitle>
<marker>Agi´c, Hovy, Søgaard, 2015</marker>
<rawString>ˇZeljko Agi´c, Dirk Hovy, and Anders Søgaard. 2015b. If all you have is a bit of the bible: Learning POS taggers for truly low-resource languages. In The 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference of the Asian Federation of Natural Language Processing (ACL-IJCNLP 2015). Hrvatska znanstvena bibliografija i MZOS-Svibor.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alena B¨ohmov´a</author>
<author>Jan Hajiˇc</author>
<author>Eva Hajiˇcov´a</author>
<author>Barbora Hladk´a</author>
</authors>
<title>The Prague dependency treebank. In Treebanks,</title>
<date>2003</date>
<pages>103--127</pages>
<publisher>Springer.</publisher>
<marker>B¨ohmov´a, Hajiˇc, Hajiˇcov´a, Hladk´a, 2003</marker>
<rawString>Alena B¨ohmov´a, Jan Hajiˇc, Eva Hajiˇcov´a, and Barbora Hladk´a. 2003. The Prague dependency treebank. In Treebanks, pages 103–127. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning,</booktitle>
<pages>149--164</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="12125" citStr="Buchholz and Marsi, 2006" startWordPosition="1929" endWordPosition="1932"> as Jenses-Shannon divergence (Lee, 2001) and cosine similarity. Based on the results, KL−4 cpos3 was selected, as it performed best in all aspects. Once the hyperparameters were fixed, we applied the parser transfer methods to the full set of 30 treebanks; our final evaluation is based on the results on the 18 test treebanks as targets. 5.2 Other datasets Additionally, we also report preliminary results on the Prague style conversion of HamleDT, which loosely follows the style of the Prague Dependency Treebank of B¨ohmov´a et al. (2003), and on the subset of CoNLL 2006 and 2007 shared tasks (Buchholz and Marsi, 2006; Nilsson et al., 2007) that was used by McDonald et al. (2011).8 6 Evaluation 6.1 Results Table 2 contains the results of our methods both on the test languages and the development languages. 7We tuned the choice of the similarity measure, POS ngram length, and the way of turning KLcpos3 into KL−4 cpos3. To tune our method to perform well in many different situations, we chose the development set to contain both smaller and larger treebanks, a pair of very close languages (ca, es), a very solitary language (ja), multiple members of several language families (Uralic, Romance), and both primari</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceedings of the Tenth Conference on Computational Natural Language Learning, pages 149–164. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giovanni Cavallanti</author>
<author>Nicolo Cesa-Bianchi</author>
<author>Claudio Gentile</author>
</authors>
<title>Linear algorithms for online multitask classification.</title>
<date>2010</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>11--2901</pages>
<contexts>
<context position="4231" citStr="Cavallanti et al., 2010" startWordPosition="629" endWordPosition="632"> similarity for delexicalized transfer, focusing on genealogy distance and word-order features. Søgaard and Wulff (2012) also introduced weighting into the treebank concatenation approach, using a POS ngram model trained on a target-language corpus 243 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 243–249, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics to weight source sentences in a weighted perceptron learning scenario (Cavallanti et al., 2010). KL divergence (Kullback and Leibler, 1951) of POS tag distributions, as well as several other measures, was used by Plank and Van Noord (2011) to estimate monolingual domain similarity. As is quite common in parsing papers, including those dealing with semi-supervised and unsupervised parsing, we use gold POS tags in all our experiments. This enables us to evaluate the effectiveness of our parsing method alone, not influenced by errors stemming from the POS tagging. Based on the published results, it seems to be considerably easier to induce POS tags than syntactic structure for under-resour</context>
</contexts>
<marker>Cavallanti, Cesa-Bianchi, Gentile, 2010</marker>
<rawString>Giovanni Cavallanti, Nicolo Cesa-Bianchi, and Claudio Gentile. 2010. Linear algorithms for online multitask classification. The Journal of Machine Learning Research, 11:2901–2934.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoeng-Jin Chu</author>
<author>Tseng-Hong Liu</author>
</authors>
<title>On shortest arborescence of a directed graph.</title>
<date>1965</date>
<journal>Scientia Sinica,</journal>
<volume>14</volume>
<issue>10</issue>
<contexts>
<context position="7596" citStr="Chu and Liu (1965)" startWordPosition="1189" endWordPosition="1192"> delexicalized parser on each source treebank. 2. Apply each of the parsers to the target sentence, obtaining a set of parse trees. 3. Construct a weighted directed graph as a complete graph over all tokens of the target sentence, where each edge is assigned a score equal to the number of parse trees in which it appears (each parse tree contributes by either 0 or 1 to the edge score). In the weighted variant of the method, the contribution of each parse tree is multiplied by its weight. 4. Find the final dependency parse tree as the maximum spanning tree over the graph, using the algorithm of Chu and Liu (1965) and Edmonds (1967). 4 KLcpos3 Language Similarity We introduce KLcpos3, a language similarity measure based on distributions of coarse POS tags in source and target POS-tagged corpora. This is motivated by the fact that POS tags constitute a key feature for delexicalized parsing. The distributions are estimated as frequencies of UPOS trigrams3 in the treebank training sections: f(cposz−1, cposz, cposz+1) = count(cposz−1, cposz, cposz+1) = EVcposa,b,c count(cposa, cposb, cposz) ; (1) we use a special value for cposz−1 or cposz+1 if cposz appears at sentence beginning or end. We then apply the </context>
</contexts>
<marker>Chu, Liu, 1965</marker>
<rawString>Yoeng-Jin Chu and Tseng-Hong Liu. 1965. On shortest arborescence of a directed graph. Scientia Sinica, 14(10):1396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>The Journal of Machine Learning Research,</journal>
<volume>3</volume>
<pages>991</pages>
<contexts>
<context position="5828" citStr="Crammer and Singer, 2003" startWordPosition="888" endWordPosition="891">15b) were able to reach accuracies around 70% by using partial or full Bible translation. Our methods could thus be applied even in a more realistic scenario, where gold POS tags are not available for the target text, by using a weaklysupervised POS tagger. We intend to evaluate the performance of our approach in such a setting in future. 3 Delexicalized Parser Transfer Throughout this work, we use MSTperl (Rosa, 2015b), an implementation of the unlabelled single-best MSTParser of McDonald et al. (2005b), with first-order features and nonprojective parsing, trained using 3 iterations of MIRA (Crammer and Singer, 2003).1 Our delexicalized feature set is based on the set of McDonald et al. (2005a) with lexical features removed. It consists of combinations of signed edge length (distance of head and parent, bucketed for values above 4 and for values above 10) with POS tag of the head, dependent, their neighbours, and all nodes between them.2 We use the Universal POS Tagset (UPOS) of Petrov et al. (2012). 1Note that while our approach does not depend in principle on the actual parser used, our results and conclusions may not be valid for other parsers. 2The feature set, as well as scripts and configuration fil</context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>Koby Crammer and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. The Journal of Machine Learning Research, 3:951– 991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
</authors>
<title>Unsupervised part-of-speech tagging with bilingual graph-based projections.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>600--609</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4936" citStr="Das and Petrov (2011)" startWordPosition="742" endWordPosition="745">veral other measures, was used by Plank and Van Noord (2011) to estimate monolingual domain similarity. As is quite common in parsing papers, including those dealing with semi-supervised and unsupervised parsing, we use gold POS tags in all our experiments. This enables us to evaluate the effectiveness of our parsing method alone, not influenced by errors stemming from the POS tagging. Based on the published results, it seems to be considerably easier to induce POS tags than syntactic structure for under-resourced languages, as there are several high-performance weakly-supervised POS taggers. Das and Petrov (2011) report an average accuracy of 83% using word-aligned texts, compared to 97% reached by a supervised tagger. T¨ackstr¨om et al. (2013a) further improve this to 89% by leveraging Wiktionary. For some languages, there are even less resources available; Agi´c et al. (2015b) were able to reach accuracies around 70% by using partial or full Bible translation. Our methods could thus be applied even in a more realistic scenario, where gold POS tags are not available for the target text, by using a weaklysupervised POS tagger. We intend to evaluate the performance of our approach in such a setting in </context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>Dipanjan Das and Slav Petrov. 2011. Unsupervised part-of-speech tagging with bilingual graph-based projections. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 600–609. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Natalia Silveira</author>
<author>Timothy Dozat</author>
<author>Katri Haverinen</author>
<author>Filip Ginter</author>
<author>Joakim Nivre</author>
<author>Christopher D Manning</author>
</authors>
<title>Universal Stanford dependencies: A cross-linguistic typology.</title>
<date>2014</date>
<booktitle>In Proc. of LREC’14,</booktitle>
<location>Reykjavik, Iceland. ELRA.</location>
<marker>de Marneffe, Silveira, Dozat, Haverinen, Ginter, Nivre, Manning, 2014</marker>
<rawString>Marie-Catherine de Marneffe, Natalia Silveira, Timothy Dozat, Katri Haverinen, Filip Ginter, Joakim Nivre, and Christopher D. Manning. 2014. Universal Stanford dependencies: A cross-linguistic typology. In Proc. of LREC’14, Reykjavik, Iceland. ELRA.</rawString>
</citation>
<citation valid="false">
<editor>Matthew S. Dryer and Martin Haspelmath, editors. 2013. WALS Online. Max</editor>
<institution>Planck Institute for Evolutionary Anthropology,</institution>
<location>Leipzig.</location>
<marker></marker>
<rawString>Matthew S. Dryer and Martin Haspelmath, editors. 2013. WALS Online. Max Planck Institute for Evolutionary Anthropology, Leipzig.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jack Edmonds</author>
</authors>
<title>Optimum branchings.</title>
<date>1967</date>
<journal>Journal of Research of the National Bureau of Standards B,</journal>
<volume>71</volume>
<issue>4</issue>
<contexts>
<context position="7615" citStr="Edmonds (1967)" startWordPosition="1194" endWordPosition="1195">n each source treebank. 2. Apply each of the parsers to the target sentence, obtaining a set of parse trees. 3. Construct a weighted directed graph as a complete graph over all tokens of the target sentence, where each edge is assigned a score equal to the number of parse trees in which it appears (each parse tree contributes by either 0 or 1 to the edge score). In the weighted variant of the method, the contribution of each parse tree is multiplied by its weight. 4. Find the final dependency parse tree as the maximum spanning tree over the graph, using the algorithm of Chu and Liu (1965) and Edmonds (1967). 4 KLcpos3 Language Similarity We introduce KLcpos3, a language similarity measure based on distributions of coarse POS tags in source and target POS-tagged corpora. This is motivated by the fact that POS tags constitute a key feature for delexicalized parsing. The distributions are estimated as frequencies of UPOS trigrams3 in the treebank training sections: f(cposz−1, cposz, cposz+1) = count(cposz−1, cposz, cposz+1) = EVcposa,b,c count(cposa, cposb, cposz) ; (1) we use a special value for cposz−1 or cposz+1 if cposz appears at sentence beginning or end. We then apply the Kullback-Leibler di</context>
</contexts>
<marker>Edmonds, 1967</marker>
<rawString>Jack Edmonds. 1967. Optimum branchings. Journal of Research of the National Bureau of Standards B, 71(4):233–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Solomon Kullback</author>
<author>Richard A Leibler</author>
</authors>
<title>On information and sufficiency. The annals of mathematical statistics,</title>
<date>1951</date>
<pages>79--86</pages>
<contexts>
<context position="1679" citStr="Kullback and Leibler, 1951" startWordPosition="246" endWordPosition="249">OS) tags, and to apply that parser to POS-tagged sentences of a target language (tgt) to obtain dependency parse trees. Delexicalized transfer yields worse results than a supervised lexicalized parser trained on a target language treebank. However, for languages with no treebanks available, it may be useful to obtain at least a lower-quality parse tree for tasks such as information retrieval. Usually, multiple source treebanks are available, and it is non-trivial to select the best one for a given target language. As a solution, we present a language similarity measure based on KL divergence (Kullback and Leibler, 1951) of distributions of coarse POS tag trigrams in POS-tagged corpora, which we call KLcpos3. The measure has been designed and tuned specifically for multilingual delexicalized parser transfer, and it often succeeds in selecting the best source treebank in a single-source setting, as well as in appropriately weighting the source treebanks by similarity to the target language in a multi-source parse tree combination approach. 2 Related Work Delexicalized parser transfer was conceived by Zeman and Resnik (2008), who also introduced two important preprocessing steps – mapping treebank-specific POS </context>
<context position="4275" citStr="Kullback and Leibler, 1951" startWordPosition="635" endWordPosition="638">ocusing on genealogy distance and word-order features. Søgaard and Wulff (2012) also introduced weighting into the treebank concatenation approach, using a POS ngram model trained on a target-language corpus 243 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 243–249, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics to weight source sentences in a weighted perceptron learning scenario (Cavallanti et al., 2010). KL divergence (Kullback and Leibler, 1951) of POS tag distributions, as well as several other measures, was used by Plank and Van Noord (2011) to estimate monolingual domain similarity. As is quite common in parsing papers, including those dealing with semi-supervised and unsupervised parsing, we use gold POS tags in all our experiments. This enables us to evaluate the effectiveness of our parsing method alone, not influenced by errors stemming from the POS tagging. Based on the published results, it seems to be considerably easier to induce POS tags than syntactic structure for under-resourced languages, as there are several high-per</context>
</contexts>
<marker>Kullback, Leibler, 1951</marker>
<rawString>Solomon Kullback and Richard A Leibler. 1951. On information and sufficiency. The annals of mathematical statistics, pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lillian Lee</author>
</authors>
<title>On the effectiveness of the skew divergence for statistical language analysis.</title>
<date>2001</date>
<booktitle>In Artificial intelligence and statistics,</booktitle>
<volume>volume</volume>
<pages>65--72</pages>
<contexts>
<context position="11542" citStr="Lee, 2001" startWordPosition="1831" endWordPosition="1832">average UAS on the development set. Avg = Average UAS. SD = Standard sample deviation of UAS, serving as an indication of robustness of the measure. Best = Number of targets for which the measure scored best. development treebanks for hyperparameter tuning: ar, bg, ca, el, es, et, fa, fi, hi, hu, it, ja.7 Table 1 contains evaluation of several language similarity measures considered in the tuning phase, applied to weighted multi-source transfer and evaluated using average UAS on the development set. We evaluated KL divergences computed in both directions, as well as Jenses-Shannon divergence (Lee, 2001) and cosine similarity. Based on the results, KL−4 cpos3 was selected, as it performed best in all aspects. Once the hyperparameters were fixed, we applied the parser transfer methods to the full set of 30 treebanks; our final evaluation is based on the results on the 18 test treebanks as targets. 5.2 Other datasets Additionally, we also report preliminary results on the Prague style conversion of HamleDT, which loosely follows the style of the Prague Dependency Treebank of B¨ohmov´a et al. (2003), and on the subset of CoNLL 2006 and 2007 shared tasks (Buchholz and Marsi, 2006; Nilsson et al.,</context>
</contexts>
<marker>Lee, 2001</marker>
<rawString>Lillian Lee. 2001. On the effectiveness of the skew divergence for statistical language analysis. In Artificial intelligence and statistics, volume 2001, pages 65–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd annual meeting on ACL,</booktitle>
<pages>91--98</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="5710" citStr="McDonald et al. (2005" startWordPosition="871" endWordPosition="874">his to 89% by leveraging Wiktionary. For some languages, there are even less resources available; Agi´c et al. (2015b) were able to reach accuracies around 70% by using partial or full Bible translation. Our methods could thus be applied even in a more realistic scenario, where gold POS tags are not available for the target text, by using a weaklysupervised POS tagger. We intend to evaluate the performance of our approach in such a setting in future. 3 Delexicalized Parser Transfer Throughout this work, we use MSTperl (Rosa, 2015b), an implementation of the unlabelled single-best MSTParser of McDonald et al. (2005b), with first-order features and nonprojective parsing, trained using 3 iterations of MIRA (Crammer and Singer, 2003).1 Our delexicalized feature set is based on the set of McDonald et al. (2005a) with lexical features removed. It consists of combinations of signed edge length (distance of head and parent, bucketed for values above 4 and for values above 10) with POS tag of the head, dependent, their neighbours, and all nodes between them.2 We use the Universal POS Tagset (UPOS) of Petrov et al. (2012). 1Note that while our approach does not depend in principle on the actual parser used, our </context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005a. Online large-margin training of dependency parsers. In Proceedings of the 43rd annual meeting on ACL, pages 91–98. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajiˇc</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>523--530</pages>
<publisher>ACL.</publisher>
<marker>McDonald, Pereira, Ribarov, Hajiˇc, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajiˇc. 2005b. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 523–530. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Slav Petrov</author>
<author>Keith Hall</author>
</authors>
<title>Multi-source transfer of delexicalized dependency parsers.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>62--72</pages>
<publisher>ACL.</publisher>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2511" citStr="McDonald et al. (2011)" startWordPosition="373" endWordPosition="376">eds in selecting the best source treebank in a single-source setting, as well as in appropriately weighting the source treebanks by similarity to the target language in a multi-source parse tree combination approach. 2 Related Work Delexicalized parser transfer was conceived by Zeman and Resnik (2008), who also introduced two important preprocessing steps – mapping treebank-specific POS tagsets to a common set using Interset (Zeman, 2008), and harmonizing treebank annotation styles into a common style, which later developed into the HamleDT harmonized treebank collection (Zeman et al., 2012). McDonald et al. (2011) applied delexicalized transfer in a setting with multiple source treebanks available, finding that the problem of selecting the best source treebank without access to a target language treebank for evaluation is non-trivial. They combined all source treebanks by concatenating them but noted that this yields worse results than using only the best source treebank. An alternative is the (monolingual) parse tree combination method of Sagae and Lavie (2006), who apply several independent parsers to the input sentence and combine the resulting parse trees using a maximum spanning tree algorithm. Su</context>
<context position="12188" citStr="McDonald et al. (2011)" startWordPosition="1941" endWordPosition="1944">Based on the results, KL−4 cpos3 was selected, as it performed best in all aspects. Once the hyperparameters were fixed, we applied the parser transfer methods to the full set of 30 treebanks; our final evaluation is based on the results on the 18 test treebanks as targets. 5.2 Other datasets Additionally, we also report preliminary results on the Prague style conversion of HamleDT, which loosely follows the style of the Prague Dependency Treebank of B¨ohmov´a et al. (2003), and on the subset of CoNLL 2006 and 2007 shared tasks (Buchholz and Marsi, 2006; Nilsson et al., 2007) that was used by McDonald et al. (2011).8 6 Evaluation 6.1 Results Table 2 contains the results of our methods both on the test languages and the development languages. 7We tuned the choice of the similarity measure, POS ngram length, and the way of turning KLcpos3 into KL−4 cpos3. To tune our method to perform well in many different situations, we chose the development set to contain both smaller and larger treebanks, a pair of very close languages (ca, es), a very solitary language (ja), multiple members of several language families (Uralic, Romance), and both primarily leftbranching (bg, el) and right-branching (ar, ja) language</context>
<context position="17907" citStr="McDonald et al. (2011)" startWordPosition="2967" endWordPosition="2970">eebank language. TB conc = Treebank concatenation. Oracle del trans = Single-source delexicalized transfer using the oracle source language. Single-src = Single-source delexicalized transfer using source language with lowest KLcpos3 distance to the target language (language bold if identical to oracle). Multi-src = Multi-source delexicalized transfer, unweighted (x1) and KL−4 cpos3 weighted (xw). Test, Dev, All, SD = Average on test/development/all, and its standard sample deviation. PRG, CoNLL = Preliminary results (average UAS) on Prague conversion of HamleDT, and on subset of CoNLL used by McDonald et al. (2011). 246 fore, determiners are parsed rather randomly.12 In the weighted methods, this is not the case anymore, as for a determiner-rich target language, determiner-rich source languages are given a high weight. For target languages for which KLcpos3 of the closest source language was lower or equal to its average value of 0.7, the oracle treebank was identified in 7 cases out of 12 and a different but competitive one in 2 cases; when higher than 0.7, an appropriate treebank was only chosen in 1 case out of 6. When KLcpos3 failed to identify the oracle, weighted tree combination was always better</context>
<context position="20366" citStr="McDonald et al. (2011)" startWordPosition="3370" endWordPosition="3373">effective even on that dataset, although the performance of KLcpos3 is lower in source selection – it achieves lower UAS than unweighted tree combination, and only identifies the oracle source treebank in 30% cases. This may be due to us having used only the Stanfordized treebanks for tuning the exact definition of the measure. related to properties of the treebank annotation or its harmonization rather than properties of the language. 12UAS of determiner attachment tends to be lower than 5%, which is several times less than for any other POS. Preliminary trials on the subset of CoNLL used by McDonald et al. (2011) indicated that our methods do not perform well on this dataset. The best results by far are achieved by the unweighted combination, i.e., it is best not to use KLcpos3 at all on this dataset. We believe this to be a deficiency of the dataset rather than of our methods – it is rather small, and there is low diversity in the languages involved, most of them being either Germanic or Romanic. The HamleDT dataset is larger and more diverse, and we believe it to correspond better to the real-life motivation for our methods, thus providing a more trustworthy evaluation. In the near future, we intend</context>
</contexts>
<marker>McDonald, Petrov, Hall, 2011</marker>
<rawString>Ryan McDonald, Slav Petrov, and Keith Hall. 2011. Multi-source transfer of delexicalized dependency parsers. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 62–72, Stroudsburg, PA, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tahira Naseem</author>
<author>Regina Barzilay</author>
<author>Amir Globerson</author>
</authors>
<title>Selective sharing for multilingual dependency parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of theACL: Long Papers - Volume 1, ACL ’12,</booktitle>
<pages>629--637</pages>
<publisher>ACL.</publisher>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="3476" citStr="Naseem et al., 2012" startWordPosition="522" endWordPosition="525">st source treebank. An alternative is the (monolingual) parse tree combination method of Sagae and Lavie (2006), who apply several independent parsers to the input sentence and combine the resulting parse trees using a maximum spanning tree algorithm. Surdeanu and Manning (2010) enrich tree combination with weighting, assigning each parser a weight based on its Unlabelled Attachment Score (UAS). In our work, we introduce an extension of this method to a crosslingual setting by combining parsers for different languages and using sourcetarget language similarity to weight them. Several authors (Naseem et al., 2012; Søgaard and Wulff, 2012; T¨ackstr¨om et al., 2013b) employed WALS (Dryer and Haspelmath, 2013) to estimate source-target language similarity for delexicalized transfer, focusing on genealogy distance and word-order features. Søgaard and Wulff (2012) also introduced weighting into the treebank concatenation approach, using a POS ngram model trained on a target-language corpus 243 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 243–249, Beijing, China, July 26</context>
</contexts>
<marker>Naseem, Barzilay, Globerson, 2012</marker>
<rawString>Tahira Naseem, Regina Barzilay, and Amir Globerson. 2012. Selective sharing for multilingual dependency parsing. In Proceedings of the 50th Annual Meeting of theACL: Long Papers - Volume 1, ACL ’12, pages 629–637, Stroudsburg, PA, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>The CoNLL</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL shared task session of EMNLP-CoNLL,</booktitle>
<pages>915--932</pages>
<contexts>
<context position="12148" citStr="Nilsson et al., 2007" startWordPosition="1933" endWordPosition="1936">nce (Lee, 2001) and cosine similarity. Based on the results, KL−4 cpos3 was selected, as it performed best in all aspects. Once the hyperparameters were fixed, we applied the parser transfer methods to the full set of 30 treebanks; our final evaluation is based on the results on the 18 test treebanks as targets. 5.2 Other datasets Additionally, we also report preliminary results on the Prague style conversion of HamleDT, which loosely follows the style of the Prague Dependency Treebank of B¨ohmov´a et al. (2003), and on the subset of CoNLL 2006 and 2007 shared tasks (Buchholz and Marsi, 2006; Nilsson et al., 2007) that was used by McDonald et al. (2011).8 6 Evaluation 6.1 Results Table 2 contains the results of our methods both on the test languages and the development languages. 7We tuned the choice of the similarity measure, POS ngram length, and the way of turning KLcpos3 into KL−4 cpos3. To tune our method to perform well in many different situations, we chose the development set to contain both smaller and larger treebanks, a pair of very close languages (ca, es), a very solitary language (ja), multiple members of several language families (Uralic, Romance), and both primarily leftbranching (bg, e</context>
</contexts>
<marker>Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proceedings of the CoNLL shared task session of EMNLP-CoNLL, pages 915–932. sn.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Joakim Nivre</author>
<author>Cristina Bosco</author>
<author>Jinho Choi</author>
<author>MarieCatherine de Marneffe</author>
<author>Timothy Dozat</author>
<author>Rich´ard Farkas</author>
<author>Jennifer Foster</author>
<author>Filip Ginter</author>
<author>Yoav Goldberg</author>
<author>Jan Hajiˇc</author>
<author>Jenna Kanerva</author>
</authors>
<date>2015</date>
<journal>Universal Dependencies</journal>
<volume>1</volume>
<pages>11234--1</pages>
<location>Veronika Laippala, Alessandro Lenci, Teresa Lynn, Christopher Manning, Ryan McDonald, Anna Missil¨a, Simonetta Montemagni, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Maria</location>
<marker>Nivre, Bosco, Choi, de Marneffe, Dozat, Farkas, Foster, Ginter, Goldberg, Hajiˇc, Kanerva, 2015</marker>
<rawString>Joakim Nivre, Cristina Bosco, Jinho Choi, MarieCatherine de Marneffe, Timothy Dozat, Rich´ard Farkas, Jennifer Foster, Filip Ginter, Yoav Goldberg, Jan Hajiˇc, Jenna Kanerva, Veronika Laippala, Alessandro Lenci, Teresa Lynn, Christopher Manning, Ryan McDonald, Anna Missil¨a, Simonetta Montemagni, Slav Petrov, Sampo Pyysalo, Natalia Silveira, Maria Simi, Aaron Smith, Reut Tsarfaty, Veronika Vincze, and Daniel Zeman. 2015. Universal Dependencies 1.0. http://hdl.handle. net/11234/1-1464.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dipanjan Das</author>
<author>Ryan McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2012</date>
<booktitle>In Proc. ofLREC2012,</booktitle>
<pages>2089--2096</pages>
<location>Istanbul, Turkey. ELRA.</location>
<contexts>
<context position="6218" citStr="Petrov et al. (2012)" startWordPosition="956" endWordPosition="959">we use MSTperl (Rosa, 2015b), an implementation of the unlabelled single-best MSTParser of McDonald et al. (2005b), with first-order features and nonprojective parsing, trained using 3 iterations of MIRA (Crammer and Singer, 2003).1 Our delexicalized feature set is based on the set of McDonald et al. (2005a) with lexical features removed. It consists of combinations of signed edge length (distance of head and parent, bucketed for values above 4 and for values above 10) with POS tag of the head, dependent, their neighbours, and all nodes between them.2 We use the Universal POS Tagset (UPOS) of Petrov et al. (2012). 1Note that while our approach does not depend in principle on the actual parser used, our results and conclusions may not be valid for other parsers. 2The feature set, as well as scripts and configuration files for the presented experiments, are available in (Rosa, 2015a). 3.1 Single-source Delexicalized Transfer In the single-source parser transfer, the delexicalized parser is trained on a single source treebank, and applied to the target corpus. The problem thus reduces to selecting a source treebank that will lead to a high performance on the target language. 3.2 Multi-source Delexicalize</context>
</contexts>
<marker>Petrov, Das, McDonald, 2012</marker>
<rawString>Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012. A universal part-of-speech tagset. In Proc. ofLREC2012, pages 2089–2096, Istanbul, Turkey. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Plank</author>
<author>Gertjan Van Noord</author>
</authors>
<title>Effective measures of domain similarity for parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the ACL: Human Language Technologies-Volume</booktitle>
<volume>1</volume>
<pages>1566--1576</pages>
<publisher>ACL.</publisher>
<marker>Plank, Van Noord, 2011</marker>
<rawString>Barbara Plank and Gertjan Van Noord. 2011. Effective measures of domain similarity for parsing. In Proceedings of the 49th Annual Meeting of the ACL: Human Language Technologies-Volume 1, pages 1566–1576. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rudolf Rosa</author>
<author>Jan Maˇsek</author>
<author>David Mareˇcek</author>
<author>Martin Popel</author>
<author>Daniel Zeman</author>
<author>Zdenˇek ˇZabokrtsk´y</author>
</authors>
<title>HamleDT 2.0: Thirty dependency treebanks Stanfordized.</title>
<date>2014</date>
<booktitle>In Proceedings of the 9th International Conference on Language Resources and Evaluation (LREC 2014),</booktitle>
<pages>2334--2341</pages>
<location>Reykjavik, Iceland. ELRA.</location>
<marker>Rosa, Maˇsek, Mareˇcek, Popel, Zeman, ˇZabokrtsk´y, 2014</marker>
<rawString>Rudolf Rosa, Jan Maˇsek, David Mareˇcek, Martin Popel, Daniel Zeman, and Zdenˇek ˇZabokrtsk´y. 2014. HamleDT 2.0: Thirty dependency treebanks Stanfordized. In Proceedings of the 9th International Conference on Language Resources and Evaluation (LREC 2014), pages 2334–2341, Reykjavik, Iceland. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rudolf Rosa</author>
</authors>
<title>MSTperl delexicalized parser transfer scripts and configuration files.</title>
<date>2015</date>
<pages>11234--1</pages>
<contexts>
<context position="5624" citStr="Rosa, 2015" startWordPosition="861" endWordPosition="862">eached by a supervised tagger. T¨ackstr¨om et al. (2013a) further improve this to 89% by leveraging Wiktionary. For some languages, there are even less resources available; Agi´c et al. (2015b) were able to reach accuracies around 70% by using partial or full Bible translation. Our methods could thus be applied even in a more realistic scenario, where gold POS tags are not available for the target text, by using a weaklysupervised POS tagger. We intend to evaluate the performance of our approach in such a setting in future. 3 Delexicalized Parser Transfer Throughout this work, we use MSTperl (Rosa, 2015b), an implementation of the unlabelled single-best MSTParser of McDonald et al. (2005b), with first-order features and nonprojective parsing, trained using 3 iterations of MIRA (Crammer and Singer, 2003).1 Our delexicalized feature set is based on the set of McDonald et al. (2005a) with lexical features removed. It consists of combinations of signed edge length (distance of head and parent, bucketed for values above 4 and for values above 10) with POS tag of the head, dependent, their neighbours, and all nodes between them.2 We use the Universal POS Tagset (UPOS) of Petrov et al. (2012). 1Not</context>
<context position="19456" citStr="Rosa, 2015" startWordPosition="3222" endWordPosition="3223">e an empirical measure, such as KLcpos3, combined with supervised information from other sources, such as WALS. Alternatively, a backoff approach, i.e. combining KLcpos3 with e.g. KLcpos2, might help to tackle the issue. Still, for target languages dissimilar to any source language, a better similarity measure will not help much, as even the oracle results are usually poor. More fine-grained resource combination methods are probably needed there, such as selectively ignoring word order, or using different sets of weights based on POS of the dependent node. 6.3 Evaluation on Other Datasets In (Rosa, 2015c), we show that the accuracies obtained when parsing HamleDT treebanks in the Universal Stanford Dependencies annotation style are significantly lower than when using the Prague style. Preliminary experiments using the Prague style conversion of HamleDT generally show our methods to be effective even on that dataset, although the performance of KLcpos3 is lower in source selection – it achieves lower UAS than unweighted tree combination, and only identifies the oracle source treebank in 30% cases. This may be due to us having used only the Stanfordized treebanks for tuning the exact definitio</context>
</contexts>
<marker>Rosa, 2015</marker>
<rawString>Rudolf Rosa. 2015a. MSTperl delexicalized parser transfer scripts and configuration files. http:// hdl.handle.net/11234/1-1485.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rudolf Rosa</author>
</authors>
<date>2015</date>
<note>MSTperl parser (2015-05-19). http://hdl.handle.net/11234/1-1480.</note>
<contexts>
<context position="5624" citStr="Rosa, 2015" startWordPosition="861" endWordPosition="862">eached by a supervised tagger. T¨ackstr¨om et al. (2013a) further improve this to 89% by leveraging Wiktionary. For some languages, there are even less resources available; Agi´c et al. (2015b) were able to reach accuracies around 70% by using partial or full Bible translation. Our methods could thus be applied even in a more realistic scenario, where gold POS tags are not available for the target text, by using a weaklysupervised POS tagger. We intend to evaluate the performance of our approach in such a setting in future. 3 Delexicalized Parser Transfer Throughout this work, we use MSTperl (Rosa, 2015b), an implementation of the unlabelled single-best MSTParser of McDonald et al. (2005b), with first-order features and nonprojective parsing, trained using 3 iterations of MIRA (Crammer and Singer, 2003).1 Our delexicalized feature set is based on the set of McDonald et al. (2005a) with lexical features removed. It consists of combinations of signed edge length (distance of head and parent, bucketed for values above 4 and for values above 10) with POS tag of the head, dependent, their neighbours, and all nodes between them.2 We use the Universal POS Tagset (UPOS) of Petrov et al. (2012). 1Not</context>
<context position="19456" citStr="Rosa, 2015" startWordPosition="3222" endWordPosition="3223">e an empirical measure, such as KLcpos3, combined with supervised information from other sources, such as WALS. Alternatively, a backoff approach, i.e. combining KLcpos3 with e.g. KLcpos2, might help to tackle the issue. Still, for target languages dissimilar to any source language, a better similarity measure will not help much, as even the oracle results are usually poor. More fine-grained resource combination methods are probably needed there, such as selectively ignoring word order, or using different sets of weights based on POS of the dependent node. 6.3 Evaluation on Other Datasets In (Rosa, 2015c), we show that the accuracies obtained when parsing HamleDT treebanks in the Universal Stanford Dependencies annotation style are significantly lower than when using the Prague style. Preliminary experiments using the Prague style conversion of HamleDT generally show our methods to be effective even on that dataset, although the performance of KLcpos3 is lower in source selection – it achieves lower UAS than unweighted tree combination, and only identifies the oracle source treebank in 30% cases. This may be due to us having used only the Stanfordized treebanks for tuning the exact definitio</context>
</contexts>
<marker>Rosa, 2015</marker>
<rawString>Rudolf Rosa. 2015b. MSTperl parser (2015-05-19). http://hdl.handle.net/11234/1-1480.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rudolf Rosa</author>
</authors>
<title>Multi-source cross-lingual delexicalized parser transfer: Prague or Stanford?</title>
<date>2015</date>
<booktitle>In Eva Hajiˇcov´a and Joakim Nivre, editors, Proceedings of the Third International Conference on Dependency Linguistics, Depling 2015,</booktitle>
<institution>Sweden. Uppsala University.</institution>
<location>Uppsala,</location>
<contexts>
<context position="5624" citStr="Rosa, 2015" startWordPosition="861" endWordPosition="862">eached by a supervised tagger. T¨ackstr¨om et al. (2013a) further improve this to 89% by leveraging Wiktionary. For some languages, there are even less resources available; Agi´c et al. (2015b) were able to reach accuracies around 70% by using partial or full Bible translation. Our methods could thus be applied even in a more realistic scenario, where gold POS tags are not available for the target text, by using a weaklysupervised POS tagger. We intend to evaluate the performance of our approach in such a setting in future. 3 Delexicalized Parser Transfer Throughout this work, we use MSTperl (Rosa, 2015b), an implementation of the unlabelled single-best MSTParser of McDonald et al. (2005b), with first-order features and nonprojective parsing, trained using 3 iterations of MIRA (Crammer and Singer, 2003).1 Our delexicalized feature set is based on the set of McDonald et al. (2005a) with lexical features removed. It consists of combinations of signed edge length (distance of head and parent, bucketed for values above 4 and for values above 10) with POS tag of the head, dependent, their neighbours, and all nodes between them.2 We use the Universal POS Tagset (UPOS) of Petrov et al. (2012). 1Not</context>
<context position="19456" citStr="Rosa, 2015" startWordPosition="3222" endWordPosition="3223">e an empirical measure, such as KLcpos3, combined with supervised information from other sources, such as WALS. Alternatively, a backoff approach, i.e. combining KLcpos3 with e.g. KLcpos2, might help to tackle the issue. Still, for target languages dissimilar to any source language, a better similarity measure will not help much, as even the oracle results are usually poor. More fine-grained resource combination methods are probably needed there, such as selectively ignoring word order, or using different sets of weights based on POS of the dependent node. 6.3 Evaluation on Other Datasets In (Rosa, 2015c), we show that the accuracies obtained when parsing HamleDT treebanks in the Universal Stanford Dependencies annotation style are significantly lower than when using the Prague style. Preliminary experiments using the Prague style conversion of HamleDT generally show our methods to be effective even on that dataset, although the performance of KLcpos3 is lower in source selection – it achieves lower UAS than unweighted tree combination, and only identifies the oracle source treebank in 30% cases. This may be due to us having used only the Stanfordized treebanks for tuning the exact definitio</context>
</contexts>
<marker>Rosa, 2015</marker>
<rawString>Rudolf Rosa. 2015c. Multi-source cross-lingual delexicalized parser transfer: Prague or Stanford? In Eva Hajiˇcov´a and Joakim Nivre, editors, Proceedings of the Third International Conference on Dependency Linguistics, Depling 2015, Uppsala, Sweden. Uppsala University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Alon Lavie</author>
</authors>
<title>Parser combination by reparsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers,</booktitle>
<pages>129--132</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="2968" citStr="Sagae and Lavie (2006)" startWordPosition="442" endWordPosition="445">ng treebank annotation styles into a common style, which later developed into the HamleDT harmonized treebank collection (Zeman et al., 2012). McDonald et al. (2011) applied delexicalized transfer in a setting with multiple source treebanks available, finding that the problem of selecting the best source treebank without access to a target language treebank for evaluation is non-trivial. They combined all source treebanks by concatenating them but noted that this yields worse results than using only the best source treebank. An alternative is the (monolingual) parse tree combination method of Sagae and Lavie (2006), who apply several independent parsers to the input sentence and combine the resulting parse trees using a maximum spanning tree algorithm. Surdeanu and Manning (2010) enrich tree combination with weighting, assigning each parser a weight based on its Unlabelled Attachment Score (UAS). In our work, we introduce an extension of this method to a crosslingual setting by combining parsers for different languages and using sourcetarget language similarity to weight them. Several authors (Naseem et al., 2012; Søgaard and Wulff, 2012; T¨ackstr¨om et al., 2013b) employed WALS (Dryer and Haspelmath, 2</context>
</contexts>
<marker>Sagae, Lavie, 2006</marker>
<rawString>Kenji Sagae and Alon Lavie. 2006. Parser combination by reparsing. In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers, pages 129–132. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Søgaard</author>
<author>Julie Wulff</author>
</authors>
<title>An empirical study of non-lexical extensions to delexicalized transfer.</title>
<date>2012</date>
<booktitle>In COLING (Posters),</booktitle>
<pages>1181--1190</pages>
<contexts>
<context position="3501" citStr="Søgaard and Wulff, 2012" startWordPosition="526" endWordPosition="529">n alternative is the (monolingual) parse tree combination method of Sagae and Lavie (2006), who apply several independent parsers to the input sentence and combine the resulting parse trees using a maximum spanning tree algorithm. Surdeanu and Manning (2010) enrich tree combination with weighting, assigning each parser a weight based on its Unlabelled Attachment Score (UAS). In our work, we introduce an extension of this method to a crosslingual setting by combining parsers for different languages and using sourcetarget language similarity to weight them. Several authors (Naseem et al., 2012; Søgaard and Wulff, 2012; T¨ackstr¨om et al., 2013b) employed WALS (Dryer and Haspelmath, 2013) to estimate source-target language similarity for delexicalized transfer, focusing on genealogy distance and word-order features. Søgaard and Wulff (2012) also introduced weighting into the treebank concatenation approach, using a POS ngram model trained on a target-language corpus 243 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 243–249, Beijing, China, July 26-31, 2015. c�2015 Associa</context>
</contexts>
<marker>Søgaard, Wulff, 2012</marker>
<rawString>Anders Søgaard and Julie Wulff. 2012. An empirical study of non-lexical extensions to delexicalized transfer. In COLING (Posters), pages 1181–1190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Christopher D Manning</author>
</authors>
<title>Ensemble models for dependency parsing: Cheap and good?</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, HLT ’10,</booktitle>
<pages>649--652</pages>
<publisher>ACL.</publisher>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="3136" citStr="Surdeanu and Manning (2010)" startWordPosition="468" endWordPosition="472">1) applied delexicalized transfer in a setting with multiple source treebanks available, finding that the problem of selecting the best source treebank without access to a target language treebank for evaluation is non-trivial. They combined all source treebanks by concatenating them but noted that this yields worse results than using only the best source treebank. An alternative is the (monolingual) parse tree combination method of Sagae and Lavie (2006), who apply several independent parsers to the input sentence and combine the resulting parse trees using a maximum spanning tree algorithm. Surdeanu and Manning (2010) enrich tree combination with weighting, assigning each parser a weight based on its Unlabelled Attachment Score (UAS). In our work, we introduce an extension of this method to a crosslingual setting by combining parsers for different languages and using sourcetarget language similarity to weight them. Several authors (Naseem et al., 2012; Søgaard and Wulff, 2012; T¨ackstr¨om et al., 2013b) employed WALS (Dryer and Haspelmath, 2013) to estimate source-target language similarity for delexicalized transfer, focusing on genealogy distance and word-order features. Søgaard and Wulff (2012) also int</context>
</contexts>
<marker>Surdeanu, Manning, 2010</marker>
<rawString>Mihai Surdeanu and Christopher D. Manning. 2010. Ensemble models for dependency parsing: Cheap and good? In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, HLT ’10, pages 649–652, Stroudsburg, PA, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Token and type constraints for cross-lingual part-of-speech tagging.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<pages>1--1</pages>
<marker>T¨ackstr¨om, Das, Petrov, McDonald, Nivre, 2013</marker>
<rawString>Oscar T¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan McDonald, and Joakim Nivre. 2013a. Token and type constraints for cross-lingual part-of-speech tagging. Transactions of the Association for Computational Linguistics, 1:1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Target language adaptation of discriminative transfer parsers.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT 2013,</booktitle>
<pages>1061--1071</pages>
<marker>T¨ackstr¨om, McDonald, Nivre, 2013</marker>
<rawString>Oscar T¨ackstr¨om, Ryan McDonald, and Joakim Nivre. 2013b. Target language adaptation of discriminative transfer parsers. In Proceedings of NAACL-HLT 2013, pages 1061–1071.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Zeman</author>
<author>Philip Resnik</author>
</authors>
<title>Crosslanguage parser adaptation between related languages.</title>
<date>2008</date>
<booktitle>In IJCNLP 2008 Workshop on NLP for Less Privileged Languages,</booktitle>
<pages>35--42</pages>
<location>Hyderabad,</location>
<contexts>
<context position="2191" citStr="Zeman and Resnik (2008)" startWordPosition="326" endWordPosition="329">ge. As a solution, we present a language similarity measure based on KL divergence (Kullback and Leibler, 1951) of distributions of coarse POS tag trigrams in POS-tagged corpora, which we call KLcpos3. The measure has been designed and tuned specifically for multilingual delexicalized parser transfer, and it often succeeds in selecting the best source treebank in a single-source setting, as well as in appropriately weighting the source treebanks by similarity to the target language in a multi-source parse tree combination approach. 2 Related Work Delexicalized parser transfer was conceived by Zeman and Resnik (2008), who also introduced two important preprocessing steps – mapping treebank-specific POS tagsets to a common set using Interset (Zeman, 2008), and harmonizing treebank annotation styles into a common style, which later developed into the HamleDT harmonized treebank collection (Zeman et al., 2012). McDonald et al. (2011) applied delexicalized transfer in a setting with multiple source treebanks available, finding that the problem of selecting the best source treebank without access to a target language treebank for evaluation is non-trivial. They combined all source treebanks by concatenating th</context>
</contexts>
<marker>Zeman, Resnik, 2008</marker>
<rawString>Daniel Zeman and Philip Resnik. 2008. Crosslanguage parser adaptation between related languages. In IJCNLP 2008 Workshop on NLP for Less Privileged Languages, pages 35–42, Hyderabad, India. Asian Federation of Natural Language Processing, International Institute of Information Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Zeman</author>
<author>David Mareˇcek</author>
<author>Martin Popel</author>
<author>Loganathan Ramasamy</author>
<author>Jan ˇStˇep´anek</author>
<author>Zdenˇek ˇZabokrtsk´y</author>
<author>Jan Hajiˇc</author>
</authors>
<title>HamleDT: To parse or not to parse?</title>
<date>2012</date>
<booktitle>In Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12),</booktitle>
<publisher>ELRA.</publisher>
<location>Istanbul, Turkey,</location>
<marker>Zeman, Mareˇcek, Popel, Ramasamy, ˇStˇep´anek, ˇZabokrtsk´y, Hajiˇc, 2012</marker>
<rawString>Daniel Zeman, David Mareˇcek, Martin Popel, Loganathan Ramasamy, Jan ˇStˇep´anek, Zdenˇek ˇZabokrtsk´y, and Jan Hajiˇc. 2012. HamleDT: To parse or not to parse? In Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12), Istanbul, Turkey, May. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Zeman</author>
</authors>
<title>Reusable tagset conversion using tagset drivers.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>213--218</pages>
<location>Marrakech, Morocco. ELRA.</location>
<contexts>
<context position="2331" citStr="Zeman, 2008" startWordPosition="348" endWordPosition="349">rams in POS-tagged corpora, which we call KLcpos3. The measure has been designed and tuned specifically for multilingual delexicalized parser transfer, and it often succeeds in selecting the best source treebank in a single-source setting, as well as in appropriately weighting the source treebanks by similarity to the target language in a multi-source parse tree combination approach. 2 Related Work Delexicalized parser transfer was conceived by Zeman and Resnik (2008), who also introduced two important preprocessing steps – mapping treebank-specific POS tagsets to a common set using Interset (Zeman, 2008), and harmonizing treebank annotation styles into a common style, which later developed into the HamleDT harmonized treebank collection (Zeman et al., 2012). McDonald et al. (2011) applied delexicalized transfer in a setting with multiple source treebanks available, finding that the problem of selecting the best source treebank without access to a target language treebank for evaluation is non-trivial. They combined all source treebanks by concatenating them but noted that this yields worse results than using only the best source treebank. An alternative is the (monolingual) parse tree combina</context>
</contexts>
<marker>Zeman, 2008</marker>
<rawString>Daniel Zeman. 2008. Reusable tagset conversion using tagset drivers. In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC 2008), pages 213–218, Marrakech, Morocco. ELRA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>