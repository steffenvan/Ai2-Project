<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.9978525">
Mining a comparable text corpus for a Vietnamese - French
statistical machine translation system
</title>
<author confidence="0.981015">
Thi-Ngoc-Diep Do *,**, Viet-Bac Le *, Brigitte Bigi*,
Laurent Besacier*, Eric Castelli**
</author>
<affiliation confidence="0.967999">
*LIG Laboratory, CNRS/UMR-5217, Grenoble, France
</affiliation>
<address confidence="0.709301">
** MICA Center, CNRS/UMI-2954, Hanoi, Vietnam
</address>
<email confidence="0.998875">
thi-ngoc-diep.do@imag.fr
</email>
<sectionHeader confidence="0.995639" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998845333333333">
This paper presents our first attempt at con-
structing a Vietnamese-French statistical
machine translation system. Since Vietnam-
ese is an under-resourced language, we con-
centrate on building a large Vietnamese-
French parallel corpus. A document align-
ment method based on publication date, spe-
cial words and sentence alignment result is
proposed. The paper also presents an appli-
cation of the obtained parallel corpus to the
construction of a Vietnamese-French statis-
tical machine translation system, where the
use of different units for Vietnamese (sylla-
bles, words, or their combinations) is dis-
cussed.
</bodyText>
<sectionHeader confidence="0.998998" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999850491525424">
Over the past fifty years of development, ma-
chine translation (MT) has obtained good results
when applied to several pairs of languages such
as English, French, German, Japanese, etc. How-
ever, for under-resourced languages, it still re-
mains a big gap. For instance, although
Vietnamese is the 14th widely-used language in
the world, research on MT for Vietnamese is
very rare.
The earliest MT system for Vietnamese is the
system from the Logos Corporation, developed
as an English-Vietnamese system for translating
aircraft manuals during the 1970s (Hutchins,
2001). Until now, in Vietnam, there are only four
research groups working on MT for Vietnamese-
English (Ho, 2005). However the results are still
modest.
MT research on Vietnamese-French occurs
even more rarely. Doan (2001) proposed a trans-
lation module for Vietnamese within ITS3, a
multilingual MT system based on the classical
analysis-transfer-generation approach. Nguyen
(2006) worked on Vietnamese language and
Vietnamese-French text alignment. But no com-
plete MT system for this pair of languages has
been published so far.
There are many approaches for MT: rule-based
(direct translation, interlingua-based, transfer-
based), corpus-based (statistical, example-based)
as well as hybrid approaches. We focus on build-
ing a Vietnamese-French statistical machine
translation (SMT) system. Such an approach re-
quires a parallel bilingual corpus for source and
target languages. Using this corpus, we build a
statistical translation model for source/target lan-
guages and a statistical language model for target
language. Then the two models and a search
module are used to decode the best translation
(Brown et al., 1993; Koehn et al., 2003).
Thus, the first task is to build a large parallel
bilingual text corpus. This corpus can be de-
scribed as a set of bilingual sentence pairs. At the
moment, such a large parallel corpus for Viet-
namese-French is unavailable. (Nguyen, 2006)
presents a Vietnamese-French parallel corpus of
law and economics documents. Our SMT system
was trained using Vietnamese-French news cor-
pus created by mining a comparable bilingual
text corpus from the Web.
Section 2 presents the general methodology of
mining a comparable text corpus. We present an
overview of document alignment methods and
sentence alignment methods, and discuss the
document alignment method we utilized, which
is based on publishing date, special words, and
sentence alignment results. Section 3 describes
our experiments in automatically mining a multi-
lingual news website to create a Vietnamese-
French parallel text corpus. Section 4 presents
</bodyText>
<note confidence="0.9378815">
Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 165–172,
Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.998431">
165
</page>
<bodyText confidence="0.988153869565217">
our application to rapidly build Vietnamese-
French SMT systems using the obtained parallel
corpus, where the use of different units for Viet-
namese (syllables, words, or their combination) is
discussed. Section 5 concludes and discusses fu-
ture work.
2 Mining a comparable text corpus
In (Munteanu and Daniel Marcu, 2006), the au-
thors present a method for extracting parallel
sub-sentential fragments from comparable bilin-
gual corpora. However this method is in need of
an initial parallel bilingual corpus, which is not
available for the pair of language Vietnamese-
French (in the news domain).
The overall process of mining a bilingual text
corpus which is used in a SMT system typically
takes five following steps (Koehn, 2005): raw
data collection, document alignment, sentence
splitting, tokenization and sentence alignment.
This section presents the two main steps: docu-
ment alignment and sentence alignment. We also
discuss the proposed document alignment
method.
</bodyText>
<subsectionHeader confidence="0.994802">
2.1 Document alignment
</subsectionHeader>
<bodyText confidence="0.999760533333333">
Let S1 be set of documents in language L1; let S2
be set of documents in language L2. Extracting
parallel documents or aligning documents from
the two sets S1, S2 can be seen as finding the
translation document D2 (in the set S2) of a
document D1 (in the set S1). We call this pair of
documents D1-D2 a parallel document pair
(PDP).
For collecting bilingual text data for the two
sets S1, S2, the Web is an ideal source as it is
large, free and available (Kilgarriff and Grefen-
stette, 2003). For this kind of data, various meth-
ods to align documents have been proposed.
Documents can be simply aligned based on the
anchor link, the clue in URL (Kraaij et al., 2003)
or the web page structure (Resnik and Smith,
2003). However, this information is not always
available or trustworthy. The titles of documents
D1, D2 can also be used (Yang and Li, 2002), but
sometimes they are completely different.
Another useful source of information is invari-
ant words, such as named entities, dates, and
numbers, which are often common in news data.
We call these words special words. (Patry and
Langlais, 2005) used numbers, punctuation, and
entity names to measure the parallelism between
two documents. The order of this information in
document is used as an important criterion. How-
ever, this order is not always respected in a PDP
(see an example in Table 1).
</bodyText>
<table confidence="0.99811105">
French document Vietnamese document
Selon l&apos;Administration Trong so gdn 2,8 trieu
nationale du tourisme, les lưgt khách quoc to ñen Viet
voyageurs en provenance de Nam tir ñau năm ñen nay,
l&apos;Asie du Nord-Est (Japon, lưong khách ñen bang
République de Corée,...) ñư6ng hàng không van
représentent 33%, de l&apos;Eu- chiem chic ñao voi khodng
rope, 16%, de l&apos;Amérique 78%.
du Nord, 13%, d&apos;Australie ðieu này cho thiiy, dòng
et de Nouvelle-Zélande, 6%. khách du lich chat lư(Yng
En outre, depuis le début cao ñin Viet Nam tăng
de cette année, environ 2,8 nhanh.
millions de touristes étran- Theo thong kê thi khách
gers ont fait le tour du Viet- quoc to vào Viet Nam cho
nam, 78% d&apos;eux sont venus thay khách ðông Bac Á
par avion. (Nhat Bdn, Hàn Quoc)
Cela témoigne d&apos;un af- chiem toi 33%, châu Âu
flux des touristes riches au chiem 16%, Bac My 13%,
Vietnam.... Ôxtrâylia và Niu Dilân
chiem 6%....
</table>
<tableCaption confidence="0.9970255">
Table 1. An example of a French-Vietnamese
parallel document pair in our corpus.
</tableCaption>
<subsectionHeader confidence="0.999462">
2.2 Sentence alignment
</subsectionHeader>
<bodyText confidence="0.9972908">
From a PDP D1-D2, the sentence alignment
process identifies parallel sentence pairs (PSPs)
between two documents D1 and D2. For each
D1-D2, we have a set SenAlignmentD1-D2 of
PSPs.
</bodyText>
<equation confidence="0.9777492">
SenAlignmentD1-D2 = {“sen1-sen2” |sen1 is
zero/one/many sentence(s) in document D1,
sen2 is zero/one/many sentence(s) in docu-
ment D2, sen1-sen2 is considered as a
PSP}.
</equation>
<bodyText confidence="0.999513352941176">
We call a PSP sen1-sen2 alignment type m:n
when sen1 contains m consecutive sentences and
sen2 contains n consecutive sentences.
Several automatic sentence alignment ap-
proaches have been proposed based on sentence
length (Brown et al., 1991) and lexical informa-
tion (Kay and Roscheisen, 1993). A hybrid ap-
proach is presented in (Gale and Church, 1993)
whose basic hypothesis is that “longer sentences
in one language tend to be translated into longer
sentences in the other language, and shorter sen-
tences tend to be translated into shorter sen-
tences”. Some toolkits such as Hunalign1 and
Vanilla2 implement these approaches. However,
they tend to work best when documents D1, D2
contain few sentence deletions and insertions,
and mainly contain PSPs of type 1:1.
</bodyText>
<footnote confidence="0.9993475">
1 http://mokk.bme.hu/resources/hunalign
2 http://nl.ijs.si/telri/Vanilla/
</footnote>
<page confidence="0.998497">
166
</page>
<bodyText confidence="0.9996044">
Ma (2006) provides an open source software
called Champollion1 to solve this limitation.
Champollion permits alignment type m:n (m, n =
0,1,2,3,4), so the length of sentence does not play
an important role. Champollion uses also lexical
information (lexemes, stop words, bilingual dic-
tionary, etc.) to align sentences. Champollion can
easily be adapted to new pairs of languages.
Available language pairs in Champollion are
English-Arabic and English-Chinese (Ma, 2006).
</bodyText>
<subsectionHeader confidence="0.994457">
2.3 Our document alignment method
</subsectionHeader>
<bodyText confidence="0.950289470588235">
Figure 1 describes our methodology for docu-
ment alignment. For each document D1 in the set
S1, we find the aligned document D2 in the set
S2.
We propose to use publishing date, special
words, and the results of sentence alignment to
discover PDPs. First, the publishing date is used
to reduce the number of possible documents D2.
Then we use a filter based on special words con-
tained in the documents to determine the candi-
date documents D2. Finally, we eliminate
candidates in D2 based on the combination of
document length information and lexical infor-
mation, which are extracted from the results of
sentence alignment.
Filter by publishing date
(±n days)
</bodyText>
<equation confidence="0.642801">
S2’
Filter by special words
(numbers+ named entities)
S2”
Align sentences
{SenAlignmentD 1- D2}, D2 ∈ S2 ’ ’
Filter SenAlignment
(use α, β)
{D1-D2}+{sen1 -sen2}
</equation>
<figureCaption confidence="0.963468">
Figure 1. Our document alignment scheme.
</figureCaption>
<bodyText confidence="0.908606">
2.3.1 The first filter: publishing date
We assume that the document D2 is translated
and published at most n days after the publishing
date of the original document. We do not know
whether D1 or D2 is the original document, so
</bodyText>
<footnote confidence="0.814115">
1 http://champollion.sourceforge.net
</footnote>
<bodyText confidence="0.999609">
we assume that D2 is published n days before or
after D1. After filtering by publishing date crite-
rion, we obtain a subset S2’ containing possible
documents D2.
</bodyText>
<subsectionHeader confidence="0.421366">
2.3.2 The second filter: special words
</subsectionHeader>
<bodyText confidence="0.9978924375">
In our case, the special words are numbers and
named entities. Not only numbers (0-9) but also
attached symbols (‘$’, ‘%’, ‘‰’, ‘,’, ‘.’...) are
extracted from documents, for example:
“12.000$”; “13,45”; “50%”;... Named entities
are specified by one or several words in which
the first letter of each word is upper case, e.g.
“Paris”, “Nations Unies” in French.
While named entities in language L1 are usu-
ally translated into the corresponding names in
language L2, in some cases the named entities in
L1 (such as personal names or organization
names) do not change in L2. In particular, many
Vietnamese personal names are translated into
other languages by removal of diacritical marks
(see examples in Table 2).
</bodyText>
<table confidence="0.999048727272727">
French Vietnamese Vietnamese
-Removed
diacritic
Changed Nations Liên Hap Lien Hop
Unies Quoc Quoc
France Pháp Phap
Not ASEAN ASEAN ASEAN
changed
Nong Duc Nông Duc Nong Duc
Manh Manh Manh
Dien Bien Dien Biên Dien Bien
</table>
<tableCaption confidence="0.944947">
Table 2. Some examples of named entities in
French-Vietnamese.
</tableCaption>
<bodyText confidence="0.999953105263158">
All special words are extracted from document
D1. This gives a list of special words w1,w2,...wn.
For each special word, we search in the set S2’
documents D2 which contain this special word.
For each word, we obtain a list of documents D2.
The document D2 which has the biggest number
of appearance in all lists is chosen. It is the
document containing the highest number of spe-
cial words. We can find zero, one or several
documents which are satisfactory. We call this
set of documents set S2” (see in Figure 2).
The way that we use special words is different
from the way used in (Patry and Langlais, 2005).
We do not use punctuation as special words. We
use the attached symbols (‘$’, ‘%’, ‘‰’, ...) with
the number. Furthermore, in our method, the or-
der of special words in documents is not impor-
tant, and if a special word appears several times
in a document, it does not affect the result.
</bodyText>
<equation confidence="0.741331">
S1
D1 D2
S2
</equation>
<page confidence="0.865594">
167
</page>
<figureCaption confidence="0.998494">
Figure 2. Using special words to filter documents
</figureCaption>
<bodyText confidence="0.794705">
D2.
</bodyText>
<subsectionHeader confidence="0.516123">
2.3.3 The third filter: sentence alignments
</subsectionHeader>
<bodyText confidence="0.999875">
As mentioned in section 2.3.2, for each document
D1, we discover a set S2’’, which contains zero,
one or several documents D2. When we continue
to align sentences for each PDP D1-D2, we get a
lot of low quality PSPs. The results of sentence
alignment allow us to further filter the documents
D2.
After aligning sentences, we have a set of
PSPs, SenAlignmentD1-D2, for each PDP D1-D2.
We add two rules to filter documents D2.
When D1-D2 is not a true PDP, it is hard to
find out PSPs. So we note the number of PSPs in
the set SenAlignmentD1-D2 by
card(SenAlignmentD1-D2). The number of sentence
pairs which can not find their alignment partner
(when sen1 or sen2 is “null”) is noted by
nbr_omitted(SenAlignmentD1-D2).
When nbr omitted(SenAlignmentD1-D2)&gt;a , this
card(SenAlignment
PDP D1-D2 will be eliminated.
This first rule also deals with the problem of
document length, sentence deletions and sentence
insertions.
The second rule makes use of lexical informa-
tion. For each PSP, we add two scores xL1 and xL2
for sen1 and sen2.
Translated words are words having translation
equivalents in the other sentence. In this rule, we
do not take into account the stop words. Table 3
shows an example for calculating two scores xL1
and xL2 for a PSP.
In the second rule, when all PSPs in Se-
nAlignmentD1-D2 have two scores xL1 and xL2 that
are both smaller than β, this PDP D1-D2 will be
eliminated. This rule removes the low quality
PDP which creates a set of low quality PSPs.
</bodyText>
<table confidence="0.99943295">
sen1 (in French) : ils ont échangé leurs opinions pour
parvenir à la signature de documents constituant la base
du développement et de l&apos; intensification de la coopéra-
tion en économie en commerce et en investissement ainsi
que celles dans la culture le sport et le tourisme entre les
deux pays
sen2 (in Vietnamese) : hai bên ñã tien_hành trao_ñoi ñi
ký_ket các văn_ban làm cơ_s&amp; cho viec ma_rong và
tăng_cưrrng quan_h� h�p_tác kinh_t� thương_m�i
ñ�u_tư văn_hoá th�_thao và du_lich gifra hai nưrrc
Translated words :
“échan-
ger:trao_ñoi” ;“base:cơ_sa”,“intensification:tăng_cưrrn
g” ;“coopération:hgp_tác”,“économie:kinh_te” ; inves-
tissement:ñju_tư”,“sport:the_thao” ; “tou-
risme :du_lich” ; “pays:nưac”
Number of non-stop words in sen1 19
Number of non-stop words in sen2 21
Number of translated words 9
xL1 = 9/19=0.47 ; xL2 = 9/21=0.43
</table>
<tableCaption confidence="0.79911">
Table 3. Example for calculating two scores xL1
and xL2.
</tableCaption>
<bodyText confidence="0.999955875">
After using three filters based on information
of publishing date, special words, and the results
of sentence alignment, we have a corpus of
PDPs, and also a corpus of corresponding PSPs.
To ensure the quality of output PSPs, we can
continue to filter PSPs. For example, we can keep
only the PSPs whose scores (xL1 and xL2) are
higher than a threshold.
</bodyText>
<sectionHeader confidence="0.999928" genericHeader="introduction">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999957">
3.1 Characteristics of Vietnamese
</subsectionHeader>
<bodyText confidence="0.999785666666667">
The basic unit of the Vietnamese language is syl-
lable. In writing, syllables are separated by a
white space. One word corresponds to one or
more syllables (Nguyen, 2006). Table 4 presents
an example of a Vietnamese sentence segmented
into syllables and words.
</bodyText>
<construct confidence="0.7791791">
Vietnamese sentence: Thành pho hy vong s ñón nhan
khodng 3 trieu khách du lich nưac ngoài trong năm nay
Segmentation in syllables: Thành  |pho  |hy  |vong  |s |
ñón  |nhan  |khoang  |3  |trieu  |khách  |du  |lich  |nưbc |
ngoài  |trong  |năm  |nay
Segmentation in words: Thành_pho  |hy_vong  |s |
ñón_nhan  |khoang  |3  |trieu  |khách_du_lich |
nưbc_ngoài  |trong  |năm  |nay
Corresponding English sentence: The city is expected to
receive 3 million foreign tourists this year
</construct>
<tableCaption confidence="0.7060325">
Table 4. An example of a Vietnamese sentence
segmented into syllables and words.
</tableCaption>
<bodyText confidence="0.95321475">
In Vietnamese, words do not change their
form. Instead of conjugation for verb, noun or
adjective, Vietnamese language uses additional
words, such as “nhieng”, “các” to express the plu-
</bodyText>
<figure confidence="0.981774571428571">
D1
Extract
special words
w1...wn
S2”
{doc3,
doc5}
Choose
the max
doc1: 1 time
doc3: 3 times
doc4: 1 time
doc5: 3 times
Count
</figure>
<equation confidence="0.953614052631579">
find w1 in S2’ 4 doc1, doc3, doc5
find w2 in S2’ 4 doc3, doc4, doc5
find w3 in S2’ 4 doc3, doc5
... ...
i
words in sen
− −
− translated −
number of
−
i
words in sen
− −
number of
− −
)
D1-D2
�
xLi
</equation>
<page confidence="0.965529">
168
</page>
<bodyText confidence="0.99887025">
ral; “ñd”, “s ” to express the past tense and the
future. The syntactic functions are also deter-
mined by the order of words in the sentence
(Nguyen, 2006).
</bodyText>
<subsectionHeader confidence="0.99961">
3.2 Data collecting
</subsectionHeader>
<bodyText confidence="0.998676933333333">
In order to build a Vietnamese-French parallel
text corpus, we applied our proposed methodol-
ogy to mine a comparable text corpus from a
Vietnamese daily news website, the Vietnam
News Agency1 (VNA). This website contains
news articles written in four languages (Vietnam-
ese, English, French, and Spanish) and divided in
9 categories including “Politics - Diplomacy”,
“Society - Education”, “Business - Finance”,
“Culture - Sports”, “Science - Technology”,
“Health”, “Environment”, “Asian corner” and
“World”. However, not all of the Vietnamese
articles have been translated into the other three
languages. The distribution of the amount of data
in four languages is shown in figure 3.
</bodyText>
<figureCaption confidence="0.980763">
Figure 3. Distribution of the amount of data for
each language on VNA website.
</figureCaption>
<bodyText confidence="0.999797857142857">
Each document (i.e., article) can be obtained
via a permanent URL link from VNA. To date,
we have obtained about 121,000 documents in
four languages, which are gathered from 12 April
2006 to 14 August 2008; each document con-
tains, on average, 10 sentences, with around 30
words per sentence.
</bodyText>
<subsectionHeader confidence="0.998136">
3.3 Data pre-processing
</subsectionHeader>
<bodyText confidence="0.999920375">
We splitted the collected data into 2 sets. The
development set, designated SDEV, contained
1000 documents, was used to tune the mining
system parameters. The rest of data, designated
STRAIN, was used as a training set, where the esti-
mated parameters were applied to build the entire
corpus. We applied the following pre-process to
each set SDEV and STRAIN:
</bodyText>
<listItem confidence="0.907925">
1. Extract contents from documents.
1 http://www.vnagency.com.vn/
2. Classify documents by language (using
TextCat2, an n-gram based language identi-
fication).
3. Process and clean both Vietnamese and
</listItem>
<bodyText confidence="0.889314333333333">
French documents by using the CLIPS-Text-
Tk toolkit (LE et al., 2003): convert html to
text file, convert character code, segment
sentence, segment word. The resulting clean
corpora are S1 (for French) and S2 (for
Vietnamese).
</bodyText>
<subsectionHeader confidence="0.991343">
3.4 Parameters estimation
</subsectionHeader>
<bodyText confidence="0.999606631578947">
Our proposed document alignment method was
applied to the sets S1 and S2 extracted from the
set SDEV. To filter by publishing date, we as-
sumed that n=2.
The second filter was implemented on the set
S1 and the new set S2* which was created by re-
moving diacritical marks from the set S2 (in the
case of Vietnamese).
The sentence alignment process was imple-
mented by using data from sets S1, S2 and the
Champollion toolkit. We adapted Champollion to
Vietnamese-French by changing some parame-
ters: the ratio of French word to Vietnamese
translation word is set to 1.2, penalty for align-
ment type 1-1 is set to 1, for type 0-1 to 0.8, for
type 2-1, 1-2 and 2-2 to 0.75, and we did not use
the other types (see more in (Ma, 2006)). After
using two filters, the result data is shown in Table
5. The true PDPs were manually extracted.
</bodyText>
<table confidence="0.937475714285714">
SDEV - Number of documents: 1000
- Number of French documents: 173
- Number of Vietnamese documents: 348
- Number of true PDPs: 129
S2” - Number of found PDPs: 379
- Number of hits PDPs: 129
- Precision = 34.04% , Recall = 100%
</table>
<tableCaption confidence="0.998738">
Table 5. Result data after using two filters.
</tableCaption>
<bodyText confidence="0.9967366">
The third filter was applied in which α was set
to (0.4, 0.5, 0.6, 0.7) and R was set to (0.1, 0.15,
0.2, 0.25, 0.3, 0.35, 0.4). The precision and recall
were calculated according to our true PDPs and
the F-measure (F1 score) was estimated.
</bodyText>
<subsectionHeader confidence="0.314581">
F-measure
</subsectionHeader>
<bodyText confidence="0.302022125">
α
β 0.1 0.15 0.2 0.25 0.3 0.35 0.4
0.4 0.69 0.71 0.71 0.60 0.48 0.36 0.21
0.5 0.76 0.79 0.77 0.65 0.52 0.39 0.23
0.6 0.77 0.83 0.82 0.70 0.56 0.41 0.26
0.7 0.75 0.84 0.83 0.73 0.59 0.44 0.27
Table 6. Filter result with different values of α
and R on the SDEV.
</bodyText>
<footnote confidence="0.970029">
2 http://www.let.rug.nl/~vannoord/TextCat/
</footnote>
<page confidence="0.998655">
169
</page>
<bodyText confidence="0.996786">
From the results mentioned in Table 6, we
chose α=0.7 and β=0.15.
</bodyText>
<subsectionHeader confidence="0.946103">
3.5 Mining the entire corpus
</subsectionHeader>
<bodyText confidence="0.998832375">
ment sets according to the Moses condition (so
the number of PSPs used in the training set dif-
fers slightly between systems). All words found
are implicitly added to the vocabulary.
We applied the same methodology with the pa-
rameters estimated in section 3.4 to the set
STRAIN. The obtained corpus is presented in Table
7.
</bodyText>
<table confidence="0.998518833333333">
STRAIN - Number of documents: 120,218
- Number of French documents: 20,884
- Number of Vietnamese documents:
54,406
Entire - Number of PDPs: 12,108
corpus - Number of PSPs: 50,322
</table>
<tableCaption confidence="0.99966">
Table 7. The obtained corpus from STRAIN.
</tableCaption>
<sectionHeader confidence="0.4473095" genericHeader="method">
4 Application: a Vietnamese - French
statistical machine translation system
</sectionHeader>
<bodyText confidence="0.9999651">
With the obtained parallel corpus, we attempted
to rapidly build a SMT system for Vietnamese-
French. The system was built using the Moses
toolkit1. The Moses toolkit contains all of the
components needed to train both the translation
model and the language model. It also contains
tools for tuning these models using minimum
error rate training and for evaluating the transla-
tion result using the BLEU score (Koehn et al.,
2007).
</bodyText>
<subsectionHeader confidence="0.99964">
4.1 Preparing data
</subsectionHeader>
<bodyText confidence="0.999939090909091">
From the entire corpus, we chose 50 PDPs (351
PSPs) for developing (Dev), 50 PDPs (384 PSPs)
for testing (Tst), with the rest PDPs (49,587
PSPs) reserved for training (Trn).
Concerning the developing and testing PSPs,
we manually verified and eliminated low quality
PSPs, which produced 198 good quality PSPs for
developing and 210 good quality PSPs for test-
ing. The data used to create the language model
were extracted from 49,587 PSPs of the training
set.
</bodyText>
<subsectionHeader confidence="0.997157">
4.2 Baseline system
</subsectionHeader>
<bodyText confidence="0.999764">
We built translation systems in two translation
directions: French to Vietnamese (F4V) and
Vietnamese to French (V4F). The Vietnamese
data were segmented into either words or sylla-
bles. So we first have four translation systems.
We removed sentences longer than 100
words/syllables from the training and develop-
</bodyText>
<footnote confidence="0.922189">
1 http://www.statmt.org/moses/
</footnote>
<table confidence="0.999556814814815">
System Direction Vietnamese is Nbr of PSPs
segmented into
S1FV F4V Syllable Training: 47,081
Developing: 198
Testing: 210
S1VF V4F
S2FV F4V Word Training: 48,864
Developing: 198
Testing: 210
S2VF V4F
System Set - Nbr. of vocab Nbr. of running
Language (K) words/syllables
(K)
S1FV Trn Fr 38.6 1783.6
S 1 VF
Vn 21.9 2190.2
Dev Fr 1.8 6.3
Vn 1.2 6.9
Tst Fr 1.9 6.4
Vn 1.3 7.1
S2FV Trn Fr 39.7 1893
S2VF
Vn 33.4 1629
Dev Fr 1.8 6.3
Vn 1.5 4.8
Tst Fr 1.9 6.3
Vn 1.6 4.9
</table>
<tableCaption confidence="0.998994">
Table 8. Our four translation systems.
</tableCaption>
<bodyText confidence="0.997847">
We obtained the performance results for those
systems in Table 9. In the case of the systems
where Vietnamese was segmented into words,
the Vietnamese sentences were changed back to
syllable representation before calculating the
BLEU scores, so that all the BLEU scores evalu-
ated can be compared to each other.
</bodyText>
<table confidence="0.9956655">
S1FV S1VF S2FV S2VF
BLEU 0.40 0.31 0.40 0.30
</table>
<tableCaption confidence="0.999675">
Table 9. Evaluation of SMTs on the Tst set.
</tableCaption>
<bodyText confidence="0.999868083333333">
The BLEU scores for French to Vietnamese
translation direction are around 0.40 and the
BLEU scores for Vietnamese to French transla-
tion direction are around 0.31, which is encour-
aging as a first result. Moreover, only one
reference was used to estimate BLEU scores in
our experiments. It is also interesting to note that
segmenting Vietnamese sentences into words or
syllables does not significantly change the per-
formance for both translation directions. An ex-
ample of translation from four systems is
presented in Table 10.
</bodyText>
<page confidence="0.987653">
170
</page>
<table confidence="0.998409657894737">
Given a pair of parallel sentences
FR: selon le d6partement de gestion des travailleurs
le qatar est un march6 prometteur et
une grande quantit6 de travailleurs 6tran-
: theo cuc quan lý lao ñ ng ngoài nưac cata
ñay tiem năng và có nhu cau lbn lao
ngoài
: theo cuc quan_lý laong ngoài nưbc
_ñ
à l&apos; 6tranger
n6cessite
gers
VNsyl
là thi trưang
ñ ng nưbc
VNword
cata là thi_trưong ñay tiem_năng và có nhu_cau lbn
lao_ñ ng nưbc_ngoài
S1FV Input: FR Reference: VNsyl
Output: theo cuc quan lý lao ñ ng a nưbc
ngoài phía cata là mot thi trưang ñay tiem
năng và can mot lưong lbn lao ñ�ng nưbc
ngoài
S2FR Input: FR Reference: VNword
Output: theo thong_kê cua cuc quan_lý
lao_ñ ng ngoài nưbc cata là mot
thi_trưong ñay tiem_năng và can có su lbn
lưting lao_ñ ng nưbc_ngoài
S1VF Input: VNsyl Reference: FR
Output: selon le d6partement de gestion
des travailleurs 6trangers cata 6tait un mar-
ch6 plein de potentialit6s et aux besoins
importants travailleurs 6trangers
S2VF Input: VNword Reference: FR
Output : selon le d6partement de gestion
des travailleurs 6trangers cata march6 plein
de potentialit6s et la grande travailleurs
6trangers
</table>
<tableCaption confidence="0.996938">
Table 10 : Example of translation from systems.
</tableCaption>
<subsectionHeader confidence="0.9118275">
4.3 Combining word- and syllable-based
systems
</subsectionHeader>
<bodyText confidence="0.999697076923077">
We performed another experiment on combining
syllable and word units on the Vietnamese side.
We carried out the experiment on the Vietnamese
to French translation direction only. In fact, the
Moses toolkit supports the combination of
phrase-tables. The phrase-tables of the system
S1VF (Tsyl) and system S2VF (Tword) were used.
Another phrase-table (Tword*) was created from
the Tword, in which all words in the phrase table
were changed back into syllable representation
(in this latter case, the word segmentation infor-
mation was used during the alignment process
and the phrase table construction, while the unit
kept at the end remains the syllable). The combi-
nations of these three phrase-tables were also
created (by simple concatenation of the phrase
tables). The Vietnamese input for this experiment
was either in word or in syllable representation.
As usual, the developing set was used for tuning
the log-linear weights and the testing set was
used to estimate the BLEU score. The obtained
results are presented in Table 11. Some perform-
ances are marked as X since those combinations
of input and phrase table do not make sense (for
instance the combination of input in words and
syllable-based phrase table).
</bodyText>
<table confidence="0.9998">
Phrase-tables Input in syllable Input in word
used
Dev Tst Dev Tst
Tsyl 0.35 0.31 X X
Tword X X 0.35 0.30
Tword* 0.37 0.31 X X
Tsyl + Tword 0.35 0.31 0.36 0.30
Tsyl + Tword* 0.38 0.32 X X
Tword + Tword* 0.37 0.30 0.36 0.30
</table>
<tableCaption confidence="0.992674">
Table 11: The BLEU scores obtained from com-
</tableCaption>
<bodyText confidence="0.928651615384615">
bination of phrase-tables on Dev set and Tst set
(Vietnamese to French machine translation).
These results show that the performance can
be improved by combining information from
word and syllable representations of Vietnamese.
(BLEU improvement from 0.35 to 0.38 on the
Dev set and from 0.31 to 0.32 on the Tst set). In
the future, we will analyze more the combination
of syllable and word units for Vietnamese MT
and we will investigate the use of confusion net-
works as an MT input, which have the advantage
to keep both segmentations (word, syllable) into
a same structure.
</bodyText>
<subsectionHeader confidence="0.999502">
4.4 Comparing with Google Translate1
</subsectionHeader>
<bodyText confidence="0.999979">
Google Translate system has recently supported
Vietnamese. In most cases, it uses English as an
intermediary language. For the first comparative
evaluation, some simple tests were carried out.
Two sets of data were used: in domain data set
(the Tst set in section 4.2) and out of domain data
set. The latter was obtained from a Vietnamese-
French bilingual website2 which is not a news
website. After pre-processing and aligning manu-
ally, we obtained 100 PSPs in the out of domain
data set. In these tests, the Vietnamese data were
segmented into syllables. Both data sets were
inputted to our translation systems (S1FV, S1VF)
and the Google Translate system. The outputs of
Google Translate system were post-processed
(lowercased) and then the BLEU scores were
estimated. Table 12 presents the results of these
tests. While our system is logically better for in
domain data set, it is also slightly better than
Google for out of domain data set.
</bodyText>
<footnote confidence="0.999561">
1 http://translate.google.com
2 http://www.ambafrance-vn.org
</footnote>
<page confidence="0.982434">
171
</page>
<table confidence="0.9997835">
Direction BLEU score
Our system Google
In domain F4V 0.40 0.25
(210 PSPs)
V4F 0.31 0.16
Out of domain F4V 0.25 0.24
(100 PSPs)
V4F 0.20 0.16
</table>
<tableCaption confidence="0.999862">
Table 12: Comparing with Google Translate.
</tableCaption>
<sectionHeader confidence="0.966623" genericHeader="conclusions">
5 Conclusions and perspectives
</sectionHeader>
<bodyText confidence="0.99996192">
In this paper, we have presented our work on
mining a comparable Vietnamese-French corpus
and our first attempts at Vietnamese-French
SMT. The paper has presented our document
alignment method, which is based on publication
date, special words and sentence alignment re-
sult. The proposed method is applied to Vietnam-
ese and French news data collected from VNA.
For Vietnamese and French data, we obtained
around 12,100 parallel document pairs and
50,300 parallel sentence pairs. This is our first
Vietnamese-French parallel bilingual corpus. We
have built SMT systems using Moses. The BLEU
scores for French to Vietnamese translation sys-
tems and Vietnamese to French translation sys-
tems were 0.40 and 0.31 in turn. Moreover,
combining information from word and syllable
representations of Vietnamese can be useful to
improve the performance of Vietnamese MT sys-
tem.
In the future, we will attempt to increase the
corpus size (by using unsupervised SMT for in-
stance) and investigate further the use of different
Vietnamese lexical units (syllable, word) in a MT
system.
</bodyText>
<sectionHeader confidence="0.999261" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999857050632911">
Brown, Peter F., Jennifer C. Lai and Robert L. Mer-
cer. 1991. Aligning sentences in parallel corpora.
Proceedings of 47th Annual Meeting of the Asso-
ciation for Computational Linguistics.
Brown, Peter F., Stephen A. Della Pietra, Vincent J.
Della Pietra and Robert L. Mercer. 1993. The
Mathematics of Statistical Machine Translation:
Parameter Estimation. Computational Linguistics.
Vol. 19, no. 2.
Doan, Nguyen Hai. 2001. Generation of Vietnamese
for French-Vietnamese and English-Vietnamese
Machine Translation. ACL, Proceedings of the 8th
European workshop on Natural Language Genera-
tion.
Gale, William A. and Kenneth W. Church. 1993. A
program for aligning sentences in bilingual cor-
pora. Proceedings of the 29th annual meeting on
Association for Computational Linguistics.
Ho, Tu Bao. 2005. Current Status of Machine Trans-
lation Research in Vietnam Towards Asian wide
multi language machine translation project. Viet-
namese Language and Speech Processing Work-
shop.
Hutchins, W.John. 2001. Machine translation over
fifty years. Histoire, epistemologie, langage: HEL,
ISSN 0750-8069, Vol. 23, Nº 1, 2001 , pages. 7-32.
Kay, Martin and Martin Roscheisen. 1993. Text -
translation alignment. Association for Computa-
tional Linguistics.
Kilgarriff, Adam and Gregory Grefenstette. 2003.
Introduction to the Special Issue on the Web as
Corpus. Computational Linguistics, volume 29.
Koehn, Philipp, Franz Josef Och and Daniel Marcu.
2003. Statistical phrase-based translation. Confer-
ence of the North American Chapter of the Asso-
ciation for Computational Linguistics on Human
Language Technology - Volume 1.
Koehn, Philipp. 2005. Europarl: A Parallel Corpus
for Statistical Machine Translation. Machine
Translation Summit.
Koehn, Philipp, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Richard Zens, Marcello Federico,
Nicola Bertoldi, Brooke Cowan, Wade Shen and
Christine Moran. 2007. Moses: Open Source Tool-
kit for Statistical Machine Translation. Proceedings
of the ACL.
Kraaij, Wessel, Jian-Yun Nie and Michel Simard.
2003. Embedding web-based statistical translation
models in cross-language information retrieval.
Computational Linguistics, Volume 29 , Issue 3.
LE, Viet Bac, Brigitte Bigi, Laurent Besacier and Eric
Castelli. 2003. Using the Web for fast language
model construction in minority languages. Eu-
rospeech&apos;03.
Ma, Xiaoyi. 2006. Champollion: A Robust Parallel
Text Sentence Aligner. LREC: Fifth International
Conference on Language Resources and Evalua-
tion.
Munteanu, Dragos Stefan and Daniel Marcu. 2006.
Extracting parallel sub-sentential fragments from
non-parallel corpora . 44th annual meeting of the
Association for Computational Linguistics
Nguyen, Thi Minh Huyen. 2006. Outils et ressources
linguistiques pour l&apos;alignement de textes multilin-
gues français-vietnamiens. Thèse présentée pour
l’obtention du titre de Docteur de l’Université Hen-
ri Poincaré, Nancy 1 en Informatique.
Patry, Alexandre and Philippe Langlais. 2005. Para-
docs: un système d’identification automatique de
documents parallèles. 12e Conference sur le Trai-
tement Automatique des Langues Naturelles.
Dourdan, France.
Resnik, Philip and Noah A. Smith. 2003. The Web as
a Parallel Corpus. Computational Linguistics.
Yang, Christopher C. and Kar Wing Li. 2002. Mining
English/Chinese Parallel Documents from the
World Wide Web. Proceedings of the 11th Interna-
tional World Wide Web Conference, Honolulu,
USA.
</reference>
<page confidence="0.997879">
172
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.471011">
<title confidence="0.9829535">Mining a comparable text corpus for a Vietnamese statistical machine translation system</title>
<author confidence="0.9072295">Viet-Bac Le_</author>
<author confidence="0.9072295">Brigitte Laurent Besacier</author>
<author confidence="0.9072295">Eric</author>
<affiliation confidence="0.862808">LIG Laboratory, CNRS/UMR-5217, Grenoble,</affiliation>
<address confidence="0.988673">MICA Center, CNRS/UMI-2954, Hanoi, Vietnam</address>
<email confidence="0.99121">thi-ngoc-diep.do@imag.fr</email>
<abstract confidence="0.980269875">This paper presents our first attempt at constructing a Vietnamese-French statistical machine translation system. Since Vietnamese is an under-resourced language, we concentrate on building a large Vietnamese- French parallel corpus. A document alignment method based on publication date, special words and sentence alignment result is proposed. The paper also presents an application of the obtained parallel corpus to the construction of a Vietnamese-French statistical machine translation system, where the use of different units for Vietnamese (syllables, words, or their combinations) is discussed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Jennifer C Lai</author>
<author>Robert L Mercer</author>
</authors>
<title>Aligning sentences in parallel corpora.</title>
<date>1991</date>
<booktitle>Proceedings of 47th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="7641" citStr="Brown et al., 1991" startWordPosition="1203" endWordPosition="1206">pus. 2.2 Sentence alignment From a PDP D1-D2, the sentence alignment process identifies parallel sentence pairs (PSPs) between two documents D1 and D2. For each D1-D2, we have a set SenAlignmentD1-D2 of PSPs. SenAlignmentD1-D2 = {“sen1-sen2” |sen1 is zero/one/many sentence(s) in document D1, sen2 is zero/one/many sentence(s) in document D2, sen1-sen2 is considered as a PSP}. We call a PSP sen1-sen2 alignment type m:n when sen1 contains m consecutive sentences and sen2 contains n consecutive sentences. Several automatic sentence alignment approaches have been proposed based on sentence length (Brown et al., 1991) and lexical information (Kay and Roscheisen, 1993). A hybrid approach is presented in (Gale and Church, 1993) whose basic hypothesis is that “longer sentences in one language tend to be translated into longer sentences in the other language, and shorter sentences tend to be translated into shorter sentences”. Some toolkits such as Hunalign1 and Vanilla2 implement these approaches. However, they tend to work best when documents D1, D2 contain few sentence deletions and insertions, and mainly contain PSPs of type 1:1. 1 http://mokk.bme.hu/resources/hunalign 2 http://nl.ijs.si/telri/Vanilla/ 166</context>
</contexts>
<marker>Brown, Lai, Mercer, 1991</marker>
<rawString>Brown, Peter F., Jennifer C. Lai and Robert L. Mercer. 1991. Aligning sentences in parallel corpora. Proceedings of 47th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<date>1993</date>
<journal>The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics.</journal>
<volume>19</volume>
<contexts>
<context position="2609" citStr="Brown et al., 1993" startWordPosition="381" endWordPosition="384">es has been published so far. There are many approaches for MT: rule-based (direct translation, interlingua-based, transferbased), corpus-based (statistical, example-based) as well as hybrid approaches. We focus on building a Vietnamese-French statistical machine translation (SMT) system. Such an approach requires a parallel bilingual corpus for source and target languages. Using this corpus, we build a statistical translation model for source/target languages and a statistical language model for target language. Then the two models and a search module are used to decode the best translation (Brown et al., 1993; Koehn et al., 2003). Thus, the first task is to build a large parallel bilingual text corpus. This corpus can be described as a set of bilingual sentence pairs. At the moment, such a large parallel corpus for Vietnamese-French is unavailable. (Nguyen, 2006) presents a Vietnamese-French parallel corpus of law and economics documents. Our SMT system was trained using Vietnamese-French news corpus created by mining a comparable bilingual text corpus from the Web. Section 2 presents the general methodology of mining a comparable text corpus. We present an overview of document alignment methods a</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Brown, Peter F., Stephen A. Della Pietra, Vincent J. Della Pietra and Robert L. Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics. Vol. 19, no. 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nguyen Hai Doan</author>
</authors>
<title>Generation of Vietnamese for French-Vietnamese and English-Vietnamese Machine Translation.</title>
<date>2001</date>
<booktitle>ACL, Proceedings of the 8th European workshop on Natural Language Generation.</booktitle>
<contexts>
<context position="1713" citStr="Doan (2001)" startWordPosition="252" endWordPosition="253">apanese, etc. However, for under-resourced languages, it still remains a big gap. For instance, although Vietnamese is the 14th widely-used language in the world, research on MT for Vietnamese is very rare. The earliest MT system for Vietnamese is the system from the Logos Corporation, developed as an English-Vietnamese system for translating aircraft manuals during the 1970s (Hutchins, 2001). Until now, in Vietnam, there are only four research groups working on MT for VietnameseEnglish (Ho, 2005). However the results are still modest. MT research on Vietnamese-French occurs even more rarely. Doan (2001) proposed a translation module for Vietnamese within ITS3, a multilingual MT system based on the classical analysis-transfer-generation approach. Nguyen (2006) worked on Vietnamese language and Vietnamese-French text alignment. But no complete MT system for this pair of languages has been published so far. There are many approaches for MT: rule-based (direct translation, interlingua-based, transferbased), corpus-based (statistical, example-based) as well as hybrid approaches. We focus on building a Vietnamese-French statistical machine translation (SMT) system. Such an approach requires a para</context>
</contexts>
<marker>Doan, 2001</marker>
<rawString>Doan, Nguyen Hai. 2001. Generation of Vietnamese for French-Vietnamese and English-Vietnamese Machine Translation. ACL, Proceedings of the 8th European workshop on Natural Language Generation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
</authors>
<title>A program for aligning sentences in bilingual corpora.</title>
<date>1993</date>
<booktitle>Proceedings of the 29th annual meeting on Association for Computational Linguistics.</booktitle>
<contexts>
<context position="7751" citStr="Gale and Church, 1993" startWordPosition="1222" endWordPosition="1225">airs (PSPs) between two documents D1 and D2. For each D1-D2, we have a set SenAlignmentD1-D2 of PSPs. SenAlignmentD1-D2 = {“sen1-sen2” |sen1 is zero/one/many sentence(s) in document D1, sen2 is zero/one/many sentence(s) in document D2, sen1-sen2 is considered as a PSP}. We call a PSP sen1-sen2 alignment type m:n when sen1 contains m consecutive sentences and sen2 contains n consecutive sentences. Several automatic sentence alignment approaches have been proposed based on sentence length (Brown et al., 1991) and lexical information (Kay and Roscheisen, 1993). A hybrid approach is presented in (Gale and Church, 1993) whose basic hypothesis is that “longer sentences in one language tend to be translated into longer sentences in the other language, and shorter sentences tend to be translated into shorter sentences”. Some toolkits such as Hunalign1 and Vanilla2 implement these approaches. However, they tend to work best when documents D1, D2 contain few sentence deletions and insertions, and mainly contain PSPs of type 1:1. 1 http://mokk.bme.hu/resources/hunalign 2 http://nl.ijs.si/telri/Vanilla/ 166 Ma (2006) provides an open source software called Champollion1 to solve this limitation. Champollion permits </context>
</contexts>
<marker>Gale, Church, 1993</marker>
<rawString>Gale, William A. and Kenneth W. Church. 1993. A program for aligning sentences in bilingual corpora. Proceedings of the 29th annual meeting on Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tu Bao Ho</author>
</authors>
<title>Current Status of Machine Translation Research in Vietnam Towards Asian wide multi language machine translation project. Vietnamese Language and Speech Processing Workshop.</title>
<date>2005</date>
<contexts>
<context position="1604" citStr="Ho, 2005" startWordPosition="236" endWordPosition="237">MT) has obtained good results when applied to several pairs of languages such as English, French, German, Japanese, etc. However, for under-resourced languages, it still remains a big gap. For instance, although Vietnamese is the 14th widely-used language in the world, research on MT for Vietnamese is very rare. The earliest MT system for Vietnamese is the system from the Logos Corporation, developed as an English-Vietnamese system for translating aircraft manuals during the 1970s (Hutchins, 2001). Until now, in Vietnam, there are only four research groups working on MT for VietnameseEnglish (Ho, 2005). However the results are still modest. MT research on Vietnamese-French occurs even more rarely. Doan (2001) proposed a translation module for Vietnamese within ITS3, a multilingual MT system based on the classical analysis-transfer-generation approach. Nguyen (2006) worked on Vietnamese language and Vietnamese-French text alignment. But no complete MT system for this pair of languages has been published so far. There are many approaches for MT: rule-based (direct translation, interlingua-based, transferbased), corpus-based (statistical, example-based) as well as hybrid approaches. We focus o</context>
</contexts>
<marker>Ho, 2005</marker>
<rawString>Ho, Tu Bao. 2005. Current Status of Machine Translation Research in Vietnam Towards Asian wide multi language machine translation project. Vietnamese Language and Speech Processing Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W John Hutchins</author>
</authors>
<title>Machine translation over fifty years. Histoire, epistemologie, langage: HEL,</title>
<date>2001</date>
<journal>ISSN 0750-8069,</journal>
<booktitle></booktitle>
<volume>23</volume>
<pages>7--32</pages>
<contexts>
<context position="1497" citStr="Hutchins, 2001" startWordPosition="218" endWordPosition="219"> their combinations) is discussed. 1 Introduction Over the past fifty years of development, machine translation (MT) has obtained good results when applied to several pairs of languages such as English, French, German, Japanese, etc. However, for under-resourced languages, it still remains a big gap. For instance, although Vietnamese is the 14th widely-used language in the world, research on MT for Vietnamese is very rare. The earliest MT system for Vietnamese is the system from the Logos Corporation, developed as an English-Vietnamese system for translating aircraft manuals during the 1970s (Hutchins, 2001). Until now, in Vietnam, there are only four research groups working on MT for VietnameseEnglish (Ho, 2005). However the results are still modest. MT research on Vietnamese-French occurs even more rarely. Doan (2001) proposed a translation module for Vietnamese within ITS3, a multilingual MT system based on the classical analysis-transfer-generation approach. Nguyen (2006) worked on Vietnamese language and Vietnamese-French text alignment. But no complete MT system for this pair of languages has been published so far. There are many approaches for MT: rule-based (direct translation, interlingu</context>
</contexts>
<marker>Hutchins, 2001</marker>
<rawString>Hutchins, W.John. 2001. Machine translation over fifty years. Histoire, epistemologie, langage: HEL, ISSN 0750-8069, Vol. 23, Nº 1, 2001 , pages. 7-32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
<author>Martin Roscheisen</author>
</authors>
<title>Text -translation alignment. Association for Computational Linguistics.</title>
<date>1993</date>
<contexts>
<context position="7692" citStr="Kay and Roscheisen, 1993" startWordPosition="1211" endWordPosition="1214"> the sentence alignment process identifies parallel sentence pairs (PSPs) between two documents D1 and D2. For each D1-D2, we have a set SenAlignmentD1-D2 of PSPs. SenAlignmentD1-D2 = {“sen1-sen2” |sen1 is zero/one/many sentence(s) in document D1, sen2 is zero/one/many sentence(s) in document D2, sen1-sen2 is considered as a PSP}. We call a PSP sen1-sen2 alignment type m:n when sen1 contains m consecutive sentences and sen2 contains n consecutive sentences. Several automatic sentence alignment approaches have been proposed based on sentence length (Brown et al., 1991) and lexical information (Kay and Roscheisen, 1993). A hybrid approach is presented in (Gale and Church, 1993) whose basic hypothesis is that “longer sentences in one language tend to be translated into longer sentences in the other language, and shorter sentences tend to be translated into shorter sentences”. Some toolkits such as Hunalign1 and Vanilla2 implement these approaches. However, they tend to work best when documents D1, D2 contain few sentence deletions and insertions, and mainly contain PSPs of type 1:1. 1 http://mokk.bme.hu/resources/hunalign 2 http://nl.ijs.si/telri/Vanilla/ 166 Ma (2006) provides an open source software called </context>
</contexts>
<marker>Kay, Roscheisen, 1993</marker>
<rawString>Kay, Martin and Martin Roscheisen. 1993. Text -translation alignment. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
<author>Gregory Grefenstette</author>
</authors>
<title>Introduction to the Special Issue on the Web as Corpus. Computational Linguistics,</title>
<date>2003</date>
<volume>29</volume>
<contexts>
<context position="5196" citStr="Kilgarriff and Grefenstette, 2003" startWordPosition="792" endWordPosition="796">s the two main steps: document alignment and sentence alignment. We also discuss the proposed document alignment method. 2.1 Document alignment Let S1 be set of documents in language L1; let S2 be set of documents in language L2. Extracting parallel documents or aligning documents from the two sets S1, S2 can be seen as finding the translation document D2 (in the set S2) of a document D1 (in the set S1). We call this pair of documents D1-D2 a parallel document pair (PDP). For collecting bilingual text data for the two sets S1, S2, the Web is an ideal source as it is large, free and available (Kilgarriff and Grefenstette, 2003). For this kind of data, various methods to align documents have been proposed. Documents can be simply aligned based on the anchor link, the clue in URL (Kraaij et al., 2003) or the web page structure (Resnik and Smith, 2003). However, this information is not always available or trustworthy. The titles of documents D1, D2 can also be used (Yang and Li, 2002), but sometimes they are completely different. Another useful source of information is invariant words, such as named entities, dates, and numbers, which are often common in news data. We call these words special words. (Patry and Langlais</context>
</contexts>
<marker>Kilgarriff, Grefenstette, 2003</marker>
<rawString>Kilgarriff, Adam and Gregory Grefenstette. 2003. Introduction to the Special Issue on the Web as Corpus. Computational Linguistics, volume 29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<date>2003</date>
<booktitle>Statistical phrase-based translation. Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology -</booktitle>
<volume>1</volume>
<contexts>
<context position="2630" citStr="Koehn et al., 2003" startWordPosition="385" endWordPosition="388">d so far. There are many approaches for MT: rule-based (direct translation, interlingua-based, transferbased), corpus-based (statistical, example-based) as well as hybrid approaches. We focus on building a Vietnamese-French statistical machine translation (SMT) system. Such an approach requires a parallel bilingual corpus for source and target languages. Using this corpus, we build a statistical translation model for source/target languages and a statistical language model for target language. Then the two models and a search module are used to decode the best translation (Brown et al., 1993; Koehn et al., 2003). Thus, the first task is to build a large parallel bilingual text corpus. This corpus can be described as a set of bilingual sentence pairs. At the moment, such a large parallel corpus for Vietnamese-French is unavailable. (Nguyen, 2006) presents a Vietnamese-French parallel corpus of law and economics documents. Our SMT system was trained using Vietnamese-French news corpus created by mining a comparable bilingual text corpus from the Web. Section 2 presents the general methodology of mining a comparable text corpus. We present an overview of document alignment methods and sentence alignment</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Koehn, Philipp, Franz Josef Och and Daniel Marcu. 2003. Statistical phrase-based translation. Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A Parallel Corpus for Statistical Machine Translation. Machine Translation Summit.</title>
<date>2005</date>
<contexts>
<context position="4442" citStr="Koehn, 2005" startWordPosition="668" endWordPosition="669"> different units for Vietnamese (syllables, words, or their combination) is discussed. Section 5 concludes and discusses future work. 2 Mining a comparable text corpus In (Munteanu and Daniel Marcu, 2006), the authors present a method for extracting parallel sub-sentential fragments from comparable bilingual corpora. However this method is in need of an initial parallel bilingual corpus, which is not available for the pair of language VietnameseFrench (in the news domain). The overall process of mining a bilingual text corpus which is used in a SMT system typically takes five following steps (Koehn, 2005): raw data collection, document alignment, sentence splitting, tokenization and sentence alignment. This section presents the two main steps: document alignment and sentence alignment. We also discuss the proposed document alignment method. 2.1 Document alignment Let S1 be set of documents in language L1; let S2 be set of documents in language L2. Extracting parallel documents or aligning documents from the two sets S1, S2 can be seen as finding the translation document D2 (in the set S2) of a document D1 (in the set S1). We call this pair of documents D1-D2 a parallel document pair (PDP). For</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Koehn, Philipp. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. Machine Translation Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Richard Zens</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>Proceedings of the ACL.</booktitle>
<contexts>
<context position="21013" citStr="Koehn et al., 2007" startWordPosition="3460" endWordPosition="3463">s: 54,406 Entire - Number of PDPs: 12,108 corpus - Number of PSPs: 50,322 Table 7. The obtained corpus from STRAIN. 4 Application: a Vietnamese - French statistical machine translation system With the obtained parallel corpus, we attempted to rapidly build a SMT system for VietnameseFrench. The system was built using the Moses toolkit1. The Moses toolkit contains all of the components needed to train both the translation model and the language model. It also contains tools for tuning these models using minimum error rate training and for evaluating the translation result using the BLEU score (Koehn et al., 2007). 4.1 Preparing data From the entire corpus, we chose 50 PDPs (351 PSPs) for developing (Dev), 50 PDPs (384 PSPs) for testing (Tst), with the rest PDPs (49,587 PSPs) reserved for training (Trn). Concerning the developing and testing PSPs, we manually verified and eliminated low quality PSPs, which produced 198 good quality PSPs for developing and 210 good quality PSPs for testing. The data used to create the language model were extracted from 49,587 PSPs of the training set. 4.2 Baseline system We built translation systems in two translation directions: French to Vietnamese (F4V) and Vietnames</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Zens, Federico, Bertoldi, Cowan, Shen, Moran, 2007</marker>
<rawString>Koehn, Philipp, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Richard Zens, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen and Christine Moran. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. Proceedings of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wessel Kraaij</author>
<author>Jian-Yun Nie</author>
<author>Michel Simard</author>
</authors>
<title>Embedding web-based statistical translation models in cross-language information retrieval.</title>
<date>2003</date>
<journal>Computational Linguistics, Volume</journal>
<volume>29</volume>
<contexts>
<context position="5371" citStr="Kraaij et al., 2003" startWordPosition="825" endWordPosition="828">t S2 be set of documents in language L2. Extracting parallel documents or aligning documents from the two sets S1, S2 can be seen as finding the translation document D2 (in the set S2) of a document D1 (in the set S1). We call this pair of documents D1-D2 a parallel document pair (PDP). For collecting bilingual text data for the two sets S1, S2, the Web is an ideal source as it is large, free and available (Kilgarriff and Grefenstette, 2003). For this kind of data, various methods to align documents have been proposed. Documents can be simply aligned based on the anchor link, the clue in URL (Kraaij et al., 2003) or the web page structure (Resnik and Smith, 2003). However, this information is not always available or trustworthy. The titles of documents D1, D2 can also be used (Yang and Li, 2002), but sometimes they are completely different. Another useful source of information is invariant words, such as named entities, dates, and numbers, which are often common in news data. We call these words special words. (Patry and Langlais, 2005) used numbers, punctuation, and entity names to measure the parallelism between two documents. The order of this information in document is used as an important criteri</context>
</contexts>
<marker>Kraaij, Nie, Simard, 2003</marker>
<rawString>Kraaij, Wessel, Jian-Yun Nie and Michel Simard. 2003. Embedding web-based statistical translation models in cross-language information retrieval. Computational Linguistics, Volume 29 , Issue 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viet Bac LE</author>
<author>Brigitte Bigi</author>
<author>Laurent Besacier</author>
<author>Eric Castelli</author>
</authors>
<title>Using the Web for fast language model construction in minority languages.</title>
<date>2003</date>
<booktitle>Eurospeech&apos;03.</booktitle>
<contexts>
<context position="18027" citStr="LE et al., 2003" startWordPosition="2931" endWordPosition="2934">d the collected data into 2 sets. The development set, designated SDEV, contained 1000 documents, was used to tune the mining system parameters. The rest of data, designated STRAIN, was used as a training set, where the estimated parameters were applied to build the entire corpus. We applied the following pre-process to each set SDEV and STRAIN: 1. Extract contents from documents. 1 http://www.vnagency.com.vn/ 2. Classify documents by language (using TextCat2, an n-gram based language identification). 3. Process and clean both Vietnamese and French documents by using the CLIPS-TextTk toolkit (LE et al., 2003): convert html to text file, convert character code, segment sentence, segment word. The resulting clean corpora are S1 (for French) and S2 (for Vietnamese). 3.4 Parameters estimation Our proposed document alignment method was applied to the sets S1 and S2 extracted from the set SDEV. To filter by publishing date, we assumed that n=2. The second filter was implemented on the set S1 and the new set S2* which was created by removing diacritical marks from the set S2 (in the case of Vietnamese). The sentence alignment process was implemented by using data from sets S1, S2 and the Champollion tool</context>
</contexts>
<marker>LE, Bigi, Besacier, Castelli, 2003</marker>
<rawString>LE, Viet Bac, Brigitte Bigi, Laurent Besacier and Eric Castelli. 2003. Using the Web for fast language model construction in minority languages. Eurospeech&apos;03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoyi Ma</author>
</authors>
<title>Champollion: A Robust Parallel Text Sentence Aligner. LREC:</title>
<date>2006</date>
<booktitle>Fifth International Conference on Language Resources and Evaluation.</booktitle>
<contexts>
<context position="8251" citStr="Ma (2006)" startWordPosition="1297" endWordPosition="1298">and lexical information (Kay and Roscheisen, 1993). A hybrid approach is presented in (Gale and Church, 1993) whose basic hypothesis is that “longer sentences in one language tend to be translated into longer sentences in the other language, and shorter sentences tend to be translated into shorter sentences”. Some toolkits such as Hunalign1 and Vanilla2 implement these approaches. However, they tend to work best when documents D1, D2 contain few sentence deletions and insertions, and mainly contain PSPs of type 1:1. 1 http://mokk.bme.hu/resources/hunalign 2 http://nl.ijs.si/telri/Vanilla/ 166 Ma (2006) provides an open source software called Champollion1 to solve this limitation. Champollion permits alignment type m:n (m, n = 0,1,2,3,4), so the length of sentence does not play an important role. Champollion uses also lexical information (lexemes, stop words, bilingual dictionary, etc.) to align sentences. Champollion can easily be adapted to new pairs of languages. Available language pairs in Champollion are English-Arabic and English-Chinese (Ma, 2006). 2.3 Our document alignment method Figure 1 describes our methodology for document alignment. For each document D1 in the set S1, we find t</context>
<context position="18934" citStr="Ma, 2006" startWordPosition="3096" endWordPosition="3097"> publishing date, we assumed that n=2. The second filter was implemented on the set S1 and the new set S2* which was created by removing diacritical marks from the set S2 (in the case of Vietnamese). The sentence alignment process was implemented by using data from sets S1, S2 and the Champollion toolkit. We adapted Champollion to Vietnamese-French by changing some parameters: the ratio of French word to Vietnamese translation word is set to 1.2, penalty for alignment type 1-1 is set to 1, for type 0-1 to 0.8, for type 2-1, 1-2 and 2-2 to 0.75, and we did not use the other types (see more in (Ma, 2006)). After using two filters, the result data is shown in Table 5. The true PDPs were manually extracted. SDEV - Number of documents: 1000 - Number of French documents: 173 - Number of Vietnamese documents: 348 - Number of true PDPs: 129 S2” - Number of found PDPs: 379 - Number of hits PDPs: 129 - Precision = 34.04% , Recall = 100% Table 5. Result data after using two filters. The third filter was applied in which α was set to (0.4, 0.5, 0.6, 0.7) and R was set to (0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4). The precision and recall were calculated according to our true PDPs and the F-measure (F1 sco</context>
</contexts>
<marker>Ma, 2006</marker>
<rawString>Ma, Xiaoyi. 2006. Champollion: A Robust Parallel Text Sentence Aligner. LREC: Fifth International Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragos Stefan Munteanu</author>
<author>Daniel Marcu</author>
</authors>
<title>Extracting parallel sub-sentential fragments from non-parallel corpora . 44th annual meeting of the Association for Computational Linguistics</title>
<date>2006</date>
<marker>Munteanu, Marcu, 2006</marker>
<rawString>Munteanu, Dragos Stefan and Daniel Marcu. 2006. Extracting parallel sub-sentential fragments from non-parallel corpora . 44th annual meeting of the Association for Computational Linguistics</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thi Minh Huyen Nguyen</author>
</authors>
<title>Outils et ressources linguistiques pour l&apos;alignement de textes multilingues français-vietnamiens. Thèse présentée pour l’obtention du titre de Docteur de l’Université Henri Poincaré, Nancy 1 en Informatique.</title>
<date>2006</date>
<contexts>
<context position="1872" citStr="Nguyen (2006)" startWordPosition="273" endWordPosition="274">orld, research on MT for Vietnamese is very rare. The earliest MT system for Vietnamese is the system from the Logos Corporation, developed as an English-Vietnamese system for translating aircraft manuals during the 1970s (Hutchins, 2001). Until now, in Vietnam, there are only four research groups working on MT for VietnameseEnglish (Ho, 2005). However the results are still modest. MT research on Vietnamese-French occurs even more rarely. Doan (2001) proposed a translation module for Vietnamese within ITS3, a multilingual MT system based on the classical analysis-transfer-generation approach. Nguyen (2006) worked on Vietnamese language and Vietnamese-French text alignment. But no complete MT system for this pair of languages has been published so far. There are many approaches for MT: rule-based (direct translation, interlingua-based, transferbased), corpus-based (statistical, example-based) as well as hybrid approaches. We focus on building a Vietnamese-French statistical machine translation (SMT) system. Such an approach requires a parallel bilingual corpus for source and target languages. Using this corpus, we build a statistical translation model for source/target languages and a statistica</context>
<context position="15011" citStr="Nguyen, 2006" startWordPosition="2425" endWordPosition="2426">le for calculating two scores xL1 and xL2. After using three filters based on information of publishing date, special words, and the results of sentence alignment, we have a corpus of PDPs, and also a corpus of corresponding PSPs. To ensure the quality of output PSPs, we can continue to filter PSPs. For example, we can keep only the PSPs whose scores (xL1 and xL2) are higher than a threshold. 3 Experiments 3.1 Characteristics of Vietnamese The basic unit of the Vietnamese language is syllable. In writing, syllables are separated by a white space. One word corresponds to one or more syllables (Nguyen, 2006). Table 4 presents an example of a Vietnamese sentence segmented into syllables and words. Vietnamese sentence: Thành pho hy vong s ñón nhan khodng 3 trieu khách du lich nưac ngoài trong năm nay Segmentation in syllables: Thành |pho |hy |vong |s | ñón |nhan |khoang |3 |trieu |khách |du |lich |nưbc | ngoài |trong |năm |nay Segmentation in words: Thành_pho |hy_vong |s | ñón_nhan |khoang |3 |trieu |khách_du_lich | nưbc_ngoài |trong |năm |nay Corresponding English sentence: The city is expected to receive 3 million foreign tourists this year Table 4. An example of a Vietnamese sentence segmented i</context>
<context position="16300" citStr="Nguyen, 2006" startWordPosition="2661" endWordPosition="2662">ead of conjugation for verb, noun or adjective, Vietnamese language uses additional words, such as “nhieng”, “các” to express the pluD1 Extract special words w1...wn S2” {doc3, doc5} Choose the max doc1: 1 time doc3: 3 times doc4: 1 time doc5: 3 times Count find w1 in S2’ 4 doc1, doc3, doc5 find w2 in S2’ 4 doc3, doc4, doc5 find w3 in S2’ 4 doc3, doc5 ... ... i words in sen − − − translated − number of − i words in sen − − number of − − ) D1-D2 � xLi 168 ral; “ñd”, “s ” to express the past tense and the future. The syntactic functions are also determined by the order of words in the sentence (Nguyen, 2006). 3.2 Data collecting In order to build a Vietnamese-French parallel text corpus, we applied our proposed methodology to mine a comparable text corpus from a Vietnamese daily news website, the Vietnam News Agency1 (VNA). This website contains news articles written in four languages (Vietnamese, English, French, and Spanish) and divided in 9 categories including “Politics - Diplomacy”, “Society - Education”, “Business - Finance”, “Culture - Sports”, “Science - Technology”, “Health”, “Environment”, “Asian corner” and “World”. However, not all of the Vietnamese articles have been translated into </context>
</contexts>
<marker>Nguyen, 2006</marker>
<rawString>Nguyen, Thi Minh Huyen. 2006. Outils et ressources linguistiques pour l&apos;alignement de textes multilingues français-vietnamiens. Thèse présentée pour l’obtention du titre de Docteur de l’Université Henri Poincaré, Nancy 1 en Informatique.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Patry</author>
<author>Philippe Langlais</author>
</authors>
<title>Paradocs: un système d’identification automatique de documents parallèles. 12e Conference sur le Traitement Automatique des Langues Naturelles.</title>
<date>2005</date>
<location>Dourdan, France.</location>
<contexts>
<context position="5803" citStr="Patry and Langlais, 2005" startWordPosition="896" endWordPosition="899">refenstette, 2003). For this kind of data, various methods to align documents have been proposed. Documents can be simply aligned based on the anchor link, the clue in URL (Kraaij et al., 2003) or the web page structure (Resnik and Smith, 2003). However, this information is not always available or trustworthy. The titles of documents D1, D2 can also be used (Yang and Li, 2002), but sometimes they are completely different. Another useful source of information is invariant words, such as named entities, dates, and numbers, which are often common in news data. We call these words special words. (Patry and Langlais, 2005) used numbers, punctuation, and entity names to measure the parallelism between two documents. The order of this information in document is used as an important criterion. However, this order is not always respected in a PDP (see an example in Table 1). French document Vietnamese document Selon l&apos;Administration Trong so gdn 2,8 trieu nationale du tourisme, les lưgt khách quoc to ñen Viet voyageurs en provenance de Nam tir ñau năm ñen nay, l&apos;Asie du Nord-Est (Japon, lưong khách ñen bang République de Corée,...) ñư6ng hàng không van représentent 33%, de l&apos;Eu- chiem chic ñao voi khodng rope, 16%,</context>
<context position="11674" citStr="Patry and Langlais, 2005" startWordPosition="1862" endWordPosition="1865">nch-Vietnamese. All special words are extracted from document D1. This gives a list of special words w1,w2,...wn. For each special word, we search in the set S2’ documents D2 which contain this special word. For each word, we obtain a list of documents D2. The document D2 which has the biggest number of appearance in all lists is chosen. It is the document containing the highest number of special words. We can find zero, one or several documents which are satisfactory. We call this set of documents set S2” (see in Figure 2). The way that we use special words is different from the way used in (Patry and Langlais, 2005). We do not use punctuation as special words. We use the attached symbols (‘$’, ‘%’, ‘‰’, ...) with the number. Furthermore, in our method, the order of special words in documents is not important, and if a special word appears several times in a document, it does not affect the result. S1 D1 D2 S2 167 Figure 2. Using special words to filter documents D2. 2.3.3 The third filter: sentence alignments As mentioned in section 2.3.2, for each document D1, we discover a set S2’’, which contains zero, one or several documents D2. When we continue to align sentences for each PDP D1-D2, we get a lot of</context>
</contexts>
<marker>Patry, Langlais, 2005</marker>
<rawString>Patry, Alexandre and Philippe Langlais. 2005. Paradocs: un système d’identification automatique de documents parallèles. 12e Conference sur le Traitement Automatique des Langues Naturelles. Dourdan, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Noah A Smith</author>
</authors>
<title>The Web as a Parallel Corpus. Computational Linguistics.</title>
<date>2003</date>
<contexts>
<context position="5422" citStr="Resnik and Smith, 2003" startWordPosition="834" endWordPosition="837">ing parallel documents or aligning documents from the two sets S1, S2 can be seen as finding the translation document D2 (in the set S2) of a document D1 (in the set S1). We call this pair of documents D1-D2 a parallel document pair (PDP). For collecting bilingual text data for the two sets S1, S2, the Web is an ideal source as it is large, free and available (Kilgarriff and Grefenstette, 2003). For this kind of data, various methods to align documents have been proposed. Documents can be simply aligned based on the anchor link, the clue in URL (Kraaij et al., 2003) or the web page structure (Resnik and Smith, 2003). However, this information is not always available or trustworthy. The titles of documents D1, D2 can also be used (Yang and Li, 2002), but sometimes they are completely different. Another useful source of information is invariant words, such as named entities, dates, and numbers, which are often common in news data. We call these words special words. (Patry and Langlais, 2005) used numbers, punctuation, and entity names to measure the parallelism between two documents. The order of this information in document is used as an important criterion. However, this order is not always respected in </context>
</contexts>
<marker>Resnik, Smith, 2003</marker>
<rawString>Resnik, Philip and Noah A. Smith. 2003. The Web as a Parallel Corpus. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher C Yang</author>
<author>Kar Wing Li</author>
</authors>
<title>Mining English/Chinese Parallel Documents from the World Wide Web.</title>
<date>2002</date>
<booktitle>Proceedings of the 11th International World Wide Web Conference,</booktitle>
<location>Honolulu, USA.</location>
<contexts>
<context position="5557" citStr="Yang and Li, 2002" startWordPosition="857" endWordPosition="860">a document D1 (in the set S1). We call this pair of documents D1-D2 a parallel document pair (PDP). For collecting bilingual text data for the two sets S1, S2, the Web is an ideal source as it is large, free and available (Kilgarriff and Grefenstette, 2003). For this kind of data, various methods to align documents have been proposed. Documents can be simply aligned based on the anchor link, the clue in URL (Kraaij et al., 2003) or the web page structure (Resnik and Smith, 2003). However, this information is not always available or trustworthy. The titles of documents D1, D2 can also be used (Yang and Li, 2002), but sometimes they are completely different. Another useful source of information is invariant words, such as named entities, dates, and numbers, which are often common in news data. We call these words special words. (Patry and Langlais, 2005) used numbers, punctuation, and entity names to measure the parallelism between two documents. The order of this information in document is used as an important criterion. However, this order is not always respected in a PDP (see an example in Table 1). French document Vietnamese document Selon l&apos;Administration Trong so gdn 2,8 trieu nationale du touri</context>
</contexts>
<marker>Yang, Li, 2002</marker>
<rawString>Yang, Christopher C. and Kar Wing Li. 2002. Mining English/Chinese Parallel Documents from the World Wide Web. Proceedings of the 11th International World Wide Web Conference, Honolulu, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>