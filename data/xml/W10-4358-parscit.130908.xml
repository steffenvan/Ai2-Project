<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000047">
<title confidence="0.994238">
User-adaptive Coordination of Agent Communicative Behavior
in Spoken Dialogue
</title>
<author confidence="0.495785">
Kohji Dohsaka
</author>
<note confidence="0.904984">
NTT Communication Science Laboratories
NTT Corporation
2-4, Hikaridai, Seika-cho,
Kyoto 619-0237, Japan
</note>
<author confidence="0.929284">
Atsushi Kanemoto
</author>
<affiliation confidence="0.886226">
Graduate School of
Information Science and Technology
Osaka University, 1-1, Yamadaoka,
Suita, Osaka 565-0871, Japan
</affiliation>
<author confidence="0.701591">
Ryuichiro Higashinaka
</author>
<affiliation confidence="0.51952525">
NTT Cyber Space Laboratories
NTT Corporation
1-1, Hikarinooka, Yokosuka,
Kanagawa 239-0847, Japan
</affiliation>
<author confidence="0.864359">
Yasuhiro Minami and Eisaku Maeda
</author>
<affiliation confidence="0.7667755">
NTT Communication Science Laboratories
NTT Corporation
</affiliation>
<address confidence="0.948424">
2-4, Hikaridai, Seika-cho,
Kyoto 619-0237, Japan
</address>
<email confidence="0.9856795">
{dohsaka,minami,maeda}@cslab.kecl.ntt.co.jp
higashinaka.ryuichiro@lab.ntt.co.jp
</email>
<sectionHeader confidence="0.996373" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999825">
In this paper, which addresses smooth spo-
ken interaction between human users and
conversational agents, we present an ex-
perimental study that evaluates a method
for user-adaptive coordination of agent
communicative behavior. Our method
adapts the pause duration preceding agent
utterances and the agent gaze duration to
reduce the discomfort perceived by indi-
vidual users during interaction. The exper-
imental results showed a statistically sig-
nificant tendency: the duration of the agent
pause and the gaze converged during inter-
action with the method. The method also
significantly improved the perceived rele-
vance of the agent communicative behav-
ior.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999901346938775">
Conversational agents have been studied as an ef-
fective human-computer interface for such pur-
poses as training decision-making in team ac-
tivities (Traum and Rickel, 2002), learning sup-
port (Johnson et al., 2002), museum guides (Kopp
et al., 2005), and community facilitators (Zheng
et al., 2005; Fujie et al., 2009). They will play
a crucial role in establishing a society where hu-
mans and robots collaborate through natural in-
teraction. However, agents cannot produce their
intended effects when the smooth flow of interac-
tion is disturbed. To fully exploit the promise of
agents, we need to achieve smooth interaction be-
tween human users and agents.
Although various types of modalities have been
used in human-computer interfaces, speech has
drawn a great deal of interest because it is one of
the most pervasive communication methods in our
daily lives and we usually perform it without any
special effort (Nass and Brave, 2005). In this pa-
per, we are interested in smooth spoken dialogues
between users and agents.
A spoken dialogue is a joint activity among
participants (Clark, 1996). For such a joint ac-
tivity to be smooth and successful, participants
need to coordinate their communicative behav-
iors in various ways. In human dialogues, par-
ticipants agree on lexical choices to refer to ob-
jects (Brennan and Clark, 1996) and coordinate
eye gaze (Richardson and Dale, 2005) and whose
turn it is to speak (Sacks et al., 1974). They
become more similar to their partners as the di-
alogue proceeds in many aspects such as pitch,
speech rate, and pause structure (Burgoon et al.,
1995; Hayashi et al., 2009). Such coordination
serves to make conversation flow easily and intel-
ligibly (Garrod and Pickering, 2004).
The coordination of communicative behaviors
also plays a crucial role in smooth human-agent
interaction. Previous work addressed human be-
havior adaptation to agents (Oviatt et al., 2004),
agent behavior adaptation to human partners (Mit-
sunaga et al., 2005; Tapus and Matari´c, 2007), and
the mutual adaptation of human and agent behav-
ior (Breazeal, 2003).
In this paper, which addresses smooth spoken
interaction between human users and agents, we
focus on the adaptation of agent communicative
behavior to individual users in spoken dialogues
</bodyText>
<note confidence="0.6226925">
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 314–321,
The University of Tokyo, September 24-25, 2010. c�2010 Association for Computational Linguistics
</note>
<page confidence="0.998698">
314
</page>
<bodyText confidence="0.999945223684211">
with flexible turn-taking. We present a method
for user-adaptive coordination of agent commu-
nicative behavior to reduce the discomfort per-
ceived by individual users during the interaction
and show experimental results that evaluate how
the method influences agent communicative be-
havior and improves its relevance as perceived by
users. For evaluation purposes, we used a quiz-
style multi-party spoken dialogue system (Minami
et al., 2007; Dohsaka et al., 2009). A quiz-style
dialogue is a kind of thought-evoking dialogue
that can stir user thinking and activate communi-
cation (Higashinaka et al., 2007a; Dohsaka et al.,
2009). This characteristic is expected to be ad-
vantageous for evaluation experiments since it en-
courages involvement in the dialogue.
Our method adapts agent communicative be-
havior based on policy gradient reinforcement
learning (Sutton et al., 2000; Kohl and Stone,
2004). The policy gradient method has been
used for robot communicative behavior adapta-
tion (Mitsunaga et al., 2005; Tapus and Matari´c,
2007). However, both studies dealt with scenario-
based interaction in which a user and a robot acted
with predetermined timing. In contrast, we focus
on spoken dialogues in which users and agents can
speak with more flexible timing. In addition, we
allow for two- and three-party interactions among
a user and two agents. It remains unclear whether
the policy gradient method can successfully adapt
agent communicative behavior to a user in two-
or three-party spoken dialogues with flexible turn-
taking. Although this paper focuses on agent be-
havior adaptation to human users, we believe that
our investigation of the agent behavior adaptation
mechanism in flexible spoken interaction will con-
tribute to conversational interfaces where human
users and agents can mutually adapt their commu-
nicative behaviors.
As agent communicative behavior to be
adapted, this paper focuses on the pause duration
preceding agent utterances and the agent gaze du-
ration. In conversation, the participant pause du-
ration is influenced by partners, and the coordina-
tion of pause structure leads to smooth communi-
cation (Burgoon et al., 1995; Hayashi et al., 2009).
Without pause structure coordination, undesired
speech overlaps or utterance collisions are likely
to occur between users and agents, which may dis-
turb smooth communication. Funakoshi et al. pro-
posed a method to prevent undesired speech over-
laps in human-robot speech interactions by using
a robot’s subtle expressions produced by a blink-
ing LED attached to its chest (Funakoshi et al.,
2008). In their method, a blinking light notifies
users about such internal states of the robot as pro-
cessing or busy and helps users identify the robot
pause structures; however we are concerned with
the adaptation of robot pause structures to users.
Gaze coordination is causally related to the
success of communication (Richardson and Dale,
2005), and the amount of gaze influences conver-
sational turn-taking (Vertegaal and Ding, 2002).
The relevant control of agent gaze duration is
thus essential to the smooth flow of conversation.
Moreover, since the amount of gaze is related to
specific interpersonal attitudes among participants
and is also subject to such individual differences as
personalities (Argyle and Cook, 1976), agent gaze
duration must be adapted to individual users.
In the following, Section 2 describes our quiz-
style multi-party spoken dialogue system. Sec-
tion 3 shows our method for the user-adaptive co-
ordination of agent communicative behavior. Sec-
tion 4 explains the experiment, and Section 5 de-
scribes its results. Section 6 concludes our paper.
</bodyText>
<sectionHeader confidence="0.918998" genericHeader="method">
2 Quiz-Style Spoken Dialogue System
</sectionHeader>
<bodyText confidence="0.999799916666666">
To evaluate a method for agent communicative
behavior adaptation, we used a quiz-style multi-
party spoken dialogue system based on a quiz-
style two-party spoken dialogue system (Minami
et al., 2007) and extended it to perform multi-party
interaction (Dohsaka et al., 2009).
In this system, a human user and one or two
agents interact. The two agents include a quiz-
master and a peer. The quizmaster agent creates
a “Who is this?” quiz about a famous person
and presents hints one by one to the user and the
peer agent, who participates in the interaction and
guesses the correct answer in the same way that
the user does.
The hints are automatically created from the
biographical facts of people in Wikipedial and
ranked based on the difficulty of solving the
quizzes experienced by users (Higashinaka et al.,
2007b). Since users must consider the hints to of-
fer reasonable answers, the system can stimulate
their thinking and encourage them to engage in the
interaction (Higashinaka et al., 2007a). In addi-
tion, the peer agent’s presence and the agent’s em-
pathic expressions improve user satisfaction and
</bodyText>
<footnote confidence="0.993086">
1http://ja.wikipedia.org/
</footnote>
<page confidence="0.998508">
315
</page>
<figureCaption confidence="0.9870435">
Figure 1: User interacting with two agents using
the quiz-style spoken dialogue system
</figureCaption>
<bodyText confidence="0.996960055555556">
increase user utterances (Dohsaka et al., 2009).
Figure 1 shows a human user interacting with
the two agents, both of whom are physically em-
bodied robots. The system utilizes an extremely
large vocabulary with continuous speech recogni-
tion (Hori et al., 2007). Agent utterances are pro-
duced by speech synthesis. The agents can gaze at
other participants by directing their faces to them.
At each point of the dialogue, the system chooses
the next speaker and its utterance based on the
dialogue state that the system maintains, the pre-
conditions of the individual utterances, and a few
turn-taking rules (Dohsaka et al., 2009). The agent
pause and gaze durations are controlled based on
the adaptation method described in Section 3.
A sample dialogue among a user and two agents
is depicted in Figure 2. Master is the quizmaster
agent, and Peer is the peer agent. The agent ut-
terances are classified as either spontaneous or re-
sponsive. Spontaneous utterances are those made
after an agent takes his turn in an unforced man-
ner, and responsive utterances are responses to the
other’s utterances. In the sample dialogue, spon
identifies spontaneous and res identifies respon-
sive utterances.
Quizmaster agent Master makes spontaneous
utterances such as presenting hints (lines 1 and 5),
indicating the quiz difficulty, and addressing lis-
teners. It also makes such responsive utterances
as evaluating the other’s answers (lines 3, 9, and
11). Peer agent Peer makes such spontaneous ut-
terances as showing its own difficulty (line 4), giv-
ing an answer (line 8), giving feedback when its
own or the other’s answer is right (line 12), and
addressing listeners. It also makes such responsive
utterances as showing empathy to the user (line 7).
</bodyText>
<sectionHeader confidence="0.7880025" genericHeader="method">
3 Method for Agent Communicative
Behavior Adaptation
</sectionHeader>
<bodyText confidence="0.9984745">
We apply policy gradient reinforcement learn-
ing (Sutton et al., 2000; Kohl and Stone, 2004)
</bodyText>
<listItem confidence="0.966618263157895">
1 Master Who is this? First hint. He gradu-
ated from the University of Tokyo.
(hint/spon)
2 User Yoshida Shigeru? (answer/spon)
3 Master No, not even close! He’s not a
politician. (evaluation/res)
4 Peer I don’t know. Very difficult.
(show difficulty/spon)
5 Master It’s time for the second hint: He’s
a novelist and a scholar of British
literature. (hint/spon)
6 User Oh, I think I know it but I can’t re-
member his name. That’s so frus-
trating. (show difficulty/spon)
7 Peer Difficult for me, too.
(show empathy/res)
8 Peer Haruki Murakami? (answer/spon)
9 Master Close! You are half right, because
he is a novelist. (evaluation/res)
</listItem>
<figure confidence="0.55023825">
10 User Natsume Soseki? (answer/spon)
11 Master That’s right. Wonderful.
(evaluation/res)
12 Peer Good job. (feedback/spon)
</figure>
<figureCaption confidence="0.78070975">
Figure 2: Sample dialogue between user and two
agents: quizmaster Master and peer Peer. Spon
identifies spontaneous and res identifies respon-
sive utterances.
</figureCaption>
<bodyText confidence="0.997955458333334">
to the user-adaptive coordination of agent com-
municative behavior. A policy gradient method
is a reinforcement learning (RL) approach that di-
rectly optimizes a parameterized policy by gradi-
ent ascent based on the gradient of the expected
reward with respect to the policy parameters. Al-
though RL methods have recently been applied to
optimizing dialogue management in spoken dia-
logue systems (Williams and Young, 2007; Mi-
nami et al., 2009), these previous studies utilized
RL methods based on the value-function estima-
tion. The policy gradient method is an alterna-
tive approach to RL that has the following mer-
its. It can handle continuous and large action
spaces (Kimura and Kobayashi, 1998) and is usu-
ally assured to converge to a locally optimal pol-
icy in such action spaces (Sutton et al., 2000).
Moreover, it does not need to explicitly estimate
the value function, and it is incremental, requiring
only a constant amount of computation per learn-
ing step (Kimura and Kobayashi, 1998).
Due to these advantages, the policy gradient
method is suitable for adapting agent communica-
tive behavior to a user during interaction, because
</bodyText>
<page confidence="0.991703">
316
</page>
<listItem confidence="0.980072342857143">
(1) O = [Bj] &lt;-- initial policy (policy parameter
vector of size n)
(2) c = [Ej] &lt;-- step size vector of size n
(3) η &lt;-- overall scalar step size
(4) maxA &lt;-- 0 (greatest absolute value of
reward ever observed in adaptation process)
(5) while dialogue continues
(6) for i = 1 to T
(7) forj = 1 ton
(8) rj &lt;-- random choice from {-1, 0,1}
(9) Rij &lt;-- Bj + Ej * rj
(Ri is T random perturbations of O)
(10) for i = 1 to T
(11) Perform a hint dialogue based on
policy Ri, and evaluate reward
(12) for j = 1 to n
(13) Avg+E,j &lt;-- average reward for all Ri
with positive perturbation in parameter Ej
(14) Avg0,j &lt;-- average reward for all Ri
with zero perturbation in parameter Ej
(15) Avg_E,j &lt;-- average reward for all Ri
with negative perturbation in parameter Ej
(16) if (Avg0,j &gt; Avg+E,j and
Avg0,j &gt; Avg_E,j)
(17) aj &lt;-- 0
(18) else
(19) aj &lt;-- Avg+E,j — Avg_E,j
aj
(20) bj(aj &lt;-- |A |* Ej * η)
(21) maxC &lt;-- maximum of absolute value of
reward in current adaptation cycle
(22) if (maxC &gt; maxA)
(23) maxA &lt;-- maxC (update maxA)
(24) else
(25) A &lt;-- A * maxC
</listItem>
<figure confidence="0.705548">
maxA
(26) O &lt;-- O + A
</figure>
<figureCaption confidence="0.9152375">
Figure 3: Pseudocode for user-adaptive coordina-
tion of agent communicative behavior
</figureCaption>
<bodyText confidence="0.997639708333333">
it can naturally incorporate such continuous pa-
rameters as pause and gaze duration and incremen-
tally adapt agent behavior. In fact, the policy gra-
dient method has been successfully used for robot
behavior adaptation (Mitsunaga et al., 2005; Tapus
and Matari´c, 2007). In this paper, we apply this
method to agent communicative behavior adapta-
tion in spoken dialogues with flexible turn-taking.
Figure 3 shows our method for the user-adaptive
coordination of agent communicative behavior.
This method is a modification of an algorithm pre-
sented by Kohl and Stone (2004) in that the gra-
dient is adjusted based on the maximum absolute
value of the reward obtained during each adapta-
tion cycle.
The agent communicative behaviors are deter-
mined based on a policy that is represented as vec-
tor O(= [Bj]) of n policy parameters. In the quiz-
style dialogues, the behavior of both the quizmas-
ter and peer agents is controlled based on the same
policy parameters. The method adapts the behav-
ior of both agents to individual users by adapting
the policy parameters. In this experiment, we used
the following four parameters (n = 4):
</bodyText>
<listItem confidence="0.993675454545455">
• pre-spontaneous-utterance pause duration
Qspon: duration of pauses preceding agent
spontaneous utterances
• pre-responsive-utterance pause duration
Qres: duration of pauses preceding agent
responsive utterances
• gaze duration Qgaze: duration of agent’s di-
recting its face to the other while it is speak-
ing or listening
• hint interval Qhint: interval of presenting quiz
hints
</listItem>
<bodyText confidence="0.999939518518519">
As shown above, we used two types of pause
duration since the relevant pause duration can be
dependent on dialogue acts (Itoh et al., 2009). Al-
though our main concern is the pause and gaze du-
ration, we examined the hint interval as a parame-
ter particular to quiz-style dialogues.
To adapt the policy parameters to individual
users, we first generate T random perturbations
[Rl, ... , RT ] of current policy O by randomly
adding Ej, 0, —Ej to each parameter Bj of O in
lines 6 to 9, where Ej is a step size set for each
parameter. In the experiment, we set T to 10. The
step sizes of the parameters used in the experiment
will be shown later in Table 1.
Dialogue per hint (a hint dialogue) is then per-
formed based on each perturbation policy Ri, and
the reward for each hint dialogue is obtained in
lines 10 to 11. All agent behaviors in a hint di-
alogue are determined based on the same pertur-
bation policy. As we will explain in Section 4, in
the experiment, we regarded the magnitude of dis-
comfort perceived by users during a hint dialogue
as a negative reward. Users signified discomfort
by pressing buttons on the controller held in their
hands. After performing hint dialogues for all T
perturbations Ri, gradient A(= [aj]) is computed
in lines 12 to 19. The gradient is normalized by
</bodyText>
<page confidence="0.986067">
317
</page>
<table confidence="0.99956325">
Parameters Uspon Ures Ugaze Uhint
(sec.) (sec.) (sec.) (sec.)
Initial value 4.96 0.53 3.04 27.7
Step size 0.50 0.20 0.30 2.5
</table>
<tableCaption confidence="0.996725">
Table 1: Initial values and step sizes of policy pa-
</tableCaption>
<bodyText confidence="0.986345578947368">
rameters: Uspon (pre-spontaneous-utterance pause
duration), Ures (pre-responsive-utterance pause
duration), Ugaze (gaze duration), and Uhint (hint
interval)
overall scalar step size q and individual step size
ϵj for each parameter in line 20. Overall scalar
step size q is used to adjust the adaptation speed,
which we set to 1.0.
Next we get the maximum maxC of the abso-
lute value of the reward in the current adaptation
cycle. As in lines 21 to 25, the gradient is ad-
justed based on the ratio of maxC to the greatest
absolute value maxA of reward ever observed in
the overall adaptation process. Finally, the current
policy parameters are updated using the gradient
in line 26.
This is an adaptation cycle. By iterating it, the
agent communicative behavior is adapted to re-
duce the discomfort perceived by each user.
</bodyText>
<sectionHeader confidence="0.998657" genericHeader="method">
4 Experiment
</sectionHeader>
<bodyText confidence="0.999916338709678">
We recruited and paid 32 Japanese adults (16
males and 16 females) for their participation. The
mean ages of the male and female groups were
33.2 and 36.8, respectively. They were divided
into two groups: two-party dialogues (user and
quizmaster) and three-party dialogues (user, quiz-
master, and peer). In each group, the numbers of
males and females were identical.
For this experiment, we used a quiz-style spo-
ken dialogue system. We chose the quiz sub-
jects in advance and divided them into sets of five
so that the difficulty level was approximately the
same in all sets. For this purpose, we made sev-
eral sets of five people of approximately identical
PageRank TM scores based on Wikipedia’s hyper-
link structure.
The users first rehearsed the dialogues for a set
of five quizzes to familiarize themselves with the
system. After practicing, they performed the dia-
logues to evaluate the adaptation method and took
a break per five-quiz set. The presentation order
of the quiz sets was permutated to prevent order
effect. For each user, the dialogues continued un-
til the user received 150 hints. The adaptation
method was applied during the interaction, and the
policy parameters were updated per 10 hint dia-
logues. As a result, the parameters were updated
15 times through the dialogues. It took about two
hours for each user to complete all dialogues.
The policy parameters were updated based on
the magnitude of discomfort perceived by users.
In this experiment, users were told to concentrate
on the discomfort caused by agent pause and gaze
duration and signified it by pressing buttons on
the controller held in their hands at three levels of
magnitude: ‘3’, ‘2’, and ‘1’. The sum of discom-
fort obtained during a hint dialogue was normal-
ized with respect to the hint dialogue length, and
the normalized values were regarded as negative
rewards. Ideally we should estimate user discom-
fort from such user behaviors as pause structure
and eye gaze. However, as the first step toward that
goal, in this experiment we adopted this setting in
which users directly signified their discomfort by
pressing buttons.
Table 1 shows the initial values and the step
sizes of the policy parameters used in the exper-
iment. To obtain the relevant initial values, we
conducted a preparatory experiment in which ten
other participants performed quiz-style dialogues
under the same conditions as this experiment. The
initial values in this experiment were set to the
averaged final values of the policy parameters in
the preparatory experiment. The step sizes were
determined as approximately one-tenth of the ini-
tial values except for the pre-responsive-utterance
pause, for which the step size was set to 200 msec
based on the limits of human perception.
Before and after the adaptation, the users filled
out the following questionnaire items (7-point Lik-
ert scale) to evaluate the relevance of agent pause
and gaze duration:
</bodyText>
<listItem confidence="0.9664714">
• Did you feel that the pause duration preced-
ing the agent utterances was relevant?
• Did you feel that the agent gaze duration was
relevant while the agents were speaking or
listening to you?
</listItem>
<sectionHeader confidence="0.99982" genericHeader="evaluation">
5 Results
</sectionHeader>
<subsectionHeader confidence="0.999943">
5.1 Convergence of policy parameters
</subsectionHeader>
<bodyText confidence="0.999895">
The policy parameters were updated based on the
adaptation method during the user-agent interac-
tion. Figure 4 exemplifies how the policy param-
eter values changed during the adaptation cycles
with a user engaged in the two-party dialogue.
</bodyText>
<page confidence="0.994433">
318
</page>
<figure confidence="0.995472666666667">
5.5
5
4.5
4
3.5
3
0 2 4 6 8 10 12 14 0 2 4 6 8 10 12 14
(a) Pre-spontaneous-utt. (b) Pre-responsive-utt.
pause duration (sec.) pause duration (sec.)
</figure>
<figureCaption confidence="0.96985175">
Figure 4: Change of policy parameter values dur-
ing adaptation cycles with a user engaged in two-
party dialogue. Horizontal axis shows adaptation
cycles and vertical axis shows parameter values.
</figureCaption>
<figure confidence="0.987673125">
σspon σres σgaze σhint
Two-party dialogue
0.12
0.08
0.04
0
σspon σres σgaze σhint
Three-party dialogue
</figure>
<figureCaption confidence="0.846999666666667">
Figure 5: For each policy parameter, average and
standard error of first- and last-phase RACs (rela-
tive amount of change in parameter values)
</figureCaption>
<bodyText confidence="0.983176133333333">
Table 2 shows the statistics of the final values
of the policy parameters at the end of the adapta-
tion process. Since the initial values were appro-
priately determined based on the preparatory ex-
periment, the final value averages were not greatly
different from the initial values. However, judging
from the maximum, minimum, and standard devi-
ations, the final values reflected individual users.
If the adaptation method works successfully, the
policy parameter values should converge during
the user-agent interaction. From this viewpoint,
we examined the relative amount of change in the
policy parameters (RAC). Given parameter value
pk−1 at (k − 1)-th adaptation cycle and param-
eter value pk at k-th cycle, RAC is defined as
</bodyText>
<table confidence="0.999231214285714">
Two-party dialogues
Parameters σspon σres σgaze σhint
(sec.) (sec.) (sec.) (sec.)
Average 5.04 0.62 3.10 25.8
Min 3.90 0.39 2.40 19.5
Max 6.17 1.18 3.69 31.2
Sd. 0.72 0.21 0.36 2.7
Three-party dialogues
Parameters σspon σres σgaze σhint
(sec.) (sec.) (sec.) (sec.)
Average 4.86 0.62 3.15 27.4
Min 4.07 0.35 2.52 22.0
Max 5.54 0.90 3.58 32.7
Sd. 0.44 0.18 0.27 2.5
</table>
<tableCaption confidence="0.8979745">
Table 2: Statistics of final values of policy param-
eters: σspon (pre-spontaneous-utterance pause du-
ration), σres (pre-responsive-utterance pause dura-
tion), σgaze (gaze duration), and σhint (hint inter-
</tableCaption>
<equation confidence="0.934599">
val)
|pk−pk−1 |.
pk−1
</equation>
<bodyText confidence="0.997773277777778">
For each policy parameter, we compared the
RAC averages in the first and in the last three adap-
tation cycles: the first-phase RAC and the last-
phase RAC. As shown in Figure 5, the last-phase
RAC tends to be smaller than the first-phase RAC.
The Kolmogorov-Smirnov test showed that the as-
sumption of normality (p &gt; 0.2) was met for each
group. By applying the paired Welch’s t-test, as
shown in Figure 5, we found that the last-phase
RAC is significantly smaller than the first-phase
RAC except for the hint interval in the two-party
dialogues. This shows that the agent pause and
gaze duration converged during the interaction in
both the two- and three-party dialogues.
The hint interval is unlikely to converge, prob-
ably because it is a longer period than the pause
and gaze duration and is subject to various factors.
Moreover, it greatly depends on user interest.
</bodyText>
<subsectionHeader confidence="0.999396">
5.2 User evaluations
</subsectionHeader>
<bodyText confidence="0.999843555555556">
Figure 6 shows the subjective user evaluations of
the relevance of agent pause and gaze duration be-
fore and after the adaptation. Each user evaluation
was measured by a Likert question. The rating of
a single Likert question is an ordinal measure, and
we generally cannot apply a parametric statistical
test to an ordinal measure. Therefore we used a
nonparametric test, the Wilcoxon signed-rank test,
to compare user evaluations before and after the
</bodyText>
<figure confidence="0.995779030303031">
4
3.5
3
2.5
2
0 2 4 6 8 10 12 14
(c) Gaze duration (sec.)
30
28
26
24
22
20
0 2 4 6 8 10 12 14
(d) Hint interval (sec.)
First-phase RAC Last-phase RAC
p=0.029 *
p=0.0071 **
p=0.041 * N.S.
0.04
0
0.12
0.08
0.65
0.55
0.45
0.6
0.5
p&lt;0.001 ***
p=0.038 *
p=0.016 *
p=0.011 *
First-phase RAC Last-phase RAC
</figure>
<page confidence="0.605547">
319
</page>
<figure confidence="0.988732">
7
6
5
4
3
2
1
Pause Gaze Pause Gaze
Two-party dialogue Three-party dialogue
</figure>
<figureCaption confidence="0.972453333333333">
Figure 6: Average and standard error of user eval-
uations of relevance of agent pause and gaze dura-
tion before and after adaptation
</figureCaption>
<bodyText confidence="0.956326875">
adaptation. The F-test for the homogeneity of vari-
ances (p &gt; 0.1) showed that the data satisfied the
statistical test assumption.
We found that in both the two- and three-party
dialogues, the relevance of the agent pause and
gaze duration significantly improved during the
two-hour adaptation process (p &lt; 0.01 for gaze
duration in the two-party dialogues, p &lt; 0.05 for
other cases). The p-values are shown in Figure 6.
No significant differences between gender were
found.
These results on the convergence of policy
parameters and user evaluations show that the
policy-gradient-based method can adapt agent
communicative behavior to individual users in
spoken dialogues with flexible turn-taking.
</bodyText>
<sectionHeader confidence="0.999199" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999992710526316">
In this paper, addressing smooth spoken inter-
action between human users and conversational
agents, we presented a method for user-adaptive
coordination of agent communicative behavior
and experimentally evaluated how it can adapt
agent behavior to individual users in spoken dia-
logues with flexible turn-taking. The method co-
ordinates agent pause and gaze duration based on
policy gradient reinforcement learning to reduce
the discomfort perceived by individual users dur-
ing interaction. We experimentally evaluated the
method in a setting where the users performed
two- and three-party quiz-style dialogues and sig-
nified their discomfort by pressing buttons held in
their hands. Our experimental results showed a
statistically significant tendency: the agent pause
and gaze duration converged during interaction
with the method in both two- or three-party dia-
logues. The method also significantly improved
the perceived relevance of the agent communica-
tive behavior in both two- and three-party di-
alogues. These results indicate that in spoken
dialogues with flexible turn-taking, the policy-
gradient-based method can adapt agent commu-
nicative behavior to individual users.
Many directions for future work remain. First,
we will analyze how users adapt their communica-
tive behaviors with our method. Second, we need
to automatically estimate user discomfort or sat-
isfaction based on such user behaviors as pause
structure, prosody, eye gaze, and body posture.
Third, we will extend the adaptation method to
regulate agent behavior based on dialogue states,
since one limitation of the current method is its
inability to recognize them. Fourth, we are inter-
ested in the adaptation of additional higher-level
actions like the relevant choice of dialogue topics
based on the level of user interest.
</bodyText>
<sectionHeader confidence="0.998464" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.993796666666667">
This work was partially supported by a Grant-in-
Aid for Scientific Research on Innovative Areas,
”Founding a creative society via collaboration be-
tween humans and robots” (21118004), from the
Ministry of Education, Culture, Sports, Science
and Technology (MEXT), Japan.
</bodyText>
<sectionHeader confidence="0.996974" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.986736869565218">
Michael Argyle and Mark Cook. 1976. Gaze and Mu-
tual Gaze. Cambridge University Press.
Cynthia Breazeal. 2003. Regulation and entrainment
for human-robot interaction. International Journal
of Experimental Robotics, 21(10-11):883–902.
Susan E. Brennan and Herbert H. Clark. 1996. Con-
ceptual pacts and lexical choice in conversation.
Journal of Experimental Psychology: Learning,
Memory, and Cognition, 22:1482–1493.
Judee K. Burgoon, Lesa A. Stern, and Leesa Dillman.
1995. Interpersonal Adaptation: Dyadic Interaction
Patterns. Cambridge University Press.
Herbert H. Clark. 1996. Using Language. Cambridge
University Press.
Kohji Dohsaka, Ryota Asai, Ryuichiro Higashinaka,
Yasuhiro Minami, and Eisaku Maeda. 2009. Effects
of conversational agents on human communication
in thought-evoking multi-party dialogues. In Proc.
of SIGDIAL 2009, pages 217–224.
Shinya Fujie, Yoichi Matsuyama, Hikaru Taniyama,
and Tetsunori Kobayashi. 2009. Conversation robot
participating in and activating a group communica-
tion. In Proc. of Interspeech 2009, pages 264–267.
</reference>
<figure confidence="0.7139005">
p=0.014 * p=0.0051 ** p=0.015 * p=0.021 *
Before Adaptation After Adaptation
</figure>
<page confidence="0.971658">
320
</page>
<reference confidence="0.998780145454546">
Kotaro Funakoshi, Kazuki Kobayashi, Mikio Nakano,
Seiji Yamada, Yasuhiko Kitamura, and Hiroshi Tsu-
jino. 2008. Smoothing human-robot speech interac-
tions by using a blinking-light as subtle expression.
In Proc. of ICMI 2008, pages 293–296.
Simon Garrod and Martin J. Pickering. 2004. Why is
conversation so easy? Trends in Cognitive Sciences,
8:8–11.
Takanori Hayashi, Shohei Kato, and Hidenori Itoh.
2009. A synchronous model of mental rhythm using
paralanguage for communication robots. In Lecture
Notes in Computer Science (PRIMA 2009), volume
5925, pages 376–388.
Ryuichiro Higashinaka, Kohji Dohsaka, Shigeaki
Amano, and Hideki Isozaki. 2007a. Effects of quiz-
style information presentation on user understand-
ing. In Proc. of Interspeech 2007, pages 2725–2728.
Ryuichiro Higashinaka, Kohji Dohsaka, and Hideki
Isozaki. 2007b. Learning to rank definitions to gen-
erate quizzes for interactive information presenta-
tion. In Proc. of ACL 2007 (Poster Presentation),
pages 117–120.
Takaaki Hori, Chiori Hori, Yasuhiro Minami, and At-
sushi Nakamura. 2007. Efficient WFST-based one-
pass decoding with on-the-fly hypothesis rescoring
in extremely large vocabulary continuous speech
recognition. IEEE Transactions on Audio, Speech
and Language Processing, 15:1352–1365.
Toshihiko Itoh, Norihide Kitaoka, and Ryota
Nishimura. 2009. Subjective experiments on
influence of response timing in spoken dialogues.
In Proc. of Interspeech 2009, pages 1835–1838.
W. Lewis Johnson, Jeff W. Rickel, and James C. Lester.
2002. Animated pedagogical aqgents: face-to-face
interaction in interactive learning environments. In-
ternational Journal of Artificial Intelligence in Edu-
cation, 11:47–78.
Hajime Kimura and Shigenobu Kobayashi. 1998. Re-
inforcement learning for continuous action using
stochastic gradient ascent. In Proc. of the 5th Inter-
national Conference on Intelligent Autonomous Sys-
tems, pages 288–295.
Nate Kohl and Peter Stone. 2004. Policy gradient rein-
forcement learning for fast quadrupedal locomotion.
In Proc. of ICRA 2004, volume 3, pages 2619–2624.
Stefan Kopp, Lars Gesellensetter, Nicole C. Kr¨amer,
and Ipke Wachsmuth. 2005. A conversational agent
as museum guide: design and evaluation of a real-
world application. In Lecture Notes in Computer
Science (IVA 2009), volume 3661, pages 329–343.
Yasuhiro Minami, Minako Sawaki, Kohji Dohsaka,
Ryuichiro Higashinaka, Kentaro Ishizuka, Hideki
Isozaki, Tatsushi Matsubayashi, Masato Miyoshi,
Atsushi Nakamura, Takanobu Oba, Hiroshi Sawada,
Takeshi Yamada, and Eisaku Maeda. 2007. The
World of Mushrooms: human-computer interaction
prototype systems for ambient intelligence. In Proc.
of ICMI 2007, pages 366–373.
Yasuhiro Minami, Akira Mori, Ryuichiro Higashinaka,
Kohji Dohsaka, and Eisaku Maeda. 2009. Dialogue
control algorithm for ambient intelligence based on
partially observable Markov decision processes. In
Proc. of IWSDS 2009.
Noriaki Mitsunaga, Christian Smith, Takayuki Kanda,
Hiroshi Isiguro, and Norihiro Hagita. 2005.
Human-robot interaction based on policy gradient
reinforcement learning. In Proc. of IROS 2005,
pages 1594–1601.
Clifford Nass and Scott Brave. 2005. Wired for
Speech: How Voice Activates and Advances the
Human-Computer Relationship. The MIT Press.
Sharon Oviatt, Courtney Darves, and Rachel Coulston.
2004. Toward adaptive conversational interfaces:
modeling speech convergence with animated per-
sonas. ACM Transactions on Computer-Human In-
teraction, 11(3):300–328.
Daniel C. Richardson and Rick Dale. 2005. Look-
ing to understand: the coupling between speakers’
and listeners’ eye movements and its relationship
to discourse comprehension. Cognitive Science,
29:1045–1060.
Harvey Sacks, Emanuel A. Schegloff, and Gail Jeffer-
son. 1974. A simplest systematics for the orga-
nization of turn-taking in conversation. Language,
50:696–735.
Richard S. Sutton, David McAllester, Satinder Singh,
and Yishay Mansour. 2000. Policy gradient meth-
ods for reinforcement learning with function approx-
imation. In Advances in Neural Information Pro-
cessing Systems, volume 12, pages 1057–1063.
Adriana Tapus and Maja J. Matari´c. 2007. Hands-off
therapist robot behavior adaptation to user person-
ality for post-stroke rehabilitation therapy. In Proc.
of 2007 IEEE International Conference on Robotics
and Automation, pages 1547–1553.
David Traum and Jeff Rickel. 2002. Embodied agents
for multi-party dialogue in immersive virtual worlds.
In Proc. of AAMAS 2002, pages 766–773.
Roel Vertegaal and Yaping Ding. 2002. Explaining
effects of eye gaze on mediated group conversations:
amount or synchronization. In Proc. of CSCW 2002,
pages 41–48.
Jason D. Williams and Steve Young. 2007. Par-
tially observable Markov decision processes for spo-
ken dialog systems. Computer &amp; Speech Language,
21(2):393–422.
Jun Zheng, Xiang Yuan, and Yam San Chee. 2005.
Designing multiparty interaction support in Elva, an
embodied tour guide. In Proc. of AAMAS 2005,
pages 929–936.
</reference>
<page confidence="0.998764">
321
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.019966">
<title confidence="0.9896915">User-adaptive Coordination of Agent Communicative in Spoken Dialogue</title>
<author confidence="0.908546">Kohji</author>
<affiliation confidence="0.982065">NTT Communication Science NTT</affiliation>
<address confidence="0.8565005">2-4, Hikaridai, Kyoto 619-0237, Japan</address>
<email confidence="0.462064">Atsushi</email>
<affiliation confidence="0.921221666666667">Graduate School Information Science and Osaka University, 1-1,</affiliation>
<address confidence="0.928554">Suita, Osaka 565-0871, Japan</address>
<email confidence="0.380259">Ryuichiro</email>
<author confidence="0.518597">NTT Cyber Space</author>
<affiliation confidence="0.881696">NTT</affiliation>
<address confidence="0.8731275">1-1, Hikarinooka, Kanagawa 239-0847, Japan</address>
<author confidence="0.490306">Minami</author>
<affiliation confidence="0.9743075">NTT Communication Science NTT</affiliation>
<address confidence="0.9420825">2-4, Hikaridai, Kyoto 619-0237, Japan</address>
<email confidence="0.949253">higashinaka.ryuichiro@lab.ntt.co.jp</email>
<abstract confidence="0.987360388888889">In this paper, which addresses smooth spoken interaction between human users and conversational agents, we present an experimental study that evaluates a method for user-adaptive coordination of agent communicative behavior. Our method adapts the pause duration preceding agent utterances and the agent gaze duration to reduce the discomfort perceived by individual users during interaction. The experimental results showed a statistically significant tendency: the duration of the agent pause and the gaze converged during interaction with the method. The method also significantly improved the perceived relevance of the agent communicative behavior.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michael Argyle</author>
<author>Mark Cook</author>
</authors>
<title>Gaze and Mutual Gaze.</title>
<date>1976</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="7114" citStr="Argyle and Cook, 1976" startWordPosition="1073" endWordPosition="1076">g or busy and helps users identify the robot pause structures; however we are concerned with the adaptation of robot pause structures to users. Gaze coordination is causally related to the success of communication (Richardson and Dale, 2005), and the amount of gaze influences conversational turn-taking (Vertegaal and Ding, 2002). The relevant control of agent gaze duration is thus essential to the smooth flow of conversation. Moreover, since the amount of gaze is related to specific interpersonal attitudes among participants and is also subject to such individual differences as personalities (Argyle and Cook, 1976), agent gaze duration must be adapted to individual users. In the following, Section 2 describes our quizstyle multi-party spoken dialogue system. Section 3 shows our method for the user-adaptive coordination of agent communicative behavior. Section 4 explains the experiment, and Section 5 describes its results. Section 6 concludes our paper. 2 Quiz-Style Spoken Dialogue System To evaluate a method for agent communicative behavior adaptation, we used a quiz-style multiparty spoken dialogue system based on a quizstyle two-party spoken dialogue system (Minami et al., 2007) and extended it to per</context>
</contexts>
<marker>Argyle, Cook, 1976</marker>
<rawString>Michael Argyle and Mark Cook. 1976. Gaze and Mutual Gaze. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia Breazeal</author>
</authors>
<title>Regulation and entrainment for human-robot interaction.</title>
<date>2003</date>
<journal>International Journal of Experimental Robotics,</journal>
<pages>21--10</pages>
<contexts>
<context position="3415" citStr="Breazeal, 2003" startWordPosition="508" endWordPosition="509">ar to their partners as the dialogue proceeds in many aspects such as pitch, speech rate, and pause structure (Burgoon et al., 1995; Hayashi et al., 2009). Such coordination serves to make conversation flow easily and intelligibly (Garrod and Pickering, 2004). The coordination of communicative behaviors also plays a crucial role in smooth human-agent interaction. Previous work addressed human behavior adaptation to agents (Oviatt et al., 2004), agent behavior adaptation to human partners (Mitsunaga et al., 2005; Tapus and Matari´c, 2007), and the mutual adaptation of human and agent behavior (Breazeal, 2003). In this paper, which addresses smooth spoken interaction between human users and agents, we focus on the adaptation of agent communicative behavior to individual users in spoken dialogues Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 314–321, The University of Tokyo, September 24-25, 2010. c�2010 Association for Computational Linguistics 314 with flexible turn-taking. We present a method for user-adaptive coordination of agent communicative behavior to reduce the discomfort perceived by individual users during the interact</context>
</contexts>
<marker>Breazeal, 2003</marker>
<rawString>Cynthia Breazeal. 2003. Regulation and entrainment for human-robot interaction. International Journal of Experimental Robotics, 21(10-11):883–902.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan E Brennan</author>
<author>Herbert H Clark</author>
</authors>
<title>Conceptual pacts and lexical choice in conversation.</title>
<date>1996</date>
<journal>Journal of Experimental Psychology: Learning, Memory, and Cognition,</journal>
<pages>22--1482</pages>
<contexts>
<context position="2673" citStr="Brennan and Clark, 1996" startWordPosition="387" endWordPosition="390">n human-computer interfaces, speech has drawn a great deal of interest because it is one of the most pervasive communication methods in our daily lives and we usually perform it without any special effort (Nass and Brave, 2005). In this paper, we are interested in smooth spoken dialogues between users and agents. A spoken dialogue is a joint activity among participants (Clark, 1996). For such a joint activity to be smooth and successful, participants need to coordinate their communicative behaviors in various ways. In human dialogues, participants agree on lexical choices to refer to objects (Brennan and Clark, 1996) and coordinate eye gaze (Richardson and Dale, 2005) and whose turn it is to speak (Sacks et al., 1974). They become more similar to their partners as the dialogue proceeds in many aspects such as pitch, speech rate, and pause structure (Burgoon et al., 1995; Hayashi et al., 2009). Such coordination serves to make conversation flow easily and intelligibly (Garrod and Pickering, 2004). The coordination of communicative behaviors also plays a crucial role in smooth human-agent interaction. Previous work addressed human behavior adaptation to agents (Oviatt et al., 2004), agent behavior adaptatio</context>
</contexts>
<marker>Brennan, Clark, 1996</marker>
<rawString>Susan E. Brennan and Herbert H. Clark. 1996. Conceptual pacts and lexical choice in conversation. Journal of Experimental Psychology: Learning, Memory, and Cognition, 22:1482–1493.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judee K Burgoon</author>
<author>Lesa A Stern</author>
<author>Leesa Dillman</author>
</authors>
<title>Interpersonal Adaptation: Dyadic Interaction Patterns.</title>
<date>1995</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="2931" citStr="Burgoon et al., 1995" startWordPosition="433" endWordPosition="436">in smooth spoken dialogues between users and agents. A spoken dialogue is a joint activity among participants (Clark, 1996). For such a joint activity to be smooth and successful, participants need to coordinate their communicative behaviors in various ways. In human dialogues, participants agree on lexical choices to refer to objects (Brennan and Clark, 1996) and coordinate eye gaze (Richardson and Dale, 2005) and whose turn it is to speak (Sacks et al., 1974). They become more similar to their partners as the dialogue proceeds in many aspects such as pitch, speech rate, and pause structure (Burgoon et al., 1995; Hayashi et al., 2009). Such coordination serves to make conversation flow easily and intelligibly (Garrod and Pickering, 2004). The coordination of communicative behaviors also plays a crucial role in smooth human-agent interaction. Previous work addressed human behavior adaptation to agents (Oviatt et al., 2004), agent behavior adaptation to human partners (Mitsunaga et al., 2005; Tapus and Matari´c, 2007), and the mutual adaptation of human and agent behavior (Breazeal, 2003). In this paper, which addresses smooth spoken interaction between human users and agents, we focus on the adaptatio</context>
<context position="5972" citStr="Burgoon et al., 1995" startWordPosition="896" endWordPosition="899">ing. Although this paper focuses on agent behavior adaptation to human users, we believe that our investigation of the agent behavior adaptation mechanism in flexible spoken interaction will contribute to conversational interfaces where human users and agents can mutually adapt their communicative behaviors. As agent communicative behavior to be adapted, this paper focuses on the pause duration preceding agent utterances and the agent gaze duration. In conversation, the participant pause duration is influenced by partners, and the coordination of pause structure leads to smooth communication (Burgoon et al., 1995; Hayashi et al., 2009). Without pause structure coordination, undesired speech overlaps or utterance collisions are likely to occur between users and agents, which may disturb smooth communication. Funakoshi et al. proposed a method to prevent undesired speech overlaps in human-robot speech interactions by using a robot’s subtle expressions produced by a blinking LED attached to its chest (Funakoshi et al., 2008). In their method, a blinking light notifies users about such internal states of the robot as processing or busy and helps users identify the robot pause structures; however we are co</context>
</contexts>
<marker>Burgoon, Stern, Dillman, 1995</marker>
<rawString>Judee K. Burgoon, Lesa A. Stern, and Leesa Dillman. 1995. Interpersonal Adaptation: Dyadic Interaction Patterns. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
</authors>
<title>Using Language.</title>
<date>1996</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="2434" citStr="Clark, 1996" startWordPosition="349" endWordPosition="350">ended effects when the smooth flow of interaction is disturbed. To fully exploit the promise of agents, we need to achieve smooth interaction between human users and agents. Although various types of modalities have been used in human-computer interfaces, speech has drawn a great deal of interest because it is one of the most pervasive communication methods in our daily lives and we usually perform it without any special effort (Nass and Brave, 2005). In this paper, we are interested in smooth spoken dialogues between users and agents. A spoken dialogue is a joint activity among participants (Clark, 1996). For such a joint activity to be smooth and successful, participants need to coordinate their communicative behaviors in various ways. In human dialogues, participants agree on lexical choices to refer to objects (Brennan and Clark, 1996) and coordinate eye gaze (Richardson and Dale, 2005) and whose turn it is to speak (Sacks et al., 1974). They become more similar to their partners as the dialogue proceeds in many aspects such as pitch, speech rate, and pause structure (Burgoon et al., 1995; Hayashi et al., 2009). Such coordination serves to make conversation flow easily and intelligibly (Ga</context>
</contexts>
<marker>Clark, 1996</marker>
<rawString>Herbert H. Clark. 1996. Using Language. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kohji Dohsaka</author>
<author>Ryota Asai</author>
<author>Ryuichiro Higashinaka</author>
<author>Yasuhiro Minami</author>
<author>Eisaku Maeda</author>
</authors>
<title>Effects of conversational agents on human communication in thought-evoking multi-party dialogues.</title>
<date>2009</date>
<booktitle>In Proc. of SIGDIAL</booktitle>
<pages>217--224</pages>
<contexts>
<context position="4291" citStr="Dohsaka et al., 2009" startWordPosition="635" endWordPosition="638">al Interest Group on Discourse and Dialogue, pages 314–321, The University of Tokyo, September 24-25, 2010. c�2010 Association for Computational Linguistics 314 with flexible turn-taking. We present a method for user-adaptive coordination of agent communicative behavior to reduce the discomfort perceived by individual users during the interaction and show experimental results that evaluate how the method influences agent communicative behavior and improves its relevance as perceived by users. For evaluation purposes, we used a quizstyle multi-party spoken dialogue system (Minami et al., 2007; Dohsaka et al., 2009). A quiz-style dialogue is a kind of thought-evoking dialogue that can stir user thinking and activate communication (Higashinaka et al., 2007a; Dohsaka et al., 2009). This characteristic is expected to be advantageous for evaluation experiments since it encourages involvement in the dialogue. Our method adapts agent communicative behavior based on policy gradient reinforcement learning (Sutton et al., 2000; Kohl and Stone, 2004). The policy gradient method has been used for robot communicative behavior adaptation (Mitsunaga et al., 2005; Tapus and Matari´c, 2007). However, both studies dealt </context>
<context position="7765" citStr="Dohsaka et al., 2009" startWordPosition="1175" endWordPosition="1178">adapted to individual users. In the following, Section 2 describes our quizstyle multi-party spoken dialogue system. Section 3 shows our method for the user-adaptive coordination of agent communicative behavior. Section 4 explains the experiment, and Section 5 describes its results. Section 6 concludes our paper. 2 Quiz-Style Spoken Dialogue System To evaluate a method for agent communicative behavior adaptation, we used a quiz-style multiparty spoken dialogue system based on a quizstyle two-party spoken dialogue system (Minami et al., 2007) and extended it to perform multi-party interaction (Dohsaka et al., 2009). In this system, a human user and one or two agents interact. The two agents include a quizmaster and a peer. The quizmaster agent creates a “Who is this?” quiz about a famous person and presents hints one by one to the user and the peer agent, who participates in the interaction and guesses the correct answer in the same way that the user does. The hints are automatically created from the biographical facts of people in Wikipedial and ranked based on the difficulty of solving the quizzes experienced by users (Higashinaka et al., 2007b). Since users must consider the hints to offer reasonable</context>
<context position="9341" citStr="Dohsaka et al., 2009" startWordPosition="1435" endWordPosition="1438">ase user utterances (Dohsaka et al., 2009). Figure 1 shows a human user interacting with the two agents, both of whom are physically embodied robots. The system utilizes an extremely large vocabulary with continuous speech recognition (Hori et al., 2007). Agent utterances are produced by speech synthesis. The agents can gaze at other participants by directing their faces to them. At each point of the dialogue, the system chooses the next speaker and its utterance based on the dialogue state that the system maintains, the preconditions of the individual utterances, and a few turn-taking rules (Dohsaka et al., 2009). The agent pause and gaze durations are controlled based on the adaptation method described in Section 3. A sample dialogue among a user and two agents is depicted in Figure 2. Master is the quizmaster agent, and Peer is the peer agent. The agent utterances are classified as either spontaneous or responsive. Spontaneous utterances are those made after an agent takes his turn in an unforced manner, and responsive utterances are responses to the other’s utterances. In the sample dialogue, spon identifies spontaneous and res identifies responsive utterances. Quizmaster agent Master makes spontan</context>
</contexts>
<marker>Dohsaka, Asai, Higashinaka, Minami, Maeda, 2009</marker>
<rawString>Kohji Dohsaka, Ryota Asai, Ryuichiro Higashinaka, Yasuhiro Minami, and Eisaku Maeda. 2009. Effects of conversational agents on human communication in thought-evoking multi-party dialogues. In Proc. of SIGDIAL 2009, pages 217–224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shinya Fujie</author>
<author>Yoichi Matsuyama</author>
<author>Hikaru Taniyama</author>
<author>Tetsunori Kobayashi</author>
</authors>
<title>Conversation robot participating in and activating a group communication.</title>
<date>2009</date>
<booktitle>In Proc. of Interspeech</booktitle>
<pages>264--267</pages>
<contexts>
<context position="1659" citStr="Fujie et al., 2009" startWordPosition="220" endWordPosition="223">l users during interaction. The experimental results showed a statistically significant tendency: the duration of the agent pause and the gaze converged during interaction with the method. The method also significantly improved the perceived relevance of the agent communicative behavior. 1 Introduction Conversational agents have been studied as an effective human-computer interface for such purposes as training decision-making in team activities (Traum and Rickel, 2002), learning support (Johnson et al., 2002), museum guides (Kopp et al., 2005), and community facilitators (Zheng et al., 2005; Fujie et al., 2009). They will play a crucial role in establishing a society where humans and robots collaborate through natural interaction. However, agents cannot produce their intended effects when the smooth flow of interaction is disturbed. To fully exploit the promise of agents, we need to achieve smooth interaction between human users and agents. Although various types of modalities have been used in human-computer interfaces, speech has drawn a great deal of interest because it is one of the most pervasive communication methods in our daily lives and we usually perform it without any special effort (Nass</context>
</contexts>
<marker>Fujie, Matsuyama, Taniyama, Kobayashi, 2009</marker>
<rawString>Shinya Fujie, Yoichi Matsuyama, Hikaru Taniyama, and Tetsunori Kobayashi. 2009. Conversation robot participating in and activating a group communication. In Proc. of Interspeech 2009, pages 264–267.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kotaro Funakoshi</author>
<author>Kazuki Kobayashi</author>
<author>Mikio Nakano</author>
<author>Seiji Yamada</author>
<author>Yasuhiko Kitamura</author>
<author>Hiroshi Tsujino</author>
</authors>
<title>Smoothing human-robot speech interactions by using a blinking-light as subtle expression.</title>
<date>2008</date>
<booktitle>In Proc. of ICMI</booktitle>
<pages>293--296</pages>
<contexts>
<context position="6389" citStr="Funakoshi et al., 2008" startWordPosition="961" endWordPosition="964">utterances and the agent gaze duration. In conversation, the participant pause duration is influenced by partners, and the coordination of pause structure leads to smooth communication (Burgoon et al., 1995; Hayashi et al., 2009). Without pause structure coordination, undesired speech overlaps or utterance collisions are likely to occur between users and agents, which may disturb smooth communication. Funakoshi et al. proposed a method to prevent undesired speech overlaps in human-robot speech interactions by using a robot’s subtle expressions produced by a blinking LED attached to its chest (Funakoshi et al., 2008). In their method, a blinking light notifies users about such internal states of the robot as processing or busy and helps users identify the robot pause structures; however we are concerned with the adaptation of robot pause structures to users. Gaze coordination is causally related to the success of communication (Richardson and Dale, 2005), and the amount of gaze influences conversational turn-taking (Vertegaal and Ding, 2002). The relevant control of agent gaze duration is thus essential to the smooth flow of conversation. Moreover, since the amount of gaze is related to specific interpers</context>
</contexts>
<marker>Funakoshi, Kobayashi, Nakano, Yamada, Kitamura, Tsujino, 2008</marker>
<rawString>Kotaro Funakoshi, Kazuki Kobayashi, Mikio Nakano, Seiji Yamada, Yasuhiko Kitamura, and Hiroshi Tsujino. 2008. Smoothing human-robot speech interactions by using a blinking-light as subtle expression. In Proc. of ICMI 2008, pages 293–296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Garrod</author>
<author>Martin J Pickering</author>
</authors>
<title>Why is conversation so easy? Trends in Cognitive Sciences,</title>
<date>2004</date>
<pages>8--8</pages>
<contexts>
<context position="3059" citStr="Garrod and Pickering, 2004" startWordPosition="452" endWordPosition="455">6). For such a joint activity to be smooth and successful, participants need to coordinate their communicative behaviors in various ways. In human dialogues, participants agree on lexical choices to refer to objects (Brennan and Clark, 1996) and coordinate eye gaze (Richardson and Dale, 2005) and whose turn it is to speak (Sacks et al., 1974). They become more similar to their partners as the dialogue proceeds in many aspects such as pitch, speech rate, and pause structure (Burgoon et al., 1995; Hayashi et al., 2009). Such coordination serves to make conversation flow easily and intelligibly (Garrod and Pickering, 2004). The coordination of communicative behaviors also plays a crucial role in smooth human-agent interaction. Previous work addressed human behavior adaptation to agents (Oviatt et al., 2004), agent behavior adaptation to human partners (Mitsunaga et al., 2005; Tapus and Matari´c, 2007), and the mutual adaptation of human and agent behavior (Breazeal, 2003). In this paper, which addresses smooth spoken interaction between human users and agents, we focus on the adaptation of agent communicative behavior to individual users in spoken dialogues Proceedings of SIGDIAL 2010: the 11th Annual Meeting o</context>
</contexts>
<marker>Garrod, Pickering, 2004</marker>
<rawString>Simon Garrod and Martin J. Pickering. 2004. Why is conversation so easy? Trends in Cognitive Sciences, 8:8–11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takanori Hayashi</author>
<author>Shohei Kato</author>
<author>Hidenori Itoh</author>
</authors>
<title>A synchronous model of mental rhythm using paralanguage for communication robots.</title>
<date>2009</date>
<booktitle>In Lecture Notes in Computer Science (PRIMA</booktitle>
<volume>5925</volume>
<pages>376--388</pages>
<contexts>
<context position="2954" citStr="Hayashi et al., 2009" startWordPosition="437" endWordPosition="440">gues between users and agents. A spoken dialogue is a joint activity among participants (Clark, 1996). For such a joint activity to be smooth and successful, participants need to coordinate their communicative behaviors in various ways. In human dialogues, participants agree on lexical choices to refer to objects (Brennan and Clark, 1996) and coordinate eye gaze (Richardson and Dale, 2005) and whose turn it is to speak (Sacks et al., 1974). They become more similar to their partners as the dialogue proceeds in many aspects such as pitch, speech rate, and pause structure (Burgoon et al., 1995; Hayashi et al., 2009). Such coordination serves to make conversation flow easily and intelligibly (Garrod and Pickering, 2004). The coordination of communicative behaviors also plays a crucial role in smooth human-agent interaction. Previous work addressed human behavior adaptation to agents (Oviatt et al., 2004), agent behavior adaptation to human partners (Mitsunaga et al., 2005; Tapus and Matari´c, 2007), and the mutual adaptation of human and agent behavior (Breazeal, 2003). In this paper, which addresses smooth spoken interaction between human users and agents, we focus on the adaptation of agent communicativ</context>
<context position="5995" citStr="Hayashi et al., 2009" startWordPosition="900" endWordPosition="903">er focuses on agent behavior adaptation to human users, we believe that our investigation of the agent behavior adaptation mechanism in flexible spoken interaction will contribute to conversational interfaces where human users and agents can mutually adapt their communicative behaviors. As agent communicative behavior to be adapted, this paper focuses on the pause duration preceding agent utterances and the agent gaze duration. In conversation, the participant pause duration is influenced by partners, and the coordination of pause structure leads to smooth communication (Burgoon et al., 1995; Hayashi et al., 2009). Without pause structure coordination, undesired speech overlaps or utterance collisions are likely to occur between users and agents, which may disturb smooth communication. Funakoshi et al. proposed a method to prevent undesired speech overlaps in human-robot speech interactions by using a robot’s subtle expressions produced by a blinking LED attached to its chest (Funakoshi et al., 2008). In their method, a blinking light notifies users about such internal states of the robot as processing or busy and helps users identify the robot pause structures; however we are concerned with the adapta</context>
</contexts>
<marker>Hayashi, Kato, Itoh, 2009</marker>
<rawString>Takanori Hayashi, Shohei Kato, and Hidenori Itoh. 2009. A synchronous model of mental rhythm using paralanguage for communication robots. In Lecture Notes in Computer Science (PRIMA 2009), volume 5925, pages 376–388.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryuichiro Higashinaka</author>
<author>Kohji Dohsaka</author>
<author>Shigeaki Amano</author>
<author>Hideki Isozaki</author>
</authors>
<title>Effects of quizstyle information presentation on user understanding.</title>
<date>2007</date>
<booktitle>In Proc. of Interspeech</booktitle>
<pages>2725--2728</pages>
<contexts>
<context position="4433" citStr="Higashinaka et al., 2007" startWordPosition="657" endWordPosition="660">ional Linguistics 314 with flexible turn-taking. We present a method for user-adaptive coordination of agent communicative behavior to reduce the discomfort perceived by individual users during the interaction and show experimental results that evaluate how the method influences agent communicative behavior and improves its relevance as perceived by users. For evaluation purposes, we used a quizstyle multi-party spoken dialogue system (Minami et al., 2007; Dohsaka et al., 2009). A quiz-style dialogue is a kind of thought-evoking dialogue that can stir user thinking and activate communication (Higashinaka et al., 2007a; Dohsaka et al., 2009). This characteristic is expected to be advantageous for evaluation experiments since it encourages involvement in the dialogue. Our method adapts agent communicative behavior based on policy gradient reinforcement learning (Sutton et al., 2000; Kohl and Stone, 2004). The policy gradient method has been used for robot communicative behavior adaptation (Mitsunaga et al., 2005; Tapus and Matari´c, 2007). However, both studies dealt with scenariobased interaction in which a user and a robot acted with predetermined timing. In contrast, we focus on spoken dialogues in which</context>
<context position="8306" citStr="Higashinaka et al., 2007" startWordPosition="1271" endWordPosition="1274">l., 2007) and extended it to perform multi-party interaction (Dohsaka et al., 2009). In this system, a human user and one or two agents interact. The two agents include a quizmaster and a peer. The quizmaster agent creates a “Who is this?” quiz about a famous person and presents hints one by one to the user and the peer agent, who participates in the interaction and guesses the correct answer in the same way that the user does. The hints are automatically created from the biographical facts of people in Wikipedial and ranked based on the difficulty of solving the quizzes experienced by users (Higashinaka et al., 2007b). Since users must consider the hints to offer reasonable answers, the system can stimulate their thinking and encourage them to engage in the interaction (Higashinaka et al., 2007a). In addition, the peer agent’s presence and the agent’s empathic expressions improve user satisfaction and 1http://ja.wikipedia.org/ 315 Figure 1: User interacting with two agents using the quiz-style spoken dialogue system increase user utterances (Dohsaka et al., 2009). Figure 1 shows a human user interacting with the two agents, both of whom are physically embodied robots. The system utilizes an extremely lar</context>
</contexts>
<marker>Higashinaka, Dohsaka, Amano, Isozaki, 2007</marker>
<rawString>Ryuichiro Higashinaka, Kohji Dohsaka, Shigeaki Amano, and Hideki Isozaki. 2007a. Effects of quizstyle information presentation on user understanding. In Proc. of Interspeech 2007, pages 2725–2728.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryuichiro Higashinaka</author>
<author>Kohji Dohsaka</author>
<author>Hideki Isozaki</author>
</authors>
<title>Learning to rank definitions to generate quizzes for interactive information presentation.</title>
<date>2007</date>
<booktitle>In Proc. of ACL 2007 (Poster Presentation),</booktitle>
<pages>117--120</pages>
<contexts>
<context position="4433" citStr="Higashinaka et al., 2007" startWordPosition="657" endWordPosition="660">ional Linguistics 314 with flexible turn-taking. We present a method for user-adaptive coordination of agent communicative behavior to reduce the discomfort perceived by individual users during the interaction and show experimental results that evaluate how the method influences agent communicative behavior and improves its relevance as perceived by users. For evaluation purposes, we used a quizstyle multi-party spoken dialogue system (Minami et al., 2007; Dohsaka et al., 2009). A quiz-style dialogue is a kind of thought-evoking dialogue that can stir user thinking and activate communication (Higashinaka et al., 2007a; Dohsaka et al., 2009). This characteristic is expected to be advantageous for evaluation experiments since it encourages involvement in the dialogue. Our method adapts agent communicative behavior based on policy gradient reinforcement learning (Sutton et al., 2000; Kohl and Stone, 2004). The policy gradient method has been used for robot communicative behavior adaptation (Mitsunaga et al., 2005; Tapus and Matari´c, 2007). However, both studies dealt with scenariobased interaction in which a user and a robot acted with predetermined timing. In contrast, we focus on spoken dialogues in which</context>
<context position="8306" citStr="Higashinaka et al., 2007" startWordPosition="1271" endWordPosition="1274">l., 2007) and extended it to perform multi-party interaction (Dohsaka et al., 2009). In this system, a human user and one or two agents interact. The two agents include a quizmaster and a peer. The quizmaster agent creates a “Who is this?” quiz about a famous person and presents hints one by one to the user and the peer agent, who participates in the interaction and guesses the correct answer in the same way that the user does. The hints are automatically created from the biographical facts of people in Wikipedial and ranked based on the difficulty of solving the quizzes experienced by users (Higashinaka et al., 2007b). Since users must consider the hints to offer reasonable answers, the system can stimulate their thinking and encourage them to engage in the interaction (Higashinaka et al., 2007a). In addition, the peer agent’s presence and the agent’s empathic expressions improve user satisfaction and 1http://ja.wikipedia.org/ 315 Figure 1: User interacting with two agents using the quiz-style spoken dialogue system increase user utterances (Dohsaka et al., 2009). Figure 1 shows a human user interacting with the two agents, both of whom are physically embodied robots. The system utilizes an extremely lar</context>
</contexts>
<marker>Higashinaka, Dohsaka, Isozaki, 2007</marker>
<rawString>Ryuichiro Higashinaka, Kohji Dohsaka, and Hideki Isozaki. 2007b. Learning to rank definitions to generate quizzes for interactive information presentation. In Proc. of ACL 2007 (Poster Presentation), pages 117–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takaaki Hori</author>
<author>Chiori Hori</author>
<author>Yasuhiro Minami</author>
<author>Atsushi Nakamura</author>
</authors>
<title>Efficient WFST-based onepass decoding with on-the-fly hypothesis rescoring in extremely large vocabulary continuous speech recognition.</title>
<date>2007</date>
<journal>IEEE Transactions on Audio, Speech and Language Processing,</journal>
<pages>15--1352</pages>
<contexts>
<context position="8974" citStr="Hori et al., 2007" startWordPosition="1374" endWordPosition="1377">easonable answers, the system can stimulate their thinking and encourage them to engage in the interaction (Higashinaka et al., 2007a). In addition, the peer agent’s presence and the agent’s empathic expressions improve user satisfaction and 1http://ja.wikipedia.org/ 315 Figure 1: User interacting with two agents using the quiz-style spoken dialogue system increase user utterances (Dohsaka et al., 2009). Figure 1 shows a human user interacting with the two agents, both of whom are physically embodied robots. The system utilizes an extremely large vocabulary with continuous speech recognition (Hori et al., 2007). Agent utterances are produced by speech synthesis. The agents can gaze at other participants by directing their faces to them. At each point of the dialogue, the system chooses the next speaker and its utterance based on the dialogue state that the system maintains, the preconditions of the individual utterances, and a few turn-taking rules (Dohsaka et al., 2009). The agent pause and gaze durations are controlled based on the adaptation method described in Section 3. A sample dialogue among a user and two agents is depicted in Figure 2. Master is the quizmaster agent, and Peer is the peer ag</context>
</contexts>
<marker>Hori, Hori, Minami, Nakamura, 2007</marker>
<rawString>Takaaki Hori, Chiori Hori, Yasuhiro Minami, and Atsushi Nakamura. 2007. Efficient WFST-based onepass decoding with on-the-fly hypothesis rescoring in extremely large vocabulary continuous speech recognition. IEEE Transactions on Audio, Speech and Language Processing, 15:1352–1365.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Toshihiko Itoh</author>
<author>Norihide Kitaoka</author>
<author>Ryota Nishimura</author>
</authors>
<title>Subjective experiments on influence of response timing in spoken dialogues.</title>
<date>2009</date>
<booktitle>In Proc. of Interspeech</booktitle>
<pages>1835--1838</pages>
<contexts>
<context position="15452" citStr="Itoh et al., 2009" startWordPosition="2465" endWordPosition="2468"> adapting the policy parameters. In this experiment, we used the following four parameters (n = 4): • pre-spontaneous-utterance pause duration Qspon: duration of pauses preceding agent spontaneous utterances • pre-responsive-utterance pause duration Qres: duration of pauses preceding agent responsive utterances • gaze duration Qgaze: duration of agent’s directing its face to the other while it is speaking or listening • hint interval Qhint: interval of presenting quiz hints As shown above, we used two types of pause duration since the relevant pause duration can be dependent on dialogue acts (Itoh et al., 2009). Although our main concern is the pause and gaze duration, we examined the hint interval as a parameter particular to quiz-style dialogues. To adapt the policy parameters to individual users, we first generate T random perturbations [Rl, ... , RT ] of current policy O by randomly adding Ej, 0, —Ej to each parameter Bj of O in lines 6 to 9, where Ej is a step size set for each parameter. In the experiment, we set T to 10. The step sizes of the parameters used in the experiment will be shown later in Table 1. Dialogue per hint (a hint dialogue) is then performed based on each perturbation polic</context>
</contexts>
<marker>Itoh, Kitaoka, Nishimura, 2009</marker>
<rawString>Toshihiko Itoh, Norihide Kitaoka, and Ryota Nishimura. 2009. Subjective experiments on influence of response timing in spoken dialogues. In Proc. of Interspeech 2009, pages 1835–1838.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Lewis Johnson</author>
<author>Jeff W Rickel</author>
<author>James C Lester</author>
</authors>
<title>Animated pedagogical aqgents: face-to-face interaction in interactive learning environments.</title>
<date>2002</date>
<journal>International Journal of Artificial Intelligence in Education,</journal>
<pages>11--47</pages>
<contexts>
<context position="1555" citStr="Johnson et al., 2002" startWordPosition="203" endWordPosition="206">ion preceding agent utterances and the agent gaze duration to reduce the discomfort perceived by individual users during interaction. The experimental results showed a statistically significant tendency: the duration of the agent pause and the gaze converged during interaction with the method. The method also significantly improved the perceived relevance of the agent communicative behavior. 1 Introduction Conversational agents have been studied as an effective human-computer interface for such purposes as training decision-making in team activities (Traum and Rickel, 2002), learning support (Johnson et al., 2002), museum guides (Kopp et al., 2005), and community facilitators (Zheng et al., 2005; Fujie et al., 2009). They will play a crucial role in establishing a society where humans and robots collaborate through natural interaction. However, agents cannot produce their intended effects when the smooth flow of interaction is disturbed. To fully exploit the promise of agents, we need to achieve smooth interaction between human users and agents. Although various types of modalities have been used in human-computer interfaces, speech has drawn a great deal of interest because it is one of the most perva</context>
</contexts>
<marker>Johnson, Rickel, Lester, 2002</marker>
<rawString>W. Lewis Johnson, Jeff W. Rickel, and James C. Lester. 2002. Animated pedagogical aqgents: face-to-face interaction in interactive learning environments. International Journal of Artificial Intelligence in Education, 11:47–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hajime Kimura</author>
<author>Shigenobu Kobayashi</author>
</authors>
<title>Reinforcement learning for continuous action using stochastic gradient ascent.</title>
<date>1998</date>
<booktitle>In Proc. of the 5th International Conference on Intelligent Autonomous Systems,</booktitle>
<pages>288--295</pages>
<contexts>
<context position="12202" citStr="Kimura and Kobayashi, 1998" startWordPosition="1894" endWordPosition="1897">. A policy gradient method is a reinforcement learning (RL) approach that directly optimizes a parameterized policy by gradient ascent based on the gradient of the expected reward with respect to the policy parameters. Although RL methods have recently been applied to optimizing dialogue management in spoken dialogue systems (Williams and Young, 2007; Minami et al., 2009), these previous studies utilized RL methods based on the value-function estimation. The policy gradient method is an alternative approach to RL that has the following merits. It can handle continuous and large action spaces (Kimura and Kobayashi, 1998) and is usually assured to converge to a locally optimal policy in such action spaces (Sutton et al., 2000). Moreover, it does not need to explicitly estimate the value function, and it is incremental, requiring only a constant amount of computation per learning step (Kimura and Kobayashi, 1998). Due to these advantages, the policy gradient method is suitable for adapting agent communicative behavior to a user during interaction, because 316 (1) O = [Bj] &lt;-- initial policy (policy parameter vector of size n) (2) c = [Ej] &lt;-- step size vector of size n (3) η &lt;-- overall scalar step size (4) max</context>
</contexts>
<marker>Kimura, Kobayashi, 1998</marker>
<rawString>Hajime Kimura and Shigenobu Kobayashi. 1998. Reinforcement learning for continuous action using stochastic gradient ascent. In Proc. of the 5th International Conference on Intelligent Autonomous Systems, pages 288–295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nate Kohl</author>
<author>Peter Stone</author>
</authors>
<title>Policy gradient reinforcement learning for fast quadrupedal locomotion.</title>
<date>2004</date>
<booktitle>In Proc. of ICRA 2004,</booktitle>
<volume>3</volume>
<pages>2619--2624</pages>
<contexts>
<context position="4724" citStr="Kohl and Stone, 2004" startWordPosition="701" endWordPosition="704">ative behavior and improves its relevance as perceived by users. For evaluation purposes, we used a quizstyle multi-party spoken dialogue system (Minami et al., 2007; Dohsaka et al., 2009). A quiz-style dialogue is a kind of thought-evoking dialogue that can stir user thinking and activate communication (Higashinaka et al., 2007a; Dohsaka et al., 2009). This characteristic is expected to be advantageous for evaluation experiments since it encourages involvement in the dialogue. Our method adapts agent communicative behavior based on policy gradient reinforcement learning (Sutton et al., 2000; Kohl and Stone, 2004). The policy gradient method has been used for robot communicative behavior adaptation (Mitsunaga et al., 2005; Tapus and Matari´c, 2007). However, both studies dealt with scenariobased interaction in which a user and a robot acted with predetermined timing. In contrast, we focus on spoken dialogues in which users and agents can speak with more flexible timing. In addition, we allow for two- and three-party interactions among a user and two agents. It remains unclear whether the policy gradient method can successfully adapt agent communicative behavior to a user in twoor three-party spoken dia</context>
<context position="10594" citStr="Kohl and Stone, 2004" startWordPosition="1638" endWordPosition="1641">ng hints (lines 1 and 5), indicating the quiz difficulty, and addressing listeners. It also makes such responsive utterances as evaluating the other’s answers (lines 3, 9, and 11). Peer agent Peer makes such spontaneous utterances as showing its own difficulty (line 4), giving an answer (line 8), giving feedback when its own or the other’s answer is right (line 12), and addressing listeners. It also makes such responsive utterances as showing empathy to the user (line 7). 3 Method for Agent Communicative Behavior Adaptation We apply policy gradient reinforcement learning (Sutton et al., 2000; Kohl and Stone, 2004) 1 Master Who is this? First hint. He graduated from the University of Tokyo. (hint/spon) 2 User Yoshida Shigeru? (answer/spon) 3 Master No, not even close! He’s not a politician. (evaluation/res) 4 Peer I don’t know. Very difficult. (show difficulty/spon) 5 Master It’s time for the second hint: He’s a novelist and a scholar of British literature. (hint/spon) 6 User Oh, I think I know it but I can’t remember his name. That’s so frustrating. (show difficulty/spon) 7 Peer Difficult for me, too. (show empathy/res) 8 Peer Haruki Murakami? (answer/spon) 9 Master Close! You are half right, because h</context>
<context position="14381" citStr="Kohl and Stone (2004)" startWordPosition="2289" endWordPosition="2292">daptive coordination of agent communicative behavior it can naturally incorporate such continuous parameters as pause and gaze duration and incrementally adapt agent behavior. In fact, the policy gradient method has been successfully used for robot behavior adaptation (Mitsunaga et al., 2005; Tapus and Matari´c, 2007). In this paper, we apply this method to agent communicative behavior adaptation in spoken dialogues with flexible turn-taking. Figure 3 shows our method for the user-adaptive coordination of agent communicative behavior. This method is a modification of an algorithm presented by Kohl and Stone (2004) in that the gradient is adjusted based on the maximum absolute value of the reward obtained during each adaptation cycle. The agent communicative behaviors are determined based on a policy that is represented as vector O(= [Bj]) of n policy parameters. In the quizstyle dialogues, the behavior of both the quizmaster and peer agents is controlled based on the same policy parameters. The method adapts the behavior of both agents to individual users by adapting the policy parameters. In this experiment, we used the following four parameters (n = 4): • pre-spontaneous-utterance pause duration Qspo</context>
</contexts>
<marker>Kohl, Stone, 2004</marker>
<rawString>Nate Kohl and Peter Stone. 2004. Policy gradient reinforcement learning for fast quadrupedal locomotion. In Proc. of ICRA 2004, volume 3, pages 2619–2624.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Kopp</author>
<author>Lars Gesellensetter</author>
<author>Nicole C Kr¨amer</author>
<author>Ipke Wachsmuth</author>
</authors>
<title>A conversational agent as museum guide: design and evaluation of a realworld application.</title>
<date>2005</date>
<booktitle>In Lecture Notes in Computer Science (IVA</booktitle>
<volume>3661</volume>
<pages>329--343</pages>
<marker>Kopp, Gesellensetter, Kr¨amer, Wachsmuth, 2005</marker>
<rawString>Stefan Kopp, Lars Gesellensetter, Nicole C. Kr¨amer, and Ipke Wachsmuth. 2005. A conversational agent as museum guide: design and evaluation of a realworld application. In Lecture Notes in Computer Science (IVA 2009), volume 3661, pages 329–343.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasuhiro Minami</author>
</authors>
<title>Minako Sawaki, Kohji Dohsaka, Ryuichiro Higashinaka, Kentaro Ishizuka, Hideki Isozaki, Tatsushi Matsubayashi,</title>
<date>2007</date>
<booktitle>In Proc. of ICMI</booktitle>
<pages>366--373</pages>
<location>Masato Miyoshi, Atsushi Nakamura, Takanobu Oba, Hiroshi Sawada, Takeshi Yamada, and</location>
<marker>Minami, 2007</marker>
<rawString>Yasuhiro Minami, Minako Sawaki, Kohji Dohsaka, Ryuichiro Higashinaka, Kentaro Ishizuka, Hideki Isozaki, Tatsushi Matsubayashi, Masato Miyoshi, Atsushi Nakamura, Takanobu Oba, Hiroshi Sawada, Takeshi Yamada, and Eisaku Maeda. 2007. The World of Mushrooms: human-computer interaction prototype systems for ambient intelligence. In Proc. of ICMI 2007, pages 366–373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasuhiro Minami</author>
<author>Akira Mori</author>
<author>Ryuichiro Higashinaka</author>
<author>Kohji Dohsaka</author>
<author>Eisaku Maeda</author>
</authors>
<title>Dialogue control algorithm for ambient intelligence based on partially observable Markov decision processes.</title>
<date>2009</date>
<booktitle>In Proc. of IWSDS</booktitle>
<contexts>
<context position="11949" citStr="Minami et al., 2009" startWordPosition="1852" endWordPosition="1856">d job. (feedback/spon) Figure 2: Sample dialogue between user and two agents: quizmaster Master and peer Peer. Spon identifies spontaneous and res identifies responsive utterances. to the user-adaptive coordination of agent communicative behavior. A policy gradient method is a reinforcement learning (RL) approach that directly optimizes a parameterized policy by gradient ascent based on the gradient of the expected reward with respect to the policy parameters. Although RL methods have recently been applied to optimizing dialogue management in spoken dialogue systems (Williams and Young, 2007; Minami et al., 2009), these previous studies utilized RL methods based on the value-function estimation. The policy gradient method is an alternative approach to RL that has the following merits. It can handle continuous and large action spaces (Kimura and Kobayashi, 1998) and is usually assured to converge to a locally optimal policy in such action spaces (Sutton et al., 2000). Moreover, it does not need to explicitly estimate the value function, and it is incremental, requiring only a constant amount of computation per learning step (Kimura and Kobayashi, 1998). Due to these advantages, the policy gradient meth</context>
</contexts>
<marker>Minami, Mori, Higashinaka, Dohsaka, Maeda, 2009</marker>
<rawString>Yasuhiro Minami, Akira Mori, Ryuichiro Higashinaka, Kohji Dohsaka, and Eisaku Maeda. 2009. Dialogue control algorithm for ambient intelligence based on partially observable Markov decision processes. In Proc. of IWSDS 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noriaki Mitsunaga</author>
<author>Christian Smith</author>
<author>Takayuki Kanda</author>
<author>Hiroshi Isiguro</author>
<author>Norihiro Hagita</author>
</authors>
<title>Human-robot interaction based on policy gradient reinforcement learning.</title>
<date>2005</date>
<booktitle>In Proc. of IROS</booktitle>
<pages>1594--1601</pages>
<contexts>
<context position="3316" citStr="Mitsunaga et al., 2005" startWordPosition="489" endWordPosition="493">aze (Richardson and Dale, 2005) and whose turn it is to speak (Sacks et al., 1974). They become more similar to their partners as the dialogue proceeds in many aspects such as pitch, speech rate, and pause structure (Burgoon et al., 1995; Hayashi et al., 2009). Such coordination serves to make conversation flow easily and intelligibly (Garrod and Pickering, 2004). The coordination of communicative behaviors also plays a crucial role in smooth human-agent interaction. Previous work addressed human behavior adaptation to agents (Oviatt et al., 2004), agent behavior adaptation to human partners (Mitsunaga et al., 2005; Tapus and Matari´c, 2007), and the mutual adaptation of human and agent behavior (Breazeal, 2003). In this paper, which addresses smooth spoken interaction between human users and agents, we focus on the adaptation of agent communicative behavior to individual users in spoken dialogues Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 314–321, The University of Tokyo, September 24-25, 2010. c�2010 Association for Computational Linguistics 314 with flexible turn-taking. We present a method for user-adaptive coordination of agen</context>
<context position="4834" citStr="Mitsunaga et al., 2005" startWordPosition="718" endWordPosition="721"> multi-party spoken dialogue system (Minami et al., 2007; Dohsaka et al., 2009). A quiz-style dialogue is a kind of thought-evoking dialogue that can stir user thinking and activate communication (Higashinaka et al., 2007a; Dohsaka et al., 2009). This characteristic is expected to be advantageous for evaluation experiments since it encourages involvement in the dialogue. Our method adapts agent communicative behavior based on policy gradient reinforcement learning (Sutton et al., 2000; Kohl and Stone, 2004). The policy gradient method has been used for robot communicative behavior adaptation (Mitsunaga et al., 2005; Tapus and Matari´c, 2007). However, both studies dealt with scenariobased interaction in which a user and a robot acted with predetermined timing. In contrast, we focus on spoken dialogues in which users and agents can speak with more flexible timing. In addition, we allow for two- and three-party interactions among a user and two agents. It remains unclear whether the policy gradient method can successfully adapt agent communicative behavior to a user in twoor three-party spoken dialogues with flexible turntaking. Although this paper focuses on agent behavior adaptation to human users, we b</context>
<context position="14052" citStr="Mitsunaga et al., 2005" startWordPosition="2238" endWordPosition="2241">g+E,j and Avg0,j &gt; Avg_E,j) (17) aj &lt;-- 0 (18) else (19) aj &lt;-- Avg+E,j — Avg_E,j aj (20) bj(aj &lt;-- |A |* Ej * η) (21) maxC &lt;-- maximum of absolute value of reward in current adaptation cycle (22) if (maxC &gt; maxA) (23) maxA &lt;-- maxC (update maxA) (24) else (25) A &lt;-- A * maxC maxA (26) O &lt;-- O + A Figure 3: Pseudocode for user-adaptive coordination of agent communicative behavior it can naturally incorporate such continuous parameters as pause and gaze duration and incrementally adapt agent behavior. In fact, the policy gradient method has been successfully used for robot behavior adaptation (Mitsunaga et al., 2005; Tapus and Matari´c, 2007). In this paper, we apply this method to agent communicative behavior adaptation in spoken dialogues with flexible turn-taking. Figure 3 shows our method for the user-adaptive coordination of agent communicative behavior. This method is a modification of an algorithm presented by Kohl and Stone (2004) in that the gradient is adjusted based on the maximum absolute value of the reward obtained during each adaptation cycle. The agent communicative behaviors are determined based on a policy that is represented as vector O(= [Bj]) of n policy parameters. In the quizstyle </context>
</contexts>
<marker>Mitsunaga, Smith, Kanda, Isiguro, Hagita, 2005</marker>
<rawString>Noriaki Mitsunaga, Christian Smith, Takayuki Kanda, Hiroshi Isiguro, and Norihiro Hagita. 2005. Human-robot interaction based on policy gradient reinforcement learning. In Proc. of IROS 2005, pages 1594–1601.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Clifford Nass</author>
<author>Scott Brave</author>
</authors>
<title>Wired for Speech: How Voice Activates and Advances the Human-Computer Relationship.</title>
<date>2005</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="2276" citStr="Nass and Brave, 2005" startWordPosition="321" endWordPosition="324">009). They will play a crucial role in establishing a society where humans and robots collaborate through natural interaction. However, agents cannot produce their intended effects when the smooth flow of interaction is disturbed. To fully exploit the promise of agents, we need to achieve smooth interaction between human users and agents. Although various types of modalities have been used in human-computer interfaces, speech has drawn a great deal of interest because it is one of the most pervasive communication methods in our daily lives and we usually perform it without any special effort (Nass and Brave, 2005). In this paper, we are interested in smooth spoken dialogues between users and agents. A spoken dialogue is a joint activity among participants (Clark, 1996). For such a joint activity to be smooth and successful, participants need to coordinate their communicative behaviors in various ways. In human dialogues, participants agree on lexical choices to refer to objects (Brennan and Clark, 1996) and coordinate eye gaze (Richardson and Dale, 2005) and whose turn it is to speak (Sacks et al., 1974). They become more similar to their partners as the dialogue proceeds in many aspects such as pitch,</context>
</contexts>
<marker>Nass, Brave, 2005</marker>
<rawString>Clifford Nass and Scott Brave. 2005. Wired for Speech: How Voice Activates and Advances the Human-Computer Relationship. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Oviatt</author>
<author>Courtney Darves</author>
<author>Rachel Coulston</author>
</authors>
<title>Toward adaptive conversational interfaces: modeling speech convergence with animated personas.</title>
<date>2004</date>
<journal>ACM Transactions on Computer-Human Interaction,</journal>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="3247" citStr="Oviatt et al., 2004" startWordPosition="479" endWordPosition="482"> to refer to objects (Brennan and Clark, 1996) and coordinate eye gaze (Richardson and Dale, 2005) and whose turn it is to speak (Sacks et al., 1974). They become more similar to their partners as the dialogue proceeds in many aspects such as pitch, speech rate, and pause structure (Burgoon et al., 1995; Hayashi et al., 2009). Such coordination serves to make conversation flow easily and intelligibly (Garrod and Pickering, 2004). The coordination of communicative behaviors also plays a crucial role in smooth human-agent interaction. Previous work addressed human behavior adaptation to agents (Oviatt et al., 2004), agent behavior adaptation to human partners (Mitsunaga et al., 2005; Tapus and Matari´c, 2007), and the mutual adaptation of human and agent behavior (Breazeal, 2003). In this paper, which addresses smooth spoken interaction between human users and agents, we focus on the adaptation of agent communicative behavior to individual users in spoken dialogues Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 314–321, The University of Tokyo, September 24-25, 2010. c�2010 Association for Computational Linguistics 314 with flexible tu</context>
</contexts>
<marker>Oviatt, Darves, Coulston, 2004</marker>
<rawString>Sharon Oviatt, Courtney Darves, and Rachel Coulston. 2004. Toward adaptive conversational interfaces: modeling speech convergence with animated personas. ACM Transactions on Computer-Human Interaction, 11(3):300–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel C Richardson</author>
<author>Rick Dale</author>
</authors>
<title>Looking to understand: the coupling between speakers’ and listeners’ eye movements and its relationship to discourse comprehension.</title>
<date>2005</date>
<journal>Cognitive Science,</journal>
<pages>29--1045</pages>
<contexts>
<context position="2725" citStr="Richardson and Dale, 2005" startWordPosition="395" endWordPosition="398">eat deal of interest because it is one of the most pervasive communication methods in our daily lives and we usually perform it without any special effort (Nass and Brave, 2005). In this paper, we are interested in smooth spoken dialogues between users and agents. A spoken dialogue is a joint activity among participants (Clark, 1996). For such a joint activity to be smooth and successful, participants need to coordinate their communicative behaviors in various ways. In human dialogues, participants agree on lexical choices to refer to objects (Brennan and Clark, 1996) and coordinate eye gaze (Richardson and Dale, 2005) and whose turn it is to speak (Sacks et al., 1974). They become more similar to their partners as the dialogue proceeds in many aspects such as pitch, speech rate, and pause structure (Burgoon et al., 1995; Hayashi et al., 2009). Such coordination serves to make conversation flow easily and intelligibly (Garrod and Pickering, 2004). The coordination of communicative behaviors also plays a crucial role in smooth human-agent interaction. Previous work addressed human behavior adaptation to agents (Oviatt et al., 2004), agent behavior adaptation to human partners (Mitsunaga et al., 2005; Tapus a</context>
<context position="6733" citStr="Richardson and Dale, 2005" startWordPosition="1016" endWordPosition="1019">tween users and agents, which may disturb smooth communication. Funakoshi et al. proposed a method to prevent undesired speech overlaps in human-robot speech interactions by using a robot’s subtle expressions produced by a blinking LED attached to its chest (Funakoshi et al., 2008). In their method, a blinking light notifies users about such internal states of the robot as processing or busy and helps users identify the robot pause structures; however we are concerned with the adaptation of robot pause structures to users. Gaze coordination is causally related to the success of communication (Richardson and Dale, 2005), and the amount of gaze influences conversational turn-taking (Vertegaal and Ding, 2002). The relevant control of agent gaze duration is thus essential to the smooth flow of conversation. Moreover, since the amount of gaze is related to specific interpersonal attitudes among participants and is also subject to such individual differences as personalities (Argyle and Cook, 1976), agent gaze duration must be adapted to individual users. In the following, Section 2 describes our quizstyle multi-party spoken dialogue system. Section 3 shows our method for the user-adaptive coordination of agent c</context>
</contexts>
<marker>Richardson, Dale, 2005</marker>
<rawString>Daniel C. Richardson and Rick Dale. 2005. Looking to understand: the coupling between speakers’ and listeners’ eye movements and its relationship to discourse comprehension. Cognitive Science, 29:1045–1060.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harvey Sacks</author>
<author>Emanuel A Schegloff</author>
<author>Gail Jefferson</author>
</authors>
<title>A simplest systematics for the organization of turn-taking in conversation.</title>
<date>1974</date>
<journal>Language,</journal>
<pages>50--696</pages>
<contexts>
<context position="2776" citStr="Sacks et al., 1974" startWordPosition="406" endWordPosition="409">ve communication methods in our daily lives and we usually perform it without any special effort (Nass and Brave, 2005). In this paper, we are interested in smooth spoken dialogues between users and agents. A spoken dialogue is a joint activity among participants (Clark, 1996). For such a joint activity to be smooth and successful, participants need to coordinate their communicative behaviors in various ways. In human dialogues, participants agree on lexical choices to refer to objects (Brennan and Clark, 1996) and coordinate eye gaze (Richardson and Dale, 2005) and whose turn it is to speak (Sacks et al., 1974). They become more similar to their partners as the dialogue proceeds in many aspects such as pitch, speech rate, and pause structure (Burgoon et al., 1995; Hayashi et al., 2009). Such coordination serves to make conversation flow easily and intelligibly (Garrod and Pickering, 2004). The coordination of communicative behaviors also plays a crucial role in smooth human-agent interaction. Previous work addressed human behavior adaptation to agents (Oviatt et al., 2004), agent behavior adaptation to human partners (Mitsunaga et al., 2005; Tapus and Matari´c, 2007), and the mutual adaptation of hu</context>
</contexts>
<marker>Sacks, Schegloff, Jefferson, 1974</marker>
<rawString>Harvey Sacks, Emanuel A. Schegloff, and Gail Jefferson. 1974. A simplest systematics for the organization of turn-taking in conversation. Language, 50:696–735.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard S Sutton</author>
<author>David McAllester</author>
<author>Satinder Singh</author>
<author>Yishay Mansour</author>
</authors>
<title>Policy gradient methods for reinforcement learning with function approximation.</title>
<date>2000</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<volume>12</volume>
<pages>1057--1063</pages>
<contexts>
<context position="4701" citStr="Sutton et al., 2000" startWordPosition="697" endWordPosition="700">uences agent communicative behavior and improves its relevance as perceived by users. For evaluation purposes, we used a quizstyle multi-party spoken dialogue system (Minami et al., 2007; Dohsaka et al., 2009). A quiz-style dialogue is a kind of thought-evoking dialogue that can stir user thinking and activate communication (Higashinaka et al., 2007a; Dohsaka et al., 2009). This characteristic is expected to be advantageous for evaluation experiments since it encourages involvement in the dialogue. Our method adapts agent communicative behavior based on policy gradient reinforcement learning (Sutton et al., 2000; Kohl and Stone, 2004). The policy gradient method has been used for robot communicative behavior adaptation (Mitsunaga et al., 2005; Tapus and Matari´c, 2007). However, both studies dealt with scenariobased interaction in which a user and a robot acted with predetermined timing. In contrast, we focus on spoken dialogues in which users and agents can speak with more flexible timing. In addition, we allow for two- and three-party interactions among a user and two agents. It remains unclear whether the policy gradient method can successfully adapt agent communicative behavior to a user in twoor</context>
<context position="10571" citStr="Sutton et al., 2000" startWordPosition="1634" endWordPosition="1637">nces such as presenting hints (lines 1 and 5), indicating the quiz difficulty, and addressing listeners. It also makes such responsive utterances as evaluating the other’s answers (lines 3, 9, and 11). Peer agent Peer makes such spontaneous utterances as showing its own difficulty (line 4), giving an answer (line 8), giving feedback when its own or the other’s answer is right (line 12), and addressing listeners. It also makes such responsive utterances as showing empathy to the user (line 7). 3 Method for Agent Communicative Behavior Adaptation We apply policy gradient reinforcement learning (Sutton et al., 2000; Kohl and Stone, 2004) 1 Master Who is this? First hint. He graduated from the University of Tokyo. (hint/spon) 2 User Yoshida Shigeru? (answer/spon) 3 Master No, not even close! He’s not a politician. (evaluation/res) 4 Peer I don’t know. Very difficult. (show difficulty/spon) 5 Master It’s time for the second hint: He’s a novelist and a scholar of British literature. (hint/spon) 6 User Oh, I think I know it but I can’t remember his name. That’s so frustrating. (show difficulty/spon) 7 Peer Difficult for me, too. (show empathy/res) 8 Peer Haruki Murakami? (answer/spon) 9 Master Close! You ar</context>
<context position="12309" citStr="Sutton et al., 2000" startWordPosition="1915" endWordPosition="1918">y by gradient ascent based on the gradient of the expected reward with respect to the policy parameters. Although RL methods have recently been applied to optimizing dialogue management in spoken dialogue systems (Williams and Young, 2007; Minami et al., 2009), these previous studies utilized RL methods based on the value-function estimation. The policy gradient method is an alternative approach to RL that has the following merits. It can handle continuous and large action spaces (Kimura and Kobayashi, 1998) and is usually assured to converge to a locally optimal policy in such action spaces (Sutton et al., 2000). Moreover, it does not need to explicitly estimate the value function, and it is incremental, requiring only a constant amount of computation per learning step (Kimura and Kobayashi, 1998). Due to these advantages, the policy gradient method is suitable for adapting agent communicative behavior to a user during interaction, because 316 (1) O = [Bj] &lt;-- initial policy (policy parameter vector of size n) (2) c = [Ej] &lt;-- step size vector of size n (3) η &lt;-- overall scalar step size (4) maxA &lt;-- 0 (greatest absolute value of reward ever observed in adaptation process) (5) while dialogue continue</context>
</contexts>
<marker>Sutton, McAllester, Singh, Mansour, 2000</marker>
<rawString>Richard S. Sutton, David McAllester, Satinder Singh, and Yishay Mansour. 2000. Policy gradient methods for reinforcement learning with function approximation. In Advances in Neural Information Processing Systems, volume 12, pages 1057–1063.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adriana Tapus</author>
<author>Maja J Matari´c</author>
</authors>
<title>Hands-off therapist robot behavior adaptation to user personality for post-stroke rehabilitation therapy.</title>
<date>2007</date>
<booktitle>In Proc. of 2007 IEEE International Conference on Robotics and Automation,</booktitle>
<pages>1547--1553</pages>
<marker>Tapus, Matari´c, 2007</marker>
<rawString>Adriana Tapus and Maja J. Matari´c. 2007. Hands-off therapist robot behavior adaptation to user personality for post-stroke rehabilitation therapy. In Proc. of 2007 IEEE International Conference on Robotics and Automation, pages 1547–1553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Traum</author>
<author>Jeff Rickel</author>
</authors>
<title>Embodied agents for multi-party dialogue in immersive virtual worlds.</title>
<date>2002</date>
<booktitle>In Proc. of AAMAS</booktitle>
<pages>766--773</pages>
<contexts>
<context position="1514" citStr="Traum and Rickel, 2002" startWordPosition="196" endWordPosition="199">behavior. Our method adapts the pause duration preceding agent utterances and the agent gaze duration to reduce the discomfort perceived by individual users during interaction. The experimental results showed a statistically significant tendency: the duration of the agent pause and the gaze converged during interaction with the method. The method also significantly improved the perceived relevance of the agent communicative behavior. 1 Introduction Conversational agents have been studied as an effective human-computer interface for such purposes as training decision-making in team activities (Traum and Rickel, 2002), learning support (Johnson et al., 2002), museum guides (Kopp et al., 2005), and community facilitators (Zheng et al., 2005; Fujie et al., 2009). They will play a crucial role in establishing a society where humans and robots collaborate through natural interaction. However, agents cannot produce their intended effects when the smooth flow of interaction is disturbed. To fully exploit the promise of agents, we need to achieve smooth interaction between human users and agents. Although various types of modalities have been used in human-computer interfaces, speech has drawn a great deal of int</context>
</contexts>
<marker>Traum, Rickel, 2002</marker>
<rawString>David Traum and Jeff Rickel. 2002. Embodied agents for multi-party dialogue in immersive virtual worlds. In Proc. of AAMAS 2002, pages 766–773.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roel Vertegaal</author>
<author>Yaping Ding</author>
</authors>
<title>Explaining effects of eye gaze on mediated group conversations: amount or synchronization.</title>
<date>2002</date>
<booktitle>In Proc. of CSCW</booktitle>
<pages>41--48</pages>
<contexts>
<context position="6822" citStr="Vertegaal and Ding, 2002" startWordPosition="1029" endWordPosition="1032">a method to prevent undesired speech overlaps in human-robot speech interactions by using a robot’s subtle expressions produced by a blinking LED attached to its chest (Funakoshi et al., 2008). In their method, a blinking light notifies users about such internal states of the robot as processing or busy and helps users identify the robot pause structures; however we are concerned with the adaptation of robot pause structures to users. Gaze coordination is causally related to the success of communication (Richardson and Dale, 2005), and the amount of gaze influences conversational turn-taking (Vertegaal and Ding, 2002). The relevant control of agent gaze duration is thus essential to the smooth flow of conversation. Moreover, since the amount of gaze is related to specific interpersonal attitudes among participants and is also subject to such individual differences as personalities (Argyle and Cook, 1976), agent gaze duration must be adapted to individual users. In the following, Section 2 describes our quizstyle multi-party spoken dialogue system. Section 3 shows our method for the user-adaptive coordination of agent communicative behavior. Section 4 explains the experiment, and Section 5 describes its res</context>
</contexts>
<marker>Vertegaal, Ding, 2002</marker>
<rawString>Roel Vertegaal and Yaping Ding. 2002. Explaining effects of eye gaze on mediated group conversations: amount or synchronization. In Proc. of CSCW 2002, pages 41–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason D Williams</author>
<author>Steve Young</author>
</authors>
<title>Partially observable Markov decision processes for spoken dialog systems.</title>
<date>2007</date>
<journal>Computer &amp; Speech Language,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="11927" citStr="Williams and Young, 2007" startWordPosition="1848" endWordPosition="1851">valuation/res) 12 Peer Good job. (feedback/spon) Figure 2: Sample dialogue between user and two agents: quizmaster Master and peer Peer. Spon identifies spontaneous and res identifies responsive utterances. to the user-adaptive coordination of agent communicative behavior. A policy gradient method is a reinforcement learning (RL) approach that directly optimizes a parameterized policy by gradient ascent based on the gradient of the expected reward with respect to the policy parameters. Although RL methods have recently been applied to optimizing dialogue management in spoken dialogue systems (Williams and Young, 2007; Minami et al., 2009), these previous studies utilized RL methods based on the value-function estimation. The policy gradient method is an alternative approach to RL that has the following merits. It can handle continuous and large action spaces (Kimura and Kobayashi, 1998) and is usually assured to converge to a locally optimal policy in such action spaces (Sutton et al., 2000). Moreover, it does not need to explicitly estimate the value function, and it is incremental, requiring only a constant amount of computation per learning step (Kimura and Kobayashi, 1998). Due to these advantages, th</context>
</contexts>
<marker>Williams, Young, 2007</marker>
<rawString>Jason D. Williams and Steve Young. 2007. Partially observable Markov decision processes for spoken dialog systems. Computer &amp; Speech Language, 21(2):393–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Zheng</author>
<author>Xiang Yuan</author>
<author>Yam San Chee</author>
</authors>
<title>Designing multiparty interaction support in Elva, an embodied tour guide.</title>
<date>2005</date>
<booktitle>In Proc. of AAMAS</booktitle>
<pages>929--936</pages>
<contexts>
<context position="1638" citStr="Zheng et al., 2005" startWordPosition="216" endWordPosition="219">rceived by individual users during interaction. The experimental results showed a statistically significant tendency: the duration of the agent pause and the gaze converged during interaction with the method. The method also significantly improved the perceived relevance of the agent communicative behavior. 1 Introduction Conversational agents have been studied as an effective human-computer interface for such purposes as training decision-making in team activities (Traum and Rickel, 2002), learning support (Johnson et al., 2002), museum guides (Kopp et al., 2005), and community facilitators (Zheng et al., 2005; Fujie et al., 2009). They will play a crucial role in establishing a society where humans and robots collaborate through natural interaction. However, agents cannot produce their intended effects when the smooth flow of interaction is disturbed. To fully exploit the promise of agents, we need to achieve smooth interaction between human users and agents. Although various types of modalities have been used in human-computer interfaces, speech has drawn a great deal of interest because it is one of the most pervasive communication methods in our daily lives and we usually perform it without any</context>
</contexts>
<marker>Zheng, Yuan, Chee, 2005</marker>
<rawString>Jun Zheng, Xiang Yuan, and Yam San Chee. 2005. Designing multiparty interaction support in Elva, an embodied tour guide. In Proc. of AAMAS 2005, pages 929–936.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>