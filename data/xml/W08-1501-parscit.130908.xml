<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.024254">
<title confidence="0.991436">
Mitigation of data sparsity in classifier-based translation
</title>
<author confidence="0.884422">
Emil Ettelaie, Panayiotis G. Georgiou, Shrikanth S. Narayanan
</author>
<affiliation confidence="0.94030175">
Signal Analysis and Interpretation Laboratory
Ming Hsieh Department of Electrical Engineering
Viterbi School of Engineering
University of Southern California
</affiliation>
<email confidence="0.998841">
ettelaie@usc.edu
</email>
<sectionHeader confidence="0.993897" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999830666666667">
The concept classifier has been used as a
translation unit in speech-to-speech trans-
lation systems. However, the sparsity of
the training data is the bottle neck of its
effectiveness. Here, a new method based
on using a statistical machine translation
system has been introduced to mitigate the
effects of data sparsity for training classi-
fiers. Also, the effects of the background
model which is necessary to compensate
the above problem, is investigated. Exper-
imental evaluation in the context of cross-
lingual doctor-patient interaction applica-
tion show the superiority of the proposed
method.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999860636363637">
Statistical machine translation (SMT) methods
are well established in speech-to-speech transla-
tion systems as the main translation technique
(Narayanan et al., 2003; Hsiao et al., 2006). Due
to their flexibility these methods provide a good
coverage of the dialog domain. The fluency of
the translation, however, is not guaranteed. Dis-
fluencies of spoken utterances plus the speech rec-
ognizer errors degrade the translation quality even
more. All these ultimately affect the quality of the
synthesized speech output in the target language,
and the effectiveness of the concept transfer.
It is quite common, though, to use other means of
translation in parallel to the SMT methods (Gao et
al., 2006; Stallard et al., 2006). Concept classifica-
tion, as an alternative translation method, has been
successfully integrated in speech-to-speech transla-
tors (Narayanan et al., 2003; Ehsani et al., 2006).
A well defined dialog domain, e.g. doctor-patient
dialog, can be partly covered by a number of con-
cept classes. Upon a successful classification of
the input utterance, the translation task reduces to
</bodyText>
<footnote confidence="0.90285375">
© 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
</footnote>
<bodyText confidence="0.999819266666667">
synthesizing a previously created translation of the
concept, as a mere look up. Since the main goal in
such applications is an accurate exchange of con-
cepts, this method would serve the purpose as long
as the input utterance falls within the coverage of
the classifier. This process can be viewed as a quan-
tization of a continuous “semantic” sub-space. The
classifier is adequate when the quantization error is
small (i.e. the derived concept and input utterance
are good matches), and when the utterance falls in
the same sub-space (domain) as the quantizer at-
tempts to cover. Since it is not feasible to accu-
rately cover the whole dialog domain (since a large
number of quantization levels needed) the classi-
fier should be accompanied by a translation system
with a much wider range such as an SMT engine.
A rejection mechanism can help identify the cases
that the input utterance falls outside the classifier
coverage (Ettelaie et al., 2006).
In spite of this short coming, the classifier-
based translator is an attractive option for speech-
to-speech applications because of its tolerance to
“noisy” input and the fluency of its output, when it
operates close to its design parameters. In practice
this is attainable for structured dialog interactions
with high levels of predictability. In addition, it can
provide the users with both an accurate feedback
and different translation options to choose from.
The latter feature, specially, is useful for applica-
tions like doctor-patient dialog.
Building a concept classifier starts with identify-
ing the desired concepts and representing them with
canonical utterances that express these concepts. A
good set of concepts should consist of the ones that
are more frequent in a typical interaction in the do-
main. For instance in a doctor-patient dialog, the
utterance “Where does it hurt?” is quite common
and therefore its concept is a good choice. Phrase
books, websites, and experts’ judgment are some of
the resources that can be used for concept selection.
Other frequently used concepts include those that
correspond to basic communicative and social as-
pects of the interaction such as greeting, acknowl-
edgment and confirmation.
After forming the concept space, for each class,
</bodyText>
<page confidence="0.801317">
1
</page>
<note confidence="0.569482">
Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications, pages 1–4
</note>
<bodyText confidence="0.974617763157895">
Manchester, August 2008
utterances that convey its concept must be gath-
ered. Hence, this training corpus would consist of
a group of paraphrases for each class. This form of
data are often very difficult to collect as the number
of classes grow. Therefore, the available training
data are usually sparse and cannot produce a classi-
fication accuracy to the degree possible. Since the
classifier range is limited, high accuracy within that
range is quite crucial for its effectiveness. One of
the main issues is dealing with data sparsity. Other
techniques have also been proposed to improve the
classification rates. For example in (Ettelaie et al.,
2006) the accuracy has been improved by introduc-
ing a dialog model. Also, a background model has
been used to improve the discrimination ability of a
given concept class model.
In this work a novel method for handling the
sparsity is introduced. This method utilizes an SMT
engine to map a single utterance to a group of them.
Furthermore, the effect of the background model on
classification accuracy is investigated.
Section 2 reviews the concept classification pro-
cess and the background model. In Section 3 the
sparsity handling method using an SMT is intro-
duced. Data and experiments are described in Sec-
tion 4. The results are discussed in Section 5.
2 Concept classifier and background
model
The concept classifier based on the maximum like-
lihood criterion can be implemented as a language
model (LM) scoring process. For each class a lan-
guage model is built using data expressing the class
concept. The classifier scores the input utterance
using the class LM’s and selects the class with high-
est score. In another word if C is the set of concept
classes and e is the input utterance, the classifica-
tion process is,
</bodyText>
<equation confidence="0.9855895">
cˆ = arg max JPc (e  |c)} (1)
c∈C
</equation>
<bodyText confidence="0.991059849056604">
where Pc(e  |c) is the score of e from the LM of
class c. The translation job is concluded by playing
out a previously constructed prompt that expresses
the concept cˆ in the target language.
It is clear that a class with limited training data
items will have an undertrained associated LM with
poor coverage. In practice such a model fails to pro-
duce a usable LM score and leads to a poor classifi-
cation accuracy. Interpolating the LM with a back-
ground language model results in a smoother model
(Stolcke, 2002) and increases the overall accuracy
of the classifier.
The background model should be built from a
larger corpus that fairly covers the domain vocab-
ulary. The interpolation level can be optimized for
the best performance based on heldout set.
3 Handling sparsity by statistical
machine translation
The goal is to employ techniques that limit the ef-
fects of data sparsity. What is proposed here is to
generate multiple utterances – possibly with lower
quality – from a single original one. One approach
is to use an SMT to generate n-best lists of trans-
lation candidates for the original utterances. Such
lists are ranked based on a combination of scores
from different models (Ney et al., 2000). The hy-
pothesis here is that for an SMT trained on a large
corpus, the quality of the candidates would not de-
grade rapidly as one moves down the n-best list.
Therefore a list with an appropriate length would
consist of translations with acceptable quality with-
out containing a lot of poor candidates. This pro-
cess would result in more data, available for train-
ing, at the cost of using noisier data.
Although the source language of the SMT must
be the same as the classifier’s, its target language
can be selected deliberately. It is clear that a lan-
guage with large available resources (in the form of
parallel corpora with the source language) must be
selected. For simplicity this language is called the
“intermediate language” here.
A classifier in the intermediate language can be
built by first generating an n-best list for every
source utterance in the classifier’s training corpus.
Then the n-best lists associated with each class are
combined to form a new training set. The class
LM’s are now built from these training sets rather
than the original sets of the source utterances.
To classify a source utterance e, first the SMT
is deployed to generate an n-best list (in the inter-
mediate language) from it. The list will consist of
candidates f1, f2,..., fn. The classification process
can be reformulated as,
</bodyText>
<equation confidence="0.996542333333334">
c = arg maCx { ˜Pc (fi  |c) } (2)
c∈
i=1
</equation>
<bodyText confidence="0.9994305">
Here, ˜Pc(fi  |c) is the score of the ith candidate fi
from the LM of class c. The scores are considered
in the probability domain.
The new class LM’s can also be smoothed by in-
terpolation with a background model in the inter-
mediate language.
</bodyText>
<sectionHeader confidence="0.988729" genericHeader="introduction">
4 Data and Experiments
</sectionHeader>
<subsectionHeader confidence="0.947743">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.9998387">
The data used in this work were originally collected
for, and used in, the Transonics project (Narayanan
et al., 2003) to develop an English/Farsi speech-to-
speech translator in the doctor-patient interaction
domain. For the doctor side, 1,269 concept classes
were carefully chosen using experts’ judgment and
medical phrase books. Then, for each concept, En-
glish data were collected from a website, a web-
based game, and multiple paraphrasing sessions at
the Information Sciences Institute of the University
</bodyText>
<page confidence="0.989751">
2
</page>
<table confidence="0.9998535">
Conventional n-best length
(baseline)
100 500 1,000 2,000
Accuracy [%] 74.9 77.4 77.5 76.8 76.4
Relative error 0.0 10.0 10.4 7.6 6.0
reduction [%]
Accuracy in 88.6 90.7 91.0 91.3 90.5
4-best [%]
Relative error 0.0 18.4 21.1 23.7 16.7
reduction [%]
</table>
<tableCaption confidence="0.994088">
Table 1: Classification accuracy for the conventional method
and the proposed method with different lengths of n-best list
</tableCaption>
<bodyText confidence="0.998174470588235">
of Southern California. The total size of the data
set consists of 9,893 English phrases.
As the test corpus for this work, 1,000 phrases
were randomly drawn from the above set and the
rest were used for training. To make sure that the
training set covered every class, one phrase per
class was excluded from the test set selection pro-
cess.
To generate the n-best lists, a phrase based SMT
(Koehn et al., 2003) was used. The intermedi-
ate language was Farsi and the SMT was trained
on a parallel English/Farsi corpus with 148K lines
(1.2M words) on the English side. This corpus
was also used to build the classification background
models in both languages. The SMT was opti-
mized using a parallel development set with 915
lines (7.3K words) on the English side.
</bodyText>
<sectionHeader confidence="0.802249" genericHeader="method">
Accuh
</sectionHeader>
<subsectionHeader confidence="0.999621">
4.2 Classification Accuracy Measures
</subsectionHeader>
<bodyText confidence="0.999973416666667">
Classifier accuracy is often used as the the qual-
ity indicator of the classification task. However, it
is common in the speech-to-speech translation sys-
tems to provide the user with a short list of potential
translations to choose from. For example the user
of system in (Narayanan et al., 2003) is provided
with the top four classifier outputs. In such cases, it
is practically useful to measure the accuracy of the
classifier within its n-best outputs (e.g., n = 4 for
the above system). In this work the classification
accuracy was measured on both the single output
and the 4-best outputs.
</bodyText>
<subsectionHeader confidence="0.989136">
4.3 Experiments
</subsectionHeader>
<bodyText confidence="0.999772823529412">
To compare the proposed method with the con-
ventional classification, a classifier based on each
method was put to test. In the proposed method,
it is expected that the accuracy is affected by the
length of the n-best lists. To observe that, n-best
lists of lengths 100, 500, 1000, and 2000 were used
in the experiments. The results are shown in Table
1. In all of the above experiments the background
interpolation factor was set to 0.9 which is close
to the optimum value obtained in (Ettelaie et al.,
2006).
To examine the effect of the background model,
the conventional and proposed methods were tried
with different values of the interpolation factor A
(the background model is weighted by 1 − A). For
the conventional method the length of the n-best
list was set to 500. Figure 1 shows the accuracy
</bodyText>
<figure confidence="0.98162775">
5%
0%
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
Background Interpolation Factor (λ)
</figure>
<figureCaption confidence="0.9790905">
Figure 1: The effect of background model on classification
accuracy
</figureCaption>
<bodyText confidence="0.882031">
changes with respect to the interpolation factor for
these two methods.
</bodyText>
<sectionHeader confidence="0.999334" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999824525">
Table 1 shows the advantage of the proposed
method over the conventional classification with a
relative error rate reduction up to 10.4% (achieved
when the length of the SMT n-best list was 500).
However, as expected, this number decreases with
longer SMT n-best lists due to the increased noise
present in lower ranked outputs of the SMT.
Table 1 also shows the accuracy within 4-best
classifier outputs for each method. In that case
the proposed method showed an error rate which
was relatively 23.7% lower than the error rate of
the conventional method. That was achieved at the
peak of the accuracy within 4-best, when the length
of the SMT n-best list was 1,000. In this case too,
further increase in the length of the n-best list led
to an accuracy degradation as the classifier models
became noisier.
The effect of the background model on classifier
accuracy is shown in Figure 1. The figure shows
the one-best accuracy and the accuracy within 4-
best outputs, versus the background interpolation
factor (A) for both conventional and proposed meth-
ods. As the curves indicate, with A equal to zero the
classifier has no discriminating feature since all the
class scores are driven solely from the background
model. However, a slight increase in A, leads to
a large jump in the accuracy. The reason is that
the background model was built from a large gen-
eral domain corpus and hence, had no bias toward
any of the classes. With a small A, the score from
the background model dominates the overall class
scores. In spite of that, the score differences caused
by the class LM’s are notable in improving the clas-
sifier performance.
As A increases the role of the class LM’s be-
comes more prominent. This makes the classifier
models more discriminative and increases its accu-
racy as shown in Figure 1. When the factor is in
the close vicinity of one, the smoothing effect of
the background model diminishes and leaves the
</bodyText>
<figure confidence="0.984634277777778">
Conv
. 4-best
Conv
New
.
4-best
New
Accuracy 95%
90%
85%
80%
75%
70%
65%
60%
55%
50%
45%
</figure>
<page confidence="0.991659">
3
</page>
<bodyText confidence="0.999141869565218">
classes with spiky models with very low vocabu-
lary coverage (lots of zeros). This leads to a rapid
drop in accuracy as A reaches one.
Both the conventional and proposed methods
follow the above trend as Figure 1 shows, al-
though, the proposed method maintains its supe-
riority throughout the range of A that was exam-
ined. The maximum measured accuracies for con-
ventional and proposed methods were 75.2% and
78.7% respectively and was measured at A = 0.999
for both methods. Therefore, the error rate of the
proposed method was relatively 14.1% lower than
its counterpart from the conventional method.
Figure 1 also indicates that when the accuracy is
measured within the 4-best outputs, again the pro-
posed method outperforms the conventional one.
The maximum 4-best accuracy for the conventional
method was measured at the sample point A = 0.9
and was equal to 88.6%. For the proposed method,
that number was measured as 91.5% achieved at the
sample point A = 0.999. In another words, consid-
ering the 4-best classifier outputs, the error rate of
the proposed method was relatively 25.4% lower.
</bodyText>
<sectionHeader confidence="0.999561" genericHeader="evaluation">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999988">
The proposed language model based method can be
used to improve the accuracy of the concept classi-
fiers specially in the case of sparse training data.
It outperformed the conventional classifier, trained
on the original source language paraphrases, in the
experiments. With this method, when the input ut-
terance is within the classification domain, the clas-
sifier can be viewed as a filter that produces fluent
translations (removes the “noise”) from the SMT
output.
The experiments also emphasized the impor-
tance of the background model, although indicated
that the classification accuracy was not very sen-
sitive to the value of the background interpolation
factor. This relieves the developers from the fine
tuning of that factor and eliminates the need for a
development data set when a suboptimal solution is
acceptable.
We believe that significant improvements to the
technique can be made through the use of weighted
n-best lists based on the SMT scores. In addition
we believe that using a much richer SMT engine
could provide significant gains through increased
diversity in the output vocabulary. We intend to ex-
tend on this work through the use of enriched, mul-
tilingual SMT engines, and the creation of multiple
classifiers (in several intermediate languages).
</bodyText>
<sectionHeader confidence="0.997939" genericHeader="conclusions">
7 Acknowledgment
</sectionHeader>
<bodyText confidence="0.9924455">
This work was supported in part by funds from
DARPA.
</bodyText>
<sectionHeader confidence="0.998352" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999894803278689">
Ehsani, F., J. Kinzey, D. Master, K. Sudre, D. Domingo,
and H. Park. 2006. S-MINDS 2-way speech-to-
speech translation system. In Proc. of the Medi-
cal Speech Translation Workshop, Conference of the
North American Chapter of the Association for Com-
putational Linguistics on Human Language Technol-
ogy (NAACL-HLT), pages 44–45, New York, NY,
USA, June.
Ettelaie, E., P. G. Georgiou, and S. Narayanan. 2006.
Cross-lingual dialog model for speech to speech
translation. In Proc. of the Ninth International Con-
ference on Spoken Language Processing (ICLSP),
pages 1173–1176, Pittsburgh, PA, USA, September.
Gao, Y., L. Gu, B. Zhou, R. Sarikaya, M. Afify, H. Kuo,
W. Zhu, Y. Deng, C. Prosser, W. Zhang, and L. Be-
sacier. 2006. IBM MASTOR SYSTEM: Multilin-
gual automatic speech-to-speech translator. In Proc.
of the Medical Speech Translation Workshop, Con-
ference of the North American Chapter of the As-
sociation for Computational Linguistics on Human
Language Technology (NAACL-HLT), pages 53–56,
New York, NY, USA, June.
Hsiao, R., A. Venugopal, T. Kohler, Y. Zhang,
P. Charoenpornsawat, A. Zollmann, S. Vogel, A. W.
Black, T. Schultz, and A. Waibel. 2006. Optimiz-
ing components for handheld two-way speech trans-
lation for an English-Iraqi Arabic system. In Proc. of
the Ninth International Conference on Spoken Lan-
guage Processing (ICLSP), pages 765–768, Pitts-
burgh, PA, USA, September.
Koehn, P., F. Och, and D. Marcu. 2003. Statistical
phrase-based translation. In Proc. of the Conference
of the North American Chapter of the Association
for Computational Linguistics on Human Language
Technology (NAACL-HLT), volume 1, pages 48–54,
Edmonton, AB, Canada, May-June.
Narayanan, S., S. Ananthakrishnan, R. Belvin, E. Ette-
laie, S. Ganjavi, P. Georgiou, C. Hein, S. Kadambe,
K. Knight, D. Marcu, H. Neely, N. Srinivasamurthy,
D. Traum, and D. Wang. 2003. Transonics: A
speech to speech system for English-Persian inter-
actions. In Proc. of IEEE Workshop on Automatic
Speech Recognition and Understanding (ASRU),
pages 670–675, St.Thomas, U.S. Virgin Islands,
November-Decmeber.
Ney, H., S. Nießen, F. J. Och, C. Tillmann, H. Sawaf,
and S. Vogel. 2000. Algorithms for statistical trans-
lation of spoken language. IEEE Trans. on Speech
and Audio Processing, Special Issue on Language
Modeling and Dialogue Systems, 8(1):24–36, Jan-
uary.
Stallard, D., F. Choi, K. Krstovski, P. Natarajan,
R. Prasad, and S. Saleem. 2006. A hybrid
phrase-based/statistical speech translation system.
In Proc. of the Ninth International Conference on
Spoken Language Processing (ICLSP), pages 757–
760, Pittsburgh, PA, USA, September.
Stolcke, A. 2002. SRILM - an extensible language
modeling toolkit. In Proc. of the International Con-
ference on Spoken Language Processing (ICSLP),
pages 901–904, Denver, CO, USA, September.
</reference>
<page confidence="0.996667">
4
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.688487">
<title confidence="0.93116875">Mitigation of data sparsity in classifier-based translation Emil Ettelaie, Panayiotis G. Georgiou, Shrikanth S. Signal Analysis and Interpretation Ming Hsieh Department of Electrical</title>
<author confidence="0.861026">Viterbi School of</author>
<affiliation confidence="0.99969">University of Southern</affiliation>
<email confidence="0.999854">ettelaie@usc.edu</email>
<abstract confidence="0.9965859375">The concept classifier has been used as a translation unit in speech-to-speech translation systems. However, the sparsity of the training data is the bottle neck of its effectiveness. Here, a new method based on using a statistical machine translation system has been introduced to mitigate the effects of data sparsity for training classifiers. Also, the effects of the background model which is necessary to compensate the above problem, is investigated. Experimental evaluation in the context of crosslingual doctor-patient interaction application show the superiority of the proposed method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>F Ehsani</author>
<author>J Kinzey</author>
<author>D Master</author>
<author>K Sudre</author>
<author>D Domingo</author>
<author>H Park</author>
</authors>
<title>S-MINDS 2-way speech-tospeech translation system.</title>
<date>2006</date>
<booktitle>In Proc. of the Medical Speech Translation Workshop, Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (NAACL-HLT),</booktitle>
<pages>44--45</pages>
<location>New York, NY, USA,</location>
<contexts>
<context position="1812" citStr="Ehsani et al., 2006" startWordPosition="263" endWordPosition="266"> fluency of the translation, however, is not guaranteed. Disfluencies of spoken utterances plus the speech recognizer errors degrade the translation quality even more. All these ultimately affect the quality of the synthesized speech output in the target language, and the effectiveness of the concept transfer. It is quite common, though, to use other means of translation in parallel to the SMT methods (Gao et al., 2006; Stallard et al., 2006). Concept classification, as an alternative translation method, has been successfully integrated in speech-to-speech translators (Narayanan et al., 2003; Ehsani et al., 2006). A well defined dialog domain, e.g. doctor-patient dialog, can be partly covered by a number of concept classes. Upon a successful classification of the input utterance, the translation task reduces to © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. synthesizing a previously created translation of the concept, as a mere look up. Since the main goal in such applications is an accurate exchange of concepts, this method would serve the purpose as long as the input utt</context>
</contexts>
<marker>Ehsani, Kinzey, Master, Sudre, Domingo, Park, 2006</marker>
<rawString>Ehsani, F., J. Kinzey, D. Master, K. Sudre, D. Domingo, and H. Park. 2006. S-MINDS 2-way speech-tospeech translation system. In Proc. of the Medical Speech Translation Workshop, Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (NAACL-HLT), pages 44–45, New York, NY, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Ettelaie</author>
<author>P G Georgiou</author>
<author>S Narayanan</author>
</authors>
<title>Cross-lingual dialog model for speech to speech translation.</title>
<date>2006</date>
<booktitle>In Proc. of the Ninth International Conference on Spoken Language Processing (ICLSP),</booktitle>
<pages>1173--1176</pages>
<location>Pittsburgh, PA, USA,</location>
<contexts>
<context position="3138" citStr="Ettelaie et al., 2006" startWordPosition="471" endWordPosition="474">ntinuous “semantic” sub-space. The classifier is adequate when the quantization error is small (i.e. the derived concept and input utterance are good matches), and when the utterance falls in the same sub-space (domain) as the quantizer attempts to cover. Since it is not feasible to accurately cover the whole dialog domain (since a large number of quantization levels needed) the classifier should be accompanied by a translation system with a much wider range such as an SMT engine. A rejection mechanism can help identify the cases that the input utterance falls outside the classifier coverage (Ettelaie et al., 2006). In spite of this short coming, the classifierbased translator is an attractive option for speechto-speech applications because of its tolerance to “noisy” input and the fluency of its output, when it operates close to its design parameters. In practice this is attainable for structured dialog interactions with high levels of predictability. In addition, it can provide the users with both an accurate feedback and different translation options to choose from. The latter feature, specially, is useful for applications like doctor-patient dialog. Building a concept classifier starts with identify</context>
<context position="5212" citStr="Ettelaie et al., 2006" startWordPosition="797" endWordPosition="800">es that convey its concept must be gathered. Hence, this training corpus would consist of a group of paraphrases for each class. This form of data are often very difficult to collect as the number of classes grow. Therefore, the available training data are usually sparse and cannot produce a classification accuracy to the degree possible. Since the classifier range is limited, high accuracy within that range is quite crucial for its effectiveness. One of the main issues is dealing with data sparsity. Other techniques have also been proposed to improve the classification rates. For example in (Ettelaie et al., 2006) the accuracy has been improved by introducing a dialog model. Also, a background model has been used to improve the discrimination ability of a given concept class model. In this work a novel method for handling the sparsity is introduced. This method utilizes an SMT engine to map a single utterance to a group of them. Furthermore, the effect of the background model on classification accuracy is investigated. Section 2 reviews the concept classification process and the background model. In Section 3 the sparsity handling method using an SMT is introduced. Data and experiments are described in</context>
<context position="12007" citStr="Ettelaie et al., 2006" startWordPosition="1963" endWordPosition="1966">s work the classification accuracy was measured on both the single output and the 4-best outputs. 4.3 Experiments To compare the proposed method with the conventional classification, a classifier based on each method was put to test. In the proposed method, it is expected that the accuracy is affected by the length of the n-best lists. To observe that, n-best lists of lengths 100, 500, 1000, and 2000 were used in the experiments. The results are shown in Table 1. In all of the above experiments the background interpolation factor was set to 0.9 which is close to the optimum value obtained in (Ettelaie et al., 2006). To examine the effect of the background model, the conventional and proposed methods were tried with different values of the interpolation factor A (the background model is weighted by 1 − A). For the conventional method the length of the n-best list was set to 500. Figure 1 shows the accuracy 5% 0% 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Background Interpolation Factor (λ) Figure 1: The effect of background model on classification accuracy changes with respect to the interpolation factor for these two methods. 5 Discussion Table 1 shows the advantage of the proposed method over the conv</context>
</contexts>
<marker>Ettelaie, Georgiou, Narayanan, 2006</marker>
<rawString>Ettelaie, E., P. G. Georgiou, and S. Narayanan. 2006. Cross-lingual dialog model for speech to speech translation. In Proc. of the Ninth International Conference on Spoken Language Processing (ICLSP), pages 1173–1176, Pittsburgh, PA, USA, September.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Y Gao</author>
<author>L Gu</author>
<author>B Zhou</author>
<author>R Sarikaya</author>
<author>M Afify</author>
<author>H Kuo</author>
<author>W Zhu</author>
<author>Y Deng</author>
<author>C Prosser</author>
<author>W Zhang</author>
<author>L Besacier</author>
</authors>
<title>IBM MASTOR SYSTEM: Multilingual automatic speech-to-speech translator.</title>
<date>2006</date>
<booktitle>In Proc. of the Medical Speech Translation Workshop, Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (NAACL-HLT),</booktitle>
<pages>53--56</pages>
<location>New York, NY, USA,</location>
<contexts>
<context position="1614" citStr="Gao et al., 2006" startWordPosition="235" endWordPosition="238">peech translation systems as the main translation technique (Narayanan et al., 2003; Hsiao et al., 2006). Due to their flexibility these methods provide a good coverage of the dialog domain. The fluency of the translation, however, is not guaranteed. Disfluencies of spoken utterances plus the speech recognizer errors degrade the translation quality even more. All these ultimately affect the quality of the synthesized speech output in the target language, and the effectiveness of the concept transfer. It is quite common, though, to use other means of translation in parallel to the SMT methods (Gao et al., 2006; Stallard et al., 2006). Concept classification, as an alternative translation method, has been successfully integrated in speech-to-speech translators (Narayanan et al., 2003; Ehsani et al., 2006). A well defined dialog domain, e.g. doctor-patient dialog, can be partly covered by a number of concept classes. Upon a successful classification of the input utterance, the translation task reduces to © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. synthesizing a previo</context>
</contexts>
<marker>Gao, Gu, Zhou, Sarikaya, Afify, Kuo, Zhu, Deng, Prosser, Zhang, Besacier, 2006</marker>
<rawString>Gao, Y., L. Gu, B. Zhou, R. Sarikaya, M. Afify, H. Kuo, W. Zhu, Y. Deng, C. Prosser, W. Zhang, and L. Besacier. 2006. IBM MASTOR SYSTEM: Multilingual automatic speech-to-speech translator. In Proc. of the Medical Speech Translation Workshop, Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (NAACL-HLT), pages 53–56, New York, NY, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hsiao</author>
<author>A Venugopal</author>
<author>T Kohler</author>
<author>Y Zhang</author>
<author>P Charoenpornsawat</author>
<author>A Zollmann</author>
<author>S Vogel</author>
<author>A W Black</author>
<author>T Schultz</author>
<author>A Waibel</author>
</authors>
<title>Optimizing components for handheld two-way speech translation for an English-Iraqi Arabic system.</title>
<date>2006</date>
<booktitle>In Proc. of the Ninth International Conference on Spoken Language Processing (ICLSP),</booktitle>
<pages>765--768</pages>
<location>Pittsburgh, PA, USA,</location>
<contexts>
<context position="1102" citStr="Hsiao et al., 2006" startWordPosition="152" endWordPosition="155">eness. Here, a new method based on using a statistical machine translation system has been introduced to mitigate the effects of data sparsity for training classifiers. Also, the effects of the background model which is necessary to compensate the above problem, is investigated. Experimental evaluation in the context of crosslingual doctor-patient interaction application show the superiority of the proposed method. 1 Introduction Statistical machine translation (SMT) methods are well established in speech-to-speech translation systems as the main translation technique (Narayanan et al., 2003; Hsiao et al., 2006). Due to their flexibility these methods provide a good coverage of the dialog domain. The fluency of the translation, however, is not guaranteed. Disfluencies of spoken utterances plus the speech recognizer errors degrade the translation quality even more. All these ultimately affect the quality of the synthesized speech output in the target language, and the effectiveness of the concept transfer. It is quite common, though, to use other means of translation in parallel to the SMT methods (Gao et al., 2006; Stallard et al., 2006). Concept classification, as an alternative translation method, </context>
</contexts>
<marker>Hsiao, Venugopal, Kohler, Zhang, Charoenpornsawat, Zollmann, Vogel, Black, Schultz, Waibel, 2006</marker>
<rawString>Hsiao, R., A. Venugopal, T. Kohler, Y. Zhang, P. Charoenpornsawat, A. Zollmann, S. Vogel, A. W. Black, T. Schultz, and A. Waibel. 2006. Optimizing components for handheld two-way speech translation for an English-Iraqi Arabic system. In Proc. of the Ninth International Conference on Spoken Language Processing (ICLSP), pages 765–768, Pittsburgh, PA, USA, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (NAACL-HLT),</booktitle>
<volume>1</volume>
<pages>48--54</pages>
<location>Edmonton, AB, Canada, May-June.</location>
<contexts>
<context position="10495" citStr="Koehn et al., 2003" startWordPosition="1705" endWordPosition="1708">6 90.7 91.0 91.3 90.5 4-best [%] Relative error 0.0 18.4 21.1 23.7 16.7 reduction [%] Table 1: Classification accuracy for the conventional method and the proposed method with different lengths of n-best list of Southern California. The total size of the data set consists of 9,893 English phrases. As the test corpus for this work, 1,000 phrases were randomly drawn from the above set and the rest were used for training. To make sure that the training set covered every class, one phrase per class was excluded from the test set selection process. To generate the n-best lists, a phrase based SMT (Koehn et al., 2003) was used. The intermediate language was Farsi and the SMT was trained on a parallel English/Farsi corpus with 148K lines (1.2M words) on the English side. This corpus was also used to build the classification background models in both languages. The SMT was optimized using a parallel development set with 915 lines (7.3K words) on the English side. Accuh 4.2 Classification Accuracy Measures Classifier accuracy is often used as the the quality indicator of the classification task. However, it is common in the speech-to-speech translation systems to provide the user with a short list of potentia</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Koehn, P., F. Och, and D. Marcu. 2003. Statistical phrase-based translation. In Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology (NAACL-HLT), volume 1, pages 48–54, Edmonton, AB, Canada, May-June.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Narayanan</author>
<author>S Ananthakrishnan</author>
<author>R Belvin</author>
<author>E Ettelaie</author>
<author>S Ganjavi</author>
<author>P Georgiou</author>
<author>C Hein</author>
<author>S Kadambe</author>
<author>K Knight</author>
<author>D Marcu</author>
<author>H Neely</author>
<author>N Srinivasamurthy</author>
<author>D Traum</author>
<author>D Wang</author>
</authors>
<title>Transonics: A speech to speech system for English-Persian interactions.</title>
<date>2003</date>
<booktitle>In Proc. of IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU),</booktitle>
<pages>670--675</pages>
<location>St.Thomas, U.S. Virgin Islands, November-Decmeber.</location>
<contexts>
<context position="1081" citStr="Narayanan et al., 2003" startWordPosition="148" endWordPosition="151">tle neck of its effectiveness. Here, a new method based on using a statistical machine translation system has been introduced to mitigate the effects of data sparsity for training classifiers. Also, the effects of the background model which is necessary to compensate the above problem, is investigated. Experimental evaluation in the context of crosslingual doctor-patient interaction application show the superiority of the proposed method. 1 Introduction Statistical machine translation (SMT) methods are well established in speech-to-speech translation systems as the main translation technique (Narayanan et al., 2003; Hsiao et al., 2006). Due to their flexibility these methods provide a good coverage of the dialog domain. The fluency of the translation, however, is not guaranteed. Disfluencies of spoken utterances plus the speech recognizer errors degrade the translation quality even more. All these ultimately affect the quality of the synthesized speech output in the target language, and the effectiveness of the concept transfer. It is quite common, though, to use other means of translation in parallel to the SMT methods (Gao et al., 2006; Stallard et al., 2006). Concept classification, as an alternative</context>
<context position="9323" citStr="Narayanan et al., 2003" startWordPosition="1513" endWordPosition="1516"> the SMT is deployed to generate an n-best list (in the intermediate language) from it. The list will consist of candidates f1, f2,..., fn. The classification process can be reformulated as, c = arg maCx { ˜Pc (fi |c) } (2) c∈ i=1 Here, ˜Pc(fi |c) is the score of the ith candidate fi from the LM of class c. The scores are considered in the probability domain. The new class LM’s can also be smoothed by interpolation with a background model in the intermediate language. 4 Data and Experiments 4.1 Data The data used in this work were originally collected for, and used in, the Transonics project (Narayanan et al., 2003) to develop an English/Farsi speech-tospeech translator in the doctor-patient interaction domain. For the doctor side, 1,269 concept classes were carefully chosen using experts’ judgment and medical phrase books. Then, for each concept, English data were collected from a website, a webbased game, and multiple paraphrasing sessions at the Information Sciences Institute of the University 2 Conventional n-best length (baseline) 100 500 1,000 2,000 Accuracy [%] 74.9 77.4 77.5 76.8 76.4 Relative error 0.0 10.0 10.4 7.6 6.0 reduction [%] Accuracy in 88.6 90.7 91.0 91.3 90.5 4-best [%] Relative error</context>
<context position="11184" citStr="Narayanan et al., 2003" startWordPosition="1820" endWordPosition="1823">ined on a parallel English/Farsi corpus with 148K lines (1.2M words) on the English side. This corpus was also used to build the classification background models in both languages. The SMT was optimized using a parallel development set with 915 lines (7.3K words) on the English side. Accuh 4.2 Classification Accuracy Measures Classifier accuracy is often used as the the quality indicator of the classification task. However, it is common in the speech-to-speech translation systems to provide the user with a short list of potential translations to choose from. For example the user of system in (Narayanan et al., 2003) is provided with the top four classifier outputs. In such cases, it is practically useful to measure the accuracy of the classifier within its n-best outputs (e.g., n = 4 for the above system). In this work the classification accuracy was measured on both the single output and the 4-best outputs. 4.3 Experiments To compare the proposed method with the conventional classification, a classifier based on each method was put to test. In the proposed method, it is expected that the accuracy is affected by the length of the n-best lists. To observe that, n-best lists of lengths 100, 500, 1000, and </context>
</contexts>
<marker>Narayanan, Ananthakrishnan, Belvin, Ettelaie, Ganjavi, Georgiou, Hein, Kadambe, Knight, Marcu, Neely, Srinivasamurthy, Traum, Wang, 2003</marker>
<rawString>Narayanan, S., S. Ananthakrishnan, R. Belvin, E. Ettelaie, S. Ganjavi, P. Georgiou, C. Hein, S. Kadambe, K. Knight, D. Marcu, H. Neely, N. Srinivasamurthy, D. Traum, and D. Wang. 2003. Transonics: A speech to speech system for English-Persian interactions. In Proc. of IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), pages 670–675, St.Thomas, U.S. Virgin Islands, November-Decmeber.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ney</author>
<author>S Nießen</author>
<author>F J Och</author>
<author>C Tillmann</author>
<author>H Sawaf</author>
<author>S Vogel</author>
</authors>
<title>Algorithms for statistical translation of spoken language.</title>
<date>2000</date>
<journal>IEEE Trans. on Speech and Audio Processing, Special Issue on Language Modeling and Dialogue Systems,</journal>
<volume>8</volume>
<issue>1</issue>
<contexts>
<context position="7569" citStr="Ney et al., 2000" startWordPosition="1205" endWordPosition="1208">hould be built from a larger corpus that fairly covers the domain vocabulary. The interpolation level can be optimized for the best performance based on heldout set. 3 Handling sparsity by statistical machine translation The goal is to employ techniques that limit the effects of data sparsity. What is proposed here is to generate multiple utterances – possibly with lower quality – from a single original one. One approach is to use an SMT to generate n-best lists of translation candidates for the original utterances. Such lists are ranked based on a combination of scores from different models (Ney et al., 2000). The hypothesis here is that for an SMT trained on a large corpus, the quality of the candidates would not degrade rapidly as one moves down the n-best list. Therefore a list with an appropriate length would consist of translations with acceptable quality without containing a lot of poor candidates. This process would result in more data, available for training, at the cost of using noisier data. Although the source language of the SMT must be the same as the classifier’s, its target language can be selected deliberately. It is clear that a language with large available resources (in the form</context>
</contexts>
<marker>Ney, Nießen, Och, Tillmann, Sawaf, Vogel, 2000</marker>
<rawString>Ney, H., S. Nießen, F. J. Och, C. Tillmann, H. Sawaf, and S. Vogel. 2000. Algorithms for statistical translation of spoken language. IEEE Trans. on Speech and Audio Processing, Special Issue on Language Modeling and Dialogue Systems, 8(1):24–36, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Stallard</author>
<author>F Choi</author>
<author>K Krstovski</author>
<author>P Natarajan</author>
<author>R Prasad</author>
<author>S Saleem</author>
</authors>
<title>A hybrid phrase-based/statistical speech translation system.</title>
<date>2006</date>
<booktitle>In Proc. of the Ninth International Conference on Spoken Language Processing (ICLSP),</booktitle>
<pages>757--760</pages>
<location>Pittsburgh, PA, USA,</location>
<contexts>
<context position="1638" citStr="Stallard et al., 2006" startWordPosition="239" endWordPosition="242">systems as the main translation technique (Narayanan et al., 2003; Hsiao et al., 2006). Due to their flexibility these methods provide a good coverage of the dialog domain. The fluency of the translation, however, is not guaranteed. Disfluencies of spoken utterances plus the speech recognizer errors degrade the translation quality even more. All these ultimately affect the quality of the synthesized speech output in the target language, and the effectiveness of the concept transfer. It is quite common, though, to use other means of translation in parallel to the SMT methods (Gao et al., 2006; Stallard et al., 2006). Concept classification, as an alternative translation method, has been successfully integrated in speech-to-speech translators (Narayanan et al., 2003; Ehsani et al., 2006). A well defined dialog domain, e.g. doctor-patient dialog, can be partly covered by a number of concept classes. Upon a successful classification of the input utterance, the translation task reduces to © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. synthesizing a previously created translation</context>
</contexts>
<marker>Stallard, Choi, Krstovski, Natarajan, Prasad, Saleem, 2006</marker>
<rawString>Stallard, D., F. Choi, K. Krstovski, P. Natarajan, R. Prasad, and S. Saleem. 2006. A hybrid phrase-based/statistical speech translation system. In Proc. of the Ninth International Conference on Spoken Language Processing (ICLSP), pages 757– 760, Pittsburgh, PA, USA, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>SRILM - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proc. of the International Conference on Spoken Language Processing (ICSLP),</booktitle>
<pages>901--904</pages>
<location>Denver, CO, USA,</location>
<contexts>
<context position="6875" citStr="Stolcke, 2002" startWordPosition="1091" endWordPosition="1092"> classes and e is the input utterance, the classification process is, cˆ = arg max JPc (e |c)} (1) c∈C where Pc(e |c) is the score of e from the LM of class c. The translation job is concluded by playing out a previously constructed prompt that expresses the concept cˆ in the target language. It is clear that a class with limited training data items will have an undertrained associated LM with poor coverage. In practice such a model fails to produce a usable LM score and leads to a poor classification accuracy. Interpolating the LM with a background language model results in a smoother model (Stolcke, 2002) and increases the overall accuracy of the classifier. The background model should be built from a larger corpus that fairly covers the domain vocabulary. The interpolation level can be optimized for the best performance based on heldout set. 3 Handling sparsity by statistical machine translation The goal is to employ techniques that limit the effects of data sparsity. What is proposed here is to generate multiple utterances – possibly with lower quality – from a single original one. One approach is to use an SMT to generate n-best lists of translation candidates for the original utterances. S</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Stolcke, A. 2002. SRILM - an extensible language modeling toolkit. In Proc. of the International Conference on Spoken Language Processing (ICSLP), pages 901–904, Denver, CO, USA, September.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>