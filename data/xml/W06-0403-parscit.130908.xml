<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.998515">
Numbat: Abolishing Privileges when Licensing New Constituents in
Constraint-oriented Parsing
</title>
<author confidence="0.988655">
Jean-Philippe Prost
</author>
<affiliation confidence="0.972661">
Centre for Language Technology
</affiliation>
<note confidence="0.8172755">
Macquarie University, Sydney, Australia
and Laboratoire Parole et Langage
</note>
<address confidence="0.566721">
Universit´e de Provence, Aix-en-Provence, France
</address>
<email confidence="0.992285">
jpprost@ics.mq.edu.au
</email>
<sectionHeader confidence="0.993644" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999912647058823">
The constraint-oriented approaches to lan-
guage processing step back from the gen-
erative theory and make it possible, in the-
ory, to deal with all types of linguistic re-
lationships (e.g. dependency, linear prece-
dence or immediate dominance) with the
same importance when parsing an input
utterance. Yet in practice, all implemented
constraint-oriented parsing strategies still
need to discriminate between “important”
and “not-so-important” types of relations
during the parsing process.
In this paper we introduce a new
constraint-oriented parsing strategy based
on Property Grammars, which overcomes
this drawback and grants the same impor-
tance to all types of relations.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99974745945946">
In linguistics, the term gradience is often used to
refer to the notion of acceptability as a gradient,
as opposed to a more classical all-or-none notion.
The research goal of this project is to build an ex-
perimental platform for computing gradience, i.e.
for quantifying the degree of acceptability of an
input utterance. We called this platform Numbat.
In order to be able to quantify such a gradi-
ent of acceptability with no a priori opinion on
the influence played by different types of linguis-
tic relationships, we want to adopt a framework
where no one type of (syntactic) relation (e.g. de-
pendency, immediate dominance, or linear prece-
dence) is preferred over the other ones. Although
a constraint-oriented (CO) paradigm such as Prop-
erty Grammars (Blache, 2001) theoretically does
not rely on any preferred relations, we observe that
the parsing strategies implemented so far (Moraw-
ietz and Blache, 2002; Balfourier et al., 2002;
Dahl and Blache, 2004; VanRullen, 2005) do not
account for such a feature of the formalism. The
strategy we have designed overcomes that prob-
lem and allows for constituents to be licensed by
any type of relation. Not only does our approach
maintain a close connection between implementa-
tion and underpinning theory, but it also allows for
the decisions made with respect to gradience to be
better informed. The purpose of the present pa-
per is to present this new parsing strategy, and to
emphasise how it “abolishes the privilege” usually
only granted to a subset of syntactic relationships.
Section 2 presents some background informa-
tion about the CO approaches and briefly intro-
duces the Property Grammars formalism. Section
3 exposes and discusses the parsing strategy im-
plemented in Numbat. Section 4 then draws the
conclusion.
</bodyText>
<sectionHeader confidence="0.99759" genericHeader="method">
2 Constraint-oriented Approaches
</sectionHeader>
<bodyText confidence="0.999895363636363">
The main feature common to all Constraint-
oriented approaches is that parsing is mod-
elled as a Constraint Satisfaction Problem (CSP).
Maruyama’s Constraint Dependency Grammar
(CDG) (Maruyama, 1990) is the first formalism
to introduce the parsing process as a CSP solver.
Several extensions of CDG have then been pro-
posed (Heinecke et al., 1998; Duchier, 1999; Foth
et al., 2004).
Menzel and colleagues (Heinecke et al., 1998;
Foth et al., 2004) developed a weighted (or
“graded”) version of CDG. Their parsing strate-
gies are explored in the context of robust parsing.
These strategies are based on an over-generation
of candidate solutions. In this approach the CSP is
turned into an optimisation problem, where sub-
optimal solutions are filtered out according to a
function of the weights associated to the violated
constraints, and the notion of well-formedness is
replaced by one of optimality. Indeed, the over-
generation introduces inconsistencies in the con-
straint system, which prevents the use of the con-
</bodyText>
<page confidence="0.989789">
17
</page>
<note confidence="0.587604">
Proceedings of the 3rd Workshop on Constraints and Language Processing (CSLP-06), pages 17–24,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999952318181818">
straint system as a set of well-formedness condi-
tions, since even a well-formed utterance violates
a subset of constraints. Consequently it is not pos-
sible to distinguish an optimal structure of an ill-
formed utterance from an optimal structure of a
well-formed utterance.
Duchier (1999) relies on set constraints and se-
lection constraints1 to axiomatise syntactic well-
formedness and provides a concurrent constraint
programming account of the parsing process. With
the eXtended Dependency Grammar (XDG) (De-
busmann et al., 2004) the notion of dependency
tree is further extended to “multi-dimensional” de-
pendency graph, where each dimension (e.g. Im-
mediate Dominance and Linear Precedence) is as-
sociated with its own set of well-formedness con-
ditions (called principles). Duchier (2000) sees
dependency parsing as a configuration problem,
where given a finite set of components (nodes in
a graph) and a set of constraints specifying how
these components may be connected, the task con-
sists of finding a solution tree.
It seems, to the best of our knowledge, that nei-
ther of these works around XDG attempts to ac-
count for ill-formedness.
The Property Grammars (PG), introduced by
Blache (Blache, 2001; Blache, 2005)2, step back
from Dependency Grammar. Solving the con-
straint system no longer results in a dependency
structure but in a phrase structure, whose granular-
ity may be tailored from a shallow one (i.e. a col-
lection of disconnected components) to a deep one
(i.e. a single hierarchical structure of constituents)
according to application requirements3. This fea-
ture makes the formalism well suited for account-
ing for both ill-formedness and well-formedness,
which is a key requirement for our experimental
platform.
Introducing degrees of acceptability for an ut-
terance does not mean indeed that it should be
done at the expense of well-formedness: we want
our model to account for ill-formedness and yet
to also be able to recognise and acknowledge
when an utterance is well-formed. This require-
</bodyText>
<footnote confidence="0.997441444444444">
1Although they are referred to with the same name by
their respective authors, Duchier’s notion of selection con-
straint is not to be confused with Dahl’s selection constraints
(Dahl and Blache, 2004). The two notions are significantly
different.
2The Property Grammars were defined on the basis of the
5P formalism (B`es and Blache, 1999).
3For a discussion regarding PG and parsing with variable
granularity see (VanRullen, 2005).
</footnote>
<bodyText confidence="0.999755">
ment rules out Optimality-theoretic frameworks
as well as the ones based on Maruyama’s CDG.
Note that this is not to say that the task could
not be achieved in a CDG-based framework; sim-
ply at this stage there is no work based on CDG,
which would combine both an account of well-
formedness and of optimality. A CO framework
based on PG seems therefore best-suited for our
purpose. Meanwhile, though different parsing
strategies have been proposed for PG (Moraw-
ietz and Blache, 2002; Balfourier et al., 2002;
Dahl and Blache, 2004; VanRullen, 2005), none
of these strategies implements the possibility af-
forded by the theory to rely on any type of con-
straint in order to license a (possibly ill-formed)
constituent.
We will see in this paper how the parsing strat-
egy implemented in Numbat overcomes this prob-
lem.
</bodyText>
<subsectionHeader confidence="0.810029">
2.1 The Property Grammars Formalism
2.1.1 Terminology
</subsectionHeader>
<bodyText confidence="0.972666">
Construction. In PG a construction can be a
lexical item’s Part-of-Speech, a phrase, or top-
level constructions such as, for example, the
Caused-motion or the Subject-auxiliary Inversion
constructions. The notion of construction is sim-
ilar to the one in Construction Grammar (CxG)4,
as in (Goldberg, 1995), where:
Cx is a construction iff Cx is a form-
meaning pair (Fi, Si) such that some as-
pect of Fi or some aspect of Si is not
strictly predictable from Cx’s compo-
nent parts or from other previously es-
tablished constructions.
In this paper we only focus on syntax. For us, at
the syntactic level, a construction is defined by a
form, where a form is specified as a list of proper-
ties. When building a traditional phrase structure
(i.e. a hierarchical structure of constituents) a con-
struction can be simply seen as a non-terminal.
Property. A property is a constraint, which
models a relationship among constructions. PG
pre-defines several types of properties, which are
specified according to their semantics. Moreover,
the framework allows for new types to be defined.
</bodyText>
<footnote confidence="0.870687">
4Blache (2004) discussed how PG can be used as a formal
framework for CxG.
</footnote>
<page confidence="0.998662">
18
</page>
<bodyText confidence="0.9999135">
In Numbat, a property type is also called a rela-
tion. Section 2.1.2 briefly presents some of the
pre-defined property types and their semantics.
Assignment. In PG an assignment is a list of
constituents. Let’s consider, for example, the three
constituents DET, ADJ and N, the following lists
are possible assignments: [DET], [ADJ], [DET,
ADJ], [ADJ, N], [DET, N], [DET, ADJ, N], etc..
</bodyText>
<subsectionHeader confidence="0.758518">
2.1.2 Some Pre-defined Property Types
</subsectionHeader>
<bodyText confidence="0.96483325">
Here are some property types pre-defined in PG.
See (Blache, 2005) for more types and more de-
tailed definitions.
Notation. We note:
</bodyText>
<listItem confidence="0.969715272727273">
• K a set of constructions, with {C, C1, C2} E
K;
• C a set of constituents, with {c, c1, c2} E C;
• A an assignment;
• ind a function such that ind(c, A) is the in-
dex of c in A;
• cx a function such that cx(c) is the construc-
tion of c;
• P(C1, C2)[c1, c2, A] or (C1 P C2)[c1, c2, A]
the constraint such that the relation P param-
etered with (C1, C2), applies to [c1, c2, A].
</listItem>
<subsectionHeader confidence="0.593505">
Linear Precedence (≺).
</subsectionHeader>
<bodyText confidence="0.750957">
By definition, (C1 ≺ C2)[c1, c2, A] holds iff
</bodyText>
<equation confidence="0.980830777777778">
{ cx(c1) = C1, and
cx(c2) = C2, and
{c1, c2} E A, and
ind(c1, A) &lt; ind(c2, A)
Exclusion (�A).
By definition, (C1 �A C2)[c1, c2, A] holds iff
{ cx(c1) = C1, and
cx(c2) = C2, and
{c1, c2} n A =� {c1, c2}
</equation>
<subsectionHeader confidence="0.591638">
Uniqueness (Uniq).
</subsectionHeader>
<bodyText confidence="0.67485275">
By definition, Uniq(C)[c, A] holds iff
{ cx(c) = C, and
cEA, and
Vc&apos; E A\{c}, cx(c&apos;) =� C
</bodyText>
<subsectionHeader confidence="0.930376">
2.2 Related Problems
</subsectionHeader>
<bodyText confidence="0.999941777777778">
CO parsing with PG is an intersection of differ-
ent classes of constraint-related problems, each of
which is listed below.
Configuration problem. Given a set of com-
ponents and a set of constraints specifying how
these components can be connected, a configu-
ration problem consists of finding a solution tree
which connects the components together. Deep
parsing with PG is a configuration problem where
the components are constituents, and the resulting
structure is a phrase structure. By extension, a so-
lution to such a problem is called a configuration.
A configuration problem can be modelled with a
(static) CSP.
Dynamic CSP. In our case the problem is actu-
ally dynamic, in that the set of constraints to be
solved evolves by the addition of new constraints.
As we will see it later new constituents are inferred
during the parsing process, and subsequently new
constraints are dynamically added to the system.
When dealing with deep parsing, i.e. with well-
formedness only, the problem can be tackled as
a Dynamic CSP, and solving techniques such as
Local Search (Verfaillie and Schiex, 1994) can be
applied.
Optimisation problem. In order to account for
ill-formedness as well as well-formedness, we
need to allow constraint relaxation, which turns
the problem into an optimisation one. The ex-
pected outcome is thus an optimal configuration
with respect to some valuation function. Should
the input be well-formed, no constraints are re-
laxed and the expected outcome is a full parse.
Should the input be ill-formed, constraints are re-
laxed and the expected outcome is either an opti-
mal full parse or a set of (optimal) partial parses.
</bodyText>
<sectionHeader confidence="0.997303" genericHeader="method">
3 Numbat Architecture
</sectionHeader>
<subsectionHeader confidence="0.999671">
3.1 The Parsing Strategy in Numbat
</subsectionHeader>
<bodyText confidence="0.98988625">
Relying on a design pattern used in various optimi-
sation techniques, such as dynamic programming,
the top-level strategy adopted in Numbat consists
in three main steps:
</bodyText>
<listItem confidence="0.99853325">
1. splitting the problem into overlapping sub-
problems;
2. solving the sub-problems—or building opti-
mal sub-solutions;
</listItem>
<page confidence="0.985623">
19
</page>
<bodyText confidence="0.989296666666667">
3. building an optimal global solution, using the
sub-solutions.
More specifically, the strategy adopted pro-
ceeds by successive generate-and-test: the possi-
ble models to local systems are generated, then
their satisfiability is tested against the grammar.
The partial solutions are re-injected in the pro-
cess dynamically, and the basic process is iterated
again. Note that the generate-and-test method is
not compulsory and is only chosen here because
it allows us to conveniently control and then filter
the assignments.
Given an input utterance, the parsing process is
made up of a re-iteration of the basic following
steps:
</bodyText>
<listItem confidence="0.92722605">
1. Building Site. Build a set of constituents;
2. Assignation. Build all the possible assign-
ments, i.e. all the possible combinations of
one or more constituents;
3. Checkpoint Alpha. Filter out illegal assign-
ments;
4. Appropriation. For every assignment, iden-
tify and build all the relevant properties
among its elements, which leaves us with a
property store, i.e. a constraint system;
5. Checkpoint Bravo. Filter out illegal assign-
ments and irrelevant properties;
6. Satisfaction. Solve the constraint system;
7. Formation. Identify forms of construction,
i.e. subsets of properties from the property
store and nominate the corresponding candi-
date constructions;
8. Polling booth. Decide which of the candi-
date constructions are licensed and carried
over to the next iteration;
</listItem>
<bodyText confidence="0.996611">
The process stops when no new constituent can be
built.
Each of these steps is defined in the following
section.
</bodyText>
<subsectionHeader confidence="0.927479">
3.1.1 Building Site
</subsectionHeader>
<bodyText confidence="0.999889833333333">
During the first iteration, this phase builds one
constituent for each Part-of-Speech (POS) associ-
ated with an input word. From the second itera-
tion onwards, new constituents are built provided
the candidate assignments output by the previous
round.
</bodyText>
<subsectionHeader confidence="0.837904">
3.1.2 Assignation
</subsectionHeader>
<bodyText confidence="0.999886916666667">
From one iteration to the next new assignments
are built, involving at least one of the new con-
stituents. These constituents result from the pre-
vious iteration. Notice that the amount of new as-
signments created by each iteration grows expo-
nentially with the amount of constituents (the ’old’
ones and the new ones). Fortunately, the next step
will filter out a large proportion of them.
This phase of assignation is essential to the pro-
cess, and makes Numbat different from any other
parsing strategy for PG. The difference will be
made clear in the Satisfaction phase.
</bodyText>
<subsectionHeader confidence="0.491642">
3.1.3 Checkpoint Alpha
</subsectionHeader>
<bodyText confidence="0.9791142">
In Numbat we use a filtering profile to specify
which combination of heuristics applies during the
parsing process. This feature proves to be very
useful when performing experiments, as it allows
an incremental approach, in order to determine the
relative importance of each of the criteria on gra-
dience by turning on and off one or other heuristic.
The heuristics play different roles. They are pri-
marily used to prune the search space as early as
possible in the process. Meanwhile, most of them
capture language specific aspects (e.g. Contigu-
ity, see below). These language specific heuris-
tics are already present in previous works on PG in
one form or another. We are working in the same
framework and accept these restrictions, which
might be relaxed by future work on the formal
side.
During Checkpoint Alpha the following heuris-
tics may apply.
Heuristic 1 (Distinct Constituents) An as-
signment may contain no pairwise intersecting
constituents.
That is, any two constituents may not have any
constituent in common. For example, the con-
stituents {DET1, ADJ2I and {ADJ2, NOUN3I may
not belong to the same assignment, since they have
one constituent in common.
Heuristic 2 (Contiguity) An assignment is a set
of contiguous elements.
This heuristic rules out crossing-over elements.
Although this heuristic has little consequence
when dealing with languages such as French or
English, it may have to be turned off for languages
with cross-serial dependencies such as Dutch. But
if turned off, an additional problem then occurs
</bodyText>
<page confidence="0.987594">
20
</page>
<bodyText confidence="0.999888625">
that the semantics of pre-defined property types
must be re-defined. The linear precedence, for in-
stance, would need to account for the order be-
tween two crossing-over phrases, which is not the
case in the current definition. On the other hand,
notice that long distance dependencies are not
ruled out by heuristic 2, since nested constituents
are still legal.
</bodyText>
<subsectionHeader confidence="0.810168">
3.1.4 Appropriation
</subsectionHeader>
<bodyText confidence="0.999972523809524">
This step has to do with the gathering of all the
properties relevant to every assignment from the
grammar. This operation is made easier by pre-
processing the grammar, which is done at an ini-
tialisation step. During this preliminary phase, a
lookup table is created for the grammar, where all
the properties are indexed by their operands. Ev-
ery property is also linked directly to the construc-
tions for which it participates in the definition—
i.e. the constructions for which the property is
a member of the form. This table is actually a
hash table, where the keys are the constructions
on which the properties hold. For example, the
property (Det ≺ Noun) is indexed by the couple
of constructions (Det, Noun). And the property
({Pronoun, Adv} �A V) is indexed by the triplets
of constructions (Pronoun, Adv, V). Thus, given
an assignment, i.e. a set of constituents, all we
have to do here is to retrieve all the relevant prop-
erties from the lookup table, using all the (rele-
vant) combinations of constituents as keys.
</bodyText>
<subsectionHeader confidence="0.841542">
3.1.5 Checkpoint Bravo
</subsectionHeader>
<bodyText confidence="0.9713924">
Filters apply here, which aim to prune again the
search space. The following heuristics may apply.
Heuristic 3 (Full Coverage) Every element of an
assignment must be involved in at least one con-
straint. That is, for each element in an assignment
there must be at least one constraint defined over
this element.
Example 1 Consider the assignment A =
(Det, N, V), and the grammar made up of the fol-
lowing properties:
</bodyText>
<equation confidence="0.946977333333333">
VP ::= {V ≺ NP}
NP ::= {Uniq(N), Det ≺ N, N ≺ Adj}
S ::= {NP ≺ VP}
</equation>
<bodyText confidence="0.983294647058823">
According to heuristic 3 A is ruled out, since the V
element is not covered by any constraints, whether
we build an NP or a VP.
Notice that this heuristic is semantically equiv-
alent to the Constituency property present in early
versions of PG5. The Constituency property used
to specify which types of constituent (i.e. con-
structions) were legal ones (for a construction).
Such a constraint is unnecessary since the infor-
mation can be retrieved by simply listing all the
types of constituents used in the definitions of
properties. In example 1 for instance, the set
of legal constituents for the NP construction is
[Det, N, Adj].
A main reason for dealing with constituency as
a filter rather than as a constraint is to improve ef-
ficiency by reducing the amount of constraints in
the system. Indeed, a filter aims to rule out con-
straints, which are subsequently removed from the
constraint system. If dealt with as a constraint it-
self, Constituency would only make the constraint
system more complex.
Heuristic 3 raises the issue of ruling out assign-
ments with “free” constituents, i.e. constituents
which are not connected to the rest of the assign-
ment. Such a situation may occur, for example,
in the case of an unknown word, either because
it is absent from the lexicon, or misspelled. We
choose to leave it up to the grammar writer to de-
sign their own ad hoc solutions regarding how to
handle such cases. It may be done, for instance,
through the definition of a “wildcard construc-
tion”, and perhaps also a “wildcard property type”,
which will be used appropriately in the grammar.
</bodyText>
<subsectionHeader confidence="0.920591">
3.1.6 Satisfaction
</subsectionHeader>
<bodyText confidence="0.999913">
At this stage, only legal assignments and rele-
vant properties are kept in the system. All the re-
quired information for evaluating the properties is
thus available and all we have to do now is to solve
the constraint system.
The solver we use is implemented in Constraint
Handling Rules (CHR) (Fr¨uhwirth, 1994). Un-
like other CHR implementations of PG (Moraw-
ietz and Blache, 2002; Dahl and Blache, 2004)
where the semantics of the property types are en-
coded in the handlers6—and therefore each type
of property requires a different handler—, the ap-
proach we have adopted allows us to externalise
the semantics and to generalise the properties eval-
uation with one single handler. The algorithm un-
</bodyText>
<footnote confidence="0.9984995">
5The Constituency property is discarded in the version of
PG underpinning Numbat.
6A CHR handler is a rule of the general form (A =&gt; B
 |C), which can be read “if A then (if B then C)”
</footnote>
<page confidence="0.998926">
21
</page>
<bodyText confidence="0.387404666666667">
derlying this handler can be expressed as follows:
for each (list of n constituents, assignment, property)
if (the list of n constituents and the assignment match the
property’s ones)
then
if (property is satisfied)
then (tick property as being SATISFIED)
else (tick property as being VIOLATED)
The CHR handler takes the following form:
</bodyText>
<equation confidence="0.9997405">
listOfConstituents(Ccs) &amp;&amp;
assignment(Asg) &amp;&amp;
property(Pp) ==&gt;
Pp.isConsistentWith(Asg,Ccs) |
(Pp.isSatisfied() -&gt;
sat(Pp) ; unSat(Pp)).
</equation>
<subsectionHeader confidence="0.463538">
3.1.7 Formation
</subsectionHeader>
<bodyText confidence="0.997893534482759">
This phase is concerned with identifying the
constructions in the grammar which can be trig-
gered (i.e. licensed) by the properties present in
the property store. A construction is triggered by
any of the properties which are used to define this
construction. This task can be performed easily
by accessing them directly in the lookup table (see
section 3.1.4), using a property’s operands as the
key. The constructions which are triggered are
called target constructions. We then build a con-
stituent for each of these target construction. Such
a constituent is called a candidate constituent.
This phase basically builds constituent struc-
tures. During the next iteration these candidates
may be used in turn as constituents. The process
thus accounts for recursive structures as well as
non-recursive ones. Meanwhile, it is interesting to
emphasise that building such a constituent struc-
ture is not necessary when parsing with PG. We
could, for instance, deal with the whole sentence
at once as a sequence of word order constraints.
This way no constituent structure would be needed
to license infinite sets of strings. In this case, the
efficiency of such a process is something that has
been worked on extensively within the CSP field.
What we are contributing is merely a representa-
tion and translation to CSP, which allows us to
take advantage of these efficiencies that decades
of other work have produced.
Monotonic and Non-monotonic Constraints.
The notions of Selection Constraint in (Dahl and
Blache, 2004) and of non-Lacunar Constraint
in (VanRullen, 2005) are equivalent and denote
a class of constraint types, whose semantics is
monotonic, in that their satisfiability does not
change when new elements are added to the as-
signment. Constraint types such as Linear Prece-
dence or Obligation, for example, are monotonic.
On the other hand the constraint Uniq(C)[c, A]
(see 2.1.2), for example, is non-monotonic: if the
contextual assignment A grows—i.e. if new con-
stituents are added to it—the constraint needs to
be re-evaluated. In parsing strategies where the as-
signments are built dynamically by successive ad-
ditions of new constituents, the evaluation of the
relevant constraints is performed on the fly, which
means that the non-monotonic constraints need to
be re-evaluated every time the assignment grows.
This problem is tackled in different ways, accord-
ing to implementation. But we observe that in all
cases, the decision to trigger new candidate con-
stituents relies only on the evaluation of the mono-
tonic constraints. The decision process usually
simply ignores the non-monotonic ones. Numbat,
by fixing the assignments prior to evaluating the
local constraint systems, includes both the mono-
tonic and the non-monotonic constraints in the li-
censing process (i.e. in the Formation phase).
</bodyText>
<subsectionHeader confidence="0.92641">
3.1.8 Polling Booth
</subsectionHeader>
<bodyText confidence="0.999466217391304">
This phase is concerned with the election pro-
cess, which leads to choosing the candidates who
will make it to the next iteration.
The following heuristics may apply.
Heuristic 4 (Minimum Satisfaction) An assign-
ment is valid only if at least one constraint holds
on any of its constituents.
Notice that in all other implementations of PG this
heuristic is much more restrictive and requires that
a monotonic constraint must hold.
Heuristic 5 (Full Input Span) A valid (partial or
final) solution to the parsing problem is either a
single constituent which spans exactly the input
utterance, or a combination of constituents (i.e.
a combination ofpartial parses) which spans ex-
actly the input utterance.
In theory, we want the Polling Booth to build all
the candidate constituents we have identified, and
re-inject them in the system for new iterations. In
practice, different strategies may apply in order to
prune the search space, such as strategies based on
the use of a ranking function. In our case, every it-
eration of the parsing process only propagates one
</bodyText>
<page confidence="0.986672">
22
</page>
<bodyText confidence="0.999975441860465">
valid combination of constituents to the next iter-
ation (e.g. the best one according to a valuation
function). Somehow such a strategy corresponds
to always providing the main process with a “dis-
ambiguated” set of input constituents from one it-
eration to another. This heuristic may also be used
as a termination rule.
A question then arises regarding the relaxation
policy: Do all the constraint types carry same im-
portance with respect to relaxation? This ques-
tion addresses the relative importance of differ-
ent constraint types with respect to acceptability.
Does, for instance, the violation of a constraint
of Linear Precedence between a Determiner and
a Noun in a Noun Phrase have the same impact
on the overall acceptability of the Noun Phrase
than the violation of Uniqueness of the Noun (still
within a Noun Phrase)? From a linguistic point of
view, the answer to that question is not straight-
forward and requires number of empirical studies.
Some works have been carried out (Gibson, 2000;
Keller, 2000), which aim to provide elements of
answer in very targeted syntactic contexts.
The impact that the relaxation of different con-
straint types has on acceptability should not be bi-
ased by a particular parsing strategy. Thus, the
framework provides the linguist (and the grammar
writer) with maximum flexibility when it comes to
decide the cost of relaxing different types of con-
straint on acceptability, since any type may be re-
laxed. Intuitively, one can clearly relax (in French)
a constraint of Agreement in gender between de-
terminer and noun; on the other hand one could
not as easily relax constraints of type Obligation,
which are often used to specify heads. A com-
plete breakdown of constraints into relaxable and
non-relaxable is future work. But at the end, the
parser just produces sets of satisfied and violated
constraints, regardless of how important they are.
There will then be a separate process for predict-
ing gradience, where the relative importance of
particular constraints in determining acceptability
will be decided experimentally.
</bodyText>
<sectionHeader confidence="0.999539" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999572">
In this paper we have presented the constraint-
oriented parsing strategy based on Property Gram-
mars, that we have developed as part of the Num-
bat platform. We have also demonstrated that,
unlike other existing parsers for PG, this strategy
does not privilege any particular type of property
when licensing a new constituent. By doing so,
this parser contributes to maintain a close connec-
tion with the underpinning theory. In the context
of robust parsing, where decisions must be made
on the basis of a balance between satisfied and vi-
olated properties, it also allows the decision pro-
cess to be better informed by providing it with
more grounding linguistic material concerning the
input.
For the same reason, this contribution is also
fairly valuable in the context of our prime research
goal, which is concerned with quantifying accept-
ability.
In further works we plan to evaluate the perfor-
mance of the parser. We also plan to use Numbat
to run series of experiments on gradience, in order
to design and test a suitable valuation function to
be used to assess the degree of acceptability of an
input utterance.
</bodyText>
<sectionHeader confidence="0.999435" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999007129032258">
Jean-Marie Balfourier, Philippe Blache, and Tris-
tan Van Rullen. 2002. From Shallow to Deep Pars-
ing Using Constraint Satisfaction. In Proc. of the
6th Int’l Conference on Computational Linguistics
(COLING 2002).
Gabriel B`es and Philippe Blache. 1999. Propri´et´es et
analyse d’un langage. In TALN.
Philippe Blache. 2001. Les Grammaires de Propri´et´es
: des contraintes pour le traitement automatique des
langues naturelles. Herm`es Sciences.
Philippe Blache. 2004. Constraints: an operational
framework for constructions grammars. In ICCG-
04, pages 25–26.
Philippe Blache. 2005. Property Grammars: A fully
constraint-based theory. In Henning Christiansen,
Peter Rossen Skadhauge, and Jorgen Villadsen, ed-
itors, Constraint Solving and Language Processing,
volume 3438 of LNAI. Springer.
Veronica Dahl and Philippe Blache. 2004. Directly
executable constraint based grammars. In Journees
Francophones de Programmation en Logique avec
Contraintes, pages 149–166, Angers, France.
Ralph Debusmann, Denys Duchier, and Geert-Jan M.
Kruijff. 2004. Extensible Dependency Grammar: A
New Methodology. In Proceedings of the 7th Inter-
national Conference on Computational Linguistics
(COLING 2004).
Denys Duchier. 1999. Axiomatizing Dependency
Parsing Using Set Constraints. In Proceedings 6th
Meeting on the Mathematics of Language, Orlando,
FL.
</reference>
<page confidence="0.970707">
23
</page>
<reference confidence="0.999908720930233">
Denys Duchier. 2000. Configuration Of Labeled Trees
Under Lexicalized Constraints And Principles. To
appear in the Journal of Language and Computation,
December.
Kilian Foth, Wolfgang Menzel, and Ingo Schr¨der.
2004. Robust Parsing with Weighted Constraints.
Natural Language Engineerings.
Thom Fr¨uhwirth. 1994. Theory and Practice of Con-
straint Handling Rules. The Journal of Logic Pro-
gramming, 37((1-3)), October. Special Issue on
Constraint Logic Programming.
Edward Gibson. 2000. The Dependency Locality
Theory: A Distance-Based Theory of Linguistic
Complexity. In Alec Marantz, Yasushi Miyashita,
and Wayne ONeil, editors, Image, Language, Brain,
pages 95–126. Cambridge, Mass., MIT Press.
Adele Goldberg. 1995. Constructions: A Con-
struction Grammar Approach to Argument Struc-
ture. Chicago University Press.
Johannes Heinecke, J¨urgen Kunze, Wolfgang Menzel,
and Ingo Shr¨oder. 1998. Eliminative Parsing with
Graded Constraints. In Proc. 7th CoLing conf., 36th
Annual Meeting of the ACL, volume Coling–ACL
’98, pages pp. 526–530, Montreal, Canada.
Frank Keller. 2000. Gradience in Grammar - Exper-
imental and Computational Aspects of Degrees of
Grammaticality. Ph.D. thesis, University of Edin-
burgh.
Hiroshi Maruyama. 1990. Structural Disambiguation
with Constraint Propagation. In Proceedings 28th
Annual Meeting of the ACL, pages pp. 31–38, Pit-
tburgh, PA.
Frank Morawietz and Philippe Blache. 2002. Pars-
ing natural languages with chr. Under consideration
for publication in Theory and Practice of Logic Pro-
gramming.
Tristan VanRullen. 2005. Vers une analyse syntaxique
a` granularit´e variable. Ph.D. thesis, Universit´e de
Provence, Informatique.
G´erard Verfaillie and Thomas Schiex. 1994. Solution
reuse in dynamic CSPs. In AAAI ’94: Proc. of the
twelfth national conf. on AI (vol. 1), pages 307–312,
Menlo Park, CA, USA. American Ass. for AI.
</reference>
<page confidence="0.999179">
24
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.557502">
<title confidence="0.982084">Numbat: Abolishing Privileges when Licensing New Constituents Constraint-oriented Parsing</title>
<author confidence="0.955557">Jean-Philippe</author>
<affiliation confidence="0.865972">Centre for Language Macquarie University, Sydney, Parole et Universit´e de Provence, Aix-en-Provence,</affiliation>
<email confidence="0.993212">jpprost@ics.mq.edu.au</email>
<abstract confidence="0.997254222222222">The constraint-oriented approaches to language processing step back from the generative theory and make it possible, in theory, to deal with all types of linguistic relationships (e.g. dependency, linear precedence or immediate dominance) with the same importance when parsing an input utterance. Yet in practice, all implemented constraint-oriented parsing strategies still need to discriminate between “important” and “not-so-important” types of relations during the parsing process. In this paper we introduce a new constraint-oriented parsing strategy based which overcomes this drawback and grants the same importance to all types of relations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jean-Marie Balfourier</author>
<author>Philippe Blache</author>
<author>Tristan Van Rullen</author>
</authors>
<title>From Shallow to Deep Parsing Using Constraint Satisfaction.</title>
<date>2002</date>
<booktitle>In Proc. of the 6th Int’l Conference on Computational Linguistics (COLING</booktitle>
<marker>Balfourier, Blache, Van Rullen, 2002</marker>
<rawString>Jean-Marie Balfourier, Philippe Blache, and Tristan Van Rullen. 2002. From Shallow to Deep Parsing Using Constraint Satisfaction. In Proc. of the 6th Int’l Conference on Computational Linguistics (COLING 2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriel B`es</author>
<author>Philippe Blache</author>
</authors>
<title>Propri´et´es et analyse d’un langage.</title>
<date>1999</date>
<booktitle>In TALN.</booktitle>
<marker>B`es, Blache, 1999</marker>
<rawString>Gabriel B`es and Philippe Blache. 1999. Propri´et´es et analyse d’un langage. In TALN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Blache</author>
</authors>
<title>Les Grammaires de Propri´et´es : des contraintes pour le traitement automatique des langues naturelles. Herm`es Sciences.</title>
<date>2001</date>
<contexts>
<context position="1753" citStr="Blache, 2001" startWordPosition="258" endWordPosition="259">The research goal of this project is to build an experimental platform for computing gradience, i.e. for quantifying the degree of acceptability of an input utterance. We called this platform Numbat. In order to be able to quantify such a gradient of acceptability with no a priori opinion on the influence played by different types of linguistic relationships, we want to adopt a framework where no one type of (syntactic) relation (e.g. dependency, immediate dominance, or linear precedence) is preferred over the other ones. Although a constraint-oriented (CO) paradigm such as Property Grammars (Blache, 2001) theoretically does not rely on any preferred relations, we observe that the parsing strategies implemented so far (Morawietz and Blache, 2002; Balfourier et al., 2002; Dahl and Blache, 2004; VanRullen, 2005) do not account for such a feature of the formalism. The strategy we have designed overcomes that problem and allows for constituents to be licensed by any type of relation. Not only does our approach maintain a close connection between implementation and underpinning theory, but it also allows for the decisions made with respect to gradience to be better informed. The purpose of the prese</context>
<context position="5160" citStr="Blache, 2001" startWordPosition="793" endWordPosition="794">i-dimensional” dependency graph, where each dimension (e.g. Immediate Dominance and Linear Precedence) is associated with its own set of well-formedness conditions (called principles). Duchier (2000) sees dependency parsing as a configuration problem, where given a finite set of components (nodes in a graph) and a set of constraints specifying how these components may be connected, the task consists of finding a solution tree. It seems, to the best of our knowledge, that neither of these works around XDG attempts to account for ill-formedness. The Property Grammars (PG), introduced by Blache (Blache, 2001; Blache, 2005)2, step back from Dependency Grammar. Solving the constraint system no longer results in a dependency structure but in a phrase structure, whose granularity may be tailored from a shallow one (i.e. a collection of disconnected components) to a deep one (i.e. a single hierarchical structure of constituents) according to application requirements3. This feature makes the formalism well suited for accounting for both ill-formedness and well-formedness, which is a key requirement for our experimental platform. Introducing degrees of acceptability for an utterance does not mean indeed</context>
</contexts>
<marker>Blache, 2001</marker>
<rawString>Philippe Blache. 2001. Les Grammaires de Propri´et´es : des contraintes pour le traitement automatique des langues naturelles. Herm`es Sciences.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Blache</author>
</authors>
<title>Constraints: an operational framework for constructions grammars.</title>
<date>2004</date>
<booktitle>In ICCG04,</booktitle>
<pages>25--26</pages>
<contexts>
<context position="1943" citStr="Blache, 2004" startWordPosition="288" endWordPosition="289"> Numbat. In order to be able to quantify such a gradient of acceptability with no a priori opinion on the influence played by different types of linguistic relationships, we want to adopt a framework where no one type of (syntactic) relation (e.g. dependency, immediate dominance, or linear precedence) is preferred over the other ones. Although a constraint-oriented (CO) paradigm such as Property Grammars (Blache, 2001) theoretically does not rely on any preferred relations, we observe that the parsing strategies implemented so far (Morawietz and Blache, 2002; Balfourier et al., 2002; Dahl and Blache, 2004; VanRullen, 2005) do not account for such a feature of the formalism. The strategy we have designed overcomes that problem and allows for constituents to be licensed by any type of relation. Not only does our approach maintain a close connection between implementation and underpinning theory, but it also allows for the decisions made with respect to gradience to be better informed. The purpose of the present paper is to present this new parsing strategy, and to emphasise how it “abolishes the privilege” usually only granted to a subset of syntactic relationships. Section 2 presents some backg</context>
<context position="6165" citStr="Blache, 2004" startWordPosition="953" endWordPosition="954">ism well suited for accounting for both ill-formedness and well-formedness, which is a key requirement for our experimental platform. Introducing degrees of acceptability for an utterance does not mean indeed that it should be done at the expense of well-formedness: we want our model to account for ill-formedness and yet to also be able to recognise and acknowledge when an utterance is well-formed. This require1Although they are referred to with the same name by their respective authors, Duchier’s notion of selection constraint is not to be confused with Dahl’s selection constraints (Dahl and Blache, 2004). The two notions are significantly different. 2The Property Grammars were defined on the basis of the 5P formalism (B`es and Blache, 1999). 3For a discussion regarding PG and parsing with variable granularity see (VanRullen, 2005). ment rules out Optimality-theoretic frameworks as well as the ones based on Maruyama’s CDG. Note that this is not to say that the task could not be achieved in a CDG-based framework; simply at this stage there is no work based on CDG, which would combine both an account of wellformedness and of optimality. A CO framework based on PG seems therefore best-suited for </context>
<context position="8350" citStr="Blache (2004)" startWordPosition="1313" endWordPosition="1314"> or from other previously established constructions. In this paper we only focus on syntax. For us, at the syntactic level, a construction is defined by a form, where a form is specified as a list of properties. When building a traditional phrase structure (i.e. a hierarchical structure of constituents) a construction can be simply seen as a non-terminal. Property. A property is a constraint, which models a relationship among constructions. PG pre-defines several types of properties, which are specified according to their semantics. Moreover, the framework allows for new types to be defined. 4Blache (2004) discussed how PG can be used as a formal framework for CxG. 18 In Numbat, a property type is also called a relation. Section 2.1.2 briefly presents some of the pre-defined property types and their semantics. Assignment. In PG an assignment is a list of constituents. Let’s consider, for example, the three constituents DET, ADJ and N, the following lists are possible assignments: [DET], [ADJ], [DET, ADJ], [ADJ, N], [DET, N], [DET, ADJ, N], etc.. 2.1.2 Some Pre-defined Property Types Here are some property types pre-defined in PG. See (Blache, 2005) for more types and more detailed definitions. </context>
<context position="19581" citStr="Blache, 2004" startWordPosition="3206" endWordPosition="3207">le such cases. It may be done, for instance, through the definition of a “wildcard construction”, and perhaps also a “wildcard property type”, which will be used appropriately in the grammar. 3.1.6 Satisfaction At this stage, only legal assignments and relevant properties are kept in the system. All the required information for evaluating the properties is thus available and all we have to do now is to solve the constraint system. The solver we use is implemented in Constraint Handling Rules (CHR) (Fr¨uhwirth, 1994). Unlike other CHR implementations of PG (Morawietz and Blache, 2002; Dahl and Blache, 2004) where the semantics of the property types are encoded in the handlers6—and therefore each type of property requires a different handler—, the approach we have adopted allows us to externalise the semantics and to generalise the properties evaluation with one single handler. The algorithm un5The Constituency property is discarded in the version of PG underpinning Numbat. 6A CHR handler is a rule of the general form (A =&gt; B |C), which can be read “if A then (if B then C)” 21 derlying this handler can be expressed as follows: for each (list of n constituents, assignment, property) if (the list o</context>
<context position="22065" citStr="Blache, 2004" startWordPosition="3603" endWordPosition="3604">essary when parsing with PG. We could, for instance, deal with the whole sentence at once as a sequence of word order constraints. This way no constituent structure would be needed to license infinite sets of strings. In this case, the efficiency of such a process is something that has been worked on extensively within the CSP field. What we are contributing is merely a representation and translation to CSP, which allows us to take advantage of these efficiencies that decades of other work have produced. Monotonic and Non-monotonic Constraints. The notions of Selection Constraint in (Dahl and Blache, 2004) and of non-Lacunar Constraint in (VanRullen, 2005) are equivalent and denote a class of constraint types, whose semantics is monotonic, in that their satisfiability does not change when new elements are added to the assignment. Constraint types such as Linear Precedence or Obligation, for example, are monotonic. On the other hand the constraint Uniq(C)[c, A] (see 2.1.2), for example, is non-monotonic: if the contextual assignment A grows—i.e. if new constituents are added to it—the constraint needs to be re-evaluated. In parsing strategies where the assignments are built dynamically by succes</context>
</contexts>
<marker>Blache, 2004</marker>
<rawString>Philippe Blache. 2004. Constraints: an operational framework for constructions grammars. In ICCG04, pages 25–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Blache</author>
</authors>
<title>Property Grammars: A fully constraint-based theory.</title>
<date>2005</date>
<booktitle>Constraint Solving and Language Processing,</booktitle>
<volume>3438</volume>
<editor>In Henning Christiansen, Peter Rossen Skadhauge, and Jorgen Villadsen, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="5175" citStr="Blache, 2005" startWordPosition="795" endWordPosition="796"> dependency graph, where each dimension (e.g. Immediate Dominance and Linear Precedence) is associated with its own set of well-formedness conditions (called principles). Duchier (2000) sees dependency parsing as a configuration problem, where given a finite set of components (nodes in a graph) and a set of constraints specifying how these components may be connected, the task consists of finding a solution tree. It seems, to the best of our knowledge, that neither of these works around XDG attempts to account for ill-formedness. The Property Grammars (PG), introduced by Blache (Blache, 2001; Blache, 2005)2, step back from Dependency Grammar. Solving the constraint system no longer results in a dependency structure but in a phrase structure, whose granularity may be tailored from a shallow one (i.e. a collection of disconnected components) to a deep one (i.e. a single hierarchical structure of constituents) according to application requirements3. This feature makes the formalism well suited for accounting for both ill-formedness and well-formedness, which is a key requirement for our experimental platform. Introducing degrees of acceptability for an utterance does not mean indeed that it should</context>
<context position="8903" citStr="Blache, 2005" startWordPosition="1405" endWordPosition="1406">framework allows for new types to be defined. 4Blache (2004) discussed how PG can be used as a formal framework for CxG. 18 In Numbat, a property type is also called a relation. Section 2.1.2 briefly presents some of the pre-defined property types and their semantics. Assignment. In PG an assignment is a list of constituents. Let’s consider, for example, the three constituents DET, ADJ and N, the following lists are possible assignments: [DET], [ADJ], [DET, ADJ], [ADJ, N], [DET, N], [DET, ADJ, N], etc.. 2.1.2 Some Pre-defined Property Types Here are some property types pre-defined in PG. See (Blache, 2005) for more types and more detailed definitions. Notation. We note: • K a set of constructions, with {C, C1, C2} E K; • C a set of constituents, with {c, c1, c2} E C; • A an assignment; • ind a function such that ind(c, A) is the index of c in A; • cx a function such that cx(c) is the construction of c; • P(C1, C2)[c1, c2, A] or (C1 P C2)[c1, c2, A] the constraint such that the relation P parametered with (C1, C2), applies to [c1, c2, A]. Linear Precedence (≺). By definition, (C1 ≺ C2)[c1, c2, A] holds iff { cx(c1) = C1, and cx(c2) = C2, and {c1, c2} E A, and ind(c1, A) &lt; ind(c2, A) Exclusion (�</context>
</contexts>
<marker>Blache, 2005</marker>
<rawString>Philippe Blache. 2005. Property Grammars: A fully constraint-based theory. In Henning Christiansen, Peter Rossen Skadhauge, and Jorgen Villadsen, editors, Constraint Solving and Language Processing, volume 3438 of LNAI. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronica Dahl</author>
<author>Philippe Blache</author>
</authors>
<title>Directly executable constraint based grammars.</title>
<date>2004</date>
<booktitle>In Journees Francophones de Programmation en Logique avec Contraintes,</booktitle>
<pages>149--166</pages>
<location>Angers, France.</location>
<contexts>
<context position="1943" citStr="Dahl and Blache, 2004" startWordPosition="286" endWordPosition="289"> platform Numbat. In order to be able to quantify such a gradient of acceptability with no a priori opinion on the influence played by different types of linguistic relationships, we want to adopt a framework where no one type of (syntactic) relation (e.g. dependency, immediate dominance, or linear precedence) is preferred over the other ones. Although a constraint-oriented (CO) paradigm such as Property Grammars (Blache, 2001) theoretically does not rely on any preferred relations, we observe that the parsing strategies implemented so far (Morawietz and Blache, 2002; Balfourier et al., 2002; Dahl and Blache, 2004; VanRullen, 2005) do not account for such a feature of the formalism. The strategy we have designed overcomes that problem and allows for constituents to be licensed by any type of relation. Not only does our approach maintain a close connection between implementation and underpinning theory, but it also allows for the decisions made with respect to gradience to be better informed. The purpose of the present paper is to present this new parsing strategy, and to emphasise how it “abolishes the privilege” usually only granted to a subset of syntactic relationships. Section 2 presents some backg</context>
<context position="6165" citStr="Dahl and Blache, 2004" startWordPosition="951" endWordPosition="954">he formalism well suited for accounting for both ill-formedness and well-formedness, which is a key requirement for our experimental platform. Introducing degrees of acceptability for an utterance does not mean indeed that it should be done at the expense of well-formedness: we want our model to account for ill-formedness and yet to also be able to recognise and acknowledge when an utterance is well-formed. This require1Although they are referred to with the same name by their respective authors, Duchier’s notion of selection constraint is not to be confused with Dahl’s selection constraints (Dahl and Blache, 2004). The two notions are significantly different. 2The Property Grammars were defined on the basis of the 5P formalism (B`es and Blache, 1999). 3For a discussion regarding PG and parsing with variable granularity see (VanRullen, 2005). ment rules out Optimality-theoretic frameworks as well as the ones based on Maruyama’s CDG. Note that this is not to say that the task could not be achieved in a CDG-based framework; simply at this stage there is no work based on CDG, which would combine both an account of wellformedness and of optimality. A CO framework based on PG seems therefore best-suited for </context>
<context position="19581" citStr="Dahl and Blache, 2004" startWordPosition="3204" endWordPosition="3207">w to handle such cases. It may be done, for instance, through the definition of a “wildcard construction”, and perhaps also a “wildcard property type”, which will be used appropriately in the grammar. 3.1.6 Satisfaction At this stage, only legal assignments and relevant properties are kept in the system. All the required information for evaluating the properties is thus available and all we have to do now is to solve the constraint system. The solver we use is implemented in Constraint Handling Rules (CHR) (Fr¨uhwirth, 1994). Unlike other CHR implementations of PG (Morawietz and Blache, 2002; Dahl and Blache, 2004) where the semantics of the property types are encoded in the handlers6—and therefore each type of property requires a different handler—, the approach we have adopted allows us to externalise the semantics and to generalise the properties evaluation with one single handler. The algorithm un5The Constituency property is discarded in the version of PG underpinning Numbat. 6A CHR handler is a rule of the general form (A =&gt; B |C), which can be read “if A then (if B then C)” 21 derlying this handler can be expressed as follows: for each (list of n constituents, assignment, property) if (the list o</context>
<context position="22065" citStr="Dahl and Blache, 2004" startWordPosition="3601" endWordPosition="3604">s not necessary when parsing with PG. We could, for instance, deal with the whole sentence at once as a sequence of word order constraints. This way no constituent structure would be needed to license infinite sets of strings. In this case, the efficiency of such a process is something that has been worked on extensively within the CSP field. What we are contributing is merely a representation and translation to CSP, which allows us to take advantage of these efficiencies that decades of other work have produced. Monotonic and Non-monotonic Constraints. The notions of Selection Constraint in (Dahl and Blache, 2004) and of non-Lacunar Constraint in (VanRullen, 2005) are equivalent and denote a class of constraint types, whose semantics is monotonic, in that their satisfiability does not change when new elements are added to the assignment. Constraint types such as Linear Precedence or Obligation, for example, are monotonic. On the other hand the constraint Uniq(C)[c, A] (see 2.1.2), for example, is non-monotonic: if the contextual assignment A grows—i.e. if new constituents are added to it—the constraint needs to be re-evaluated. In parsing strategies where the assignments are built dynamically by succes</context>
</contexts>
<marker>Dahl, Blache, 2004</marker>
<rawString>Veronica Dahl and Philippe Blache. 2004. Directly executable constraint based grammars. In Journees Francophones de Programmation en Logique avec Contraintes, pages 149–166, Angers, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Debusmann</author>
<author>Denys Duchier</author>
<author>Geert-Jan M Kruijff</author>
</authors>
<title>Extensible Dependency Grammar: A New Methodology.</title>
<date>2004</date>
<booktitle>In Proceedings of the 7th International Conference on Computational Linguistics (COLING</booktitle>
<contexts>
<context position="4489" citStr="Debusmann et al., 2004" startWordPosition="682" endWordPosition="686">ing (CSLP-06), pages 17–24, Sydney, July 2006. c�2006 Association for Computational Linguistics straint system as a set of well-formedness conditions, since even a well-formed utterance violates a subset of constraints. Consequently it is not possible to distinguish an optimal structure of an illformed utterance from an optimal structure of a well-formed utterance. Duchier (1999) relies on set constraints and selection constraints1 to axiomatise syntactic wellformedness and provides a concurrent constraint programming account of the parsing process. With the eXtended Dependency Grammar (XDG) (Debusmann et al., 2004) the notion of dependency tree is further extended to “multi-dimensional” dependency graph, where each dimension (e.g. Immediate Dominance and Linear Precedence) is associated with its own set of well-formedness conditions (called principles). Duchier (2000) sees dependency parsing as a configuration problem, where given a finite set of components (nodes in a graph) and a set of constraints specifying how these components may be connected, the task consists of finding a solution tree. It seems, to the best of our knowledge, that neither of these works around XDG attempts to account for ill-for</context>
</contexts>
<marker>Debusmann, Duchier, Kruijff, 2004</marker>
<rawString>Ralph Debusmann, Denys Duchier, and Geert-Jan M. Kruijff. 2004. Extensible Dependency Grammar: A New Methodology. In Proceedings of the 7th International Conference on Computational Linguistics (COLING 2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Denys Duchier</author>
</authors>
<title>Axiomatizing Dependency Parsing Using Set Constraints.</title>
<date>1999</date>
<booktitle>In Proceedings 6th Meeting on the Mathematics of Language,</booktitle>
<location>Orlando, FL.</location>
<contexts>
<context position="3144" citStr="Duchier, 1999" startWordPosition="479" endWordPosition="480">s some background information about the CO approaches and briefly introduces the Property Grammars formalism. Section 3 exposes and discusses the parsing strategy implemented in Numbat. Section 4 then draws the conclusion. 2 Constraint-oriented Approaches The main feature common to all Constraintoriented approaches is that parsing is modelled as a Constraint Satisfaction Problem (CSP). Maruyama’s Constraint Dependency Grammar (CDG) (Maruyama, 1990) is the first formalism to introduce the parsing process as a CSP solver. Several extensions of CDG have then been proposed (Heinecke et al., 1998; Duchier, 1999; Foth et al., 2004). Menzel and colleagues (Heinecke et al., 1998; Foth et al., 2004) developed a weighted (or “graded”) version of CDG. Their parsing strategies are explored in the context of robust parsing. These strategies are based on an over-generation of candidate solutions. In this approach the CSP is turned into an optimisation problem, where suboptimal solutions are filtered out according to a function of the weights associated to the violated constraints, and the notion of well-formedness is replaced by one of optimality. Indeed, the overgeneration introduces inconsistencies in the </context>
</contexts>
<marker>Duchier, 1999</marker>
<rawString>Denys Duchier. 1999. Axiomatizing Dependency Parsing Using Set Constraints. In Proceedings 6th Meeting on the Mathematics of Language, Orlando, FL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Denys Duchier</author>
</authors>
<title>Configuration Of Labeled Trees Under Lexicalized Constraints And Principles.</title>
<date>2000</date>
<journal>the Journal of Language and Computation,</journal>
<note>To appear in</note>
<contexts>
<context position="4747" citStr="Duchier (2000)" startWordPosition="723" endWordPosition="724">an optimal structure of an illformed utterance from an optimal structure of a well-formed utterance. Duchier (1999) relies on set constraints and selection constraints1 to axiomatise syntactic wellformedness and provides a concurrent constraint programming account of the parsing process. With the eXtended Dependency Grammar (XDG) (Debusmann et al., 2004) the notion of dependency tree is further extended to “multi-dimensional” dependency graph, where each dimension (e.g. Immediate Dominance and Linear Precedence) is associated with its own set of well-formedness conditions (called principles). Duchier (2000) sees dependency parsing as a configuration problem, where given a finite set of components (nodes in a graph) and a set of constraints specifying how these components may be connected, the task consists of finding a solution tree. It seems, to the best of our knowledge, that neither of these works around XDG attempts to account for ill-formedness. The Property Grammars (PG), introduced by Blache (Blache, 2001; Blache, 2005)2, step back from Dependency Grammar. Solving the constraint system no longer results in a dependency structure but in a phrase structure, whose granularity may be tailored</context>
</contexts>
<marker>Duchier, 2000</marker>
<rawString>Denys Duchier. 2000. Configuration Of Labeled Trees Under Lexicalized Constraints And Principles. To appear in the Journal of Language and Computation, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kilian Foth</author>
<author>Wolfgang Menzel</author>
<author>Ingo Schr¨der</author>
</authors>
<title>Robust Parsing with Weighted Constraints. Natural Language Engineerings.</title>
<date>2004</date>
<marker>Foth, Menzel, Schr¨der, 2004</marker>
<rawString>Kilian Foth, Wolfgang Menzel, and Ingo Schr¨der. 2004. Robust Parsing with Weighted Constraints. Natural Language Engineerings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thom Fr¨uhwirth</author>
</authors>
<title>Theory and Practice of Constraint Handling Rules.</title>
<date>1994</date>
<journal>The Journal of Logic Programming,</journal>
<booktitle>Special Issue on Constraint Logic Programming.</booktitle>
<pages>37--1</pages>
<marker>Fr¨uhwirth, 1994</marker>
<rawString>Thom Fr¨uhwirth. 1994. Theory and Practice of Constraint Handling Rules. The Journal of Logic Programming, 37((1-3)), October. Special Issue on Constraint Logic Programming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Gibson</author>
</authors>
<title>The Dependency Locality Theory: A Distance-Based Theory of Linguistic Complexity.</title>
<date>2000</date>
<pages>95--126</pages>
<editor>In Alec Marantz, Yasushi Miyashita, and Wayne ONeil, editors, Image, Language, Brain,</editor>
<publisher>MIT Press.</publisher>
<location>Cambridge, Mass.,</location>
<contexts>
<context position="25444" citStr="Gibson, 2000" startWordPosition="4149" endWordPosition="4150">constraint types carry same importance with respect to relaxation? This question addresses the relative importance of different constraint types with respect to acceptability. Does, for instance, the violation of a constraint of Linear Precedence between a Determiner and a Noun in a Noun Phrase have the same impact on the overall acceptability of the Noun Phrase than the violation of Uniqueness of the Noun (still within a Noun Phrase)? From a linguistic point of view, the answer to that question is not straightforward and requires number of empirical studies. Some works have been carried out (Gibson, 2000; Keller, 2000), which aim to provide elements of answer in very targeted syntactic contexts. The impact that the relaxation of different constraint types has on acceptability should not be biased by a particular parsing strategy. Thus, the framework provides the linguist (and the grammar writer) with maximum flexibility when it comes to decide the cost of relaxing different types of constraint on acceptability, since any type may be relaxed. Intuitively, one can clearly relax (in French) a constraint of Agreement in gender between determiner and noun; on the other hand one could not as easily</context>
</contexts>
<marker>Gibson, 2000</marker>
<rawString>Edward Gibson. 2000. The Dependency Locality Theory: A Distance-Based Theory of Linguistic Complexity. In Alec Marantz, Yasushi Miyashita, and Wayne ONeil, editors, Image, Language, Brain, pages 95–126. Cambridge, Mass., MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adele Goldberg</author>
</authors>
<title>Constructions: A Construction Grammar Approach to Argument Structure.</title>
<date>1995</date>
<publisher>Chicago University Press.</publisher>
<contexts>
<context position="7567" citStr="Goldberg, 1995" startWordPosition="1180" endWordPosition="1181">f these strategies implements the possibility afforded by the theory to rely on any type of constraint in order to license a (possibly ill-formed) constituent. We will see in this paper how the parsing strategy implemented in Numbat overcomes this problem. 2.1 The Property Grammars Formalism 2.1.1 Terminology Construction. In PG a construction can be a lexical item’s Part-of-Speech, a phrase, or toplevel constructions such as, for example, the Caused-motion or the Subject-auxiliary Inversion constructions. The notion of construction is similar to the one in Construction Grammar (CxG)4, as in (Goldberg, 1995), where: Cx is a construction iff Cx is a formmeaning pair (Fi, Si) such that some aspect of Fi or some aspect of Si is not strictly predictable from Cx’s component parts or from other previously established constructions. In this paper we only focus on syntax. For us, at the syntactic level, a construction is defined by a form, where a form is specified as a list of properties. When building a traditional phrase structure (i.e. a hierarchical structure of constituents) a construction can be simply seen as a non-terminal. Property. A property is a constraint, which models a relationship among </context>
</contexts>
<marker>Goldberg, 1995</marker>
<rawString>Adele Goldberg. 1995. Constructions: A Construction Grammar Approach to Argument Structure. Chicago University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Heinecke</author>
<author>J¨urgen Kunze</author>
<author>Wolfgang Menzel</author>
<author>Ingo Shr¨oder</author>
</authors>
<title>Eliminative Parsing with Graded Constraints.</title>
<date>1998</date>
<journal>Coling–ACL</journal>
<booktitle>In Proc. 7th CoLing conf., 36th Annual Meeting of the ACL,</booktitle>
<volume>volume</volume>
<pages>526--530</pages>
<location>Montreal, Canada.</location>
<marker>Heinecke, Kunze, Menzel, Shr¨oder, 1998</marker>
<rawString>Johannes Heinecke, J¨urgen Kunze, Wolfgang Menzel, and Ingo Shr¨oder. 1998. Eliminative Parsing with Graded Constraints. In Proc. 7th CoLing conf., 36th Annual Meeting of the ACL, volume Coling–ACL ’98, pages pp. 526–530, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Keller</author>
</authors>
<date>2000</date>
<booktitle>Gradience in Grammar - Experimental and Computational Aspects of Degrees of Grammaticality. Ph.D. thesis,</booktitle>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="25459" citStr="Keller, 2000" startWordPosition="4151" endWordPosition="4152">es carry same importance with respect to relaxation? This question addresses the relative importance of different constraint types with respect to acceptability. Does, for instance, the violation of a constraint of Linear Precedence between a Determiner and a Noun in a Noun Phrase have the same impact on the overall acceptability of the Noun Phrase than the violation of Uniqueness of the Noun (still within a Noun Phrase)? From a linguistic point of view, the answer to that question is not straightforward and requires number of empirical studies. Some works have been carried out (Gibson, 2000; Keller, 2000), which aim to provide elements of answer in very targeted syntactic contexts. The impact that the relaxation of different constraint types has on acceptability should not be biased by a particular parsing strategy. Thus, the framework provides the linguist (and the grammar writer) with maximum flexibility when it comes to decide the cost of relaxing different types of constraint on acceptability, since any type may be relaxed. Intuitively, one can clearly relax (in French) a constraint of Agreement in gender between determiner and noun; on the other hand one could not as easily relax constrai</context>
</contexts>
<marker>Keller, 2000</marker>
<rawString>Frank Keller. 2000. Gradience in Grammar - Experimental and Computational Aspects of Degrees of Grammaticality. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Maruyama</author>
</authors>
<title>Structural Disambiguation with Constraint Propagation.</title>
<date>1990</date>
<booktitle>In Proceedings 28th Annual Meeting of the ACL,</booktitle>
<pages>31--38</pages>
<location>Pittburgh, PA.</location>
<contexts>
<context position="2983" citStr="Maruyama, 1990" startWordPosition="451" endWordPosition="452">present this new parsing strategy, and to emphasise how it “abolishes the privilege” usually only granted to a subset of syntactic relationships. Section 2 presents some background information about the CO approaches and briefly introduces the Property Grammars formalism. Section 3 exposes and discusses the parsing strategy implemented in Numbat. Section 4 then draws the conclusion. 2 Constraint-oriented Approaches The main feature common to all Constraintoriented approaches is that parsing is modelled as a Constraint Satisfaction Problem (CSP). Maruyama’s Constraint Dependency Grammar (CDG) (Maruyama, 1990) is the first formalism to introduce the parsing process as a CSP solver. Several extensions of CDG have then been proposed (Heinecke et al., 1998; Duchier, 1999; Foth et al., 2004). Menzel and colleagues (Heinecke et al., 1998; Foth et al., 2004) developed a weighted (or “graded”) version of CDG. Their parsing strategies are explored in the context of robust parsing. These strategies are based on an over-generation of candidate solutions. In this approach the CSP is turned into an optimisation problem, where suboptimal solutions are filtered out according to a function of the weights associat</context>
</contexts>
<marker>Maruyama, 1990</marker>
<rawString>Hiroshi Maruyama. 1990. Structural Disambiguation with Constraint Propagation. In Proceedings 28th Annual Meeting of the ACL, pages pp. 31–38, Pittburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Morawietz</author>
<author>Philippe Blache</author>
</authors>
<title>Parsing natural languages with chr. Under consideration for publication in Theory and Practice of Logic Programming.</title>
<date>2002</date>
<contexts>
<context position="1895" citStr="Morawietz and Blache, 2002" startWordPosition="277" endWordPosition="281">f acceptability of an input utterance. We called this platform Numbat. In order to be able to quantify such a gradient of acceptability with no a priori opinion on the influence played by different types of linguistic relationships, we want to adopt a framework where no one type of (syntactic) relation (e.g. dependency, immediate dominance, or linear precedence) is preferred over the other ones. Although a constraint-oriented (CO) paradigm such as Property Grammars (Blache, 2001) theoretically does not rely on any preferred relations, we observe that the parsing strategies implemented so far (Morawietz and Blache, 2002; Balfourier et al., 2002; Dahl and Blache, 2004; VanRullen, 2005) do not account for such a feature of the formalism. The strategy we have designed overcomes that problem and allows for constituents to be licensed by any type of relation. Not only does our approach maintain a close connection between implementation and underpinning theory, but it also allows for the decisions made with respect to gradience to be better informed. The purpose of the present paper is to present this new parsing strategy, and to emphasise how it “abolishes the privilege” usually only granted to a subset of syntac</context>
<context position="6878" citStr="Morawietz and Blache, 2002" startWordPosition="1068" endWordPosition="1072">he basis of the 5P formalism (B`es and Blache, 1999). 3For a discussion regarding PG and parsing with variable granularity see (VanRullen, 2005). ment rules out Optimality-theoretic frameworks as well as the ones based on Maruyama’s CDG. Note that this is not to say that the task could not be achieved in a CDG-based framework; simply at this stage there is no work based on CDG, which would combine both an account of wellformedness and of optimality. A CO framework based on PG seems therefore best-suited for our purpose. Meanwhile, though different parsing strategies have been proposed for PG (Morawietz and Blache, 2002; Balfourier et al., 2002; Dahl and Blache, 2004; VanRullen, 2005), none of these strategies implements the possibility afforded by the theory to rely on any type of constraint in order to license a (possibly ill-formed) constituent. We will see in this paper how the parsing strategy implemented in Numbat overcomes this problem. 2.1 The Property Grammars Formalism 2.1.1 Terminology Construction. In PG a construction can be a lexical item’s Part-of-Speech, a phrase, or toplevel constructions such as, for example, the Caused-motion or the Subject-auxiliary Inversion constructions. The notion of </context>
<context position="19557" citStr="Morawietz and Blache, 2002" startWordPosition="3199" endWordPosition="3203">d hoc solutions regarding how to handle such cases. It may be done, for instance, through the definition of a “wildcard construction”, and perhaps also a “wildcard property type”, which will be used appropriately in the grammar. 3.1.6 Satisfaction At this stage, only legal assignments and relevant properties are kept in the system. All the required information for evaluating the properties is thus available and all we have to do now is to solve the constraint system. The solver we use is implemented in Constraint Handling Rules (CHR) (Fr¨uhwirth, 1994). Unlike other CHR implementations of PG (Morawietz and Blache, 2002; Dahl and Blache, 2004) where the semantics of the property types are encoded in the handlers6—and therefore each type of property requires a different handler—, the approach we have adopted allows us to externalise the semantics and to generalise the properties evaluation with one single handler. The algorithm un5The Constituency property is discarded in the version of PG underpinning Numbat. 6A CHR handler is a rule of the general form (A =&gt; B |C), which can be read “if A then (if B then C)” 21 derlying this handler can be expressed as follows: for each (list of n constituents, assignment, </context>
</contexts>
<marker>Morawietz, Blache, 2002</marker>
<rawString>Frank Morawietz and Philippe Blache. 2002. Parsing natural languages with chr. Under consideration for publication in Theory and Practice of Logic Programming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tristan VanRullen</author>
</authors>
<title>Vers une analyse syntaxique a` granularit´e variable.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>Universit´e de Provence, Informatique.</institution>
<contexts>
<context position="1961" citStr="VanRullen, 2005" startWordPosition="290" endWordPosition="291">der to be able to quantify such a gradient of acceptability with no a priori opinion on the influence played by different types of linguistic relationships, we want to adopt a framework where no one type of (syntactic) relation (e.g. dependency, immediate dominance, or linear precedence) is preferred over the other ones. Although a constraint-oriented (CO) paradigm such as Property Grammars (Blache, 2001) theoretically does not rely on any preferred relations, we observe that the parsing strategies implemented so far (Morawietz and Blache, 2002; Balfourier et al., 2002; Dahl and Blache, 2004; VanRullen, 2005) do not account for such a feature of the formalism. The strategy we have designed overcomes that problem and allows for constituents to be licensed by any type of relation. Not only does our approach maintain a close connection between implementation and underpinning theory, but it also allows for the decisions made with respect to gradience to be better informed. The purpose of the present paper is to present this new parsing strategy, and to emphasise how it “abolishes the privilege” usually only granted to a subset of syntactic relationships. Section 2 presents some background information </context>
<context position="6396" citStr="VanRullen, 2005" startWordPosition="988" endWordPosition="989">one at the expense of well-formedness: we want our model to account for ill-formedness and yet to also be able to recognise and acknowledge when an utterance is well-formed. This require1Although they are referred to with the same name by their respective authors, Duchier’s notion of selection constraint is not to be confused with Dahl’s selection constraints (Dahl and Blache, 2004). The two notions are significantly different. 2The Property Grammars were defined on the basis of the 5P formalism (B`es and Blache, 1999). 3For a discussion regarding PG and parsing with variable granularity see (VanRullen, 2005). ment rules out Optimality-theoretic frameworks as well as the ones based on Maruyama’s CDG. Note that this is not to say that the task could not be achieved in a CDG-based framework; simply at this stage there is no work based on CDG, which would combine both an account of wellformedness and of optimality. A CO framework based on PG seems therefore best-suited for our purpose. Meanwhile, though different parsing strategies have been proposed for PG (Morawietz and Blache, 2002; Balfourier et al., 2002; Dahl and Blache, 2004; VanRullen, 2005), none of these strategies implements the possibilit</context>
<context position="22116" citStr="VanRullen, 2005" startWordPosition="3610" endWordPosition="3611">nce, deal with the whole sentence at once as a sequence of word order constraints. This way no constituent structure would be needed to license infinite sets of strings. In this case, the efficiency of such a process is something that has been worked on extensively within the CSP field. What we are contributing is merely a representation and translation to CSP, which allows us to take advantage of these efficiencies that decades of other work have produced. Monotonic and Non-monotonic Constraints. The notions of Selection Constraint in (Dahl and Blache, 2004) and of non-Lacunar Constraint in (VanRullen, 2005) are equivalent and denote a class of constraint types, whose semantics is monotonic, in that their satisfiability does not change when new elements are added to the assignment. Constraint types such as Linear Precedence or Obligation, for example, are monotonic. On the other hand the constraint Uniq(C)[c, A] (see 2.1.2), for example, is non-monotonic: if the contextual assignment A grows—i.e. if new constituents are added to it—the constraint needs to be re-evaluated. In parsing strategies where the assignments are built dynamically by successive additions of new constituents, the evaluation </context>
</contexts>
<marker>VanRullen, 2005</marker>
<rawString>Tristan VanRullen. 2005. Vers une analyse syntaxique a` granularit´e variable. Ph.D. thesis, Universit´e de Provence, Informatique.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G´erard Verfaillie</author>
<author>Thomas Schiex</author>
</authors>
<title>Solution reuse in dynamic CSPs.</title>
<date>1994</date>
<booktitle>In AAAI ’94: Proc. of the twelfth national conf. on AI</booktitle>
<volume>1</volume>
<pages>307--312</pages>
<publisher>American Ass. for AI.</publisher>
<location>Menlo Park, CA, USA.</location>
<contexts>
<context position="10839" citStr="Verfaillie and Schiex, 1994" startWordPosition="1761" endWordPosition="1764">phrase structure. By extension, a solution to such a problem is called a configuration. A configuration problem can be modelled with a (static) CSP. Dynamic CSP. In our case the problem is actually dynamic, in that the set of constraints to be solved evolves by the addition of new constraints. As we will see it later new constituents are inferred during the parsing process, and subsequently new constraints are dynamically added to the system. When dealing with deep parsing, i.e. with wellformedness only, the problem can be tackled as a Dynamic CSP, and solving techniques such as Local Search (Verfaillie and Schiex, 1994) can be applied. Optimisation problem. In order to account for ill-formedness as well as well-formedness, we need to allow constraint relaxation, which turns the problem into an optimisation one. The expected outcome is thus an optimal configuration with respect to some valuation function. Should the input be well-formed, no constraints are relaxed and the expected outcome is a full parse. Should the input be ill-formed, constraints are relaxed and the expected outcome is either an optimal full parse or a set of (optimal) partial parses. 3 Numbat Architecture 3.1 The Parsing Strategy in Numbat</context>
</contexts>
<marker>Verfaillie, Schiex, 1994</marker>
<rawString>G´erard Verfaillie and Thomas Schiex. 1994. Solution reuse in dynamic CSPs. In AAAI ’94: Proc. of the twelfth national conf. on AI (vol. 1), pages 307–312, Menlo Park, CA, USA. American Ass. for AI.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>