<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007486">
<title confidence="0.996666333333333">
Incremental Hypothesis Alignment with Flexible Matching for Building
Confusion Networks: BBN System Description for WMT09 System
Combination Task
</title>
<note confidence="0.7040965">
Antti-Veikko I. Rosti and Bing Zhang and Spyros Matsoukas and Richard Schwartz
BBN Technologies, 10 Moulton Street, Cambridge, MA 02138
</note>
<email confidence="0.984489">
arosti,bzhang,smatsouk,schwartz @bbn.com
</email>
<sectionHeader confidence="0.993534" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999977894736842">
This paper describes the incremental hy-
pothesis alignment algorithm used in the
BBN submissions to the WMT09 system
combination task. The alignment algo-
rithm used a sentence specific alignment
order, flexible matching, and new shift
heuristics. These refinements yield more
compact confusion networks compared to
using the pair-wise or incremental TER
alignment algorithms. This should reduce
the number of spurious insertions in the
system combination output and the sys-
tem combination weight tuning converges
faster. System combination experiments
on the WMT09 test sets from five source
languages to English are presented. The
best BLEU scores were achieved by comb-
ing the English outputs of three systems
from all five source languages.
</bodyText>
<sectionHeader confidence="0.998986" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999660212765957">
Machine translation (MT) systems have different
strengths and weaknesses which can be exploited
by system combination methods resulting in an
output with a better performance than any indi-
vidual MT system output as measured by auto-
matic evaluation metrics. Confusion network de-
coding has become the most popular approach to
MT system combination. The first confusion net-
work decoding method (Bangalore et al., 2001)
was based on multiple string alignment (MSA)
(Durbin et al., 1988) borrowed from biological
sequence analysis. However, MSA does not al-
low re-ordering. The translation edit rate (TER)
(Snover et al., 2006) produces an alignment be-
tween two strings and allows shifts of blocks of
words. The availability of the TER software has
made it easy to build a high performance system
combination baseline (Rosti et al., 2007).
The pair-wise TER alignment originally de-
scribed by Sim et al. (2007) has various limita-
tions. First, the hypotheses are aligned indepen-
dently against the skeleton which determines the
word order of the output. The same word from
two different hypotheses may be inserted in differ-
ent positions w.r.t. the skeleton and multiple inser-
tions require special handling. Rosti et al. (2008)
described an incremental TER alignment to miti-
gate these problems. The incremental TER align-
ment used a global order in which the hypotheses
were aligned. Second, the TER software matches
words with identical surface strings. The pair-
wise alignment methods proposed by Ayan et al.
(2008), He et al. (2008), and Matusov et al. (2006)
are able to match also synonyms and words with
identical stems. Third, the TER software uses a set
of heuristics which is not always optimal in de-
termining the block shifts. Karakos et al. (2008)
proposed using inversion transduction grammars
to produce different pair-wise alignments.
This paper is organized as follows. A refined
incremental alignment algorithm is described in
Section 2. Experimental evaluation comparing
the pair-wise and incremental TER alignment al-
gorithms with the refined alignment algorithm on
WMT09 system combination task is presented in
Section 3. Conclusions and future work are pre-
sented in Section 4.
</bodyText>
<sectionHeader confidence="0.9968455" genericHeader="method">
2 Incremental Hypothesis Alignment
with Flexible Matching
</sectionHeader>
<subsectionHeader confidence="0.999495">
2.1 Sentence Specific Alignment Order
</subsectionHeader>
<bodyText confidence="0.851089">
Rosti et al. (2008) proposed incremental hypothe-
sis alignment using a system specific order. This
is not likely to be optimal since one MT system
may have better output on one sentence and worse
on another. More principled approach is similar to
MSA where the order is determined by the edit
distance of the hypothesis from the network for
Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 61–65,
Athens, Greece, 30 March – 31 March 2009. c�2009 Association for Computational Linguistics
</bodyText>
<page confidence="0.992304">
61
</page>
<figure confidence="0.99940940625">
NULL
vegetables
jefferson
edison
8
NULL
thomas
cereal
NULL
2
3
17
NULL
NULL(6.2e-7)
1
says eat your
4 5 6 7
0
NULL(0.9999)
NULL
cereal 12
9 eat 10 your 11
NULL
edison
thomas 14
13
jefferson
vegetables
says 16
15
(a) Alignment using the standard TER shift heuristics.
(b) Alignment using the modified shift heuristics.
</figure>
<figureCaption confidence="0.970308">
Figure 1: Combined confusion networks using different shift heuristics. The initial NULL arcs include
the prior probability estimates in parentheses.
</figureCaption>
<figure confidence="0.987227043478261">
NULL(0.5)
1
thomas
2
jefferson
edison
3
says eat your
4 5 6
vegetables
cereal 7 NULL
0
NULL(0.5)
NULL
15
eat your cereal
8 9 10 11
vegetables
thomas edison
12 13
jefferson
says
14
</figure>
<bodyText confidence="0.983907166666667">
each sentence. The TER scores of the remaining
unaligned hypotheses using the current network as
the reference are computed. The hypothesis with
the lowest edit cost w.r.t. the network is aligned.
Given systems, this increases the number of
alignments performed from to .
</bodyText>
<subsectionHeader confidence="0.997096">
2.2 Flexible Matching
</subsectionHeader>
<bodyText confidence="0.9999824375">
The TER software assigns a zero cost for match-
ing tokens and a cost of one for all errors includ-
ing insertions, deletions, substitutions, and block
shifts. Ayan et al. (2008) modified the TER soft-
ware to consider substitutions of synonyms with
a reduced cost. Recently, Snover et al. (2009)
extended the TER algorithm in a similar fashion
to produce a new evaluation metric, TER plus
(TERp), which allows tuning of the edit costs in
order to maximize correlation with human judg-
ment. The incremental alignment with flexible
matching uses WordNet (Fellbaum, 1998) to find
all possible synonyms and words with identical
stems in a set of hypotheses. Substitutions involv-
ing synonyms and words with identical stems are
considered with a reduced cost of 0.2.
</bodyText>
<subsectionHeader confidence="0.998669">
2.3 Modified Shift Heuristics
</subsectionHeader>
<bodyText confidence="0.998660875">
The TER is computed by trying shifts of blocks of
words that have an exact match somewhere else in
the reference in order to find a re-ordering of the
hypothesis with a lower edit distance to the refer-
ence. Karakos et al. (2008) showed that the shift
heuristics in TER do not always yield an optimal
alignment. Their example used the following two
hypotheses:
</bodyText>
<listItem confidence="0.9705325">
1. thomas jefferson says eat your vegetables
2. eat your cereal thomas edison says
</listItem>
<bodyText confidence="0.9998958">
A system combination lattice using TER align-
ment is shown in Figure 1(a). The blocks
“eat your” are shifted when building both con-
fusion networks. Using the second hypothe-
sis as the skeleton seems to give a better align-
ment. The lower number of edits also results in a
higher skeleton prior shown between nodes 0 and
9. There are obviously some undesirable paths
through the lattice but it is likely that a language
model will give a higher score to the reasonable
hypotheses.
Since the flexible matching allows substitutions
with a reduced cost, the standard TER shift heuris-
tics have to be modified. A block of words may
have some words with identical matches and other
words with synonym matches. In TERp, synonym
and stem matches are considered as exact matches
for the block shifts, otherwise the TER shift con-
straints are used. In the flexible matching, the shift
heuristics were modified to allow any block shifts
</bodyText>
<page confidence="0.99632">
62
</page>
<bodyText confidence="0.9999117">
that do not increase the edit cost. A system combi-
nation lattice using the modified shift heuristics is
shown in Figure 1(b). The optimal shifts of blocks
“eat your cereal” and “eat your vegetables” were
found and both networks received equal skeleton
priors. TERp would yield this alignment only
if these blocks appear in the paraphrase table or
if “cereal” and “vegetables” are considered syn-
onyms. This example is artificial and does not
guarantee that optimal shifts are always found.
</bodyText>
<sectionHeader confidence="0.998452" genericHeader="method">
3 Experimental Evaluation
</sectionHeader>
<bodyText confidence="0.99986416">
System combination experiments combining the
English WMT09 translation task outputs were per-
formed. A total of 96 English outputs were pro-
vided including primary, contrastive, and -best
outputs. Only the primary -best outputs were
combined due to time constraints. The numbers
of primary systems per source language were: 3
for Czech, 15 for German, 9 for Spanish, 15 for
French, and 3 for Hungarian. The English bigram
and 5-gram language models were interpolated
from four LM components trained on the English
monolingual Europarl (45M tokens) and News
(510M tokens) corpora, and the English sides of
the News Commentary (2M tokens) and Giga-
FrEn (683M tokens) parallel corpora. The interpo-
lation weights were tuned to minimize perplexity
on news-dev2009 set. The system combination
weights – one for each system, LM weight, and
word and NULL insertion penalties – were tuned
to maximize the BLEU (Papineni et al., 2002)
score on the tuning set (newssyscomb2009).
Since the system combination was performed on
tokenized and lower cased outputs, a trigram-
based true caser was trained on all News training
data. The tuning may be summarized as follows:
</bodyText>
<listItem confidence="0.928016454545455">
1. Tokenize and lower case the outputs;
2. Align hypotheses incrementally using each
output as a skeleton;
3. Join the confusion networks into a lattice
with skeleton specific prior estimates;
7. Iterate 4-6 three times;
8. Extract a -best list from the lattice given
the best decoding weights and re-score hy-
potheses with a 5-gram;
9. Tune re-scoring weights given the final -
best list;
</listItem>
<bodyText confidence="0.974692860465116">
10. Extract -best hypotheses from the -best
list given the best re-scoring weights, re-case,
and detokenize.
After tuning the system combination weights, the
outputs on a test set may be combined using the
same steps excluding 4-7 and 9. The hypothesis
scores and tuning are identical to the setup used in
(Rosti et al., 2007).
Case insensitive TER and BLEU scores for the
combination outputs using the pair-wise and in-
cremental TER alignment as well as the flexible
alignment on the tuning (dev) and test sets are
shown in Table 1. Only case insensitive scores
are reported since the re-casers used by different
systems are very different and some are trained
using larger resources than provided for WMT09.
The scores of the worst and best individual sys-
tem outputs are also shown. The best and worst
TER and BLEU scores are not necessarily from
the same system output. Both incremental
and flexible alignments used sentence spe-
cific alignment order. Combinations using the in-
cremental and flexible hypothesis alignment algo-
rithms consistently outperform the ones using the
pair-wise TER alignment. The flexible alignment
is slightly better than the incremental alignment on
Czech, Spanish, and Hungarian, and significantly
better on French to English test set scores.
Since the test sets for each language pair consist
of translations of the same documents, it is pos-
sible to combine outputs from many source lan-
guages to English. There were a total of 46 En-
glish primary -best system outputs. Using all 46
outputs would have required too much memory in
tuning, so a subset of 11 outputs was chosen. The
11 outputs consist of google, uedin, and uka
outputs on all languages. Case insensitive TER
and BLEU scores for the xx-en combination are
shown in Table 2. In addition to incremental
and flexible alignment methods which used
sentence specific alignment order, scores for in-
cremental TER alignment with a fixed alignment
order used in the BBN submissions to WMT08
</bodyText>
<footnote confidence="0.978666">
4. Extract a -best list from the lattice given
the current weights;
5. Merge the -best list with the hypotheses
from the previous iteration;
6. Tune new weights given the current merged
-best list;
</footnote>
<page confidence="0.99732">
63
</page>
<table confidence="0.998001">
dev cz-en de-en es-en
System TER BLEU TER BLEU TER BLEU
worst 67.30 17.63 82.01 6.83 65.64 19.74
best 58.16 23.12 57.24 23.20 53.02 29.48
pairwise 59.60 24.01 56.35 26.04 53.11 29.49
incremental 59.22 24.31 55.73 26.73 53.05 29.72
flexible 59.38 24.18 55.51 26.71 52.62 30.24
test cz-en de-en es-en
System TER BLEU TER BLEU TER BLEU
worst 67.74 16.37 82.39 6.81 65.44 19.04
best 59.53 21.18 59.41 21.30 53.34 28.69
pairwise 61.02 21.25 58.75 23.41 53.65 28.15
incremental 60.63 21.67 58.13 23.96 53.47 28.38
flexible 60.34 21.87 58.05 23.86 53.13 28.57
fr-en hu-en
TER BLEU TER BLEU
69.19 15.21 78.70 10.33
49.78 32.27 66.77 13.59
51.03 31.65 69.58 14.60
50.72 32.09 70.15 14.85
50.22 32.58 69.83 14.88
fr-en hu-en
TER BLEU TER BLEU
71.44 14.49 81.21 9.90
51.33 31.14 68.32 12.75
53.17 29.83 71.50 13.39
52.51 30.45 71.69 13.60
51.98 31.30 71.17 13.84
</table>
<tableCaption confidence="0.942463">
Table 1: Case insensitive TER and BLEU scores on newssyscomb2009 (dev) and newstest2009
(test) for five source languages.
</tableCaption>
<bodyText confidence="0.99332065625">
(Rosti et al., 2008) are marked as incr-wmt08.
The sentence specific alignment order yields about
a half BLEU point gain on the tuning set and a
one BLEU point gain on the test set. All system
combination experiments yield very good BLEU
gains on both sets. The scores are also signifi-
cantly higher than any combination from a single
source language. This shows that the outputs from
different source languages are likely to be more di-
verse than outputs from different MT systems on a
single language pair. The combination is not guar-
anteed to be the best possible as the set of outputs
was chosen arbitrarily.
The compactness of the confusion networks
may be measured by the average number of
nodes and arcs per segment. All xx-en con-
fusion networks for newssyscomb2009 and
newstest2009 after the incremental TER
alignment had on average 44.5 nodes and 112.7
arcs per segment. After the flexible hypothesis
alignment, there were on average 41.1 nodes and
104.6 arcs per segment. The number of NULL
word arcs may also be indicative of the alignment
quality. The flexible hypothesis alignment reduced
the average number of NULL word arcs from 29.0
to 24.8 per segment. The rate of convergence in
the -best list based iterative tuning may be mon-
itored by the number of new hypotheses in the
merged -best lists from iteration to iteration. By
the third tuning iteration, there were 10% fewer
new hypotheses in the merged -best list when
using the flexible hypothesis alignment.
</bodyText>
<table confidence="0.842262375">
xx-en TER dev TER test
System BLEU BLEU
worst 74.21 12.80 75.84 12.05
best 49.78 32.27 51.33 31.14
pairwise 46.10 35.95 47.77 33.53
incr-wmt08 44.58 36.84 46.60 33.61
incremental 44.59 37.30 46.42 34.61
flexible 44.54 37.38 45.82 34.48
</table>
<tableCaption confidence="0.899756666666667">
Table 2: Case insensitive TER and BLEU
scores on newssyscomb2009 (dev) and
newstest2009 (test) for xx-en combination.
</tableCaption>
<sectionHeader confidence="0.998948" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999823">
This paper described a refined incremental hy-
pothesis alignment algorithm used in the BBN
submissions to the WMT09 system combination
task. The new features included sentence specific
alignment order, flexible matching, and modified
shift heuristics. The refinements yield more com-
pact confusion networks which should allow fewer
spurious insertions in the output and faster conver-
gence in tuning. The future work will investigate
tunable edit costs and methods to choose an opti-
mal subset of outputs for combination.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997555">
This work was supported by DARPA/IPTO Con-
tract No. HR0011-06-C-0022 under the GALE
program.
</bodyText>
<page confidence="0.999128">
64
</page>
<sectionHeader confidence="0.976645" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.981096567164179">
Necip Fazil Ayan, Jing Zheng, and Wen Wang. 2008.
Improving alignments for better confusion networks
for combining machine translation systems. In Pro-
ceedings of the 22nd International Conference on
Computational Linguistics (Coling 2008), pages 33–
40.
Srinivas Bangalore, German Bordel, and Giuseppe Ric-
cardi. 2001. Computing consensus translation from
multiple machine translation systems. In Proceed-
ings of the Automatic Speech Recognition and Un-
derstanding Workshop (ASRU), pages 351–354.
Richard Durbin, Sean R. Eddy, Anders Krogh, and
Graeme Mitchison. 1988. Biological Sequence
Analysis: Probabilistic Models of Proteins and Nu-
cleic Acids. Cambridge University Press.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press.
Xiaodong He, Mei Yang, Jianfeng Gao, Patrick
Nguyen, and Robert Moore. 2008. Indirect-HMM-
based hypothesis alignment for combining outputs
from machine translation systems. In Proceedings
of the 2008 Conference on Empirical Methods in
Natural Language Processing, pages 98–107.
Damianos Karakos, Jason Eisner, Sanjeev Khundan-
pur, and Markus Dreyer. 2008. Machine trans-
lation system combination using ITG-based align-
ments. In Proceedings of ACL-08: HLT, pages 81–
84.
Evgeny Matusov, Nicola Ueffing, and Hermann Ney.
2006. Computing consensus translation from multi-
ple machine translation systems using enhanced hy-
potheses alignment. In Proceedings of the 11th Con-
ference of the European Chapter of the Association
for Computational Linguistics, pages 33–40.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings
of the 40th Annual Meeting of the Association for
Computational Linguistics, pages 311–318.
Antti-Veikko I. Rosti, Spyros Matsoukas, and Richard
Schwartz. 2007. Improved word-level system com-
bination for machine translation. In Proceedings of
the 45th Annual Meeting of the Association of Com-
putational Linguistics, pages 312–319.
Antti-Veikko I. Rosti, Bing Zhang, Spyros Matsoukas,
and Richard Schwartz. 2008. Incremental hypothe-
sis alignment for building confusion networks with
application to machine translation system combina-
tion. In Proceedings of the Third Workshop on Sta-
tistical Machine Translation, pages 183–186.
Khe Chai Sim, William J. Byrne, Mark J.F. Gales,
Hichem Sahbi, and Phil C. Woodland. 2007. Con-
sensus network decoding for statistical machine
translation system combination. In Proceedings of
the 32nd IEEE International Conference on Acous-
tics, Speech, and Signal Processing, pages 105–108.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciula, and John Makhoul. 2006. A study of
translation edit rate with targeted human annotation.
In Proceedings of the 7th Conference of the Associa-
tion for Machine Translation in the Americas, pages
223–231.
Matthew Snover, Nitin Madnani, Bonnie Dorr, and
Richard Schwartz. 2009. Fluency, adequacy, or
HTER? Exploring different human judgments with
a tunable MT metric. In Proceedings of the Fourth
Workshop on Statistical Machine Translation.
</reference>
<page confidence="0.999607">
65
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.940894">
<title confidence="0.996352666666667">Incremental Hypothesis Alignment with Flexible Matching for Confusion Networks: BBN System Description for WMT09 Combination Task</title>
<author confidence="0.997809">Antti-Veikko I Rosti</author>
<author confidence="0.997809">Bing Zhang</author>
<author confidence="0.997809">Spyros Matsoukas</author>
<author confidence="0.997809">Richard Schwartz</author>
<address confidence="0.962253">BBN Technologies, 10 Moulton Street, Cambridge, MA 02138</address>
<email confidence="0.994203">arosti,bzhang,smatsouk,schwartz@bbn.com</email>
<abstract confidence="0.9996924">This paper describes the incremental hypothesis alignment algorithm used in the BBN submissions to the WMT09 system combination task. The alignment algorithm used a sentence specific alignment order, flexible matching, and new shift heuristics. These refinements yield more compact confusion networks compared to using the pair-wise or incremental TER alignment algorithms. This should reduce the number of spurious insertions in the system combination output and the system combination weight tuning converges faster. System combination experiments on the WMT09 test sets from five source languages to English are presented. The best BLEU scores were achieved by combing the English outputs of three systems from all five source languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Necip Fazil Ayan</author>
<author>Jing Zheng</author>
<author>Wen Wang</author>
</authors>
<title>Improving alignments for better confusion networks for combining machine translation systems.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (Coling</booktitle>
<pages>33--40</pages>
<contexts>
<context position="2593" citStr="Ayan et al. (2008)" startWordPosition="390" endWordPosition="393">im et al. (2007) has various limitations. First, the hypotheses are aligned independently against the skeleton which determines the word order of the output. The same word from two different hypotheses may be inserted in different positions w.r.t. the skeleton and multiple insertions require special handling. Rosti et al. (2008) described an incremental TER alignment to mitigate these problems. The incremental TER alignment used a global order in which the hypotheses were aligned. Second, the TER software matches words with identical surface strings. The pairwise alignment methods proposed by Ayan et al. (2008), He et al. (2008), and Matusov et al. (2006) are able to match also synonyms and words with identical stems. Third, the TER software uses a set of heuristics which is not always optimal in determining the block shifts. Karakos et al. (2008) proposed using inversion transduction grammars to produce different pair-wise alignments. This paper is organized as follows. A refined incremental alignment algorithm is described in Section 2. Experimental evaluation comparing the pair-wise and incremental TER alignment algorithms with the refined alignment algorithm on WMT09 system combination task is p</context>
<context position="5003" citStr="Ayan et al. (2008)" startWordPosition="783" endWordPosition="786"> edison 3 says eat your 4 5 6 vegetables cereal 7 NULL 0 NULL(0.5) NULL 15 eat your cereal 8 9 10 11 vegetables thomas edison 12 13 jefferson says 14 each sentence. The TER scores of the remaining unaligned hypotheses using the current network as the reference are computed. The hypothesis with the lowest edit cost w.r.t. the network is aligned. Given systems, this increases the number of alignments performed from to . 2.2 Flexible Matching The TER software assigns a zero cost for matching tokens and a cost of one for all errors including insertions, deletions, substitutions, and block shifts. Ayan et al. (2008) modified the TER software to consider substitutions of synonyms with a reduced cost. Recently, Snover et al. (2009) extended the TER algorithm in a similar fashion to produce a new evaluation metric, TER plus (TERp), which allows tuning of the edit costs in order to maximize correlation with human judgment. The incremental alignment with flexible matching uses WordNet (Fellbaum, 1998) to find all possible synonyms and words with identical stems in a set of hypotheses. Substitutions involving synonyms and words with identical stems are considered with a reduced cost of 0.2. 2.3 Modified Shift </context>
</contexts>
<marker>Ayan, Zheng, Wang, 2008</marker>
<rawString>Necip Fazil Ayan, Jing Zheng, and Wen Wang. 2008. Improving alignments for better confusion networks for combining machine translation systems. In Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 33– 40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>German Bordel</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Computing consensus translation from multiple machine translation systems.</title>
<date>2001</date>
<booktitle>In Proceedings of the Automatic Speech Recognition and Understanding Workshop (ASRU),</booktitle>
<pages>351--354</pages>
<contexts>
<context position="1503" citStr="Bangalore et al., 2001" startWordPosition="214" endWordPosition="217">s on the WMT09 test sets from five source languages to English are presented. The best BLEU scores were achieved by combing the English outputs of three systems from all five source languages. 1 Introduction Machine translation (MT) systems have different strengths and weaknesses which can be exploited by system combination methods resulting in an output with a better performance than any individual MT system output as measured by automatic evaluation metrics. Confusion network decoding has become the most popular approach to MT system combination. The first confusion network decoding method (Bangalore et al., 2001) was based on multiple string alignment (MSA) (Durbin et al., 1988) borrowed from biological sequence analysis. However, MSA does not allow re-ordering. The translation edit rate (TER) (Snover et al., 2006) produces an alignment between two strings and allows shifts of blocks of words. The availability of the TER software has made it easy to build a high performance system combination baseline (Rosti et al., 2007). The pair-wise TER alignment originally described by Sim et al. (2007) has various limitations. First, the hypotheses are aligned independently against the skeleton which determines </context>
</contexts>
<marker>Bangalore, Bordel, Riccardi, 2001</marker>
<rawString>Srinivas Bangalore, German Bordel, and Giuseppe Riccardi. 2001. Computing consensus translation from multiple machine translation systems. In Proceedings of the Automatic Speech Recognition and Understanding Workshop (ASRU), pages 351–354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Durbin</author>
<author>Sean R Eddy</author>
<author>Anders Krogh</author>
<author>Graeme Mitchison</author>
</authors>
<title>Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids.</title>
<date>1988</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1570" citStr="Durbin et al., 1988" startWordPosition="225" endWordPosition="228">sented. The best BLEU scores were achieved by combing the English outputs of three systems from all five source languages. 1 Introduction Machine translation (MT) systems have different strengths and weaknesses which can be exploited by system combination methods resulting in an output with a better performance than any individual MT system output as measured by automatic evaluation metrics. Confusion network decoding has become the most popular approach to MT system combination. The first confusion network decoding method (Bangalore et al., 2001) was based on multiple string alignment (MSA) (Durbin et al., 1988) borrowed from biological sequence analysis. However, MSA does not allow re-ordering. The translation edit rate (TER) (Snover et al., 2006) produces an alignment between two strings and allows shifts of blocks of words. The availability of the TER software has made it easy to build a high performance system combination baseline (Rosti et al., 2007). The pair-wise TER alignment originally described by Sim et al. (2007) has various limitations. First, the hypotheses are aligned independently against the skeleton which determines the word order of the output. The same word from two different hypo</context>
</contexts>
<marker>Durbin, Eddy, Krogh, Mitchison, 1988</marker>
<rawString>Richard Durbin, Sean R. Eddy, Anders Krogh, and Graeme Mitchison. 1988. Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaodong He</author>
<author>Mei Yang</author>
<author>Jianfeng Gao</author>
<author>Patrick Nguyen</author>
<author>Robert Moore</author>
</authors>
<title>Indirect-HMMbased hypothesis alignment for combining outputs from machine translation systems.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>98--107</pages>
<contexts>
<context position="2611" citStr="He et al. (2008)" startWordPosition="394" endWordPosition="397"> various limitations. First, the hypotheses are aligned independently against the skeleton which determines the word order of the output. The same word from two different hypotheses may be inserted in different positions w.r.t. the skeleton and multiple insertions require special handling. Rosti et al. (2008) described an incremental TER alignment to mitigate these problems. The incremental TER alignment used a global order in which the hypotheses were aligned. Second, the TER software matches words with identical surface strings. The pairwise alignment methods proposed by Ayan et al. (2008), He et al. (2008), and Matusov et al. (2006) are able to match also synonyms and words with identical stems. Third, the TER software uses a set of heuristics which is not always optimal in determining the block shifts. Karakos et al. (2008) proposed using inversion transduction grammars to produce different pair-wise alignments. This paper is organized as follows. A refined incremental alignment algorithm is described in Section 2. Experimental evaluation comparing the pair-wise and incremental TER alignment algorithms with the refined alignment algorithm on WMT09 system combination task is presented in Sectio</context>
</contexts>
<marker>He, Yang, Gao, Nguyen, Moore, 2008</marker>
<rawString>Xiaodong He, Mei Yang, Jianfeng Gao, Patrick Nguyen, and Robert Moore. 2008. Indirect-HMMbased hypothesis alignment for combining outputs from machine translation systems. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 98–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Damianos Karakos</author>
<author>Jason Eisner</author>
<author>Sanjeev Khundanpur</author>
<author>Markus Dreyer</author>
</authors>
<title>Machine translation system combination using ITG-based alignments.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>81--84</pages>
<contexts>
<context position="2834" citStr="Karakos et al. (2008)" startWordPosition="434" endWordPosition="437">ns w.r.t. the skeleton and multiple insertions require special handling. Rosti et al. (2008) described an incremental TER alignment to mitigate these problems. The incremental TER alignment used a global order in which the hypotheses were aligned. Second, the TER software matches words with identical surface strings. The pairwise alignment methods proposed by Ayan et al. (2008), He et al. (2008), and Matusov et al. (2006) are able to match also synonyms and words with identical stems. Third, the TER software uses a set of heuristics which is not always optimal in determining the block shifts. Karakos et al. (2008) proposed using inversion transduction grammars to produce different pair-wise alignments. This paper is organized as follows. A refined incremental alignment algorithm is described in Section 2. Experimental evaluation comparing the pair-wise and incremental TER alignment algorithms with the refined alignment algorithm on WMT09 system combination task is presented in Section 3. Conclusions and future work are presented in Section 4. 2 Incremental Hypothesis Alignment with Flexible Matching 2.1 Sentence Specific Alignment Order Rosti et al. (2008) proposed incremental hypothesis alignment usin</context>
<context position="5842" citStr="Karakos et al. (2008)" startWordPosition="924" endWordPosition="927">which allows tuning of the edit costs in order to maximize correlation with human judgment. The incremental alignment with flexible matching uses WordNet (Fellbaum, 1998) to find all possible synonyms and words with identical stems in a set of hypotheses. Substitutions involving synonyms and words with identical stems are considered with a reduced cost of 0.2. 2.3 Modified Shift Heuristics The TER is computed by trying shifts of blocks of words that have an exact match somewhere else in the reference in order to find a re-ordering of the hypothesis with a lower edit distance to the reference. Karakos et al. (2008) showed that the shift heuristics in TER do not always yield an optimal alignment. Their example used the following two hypotheses: 1. thomas jefferson says eat your vegetables 2. eat your cereal thomas edison says A system combination lattice using TER alignment is shown in Figure 1(a). The blocks “eat your” are shifted when building both confusion networks. Using the second hypothesis as the skeleton seems to give a better alignment. The lower number of edits also results in a higher skeleton prior shown between nodes 0 and 9. There are obviously some undesirable paths through the lattice bu</context>
</contexts>
<marker>Karakos, Eisner, Khundanpur, Dreyer, 2008</marker>
<rawString>Damianos Karakos, Jason Eisner, Sanjeev Khundanpur, and Markus Dreyer. 2008. Machine translation system combination using ITG-based alignments. In Proceedings of ACL-08: HLT, pages 81– 84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeny Matusov</author>
<author>Nicola Ueffing</author>
<author>Hermann Ney</author>
</authors>
<title>Computing consensus translation from multiple machine translation systems using enhanced hypotheses alignment.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>33--40</pages>
<contexts>
<context position="2638" citStr="Matusov et al. (2006)" startWordPosition="399" endWordPosition="402">First, the hypotheses are aligned independently against the skeleton which determines the word order of the output. The same word from two different hypotheses may be inserted in different positions w.r.t. the skeleton and multiple insertions require special handling. Rosti et al. (2008) described an incremental TER alignment to mitigate these problems. The incremental TER alignment used a global order in which the hypotheses were aligned. Second, the TER software matches words with identical surface strings. The pairwise alignment methods proposed by Ayan et al. (2008), He et al. (2008), and Matusov et al. (2006) are able to match also synonyms and words with identical stems. Third, the TER software uses a set of heuristics which is not always optimal in determining the block shifts. Karakos et al. (2008) proposed using inversion transduction grammars to produce different pair-wise alignments. This paper is organized as follows. A refined incremental alignment algorithm is described in Section 2. Experimental evaluation comparing the pair-wise and incremental TER alignment algorithms with the refined alignment algorithm on WMT09 system combination task is presented in Section 3. Conclusions and future</context>
</contexts>
<marker>Matusov, Ueffing, Ney, 2006</marker>
<rawString>Evgeny Matusov, Nicola Ueffing, and Hermann Ney. 2006. Computing consensus translation from multiple machine translation systems using enhanced hypotheses alignment. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, pages 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="8417" citStr="Papineni et al., 2002" startWordPosition="1348" endWordPosition="1351"> source language were: 3 for Czech, 15 for German, 9 for Spanish, 15 for French, and 3 for Hungarian. The English bigram and 5-gram language models were interpolated from four LM components trained on the English monolingual Europarl (45M tokens) and News (510M tokens) corpora, and the English sides of the News Commentary (2M tokens) and GigaFrEn (683M tokens) parallel corpora. The interpolation weights were tuned to minimize perplexity on news-dev2009 set. The system combination weights – one for each system, LM weight, and word and NULL insertion penalties – were tuned to maximize the BLEU (Papineni et al., 2002) score on the tuning set (newssyscomb2009). Since the system combination was performed on tokenized and lower cased outputs, a trigrambased true caser was trained on all News training data. The tuning may be summarized as follows: 1. Tokenize and lower case the outputs; 2. Align hypotheses incrementally using each output as a skeleton; 3. Join the confusion networks into a lattice with skeleton specific prior estimates; 7. Iterate 4-6 three times; 8. Extract a -best list from the lattice given the best decoding weights and re-score hypotheses with a 5-gram; 9. Tune re-scoring weights given the</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antti-Veikko I Rosti</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
</authors>
<title>Improved word-level system combination for machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>312--319</pages>
<contexts>
<context position="1920" citStr="Rosti et al., 2007" startWordPosition="282" endWordPosition="285">s measured by automatic evaluation metrics. Confusion network decoding has become the most popular approach to MT system combination. The first confusion network decoding method (Bangalore et al., 2001) was based on multiple string alignment (MSA) (Durbin et al., 1988) borrowed from biological sequence analysis. However, MSA does not allow re-ordering. The translation edit rate (TER) (Snover et al., 2006) produces an alignment between two strings and allows shifts of blocks of words. The availability of the TER software has made it easy to build a high performance system combination baseline (Rosti et al., 2007). The pair-wise TER alignment originally described by Sim et al. (2007) has various limitations. First, the hypotheses are aligned independently against the skeleton which determines the word order of the output. The same word from two different hypotheses may be inserted in different positions w.r.t. the skeleton and multiple insertions require special handling. Rosti et al. (2008) described an incremental TER alignment to mitigate these problems. The incremental TER alignment used a global order in which the hypotheses were aligned. Second, the TER software matches words with identical surfa</context>
<context position="9363" citStr="Rosti et al., 2007" startWordPosition="1505" endWordPosition="1508"> skeleton; 3. Join the confusion networks into a lattice with skeleton specific prior estimates; 7. Iterate 4-6 three times; 8. Extract a -best list from the lattice given the best decoding weights and re-score hypotheses with a 5-gram; 9. Tune re-scoring weights given the final - best list; 10. Extract -best hypotheses from the -best list given the best re-scoring weights, re-case, and detokenize. After tuning the system combination weights, the outputs on a test set may be combined using the same steps excluding 4-7 and 9. The hypothesis scores and tuning are identical to the setup used in (Rosti et al., 2007). Case insensitive TER and BLEU scores for the combination outputs using the pair-wise and incremental TER alignment as well as the flexible alignment on the tuning (dev) and test sets are shown in Table 1. Only case insensitive scores are reported since the re-casers used by different systems are very different and some are trained using larger resources than provided for WMT09. The scores of the worst and best individual system outputs are also shown. The best and worst TER and BLEU scores are not necessarily from the same system output. Both incremental and flexible alignments used sentence</context>
</contexts>
<marker>Rosti, Matsoukas, Schwartz, 2007</marker>
<rawString>Antti-Veikko I. Rosti, Spyros Matsoukas, and Richard Schwartz. 2007. Improved word-level system combination for machine translation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 312–319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antti-Veikko I Rosti</author>
<author>Bing Zhang</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
</authors>
<title>Incremental hypothesis alignment for building confusion networks with application to machine translation system combination.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>183--186</pages>
<contexts>
<context position="2305" citStr="Rosti et al. (2008)" startWordPosition="344" endWordPosition="347">) (Snover et al., 2006) produces an alignment between two strings and allows shifts of blocks of words. The availability of the TER software has made it easy to build a high performance system combination baseline (Rosti et al., 2007). The pair-wise TER alignment originally described by Sim et al. (2007) has various limitations. First, the hypotheses are aligned independently against the skeleton which determines the word order of the output. The same word from two different hypotheses may be inserted in different positions w.r.t. the skeleton and multiple insertions require special handling. Rosti et al. (2008) described an incremental TER alignment to mitigate these problems. The incremental TER alignment used a global order in which the hypotheses were aligned. Second, the TER software matches words with identical surface strings. The pairwise alignment methods proposed by Ayan et al. (2008), He et al. (2008), and Matusov et al. (2006) are able to match also synonyms and words with identical stems. Third, the TER software uses a set of heuristics which is not always optimal in determining the block shifts. Karakos et al. (2008) proposed using inversion transduction grammars to produce different pa</context>
<context position="12202" citStr="Rosti et al., 2008" startWordPosition="1976" endWordPosition="1979">est 59.53 21.18 59.41 21.30 53.34 28.69 pairwise 61.02 21.25 58.75 23.41 53.65 28.15 incremental 60.63 21.67 58.13 23.96 53.47 28.38 flexible 60.34 21.87 58.05 23.86 53.13 28.57 fr-en hu-en TER BLEU TER BLEU 69.19 15.21 78.70 10.33 49.78 32.27 66.77 13.59 51.03 31.65 69.58 14.60 50.72 32.09 70.15 14.85 50.22 32.58 69.83 14.88 fr-en hu-en TER BLEU TER BLEU 71.44 14.49 81.21 9.90 51.33 31.14 68.32 12.75 53.17 29.83 71.50 13.39 52.51 30.45 71.69 13.60 51.98 31.30 71.17 13.84 Table 1: Case insensitive TER and BLEU scores on newssyscomb2009 (dev) and newstest2009 (test) for five source languages. (Rosti et al., 2008) are marked as incr-wmt08. The sentence specific alignment order yields about a half BLEU point gain on the tuning set and a one BLEU point gain on the test set. All system combination experiments yield very good BLEU gains on both sets. The scores are also significantly higher than any combination from a single source language. This shows that the outputs from different source languages are likely to be more diverse than outputs from different MT systems on a single language pair. The combination is not guaranteed to be the best possible as the set of outputs was chosen arbitrarily. The compa</context>
</contexts>
<marker>Rosti, Zhang, Matsoukas, Schwartz, 2008</marker>
<rawString>Antti-Veikko I. Rosti, Bing Zhang, Spyros Matsoukas, and Richard Schwartz. 2008. Incremental hypothesis alignment for building confusion networks with application to machine translation system combination. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 183–186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Khe Chai Sim</author>
<author>William J Byrne</author>
<author>Mark J F Gales</author>
<author>Hichem Sahbi</author>
<author>Phil C Woodland</author>
</authors>
<title>Consensus network decoding for statistical machine translation system combination.</title>
<date>2007</date>
<booktitle>In Proceedings of the 32nd IEEE International Conference on Acoustics, Speech, and Signal Processing,</booktitle>
<pages>105--108</pages>
<contexts>
<context position="1991" citStr="Sim et al. (2007)" startWordPosition="294" endWordPosition="297">s become the most popular approach to MT system combination. The first confusion network decoding method (Bangalore et al., 2001) was based on multiple string alignment (MSA) (Durbin et al., 1988) borrowed from biological sequence analysis. However, MSA does not allow re-ordering. The translation edit rate (TER) (Snover et al., 2006) produces an alignment between two strings and allows shifts of blocks of words. The availability of the TER software has made it easy to build a high performance system combination baseline (Rosti et al., 2007). The pair-wise TER alignment originally described by Sim et al. (2007) has various limitations. First, the hypotheses are aligned independently against the skeleton which determines the word order of the output. The same word from two different hypotheses may be inserted in different positions w.r.t. the skeleton and multiple insertions require special handling. Rosti et al. (2008) described an incremental TER alignment to mitigate these problems. The incremental TER alignment used a global order in which the hypotheses were aligned. Second, the TER software matches words with identical surface strings. The pairwise alignment methods proposed by Ayan et al. (200</context>
</contexts>
<marker>Sim, Byrne, Gales, Sahbi, Woodland, 2007</marker>
<rawString>Khe Chai Sim, William J. Byrne, Mark J.F. Gales, Hichem Sahbi, and Phil C. Woodland. 2007. Consensus network decoding for statistical machine translation system combination. In Proceedings of the 32nd IEEE International Conference on Acoustics, Speech, and Signal Processing, pages 105–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciula</author>
<author>John Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas,</booktitle>
<pages>223--231</pages>
<contexts>
<context position="1709" citStr="Snover et al., 2006" startWordPosition="246" endWordPosition="249">achine translation (MT) systems have different strengths and weaknesses which can be exploited by system combination methods resulting in an output with a better performance than any individual MT system output as measured by automatic evaluation metrics. Confusion network decoding has become the most popular approach to MT system combination. The first confusion network decoding method (Bangalore et al., 2001) was based on multiple string alignment (MSA) (Durbin et al., 1988) borrowed from biological sequence analysis. However, MSA does not allow re-ordering. The translation edit rate (TER) (Snover et al., 2006) produces an alignment between two strings and allows shifts of blocks of words. The availability of the TER software has made it easy to build a high performance system combination baseline (Rosti et al., 2007). The pair-wise TER alignment originally described by Sim et al. (2007) has various limitations. First, the hypotheses are aligned independently against the skeleton which determines the word order of the output. The same word from two different hypotheses may be inserted in different positions w.r.t. the skeleton and multiple insertions require special handling. Rosti et al. (2008) des</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciula, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciula, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas, pages 223–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Nitin Madnani</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
</authors>
<title>Fluency, adequacy, or HTER? Exploring different human judgments with a tunable MT metric.</title>
<date>2009</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Machine Translation.</booktitle>
<contexts>
<context position="5119" citStr="Snover et al. (2009)" startWordPosition="802" endWordPosition="805">omas edison 12 13 jefferson says 14 each sentence. The TER scores of the remaining unaligned hypotheses using the current network as the reference are computed. The hypothesis with the lowest edit cost w.r.t. the network is aligned. Given systems, this increases the number of alignments performed from to . 2.2 Flexible Matching The TER software assigns a zero cost for matching tokens and a cost of one for all errors including insertions, deletions, substitutions, and block shifts. Ayan et al. (2008) modified the TER software to consider substitutions of synonyms with a reduced cost. Recently, Snover et al. (2009) extended the TER algorithm in a similar fashion to produce a new evaluation metric, TER plus (TERp), which allows tuning of the edit costs in order to maximize correlation with human judgment. The incremental alignment with flexible matching uses WordNet (Fellbaum, 1998) to find all possible synonyms and words with identical stems in a set of hypotheses. Substitutions involving synonyms and words with identical stems are considered with a reduced cost of 0.2. 2.3 Modified Shift Heuristics The TER is computed by trying shifts of blocks of words that have an exact match somewhere else in the re</context>
</contexts>
<marker>Snover, Madnani, Dorr, Schwartz, 2009</marker>
<rawString>Matthew Snover, Nitin Madnani, Bonnie Dorr, and Richard Schwartz. 2009. Fluency, adequacy, or HTER? Exploring different human judgments with a tunable MT metric. In Proceedings of the Fourth Workshop on Statistical Machine Translation.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>