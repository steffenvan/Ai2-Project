<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001851">
<title confidence="0.98917">
TIPSem (English and Spanish):
Evaluating CRFs and Semantic Roles in TempEval-2
</title>
<author confidence="0.999618">
Hector Llorens, Estela Saquete, Borja Navarro
</author>
<affiliation confidence="0.999354">
University of Alicante
</affiliation>
<address confidence="0.609914">
Alicante, Spain
</address>
<email confidence="0.999064">
{hllorens,stela,borja}@dlsi.ua.es
</email>
<sectionHeader confidence="0.997391" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999735">
This paper presents TIPSem, a system to
extract temporal information from natural
language texts for English and Spanish.
TIPSem, learns CRF models from training
data. Although the used features include
different language analysis levels, the ap-
proach is focused on semantic informa-
tion. For Spanish, TIPSem achieved the
best F1 score in all the tasks. For English,
it obtained the best F1 in tasks B (events)
and D (event-dct links); and was among
the best systems in the rest.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.964455111111111">
The automatic treatment of time expressions,
events and their relations over natural language
text consists of making temporal elements ex-
plicit through a system that identifies and anno-
tates them following a standard scheme. This in-
formation is crucial for other natural language pro-
cessing (NLP) areas, such as summarization or
question answering. The relevance of temporal in-
formation has been reflected in specialized confer-
ences (Schilder et al., 2007) and evaluation forums
(Verhagen et al., 2007).
We present a system to tackle the six different
tasks related to multilingual temporal information
treatment proposed in TempEval-2. Particularly,
in this evaluation exercise, TimeML (Pustejovsky
et al., 2003) is adopted as temporal annotation
scheme. In this manner, the tasks require partic-
ipating systems to automatically annotate differ-
ent TimeML elements. Firstly, task A consists
of determining the extent of time expressions as
defined by the TimeML TIMEX3 tag, as well as
the attributes “type” and “value”. Secondly, task
B addresses the recognition and classification of
events as defined by TimeML EVENT tag. Fi-
nally, tasks C to F comprise the categorization of
different temporal links (TimeML LINKs). Figure
1 illustrates the TimeML elements in a sentence.
</bodyText>
<figureCaption confidence="0.999746">
Figure 1: TimeML example
</figureCaption>
<bodyText confidence="0.999897166666667">
In the context of TempEval-2, we tackle all
tasks for English and Spanish with a data-driven
system. This consists of CRF models inferred
from lexical, syntactic and semantic information
of given training data.
Our main approach, TIPSem (Temporal
Information Processing based on Semantic in-
formation), is focused on semantic roles and
semantic networks. Furthermore, we present
a secondary approach, TIPSem-B (TIPSem-
Baseline), which contrary to the former does not
consider semantic information.
The main objectives of this paper are (1) evalu-
ating the performance of TIPSem comparing it to
other participating systems and (2) measuring the
contribution of semantic information to different
TempEval-2 tasks though the comparison between
our systems: TIPSem and TIPSem-B.
This paper is structured as follows. Our ap-
proach to address the TempEval-2 tasks is moti-
vated in Section 2 and described in Section 3. The
results obtained in the evaluation are shown and
analyzed in Section 4. Finally, conclusions are
drawn in Section 5.
</bodyText>
<sectionHeader confidence="0.991925" genericHeader="method">
2 Approach motivation
</sectionHeader>
<bodyText confidence="0.9998325">
The next two subsections describe the two main
characteristics of our approach, CRFs and seman-
tic roles, and the reasons why we think they could
be useful to tackle TimeML annotation.
</bodyText>
<page confidence="0.971521">
284
</page>
<note confidence="0.9673905">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 284–291,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<subsectionHeader confidence="0.785651">
2.1 CRF probabilistic model
</subsectionHeader>
<bodyText confidence="0.998647833333333">
Conditional Random Fields is a popular and effi-
cient ML technique for supervised sequence label-
ing (Lafferty et al., 2001). In the recognition prob-
lem raised by TempEval-2 tasks A and B, assume
X is a random variable over data sequences to be
labeled, and Y is a random variable over the corre-
sponding label sequences, being all Y components
(Yi) members of a finite label alphabet -y. X might
range over the sentences and Y range over possi-
ble annotations of those sentences, with -y the set
of possible event IOB21 labels. The following ex-
ample illustrates the problem.
</bodyText>
<equation confidence="0.999764333333333">
(1) X Y
That ? B-TIMEX3
was ? B-EVENT
another ? ? = I-TIMEX3
bad ? I-EVENT
week ? O
</equation>
<bodyText confidence="0.9994036">
Then, CRFs construct a conditional model from
paired observations and label sequences: p(Y |X).
To extend the problem to classification, X is re-
placed with elements to be classified and -y is re-
placed with the possible classes, for instance, in
task A X = {TIMEX3 instances in text} and
-y = {DATE, DURATION, SET, TIME}.
From our point of view, CRFs are well suited
to address TempEval-2 tasks. Firstly, TimeML
elements depend on structural properties of sen-
tences. Not only the word sequence, but mor-
phological, syntactic and semantic structure is re-
lated with them. Secondly, some TIMEX3 and
EVENT elements are denoted by sequences of
words, therefore the CRFs are very appropriate.
</bodyText>
<subsectionHeader confidence="0.999096">
2.2 Semantic roles
</subsectionHeader>
<bodyText confidence="0.999979714285714">
Semantic role labeling (SRL) has achieved impor-
tant results in the last years (Gildea and Jurafsky,
2002; Moreda et al., 2007). For each predicate in a
sentence, semantic roles identify all constituents,
determining their arguments (agent, patient, etc.)
and their adjuncts (locative, temporal, etc.). Fig-
ure 2 illustrates a semantic role labeled sentence.
</bodyText>
<figureCaption confidence="0.984174">
Figure 2: Semantic roles example
</figureCaption>
<bodyText confidence="0.889471">
Semantic roles provide structural relations of
the predicates in which TimeML elements may
</bodyText>
<page confidence="0.673397">
1IOB2 format: (B)egin, (I)nside, and (O)utside
</page>
<bodyText confidence="0.999802444444444">
participate. Beyond syntactic relations expressed
by means of the different types of phrases, seman-
tic roles give further information about semantic
relations between the arguments of a predicate.
Due to the fact that roles represent high level in-
formation, they are more independent from word
tokens. Hence, roles may aid in learning more
general models that could improve the results of
approaches focused on lower level information.
</bodyText>
<sectionHeader confidence="0.979386" genericHeader="method">
3 Our approach: TIPSem
</sectionHeader>
<bodyText confidence="0.99995364516129">
As defined in previous section, this paper pro-
poses CRF as learning method to infer models to
face the TempEval-2 tasks. Specifically, CRF++
toolkit2 was used for training and testing our ap-
proach. The learning process was done using
the parameters: CRF-L2 algorithm and hyper-
parameter C=1.
In order to set out the approach architecture and
select the features for learning, we divided the
tasks proposed in the evaluation exercise into four
groups: recognition, classification, normalization
and link-categorization. Each group represents a
kind of problem to be resolved. Recognition prob-
lem is present in TIMEX3 and EVENT bounding
(tasks A and B). Classification problem appears in
TIMEX3 type and EVENT class attributes (tasks
A and B). Normalization arises in TIMEX3 value
attribute (task A). And link-categorization is ap-
plied to different kind of link relations (tasks C to
F). Each group uses a particular feature set to learn
an annotation model. The features of these sets are
grouped in two subsets. On the one hand, general
features, which are widely used in different NLP
fields and represent lower language analysis lev-
els. On the other hand, semantic features, which
are a novelty in the task and our main focus.
TIPSem system uses all the features defined
above. However, to measure the influence of se-
mantic information in temporal information treat-
ment, TIPSem-B system was implemented ex-
cluding the semantic features.
</bodyText>
<subsectionHeader confidence="0.997814">
3.1 Recognition
</subsectionHeader>
<bodyText confidence="0.997352">
In recognition, the features are obtained at token
level, that is to say, each token has its own set of
features.
Regarding each language analysis level, the
general features used to train our CRF model are:
</bodyText>
<footnote confidence="0.983739">
2http://crfpp.sourceforge.net/
</footnote>
<page confidence="0.99329">
285
</page>
<listItem confidence="0.9586215">
• Morphological: The lemma and part-of-
speech (PoS) context, in a 5-window (-2,+2),
was employed due to the good results it
achieved in other NLP tasks. Tokenization,
PoS and lemmatization were obtained using
TreeTagger (Schmid, 1994) for English, and
were got from AnCora (Taul´e et al., 2008) for
Spanish.
• Syntactic: Different TimeML elements are
contained in particular types of phrases. This
feature tries to capture this fact by consider-
ing phrase level syntactic information. The
syntactic tree was obtained using Charniak
parser (Charniak and Johnson, 2005) for En-
glish, and AnCora for Spanish.
• Polarity, tense and aspect: These were ob-
tained using PoS and a set of handcrafted
rules (e.g., will+verb → future).
</listItem>
<bodyText confidence="0.99166">
The semantic level features used to enhance the
training framework of the CRF model are:
</bodyText>
<listItem confidence="0.9900412">
• Role: For each token, we considered the
role regarding the verb the token depends on.
To get semantic roles, CCG SRL tool (Pun-
yakanok et al., 2004) was used for English,
and AnCora for Spanish.
• Governing verb: The verb to which the cur-
rent token holds a particular role. This may
distinguish tokens appearing under the influ-
ence of different verbs.
• Role+verb combination: The previous two
</listItem>
<bodyText confidence="0.970634857142857">
features were combined to capture the rela-
tion between them. This introduces addi-
tional information by distinguishing roles de-
pending on different verbs. The importance
of this falls especially on the numbered roles
(A0, A1, etc.) meaning different things when
depending on different verbs.
</bodyText>
<listItem confidence="0.992416">
• Role configuration: This feature is only
present in verb tokens heading a sentence or
sub-sentence. This consists of the set of roles
depending on the verb. This may be particu-
larly useful for distinguish different sentence
settings.
• Lexical semantics: WordNet (Fellbaum,
1998) top ontology classes have been widely
used to represent word meaning at ontologi-
cal level, and demonstrated its worth in many
</listItem>
<bodyText confidence="0.99948525">
tasks. TIPSem uses the top four classes
for each word. For Spanish, EuroWordNet
(Vossen, 1998) was used.
In this manner, given a list of tokens and its fea-
tures, the trained recognition model will assign to
each token one of the valid labels. For instance,
in the case of TIMEX3 recognition: B-TIMEX3,
I-TIMEX3 or O.
</bodyText>
<subsectionHeader confidence="0.998415">
3.2 Classification
</subsectionHeader>
<bodyText confidence="0.999915571428571">
Classification features, used to get TIMEX3 types
and EVENT classes, are basically the same as the
ones used for recognition. However, the main
difference is that the features are not obtained
at token level but at TIMEX3 or EVENT level.
This implies that the word context is set to the
extent of each element (TIMEX3 and EVENT),
as well as all the features have as many values
as tokens comprises the element (e.g., element-
tokens=“next Monday”, PoS-feature=“JJ+NNP”).
Hence, following this description, the classifica-
tion models will assign to each element one of the
valid classes. For example, in the case of TIMEX3
typing: DATE, DURATION, SET or TIME.
</bodyText>
<subsectionHeader confidence="0.994978">
3.3 Normalization
</subsectionHeader>
<bodyText confidence="0.999841083333333">
As in classification the features are obtained at
TIMEX3 level. Furthermore, word-spelled num-
bers contained in the TIMEX3 extent are trans-
lated to their numerical value (e.g., “three days”
→ “3 days”).
Normalization process consists of two main
steps: (1) obtain the normalization type and (2)
apply the corresponding normalization rules.
The first step applies a CRF model that uses the
same features as the previous two plus TIMEX3
pattern. This new feature consists of the tokens
comprised by the TIMEX3 but replacing num-
bers by NUM, temporal units, such as years or
days, by TUNIT, months by MONTH, and week-
days by WEEKDAY. In other words, “next Mon-
day” would result in “next WEEKDAY” and “June
1999” in “MONTH NUM”. Once the model is
trained, for each new TIMEX3 it assigns a normal-
ization type. We define seven normalization types:
Period, ISO, ISO set, ISO function, present ref,
past ref and future ref.
The second step uses as input the output of the
first one. Each normalization type has its own nor-
malization rules.
</bodyText>
<page confidence="0.982769">
286
</page>
<listItem confidence="0.998616176470588">
• Period: Apply rules to convert period-like
TIMEX3 (“3 days”) into P NUM TUNIT
normalized period (“P3D”).
• ISO: Apply rules to convert any-format ex-
plicit date or time into a valid ISO 8601 stan-
dard date.
• ISO set: Apply rules to get a valid ISO-
like set from a TIMEX3 set (“monthly” →
XXXX-XX).
• ISO function: This is the most complex
type. The system applies different functions
to get a valid ISO date or time in a valid gran-
ularity from DCT3 dates. Here, time direc-
tion indicators like “next” or “previous”, as
well as verbal tenses are used.
• Present ref, past ref and future ref: these
are already normalized.
</listItem>
<subsectionHeader confidence="0.953038">
3.4 Link-categorization
</subsectionHeader>
<bodyText confidence="0.947803666666667">
Each one of link-related tasks (C to F) has its own
link-categorization features. Nevertheless, all link
types share some of them.
</bodyText>
<listItem confidence="0.8687005">
• Task C: For categorizing the relation be-
tween an EVENT and a TIMEX3, the system
takes into account the following features:
– Heading preposition if the event or the
</listItem>
<bodyText confidence="0.903707428571429">
TIMEX3 are contained by a preposi-
tional phrase as in “before the meeting”,
where “meeting” is the event and “be-
fore” the heading preposition.
– Syntactic relation of the event and the
TIMEX3 in the sentence. This feature
may be evaluated as: same sentence,
same subsentence or same phrase.
– Time position. If the event is not di-
rectly linked with the relation TIMEX3
but related to another TIMEX3, the time
position represents whether the event
is before, overlap or after the relation
TIMEX3.
</bodyText>
<listItem confidence="0.956163833333333">
– Interval. This feature is 0 unless there
appears some interval indicator token
near the TIMEX3. This is useful to
identify overlap-and-after and overlap-
and-before categories.
– TIMEX3 type.
</listItem>
<subsectionHeader confidence="0.364069">
3Date Creation Time
</subsectionHeader>
<bodyText confidence="0.759389333333333">
– Semantic roles if the event or the
TIMEX3 are contained by a tempo-
ral subordination (labeled with tempo-
ral role), for example, in “after he left
home”, “left” is the event and “after” the
subordinating element (role feature).
</bodyText>
<listItem confidence="0.95663515">
• Task D: To determine the relationship be-
tween an event and the DCT, TIPSem uses
the same features as in task C except in-
terval. In addition, all the features related
to TIMEX3 are now related to the closer
TIMEX3 (if exists) in the event sentence. In
this manner, the time position is calculated by
comparing DCT and that TIMEX3.
• Task E: Relations between two main events
are categorized using only four features: the
tense and aspect of the two events, the syn-
tactic relation between them, and the time po-
sition, calculated using the closer TIMEX3 to
each event.
• Task F: For categorizing subordinated
events, TIPSem uses the subordinating
element of temporal roles containing each
event (if present), the heading preposition of
a prepositional phrases containing each event
(if present), as well as the tense and aspect.
</listItem>
<bodyText confidence="0.9838585">
To illustrate the system architecture, Figure 3
summarizes the strategies that TIPSem follows
to tackle the tasks proposed in the TempEval-2
framework.
</bodyText>
<figureCaption confidence="0.996074">
Figure 3: TIPSem architecture
</figureCaption>
<page confidence="0.995068">
287
</page>
<sectionHeader confidence="0.999182" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999974678571428">
The test corpus consists of 17K words for English
and 10K words for Spanish, in which approxi-
mately a half part correspond to tasks A and B,
and the other half to tasks C, D, E and F. The per-
formance is measured using precision, recall and
Fβ=1 metrics. A scoring script is provided. This
counts correct instances at token level for tasks A
and B, and at temporal link level for the rest.
Next subsections show the results obtained by
TIPSem system in each one of the TempEval-2
tasks for English (EN) and Spanish (ES). More-
over, a final subsection illustrates the Fβ=1 results
in three comparative graphs. In tasks A and B, pre-
cision, recall and Fβ=1 are given. In tasks C to E,
links tasks precision, recall and Fβ=1 are the same
because our system does not consider the NONE
value. Hence, only Fβ=1 is given. Tasks E and
F were not considered for Spanish in TempEval-
2 evaluation and thus Spanish is excluded from
those subsections.
For each task, scores in which our system ob-
tained the first place in the evaluation exercise are
in bold. Furthermore, in all cases the best score
obtained by participating systems is reported. Fi-
nally, the influence of semantic information in
terms of improvement is indicated and analyzed
through the comparison with TIPSem-B system,
which exclude the features related with semantics.
</bodyText>
<subsectionHeader confidence="0.975915">
4.1 Task A: TIMEX3
</subsectionHeader>
<bodyText confidence="0.941718">
Table 1 shows the results obtained by our ap-
proaches in TIMEX3 recognition, typing and ISO
8601 normalization (value).
</bodyText>
<table confidence="0.9978498">
System lang Prec. Rec. Fβ=1 type value
TIPSem EN 0.92 0.80 0.85 0.92 0.65
TIPSem ES 0.95 0.87 0.91 0.91 0.78
TIPSem-B EN 0.88 0.60 0.71 0.88 0.59
TIPSem-B ES 0.97 0.81 0.88 0.99 0.75
</table>
<tableCaption confidence="0.999808">
Table 1: Task A - English and Spanish
</tableCaption>
<bodyText confidence="0.99995888">
As shown in results, TIPSem obtains the best re-
sults for Spanish in all measures except for “value”
attribute, in which the best system obtained a 0.83.
Another system obtained the same recall (0.87)
but a lower precision (0.90), and thus a Fβ=1 of
(0.88) below TIPSem score (0.91). For English,
our main approach obtained the best precision.
However, another system obtained the best recall
(0.91). The best Fβ=1 was 0.86. Regarding type
attribute, TIPSem obtained values closer to best
system (0.98). Finally, in normalization, which
is the only attribute that is not annotated by a
purely data-driven process, best system surpassed
TIPSem in 0.20.
These results indicate that CRFs represent an
appropriate ML technique to learn models for an-
notating TIMEX3. Furthermore, they show that
normalization process used by TIPSem could be
improved using other techniques.
Specifically, the usage of semantic information
improved the capability of learned models to gen-
eralize rules. For instance in time expressions, if
an unseen instance is contained by a temporal role
is a clear candidate to be a time expression. Hence,
they improve system recall (33% EN, 7% ES).
</bodyText>
<subsectionHeader confidence="0.94407">
4.2 Task B: EVENT
</subsectionHeader>
<bodyText confidence="0.921959">
Table 2 shows the results obtained by our ap-
proaches in recognizing and classifying events.
</bodyText>
<table confidence="0.9986172">
System lang Prec. Recall Fβ=1 class
TIPSem EN 0.81 0.86 0.83 0.79
TIPSem ES 0.90 0.86 0.88 0.66
TIPSem-B EN 0.83 0.81 0.82 0.79
TIPSem-B ES 0.92 0.85 0.88 0.66
</table>
<tableCaption confidence="0.999343">
Table 2: Task B - English and Spanish
</tableCaption>
<bodyText confidence="0.999985666666667">
In this tasks, TIPSem obtained the best re-
sults in TempEval-2 for Spanish and English in
both recognition and classification. Although for
English another system achieved the best recall
(0.88), it obtained a lower precision (0.55); and
thus a 0.68 Fβ=1. This indicates that our approach
obtains the best Fβ=1 (0.83) with a well-balanced
precision and recall.
Again, the usage of semantic information im-
proves the capability of learned models to gen-
eralize, which improves the recall (6% EN, 1%
ES). For events, the improvement is lower than for
TIMEX3 because, contrary to TIMEX3, they are
not clearly defined by specific roles. In this case,
features like role configuration, semantic classes,
or role-governing verb are more useful.
Other attributes present in events such as polar-
ity, mood and tense obtained values of about 90%.
However, to get the values for these attributes the
system applies a set of handcrafted rules and then
the results are not relevant for our approach.
</bodyText>
<subsectionHeader confidence="0.979937">
4.3 Task C: LINKS - Events and TIMEXs
</subsectionHeader>
<bodyText confidence="0.9746215">
Table 3 shows the results obtained by our ap-
proaches in categorizing EVENT-TIMEX3 links.
</bodyText>
<page confidence="0.991049">
288
</page>
<table confidence="0.9997508">
System lang Fp=1
TIPSem EN 0.55
TIPSem ES 0.81
TIPSem-B EN 0.54
TIPSem-B ES 0.81
</table>
<tableCaption confidence="0.999864">
Table 3: Task C - English and Spanish
</tableCaption>
<bodyText confidence="0.999825714285714">
TIPSem was the only system participating in
this task for Spanish. Nevertheless, 0.81 is a high
score comparing it to English best score (0.63).
Our system, for English, is 8 points below top
scored system.
In this task, the application of semantic roles in-
troduced an improvement of 2% in F0=1.
</bodyText>
<subsectionHeader confidence="0.995954">
4.4 Task D: LINKS - Events and DCTs
</subsectionHeader>
<bodyText confidence="0.991888666666667">
Table 4 shows the results obtained by our ap-
proaches in categorizing events with respect to the
creation time of a document.
</bodyText>
<table confidence="0.999395">
System lang Fp=1
TIPSem EN 0.82
TIPSem ES 0.59
TIPSem-B EN 0.81
TIPSem-B ES 0.59
</table>
<tableCaption confidence="0.999478">
Table 4: Task D - English and Spanish
</tableCaption>
<bodyText confidence="0.998984818181818">
Task D is successfully covered by TIPSem ob-
taining the best results in the evaluation.
It seems that the relation of events with doc-
ument creation time strongly depends on tense
and aspect, as well as the event position in time
with respect to DCT when defined by neighboring
TIMEX3.
Furthermore, the learned CRF models take ad-
vantage of using temporal semantic roles informa-
tion. Specifically, the usefulness of semantic roles
in this task was quantified to 2%.
</bodyText>
<subsectionHeader confidence="0.996724">
4.5 Task E: LINKS - Main events
</subsectionHeader>
<bodyText confidence="0.991087666666667">
Table 5 shows the results obtained by our ap-
proaches in categorizing main events relations in
text.
</bodyText>
<table confidence="0.996922666666667">
System lang Fp=1
TIPSem EN 0.55
TIPSem-B EN 0.55
</table>
<tableCaption confidence="0.999129">
Table 5: Task E - English
</tableCaption>
<bodyText confidence="0.999501857142857">
In this task, our system obtains the second
place. However, the top scored achieved a 0.56.
Again, the tense and aspect features, as well as
the events position in time resulted useful to tackle
this task. In this case, semantic roles information
is not used so TIPSem and TIPSem-B are equiva-
lent.
</bodyText>
<subsectionHeader confidence="0.979948">
4.6 Task F: LINKS - Subordinated events
</subsectionHeader>
<bodyText confidence="0.972980666666667">
Table 6 shows the results obtained by our ap-
proaches in categorizing events relations with the
events they syntactically govern.
</bodyText>
<table confidence="0.998851">
System lang Fp=1
TIPSem EN 0.59
TIPSem-B EN 0.60
</table>
<tableCaption confidence="0.99824">
Table 6: Task F - English
</tableCaption>
<bodyText confidence="0.99933675">
Categorizing subordinated events TIPSem ob-
tained the second place. Best score was 0.66. In
this task, the application of roles did not help and
decreased the score in one point. The cause may
be that for this task roles are not relevant but noisy.
In this case, some extra information extending se-
mantic roles is needed to turn them into a useful
feature.
</bodyText>
<subsectionHeader confidence="0.996478">
4.7 Comparative graphs
</subsectionHeader>
<bodyText confidence="0.949371083333333">
This subsection presents the TIPSem F0=1 re-
sults in three graphs. Figure 4 illustrates the re-
sults for English indicating the higher and lower
scores achieved by TempEval-2 participating sys-
tems. Figure 5 shows the same for Spanish but,
due to the fact that TIPSem was the only partici-
pant in tasks B, C and D, the graph includes En-
glish min. and max. scores as indirect assessment.
Finally, Figure 6, compares the TIPSem results for
English and Spanish.
Figure 4 shows how TIPSem achieved, in gen-
eral, a high performance for English.
</bodyText>
<figureCaption confidence="0.991476">
Figure 4: English F0=1 comparative
</figureCaption>
<page confidence="0.987943">
289
</page>
<figureCaption confidence="0.999206">
Figure 5: Spanish F0=1 indirect assessment
</figureCaption>
<bodyText confidence="0.9943722">
For Spanish we can only report indirect assess-
ment comparing the results to English scores. It
can be seen that the quality of the results is similar
for tasks A and B, but seems to be inverted in tasks
C and D.
</bodyText>
<figureCaption confidence="0.991384">
Figure 6: TIPSem EN - ES F0=1 comparative
</figureCaption>
<bodyText confidence="0.999967363636364">
Finally, in this graph comparing TIPSem re-
sults, we observe that our approach achieved simi-
lar performance for both languages in tasks A and
B. This indicates that for this tasks, the approach is
valid for both languages. However, as in the previ-
ous graph, it seems that for English TIPSem per-
forms worse in task C and better in task D while
for Spanish it does right the opposite.
The train and test corpora were reviewed to an-
alyze this fact. On the one hand, the reason for
the high performance in task C for Spanish was
the high amount of “overlap” instances in both
corpora. This trained the CRF model for catego-
rizing event-timex links as “overlap” in most of
cases. On the other hand, the cause of the Spanish
low performance in task D is “vague” links. The
features defined in TIPSem cannot distinguish be-
tween “overlap” and “vague”. Due to the fact that
“vague” links are quite popular in Spanish test set,
the results decreased. This did not affect to En-
glish results because of the spareness of “vague”
links.
</bodyText>
<sectionHeader confidence="0.995498" genericHeader="conclusions">
5 Conclusions and Further Work
</sectionHeader>
<bodyText confidence="0.999980090909091">
This paper presented a system for automatically
treating temporal information of natural language
texts as required in the TempEval-2 evaluation ex-
ercise, in particular, following TimeML specifica-
tions.
Our system, TIPSem, is a data-driven approach
and consists of different CRF models learned us-
ing semantic information as main feature. CRFs
were used taking into account that data-driven ap-
proaches have obtained good results in many NLP
tasks, and due to their appropriateness in sequence
labeling problems and problems in which struc-
tural properties are relevant, as those proposed in
TempEval-2. Furthermore, the models were en-
hanced using semantic information. Roles have
been applied in other NLP fields with successful
results, but never employed before for this pur-
pose. With these two main characteristics, we de-
signed a complete learning environment selecting,
in addition to roles, different language analysis
level properties as features to train the models.
The results obtained for English and Spanish
in the evaluation exercise were satisfactory and
well-balanced between precision and recall. For
Spanish, TIPSem achieved the best F0=1 in all
tasks. For English, it obtained the best F0=1 in
event recognition and classification (task B), and
event and document creation time links catego-
rization (task D). Furthermore, in general, all the
results of TIPSem were very competitive and were
among the top scored systems. This verifies that
our approach is appropriate to address TempEval-
2 tasks.
Regarding multilinguality, the approach was
proven to be valid for different languages (English
and Spanish). This was also verified for Catalan
language by earlier versions of TIPSem (Llorens
et al., 2009). In fact, the data-driven part of the
system could be considered language independent
because it has been applied to different languages
and could be applied to other languages without
adaptation, provided that there are tools available
to get the morphosyntactic and semantic informa-
tion required by the approach. It has to be high-
</bodyText>
<page confidence="0.979111">
290
</page>
<bodyText confidence="0.999971393939394">
lighted that to apply TIPSem-B only morphosyn-
tactic information is required. Only the normaliza-
tion of time expressions is a language dependent
process in our system and requires the construc-
tion of a set of rules for each target language.
The contribution of semantic information to
temporal information treatment was more signif-
icant in recall and the improvement was concen-
trated in tasks A and B (approx. 12% recall im-
provement). Although, TIPSem-B achieved lower
results they are high enough to confirm that that
most of temporal elements strongly depends on
lexical and morphosyntactic information.
The main errors and difficulties of our approach
in this evaluation exercise are related to TIMEX3
normalization (value attribute). A pure ML ap-
proach for solving this problem is not trivial, at
least, using our approach philosophy. The treat-
ment of normalization functions is an inherently
complex task and requires many training data to be
automatically learned. This required us to include
in the system some handcrafted rules to enable the
system for this task.
As further work we propose improving the
TIMEX3 normalization by replacing handcrafted
normalization rules with machine learned ones
by combining statistic techniques and multilingual
temporal knowledge resources (ontologies). Fur-
thermore, link-categorization will be analyzed in
more detail in order to include more features to im-
prove the models. Finally, the suggested language
independence of the approach will be tested using
TempEval-2 available data for other languages.
</bodyText>
<sectionHeader confidence="0.999196" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999162">
This paper has been supported by the Spanish
Government, projects TIN-2006-15265-C06-01, TIN-
2009-13391-C04-01 and PROMETEO/2009/119, where
Hector Llorens is funded under a FPI grant (BES-
2007-16256).
</bodyText>
<sectionHeader confidence="0.999641" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999836981132075">
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-fine n-best parsing and maxent discriminative
reranking. In 43rd Annual Meeting of the ACL.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database (Language, Speech, and Commu-
nication). MIT Press.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic
labeling of semantic roles. Computational Linguis-
tics, 28(3):245–288.
John D. Lafferty, Andrew McCallum, and Fernando
C. N. Pereira. 2001. Conditional random fields:
Probabilistic models for segmenting and labeling se-
quence data. In Proceedings of the 18th ICML,
pages 282–289. Morgan Kaufmann.
Hector Llorens, Borja Navarro, and Estela Saquete.
2009. Detecci´on de Expresiones Temporales
TimeML en Catal´an mediante Roles Sem´anticos y
Redes Sem´anticas. In Procesamiento del Lenguaje
Natural (SEPLN), number 43, pages 13–21.
Paloma Moreda, Borja Navarro, and Manuel Palomar.
2007. Corpus-based semantic role approach in in-
formation retrieval. Data Knowledge Engineering,
61(3):467–483.
Vasin Punyakanok, Dan Roth, W. Yih, D. Zimak, and
Y. Tu. 2004. Semantic role labeling via generalized
inference over classifiers. In HLT-NAACL (CoNLL),
pages 130–133. ACL.
James Pustejovsky, Jos´e M. Casta˜no, Robert Ingria,
Roser Sauri, Robert Gaizauskas, Andrea Setzer, and
Graham Katz. 2003. TimeML: Robust Specifica-
tion of Event and Temporal Expressions in Text. In
IWCS-5.
Frank Schilder, Graham Katz, and James Pustejovsky.
2007. Annotating, Extracting and Reasoning About
Time and Events (Dagstuhl 2005), volume 4795 of
LNCS. Springer.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. In Proceedings of the
International Conference on New Methods in Lan-
guage Processing, pages 44–49.
Mariona Taul´e, M. Antonia Marti, and Marta Recasens.
2008. AnCora: Multilevel Annotated Corpora for
Catalan and Spanish. In ELRA, editor, LREC, Mar-
rakech, Morocco.
Marc Verhagen, Robert Gaizauskas, Mark Hepple,
Frank Schilder, Graham Katz, and James Puste-
jovsky. 2007. Semeval-2007 task 15: Tempeval
temporal relation identification. In Proceedings of
the 4th International Workshop on Semantic Evalu-
ations, pages 75–80, Prague. ACL.
Piek Vossen. 1998. EuroWordNet: a multilingual
database with lexical semantic networks. Kluwer
Academic Publishers, MA, USA.
</reference>
<page confidence="0.997856">
291
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.904045">
<title confidence="0.997028">TIPSem (English and Spanish): Evaluating CRFs and Semantic Roles in TempEval-2</title>
<author confidence="0.999789">Hector Llorens</author>
<author confidence="0.999789">Estela Saquete</author>
<author confidence="0.999789">Borja Navarro</author>
<affiliation confidence="0.99997">University of Alicante</affiliation>
<address confidence="0.940539">Alicante, Spain</address>
<abstract confidence="0.997226384615385">This paper presents TIPSem, a system to extract temporal information from natural language texts for English and Spanish. TIPSem, learns CRF models from training data. Although the used features include different language analysis levels, the approach is focused on semantic information. For Spanish, TIPSem achieved the best F1 score in all the tasks. For English, it obtained the best F1 in tasks B (events) and D (event-dct links); and was among the best systems in the rest.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarseto-fine n-best parsing and maxent discriminative reranking.</title>
<date>2005</date>
<booktitle>In 43rd Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="8053" citStr="Charniak and Johnson, 2005" startWordPosition="1261" endWordPosition="1264">o train our CRF model are: 2http://crfpp.sourceforge.net/ 285 • Morphological: The lemma and part-ofspeech (PoS) context, in a 5-window (-2,+2), was employed due to the good results it achieved in other NLP tasks. Tokenization, PoS and lemmatization were obtained using TreeTagger (Schmid, 1994) for English, and were got from AnCora (Taul´e et al., 2008) for Spanish. • Syntactic: Different TimeML elements are contained in particular types of phrases. This feature tries to capture this fact by considering phrase level syntactic information. The syntactic tree was obtained using Charniak parser (Charniak and Johnson, 2005) for English, and AnCora for Spanish. • Polarity, tense and aspect: These were obtained using PoS and a set of handcrafted rules (e.g., will+verb → future). The semantic level features used to enhance the training framework of the CRF model are: • Role: For each token, we considered the role regarding the verb the token depends on. To get semantic roles, CCG SRL tool (Punyakanok et al., 2004) was used for English, and AnCora for Spanish. • Governing verb: The verb to which the current token holds a particular role. This may distinguish tokens appearing under the influence of different verbs. •</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarseto-fine n-best parsing and maxent discriminative reranking. In 43rd Annual Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database (Language, Speech, and Communication).</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="9266" citStr="Fellbaum, 1998" startWordPosition="1463" endWordPosition="1464"> • Role+verb combination: The previous two features were combined to capture the relation between them. This introduces additional information by distinguishing roles depending on different verbs. The importance of this falls especially on the numbered roles (A0, A1, etc.) meaning different things when depending on different verbs. • Role configuration: This feature is only present in verb tokens heading a sentence or sub-sentence. This consists of the set of roles depending on the verb. This may be particularly useful for distinguish different sentence settings. • Lexical semantics: WordNet (Fellbaum, 1998) top ontology classes have been widely used to represent word meaning at ontological level, and demonstrated its worth in many tasks. TIPSem uses the top four classes for each word. For Spanish, EuroWordNet (Vossen, 1998) was used. In this manner, given a list of tokens and its features, the trained recognition model will assign to each token one of the valid labels. For instance, in the case of TIMEX3 recognition: B-TIMEX3, I-TIMEX3 or O. 3.2 Classification Classification features, used to get TIMEX3 types and EVENT classes, are basically the same as the ones used for recognition. However, th</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database (Language, Speech, and Communication). MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="4909" citStr="Gildea and Jurafsky, 2002" startWordPosition="773" endWordPosition="776">nd -y is replaced with the possible classes, for instance, in task A X = {TIMEX3 instances in text} and -y = {DATE, DURATION, SET, TIME}. From our point of view, CRFs are well suited to address TempEval-2 tasks. Firstly, TimeML elements depend on structural properties of sentences. Not only the word sequence, but morphological, syntactic and semantic structure is related with them. Secondly, some TIMEX3 and EVENT elements are denoted by sequences of words, therefore the CRFs are very appropriate. 2.2 Semantic roles Semantic role labeling (SRL) has achieved important results in the last years (Gildea and Jurafsky, 2002; Moreda et al., 2007). For each predicate in a sentence, semantic roles identify all constituents, determining their arguments (agent, patient, etc.) and their adjuncts (locative, temporal, etc.). Figure 2 illustrates a semantic role labeled sentence. Figure 2: Semantic roles example Semantic roles provide structural relations of the predicates in which TimeML elements may 1IOB2 format: (B)egin, (I)nside, and (O)utside participate. Beyond syntactic relations expressed by means of the different types of phrases, semantic roles give further information about semantic relations between the argum</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the 18th ICML,</booktitle>
<pages>282--289</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="3567" citStr="Lafferty et al., 2001" startWordPosition="539" endWordPosition="542">n are shown and analyzed in Section 4. Finally, conclusions are drawn in Section 5. 2 Approach motivation The next two subsections describe the two main characteristics of our approach, CRFs and semantic roles, and the reasons why we think they could be useful to tackle TimeML annotation. 284 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 284–291, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics 2.1 CRF probabilistic model Conditional Random Fields is a popular and efficient ML technique for supervised sequence labeling (Lafferty et al., 2001). In the recognition problem raised by TempEval-2 tasks A and B, assume X is a random variable over data sequences to be labeled, and Y is a random variable over the corresponding label sequences, being all Y components (Yi) members of a finite label alphabet -y. X might range over the sentences and Y range over possible annotations of those sentences, with -y the set of possible event IOB21 labels. The following example illustrates the problem. (1) X Y That ? B-TIMEX3 was ? B-EVENT another ? ? = I-TIMEX3 bad ? I-EVENT week ? O Then, CRFs construct a conditional model from paired observations </context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the 18th ICML, pages 282–289. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hector Llorens</author>
<author>Borja Navarro</author>
<author>Estela Saquete</author>
</authors>
<title>Detecci´on de Expresiones Temporales TimeML en Catal´an mediante Roles Sem´anticos y Redes Sem´anticas.</title>
<date>2009</date>
<booktitle>In Procesamiento del Lenguaje Natural (SEPLN), number 43,</booktitle>
<pages>13--21</pages>
<contexts>
<context position="24534" citStr="Llorens et al., 2009" startWordPosition="4049" endWordPosition="4052">n and recall. For Spanish, TIPSem achieved the best F0=1 in all tasks. For English, it obtained the best F0=1 in event recognition and classification (task B), and event and document creation time links categorization (task D). Furthermore, in general, all the results of TIPSem were very competitive and were among the top scored systems. This verifies that our approach is appropriate to address TempEval2 tasks. Regarding multilinguality, the approach was proven to be valid for different languages (English and Spanish). This was also verified for Catalan language by earlier versions of TIPSem (Llorens et al., 2009). In fact, the data-driven part of the system could be considered language independent because it has been applied to different languages and could be applied to other languages without adaptation, provided that there are tools available to get the morphosyntactic and semantic information required by the approach. It has to be high290 lighted that to apply TIPSem-B only morphosyntactic information is required. Only the normalization of time expressions is a language dependent process in our system and requires the construction of a set of rules for each target language. The contribution of sem</context>
</contexts>
<marker>Llorens, Navarro, Saquete, 2009</marker>
<rawString>Hector Llorens, Borja Navarro, and Estela Saquete. 2009. Detecci´on de Expresiones Temporales TimeML en Catal´an mediante Roles Sem´anticos y Redes Sem´anticas. In Procesamiento del Lenguaje Natural (SEPLN), number 43, pages 13–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paloma Moreda</author>
<author>Borja Navarro</author>
<author>Manuel Palomar</author>
</authors>
<title>Corpus-based semantic role approach in information retrieval.</title>
<date>2007</date>
<journal>Data Knowledge Engineering,</journal>
<volume>61</volume>
<issue>3</issue>
<contexts>
<context position="4931" citStr="Moreda et al., 2007" startWordPosition="777" endWordPosition="780">possible classes, for instance, in task A X = {TIMEX3 instances in text} and -y = {DATE, DURATION, SET, TIME}. From our point of view, CRFs are well suited to address TempEval-2 tasks. Firstly, TimeML elements depend on structural properties of sentences. Not only the word sequence, but morphological, syntactic and semantic structure is related with them. Secondly, some TIMEX3 and EVENT elements are denoted by sequences of words, therefore the CRFs are very appropriate. 2.2 Semantic roles Semantic role labeling (SRL) has achieved important results in the last years (Gildea and Jurafsky, 2002; Moreda et al., 2007). For each predicate in a sentence, semantic roles identify all constituents, determining their arguments (agent, patient, etc.) and their adjuncts (locative, temporal, etc.). Figure 2 illustrates a semantic role labeled sentence. Figure 2: Semantic roles example Semantic roles provide structural relations of the predicates in which TimeML elements may 1IOB2 format: (B)egin, (I)nside, and (O)utside participate. Beyond syntactic relations expressed by means of the different types of phrases, semantic roles give further information about semantic relations between the arguments of a predicate. D</context>
</contexts>
<marker>Moreda, Navarro, Palomar, 2007</marker>
<rawString>Paloma Moreda, Borja Navarro, and Manuel Palomar. 2007. Corpus-based semantic role approach in information retrieval. Data Knowledge Engineering, 61(3):467–483.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>W Yih</author>
<author>D Zimak</author>
<author>Y Tu</author>
</authors>
<title>Semantic role labeling via generalized inference over classifiers.</title>
<date>2004</date>
<booktitle>In HLT-NAACL (CoNLL),</booktitle>
<pages>130--133</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="8448" citStr="Punyakanok et al., 2004" startWordPosition="1331" endWordPosition="1335"> elements are contained in particular types of phrases. This feature tries to capture this fact by considering phrase level syntactic information. The syntactic tree was obtained using Charniak parser (Charniak and Johnson, 2005) for English, and AnCora for Spanish. • Polarity, tense and aspect: These were obtained using PoS and a set of handcrafted rules (e.g., will+verb → future). The semantic level features used to enhance the training framework of the CRF model are: • Role: For each token, we considered the role regarding the verb the token depends on. To get semantic roles, CCG SRL tool (Punyakanok et al., 2004) was used for English, and AnCora for Spanish. • Governing verb: The verb to which the current token holds a particular role. This may distinguish tokens appearing under the influence of different verbs. • Role+verb combination: The previous two features were combined to capture the relation between them. This introduces additional information by distinguishing roles depending on different verbs. The importance of this falls especially on the numbered roles (A0, A1, etc.) meaning different things when depending on different verbs. • Role configuration: This feature is only present in verb toke</context>
</contexts>
<marker>Punyakanok, Roth, Yih, Zimak, Tu, 2004</marker>
<rawString>Vasin Punyakanok, Dan Roth, W. Yih, D. Zimak, and Y. Tu. 2004. Semantic role labeling via generalized inference over classifiers. In HLT-NAACL (CoNLL), pages 130–133. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Jos´e M Casta˜no</author>
<author>Robert Ingria</author>
<author>Roser Sauri</author>
<author>Robert Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Graham Katz</author>
</authors>
<title>TimeML: Robust Specification of Event and Temporal Expressions in Text.</title>
<date>2003</date>
<booktitle>In IWCS-5.</booktitle>
<marker>Pustejovsky, Casta˜no, Ingria, Sauri, Gaizauskas, Setzer, Katz, 2003</marker>
<rawString>James Pustejovsky, Jos´e M. Casta˜no, Robert Ingria, Roser Sauri, Robert Gaizauskas, Andrea Setzer, and Graham Katz. 2003. TimeML: Robust Specification of Event and Temporal Expressions in Text. In IWCS-5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Schilder</author>
<author>Graham Katz</author>
<author>James Pustejovsky</author>
</authors>
<title>Annotating, Extracting and Reasoning About Time and Events (Dagstuhl</title>
<date>2007</date>
<volume>4795</volume>
<publisher>Springer.</publisher>
<contexts>
<context position="1158" citStr="Schilder et al., 2007" startWordPosition="171" endWordPosition="174">score in all the tasks. For English, it obtained the best F1 in tasks B (events) and D (event-dct links); and was among the best systems in the rest. 1 Introduction The automatic treatment of time expressions, events and their relations over natural language text consists of making temporal elements explicit through a system that identifies and annotates them following a standard scheme. This information is crucial for other natural language processing (NLP) areas, such as summarization or question answering. The relevance of temporal information has been reflected in specialized conferences (Schilder et al., 2007) and evaluation forums (Verhagen et al., 2007). We present a system to tackle the six different tasks related to multilingual temporal information treatment proposed in TempEval-2. Particularly, in this evaluation exercise, TimeML (Pustejovsky et al., 2003) is adopted as temporal annotation scheme. In this manner, the tasks require participating systems to automatically annotate different TimeML elements. Firstly, task A consists of determining the extent of time expressions as defined by the TimeML TIMEX3 tag, as well as the attributes “type” and “value”. Secondly, task B addresses the recogn</context>
</contexts>
<marker>Schilder, Katz, Pustejovsky, 2007</marker>
<rawString>Frank Schilder, Graham Katz, and James Pustejovsky. 2007. Annotating, Extracting and Reasoning About Time and Events (Dagstuhl 2005), volume 4795 of LNCS. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Conference on New Methods in Language Processing,</booktitle>
<pages>44--49</pages>
<contexts>
<context position="7721" citStr="Schmid, 1994" startWordPosition="1212" endWordPosition="1213">semantic information in temporal information treatment, TIPSem-B system was implemented excluding the semantic features. 3.1 Recognition In recognition, the features are obtained at token level, that is to say, each token has its own set of features. Regarding each language analysis level, the general features used to train our CRF model are: 2http://crfpp.sourceforge.net/ 285 • Morphological: The lemma and part-ofspeech (PoS) context, in a 5-window (-2,+2), was employed due to the good results it achieved in other NLP tasks. Tokenization, PoS and lemmatization were obtained using TreeTagger (Schmid, 1994) for English, and were got from AnCora (Taul´e et al., 2008) for Spanish. • Syntactic: Different TimeML elements are contained in particular types of phrases. This feature tries to capture this fact by considering phrase level syntactic information. The syntactic tree was obtained using Charniak parser (Charniak and Johnson, 2005) for English, and AnCora for Spanish. • Polarity, tense and aspect: These were obtained using PoS and a set of handcrafted rules (e.g., will+verb → future). The semantic level features used to enhance the training framework of the CRF model are: • Role: For each token</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Proceedings of the International Conference on New Methods in Language Processing, pages 44–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mariona Taul´e</author>
<author>M Antonia Marti</author>
<author>Marta Recasens</author>
</authors>
<title>AnCora: Multilevel Annotated Corpora for Catalan and Spanish.</title>
<date>2008</date>
<editor>In ELRA, editor, LREC,</editor>
<location>Marrakech, Morocco.</location>
<marker>Taul´e, Marti, Recasens, 2008</marker>
<rawString>Mariona Taul´e, M. Antonia Marti, and Marta Recasens. 2008. AnCora: Multilevel Annotated Corpora for Catalan and Spanish. In ELRA, editor, LREC, Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert Gaizauskas</author>
<author>Mark Hepple</author>
<author>Frank Schilder</author>
<author>Graham Katz</author>
<author>James Pustejovsky</author>
</authors>
<title>Semeval-2007 task 15: Tempeval temporal relation identification.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations,</booktitle>
<pages>75--80</pages>
<publisher>ACL.</publisher>
<location>Prague.</location>
<contexts>
<context position="1204" citStr="Verhagen et al., 2007" startWordPosition="178" endWordPosition="181">ed the best F1 in tasks B (events) and D (event-dct links); and was among the best systems in the rest. 1 Introduction The automatic treatment of time expressions, events and their relations over natural language text consists of making temporal elements explicit through a system that identifies and annotates them following a standard scheme. This information is crucial for other natural language processing (NLP) areas, such as summarization or question answering. The relevance of temporal information has been reflected in specialized conferences (Schilder et al., 2007) and evaluation forums (Verhagen et al., 2007). We present a system to tackle the six different tasks related to multilingual temporal information treatment proposed in TempEval-2. Particularly, in this evaluation exercise, TimeML (Pustejovsky et al., 2003) is adopted as temporal annotation scheme. In this manner, the tasks require participating systems to automatically annotate different TimeML elements. Firstly, task A consists of determining the extent of time expressions as defined by the TimeML TIMEX3 tag, as well as the attributes “type” and “value”. Secondly, task B addresses the recognition and classification of events as defined </context>
</contexts>
<marker>Verhagen, Gaizauskas, Hepple, Schilder, Katz, Pustejovsky, 2007</marker>
<rawString>Marc Verhagen, Robert Gaizauskas, Mark Hepple, Frank Schilder, Graham Katz, and James Pustejovsky. 2007. Semeval-2007 task 15: Tempeval temporal relation identification. In Proceedings of the 4th International Workshop on Semantic Evaluations, pages 75–80, Prague. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Piek Vossen</author>
</authors>
<title>EuroWordNet: a multilingual database with lexical semantic networks.</title>
<date>1998</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>MA, USA.</location>
<contexts>
<context position="9487" citStr="Vossen, 1998" startWordPosition="1499" endWordPosition="1500">ls especially on the numbered roles (A0, A1, etc.) meaning different things when depending on different verbs. • Role configuration: This feature is only present in verb tokens heading a sentence or sub-sentence. This consists of the set of roles depending on the verb. This may be particularly useful for distinguish different sentence settings. • Lexical semantics: WordNet (Fellbaum, 1998) top ontology classes have been widely used to represent word meaning at ontological level, and demonstrated its worth in many tasks. TIPSem uses the top four classes for each word. For Spanish, EuroWordNet (Vossen, 1998) was used. In this manner, given a list of tokens and its features, the trained recognition model will assign to each token one of the valid labels. For instance, in the case of TIMEX3 recognition: B-TIMEX3, I-TIMEX3 or O. 3.2 Classification Classification features, used to get TIMEX3 types and EVENT classes, are basically the same as the ones used for recognition. However, the main difference is that the features are not obtained at token level but at TIMEX3 or EVENT level. This implies that the word context is set to the extent of each element (TIMEX3 and EVENT), as well as all the features </context>
</contexts>
<marker>Vossen, 1998</marker>
<rawString>Piek Vossen. 1998. EuroWordNet: a multilingual database with lexical semantic networks. Kluwer Academic Publishers, MA, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>