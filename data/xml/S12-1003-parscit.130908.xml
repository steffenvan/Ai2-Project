<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.019959">
<title confidence="0.991544">
Measuring Semantic Relatedness using Multilingual Representations
</title>
<author confidence="0.986356">
Samer Hassan Carmen Banea Rada Mihalcea
</author>
<affiliation confidence="0.997195">
University of North Texas University of North Texas University of North Texas
</affiliation>
<address confidence="0.647234">
Denton, TX Denton, TX Denton, TX
</address>
<email confidence="0.998988">
samer@unt.edu carmenbanea@my.unt.edu rada@cs.unt.edu
</email>
<sectionHeader confidence="0.997391" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999594">
This paper explores the hypothesis that se-
mantic relatedness may be more reliably in-
ferred by using a multilingual space, as com-
pared to the typical monolingual representa-
tion. Through evaluations using several state-
of-the-art semantic relatedness systems, ap-
plied on standard datasets, we show that a
multilingual approach is better suited for this
task, and leads to improvements of up to 47%
with respect to the monolingual baseline.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999122208333333">
Semantic relatedness is the task of quantifying the
strength of the semantic connection between tex-
tual units, be they words, sentences, or documents.
For instance, one may want to determine how se-
mantically related are two words such as car and
automobile, or two pieces of text such as I love an-
imals and I own a pet. It is one of the main tasks
explored in the field of natural language processing,
as it lies at the core of a large number of applica-
tions such as information retrieval (Ponte and Croft,
1998), query reformulation (Metzler et al., 2007;
Yih and Meek, 2007; Sahami and Heilman, 2006;
Broder et al., 2008), image retrieval (Leong and Mi-
halcea, 2009; Goodrum, 2000), plagiarism detection
(Hoad and Zobel, 2003; Shivakumar and Garcia-
Molina, 1995; Broder et al., 1997; Heintze, 1996;
Brin et al., 1995; Manber, 1994), information flow
(Metzler et al., 2005), sponsored search (Broder et
al., 2008), short answer grading (Mohler and Mihal-
cea, 2009a; Pulman and Sukkarieh, 2005; Mitchell
et al., 2002), and textual entailment (Dagan et al.,
2005).
The typical approach to semantic relatedness is to
either measure the distance between the constituent
</bodyText>
<page confidence="0.917546">
20
</page>
<bodyText confidence="0.999945552631579">
words by using a knowledge base such as Word-
Net or Roget (e.g., (Leacock and Chodorow, 1998;
Lesk, 1986; Jarmasz and Szpakowicz, 2003; Peder-
sen et al., 2004)), or to calculate the similarity be-
tween the word distributions in very large corpora
(e.g., (Landauer et al., 1991; Lin, 1998; Gabrilovich
and Markovitch, 2007)). With almost no exception,
these methods have been applied on one language at
a time – English, most of the time, although mea-
sures of relatedness have also been explored on lan-
guages such as German (Zesch et al., 2007), Chinese
(Li et al., 2005), Japanese (Kazama et al., 2010), and
others.
In this paper, we take a step further and ex-
plore a joint multilingual semantic relatedness met-
ric, which aggregates semantic relatedness scores
measured on several different languages. Specifi-
cally, in our method, in order to measure the re-
latedness of two textual units, we first determine
their relatedness in multiple languages, and conse-
quently infer a final relatedness score by averaging
the scores calculated in the individual languages.
Our hypothesis is that a multilingual representa-
tion can enrich the relatedness space and address
relevant issues such as polysemy (i.e., find that two
occurrences of the same word in language L1 rep-
resent two different meanings because of different
translations in language L2) and synonymy (i.e., find
that two words in language L1 are related because
they have the same translation in language L2). We
show that by measuring relatedness in a multilingual
space, we are able to improve over a traditional re-
latedness measure that relies exclusively on a mono-
lingual representation.
Through experiments using several state-of-the-
art measures of relatedness, applied on a multilin-
gual space including English, Arabic, Spanish, and
Romanian, we aim to answer the following research
</bodyText>
<note confidence="0.956721">
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 20–29,
Montr´eal, Canada, June 7-8, 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.998911285714286">
questions: (1) Does the task of semantic relatedness
benefit from a multilingual representation, as com-
pared to a monolingual one? (2) Does the translation
quality affect the results? and (3) Do the findings
hold for different relatedness datasets?
The paper is organized as follows. First, we
overview related work on word and text related-
ness, and on multilingual natural language process-
ing. We then briefly describe three corpus-based
measures of relatedness, and present several word
and text datasets that have been used in the past to
evaluate relatedness. We then present evaluations
and experiments addressing each of the three re-
search questions, and discuss our findings.
</bodyText>
<sectionHeader confidence="0.999944" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999963242424242">
Semantic relatedness. The approaches for seman-
tic relatedness that have been considered to date
can be grouped into knowledge-based and corpus-
based. Knowledge-based methods derive a measure
of relatedness by utilizing lexical resources and on-
tologies such as WordNet (Miller, 1995) to mea-
sure definitional overlap (Lesk, 1986), term dis-
tance within a graphical taxonomy (Leacock and
Chodorow, 1998), term depth in the taxonomy as a
measure of specificity (Wu and Palmer, 1994), and
others. The application of such measures to a lan-
guage other than English requires the availability of
the lexical resource in that language; furthermore,
even though taxonomies such as WordNet (Miller,
1995) are available in a number of languages1, their
coverage is still limited, and often times they are not
publicly available. For these reasons, in multilingual
settings, these measures often become untractable.
On the other side, corpus-based measures
such as Latent Semantic Analysis (LSA) (Lan-
dauer et al., 1991), Explicit Semantic Analy-
sis (ESA) (Gabrilovich and Markovitch, 2007),
Salient Semantic Analysis (SSA) (Hassan and Mi-
halcea, 2011), Pointwise Mutual Information (PMI)
(Church and Hanks, 1990), PMI-IR (Turney, 2001),
Second Order PMI (Islam and Inkpen, 2006), Hy-
perspace Analogues to Language (HAL) (Burgess
et al., 1998) and distributional similarity (Lin, 1998)
employ probabilistic approaches to decode the se-
mantics of words. They consist of unsupervised
methods that utilize the contextual information and
patterns observed in raw text to build semantic pro-
files of words, and thus they can be easily transferred
</bodyText>
<footnote confidence="0.949212">
1http://www.illc.uva.nl/EuroWordNet/
</footnote>
<bodyText confidence="0.999614479166667">
to a new language provided that a large corpus in that
language is available.
Multilingual natural language processing. Also
relevant is the work done on multilingual text pro-
cessing, which attempts to improve the performance
of different natural language processing tasks by
integrating information drawn from multiple lan-
guages. For instance, (Cohn and Lapata, 2007) ex-
plore the use of triangulation for machine transla-
tion, where multiple translation models are learned
using multilingual parallel corpora. The model was
found especially beneficial for languages where the
training dataset was small, thus suggesting that this
method may be particularly useful for languages
with scarce resources. (Davidov and Rappoport,
2009) experiment with the use of multiple languages
to enhance an existing lexicon. In their experiments,
using three source languages and 45 intermediate
languages, they find that the multilingual resources
can lead to significant improvements in concept ex-
pansion. (Banea et al., 2010) explore the use of
parallel multilingual corpora to improve subjectivity
classification in a target language, finding that the
use of multilingual representations for subjectivity
analysis improves over the monolingual classifiers.
Similarly, (Banea and Mihalcea, 2011) investigate
the use of multilingual contexts for word sense dis-
ambiguation. By leveraging on the translations of
the annotated contexts in multiple languages, a mul-
tilingual thematic space emerges that better disam-
biguates target words.
Finally, there are two lines of work that explore
semantic distances in a multilingual space. First,
(Besanc¸on and Rajman, 2002) examine the notion
that the distances between document vectors within
a language correlate with the distances between their
corresponding vectors in a parallel corpus. These
findings provide clues about the possibility of reli-
able semantic knowledge transfer across language
boundaries. Second, (Hassan and Mihalcea, 2009)
propose a framework to compute semantic relat-
edness between two words in different languages,
by considering Wikipedia articles in multiple lan-
guages. The method differs from the one proposed
here, as we aggregate relatedness over monolingual
spaces rather than measuring cross-lingual related-
ness, and we do not specifically use the inter-wiki
links between Wikipedia pages.
</bodyText>
<page confidence="0.99947">
21
</page>
<sectionHeader confidence="0.973775" genericHeader="method">
3 Measures of Text Relatedness
</sectionHeader>
<bodyText confidence="0.99858875">
In this work, we focus on corpus-based metrics
because of their unsupervised nature, their flexi-
bility, scalability, and portability to different lan-
guages. Specifically, we utilize three popular mod-
els, LSA (Landauer et al., 1991), ESA (Gabrilovich
and Markovitch, 2007), and SSA (Hassan and Mi-
halcea, 2011). In these models, the semantic profile
of a word is expressed in terms of the explicit (ESA),
implicit (LSA), or salient (SSA) concepts. All three
models are trained on the Wikipedia 2010 corpora
corresponding to the four languages of interest (En-
glish, Arabic, Spanish, Romanian).
</bodyText>
<subsectionHeader confidence="0.826715">
Explicit Semantic Analysis. ESA (Gabrilovich
</subsectionHeader>
<bodyText confidence="0.997767804878049">
and Markovitch, 2007) uses encyclopedic knowl-
edge in an information retrieval framework to gen-
erate a semantic interpretation of words. Since en-
cyclopedic knowledge is typically organized into
concepts (or topics), each concept is described us-
ing definitions and examples. ESA relies on the
distribution of words inside the encyclopedic de-
scriptions. It builds semantic representations for
a given word using a word-document association,
where each document represents a Wikipedia article.
In this vector representation, the semantic interpre-
tation of a text can be modeled as an aggregation of
the semantic vectors of its individual words.
Latent Semantic Analysis. In LSA (Landauer et
al., 1991), term-context associations are captured by
means of a dimensionality reduction operated by a
singular value decomposition (SVD) on the term-by-
context matrix T, where the matrix is induced from
a large corpus. This reduction entails the abstraction
of meaning by collapsing similar contexts and dis-
counting noisy and irrelevant ones, hence transform-
ing the real world term-context space into a word-
latent-concept space which achieves a much deeper
and concrete semantic representation of words.
Salient Semantic Analysis. SSA (Hassan and
Mihalcea, 2011) incorporates a similar semantic
abstraction and interpretation of words, by using
salient concepts gathered from encyclopedic knowl-
edge, where a concept is defined as an unambigu-
ous word or phrase with a concrete meaning, which
can afford an encyclopedic definition. The links
available between Wikipedia articles, obtained ei-
ther through manual annotation by the Wikipedia
users or using an automatic annotation process, are
regarded as clues or salient features within the text
that help define and disambiguate its context. This
method seeks to determine the semantic relatedness
of words by measuring the distance between their
concept-based profiles, where a profile consists of
co-occurring salient concepts found within a given
window size in a very large corpus.
</bodyText>
<sectionHeader confidence="0.998602" genericHeader="method">
4 Datasets
</sectionHeader>
<bodyText confidence="0.999958">
To evaluate the representation strength of a multilin-
gual semantic relatedness model we employ several
standard word-to-word and text-to-text datasets. For
each of these datasets, we make use of their repre-
sentation in the four languages of interest.
</bodyText>
<subsectionHeader confidence="0.998074">
4.1 Word Relatedness
</subsectionHeader>
<bodyText confidence="0.999950324324324">
We construct our multilingual word-to-word
datasets building upon three word relatedness
datasets that have been widely used in the past.
Rubenstein and Goodenough (Rubenstein and
Goodenough, 1965) (RG65) consists of 65 word
pairs ranging from synonymy pairs (e.g., car -
automobile) to completely unrelated words (e.g.,
noon - string). The participating terms in all the
pairs are non-technical nouns annotated by 51 hu-
man judges on a scale from 0 (unrelated) to 4 (syn-
onyms).
Miller-Charles (Miller and Charles, 1991) (MC30)
is a subset of RG65, consisting of 30 word pairs an-
notated for relatedness by 38 human subjects, using
the same 0 to 4 scale.
WordSimilarity-353 (Finkelstein et al., 2001)
(WS353), also known as Finkelstein-353, consists
of 353 word pairs annotated by 13 human experts,
on a scale from 0 (unrelated) to 10 (synonyms).
While containing the MC30 set, it poses an addi-
tional degree of difficulty by also including phrases
(e.g., “Wednesday news”), proper names and tech-
nical terms.
To enable a multilingual representation, we use
the multilingual datasets introduced by (Hassan and
Mihalcea, 2009), which are based upon MC30 and
WS353. These multilingual datasets are built us-
ing manual translations, following the same guide-
lines adopted for the generation and the annotation
of their original English counterparts. These manu-
ally translated collections, available in Arabic, Span-
ish, and Romanian, allow us to infer an upper bound
for the multilingual semantic relatedness model.
Moreover, in order to provide a more realistic
scenario, where manual translations are not avail-
able, we also create multilingual datasets by auto-
matically translating the three English datasets into
</bodyText>
<page confidence="0.976895">
22
</page>
<bodyText confidence="0.999904916666667">
Arabic, Spanish and Romanian.2 Similar to how the
manually translated datasets were created by provid-
ing the bilingual speakers with one word pair at a
time, for the automatic translation each word pair is
processed as a single query to the translation engine.
Thus, the co-occurrence metrics derived from large
corpora are able to play a role in providing a dis-
ambiguated translation instead of defaulting to the
most frequently used sense if the words were to be
processed individually. This allows for the embed-
ded word pair relatedness to be transferred to other
languages as well.
</bodyText>
<subsectionHeader confidence="0.994267">
4.2 Text Relatedness
</subsectionHeader>
<bodyText confidence="0.999775514285714">
We use three standard text-to-text datasets.
Lee50 (Lee and Welsh, 2005) is a compilation of
50 documents collected from the Australian Broad-
casting Corporation’s news mail service. Each doc-
ument is scored by ten annotators on a scale from 1
(unrelated) to 5 (alike) based on its semantic related-
ness to all the other documents. The users’ annota-
tion is then averaged per document pair, resulting in
2,500 document pairs annotated with their similarity
scores. Since it was found that there was no signif-
icant difference between annotations given a differ-
ent order of the documents in a pair (Lee and Welsh,
2005), the evaluations are carried out on only 1225
document pairs after ignoring duplicates.
Li30 (Li et al., 2006) is a sentence pair similar-
ity dataset obtained by replacing each of the RG65
word-pairs with their respective definitions extracted
from the Collins Cobuild dictionary (Sinclair, 2001).
Each sentence pair was scored between 0 (unrelated)
to 4 (alike) by 32 native English speakers, and their
annotations were averaged. Due to the skew in the
scores toward low similarity sentence-pairs, they se-
lected a subset of 30 sentences from the 65 sentence
pairs to maintain an even relatedness distribution.
AG400 (Mohler and Mihalcea, 2009b) is a domain
specific dataset from the field of computer science,
used to evaluate the application of semantic relat-
edness measures to real world applications such as
short answer grading. We employ the version pro-
posed by (Hassan and Mihalcea, 2011) which con-
sists of 400 student answers along with the corre-
sponding questions and correct instructor answers.
Each student answer was graded by two judges on
a scale from 0 (completely wrong) to 5 (perfect an-
swer). The correlation between human judges was
</bodyText>
<footnote confidence="0.60809">
2For all the automatic translations we used the Google
Translate service.
</footnote>
<bodyText confidence="0.999512842105263">
measured at 0.64.
First, we construct a multilingual, manually trans-
lated text-to-text relatedness dataset based on the
standard Li30 corpus.3 Native speakers of Spanish,
Romanian and Arabic, who were also highly profi-
cient in English, were asked to translate the entries
drawn from the English collection. They were pre-
sented with one sentence at a time, and asked to pro-
vide the appropriate translation into their native lan-
guage. Since we had five Spanish, two Arabic, and
two Romanian translators, an arbitrator (native to the
language) was charged with merging the candidate
translations by proposing one sentence per language.
Furthermore, to test the abstraction of semantics
from the choice of underlying language, we asked
three different Spanish human experts to re-score the
Spanish text-pair translations on the same scale used
in the construction of the English collection. The
correlation between the relatedness scores assigned
during this experiment and the scores assigned to the
original English experiment was 0.77 − 0.86, indi-
cating that the translations provided by the bilingual
judges were correct and preserved the semantics of
the original English text-pairs. As was the case
for the manually constructed word-to-word datasets
previously described, the metrics obtained on the
manually translated Li30 dataset will also act as an
upper bound for the text-to-text evaluations.
Finally, for a more sensible scenario where the
text fragments do not require manual translations
in order to compute their semantic relatedness, we
create a multilingual version of the three English
datasets by employing statistical machine translation
to translate the texts into the other three languages.
Each text pair was processed through two separate
queries to the translation engine, since the two text
fragments contain sufficient information to prompt
an in-context translation on their own.
</bodyText>
<sectionHeader confidence="0.997178" genericHeader="method">
5 Framework
</sectionHeader>
<bodyText confidence="0.999700125">
We generate SSA, LSA and ESA vectorial models
for English, Romanian, Arabic, and Spanish, using
the same Wikipedia 2010 versions for all the sys-
tems (e.g., the SSA, LSA and ESA relatedness
measures for Spanish are all trained on the same
Spanish Wikipedia version).
We construct a multilingual model by considering
a word- or text-pair from a source language along
</bodyText>
<footnote confidence="0.9904615">
3Dataset is available for download at lit.csci.unt.
edu/index.php?P=research/downloads
</footnote>
<page confidence="0.998083">
23
</page>
<bodyText confidence="0.999907">
with its translations in the other languages. To eval-
uate this multilingual model in a way that reduces
the bias that may arise from choosing one language
over the other, we do the following: we start from a
source language and generate all the possible combi-
nations of this language with the available language
set {ar, en, es, rol. Within each combination, we
average the monolingual model scores for the lan-
guages in this combination with respect to the target
word- or text-pair into a final relatedness score.
For example, let us consider Spanish as the source
language, then the possible combinations of the lan-
guages that include the source language will be
{{esl, {es, arl, {es, rol, {es, enl, {es, ar, enl,
{es, ar, rol, {es, en, rol, and {es, ar, en, roll.
For each possible combination, we aggregate the
scores of the languages in that combination. In this
setting, a combination of size (cardinality) one will
always be the source language and will serve as the
baseline. For every combination (e.g. {es, arl),
we average the individual monolingual relatedness
scores for a given word- or text-pair in this set.
Finally, to calculate the overall correlation of
these generated multilingual models (one system per
combination size) with the human scores, we av-
erage the correlation scores achieved over all the
datasets in a given combination (e.g., {es, arl) with
all correlation scores achieved under other combina-
tions of the same size (e.g., {es, rol, {es, enl). This
in effect allows us to observe the cumulative perfor-
mance irrespective of language choice, as we extend
the multilingual model to include more languages.
Formally, let N be the number of languages, Cn
be the set of all language combinations of size n, and
ci be one of the possible combinations of size n,
then the relatedness of a word- or text-pair p from
the dataset P under this combination can be repre-
sented as:
where Siml(p) is the relatedness score of the word-
or text-pair p in the monolingual model of language
l. To evaluate the performance of the multilingual
model, let Di be the generated relatedness distribu-
tion for the dataset P using the combination ci:
</bodyText>
<equation confidence="0.974097">
Di = {(p, Simci(p))  |p E Pl. (3)
</equation>
<bodyText confidence="0.999539333333333">
Then, the correlation between the gold standard
distribution G and the generated scores can be cal-
culated as follows:
</bodyText>
<equation confidence="0.68506">
1 CorrelCn(D, G) = |Cn |ciECn Correlci(Di, G),
(4)
</equation>
<bodyText confidence="0.997381666666667">
where Correl can stand for Pearson (r), Spearman
(p), or their harmonic mean (µ), as also reported in
(Hassan and Mihalcea, 2011).
</bodyText>
<sectionHeader confidence="0.999102" genericHeader="method">
6 Evaluations
</sectionHeader>
<bodyText confidence="0.999140923076923">
In this section we revisit the questions formulated in
the introduction, and based on different experiment
setups following the framework introduced in Sec-
tion 5, we provide an answer to each one of them.
Does the task of semantic relatedness benefit
from a multilingual representation? We evalu-
ate the three semantic relatedness models, namely
LSA, ESA and SSA on our manually constructed
multilingual word relatedness (MC30, WS353)
and text relatedness datasets (LI30), as described in
Section 4.
Figure 1 plots the correlation scores achieved
across all the languages against the gold stan-
dard and then averaged across all the multilingual
datasets. The figure shows a clear and steady im-
provement (25% - 28% with respect to the mono-
lingual baseline) achieved when more languages are
incorporated into the relatedness model. It is worth
noting that both the Pearson and Spearman correla-
tions exhibit the same improvement pattern, which
confirms our hypothesis that adding more languages
has a positive impact on the relatedness scores. The
fact that this trend is visible across all the systems
supports the idea that a multilingual representation
constitutes a better model for determining semantic
relatedness. Furthermore, we notice that SSA is the
best performing system under these settings, with a
correlation improvement of approximately 15%.
To further analyze the role of the multilingual
model and to explore whether some languages ben-
efit from using this abstraction more than others,
we plot the correlation scores achieved by the indi-
vidual languages averaged over all the systems and
the datasets in Figure 2. We notice a sharp rise in
performance associated with the addition of more
languages to the Arabic (42%) and the Romanian
(47%) models, and a slower rise for Spanish (23%).
The performance of English is also affected, but on
a smaller scale (4%) when compared to the other
</bodyText>
<equation confidence="0.996945333333333">
Cn = {ci  ||ci |= n, 0 &lt; i &lt; l
(N )
(1)
n
1 Simci (p) = |c  |E Siml (p) (2)
lEci
</equation>
<page confidence="0.993244">
24
</page>
<figure confidence="0.985961">
1 2 3 4
Number of Languages
</figure>
<figureCaption confidence="0.946949333333333">
Figure 1: Manual translation - average correlation (p,
r, p) obtained from incorporating scores from models in
other languages
</figureCaption>
<figure confidence="0.990769">
1 2 3 4
Number of Languages
</figure>
<figureCaption confidence="0.984849666666667">
Figure 2: Manual translation - average correlation (p,
r, p) obtained by supplementing a source language with
scores from other languages
</figureCaption>
<figure confidence="0.989867674418604">
0.9
0.8
0.7
0.6
0.5
0.4
0.3
µ
0.8
0.6
0.4
1 2 3 4
r
0.8
0.6
0.4
1 2 3 4
ESA
LSA
SSA
ρ
0.9
0.8
0.7
0.6
0.5
0.4
0.3
µ
0.8
0.6
0.4
1 2 3 4
r
0.8
0.6
0.4
1 2 3 4
ρ
ar
en
es
ro
</figure>
<bodyText confidence="0.995556586206896">
languages. Not surprisingly, this correlates with the
size of each corpus, where Arabic and Romanian are
the smallest, while English is the largest.
The results support the notion that resource poor
languages can benefit from languages with richer
and larger resources, such as English or Spanish.
Furthermore, incorporating additional languages to
English also leads to small improvements, which in-
dicates that the benefit, while disproportionate, is
mutual.
Does the quality of translations affect the results?
As a natural next step, we investigate the role played
by the manual translations in the performance of the
multilingual model. Since the previous evaluations
require the availability of the word- or text-pairs
in multiple languages, we attempt to see if we can
eliminate this restriction by automating the trans-
lation process using statistical machine translation
(MT). Therefore, for a multilingual model employ-
ing automated settings, the manual models proposed
previously constitute an upper bound.
We use the Google MT engine4 to translate our
multilingual datasets into the target languages (en,
es, ar, and ro). We then repeat all the evaluations
using the newly constructed datasets.
Figure 3 shows the correlation scores achieved
across all the languages and averaged across all the
multilingual datasets constructed using automatic
translation. We again see a clear and steady im-
</bodyText>
<footnote confidence="0.956709">
4This API is now offered as a paid service; Microsoft or
Babelfish automatic translation services are publicly available.
</footnote>
<bodyText confidence="0.99990259375">
provement (12% - 35% with respect to the mono-
lingual baseline) similar to the observed pattern in
the corresponding manual evaluations (Figure 1).
While the overall achieved performance for SSA
has dropped (from p = 0.793 to p = 0.71) when
compared to the manual settings, we are still able
to improve over the baseline (p = 0.635). LSA
seems to experience the highest relative improve-
ment (35%), which might be due to its ability to
handle noise in these automatic settings. Over-
all Pearson and Spearman correlations exhibit the
same improvement pattern, which supports the no-
tion that even with the possibility of introducing
noise through miss-translations, the models overall
benefit from the additional clues provided by the
multilingual representation.
To explore the effect of automatic translation on
the individual languages, we plot the correlation
scores achieved vis-`a-vis a reference language, and
average over all the systems and the automatically
translated datasets in Figure 4, in a similar fashion
to Figure 2.
We notice the similar rise in performance asso-
ciated with the addition of more languages to the
Arabic (20%) and the Romanian (37%) models, and
a slower rise for Spanish (16%) and English (8%).
The effect of the automatic translation quality is ev-
ident for the Arabic language where the automatic
translation seems to slow down the improvement
when compared to the manual translations (Figure
2). A similar behavior is also observed in Spanish
and Romanian but on a lower scale.
</bodyText>
<page confidence="0.989145">
25
</page>
<figure confidence="0.994278">
1 2 3 4
Number of Languages
</figure>
<figureCaption confidence="0.954994666666667">
Figure 3: Automatic translation - average correlation (p,
r, p) obtained from incorporating scores from models in
other languages
</figureCaption>
<figure confidence="0.9950165">
1 2 3 4
Number of Languages
</figure>
<figureCaption confidence="0.990176">
Figure 4: Automatic translation - average correlation (p,
r, p) obtained by supplementing a source language with
scores from other languages
</figureCaption>
<figure confidence="0.998103627906977">
0.9
0.8
0.7
0.6
0.5
0.4
0.3
µ
0.8
0.6
0.4
1 2 3 4
r
0.8
0.6
0.4
2 3 4
ESA
LSA
SSA
ρ
µ
0.8
0.6
0.4
1 2 3 4
r
0.8
0.6
0.4
1 2 3 4
ρ
ar
en
es
ro
0.9
0.8
0.7
0.6
0.5
0.4
0.3
</figure>
<bodyText confidence="0.986371133333333">
A very interesting consideration is that English
experiences a stronger improvement when using au-
tomatic translations (8%) compared to manual trans-
lations (4%). This can be attributed to the trans-
lation engine quality in transferring English text to
other languages and to the fact that the statistical
translation (when accurate) can lead to a transla-
tion that makes use of more frequently used words,
which contribute to more robust relatedness mea-
sures. When presented with a word pair, human
judges may provide a translation influenced by the
form/root of the word in the source language, which
may not be as commonly used as the output of a
MT system. For example, when presented with the
pair “coast - shore,” a Romanian translator may be
tempted to provide “coast˘a” as a translation candi-
date for the first word in the pair, as it resembles the
English word in form. However, the Romanian word
is highly ambiguous, and in an authoritative Roma-
nian dictionary5 its primary sense is that of rib, fol-
lowed by side, slope, and ultimately coast. Thus, a
MT system using a statistical inference may provide
a stronger translation such as “t¸˘arm” that is far less
ambiguous, and whose primary meaning is the one
intended by the original pair.
Overall, the trend is positive and follows the
pattern previously observed on the manually con-
structed datasets. This suggests that an automatic
translation, even if more noisy, is beneficial and pro-
vides a way to reinforce semantic relatedness in a
</bodyText>
<footnote confidence="0.791312">
5http://dexonline.ro/definitie/coasta
</footnote>
<bodyText confidence="0.999817419354839">
given language with information coming from mul-
tiple languages with no manual effort.
Do our findings hold for different relatedness
datasets? At last, encouraged by the small perfor-
mance difference between the use of manual ver-
sus automatic translations, we seek to explore how
this multilingual model behaves under the different
paradigms dictated by word relatedness versus text
relatedness scenarios. Since our previous experi-
ments were constrained to collections for which we
also had a manual translation, we perform a larger
scale evaluation by including automatically trans-
lated word relatedness (RG65) and text relatedness
(LEE50 and AG400) datasets into all the languages
in our language set, and repeat all the word-to-word
and text-to-text evaluations.
Table 1 shows the correlation scores achieved us-
ing automatic translations on the word relatedness
datasets. Most models on most datasets benefit from
the multilingual representation (as shown by the fig-
ures in bold). Specifically, the SSA model has an
improvement in p of 26% for WS353 and 15% for
MC30. This improvement is most evident in the
case of the largest dataset WS353, where all the
multilingual models exhibit a consistent and strong
performance.
Table 2 reports the results obtained for the text
relatedness datasets using automatic translation.
While the ESA performance suffers in the multi-
lingual model, it is overshadowed by the improve-
ment experienced by LSA and SSA. The multilin-
</bodyText>
<page confidence="0.990898">
26
</page>
<table confidence="0.999023125">
r p p
Models MC30 RG65 WS353 MC30 RG65 WS353 MC30 RG65 WS353
ESA,,,, 0.645 0.644 0.487 0.742 0.768 0.525 0.690 0.701 0.506
ESA,,,,l 0.723 0.741 0.515 0.766 0.759 0.519 0.744 0.75 0.517
LSA,,,, 0.509 0.450 0.435 0.525 0.499 0.436 0.517 0.473 0.436
LSA,,,,l 0.538 0.566 0.487 0.484 0.569 0.517 0.510 0.567 0.502
SSA,,,, 0.771 0.824 0.543 0.688 0.772 0.553 0.727 0.797 0.548
SSA,,,,l 0.873 0.807 0.674 0.803 0.795 0.713 0.836 0.801 0.693
</table>
<tableCaption confidence="0.993897">
Table 1: Automatic translation - r, p, p correlations on the word relatedness datasets using multilingual models.
</tableCaption>
<table confidence="0.99710125">
r p p
Models LI30 LEE50 AG400 LI30 LEE50 AG400 LI30 LEE50 AG400
ESA,,,, 0.792 0.756 0.434 0.797 0.48 0.392 0.795 0.587 0.412
ESA,,,,l 0.776 0.648 0.382 0.742 0.339 0.358 0.759 0.445 0.369
LSA,,,, 0.829 0.776 0.400 0.824 0.523 0.359 0.826 0.625 0.379
LSA,,,,l 0.856 0.765 0.46 0.855 0.502 0.404 0.856 0.606 0.43
SSA,,,, 0.840 0.744 0.520 0.843 0.371 0.501 0.841 0.495 0.510
SSA,,,,l 0.829 0.743 0.539 0.87 0.41 0.521 0.849 0.528 0.53
</table>
<tableCaption confidence="0.999255">
Table 2: Automatic translation - r, p, p correlations on the text relatedness datasets using multilingual models.
</tableCaption>
<bodyText confidence="0.999779684210526">
gual model reports some of the best scores in the
literature, such as a correlations of r = 0.856 and
p = 0.87 for LI30 achieved by LSA and SSA, re-
spectively. Not surprisingly, SSA is still a top con-
tender, achieving the highest scores for AG400 and
LI30. In AG400, SSA reports a p of 0.53 which
represents a 4% improvement over the English SSA
model (p = 0.51) and a 16% improvement over the
best knowledge-based system J&amp;C (p = 0.457).
It is important to note that the evaluation in Ta-
bles 1 and 2 are restricted to data translated from En-
glish into a target language. English, as a resource-
rich language, has an extensive and robust monolin-
gual model, yet it can still be enhanced with addi-
tional clues originating from other languages. Ac-
cordingly, we only expected small improvements in
these two experiments, unlike the cases where we
start from resource-poor languages such as Roma-
nian or Arabic (see Figures 2 and 4).
</bodyText>
<sectionHeader confidence="0.998919" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999983444444445">
In this paper, we showed how a semantic relatedness
measure computed in a multilingual space is able
to acquire and leverage additional information from
the multilingual representation, and thus be strength-
ened as more languages are taken into considera-
tion. Our experiments seem to suggest that combi-
nations of multiple languages supply additional in-
formation to derive a semantic relatedness between
texts in an automatic framework. Since establishing
semantic relatedness requires us to employ cogni-
tive processes that are in large part independent of
the language that we speak, it comes at no surprise
that using relatedness clues originating from more
than one language allows for a better identification
of relationships between texts. While efficiency may
be a concern, it is worth noting that the method is
highly parallelizable, as the individual relatedness
measures obtained before the aggregation step can
be calculated in parallel.
Notably, all the relatedness measures that we ex-
perimented with exhibited the same improvement
trend. While this framework allows languages with
scarce electronic resources, such as Romanian and
Arabic, to obtain very large improvements in seman-
tic relatedness as compared to the monolingual mea-
sures, improvements are also noticed for languages
with richer resources such as English.
</bodyText>
<sectionHeader confidence="0.998137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999650142857143">
This material is based in part upon work sup-
ported by the National Science Foundation CA-
REER award #0747340 and IIS award #1018613.
Any opinions, findings, and conclusions or recom-
mendations expressed in this material are those of
the authors and do not necessarily reflect the views
of the National Science Foundation.
</bodyText>
<page confidence="0.997396">
27
</page>
<sectionHeader confidence="0.996412" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999705807692308">
C. Banea and R. Mihalcea. 2011. Word sense disam-
biguation with multilingual features. In International
Conference on Semantic Computing, Oxford, UK.
C. Banea, R. Mihalcea, and J. Wiebe. 2010. Multilingual
subjectivity: Are more languages better? In Proceed-
ings of the 23rd International Conference on Compu-
tational Linguistics (Coling 2010), pages 28–36, Bei-
jing, China, August.
R. Besanc¸on and M. Rajman. 2002. Evaluation of a vec-
tor space similarity measure in a multilingual frame-
work. In Proceedings of the Third International Con-
ference on Language Resource and Evaluation (LREC
2002), Las Palmas, Spain.
S. Brin, J. Davis, and H. Garcia-Molina. 1995. Copy de-
tection mechanisms for digital documents. In ACMIn-
ternational Conference on Management ofData (SIG-
MOD 1995).
A. Z. Broder, S. C. Glassman, M. S. Manasse, and
G. Zweig. 1997. Syntactic clustering of the web.
Comput. Netw. ISDN Syst., 29(8-13):1157–1166.
A Z. Broder, P. Ciccolo, M. Fontoura, E. Gabrilovich,
V. Josifovski, and L. Riedel. 2008. Search advertising
using web relevance feedback. In CIKM ’08: Pro-
ceeding of the 17th ACM conference on Information
and knowledge management, pages 1013–1022, New
York, NY, USA. ACM.
C. Burgess, K. Livesay, and K. Lund. 1998. Explorations
in context space: words, sentences, discourse. Dis-
course Processes, 25(2):211–257.
K. Church and P. Hanks. 1990. Word association norms,
mutual information, and lexicography. Computational
Linguistics, 16(1):22–29.
T. Cohn and M. Lapata. 2007. Machine translation by
triangulation: making effective use of multi-parallel
corpora. In Proceedings of the 45th Annual Meeting
of the Association of Computational Linguistics, pages
728–735, Prague, Czech Republic.
I. Dagan, O. Glickman, and B. Magnini. 2005. The PAS-
CAL recognising textual entailment challenge. In Pro-
ceedings of the PASCAL Workshop.
D. Davidov and A. Rappoport. 2009. Enhancement
of lexical concepts using cross-lingual web mining.
In Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing, pages 852–
861, Singapore.
L. Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin,
Z. Solan, G. Wolfman, and E. Ruppin. 2001. Plac-
ing search in context: the concept revisited. In ACM
Press, editor, The Tenth International World Wide Web
Conference, pages 406–414, Hong Kong.
E. Gabrilovich and S. Markovitch. 2007. Computing
semantic relatedness using Wikipedia-based explicit
semantic analysis. In Proceedings of the 20th Inter-
national Joint Conference on Artificial Intelligence,
pages 1606–1611, Hyderabad, India.
A. Goodrum. 2000. Image information retrieval: An
overview of current research. Informing Science,
3(2):63–66.
S. Hassan and R. Mihalcea. 2009. Cross-lingual seman-
tic relatedness using encyclopedic knowledge. In Pro-
ceedings of the 2009 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1192–
1201, Singapore. Association for Computational Lin-
guistics.
S. Hassan and R. Mihalcea. 2011. Measuring semantic
relatedness using salient encyclopedic concepts. Arti-
ficial Intelligence, Special Issue, xx(xx).
N. Heintze. 1996. Scalable document fingerprinting. In
In Proc. USENIX Workshop on Electronic Commerce.
T. C. Hoad and J. Zobel. 2003. Methods for identifying
versioned and plagiarized documents. J. Am. Soc. Inf.
Sci. Technol., 54(3):203–215.
A. Islam and D. Inkpen. 2006. Second order co-
occurrence PMI for determining the semantic similar-
ity of words. In Proceedings of the Fifth Conference
on Language Resources and Evaluation, volume 2,
Genoa, Italy, July.
M. Jarmasz and S. Szpakowicz. 2003. Roget’s thesaurus
and semantic similarity. In Proceedings of the confer-
ence on Recent Advances in Natural Language Pro-
cessing RANLP-2003, Borovetz, Bulgaria, September.
J. Kazama, S. De Saeger, K. Kuroda, M. Murata, and
K. Torisawa. 2010. A bayesian method for robust
estimation of distributional similarities. In Proceed-
ings of the 48th Annual Meeting of the Association for
Computational Linguistics, Uppsala, Sweden.
T. K. Landauer, D. Laham, B. Rehder, and M. E.
Schreiner. 1991. How well can passage meaning be
derived without using word order? A comparison of
latent semantic analysis and humans. In Proceedings
of the 19th annual meeting of the Cognitive Science
Society, pages 412–417, Mawhwah, N. Erlbaum.
C. Leacock and M. Chodorow, 1998. Combining local
context and WordNet similarity for word sense identi-
fication, pages 305–332.
M. D. Lee and M. Welsh. 2005. An empirical evaluation
of models of text document similarity. In Proceedings
of the 27th annual meeting of the Cognitive Science
Society, pages 1254–1259, Stresa, Italy.
C. W. Leong and R. Mihalcea. 2009. Explorations in
automatic image annotation using textual features. In
Proceedings of the Third Linguistic Annotation Work-
shop, pages 56–59, Suntec, Singapore, August. Asso-
ciation for Computational Linguistics.
</reference>
<page confidence="0.976597">
28
</page>
<reference confidence="0.999881595959596">
M. Lesk. 1986. Automatic sense disambiguation using
machine readable dictionaries. In Proceedings of the
5th annual international conference on Systems docu-
mentation - SIGDOC ’86, pages 24–26, Toronto, On-
tario. ACM Press.
W. Li, Q. Lu, and R. Xu. 2005. Similarity based chinese
synonym collocation extraction. International Journal
of Computational Linguistics and Chinese Language
Processing, 10(1).
Y. Li, D. McLean, Z. A. Bandar, J. D. O’Shea, and
K. Crockett. 2006. Sentence similarity based on se-
mantic nets and corpus statistics. IEEE Transactions
on Knowledge and Data Engineering, 18(8):1138–
1150, August.
D. Lin. 1998. An information-theoretic definition of
similarity. In Proceedings of the Fifteenth Interna-
tional Conference on Machine Learning, pages 296–
304, Madison, Wisconsin.
U. Manber. 1994. Finding similar files in a large file sys-
tem. In USENIX WINTER 1994 TECHNICAL CON-
FERENCE, pages 1–10.
D. Metzler, Y. Bernstein, W. Bruce Croft, A. Moffat,
and J. Zobel. 2005. Similarity measures for track-
ing information flow. In CIKM ’05: Proceedings
of the 14th ACM international conference on Infor-
mation and knowledge management, pages 517–524,
New York, NY, USA. ACM.
D. Metzler, S. T. Dumais, and C. Meek. 2007. Similarity
measures for short segments of text. In Giambattista
Amati, Claudio Carpineto, and Giovanni Romano, edi-
tors, ECIR, volume 4425 of Lecture Notes in Computer
Science, pages 16–27. Springer.
G. A. Miller and W. G. Charles. 1991. Contextual corre-
lates of semantic similarity. Language and Cognitive
Processes, 6(1):1–28.
G. A. Miller. 1995. WordNet: a Lexical database for
english. Communications of the Association for Com-
putingMachinery, 38(11):39–41.
T. Mitchell, T. Russell, P. Broomhead, and N. Aldridge.
2002. Towards robust computerised marking of free-
text responses. In roceedings of the 6th Interna-
tional Computer Assisted Assessment (CAA) Confer-
ence, Loughborough, UK. Loughborough University.
M. Mohler and R. Mihalcea. 2009a. Text-to-text seman-
tic similarity for automatic short answer grading. In
EACL, pages 567–575. The Association for Computer
Linguistics.
M. Mohler and R. Mihalcea. 2009b. Text-to-text seman-
tic similarity for automatic short answer grading. In
Proceedings of the 12th Conference of the European
Chapter of the Association for Computational Linguis-
tics, pages 567–575, Stroudsburg, PA, USA.
T. Pedersen, S. Patwardhan, and J. Michelizzi. 2004.
WordNet::Similarity - measuring the relatedness of
concepts. In Proceedings of the Nineteenth Na-
tional Conference on Artificial Intelligence (AAAI-04),
demonstrations, San Jose, CA.
J. Ponte and W. Croft. 1998. A language modeling ap-
proach to information retrieval. In Proceedings of the
Annual International SIGIR Conference on Research
and Development in Information Retrieval, pages 275–
281, Melbourne, Australia.
S. G. Pulman and J. Z. Sukkarieh. 2005. Automatic
short answer marking. In EdAppsNLP 05: Proceed-
ings of the second workshop on Building Educational
Applications Using NLP, pages 9–16, Morristown, NJ,
USA. Association for Computational Linguistics.
H. Rubenstein and J. B. Goodenough. 1965. Contextual
correlates of synonymy. Communications of the ACM,
8(10):627–633, October.
M. Sahami and T. D. Heilman. 2006. A web-based ker-
nel function for measuring the similarity of short text
snippets. In WWW ’06: Proceedings of the 15th inter-
national conference on World Wide Web, pages 377–
386, New York, NY, USA. ACM.
N. Shivakumar and H. Garcia-Molina. 1995. Scam: A
copy detection mechanism for digital documents. In
2nd International Conference in Theory and Practice
ofDigital Libraries (DL 1995).
J. Sinclair. 2001. Collins cobuild English dictionary for
advanced learners. Harper Collins, 3rd edition.
P. D. Turney. 2001. Mining the Web for Synonyms:
PMI-IR versus LSA on TOEFL. In Proceedings of
the 12th European Conference on Machine Learning,
pages 491–502, Freiburg, Germany.
Z. Wu and M. Palmer. 1994. Verbs semantics and lexical
selection. In Proceedings of the 32nd annual meeting
on Association for Computational Linguistics, pages
133—-138, Las Cruces, New Mexico.
W. T. Yih and C. Meek. 2007. Improving similarity mea-
sures for short segments of text. In AAAI’07: Pro-
ceedings of the 22nd national conference on Artificial
intelligence, pages 1489–1494. AAAI Press.
T. Zesch, I. Gurevych, and M. M¨uhlh¨auser. 2007. Com-
paring Wikipedia and German Wordnet by Evaluating
Semantic Relatedness on Multiple Datasets. In Pro-
ceedings of Human Language Technologies: The An-
nual Conference of the North American Chapter of the
Association for Computational Linguistics.
</reference>
<page confidence="0.999115">
29
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.960228">
<title confidence="0.999903">Measuring Semantic Relatedness using Multilingual Representations</title>
<author confidence="0.999149">Samer Hassan Carmen Banea Rada Mihalcea</author>
<affiliation confidence="0.9964935">University of North Texas University of North Texas University of North Texas Denton, TX Denton, TX Denton,</affiliation>
<email confidence="0.999889">samer@unt.educarmenbanea@my.unt.edurada@cs.unt.edu</email>
<abstract confidence="0.997002818181818">This paper explores the hypothesis that semantic relatedness may be more reliably inferred by using a multilingual space, as compared to the typical monolingual representation. Through evaluations using several stateof-the-art semantic relatedness systems, applied on standard datasets, we show that a multilingual approach is better suited for this task, and leads to improvements of up to 47% with respect to the monolingual baseline.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Banea</author>
<author>R Mihalcea</author>
</authors>
<title>Word sense disambiguation with multilingual features.</title>
<date>2011</date>
<booktitle>In International Conference on Semantic Computing,</booktitle>
<location>Oxford, UK.</location>
<contexts>
<context position="7542" citStr="Banea and Mihalcea, 2011" startWordPosition="1152" endWordPosition="1155">useful for languages with scarce resources. (Davidov and Rappoport, 2009) experiment with the use of multiple languages to enhance an existing lexicon. In their experiments, using three source languages and 45 intermediate languages, they find that the multilingual resources can lead to significant improvements in concept expansion. (Banea et al., 2010) explore the use of parallel multilingual corpora to improve subjectivity classification in a target language, finding that the use of multilingual representations for subjectivity analysis improves over the monolingual classifiers. Similarly, (Banea and Mihalcea, 2011) investigate the use of multilingual contexts for word sense disambiguation. By leveraging on the translations of the annotated contexts in multiple languages, a multilingual thematic space emerges that better disambiguates target words. Finally, there are two lines of work that explore semantic distances in a multilingual space. First, (Besanc¸on and Rajman, 2002) examine the notion that the distances between document vectors within a language correlate with the distances between their corresponding vectors in a parallel corpus. These findings provide clues about the possibility of reliable s</context>
</contexts>
<marker>Banea, Mihalcea, 2011</marker>
<rawString>C. Banea and R. Mihalcea. 2011. Word sense disambiguation with multilingual features. In International Conference on Semantic Computing, Oxford, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Banea</author>
<author>R Mihalcea</author>
<author>J Wiebe</author>
</authors>
<title>Multilingual subjectivity: Are more languages better?</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>28--36</pages>
<location>Beijing, China,</location>
<contexts>
<context position="7272" citStr="Banea et al., 2010" startWordPosition="1117" endWordPosition="1120">gulation for machine translation, where multiple translation models are learned using multilingual parallel corpora. The model was found especially beneficial for languages where the training dataset was small, thus suggesting that this method may be particularly useful for languages with scarce resources. (Davidov and Rappoport, 2009) experiment with the use of multiple languages to enhance an existing lexicon. In their experiments, using three source languages and 45 intermediate languages, they find that the multilingual resources can lead to significant improvements in concept expansion. (Banea et al., 2010) explore the use of parallel multilingual corpora to improve subjectivity classification in a target language, finding that the use of multilingual representations for subjectivity analysis improves over the monolingual classifiers. Similarly, (Banea and Mihalcea, 2011) investigate the use of multilingual contexts for word sense disambiguation. By leveraging on the translations of the annotated contexts in multiple languages, a multilingual thematic space emerges that better disambiguates target words. Finally, there are two lines of work that explore semantic distances in a multilingual space</context>
</contexts>
<marker>Banea, Mihalcea, Wiebe, 2010</marker>
<rawString>C. Banea, R. Mihalcea, and J. Wiebe. 2010. Multilingual subjectivity: Are more languages better? In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 28–36, Beijing, China, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Besanc¸on</author>
<author>M Rajman</author>
</authors>
<title>Evaluation of a vector space similarity measure in a multilingual framework.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third International Conference on Language Resource and Evaluation (LREC</booktitle>
<location>Las Palmas,</location>
<marker>Besanc¸on, Rajman, 2002</marker>
<rawString>R. Besanc¸on and M. Rajman. 2002. Evaluation of a vector space similarity measure in a multilingual framework. In Proceedings of the Third International Conference on Language Resource and Evaluation (LREC 2002), Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Brin</author>
<author>J Davis</author>
<author>H Garcia-Molina</author>
</authors>
<title>Copy detection mechanisms for digital documents.</title>
<date>1995</date>
<booktitle>In ACMInternational Conference on Management ofData (SIGMOD</booktitle>
<contexts>
<context position="1547" citStr="Brin et al., 1995" startWordPosition="243" endWordPosition="246">ntically related are two words such as car and automobile, or two pieces of text such as I love animals and I own a pet. It is one of the main tasks explored in the field of natural language processing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very large corpora (e.g.</context>
</contexts>
<marker>Brin, Davis, Garcia-Molina, 1995</marker>
<rawString>S. Brin, J. Davis, and H. Garcia-Molina. 1995. Copy detection mechanisms for digital documents. In ACMInternational Conference on Management ofData (SIGMOD 1995).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Z Broder</author>
<author>S C Glassman</author>
<author>M S Manasse</author>
<author>G Zweig</author>
</authors>
<title>Syntactic clustering of the web.</title>
<date>1997</date>
<journal>Comput. Netw. ISDN Syst.,</journal>
<pages>29--8</pages>
<contexts>
<context position="1513" citStr="Broder et al., 1997" startWordPosition="237" endWordPosition="240">, one may want to determine how semantically related are two words such as car and automobile, or two pieces of text such as I love animals and I own a pet. It is one of the main tasks explored in the field of natural language processing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distrib</context>
</contexts>
<marker>Broder, Glassman, Manasse, Zweig, 1997</marker>
<rawString>A. Z. Broder, S. C. Glassman, M. S. Manasse, and G. Zweig. 1997. Syntactic clustering of the web. Comput. Netw. ISDN Syst., 29(8-13):1157–1166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Z Broder</author>
<author>P Ciccolo</author>
<author>M Fontoura</author>
<author>E Gabrilovich</author>
<author>V Josifovski</author>
<author>L Riedel</author>
</authors>
<title>Search advertising using web relevance feedback.</title>
<date>2008</date>
<booktitle>In CIKM ’08: Proceeding of the 17th ACM conference on Information and knowledge management,</booktitle>
<pages>1013--1022</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1354" citStr="Broder et al., 2008" startWordPosition="213" endWordPosition="216">antic relatedness is the task of quantifying the strength of the semantic connection between textual units, be they words, sentences, or documents. For instance, one may want to determine how semantically related are two words such as car and automobile, or two pieces of text such as I love animals and I own a pet. It is one of the main tasks explored in the field of natural language processing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget</context>
</contexts>
<marker>Broder, Ciccolo, Fontoura, Gabrilovich, Josifovski, Riedel, 2008</marker>
<rawString>A Z. Broder, P. Ciccolo, M. Fontoura, E. Gabrilovich, V. Josifovski, and L. Riedel. 2008. Search advertising using web relevance feedback. In CIKM ’08: Proceeding of the 17th ACM conference on Information and knowledge management, pages 1013–1022, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Burgess</author>
<author>K Livesay</author>
<author>K Lund</author>
</authors>
<title>Explorations in context space: words, sentences, discourse.</title>
<date>1998</date>
<booktitle>Discourse Processes,</booktitle>
<pages>25--2</pages>
<contexts>
<context position="5926" citStr="Burgess et al., 1998" startWordPosition="922" endWordPosition="925">le in a number of languages1, their coverage is still limited, and often times they are not publicly available. For these reasons, in multilingual settings, these measures often become untractable. On the other side, corpus-based measures such as Latent Semantic Analysis (LSA) (Landauer et al., 1991), Explicit Semantic Analysis (ESA) (Gabrilovich and Markovitch, 2007), Salient Semantic Analysis (SSA) (Hassan and Mihalcea, 2011), Pointwise Mutual Information (PMI) (Church and Hanks, 1990), PMI-IR (Turney, 2001), Second Order PMI (Islam and Inkpen, 2006), Hyperspace Analogues to Language (HAL) (Burgess et al., 1998) and distributional similarity (Lin, 1998) employ probabilistic approaches to decode the semantics of words. They consist of unsupervised methods that utilize the contextual information and patterns observed in raw text to build semantic profiles of words, and thus they can be easily transferred 1http://www.illc.uva.nl/EuroWordNet/ to a new language provided that a large corpus in that language is available. Multilingual natural language processing. Also relevant is the work done on multilingual text processing, which attempts to improve the performance of different natural language processing</context>
</contexts>
<marker>Burgess, Livesay, Lund, 1998</marker>
<rawString>C. Burgess, K. Livesay, and K. Lund. 1998. Explorations in context space: words, sentences, discourse. Discourse Processes, 25(2):211–257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="5797" citStr="Church and Hanks, 1990" startWordPosition="902" endWordPosition="905">ailability of the lexical resource in that language; furthermore, even though taxonomies such as WordNet (Miller, 1995) are available in a number of languages1, their coverage is still limited, and often times they are not publicly available. For these reasons, in multilingual settings, these measures often become untractable. On the other side, corpus-based measures such as Latent Semantic Analysis (LSA) (Landauer et al., 1991), Explicit Semantic Analysis (ESA) (Gabrilovich and Markovitch, 2007), Salient Semantic Analysis (SSA) (Hassan and Mihalcea, 2011), Pointwise Mutual Information (PMI) (Church and Hanks, 1990), PMI-IR (Turney, 2001), Second Order PMI (Islam and Inkpen, 2006), Hyperspace Analogues to Language (HAL) (Burgess et al., 1998) and distributional similarity (Lin, 1998) employ probabilistic approaches to decode the semantics of words. They consist of unsupervised methods that utilize the contextual information and patterns observed in raw text to build semantic profiles of words, and thus they can be easily transferred 1http://www.illc.uva.nl/EuroWordNet/ to a new language provided that a large corpus in that language is available. Multilingual natural language processing. Also relevant is </context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>K. Church and P. Hanks. 1990. Word association norms, mutual information, and lexicography. Computational Linguistics, 16(1):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Cohn</author>
<author>M Lapata</author>
</authors>
<title>Machine translation by triangulation: making effective use of multi-parallel corpora.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>728--735</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="6628" citStr="Cohn and Lapata, 2007" startWordPosition="1023" endWordPosition="1026">code the semantics of words. They consist of unsupervised methods that utilize the contextual information and patterns observed in raw text to build semantic profiles of words, and thus they can be easily transferred 1http://www.illc.uva.nl/EuroWordNet/ to a new language provided that a large corpus in that language is available. Multilingual natural language processing. Also relevant is the work done on multilingual text processing, which attempts to improve the performance of different natural language processing tasks by integrating information drawn from multiple languages. For instance, (Cohn and Lapata, 2007) explore the use of triangulation for machine translation, where multiple translation models are learned using multilingual parallel corpora. The model was found especially beneficial for languages where the training dataset was small, thus suggesting that this method may be particularly useful for languages with scarce resources. (Davidov and Rappoport, 2009) experiment with the use of multiple languages to enhance an existing lexicon. In their experiments, using three source languages and 45 intermediate languages, they find that the multilingual resources can lead to significant improvement</context>
</contexts>
<marker>Cohn, Lapata, 2007</marker>
<rawString>T. Cohn and M. Lapata. 2007. Machine translation by triangulation: making effective use of multi-parallel corpora. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 728–735, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>O Glickman</author>
<author>B Magnini</author>
</authors>
<title>The PASCAL recognising textual entailment challenge.</title>
<date>2005</date>
<booktitle>In Proceedings of the PASCAL Workshop.</booktitle>
<contexts>
<context position="1790" citStr="Dagan et al., 2005" startWordPosition="280" endWordPosition="283">er of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very large corpora (e.g., (Landauer et al., 1991; Lin, 1998; Gabrilovich and Markovitch, 2007)). With almost no exception, these methods have been applied on one language at a time – English, most of the time, although measures of relatedness have also been explored </context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2005</marker>
<rawString>I. Dagan, O. Glickman, and B. Magnini. 2005. The PASCAL recognising textual entailment challenge. In Proceedings of the PASCAL Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Davidov</author>
<author>A Rappoport</author>
</authors>
<title>Enhancement of lexical concepts using cross-lingual web mining.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>852--861</pages>
<contexts>
<context position="6990" citStr="Davidov and Rappoport, 2009" startWordPosition="1075" endWordPosition="1078">guage processing. Also relevant is the work done on multilingual text processing, which attempts to improve the performance of different natural language processing tasks by integrating information drawn from multiple languages. For instance, (Cohn and Lapata, 2007) explore the use of triangulation for machine translation, where multiple translation models are learned using multilingual parallel corpora. The model was found especially beneficial for languages where the training dataset was small, thus suggesting that this method may be particularly useful for languages with scarce resources. (Davidov and Rappoport, 2009) experiment with the use of multiple languages to enhance an existing lexicon. In their experiments, using three source languages and 45 intermediate languages, they find that the multilingual resources can lead to significant improvements in concept expansion. (Banea et al., 2010) explore the use of parallel multilingual corpora to improve subjectivity classification in a target language, finding that the use of multilingual representations for subjectivity analysis improves over the monolingual classifiers. Similarly, (Banea and Mihalcea, 2011) investigate the use of multilingual contexts fo</context>
</contexts>
<marker>Davidov, Rappoport, 2009</marker>
<rawString>D. Davidov and A. Rappoport. 2009. Enhancement of lexical concepts using cross-lingual web mining. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 852– 861, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Finkelstein</author>
<author>E Gabrilovich</author>
<author>Y Matias</author>
<author>E Rivlin</author>
<author>Z Solan</author>
<author>G Wolfman</author>
<author>E Ruppin</author>
</authors>
<title>Placing search in context: the concept revisited. In</title>
<date>2001</date>
<booktitle>The Tenth International World Wide Web Conference,</booktitle>
<pages>406--414</pages>
<editor>editor,</editor>
<publisher>ACM Press,</publisher>
<location>Hong Kong.</location>
<contexts>
<context position="12282" citStr="Finkelstein et al., 2001" startWordPosition="1867" endWordPosition="1870">ord relatedness datasets that have been widely used in the past. Rubenstein and Goodenough (Rubenstein and Goodenough, 1965) (RG65) consists of 65 word pairs ranging from synonymy pairs (e.g., car - automobile) to completely unrelated words (e.g., noon - string). The participating terms in all the pairs are non-technical nouns annotated by 51 human judges on a scale from 0 (unrelated) to 4 (synonyms). Miller-Charles (Miller and Charles, 1991) (MC30) is a subset of RG65, consisting of 30 word pairs annotated for relatedness by 38 human subjects, using the same 0 to 4 scale. WordSimilarity-353 (Finkelstein et al., 2001) (WS353), also known as Finkelstein-353, consists of 353 word pairs annotated by 13 human experts, on a scale from 0 (unrelated) to 10 (synonyms). While containing the MC30 set, it poses an additional degree of difficulty by also including phrases (e.g., “Wednesday news”), proper names and technical terms. To enable a multilingual representation, we use the multilingual datasets introduced by (Hassan and Mihalcea, 2009), which are based upon MC30 and WS353. These multilingual datasets are built using manual translations, following the same guidelines adopted for the generation and the annotati</context>
</contexts>
<marker>Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, Ruppin, 2001</marker>
<rawString>L. Finkelstein, E. Gabrilovich, Y. Matias, E. Rivlin, Z. Solan, G. Wolfman, and E. Ruppin. 2001. Placing search in context: the concept revisited. In ACM Press, editor, The Tenth International World Wide Web Conference, pages 406–414, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Gabrilovich</author>
<author>S Markovitch</author>
</authors>
<title>Computing semantic relatedness using Wikipedia-based explicit semantic analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1606--1611</pages>
<location>Hyderabad, India.</location>
<contexts>
<context position="2217" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="349" endWordPosition="352">tzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very large corpora (e.g., (Landauer et al., 1991; Lin, 1998; Gabrilovich and Markovitch, 2007)). With almost no exception, these methods have been applied on one language at a time – English, most of the time, although measures of relatedness have also been explored on languages such as German (Zesch et al., 2007), Chinese (Li et al., 2005), Japanese (Kazama et al., 2010), and others. In this paper, we take a step further and explore a joint multilingual semantic relatedness metric, which aggregates semantic relatedness scores measured on several different languages. Specifically, in our method, in order to measure the relatedness of two textual units, we first determine their relatedn</context>
<context position="5675" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="885" endWordPosition="888"> of specificity (Wu and Palmer, 1994), and others. The application of such measures to a language other than English requires the availability of the lexical resource in that language; furthermore, even though taxonomies such as WordNet (Miller, 1995) are available in a number of languages1, their coverage is still limited, and often times they are not publicly available. For these reasons, in multilingual settings, these measures often become untractable. On the other side, corpus-based measures such as Latent Semantic Analysis (LSA) (Landauer et al., 1991), Explicit Semantic Analysis (ESA) (Gabrilovich and Markovitch, 2007), Salient Semantic Analysis (SSA) (Hassan and Mihalcea, 2011), Pointwise Mutual Information (PMI) (Church and Hanks, 1990), PMI-IR (Turney, 2001), Second Order PMI (Islam and Inkpen, 2006), Hyperspace Analogues to Language (HAL) (Burgess et al., 1998) and distributional similarity (Lin, 1998) employ probabilistic approaches to decode the semantics of words. They consist of unsupervised methods that utilize the contextual information and patterns observed in raw text to build semantic profiles of words, and thus they can be easily transferred 1http://www.illc.uva.nl/EuroWordNet/ to a new langua</context>
<context position="8914" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="1353" endWordPosition="1356">ess between two words in different languages, by considering Wikipedia articles in multiple languages. The method differs from the one proposed here, as we aggregate relatedness over monolingual spaces rather than measuring cross-lingual relatedness, and we do not specifically use the inter-wiki links between Wikipedia pages. 21 3 Measures of Text Relatedness In this work, we focus on corpus-based metrics because of their unsupervised nature, their flexibility, scalability, and portability to different languages. Specifically, we utilize three popular models, LSA (Landauer et al., 1991), ESA (Gabrilovich and Markovitch, 2007), and SSA (Hassan and Mihalcea, 2011). In these models, the semantic profile of a word is expressed in terms of the explicit (ESA), implicit (LSA), or salient (SSA) concepts. All three models are trained on the Wikipedia 2010 corpora corresponding to the four languages of interest (English, Arabic, Spanish, Romanian). Explicit Semantic Analysis. ESA (Gabrilovich and Markovitch, 2007) uses encyclopedic knowledge in an information retrieval framework to generate a semantic interpretation of words. Since encyclopedic knowledge is typically organized into concepts (or topics), each concept is desc</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>E. Gabrilovich and S. Markovitch. 2007. Computing semantic relatedness using Wikipedia-based explicit semantic analysis. In Proceedings of the 20th International Joint Conference on Artificial Intelligence, pages 1606–1611, Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Goodrum</author>
</authors>
<title>Image information retrieval: An overview of current research.</title>
<date>2000</date>
<journal>Informing Science,</journal>
<volume>3</volume>
<issue>2</issue>
<contexts>
<context position="1413" citStr="Goodrum, 2000" startWordPosition="224" endWordPosition="225">semantic connection between textual units, be they words, sentences, or documents. For instance, one may want to determine how semantically related are two words such as car and automobile, or two pieces of text such as I love animals and I own a pet. It is one of the main tasks explored in the field of natural language processing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz an</context>
</contexts>
<marker>Goodrum, 2000</marker>
<rawString>A. Goodrum. 2000. Image information retrieval: An overview of current research. Informing Science, 3(2):63–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Hassan</author>
<author>R Mihalcea</author>
</authors>
<title>Cross-lingual semantic relatedness using encyclopedic knowledge.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1192--1201</pages>
<institution>Singapore. Association for Computational Linguistics.</institution>
<contexts>
<context position="8232" citStr="Hassan and Mihalcea, 2009" startWordPosition="1252" endWordPosition="1255">ambiguation. By leveraging on the translations of the annotated contexts in multiple languages, a multilingual thematic space emerges that better disambiguates target words. Finally, there are two lines of work that explore semantic distances in a multilingual space. First, (Besanc¸on and Rajman, 2002) examine the notion that the distances between document vectors within a language correlate with the distances between their corresponding vectors in a parallel corpus. These findings provide clues about the possibility of reliable semantic knowledge transfer across language boundaries. Second, (Hassan and Mihalcea, 2009) propose a framework to compute semantic relatedness between two words in different languages, by considering Wikipedia articles in multiple languages. The method differs from the one proposed here, as we aggregate relatedness over monolingual spaces rather than measuring cross-lingual relatedness, and we do not specifically use the inter-wiki links between Wikipedia pages. 21 3 Measures of Text Relatedness In this work, we focus on corpus-based metrics because of their unsupervised nature, their flexibility, scalability, and portability to different languages. Specifically, we utilize three p</context>
<context position="12705" citStr="Hassan and Mihalcea, 2009" startWordPosition="1933" endWordPosition="1936">iller and Charles, 1991) (MC30) is a subset of RG65, consisting of 30 word pairs annotated for relatedness by 38 human subjects, using the same 0 to 4 scale. WordSimilarity-353 (Finkelstein et al., 2001) (WS353), also known as Finkelstein-353, consists of 353 word pairs annotated by 13 human experts, on a scale from 0 (unrelated) to 10 (synonyms). While containing the MC30 set, it poses an additional degree of difficulty by also including phrases (e.g., “Wednesday news”), proper names and technical terms. To enable a multilingual representation, we use the multilingual datasets introduced by (Hassan and Mihalcea, 2009), which are based upon MC30 and WS353. These multilingual datasets are built using manual translations, following the same guidelines adopted for the generation and the annotation of their original English counterparts. These manually translated collections, available in Arabic, Spanish, and Romanian, allow us to infer an upper bound for the multilingual semantic relatedness model. Moreover, in order to provide a more realistic scenario, where manual translations are not available, we also create multilingual datasets by automatically translating the three English datasets into 22 Arabic, Span</context>
</contexts>
<marker>Hassan, Mihalcea, 2009</marker>
<rawString>S. Hassan and R. Mihalcea. 2009. Cross-lingual semantic relatedness using encyclopedic knowledge. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1192– 1201, Singapore. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Hassan</author>
<author>R Mihalcea</author>
</authors>
<title>Measuring semantic relatedness using salient encyclopedic concepts.</title>
<date>2011</date>
<journal>Artificial Intelligence, Special Issue, xx(xx).</journal>
<contexts>
<context position="5736" citStr="Hassan and Mihalcea, 2011" startWordPosition="893" endWordPosition="897">f such measures to a language other than English requires the availability of the lexical resource in that language; furthermore, even though taxonomies such as WordNet (Miller, 1995) are available in a number of languages1, their coverage is still limited, and often times they are not publicly available. For these reasons, in multilingual settings, these measures often become untractable. On the other side, corpus-based measures such as Latent Semantic Analysis (LSA) (Landauer et al., 1991), Explicit Semantic Analysis (ESA) (Gabrilovich and Markovitch, 2007), Salient Semantic Analysis (SSA) (Hassan and Mihalcea, 2011), Pointwise Mutual Information (PMI) (Church and Hanks, 1990), PMI-IR (Turney, 2001), Second Order PMI (Islam and Inkpen, 2006), Hyperspace Analogues to Language (HAL) (Burgess et al., 1998) and distributional similarity (Lin, 1998) employ probabilistic approaches to decode the semantics of words. They consist of unsupervised methods that utilize the contextual information and patterns observed in raw text to build semantic profiles of words, and thus they can be easily transferred 1http://www.illc.uva.nl/EuroWordNet/ to a new language provided that a large corpus in that language is available</context>
<context position="8951" citStr="Hassan and Mihalcea, 2011" startWordPosition="1359" endWordPosition="1363">, by considering Wikipedia articles in multiple languages. The method differs from the one proposed here, as we aggregate relatedness over monolingual spaces rather than measuring cross-lingual relatedness, and we do not specifically use the inter-wiki links between Wikipedia pages. 21 3 Measures of Text Relatedness In this work, we focus on corpus-based metrics because of their unsupervised nature, their flexibility, scalability, and portability to different languages. Specifically, we utilize three popular models, LSA (Landauer et al., 1991), ESA (Gabrilovich and Markovitch, 2007), and SSA (Hassan and Mihalcea, 2011). In these models, the semantic profile of a word is expressed in terms of the explicit (ESA), implicit (LSA), or salient (SSA) concepts. All three models are trained on the Wikipedia 2010 corpora corresponding to the four languages of interest (English, Arabic, Spanish, Romanian). Explicit Semantic Analysis. ESA (Gabrilovich and Markovitch, 2007) uses encyclopedic knowledge in an information retrieval framework to generate a semantic interpretation of words. Since encyclopedic knowledge is typically organized into concepts (or topics), each concept is described using definitions and examples.</context>
<context position="10529" citStr="Hassan and Mihalcea, 2011" startWordPosition="1597" endWordPosition="1600">ndividual words. Latent Semantic Analysis. In LSA (Landauer et al., 1991), term-context associations are captured by means of a dimensionality reduction operated by a singular value decomposition (SVD) on the term-bycontext matrix T, where the matrix is induced from a large corpus. This reduction entails the abstraction of meaning by collapsing similar contexts and discounting noisy and irrelevant ones, hence transforming the real world term-context space into a wordlatent-concept space which achieves a much deeper and concrete semantic representation of words. Salient Semantic Analysis. SSA (Hassan and Mihalcea, 2011) incorporates a similar semantic abstraction and interpretation of words, by using salient concepts gathered from encyclopedic knowledge, where a concept is defined as an unambiguous word or phrase with a concrete meaning, which can afford an encyclopedic definition. The links available between Wikipedia articles, obtained either through manual annotation by the Wikipedia users or using an automatic annotation process, are regarded as clues or salient features within the text that help define and disambiguate its context. This method seeks to determine the semantic relatedness of words by meas</context>
<context position="15408" citStr="Hassan and Mihalcea, 2011" startWordPosition="2367" endWordPosition="2370">dictionary (Sinclair, 2001). Each sentence pair was scored between 0 (unrelated) to 4 (alike) by 32 native English speakers, and their annotations were averaged. Due to the skew in the scores toward low similarity sentence-pairs, they selected a subset of 30 sentences from the 65 sentence pairs to maintain an even relatedness distribution. AG400 (Mohler and Mihalcea, 2009b) is a domain specific dataset from the field of computer science, used to evaluate the application of semantic relatedness measures to real world applications such as short answer grading. We employ the version proposed by (Hassan and Mihalcea, 2011) which consists of 400 student answers along with the corresponding questions and correct instructor answers. Each student answer was graded by two judges on a scale from 0 (completely wrong) to 5 (perfect answer). The correlation between human judges was 2For all the automatic translations we used the Google Translate service. measured at 0.64. First, we construct a multilingual, manually translated text-to-text relatedness dataset based on the standard Li30 corpus.3 Native speakers of Spanish, Romanian and Arabic, who were also highly proficient in English, were asked to translate the entrie</context>
<context position="20595" citStr="Hassan and Mihalcea, 2011" startWordPosition="3204" endWordPosition="3207">r this combination can be represented as: where Siml(p) is the relatedness score of the wordor text-pair p in the monolingual model of language l. To evaluate the performance of the multilingual model, let Di be the generated relatedness distribution for the dataset P using the combination ci: Di = {(p, Simci(p)) |p E Pl. (3) Then, the correlation between the gold standard distribution G and the generated scores can be calculated as follows: 1 CorrelCn(D, G) = |Cn |ciECn Correlci(Di, G), (4) where Correl can stand for Pearson (r), Spearman (p), or their harmonic mean (µ), as also reported in (Hassan and Mihalcea, 2011). 6 Evaluations In this section we revisit the questions formulated in the introduction, and based on different experiment setups following the framework introduced in Section 5, we provide an answer to each one of them. Does the task of semantic relatedness benefit from a multilingual representation? We evaluate the three semantic relatedness models, namely LSA, ESA and SSA on our manually constructed multilingual word relatedness (MC30, WS353) and text relatedness datasets (LI30), as described in Section 4. Figure 1 plots the correlation scores achieved across all the languages against the g</context>
</contexts>
<marker>Hassan, Mihalcea, 2011</marker>
<rawString>S. Hassan and R. Mihalcea. 2011. Measuring semantic relatedness using salient encyclopedic concepts. Artificial Intelligence, Special Issue, xx(xx).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Heintze</author>
</authors>
<title>Scalable document fingerprinting. In</title>
<date>1996</date>
<booktitle>In Proc. USENIX Workshop on Electronic Commerce.</booktitle>
<contexts>
<context position="1528" citStr="Heintze, 1996" startWordPosition="241" endWordPosition="242">ermine how semantically related are two words such as car and automobile, or two pieces of text such as I love animals and I own a pet. It is one of the main tasks explored in the field of natural language processing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very </context>
</contexts>
<marker>Heintze, 1996</marker>
<rawString>N. Heintze. 1996. Scalable document fingerprinting. In In Proc. USENIX Workshop on Electronic Commerce.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T C Hoad</author>
<author>J Zobel</author>
</authors>
<title>Methods for identifying versioned and plagiarized documents.</title>
<date>2003</date>
<journal>J. Am. Soc. Inf. Sci. Technol.,</journal>
<volume>54</volume>
<issue>3</issue>
<contexts>
<context position="1457" citStr="Hoad and Zobel, 2003" startWordPosition="228" endWordPosition="231">its, be they words, sentences, or documents. For instance, one may want to determine how semantically related are two words such as car and automobile, or two pieces of text such as I love animals and I own a pet. It is one of the main tasks explored in the field of natural language processing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)),</context>
</contexts>
<marker>Hoad, Zobel, 2003</marker>
<rawString>T. C. Hoad and J. Zobel. 2003. Methods for identifying versioned and plagiarized documents. J. Am. Soc. Inf. Sci. Technol., 54(3):203–215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Islam</author>
<author>D Inkpen</author>
</authors>
<title>Second order cooccurrence PMI for determining the semantic similarity of words.</title>
<date>2006</date>
<booktitle>In Proceedings of the Fifth Conference on Language Resources and Evaluation,</booktitle>
<volume>2</volume>
<location>Genoa, Italy,</location>
<contexts>
<context position="5863" citStr="Islam and Inkpen, 2006" startWordPosition="912" endWordPosition="915">even though taxonomies such as WordNet (Miller, 1995) are available in a number of languages1, their coverage is still limited, and often times they are not publicly available. For these reasons, in multilingual settings, these measures often become untractable. On the other side, corpus-based measures such as Latent Semantic Analysis (LSA) (Landauer et al., 1991), Explicit Semantic Analysis (ESA) (Gabrilovich and Markovitch, 2007), Salient Semantic Analysis (SSA) (Hassan and Mihalcea, 2011), Pointwise Mutual Information (PMI) (Church and Hanks, 1990), PMI-IR (Turney, 2001), Second Order PMI (Islam and Inkpen, 2006), Hyperspace Analogues to Language (HAL) (Burgess et al., 1998) and distributional similarity (Lin, 1998) employ probabilistic approaches to decode the semantics of words. They consist of unsupervised methods that utilize the contextual information and patterns observed in raw text to build semantic profiles of words, and thus they can be easily transferred 1http://www.illc.uva.nl/EuroWordNet/ to a new language provided that a large corpus in that language is available. Multilingual natural language processing. Also relevant is the work done on multilingual text processing, which attempts to i</context>
</contexts>
<marker>Islam, Inkpen, 2006</marker>
<rawString>A. Islam and D. Inkpen. 2006. Second order cooccurrence PMI for determining the semantic similarity of words. In Proceedings of the Fifth Conference on Language Resources and Evaluation, volume 2, Genoa, Italy, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Jarmasz</author>
<author>S Szpakowicz</author>
</authors>
<title>Roget’s thesaurus and semantic similarity.</title>
<date>2003</date>
<booktitle>In Proceedings of the conference on Recent Advances in Natural Language Processing RANLP-2003,</booktitle>
<location>Borovetz, Bulgaria,</location>
<contexts>
<context position="2031" citStr="Jarmasz and Szpakowicz, 2003" startWordPosition="319" endWordPosition="322">rum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very large corpora (e.g., (Landauer et al., 1991; Lin, 1998; Gabrilovich and Markovitch, 2007)). With almost no exception, these methods have been applied on one language at a time – English, most of the time, although measures of relatedness have also been explored on languages such as German (Zesch et al., 2007), Chinese (Li et al., 2005), Japanese (Kazama et al., 2010), and others. In this paper, we take a step further and explore a joint multilingual semantic relatedness metric, which aggregates sem</context>
</contexts>
<marker>Jarmasz, Szpakowicz, 2003</marker>
<rawString>M. Jarmasz and S. Szpakowicz. 2003. Roget’s thesaurus and semantic similarity. In Proceedings of the conference on Recent Advances in Natural Language Processing RANLP-2003, Borovetz, Bulgaria, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kazama</author>
<author>S De Saeger</author>
<author>K Kuroda</author>
<author>M Murata</author>
<author>K Torisawa</author>
</authors>
<title>A bayesian method for robust estimation of distributional similarities.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Uppsala,</location>
<marker>Kazama, De Saeger, Kuroda, Murata, Torisawa, 2010</marker>
<rawString>J. Kazama, S. De Saeger, K. Kuroda, M. Murata, and K. Torisawa. 2010. A bayesian method for robust estimation of distributional similarities. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T K Landauer</author>
<author>D Laham</author>
<author>B Rehder</author>
<author>M E Schreiner</author>
</authors>
<title>How well can passage meaning be derived without using word order? A comparison of latent semantic analysis and humans.</title>
<date>1991</date>
<booktitle>In Proceedings of the 19th annual meeting of the Cognitive Science Society,</booktitle>
<pages>412--417</pages>
<publisher>Mawhwah, N. Erlbaum.</publisher>
<contexts>
<context position="2171" citStr="Landauer et al., 1991" startWordPosition="343" endWordPosition="346">anber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very large corpora (e.g., (Landauer et al., 1991; Lin, 1998; Gabrilovich and Markovitch, 2007)). With almost no exception, these methods have been applied on one language at a time – English, most of the time, although measures of relatedness have also been explored on languages such as German (Zesch et al., 2007), Chinese (Li et al., 2005), Japanese (Kazama et al., 2010), and others. In this paper, we take a step further and explore a joint multilingual semantic relatedness metric, which aggregates semantic relatedness scores measured on several different languages. Specifically, in our method, in order to measure the relatedness of two te</context>
<context position="5606" citStr="Landauer et al., 1991" startWordPosition="875" endWordPosition="879">d Chodorow, 1998), term depth in the taxonomy as a measure of specificity (Wu and Palmer, 1994), and others. The application of such measures to a language other than English requires the availability of the lexical resource in that language; furthermore, even though taxonomies such as WordNet (Miller, 1995) are available in a number of languages1, their coverage is still limited, and often times they are not publicly available. For these reasons, in multilingual settings, these measures often become untractable. On the other side, corpus-based measures such as Latent Semantic Analysis (LSA) (Landauer et al., 1991), Explicit Semantic Analysis (ESA) (Gabrilovich and Markovitch, 2007), Salient Semantic Analysis (SSA) (Hassan and Mihalcea, 2011), Pointwise Mutual Information (PMI) (Church and Hanks, 1990), PMI-IR (Turney, 2001), Second Order PMI (Islam and Inkpen, 2006), Hyperspace Analogues to Language (HAL) (Burgess et al., 1998) and distributional similarity (Lin, 1998) employ probabilistic approaches to decode the semantics of words. They consist of unsupervised methods that utilize the contextual information and patterns observed in raw text to build semantic profiles of words, and thus they can be ea</context>
<context position="8874" citStr="Landauer et al., 1991" startWordPosition="1348" endWordPosition="1351"> to compute semantic relatedness between two words in different languages, by considering Wikipedia articles in multiple languages. The method differs from the one proposed here, as we aggregate relatedness over monolingual spaces rather than measuring cross-lingual relatedness, and we do not specifically use the inter-wiki links between Wikipedia pages. 21 3 Measures of Text Relatedness In this work, we focus on corpus-based metrics because of their unsupervised nature, their flexibility, scalability, and portability to different languages. Specifically, we utilize three popular models, LSA (Landauer et al., 1991), ESA (Gabrilovich and Markovitch, 2007), and SSA (Hassan and Mihalcea, 2011). In these models, the semantic profile of a word is expressed in terms of the explicit (ESA), implicit (LSA), or salient (SSA) concepts. All three models are trained on the Wikipedia 2010 corpora corresponding to the four languages of interest (English, Arabic, Spanish, Romanian). Explicit Semantic Analysis. ESA (Gabrilovich and Markovitch, 2007) uses encyclopedic knowledge in an information retrieval framework to generate a semantic interpretation of words. Since encyclopedic knowledge is typically organized into co</context>
</contexts>
<marker>Landauer, Laham, Rehder, Schreiner, 1991</marker>
<rawString>T. K. Landauer, D. Laham, B. Rehder, and M. E. Schreiner. 1991. How well can passage meaning be derived without using word order? A comparison of latent semantic analysis and humans. In Proceedings of the 19th annual meeting of the Cognitive Science Society, pages 412–417, Mawhwah, N. Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Leacock</author>
<author>M Chodorow</author>
</authors>
<title>Combining local context and WordNet similarity for word sense identification,</title>
<date>1998</date>
<pages>305--332</pages>
<contexts>
<context position="1989" citStr="Leacock and Chodorow, 1998" startWordPosition="313" endWordPosition="316">etrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very large corpora (e.g., (Landauer et al., 1991; Lin, 1998; Gabrilovich and Markovitch, 2007)). With almost no exception, these methods have been applied on one language at a time – English, most of the time, although measures of relatedness have also been explored on languages such as German (Zesch et al., 2007), Chinese (Li et al., 2005), Japanese (Kazama et al., 2010), and others. In this paper, we take a step further and explore a joint multilingual semanti</context>
<context position="5001" citStr="Leacock and Chodorow, 1998" startWordPosition="781" endWordPosition="784">resent several word and text datasets that have been used in the past to evaluate relatedness. We then present evaluations and experiments addressing each of the three research questions, and discuss our findings. 2 Related Work Semantic relatedness. The approaches for semantic relatedness that have been considered to date can be grouped into knowledge-based and corpusbased. Knowledge-based methods derive a measure of relatedness by utilizing lexical resources and ontologies such as WordNet (Miller, 1995) to measure definitional overlap (Lesk, 1986), term distance within a graphical taxonomy (Leacock and Chodorow, 1998), term depth in the taxonomy as a measure of specificity (Wu and Palmer, 1994), and others. The application of such measures to a language other than English requires the availability of the lexical resource in that language; furthermore, even though taxonomies such as WordNet (Miller, 1995) are available in a number of languages1, their coverage is still limited, and often times they are not publicly available. For these reasons, in multilingual settings, these measures often become untractable. On the other side, corpus-based measures such as Latent Semantic Analysis (LSA) (Landauer et al., </context>
</contexts>
<marker>Leacock, Chodorow, 1998</marker>
<rawString>C. Leacock and M. Chodorow, 1998. Combining local context and WordNet similarity for word sense identification, pages 305–332.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M D Lee</author>
<author>M Welsh</author>
</authors>
<title>An empirical evaluation of models of text document similarity.</title>
<date>2005</date>
<booktitle>In Proceedings of the 27th annual meeting of the Cognitive Science Society,</booktitle>
<pages>1254--1259</pages>
<location>Stresa, Italy.</location>
<contexts>
<context position="13972" citStr="Lee and Welsh, 2005" startWordPosition="2133" endWordPosition="2136">translated datasets were created by providing the bilingual speakers with one word pair at a time, for the automatic translation each word pair is processed as a single query to the translation engine. Thus, the co-occurrence metrics derived from large corpora are able to play a role in providing a disambiguated translation instead of defaulting to the most frequently used sense if the words were to be processed individually. This allows for the embedded word pair relatedness to be transferred to other languages as well. 4.2 Text Relatedness We use three standard text-to-text datasets. Lee50 (Lee and Welsh, 2005) is a compilation of 50 documents collected from the Australian Broadcasting Corporation’s news mail service. Each document is scored by ten annotators on a scale from 1 (unrelated) to 5 (alike) based on its semantic relatedness to all the other documents. The users’ annotation is then averaged per document pair, resulting in 2,500 document pairs annotated with their similarity scores. Since it was found that there was no significant difference between annotations given a different order of the documents in a pair (Lee and Welsh, 2005), the evaluations are carried out on only 1225 document pai</context>
</contexts>
<marker>Lee, Welsh, 2005</marker>
<rawString>M. D. Lee and M. Welsh. 2005. An empirical evaluation of models of text document similarity. In Proceedings of the 27th annual meeting of the Cognitive Science Society, pages 1254–1259, Stresa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C W Leong</author>
<author>R Mihalcea</author>
</authors>
<title>Explorations in automatic image annotation using textual features.</title>
<date>2009</date>
<booktitle>In Proceedings of the Third Linguistic Annotation Workshop,</booktitle>
<pages>56--59</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Suntec, Singapore,</location>
<contexts>
<context position="1397" citStr="Leong and Mihalcea, 2009" startWordPosition="219" endWordPosition="223">fying the strength of the semantic connection between textual units, be they words, sentences, or documents. For instance, one may want to determine how semantically related are two words such as car and automobile, or two pieces of text such as I love animals and I own a pet. It is one of the main tasks explored in the field of natural language processing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, </context>
</contexts>
<marker>Leong, Mihalcea, 2009</marker>
<rawString>C. W. Leong and R. Mihalcea. 2009. Explorations in automatic image annotation using textual features. In Proceedings of the Third Linguistic Annotation Workshop, pages 56–59, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lesk</author>
</authors>
<title>Automatic sense disambiguation using machine readable dictionaries.</title>
<date>1986</date>
<booktitle>In Proceedings of the 5th annual international conference on Systems documentation - SIGDOC ’86,</booktitle>
<pages>24--26</pages>
<publisher>ACM Press.</publisher>
<location>Toronto, Ontario.</location>
<contexts>
<context position="2001" citStr="Lesk, 1986" startWordPosition="317" endWordPosition="318">, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very large corpora (e.g., (Landauer et al., 1991; Lin, 1998; Gabrilovich and Markovitch, 2007)). With almost no exception, these methods have been applied on one language at a time – English, most of the time, although measures of relatedness have also been explored on languages such as German (Zesch et al., 2007), Chinese (Li et al., 2005), Japanese (Kazama et al., 2010), and others. In this paper, we take a step further and explore a joint multilingual semantic relatednes</context>
<context position="4929" citStr="Lesk, 1986" startWordPosition="772" endWordPosition="773">scribe three corpus-based measures of relatedness, and present several word and text datasets that have been used in the past to evaluate relatedness. We then present evaluations and experiments addressing each of the three research questions, and discuss our findings. 2 Related Work Semantic relatedness. The approaches for semantic relatedness that have been considered to date can be grouped into knowledge-based and corpusbased. Knowledge-based methods derive a measure of relatedness by utilizing lexical resources and ontologies such as WordNet (Miller, 1995) to measure definitional overlap (Lesk, 1986), term distance within a graphical taxonomy (Leacock and Chodorow, 1998), term depth in the taxonomy as a measure of specificity (Wu and Palmer, 1994), and others. The application of such measures to a language other than English requires the availability of the lexical resource in that language; furthermore, even though taxonomies such as WordNet (Miller, 1995) are available in a number of languages1, their coverage is still limited, and often times they are not publicly available. For these reasons, in multilingual settings, these measures often become untractable. On the other side, corpus-</context>
</contexts>
<marker>Lesk, 1986</marker>
<rawString>M. Lesk. 1986. Automatic sense disambiguation using machine readable dictionaries. In Proceedings of the 5th annual international conference on Systems documentation - SIGDOC ’86, pages 24–26, Toronto, Ontario. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Li</author>
<author>Q Lu</author>
<author>R Xu</author>
</authors>
<title>Similarity based chinese synonym collocation extraction.</title>
<date>2005</date>
<journal>International Journal of Computational Linguistics and Chinese Language Processing,</journal>
<volume>10</volume>
<issue>1</issue>
<contexts>
<context position="2465" citStr="Li et al., 2005" startWordPosition="394" endWordPosition="397"> measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very large corpora (e.g., (Landauer et al., 1991; Lin, 1998; Gabrilovich and Markovitch, 2007)). With almost no exception, these methods have been applied on one language at a time – English, most of the time, although measures of relatedness have also been explored on languages such as German (Zesch et al., 2007), Chinese (Li et al., 2005), Japanese (Kazama et al., 2010), and others. In this paper, we take a step further and explore a joint multilingual semantic relatedness metric, which aggregates semantic relatedness scores measured on several different languages. Specifically, in our method, in order to measure the relatedness of two textual units, we first determine their relatedness in multiple languages, and consequently infer a final relatedness score by averaging the scores calculated in the individual languages. Our hypothesis is that a multilingual representation can enrich the relatedness space and address relevant i</context>
</contexts>
<marker>Li, Lu, Xu, 2005</marker>
<rawString>W. Li, Q. Lu, and R. Xu. 2005. Similarity based chinese synonym collocation extraction. International Journal of Computational Linguistics and Chinese Language Processing, 10(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Li</author>
<author>D McLean</author>
<author>Z A Bandar</author>
<author>J D O’Shea</author>
<author>K Crockett</author>
</authors>
<title>Sentence similarity based on semantic nets and corpus statistics.</title>
<date>2006</date>
<journal>IEEE Transactions on Knowledge and Data Engineering,</journal>
<volume>18</volume>
<issue>8</issue>
<pages>1150</pages>
<marker>Li, McLean, Bandar, O’Shea, Crockett, 2006</marker>
<rawString>Y. Li, D. McLean, Z. A. Bandar, J. D. O’Shea, and K. Crockett. 2006. Sentence similarity based on semantic nets and corpus statistics. IEEE Transactions on Knowledge and Data Engineering, 18(8):1138– 1150, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>An information-theoretic definition of similarity.</title>
<date>1998</date>
<booktitle>In Proceedings of the Fifteenth International Conference on Machine Learning,</booktitle>
<pages>296--304</pages>
<location>Madison, Wisconsin.</location>
<contexts>
<context position="2182" citStr="Lin, 1998" startWordPosition="347" endWordPosition="348">on flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very large corpora (e.g., (Landauer et al., 1991; Lin, 1998; Gabrilovich and Markovitch, 2007)). With almost no exception, these methods have been applied on one language at a time – English, most of the time, although measures of relatedness have also been explored on languages such as German (Zesch et al., 2007), Chinese (Li et al., 2005), Japanese (Kazama et al., 2010), and others. In this paper, we take a step further and explore a joint multilingual semantic relatedness metric, which aggregates semantic relatedness scores measured on several different languages. Specifically, in our method, in order to measure the relatedness of two textual units</context>
<context position="5968" citStr="Lin, 1998" startWordPosition="929" endWordPosition="930"> limited, and often times they are not publicly available. For these reasons, in multilingual settings, these measures often become untractable. On the other side, corpus-based measures such as Latent Semantic Analysis (LSA) (Landauer et al., 1991), Explicit Semantic Analysis (ESA) (Gabrilovich and Markovitch, 2007), Salient Semantic Analysis (SSA) (Hassan and Mihalcea, 2011), Pointwise Mutual Information (PMI) (Church and Hanks, 1990), PMI-IR (Turney, 2001), Second Order PMI (Islam and Inkpen, 2006), Hyperspace Analogues to Language (HAL) (Burgess et al., 1998) and distributional similarity (Lin, 1998) employ probabilistic approaches to decode the semantics of words. They consist of unsupervised methods that utilize the contextual information and patterns observed in raw text to build semantic profiles of words, and thus they can be easily transferred 1http://www.illc.uva.nl/EuroWordNet/ to a new language provided that a large corpus in that language is available. Multilingual natural language processing. Also relevant is the work done on multilingual text processing, which attempts to improve the performance of different natural language processing tasks by integrating information drawn fr</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>D. Lin. 1998. An information-theoretic definition of similarity. In Proceedings of the Fifteenth International Conference on Machine Learning, pages 296– 304, Madison, Wisconsin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Manber</author>
</authors>
<title>Finding similar files in a large file system.</title>
<date>1994</date>
<booktitle>In USENIX WINTER 1994 TECHNICAL CONFERENCE,</booktitle>
<pages>1--10</pages>
<contexts>
<context position="1562" citStr="Manber, 1994" startWordPosition="247" endWordPosition="248">e two words such as car and automobile, or two pieces of text such as I love animals and I own a pet. It is one of the main tasks explored in the field of natural language processing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very large corpora (e.g., (Landauer et </context>
</contexts>
<marker>Manber, 1994</marker>
<rawString>U. Manber. 1994. Finding similar files in a large file system. In USENIX WINTER 1994 TECHNICAL CONFERENCE, pages 1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Metzler</author>
<author>Y Bernstein</author>
<author>W Bruce Croft</author>
<author>A Moffat</author>
<author>J Zobel</author>
</authors>
<title>Similarity measures for tracking information flow.</title>
<date>2005</date>
<booktitle>In CIKM ’05: Proceedings of the 14th ACM international conference on Information and knowledge management,</booktitle>
<pages>517--524</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1603" citStr="Metzler et al., 2005" startWordPosition="251" endWordPosition="254">obile, or two pieces of text such as I love animals and I own a pet. It is one of the main tasks explored in the field of natural language processing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very large corpora (e.g., (Landauer et al., 1991; Lin, 1998; Gabrilovich and Mar</context>
</contexts>
<marker>Metzler, Bernstein, Croft, Moffat, Zobel, 2005</marker>
<rawString>D. Metzler, Y. Bernstein, W. Bruce Croft, A. Moffat, and J. Zobel. 2005. Similarity measures for tracking information flow. In CIKM ’05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 517–524, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Metzler</author>
<author>S T Dumais</author>
<author>C Meek</author>
</authors>
<title>Similarity measures for short segments of text.</title>
<date>2007</date>
<booktitle>of Lecture Notes in Computer Science,</booktitle>
<volume>4425</volume>
<pages>16--27</pages>
<editor>In Giambattista Amati, Claudio Carpineto, and Giovanni Romano, editors, ECIR,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="1286" citStr="Metzler et al., 2007" startWordPosition="201" endWordPosition="204"> to 47% with respect to the monolingual baseline. 1 Introduction Semantic relatedness is the task of quantifying the strength of the semantic connection between textual units, be they words, sentences, or documents. For instance, one may want to determine how semantically related are two words such as car and automobile, or two pieces of text such as I love animals and I own a pet. It is one of the main tasks explored in the field of natural language processing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the con</context>
</contexts>
<marker>Metzler, Dumais, Meek, 2007</marker>
<rawString>D. Metzler, S. T. Dumais, and C. Meek. 2007. Similarity measures for short segments of text. In Giambattista Amati, Claudio Carpineto, and Giovanni Romano, editors, ECIR, volume 4425 of Lecture Notes in Computer Science, pages 16–27. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>W G Charles</author>
</authors>
<title>Contextual correlates of semantic similarity.</title>
<date>1991</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>6--1</pages>
<contexts>
<context position="12103" citStr="Miller and Charles, 1991" startWordPosition="1836" endWordPosition="1839">ese datasets, we make use of their representation in the four languages of interest. 4.1 Word Relatedness We construct our multilingual word-to-word datasets building upon three word relatedness datasets that have been widely used in the past. Rubenstein and Goodenough (Rubenstein and Goodenough, 1965) (RG65) consists of 65 word pairs ranging from synonymy pairs (e.g., car - automobile) to completely unrelated words (e.g., noon - string). The participating terms in all the pairs are non-technical nouns annotated by 51 human judges on a scale from 0 (unrelated) to 4 (synonyms). Miller-Charles (Miller and Charles, 1991) (MC30) is a subset of RG65, consisting of 30 word pairs annotated for relatedness by 38 human subjects, using the same 0 to 4 scale. WordSimilarity-353 (Finkelstein et al., 2001) (WS353), also known as Finkelstein-353, consists of 353 word pairs annotated by 13 human experts, on a scale from 0 (unrelated) to 10 (synonyms). While containing the MC30 set, it poses an additional degree of difficulty by also including phrases (e.g., “Wednesday news”), proper names and technical terms. To enable a multilingual representation, we use the multilingual datasets introduced by (Hassan and Mihalcea, 200</context>
</contexts>
<marker>Miller, Charles, 1991</marker>
<rawString>G. A. Miller and W. G. Charles. 1991. Contextual correlates of semantic similarity. Language and Cognitive Processes, 6(1):1–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
</authors>
<title>WordNet: a Lexical database for english.</title>
<date>1995</date>
<journal>Communications of the Association for ComputingMachinery,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="4884" citStr="Miller, 1995" startWordPosition="765" endWordPosition="766">natural language processing. We then briefly describe three corpus-based measures of relatedness, and present several word and text datasets that have been used in the past to evaluate relatedness. We then present evaluations and experiments addressing each of the three research questions, and discuss our findings. 2 Related Work Semantic relatedness. The approaches for semantic relatedness that have been considered to date can be grouped into knowledge-based and corpusbased. Knowledge-based methods derive a measure of relatedness by utilizing lexical resources and ontologies such as WordNet (Miller, 1995) to measure definitional overlap (Lesk, 1986), term distance within a graphical taxonomy (Leacock and Chodorow, 1998), term depth in the taxonomy as a measure of specificity (Wu and Palmer, 1994), and others. The application of such measures to a language other than English requires the availability of the lexical resource in that language; furthermore, even though taxonomies such as WordNet (Miller, 1995) are available in a number of languages1, their coverage is still limited, and often times they are not publicly available. For these reasons, in multilingual settings, these measures often b</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>G. A. Miller. 1995. WordNet: a Lexical database for english. Communications of the Association for ComputingMachinery, 38(11):39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mitchell</author>
<author>T Russell</author>
<author>P Broomhead</author>
<author>N Aldridge</author>
</authors>
<title>Towards robust computerised marking of freetext responses.</title>
<date>2002</date>
<booktitle>In roceedings of the 6th International Computer Assisted Assessment (CAA) Conference,</booktitle>
<location>Loughborough, UK. Loughborough University.</location>
<contexts>
<context position="1745" citStr="Mitchell et al., 2002" startWordPosition="273" endWordPosition="276">ocessing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very large corpora (e.g., (Landauer et al., 1991; Lin, 1998; Gabrilovich and Markovitch, 2007)). With almost no exception, these methods have been applied on one language at a time – English, most of the time, although mea</context>
</contexts>
<marker>Mitchell, Russell, Broomhead, Aldridge, 2002</marker>
<rawString>T. Mitchell, T. Russell, P. Broomhead, and N. Aldridge. 2002. Towards robust computerised marking of freetext responses. In roceedings of the 6th International Computer Assisted Assessment (CAA) Conference, Loughborough, UK. Loughborough University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mohler</author>
<author>R Mihalcea</author>
</authors>
<title>Text-to-text semantic similarity for automatic short answer grading.</title>
<date>2009</date>
<booktitle>In EACL,</booktitle>
<pages>567--575</pages>
<institution>The Association for Computer Linguistics.</institution>
<contexts>
<context position="1692" citStr="Mohler and Mihalcea, 2009" startWordPosition="264" endWordPosition="268"> main tasks explored in the field of natural language processing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very large corpora (e.g., (Landauer et al., 1991; Lin, 1998; Gabrilovich and Markovitch, 2007)). With almost no exception, these methods have been applied on one languag</context>
<context position="15156" citStr="Mohler and Mihalcea, 2009" startWordPosition="2326" endWordPosition="2329">are carried out on only 1225 document pairs after ignoring duplicates. Li30 (Li et al., 2006) is a sentence pair similarity dataset obtained by replacing each of the RG65 word-pairs with their respective definitions extracted from the Collins Cobuild dictionary (Sinclair, 2001). Each sentence pair was scored between 0 (unrelated) to 4 (alike) by 32 native English speakers, and their annotations were averaged. Due to the skew in the scores toward low similarity sentence-pairs, they selected a subset of 30 sentences from the 65 sentence pairs to maintain an even relatedness distribution. AG400 (Mohler and Mihalcea, 2009b) is a domain specific dataset from the field of computer science, used to evaluate the application of semantic relatedness measures to real world applications such as short answer grading. We employ the version proposed by (Hassan and Mihalcea, 2011) which consists of 400 student answers along with the corresponding questions and correct instructor answers. Each student answer was graded by two judges on a scale from 0 (completely wrong) to 5 (perfect answer). The correlation between human judges was 2For all the automatic translations we used the Google Translate service. measured at 0.64. </context>
</contexts>
<marker>Mohler, Mihalcea, 2009</marker>
<rawString>M. Mohler and R. Mihalcea. 2009a. Text-to-text semantic similarity for automatic short answer grading. In EACL, pages 567–575. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mohler</author>
<author>R Mihalcea</author>
</authors>
<title>Text-to-text semantic similarity for automatic short answer grading.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>567--575</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1692" citStr="Mohler and Mihalcea, 2009" startWordPosition="264" endWordPosition="268"> main tasks explored in the field of natural language processing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very large corpora (e.g., (Landauer et al., 1991; Lin, 1998; Gabrilovich and Markovitch, 2007)). With almost no exception, these methods have been applied on one languag</context>
<context position="15156" citStr="Mohler and Mihalcea, 2009" startWordPosition="2326" endWordPosition="2329">are carried out on only 1225 document pairs after ignoring duplicates. Li30 (Li et al., 2006) is a sentence pair similarity dataset obtained by replacing each of the RG65 word-pairs with their respective definitions extracted from the Collins Cobuild dictionary (Sinclair, 2001). Each sentence pair was scored between 0 (unrelated) to 4 (alike) by 32 native English speakers, and their annotations were averaged. Due to the skew in the scores toward low similarity sentence-pairs, they selected a subset of 30 sentences from the 65 sentence pairs to maintain an even relatedness distribution. AG400 (Mohler and Mihalcea, 2009b) is a domain specific dataset from the field of computer science, used to evaluate the application of semantic relatedness measures to real world applications such as short answer grading. We employ the version proposed by (Hassan and Mihalcea, 2011) which consists of 400 student answers along with the corresponding questions and correct instructor answers. Each student answer was graded by two judges on a scale from 0 (completely wrong) to 5 (perfect answer). The correlation between human judges was 2For all the automatic translations we used the Google Translate service. measured at 0.64. </context>
</contexts>
<marker>Mohler, Mihalcea, 2009</marker>
<rawString>M. Mohler and R. Mihalcea. 2009b. Text-to-text semantic similarity for automatic short answer grading. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 567–575, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
<author>S Patwardhan</author>
<author>J Michelizzi</author>
</authors>
<title>WordNet::Similarity - measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>In Proceedings of the Nineteenth National Conference on Artificial Intelligence (AAAI-04), demonstrations,</booktitle>
<location>San Jose, CA.</location>
<contexts>
<context position="2055" citStr="Pedersen et al., 2004" startWordPosition="323" endWordPosition="327">on (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very large corpora (e.g., (Landauer et al., 1991; Lin, 1998; Gabrilovich and Markovitch, 2007)). With almost no exception, these methods have been applied on one language at a time – English, most of the time, although measures of relatedness have also been explored on languages such as German (Zesch et al., 2007), Chinese (Li et al., 2005), Japanese (Kazama et al., 2010), and others. In this paper, we take a step further and explore a joint multilingual semantic relatedness metric, which aggregates semantic relatedness scores</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>T. Pedersen, S. Patwardhan, and J. Michelizzi. 2004. WordNet::Similarity - measuring the relatedness of concepts. In Proceedings of the Nineteenth National Conference on Artificial Intelligence (AAAI-04), demonstrations, San Jose, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ponte</author>
<author>W Croft</author>
</authors>
<title>A language modeling approach to information retrieval.</title>
<date>1998</date>
<booktitle>In Proceedings of the Annual International SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>275--281</pages>
<location>Melbourne, Australia.</location>
<contexts>
<context position="1243" citStr="Ponte and Croft, 1998" startWordPosition="195" endWordPosition="198">or this task, and leads to improvements of up to 47% with respect to the monolingual baseline. 1 Introduction Semantic relatedness is the task of quantifying the strength of the semantic connection between textual units, be they words, sentences, or documents. For instance, one may want to determine how semantically related are two words such as car and automobile, or two pieces of text such as I love animals and I own a pet. It is one of the main tasks explored in the field of natural language processing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to </context>
</contexts>
<marker>Ponte, Croft, 1998</marker>
<rawString>J. Ponte and W. Croft. 1998. A language modeling approach to information retrieval. In Proceedings of the Annual International SIGIR Conference on Research and Development in Information Retrieval, pages 275– 281, Melbourne, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S G Pulman</author>
<author>J Z Sukkarieh</author>
</authors>
<title>Automatic short answer marking.</title>
<date>2005</date>
<booktitle>In EdAppsNLP 05: Proceedings of the second workshop on Building Educational Applications Using NLP,</booktitle>
<pages>9--16</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="1721" citStr="Pulman and Sukkarieh, 2005" startWordPosition="269" endWordPosition="272">field of natural language processing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base such as WordNet or Roget (e.g., (Leacock and Chodorow, 1998; Lesk, 1986; Jarmasz and Szpakowicz, 2003; Pedersen et al., 2004)), or to calculate the similarity between the word distributions in very large corpora (e.g., (Landauer et al., 1991; Lin, 1998; Gabrilovich and Markovitch, 2007)). With almost no exception, these methods have been applied on one language at a time – English, most o</context>
</contexts>
<marker>Pulman, Sukkarieh, 2005</marker>
<rawString>S. G. Pulman and J. Z. Sukkarieh. 2005. Automatic short answer marking. In EdAppsNLP 05: Proceedings of the second workshop on Building Educational Applications Using NLP, pages 9–16, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Rubenstein</author>
<author>J B Goodenough</author>
</authors>
<title>Contextual correlates of synonymy.</title>
<date>1965</date>
<journal>Communications of the ACM,</journal>
<volume>8</volume>
<issue>10</issue>
<contexts>
<context position="11781" citStr="Rubenstein and Goodenough, 1965" startWordPosition="1783" endWordPosition="1786">etween their concept-based profiles, where a profile consists of co-occurring salient concepts found within a given window size in a very large corpus. 4 Datasets To evaluate the representation strength of a multilingual semantic relatedness model we employ several standard word-to-word and text-to-text datasets. For each of these datasets, we make use of their representation in the four languages of interest. 4.1 Word Relatedness We construct our multilingual word-to-word datasets building upon three word relatedness datasets that have been widely used in the past. Rubenstein and Goodenough (Rubenstein and Goodenough, 1965) (RG65) consists of 65 word pairs ranging from synonymy pairs (e.g., car - automobile) to completely unrelated words (e.g., noon - string). The participating terms in all the pairs are non-technical nouns annotated by 51 human judges on a scale from 0 (unrelated) to 4 (synonyms). Miller-Charles (Miller and Charles, 1991) (MC30) is a subset of RG65, consisting of 30 word pairs annotated for relatedness by 38 human subjects, using the same 0 to 4 scale. WordSimilarity-353 (Finkelstein et al., 2001) (WS353), also known as Finkelstein-353, consists of 353 word pairs annotated by 13 human experts, </context>
</contexts>
<marker>Rubenstein, Goodenough, 1965</marker>
<rawString>H. Rubenstein and J. B. Goodenough. 1965. Contextual correlates of synonymy. Communications of the ACM, 8(10):627–633, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sahami</author>
<author>T D Heilman</author>
</authors>
<title>A web-based kernel function for measuring the similarity of short text snippets.</title>
<date>2006</date>
<booktitle>In WWW ’06: Proceedings of the 15th international conference on World Wide Web,</booktitle>
<pages>377--386</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1332" citStr="Sahami and Heilman, 2006" startWordPosition="209" endWordPosition="212">seline. 1 Introduction Semantic relatedness is the task of quantifying the strength of the semantic connection between textual units, be they words, sentences, or documents. For instance, one may want to determine how semantically related are two words such as car and automobile, or two pieces of text such as I love animals and I own a pet. It is one of the main tasks explored in the field of natural language processing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by using a knowledge base su</context>
</contexts>
<marker>Sahami, Heilman, 2006</marker>
<rawString>M. Sahami and T. D. Heilman. 2006. A web-based kernel function for measuring the similarity of short text snippets. In WWW ’06: Proceedings of the 15th international conference on World Wide Web, pages 377– 386, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Shivakumar</author>
<author>H Garcia-Molina</author>
</authors>
<title>Scam: A copy detection mechanism for digital documents.</title>
<date>1995</date>
<booktitle>In 2nd International Conference in Theory and Practice ofDigital Libraries (DL</booktitle>
<marker>Shivakumar, Garcia-Molina, 1995</marker>
<rawString>N. Shivakumar and H. Garcia-Molina. 1995. Scam: A copy detection mechanism for digital documents. In 2nd International Conference in Theory and Practice ofDigital Libraries (DL 1995).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Sinclair</author>
</authors>
<title>Collins cobuild English dictionary for advanced learners. Harper Collins, 3rd edition.</title>
<date>2001</date>
<contexts>
<context position="14809" citStr="Sinclair, 2001" startWordPosition="2272" endWordPosition="2273">edness to all the other documents. The users’ annotation is then averaged per document pair, resulting in 2,500 document pairs annotated with their similarity scores. Since it was found that there was no significant difference between annotations given a different order of the documents in a pair (Lee and Welsh, 2005), the evaluations are carried out on only 1225 document pairs after ignoring duplicates. Li30 (Li et al., 2006) is a sentence pair similarity dataset obtained by replacing each of the RG65 word-pairs with their respective definitions extracted from the Collins Cobuild dictionary (Sinclair, 2001). Each sentence pair was scored between 0 (unrelated) to 4 (alike) by 32 native English speakers, and their annotations were averaged. Due to the skew in the scores toward low similarity sentence-pairs, they selected a subset of 30 sentences from the 65 sentence pairs to maintain an even relatedness distribution. AG400 (Mohler and Mihalcea, 2009b) is a domain specific dataset from the field of computer science, used to evaluate the application of semantic relatedness measures to real world applications such as short answer grading. We employ the version proposed by (Hassan and Mihalcea, 2011) </context>
</contexts>
<marker>Sinclair, 2001</marker>
<rawString>J. Sinclair. 2001. Collins cobuild English dictionary for advanced learners. Harper Collins, 3rd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
</authors>
<title>Mining the Web for Synonyms: PMI-IR versus LSA on TOEFL.</title>
<date>2001</date>
<booktitle>In Proceedings of the 12th European Conference on Machine Learning,</booktitle>
<pages>491--502</pages>
<location>Freiburg, Germany.</location>
<contexts>
<context position="5820" citStr="Turney, 2001" startWordPosition="907" endWordPosition="908">e in that language; furthermore, even though taxonomies such as WordNet (Miller, 1995) are available in a number of languages1, their coverage is still limited, and often times they are not publicly available. For these reasons, in multilingual settings, these measures often become untractable. On the other side, corpus-based measures such as Latent Semantic Analysis (LSA) (Landauer et al., 1991), Explicit Semantic Analysis (ESA) (Gabrilovich and Markovitch, 2007), Salient Semantic Analysis (SSA) (Hassan and Mihalcea, 2011), Pointwise Mutual Information (PMI) (Church and Hanks, 1990), PMI-IR (Turney, 2001), Second Order PMI (Islam and Inkpen, 2006), Hyperspace Analogues to Language (HAL) (Burgess et al., 1998) and distributional similarity (Lin, 1998) employ probabilistic approaches to decode the semantics of words. They consist of unsupervised methods that utilize the contextual information and patterns observed in raw text to build semantic profiles of words, and thus they can be easily transferred 1http://www.illc.uva.nl/EuroWordNet/ to a new language provided that a large corpus in that language is available. Multilingual natural language processing. Also relevant is the work done on multil</context>
</contexts>
<marker>Turney, 2001</marker>
<rawString>P. D. Turney. 2001. Mining the Web for Synonyms: PMI-IR versus LSA on TOEFL. In Proceedings of the 12th European Conference on Machine Learning, pages 491–502, Freiburg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Wu</author>
<author>M Palmer</author>
</authors>
<title>Verbs semantics and lexical selection.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd annual meeting on Association for Computational Linguistics,</booktitle>
<pages>133--138</pages>
<location>Las Cruces, New Mexico.</location>
<contexts>
<context position="5079" citStr="Wu and Palmer, 1994" startWordPosition="795" endWordPosition="798">atedness. We then present evaluations and experiments addressing each of the three research questions, and discuss our findings. 2 Related Work Semantic relatedness. The approaches for semantic relatedness that have been considered to date can be grouped into knowledge-based and corpusbased. Knowledge-based methods derive a measure of relatedness by utilizing lexical resources and ontologies such as WordNet (Miller, 1995) to measure definitional overlap (Lesk, 1986), term distance within a graphical taxonomy (Leacock and Chodorow, 1998), term depth in the taxonomy as a measure of specificity (Wu and Palmer, 1994), and others. The application of such measures to a language other than English requires the availability of the lexical resource in that language; furthermore, even though taxonomies such as WordNet (Miller, 1995) are available in a number of languages1, their coverage is still limited, and often times they are not publicly available. For these reasons, in multilingual settings, these measures often become untractable. On the other side, corpus-based measures such as Latent Semantic Analysis (LSA) (Landauer et al., 1991), Explicit Semantic Analysis (ESA) (Gabrilovich and Markovitch, 2007), Sa</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Z. Wu and M. Palmer. 1994. Verbs semantics and lexical selection. In Proceedings of the 32nd annual meeting on Association for Computational Linguistics, pages 133—-138, Las Cruces, New Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W T Yih</author>
<author>C Meek</author>
</authors>
<title>Improving similarity measures for short segments of text.</title>
<date>2007</date>
<booktitle>In AAAI’07: Proceedings of the 22nd national conference on Artificial intelligence,</booktitle>
<pages>1489--1494</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="1306" citStr="Yih and Meek, 2007" startWordPosition="205" endWordPosition="208">o the monolingual baseline. 1 Introduction Semantic relatedness is the task of quantifying the strength of the semantic connection between textual units, be they words, sentences, or documents. For instance, one may want to determine how semantically related are two words such as car and automobile, or two pieces of text such as I love animals and I own a pet. It is one of the main tasks explored in the field of natural language processing, as it lies at the core of a large number of applications such as information retrieval (Ponte and Croft, 1998), query reformulation (Metzler et al., 2007; Yih and Meek, 2007; Sahami and Heilman, 2006; Broder et al., 2008), image retrieval (Leong and Mihalcea, 2009; Goodrum, 2000), plagiarism detection (Hoad and Zobel, 2003; Shivakumar and GarciaMolina, 1995; Broder et al., 1997; Heintze, 1996; Brin et al., 1995; Manber, 1994), information flow (Metzler et al., 2005), sponsored search (Broder et al., 2008), short answer grading (Mohler and Mihalcea, 2009a; Pulman and Sukkarieh, 2005; Mitchell et al., 2002), and textual entailment (Dagan et al., 2005). The typical approach to semantic relatedness is to either measure the distance between the constituent 20 words by</context>
</contexts>
<marker>Yih, Meek, 2007</marker>
<rawString>W. T. Yih and C. Meek. 2007. Improving similarity measures for short segments of text. In AAAI’07: Proceedings of the 22nd national conference on Artificial intelligence, pages 1489–1494. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Zesch</author>
<author>I Gurevych</author>
<author>M M¨uhlh¨auser</author>
</authors>
<title>Comparing Wikipedia and German Wordnet by Evaluating Semantic Relatedness on Multiple Datasets.</title>
<date>2007</date>
<booktitle>In Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<marker>Zesch, Gurevych, M¨uhlh¨auser, 2007</marker>
<rawString>T. Zesch, I. Gurevych, and M. M¨uhlh¨auser. 2007. Comparing Wikipedia and German Wordnet by Evaluating Semantic Relatedness on Multiple Datasets. In Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>