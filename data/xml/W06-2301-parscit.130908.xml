<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.367872">
<title confidence="0.73912625">
Robust Parsing, Error Mining, Automated Lexical
Acquisition, and Evaluation
Gertjan van Noord
University of Groningen
</title>
<email confidence="0.896251">
vannoord@let.rug.nl
</email>
<sectionHeader confidence="0.957038" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999975">
In our attempts to construct a wide coverage HPSG parser for Dutch, techniques to improve
the overall robustness of the parser are required at various steps in the parsing process.
Straightforward but important aspects include the treatment of unknown words, and the
treatment of input for which no full parse is available.
Another important means to improve the parser&apos;s performance on unexpected input is the
ability to learn from your errors. In our methodology we apply the parser to large quantities of
text (preferably from different types of corpora), and we then apply error mining techniques to
identify potential errors, and furthermore we apply machine learning techniques to correct
some of those errors (semi-)automatically, in particular those errors that are due to missing or
incomplete lexical entries.
Evaluating the robustness of a parser is notoriously hard. We argue against coverage as a
meaningful evaluation metric. More generally, we argue against evaluation metrics that do not
take into account accuracy. We propose to use variance of accuracy across sentences (and
more generally across corpora) as a measure for robustness.
</bodyText>
<page confidence="0.969373">
1
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.793140">
<title confidence="0.960235">Robust Parsing, Error Mining, Automated Acquisition, and Evaluation</title>
<author confidence="0.999143">Gertjan van_Noord</author>
<affiliation confidence="0.995492">University of</affiliation>
<email confidence="0.938192">vannoord@let.rug.nl</email>
<abstract confidence="0.999756733333333">In our attempts to construct a wide coverage HPSG parser for Dutch, techniques to improve the overall robustness of the parser are required at various steps in the parsing process. Straightforward but important aspects include the treatment of unknown words, and the treatment of input for which no full parse is available. Another important means to improve the parser&apos;s performance on unexpected input is the ability to learn from your errors. In our methodology we apply the parser to large quantities of text (preferably from different types of corpora), and we then apply error mining techniques to identify potential errors, and furthermore we apply machine learning techniques to correct some of those errors (semi-)automatically, in particular those errors that are due to missing or incomplete lexical entries. Evaluating the robustness of a parser is notoriously hard. We argue against coverage as a meaningful evaluation metric. More generally, we argue against evaluation metrics that do not take into account accuracy. We propose to use variance of accuracy across sentences (and more generally across corpora) as a measure for robustness.</abstract>
<intro confidence="0.921797">1</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>