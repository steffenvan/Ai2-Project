<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000263">
<note confidence="0.539149">
SENSEVAL-3: Third International Workshop on the Evaluation of Systems
for the Semantic Analysis of Text, Barcelona, Spain, July 2004
Association for Computational Linguistics
</note>
<title confidence="0.997438">
Class-based Collocations for Word-Sense Disambiguation
</title>
<author confidence="0.995531">
Tom O’Hara
</author>
<affiliation confidence="0.902334">
Department of Computer Science
New Mexico State University
</affiliation>
<address confidence="0.942023">
Las Cruces, NM 88003-8001
</address>
<email confidence="0.999012">
tomohara@cs.nmsu.edu
</email>
<author confidence="0.99927">
Jeff Donner
</author>
<affiliation confidence="0.902426">
Department of Computer Science
New Mexico State University
</affiliation>
<address confidence="0.94137">
Las Cruces, NM 88003-8001
</address>
<email confidence="0.996927">
jdonner@cs.nmsu.edu
</email>
<sectionHeader confidence="0.995606" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9983297">
This paper describes the NMSU-PITT-UNCA
word-sense disambiguation system participat-
ing in the Senseval-3 English lexical sample
task. The focus of the work is on using seman-
tic class-based collocations to augment tradi-
tional word-based collocations. Three separate
sources of word relatedness are used for these
collocations: 1) WordNet hypernym relations;
2) cluster-based word similarity classes; and 3)
dictionary definition analysis.
</bodyText>
<sectionHeader confidence="0.998985" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999940555555556">
Supervised systems for word-sense disambigua-
tion (WSD) often rely upon word collocations
(i.e., sense-specific keywords) to provide clues
on the most likely sense for a word given the
context. In the second Senseval competition,
these features figured predominantly among the
feature sets for the leading systems (Mihalcea,
2002; Yarowsky et al., 2001; Seo et al., 2001).
A limitation of such features is that the words
selected must occur in the test data in order for
the features to apply. To alleviate this problem,
class-based approaches augment word-level fea-
tures with category-level ones (Ide and V´eronis,
1998; Jurafsky and Martin, 2000). When ap-
plied to collocational features, this approach ef-
fectively uses class labels rather than wordforms
in deriving the collocational features.
This research focuses on the determination
of class-based collocations to improve word-
sense disambiguation. We do not address refine-
ment of existing algorithms for machine learn-
ing. Therefore, a commonly used decision tree
algorithm is employed to combine the various
features when performing classification.
This paper describes the NMSU-PITT-
UNCA system we developed for the third
Senseval competition. Section 2 presents an
</bodyText>
<subsectionHeader confidence="0.754418">
Rebecca Bruce
</subsectionHeader>
<affiliation confidence="0.920428">
Department of Computer Science
University of North Carolina at Asheville
</affiliation>
<address confidence="0.478519">
Asheville, NC 28804-3299
</address>
<email confidence="0.952055">
bruce@cs.unca.edu
</email>
<author confidence="0.84763">
Janyce Wiebe
</author>
<affiliation confidence="0.801726333333333">
Department of Computer Science
University of Pittsburgh
Pittsburgh, PA 15260-4034
</affiliation>
<email confidence="0.752734">
wiebe@cs.pitt.edu
</email>
<bodyText confidence="0.999783">
overview of the feature set used in the system.
Section 3 describes how the class-based colloca-
tions are derived. Section 4 shows the results
over the Senseval-3 data and includes detailed
analysis of the performance of the various col-
locational features.
</bodyText>
<sectionHeader confidence="0.948228" genericHeader="method">
2 System Overview
</sectionHeader>
<bodyText confidence="0.982297772727273">
We use a decision tree algorithm for word-sense
disambiguation that combines features from the
local context of the target word with other lex-
ical features representing the broader context.
Figure 1 presents the features that are used
in this application. In the first Senseval com-
petition, we used the first two groups of fea-
tures, Local-context features and Collocational
features, with competitive results (O’Hara et al.,
2000).
Five of the local-context features represent
the part of speech (POS) of words immediately
surrounding the target word. These five fea-
tures are POS±i for i from -2 to +2), where
POS+1, for example, represents the POS of the
word immediately following the target word.
Five other local-context features represent
the word tokens immediately surrounding the
target word (Word±i for i from −2 to +2).
Each Word±i feature is multi-valued; its values
correspond to all possible word tokens.
There is a collocation feature WordColls de-
fined for each sense s of the target word. It
is a binary feature, representing the absence or
presence of any word in a set specifically chosen
for s. A word w that occurs more than once in
the training data is included in the collocation
set for sense s if the relative percent gain in the
conditional probability over the prior probabil-
Local-context features
POS: part-of-speech of target word
POSfi: part-of-speech of word at offset i
WordForm: target wordform
Wordfi: stem of word at offset i
Collocational features
WordColls: word collocation for sense s
WordColl* wordform of non-sense-specific
collocation (enumerated)
Class-based collocational features
HyperColls: hypernym collocation for s
HyperColl*,i: non-sense-specific hypernym collo-
cation
SimilarColls: similarity collocation for s
DictColls: dictionary collocation for s
</bodyText>
<figureCaption confidence="0.921881">
Figure 1: Features for word-sense disambigua-
</figureCaption>
<bodyText confidence="0.778462">
tion. All collocational features are binary indi-
cators for sense s, except for WordColl*.
</bodyText>
<equation confidence="0.870792">
ity is 20% or higher:
(P(s|w) − P(s)) &gt; 0.20.
P(s) —
</equation>
<bodyText confidence="0.9999475">
This threshold was determined to be effective
via an optimization search over the Senseval-2
data. WordColl* represents a set of non-sense-
specific collocations (i.e., not necessarily indica-
tive of any one sense), chosen via the G2 criteria
(Wiebe et al., 1998). In contrast to WordColls,
each of which is a separate binary feature, the
words contained in the set WordColl* serve as
values in a single enumerated feature.
These features are augmented with class-
based collocational features that represent in-
formation about word relationships derived
from three separate sources: 1) WordNet
(Miller, 1990) hypernym relations (HyperColl);
2) cluster-based word similarity classes (Simi-
larColl); and 3) relatedness inferred from dictio-
nary definition analysis (DictColl). The infor-
mation inherent in the sources from which these
class-based features are derived allows words
that do not occur in the training data context
to be considered as collocations during classifi-
cation.
</bodyText>
<sectionHeader confidence="0.999207" genericHeader="method">
3 Class-based Collocations
</sectionHeader>
<bodyText confidence="0.999847444444445">
The HyperColl features are intended to capture
a portion of the information in the WordNet hy-
pernyms links (i.e., is-a relations). Hypernym-
based collocations are formulated by replacing
each word in the context of the target word (e.g.,
in the same sentence as the target word) with
its complete hypernym ancestry from WordNet.
Since context words are not sense-tagged, each
synset representing a different sense of a context
word is included in the set of hypernyms replac-
ing that word. Likewise, in the case of multiple
inheritance, each parent synset is included.
The collocation variable HyperColls for each
sense s is binary, corresponding to the absence
or presence of any hypernym in the set chosen
for s. This set of hypernyms is chosen using the
ratio of conditional probability to prior prob-
ability as described for the WordColls feature
above. In contrast, HyperColl*,i selects non-
sense-specific hypernym collocations: 10 sepa-
rate binary features are used based on the G2
selection criteria. (More of these features could
be used, but they are limited for tractability.)
For more details on hypernym collocations, see
(O’Hara, forthcoming).
Word-similarity classes (Lin, 1998) derived
from clustering are also used to expand the
pool of potential collocations; this type of se-
mantic relatedness among words is expressed in
the SimilarColl feature. For the DictColl fea-
tures, definition analysis (O’Hara, forthcoming)
is used to determine the semantic relatedness of
the defining words. Differences between these
two sources of word relations are illustrated by
looking at the information they provide for ‘bal-
lerina’:
</bodyText>
<equation confidence="0.977262">
word-clusters:
dancer:0.115 baryshnikov:0.072
pianist:0.056 choreographer:0.049
... [18 other words]
nicole:0.041 wrestler:0.040
tibetans:0.040 clown:0.040
definition words:
dancer:0.0013 female:0.0013 ballet:0.0004
</equation>
<bodyText confidence="0.999576769230769">
This shows that word clusters capture a wider
range of relatedness than the dictionary def-
initions at the expense of incidental associa-
tions (e.g., ‘nicole’). Again, because context
words are not disambiguated, the relations for
all senses of a context word are conflated. For
details on the extraction of word clusters, see
(Lin, 1998); and, for details on the definition
analysis, see (O’Hara, forthcoming).
When formulating the features SimilarColl
and DictColl, the words related to each con-
text word are considered as potential colloca-
tions (Wiebe et al., 1998). Co-occurrence fre-
</bodyText>
<table confidence="0.991206666666667">
Sense Distinctions Precision Recall
Fine-grained .566 .565
Course-grained .660 .658
</table>
<tableCaption confidence="0.997116">
Table 1: Results for Senseval-3 test data.
</tableCaption>
<bodyText confidence="0.9977445">
99.72% of the answers were attempted. All fea-
tures from Figure 1 were used.
quencies f(s, w) are used in estimating the con-
ditional probability P(s|w) required by the rel-
ative conditional probability selection scheme
noted earlier. However, instead of using a unit
weight for each co-occurrence, the relatedness
weight is used (e.g., 0.056 for ‘pianist’); and,
because a given related-word might occur with
more than one context word for the same target-
word sense, the relatedness weights are added.
The conditional probability of the sense given
the relatedness collocation is estimated by di-
viding the weighted frequency by the sum of all
such weighted co-occurrence frequencies for the
word:
Here wf(s, w) stands for the weighted co-
occurrence frequency of the related-word collo-
cation w and target sense s.
The relatedness collocations are less reliable
than word collocations given the level of indi-
rection involved in their extraction. Therefore,
tighter constraints are used in order to filter out
extraneous potential collocations. In particular,
the relative percent gain in the conditional ver-
sus prior probability must be 80% or higher, a
threshold again determined via an optimization
search over the Senseval-2 data. In addition,
the context words that they are related to must
occur more than four times in the training data.
</bodyText>
<sectionHeader confidence="0.999728" genericHeader="evaluation">
4 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999904090909091">
Disambiguation is performed via a decision tree
formulated using Weka’s J4.8 classifier (Witten
and Frank, 1999). For the system used in the
competition, the decision tree was learned over
the entire Senseval-3 training data and then ap-
plied to the test data. Table 1 shows the results
of our system in the Senseval-3 competition.
Table 2 shows the results of 10-fold cross-
validation just over the Senseval-3 training data
(using Naive Bayes rather than decision trees.)
To illustrate the contribution of the three types
</bodyText>
<table confidence="0.999056846153846">
Experiment Precision
−Local +Local
Local - .593
WordColl .490 .599
HyperColl .525 .590
DictColl .532 .570
SimilarColl .534 .586
HyperColl+WordColl .525 .611
DictColl+WordColl .501 .606
SimilarColl+WordColl .518 .596
All Collocations .543 .608
#Words: 57 Avg. Entropy: 1.641
Avg. #Senses: 5.3 Baseline: 0.544
</table>
<tableCaption confidence="0.971485">
Table 2: Results for Senseval-3 training data.
</tableCaption>
<bodyText confidence="0.999830513513514">
All values are averages, except #Words, which
is the number of distinct word types classified.
Baseline always uses the most-frequent sense.
of class-based collocations, the table shows re-
sults separately for systems developed using a
single feature type, as well as for all features in
combination. In addition, the performance of
these systems are shown with and without the
use of the local features (Local), as well as with
and without the use of standard word colloca-
tions (WordColl). As can be seen, the related-
word and definition collocations perform better
than hypernym collocations when used alone.
However, hypernym collocations perform bet-
ter when combined with other features. Fu-
ture work will investigate ways of ameliorat-
ing such interactions. The best overall system
(HyperColl +WordColl +Local) uses the com-
bination of local-context features, word colloca-
tions, and hypernym collocations. The perfor-
mance of this system compared to a more typi-
cal system for WSD (WordColl + Local) is sta-
tistically significant at p &lt; .05, using a paired
t-test.
We analyzed the contributions of the various
collocation types to determine their effective-
ness. Table 3 shows performance statistics for
each collocation type taken individually over the
training data. Precision is based on the num-
ber of correct positive indicators versus the to-
tal number of positive indicators, whereas recall
is the number correct over the total number of
training instances (7706). This shows that hy-
pernym collocations are nearly as effective as
word collocations. We also analyzed the occur-
rence of unique positive indicators provided by
the collocation types over the training data. Ta-
</bodyText>
<table confidence="0.861196333333333">
wf (s, w)
P(s|w)≈
E3, wf (s&apos;, w)
Total Total
Feature #Corr. #Pos. Recall Prec.
DictColl 273 592 .035 .461
HyperColl 2932 6479 .380 .453
SimilarColl 528 1535 .069 .344
WordColl 3707 7718 .481 .480
</table>
<tableCaption confidence="0.996225">
Table 3: Collocation performance statistics.
</tableCaption>
<bodyText confidence="0.436506666666667">
Total #Pos. is number of positive indicators for
the collocation in the training data, and Total
#Corr. is the number of these that are correct.
</bodyText>
<table confidence="0.999470833333333">
Unique Unique
Feature #Corr. #Pos. Prec.
DictColl 110 181 .608
HyperColl 992 1795 .553
SimilarColl 198 464 .427
DictColl 1244 2085 .597
</table>
<tableCaption confidence="0.997467">
Table 4: Analysis of unique positive indicators.
</tableCaption>
<bodyText confidence="0.998503461538462">
Unique #Pos. is number of training instances
with the feature as the only positive indicator,
and Unique #Corr. is number of these correct.
ble 4 shows how often each feature type is pos-
itive for a particular sense when all other fea-
tures for the sense are negative. This occurs
fairly often, suggesting that the different types
of collocations are complementary and thus gen-
erally useful when combined for word-sense dis-
ambiguation. Both tables illustrate coverage
problems for the definition and related word
collocations, which will be addressed in future
work.
</bodyText>
<sectionHeader confidence="0.982935" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.944760017857143">
Nancy Ide and Jean V´eronis. 1998. Introduc-
tion to the special issue on word sense dis-
ambiguation: the state of the art. Computa-
tional Linguistics, 24(1):1–40.
Daniel Jurafsky and James H. Martin. 2000.
Speech and Language Processing. Prentice
Hall, Upper Saddle River, New Jersey.
Dekang Lin. 1998. Automatic retrieval
and clustering of similar words. In Proc.
COLING-ACL 98, pages 768–764, Montreal.
August 10-14.
Rada Mihalcea. 2002. Instance based learning
with automatic feature selection applied to
word sense disambiguation. In Proceedings of
the 19th International Conference on Com-
putational Linguistics (COLING 2002), Tai-
wan. August 26-30.
George Miller. 1990. Introduction. Interna-
tional Journal of Lexicography, 3(4): Special
Issue on WordNet.
Tom O’Hara, Janyce Wiebe, and Rebecca F.
Bruce. 2000. Selecting decomposable models
for word-sense disambiguation: The GRLING-
sDM system. Computers and the Humanities,
34(1-2):159–164.
Thomas P. O’Hara. forthcoming. Empirical ac-
quisition of conceptual distinctions via dictio-
nary definitions. Ph.D. thesis, Department of
Computer Science, New Mexico State Univer-
sity.
Hee-Cheol Seo, Sang-Zoo Lee, Hae-Chang
Rim, and Ho Lee. 2001. KUNLP sys-
tem using classification information model at
SENSEVAL-2. In Proceedings of the Second
International Workshop on Evaluating Word
Sense Disambiguation Systems (SENSEVAL-
2), pages 147–150, Toulouse. July 5-6.
Janyce Wiebe, Kenneth McKeever, and Re-
becca F. Bruce. 1998. Mapping collocational
properties into machine learning features. In
Proc. 6th Workshop on Very Large Corpora
(WVLC-98), pages 225–233, Montreal, Que-
bec, Canada. Association for Computational
Linguistics. SIGDAT.
Ian H. Witten and Eibe Frank. 1999. Data
Mining: Practical Machine Learning Tools
and Techniques with Java Implementations.
Morgan Kaufmann, San Francisco, CA.
David Yarowsky, Silviu Cucerzan, Radu Flo-
rian, Charles Schafer, and Richard Wicen-
towski. 2001. The Johns Hopkins SENSE-
VAL2 system descriptions. In Proceedings of
the Second International Workshop on Eval-
uating Word Sense Disambiguation Systems
(SENSEVAL-2), pages 163–166, Toulouse.
July 5-6.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.135385">
<note confidence="0.711278">SENSEVAL-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, Barcelona, Spain, July 2004</note>
<title confidence="0.887626">Association for Computational Linguistics Class-based Collocations for Word-Sense Disambiguation</title>
<author confidence="0.991255">Tom</author>
<affiliation confidence="0.85193">Department of Computer New Mexico State Las Cruces, NM</affiliation>
<email confidence="0.99891">tomohara@cs.nmsu.edu</email>
<author confidence="0.994014">Jeff</author>
<affiliation confidence="0.825995666666667">Department of Computer New Mexico State Las Cruces, NM</affiliation>
<email confidence="0.999363">jdonner@cs.nmsu.edu</email>
<abstract confidence="0.999210454545455">This paper describes the NMSU-PITT-UNCA word-sense disambiguation system participating in the Senseval-3 English lexical sample task. The focus of the work is on using semantic class-based collocations to augment traditional word-based collocations. Three separate sources of word relatedness are used for these collocations: 1) WordNet hypernym relations; 2) cluster-based word similarity classes; and 3) dictionary definition analysis.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Jean V´eronis</author>
</authors>
<title>Introduction to the special issue on word sense disambiguation: the state of the art.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<marker>Ide, V´eronis, 1998</marker>
<rawString>Nancy Ide and Jean V´eronis. 1998. Introduction to the special issue on word sense disambiguation: the state of the art. Computational Linguistics, 24(1):1–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>James H Martin</author>
</authors>
<title>Speech and Language Processing. Prentice Hall, Upper Saddle River,</title>
<date>2000</date>
<location>New Jersey.</location>
<contexts>
<context position="1573" citStr="Jurafsky and Martin, 2000" startWordPosition="217" endWordPosition="220">r word-sense disambiguation (WSD) often rely upon word collocations (i.e., sense-specific keywords) to provide clues on the most likely sense for a word given the context. In the second Senseval competition, these features figured predominantly among the feature sets for the leading systems (Mihalcea, 2002; Yarowsky et al., 2001; Seo et al., 2001). A limitation of such features is that the words selected must occur in the test data in order for the features to apply. To alleviate this problem, class-based approaches augment word-level features with category-level ones (Ide and V´eronis, 1998; Jurafsky and Martin, 2000). When applied to collocational features, this approach effectively uses class labels rather than wordforms in deriving the collocational features. This research focuses on the determination of class-based collocations to improve wordsense disambiguation. We do not address refinement of existing algorithms for machine learning. Therefore, a commonly used decision tree algorithm is employed to combine the various features when performing classification. This paper describes the NMSU-PITTUNCA system we developed for the third Senseval competition. Section 2 presents an Rebecca Bruce Department o</context>
</contexts>
<marker>Jurafsky, Martin, 2000</marker>
<rawString>Daniel Jurafsky and James H. Martin. 2000. Speech and Language Processing. Prentice Hall, Upper Saddle River, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proc. COLING-ACL 98,</booktitle>
<pages>768--764</pages>
<location>Montreal.</location>
<contexts>
<context position="6838" citStr="Lin, 1998" startWordPosition="1019" endWordPosition="1020">ation variable HyperColls for each sense s is binary, corresponding to the absence or presence of any hypernym in the set chosen for s. This set of hypernyms is chosen using the ratio of conditional probability to prior probability as described for the WordColls feature above. In contrast, HyperColl*,i selects nonsense-specific hypernym collocations: 10 separate binary features are used based on the G2 selection criteria. (More of these features could be used, but they are limited for tractability.) For more details on hypernym collocations, see (O’Hara, forthcoming). Word-similarity classes (Lin, 1998) derived from clustering are also used to expand the pool of potential collocations; this type of semantic relatedness among words is expressed in the SimilarColl feature. For the DictColl features, definition analysis (O’Hara, forthcoming) is used to determine the semantic relatedness of the defining words. Differences between these two sources of word relations are illustrated by looking at the information they provide for ‘ballerina’: word-clusters: dancer:0.115 baryshnikov:0.072 pianist:0.056 choreographer:0.049 ... [18 other words] nicole:0.041 wrestler:0.040 tibetans:0.040 clown:0.040 de</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. In Proc. COLING-ACL 98, pages 768–764, Montreal. August 10-14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
</authors>
<title>Instance based learning with automatic feature selection applied to word sense disambiguation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics (COLING 2002),</booktitle>
<location>Taiwan.</location>
<contexts>
<context position="1254" citStr="Mihalcea, 2002" startWordPosition="167" endWordPosition="168"> semantic class-based collocations to augment traditional word-based collocations. Three separate sources of word relatedness are used for these collocations: 1) WordNet hypernym relations; 2) cluster-based word similarity classes; and 3) dictionary definition analysis. 1 Introduction Supervised systems for word-sense disambiguation (WSD) often rely upon word collocations (i.e., sense-specific keywords) to provide clues on the most likely sense for a word given the context. In the second Senseval competition, these features figured predominantly among the feature sets for the leading systems (Mihalcea, 2002; Yarowsky et al., 2001; Seo et al., 2001). A limitation of such features is that the words selected must occur in the test data in order for the features to apply. To alleviate this problem, class-based approaches augment word-level features with category-level ones (Ide and V´eronis, 1998; Jurafsky and Martin, 2000). When applied to collocational features, this approach effectively uses class labels rather than wordforms in deriving the collocational features. This research focuses on the determination of class-based collocations to improve wordsense disambiguation. We do not address refinem</context>
</contexts>
<marker>Mihalcea, 2002</marker>
<rawString>Rada Mihalcea. 2002. Instance based learning with automatic feature selection applied to word sense disambiguation. In Proceedings of the 19th International Conference on Computational Linguistics (COLING 2002), Taiwan. August 26-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Miller</author>
</authors>
<date>1990</date>
<journal>Introduction. International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<note>Special Issue on WordNet.</note>
<contexts>
<context position="5253" citStr="Miller, 1990" startWordPosition="776" endWordPosition="777">0. P(s) — This threshold was determined to be effective via an optimization search over the Senseval-2 data. WordColl* represents a set of non-sensespecific collocations (i.e., not necessarily indicative of any one sense), chosen via the G2 criteria (Wiebe et al., 1998). In contrast to WordColls, each of which is a separate binary feature, the words contained in the set WordColl* serve as values in a single enumerated feature. These features are augmented with classbased collocational features that represent information about word relationships derived from three separate sources: 1) WordNet (Miller, 1990) hypernym relations (HyperColl); 2) cluster-based word similarity classes (SimilarColl); and 3) relatedness inferred from dictionary definition analysis (DictColl). The information inherent in the sources from which these class-based features are derived allows words that do not occur in the training data context to be considered as collocations during classification. 3 Class-based Collocations The HyperColl features are intended to capture a portion of the information in the WordNet hypernyms links (i.e., is-a relations). Hypernymbased collocations are formulated by replacing each word in the</context>
</contexts>
<marker>Miller, 1990</marker>
<rawString>George Miller. 1990. Introduction. International Journal of Lexicography, 3(4): Special Issue on WordNet.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom O’Hara</author>
<author>Janyce Wiebe</author>
<author>Rebecca F Bruce</author>
</authors>
<title>Selecting decomposable models for word-sense disambiguation:</title>
<date>2000</date>
<booktitle>The GRLINGsDM system. Computers and the Humanities,</booktitle>
<pages>34--1</pages>
<marker>O’Hara, Wiebe, Bruce, 2000</marker>
<rawString>Tom O’Hara, Janyce Wiebe, and Rebecca F. Bruce. 2000. Selecting decomposable models for word-sense disambiguation: The GRLINGsDM system. Computers and the Humanities, 34(1-2):159–164.</rawString>
</citation>
<citation valid="false">
<authors>
<author>forthcoming</author>
</authors>
<title>Empirical acquisition of conceptual distinctions via dictionary definitions.</title>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computer Science, New Mexico State University.</institution>
<marker>forthcoming, </marker>
<rawString>Thomas P. O’Hara. forthcoming. Empirical acquisition of conceptual distinctions via dictionary definitions. Ph.D. thesis, Department of Computer Science, New Mexico State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hee-Cheol Seo</author>
<author>Sang-Zoo Lee</author>
<author>Hae-Chang Rim</author>
<author>Ho Lee</author>
</authors>
<title>KUNLP system using classification information model at SENSEVAL-2.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems (SENSEVAL2),</booktitle>
<pages>147--150</pages>
<location>Toulouse.</location>
<contexts>
<context position="1296" citStr="Seo et al., 2001" startWordPosition="173" endWordPosition="176">ugment traditional word-based collocations. Three separate sources of word relatedness are used for these collocations: 1) WordNet hypernym relations; 2) cluster-based word similarity classes; and 3) dictionary definition analysis. 1 Introduction Supervised systems for word-sense disambiguation (WSD) often rely upon word collocations (i.e., sense-specific keywords) to provide clues on the most likely sense for a word given the context. In the second Senseval competition, these features figured predominantly among the feature sets for the leading systems (Mihalcea, 2002; Yarowsky et al., 2001; Seo et al., 2001). A limitation of such features is that the words selected must occur in the test data in order for the features to apply. To alleviate this problem, class-based approaches augment word-level features with category-level ones (Ide and V´eronis, 1998; Jurafsky and Martin, 2000). When applied to collocational features, this approach effectively uses class labels rather than wordforms in deriving the collocational features. This research focuses on the determination of class-based collocations to improve wordsense disambiguation. We do not address refinement of existing algorithms for machine lea</context>
</contexts>
<marker>Seo, Lee, Rim, Lee, 2001</marker>
<rawString>Hee-Cheol Seo, Sang-Zoo Lee, Hae-Chang Rim, and Ho Lee. 2001. KUNLP system using classification information model at SENSEVAL-2. In Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems (SENSEVAL2), pages 147–150, Toulouse. July 5-6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Kenneth McKeever</author>
<author>Rebecca F Bruce</author>
</authors>
<title>Mapping collocational properties into machine learning features.</title>
<date>1998</date>
<booktitle>In Proc. 6th Workshop on Very Large Corpora (WVLC-98),</booktitle>
<pages>225--233</pages>
<publisher>SIGDAT.</publisher>
<location>Montreal, Quebec,</location>
<contexts>
<context position="4910" citStr="Wiebe et al., 1998" startWordPosition="722" endWordPosition="725">rColls: hypernym collocation for s HyperColl*,i: non-sense-specific hypernym collocation SimilarColls: similarity collocation for s DictColls: dictionary collocation for s Figure 1: Features for word-sense disambiguation. All collocational features are binary indicators for sense s, except for WordColl*. ity is 20% or higher: (P(s|w) − P(s)) &gt; 0.20. P(s) — This threshold was determined to be effective via an optimization search over the Senseval-2 data. WordColl* represents a set of non-sensespecific collocations (i.e., not necessarily indicative of any one sense), chosen via the G2 criteria (Wiebe et al., 1998). In contrast to WordColls, each of which is a separate binary feature, the words contained in the set WordColl* serve as values in a single enumerated feature. These features are augmented with classbased collocational features that represent information about word relationships derived from three separate sources: 1) WordNet (Miller, 1990) hypernym relations (HyperColl); 2) cluster-based word similarity classes (SimilarColl); and 3) relatedness inferred from dictionary definition analysis (DictColl). The information inherent in the sources from which these class-based features are derived al</context>
<context position="8062" citStr="Wiebe et al., 1998" startWordPosition="1191" endWordPosition="1194">ion words: dancer:0.0013 female:0.0013 ballet:0.0004 This shows that word clusters capture a wider range of relatedness than the dictionary definitions at the expense of incidental associations (e.g., ‘nicole’). Again, because context words are not disambiguated, the relations for all senses of a context word are conflated. For details on the extraction of word clusters, see (Lin, 1998); and, for details on the definition analysis, see (O’Hara, forthcoming). When formulating the features SimilarColl and DictColl, the words related to each context word are considered as potential collocations (Wiebe et al., 1998). Co-occurrence freSense Distinctions Precision Recall Fine-grained .566 .565 Course-grained .660 .658 Table 1: Results for Senseval-3 test data. 99.72% of the answers were attempted. All features from Figure 1 were used. quencies f(s, w) are used in estimating the conditional probability P(s|w) required by the relative conditional probability selection scheme noted earlier. However, instead of using a unit weight for each co-occurrence, the relatedness weight is used (e.g., 0.056 for ‘pianist’); and, because a given related-word might occur with more than one context word for the same targetw</context>
</contexts>
<marker>Wiebe, McKeever, Bruce, 1998</marker>
<rawString>Janyce Wiebe, Kenneth McKeever, and Rebecca F. Bruce. 1998. Mapping collocational properties into machine learning features. In Proc. 6th Workshop on Very Large Corpora (WVLC-98), pages 225–233, Montreal, Quebec, Canada. Association for Computational Linguistics. SIGDAT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
</authors>
<date>1999</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco, CA.</location>
<contexts>
<context position="9684" citStr="Witten and Frank, 1999" startWordPosition="1442" endWordPosition="1445">ble than word collocations given the level of indirection involved in their extraction. Therefore, tighter constraints are used in order to filter out extraneous potential collocations. In particular, the relative percent gain in the conditional versus prior probability must be 80% or higher, a threshold again determined via an optimization search over the Senseval-2 data. In addition, the context words that they are related to must occur more than four times in the training data. 4 Results and Discussion Disambiguation is performed via a decision tree formulated using Weka’s J4.8 classifier (Witten and Frank, 1999). For the system used in the competition, the decision tree was learned over the entire Senseval-3 training data and then applied to the test data. Table 1 shows the results of our system in the Senseval-3 competition. Table 2 shows the results of 10-fold crossvalidation just over the Senseval-3 training data (using Naive Bayes rather than decision trees.) To illustrate the contribution of the three types Experiment Precision −Local +Local Local - .593 WordColl .490 .599 HyperColl .525 .590 DictColl .532 .570 SimilarColl .534 .586 HyperColl+WordColl .525 .611 DictColl+WordColl .501 .606 Simila</context>
</contexts>
<marker>Witten, Frank, 1999</marker>
<rawString>Ian H. Witten and Eibe Frank. 1999. Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. Morgan Kaufmann, San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Silviu Cucerzan</author>
<author>Radu Florian</author>
<author>Charles Schafer</author>
<author>Richard Wicentowski</author>
</authors>
<title>The Johns Hopkins SENSEVAL2 system descriptions.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems (SENSEVAL-2),</booktitle>
<pages>163--166</pages>
<location>Toulouse.</location>
<contexts>
<context position="1277" citStr="Yarowsky et al., 2001" startWordPosition="169" endWordPosition="172">based collocations to augment traditional word-based collocations. Three separate sources of word relatedness are used for these collocations: 1) WordNet hypernym relations; 2) cluster-based word similarity classes; and 3) dictionary definition analysis. 1 Introduction Supervised systems for word-sense disambiguation (WSD) often rely upon word collocations (i.e., sense-specific keywords) to provide clues on the most likely sense for a word given the context. In the second Senseval competition, these features figured predominantly among the feature sets for the leading systems (Mihalcea, 2002; Yarowsky et al., 2001; Seo et al., 2001). A limitation of such features is that the words selected must occur in the test data in order for the features to apply. To alleviate this problem, class-based approaches augment word-level features with category-level ones (Ide and V´eronis, 1998; Jurafsky and Martin, 2000). When applied to collocational features, this approach effectively uses class labels rather than wordforms in deriving the collocational features. This research focuses on the determination of class-based collocations to improve wordsense disambiguation. We do not address refinement of existing algorit</context>
</contexts>
<marker>Yarowsky, Cucerzan, Florian, Schafer, Wicentowski, 2001</marker>
<rawString>David Yarowsky, Silviu Cucerzan, Radu Florian, Charles Schafer, and Richard Wicentowski. 2001. The Johns Hopkins SENSEVAL2 system descriptions. In Proceedings of the Second International Workshop on Evaluating Word Sense Disambiguation Systems (SENSEVAL-2), pages 163–166, Toulouse. July 5-6.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>