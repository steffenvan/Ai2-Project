<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000057">
<title confidence="0.981302">
Leveraging Domain-Independent Information in Semantic Parsing
</title>
<author confidence="0.997417">
Dan Goldwasser
</author>
<affiliation confidence="0.99884">
University of Maryland
</affiliation>
<address confidence="0.919528">
College Park, MD 20740
</address>
<email confidence="0.992557">
goldwas1@umiacs.umd.edu
</email>
<sectionHeader confidence="0.997293" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999863538461539">
Semantic parsing is a domain-dependent
process by nature, as its output is defined
over a set of domain symbols. Motivated
by the observation that interpretation can
be decomposed into domain-dependent
and independent components, we suggest
a novel interpretation model, which aug-
ments a domain dependent model with ab-
stract information that can be shared by
multiple domains. Our experiments show
that this type of information is useful and
can reduce the annotation effort signifi-
cantly when moving between domains.
</bodyText>
<sectionHeader confidence="0.999392" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99984516">
Natural Language (NL) understanding can be intu-
itively understood as a general capacity, mapping
words to entities and their relationships. However,
current work on automated NL understanding
(typically referenced as semantic parsing (Zettle-
moyer and Collins, 2005; Wong and Mooney,
2007; Chen and Mooney, 2008; Kwiatkowski et
al., 2010; B¨orschinger et al., 2011)) is restricted
to a given output domain1 (or task) consisting of a
closed set of meaning representation symbols, de-
scribing domains such as robotic soccer, database
queries and flight ordering systems.
In this work, we take a first step towards con-
structing a semantic interpreter that can leverage
information from multiple tasks. This is not a
straight forward objective – the domain specific
nature of semantic interpretation, as described in
the current literature, does not allow for an easy
move between domains. For example, a sys-
tem trained for the task of understanding database
queries will not be of any use when it will be given
a sentence describing robotic soccer instructions.
In order to understand this difficulty, a closer
look at semantic parsing is required. Given a sen-
tence, the interpretation process breaks it into a
</bodyText>
<footnote confidence="0.960873">
1The term domain is overloaded in NLP; in this work we
use it to refer to the set of output symbols.
</footnote>
<author confidence="0.687098">
Dan Roth
</author>
<affiliation confidence="0.5431615">
University of Illinois
Urbana, IL 61801
</affiliation>
<email confidence="0.881902">
danr@illinois.edu
</email>
<bodyText confidence="0.99926515">
set of interdependent decisions, which rely on an
underlying representation mapping words to sym-
bols and syntactic patterns into compositional de-
cisions. This representation takes into account do-
main specific information (e.g., a lexicon mapping
phrases to a domain predicate) and is therefore of
little use when moving to a different domain.
In this work, we attempt to develop a domain in-
dependent approach to semantic parsing. We do it
by developing a layer of representation that is ap-
plicable to multiple domains. Specifically, we add
an intermediate layer capturing shallow semantic
relations between the input sentence constituents.
Unlike semantic parsing which maps the input to
a closed set of symbols, this layer can be used to
identify general predicate-argument structures in
the input sentence.The following example demon-
strates the key idea behind our representation –
two sentences from two different domains have a
similar intermediate structure.
</bodyText>
<listItem confidence="0.55930425">
Example 1. Domains with similar intermediate structures
• The [Pink goalie]ARG [kicks]P RED to [Pink11]ARG
pass(pink1, pink11)
• [She]ARG [walks]PRED to the [kitchen]ARG
</listItem>
<equation confidence="0.733397">
go(sister,kitchen)
</equation>
<bodyText confidence="0.9998144375">
In this case, the constituents of the first
sentence (from the Robocup domain (Chen
and Mooney, 2008)), are assigned domain-
independent predicate-argument labels (e.g., the
word corresponding to a logical function is identi-
fied as a PRED). Note that it does not use any do-
main specific information, for example, the PRED
label assigned to the word “kicks” indicates that
this word is the predicate of the sentence, not a
specific domain predicate (e.g., pass(·)). The in-
termediate layer can be reused across domains.
The logical output associated with the second sen-
tence is taken from a different domain, using a dif-
ferent set of output symbols, however it shares the
same predicate-argument structure.
Despite the idealized example, in practice,
</bodyText>
<page confidence="0.991253">
462
</page>
<bodyText confidence="0.900249857142857">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 462–466,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
leveraging this information is challenging, as the
logical structure is assumed to only weakly corre-
spond to the domain-independent structure, a cor-
respondence which may change in different do-
mains. The mismatch between the domain in-
dependent (linguistic) structure and logical struc-
tures typically stems from technical considera-
tions, as the domain logical language is designed
according to an application-specific logic and not
according to linguistic considerations. This situa-
tion is depicted in the following example, in which
one of the domain-independent labels is omitted.
</bodyText>
<listItem confidence="0.796355">
• The [Pink goalie]ARG [kicks]P RED the [ball]ARG to [Pink11]ARG
</listItem>
<equation confidence="0.591291">
pass(pink1, pink11)
</equation>
<bodyText confidence="0.999752666666667">
In order to overcome this difficulty, we suggest
a flexible model that is able to leverage the super-
vision provided in one domain to learn an abstract
intermediate layer, and show empirically that it
learns a robust model, improving results signifi-
cantly in a second domain.
</bodyText>
<sectionHeader confidence="0.996681" genericHeader="method">
2 Semantic Interpretation Model
</sectionHeader>
<bodyText confidence="0.999982142857143">
Our model consists of both domain-dependent
(mapping between text and a closed set of sym-
bols) and domain independent (abstract predicate-
argument structures) information. We formulate
the joint interpretation process as a structured pre-
diction problem, mapping a NL input sentence (x),
to its highest ranking interpretation and abstract
structure (y). The decision is quantified using a
linear objective, which uses a vector w, mapping
features to weights and a feature function 41) which
maps the output decision to a feature vector. The
output interpretation y is described using a sub-
set of first order logic, consisting of typed con-
stants (e.g., robotic soccer player), functions cap-
turing relations between entities, and their prop-
erties (e.g., pass(x, y), where pass is a function
symbol and x, y are typed arguments). We use
data taken from two grounded domains, describing
robotic soccer events and household situations.
We begin by formulating the domain-specific
process. We follow (Goldwasser et al., 2011;
Clarke et al., 2010) and formalize semantic infer-
ence as an Integer Linear Program (ILP). Due to
space consideration, we provide a brief descrip-
tion (see (Clarke et al., 2010) for more details).
We then proceed to augment this model with
domain-independent information, and connect the
two models by constraining the ILP model.
</bodyText>
<subsectionHeader confidence="0.650135">
2.1 Domain-Dependent Model
</subsectionHeader>
<bodyText confidence="0.999921545454545">
Interpretation is composed of several decisions,
capturing mapping of input tokens to logical frag-
ments (first order) and their composition into
larger fragments (second). We encode a first-order
decision as αcs, a binary variable indicating that
constituent c is aligned with the logical symbol s.
A second-order decision 0cs,dt, is encoded as a bi-
nary variable indicating that the symbol t (associ-
ated with constituent d) is an argument of a func-
tion s (associated with constituent c). The overall
inference problem (Eq. 1) is as follows:
</bodyText>
<equation confidence="0.954349">
FW (X) = arg ma//��xα,β Ec∈x Es∈D αcs · WTΦ1(X c s)
+ Ec,d∈x Es,t∈D Ncs,dt · WTΦ2(X, c, s, d, t) (1)
</equation>
<bodyText confidence="0.999961681818182">
We restrict the possible assignments to the deci-
sion variables, forcing the resulting output formula
to be syntactically legal, for example by restrict-
ing active 0-variables to be type consistent, and
forcing the resulting functional composition to be
acyclic and fully connected (we refer the reader to
(Clarke et al., 2010) for more details). We take ad-
vantage of the flexible ILP framework and encode
these restrictions as global constraints.
Features We use two types of feature, first-order
41)1 and second-order 41)2. 41)1 depends on lexical
information: each mapping of a lexical item c to a
domain symbol s generates a feature. In addition
each combination of a lexical item c and an sym-
bol type generates a feature.
41)2 captures a pair of symbols and their alignment
to lexical items. Given a second-order decision
0cs,dt, a feature is generated considering the nor-
malized distance between the head words in the
constituents c and d. Another feature is gener-
ated for every composition of symbols (ignoring
the alignment to the text).
</bodyText>
<subsectionHeader confidence="0.987464">
2.2 Domain-Independent Information
</subsectionHeader>
<bodyText confidence="0.999951333333334">
We enhance the decision process with informa-
tion that abstracts over the attributes of specific
domains by adding an intermediate layer consist-
ing of the predicate-argument structure of the sen-
tence. Consider the mappings described in Exam-
ple 1. Instead of relying on the mapping between
Pink goalie and pink1, this model tries to iden-
tify an ARG using different means. For example, the
fact that it is preceded by a determiner, or capital-
ized provide useful cues. We do not assume any
language specific knowledge and use features that
help capture these cues.
</bodyText>
<page confidence="0.998673">
463
</page>
<bodyText confidence="0.988130531914894">
This information is used to assist the overall
learning process. We assume that these labels cor-
respond to a binding to some logical symbol, and
encode it as a constraint forcing the relations be-
tween the two models. Moreover, since learning
this layer is a by-product of the learning process
(as it does not use any labeled data) forcing the
connection between the decisions is the mecha-
nism that drives learning this model.
Our domain-independent layer bears some
similarity to other semantic tasks, most no-
tably Semantic-Role Labeling (SRL) introduced
in (Gildea and Jurafsky, 2002), in which identi-
fying the predicate-argument structure is consid-
ered a preprocessing step, prior to assigning ar-
gument labels. Unlike SRL, which aims to iden-
tify linguistic structures alone, in our framework
these structures capture both natural-language and
domain-language considerations.
Domain-Independent Decision Variables We
add two new types of decisions abstracting over
the domain-specific decisions. We encode the new
decisions as -y and J d. The first (-y) captures local
information helping to determine if a given con-
stituent c is likely to have a label (i.e., -yP for pred-
icate or -yA for argument). The second (J) consid-
ers higher level structures, quantifying decisions
over both the labels of the constituents c,d as a
predicate-argument pair. Note, a given word c can
be labeled as FRED or ARG if -y and J d are active.
Model’s Features We use the following fea-
tures: (1) Local Decisions Φ3(-y(c)) use a feature
indicating if c is capitalized, a set of features cap-
turing the context of c (window of size 2), such
as determiner and quantifier occurrences. Finally
we use a set of features capturing the suffix letters
of c, these features are useful in identifying verb
patterns. Features indicate if c is mapped to an ARG
or FRED. (2) Global Decision Φ4(J(c, d)): a feature
indicating the relative location of c compared to d
in the input sentence. Additional features indicate
properties of the relative location, such as if the
word appears initially or finally in the sentence.
Combined Model In order to consider both
types of information we augment our decision
model with the new variables, resulting in the fol-
lowing objective function (Eq. 2).
</bodyText>
<equation confidence="0.5450752">
[Fw (x) = arg maxα,β/�&amp;∈x Ps∈D αcs·w1TΦ1(x, c, s)+
Ec,d∈x Ps,t∈D Pi,j Ncsi,dtj · w2T Φ2(x, c, si, d, tj) +
�
`
/�cEx γc·w3T Φ3(x, c)
</equation>
<bodyText confidence="0.843612111111111">
For notational convenience we decompose the
weight vector w into four parts, w1, w2 for fea-
tures of (first, second) order domain-dependent de-
cisions, and similarly for the independent ones.
In addition, we also add new constraints tying
these new variables to semantic interpretation :
∀c ∈ x (γc → αc,s1 ∨ αc,s2 ∨ ... ∨ αc,sn)
∀c ∈ x, ∀d ∈ x (δc,d → βc,s1,dt1∨βc,s2,dt1∨...∨βc,sn,dtn)
(where n is the length of x).
</bodyText>
<subsectionHeader confidence="0.999148">
2.3 Learning the Combined Model
</subsectionHeader>
<bodyText confidence="0.999943166666667">
The supervision to the learning process is given
via data consisting of pairs of sentences and (do-
main specific) semantic interpretation. Given that
we have introduced additional variables that cap-
ture the more abstract predicate-argument struc-
ture of the text, we need to induce these as la-
tent variables. Our decision model maps an input
sentence x, into a logical output y and predicate-
argument structure h. We are only supplied with
training data pertaining to the input (x) and out-
put (y). We use a variant of the latent structure
perceptron to learn in these settings2.
</bodyText>
<sectionHeader confidence="0.997916" genericHeader="method">
3 Experimental Settings
</sectionHeader>
<bodyText confidence="0.997627043478261">
Situated Language This dataset, introduced in
(Bordes et al., 2010), describes situations in a sim-
ulated world. The dataset consists of triplets of the
form - (x,u, y), where x is a NL sentence describ-
ing a situation (e.g., “He goes to the kitchen”), u
is a world state consisting of grounded relations
(e.g., loc(John, Kitchen)) description, and y is
a logical interpretation corresponding to x.
The original dataset was used for concept tag-
ging, which does not include a compositional as-
pect. We automatically generated the full logical
structure by mapping the constants to function ar-
guments. We generated additional function sym-
bols of the same relation, but of different arity
when needed 3. Our new dataset consists of 25 re-
lation symbols (originally 15). In our experiments
we used a set of 5000 of the training triplets.
Robocup The Robocup dataset, originally in-
troduced in (Chen and Mooney, 2008), describes
robotic soccer events. The dataset was collected
for the purpose of constructing semantic parsers
from ambiguous supervision and consists of both
“noisy” and gold labeled data. The noisy dataset
</bodyText>
<footnote confidence="0.9154265">
2Details omitted, see (Chang et al., 2010) for more details.
3For example, a unary relation symbol for “He plays”,
and a binary for “He plays with a ball”.
+Pc,d∈x δcd ·w4TΦ4(x, c, d) (2)
</footnote>
<page confidence="0.992647">
464
</page>
<table confidence="0.9942145">
System Training Procedure
DOM-INIT w1: Noisy probabilistic model, described below.
FRED-ARGS Only w3, w4 Trained over the Situ. dataset.
COMBINEDRL w1, w2, w3, w4:learned from Robocup gold
COMBINEDRI+S w3, w4: learned from the Situ. dataset,
w1 uses the DOM-INIT Robocup model.
COMBINEDRL+S w3, w4: Initially learned over the Situ. dataset,
updated jointly with w1, w2 over Robocup gold
</table>
<tableCaption confidence="0.99959">
Table 1: Evaluated System descriptions.
</tableCaption>
<bodyText confidence="0.999668769230769">
was constructed by temporally aligning a stream
of soccer events occurring during a robotic soc-
cer match with human commentary describing the
game. This dataset consists of pairs (x, {y0, yk}),
x is a sentence and {y0, yk} is a set of events (log-
ical formulas). One of these events is assumed to
correspond to the comment, however this is not
guaranteed. The gold labeled labeled data con-
sists of pairs (x, y). The data was collected from
four Robocup games. In our experiments we fol-
low other works and use 4-fold cross validation,
training over 3 games and testing over the remain-
ing game. We evaluate the Accuracy of the parser
over the test game data.4 Due to space consider-
ations, we refer the reader to (Chen and Mooney,
2008) for further details about this dataset.
Semantic Interpretation Tasks We consider
two of the tasks described in (Chen and Mooney,
2008) (1) Semantic Parsing requires generating
the correct logical form given an input sentence.
(2) Matching, given a NL sentence and a set of
several possible interpretation candidates, the sys-
tem is required to identify the correct one. In all
systems, the source for domain-independent infor-
mation is the Situated domain, and the results are
evaluated over the Robocup domain.
Experimental Systems We tested several vari-
ations, all solving Eq. 2, however different re-
sources were used to obtain Eq. 2 parameters (see
sec. 2.2). Tab. 1 describes the different varia-
tions. We used the noisy Robocup dataset to ini-
tialize DOM-INIT, a noisy probabilistic model, con-
structed by taking statistics over the noisy robocup
data and computing p(y|x). Given the training set
{(x, {y1, .., yk})}, every word in x is aligned to
every symbol in every y that is aligned with it. The
probability of a matching (x, y)is computed as the
product: Hni=, p(yi|xi), where n is the number
of symbols appearing in y, and xi, yi is the word
</bodyText>
<footnote confidence="0.831336">
4In our model accuracy is equivalent to F-measure.
</footnote>
<table confidence="0.934437166666667">
System Matching Parsing
PRED-ARGS 0.692 –
DOM-INIT 0.823 0.357
COMBINEDRI+S 0.905 0.627
(B ¨ORSCHINGER ET AL., 2011) – 0.86
(KIM AND MOONEY, 2010) 0.885 0.742
</table>
<tableCaption confidence="0.98885">
Table 2: Results for the matching and parsing tasks. Our
system performs well on the matching task without any do-
main information. Results for both parsing and matching
tasks show that using domain-independent information im-
proves results dramatically.
</tableCaption>
<bodyText confidence="0.999729">
level matching to a logical symbol. Note that this
model uses lexical information only.
</bodyText>
<sectionHeader confidence="0.944438" genericHeader="method">
4 Knowledge Transfer Experiments
</sectionHeader>
<bodyText confidence="0.999883243243243">
We begin by studying the role of domain-
independent information when very little domain
information is available. Domain-independent in-
formation is learned from the situated domain
and domain-specific information (Robocup) avail-
able is the simple probabilistic model (DOM-INIT).
This model can be considered as a noisy proba-
bilistic lexicon, without any domain-specific com-
positional information, which is only available
through domain-independent information.
The results, summarized in Table 2, show that
in both tasks domain-independent information is
extremely useful and can make up for missing do-
main information. Most notably, performance for
the matching task using only domain independent
information (PRED-ARGS) was surprisingly good,
with an accuracy of 0.69. Adding domain-specific
lexical information (COMBINEDRI+S) pushes this
result to over 0.9, currently the highest for this task
– achieved without domain specific learning.
The second set of experiments study whether
using domain independent information, when rel-
evant (gold) domain-specific training data is avail-
able, improves learning. In this scenario, the
domain-independent model is updated according
to training data available for the Robocup domain.
We compare two system over varying amounts
of training data (25, 50, 200 training samples
and the full set of 3 Robocup games), one boot-
strapped using the Situ. domain (COMBINEDRL+S)
and one relying on the Robocup training data
alone (COMBINEDRL). The results, summarized in
table 3, consistently show that transferring domain
independent information is helpful, and helps push
the learned models beyond the supervision offered
by the relevant domain training data. Our final
system, trained over the entire dataset achieves a
</bodyText>
<page confidence="0.998406">
465
</page>
<table confidence="0.9995695">
System # training Parsing
COMBINEDRL+g(COMBINEDRL) 25 0.16 (0.03)
COMBINEDRL+g(COMBINEDRL) 50 0.323 (0.16)
COMBINEDRL+g(COMBINEDRL) 200 0.385 (0.36)
COMBINEDRL+g(COMBINEDRL) full game 0.86 (0.79)
(CHEN ET AL., 2010) full game 0.81
</table>
<tableCaption confidence="0.9886972">
Table 3: Evaluating our model in a learning settings. The
domain-independent information is used to bootstrap learn-
ing from the Robocup domain. Results show that this infor-
mation improves performance significantly, especially when
little data is available
</tableCaption>
<bodyText confidence="0.999962333333333">
score of 0.86, significantly outperforming (Chen
et al., 2010), a competing supervised model. It
achieves similar results to (B¨orschinger et al.,
2011), the current state-of-the-art for the pars-
ing task over this dataset. The system used in
(B¨orschinger et al., 2011) learns from ambigu-
ous training data and achieves this score by using
global information. We hypothesize that it can be
used by our model and leave it for future work.
</bodyText>
<sectionHeader confidence="0.999575" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.99997404">
In this paper, we took a first step towards a new
kind of generalization in semantic parsing: con-
structing a model that is able to generalize to a
new domain defined over a different set of sym-
bols. Our approach adds an additional hidden
layer to the semantic interpretation process, cap-
turing shallow but domain-independent semantic
information, which can be shared by different do-
mains. Our experiments consistently show that
domain-independent knowledge can be transferred
between domains. We describe two settings; in
the first, where only noisy lexical-level domain-
specific information is available, we observe that
the model learned in the other domain can be used
to make up for the missing compositional infor-
mation. For example, in the matching task, even
when no domain information is available, iden-
tifying the abstract predicate argument structure
provides sufficient discriminatory power to iden-
tify the correct event in over 69% of the times.
In the second setting domain-specific examples
are available. The learning process can still utilize
the transferred knowledge, as it provides scaffold-
ing for the latent learning process, resulting in a
significant improvement in performance.
</bodyText>
<sectionHeader confidence="0.999461" genericHeader="acknowledgments">
6 Acknowledgement
</sectionHeader>
<bodyText confidence="0.978865235294118">
The authors would like to thank Julia Hockenmaier, Gerald
DeJong, Raymond Mooney and the anonymous reviewers for
their efforts and insightful comments.
Most of this work was done while the first author was
at the University of Illinois. The authors gratefully ac-
knowledge the support of the Defense Advanced Research
Projects Agency (DARPA) Machine Reading Program un-
der Air Force Research Laboratory (AFRL) prime contract
no. FA8750-09-C-0181. In addition, this material is based
on research sponsored by DARPA under agreement number
FA8750-13-2-0008. The U.S. Government is authorized to
reproduce and distribute reprints for Governmental purposes
notwithstanding any copyright notation thereon. The views
and conclusions contained herein are those of the authors and
should not be interpreted as necessarily representing the offi-
cial policies or endorsements, either expressed or implied, of
DARPA,AFRL, or the U.S. Government.
</bodyText>
<sectionHeader confidence="0.999427" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999135583333334">
A. Bordes, N. Usunier, R. Collobert, and J. Weston.
2010. Towards understanding situated natural lan-
guage. In AISTATS.
B. B¨orschinger, B. K. Jones, and M. Johnson. 2011.
Reducing grounded learning tasks to grammatical
inference. In EMNLP.
M. Chang, D. Goldwasser, D. Roth, and V. Srikumar.
2010. Discriminative learning over constrained la-
tent representations. In NAACL.
D. Chen and R. Mooney. 2008. Learning to sportscast:
a test of grounded language acquisition. In ICML.
D. L. Chen, J. Kim, and R. J. Mooney. 2010. Training
a multilingual sportscaster: Using perceptual con-
text to learn language. Journal of Artificial Intelli-
gence Research, 37:397–435.
J. Clarke, D. Goldwasser, M. Chang, and D. Roth.
2010. Driving semantic parsing from the world’s
response. In CoNLL.
D. Gildea and D. Jurafsky. 2002. Automatic labeling
of semantic roles. Computational Linguistics.
D. Goldwasser, R. Reichart, J. Clarke, and D. Roth.
2011. Confidence driven unsupervised semantic
parsing. In ACL.
J. Kim and R. J. Mooney. 2010. Generative alignment
and semantic parsing for learning from ambiguous
supervision. In COLING.
T. Kwiatkowski, L. Zettlemoyer, S. Goldwater, , and
M. Steedman. 2010. Inducing probabilistic ccg
grammars from logical form with higher-order uni-
fication. In EMNLP.
Y.W. Wong and R. Mooney. 2007. Learning
synchronous grammars for semantic parsing with
lambda calculus. In ACL.
L. Zettlemoyer and M. Collins. 2005. Learning to map
sentences to logical form: Structured classification
with probabilistic categorial grammars. In UAI.
</reference>
<page confidence="0.999594">
466
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.942459">
<title confidence="0.999982">Leveraging Domain-Independent Information in Semantic Parsing</title>
<author confidence="0.996152">Dan</author>
<affiliation confidence="0.999813">University of</affiliation>
<address confidence="0.967351">College Park, MD</address>
<email confidence="0.993473">goldwas1@umiacs.umd.edu</email>
<abstract confidence="0.998745571428571">Semantic parsing is a domain-dependent process by nature, as its output is defined over a set of domain symbols. Motivated by the observation that interpretation can be decomposed into domain-dependent and independent components, we suggest a novel interpretation model, which augments a domain dependent model with abstract information that can be shared by multiple domains. Our experiments show that this type of information is useful and can reduce the annotation effort significantly when moving between domains.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Bordes</author>
<author>N Usunier</author>
<author>R Collobert</author>
<author>J Weston</author>
</authors>
<title>Towards understanding situated natural language.</title>
<date>2010</date>
<booktitle>In AISTATS.</booktitle>
<contexts>
<context position="12292" citStr="Bordes et al., 2010" startWordPosition="1956" endWordPosition="1959">n via data consisting of pairs of sentences and (domain specific) semantic interpretation. Given that we have introduced additional variables that capture the more abstract predicate-argument structure of the text, we need to induce these as latent variables. Our decision model maps an input sentence x, into a logical output y and predicateargument structure h. We are only supplied with training data pertaining to the input (x) and output (y). We use a variant of the latent structure perceptron to learn in these settings2. 3 Experimental Settings Situated Language This dataset, introduced in (Bordes et al., 2010), describes situations in a simulated world. The dataset consists of triplets of the form - (x,u, y), where x is a NL sentence describing a situation (e.g., “He goes to the kitchen”), u is a world state consisting of grounded relations (e.g., loc(John, Kitchen)) description, and y is a logical interpretation corresponding to x. The original dataset was used for concept tagging, which does not include a compositional aspect. We automatically generated the full logical structure by mapping the constants to function arguments. We generated additional function symbols of the same relation, but of </context>
</contexts>
<marker>Bordes, Usunier, Collobert, Weston, 2010</marker>
<rawString>A. Bordes, N. Usunier, R. Collobert, and J. Weston. 2010. Towards understanding situated natural language. In AISTATS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B B¨orschinger</author>
<author>B K Jones</author>
<author>M Johnson</author>
</authors>
<title>Reducing grounded learning tasks to grammatical inference.</title>
<date>2011</date>
<booktitle>In EMNLP.</booktitle>
<marker>B¨orschinger, Jones, Johnson, 2011</marker>
<rawString>B. B¨orschinger, B. K. Jones, and M. Johnson. 2011. Reducing grounded learning tasks to grammatical inference. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chang</author>
<author>D Goldwasser</author>
<author>D Roth</author>
<author>V Srikumar</author>
</authors>
<title>Discriminative learning over constrained latent representations.</title>
<date>2010</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="13381" citStr="Chang et al., 2010" startWordPosition="2134" endWordPosition="2137">l structure by mapping the constants to function arguments. We generated additional function symbols of the same relation, but of different arity when needed 3. Our new dataset consists of 25 relation symbols (originally 15). In our experiments we used a set of 5000 of the training triplets. Robocup The Robocup dataset, originally introduced in (Chen and Mooney, 2008), describes robotic soccer events. The dataset was collected for the purpose of constructing semantic parsers from ambiguous supervision and consists of both “noisy” and gold labeled data. The noisy dataset 2Details omitted, see (Chang et al., 2010) for more details. 3For example, a unary relation symbol for “He plays”, and a binary for “He plays with a ball”. +Pc,d∈x δcd ·w4TΦ4(x, c, d) (2) 464 System Training Procedure DOM-INIT w1: Noisy probabilistic model, described below. FRED-ARGS Only w3, w4 Trained over the Situ. dataset. COMBINEDRL w1, w2, w3, w4:learned from Robocup gold COMBINEDRI+S w3, w4: learned from the Situ. dataset, w1 uses the DOM-INIT Robocup model. COMBINEDRL+S w3, w4: Initially learned over the Situ. dataset, updated jointly with w1, w2 over Robocup gold Table 1: Evaluated System descriptions. was constructed by temp</context>
</contexts>
<marker>Chang, Goldwasser, Roth, Srikumar, 2010</marker>
<rawString>M. Chang, D. Goldwasser, D. Roth, and V. Srikumar. 2010. Discriminative learning over constrained latent representations. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chen</author>
<author>R Mooney</author>
</authors>
<title>Learning to sportscast: a test of grounded language acquisition.</title>
<date>2008</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="999" citStr="Chen and Mooney, 2008" startWordPosition="139" endWordPosition="142">onents, we suggest a novel interpretation model, which augments a domain dependent model with abstract information that can be shared by multiple domains. Our experiments show that this type of information is useful and can reduce the annotation effort significantly when moving between domains. 1 Introduction Natural Language (NL) understanding can be intuitively understood as a general capacity, mapping words to entities and their relationships. However, current work on automated NL understanding (typically referenced as semantic parsing (Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Chen and Mooney, 2008; Kwiatkowski et al., 2010; B¨orschinger et al., 2011)) is restricted to a given output domain1 (or task) consisting of a closed set of meaning representation symbols, describing domains such as robotic soccer, database queries and flight ordering systems. In this work, we take a first step towards constructing a semantic interpreter that can leverage information from multiple tasks. This is not a straight forward objective – the domain specific nature of semantic interpretation, as described in the current literature, does not allow for an easy move between domains. For example, a system trai</context>
<context position="3317" citStr="Chen and Mooney, 2008" startWordPosition="502" endWordPosition="505">tuents. Unlike semantic parsing which maps the input to a closed set of symbols, this layer can be used to identify general predicate-argument structures in the input sentence.The following example demonstrates the key idea behind our representation – two sentences from two different domains have a similar intermediate structure. Example 1. Domains with similar intermediate structures • The [Pink goalie]ARG [kicks]P RED to [Pink11]ARG pass(pink1, pink11) • [She]ARG [walks]PRED to the [kitchen]ARG go(sister,kitchen) In this case, the constituents of the first sentence (from the Robocup domain (Chen and Mooney, 2008)), are assigned domainindependent predicate-argument labels (e.g., the word corresponding to a logical function is identified as a PRED). Note that it does not use any domain specific information, for example, the PRED label assigned to the word “kicks” indicates that this word is the predicate of the sentence, not a specific domain predicate (e.g., pass(·)). The intermediate layer can be reused across domains. The logical output associated with the second sentence is taken from a different domain, using a different set of output symbols, however it shares the same predicate-argument structure</context>
<context position="13132" citStr="Chen and Mooney, 2008" startWordPosition="2097" endWordPosition="2100">rounded relations (e.g., loc(John, Kitchen)) description, and y is a logical interpretation corresponding to x. The original dataset was used for concept tagging, which does not include a compositional aspect. We automatically generated the full logical structure by mapping the constants to function arguments. We generated additional function symbols of the same relation, but of different arity when needed 3. Our new dataset consists of 25 relation symbols (originally 15). In our experiments we used a set of 5000 of the training triplets. Robocup The Robocup dataset, originally introduced in (Chen and Mooney, 2008), describes robotic soccer events. The dataset was collected for the purpose of constructing semantic parsers from ambiguous supervision and consists of both “noisy” and gold labeled data. The noisy dataset 2Details omitted, see (Chang et al., 2010) for more details. 3For example, a unary relation symbol for “He plays”, and a binary for “He plays with a ball”. +Pc,d∈x δcd ·w4TΦ4(x, c, d) (2) 464 System Training Procedure DOM-INIT w1: Noisy probabilistic model, described below. FRED-ARGS Only w3, w4 Trained over the Situ. dataset. COMBINEDRL w1, w2, w3, w4:learned from Robocup gold COMBINEDRI+S</context>
<context position="14690" citStr="Chen and Mooney, 2008" startWordPosition="2356" endWordPosition="2359">human commentary describing the game. This dataset consists of pairs (x, {y0, yk}), x is a sentence and {y0, yk} is a set of events (logical formulas). One of these events is assumed to correspond to the comment, however this is not guaranteed. The gold labeled labeled data consists of pairs (x, y). The data was collected from four Robocup games. In our experiments we follow other works and use 4-fold cross validation, training over 3 games and testing over the remaining game. We evaluate the Accuracy of the parser over the test game data.4 Due to space considerations, we refer the reader to (Chen and Mooney, 2008) for further details about this dataset. Semantic Interpretation Tasks We consider two of the tasks described in (Chen and Mooney, 2008) (1) Semantic Parsing requires generating the correct logical form given an input sentence. (2) Matching, given a NL sentence and a set of several possible interpretation candidates, the system is required to identify the correct one. In all systems, the source for domain-independent information is the Situated domain, and the results are evaluated over the Robocup domain. Experimental Systems We tested several variations, all solving Eq. 2, however different </context>
</contexts>
<marker>Chen, Mooney, 2008</marker>
<rawString>D. Chen and R. Mooney. 2008. Learning to sportscast: a test of grounded language acquisition. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D L Chen</author>
<author>J Kim</author>
<author>R J Mooney</author>
</authors>
<title>Training a multilingual sportscaster: Using perceptual context to learn language.</title>
<date>2010</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>37--397</pages>
<contexts>
<context position="18731" citStr="Chen et al., 2010" startWordPosition="2966" endWordPosition="2969">ta. Our final system, trained over the entire dataset achieves a 465 System # training Parsing COMBINEDRL+g(COMBINEDRL) 25 0.16 (0.03) COMBINEDRL+g(COMBINEDRL) 50 0.323 (0.16) COMBINEDRL+g(COMBINEDRL) 200 0.385 (0.36) COMBINEDRL+g(COMBINEDRL) full game 0.86 (0.79) (CHEN ET AL., 2010) full game 0.81 Table 3: Evaluating our model in a learning settings. The domain-independent information is used to bootstrap learning from the Robocup domain. Results show that this information improves performance significantly, especially when little data is available score of 0.86, significantly outperforming (Chen et al., 2010), a competing supervised model. It achieves similar results to (B¨orschinger et al., 2011), the current state-of-the-art for the parsing task over this dataset. The system used in (B¨orschinger et al., 2011) learns from ambiguous training data and achieves this score by using global information. We hypothesize that it can be used by our model and leave it for future work. 5 Conclusions In this paper, we took a first step towards a new kind of generalization in semantic parsing: constructing a model that is able to generalize to a new domain defined over a different set of symbols. Our approach</context>
</contexts>
<marker>Chen, Kim, Mooney, 2010</marker>
<rawString>D. L. Chen, J. Kim, and R. J. Mooney. 2010. Training a multilingual sportscaster: Using perceptual context to learn language. Journal of Artificial Intelligence Research, 37:397–435.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Clarke</author>
<author>D Goldwasser</author>
<author>M Chang</author>
<author>D Roth</author>
</authors>
<title>Driving semantic parsing from the world’s response.</title>
<date>2010</date>
<booktitle>In CoNLL.</booktitle>
<contexts>
<context position="6165" citStr="Clarke et al., 2010" startWordPosition="939" endWordPosition="942">vector w, mapping features to weights and a feature function 41) which maps the output decision to a feature vector. The output interpretation y is described using a subset of first order logic, consisting of typed constants (e.g., robotic soccer player), functions capturing relations between entities, and their properties (e.g., pass(x, y), where pass is a function symbol and x, y are typed arguments). We use data taken from two grounded domains, describing robotic soccer events and household situations. We begin by formulating the domain-specific process. We follow (Goldwasser et al., 2011; Clarke et al., 2010) and formalize semantic inference as an Integer Linear Program (ILP). Due to space consideration, we provide a brief description (see (Clarke et al., 2010) for more details). We then proceed to augment this model with domain-independent information, and connect the two models by constraining the ILP model. 2.1 Domain-Dependent Model Interpretation is composed of several decisions, capturing mapping of input tokens to logical fragments (first order) and their composition into larger fragments (second). We encode a first-order decision as αcs, a binary variable indicating that constituent c is a</context>
<context position="7467" citStr="Clarke et al., 2010" startWordPosition="1152" endWordPosition="1155">binary variable indicating that the symbol t (associated with constituent d) is an argument of a function s (associated with constituent c). The overall inference problem (Eq. 1) is as follows: FW (X) = arg ma//��xα,β Ec∈x Es∈D αcs · WTΦ1(X c s) + Ec,d∈x Es,t∈D Ncs,dt · WTΦ2(X, c, s, d, t) (1) We restrict the possible assignments to the decision variables, forcing the resulting output formula to be syntactically legal, for example by restricting active 0-variables to be type consistent, and forcing the resulting functional composition to be acyclic and fully connected (we refer the reader to (Clarke et al., 2010) for more details). We take advantage of the flexible ILP framework and encode these restrictions as global constraints. Features We use two types of feature, first-order 41)1 and second-order 41)2. 41)1 depends on lexical information: each mapping of a lexical item c to a domain symbol s generates a feature. In addition each combination of a lexical item c and an symbol type generates a feature. 41)2 captures a pair of symbols and their alignment to lexical items. Given a second-order decision 0cs,dt, a feature is generated considering the normalized distance between the head words in the con</context>
</contexts>
<marker>Clarke, Goldwasser, Chang, Roth, 2010</marker>
<rawString>J. Clarke, D. Goldwasser, M. Chang, and D. Roth. 2010. Driving semantic parsing from the world’s response. In CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics.</journal>
<contexts>
<context position="9371" citStr="Gildea and Jurafsky, 2002" startWordPosition="1465" endWordPosition="1468">atures that help capture these cues. 463 This information is used to assist the overall learning process. We assume that these labels correspond to a binding to some logical symbol, and encode it as a constraint forcing the relations between the two models. Moreover, since learning this layer is a by-product of the learning process (as it does not use any labeled data) forcing the connection between the decisions is the mechanism that drives learning this model. Our domain-independent layer bears some similarity to other semantic tasks, most notably Semantic-Role Labeling (SRL) introduced in (Gildea and Jurafsky, 2002), in which identifying the predicate-argument structure is considered a preprocessing step, prior to assigning argument labels. Unlike SRL, which aims to identify linguistic structures alone, in our framework these structures capture both natural-language and domain-language considerations. Domain-Independent Decision Variables We add two new types of decisions abstracting over the domain-specific decisions. We encode the new decisions as -y and J d. The first (-y) captures local information helping to determine if a given constituent c is likely to have a label (i.e., -yP for predicate or -yA</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>D. Gildea and D. Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Goldwasser</author>
<author>R Reichart</author>
<author>J Clarke</author>
<author>D Roth</author>
</authors>
<title>Confidence driven unsupervised semantic parsing.</title>
<date>2011</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="6143" citStr="Goldwasser et al., 2011" startWordPosition="935" endWordPosition="938"> objective, which uses a vector w, mapping features to weights and a feature function 41) which maps the output decision to a feature vector. The output interpretation y is described using a subset of first order logic, consisting of typed constants (e.g., robotic soccer player), functions capturing relations between entities, and their properties (e.g., pass(x, y), where pass is a function symbol and x, y are typed arguments). We use data taken from two grounded domains, describing robotic soccer events and household situations. We begin by formulating the domain-specific process. We follow (Goldwasser et al., 2011; Clarke et al., 2010) and formalize semantic inference as an Integer Linear Program (ILP). Due to space consideration, we provide a brief description (see (Clarke et al., 2010) for more details). We then proceed to augment this model with domain-independent information, and connect the two models by constraining the ILP model. 2.1 Domain-Dependent Model Interpretation is composed of several decisions, capturing mapping of input tokens to logical fragments (first order) and their composition into larger fragments (second). We encode a first-order decision as αcs, a binary variable indicating t</context>
</contexts>
<marker>Goldwasser, Reichart, Clarke, Roth, 2011</marker>
<rawString>D. Goldwasser, R. Reichart, J. Clarke, and D. Roth. 2011. Confidence driven unsupervised semantic parsing. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kim</author>
<author>R J Mooney</author>
</authors>
<title>Generative alignment and semantic parsing for learning from ambiguous supervision.</title>
<date>2010</date>
<booktitle>In COLING.</booktitle>
<marker>Kim, Mooney, 2010</marker>
<rawString>J. Kim and R. J. Mooney. 2010. Generative alignment and semantic parsing for learning from ambiguous supervision. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kwiatkowski</author>
<author>L Zettlemoyer</author>
<author>S Goldwater</author>
</authors>
<title>Inducing probabilistic ccg grammars from logical form with higher-order unification.</title>
<date>2010</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="1025" citStr="Kwiatkowski et al., 2010" startWordPosition="143" endWordPosition="146">vel interpretation model, which augments a domain dependent model with abstract information that can be shared by multiple domains. Our experiments show that this type of information is useful and can reduce the annotation effort significantly when moving between domains. 1 Introduction Natural Language (NL) understanding can be intuitively understood as a general capacity, mapping words to entities and their relationships. However, current work on automated NL understanding (typically referenced as semantic parsing (Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Chen and Mooney, 2008; Kwiatkowski et al., 2010; B¨orschinger et al., 2011)) is restricted to a given output domain1 (or task) consisting of a closed set of meaning representation symbols, describing domains such as robotic soccer, database queries and flight ordering systems. In this work, we take a first step towards constructing a semantic interpreter that can leverage information from multiple tasks. This is not a straight forward objective – the domain specific nature of semantic interpretation, as described in the current literature, does not allow for an easy move between domains. For example, a system trained for the task of unders</context>
</contexts>
<marker>Kwiatkowski, Zettlemoyer, Goldwater, 2010</marker>
<rawString>T. Kwiatkowski, L. Zettlemoyer, S. Goldwater, , and M. Steedman. 2010. Inducing probabilistic ccg grammars from logical form with higher-order unification. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y W Wong</author>
<author>R Mooney</author>
</authors>
<title>Learning synchronous grammars for semantic parsing with lambda calculus.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="976" citStr="Wong and Mooney, 2007" startWordPosition="135" endWordPosition="138">nt and independent components, we suggest a novel interpretation model, which augments a domain dependent model with abstract information that can be shared by multiple domains. Our experiments show that this type of information is useful and can reduce the annotation effort significantly when moving between domains. 1 Introduction Natural Language (NL) understanding can be intuitively understood as a general capacity, mapping words to entities and their relationships. However, current work on automated NL understanding (typically referenced as semantic parsing (Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Chen and Mooney, 2008; Kwiatkowski et al., 2010; B¨orschinger et al., 2011)) is restricted to a given output domain1 (or task) consisting of a closed set of meaning representation symbols, describing domains such as robotic soccer, database queries and flight ordering systems. In this work, we take a first step towards constructing a semantic interpreter that can leverage information from multiple tasks. This is not a straight forward objective – the domain specific nature of semantic interpretation, as described in the current literature, does not allow for an easy move between domains. For</context>
</contexts>
<marker>Wong, Mooney, 2007</marker>
<rawString>Y.W. Wong and R. Mooney. 2007. Learning synchronous grammars for semantic parsing with lambda calculus. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Zettlemoyer</author>
<author>M Collins</author>
</authors>
<title>Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars.</title>
<date>2005</date>
<booktitle>In UAI.</booktitle>
<contexts>
<context position="953" citStr="Zettlemoyer and Collins, 2005" startWordPosition="130" endWordPosition="134"> decomposed into domain-dependent and independent components, we suggest a novel interpretation model, which augments a domain dependent model with abstract information that can be shared by multiple domains. Our experiments show that this type of information is useful and can reduce the annotation effort significantly when moving between domains. 1 Introduction Natural Language (NL) understanding can be intuitively understood as a general capacity, mapping words to entities and their relationships. However, current work on automated NL understanding (typically referenced as semantic parsing (Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Chen and Mooney, 2008; Kwiatkowski et al., 2010; B¨orschinger et al., 2011)) is restricted to a given output domain1 (or task) consisting of a closed set of meaning representation symbols, describing domains such as robotic soccer, database queries and flight ordering systems. In this work, we take a first step towards constructing a semantic interpreter that can leverage information from multiple tasks. This is not a straight forward objective – the domain specific nature of semantic interpretation, as described in the current literature, does not allow for an easy mo</context>
</contexts>
<marker>Zettlemoyer, Collins, 2005</marker>
<rawString>L. Zettlemoyer and M. Collins. 2005. Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars. In UAI.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>