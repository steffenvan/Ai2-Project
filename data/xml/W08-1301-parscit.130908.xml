<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001009">
<title confidence="0.77521">
The Stanford typed dependencies representation
Marie-Catherine de Marneffe
</title>
<author confidence="0.581596">
Linguistics Department
</author>
<affiliation confidence="0.873729">
Stanford University
</affiliation>
<address confidence="0.782674">
Stanford, CA 94305
</address>
<email confidence="0.998566">
mcdm@stanford.edu
</email>
<author confidence="0.992812">
Christopher D. Manning
</author>
<affiliation confidence="0.9818525">
Computer Science Department
Stanford University
</affiliation>
<address confidence="0.762027">
Stanford, CA 94305
</address>
<email confidence="0.99823">
manning@stanford.edu
</email>
<sectionHeader confidence="0.993867" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999819375">
This paper examines the Stanford typed
dependencies representation, which was
designed to provide a straightforward de-
scription of grammatical relations for any
user who could benefit from automatic text
understanding. For such purposes, we ar-
gue that dependency schemes must follow
a simple design and provide semantically
contentful information, as well as offer an
automatic procedure to extract the rela-
tions. We consider the underlying design
principles of the Stanford scheme from this
perspective, and compare it to the GR and
PARC representations. Finally, we address
the question of the suitability of the Stan-
ford scheme for parser evaluation.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9996626875">
The Stanford typed dependencies representation
was designed to provide a simple description of
the grammatical relationships in a sentence that
could easily be understood and effectively used by
people without linguistic expertise who wanted to
extract textual relations. The representation was
not designed for the purpose of parser evaluation.
Nevertheless, we agree with the widespread senti-
ment that dependency-based evaluation of parsers
avoids many of the problems of the traditional Par-
seval measures (Black et al., 1991), and to the ex-
tent that the Stanford dependency representation
is an effective representation for the tasks envi-
sioned, it is perhaps closer to an appropriate task-
based evaluation than some of the alternative de-
pendency representations available. In this paper
</bodyText>
<note confidence="0.723011">
© 2008. Licensed under the Creative Commons
</note>
<footnote confidence="0.96727">
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
</footnote>
<bodyText confidence="0.967740512820513">
we examine the representation and its underlying
design principles, look at how this representation
compares with other dependency representations
in ways that reflect the design principles, and con-
sider its suitability for parser evaluation.
A major problem for the natural language pro-
cessing (NLP) community is how to make the
very impressive and practical technology which
has been developed over the last two decades ap-
proachable to and usable by everyone who has text
understanding needs. That is, usable not only by
computational linguists, but also by the computer
science community more generally and by all sorts
of information professionals including biologists,
medical researchers, political scientists, law firms,
business and market analysts, etc. Thinking about
this issue, we were struck by two facts. First, we
noted how frequently WordNet (Fellbaum, 1998)
gets used compared to other resources, such as
FrameNet (Fillmore et al., 2003) or the Penn Tree-
bank (Marcus et al., 1993). We believe that much
of the explanation for this fact lies in the differ-
ence of complexity of the representation used by
the resources. It is easy for users not necessarily
versed in linguistics to see how to use and to get
value from the straightforward structure of Word-
Net. Second, we noted the widespread use of Mini-
Par (Lin, 1998) and the Link Parser (Sleator and
Temperley, 1993). This clearly shows that (i) it is
very easy for a non-linguist thinking in relation ex-
traction terms to see how to make use of a depen-
dency representation (whereas a phrase structure
representation seems much more foreign and for-
bidding), and (ii) the availability of high quality,
easy-to-use (and preferably free) tools is essential
for driving broader use of NLP tools.1
1On the other hand, evaluation seems less important; to the
best of our knowledge there has never been a convincing and
thorough evaluation of either MiniPar or the Link Grammar
</bodyText>
<page confidence="0.723124">
1
</page>
<note confidence="0.849464">
Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation, pages 1–8
Manchester, August 2008
</note>
<bodyText confidence="0.9998674">
This paper advocates for the Stanford typed de-
pendencies representation (henceforth SD) being a
promising vehicle for bringing the breakthroughs
of the last 15 years of parsing research to this broad
potential user community. The representation aims
to provide a simple, habitable design. All infor-
mation is represented as binary relations. This
maps straightforwardly on to common representa-
tions of potential users, including the logic forms
of Moldovan and Rus (Moldovan and Rus, 2001),2
semantic web Resource Description Framework
(RDF) triples (http://www.w3.org/RDF/), and graph
representations (with labeled edges and nodes).
Unlike many linguistic formalisms, excessive de-
tail is viewed as a defect: information that users do
not understand or wish to process detracts from up-
take and usability. The user-centered design pro-
cess saw the key goal as representing semantically
contentful relations suitable for relation extraction
and more general information extraction uses. The
design supports this use by favoring relations be-
tween content words, by maintaining semantically
useful closed class word information while ignor-
ing linguistic decisions less relevant to users, and
by not representing less used material about lin-
guistic features such as tense and agreement. The
SD scheme thus provides a semantic representa-
tion simple and natural enough for people who are
not (computational) linguists but can benefit from
NLP tools.
</bodyText>
<sectionHeader confidence="0.826702" genericHeader="method">
2 Design choices and their implications
</sectionHeader>
<subsectionHeader confidence="0.963856">
2.1 Design principles
</subsectionHeader>
<bodyText confidence="0.999645642857143">
The style of the SD representation bears a strong
intellectual debt to the framework of Lexical-
Functional Grammar (Bresnan, 2001), and, more
directly, it owes a debt to both the sets of gram-
matical relations and the naming defined in two
representations that follow an LFG style: the GR
(Carroll et al., 1999) and PARC (King et al., 2003)
schemes. These were used as a starting point for
developing the Stanford dependencies (de Marn-
effe et al., 2006). But where the SD scheme devi-
ates from GR, PARC, and its LFG roots is that it
has been designed to be a practical model of sen-
tence representation, particularly in the context of
relation extraction tasks.
</bodyText>
<footnote confidence="0.7619734">
parser.
2The logic forms of Moldovan and Rus are in the form
of a predicate calculus representation, although not one that
represents such things as operator scope in a way that most
would expect of a predicate calculus representation.
</footnote>
<bodyText confidence="0.999248444444444">
SD makes available two options, suited to dif-
ferent use cases: in one, every word of the origi-
nal sentence is present as a node with relations be-
tween it and other nodes, whereas in the latter, cer-
tain words are “collapsed” out of the representa-
tion, making such changes as turning prepositions
into relations. The former is useful when a close
parallelism to the source text words must be main-
tained, whereas the latter is intended to be more
useful for relation extraction and shallow language
understanding tasks. Here, we discuss only the lat-
ter representation; see (de Marneffe et al., 2006)
for a discussion of both options and the precise re-
lationship between them.
The intended use cases of usability by people
who are not (computational) linguists and suitabil-
ity for relation extraction applications led SD to try
to adhere to the following design principles (DPs):
</bodyText>
<listItem confidence="0.994117928571429">
1. Everything is represented uniformly as some
binary relation between two sentence words.
2. Relations should be semantically contentful
and useful to applications.
3. Where possible, relations should use notions
of traditional grammar for easier comprehen-
sion by users.
4. Underspecified relations should be available
to deal with the complexities of real text.
5. Where possible, relations should be between
content words, not indirectly mediated via
function words.
6. The representation should be spartan rather
than overwhelming with linguistic details.
</listItem>
<bodyText confidence="0.999686823529412">
We illustrate many of them in the rest of this sec-
tion, using example sentences which were made
available for the Parser Evaluation Shared Task.
The grammatical relations of SD are arranged in
a hierarchy, rooted with the most generic relation,
dependent. The hierarchy contains 56 grammatical
relations. When the relation between a head and
its dependent can be identified more precisely, re-
lations further down in the hierarchy are used, but
when it is unclear, more generic dependencies are
possible (DP1, DP4). For example, the dependent
relation can be specialized to aux (auxiliary), arg
(argument), or mod (modifier). The arg relation is
further divided into the subj (subject) relation and
the comp (complement) relation, and so on. The
backbone of this hierarchy is quite similar to that
in GR, but there are some crucial differences.
</bodyText>
<page confidence="0.985131">
2
</page>
<subsectionHeader confidence="0.999177">
2.2 Comparison with GR and PARC
</subsectionHeader>
<bodyText confidence="0.995270724489797">
The SD scheme is not concerned with the argu-
ment/adjunct distinction which is largely useless in
practice. In contrast, NP-internal relations are an
inherent part of corpus texts and are critical in real-
world applications. The SD scheme therefore in-
cludes many relations of this kind: appos (apposi-
tive modifier), nn (noun compound), num (numeric
modifier), number (element of compound num-
ber) and abbrev (abbreviation), etc. (DP2). For
instance, in the sentence “I feel like a little kid,”
says a gleeful Alex de Castro, a car salesman, who
has stopped by a workout of the Suns to slip six
Campaneris cards to the Great Man Himself to be
autographed (WSJ-R), we obtain the following re-
lations under the SD representation:
SD appos(Castro, salesman)
num(cards, six)
nn(cards, Campaneris)
The numeric modifier relation between cards and
six is also standard in the PARC and GR schemes.
PARC provides an apposition relation between
salesman and Alex de Castro, whereas GR only
identifies salesman as a text adjunct of Castro.
But on the whole, SD makes more fine-grained
distinctions in the relations, which are needed in
practice. The adjunct dependency of the PARC
scheme lumps together different relations. For ex-
ample, the adjectival modifier gleeful in the sen-
tence above will not be marked distinctively from
the preposition modifying workout, nor from the
relation between the verbs stop and slip:
PARC adjunct(Alex de Castro, gleeful)
adjunct(kid, little)
adjunct(stop, slip)
adjunct(workout, of)
The SD output for the relations between these
words looks as follows:
SD amod(Castro, gleeful)
amod(kid, little)
xcomp(stop, slip)
prep of(workout, Suns)
The comparison between the two outputs shows
that SD proposes a larger set of dependencies, cap-
turing relation differences which can play a role
in applications (DP2), while sticking to notions of
traditional grammar (DP3).
The SD scheme also chooses content words as
heads of the dependencies (DP5). Auxiliaries,
complementizers, and so on, are dependents of
them. This choice in design is driven by the kind of
information that is useful for applications. For in-
stance, in the sentence Considered as a whole, Mr.
Lane said, the filings required under the proposed
rules “will be at least as effective, if not more so,
for investors following transactions” (WSJ-R), ef-
fective is chosen as the head of the quoted phrase.
This enables the representation to have a direct de-
pendency (nsubj for nominal subject) between the
key content words effective and filings. Such a
link is more difficult to infer from the GR scheme,
where be is chosen as the head. However the re-
lation between effective and filings is key to ex-
tracting the gist of the sentence semantics, and it
is therefore important for applications to be able
to retrieve it easily. Also, in the case of struc-
tures involving copular verbs, a direct link between
the subject and the complement enables equiva-
lent representations across languages (in Chinese,
for example, copulas are not explicitly expressed).
Such parallel representations should presumably
help machine translation, and this was a further
motivation for choosing content words as heads.
Another instance where direct links between
content words is useful is the case of prepositional
complements. The SD scheme offers the option
of “collapsing” dependencies involving a preposi-
tion (DP5). In the example above, instead of hav-
ing two relations adjunct(workout, of) and obj(of,
Suns) as in PARC or ncmod(workout, of) and
dobj(of, Suns) as in GR, SD provides a direct rela-
tion between the content words: prep of(workout,
Suns). Prepositions often work as role markers,
and this type of link facilitates the extraction of
how the two content words are related; and thus
these links are often used by downstream applica-
tions (Lin and Pantel, 2001; Snow et al., 2005).
The usefulness of the representation is exemplified
in the sentence A similar technique is almost im-
possible to apply to other crops, such as cotton,
soybeans and rice (WSJ-R) for which SD gives di-
rect links between the entities joined through the
preposition such as:
SD prep such as(crops, cotton)
prep such as(crops, soybeans)
prep such as(crops, rice)
A similar collapsing treatment takes place for
conjuncts (DP5). Consider the following sentence:
Bell, based in Los Angeles, makes and distributes
</bodyText>
<page confidence="0.841006">
3
</page>
<equation confidence="0.976606916666667">
SD nsubj(makes-8, Bell-1)
nsubj(distributes-10, Bell-1)
partmod(Bell-1, based-3)
nn(Angeles-6, Los-5)
prep in(based-3, Angeles-6)
conj and(makes-8, distributes-10)
amod(products-16, electronic-11)
conj and(electronic-11, computer-13)
amod(products-16, computer-13)
conj and(electronic-11, building-15)
amod(products-16, building-15)
dobj(makes-8, products-16)
</equation>
<figureCaption confidence="0.875427">
Figure 1: SD representation for Bell, based in Los
Angeles, makes and distributes electronic, com-
puter and building products.
</figureCaption>
<bodyText confidence="0.9996685">
electronic, computer and building products (WSJ-
R). Figures 1 and 2 give the full dependency out-
put from SD and GR, respectively. The numbers
after the words in the SD representation indicate
the word position in the sentence.3 From the SD
representation, one can easily see that the sentence
talks about electronic products and computer prod-
ucts as well as building products. By collapsing the
dependencies involving conjuncts, the output pro-
duced is closer to the semantics of the sentence,
and this facilitates information extraction (DP2).
This information is not straightforwardly apparent
in the GR scheme (see figure 2), nor in the PARC
scheme which follows a similar treatment of con-
juncts.
Another choice in the design has been to con-
sistently have binary relations (DP1). All the de-
pendencies form a triple: a grammatical relation
holding between two words (head and dependent).
This gives uniformity to the representation and
renders it very readable, critical features for a user-
centered design. Furthermore, all the information
can be represented by a directed graph, enabling
the creation of both a limpid visual representation
for humans and a canonical data structure for soft-
ware. Moreover, it maps straightforwardly on to
semantic web representations such as OWL and
RDF triples, as exploited in (Zouaq et al., 2006;
Zouaq et al., 2007).
This design choice limits the kind of informa-
tion offered by the SD scheme. For instance, the
PARC scheme contains much more information
</bodyText>
<footnote confidence="0.7323745">
3Without word position, the representation is deficient if
the same word occurs more than once in a sentence.
</footnote>
<bodyText confidence="0.912771857142857">
GR (passive based)
(ncsubj based Bell obj)
(ta bal Bell based)
(iobj based in)
(dobj in Angeles)
(ncmod Angeles Los)
(conj and makes)
(conj and distributes)
(conj and electronic)
(conj and computer)
(conj and building)
(ncsubj and Bell )
(dobj and products)
(ncmod products and)
</bodyText>
<figureCaption confidence="0.947367333333333">
Figure 2: GR representation for Bell, based in Los
Angeles, makes and distributes electronic, com-
puter and building products.
</figureCaption>
<bodyText confidence="0.997534666666667">
about individual words, such as verb tense and
aspect, noun number and person, type of NE for
proper nouns, pronoun form, adjective degree, etc.
For the sentence in figures 1 and 2, the following
information is available for the word Los Angeles
in the PARC scheme:
</bodyText>
<construct confidence="0.573179666666667">
PARC num(Los Angeles-5, sg)
pers(Los Angeles-5, 3)
proper(Los Angeles-5, location)
</construct>
<bodyText confidence="0.999809333333333">
This kind of information is indubitably valuable,
but is often less used in practice, and does not per
se pertain to dependency data. Adding it lengthens
an output already complex enough, and impedes
readability and convenience. Thus, SD does not
provide such overwhelming detail (DP6).
</bodyText>
<subsectionHeader confidence="0.996956">
2.3 Trading off linguistic fidelity and usability
</subsectionHeader>
<bodyText confidence="0.999943333333334">
We feel that turning prepositions into relations is
useful for 98% of users 98% of the time. Neverthe-
less opting for usability in this way causes the SD
scheme to sacrifice some linguistic fidelity. One
instance is that modifiers of prepositions are de-
pendent on the verb (or more precisely, on the head
of the clause in which they appear) and not on the
preposition itself. In Bill went over the river and
right through the woods, right will be an adverbial
modifier of went. In He had laughed, simultane-
ously mocking the stupidity of government by cos-
metics and confessing that he was also a part of it,
just as he was part of government by voice coach
and acting coach (BNC), just which modifies as
will be a dependent of the head of the adverbial
</bodyText>
<page confidence="0.98794">
4
</page>
<bodyText confidence="0.981436185185185">
clause, i.e., part. This induces some distortion in
the exact semantics of the sentence.
The interaction between preposition collapsing
and PP conjunction is another instance in which
the SD treatment slightly alters the semantics of
the sentence. Consider again the sentence Bill
went over the river and right through the woods.
Both prepositions, over and through, are governed
by the verb went. To avoid disjoint subgraphs
when collapsing the relations, examples like this
are transformed into VP coordination, which re-
quires making a copy of the word went. This gives
the following representation, which corresponds to
a sentence like Bill went over the river and went
right through the woods:
SD prep over(went-2, river-5)
prep through(went-2’, woods-10)
conj and(went-2, went-2’)
Not collapsing the relations in such a case would
prevent the alteration of the semantics, but would
lead to a non-uniform treatment of prepositions.
Uniformity is key for readability and user con-
venience. It seems therefore reasonable to use a
representation which sacrifices the exact semantics
of the original sentence by producing a sentence
roughly equivalent, but which ensures uniformity
across relations.
</bodyText>
<sectionHeader confidence="0.842445" genericHeader="method">
3 The formalism and the tool
</sectionHeader>
<bodyText confidence="0.9999481">
Two vital conditions for the success of a depen-
dency scheme are to provide a suitable represen-
tation for users as well as a tool that is easy to
use. Sagae et al. (2008) note that the availability of
an automatic procedure to convert phrase structure
parses to SD is the reason for its use in evaluations
of parsers in the biomedical domain. The primary
focus of the SD scheme, however, has been to offer
grammatical relations appropriate for end-users.
The Stanford parser4 comes with a tool, de-
scribed in (de Marneffe et al., 2006), which pro-
vides for the rapid extraction of the grammati-
cal relations from phrase structure parses. Struc-
tural configurations are used to define grammatical
roles: the semantic head of each constituent of the
parse is identified, using rules akin to the Collins
head rules, but modified to retrieve the semantic
head of the constituent rather than the syntactic
head. As mentioned, content words are chosen as
heads, and all the other words in the constituent
</bodyText>
<footnote confidence="0.712536">
4http://nlp.stanford.edu/software/lex-parser.shtml
</footnote>
<bodyText confidence="0.996707146341464">
depend on this head. To retrieve adequate heads
from a semantic point of view, heuristics are used
to inject more structure when the Penn Treebank
gives only flat constituents, as is often the case for
conjuncts, e.g., (NP the new phone book and tour
guide), and QP constituents, e.g., (QP more than
300). Then for each grammatical relation, patterns
are defined over the phrase structure parse tree us-
ing the tree-expression syntax defined by tregex
(Levy and Andrew, 2006). Conceptually, each pat-
tern is matched against every tree node, and the
matching pattern with the most specific grammati-
cal relation is taken as the type of the dependency.
The automatic extraction of the relations is not
infallible. For instance, in the sentence Behind
their perimeter walls lie freshly laundered flowers,
verdant grass still sparkling from the last shower,
yew hedges in an ecstasy of precision clipping
(BNC), the system will erroneously retrieve ap-
position relations between flowers and grass, as
well as between flowers and hedges whereas these
should be conj and relations. The system is clue-
less when there is no overt maker of conjunction.
Another limitation of the tool is the treat-
ment of long-distance dependencies, such as wh-
movement and control/raising: the system can-
not handle long-distance dependencies that cross
clauses. In a sentence like What does he think?,
the system will correctly find that what is a direct
object of think:
SD dobj(think-4, What-1)
aux(think-4, does-2)
nsubj(think-4, he-3)
However in a sentence such as Who the hell does
he think he’s kidding? (BNC), the automatic ex-
traction will fail to find that who is the direct ob-
ject of kidding. Here, it is vital to distinguish be-
tween SD as a representation versus the extant con-
version tool. Long-distance dependencies are not
absent from the formalism, but the tool does not
accurately deal with them.5
</bodyText>
<sectionHeader confidence="0.820484" genericHeader="method">
4 Stanford dependencies in practice
</sectionHeader>
<bodyText confidence="0.873597125">
SD has been successfully used by researchers in
different domains. In the PASCAL Recognizing
5As possible future work, we have thought of using a tool
such as the one of Levy and Manning (2004) to correctly de-
termine long distance dependencies, as input to the current
dependency conversion system. This would presumably be
effective, but would make the conversion process much heav-
ier weight.
</bodyText>
<page confidence="0.986602">
5
</page>
<bodyText confidence="0.999962714285714">
Textual Entailment (RTE) challenges (Dagan et al.,
2006; Giampiccolo et al., 2007), the increase in
the use of SD is clearly apparent. The goal in
these challenges consists of identifying whether
one sentence follows from a piece of text and gen-
eral background knowledge, according to the intu-
itions of an intelligent human reader. In 2007, out
of the 21 systems which participated in the chal-
lenge, 5 used the SD representation, whereas the
year before only the Stanford entry was using it.
SD is also widely present in the bioinformatic
world where it is used with success (Erkan et al.,
2007; Greenwood and Stevenson, 2007; Urbain et
al., 2007; Clegg, 2008). Fundel et al. (2007) found
that, in extraction of relations between genes and
proteins, a system based on the SD scheme greatly
outperformed the previous best system on the LLL
challenge dataset (by an 18% absolute improve-
ment in F-measure). Airola et al. (2008) provide
more systematic results on a number of protein-
protein interaction datasets. Their graph kernel ap-
proach uses an all-dependency-paths kernel which
allows their system to consider full dependency
graphs. Their system is based on the SD scheme,
and they demonstrate state-of-the-art performance
for this approach.
In the biomedical domain, SD has recently been
used in evaluations of parsers (Clegg and Shep-
herd, 2007; Pyysalo et al., 2007a). Pyysalo et al.
(2007a) assessed the suitability of the SD scheme
over the Link Grammar dependency scheme in an
application-oriented evaluation. The Link Parser
indeed uses a very fine-grained set of relations,
which often makes distinctions of a structural
rather than a semantic nature. One example is the
MX relation which “connects modifying phrases
with commas to preceding nouns (‘The DOG, a
POODLE, was black’; ‘JOHN, IN a black suit,
looked great’).” The Link Parser uses a different
set of dependency types for dependencies appear-
ing in questions and relative clauses. Another ex-
ample is the prepositional phrase where alterna-
tive attachment structures are indicated by differ-
ent relations. Many of these distinctions are too
fine and non-semantic to be of practical value. The
SD scheme, by aiming for an intermediate level of
granularity, and targeting semantic dependencies,
provides a more adequate representation for appli-
cations. Therefore, to increase the usability of the
BioInfer corpus (Pyysalo et al., 2007b), which pro-
vides manually annotated data for information ex-
traction in the biomedical domain and originally
followed the Link Grammar scheme, Pyysalo et
al. (2007a) developed a version of the corpus an-
notated with the SD scheme. They also made
available a program and conversion rules that they
used to transform Link Grammar relations into SD
graphs, which were then hand-corrected (Pyysalo
et al., 2007b). While a limited amount of gold stan-
dard annotated data was prepared for the Parser
Evaluation Shared Task, this is the main source of
gold-standard SD data which is currently available.
In other domains, Zhuang et al. (2006) uses the
representation to extract opinions about features in
reviews and Meena and Prabhakar (2007) uses it
to improve the quality of sentence-level sentiment
analysis. The open information extraction system
TEXTRUNNER (Banko et al., 2007) also makes use
of the SD graph representation: its first module
uses the Stanford parser and the dependency tool
to automatically identify and label trustworthy and
untrustworthy extractions. Even in theoretical lin-
guistic work, SD has proven very useful: it has
hugely facilitated data extraction from corpora, in
the context of the NSF-funded project “Dynamics
of probabilistic grammar” carried out at the Stan-
ford Linguistics department.
</bodyText>
<sectionHeader confidence="0.990896" genericHeader="method">
5 Suitability for parser evaluation
</sectionHeader>
<bodyText confidence="0.999731173913043">
When seeking a gold-standard dependency scheme
for parser evaluation, the ultimate goal of such an
evaluation is an important question. It is necessary
to contrast the two different forms that evaluation
can take: extrinsic task-based evaluation and in-
trinsic evaluation. We tend to agree with Moll´a
and Hutchinson (2003) that intrinsic evaluations
have limited value and that task-based evaluation
is the correct approach. Some of the results of the
previous section at least broadly support the util-
ity of the SD scheme for practical use in higher-
level tasks. Nevertheless, given the current trend
in the NLP community as well as in other fields
such as bioinformatics, where the advantage of de-
pendency representations for shallow text under-
standing tasks has become salient, we would ar-
gue, following Clegg and Shepherd (2007), that
dependency-based evaluation is close to typical
user tasks. Moreover, it avoids some of the known
deficiencies of other parser evaluation measures
such as Parseval (Carroll et al., 1999).
Recent work on parser evaluation using depen-
dency graphs in the biomedical domain confirms
</bodyText>
<page confidence="0.998557">
6
</page>
<bodyText confidence="0.999961977777778">
that researchers regard dependency-based evalu-
ation as a more useful surrogate for extrinsic
task-based evaluation (Clegg and Shepherd, 2007;
Pyysalo et al., 2007a). In their evaluation, Clegg
and Shepherd (2007) aimed at analyzing the ca-
pabilities of syntactic parsers with respect to se-
mantically important tasks crucial to biological
information extraction systems. To do so, they
used the SD scheme, which provides “a de facto
standard for comparing a variety of constituent
parsers and treebanks at the dependency level,” and
they assessed its suitability for evaluation. They
found that the SD scheme better illuminates the
performance differences between higher ranked
parsers (e.g., Charniak-Lease parser (Lease and
Charniak, 2005)), and lower ranked parsers (e.g.,
the Stanford parser (Klein and Manning, 2003)).
Their parser evaluation accommodates user needs:
they used the collapsed version of the dependency
graphs offered by the SD scheme, arguing that this
is the kind of graph one would find most useful in
an information extraction project. Although Clegg
and Shepherd (2007) also favor dependency graph
representations for parser evaluation, they advo-
cate retention of parse trees so information lost in
the dependency structures can be accessed.
In essence, any existing dependency scheme
could be adopted as the gold-standard for evalu-
ation. However if one believes in ultimately valu-
ing extrinsic task-based evaluation, a dependency
representation which proposes a suitable design for
users and user tasks is probably the best surrogate
for intrinsic evaluation. Moreover, the existence
of tools for automatically generating and convert-
ing dependency representations has aided greatly
in making parser comparison possible across dif-
ferent formalisms. We believe that the SD scheme
approaches these goals. If one accepts the goals
set here, in order to enforce uniformity between
application and evaluation, it seems sensible to
have a unique scheme for both purposes. Some
of the positive results from use of the SD represen-
tation, as well as the evaluations carried out in the
biomedical field, point to the usability of the SD
scheme for both purposes.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9985436">
We wish to thank Andrew Brian Clegg and Sampo
Pyysalo for their useful feedback on the depen-
dency extraction tool. Their comments enabled us
to improve the tool. We also thank the workshop
reviewers for their helpful comments.
</bodyText>
<sectionHeader confidence="0.992427" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999084843137255">
Airola, Antti, Sampo Pyysalo, Jari Bj¨orne, Tapio
Pahikkala, Filip Ginter, and Tapio Salakoski. 2008.
A graph kernel for protein-protein interaction ex-
traction. In Proceedings of BioNLP 2008: Current
Trends in Biomedical Natural Language Processing
(ACL08).
Banko, Michele, Michael J. Cafarella, Stephen Soder-
land, Matt Broadhead, and Oren Etzioni. 2007.
Open information extraction from the web. In Pro-
ceedings of the 20th International Joint Conference
on Artificial Intelligence (IJCAI 2007).
Black, E., S. Abney, D. Flickinger, C. Gdaniec, R. Gr-
ishman, P. Harrison, D. Hindle, R. Ingria, F. Jelinek,
J. Klavans, M. Liberman, M. Marcus, S. Roukos,
B. Santorini, and T. Strzalkowski. 1991. A proce-
dure for quantitatively comparing the syntactic cov-
erage of English grammars. In Proceedings, Speech
and Natural Language Workshop, pages 306–311,
Pacific Grove, CA. DARPA.
Bresnan, Joan. 2001. Lexical-Functional Syntax.
Blackwell, Oxford.
Carroll, John, Guido Minnen, and Ted Briscoe. 1999.
Corpus annotation for parser evaluation. In Proceed-
ings of the EACL workshop on Linguistically Inter-
preted Corpora (LINC).
Clegg, Andrew B. and Adrian J. Shepherd. 2007.
Benchmarking natural-language parsers for biolog-
ical applications using dependency graphs. BMC
Bioinformatics, 8:24.
Clegg, Andrew B. 2008. Computational-Linguistic
Approaches to Biological Text Mining. Ph.D. the-
sis, School of Crystallography, Birkbeck, University
of London.
Dagan, Ido, Oren Glickman, and Bernardo Magnini.
2006. The PASCAL recognising textual entailment
challenge. In et al., Quinonero-Candela, editor,
MLCW 2005, LNAI Volume 3944, pages 177–190.
Springer-Verlag.
de Marneffe, Marie-Catherine, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
Proceedings of LREC-06.
Erkan, Gunes, Arzucan Ozgur, and Dragomir R. Radev.
2007. Semi-supervised classification for extracting
protein interaction sentences using dependency pars-
ing. In Proceedings of the 2007 Joint Conference
on Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL).
Fellbaum, Christiane. 1998. WordNet: an electronic
lexical database. MIT Press.
</reference>
<page confidence="0.995968">
7
</page>
<reference confidence="0.99948423364486">
Fillmore, Charles J., Christopher R. Johnson, and Mir-
iam R.L. Petruck. 2003. Background to FrameNet.
International Journal of Lexicography, 16:235–250.
Fundel, Katrin, Robert K¨uffner, and Ralf Zimmer.
2007. RelEx relation extraction using dependency
parse trees. Bioinformatics, 23.
Giampiccolo, Danilo, Bernardo Magnini, Ido Dagan,
and Bill Dolan. 2007. The third PASCAL recogniz-
ing textual entailment challenge. In Proceedings of
the ACL-PASCAL Workshop on Textual Entailment
and Paraphrasing, pages 1–9.
Greenwood, Mark A. and Mark Stevenson. 2007.
A semi-supervised approach to learning relevant
protein-protein interaction articles. In Proceedings
of the Second BioCreAtIvE Challenge Workshop,
Madrid, Spain.
King, Tracy H., Richard Crouch, Stefan Riezler, Mary
Dalrymple, and Ronald Kaplan. 2003. The PARC
700 dependency bank. In 4th International Work-
shop on Linguistically Interpreted Corpora (LINC-
03).
Klein, Dan and Christopher D. Manning. 2003. Ac-
curate unlexicalized parsing. In Proceedings of the
41st Meeting of the Association for Computational
Linguistics.
Lease, Matthew and Eugene Charniak. 2005. Parsing
biomedical literature. In Proceedings of the Second
International Joint Conference on Natural Language
Processing (IJCNLP’05).
Levy, Roger and Galen Andrew. 2006. Tregex
and Tsurgeon: tools for querying and manipulating
tree data structures. In LREC 2006. http://www-
nlp.stanford.edu/software/tregex.shtml.
Levy, Roger and Christopher D. Manning. 2004. Deep
dependencies from context-free statistical parsers:
correcting the surface dependency approximation.
In ACL 42, pages 328–335.
Lin, Dekang and Patrick Pantel. 2001. Discovery of in-
ference rules for question answering. Natural Lan-
guage Engineering, 7(4):343–360.
Lin, Dekang. 1998. Dependency-based evaluation of
MINIPAR. In Workshop on the Evaluation of Pars-
ing Systems, Granada, Spain.
Marcus, Mitchell P., Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated
corpus of english: The Penn Treebank. Computa-
tional Linguistics, 19 (2).
Meena, Arun and T. V. Prabhakar. 2007. Sentence level
sentiment analysis in the presence of conjuncts using
linguistic analysis. In Advances in Information Re-
trieval, volume 4425 of Lecture Notes in Computer
Science. Springer.
Moldovan, Dan I. and Vasile Rus. 2001. Logic form
transformation of wordnet and its applicability to
question answering. In Meeting of the Association
for Computational Linguistics, pages 394–401.
Moll´a, Diego and Ben Hutchinson. 2003. Intrinsic ver-
sus extrinsic evaluations of parsing systems. In Pro-
ceedings of the Workshop on Evaluation Initiatives
in Natural Language Processing, pages 43–50. Eu-
ropean Association for Computational Linguistics.
Pyysalo, Sampo, Filip Ginter, Katri Haverinen, Juho
Heimonen, Tapio Salakoski, and Veronika Laippala.
2007a. On the unification of syntactic annotations
under the Stanford dependency scheme: A case
study on BioInfer and GENIA. In Proceedings of
BioNLP 2007: Biological, translational, and clini-
cal language processing (ACL07).
Pyysalo, Sampo, Filip Ginter, Juho Heimonen, Jari
Bj¨orne, Jorma Boberg, Jouni J¨arvinen, and Tapio
Salakoski. 2007b. BioInfer: A corpus for infor-
mation extraction in the biomedical domain. BMC
Bioinformatics, 8:50.
Sagae, Kenji, Yusuke Miyao, and Jun’ichi Tsujii. 2008.
Challenges in mapping of syntactic representations
for framework-independent parser evaluation. In
Proceedings of the Workshop on Automated Syntatic
Annotations for Interoperable Language Resources
at the First International Conference on Global In-
teroperability for Language Resources (ICGL’08).
Sleator, Daniel D. and Davy Temperley. 1993. Parsing
English with a link grammar. In Third International
Workshop on Parsing Technologies.
Snow, Rion, Daniel Jurafsky, and Andrew Y. Ng. 2005.
Learning syntactic patterns for automatic hypernym
discovery. In Proceedings of NIPS 2004.
Urbain, Jay, Nazli Goharian, and Ophir Frieder. 2007.
IIT TREC 2007 genomics track: Using concept-
based semantics in context for genomics literature
passage retrieval. In The Sixteenth Text REtrieval
Conference (TREC 2007) Proceedings.
Zhuang, Li, Feng Jing, Xiao yan Zhu, and Lei Zhang.
2006. Movie review mining and summarization. In
Proc. ACM Conference on Information and Knowl-
edge Management (CIKM).
Zouaq, Amal, Roger Nkambou, and Claude Frasson.
2006. The knowledge puzzle: An integrated ap-
proach of intelligent tutoring systems and knowledge
management. In Proceedings of the 18th IEEE Inter-
national Conference on Tools with Artificial Intelli-
gence (ICTAI2006), pages 575–582.
Zouaq, Amal, Roger Nkambou, and Claude Frasson.
2007. Building domain ontologies from text for edu-
cational purposes. In Proceedings of the Second Eu-
ropean Conference on Technology Enhanced Learn-
ing: Creating new learning experiences on a global
scale.
</reference>
<page confidence="0.998446">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.120527">
<title confidence="0.6449">The Stanford typed dependencies representation Marie-Catherine de Linguistics</title>
<author confidence="0.244956">Stanford Stanford</author>
<author confidence="0.244956">CA</author>
<email confidence="0.996324">mcdm@stanford.edu</email>
<author confidence="0.999815">Christopher D Manning</author>
<affiliation confidence="0.9998665">Computer Science Department Stanford University</affiliation>
<address confidence="0.999261">Stanford, CA 94305</address>
<email confidence="0.999624">manning@stanford.edu</email>
<abstract confidence="0.992532352941176">This paper examines the Stanford typed dependencies representation, which was designed to provide a straightforward description of grammatical relations for any user who could benefit from automatic text understanding. For such purposes, we argue that dependency schemes must follow a simple design and provide semantically contentful information, as well as offer an automatic procedure to extract the relations. We consider the underlying design principles of the Stanford scheme from this perspective, and compare it to the GR and PARC representations. Finally, we address the question of the suitability of the Stanford scheme for parser evaluation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Antti Airola</author>
<author>Sampo Pyysalo</author>
<author>Jari Bj¨orne</author>
<author>Tapio Pahikkala</author>
<author>Filip Ginter</author>
<author>Tapio Salakoski</author>
</authors>
<title>A graph kernel for protein-protein interaction extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of BioNLP 2008: Current Trends in Biomedical Natural Language Processing (ACL08).</booktitle>
<marker>Airola, Pyysalo, Bj¨orne, Pahikkala, Ginter, Salakoski, 2008</marker>
<rawString>Airola, Antti, Sampo Pyysalo, Jari Bj¨orne, Tapio Pahikkala, Filip Ginter, and Tapio Salakoski. 2008. A graph kernel for protein-protein interaction extraction. In Proceedings of BioNLP 2008: Current Trends in Biomedical Natural Language Processing (ACL08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Michael J Cafarella</author>
<author>Stephen Soderland</author>
<author>Matt Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<title>Open information extraction from the web.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI</booktitle>
<contexts>
<context position="24837" citStr="Banko et al., 2007" startWordPosition="3912" endWordPosition="3915">a program and conversion rules that they used to transform Link Grammar relations into SD graphs, which were then hand-corrected (Pyysalo et al., 2007b). While a limited amount of gold standard annotated data was prepared for the Parser Evaluation Shared Task, this is the main source of gold-standard SD data which is currently available. In other domains, Zhuang et al. (2006) uses the representation to extract opinions about features in reviews and Meena and Prabhakar (2007) uses it to improve the quality of sentence-level sentiment analysis. The open information extraction system TEXTRUNNER (Banko et al., 2007) also makes use of the SD graph representation: its first module uses the Stanford parser and the dependency tool to automatically identify and label trustworthy and untrustworthy extractions. Even in theoretical linguistic work, SD has proven very useful: it has hugely facilitated data extraction from corpora, in the context of the NSF-funded project “Dynamics of probabilistic grammar” carried out at the Stanford Linguistics department. 5 Suitability for parser evaluation When seeking a gold-standard dependency scheme for parser evaluation, the ultimate goal of such an evaluation is an import</context>
</contexts>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Banko, Michele, Michael J. Cafarella, Stephen Soderland, Matt Broadhead, and Oren Etzioni. 2007. Open information extraction from the web. In Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI 2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Black</author>
<author>S Abney</author>
<author>D Flickinger</author>
<author>C Gdaniec</author>
<author>R Grishman</author>
<author>P Harrison</author>
<author>D Hindle</author>
<author>R Ingria</author>
<author>F Jelinek</author>
<author>J Klavans</author>
<author>M Liberman</author>
<author>M Marcus</author>
<author>S Roukos</author>
<author>B Santorini</author>
<author>T Strzalkowski</author>
</authors>
<title>A procedure for quantitatively comparing the syntactic coverage of English grammars.</title>
<date>1991</date>
<booktitle>In Proceedings, Speech and Natural Language Workshop,</booktitle>
<pages>306--311</pages>
<publisher>DARPA.</publisher>
<location>Pacific Grove, CA.</location>
<contexts>
<context position="1472" citStr="Black et al., 1991" startWordPosition="203" endWordPosition="206">e question of the suitability of the Stanford scheme for parser evaluation. 1 Introduction The Stanford typed dependencies representation was designed to provide a simple description of the grammatical relationships in a sentence that could easily be understood and effectively used by people without linguistic expertise who wanted to extract textual relations. The representation was not designed for the purpose of parser evaluation. Nevertheless, we agree with the widespread sentiment that dependency-based evaluation of parsers avoids many of the problems of the traditional Parseval measures (Black et al., 1991), and to the extent that the Stanford dependency representation is an effective representation for the tasks envisioned, it is perhaps closer to an appropriate taskbased evaluation than some of the alternative dependency representations available. In this paper © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. we examine the representation and its underlying design principles, look at how this representation compares with other dependency representations in ways that </context>
</contexts>
<marker>Black, Abney, Flickinger, Gdaniec, Grishman, Harrison, Hindle, Ingria, Jelinek, Klavans, Liberman, Marcus, Roukos, Santorini, Strzalkowski, 1991</marker>
<rawString>Black, E., S. Abney, D. Flickinger, C. Gdaniec, R. Grishman, P. Harrison, D. Hindle, R. Ingria, F. Jelinek, J. Klavans, M. Liberman, M. Marcus, S. Roukos, B. Santorini, and T. Strzalkowski. 1991. A procedure for quantitatively comparing the syntactic coverage of English grammars. In Proceedings, Speech and Natural Language Workshop, pages 306–311, Pacific Grove, CA. DARPA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan Bresnan</author>
</authors>
<title>Lexical-Functional Syntax.</title>
<date>2001</date>
<publisher>Blackwell,</publisher>
<location>Oxford.</location>
<contexts>
<context position="5614" citStr="Bresnan, 2001" startWordPosition="837" endWordPosition="838">oring relations between content words, by maintaining semantically useful closed class word information while ignoring linguistic decisions less relevant to users, and by not representing less used material about linguistic features such as tense and agreement. The SD scheme thus provides a semantic representation simple and natural enough for people who are not (computational) linguists but can benefit from NLP tools. 2 Design choices and their implications 2.1 Design principles The style of the SD representation bears a strong intellectual debt to the framework of LexicalFunctional Grammar (Bresnan, 2001), and, more directly, it owes a debt to both the sets of grammatical relations and the naming defined in two representations that follow an LFG style: the GR (Carroll et al., 1999) and PARC (King et al., 2003) schemes. These were used as a starting point for developing the Stanford dependencies (de Marneffe et al., 2006). But where the SD scheme deviates from GR, PARC, and its LFG roots is that it has been designed to be a practical model of sentence representation, particularly in the context of relation extraction tasks. parser. 2The logic forms of Moldovan and Rus are in the form of a predi</context>
</contexts>
<marker>Bresnan, 2001</marker>
<rawString>Bresnan, Joan. 2001. Lexical-Functional Syntax. Blackwell, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Guido Minnen</author>
<author>Ted Briscoe</author>
</authors>
<title>Corpus annotation for parser evaluation.</title>
<date>1999</date>
<booktitle>In Proceedings of the EACL workshop on Linguistically Interpreted Corpora (LINC).</booktitle>
<contexts>
<context position="5794" citStr="Carroll et al., 1999" startWordPosition="868" endWordPosition="871">t representing less used material about linguistic features such as tense and agreement. The SD scheme thus provides a semantic representation simple and natural enough for people who are not (computational) linguists but can benefit from NLP tools. 2 Design choices and their implications 2.1 Design principles The style of the SD representation bears a strong intellectual debt to the framework of LexicalFunctional Grammar (Bresnan, 2001), and, more directly, it owes a debt to both the sets of grammatical relations and the naming defined in two representations that follow an LFG style: the GR (Carroll et al., 1999) and PARC (King et al., 2003) schemes. These were used as a starting point for developing the Stanford dependencies (de Marneffe et al., 2006). But where the SD scheme deviates from GR, PARC, and its LFG roots is that it has been designed to be a practical model of sentence representation, particularly in the context of relation extraction tasks. parser. 2The logic forms of Moldovan and Rus are in the form of a predicate calculus representation, although not one that represents such things as operator scope in a way that most would expect of a predicate calculus representation. SD makes availa</context>
<context position="26339" citStr="Carroll et al., 1999" startWordPosition="4144" endWordPosition="4147">the correct approach. Some of the results of the previous section at least broadly support the utility of the SD scheme for practical use in higherlevel tasks. Nevertheless, given the current trend in the NLP community as well as in other fields such as bioinformatics, where the advantage of dependency representations for shallow text understanding tasks has become salient, we would argue, following Clegg and Shepherd (2007), that dependency-based evaluation is close to typical user tasks. Moreover, it avoids some of the known deficiencies of other parser evaluation measures such as Parseval (Carroll et al., 1999). Recent work on parser evaluation using dependency graphs in the biomedical domain confirms 6 that researchers regard dependency-based evaluation as a more useful surrogate for extrinsic task-based evaluation (Clegg and Shepherd, 2007; Pyysalo et al., 2007a). In their evaluation, Clegg and Shepherd (2007) aimed at analyzing the capabilities of syntactic parsers with respect to semantically important tasks crucial to biological information extraction systems. To do so, they used the SD scheme, which provides “a de facto standard for comparing a variety of constituent parsers and treebanks at t</context>
</contexts>
<marker>Carroll, Minnen, Briscoe, 1999</marker>
<rawString>Carroll, John, Guido Minnen, and Ted Briscoe. 1999. Corpus annotation for parser evaluation. In Proceedings of the EACL workshop on Linguistically Interpreted Corpora (LINC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew B Clegg</author>
<author>Adrian J Shepherd</author>
</authors>
<title>Benchmarking natural-language parsers for biological applications using dependency graphs.</title>
<date>2007</date>
<journal>BMC Bioinformatics,</journal>
<volume>8</volume>
<contexts>
<context position="22911" citStr="Clegg and Shepherd, 2007" startWordPosition="3610" endWordPosition="3614">etween genes and proteins, a system based on the SD scheme greatly outperformed the previous best system on the LLL challenge dataset (by an 18% absolute improvement in F-measure). Airola et al. (2008) provide more systematic results on a number of proteinprotein interaction datasets. Their graph kernel approach uses an all-dependency-paths kernel which allows their system to consider full dependency graphs. Their system is based on the SD scheme, and they demonstrate state-of-the-art performance for this approach. In the biomedical domain, SD has recently been used in evaluations of parsers (Clegg and Shepherd, 2007; Pyysalo et al., 2007a). Pyysalo et al. (2007a) assessed the suitability of the SD scheme over the Link Grammar dependency scheme in an application-oriented evaluation. The Link Parser indeed uses a very fine-grained set of relations, which often makes distinctions of a structural rather than a semantic nature. One example is the MX relation which “connects modifying phrases with commas to preceding nouns (‘The DOG, a POODLE, was black’; ‘JOHN, IN a black suit, looked great’).” The Link Parser uses a different set of dependency types for dependencies appearing in questions and relative clause</context>
<context position="26146" citStr="Clegg and Shepherd (2007)" startWordPosition="4115" endWordPosition="4118">n take: extrinsic task-based evaluation and intrinsic evaluation. We tend to agree with Moll´a and Hutchinson (2003) that intrinsic evaluations have limited value and that task-based evaluation is the correct approach. Some of the results of the previous section at least broadly support the utility of the SD scheme for practical use in higherlevel tasks. Nevertheless, given the current trend in the NLP community as well as in other fields such as bioinformatics, where the advantage of dependency representations for shallow text understanding tasks has become salient, we would argue, following Clegg and Shepherd (2007), that dependency-based evaluation is close to typical user tasks. Moreover, it avoids some of the known deficiencies of other parser evaluation measures such as Parseval (Carroll et al., 1999). Recent work on parser evaluation using dependency graphs in the biomedical domain confirms 6 that researchers regard dependency-based evaluation as a more useful surrogate for extrinsic task-based evaluation (Clegg and Shepherd, 2007; Pyysalo et al., 2007a). In their evaluation, Clegg and Shepherd (2007) aimed at analyzing the capabilities of syntactic parsers with respect to semantically important tas</context>
<context position="27526" citStr="Clegg and Shepherd (2007)" startWordPosition="4322" endWordPosition="4325">constituent parsers and treebanks at the dependency level,” and they assessed its suitability for evaluation. They found that the SD scheme better illuminates the performance differences between higher ranked parsers (e.g., Charniak-Lease parser (Lease and Charniak, 2005)), and lower ranked parsers (e.g., the Stanford parser (Klein and Manning, 2003)). Their parser evaluation accommodates user needs: they used the collapsed version of the dependency graphs offered by the SD scheme, arguing that this is the kind of graph one would find most useful in an information extraction project. Although Clegg and Shepherd (2007) also favor dependency graph representations for parser evaluation, they advocate retention of parse trees so information lost in the dependency structures can be accessed. In essence, any existing dependency scheme could be adopted as the gold-standard for evaluation. However if one believes in ultimately valuing extrinsic task-based evaluation, a dependency representation which proposes a suitable design for users and user tasks is probably the best surrogate for intrinsic evaluation. Moreover, the existence of tools for automatically generating and converting dependency representations has </context>
</contexts>
<marker>Clegg, Shepherd, 2007</marker>
<rawString>Clegg, Andrew B. and Adrian J. Shepherd. 2007. Benchmarking natural-language parsers for biological applications using dependency graphs. BMC Bioinformatics, 8:24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew B Clegg</author>
</authors>
<title>Computational-Linguistic Approaches to Biological Text Mining.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>School of Crystallography, Birkbeck, University of London.</institution>
<contexts>
<context position="22224" citStr="Clegg, 2008" startWordPosition="3505" endWordPosition="3506">., 2006; Giampiccolo et al., 2007), the increase in the use of SD is clearly apparent. The goal in these challenges consists of identifying whether one sentence follows from a piece of text and general background knowledge, according to the intuitions of an intelligent human reader. In 2007, out of the 21 systems which participated in the challenge, 5 used the SD representation, whereas the year before only the Stanford entry was using it. SD is also widely present in the bioinformatic world where it is used with success (Erkan et al., 2007; Greenwood and Stevenson, 2007; Urbain et al., 2007; Clegg, 2008). Fundel et al. (2007) found that, in extraction of relations between genes and proteins, a system based on the SD scheme greatly outperformed the previous best system on the LLL challenge dataset (by an 18% absolute improvement in F-measure). Airola et al. (2008) provide more systematic results on a number of proteinprotein interaction datasets. Their graph kernel approach uses an all-dependency-paths kernel which allows their system to consider full dependency graphs. Their system is based on the SD scheme, and they demonstrate state-of-the-art performance for this approach. In the biomedica</context>
</contexts>
<marker>Clegg, 2008</marker>
<rawString>Clegg, Andrew B. 2008. Computational-Linguistic Approaches to Biological Text Mining. Ph.D. thesis, School of Crystallography, Birkbeck, University of London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
<author>Bernardo Magnini</author>
</authors>
<title>The PASCAL recognising textual entailment challenge. In</title>
<date>2006</date>
<booktitle>MLCW 2005, LNAI Volume 3944,</booktitle>
<pages>177--190</pages>
<editor>et al., Quinonero-Candela, editor,</editor>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="21619" citStr="Dagan et al., 2006" startWordPosition="3399" endWordPosition="3402">t conversion tool. Long-distance dependencies are not absent from the formalism, but the tool does not accurately deal with them.5 4 Stanford dependencies in practice SD has been successfully used by researchers in different domains. In the PASCAL Recognizing 5As possible future work, we have thought of using a tool such as the one of Levy and Manning (2004) to correctly determine long distance dependencies, as input to the current dependency conversion system. This would presumably be effective, but would make the conversion process much heavier weight. 5 Textual Entailment (RTE) challenges (Dagan et al., 2006; Giampiccolo et al., 2007), the increase in the use of SD is clearly apparent. The goal in these challenges consists of identifying whether one sentence follows from a piece of text and general background knowledge, according to the intuitions of an intelligent human reader. In 2007, out of the 21 systems which participated in the challenge, 5 used the SD representation, whereas the year before only the Stanford entry was using it. SD is also widely present in the bioinformatic world where it is used with success (Erkan et al., 2007; Greenwood and Stevenson, 2007; Urbain et al., 2007; Clegg, </context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2006</marker>
<rawString>Dagan, Ido, Oren Glickman, and Bernardo Magnini. 2006. The PASCAL recognising textual entailment challenge. In et al., Quinonero-Candela, editor, MLCW 2005, LNAI Volume 3944, pages 177–190. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC-06.</booktitle>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>de Marneffe, Marie-Catherine, Bill MacCartney, and Christopher D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of LREC-06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gunes Erkan</author>
<author>Arzucan Ozgur</author>
<author>Dragomir R Radev</author>
</authors>
<title>Semi-supervised classification for extracting protein interaction sentences using dependency parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).</booktitle>
<contexts>
<context position="22158" citStr="Erkan et al., 2007" startWordPosition="3493" endWordPosition="3496"> much heavier weight. 5 Textual Entailment (RTE) challenges (Dagan et al., 2006; Giampiccolo et al., 2007), the increase in the use of SD is clearly apparent. The goal in these challenges consists of identifying whether one sentence follows from a piece of text and general background knowledge, according to the intuitions of an intelligent human reader. In 2007, out of the 21 systems which participated in the challenge, 5 used the SD representation, whereas the year before only the Stanford entry was using it. SD is also widely present in the bioinformatic world where it is used with success (Erkan et al., 2007; Greenwood and Stevenson, 2007; Urbain et al., 2007; Clegg, 2008). Fundel et al. (2007) found that, in extraction of relations between genes and proteins, a system based on the SD scheme greatly outperformed the previous best system on the LLL challenge dataset (by an 18% absolute improvement in F-measure). Airola et al. (2008) provide more systematic results on a number of proteinprotein interaction datasets. Their graph kernel approach uses an all-dependency-paths kernel which allows their system to consider full dependency graphs. Their system is based on the SD scheme, and they demonstrat</context>
</contexts>
<marker>Erkan, Ozgur, Radev, 2007</marker>
<rawString>Erkan, Gunes, Arzucan Ozgur, and Dragomir R. Radev. 2007. Semi-supervised classification for extracting protein interaction sentences using dependency parsing. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: an electronic lexical database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2786" citStr="Fellbaum, 1998" startWordPosition="394" endWordPosition="395">for the natural language processing (NLP) community is how to make the very impressive and practical technology which has been developed over the last two decades approachable to and usable by everyone who has text understanding needs. That is, usable not only by computational linguists, but also by the computer science community more generally and by all sorts of information professionals including biologists, medical researchers, political scientists, law firms, business and market analysts, etc. Thinking about this issue, we were struck by two facts. First, we noted how frequently WordNet (Fellbaum, 1998) gets used compared to other resources, such as FrameNet (Fillmore et al., 2003) or the Penn Treebank (Marcus et al., 1993). We believe that much of the explanation for this fact lies in the difference of complexity of the representation used by the resources. It is easy for users not necessarily versed in linguistics to see how to use and to get value from the straightforward structure of WordNet. Second, we noted the widespread use of MiniPar (Lin, 1998) and the Link Parser (Sleator and Temperley, 1993). This clearly shows that (i) it is very easy for a non-linguist thinking in relation extr</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Fellbaum, Christiane. 1998. WordNet: an electronic lexical database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
<author>Christopher R Johnson</author>
<author>Miriam R L Petruck</author>
</authors>
<title>Background to FrameNet.</title>
<date>2003</date>
<journal>International Journal of Lexicography,</journal>
<pages>16--235</pages>
<contexts>
<context position="2866" citStr="Fillmore et al., 2003" startWordPosition="405" endWordPosition="408">ry impressive and practical technology which has been developed over the last two decades approachable to and usable by everyone who has text understanding needs. That is, usable not only by computational linguists, but also by the computer science community more generally and by all sorts of information professionals including biologists, medical researchers, political scientists, law firms, business and market analysts, etc. Thinking about this issue, we were struck by two facts. First, we noted how frequently WordNet (Fellbaum, 1998) gets used compared to other resources, such as FrameNet (Fillmore et al., 2003) or the Penn Treebank (Marcus et al., 1993). We believe that much of the explanation for this fact lies in the difference of complexity of the representation used by the resources. It is easy for users not necessarily versed in linguistics to see how to use and to get value from the straightforward structure of WordNet. Second, we noted the widespread use of MiniPar (Lin, 1998) and the Link Parser (Sleator and Temperley, 1993). This clearly shows that (i) it is very easy for a non-linguist thinking in relation extraction terms to see how to make use of a dependency representation (whereas a ph</context>
</contexts>
<marker>Fillmore, Johnson, Petruck, 2003</marker>
<rawString>Fillmore, Charles J., Christopher R. Johnson, and Miriam R.L. Petruck. 2003. Background to FrameNet. International Journal of Lexicography, 16:235–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Fundel</author>
<author>Robert K¨uffner</author>
<author>Ralf Zimmer</author>
</authors>
<title>RelEx relation extraction using dependency parse trees.</title>
<date>2007</date>
<journal>Bioinformatics,</journal>
<volume>23</volume>
<marker>Fundel, K¨uffner, Zimmer, 2007</marker>
<rawString>Fundel, Katrin, Robert K¨uffner, and Ralf Zimmer. 2007. RelEx relation extraction using dependency parse trees. Bioinformatics, 23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Giampiccolo</author>
<author>Bernardo Magnini</author>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
</authors>
<title>The third PASCAL recognizing textual entailment challenge.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing,</booktitle>
<pages>1--9</pages>
<contexts>
<context position="21646" citStr="Giampiccolo et al., 2007" startWordPosition="3403" endWordPosition="3406">ong-distance dependencies are not absent from the formalism, but the tool does not accurately deal with them.5 4 Stanford dependencies in practice SD has been successfully used by researchers in different domains. In the PASCAL Recognizing 5As possible future work, we have thought of using a tool such as the one of Levy and Manning (2004) to correctly determine long distance dependencies, as input to the current dependency conversion system. This would presumably be effective, but would make the conversion process much heavier weight. 5 Textual Entailment (RTE) challenges (Dagan et al., 2006; Giampiccolo et al., 2007), the increase in the use of SD is clearly apparent. The goal in these challenges consists of identifying whether one sentence follows from a piece of text and general background knowledge, according to the intuitions of an intelligent human reader. In 2007, out of the 21 systems which participated in the challenge, 5 used the SD representation, whereas the year before only the Stanford entry was using it. SD is also widely present in the bioinformatic world where it is used with success (Erkan et al., 2007; Greenwood and Stevenson, 2007; Urbain et al., 2007; Clegg, 2008). Fundel et al. (2007)</context>
</contexts>
<marker>Giampiccolo, Magnini, Dagan, Dolan, 2007</marker>
<rawString>Giampiccolo, Danilo, Bernardo Magnini, Ido Dagan, and Bill Dolan. 2007. The third PASCAL recognizing textual entailment challenge. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, pages 1–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark A Greenwood</author>
<author>Mark Stevenson</author>
</authors>
<title>A semi-supervised approach to learning relevant protein-protein interaction articles.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second BioCreAtIvE Challenge Workshop,</booktitle>
<location>Madrid,</location>
<contexts>
<context position="22189" citStr="Greenwood and Stevenson, 2007" startWordPosition="3497" endWordPosition="3500">. 5 Textual Entailment (RTE) challenges (Dagan et al., 2006; Giampiccolo et al., 2007), the increase in the use of SD is clearly apparent. The goal in these challenges consists of identifying whether one sentence follows from a piece of text and general background knowledge, according to the intuitions of an intelligent human reader. In 2007, out of the 21 systems which participated in the challenge, 5 used the SD representation, whereas the year before only the Stanford entry was using it. SD is also widely present in the bioinformatic world where it is used with success (Erkan et al., 2007; Greenwood and Stevenson, 2007; Urbain et al., 2007; Clegg, 2008). Fundel et al. (2007) found that, in extraction of relations between genes and proteins, a system based on the SD scheme greatly outperformed the previous best system on the LLL challenge dataset (by an 18% absolute improvement in F-measure). Airola et al. (2008) provide more systematic results on a number of proteinprotein interaction datasets. Their graph kernel approach uses an all-dependency-paths kernel which allows their system to consider full dependency graphs. Their system is based on the SD scheme, and they demonstrate state-of-the-art performance </context>
</contexts>
<marker>Greenwood, Stevenson, 2007</marker>
<rawString>Greenwood, Mark A. and Mark Stevenson. 2007. A semi-supervised approach to learning relevant protein-protein interaction articles. In Proceedings of the Second BioCreAtIvE Challenge Workshop, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tracy H King</author>
<author>Richard Crouch</author>
<author>Stefan Riezler</author>
<author>Mary Dalrymple</author>
<author>Ronald Kaplan</author>
</authors>
<date>2003</date>
<booktitle>The PARC 700 dependency bank. In 4th International Workshop on Linguistically Interpreted Corpora (LINC03).</booktitle>
<contexts>
<context position="5823" citStr="King et al., 2003" startWordPosition="874" endWordPosition="877">l about linguistic features such as tense and agreement. The SD scheme thus provides a semantic representation simple and natural enough for people who are not (computational) linguists but can benefit from NLP tools. 2 Design choices and their implications 2.1 Design principles The style of the SD representation bears a strong intellectual debt to the framework of LexicalFunctional Grammar (Bresnan, 2001), and, more directly, it owes a debt to both the sets of grammatical relations and the naming defined in two representations that follow an LFG style: the GR (Carroll et al., 1999) and PARC (King et al., 2003) schemes. These were used as a starting point for developing the Stanford dependencies (de Marneffe et al., 2006). But where the SD scheme deviates from GR, PARC, and its LFG roots is that it has been designed to be a practical model of sentence representation, particularly in the context of relation extraction tasks. parser. 2The logic forms of Moldovan and Rus are in the form of a predicate calculus representation, although not one that represents such things as operator scope in a way that most would expect of a predicate calculus representation. SD makes available two options, suited to di</context>
</contexts>
<marker>King, Crouch, Riezler, Dalrymple, Kaplan, 2003</marker>
<rawString>King, Tracy H., Richard Crouch, Stefan Riezler, Mary Dalrymple, and Ronald Kaplan. 2003. The PARC 700 dependency bank. In 4th International Workshop on Linguistically Interpreted Corpora (LINC03).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="27253" citStr="Klein and Manning, 2003" startWordPosition="4279" endWordPosition="4282">d Shepherd (2007) aimed at analyzing the capabilities of syntactic parsers with respect to semantically important tasks crucial to biological information extraction systems. To do so, they used the SD scheme, which provides “a de facto standard for comparing a variety of constituent parsers and treebanks at the dependency level,” and they assessed its suitability for evaluation. They found that the SD scheme better illuminates the performance differences between higher ranked parsers (e.g., Charniak-Lease parser (Lease and Charniak, 2005)), and lower ranked parsers (e.g., the Stanford parser (Klein and Manning, 2003)). Their parser evaluation accommodates user needs: they used the collapsed version of the dependency graphs offered by the SD scheme, arguing that this is the kind of graph one would find most useful in an information extraction project. Although Clegg and Shepherd (2007) also favor dependency graph representations for parser evaluation, they advocate retention of parse trees so information lost in the dependency structures can be accessed. In essence, any existing dependency scheme could be adopted as the gold-standard for evaluation. However if one believes in ultimately valuing extrinsic t</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Klein, Dan and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Lease</author>
<author>Eugene Charniak</author>
</authors>
<title>Parsing biomedical literature.</title>
<date>2005</date>
<booktitle>In Proceedings of the Second International Joint Conference on Natural Language Processing (IJCNLP’05).</booktitle>
<contexts>
<context position="27173" citStr="Lease and Charniak, 2005" startWordPosition="4267" endWordPosition="4270"> (Clegg and Shepherd, 2007; Pyysalo et al., 2007a). In their evaluation, Clegg and Shepherd (2007) aimed at analyzing the capabilities of syntactic parsers with respect to semantically important tasks crucial to biological information extraction systems. To do so, they used the SD scheme, which provides “a de facto standard for comparing a variety of constituent parsers and treebanks at the dependency level,” and they assessed its suitability for evaluation. They found that the SD scheme better illuminates the performance differences between higher ranked parsers (e.g., Charniak-Lease parser (Lease and Charniak, 2005)), and lower ranked parsers (e.g., the Stanford parser (Klein and Manning, 2003)). Their parser evaluation accommodates user needs: they used the collapsed version of the dependency graphs offered by the SD scheme, arguing that this is the kind of graph one would find most useful in an information extraction project. Although Clegg and Shepherd (2007) also favor dependency graph representations for parser evaluation, they advocate retention of parse trees so information lost in the dependency structures can be accessed. In essence, any existing dependency scheme could be adopted as the gold-st</context>
</contexts>
<marker>Lease, Charniak, 2005</marker>
<rawString>Lease, Matthew and Eugene Charniak. 2005. Parsing biomedical literature. In Proceedings of the Second International Joint Conference on Natural Language Processing (IJCNLP’05).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Levy</author>
<author>Galen Andrew</author>
</authors>
<title>Tregex and Tsurgeon: tools for querying and manipulating tree data structures.</title>
<date>2006</date>
<booktitle>In LREC</booktitle>
<note>http://wwwnlp.stanford.edu/software/tregex.shtml.</note>
<contexts>
<context position="19724" citStr="Levy and Andrew, 2006" startWordPosition="3091" endWordPosition="3094">ead. As mentioned, content words are chosen as heads, and all the other words in the constituent 4http://nlp.stanford.edu/software/lex-parser.shtml depend on this head. To retrieve adequate heads from a semantic point of view, heuristics are used to inject more structure when the Penn Treebank gives only flat constituents, as is often the case for conjuncts, e.g., (NP the new phone book and tour guide), and QP constituents, e.g., (QP more than 300). Then for each grammatical relation, patterns are defined over the phrase structure parse tree using the tree-expression syntax defined by tregex (Levy and Andrew, 2006). Conceptually, each pattern is matched against every tree node, and the matching pattern with the most specific grammatical relation is taken as the type of the dependency. The automatic extraction of the relations is not infallible. For instance, in the sentence Behind their perimeter walls lie freshly laundered flowers, verdant grass still sparkling from the last shower, yew hedges in an ecstasy of precision clipping (BNC), the system will erroneously retrieve apposition relations between flowers and grass, as well as between flowers and hedges whereas these should be conj and relations. Th</context>
</contexts>
<marker>Levy, Andrew, 2006</marker>
<rawString>Levy, Roger and Galen Andrew. 2006. Tregex and Tsurgeon: tools for querying and manipulating tree data structures. In LREC 2006. http://wwwnlp.stanford.edu/software/tregex.shtml.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Levy</author>
<author>Christopher D Manning</author>
</authors>
<title>Deep dependencies from context-free statistical parsers: correcting the surface dependency approximation.</title>
<date>2004</date>
<booktitle>In ACL 42,</booktitle>
<pages>328--335</pages>
<contexts>
<context position="21361" citStr="Levy and Manning (2004)" startWordPosition="3360" endWordPosition="3363">subj(think-4, he-3) However in a sentence such as Who the hell does he think he’s kidding? (BNC), the automatic extraction will fail to find that who is the direct object of kidding. Here, it is vital to distinguish between SD as a representation versus the extant conversion tool. Long-distance dependencies are not absent from the formalism, but the tool does not accurately deal with them.5 4 Stanford dependencies in practice SD has been successfully used by researchers in different domains. In the PASCAL Recognizing 5As possible future work, we have thought of using a tool such as the one of Levy and Manning (2004) to correctly determine long distance dependencies, as input to the current dependency conversion system. This would presumably be effective, but would make the conversion process much heavier weight. 5 Textual Entailment (RTE) challenges (Dagan et al., 2006; Giampiccolo et al., 2007), the increase in the use of SD is clearly apparent. The goal in these challenges consists of identifying whether one sentence follows from a piece of text and general background knowledge, according to the intuitions of an intelligent human reader. In 2007, out of the 21 systems which participated in the challeng</context>
</contexts>
<marker>Levy, Manning, 2004</marker>
<rawString>Levy, Roger and Christopher D. Manning. 2004. Deep dependencies from context-free statistical parsers: correcting the surface dependency approximation. In ACL 42, pages 328–335.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Discovery of inference rules for question answering.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="12518" citStr="Lin and Pantel, 2001" startWordPosition="1953" endWordPosition="1956">s between content words is useful is the case of prepositional complements. The SD scheme offers the option of “collapsing” dependencies involving a preposition (DP5). In the example above, instead of having two relations adjunct(workout, of) and obj(of, Suns) as in PARC or ncmod(workout, of) and dobj(of, Suns) as in GR, SD provides a direct relation between the content words: prep of(workout, Suns). Prepositions often work as role markers, and this type of link facilitates the extraction of how the two content words are related; and thus these links are often used by downstream applications (Lin and Pantel, 2001; Snow et al., 2005). The usefulness of the representation is exemplified in the sentence A similar technique is almost impossible to apply to other crops, such as cotton, soybeans and rice (WSJ-R) for which SD gives direct links between the entities joined through the preposition such as: SD prep such as(crops, cotton) prep such as(crops, soybeans) prep such as(crops, rice) A similar collapsing treatment takes place for conjuncts (DP5). Consider the following sentence: Bell, based in Los Angeles, makes and distributes 3 SD nsubj(makes-8, Bell-1) nsubj(distributes-10, Bell-1) partmod(Bell-1, b</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Lin, Dekang and Patrick Pantel. 2001. Discovery of inference rules for question answering. Natural Language Engineering, 7(4):343–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Dependency-based evaluation of MINIPAR.</title>
<date>1998</date>
<booktitle>In Workshop on the Evaluation of Parsing Systems,</booktitle>
<location>Granada,</location>
<contexts>
<context position="3246" citStr="Lin, 1998" startWordPosition="477" endWordPosition="478">ms, business and market analysts, etc. Thinking about this issue, we were struck by two facts. First, we noted how frequently WordNet (Fellbaum, 1998) gets used compared to other resources, such as FrameNet (Fillmore et al., 2003) or the Penn Treebank (Marcus et al., 1993). We believe that much of the explanation for this fact lies in the difference of complexity of the representation used by the resources. It is easy for users not necessarily versed in linguistics to see how to use and to get value from the straightforward structure of WordNet. Second, we noted the widespread use of MiniPar (Lin, 1998) and the Link Parser (Sleator and Temperley, 1993). This clearly shows that (i) it is very easy for a non-linguist thinking in relation extraction terms to see how to make use of a dependency representation (whereas a phrase structure representation seems much more foreign and forbidding), and (ii) the availability of high quality, easy-to-use (and preferably free) tools is essential for driving broader use of NLP tools.1 1On the other hand, evaluation seems less important; to the best of our knowledge there has never been a convincing and thorough evaluation of either MiniPar or the Link Gram</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Lin, Dekang. 1998. Dependency-based evaluation of MINIPAR. In Workshop on the Evaluation of Parsing Systems, Granada, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The Penn Treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="2909" citStr="Marcus et al., 1993" startWordPosition="414" endWordPosition="417">has been developed over the last two decades approachable to and usable by everyone who has text understanding needs. That is, usable not only by computational linguists, but also by the computer science community more generally and by all sorts of information professionals including biologists, medical researchers, political scientists, law firms, business and market analysts, etc. Thinking about this issue, we were struck by two facts. First, we noted how frequently WordNet (Fellbaum, 1998) gets used compared to other resources, such as FrameNet (Fillmore et al., 2003) or the Penn Treebank (Marcus et al., 1993). We believe that much of the explanation for this fact lies in the difference of complexity of the representation used by the resources. It is easy for users not necessarily versed in linguistics to see how to use and to get value from the straightforward structure of WordNet. Second, we noted the widespread use of MiniPar (Lin, 1998) and the Link Parser (Sleator and Temperley, 1993). This clearly shows that (i) it is very easy for a non-linguist thinking in relation extraction terms to see how to make use of a dependency representation (whereas a phrase structure representation seems much mo</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Marcus, Mitchell P., Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of english: The Penn Treebank. Computational Linguistics, 19 (2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arun Meena</author>
<author>T V Prabhakar</author>
</authors>
<title>Sentence level sentiment analysis in the presence of conjuncts using linguistic analysis.</title>
<date>2007</date>
<booktitle>In Advances in Information Retrieval,</booktitle>
<volume>4425</volume>
<publisher>Springer.</publisher>
<contexts>
<context position="24697" citStr="Meena and Prabhakar (2007)" startWordPosition="3892" endWordPosition="3895"> followed the Link Grammar scheme, Pyysalo et al. (2007a) developed a version of the corpus annotated with the SD scheme. They also made available a program and conversion rules that they used to transform Link Grammar relations into SD graphs, which were then hand-corrected (Pyysalo et al., 2007b). While a limited amount of gold standard annotated data was prepared for the Parser Evaluation Shared Task, this is the main source of gold-standard SD data which is currently available. In other domains, Zhuang et al. (2006) uses the representation to extract opinions about features in reviews and Meena and Prabhakar (2007) uses it to improve the quality of sentence-level sentiment analysis. The open information extraction system TEXTRUNNER (Banko et al., 2007) also makes use of the SD graph representation: its first module uses the Stanford parser and the dependency tool to automatically identify and label trustworthy and untrustworthy extractions. Even in theoretical linguistic work, SD has proven very useful: it has hugely facilitated data extraction from corpora, in the context of the NSF-funded project “Dynamics of probabilistic grammar” carried out at the Stanford Linguistics department. 5 Suitability for </context>
</contexts>
<marker>Meena, Prabhakar, 2007</marker>
<rawString>Meena, Arun and T. V. Prabhakar. 2007. Sentence level sentiment analysis in the presence of conjuncts using linguistic analysis. In Advances in Information Retrieval, volume 4425 of Lecture Notes in Computer Science. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan I Moldovan</author>
<author>Vasile Rus</author>
</authors>
<title>Logic form transformation of wordnet and its applicability to question answering.</title>
<date>2001</date>
<booktitle>In Meeting of the Association for Computational Linguistics,</booktitle>
<pages>394--401</pages>
<contexts>
<context position="4470" citStr="Moldovan and Rus, 2001" startWordPosition="667" endWordPosition="670">ar 1 Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation, pages 1–8 Manchester, August 2008 This paper advocates for the Stanford typed dependencies representation (henceforth SD) being a promising vehicle for bringing the breakthroughs of the last 15 years of parsing research to this broad potential user community. The representation aims to provide a simple, habitable design. All information is represented as binary relations. This maps straightforwardly on to common representations of potential users, including the logic forms of Moldovan and Rus (Moldovan and Rus, 2001),2 semantic web Resource Description Framework (RDF) triples (http://www.w3.org/RDF/), and graph representations (with labeled edges and nodes). Unlike many linguistic formalisms, excessive detail is viewed as a defect: information that users do not understand or wish to process detracts from uptake and usability. The user-centered design process saw the key goal as representing semantically contentful relations suitable for relation extraction and more general information extraction uses. The design supports this use by favoring relations between content words, by maintaining semantically use</context>
</contexts>
<marker>Moldovan, Rus, 2001</marker>
<rawString>Moldovan, Dan I. and Vasile Rus. 2001. Logic form transformation of wordnet and its applicability to question answering. In Meeting of the Association for Computational Linguistics, pages 394–401.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diego Moll´a</author>
<author>Ben Hutchinson</author>
</authors>
<title>Intrinsic versus extrinsic evaluations of parsing systems.</title>
<date>2003</date>
<booktitle>In Proceedings of the Workshop on Evaluation Initiatives in Natural Language Processing,</booktitle>
<pages>43--50</pages>
<institution>European Association for Computational Linguistics.</institution>
<marker>Moll´a, Hutchinson, 2003</marker>
<rawString>Moll´a, Diego and Ben Hutchinson. 2003. Intrinsic versus extrinsic evaluations of parsing systems. In Proceedings of the Workshop on Evaluation Initiatives in Natural Language Processing, pages 43–50. European Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sampo Pyysalo</author>
<author>Filip Ginter</author>
<author>Katri Haverinen</author>
<author>Juho Heimonen</author>
<author>Tapio Salakoski</author>
<author>Veronika Laippala</author>
</authors>
<title>On the unification of syntactic annotations under the Stanford dependency scheme: A case study on BioInfer and GENIA.</title>
<date>2007</date>
<booktitle>In Proceedings of BioNLP</booktitle>
<contexts>
<context position="22933" citStr="Pyysalo et al., 2007" startWordPosition="3615" endWordPosition="3618"> a system based on the SD scheme greatly outperformed the previous best system on the LLL challenge dataset (by an 18% absolute improvement in F-measure). Airola et al. (2008) provide more systematic results on a number of proteinprotein interaction datasets. Their graph kernel approach uses an all-dependency-paths kernel which allows their system to consider full dependency graphs. Their system is based on the SD scheme, and they demonstrate state-of-the-art performance for this approach. In the biomedical domain, SD has recently been used in evaluations of parsers (Clegg and Shepherd, 2007; Pyysalo et al., 2007a). Pyysalo et al. (2007a) assessed the suitability of the SD scheme over the Link Grammar dependency scheme in an application-oriented evaluation. The Link Parser indeed uses a very fine-grained set of relations, which often makes distinctions of a structural rather than a semantic nature. One example is the MX relation which “connects modifying phrases with commas to preceding nouns (‘The DOG, a POODLE, was black’; ‘JOHN, IN a black suit, looked great’).” The Link Parser uses a different set of dependency types for dependencies appearing in questions and relative clauses. Another example is </context>
<context position="24368" citStr="Pyysalo et al., 2007" startWordPosition="3839" endWordPosition="3842">an intermediate level of granularity, and targeting semantic dependencies, provides a more adequate representation for applications. Therefore, to increase the usability of the BioInfer corpus (Pyysalo et al., 2007b), which provides manually annotated data for information extraction in the biomedical domain and originally followed the Link Grammar scheme, Pyysalo et al. (2007a) developed a version of the corpus annotated with the SD scheme. They also made available a program and conversion rules that they used to transform Link Grammar relations into SD graphs, which were then hand-corrected (Pyysalo et al., 2007b). While a limited amount of gold standard annotated data was prepared for the Parser Evaluation Shared Task, this is the main source of gold-standard SD data which is currently available. In other domains, Zhuang et al. (2006) uses the representation to extract opinions about features in reviews and Meena and Prabhakar (2007) uses it to improve the quality of sentence-level sentiment analysis. The open information extraction system TEXTRUNNER (Banko et al., 2007) also makes use of the SD graph representation: its first module uses the Stanford parser and the dependency tool to automatically </context>
<context position="26596" citStr="Pyysalo et al., 2007" startWordPosition="4182" endWordPosition="4185">nformatics, where the advantage of dependency representations for shallow text understanding tasks has become salient, we would argue, following Clegg and Shepherd (2007), that dependency-based evaluation is close to typical user tasks. Moreover, it avoids some of the known deficiencies of other parser evaluation measures such as Parseval (Carroll et al., 1999). Recent work on parser evaluation using dependency graphs in the biomedical domain confirms 6 that researchers regard dependency-based evaluation as a more useful surrogate for extrinsic task-based evaluation (Clegg and Shepherd, 2007; Pyysalo et al., 2007a). In their evaluation, Clegg and Shepherd (2007) aimed at analyzing the capabilities of syntactic parsers with respect to semantically important tasks crucial to biological information extraction systems. To do so, they used the SD scheme, which provides “a de facto standard for comparing a variety of constituent parsers and treebanks at the dependency level,” and they assessed its suitability for evaluation. They found that the SD scheme better illuminates the performance differences between higher ranked parsers (e.g., Charniak-Lease parser (Lease and Charniak, 2005)), and lower ranked par</context>
</contexts>
<marker>Pyysalo, Ginter, Haverinen, Heimonen, Salakoski, Laippala, 2007</marker>
<rawString>Pyysalo, Sampo, Filip Ginter, Katri Haverinen, Juho Heimonen, Tapio Salakoski, and Veronika Laippala. 2007a. On the unification of syntactic annotations under the Stanford dependency scheme: A case study on BioInfer and GENIA. In Proceedings of BioNLP 2007: Biological, translational, and clinical language processing (ACL07).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sampo Pyysalo</author>
<author>Filip Ginter</author>
<author>Juho Heimonen</author>
<author>Jari Bj¨orne</author>
<author>Jorma Boberg</author>
<author>Jouni J¨arvinen</author>
<author>Tapio Salakoski</author>
</authors>
<title>BioInfer: A corpus for information extraction in the biomedical domain.</title>
<date>2007</date>
<journal>BMC Bioinformatics,</journal>
<volume>8</volume>
<marker>Pyysalo, Ginter, Heimonen, Bj¨orne, Boberg, J¨arvinen, Salakoski, 2007</marker>
<rawString>Pyysalo, Sampo, Filip Ginter, Juho Heimonen, Jari Bj¨orne, Jorma Boberg, Jouni J¨arvinen, and Tapio Salakoski. 2007b. BioInfer: A corpus for information extraction in the biomedical domain. BMC Bioinformatics, 8:50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Challenges in mapping of syntactic representations for framework-independent parser evaluation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Workshop on Automated Syntatic Annotations for Interoperable Language Resources at the First International Conference on Global Interoperability for Language Resources (ICGL’08).</booktitle>
<contexts>
<context position="18374" citStr="Sagae et al. (2008)" startWordPosition="2875" endWordPosition="2878">ent-2’) Not collapsing the relations in such a case would prevent the alteration of the semantics, but would lead to a non-uniform treatment of prepositions. Uniformity is key for readability and user convenience. It seems therefore reasonable to use a representation which sacrifices the exact semantics of the original sentence by producing a sentence roughly equivalent, but which ensures uniformity across relations. 3 The formalism and the tool Two vital conditions for the success of a dependency scheme are to provide a suitable representation for users as well as a tool that is easy to use. Sagae et al. (2008) note that the availability of an automatic procedure to convert phrase structure parses to SD is the reason for its use in evaluations of parsers in the biomedical domain. The primary focus of the SD scheme, however, has been to offer grammatical relations appropriate for end-users. The Stanford parser4 comes with a tool, described in (de Marneffe et al., 2006), which provides for the rapid extraction of the grammatical relations from phrase structure parses. Structural configurations are used to define grammatical roles: the semantic head of each constituent of the parse is identified, using</context>
</contexts>
<marker>Sagae, Miyao, Tsujii, 2008</marker>
<rawString>Sagae, Kenji, Yusuke Miyao, and Jun’ichi Tsujii. 2008. Challenges in mapping of syntactic representations for framework-independent parser evaluation. In Proceedings of the Workshop on Automated Syntatic Annotations for Interoperable Language Resources at the First International Conference on Global Interoperability for Language Resources (ICGL’08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel D Sleator</author>
<author>Davy Temperley</author>
</authors>
<title>Parsing English with a link grammar.</title>
<date>1993</date>
<booktitle>In Third International Workshop on Parsing Technologies.</booktitle>
<contexts>
<context position="3296" citStr="Sleator and Temperley, 1993" startWordPosition="483" endWordPosition="486">, etc. Thinking about this issue, we were struck by two facts. First, we noted how frequently WordNet (Fellbaum, 1998) gets used compared to other resources, such as FrameNet (Fillmore et al., 2003) or the Penn Treebank (Marcus et al., 1993). We believe that much of the explanation for this fact lies in the difference of complexity of the representation used by the resources. It is easy for users not necessarily versed in linguistics to see how to use and to get value from the straightforward structure of WordNet. Second, we noted the widespread use of MiniPar (Lin, 1998) and the Link Parser (Sleator and Temperley, 1993). This clearly shows that (i) it is very easy for a non-linguist thinking in relation extraction terms to see how to make use of a dependency representation (whereas a phrase structure representation seems much more foreign and forbidding), and (ii) the availability of high quality, easy-to-use (and preferably free) tools is essential for driving broader use of NLP tools.1 1On the other hand, evaluation seems less important; to the best of our knowledge there has never been a convincing and thorough evaluation of either MiniPar or the Link Grammar 1 Coling 2008: Proceedings of the workshop on </context>
</contexts>
<marker>Sleator, Temperley, 1993</marker>
<rawString>Sleator, Daniel D. and Davy Temperley. 1993. Parsing English with a link grammar. In Third International Workshop on Parsing Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Daniel Jurafsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Learning syntactic patterns for automatic hypernym discovery.</title>
<date>2005</date>
<booktitle>In Proceedings of NIPS</booktitle>
<contexts>
<context position="12538" citStr="Snow et al., 2005" startWordPosition="1957" endWordPosition="1960">s is useful is the case of prepositional complements. The SD scheme offers the option of “collapsing” dependencies involving a preposition (DP5). In the example above, instead of having two relations adjunct(workout, of) and obj(of, Suns) as in PARC or ncmod(workout, of) and dobj(of, Suns) as in GR, SD provides a direct relation between the content words: prep of(workout, Suns). Prepositions often work as role markers, and this type of link facilitates the extraction of how the two content words are related; and thus these links are often used by downstream applications (Lin and Pantel, 2001; Snow et al., 2005). The usefulness of the representation is exemplified in the sentence A similar technique is almost impossible to apply to other crops, such as cotton, soybeans and rice (WSJ-R) for which SD gives direct links between the entities joined through the preposition such as: SD prep such as(crops, cotton) prep such as(crops, soybeans) prep such as(crops, rice) A similar collapsing treatment takes place for conjuncts (DP5). Consider the following sentence: Bell, based in Los Angeles, makes and distributes 3 SD nsubj(makes-8, Bell-1) nsubj(distributes-10, Bell-1) partmod(Bell-1, based-3) nn(Angeles-6</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2005</marker>
<rawString>Snow, Rion, Daniel Jurafsky, and Andrew Y. Ng. 2005. Learning syntactic patterns for automatic hypernym discovery. In Proceedings of NIPS 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay Urbain</author>
<author>Nazli Goharian</author>
<author>Ophir Frieder</author>
</authors>
<title>IIT TREC</title>
<date>2007</date>
<booktitle>In The Sixteenth Text REtrieval Conference (TREC 2007) Proceedings.</booktitle>
<contexts>
<context position="22210" citStr="Urbain et al., 2007" startWordPosition="3501" endWordPosition="3504">allenges (Dagan et al., 2006; Giampiccolo et al., 2007), the increase in the use of SD is clearly apparent. The goal in these challenges consists of identifying whether one sentence follows from a piece of text and general background knowledge, according to the intuitions of an intelligent human reader. In 2007, out of the 21 systems which participated in the challenge, 5 used the SD representation, whereas the year before only the Stanford entry was using it. SD is also widely present in the bioinformatic world where it is used with success (Erkan et al., 2007; Greenwood and Stevenson, 2007; Urbain et al., 2007; Clegg, 2008). Fundel et al. (2007) found that, in extraction of relations between genes and proteins, a system based on the SD scheme greatly outperformed the previous best system on the LLL challenge dataset (by an 18% absolute improvement in F-measure). Airola et al. (2008) provide more systematic results on a number of proteinprotein interaction datasets. Their graph kernel approach uses an all-dependency-paths kernel which allows their system to consider full dependency graphs. Their system is based on the SD scheme, and they demonstrate state-of-the-art performance for this approach. In</context>
</contexts>
<marker>Urbain, Goharian, Frieder, 2007</marker>
<rawString>Urbain, Jay, Nazli Goharian, and Ophir Frieder. 2007. IIT TREC 2007 genomics track: Using conceptbased semantics in context for genomics literature passage retrieval. In The Sixteenth Text REtrieval Conference (TREC 2007) Proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Zhuang</author>
<author>Feng Jing</author>
<author>Xiao yan Zhu</author>
<author>Lei Zhang</author>
</authors>
<title>Movie review mining and summarization.</title>
<date>2006</date>
<booktitle>In Proc. ACM Conference on Information and Knowledge Management (CIKM).</booktitle>
<contexts>
<context position="24596" citStr="Zhuang et al. (2006)" startWordPosition="3877" endWordPosition="3880">ides manually annotated data for information extraction in the biomedical domain and originally followed the Link Grammar scheme, Pyysalo et al. (2007a) developed a version of the corpus annotated with the SD scheme. They also made available a program and conversion rules that they used to transform Link Grammar relations into SD graphs, which were then hand-corrected (Pyysalo et al., 2007b). While a limited amount of gold standard annotated data was prepared for the Parser Evaluation Shared Task, this is the main source of gold-standard SD data which is currently available. In other domains, Zhuang et al. (2006) uses the representation to extract opinions about features in reviews and Meena and Prabhakar (2007) uses it to improve the quality of sentence-level sentiment analysis. The open information extraction system TEXTRUNNER (Banko et al., 2007) also makes use of the SD graph representation: its first module uses the Stanford parser and the dependency tool to automatically identify and label trustworthy and untrustworthy extractions. Even in theoretical linguistic work, SD has proven very useful: it has hugely facilitated data extraction from corpora, in the context of the NSF-funded project “Dyna</context>
</contexts>
<marker>Zhuang, Jing, Zhu, Zhang, 2006</marker>
<rawString>Zhuang, Li, Feng Jing, Xiao yan Zhu, and Lei Zhang. 2006. Movie review mining and summarization. In Proc. ACM Conference on Information and Knowledge Management (CIKM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amal Zouaq</author>
<author>Roger Nkambou</author>
<author>Claude Frasson</author>
</authors>
<title>The knowledge puzzle: An integrated approach of intelligent tutoring systems and knowledge management.</title>
<date>2006</date>
<booktitle>In Proceedings of the 18th IEEE International Conference on Tools with Artificial Intelligence (ICTAI2006),</booktitle>
<pages>575--582</pages>
<contexts>
<context position="14863" citStr="Zouaq et al., 2006" startWordPosition="2298" endWordPosition="2301">n the design has been to consistently have binary relations (DP1). All the dependencies form a triple: a grammatical relation holding between two words (head and dependent). This gives uniformity to the representation and renders it very readable, critical features for a usercentered design. Furthermore, all the information can be represented by a directed graph, enabling the creation of both a limpid visual representation for humans and a canonical data structure for software. Moreover, it maps straightforwardly on to semantic web representations such as OWL and RDF triples, as exploited in (Zouaq et al., 2006; Zouaq et al., 2007). This design choice limits the kind of information offered by the SD scheme. For instance, the PARC scheme contains much more information 3Without word position, the representation is deficient if the same word occurs more than once in a sentence. GR (passive based) (ncsubj based Bell obj) (ta bal Bell based) (iobj based in) (dobj in Angeles) (ncmod Angeles Los) (conj and makes) (conj and distributes) (conj and electronic) (conj and computer) (conj and building) (ncsubj and Bell ) (dobj and products) (ncmod products and) Figure 2: GR representation for Bell, based in Los </context>
</contexts>
<marker>Zouaq, Nkambou, Frasson, 2006</marker>
<rawString>Zouaq, Amal, Roger Nkambou, and Claude Frasson. 2006. The knowledge puzzle: An integrated approach of intelligent tutoring systems and knowledge management. In Proceedings of the 18th IEEE International Conference on Tools with Artificial Intelligence (ICTAI2006), pages 575–582.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amal Zouaq</author>
<author>Roger Nkambou</author>
<author>Claude Frasson</author>
</authors>
<title>Building domain ontologies from text for educational purposes.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second European Conference on Technology Enhanced Learning: Creating new</booktitle>
<contexts>
<context position="14884" citStr="Zouaq et al., 2007" startWordPosition="2302" endWordPosition="2305">n to consistently have binary relations (DP1). All the dependencies form a triple: a grammatical relation holding between two words (head and dependent). This gives uniformity to the representation and renders it very readable, critical features for a usercentered design. Furthermore, all the information can be represented by a directed graph, enabling the creation of both a limpid visual representation for humans and a canonical data structure for software. Moreover, it maps straightforwardly on to semantic web representations such as OWL and RDF triples, as exploited in (Zouaq et al., 2006; Zouaq et al., 2007). This design choice limits the kind of information offered by the SD scheme. For instance, the PARC scheme contains much more information 3Without word position, the representation is deficient if the same word occurs more than once in a sentence. GR (passive based) (ncsubj based Bell obj) (ta bal Bell based) (iobj based in) (dobj in Angeles) (ncmod Angeles Los) (conj and makes) (conj and distributes) (conj and electronic) (conj and computer) (conj and building) (ncsubj and Bell ) (dobj and products) (ncmod products and) Figure 2: GR representation for Bell, based in Los Angeles, makes and di</context>
</contexts>
<marker>Zouaq, Nkambou, Frasson, 2007</marker>
<rawString>Zouaq, Amal, Roger Nkambou, and Claude Frasson. 2007. Building domain ontologies from text for educational purposes. In Proceedings of the Second European Conference on Technology Enhanced Learning: Creating new learning experiences on a global scale.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>