<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001013">
<title confidence="0.921673">
Neighbors Help: Bilingual Unsupervised WSD Using Context
</title>
<author confidence="0.978291">
Sudha Bhingardive Samiulla Shaikh Pushpak Bhattacharyya
</author>
<affiliation confidence="0.836809">
Department of Computer Science and Engineering,
IIT Bombay, Powai,
</affiliation>
<address confidence="0.887462">
Mumbai, 400076.
</address>
<email confidence="0.999178">
{sudha,samiulla,pb}@cse.iitb.ac.in
</email>
<sectionHeader confidence="0.99459" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998146615384615">
Word Sense Disambiguation (WSD) is one
of the toughest problems in NLP, and in
WSD, verb disambiguation has proved to
be extremely difficult, because of high de-
gree of polysemy, too fine grained senses,
absence of deep verb hierarchy and low in-
ter annotator agreement in verb sense an-
notation. Unsupervised WSD has received
widespread attention, but has performed
poorly, specially on verbs. Recently an
unsupervised bilingual EM based algo-
rithm has been proposed, which makes
use only of the raw counts of the transla-
tions in comparable corpora (Marathi and
Hindi). But the performance of this ap-
proach is poor on verbs with accuracy
level at 25-38%. We suggest a modifica-
tion to this mentioned formulation, using
context and semantic relatedness of neigh-
boring words. An improvement of 17% -
35% in the accuracy of verb WSD is ob-
tained compared to the existing EM based
approach. On a general note, the work
can be looked upon as contributing to the
framework of unsupervised WSD through
context aware expectation maximization.
</bodyText>
<sectionHeader confidence="0.998881" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999939807692308">
The importance of unsupervised approaches in
WSD is well known, because they do not need
sense tagged corpus. In multilingual unsuper-
vised scenario, either comparable or parallel cor-
pora have been used by past researchers for disam-
biguation (Dagan et al., 1991; Diab and Resnik,
2002; Kaji and Morimoto, 2002; Specia et al.,
2005; Lefever and Hoste, 2010; Khapra et al.,
2011). Recent work by Khapra et al., (2011) has
shown that, in comparable corpora, sense distribu-
tion of a word in one language can be estimated
using the raw counts of translations of the target
words in the other language; such sense distribu-
tions contribute to the ranking of senses. Since
translations can themselves be ambiguous, Expec-
tation Maximization based formulation is used to
determine the sense frequencies. Using this ap-
proach every instance of a word is tagged with the
most probable sense according to the algorithm.
In the above formulation, no importance is
given to the context. That would do, had the ac-
curacy of disambiguation on verbs not been poor
25-35%. This motivated us to propose and inves-
tigate use of context in the formulation by Khapra
et al. (2011).
For example consider the sentence in chem-
istry domain, “Keep the beaker on the flat table.”
In this sentence, the target word ‘table’ will be
tagged as ‘the tabular array’ sense since it is dom-
inant in the chemistry domain by their algorithm.
But its actual sense is ‘a piece of furniture’ which
can be captured only if context is taken into con-
sideration. In our approach we tackle this problem
by taking into account the words from the context
of the target word. We use semantic relatedness
between translations of the target word and those
of its context words to determine its sense.
Verb disambiguation has proved to be extremely
difficult (Jean, 2004), because of high degree of
polysemy (Khapra et al., 2010), too fine grained
senses, absence of deep verb hierarchy and low in-
ter annotator agreement in verb sense annotation.
On the other hand, verb disambiguation is very
important for NLP applications like MT and IR.
Our approach has shown significant improvement
in verb accuracy as compared to Khapra’s (2011)
approach.
The roadmap of the paper is as follows. Sec-
tion 2 presents related work. Section 3 covers the
background work. Section 4 explains the modified
EM formulation using context and semantic relat-
edness. Section 5 presents the experimental setup.
</bodyText>
<page confidence="0.957075">
538
</page>
<bodyText confidence="0.63328">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 538–542,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
Results are presented in section 6. Section 7 cov- M-Step: X P(πL1 (SL2)|u) · #(u)
ers phenomena study and error analysis. Conclu- P(SL2|v) = U
sions and future work are given in the last section,
section 8.
</bodyText>
<sectionHeader confidence="0.998724" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.998713846153846">
Word Sense Disambiguation is one of the hard-
est problems in NLP. Successful supervised WSD
approaches (Lee et al., 2004; Ng and Lee, 1996)
are restricted to resource rich languages and do-
mains. They are directly dependent on availabil-
ity of good amount of sense tagged data. Creat-
ing such a costly resource for all language-domain
pairs is impracticable looking at the amount of
time and money required. Hence, unsupervised
WSD approaches (Diab and Resnik, 2002; Kaji
and Morimoto, 2002; Mihalcea et al., 2004; Jean,
2004; Khapra et al., 2011) attract most of the re-
searchers.
</bodyText>
<sectionHeader confidence="0.996679" genericHeader="method">
3 Background
</sectionHeader>
<bodyText confidence="0.99047895">
Khapra et al. (2011) dealt with bilingual unsuper-
vised WSD. It uses EM algorithm for estimating
sense distributions in comparable corpora. Ev-
ery polysemous word is disambiguated using the
raw counts of its translations in different senses.
Synset aligned multilingual dictionary (Mohanty
et al., 2008) is used for finding its translations.
In this dictionary, synsets are linked, and after
that the words inside the synsets are also linked.
For example, for the concept of ‘boy’, the Hindi
synset {ladakaa, balak, bachhaa} is linked with
the Marathi synset {mulagaa, poragaa, por}. The
Marathi word ‘mulagaa’ is linked to the Hindi
word ‘ladakaa’ which is its exact lexical substi-
tution.
Suppose words u in language L1 and v in lan-
guage L2 are translations of each other and their
senses are required. The EM based formulation is
as follows:
E-Step:
</bodyText>
<equation confidence="0.994912176470588">
X P(πL2 (SL1)|v) · #(v)
V
X X P(πL2 (SL1
i )|x) · #(x)
i
SL1 x
where, SL1 iE synsetsL1(u)
v E crosslinksL2(u, SL1)
x E crosslinksL2(u, SL1
i )
P(πL1 (SL2
i )|y) · #(y)
where, SL2
i E synsetsL2(v)
u E crosslinksL1(v, SL2)
y E crosslinksL1(v, SL2
i )
</equation>
<bodyText confidence="0.805728">
Here,
</bodyText>
<listItem confidence="0.988182333333333">
• ‘#’ indicates the raw count.
• crosslinksL1(a, SL2) is the set of possible
translations of the word ‘a’ from language L1
to L2 in the sense SL2.
• πL2 (SL1) means the linked synset of the
sense SL1 in L2.
</listItem>
<bodyText confidence="0.98084472">
E and M steps are symmetric except for the
change in language. In both the steps, we esti-
mate sense distribution in one language using raw
counts of translations in another language. But
this approach has following limitations:
Poor performance on verbs: This approach gives
poor performance on verbs (25%-38%). See sec-
tion 6.
Same sense throughout the corpus: Every oc-
currence of a word is tagged with the single sense
found by the algorithm, throughout the corpus.
Closed loop of translations: This formulation
does not work for some common words which
have the same translations in all senses. For ex-
ample, the verb ‘karna’ in Hindi has two differ-
ent senses in the corpus viz., ‘to do’ (S1) and ‘to
make’ (S2). In both these senses, it gets trans-
lated as ‘karne’ in Marathi. The word ‘karne’ also
back translates to ‘karna’ in Hindi through both its
senses. In this case, the formulation works out as
follows:
The probabilities are initialized uniformly.
Hence, P(S1|karna) = P(S2|karna) = 0.5.
Now, in first iteration the sense of ‘karne’ will be
estimated as follows (E-step):
</bodyText>
<equation confidence="0.979270066666666">
P(S1|karna) ∗ #(karna)
P(S1|karne) =
#(karna)
= 0.5,
P(SL1|u) =
X
SL2
i
X
Y
539
P(S2|karna) ∗ #(karna)
P(S2|karne) =
#(karna)
= 0.5
</equation>
<bodyText confidence="0.998223285714286">
Similarly, in M-step, we will get P(S1|karna) =
P(S2|karna) = 0.5. Eventually, it will end up
with initial probabilities and no strong decision
can be made.
To address these problems we have introduced
contextual clues in their formulation by using se-
mantic relatedness.
</bodyText>
<sectionHeader confidence="0.990023" genericHeader="method">
4 Modified Bilingual EM approach
</sectionHeader>
<bodyText confidence="0.999955">
We introduce context in the EM formulation stated
above and treat the context as a bag of words. We
assume that each word in the context influences
the sense of the target word independently. Hence,
</bodyText>
<equation confidence="0.9933265">
p(S|w, C) = � p(S|w, ci)
ci∈C
</equation>
<bodyText confidence="0.999527166666667">
where, w is the target word, S is one of the candi-
date synsets of w, C is the set of words in context
(sentence in our case) and ci is one of the context
words.
Suppose we would have sense tagged data,
p(S|w, c) could have been computed as:
</bodyText>
<equation confidence="0.965748">
p(S|w, c) = #(S, w, c)
#(w, c)
</equation>
<bodyText confidence="0.971203833333333">
But since the sense tagged corpus is not avail-
able, we cannot find #(S, w, c) from the corpus
directly. However, we can estimate it using the
comparable corpus in other language. Here, we
assume that given a word and its context word
in language L1, the sense distribution in L1 will
be same as that in L2 given the translation of a
word and the translation of its context word in L2.
But these translations can be ambiguous, hence
we can use Expectation Maximization approach
similar to (Khapra et al., 2011) as follows:
E-Step:
</bodyText>
<equation confidence="0.987760727272727">
� P(7rL2 (SL1)|v, b) · Q(v, b)
P(SL1|u, a) = v,b
P(7rL2 (SL1
i )|x, b) · Q(x, b)
where, SL1
i ∈ synsetsL1(u)
a ∈ context(u)
v ∈ crosslinksL2(u, SL1)
b ∈ crosslinksL2(a)
x ∈ crosslinksL2(u, SL1
i )
</equation>
<bodyText confidence="0.999280083333333">
crosslinksL1(a) is the set of all possible transla-
tions of the word ‘a’ from L1 to L2 in all its senses.
Q(v, b) is the semantic relatedness between the
senses of v and senses of b. Since, v and b go over
all possible translations of u and a respectively.
Q(v, b) has the effect of indirectly capturing the
semantic similarity between the senses of u and
a. A symetric formulation in the M-step below
takes the computation back from language L2 to
language L1. The semantic relatedness comes as
an additional weighing factor, capturing context,
in the probablistic score.
</bodyText>
<equation confidence="0.959275583333333">
M-Step:
� P(7rL1 (SL2)|u, a) · Q(u, a)
P(SL2|v, b) = u,a
P(7rL1 (SL2
i )|y, a) · Q(y, a)
where, SL2
i ∈ synsetsL2(v)
b ∈ context(v)
u ∈ crosslinksL1(v, SL2)
a ∈ crosslinksL1(b)
y ∈ crosslinksL1(v, SL2
i )
</equation>
<bodyText confidence="0.95471975">
Q(u, a) is the semantic relatedness between the
senses of u and senses of a and contributes to the
score like Q(v, b).
Note how the computation moves back and
forth between L1 and L2 considering translations
of both target words and their context words.
In the above formulation, we could have con-
sidered the term #(word, context word) (i.e.,
the co-occurrence count of the translations of
the word and the context word) instead of
Q(word, context word). But it is very unlikely
that every translation of a word will co-occur with
</bodyText>
<figure confidence="0.9939897">
�
SL1
i
�
x,b
�
SL2
i
�
y,b
</figure>
<page confidence="0.978334">
540
</page>
<table confidence="0.997947666666667">
Algorithm HIN-HEALTH MAR-HEALTH
NOUN ADV ADJ VERB Overall NOUN ADV ADJ VERB Overall
EM-C 59.82 67.80 56.66 60.38 59.63 62.90 62.54 53.63 52.49 59.77
EM 60.68 67.48 55.54 25.29 58.16 63.88 58.88 55.71 35.60 58.03
WFS 53.49 73.24 55.16 38.64 54.46 59.35 67.32 38.12 34.91 52.57
RB 32.52 45.08 35.42 17.93 33.31 33.83 38.76 37.68 18.49 32.45
</table>
<tableCaption confidence="0.997803">
Table 1: Comparison(F-Score) of EM-C and EM for Health domain
</tableCaption>
<table confidence="0.999693">
Algorithm HIN-TOURISM MAR-TOURISM
NOUN ADV ADJ VERB Overall NOUN ADV ADJ VERB Overall
EM-C 62.78 65.10 54.67 55.24 60.70 59.08 63.66 58.02 55.23 58.67
EM 61.16 62.31 56.02 31.85 57.92 59.66 62.15 58.42 38.33 56.90
WFS 63.98 75.94 52.72 36.29 60.22 61.95 62.39 48.29 46.56 57.47
RB 32.46 42.56 36.35 18.29 32.68 33.93 39.30 37.49 15.99 32.65
</table>
<tableCaption confidence="0.999774">
Table 2: Comparison(F-Score) of EM-C and EM for Tourism domain
</tableCaption>
<bodyText confidence="0.998791">
every translation of its context word considerable
number of times. This term may make sense only
if we have arbitrarily large comparable corpus in
the other language.
</bodyText>
<subsectionHeader confidence="0.999829">
4.1 Computation of semantic relatedness
</subsectionHeader>
<bodyText confidence="0.9999905">
The semantic relatedness is computed by taking
the inverse of the length of the shortest path among
two senses in the wordnet graph (Pedersen et al.,
2005). All the semantic relations (including cross-
part-of-speech links) viz., hypernymy, hyponymy,
meronymy, entailment, attribute etc., are used for
computing the semantic relatedness.
Sense scores thus obtained are used to disam-
biguate all words in the corpus. We consider all
the content words from the context for disam-
biguation of a word. The winner sense is the one
with the highest probability.
</bodyText>
<sectionHeader confidence="0.991551" genericHeader="method">
5 Experimental setup
</sectionHeader>
<bodyText confidence="0.9999295">
We have used freely available in-domain compa-
rable corpora1 in Hindi and Marathi languages.
These corpora are available for health and tourism
domains. The dataset is same as that used in
(Khapra et al., 2011) in order to compare the per-
formance.
</bodyText>
<sectionHeader confidence="0.99985" genericHeader="method">
6 Results
</sectionHeader>
<bodyText confidence="0.994196">
Table 1 and Table 2 compare the performance of
the following two approaches:
</bodyText>
<listItem confidence="0.99786025">
1. EM-C (EM with Context): Our modified ap-
proach explained in section 4.
2. EM: Basic EM based approach by Khapra et
al., (2011).
</listItem>
<footnote confidence="0.89625">
1http://www.cfilt.iitb.ac.in/wsd/annotated corpus/
</footnote>
<listItem confidence="0.995591">
3. WFS: Wordnet First Sense baseline.
4. RB: Random baseline.
</listItem>
<bodyText confidence="0.999713">
Results clearly show that EM-C outperforms EM
especially in case of verbs in all language-domain
pairs. In health domain, verb accuracy is increased
by 35% for Hindi and 17% for Marathi, while in
tourism domain, it is increased by 23% for Hindi
and 17% for Marathi. The overall accuracy is in-
creased by (1.8-2.8%) for health domain and (1.5-
1.7%) for tourism domain. Since there are less
number of verbs, the improved accuracy is not di-
rectly reflected in the overall performance.
</bodyText>
<sectionHeader confidence="0.705652" genericHeader="method">
7 Error analysis and phenomena study
</sectionHeader>
<bodyText confidence="0.9836795">
Our approach tags all the instances of a word de-
pending on its context as apposed to basic EM ap-
proach. For example, consider the following sen-
tence from the tourism domain:
vh p•� х�l rh� T�।
(vaha patte khel rahe the)
(They were playing cards/leaves)
Here, the word p•~ (plural form of p•A) has two
senses viz., ‘leaf’ and ‘playing card’. In tourism
domain, the ‘leaf’ sense is more dominant. Hence,
basic EM will tag p•~ with ‘leaf’ sense. But it’s
true sense is ‘playing card’. The true sense is cap-
tured only if context is considered. Here, the word
х�lnA (to play) (root form of х�l) endorses the
‘playing card’ sense of the word p•A. This phe-
nomenon is captured by our approach through se-
mantic relatedness.
But there are certain cases where our algorithm
fails. For example, consider the following sen-
tence:
</bodyText>
<page confidence="0.986028">
541
</page>
<bodyText confidence="0.974998611111111">
vh p�X к� Enc~ p•~ х�l rh� T�।
(vaha ped ke niche patte khel rahe the)
(They were playing cards/leaves below the tree)
Here, two strong context words p�X (tree) and
х�l (play) are influencing the sense of the word
p•�. Semantic relatedness between p�X (tree) and
p•A (leaf) is more than that of х�l (play) and p•A
(playing card). Hence, the ‘leaf sense’ is assigned
to p•A.
This problem occurred because we considered
the context as a bag of words. This problem can
be solved by considering the semantic structure
of the sentence. In this example, the word p•A
(leaf/playing card) is the subject of the verb х�lnA
(to play) while p�X (tree) is not even in the same
clause with p•A (leaf/playing cards). Thus we
could consider х�lnA (to play) as the stronger clue
for its disambiguation.
</bodyText>
<sectionHeader confidence="0.987923" genericHeader="conclusions">
8 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999975866666667">
We have presented a context aware EM formula-
tion building on the framework of Khapra et al
(2011). Our formulation solves the problems of
“inhibited progress due to lack of translation diver-
sity” and “uniform sense assignment, irrespective
of context” that the previous EM based formula-
tion of Khapra et al. suffers from. More impor-
tantly our accuracy on verbs is much higher and
more than the state of the art, to the best of our
knowledge. Improving the performance on other
parts of speech is the primary future work. Fu-
ture directions also point to usage of semantic role
clues, investigation of familialy apart pair of lan-
guages and effect of variation of measures of se-
mantic relatedness.
</bodyText>
<sectionHeader confidence="0.997386" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998735685714286">
Ido Dagan, Alon Itai, and Ulrike Schwall. 1991. Two
languages are more informative than one. In Dou-
glas E. Appelt, editor, ACL, pages 130–137. ACL.
Mona Diab and Philip Resnik. 2002. An unsupervised
method for word sense tagging using parallel cor-
pora. In Proceedings of the 40th Annual Meeting
on Association for Computational Linguistics, ACL
’02, pages 255–262, Morristown, NJ, USA. Associ-
ation for Computational Linguistics.
V´eronis Jean. 2004. Hyperlex: Lexical cartography
for information retrieval. In Computer Speech and
Language, pages 18(3):223–252.
Hiroyuki Kaji and Yasutsugu Morimoto. 2002. Unsu-
pervised word sense disambiguation using bilingual
comparable corpora. In Proceedings of the 19th in-
ternational conference on Computational linguistics
- Volume 1, COLING ’02, pages 1–7, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
Mitesh M. Khapra, Anup Kulkarni, Saurabh Sohoney,
and Pushpak Bhattacharyya. 2010. All words do-
main adapted wsd: Finding a middle ground be-
tween supervision and unsupervision. In Jan Ha-
jic, Sandra Carberry, and Stephen Clark, editors,
ACL, pages 1532–1541. The Association for Com-
puter Linguistics.
Mitesh M Khapra, Salil Joshi, and Pushpak Bhat-
tacharyya. 2011. It takes two to tango: A bilingual
unsupervised approach for estimating sense distribu-
tions using expectation maximization. In Proceed-
ings of 5th International Joint Conference on Nat-
ural Language Processing, pages 695–704, Chiang
Mai, Thailand, November. Asian Federation of Nat-
ural Language Processing.
K. Yoong Lee, Hwee T. Ng, and Tee K. Chia. 2004.
Supervised word sense disambiguation with support
vector machines and multiple knowledge sources.
In Proceedings of Senseval-3: Third International
Workshop on the Evaluation of Systems for the Se-
mantic Analysis of Text, pages 137–140.
Els Lefever and Veronique Hoste. 2010. Semeval-
2010 task 3: cross-lingual word sense disambigua-
tion. In Katrin Erk and Carlo Strapparava, editors,
SemEval 2010 : 5th International workshop on Se-
mantic Evaluation : proceedings of the workshop,
pages 15–20. ACL.
Rada Mihalcea, Paul Tarau, and Elizabeth Figa. 2004.
Pagerank on semantic networks, with application to
word sense disambiguation. In COLING.
Rajat Mohanty, Pushpak Bhattacharyya, Prabhakar
Pande, Shraddha Kalele, Mitesh Khapra, and Aditya
Sharma. 2008. Synset based multilingual dic-
tionary: Insights, applications and challenges. In
Global Wordnet Conference.
Hwee Tou Ng and Hian Beng Lee. 1996. Integrating
multiple knowledge sources to disambiguate word
sense: an exemplar-based approach. In Proceedings
of the 34th annual meeting on Association for Com-
putational Linguistics, pages 40–47, Morristown,
NJ, USA. ACL.
T. Pedersen, S. Banerjee, and S. Patwardhan. 2005.
Maximizing Semantic Relatedness to Perform Word
Sense Disambiguation. Research Report UMSI
2005/25, University of Minnesota Supercomputing
Institute, March.
Lucia Specia, Maria Das Grac¸as, Volpe Nunes, and
Mark Stevenson. 2005. Exploiting parallel texts to
produce a multilingual sense tagged corpus for word
sense disambiguation. In In Proceedings ofRANLP-
05, Borovets, pages 525–531.
</reference>
<page confidence="0.997387">
542
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.926008">
<title confidence="0.99931">Bilingual Unsupervised WSD Using Context</title>
<author confidence="0.99621">Sudha Bhingardive Samiulla Shaikh Pushpak</author>
<affiliation confidence="0.997345">Department of Computer Science and IIT Bombay,</affiliation>
<address confidence="0.940443">Mumbai,</address>
<abstract confidence="0.999760518518518">Word Sense Disambiguation (WSD) is one of the toughest problems in NLP, and in WSD, verb disambiguation has proved to be extremely difficult, because of high degree of polysemy, too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation. Unsupervised WSD has received widespread attention, but has performed poorly, specially on verbs. Recently an unsupervised bilingual EM based algorithm has been proposed, which makes use only of the raw counts of the translations in comparable corpora (Marathi and Hindi). But the performance of this approach is poor on verbs with accuracy level at 25-38%. We suggest a modification to this mentioned formulation, using context and semantic relatedness of neighboring words. An improvement of 17% - 35% in the accuracy of verb WSD is obtained compared to the existing EM based approach. On a general note, the work can be looked upon as contributing to the framework of unsupervised WSD through context aware expectation maximization.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Alon Itai</author>
<author>Ulrike Schwall</author>
</authors>
<title>Two languages are more informative than one.</title>
<date>1991</date>
<pages>130--137</pages>
<editor>In Douglas E. Appelt, editor, ACL,</editor>
<publisher>ACL.</publisher>
<contexts>
<context position="1545" citStr="Dagan et al., 1991" startWordPosition="237" endWordPosition="240">entioned formulation, using context and semantic relatedness of neighboring words. An improvement of 17% - 35% in the accuracy of verb WSD is obtained compared to the existing EM based approach. On a general note, the work can be looked upon as contributing to the framework of unsupervised WSD through context aware expectation maximization. 1 Introduction The importance of unsupervised approaches in WSD is well known, because they do not need sense tagged corpus. In multilingual unsupervised scenario, either comparable or parallel corpora have been used by past researchers for disambiguation (Dagan et al., 1991; Diab and Resnik, 2002; Kaji and Morimoto, 2002; Specia et al., 2005; Lefever and Hoste, 2010; Khapra et al., 2011). Recent work by Khapra et al., (2011) has shown that, in comparable corpora, sense distribution of a word in one language can be estimated using the raw counts of translations of the target words in the other language; such sense distributions contribute to the ranking of senses. Since translations can themselves be ambiguous, Expectation Maximization based formulation is used to determine the sense frequencies. Using this approach every instance of a word is tagged with the mos</context>
</contexts>
<marker>Dagan, Itai, Schwall, 1991</marker>
<rawString>Ido Dagan, Alon Itai, and Ulrike Schwall. 1991. Two languages are more informative than one. In Douglas E. Appelt, editor, ACL, pages 130–137. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Philip Resnik</author>
</authors>
<title>An unsupervised method for word sense tagging using parallel corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>255--262</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="1568" citStr="Diab and Resnik, 2002" startWordPosition="241" endWordPosition="244">, using context and semantic relatedness of neighboring words. An improvement of 17% - 35% in the accuracy of verb WSD is obtained compared to the existing EM based approach. On a general note, the work can be looked upon as contributing to the framework of unsupervised WSD through context aware expectation maximization. 1 Introduction The importance of unsupervised approaches in WSD is well known, because they do not need sense tagged corpus. In multilingual unsupervised scenario, either comparable or parallel corpora have been used by past researchers for disambiguation (Dagan et al., 1991; Diab and Resnik, 2002; Kaji and Morimoto, 2002; Specia et al., 2005; Lefever and Hoste, 2010; Khapra et al., 2011). Recent work by Khapra et al., (2011) has shown that, in comparable corpora, sense distribution of a word in one language can be estimated using the raw counts of translations of the target words in the other language; such sense distributions contribute to the ranking of senses. Since translations can themselves be ambiguous, Expectation Maximization based formulation is used to determine the sense frequencies. Using this approach every instance of a word is tagged with the most probable sense accord</context>
<context position="4589" citStr="Diab and Resnik, 2002" startWordPosition="743" endWordPosition="746">πL1 (SL2)|u) · #(u) ers phenomena study and error analysis. Conclu- P(SL2|v) = U sions and future work are given in the last section, section 8. 2 Related work Word Sense Disambiguation is one of the hardest problems in NLP. Successful supervised WSD approaches (Lee et al., 2004; Ng and Lee, 1996) are restricted to resource rich languages and domains. They are directly dependent on availability of good amount of sense tagged data. Creating such a costly resource for all language-domain pairs is impracticable looking at the amount of time and money required. Hence, unsupervised WSD approaches (Diab and Resnik, 2002; Kaji and Morimoto, 2002; Mihalcea et al., 2004; Jean, 2004; Khapra et al., 2011) attract most of the researchers. 3 Background Khapra et al. (2011) dealt with bilingual unsupervised WSD. It uses EM algorithm for estimating sense distributions in comparable corpora. Every polysemous word is disambiguated using the raw counts of its translations in different senses. Synset aligned multilingual dictionary (Mohanty et al., 2008) is used for finding its translations. In this dictionary, synsets are linked, and after that the words inside the synsets are also linked. For example, for the concept o</context>
</contexts>
<marker>Diab, Resnik, 2002</marker>
<rawString>Mona Diab and Philip Resnik. 2002. An unsupervised method for word sense tagging using parallel corpora. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02, pages 255–262, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V´eronis Jean</author>
</authors>
<title>Hyperlex: Lexical cartography for information retrieval.</title>
<date>2004</date>
<booktitle>In Computer Speech and Language,</booktitle>
<pages>18--3</pages>
<contexts>
<context position="3098" citStr="Jean, 2004" startWordPosition="505" endWordPosition="506">domain, “Keep the beaker on the flat table.” In this sentence, the target word ‘table’ will be tagged as ‘the tabular array’ sense since it is dominant in the chemistry domain by their algorithm. But its actual sense is ‘a piece of furniture’ which can be captured only if context is taken into consideration. In our approach we tackle this problem by taking into account the words from the context of the target word. We use semantic relatedness between translations of the target word and those of its context words to determine its sense. Verb disambiguation has proved to be extremely difficult (Jean, 2004), because of high degree of polysemy (Khapra et al., 2010), too fine grained senses, absence of deep verb hierarchy and low inter annotator agreement in verb sense annotation. On the other hand, verb disambiguation is very important for NLP applications like MT and IR. Our approach has shown significant improvement in verb accuracy as compared to Khapra’s (2011) approach. The roadmap of the paper is as follows. Section 2 presents related work. Section 3 covers the background work. Section 4 explains the modified EM formulation using context and semantic relatedness. Section 5 presents the expe</context>
<context position="4649" citStr="Jean, 2004" startWordPosition="755" endWordPosition="756">L2|v) = U sions and future work are given in the last section, section 8. 2 Related work Word Sense Disambiguation is one of the hardest problems in NLP. Successful supervised WSD approaches (Lee et al., 2004; Ng and Lee, 1996) are restricted to resource rich languages and domains. They are directly dependent on availability of good amount of sense tagged data. Creating such a costly resource for all language-domain pairs is impracticable looking at the amount of time and money required. Hence, unsupervised WSD approaches (Diab and Resnik, 2002; Kaji and Morimoto, 2002; Mihalcea et al., 2004; Jean, 2004; Khapra et al., 2011) attract most of the researchers. 3 Background Khapra et al. (2011) dealt with bilingual unsupervised WSD. It uses EM algorithm for estimating sense distributions in comparable corpora. Every polysemous word is disambiguated using the raw counts of its translations in different senses. Synset aligned multilingual dictionary (Mohanty et al., 2008) is used for finding its translations. In this dictionary, synsets are linked, and after that the words inside the synsets are also linked. For example, for the concept of ‘boy’, the Hindi synset {ladakaa, balak, bachhaa} is linke</context>
</contexts>
<marker>Jean, 2004</marker>
<rawString>V´eronis Jean. 2004. Hyperlex: Lexical cartography for information retrieval. In Computer Speech and Language, pages 18(3):223–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyuki Kaji</author>
<author>Yasutsugu Morimoto</author>
</authors>
<title>Unsupervised word sense disambiguation using bilingual comparable corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th international conference on Computational linguistics - Volume 1, COLING ’02,</booktitle>
<pages>1--7</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1593" citStr="Kaji and Morimoto, 2002" startWordPosition="245" endWordPosition="248">antic relatedness of neighboring words. An improvement of 17% - 35% in the accuracy of verb WSD is obtained compared to the existing EM based approach. On a general note, the work can be looked upon as contributing to the framework of unsupervised WSD through context aware expectation maximization. 1 Introduction The importance of unsupervised approaches in WSD is well known, because they do not need sense tagged corpus. In multilingual unsupervised scenario, either comparable or parallel corpora have been used by past researchers for disambiguation (Dagan et al., 1991; Diab and Resnik, 2002; Kaji and Morimoto, 2002; Specia et al., 2005; Lefever and Hoste, 2010; Khapra et al., 2011). Recent work by Khapra et al., (2011) has shown that, in comparable corpora, sense distribution of a word in one language can be estimated using the raw counts of translations of the target words in the other language; such sense distributions contribute to the ranking of senses. Since translations can themselves be ambiguous, Expectation Maximization based formulation is used to determine the sense frequencies. Using this approach every instance of a word is tagged with the most probable sense according to the algorithm. In </context>
<context position="4614" citStr="Kaji and Morimoto, 2002" startWordPosition="747" endWordPosition="750"> phenomena study and error analysis. Conclu- P(SL2|v) = U sions and future work are given in the last section, section 8. 2 Related work Word Sense Disambiguation is one of the hardest problems in NLP. Successful supervised WSD approaches (Lee et al., 2004; Ng and Lee, 1996) are restricted to resource rich languages and domains. They are directly dependent on availability of good amount of sense tagged data. Creating such a costly resource for all language-domain pairs is impracticable looking at the amount of time and money required. Hence, unsupervised WSD approaches (Diab and Resnik, 2002; Kaji and Morimoto, 2002; Mihalcea et al., 2004; Jean, 2004; Khapra et al., 2011) attract most of the researchers. 3 Background Khapra et al. (2011) dealt with bilingual unsupervised WSD. It uses EM algorithm for estimating sense distributions in comparable corpora. Every polysemous word is disambiguated using the raw counts of its translations in different senses. Synset aligned multilingual dictionary (Mohanty et al., 2008) is used for finding its translations. In this dictionary, synsets are linked, and after that the words inside the synsets are also linked. For example, for the concept of ‘boy’, the Hindi synset</context>
</contexts>
<marker>Kaji, Morimoto, 2002</marker>
<rawString>Hiroyuki Kaji and Yasutsugu Morimoto. 2002. Unsupervised word sense disambiguation using bilingual comparable corpora. In Proceedings of the 19th international conference on Computational linguistics - Volume 1, COLING ’02, pages 1–7, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitesh M Khapra</author>
<author>Anup Kulkarni</author>
</authors>
<title>Saurabh Sohoney, and Pushpak Bhattacharyya.</title>
<date>2010</date>
<pages>1532--1541</pages>
<editor>In Jan Hajic, Sandra Carberry, and Stephen Clark, editors, ACL,</editor>
<publisher>The Association for Computer Linguistics.</publisher>
<marker>Khapra, Kulkarni, 2010</marker>
<rawString>Mitesh M. Khapra, Anup Kulkarni, Saurabh Sohoney, and Pushpak Bhattacharyya. 2010. All words domain adapted wsd: Finding a middle ground between supervision and unsupervision. In Jan Hajic, Sandra Carberry, and Stephen Clark, editors, ACL, pages 1532–1541. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitesh M Khapra</author>
<author>Salil Joshi</author>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>It takes two to tango: A bilingual unsupervised approach for estimating sense distributions using expectation maximization.</title>
<date>2011</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>695--704</pages>
<location>Chiang Mai, Thailand,</location>
<contexts>
<context position="1661" citStr="Khapra et al., 2011" startWordPosition="257" endWordPosition="260">the accuracy of verb WSD is obtained compared to the existing EM based approach. On a general note, the work can be looked upon as contributing to the framework of unsupervised WSD through context aware expectation maximization. 1 Introduction The importance of unsupervised approaches in WSD is well known, because they do not need sense tagged corpus. In multilingual unsupervised scenario, either comparable or parallel corpora have been used by past researchers for disambiguation (Dagan et al., 1991; Diab and Resnik, 2002; Kaji and Morimoto, 2002; Specia et al., 2005; Lefever and Hoste, 2010; Khapra et al., 2011). Recent work by Khapra et al., (2011) has shown that, in comparable corpora, sense distribution of a word in one language can be estimated using the raw counts of translations of the target words in the other language; such sense distributions contribute to the ranking of senses. Since translations can themselves be ambiguous, Expectation Maximization based formulation is used to determine the sense frequencies. Using this approach every instance of a word is tagged with the most probable sense according to the algorithm. In the above formulation, no importance is given to the context. That w</context>
<context position="4671" citStr="Khapra et al., 2011" startWordPosition="757" endWordPosition="760">ons and future work are given in the last section, section 8. 2 Related work Word Sense Disambiguation is one of the hardest problems in NLP. Successful supervised WSD approaches (Lee et al., 2004; Ng and Lee, 1996) are restricted to resource rich languages and domains. They are directly dependent on availability of good amount of sense tagged data. Creating such a costly resource for all language-domain pairs is impracticable looking at the amount of time and money required. Hence, unsupervised WSD approaches (Diab and Resnik, 2002; Kaji and Morimoto, 2002; Mihalcea et al., 2004; Jean, 2004; Khapra et al., 2011) attract most of the researchers. 3 Background Khapra et al. (2011) dealt with bilingual unsupervised WSD. It uses EM algorithm for estimating sense distributions in comparable corpora. Every polysemous word is disambiguated using the raw counts of its translations in different senses. Synset aligned multilingual dictionary (Mohanty et al., 2008) is used for finding its translations. In this dictionary, synsets are linked, and after that the words inside the synsets are also linked. For example, for the concept of ‘boy’, the Hindi synset {ladakaa, balak, bachhaa} is linked with the Marathi syn</context>
<context position="8558" citStr="Khapra et al., 2011" startWordPosition="1444" endWordPosition="1447">Suppose we would have sense tagged data, p(S|w, c) could have been computed as: p(S|w, c) = #(S, w, c) #(w, c) But since the sense tagged corpus is not available, we cannot find #(S, w, c) from the corpus directly. However, we can estimate it using the comparable corpus in other language. Here, we assume that given a word and its context word in language L1, the sense distribution in L1 will be same as that in L2 given the translation of a word and the translation of its context word in L2. But these translations can be ambiguous, hence we can use Expectation Maximization approach similar to (Khapra et al., 2011) as follows: E-Step: � P(7rL2 (SL1)|v, b) · Q(v, b) P(SL1|u, a) = v,b P(7rL2 (SL1 i )|x, b) · Q(x, b) where, SL1 i ∈ synsetsL1(u) a ∈ context(u) v ∈ crosslinksL2(u, SL1) b ∈ crosslinksL2(a) x ∈ crosslinksL2(u, SL1 i ) crosslinksL1(a) is the set of all possible translations of the word ‘a’ from L1 to L2 in all its senses. Q(v, b) is the semantic relatedness between the senses of v and senses of b. Since, v and b go over all possible translations of u and a respectively. Q(v, b) has the effect of indirectly capturing the semantic similarity between the senses of u and a. A symetric formulation i</context>
<context position="11911" citStr="Khapra et al., 2011" startWordPosition="2023" endWordPosition="2026">he semantic relations (including crosspart-of-speech links) viz., hypernymy, hyponymy, meronymy, entailment, attribute etc., are used for computing the semantic relatedness. Sense scores thus obtained are used to disambiguate all words in the corpus. We consider all the content words from the context for disambiguation of a word. The winner sense is the one with the highest probability. 5 Experimental setup We have used freely available in-domain comparable corpora1 in Hindi and Marathi languages. These corpora are available for health and tourism domains. The dataset is same as that used in (Khapra et al., 2011) in order to compare the performance. 6 Results Table 1 and Table 2 compare the performance of the following two approaches: 1. EM-C (EM with Context): Our modified approach explained in section 4. 2. EM: Basic EM based approach by Khapra et al., (2011). 1http://www.cfilt.iitb.ac.in/wsd/annotated corpus/ 3. WFS: Wordnet First Sense baseline. 4. RB: Random baseline. Results clearly show that EM-C outperforms EM especially in case of verbs in all language-domain pairs. In health domain, verb accuracy is increased by 35% for Hindi and 17% for Marathi, while in tourism domain, it is increased by 2</context>
<context position="14531" citStr="Khapra et al (2011)" startWordPosition="2477" endWordPosition="2480"> х�l (play) and p•A (playing card). Hence, the ‘leaf sense’ is assigned to p•A. This problem occurred because we considered the context as a bag of words. This problem can be solved by considering the semantic structure of the sentence. In this example, the word p•A (leaf/playing card) is the subject of the verb х�lnA (to play) while p�X (tree) is not even in the same clause with p•A (leaf/playing cards). Thus we could consider х�lnA (to play) as the stronger clue for its disambiguation. 8 Conclusion and Future Work We have presented a context aware EM formulation building on the framework of Khapra et al (2011). Our formulation solves the problems of “inhibited progress due to lack of translation diversity” and “uniform sense assignment, irrespective of context” that the previous EM based formulation of Khapra et al. suffers from. More importantly our accuracy on verbs is much higher and more than the state of the art, to the best of our knowledge. Improving the performance on other parts of speech is the primary future work. Future directions also point to usage of semantic role clues, investigation of familialy apart pair of languages and effect of variation of measures of semantic relatedness. Re</context>
</contexts>
<marker>Khapra, Joshi, Bhattacharyya, 2011</marker>
<rawString>Mitesh M Khapra, Salil Joshi, and Pushpak Bhattacharyya. 2011. It takes two to tango: A bilingual unsupervised approach for estimating sense distributions using expectation maximization. In Proceedings of 5th International Joint Conference on Natural Language Processing, pages 695–704, Chiang Mai, Thailand, November. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yoong Lee</author>
<author>Hwee T Ng</author>
<author>Tee K Chia</author>
</authors>
<title>Supervised word sense disambiguation with support vector machines and multiple knowledge sources.</title>
<date>2004</date>
<booktitle>In Proceedings of Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text,</booktitle>
<pages>137--140</pages>
<contexts>
<context position="4247" citStr="Lee et al., 2004" startWordPosition="687" endWordPosition="690">using context and semantic relatedness. Section 5 presents the experimental setup. 538 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 538–542, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Results are presented in section 6. Section 7 cov- M-Step: X P(πL1 (SL2)|u) · #(u) ers phenomena study and error analysis. Conclu- P(SL2|v) = U sions and future work are given in the last section, section 8. 2 Related work Word Sense Disambiguation is one of the hardest problems in NLP. Successful supervised WSD approaches (Lee et al., 2004; Ng and Lee, 1996) are restricted to resource rich languages and domains. They are directly dependent on availability of good amount of sense tagged data. Creating such a costly resource for all language-domain pairs is impracticable looking at the amount of time and money required. Hence, unsupervised WSD approaches (Diab and Resnik, 2002; Kaji and Morimoto, 2002; Mihalcea et al., 2004; Jean, 2004; Khapra et al., 2011) attract most of the researchers. 3 Background Khapra et al. (2011) dealt with bilingual unsupervised WSD. It uses EM algorithm for estimating sense distributions in comparable</context>
</contexts>
<marker>Lee, Ng, Chia, 2004</marker>
<rawString>K. Yoong Lee, Hwee T. Ng, and Tee K. Chia. 2004. Supervised word sense disambiguation with support vector machines and multiple knowledge sources. In Proceedings of Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, pages 137–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Els Lefever</author>
<author>Veronique Hoste</author>
</authors>
<title>Semeval2010 task 3: cross-lingual word sense disambiguation.</title>
<date>2010</date>
<booktitle>In Katrin Erk and Carlo Strapparava, editors, SemEval 2010 : 5th International workshop on Semantic Evaluation : proceedings of the workshop,</booktitle>
<pages>15--20</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="1639" citStr="Lefever and Hoste, 2010" startWordPosition="253" endWordPosition="256">rovement of 17% - 35% in the accuracy of verb WSD is obtained compared to the existing EM based approach. On a general note, the work can be looked upon as contributing to the framework of unsupervised WSD through context aware expectation maximization. 1 Introduction The importance of unsupervised approaches in WSD is well known, because they do not need sense tagged corpus. In multilingual unsupervised scenario, either comparable or parallel corpora have been used by past researchers for disambiguation (Dagan et al., 1991; Diab and Resnik, 2002; Kaji and Morimoto, 2002; Specia et al., 2005; Lefever and Hoste, 2010; Khapra et al., 2011). Recent work by Khapra et al., (2011) has shown that, in comparable corpora, sense distribution of a word in one language can be estimated using the raw counts of translations of the target words in the other language; such sense distributions contribute to the ranking of senses. Since translations can themselves be ambiguous, Expectation Maximization based formulation is used to determine the sense frequencies. Using this approach every instance of a word is tagged with the most probable sense according to the algorithm. In the above formulation, no importance is given </context>
</contexts>
<marker>Lefever, Hoste, 2010</marker>
<rawString>Els Lefever and Veronique Hoste. 2010. Semeval2010 task 3: cross-lingual word sense disambiguation. In Katrin Erk and Carlo Strapparava, editors, SemEval 2010 : 5th International workshop on Semantic Evaluation : proceedings of the workshop, pages 15–20. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
<author>Elizabeth Figa</author>
</authors>
<title>Pagerank on semantic networks, with application to word sense disambiguation.</title>
<date>2004</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="4637" citStr="Mihalcea et al., 2004" startWordPosition="751" endWordPosition="754">r analysis. Conclu- P(SL2|v) = U sions and future work are given in the last section, section 8. 2 Related work Word Sense Disambiguation is one of the hardest problems in NLP. Successful supervised WSD approaches (Lee et al., 2004; Ng and Lee, 1996) are restricted to resource rich languages and domains. They are directly dependent on availability of good amount of sense tagged data. Creating such a costly resource for all language-domain pairs is impracticable looking at the amount of time and money required. Hence, unsupervised WSD approaches (Diab and Resnik, 2002; Kaji and Morimoto, 2002; Mihalcea et al., 2004; Jean, 2004; Khapra et al., 2011) attract most of the researchers. 3 Background Khapra et al. (2011) dealt with bilingual unsupervised WSD. It uses EM algorithm for estimating sense distributions in comparable corpora. Every polysemous word is disambiguated using the raw counts of its translations in different senses. Synset aligned multilingual dictionary (Mohanty et al., 2008) is used for finding its translations. In this dictionary, synsets are linked, and after that the words inside the synsets are also linked. For example, for the concept of ‘boy’, the Hindi synset {ladakaa, balak, bachh</context>
</contexts>
<marker>Mihalcea, Tarau, Figa, 2004</marker>
<rawString>Rada Mihalcea, Paul Tarau, and Elizabeth Figa. 2004. Pagerank on semantic networks, with application to word sense disambiguation. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rajat Mohanty</author>
<author>Pushpak Bhattacharyya</author>
<author>Prabhakar Pande</author>
<author>Shraddha Kalele</author>
<author>Mitesh Khapra</author>
<author>Aditya Sharma</author>
</authors>
<title>Synset based multilingual dictionary: Insights, applications and challenges.</title>
<date>2008</date>
<booktitle>In Global Wordnet Conference.</booktitle>
<contexts>
<context position="5019" citStr="Mohanty et al., 2008" startWordPosition="810" endWordPosition="813">ata. Creating such a costly resource for all language-domain pairs is impracticable looking at the amount of time and money required. Hence, unsupervised WSD approaches (Diab and Resnik, 2002; Kaji and Morimoto, 2002; Mihalcea et al., 2004; Jean, 2004; Khapra et al., 2011) attract most of the researchers. 3 Background Khapra et al. (2011) dealt with bilingual unsupervised WSD. It uses EM algorithm for estimating sense distributions in comparable corpora. Every polysemous word is disambiguated using the raw counts of its translations in different senses. Synset aligned multilingual dictionary (Mohanty et al., 2008) is used for finding its translations. In this dictionary, synsets are linked, and after that the words inside the synsets are also linked. For example, for the concept of ‘boy’, the Hindi synset {ladakaa, balak, bachhaa} is linked with the Marathi synset {mulagaa, poragaa, por}. The Marathi word ‘mulagaa’ is linked to the Hindi word ‘ladakaa’ which is its exact lexical substitution. Suppose words u in language L1 and v in language L2 are translations of each other and their senses are required. The EM based formulation is as follows: E-Step: X P(πL2 (SL1)|v) · #(v) V X X P(πL2 (SL1 i )|x) · #</context>
</contexts>
<marker>Mohanty, Bhattacharyya, Pande, Kalele, Khapra, Sharma, 2008</marker>
<rawString>Rajat Mohanty, Pushpak Bhattacharyya, Prabhakar Pande, Shraddha Kalele, Mitesh Khapra, and Aditya Sharma. 2008. Synset based multilingual dictionary: Insights, applications and challenges. In Global Wordnet Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hwee Tou Ng</author>
<author>Hian Beng Lee</author>
</authors>
<title>Integrating multiple knowledge sources to disambiguate word sense: an exemplar-based approach.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th annual meeting on Association for Computational Linguistics,</booktitle>
<pages>40--47</pages>
<publisher>ACL.</publisher>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="4266" citStr="Ng and Lee, 1996" startWordPosition="691" endWordPosition="694">semantic relatedness. Section 5 presents the experimental setup. 538 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 538–542, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics Results are presented in section 6. Section 7 cov- M-Step: X P(πL1 (SL2)|u) · #(u) ers phenomena study and error analysis. Conclu- P(SL2|v) = U sions and future work are given in the last section, section 8. 2 Related work Word Sense Disambiguation is one of the hardest problems in NLP. Successful supervised WSD approaches (Lee et al., 2004; Ng and Lee, 1996) are restricted to resource rich languages and domains. They are directly dependent on availability of good amount of sense tagged data. Creating such a costly resource for all language-domain pairs is impracticable looking at the amount of time and money required. Hence, unsupervised WSD approaches (Diab and Resnik, 2002; Kaji and Morimoto, 2002; Mihalcea et al., 2004; Jean, 2004; Khapra et al., 2011) attract most of the researchers. 3 Background Khapra et al. (2011) dealt with bilingual unsupervised WSD. It uses EM algorithm for estimating sense distributions in comparable corpora. Every pol</context>
</contexts>
<marker>Ng, Lee, 1996</marker>
<rawString>Hwee Tou Ng and Hian Beng Lee. 1996. Integrating multiple knowledge sources to disambiguate word sense: an exemplar-based approach. In Proceedings of the 34th annual meeting on Association for Computational Linguistics, pages 40–47, Morristown, NJ, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
<author>S Banerjee</author>
<author>S Patwardhan</author>
</authors>
<title>Maximizing Semantic Relatedness to Perform Word Sense Disambiguation.</title>
<date>2005</date>
<tech>Research Report UMSI 2005/25,</tech>
<institution>University of Minnesota Supercomputing Institute,</institution>
<contexts>
<context position="11284" citStr="Pedersen et al., 2005" startWordPosition="1924" endWordPosition="1927">58.67 EM 61.16 62.31 56.02 31.85 57.92 59.66 62.15 58.42 38.33 56.90 WFS 63.98 75.94 52.72 36.29 60.22 61.95 62.39 48.29 46.56 57.47 RB 32.46 42.56 36.35 18.29 32.68 33.93 39.30 37.49 15.99 32.65 Table 2: Comparison(F-Score) of EM-C and EM for Tourism domain every translation of its context word considerable number of times. This term may make sense only if we have arbitrarily large comparable corpus in the other language. 4.1 Computation of semantic relatedness The semantic relatedness is computed by taking the inverse of the length of the shortest path among two senses in the wordnet graph (Pedersen et al., 2005). All the semantic relations (including crosspart-of-speech links) viz., hypernymy, hyponymy, meronymy, entailment, attribute etc., are used for computing the semantic relatedness. Sense scores thus obtained are used to disambiguate all words in the corpus. We consider all the content words from the context for disambiguation of a word. The winner sense is the one with the highest probability. 5 Experimental setup We have used freely available in-domain comparable corpora1 in Hindi and Marathi languages. These corpora are available for health and tourism domains. The dataset is same as that us</context>
</contexts>
<marker>Pedersen, Banerjee, Patwardhan, 2005</marker>
<rawString>T. Pedersen, S. Banerjee, and S. Patwardhan. 2005. Maximizing Semantic Relatedness to Perform Word Sense Disambiguation. Research Report UMSI 2005/25, University of Minnesota Supercomputing Institute, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucia Specia</author>
<author>Maria Das Grac¸as</author>
<author>Volpe Nunes</author>
<author>Mark Stevenson</author>
</authors>
<title>Exploiting parallel texts to produce a multilingual sense tagged corpus for word sense disambiguation. In</title>
<date>2005</date>
<booktitle>In Proceedings ofRANLP05, Borovets,</booktitle>
<pages>525--531</pages>
<marker>Specia, Grac¸as, Nunes, Stevenson, 2005</marker>
<rawString>Lucia Specia, Maria Das Grac¸as, Volpe Nunes, and Mark Stevenson. 2005. Exploiting parallel texts to produce a multilingual sense tagged corpus for word sense disambiguation. In In Proceedings ofRANLP05, Borovets, pages 525–531.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>