<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000868">
<title confidence="0.998143">
Reranking with Linguistic and Semantic Features
for Arabic Optical Character Recognition
</title>
<author confidence="0.996209">
Nadi Tomeh, Nizar Habash, Ryan Roth, Noura Farra
</author>
<affiliation confidence="0.985641">
Center for Computational Learning Systems, Columbia University
</affiliation>
<email confidence="0.992132">
{nadi,habash,ryanr,noura}@ccls.columbia.edu
</email>
<author confidence="0.976628">
Pradeep Dasigi Mona Diab
</author>
<affiliation confidence="0.906641">
Safaba Translation Solutions The George Washington University
</affiliation>
<email confidence="0.996977">
pradeep@safaba.com mtdiab@gwu.edu
</email>
<sectionHeader confidence="0.997304" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997545714285714">
Optical Character Recognition (OCR) sys-
tems for Arabic rely on information con-
tained in the scanned images to recognize
sequences of characters and on language
models to emphasize fluency. In this paper
we incorporate linguistically and seman-
tically motivated features to an existing
OCR system. To do so we follow an n-best
list reranking approach that exploits recent
advances in learning to rank techniques.
We achieve 10.1% and 11.4% reduction in
recognition word error rate (WER) relative
to a standard baseline system on typewrit-
ten and handwritten Arabic respectively.
</bodyText>
<sectionHeader confidence="0.999492" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999443543859649">
Optical Character Recognition (OCR) is the task
of converting scanned images of handwritten,
typewritten or printed text into machine-encoded
text. Arabic OCR is a challenging problem due
to Arabic’s connected letter forms, consonantal
diacritics and rich morphology (Habash, 2010).
Therefore only a few OCR systems have been de-
veloped (M¨argner and Abed, 2009). The BBN
Byblos OCR system (Natajan et al., 2002; Prasad
et al., 2008; Saleem et al., 2009), which we use
in this paper, relies on a hidden Markov model
(HMM) to recover the sequence of characters from
the image, and uses an n-gram language model
(LM) to emphasize the fluency of the output. For
an input image, the OCR decoder generates an n-
best list of hypotheses each of which is associated
with HMM and LM scores.
In addition to fluency as evaluated by LMs,
other information potentially helps in discrimi-
nating good from bad hypotheses. For example,
Habash and Roth (2011) use a variety of linguistic
(morphological and syntactic) and non-linguistic
features to automatically identify errors in OCR
hypotheses. Another example presented by De-
vlin et al. (2012) shows that using a statistical ma-
chine translation system to assess the difficulty of
translating an Arabic OCR hypothesis into English
gives valuable feedback on OCR quality. There-
fore, combining additional information with the
LMs could reduce recognition errors. However,
direct integration of such information in the de-
coder is difficult.
A straightforward alternative which we advo-
cate in this paper is to use the available informa-
tion to rerank the hypotheses in the n-best lists.
The new top ranked hypothesis is considered as
the new output of the system. We propose com-
bining LMs with linguistically and semantically
motivated features using learning to rank meth-
ods. Discriminative reranking allows each hypoth-
esis to be represented as an arbitrary set of features
without the need to explicitly model their interac-
tions. Therefore, the system benefits from global
and potentially complex features which are not
available to the baseline OCR decoder. This ap-
proach has successfully been applied in numerous
Natural Language Processing (NLP) tasks includ-
ing syntactic parsing (Collins and Koo, 2005), se-
mantic parsing (Ge and Mooney, 2006), machine
translation (Shen et al., 2004), spoken language
understanding (Dinarelli et al., 2012), etc. Fur-
thermore, we propose to combine several ranking
methods into an ensemble which learns from their
predictions to further reduce recognition errors.
We describe our features and reranking ap-
proach in §2, and we present our experiments and
results in §3.
</bodyText>
<sectionHeader confidence="0.887938" genericHeader="method">
2 Discriminative Reranking for OCR
</sectionHeader>
<footnote confidence="0.7166188">
Each hypothesis in an n-best list {hi}ni=1 is repre-
sented by a d-dimensional feature vector xi E Rd.
Each xi is associated with a loss li to generate a
labeled n-best list H = {(xi, li)}ni=1. The loss is
computed as the Word Error Rate (WER) of the
</footnote>
<page confidence="0.956003">
549
</page>
<bodyText confidence="0.5977265">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 549–555,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
hypotheses compared to a reference transcription.
For supervised training we use a set of n-best lists
</bodyText>
<equation confidence="0.720599">
H =
{H(k)}M k=1.
</equation>
<subsectionHeader confidence="0.998168">
2.1 Learning to rank approaches
</subsectionHeader>
<bodyText confidence="0.99385769047619">
Major approaches to learning to rank can be di-
vided into pointwise score regression, pairwise
preference satisfaction, and listwise structured
learning. See Liu (2009) for a survey. In this
paper, we explore all of the following learning to
rank approaches.
Pointwise In the pointwise approach, the rank-
ing problem is formulated as a regression, or ordi-
nal classification, for which any existing method
can be applied. Each hypothesis constitutes a
learning instance. In this category we use a regres-
sion method called Multiple Additive Regression
Trees (MART) (Friedman, 2000) as implemented
in RankLib.1 The major problem with pointwise
approaches is that the structure of the list of hy-
potheses is ignored.
Pairwise The pairwise approach takes pairs of
hypotheses as instances in learning, and formal-
izes the ranking problem as a pairwise classifica-
tion or pairwise regression. We use several meth-
ods from this category.
RankSVM (Joachims, 2002) is a method based
on Support Vector Machines (SVMs) for which
we use only linear kernels to keep complexity low.
Exact optimization of the RankSVM objective can
be computationally expensive as the number of
hypothesis pairs can be very large. Approximate
stochastic training strategies reduces complexity
and produce comparable performance. There-
fore, in addition to RankSVM, we use stochas-
tic sub-gradient descent (SGDSVM), Pegasos (Pe-
gasosSVM) and Passive-Aggressive Perceptron
(PAPSVM) as implemented in Sculley (2009).2
RankBoost (Freund et al., 2003) is a pairwise
boosting approach implemented in RankLib. It
uses a linear combination of weak rankers, each of
which is a binary function associated with a single
feature. This function is 1 when the feature value
exceeds some threshold and 0 otherwise.
RankMIRA is a ranking method presented in (Le
Roux et al., 2012).3 It uses a weighted linear
combination of features which assigns the highest
</bodyText>
<footnote confidence="0.9627806">
1http://people.cs.umass.edu/˜vdang/
ranklib.html
2http://code.google.com/p/sofia-ml
3https://github.com/jihelhere/
adMIRAble
</footnote>
<bodyText confidence="0.9996565">
score to the hypotheses with the lowest loss. Dur-
ing training, the weights are updated according to
the Margin-Infused Relaxed Algorithm (MIRA),
whenever the highest scoring hypothesis differs
from the hypothesis with the lowest error rate.
In pairwise approaches, the group structure of
the n-best list is still ignored. Additionally, the
number of training pairs generated from an n-best
list depends on its size, which could result in train-
ing a model biased toward larger hypothesis lists
(Cao et al., 2006).
Listwise The listwise approach takes n-best lists
as instances in both learning and prediction. The
group structure is considered explicitly and rank-
ing evaluation measures can be directly optimized.
The listwise methods we use are implemented in
RankLib.
AdaRank (Xu and Li, 2007) is a boosting ap-
proach, similar to RankBoost, except that it opti-
mizes an arbitrary ranking metric, for which we
use Mean Average Precision (MAP).
Coordinate Ascent (CA) uses a listwise linear
model whose weights are learned by a coordinate
ascent method to optimize a ranking metric (Met-
zler and Bruce Croft, 2007). As with AdaRank we
use MAP.
ListNet (Cao et al., 2007) uses a neural network
model whose parameters are learned by gradient
descent method to optimize a listwise loss based
on a probabilistic model of permutations.
</bodyText>
<subsectionHeader confidence="0.998222">
2.2 Ensemble reranking
</subsectionHeader>
<bodyText confidence="0.99995625">
In addition to the above mentioned approaches,
we couple simple feature selection and reranking
models combination via a straightforward ensem-
ble learning method similar to stacked general-
ization (Wolpert, 1992) and Combiner (Chan and
Stolfo, 1993). Our goal is to generate an overall
meta-ranker that outperforms all base-rankers by
learning from their predictions how they correlate
with each other.
To obtain the base-rankers, we train each of the
ranking models of §2.1 using all the features of
§2.3 and also using each feature family added to
the baseline features separately. Then, we use the
best model for each ranking approach to make pre-
dictions on a held-out data set of n-best lists. We
can think of each base-ranker as computing one
feature for each hypothesis. Hence, the scores
generated by all the rankers for a given hypothe-
sis constitute its feature vector.
The held-out n-best lists and the predictions of
</bodyText>
<page confidence="0.971984">
550
</page>
<bodyText confidence="0.999932333333333">
the base-rankers represent the training data for the
meta-ranker. We choose RankSVM4 as the meta-
ranker since it performed well as a base-ranker.
</bodyText>
<subsectionHeader confidence="0.973213">
2.3 Features
</subsectionHeader>
<bodyText confidence="0.9999539">
Our features fall into five families.
Base features include the HMM and LM scores
produced by the OCR system. These features are
used by the baseline system5 as well as by the var-
ious reranking methods.
Simple features (“simple”) include the baseline
rank of the hypothesis and a 0-to-1 range normal-
ized version of it. We also use a hypothesis confi-
dence feature which corresponds to the average of
the confidence of individual words in the hypoth-
esis; “confidence” for a given word is computed
as the fraction of hypotheses in the n-best list
that contain the word (Habash and Roth, 2011).
The more consensus words a hypothesis contains,
the higher its assigned confidence. We also use
the average word length and the number of con-
tent words (normalized by the hypothesis length).
We define “content words” as non-punctuation and
non-digit words. Additionally, we use a set of bi-
nary features indicating if the hypothesis contains
a sequence of duplicated characters, a date-like se-
quence and an occurrence of a specific character
class (punctuation, alphabetic and digit).
Word LM features (“LM-word”) include the
log probabilities of the hypothesis obtained us-
ing n-gram LMs with n E 11, ... , 5}. Separate
LMs are trained on the Arabic Gigaword 3 corpus
(Graff, 2007), and on the reference transcriptions
of the training data (see §3.1). The LM models
are built using the SRI Language Modeling Toolkit
(Stolcke, 2002).
Linguistic LM features (“LM-MADA”) are
similar to the word LM features except that they
are computed using the part-of-speech and the
lemma of the words instead of the actual words.6
Semantic coherence feature (“SemCoh”) is
motivated by the fact that semantic information
can be very useful in modeling the fluency of
phrases, and can augment the information pro-
vided by n-gram LMs. In modeling contextual
</bodyText>
<footnote confidence="0.992776444444444">
4RankSVM has also been shown to be a good choice for
the meta-learner in general stacking ensemble learning (Tang
et al., 2010).
5The baseline ranking is simply based on the sum of the
logs of the HMM and LM scores.
6The part-of-speech and the lemmas are obtained using
MADA 3.0, a tool for Arabic morphological analysis and
disambiguation (Habash and Rambow, 2005; Habash et al.,
2009).
</footnote>
<bodyText confidence="0.996764272727273">
lexical semantic information, simple bag-of-words
models usually have a lot of noise; while more
sophisticated models considering positional infor-
mation have sparsity issues. To strike a balance
between these two extremes, we introduce a novel
model of semantic coherence that is based on a
measure of semantic relatedness between pairs of
words. We model semantic relatedness between
two words using the Information Content (IC) of
the pair in a method similar to the one used by Lin
(1997) and Lin (1998).
</bodyText>
<equation confidence="0.9931615">
IC(w1, d, w2) = log f(w1, d, w2)f(*, d, *)
f(w1,d,*)f(*,d,w2)
</equation>
<bodyText confidence="0.999916875">
Here, d can generally represent some form of re-
lation between w1 and w2. Whereas Lin (1997)
and Lin (1998) used dependency relation between
words, we use distance. Given a sentence, the dis-
tance between w1 and w2 is one plus the number
of words that are seen after w1 and before w2 in
that sentence. Hence, f(w1, d, w2) is the number
of times w1 occurs before w2 at a distance d in
all the sentences in a corpus. * is a placeholder
for any word, i.e., f(*, d, *) is the frequency of all
word pairs occurring at distance d. The distances
are directional and not absolute values. A simi-
lar measure of relatedness was also used by Kolb
(2009).
We estimate the frequencies from the Arabic
Gigaword. We set the window size to 3 and cal-
culate IC values of all pairs of words occurring at
distance within the window size. Since the dis-
tances are directional, it has to be noted that given
a word, its relations with three words before it and
three words after it are modeled. During testing,
for each phrase in our test set, we measure se-
mantic relatedness of pairs of words using the IC
values estimated from the Arabic Gigaword, and
normalize their sum by the number of pairs in the
phrase to obtain a measure of Semantic Coherence
(SC) of the phrase. That is,
where p is the phrase being evaluated, n is the
number of words in it, d is the distance between
words, W is the window size (set to 3), and m is
the number of all possible wi, wi+d pairs in the
phrase given these conditions.
</bodyText>
<table confidence="0.888208888888889">
1 �X IC(wi, d, wi+d)
SC(p) = m 1≤d≤W
1≤i+d&lt;n
551
print hand
|W* |n |h ||W* |n |h|
Wb 1,560 62 9 2,295 225 8
Wm 1,000 76 9 1,000 225 9
Wt 1,000 64 9 1,000 227 9
</table>
<tableCaption confidence="0.993151666666667">
Table 1: Data sets statistics. |W* |refers to the
number of n-best lists, n is the average size of the
lists, and |h |is the average length of a hypothesis.
</tableCaption>
<table confidence="0.99956175">
print hand
Baseline 13.8% 35%
Oracle 9.8% 20.9%
Best result 12.4% 30.9%
</table>
<tableCaption confidence="0.9769425">
Table 2: WER for baseline, oracle and best
reranked hypotheses.
</tableCaption>
<sectionHeader confidence="0.999739" genericHeader="method">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999396">
3.1 Data and baselines
</subsectionHeader>
<bodyText confidence="0.993126068965517">
We used two data sets derived from high-
resolution image scans of typewritten and hand-
written Arabic text along with ground truth tran-
scriptions.7 The BBN Byblos system was then
used to process these scanned images into se-
quences of segments (sentence fragments) and
generate a ranked n-best list of hypotheses for
each segment (Natajan et al., 2002; Prasad et al.,
2008; Saleem et al., 2009). We divided each of the
typewritten data set (“print”) and handwritten data
set (“hand”) into three disjoint parts: a training set
for the base-rankers Wb, a training set for the meta-
ranker Wm and a test set Wt. Table 1 presents
some statistics about these data sets. Our base-
line is based on the sum of the logs of the HMM
and LM scores. Table 2 presents the WER for our
baseline hypothesis, the best hypothesis in the list
(our oracle) and our best reranking results which
we describe in details in §3.2.
For LM training we used 220M words from
Arabic Gigaword 3, and 2.4M words from each
“print” and “hand” ground truth annotations.
Effect of n-best training size on WER The size
of the training n-best lists is crucial to the learning
of the ranking model. In particular, it determines
the number of training instances per list. To deter-
mine the optimal n to use for the rest of this pa-
per, we conducted the following experiment aims
to understand the effect of the size of n-best lists
</bodyText>
<footnote confidence="0.9234475">
7The Anfal data set discussed here was collected by the
Linguistic Data Consortium.
</footnote>
<figure confidence="0.7434445">
5 15 25 35 45 55
Size of each training n-best list
</figure>
<figureCaption confidence="0.68901">
Figure 1: Effect of the size of training n-best lists
on WER. The horizontal axis represents the max-
imum size of the n-best lists and the vertical axis
represents WER, left is “print” and right is “hand”.
</figureCaption>
<bodyText confidence="0.9998824375">
on the reranking performance for one of our best
reranking models, namely RankSVM. We trained
each model with different sizes of n-best, varying
from n = 5 to n = 60 for “print” data, and be-
tween n = 5 and n = 150 for “hand” data. The
top n hypotheses according to the baseline are se-
lected for each n. Figure 1 plots WER as a func-
tion of the size of the training list n for both “print”
and “hand” data.
The lowest WER scores are achieved for n =
10 and n = 15 for both “print” and “hand” data.
We note that a small number of hypotheses per list
is sufficient for RankSVM to obtain a good per-
formance, but also increasing n further seems to
increase the error rate. For the rest of this paper
we use the top 10-best hypotheses per segment.
</bodyText>
<subsectionHeader confidence="0.999746">
3.2 Reranking results
</subsectionHeader>
<bodyText confidence="0.9999945">
The reranking results for “print” and “hand” are
presented in Table 3. The results are presented
as the difference in WER from the baseline WER.
See the caption in Table 3 for more information.
For “print”, the pairwise approaches clearly out-
perform the listwise approaches and achieve the
lowest WER of 12.4% (10.1% WER reduction rel-
ative to the baseline) with 7 different combinations
of rankers and feature families. While both ap-
proaches do not minimize WER directly, the pair-
wise methods have the advantage of using objec-
tives that are simpler to optimize, and they are
trained on much larger number of examples which
may explain their superiority. RankBoost, how-
ever, is less competitive with a performance closer
to that of listwise approaches. All the methods
improved over the baseline with any feature fam-
ily, except for the pointwise approach which did
</bodyText>
<figure confidence="0.982615333333333">
15
34
WER
print
14.5
33.5
hand
14
33
32.5
32
13
31.5
12.5
31
12
30.5
13.5
</figure>
<page confidence="0.977781">
552
</page>
<table confidence="0.97434">
Pointwise Listwise Pairwise
Features
Base 1.1 -0.4 -1.0 -1.0 -1.0 -1.1 -1.2 -1.2 -1.3 -1.3
+simple -0.1 0.0 -0.1 -0.2 0.0 -0.1 0.1 0.0 0.1 0.0
+LM-word -1.0 -0.2 0.1 -0.1 -0.1 -0.3 -0.2 -0.1 0.0 -0.1
+LM-MADA 0.0 -0.3 0.1 -0.2 -0.1 0.0 -0.1 -0.2 -0.1 -0.1
+SemCoh 0.0 -0.4 0.0 -0.2 -0.1 -0.1 0.0 -0.1 0.0 0.1
+All 0.6 0.1 0.0 0.1 0.0 0.1 0.2 0.2 0.2 0.0
Base 4.2 -3.1 -3.2 -3.4 -2.9 -3.2 -3.5 -3.8 -3.6 -3.8
+simple 0.3 -0.1 0.1 0.2 0.1 -0.1 0.2 -0.2 0.1 0.2
+LM-word 0.4 -0.1 0.1 0.8 -0.2 -0.7 -0.2 -0.1 0.0 0.1
+LM-MADA 0.0 -0.5 0.1 0.0 0.1 -0.4 -0.1 0.3 -0.2 0.1
+SemCoh 0.0 -0.1 0.0 -0.4 0.0 -0.2 -0.3 -0.2 -0.2 0.0
+All 0.2 0.4 0.0 0.4 0.2 0.4 0.2 0.1 0.2 0.0
</table>
<tableCaption confidence="0.999153">
Table 3: Reranking results for the “print” and “hand” data sets; the “print” baseline WER is 13.9% and the “hand” baseline
</tableCaption>
<bodyText confidence="0.954219418604651">
WER is 35.0%. The “Base” numbers represent the difference in WER between the corresponding ranker using “Base” features
only and the baseline, which uses the same “Base” features. The “+features” numbers represent additional gain (relative to
“Base”) obtained by adding the corresponding feature family. The “+All” numbers represent the gain of using all features,
relative to the best single-family system. The actual WER of a ranker can be obtained by summing the baseline WER and the
corresponding “Base” and “+features” scores. Bolded values are the best performers overall.
Print
Hand
worse than the baseline. When combined with
the “Base” features, “LM-words” lead to improve-
ments with 8 out of 10 rankers, and proved to be
the most helpful among feature families. “LM-
MADA” follows with improvements with 7 out of
10 rankers. The lowest WER is achieved using
one of these two LM-based families. Combining
all feature families did not help and in many cases
resulted in a higher WER than the best family.
Similar improvements are observed for “hand”.
The lowest achieved WER is 31% (11.4% WER
reduction relative to the baseline). Here also,
the pointwise method increased the WER by 12%
relative to the baseline (as opposed to 7% for
“print”). Again, the listwise approaches are over-
all less effective than their pairwise counterparts,
except for RankBoost which resulted in the small-
est WER reduction among all rankers. The two
best rankers correspond to RankMIRA with the
“simple” and the “SemCoh” features. The “Sem-
Coh” feature resulted in improvements for 6 out of
the 10 rankers, and thus was the best single feature
on average for the “hand” data set. As observed
with “print” data, combining all the features does
not lead to the best performance.
In an additional experiment, we selected the
best model for each ranking method and combined
them to build an ensemble as described in §2.2.
For “hand”, the ensemble slightly outperformed
all the individual rankers and achieved the lowest
WER of 30.9%. However, for the “print” data, the
ensemble failed to improve over the base-rankers
and resulted in a WER of 12.4%.
The best overall results are presented in Table 2.
Our best results reduce the distance to the oracle
top line by 35% for “print” and 29% for “hand”.
</bodyText>
<sectionHeader confidence="0.996878" genericHeader="method">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999967">
We presented a set of experiments on incorporat-
ing features into an existing OCR system via n-
best list reranking. We compared several learn-
ing to rank techniques and combined them us-
ing an ensemble technique. We obtained 10.1%
and 11.4% reduction in WER relative to the base-
line for “print” and “hand” data respectively. Our
best systems used pairwise reranking which out-
performed the other methods, and used the MADA
based features for “print” and our novel semantic
coherence feature for “hand”.
</bodyText>
<sectionHeader confidence="0.696003" genericHeader="conclusions">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.9999603">
We would like to thank Rohit Prasad and Matin
Kamali for providing the data and helpful dis-
cussions. This work was funded under DARPA
project number HR0011-08-C-0004. Any opin-
ions, findings and conclusions or recommenda-
tions expressed in this paper are those of the au-
thors and do not necessarily reflect the views of
DARPA. The last two authors, Dasigi and Diab,
worked on this project while at Columbia Univer-
sity.
</bodyText>
<page confidence="0.998208">
553
</page>
<sectionHeader confidence="0.980071" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99653">
Yunbo Cao, Jun Xu, Tie-Yan Liu, Hang Li, Yalou
Huang, and Hsiao-Wuen Hon. 2006. Adapting
ranking SVM to document retrieval. In Proceedings
of the 29th annual international ACM SIGIR confer-
ence on Research and development in information
retrieval, SIGIR ’06, pages 186–193.
Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and
Hang Li. 2007. Learning to rank: from pairwise
approach to listwise approach. In Proceedings of the
24th international conference on Machine learning,
ICML ’07, pages 129–136.
Philip K. Chan and Salvatore J. Stolfo. 1993. Exper-
iments on multistrategy learning by meta-learning.
In Proceedings of the second international confer-
ence on Information and knowledge management,
CIKM ’93, pages 314–323.
Michael Collins and Terry Koo. 2005. Discriminative
Reranking for Natural Language Parsing. Comput.
Linguist., 31(1):25–70, March.
Jacob Devlin, Matin Kamali, Krishna Subramanian,
Rohit Prasad, and Prem Natarajan. 2012. Statisti-
cal Machine Translation as a Language Model for
Handwriting Recognition. In ICFHR, pages 291–
296.
Marco Dinarelli, Alessandro Moschitti, and Giuseppe
Riccardi. 2012. Discriminative Reranking for
Spoken Language Understanding. IEEE Transac-
tions on Audio, Speech &amp; Language Processing,
20(2):526–539.
Yoav Freund, Raj Iyer, Robert E. Schapire, and Yoram
Singer. 2003. An efficient boosting algorithm
for combining preferences. J. Mach. Learn. Res.,
4:933–969, December.
Jerome H. Friedman. 2000. Greedy Function Approx-
imation: A Gradient Boosting Machine. Annals of
Statistics, 29:1189–1232.
Ruifang Ge and Raymond J. Mooney. 2006. Discrimi-
native Reranking for Semantic Parsing. In ACL.
David Graff. 2007. Arabic Gigaword 3, LDC Cat-
alog No.: LDC2003T40. Linguistic Data Consor-
tium, University of Pennsylvania.
Nizar Habash and Owen Rambow. 2005. Arabic Tok-
enization, Part-of-Speech Tagging and Morphologi-
cal Disambiguation in One Fell Swoop. In Proceed-
ings of the 43rd Annual Meeting of the Association
for Computational Linguistics (ACL’05), pages 573–
580, Ann Arbor, Michigan, June.
Nizar Habash and Ryan M. Roth. 2011. Using deep
morphology to improve automatic error detection in
Arabic handwriting recognition. In Proceedings of
the 49th Annual Meeting of the Association for Com-
putational Linguistics: Human Language Technolo-
gies - Volume 1, HLT ’11, pages 875–884.
Nizar Habash, Owen Rambow, and Ryan Roth. 2009.
MADA+TOKAN: A toolkit for Arabic tokenization,
diacritization, morphological disambiguation, POS
tagging, stemming and lemmatization. In Khalid
Choukri and Bente Maegaard, editors, Proceedings
of the Second International Conference on Arabic
Language Resources and Tools. The MEDAR Con-
sortium, April.
Nizar Habash. 2010. Introduction to Arabic Natural
Language Processing. Morgan &amp; Claypool Publish-
ers.
Thorsten Joachims. 2002. Optimizing search en-
gines using clickthrough data. In Proceedings of
the eighth ACM SIGKDD international conference
on Knowledge discovery and data mining, KDD ’02,
pages 133–142.
Peter Kolb. 2009. Experiments on the difference be-
tween semantic similarity and relatedness. In Pro-
ceedings of the 17th Nordic Conference of Computa-
tional Linguistics, NEALT Proceedings Series Vol.
4.
Joseph Le Roux, Benoit Favre, Alexis Nasr, and
Seyed Abolghasem Mirroshandel. 2012. Gener-
ative Constituent Parsing and Discriminative De-
pendency Reranking: Experiments on English and
French. In SP-SEM-MRL 2012.
Dekang Lin. 1997. Using syntactic dependency as
local context to resolve word sense ambiguity. In
Proceedings of the eighth conference on European
chapter of the Association for Computational Lin-
guistics, EACL ’97, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Dekang Lin. 1998. Automatic retrieval and clustering
of similar words. In Proceedings of the 36th Annual
Meeting of the Association for Computational Lin-
guistics and 17th International Conference on Com-
putational Linguistics - Volume 2, ACL ’98.
Tie-Yan Liu. 2009. Learning to Rank for Informa-
tion Retrieval. Now Publishers Inc., Hanover, MA,
USA.
Volker M¨argner and Haikal El Abed. 2009. Ara-
bic Word and Text Recognition - Current Develop-
ments. In Khalid Choukri and Bente Maegaard, ed-
itors, Proceedings of the Second International Con-
ference on Arabic Language Resources and Tools,
Cairo, Egypt, April. The MEDAR Consortium.
Donald Metzler and W. Bruce Croft. 2007. Linear
feature-based models for information retrieval. Inf.
Retr., 10(3):257–274, June.
Premkumar Natajan, Zhidong Lu, Richard Schwartz,
Issam Bazzi, and John Makhoul. 2002. Hid-
den Markov models. chapter Multilingual machine
printed OCR, pages 43–63. World Scientific Pub-
lishing Co., Inc., River Edge, NJ, USA.
</reference>
<page confidence="0.986977">
554
</page>
<reference confidence="0.998839512820513">
Rohit Prasad, Shirin Saleem, Matin Kamali, Ralf Meer-
meier, and Premkumar Natarajan. 2008. Improve-
ments in hidden Markov model based Arabic OCR.
In Proceedings of International Conference on Pat-
tern Recognition (ICPR), pages 1–4.
Shirin Saleem, Huaigu Cao, Krishna Subramanian,
Matin Kamali, Rohit Prasad, and Prem Natarajan.
2009. Improvements in BBN’s HMM-Based Of-
fline Arabic Handwriting Recognition System. In
Proceedings of the 2009 10th International Confer-
ence on Document Analysis and Recognition, IC-
DAR ’09, pages 773–777.
D. Sculley. 2009. Large scale learning to rank. In
NIPS 2009 Workshop on Advances in Ranking.
Libin Shen, Anoop Sarkar, and Franz Josef Och.
2004. Discriminative Reranking for Machine Trans-
lation. In Daniel Marcu Susan Dumais and Salim
Roukos, editors, HLT-NAACL 2004: Main Proceed-
ings, pages 177–184, Boston, Massachusetts, USA,
May.
Andreas Stolcke. 2002. SRILM - an Extensible Lan-
guage Modeling Toolkit. In Proceedings of the In-
ternational Conference on Spoken Language Pro-
cessing (ICSLP), volume 2, pages 901–904, Denver,
CO.
Buzhou Tang, Qingcai Chen, Xuan Wang, and Xiao-
long Wang. 2010. Reranking for stacking ensem-
ble learning. In Proceedings of the 17th interna-
tional conference on Neural information processing:
theory and algorithms - Volume Part I, ICONIP’10,
pages 575–584.
David H. Wolpert. 1992. Original Contribution:
Stacked generalization. Neural Netw., 5(2):241–
259, February.
Jun Xu and Hang Li. 2007. AdaRank: a boosting al-
gorithm for information retrieval. In Proceedings of
the 30th annual international ACM SIGIR confer-
ence on Research and development in information
retrieval, SIGIR ’07, pages 391–398.
</reference>
<page confidence="0.998501">
555
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.796255">
<title confidence="0.998526">Reranking with Linguistic and Semantic Features for Arabic Optical Character Recognition</title>
<author confidence="0.98745">Nadi Tomeh</author>
<author confidence="0.98745">Nizar Habash</author>
<author confidence="0.98745">Ryan Roth</author>
<author confidence="0.98745">Noura Farra</author>
<affiliation confidence="0.999785">Center for Computational Learning Systems, Columbia University</affiliation>
<author confidence="0.962798">Pradeep Dasigi Mona Diab</author>
<affiliation confidence="0.998214">Safaba Translation Solutions The George Washington University</affiliation>
<email confidence="0.9985">pradeep@safaba.commtdiab@gwu.edu</email>
<abstract confidence="0.989433333333334">Optical Character Recognition (OCR) systems for Arabic rely on information contained in the scanned images to recognize sequences of characters and on language models to emphasize fluency. In this paper we incorporate linguistically and semantically motivated features to an existing system. To do so we follow an list reranking approach that exploits recent advances in learning to rank techniques. We achieve 10.1% and 11.4% reduction in recognition word error rate (WER) relative to a standard baseline system on typewritten and handwritten Arabic respectively.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yunbo Cao</author>
<author>Jun Xu</author>
<author>Tie-Yan Liu</author>
<author>Hang Li</author>
<author>Yalou Huang</author>
<author>Hsiao-Wuen Hon</author>
</authors>
<title>Adapting ranking SVM to document retrieval.</title>
<date>2006</date>
<booktitle>In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’06,</booktitle>
<pages>186--193</pages>
<contexts>
<context position="6765" citStr="Cao et al., 2006" startWordPosition="1027" endWordPosition="1030">mass.edu/˜vdang/ ranklib.html 2http://code.google.com/p/sofia-ml 3https://github.com/jihelhere/ adMIRAble score to the hypotheses with the lowest loss. During training, the weights are updated according to the Margin-Infused Relaxed Algorithm (MIRA), whenever the highest scoring hypothesis differs from the hypothesis with the lowest error rate. In pairwise approaches, the group structure of the n-best list is still ignored. Additionally, the number of training pairs generated from an n-best list depends on its size, which could result in training a model biased toward larger hypothesis lists (Cao et al., 2006). Listwise The listwise approach takes n-best lists as instances in both learning and prediction. The group structure is considered explicitly and ranking evaluation measures can be directly optimized. The listwise methods we use are implemented in RankLib. AdaRank (Xu and Li, 2007) is a boosting approach, similar to RankBoost, except that it optimizes an arbitrary ranking metric, for which we use Mean Average Precision (MAP). Coordinate Ascent (CA) uses a listwise linear model whose weights are learned by a coordinate ascent method to optimize a ranking metric (Metzler and Bruce Croft, 2007).</context>
</contexts>
<marker>Cao, Xu, Liu, Li, Huang, Hon, 2006</marker>
<rawString>Yunbo Cao, Jun Xu, Tie-Yan Liu, Hang Li, Yalou Huang, and Hsiao-Wuen Hon. 2006. Adapting ranking SVM to document retrieval. In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’06, pages 186–193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhe Cao</author>
<author>Tao Qin</author>
<author>Tie-Yan Liu</author>
<author>Ming-Feng Tsai</author>
<author>Hang Li</author>
</authors>
<title>Learning to rank: from pairwise approach to listwise approach.</title>
<date>2007</date>
<booktitle>In Proceedings of the 24th international conference on Machine learning, ICML ’07,</booktitle>
<pages>129--136</pages>
<contexts>
<context position="7420" citStr="Cao et al., 2007" startWordPosition="1134" endWordPosition="1137"> n-best lists as instances in both learning and prediction. The group structure is considered explicitly and ranking evaluation measures can be directly optimized. The listwise methods we use are implemented in RankLib. AdaRank (Xu and Li, 2007) is a boosting approach, similar to RankBoost, except that it optimizes an arbitrary ranking metric, for which we use Mean Average Precision (MAP). Coordinate Ascent (CA) uses a listwise linear model whose weights are learned by a coordinate ascent method to optimize a ranking metric (Metzler and Bruce Croft, 2007). As with AdaRank we use MAP. ListNet (Cao et al., 2007) uses a neural network model whose parameters are learned by gradient descent method to optimize a listwise loss based on a probabilistic model of permutations. 2.2 Ensemble reranking In addition to the above mentioned approaches, we couple simple feature selection and reranking models combination via a straightforward ensemble learning method similar to stacked generalization (Wolpert, 1992) and Combiner (Chan and Stolfo, 1993). Our goal is to generate an overall meta-ranker that outperforms all base-rankers by learning from their predictions how they correlate with each other. To obtain the </context>
</contexts>
<marker>Cao, Qin, Liu, Tsai, Li, 2007</marker>
<rawString>Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and Hang Li. 2007. Learning to rank: from pairwise approach to listwise approach. In Proceedings of the 24th international conference on Machine learning, ICML ’07, pages 129–136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip K Chan</author>
<author>Salvatore J Stolfo</author>
</authors>
<title>Experiments on multistrategy learning by meta-learning.</title>
<date>1993</date>
<booktitle>In Proceedings of the second international conference on Information and knowledge management, CIKM ’93,</booktitle>
<pages>314--323</pages>
<contexts>
<context position="7852" citStr="Chan and Stolfo, 1993" startWordPosition="1198" endWordPosition="1201">wise linear model whose weights are learned by a coordinate ascent method to optimize a ranking metric (Metzler and Bruce Croft, 2007). As with AdaRank we use MAP. ListNet (Cao et al., 2007) uses a neural network model whose parameters are learned by gradient descent method to optimize a listwise loss based on a probabilistic model of permutations. 2.2 Ensemble reranking In addition to the above mentioned approaches, we couple simple feature selection and reranking models combination via a straightforward ensemble learning method similar to stacked generalization (Wolpert, 1992) and Combiner (Chan and Stolfo, 1993). Our goal is to generate an overall meta-ranker that outperforms all base-rankers by learning from their predictions how they correlate with each other. To obtain the base-rankers, we train each of the ranking models of §2.1 using all the features of §2.3 and also using each feature family added to the baseline features separately. Then, we use the best model for each ranking approach to make predictions on a held-out data set of n-best lists. We can think of each base-ranker as computing one feature for each hypothesis. Hence, the scores generated by all the rankers for a given hypothesis co</context>
</contexts>
<marker>Chan, Stolfo, 1993</marker>
<rawString>Philip K. Chan and Salvatore J. Stolfo. 1993. Experiments on multistrategy learning by meta-learning. In Proceedings of the second international conference on Information and knowledge management, CIKM ’93, pages 314–323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Terry Koo</author>
</authors>
<title>Discriminative Reranking for Natural Language Parsing.</title>
<date>2005</date>
<journal>Comput. Linguist.,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="3202" citStr="Collins and Koo, 2005" startWordPosition="482" endWordPosition="485"> The new top ranked hypothesis is considered as the new output of the system. We propose combining LMs with linguistically and semantically motivated features using learning to rank methods. Discriminative reranking allows each hypothesis to be represented as an arbitrary set of features without the need to explicitly model their interactions. Therefore, the system benefits from global and potentially complex features which are not available to the baseline OCR decoder. This approach has successfully been applied in numerous Natural Language Processing (NLP) tasks including syntactic parsing (Collins and Koo, 2005), semantic parsing (Ge and Mooney, 2006), machine translation (Shen et al., 2004), spoken language understanding (Dinarelli et al., 2012), etc. Furthermore, we propose to combine several ranking methods into an ensemble which learns from their predictions to further reduce recognition errors. We describe our features and reranking approach in §2, and we present our experiments and results in §3. 2 Discriminative Reranking for OCR Each hypothesis in an n-best list {hi}ni=1 is represented by a d-dimensional feature vector xi E Rd. Each xi is associated with a loss li to generate a labeled n-best</context>
</contexts>
<marker>Collins, Koo, 2005</marker>
<rawString>Michael Collins and Terry Koo. 2005. Discriminative Reranking for Natural Language Parsing. Comput. Linguist., 31(1):25–70, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Devlin</author>
<author>Matin Kamali</author>
<author>Krishna Subramanian</author>
<author>Rohit Prasad</author>
<author>Prem Natarajan</author>
</authors>
<title>Statistical Machine Translation as a Language Model for Handwriting Recognition. In</title>
<date>2012</date>
<booktitle>ICFHR,</booktitle>
<pages>291--296</pages>
<contexts>
<context position="2093" citStr="Devlin et al. (2012)" startWordPosition="309" endWordPosition="313">v model (HMM) to recover the sequence of characters from the image, and uses an n-gram language model (LM) to emphasize the fluency of the output. For an input image, the OCR decoder generates an nbest list of hypotheses each of which is associated with HMM and LM scores. In addition to fluency as evaluated by LMs, other information potentially helps in discriminating good from bad hypotheses. For example, Habash and Roth (2011) use a variety of linguistic (morphological and syntactic) and non-linguistic features to automatically identify errors in OCR hypotheses. Another example presented by Devlin et al. (2012) shows that using a statistical machine translation system to assess the difficulty of translating an Arabic OCR hypothesis into English gives valuable feedback on OCR quality. Therefore, combining additional information with the LMs could reduce recognition errors. However, direct integration of such information in the decoder is difficult. A straightforward alternative which we advocate in this paper is to use the available information to rerank the hypotheses in the n-best lists. The new top ranked hypothesis is considered as the new output of the system. We propose combining LMs with lingu</context>
</contexts>
<marker>Devlin, Kamali, Subramanian, Prasad, Natarajan, 2012</marker>
<rawString>Jacob Devlin, Matin Kamali, Krishna Subramanian, Rohit Prasad, and Prem Natarajan. 2012. Statistical Machine Translation as a Language Model for Handwriting Recognition. In ICFHR, pages 291– 296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Dinarelli</author>
<author>Alessandro Moschitti</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Discriminative Reranking for Spoken Language Understanding.</title>
<date>2012</date>
<journal>IEEE Transactions on Audio, Speech &amp; Language Processing,</journal>
<volume>20</volume>
<issue>2</issue>
<contexts>
<context position="3339" citStr="Dinarelli et al., 2012" startWordPosition="502" endWordPosition="505">lly motivated features using learning to rank methods. Discriminative reranking allows each hypothesis to be represented as an arbitrary set of features without the need to explicitly model their interactions. Therefore, the system benefits from global and potentially complex features which are not available to the baseline OCR decoder. This approach has successfully been applied in numerous Natural Language Processing (NLP) tasks including syntactic parsing (Collins and Koo, 2005), semantic parsing (Ge and Mooney, 2006), machine translation (Shen et al., 2004), spoken language understanding (Dinarelli et al., 2012), etc. Furthermore, we propose to combine several ranking methods into an ensemble which learns from their predictions to further reduce recognition errors. We describe our features and reranking approach in §2, and we present our experiments and results in §3. 2 Discriminative Reranking for OCR Each hypothesis in an n-best list {hi}ni=1 is represented by a d-dimensional feature vector xi E Rd. Each xi is associated with a loss li to generate a labeled n-best list H = {(xi, li)}ni=1. The loss is computed as the Word Error Rate (WER) of the 549 Proceedings of the 51st Annual Meeting of the Asso</context>
</contexts>
<marker>Dinarelli, Moschitti, Riccardi, 2012</marker>
<rawString>Marco Dinarelli, Alessandro Moschitti, and Giuseppe Riccardi. 2012. Discriminative Reranking for Spoken Language Understanding. IEEE Transactions on Audio, Speech &amp; Language Processing, 20(2):526–539.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Freund</author>
<author>Raj Iyer</author>
<author>Robert E Schapire</author>
<author>Yoram Singer</author>
</authors>
<title>An efficient boosting algorithm for combining preferences.</title>
<date>2003</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>4--933</pages>
<contexts>
<context position="5732" citStr="Freund et al., 2003" startWordPosition="875" endWordPosition="878">use several methods from this category. RankSVM (Joachims, 2002) is a method based on Support Vector Machines (SVMs) for which we use only linear kernels to keep complexity low. Exact optimization of the RankSVM objective can be computationally expensive as the number of hypothesis pairs can be very large. Approximate stochastic training strategies reduces complexity and produce comparable performance. Therefore, in addition to RankSVM, we use stochastic sub-gradient descent (SGDSVM), Pegasos (PegasosSVM) and Passive-Aggressive Perceptron (PAPSVM) as implemented in Sculley (2009).2 RankBoost (Freund et al., 2003) is a pairwise boosting approach implemented in RankLib. It uses a linear combination of weak rankers, each of which is a binary function associated with a single feature. This function is 1 when the feature value exceeds some threshold and 0 otherwise. RankMIRA is a ranking method presented in (Le Roux et al., 2012).3 It uses a weighted linear combination of features which assigns the highest 1http://people.cs.umass.edu/˜vdang/ ranklib.html 2http://code.google.com/p/sofia-ml 3https://github.com/jihelhere/ adMIRAble score to the hypotheses with the lowest loss. During training, the weights are</context>
</contexts>
<marker>Freund, Iyer, Schapire, Singer, 2003</marker>
<rawString>Yoav Freund, Raj Iyer, Robert E. Schapire, and Yoram Singer. 2003. An efficient boosting algorithm for combining preferences. J. Mach. Learn. Res., 4:933–969, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerome H Friedman</author>
</authors>
<title>Greedy Function Approximation: A Gradient Boosting Machine. Annals of Statistics,</title>
<date>2000</date>
<pages>29--1189</pages>
<contexts>
<context position="4805" citStr="Friedman, 2000" startWordPosition="738" endWordPosition="739"> k=1. 2.1 Learning to rank approaches Major approaches to learning to rank can be divided into pointwise score regression, pairwise preference satisfaction, and listwise structured learning. See Liu (2009) for a survey. In this paper, we explore all of the following learning to rank approaches. Pointwise In the pointwise approach, the ranking problem is formulated as a regression, or ordinal classification, for which any existing method can be applied. Each hypothesis constitutes a learning instance. In this category we use a regression method called Multiple Additive Regression Trees (MART) (Friedman, 2000) as implemented in RankLib.1 The major problem with pointwise approaches is that the structure of the list of hypotheses is ignored. Pairwise The pairwise approach takes pairs of hypotheses as instances in learning, and formalizes the ranking problem as a pairwise classification or pairwise regression. We use several methods from this category. RankSVM (Joachims, 2002) is a method based on Support Vector Machines (SVMs) for which we use only linear kernels to keep complexity low. Exact optimization of the RankSVM objective can be computationally expensive as the number of hypothesis pairs can </context>
</contexts>
<marker>Friedman, 2000</marker>
<rawString>Jerome H. Friedman. 2000. Greedy Function Approximation: A Gradient Boosting Machine. Annals of Statistics, 29:1189–1232.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruifang Ge</author>
<author>Raymond J Mooney</author>
</authors>
<title>Discriminative Reranking for Semantic Parsing.</title>
<date>2006</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="3242" citStr="Ge and Mooney, 2006" startWordPosition="489" endWordPosition="492">ed as the new output of the system. We propose combining LMs with linguistically and semantically motivated features using learning to rank methods. Discriminative reranking allows each hypothesis to be represented as an arbitrary set of features without the need to explicitly model their interactions. Therefore, the system benefits from global and potentially complex features which are not available to the baseline OCR decoder. This approach has successfully been applied in numerous Natural Language Processing (NLP) tasks including syntactic parsing (Collins and Koo, 2005), semantic parsing (Ge and Mooney, 2006), machine translation (Shen et al., 2004), spoken language understanding (Dinarelli et al., 2012), etc. Furthermore, we propose to combine several ranking methods into an ensemble which learns from their predictions to further reduce recognition errors. We describe our features and reranking approach in §2, and we present our experiments and results in §3. 2 Discriminative Reranking for OCR Each hypothesis in an n-best list {hi}ni=1 is represented by a d-dimensional feature vector xi E Rd. Each xi is associated with a loss li to generate a labeled n-best list H = {(xi, li)}ni=1. The loss is co</context>
</contexts>
<marker>Ge, Mooney, 2006</marker>
<rawString>Ruifang Ge and Raymond J. Mooney. 2006. Discriminative Reranking for Semantic Parsing. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Graff</author>
</authors>
<date>2007</date>
<booktitle>Arabic Gigaword 3, LDC Catalog No.: LDC2003T40. Linguistic</booktitle>
<institution>Data Consortium, University of Pennsylvania.</institution>
<contexts>
<context position="9963" citStr="Graff, 2007" startWordPosition="1552" endWordPosition="1553">ned confidence. We also use the average word length and the number of content words (normalized by the hypothesis length). We define “content words” as non-punctuation and non-digit words. Additionally, we use a set of binary features indicating if the hypothesis contains a sequence of duplicated characters, a date-like sequence and an occurrence of a specific character class (punctuation, alphabetic and digit). Word LM features (“LM-word”) include the log probabilities of the hypothesis obtained using n-gram LMs with n E 11, ... , 5}. Separate LMs are trained on the Arabic Gigaword 3 corpus (Graff, 2007), and on the reference transcriptions of the training data (see §3.1). The LM models are built using the SRI Language Modeling Toolkit (Stolcke, 2002). Linguistic LM features (“LM-MADA”) are similar to the word LM features except that they are computed using the part-of-speech and the lemma of the words instead of the actual words.6 Semantic coherence feature (“SemCoh”) is motivated by the fact that semantic information can be very useful in modeling the fluency of phrases, and can augment the information provided by n-gram LMs. In modeling contextual 4RankSVM has also been shown to be a good </context>
</contexts>
<marker>Graff, 2007</marker>
<rawString>David Graff. 2007. Arabic Gigaword 3, LDC Catalog No.: LDC2003T40. Linguistic Data Consortium, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>573--580</pages>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="10885" citStr="Habash and Rambow, 2005" startWordPosition="1701" endWordPosition="1704">words instead of the actual words.6 Semantic coherence feature (“SemCoh”) is motivated by the fact that semantic information can be very useful in modeling the fluency of phrases, and can augment the information provided by n-gram LMs. In modeling contextual 4RankSVM has also been shown to be a good choice for the meta-learner in general stacking ensemble learning (Tang et al., 2010). 5The baseline ranking is simply based on the sum of the logs of the HMM and LM scores. 6The part-of-speech and the lemmas are obtained using MADA 3.0, a tool for Arabic morphological analysis and disambiguation (Habash and Rambow, 2005; Habash et al., 2009). lexical semantic information, simple bag-of-words models usually have a lot of noise; while more sophisticated models considering positional information have sparsity issues. To strike a balance between these two extremes, we introduce a novel model of semantic coherence that is based on a measure of semantic relatedness between pairs of words. We model semantic relatedness between two words using the Information Content (IC) of the pair in a method similar to the one used by Lin (1997) and Lin (1998). IC(w1, d, w2) = log f(w1, d, w2)f(*, d, *) f(w1,d,*)f(*,d,w2) Here, </context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow. 2005. Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 573– 580, Ann Arbor, Michigan, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ryan M Roth</author>
</authors>
<title>Using deep morphology to improve automatic error detection in Arabic handwriting recognition.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>875--884</pages>
<contexts>
<context position="1905" citStr="Habash and Roth (2011)" startWordPosition="283" endWordPosition="286">ave been developed (M¨argner and Abed, 2009). The BBN Byblos OCR system (Natajan et al., 2002; Prasad et al., 2008; Saleem et al., 2009), which we use in this paper, relies on a hidden Markov model (HMM) to recover the sequence of characters from the image, and uses an n-gram language model (LM) to emphasize the fluency of the output. For an input image, the OCR decoder generates an nbest list of hypotheses each of which is associated with HMM and LM scores. In addition to fluency as evaluated by LMs, other information potentially helps in discriminating good from bad hypotheses. For example, Habash and Roth (2011) use a variety of linguistic (morphological and syntactic) and non-linguistic features to automatically identify errors in OCR hypotheses. Another example presented by Devlin et al. (2012) shows that using a statistical machine translation system to assess the difficulty of translating an Arabic OCR hypothesis into English gives valuable feedback on OCR quality. Therefore, combining additional information with the LMs could reduce recognition errors. However, direct integration of such information in the decoder is difficult. A straightforward alternative which we advocate in this paper is to </context>
<context position="9281" citStr="Habash and Roth, 2011" startWordPosition="1440" endWordPosition="1443">l as a base-ranker. 2.3 Features Our features fall into five families. Base features include the HMM and LM scores produced by the OCR system. These features are used by the baseline system5 as well as by the various reranking methods. Simple features (“simple”) include the baseline rank of the hypothesis and a 0-to-1 range normalized version of it. We also use a hypothesis confidence feature which corresponds to the average of the confidence of individual words in the hypothesis; “confidence” for a given word is computed as the fraction of hypotheses in the n-best list that contain the word (Habash and Roth, 2011). The more consensus words a hypothesis contains, the higher its assigned confidence. We also use the average word length and the number of content words (normalized by the hypothesis length). We define “content words” as non-punctuation and non-digit words. Additionally, we use a set of binary features indicating if the hypothesis contains a sequence of duplicated characters, a date-like sequence and an occurrence of a specific character class (punctuation, alphabetic and digit). Word LM features (“LM-word”) include the log probabilities of the hypothesis obtained using n-gram LMs with n E 11</context>
</contexts>
<marker>Habash, Roth, 2011</marker>
<rawString>Nizar Habash and Ryan M. Roth. 2011. Using deep morphology to improve automatic error detection in Arabic handwriting recognition. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 875–884.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Ryan Roth</author>
</authors>
<title>MADA+TOKAN: A toolkit for Arabic tokenization, diacritization, morphological disambiguation, POS tagging, stemming and lemmatization.</title>
<date>2009</date>
<booktitle>In Khalid Choukri and Bente Maegaard, editors, Proceedings of the Second International Conference on Arabic Language Resources and Tools. The MEDAR Consortium,</booktitle>
<contexts>
<context position="10907" citStr="Habash et al., 2009" startWordPosition="1705" endWordPosition="1708">al words.6 Semantic coherence feature (“SemCoh”) is motivated by the fact that semantic information can be very useful in modeling the fluency of phrases, and can augment the information provided by n-gram LMs. In modeling contextual 4RankSVM has also been shown to be a good choice for the meta-learner in general stacking ensemble learning (Tang et al., 2010). 5The baseline ranking is simply based on the sum of the logs of the HMM and LM scores. 6The part-of-speech and the lemmas are obtained using MADA 3.0, a tool for Arabic morphological analysis and disambiguation (Habash and Rambow, 2005; Habash et al., 2009). lexical semantic information, simple bag-of-words models usually have a lot of noise; while more sophisticated models considering positional information have sparsity issues. To strike a balance between these two extremes, we introduce a novel model of semantic coherence that is based on a measure of semantic relatedness between pairs of words. We model semantic relatedness between two words using the Information Content (IC) of the pair in a method similar to the one used by Lin (1997) and Lin (1998). IC(w1, d, w2) = log f(w1, d, w2)f(*, d, *) f(w1,d,*)f(*,d,w2) Here, d can generally repres</context>
</contexts>
<marker>Habash, Rambow, Roth, 2009</marker>
<rawString>Nizar Habash, Owen Rambow, and Ryan Roth. 2009. MADA+TOKAN: A toolkit for Arabic tokenization, diacritization, morphological disambiguation, POS tagging, stemming and lemmatization. In Khalid Choukri and Bente Maegaard, editors, Proceedings of the Second International Conference on Arabic Language Resources and Tools. The MEDAR Consortium, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Introduction to Arabic Natural Language Processing.</title>
<date>2010</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="1247" citStr="Habash, 2010" startWordPosition="169" endWordPosition="170"> features to an existing OCR system. To do so we follow an n-best list reranking approach that exploits recent advances in learning to rank techniques. We achieve 10.1% and 11.4% reduction in recognition word error rate (WER) relative to a standard baseline system on typewritten and handwritten Arabic respectively. 1 Introduction Optical Character Recognition (OCR) is the task of converting scanned images of handwritten, typewritten or printed text into machine-encoded text. Arabic OCR is a challenging problem due to Arabic’s connected letter forms, consonantal diacritics and rich morphology (Habash, 2010). Therefore only a few OCR systems have been developed (M¨argner and Abed, 2009). The BBN Byblos OCR system (Natajan et al., 2002; Prasad et al., 2008; Saleem et al., 2009), which we use in this paper, relies on a hidden Markov model (HMM) to recover the sequence of characters from the image, and uses an n-gram language model (LM) to emphasize the fluency of the output. For an input image, the OCR decoder generates an nbest list of hypotheses each of which is associated with HMM and LM scores. In addition to fluency as evaluated by LMs, other information potentially helps in discriminating goo</context>
</contexts>
<marker>Habash, 2010</marker>
<rawString>Nizar Habash. 2010. Introduction to Arabic Natural Language Processing. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Optimizing search engines using clickthrough data.</title>
<date>2002</date>
<booktitle>In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’02,</booktitle>
<pages>133--142</pages>
<contexts>
<context position="5176" citStr="Joachims, 2002" startWordPosition="797" endWordPosition="798"> regression, or ordinal classification, for which any existing method can be applied. Each hypothesis constitutes a learning instance. In this category we use a regression method called Multiple Additive Regression Trees (MART) (Friedman, 2000) as implemented in RankLib.1 The major problem with pointwise approaches is that the structure of the list of hypotheses is ignored. Pairwise The pairwise approach takes pairs of hypotheses as instances in learning, and formalizes the ranking problem as a pairwise classification or pairwise regression. We use several methods from this category. RankSVM (Joachims, 2002) is a method based on Support Vector Machines (SVMs) for which we use only linear kernels to keep complexity low. Exact optimization of the RankSVM objective can be computationally expensive as the number of hypothesis pairs can be very large. Approximate stochastic training strategies reduces complexity and produce comparable performance. Therefore, in addition to RankSVM, we use stochastic sub-gradient descent (SGDSVM), Pegasos (PegasosSVM) and Passive-Aggressive Perceptron (PAPSVM) as implemented in Sculley (2009).2 RankBoost (Freund et al., 2003) is a pairwise boosting approach implemented</context>
</contexts>
<marker>Joachims, 2002</marker>
<rawString>Thorsten Joachims. 2002. Optimizing search engines using clickthrough data. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’02, pages 133–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Kolb</author>
</authors>
<title>Experiments on the difference between semantic similarity and relatedness.</title>
<date>2009</date>
<booktitle>In Proceedings of the 17th Nordic Conference of Computational Linguistics, NEALT Proceedings Series</booktitle>
<volume>4</volume>
<contexts>
<context position="12118" citStr="Kolb (2009)" startWordPosition="1921" endWordPosition="1922">ent some form of relation between w1 and w2. Whereas Lin (1997) and Lin (1998) used dependency relation between words, we use distance. Given a sentence, the distance between w1 and w2 is one plus the number of words that are seen after w1 and before w2 in that sentence. Hence, f(w1, d, w2) is the number of times w1 occurs before w2 at a distance d in all the sentences in a corpus. * is a placeholder for any word, i.e., f(*, d, *) is the frequency of all word pairs occurring at distance d. The distances are directional and not absolute values. A similar measure of relatedness was also used by Kolb (2009). We estimate the frequencies from the Arabic Gigaword. We set the window size to 3 and calculate IC values of all pairs of words occurring at distance within the window size. Since the distances are directional, it has to be noted that given a word, its relations with three words before it and three words after it are modeled. During testing, for each phrase in our test set, we measure semantic relatedness of pairs of words using the IC values estimated from the Arabic Gigaword, and normalize their sum by the number of pairs in the phrase to obtain a measure of Semantic Coherence (SC) of the </context>
</contexts>
<marker>Kolb, 2009</marker>
<rawString>Peter Kolb. 2009. Experiments on the difference between semantic similarity and relatedness. In Proceedings of the 17th Nordic Conference of Computational Linguistics, NEALT Proceedings Series Vol. 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Le Roux</author>
<author>Benoit Favre</author>
</authors>
<title>Alexis Nasr, and Seyed Abolghasem Mirroshandel.</title>
<date>2012</date>
<marker>Le Roux, Favre, 2012</marker>
<rawString>Joseph Le Roux, Benoit Favre, Alexis Nasr, and Seyed Abolghasem Mirroshandel. 2012. Generative Constituent Parsing and Discriminative Dependency Reranking: Experiments on English and French. In SP-SEM-MRL 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Using syntactic dependency as local context to resolve word sense ambiguity.</title>
<date>1997</date>
<booktitle>In Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics, EACL ’97,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="11400" citStr="Lin (1997)" startWordPosition="1785" endWordPosition="1786"> MADA 3.0, a tool for Arabic morphological analysis and disambiguation (Habash and Rambow, 2005; Habash et al., 2009). lexical semantic information, simple bag-of-words models usually have a lot of noise; while more sophisticated models considering positional information have sparsity issues. To strike a balance between these two extremes, we introduce a novel model of semantic coherence that is based on a measure of semantic relatedness between pairs of words. We model semantic relatedness between two words using the Information Content (IC) of the pair in a method similar to the one used by Lin (1997) and Lin (1998). IC(w1, d, w2) = log f(w1, d, w2)f(*, d, *) f(w1,d,*)f(*,d,w2) Here, d can generally represent some form of relation between w1 and w2. Whereas Lin (1997) and Lin (1998) used dependency relation between words, we use distance. Given a sentence, the distance between w1 and w2 is one plus the number of words that are seen after w1 and before w2 in that sentence. Hence, f(w1, d, w2) is the number of times w1 occurs before w2 at a distance d in all the sentences in a corpus. * is a placeholder for any word, i.e., f(*, d, *) is the frequency of all word pairs occurring at distance d</context>
</contexts>
<marker>Lin, 1997</marker>
<rawString>Dekang Lin. 1997. Using syntactic dependency as local context to resolve word sense ambiguity. In Proceedings of the eighth conference on European chapter of the Association for Computational Linguistics, EACL ’97, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics - Volume 2, ACL ’98.</booktitle>
<contexts>
<context position="11415" citStr="Lin (1998)" startWordPosition="1788" endWordPosition="1789">ol for Arabic morphological analysis and disambiguation (Habash and Rambow, 2005; Habash et al., 2009). lexical semantic information, simple bag-of-words models usually have a lot of noise; while more sophisticated models considering positional information have sparsity issues. To strike a balance between these two extremes, we introduce a novel model of semantic coherence that is based on a measure of semantic relatedness between pairs of words. We model semantic relatedness between two words using the Information Content (IC) of the pair in a method similar to the one used by Lin (1997) and Lin (1998). IC(w1, d, w2) = log f(w1, d, w2)f(*, d, *) f(w1,d,*)f(*,d,w2) Here, d can generally represent some form of relation between w1 and w2. Whereas Lin (1997) and Lin (1998) used dependency relation between words, we use distance. Given a sentence, the distance between w1 and w2 is one plus the number of words that are seen after w1 and before w2 in that sentence. Hence, f(w1, d, w2) is the number of times w1 occurs before w2 at a distance d in all the sentences in a corpus. * is a placeholder for any word, i.e., f(*, d, *) is the frequency of all word pairs occurring at distance d. The distances</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics - Volume 2, ACL ’98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tie-Yan Liu</author>
</authors>
<title>Learning to Rank for Information Retrieval.</title>
<date>2009</date>
<publisher>Now Publishers Inc.,</publisher>
<location>Hanover, MA, USA.</location>
<contexts>
<context position="4395" citStr="Liu (2009)" startWordPosition="673" endWordPosition="674"> a labeled n-best list H = {(xi, li)}ni=1. The loss is computed as the Word Error Rate (WER) of the 549 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 549–555, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics hypotheses compared to a reference transcription. For supervised training we use a set of n-best lists H = {H(k)}M k=1. 2.1 Learning to rank approaches Major approaches to learning to rank can be divided into pointwise score regression, pairwise preference satisfaction, and listwise structured learning. See Liu (2009) for a survey. In this paper, we explore all of the following learning to rank approaches. Pointwise In the pointwise approach, the ranking problem is formulated as a regression, or ordinal classification, for which any existing method can be applied. Each hypothesis constitutes a learning instance. In this category we use a regression method called Multiple Additive Regression Trees (MART) (Friedman, 2000) as implemented in RankLib.1 The major problem with pointwise approaches is that the structure of the list of hypotheses is ignored. Pairwise The pairwise approach takes pairs of hypotheses </context>
</contexts>
<marker>Liu, 2009</marker>
<rawString>Tie-Yan Liu. 2009. Learning to Rank for Information Retrieval. Now Publishers Inc., Hanover, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Volker M¨argner</author>
<author>Haikal El Abed</author>
</authors>
<title>Arabic Word and Text Recognition - Current Developments.</title>
<date>2009</date>
<booktitle>In Khalid Choukri and Bente Maegaard, editors, Proceedings of the Second International Conference on Arabic Language Resources and Tools,</booktitle>
<publisher>The MEDAR Consortium.</publisher>
<location>Cairo, Egypt,</location>
<marker>M¨argner, El Abed, 2009</marker>
<rawString>Volker M¨argner and Haikal El Abed. 2009. Arabic Word and Text Recognition - Current Developments. In Khalid Choukri and Bente Maegaard, editors, Proceedings of the Second International Conference on Arabic Language Resources and Tools, Cairo, Egypt, April. The MEDAR Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Metzler</author>
<author>W Bruce Croft</author>
</authors>
<title>Linear feature-based models for information retrieval.</title>
<date>2007</date>
<journal>Inf. Retr.,</journal>
<volume>10</volume>
<issue>3</issue>
<marker>Metzler, Croft, 2007</marker>
<rawString>Donald Metzler and W. Bruce Croft. 2007. Linear feature-based models for information retrieval. Inf. Retr., 10(3):257–274, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Premkumar Natajan</author>
<author>Zhidong Lu</author>
<author>Richard Schwartz</author>
<author>Issam Bazzi</author>
<author>John Makhoul</author>
</authors>
<title>Hidden Markov models. chapter Multilingual machine printed OCR,</title>
<date>2002</date>
<pages>43--63</pages>
<publisher>World Scientific Publishing Co., Inc.,</publisher>
<location>River Edge, NJ, USA.</location>
<contexts>
<context position="1376" citStr="Natajan et al., 2002" startWordPosition="190" endWordPosition="193"> learning to rank techniques. We achieve 10.1% and 11.4% reduction in recognition word error rate (WER) relative to a standard baseline system on typewritten and handwritten Arabic respectively. 1 Introduction Optical Character Recognition (OCR) is the task of converting scanned images of handwritten, typewritten or printed text into machine-encoded text. Arabic OCR is a challenging problem due to Arabic’s connected letter forms, consonantal diacritics and rich morphology (Habash, 2010). Therefore only a few OCR systems have been developed (M¨argner and Abed, 2009). The BBN Byblos OCR system (Natajan et al., 2002; Prasad et al., 2008; Saleem et al., 2009), which we use in this paper, relies on a hidden Markov model (HMM) to recover the sequence of characters from the image, and uses an n-gram language model (LM) to emphasize the fluency of the output. For an input image, the OCR decoder generates an nbest list of hypotheses each of which is associated with HMM and LM scores. In addition to fluency as evaluated by LMs, other information potentially helps in discriminating good from bad hypotheses. For example, Habash and Roth (2011) use a variety of linguistic (morphological and syntactic) and non-ling</context>
<context position="13799" citStr="Natajan et al., 2002" startWordPosition="2234" endWordPosition="2237">f n-best lists, n is the average size of the lists, and |h |is the average length of a hypothesis. print hand Baseline 13.8% 35% Oracle 9.8% 20.9% Best result 12.4% 30.9% Table 2: WER for baseline, oracle and best reranked hypotheses. 3 Experiments 3.1 Data and baselines We used two data sets derived from highresolution image scans of typewritten and handwritten Arabic text along with ground truth transcriptions.7 The BBN Byblos system was then used to process these scanned images into sequences of segments (sentence fragments) and generate a ranked n-best list of hypotheses for each segment (Natajan et al., 2002; Prasad et al., 2008; Saleem et al., 2009). We divided each of the typewritten data set (“print”) and handwritten data set (“hand”) into three disjoint parts: a training set for the base-rankers Wb, a training set for the metaranker Wm and a test set Wt. Table 1 presents some statistics about these data sets. Our baseline is based on the sum of the logs of the HMM and LM scores. Table 2 presents the WER for our baseline hypothesis, the best hypothesis in the list (our oracle) and our best reranking results which we describe in details in §3.2. For LM training we used 220M words from Arabic Gi</context>
</contexts>
<marker>Natajan, Lu, Schwartz, Bazzi, Makhoul, 2002</marker>
<rawString>Premkumar Natajan, Zhidong Lu, Richard Schwartz, Issam Bazzi, and John Makhoul. 2002. Hidden Markov models. chapter Multilingual machine printed OCR, pages 43–63. World Scientific Publishing Co., Inc., River Edge, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rohit Prasad</author>
<author>Shirin Saleem</author>
<author>Matin Kamali</author>
<author>Ralf Meermeier</author>
<author>Premkumar Natarajan</author>
</authors>
<title>Improvements in hidden Markov model based Arabic OCR.</title>
<date>2008</date>
<booktitle>In Proceedings of International Conference on Pattern Recognition (ICPR),</booktitle>
<pages>1--4</pages>
<contexts>
<context position="1397" citStr="Prasad et al., 2008" startWordPosition="194" endWordPosition="197">niques. We achieve 10.1% and 11.4% reduction in recognition word error rate (WER) relative to a standard baseline system on typewritten and handwritten Arabic respectively. 1 Introduction Optical Character Recognition (OCR) is the task of converting scanned images of handwritten, typewritten or printed text into machine-encoded text. Arabic OCR is a challenging problem due to Arabic’s connected letter forms, consonantal diacritics and rich morphology (Habash, 2010). Therefore only a few OCR systems have been developed (M¨argner and Abed, 2009). The BBN Byblos OCR system (Natajan et al., 2002; Prasad et al., 2008; Saleem et al., 2009), which we use in this paper, relies on a hidden Markov model (HMM) to recover the sequence of characters from the image, and uses an n-gram language model (LM) to emphasize the fluency of the output. For an input image, the OCR decoder generates an nbest list of hypotheses each of which is associated with HMM and LM scores. In addition to fluency as evaluated by LMs, other information potentially helps in discriminating good from bad hypotheses. For example, Habash and Roth (2011) use a variety of linguistic (morphological and syntactic) and non-linguistic features to au</context>
<context position="13820" citStr="Prasad et al., 2008" startWordPosition="2238" endWordPosition="2241">he average size of the lists, and |h |is the average length of a hypothesis. print hand Baseline 13.8% 35% Oracle 9.8% 20.9% Best result 12.4% 30.9% Table 2: WER for baseline, oracle and best reranked hypotheses. 3 Experiments 3.1 Data and baselines We used two data sets derived from highresolution image scans of typewritten and handwritten Arabic text along with ground truth transcriptions.7 The BBN Byblos system was then used to process these scanned images into sequences of segments (sentence fragments) and generate a ranked n-best list of hypotheses for each segment (Natajan et al., 2002; Prasad et al., 2008; Saleem et al., 2009). We divided each of the typewritten data set (“print”) and handwritten data set (“hand”) into three disjoint parts: a training set for the base-rankers Wb, a training set for the metaranker Wm and a test set Wt. Table 1 presents some statistics about these data sets. Our baseline is based on the sum of the logs of the HMM and LM scores. Table 2 presents the WER for our baseline hypothesis, the best hypothesis in the list (our oracle) and our best reranking results which we describe in details in §3.2. For LM training we used 220M words from Arabic Gigaword 3, and 2.4M wo</context>
</contexts>
<marker>Prasad, Saleem, Kamali, Meermeier, Natarajan, 2008</marker>
<rawString>Rohit Prasad, Shirin Saleem, Matin Kamali, Ralf Meermeier, and Premkumar Natarajan. 2008. Improvements in hidden Markov model based Arabic OCR. In Proceedings of International Conference on Pattern Recognition (ICPR), pages 1–4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shirin Saleem</author>
<author>Huaigu Cao</author>
<author>Krishna Subramanian</author>
<author>Matin Kamali</author>
<author>Rohit Prasad</author>
<author>Prem Natarajan</author>
</authors>
<title>Improvements in BBN’s HMM-Based Offline Arabic Handwriting Recognition System.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 10th International Conference on Document Analysis and Recognition, ICDAR ’09,</booktitle>
<pages>773--777</pages>
<contexts>
<context position="1419" citStr="Saleem et al., 2009" startWordPosition="198" endWordPosition="201">.1% and 11.4% reduction in recognition word error rate (WER) relative to a standard baseline system on typewritten and handwritten Arabic respectively. 1 Introduction Optical Character Recognition (OCR) is the task of converting scanned images of handwritten, typewritten or printed text into machine-encoded text. Arabic OCR is a challenging problem due to Arabic’s connected letter forms, consonantal diacritics and rich morphology (Habash, 2010). Therefore only a few OCR systems have been developed (M¨argner and Abed, 2009). The BBN Byblos OCR system (Natajan et al., 2002; Prasad et al., 2008; Saleem et al., 2009), which we use in this paper, relies on a hidden Markov model (HMM) to recover the sequence of characters from the image, and uses an n-gram language model (LM) to emphasize the fluency of the output. For an input image, the OCR decoder generates an nbest list of hypotheses each of which is associated with HMM and LM scores. In addition to fluency as evaluated by LMs, other information potentially helps in discriminating good from bad hypotheses. For example, Habash and Roth (2011) use a variety of linguistic (morphological and syntactic) and non-linguistic features to automatically identify e</context>
<context position="13842" citStr="Saleem et al., 2009" startWordPosition="2242" endWordPosition="2245">e lists, and |h |is the average length of a hypothesis. print hand Baseline 13.8% 35% Oracle 9.8% 20.9% Best result 12.4% 30.9% Table 2: WER for baseline, oracle and best reranked hypotheses. 3 Experiments 3.1 Data and baselines We used two data sets derived from highresolution image scans of typewritten and handwritten Arabic text along with ground truth transcriptions.7 The BBN Byblos system was then used to process these scanned images into sequences of segments (sentence fragments) and generate a ranked n-best list of hypotheses for each segment (Natajan et al., 2002; Prasad et al., 2008; Saleem et al., 2009). We divided each of the typewritten data set (“print”) and handwritten data set (“hand”) into three disjoint parts: a training set for the base-rankers Wb, a training set for the metaranker Wm and a test set Wt. Table 1 presents some statistics about these data sets. Our baseline is based on the sum of the logs of the HMM and LM scores. Table 2 presents the WER for our baseline hypothesis, the best hypothesis in the list (our oracle) and our best reranking results which we describe in details in §3.2. For LM training we used 220M words from Arabic Gigaword 3, and 2.4M words from each “print” </context>
</contexts>
<marker>Saleem, Cao, Subramanian, Kamali, Prasad, Natarajan, 2009</marker>
<rawString>Shirin Saleem, Huaigu Cao, Krishna Subramanian, Matin Kamali, Rohit Prasad, and Prem Natarajan. 2009. Improvements in BBN’s HMM-Based Offline Arabic Handwriting Recognition System. In Proceedings of the 2009 10th International Conference on Document Analysis and Recognition, ICDAR ’09, pages 773–777.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Sculley</author>
</authors>
<title>Large scale learning to rank.</title>
<date>2009</date>
<booktitle>In NIPS 2009 Workshop on Advances in Ranking.</booktitle>
<contexts>
<context position="5698" citStr="Sculley (2009)" startWordPosition="872" endWordPosition="873"> or pairwise regression. We use several methods from this category. RankSVM (Joachims, 2002) is a method based on Support Vector Machines (SVMs) for which we use only linear kernels to keep complexity low. Exact optimization of the RankSVM objective can be computationally expensive as the number of hypothesis pairs can be very large. Approximate stochastic training strategies reduces complexity and produce comparable performance. Therefore, in addition to RankSVM, we use stochastic sub-gradient descent (SGDSVM), Pegasos (PegasosSVM) and Passive-Aggressive Perceptron (PAPSVM) as implemented in Sculley (2009).2 RankBoost (Freund et al., 2003) is a pairwise boosting approach implemented in RankLib. It uses a linear combination of weak rankers, each of which is a binary function associated with a single feature. This function is 1 when the feature value exceeds some threshold and 0 otherwise. RankMIRA is a ranking method presented in (Le Roux et al., 2012).3 It uses a weighted linear combination of features which assigns the highest 1http://people.cs.umass.edu/˜vdang/ ranklib.html 2http://code.google.com/p/sofia-ml 3https://github.com/jihelhere/ adMIRAble score to the hypotheses with the lowest loss</context>
</contexts>
<marker>Sculley, 2009</marker>
<rawString>D. Sculley. 2009. Large scale learning to rank. In NIPS 2009 Workshop on Advances in Ranking.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Anoop Sarkar</author>
<author>Franz Josef Och</author>
</authors>
<title>Discriminative Reranking for Machine Translation.</title>
<date>2004</date>
<booktitle>HLT-NAACL 2004: Main Proceedings,</booktitle>
<pages>177--184</pages>
<editor>In Daniel Marcu Susan Dumais and Salim Roukos, editors,</editor>
<location>Boston, Massachusetts, USA,</location>
<contexts>
<context position="3283" citStr="Shen et al., 2004" startWordPosition="495" endWordPosition="498">ose combining LMs with linguistically and semantically motivated features using learning to rank methods. Discriminative reranking allows each hypothesis to be represented as an arbitrary set of features without the need to explicitly model their interactions. Therefore, the system benefits from global and potentially complex features which are not available to the baseline OCR decoder. This approach has successfully been applied in numerous Natural Language Processing (NLP) tasks including syntactic parsing (Collins and Koo, 2005), semantic parsing (Ge and Mooney, 2006), machine translation (Shen et al., 2004), spoken language understanding (Dinarelli et al., 2012), etc. Furthermore, we propose to combine several ranking methods into an ensemble which learns from their predictions to further reduce recognition errors. We describe our features and reranking approach in §2, and we present our experiments and results in §3. 2 Discriminative Reranking for OCR Each hypothesis in an n-best list {hi}ni=1 is represented by a d-dimensional feature vector xi E Rd. Each xi is associated with a loss li to generate a labeled n-best list H = {(xi, li)}ni=1. The loss is computed as the Word Error Rate (WER) of th</context>
</contexts>
<marker>Shen, Sarkar, Och, 2004</marker>
<rawString>Libin Shen, Anoop Sarkar, and Franz Josef Och. 2004. Discriminative Reranking for Machine Translation. In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLT-NAACL 2004: Main Proceedings, pages 177–184, Boston, Massachusetts, USA, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing (ICSLP),</booktitle>
<volume>2</volume>
<pages>901--904</pages>
<location>Denver, CO.</location>
<contexts>
<context position="10113" citStr="Stolcke, 2002" startWordPosition="1576" endWordPosition="1577"> as non-punctuation and non-digit words. Additionally, we use a set of binary features indicating if the hypothesis contains a sequence of duplicated characters, a date-like sequence and an occurrence of a specific character class (punctuation, alphabetic and digit). Word LM features (“LM-word”) include the log probabilities of the hypothesis obtained using n-gram LMs with n E 11, ... , 5}. Separate LMs are trained on the Arabic Gigaword 3 corpus (Graff, 2007), and on the reference transcriptions of the training data (see §3.1). The LM models are built using the SRI Language Modeling Toolkit (Stolcke, 2002). Linguistic LM features (“LM-MADA”) are similar to the word LM features except that they are computed using the part-of-speech and the lemma of the words instead of the actual words.6 Semantic coherence feature (“SemCoh”) is motivated by the fact that semantic information can be very useful in modeling the fluency of phrases, and can augment the information provided by n-gram LMs. In modeling contextual 4RankSVM has also been shown to be a good choice for the meta-learner in general stacking ensemble learning (Tang et al., 2010). 5The baseline ranking is simply based on the sum of the logs of</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an Extensible Language Modeling Toolkit. In Proceedings of the International Conference on Spoken Language Processing (ICSLP), volume 2, pages 901–904, Denver, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Buzhou Tang</author>
<author>Qingcai Chen</author>
<author>Xuan Wang</author>
<author>Xiaolong Wang</author>
</authors>
<title>Reranking for stacking ensemble learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 17th international conference on Neural information processing: theory and algorithms - Volume Part I, ICONIP’10,</booktitle>
<pages>575--584</pages>
<contexts>
<context position="10648" citStr="Tang et al., 2010" startWordPosition="1661" endWordPosition="1664">1). The LM models are built using the SRI Language Modeling Toolkit (Stolcke, 2002). Linguistic LM features (“LM-MADA”) are similar to the word LM features except that they are computed using the part-of-speech and the lemma of the words instead of the actual words.6 Semantic coherence feature (“SemCoh”) is motivated by the fact that semantic information can be very useful in modeling the fluency of phrases, and can augment the information provided by n-gram LMs. In modeling contextual 4RankSVM has also been shown to be a good choice for the meta-learner in general stacking ensemble learning (Tang et al., 2010). 5The baseline ranking is simply based on the sum of the logs of the HMM and LM scores. 6The part-of-speech and the lemmas are obtained using MADA 3.0, a tool for Arabic morphological analysis and disambiguation (Habash and Rambow, 2005; Habash et al., 2009). lexical semantic information, simple bag-of-words models usually have a lot of noise; while more sophisticated models considering positional information have sparsity issues. To strike a balance between these two extremes, we introduce a novel model of semantic coherence that is based on a measure of semantic relatedness between pairs of</context>
</contexts>
<marker>Tang, Chen, Wang, Wang, 2010</marker>
<rawString>Buzhou Tang, Qingcai Chen, Xuan Wang, and Xiaolong Wang. 2010. Reranking for stacking ensemble learning. In Proceedings of the 17th international conference on Neural information processing: theory and algorithms - Volume Part I, ICONIP’10, pages 575–584.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David H Wolpert</author>
</authors>
<title>Original Contribution: Stacked generalization.</title>
<date>1992</date>
<journal>Neural Netw.,</journal>
<volume>5</volume>
<issue>2</issue>
<pages>259</pages>
<contexts>
<context position="7815" citStr="Wolpert, 1992" startWordPosition="1194" endWordPosition="1195">inate Ascent (CA) uses a listwise linear model whose weights are learned by a coordinate ascent method to optimize a ranking metric (Metzler and Bruce Croft, 2007). As with AdaRank we use MAP. ListNet (Cao et al., 2007) uses a neural network model whose parameters are learned by gradient descent method to optimize a listwise loss based on a probabilistic model of permutations. 2.2 Ensemble reranking In addition to the above mentioned approaches, we couple simple feature selection and reranking models combination via a straightforward ensemble learning method similar to stacked generalization (Wolpert, 1992) and Combiner (Chan and Stolfo, 1993). Our goal is to generate an overall meta-ranker that outperforms all base-rankers by learning from their predictions how they correlate with each other. To obtain the base-rankers, we train each of the ranking models of §2.1 using all the features of §2.3 and also using each feature family added to the baseline features separately. Then, we use the best model for each ranking approach to make predictions on a held-out data set of n-best lists. We can think of each base-ranker as computing one feature for each hypothesis. Hence, the scores generated by all </context>
</contexts>
<marker>Wolpert, 1992</marker>
<rawString>David H. Wolpert. 1992. Original Contribution: Stacked generalization. Neural Netw., 5(2):241– 259, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Xu</author>
<author>Hang Li</author>
</authors>
<title>AdaRank: a boosting algorithm for information retrieval.</title>
<date>2007</date>
<booktitle>In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’07,</booktitle>
<pages>391--398</pages>
<contexts>
<context position="7048" citStr="Xu and Li, 2007" startWordPosition="1070" endWordPosition="1073">thesis differs from the hypothesis with the lowest error rate. In pairwise approaches, the group structure of the n-best list is still ignored. Additionally, the number of training pairs generated from an n-best list depends on its size, which could result in training a model biased toward larger hypothesis lists (Cao et al., 2006). Listwise The listwise approach takes n-best lists as instances in both learning and prediction. The group structure is considered explicitly and ranking evaluation measures can be directly optimized. The listwise methods we use are implemented in RankLib. AdaRank (Xu and Li, 2007) is a boosting approach, similar to RankBoost, except that it optimizes an arbitrary ranking metric, for which we use Mean Average Precision (MAP). Coordinate Ascent (CA) uses a listwise linear model whose weights are learned by a coordinate ascent method to optimize a ranking metric (Metzler and Bruce Croft, 2007). As with AdaRank we use MAP. ListNet (Cao et al., 2007) uses a neural network model whose parameters are learned by gradient descent method to optimize a listwise loss based on a probabilistic model of permutations. 2.2 Ensemble reranking In addition to the above mentioned approache</context>
</contexts>
<marker>Xu, Li, 2007</marker>
<rawString>Jun Xu and Hang Li. 2007. AdaRank: a boosting algorithm for information retrieval. In Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’07, pages 391–398.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>