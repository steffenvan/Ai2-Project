<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.997926">
Stochastic Multiple Context-Free Grammar
for RNA Pseudoknot Modeling
</title>
<author confidence="0.998817">
Yuki Kato
</author>
<affiliation confidence="0.91257025">
Graduate School of
Information Science,
Nara Institute of
Science and Technology
</affiliation>
<address confidence="0.9359635">
8916-5 Takayama, Ikoma,
Nara 630-0192, Japan
</address>
<email confidence="0.99804">
yuuki-ka@is.naist.jp
</email>
<author confidence="0.981303">
Hiroyuki Seki
</author>
<affiliation confidence="0.90941875">
Graduate School of
Information Science,
Nara Institute of
Science and Technology
</affiliation>
<address confidence="0.9359935">
8916-5 Takayama, Ikoma,
Nara 630-0192, Japan
</address>
<email confidence="0.998032">
seki@is.naist.jp
</email>
<author confidence="0.986751">
Tadao Kasami
</author>
<affiliation confidence="0.91094775">
Graduate School of
Information Science,
Nara Institute of
Science and Technology
</affiliation>
<address confidence="0.936174">
8916-5 Takayama, Ikoma,
Nara 630-0192, Japan
</address>
<email confidence="0.998683">
kasami@naist.jp
</email>
<sectionHeader confidence="0.997384" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999651357142857">
Several grammars have been proposed
for modeling RNA pseudoknotted struc-
ture. In this paper, we focus on multiple
context-free grammars (MCFGs), which
are natural extension of context-free gram-
mars and can represent pseudoknots, and
extend a specific subclass of MCFGs to
a probabilistic model called SMCFG. We
present a polynomial time parsing algo-
rithm for finding the most probable deriva-
tion tree and a probability parameter esti-
mation algorithm. Furthermore, we show
some experimental results of pseudoknot
prediction using SMCFG algorithm.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99993015">
Non-coding RNAs fold into characteristic struc-
tures determined by interactions between mostly
Watson-Crick complementary base pairs. Such a
base paired structure is called the secondary struc-
ture. Pseudoknot (Figure 1 (a)) is one of the typi-
cal substructures found in the secondary structures
of several RNAs, including rRNAs, tmRNAs and
viral RNAs. An alternative graphic representation
of a pseudoknot is arc depiction where arcs con-
nect base pairs (Figure 1 (b)). It has been rec-
ognized that pseudoknots play an important role
in RNA functions such as ribosomal frameshifting
and regulation of translation.
Many attempts have so far been made at mod-
eling RNA secondary structure by formal gram-
mars. In a grammatical approach, secondary struc-
ture prediction can be viewed as parsing problem.
However, there may be many different derivation
trees for an input sequence. Thus, it is necessary to
have a method of extracting biologically realistic
</bodyText>
<figure confidence="0.8588474">
C
5’−C A G G
· · ·
U C C A G U
· · ·
G U C A G−3’
C
(a) Pseudoknot
c a g g c u g a c c u g c u c a g
(b) Arc depiction of (a)
</figure>
<figureCaption confidence="0.999984">
Figure 1: Example of RNA secondary structure
</figureCaption>
<bodyText confidence="0.999485625">
derivation trees among them. One solution to this
problem is to extend a grammar to a probabilistic
model and find the most likely derivation tree, and
another is to take free energy minimization into ac-
count. Eddy and Durbin (1994), and Sakakibara et
al. (1994) modeled RNA secondary structure with-
out pseudoknots by using stochastic context-free
grammars (stochastic CFGs or SCFGs). For pseu-
doknotted structure (Figure 1 (a)), however, an-
other approach has to be taken since a single CFG
cannot represent crossing dependencies of base
pairs in pseudoknots (Figure 1 (b)) for the lack of
generative power. Brown and Wilson (1996) pro-
posed a model based on intersections of SCFGs
to describe RNA pseudoknots. Cai et al. (2003)
introduced a model based on parallel communi-
cation grammar systems using a single CFG syn-
chronized with a number of regular grammars.
Akutsu (2000) provided dynamic programming al-
gorithms for RNA pseudoknot prediction without
using grammars. On the other hand, several gram-
mars have been proposed where the grammar itself
can fully describe pseudoknots. Rivas and Eddy
(1999, 2000) provided a dynamic programming
</bodyText>
<page confidence="0.983645">
57
</page>
<note confidence="0.5824415">
Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 57–64,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.99993897368421">
algorithm for predicting RNA secondary structure
including pseudoknots, and introduced a new class
of grammars called RNA pseudoknot grammars
(RPGs) for deriving sequences with gap. Ue-
mura et al. (1999) defined specific subclasses of
tree adjoining grammars (TAGs) named SL-TAGs
and extended SL-TAGs (ESL-TAGs) respectively,
and predicted RNA pseudoknots by using pars-
ing algorithm of ESL-TAG. Matsui et al. (2005)
proposed pair stochastic tree adjoining grammars
(PSTAGs) based on ESL-TAGs and tree automata
for aligning and predicting pseudoknots, which
showed good prediction accuracy. These gram-
mars have generative power stronger than CFGs
and polynomial time algorithms for parsing prob-
lem.
In our previous work (Kato et al., 2005),
we identified RPGs, SL-TAGs and ESL-TAGs
as subclasses of multiple context-free grammars
(MCFGs) (Kasami et al., 1988; Seki et al., 1991),
which can model RNA pseudoknots, and showed a
candidate subclass of the minimum grammars for
representing pseudoknots. The generative power
of MCFGs is stronger than that of CFGs and
MCFGs have a polynomial time parsing algo-
rithm like the CYK (Cocke-Younger-Kasami) al-
gorithm for CFGs. In this paper, we extend the
above candidate subclass of MCFGs to a prob-
abilistic model called a stochastic MCFG (SM-
CFG). We present a polynomial time parsing algo-
rithm for finding the most probable derivation tree,
which is applicable to RNA pseudoknot predic-
tion. In addition, we mention a probability param-
eter estimation method based on the EM (expec-
tation maximization) algorithm. Finally, we show
some experimental results on pseudoknot predic-
tion for three RNA families using SMCFG algo-
rithm, which show good prediction accuracy.
</bodyText>
<sectionHeader confidence="0.950793" genericHeader="method">
2 Stochastic Multiple Context-Free
Grammar
</sectionHeader>
<bodyText confidence="0.998765785714286">
A stochastic multiple context-free grammar
(stochastic MCFG, or SMCFG) is a probabilistic
extension of MCFG (Kasami et al., 1988; Seki et
al., 1991) or linear context-free rewriting system
(Vijay-Shanker et al., 1987). An SMCFG is a 5-
tuple G = (N, T, F, P, 5) where N is a finite set
of nonterminals, T is a finite set of terminals, F is
a finite set of functions, P is a finite set of (pro-
duction) rules and 5 ∈ N is the start symbol. For
each A ∈ N, a positive integer denoted by dim(A)
is given and A derives dim(A)-tuples of terminal
sequences. For the start symbol 5, dim(5) = 1.
For each f ∈ F, positive integers di (0 ≤ i ≤ k)
are given and f is a total function from (T∗)d1 ×
</bodyText>
<listItem confidence="0.703379428571429">
· · · × (T ∗)dk to (T ∗)d0 where each component of
f is defined as the concatenation of some compo-
nents of arguments and constant sequences. Note
that each component of an argument should oc-
cur in the function value at most once (linear-
ity). For example, f[(x11, x12), (x21, x22)] =
(x11x21, x12x22). Each rule in P has the form
</listItem>
<equation confidence="0.503516">
p
</equation>
<bodyText confidence="0.953830804878049">
of A0 → f[A1,..., Ak] where Ai ∈ N (0 ≤
i ≤ k), f : (T∗)dim(A1) × ··· × (T∗)dim(Ak) →
(T∗)dim(A0) ∈ F and p is a real number with 0 ≤
p ≤ 1 called the probability of this rule. The sum-
mation of the probabilities of the rules with the
same left-hand side should be one. If we are not
interested in p, we just write A0 → f[A1,... , Ak].
If k ≥ 1, then the rule is called a nonterminat-
ing rule, and if k = 0, then it is called a termi-
nating rule. A terminating rule A0 → f[ ] with
f[h][ ] = Oh (1 ≤ h ≤ dim(A0)) is simply written
as A0 → (O1, . . . , Odim(A0)).
We recursively define the relation ⇒∗ by the fol-
lowing (L1) and (L2): (L1) if A p→ α ∈ P (α ∈
(T∗)dim(A)), then we write A ⇒ ∗α with proba-
bility p, and (L2) if A p→ f[A1,..., Ak] ∈ P
and Ai ⇒ αi ∈ (T∗)dim(Ai) (1 ≤ i ≤ k)
∗
with probabilities p1, ... , pk, respectively, then
we write A ⇒ ∗f[α1,..., αk] with probability
p· nki=1 pi. In parallel with the relation ∗⇒, we
define derivation trees as follows: (D1) if A p→
α ∈ P (α ∈ (T∗)dim(A)), then the ordered tree
with the root labeled A which has α as the only
one child is a derivation tree for α with proba-
bility p, and (D2) if A p→ f[A1,..., Ak] ∈ P,
Ai ⇒ αi ∈ (T∗)dim(Ai) (1 ≤ i ≤ k) and
∗
t1, ... , tk are derivation trees for α1, ... , αk with
probabilities p1, ... , pk, respectively, then the or-
dered tree with the root labeled A (or A : f
if necessary) which has t1, ... , tk as (immediate)
subtrees from left to right is a derivation tree for
f[α1, ... , αk] with probability p · nki=1 pi. Ex-
ample rules are A 0.3→ f[A] where f[(x1, x2)] =
(ax1b, cx2d) and A →0.7 (ab, cd). Then, A ⇒ ∗
(ab, cd) by the second rule, which is followed
by A ⇒∗ f[(ab, cd)] = (aabb, ccdd) by the first
rule. The probability of the latter derivation is
0.3 · 0.7 = 0.21. The language generated by an
SMCFG G is defined as L(G) = {w ∈ T∗  |5 ⇒∗
</bodyText>
<page confidence="0.999714">
58
</page>
<tableCaption confidence="0.99967">
Table 1: SMCFG G3
</tableCaption>
<table confidence="0.915275882352941">
Type Rule set Function Transition probability Emission probability
E Wv → (ε, ε) 1 1
S Wv → J[Wy] J[(x1, x2)] = x1x2 tv(y) 1
D Wv → SK[Wy] SK[(x1, x2)] = (x1, x2) tv(y) 1
B1 Wv → C1[Wy, Wz] C1[x1, (x21, x22)] = (x1x21, x22) 1 1
B2 Wv → C2[Wy, Wz] C2[x1, (x21, x22)] = (x21x1, x22) 1 1
B3 Wv → C3[Wy, Wz] C3[x1, (x21, x22)] = (x21, x1x22) 1 1
B4 Wv → C4[Wy, Wz] C4[x1, (x21, x22)] = (x21, x22x1) 1 1
U1L Wv → UPai UPai tv(y) ev(ai)
1L[Wy] 1L[(x1, x2)] = (aix1, x2)
U1R Wv → UP aj UP aj tv(y) ev(aj)
1R[Wy] 1R[(x1, x2)] = (x1aj, x2)
U2L Wv → UPak UPak tv(y) ev(ak)
2L [Wy] 2L [(x1, x2)] = (x1, akx2)
U2R Wv → UPal UPal tv(y) ev(al)
2R[Wy] 2R[(x1, x2)] = (x1, x2al)
P Wv → BPaial[Wy] BPaial[(x1, x2)] = (aix1, x2al) tv(y) ev(ai, al)
</table>
<bodyText confidence="0.976155578947368">
w with probability greater than 0}.
In this paper, we focus on an SMCFG G3 =
(N, T, F, P, S) that satisfies the following condi-
tions: G3 has m different nonterminals denoted
by W1, ... , Wm, each of which uses the only one
type of a rule denoted by E, S, D, B1, B2, B3, B4,
U1L, U1R, U2L, U2R or P 1 (see Table 1). The
type of Wv is denoted by type(v) and we prede-
fine type(1) = S, that is, W1 is the start symbol.
Consider a sample rule set Wv → UPα1L[Wy] |
UPα1L[Wz] where UPα1L[(x1, x2)] = (αx1, x2)
and α ∈ T. For each rule r, two real values
called transition probability p1 and emission prob-
ability p2 are specified in Table 1. The probability
of r is simply defined as p1 · p2. In application,
p1 = tv(y) and p2 = ev(ai), ... in Table 1 are the
parameters of the grammar, which are set by hand
or by a training algorithm (Section 3.3) depending
on the set of possible sequences to be analyzed.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="method">
3 Algorithms for SMCFG
</sectionHeader>
<bodyText confidence="0.999689">
In RNA structure analysis using stochastic gram-
mars, we have to deal with the following three
problems: (1) calculate the optimal alignment of
a sequence to a stochastic grammar (alignment
problem), (2) calculate the probability of a se-
quence given a stochastic grammar (scoring prob-
lem), and (3) estimate optimal probability param-
eters for a stochastic grammar given a set of exam-
ple sequences (training problem). In this section,
we give solutions to each problem for the specific
SMCFG G3 = (N, T, F, P, S).
</bodyText>
<subsectionHeader confidence="0.999154">
3.1 Alignment Problem
</subsectionHeader>
<bodyText confidence="0.97362071875">
The alignment problem for G3 is to find the
most probable derivation tree for a given input se-
&apos;These types stand for END, START, DELETE, BIFURCA-
TION, UNPAIR and PAIR respectively.
quence. This problem can be solved by a dynamic
programming algorithm similar to the CYK algo-
rithm for SCFGs (Durbin et al., 1998), and in this
paper, we also call the parsing algorithm for G3
the CYK algorithm. We fix an input sequence w =
a1 ··· an (|w |= n). Let -yv(i,j) and -yy(i,j,k,l)
be the logarithm of maximum probabilities of a
derivation subtree rooted at a nonterminal Wv for
a terminal subsequence ai · · · aj and of a deriva-
tion subtree rooted at a nonterminal Wy for a tuple
of terminal subsequences (ai · · · aj, ak · · · al) re-
spectively. The variables -yv(i, i − 1) and -yy(i, i −
1, j, j − 1) are the logarithm of maximum prob-
abilities for an empty sequence E and a pair of E.
Let τv(i, j) and τy(i, j, k, l) be traceback variables
for constructing a derivation tree, which are calcu-
lated together with -yv(i, j) and -yy(i, j, k, l). We
define Cv = {y  |Wv → f[Wy] ∈ P, f ∈ F}.
To avoid non-emitting cycles, we assume that the
nonterminals are numbered such that v &lt; y for
all y ∈ Cv. The CYK algorithm uses five dimen-
sional dynamic programming matrix to calculate
-y, which leads to log P(w, πˆ  |0) where πˆ is the
most probable derivation tree and 0 is an entire set
of probability parameters. The detailed descrip-
tion of the CYK algorithm is as follows:
Algorithm 1 (CYK).
Initialization:
</bodyText>
<equation confidence="0.631140444444445">
for i ← 1 to n + 1, j ← i to n + 1, v ← 1tom
do if type(v) = E
then -yv(i, i − 1, j, j − 1) ← 0
else -yv(i, i − 1, j, j − 1) ← −∞
Iteration:
for i ← n downto 1, j ← i − 1 to n, k ← n + 1
downto j + 1, l ← k − 1 to n, v ← 1 to m
do if type(v) = E
then if j = i − 1 and l = k − 1
</equation>
<bodyText confidence="0.518986">
then skip
</bodyText>
<page confidence="0.980145">
59
</page>
<construct confidence="0.7245355">
else γv(i, j, k, l) ← −∞
if type(v) = S
</construct>
<figure confidence="0.703489894736842">
then γv(i, j)
← max max [log tv(y)
yECv h=i−1,...,j
+γy(i, h, h + 1, j)]
τv(i, j)
arg max [log tv (y) +γy (i, h, h+1, j)]
(y,h)
if type(v) = B1 and Wv → C1 [Wy, Wz]
then γv (i, j, k, l )
←
[γy(i, h)+γz(h+1, j, k, l)]
h=i−1,...,j
τv(i, j, k, l)
← arg max
(y,z,h)
if type(v) = B2 and Wv → C2[Wy, Wz]
then γv(i, j, k, l)
←max
h=k−1,...,l [γz(i,j, h+1, l)+γy(k, h)]
τv(i, j, k, l)
← arg max
(y,z,h) [γz(i, j, h+1, l)+γy(k, h)]
if type(v) = B4 and Wv → C4[Wy, Wz]
then γv(i, j, k, l)
← max [γz(i,j, k, h)+γy(h+1, l)]
h=k−1,...,l
τv(i, j, k, l)
← arg max
(y,z,h)
then
then
j, k, l)
j, k,
max [log
if j = i − 1 or l = k − 1
γv(i,
←−∞
γv(i,
</figure>
<equation confidence="0.873093101851852">
l)←
ev(ai, al) + log tv(y)
yECv
+γy(i + 1, j, k, l − 1)]
τv(i, j, k, l)
← arg max
[log
y
j, k, l)
max [log
aj, ak,
+log
yECv
+
j
+
l
+γy(i + 1, j, k, l − 1)]
γv(i,
←
ev(ai,
al)
tv(y)
+γy(i
∆1L
v ,
−∆1R
v ,
∆2L
v ,
−∆2R
v )]
τv(i, j, k, l)
← arg max
+ log
+
+
aj, ak,
=
tv(y)
γy(i
∆1L
v ,j−∆1R
v ,k + ∆2L
v , l − ∆2R
v )]
ev(ai,
al)
ev(ai) for type(v) =
←max
[γy(i, h)+γz(h+1, j, k, l)]
[γy(h+1, j)+γz(i, h, k, l)]
(y,z,h)
if type(v) = B3 and Wv → C3[Wy, Wz]
then γv(i, j, k, l)
← max
[γy(h+1,j)+γz(i, h, k, l)]
h=i−1,...,j
τv(i, j, k, l)
← arg max
U1L,
ak,
=
ev(ai,
ak,
=
ev(ai,aj,ak,
ev(al)
=
ev(ai,
, ak, al) = 1 for the other types
except P. Also, ∆1L
v = 1 for type(v) = U1L,
∆1R
v = 1 for type(v) = U1R, ∆2L
v = 1 for
= 1 for type(v) = U2R,
∆2R
v
[γz(i,j, k, h)+γy(h+1, l)]
if type(v) = P
else
ev(ai, al) + log tv(y)
else
y
[log
ak, al)
ev(ai,aj,
Note:
60
ev(ai, aj,
al) = ev(aj) for type(v)
U1R,
aj,
al) = ev(ak) for type(v)
U2L,
al) =
for type(v)
U2R,
aj
type(v) = U2L,
an
d ∆1L
v , ... ∆2R
v are set to 0 for the other types
except P.
When the calculation terminates, we obtain
log P(w, πˆ  |θ) = γ1(1, n). If there are b BI-
</equation>
<bodyText confidence="0.638302857142857">
FURCATION nonterminals and a other nontermi-
nals, the time and space complexities of the CYK
algorithm are O(amn4 + bn5) and O(mn4), re-
spectively. To recover the optimal derivation tree,
we use the traceback variables τ. Due to limitation
of the space, the full description of the traceback
algorithm is omitted (see (Kato and Seki, 2006)).
</bodyText>
<subsectionHeader confidence="0.939317">
3.2 Scoring Problem
</subsectionHeader>
<bodyText confidence="0.632965125">
As in SCFGs (Durbin et al., 1998), the scor-
ing problem for
can be solved by the inside
algorithm. The inside algorithm calculates the
summed probabilities
j) and
j, k, l) of
all derivation subtrees rooted at a nonterminal Wv
for a subsequence ai
aj and of all derivation
subtrees rooted at a nonterminal Wy for a tuple
of subsequences (ai
aj, ak
respectively.
The variables
i
and
i
j, j
are defined for empty sequences in a similar way
to the CYK algorithm. Therefore, we can easily
obtain the inside algorithm by replacing max op-
erations with summations in the CYK algorithm.
When the calculation terminates, we obtain the
</bodyText>
<equation confidence="0.416752">
probability P(w
=
</equation>
<bodyText confidence="0.941954">
n). The time and
space complexities of the algorithm are identical
with those of the CYK algorithm.
In order to re-estimate the probability parame-
</bodyText>
<subsectionHeader confidence="0.636852">
ters of
</subsectionHeader>
<bodyText confidence="0.859573">
we need the outside algorithm. The
outside algorithm calculates the summed prob-
</bodyText>
<figure confidence="0.552966357142857">
ability
j) of all derivation trees excluding
subtrees rooted at a nonterminal Wv generat-
ing asubsequence ai
aj. Also, it calculates
j, k,
the summed probability of all deriva-
tion trees excluding subtrees rooted at a non-
terminal Wy generating a tuple of subsequences
(ai
aj, ak
In the algorithm, we will use
f
Note
</figure>
<footnote confidence="0.3467945">
that calculating the outside variables
requires
the inside variables
Unlike CYK and inside al-
</footnote>
<bodyText confidence="0.54185">
gorithms, the outside algori
</bodyText>
<equation confidence="0.896310962962963">
Gs
αv(i,
αy(i,
···
···
···al)
αv(i,
−1)
αy(i,
−1,
−1)
|θ)
α1(1,
Gs,
βv(i,
···
βy(i,
l),
···
···al).
Pv = {y  |Wy →f[Wv] ∈ P,
∈ F}.
β
α.
thm recursively works
�←
y∈Pv
</equation>
<bodyText confidence="0.9943265">
its way inward. The time and space complexities
of the outside algorithm are the same as those of
CYK and inside algorithms. Formally, the outside
algorithm is as follows:
</bodyText>
<figure confidence="0.94915375">
Algorithm 2 (Outside).
Initialization:
β1(1,n) ← 1
Iteration:
</figure>
<construct confidence="0.88695025">
for i ← 1 to n+1, j ← n downto i−1, k ← j+1
ton+1,l ← n downto k − 1, v ← 1tom
do if type(v) = S and Wy → C1[Wv, Wz]
then βv(i, j)
βy(i, h, k′, l′)
αz(j + 1, h, k′, l′)
if type(v) = S and Wy → C2[Wv, Wz]
then βv(i, j)
βy(h, j, k′, l′)
αz(h, i − 1, k′, l′)
if type(v) = S and Wy → C3[Wv, Wz]
then βv(i, j)
</construct>
<equation confidence="0.935281052631579">
�i− 1
k′=h−1
αz(h, k′,j + 1, l′)
if type(v) = S and Wy → C4[Wv, Wz]
then βv(i, j)
i
βy(h, k′, l′, j)
l′=k′+1
αz(h, k′, l′, i − 1)
if type(v) ≠ S and Wy → C1[Wz, Wv]
then βv(i, j, k, l)
i
← βy(h,j, k,l)αz(h, i − 1)
h=1
if type(v) ≠ S and Wy → C2[Wz, Wv]
then βv(i, j, k, l)
← k−1� βy(i, h, k, l)αz(j + 1, h)
h=j
if type(v) ≠ S and Wy → C3[Wz, Wv]
then βv(i, j, k, l)
k
← βy(i,j, h,l)αz(h, k − 1)
h=j+1
if type(v) ≠ S and Wy → C4[Wz, Wv]
then βv(i, j, k, l)
n
← βy(i, j, k, h)αz(l + 1, h)
h=l
else βv(i, j, k, l)
βy(i − ∆1L
y , j + ∆1R
y , k − ∆2L
y ,
l+∆2Ry)ey(ai−∆,L, aj+∆1R
y , ak−∆2L
y ,
al+∆2R
y )ty(v)
</equation>
<subsectionHeader confidence="0.991613">
3.3 Training Problem
</subsectionHeader>
<bodyText confidence="0.999921428571429">
The training problem for Gs can be solved by the
EM algorithm called the inside-outside algorithm
where the inside variables α and outside variables
β are used to re-estimate probability parameters.
First, we consider the probability that a nonter-
minal Wv is used at positions i, j, k and l in a
derivation of a single sequence w. If type(v) =
</bodyText>
<equation confidence="0.83796775">
S, the probability is 1
P(w|θ)αv(i, j)βv(i, j), other-
wise 1
P(w|θ)αv(i, j, k, l)βv(i, j, k, l). By summing
</equation>
<bodyText confidence="0.994035">
these over all positions in the sequence, we can ob-
tain the expected number of times that Wv is used
for w as follows: for type(v) = S, the expected
count is
</bodyText>
<equation confidence="0.91797175">
αv(i, j)βv(i, j),
otherwise
αv(i, j, k, l)
βv(i, j, k, l).
</equation>
<bodyText confidence="0.998253375">
Next, we extend these expected values from a sin-
gle sequence w to multiple independent sequences
w(r) (1 ≤ r ≤ N). Let α(r) and β(r) be the in-
side and outside variables calculated for each in-
put sequence w(r). Then we can obtain the ex-
pected number of times that a nonterminal Wv is
used for training sequences w(r) (1 ≤ r ≤ N) by
summing the above terms over all sequences: for
</bodyText>
<equation confidence="0.99407">
type(v) = S,
1
P(w(r)  |θ)
α(r) v(i, j, k,l)β(r)
v (i, j, k, l).
</equation>
<bodyText confidence="0.998807">
Similarly, for a given Wy, the expected number of
times that a rule Wv → f[Wy] is applied can be
</bodyText>
<equation confidence="0.953742763157895">
n
←
h=j
n+1
k′=h+1
n
�
l′=k′−1
n+1
k′=j+1
n
�
l′=k′−1
i
←
h=1
i
←
h=1
n
� βy(h, k′, i, l′)
l′=j
�i− 1
k′=h−1
i
←
h=1
1 n+1 n
i=1 j=i−1
P(w  |θ)
1 n+1 n n+1 n
i=1 j=i−1 k=j+1 l=k−1
P(w  |θ)
E(v) = N n+1 n 1
r=1 i=1 j=i−1 P(w(r)  |θ) α j)
β(r) v(i, j),
otherwise N n+1 n n+1 n
E(v) = r=1 i=1 j=i−1 k=j+1 l=k−1
</equation>
<page confidence="0.98109">
61
</page>
<bodyText confidence="0.98702">
obtained as follows: for type(v) = S, and for type(v) = P,
</bodyText>
<equation confidence="0.9836935">
E(v — y) =
β(r) v(i, j)tv(y)α(r)
y (i, h, h + 1, j),
otherwise
β(r)
v (i, j, k,l)ev(ai, aj, ak, al)tv(y)
α(r)
y (i + ∆1L
v , j — ∆1R v ,k + ∆2L
v ,
l — ∆2R
v ).
</equation>
<bodyText confidence="0.99502">
For a given terminal a or a pair of terminals (a, b),
the expected number of times that a rule contain-
ing a (or a and b) is applied is as shown below: for
</bodyText>
<equation confidence="0.998891684210527">
type(v) = U1L,
E(v — a) = N n n n+1∑ n 1
∑ ∑ ∑ k=j+1 ∑
r=1 i=1 j=i l=k−1
P(w(r)  |θ)
δ(a(r)
i = a)β(r)
v (i, j, k, l)
α(r)
v (i, j, k, l),
for type(v) = U1R,
1
P(w(r)  |θ)
δ(a(r)
j = a)β(r) v(i, j, k, l)
α(r)
v (i, j, k, l),
for type(v) = U2L,
1
P(w(r)  |θ)
δ(a(r)
k = a)β(r)
v (i, j, k, l)
α(r) v(i, j, k, l),
for type(v) = U2R,
1
P(w(r)  |θ)
δ(a(r)
l = a)β(r)
v (i, j, k, l)
α(r)
v (i, j, k, l),
1
P(w(r)  |θ)
δ(a(r)
i = a, a(r)
l = b)β(r) v(i, j, k, l)
α(r) v(i, j, k, l),
</equation>
<bodyText confidence="0.9995627">
where δ(C) is 1 if the condition C in the parenthe-
sis is ture, and 0 if C is false.
Now, we re-estimate probability parameters by
using the above expected counts. Let ˆtv(y) be re-
estimated transition probabilities from Wv to Wy.
Also, let ˆev(a) and ˆev(a, b) be re-estimated emis-
sion probabilities that Wv emits a symbol a and
two symbols a and b respectively. We can ob-
tain each re-estimated probability by the following
equations:
</bodyText>
<equation confidence="0.99372925">
ˆtv(y) = E(v) , ˆev(a) = E(v) ,
ˆev(a, b) = E(v) .
E(v — y) E(v — a)
E(v — ab) (3.1)
</equation>
<bodyText confidence="0.999821">
Note that the expected count correctly correspond-
ing to its nonterminal type must be substituted
for the above equations. In summary, the inside-
outside algorithm is as follows:
</bodyText>
<sectionHeader confidence="0.431357" genericHeader="method">
Algorithm 3 (Inside-Outside).
</sectionHeader>
<bodyText confidence="0.992742">
Initialization: Pick arbitrary probability parame-
ters of the model.
Iteration: Calculate the new probability parame-
ters using (3.1). Calculate the new log likelihood
∑N r=1 log P(w(r)  |θ) of the model.
Termination: Stop if the change in log likelihood
is less than predefined threshold.
</bodyText>
<sectionHeader confidence="0.999927" genericHeader="evaluation">
4 Experimental Results
</sectionHeader>
<subsectionHeader confidence="0.966182">
4.1 Data for Experiments
</subsectionHeader>
<bodyText confidence="0.999720461538462">
The dataset for experiments was taken from an
RNA family database called “Rfam” (version 7.0)
(Griffiths-Jones et al., 2003) which is a database
of multiple sequence alignment and covariance
models (Eddy and Durbin, 1994) representing
non-coding RNA families. We selected three vi-
ral RNA families with pseudoknot annotations
named Corona pk 3 (Corona), HDV ribozyme
(HDV) and Tombus 3 IV (Tombus) (see Table 2).
Corona pk 3 has a simple pseudoknotted struc-
ture, whereas HDV ribozyme and Tombus 3 IV
have more complicated structures with pseudo-
knot.
</bodyText>
<table confidence="0.841433">
∑ j 1 E(v — ab) = ∑N n−1∑ n−1∑ ∑n ∑n
h=i−1 r=1 i=1 j=i k=j+1 l=k
P (w(r) |θ)
∑N n+1∑ ∑n
r=1 i=1 j=i−1
E(v ∑N n+1∑ ∑n n+1∑ ∑n 1
— y) = r=1 i=1 j=i−1 k=j+1 l=k−1
</table>
<equation confidence="0.995856875">
P(w(r)  |θ)
E(v — a) = ∑N ∑n ∑n n+1∑ ∑n
r=1 i=1 j=i k=j+1 l=k−1
E(v — a) = ∑N n−1∑ n−1∑ ∑n n
r=1 i=1 j=i−1 k=j+1 ∑
l=k
E(v — a) = ∑N n−1∑ n−1∑ ∑n ∑n
r=1 i=1 j=i−1 k=j+1 l=k
</equation>
<page confidence="0.999114">
62
</page>
<tableCaption confidence="0.998185">
Table 2: Three RNA families from Rfam ver. 7.0
</tableCaption>
<table confidence="0.99807125">
Family Range of length # of annotated sequences # of test sequences
Corona pk 3 62–64 14 10
HDV ribozyme 87–91 15 10
Tombus 3 IV 89–92 18 12
</table>
<tableCaption confidence="0.959002">
Table 3: Prediction results
</tableCaption>
<table confidence="0.9988218">
Family Precision [%] Recall [%] CPU time [sec]
Average Min Max Average Min Max Average Min Max
Corona pk 3 99.4 94.4 100.0 99.4 94.4 100.0 27.8 26.0 30.4
HDV ribozyme 100.0 100.0 100.0 100.0 100.0 100.0 252.1 219.0 278.4
Tombus 3 IV 100.0 100.0 100.0 100.0 100.0 100.0 244.8 215.2 257.5
</table>
<subsectionHeader confidence="0.906606">
4.2 Implementation
</subsectionHeader>
<bodyText confidence="0.99999668">
We specified a particular SMCFG G3 by utiliz-
ing secondary structure annotation of each fam-
ily. Rules were determined by considering con-
sensus secondary structure. Probability parame-
ters were estimated in a few selected sequences by
the simplest pseudocounting method known as the
Laplace’s rule (Durbin et al., 1998): to add one ex-
tra count to the true counts for each base configu-
ration observed in a few selected sequences. Note
that the inside-outside algorithm was not used in
the experiments. The other sequences in the align-
ment were used as the test sequences for predic-
tion (see Table 2). We implemented the CYK al-
gorithm with traceback in ANSI C on a machine
with Intel Pentium D CPU 2.80 GHz and 2.00 GB
RAM. Straightforward implementation gives rise
to a serious problem of lack of memory space due
to the higher order dynamic programming matrix
(remember that the space complexity of the CYK
algorithm is O(mn4)). The dynamic program-
ming matrix in our specified model is sparse, and
therefore, we successfully implemented the matrix
as a hash table storing only nonzero probability
values (equivalently, finite values of the logarithm
of probabilities).
</bodyText>
<subsectionHeader confidence="0.991446">
4.3 Tests
</subsectionHeader>
<bodyText confidence="0.999875642857143">
We tested prediction accuracy by calculating pre-
cision and recall (sensitivity), which are the ratio
of the number of correct base pairs predicted by
the algorithm to the total number of predicted base
pairs, and the ratio of the number of correct base
pairs predicted by the algorithm to the total num-
ber of base pairs specified by the trusted annota-
tion, respectively. The results are shown in Table
3. A nearly correct prediction (94.4% precision
and recall) for Corona pk 3 is shown in Figure
2 where underlined base pairs agree with trusted
ones. The secondary structures predicted by our
algorithm agree very well with the trusted struc-
tures.
</bodyText>
<subsectionHeader confidence="0.996871">
4.4 Comparison with PSTAG
</subsectionHeader>
<bodyText confidence="0.9999755">
We compared the prediction accuracy of our SM-
CFG algorithm with that of PSTAG algorithm
(Matsui et al., 2005) (see Table 4). PSTAGs,
as we have mentioned before, are proposed for
modeling pairwise alignment of RNA sequences
with pseudoknots and assign a probability to each
alignment of TAG derivation trees. PSTAG al-
gorithm, based on dynamic programming, calcu-
lates the most likely alignment for the pair of
TAG derivation trees where one of them is in the
form of an unfolded sequence and the other is a
TAG derivation tree for known structure. SMCFG
method shows better performance in accuracy than
PSTAG method in the same test sets.
</bodyText>
<sectionHeader confidence="0.999656" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99993325">
In this paper, we have proposed a probabilistic
model named SMCFG, and designed a polyno-
mial time parsing and a parameter estimation al-
gorithm for SMCFG. Moreover, we have demon-
strated computational experiments of RNA sec-
ondary structure prediction with pseudoknots us-
ing SMCFG parsing algorithm, which show good
performance in accuracy.
</bodyText>
<sectionHeader confidence="0.999389" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.906343333333333">
This work is supported in part by Grant-in-Aid
for Scientific Research from Japan Society for the
Promotion of Science (JSPS). We also wish to
thank JSPS Research Fellowships for Young Sci-
entists for their generous financial assistance. The
authors thank Dr. Yoshiaki Takata for his useful
</bodyText>
<page confidence="0.994653">
63
</page>
<figure confidence="0.949282">
Corona_pk3 (EMBL accession #: X51325.1)
[Trusted structure in Rfam]
CUAGUCUUAUACACAAUGGUAAGCCAGUGGUAGUAAAGGUAUAAGAAAUUUGCUACUAUGUUA
[[[[[[[[ ((( ((((((( ]]]]]]]] ))))))) )))
[Prediction by SMCFG]
CUAGUCUUAUACACAAUGGUAAGCCAGUGGUAGUAAAGGUAUAAGAAAUUUGCUACUAUGUUA
[[[[[[[[ (((((((((( ]]]]]]]] ))))))))))
</figure>
<figureCaption confidence="0.99329">
Figure 2: Comparison of a prediction result with a trusted structure in Rfam
</figureCaption>
<tableCaption confidence="0.944262">
Table 4: Comparison between SMCFG and PSTAG
</tableCaption>
<table confidence="0.969893">
Model Average precision [%] Average recall [%]
Corona HDV Tombus Corona HDV Tombus
SMCFG 99.4 100.0 100.0 99.4 100.0 100.0
PSTAG 95.5 95.6 97.4 94.6 94.1 97.4
</table>
<bodyText confidence="0.782226">
comments on implementation of high dimensional
dynamic programming.
</bodyText>
<sectionHeader confidence="0.99795" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999723492063492">
Tatsuya Akutsu. 2000. Dynamic programming al-
gorithms for RNA secondary structure prediction
with pseudoknots. Discrete Applied Mathematics,
104:45–62.
Michael Brown and Charles Wilson. 1996. RNA pseu-
doknot modeling using intersections of stochastic
context free grammars with applications to database
search. Proc. Pacific Symposium on Biocomputing,
109–125.
Liming Cai, Russell L. Malmberg, and Yunzhou Wu.
2003. Stochastic modeling of RNA pseudoknotted
structures: a grammatical approach. Bioinformatics,
19(1):i66–i73.
Richard Durbin, Sean R. Eddy, Anders Krogh, and
Graeme Mitchison. 1998. Biological Sequence
Analysis, Cambridge University Press.
Sean R. Eddy and Richard Durbin. 1994. RNA
sequence analysis using covariance models. Nuc.
Acids Res., 22(11):2079–2088.
Sam Griffiths-Jones, Alex Bateman, Mhairi Marshall,
Ajay Khanna, and Sean R. Eddy. 2003. Rfam: an
RNA family database. Nuc. Acids Res., 31(1):439–
441.
Tadao Kasami, Hiroyuki Seki, and Mamoru Fujii.
1988. Generalized context-free grammar and multi-
ple context-free grammar. IEICE Trans. Inf. &amp; Syst.,
J71-D(5):758–765 (in Japanese).
Yuki Kato, Hiroyuki Seki, and Tadao Kasami. 2005.
On the generative power of grammars for RNA sec-
ondary structure. IEICE Trans. Inf. &amp; Syst., E88-
D(1):53–64.
Yuki Kato and Hiroyuki Seki. 2006. Stochastic
multiple context-free grammar for RNA pseudoknot
modeling. NAIST Info. Sci. Tech. Rep. (NAIST-IS-
TR2006002).
Hiroshi Matsui, Kengo Sato, and Yasubumi Sakak-
ibara. 2005. Pair stochastic tree adjoining gram-
mars for aligning and predicting pseudoknot RNA
structures. Bioinformatics, 21(11):2611–2617.
Elena Rivas and Sean R. Eddy. 1999. A dynamic pro-
gramming algorithm for RNA structure prediction
including pseudoknots. J. Mol. Biol., 285:2053–
2068.
Elena Rivas and Sean R. Eddy. 2000. The language of
RNA: A formal grammar that includes pseudoknots.
Bioinformatics, 16(4):334–340.
Yasubumi Sakakibara, Michael Brown, Richard
Hughey, I. Saira Mian, Kimmen Sj¨olander, Rebecca
C. Underwood, and David Haussler. 1994. Stochas-
tic context-free grammars for tRNA modeling. Nuc.
Acids Res., 22:5112–5120.
Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii, and
Tadao Kasami. 1991. On multiple context-free
grammars. Theor. Comput. Sci., 88:191–229.
Yasuo Uemura, Aki Hasegawa, Satoshi Kobayashi, and
Takashi Yokomori. 1999. Tree adjoining grammars
for RNA structure prediction. Theor. Comput. Sci.,
210:277–303.
K. Vijay-Shanker, David J. Weir, and Aravind K. Joshi.
1987. Characterizing structural descriptions pro-
duced by various grammatical formalisms. Proc.
25th Annual Meeting of Association for Computa-
tional Linguistics (ACL87), 104–111.
</reference>
<page confidence="0.999414">
64
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.118644">
<title confidence="0.9977335">Stochastic Multiple Context-Free for RNA Pseudoknot Modeling</title>
<author confidence="0.948949">Yuki</author>
<affiliation confidence="0.97895775">Graduate School Information Nara Institute Science and</affiliation>
<address confidence="0.956069">8916-5 Takayama, Nara 630-0192,</address>
<email confidence="0.965799">yuuki-ka@is.naist.jp</email>
<author confidence="0.495483">Hiroyuki</author>
<affiliation confidence="0.96152475">Graduate School Information Nara Institute Science and</affiliation>
<address confidence="0.9623635">8916-5 Takayama, Nara 630-0192,</address>
<email confidence="0.967312">seki@is.naist.jp</email>
<author confidence="0.512292">Tadao</author>
<affiliation confidence="0.93071575">Graduate School Information Nara Institute Science and</affiliation>
<address confidence="0.966605">8916-5 Takayama, Nara 630-0192,</address>
<email confidence="0.988532">kasami@naist.jp</email>
<abstract confidence="0.997141266666667">Several grammars have been proposed for modeling RNA pseudoknotted structure. In this paper, we focus on multiple context-free grammars (MCFGs), which are natural extension of context-free grammars and can represent pseudoknots, and extend a specific subclass of MCFGs to a probabilistic model called SMCFG. We present a polynomial time parsing algorithm for finding the most probable derivation tree and a probability parameter estimation algorithm. Furthermore, we show some experimental results of pseudoknot prediction using SMCFG algorithm.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Tatsuya Akutsu</author>
</authors>
<title>Dynamic programming algorithms for RNA secondary structure prediction with pseudoknots.</title>
<date>2000</date>
<journal>Discrete Applied Mathematics,</journal>
<pages>104--45</pages>
<contexts>
<context position="3100" citStr="Akutsu (2000)" startWordPosition="495" endWordPosition="496">) modeled RNA secondary structure without pseudoknots by using stochastic context-free grammars (stochastic CFGs or SCFGs). For pseudoknotted structure (Figure 1 (a)), however, another approach has to be taken since a single CFG cannot represent crossing dependencies of base pairs in pseudoknots (Figure 1 (b)) for the lack of generative power. Brown and Wilson (1996) proposed a model based on intersections of SCFGs to describe RNA pseudoknots. Cai et al. (2003) introduced a model based on parallel communication grammar systems using a single CFG synchronized with a number of regular grammars. Akutsu (2000) provided dynamic programming algorithms for RNA pseudoknot prediction without using grammars. On the other hand, several grammars have been proposed where the grammar itself can fully describe pseudoknots. Rivas and Eddy (1999, 2000) provided a dynamic programming 57 Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 57–64, Sydney, July 2006. c�2006 Association for Computational Linguistics algorithm for predicting RNA secondary structure including pseudoknots, and introduced a new class of grammars called RNA pseudoknot grammars (RPGs) for d</context>
</contexts>
<marker>Akutsu, 2000</marker>
<rawString>Tatsuya Akutsu. 2000. Dynamic programming algorithms for RNA secondary structure prediction with pseudoknots. Discrete Applied Mathematics, 104:45–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Brown</author>
<author>Charles Wilson</author>
</authors>
<title>RNA pseudoknot modeling using intersections of stochastic context free grammars with applications to database search.</title>
<date>1996</date>
<booktitle>Proc. Pacific Symposium on Biocomputing,</booktitle>
<pages>109--125</pages>
<contexts>
<context position="2856" citStr="Brown and Wilson (1996)" startWordPosition="452" endWordPosition="455">ion trees among them. One solution to this problem is to extend a grammar to a probabilistic model and find the most likely derivation tree, and another is to take free energy minimization into account. Eddy and Durbin (1994), and Sakakibara et al. (1994) modeled RNA secondary structure without pseudoknots by using stochastic context-free grammars (stochastic CFGs or SCFGs). For pseudoknotted structure (Figure 1 (a)), however, another approach has to be taken since a single CFG cannot represent crossing dependencies of base pairs in pseudoknots (Figure 1 (b)) for the lack of generative power. Brown and Wilson (1996) proposed a model based on intersections of SCFGs to describe RNA pseudoknots. Cai et al. (2003) introduced a model based on parallel communication grammar systems using a single CFG synchronized with a number of regular grammars. Akutsu (2000) provided dynamic programming algorithms for RNA pseudoknot prediction without using grammars. On the other hand, several grammars have been proposed where the grammar itself can fully describe pseudoknots. Rivas and Eddy (1999, 2000) provided a dynamic programming 57 Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related For</context>
</contexts>
<marker>Brown, Wilson, 1996</marker>
<rawString>Michael Brown and Charles Wilson. 1996. RNA pseudoknot modeling using intersections of stochastic context free grammars with applications to database search. Proc. Pacific Symposium on Biocomputing, 109–125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liming Cai</author>
<author>Russell L Malmberg</author>
<author>Yunzhou Wu</author>
</authors>
<title>Stochastic modeling of RNA pseudoknotted structures: a grammatical approach.</title>
<date>2003</date>
<journal>Bioinformatics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="2952" citStr="Cai et al. (2003)" startWordPosition="469" endWordPosition="472"> find the most likely derivation tree, and another is to take free energy minimization into account. Eddy and Durbin (1994), and Sakakibara et al. (1994) modeled RNA secondary structure without pseudoknots by using stochastic context-free grammars (stochastic CFGs or SCFGs). For pseudoknotted structure (Figure 1 (a)), however, another approach has to be taken since a single CFG cannot represent crossing dependencies of base pairs in pseudoknots (Figure 1 (b)) for the lack of generative power. Brown and Wilson (1996) proposed a model based on intersections of SCFGs to describe RNA pseudoknots. Cai et al. (2003) introduced a model based on parallel communication grammar systems using a single CFG synchronized with a number of regular grammars. Akutsu (2000) provided dynamic programming algorithms for RNA pseudoknot prediction without using grammars. On the other hand, several grammars have been proposed where the grammar itself can fully describe pseudoknots. Rivas and Eddy (1999, 2000) provided a dynamic programming 57 Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 57–64, Sydney, July 2006. c�2006 Association for Computational Linguistics algori</context>
</contexts>
<marker>Cai, Malmberg, Wu, 2003</marker>
<rawString>Liming Cai, Russell L. Malmberg, and Yunzhou Wu. 2003. Stochastic modeling of RNA pseudoknotted structures: a grammatical approach. Bioinformatics, 19(1):i66–i73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Durbin</author>
<author>Sean R Eddy</author>
<author>Anders Krogh</author>
<author>Graeme Mitchison</author>
</authors>
<title>Biological Sequence Analysis,</title>
<date>1998</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="10667" citStr="Durbin et al., 1998" startWordPosition="1920" endWordPosition="1923">ility of a sequence given a stochastic grammar (scoring problem), and (3) estimate optimal probability parameters for a stochastic grammar given a set of example sequences (training problem). In this section, we give solutions to each problem for the specific SMCFG G3 = (N, T, F, P, S). 3.1 Alignment Problem The alignment problem for G3 is to find the most probable derivation tree for a given input se&apos;These types stand for END, START, DELETE, BIFURCATION, UNPAIR and PAIR respectively. quence. This problem can be solved by a dynamic programming algorithm similar to the CYK algorithm for SCFGs (Durbin et al., 1998), and in this paper, we also call the parsing algorithm for G3 the CYK algorithm. We fix an input sequence w = a1 ··· an (|w |= n). Let -yv(i,j) and -yy(i,j,k,l) be the logarithm of maximum probabilities of a derivation subtree rooted at a nonterminal Wv for a terminal subsequence ai · · · aj and of a derivation subtree rooted at a nonterminal Wy for a tuple of terminal subsequences (ai · · · aj, ak · · · al) respectively. The variables -yv(i, i − 1) and -yy(i, i − 1, j, j − 1) are the logarithm of maximum probabilities for an empty sequence E and a pair of E. Let τv(i, j) and τy(i, j, k, l) b</context>
<context position="14336" citStr="Durbin et al., 1998" startWordPosition="2749" endWordPosition="2752">, al) = ev(ak) for type(v) U2L, al) = for type(v) U2R, aj type(v) = U2L, an d ∆1L v , ... ∆2R v are set to 0 for the other types except P. When the calculation terminates, we obtain log P(w, πˆ |θ) = γ1(1, n). If there are b BIFURCATION nonterminals and a other nonterminals, the time and space complexities of the CYK algorithm are O(amn4 + bn5) and O(mn4), respectively. To recover the optimal derivation tree, we use the traceback variables τ. Due to limitation of the space, the full description of the traceback algorithm is omitted (see (Kato and Seki, 2006)). 3.2 Scoring Problem As in SCFGs (Durbin et al., 1998), the scoring problem for can be solved by the inside algorithm. The inside algorithm calculates the summed probabilities j) and j, k, l) of all derivation subtrees rooted at a nonterminal Wv for a subsequence ai aj and of all derivation subtrees rooted at a nonterminal Wy for a tuple of subsequences (ai aj, ak respectively. The variables i and i j, j are defined for empty sequences in a similar way to the CYK algorithm. Therefore, we can easily obtain the inside algorithm by replacing max operations with summations in the CYK algorithm. When the calculation terminates, we obtain the probabili</context>
<context position="22094" citStr="Durbin et al., 1998" startWordPosition="4306" endWordPosition="4309">mily Precision [%] Recall [%] CPU time [sec] Average Min Max Average Min Max Average Min Max Corona pk 3 99.4 94.4 100.0 99.4 94.4 100.0 27.8 26.0 30.4 HDV ribozyme 100.0 100.0 100.0 100.0 100.0 100.0 252.1 219.0 278.4 Tombus 3 IV 100.0 100.0 100.0 100.0 100.0 100.0 244.8 215.2 257.5 4.2 Implementation We specified a particular SMCFG G3 by utilizing secondary structure annotation of each family. Rules were determined by considering consensus secondary structure. Probability parameters were estimated in a few selected sequences by the simplest pseudocounting method known as the Laplace’s rule (Durbin et al., 1998): to add one extra count to the true counts for each base configuration observed in a few selected sequences. Note that the inside-outside algorithm was not used in the experiments. The other sequences in the alignment were used as the test sequences for prediction (see Table 2). We implemented the CYK algorithm with traceback in ANSI C on a machine with Intel Pentium D CPU 2.80 GHz and 2.00 GB RAM. Straightforward implementation gives rise to a serious problem of lack of memory space due to the higher order dynamic programming matrix (remember that the space complexity of the CYK algorithm is</context>
</contexts>
<marker>Durbin, Eddy, Krogh, Mitchison, 1998</marker>
<rawString>Richard Durbin, Sean R. Eddy, Anders Krogh, and Graeme Mitchison. 1998. Biological Sequence Analysis, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sean R Eddy</author>
<author>Richard Durbin</author>
</authors>
<title>RNA sequence analysis using covariance models.</title>
<date>1994</date>
<journal>Nuc. Acids Res.,</journal>
<volume>22</volume>
<issue>11</issue>
<contexts>
<context position="2458" citStr="Eddy and Durbin (1994)" startWordPosition="390" endWordPosition="393"> secondary structure prediction can be viewed as parsing problem. However, there may be many different derivation trees for an input sequence. Thus, it is necessary to have a method of extracting biologically realistic C 5’−C A G G · · · U C C A G U · · · G U C A G−3’ C (a) Pseudoknot c a g g c u g a c c u g c u c a g (b) Arc depiction of (a) Figure 1: Example of RNA secondary structure derivation trees among them. One solution to this problem is to extend a grammar to a probabilistic model and find the most likely derivation tree, and another is to take free energy minimization into account. Eddy and Durbin (1994), and Sakakibara et al. (1994) modeled RNA secondary structure without pseudoknots by using stochastic context-free grammars (stochastic CFGs or SCFGs). For pseudoknotted structure (Figure 1 (a)), however, another approach has to be taken since a single CFG cannot represent crossing dependencies of base pairs in pseudoknots (Figure 1 (b)) for the lack of generative power. Brown and Wilson (1996) proposed a model based on intersections of SCFGs to describe RNA pseudoknots. Cai et al. (2003) introduced a model based on parallel communication grammar systems using a single CFG synchronized with a</context>
<context position="20593" citStr="Eddy and Durbin, 1994" startWordPosition="4020" endWordPosition="4023">ideoutside algorithm is as follows: Algorithm 3 (Inside-Outside). Initialization: Pick arbitrary probability parameters of the model. Iteration: Calculate the new probability parameters using (3.1). Calculate the new log likelihood ∑N r=1 log P(w(r) |θ) of the model. Termination: Stop if the change in log likelihood is less than predefined threshold. 4 Experimental Results 4.1 Data for Experiments The dataset for experiments was taken from an RNA family database called “Rfam” (version 7.0) (Griffiths-Jones et al., 2003) which is a database of multiple sequence alignment and covariance models (Eddy and Durbin, 1994) representing non-coding RNA families. We selected three viral RNA families with pseudoknot annotations named Corona pk 3 (Corona), HDV ribozyme (HDV) and Tombus 3 IV (Tombus) (see Table 2). Corona pk 3 has a simple pseudoknotted structure, whereas HDV ribozyme and Tombus 3 IV have more complicated structures with pseudoknot. ∑ j 1 E(v — ab) = ∑N n−1∑ n−1∑ ∑n ∑n h=i−1 r=1 i=1 j=i k=j+1 l=k P (w(r) |θ) ∑N n+1∑ ∑n r=1 i=1 j=i−1 E(v ∑N n+1∑ ∑n n+1∑ ∑n 1 — y) = r=1 i=1 j=i−1 k=j+1 l=k−1 P(w(r) |θ) E(v — a) = ∑N ∑n ∑n n+1∑ ∑n r=1 i=1 j=i k=j+1 l=k−1 E(v — a) = ∑N n−1∑ n−1∑ ∑n n r=1 i=1 j=i−1 k=j+1 </context>
</contexts>
<marker>Eddy, Durbin, 1994</marker>
<rawString>Sean R. Eddy and Richard Durbin. 1994. RNA sequence analysis using covariance models. Nuc. Acids Res., 22(11):2079–2088.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sam Griffiths-Jones</author>
<author>Alex Bateman</author>
<author>Mhairi Marshall</author>
<author>Ajay Khanna</author>
<author>Sean R Eddy</author>
</authors>
<title>Rfam: an RNA family database.</title>
<date>2003</date>
<journal>Nuc. Acids Res.,</journal>
<volume>31</volume>
<issue>1</issue>
<pages>441</pages>
<contexts>
<context position="20496" citStr="Griffiths-Jones et al., 2003" startWordPosition="4005" endWordPosition="4008">y corresponding to its nonterminal type must be substituted for the above equations. In summary, the insideoutside algorithm is as follows: Algorithm 3 (Inside-Outside). Initialization: Pick arbitrary probability parameters of the model. Iteration: Calculate the new probability parameters using (3.1). Calculate the new log likelihood ∑N r=1 log P(w(r) |θ) of the model. Termination: Stop if the change in log likelihood is less than predefined threshold. 4 Experimental Results 4.1 Data for Experiments The dataset for experiments was taken from an RNA family database called “Rfam” (version 7.0) (Griffiths-Jones et al., 2003) which is a database of multiple sequence alignment and covariance models (Eddy and Durbin, 1994) representing non-coding RNA families. We selected three viral RNA families with pseudoknot annotations named Corona pk 3 (Corona), HDV ribozyme (HDV) and Tombus 3 IV (Tombus) (see Table 2). Corona pk 3 has a simple pseudoknotted structure, whereas HDV ribozyme and Tombus 3 IV have more complicated structures with pseudoknot. ∑ j 1 E(v — ab) = ∑N n−1∑ n−1∑ ∑n ∑n h=i−1 r=1 i=1 j=i k=j+1 l=k P (w(r) |θ) ∑N n+1∑ ∑n r=1 i=1 j=i−1 E(v ∑N n+1∑ ∑n n+1∑ ∑n 1 — y) = r=1 i=1 j=i−1 k=j+1 l=k−1 P(w(r) |θ) E(v </context>
</contexts>
<marker>Griffiths-Jones, Bateman, Marshall, Khanna, Eddy, 2003</marker>
<rawString>Sam Griffiths-Jones, Alex Bateman, Mhairi Marshall, Ajay Khanna, and Sean R. Eddy. 2003. Rfam: an RNA family database. Nuc. Acids Res., 31(1):439– 441.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tadao Kasami</author>
<author>Hiroyuki Seki</author>
<author>Mamoru Fujii</author>
</authors>
<title>Generalized context-free grammar and multiple context-free grammar.</title>
<date>1988</date>
<journal>IEICE Trans. Inf. &amp; Syst., J71-D(5):758–765 (in Japanese).</journal>
<contexts>
<context position="4402" citStr="Kasami et al., 1988" startWordPosition="681" endWordPosition="684">e adjoining grammars (TAGs) named SL-TAGs and extended SL-TAGs (ESL-TAGs) respectively, and predicted RNA pseudoknots by using parsing algorithm of ESL-TAG. Matsui et al. (2005) proposed pair stochastic tree adjoining grammars (PSTAGs) based on ESL-TAGs and tree automata for aligning and predicting pseudoknots, which showed good prediction accuracy. These grammars have generative power stronger than CFGs and polynomial time algorithms for parsing problem. In our previous work (Kato et al., 2005), we identified RPGs, SL-TAGs and ESL-TAGs as subclasses of multiple context-free grammars (MCFGs) (Kasami et al., 1988; Seki et al., 1991), which can model RNA pseudoknots, and showed a candidate subclass of the minimum grammars for representing pseudoknots. The generative power of MCFGs is stronger than that of CFGs and MCFGs have a polynomial time parsing algorithm like the CYK (Cocke-Younger-Kasami) algorithm for CFGs. In this paper, we extend the above candidate subclass of MCFGs to a probabilistic model called a stochastic MCFG (SMCFG). We present a polynomial time parsing algorithm for finding the most probable derivation tree, which is applicable to RNA pseudoknot prediction. In addition, we mention a </context>
</contexts>
<marker>Kasami, Seki, Fujii, 1988</marker>
<rawString>Tadao Kasami, Hiroyuki Seki, and Mamoru Fujii. 1988. Generalized context-free grammar and multiple context-free grammar. IEICE Trans. Inf. &amp; Syst., J71-D(5):758–765 (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuki Kato</author>
<author>Hiroyuki Seki</author>
<author>Tadao Kasami</author>
</authors>
<title>On the generative power of grammars for RNA secondary structure.</title>
<date>2005</date>
<journal>IEICE Trans. Inf. &amp; Syst.,</journal>
<pages>88--1</pages>
<contexts>
<context position="4283" citStr="Kato et al., 2005" startWordPosition="664" endWordPosition="667">NA pseudoknot grammars (RPGs) for deriving sequences with gap. Uemura et al. (1999) defined specific subclasses of tree adjoining grammars (TAGs) named SL-TAGs and extended SL-TAGs (ESL-TAGs) respectively, and predicted RNA pseudoknots by using parsing algorithm of ESL-TAG. Matsui et al. (2005) proposed pair stochastic tree adjoining grammars (PSTAGs) based on ESL-TAGs and tree automata for aligning and predicting pseudoknots, which showed good prediction accuracy. These grammars have generative power stronger than CFGs and polynomial time algorithms for parsing problem. In our previous work (Kato et al., 2005), we identified RPGs, SL-TAGs and ESL-TAGs as subclasses of multiple context-free grammars (MCFGs) (Kasami et al., 1988; Seki et al., 1991), which can model RNA pseudoknots, and showed a candidate subclass of the minimum grammars for representing pseudoknots. The generative power of MCFGs is stronger than that of CFGs and MCFGs have a polynomial time parsing algorithm like the CYK (Cocke-Younger-Kasami) algorithm for CFGs. In this paper, we extend the above candidate subclass of MCFGs to a probabilistic model called a stochastic MCFG (SMCFG). We present a polynomial time parsing algorithm for </context>
</contexts>
<marker>Kato, Seki, Kasami, 2005</marker>
<rawString>Yuki Kato, Hiroyuki Seki, and Tadao Kasami. 2005. On the generative power of grammars for RNA secondary structure. IEICE Trans. Inf. &amp; Syst., E88-D(1):53–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuki Kato</author>
<author>Hiroyuki Seki</author>
</authors>
<title>Stochastic multiple context-free grammar for RNA pseudoknot modeling.</title>
<date>2006</date>
<tech>NAIST Info. Sci. Tech. Rep. (NAIST-ISTR2006002).</tech>
<contexts>
<context position="14280" citStr="Kato and Seki, 2006" startWordPosition="2739" endWordPosition="2742">aj, Note: 60 ev(ai, aj, al) = ev(aj) for type(v) U1R, aj, al) = ev(ak) for type(v) U2L, al) = for type(v) U2R, aj type(v) = U2L, an d ∆1L v , ... ∆2R v are set to 0 for the other types except P. When the calculation terminates, we obtain log P(w, πˆ |θ) = γ1(1, n). If there are b BIFURCATION nonterminals and a other nonterminals, the time and space complexities of the CYK algorithm are O(amn4 + bn5) and O(mn4), respectively. To recover the optimal derivation tree, we use the traceback variables τ. Due to limitation of the space, the full description of the traceback algorithm is omitted (see (Kato and Seki, 2006)). 3.2 Scoring Problem As in SCFGs (Durbin et al., 1998), the scoring problem for can be solved by the inside algorithm. The inside algorithm calculates the summed probabilities j) and j, k, l) of all derivation subtrees rooted at a nonterminal Wv for a subsequence ai aj and of all derivation subtrees rooted at a nonterminal Wy for a tuple of subsequences (ai aj, ak respectively. The variables i and i j, j are defined for empty sequences in a similar way to the CYK algorithm. Therefore, we can easily obtain the inside algorithm by replacing max operations with summations in the CYK algorithm. </context>
</contexts>
<marker>Kato, Seki, 2006</marker>
<rawString>Yuki Kato and Hiroyuki Seki. 2006. Stochastic multiple context-free grammar for RNA pseudoknot modeling. NAIST Info. Sci. Tech. Rep. (NAIST-ISTR2006002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Matsui</author>
<author>Kengo Sato</author>
<author>Yasubumi Sakakibara</author>
</authors>
<title>Pair stochastic tree adjoining grammars for aligning and predicting pseudoknot RNA structures.</title>
<date>2005</date>
<journal>Bioinformatics,</journal>
<volume>21</volume>
<issue>11</issue>
<contexts>
<context position="3960" citStr="Matsui et al. (2005)" startWordPosition="616" endWordPosition="619">ded a dynamic programming 57 Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 57–64, Sydney, July 2006. c�2006 Association for Computational Linguistics algorithm for predicting RNA secondary structure including pseudoknots, and introduced a new class of grammars called RNA pseudoknot grammars (RPGs) for deriving sequences with gap. Uemura et al. (1999) defined specific subclasses of tree adjoining grammars (TAGs) named SL-TAGs and extended SL-TAGs (ESL-TAGs) respectively, and predicted RNA pseudoknots by using parsing algorithm of ESL-TAG. Matsui et al. (2005) proposed pair stochastic tree adjoining grammars (PSTAGs) based on ESL-TAGs and tree automata for aligning and predicting pseudoknots, which showed good prediction accuracy. These grammars have generative power stronger than CFGs and polynomial time algorithms for parsing problem. In our previous work (Kato et al., 2005), we identified RPGs, SL-TAGs and ESL-TAGs as subclasses of multiple context-free grammars (MCFGs) (Kasami et al., 1988; Seki et al., 1991), which can model RNA pseudoknots, and showed a candidate subclass of the minimum grammars for representing pseudoknots. The generative po</context>
<context position="23738" citStr="Matsui et al., 2005" startWordPosition="4584" endWordPosition="4587">to the total number of predicted base pairs, and the ratio of the number of correct base pairs predicted by the algorithm to the total number of base pairs specified by the trusted annotation, respectively. The results are shown in Table 3. A nearly correct prediction (94.4% precision and recall) for Corona pk 3 is shown in Figure 2 where underlined base pairs agree with trusted ones. The secondary structures predicted by our algorithm agree very well with the trusted structures. 4.4 Comparison with PSTAG We compared the prediction accuracy of our SMCFG algorithm with that of PSTAG algorithm (Matsui et al., 2005) (see Table 4). PSTAGs, as we have mentioned before, are proposed for modeling pairwise alignment of RNA sequences with pseudoknots and assign a probability to each alignment of TAG derivation trees. PSTAG algorithm, based on dynamic programming, calculates the most likely alignment for the pair of TAG derivation trees where one of them is in the form of an unfolded sequence and the other is a TAG derivation tree for known structure. SMCFG method shows better performance in accuracy than PSTAG method in the same test sets. 5 Conclusion In this paper, we have proposed a probabilistic model name</context>
</contexts>
<marker>Matsui, Sato, Sakakibara, 2005</marker>
<rawString>Hiroshi Matsui, Kengo Sato, and Yasubumi Sakakibara. 2005. Pair stochastic tree adjoining grammars for aligning and predicting pseudoknot RNA structures. Bioinformatics, 21(11):2611–2617.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elena Rivas</author>
<author>Sean R Eddy</author>
</authors>
<title>A dynamic programming algorithm for RNA structure prediction including pseudoknots.</title>
<date>1999</date>
<journal>J. Mol. Biol.,</journal>
<volume>285</volume>
<contexts>
<context position="3327" citStr="Rivas and Eddy (1999" startWordPosition="527" endWordPosition="530">ngle CFG cannot represent crossing dependencies of base pairs in pseudoknots (Figure 1 (b)) for the lack of generative power. Brown and Wilson (1996) proposed a model based on intersections of SCFGs to describe RNA pseudoknots. Cai et al. (2003) introduced a model based on parallel communication grammar systems using a single CFG synchronized with a number of regular grammars. Akutsu (2000) provided dynamic programming algorithms for RNA pseudoknot prediction without using grammars. On the other hand, several grammars have been proposed where the grammar itself can fully describe pseudoknots. Rivas and Eddy (1999, 2000) provided a dynamic programming 57 Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 57–64, Sydney, July 2006. c�2006 Association for Computational Linguistics algorithm for predicting RNA secondary structure including pseudoknots, and introduced a new class of grammars called RNA pseudoknot grammars (RPGs) for deriving sequences with gap. Uemura et al. (1999) defined specific subclasses of tree adjoining grammars (TAGs) named SL-TAGs and extended SL-TAGs (ESL-TAGs) respectively, and predicted RNA pseudoknots by using parsing algorithm</context>
</contexts>
<marker>Rivas, Eddy, 1999</marker>
<rawString>Elena Rivas and Sean R. Eddy. 1999. A dynamic programming algorithm for RNA structure prediction including pseudoknots. J. Mol. Biol., 285:2053– 2068.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elena Rivas</author>
<author>Sean R Eddy</author>
</authors>
<title>The language of RNA: A formal grammar that includes pseudoknots.</title>
<date>2000</date>
<journal>Bioinformatics,</journal>
<volume>16</volume>
<issue>4</issue>
<marker>Rivas, Eddy, 2000</marker>
<rawString>Elena Rivas and Sean R. Eddy. 2000. The language of RNA: A formal grammar that includes pseudoknots. Bioinformatics, 16(4):334–340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasubumi Sakakibara</author>
<author>Michael Brown</author>
<author>Richard Hughey</author>
<author>I Saira Mian</author>
<author>Kimmen Sj¨olander</author>
<author>Rebecca C Underwood</author>
<author>David Haussler</author>
</authors>
<title>Stochastic context-free grammars for tRNA modeling.</title>
<date>1994</date>
<journal>Nuc. Acids Res.,</journal>
<pages>22--5112</pages>
<marker>Sakakibara, Brown, Hughey, Mian, Sj¨olander, Underwood, Haussler, 1994</marker>
<rawString>Yasubumi Sakakibara, Michael Brown, Richard Hughey, I. Saira Mian, Kimmen Sj¨olander, Rebecca C. Underwood, and David Haussler. 1994. Stochastic context-free grammars for tRNA modeling. Nuc. Acids Res., 22:5112–5120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyuki Seki</author>
<author>Takashi Matsumura</author>
<author>Mamoru Fujii</author>
<author>Tadao Kasami</author>
</authors>
<title>On multiple context-free grammars.</title>
<date>1991</date>
<journal>Theor. Comput. Sci.,</journal>
<pages>88--191</pages>
<contexts>
<context position="4422" citStr="Seki et al., 1991" startWordPosition="685" endWordPosition="688">(TAGs) named SL-TAGs and extended SL-TAGs (ESL-TAGs) respectively, and predicted RNA pseudoknots by using parsing algorithm of ESL-TAG. Matsui et al. (2005) proposed pair stochastic tree adjoining grammars (PSTAGs) based on ESL-TAGs and tree automata for aligning and predicting pseudoknots, which showed good prediction accuracy. These grammars have generative power stronger than CFGs and polynomial time algorithms for parsing problem. In our previous work (Kato et al., 2005), we identified RPGs, SL-TAGs and ESL-TAGs as subclasses of multiple context-free grammars (MCFGs) (Kasami et al., 1988; Seki et al., 1991), which can model RNA pseudoknots, and showed a candidate subclass of the minimum grammars for representing pseudoknots. The generative power of MCFGs is stronger than that of CFGs and MCFGs have a polynomial time parsing algorithm like the CYK (Cocke-Younger-Kasami) algorithm for CFGs. In this paper, we extend the above candidate subclass of MCFGs to a probabilistic model called a stochastic MCFG (SMCFG). We present a polynomial time parsing algorithm for finding the most probable derivation tree, which is applicable to RNA pseudoknot prediction. In addition, we mention a probability paramete</context>
</contexts>
<marker>Seki, Matsumura, Fujii, Kasami, 1991</marker>
<rawString>Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii, and Tadao Kasami. 1991. On multiple context-free grammars. Theor. Comput. Sci., 88:191–229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasuo Uemura</author>
<author>Aki Hasegawa</author>
<author>Satoshi Kobayashi</author>
<author>Takashi Yokomori</author>
</authors>
<title>Tree adjoining grammars for RNA structure prediction.</title>
<date>1999</date>
<journal>Theor. Comput. Sci.,</journal>
<pages>210--277</pages>
<contexts>
<context position="3748" citStr="Uemura et al. (1999)" startWordPosition="585" endWordPosition="589">g algorithms for RNA pseudoknot prediction without using grammars. On the other hand, several grammars have been proposed where the grammar itself can fully describe pseudoknots. Rivas and Eddy (1999, 2000) provided a dynamic programming 57 Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 57–64, Sydney, July 2006. c�2006 Association for Computational Linguistics algorithm for predicting RNA secondary structure including pseudoknots, and introduced a new class of grammars called RNA pseudoknot grammars (RPGs) for deriving sequences with gap. Uemura et al. (1999) defined specific subclasses of tree adjoining grammars (TAGs) named SL-TAGs and extended SL-TAGs (ESL-TAGs) respectively, and predicted RNA pseudoknots by using parsing algorithm of ESL-TAG. Matsui et al. (2005) proposed pair stochastic tree adjoining grammars (PSTAGs) based on ESL-TAGs and tree automata for aligning and predicting pseudoknots, which showed good prediction accuracy. These grammars have generative power stronger than CFGs and polynomial time algorithms for parsing problem. In our previous work (Kato et al., 2005), we identified RPGs, SL-TAGs and ESL-TAGs as subclasses of multi</context>
</contexts>
<marker>Uemura, Hasegawa, Kobayashi, Yokomori, 1999</marker>
<rawString>Yasuo Uemura, Aki Hasegawa, Satoshi Kobayashi, and Takashi Yokomori. 1999. Tree adjoining grammars for RNA structure prediction. Theor. Comput. Sci., 210:277–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>David J Weir</author>
<author>Aravind K Joshi</author>
</authors>
<title>Characterizing structural descriptions produced by various grammatical formalisms.</title>
<date>1987</date>
<booktitle>Proc. 25th Annual Meeting of Association for Computational Linguistics (ACL87),</booktitle>
<pages>104--111</pages>
<contexts>
<context position="5507" citStr="Vijay-Shanker et al., 1987" startWordPosition="853" endWordPosition="856">or finding the most probable derivation tree, which is applicable to RNA pseudoknot prediction. In addition, we mention a probability parameter estimation method based on the EM (expectation maximization) algorithm. Finally, we show some experimental results on pseudoknot prediction for three RNA families using SMCFG algorithm, which show good prediction accuracy. 2 Stochastic Multiple Context-Free Grammar A stochastic multiple context-free grammar (stochastic MCFG, or SMCFG) is a probabilistic extension of MCFG (Kasami et al., 1988; Seki et al., 1991) or linear context-free rewriting system (Vijay-Shanker et al., 1987). An SMCFG is a 5- tuple G = (N, T, F, P, 5) where N is a finite set of nonterminals, T is a finite set of terminals, F is a finite set of functions, P is a finite set of (production) rules and 5 ∈ N is the start symbol. For each A ∈ N, a positive integer denoted by dim(A) is given and A derives dim(A)-tuples of terminal sequences. For the start symbol 5, dim(5) = 1. For each f ∈ F, positive integers di (0 ≤ i ≤ k) are given and f is a total function from (T∗)d1 × · · · × (T ∗)dk to (T ∗)d0 where each component of f is defined as the concatenation of some components of arguments and constant s</context>
</contexts>
<marker>Vijay-Shanker, Weir, Joshi, 1987</marker>
<rawString>K. Vijay-Shanker, David J. Weir, and Aravind K. Joshi. 1987. Characterizing structural descriptions produced by various grammatical formalisms. Proc. 25th Annual Meeting of Association for Computational Linguistics (ACL87), 104–111.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>