<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000209">
<title confidence="0.995293">
Combining Classifiers for Chinese Word Segmentation
</title>
<author confidence="0.983812">
Nianwen Xue
</author>
<affiliation confidence="0.9937325">
Institute for Research in Cognitive Science
University of Pennsylvania
</affiliation>
<address confidence="0.9732525">
Suite 400A, 3401 Walnut
Philadelphia, PA 19014
</address>
<email confidence="0.991411">
xueniwen@linc.cis.upenn.edu
</email>
<author confidence="0.811071">
Susan P. Converse
</author>
<affiliation confidence="0.992135">
Dept. of Computer and Information Science
University of Pennsylvania
</affiliation>
<address confidence="0.959539">
200 South 33rd Street,
Philadelphia, PA 19104-6389
</address>
<email confidence="0.995951">
spc@linc.cis.upenn.edu
</email>
<sectionHeader confidence="0.981408" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999585642857143">
In this paper we report results of a
supervised machine-learning approach to
Chinese word segmentation. First, a maximum
entropy tagger is trained on manually annotated
data to automatically labels the characters with
tags that indicate the position of character within
a word. An error-driven transformation-based
tagger is then trained to clean up the tagging
inconsistencies of the first tagger. The tagged
output is then converted into segmented text.
The preliminary results show that this approach
is competitive compared with other supervised
machine-learning segmenters reported in
previous studies.
</bodyText>
<sectionHeader confidence="0.995724" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.979395217391304">
It is generally agreed among researchers that
word segmentation is a necessary first step in
Chinese language processing. Most of the
previous work in this area views a good
dictionary as the cornerstone of this task. Several
word segmentation algorithms have been
developed using a dictionary as an essential tool.
Most notably, variants of the maximum
matching algorithm have been applied to word
segmentation with considerable success. The
results that have been reported are generally in
the upper 90 percentile range. However, the
success of such algorithms is premised on a large,
exhaustive dictionary. The accuracy of word
segmentation degrades sharply as new words
appear. Since Chinese word formation is a
highly productive process, new words are bound
to appear in substantial numbers in realistic
scenarios (Wu and Jiang 1998, Xue 2001), and it
is virtually impossible to list all the words in a
dictionary. In recent years, as annotated Chinese
corpora have become available, various
machine-learning approaches have been applied
to Chinese word segmentation, with different
levels of success. Compared with dictionary-
based approaches, machine-learning approaches
have the advantage of not needing a dictionary
and thus are more suitable for use on naturally
occurring Chinese text. In this paper we report
results of a supervised machine-learning
approach towards Chinese word segmentation
that combines two fairly standard machine
learning models. We show that this approach is
very promising compared with dictionary-based
approaches as well as other machine-learning
approaches that have been reported in the
literature.
2 Combining Classifiers for
Chinese word segmentation
The two machine-learning models we use in this
work are the maximum entropy model
(Ratnaparkhi 1996) and the error-driven
transformation-based learning model (Brill
1994). We use the former as the main workhorse
and the latter to correct some of the errors
produced by the former.
</bodyText>
<subsectionHeader confidence="0.6702355">
2.1 Reformulating word segmentation
as a tagging problem
</subsectionHeader>
<bodyText confidence="0.978802888888889">
Before we apply the machine-learning
algorithms we first convert the manually
segmented words in the corpus into a tagged
sequence of Chinese characters. To do this, we
tag each character with one of the four tags, LL,
RR, MM and LR, depending on its position
within a word. It is tagged LL if it occurs on the
left boundary of a word, and forms a word with
the character(s) on its right. It is tagged RR if it
occurs on the right boundary of a word, and
forms a word with the character(s) on its left. It
is tagged MM if it occurs in the middle of a word.
It is tagged LR if it forms a word by itself. We
call such tags position-of-character (POC) tags
to differentiate them from the more familiar part-
of-speech (POS) tags. For example, the manually
segmented string in (1)a will be tagged as shown
in (1)b:
</bodyText>
<listItem confidence="0.89297">
(1) a.
b. /LL /RR /LL /RR /LR /LR
/LL /RR /LR /LL /RR /LL /RR
/LL /RR /LL /RR /LL /RR /LL
/RR /LL /RR
c. Shanghai plans to reach the goal of 5,000
dollars in per capita GDP by the end of the
century.
</listItem>
<bodyText confidence="0.9975155">
Given a manually segmented corpus, a POC-
tagged corpus can be derived trivially with
perfect accuracy. The reason that we use such
POC-tagged sequences of characters instead of
applying n-gram rules to a segmented corpus
directly (Hockenmaier and Brew 1998, Xue
2001) is that they are much easier to manipulate
in the training process. Naturally, while some
characters will have only one POC tag, most
characters will receive multiple POC tags, in the
same way that words can have multiple POS tags.
The example in (2) shows how all four of the
POC tags can be assigned to the character
(‘produce’):
</bodyText>
<listItem confidence="0.70929175">
(2) LL &apos;product&apos;
LR &apos;produce&apos;
MM &apos;productivity&apos;
RR &apos;start production&apos;
</listItem>
<bodyText confidence="0.99751">
Also as in POS tags, the way the character is
POC-tagged in naturally occurring text is
affected by the context in which it occurs. For
example, if the preceding character is tagged a
LR or RR, then the next character can only be
tagged LL or LR. How a character is tagged is
also affected by the surrounding characters. For
example, (‘close’) should be tagged RR if the
previous character is (‘open’) and neither of
them forms a word with other characters, while it
should be tagged LL if the next character is
(‘heart’) and neither of them forms a word with
other characters. This state of affairs closely
resembles the familiar POS tagging problem and
lends itself naturally to a solution similar to that
of POS tagging. The task is one of ambiguity
resolution in which the correct POC tag is
determined among several possible POC tags in
a specific context. Our next step is to train a
maximum entropy model on the perfectly POC-
tagged data derived from a manually segmented
corpus and use the model to automatically POC-
tag unseen text.
</bodyText>
<subsectionHeader confidence="0.993864">
2.2 The maximum entropy tagger
</subsectionHeader>
<bodyText confidence="0.999984625">
The maximum entropy model used in POS-
tagging is described in detail in Ratnaparkhi
(1996) and the POC tagger here uses the same
probability model. The probability model is
defined over H x T, where H is the set of
possible contexts or &amp;quot;histories&amp;quot; and T is the set of
possible tags. The model&apos;s joint probability of a
history h and a tag t is defined as
</bodyText>
<equation confidence="0.99689775">
p(h,t) = z/l laij (i)
T� i&apos;(h,t)
k
j=1
</equation>
<bodyText confidence="0.998447">
where is a normalization constant, {✫, 1, ..., k}
are the model parameters and {f1, ..., fk} are
known as features, where fj (h, t) {0,1}. Each
feature fj has a corresponding parameter j,
which effectively serves as a &amp;quot;weight&amp;quot; of this
feature. In the training process, given a sequence
n of characters {c1,...,cn} and their POC tags
{t1,...,tn} as training data, the purpose is to
determine the parameters {✯, 1, ..., k} that
maximize the likelihood L of the training data
using p:
</bodyText>
<equation confidence="0.994351166666667">
k ( , )
hi ti
f
( ) = ∏ p h t
( , ) = ∏ πμ α (ii)
j
L p ∏
i i j
=1 j=1
n
n
i = 1 i
</equation>
<bodyText confidence="0.999965833333333">
The success of the model in tagging depends to a
large extent on the selection of suitable features.
Given (h,t), a feature must encode information
that helps to predict t. The features we used in
this experiment are instantiations of the
following feature templates:
</bodyText>
<listItem confidence="0.900106846153846">
(3) Feature templates used in this tagger:
a. The current character
b.The previous (next) character and the
current character
c. The previous (next) two characters
d. The tag of the previous character
e. The tag of the character two before the
current character
f. Whether the current character is a
punctuation mark
g. Whether the current character is a numeral
h. Whether the current character is a Latin
letter
</listItem>
<bodyText confidence="0.988660314814815">
In general, given (h,t), these features are in the
form of co-occurrence relations between t and
some type of context. For example,
In the second type of context, features based on
the previous tags are extracted. Information like
this is useful in predicting the POC tag for the
current character just as the POS tags are useful
in predicting the POS tag of the current word in
a similar context. For example, if the previous
character is tagged LR or RR, this means that the
current character must start a word, and should
be tagged either LL or LR. Finally, limited POS-
tagging information can also be used to predict
how the current character should be POC-tagged.
For example, a punctuation mark is generally
treated as one segment in the CTB corpus.
Therefore, if a character is a punctuation mark,
then it should be POC-tagged LR. This also
means that the previous character should close a
word and the following character should start a
word. When the training is complete, the
features and their corresponding parameters will
be used to calculate the probability of the tag
sequence of a sentence when the tagger tags
unseen data. Given a sequence of characters
{c1,...,cn}, the tagger searches for the tag
sequence {t1, ..., tn} with the highest conditional
probability
f h t 1 if ti−1 = LL &amp; ti = RR n
( , ) = 0 otherwise PQ1 , ... tn  |c1 , ... cn) = jI p(ti  |hi)
i i i i=1
This feature will map to 1 and contribute
towards p(hi,ti) if c(i-1) is tagged LL and ci is
tagged RR.
The feature templates in (3) encode three types
of contexts. First, features based on the current
and surrounding characters are extracted. Given
a character in a sentence, this model will look at
the current character, the previous two and next
two characters. For example, if the current
character is (‘-ize’), it is very likely that it will
occur as a suffix in a word, thus receiving the tag
RR. On the other hand, other characters might be
equally likely to appear on the left, on the right
or in the middle. In those cases, where a
character occurs within a word depends on its
surrounding characters. For example, if the
current character is (‘love’), it should perhaps
be tagged LL if the next character is
(‘protect’). However, if the previous character is
(‘warm’), then it should perhaps be tagged
RR.
in which the conditional probability for each
POC tag t given its history h is calculated as
</bodyText>
<equation confidence="0.9779625">
p(t  |h) = p(h, t) ) (iv)
t
∈T
′
&apos;
P(h,
</equation>
<subsectionHeader confidence="0.935687">
2.3 The transformation-based
</subsectionHeader>
<bodyText confidence="0.998801266666667">
tagger
The error-driven transformation-based tagger we
used in this paper is Brill&apos;s POS tagger (1994)
with minimal modification. The way this tagger
is set up makes it easy for it to work in
conjunction with other taggers. When it is used
for its original task of POS tagging, the model is
trained in two phases. In the first phase lexical
information, such as the affixes of a word, is
learned to predict POS tags. The rules learned in
this phase are then applied to the training corpus.
In the second phase, contextual information is
learned to correct the wrong tags produced in the
first phase. In the segmentation task, since we
are dealing with single characters, by definition
there is no lexical information as such. Instead,
the training data are first POC-tagged by the
maximum entropy model and then used by the
error-driven transformation-based model to learn
the contextual rules. The error-driven
transformation-based model learns a ranked set
of rules by comparing the perfectly POC-tagged
corpus (the reference corpus) with the same
corpus tagged by the maximum entropy model
(the maxent-tagged corpus). At each iteration,
this model tries to find the rule that achieves the
maximum gain if it is applied. The rule with the
maximum gain is the one that makes the maxent-
tagged corpus most like the reference corpus.
The maximum gain is calculated with an
evaluation function which quantifies the gain
and takes the largest value. The rules are
instantiations of a set of pre-defined rule
templates. After the rule with the maximum gain
is found, it is applied to the maxent-tagged
corpus, which will better resemble the reference
corpus as a result. This process is repeated until
the maximum gain drops below a pre-defined
threshold, which indicates improvement
achieved through further training will no longer
be significant. The training will then be
terminated. The rule templates are the same as
those used in Brill (1994), except that these rule
templates are now defined over characters rather
than words.
</bodyText>
<listItem confidence="0.7285878">
(4) Rule templates used to learn contextual
information:
Change tag a to tag b when:
a. The preceding (following) character is
tagged z.
b. The character two before (after) is tagged z.
c. One of the two preceding (following)
characters is tagged z.
d. One of the three preceding (following)
characters is tagged z.
</listItem>
<bodyText confidence="0.966664611111111">
e. The preceding character is tagged z and the
following character is tagged w.
f. The preceding (following) character is
tagged z and the character two before (after) was
tagged w.
g. The preceding (following) character is c.
h. The character two before (after) is c.
i. One of the two preceding (following)
characters is c.
j. The current character is c and the
preceding (following) character is x.
k. The current character is c and the
preceding (following) character is tagged z.
where a, b, z and w are variables over the set of
four tags (LL, RR, LR, MM)
The ranked set of rules learned in this training
process will be applied to the output of the
maximum entropy tagger.
</bodyText>
<sectionHeader confidence="0.99773" genericHeader="introduction">
3 Experimental results
</sectionHeader>
<bodyText confidence="0.999972741935484">
We conducted three experiments. In the first
experiment, we used the maximum matching
algorithm to establish a baseline, as comparing
results across different data sources can be
difficult. This experiment is also designed to
demonstrate that even with a relatively small
number of new words in the testing data, the
segmentation accuracy drops sharply. In the
second experiment, we applied the maximum
entropy model to the problem of Chinese word
segmentation. The results will show that this
approach alone outperforms the state-of-the-art
results reported in previous work in supervised
machine-learning approaches. In the third
experiment we combined the maximum entropy
model with the error-driven transformation-
based model. We used the error-driven
transformation-based model to learn a set of
rules to correct the errors produced by the
maximum entropy model. The data we used are
from the Penn Chinese Treebank (Xia et al. 2000,
Xue et al. 2002) and they consist of Xinhua
newswire articles. We took 250,389 words
(426,292 characters or hanzi) worth of manually
segmented data and divided them into two
chunks. The first chunk has 237,791 words
(404,680 Chinese characters) and is used as
training data. The second chunk has 12,598
words (21,612 characters) and is used as testing
data. These data are used in all three of our
experiments.
</bodyText>
<subsectionHeader confidence="0.99611">
3.1 Experiment One
</subsectionHeader>
<bodyText confidence="0.999978916666667">
In this experiment, we conducted two sub-
experiments. In the first sub-experiment, we
used a forward maximum matching algorithm to
segment the testing data with a dictionary
compiled from the training data. There are 497
(or 3.95%) new words (words that are not found
in the training data) in the testing data. In the
second sub-experiment, we used the same
algorithm to segment the same testing data with
a dictionary that was compiled from BOTH the
training data and the testing data, so that there
are no “new” words in the testing data.
</bodyText>
<subsectionHeader confidence="0.998901">
3.2 Experiment Two
</subsectionHeader>
<bodyText confidence="0.999997647058824">
In this experiment, a maximum entropy model
was trained on a POC-tagged corpus derived
from the training data described above. In the
testing phase, the sentences in the testing data
were first split into sequences of characters and
then tagged this maximum entropy tagger. The
tagged testing data are then converted back into
word segments for evaluation. Note that
converting a POC-tagged corpus into a
segmented corpus is not entirely straightforward
when inconsistent tagging occurs. For example it
is possible that the tagger assigns a LL-LR
sequence to two adjacent characters. We made
no effort to ensure the best possible conversion.
The character that is POC-tagged LL is
invariably combined with the following
character, no matter how it is tagged.
</bodyText>
<subsectionHeader confidence="0.999294">
3.3 Experiment Three
</subsectionHeader>
<bodyText confidence="0.999948315789474">
In this experiment, we used the maximum
entropy model trained in experiment two to
automatically tag the training data. The training
accuracy of the maximum entropy model is
97.54% in terms of the number of characters
tagged correctly and there are 9940 incorrectly
tagged characters, out of 404,680 characters in
total. We then used this output and the correctly
tagged data derived from the manually
segmented training data (as the reference corpus)
to learn a set of transformation rules. 214 rules
were learned in this phase. These 214 rules were
then used to correct the errors of the testing data
that was first tagged by maximum entropy model
in experiment two. As a final step, the tagged
and corrected testing data were converted into
word segments. Again, no effort was made to
optimize the segmentation accuracy during the
conversion.
</bodyText>
<subsectionHeader confidence="0.941042">
3.4 Evaluation
</subsectionHeader>
<bodyText confidence="0.99992225">
In evaluating our model, we calculated both the
tagging accuracy and segmentation accuracy.
The calculation of the tagging accuracy is
straightforward. It is simply the total number of
correctly POC-tagged characters divided by the
total number of characters. In evaluating
segmentation accuracy, we used three measures:
precision, recall and balanced F-score. Precision
(p) is defined as the number of correctly
segmented words divided by the total number of
words in the automatically segmented corpus.
Recall (r) is defined as the number of correctly
segmented words divided by the total number of
words in the gold standard, which is the
manually annotated corpus. F-score (f) is defined
as follows:
</bodyText>
<equation confidence="0.765426333333333">
p × ×
r 2
+r
</equation>
<bodyText confidence="0.9884205">
The results of the three experiments are tabulated
as follows:
</bodyText>
<table confidence="0.851363375">
tagger tagging segmentation accuracy
accuracy
training testing testing
p(%) r(%) f(%)
1 n/a n/a 87.34 92.34 89.77
2 n/a n/a 94.51 95.80 95.15
3 97.55 95.95 94.90 94.88 94.89
4 97.81 96.07 95.21 95.13 95.17
</table>
<tableCaption confidence="0.997463">
Table 1
</tableCaption>
<footnote confidence="0.7511715">
1 = maximum matching algorithm applied to
testing data with new words
2 = maximum matching algorithm applied to
testing data without new words
</footnote>
<page confidence="0.568401">
3 = maximum entropy tagger
</page>
<figure confidence="0.9472425">
f
(v)
p
4 = maximum entropy tagger combined with
the transformation-based tagger
Incidentally, the combined segmentation
</figure>
<bodyText confidence="0.788492666666667">
accuracy is almost the same as that of the
maximum matching method when there are no
new words.
</bodyText>
<sectionHeader confidence="0.975535" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999915034482759">
The results from Experiment one show that the
accuracy of the maximum matching algorithm
degrades sharply when there are new words in
the testing data, even when there is only a small
proportion of them. Assuming an ideal scenario
where there are no new words in the testing data,
the maximum matching algorithm achieves an F-
score of 95.15%. However, when there are new
words (words not found in the training data), the
accuracy drops to only 89.77% in F-score. In
contrast, the maximum entropy tagger achieves
an accuracy of 94.89% measured by the
balanced F-score even when there are new words
in the testing data. This result is only slightly
lower than the 95.15% that the maximum
matching algorithm achieved when there are no
new words. The transformation-based tagger
improves the tagging accuracy by 0.12% from
95.95% to 96.07%. The segmentation accuracy
jumps to 95.17% (F-score) from 94.89%, an
increase of 0.28%. That fact that the
improvement in segmentation accuracy is higher
than the improvement in tagging accuracy shows
that the transformation-based tagger is able to
correct some of the inconsistent tagging errors
produced by the maximum entropy tagger. This
is clearly demonstrated in the five highest-
ranked transformation rules learned by this
model:
</bodyText>
<listItem confidence="0.735062">
(5) Top five transformation rules
</listItem>
<sectionHeader confidence="0.9702526" genericHeader="method">
RR MM NEXTTAG RR
LL LR NEXTTAG LL
LL LR NEXTTAG LR
MM RR NEXTBIGRAM LR LR
RR LR PREVBIGRAM RR LR
</sectionHeader>
<bodyText confidence="0.999960511627907">
For example, the first rule says that if the next
character is tagged RR, then change the current
tag to MM from RR, since an RR RR sequence
is inconsistent.
Evaluating this approach against previous results
can be a tricky matter. There are several reasons
for this. One is that the source of data can affect
the segmentation accuracy. Since the results of
machine-learning approaches are heavily
dependent on the type of training data,
comparison of segmenters trained on different
data is not exactly valid. The second reason is
that the amount of training data also affects the
accuracy of segmenters. Still some preliminary
observations can be made in this regard. Our
accuracy is much higher that those reported in
Hockenmaier and Brew (1998) and Xue (2001),
who used error-driven transformation-based
learning to learn a set of n-gram rules to do a
series of merge and split operations on data from
Xinhua news, the same data source as ours. The
results they reported are 87.9% (trained on
100,000 words) and 90.2% (trained on 80,000
words) respectively, measured by the balanced
F-score.
Using a statistical model called prediction by
partial matching (PPM), Teahan et al (2000)
reported a significantly better result. The model
was trained on a million words from Guo Jin&apos;s
Mandarin Chinese PH corpus and tested on five
500-segment files. The reported F-scores are in a
range between 89.4% and 98.6%, averaging
94.4%. Since the data are also from Xinhua
newswire, some comparison can be made
between our results and this model. With less
training data, our results are slightly higher (by
0.48%) when using just the maximum entropy
model. When this model is combined with the
error-driven transformation-based learning
model, our accuracy is higher by 0.77%. Still,
this comparison is just preliminary since
different segmentation standards can also affect
segmentation accuracy.
</bodyText>
<sectionHeader confidence="0.996892" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999926333333333">
The preliminary results show that our approach
is more robust than the dictionary-based
approaches. They also show that the present
approach outperforms other state-of-the-art
machine-learning models. We can also conclude
that the maximum entropy model is a promising
supervised machine learning alternative that can
be effectively applied to Chinese word
segmentation.
</bodyText>
<sectionHeader confidence="0.998191" genericHeader="acknowledgments">
6 Acknowledgement
</sectionHeader>
<bodyText confidence="0.999937333333333">
This research was funded by DARPA N66001-
00-1-8915. We gratefully acknowledge
comments from two anonymous reviewers.
</bodyText>
<sectionHeader confidence="0.997667" genericHeader="references">
7 References
</sectionHeader>
<reference confidence="0.999332916666667">
Eric Brill. 1995. Some Advances In Rule-Based
Part of Speech Tagging, AAAI 1994
Julia Hockenmaier and Chris Brew. 1998. Error-
driven segmentation of Chinese.
Communications of COLIPS, 1:1:69-84.
Adwait Ratnaparkhi. 1996. A Maximum Entropy
Part-of-Speech Tagger. In Proceedings of the
Empirical Methods in Natural Language
Processing Conference, May 17-18, 1996.
University of Pennsylvania.
W. J. Teahan, Rodger McNab, Yingying Wen
and Ian H. Witten. 2000. A Compression-based
Algorithm for Chinese Word Segmentation.
Computational Linguistics, 26:3:375-393
Andi Wu and Zixin Jiang. 1998. Word
Segmentation in Sentence Analysis. In
Proceedings of the 1998 International
Conference on Chinese Information Processing.
Nov. 1998, Beijing, pp. 167-180.
Fei Xia, Martha Palmer, Nianwen Xue, Mary
Ellen Okurowski, John Kovarik, Shizhe Huang,
Tony Kroch, Mitch Marcus. 2000. Developing
Guidelines and Ensuring Consistency for
Chinese Text Annotation. In Proc. of the 2nd
International Conference on Language
Resources and Evaluation (LREC-2000), Athens,
Greece.
Nianwen Xue. 2001. Defining and Automatically
Identifying Words in Chinese. PhD Dissertation,
University of Delaware.
Nianwen Xue, Fu-dong Chiou, Martha Palmer.
2002. Building a Large Annotated Chinese
Corpus. To appear in Proceedings of the 19th
International Conference on Computational
Linguistics. August 14 - September 1, 2002.
Taipei, Taiwan.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.738308">
<title confidence="0.99996">Combining Classifiers for Chinese Word Segmentation</title>
<author confidence="0.994177">Nianwen Xue</author>
<affiliation confidence="0.99918">Institute for Research in Cognitive University of</affiliation>
<address confidence="0.938111">Suite 400A, 3401 Philadelphia, PA</address>
<email confidence="0.996079">xueniwen@linc.cis.upenn.edu</email>
<author confidence="0.999359">Susan P Converse</author>
<affiliation confidence="0.9996305">Dept. of Computer and Information University of</affiliation>
<address confidence="0.9271655">200 South 33rd Philadelphia, PA</address>
<email confidence="0.999539">spc@linc.cis.upenn.edu</email>
<abstract confidence="0.999052333333333">In this paper we report results of a supervised machine-learning approach to Chinese word segmentation. First, a maximum entropy tagger is trained on manually annotated data to automatically labels the characters with tags that indicate the position of character within a word. An error-driven transformation-based tagger is then trained to clean up the tagging inconsistencies of the first tagger. The tagged output is then converted into segmented text. The preliminary results show that this approach is competitive compared with other supervised machine-learning segmenters reported in previous studies.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Some Advances In Rule-Based Part of Speech Tagging,</title>
<date>1995</date>
<location>AAAI</location>
<marker>Brill, 1995</marker>
<rawString>Eric Brill. 1995. Some Advances In Rule-Based Part of Speech Tagging, AAAI 1994</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Chris Brew</author>
</authors>
<title>Errordriven segmentation of Chinese.</title>
<date>1998</date>
<journal>Communications of COLIPS,</journal>
<pages>1--1</pages>
<contexts>
<context position="4297" citStr="Hockenmaier and Brew 1998" startWordPosition="675" endWordPosition="678">ter (POC) tags to differentiate them from the more familiar partof-speech (POS) tags. For example, the manually segmented string in (1)a will be tagged as shown in (1)b: (1) a. b. /LL /RR /LL /RR /LR /LR /LL /RR /LR /LL /RR /LL /RR /LL /RR /LL /RR /LL /RR /LL /RR /LL /RR c. Shanghai plans to reach the goal of 5,000 dollars in per capita GDP by the end of the century. Given a manually segmented corpus, a POCtagged corpus can be derived trivially with perfect accuracy. The reason that we use such POC-tagged sequences of characters instead of applying n-gram rules to a segmented corpus directly (Hockenmaier and Brew 1998, Xue 2001) is that they are much easier to manipulate in the training process. Naturally, while some characters will have only one POC tag, most characters will receive multiple POC tags, in the same way that words can have multiple POS tags. The example in (2) shows how all four of the POC tags can be assigned to the character (‘produce’): (2) LL &apos;product&apos; LR &apos;produce&apos; MM &apos;productivity&apos; RR &apos;start production&apos; Also as in POS tags, the way the character is POC-tagged in naturally occurring text is affected by the context in which it occurs. For example, if the preceding character is tagged a LR</context>
<context position="20041" citStr="Hockenmaier and Brew (1998)" startWordPosition="3358" endWordPosition="3361">e an RR RR sequence is inconsistent. Evaluating this approach against previous results can be a tricky matter. There are several reasons for this. One is that the source of data can affect the segmentation accuracy. Since the results of machine-learning approaches are heavily dependent on the type of training data, comparison of segmenters trained on different data is not exactly valid. The second reason is that the amount of training data also affects the accuracy of segmenters. Still some preliminary observations can be made in this regard. Our accuracy is much higher that those reported in Hockenmaier and Brew (1998) and Xue (2001), who used error-driven transformation-based learning to learn a set of n-gram rules to do a series of merge and split operations on data from Xinhua news, the same data source as ours. The results they reported are 87.9% (trained on 100,000 words) and 90.2% (trained on 80,000 words) respectively, measured by the balanced F-score. Using a statistical model called prediction by partial matching (PPM), Teahan et al (2000) reported a significantly better result. The model was trained on a million words from Guo Jin&apos;s Mandarin Chinese PH corpus and tested on five 500-segment files. </context>
</contexts>
<marker>Hockenmaier, Brew, 1998</marker>
<rawString>Julia Hockenmaier and Chris Brew. 1998. Errordriven segmentation of Chinese. Communications of COLIPS, 1:1:69-84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A Maximum Entropy Part-of-Speech Tagger.</title>
<date>1996</date>
<booktitle>In Proceedings of the Empirical Methods in Natural Language Processing Conference,</booktitle>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="2795" citStr="Ratnaparkhi 1996" startWordPosition="401" endWordPosition="402">s have the advantage of not needing a dictionary and thus are more suitable for use on naturally occurring Chinese text. In this paper we report results of a supervised machine-learning approach towards Chinese word segmentation that combines two fairly standard machine learning models. We show that this approach is very promising compared with dictionary-based approaches as well as other machine-learning approaches that have been reported in the literature. 2 Combining Classifiers for Chinese word segmentation The two machine-learning models we use in this work are the maximum entropy model (Ratnaparkhi 1996) and the error-driven transformation-based learning model (Brill 1994). We use the former as the main workhorse and the latter to correct some of the errors produced by the former. 2.1 Reformulating word segmentation as a tagging problem Before we apply the machine-learning algorithms we first convert the manually segmented words in the corpus into a tagged sequence of Chinese characters. To do this, we tag each character with one of the four tags, LL, RR, MM and LR, depending on its position within a word. It is tagged LL if it occurs on the left boundary of a word, and forms a word with the </context>
<context position="5871" citStr="Ratnaparkhi (1996)" startWordPosition="952" endWordPosition="953">forms a word with other characters. This state of affairs closely resembles the familiar POS tagging problem and lends itself naturally to a solution similar to that of POS tagging. The task is one of ambiguity resolution in which the correct POC tag is determined among several possible POC tags in a specific context. Our next step is to train a maximum entropy model on the perfectly POCtagged data derived from a manually segmented corpus and use the model to automatically POCtag unseen text. 2.2 The maximum entropy tagger The maximum entropy model used in POStagging is described in detail in Ratnaparkhi (1996) and the POC tagger here uses the same probability model. The probability model is defined over H x T, where H is the set of possible contexts or &amp;quot;histories&amp;quot; and T is the set of possible tags. The model&apos;s joint probability of a history h and a tag t is defined as p(h,t) = z/l laij (i) T� i&apos;(h,t) k j=1 where is a normalization constant, {✫, 1, ..., k} are the model parameters and {f1, ..., fk} are known as features, where fj (h, t) {0,1}. Each feature fj has a corresponding parameter j, which effectively serves as a &amp;quot;weight&amp;quot; of this feature. In the training process, given a sequence n of charac</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Adwait Ratnaparkhi. 1996. A Maximum Entropy Part-of-Speech Tagger. In Proceedings of the Empirical Methods in Natural Language Processing Conference, May 17-18, 1996. University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W J Teahan</author>
<author>Rodger McNab</author>
<author>Yingying Wen</author>
<author>Ian H Witten</author>
</authors>
<title>A Compression-based Algorithm for Chinese Word Segmentation. Computational Linguistics,</title>
<date>2000</date>
<pages>26--3</pages>
<contexts>
<context position="20479" citStr="Teahan et al (2000)" startWordPosition="3429" endWordPosition="3432">so affects the accuracy of segmenters. Still some preliminary observations can be made in this regard. Our accuracy is much higher that those reported in Hockenmaier and Brew (1998) and Xue (2001), who used error-driven transformation-based learning to learn a set of n-gram rules to do a series of merge and split operations on data from Xinhua news, the same data source as ours. The results they reported are 87.9% (trained on 100,000 words) and 90.2% (trained on 80,000 words) respectively, measured by the balanced F-score. Using a statistical model called prediction by partial matching (PPM), Teahan et al (2000) reported a significantly better result. The model was trained on a million words from Guo Jin&apos;s Mandarin Chinese PH corpus and tested on five 500-segment files. The reported F-scores are in a range between 89.4% and 98.6%, averaging 94.4%. Since the data are also from Xinhua newswire, some comparison can be made between our results and this model. With less training data, our results are slightly higher (by 0.48%) when using just the maximum entropy model. When this model is combined with the error-driven transformation-based learning model, our accuracy is higher by 0.77%. Still, this compar</context>
</contexts>
<marker>Teahan, McNab, Wen, Witten, 2000</marker>
<rawString>W. J. Teahan, Rodger McNab, Yingying Wen and Ian H. Witten. 2000. A Compression-based Algorithm for Chinese Word Segmentation. Computational Linguistics, 26:3:375-393</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andi Wu</author>
<author>Zixin Jiang</author>
</authors>
<title>Word Segmentation in Sentence Analysis.</title>
<date>1998</date>
<booktitle>In Proceedings of the 1998 International Conference on Chinese Information Processing.</booktitle>
<pages>167--180</pages>
<location>Beijing,</location>
<contexts>
<context position="1840" citStr="Wu and Jiang 1998" startWordPosition="261" endWordPosition="264">veral word segmentation algorithms have been developed using a dictionary as an essential tool. Most notably, variants of the maximum matching algorithm have been applied to word segmentation with considerable success. The results that have been reported are generally in the upper 90 percentile range. However, the success of such algorithms is premised on a large, exhaustive dictionary. The accuracy of word segmentation degrades sharply as new words appear. Since Chinese word formation is a highly productive process, new words are bound to appear in substantial numbers in realistic scenarios (Wu and Jiang 1998, Xue 2001), and it is virtually impossible to list all the words in a dictionary. In recent years, as annotated Chinese corpora have become available, various machine-learning approaches have been applied to Chinese word segmentation, with different levels of success. Compared with dictionarybased approaches, machine-learning approaches have the advantage of not needing a dictionary and thus are more suitable for use on naturally occurring Chinese text. In this paper we report results of a supervised machine-learning approach towards Chinese word segmentation that combines two fairly standard</context>
</contexts>
<marker>Wu, Jiang, 1998</marker>
<rawString>Andi Wu and Zixin Jiang. 1998. Word Segmentation in Sentence Analysis. In Proceedings of the 1998 International Conference on Chinese Information Processing. Nov. 1998, Beijing, pp. 167-180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>Martha Palmer</author>
<author>Nianwen Xue</author>
<author>Mary Ellen Okurowski</author>
<author>John Kovarik</author>
<author>Shizhe Huang</author>
<author>Tony Kroch</author>
<author>Mitch Marcus</author>
</authors>
<title>Developing Guidelines and Ensuring Consistency for Chinese Text Annotation.</title>
<date>2000</date>
<booktitle>In Proc. of the 2nd International Conference on Language Resources and Evaluation (LREC-2000),</booktitle>
<location>Athens, Greece.</location>
<contexts>
<context position="13865" citStr="Xia et al. 2000" startWordPosition="2343" endWordPosition="2346">mentation accuracy drops sharply. In the second experiment, we applied the maximum entropy model to the problem of Chinese word segmentation. The results will show that this approach alone outperforms the state-of-the-art results reported in previous work in supervised machine-learning approaches. In the third experiment we combined the maximum entropy model with the error-driven transformationbased model. We used the error-driven transformation-based model to learn a set of rules to correct the errors produced by the maximum entropy model. The data we used are from the Penn Chinese Treebank (Xia et al. 2000, Xue et al. 2002) and they consist of Xinhua newswire articles. We took 250,389 words (426,292 characters or hanzi) worth of manually segmented data and divided them into two chunks. The first chunk has 237,791 words (404,680 Chinese characters) and is used as training data. The second chunk has 12,598 words (21,612 characters) and is used as testing data. These data are used in all three of our experiments. 3.1 Experiment One In this experiment, we conducted two subexperiments. In the first sub-experiment, we used a forward maximum matching algorithm to segment the testing data with a dictio</context>
</contexts>
<marker>Xia, Palmer, Xue, Okurowski, Kovarik, Huang, Kroch, Marcus, 2000</marker>
<rawString>Fei Xia, Martha Palmer, Nianwen Xue, Mary Ellen Okurowski, John Kovarik, Shizhe Huang, Tony Kroch, Mitch Marcus. 2000. Developing Guidelines and Ensuring Consistency for Chinese Text Annotation. In Proc. of the 2nd International Conference on Language Resources and Evaluation (LREC-2000), Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
</authors>
<title>Defining and Automatically Identifying Words in Chinese.</title>
<date>2001</date>
<tech>PhD</tech>
<institution>Dissertation, University of Delaware.</institution>
<contexts>
<context position="1851" citStr="Xue 2001" startWordPosition="265" endWordPosition="266">tion algorithms have been developed using a dictionary as an essential tool. Most notably, variants of the maximum matching algorithm have been applied to word segmentation with considerable success. The results that have been reported are generally in the upper 90 percentile range. However, the success of such algorithms is premised on a large, exhaustive dictionary. The accuracy of word segmentation degrades sharply as new words appear. Since Chinese word formation is a highly productive process, new words are bound to appear in substantial numbers in realistic scenarios (Wu and Jiang 1998, Xue 2001), and it is virtually impossible to list all the words in a dictionary. In recent years, as annotated Chinese corpora have become available, various machine-learning approaches have been applied to Chinese word segmentation, with different levels of success. Compared with dictionarybased approaches, machine-learning approaches have the advantage of not needing a dictionary and thus are more suitable for use on naturally occurring Chinese text. In this paper we report results of a supervised machine-learning approach towards Chinese word segmentation that combines two fairly standard machine le</context>
<context position="4308" citStr="Xue 2001" startWordPosition="679" endWordPosition="680">iate them from the more familiar partof-speech (POS) tags. For example, the manually segmented string in (1)a will be tagged as shown in (1)b: (1) a. b. /LL /RR /LL /RR /LR /LR /LL /RR /LR /LL /RR /LL /RR /LL /RR /LL /RR /LL /RR /LL /RR /LL /RR c. Shanghai plans to reach the goal of 5,000 dollars in per capita GDP by the end of the century. Given a manually segmented corpus, a POCtagged corpus can be derived trivially with perfect accuracy. The reason that we use such POC-tagged sequences of characters instead of applying n-gram rules to a segmented corpus directly (Hockenmaier and Brew 1998, Xue 2001) is that they are much easier to manipulate in the training process. Naturally, while some characters will have only one POC tag, most characters will receive multiple POC tags, in the same way that words can have multiple POS tags. The example in (2) shows how all four of the POC tags can be assigned to the character (‘produce’): (2) LL &apos;product&apos; LR &apos;produce&apos; MM &apos;productivity&apos; RR &apos;start production&apos; Also as in POS tags, the way the character is POC-tagged in naturally occurring text is affected by the context in which it occurs. For example, if the preceding character is tagged a LR or RR, the</context>
<context position="20056" citStr="Xue (2001)" startWordPosition="3363" endWordPosition="3364">ent. Evaluating this approach against previous results can be a tricky matter. There are several reasons for this. One is that the source of data can affect the segmentation accuracy. Since the results of machine-learning approaches are heavily dependent on the type of training data, comparison of segmenters trained on different data is not exactly valid. The second reason is that the amount of training data also affects the accuracy of segmenters. Still some preliminary observations can be made in this regard. Our accuracy is much higher that those reported in Hockenmaier and Brew (1998) and Xue (2001), who used error-driven transformation-based learning to learn a set of n-gram rules to do a series of merge and split operations on data from Xinhua news, the same data source as ours. The results they reported are 87.9% (trained on 100,000 words) and 90.2% (trained on 80,000 words) respectively, measured by the balanced F-score. Using a statistical model called prediction by partial matching (PPM), Teahan et al (2000) reported a significantly better result. The model was trained on a million words from Guo Jin&apos;s Mandarin Chinese PH corpus and tested on five 500-segment files. The reported F-</context>
</contexts>
<marker>Xue, 2001</marker>
<rawString>Nianwen Xue. 2001. Defining and Automatically Identifying Words in Chinese. PhD Dissertation, University of Delaware.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fu-dong Chiou</author>
<author>Martha Palmer</author>
</authors>
<title>Building a Large Annotated Chinese Corpus. To appear in</title>
<date>2002</date>
<booktitle>Proceedings of the 19th International Conference on Computational Linguistics.</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="13883" citStr="Xue et al. 2002" startWordPosition="2347" endWordPosition="2350">y drops sharply. In the second experiment, we applied the maximum entropy model to the problem of Chinese word segmentation. The results will show that this approach alone outperforms the state-of-the-art results reported in previous work in supervised machine-learning approaches. In the third experiment we combined the maximum entropy model with the error-driven transformationbased model. We used the error-driven transformation-based model to learn a set of rules to correct the errors produced by the maximum entropy model. The data we used are from the Penn Chinese Treebank (Xia et al. 2000, Xue et al. 2002) and they consist of Xinhua newswire articles. We took 250,389 words (426,292 characters or hanzi) worth of manually segmented data and divided them into two chunks. The first chunk has 237,791 words (404,680 Chinese characters) and is used as training data. The second chunk has 12,598 words (21,612 characters) and is used as testing data. These data are used in all three of our experiments. 3.1 Experiment One In this experiment, we conducted two subexperiments. In the first sub-experiment, we used a forward maximum matching algorithm to segment the testing data with a dictionary compiled from</context>
</contexts>
<marker>Xue, Chiou, Palmer, 2002</marker>
<rawString>Nianwen Xue, Fu-dong Chiou, Martha Palmer. 2002. Building a Large Annotated Chinese Corpus. To appear in Proceedings of the 19th International Conference on Computational Linguistics. August 14 - September 1, 2002. Taipei, Taiwan.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>