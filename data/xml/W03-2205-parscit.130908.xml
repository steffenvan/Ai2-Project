<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.989409">
Parallel Corpora Segmentation Using Anchor Words*
</title>
<author confidence="0.892488">
Francisco Nevado and Francisco Casacuberta and Enrique Vidal
</author>
<affiliation confidence="0.429206">
Instituto Tecnologico de Informatica
Universidad Politecnica de Valencia
</affiliation>
<email confidence="0.979544">
ffnevado,fon,evidall@iti.upv.es
</email>
<sectionHeader confidence="0.982041" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999892333333333">
A new technique for monotone segmen-
tation of parallel corpora is introduced.
This segmentation is based on a set of
anchor words which are defined man-
ually. The parallel segments are com-
puted using a dynamic programming
algorithm. To assess this technique,
finite-state transducers are inferred from
both non-segmented and segmented cor-
pora. Experiments have been carried
out with Spanish-English and Italian-
English translation tasks. This tech-
nique has proven useful in improving
the results with respect to those obtained
with unsegmented corpora.
</bodyText>
<sectionHeader confidence="0.996305" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.98639655">
In this paper, we present a new technique for im-
proving machine translation systems. This is a
heuristic approach for parallel corpora segmenta-
tion using anchor words and a dynamic program-
ming algorithm.
In a parallel corpus, the anchor words are spe-
cific words that are defined for the two languages
of the corpus and that are strongly related.
The goal of parallel corpus segmentation is to
segment the source sentence and the target sen-
tence in such a way that the correspondence be-
tween segments is monotone and one-to-one.
*This work has been partially supported by TransType 2
(IST-2001-32091) and SisHITRA (TIC2000-1599-0O2).
Using this segmentation, we attempted to im-
prove the word alignments obtained with statisti-
cal techniques (Brown et al., 1993; Brown et al.,
1990). These models depend on the length of the
source and target sentences. The models are bet-
ter estimated with shorter segments and, conse-
quently, better word alignments are obtained.
The basic scheme of the proposed parallel seg-
mentation is the following:
a) The source and the target sentences are ini-
tially segmented in the positions of the an-
chor words.
b) As the number of source and target segments
can be different, a dynamic programming al-
gorithm is applied to find the optimal corre-
spondences between segments.
In section 2, we will show how to segment a
bilingual corpus describing the segmentation of a
pair of sentences using anchor words. We will
then describe the experiments carried out to test
this new technique and the obtained results.
2 Segmentation of a parallel corpus
Parallel segmentation is considered from a statis-
tical point of view. Segmentation of a parallel cor-
pus is carried out by segmenting every pair of sen-
tences in this corpus.
</bodyText>
<subsectionHeader confidence="0.974063">
2.1 Statistical machine translation
</subsectionHeader>
<bodyText confidence="0.999371333333333">
We use a notation which is similar to the one pro-
posed in (Brown et al., 1993), where f is a source
sentence and e is a target sentence.
</bodyText>
<page confidence="0.998253">
33
</page>
<bodyText confidence="0.999079">
In order to translate from the source language
to the target language in a statistical framework
(Brown et al., 1993), we look for the probability
of obtaining a sentence e from a sentence f, that is,
Pr(e f). Applying Bayes rule, we have:
</bodyText>
<equation confidence="0.997964">
Pr(e) Pr(f e)
Pr(e = (1)
Pr (f)
</equation>
<bodyText confidence="0.99989625">
Since we are searching for the target sentence
with the best probability of being generated from
the source sentence, by maximizing the preceding
expression, we have:
</bodyText>
<equation confidence="0.7852515">
argmax Pr(e f)
argmax Pr(e) Pr (f e), (2)
</equation>
<bodyText confidence="0.9999566">
where Pr(e) corresponds to the probability of the
target language model and Pr(f I e) is known
as the probability of the translation model. This
model transforms a sentence in the target language
into a sentence in the source language.
</bodyText>
<subsectionHeader confidence="0.998602">
2.2 Segmentation of a pair of sentences
</subsectionHeader>
<bodyText confidence="0.999975590909091">
We obtain the segmentation as a byproduct of the
translation process of a sentence. To start with,
a trivial monolingual anchor-point-based initial
segmentation is assumed on the sentence f. A dif-
ferent trivial monolingual anchor-point-based ini-
tial segmentation is also assumed on the sentence
e. Having defined a set of anchor words for the
source language and another set of anchor words
for the target sentence, the first initial segment for
sentence f is composed of the sequence of words
from the beginning of the sentence until the first
anchor word of f. The rest of the initial segments
are composed of the sequences of words from the
first word following the last segment until the next
anchor word. The last segment of the sentence
may end with the end of the sentence instead of an
anchor word. The initial segments of e are com-
puted in the same way, but taking into account the
anchor words for the target language. Let us sup-
pose that there are a initial segments for sentence
f and there are b initial segments for sentence e.
This initial segmentation is represented as:
</bodyText>
<equation confidence="0.9713385">
e = el e2 ea = ecl
f fif2.• • fb =f
</equation>
<bodyText confidence="0.998924">
where ec is a segment of consecutive words of e
and fd is a segment of consecutive words of f.
See Figure 2 for an example of this kind of ini-
tial segmentation. E2 is the sequence of words
constituted by the concatenation of the segments
ec,+1 6,2, and fddi2 is the sequence of words
constituted by the concatenation of the segments
</bodyText>
<equation confidence="0.6717478">
fdi fdi +1 • • • fd2 •
Processing each initial segment as an atomic
block, we can rewrite expression (2) with this no-
tation:
= argmax Pr(e7) Pr (.e 67). (3)
</equation>
<bodyText confidence="0.988898777777778">
A parallel segmentation s is an ordered set of
pairs of sequences of words, where every one
of these pairs has a sequence of words from the
source sentence and a sequence of words from the
target sentence composed by one or more consec-
utive initial segments of the source sentence or the
target sentence, respectively&apos;.
Given an initial segmentation (q,fb, we can
represent a parallel segmentation as:
</bodyText>
<equation confidence="0.85052">
s (r_cl rn-c2 cd2
reels I fdls1
• • • els1-1+1, d1,1_1+1
</equation>
<bodyText confidence="0.979386666666667">
where s is the number of segments for the paral-
lel segmentation s. Clearly we have c = a and
= b. Therefore, in a segmentation, any seg-
ment in the input sentence cannot be left without a
corresponding segment of the output sentence, and
vice versa. Another restriction is that there cannot
be inversions in the order of the initial segments;
that is, if [ecc2i , id112] is a pair of segments of a seg-
mentation s, then V[e2 , lcd/34] E s:
</bodyText>
<construct confidence="0.970881">
if C2 &lt; C3 &gt; d2 &lt;d3
if c4 &lt; c1 &gt; d &lt;d1
</construct>
<bodyText confidence="0.972087375">
An example of this kind of segmentation is
shown in section 2.3.
The set of possible parallel segmentations for
an initial segmentation based on anchor words
1Note the difference with an initial segmentation. A seg-
mentation may have joined several consecutive segments of
the initial segments, but it has the same number of final seg-
ments for the source and target sentences.
</bodyText>
<page confidence="0.99357">
34
</page>
<bodyText confidence="0.981794">
(e7_ , fi) is denoted by S(q, fn. Now, we can
write the probability for the translation model,
</bodyText>
<equation confidence="0.974038">
Pr(fil
Pr(fi =&gt; Pr(fi, s e7) (4)
SES(eeljP)
</equation>
<bodyText confidence="0.999991428571429">
where Pr( f, s ect) allows for the interpretation
of a segmentation as a generative model. We can
say that the segments in the source sentence are
generated from the corresponding segments of the
target sentence.
Given a sentence 67, we define the probability
for a sentence fi and a segmentation s as:
</bodyText>
<equation confidence="0.9761445">
Pr(fi, s I q) =
1S1
-d
Pr(s ë) [f Pr(fd:_i+1 eccqg 1+1), (5)
q=1
-d
</equation>
<bodyText confidence="0.999212294117647">
where Pr (fi+1 eccq 1+1) is again the proba-
bility of the translation model for a subsequence of
the sentence f and a subsequence of the sentence
e.
We do not want to consider the translation
model as a recursive model, so we will approxi-
mate_
the probability Pr ( fd: +1 ec _1+1) using
Model 1 proposed in (Brown et al., 1993). In an
intuitive manner, Model 1 computes the probabil-
ity of a sequence of words to be translated by other
sequence of words, without taking into account the
word order. Therefore, it can allow translation in-
versions inside the sequences of words. The trans-
lation probability of a sequence of words e2 into a
sequence of words eii2 using Model 1 is computed
by:
</bodyText>
<equation confidence="0.9932648">
pr(e112 ecc2i _ m f( ci
,di2 ec2) _
o p
(p+ l)° Et((d2,i) (eCC21 i))7
j=1 i=0
</equation>
<bodyText confidence="0.98975275">
where p and o are the lengths in words of the se-
quences 4,2 and f, respectively. (fddi2, j) is the
j-th word of the sequence fddi2, and (e2 , i) is the i-
th word of the sequence 62. t((fd7
</bodyText>
<construct confidence="0.5359945">
2 j) 1(42 i))is
d 1
</construct>
<bodyText confidence="0.9809508">
a statistical translation dictionary which stores the
probability of the target word (42, , i) being trans-
lated into the source word (fddi2, j). This dictionary
can be estimated automatically from the bilingual
corpus by using the estimation methods described
in (Brown et al., 1993). The software used to ob-
tain this statistical dictionary was GIZA++ (Och
and Ney, 2000; Knight, 1999). The probability
that the sequences of words of the pair have a cer-
tain length (number of words) is measured by the
</bodyText>
<equation confidence="0.949985875">
C term.
Now, expanding expression (4) with (5), we
have:
Pr(fib eel&apos;) =
ISI
_
E Pr(s en fl Pr(fo I eeegg_1+1). (6)
sE5(e74) q=1
</equation>
<bodyText confidence="0.9988075">
However, we are interested in computing only
the best segmentation, so, we define the most
</bodyText>
<figure confidence="0.289037">
probable segmentation probability,
Pr(f ei), as
the maximum of expression (6):
max Pr(s -dq _cq
ses(ec,f) q) 1-1Pru1
q=1
Considering Pr(s e) to be equally probable
Pb
for all s E $(e fi)
l, (that is, C = Pr(s e7)) and
-dg _cg
assuming that Pr (f e
d„ 1+1) is computed
using the Model 1:
Pr(fi I =
Isl
C max H
Mi(f ecc:_1±1). (7)
•
sEs(e7,n) g_i
</figure>
<bodyText confidence="0.999102">
In order to obtain the segmentation with maxi-
mum probability, we want the argument that max-
imizes expression (7), so, we look for:
</bodyText>
<equation confidence="0.9280845">
Isl
7d, , _c,
s = argmax H (idq 1+1 ecg_i+1) •
SES(Eel,f) q-1
</equation>
<bodyText confidence="0.999694285714286">
To solve the maximization problems (7) and (8),
we use a dynamic programming scheme. In order
to reduce the computational search cost, we im-
pose a new restriction: no more than k initial seg-
ments can be joined for fli&amp;quot; or e7.
The algorithm to compute the probability of
the best segmentation uses a bidimensional matrix
</bodyText>
<equation confidence="0.596617">
(8)
</equation>
<page confidence="0.977972">
35
</page>
<bodyText confidence="0.813916142857143">
s[d, c]. A graphical representation of this structure
is shown in Figure 1, where the rows correspond
to the initial segments of the source sentence and
the columns correspond to the initial segments of
the target sentence.
The expression which is computed for every po-
sition of the matrix s in Figure 1 is:
</bodyText>
<equation confidence="0.834357428571429">
s[d, c] =
max s[d — j — 1, c — i — 1] i (fcci—i
i = 0..k
j = 0..k
s[d, c] is the probability of translating the se-
quence of words e? into the sequence of words g,
Pr(ei
</equation>
<bodyText confidence="0.999008166666667">
The algorithm for computing the probability of
the best parallel segmentation for an initial seg-
mentation based on anchor words is shown in al-
gorithm 1. When the computation of every s[d,
is done, the probability of the best segmentation is
stored in s[b, a]
</bodyText>
<figure confidence="0.357278">
d = 1 ...b
</figure>
<figureCaption confidence="0.994381">
Figure 1: Graphical representation of the matrix
</figureCaption>
<bodyText confidence="0.881956125">
s[d, c] used for the computation of in
I
the dynamic programming algorithm ei);
Another matrix can be computed together with
the matrix s in order to store the path for the most
probable segmentation, that is, to store the group-
ings of initial segments that are carried out for the
most probable segmentation.
</bodyText>
<subsectionHeader confidence="0.973814">
2.3 A complete example
</subsectionHeader>
<bodyText confidence="0.999980375">
Now we offer a complete example of the compu-
tation of the segmentation of a pair of sentences.
This pair of sentences is extracted from the FUB
corpus (Vidal, 2000). This corpus is a bilingual
text corpus of Italian-English pairs of sentences
with restricted semantic domain. The sentences
in the corpus are typical sentences of a tourist in
the hotel domain, for example:
</bodyText>
<listItem confidence="0.997330833333333">
• A che ora e disponibile ii servizio navetta per
l&apos;aeroporto? /At what time is the shuttle ser-
vice to the airport available?.
• Avete una stanza libera dal quattro al dieci
Settembre? / Do you have a free room from
the fourth to the tenth of September?.
</listItem>
<bodyText confidence="0.815205">
Defining the following sets of anchor words for
Italian and English, respectively:
</bodyText>
<equation confidence="0.868599">
Italian Anchors
„ : ?, !, con, per, e, perche, vorrei, volevo
English Anchors
„ : ?, !, with, for, and, because,
I would like, I wish
</equation>
<bodyText confidence="0.988019315789474">
The English expressions I would like and I wish
were treated as atomic anchor words.
This is a pair of sentences extracted from the
corpus:
buonasera , sono la signora Rossi
della camera trecentodue , vorrei dis-
dire per domani mattina la colazione in
camera, grazie .
good evening, it is Mrs Rossi from
room three hundred and two, I would
like to cancel breakfast in room for to-
morrow morning, thanks.
The initial segmentation for the original sen-
tences and the anchor words is shown in Figure
2.
After running Algorithm 1 described in section
2 on the initial segmentation of Figure 2, we ob-
tained the segmentation shown in Figure 3 as the
best segmentation.
</bodyText>
<sectionHeader confidence="0.998963" genericHeader="introduction">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.984513">
3.1 Corpora description
</subsectionHeader>
<bodyText confidence="0.99969775">
The EuTRANs-I corpus (Vidal, 2000) is a
Spanish-English corpus which was generated
semi-automatically for the E u TRAN S -I task
which is a subtask of the &amp;quot;Traveler Task&amp;quot;. The
</bodyText>
<figure confidence="0.888096833333333">
1
0
0
0
fl
0
f2
0
0
ft
c = 1 ... a
el e2 • • • ea
</figure>
<page confidence="0.991193">
36
</page>
<table confidence="0.959032333333333">
Algorithm 1: Algorithm for the computation of the probability of the best parallel segmentation
for an initial segmentation based on anchor words (q,
INPUT: (67 , n): initial segmentation;
k: maximum number of consecutive initial segments that can be joined;
OUTPUT: Pr(ff) q) probability of the best parallel segmentation for (67:, fb;
VAR: s: matrix to compute the best probability;
</table>
<equation confidence="0.553064230769231">
BEGIN
for (c=1; c &lt;=a; c++) I* For every initial segment in e *I
for (d=1; d &lt;=b; d++) /* For every initial segment in f *1
c] = 0.0;
/* Try to join 6, with previous initial segments: ec-1 • • • ec—k *1
for(i=0; i &lt;=k; i++)
/* Try to join fd with previous initial segments: fd_i . . . fd_k */
for(j=0; j &lt;=k; j++)
/* Store the best probability */
aux = s[d — j — 1, c — i — 1] • 11/11(fli ec,J;
if (aux &gt; sd, c]) slid, c] = aux;
return(s [b, a]);
END
</equation>
<bodyText confidence="0.999961727272727">
domain of the corpus is a human-to-human com-
munication situation at a reception desk of a hotel.
The corpus characteristics are shown in Table 1.
The FUB corpus (Vidal, 2000), is a bilingual
Italian-English corpus with a restricted seman-
tic domain. The application is the translation of
queries, requests and complaints that a tourist can
make at the front desk of a hotel, for example, ask-
ing for a booked room, requesting a service of the
hotel, etc. The characteristics of the corpus are
shown in Table 2.
</bodyText>
<subsectionHeader confidence="0.86249">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.999751041666667">
There is no standard method for evaluating the
quality of a segmentation. One possible method is
to compare the segmentation produced by the ap-
proach presented here with respect to a reference
segmentation produced by hand. However, this
is a very expensive procedure which is not error
free. Another possible method for assessing the
performance of this new segmentation technique
is to compare the efficiency of a translation sys-
tem obtained from the original corpus and another
obtained from the segmented corpus on the trans-
lations of a test set of sentences.
We trained two finite-state transducers: one
from the original parallel corpus and one from the
segmented parallel corpus. In order to infer the
transducers from a parallel corpus we used a tech-
nique known as Grammatical Inference and Align-
ments for Transducer Inference (GIATI) (Casacu-
berta, 2000). The translation quality was mea-
sured for every transducer on the test set by using
the translation word error rate (TWER). This is the
average number of wrong words in the translations
generated by the transducer with respect to fixed
reference translations for the source sentences.
</bodyText>
<page confidence="0.997663">
37
</page>
<table confidence="0.995717866666667">
ITALIAN INITIAL SEGMENTS
buonasera ,
sono la signora Rossi della camera trecentodue ,
vorrei
disdire per
domani mattina la colazione in camera,
grazie .
ENGLISH INITIAL SEGMENTS
good evening,
it is Mrs Rossi from room three hundred and
two,
I would like
to cancel breakfast in room for
tomorrow morning,
thanks.
</table>
<figureCaption confidence="0.915544545454545">
Figure 2: Initial segmentation from the original sentences of the FUB corpus and the sets of anchor
words.
ITALIAN ENGLISH
buonasera , good evening,
sono la signora Rossi della camera trecen- it is Mrs Rossi from room three hundred
todue , and two,
vorrei I would like
disdire per domani mattina la colazione in to cancel breakfast in room for tomorrow
camera, morning,
grazie . thanks.
Figure 3: Final parallel segmentation for the example pair of sentences of the FUB corpus.
</figureCaption>
<tableCaption confidence="0.9792525">
Table 1: Training and test data sets of the bilingual
corpus EuTRANS-I.
</tableCaption>
<table confidence="0.982026285714286">
Training
Spanish English
N. Sentences 10,000
N. Words 97,131 99,292
Vocabulary size 686 513
Perplexity(bigram) 8.6 5.2
Test
</table>
<tableCaption confidence="0.802498">
Table 2: Training and test data sets of the bilingual
FUB corpus 5.1.
</tableCaption>
<table confidence="0.988692909090909">
Training
Italian English
N. Sentences 3,038
N. Words 55,302 64,176
Vocabulary size 2,459 1,712
Perplexity(bigram) 31 25
Test
Italian English
N. Sentences 300
N. Words 6,121 7,243
Vocabulary size 715 547
</table>
<figure confidence="0.873990375">
N. Sentences
2,996
Spanish
English
N. Words
35,023
35,590
Vocabulary size 613
</figure>
<page confidence="0.953326">
469
</page>
<bodyText confidence="0.999934428571429">
The number of initial segments that were al-
lowed to be joined in one segment of the final seg-
mentation was five.
In order to infer a finite-state transducer, the GI-
ATI technique needs word-level alignments such
as those described in (Brown et al., 1993; Knight,
1999) for every pair of sentences of the training
set. Model 4 (Brown et al., 1993) was estimated
with the non-segmented corpus and word align-
ments were obtained. With the segmented cor-
pus, each pair of segments was considered as a
pair of sentences, Model 4 was estimated and the
corresponding word alignments were computed.
These alignments were computed using the soft-
</bodyText>
<page confidence="0.996992">
38
</page>
<bodyText confidence="0.9983984375">
ware GIZA++ (Och and Ney, 2000; Knight, 1999),
obtaining the alignments produced by Model 4
(Brown et al., 1993). The finite-state transducer
generated with GIATI is derived from a n-gram
model inferred from the source sentences. In these
source sentences, the words of every input sen-
tence are labeled with the words of the correspond-
ing target sentence according to the word align-
ments obtained with Model 4.
Tables 3 and 4 show the average lengths of the
source-target sentences, along with the lengths of
the segmented sentences obtained by the proposed
technique. It is worth noting that on the average,
the more complex and long sentences of the FUB
corpus are broken down into much shorter (and
simpler) segments.
</bodyText>
<tableCaption confidence="0.998218">
Table 3: Average sentence length (number of
words) for the EuTRANs -I training set in the non-
segmented and segmented versions.
</tableCaption>
<table confidence="0.998585333333333">
Spanish English
Non-segmented 9.71 9.93
Segmented 7.40 7.57
</table>
<tableCaption confidence="0.988091666666667">
Table 4: Average sentence length (number of
words) for the FUB training set in the non-
segmented and segmented versions.
</tableCaption>
<table confidence="0.798905">
Italian English
Non-segmented 17.94 21.55
Segmented 4.79 5.76
</table>
<bodyText confidence="0.953953291666667">
Table 5 shows the TWER values for the inferred
transducers from the EuTRANs -I training set us-
ing the Model 4 alignments and fourgrams for GI-
ATI. Table 6 shows the TWER values for the cor-
responding transducers of the FUB training set us-
ing the Model 4 alignments and bigrams for GI-
ATI.
The transducer inferred using the segmented
EuTRANs-I corpus produced a greater error
rate than the transducer inferred using the non-
segmented corpus. On the other hand, the results
for the segmented FUB corpus improved the re-
sults over those obtained for the non-segmented
version of the corpus.
Table 5: TWER for the EuTRANs -I test set using
the transducers inferred with GIATI using four-
grams and the Model 4 alignments.
Non-segmented 8.0
Segmented 10.5
Table 6: TWER for the FUB test set using the
transducers inferred with GIATI using bigrams
and the Model 4 alignments.
Non-segmented 26.6
Segmented 25.2
</bodyText>
<sectionHeader confidence="0.999427" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999986133333333">
A new automatic segmentation technique for a
parallel corpus has been presented. The method
has been tested using the translation results ob-
tained for two tasks: the EuTRANs -I task and the
FUB task.
The EuTRANs-I task is relatively much simpler
than the FUB task, and the length of the sentences
is significantly shorter. Consequently, alignment
models such as Model 4 produce very good results
on unsegmented pairs of this corpus, thereby di-
rectly leading to good translation results with GI-
ATI transducers trained on unsegmented aligned
data. The FUB corpus, on the other hand, is much
more complex and the lengths of the sentences
are much longer. For these (long) pairs of sen-
tences, alignments obtained by alignments models
such as Model 4 tend not to be as good as those
of EuTRANs -I. In this case, using the shorter
pairs of sentences obtained by the proposed seg-
mentation technique definitely helps the alignment
model to produce better alignments, thereby lead-
ing to improved results for the GIATI transducers
trained on segmented aligned pairs. It should be
noted that the FUB task is much more realistic
than the EuTRANs -I task.
Although the proposed technique has a heuris-
tic component (the selection of the anchor words
sets), it improves the translation results with min-
imum human effort, especially for difficult tasks
such as the FUB task.
</bodyText>
<page confidence="0.99916">
39
</page>
<sectionHeader confidence="0.98896" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999933392857143">
P.F. Brown, J. Cocke, S.A. Della Pietra, V.J. Della
Pietra, F. Jelinek, J. Lafferty, R.L. Mercer, and
P. Roossin. 1990. A statistical approach to machine
translation. Computational Linguistics, _I 6(2):79-
85.
P.F. Brown, S.A. Della Pietra, V.J. Della Pietra, and
R.L. Mercer. 1993. The mathematics of machine
translation: Parameter estimation. Computational
Linguistics, 19(2):263-310.
F. Casacuberta. 2000. Inference of finite-state
transducers by using regular grammars and mor-
phisms. In Proceedings of International Conference
on Grammatical Inference - ICGI2000, pages 1-14.
K. Knight. 1999. A statistical MT tutorial workbook.
Technical Report prepared in connection with the
JHU summer workshop, Johns Hopkins Univ.
F. J. Och and H. Ney. 2000. Improved statisti-
cal alignment models. In ACLOO, pages 440-447,
Hongkong, China, October.
E. Vidal. 1997. Finite-state speech-to-speech trans-
lation. In Proceedings of the International Con-
ference on Acoustic, Speech and Signal Processing,
volume 1, pages 111-114.
E. Vidal. 2000. Final report. Technical Re-
port EUTRANS project, Technical Report Deliver-
able D0.1c, Information Technology. Long Term
Research Domain. Open Scheme. Project Number
32026.
</reference>
<page confidence="0.998637">
40
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.444775">
<title confidence="0.804995666666667">Parallel Corpora Segmentation Using Anchor Words* Nevado Casacuberta Instituto Tecnologico de</title>
<author confidence="0.752498">Universidad Politecnica de</author>
<email confidence="0.932059">ffnevado,fon,evidall@iti.upv.es</email>
<abstract confidence="0.9951316875">A new technique for monotone segmentation of parallel corpora is introduced. This segmentation is based on a set of anchor words which are defined manually. The parallel segments are computed using a dynamic programming algorithm. To assess this technique, finite-state transducers are inferred from both non-segmented and segmented corpora. Experiments have been carried out with Spanish-English and Italian- English translation tasks. This technique has proven useful in improving the results with respect to those obtained with unsegmented corpora.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>J Cocke</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>F Jelinek</author>
<author>J Lafferty</author>
<author>R L Mercer</author>
<author>P Roossin</author>
</authors>
<title>A statistical approach to machine translation.</title>
<date>1990</date>
<journal>Computational Linguistics, _I</journal>
<pages>6--2</pages>
<contexts>
<context position="1569" citStr="Brown et al., 1990" startWordPosition="232" endWordPosition="235"> words and a dynamic programming algorithm. In a parallel corpus, the anchor words are specific words that are defined for the two languages of the corpus and that are strongly related. The goal of parallel corpus segmentation is to segment the source sentence and the target sentence in such a way that the correspondence between segments is monotone and one-to-one. *This work has been partially supported by TransType 2 (IST-2001-32091) and SisHITRA (TIC2000-1599-0O2). Using this segmentation, we attempted to improve the word alignments obtained with statistical techniques (Brown et al., 1993; Brown et al., 1990). These models depend on the length of the source and target sentences. The models are better estimated with shorter segments and, consequently, better word alignments are obtained. The basic scheme of the proposed parallel segmentation is the following: a) The source and the target sentences are initially segmented in the positions of the anchor words. b) As the number of source and target segments can be different, a dynamic programming algorithm is applied to find the optimal correspondences between segments. In section 2, we will show how to segment a bilingual corpus describing the segmen</context>
</contexts>
<marker>Brown, Cocke, Pietra, Pietra, Jelinek, Lafferty, Mercer, Roossin, 1990</marker>
<rawString>P.F. Brown, J. Cocke, S.A. Della Pietra, V.J. Della Pietra, F. Jelinek, J. Lafferty, R.L. Mercer, and P. Roossin. 1990. A statistical approach to machine translation. Computational Linguistics, _I 6(2):79-85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--2</pages>
<contexts>
<context position="1548" citStr="Brown et al., 1993" startWordPosition="228" endWordPosition="231">ntation using anchor words and a dynamic programming algorithm. In a parallel corpus, the anchor words are specific words that are defined for the two languages of the corpus and that are strongly related. The goal of parallel corpus segmentation is to segment the source sentence and the target sentence in such a way that the correspondence between segments is monotone and one-to-one. *This work has been partially supported by TransType 2 (IST-2001-32091) and SisHITRA (TIC2000-1599-0O2). Using this segmentation, we attempted to improve the word alignments obtained with statistical techniques (Brown et al., 1993; Brown et al., 1990). These models depend on the length of the source and target sentences. The models are better estimated with shorter segments and, consequently, better word alignments are obtained. The basic scheme of the proposed parallel segmentation is the following: a) The source and the target sentences are initially segmented in the positions of the anchor words. b) As the number of source and target segments can be different, a dynamic programming algorithm is applied to find the optimal correspondences between segments. In section 2, we will show how to segment a bilingual corpus </context>
<context position="2824" citStr="Brown et al., 1993" startWordPosition="449" endWordPosition="452">anchor words. We will then describe the experiments carried out to test this new technique and the obtained results. 2 Segmentation of a parallel corpus Parallel segmentation is considered from a statistical point of view. Segmentation of a parallel corpus is carried out by segmenting every pair of sentences in this corpus. 2.1 Statistical machine translation We use a notation which is similar to the one proposed in (Brown et al., 1993), where f is a source sentence and e is a target sentence. 33 In order to translate from the source language to the target language in a statistical framework (Brown et al., 1993), we look for the probability of obtaining a sentence e from a sentence f, that is, Pr(e f). Applying Bayes rule, we have: Pr(e) Pr(f e) Pr(e = (1) Pr (f) Since we are searching for the target sentence with the best probability of being generated from the source sentence, by maximizing the preceding expression, we have: argmax Pr(e f) argmax Pr(e) Pr (f e), (2) where Pr(e) corresponds to the probability of the target language model and Pr(f I e) is known as the probability of the translation model. This model transforms a sentence in the target language into a sentence in the source language. </context>
<context position="7228" citStr="Brown et al., 1993" startWordPosition="1256" endWordPosition="1259">ative model. We can say that the segments in the source sentence are generated from the corresponding segments of the target sentence. Given a sentence 67, we define the probability for a sentence fi and a segmentation s as: Pr(fi, s I q) = 1S1 -d Pr(s ë) [f Pr(fd:_i+1 eccqg 1+1), (5) q=1 -d where Pr (fi+1 eccq 1+1) is again the probability of the translation model for a subsequence of the sentence f and a subsequence of the sentence e. We do not want to consider the translation model as a recursive model, so we will approximate_ the probability Pr ( fd: +1 ec _1+1) using Model 1 proposed in (Brown et al., 1993). In an intuitive manner, Model 1 computes the probability of a sequence of words to be translated by other sequence of words, without taking into account the word order. Therefore, it can allow translation inversions inside the sequences of words. The translation probability of a sequence of words e2 into a sequence of words eii2 using Model 1 is computed by: pr(e112 ecc2i _ m f( ci ,di2 ec2) _ o p (p+ l)° Et((d2,i) (eCC21 i))7 j=1 i=0 where p and o are the lengths in words of the sequences 4,2 and f, respectively. (fddi2, j) is the j-th word of the sequence fddi2, and (e2 , i) is the ith wor</context>
<context position="16465" citStr="Brown et al., 1993" startWordPosition="2909" endWordPosition="2912">6 5.2 Test Table 2: Training and test data sets of the bilingual FUB corpus 5.1. Training Italian English N. Sentences 3,038 N. Words 55,302 64,176 Vocabulary size 2,459 1,712 Perplexity(bigram) 31 25 Test Italian English N. Sentences 300 N. Words 6,121 7,243 Vocabulary size 715 547 N. Sentences 2,996 Spanish English N. Words 35,023 35,590 Vocabulary size 613 469 The number of initial segments that were allowed to be joined in one segment of the final segmentation was five. In order to infer a finite-state transducer, the GIATI technique needs word-level alignments such as those described in (Brown et al., 1993; Knight, 1999) for every pair of sentences of the training set. Model 4 (Brown et al., 1993) was estimated with the non-segmented corpus and word alignments were obtained. With the segmented corpus, each pair of segments was considered as a pair of sentences, Model 4 was estimated and the corresponding word alignments were computed. These alignments were computed using the soft38 ware GIZA++ (Och and Ney, 2000; Knight, 1999), obtaining the alignments produced by Model 4 (Brown et al., 1993). The finite-state transducer generated with GIATI is derived from a n-gram model inferred from the sour</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P.F. Brown, S.A. Della Pietra, V.J. Della Pietra, and R.L. Mercer. 1993. The mathematics of machine translation: Parameter estimation. Computational Linguistics, 19(2):263-310.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Casacuberta</author>
</authors>
<title>Inference of finite-state transducers by using regular grammars and morphisms.</title>
<date>2000</date>
<booktitle>In Proceedings of International Conference on Grammatical Inference - ICGI2000,</booktitle>
<pages>1--14</pages>
<contexts>
<context position="14583" citStr="Casacuberta, 2000" startWordPosition="2599" endWordPosition="2601">ery expensive procedure which is not error free. Another possible method for assessing the performance of this new segmentation technique is to compare the efficiency of a translation system obtained from the original corpus and another obtained from the segmented corpus on the translations of a test set of sentences. We trained two finite-state transducers: one from the original parallel corpus and one from the segmented parallel corpus. In order to infer the transducers from a parallel corpus we used a technique known as Grammatical Inference and Alignments for Transducer Inference (GIATI) (Casacuberta, 2000). The translation quality was measured for every transducer on the test set by using the translation word error rate (TWER). This is the average number of wrong words in the translations generated by the transducer with respect to fixed reference translations for the source sentences. 37 ITALIAN INITIAL SEGMENTS buonasera , sono la signora Rossi della camera trecentodue , vorrei disdire per domani mattina la colazione in camera, grazie . ENGLISH INITIAL SEGMENTS good evening, it is Mrs Rossi from room three hundred and two, I would like to cancel breakfast in room for tomorrow morning, thanks.</context>
</contexts>
<marker>Casacuberta, 2000</marker>
<rawString>F. Casacuberta. 2000. Inference of finite-state transducers by using regular grammars and morphisms. In Proceedings of International Conference on Grammatical Inference - ICGI2000, pages 1-14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
</authors>
<title>A statistical MT tutorial workbook.</title>
<date>1999</date>
<tech>Technical Report</tech>
<institution>Johns Hopkins Univ.</institution>
<note>prepared in connection with the JHU summer workshop,</note>
<contexts>
<context position="8262" citStr="Knight, 1999" startWordPosition="1449" endWordPosition="1450">(eCC21 i))7 j=1 i=0 where p and o are the lengths in words of the sequences 4,2 and f, respectively. (fddi2, j) is the j-th word of the sequence fddi2, and (e2 , i) is the ith word of the sequence 62. t((fd7 2 j) 1(42 i))is d 1 a statistical translation dictionary which stores the probability of the target word (42, , i) being translated into the source word (fddi2, j). This dictionary can be estimated automatically from the bilingual corpus by using the estimation methods described in (Brown et al., 1993). The software used to obtain this statistical dictionary was GIZA++ (Och and Ney, 2000; Knight, 1999). The probability that the sequences of words of the pair have a certain length (number of words) is measured by the C term. Now, expanding expression (4) with (5), we have: Pr(fib eel&apos;) = ISI _ E Pr(s en fl Pr(fo I eeegg_1+1). (6) sE5(e74) q=1 However, we are interested in computing only the best segmentation, so, we define the most probable segmentation probability, Pr(f ei), as the maximum of expression (6): max Pr(s -dq _cq ses(ec,f) q) 1-1Pru1 q=1 Considering Pr(s e) to be equally probable Pb for all s E $(e fi) l, (that is, C = Pr(s e7)) and -dg _cg assuming that Pr (f e d„ 1+1) is compu</context>
<context position="16480" citStr="Knight, 1999" startWordPosition="2913" endWordPosition="2914">Training and test data sets of the bilingual FUB corpus 5.1. Training Italian English N. Sentences 3,038 N. Words 55,302 64,176 Vocabulary size 2,459 1,712 Perplexity(bigram) 31 25 Test Italian English N. Sentences 300 N. Words 6,121 7,243 Vocabulary size 715 547 N. Sentences 2,996 Spanish English N. Words 35,023 35,590 Vocabulary size 613 469 The number of initial segments that were allowed to be joined in one segment of the final segmentation was five. In order to infer a finite-state transducer, the GIATI technique needs word-level alignments such as those described in (Brown et al., 1993; Knight, 1999) for every pair of sentences of the training set. Model 4 (Brown et al., 1993) was estimated with the non-segmented corpus and word alignments were obtained. With the segmented corpus, each pair of segments was considered as a pair of sentences, Model 4 was estimated and the corresponding word alignments were computed. These alignments were computed using the soft38 ware GIZA++ (Och and Ney, 2000; Knight, 1999), obtaining the alignments produced by Model 4 (Brown et al., 1993). The finite-state transducer generated with GIATI is derived from a n-gram model inferred from the source sentences. I</context>
</contexts>
<marker>Knight, 1999</marker>
<rawString>K. Knight. 1999. A statistical MT tutorial workbook. Technical Report prepared in connection with the JHU summer workshop, Johns Hopkins Univ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In ACLOO,</booktitle>
<pages>440--447</pages>
<location>Hongkong, China,</location>
<contexts>
<context position="8247" citStr="Och and Ney, 2000" startWordPosition="1445" endWordPosition="1448"> (p+ l)° Et((d2,i) (eCC21 i))7 j=1 i=0 where p and o are the lengths in words of the sequences 4,2 and f, respectively. (fddi2, j) is the j-th word of the sequence fddi2, and (e2 , i) is the ith word of the sequence 62. t((fd7 2 j) 1(42 i))is d 1 a statistical translation dictionary which stores the probability of the target word (42, , i) being translated into the source word (fddi2, j). This dictionary can be estimated automatically from the bilingual corpus by using the estimation methods described in (Brown et al., 1993). The software used to obtain this statistical dictionary was GIZA++ (Och and Ney, 2000; Knight, 1999). The probability that the sequences of words of the pair have a certain length (number of words) is measured by the C term. Now, expanding expression (4) with (5), we have: Pr(fib eel&apos;) = ISI _ E Pr(s en fl Pr(fo I eeegg_1+1). (6) sE5(e74) q=1 However, we are interested in computing only the best segmentation, so, we define the most probable segmentation probability, Pr(f ei), as the maximum of expression (6): max Pr(s -dq _cq ses(ec,f) q) 1-1Pru1 q=1 Considering Pr(s e) to be equally probable Pb for all s E $(e fi) l, (that is, C = Pr(s e7)) and -dg _cg assuming that Pr (f e d</context>
<context position="16879" citStr="Och and Ney, 2000" startWordPosition="2979" endWordPosition="2982">to be joined in one segment of the final segmentation was five. In order to infer a finite-state transducer, the GIATI technique needs word-level alignments such as those described in (Brown et al., 1993; Knight, 1999) for every pair of sentences of the training set. Model 4 (Brown et al., 1993) was estimated with the non-segmented corpus and word alignments were obtained. With the segmented corpus, each pair of segments was considered as a pair of sentences, Model 4 was estimated and the corresponding word alignments were computed. These alignments were computed using the soft38 ware GIZA++ (Och and Ney, 2000; Knight, 1999), obtaining the alignments produced by Model 4 (Brown et al., 1993). The finite-state transducer generated with GIATI is derived from a n-gram model inferred from the source sentences. In these source sentences, the words of every input sentence are labeled with the words of the corresponding target sentence according to the word alignments obtained with Model 4. Tables 3 and 4 show the average lengths of the source-target sentences, along with the lengths of the segmented sentences obtained by the proposed technique. It is worth noting that on the average, the more complex and </context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F. J. Och and H. Ney. 2000. Improved statistical alignment models. In ACLOO, pages 440-447, Hongkong, China, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Vidal</author>
</authors>
<title>Finite-state speech-to-speech translation.</title>
<date>1997</date>
<booktitle>In Proceedings of the International Conference on Acoustic, Speech and Signal Processing,</booktitle>
<volume>1</volume>
<pages>111--114</pages>
<marker>Vidal, 1997</marker>
<rawString>E. Vidal. 1997. Finite-state speech-to-speech translation. In Proceedings of the International Conference on Acoustic, Speech and Signal Processing, volume 1, pages 111-114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Vidal</author>
</authors>
<title>Final report.</title>
<date>2000</date>
<tech>Technical Report EUTRANS project, Technical Report Deliverable D0.1c,</tech>
<pages>32026</pages>
<institution>Information Technology. Long Term Research Domain. Open Scheme. Project Number</institution>
<contexts>
<context position="10756" citStr="Vidal, 2000" startWordPosition="1915" endWordPosition="1916">bability of the best segmentation is stored in s[b, a] d = 1 ...b Figure 1: Graphical representation of the matrix s[d, c] used for the computation of in I the dynamic programming algorithm ei); Another matrix can be computed together with the matrix s in order to store the path for the most probable segmentation, that is, to store the groupings of initial segments that are carried out for the most probable segmentation. 2.3 A complete example Now we offer a complete example of the computation of the segmentation of a pair of sentences. This pair of sentences is extracted from the FUB corpus (Vidal, 2000). This corpus is a bilingual text corpus of Italian-English pairs of sentences with restricted semantic domain. The sentences in the corpus are typical sentences of a tourist in the hotel domain, for example: • A che ora e disponibile ii servizio navetta per l&apos;aeroporto? /At what time is the shuttle service to the airport available?. • Avete una stanza libera dal quattro al dieci Settembre? / Do you have a free room from the fourth to the tenth of September?. Defining the following sets of anchor words for Italian and English, respectively: Italian Anchors „ : ?, !, con, per, e, perche, vorrei</context>
<context position="12169" citStr="Vidal, 2000" startWordPosition="2162" endWordPosition="2163">ed from the corpus: buonasera , sono la signora Rossi della camera trecentodue , vorrei disdire per domani mattina la colazione in camera, grazie . good evening, it is Mrs Rossi from room three hundred and two, I would like to cancel breakfast in room for tomorrow morning, thanks. The initial segmentation for the original sentences and the anchor words is shown in Figure 2. After running Algorithm 1 described in section 2 on the initial segmentation of Figure 2, we obtained the segmentation shown in Figure 3 as the best segmentation. 3 Experiments 3.1 Corpora description The EuTRANs-I corpus (Vidal, 2000) is a Spanish-English corpus which was generated semi-automatically for the E u TRAN S -I task which is a subtask of the &amp;quot;Traveler Task&amp;quot;. The 1 0 0 0 fl 0 f2 0 0 ft c = 1 ... a el e2 • • • ea 36 Algorithm 1: Algorithm for the computation of the probability of the best parallel segmentation for an initial segmentation based on anchor words (q, INPUT: (67 , n): initial segmentation; k: maximum number of consecutive initial segments that can be joined; OUTPUT: Pr(ff) q) probability of the best parallel segmentation for (67:, fb; VAR: s: matrix to compute the best probability; BEGIN for (c=1; c &lt;=</context>
</contexts>
<marker>Vidal, 2000</marker>
<rawString>E. Vidal. 2000. Final report. Technical Report EUTRANS project, Technical Report Deliverable D0.1c, Information Technology. Long Term Research Domain. Open Scheme. Project Number 32026.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>