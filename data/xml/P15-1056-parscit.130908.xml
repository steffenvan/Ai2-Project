<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.9611945">
Bring you to the past: Automatic Generation of Topically Relevant Event
Chronicles
</title>
<author confidence="0.999347">
Tao Ge1,2, Wenzhe Pei1, Heng Ji3, Sujian Li1,2, Baobao Chang1,2, Zhifang Sui1,2
</author>
<affiliation confidence="0.99796075">
1Key Laboratory of Computational Linguistics, Ministry of Education,
School of EECS, Peking University, Beijing, 100871, China
2Collaborative Innovation Center for Language Ability, Xuzhou, Jiangsu, 221009, China
3Computer Science Department, Rensselaer Polytechnic Institute, Troy, NY 12180, USA
</affiliation>
<email confidence="0.9477155">
getao@pku.edu.cn, wenzhepei@pku.edu.cn, jih@rpi.edu,
lisujian@pku.edu.cn, chbb@pku.edu.cn, szf@pku.edu.cn
</email>
<sectionHeader confidence="0.997373" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999976928571429">
An event chronicle provides people with
an easy and fast access to learn the past.
In this paper, we propose the first novel
approach to automatically generate a top-
ically relevant event chronicle during a
certain period given a reference chronicle
during another period. Our approach con-
sists of two core components – a time-
aware hierarchical Bayesian model for
event detection, and a learning-to-rank
model to select the salient events to con-
struct the final chronicle. Experimental re-
sults demonstrate our approach is promis-
ing to tackle this new problem.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999967952380952">
Human civilization has developed for thousands of
years. During the long period, history witnessed
the changes of societies and dynasties, the revo-
lution of science and technology, as well as the
emergency of celebrities, which are great wealth
for later generations. Even nowadays, people usu-
ally look back through history either for their work
or interests. Among various ways to learn history,
many people prefer reading an event chronicle
summarizing important events in the past, which
saves much time and efforts.
The left part of Figure 1 shows a disaster event
chronicle from Infoplease1, by which people can
easily learn important disaster events in 2009. Un-
fortunately, almost all the available event chron-
icles are created and edited manually, which re-
quires editors to learn everything that happened in
the past. Even if an editor tries her best to gener-
ate an event chronicle, she still cannot guarantee
that all the important events are included. More-
over, when new events happen in the future, she
</bodyText>
<footnote confidence="0.879354">
1http://www.infoplease.com/world/disasters/2009.html
</footnote>
<bodyText confidence="0.999936512820513">
needs to update the chronicle in time, which is
laborious. For example, the event chronicle of
2010 in Wikipedia2 has been edited 8,488 times
by 3,211 distinct editors since this page was cre-
ated. In addition, event chronicles can vary ac-
cording to topic preferences. Some event chroni-
cles are mainly about disasters while others may
focus more on sports. For people interested in
sports, the event chronicle in Figure 1 is unde-
sirable. Due to the diversity of event chronicles,
it is common that an event chronicle regarding a
specific topic for some certain period is unavail-
able. If editing an event chronicle can be done by
computers, people can have an overview of any pe-
riod according to their interests and do not have to
wait for human editing, which will largely speed
up knowledge acquisition and popularization.
Based on this motivation, we propose a new task
of automatic event chronicle generation, whose
goal is to generate a topically relevant event chron-
icle for some period based on a reference chroni-
cle of another period. For example, if an disaster
event chronicle during 2009 is available, we can
use it to generate a disaster chronicle during 2010
from a news collection, as shown in Figure 1.
To achieve this goal, we need to know what
events happened during the target period, whether
these events are topically relevant to the chron-
icle, and whether they are important enough to
be included, since an event chronicle has only a
limited number of entries. To tackle these chal-
lenges, we propose an approach consisting of two
core components – an event detection component
based on a novel time-aware hierarchical Bayesian
model and a learning-to-rank component to select
the salient events to construct the final chronicle.
Our event detection model can not only learn topic
preferences of the reference chronicle and mea-
sure topical relevance of an event to the chronicle
</bodyText>
<footnote confidence="0.81671">
2http://en.wikipedia.org/wiki/2010
</footnote>
<page confidence="0.928386">
575
</page>
<note confidence="0.986848333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 575–585,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<figureCaption confidence="0.99972">
Figure 1: Example for automatic generation of a topically relevant event chronicle.
</figureCaption>
<bodyText confidence="0.999515333333333">
but also can effectively distinguish similar events
by taking into account time information and event-
specific details. Experimental results show our ap-
proach significantly outperforms baseline methods
and that is promising to tackle this new problem.
The major novel contributions of this paper are:
</bodyText>
<listItem confidence="0.998460583333333">
• We propose a new task automatic generation
of a topically relevant event chronicle, which
is meaningful and has never been studied to
the best of our knowledge.
• We design a general approach to tackle
this new problem, which is language-
independent, domain-independent and scal-
able to any arbitrary topics.
• We design a novel event detection model. It
outperforms the state-of-the-art event detec-
tion model for generating topically relevant
event chronicles.
</listItem>
<sectionHeader confidence="0.835378" genericHeader="introduction">
2 Terminology and Task Overview
</sectionHeader>
<bodyText confidence="0.977888857142857">
Figure 2: An example of relevance-topic-event hi-
erarchical structure for a disaster event chronicle.
As shown in Figure 1, an event (entry) in an
event chronicle corresponds to a specific occur-
rence in the real world, whose granularity depends
on the chronicle. For a sports chronicle, an event
entry may be a match in 2010 World Cup, while
for a comprehensive chronicle, the World Cup is
regarded as one event. In general, an event can be
represented by a cluster of documents related to
it. The topic of an event can be considered as the
event class. For example, we can call the topic of
MH17 crash as air crash (fine-grained) or disaster
(coarse-grained). The relation between topic and
event is shown through the example in Figure 2.
An event chronicle is a set of important events
occurring in the past. Event chronicles vary ac-
cording to topic preferences. For the disaster
chronicle shown in Figure 1, earthquakes and air
crashes are relevant topics while election is not.
Hence, we can use a hierarchical structure to orga-
nize documents in a corpus, as Figure 2 shows.
Formally, we define an event chronicle E =
{e1, e2, ..., en} where ez is an event entry in
E and it can be represented by a tuple ez =
(Dei, tei, zei). Dei denotes the set of documents
about ez, tei is ez’s time and zei is ez’s topic. Spe-
cially, we use A to denote the time period (inter-
val) covered by E, and B to denote the topic distri-
bution of E, which reflects E’s topic preferences.
As shown in Figure 1, the goal of our task is to
generate an (target) event chronicle ET during AT
based on a reference chronicle ER during AR. The
topic distributions of ET and ER (i.e., BT and BR)
should be consistent.
</bodyText>
<sectionHeader confidence="0.998771" genericHeader="method">
3 Event Detection
</sectionHeader>
<subsectionHeader confidence="0.999814">
3.1 Challenges of Event Detection
</subsectionHeader>
<figureCaption confidence="0.890328333333333">
Figure 3: Documents that are lexically similar but
refer to different events. The underlined words are
event-specific words.
</figureCaption>
<page confidence="0.996292">
576
</page>
<bodyText confidence="0.999323">
For our task, the first step is to detect topically
relevant events from a corpus. A good event de-
tection model should be able to
</bodyText>
<listItem confidence="0.999445">
(1) measure the topical relevance of a detected
event to the reference chronicle.
(2) consider document time information.
(3) look into a document’s event-specific details.
</listItem>
<bodyText confidence="0.996626909090909">
The first requirement is to identify topically rele-
vant events since we want to generate a topically
relevant chronicle. The second and third require-
ments are for effectively distinguishing events, es-
pecially similar events like the example in Figure
3. To distinguish the similar events, we must con-
sider document time information (for distinguish-
ing events in d1 and d2) and look into the docu-
ment’s event-specific details (the underlined words
in Figure 3) (for distinguishing events in d1 and
d3).
</bodyText>
<subsectionHeader confidence="0.999021">
3.2 TaHBM: A Time-aware Hierarchical
Bayesian Model
</subsectionHeader>
<bodyText confidence="0.9971754">
To tackle all the above challenges mentioned in
Section 3.1, which cannot be tackled by conven-
tional detection methods (e.g., agglomerative clus-
tering), we propose a Time-aware Hierarchical
Bayesian Model (TaHBM) for detecting events.
</bodyText>
<subsectionHeader confidence="0.580635">
Model Overview
</subsectionHeader>
<bodyText confidence="0.8784251">
Figure 4: The plate diagram of TaHBM. The
shaded nodes are observable nodes.
The plate diagram and generative story of
TaHBM are depicted in Figure 4 and Figure 5
respectively. For a corpus with M documents,
TaHBM assumes each document has three labels –
s, z, and e. s is a binary variable indicating a doc-
ument’s topical relevance to the reference event
chronicle, whose distribution is a Bernoulli dis-
tribution πs drawn from a Beta distribution with
</bodyText>
<equation confidence="0.994183105263158">
Draw πs — Beta(γs)
For each s E 10, 11: draw θ(3) — Dir(α)
For each z = 1, 2, 3, ..., K: draw φ(z) —
Dir(ε), ψ(z) z— Dir(βz)
For each e = 1, 2, 3, ..., E: drawψ(e)
e —
Dir(βe)
For each document m = 1, 2, 3, ..., M:
Draw s — Bernoulli(πs)
Draw z — Multi(θ(3))
Draw e — Multi(φ(z))
Draw t&apos; — Gaussian(µe, σe), t — Lt&apos;]
Draw πx — Beta(γx)
For each word w in document m:
Draw x — Bernoulli(πx)
If x = 0: draw w — ψ(z)
z
Else: draw w — ψ(e)
e
</equation>
<figureCaption confidence="0.998829">
Figure 5: The generative story of TaHBM
</figureCaption>
<bodyText confidence="0.9996625">
symmetric hyperparameter γs. s=1 indicates the
document is topically relevant to the chronicle
while s=0 means not. z is a document’s topic label
drawn from a K-dimensional multinomial distri-
bution θ, and e is a document’s event label drawn
from an E-dimensional multinomial distribution
φ. θ and φ are drawn from Dirichlet distributions
with symmetric hyperparameter α and ε respec-
tively. For an event e&apos;, it can be represented by a
set of documents whose event label is e&apos;.
In TaHBM, the relations among s, z and e are
similar to the hierarchical structure in Figure 2.
Based on the dependencies among s, z and e, we
can compute the topical relevance of an event to
the reference chronicle by Eq (1) where P(e|z),
P(e), P(s) and P(z|s) can be estimated using
Bayesian inference (some details of estimation of
P(s) and P(s|z) will be discussed in Section 3.3)
and thus we solve the first challenge in Section 3.1
(i.e., topical relevance measure problem).
</bodyText>
<equation confidence="0.999589">
P(s) x P(z|s) x P(e|z)
P(s|e) = (1)
P(e)
</equation>
<bodyText confidence="0.999955125">
Now, we introduce how to tackle the second
challenge – how to take into account a document’s
time information for distinguishing events. In
TaHBM, we introduce t, document timestamps.
We assume t = Lt&apos;] where t&apos; is drawn from a
Gaussian distribution with mean µ and variance
σ2. Each event e corresponds to a specific Gaus-
sian distribution which serves as a temporal con-
</bodyText>
<page confidence="0.981329">
577
</page>
<bodyText confidence="0.99998842">
straint for e. A Gaussian distribution has only one
peak around where the probability is concentrated.
Its value trends to zero if a point lies far away
from the mean. For this reason, a Gaussian dis-
tribution is suitable to describe an event’s tempo-
ral distribution whose probability usually concen-
trates around the event’s burst time and it will be
close to zero if time lies far from the burst time.
Figure 6 shows the temporal distribution of the
July 2009 Urumqi riots3. The probability of this
event concentrates around the 7th day. If we use a
Gaussian distribution (the dashed curve in Figure
6) to constrain this event’s time scope, the doc-
uments whose timestamps are beyond this scope
are unlikely to be grouped into this event’s cluster.
Now that the problems of topical relevance
measure and temporal constraints have been
solved, we discuss how to identify event-specific
details of a document for distinguishing events.
By analyzing the documents shown in Figure 3,
we find that general words (e.g., earthquake, kill,
injury, devastate) indicate the document’s topic
while words about event-specific details (e.g.,
Napa, California, 3.4-magnitude) are helpful to
determine what events the document talks about.
Assuming a person is asked to analyze what event
a document discusses, it would be a natural way
to first determine topic of the document based its
general words, and then determine what event it
talks about given its topic, timestamp and event-
specific details, which is exactly the way our
TaHBM works.
For simplicity, we call the general words as
topic words and call the words describing event-
specific information as event words. Inspired by
the idea of Chemudugunta et al. (2007), given the
different roles these two kinds of words play, we
assume words in a document are generated by two
distributions: topic words are generated by a topic
word distribution 0z while event words are gen-
erated by an event word distribution 0e. 0z and
0e are V -dimensional multinomial distributions
drawn from Dirichlet distributions with symmetric
hyperparameter βz and βe respectively, where IV
denotes the size of vocabulary V . A binary indica-
tor x, which is generated by a Bernoulli distribu-
tion π. drawn from a Beta distribution with sym-
metric hyperparameter γ., determines whether a
word is generated by 0z or 0e. Specifically, if
x = 0, a word is drawn from 0z; otherwise the
</bodyText>
<footnote confidence="0.98472">
3http://en.wikipedia.org/wiki/July 2009 Urumqi riots
</footnote>
<figureCaption confidence="0.987423">
Figure 6: The temporal distribution of documents
</figureCaption>
<bodyText confidence="0.864883272727273">
about the Urumqi riots, which can be described by
a Gaussian distribution (the dashed curve). The
horizontal axis is time (day) and the vertical axis
is the number of documents about this event.
word is drawn from 0e. Since 0z is shared by all
events of one topic, it can be seen as a background
word distribution which captures general aspects.
In contrast, 0e tends to describe the event-specific
aspects. In this way, we can model a document’s
general and specific aspects and use the informa-
tion to better distinguish similar events4.
</bodyText>
<subsectionHeader confidence="0.420311">
Model Inference
</subsectionHeader>
<bodyText confidence="0.9996464">
Like most Bayesian models, we use collapsed
Gibbs sampling for model inference in TaHBM.
For a document m, we present the conditional
probability of its latent variables s, z and x for
sampling:
</bodyText>
<equation confidence="0.987902375">
cs + γ. cs,zm + α
P(sm|s~¬m,~z, γ., α) = Ps(cs + γ.) X Pz(cs,z + α) (2)
P(zm|~z¬m, ~e, ~s, ~wm,~xm, α, ε, βz)
csm,z + α
X
Pz (csm,z + α)
(cz,wm,n + Pn−1
w∈V (cz,w + βz) + n − 1 )(1−xm,n)
i=1 1(wm,i = wm,n) + βz
P
(3)
P(xm,n|~wm, ~x¬m,n, zm, em, γx)
= cm,x + γxX ( E [�Czm,w,n + βz/� (1−x)
(cX Nm + 2γx w∈V (mczm,w + ,C0
em,wm,n+βe
Pw∈V (cem,w + βe))x
</equation>
<bodyText confidence="0.983733">
where V denotes the vocabulary, wm,n is the nth
word in a document m, cs is the count of docu-
ments with topic relevance label s, cs,z is the count
</bodyText>
<footnote confidence="0.683354">
4TaHBM is language-independent, which can identify
event words without name tagging. But if name tagging re-
sults are available, we can also exploit them (e.g., we can fix x
of a named entity specific to an event to 1 during inference.).
</footnote>
<equation confidence="0.9771798">
=
cz,em + ε
P e(cz,e + ε)
NmYX
n=1
</equation>
<page confidence="0.96045">
578
</page>
<bodyText confidence="0.999736125">
of documents with topic relevance label s and
topic label z, cz,w is the count of word w whose
document’s topic label is z, cm,x is the count of
words with binary indicator label x in m and 1( )
is an indicator function.
Specially, for variable e which is dependent on
the Gaussian distribution, its conditional probabil-
ity for sampling is computed as Eq (5):
</bodyText>
<equation confidence="0.989316444444444">
P(em|~e¬m,~z,~wm,~xm, tm, ε, βe, µe, σe)
I
czm, e + ε ×tm+1 pG(tm; µe, σe)
Lee(czm,e + ε) m
En-1 /�
(ce,wm nw � (Ce,w (+ /tee) + n wm,n)
+ /tee )xm n
Le
(5)
</equation>
<bodyText confidence="0.999695">
where pG(x; µ, σ) is a Gaussian probability mass
function with parameter µ and σ.
The function pG( ) can be seen as the temporal
distribution of an event, as discussed before. In
this sense, the temporal distribution of the whole
corpus can be considered as a mixture of Gaussian
distributions of events. As a natural way to esti-
mate parameters of mixture of Gaussians, we use
EM algorithm (Bilmes, 1998). In fact, Eq (5) can
be seen as the E-step. The M-step of EM updates
µ and σ as follows:
where td is document d’s timestamp and De is the
set of documents with event label e.
Specially, for sampling e we use σ0 e defined as
σ0e = σe + τ (τ is a small number for smoothing5)
because when σ is very small (e.g., σ = 0), an
event’s temporal scope will be strictly constrained.
Using σ0 e can help the model overcome this “trap”
for better parameter estimation.
Above all, the model inference and parameter
estimation procedure can be summarized by algo-
rithm 1.
</bodyText>
<subsectionHeader confidence="0.9848515">
3.3 Learn Topic Preferences of the Event
Chronicle
</subsectionHeader>
<bodyText confidence="0.842918125">
A prerequisite to use Eq (1) to compute an event’s
topical relevance to an event chronicle is that
we know P(s) and P(z|s) which reflects topic
preferences of the event chronicle. Nonetheless,
P(s) and P(z|s) vary according to different event
chronicles. Hence, we cannot directly estimate
5τ is set to 0.5 in our experiments.
Algorithm 1 Model inference for TaHBM
</bodyText>
<listItem confidence="0.973323928571429">
1: Initialize parameters in TaHBM;
2: for each iteration do
3: for each document d in the corpus do
4: sample s according to Eq (2)
5: sample z according to Eq (3)
6: sample e according to Eq (5)
7: for each word w in d do
8: sample x according to Eq (4)
9: end for
10: end for
11: for each event e do
12: update µe, σe according to Eq (6)
13: end for
14: end for
</listItem>
<bodyText confidence="0.999834533333333">
them in an unsupervised manner; instead, we pro-
vide TaHBM some “supervision”. As we men-
tioned in section 3.2, the variable s indicates a
document’s topical relevance to the event chron-
icle. For some documents, s label can be easily
derived with high accuracy so that we can exploit
the information to learn the topic preferences.
To obtain the labeled data, we use the descrip-
tion of each event entry in the reference chroni-
cle ER during period AR as a query to retrieve
relevant documents in the corpus using Lucene
(Jakarta, 2004) which is an information retrieval
software library. We define R as the set of doc-
uments in hits of any event entry in the reference
chronicle returned by Lucene:
</bodyText>
<equation confidence="0.975106">
R = Ue∈ERHit(e)
</equation>
<bodyText confidence="0.977499125">
where Hit(e) is the complete hit list of event e re-
turned by Lucene. For document d with timestamp
td, if d E/ R and td E AR, then d is considered ir-
relevant to the event chronicle and thus it would be
labeled as a negative example.
To generate positive examples, we use a strict
criterion since we cannot guarantee that all the
documents in R are actually relevant. To pre-
cisely generate positive examples, a document d is
labeled as positive only if it satisfies the positive
condition which is defined as follows:
]e∈ER0 G td − te G 10 n sim(d, e) &gt; 0.4
where te is time6 of event e, provided by the ref-
erence chronicle. sim(d, e) is Lucene’s score of
d given query e. According to the positive con-
dition, a positive document example must be lexi-
</bodyText>
<footnote confidence="0.894875">
6The time unit of td and te is one day.
</footnote>
<figure confidence="0.815975">
Nmrl×
n=1
Ed∈De td Ed∈D (td − µe)2
|De |,σe |De|
µe =
(6)
</figure>
<page confidence="0.987873">
579
</page>
<bodyText confidence="0.992218454545455">
cally similar to some event in the reference chron-
icle and its timestamp is close to the event’s time.
As a result, we can use the labeled data to learn
topic preferences of the event chronicle. For the
labeled documents, s is fixed during model infer-
ence. In contrast, for documents that are not la-
beled, s is sampled by Eq (2). In this manner,
TaHBM can learn topic preferences (i.e., P(z|s))
without any manually labeled data and thus can
measure the topical relevance between an event
and the reference chronicle.
</bodyText>
<sectionHeader confidence="0.992342" genericHeader="method">
4 Event Ranking
</sectionHeader>
<bodyText confidence="0.999604666666667">
Generating an event chronicle is beyond event de-
tection because we cannot use all detected events
to generate the chronicle with a limited number of
entries. We propose to use learning-to-rank tech-
niques to select the most salient events to generate
the final chronicle since we believe the reference
event chronicle can teach us the principles of se-
lecting salient events. Specifically, we use SVM-
Rank (Joachims, 2006).
</bodyText>
<subsectionHeader confidence="0.995774">
4.1 Training and Test Set Generation
</subsectionHeader>
<bodyText confidence="0.999139733333333">
The event detection component returns many doc-
ument clusters, each of which represents an event.
As Section 3.2 shows, each event has a Gaussian
distribution whose mean indicates its burst time in
TaHBM. We use the events whose burst time is
during the reference chronicle’s period as training
examples and treat those during the target chroni-
cle’s period as test examples. Formally, the train-
ing set and test set are defined as follows:
Train = {e|µe E AR}, Test = {e|µe E AT}
In the training set, events containing at least one
positive document (i.e. relevant to the event chron-
icle) in Section 3.3 are labeled as high rank pri-
ority while those without positive documents are
labeled as low priority.
</bodyText>
<subsectionHeader confidence="0.882241">
4.2 Features
</subsectionHeader>
<bodyText confidence="0.994178">
We use the following features to train the ranking
model, all of which can be provided by TaHBM.
</bodyText>
<listItem confidence="0.83770625">
• P(s = 1|e): the probability that an event e is
topically relevant to the reference chronicle.
• P(e|z): the probability reflects an event’s im-
pact given its topic.
• σe: the parameter of an event e’s Gaussian
distribution. It determines the ‘bandwidth’
of the Gaussian distribution and thus can be
considered as the time span of e.
|De|: the number of documents related to
event e, reflecting the impact of e.
• |De |: For an event with a long time span (e.g.,
σe
</listItem>
<bodyText confidence="0.8482998">
Premier League), the number of relevant doc-
uments is large but its impact may not be pro-
found. Hence, we use |De|
σe to normalize |De|,
which may better reflect the impact of e.
</bodyText>
<sectionHeader confidence="0.999525" genericHeader="method">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.9995">
5.1 Experiment Setting
</subsectionHeader>
<bodyText confidence="0.999918558823529">
Data: We use various event chronicles during
2009 as references to generate their counterparts
during 2010. Specifically, we collected disaster,
sports, war, politics and comprehensive chroni-
cles during 2009 from mapreport7, infoplease and
Wikipedia8. To generate chronicles during 2010,
we use 2009-2010 APW and Xinhua news in En-
glish Gigaword (Graff et al., 2003) and remove
documents whose titles and first paragraphs do not
include any burst words. We detect burst words us-
ing Kleinberg algorithm (Kleinberg, 2003), which
is a 2-state finite automaton model and widely
used to detect bursts. In total, there are 140,557
documents in the corpus.
Preprocessing: We remove stopwords and use
Stanford CoreNLP (Manning et al., 2014) to do
lemmatization.
Parameter setting: For TaHBM, we empirically
set α = 0.05, Qz = 0.005, Qe = 0.0001, ryg =
0.05, ryx = 0.5, ε = 0.01, the number of topics
K = 50, and the number of events E = 5000. We
run Gibbs sampler for 2000 iterations with burn-in
period of 500 for inference. For event ranking, we
set regularization parameter of SVMRank c = 0.1.
Chronicle display: We use a heuristic way to
generate the description of each event. Since the
first paragraph of a news article is usually a good
summary of the article and the earliest document
in a cluster usually explicitly describes the event,
for an event represented by a document cluster,
we choose the first paragraph of the earliest doc-
ument written in 2010 in the cluster to generate
the event’s description. The earliest document’s
timestamp is considered as the event’s time.
</bodyText>
<figure confidence="0.379252">
•
</figure>
<footnote confidence="0.995636">
7http://www.mapreport.com
8http://en.wikipedia.org/wiki/2009
</footnote>
<page confidence="0.994069">
580
</page>
<subsectionHeader confidence="0.958273">
5.2 Evaluation Methods and Baselines
</subsectionHeader>
<bodyText confidence="0.9998991">
Since there is no existing evaluation metric for the
new task, we design a method for evaluation.
Although there are manually edited event
chronicles on the web, which may serve as ref-
erences for evaluation, they are often incomplete.
For example, the 2010 politics event chronicle on
Wikipedia has only two event entries. Hence, we
first pool all event entries of existing chronicles on
the web and chronicles generated by approaches
evaluated in this paper and then have 3 human
assessors judge each event entry for generating a
ground truth based on its topical relevance, impact
and description according to the standard of the
reference chronicles. An event entry will be in-
cluded in the ground-truth only if it is selected as
a candidate by at least two human judges. On aver-
age, the existing event chronicles on the web cover
50.3% of event entries in the ground-truth.
Given the ground truth, we can use Precision@k
to evaluate an event chronicle’s quality.
</bodyText>
<equation confidence="0.99129">
Precision@k = |EG n Et,,pk|/k
</equation>
<bodyText confidence="0.999896818181818">
where EG and Et,,pk are ground-truth chronicle
and the chronicle with top k entries generated by
an approach respectively. If there are multiple
event entries corresponding to one event in the
ground-truth, only one is counted.
For comparison, we choose several baseline ap-
proaches. Note that event detection models except
TaHBM do not provide features used in learning-
to-rank model. For these detection models, we use
a criterion that considers both relevance and im-
portance to rank events:
</bodyText>
<equation confidence="0.9719825">
�rankscorebasic(e) = maze/EERsim(d, e&apos;)
dEDe
</equation>
<bodyText confidence="0.999440666666667">
where ER is the reference chronicle and sim(d, e&apos;)
is Lucene’s score of document d given query e&apos;.
We call this ranking criterion as basic criterion.
</bodyText>
<listItem confidence="0.979705076923077">
• Random: We randomly select k documents
to generate the chronicle.
• NB+basic: Since TaHBM is essentially an
extension of NB, we use Naive Bayes (NB)
to detect events and basic ranking criterion to
rank events.
• B-HAC+basic: We use hierarchical agglom-
erative clustering (HAC) based on BurstVSM
schema (Zhao et al., 2012) to detect events,
which is the state-of-the-art event detection
method for general domains.
• TaHBM+basic: we use this baseline to verify
the effectiveness of learning-to-rank.
</listItem>
<bodyText confidence="0.998478">
As TaHBM, the number of clusters in NB is set to
5000 for comparison. For B-HAC, we adopt the
same setting with (Zhao et al., 2012).
</bodyText>
<subsectionHeader confidence="0.999302">
5.3 Experiment Results
</subsectionHeader>
<bodyText confidence="0.999736184210526">
Using the evaluation method introduced above,
we can conduct a quantitative evaluation for event
chronicle generation approaches9.
Table 1 shows the overall performance. Our
approach outperforms the baselines for all chron-
icles. TaHBM beats other detection models for
chronicle generation owing to its ability of incor-
porating the temporal information and identifica-
tion of event-specific details of a document. More-
over, learning-to-ranking is proven more effective
to rank events than the basic ranking criterion.
Among these 5 chronicles, almost all ap-
proaches perform best on disaster event chronicle
while worst on sports event chronicle. We ana-
lyzed the results and found that many event entries
in the sports event chronicle are about the open-
ing match, or the first-round match of a tourna-
ment due to the display method described in Sec-
tion 5.1. According to the reference sport event
chronicle, however, only matches after quarterfi-
nals in a tournament are qualified to be event en-
tries. In other words, a sports chronicle should
provide information about the results of semi-final
and final, and the champion of the tournament in-
stead of the first-round match’s result, which ac-
counts for the poor performance. In contrast, the
earliest document about a disaster event always di-
rectly describes the disaster event while the fol-
lowing reports usually concern responses to the
event such as humanitarian aids and condolence
from the world leaders. The patterns of reporting
war events are similar to those of disasters, thus
the quality of war chronicle is also good. Pol-
itics is somewhat complex because some politi-
cal events (e.g., election) are arranged in advance
while others (e.g., government shutdown) are un-
expected. It is notable that for generating com-
prehensive event chronicles, learning-to-rank does
</bodyText>
<footnote confidence="0.9846395">
9Due to the space limitation, we display chronicles gener-
ated by our approach in the supplementary notes.
</footnote>
<page confidence="0.98745">
581
</page>
<table confidence="0.997963285714286">
sports politics disaster war comprehensive
P@50 P@100 P@50 P@100 P@50 P@100 P@50 P@100 P@50 P@100
Random 0.02 0.08 0 0 0.02 0.04 0 0 0.02 0.03
NB+basic 0.08 0.12 0.18 0.19 0.42 0.36 0.18 0.17 0.38 0.31
B-HAC+basic 0.10 0.13 0.30 0.26 0.50 0.47 0.30 0.22 0.36 0.32
TaHBM+basic 0.18 0.15 0.30 0.29 0.50 0.43 0.46 0.36 0.38 0.33
Our approach 0.20 0.15 0.38 0.36 0.64 0.53 0.54 0.41 0.40 0.33
</table>
<tableCaption confidence="0.995663">
Table 1: Performance of event chronicle generation.
</tableCaption>
<table confidence="0.9997985">
Topically Irrelevant Trivial Events Indirect Description Redundant Entries
disaster 31.91% 17.02% 44.68% 6.38%
sports 38.82% 55.29% 3.52% 2.35%
comp - 67.16% 31.34% 1.49%
</table>
<tableCaption confidence="0.999765">
Table 2: Proportion of errors in disaster, sports and comprehensive event chronicles.
</tableCaption>
<bodyText confidence="0.998323438356164">
not show significant improvement. A possible rea-
son is that a comprehensive event chronicle does
not care the topical relevance of a event. In other
words, its ranking problem is simpler so that the
learning-to-rank does not improve the basic rank-
ing criterion much.
Moreover, we analyze the incorrect entries in
the chronicles generated by our approaches. In
general, there are four types of errors.
Topically irrelevant: the topic of an event entry
is irrelevant to the event chronicle.
Minor events: the event is not important enough
to be included. For example, “20100828:
Lebanon beat Canada 81-71 in the opening round
of the basketball world championships” is a minor
event in the sports chronicle because it is about an
opening-round match and not important enough.
Indirect description: the entry does not describe
a major event directly. For instance, “20100114:
Turkey expressed sorrow over the Haiti earth-
quake” is an incorrect entry in the disaster chroni-
cle though it mentions the Haiti earthquake.
Redundant entries: multiple event entries de-
scribe the same event.
We analyze the errors of the disaster, sports and
comprehensive event chronicle since they are rep-
resentative, as shown in Table 2.
Topical irrelevance is a major error source for
both disaster and sports event chronicles. This
problem mainly arises from incorrect identifica-
tion of topically relevant events during detection.
Moreover, disaster and sports chronicles have their
own more serious problems. Disaster event chron-
icles suffer from the indirect description problem
since there are many responses (e.g., humanitar-
ian aids) to a disaster. These responses are top-
ically relevant and contain many documents, and
thus appear in the top list. One possible solution
might be to increase the event granularity by ad-
justing parameters of the detection model so that
the documents describing a major event and those
discussing in response to this event can be grouped
into one cluster (i.e., one event). In contrast, the
sports event chronicle’s biggest problem is on mi-
nor events, as mentioned before. Like the sports
chronicle, the comprehensive event chronicle also
has many minor event entries but its main prob-
lem results from its strict criterion. Since com-
prehensive chronicles can include events of any
topic, only extremely important events can be in-
cluded. For example, “Netherlands beat Uruguay
to reach final in the World Cup 2010” may be a
correct event entry in sports chronicles but it is not
a good entry in comprehensive chronicles. Com-
pared with comprehensive event chronicles, events
in other chronicles tend to describe more details.
For example, a sports chronicle may regard each
match in the World Cup as an event while compre-
hensive chronicles consider the World Cup as one
event, which requires us to adapt event granularity
for different chronicles.
Also, we evaluate the time of event entries in
these five event chronicles because event’s hap-
pening time is not always equal to the timestamp
of the document creation time (UzZaman et al.,
2012; Ge et al., 2013). We collect existing man-
ually edited 2010 chronicles on the web and use
their event time as gold standard. We define a
metric to evaluate if the event entry’s time in our
chronicle is accurate:
diff = �e∈E∩E∗ |(te − t* e)|/|E n E*|
where E and E* are our chronicle and the manu-
ally edited event chronicle respectively. te is e’s
</bodyText>
<page confidence="0.991369">
582
</page>
<bodyText confidence="0.8750265">
time labeled by our method and t∗e is e’s correct
time. Note that for multiple entries referring the
same event in event chronicles, the earliest entry’s
time is used as the event’s time to compute diff.
sports politics disaster war comprehensive
0.800 3.363 1.042 1.610 2.467
</bodyText>
<tableCaption confidence="0.758797">
Table 3: Difference between an event’s actual time
and the time in our chronicles. Time unit is a day.
</tableCaption>
<bodyText confidence="0.98611725">
Table 3 shows the performance of our approach
in labeling event time. For disaster, sports and war,
the accuracy is desirable since important events
about these topics are usually reported in time.
In contrast, the accuracy of political event time
is the lowest. The reason is that some political
events may be confidential and thus they are not
reported as soon as they happen; on the other hand,
some political events (e.g., a summit) are reported
several days before the events happen. The com-
prehensive event chronicle includes many political
events, which results in a lower accuracy.
</bodyText>
<sectionHeader confidence="0.999986" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999959820512821">
To the best of our knowledge, there was no previ-
ous end-to-end topically relevant event chronicle
generation work but there are some related tasks.
Event detection, sometimes called topic detec-
tion (Allan, 2002), is an important part of our ap-
proach. Yang et al. (1998) used clustering tech-
niques for event detection on news. He et al.
(2007) and Zhao et al. (2012) designed burst fea-
ture representations for detecting bursty events.
Compared with our TaHBM, these methods lack
the ability of distinguishing similar events.
Similar to event detection, event extraction fo-
cuses on finding events from documents. Most
work regarding event extraction (Grishman et al.,
2005; Ahn, 2006; Ji and Grishman, 2008; Chen
and Ji, 2009; Liao and Grishman, 2010; Hong et
al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et
al., 2013) was developed under Automatic Content
Extraction (ACE) program. The task only defines
33 event types and events are in much finer grain
than those in our task. Moreover, there was work
(Verhagen et al., 2005; Chambers and Jurafsky,
2008; Bethard, 2013; Chambers, 2013; Chambers
et al., 2014) about temporal event extraction and
tracking. Like ACE, the granularity of events in
this task is too fine to be suitable for our task.
Also, timeline generation is related to our work.
Most previous work focused on generating a time-
line for a document (Do et al., 2012), a centroid
entity (Ji et al., 2009) or one major event (Hu et
al., 2011; Yan et al., 2011; Lin et al., 2012; Li and
Li, 2013). In addition, Li and Cardie (2014) gen-
erated timelines for users in microblogs. The most
related work to ours is Swan and Allan (2000).
They used a timeline to show bursty events along
the time, which can be seen as an early form of
event chronicles. Different from their work, we
generate a topically relevant event chronicle based
on a reference event chronicle.
</bodyText>
<sectionHeader confidence="0.997831" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999959545454546">
In this paper, we propose a novel task – automatic
generation of topically relevant event chronicles.
It can serve as a new framework to combine the
merits of Information Retrieval, Information Ex-
traction and Summarization techniques, to rapidly
extract and rank salient events. This framework is
also able to rapidly and accurately capture a user’s
interest and needs based on the reference chronicle
(instead of keywords as in Information Retrieval
or event templates as in Guided Summarization)
which can reflect diverse levels of granularity.
As a preliminary study of this new challenge,
this paper focuses on event detection and rank-
ing. There are still many challenges for gener-
ating high-quality event chronicles. In the fu-
ture, we plan to investigate automatically adapt-
ing an event’s granularity and learn the principle
of summarizing the event according to the refer-
ence event chronicle. Moreover, we plan to study
the generation of entity-driven event chronicles,
leveraging more fine-grained entity and event ex-
traction approaches.
</bodyText>
<sectionHeader confidence="0.998136" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99960775">
We thank the anonymous reviewers for their
thought-provoking comments. This work is sup-
ported by National Key Basic Research Pro-
gram of China 2014CB340504, NSFC project
61375074, China Scholarship Council (CSC, No.
201406010174) and USA ARL NS-CTA No.
W911NF-09-2-0053. The contact author of this
paper is Zhifang Sui.
</bodyText>
<sectionHeader confidence="0.998757" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.945078333333333">
David Ahn. 2006. The stages of event extraction. In
Workshop on Annotating and Reasoning about Time
and Events.
</reference>
<page confidence="0.98932">
583
</page>
<reference confidence="0.998867561904762">
James Allan. 2002. Topic detection and tracking:
event-based information organization, volume 12.
Springer Science &amp; Business Media.
Steven Bethard. 2013. Cleartk-timeml: A minimalist
approach to tempeval 2013. In Second Joint Confer-
ence on Lexical and Computational Semantics.
Jeff A Bilmes. 1998. A gentle tutorial of the em algo-
rithm and its application to parameter estimation for
gaussian mixture and hidden markov models. Inter-
national Computer Science Institute, 4(510):126.
Nathanael Chambers and Dan Jurafsky. 2008. Jointly
combining implicit constraints improves temporal
ordering. In EMNLP.
Nathanael Chambers, Taylor Cassidy, Bill McDowell,
and Steven Bethard. 2014. Dense event ordering
with a multi-pass architecture. TACL, 2:273–284.
Nathanael Chambers. 2013. Navytime: Event and
time ordering from raw text. Technical report, DTIC
Document.
Chaitanya Chemudugunta and Padhraic Smyth Mark
Steyvers. 2007. Modeling general and specific as-
pects of documents with a probabilistic topic model.
In NIPS.
Zheng Chen and Heng Ji. 2009. Language specific is-
sue and feature exploration in chinese event extrac-
tion. In NAACL.
Chen Chen and Vincent Ng. 2012. Joint modeling for
chinese event extraction with rich linguistic features.
In COLING.
Quang Xuan Do, Wei Lu, and Dan Roth. 2012.
Joint inference for event timeline construction. In
EMNLP.
Tao Ge, Baobao Chang, Sujian Li, and Zhifang Sui.
2013. Event-based time label propagation for auto-
matic dating of news articles. In EMNLP.
David Graff, Junbo Kong, Ke Chen, and Kazuaki
Maeda. 2003. English gigaword. Linguistic Data
Consortium, Philadelphia.
Ralph Grishman, David Westbrook, and Adam Meyers.
2005. Nyu’s english ace 2005 system description.
In ACE 2005 Evaluation Workshop.
Qi He, Kuiyu Chang, and Ee-Peng Lim. 2007. Using
burstiness to improve clustering of topics in news
streams. In ICDM.
Yu Hong, Jianfeng Zhang, Bin Ma, Jian-Min Yao,
Guodong Zhou, and Qiaoming Zhu. 2011. Using
cross-entity inference to improve event extraction.
In ACL.
Po Hu, Minlie Huang, Peng Xu, Weichang Li, Adam K
Usadi, and Xiaoyan Zhu. 2011. Generating
breakpoint-based timeline overview for news topic
retrospection. In ICDM.
Apache Jakarta. 2004. Apache lucene-a high-
performance, full-featured text search engine li-
brary.
Heng Ji and Ralph Grishman. 2008. Refining event ex-
traction through cross-document inference. In ACL.
Heng Ji, Ralph Grishman, Zheng Chen, and Prashant
Gupta. 2009. Cross-document event extraction
and tracking: Task, evaluation, techniques and chal-
lenges. In RANLP.
Thorsten Joachims. 2006. Training linear svms in lin-
ear time. In SIGKDD.
Jon Kleinberg. 2003. Bursty and hierarchical structure
in streams. Data Mining and Knowledge Discovery,
7(4):373–397.
Jiwei Li and Claire Cardie. 2014. Timeline generation:
Tracking individuals on twitter. In WWW.
Jiwei Li and Sujian Li. 2013. Evolutionary hierarchi-
cal dirichlet process for timeline summarization. In
ACL.
Peifeng Li, Guodong Zhou, Qiaoming Zhu, and Libin
Hou. 2012. Employing compositional semantics
and discourse consistency in chinese event extrac-
tion. In EMNLP.
Qi Li, Heng Ji, and Liang Huang. 2013. Joint event
extraction via structured prediction with global fea-
tures. In ACL.
Shasha Liao and Ralph Grishman. 2010. Using doc-
ument level cross-event inference to improve event
extraction. In ACL.
Chen Lin, Chun Lin, Jingxuan Li, Dingding Wang,
Yang Chen, and Tao Li. 2012. Generating event
storylines from microblogs. In CIKM.
Christopher D Manning, Mihai Surdeanu, John Bauer,
Jenny Finkel, Steven J Bethard, and David Mc-
Closky. 2014. The stanford corenlp natural lan-
guage processing toolkit. In ACL System Demon-
strations.
Russell Swan and James Allan. 2000. Automatic gen-
eration of overview timelines. In SIGIR.
Naushad UzZaman, Hector Llorens, James Allen, Leon
Derczynski, Marc Verhagen, and James Pustejovsky.
2012. Tempeval-3: Evaluating events, time ex-
pressions, and temporal relations. arXiv preprint
arXiv:1206.5333.
Marc Verhagen, Inderjeet Mani, Roser Sauri, Robert
Knippen, Seok Bae Jang, Jessica Littman, Anna
Rumshisky, John Phillips, and James Pustejovsky.
2005. Automating temporal annotation with tarsqi.
In ACL demo.
Rui Yan, Xiaojun Wan, Jahna Otterbacher, Liang Kong,
Xiaoming Li, and Yan Zhang. 2011. Evolution-
ary timeline summarization: a balanced optimiza-
tion framework via iterative substitution. In SIGIR.
</reference>
<page confidence="0.986563">
584
</page>
<reference confidence="0.984196571428571">
Yiming Yang, Tom Pierce, and Jaime Carbonell. 1998.
A study of retrospective and on-line event detection.
In SIGIR.
Wayne Xin Zhao, Rishan Chen, Kai Fan, Hongfei Yan,
and Xiaoming Li. 2012. A novel burst-based text
representation model for scalable event detection. In
ACL.
</reference>
<page confidence="0.998736">
585
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.440041">
<title confidence="0.995205">Bring you to the past: Automatic Generation of Topically Relevant Event Chronicles</title>
<author confidence="0.989193">Wenzhe Heng Sujian Baobao Zhifang</author>
<affiliation confidence="0.9706175">Laboratory of Computational Linguistics, Ministry of School of EECS, Peking University, Beijing, 100871,</affiliation>
<address confidence="0.934095">Innovation Center for Language Ability, Xuzhou, Jiangsu, 221009, Science Department, Rensselaer Polytechnic Institute, Troy, NY 12180,</address>
<email confidence="0.6622585">getao@pku.edu.cn,wenzhepei@pku.edu.cn,lisujian@pku.edu.cn,chbb@pku.edu.cn,szf@pku.edu.cn</email>
<abstract confidence="0.993310733333333">An event chronicle provides people with an easy and fast access to learn the past. In this paper, we propose the first novel approach to automatically generate a topically relevant event chronicle during a certain period given a reference chronicle during another period. Our approach consists of two core components – a timeaware hierarchical Bayesian model for event detection, and a learning-to-rank model to select the salient events to construct the final chronicle. Experimental results demonstrate our approach is promising to tackle this new problem.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Ahn</author>
</authors>
<title>The stages of event extraction.</title>
<date>2006</date>
<booktitle>In Workshop on Annotating and Reasoning about Time and Events.</booktitle>
<contexts>
<context position="32618" citStr="Ahn, 2006" startWordPosition="5505" endWordPosition="5506"> relevant event chronicle generation work but there are some related tasks. Event detection, sometimes called topic detection (Allan, 2002), is an important part of our approach. Yang et al. (1998) used clustering techniques for event detection on news. He et al. (2007) and Zhao et al. (2012) designed burst feature representations for detecting bursty events. Compared with our TaHBM, these methods lack the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is re</context>
</contexts>
<marker>Ahn, 2006</marker>
<rawString>David Ahn. 2006. The stages of event extraction. In Workshop on Annotating and Reasoning about Time and Events.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Allan</author>
</authors>
<title>Topic detection and tracking: event-based information organization,</title>
<date>2002</date>
<volume>12</volume>
<publisher>Springer Science &amp; Business Media.</publisher>
<contexts>
<context position="32148" citStr="Allan, 2002" startWordPosition="5429" endWordPosition="5430">trast, the accuracy of political event time is the lowest. The reason is that some political events may be confidential and thus they are not reported as soon as they happen; on the other hand, some political events (e.g., a summit) are reported several days before the events happen. The comprehensive event chronicle includes many political events, which results in a lower accuracy. 6 Related Work To the best of our knowledge, there was no previous end-to-end topically relevant event chronicle generation work but there are some related tasks. Event detection, sometimes called topic detection (Allan, 2002), is an important part of our approach. Yang et al. (1998) used clustering techniques for event detection on news. He et al. (2007) and Zhao et al. (2012) designed burst feature representations for detecting bursty events. Compared with our TaHBM, these methods lack the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et </context>
</contexts>
<marker>Allan, 2002</marker>
<rawString>James Allan. 2002. Topic detection and tracking: event-based information organization, volume 12. Springer Science &amp; Business Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bethard</author>
</authors>
<title>Cleartk-timeml: A minimalist approach to tempeval 2013.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics.</booktitle>
<contexts>
<context position="33010" citStr="Bethard, 2013" startWordPosition="5574" endWordPosition="5575">hese methods lack the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document (Do et al., 2012), a centroid entity (Ji et al., 2009) or one major event (Hu et al., 2011; Yan et al., 2011; Lin et al., 2012; Li and Li, 2013). In addition, Li and Cardie (2014) generated timelines for users in microblogs. The most related work to ours is Swan and Allan (2000). They used a timeline to s</context>
</contexts>
<marker>Bethard, 2013</marker>
<rawString>Steven Bethard. 2013. Cleartk-timeml: A minimalist approach to tempeval 2013. In Second Joint Conference on Lexical and Computational Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff A Bilmes</author>
</authors>
<title>A gentle tutorial of the em algorithm and its application to parameter estimation for gaussian mixture and hidden markov models.</title>
<date>1998</date>
<journal>International Computer Science Institute,</journal>
<volume>4</volume>
<issue>510</issue>
<contexts>
<context position="15512" citStr="Bilmes, 1998" startWordPosition="2619" endWordPosition="2620">nal probability for sampling is computed as Eq (5): P(em|~e¬m,~z,~wm,~xm, tm, ε, βe, µe, σe) I czm, e + ε ×tm+1 pG(tm; µe, σe) Lee(czm,e + ε) m En-1 /� (ce,wm nw � (Ce,w (+ /tee) + n wm,n) + /tee )xm n Le (5) where pG(x; µ, σ) is a Gaussian probability mass function with parameter µ and σ. The function pG( ) can be seen as the temporal distribution of an event, as discussed before. In this sense, the temporal distribution of the whole corpus can be considered as a mixture of Gaussian distributions of events. As a natural way to estimate parameters of mixture of Gaussians, we use EM algorithm (Bilmes, 1998). In fact, Eq (5) can be seen as the E-step. The M-step of EM updates µ and σ as follows: where td is document d’s timestamp and De is the set of documents with event label e. Specially, for sampling e we use σ0 e defined as σ0e = σe + τ (τ is a small number for smoothing5) because when σ is very small (e.g., σ = 0), an event’s temporal scope will be strictly constrained. Using σ0 e can help the model overcome this “trap” for better parameter estimation. Above all, the model inference and parameter estimation procedure can be summarized by algorithm 1. 3.3 Learn Topic Preferences of the Event </context>
</contexts>
<marker>Bilmes, 1998</marker>
<rawString>Jeff A Bilmes. 1998. A gentle tutorial of the em algorithm and its application to parameter estimation for gaussian mixture and hidden markov models. International Computer Science Institute, 4(510):126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Jointly combining implicit constraints improves temporal ordering.</title>
<date>2008</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="32995" citStr="Chambers and Jurafsky, 2008" startWordPosition="5570" endWordPosition="5573">s. Compared with our TaHBM, these methods lack the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document (Do et al., 2012), a centroid entity (Ji et al., 2009) or one major event (Hu et al., 2011; Yan et al., 2011; Lin et al., 2012; Li and Li, 2013). In addition, Li and Cardie (2014) generated timelines for users in microblogs. The most related work to ours is Swan and Allan (2000). They used </context>
</contexts>
<marker>Chambers, Jurafsky, 2008</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2008. Jointly combining implicit constraints improves temporal ordering. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Taylor Cassidy</author>
<author>Bill McDowell</author>
<author>Steven Bethard</author>
</authors>
<title>Dense event ordering with a multi-pass architecture.</title>
<date>2014</date>
<tech>TACL,</tech>
<pages>2--273</pages>
<contexts>
<context position="33050" citStr="Chambers et al., 2014" startWordPosition="5578" endWordPosition="5581">f distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document (Do et al., 2012), a centroid entity (Ji et al., 2009) or one major event (Hu et al., 2011; Yan et al., 2011; Lin et al., 2012; Li and Li, 2013). In addition, Li and Cardie (2014) generated timelines for users in microblogs. The most related work to ours is Swan and Allan (2000). They used a timeline to show bursty events along the time, which </context>
</contexts>
<marker>Chambers, Cassidy, McDowell, Bethard, 2014</marker>
<rawString>Nathanael Chambers, Taylor Cassidy, Bill McDowell, and Steven Bethard. 2014. Dense event ordering with a multi-pass architecture. TACL, 2:273–284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
</authors>
<title>Navytime: Event and time ordering from raw text.</title>
<date>2013</date>
<tech>Technical report, DTIC Document.</tech>
<contexts>
<context position="33026" citStr="Chambers, 2013" startWordPosition="5576" endWordPosition="5577">ck the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document (Do et al., 2012), a centroid entity (Ji et al., 2009) or one major event (Hu et al., 2011; Yan et al., 2011; Lin et al., 2012; Li and Li, 2013). In addition, Li and Cardie (2014) generated timelines for users in microblogs. The most related work to ours is Swan and Allan (2000). They used a timeline to show bursty event</context>
</contexts>
<marker>Chambers, 2013</marker>
<rawString>Nathanael Chambers. 2013. Navytime: Event and time ordering from raw text. Technical report, DTIC Document.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chaitanya Chemudugunta</author>
<author>Padhraic Smyth Mark Steyvers</author>
</authors>
<title>Modeling general and specific aspects of documents with a probabilistic topic model.</title>
<date>2007</date>
<booktitle>In NIPS.</booktitle>
<marker>Chemudugunta, Steyvers, 2007</marker>
<rawString>Chaitanya Chemudugunta and Padhraic Smyth Mark Steyvers. 2007. Modeling general and specific aspects of documents with a probabilistic topic model. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Chen</author>
<author>Heng Ji</author>
</authors>
<title>Language specific issue and feature exploration in chinese event extraction.</title>
<date>2009</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="32660" citStr="Chen and Ji, 2009" startWordPosition="5511" endWordPosition="5514">on work but there are some related tasks. Event detection, sometimes called topic detection (Allan, 2002), is an important part of our approach. Yang et al. (1998) used clustering techniques for event detection on news. He et al. (2007) and Zhao et al. (2012) designed burst feature representations for detecting bursty events. Compared with our TaHBM, these methods lack the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focu</context>
</contexts>
<marker>Chen, Ji, 2009</marker>
<rawString>Zheng Chen and Heng Ji. 2009. Language specific issue and feature exploration in chinese event extraction. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Chen</author>
<author>Vincent Ng</author>
</authors>
<title>Joint modeling for chinese event extraction with rich linguistic features.</title>
<date>2012</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="32740" citStr="Chen and Ng, 2012" startWordPosition="5527" endWordPosition="5530">c detection (Allan, 2002), is an important part of our approach. Yang et al. (1998) used clustering techniques for event detection on news. He et al. (2007) and Zhao et al. (2012) designed burst feature representations for detecting bursty events. Compared with our TaHBM, these methods lack the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document (Do et al., 2012), a centroid entity</context>
</contexts>
<marker>Chen, Ng, 2012</marker>
<rawString>Chen Chen and Vincent Ng. 2012. Joint modeling for chinese event extraction with rich linguistic features. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quang Xuan Do</author>
<author>Wei Lu</author>
<author>Dan Roth</author>
</authors>
<title>Joint inference for event timeline construction.</title>
<date>2012</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="33321" citStr="Do et al., 2012" startWordPosition="5626" endWordPosition="5629"> Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document (Do et al., 2012), a centroid entity (Ji et al., 2009) or one major event (Hu et al., 2011; Yan et al., 2011; Lin et al., 2012; Li and Li, 2013). In addition, Li and Cardie (2014) generated timelines for users in microblogs. The most related work to ours is Swan and Allan (2000). They used a timeline to show bursty events along the time, which can be seen as an early form of event chronicles. Different from their work, we generate a topically relevant event chronicle based on a reference event chronicle. 7 Conclusions and Future Work In this paper, we propose a novel task – automatic generation of topically re</context>
</contexts>
<marker>Do, Lu, Roth, 2012</marker>
<rawString>Quang Xuan Do, Wei Lu, and Dan Roth. 2012. Joint inference for event timeline construction. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Ge</author>
<author>Baobao Chang</author>
<author>Sujian Li</author>
<author>Zhifang Sui</author>
</authors>
<title>Event-based time label propagation for automatic dating of news articles.</title>
<date>2013</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="30618" citStr="Ge et al., 2013" startWordPosition="5166" endWordPosition="5169"> in sports chronicles but it is not a good entry in comprehensive chronicles. Compared with comprehensive event chronicles, events in other chronicles tend to describe more details. For example, a sports chronicle may regard each match in the World Cup as an event while comprehensive chronicles consider the World Cup as one event, which requires us to adapt event granularity for different chronicles. Also, we evaluate the time of event entries in these five event chronicles because event’s happening time is not always equal to the timestamp of the document creation time (UzZaman et al., 2012; Ge et al., 2013). We collect existing manually edited 2010 chronicles on the web and use their event time as gold standard. We define a metric to evaluate if the event entry’s time in our chronicle is accurate: diff = �e∈E∩E∗ |(te − t* e)|/|E n E*| where E and E* are our chronicle and the manually edited event chronicle respectively. te is e’s 582 time labeled by our method and t∗e is e’s correct time. Note that for multiple entries referring the same event in event chronicles, the earliest entry’s time is used as the event’s time to compute diff. sports politics disaster war comprehensive 0.800 3.363 1.042 1</context>
</contexts>
<marker>Ge, Chang, Li, Sui, 2013</marker>
<rawString>Tao Ge, Baobao Chang, Sujian Li, and Zhifang Sui. 2013. Event-based time label propagation for automatic dating of news articles. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Graff</author>
<author>Junbo Kong</author>
<author>Ke Chen</author>
<author>Kazuaki Maeda</author>
</authors>
<date>2003</date>
<booktitle>English gigaword. Linguistic Data Consortium,</booktitle>
<location>Philadelphia.</location>
<contexts>
<context position="21265" citStr="Graff et al., 2003" startWordPosition="3653" endWordPosition="3656"> event with a long time span (e.g., σe Premier League), the number of relevant documents is large but its impact may not be profound. Hence, we use |De| σe to normalize |De|, which may better reflect the impact of e. 5 Experiments 5.1 Experiment Setting Data: We use various event chronicles during 2009 as references to generate their counterparts during 2010. Specifically, we collected disaster, sports, war, politics and comprehensive chronicles during 2009 from mapreport7, infoplease and Wikipedia8. To generate chronicles during 2010, we use 2009-2010 APW and Xinhua news in English Gigaword (Graff et al., 2003) and remove documents whose titles and first paragraphs do not include any burst words. We detect burst words using Kleinberg algorithm (Kleinberg, 2003), which is a 2-state finite automaton model and widely used to detect bursts. In total, there are 140,557 documents in the corpus. Preprocessing: We remove stopwords and use Stanford CoreNLP (Manning et al., 2014) to do lemmatization. Parameter setting: For TaHBM, we empirically set α = 0.05, Qz = 0.005, Qe = 0.0001, ryg = 0.05, ryx = 0.5, ε = 0.01, the number of topics K = 50, and the number of events E = 5000. We run Gibbs sampler for 2000 i</context>
</contexts>
<marker>Graff, Kong, Chen, Maeda, 2003</marker>
<rawString>David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. 2003. English gigaword. Linguistic Data Consortium, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
<author>David Westbrook</author>
<author>Adam Meyers</author>
</authors>
<title>Nyu’s english ace 2005 system description.</title>
<date>2005</date>
<booktitle>In ACE 2005 Evaluation Workshop.</booktitle>
<contexts>
<context position="32607" citStr="Grishman et al., 2005" startWordPosition="5501" endWordPosition="5504">us end-to-end topically relevant event chronicle generation work but there are some related tasks. Event detection, sometimes called topic detection (Allan, 2002), is an important part of our approach. Yang et al. (1998) used clustering techniques for event detection on news. He et al. (2007) and Zhao et al. (2012) designed burst feature representations for detecting bursty events. Compared with our TaHBM, these methods lack the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline gener</context>
</contexts>
<marker>Grishman, Westbrook, Meyers, 2005</marker>
<rawString>Ralph Grishman, David Westbrook, and Adam Meyers. 2005. Nyu’s english ace 2005 system description. In ACE 2005 Evaluation Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi He</author>
<author>Kuiyu Chang</author>
<author>Ee-Peng Lim</author>
</authors>
<title>Using burstiness to improve clustering of topics in news streams.</title>
<date>2007</date>
<booktitle>In ICDM.</booktitle>
<contexts>
<context position="32279" citStr="He et al. (2007)" startWordPosition="5452" endWordPosition="5455">s they are not reported as soon as they happen; on the other hand, some political events (e.g., a summit) are reported several days before the events happen. The comprehensive event chronicle includes many political events, which results in a lower accuracy. 6 Related Work To the best of our knowledge, there was no previous end-to-end topically relevant event chronicle generation work but there are some related tasks. Event detection, sometimes called topic detection (Allan, 2002), is an important part of our approach. Yang et al. (1998) used clustering techniques for event detection on news. He et al. (2007) and Zhao et al. (2012) designed burst feature representations for detecting bursty events. Compared with our TaHBM, these methods lack the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in m</context>
</contexts>
<marker>He, Chang, Lim, 2007</marker>
<rawString>Qi He, Kuiyu Chang, and Ee-Peng Lim. 2007. Using burstiness to improve clustering of topics in news streams. In ICDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yu Hong</author>
<author>Jianfeng Zhang</author>
<author>Bin Ma</author>
<author>Jian-Min Yao</author>
<author>Guodong Zhou</author>
<author>Qiaoming Zhu</author>
</authors>
<title>Using cross-entity inference to improve event extraction.</title>
<date>2011</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="32704" citStr="Hong et al., 2011" startWordPosition="5519" endWordPosition="5522">ent detection, sometimes called topic detection (Allan, 2002), is an important part of our approach. Yang et al. (1998) used clustering techniques for event detection on news. He et al. (2007) and Zhao et al. (2012) designed burst feature representations for detecting bursty events. Compared with our TaHBM, these methods lack the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document </context>
</contexts>
<marker>Hong, Zhang, Ma, Yao, Zhou, Zhu, 2011</marker>
<rawString>Yu Hong, Jianfeng Zhang, Bin Ma, Jian-Min Yao, Guodong Zhou, and Qiaoming Zhu. 2011. Using cross-entity inference to improve event extraction. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Po Hu</author>
<author>Minlie Huang</author>
<author>Peng Xu</author>
<author>Weichang Li</author>
<author>Adam K Usadi</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Generating breakpoint-based timeline overview for news topic retrospection.</title>
<date>2011</date>
<booktitle>In ICDM.</booktitle>
<contexts>
<context position="33394" citStr="Hu et al., 2011" startWordPosition="5641" endWordPosition="5644">Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document (Do et al., 2012), a centroid entity (Ji et al., 2009) or one major event (Hu et al., 2011; Yan et al., 2011; Lin et al., 2012; Li and Li, 2013). In addition, Li and Cardie (2014) generated timelines for users in microblogs. The most related work to ours is Swan and Allan (2000). They used a timeline to show bursty events along the time, which can be seen as an early form of event chronicles. Different from their work, we generate a topically relevant event chronicle based on a reference event chronicle. 7 Conclusions and Future Work In this paper, we propose a novel task – automatic generation of topically relevant event chronicles. It can serve as a new framework to combine the m</context>
</contexts>
<marker>Hu, Huang, Xu, Li, Usadi, Zhu, 2011</marker>
<rawString>Po Hu, Minlie Huang, Peng Xu, Weichang Li, Adam K Usadi, and Xiaoyan Zhu. 2011. Generating breakpoint-based timeline overview for news topic retrospection. In ICDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Apache Jakarta</author>
</authors>
<title>Apache lucene-a highperformance, full-featured text search engine library.</title>
<date>2004</date>
<contexts>
<context position="17383" citStr="Jakarta, 2004" startWordPosition="2968" endWordPosition="2969">for each event e do 12: update µe, σe according to Eq (6) 13: end for 14: end for them in an unsupervised manner; instead, we provide TaHBM some “supervision”. As we mentioned in section 3.2, the variable s indicates a document’s topical relevance to the event chronicle. For some documents, s label can be easily derived with high accuracy so that we can exploit the information to learn the topic preferences. To obtain the labeled data, we use the description of each event entry in the reference chronicle ER during period AR as a query to retrieve relevant documents in the corpus using Lucene (Jakarta, 2004) which is an information retrieval software library. We define R as the set of documents in hits of any event entry in the reference chronicle returned by Lucene: R = Ue∈ERHit(e) where Hit(e) is the complete hit list of event e returned by Lucene. For document d with timestamp td, if d E/ R and td E AR, then d is considered irrelevant to the event chronicle and thus it would be labeled as a negative example. To generate positive examples, we use a strict criterion since we cannot guarantee that all the documents in R are actually relevant. To precisely generate positive examples, a document d </context>
</contexts>
<marker>Jakarta, 2004</marker>
<rawString>Apache Jakarta. 2004. Apache lucene-a highperformance, full-featured text search engine library.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
</authors>
<title>Refining event extraction through cross-document inference.</title>
<date>2008</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="32641" citStr="Ji and Grishman, 2008" startWordPosition="5507" endWordPosition="5510">vent chronicle generation work but there are some related tasks. Event detection, sometimes called topic detection (Allan, 2002), is an important part of our approach. Yang et al. (1998) used clustering techniques for event detection on news. He et al. (2007) and Zhao et al. (2012) designed burst feature representations for detecting bursty events. Compared with our TaHBM, these methods lack the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most</context>
</contexts>
<marker>Ji, Grishman, 2008</marker>
<rawString>Heng Ji and Ralph Grishman. 2008. Refining event extraction through cross-document inference. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>Zheng Chen</author>
<author>Prashant Gupta</author>
</authors>
<title>Cross-document event extraction and tracking: Task, evaluation, techniques and challenges.</title>
<date>2009</date>
<booktitle>In RANLP.</booktitle>
<contexts>
<context position="33358" citStr="Ji et al., 2009" startWordPosition="5633" endWordPosition="5636">Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document (Do et al., 2012), a centroid entity (Ji et al., 2009) or one major event (Hu et al., 2011; Yan et al., 2011; Lin et al., 2012; Li and Li, 2013). In addition, Li and Cardie (2014) generated timelines for users in microblogs. The most related work to ours is Swan and Allan (2000). They used a timeline to show bursty events along the time, which can be seen as an early form of event chronicles. Different from their work, we generate a topically relevant event chronicle based on a reference event chronicle. 7 Conclusions and Future Work In this paper, we propose a novel task – automatic generation of topically relevant event chronicles. It can serve</context>
</contexts>
<marker>Ji, Grishman, Chen, Gupta, 2009</marker>
<rawString>Heng Ji, Ralph Grishman, Zheng Chen, and Prashant Gupta. 2009. Cross-document event extraction and tracking: Task, evaluation, techniques and challenges. In RANLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Training linear svms in linear time.</title>
<date>2006</date>
<booktitle>In SIGKDD.</booktitle>
<contexts>
<context position="19366" citStr="Joachims, 2006" startWordPosition="3330" endWordPosition="3331">manner, TaHBM can learn topic preferences (i.e., P(z|s)) without any manually labeled data and thus can measure the topical relevance between an event and the reference chronicle. 4 Event Ranking Generating an event chronicle is beyond event detection because we cannot use all detected events to generate the chronicle with a limited number of entries. We propose to use learning-to-rank techniques to select the most salient events to generate the final chronicle since we believe the reference event chronicle can teach us the principles of selecting salient events. Specifically, we use SVMRank (Joachims, 2006). 4.1 Training and Test Set Generation The event detection component returns many document clusters, each of which represents an event. As Section 3.2 shows, each event has a Gaussian distribution whose mean indicates its burst time in TaHBM. We use the events whose burst time is during the reference chronicle’s period as training examples and treat those during the target chronicle’s period as test examples. Formally, the training set and test set are defined as follows: Train = {e|µe E AR}, Test = {e|µe E AT} In the training set, events containing at least one positive document (i.e. relevan</context>
</contexts>
<marker>Joachims, 2006</marker>
<rawString>Thorsten Joachims. 2006. Training linear svms in linear time. In SIGKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Kleinberg</author>
</authors>
<title>Bursty and hierarchical structure in streams.</title>
<date>2003</date>
<journal>Data Mining and Knowledge Discovery,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="21418" citStr="Kleinberg, 2003" startWordPosition="3679" endWordPosition="3680">to normalize |De|, which may better reflect the impact of e. 5 Experiments 5.1 Experiment Setting Data: We use various event chronicles during 2009 as references to generate their counterparts during 2010. Specifically, we collected disaster, sports, war, politics and comprehensive chronicles during 2009 from mapreport7, infoplease and Wikipedia8. To generate chronicles during 2010, we use 2009-2010 APW and Xinhua news in English Gigaword (Graff et al., 2003) and remove documents whose titles and first paragraphs do not include any burst words. We detect burst words using Kleinberg algorithm (Kleinberg, 2003), which is a 2-state finite automaton model and widely used to detect bursts. In total, there are 140,557 documents in the corpus. Preprocessing: We remove stopwords and use Stanford CoreNLP (Manning et al., 2014) to do lemmatization. Parameter setting: For TaHBM, we empirically set α = 0.05, Qz = 0.005, Qe = 0.0001, ryg = 0.05, ryx = 0.5, ε = 0.01, the number of topics K = 50, and the number of events E = 5000. We run Gibbs sampler for 2000 iterations with burn-in period of 500 for inference. For event ranking, we set regularization parameter of SVMRank c = 0.1. Chronicle display: We use a he</context>
</contexts>
<marker>Kleinberg, 2003</marker>
<rawString>Jon Kleinberg. 2003. Bursty and hierarchical structure in streams. Data Mining and Knowledge Discovery, 7(4):373–397.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiwei Li</author>
<author>Claire Cardie</author>
</authors>
<title>Timeline generation: Tracking individuals on twitter.</title>
<date>2014</date>
<booktitle>In WWW.</booktitle>
<contexts>
<context position="33483" citStr="Li and Cardie (2014)" startWordPosition="5659" endWordPosition="5662"> events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document (Do et al., 2012), a centroid entity (Ji et al., 2009) or one major event (Hu et al., 2011; Yan et al., 2011; Lin et al., 2012; Li and Li, 2013). In addition, Li and Cardie (2014) generated timelines for users in microblogs. The most related work to ours is Swan and Allan (2000). They used a timeline to show bursty events along the time, which can be seen as an early form of event chronicles. Different from their work, we generate a topically relevant event chronicle based on a reference event chronicle. 7 Conclusions and Future Work In this paper, we propose a novel task – automatic generation of topically relevant event chronicles. It can serve as a new framework to combine the merits of Information Retrieval, Information Extraction and Summarization techniques, to r</context>
</contexts>
<marker>Li, Cardie, 2014</marker>
<rawString>Jiwei Li and Claire Cardie. 2014. Timeline generation: Tracking individuals on twitter. In WWW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiwei Li</author>
<author>Sujian Li</author>
</authors>
<title>Evolutionary hierarchical dirichlet process for timeline summarization.</title>
<date>2013</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="33448" citStr="Li and Li, 2013" startWordPosition="5653" endWordPosition="5656">only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document (Do et al., 2012), a centroid entity (Ji et al., 2009) or one major event (Hu et al., 2011; Yan et al., 2011; Lin et al., 2012; Li and Li, 2013). In addition, Li and Cardie (2014) generated timelines for users in microblogs. The most related work to ours is Swan and Allan (2000). They used a timeline to show bursty events along the time, which can be seen as an early form of event chronicles. Different from their work, we generate a topically relevant event chronicle based on a reference event chronicle. 7 Conclusions and Future Work In this paper, we propose a novel task – automatic generation of topically relevant event chronicles. It can serve as a new framework to combine the merits of Information Retrieval, Information Extraction</context>
</contexts>
<marker>Li, Li, 2013</marker>
<rawString>Jiwei Li and Sujian Li. 2013. Evolutionary hierarchical dirichlet process for timeline summarization. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peifeng Li</author>
<author>Guodong Zhou</author>
<author>Qiaoming Zhu</author>
<author>Libin Hou</author>
</authors>
<title>Employing compositional semantics and discourse consistency in chinese event extraction.</title>
<date>2012</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="32721" citStr="Li et al., 2012" startWordPosition="5523" endWordPosition="5526">times called topic detection (Allan, 2002), is an important part of our approach. Yang et al. (1998) used clustering techniques for event detection on news. He et al. (2007) and Zhao et al. (2012) designed burst feature representations for detecting bursty events. Compared with our TaHBM, these methods lack the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document (Do et al., 2012)</context>
</contexts>
<marker>Li, Zhou, Zhu, Hou, 2012</marker>
<rawString>Peifeng Li, Guodong Zhou, Qiaoming Zhu, and Libin Hou. 2012. Employing compositional semantics and discourse consistency in chinese event extraction. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Li</author>
<author>Heng Ji</author>
<author>Liang Huang</author>
</authors>
<title>Joint event extraction via structured prediction with global features.</title>
<date>2013</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="32758" citStr="Li et al., 2013" startWordPosition="5531" endWordPosition="5534"> 2002), is an important part of our approach. Yang et al. (1998) used clustering techniques for event detection on news. He et al. (2007) and Zhao et al. (2012) designed burst feature representations for detecting bursty events. Compared with our TaHBM, these methods lack the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document (Do et al., 2012), a centroid entity (Ji et al., 2009)</context>
</contexts>
<marker>Li, Ji, Huang, 2013</marker>
<rawString>Qi Li, Heng Ji, and Liang Huang. 2013. Joint event extraction via structured prediction with global features. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shasha Liao</author>
<author>Ralph Grishman</author>
</authors>
<title>Using document level cross-event inference to improve event extraction.</title>
<date>2010</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="32685" citStr="Liao and Grishman, 2010" startWordPosition="5515" endWordPosition="5518">re some related tasks. Event detection, sometimes called topic detection (Allan, 2002), is an important part of our approach. Yang et al. (1998) used clustering techniques for event detection on news. He et al. (2007) and Zhao et al. (2012) designed burst feature representations for detecting bursty events. Compared with our TaHBM, these methods lack the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timel</context>
</contexts>
<marker>Liao, Grishman, 2010</marker>
<rawString>Shasha Liao and Ralph Grishman. 2010. Using document level cross-event inference to improve event extraction. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Lin</author>
<author>Chun Lin</author>
<author>Jingxuan Li</author>
<author>Dingding Wang</author>
<author>Yang Chen</author>
<author>Tao Li</author>
</authors>
<title>Generating event storylines from microblogs.</title>
<date>2012</date>
<booktitle>In CIKM.</booktitle>
<contexts>
<context position="33430" citStr="Lin et al., 2012" startWordPosition="5649" endWordPosition="5652">program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document (Do et al., 2012), a centroid entity (Ji et al., 2009) or one major event (Hu et al., 2011; Yan et al., 2011; Lin et al., 2012; Li and Li, 2013). In addition, Li and Cardie (2014) generated timelines for users in microblogs. The most related work to ours is Swan and Allan (2000). They used a timeline to show bursty events along the time, which can be seen as an early form of event chronicles. Different from their work, we generate a topically relevant event chronicle based on a reference event chronicle. 7 Conclusions and Future Work In this paper, we propose a novel task – automatic generation of topically relevant event chronicles. It can serve as a new framework to combine the merits of Information Retrieval, Info</context>
</contexts>
<marker>Lin, Lin, Li, Wang, Chen, Li, 2012</marker>
<rawString>Chen Lin, Chun Lin, Jingxuan Li, Dingding Wang, Yang Chen, and Tao Li. 2012. Generating event storylines from microblogs. In CIKM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Mihai Surdeanu</author>
<author>John Bauer</author>
<author>Jenny Finkel</author>
<author>Steven J Bethard</author>
<author>David McClosky</author>
</authors>
<title>The stanford corenlp natural language processing toolkit.</title>
<date>2014</date>
<booktitle>In ACL System Demonstrations.</booktitle>
<contexts>
<context position="21631" citStr="Manning et al., 2014" startWordPosition="3711" endWordPosition="3714">ecifically, we collected disaster, sports, war, politics and comprehensive chronicles during 2009 from mapreport7, infoplease and Wikipedia8. To generate chronicles during 2010, we use 2009-2010 APW and Xinhua news in English Gigaword (Graff et al., 2003) and remove documents whose titles and first paragraphs do not include any burst words. We detect burst words using Kleinberg algorithm (Kleinberg, 2003), which is a 2-state finite automaton model and widely used to detect bursts. In total, there are 140,557 documents in the corpus. Preprocessing: We remove stopwords and use Stanford CoreNLP (Manning et al., 2014) to do lemmatization. Parameter setting: For TaHBM, we empirically set α = 0.05, Qz = 0.005, Qe = 0.0001, ryg = 0.05, ryx = 0.5, ε = 0.01, the number of topics K = 50, and the number of events E = 5000. We run Gibbs sampler for 2000 iterations with burn-in period of 500 for inference. For event ranking, we set regularization parameter of SVMRank c = 0.1. Chronicle display: We use a heuristic way to generate the description of each event. Since the first paragraph of a news article is usually a good summary of the article and the earliest document in a cluster usually explicitly describes the e</context>
</contexts>
<marker>Manning, Surdeanu, Bauer, Finkel, Bethard, McClosky, 2014</marker>
<rawString>Christopher D Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J Bethard, and David McClosky. 2014. The stanford corenlp natural language processing toolkit. In ACL System Demonstrations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Russell Swan</author>
<author>James Allan</author>
</authors>
<title>Automatic generation of overview timelines.</title>
<date>2000</date>
<booktitle>In SIGIR.</booktitle>
<contexts>
<context position="33583" citStr="Swan and Allan (2000)" startWordPosition="5677" endWordPosition="5680">2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document (Do et al., 2012), a centroid entity (Ji et al., 2009) or one major event (Hu et al., 2011; Yan et al., 2011; Lin et al., 2012; Li and Li, 2013). In addition, Li and Cardie (2014) generated timelines for users in microblogs. The most related work to ours is Swan and Allan (2000). They used a timeline to show bursty events along the time, which can be seen as an early form of event chronicles. Different from their work, we generate a topically relevant event chronicle based on a reference event chronicle. 7 Conclusions and Future Work In this paper, we propose a novel task – automatic generation of topically relevant event chronicles. It can serve as a new framework to combine the merits of Information Retrieval, Information Extraction and Summarization techniques, to rapidly extract and rank salient events. This framework is also able to rapidly and accurately captur</context>
</contexts>
<marker>Swan, Allan, 2000</marker>
<rawString>Russell Swan and James Allan. 2000. Automatic generation of overview timelines. In SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naushad UzZaman</author>
<author>Hector Llorens</author>
<author>James Allen</author>
<author>Leon Derczynski</author>
<author>Marc Verhagen</author>
<author>James Pustejovsky</author>
</authors>
<title>Tempeval-3: Evaluating events, time expressions, and temporal relations. arXiv preprint arXiv:1206.5333.</title>
<date>2012</date>
<contexts>
<context position="30600" citStr="UzZaman et al., 2012" startWordPosition="5162" endWordPosition="5165"> a correct event entry in sports chronicles but it is not a good entry in comprehensive chronicles. Compared with comprehensive event chronicles, events in other chronicles tend to describe more details. For example, a sports chronicle may regard each match in the World Cup as an event while comprehensive chronicles consider the World Cup as one event, which requires us to adapt event granularity for different chronicles. Also, we evaluate the time of event entries in these five event chronicles because event’s happening time is not always equal to the timestamp of the document creation time (UzZaman et al., 2012; Ge et al., 2013). We collect existing manually edited 2010 chronicles on the web and use their event time as gold standard. We define a metric to evaluate if the event entry’s time in our chronicle is accurate: diff = �e∈E∩E∗ |(te − t* e)|/|E n E*| where E and E* are our chronicle and the manually edited event chronicle respectively. te is e’s 582 time labeled by our method and t∗e is e’s correct time. Note that for multiple entries referring the same event in event chronicles, the earliest entry’s time is used as the event’s time to compute diff. sports politics disaster war comprehensive 0</context>
</contexts>
<marker>UzZaman, Llorens, Allen, Derczynski, Verhagen, Pustejovsky, 2012</marker>
<rawString>Naushad UzZaman, Hector Llorens, James Allen, Leon Derczynski, Marc Verhagen, and James Pustejovsky. 2012. Tempeval-3: Evaluating events, time expressions, and temporal relations. arXiv preprint arXiv:1206.5333.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Inderjeet Mani</author>
<author>Roser Sauri</author>
<author>Robert Knippen</author>
</authors>
<title>Automating temporal annotation with tarsqi.</title>
<date>2005</date>
<booktitle>In ACL demo.</booktitle>
<location>Seok Bae Jang, Jessica Littman, Anna Rumshisky, John Phillips, and</location>
<contexts>
<context position="32966" citStr="Verhagen et al., 2005" startWordPosition="5566" endWordPosition="5569"> detecting bursty events. Compared with our TaHBM, these methods lack the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document (Do et al., 2012), a centroid entity (Ji et al., 2009) or one major event (Hu et al., 2011; Yan et al., 2011; Lin et al., 2012; Li and Li, 2013). In addition, Li and Cardie (2014) generated timelines for users in microblogs. The most related work to ours is Swan</context>
</contexts>
<marker>Verhagen, Mani, Sauri, Knippen, 2005</marker>
<rawString>Marc Verhagen, Inderjeet Mani, Roser Sauri, Robert Knippen, Seok Bae Jang, Jessica Littman, Anna Rumshisky, John Phillips, and James Pustejovsky. 2005. Automating temporal annotation with tarsqi. In ACL demo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Yan</author>
<author>Xiaojun Wan</author>
<author>Jahna Otterbacher</author>
<author>Liang Kong</author>
<author>Xiaoming Li</author>
<author>Yan Zhang</author>
</authors>
<title>Evolutionary timeline summarization: a balanced optimization framework via iterative substitution.</title>
<date>2011</date>
<booktitle>In SIGIR.</booktitle>
<contexts>
<context position="33412" citStr="Yan et al., 2011" startWordPosition="5645" endWordPosition="5648"> Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than those in our task. Moreover, there was work (Verhagen et al., 2005; Chambers and Jurafsky, 2008; Bethard, 2013; Chambers, 2013; Chambers et al., 2014) about temporal event extraction and tracking. Like ACE, the granularity of events in this task is too fine to be suitable for our task. Also, timeline generation is related to our work. Most previous work focused on generating a timeline for a document (Do et al., 2012), a centroid entity (Ji et al., 2009) or one major event (Hu et al., 2011; Yan et al., 2011; Lin et al., 2012; Li and Li, 2013). In addition, Li and Cardie (2014) generated timelines for users in microblogs. The most related work to ours is Swan and Allan (2000). They used a timeline to show bursty events along the time, which can be seen as an early form of event chronicles. Different from their work, we generate a topically relevant event chronicle based on a reference event chronicle. 7 Conclusions and Future Work In this paper, we propose a novel task – automatic generation of topically relevant event chronicles. It can serve as a new framework to combine the merits of Informati</context>
</contexts>
<marker>Yan, Wan, Otterbacher, Kong, Li, Zhang, 2011</marker>
<rawString>Rui Yan, Xiaojun Wan, Jahna Otterbacher, Liang Kong, Xiaoming Li, and Yan Zhang. 2011. Evolutionary timeline summarization: a balanced optimization framework via iterative substitution. In SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yiming Yang</author>
<author>Tom Pierce</author>
<author>Jaime Carbonell</author>
</authors>
<title>A study of retrospective and on-line event detection.</title>
<date>1998</date>
<booktitle>In SIGIR.</booktitle>
<contexts>
<context position="32206" citStr="Yang et al. (1998)" startWordPosition="5439" endWordPosition="5442">owest. The reason is that some political events may be confidential and thus they are not reported as soon as they happen; on the other hand, some political events (e.g., a summit) are reported several days before the events happen. The comprehensive event chronicle includes many political events, which results in a lower accuracy. 6 Related Work To the best of our knowledge, there was no previous end-to-end topically relevant event chronicle generation work but there are some related tasks. Event detection, sometimes called topic detection (Allan, 2002), is an important part of our approach. Yang et al. (1998) used clustering techniques for event detection on news. He et al. (2007) and Zhao et al. (2012) designed burst feature representations for detecting bursty events. Compared with our TaHBM, these methods lack the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extractio</context>
</contexts>
<marker>Yang, Pierce, Carbonell, 1998</marker>
<rawString>Yiming Yang, Tom Pierce, and Jaime Carbonell. 1998. A study of retrospective and on-line event detection. In SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wayne Xin Zhao</author>
<author>Rishan Chen</author>
<author>Kai Fan</author>
<author>Hongfei Yan</author>
<author>Xiaoming Li</author>
</authors>
<title>A novel burst-based text representation model for scalable event detection.</title>
<date>2012</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="24586" citStr="Zhao et al., 2012" startWordPosition="4199" endWordPosition="4202">se detection models, we use a criterion that considers both relevance and importance to rank events: �rankscorebasic(e) = maze/EERsim(d, e&apos;) dEDe where ER is the reference chronicle and sim(d, e&apos;) is Lucene’s score of document d given query e&apos;. We call this ranking criterion as basic criterion. • Random: We randomly select k documents to generate the chronicle. • NB+basic: Since TaHBM is essentially an extension of NB, we use Naive Bayes (NB) to detect events and basic ranking criterion to rank events. • B-HAC+basic: We use hierarchical agglomerative clustering (HAC) based on BurstVSM schema (Zhao et al., 2012) to detect events, which is the state-of-the-art event detection method for general domains. • TaHBM+basic: we use this baseline to verify the effectiveness of learning-to-rank. As TaHBM, the number of clusters in NB is set to 5000 for comparison. For B-HAC, we adopt the same setting with (Zhao et al., 2012). 5.3 Experiment Results Using the evaluation method introduced above, we can conduct a quantitative evaluation for event chronicle generation approaches9. Table 1 shows the overall performance. Our approach outperforms the baselines for all chronicles. TaHBM beats other detection models fo</context>
<context position="32302" citStr="Zhao et al. (2012)" startWordPosition="5457" endWordPosition="5460">ed as soon as they happen; on the other hand, some political events (e.g., a summit) are reported several days before the events happen. The comprehensive event chronicle includes many political events, which results in a lower accuracy. 6 Related Work To the best of our knowledge, there was no previous end-to-end topically relevant event chronicle generation work but there are some related tasks. Event detection, sometimes called topic detection (Allan, 2002), is an important part of our approach. Yang et al. (1998) used clustering techniques for event detection on news. He et al. (2007) and Zhao et al. (2012) designed burst feature representations for detecting bursty events. Compared with our TaHBM, these methods lack the ability of distinguishing similar events. Similar to event detection, event extraction focuses on finding events from documents. Most work regarding event extraction (Grishman et al., 2005; Ahn, 2006; Ji and Grishman, 2008; Chen and Ji, 2009; Liao and Grishman, 2010; Hong et al., 2011; Li et al., 2012; Chen and Ng, 2012; Li et al., 2013) was developed under Automatic Content Extraction (ACE) program. The task only defines 33 event types and events are in much finer grain than th</context>
</contexts>
<marker>Zhao, Chen, Fan, Yan, Li, 2012</marker>
<rawString>Wayne Xin Zhao, Rishan Chen, Kai Fan, Hongfei Yan, and Xiaoming Li. 2012. A novel burst-based text representation model for scalable event detection. In ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>