<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<sectionHeader confidence="0.837055" genericHeader="method">
A HARDWARE ALGORITHM
FOR HIGH SPEED MORPHEME EXTRACTION
AND ITS IMPLEMENTATION
</sectionHeader>
<author confidence="0.620382">
Toshikazu Fukushima, Yutaka Ohyama and ilitoshi Miyai
</author>
<affiliation confidence="0.536064">
C&amp;C Systems Research Laboratories, NEC Corporation
</affiliation>
<address confidence="0.70863">
1-1, Miyazaki 4-chome, Miyamae-ku, Kawasaki City, Kanagawa 213, Japan
</address>
<email confidence="0.386224">
(fukuOtsl.cl.nec.cojp, ohyamatitsl.cl.nec.co.jp, miyaOtsl.cl. nec .c ojp)
</email>
<sectionHeader confidence="0.832885" genericHeader="method">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999752866666667">
This paper describes a new hardware algorithm
for morpheme extraction and its implementation
on a. specific machine (MEX-./), as the first step
toward achieving natural language parsing accel-
erators. It also shows the machine&apos;s performance,
100-1,000 times faster than a personal computer.
This machine can extract morphemes from 10,000
character Japanese text by searching an 80,000
morpheme dictionary in 1 second. It can treat
multiple text streams, which are composed of char-
acter candidates, as well as one text stream. The
algorithm is implemented on the machine in linear
time for the number of candidates, while conven-
tional sequential algorithms are implemented in
combinational time.
</bodyText>
<sectionHeader confidence="0.997551" genericHeader="method">
I. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.99849788">
Recent advancement in natural language pars-
ing technology has especially extended the word
processor market and the machine translation sys-
tem market. For further market extension or new
market creation for natural lang-uage applications,
parsing speed-up as well as improving parsing ac-
curacy is required. First, the parsing speed-up
directly reduces system response time required in
such interactive natural language application sys-
tems as those using natural language interface,
speech recognition, Kana-to-Kanji conversion,
which is the most popular Japanese text input
method, and so on. Second, it also increases the
advantage of such applications as machine transla-
tion, document proofreading, automatic indexing,
and so on, which are used to treat a large amount
of documents. Third, it realizes parsing meth-
ods based on larger scale dictionary or knowledge
database, which are necessary to improve parsing
accuracy.
Until now, in the natural language processing
field, the speed-up has depended mainly on perfor-
mance improvements achieved in sequential pro-
cessing computers and the development of sequen-
tial algorithms. Recently, because of the further
</bodyText>
<tableCaption confidence="0.501636">
&apos;Karla characters are combined consonant and vowel
symbols used in written Japanese. Kanji characters are
Chinese ideographs.
</tableCaption>
<bodyText confidence="0.999450111111111">
speeded-up requirement, parallel processing com-
puters have been designed and parallel parsing al-
gorithms (Matsumoto, 1986) (Haas, 1987) (Ryt-
ter, 1987) (Fukushima, 1990b) have been pro-
posed. However, there are many difficult problems
blocking efficient practical use of parallel process-
ing computers. One of the problems is that ac-
cess conflicts occur when several processors read
or write a common memory simultaneously. An-
other is the bottle-neck problem, wherein commt-
nication between any two processors is restricted,
because of hardware scale limitation.
On the other hand, in the pattern processing
field, various kinds of accelerator hardware have
been developed. They are designed for a special
purpose, not for general purposes. A hardware
approach hasn&apos;t been tried in the natural language
processing field yet.
The authors propose developing natural lan-
guage parsing accelerators, a hardware approach
to the parsing speed-up (Fukushima, 1989b)
(Fukushima, 1990a). This paper describes a new
hardware algorithm for high speed morpheme ex-
traction and its implementation on a. specific ma-
chine. This morpheme extraction machine is de-
signed as the first step toward achieving the nat-
ural language parsing accelerators.
</bodyText>
<sectionHeader confidence="0.999655" genericHeader="method">
2 MACHINE DESIGN
STRATEGY
</sectionHeader>
<subsectionHeader confidence="0.987099">
2.1 MORPHEME EXTRACTION
</subsectionHeader>
<bodyText confidence="0.99911175">
Morphological analysis methods are generally
composed of two processes: (1) a morpheme ex-
traction process and (2) a morpheme determina-
tion process. In process (1), all morphemes, which
are considered as probably being used to construct
input text, are extracted by searching a. morpheme
dictionary. These morphemes are extracted as
candidates. Therefore, they are selected mainly
by morpheme conjunction constraint. Morphemes
which actually construct the text are determined
in process (2).
The authors selected morpheme extraction as
the first process to be implemented on specific
hardware, for the following three reasons. First
is that the speed-up requirement for the morpho-
logical analysis process is very strong in Japanese
</bodyText>
<page confidence="0.991131">
307
</page>
<figure confidence="0.9995649375">
Extracted
Morphemes
verb
noun
Pfi suffix
Pfin. noun
Input Text
iffM.R.4-`11-
(Morpheme Extraction 44.
Process
Morpheme Dictionary
postposition
----- suffix
ffERM verb
noun
noun
</figure>
<figureCaption confidence="0.9102015">
Figure 1: Morpheme Extraction Process for
Japanese Text
</figureCaption>
<subsectionHeader confidence="0.982345">
2.2 STRATEGY DISCUSSION
</subsectionHeader>
<bodyText confidence="0.996307283333333">
In conventional morpheme extraction methods,
which are the software methods used on sequential
processing computers, the comparison operation
between one key string in the morpheme dictio-
nary and one sub-string of input text is repeated.
This is one to one comparison. On the other hand,
many to one comparison or one to many compar-
ison is practicable in parallel computing.
Content- addressable mem-
ories (CAMs) (Chisvin, 1989) (Yamada, 1987) re-
alize the many to one comparison. One sub-string
of input text is simultaneously compared with all
key strings stored in a. CAM. However, presently
available CAMs have only a. several tens of kilo-
bit memory, which is too small to store data. for a
more than 50,000 morpheme dictionary.
The above mentioned parallel processing com-
puters realize the one to many comparison. On
the parallel processing computers, one processor
searches the dictionary at one text position, while
another processor searches the same dictionary at
the next position at the same time (Nakamura,
1988). However, there is an access conflict prob-
lem involved, as already mentioned.
The above discussion has led the authors to the
following strategy to design the morpheme extrac-
tion machine (Fnkushima, 19894 This strategy is
to shorten the one to one comparison cycle. Simple
architecture, which will be described in the next
section, can realize this strategy.
text parsing systems. This process is necessary for
natural language parsing, because it is the first
step in the parsing. However, it is more labo-
rious for Japanese and several other languages,
which have no explicit word boundaries, than for
English and many European languages (Miyazaki,
1983) (Ohyama, 1986) (Abe, 1986). English text
reading has the advantage of including blanks be-
tween words. Figure 1 shows an example of the
morpheme extraction process for Japanese text.
Because of the disadvantage inherent in reading
difficulty involved in all symbols being strung to-
gether without any logical break between words,
the morpheme dictionary, including more than
50,000 morphemes in Japanese, is searched at al-
most all positions of Japanese text to extract mor-
phemes. The authors&apos; investigation results, indi-
cating that the morpheme extraction process re-
quires using more than 70 % of the morphologi-
cal analysis process time in conventional Japanese
parsing systems, proves the strong requirement for
the speed-up.
The second reason is that the morpheme ex-
traction process is suitable for being implemented
on specific hardware, because simple character
comparison operation has the heaviest percentage
weight in this process. The third reason is that
this speed-up will be effective to evade the com-
mon memory access conflict problem mentioned in
Section 1.
</bodyText>
<sectionHeader confidence="0.8021016" genericHeader="method">
3 A HARDWARE ALGO-
RITHM FOR MOR-
PHEME EXTRACTION
3.1 FUNDAMENTAL
ARCHITECTURE
</sectionHeader>
<bodyText confidence="0.998611652173913">
A new hardware algorithm for the morpheme
extraction, which was designed with the stratev
mentioned in the previous section, is described in
this section.
The fundamental architecture, used to imple-
ment the algorithm, is shown in Fig. 2. The main
components of this architecture are a dictionary
block, a shift register block, an index memory, an
address generator and comparators.
The dictionary block consists of character mem-
ories (i.e. 1st character memory, 2nd character
memory, ... , N-th character memory). The n-tli
character memory (1 &lt; n N) stores n-th charac-
ters of all key strings in the morpheme diction
as shown in Fig. 3. In Fig. 3, &amp;quot;Fil*&amp;quot;, &amp;quot;Et&amp;quot;, &amp;quot;
&amp;quot;, &amp;quot;ig-9tffl&amp;quot;, &amp;quot;Off&amp;quot;, and so on are Japanese mor-
phemes. As regarding morphemes shorter than
the key length /V, pre-defined remainder symbols
fill in their key areas. In Fig. 3, `gc&apos; indicates the
remain der symbol.
The shift register block consists of character reg-
isters (i.e. 1st character register, 2nd character reg-
ister, ... , N-th character register). These registers
</bodyText>
<page confidence="0.977436">
308
</page>
<figure confidence="0.999446785714286">
Shift
sm.
Shift
immp
-7-
Shift T; Shift
NEN* 2 moo
4Tf&apos;
Th
-7-AA
5711
Shift 7/7
riamO
(a) (b) (c) (d) (e)
</figure>
<figureCaption confidence="0.995975666666667">
Figure 4: Movement in Shift Register Block
Figure 3: Relation between Character Memories
and Index Memory
</figureCaption>
<bodyText confidence="0.999750891891892">
store the sub-string of input text, which can be
shifted, as shown in Fig. 4. The index memory re-
ceives a character from the 1st character register.
Then, it outputs the top address and the number
of morphemes in the dictionary, whose 1st char-
acter corresponds to the input character. Because
morphemes are arranged in the incremental order
of their key string in the dictionary, the pair for the
top address and the number expresses the address
range in the dictionary. Figure 3 shows the rela-
tion between the index memory and the character
memories. For example, when the shift register
block content is as shown in Fig. 4(a), where
is stored in the 1st character register, the index
memory&apos;s output expresses the address range for
the morpheme set {lir, gif%e&amp;quot;, &amp;quot;Mr&apos;,
s&amp;quot;, &amp;quot;FBI&amp;quot;, , in Fig. 3.
The address generator sets the same address to
all the character memories, and changes their ad-
dresses simultaneously within the address range
which the index memory expresses. Then, the dic-
tionary block outputs all characters constructing
one morpheme (key string with length N ) simul-
taneously at one address. The comparators are
N in number (i.e. 1st comparator, 2nd compara-
tor, ..., N-th comparator). The n-th comparator
compares the character in the n-th character reg-
ister with the one from the n-th character mem-
ory. When there is correspondence between the
two characters, a match signal is output. In this
comparison, the remainder symbol operates as a
wild card. This means that the comparator also
outputs a match signal when the n-th character
memory outputs the remainder symbol. Other-
wise, it outputs a no mageh signal.
The algorithm, implemented on the above de-
scribed fundamental architecture, is as follows.
</bodyText>
<listItem confidence="0.840256">
• Main procedure
</listItem>
<bodyText confidence="0.742157666666667">
Step 1: Load the top N characters from the
input text into the character registers in
the shift register block.
</bodyText>
<figure confidence="0.999012444444445">
Generatop Memory
AddressH Index
1
2
3
4
5
6
7
8
3rd
Comparator
—
r —Shift
Dictionary Block Match Sig
Text Register
CM = Character Memory Block
CR Character Register
</figure>
<figureCaption confidence="0.765137">
Figure 2: Fundamental Architecture
</figureCaption>
<figure confidence="0.998111666666667">
. : r
• 1
tst 21K * * .
1 .
a * * *-1.• 1-
Tfi * * I--; *
1*
Fff 6 ,* * i I *
I
• I :
I ;
isl * * * i i&apos;*
: I I j
!
!
1 2 3 4 N-th
Character Memory
Index Memory
</figure>
<page confidence="0.990899">
309
</page>
<bodyText confidence="0.957934333333333">
Step 2: While the text end mark has not ar-
rived at the 1st character register, im-
plement Procedure 1.
</bodyText>
<listItem confidence="0.982088">
• Procedure 1
</listItem>
<bodyText confidence="0.9745472">
Step 1: Obtain the address range for the
morphemes in the dictionary, whose 1st
character corresponds to the character in
the 1st character register. Then, set the
top address for this range to the current
address for the character memories.
Step 2: While the current address is in this
range, implement Procedure 2.
Step 3: Accomplish a shift operation to the
shift register block.
</bodyText>
<figure confidence="0.625937">
a Procedure 2
</figure>
<figureCaption confidence="0.47303575">
Step 1: Judge the result of the simultane-
ous comparisons at the current address.
When all the comparators output match
signals, detection of one morpheme is in-
dicated. When at least one comparator
outputs the no match signal, there is no
detection.
Step 2: Increase the current address.
</figureCaption>
<bodyText confidence="0.9946631">
For example, Fig. 4(a) shows the sub-string in
the shift register block immediately after Step
1 for Main procedure, when the input text is
&amp;quot;LW). L Step 3 for
Procedure 1 causes such movement as
(b)—(c), (c)-4(d), (d)—qe), and so on. Step 1
and Step 2 for Procedure 1 are implemented in
each state for (a), (b), (c), (d), (e), and so on.
In state (a) for Fig. 4, the index memory&apos;s out-
put expresses the address range for the morpheme
set { uer, HEM% iii3140A,P,
&amp;quot; 101&amp;quot;} if the dictionary is as shown in Fig. 3.
Then, Step 1 for Procedure 2 is repeated at
each address for the morpheme set OK&amp;quot;, &amp;quot;OM&amp;quot;,
Le Opt 1.
Figure 5 shows two examples of Step 1 for Pro-
cedure 2. In Fig. 5(a), the current address for
the dictionary is at the morpheme &amp;quot;liff/EN&amp;quot;. In
Fig. 5(b), the address is at the morpheme &amp;quot;effili
N&amp;quot;. In Fig. 5(a), all of the eight comparators
output match signals as the result of the simul-
taneous comparisons. This means that the mor-
pheme &amp;quot;OMR&amp;quot; has been detected at the top po-
sition of the sub-string &amp;quot;1015Effl.R.*t 111 L&amp;quot;. On
the other hand, in Fig. 5(b), seven comparators
output match signals, but one comparator, at 2nd
position, outputs a no match signal, due to the
discord between the two characters, &apos;Si and &apos;5E&apos;.
This means that the morpheme &amp;quot;COM&amp;quot; hasn&apos;t
been detected at this position.
</bodyText>
<figure confidence="0.870469">
Key String Text Sub-string
from Dictionary Block in Shift Register Block
/Comparators Comparators \
</figure>
<figureCaption confidence="0.9752135">
Figure 5: Simultaneous Comparison in Fundamen-
tal Architecture
</figureCaption>
<sectionHeader confidence="0.8704335" genericHeader="method">
3.2 EXTENDED
ARCHITECTURE
</sectionHeader>
<bodyText confidence="0.999768882352941">
The architecture described in the previous sec-
tion treats one stream of text string. In this sec-
tion, the architecture is extended to treat multi-
ple text streams, and the algorithm for extract-
ing morphemes from multiple text streams is pro-
posed.
Generally, in character recognition results or
speech recognition results, there is a certain
amount of ambiguity, in that a character or a syl-
lable has multiple candidates. Such multiple can-
didates form the multiple text streams. Figure
6(a) shows an example of multiple text streams,
expressed by a two dimensional matrix. One di-
mension corresponds to the position in the text.
The other dimension corresponds to the candi-
date level. Candidates on the same level form one
stream. For example, in Fig. 6(a), the character
at the 3rd position has three candidates: the 1st
candidate is the 2nd one is le&apos; and the 3rd
one is &apos;N&apos;. The 1st level stream is NOMA...&amp;quot;.
The 2nd level stream is &amp;quot;liffMe.g...&amp;quot;. The 3rd
level stream is &amp;quot;OiM# &amp;quot;.
Figure 6(b) shows an example of the morphemes
extracted from the multiple text streams shown in
Fig. 6(a). In the morpheme extraction process for
the multiple text streams, the key strings in the
morpheme dictionary are compared with the com-
binations of various candidates, For example, &amp;quot;Iir
9M&amp;quot;, one of the extracted morphemes, is com-
posed of the 2nd candidate at the 1st position,
the 1st candidate at the 2nd position and the 3r,zi
candidate at the 3rd position. The architecture
described in the previous section can be easily ex-
tended to treat multiple text streams. Figure 7
</bodyText>
<figure confidence="0.955514">
2
3
2
3
8
illfrififi&amp;quot; is detected. &amp;quot;PIM&amp;quot; is NOT detected.
(a) (b)
0 shows match in a comparator.
X shows no match in a comparator.
310
(a) Multiple Text Streams
— Position in 12342 3 4
• verb
noun
noun
verb
noun
fiTPL.Ph noun
f.13 verb
</figure>
<figureCaption confidence="0.716974">
Figure 6: Morpheme Extraction from Multiple
Text Streams
</figureCaption>
<equation confidence="0.450038777777778">
4elector
J 1
1st
Comparator
timi M-2 CR
• is r
✓ a r
r • a
ir • I
</equation>
<bodyText confidence="0.875911631578947">
N-th
Comparator
shows the extended architecture. This extended
architecture is different from the fundamental ar-
chitecture, in regard to the following three points.
First, there are M sets of character registers in
the shift register block. Each set is composed of
N character registers, which store and shift the
sub-string for one text stream. Here, M is the
number of text streams. N has already been in-
troduced in Section 3.1. The text streams move
simultaneously in all the register sets.
Second, the n-th comparator compares the char-
acter from the n-th character memory with the M
characters at the n-th position in the shift regis-
ter block. A match signal is output, when there
is correspondence between the character from the
memory and either of the M characters in the reg-
isters.
</bodyText>
<tableCaption confidence="0.6824797">
Third, a selector is a new component. It changes
the index memory&apos;s input. It connects one of the
registers at the 1st position to sequential index
memory inputs in turn. This changeover occurs
M times in one state of the shift register block.
Regarding the algorithm described in Section
3.1, the following modification enables treating
multiple text streams. Procedure 1 and Pro-
cedure 1.5, shown below, replace the previous
Procedure 1.
</tableCaption>
<figure confidence="0.534954166666667">
• Procedure 1
2nd s
C
Step 1: Set the highest stream to the current
ple2v:elW
Ste
hile the current level has not ex-
ceeded the lowest stream, implement
Procedure 1.5.
Step 3: Accomplish a shift operation to the
shift register block.
• Procedure 1.5
</figure>
<figureCaption confidence="0.813622833333333">
Step 1: Obtain the address range for the
morphemes in the dictionary, whose 1st
character corresponds to the character in
the register at the 1st position with the
current level. Then, set the top address
for this range to the current address for
the character memories.
Stop 2: While the current address is in this
range, implement Procedure 2,
Step 3: Lower the current level.
Figure 8 shows an example of Step 1 for Proce-
dure 2. In this example, all of the eight compare,-
</figureCaption>
<bodyText confidence="0.911715166666667">
tors output the match signal as a result of simulta.-
neon comparisons, when the morpheme from the
dictionary is &amp;quot;E/15M&amp;quot;. Characters marked with
a circle match the characters from the dictionary.
This means that the morpheme &amp;quot; 5ffii&amp;quot; has been
detected.
When each character has M candidates, the
worst case time complexity for sequential mor-
pheme extraction algorithms is 0(MN). On
the other hand, the above proposed algorithm
(Fulcushima&apos;s algorithm) has the advantage that
the time complexity is 0(M).
</bodyText>
<figure confidence="0.981227416666667">
A
• • • • • • • •
.411
coo
Ph
• • • • • • • •
verb
noun
noun
jj verb
th noun
Ph suffix
PRA noun
1
Candidate Level 2
3
(b) Extracted
Morphemes
Dictionary Block
Match Signal
1st Level 2nd Level M-th Level
Stream Stream Stream
CM = Character Memory
m-n CR = m-th Level n-th Character Register
</figure>
<figureCaption confidence="0.999431">
Figure 7: Extended Architecture
</figureCaption>
<figure confidence="0.97148388">
01 1-19R
«...!. i 2-1 CR
4. .. ....1 m-1 CR
j
--,4 1-2 R
comparato i• 2-2 CRr 1
Shift
Register
Block
311
Sub-Strings
Key String for Multiple Text Streams
from Dictionary Block in Shift Regoster Block
2
3
2
3
Comparators
I I
I I
I I
I I
I I
1 2
&amp;quot;inTifi&amp;quot; is detected.
</figure>
<figureCaption confidence="0.72501">
Figure 8: Simultaneous Comparison in Extended
Architecture
</figureCaption>
<figure confidence="0.9029245">
MEX-I
PC-9801VX
</figure>
<bodyText confidence="0.998405">
Hamaguchi&apos;s hardware algorithm (Hamaguchi,
1988), proposed for speech recognition systems, is
similar to Fukushima&apos;s algorithm. In Hamaguchi&apos;s
algorithm, S bit memory space expresses a, set of
syllables, when there are S different kinds of syl-
lables ( S = 101 in Japanese). The syllable candi-
dates at the same position in input phonetic text
are located in one 5 bit space. Therefore, Ham-
a,guchi&apos;s algorithm shows more advantages, as the
full set size of syllables is smaller and the num-
ber of syllable candidates is larger. On the other
hand, Ftikushima&apos;s algorithm is very suitable for
text with a large character set, such as Japanese
(more than 5,000 different characters are com-
puter readable in Japanese). This algorithm also
has the advantage of high speed text stream shift,
compared with conventional algorithms, including
Hamag-a chi&apos;s.
</bodyText>
<sectionHeader confidence="0.999735" genericHeader="method">
4 A MORPHEME EX-
TRACTION MACHINE
</sectionHeader>
<subsectionHeader confidence="0.998655">
4.1 A MACHINE OUTLINE
</subsectionHeader>
<bodyText confidence="0.999718888888889">
This section describes a morpheme extraction
machine, called MEX-I. It is specific hardware
which realizes extended architecture and algo-
rithm proposed in the previous section.
It works as a backend machine for NEC Per-
sonal Computer PC-9801VX (CPU: 80286 or V30,
clock: 8MHz or 10MHz). It receives Japanese text
from the host personal computer, and returns mor-
phemes extracted from the text after a bit of time.
</bodyText>
<figureCaption confidence="0.906605">
Figure 9: System Overall View
Figure 9 shows an overall view of the system, in-
cluding MEX-I and its host personal computer.
MEX-I is composed of 12 boards. Approximately
80 memory IC chips (whose total memory storage
capacity is approximately 2MB) and 500 logic IC
chips are on the boards.
</figureCaption>
<bodyText confidence="0.9999529">
The algorithm parameters in MEX-I are as fol-
low. The key length (the maximum morpheme
length) in the dictionary is 8 (i.e. N = 8 ).
The maximum number of text streams is 3 (i.e.
M = 1,2,3). The dictionary includes approxi-
mately 80,000 Japanese morphemes. This dictio-
nary size is popular in Japanese word processors.
The data length for the memories and the registers
is 16 bits, corresponding to the character code in
Japanese text.
</bodyText>
<subsectionHeader confidence="0.876234">
4.2 EVALUATION
</subsectionHeader>
<bodyText confidence="0.999913692307692">
MEX-I works with 10MHz clock (i.e. the clock
cycle is 100ns). Procedure 2, described in Sec-
tion 3.1, including the simultaneous comparisons,
is implemented for three clock cycles (i.e. 300ns).
Then, the entire implementation time for mor-
pheme extraction approximates A xD xLxMx
300ns. Here, D is the number of all morphemes in
the dictionary, L is the length of input text, M is
the number of text streams, and A is the index-
ing coefficient. This coefficient means the aver-
age rate for the number of compared morphemes,
compared to the number of all morphemes in the
dictionary.
</bodyText>
<page confidence="0.989316">
312
</page>
<figure confidence="0.982607363636364">
Implementation Time [sec]
• Newspapers
A Technical Reports
• Novels
...-it;
/
...
4
3
2
1
</figure>
<table confidence="0.877387533333333">
A.0.005
• A=0.003
/........
,■••-•&apos;..
.,.............&apos;
Morpheme Extraction Methods Text1 Text2 Text3 Text4
Programs Based on Sequential Algorithms 642 615 673 [sec]
• Binary Search Method (Knigh, 1973} 564 133 153 147 155
• Binary Search Method 406 440 435 416
Checking Top Character Index 52 56 54 54
• Ordered Hash Method (Antis. 1S74
•D igital Search Method (KM ih, 1973)
with Tree Structure index
MEX-I 0.56 0.50 0.51 0.44
A.0.001
</table>
<figureCaption confidence="0.975313">
Figure 11: Implementation Time Comparison for
</figureCaption>
<figure confidence="0.964955333333333">
5,000 Character Japanese Text
0 10,000 20,000 30,000 40,000 50,000 60,000
Number of Candidates in Text Streams (=LXM)
</figure>
<figureCaption confidence="0.925072">
Figure 10: Implementation Time Measurement
Results
</figureCaption>
<bodyText confidence="0.996423814814815">
The implementation time measurement results,
obtained for various kinds of Japanese text, are
plotted in Fig. 10. The horizontal scale in Fig. 10
is the L x M value, which corresponds to the num-
ber of characters in all the text streams. The ver-
tical scale is the measured implementation time.
The above mentioned 801000 morpheme dictio-
nary was used in this measurement. These re-
sults show performance wherein MEX-I can ex-
tract morphemes from 10,000 character Japanese
text by searching an 80,000 morpheme dictionary
in 1 second.
Figure 11 shows implementation time compari-
son with four conventional sequential algorithms.
The conventional algorithms were carried out on
NEC Personal Computer PC-98X0 (CPU: 80386,
clock: 16MHz). Then, the 80,000 morpheme dic-
tionary was on a memory board. Implementation
time was measured for four different Japanese text
samplings. Each of them forms one text stream,
which includes 5,000 characters. In these measure-
ment results, MEX-I runs approximately 1,000
times as fast as the morpheme extraction pro-
gram, using the simple binary search algorithm.
It runs approximately 100 times as fast as a pro-
gram using the digital search algorithm, which has
the highest speed among the four algorithms.
</bodyText>
<sectionHeader confidence="0.999662" genericHeader="conclusions">
5 CONCLUSION
</sectionHeader>
<bodyText confidence="0.9998861">
This paper proposes a new hardware algorithm
for high speed morpheme extraction, and also de-
scribes its implementation on a specific machine.
This machine, MEX-I, is designed as the first step
toward achieving natural language parsing accel-
erators, which is a. new approach to speeding up
the parsing.
The implementation time measurement results
show performance wherein MEX-I can extract
morphemes from 10,000 character Japanese text
by searching an 80,000 morpheme dictionary in 1
second. When input is one stream of text, it runs
100-1,000 times faster than morpheme extraction
programs on personal computers.
It can treat multiple text streams, which are
composed of character candidates, as well as one
stream of text. The proposed algorithm is imple-
mented on it in linear time for the number of can-
didates, while conventional sequential algorithms
are implemented in combinational time. This is
aclvanta?eous for character recognition or speech
recognition.
Its architecture is so simple that the authors be-
lieve it is suitable for VLSI implementation. Ac-
tually, its VLSI implementation is in progress. A
high speed morpheme extraction VLSI will im-
prove the performance of such text processing ap-
plications in practical use as Kana.to-Kanii con-
version Japanese text input methods and spelling
checkers on word processors, machine translation,
automatic indexing for text database, text-to-
speech conversion, and so on, because the mor-
pheme extraction process is necessary for these
applications.
The development of various kinds of accelera-
tor hardware for the other processes in parsing
is work for the future. The authors believe that
the hardware approach not only improves conven-
tional parsing methods, but also enables new pars-
ing methods to be designed.
</bodyText>
<page confidence="0.999189">
313
</page>
<sectionHeader confidence="0.99698" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999827023255814">
Abe, M., Ooshima, Y., Yuura, K. and Takeichi,
N. (1986). &amp;quot;A Kana-Kanji Translation System for
Non-segmented Input Sentences Based on Syntac-
tic and Semantic Analysis&amp;quot;, Proc. 11th Interna-
tional Conference on Computational Linguistics:
280-285.
Amble, 0. and Knuth, D. E. (1974). &amp;quot;Ordered
Hash Tables&amp;quot;, The Computer Journal, 17(e):
135-142.
Bear, J. (1986). &amp;quot;A Morphological recognizer
with Syntactic and Phonological Rules&amp;quot;, Prot.
11th International Conference on Computational
Linguistics: 272-276.
Chisvin, L. and Duckworth, R. J. (1989).
&amp;quot;Content-Addressable and Associative Memory:
Alternatives to the Ubiquitous RAM&amp;quot;, Computer
51-64.
Fulushima, T. Kikuchi, Y., Ohyama, Y. and
Miyai, H. (19890. &amp;quot;A Study of the Morpheme
Extraction Methods with Multi-matching Tech-
nique&amp;quot; (in Japanese), Proc. 39th National Conven-
tion of Information Processing Society of Japan:
591-592.
Pakushima, T., Ohyama, Y. and Miyai H.
(19894 &amp;quot;Natural Language Parsing Accelera-
tors (1): An Experimental Machine for Morpheme
Extraction&amp;quot; (in Japanese), Proc. 39th National
Convention of Information Processing Society of
Japan: 600-601.
Fulrushima, T.&apos; Ohya.ma, Y. and Miyai, H.
(1990a.). &amp;quot;Natural Language Parsing Accelerators
(1): An Experimental Machine for Morpheme Ex-
traction&amp;quot; (in Japanese), SIG Reports of Informa-
tion Processing Satiety of Japan, NL75(9).
Puk-ashirrui, T. (1990b). &amp;quot;A Parallel Recogni-
tion Algorithm of Context-free Language by Ar-
ray Processors&amp;quot; fin Japanese), Proc. 40th National
Convention of Information Processing Society of
Japan: 462-463.
Haas, A. (1987). &amp;quot;Parallel Parsing for Unifi-
cation Grammar&amp;quot;, Proc. 10th International Joint
Conference on Artificial Intelligence: 615-618.
Hamaguchi,
S. and Suzuki, Y. (1988). &amp;quot;Hardware-matching
Algorithm for High Speed Linguistic Processing in
Continuous Speech-recognition Systems&amp;quot;, Systems
and Computers in Japan, 19(7): 72-81.
Knuth, D. E. (1973). Sorting and Search-
ing, The Art of Computer Programming, Vol.S.
Addison-Wesley.
Koskenniemi, K. (1983). &amp;quot;Two-level Model for
Morphological Analysis&amp;quot;, Proc. 8th International
Joint Conference on Artificial Intelligence: 683-
685.
Matsumoto, Y. (1986). &amp;quot;A Parallel Parsing Sys-
tem for Natural Language Analysis&amp;quot;, Proc. 3rd
International Conference of Logic Programming,
Lecture Notes in Computer Science: 396-409.
Miyazaki, M., Goto, S., Ooyama, Y. and Shirai,
S. (1983). &amp;quot;Linguistic Processing in a Japanese-
text-to-speech-system&amp;quot; International Conference
on Text Processing with a Large Character Set:
315-320.
Nakamura, 0., Tanaka, A. and Kikuchi, H.
(1988). &amp;quot;High-Speed Processing Method for the
Morpheme Extraction Algorithm&amp;quot; (in Japanese),
Proc. 37th National Convention of Information
Processing Society of Japan: 1002-1003.
Ob.yama, Y., Fukushima, T., Shutoh, T. and
Shutoh, M. (1986). &amp;quot;A Sentence Analysis Method
for a Japanese Book Reading Machine for the
Blind&amp;quot;, Proc. 24th Annual Meeting of Association
for Computational Linguistics: 165-172.
Russell, G. J., Ritchie, G. D., Pulman, S. G. and
Black, A. W. (1986). &amp;quot;A Dictionary and Morpho-
logical Analyser for English&amp;quot;, Proc. 11th Interna-
tional Conference on Computational Linguistics:
277-279.
Rytter, W. (1987). &amp;quot;Parallel Time 0(log n)
Recognition of Unambiguous Context-free Lan-
guages , Information and Computation, 73: 75-
86.
Yamada, H., Hirata, M., Nagai, H. and Taka-
hashi, K. (j987). &amp;quot;A High-speed String-search En-
gine&amp;quot;, IEEE Journal of Solid-state Circuits, SC-
22(5): 829-834.
</reference>
<page confidence="0.999131">
314
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.789650">
<title confidence="0.996834">A HARDWARE ALGORITHM FOR HIGH SPEED MORPHEME EXTRACTION AND ITS IMPLEMENTATION</title>
<author confidence="0.989552">Toshikazu Fukushima</author>
<author confidence="0.989552">Yutaka Ohyama</author>
<author confidence="0.989552">ilitoshi Miyai</author>
<affiliation confidence="0.999901">C&amp;C Systems Research Laboratories, NEC Corporation</affiliation>
<address confidence="0.993117">1-1, Miyazaki 4-chome, Miyamae-ku, Kawasaki City, Kanagawa 213, Japan</address>
<email confidence="0.860081">ohyamatitsl.cl.nec.co.jp,miyaOtsl.cl..c</email>
<abstract confidence="0.9957721875">This paper describes a new hardware algorithm for morpheme extraction and its implementation a. specific machine the first step toward achieving natural language parsing accelerators. It also shows the machine&apos;s performance, 100-1,000 times faster than a personal computer. This machine can extract morphemes from 10,000 character Japanese text by searching an 80,000 morpheme dictionary in 1 second. It can treat multiple text streams, which are composed of character candidates, as well as one text stream. The algorithm is implemented on the machine in linear time for the number of candidates, while convensequential algorithms are implemented combinational time.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Abe</author>
<author>Y Ooshima</author>
<author>K Yuura</author>
<author>N Takeichi</author>
</authors>
<title>A Kana-Kanji Translation System for Non-segmented Input Sentences Based on Syntactic and Semantic Analysis&amp;quot;,</title>
<date>1986</date>
<booktitle>Proc. 11th International Conference on Computational Linguistics:</booktitle>
<pages>280--285</pages>
<marker>Abe, Ooshima, Yuura, Takeichi, 1986</marker>
<rawString>Abe, M., Ooshima, Y., Yuura, K. and Takeichi, N. (1986). &amp;quot;A Kana-Kanji Translation System for Non-segmented Input Sentences Based on Syntactic and Semantic Analysis&amp;quot;, Proc. 11th International Conference on Computational Linguistics: 280-285.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Knuth</author>
</authors>
<title>Ordered Hash Tables&amp;quot;,</title>
<date>1974</date>
<journal>The Computer Journal,</journal>
<volume>17</volume>
<pages>135--142</pages>
<marker>Knuth, 1974</marker>
<rawString>Amble, 0. and Knuth, D. E. (1974). &amp;quot;Ordered Hash Tables&amp;quot;, The Computer Journal, 17(e): 135-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bear</author>
</authors>
<title>A Morphological recognizer with Syntactic and Phonological Rules&amp;quot;,</title>
<date>1986</date>
<booktitle>Prot. 11th International Conference on Computational Linguistics:</booktitle>
<pages>272--276</pages>
<marker>Bear, 1986</marker>
<rawString>Bear, J. (1986). &amp;quot;A Morphological recognizer with Syntactic and Phonological Rules&amp;quot;, Prot. 11th International Conference on Computational Linguistics: 272-276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Chisvin</author>
<author>R J Duckworth</author>
</authors>
<title>Content-Addressable and Associative Memory: Alternatives to the Ubiquitous RAM&amp;quot;,</title>
<date>1989</date>
<journal>Computer</journal>
<pages>51--64</pages>
<marker>Chisvin, Duckworth, 1989</marker>
<rawString>Chisvin, L. and Duckworth, R. J. (1989). &amp;quot;Content-Addressable and Associative Memory: Alternatives to the Ubiquitous RAM&amp;quot;, Computer 51-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kikuchi Fulushima</author>
<author>Y Ohyama</author>
<author>Y</author>
<author>H Miyai</author>
</authors>
<title>A Study of the Morpheme Extraction Methods with Multi-matching Technique&amp;quot;</title>
<date>1989</date>
<booktitle>(in Japanese), Proc. 39th National Convention of Information Processing Society of Japan:</booktitle>
<pages>591--592</pages>
<marker>Fulushima, Ohyama, Y, Miyai, 1989</marker>
<rawString>Fulushima, T. Kikuchi, Y., Ohyama, Y. and Miyai, H. (19890. &amp;quot;A Study of the Morpheme Extraction Methods with Multi-matching Technique&amp;quot; (in Japanese), Proc. 39th National Convention of Information Processing Society of Japan: 591-592.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pakushima</author>
<author>Y Ohyama</author>
<author>H Miyai</author>
</authors>
<title>Natural Language Parsing Accelerators (1): An Experimental Machine for Morpheme Extraction&amp;quot; (in</title>
<date>1989</date>
<booktitle>Japanese), Proc. 39th National Convention of Information Processing Society of Japan:</booktitle>
<pages>600--601</pages>
<marker>Pakushima, Ohyama, Miyai, 1989</marker>
<rawString>Pakushima, T., Ohyama, Y. and Miyai H. (19894 &amp;quot;Natural Language Parsing Accelerators (1): An Experimental Machine for Morpheme Extraction&amp;quot; (in Japanese), Proc. 39th National Convention of Information Processing Society of Japan: 600-601.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T &apos; Ohya ma Fulrushima</author>
<author>Y</author>
<author>H Miyai</author>
</authors>
<title>Natural Language Parsing Accelerators (1): An Experimental Machine for Morpheme Extraction&amp;quot; (in</title>
<date>1990</date>
<booktitle>Japanese), SIG Reports of Information Processing Satiety of Japan,</booktitle>
<volume>75</volume>
<issue>9</issue>
<marker>Fulrushima, Y, Miyai, 1990</marker>
<rawString>Fulrushima, T.&apos; Ohya.ma, Y. and Miyai, H. (1990a.). &amp;quot;Natural Language Parsing Accelerators (1): An Experimental Machine for Morpheme Extraction&amp;quot; (in Japanese), SIG Reports of Information Processing Satiety of Japan, NL75(9).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Puk-ashirrui</author>
</authors>
<title>A Parallel Recognition Algorithm of Context-free Language by Array Processors&amp;quot; fin Japanese),</title>
<date>1990</date>
<booktitle>Proc. 40th National Convention of Information Processing Society of Japan:</booktitle>
<pages>462--463</pages>
<marker>Puk-ashirrui, 1990</marker>
<rawString>Puk-ashirrui, T. (1990b). &amp;quot;A Parallel Recognition Algorithm of Context-free Language by Array Processors&amp;quot; fin Japanese), Proc. 40th National Convention of Information Processing Society of Japan: 462-463.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Haas</author>
</authors>
<title>Parallel Parsing for Unification Grammar&amp;quot;,</title>
<date>1987</date>
<booktitle>Proc. 10th International Joint Conference on Artificial Intelligence:</booktitle>
<pages>615--618</pages>
<contexts>
<context position="2470" citStr="Haas, 1987" startWordPosition="351" endWordPosition="352">methods based on larger scale dictionary or knowledge database, which are necessary to improve parsing accuracy. Until now, in the natural language processing field, the speed-up has depended mainly on performance improvements achieved in sequential processing computers and the development of sequential algorithms. Recently, because of the further &apos;Karla characters are combined consonant and vowel symbols used in written Japanese. Kanji characters are Chinese ideographs. speeded-up requirement, parallel processing computers have been designed and parallel parsing algorithms (Matsumoto, 1986) (Haas, 1987) (Rytter, 1987) (Fukushima, 1990b) have been proposed. However, there are many difficult problems blocking efficient practical use of parallel processing computers. One of the problems is that access conflicts occur when several processors read or write a common memory simultaneously. Another is the bottle-neck problem, wherein commtnication between any two processors is restricted, because of hardware scale limitation. On the other hand, in the pattern processing field, various kinds of accelerator hardware have been developed. They are designed for a special purpose, not for general purposes</context>
</contexts>
<marker>Haas, 1987</marker>
<rawString>Haas, A. (1987). &amp;quot;Parallel Parsing for Unification Grammar&amp;quot;, Proc. 10th International Joint Conference on Artificial Intelligence: 615-618.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Hamaguchi</author>
<author>Y Suzuki</author>
</authors>
<title>Hardware-matching Algorithm for High Speed Linguistic Processing in Continuous Speech-recognition Systems&amp;quot;,</title>
<date>1988</date>
<booktitle>Systems and Computers in Japan,</booktitle>
<volume>19</volume>
<issue>7</issue>
<pages>72--81</pages>
<marker>Hamaguchi, Suzuki, 1988</marker>
<rawString>Hamaguchi, S. and Suzuki, Y. (1988). &amp;quot;Hardware-matching Algorithm for High Speed Linguistic Processing in Continuous Speech-recognition Systems&amp;quot;, Systems and Computers in Japan, 19(7): 72-81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Knuth</author>
</authors>
<title>Sorting and Searching, The Art of Computer Programming,</title>
<date>1973</date>
<publisher>Vol.S. Addison-Wesley.</publisher>
<marker>Knuth, 1973</marker>
<rawString>Knuth, D. E. (1973). Sorting and Searching, The Art of Computer Programming, Vol.S. Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Koskenniemi</author>
</authors>
<title>Two-level Model for Morphological Analysis&amp;quot;,</title>
<date>1983</date>
<booktitle>Proc. 8th International Joint Conference on Artificial Intelligence:</booktitle>
<pages>683--685</pages>
<marker>Koskenniemi, 1983</marker>
<rawString>Koskenniemi, K. (1983). &amp;quot;Two-level Model for Morphological Analysis&amp;quot;, Proc. 8th International Joint Conference on Artificial Intelligence: 683-685.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Matsumoto</author>
</authors>
<title>A Parallel Parsing System for Natural Language Analysis&amp;quot;,</title>
<date>1986</date>
<booktitle>Proc. 3rd International Conference of Logic Programming, Lecture Notes in Computer Science:</booktitle>
<pages>396--409</pages>
<contexts>
<context position="2457" citStr="Matsumoto, 1986" startWordPosition="349" endWordPosition="350"> realizes parsing methods based on larger scale dictionary or knowledge database, which are necessary to improve parsing accuracy. Until now, in the natural language processing field, the speed-up has depended mainly on performance improvements achieved in sequential processing computers and the development of sequential algorithms. Recently, because of the further &apos;Karla characters are combined consonant and vowel symbols used in written Japanese. Kanji characters are Chinese ideographs. speeded-up requirement, parallel processing computers have been designed and parallel parsing algorithms (Matsumoto, 1986) (Haas, 1987) (Rytter, 1987) (Fukushima, 1990b) have been proposed. However, there are many difficult problems blocking efficient practical use of parallel processing computers. One of the problems is that access conflicts occur when several processors read or write a common memory simultaneously. Another is the bottle-neck problem, wherein commtnication between any two processors is restricted, because of hardware scale limitation. On the other hand, in the pattern processing field, various kinds of accelerator hardware have been developed. They are designed for a special purpose, not for gen</context>
</contexts>
<marker>Matsumoto, 1986</marker>
<rawString>Matsumoto, Y. (1986). &amp;quot;A Parallel Parsing System for Natural Language Analysis&amp;quot;, Proc. 3rd International Conference of Logic Programming, Lecture Notes in Computer Science: 396-409.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Miyazaki</author>
<author>S Goto</author>
<author>Y Ooyama</author>
<author>S Shirai</author>
</authors>
<title>Linguistic Processing in a Japanesetext-to-speech-system&amp;quot;</title>
<date>1983</date>
<booktitle>International Conference on Text Processing with a Large Character Set:</booktitle>
<pages>315--320</pages>
<marker>Miyazaki, Goto, Ooyama, Shirai, 1983</marker>
<rawString>Miyazaki, M., Goto, S., Ooyama, Y. and Shirai, S. (1983). &amp;quot;Linguistic Processing in a Japanesetext-to-speech-system&amp;quot; International Conference on Text Processing with a Large Character Set: 315-320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Tanaka</author>
<author>H Kikuchi</author>
</authors>
<title>High-Speed Processing Method for the Morpheme Extraction Algorithm&amp;quot; (in</title>
<date>1988</date>
<booktitle>Japanese), Proc. 37th National Convention of Information Processing Society of Japan:</booktitle>
<pages>1002--1003</pages>
<marker>Tanaka, Kikuchi, 1988</marker>
<rawString>Nakamura, 0., Tanaka, A. and Kikuchi, H. (1988). &amp;quot;High-Speed Processing Method for the Morpheme Extraction Algorithm&amp;quot; (in Japanese), Proc. 37th National Convention of Information Processing Society of Japan: 1002-1003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Ob yama</author>
<author>T Fukushima</author>
<author>T Shutoh</author>
<author>M Shutoh</author>
</authors>
<title>A Sentence Analysis Method for a Japanese Book Reading Machine for the Blind&amp;quot;,</title>
<date>1986</date>
<booktitle>Proc. 24th Annual Meeting of Association for Computational Linguistics:</booktitle>
<pages>165--172</pages>
<marker>yama, Fukushima, Shutoh, Shutoh, 1986</marker>
<rawString>Ob.yama, Y., Fukushima, T., Shutoh, T. and Shutoh, M. (1986). &amp;quot;A Sentence Analysis Method for a Japanese Book Reading Machine for the Blind&amp;quot;, Proc. 24th Annual Meeting of Association for Computational Linguistics: 165-172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G J Russell</author>
<author>G D Ritchie</author>
<author>S G Pulman</author>
<author>A W Black</author>
</authors>
<title>A Dictionary and Morphological Analyser for English&amp;quot;,</title>
<date>1986</date>
<booktitle>Proc. 11th International Conference on Computational Linguistics:</booktitle>
<pages>277--279</pages>
<marker>Russell, Ritchie, Pulman, Black, 1986</marker>
<rawString>Russell, G. J., Ritchie, G. D., Pulman, S. G. and Black, A. W. (1986). &amp;quot;A Dictionary and Morphological Analyser for English&amp;quot;, Proc. 11th International Conference on Computational Linguistics: 277-279.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Rytter</author>
</authors>
<title>Parallel Time 0(log n) Recognition of Unambiguous Context-free Languages ,</title>
<date>1987</date>
<journal>Information and Computation,</journal>
<volume>73</volume>
<pages>75--86</pages>
<contexts>
<context position="2485" citStr="Rytter, 1987" startWordPosition="353" endWordPosition="355"> on larger scale dictionary or knowledge database, which are necessary to improve parsing accuracy. Until now, in the natural language processing field, the speed-up has depended mainly on performance improvements achieved in sequential processing computers and the development of sequential algorithms. Recently, because of the further &apos;Karla characters are combined consonant and vowel symbols used in written Japanese. Kanji characters are Chinese ideographs. speeded-up requirement, parallel processing computers have been designed and parallel parsing algorithms (Matsumoto, 1986) (Haas, 1987) (Rytter, 1987) (Fukushima, 1990b) have been proposed. However, there are many difficult problems blocking efficient practical use of parallel processing computers. One of the problems is that access conflicts occur when several processors read or write a common memory simultaneously. Another is the bottle-neck problem, wherein commtnication between any two processors is restricted, because of hardware scale limitation. On the other hand, in the pattern processing field, various kinds of accelerator hardware have been developed. They are designed for a special purpose, not for general purposes. A hardware ap</context>
</contexts>
<marker>Rytter, 1987</marker>
<rawString>Rytter, W. (1987). &amp;quot;Parallel Time 0(log n) Recognition of Unambiguous Context-free Languages , Information and Computation, 73: 75-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yamada</author>
<author>M Hirata</author>
<author>H Nagai</author>
<author>K Takahashi</author>
</authors>
<title>A High-speed String-search Engine&amp;quot;,</title>
<date></date>
<journal>IEEE Journal of Solid-state Circuits,</journal>
<volume>22</volume>
<issue>5</issue>
<pages>829--834</pages>
<marker>Yamada, Hirata, Nagai, Takahashi, </marker>
<rawString>Yamada, H., Hirata, M., Nagai, H. and Takahashi, K. (j987). &amp;quot;A High-speed String-search Engine&amp;quot;, IEEE Journal of Solid-state Circuits, SC22(5): 829-834.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>