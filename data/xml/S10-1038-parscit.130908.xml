<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000103">
<title confidence="0.951655">
UNPMC: Naive Approach to Extract Keyphrases from Scientific Articles
</title>
<author confidence="0.561761">
Jungyeul Park Jong Gun Lee B´eatrice Daille
</author>
<affiliation confidence="0.597278666666667">
LINA, LIP6-CNRS, LINA,
Universit´e de Nantes UPMC (Paris 6) Universit´e de Nantes
Nantes, France Paris, France Nantes, France
</affiliation>
<note confidence="0.366605">
jungyeul.park jonggun.lee beatrice.daille
</note>
<email confidence="0.980217">
@univ-nantes.fr @lip6.fr @univ-nantes.fr
</email>
<sectionHeader confidence="0.993213" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999950611111111">
We describe our method for extracting
keyphrases from scientific articles which
we participate in the shared task of
SemEval-2 Evaluation Exercise. Even
though general-purpose term extractors
along with linguistically-motivated analy-
sis allow us to extract elaborated morpho-
syntactic variation forms of terms, a naive
statistic approach proposed in this paper
is very simple and quite efficient for ex-
tracting keyphrases especially from well-
structured scientific articles. Based on
the characteristics of keyphrases with sec-
tion information, we obtain 18.34% for
f-measure using top 15 candidates. We
also show further improvement without
any complications and we discuss this at
the end of the paper.
</bodyText>
<sectionHeader confidence="0.80792" genericHeader="keywords">
1 Introduction1
</sectionHeader>
<bodyText confidence="0.983177733333333">
Key phrases are a set of words to capture the main
topic of the document. Since key phrases con-
tain the substance of the document, they are used
in the large spectrum of areas; from applications
which explicitly use key phrases such as automatic
indexing, documents classification and search en-
gine optimization in information retrieval, to ap-
plications which implicitly use key phrases such as
summarization and question-answering systems.
During the last decade, many previous works have
dealt with the various methods for automatically
extracting key phrases (e.g., Frank et al., 1999;
Barker and Corrnacchia, 2000; Turney, 2003;
Medelyan and Witten, 2006; Nguyen and Kan,
2007; Wan and Xiao, 2008).
</bodyText>
<footnote confidence="0.9463055">
1UNPMC means the collaborative team from Laboratoire
d’Informatique de Nantes Atlantique of the Universit´e de
Nantes and Laboratoire d’Informatique de Paris 6 of the Uni-
versit´e Pierre et Marie Curie.
</footnote>
<bodyText confidence="0.991522897435897">
The task of extracting key phrases would be
considered as a subtask of extracting terminology
if key phrases are a kind of terms. Typical ap-
proaches for automatically extracting terms use
linguistic preprocessing which involves morpho-
syntactic analysis such as part-of-speech tagging
and phrase chunking, and statistical postprocess-
ing such as log likelihood which compares the
term frequencies in a document against their ex-
pected frequencies derived in a bigger text. Be-
sides, extracting terms prefers syntactically plau-
sible noun phrases (NPs) which are mainly multi-
words terms. Kim and Kan (2009) report that most
of key phrases are often simple words than less of-
ten compound words2.
The task for extracting key phrases tend to in-
clude analyzing the document structure. Espe-
cially, extracting key phrases from well-structured
scientific articles should consider cross-section in-
formation (Nguyen and Kan, 2007). This informa-
tion has been explored to assess the suitability of
features during learning in Kim and Kan (2009).
Extracting key phrases, however, is more than to
extracting terminology or analyzing the document
structure. While terms are words which appear in
specific contexts and analyse concept structures in
domains of human activity, key phrases are words
that capture the key idea of documents. In addi-
tion, while terms usually occur in the given doc-
ument more often than we would expect to occur,
key phrases do not necessarily occur frequently or
key phrases do not occur at all in the document.
Consequently, the task for extracting key phrases
should not be considered as the subtask of extract-
ing terminology and we are not able to directly ap-
ply general-purpose term extractors to extract key
phrases.
In this paper, we describe our method for “Au-
tomatic Keyphrase Extraction from Scientific Ar-
</bodyText>
<footnote confidence="0.997017">
2In training data, only 23.4% of keyphrases, however, are
single words.
</footnote>
<page confidence="0.900574">
178
</page>
<bodyText confidence="0.956413047619047">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 178–181,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
ticles”, the shared task of SemEval-2 Evalua-
tion Exercise which we participated in. Al-
though term extractors along with linguistically-
motivated analysis allow us to extract even elab-
orated morpho-syntactic variation forms of terms,
the naive statistic approach proposed in this pa-
per is very simple and quite efficient for extracting
keyphrases especially from well-structured scien-
tific articles. In a nutshell, our method is based
on empirical rules without any linguistically-
motivated preprocessing. Empirical rules are ob-
tained from the analysis of the characteristics of
keyphrases by observing training data.
The remaining of this paper is organized as fol-
lows: Section 2 explains the characteristics of
keyphrases in scientific articles. Section 3 and 4
detail our naive statistic approach and experiment,
respectively. We conclude this paper and discuss a
further improvement in Section 6.
</bodyText>
<subsectionHeader confidence="0.7997595">
2 Characteristics of Keyphrases in
Scientific Articles
</subsectionHeader>
<bodyText confidence="0.999444285714286">
In this section, we investigate the characteristics of
keyphrases in training data. Table 1 shows statis-
tics of training data. In Table 1, D-author means
the keyphrases assigned by authors, D-reader the
keyphrases assigned by readers, and D-combined
the combined keyphrases assigned by both of au-
thors and readers.
</bodyText>
<table confidence="0.98777875">
# of papers (p) # of key phrases (k) k / p
D-author 144 563 3.91
D-reader 144 1,865 12.95
D-combined 144 2,265 15.73
</table>
<tableCaption confidence="0.999813">
Table 1: Statistics of training data
</tableCaption>
<subsectionHeader confidence="0.992958">
2.1 Word length of keyphrases
</subsectionHeader>
<bodyText confidence="0.999997454545455">
We measure the distribution of word length of key
phrases in training data and present it in Figure 1.
Over half of key phrases are two-word key phrases
in both author- and reader-assigned key phrases.
Differently with Kim and Kan (2009) which they
reported that most of key phrases are often sim-
ple words than less often compound words, only
29.7% and 17.7% of key phrases are one-word key
phrases. There are also more than four-word key
phrases which hold 4.3% and 7.2% of author and
reader assigned key phrases, respectively.
</bodyText>
<subsectionHeader confidence="0.999747">
2.2 Occurrences of keyphrases
</subsectionHeader>
<bodyText confidence="0.999727">
In which section do keyphrases occur frequently?
To answer this question, we count the number of
</bodyText>
<figure confidence="0.998222">
(a) D-author (b) D-reader
</figure>
<figureCaption confidence="0.967429">
Figure 1: Word length of keyphrases in training
data
</figureCaption>
<bodyText confidence="0.998056">
occurrences of keyphrases of each section. Due
to the variation of the naming of the section,
we divide sections into title and abstract, intro-
duction, conclusion, and the rest including refer-
ences. Table 2 and 3 show the number of occur-
rences and the accumulative number of unique oc-
currences of keyphrases in each section, respec-
tively. We also show the accumulative number
of words in each section in Table 4. Including
the rest sections exponentially diminishes the ra-
tio of the number of gold keyphrases to the number
of candidate keyphrases. Note that m words pro-
</bodyText>
<equation confidence="0.9175895">
duce �n−1
i=0 (m − i) candidate keyphrases for up
</equation>
<bodyText confidence="0.969853090909091">
to n-word keyphrases by supposing that candidate
keyphrases are simple n-word terms.
Note also that both author- and reader-assigned
keyphrases hold only 75.49% and 89.44%, re-
spectively. Even some keyphrases are different
with surface forms in the document and our naive
method with no linguistic intervention is not able
to recognize them. For example, one of reader-
assigned keyphrases distributed real-time embed-
ded system for C-41 actually appears as distributed
real-time and embedded (DRE) systems.
</bodyText>
<table confidence="0.9987748">
D-author D-reader
277 802
215 491
313 982
387 1,210
</table>
<tableCaption confidence="0.999115">
Table 2: Number of occurrences of keyphrases in
each section
Table 3: Accumulative number of unique occur-
rences of keyphrases in each section
</tableCaption>
<figure confidence="0.998718322580645">
length=1
(29.7%)
length=1
(17.7%)
length=4+
(4.3%)
length=3
(21.8%)
length=3
(14.7%)
length=2
(51.3%)
length=2
(53.2%)
length=4+
(7.2%)
Title and Abstract
Introduction
Conclusion
Other
D-author D-reader
563 (100.0%) 1,865 (100.0%)
277 (49.20%) 802 (43.00%)
317 (56.30%) 937 (50.24%)
367 (65.19%) 1,311 (70.29%)
425 (75.49%) 1,668 (89.44%)
Total
Title and Abstract
‘+’ Introduction
‘+’ Conclusion
‘+’ Other
</figure>
<page confidence="0.988056">
179
</page>
<table confidence="0.9983456">
# words (W) # gold (G) G/W
Title and Abstract 28435 802 0.0282
‘+’ Introduction 72729 937 0.0128
‘+’ Conclusion 178473 1311 0.0073
‘+’ Other 948007 1668 0.0018
</table>
<tableCaption confidence="0.9933095">
Table 4: Number of words in training data and
gold data (D-reader)
</tableCaption>
<subsectionHeader confidence="0.991118">
2.3 Coincidence of keyphrases
</subsectionHeader>
<figureCaption confidence="0.564604888888889">
Figure 2 shows the coincidence of keyphrases3.
Almost half of keyphrases (58.44% and 45.74%
for author- and reader-assigned keyphrases, re-
spectively) occur coincidentally in keysections
and the rest sections. Keysections hold 65.19%
and 70.29% of keyphrases and the rest sections
besides keysections hold 68.74% and 64.88% of
whole keyphrases. Note that the rest sections oc-
cupy over 70% of the document on the average.
</figureCaption>
<figure confidence="0.997586">
(a) D-author (b) D-reader
</figure>
<figureCaption confidence="0.999685">
Figure 2: Coincidence of keyphrases
</figureCaption>
<sectionHeader confidence="0.997319" genericHeader="introduction">
3 Methodology
</sectionHeader>
<bodyText confidence="0.915642545454546">
From training data, we observe and decide the fol-
lowings:
• More than four-word keyphrases hold only
4.3% and 7.2% of whole keyphrases. We
decide that our approach limits the word
length as three for extracting keyphrases.
Thus we extract only up to three-word
keyphrases. This choice might lead the per-
formance degradation of our method because
we explicitly exclude more than four-word
keyphrases.
</bodyText>
<listItem confidence="0.80270925">
• Keysections hold 65.19% and 70.29% of
keyphrases. We decide that our approach
limits keysections from which we extract
keyphrases. Including the rest sections may
</listItem>
<footnote confidence="0.567235">
3We denote title and abstract as A, introduction as I, con-
clusion as C, and the rest sections including references as
Other.
</footnote>
<bodyText confidence="0.9092258">
improve recall, but probably diminish preci-
sion since the rest sections occupy over 70%
of the document.
• Almost half of keyphrases occur coinciden-
tally in keysections and the rest sections. We
decide that our approach limits coincident
keyphrases in both of them. This decision is
made empirically and improve precision.
The following procedure explains and details
our approach for extracting keyphrases.
</bodyText>
<listItem confidence="0.983777692307692">
• Extract up to three-word terms from keysec-
tions as candidate keyphrases.
• Filter them out if they contain one or more of
stop words or non-content-containing words
(see Table 5 for non-content-containing
words).
• Count the number of occurrences of extracted
terms from each keysection.
• Check the coincidence whether candidate
keyphrases occurs in more than two keysec-
tions. If so, we assign weight.
• Calculate a score for candidate keyphrases
and list them by order of the score.
</listItem>
<sectionHeader confidence="0.967896" genericHeader="method">
4 Experiment results
</sectionHeader>
<bodyText confidence="0.998968">
This section shows the experiment results with
training and test data.
</bodyText>
<subsectionHeader confidence="0.999238">
4.1 Training data
</subsectionHeader>
<bodyText confidence="0.957116428571429">
To optimize our results, we use various thresholds
for the number of n-word keyphrases and weight.
We try to find the (i : j : k) pattern which
means i one-word, j two-word, and K three-
word keyphrases to produce the best results. We
also try to find the threshold for weight d to cal-
culate the score as follows: if keyphrases ap-
pear in more than two keysections, score =
d ∗ # of total occurences, otherwise score =
# of total occurences. Table 6 shows our best
results for training data where (i : j : k) = (3 :
9 : 3) and d = 2. Empirically, we found these
thresholds from training data by iterating several
possibilities4.
</bodyText>
<subsectionHeader confidence="0.998364">
4.2 Test data
</subsectionHeader>
<bodyText confidence="0.833137333333333">
Table 7 shows our test data results published by
organizers of the shared task of SemEval-2 Evalu-
ation Exercise.
</bodyText>
<footnote confidence="0.967615">
4These thresholds will be more examined in future work.
</footnote>
<page confidence="0.989331">
180
</page>
<table confidence="0.558820875">
Type Examples
Noun section, abstract, introduction, conclusion, reference, future work, figure, paper, result, laboratory, university
Verb present, how, introduce, become, improve, find, help, improve, consider, call, yield, allow, give, assume
Adverb always, formally, necessarily, successfully, previously, usually,mainly, final, essentially, ultinately, commonly,
severely, significantly, dramatically, clearly, still, well, who, whose, whom, which, whether, therefore,
Other POSs that, this, those, these, many, several, more, over, less, behind, above, below, each, few, different, under,
both, within, through, prior, various, better, following, between, possible, via, before,even, such, if, new,
show, important, simple, good, tranditional, current, varying, necessary, previous, clear
</table>
<tableCaption confidence="0.991918">
Table 5: Example of (heuristically obtained) non-content-containing terms
</tableCaption>
<table confidence="0.996311666666667">
AUTHOR.STEM.FINAL
# Gold: 559 Match Precision Recall F-score
Top 05 43 5.97% 7.69% 6.72%
Top 10 101 7.01% 18.07% 10.10%
Top 15 139 6.44% 24.87% 10.23%
READER.STEM.FINAL
# Gold: 1824 Match Precision Recall F-score
Top 05 118 16.39% 6.47% 9.28%
Top 10 249 17.29% 13.65% 15.26%
Top 15 361 16.71% 19.79% 18.12%
COMBINED.STEM.FINAL
# Gold: 2223 Match Precision Recall F-score
Top 05 143 19.86% 6.43% 9.71%
Top 10 309 21.46% 13.90% 16.87%
Top 15 441 20.42% 19.84% 20.13%
</table>
<tableCaption confidence="0.954691">
Table 6: Training data results
</tableCaption>
<table confidence="0.994242">
READER.STEM.FINAL
# Gold: 1204 Precision Recall Fscore
Top 05 13.80% 5.73% 8.10%
Top 10 15.10% 12.54% 13.70%
Top 15 14.47% 18.02% 16.05%
COMBINED.STEM.FINAL
# Gold: 1466 Precision Recall Fscore
Top 05 18.00% 6.14% 9.16%
Top 10 19.00% 12.96% 15.41%
Top 15 18.13% 18.55% 18.34%
</table>
<tableCaption confidence="0.997462">
Table 7: Test data results
</tableCaption>
<sectionHeader confidence="0.983637" genericHeader="conclusions">
5 Conclusion and Discussion
</sectionHeader>
<bodyText confidence="0.999747470588235">
In this paper, we described our simple method
for extracting keyphrases from scientific arti-
cles which we participate in the shared task of
SemEval-2 Evaluation Exercise. The naive ap-
proach was proposed. This approach turned
out very simple and quite efficient for extracting
keyphrases from well-structured scientific articles.
Based on learning the distribution of keyphrases
with section information, we obtain 18.34% for f-
measure using top 15 candidates.
Our naive approach still has much room for
improvement. For example, we are able to im-
prove the result for same test data up to 20.71%
and 25.55% for f-measure using top 15 candidates
simply by adding the rest sections and normaliz-
ing the number of occurrences of terms from each
section5.
</bodyText>
<footnote confidence="0.974916">
5The result is not improved only by adding the rest sec-
tions.
</footnote>
<bodyText confidence="0.999884363636364">
Moreover, our n-word terms based extraction
can be benefited by linguistic preprocessing such
as normalizing surface forms. Handcrafted regu-
lar expression rules along with part-of-speech tag-
ging and phrase chunking would be also intro-
duced to improve candidate selection. We have
not explored thoroughly feature engineering, nei-
ther. For example, more fine-grained section infor-
mation and weight re-assignment might help filter
out irrelevant candidates. We leave these possibil-
ities for future work.
</bodyText>
<sectionHeader confidence="0.999414" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999611764705882">
Ken Barker and Nadia Cornacchia. 2000. Using noun phrase
heads to extract document keyphrases. In Proceedings
of the 13th Biennial Conference of the Canadian Soci-
ety on Computational Studies of Intelligence: Advances
in Artificial Intelligence, pages 40-52. May 14-17, 2000.
Montr´eal, Quebec, Canada.
Eibe Frank, Gordon W. Paynter, Ian H. Witten, Carl Gutwin,
and Craig G. Nevill-Manning. 1999. Domain-Specific
Keyphrase Extraction. In Proceedings of the 16th Inter-
national Joint Conference on Artificial Intelligence, pages
668-673. July 31-August 6, 1999. Stockholm, Sweden.
Su Nam Kim and Min-Yen Kan. 2009. Re-examining Auto-
matic Keyphrase Extraction Approaches in Scientific Ar-
ticles. In Proceedings of the Workshop on Multiword Ex-
pressions: Identification, Interpretation, Disambiguation
and Applications (MWE 2009), ACL-IJCNLP 2009, pages
9-12. August 6, 2009. Singapore.
Olena Medelyan and Ian H. Witten. 2006. Thesaurus based
automatic keyphrase indexing. In Proceedings of the
6th ACM/IEEE-CS joint conference on Digital libraries,
pages 296-297. June 11-15, 2006. Chapel Hill, NC, USA.
Thuy Dung Nguyen and Min-Yen Kan. 2007. Key phrase
Extraction in Scientific Publications. Asian Digital Li-
braries. Looking Back 10 Years and Forging New Fron-
tiers, pages 317-326. Springer Berlin, Heidelberg.
Peter D. Turney. 2003. Coherent keyphrase extraction via
Web mining. In Proceedings of the 18th International
Joint Conference on Artificial Intelligence, pages 434-
439. August 9-15, 2003. Acapulco, Mexico.
Xiaojun Wan and Jianguo Xiao. 2008. CollabRank: towards
a collaborative approach to single-document keyphrase
extraction. In Proceedings of the 22nd International
Conference on Computational Linguistics (Coling 2008),
pages 969-976. 18-22 August, 2008. Manchester, UK.
</reference>
<page confidence="0.998372">
181
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.003569">
<title confidence="0.998708">UNPMC: Naive Approach to Extract Keyphrases from Scientific Articles</title>
<author confidence="0.994249">Jungyeul Park Jong Gun Lee B´eatrice Daille</author>
<affiliation confidence="0.9197675">LINA, LIP6-CNRS, LINA, Universit´e de Nantes UPMC (Paris 6) Universit´e de Nantes</affiliation>
<address confidence="0.981395">Nantes, France Paris, France Nantes, France</address>
<abstract confidence="0.985007215189873">jungyeul.park jonggun.lee beatrice.daille @univ-nantes.fr @lip6.fr @univ-nantes.fr Abstract We describe our method for extracting keyphrases from scientific articles which we participate in the shared task of SemEval-2 Evaluation Exercise. Even though general-purpose term extractors along with linguistically-motivated analysis allow us to extract elaborated morphosyntactic variation forms of terms, a naive statistic approach proposed in this paper is very simple and quite efficient for extracting keyphrases especially from wellstructured scientific articles. Based on the characteristics of keyphrases with section information, we obtain 18.34% for f-measure using top 15 candidates. We also show further improvement without any complications and we discuss this at the end of the paper. Key phrases are a set of words to capture the main topic of the document. Since key phrases contain the substance of the document, they are used in the large spectrum of areas; from applications which explicitly use key phrases such as automatic indexing, documents classification and search engine optimization in information retrieval, to applications which implicitly use key phrases such as summarization and question-answering systems. During the last decade, many previous works have dealt with the various methods for automatically extracting key phrases (e.g., Frank et al., 1999; Barker and Corrnacchia, 2000; Turney, 2003; Medelyan and Witten, 2006; Nguyen and Kan, 2007; Wan and Xiao, 2008). means the collaborative team from Laboratoire d’Informatique de Nantes Atlantique of the Universit´e de Nantes and Laboratoire d’Informatique de Paris 6 of the Universit´e Pierre et Marie Curie. The task of extracting key phrases would be considered as a subtask of extracting terminology if key phrases are a kind of terms. Typical approaches for automatically extracting terms use linguistic preprocessing which involves morphosyntactic analysis such as part-of-speech tagging and phrase chunking, and statistical postprocessing such as log likelihood which compares the term frequencies in a document against their expected frequencies derived in a bigger text. Besides, extracting terms prefers syntactically plausible noun phrases (NPs) which are mainly multiwords terms. Kim and Kan (2009) report that most of key phrases are often simple words than less ofcompound The task for extracting key phrases tend to include analyzing the document structure. Especially, extracting key phrases from well-structured scientific articles should consider cross-section information (Nguyen and Kan, 2007). This information has been explored to assess the suitability of features during learning in Kim and Kan (2009). Extracting key phrases, however, is more than to extracting terminology or analyzing the document structure. While terms are words which appear in specific contexts and analyse concept structures in human activity, key phrases are words capture the key idea of In addition, while terms usually occur in the given document more often than we would expect to occur, key phrases do not necessarily occur frequently or key phrases do not occur at all in the document. Consequently, the task for extracting key phrases should not be considered as the subtask of extracting terminology and we are not able to directly apply general-purpose term extractors to extract key phrases. In this paper, we describe our method for “Au- Keyphrase Extraction from Scientific Artraining data, only 23.4% of keyphrases, however, are single words. 178 of the 5th International Workshop on Semantic Evaluation, ACL pages 178–181, Sweden, 15-16 July 2010. Association for Computational Linguistics ticles”, the shared task of SemEval-2 Evaluation Exercise which we participated in. Although term extractors along with linguisticallymotivated analysis allow us to extract even elaborated morpho-syntactic variation forms of terms, the naive statistic approach proposed in this paper is very simple and quite efficient for extracting keyphrases especially from well-structured scientific articles. In a nutshell, our method is based on empirical rules without any linguisticallymotivated preprocessing. Empirical rules are obtained from the analysis of the characteristics of keyphrases by observing training data. The remaining of this paper is organized as follows: Section 2 explains the characteristics of keyphrases in scientific articles. Section 3 and 4 detail our naive statistic approach and experiment, respectively. We conclude this paper and discuss a further improvement in Section 6. 2 Characteristics of Keyphrases in Scientific Articles In this section, we investigate the characteristics of keyphrases in training data. Table 1 shows statisof training data. In Table 1, keyphrases assigned by authors, assigned by readers, and the combined keyphrases assigned by both of authors and readers. D-author 144 563 3.91 D-reader 144 1,865 12.95 D-combined 144 2,265 15.73 Table 1: Statistics of training data 2.1 Word length of keyphrases We measure the distribution of word length of key phrases in training data and present it in Figure 1. Over half of key phrases are two-word key phrases in both authorand reader-assigned key phrases. Differently with Kim and Kan (2009) which they reported that most of key phrases are often simple words than less often compound words, only 29.7% and 17.7% of key phrases are one-word key phrases. There are also more than four-word key phrases which hold 4.3% and 7.2% of author and reader assigned key phrases, respectively. 2.2 Occurrences of keyphrases In which section do keyphrases occur frequently? To answer this question, we count the number of Figure 1: Word length of keyphrases in training data occurrences of keyphrases of each section. Due to the variation of the naming of the section, we divide sections into title and abstract, introduction, conclusion, and the rest including references. Table 2 and 3 show the number of occurrences and the accumulative number of unique occurrences of keyphrases in each section, respectively. We also show the accumulative number of words in each section in Table 4. Including the rest sections exponentially diminishes the ratio of the number of gold keyphrases to the number candidate keyphrases. Note that prokeyphrases for up keyphrases by supposing that candidate are simple terms. Note also that both authorand reader-assigned keyphrases hold only 75.49% and 89.44%, respectively. Even some keyphrases are different with surface forms in the document and our naive method with no linguistic intervention is not able to recognize them. For example, one of readerkeyphrases real-time embedsystem C-41 actually appears as and embedded (DRE) D-author D-reader</abstract>
<phone confidence="0.7288255">277 802 215 491 313 982 387 1,210</phone>
<abstract confidence="0.50170955">Table 2: Number of occurrences of keyphrases in each section Table 3: Accumulative number of unique occurrences of keyphrases in each section length=1 (29.7%) length=1 (17.7%) length=4+ (4.3%) length=3 (21.8%) length=3 (14.7%) length=2 (51.3%) length=2 (53.2%) length=4+ (7.2%)</abstract>
<intro confidence="0.735433">Title and Abstract</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ken Barker</author>
<author>Nadia Cornacchia</author>
</authors>
<title>Using noun phrase heads to extract document keyphrases.</title>
<date>2000</date>
<booktitle>In Proceedings of the 13th Biennial Conference of the Canadian Society on Computational Studies of Intelligence: Advances in Artificial Intelligence,</booktitle>
<pages>40--52</pages>
<location>Montr´eal, Quebec, Canada.</location>
<marker>Barker, Cornacchia, 2000</marker>
<rawString>Ken Barker and Nadia Cornacchia. 2000. Using noun phrase heads to extract document keyphrases. In Proceedings of the 13th Biennial Conference of the Canadian Society on Computational Studies of Intelligence: Advances in Artificial Intelligence, pages 40-52. May 14-17, 2000. Montr´eal, Quebec, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eibe Frank</author>
<author>Gordon W Paynter</author>
<author>Ian H Witten</author>
<author>Carl Gutwin</author>
<author>Craig G Nevill-Manning</author>
</authors>
<title>Domain-Specific Keyphrase Extraction.</title>
<date>1999</date>
<booktitle>In Proceedings of the 16th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>668--673</pages>
<location>Stockholm,</location>
<contexts>
<context position="1636" citStr="Frank et al., 1999" startWordPosition="234" endWordPosition="237"> of the paper. 1 Introduction1 Key phrases are a set of words to capture the main topic of the document. Since key phrases contain the substance of the document, they are used in the large spectrum of areas; from applications which explicitly use key phrases such as automatic indexing, documents classification and search engine optimization in information retrieval, to applications which implicitly use key phrases such as summarization and question-answering systems. During the last decade, many previous works have dealt with the various methods for automatically extracting key phrases (e.g., Frank et al., 1999; Barker and Corrnacchia, 2000; Turney, 2003; Medelyan and Witten, 2006; Nguyen and Kan, 2007; Wan and Xiao, 2008). 1UNPMC means the collaborative team from Laboratoire d’Informatique de Nantes Atlantique of the Universit´e de Nantes and Laboratoire d’Informatique de Paris 6 of the Universit´e Pierre et Marie Curie. The task of extracting key phrases would be considered as a subtask of extracting terminology if key phrases are a kind of terms. Typical approaches for automatically extracting terms use linguistic preprocessing which involves morphosyntactic analysis such as part-of-speech taggin</context>
</contexts>
<marker>Frank, Paynter, Witten, Gutwin, Nevill-Manning, 1999</marker>
<rawString>Eibe Frank, Gordon W. Paynter, Ian H. Witten, Carl Gutwin, and Craig G. Nevill-Manning. 1999. Domain-Specific Keyphrase Extraction. In Proceedings of the 16th International Joint Conference on Artificial Intelligence, pages 668-673. July 31-August 6, 1999. Stockholm, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Su Nam Kim</author>
<author>Min-Yen Kan</author>
</authors>
<title>Re-examining Automatic Keyphrase Extraction Approaches in Scientific Articles.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: Identification, Interpretation, Disambiguation and Applications (MWE 2009), ACL-IJCNLP 2009,</booktitle>
<pages>9--12</pages>
<contexts>
<context position="2554" citStr="Kim and Kan (2009)" startWordPosition="374" endWordPosition="377">e et Marie Curie. The task of extracting key phrases would be considered as a subtask of extracting terminology if key phrases are a kind of terms. Typical approaches for automatically extracting terms use linguistic preprocessing which involves morphosyntactic analysis such as part-of-speech tagging and phrase chunking, and statistical postprocessing such as log likelihood which compares the term frequencies in a document against their expected frequencies derived in a bigger text. Besides, extracting terms prefers syntactically plausible noun phrases (NPs) which are mainly multiwords terms. Kim and Kan (2009) report that most of key phrases are often simple words than less often compound words2. The task for extracting key phrases tend to include analyzing the document structure. Especially, extracting key phrases from well-structured scientific articles should consider cross-section information (Nguyen and Kan, 2007). This information has been explored to assess the suitability of features during learning in Kim and Kan (2009). Extracting key phrases, however, is more than to extracting terminology or analyzing the document structure. While terms are words which appear in specific contexts and an</context>
<context position="5719" citStr="Kim and Kan (2009)" startWordPosition="873" endWordPosition="876">ng data. In Table 1, D-author means the keyphrases assigned by authors, D-reader the keyphrases assigned by readers, and D-combined the combined keyphrases assigned by both of authors and readers. # of papers (p) # of key phrases (k) k / p D-author 144 563 3.91 D-reader 144 1,865 12.95 D-combined 144 2,265 15.73 Table 1: Statistics of training data 2.1 Word length of keyphrases We measure the distribution of word length of key phrases in training data and present it in Figure 1. Over half of key phrases are two-word key phrases in both author- and reader-assigned key phrases. Differently with Kim and Kan (2009) which they reported that most of key phrases are often simple words than less often compound words, only 29.7% and 17.7% of key phrases are one-word key phrases. There are also more than four-word key phrases which hold 4.3% and 7.2% of author and reader assigned key phrases, respectively. 2.2 Occurrences of keyphrases In which section do keyphrases occur frequently? To answer this question, we count the number of (a) D-author (b) D-reader Figure 1: Word length of keyphrases in training data occurrences of keyphrases of each section. Due to the variation of the naming of the section, we divid</context>
</contexts>
<marker>Kim, Kan, 2009</marker>
<rawString>Su Nam Kim and Min-Yen Kan. 2009. Re-examining Automatic Keyphrase Extraction Approaches in Scientific Articles. In Proceedings of the Workshop on Multiword Expressions: Identification, Interpretation, Disambiguation and Applications (MWE 2009), ACL-IJCNLP 2009, pages 9-12. August 6, 2009. Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olena Medelyan</author>
<author>Ian H Witten</author>
</authors>
<title>Thesaurus based automatic keyphrase indexing.</title>
<date>2006</date>
<booktitle>In Proceedings of the 6th ACM/IEEE-CS joint conference on Digital libraries,</booktitle>
<pages>296--297</pages>
<publisher>Chapel Hill, NC, USA.</publisher>
<contexts>
<context position="1707" citStr="Medelyan and Witten, 2006" startWordPosition="244" endWordPosition="247"> capture the main topic of the document. Since key phrases contain the substance of the document, they are used in the large spectrum of areas; from applications which explicitly use key phrases such as automatic indexing, documents classification and search engine optimization in information retrieval, to applications which implicitly use key phrases such as summarization and question-answering systems. During the last decade, many previous works have dealt with the various methods for automatically extracting key phrases (e.g., Frank et al., 1999; Barker and Corrnacchia, 2000; Turney, 2003; Medelyan and Witten, 2006; Nguyen and Kan, 2007; Wan and Xiao, 2008). 1UNPMC means the collaborative team from Laboratoire d’Informatique de Nantes Atlantique of the Universit´e de Nantes and Laboratoire d’Informatique de Paris 6 of the Universit´e Pierre et Marie Curie. The task of extracting key phrases would be considered as a subtask of extracting terminology if key phrases are a kind of terms. Typical approaches for automatically extracting terms use linguistic preprocessing which involves morphosyntactic analysis such as part-of-speech tagging and phrase chunking, and statistical postprocessing such as log likel</context>
</contexts>
<marker>Medelyan, Witten, 2006</marker>
<rawString>Olena Medelyan and Ian H. Witten. 2006. Thesaurus based automatic keyphrase indexing. In Proceedings of the 6th ACM/IEEE-CS joint conference on Digital libraries, pages 296-297. June 11-15, 2006. Chapel Hill, NC, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thuy Dung Nguyen</author>
<author>Min-Yen Kan</author>
</authors>
<title>Key phrase Extraction in Scientific Publications. Asian Digital Libraries. Looking Back 10 Years and Forging New Frontiers,</title>
<date>2007</date>
<pages>317--326</pages>
<publisher>Springer</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="1729" citStr="Nguyen and Kan, 2007" startWordPosition="248" endWordPosition="251">the document. Since key phrases contain the substance of the document, they are used in the large spectrum of areas; from applications which explicitly use key phrases such as automatic indexing, documents classification and search engine optimization in information retrieval, to applications which implicitly use key phrases such as summarization and question-answering systems. During the last decade, many previous works have dealt with the various methods for automatically extracting key phrases (e.g., Frank et al., 1999; Barker and Corrnacchia, 2000; Turney, 2003; Medelyan and Witten, 2006; Nguyen and Kan, 2007; Wan and Xiao, 2008). 1UNPMC means the collaborative team from Laboratoire d’Informatique de Nantes Atlantique of the Universit´e de Nantes and Laboratoire d’Informatique de Paris 6 of the Universit´e Pierre et Marie Curie. The task of extracting key phrases would be considered as a subtask of extracting terminology if key phrases are a kind of terms. Typical approaches for automatically extracting terms use linguistic preprocessing which involves morphosyntactic analysis such as part-of-speech tagging and phrase chunking, and statistical postprocessing such as log likelihood which compares t</context>
</contexts>
<marker>Nguyen, Kan, 2007</marker>
<rawString>Thuy Dung Nguyen and Min-Yen Kan. 2007. Key phrase Extraction in Scientific Publications. Asian Digital Libraries. Looking Back 10 Years and Forging New Frontiers, pages 317-326. Springer Berlin, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Coherent keyphrase extraction via Web mining.</title>
<date>2003</date>
<booktitle>In Proceedings of the 18th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>434--439</pages>
<location>Acapulco, Mexico.</location>
<contexts>
<context position="1680" citStr="Turney, 2003" startWordPosition="242" endWordPosition="243">et of words to capture the main topic of the document. Since key phrases contain the substance of the document, they are used in the large spectrum of areas; from applications which explicitly use key phrases such as automatic indexing, documents classification and search engine optimization in information retrieval, to applications which implicitly use key phrases such as summarization and question-answering systems. During the last decade, many previous works have dealt with the various methods for automatically extracting key phrases (e.g., Frank et al., 1999; Barker and Corrnacchia, 2000; Turney, 2003; Medelyan and Witten, 2006; Nguyen and Kan, 2007; Wan and Xiao, 2008). 1UNPMC means the collaborative team from Laboratoire d’Informatique de Nantes Atlantique of the Universit´e de Nantes and Laboratoire d’Informatique de Paris 6 of the Universit´e Pierre et Marie Curie. The task of extracting key phrases would be considered as a subtask of extracting terminology if key phrases are a kind of terms. Typical approaches for automatically extracting terms use linguistic preprocessing which involves morphosyntactic analysis such as part-of-speech tagging and phrase chunking, and statistical postp</context>
</contexts>
<marker>Turney, 2003</marker>
<rawString>Peter D. Turney. 2003. Coherent keyphrase extraction via Web mining. In Proceedings of the 18th International Joint Conference on Artificial Intelligence, pages 434-439. August 9-15, 2003. Acapulco, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojun Wan</author>
<author>Jianguo Xiao</author>
</authors>
<title>CollabRank: towards a collaborative approach to single-document keyphrase extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (Coling</booktitle>
<pages>969--976</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="1750" citStr="Wan and Xiao, 2008" startWordPosition="252" endWordPosition="255">y phrases contain the substance of the document, they are used in the large spectrum of areas; from applications which explicitly use key phrases such as automatic indexing, documents classification and search engine optimization in information retrieval, to applications which implicitly use key phrases such as summarization and question-answering systems. During the last decade, many previous works have dealt with the various methods for automatically extracting key phrases (e.g., Frank et al., 1999; Barker and Corrnacchia, 2000; Turney, 2003; Medelyan and Witten, 2006; Nguyen and Kan, 2007; Wan and Xiao, 2008). 1UNPMC means the collaborative team from Laboratoire d’Informatique de Nantes Atlantique of the Universit´e de Nantes and Laboratoire d’Informatique de Paris 6 of the Universit´e Pierre et Marie Curie. The task of extracting key phrases would be considered as a subtask of extracting terminology if key phrases are a kind of terms. Typical approaches for automatically extracting terms use linguistic preprocessing which involves morphosyntactic analysis such as part-of-speech tagging and phrase chunking, and statistical postprocessing such as log likelihood which compares the term frequencies i</context>
</contexts>
<marker>Wan, Xiao, 2008</marker>
<rawString>Xiaojun Wan and Jianguo Xiao. 2008. CollabRank: towards a collaborative approach to single-document keyphrase extraction. In Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 969-976. 18-22 August, 2008. Manchester, UK.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>