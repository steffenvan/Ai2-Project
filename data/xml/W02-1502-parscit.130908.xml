<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.057592">
<title confidence="0.997235">
The Grammar Matrix: An Open-Source Starter-Kit for the Rapid
Development of Cross-Linguistically Consistent Broad-Coverage Precision
Grammars
</title>
<author confidence="0.981089">
Emily M. Bender and Dan Flickinger and Stephan Oepen
</author>
<affiliation confidence="0.977947">
Center for the Study of Language and Information
Stanford University
</affiliation>
<email confidence="0.998485">
{benderldanloe}@csli.stanford.edu
</email>
<sectionHeader confidence="0.993887" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999724">
The grammar matrix is an open-source
starter-kit for the development of broad-
coverage HPSGs. By using a type hierar-
chy to represent cross-linguistic generaliza-
tions and providing compatibility with other
open-source tools for grammar engineering,
evaluation, parsing and generation, it facil-
itates not only quick start-up but also rapid
growth towards the wide coverage necessary
for robust natural language processing and
the precision parses and semantic represen-
tations necessary for natural language under-
standing.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999570339285714">
The past decade has seen the development of
wide-coverage implemented grammars represent-
ing deep linguistic analysis of several languages
in several frameworks, including Head-Driven
Phrase Structure Grammar (HPSG), Lexical-
Functional Grammar (LFG), and Lexicalized Tree
Adjoining Grammar (LTAG). In HPSG, the most ex-
tensive grammars are those of English (Flickinger,
2000), German (M¨uller &amp; Kasper, 2000), and
Japanese (Siegel, 2000; Siegel &amp; Bender, 2002).
Despite being couched in the same general frame-
work and in some cases being written in the
same formalism and consequently being compati-
ble with the same parsing and generation software,
these grammars were developed more or less inde-
pendently of each other. They each represent be-
tween 5 and 15 person years of research efforts,
and comprise 35–70,000 lines of code. Unfor-
tunately, most of that research is undocumented
and the accumulated analyses, best practices for
grammar engineering, and tricks of the trade are
only available through painstaking inspection of
the grammars and/or consultation with their au-
thors. This lack of documentation holds across
frameworks, with certain notable exceptions, in-
cluding Alshawi (1992), M¨uller (1999), and Butt,
King, Ni˜no, &amp; Segond (1999).
Grammars which have been under development
for many years tend to be very difficult to mine for
information, as they contain layers upon layers of
interacting analyses and decisions made in light of
various intermediate stages of the grammar. As a
result, when embarking on the creation of a new
grammar for another language, it seems almost
easier to start from scratch than to try to model it on
an existing grammar. This is unfortunate—being
able to leverage the knowledge and infrastructure
embedded in existing grammars would greatly ac-
celerate the process of developing new ones. At the
same time, these grammars represent an untapped
resource for the bottom-up exploration of language
universals.
As part of the LinGO consortium’s multi-lingual
grammar engineering effort, we are developing a
‘grammar matrix’ or starter-kit, distilling the wis-
dom of existing grammars and codifying and doc-
umenting it in a form that can be used as the basis
for new grammars.
In the following sections, we outline the inven-
tory of a first, preliminary version of the grammar
matrix, discuss the interaction of basic construc-
tion types and semantic composition in unification
grammars by means of a detailed example, and
consider extensions to the core inventory that we
foresee and an evaluation methodology for the ma-
trix proper.
</bodyText>
<sectionHeader confidence="0.982933" genericHeader="method">
2 Preliminary Development of Matrix
</sectionHeader>
<bodyText confidence="0.997078142857143">
We have produced a preliminary version of the
grammar matrix relying heavily on the LinGO
project’s English Resource Grammar, and to a
lesser extent on the Japanese grammar developed
jointly between DFKI Saarbr¨ucken (Germany) and
YY Technologies (Mountain View, CA). This early
version of the matrix comprises the following com-
</bodyText>
<listItem confidence="0.91963421875">
ponents:
• Types defining the basic feature geometry and
technical devices (e.g., for list manipulation).
• Types associated with Minimal Recursion Se-
mantics (see, e.g., Copestake, Lascarides, &amp;
Flickinger, 2001), a meaning representation
language which has been shown to be well-
suited for semantic composition in typed fea-
ture structure grammars. This portion of the
grammar matrix includes a hierarchy of rela-
tion types, types and constraints for the prop-
agation of semantic information through the
phrase structure tree, a representation of illo-
cutionary force, and provisions for grammar
rules which make semantic contributions.
• General classes of rules, including deriva-
tional and inflectional (lexical) rules, unary
and binary phrase structure rules, headed and
non-headed rules, and head-initial and head-
final rules. These rule classes include im-
plementations of general principles of HPSG,
like, for example, the Head Feature and Non-
Local Feature Principles.
• Types for basic constructions such as head-
complement, head-specifier, head-subject,
head-filler, and head-modifier rules, coordi-
nation, as well as more specialized classes
of constructions, such as relative clauses and
noun-noun compounding. Unlike in specific
grammars, these types do not impose any or-
dering on their daughters in the grammar ma-
trix.
</listItem>
<bodyText confidence="0.99977805">
Included with the matrix are configuration and
parameter files for the LKB grammar engineering
environment (Copestake, 2002).
Although small, this preliminary version of
the matrix already reflects the main goals of
the project: (i) Consistent with other work in
HPSG, semantic representations and in particular
the syntax-semantics interface are developed in de-
tail; (ii) the types of the matrix are each represen-
tations of generalizations across linguistic objects
and across languages; and (iii) the richness of the
matrix and the incorporation of files which connect
it with the LKB allow for extremely quick start-up
as the matrix is applied to new languages.
Since February 2002, this preliminary version of
the matrix has been in use at two Norwegian uni-
versities, one working towards a broad-coverage
reference implementation of Norwegian (NTNU),
the other—for the time being—focused on specific
aspects of clause structure and lexical description
(Oslo University). In the first experiment with
the matrix, at NTNU, basic Norwegian sentences
were parsing and producing reasonable semantics
within two hours of downloading the matrix files.
Linguistic coverage should scale up quickly, since
the foundation supplied by the matrix is designed
not only to provide a quick start, but also to support
long-term development of broad-coverage gram-
mars. Both initiatives have confirmed the utility of
the matrix starter kit and already have contributed
to a series of discussions on cross-lingual HPSG
design aspects, specifically in the areas of argu-
ment structure representations in the lexicon and
basic assumptions about constituent structure (in
one view, Norwegian exhibits a VSO topology in
the main clause). The user groups have suggested
refinements and extensions of the basic inventory,
and it is expected that general solutions, as they are
identified jointly, will propagate into the existing
grammars too.
</bodyText>
<sectionHeader confidence="0.992304" genericHeader="method">
3 A Detailed Example
</sectionHeader>
<bodyText confidence="0.9994879">
As an example of the level of detail involved in
the grammar matrix, in this section we consider
the analysis of intersective and scopal modifica-
tion. The matrix is built to give Minimal Recursion
Semantics (MRS; Copestake et al., 2001; Copes-
take, Flickinger, Sag, &amp; Pollard, 1999; Copestake,
Flickinger, Malouf, Riehemann, &amp; Sag, 1995) rep-
resentations. The two English examples in (1)
exemplify the difference between intersective and
scopal modification:1
</bodyText>
<listItem confidence="0.9883105">
(1) a. Keanu studied Kung Fu on a spaceship.
b. Keanu probably studied Kung Fu.
</listItem>
<bodyText confidence="0.994224214285714">
The MRSs for (1a-b) (abstracting away from
agreement information) are given in (2) and (3).
The MRSs are ordered tuples consisting of a top
handle (h1 in both cases), an instance or event vari-
able (e in both cases), a bag of elementary predica-
tions (eps), and a bag of scope constraints (in these
cases, QEQ constraints or ‘equal modulo quanti-
fiers’). In a well-formed MRS, the handles can be
1These examples also differ in that probably is a pre-
head modifier while on a spaceship is a post-head modifier.
This word-order distinction cross-cuts the semantic distinc-
tion, and our focus is on the latter, so we won’t consider the
word-order aspects of these examples here.
identified in one or more ways respecting the scope
constraints such that the dependencies between the
eps form a tree. For a detailed description of MRS,
see the works cited above. Here, we will focus on
the difference between the intersective modifier on
(a spaceship) and the scopal modifier probably.
In (2), the ep contributed by on (‘on-rel’) shares
its handle (h7) with the ep contributed by the verb
it is modifying (‘study-rel’). As such, the two will
always have the same scope; no quantifier can in-
tervene. Further, the second argument of the on-rel
(e) is the event variable of the study-rel. The first
argument, e&apos;, is the event variable of the on-rel and
the third argument, z, is the instance variable of the
spaceship-rel.
</bodyText>
<equation confidence="0.951365555555555">
(2)( h1, e,
{ h1:prpstn-rel(h2), h3:def-np-rel(x, h4, h5),
h6:named-rel(x, ‘Keanu’), h7:study-rel(e, x, y),
h8:def-np-rel(y, h9, h10),
h11:named-rel(y, ‘Kung Fu’), h7:on-rel(e&apos;, e, z),
h12:a-quant-rel(z, h13, h14),
h15:spaceship-rel(z) },
{ h2 QEQ h7, h4 QEQ h6, h19 QEQ h11,
h13 QEQ h15 } )
</equation>
<bodyText confidence="0.99954375">
In (3), the ep contributed by the scopal modifier
probably (‘probably-rel’) has its own handle (h7)
which is not shared by anything. Furthermore, it
takes a handle (h8) rather than the event variable
of the study-rel as its argument. h8 is equal mod-
ulo quantifiers (QEQ) to the handle of the study-rel
(h9), and h7 is equal modulo quantifiers to the ar-
gument of the prpstn-rel (h2). The prpstn-rel is the
ep representing the illocutionary force of the whole
expression. This means that quantifiers associated
with the NPs Keanu and Kung Fu can scope inside
or outside probably.
</bodyText>
<construct confidence="0.944310625">
(3)( h1, e,
{ h1:prpstn-rel(h2), h3:def-np-rel(x, h4, h5),
h6:named-rel(x, ‘Keanu’),
h7:probably-rel(h8), h9:study-rel(e, x, y),
h10:def-np-rel(y, h11, h12),
h13:named-rel(y, ‘Kung Fu’) },
{ h2 QEQ h7, h4 QEQ h6, h8 QEQ h9,
h11 QEQ h13 } )
</construct>
<bodyText confidence="0.9998526">
While the details of modifier placement, which
parts of speech can modify which kinds of phrases,
etc., differ across languages, we believe that all
languages display a distinction between scopal and
intersective modification. Accordingly, the types
</bodyText>
<equation confidence="0.784775">
isect-mod-phrase := head-mod-phr-simple &amp;
[ HEAD-DTR.SYNSEM.LOCAL
[ CONT [ TOP #hand,
INDEX #index ],
KEYS.MESSAGE 0-dlist ],
NON-HEAD-DTR.SYNSEM.LOCAL
[ CAT.HEAD.MOD &lt;[ LOCAL isect-mod ]&gt;,
CONT.TOP #hand ],
C-CONT.INDEX #index ].
</equation>
<figureCaption confidence="0.985599">
Figure 1: TDL description of isect-mod-phrase
</figureCaption>
<figure confidence="0.8956398">
scopal-mod-phrase := head-mod-phr-simple &amp;
[ NON-HEAD-DTR.SYNSEM.LOCAL
[ CAT.HEAD.MOD &lt;[ LOCAL scopal-mod ]&gt;,
CONT.INDEX #index ],
C-CONT.INDEX #index ].
</figure>
<figureCaption confidence="0.998722">
Figure 2: TDL description of scopal-mod-phrase
</figureCaption>
<bodyText confidence="0.9999324">
necessary for describing these two kinds of modi-
fication are included in the matrix.
The types isect-mod-phrase and scopal-mod-
phrase (shown in Figures 1 and 2) encode the in-
formation necessary to build up in a compositional
manner the modifier portions of the MRSs in (2)
and (3).
These types are embedded in the type hierar-
chy of the matrix. Through their supertype head-
mod-phr-simple they inherit information common
to many types of phrases, including the basic fea-
ture geometry, head feature and non-local feature
passing, and semantic compositionality. These
types also have subtypes in the matrix specifying
the two word-order possibilities (pre- or post-head
modifiers), giving a total of four subtypes.2
The most important difference between these
types is in the treatment of the handle of the head
daughter’s semantics, to distinguish intersective
and scopal modification. In isect-mod-phrase, the
top handles (TOP) of the head and non-head (i.e.,
modifier) daughters are identified (#hand). This
allows for MRSs like (2) where the eps contributed
by the head (‘study-rel’) and the modifier (‘on-rel’)
take the same scope. The type scopal-mod-phrase
bears no such constraint. This allows for MRSs
like (3) where the modifier’s semantic contribution
(‘probably-rel’) takes the handle of the head’s se-
mantics (‘study-rel’) as its argument, so that the
modifier outscopes the head. In both types of mod-
</bodyText>
<footnote confidence="0.8011665">
2All four subtypes are provided on the theory that most
languages will make use of all or most of them.
</footnote>
<bodyText confidence="0.999714130434783">
ifier phrase, a constraint inherited from the super-
type ensures that the handle of the modifier is also
the handle of the whole phrase.
The constraints on the LOCAL value inside
the modifier’s MOD value regulate which lexi-
cal items can appear in which kind of phrase.
Intersective modifiers specify lexically that they
are [ MOD ( [ LOCAL isect-mod ] )] and sco-
pal modifiers specify lexically that they are
[ MOD ( [ LOCAL scopal-mod ] )].3 These con-
straints exemplify the kind of information that will
be developed in the lexical hierarchy of the matrix.
It is characteristic of broad-coverage grammars
that every particular analysis interacts with many
other analyses. Modularization is an on-going con-
cern, both for maintainability of individual gram-
mars, and for providing the right level of abstrac-
tion in the matrix. For the same reasons, we have
only been able to touch on the highlights of the se-
mantic analysis of modification here, but hope that
this quick tour will suffice to illustrate the extent
of the jump-start the matrix can give in the devel-
opment of new grammars.
</bodyText>
<sectionHeader confidence="0.995884" genericHeader="method">
4 Future Extensions
</sectionHeader>
<bodyText confidence="0.999916761904762">
The initial version of the matrix, while sufficient to
support some useful grammar work, will require
substantial further development on several fronts,
including lexical representation, syntactic gener-
alization, sociolinguistic variation, processing is-
sues, and evaluation. This first version drew most
heavily from the implementation of the English
grammar, with some further insights drawn from
the grammar of Japanese. Extensions to the ma-
trix will be based on careful study of existing im-
plemented grammars for other languages, notably
German, Spanish and Japanese, as well as feed-
back from those using the first version of the ma-
trix.
For lexical representation, one of the most ur-
gent needs is to provide a language-independent
type hierarchy for the lexicon, at least for major
parts of speech, establishing the mechanisms used
for linking syntactic subcategorization to seman-
tic predicate-argument structure. Lexical rules pro-
vide a second mechanism for expressing general-
</bodyText>
<footnote confidence="0.9430234">
3Note that there are no further subtypes of LOCAL values
beyond isect-mod and scopal-mod. Since these grammars do
not make extensive use of subtypes of LOCAL values, they
were available for encoding this distinction. Alternative solu-
tions include positing a new feature.
</footnote>
<bodyText confidence="0.999891510204082">
izations within the lexicon, and offer ready oppor-
tunities for cross-linguistic abstractions for both
inflectional and derivational regularities. Work is
also progressing on establishing a standard rela-
tional database (using PostgreSQL) for storing in-
formation for the lexical entries themselves, im-
proving both scalability and clarity compared to
the current simple text file representation. Form-
based tools will be provided both for constructing
lexical entries and for viewing the contents of the
lexicon.
The primary focus of work on syntactic general-
ization in the matrix is to support more freedom
in word order, for both complements and modi-
fiers. The first step will be a relatively conserva-
tive extension along the lines of Netter (1996), al-
lowing the grammar writer more control over how
a head combines with complements of different
types, and their interleaving with modifier phrases.
Other areas of immediate cross-linguistic interest
include the hierarchy of head types, control phe-
nomena, clitics, auxiliary verbs, noun-noun com-
pounds, and more generally, phenomena that in-
volve the word/phrase distinction, such as noun in-
corporation. A study of the existing grammars for
English, German, Japanese, and Spanish reveals
a high degree of language-specificity for several
of these phenomena, but also suggests promise of
reusable abstractions.
Several kinds of sociolinguistic variation require
extensions to the matrix, including grammaticized
aspects of pragmatics such as politeness and em-
pathy, as well as dialect and register alternations.
The grammar of Japanese provides a starting point
for representations of both empathy and politeness.
Implementations of familiar vs. formal verb forms
in German and Spanish provide further instances
of politeness to help build the cross-linguistic ab-
stractions. Extensions for dialect variation will
build on some exploratory work in adapting the
English grammar to support American, British,
and Australian regionalisms, both lexical and syn-
tactic, while restricting dialect mixture in genera-
tion and associated spurious ambiguity in parsing.
While the development of the matrix will be
built largely on the LKB platform, support will also
be needed for using the emerging grammars on
other processing platforms, and for linking to other
packages for pre-processing the linguistic input.
Several other platforms exist which can efficiently
parse text using the existing grammars, includ-
ing the PET system developed in C++ at Saarland
University (Germany) and the DFKI (Callmeier,
2000); the PAGE system developed in Lisp at the
DFKI (Uszkoreit et al., 1994); the LiLFeS system
developed at Tokyo University (Makino, Yoshida,
Torisawa, &amp; Tsujii, 1998), and a parallel process-
ing system developed in Objective C at Delft Uni-
versity (The Netherlands; van Lohuizen, 2002).
As part of the matrix package, sample configura-
tion files and documentation will be provided for
at least some of these additional platforms.
Existing pre-processing packages can also sig-
nificantly reduce the effort required to develop
a new grammar, particularly for coping with the
morphology/syntax interface. For example, the
ChaSen package for segmenting Japanese input
into words and morphemes (Asahara &amp; Mat-
sumoto, 2000) has been linked to at least the LKB
and PET systems. Support for connecting im-
plementations of language-specific pre-processing
packages of this kind will be preserved and ex-
tended as the matrix develops. Likewise, config-
uration files are included to support generation, at
least within the LKB, provided that the grammar
conforms to certain assumptions about semantic
representation using the Minimal Recursion Se-
mantics framework.
Finally, a methodology is under development for
constructing and using test suites organized around
a typology of linguistic phenomena, using the im-
plementation platform of the [incr tsdbo)] profil-
ing package (Oepen &amp; Flickinger, 1998; Oepen
&amp; Callmeier, 2000). These test suites will enable
better communication about current coverage of a
given grammar built using the matrix, and serve as
the basis for identifying additional phenomena that
need to be addressed cross-linguistically within the
matrix. Of course, the development of the typol-
ogy of phenomena is itself a major undertaking
for which a systematic cross-linguistic approach
will be needed, a discussion of which is outside
the scope of this report. But the intent is to seed
this classification scheme with a set of relatively
coarse-grained phenomenon classes drawn from
the existing grammars, then refine the typology as
it is applied to these and new grammars built using
the matrix.
</bodyText>
<sectionHeader confidence="0.867077" genericHeader="method">
5 Case Studies
</sectionHeader>
<bodyText confidence="0.999843263157895">
One important part of the matrix package will be a
library of phenomenon-based analyses drawn from
the existing grammars and over time from users of
the matrix, to provide working examples of how
the matrix can be applied and extended. Each case
study will be a set of grammar files, simplified for
relevance, along with documentation of the anal-
ysis, and a test suite of sample sentences which
define the range of data covered by the analysis.
This library, too, will be organized around the ty-
pology of phenomena introduced above, but will
also make explicit reference to language families,
since both similarities and differences among re-
lated languages will be of interest in these case
studies. Examples to be included in the first re-
lease of this library include numeral classifiers in
Japanese, subject pro drop in Spanish, partial-VP
fronting in German, and verb diathesis in Norwe-
gian.
</bodyText>
<sectionHeader confidence="0.986192" genericHeader="evaluation">
6 Evaluation and Evolution
</sectionHeader>
<bodyText confidence="0.999986349206349">
The matrix itself is not a grammar but a collec-
tion of generalizations across grammars. As such,
it cannot be tested directly on corpora from partic-
ular languages, and we must find other means of
evaluation. We envision overall evaluation of the
matrix based on case studies of its performance
in helping grammar engineers quickly start new
grammars and in helping them scale those gram-
mars up. Evaluation in detail will based on au-
tomatable deletion/substitution metrics, i.e., tools
that determine which types from the matrix get
used as is, which get used with modifications, and
which get ignored in various matrix-derived gram-
mars. Furthermore, if the matrix evolves to include
defeasible constraints, these tools will check which
constraints get overridden and whether the value
chosen is indeed common enough to be motivated
as a default value. This evaluation in detail should
be paired with feedback from the grammar engi-
neers to determine why changes were made.
The main goal of evaluation is, of course, to im-
prove the matrix over time. This raises the ques-
tion of how to propagate changes in the matrix to
grammars based on earlier versions. The following
three strategies (meant to be used in combination)
seem promising: (i) segregate changes that are im-
portant to sync to (e.g., changes that affect MRS
outputs, fundamental changes to important anal-
yses), (ii) develop a methodology for communi-
cating changes in the matrix, their motivation and
their implementation to the user community, and
(iii) develop tools for semi-automating resynching
of existing grammars to upgrades of the matrix.
These tools could use the type hierarchy to predict
where conflicts are likely to arise and bring these
to the engineer’s attention, possibly inspired by the
approach under development at CSLI for the dy-
namic maintenance of the LinGO Redwoods tree-
bank (Oepen et al., 2002).
Finally, while initial development of the ma-
trix has been and will continue to be highly cen-
tralized, we hope to provide support for proposed
matrix improvements from the user community.
User feedback will already come in the form of
case studies for the library as discussed in Sec-
tion 5 above, but also potentially in proposals for
modification of the matrix drawing on experiences
in grammar development. In order to provide
users with some cross-linguistic context in which
to develop and evaluate such proposals themselves,
we intend to provide some sample matrix-derived
grammars and corresponding testsuites with the
matrix. A user could thus make a proposed change
to the matrix, run the testsuites for several lan-
guages using the supplied grammars which draw
from that changed matrix, and use [incr tsdbo)]
to determine which phenomena have been affected
by the change. It is clear that full automation of
this evaluation process will be difficult, but at least
some classes of changes to the matrix will per-
mit this kind of quick cross-linguistic feedback to
users with only a modest amount of additional in-
frastructure.
</bodyText>
<sectionHeader confidence="0.990779" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999996952380953">
This project carries linguistic, computational, and
practical interest. The linguistic interest lies in the
HPSG community’s general bottom-up approach
to language universals, which involves aiming for
good coverage of a variety of languages first, and
leaving the task of what they have in common for
later. (Of course, theory building is never purely
data-driven, and there are substantive hypotheses
within HPSG about language universals.) Now
that we have implementations with fairly extensive
coverage for a somewhat typologically diverse set
of languages, it is a good time to take the next step
in this program, working to extract and generalize
what is similar across these existing wide-coverage
grammars. Moreover, the central role of types in
the representation of linguistic generalizations en-
ables the kind of underspecification which is useful
for expressing what is common among related lan-
guages while allowing for the further specializa-
tion which necessarily distinguishes one language
from another.
The computational interest is threefold. First
there is the question of what formal devices the
grammar matrix will require. Should it include
defaults? What about domain union (linearization
theory)? The selection and deployment of formal
devices should be informed by on-going research
on processing schemes, and here the crosslinguis-
tic perspective can be particularly helpful. Where
there are several equivalent analyses of the same
linguistic phenomena (e.g., morphosyntactic am-
biguity or optionality), the choice of analysis can
have processing implications that aren’t necessar-
ily apparent in a single grammar. Second, having
a set ofwide-coverage HPSGs with fairly standard-
ized fundamentals could prove interesting for re-
search on stochastic processing and disambigua-
tion, especially if the languages differ in gross ty-
pological features such as word order. Finally,
there are also computational issues involved in
how the grammar matrix would evolve over time
as it is used in new grammars. The matrix en-
ables the developer of a grammar for a new lan-
guage to get a quick start on producing a system
that parses and generates with non-trivial seman-
tics, while also building the foundation for a wide-
coverage grammar of the language. But the matrix
itself may well change in parallel with the devel-
opment of the grammar for a particular language,
so appropriate mechanisms must be developed to
support the merging of enhancements to both.
There is also practical industrial benefit to this
project. Companies that are consumers of these
grammars benefit when grammars of multiple lan-
guages work with the same parsing and generation
algorithms and produce standardized semantic rep-
resentations derived from a rich, linguistically mo-
tivated syntax-semantics interface. More impor-
tantly, the grammar matrix will help to remove one
of the primary remaining obstacles to commercial
deployment of grammars of this type and indeed of
the commercial use of deep linguistic analysis: the
immense cost of developing the resource.
</bodyText>
<sectionHeader confidence="0.997037" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999867866666667">
Since the grammar matrix draws on prior re-
search and existing grammars, it necessarily re-
flects contributions from many people. Rob
Malouf, Jeff Smith, John Beavers, and Kathryn
Campbell-Kibler have contributed to the LinGO
ERG; Melanie Siegel is the original developer for
the Japanese grammar. Tim Baldwin, Ann Copes-
take, Ivan Sag, Tom Wasow, and other members
of the LinGO Laboratory at CSLI have had a great
deal of influence on the design of the grammatical
analyses and corresponding MRS representations.
Warmest thanks to Lars Hellan and his colleagues
at NTNU and Jan Tore Lønning and his students
at Oslo University for their cooperation, patience,
and tolerance.
</bodyText>
<sectionHeader confidence="0.998542" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999784336956522">
Alshawi, H. (Ed.). (1992). The Core Language Engine.
Cambridge, MA: MIT Press.
Asahara, M., &amp; Matsumoto, Y. (2000). Extended mod-
els and tools for high-performance part-of-speech
tagger. In Proceedings of the 18th International
Conference on Computational Linguistics (pp. 21 –
27). Saarbr¨ucken, Germany.
Butt, M., King, T. H., Ni˜no, M.-E., &amp; Segond, F.
(1999). A grammar writer’s cookbook. Stanford,
CA: CSLI Publications.
Callmeier, U. (2000). PET — A platform for ex-
perimentation with efficient HPSG processing tech-
niques. Natural Language Engineering, 6 (1) (Spe-
cial Issue on Efficient Processing with HPSG), 99 –
108.
Copestake, A. (2002). Implementing typed feature
structure grammars. Stanford, CA: CSLI Publica-
tions.
Copestake, A., Flickinger, D., Malouf, R., Riehemann,
S., &amp; Sag, I. (1995). Translation using minimal re-
cursion semantics. In Proceedings of the Sixth In-
ternational Conference on Theoretical and Method-
ological Issues in Machine Translation. Leuven,
Belgium.
Copestake, A., Flickinger, D. P., Sag, I. A., &amp; Pol-
lard, C. (1999). Minimal Recursion Semantics. An
introduction. in preparation, CSLI Stanford, Stan-
ford, CA.
Copestake, A., Lascarides, A., &amp; Flickinger, D. (2001).
An algebra for semantic construction in constraint-
based grammars. In Proceedings of the 39th Meet-
ing of the Association for Computational Linguistics.
Toulouse, France.
Flickinger, D. (2000). On building a more efficient
grammar by exploiting types. Natural Language En-
gineering, 6 (1) (Special Issue on Efficient Process-
ing with HPSG), 15 – 28.
van Lohuizen, M. (2002). Efficient and thread-safe
unification with LinGO. In S. Oepen, D. Flickinger,
J. Tsujii, &amp; H. Uszkoreit (Eds.), Collaborative
language engineering. A case study in efficient
grammar-based processing. Stanford, CA: CSLI
Publications. (forthcoming)
Makino, T., Yoshida, M., Torisawa, K., &amp; Tsujii, J.
(1998). LiLFeS — towards a practical HPSG parser.
In Proceedings of the 17th International Conference
on Computational Linguistics and the 36th Annual
Meeting of the Association for Computational Lin-
guistics (pp. 807 – 11). Montreal, Canada.
M¨uller, S. (1999). Deutsche syntax deklarativ. Head-
Driven Phrase Structure Grammarf¨ur das Deutsche.
T¨ubingen, Germany: Max Niemeyer Verlag.
M¨uller, S., &amp; Kasper, W. (2000). HPSG analysis of
German. In W. Wahlster (Ed.), Verbmobil. Foun-
dations of speech-to-speech translation (Artificial
Intelligence ed., pp. 238 – 253). Berlin, Germany:
Springer.
Netter, K. (1996). Functional categories in an HPSG
for German. Unpublished doctoral dissertation,
Saarland University, Saarbr¨ucken, Germany.
Oepen, S., &amp; Callmeier, U. (2000). Measure for mea-
sure: Parser cross-fertilization. Towards increased
component comparability and exchange. In Pro-
ceedings of the 6th International Workshop on Pars-
ing Technologies (pp. 183 – 194). Trento, Italy.
Oepen, S., &amp; Flickinger, D. P. (1998). Towards sys-
tematic grammar profiling. Test suite technology ten
years after. Journal of Computer Speech and Lan-
guage, 12 (4) (Special Issue on Evaluation), 411 –
436.
Oepen, S., Toutanova, K., Shieber, S., Manning, C.,
Flickinger, D., &amp; Brants, T. (2002). The LinGO
Redwoods treebank. Motivation and preliminary ap-
plications. In Proceedings of the 19th International
Conference on Computational Linguistics. Taipei,
Taiwan.
Siegel, M. (2000). HPSG analysis of Japanese.
In W. Wahlster (Ed.), Verbmobil. Foundations of
speech-to-speech translation (Artificial Intelligence
ed., pp. 265 – 280). Berlin, Germany: Springer.
Siegel, M., &amp; Bender, E. M. (2002). Efficient deep
processing of japanese. In Proceedings of the 19th
International Conference on Computational Linguis-
tics. Taipei, Taiwan.
Uszkoreit, H., Backofen, R., Busemann, S., Diagne,
A. K., Hinkelman, E. A., Kasper, W., Kiefer, B.,
Krieger, H.-U., Netter, K., Neumann, G., Oepen, S.,
&amp; Spackman, S. P. (1994). DISCO — an HPSG-
based NLP system and its application for appoint-
ment scheduling. In Proceedings of the 15th Inter-
national Conference on Computational Linguistics.
Kyoto, Japan.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.416306">
<title confidence="0.997252333333333">The Grammar Matrix: An Open-Source Starter-Kit for the Development of Cross-Linguistically Consistent Broad-Coverage Precision Grammars</title>
<author confidence="0.999451">M Bender Flickinger</author>
<affiliation confidence="0.7195985">Center for the Study of Language and Stanford</affiliation>
<abstract confidence="0.993528857142857">The grammar matrix is an open-source starter-kit for the development of broad- By using a type hierarchy to represent cross-linguistic generalizations and providing compatibility with other open-source tools for grammar engineering, evaluation, parsing and generation, it facilitates not only quick start-up but also rapid growth towards the wide coverage necessary for robust natural language processing and the precision parses and semantic representations necessary for natural language understanding.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H Alshawi</author>
</authors>
<title>The Core Language Engine.</title>
<date>1992</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="2030" citStr="Alshawi (1992)" startWordPosition="289" endWordPosition="290">uently being compatible with the same parsing and generation software, these grammars were developed more or less independently of each other. They each represent between 5 and 15 person years of research efforts, and comprise 35–70,000 lines of code. Unfortunately, most of that research is undocumented and the accumulated analyses, best practices for grammar engineering, and tricks of the trade are only available through painstaking inspection of the grammars and/or consultation with their authors. This lack of documentation holds across frameworks, with certain notable exceptions, including Alshawi (1992), M¨uller (1999), and Butt, King, Ni˜no, &amp; Segond (1999). Grammars which have been under development for many years tend to be very difficult to mine for information, as they contain layers upon layers of interacting analyses and decisions made in light of various intermediate stages of the grammar. As a result, when embarking on the creation of a new grammar for another language, it seems almost easier to start from scratch than to try to model it on an existing grammar. This is unfortunate—being able to leverage the knowledge and infrastructure embedded in existing grammars would greatly acc</context>
</contexts>
<marker>Alshawi, 1992</marker>
<rawString>Alshawi, H. (Ed.). (1992). The Core Language Engine. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Asahara</author>
<author>Y Matsumoto</author>
</authors>
<title>Extended models and tools for high-performance part-of-speech tagger.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics (pp. 21 – 27).</booktitle>
<location>Saarbr¨ucken, Germany.</location>
<contexts>
<context position="17949" citStr="Asahara &amp; Matsumoto, 2000" startWordPosition="2758" endWordPosition="2762">system developed at Tokyo University (Makino, Yoshida, Torisawa, &amp; Tsujii, 1998), and a parallel processing system developed in Objective C at Delft University (The Netherlands; van Lohuizen, 2002). As part of the matrix package, sample configuration files and documentation will be provided for at least some of these additional platforms. Existing pre-processing packages can also significantly reduce the effort required to develop a new grammar, particularly for coping with the morphology/syntax interface. For example, the ChaSen package for segmenting Japanese input into words and morphemes (Asahara &amp; Matsumoto, 2000) has been linked to at least the LKB and PET systems. Support for connecting implementations of language-specific pre-processing packages of this kind will be preserved and extended as the matrix develops. Likewise, configuration files are included to support generation, at least within the LKB, provided that the grammar conforms to certain assumptions about semantic representation using the Minimal Recursion Semantics framework. Finally, a methodology is under development for constructing and using test suites organized around a typology of linguistic phenomena, using the implementation platf</context>
</contexts>
<marker>Asahara, Matsumoto, 2000</marker>
<rawString>Asahara, M., &amp; Matsumoto, Y. (2000). Extended models and tools for high-performance part-of-speech tagger. In Proceedings of the 18th International Conference on Computational Linguistics (pp. 21 – 27). Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Butt</author>
<author>T H King</author>
<author>M-E Ni˜no</author>
<author>F Segond</author>
</authors>
<title>A grammar writer’s cookbook.</title>
<date>1999</date>
<publisher>CSLI Publications.</publisher>
<location>Stanford, CA:</location>
<marker>Butt, King, Ni˜no, Segond, 1999</marker>
<rawString>Butt, M., King, T. H., Ni˜no, M.-E., &amp; Segond, F. (1999). A grammar writer’s cookbook. Stanford, CA: CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Callmeier</author>
</authors>
<title>PET — A platform for experimentation with efficient HPSG processing techniques.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<booktitle>(Special Issue on Efficient Processing with HPSG), 99 –</booktitle>
<volume>6</volume>
<issue>1</issue>
<pages>108</pages>
<contexts>
<context position="17238" citStr="Callmeier, 2000" startWordPosition="2652" endWordPosition="2653">ort American, British, and Australian regionalisms, both lexical and syntactic, while restricting dialect mixture in generation and associated spurious ambiguity in parsing. While the development of the matrix will be built largely on the LKB platform, support will also be needed for using the emerging grammars on other processing platforms, and for linking to other packages for pre-processing the linguistic input. Several other platforms exist which can efficiently parse text using the existing grammars, including the PET system developed in C++ at Saarland University (Germany) and the DFKI (Callmeier, 2000); the PAGE system developed in Lisp at the DFKI (Uszkoreit et al., 1994); the LiLFeS system developed at Tokyo University (Makino, Yoshida, Torisawa, &amp; Tsujii, 1998), and a parallel processing system developed in Objective C at Delft University (The Netherlands; van Lohuizen, 2002). As part of the matrix package, sample configuration files and documentation will be provided for at least some of these additional platforms. Existing pre-processing packages can also significantly reduce the effort required to develop a new grammar, particularly for coping with the morphology/syntax interface. For</context>
<context position="18643" citStr="Callmeier, 2000" startWordPosition="2865" endWordPosition="2866">mplementations of language-specific pre-processing packages of this kind will be preserved and extended as the matrix develops. Likewise, configuration files are included to support generation, at least within the LKB, provided that the grammar conforms to certain assumptions about semantic representation using the Minimal Recursion Semantics framework. Finally, a methodology is under development for constructing and using test suites organized around a typology of linguistic phenomena, using the implementation platform of the [incr tsdbo)] profiling package (Oepen &amp; Flickinger, 1998; Oepen &amp; Callmeier, 2000). These test suites will enable better communication about current coverage of a given grammar built using the matrix, and serve as the basis for identifying additional phenomena that need to be addressed cross-linguistically within the matrix. Of course, the development of the typology of phenomena is itself a major undertaking for which a systematic cross-linguistic approach will be needed, a discussion of which is outside the scope of this report. But the intent is to seed this classification scheme with a set of relatively coarse-grained phenomenon classes drawn from the existing grammars,</context>
</contexts>
<marker>Callmeier, 2000</marker>
<rawString>Callmeier, U. (2000). PET — A platform for experimentation with efficient HPSG processing techniques. Natural Language Engineering, 6 (1) (Special Issue on Efficient Processing with HPSG), 99 – 108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
</authors>
<title>Implementing typed feature structure grammars.</title>
<date>2002</date>
<publisher>CSLI Publications.</publisher>
<location>Stanford, CA:</location>
<contexts>
<context position="5221" citStr="Copestake, 2002" startWordPosition="780" endWordPosition="781"> rule classes include implementations of general principles of HPSG, like, for example, the Head Feature and NonLocal Feature Principles. • Types for basic constructions such as headcomplement, head-specifier, head-subject, head-filler, and head-modifier rules, coordination, as well as more specialized classes of constructions, such as relative clauses and noun-noun compounding. Unlike in specific grammars, these types do not impose any ordering on their daughters in the grammar matrix. Included with the matrix are configuration and parameter files for the LKB grammar engineering environment (Copestake, 2002). Although small, this preliminary version of the matrix already reflects the main goals of the project: (i) Consistent with other work in HPSG, semantic representations and in particular the syntax-semantics interface are developed in detail; (ii) the types of the matrix are each representations of generalizations across linguistic objects and across languages; and (iii) the richness of the matrix and the incorporation of files which connect it with the LKB allow for extremely quick start-up as the matrix is applied to new languages. Since February 2002, this preliminary version of the matrix</context>
</contexts>
<marker>Copestake, 2002</marker>
<rawString>Copestake, A. (2002). Implementing typed feature structure grammars. Stanford, CA: CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
<author>D Flickinger</author>
<author>R Malouf</author>
<author>S Riehemann</author>
<author>I Sag</author>
</authors>
<title>Translation using minimal recursion semantics.</title>
<date>1995</date>
<booktitle>In Proceedings of the Sixth International Conference on Theoretical and Methodological Issues in Machine Translation.</booktitle>
<location>Leuven, Belgium.</location>
<contexts>
<context position="7374" citStr="Copestake, Flickinger, Malouf, Riehemann, &amp; Sag, 1995" startWordPosition="1106" endWordPosition="1112">t constituent structure (in one view, Norwegian exhibits a VSO topology in the main clause). The user groups have suggested refinements and extensions of the basic inventory, and it is expected that general solutions, as they are identified jointly, will propagate into the existing grammars too. 3 A Detailed Example As an example of the level of detail involved in the grammar matrix, in this section we consider the analysis of intersective and scopal modification. The matrix is built to give Minimal Recursion Semantics (MRS; Copestake et al., 2001; Copestake, Flickinger, Sag, &amp; Pollard, 1999; Copestake, Flickinger, Malouf, Riehemann, &amp; Sag, 1995) representations. The two English examples in (1) exemplify the difference between intersective and scopal modification:1 (1) a. Keanu studied Kung Fu on a spaceship. b. Keanu probably studied Kung Fu. The MRSs for (1a-b) (abstracting away from agreement information) are given in (2) and (3). The MRSs are ordered tuples consisting of a top handle (h1 in both cases), an instance or event variable (e in both cases), a bag of elementary predications (eps), and a bag of scope constraints (in these cases, QEQ constraints or ‘equal modulo quantifiers’). In a well-formed MRS, the handles can be 1The</context>
</contexts>
<marker>Copestake, Flickinger, Malouf, Riehemann, Sag, 1995</marker>
<rawString>Copestake, A., Flickinger, D., Malouf, R., Riehemann, S., &amp; Sag, I. (1995). Translation using minimal recursion semantics. In Proceedings of the Sixth International Conference on Theoretical and Methodological Issues in Machine Translation. Leuven, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
<author>D P Flickinger</author>
<author>I A Sag</author>
<author>C Pollard</author>
</authors>
<title>Minimal Recursion Semantics. An introduction. in preparation, CSLI</title>
<date>1999</date>
<location>Stanford, Stanford, CA.</location>
<contexts>
<context position="7319" citStr="Copestake, Flickinger, Sag, &amp; Pollard, 1999" startWordPosition="1099" endWordPosition="1105">ons in the lexicon and basic assumptions about constituent structure (in one view, Norwegian exhibits a VSO topology in the main clause). The user groups have suggested refinements and extensions of the basic inventory, and it is expected that general solutions, as they are identified jointly, will propagate into the existing grammars too. 3 A Detailed Example As an example of the level of detail involved in the grammar matrix, in this section we consider the analysis of intersective and scopal modification. The matrix is built to give Minimal Recursion Semantics (MRS; Copestake et al., 2001; Copestake, Flickinger, Sag, &amp; Pollard, 1999; Copestake, Flickinger, Malouf, Riehemann, &amp; Sag, 1995) representations. The two English examples in (1) exemplify the difference between intersective and scopal modification:1 (1) a. Keanu studied Kung Fu on a spaceship. b. Keanu probably studied Kung Fu. The MRSs for (1a-b) (abstracting away from agreement information) are given in (2) and (3). The MRSs are ordered tuples consisting of a top handle (h1 in both cases), an instance or event variable (e in both cases), a bag of elementary predications (eps), and a bag of scope constraints (in these cases, QEQ constraints or ‘equal modulo quant</context>
</contexts>
<marker>Copestake, Flickinger, Sag, Pollard, 1999</marker>
<rawString>Copestake, A., Flickinger, D. P., Sag, I. A., &amp; Pollard, C. (1999). Minimal Recursion Semantics. An introduction. in preparation, CSLI Stanford, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Copestake</author>
<author>A Lascarides</author>
<author>D Flickinger</author>
</authors>
<title>An algebra for semantic construction in constraintbased grammars.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Meeting of the Association for Computational Linguistics.</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="3985" citStr="Copestake, Lascarides, &amp; Flickinger, 2001" startWordPosition="594" endWordPosition="598">t we foresee and an evaluation methodology for the matrix proper. 2 Preliminary Development of Matrix We have produced a preliminary version of the grammar matrix relying heavily on the LinGO project’s English Resource Grammar, and to a lesser extent on the Japanese grammar developed jointly between DFKI Saarbr¨ucken (Germany) and YY Technologies (Mountain View, CA). This early version of the matrix comprises the following components: • Types defining the basic feature geometry and technical devices (e.g., for list manipulation). • Types associated with Minimal Recursion Semantics (see, e.g., Copestake, Lascarides, &amp; Flickinger, 2001), a meaning representation language which has been shown to be wellsuited for semantic composition in typed feature structure grammars. This portion of the grammar matrix includes a hierarchy of relation types, types and constraints for the propagation of semantic information through the phrase structure tree, a representation of illocutionary force, and provisions for grammar rules which make semantic contributions. • General classes of rules, including derivational and inflectional (lexical) rules, unary and binary phrase structure rules, headed and non-headed rules, and head-initial and he</context>
<context position="7274" citStr="Copestake et al., 2001" startWordPosition="1095" endWordPosition="1098">t structure representations in the lexicon and basic assumptions about constituent structure (in one view, Norwegian exhibits a VSO topology in the main clause). The user groups have suggested refinements and extensions of the basic inventory, and it is expected that general solutions, as they are identified jointly, will propagate into the existing grammars too. 3 A Detailed Example As an example of the level of detail involved in the grammar matrix, in this section we consider the analysis of intersective and scopal modification. The matrix is built to give Minimal Recursion Semantics (MRS; Copestake et al., 2001; Copestake, Flickinger, Sag, &amp; Pollard, 1999; Copestake, Flickinger, Malouf, Riehemann, &amp; Sag, 1995) representations. The two English examples in (1) exemplify the difference between intersective and scopal modification:1 (1) a. Keanu studied Kung Fu on a spaceship. b. Keanu probably studied Kung Fu. The MRSs for (1a-b) (abstracting away from agreement information) are given in (2) and (3). The MRSs are ordered tuples consisting of a top handle (h1 in both cases), an instance or event variable (e in both cases), a bag of elementary predications (eps), and a bag of scope constraints (in these </context>
</contexts>
<marker>Copestake, Lascarides, Flickinger, 2001</marker>
<rawString>Copestake, A., Lascarides, A., &amp; Flickinger, D. (2001). An algebra for semantic construction in constraintbased grammars. In Proceedings of the 39th Meeting of the Association for Computational Linguistics. Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Flickinger</author>
</authors>
<title>On building a more efficient grammar by exploiting types.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<booktitle>(Special Issue on Efficient Processing with HPSG), 15 –</booktitle>
<volume>6</volume>
<issue>1</issue>
<pages>28</pages>
<contexts>
<context position="1213" citStr="Flickinger, 2000" startWordPosition="162" endWordPosition="163">ilitates not only quick start-up but also rapid growth towards the wide coverage necessary for robust natural language processing and the precision parses and semantic representations necessary for natural language understanding. 1 Introduction The past decade has seen the development of wide-coverage implemented grammars representing deep linguistic analysis of several languages in several frameworks, including Head-Driven Phrase Structure Grammar (HPSG), LexicalFunctional Grammar (LFG), and Lexicalized Tree Adjoining Grammar (LTAG). In HPSG, the most extensive grammars are those of English (Flickinger, 2000), German (M¨uller &amp; Kasper, 2000), and Japanese (Siegel, 2000; Siegel &amp; Bender, 2002). Despite being couched in the same general framework and in some cases being written in the same formalism and consequently being compatible with the same parsing and generation software, these grammars were developed more or less independently of each other. They each represent between 5 and 15 person years of research efforts, and comprise 35–70,000 lines of code. Unfortunately, most of that research is undocumented and the accumulated analyses, best practices for grammar engineering, and tricks of the trad</context>
</contexts>
<marker>Flickinger, 2000</marker>
<rawString>Flickinger, D. (2000). On building a more efficient grammar by exploiting types. Natural Language Engineering, 6 (1) (Special Issue on Efficient Processing with HPSG), 15 – 28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M van Lohuizen</author>
</authors>
<title>Efficient and thread-safe unification with LinGO. In</title>
<date>2002</date>
<publisher>CSLI Publications. (forthcoming)</publisher>
<location>Stanford, CA:</location>
<marker>van Lohuizen, 2002</marker>
<rawString>van Lohuizen, M. (2002). Efficient and thread-safe unification with LinGO. In S. Oepen, D. Flickinger, J. Tsujii, &amp; H. Uszkoreit (Eds.), Collaborative language engineering. A case study in efficient grammar-based processing. Stanford, CA: CSLI Publications. (forthcoming)</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Makino</author>
<author>M Yoshida</author>
<author>K Torisawa</author>
<author>J Tsujii</author>
</authors>
<title>LiLFeS — towards a practical HPSG parser.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics and the 36th Annual Meeting of the Association for Computational Linguistics (pp. 807 – 11).</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="17402" citStr="Makino, Yoshida, Torisawa, &amp; Tsujii, 1998" startWordPosition="2674" endWordPosition="2679">ted spurious ambiguity in parsing. While the development of the matrix will be built largely on the LKB platform, support will also be needed for using the emerging grammars on other processing platforms, and for linking to other packages for pre-processing the linguistic input. Several other platforms exist which can efficiently parse text using the existing grammars, including the PET system developed in C++ at Saarland University (Germany) and the DFKI (Callmeier, 2000); the PAGE system developed in Lisp at the DFKI (Uszkoreit et al., 1994); the LiLFeS system developed at Tokyo University (Makino, Yoshida, Torisawa, &amp; Tsujii, 1998), and a parallel processing system developed in Objective C at Delft University (The Netherlands; van Lohuizen, 2002). As part of the matrix package, sample configuration files and documentation will be provided for at least some of these additional platforms. Existing pre-processing packages can also significantly reduce the effort required to develop a new grammar, particularly for coping with the morphology/syntax interface. For example, the ChaSen package for segmenting Japanese input into words and morphemes (Asahara &amp; Matsumoto, 2000) has been linked to at least the LKB and PET systems.</context>
</contexts>
<marker>Makino, Yoshida, Torisawa, Tsujii, 1998</marker>
<rawString>Makino, T., Yoshida, M., Torisawa, K., &amp; Tsujii, J. (1998). LiLFeS — towards a practical HPSG parser. In Proceedings of the 17th International Conference on Computational Linguistics and the 36th Annual Meeting of the Association for Computational Linguistics (pp. 807 – 11). Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M¨uller</author>
</authors>
<title>Deutsche syntax deklarativ. HeadDriven Phrase Structure Grammarf¨ur das Deutsche.</title>
<date>1999</date>
<publisher>Max Niemeyer Verlag.</publisher>
<location>T¨ubingen, Germany:</location>
<marker>M¨uller, 1999</marker>
<rawString>M¨uller, S. (1999). Deutsche syntax deklarativ. HeadDriven Phrase Structure Grammarf¨ur das Deutsche. T¨ubingen, Germany: Max Niemeyer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M¨uller</author>
<author>W Kasper</author>
</authors>
<title>HPSG analysis of German. In</title>
<date>2000</date>
<booktitle>Verbmobil. Foundations of speech-to-speech translation (Artificial Intelligence ed.,</booktitle>
<pages>238--253</pages>
<editor>W. Wahlster (Ed.),</editor>
<publisher>Springer.</publisher>
<location>Berlin, Germany:</location>
<marker>M¨uller, Kasper, 2000</marker>
<rawString>M¨uller, S., &amp; Kasper, W. (2000). HPSG analysis of German. In W. Wahlster (Ed.), Verbmobil. Foundations of speech-to-speech translation (Artificial Intelligence ed., pp. 238 – 253). Berlin, Germany: Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Netter</author>
</authors>
<title>Functional categories in an HPSG for German. Unpublished doctoral dissertation,</title>
<date>1996</date>
<institution>Saarland University,</institution>
<location>Saarbr¨ucken, Germany.</location>
<contexts>
<context position="15439" citStr="Netter (1996)" startWordPosition="2388" endWordPosition="2389">egularities. Work is also progressing on establishing a standard relational database (using PostgreSQL) for storing information for the lexical entries themselves, improving both scalability and clarity compared to the current simple text file representation. Formbased tools will be provided both for constructing lexical entries and for viewing the contents of the lexicon. The primary focus of work on syntactic generalization in the matrix is to support more freedom in word order, for both complements and modifiers. The first step will be a relatively conservative extension along the lines of Netter (1996), allowing the grammar writer more control over how a head combines with complements of different types, and their interleaving with modifier phrases. Other areas of immediate cross-linguistic interest include the hierarchy of head types, control phenomena, clitics, auxiliary verbs, noun-noun compounds, and more generally, phenomena that involve the word/phrase distinction, such as noun incorporation. A study of the existing grammars for English, German, Japanese, and Spanish reveals a high degree of language-specificity for several of these phenomena, but also suggests promise of reusable abs</context>
</contexts>
<marker>Netter, 1996</marker>
<rawString>Netter, K. (1996). Functional categories in an HPSG for German. Unpublished doctoral dissertation, Saarland University, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Oepen</author>
<author>U Callmeier</author>
</authors>
<title>Measure for measure: Parser cross-fertilization. Towards increased component comparability and exchange.</title>
<date>2000</date>
<booktitle>In Proceedings of the 6th International Workshop on Parsing Technologies (pp. 183 – 194).</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="18643" citStr="Oepen &amp; Callmeier, 2000" startWordPosition="2863" endWordPosition="2866">ecting implementations of language-specific pre-processing packages of this kind will be preserved and extended as the matrix develops. Likewise, configuration files are included to support generation, at least within the LKB, provided that the grammar conforms to certain assumptions about semantic representation using the Minimal Recursion Semantics framework. Finally, a methodology is under development for constructing and using test suites organized around a typology of linguistic phenomena, using the implementation platform of the [incr tsdbo)] profiling package (Oepen &amp; Flickinger, 1998; Oepen &amp; Callmeier, 2000). These test suites will enable better communication about current coverage of a given grammar built using the matrix, and serve as the basis for identifying additional phenomena that need to be addressed cross-linguistically within the matrix. Of course, the development of the typology of phenomena is itself a major undertaking for which a systematic cross-linguistic approach will be needed, a discussion of which is outside the scope of this report. But the intent is to seed this classification scheme with a set of relatively coarse-grained phenomenon classes drawn from the existing grammars,</context>
</contexts>
<marker>Oepen, Callmeier, 2000</marker>
<rawString>Oepen, S., &amp; Callmeier, U. (2000). Measure for measure: Parser cross-fertilization. Towards increased component comparability and exchange. In Proceedings of the 6th International Workshop on Parsing Technologies (pp. 183 – 194). Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Oepen</author>
<author>D P Flickinger</author>
</authors>
<title>Towards systematic grammar profiling. Test suite technology ten years after.</title>
<date>1998</date>
<journal>Journal of Computer Speech and Language,</journal>
<volume>12</volume>
<issue>4</issue>
<pages>436</pages>
<contexts>
<context position="18617" citStr="Oepen &amp; Flickinger, 1998" startWordPosition="2859" endWordPosition="2862"> systems. Support for connecting implementations of language-specific pre-processing packages of this kind will be preserved and extended as the matrix develops. Likewise, configuration files are included to support generation, at least within the LKB, provided that the grammar conforms to certain assumptions about semantic representation using the Minimal Recursion Semantics framework. Finally, a methodology is under development for constructing and using test suites organized around a typology of linguistic phenomena, using the implementation platform of the [incr tsdbo)] profiling package (Oepen &amp; Flickinger, 1998; Oepen &amp; Callmeier, 2000). These test suites will enable better communication about current coverage of a given grammar built using the matrix, and serve as the basis for identifying additional phenomena that need to be addressed cross-linguistically within the matrix. Of course, the development of the typology of phenomena is itself a major undertaking for which a systematic cross-linguistic approach will be needed, a discussion of which is outside the scope of this report. But the intent is to seed this classification scheme with a set of relatively coarse-grained phenomenon classes drawn f</context>
</contexts>
<marker>Oepen, Flickinger, 1998</marker>
<rawString>Oepen, S., &amp; Flickinger, D. P. (1998). Towards systematic grammar profiling. Test suite technology ten years after. Journal of Computer Speech and Language, 12 (4) (Special Issue on Evaluation), 411 – 436.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Oepen</author>
<author>K Toutanova</author>
<author>S Shieber</author>
<author>C Manning</author>
<author>D Flickinger</author>
<author>T Brants</author>
</authors>
<title>The LinGO Redwoods treebank. Motivation and preliminary applications.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics.</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="22152" citStr="Oepen et al., 2002" startWordPosition="3435" endWordPosition="3438">t are important to sync to (e.g., changes that affect MRS outputs, fundamental changes to important analyses), (ii) develop a methodology for communicating changes in the matrix, their motivation and their implementation to the user community, and (iii) develop tools for semi-automating resynching of existing grammars to upgrades of the matrix. These tools could use the type hierarchy to predict where conflicts are likely to arise and bring these to the engineer’s attention, possibly inspired by the approach under development at CSLI for the dynamic maintenance of the LinGO Redwoods treebank (Oepen et al., 2002). Finally, while initial development of the matrix has been and will continue to be highly centralized, we hope to provide support for proposed matrix improvements from the user community. User feedback will already come in the form of case studies for the library as discussed in Section 5 above, but also potentially in proposals for modification of the matrix drawing on experiences in grammar development. In order to provide users with some cross-linguistic context in which to develop and evaluate such proposals themselves, we intend to provide some sample matrix-derived grammars and correspo</context>
</contexts>
<marker>Oepen, Toutanova, Shieber, Manning, Flickinger, Brants, 2002</marker>
<rawString>Oepen, S., Toutanova, K., Shieber, S., Manning, C., Flickinger, D., &amp; Brants, T. (2002). The LinGO Redwoods treebank. Motivation and preliminary applications. In Proceedings of the 19th International Conference on Computational Linguistics. Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Siegel</author>
</authors>
<title>HPSG analysis of Japanese. In</title>
<date>2000</date>
<booktitle>Verbmobil. Foundations of speech-to-speech translation (Artificial Intelligence ed.,</booktitle>
<pages>265--280</pages>
<editor>W. Wahlster (Ed.),</editor>
<publisher>Springer.</publisher>
<location>Berlin, Germany:</location>
<contexts>
<context position="1274" citStr="Siegel, 2000" startWordPosition="171" endWordPosition="172"> wide coverage necessary for robust natural language processing and the precision parses and semantic representations necessary for natural language understanding. 1 Introduction The past decade has seen the development of wide-coverage implemented grammars representing deep linguistic analysis of several languages in several frameworks, including Head-Driven Phrase Structure Grammar (HPSG), LexicalFunctional Grammar (LFG), and Lexicalized Tree Adjoining Grammar (LTAG). In HPSG, the most extensive grammars are those of English (Flickinger, 2000), German (M¨uller &amp; Kasper, 2000), and Japanese (Siegel, 2000; Siegel &amp; Bender, 2002). Despite being couched in the same general framework and in some cases being written in the same formalism and consequently being compatible with the same parsing and generation software, these grammars were developed more or less independently of each other. They each represent between 5 and 15 person years of research efforts, and comprise 35–70,000 lines of code. Unfortunately, most of that research is undocumented and the accumulated analyses, best practices for grammar engineering, and tricks of the trade are only available through painstaking inspection of the gr</context>
</contexts>
<marker>Siegel, 2000</marker>
<rawString>Siegel, M. (2000). HPSG analysis of Japanese. In W. Wahlster (Ed.), Verbmobil. Foundations of speech-to-speech translation (Artificial Intelligence ed., pp. 265 – 280). Berlin, Germany: Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Siegel</author>
<author>E M Bender</author>
</authors>
<title>Efficient deep processing of japanese.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics.</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="1298" citStr="Siegel &amp; Bender, 2002" startWordPosition="173" endWordPosition="176"> necessary for robust natural language processing and the precision parses and semantic representations necessary for natural language understanding. 1 Introduction The past decade has seen the development of wide-coverage implemented grammars representing deep linguistic analysis of several languages in several frameworks, including Head-Driven Phrase Structure Grammar (HPSG), LexicalFunctional Grammar (LFG), and Lexicalized Tree Adjoining Grammar (LTAG). In HPSG, the most extensive grammars are those of English (Flickinger, 2000), German (M¨uller &amp; Kasper, 2000), and Japanese (Siegel, 2000; Siegel &amp; Bender, 2002). Despite being couched in the same general framework and in some cases being written in the same formalism and consequently being compatible with the same parsing and generation software, these grammars were developed more or less independently of each other. They each represent between 5 and 15 person years of research efforts, and comprise 35–70,000 lines of code. Unfortunately, most of that research is undocumented and the accumulated analyses, best practices for grammar engineering, and tricks of the trade are only available through painstaking inspection of the grammars and/or consultati</context>
</contexts>
<marker>Siegel, Bender, 2002</marker>
<rawString>Siegel, M., &amp; Bender, E. M. (2002). Efficient deep processing of japanese. In Proceedings of the 19th International Conference on Computational Linguistics. Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Uszkoreit</author>
<author>R Backofen</author>
<author>S Busemann</author>
<author>A K Diagne</author>
<author>E A Hinkelman</author>
<author>W Kasper</author>
<author>B Kiefer</author>
<author>H-U Krieger</author>
<author>K Netter</author>
<author>G Neumann</author>
<author>S Oepen</author>
<author>S P Spackman</author>
</authors>
<title>DISCO — an HPSGbased NLP system and its application for appointment scheduling.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics. Kyoto,</booktitle>
<contexts>
<context position="17310" citStr="Uszkoreit et al., 1994" startWordPosition="2663" endWordPosition="2666">and syntactic, while restricting dialect mixture in generation and associated spurious ambiguity in parsing. While the development of the matrix will be built largely on the LKB platform, support will also be needed for using the emerging grammars on other processing platforms, and for linking to other packages for pre-processing the linguistic input. Several other platforms exist which can efficiently parse text using the existing grammars, including the PET system developed in C++ at Saarland University (Germany) and the DFKI (Callmeier, 2000); the PAGE system developed in Lisp at the DFKI (Uszkoreit et al., 1994); the LiLFeS system developed at Tokyo University (Makino, Yoshida, Torisawa, &amp; Tsujii, 1998), and a parallel processing system developed in Objective C at Delft University (The Netherlands; van Lohuizen, 2002). As part of the matrix package, sample configuration files and documentation will be provided for at least some of these additional platforms. Existing pre-processing packages can also significantly reduce the effort required to develop a new grammar, particularly for coping with the morphology/syntax interface. For example, the ChaSen package for segmenting Japanese input into words an</context>
</contexts>
<marker>Uszkoreit, Backofen, Busemann, Diagne, Hinkelman, Kasper, Kiefer, Krieger, Netter, Neumann, Oepen, Spackman, 1994</marker>
<rawString>Uszkoreit, H., Backofen, R., Busemann, S., Diagne, A. K., Hinkelman, E. A., Kasper, W., Kiefer, B., Krieger, H.-U., Netter, K., Neumann, G., Oepen, S., &amp; Spackman, S. P. (1994). DISCO — an HPSGbased NLP system and its application for appointment scheduling. In Proceedings of the 15th International Conference on Computational Linguistics. Kyoto, Japan.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>