<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002872">
<title confidence="0.998459">
ParaMor: Minimally Supervised Induction of Paradigm
Structure and Morphological Analysis
</title>
<author confidence="0.999597">
Christian Monson, Jaime Carbonell, Alon Lavie, Lori Levin
</author>
<affiliation confidence="0.986694">
Language Technologies Institute
Carnegie Mellon University
</affiliation>
<address confidence="0.88905">
5000 Forbes Ave.
Pittsburgh, PA, USA 15213
</address>
<email confidence="0.993545">
{cmonson, alavie+, jgc+, lsl+}@cs.cmu.edu
</email>
<sectionHeader confidence="0.995568" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999731">
Paradigms provide an inherent
organizational structure to natural language
morphology. ParaMor, our minimally
supervised morphology induction
algorithm, retrusses the word forms of raw
text corpora back onto their paradigmatic
skeletons; performing on par with state-of-
the-art minimally supervised morphology
induction algorithms at morphological
analysis of English and German. ParaMor
consists of two phases. Our algorithm first
constructs sets of affixes closely mimicking
the paradigms of a language. And with
these structures in hand, ParaMor then
annotates word forms with morpheme
boundaries. To set ParaMor’s few free
parameters we analyze a training corpus of
Spanish. Without adjusting parameters, we
induce the morphological structure of
English and German. Adopting the
evaluation methodology of Morpho
Challenge 2007 (Kurimo et al., 2007), we
compare ParaMor’s morphological
analyses with Morfessor (Creutz, 2006), a
modern minimally supervised morphology
induction system. ParaMor consistently
achieves competitive F1 measures.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999900909090909">
Words in natural language (NL) have internal
structure. Morphological processes derive new lex-
emes from old ones or inflect the surface form of
lexemes to mark morphosyntactic features such as
tense, number, person, etc. This paper address
minimally supervised induction of productive natu-
ral language morphology from text. Minimally su-
pervised induction of morphology interests us both
for practical and theoretical reasons. In linguistic
theory, the morpheme is often defined as the
smallest unit of language which conveys meaning.
And yet, without annotating for meaning, recent
work on minimally supervised morphology induc-
tion from written corpora has met with some suc-
cess (Creutz, 2006). We are curious how far this
program can be pushed. From a practical perspec-
tive, minimally supervised morphology induction
would help create morphological analysis systems
for languages outside the traditional scope of NLP.
However, to develop our method we induce the
morphological structure of three well-understood
languages, English, German, and Spanish.
</bodyText>
<subsectionHeader confidence="0.999444">
1.1 Inherent Structure in NL Morphology
</subsectionHeader>
<bodyText confidence="0.999975105263158">
The approach we have taken to induce morpho-
logical structure has explicit roots in linguistic the-
ory. Cross-linguistically, natural language organ-
izes inflectional morphology into paradigms and
inflection classes. A paradigm is a set of mutually
exclusive operations that can be performed on a
word form. Each mutually exclusive morphologi-
cal operation in a paradigm marks a lexeme for
some set or cell of morphosyntactic features. An
inflection class, meanwhile, specifies the proce-
dural details that a particular set of adherent lex-
emes follow to realize the surface form filling each
paradigm cell. Each lexeme in a language adheres
to a single inflection class for each paradigm the
lexeme realizes. The lexemes belonging to an in-
flection class may have no relationship binding
them together beyond an arbitrary morphological
stipulation that they adhere to the same inflection
class. But for this paper, an inflection class may
</bodyText>
<page confidence="0.977326">
117
</page>
<table confidence="0.8544084">
Proceedings of Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology, pages 117–125,
Prague, June 2007. c�2007 Association for Computational Linguistics
Paradigm Inflection Class
Cells
‘eat’ ‘silent-e’
Unmarked eat dance, erase, ...
Present, 3rd eats dances, erases, ...
Past Tense ate danced, erased, ...
Progressive eating dancing, erasing, ...
Passive eaten danced, erased, ...
</table>
<tableCaption confidence="0.998496">
Table 1: The English verbal paradigm, left col-
</tableCaption>
<bodyText confidence="0.978374586956521">
umn, and two inflection classes of the verbal
paradigm. The verb eat fills the cells of its in-
flection class with the five surface forms
shown in the second column. Verbs belonging
to the ‘silent-e’ inflection class inflect follow-
ing the pattern of the third column.
also refer to a set of lexemes that inflect similarly
for phonological or orthographic reasons. Working
with text we intentionally blur phonology and or-
thography.
A simple example will help illustrate paradigms,
inflection classes, and the mutual exclusivity of
cells. As shown in Table 1, all English verbs
belong to a single common paradigm of five cells:
One cell marks a verb for the morphosyntactic
feature values present tense 3rd person, as in eats;
another cell marks past tense, as in ate; a third cell
holds a surface form typically used to mark
progressive aspect, eating; a fourth produces a
passive participle, eaten; and finally there is the
unmarked cell, in this example eat.
Aside from inflection classes each containing
only a few irregular lexemes, such as that
containing eat, there are no English verbal
inflection classes that arbitrarily differentiate
lexemes on purely morphological grounds. There
are, however, several inflection classes that realize
surface forms only for verbs with particular
phonology or orthography. The ‘silent-e’ inflection
class is one such. To adhere to the ‘silent-e’
inflection class a lexeme must fill the unmarked
paradigm cell with a form that ends in an unspoken
character e, as in dance. The other paradigm cells
in the ‘silent-e’ inflection class are filled by
applying orthographic rules such as:
Progressive Aspect Cell – replace the final e of
the unmarked form with the string ing,
dance 4 dancing
Past Cell – substitute ed, dance 4 danced
Paradigm cells are mutually exclusive. In the Eng-
lish verbal paradigm, although English speakers
can express progressive past actions with a
grammatical construction, viz. was eating, there is
no surface form of the lexeme eat that
simultaneously fills both the progressive and the
past cells of the verbal paradigm, *ateing.
</bodyText>
<subsectionHeader confidence="0.964726">
1.2 ParaMor
</subsectionHeader>
<bodyText confidence="0.999976395348837">
Paradigms and inflection classes, the inherent
structure of natural language morphology, form the
basis of ParaMor, our minimally supervised
morphological induction algorithm. In ParaMor’s
first phase, we find sets of mutually exclusive
strings which closely mirror the inflection classes
of a language—although ParaMor does not
differentiate between syncretic word forms of the
same lexeme filling different paradigm cells, such
as ed-suffixed forms which can fill either the past
or the passive cells of English verbs. In ParaMor’s
second phase we employ the structured knowledge
contained within the discovered inflection classes
to segment word forms into morpheme-like pieces.
Languages employ a variety of morphological
processes to arrive at grammatical word forms—
processes including suffix-, prefix-, and infixation,
reduplication, and template filling. Furthermore,
the application of word forming processes often
triggers phonological (or orthographic) change,
such a as the dropped final e of the ‘silent-e’
inflection class, see Table 1. Despite the wide
range of morphological processes and their
complicating concomitant phonology, a large caste
of inflection classes, and hence paradigms, can be
represented as mutually exclusive substring
substitutions. In the ‘silent-e’ inflection class, for
example, the word-final strings e.ed.es.ing can be
substituted for one another to produce the surface
forms that fill the paradigm cells of lexemes
belonging to this inflection class. In this paper we
focus on identifying word final suffix morphology.
While we focus on suffixes, the methods we
employ can be straightforwardly generalized to
prefixes and ongoing work seeks to model
sequences of concatenative morphemes.
Inducing the morphology of a language from a
naturally occurring text corpus is challenging. In
languages with a rich morphological structure, sur-
face forms filling particular cells of an inflection
class may be relatively rare. In the Spanish news-
wire text over which we developed ParaMor there
are 50,000 unique types. Among these types, in-
</bodyText>
<page confidence="0.997334">
118
</page>
<bodyText confidence="0.999982129032258">
stances of first and second person verb forms are
few. The suffix imos which fills the first person
plural indicative present cell for the ir verbal in-
flection class of Spanish occurs on only 77 unique
lexemes. And yet we aim to identify candidate in-
flection classes which closely model the true in-
flection classes of a language, covering as many
inflectional paradigm cells as possible.
Fortunately, we can leverage the paradigm struc-
ture of natural language morphology itself to retain
many inflections which, because of data sparse-
ness, might be missed if considered in isolation.
ParaMor begins with a recall-centric search for
partial candidate inflection classes. Many of the
candidates which result from this initial search are
incorrect. But intermingled with the false positives
are candidates which collectively model significant
fractions of true inflection classes. Hence, Pa-
raMor’s next step is to cluster the initial partial
candidate inflection classes into larger groups. This
clustering effectively uses the larger correct initial
candidates as nuclei to which smaller correct can-
didates accrete. With as many initial true candi-
dates as possible safely corralled with other candi-
dates covering the same inflection class, ParaMor
completes the paradigm discovery phase by dis-
carding the large number of erroneous initially se-
lected candidate inflection classes. Finally, with a
strong grasp on the paradigm structure, ParaMor
straightforwardly segments the words of a corpus
into morphemes.
</bodyText>
<sectionHeader confidence="0.58466" genericHeader="related work">
1.3 Related Work
</sectionHeader>
<bodyText confidence="0.999988146341463">
In this section we highlight previously proposed
minimally supervised approaches to the induction
of morphology that, like ParaMor, draw on the
unique structure of natural language morphology.
One facet of NL morphological structure com-
monly leveraged by morphology induction algo-
rithms is that morphemes are recurrent building
blocks of words. Brent et al. (1995), Goldsmith
(2001), and Creutz (2006) emphasize the building
block nature of morphemes when they each use
recurring word segments to efficiently encode a
corpus. These approaches then hypothesize that
those recurring segments which most efficiently
encode a corpus are likely morphemes. Another
technique that exploits morphemes as repeating
sub-word segments encodes the lexemes of a cor-
pus as a character tree, i.e. trie, (Harris, 1955;
Hafer and Weis, 1974), or as a finite state automa-
ton (FSA) over characters (Johnson, H. and Martin,
2003; Altun and M. Johnson, 2001). A trie or FSA
conflates multiple instances of a morpheme into a
single sequence of states. Because the choice of
possible succeeding characters is highly con-
strained within a morpheme, branch points in the
trie or FSA are likely morpheme boundaries. Often
trie similarities are used as a first step followed by
further processing to identify morphemes (Schone
and Jurafsky, 2001).
The paradigm structure of NL morphology has
also been previously leveraged. Goldsmith (2001)
uses morphemes to efficiently encode a corpus, but
he first groups morphemes into paradigm like
structures he calls signatures. To date, the work
that draws the most on paradigm structure is
Snover (2002). Snover incorporates paradigm
structure into a generative statistical model of
morphology. Additionally, to discover paradigm
like sets of suffixes, Snover designs and searches
networks of partial paradigms. These networks are
the direct inspiration for ParaMor’s morphology
scheme networks described in section 2.1.
</bodyText>
<sectionHeader confidence="0.855647" genericHeader="conclusions">
2 ParaMor: Inflection Class Identification
</sectionHeader>
<subsectionHeader confidence="0.818281">
2.1 Search
</subsectionHeader>
<bodyText confidence="0.999964269230769">
A Search Space: The first stage of ParaMor is a
search procedure designed to identify partial in-
flection classes containing as many true productive
suffixes of a language as possible. To search for
these partial inflection classes we must first define
a space to search over. In a naturally occurring
corpus not all possible surface forms occur. In a
corpus, each stem adhering to an inflection class
will likely be observed in combination with only a
subset of the suffixes in that inflection class. Each
box in Figure 1 depicts a small portion of the em-
pirical co-occurrence of suffixes and stems from a
Spanish newswire corpus of 50,000 types. Each
box in this figure contains a list of suffixes at the
top in bold, together with the total number, and a
few examples (in italics), of stems that occurred in
separate word forms with each suffix in that box.
For example, the box containing the suffixes e,
erá, ieron, and i6 contains the stems deb and
padec because the word forms debe, padece, de-
berá, padecerá, etc. all occurred in the corpus. We
call each possible pair of suffix and stem sets a
scheme, and say that the e.erá.ieron.i6 scheme
covers the words debe, padece, etc. Note that a
scheme contains both stems that occurred with ex-
actly the set of suffixes in that scheme, as well as
</bodyText>
<page confidence="0.997972">
119
</page>
<figureCaption confidence="0.994392">
Figure 1: A small portion of a morphology scheme network—our search space of partial empirical in-
flection classes. This network was built from a Spanish Newswire corpus of 50,000 types, 1.26 million
tokens. Each box contains a scheme. The suffixes of each scheme appear in bold at the top of each box.
The total number of adherent stems for each scheme, together with a few exemplar stems, is in italics.
Stems are underlined if they do not appear in any parent shown in this figure.
</figureCaption>
<figure confidence="0.974079947368421">
azar.e.ido.ieron.ir.ió
1: sal
e.ido.ieron.ir.irá.ió
28: asist, dirig, exig, ocurr, sufr, ...
e.er.erá.ido.ieron.ió
28: deb, escog, ofrec, roconoc, vend, ...
e.erá.ieron.ió er.ido.ieron.ió e.ido.ieron.ió ido.ieron.ir.ió
32: deb, padec, ... 58: ascend, ejerc, recog, ... 86: asist, deb, hund,... 44: interrump, sal,
...
e.er.erá.ieron.ió
32: deb, padec, romp, ...
e.erá.ido.ieron.ió
28: deb, escog, ...
e.er.ido.ieron.ió
46: deb, parec, recog...
e.ido.ieron.irá.ió
28: asist, dirig, ...
e.ido.ieron.ir.ió
39: asist, bat, sal, ...
</figure>
<bodyText confidence="0.999916136986302">
stems that occurred with suffixes beyond just those
in the scheme. For example, in addition to the four
suffixes e, erá, ieron, and i6, the stem deb oc-
curred with the suffixes er and ido, as evident from
the top left scheme e.er.erá.ido.ieron.i6 which
contains the stem deb. Intuitively, a scheme is a
subset of the suffixes filling the paradigm cells of a
true inflection class together with the stems that
empirically occurred with that set of suffixes.
The schemes in Figure 1 cover portions of the er
and the ir Spanish verbal inflection classes. The
top left scheme of the figure contains suffixes in
the er inflection class, while the top center scheme
contains suffixes in the ir inflection class. The six
suffixes in the top left scheme and the six suffixes
in the top center scheme are just a few of the
suffixes in the full er and ir inflection classes. As
is fairly common for inflection classes across
languages, the sets of suffixes in the Spanish er
and ir inflection classes overlap. That is, verbs that
belong to the er inflection class can take as a suffix
certain strings of characters that verbs belonging to
the ir inflection class can also take. The suffixes
that are unique to the er verb inflection class in the
top left scheme are er and erá; while the unique
suffixes for the ir class in the top center scheme are
ir and irá. In the third row of the figure, the
scheme e.ido.ieron.i6 contains only suffixes found
in both the er and ir schemes.
While the example schemes in Figure 1 are cor-
rect and do occur in a real Spanish newswire cor-
pus, the schemes are atypically perfect. There is
only one suffix appearing in Figure 1 that is not a
true suffix of Spanish—azar in the upper right
scheme. In unsupervised morphology induction we
do not know a priori the correct suffixes of a lan-
guage. Hence, we form schemes by proposing can-
didate morpheme boundaries at every character
boundary in every word, including the character
boundary after the final character in each word
form, to allow for empty suffixes.
Schemes of suffixes and their exhaustively co-
occurring stems define a natural search space over
partial inflection classes because schemes readily
organize by the suffixes and stems they contain.
We define a parent-child relationship between a
parent scheme, P and a child scheme C , when P
contains all the suffixes that C contains and when
P contains exactly one more suffix than C . In
Figure 1, parent child relations are represented by
solid lines connecting boxed schemes. The scheme
e.er.erá.ido.ieron.i6, for example, is the parent of
three depicted children in Figure 1, one of which is
e.er.erá.ieron.i6.
Our search strategy exploits a fundamental
aspect of the relationship between parent and child
schemes. Consider the number of stems in a parent
scheme P as compared to the number of stems in
any one of its children C . Since P contains all the
suffixes which C contains, and because P only
contains stems that occurred with every suffix in
P , P can at most contain exactly the stems C
contains and typically will contain fewer. In the
Spanish corpus from which the scheme network of
Figure 1 was built, 32 stems occur in forms with
each of the five suffixes e, er, erá, ieron, and i6
attached. But only 28 of these 32 stems occur in
yet another form involving ido—the stem deb did
but the stems padec and romp did not, for example.
A Search Strategy: To search for schemes
which cover portions of the true inflection classes
of a language, ParaMor’s search starts at the bot-
tom of the network. The lowest level in the scheme
</bodyText>
<page confidence="0.976738">
120
</page>
<bodyText confidence="0.999960326923077">
network consists of schemes which contain exactly
one suffix together with all the stems that occurred
in the corpus with that suffix attached. ParaMor
considers each one-suffix scheme in turn beginning
with that scheme containing the most stems, work-
ing toward schemes containing fewer. From each
bottom scheme, ParaMor follows a single greedy
upward path from child to parent. As long as an
upward path takes at least one step, making it to a
scheme containing two or more alternating suf-
fixes, our search strategy accepts the terminal
scheme of the path as likely modeling a portion of
a true inflection class.
Each greedily chosen upward step is based on
two criteria. The first criterion considers the
number of adherent stems in the current scheme as
compared to its parents’ adherent sizes. A variety
of statistics could judge the stem-strength of parent
schemes: ranging from simple ratios through
(dis)similarity measures, such as the dice
coefficient or mutual information, to full fledged
statistical tests. After experimenting with a range
of such statistics we found, somewhat surprisingly,
that measuring the ratio of parent stem size to child
stem size correctly identifies parent schemes which
contain only true suffixes just as consistently as
more sophisticated tests. While a full report of our
experiments is beyond the scope of this paper, the
short explanation of this behavior is data
sparseness. Many upward search steps start from
schemes containing few stems. And when little
data is available no statistic is particularly reliable.
Parent-child stem ratios have two additional
computational advantages over other measures.
First, they are quick to compute and second, the
parent with the largest stem ratio is always that
parent with the most stems. So, being greedy, each
search step simply moves to that parent, P , with
the most stems, as long as the parent-child stem
ratio to P is large. The threshold above which a
stem ratio is considered large enough to warrant an
upward step is a free parameter. As the goal of this
initial search stage is to identify schemes contain-
ing as wide a variety of productive suffixes as pos-
sible, we want to set the parent-child stem ratio
threshold as low as possible. But a ratio threshold
that is too small will allow search paths to schemes
containing unproductive and spurious suffixes. In
practice, for Spanish, we have found that setting
the parent-child stem ratio cutoff much below 0.25
results in schemes that begin to include only mar-
ginally productive derivational suffixes. For this
paper we leave the parent-child stem ratio cutoff
parameter at 0.25.
Alone, stem strength assessments of parent
schemes, such as parent-child stem ratios, falter as
a search path nears the top of the morphology
scheme network. Monotonically decreasing adher-
ent stem size causes statistics that assess parents’
stem-strength to become less and less reliable.
Hence, the second criterion governing each search
step helps to halt upward search paths before judg-
ing parents’ worth becomes impossible. While
there are certainly many possible stopping criteria,
ParaMor’s policy stops each upward search path
when there is no parent scheme with more stems
than it has suffixes. We devised this halting condi-
tion for two reasons. First, requiring each path
scheme to contain more stems than suffixes attains
high suffix recall. High recall results from setting a
low bar for upward movement at the bottom of the
network. Search paths which begin from schemes
whose single suffix is rare in the text corpus can
often take one or two upward search steps and
reach a scheme containing the necessary three or
four stems. Second, this halting criterion requires
the top scheme of search paths that climb high in
the network to contain a comparatively large num-
ber of stems. Reigning in high-reaching search
paths before the stem count falls too far, captures
path-terminal schemes which cover a large number
of word types. In the second stage of ParaMor’s
inflection class identification phase these larger
terminal schemes effectively vacuum up the useful
smaller paths that result from the more rare suf-
fixes. Figure 2 contains examples of schemes se-
lected by ParaMor’s initial search.
To evaluate ParaMor at paradigm identification,
we hand compiled an answer key of the inflection
classes of Spanish. This answer key contains nine
productive inflection classes. Three contain the
suffixes of the ar, er, and ir verbal inflection
classes. There are two orthographically differenti-
ated inflection classes for nouns in the answer key:
one for nouns that form the plural by adding s, and
one for nouns that take es. Adjectives in Spanish
inflect for gender and number. Arguably, gender
and number each constitute separate paradigms,
each with two cells. But here we conflated these
into a single inflection class with four cells. Fi-
nally, there are three inflection classes in our an-
swer key covering Spanish clitics. Spanish verbal
clitics behave orthographically as agglutinative
sequences of suffixes.
</bodyText>
<page confidence="0.985945">
121
</page>
<figure confidence="0.9988001875">
1) Ø.s 5501 stems
2) a.as.o.os 892 stems
...
5) a.aba.aban.ada.adas.ado.ados.an.ando.
ar.aron.arse.ará.arán.6 25 stems
...
12) a.aba.ada.adas.ado.ados.an.ando.ar.
aron.ará.arán.e.en.6 21 stems
...
209) e.er.ida.idas.ido.idos.imiento.i6 9 stems
...
1590) Ø.ipo 4 stems
1591) ido.idos.ir.iré 6 stems
1592) Ø.e.iu 4 stems
1593) iza.izado.izan.izar.izaron.izarán.iz6
... 8 stems
</figure>
<figureCaption confidence="0.647127142857143">
Figure 2: The suffixes of some schemes selected
by the initial search over a Spanish corpus of
50,000 types. While some selected schemes
contain large numbers of correct suffixes, such
as the 1st, 2nd, 5th, 12th, 209th, and 1591st selected
schemes; many others are incorrect collections
of word final strings.
</figureCaption>
<bodyText confidence="0.99991">
In a corpus of Spanish newswire text of 50,000
types and 1.26 million tokens, the initial search
identifies schemes containing 92% of all ideal in-
flectional suffixes of Spanish, or 98% of the ideal
suffixes that occurred at least twice in the corpus.
There are selected schemes which contain portions
of each of the nine inflection classes in the answer
key. The high recall of the initial search comes, of
course, at the expense of precision. While there are
nine inflection-classes and 87 unique suffixes in
the hand-built answer key for Spanish, 8339
schemes are selected containing 9889 unique can-
didate suffixes.
</bodyText>
<subsectionHeader confidence="0.999822">
2.2 Clustering Partial Inflection Classes
</subsectionHeader>
<bodyText confidence="0.999991815384616">
While the third step of inflection class identifica-
tion, discussed in Section 2.3, directly improves
the initial search’s low precision by filtering out
bogus schemes, the second step, described here,
conflates selected schemes which model portions
of the same inflection class. Consider the fifth and
twelfth schemes selected by ParaMor from our
Spanish corpus, as shown in Figure 2. Both of
these schemes contain a large number of suffixes
from the Spanish ar verbal inflection class. And
while each contains many overlapping suffixes,
each possesses correct suffixes which the other
does not. Meanwhile, the 1591st selected scheme
contains four suffixes of the ir verbal inflection
class, including the only instance of iré that occurs
in any selected scheme. Containing only six stems,
the 1591st scheme could accidentally be filtered out
during the third phase of inflection class identifica-
tion. Hence, the rationale for clustering initial se-
lected schemes is two fold. First, by consolidating
schemes which cover portions of the same inflec-
tion class we produce sets of suffixes which more
closely model the paradigm structure of natural
language morphology. And, second, corralling cor-
rect schemes safeguards against losing unique suf-
fixes.
The clustering of schemes presents two unique
challenges. First, we must avoid over-clustering
schemes which model distinct inflection classes.
As noted in Section 2.1, it is common, cross-
linguistically, for the suffixes of inflection classes
to overlap. Looking at Figure 2, we must be careful
not to merge the 209th selected scheme, which
models a portion of the er verbal inflection class,
with the 1591st selected scheme, which models the
ir class—despite these schemes sharing two suf-
fixes, ido and idos. As the second challenge, the
many small schemes which the search strategy
produces act as distractive noise during clustering.
While small schemes containing correct suffixes
do exist, e.g. the 1591st scheme, the vast majority
of schemes containing few stems and suffixes are
incorrect collections of word final strings that hap-
pen to occur in corpus word forms attached to a
small number of shared initial strings. ParaMor’s
clustering algorithm should, for example, avoid
placing Ø.s and Ø.ipo, respectively the 1st and
1590th selected schemes, in the same cluster. Al-
though Ø.ipo shares the null suffix with the valid
nominal scheme Ø.s, the string ‘ipo’ is not a mor-
phological suffix of Spanish.
To form clusters of related schemes while ad-
dressing both the challenge of observing a lan-
guage’s paradigm structure as well as the challenge
of merging in the face of many small incorrectly
selected schemes, ParaMor adapts greedy hierar-
chical agglomerative clustering. We modify vanilla
bottom-up clustering by placing restrictions on
which clusters are allowed to merge. The first re-
striction helps ensure that schemes modeling dis-
tinct but overlapping inflection classes remain
separated. The restriction: do not place into the
same cluster suffixes which share no stem in the
corpus. This restriction retains separate clusters for
separate inflection classes because a lexeme’s stem
</bodyText>
<page confidence="0.994785">
122
</page>
<bodyText confidence="0.999976828571429">
occurring with suffixes unique to that lexeme’s
inflection class will not occur with suffixes unique
to some other inflection class.
Alone, requiring all pairs of suffixes in a cluster
to occur in the corpus with some common stem
will not prevent small bogus schemes, such as
Ø.ipo from attaching to correct schemes, such as
Ø.s—the ipo.s scheme contains two ‘stems,’ the
word form initial strings ‘ma’ and ‘t’. And so a
second restriction is required. This second restric-
tion employs a heuristic specifically adapted to
ParaMor’s initial search strategy. As discussed in
Section 2.1, in addition to many schemes which
contain only few suffixes, ParaMor’s initial net-
work search also identifies multiple overlapping
schemes containing significant subsets of the suf-
fixes in an inflection class. The 5th, 12th, and 209th
selected schemes of Figure 2 are three such larger
schemes. ParaMor restricts cluster merges heuristi-
cally by requiring at least one large scheme for
each small scheme the cluster contains, where we
measure the size of a scheme as the number of
unique word forms it covers. The threshold size
above which schemes are considered large is the
second of ParaMor‘s two free parameters. The
scheme size threshold is reused during ParaMor’s
filtering stage. We discuss the unsupervised proce-
dure we use to set the size threshold when we pre-
sent the details of cluster filtering in Section 2.3.
We have found that with these two cluster re-
strictions in place, the particular metric we use to
measure the similarity of scheme-clusters does not
significantly affect clustering. For the experiments
we report here, we measure the similarity of
scheme-clusters as the cosine between the sets of
</bodyText>
<figure confidence="0.8852735">
0 50 100 150
Scheme or Cluster Size
</figure>
<figureCaption confidence="0.7826468">
Figure 3: The # of clusters and their recall of
unique Spanish suffixes as the scheme-cluster
size cutoff is varied. The value of each function
at the threshold we use in all experiments re-
ported in this paper is that of the larger symbol.
</figureCaption>
<bodyText confidence="0.999858142857143">
all possible stem-suffix pairs the clusters contain.
A stem-suffix pair occurs in a cluster if some
scheme belonging to that cluster contains both that
stem and that suffix. With these adaptations, we
allow agglomerative clustering to proceed until
there are no more clusters that can legally be
merged.
</bodyText>
<subsectionHeader confidence="0.999988">
2.3 Filtering of Inflection Classes
</subsectionHeader>
<bodyText confidence="0.999995534883721">
With most valid schemes having found a safe ha-
ven in a cluster with other schemes modeling the
same inflection class, we turn our attention to im-
proving scheme-cluster precision. ParaMor applies
a series of filters, culling out unwanted scheme-
clusters. The first filter is closely related to the
cluster restriction on scheme size discussed in Sec-
tion 2.2. ParaMor discards all unclustered schemes
falling below the size threshold used during clus-
tering. Figure 3 graphs the number of Spanish clus-
ters which survive this size-based filtering step as
the threshold size is varied. Figure 3 also contains
a plot of the recall of unique Spanish suffixes as a
function of this threshold. As the size threshold is
increased the number of remaining clusters quickly
drops. But suffix recall only slowly falls during the
steep decline in cluster count, indicating ParaMor
discards mostly bogus schemes containing illicit
suffixes. Because recall is relatively stable, the ex-
act size threshold we use should have only a minor
effect on ParaMor’s final morphological analyses.
In fact, we have not fully explored the ramifica-
tions various threshold values have on the final
morphological word segmentations, but have sim-
ply picked a reasonable setting, 37 covered word
types. At this threshold, the number of scheme-
clusters is reduced by more than 98%, while the
number of unique candidate suffixes in any cluster
is reduced by more than 85%. Note that the initial
number of selected schemes, 8339, falls outside the
scale of Figure 3.
Of the scheme-clusters which remain after size
based filtering is complete, by far the largest cate-
gory of incorrect clusters contains schemes which,
like the 1593rd selected scheme, shown in Figure 2,
incorrectly hypothesize morpheme boundaries one
or more characters to the left of the true boundary.
To filter out these incorrectly segmented clusters
we use a technique inspired by Harris (1955). For
each initial string common to all suffixes in the
cluster, for each scheme in the cluster, we examine
the network scheme containing the suffixes formed
by stripping the initial string from the scheme’s
</bodyText>
<figure confidence="0.997561375">
# of Clusters
1000
400
200
600
800
0
# of Clusters
Recall
0.8
0.6
0.4
0.2
0
1
Recall
</figure>
<page confidence="0.995814">
123
</page>
<bodyText confidence="0.999993666666667">
suffixes. We then measure the entropy of leftward
trie characters of the stripped scheme. If the en-
tropy is large, then the character stripped scheme is
likely at a morpheme boundary and the original
scheme is likely modeling an incorrect morpheme
boundary. This algorithm would throw out the
1593rd selected scheme because the stems in the
scheme a.ado.an.ar.aron.arán.ó end in a wide
variety of characters, yielding high trie entropy,
and signaling a likely morpheme boundary.
Because we apply morpheme boundary filtering
after we have clustered, the redundancy of the
many schemes in the cluster makes this filter quite
robust, letting us set the cutoff parameter as low as
we like avoiding another free parameter.
</bodyText>
<subsectionHeader confidence="0.993383">
2.4 Segmentation and Evaluation
</subsectionHeader>
<bodyText confidence="0.9999096">
Word segmentation is our final step of morpholo-
gical analysis. ParaMor’s current segmentation
algorithm is perhaps the most simple paradigm
inspired segmentation algorithm possible. Essen-
tially, ParaMor strips off suffixes which likely par-
ticipate in a paradigm. To segment any word, w,
ParaMor identifies all scheme-clusters that contain
a non-empty suffix that matches a word final string
of w. For each such matching suffix, f E C,
where C is the cluster containing f , we strip f
from w obtaining a stem t . If there is some sec-
ond suffix f ′ E C such that t. f ′ is a word form
found in either of the training or the test corpora,
then ParaMor proposes a segmentation of w be-
tween t and f . ParaMor, here, identifies f and
f ′ as mutually exclusive suffixes from the same
paradigm. If ParaMor finds no complex analysis,
then we propose w itself as the sole analysis of the
word. Note that for each word form, ParaMor may
propose multiple separate segmentation analyses
each containing a single proposed stem and suffix.
To evaluate ParaMor’s morphological segmenta-
tions we follow the methodology of Morpho Chal-
lenge 2007 (Kurimo et al., 2007), a minimally su-
pervised morphology induction competition. Word
segmentations are evaluated in Morpho Challenge
2007 by comparing against hand annotated mor-
phological analyses. The correctness of proposed
morphological analyses is computed in Morpho
Challenge 2007 by comparing pairs of word forms
which share portions of their analyses. Recall is
measured by first sampling pairs of words from the
answer analyses which share a stem or morphosyn-
tactic feature and then noting if that pair of word
forms shares a morpheme in any of their proposed
analyses. Precision is measured analogously, sam-
pling morpheme-sharing pairs of words from the
proposed analyses and noting if that pair of words
shares a feature in any correct analysis of those
words.
We evaluate ParaMor on two languages not
examined during the development of ParaMor’s
induction algorithms: English and German. And
we evaluate with each of these two languages at
two tasks:
</bodyText>
<listItem confidence="0.958699333333333">
1. Analyzing inflectional morphology alone
2. Jointly analyzing inflectional and derivational
morphology.
</listItem>
<bodyText confidence="0.999992307692308">
We constructed Morpho Challenge 2007 style
answer keys for each language and each task using
the Celex database (Burnage, 1990). The English
and German corpora we test over are the corpora
available through Morpho Challenge 2007. The
English corpus contains nearly 385,000 types,
while the German corpus contains more than 1.26
million types. ParaMor induced paradigmatic
scheme-clusters over these larger corpora by
reading just the top 50,000 most frequent types.
But with the scheme-clusters in hand, ParaMor
segmented all the types in each corpus.
We compare ParaMor to Morfessor v0.9.2
(Creutz, 2006), a state-of-the-art minimally super-
vised morphology induction algorithm. Morfessor
has a single free parameter. To make for stiff com-
petition, we report results for Morfessor at that pa-
rameter setting which maximized F1 on each sepa-
rate test scenario. We did not vary the two free pa-
rameters of ParaMor, but hold each of ParaMor’s
parameters at a setting which produced reasonable
Spanish suffix sets, see sections 2.1-2.2. Table 2
contains the evaluation results. To estimate the
variance of our experimental results we measured
Morpho Challenge 2007 style precision, recall, and
F1 on multiple non-overlapping pairs of 1000 fea-
ture-sharing words.
Neither ParaMor nor Morfessor arise in Table 2
as clearly superior. Each algorithm outperforms the
other at F1 in some scenario. Examining precision
and recall is more illuminating. ParaMor attains
particularly high recall of inflectional affixes for
both English and German. We conjecture that Pa-
raMor’s strong performance at identifying inflec-
tional morphemes comes from closely modeling
the natural paradigm structure of language. Con-
versely, Morfessor places its focus on precision
and does not rely on any property exclusive to in-
flectional (or derivational) morphology. Hence,
</bodyText>
<page confidence="0.99628">
124
</page>
<table confidence="0.9978572">
Inflectional Morphology Only Inflectional &amp; Derivational Morphology
English German English German
P R F1 P R F1 P R F1 P R F1
Morfessor 53.3 47.0 49.9 1.3 38.7 44.2 41.2 0.8 73.6 34.0 46.5 1.1 66.9 37.1 47.7 0.7
ParaMor 33.0 81.4 47.0 0.9 42.8 68.6 52.7 0.8 48.9 53.6 51.1 0.8 60.0 33.5 43.0 0.7
</table>
<tableCaption confidence="0.995771">
Table 2: ParaMor segmentations compared to Morfessor’s (Creutz, 2006) evaluated for Precision, Recall,
</tableCaption>
<bodyText confidence="0.950952611111111">
F1, and standard deviation of F1, , in four scenarios. Segmentations over English and German are each
evaluated against correct morphological analyses consisting, on the left, of inflectional morphology
only, and on the right, of both inflectional and derivational morphology.
Morfessor attains high precision with reasonable
recall when graded against an answer key contain-
ing both inflectional and derivational morphology.
We are excited by ParaMor’s strong
performance and are eager to extend our algorithm.
We believe the precision of ParaMor’s simple
segmentation algorithm can be improved by
narrowing down the proposed analyses for each
word to the most likely. Perhaps ParaMor and
Morfessor’s vastly different strategies for
morphology induction could be combined into a
hybrid strategy more successful than either alone.
And ambitiously, we hope to extend ParaMor to
analyze languages with agglutinative sequences of
affixes by generalizing the definition of a scheme.
</bodyText>
<sectionHeader confidence="0.996312" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.905578">
The research reported in this paper was funded in
part by NSF grant number IIS-0121631.
</bodyText>
<sectionHeader confidence="0.999052" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999771454545454">
Altun, Yasemin, and Mark Johnson. &amp;quot;Inducing
SFA with -Transitions Using Minimum
Description Length.&amp;quot; Finite State Methods in
Natural Language Processing Workshop at
ESSLLI Helsinki: 2001.
Brent, Michael R., Sreerama K. Murthy, and
Andrew Lundberg. &amp;quot;Discovering Morphemic
Suffixes: A Case Study in MDL Induction.&amp;quot; The
Fifth International Workshop on Artificial Intel-
ligence and Statistics Fort Lauderdale, Florida,
1995.
Burnage, Gavin. Celex—A Guide for Users.
Springer, Centre for Lexical information,
Nijmegen, the Netherlands, 1990.
Creutz, Mathias. “Induction of the Morphology of
Natural Language: Unsupervised Morpheme
Segmentation with Application to Automatic
Speech Recognition.” Ph.D. Thesis in Computer
and Information Science, Report D13. Helsinki:
University of Technology, Espoo, Finland, 2006.
Goldsmith, John. &amp;quot;Unsupervised Learning of the
Morphology of a Natural Language.&amp;quot; Computa-
tional Linguistics 27.2 (2001): 153-198.
Hafer, Margaret A., and Stephen F. Weiss. &amp;quot;Word
Segmentation by Letter Successor Varieties.&amp;quot;
Information Storage and Retrieval 10.11/12
(1974): 371-385.
Harris, Zellig. &amp;quot;From Phoneme to Morpheme.&amp;quot;
Language 31.2 (1955): 190-222. Reprinted in
Harris 1970.
Harris, Zellig. Papers in Structural and
Transformational Linguists. Ed. D. Reidel,
Dordrecht 1970.
Johnson, Howard, and Joel Martin. &amp;quot;Unsupervised
Learning of Morphology for English and Inuk-
titut.&amp;quot; Human Language Technology Conference
/ North American Chapter of the Association for
Computational Linguistics (HLT-NAACL).
Edmonton, Canada: 2003.
Kurimo, Mikko, Mathias Creutz, and Matti
Varjokallio. “Unsupervised Morpheme Analysis
– Morpho Challenge 2007.” March 26, 2007.
&lt;http://www.cis.hut.fi/morphochallenge2007/&gt;
Schone, Patrick, and Daniel Jurafsky. &amp;quot;Know-
ledge-Free Induction of Inflectional Morpho-
logies.&amp;quot; North American Chapter of the
Association for Computational Linguistics
(NAACL). Pittsburgh, Pennsylvania: 2001. 183-
191.
Snover, Matthew G. &amp;quot;An Unsupervised Knowledge
Free Algorithm for the Learning of Morphology
in Natural Languages.&amp;quot; Sever Institute of Tech-
nology, Computer Science Saint Louis, Mis-
souri: Washington University, M.S. Thesis,
2002.
</reference>
<page confidence="0.998497">
125
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.689399">
<title confidence="0.9996075">ParaMor: Minimally Supervised Induction of Paradigm Structure and Morphological Analysis</title>
<author confidence="0.998399">Christian Monson</author>
<author confidence="0.998399">Jaime Carbonell</author>
<author confidence="0.998399">Alon Lavie</author>
<author confidence="0.998399">Lori Levin</author>
<affiliation confidence="0.9965025">Language Technologies Institute Carnegie Mellon University</affiliation>
<address confidence="0.999373">5000 Forbes Ave. Pittsburgh, PA, USA 15213</address>
<email confidence="0.996709">cmonson@cs.cmu.edu</email>
<email confidence="0.996709">alavie+@cs.cmu.edu</email>
<email confidence="0.996709">jgc+@cs.cmu.edu</email>
<email confidence="0.996709">lsl+@cs.cmu.edu</email>
<abstract confidence="0.999502814814815">Paradigms provide an organizational structure to natural morphology. ParaMor, our minimally supervised morphology algorithm, retrusses the word forms of raw text corpora back onto their paradigmatic skeletons; performing on par with state-ofthe-art minimally supervised morphology induction algorithms at morphological analysis of English and German. ParaMor consists of two phases. Our algorithm first constructs sets of affixes closely mimicking the paradigms of a language. And with these structures in hand, ParaMor then annotates word forms with morpheme boundaries. To set ParaMor’s few free parameters we analyze a training corpus of Spanish. Without adjusting parameters, we induce the morphological structure of English and German. Adopting the evaluation methodology of Morpho Challenge 2007 (Kurimo et al., 2007), we compare ParaMor’s morphological analyses with Morfessor (Creutz, 2006), a modern minimally supervised morphology induction system. ParaMor consistently</abstract>
<intro confidence="0.7089">competitive</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yasemin Altun</author>
<author>Mark Johnson</author>
</authors>
<title>Inducing SFA with -Transitions Using Minimum Description Length.&amp;quot;</title>
<date>2001</date>
<booktitle>Finite State Methods in Natural Language Processing Workshop at ESSLLI</booktitle>
<location>Helsinki:</location>
<marker>Altun, Johnson, 2001</marker>
<rawString>Altun, Yasemin, and Mark Johnson. &amp;quot;Inducing SFA with -Transitions Using Minimum Description Length.&amp;quot; Finite State Methods in Natural Language Processing Workshop at ESSLLI Helsinki: 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Brent</author>
<author>Sreerama K Murthy</author>
<author>Andrew Lundberg</author>
</authors>
<title>Discovering Morphemic Suffixes: A Case Study in MDL Induction.&amp;quot;</title>
<date>1995</date>
<booktitle>The Fifth International Workshop on Artificial Intelligence and Statistics</booktitle>
<location>Fort Lauderdale, Florida,</location>
<contexts>
<context position="9926" citStr="Brent et al. (1995)" startWordPosition="1478" endWordPosition="1481">discovery phase by discarding the large number of erroneous initially selected candidate inflection classes. Finally, with a strong grasp on the paradigm structure, ParaMor straightforwardly segments the words of a corpus into morphemes. 1.3 Related Work In this section we highlight previously proposed minimally supervised approaches to the induction of morphology that, like ParaMor, draw on the unique structure of natural language morphology. One facet of NL morphological structure commonly leveraged by morphology induction algorithms is that morphemes are recurrent building blocks of words. Brent et al. (1995), Goldsmith (2001), and Creutz (2006) emphasize the building block nature of morphemes when they each use recurring word segments to efficiently encode a corpus. These approaches then hypothesize that those recurring segments which most efficiently encode a corpus are likely morphemes. Another technique that exploits morphemes as repeating sub-word segments encodes the lexemes of a corpus as a character tree, i.e. trie, (Harris, 1955; Hafer and Weis, 1974), or as a finite state automaton (FSA) over characters (Johnson, H. and Martin, 2003; Altun and M. Johnson, 2001). A trie or FSA conflates m</context>
</contexts>
<marker>Brent, Murthy, Lundberg, 1995</marker>
<rawString>Brent, Michael R., Sreerama K. Murthy, and Andrew Lundberg. &amp;quot;Discovering Morphemic Suffixes: A Case Study in MDL Induction.&amp;quot; The Fifth International Workshop on Artificial Intelligence and Statistics Fort Lauderdale, Florida, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gavin Burnage</author>
</authors>
<title>Celex—A Guide for Users. Springer, Centre for Lexical information,</title>
<date>1990</date>
<location>Nijmegen, the</location>
<contexts>
<context position="34608" citStr="Burnage, 1990" startWordPosition="5489" endWordPosition="5490">cision is measured analogously, sampling morpheme-sharing pairs of words from the proposed analyses and noting if that pair of words shares a feature in any correct analysis of those words. We evaluate ParaMor on two languages not examined during the development of ParaMor’s induction algorithms: English and German. And we evaluate with each of these two languages at two tasks: 1. Analyzing inflectional morphology alone 2. Jointly analyzing inflectional and derivational morphology. We constructed Morpho Challenge 2007 style answer keys for each language and each task using the Celex database (Burnage, 1990). The English and German corpora we test over are the corpora available through Morpho Challenge 2007. The English corpus contains nearly 385,000 types, while the German corpus contains more than 1.26 million types. ParaMor induced paradigmatic scheme-clusters over these larger corpora by reading just the top 50,000 most frequent types. But with the scheme-clusters in hand, ParaMor segmented all the types in each corpus. We compare ParaMor to Morfessor v0.9.2 (Creutz, 2006), a state-of-the-art minimally supervised morphology induction algorithm. Morfessor has a single free parameter. To make f</context>
</contexts>
<marker>Burnage, 1990</marker>
<rawString>Burnage, Gavin. Celex—A Guide for Users. Springer, Centre for Lexical information, Nijmegen, the Netherlands, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mathias Creutz</author>
</authors>
<title>Induction of the Morphology of Natural Language: Unsupervised Morpheme Segmentation with Application to Automatic Speech Recognition.”</title>
<date>2006</date>
<booktitle>Ph.D. Thesis in Computer and Information Science, Report D13.</booktitle>
<institution>University of Technology,</institution>
<location>Helsinki:</location>
<contexts>
<context position="1226" citStr="Creutz, 2006" startWordPosition="161" endWordPosition="162">ction algorithms at morphological analysis of English and German. ParaMor consists of two phases. Our algorithm first constructs sets of affixes closely mimicking the paradigms of a language. And with these structures in hand, ParaMor then annotates word forms with morpheme boundaries. To set ParaMor’s few free parameters we analyze a training corpus of Spanish. Without adjusting parameters, we induce the morphological structure of English and German. Adopting the evaluation methodology of Morpho Challenge 2007 (Kurimo et al., 2007), we compare ParaMor’s morphological analyses with Morfessor (Creutz, 2006), a modern minimally supervised morphology induction system. ParaMor consistently achieves competitive F1 measures. 1 Introduction Words in natural language (NL) have internal structure. Morphological processes derive new lexemes from old ones or inflect the surface form of lexemes to mark morphosyntactic features such as tense, number, person, etc. This paper address minimally supervised induction of productive natural language morphology from text. Minimally supervised induction of morphology interests us both for practical and theoretical reasons. In linguistic theory, the morpheme is often</context>
<context position="9963" citStr="Creutz (2006)" startWordPosition="1485" endWordPosition="1486">ber of erroneous initially selected candidate inflection classes. Finally, with a strong grasp on the paradigm structure, ParaMor straightforwardly segments the words of a corpus into morphemes. 1.3 Related Work In this section we highlight previously proposed minimally supervised approaches to the induction of morphology that, like ParaMor, draw on the unique structure of natural language morphology. One facet of NL morphological structure commonly leveraged by morphology induction algorithms is that morphemes are recurrent building blocks of words. Brent et al. (1995), Goldsmith (2001), and Creutz (2006) emphasize the building block nature of morphemes when they each use recurring word segments to efficiently encode a corpus. These approaches then hypothesize that those recurring segments which most efficiently encode a corpus are likely morphemes. Another technique that exploits morphemes as repeating sub-word segments encodes the lexemes of a corpus as a character tree, i.e. trie, (Harris, 1955; Hafer and Weis, 1974), or as a finite state automaton (FSA) over characters (Johnson, H. and Martin, 2003; Altun and M. Johnson, 2001). A trie or FSA conflates multiple instances of a morpheme into </context>
<context position="35086" citStr="Creutz, 2006" startWordPosition="5561" endWordPosition="5562">hology. We constructed Morpho Challenge 2007 style answer keys for each language and each task using the Celex database (Burnage, 1990). The English and German corpora we test over are the corpora available through Morpho Challenge 2007. The English corpus contains nearly 385,000 types, while the German corpus contains more than 1.26 million types. ParaMor induced paradigmatic scheme-clusters over these larger corpora by reading just the top 50,000 most frequent types. But with the scheme-clusters in hand, ParaMor segmented all the types in each corpus. We compare ParaMor to Morfessor v0.9.2 (Creutz, 2006), a state-of-the-art minimally supervised morphology induction algorithm. Morfessor has a single free parameter. To make for stiff competition, we report results for Morfessor at that parameter setting which maximized F1 on each separate test scenario. We did not vary the two free parameters of ParaMor, but hold each of ParaMor’s parameters at a setting which produced reasonable Spanish suffix sets, see sections 2.1-2.2. Table 2 contains the evaluation results. To estimate the variance of our experimental results we measured Morpho Challenge 2007 style precision, recall, and F1 on multiple non</context>
<context position="36688" citStr="Creutz, 2006" startWordPosition="5815" endWordPosition="5816">inflectional morphemes comes from closely modeling the natural paradigm structure of language. Conversely, Morfessor places its focus on precision and does not rely on any property exclusive to inflectional (or derivational) morphology. Hence, 124 Inflectional Morphology Only Inflectional &amp; Derivational Morphology English German English German P R F1 P R F1 P R F1 P R F1 Morfessor 53.3 47.0 49.9 1.3 38.7 44.2 41.2 0.8 73.6 34.0 46.5 1.1 66.9 37.1 47.7 0.7 ParaMor 33.0 81.4 47.0 0.9 42.8 68.6 52.7 0.8 48.9 53.6 51.1 0.8 60.0 33.5 43.0 0.7 Table 2: ParaMor segmentations compared to Morfessor’s (Creutz, 2006) evaluated for Precision, Recall, F1, and standard deviation of F1, , in four scenarios. Segmentations over English and German are each evaluated against correct morphological analyses consisting, on the left, of inflectional morphology only, and on the right, of both inflectional and derivational morphology. Morfessor attains high precision with reasonable recall when graded against an answer key containing both inflectional and derivational morphology. We are excited by ParaMor’s strong performance and are eager to extend our algorithm. We believe the precision of ParaMor’s simple segmentati</context>
</contexts>
<marker>Creutz, 2006</marker>
<rawString>Creutz, Mathias. “Induction of the Morphology of Natural Language: Unsupervised Morpheme Segmentation with Application to Automatic Speech Recognition.” Ph.D. Thesis in Computer and Information Science, Report D13. Helsinki: University of Technology, Espoo, Finland, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Goldsmith</author>
</authors>
<title>Unsupervised Learning of the Morphology of a Natural Language.&amp;quot;</title>
<date>2001</date>
<journal>Computational Linguistics</journal>
<volume>27</volume>
<pages>153--198</pages>
<contexts>
<context position="9944" citStr="Goldsmith (2001)" startWordPosition="1482" endWordPosition="1483">scarding the large number of erroneous initially selected candidate inflection classes. Finally, with a strong grasp on the paradigm structure, ParaMor straightforwardly segments the words of a corpus into morphemes. 1.3 Related Work In this section we highlight previously proposed minimally supervised approaches to the induction of morphology that, like ParaMor, draw on the unique structure of natural language morphology. One facet of NL morphological structure commonly leveraged by morphology induction algorithms is that morphemes are recurrent building blocks of words. Brent et al. (1995), Goldsmith (2001), and Creutz (2006) emphasize the building block nature of morphemes when they each use recurring word segments to efficiently encode a corpus. These approaches then hypothesize that those recurring segments which most efficiently encode a corpus are likely morphemes. Another technique that exploits morphemes as repeating sub-word segments encodes the lexemes of a corpus as a character tree, i.e. trie, (Harris, 1955; Hafer and Weis, 1974), or as a finite state automaton (FSA) over characters (Johnson, H. and Martin, 2003; Altun and M. Johnson, 2001). A trie or FSA conflates multiple instances </context>
</contexts>
<marker>Goldsmith, 2001</marker>
<rawString>Goldsmith, John. &amp;quot;Unsupervised Learning of the Morphology of a Natural Language.&amp;quot; Computational Linguistics 27.2 (2001): 153-198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Margaret A Hafer</author>
<author>Stephen F Weiss</author>
</authors>
<title>Word Segmentation by Letter Successor Varieties.&amp;quot;</title>
<date>1974</date>
<journal>Information Storage and Retrieval</journal>
<volume>10</volume>
<pages>371--385</pages>
<marker>Hafer, Weiss, 1974</marker>
<rawString>Hafer, Margaret A., and Stephen F. Weiss. &amp;quot;Word Segmentation by Letter Successor Varieties.&amp;quot; Information Storage and Retrieval 10.11/12 (1974): 371-385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<title>From Phoneme to Morpheme.&amp;quot;</title>
<date>1955</date>
<journal>Language</journal>
<volume>31</volume>
<pages>190--222</pages>
<note>Reprinted in Harris</note>
<contexts>
<context position="10363" citStr="Harris, 1955" startWordPosition="1545" endWordPosition="1546">gy. One facet of NL morphological structure commonly leveraged by morphology induction algorithms is that morphemes are recurrent building blocks of words. Brent et al. (1995), Goldsmith (2001), and Creutz (2006) emphasize the building block nature of morphemes when they each use recurring word segments to efficiently encode a corpus. These approaches then hypothesize that those recurring segments which most efficiently encode a corpus are likely morphemes. Another technique that exploits morphemes as repeating sub-word segments encodes the lexemes of a corpus as a character tree, i.e. trie, (Harris, 1955; Hafer and Weis, 1974), or as a finite state automaton (FSA) over characters (Johnson, H. and Martin, 2003; Altun and M. Johnson, 2001). A trie or FSA conflates multiple instances of a morpheme into a single sequence of states. Because the choice of possible succeeding characters is highly constrained within a morpheme, branch points in the trie or FSA are likely morpheme boundaries. Often trie similarities are used as a first step followed by further processing to identify morphemes (Schone and Jurafsky, 2001). The paradigm structure of NL morphology has also been previously leveraged. Golds</context>
<context position="31240" citStr="Harris (1955)" startWordPosition="4936" endWordPosition="4937">rs is reduced by more than 98%, while the number of unique candidate suffixes in any cluster is reduced by more than 85%. Note that the initial number of selected schemes, 8339, falls outside the scale of Figure 3. Of the scheme-clusters which remain after size based filtering is complete, by far the largest category of incorrect clusters contains schemes which, like the 1593rd selected scheme, shown in Figure 2, incorrectly hypothesize morpheme boundaries one or more characters to the left of the true boundary. To filter out these incorrectly segmented clusters we use a technique inspired by Harris (1955). For each initial string common to all suffixes in the cluster, for each scheme in the cluster, we examine the network scheme containing the suffixes formed by stripping the initial string from the scheme’s # of Clusters 1000 400 200 600 800 0 # of Clusters Recall 0.8 0.6 0.4 0.2 0 1 Recall 123 suffixes. We then measure the entropy of leftward trie characters of the stripped scheme. If the entropy is large, then the character stripped scheme is likely at a morpheme boundary and the original scheme is likely modeling an incorrect morpheme boundary. This algorithm would throw out the 1593rd sel</context>
</contexts>
<marker>Harris, 1955</marker>
<rawString>Harris, Zellig. &amp;quot;From Phoneme to Morpheme.&amp;quot; Language 31.2 (1955): 190-222. Reprinted in Harris 1970.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<title>Papers in Structural and Transformational</title>
<date>1970</date>
<location>Dordrecht</location>
<marker>Harris, 1970</marker>
<rawString>Harris, Zellig. Papers in Structural and Transformational Linguists. Ed. D. Reidel, Dordrecht 1970.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Howard Johnson</author>
<author>Joel Martin</author>
</authors>
<title>Unsupervised Learning of Morphology for English and Inuktitut.&amp;quot;</title>
<date>2003</date>
<booktitle>Human Language Technology Conference / North American Chapter of the Association for Computational Linguistics (HLT-NAACL).</booktitle>
<location>Edmonton, Canada:</location>
<marker>Johnson, Martin, 2003</marker>
<rawString>Johnson, Howard, and Joel Martin. &amp;quot;Unsupervised Learning of Morphology for English and Inuktitut.&amp;quot; Human Language Technology Conference / North American Chapter of the Association for Computational Linguistics (HLT-NAACL). Edmonton, Canada: 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikko Kurimo</author>
<author>Mathias Creutz</author>
<author>Matti Varjokallio</author>
</authors>
<title>Unsupervised Morpheme Analysis – Morpho Challenge</title>
<date>2007</date>
<contexts>
<context position="1151" citStr="Kurimo et al., 2007" startWordPosition="150" endWordPosition="153">etons; performing on par with state-ofthe-art minimally supervised morphology induction algorithms at morphological analysis of English and German. ParaMor consists of two phases. Our algorithm first constructs sets of affixes closely mimicking the paradigms of a language. And with these structures in hand, ParaMor then annotates word forms with morpheme boundaries. To set ParaMor’s few free parameters we analyze a training corpus of Spanish. Without adjusting parameters, we induce the morphological structure of English and German. Adopting the evaluation methodology of Morpho Challenge 2007 (Kurimo et al., 2007), we compare ParaMor’s morphological analyses with Morfessor (Creutz, 2006), a modern minimally supervised morphology induction system. ParaMor consistently achieves competitive F1 measures. 1 Introduction Words in natural language (NL) have internal structure. Morphological processes derive new lexemes from old ones or inflect the surface form of lexemes to mark morphosyntactic features such as tense, number, person, etc. This paper address minimally supervised induction of productive natural language morphology from text. Minimally supervised induction of morphology interests us both for pra</context>
<context position="33434" citStr="Kurimo et al., 2007" startWordPosition="5308" endWordPosition="5311">e second suffix f ′ E C such that t. f ′ is a word form found in either of the training or the test corpora, then ParaMor proposes a segmentation of w between t and f . ParaMor, here, identifies f and f ′ as mutually exclusive suffixes from the same paradigm. If ParaMor finds no complex analysis, then we propose w itself as the sole analysis of the word. Note that for each word form, ParaMor may propose multiple separate segmentation analyses each containing a single proposed stem and suffix. To evaluate ParaMor’s morphological segmentations we follow the methodology of Morpho Challenge 2007 (Kurimo et al., 2007), a minimally supervised morphology induction competition. Word segmentations are evaluated in Morpho Challenge 2007 by comparing against hand annotated morphological analyses. The correctness of proposed morphological analyses is computed in Morpho Challenge 2007 by comparing pairs of word forms which share portions of their analyses. Recall is measured by first sampling pairs of words from the answer analyses which share a stem or morphosyntactic feature and then noting if that pair of word forms shares a morpheme in any of their proposed analyses. Precision is measured analogously, sampling</context>
</contexts>
<marker>Kurimo, Creutz, Varjokallio, 2007</marker>
<rawString>Kurimo, Mikko, Mathias Creutz, and Matti Varjokallio. “Unsupervised Morpheme Analysis – Morpho Challenge 2007.” March 26, 2007. &lt;http://www.cis.hut.fi/morphochallenge2007/&gt;</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Schone</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Knowledge-Free Induction of Inflectional Morphologies.&amp;quot; North American Chapter of the Association for Computational Linguistics (NAACL).</title>
<date>2001</date>
<pages>183--191</pages>
<location>Pittsburgh, Pennsylvania:</location>
<contexts>
<context position="10880" citStr="Schone and Jurafsky, 2001" startWordPosition="1628" endWordPosition="1631"> as repeating sub-word segments encodes the lexemes of a corpus as a character tree, i.e. trie, (Harris, 1955; Hafer and Weis, 1974), or as a finite state automaton (FSA) over characters (Johnson, H. and Martin, 2003; Altun and M. Johnson, 2001). A trie or FSA conflates multiple instances of a morpheme into a single sequence of states. Because the choice of possible succeeding characters is highly constrained within a morpheme, branch points in the trie or FSA are likely morpheme boundaries. Often trie similarities are used as a first step followed by further processing to identify morphemes (Schone and Jurafsky, 2001). The paradigm structure of NL morphology has also been previously leveraged. Goldsmith (2001) uses morphemes to efficiently encode a corpus, but he first groups morphemes into paradigm like structures he calls signatures. To date, the work that draws the most on paradigm structure is Snover (2002). Snover incorporates paradigm structure into a generative statistical model of morphology. Additionally, to discover paradigm like sets of suffixes, Snover designs and searches networks of partial paradigms. These networks are the direct inspiration for ParaMor’s morphology scheme networks described</context>
</contexts>
<marker>Schone, Jurafsky, 2001</marker>
<rawString>Schone, Patrick, and Daniel Jurafsky. &amp;quot;Knowledge-Free Induction of Inflectional Morphologies.&amp;quot; North American Chapter of the Association for Computational Linguistics (NAACL). Pittsburgh, Pennsylvania: 2001. 183-191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew G Snover</author>
</authors>
<title>An Unsupervised Knowledge Free Algorithm for the Learning of Morphology in Natural Languages.&amp;quot;</title>
<date>2002</date>
<tech>M.S. Thesis,</tech>
<institution>Sever Institute of Technology, Computer Science Saint Louis, Missouri: Washington University,</institution>
<contexts>
<context position="11179" citStr="Snover (2002)" startWordPosition="1676" endWordPosition="1677">ingle sequence of states. Because the choice of possible succeeding characters is highly constrained within a morpheme, branch points in the trie or FSA are likely morpheme boundaries. Often trie similarities are used as a first step followed by further processing to identify morphemes (Schone and Jurafsky, 2001). The paradigm structure of NL morphology has also been previously leveraged. Goldsmith (2001) uses morphemes to efficiently encode a corpus, but he first groups morphemes into paradigm like structures he calls signatures. To date, the work that draws the most on paradigm structure is Snover (2002). Snover incorporates paradigm structure into a generative statistical model of morphology. Additionally, to discover paradigm like sets of suffixes, Snover designs and searches networks of partial paradigms. These networks are the direct inspiration for ParaMor’s morphology scheme networks described in section 2.1. 2 ParaMor: Inflection Class Identification 2.1 Search A Search Space: The first stage of ParaMor is a search procedure designed to identify partial inflection classes containing as many true productive suffixes of a language as possible. To search for these partial inflection class</context>
</contexts>
<marker>Snover, 2002</marker>
<rawString>Snover, Matthew G. &amp;quot;An Unsupervised Knowledge Free Algorithm for the Learning of Morphology in Natural Languages.&amp;quot; Sever Institute of Technology, Computer Science Saint Louis, Missouri: Washington University, M.S. Thesis, 2002.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>