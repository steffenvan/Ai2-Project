<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.585542">
TAL Recognition in 0(M(n2)) Time
</title>
<author confidence="0.671718">
Sanguthevar Raj asekaran
</author>
<affiliation confidence="0.918053">
Dept. of CISE, Univ. of Florida
</affiliation>
<email confidence="0.97582">
raj@cis.uledu
</email>
<author confidence="0.88797">
Shibu Yooseph
</author>
<affiliation confidence="0.992098">
Dept. of CIS, Univ. of Pennsylvania
</affiliation>
<email confidence="0.996684">
yooseph@gradient.cis.upenn.edu
</email>
<sectionHeader confidence="0.988288" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999949722222222">
We propose an 0(M(n2)) time algorithm
for the recognition of Tree Adjoining Lan-
guages (TALs), where n is the size of the
input string and M(k) is the time needed
to multiply two k x k boolean matrices.
Tree Adjoining Grammars (TAGs) are for-
malisms suitable for natural language pro-
cessing and have received enormous atten-
tion in the past among not only natural
language processing researchers but also al-
gorithms designers. The first polynomial
time algorithm for TAL parsing was pro-
posed in 1986 and had a run time of 0(n6).
Quite recently, an 0(n3 M(n)) algorithm
has been proposed. The algorithm pre-
sented in this paper improves the run time
of the recent result using an entirely differ-
ent approach.
</bodyText>
<sectionHeader confidence="0.99876" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999558451612903">
The Tree Adjoining Grammar (TAG) formalism was
introduced by Joshi, Levy and Takahashi (1975).
TAGs are tree generating systems, and are strictly
more powerful than context-free grammars. They
belong to the class of mildly context sensitive gram-
mars (Joshi, et al., 1991). They have been found
to be good grammatical systems for natural lan-
guages (Kroch, Joshi, 1985). The first polynomial
time parsing algorithm for TALs was given by Vi-
jayashanker and Joshi (1986), which had a run time
of 0(n6), for an input of size n. Their algorithm
had a flavor similar to the Cocke-Younger-Kasami
(CYK) algorithm for context-free grammars. An
Earley-type parsing algorithm has been given by
Schabes and Joshi (1988). An optimal linear time
parallel parsing algorithm for TALs was given by
Palis, Shende and Wei (1990). In a recent paper,
Rajasekaran (1995) shows how TALs can be parsed
in time 0 (n3 M(n)).
In this paper, we propose an 0(M(n2)) time
recognition algorithm for TALs, where M(k) is the
time needed to multiply two k x k boolean matri-
ces. The best known value for M(k) is 0(n2.376)
(Coppersmith, Winograd, 1990). Though our algo-
rithm is similar in flavor to those of Graham, Har-
rison, &amp; Ruzzo (1976), and Valiant (1975) (which
were algorithms proposed for recognition of Con-
text Free Languages (CFLs)), there are crucial dif-
ferences. As such, the techniques of (Graham, et al.,
1976) and (Valiant, 1975) do not seem to extend to
TALs (Satta, 1993).
</bodyText>
<sectionHeader confidence="0.950209" genericHeader="introduction">
2 Tree Adjoining Grammars
</sectionHeader>
<bodyText confidence="0.954697375">
A Tree Adjoining Grammar (TAG) consists of a
quintuple (N, E U {E}, /, A, S), where
N is a finite set of nonterminal symbols,
E is a finite set of terminal symbols disjoint from
N,
c is the empty terminal string not in E,
I is a finite set of labelled initial trees,
A is a finite set of auxiliary trees,
</bodyText>
<equation confidence="0.432395">
S E Nis the distinguished start symbol
</equation>
<bodyText confidence="0.99875719047619">
The trees in / U A are called elementary trees. All
internal nodes of elementary trees are labelled with
nonterminal symbols. Also, every initial tree is la-
belled at the root by the start symbol S and has
leaf nodes labelled with symbols from E U {e}. An
auxiliary tree has both its root and exactly one leaf
(called the foot node ) labelled with the same non-
terminal symbol. All other leaf nodes are labelled
with symbols in EU fel, at least one of which has a
label strictly in E. An example of a TAG is given in
figure 1.
A tree built from an operation involving two other
trees is called a derived tree. The operation involved
is called adjunction. Formally, adjunction is an op-
eration which builds a new tree -y, from an auxiliary
tree # and another tree a (a is any tree - initial, aux-
iliary or derived). Let a contain an internal node m
labelled X and let # be the auxiliary tree with root
node also labelled X. The resulting tree 7, obtained
by adjoining # onto a at node m is built as follows
(figure 2):
</bodyText>
<page confidence="0.995584">
166
</page>
<figure confidence="0.998095333333333">
Initial tree
Auxiliary tree
G = ((S),(a,b,c,E), (a), ( p ), S)
</figure>
<figureCaption confidence="0.999948">
Figure 1: Example of a TAG
</figureCaption>
<listItem confidence="0.986923875">
1. The subtree of a rooted at m, call it t, is excised,
leaving a copy of m behind.
2. The auxiliary tree is attached at the copy of
m and its root node is identified with the copy
of m.
3. The subtree t is attached to the foot node of 16
and the root node of t (i.e. m) is identified with
the foot node of P.
</listItem>
<bodyText confidence="0.999512076923077">
This definition can be extended to include adjunc-
tion constraints at nodes in a tree. The constraints
include Selective, Null and Obligatory adjunction
constraints. The algorithm we present here can be
modified to include constraints.
For our purpose, we will assume that every inter-
nal node in an elementary tree has exactly 2 children.
Each node in a tree is represented by a tuple &lt;
tree, node index, label &gt;. (For brevity, we will refer
to a node with a single variable m whereever there
is no confusion)
A good introduction to TAGs can be found in
(Partee, et al., 1990).
</bodyText>
<sectionHeader confidence="0.9145845" genericHeader="method">
3 Context Free recognition in
0(M(n)) Time
</sectionHeader>
<bodyText confidence="0.9386210625">
The CFG G = (N,E,P,A1), where
Nis a set of Nonterminals {Ai, A2, ..,Ak},
E is a finite set of terminals,
P is a finite set of productions,
A1 is the start symbol
is assumed to be in the Chomsky Normal Form.
Valiant (1975) shows how the recognition problem
can be reduced to the problem of finding Transitive
Closure and how Transitive Closure can be reduced
to Matrix Multiplication.
Given an input string ala2--an E E*, the recur-
sive algorithm makes use of an (71+1)x (n+1) upper
triangular matrix b defined by
bi,i+/ = {Ak I (Ak --+ ai) E P},
= 0, for j i +1
and proceeds to find the transitive closure 6+ of this
</bodyText>
<equation confidence="0.768637333333333">
matrix. (If 6+ is the transitive closure, then Ak E
Ak a • a • i)
1,1
</equation>
<bodyText confidence="0.999627833333333">
Instead of finding the transitive closure by the cus-
tomary method based on recursively splitting into
disjoint parts, a more complex procedure based on
&apos;splitting with overlaps&apos; is used. The extra cost in-
volved in such a strategy can be made almost negligi-
ble. The algorithm is based on the following lemma
</bodyText>
<construct confidence="0.9914116">
Lemma : Let b be an n x n upper triangular ma-
trix, and suppose that for any r &gt; n/2, the tran-
sitive closure of the partitions [1 &lt; i, j &lt; r] and
[n — r &lt; i, j &lt; n] are known. Then the closure of b
can be computed by
</construct>
<listItem confidence="0.8806602">
1. performing a single matrix multiplication, and
2. finding the closure of a 2(n — r) x 2(n — r) up-
per triangular matrix of which the closure of the
partitions [1 &lt; i,j &lt; n — r] and [n — r &lt; i,j &lt;
2(n — r)] are known.
</listItem>
<subsubsectionHeader confidence="0.521068">
Proof: See (Valiant, 1975) for details
</subsubsectionHeader>
<bodyText confidence="0.9522065">
The idea behind (Valiant, 1975) is based on visu-
alizing Ak E btj as spanning a tree rooted at the
node Ak with leaves ai through aj_i and internal
nodes as nonterminals generated from Ak according
to the productions in P. Having done this, the fol-
lowing observation is made :
Given an input string a1 ...a and 2 distinct sym-
bol positions, i and j, and a nonterminal Ak such
that Ak E b., where &lt; &gt; j, then 3 a non-
terminal Aki which is a descendent of Ak in the
tree rooted at Ak, such that Ak&apos; E bt where
z &lt; i,3 &gt; j and Ak&apos; has two children Ak, and Ak2
such that Ak, E bt and Ak2 E b.+1,. with i &lt; s &lt; j.
Ak&apos; can be thought of as a minimal node in this
sense.(The descendent relation is both reflexive and
transitive)
Thus, given a string al...an of length it, (say r =
2/3), the following steps are done :
</bodyText>
<equation confidence="0.765959666666667">
1 67
adjoined X
AX
</equation>
<figureCaption confidence="0.988825">
Figure 2: Adjunction Operation
</figureCaption>
<listItem confidence="0.99839725">
1. Find the closure of the first 2/3 ,i.e. all nodes
spanning trees which are within the first 2/3 .
2. Find the closure of the last 2/3 , i.e. all nodes
spanning trees which are within the last 2/3.
3. Do a composition operation (i.e. matrix multi-
plication) on the nodes got as a result of Step
1 with nodes got as a result of Step 2.
4. Reduce problem size to al ...anpa
</listItem>
<bodyText confidence="0.998770944444444">
and find closure of this input. 1+2,/3...a.
The point to note is that in step 3, we can get rid
of the mid 1/3 and focus on the remaining problem
size.
This approach does not work for TALs because of
the presence of the adjunction operation.
Firstly, the data structure used, i.e. the 2-
dimensional matrix with the given representation,
is not sufficient as adjunction does not operate on
contiguous strings. Suppose a node in a tree domi-
nates a frontier which has the substring as ai to the
left of the foot node and 401 to the right of the
footnode. These substrings need not be a contigu-
ous part of the input; in fact, when this tree is used
for adjunction then a string is inserted between these
two substrings. Thus in order to represent a node,
we need to use a matrix of higher dimension, namely
dimension 4, to characterize the substring that ap-
pears to the left of the footnode and the substring
that appears to the right of the footnode.
Secondly, the observation we made about an entry
E b+ is no longer quite true because of the presence
of adjunction.
Thirdly, the technique of getting rid of the mid
1/3 and focusing on the reduced problem size alone,
does not work as shown in figure 3:
Suppose 7 is a derived tree in which 3 a node m
on which adjunction was done by an auxiliary tree
/3. Even if we are able to identify the derived tree
71 rooted at m, we have to first identify before we
can check for adjunction. i3 need not be realised as
a result of the composition operation involving the
nodes from the first and last 2/3&apos;s ,(say r =2/3).
Thus, if we discard the mid 1/3, we will not be able
to infer that the adjunction had indeed taken place
at node m.
</bodyText>
<sectionHeader confidence="0.992212" genericHeader="method">
4 Notations
</sectionHeader>
<bodyText confidence="0.999872433333334">
Before we introduce the algorithm, we state the no-
tations that will be used.
We will be making use of a 4-dimensional matrix
A of size (n+ 1) x (n+ 1) x (n+ 1) x (n+ 1), where
n is the size of the input string.
(Vijayashanker, Joshi, 1986) Given a TAG G and
an input string aia2..an, n &gt; 1, the entries in A will
be nodes of the trees of G. We say, that a node m
&lt; 71, node index , label &gt;) E A(i,j, k, 1) if m is a
node in a derived tree 7 and the subtree of 7 rooted
at m has a yield given by either ai+1...aiXak+1...ai
(where X is the footnode of n, j &lt; k) or ai+1....a/
(when j = k).
If a node m E A(i,j,k,1), we will refer to m as
spanning a tree (i,j,k,1).
When we refer to a node m being realised as a
result of composition of two nodes ml and m2, we
mean that 3 an elementary tree in which m is the
parent of ml and m2.
A Grown Auxiliary Tree is defined to be either
a tree resulting from an adjunction involving two
auxiliary trees or a tree resulting from an adjunction
involving an auxiliary tree and a grown auxiliary
tree.
Given a node m spanning a tree (i,j,k,/), we define
the last operation to create this tree as follows :
if the tree (i,j,k,l) was created in a series of op-
erations, which also involved an adjunction by an
auxiliary tree (or a grown auxiliary tree) (1, ji, kJ., 1)
onto the node m, then we say that the last opera-
</bodyText>
<listItem confidence="0.924469333333333">
• tion to create this tree is an adjunction operation;
else the last operation to create the tree (i,j,k,/) is a
composition.
</listItem>
<bodyText confidence="0.9985705">
The concept of last operation is useful in modelling
the steps required, in a bottom-up fashion, to create
</bodyText>
<page confidence="0.995366">
168
</page>
<figureCaption confidence="0.999194">
Figure 3: Situation where we cannot infer the adjunction if we simply get rid of the mid 1/3
</figureCaption>
<figure confidence="0.971104333333333">
Derived tree y
Node m has label X
a tree.
</figure>
<sectionHeader confidence="0.900126" genericHeader="method">
5 Algorithm
</sectionHeader>
<bodyText confidence="0.9874385">
Given that the set of initial and auxiliary trees can
have leaf nodes labelled with E, we do some prepro-
cessing on the TAG G to obtain an Association List
(ASSOC LIST) for each node. ASSOC LIST (m),
where m is a node, will be useful in obtaining chains
of nodes in elementary trees which have children la-
belled e.
Initialize ASSOC LIST (m) = V m, and then
call procedure MAKELIST on each elementary tree,
in a top down fashion starting with the root node.
Procedure MAKELIST (m)
Begin
</bodyText>
<listItem confidence="0.99687575">
1. If m is a leaf then quit
2. If m has children ml and m2 both yielding the
empty string at their frontiers (i.e. m spans a
subtree yielding E) then
</listItem>
<equation confidence="0.5310025">
ASSOC LIST (m1)= ASSOC
LIST (m)U {m}
ASSOC LIST (m2) = ASSOC
LIST (m)U {m}
</equation>
<listItem confidence="0.9716525">
3. If m has children ml and m2, with only m2
yielding the empty string at its frontier, then
</listItem>
<equation confidence="0.8929795">
ASSOC LIST (m1) = ASSOC
LIST (m) U {m}
</equation>
<bodyText confidence="0.962416857142857">
End
We initially fill A(i,i+1,i+1,i+1) with all nodes
from Sin&apos;, Vml, where Smi -= U AS-
SOC LIST (m1), ml being a node with the same
label as the input ai+1, for 0 &lt; i &lt; n-1. We also fill
A &lt; j, with nodes from Sm2,Vm2, where
ImP4 U ASSOC LIST (m2), m2 being a foot
node. All entries 0 &lt; i &lt; n, are filled with
nodes from Sm3,Vrn3, where Sm3 = {m3} u AS-
SOC LIST (m3), m3 having label E.
Following is the main procedure, Compute Nodes,
which takes as input a sequence r1r2 rp of symbol
positions (not necessarily contiguous). The proce-
dure outputs all nodes spanning trees (i,j,k,/), with
{i,/} E {ri,r2 rp} and {j,k} E {ri,ri + 1, •-•,rp}•
The procedure is initially called with the sequence
012..n corresponding to the input string al an.
The matrix A is updated with every call to this pro-
cedure and it is updated with the nodes just realised
and also with the nodes in the ASSOC LISTs of the
nodes just realised.
</bodyText>
<listItem confidence="0.942315142857143">
Procedure Compute Nodes ( r1r2 r)
Begin
1. If p = 2, then
a. Compose all nodes E A(ri, j, k, r2) with all
nodes E A(r2, r2, r2, r2), r1 &lt; j &lt; k &lt; r2.
Update A .
b. Compose all nodes E A(ri , ri , ri, ri) with
all nodes E A(ri,i, k, r2), r1 &lt;j &lt; k &lt; rz.
Update A.
c. Check for adjunctions involving nodes re-
alised from steps a and b. Update A .
d. Return
2. Compute Nodes ( rir2 r2p/3 ).
3. Compute Nodes ( ri+pis rp )-
4. a. Compose nodes realised from step 2 with
nodes realised from step 3.
b. Update A.
5. a. Check for all possible adjunctions involving
the nodes realised as a result of step 4.
b. Update A.
6. Compute Nodes ( rir2...rplari+2p13...rp )
</listItem>
<page confidence="0.994247">
169
</page>
<subsectionHeader confidence="0.346192">
End
</subsectionHeader>
<bodyText confidence="0.999443428571428">
Steps la,lb and 4a can be carried out in the fol-
lowing manner:
Consider the composition of node ml with node
m2. For step 4a, there are two cases to take care of.
Case 1
If node ml in a derived tree is the ancestor of the
foot node, and node m2 is its right sibling, such that
ml E A(i, j,k,l) and m2 E A(1,r,r, s), then their
parent, say node m should belong to A(i, j,k, s).
This composition of m/ with m2 can be reduced to a
boolean matrix multiplication in the following way:
(We use a technique similar to the one used in (Ra-
jasekaran, 1995)) Construct two boolean matrices
B1, of size ((n + 1)2p/3) x (p/3) and B2, of size
</bodyText>
<equation confidence="0.7704095">
(P/3) x (P/3).
= 1 if ml E A(i , j , k, 1)
</equation>
<bodyText confidence="0.955187333333333">
and i E ••,
and 1 E {ri÷p/3, ..r2p13}
= 0 otherwise
</bodyText>
<equation confidence="0.9445875">
Note that in B1 0 &lt; j &lt; k &lt; n.
B2(1,$) = 1 if m2 E A(1, r, r, s)
</equation>
<bodyText confidence="0.989383214285714">
and 1 E {ri+p13, ..r213}
and s E {r1+2p/3, rp}
= 0 otherwise
Clearly the dot product of the ijkth row of BI
with the sth column of B2 is a 1 if m E A(i, j,k,$).
Thus, update A(i, j,k, s) with {m} U ASSOC LIST
(m).
Case 2
If node m2 in a derived tree is the ancestor of the
foot node, and node ml is its left sibling, such that
ml E A(i, j, j, 1) and m2 E A(1, p, q, r), then their
parent, say node m should belong to A(i,p,q, s).
This can also be handled similar to the manner de-
scribed for case 1. Update A(i, p, q, s) with {m} U
</bodyText>
<sectionHeader confidence="0.532581" genericHeader="method">
ASSOC LIST (m).
</sectionHeader>
<bodyText confidence="0.979519076923077">
Notice that Case 1 also covers step la and Case 2
also covers step lb.
Step 5a and Step lc can be carried out in the
following manner :
We know that if a node m E A(i, j, k,1), and the
root ml of an auxiliary tree E A(r, i,1, s), then ad-
joining the tree n, rooted at ml, onto the node m,
results in the node m spanning a tree (r,j,k,$), i.e. m
E A(r, j, k, s).
We can essentially use the previous technique of
reducing to boolean matrix multiplication. Con-
struct two matrices Cl and C2 of sizes (p2/9) x (n+
1)2 and (n + 1)2 x (n + 1)2, respectively, as follows :
</bodyText>
<equation confidence="0.880547166666667">
C/(ii,jk) = 1 if 3m1, root of an auxiliary
tree E A(i, j,k,1), with same label as m and
C./(i/,jk) = 0 otherwise
Note that in Cl i E 1 E
{ri÷2p/s, rp}, and 0 &lt;j &lt; k &lt; n.
C2(qt,rs) 1 iff m A(q, r, s,t)
</equation>
<bodyText confidence="0.926278222222222">
= 0 otherwise
Note that in C2 0&lt;q&lt;r&lt;s&lt;t&lt; n.
Clearly the dot product of the 11th row of Cl with
the rith column of C2 is a 1 if m E A(i, r, s, I).
Thus, update A(i, r, s,1) with {m} U ASSOC LIST
(m).
The input string aia2...an is in the language gener-
ated by the TAG G if 3 a node labelled S in some
A(0, j, j,n), 0 &lt;j &lt;n.
</bodyText>
<sectionHeader confidence="0.978442" genericHeader="method">
6 Complexity
</sectionHeader>
<bodyText confidence="0.606938">
Steps la, lb and 4a can be computed in
</bodyText>
<equation confidence="0.938866714285714">
0 (n2 M (p)).
Steps 5a and lc can be computed in
002/p2)2m(p2)).
If T(p) is the time taken by the procedure Compute
Nodes, for an input of size p, then
T(p) = 3T(2p/3)+0(n2M(p))+
0( (n2/P2)2M (P2))
</equation>
<bodyText confidence="0.995370333333333">
where n is the initial size of the input string.
Solving the recurrence relation, we get T(n) =
0(M(n2)).
</bodyText>
<sectionHeader confidence="0.807247" genericHeader="method">
7 Proof of Correctness
</sectionHeader>
<bodyText confidence="0.99998825">
We will show the proof of correctness of the algo-
rithm by induction on the length of the sequence of
symbol positions.
But first, we make an observation, given any two
symbol positions (r,, re), rt &gt; r, +1 , and a node m
spanning a tree (i, j,k,l) such that i &lt; r, and / &gt; rt
with j and k in any of the possible combinations as
shown in figure 4.
</bodyText>
<listItem confidence="0.879562473684211">
3 a node m which is a descendent of the
node m in the tree (i,j,k,l) and which either
E ASSOC LIST(ml) or is the same as m1, with
ml having one of the two properties mentioned be-
low:
1. ml spans a tree (i1, k1,11) such that the last
operation to create this tree was a composition
operation involving two nodes m2 and m3 with
m2 spanning (ii, j2, k2, /2) and m3 spanning
(12, is, k3, /O. (with (r3 &lt; 12 &lt; re), 01 &lt; rs),
(r &lt; li) and either (j2 = k2, j3 = j1, k3 = k1)
Or (j2 = 11,k2 = k1 ,j3 = k3) )
2. ml spans a tree k1,11) such that the last
operation to create this tree was an adjunction
by an auxiliary tree (or a grown auxiliary tree)
(i1,i2, k2,11), rooted at node m2, onto the node
m1 spanning the tree (j2, j1, ki, k2) such that
node m2 has either the property mentioned in
(1) or belongs to the ASSOC LIST of a node
</listItem>
<page confidence="0.978624">
170
</page>
<figure confidence="0.997996166666666">
rs rt
1
2
3
4
5
</figure>
<figureCaption confidence="0.999994">
Figure 4: Combinations of j and k being considered
</figureCaption>
<bodyText confidence="0.995541444444444">
which has the property mentioned in (1). (The
labels of ml and m2 being the same)
Any node satisfying the above observation will be
called a minimal node w.r.t. the symbol positions
(7-3, re).
The minimal nodes can be identified in the follow-
ing manner. If the node m spans (i, j,k,1) such that
the last operation to create this tree is a composition
of the form in figure 5a, then m U ASSOC LIST(m)
is minimal. Else, if it is as shown in figure 5b, we
can concentrate on the tree spanned by node ml and
repeat the process. But, if the last operation to cre-
ate (i, j, k, 1) was an adjunction as shown in figure
5c, we can concentrate on the tree (ii, j, k, /1) ini-
tially spanned by node m. If the only adjunction
was by an auxiliary tree, on node m spanning tree
k,li) as shown in figure 5d, then the set of
minimal nodes will include both m and the root ml
of the auxiliary_ tree and the nodes in their respec-
tive ASSOC LISTs. But if the adjunction was by a
grown auxiliary tree as shown in figure 5e, then the
minimal nodes include the roots of 131, ..,
and the node m.
Given a sequence &lt; ri, r2, rp &gt;, we call
(rq, rq+i) a gap, if rq.“ rq + 1. Identifying min-
imal nodes w.r.t. every new gap created, will serve
our purpose in determining all the nodes spanning
</bodyText>
<equation confidence="0.892758666666667">
trees (i, j, k, 1), with {i, E rz, ••, rp}•
Theorem : Given an increasing sequence &lt;
ri, r2, rp &gt; of symbol positions and given
</equation>
<bodyText confidence="0.443546">
a. V gaps (rq,rq+1), all nodes spanning trees (i,j,k,l)
withrq&lt;i&lt;j&lt;k&lt;1&lt;rq+i
b. V gaps (rq,rq+1), all nodes spanning trees (i,j,k,l)
such that either rq &lt; i &lt; rq+1 or rq &lt; 1 &lt; rq.4.1
</bodyText>
<listItem confidence="0.620185">
c. V gaps (rq, rq+1), all the minimal nodes for the
gap such that these nodes span trees (i,j,k,l) with
{i,1} E { ri, r2, rp } and i &lt; 1
</listItem>
<construct confidence="0.435543">
in addition to the initialization information, the
algorithm computes all the nodes spanning trees
(i,j,k,l) with {0} E { r1,r2,..,rp } and i &lt; j &lt;
k &lt;1.
</construct>
<subsectionHeader confidence="0.6931915">
Proof:
Base Cases :
</subsectionHeader>
<bodyText confidence="0.991291741935484">
For length = 1, it is trivial as this information is
already known as a result of initialization.
For length = 2, there are two cases to consider :
1. r2 = r1 + 1, in which case a composition in-
volving nodes from A(ri, r1, r1, ri) with nodes
from A(ri, r2, r2, r2) and a composition involv-
ing nodes from A(ri, r2, r2, r2) with nodes from
A(r2, r2, r2, r2), followed by a check for adjunc-
tion involving nodes realised from the previous
two compositions, will be sufficient. Note that
since there is only one symbol from the input
(namely, ar,), and because an auxiliary tree has
at least one label from E, thus, checking for one
adjunction is sufficient as there can be at most
one adjunction.
2. r2 r1 + 1, implies that (ri, r2) is a gap.
Thus, in addition to the information given
as per the theorem, a composition involv-
ing nodes from A(ri, j, k, r2) with nodes from
A(r2, r2, r2, r2) and a composition involving
nodes from A(ri, ri, ri, ri) with nodes from
A(ri, j, k, r2), (ri &lt;j &lt; k &lt; r2), followed by an
adjunction involving nodes realised as a result of
the previous two compositions will be sufficient
as the only adjunction to take care of involves
the adjunction of some auxiliary tree onto a
node m which yields e, and m E A(ri,r1,ri,r1)
or m E A(r2, r2, r2, r2).
Induction hypothesis : V increasing sequence
&lt; r1, r2, rq &gt; of symbol positions of length &lt; p,
(i.e q &lt;p), the algorithm, given the information as
</bodyText>
<page confidence="0.99736">
171
</page>
<figureCaption confidence="0.995742">
Figure 5: Identifying minimal nodes
</figureCaption>
<figure confidence="0.996326555555556">
(5a)
(5b)
rs
rt
Grown aux tree formed by adjoining
Ps P2 Pi
onto root of grown aux tree 7
Root of t1 has property shown in (5a)
7
root of auxiliary
tree has property
shown in (5a)
(5d)
(Sc)
• auxiliary
tree o
grown aux.
tree
</figure>
<bodyText confidence="0.956259956521739">
required by the theorem, computes all nodes span-
ning trees (i,j,k,l) such that {1, E { ri, r2, rq }
and i &lt;j &lt; k &lt;1. Induction: Given an increasing
sequence &lt; ri, r2, rp, rp+i &gt; of symbol positions
together with the information required as per parts
a,b,c of the theorem, the algorithm proceeds as fol-
lows:
1. By the induction hypothesis, the algorithm
correctly computes all nodes spanning trees
(i,j,k,l) within the first 2/3, i.e, {i, l} E {
r1, r2, r2(p+i)/3 } and i &lt;1 . By the hypothe-
sis, it also computes all nodes (i&apos;,F,k&apos;,19 within
the last 2/3, i.e, { i&apos;, 1&apos; } E frii-(p+i)/3,
and i&apos; &lt;1&apos;.
2. The composition step involving the nodes
from the first and last 2/3 of the sequence
&lt; ri, r2, rp, rp+i &gt;, followed by the adjunc-
tion step captures all nodes m such that either
a. m spans a tree (i,j,k,l) such that the last op-
eration to create this tree was a composi-
tion operation on two nodes ml and m2
with ml spanning (i,jck&apos;,19 and m2 span-
ning
</bodyText>
<equation confidence="0.881908">
(1&apos;,j&amp;quot;,k&amp;quot;,1). (with i E { r1, r2, r(p+i)/3 },
E { r1+(p+0/3, r2(p+i)/3 } and I E {
ri+2(p+i)/3, •., rp+1 1, and either (j&apos; = k&apos;,
j&amp;quot; = j, k&amp;quot; = k) or (j&apos; = j, k&apos; = k, j&amp;quot; = k&amp;quot;)
)•
</equation>
<bodyText confidence="0.998857083333333">
b. m spans a tree (i,j,k,Osuch that the last op-
eration to create this tree was an adjunc-
tion by an auxiliary or grown auxiliary tree
0, rooted at node ml, onto the node
m spanning the tree (f,j,k,k9 such that
node ml has either the property mentioned
in (I) or it belongs to the ASSOC LIST of
a node which has the property mentioned
in (1). (The labels of m and ml being the
same)
Note that, in addition to the nodes m captured
from a or b, we will also be realising nodes E
</bodyText>
<sectionHeader confidence="0.793022" genericHeader="method">
ASSOC LIST (m).
</sectionHeader>
<bodyText confidence="0.998234307692308">
The nodes captured as a result of 2 are
the minimal nodes with respect to the gap
(r(p+i)/3, rii.2(p+i)/ 3) with the additional property
that the trees (i,j,k,l) they span are such that i E {
r1, r2, r(p+i)/3 } and 1E { ri+2(p+i)/3, rp44 }.
Before we can apply the hypothesis on the se-
quence &lt; ri , r2, r(p+i)/3, ri4-2(p+i),a, ••ri,4-1 &gt;, we
have to make sure that the conditions in parts
a,b,c of the theorem are met for the new gap
(r(p+i)/3, ri+2(p+i)/3). It is easy to see that con-
ditions for parts a and b are met for this gap. We
have also seen that as a result of step 2, all the mini-
mal nodes w.r.t the gap (r(p+i)/3, ri+2(p4.1)/3), with
</bodyText>
<page confidence="0.993007">
172
</page>
<bodyText confidence="0.999733333333333">
the desired property as required in part c have been
computed. Thus applying the hypothesis on the
sequence &lt; r1, r2, .•, r(p+1)/3, ri-1-2(p+i)/3, -rp+i &gt;,
the algorithm in the end correctly computes all
the nodes spanning trees (i,j,k,l) with {i, l} E
{ri,r2,..,ri}andi&lt;j&lt;k&lt;l.D
</bodyText>
<sectionHeader confidence="0.996715" genericHeader="method">
8 Implementation
</sectionHeader>
<bodyText confidence="0.999945041666667">
The TAL recognizer given in this paper was im-
plemented in Scheme on a SPARC station-10/30.
Theoretical results in this paper and those in (Ra-
jasekaran, 1995) clearly demonstrate that asymp-
totically fast algorithms can be obtained for TAL
parsing with the help of matrix multiplication al-
gorithms. The main objective of the implementa-
tion was to check if matrix multiplication techniques
help in practice also to obtain efficient parsing algo-
rithms.
The recognizer implemented two different algo-
rithms for matrix multiplication, namely the triv-
ial cubic time algorithm and an algorithm that ex-
ploits the sparsity of the matrices. The TAL recog-
nizer that uses the cubic time algorithm has a run
time comparable to that of Vijayashanker-Joshi&apos;s al-
gorithm.
Below is given a sample of a grammar tested and
also the speed up using the sparse version over the
ordinary version. The grammar used, generated the
TAL bn en . This grammar is shown in figure 1.
Interestingly, the sparse version is an order of
magnitude faster than the ordinary version for
strings of length greater than 7.
</bodyText>
<table confidence="0.4857165">
String Answer Speedup
abc Yes 3.1
aabbcc Yes 6.1
aabcabc No 8.0
abacabac No 11.7
aaabbbccc Yes 11.4
</table>
<bodyText confidence="0.9998125">
The above implementation results suggest that
even in practice better parsing algorithms can be
obtained through the use of matrix multiplication
techniques.
</bodyText>
<sectionHeader confidence="0.998658" genericHeader="conclusions">
9 Conclusions
</sectionHeader>
<bodyText confidence="0.9956595">
In this paper we have presented an 0(M(n2)) time
algorithm for parsing TALs, n being the length of
the input string. We have also demonstrated with
our implementation work that matrix multiplication
techniques can help us obtain efficient parsing algo-
rithms.
</bodyText>
<sectionHeader confidence="0.994026" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.981025666666667">
This research was supported in part by an NSF Re-
search Initiation Award CCR-92-09260 and an ARO
grant DAAL03-89-C-0031.
</bodyText>
<sectionHeader confidence="0.992163" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999930673913044">
D. Coppersmith and S. Winograd, Matrix Multi-
plication Via Arithmetic Progressions, in Proc.
19th Annual ACM Symposium on Theory of Com-
puting, 1987,pp. 1-6. Also in Journal of Symbolic
Computation, Vol. 9, 1990, pp. 251-280.
S.L. Graham, M.A. Harrison, and W.L. Ruzzo, On
Line Context Free Language Recognition in Less
than Cubic Time, Proc. ACM Symposium on The-
ory of Computing, 1976, pp. 112-120.
A.K. Joshi, L.S. Levy, and M. Takahashi, Tree Ad-
junct Grammars, Journal of Computer and Sys-
tem Sciences, 10(1), 1975.
A.K. Joshi, K. Vijayashanker and D. Weir, The Con-
vergence of Mildly Context-Sensitive Grammar
Formalisms, Foundational Issues of Natural Lan-
guage Processing, MIT Press, Cambridge, MA,
1991,pp. 31-81.
A. Kroch and A.K. Joshi, Linguistic Relevance of
Tree Adjoining Grammars, Technical Report MS-
CS-85-18, Department of Computer and Informa-
tion Science, University of Pennsylvania, 1985.
M. Palis, S. Shende, and D.S.L. Wei, An Optimal
Linear Time Parallel Parser for Tree Adjoining
Languages, SIAM Journal on Computing,1990.
B.H. Partee, A. Ter Meulen, and R.E. Wall, Stud-
ies in Linguistics and Philosophy, Vol. 30, Kluwer
Academic Publishers, 1990.
S. Rajasekaran, TAL Parsing in o(n6) Time, to ap-
pear in SIAM Journal on Computing, 1995.
G. Satta, Tree Adjoining Grammar Parsing and
Boolean Matrix Multiplication, to be presented in
the 31st Meeting of the Association for Computa-
tional Linguistics, 1993.
G. Satta, Personal Communication, September
1993.
Y. Schabes and A.K. Joshi, An Earley-Type Parsing
Algorithm for Tree Adjoining Grammars, Proc.
26111 Meeting of the Association for Computa-
tional Linguistics, 1988.
L.G. Valiant, General Context-Free Recognition in
Less than Cubic Time, Journal of Computer and
System Sciences, 10,1975, pp. 308-315.
K. Vijayashanker and A.K. Joshi, Some Computa-
tional Properties of Tree Adjoining Grammars,
Proc. 24th Meeting of the Association for Com-
putational Linguistics, 1986.
</reference>
<page confidence="0.999104">
173
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.732039">
<title confidence="0.996131">Recognition in</title>
<author confidence="0.998157">Sanguthevar Raj asekaran</author>
<affiliation confidence="0.999625">Dept. of CISE, Univ. of Florida</affiliation>
<email confidence="0.999192">raj@cis.uledu</email>
<author confidence="0.926577">Shibu Yooseph</author>
<affiliation confidence="0.999565">Dept. of CIS, Univ. of Pennsylvania</affiliation>
<email confidence="0.999822">yooseph@gradient.cis.upenn.edu</email>
<abstract confidence="0.989181">propose an algorithm for the recognition of Tree Adjoining Languages (TALs), where n is the size of the string and the time needed multiply two matrices. Tree Adjoining Grammars (TAGs) are formalisms suitable for natural language processing and have received enormous attention in the past among not only natural language processing researchers but also algorithms designers. The first polynomial time algorithm for TAL parsing was proin 1986 and had a run time of recently, an M(n)) algorithm has been proposed. The algorithm presented in this paper improves the run time of the recent result using an entirely different approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Coppersmith</author>
<author>S Winograd</author>
</authors>
<title>Matrix Multiplication Via Arithmetic Progressions, in</title>
<date>1990</date>
<journal>Journal of Symbolic Computation,</journal>
<booktitle>Proc. 19th Annual ACM Symposium on Theory of Computing, 1987,pp.</booktitle>
<volume>9</volume>
<pages>1--6</pages>
<note>Also in</note>
<marker>Coppersmith, Winograd, 1990</marker>
<rawString>D. Coppersmith and S. Winograd, Matrix Multiplication Via Arithmetic Progressions, in Proc. 19th Annual ACM Symposium on Theory of Computing, 1987,pp. 1-6. Also in Journal of Symbolic Computation, Vol. 9, 1990, pp. 251-280.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S L Graham</author>
<author>M A Harrison</author>
<author>W L Ruzzo</author>
</authors>
<title>On Line Context Free Language Recognition in Less than Cubic Time,</title>
<date>1976</date>
<booktitle>Proc. ACM Symposium on Theory of Computing,</booktitle>
<pages>112--120</pages>
<contexts>
<context position="2299" citStr="Graham, et al., 1976" startWordPosition="376" endWordPosition="379"> was given by Palis, Shende and Wei (1990). In a recent paper, Rajasekaran (1995) shows how TALs can be parsed in time 0 (n3 M(n)). In this paper, we propose an 0(M(n2)) time recognition algorithm for TALs, where M(k) is the time needed to multiply two k x k boolean matrices. The best known value for M(k) is 0(n2.376) (Coppersmith, Winograd, 1990). Though our algorithm is similar in flavor to those of Graham, Harrison, &amp; Ruzzo (1976), and Valiant (1975) (which were algorithms proposed for recognition of Context Free Languages (CFLs)), there are crucial differences. As such, the techniques of (Graham, et al., 1976) and (Valiant, 1975) do not seem to extend to TALs (Satta, 1993). 2 Tree Adjoining Grammars A Tree Adjoining Grammar (TAG) consists of a quintuple (N, E U {E}, /, A, S), where N is a finite set of nonterminal symbols, E is a finite set of terminal symbols disjoint from N, c is the empty terminal string not in E, I is a finite set of labelled initial trees, A is a finite set of auxiliary trees, S E Nis the distinguished start symbol The trees in / U A are called elementary trees. All internal nodes of elementary trees are labelled with nonterminal symbols. Also, every initial tree is labelled a</context>
</contexts>
<marker>Graham, Harrison, Ruzzo, 1976</marker>
<rawString>S.L. Graham, M.A. Harrison, and W.L. Ruzzo, On Line Context Free Language Recognition in Less than Cubic Time, Proc. ACM Symposium on Theory of Computing, 1976, pp. 112-120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>L S Levy</author>
<author>M Takahashi</author>
</authors>
<title>Tree Adjunct Grammars,</title>
<date>1975</date>
<journal>Journal of Computer and System Sciences,</journal>
<volume>10</volume>
<issue>1</issue>
<marker>Joshi, Levy, Takahashi, 1975</marker>
<rawString>A.K. Joshi, L.S. Levy, and M. Takahashi, Tree Adjunct Grammars, Journal of Computer and System Sciences, 10(1), 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>K Vijayashanker</author>
<author>D Weir</author>
</authors>
<title>The Convergence of Mildly Context-Sensitive Grammar Formalisms, Foundational Issues of Natural Language Processing,</title>
<date>1991</date>
<pages>31--81</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="1184" citStr="Joshi, et al., 1991" startWordPosition="187" endWordPosition="190">processing researchers but also algorithms designers. The first polynomial time algorithm for TAL parsing was proposed in 1986 and had a run time of 0(n6). Quite recently, an 0(n3 M(n)) algorithm has been proposed. The algorithm presented in this paper improves the run time of the recent result using an entirely different approach. 1 Introduction The Tree Adjoining Grammar (TAG) formalism was introduced by Joshi, Levy and Takahashi (1975). TAGs are tree generating systems, and are strictly more powerful than context-free grammars. They belong to the class of mildly context sensitive grammars (Joshi, et al., 1991). They have been found to be good grammatical systems for natural languages (Kroch, Joshi, 1985). The first polynomial time parsing algorithm for TALs was given by Vijayashanker and Joshi (1986), which had a run time of 0(n6), for an input of size n. Their algorithm had a flavor similar to the Cocke-Younger-Kasami (CYK) algorithm for context-free grammars. An Earley-type parsing algorithm has been given by Schabes and Joshi (1988). An optimal linear time parallel parsing algorithm for TALs was given by Palis, Shende and Wei (1990). In a recent paper, Rajasekaran (1995) shows how TALs can be pa</context>
</contexts>
<marker>Joshi, Vijayashanker, Weir, 1991</marker>
<rawString>A.K. Joshi, K. Vijayashanker and D. Weir, The Convergence of Mildly Context-Sensitive Grammar Formalisms, Foundational Issues of Natural Language Processing, MIT Press, Cambridge, MA, 1991,pp. 31-81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kroch</author>
<author>A K Joshi</author>
</authors>
<title>Linguistic Relevance of Tree Adjoining Grammars,</title>
<date>1985</date>
<tech>Technical Report MSCS-85-18,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania,</institution>
<marker>Kroch, Joshi, 1985</marker>
<rawString>A. Kroch and A.K. Joshi, Linguistic Relevance of Tree Adjoining Grammars, Technical Report MSCS-85-18, Department of Computer and Information Science, University of Pennsylvania, 1985.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Palis</author>
<author>S Shende</author>
<author>D S L Wei</author>
</authors>
<title>An Optimal Linear Time Parallel Parser for Tree Adjoining Languages,</title>
<journal>SIAM Journal on Computing,1990.</journal>
<marker>Palis, Shende, Wei, </marker>
<rawString>M. Palis, S. Shende, and D.S.L. Wei, An Optimal Linear Time Parallel Parser for Tree Adjoining Languages, SIAM Journal on Computing,1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B H Partee</author>
<author>A Ter Meulen</author>
<author>R E Wall</author>
</authors>
<date>1990</date>
<booktitle>Studies in Linguistics and Philosophy,</booktitle>
<volume>30</volume>
<publisher>Kluwer Academic Publishers,</publisher>
<contexts>
<context position="4728" citStr="Partee, et al., 1990" startWordPosition="845" endWordPosition="848">.e. m) is identified with the foot node of P. This definition can be extended to include adjunction constraints at nodes in a tree. The constraints include Selective, Null and Obligatory adjunction constraints. The algorithm we present here can be modified to include constraints. For our purpose, we will assume that every internal node in an elementary tree has exactly 2 children. Each node in a tree is represented by a tuple &lt; tree, node index, label &gt;. (For brevity, we will refer to a node with a single variable m whereever there is no confusion) A good introduction to TAGs can be found in (Partee, et al., 1990). 3 Context Free recognition in 0(M(n)) Time The CFG G = (N,E,P,A1), where Nis a set of Nonterminals {Ai, A2, ..,Ak}, E is a finite set of terminals, P is a finite set of productions, A1 is the start symbol is assumed to be in the Chomsky Normal Form. Valiant (1975) shows how the recognition problem can be reduced to the problem of finding Transitive Closure and how Transitive Closure can be reduced to Matrix Multiplication. Given an input string ala2--an E E*, the recursive algorithm makes use of an (71+1)x (n+1) upper triangular matrix b defined by bi,i+/ = {Ak I (Ak --+ ai) E P}, = 0, for j</context>
</contexts>
<marker>Partee, Meulen, Wall, 1990</marker>
<rawString>B.H. Partee, A. Ter Meulen, and R.E. Wall, Studies in Linguistics and Philosophy, Vol. 30, Kluwer Academic Publishers, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Rajasekaran</author>
</authors>
<title>TAL Parsing in o(n6) Time, to appear in</title>
<date>1995</date>
<journal>SIAM Journal on Computing,</journal>
<contexts>
<context position="1759" citStr="Rajasekaran (1995)" startWordPosition="283" endWordPosition="284">xt sensitive grammars (Joshi, et al., 1991). They have been found to be good grammatical systems for natural languages (Kroch, Joshi, 1985). The first polynomial time parsing algorithm for TALs was given by Vijayashanker and Joshi (1986), which had a run time of 0(n6), for an input of size n. Their algorithm had a flavor similar to the Cocke-Younger-Kasami (CYK) algorithm for context-free grammars. An Earley-type parsing algorithm has been given by Schabes and Joshi (1988). An optimal linear time parallel parsing algorithm for TALs was given by Palis, Shende and Wei (1990). In a recent paper, Rajasekaran (1995) shows how TALs can be parsed in time 0 (n3 M(n)). In this paper, we propose an 0(M(n2)) time recognition algorithm for TALs, where M(k) is the time needed to multiply two k x k boolean matrices. The best known value for M(k) is 0(n2.376) (Coppersmith, Winograd, 1990). Though our algorithm is similar in flavor to those of Graham, Harrison, &amp; Ruzzo (1976), and Valiant (1975) (which were algorithms proposed for recognition of Context Free Languages (CFLs)), there are crucial differences. As such, the techniques of (Graham, et al., 1976) and (Valiant, 1975) do not seem to extend to TALs (Satta, 1</context>
<context position="13861" citStr="Rajasekaran, 1995" startWordPosition="2666" endWordPosition="2668">ep 4. b. Update A. 6. Compute Nodes ( rir2...rplari+2p13...rp ) 169 End Steps la,lb and 4a can be carried out in the following manner: Consider the composition of node ml with node m2. For step 4a, there are two cases to take care of. Case 1 If node ml in a derived tree is the ancestor of the foot node, and node m2 is its right sibling, such that ml E A(i, j,k,l) and m2 E A(1,r,r, s), then their parent, say node m should belong to A(i, j,k, s). This composition of m/ with m2 can be reduced to a boolean matrix multiplication in the following way: (We use a technique similar to the one used in (Rajasekaran, 1995)) Construct two boolean matrices B1, of size ((n + 1)2p/3) x (p/3) and B2, of size (P/3) x (P/3). = 1 if ml E A(i , j , k, 1) and i E ••, and 1 E {ri÷p/3, ..r2p13} = 0 otherwise Note that in B1 0 &lt; j &lt; k &lt; n. B2(1,$) = 1 if m2 E A(1, r, r, s) and 1 E {ri+p13, ..r213} and s E {r1+2p/3, rp} = 0 otherwise Clearly the dot product of the ijkth row of BI with the sth column of B2 is a 1 if m E A(i, j,k,$). Thus, update A(i, j,k, s) with {m} U ASSOC LIST (m). Case 2 If node m2 in a derived tree is the ancestor of the foot node, and node ml is its left sibling, such that ml E A(i, j, j, 1) and m2 E A(</context>
<context position="23656" citStr="Rajasekaran, 1995" startWordPosition="4652" endWordPosition="4654">ditions for parts a and b are met for this gap. We have also seen that as a result of step 2, all the minimal nodes w.r.t the gap (r(p+i)/3, ri+2(p4.1)/3), with 172 the desired property as required in part c have been computed. Thus applying the hypothesis on the sequence &lt; r1, r2, .•, r(p+1)/3, ri-1-2(p+i)/3, -rp+i &gt;, the algorithm in the end correctly computes all the nodes spanning trees (i,j,k,l) with {i, l} E {ri,r2,..,ri}andi&lt;j&lt;k&lt;l.D 8 Implementation The TAL recognizer given in this paper was implemented in Scheme on a SPARC station-10/30. Theoretical results in this paper and those in (Rajasekaran, 1995) clearly demonstrate that asymptotically fast algorithms can be obtained for TAL parsing with the help of matrix multiplication algorithms. The main objective of the implementation was to check if matrix multiplication techniques help in practice also to obtain efficient parsing algorithms. The recognizer implemented two different algorithms for matrix multiplication, namely the trivial cubic time algorithm and an algorithm that exploits the sparsity of the matrices. The TAL recognizer that uses the cubic time algorithm has a run time comparable to that of Vijayashanker-Joshi&apos;s algorithm. Belo</context>
</contexts>
<marker>Rajasekaran, 1995</marker>
<rawString>S. Rajasekaran, TAL Parsing in o(n6) Time, to appear in SIAM Journal on Computing, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Satta</author>
</authors>
<title>Tree Adjoining Grammar Parsing and Boolean Matrix Multiplication, to be presented</title>
<date>1993</date>
<booktitle>in the 31st Meeting of the Association for Computational Linguistics,</booktitle>
<contexts>
<context position="2363" citStr="Satta, 1993" startWordPosition="390" endWordPosition="391">n (1995) shows how TALs can be parsed in time 0 (n3 M(n)). In this paper, we propose an 0(M(n2)) time recognition algorithm for TALs, where M(k) is the time needed to multiply two k x k boolean matrices. The best known value for M(k) is 0(n2.376) (Coppersmith, Winograd, 1990). Though our algorithm is similar in flavor to those of Graham, Harrison, &amp; Ruzzo (1976), and Valiant (1975) (which were algorithms proposed for recognition of Context Free Languages (CFLs)), there are crucial differences. As such, the techniques of (Graham, et al., 1976) and (Valiant, 1975) do not seem to extend to TALs (Satta, 1993). 2 Tree Adjoining Grammars A Tree Adjoining Grammar (TAG) consists of a quintuple (N, E U {E}, /, A, S), where N is a finite set of nonterminal symbols, E is a finite set of terminal symbols disjoint from N, c is the empty terminal string not in E, I is a finite set of labelled initial trees, A is a finite set of auxiliary trees, S E Nis the distinguished start symbol The trees in / U A are called elementary trees. All internal nodes of elementary trees are labelled with nonterminal symbols. Also, every initial tree is labelled at the root by the start symbol S and has leaf nodes labelled wit</context>
</contexts>
<marker>Satta, 1993</marker>
<rawString>G. Satta, Tree Adjoining Grammar Parsing and Boolean Matrix Multiplication, to be presented in the 31st Meeting of the Association for Computational Linguistics, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Satta</author>
</authors>
<date>1993</date>
<tech>Personal Communication,</tech>
<contexts>
<context position="2363" citStr="Satta, 1993" startWordPosition="390" endWordPosition="391">n (1995) shows how TALs can be parsed in time 0 (n3 M(n)). In this paper, we propose an 0(M(n2)) time recognition algorithm for TALs, where M(k) is the time needed to multiply two k x k boolean matrices. The best known value for M(k) is 0(n2.376) (Coppersmith, Winograd, 1990). Though our algorithm is similar in flavor to those of Graham, Harrison, &amp; Ruzzo (1976), and Valiant (1975) (which were algorithms proposed for recognition of Context Free Languages (CFLs)), there are crucial differences. As such, the techniques of (Graham, et al., 1976) and (Valiant, 1975) do not seem to extend to TALs (Satta, 1993). 2 Tree Adjoining Grammars A Tree Adjoining Grammar (TAG) consists of a quintuple (N, E U {E}, /, A, S), where N is a finite set of nonterminal symbols, E is a finite set of terminal symbols disjoint from N, c is the empty terminal string not in E, I is a finite set of labelled initial trees, A is a finite set of auxiliary trees, S E Nis the distinguished start symbol The trees in / U A are called elementary trees. All internal nodes of elementary trees are labelled with nonterminal symbols. Also, every initial tree is labelled at the root by the start symbol S and has leaf nodes labelled wit</context>
</contexts>
<marker>Satta, 1993</marker>
<rawString>G. Satta, Personal Communication, September 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Schabes</author>
<author>A K Joshi</author>
</authors>
<title>An Earley-Type Parsing Algorithm for Tree Adjoining Grammars,</title>
<date>1988</date>
<booktitle>Proc. 26111 Meeting of the Association for Computational Linguistics,</booktitle>
<contexts>
<context position="1618" citStr="Schabes and Joshi (1988)" startWordPosition="258" endWordPosition="261">hashi (1975). TAGs are tree generating systems, and are strictly more powerful than context-free grammars. They belong to the class of mildly context sensitive grammars (Joshi, et al., 1991). They have been found to be good grammatical systems for natural languages (Kroch, Joshi, 1985). The first polynomial time parsing algorithm for TALs was given by Vijayashanker and Joshi (1986), which had a run time of 0(n6), for an input of size n. Their algorithm had a flavor similar to the Cocke-Younger-Kasami (CYK) algorithm for context-free grammars. An Earley-type parsing algorithm has been given by Schabes and Joshi (1988). An optimal linear time parallel parsing algorithm for TALs was given by Palis, Shende and Wei (1990). In a recent paper, Rajasekaran (1995) shows how TALs can be parsed in time 0 (n3 M(n)). In this paper, we propose an 0(M(n2)) time recognition algorithm for TALs, where M(k) is the time needed to multiply two k x k boolean matrices. The best known value for M(k) is 0(n2.376) (Coppersmith, Winograd, 1990). Though our algorithm is similar in flavor to those of Graham, Harrison, &amp; Ruzzo (1976), and Valiant (1975) (which were algorithms proposed for recognition of Context Free Languages (CFLs)),</context>
</contexts>
<marker>Schabes, Joshi, 1988</marker>
<rawString>Y. Schabes and A.K. Joshi, An Earley-Type Parsing Algorithm for Tree Adjoining Grammars, Proc. 26111 Meeting of the Association for Computational Linguistics, 1988.</rawString>
</citation>
<citation valid="false">
<authors>
<author>L G Valiant</author>
</authors>
<title>General Context-Free Recognition in Less than Cubic Time,</title>
<journal>Journal of Computer and System Sciences,</journal>
<volume>10</volume>
<pages>308--315</pages>
<marker>Valiant, </marker>
<rawString>L.G. Valiant, General Context-Free Recognition in Less than Cubic Time, Journal of Computer and System Sciences, 10,1975, pp. 308-315.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijayashanker</author>
<author>A K Joshi</author>
</authors>
<title>Some Computational Properties of Tree Adjoining Grammars,</title>
<date>1986</date>
<booktitle>Proc. 24th Meeting of the Association for Computational Linguistics,</booktitle>
<contexts>
<context position="1378" citStr="Vijayashanker and Joshi (1986)" startWordPosition="218" endWordPosition="222">) algorithm has been proposed. The algorithm presented in this paper improves the run time of the recent result using an entirely different approach. 1 Introduction The Tree Adjoining Grammar (TAG) formalism was introduced by Joshi, Levy and Takahashi (1975). TAGs are tree generating systems, and are strictly more powerful than context-free grammars. They belong to the class of mildly context sensitive grammars (Joshi, et al., 1991). They have been found to be good grammatical systems for natural languages (Kroch, Joshi, 1985). The first polynomial time parsing algorithm for TALs was given by Vijayashanker and Joshi (1986), which had a run time of 0(n6), for an input of size n. Their algorithm had a flavor similar to the Cocke-Younger-Kasami (CYK) algorithm for context-free grammars. An Earley-type parsing algorithm has been given by Schabes and Joshi (1988). An optimal linear time parallel parsing algorithm for TALs was given by Palis, Shende and Wei (1990). In a recent paper, Rajasekaran (1995) shows how TALs can be parsed in time 0 (n3 M(n)). In this paper, we propose an 0(M(n2)) time recognition algorithm for TALs, where M(k) is the time needed to multiply two k x k boolean matrices. The best known value fo</context>
</contexts>
<marker>Vijayashanker, Joshi, 1986</marker>
<rawString>K. Vijayashanker and A.K. Joshi, Some Computational Properties of Tree Adjoining Grammars, Proc. 24th Meeting of the Association for Computational Linguistics, 1986.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>