<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.980112">
The Stanford CoreNLP Natural Language Processing Toolkit
</title>
<author confidence="0.732131">
Christopher D. Manning Mihai Surdeanu John Bauer
Linguistics &amp; Computer Science SISTA Dept of Computer Science
</author>
<affiliation confidence="0.989472">
Stanford University University of Arizona Stanford University
</affiliation>
<email confidence="0.984917">
manning@stanford.edu msurdeanu@email.arizona.edu horatio@stanford.edu
</email>
<author confidence="0.987924">
Jenny Finkel Steven J. Bethard David McClosky
</author>
<affiliation confidence="0.8184705">
Prismatic Inc. Computer and Information Sciences IBM Research
jrfinkel@gmail.com U. of Alabama at Birmingham dmcclosky@us.ibm.com
</affiliation>
<email confidence="0.998164">
bethard@cis.uab.edu
</email>
<sectionHeader confidence="0.993877" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999970076923077">
We describe the design and use of the
Stanford CoreNLP toolkit, an extensible
pipeline that provides core natural lan-
guage analysis. This toolkit is quite widely
used, both in the research NLP community
and also among commercial and govern-
ment users of open source NLP technol-
ogy. We suggest that this follows from
a simple, approachable design, straight-
forward interfaces, the inclusion of ro-
bust and good quality analysis compo-
nents, and not requiring use of a large
amount of associated baggage.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999956">
This paper describe the design and development of
Stanford CoreNLP, a Java (or at least JVM-based)
annotation pipeline framework, which provides
most of the common core natural language pro-
cessing (NLP) steps, from tokenization through to
coreference resolution. We describe the original
design of the system and its strengths (section 2),
simple usage patterns (section 3), the set of pro-
vided annotators and how properties control them
(section 4), and how to add additional annotators
(section 5), before concluding with some higher-
level remarks and additional appendices. While
there are several good natural language analysis
toolkits, Stanford CoreNLP is one of the most
used, and a central theme is trying to identify the
attributes that contributed to its success.
</bodyText>
<sectionHeader confidence="0.965711" genericHeader="method">
2 Original Design and Development
</sectionHeader>
<bodyText confidence="0.951285782608696">
Our pipeline system was initially designed for in-
ternal use. Previously, when combining multiple
natural language analysis components, each with
their own ad hoc APIs, we had tied them together
with custom glue code. The initial version of the
Figure 1: Overall system architecture: Raw text
is put into an Annotation object and then a se-
quence of Annotators add information in an analy-
sis pipeline. The resulting Annotation, containing
all the analysis information added by the Annota-
tors, can be output in XML or plain text forms.
annotation pipeline was developed in 2006 in or-
der to replace this jumble with something better.
A uniform interface was provided for an Annota-
tor that adds some kind of analysis information to
some text. An Annotator does this by taking in an
Annotation object to which it can add extra infor-
mation. An Annotation is stored as a typesafe het-
erogeneous map, following the ideas for this data
type presented by Bloch (2008). This basic archi-
tecture has proven quite successful, and is still the
basis of the system described here. It is illustrated
in figure 1. The motivations were:
</bodyText>
<listItem confidence="0.9920388">
• To be able to quickly and painlessly get linguis-
tic annotations for a text.
• To hide variations across components behind a
common API.
• To have a minimal conceptual footprint, so the
system is easy to learn.
• To provide a lightweight framework, using plain
Java objects (rather than something of heav-
ier weight, such as XML or UIMA’s Common
Analysis System (CAS) objects).
</listItem>
<figure confidence="0.998036">
Tokenisation
Annotation
Object
(gender, sentiment)
Other Annotators
Execution Flow
(tokenize)
Named Entity Recognition
Coreference Resolution
Morphological Analysis
Partof-speech Tagging
Sentence Splitting
Syntactic Parsing
(dcoref)
(parse)
(lemma)
(ssplit)
(pos)
(ner)
Annotated
text
Raw
text
</figure>
<page confidence="0.975682">
55
</page>
<bodyText confidence="0.98986768">
Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 55–60,
Baltimore, Maryland USA, June 23-24, 2014. c�2014 Association for Computational Linguistics
In 2009, initially as part of a multi-site grant
project, the system was extended to be more easily
usable by a broader range of users. We provided
a command-line interface and the ability to write
out an Annotation in various formats, including
XML. Further work led to the system being re-
leased as free open source software in 2010.
On the one hand, from an architectural perspec-
tive, Stanford CoreNLP does not attempt to do ev-
erything. It is nothing more than a straightforward
pipeline architecture. It provides only a Java API.1
It does not attempt to provide multiple machine
scale-out (though it does provide multi-threaded
processing on a single machine). It provides a sim-
ple concrete API. But these requirements satisfy
a large percentage of potential users, and the re-
sulting simplicity makes it easier for users to get
started with the framework. That is, the primary
advantage of Stanford CoreNLP over larger frame-
works like UIMA (Ferrucci and Lally, 2004) or
GATE (Cunningham et al., 2002) is that users do
not have to learn UIMA or GATE before they can
get started; they only need to know a little Java.
In practice, this is a large and important differ-
entiator. If more complex scenarios are required,
such as multiple machine scale-out, they can nor-
mally be achieved by running the analysis pipeline
within a system that focuses on distributed work-
flows (such as Hadoop or Spark). Other systems
attempt to provide more, such as the UIUC Cu-
rator (Clarke et al., 2012), which includes inter-
machine client-server communication for process-
ing and the caching of natural language analyses.
But this functionality comes at a cost. The system
is complex to install and complex to understand.
Moreover, in practice, an organization may well
be committed to a scale-out solution which is dif-
ferent from that provided by the natural language
analysis toolkit. For example, they may be using
Kryo or Google’s protobuf for binary serialization
rather than Apache Thrift which underlies Cura-
tor. In this case, the user is better served by a fairly
small and self-contained natural language analysis
system, rather than something which comes with
a lot of baggage for all sorts of purposes, most of
which they are not using.
On the other hand, most users benefit greatly
from the provision of a set of stable, robust, high
</bodyText>
<footnote confidence="0.8680635">
1Nevertheless, it can call an analysis component written in
other languages via an appropriate wrapper Annotator, and
in turn, it has been wrapped by many people to provide Stan-
ford CoreNLP bindings for other languages.
</footnote>
<bodyText confidence="0.999929771428571">
quality linguistic analysis components, which can
be easily invoked for common scenarios. While
the builder of a larger system may have made over-
all design choices, such as how to handle scale-
out, they are unlikely to be an NLP expert, and
are hence looking for NLP components that just
work. This is a huge advantage that Stanford
CoreNLP and GATE have over the empty tool-
box of an Apache UIMA download, something
addressed in part by the development of well-
integrated component packages for UIMA, such
as ClearTK (Bethard et al., 2014), DKPro Core
(Gurevych et al., 2007), and JCoRe (Hahn et al.,
2008). However, the solution provided by these
packages remains harder to learn, more complex
and heavier weight for users than the pipeline de-
scribed here.
These attributes echo what Patricio (2009) ar-
gued made Hibernate successful, including: (i) do
one thing well, (ii) avoid over-design, and (iii)
up and running in ten minutes or less! Indeed,
the design and success of Stanford CoreNLP also
reflects several other of the factors that Patricio
highlights, including (iv) avoid standardism, (v)
documentation, and (vi) developer responsiveness.
While there are many factors that contribute to the
uptake of a project, and it is hard to show causal-
ity, we believe that some of these attributes ac-
count for the fact that Stanford CoreNLP is one of
the more used NLP toolkits. While we certainly
have not done a perfect job, compared to much
academic software, Stanford CoreNLP has gained
from attributes such as clear open source licens-
ing, a modicum of attention to documentation, and
attempting to answer user questions.
</bodyText>
<sectionHeader confidence="0.99002" genericHeader="method">
3 Elementary Usage
</sectionHeader>
<bodyText confidence="0.999989785714286">
A key design goal was to make it very simple to
set up and run processing pipelines, from either
the API or the command-line. Using the API, run-
ning a pipeline can be as easy as figure 2. Or,
at the command-line, doing linguistic processing
for a file can be as easy as figure 3. Real life is
rarely this simple, but the ability to get started us-
ing the product with minimal configuration code
gives new users a very good initial experience.
Figure 4 gives a more realistic (and complete)
example of use, showing several key properties of
the system. An annotation pipeline can be applied
to any text, such as a paragraph or whole story
rather than just a single sentence. The behavior of
</bodyText>
<page confidence="0.985796">
56
</page>
<bodyText confidence="0.55441625">
Annotator pipeline = new StanfordCoreNLP();
Annotation annotation = new Annotation(
&amp;quot;Can you parse my sentence?&amp;quot;);
pipeline.annotate(annotation);
</bodyText>
<figureCaption confidence="0.971998">
Figure 2: Minimal code for an analysis pipeline.
</figureCaption>
<figure confidence="0.84755175">
export StanfordCoreNLP_HOME /where/installed
java -Xmx2g -cp $StanfordCoreNLP_HOME/*
edu.stanford.nlp.StanfordCoreNLP
-file input.txt
</figure>
<figureCaption confidence="0.998501">
Figure 3: Minimal command-line invocation.
</figureCaption>
<construct confidence="0.568292333333333">
import java.io.*;
import java.util.*;
import edu.stanford.nlp.io.*;
import edu.stanford.nlp.ling.*;
import edu.stanford.nlp.pipeline.*;
import edu.stanford.nlp.trees.*;
import edu.stanford.nlp.trees.TreeCoreAnnotations.*;
import edu.stanford.nlp.util.*;
public class StanfordCoreNlpExample {
public static void main(String[] args) throws IOException {
PrintWriter xmlOut = new PrintWriter(&amp;quot;xmlOutput.xml&amp;quot;);
Properties props = new Properties();
props.setProperty(&amp;quot;annotators&amp;quot;,
&amp;quot;tokenize, ssplit, pos, lemma, ner, parse&amp;quot;);
StanfordCoreNLP pipeline = new StanfordCoreNLP(props);
Annotation annotation = new Annotation(
&amp;quot;This is a short sentence. And this is another.&amp;quot;);
pipeline.annotate(annotation);
pipeline.xmlPrint(annotation, xmlOut);
// An Annotation is a Map and you can get and use the
// various analyses individually. For instance, this
// gets the parse tree of the 1st sentence in the text.
List&lt;CoreMap&gt; sentences = annotation.get(
CoreAnnotations.SentencesAnnotation.class);
if (sentences != null &amp;&amp; sentences.size() &gt; 0) {
CoreMap sentence = sentences.get(0);
Tree tree = sentence.get(TreeAnnotation.class);
PrintWriter out = new PrintWriter(System.out);
out.println(&amp;quot;The first sentence parsed is:&amp;quot;);
tree.pennPrint(out);
}
}
}
</construct>
<figureCaption confidence="0.999191">
Figure 4: A simple, complete example program.
</figureCaption>
<bodyText confidence="0.999220526315789">
annotators in a pipeline is controlled by standard
Java properties in a Properties object. The most
basic property to specify is what annotators to run,
in what order, as shown here. But as discussed be-
low, most annotators have their own properties to
allow further customization of their usage. If none
are specified, reasonable defaults are used. Run-
ning the pipeline is as simple as in the first exam-
ple, but then we show two possibilities for access-
ing the results. First, we convert the Annotation
object to XML and write it to a file. Second, we
show code that gets a particular type of informa-
tion out of an Annotation and then prints it.
Our presentation shows only usage in Java, but
the Stanford CoreNLP pipeline has been wrapped
by others so that it can be accessed easily from
many languages, including Python, Ruby, Perl,
Scala, Clojure, Javascript (node.js), and .NET lan-
guages, including C# and F#.
</bodyText>
<sectionHeader confidence="0.919605" genericHeader="method">
4 Provided annotators
</sectionHeader>
<bodyText confidence="0.991287583333333">
The annotators provided with StanfordCoreNLP
can work with any character encoding, making use
of Java’s good Unicode support, but the system
defaults to UTF-8 encoding. The annotators also
support processing in various human languages,
providing that suitable underlying models or re-
sources are available for the different languages.
The system comes packaged with models for En-
glish. Separate model packages provide support
for Chinese and for case-insensitive processing of
English. Support for other languages is less com-
plete, but many of the Annotators also support
models for French, German, and Arabic (see ap-
pendix B), and building models for further lan-
guages is possible using the underlying tools. In
this section, we outline the provided annotators,
focusing on the English versions. It should be
noted that some of the models underlying annota-
tors are trained from annotated corpora using su-
pervised machine learning, while others are rule-
based components, which nevertheless often re-
quire some language resources of their own.
tokenize Tokenizes the text into a sequence of to-
kens. The English component provides a PTB-
style tokenizer, extended to reasonably handle
noisy and web text. The corresponding com-
ponents for Chinese and Arabic provide word
and clitic segmentation. The tokenizer saves the
character offsets of each token in the input text.
cleanxml Removes most or all XML tags from
the document.
ssplit Splits a sequence of tokens into sentences.
truecase Determines the likely true case of tokens
in text (that is, their likely case in well-edited
text), where this information was lost, e.g., for
all upper case text. This is implemented with
a discriminative model using a CRF sequence
tagger (Finkel et al., 2005).
pos Labels tokens with their part-of-speech (POS)
tag, using a maximum entropy POS tagger
(Toutanova et al., 2003).
lemma Generates the lemmas (base forms) for all
tokens in the annotation.
gender Adds likely gender information to names.
ner Recognizes named (PERSON, LOCATION,
ORGANIZATION, MISC) and numerical
(MONEY, NUMBER, DATE, TIME, DU-
RATION, SET) entities. With the default
</bodyText>
<page confidence="0.993101">
57
</page>
<bodyText confidence="0.999873723404255">
annotators, named entities are recognized
using a combination of CRF sequence taggers
trained on various corpora (Finkel et al., 2005),
while numerical entities are recognized using
two rule-based systems, one for money and
numbers, and a separate state-of-the-art system
for processing temporal expressions (Chang
and Manning, 2012).
regexner Implements a simple, rule-based NER
over token sequences building on Java regular
expressions. The goal of this Annotator is to
provide a simple framework to allow a user to
incorporate NE labels that are not annotated in
traditional NL corpora. For example, a default
list of regular expressions that we distribute
in the models file recognizes ideologies (IDE-
OLOGY), nationalities (NATIONALITY), reli-
gions (RELIGION), and titles (TITLE).
parse Provides full syntactic analysis, including
both constituent and dependency representa-
tion, based on a probabilistic parser (Klein and
Manning, 2003; de Marneffe et al., 2006).
sentiment Sentiment analysis with a composi-
tional model over trees using deep learning
(Socher et al., 2013). Nodes of a binarized tree
of each sentence, including, in particular, the
root node of each sentence, are given a senti-
ment score.
dcoref Implements mention detection and both
pronominal and nominal coreference resolution
(Lee et al., 2013). The entire coreference graph
of a text (with head words of mentions as nodes)
is provided in the Annotation.
Most of these annotators have various options
which can be controlled by properties. These can
either be added to the Properties object when cre-
ating an annotation pipeline via the API, or spec-
ified either by command-line flags or through a
properties file when running the system from the
command-line. As a simple example, input to the
system may already be tokenized and presented
one-sentence-per-line. In this case, we wish the
tokenization and sentence splitting to just work by
using the whitespace, rather than trying to do any-
thing more creative (be it right or wrong). This can
be accomplished by adding two properties, either
to a properties file:
</bodyText>
<figure confidence="0.86933012">
tokenize.whitespace: true
ssplit.eolonly: true
in code:
/** Simple annotator for locations stored in a gazetteer.*/
package org.foo;
public class GazetteerLocationAnnotator implements Annotator {
// this is the only method an Annotator must implement
public void annotate(Annotation annotation) {
// traverse all sentences in this document
for (CoreMap sentence:annotation.get(SentencesAnnotation.class)) {
// loop over all tokens in sentence (the text already tokenized)
List&lt;CoreLabel&gt; toks = sentence.get(TokensAnnotation.class);
for (int start = 0; start &lt; toks.size(); start++) {
// assumes that the gazetteer returns the token index
// after the match or -1 otherwise
int end = Gazetteer.isLocation(toks, start);
if (end &gt; start) {
for (int i = start; i &lt; end; i ++) {
toks.get(i).set(NamedEntityTagAnnotation.class,&amp;quot;LOCATION&amp;quot;);
}
}
}
}
}
}
</figure>
<figureCaption confidence="0.749068666666667">
Figure 5: An example of a simple custom anno-
tator. The annotator marks the words of possibly
multi-word locations that are in a gazetteer.
props.setProperty(&amp;quot;tokenize.whitespace&amp;quot;, &amp;quot;true&amp;quot;);
props.setProperty(&amp;quot;ssplit.eolonly&amp;quot;, &amp;quot;true&amp;quot;);
or via command-line flags:
</figureCaption>
<bodyText confidence="0.979620714285714">
-tokenize.whitespace -ssplit.eolonly
We do not attempt to describe all the properties
understood by each annotator here; they are avail-
able in the documentation for Stanford CoreNLP.
However, we note that they follow the pattern of
being x.y, where x is the name of the annotator
that they apply to.
</bodyText>
<sectionHeader confidence="0.904698" genericHeader="method">
5 Adding annotators
</sectionHeader>
<bodyText confidence="0.934438052631579">
While most users work with the provided annota-
tors, it is quite easy to add additional custom an-
notators to the system. We illustrate here both how
to write an Annotator in code and how to load it
into the Stanford CoreNLP system. An Annotator
is a class that implements three methods: a sin-
gle method for analysis, and two that describe the
dependencies between analysis steps:
public void annotate(Annotation annotation);
public Set&lt;Requirement&gt; requirementsSatisfied();
public Set&lt;Requirement&gt; requires();
The information in an Annotation is updated in
place (usually in a non-destructive manner, by
adding new keys and values to the Annotation).
The code for a simple Annotator that marks loca-
tions contained in a gazetteer is shown in figure 5.2
Similar code can be used to write a wrapper Anno-
tator, which calls some pre-existing analysis com-
ponent, and adds its results to the Annotation.
</bodyText>
<footnote confidence="0.9969095">
2The functionality of this annotator is already provided by
the regexner annotator, but it serves as a simple example.
</footnote>
<page confidence="0.998833">
58
</page>
<bodyText confidence="0.9361885">
While building an analysis pipeline, Stanford
CoreNLP can add additional annotators to the
pipeline which are loaded using reflection. To pro-
vide anew Annotator, the user extends the class
edu.stanford.nlp.pipeline.Annotator
and provides a constructor with the signature
(String, Properties). Then, the user adds
the property
customAnnotatorClass.FOO: BAR
to the properties used to create the pipeline. If
FOO is then added to the list of annotators, the
class BAR will be loaded to instantiate it. The
Properties object is also passed to the constructor,
so that annotator-specific behavior can be initial-
ized from the Properties object. For instance, for
the example above, the properties file lines might
be:
customAnnotatorClass.locgaz: org.foo.GazetteerLocationAnnotator
annotators: tokenize,ssplit,locgaz
locgaz.maxLength: 5
</bodyText>
<sectionHeader confidence="0.991231" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999253125">
In this paper, we have presented the design
and usage of the Stanford CoreNLP system, an
annotation-based NLP processing pipeline. We
have in particular tried to emphasize the proper-
ties that we feel have made it successful. Rather
than trying to provide the largest and most engi-
neered kitchen sink, the goal has been to make it
as easy as possible for users to get started using
the framework, and to keep the framework small,
so it is easily comprehensible, and can easily be
used as a component within the much larger sys-
tem that a user may be developing. The broad us-
age of this system, and of other systems such as
NLTK (Bird et al., 2009), which emphasize acces-
sibility to beginning users, suggests the merits of
this approach.
</bodyText>
<subsectionHeader confidence="0.296049">
A Pointers
</subsectionHeader>
<bodyText confidence="0.702104">
Website: http://nlp.stanford.edu/software/
corenlp.shtml
Github: https://github.com/stanfordnlp/CoreNLP
Maven: http://mvnrepository.com/artifact/edu.
stanford.nlp/stanford-corenlp
License: GPL v2+
Stanford CoreNLP keeps the models for ma-
chine learning components and miscellaneous
other data files in a separate models jar file. If you
are using Maven, you need to make sure that you
list the dependency on this models file as well as
the code jar file. You can do that with code like the
following in your pom.xml. Note the extra depen-
dency with a classifier element at the bottom.
</bodyText>
<figure confidence="0.978812333333333">
&lt;dependency&gt;
&lt;groupId&gt;edu.stanford.nlp&lt;/groupId&gt;
&lt;artifactId&gt;stanford-corenlp&lt;/artifactId&gt;
&lt;version&gt;3.3.1&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
&lt;groupId&gt;edu.stanford.nlp&lt;/groupId&gt;
&lt;artifactId&gt;stanford-corenlp&lt;/artifactId&gt;
&lt;version&gt;3.3.1&lt;/version&gt;
&lt;classifier&gt;models&lt;/classifier&gt;
&lt;/dependency&gt;
B Human language support
</figure>
<bodyText confidence="0.995483">
We summarize the analysis components supported
for different human languages in early 2014.
</bodyText>
<table confidence="0.909032155555556">
Annotator Ara- Chi- Eng- Fre- Ger-
bic nese lish nch man
Tokenize ✓ ✓ ✓ ✓ ✓
Sent. split ✓ ✓ ✓ ✓ ✓
Truecase ✓
POS ✓ ✓ ✓ ✓ ✓
Lemma ✓
Gender ✓
NER ✓ ✓ ✓
RegexNER ✓ ✓ ✓ ✓ ✓
Parse ✓ ✓ ✓ ✓ ✓
Dep. Parse ✓ ✓
Sentiment ✓
Coref. ✓
C Getting the sentiment of sentences
We show a command-line for sentiment analysis.
$ cat sentiment.txt
I liked it.
It was a fantastic experience.
The plot move rather slowly.
$ java -cp &amp;quot;*&amp;quot; -Xmx2g edu.stanford.nlp.pipeline.StanfordCoreNLP -annotators
tokenize,ssplit,pos,lemma,parse,sentiment -file sentiment.txt
Adding annotator tokenize
Adding annotator ssplit
Adding annotator pos
Reading POS tagger model from edu/stanford/nlp/models/pos-tagger/
english-left3words/english-left3words-distsim.tagger ... done [1.0 sec].
Adding annotator lemma
Adding annotator parse
Loading parser from serialized file edu/stanford/nlp/models/lexparser/
englishPCFG.ser.gz ... done [1.4 sec].
Adding annotator sentiment
Ready to process: 1 files, skipped 0, total 1
Processing file /Users/manning/Software/stanford-corenlp-full-2014-01-04/
sentiment.txt ... writing to /Users/manning/Software/
stanford-corenlp-full-2014-01-04/sentiment.txt.xml {
Annotating file /Users/manning/Software/stanford-corenlp-full-2014-01-04/
sentiment.txt [0.583 seconds]
} [1.219 seconds]
Processed 1 documents
Skipped 0 documents, error annotating 0 documents
Annotation pipeline timing information:
PTBTokenizerAnnotator: 0.0 sec.
WordsToSentencesAnnotator: 0.0 sec.
POSTaggerAnnotator: 0.0 sec.
</table>
<page confidence="0.751407">
59
</page>
<table confidence="0.965340454545455">
MorphaAnnotator: 0.0 sec.
ParserAnnotator: 0.4 sec.
SentimentAnnotator: 0.1 sec.
TOTAL: 0.6 sec. for 16 tokens at 27.4 tokens/sec.
Pipelinesetup: 3.0 sec.
Total time for StanfordCoreNLP pipeline: 4.2 sec.
$ grep sentiment sentiment.txt.xml
&lt;sentence id=&amp;quot;1&amp;quot; sentimentValue=&amp;quot;3&amp;quot; sentiment=&amp;quot;Positive&amp;quot;&gt;
&lt;sentence id=&amp;quot;2&amp;quot; sentimentValue=&amp;quot;4&amp;quot; sentiment=&amp;quot;Verypositive&amp;quot;&gt;
&lt;sentence id=&amp;quot;3&amp;quot; sentimentValue=&amp;quot;1&amp;quot; sentiment=&amp;quot;Negative&amp;quot;&gt;
D Use within UIMA
</table>
<bodyText confidence="0.972588814814815">
The main part of using Stanford CoreNLP within
the UIMA framework (Ferrucci and Lally, 2004)
is mapping between CoreNLP annotations, which
are regular Java classes, and UIMA annotations,
which are declared via XML type descriptors
(from which UIMA-specific Java classes are gen-
erated). A wrapper for CoreNLP will typically de-
fine a subclass of JCasAnnotator ImplBase whose
process method: (i) extracts UIMA annotations
from the CAS, (ii) converts UIMA annotations to
CoreNLP annotations, (iii) runs CoreNLP on the
input annotations, (iv) converts the CoreNLP out-
put annotations into UIMA annotations, and (v)
saves the UIMA annotations to the CAS.
To illustrate part of this process, the ClearTK
(Bethard et al., 2014) wrapper converts CoreNLP
token annotations to UIMA annotations and saves
them to the CAS with the following code:
int begin = tokenAnn.get(CharacterOffsetBeginAnnotation.class);
int end = tokenAnn.get(CharacterOffsetEndAnnotation.class);
Stringpos = tokenAnn.get(PartOfSpeechAnnotation.class);
String lemma = tokenAnn.get(LemmaAnnotation.class);
Token token = new Token(jCas, begin, end);
token.setPos(pos);
token.setLemma(lemma);
token.addToIndexes();
where Token is a UIMA type, declared as:
</bodyText>
<figure confidence="0.997419210526316">
&lt;typeSystemDescription&gt;
&lt;name&gt;Token&lt;/name&gt;
&lt;types&gt;
&lt;typeDescription&gt;
&lt;name&gt;org.cleartk.token.type.Token&lt;/name&gt;
&lt;supertypeName&gt;uima.tcas.Annotation&lt;/supertypeName&gt;
&lt;features&gt;
&lt;featureDescription&gt;
&lt;name&gt;pos&lt;/name&gt;
&lt;rangeTypeName&gt;uima.cas.String&lt;/rangeTypeName&gt;
&lt;/featureDescription&gt;
&lt;featureDescription&gt;
&lt;name&gt;lemma&lt;/name&gt;
&lt;rangeTypeName&gt;uima.cas.String&lt;/rangeTypeName&gt;
&lt;/featureDescription&gt;
&lt;/features&gt;
&lt;/typeDescription&gt;
&lt;/types&gt;
&lt;/typeSystemDescription&gt;
</figure>
<sectionHeader confidence="0.984041" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999341317460318">
Steven Bethard, Philip Ogren, and Lee Becker. 2014.
ClearTK 2.0: Design patterns for machine learning
in UIMA. In LREC 2014.
Steven Bird, Ewan Klein, and Edward Loper.
2009. Natural Language Processing with Python.
O’Reilly Media.
Joshua Bloch. 2008. Effective Java. Addison Wesley,
Upper Saddle River, NJ, 2nd edition.
Angel X. Chang and Christopher D. Manning. 2012.
SUTIME: A library for recognizing and normalizing
time expressions. In LREC 2012.
James Clarke, Vivek Srikumar, Mark Sammons, and
Dan Roth. 2012. An NLP Curator (or: How I
learned to stop worrying and love NLP pipelines).
In LREC 2012.
Hamish Cunningham, Diana Maynard, Kalina
Bontcheva, and Valentin Tablan. 2002. GATE:
an architecture for development of robust HLT
applications. In ACL 2002.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
LREC 2006, pages 449–454.
David Ferrucci and Adam Lally. 2004. UIMA: an
architectural approach to unstructured information
processing in the corporate research environment.
Natural Language Engineering, 10:327–348.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by Gibbs
sampling. In ACL 43, pages 363–370.
I. Gurevych, M. M¨uhlh¨auser, C. M¨uller, J. Steimle,
M. Weimer, and T. Zesch. 2007. Darmstadt knowl-
edge processing repository based on UIMA. In
First Workshop on Unstructured Information Man-
agement Architecture at GLDV 2007, T¨ubingen.
U. Hahn, E. Buyko, R. Landefeld, M. M¨uhlhausen,
Poprat M, K. Tomanek, and J. Wermter. 2008. An
overview of JCoRe, the Julie lab UIMA component
registry. In LREC 2008.
Dan Klein and Christopher D. Manning. 2003. Fast
exact inference with a factored model for natural
language parsing. In Suzanna Becker, Sebastian
Thrun, and Klaus Obermayer, editors, Advances in
Neural Information Processing Systems, volume 15,
pages 3–10. MIT Press.
Heeyoung Lee, Angel Chang, Yves Peirsman,
Nathanael Chambers, Mihai Surdeanu, and Dan Ju-
rafsky. 2013. Deterministic coreference resolu-
tion based on entity-centric, precision-ranked rules.
Computational Linguistics, 39(4).
Anthony Patricio. 2009. Why this project is success-
ful? https://community.jboss.org/wiki/
WhyThisProjectIsSuccessful.
Richard Socher, Alex Perelygin, Jean Wu, Jason
Chuang, Christopher D. Manning, Andrew Ng, and
Christopher Potts. 2013. Recursive deep models
for semantic compositionality over a sentiment tree-
bank. In EMNLP 2013, pages 1631–1642.
Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In NAACL 3, pages 252–259.
</reference>
<page confidence="0.998397">
60
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.886347">
<title confidence="0.999836">The Stanford CoreNLP Natural Language Processing Toolkit</title>
<author confidence="0.999962">Christopher D Manning Mihai Surdeanu John Bauer</author>
<affiliation confidence="0.9975835">Linguistics &amp; Computer Science SISTA Dept of Computer Science Stanford University University of Arizona Stanford</affiliation>
<email confidence="0.997605">manning@stanford.edumsurdeanu@email.arizona.eduhoratio@stanford.edu</email>
<author confidence="0.999488">Jenny Finkel Steven J Bethard David McClosky</author>
<affiliation confidence="0.9434605">Prismatic Inc. Computer and Information Sciences IBM of Alabama at Birmingham</affiliation>
<email confidence="0.999804">bethard@cis.uab.edu</email>
<abstract confidence="0.999596714285714">We describe the design and use of the Stanford CoreNLP toolkit, an extensible pipeline that provides core natural language analysis. This toolkit is quite widely used, both in the research NLP community and also among commercial and government users of open source NLP technology. We suggest that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Bethard</author>
<author>Philip Ogren</author>
<author>Lee Becker</author>
</authors>
<title>ClearTK 2.0: Design patterns for machine learning in UIMA.</title>
<date>2014</date>
<booktitle>In LREC</booktitle>
<contexts>
<context position="6913" citStr="Bethard et al., 2014" startWordPosition="1096" endWordPosition="1099">en wrapped by many people to provide Stanford CoreNLP bindings for other languages. quality linguistic analysis components, which can be easily invoked for common scenarios. While the builder of a larger system may have made overall design choices, such as how to handle scaleout, they are unlikely to be an NLP expert, and are hence looking for NLP components that just work. This is a huge advantage that Stanford CoreNLP and GATE have over the empty toolbox of an Apache UIMA download, something addressed in part by the development of wellintegrated component packages for UIMA, such as ClearTK (Bethard et al., 2014), DKPro Core (Gurevych et al., 2007), and JCoRe (Hahn et al., 2008). However, the solution provided by these packages remains harder to learn, more complex and heavier weight for users than the pipeline described here. These attributes echo what Patricio (2009) argued made Hibernate successful, including: (i) do one thing well, (ii) avoid over-design, and (iii) up and running in ten minutes or less! Indeed, the design and success of Stanford CoreNLP also reflects several other of the factors that Patricio highlights, including (iv) avoid standardism, (v) documentation, and (vi) developer respo</context>
<context position="23190" citStr="Bethard et al., 2014" startWordPosition="3476" endWordPosition="3479">apping between CoreNLP annotations, which are regular Java classes, and UIMA annotations, which are declared via XML type descriptors (from which UIMA-specific Java classes are generated). A wrapper for CoreNLP will typically define a subclass of JCasAnnotator ImplBase whose process method: (i) extracts UIMA annotations from the CAS, (ii) converts UIMA annotations to CoreNLP annotations, (iii) runs CoreNLP on the input annotations, (iv) converts the CoreNLP output annotations into UIMA annotations, and (v) saves the UIMA annotations to the CAS. To illustrate part of this process, the ClearTK (Bethard et al., 2014) wrapper converts CoreNLP token annotations to UIMA annotations and saves them to the CAS with the following code: int begin = tokenAnn.get(CharacterOffsetBeginAnnotation.class); int end = tokenAnn.get(CharacterOffsetEndAnnotation.class); Stringpos = tokenAnn.get(PartOfSpeechAnnotation.class); String lemma = tokenAnn.get(LemmaAnnotation.class); Token token = new Token(jCas, begin, end); token.setPos(pos); token.setLemma(lemma); token.addToIndexes(); where Token is a UIMA type, declared as: &lt;typeSystemDescription&gt; &lt;name&gt;Token&lt;/name&gt; &lt;types&gt; &lt;typeDescription&gt; &lt;name&gt;org.cleartk.token.type.Token&lt;/</context>
</contexts>
<marker>Bethard, Ogren, Becker, 2014</marker>
<rawString>Steven Bethard, Philip Ogren, and Lee Becker. 2014. ClearTK 2.0: Design patterns for machine learning in UIMA. In LREC 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Ewan Klein</author>
<author>Edward Loper</author>
</authors>
<date>2009</date>
<booktitle>Natural Language Processing with Python. O’Reilly Media.</booktitle>
<contexts>
<context position="19456" citStr="Bird et al., 2009" startWordPosition="3001" endWordPosition="3004">ented the design and usage of the Stanford CoreNLP system, an annotation-based NLP processing pipeline. We have in particular tried to emphasize the properties that we feel have made it successful. Rather than trying to provide the largest and most engineered kitchen sink, the goal has been to make it as easy as possible for users to get started using the framework, and to keep the framework small, so it is easily comprehensible, and can easily be used as a component within the much larger system that a user may be developing. The broad usage of this system, and of other systems such as NLTK (Bird et al., 2009), which emphasize accessibility to beginning users, suggests the merits of this approach. A Pointers Website: http://nlp.stanford.edu/software/ corenlp.shtml Github: https://github.com/stanfordnlp/CoreNLP Maven: http://mvnrepository.com/artifact/edu. stanford.nlp/stanford-corenlp License: GPL v2+ Stanford CoreNLP keeps the models for machine learning components and miscellaneous other data files in a separate models jar file. If you are using Maven, you need to make sure that you list the dependency on this models file as well as the code jar file. You can do that with code like the following </context>
</contexts>
<marker>Bird, Klein, Loper, 2009</marker>
<rawString>Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural Language Processing with Python. O’Reilly Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joshua Bloch</author>
</authors>
<title>Effective Java. Addison Wesley, Upper Saddle River, NJ, 2nd edition.</title>
<date>2008</date>
<contexts>
<context position="2781" citStr="Bloch (2008)" startWordPosition="425" endWordPosition="426">e of Annotators add information in an analysis pipeline. The resulting Annotation, containing all the analysis information added by the Annotators, can be output in XML or plain text forms. annotation pipeline was developed in 2006 in order to replace this jumble with something better. A uniform interface was provided for an Annotator that adds some kind of analysis information to some text. An Annotator does this by taking in an Annotation object to which it can add extra information. An Annotation is stored as a typesafe heterogeneous map, following the ideas for this data type presented by Bloch (2008). This basic architecture has proven quite successful, and is still the basis of the system described here. It is illustrated in figure 1. The motivations were: • To be able to quickly and painlessly get linguistic annotations for a text. • To hide variations across components behind a common API. • To have a minimal conceptual footprint, so the system is easy to learn. • To provide a lightweight framework, using plain Java objects (rather than something of heavier weight, such as XML or UIMA’s Common Analysis System (CAS) objects). Tokenisation Annotation Object (gender, sentiment) Other Anno</context>
</contexts>
<marker>Bloch, 2008</marker>
<rawString>Joshua Bloch. 2008. Effective Java. Addison Wesley, Upper Saddle River, NJ, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angel X Chang</author>
<author>Christopher D Manning</author>
</authors>
<title>SUTIME: A library for recognizing and normalizing time expressions.</title>
<date>2012</date>
<booktitle>In LREC</booktitle>
<contexts>
<context position="13767" citStr="Chang and Manning, 2012" startWordPosition="2125" endWordPosition="2128">tanova et al., 2003). lemma Generates the lemmas (base forms) for all tokens in the annotation. gender Adds likely gender information to names. ner Recognizes named (PERSON, LOCATION, ORGANIZATION, MISC) and numerical (MONEY, NUMBER, DATE, TIME, DURATION, SET) entities. With the default 57 annotators, named entities are recognized using a combination of CRF sequence taggers trained on various corpora (Finkel et al., 2005), while numerical entities are recognized using two rule-based systems, one for money and numbers, and a separate state-of-the-art system for processing temporal expressions (Chang and Manning, 2012). regexner Implements a simple, rule-based NER over token sequences building on Java regular expressions. The goal of this Annotator is to provide a simple framework to allow a user to incorporate NE labels that are not annotated in traditional NL corpora. For example, a default list of regular expressions that we distribute in the models file recognizes ideologies (IDEOLOGY), nationalities (NATIONALITY), religions (RELIGION), and titles (TITLE). parse Provides full syntactic analysis, including both constituent and dependency representation, based on a probabilistic parser (Klein and Manning,</context>
</contexts>
<marker>Chang, Manning, 2012</marker>
<rawString>Angel X. Chang and Christopher D. Manning. 2012. SUTIME: A library for recognizing and normalizing time expressions. In LREC 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Vivek Srikumar</author>
<author>Mark Sammons</author>
<author>Dan Roth</author>
</authors>
<title>An NLP Curator (or: How I learned to stop worrying and love NLP pipelines).</title>
<date>2012</date>
<booktitle>In LREC</booktitle>
<contexts>
<context position="5313" citStr="Clarke et al., 2012" startWordPosition="830" endWordPosition="833"> is, the primary advantage of Stanford CoreNLP over larger frameworks like UIMA (Ferrucci and Lally, 2004) or GATE (Cunningham et al., 2002) is that users do not have to learn UIMA or GATE before they can get started; they only need to know a little Java. In practice, this is a large and important differentiator. If more complex scenarios are required, such as multiple machine scale-out, they can normally be achieved by running the analysis pipeline within a system that focuses on distributed workflows (such as Hadoop or Spark). Other systems attempt to provide more, such as the UIUC Curator (Clarke et al., 2012), which includes intermachine client-server communication for processing and the caching of natural language analyses. But this functionality comes at a cost. The system is complex to install and complex to understand. Moreover, in practice, an organization may well be committed to a scale-out solution which is different from that provided by the natural language analysis toolkit. For example, they may be using Kryo or Google’s protobuf for binary serialization rather than Apache Thrift which underlies Curator. In this case, the user is better served by a fairly small and self-contained natura</context>
</contexts>
<marker>Clarke, Srikumar, Sammons, Roth, 2012</marker>
<rawString>James Clarke, Vivek Srikumar, Mark Sammons, and Dan Roth. 2012. An NLP Curator (or: How I learned to stop worrying and love NLP pipelines). In LREC 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hamish Cunningham</author>
<author>Diana Maynard</author>
<author>Kalina Bontcheva</author>
<author>Valentin Tablan</author>
</authors>
<title>GATE: an architecture for development of robust HLT applications.</title>
<date>2002</date>
<booktitle>In ACL</booktitle>
<contexts>
<context position="4833" citStr="Cunningham et al., 2002" startWordPosition="744" endWordPosition="747">ective, Stanford CoreNLP does not attempt to do everything. It is nothing more than a straightforward pipeline architecture. It provides only a Java API.1 It does not attempt to provide multiple machine scale-out (though it does provide multi-threaded processing on a single machine). It provides a simple concrete API. But these requirements satisfy a large percentage of potential users, and the resulting simplicity makes it easier for users to get started with the framework. That is, the primary advantage of Stanford CoreNLP over larger frameworks like UIMA (Ferrucci and Lally, 2004) or GATE (Cunningham et al., 2002) is that users do not have to learn UIMA or GATE before they can get started; they only need to know a little Java. In practice, this is a large and important differentiator. If more complex scenarios are required, such as multiple machine scale-out, they can normally be achieved by running the analysis pipeline within a system that focuses on distributed workflows (such as Hadoop or Spark). Other systems attempt to provide more, such as the UIUC Curator (Clarke et al., 2012), which includes intermachine client-server communication for processing and the caching of natural language analyses. B</context>
</contexts>
<marker>Cunningham, Maynard, Bontcheva, Tablan, 2002</marker>
<rawString>Hamish Cunningham, Diana Maynard, Kalina Bontcheva, and Valentin Tablan. 2002. GATE: an architecture for development of robust HLT applications. In ACL 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses. In LREC</title>
<date>2006</date>
<pages>449--454</pages>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In LREC 2006, pages 449–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Ferrucci</author>
<author>Adam Lally</author>
</authors>
<title>UIMA: an architectural approach to unstructured information processing in the corporate research environment.</title>
<date>2004</date>
<journal>Natural Language Engineering,</journal>
<pages>10--327</pages>
<contexts>
<context position="4799" citStr="Ferrucci and Lally, 2004" startWordPosition="738" endWordPosition="741">e hand, from an architectural perspective, Stanford CoreNLP does not attempt to do everything. It is nothing more than a straightforward pipeline architecture. It provides only a Java API.1 It does not attempt to provide multiple machine scale-out (though it does provide multi-threaded processing on a single machine). It provides a simple concrete API. But these requirements satisfy a large percentage of potential users, and the resulting simplicity makes it easier for users to get started with the framework. That is, the primary advantage of Stanford CoreNLP over larger frameworks like UIMA (Ferrucci and Lally, 2004) or GATE (Cunningham et al., 2002) is that users do not have to learn UIMA or GATE before they can get started; they only need to know a little Java. In practice, this is a large and important differentiator. If more complex scenarios are required, such as multiple machine scale-out, they can normally be achieved by running the analysis pipeline within a system that focuses on distributed workflows (such as Hadoop or Spark). Other systems attempt to provide more, such as the UIUC Curator (Clarke et al., 2012), which includes intermachine client-server communication for processing and the cachi</context>
<context position="22564" citStr="Ferrucci and Lally, 2004" startWordPosition="3380" endWordPosition="3383">TokenizerAnnotator: 0.0 sec. WordsToSentencesAnnotator: 0.0 sec. POSTaggerAnnotator: 0.0 sec. 59 MorphaAnnotator: 0.0 sec. ParserAnnotator: 0.4 sec. SentimentAnnotator: 0.1 sec. TOTAL: 0.6 sec. for 16 tokens at 27.4 tokens/sec. Pipelinesetup: 3.0 sec. Total time for StanfordCoreNLP pipeline: 4.2 sec. $ grep sentiment sentiment.txt.xml &lt;sentence id=&amp;quot;1&amp;quot; sentimentValue=&amp;quot;3&amp;quot; sentiment=&amp;quot;Positive&amp;quot;&gt; &lt;sentence id=&amp;quot;2&amp;quot; sentimentValue=&amp;quot;4&amp;quot; sentiment=&amp;quot;Verypositive&amp;quot;&gt; &lt;sentence id=&amp;quot;3&amp;quot; sentimentValue=&amp;quot;1&amp;quot; sentiment=&amp;quot;Negative&amp;quot;&gt; D Use within UIMA The main part of using Stanford CoreNLP within the UIMA framework (Ferrucci and Lally, 2004) is mapping between CoreNLP annotations, which are regular Java classes, and UIMA annotations, which are declared via XML type descriptors (from which UIMA-specific Java classes are generated). A wrapper for CoreNLP will typically define a subclass of JCasAnnotator ImplBase whose process method: (i) extracts UIMA annotations from the CAS, (ii) converts UIMA annotations to CoreNLP annotations, (iii) runs CoreNLP on the input annotations, (iv) converts the CoreNLP output annotations into UIMA annotations, and (v) saves the UIMA annotations to the CAS. To illustrate part of this process, the Clea</context>
</contexts>
<marker>Ferrucci, Lally, 2004</marker>
<rawString>David Ferrucci and Adam Lally. 2004. UIMA: an architectural approach to unstructured information processing in the corporate research environment. Natural Language Engineering, 10:327–348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by Gibbs sampling.</title>
<date>2005</date>
<booktitle>In ACL 43,</booktitle>
<pages>363--370</pages>
<contexts>
<context position="13047" citStr="Finkel et al., 2005" startWordPosition="2020" endWordPosition="2023">ides a PTBstyle tokenizer, extended to reasonably handle noisy and web text. The corresponding components for Chinese and Arabic provide word and clitic segmentation. The tokenizer saves the character offsets of each token in the input text. cleanxml Removes most or all XML tags from the document. ssplit Splits a sequence of tokens into sentences. truecase Determines the likely true case of tokens in text (that is, their likely case in well-edited text), where this information was lost, e.g., for all upper case text. This is implemented with a discriminative model using a CRF sequence tagger (Finkel et al., 2005). pos Labels tokens with their part-of-speech (POS) tag, using a maximum entropy POS tagger (Toutanova et al., 2003). lemma Generates the lemmas (base forms) for all tokens in the annotation. gender Adds likely gender information to names. ner Recognizes named (PERSON, LOCATION, ORGANIZATION, MISC) and numerical (MONEY, NUMBER, DATE, TIME, DURATION, SET) entities. With the default 57 annotators, named entities are recognized using a combination of CRF sequence taggers trained on various corpora (Finkel et al., 2005), while numerical entities are recognized using two rule-based systems, one for</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by Gibbs sampling. In ACL 43, pages 363–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Gurevych</author>
<author>M M¨uhlh¨auser</author>
<author>C M¨uller</author>
<author>J Steimle</author>
<author>M Weimer</author>
<author>T Zesch</author>
</authors>
<title>Darmstadt knowledge processing repository based on UIMA.</title>
<date>2007</date>
<booktitle>In First Workshop on Unstructured Information Management Architecture at GLDV 2007, T¨ubingen.</booktitle>
<marker>Gurevych, M¨uhlh¨auser, M¨uller, Steimle, Weimer, Zesch, 2007</marker>
<rawString>I. Gurevych, M. M¨uhlh¨auser, C. M¨uller, J. Steimle, M. Weimer, and T. Zesch. 2007. Darmstadt knowledge processing repository based on UIMA. In First Workshop on Unstructured Information Management Architecture at GLDV 2007, T¨ubingen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hahn</author>
<author>E Buyko</author>
<author>R Landefeld</author>
<author>M M¨uhlhausen</author>
<author>M Poprat</author>
<author>K Tomanek</author>
<author>J Wermter</author>
</authors>
<title>An overview of JCoRe, the Julie lab UIMA component registry.</title>
<date>2008</date>
<booktitle>In LREC</booktitle>
<marker>Hahn, Buyko, Landefeld, M¨uhlhausen, Poprat, Tomanek, Wermter, 2008</marker>
<rawString>U. Hahn, E. Buyko, R. Landefeld, M. M¨uhlhausen, Poprat M, K. Tomanek, and J. Wermter. 2008. An overview of JCoRe, the Julie lab UIMA component registry. In LREC 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Fast exact inference with a factored model for natural language parsing.</title>
<date>2003</date>
<booktitle>Advances in Neural Information Processing Systems,</booktitle>
<volume>15</volume>
<pages>3--10</pages>
<editor>In Suzanna Becker, Sebastian Thrun, and Klaus Obermayer, editors,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="14372" citStr="Klein and Manning, 2003" startWordPosition="2214" endWordPosition="2217">and Manning, 2012). regexner Implements a simple, rule-based NER over token sequences building on Java regular expressions. The goal of this Annotator is to provide a simple framework to allow a user to incorporate NE labels that are not annotated in traditional NL corpora. For example, a default list of regular expressions that we distribute in the models file recognizes ideologies (IDEOLOGY), nationalities (NATIONALITY), religions (RELIGION), and titles (TITLE). parse Provides full syntactic analysis, including both constituent and dependency representation, based on a probabilistic parser (Klein and Manning, 2003; de Marneffe et al., 2006). sentiment Sentiment analysis with a compositional model over trees using deep learning (Socher et al., 2013). Nodes of a binarized tree of each sentence, including, in particular, the root node of each sentence, are given a sentiment score. dcoref Implements mention detection and both pronominal and nominal coreference resolution (Lee et al., 2013). The entire coreference graph of a text (with head words of mentions as nodes) is provided in the Annotation. Most of these annotators have various options which can be controlled by properties. These can either be added</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Fast exact inference with a factored model for natural language parsing. In Suzanna Becker, Sebastian Thrun, and Klaus Obermayer, editors, Advances in Neural Information Processing Systems, volume 15, pages 3–10. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heeyoung Lee</author>
<author>Angel Chang</author>
<author>Yves Peirsman</author>
<author>Nathanael Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
</authors>
<title>Deterministic coreference resolution based on entity-centric, precision-ranked rules.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>39</volume>
<issue>4</issue>
<contexts>
<context position="14751" citStr="Lee et al., 2013" startWordPosition="2274" endWordPosition="2277"> (IDEOLOGY), nationalities (NATIONALITY), religions (RELIGION), and titles (TITLE). parse Provides full syntactic analysis, including both constituent and dependency representation, based on a probabilistic parser (Klein and Manning, 2003; de Marneffe et al., 2006). sentiment Sentiment analysis with a compositional model over trees using deep learning (Socher et al., 2013). Nodes of a binarized tree of each sentence, including, in particular, the root node of each sentence, are given a sentiment score. dcoref Implements mention detection and both pronominal and nominal coreference resolution (Lee et al., 2013). The entire coreference graph of a text (with head words of mentions as nodes) is provided in the Annotation. Most of these annotators have various options which can be controlled by properties. These can either be added to the Properties object when creating an annotation pipeline via the API, or specified either by command-line flags or through a properties file when running the system from the command-line. As a simple example, input to the system may already be tokenized and presented one-sentence-per-line. In this case, we wish the tokenization and sentence splitting to just work by usin</context>
</contexts>
<marker>Lee, Chang, Peirsman, Chambers, Surdeanu, Jurafsky, 2013</marker>
<rawString>Heeyoung Lee, Angel Chang, Yves Peirsman, Nathanael Chambers, Mihai Surdeanu, and Dan Jurafsky. 2013. Deterministic coreference resolution based on entity-centric, precision-ranked rules. Computational Linguistics, 39(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Patricio</author>
</authors>
<title>Why this project is successful?</title>
<date>2009</date>
<note>https://community.jboss.org/wiki/ WhyThisProjectIsSuccessful.</note>
<contexts>
<context position="7174" citStr="Patricio (2009)" startWordPosition="1140" endWordPosition="1141">dle scaleout, they are unlikely to be an NLP expert, and are hence looking for NLP components that just work. This is a huge advantage that Stanford CoreNLP and GATE have over the empty toolbox of an Apache UIMA download, something addressed in part by the development of wellintegrated component packages for UIMA, such as ClearTK (Bethard et al., 2014), DKPro Core (Gurevych et al., 2007), and JCoRe (Hahn et al., 2008). However, the solution provided by these packages remains harder to learn, more complex and heavier weight for users than the pipeline described here. These attributes echo what Patricio (2009) argued made Hibernate successful, including: (i) do one thing well, (ii) avoid over-design, and (iii) up and running in ten minutes or less! Indeed, the design and success of Stanford CoreNLP also reflects several other of the factors that Patricio highlights, including (iv) avoid standardism, (v) documentation, and (vi) developer responsiveness. While there are many factors that contribute to the uptake of a project, and it is hard to show causality, we believe that some of these attributes account for the fact that Stanford CoreNLP is one of the more used NLP toolkits. While we certainly ha</context>
</contexts>
<marker>Patricio, 2009</marker>
<rawString>Anthony Patricio. 2009. Why this project is successful? https://community.jboss.org/wiki/ WhyThisProjectIsSuccessful.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Alex Perelygin</author>
<author>Jean Wu</author>
<author>Jason Chuang</author>
<author>Christopher D Manning</author>
<author>Andrew Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Recursive deep models for semantic compositionality over a sentiment treebank. In EMNLP</title>
<date>2013</date>
<pages>1631--1642</pages>
<contexts>
<context position="14509" citStr="Socher et al., 2013" startWordPosition="2236" endWordPosition="2239"> Annotator is to provide a simple framework to allow a user to incorporate NE labels that are not annotated in traditional NL corpora. For example, a default list of regular expressions that we distribute in the models file recognizes ideologies (IDEOLOGY), nationalities (NATIONALITY), religions (RELIGION), and titles (TITLE). parse Provides full syntactic analysis, including both constituent and dependency representation, based on a probabilistic parser (Klein and Manning, 2003; de Marneffe et al., 2006). sentiment Sentiment analysis with a compositional model over trees using deep learning (Socher et al., 2013). Nodes of a binarized tree of each sentence, including, in particular, the root node of each sentence, are given a sentiment score. dcoref Implements mention detection and both pronominal and nominal coreference resolution (Lee et al., 2013). The entire coreference graph of a text (with head words of mentions as nodes) is provided in the Annotation. Most of these annotators have various options which can be controlled by properties. These can either be added to the Properties object when creating an annotation pipeline via the API, or specified either by command-line flags or through a proper</context>
</contexts>
<marker>Socher, Perelygin, Wu, Chuang, Manning, Ng, Potts, 2013</marker>
<rawString>Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In EMNLP 2013, pages 1631–1642.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-ofspeech tagging with a cyclic dependency network. In</title>
<date>2003</date>
<booktitle>NAACL 3,</booktitle>
<pages>252--259</pages>
<contexts>
<context position="13163" citStr="Toutanova et al., 2003" startWordPosition="2038" endWordPosition="2041">nese and Arabic provide word and clitic segmentation. The tokenizer saves the character offsets of each token in the input text. cleanxml Removes most or all XML tags from the document. ssplit Splits a sequence of tokens into sentences. truecase Determines the likely true case of tokens in text (that is, their likely case in well-edited text), where this information was lost, e.g., for all upper case text. This is implemented with a discriminative model using a CRF sequence tagger (Finkel et al., 2005). pos Labels tokens with their part-of-speech (POS) tag, using a maximum entropy POS tagger (Toutanova et al., 2003). lemma Generates the lemmas (base forms) for all tokens in the annotation. gender Adds likely gender information to names. ner Recognizes named (PERSON, LOCATION, ORGANIZATION, MISC) and numerical (MONEY, NUMBER, DATE, TIME, DURATION, SET) entities. With the default 57 annotators, named entities are recognized using a combination of CRF sequence taggers trained on various corpora (Finkel et al., 2005), while numerical entities are recognized using two rule-based systems, one for money and numbers, and a separate state-of-the-art system for processing temporal expressions (Chang and Manning, 2</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-ofspeech tagging with a cyclic dependency network. In NAACL 3, pages 252–259.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>