<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000349">
<title confidence="0.986639">
Synchronous Models of Language
</title>
<author confidence="0.989279">
Owen Rambow
</author>
<affiliation confidence="0.9327">
CoGenTex, Inc.
</affiliation>
<address confidence="0.983387">
840 Hanshaw Road, Suite 11
Ithaca, NY 14850-1589
</address>
<email confidence="0.978538">
owen@cogentex. corn
</email>
<note confidence="0.760807666666667">
Giorgio Satt a
Dipartimento di Elettronica ed Informatica
Universita di Padova
</note>
<address confidence="0.9221155">
via Gradenigo, 6/A
1-35131 Padova, Italy
</address>
<email confidence="0.998593">
satta@dei.unipd.it
</email>
<sectionHeader confidence="0.99388" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996829">
In synchronous rewriting, the productions
of two rewriting systems are paired and
applied synchronously in the derivation of
a pair of strings. We present a new syn-
chronous rewriting system and argue that
it can handle certain phenomena that are
not covered by existing synchronous sys-
tems. We also prove some interesting for-
mal/computational properties of our sys-
tem.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999259636363637">
Much of theoretical linguistics can be formulated in
a very natural manner as stating correspondences
(translations) between layers of representation; for
example, related interface layers LF and PF in GB
and Minimalism (Chomsky, 1993), semantic and
syntactic information in HPSG (Pollard and Sag,
1994), or the different structures such as c-structure
and f-structure in LFG (Bresnan and Kaplan, 1982).
Similarly, many problems in natural language pro-
cessing, in particular parsing and generation, can be
expressed as transductions, which are calculations
of such correspondences. There is therefore a great
need for formal models of corresponding levels of
representation, and for corresponding algorithms for
transduction.
Several different transduction systems have been
used in the past by the computational and theoret-
ical linguistics communities. These systems have
been borrowed from translation theory, a subfield
of formal language theory, or have been originally
(and sometimes redundantly) developed. Finite
state transducers (for an overview, see, e.g., (Aho
and Ullman, 1972)) provide translations between
regular languages. These devices have been pop-
ular in computational morphology and computa-
tional phonology since the early eighties (Kosken-
niemi, 1983; Kaplan and Kay, 1994), and more re-
cently in parsing as well (see, e.g., (Gross, 1989;
Pereira, 1991; Roche, 1993)). Pushdown transduc-
ers and syntax directed translation schemata (SDTS)
(Aho and Ullman, 1969) translate between context-
free languages and are therefore more powerful than
finite state transducers. Pushdown transducers are
a standard model for parsing, and have also been
used (usually implicitly) in speech understanding.
Recently, variants of SDTS have been proposed as
models for simultaneously bracketing parallel cor-
pora (Wu, 1995). Synchronization of tree adjoin-
ing grammars (TAGs) (Shieber and Schabes, 1990;
Shieber, 1994) are even more powerful than the pre-
vious formalisms, and have been applied in machine
translation (Abellle, Schabes, and Joshi, 1990; Egedi
and Palmer, 1994; Harbusch and Poller, 1994; Pri-
gent, 1994), natural language generation (Shieber
and Schabes, 1991), and theoretical syntax (Abeille,
1994). The common underlying idea in all of these
formalisms is to combine two generative devices
through a pairing of their productions (or, in the
case of the corresponding automata, of their tran-
sitions) in such a way that right-hand side nonter-
minal symbols in the paired productions are linked.
The processes of derivation proceed synchronously
in the two devices by applying the paired grammar
rules only to linked nonterminals introduced previ-
ously in the derivation. The fact that the above sys-
tems all reflect the same translation technique has
not always been recognized in the computational lin-
guistics literature. Following (Shieber and Schabes,
1990) we will refer to the general approach as syn-
chronous rewriting. While synchronous systems are
becoming more and more popular, surprisingly little
is known about the formal characteristics of these
systems (with the exception of the finite-state de-
vices).
In this paper, we argue that existing synchronous
systems cannot handle, in a computationally attrac-
</bodyText>
<page confidence="0.997684">
116
</page>
<figureCaption confidence="0.808691526315789">
tive way, a standard problem in syntax/semantics
translation, namely quantifier scoping. We propose
a new system that provides a synchronization be-
tween two unordered vector grammars with domi-
nance links (UVG-DL) (Rambow, 1994). The type
of synchronization is closely based on a previously
proposed model, which we will call &amp;quot;local&amp;quot; synchro-
nization. We argue that this synchronous system can
deal with quantifier scoping in the desired way. The
proposed system has the weak language preservation
property, that is, the defined synchronization mech-
anism does not alter the weak generative capacity
of the formalism being synchronized. Furthermore,
the tree-to-forest translation problem for our system
can be solved in polynomial time; that is, given a
derivation tree obtained according to one of the syn-
chronized grammars, we can construct the forest of
all the translated derivation trees in the other gram-
mar, using a polynomial amount of time.
</figureCaption>
<bodyText confidence="0.948137166666667">
The structure of this paper is as follows. In Sec-
tion 2, we introduce quantifier raising and review
two types of synchronization and mention some new
formal results. We introduce our new synchronous
system in Section 3, and present our formal results
and outline the proof techniques in Section 4.
</bodyText>
<sectionHeader confidence="0.668334" genericHeader="method">
2 Types of Synchronization
</sectionHeader>
<subsectionHeader confidence="0.993917">
2.1 Quantifier Raising
</subsectionHeader>
<bodyText confidence="0.999984666666667">
We start by presenting an example which is based
on transfer between a syntactic representation and
a &amp;quot;semantic&amp;quot; representation of the scoping of quan-
tified NPs. It is generally assumed that in English
(and many other languages), quantified arguments
of a verb can (in appropriate contexts) take scope
in any possible order, and that this generalization
extends to cases of embedded clauses (May, 1985).1
For example, sentence (1) can have four possible in-
terpretations (of the six possible orderings of the
quantifiers, two pairs are logically equivalent), two
of which are shown in (2).
</bodyText>
<listItem confidence="0.99406275">
(1) Every man thinks some official said some Nor-
wegian arrived
(2) a. Vx, x a man, 3y, y an official, 3z, z a Nor-
wegian, x thinks y said z arrived
</listItem>
<equation confidence="0.4961645">
b. 3z, z a Norwegian, 3y, y an official, Vx, x a
man, x thinks y said z arrived
</equation>
<bodyText confidence="0.648875857142857">
&apos;We explicitly exclude from our analysis cases of
quantified NPs embedded in NPs, and do not, of course,
propose to develop a serious linguistic theory of quanti-
fier scoping.
We give a simplified syntactic representation for
(1) in Figure 1, and a simplified semantic represen-
tation for (2b) in Figure 2.
</bodyText>
<figure confidence="0.9454454">
every man VP
thinks
some official VP
said
some Norwegian arrived
</figure>
<figureCaption confidence="0.997859">
Figure 1: Syntactic representation for (1)
</figureCaption>
<construct confidence="0.768326166666667">
exists z,
z a Norwegian
exists y,
y an official
for all x,
x a man
</construct>
<equation confidence="0.635796">
think T
I
say T
I
arrive
</equation>
<figureCaption confidence="0.99506">
Figure 2: Semantic representation for (2b)
</figureCaption>
<subsectionHeader confidence="0.988477">
2.2 Non-Local Synchronization
</subsectionHeader>
<bodyText confidence="0.979265470588235">
We will first discuss a type of synchronization pro-
posed by (Shieber and Schabes, 1990), based on
TAG. We will refer to this system as non-local syn-
chronous TAG (n1SynchTAG). The synchronization
is non-local in the sense that once links are intro-
duced during a derivation by a synchronized pair of
grammar rules, they need not continue to impinge on
the nodes that introduced them: the links may be re-
assigned to a newly introduced nonterminal when an
original node is rewritten. We will refer to this mech-
anism as link inheritance. To illustrate, we will give
as an example an analysis of the quantifier-raising
example introduced above, extending in a natural
manner an example given by Shieber and Schabes.
The elementary structures are shown in Figure 3
(we only give one NP â€” the others are similar). The
nominal arguments in the syntax are associated with
</bodyText>
<figure confidence="0.991594166666667">
1 1 7
for all x,
x a man
NP
every man
NP VP
thinks
NP VP
think T F
say T F
arrive T
says
</figure>
<figureCaption confidence="0.99972">
Figure 3: Elementary structures in n1SynchTAG
</figureCaption>
<bodyText confidence="0.9993881">
pairs of trees in the semantics, and are linked to two
nodes, the quantifier and the variable. The deriva-
tion proceeds as illustrated in Figure 4, finally yield-
ing the two structures in Figure 1 and Figure 2. Note
that some of the links originating with the NP nodes
are inherited during the derivation. By changing the
order in which we add the nominal arguments at the
end of the derivation, we can obtain all quantifier
scopes in the semantics.
The problem with non-local synchronization is
that the weak language preservation property does
not hold. (Shieber, 1994) shows that not all
n1SynchTAG left-projection languages can be gen-
erated by TAGs. As a new result, in (Rambow and
Satta, 1996) we show that the recognition of some
fixed left-projection languages of a n1SynchTAG is
NP-complete. Our reduction crucially relies on link
inheritance. This makes n1SynchTAG unattractive
for applications in theoretical or computational lin-
guistics.
</bodyText>
<subsectionHeader confidence="0.999265">
2.3 Local Synchronous Systems
</subsectionHeader>
<bodyText confidence="0.999777875">
In contrast with non-local synchronization, in local
synchronization there is no inheritance of synchro-
nization links. This is enforced by requiring that
the links establish a bijection between nonterminals
in the two synchronously derived sentential forms,
that is, each nonterminal must be involved in exactly
one link. In this way, once a nonterminal is rewrit-
ten through the application of a pair of rules to two
</bodyText>
<figureCaption confidence="0.994375">
Figure 4: Non-local derivation in n1SynchTAG
</figureCaption>
<bodyText confidence="0.999858866666667">
linked nonterminals, no additional link remains to
be transferred to the newly introduced nonterminals.
As a consequence of this, the derivation structures in
the left and right grammars are always isomorphic
(up to ordering and labeling of nodes).
The canonical example of local synchronization
is SDTS (Aho and Ullman, 1969), in which two
context-free grammars are synchronized. We give
an example of an SDTS and a derivation in Fig-
ure 5. The links are indicated as boxed numbers
to the right of the nonterminal to which they ap-
ply. (Shieber, 1994) defines the tree-rewriting ver-
sion of SDTS, which we will call synchronous TAG
(SynchTAG), and argues that SynchTAG does not
have the formal problems of n1SynchTAG (though
</bodyText>
<figure confidence="0.99811162962963">
VP
NP VP
I
every man thinks
NP
says
tor all x,
x a man
think T F
I /1
say T F
arrive
NP VP
arrives
1 1 8
Grammar: NP13 likes NP NPEI plait a NP
SU -+
NPU --+ John NP11:1 -4 Jean
NPEI -Ã· the white NE NPO â€”&gt; la N111 blanche
13 house --+ maison
Derivation:
(S o , SE])
(N1313 likes NP , N
.(NP likes the white
NPEI)
(John likes the white
plait a Jean)
</figure>
<figureCaption confidence="0.99993">
Figure 5: Sample SDTS and derivation
</figureCaption>
<bodyText confidence="0.983472272727273">
(Shieber, 1994) studies the translation problem mak-
ing the unappealing assumption that each tree in the
input grammar is associated with only one output
grammar tree).
However, SynchTAG cannot derive all possible
scope orderings, because of the locality restriction.
This can be shown by adapting the proof technique
in (Becker, Rambow, and Niv, 1992). In the follow-
ing section, we will present a synchronous system
which has local synchronization&apos;s formal advantages,
but handles the scoping data.
</bodyText>
<sectionHeader confidence="0.986848" genericHeader="method">
3 Extended Local Synchronization
</sectionHeader>
<bodyText confidence="0.999256193548387">
In this section, we propose a new synchronous sys-
tem, which is based on local synchronization of
unordered vector grammars with dominance links
(UVG-DL) (Rambow, 1994). The presentations will
be informal for reasons of space; we refer to (Ram-
bow and Satta, 1996) for details. In UVG-DL, sev-
eral context-free string rewriting rules are grouped
into sets, called vectors. In a derivation, all or no
rules from a given instance of a vector must be used.
Put differently, all productions from a given vector
must be used the same number of times. They can
be applied in any order and need not be applied
simultaneously or one right after the other. In addi-
tion, UVG-DL has dominance links. An occurrence
of a nonterminal A in the right-hand side of a rule p
can be linked to the left-hand nonterminal of another
rule p&apos; in the same vector. This dominance link will
act as a constraint on derivations: if p is used in
a derivation, then p&apos; must be used subsequently in
the subderivation that starts with the occurrence of
A introduced by p. A UVG-DL is lexicalized if at
least one production in every vector contains a ter-
minal symbol. Henceforth, all UVG-DLs mentioned
in this paper will implicitly be assumed to be lex-
icalized. The derivation structure of a UVG-DL is
just the derivation structure of the same derivation
in the underlying context-free grammar (the CFG
obtained by forming the union of all vectors). We
give an example of a UVG-DL in Figure 6, in which
the dotted lines represent the dominance links. A
sample derivation is in Figure 7.
</bodyText>
<table confidence="0.832502571428571">
FA&apos;\
think T F
exists y,
y an official
lz lam?\. \T
exists z F
z a Norwegian
</table>
<figureCaption confidence="0.9995475">
Figure 6: A UVG-DL for deriving semantic repre-
sentations such as (2)
</figureCaption>
<bodyText confidence="0.998632967741936">
Our proposal for the synchronization of two UVG-
DL uses the notion of locality in synchronization,
but with respect to entire vectors, not individual
productions in these vectors. This approach, as we
will see, gives us both the desired empirical coverage
and acceptable computational and formal results.
We suppose that in each vector v of a UVG-DL there
is exactly one privileged element, which we call the
synchronous production of v. All other elements of
v are referred to as asynchronous productions. In
Figures 6 and 7, the synchronous productions are
designated by a bold-italic left-hand side symbol.
Furthermore, in the right-hand side of each asyn-
chronous production of v we identify a single non-
terminal nonterminal, called the heir.
In a synchronous UVG-DL (SynchUVG-DL), vec-
tors from one UVG-DL are synchronized with vec-
tors from another UVG-DL. Two vectors are syn-
chronized by specifying a bijective synchronization
mapping (as in local synchronization) between the
non-heir right-hand side occurrences of nonterminals
in the productions of the two vectors. A nontermi-
nal on which a synchronization link impinges is re-
ferred to as a synchronous nonterminal. A sample
SynchUVG-DL grammar is shown in Figure 9.
Informally speaking, during a SynchUVG-DL
derivation, the two synchronous productions in a
pair of synchronized vectors must be applied at
the same time and must rewrite linked occurrences
of nonterminals previously introduced. The asyn-
chronous productions of the two synchronized gram-
</bodyText>
<table confidence="0.786470333333333">
plait a NP
NE, la NE blanche plait a
for all x,
house, la maison blanche x a man
F
say T F
</table>
<page confidence="0.994663">
119
</page>
<bodyText confidence="0.999825393939394">
mars are not subject to the synchronization require-
ment, and they can be applied at any time and in-
dependently of the other grammar (but of course
subject to the grammar-specific dominance links).
Any synchronous links that impinge on a nonter-
minal rewritten by an asynchronous production are
transferred to the heir of the asynchronous produc-
tion. A production may introduce a synchronous
nonterminal whose counterpart in the other gram-
mar has not yet been introduced. In this case, the
link remains &amp;quot;pending&amp;quot;. Thus, while in SynchUVG-
DL there is link inheritance as in non-local synchro-
nization, link inheritance is only possible with those
productions that themselves are not subject to the
synchronization requirement.
The locality of the synchronization becomes clear
when we consider a new tree structure which we
introduce here, called the vector derivation tree.
Consider two synchronized UVG-DLderivations in a
SynchUVG-DL. The vector derivation tree for either
component derivation is obtained as follows. Each
instance of a vector used in the derivation is repre-
sented as a single node (which we label with that
vector&apos;s lexeme). A node representing a vector vi
is immediately dominated by the node representing
the vector v2 which introduced the synchronization
link that the synchronous production of v1 rewrites.
Unlike the standard derivation tree for UVG-DL, the
vector derivation tree clearly shows how the vectors
(rather than the component rules of the vectors)
were combined during the derivation. The vector
derivation tree for the derivation in Figure 7 is shown
in Figure 8.
</bodyText>
<figureCaption confidence="0.999697">
Figure 7: Derivation of (2b) in a UVG-DL
</figureCaption>
<bodyText confidence="0.997687666666667">
It should be clear that the vector derivation trees
for two synchronized derivations are isomorphic, re-
flecting the fact that our definition of SynchUVG-
</bodyText>
<figure confidence="0.9955895">
think
every man say
exists arrive
an official
exists
a Norwegian
</figure>
<figureCaption confidence="0.970545">
Figure 8: Vector derivation tree for derivation of
(2b)
</figureCaption>
<bodyText confidence="0.986863075">
DL is local with respect to vectors (though not with
respect to productions, since the derivation trees of
two synchronized UVG-DL derivations need not be
isomorphic). The vector derivation tree can be seen
as representing an &amp;quot;outline&amp;quot; for the derivation. Such
a view is attractive from a linguistic perspective: if
each vector represents a lexeme and its projection
(where the synchronous production is the basis of
the lexical projection that the vector represents),
then the vector derivation tree is in fact the depen-
dency tree of the sentence (representing direct re-
lations between lexemes such as grammatical func-
tion). In this respect, the vector derivation tree of
UVG-DL is like the derivation tree of tree adjoining
grammar and of D-tree grammars (DTG) (Rambow,
Vijay-Shanker, and Weir, 1995), which is not sur-
prising, since all three formalisms share the same
extended domain of locality. Furthermore, the vec-
tor derivation tree of SynchUVG-DL shares with
the the derivation tree of DTG the property that
it reflects linguistic dependency uniformly; however,
while the definition of DTG was motivated pre-
cisely from considerations of dependency, the vector
derivation tree is merely a by-product of our defi-
nition of SynchUVG-DL, which was motivated from
the desire to have a computationally tractable model
of synchronization more powerful than SynchTAG.2
We briefly discuss a sample derivation. We start
with the two start symbols, which are linked. We
then apply an asynchronous production from the se-
mantic grammar. In Figure 10 (top) we see how
the link is inherited by the heir nonterminal of the
applied production. This step is repeated with two
more asynchronous productions, yielding Figure 10
(bottom). We now apply productions for the bodies
of the clauses, but stop short before the two syn-
chronous productions for the arrive clause, yielding
Figure 11. We see the asynchronous production of
the syntactic arrive vector has not only inherited the
link to its heir nonterminal, but has introduced a link
</bodyText>
<footnote confidence="0.7954385">
2We do not discuss modifiers in this paper for lack of
space.
</footnote>
<figure confidence="0.988873888888889">
think T F
xi say T
I
arrive
exists z,
z a Norwegian
...............
exists y,
..
for all x, Fâ€¢
y an official
x a man
120
F
every man for all x, F*
x a tnan
1/---Z-&apos;\
NP VP* think S Mink T F
</figure>
<figureCaption confidence="0.969483">
Figure 9: SynchUVG-DL grammar for quantifier
scope disambiguation
</figureCaption>
<table confidence="0.444457666666667">
exists z,
z a Norwegian
exists y,
y an official
for all it, F*
x a man
</table>
<figureCaption confidence="0.909678">
Figure 10: SynchUVG-DL derivation, steps 1 and 2
</figureCaption>
<bodyText confidence="0.9896002">
of its own. Since the semantic end of the link has
not been introduced yet, the links remains &amp;quot;pend-
ing&amp;quot; until that time. We then finish the derivation
to obtain the two trees in Figure 1 and Figure 2,
with no synchronization or dominance links left.
</bodyText>
<sectionHeader confidence="0.996998" genericHeader="method">
4 Formal results
</sectionHeader>
<bodyText confidence="0.923222166666667">
Theorem 1 SynchUVG-DL has the language
preservation property.
Proof (outline). Let G, be a SynchUVG-DL, G&apos;
and G&amp;quot; its left and right UVG-DL components, re-
spectively. We construct a UVG-DL G generating
the left-projection language of G,. G uses all the
</bodyText>
<figureCaption confidence="0.991419">
Figure 11: SynchUVG-DL derivation, step 3
</figureCaption>
<bodyText confidence="0.999944555555555">
nonterminal symbols of G&apos; and G&amp;quot;, and some com-
pound nonterminals of the form [A, B], A and B
nonterminals of G&apos; and G&amp;quot;, respectively. G simu-
lates G, derivations by intermixing symbols of G&apos;
and symbols of G&amp;quot;, and without generating any of
the terminal symbols of G&amp;quot;. Most important, each
pair of linked nonterminals generated by G, is rep-
resented by G using a compound symbol. This en-
forces the requirement of simultaneous application
of synchronous productions to linked nonterminals.
Each vector v of G is constructed from a pair of
synchronous vectors (v&apos;, v&amp;quot;) of G. as follows. First,
all instances of nonterminals in v&amp;quot; are replaced by e.
Furthermore, for any instance B of a right-hand side
nonterminal of v&amp;quot; linked to a right-hand side non-
terminal A of VI, B is replaced by e and A by [A, B].
Then the two synchronous productions in v` and v&amp;quot;
are composed into a single production in v, by com-
posing the two left-hand sides in a compound symbol
and by concatenating the two right-hand sides. Fi-
nally, to simulate link inheritance in derivations of
G,, each asynchronous production in v&apos; and v&amp;quot; is
transferred to v, either without any change, or by
composing with some nonterminal C both its left-
hand side and the heir nonterminal in its right-hand
side. Note that there are finitely many choices for
the last step, and each choice gives a different vector
in G, simulating the application of v&apos; and v&amp;quot; to a set
of (occurrences of) nonterminals in a particular link
configuration in a sentential form of G,.
We now introduce a representation for sets of
derivation trees in a UVG-DL G. A parse tree in
G is an ordered tree representing a derivation in G
and encoding at each node the production p used to
start the corresponding subderivation and the mul-
tiset of productions f used in that subderivation. A
</bodyText>
<figure confidence="0.670069315789474">
INP /some official exists y, F*
y an official â€¢ â€¢
NP VP
thinks
NP VP
said
.--â€¢â– â€¢â€¢â€¢â€¢â€¢â€¢â€¢
exists y, F.
y an official
â€¢
for all x,
x a man
think T F I
NP VP
say T F
exists z,
z a Norwegian
exists z, F*
z a Norwegian
</figure>
<page confidence="0.994813">
121
</page>
<bodyText confidence="0.998030333333333">
parse forest in G is a directed acyclic graph which
is ordered and bipartite. (We use ideas originally
developed in (Lang, 1991) for the context-free case.)
Nodes of the graph are of two different types, called
and-nodes and or-nodes, respectively, and each di-
rected arc connects nodes of different types. A parse
forest in G represents a set T of parse trees in G if
the following holds. When starting at a root node
and walking through the graph, if we follow exactly
one of the outgoing arcs at each or-node, and all of
the outgoing arcs at each and-node, we obtain a tree
in T modulo the removal of the or-nodes. Further-
more, every tree in T can be obtained in this way.
Lemma 2 Let G be a UVG-DL and let q &gt; 1 be
a natural number. The parse forest representing the
set of all parse trees in G with no more than q vectors
can be constructed in an amount of time bounded by
a polynomial function of q. â€¢
Let G, be a SynchUVG-DL, G&apos; and G&amp;quot; its left
and right UVG-DL components, respectively. For
a parse tree T in G&apos;, we denote as T(T) the set
of all parse trees in G&amp;quot; that are synchronous with
T according to G.. The parse-to-forest translation
problem for G, takes as input a parse tree T in G&apos;
and gives as output a parse forest representation for
T(r). If G, is lexicalized, such a parse forest has size
bounded by a polynomial function of IT I, despite the
fact that the size of T(r) can be exponentially larger
than the size of T. In fact, we have a stronger result.
Theorem 3 The parse-to-forest translation prob-
lem for a lexicalized SynchUVG-DL can be computed
in polynomial time.
Proof (outline). Let G, be a SynchUVG-DL
with G&apos; and G&amp;quot; its left and right UVG-DL com-
ponents, respectively. Let T be a parse tree in G&apos;
and 7r be the parse forest representing T(r). The
construction of ir consists of two stages.
In the first stage, we construct the vector deriva-
tion tree 7 associated with T. Let q be the number
of nodes of 7. We also construct a parse forest 7rq
representing the set of all parse trees in G&amp;quot; with no
more than q vectors. This stage takes polynomial
time in the size of T, since -y can be constructed
from r in linear time and irq can be constructed as
in Lemma 2.
In the second stage, we remove from 7rq all the
parse trees not in 7r. This completes the construc-
tion, since the set of parse trees represented by ir is
included in the set of parse trees represented by Irq.
Let n and r be the root node and the set of all nodes
of 7, respectively. For n E out(n) denotes the set
of all children of n. We call family the set {nr} and
any nonempty subset of out(n), n E r. The main
idea is to associate a set of families Yr, to each node
n of 7rq, such that the following condition is satis-
fied. A family F belongs to _Fri if and only if at least
one subderivation in G&amp;quot; represented at n induces a
forest of vector derivation trees whose root nodes
are all and only the nodes in F. Each .FT, can eas-
ily be computed visiting irq in a bottom-up fashion.
Crucially, we &amp;quot;block&amp;quot; a node of 7rq if we fail in the
construction of 7;2. We claim that each set ..rn has
size bounded by the number of nodes in 7. This can
be shown using the fact that all derivation trees rep-
resented at a node of Irq employ the same multiset of
productions of G&amp;quot;. From the above claim, it follows
that irq can be processed in time polynomial in the
size of T. Finally, we obtain 7r simply by removing
from irq all nodes that have been blocked. â€¢
</bodyText>
<sectionHeader confidence="0.9993" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999982">
We have presented SynchUVG-DL, a synchronous
system which has restricted formal power, is com-
putationally tractable, and which handles the
quantifier-raising data. In addition, SynchUVG-DL
can be used for modeling the syntax of languages
with syntactic constructions which have been ar-
gued to be beyond the formal power of TAG, such
as scrambling in German and many other lan-
guages (Rainbow, 1994) or wh-movement in Kash-
miri (Rambow, Vijay-Shanker, and Weir, 1995).
SynchUVG-DL can be used to synchronize a syn-
tactic grammar for these languages either with a se-
mantic grammar, or with the syntactic grammar of
another language for machine translation applica-
tions. However, SynchUVG-DL cannot handle the
list of cases listed in (Shieber, 1994). These pose a
problem for SynchUVG-DL for the same reason that
they pose a problem for other local synchronous sys-
tems: the (syntactic) dependency structures repre-
sented by the two derivations are different. These
cases remain an open research issue.
</bodyText>
<sectionHeader confidence="0.997488" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999017833333333">
Parts of the present research were done while Ram-
bow was supported by the North Atlantic Treaty Or-
ganization under a Grant awarded in 1993, while at
TALANA, Universite Paris 7, and while Satta was
visiting the Center for Language and Speech Pro-
cessing, Johns Hopkins University, Baltimore, MD.
</bodyText>
<sectionHeader confidence="0.987296" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.995891">
Abeille, Anne. 1994. Syntax or semantics? Han-
dling nonlocal dependencies with MCTAGs or
</bodyText>
<page confidence="0.995373">
122
</page>
<reference confidence="0.999681572916667">
Synchronous TAGs. Computational Intelligence,
10(4):471-485.
Abeille, Anne, Yves Schabes, and Aravind Joshi.
1990. Using lexicalized TAGs for machine trans-
lation. In Proceedings of the 13th International
Conference on Computational Linguistics (COL-
INC &apos;90), Helsinki. COLING-90.
Aho, A. V. and J. D. Ullman. 1969. Syntax di-
rected translations and the pushdown assembler.
J. Comput. Syst. Sci., 3(1):37-56.
Aho, A. V. and J. D. Ullman. 1972. The Theory
of Parsing, Translation, and Compiling. Prentice
Hall, Englewood Cliffs, NJ.
Becker, Tilman, Owen Rambow, and Michael Niv.
1992. The derivational generative power, or,
scrambling is beyond LCFRS. Technical Report
IRCS-92-38, Institute for Research in Cognitive
Science, University of Pennsylvania.
Bresnan, J. and R. Kaplan. 1982. Lexical-functional
grammar: A formal system for grammatical repre-
sentation. In J. Bresnan, editor, The Mental Rep-
resentation of Grammatical Relations. MIT Press.
Chomsky, Noam. 1993. A minimalist program for
linguistic theory. In Kenneth Hale and Samuel J.
Keyser, editors, The View from Building 20. MIT
Press, Cambridge, Mass., pages 1-52.
Egedi, Dana and Martha Palmer. 1994. Constrain-
ing lexical selection across languages using TAG.
In 3e Colloque International sur les Grammaires
d&apos;Arbres Adjoints (TA G+3), Rapport Technique
TALANA-RT-94-01. Universite Paris 7.
Gross, Maurice. 1989. The use of Finite-State Au-
tomata in the lexical representation of natural lan-
guage. In M. Gross and D. Perrin, editors, Elec-
tronic Dictionaries and Automata in Computa-
tional Linguistics. Springer.
Harbusch, Karin and Peter Poller. 1994. Structural
rewriting with synchronous rewriting systems. In
3e Colloque International sur les Grammaires
d&apos;Arbres Adjoints (TAG+3), Rapport Technique
TALANA-RT-94-01. Universite Paris 7.
Kaplan, Ronald M. and Martin Kay. 1994. Regular
models of phonological rule systems. Computa-
tional Linguistics, 20(3):331-378.
Koskenniemi, Kimmo. 1983. Two-level morphol-
ogy: A general computational model for word-
form recognition and production. Technical Re-
port 11, Department of General Linguistics, Uni-
versity of Helsinki.
Lang, B. 1991. Towards a uniform formal frame-
work for parsing. In M. Tomita, editor, Current
Issues in Parsing technology. Kluwer Academic
Publishers, chapter 11, pages 153-171.
May, Robert. 1985. Logical Form: Its structure and
Derivation. MIT Press, Cambridge, Mass.
Pereira, Fernando. 1991. Finite-state approxima-
tion of phrase structure grammars. In 29th Meet-
ing of the Association for Computational Linguis-
tics (ACL &apos;91), Berkeley, California. ACL.
Pollard, Carl and Ivan Sag. 1994. Head-
Driven Phrase Structure Grammar. University of
Chicago Press, Chicago.
Prigent, Gilles. 1994. Synchronous tags and ma-
chine translation. In 3e Colloque International
sur les Grammaires d&apos;Arbres Adjoints (TAG+3),
Rapport Technique TALANA-RT-94-01. Univer-
site Paris 7.
Rambow, Owen. 1994. Multiset-valued linear index
grammars. In 32nd Meeting of the Association for
Computational Linguistics (ACL&apos;94). ACL.
Rambow, Owen and Giorgio Satta. 1996. Syn-
chronous models of language. Manuscript under
preparation.
Rambow, Owen, K. Vijay-Shanker, and David Weir.
1995. D-Tree Grammars. In 33rd Meeting
of the Association for Computational Linguistics
(ACL&apos;95). ACL.
Roche, Emmanuel. 1993. Analyse syntaxique
transformationelle du francais par transducteur et
lexique-gramrnaire. Ph.D. thesis, Universite Raris
7, Paris, France.
Shieber, Stuart and Yves Schabes. 1990. Syn-
chronous tree adjoining grammars. In Proceedings
of the 13th International Conference on Compu-
tational Linguistics, Helsinki.
Shieber, Stuart and Yves Schabes. 1991. Gener-
ation and synchronous tree adjoining grammars.
Computational Intelligence, 4(7):220-228.
Shieber, Stuart B. 1994. Restricting the weak
generative capacity of Synchronous Tree Ad-
joining Grammar. Computational Intelligence,
10(4):371-385.
Wu, Delcai. 1995. An algorithm for simultane-
ously bracketing parallel texts by aligning words.
In 33rd Meeting of the Association for Computa-
tional Linguistics (ACL&apos;95). ACL.
</reference>
<page confidence="0.998949">
123
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.451493">
<title confidence="0.999867">Synchronous Models of Language</title>
<author confidence="0.999708">Owen Rambow</author>
<affiliation confidence="0.994353">CoGenTex, Inc.</affiliation>
<address confidence="0.99961">840 Hanshaw Road, Suite 11 Ithaca, NY 14850-1589</address>
<author confidence="0.767403">corn Giorgio Satt a</author>
<affiliation confidence="0.998652">Dipartimento di Elettronica ed Informatica Universita di Padova</affiliation>
<address confidence="0.9919845">via Gradenigo, 6/A 1-35131 Padova, Italy</address>
<email confidence="0.998905">satta@dei.unipd.it</email>
<abstract confidence="0.980648909090909">In synchronous rewriting, the productions of two rewriting systems are paired and applied synchronously in the derivation of a pair of strings. We present a new synchronous rewriting system and argue that it can handle certain phenomena that are not covered by existing synchronous systems. We also prove some interesting formal/computational properties of our system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Synchronous TAGs</author>
</authors>
<journal>Computational Intelligence,</journal>
<pages>10--4</pages>
<marker>TAGs, </marker>
<rawString>Synchronous TAGs. Computational Intelligence, 10(4):471-485.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anne Abeille</author>
<author>Yves Schabes</author>
<author>Aravind Joshi</author>
</authors>
<title>Using lexicalized TAGs for machine translation.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics (COLINC &apos;90),</booktitle>
<location>Helsinki.</location>
<marker>Abeille, Schabes, Joshi, 1990</marker>
<rawString>Abeille, Anne, Yves Schabes, and Aravind Joshi. 1990. Using lexicalized TAGs for machine translation. In Proceedings of the 13th International Conference on Computational Linguistics (COLINC &apos;90), Helsinki. COLING-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A V Aho</author>
<author>J D Ullman</author>
</authors>
<title>Syntax directed translations and the pushdown assembler.</title>
<date>1969</date>
<journal>J. Comput. Syst. Sci.,</journal>
<pages>3--1</pages>
<contexts>
<context position="2138" citStr="Aho and Ullman, 1969" startWordPosition="307" endWordPosition="310">e systems have been borrowed from translation theory, a subfield of formal language theory, or have been originally (and sometimes redundantly) developed. Finite state transducers (for an overview, see, e.g., (Aho and Ullman, 1972)) provide translations between regular languages. These devices have been popular in computational morphology and computational phonology since the early eighties (Koskenniemi, 1983; Kaplan and Kay, 1994), and more recently in parsing as well (see, e.g., (Gross, 1989; Pereira, 1991; Roche, 1993)). Pushdown transducers and syntax directed translation schemata (SDTS) (Aho and Ullman, 1969) translate between contextfree languages and are therefore more powerful than finite state transducers. Pushdown transducers are a standard model for parsing, and have also been used (usually implicitly) in speech understanding. Recently, variants of SDTS have been proposed as models for simultaneously bracketing parallel corpora (Wu, 1995). Synchronization of tree adjoining grammars (TAGs) (Shieber and Schabes, 1990; Shieber, 1994) are even more powerful than the previous formalisms, and have been applied in machine translation (Abellle, Schabes, and Joshi, 1990; Egedi and Palmer, 1994; Harbu</context>
<context position="9341" citStr="Aho and Ullman, 1969" startWordPosition="1478" endWordPosition="1481">ablish a bijection between nonterminals in the two synchronously derived sentential forms, that is, each nonterminal must be involved in exactly one link. In this way, once a nonterminal is rewritten through the application of a pair of rules to two Figure 4: Non-local derivation in n1SynchTAG linked nonterminals, no additional link remains to be transferred to the newly introduced nonterminals. As a consequence of this, the derivation structures in the left and right grammars are always isomorphic (up to ordering and labeling of nodes). The canonical example of local synchronization is SDTS (Aho and Ullman, 1969), in which two context-free grammars are synchronized. We give an example of an SDTS and a derivation in Figure 5. The links are indicated as boxed numbers to the right of the nonterminal to which they apply. (Shieber, 1994) defines the tree-rewriting version of SDTS, which we will call synchronous TAG (SynchTAG), and argues that SynchTAG does not have the formal problems of n1SynchTAG (though VP NP VP I every man thinks NP says tor all x, x a man think T F I /1 say T F arrive NP VP arrives 1 1 8 Grammar: NP13 likes NP NPEI plait a NP SU -+ NPU --+ John NP11:1 -4 Jean NPEI -Ã· the white NE NPO </context>
</contexts>
<marker>Aho, Ullman, 1969</marker>
<rawString>Aho, A. V. and J. D. Ullman. 1969. Syntax directed translations and the pushdown assembler. J. Comput. Syst. Sci., 3(1):37-56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A V Aho</author>
<author>J D Ullman</author>
</authors>
<date>1972</date>
<booktitle>The Theory of Parsing, Translation, and Compiling.</booktitle>
<publisher>Prentice Hall,</publisher>
<location>Englewood Cliffs, NJ.</location>
<contexts>
<context position="1748" citStr="Aho and Ullman, 1972" startWordPosition="249" endWordPosition="252">icular parsing and generation, can be expressed as transductions, which are calculations of such correspondences. There is therefore a great need for formal models of corresponding levels of representation, and for corresponding algorithms for transduction. Several different transduction systems have been used in the past by the computational and theoretical linguistics communities. These systems have been borrowed from translation theory, a subfield of formal language theory, or have been originally (and sometimes redundantly) developed. Finite state transducers (for an overview, see, e.g., (Aho and Ullman, 1972)) provide translations between regular languages. These devices have been popular in computational morphology and computational phonology since the early eighties (Koskenniemi, 1983; Kaplan and Kay, 1994), and more recently in parsing as well (see, e.g., (Gross, 1989; Pereira, 1991; Roche, 1993)). Pushdown transducers and syntax directed translation schemata (SDTS) (Aho and Ullman, 1969) translate between contextfree languages and are therefore more powerful than finite state transducers. Pushdown transducers are a standard model for parsing, and have also been used (usually implicitly) in spe</context>
</contexts>
<marker>Aho, Ullman, 1972</marker>
<rawString>Aho, A. V. and J. D. Ullman. 1972. The Theory of Parsing, Translation, and Compiling. Prentice Hall, Englewood Cliffs, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tilman Becker</author>
<author>Owen Rambow</author>
<author>Michael Niv</author>
</authors>
<title>The derivational generative power, or, scrambling is beyond LCFRS.</title>
<date>1992</date>
<tech>Technical Report IRCS-92-38,</tech>
<institution>Institute for Research in Cognitive Science, University of Pennsylvania.</institution>
<contexts>
<context position="10474" citStr="Becker, Rambow, and Niv, 1992" startWordPosition="1687" endWordPosition="1691">ammar: NP13 likes NP NPEI plait a NP SU -+ NPU --+ John NP11:1 -4 Jean NPEI -Ã· the white NE NPO â€”&gt; la N111 blanche 13 house --+ maison Derivation: (S o , SE]) (N1313 likes NP , N .(NP likes the white NPEI) (John likes the white plait a Jean) Figure 5: Sample SDTS and derivation (Shieber, 1994) studies the translation problem making the unappealing assumption that each tree in the input grammar is associated with only one output grammar tree). However, SynchTAG cannot derive all possible scope orderings, because of the locality restriction. This can be shown by adapting the proof technique in (Becker, Rambow, and Niv, 1992). In the following section, we will present a synchronous system which has local synchronization&apos;s formal advantages, but handles the scoping data. 3 Extended Local Synchronization In this section, we propose a new synchronous system, which is based on local synchronization of unordered vector grammars with dominance links (UVG-DL) (Rambow, 1994). The presentations will be informal for reasons of space; we refer to (Rambow and Satta, 1996) for details. In UVG-DL, several context-free string rewriting rules are grouped into sets, called vectors. In a derivation, all or no rules from a given in</context>
</contexts>
<marker>Becker, Rambow, Niv, 1992</marker>
<rawString>Becker, Tilman, Owen Rambow, and Michael Niv. 1992. The derivational generative power, or, scrambling is beyond LCFRS. Technical Report IRCS-92-38, Institute for Research in Cognitive Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bresnan</author>
<author>R Kaplan</author>
</authors>
<title>Lexical-functional grammar: A formal system for grammatical representation.</title>
<date>1982</date>
<editor>In J. Bresnan, editor,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="1061" citStr="Bresnan and Kaplan, 1982" startWordPosition="153" endWordPosition="156">synchronous rewriting system and argue that it can handle certain phenomena that are not covered by existing synchronous systems. We also prove some interesting formal/computational properties of our system. 1 Introduction Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences (translations) between layers of representation; for example, related interface layers LF and PF in GB and Minimalism (Chomsky, 1993), semantic and syntactic information in HPSG (Pollard and Sag, 1994), or the different structures such as c-structure and f-structure in LFG (Bresnan and Kaplan, 1982). Similarly, many problems in natural language processing, in particular parsing and generation, can be expressed as transductions, which are calculations of such correspondences. There is therefore a great need for formal models of corresponding levels of representation, and for corresponding algorithms for transduction. Several different transduction systems have been used in the past by the computational and theoretical linguistics communities. These systems have been borrowed from translation theory, a subfield of formal language theory, or have been originally (and sometimes redundantly) </context>
</contexts>
<marker>Bresnan, Kaplan, 1982</marker>
<rawString>Bresnan, J. and R. Kaplan. 1982. Lexical-functional grammar: A formal system for grammatical representation. In J. Bresnan, editor, The Mental Representation of Grammatical Relations. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
</authors>
<title>A minimalist program for linguistic theory.</title>
<date>1993</date>
<booktitle>The View from Building 20.</booktitle>
<pages>1--52</pages>
<editor>In Kenneth Hale and Samuel J. Keyser, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Mass.,</location>
<contexts>
<context position="894" citStr="Chomsky, 1993" startWordPosition="130" endWordPosition="131">nchronous rewriting, the productions of two rewriting systems are paired and applied synchronously in the derivation of a pair of strings. We present a new synchronous rewriting system and argue that it can handle certain phenomena that are not covered by existing synchronous systems. We also prove some interesting formal/computational properties of our system. 1 Introduction Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences (translations) between layers of representation; for example, related interface layers LF and PF in GB and Minimalism (Chomsky, 1993), semantic and syntactic information in HPSG (Pollard and Sag, 1994), or the different structures such as c-structure and f-structure in LFG (Bresnan and Kaplan, 1982). Similarly, many problems in natural language processing, in particular parsing and generation, can be expressed as transductions, which are calculations of such correspondences. There is therefore a great need for formal models of corresponding levels of representation, and for corresponding algorithms for transduction. Several different transduction systems have been used in the past by the computational and theoretical lingui</context>
</contexts>
<marker>Chomsky, 1993</marker>
<rawString>Chomsky, Noam. 1993. A minimalist program for linguistic theory. In Kenneth Hale and Samuel J. Keyser, editors, The View from Building 20. MIT Press, Cambridge, Mass., pages 1-52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dana Egedi</author>
<author>Martha Palmer</author>
</authors>
<title>Constraining lexical selection across languages using TAG.</title>
<date>1994</date>
<booktitle>In 3e Colloque International sur les Grammaires d&apos;Arbres Adjoints (TA G+3), Rapport Technique TALANA-RT-94-01. Universite Paris 7.</booktitle>
<contexts>
<context position="2731" citStr="Egedi and Palmer, 1994" startWordPosition="394" endWordPosition="397">(SDTS) (Aho and Ullman, 1969) translate between contextfree languages and are therefore more powerful than finite state transducers. Pushdown transducers are a standard model for parsing, and have also been used (usually implicitly) in speech understanding. Recently, variants of SDTS have been proposed as models for simultaneously bracketing parallel corpora (Wu, 1995). Synchronization of tree adjoining grammars (TAGs) (Shieber and Schabes, 1990; Shieber, 1994) are even more powerful than the previous formalisms, and have been applied in machine translation (Abellle, Schabes, and Joshi, 1990; Egedi and Palmer, 1994; Harbusch and Poller, 1994; Prigent, 1994), natural language generation (Shieber and Schabes, 1991), and theoretical syntax (Abeille, 1994). The common underlying idea in all of these formalisms is to combine two generative devices through a pairing of their productions (or, in the case of the corresponding automata, of their transitions) in such a way that right-hand side nonterminal symbols in the paired productions are linked. The processes of derivation proceed synchronously in the two devices by applying the paired grammar rules only to linked nonterminals introduced previously in the de</context>
</contexts>
<marker>Egedi, Palmer, 1994</marker>
<rawString>Egedi, Dana and Martha Palmer. 1994. Constraining lexical selection across languages using TAG. In 3e Colloque International sur les Grammaires d&apos;Arbres Adjoints (TA G+3), Rapport Technique TALANA-RT-94-01. Universite Paris 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maurice Gross</author>
</authors>
<title>The use of Finite-State Automata in the lexical representation of natural language.</title>
<date>1989</date>
<booktitle>Electronic Dictionaries and Automata in Computational Linguistics.</booktitle>
<editor>In M. Gross and D. Perrin, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="2015" citStr="Gross, 1989" startWordPosition="292" endWordPosition="293">ransduction systems have been used in the past by the computational and theoretical linguistics communities. These systems have been borrowed from translation theory, a subfield of formal language theory, or have been originally (and sometimes redundantly) developed. Finite state transducers (for an overview, see, e.g., (Aho and Ullman, 1972)) provide translations between regular languages. These devices have been popular in computational morphology and computational phonology since the early eighties (Koskenniemi, 1983; Kaplan and Kay, 1994), and more recently in parsing as well (see, e.g., (Gross, 1989; Pereira, 1991; Roche, 1993)). Pushdown transducers and syntax directed translation schemata (SDTS) (Aho and Ullman, 1969) translate between contextfree languages and are therefore more powerful than finite state transducers. Pushdown transducers are a standard model for parsing, and have also been used (usually implicitly) in speech understanding. Recently, variants of SDTS have been proposed as models for simultaneously bracketing parallel corpora (Wu, 1995). Synchronization of tree adjoining grammars (TAGs) (Shieber and Schabes, 1990; Shieber, 1994) are even more powerful than the previous</context>
</contexts>
<marker>Gross, 1989</marker>
<rawString>Gross, Maurice. 1989. The use of Finite-State Automata in the lexical representation of natural language. In M. Gross and D. Perrin, editors, Electronic Dictionaries and Automata in Computational Linguistics. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Harbusch</author>
<author>Peter Poller</author>
</authors>
<title>Structural rewriting with synchronous rewriting systems.</title>
<date>1994</date>
<booktitle>In 3e Colloque International sur les Grammaires d&apos;Arbres Adjoints (TAG+3), Rapport Technique TALANA-RT-94-01. Universite Paris 7.</booktitle>
<contexts>
<context position="2758" citStr="Harbusch and Poller, 1994" startWordPosition="398" endWordPosition="401">1969) translate between contextfree languages and are therefore more powerful than finite state transducers. Pushdown transducers are a standard model for parsing, and have also been used (usually implicitly) in speech understanding. Recently, variants of SDTS have been proposed as models for simultaneously bracketing parallel corpora (Wu, 1995). Synchronization of tree adjoining grammars (TAGs) (Shieber and Schabes, 1990; Shieber, 1994) are even more powerful than the previous formalisms, and have been applied in machine translation (Abellle, Schabes, and Joshi, 1990; Egedi and Palmer, 1994; Harbusch and Poller, 1994; Prigent, 1994), natural language generation (Shieber and Schabes, 1991), and theoretical syntax (Abeille, 1994). The common underlying idea in all of these formalisms is to combine two generative devices through a pairing of their productions (or, in the case of the corresponding automata, of their transitions) in such a way that right-hand side nonterminal symbols in the paired productions are linked. The processes of derivation proceed synchronously in the two devices by applying the paired grammar rules only to linked nonterminals introduced previously in the derivation. The fact that the</context>
</contexts>
<marker>Harbusch, Poller, 1994</marker>
<rawString>Harbusch, Karin and Peter Poller. 1994. Structural rewriting with synchronous rewriting systems. In 3e Colloque International sur les Grammaires d&apos;Arbres Adjoints (TAG+3), Rapport Technique TALANA-RT-94-01. Universite Paris 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
<author>Martin Kay</author>
</authors>
<title>Regular models of phonological rule systems.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--3</pages>
<contexts>
<context position="1952" citStr="Kaplan and Kay, 1994" startWordPosition="278" endWordPosition="281">n, and for corresponding algorithms for transduction. Several different transduction systems have been used in the past by the computational and theoretical linguistics communities. These systems have been borrowed from translation theory, a subfield of formal language theory, or have been originally (and sometimes redundantly) developed. Finite state transducers (for an overview, see, e.g., (Aho and Ullman, 1972)) provide translations between regular languages. These devices have been popular in computational morphology and computational phonology since the early eighties (Koskenniemi, 1983; Kaplan and Kay, 1994), and more recently in parsing as well (see, e.g., (Gross, 1989; Pereira, 1991; Roche, 1993)). Pushdown transducers and syntax directed translation schemata (SDTS) (Aho and Ullman, 1969) translate between contextfree languages and are therefore more powerful than finite state transducers. Pushdown transducers are a standard model for parsing, and have also been used (usually implicitly) in speech understanding. Recently, variants of SDTS have been proposed as models for simultaneously bracketing parallel corpora (Wu, 1995). Synchronization of tree adjoining grammars (TAGs) (Shieber and Schabes</context>
</contexts>
<marker>Kaplan, Kay, 1994</marker>
<rawString>Kaplan, Ronald M. and Martin Kay. 1994. Regular models of phonological rule systems. Computational Linguistics, 20(3):331-378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kimmo Koskenniemi</author>
</authors>
<title>Two-level morphology: A general computational model for wordform recognition and production.</title>
<date>1983</date>
<tech>Technical Report 11,</tech>
<institution>Department of General Linguistics, University of Helsinki.</institution>
<contexts>
<context position="1929" citStr="Koskenniemi, 1983" startWordPosition="275" endWordPosition="277">ls of representation, and for corresponding algorithms for transduction. Several different transduction systems have been used in the past by the computational and theoretical linguistics communities. These systems have been borrowed from translation theory, a subfield of formal language theory, or have been originally (and sometimes redundantly) developed. Finite state transducers (for an overview, see, e.g., (Aho and Ullman, 1972)) provide translations between regular languages. These devices have been popular in computational morphology and computational phonology since the early eighties (Koskenniemi, 1983; Kaplan and Kay, 1994), and more recently in parsing as well (see, e.g., (Gross, 1989; Pereira, 1991; Roche, 1993)). Pushdown transducers and syntax directed translation schemata (SDTS) (Aho and Ullman, 1969) translate between contextfree languages and are therefore more powerful than finite state transducers. Pushdown transducers are a standard model for parsing, and have also been used (usually implicitly) in speech understanding. Recently, variants of SDTS have been proposed as models for simultaneously bracketing parallel corpora (Wu, 1995). Synchronization of tree adjoining grammars (TAG</context>
</contexts>
<marker>Koskenniemi, 1983</marker>
<rawString>Koskenniemi, Kimmo. 1983. Two-level morphology: A general computational model for wordform recognition and production. Technical Report 11, Department of General Linguistics, University of Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Lang</author>
</authors>
<title>Towards a uniform formal framework for parsing.</title>
<date>1991</date>
<booktitle>Current Issues in Parsing technology. Kluwer Academic Publishers, chapter 11,</booktitle>
<pages>153--171</pages>
<editor>In M. Tomita, editor,</editor>
<contexts>
<context position="21049" citStr="Lang, 1991" startWordPosition="3486" endWordPosition="3487">n for sets of derivation trees in a UVG-DL G. A parse tree in G is an ordered tree representing a derivation in G and encoding at each node the production p used to start the corresponding subderivation and the multiset of productions f used in that subderivation. A INP /some official exists y, F* y an official â€¢ â€¢ NP VP thinks NP VP said .--â€¢â– â€¢â€¢â€¢â€¢â€¢â€¢â€¢ exists y, F. y an official â€¢ for all x, x a man think T F I NP VP say T F exists z, z a Norwegian exists z, F* z a Norwegian 121 parse forest in G is a directed acyclic graph which is ordered and bipartite. (We use ideas originally developed in (Lang, 1991) for the context-free case.) Nodes of the graph are of two different types, called and-nodes and or-nodes, respectively, and each directed arc connects nodes of different types. A parse forest in G represents a set T of parse trees in G if the following holds. When starting at a root node and walking through the graph, if we follow exactly one of the outgoing arcs at each or-node, and all of the outgoing arcs at each and-node, we obtain a tree in T modulo the removal of the or-nodes. Furthermore, every tree in T can be obtained in this way. Lemma 2 Let G be a UVG-DL and let q &gt; 1 be a natural </context>
</contexts>
<marker>Lang, 1991</marker>
<rawString>Lang, B. 1991. Towards a uniform formal framework for parsing. In M. Tomita, editor, Current Issues in Parsing technology. Kluwer Academic Publishers, chapter 11, pages 153-171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert May</author>
</authors>
<title>Logical Form: Its structure and Derivation.</title>
<date>1985</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Mass.</location>
<contexts>
<context position="5587" citStr="May, 1985" startWordPosition="841" endWordPosition="842"> some new formal results. We introduce our new synchronous system in Section 3, and present our formal results and outline the proof techniques in Section 4. 2 Types of Synchronization 2.1 Quantifier Raising We start by presenting an example which is based on transfer between a syntactic representation and a &amp;quot;semantic&amp;quot; representation of the scoping of quantified NPs. It is generally assumed that in English (and many other languages), quantified arguments of a verb can (in appropriate contexts) take scope in any possible order, and that this generalization extends to cases of embedded clauses (May, 1985).1 For example, sentence (1) can have four possible interpretations (of the six possible orderings of the quantifiers, two pairs are logically equivalent), two of which are shown in (2). (1) Every man thinks some official said some Norwegian arrived (2) a. Vx, x a man, 3y, y an official, 3z, z a Norwegian, x thinks y said z arrived b. 3z, z a Norwegian, 3y, y an official, Vx, x a man, x thinks y said z arrived &apos;We explicitly exclude from our analysis cases of quantified NPs embedded in NPs, and do not, of course, propose to develop a serious linguistic theory of quantifier scoping. We give a s</context>
</contexts>
<marker>May, 1985</marker>
<rawString>May, Robert. 1985. Logical Form: Its structure and Derivation. MIT Press, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
</authors>
<title>Finite-state approximation of phrase structure grammars.</title>
<date>1991</date>
<booktitle>In 29th Meeting of the Association for Computational Linguistics (ACL &apos;91),</booktitle>
<publisher>ACL.</publisher>
<location>Berkeley, California.</location>
<contexts>
<context position="2030" citStr="Pereira, 1991" startWordPosition="294" endWordPosition="295">ystems have been used in the past by the computational and theoretical linguistics communities. These systems have been borrowed from translation theory, a subfield of formal language theory, or have been originally (and sometimes redundantly) developed. Finite state transducers (for an overview, see, e.g., (Aho and Ullman, 1972)) provide translations between regular languages. These devices have been popular in computational morphology and computational phonology since the early eighties (Koskenniemi, 1983; Kaplan and Kay, 1994), and more recently in parsing as well (see, e.g., (Gross, 1989; Pereira, 1991; Roche, 1993)). Pushdown transducers and syntax directed translation schemata (SDTS) (Aho and Ullman, 1969) translate between contextfree languages and are therefore more powerful than finite state transducers. Pushdown transducers are a standard model for parsing, and have also been used (usually implicitly) in speech understanding. Recently, variants of SDTS have been proposed as models for simultaneously bracketing parallel corpora (Wu, 1995). Synchronization of tree adjoining grammars (TAGs) (Shieber and Schabes, 1990; Shieber, 1994) are even more powerful than the previous formalisms, an</context>
</contexts>
<marker>Pereira, 1991</marker>
<rawString>Pereira, Fernando. 1991. Finite-state approximation of phrase structure grammars. In 29th Meeting of the Association for Computational Linguistics (ACL &apos;91), Berkeley, California. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan Sag</author>
</authors>
<title>HeadDriven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="962" citStr="Pollard and Sag, 1994" startWordPosition="138" endWordPosition="141">s are paired and applied synchronously in the derivation of a pair of strings. We present a new synchronous rewriting system and argue that it can handle certain phenomena that are not covered by existing synchronous systems. We also prove some interesting formal/computational properties of our system. 1 Introduction Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences (translations) between layers of representation; for example, related interface layers LF and PF in GB and Minimalism (Chomsky, 1993), semantic and syntactic information in HPSG (Pollard and Sag, 1994), or the different structures such as c-structure and f-structure in LFG (Bresnan and Kaplan, 1982). Similarly, many problems in natural language processing, in particular parsing and generation, can be expressed as transductions, which are calculations of such correspondences. There is therefore a great need for formal models of corresponding levels of representation, and for corresponding algorithms for transduction. Several different transduction systems have been used in the past by the computational and theoretical linguistics communities. These systems have been borrowed from translation</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Pollard, Carl and Ivan Sag. 1994. HeadDriven Phrase Structure Grammar. University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gilles Prigent</author>
</authors>
<title>Synchronous tags and machine translation.</title>
<date>1994</date>
<booktitle>In 3e Colloque International sur les Grammaires d&apos;Arbres Adjoints (TAG+3), Rapport Technique TALANA-RT-94-01. Universite Paris 7.</booktitle>
<contexts>
<context position="2774" citStr="Prigent, 1994" startWordPosition="402" endWordPosition="404">textfree languages and are therefore more powerful than finite state transducers. Pushdown transducers are a standard model for parsing, and have also been used (usually implicitly) in speech understanding. Recently, variants of SDTS have been proposed as models for simultaneously bracketing parallel corpora (Wu, 1995). Synchronization of tree adjoining grammars (TAGs) (Shieber and Schabes, 1990; Shieber, 1994) are even more powerful than the previous formalisms, and have been applied in machine translation (Abellle, Schabes, and Joshi, 1990; Egedi and Palmer, 1994; Harbusch and Poller, 1994; Prigent, 1994), natural language generation (Shieber and Schabes, 1991), and theoretical syntax (Abeille, 1994). The common underlying idea in all of these formalisms is to combine two generative devices through a pairing of their productions (or, in the case of the corresponding automata, of their transitions) in such a way that right-hand side nonterminal symbols in the paired productions are linked. The processes of derivation proceed synchronously in the two devices by applying the paired grammar rules only to linked nonterminals introduced previously in the derivation. The fact that the above systems a</context>
</contexts>
<marker>Prigent, 1994</marker>
<rawString>Prigent, Gilles. 1994. Synchronous tags and machine translation. In 3e Colloque International sur les Grammaires d&apos;Arbres Adjoints (TAG+3), Rapport Technique TALANA-RT-94-01. Universite Paris 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Owen Rambow</author>
</authors>
<title>Multiset-valued linear index grammars.</title>
<date>1994</date>
<booktitle>In 32nd Meeting of the Association for Computational Linguistics (ACL&apos;94).</booktitle>
<publisher>ACL.</publisher>
<contexts>
<context position="4116" citStr="Rambow, 1994" startWordPosition="607" endWordPosition="608">Shieber and Schabes, 1990) we will refer to the general approach as synchronous rewriting. While synchronous systems are becoming more and more popular, surprisingly little is known about the formal characteristics of these systems (with the exception of the finite-state devices). In this paper, we argue that existing synchronous systems cannot handle, in a computationally attrac116 tive way, a standard problem in syntax/semantics translation, namely quantifier scoping. We propose a new system that provides a synchronization between two unordered vector grammars with dominance links (UVG-DL) (Rambow, 1994). The type of synchronization is closely based on a previously proposed model, which we will call &amp;quot;local&amp;quot; synchronization. We argue that this synchronous system can deal with quantifier scoping in the desired way. The proposed system has the weak language preservation property, that is, the defined synchronization mechanism does not alter the weak generative capacity of the formalism being synchronized. Furthermore, the tree-to-forest translation problem for our system can be solved in polynomial time; that is, given a derivation tree obtained according to one of the synchronized grammars, we </context>
<context position="10823" citStr="Rambow, 1994" startWordPosition="1742" endWordPosition="1743"> each tree in the input grammar is associated with only one output grammar tree). However, SynchTAG cannot derive all possible scope orderings, because of the locality restriction. This can be shown by adapting the proof technique in (Becker, Rambow, and Niv, 1992). In the following section, we will present a synchronous system which has local synchronization&apos;s formal advantages, but handles the scoping data. 3 Extended Local Synchronization In this section, we propose a new synchronous system, which is based on local synchronization of unordered vector grammars with dominance links (UVG-DL) (Rambow, 1994). The presentations will be informal for reasons of space; we refer to (Rambow and Satta, 1996) for details. In UVG-DL, several context-free string rewriting rules are grouped into sets, called vectors. In a derivation, all or no rules from a given instance of a vector must be used. Put differently, all productions from a given vector must be used the same number of times. They can be applied in any order and need not be applied simultaneously or one right after the other. In addition, UVG-DL has dominance links. An occurrence of a nonterminal A in the right-hand side of a rule p can be linked</context>
</contexts>
<marker>Rambow, 1994</marker>
<rawString>Rambow, Owen. 1994. Multiset-valued linear index grammars. In 32nd Meeting of the Association for Computational Linguistics (ACL&apos;94). ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Owen Rambow</author>
<author>Giorgio Satta</author>
</authors>
<title>Synchronous models of language. Manuscript under preparation.</title>
<date>1996</date>
<contexts>
<context position="8272" citStr="Rambow and Satta, 1996" startWordPosition="1318" endWordPosition="1321">ier and the variable. The derivation proceeds as illustrated in Figure 4, finally yielding the two structures in Figure 1 and Figure 2. Note that some of the links originating with the NP nodes are inherited during the derivation. By changing the order in which we add the nominal arguments at the end of the derivation, we can obtain all quantifier scopes in the semantics. The problem with non-local synchronization is that the weak language preservation property does not hold. (Shieber, 1994) shows that not all n1SynchTAG left-projection languages can be generated by TAGs. As a new result, in (Rambow and Satta, 1996) we show that the recognition of some fixed left-projection languages of a n1SynchTAG is NP-complete. Our reduction crucially relies on link inheritance. This makes n1SynchTAG unattractive for applications in theoretical or computational linguistics. 2.3 Local Synchronous Systems In contrast with non-local synchronization, in local synchronization there is no inheritance of synchronization links. This is enforced by requiring that the links establish a bijection between nonterminals in the two synchronously derived sentential forms, that is, each nonterminal must be involved in exactly one lin</context>
<context position="10918" citStr="Rambow and Satta, 1996" startWordPosition="1756" endWordPosition="1760">ever, SynchTAG cannot derive all possible scope orderings, because of the locality restriction. This can be shown by adapting the proof technique in (Becker, Rambow, and Niv, 1992). In the following section, we will present a synchronous system which has local synchronization&apos;s formal advantages, but handles the scoping data. 3 Extended Local Synchronization In this section, we propose a new synchronous system, which is based on local synchronization of unordered vector grammars with dominance links (UVG-DL) (Rambow, 1994). The presentations will be informal for reasons of space; we refer to (Rambow and Satta, 1996) for details. In UVG-DL, several context-free string rewriting rules are grouped into sets, called vectors. In a derivation, all or no rules from a given instance of a vector must be used. Put differently, all productions from a given vector must be used the same number of times. They can be applied in any order and need not be applied simultaneously or one right after the other. In addition, UVG-DL has dominance links. An occurrence of a nonterminal A in the right-hand side of a rule p can be linked to the left-hand nonterminal of another rule p&apos; in the same vector. This dominance link will a</context>
</contexts>
<marker>Rambow, Satta, 1996</marker>
<rawString>Rambow, Owen and Giorgio Satta. 1996. Synchronous models of language. Manuscript under preparation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Owen Rambow</author>
<author>K Vijay-Shanker</author>
<author>David Weir</author>
</authors>
<title>D-Tree Grammars.</title>
<date>1995</date>
<booktitle>In 33rd Meeting of the Association for Computational Linguistics (ACL&apos;95).</booktitle>
<publisher>ACL.</publisher>
<contexts>
<context position="16667" citStr="Rambow, Vijay-Shanker, and Weir, 1995" startWordPosition="2703" endWordPosition="2707">c). The vector derivation tree can be seen as representing an &amp;quot;outline&amp;quot; for the derivation. Such a view is attractive from a linguistic perspective: if each vector represents a lexeme and its projection (where the synchronous production is the basis of the lexical projection that the vector represents), then the vector derivation tree is in fact the dependency tree of the sentence (representing direct relations between lexemes such as grammatical function). In this respect, the vector derivation tree of UVG-DL is like the derivation tree of tree adjoining grammar and of D-tree grammars (DTG) (Rambow, Vijay-Shanker, and Weir, 1995), which is not surprising, since all three formalisms share the same extended domain of locality. Furthermore, the vector derivation tree of SynchUVG-DL shares with the the derivation tree of DTG the property that it reflects linguistic dependency uniformly; however, while the definition of DTG was motivated precisely from considerations of dependency, the vector derivation tree is merely a by-product of our definition of SynchUVG-DL, which was motivated from the desire to have a computationally tractable model of synchronization more powerful than SynchTAG.2 We briefly discuss a sample deriv</context>
<context position="24839" citStr="Rambow, Vijay-Shanker, and Weir, 1995" startWordPosition="4204" endWordPosition="4208"> it follows that irq can be processed in time polynomial in the size of T. Finally, we obtain 7r simply by removing from irq all nodes that have been blocked. â€¢ 5 Conclusion We have presented SynchUVG-DL, a synchronous system which has restricted formal power, is computationally tractable, and which handles the quantifier-raising data. In addition, SynchUVG-DL can be used for modeling the syntax of languages with syntactic constructions which have been argued to be beyond the formal power of TAG, such as scrambling in German and many other languages (Rainbow, 1994) or wh-movement in Kashmiri (Rambow, Vijay-Shanker, and Weir, 1995). SynchUVG-DL can be used to synchronize a syntactic grammar for these languages either with a semantic grammar, or with the syntactic grammar of another language for machine translation applications. However, SynchUVG-DL cannot handle the list of cases listed in (Shieber, 1994). These pose a problem for SynchUVG-DL for the same reason that they pose a problem for other local synchronous systems: the (syntactic) dependency structures represented by the two derivations are different. These cases remain an open research issue. Acknowledgments Parts of the present research were done while Rambow</context>
</contexts>
<marker>Rambow, Vijay-Shanker, Weir, 1995</marker>
<rawString>Rambow, Owen, K. Vijay-Shanker, and David Weir. 1995. D-Tree Grammars. In 33rd Meeting of the Association for Computational Linguistics (ACL&apos;95). ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emmanuel Roche</author>
</authors>
<title>Analyse syntaxique transformationelle du francais par transducteur et lexique-gramrnaire.</title>
<date>1993</date>
<booktitle>Ph.D. thesis, Universite Raris 7,</booktitle>
<location>Paris, France.</location>
<contexts>
<context position="2044" citStr="Roche, 1993" startWordPosition="296" endWordPosition="297">n used in the past by the computational and theoretical linguistics communities. These systems have been borrowed from translation theory, a subfield of formal language theory, or have been originally (and sometimes redundantly) developed. Finite state transducers (for an overview, see, e.g., (Aho and Ullman, 1972)) provide translations between regular languages. These devices have been popular in computational morphology and computational phonology since the early eighties (Koskenniemi, 1983; Kaplan and Kay, 1994), and more recently in parsing as well (see, e.g., (Gross, 1989; Pereira, 1991; Roche, 1993)). Pushdown transducers and syntax directed translation schemata (SDTS) (Aho and Ullman, 1969) translate between contextfree languages and are therefore more powerful than finite state transducers. Pushdown transducers are a standard model for parsing, and have also been used (usually implicitly) in speech understanding. Recently, variants of SDTS have been proposed as models for simultaneously bracketing parallel corpora (Wu, 1995). Synchronization of tree adjoining grammars (TAGs) (Shieber and Schabes, 1990; Shieber, 1994) are even more powerful than the previous formalisms, and have been ap</context>
</contexts>
<marker>Roche, 1993</marker>
<rawString>Roche, Emmanuel. 1993. Analyse syntaxique transformationelle du francais par transducteur et lexique-gramrnaire. Ph.D. thesis, Universite Raris 7, Paris, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
<author>Yves Schabes</author>
</authors>
<title>Synchronous tree adjoining grammars.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics,</booktitle>
<location>Helsinki.</location>
<contexts>
<context position="2558" citStr="Shieber and Schabes, 1990" startWordPosition="367" endWordPosition="370">plan and Kay, 1994), and more recently in parsing as well (see, e.g., (Gross, 1989; Pereira, 1991; Roche, 1993)). Pushdown transducers and syntax directed translation schemata (SDTS) (Aho and Ullman, 1969) translate between contextfree languages and are therefore more powerful than finite state transducers. Pushdown transducers are a standard model for parsing, and have also been used (usually implicitly) in speech understanding. Recently, variants of SDTS have been proposed as models for simultaneously bracketing parallel corpora (Wu, 1995). Synchronization of tree adjoining grammars (TAGs) (Shieber and Schabes, 1990; Shieber, 1994) are even more powerful than the previous formalisms, and have been applied in machine translation (Abellle, Schabes, and Joshi, 1990; Egedi and Palmer, 1994; Harbusch and Poller, 1994; Prigent, 1994), natural language generation (Shieber and Schabes, 1991), and theoretical syntax (Abeille, 1994). The common underlying idea in all of these formalisms is to combine two generative devices through a pairing of their productions (or, in the case of the corresponding automata, of their transitions) in such a way that right-hand side nonterminal symbols in the paired productions are </context>
<context position="6666" citStr="Shieber and Schabes, 1990" startWordPosition="1035" endWordPosition="1038">s cases of quantified NPs embedded in NPs, and do not, of course, propose to develop a serious linguistic theory of quantifier scoping. We give a simplified syntactic representation for (1) in Figure 1, and a simplified semantic representation for (2b) in Figure 2. every man VP thinks some official VP said some Norwegian arrived Figure 1: Syntactic representation for (1) exists z, z a Norwegian exists y, y an official for all x, x a man think T I say T I arrive Figure 2: Semantic representation for (2b) 2.2 Non-Local Synchronization We will first discuss a type of synchronization proposed by (Shieber and Schabes, 1990), based on TAG. We will refer to this system as non-local synchronous TAG (n1SynchTAG). The synchronization is non-local in the sense that once links are introduced during a derivation by a synchronized pair of grammar rules, they need not continue to impinge on the nodes that introduced them: the links may be reassigned to a newly introduced nonterminal when an original node is rewritten. We will refer to this mechanism as link inheritance. To illustrate, we will give as an example an analysis of the quantifier-raising example introduced above, extending in a natural manner an example given b</context>
</contexts>
<marker>Shieber, Schabes, 1990</marker>
<rawString>Shieber, Stuart and Yves Schabes. 1990. Synchronous tree adjoining grammars. In Proceedings of the 13th International Conference on Computational Linguistics, Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
<author>Yves Schabes</author>
</authors>
<title>Generation and synchronous tree adjoining grammars.</title>
<date>1991</date>
<journal>Computational Intelligence,</journal>
<pages>4--7</pages>
<contexts>
<context position="2831" citStr="Shieber and Schabes, 1991" startWordPosition="408" endWordPosition="411">erful than finite state transducers. Pushdown transducers are a standard model for parsing, and have also been used (usually implicitly) in speech understanding. Recently, variants of SDTS have been proposed as models for simultaneously bracketing parallel corpora (Wu, 1995). Synchronization of tree adjoining grammars (TAGs) (Shieber and Schabes, 1990; Shieber, 1994) are even more powerful than the previous formalisms, and have been applied in machine translation (Abellle, Schabes, and Joshi, 1990; Egedi and Palmer, 1994; Harbusch and Poller, 1994; Prigent, 1994), natural language generation (Shieber and Schabes, 1991), and theoretical syntax (Abeille, 1994). The common underlying idea in all of these formalisms is to combine two generative devices through a pairing of their productions (or, in the case of the corresponding automata, of their transitions) in such a way that right-hand side nonterminal symbols in the paired productions are linked. The processes of derivation proceed synchronously in the two devices by applying the paired grammar rules only to linked nonterminals introduced previously in the derivation. The fact that the above systems all reflect the same translation technique has not always </context>
</contexts>
<marker>Shieber, Schabes, 1991</marker>
<rawString>Shieber, Stuart and Yves Schabes. 1991. Generation and synchronous tree adjoining grammars. Computational Intelligence, 4(7):220-228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart B Shieber</author>
</authors>
<title>Restricting the weak generative capacity of Synchronous Tree Adjoining Grammar.</title>
<date>1994</date>
<journal>Computational Intelligence,</journal>
<pages>10--4</pages>
<contexts>
<context position="2574" citStr="Shieber, 1994" startWordPosition="371" endWordPosition="372">re recently in parsing as well (see, e.g., (Gross, 1989; Pereira, 1991; Roche, 1993)). Pushdown transducers and syntax directed translation schemata (SDTS) (Aho and Ullman, 1969) translate between contextfree languages and are therefore more powerful than finite state transducers. Pushdown transducers are a standard model for parsing, and have also been used (usually implicitly) in speech understanding. Recently, variants of SDTS have been proposed as models for simultaneously bracketing parallel corpora (Wu, 1995). Synchronization of tree adjoining grammars (TAGs) (Shieber and Schabes, 1990; Shieber, 1994) are even more powerful than the previous formalisms, and have been applied in machine translation (Abellle, Schabes, and Joshi, 1990; Egedi and Palmer, 1994; Harbusch and Poller, 1994; Prigent, 1994), natural language generation (Shieber and Schabes, 1991), and theoretical syntax (Abeille, 1994). The common underlying idea in all of these formalisms is to combine two generative devices through a pairing of their productions (or, in the case of the corresponding automata, of their transitions) in such a way that right-hand side nonterminal symbols in the paired productions are linked. The proc</context>
<context position="8145" citStr="Shieber, 1994" startWordPosition="1298" endWordPosition="1299">igure 3: Elementary structures in n1SynchTAG pairs of trees in the semantics, and are linked to two nodes, the quantifier and the variable. The derivation proceeds as illustrated in Figure 4, finally yielding the two structures in Figure 1 and Figure 2. Note that some of the links originating with the NP nodes are inherited during the derivation. By changing the order in which we add the nominal arguments at the end of the derivation, we can obtain all quantifier scopes in the semantics. The problem with non-local synchronization is that the weak language preservation property does not hold. (Shieber, 1994) shows that not all n1SynchTAG left-projection languages can be generated by TAGs. As a new result, in (Rambow and Satta, 1996) we show that the recognition of some fixed left-projection languages of a n1SynchTAG is NP-complete. Our reduction crucially relies on link inheritance. This makes n1SynchTAG unattractive for applications in theoretical or computational linguistics. 2.3 Local Synchronous Systems In contrast with non-local synchronization, in local synchronization there is no inheritance of synchronization links. This is enforced by requiring that the links establish a bijection betwee</context>
<context position="9565" citStr="Shieber, 1994" startWordPosition="1521" endWordPosition="1522">ir of rules to two Figure 4: Non-local derivation in n1SynchTAG linked nonterminals, no additional link remains to be transferred to the newly introduced nonterminals. As a consequence of this, the derivation structures in the left and right grammars are always isomorphic (up to ordering and labeling of nodes). The canonical example of local synchronization is SDTS (Aho and Ullman, 1969), in which two context-free grammars are synchronized. We give an example of an SDTS and a derivation in Figure 5. The links are indicated as boxed numbers to the right of the nonterminal to which they apply. (Shieber, 1994) defines the tree-rewriting version of SDTS, which we will call synchronous TAG (SynchTAG), and argues that SynchTAG does not have the formal problems of n1SynchTAG (though VP NP VP I every man thinks NP says tor all x, x a man think T F I /1 say T F arrive NP VP arrives 1 1 8 Grammar: NP13 likes NP NPEI plait a NP SU -+ NPU --+ John NP11:1 -4 Jean NPEI -Ã· the white NE NPO â€”&gt; la N111 blanche 13 house --+ maison Derivation: (S o , SE]) (N1313 likes NP , N .(NP likes the white NPEI) (John likes the white plait a Jean) Figure 5: Sample SDTS and derivation (Shieber, 1994) studies the translation p</context>
<context position="25119" citStr="Shieber, 1994" startWordPosition="4251" endWordPosition="4252">ndles the quantifier-raising data. In addition, SynchUVG-DL can be used for modeling the syntax of languages with syntactic constructions which have been argued to be beyond the formal power of TAG, such as scrambling in German and many other languages (Rainbow, 1994) or wh-movement in Kashmiri (Rambow, Vijay-Shanker, and Weir, 1995). SynchUVG-DL can be used to synchronize a syntactic grammar for these languages either with a semantic grammar, or with the syntactic grammar of another language for machine translation applications. However, SynchUVG-DL cannot handle the list of cases listed in (Shieber, 1994). These pose a problem for SynchUVG-DL for the same reason that they pose a problem for other local synchronous systems: the (syntactic) dependency structures represented by the two derivations are different. These cases remain an open research issue. Acknowledgments Parts of the present research were done while Rambow was supported by the North Atlantic Treaty Organization under a Grant awarded in 1993, while at TALANA, Universite Paris 7, and while Satta was visiting the Center for Language and Speech Processing, Johns Hopkins University, Baltimore, MD. References Abeille, Anne. 1994. Syntax</context>
</contexts>
<marker>Shieber, 1994</marker>
<rawString>Shieber, Stuart B. 1994. Restricting the weak generative capacity of Synchronous Tree Adjoining Grammar. Computational Intelligence, 10(4):371-385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delcai Wu</author>
</authors>
<title>An algorithm for simultaneously bracketing parallel texts by aligning words.</title>
<date>1995</date>
<booktitle>In 33rd Meeting of the Association for Computational Linguistics (ACL&apos;95).</booktitle>
<publisher>ACL.</publisher>
<contexts>
<context position="2480" citStr="Wu, 1995" startWordPosition="358" endWordPosition="359">onal phonology since the early eighties (Koskenniemi, 1983; Kaplan and Kay, 1994), and more recently in parsing as well (see, e.g., (Gross, 1989; Pereira, 1991; Roche, 1993)). Pushdown transducers and syntax directed translation schemata (SDTS) (Aho and Ullman, 1969) translate between contextfree languages and are therefore more powerful than finite state transducers. Pushdown transducers are a standard model for parsing, and have also been used (usually implicitly) in speech understanding. Recently, variants of SDTS have been proposed as models for simultaneously bracketing parallel corpora (Wu, 1995). Synchronization of tree adjoining grammars (TAGs) (Shieber and Schabes, 1990; Shieber, 1994) are even more powerful than the previous formalisms, and have been applied in machine translation (Abellle, Schabes, and Joshi, 1990; Egedi and Palmer, 1994; Harbusch and Poller, 1994; Prigent, 1994), natural language generation (Shieber and Schabes, 1991), and theoretical syntax (Abeille, 1994). The common underlying idea in all of these formalisms is to combine two generative devices through a pairing of their productions (or, in the case of the corresponding automata, of their transitions) in such</context>
</contexts>
<marker>Wu, 1995</marker>
<rawString>Wu, Delcai. 1995. An algorithm for simultaneously bracketing parallel texts by aligning words. In 33rd Meeting of the Association for Computational Linguistics (ACL&apos;95). ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>