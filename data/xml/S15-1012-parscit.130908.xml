<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.5877695">
Collective Document Classification with Implicit Inter-document Semantic
Relationships
</title>
<author confidence="0.988616">
Clinton Burford, Steven Bird and Timothy Baldwin
</author>
<affiliation confidence="0.998221">
Department of Computing and Information Systems
The University of Melbourne, VIC 3010, Australia
</affiliation>
<email confidence="0.995139">
clint@burford.co sbird@unimelb.edu.au tb@ldwin.net
</email>
<sectionHeader confidence="0.994725" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999329916666667">
This paper addresses the question of how doc-
ument classifiers can exploit implicit infor-
mation about document similarity to improve
document classifier accuracy. We infer doc-
ument similarity using simple n-gram over-
lap, and demonstrate that this improves over-
all document classification performance over
two datasets. As part of this, we find that
collective classification based on simple itera-
tive classifiers outperforms the more complex
and computationally-intensive dual classifier
approach.
</bodyText>
<sectionHeader confidence="0.998784" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999919411764706">
In machine learning, there is a rich tradition of re-
search into the two tasks of: (1) “point-wise” clas-
sification, where each instance is represented as an
independent instance, and the predictive model at-
tempts to learn a decision boundary to capture in-
stances of a given class; and (2) graphical learn-
ing and inference, where instances are connected in
a graph, and learning/inference take place relative
to the graph structure connecting those instances,
based primarily on either conditional dependence
(i.e. one event is dependent on the outcome of an-
other) or “homophily” (i.e. the tendency for con-
nected instances to share various properties).1 Var-
ious joint models that combine the two have also
been proposed, although in natural language pro-
cessing at least, these have focused largely on con-
ditional dependence, in the form of models such as
</bodyText>
<footnote confidence="0.963959333333333">
1In some tasks, it can also indicate heterophily, i.e. the ten-
dency for connected instances to have contrasting properties, as
we shall see for one of our two dataset.
</footnote>
<bodyText confidence="0.999758861111111">
hidden Markov models (Rabiner and Juang, 1986)
and conditional random fields (Lafferty et al., 2001),
where independent properties of words, e.g., are
combined with conditional dependencies based on
their context of use to jointly predict the senses of
all words in a given sentence (Ciaramita and John-
son, 2003; Johannsen et al., 2014).
This paper explores the utility of homophily
within joint models for document-level semantic
classification, focusing specifically on tasks which
are not associated with any explicit graph structure.
That is, we examine whether implicit semantic doc-
ument links can improve the results of a point-wise
(content-based) classification approach.
Explicit inter-document links have been variously
shown to improve document classifier performance,
based on information sources including hyperlinks
in web documents (Slattery and Craven, 1998; Oh et
al., 2000; Yang et al., 2002), direct name-references
in congressional debates (Thomas et al., 2006; Bur-
foot et al., 2011; Stoyanov and Eisner, 2012), ci-
tations in scientific papers (Giles et al., 1998; Lu
and Getoor, 2003; McDowell et al., 2007), and user
mentions or retweets in social media (Jiang et al.,
2011; Tan et al., 2011). However, document col-
lections often don’t contain explicit inter-document
links, limiting the practical usefulness of such meth-
ods. In this paper, we seek to expand the reach of
research which incorporates linking information, in
inducing implicit linking information between doc-
uments, and demonstrating that the resultant (noisy)
network structure improves document classification
accuracy.
The intuition underlying this work is that some
types of documents have features which are either
absent or ambiguous in training data, but which have
</bodyText>
<page confidence="0.974928">
106
</page>
<note confidence="0.953293">
Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics (*SEM 2015), pages 106–116,
Denver, Colorado, June 4–5, 2015.
</note>
<bodyText confidence="0.999956896551724">
the special characteristic of indicating relationships
between the labels of documents. Most often, an
inter-document relationship indicates that two doc-
uments have the same label, but depending of the
task, it may also indicate that they have different la-
bels. In either case, classifiers gain an advantage if
they can consider these features as well as conven-
tional content-based features.
The major contribution of this paper is in show-
ing that document classification accuracy can be im-
proved over a range of datasets using automatically-
induced implicit semantic inter-document links, us-
ing collective classification. We are the first to
achieve this using a general-purpose setup, as ap-
plied to a range of datasets. Our results are achieved
using n-gram overlap features for both the CON-
VOTE and BITTERLEMONS corpora, without the use
of annotations for explicit semantic inter-document
relationships. A second contribution of this work
is the finding that simple iterative classifiers outper-
form more complex dual classifiers when using im-
plicit inter-document links. This finding contradicts
earlier work using explicit document links, where
the dual classifier approach has generally been found
to perform best (Thomas et al., 2006; Burfoot et al.,
2011). While the work presented here is concep-
tually quite simple, the findings are significant and
potentially open the door to accuracy improvements
on a range of document-level semantic tasks.
</bodyText>
<sectionHeader confidence="0.999372" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.831610666666667">
Previous work has dealt with the question of col-
lective document classification using implicit inter-
document relationships in two basic ways:
</bodyText>
<listItem confidence="0.996295111111111">
1. proximity: use a spatial or temporal dimension
of the domain to relate documents (Agrawal et
al., 2003; Goldberg et al., 2007; McDowell et
al., 2009; Somasundaran et al., 2009).
2. similarity: relate documents via some notion
of their content-based similarity (Blum and
Chawla, 2001; Joachims, 2003; Takamura et
al., 2007; Sindhwani and Melville, 2008; Jur-
gens, 2013)
</listItem>
<bodyText confidence="0.99989">
The work using similarity-based links is the clos-
est to ours but is also strongly differentiated because
it focuses on transductive semi-supervised classifi-
cation. That task begins with the premise that only
a small amount of labelled training data is avail-
able, so content-only classification is likely to be
inaccurate. By contrast, the supervised techniques
in this paper deal with large amounts of labelled
training data and relatively high content-only perfor-
mance – 76% for CONVOTE and 87% for BITTER-
LEMONS. It is reasonable to assume that the types of
similarity-based relationships derived for transduc-
tive semi-supervised classification would be ineffec-
tive in a supervised context.
This conclusion is supported by an experiment
that shows that the vocabularies of document pairs
tend to overlap to similar degrees regardless of doc-
ument class (Pang and Lee, 2005).
</bodyText>
<sectionHeader confidence="0.997734" genericHeader="method">
3 Corpora
</sectionHeader>
<bodyText confidence="0.999980333333334">
We experiment with two corpora in this research:
CONVOTE and BITTERLEMONS. These two are se-
lected on the grounds that they satisfy two intuitive
criteria about types of text collections that may con-
tain features that are not useful for content-only clas-
sification, but which may indicate relationships be-
tween pairs of documents: (1) the corpora both use
an unconstrained prose vocabulary, which increases
the likelihood that authors will use distinctive words
or sequences of words that are not frequent enough
to be useful in training, but which can be used to se-
mantically relate pairs of documents (c.f. newswire
articles); and (2) the majority of the text content in
both corpora is clearly relevant to the dimension of
classification, i.e. there is minimal use of “boiler-
plate” or “background” material, so the pool from
which to select task-relevant content to form inter-
document semantic relationships is larger.
</bodyText>
<subsectionHeader confidence="0.985123">
3.1 CONVOTE
</subsectionHeader>
<bodyText confidence="0.997843111111111">
CONVOTE (Thomas et al., 2006) consists of US
congressional speeches relating to a specific bill or
resolution, and the ultimate vote of each speaker
(“for” or “against”). The document classifier uses
the text of each speech to predict the vote of the
speaker. Three modifications are made to the cor-
pus: (1) speeches by the same speaker are concate-
nated, to more naturally represent the requirement
that each speaker only has one vote; (2) we drop
</bodyText>
<page confidence="0.996817">
107
</page>
<table confidence="0.999494142857143">
Total
Tokens 1.2M
Speeches 1699
Debates 53
Average speakers/speeches per debate 32
Average tokens per speech 735
Proportion of FOR speeches 49%
</table>
<tableCaption confidence="0.998493">
Table 1: Corpus statistics for CONVOTE.
</tableCaption>
<table confidence="0.999779571428571">
Total
Tokens 0.5M
Articles 594
Topics 149
Average articles per topic 4
Average tokens per article 843
Percentage of ISRAELI speeches 50%
</table>
<tableCaption confidence="0.999756">
Table 2: Corpus statistics for BITTERLEMONS.
</tableCaption>
<bodyText confidence="0.999664615384615">
the fixed train, test, development set assignments
from the original dataset, and instead evaluate using
leave-one-out cross-validation over the 53 debates
contained in the dataset, to allow for a more statisti-
cally robust evaluation; and (3) we discard the man-
ually annotated inter-document relationships based
on references to speaker names, because implicit re-
lationships are the focus of this work.
Table 1 gives statistics for our rendering of CON-
VOTE. The identical figures for the average number
of speeches and speakers per debate reflect the fact
that each speaker now contributes only one unified
speech.
</bodyText>
<subsectionHeader confidence="0.966281">
3.2 BITTERLEMONS
</subsectionHeader>
<bodyText confidence="0.999955777777778">
BITTERLEMONS (Lin et al., 2006) is a collection of
articles on the Israeli–Arab conflict harvested from
the Bitterlemons website.2 In each weekly issue, the
editors contribute an article giving their perspectives
on some aspect of the conflict, and two guest authors
contribute articles, one from an Israeli perspective
and the other from a Palestinian perspective. Some-
times these guest contributions take the form of an
interview, in which case we remove the questions
(from the editors) and retain only the answers.
The statistics in Table 2 give a picture of the size
and structure of BITTERLEMONS.
In accordance with Lin et al. (2006), we experi-
ment with heldout evaluation, with all articles con-
tributed by the editors placed in the training set and
those contributed by the guests in the test set. This
allows the task to be framed as “perspective” classi-
fication, rather than author attribution, i.e. we are fo-
</bodyText>
<footnote confidence="0.846612">
2http:/www.bitterlemons.org/
</footnote>
<bodyText confidence="0.999392">
cused on the content of the contributions rather than
stylistic or biographical features that may identify
one editor or the other.
</bodyText>
<sectionHeader confidence="0.994235" genericHeader="method">
4 Implicit Inter-document Similarity
</sectionHeader>
<bodyText confidence="0.996259266666667">
To implement the hypothesis that documents that
use the same rare word or sequence of words are
more likely to carry the same label, we calculate
a cosine similarity metric between every pairing of
documents in a given corpus, using an idf-weighted
term vector used to represent document dz. The idf
weighting serves to emphasise terms that are rare
within the corpus, and de-emphasise terms that are
common. To further enhance this effect, we repre-
sent terms by existence-based rather than frequency-
based features.
An example of a (tokenised) high-idf sentence
pair from CONVOTE is (with the speaker, party affil-
iation and vote shown in each case, and the high-idf
token underlined):
</bodyText>
<listItem confidence="0.980421083333333">
(1) the president s top counselor dan bartlett said
this week that there is no magic wand to
reduce gas prices. [CROWLEY, JOE (D);
AGAINST]
(2) mr. chairman, yesterday the president said, i
wish i could simply wave a magic wand and
lower gas prices tomorrow. [EMANUEL,
RAHM (D); AGAINST]
An example for BITTERLEMONS is:
(3) Even if we /wanted/ to succumb to Israeli
pressure, it is impossible to make a Palestinian
teach his child that Jaffa or Haifa or Palestine
</listItem>
<page confidence="0.982069">
108
</page>
<figure confidence="0.993622">
Corpus
content
Overall
classifications
</figure>
<figureCaption confidence="0.999979">
Figure 1: Dual classifier with similarity-based links.
</figureCaption>
<bodyText confidence="0.949401111111111">
before 1948 was not his land. [AHMAD HARB
(GUEST); PALESTINIAN]
(4) This is being neglected and Sharon is having
his way in brutalizing the Palestinian people in
the hope that they will succumb and abandon
their rights. [HAIDAR ABDEL SHAFI
(GUEST); PALESTINIAN]
For other examples and more justification of this
methodology, see Burford (2013).
</bodyText>
<sectionHeader confidence="0.990167" genericHeader="method">
5 Collective Classification
</sectionHeader>
<bodyText confidence="0.9994655">
Two standard approaches to collective classification
are: (1) the dual classifier approach; and (2) the it-
erative classifier approach. We briefly review these
approaches below, but refer the reader to Sen et al.
(2008), McDowell et al. (2009) and Burford (2013)
for a more detailed methodological discussion.
</bodyText>
<subsectionHeader confidence="0.994437">
5.1 Dual Classifier Approach
</subsectionHeader>
<bodyText confidence="0.999947">
The dual classifier approach is made up of three
steps, as depicted in Figure 1:
</bodyText>
<listItem confidence="0.937399375">
1. Base classification: Produce base classifica-
tions using (1) a content-only classifier; and
(2) a relationship classifier. The content-
only classifier makes a binary prediction: FOR
and AGAINST for CONVOTE, and ISRAELI or
PALESTINIAN for BITTERLEMONS. The rela-
tionship classifier indicates the preference that
each document pair be SAME or not (SAME).
2. Normalisation: Normalise the scores, pro-
ducing values for the classification preference
functions, ψi, which can be input into a collec-
tive classification algorithm.
3. Decoding: Produce final classifications by op-
timally decoding the content-only and relation-
ship level preferences using a collective classi-
fication algorithm.
</listItem>
<subsubsectionHeader confidence="0.751691">
5.1.1 Base classification
</subsubsectionHeader>
<bodyText confidence="0.999973888888889">
For our content-only base classifier, we use the
same bag-of-words SVM with binary (existence-
based) unigram features as (Thomas et al., 2006).
This classifier has been shown to be the best bag-
of-words model for BITTERLEMONS (Beigman Kle-
banov et al., 2010). As our relationship base classi-
fier, we use the cosine similarity scores described
above, calculated using n-grams of several different
lengths.
</bodyText>
<subsubsectionHeader confidence="0.669432">
5.1.2 Normalisation
</subsubsectionHeader>
<bodyText confidence="0.999967647058823">
We use probabilistic SVM normalisation to con-
vert the signed decision-plane distance output by the
content-only classifier into the probability that the
instance is in the positive class (Platt, 1999).
For the relationship classifier, the technique used
to convert the cosine similarity score into a clas-
sification preference needs to fit complex criteria.
Preliminary experiments suggested that while the
very highest similarity scores are good indicators
of SAME relationships, classifier precision drops
quickly as recall increases. To avoid polluting
the classification graph with large numbers of low-
quality links, the normalisation method should in-
corporate a threshold that discards a significant pro-
portion of the test set pairs. We adopt the follow-
ing binning technique to convert the cosine similar-
ity score into a probability that the two instances are
</bodyText>
<figure confidence="0.996518608695652">
Binary unigram
content-only
vectors
Base classification:
linear kernel SVMs
tf.idf
weighted
vector pairs
Base classification:
cosine similarity
Content-only
classifications
Relationship
classifications
Normalisation:
probabilistic SVM
normalisation
Classification
preference values
Normalisation: bin-
ning
Decoding: minimum-cut, mean-field
or loopy belief propagation
</figure>
<page confidence="0.947936">
109
</page>
<equation confidence="0.9768028">
0.9 s(i, j) &gt; b1;
0.8 b2 &lt; s(i, j) &lt; b1;
0.7 b3 &lt; s(i, j) &lt; b2;
0.6 b4 &lt; s(i, j) &lt; b3;
0.5 s(i, j) &lt; b4;
</equation>
<bodyText confidence="0.999907545454545">
where ψij(l, l) represents the SAME preference (i.e.
the probability of i and j having the same label);
the values for b1, b2, b3, and b4 are derived by sort-
ing the relationships in the training data by similar-
ity score, and separating them into intervals holding
a proportion of SAME pairs equivalent to the nomi-
nated probability. This approach is similar to unsu-
pervised discretisation (Kotsiantis and Kanellopou-
los, 2006), except the intervals are arranged so that
the output categories have a probabilistic interpreta-
tion.
</bodyText>
<listItem confidence="0.48382325">
5.1.3 Decoding
Decoding is carried out using three techniques:
(1) loopy belief propagation (McDowell et al.,
2009); (2) mean-field; and (3) minimum-cut.
</listItem>
<subsectionHeader confidence="0.740022">
Loopy Belief Propagation
</subsectionHeader>
<bodyText confidence="0.998719">
Loopy belief propagation is a message passing al-
gorithm that can be expressed as:
</bodyText>
<equation confidence="0.9981945">
mi—,j(l) =
Xα
l&apos;EL ⎛ ⎞
⎝ψi(l&apos;)ψij(l&apos;, l) mk—,i(l&apos;) ⎠
kENinDU\{j1
Y
bi(l) = αψi(l) Y mk—,i(l)
kENinDU
</equation>
<bodyText confidence="0.9826949375">
where mi—,j is a message sent by document di to
document dj, and α is a normalization constant that
ensures that each message and each set of marginal
probabilities sum to 1. The message flow from di
to dj communicates the belief of di about the label
of dj. The algorithm proceeds by making each node
communicate with its neighbours until the messages
stabilise. The marginal probability is then derived
by calculating bi(l).
Loopy belief propagation was used in early col-
lective classification work (Taskar et al., 2002) and
has remained popular since (Sen et al., 2008; Mc-
Dowell et al., 2009; Stoyanov and Eisner, 2012).
Mean-field
Mean-field is an alternative message passing al-
gorithm, that can be expressed as:
</bodyText>
<equation confidence="0.993283666666667">
Y
bi(l) = αψi(l)
jENinD
</equation>
<bodyText confidence="0.9751555">
and is re-computed for each document until the
marginal probabilities stabilise.
Loopy belief propagation and mean-field have
both been justified as variational methods for
Markov random fields (Jordan et al., 1999; Weiss,
2001; Yedidia et al., 2005).
</bodyText>
<subsectionHeader confidence="0.775798">
Minimum Cut
</subsectionHeader>
<bodyText confidence="0.999877125">
The minimum-cut technique involves formulating
a binary collective classification task as a flow graph
and finding solutions using standard methods for
solving minimum-cut (maximum-flow) problems.
We use the method described by Blum and
Chawla (2001) in an in-sample setting, which is
equivalent to finding the optimal solution for the cost
function for labellings:
</bodyText>
<equation confidence="0.9924475">
cost(Y) = X Xwi(Yi) + wr(di, dj)
diED (di,dj)EE:Yi=,4Yj
</equation>
<sectionHeader confidence="0.3256" genericHeader="method">
5.1.4 Tuning
</sectionHeader>
<bodyText confidence="0.999535666666667">
The relative weights given to the content-only and
relational classifiers can be tuned as follows (for
CONVOTE, without loss of generality):
</bodyText>
<equation confidence="0.990323166666667">
ψ&apos;i(FOR) = ψi(FOR)+
min(0,γ)(ψi(FOR)−ψi(AGAINST))
2
ψ&apos;ij(FOR, FOR) = ψij(FOR, FOR)−
max(0,γ)(ψij(FOR,FOR)−ψij(FOR,AGAINST))
2
</equation>
<bodyText confidence="0.9152062">
where ψ&apos; i and ψ&apos;ij refer to the dampened versions of
the content-only and relationship preference func-
tions, respectively, γ is the dampening parameter
E [−1, 1], ψ&apos;i(AGAINST) = 1 − ψ&apos;i(FOR),
ψ&apos;ij(AGAINST, AGAINST) = ψ&apos;ij(FOR, FOR), and
ψ&apos;ij(FOR, AGAINST) =ψ&apos;ij(AGAINST, FOR) = 1 −
ψ&apos;ij(FOR, FOR).
This approach works by reducing the difference
between the preferences for the two classes (FOR or
AGAINST) by an amount that is proportional to the
</bodyText>
<figure confidence="0.974192545454545">
SAME: ⎧
ψij(l, l) = ⎨⎪⎪⎪⎪
⎪⎪⎪⎪⎩
l
(l&apos;)
ψi (l&apos;, l)
Y
l&apos;EL
110
Corpus
content
</figure>
<figureCaption confidence="0.998384">
Figure 2: Iterative classifier approach with
</figureCaption>
<bodyText confidence="0.975569736842105">
similarity-based relational features.
absolute value of the dampening parameter. If the
dampening parameter is &lt; 0, only the content-only
preferences will be dampened (giving more relative
weight to relationship preferences). If the dampen-
ing parameter is &gt; 0, only the relationship prefer-
ences will be dampened (giving more relative weight
to the content-only preferences).
For CONVOTE, the training fold is adapted for
tuning by use of 52-fold cross-validation, where
each of the 52 debates in the training fold is classi-
fied using all of the other debates as training data.
BITTERLEMONS does not have internal structure
within the training set, so it cannot be adapted in this
way. Instead, we use leave-one-out cross-validation
over the training set. Unfortunately this approach
carries the risk of producing base classifications that
are unrealistically accurate, because the training set
is composed of articles by only two authors.
</bodyText>
<subsectionHeader confidence="0.995048">
5.2 Iterative Classifier Approach
</subsectionHeader>
<bodyText confidence="0.688281888888889">
The iterative classifier approach has three major
components, as depicted in Figure 2:
1. Base classification. Produce base classifica-
tions using a content-only classifier. As with
the dual classifier approach, the content-only
classifier will give the preference that each in-
stance be classified with FOR or AGAINST for
CONVOTE, and ISRAELI or PALESTINIAN for
BITTERLEMONS.
</bodyText>
<listItem confidence="0.9323818">
2. Addition of relational features. Produce lo-
cal vectors by adding relational features to the
vectors previously used for content-only classi-
fication.
3. Iterative re-classification. Use a local classi-
fier to classify the new feature vectors. Update
the relational features after each iteration to re-
flect new class assignments. Repeat until class
assignments stabilise or a threshold number of
iterations is met.
</listItem>
<subsectionHeader confidence="0.665144">
5.2.1 Base Classification
</subsectionHeader>
<bodyText confidence="0.993427333333333">
Once again, content-only classification for the it-
erative classifier is performed using a bag-of-words
SVM with binary unigram features.
</bodyText>
<subsubsectionHeader confidence="0.847166">
5.2.2 Relational Features
</subsubsectionHeader>
<bodyText confidence="0.909482">
Let, fs be an average similarity score:
</bodyText>
<equation confidence="0.983794">
E
djED\{di} s(i,j)δYj,l fs(i, l) =(5)
EdjED\{di} δYj,l
</equation>
<bodyText confidence="0.999984666666667">
where δ is the Kronecker delta. Put in words, fs is
the average of the similarity scores for the pairings
of the given instance with each of the instances that
have the label l.
We derive relational features for the iterative clas-
sifier from the average similarity score as follows:
</bodyText>
<equation confidence="0.643707">
I 1 fs(i, l) &gt; fs(i, l&apos;);
</equation>
<bodyText confidence="0.977991444444445">
l 0 otherwise.
This means that the feature fas(i, l) is set to 1 iff
the average similarity of document di to instances
with label l is greater than its average similarity to
instances with label l&apos;. In training, document la-
bels are used when counting negative and positive
instances to determine the values for fas. In evalu-
ation, the classes assigned in the previous iteration
are used.
</bodyText>
<sectionHeader confidence="0.999601" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.999937833333333">
We assess the accuracy of the dual classifier and it-
erative classifier approaches described above over
CONVOTE and BITTERLEMONS in terms of classifi-
cation accuracy, micro-averaging across the 53 folds
of cross-validation in the case of CONVOTE. When
quoted, statistical significance has been determined
</bodyText>
<figure confidence="0.996209875">
Content-only
vectors
Base classification: linear kernel SVMs
Content-only
classifications
Addition of relational features:
average similarity score features
Local
vectors
Local
classifications
[terminate iteration]
Iterative re-classification: linear kernel SVMs
Overall
classifications
fas(i,l) =
</figure>
<page confidence="0.991789">
111
</page>
<table confidence="0.9996985">
Type Description n-gram size
1 2 3 4 5
Baseline Majority 51.44 51.44 51.44 51.44 51.44
Baseline Content-only 76.40 76.40 76.40 76.40 76.40
Dual Cosine similarity, min-cut 75.22 77.22? 76.52 77.28? 77.46?
Dual Cosine similarity, loopy belief 75.10 74.99 75.10 75.46 76.16
Dual Cosine similarity, mean-field 75.10 74.99 75.10 75.46 76.63
Iterative Average similarity score 77.99? 78.10? 78.81? 79.05? 78.16?
</table>
<tableCaption confidence="0.9971235">
Table 3: Collective classification performance on CONVOTE (* signifies a statistically significant improve-
ment over the content-only baseline, p &lt; 0.05).
</tableCaption>
<table confidence="0.999467666666667">
n-gram size
Type Description
1 2 3 4 5
Baseline Majority 49.83 49.83 49.83 49.83 49.83
Baseline Content-only 86.53 86.53 86.53 86.53 86.53
Dual Cosine similarity, min-cut 87.88 88.55? 88.89? 89.90? 90.57?
Dual Cosine similarity, loopy belief 87.54 86.87 87.88 87.88 88.55
Dual Cosine similarity, mean-field 87.54 86.87 87.88 87.88 88.55
Iterative Average similarity score 87.54 89.90? 90.91? 90.91? 89.90?
</table>
<tableCaption confidence="0.7896255">
Table 4: Collective classification performance on BITTERLEMONS (* signifies a statistically significant
improvement over the content-only baseline, p &lt; 0.05).
</tableCaption>
<bodyText confidence="0.972257">
using approximate randomisation with p &lt; 0.05
(Nooreen, 1989).
Two baseline scores are shown in the tables for
collective classification results: (1) “Majority” gives
the performance of the simplest possible classifier,
which classifies every instance with the label that
is most frequent in training data; and (2) “Content-
only” gives the performance of the bag-of-words
linear-kernel SVM used to perform base classifica-
tion.
</bodyText>
<subsectionHeader confidence="0.998936">
6.1 Collective Classifier Performance
</subsectionHeader>
<bodyText confidence="0.999961176470588">
Table 3 shows the overall collective classifier per-
formance on CONVOTE. The best performer is the
iterative classifier with 4-grams, with an accuracy
of 79.05%. This is a statistically significant 2.65%
absolute gain over the content-only baseline. The
iterative classifier is the best performer in general,
obtaining the next four best results with statistically
significant absolute gains of 2.41%, 1.76%, 1.70%
and 1.59% for 3-grams, 5-grams, 2-grams and 1-
grams respectively.
The dual classifier with minimum-cut is the next
best performer, with a best score of 77.45% for
5-grams, a statistically significant absolute gain of
1.06%. 4-grams and 2-grams also provide statisti-
cally significant gains, but 3-grams and 1-grams do
not.
For loopy-belief and mean-field the story is less
positive. None of the variations gives a statistically
significant improvement over the content-only base-
line. The best performer is mean-field with 5-grams,
with a score of 76.63, a 0.23% absolute improve-
ment over the baseline.
Table 4 shows overall collective classifier perfor-
mance on BITTERLEMONS. As with CONVOTE, the
best performer is the iterative classifier. 4-grams and
3-grams are the top-performing variants, obtaining a
score of 90.91%, a statistically significant 4.38% ab-
solute gain over the content-only baseline. 2-grams
and 5-grams are the next best, with a statistically sig-
nificant 3.37% absolute gain over the content-only
baseline. 1-grams are the only iterative classifier
variant that do not yield a statistically significant im-
provement over the content-only baseline.
The dual classifier results for BITTERLEMONS
</bodyText>
<page confidence="0.99665">
112
</page>
<bodyText confidence="0.999771304347826">
warrant special comment. As mentioned in Sec-
tion 5.1.4, leave-one-out tuning with the BITTER-
LEMONS training corpus is compromised. The aim
of cross-validation on the training set is to gain a
picture of likely performance on the test set. Un-
fortunately, BITTERLEMONS is not homogeneous:
articles in each class in the training set are con-
tributed by just one author, whereas articles in the
test set are contributed by different authors. Tuning
on BITTERLEMONS failed because leave-one-out on
the training set produced 100% accuracy, presum-
ably because there are features specific to the two
authors that make classification easy. This meant
that the ideal dampening parameter was found to be
exactly 1, i.e. collective classification was unneces-
sary, because the expected performance on the test
set was 100%.
As with CONVOTE, none of the loopy belief or
mean-field variants provide statistically significant
improvements over the content-only baseline. The
best performers are mean-field and loopy belief with
5-grams, with a score of 88.55%, a 2.02% absolute
improvement over the baseline.
</bodyText>
<figure confidence="0.996579772727273">
0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95
75
70
65
1-grams
2-grams
3-grams
4-grams
5-grams
baseline
dampening factor
(a) Min-cut
accuracy
65
75
70
1-grams
2-grams
3-grams
4-grams
5-grams
baseline
0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1
dampening factor
(b) Loopy belief
accurac7
68
66
64
62
78
76
74
72
70
1-grams
2-grams
3-grams
4-grams
5-grams
baseline
0.5 0.55 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1
accuracy
dampening factor
</figure>
<subsectionHeader confidence="0.997801">
6.2 Dual Classifier Dampening Response
</subsectionHeader>
<bodyText confidence="0.999958347826087">
We next examine the dampening response of the
dual classifier methods, by presenting six graphs
showing the performance of the three different de-
coding algorithms on the two test corpora. This
analysis helps to establish a picture of the limita-
tions of the dual classifier approach in comparison
with the iterative classifier approach.
Each of the graphs in this section shows the ef-
fect of a varying dampening factor on classification
accuracy. In each graph only a small portion of the
[−1, 1] range supported by the dampening parameter
is shown. The reason for this is visible on many of
the graphs: performance is fixed at or near 50% un-
til the dampening parameter is close to 1. This indi-
cates that the probabilities of the content-only classi-
fier and relationship classifier are badly mismatched:
performance only becomes reasonable after the rela-
tionship preferences have been massively reduced in
strength relative to the content-only preferences.
Figure 3 shows performance on CONVOTE for
minimum-cut, loopy belief, and mean-field respec-
tively. The trend is the same in each: performance
is flat until a sudden jump-up, leading to steady im-
</bodyText>
<figure confidence="0.765728">
(c) Mean-field
</figure>
<figureCaption confidence="0.962611">
Figure 3: The impact of the dampening factor on
dual classifier performance for CONVOTE.
</figureCaption>
<bodyText confidence="0.9960533125">
provement up to a peak, shortly before the maximum
dampening value of 1. At 1, the relationship prefer-
ences are entirely dampened and performance is the
same as the content-only baseline.
For minimum-cut, 1-grams provide the highest
peak accuracy with close to 78% at dampening fac-
tor 0.93. Each of the other n-gram orders jumps
above the 76.40% baseline at close to this point, with
5-grams providing the most sustained period of high
performance from dampening factor 0.85 through to
almost 1.
Performance is worse for loopy belief and mean-
field. Only 5-grams do better than the baseline, be-
tween approximately 0.92 and 0.95 dampening fac-
tor for both algorithms.
Figure 4 shows performance on BITTERLEMONS
</bodyText>
<page confidence="0.995502">
113
</page>
<figure confidence="0.995605166666667">
dampening factor
(a) Min-cut
dampening factor
(b) Loopy belief
dampening factor
(c) Mean-field
</figure>
<figureCaption confidence="0.9645125">
Figure 4: The impact of the dampening factor on
dual classifier performance for BITTERLEMONS.
</figureCaption>
<bodyText confidence="0.999869466666667">
for minimum-cut, loopy belief, and mean-field re-
spectively. The trend is the same: after a pe-
riod of flat performance, scores steadily improve as
the dampening factor is increased, reaching a peak
shortly before the maximum dampening value of 1.
For minimum-cut, 5-grams give the best perfor-
mance with a peak of 90.57% accuracy at damp-
ening factor 0.95. 4-grams do the next best, fol-
lowed by 3-grams, 2-grams and 1-grams. Each al-
gorithm rises to a sudden peak and then trails off as
it approaches maximum dampening. Loopy belief
and mean-field give almost identical performance.
Both show the same peak-and-trail-off shape as with
minimum-cut but the performance gain is smaller,
with 5-grams obtaining a best score of 88.55%.
</bodyText>
<sectionHeader confidence="0.866111" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999986411764706">
The collective classification experiments in this pa-
per demonstrate that useful inter-document seman-
tic relationships can be accurately predicted using
features based on matching sequences of words, i.e.
semantic relationships between pairs of documents
that can be detected based on the mutual use of par-
ticular n-grams. These semantic relationships can
be used to build collective classifiers that outperform
standard content-based classifiers.
Iterative classifiers do better than dual classifiers
at collective classification using similarity-based re-
lationships. Their superiority goes beyond measures
of performance: iterative classifiers are simpler to
implement, and more efficient. The key advantage
of the iterative classifier seems to lie in its ability to
sum up relationship information in a single average
similarity score.
Future work should consider the combination of
the methods investigated in this paper with more
advanced content-only approaches. For dual clas-
sifiers and iterative classifiers, it would be also in-
teresting to explore whether alternative base clas-
sifiers can provide better performance. For exam-
ple, confidence-weighted linear classification has
been shown to be highly effective on non-collective
document classification tasks, and could be easily
adapted for use in a dual classifier or iterative classi-
fier (Dredze et al., 2008). Finally, there is significant
scope to apply the techniques in this paper to other
collective classification tasks and to unambiguously
define the types of content for which collective doc-
ument classification with implicit inter-document re-
lationships can be expected to provide performance
gains.
</bodyText>
<sectionHeader confidence="0.995657" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.640419">
This research was supported in part by the Aus-
tralian Research Council.
</bodyText>
<sectionHeader confidence="0.996182" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.8835148">
Rakesh Agrawal, Sridhar Rajagopalan, Ramakrishnan
Srikant, and Yirong Xu. 2003. Mining newsgroups
using networks arising from social behavior. In
Proceedings of the 12th International Conference on
World Wide Web, pages 529–535, Budapest, Hungary.
</reference>
<figure confidence="0.999420717948718">
0.78 0.8 0.82 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98
90
80
70
60
50
1-grams
2-grams
3-grams
4-grams
5-grams
baseline
0.78 0.8 0.82 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98
accuracy
90
80
60
50
70
1-grams
2-grams
3-grams
4-grams
5-grams
baseline
0.78 0.8 0.82 0.84 0.86 0.88 0.9 0.92 0.94 0.96 0.98 1
accuracy
90
80
60
50
70
1-grams
2-grams
3-grams
4-grams
5-grams
baseline
accurac7
</figure>
<page confidence="0.985223">
114
</page>
<reference confidence="0.999517235849056">
Beata Beigman Klebanov, Eyal Beigman, and Daniel
Diermeier. 2010. Vocabulary choice as an indicator of
perspective. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguistics:
Short papers, pages 253–257, Uppsala, Sweden.
Avrim Blum and Shuchi Chawla. 2001. Learning from
labeled and unlabeled data using graph mincuts. In
Proceedings of the 18th International Conference on
Machine Learning, pages 19–26, Williamstown, USA.
Clinton Burfoot, Steven Bird, and Timothy Baldwin.
2011. Collective classification of congressional floor-
debate transcripts. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies, pages 1506–
1515, Portland, USA.
Clinton Burford. 2013. Collective Document Classifica-
tion Using Explicit and Implicit Inter-document Rela-
tionships. Ph.D. thesis, The University of Melbourne.
Massimiliano Ciaramita and Mark Johnson. 2003. Su-
persense tagging of unknown nouns in WordNet. In
Proceedings of the 2003 Conference on Empirical
Methods in Natural Language Processing, pages 168–
175, Sapporo, Japan.
Mark Dredze, Koby Crammer, and Fernando Pereira.
2008. Confidence-weighted linear classification. In
Proceedings of the 25th International Conference on
Machine Learning, pages 264–271, Helsinki, Finland.
C. Lee Giles, Kurt D. Bollacker, and Steve Lawrence.
1998. Citeseer: an automatic citation indexing sys-
tem. In Proceedings of the 3rd ACM Conference on
Digital libraries, pages 89–98, Pittsburgh, USA.
Andrew B. Goldberg, Xiaojin Zhu, and Stephen Wright.
2007. Dissimilarity in graph-based semi-supervised
classification. Journal of Machine Learning Research,
2:155–162.
Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun
Zhao. 2011. Target-dependent Twitter sentiment clas-
sification. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics:
Human Language Technologies, pages 151–160, Port-
land, USA.
Thorsten Joachims. 2003. Transductive learning via
spectral graph partitioning. In Proceedings of the In-
ternational Conference on Machine Learning, pages
290–297, Washington, USA.
Anders Johannsen, Dirk Hovy, H´ector Martinez Alonso,
Barbara Plank, and Anders Søgaard. 2014. More or
less supervised supersense tagging of twitter. In Pro-
ceedings of the Third Joint Conference on Lexical and
Computational Semantics (*SEM 2014), pages 1–11,
Dublin, Ireland.
Michael Jordan, Zoubin Ghahramani, Tommi Jaakkola,
Lawrence Saul, and David Heckerman. 1999. An in-
troduction to variational methods for graphical mod-
els. Machine Learning, 37:183–233.
David Jurgens. 2013. That’s what friends are for: In-
ferring location in online social media platforms based
on social relationships. In Proceedings of the 7th In-
ternational Conference on Weblogs and Social Media
(ICWSM 2013), pages 273–282, Dublin, Ireland.
Sotiris Kotsiantis and Dimitris Kanellopoulos. 2006.
Discretization techniques: A recent survey. In GESTS
International Transactions on Computer Science and
Engineering, volume 32, pages 47–58.
John D. Lafferty, Andrew McCallum, and Fernando C. N.
Pereira. 2001. Conditional random fields: Probabilis-
tic models for segmenting and labeling sequence data.
In Proceedings of the 18th International Conference
on Machine Learning, pages 282–289, Williamstown,
USA.
Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, and
Alexander Hauptmann. 2006. Which side are you
on? Identifying perspectives at the document and sen-
tence levels. In Proceedings of the 10th Conference
on Computational Natural Language Learning, pages
109–116, New York, USA.
Qing Lu and Lise Getoor. 2003. Link-based classifica-
tion. In Proceedings of the 20th International Confer-
ence on Machine Learning, pages 496–503, Washing-
ton, USA.
Luke McDowell, Kalyan Moy Gupta, and David W. Aha.
2007. Case-based collective classification. In Pro-
ceedings of the 20th International Florida Artificial
Intelligence Research Society Conference, pages 399–
404, Key West, USA.
Luke K McDowell, Kalyan Moy Gupta, and David W
Aha. 2009. Cautious collective classification. Journal
of Machine Learning Research, 10:2777–2836.
Eric W. Nooreen. 1989. Computer Intensive Methods for
Testing Hypothesis. Wiley and Sons Inc., New York,
USA.
Hyo-Jung Oh, Sung Hyon Myaeng, and Mann-Ho Lee.
2000. A practical hypertext categorization method
using links and incrementally available class infor-
mation. In Proceedings of the 23rd Annual Interna-
tional ACM SIGIR Conference on Research and De-
velopment in Information Retrieval, pages 264–271,
Athens, Greece.
Bo Pang and Lillian Lee. 2005. Seeing stars: Exploiting
class relationships for sentiment categorization with
respect to rating scales. In Proceedings of the 43rd
Annual Meeting of the Association for Computational
Linguistics, pages 115–124, Ann Arbor, USA.
John C. Platt. 1999. Probabilistic outputs for support
vector machines and comparisons to regularized like-
lihood methods. In Alexander Smola, Peter Bartlett,
</reference>
<page confidence="0.988723">
115
</page>
<reference confidence="0.999637820895522">
and Bernhard Sch¨olkopf, editors, Advances in Large
Margin Classifiers, pages 61–74. MIT Press, Cam-
bridge, USA.
Lawrence R. Rabiner and Biing-Hwang Juang. 1986. An
introduction to hidden markov models. ASSP Maga-
zine, IEEE, 3(1):4–16.
Prithviraj Sen, Galileo Mark Namata, Mustafa Bilgic,
Lise Getoor, Brian Gallagher, and Tina Eliassi-Rad.
2008. Collective classification in network data. AI
Magazine, 29(3):93–106.
Vikas Sindhwani and Prem Melville. 2008. Document-
word co-regularization for semi-supervised sentiment
analysis. In Proceedings of the 2008 IEEE Interna-
tional Conference on Data Mining, pages 1025–1030,
Washington, USA.
Se´an Slattery and Mark Craven. 1998. Combining sta-
tistical and relational methods for learning in hyper-
text domains. In Proceedings of Inductive Logic Pro-
gramming, 8th International Workshop, pages 38–52,
Madison, USA.
Swapna Somasundaran, Galileo Namata, Lise Getoor,
and Janyce Wiebe. 2009. Opinion graphs for polar-
ity and discourse classification. In Proceedings of the
2009 Workshop on Graph-based Methods for Natural
Language Processing, pages 66–74, Singapore.
Veselin Stoyanov and Jason Eisner. 2012. Minimum-
risk training of approximate CRF-based NLP systems.
In Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 120–130, Montr´eal, Canada.
Hiroya Takamura, Takashi Inui, and Manabu Okumura.
2007. Extracting semantic orientations of phrases
from dictionary. In Human Language Technologies
2007: The Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 292–299, Rochester, USA.
Chenhao Tan, Lillian Lee, Jie Tang, Long Jiang, Ming
Zhou, and Ping Li. 2011. User-level sentiment anal-
ysis incorporating social networks. In Proceedings of
the 17th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pages 1397–
1405, San Diego, USA.
Ben Taskar, Pieter Abbeel, and Daphne Koller. 2002.
Discriminative probabilistic models for relational data.
In Proceedings of the 18th Conference on Uncer-
tainty in Artificial Intelligence, pages 485–492, Al-
berta, Canada.
Matt Thomas, Bo Pang, and Lillian Lee. 2006. Get out
the vote: Determining support or opposition from con-
gressional floor-debate transcripts. In Proceedings of
the 2006 Conference on Empirical Methods in Natural
Language Processing, pages 327–335, Sydney, Aus-
tralia.
Yair Weiss. 2001. Comparing the mean field method and
belief propagation for approximate inference in MRFs.
In Manfred Opper and David Saad, editors, Advanced
mean field methods: theory and practice, pages 229–
239. MIT Press, Cambridge, USA.
Yiming Yang, Se´an Slattery, and Rayid Ghani. 2002. A
study of approaches to hypertext categorization. Jour-
nal of Intelligent Information Systems, 18(2-3):219–
241.
Jonathan Yedidia, William Freeman, and Yair Weiss.
2005. Constructing free-energy approximations and
generalized belief propagation algorithms. IEEE
Transactions on Information Theory, 51:2282–2312.
</reference>
<page confidence="0.999013">
116
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.571197">
<title confidence="0.99517">Collective Document Classification with Implicit Inter-document Semantic Relationships</title>
<author confidence="0.999491">Steven Bird Burford</author>
<affiliation confidence="0.892054">Department of Computing and Information The University of Melbourne, VIC 3010,</affiliation>
<email confidence="0.803501">clint@burford.cosbird@unimelb.edu.autb@ldwin.net</email>
<abstract confidence="0.994045461538462">This paper addresses the question of how document classifiers can exploit implicit information about document similarity to improve document classifier accuracy. We infer docsimilarity using simple overlap, and demonstrate that this improves overall document classification performance over two datasets. As part of this, we find that collective classification based on simple iterative classifiers outperforms the more complex and computationally-intensive dual classifier approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rakesh Agrawal</author>
<author>Sridhar Rajagopalan</author>
<author>Ramakrishnan Srikant</author>
<author>Yirong Xu</author>
</authors>
<title>Mining newsgroups using networks arising from social behavior.</title>
<date>2003</date>
<booktitle>In Proceedings of the 12th International Conference on World Wide Web,</booktitle>
<pages>529--535</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="5447" citStr="Agrawal et al., 2003" startWordPosition="815" endWordPosition="818">cts earlier work using explicit document links, where the dual classifier approach has generally been found to perform best (Thomas et al., 2006; Burfoot et al., 2011). While the work presented here is conceptually quite simple, the findings are significant and potentially open the door to accuracy improvements on a range of document-level semantic tasks. 2 Related Work Previous work has dealt with the question of collective document classification using implicit interdocument relationships in two basic ways: 1. proximity: use a spatial or temporal dimension of the domain to relate documents (Agrawal et al., 2003; Goldberg et al., 2007; McDowell et al., 2009; Somasundaran et al., 2009). 2. similarity: relate documents via some notion of their content-based similarity (Blum and Chawla, 2001; Joachims, 2003; Takamura et al., 2007; Sindhwani and Melville, 2008; Jurgens, 2013) The work using similarity-based links is the closest to ours but is also strongly differentiated because it focuses on transductive semi-supervised classification. That task begins with the premise that only a small amount of labelled training data is available, so content-only classification is likely to be inaccurate. By contrast,</context>
</contexts>
<marker>Agrawal, Rajagopalan, Srikant, Xu, 2003</marker>
<rawString>Rakesh Agrawal, Sridhar Rajagopalan, Ramakrishnan Srikant, and Yirong Xu. 2003. Mining newsgroups using networks arising from social behavior. In Proceedings of the 12th International Conference on World Wide Web, pages 529–535, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beata Beigman Klebanov</author>
<author>Eyal Beigman</author>
<author>Daniel Diermeier</author>
</authors>
<title>Vocabulary choice as an indicator of perspective.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics: Short papers,</booktitle>
<pages>253--257</pages>
<location>Uppsala,</location>
<contexts>
<context position="13101" citStr="Klebanov et al., 2010" startWordPosition="2020" endWordPosition="2024">t (SAME). 2. Normalisation: Normalise the scores, producing values for the classification preference functions, ψi, which can be input into a collective classification algorithm. 3. Decoding: Produce final classifications by optimally decoding the content-only and relationship level preferences using a collective classification algorithm. 5.1.1 Base classification For our content-only base classifier, we use the same bag-of-words SVM with binary (existencebased) unigram features as (Thomas et al., 2006). This classifier has been shown to be the best bagof-words model for BITTERLEMONS (Beigman Klebanov et al., 2010). As our relationship base classifier, we use the cosine similarity scores described above, calculated using n-grams of several different lengths. 5.1.2 Normalisation We use probabilistic SVM normalisation to convert the signed decision-plane distance output by the content-only classifier into the probability that the instance is in the positive class (Platt, 1999). For the relationship classifier, the technique used to convert the cosine similarity score into a classification preference needs to fit complex criteria. Preliminary experiments suggested that while the very highest similarity sco</context>
</contexts>
<marker>Klebanov, Beigman, Diermeier, 2010</marker>
<rawString>Beata Beigman Klebanov, Eyal Beigman, and Daniel Diermeier. 2010. Vocabulary choice as an indicator of perspective. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics: Short papers, pages 253–257, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avrim Blum</author>
<author>Shuchi Chawla</author>
</authors>
<title>Learning from labeled and unlabeled data using graph mincuts.</title>
<date>2001</date>
<booktitle>In Proceedings of the 18th International Conference on Machine Learning,</booktitle>
<pages>pages</pages>
<location>Williamstown, USA.</location>
<contexts>
<context position="5627" citStr="Blum and Chawla, 2001" startWordPosition="842" endWordPosition="845">work presented here is conceptually quite simple, the findings are significant and potentially open the door to accuracy improvements on a range of document-level semantic tasks. 2 Related Work Previous work has dealt with the question of collective document classification using implicit interdocument relationships in two basic ways: 1. proximity: use a spatial or temporal dimension of the domain to relate documents (Agrawal et al., 2003; Goldberg et al., 2007; McDowell et al., 2009; Somasundaran et al., 2009). 2. similarity: relate documents via some notion of their content-based similarity (Blum and Chawla, 2001; Joachims, 2003; Takamura et al., 2007; Sindhwani and Melville, 2008; Jurgens, 2013) The work using similarity-based links is the closest to ours but is also strongly differentiated because it focuses on transductive semi-supervised classification. That task begins with the premise that only a small amount of labelled training data is available, so content-only classification is likely to be inaccurate. By contrast, the supervised techniques in this paper deal with large amounts of labelled training data and relatively high content-only performance – 76% for CONVOTE and 87% for BITTERLEMONS. </context>
<context position="16752" citStr="Blum and Chawla (2001)" startWordPosition="2586" endWordPosition="2589">d Mean-field is an alternative message passing algorithm, that can be expressed as: Y bi(l) = αψi(l) jENinD and is re-computed for each document until the marginal probabilities stabilise. Loopy belief propagation and mean-field have both been justified as variational methods for Markov random fields (Jordan et al., 1999; Weiss, 2001; Yedidia et al., 2005). Minimum Cut The minimum-cut technique involves formulating a binary collective classification task as a flow graph and finding solutions using standard methods for solving minimum-cut (maximum-flow) problems. We use the method described by Blum and Chawla (2001) in an in-sample setting, which is equivalent to finding the optimal solution for the cost function for labellings: cost(Y) = X Xwi(Yi) + wr(di, dj) diED (di,dj)EE:Yi=,4Yj 5.1.4 Tuning The relative weights given to the content-only and relational classifiers can be tuned as follows (for CONVOTE, without loss of generality): ψ&apos;i(FOR) = ψi(FOR)+ min(0,γ)(ψi(FOR)−ψi(AGAINST)) 2 ψ&apos;ij(FOR, FOR) = ψij(FOR, FOR)− max(0,γ)(ψij(FOR,FOR)−ψij(FOR,AGAINST)) 2 where ψ&apos; i and ψ&apos;ij refer to the dampened versions of the content-only and relationship preference functions, respectively, γ is the dampening param</context>
</contexts>
<marker>Blum, Chawla, 2001</marker>
<rawString>Avrim Blum and Shuchi Chawla. 2001. Learning from labeled and unlabeled data using graph mincuts. In Proceedings of the 18th International Conference on Machine Learning, pages 19–26, Williamstown, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Clinton Burfoot</author>
<author>Steven Bird</author>
<author>Timothy Baldwin</author>
</authors>
<title>Collective classification of congressional floordebate transcripts.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>1506--1515</pages>
<location>Portland, USA.</location>
<contexts>
<context position="2828" citStr="Burfoot et al., 2011" startWordPosition="414" endWordPosition="418"> within joint models for document-level semantic classification, focusing specifically on tasks which are not associated with any explicit graph structure. That is, we examine whether implicit semantic document links can improve the results of a point-wise (content-based) classification approach. Explicit inter-document links have been variously shown to improve document classifier performance, based on information sources including hyperlinks in web documents (Slattery and Craven, 1998; Oh et al., 2000; Yang et al., 2002), direct name-references in congressional debates (Thomas et al., 2006; Burfoot et al., 2011; Stoyanov and Eisner, 2012), citations in scientific papers (Giles et al., 1998; Lu and Getoor, 2003; McDowell et al., 2007), and user mentions or retweets in social media (Jiang et al., 2011; Tan et al., 2011). However, document collections often don’t contain explicit inter-document links, limiting the practical usefulness of such methods. In this paper, we seek to expand the reach of research which incorporates linking information, in inducing implicit linking information between documents, and demonstrating that the resultant (noisy) network structure improves document classification accu</context>
<context position="4994" citStr="Burfoot et al., 2011" startWordPosition="744" endWordPosition="747">o achieve this using a general-purpose setup, as applied to a range of datasets. Our results are achieved using n-gram overlap features for both the CONVOTE and BITTERLEMONS corpora, without the use of annotations for explicit semantic inter-document relationships. A second contribution of this work is the finding that simple iterative classifiers outperform more complex dual classifiers when using implicit inter-document links. This finding contradicts earlier work using explicit document links, where the dual classifier approach has generally been found to perform best (Thomas et al., 2006; Burfoot et al., 2011). While the work presented here is conceptually quite simple, the findings are significant and potentially open the door to accuracy improvements on a range of document-level semantic tasks. 2 Related Work Previous work has dealt with the question of collective document classification using implicit interdocument relationships in two basic ways: 1. proximity: use a spatial or temporal dimension of the domain to relate documents (Agrawal et al., 2003; Goldberg et al., 2007; McDowell et al., 2009; Somasundaran et al., 2009). 2. similarity: relate documents via some notion of their content-based </context>
</contexts>
<marker>Burfoot, Bird, Baldwin, 2011</marker>
<rawString>Clinton Burfoot, Steven Bird, and Timothy Baldwin. 2011. Collective classification of congressional floordebate transcripts. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1506– 1515, Portland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Clinton Burford</author>
</authors>
<title>Collective Document Classification Using Explicit and Implicit Inter-document Relationships.</title>
<date>2013</date>
<tech>Ph.D. thesis,</tech>
<institution>The University of Melbourne.</institution>
<contexts>
<context position="11687" citStr="Burford (2013)" startWordPosition="1811" endWordPosition="1812">example for BITTERLEMONS is: (3) Even if we /wanted/ to succumb to Israeli pressure, it is impossible to make a Palestinian teach his child that Jaffa or Haifa or Palestine 108 Corpus content Overall classifications Figure 1: Dual classifier with similarity-based links. before 1948 was not his land. [AHMAD HARB (GUEST); PALESTINIAN] (4) This is being neglected and Sharon is having his way in brutalizing the Palestinian people in the hope that they will succumb and abandon their rights. [HAIDAR ABDEL SHAFI (GUEST); PALESTINIAN] For other examples and more justification of this methodology, see Burford (2013). 5 Collective Classification Two standard approaches to collective classification are: (1) the dual classifier approach; and (2) the iterative classifier approach. We briefly review these approaches below, but refer the reader to Sen et al. (2008), McDowell et al. (2009) and Burford (2013) for a more detailed methodological discussion. 5.1 Dual Classifier Approach The dual classifier approach is made up of three steps, as depicted in Figure 1: 1. Base classification: Produce base classifications using (1) a content-only classifier; and (2) a relationship classifier. The contentonly classifier</context>
</contexts>
<marker>Burford, 2013</marker>
<rawString>Clinton Burford. 2013. Collective Document Classification Using Explicit and Implicit Inter-document Relationships. Ph.D. thesis, The University of Melbourne.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimiliano Ciaramita</author>
<author>Mark Johnson</author>
</authors>
<title>Supersense tagging of unknown nouns in WordNet.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>168--175</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="2137" citStr="Ciaramita and Johnson, 2003" startWordPosition="316" endWordPosition="320">een proposed, although in natural language processing at least, these have focused largely on conditional dependence, in the form of models such as 1In some tasks, it can also indicate heterophily, i.e. the tendency for connected instances to have contrasting properties, as we shall see for one of our two dataset. hidden Markov models (Rabiner and Juang, 1986) and conditional random fields (Lafferty et al., 2001), where independent properties of words, e.g., are combined with conditional dependencies based on their context of use to jointly predict the senses of all words in a given sentence (Ciaramita and Johnson, 2003; Johannsen et al., 2014). This paper explores the utility of homophily within joint models for document-level semantic classification, focusing specifically on tasks which are not associated with any explicit graph structure. That is, we examine whether implicit semantic document links can improve the results of a point-wise (content-based) classification approach. Explicit inter-document links have been variously shown to improve document classifier performance, based on information sources including hyperlinks in web documents (Slattery and Craven, 1998; Oh et al., 2000; Yang et al., 2002),</context>
</contexts>
<marker>Ciaramita, Johnson, 2003</marker>
<rawString>Massimiliano Ciaramita and Mark Johnson. 2003. Supersense tagging of unknown nouns in WordNet. In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing, pages 168– 175, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Confidence-weighted linear classification.</title>
<date>2008</date>
<booktitle>In Proceedings of the 25th International Conference on Machine Learning,</booktitle>
<pages>264--271</pages>
<location>Helsinki, Finland.</location>
<marker>Dredze, Crammer, Pereira, 2008</marker>
<rawString>Mark Dredze, Koby Crammer, and Fernando Pereira. 2008. Confidence-weighted linear classification. In Proceedings of the 25th International Conference on Machine Learning, pages 264–271, Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lee Giles</author>
<author>Kurt D Bollacker</author>
<author>Steve Lawrence</author>
</authors>
<title>Citeseer: an automatic citation indexing system.</title>
<date>1998</date>
<booktitle>In Proceedings of the 3rd ACM Conference on Digital libraries,</booktitle>
<pages>89--98</pages>
<location>Pittsburgh, USA.</location>
<contexts>
<context position="2908" citStr="Giles et al., 1998" startWordPosition="428" endWordPosition="431">ally on tasks which are not associated with any explicit graph structure. That is, we examine whether implicit semantic document links can improve the results of a point-wise (content-based) classification approach. Explicit inter-document links have been variously shown to improve document classifier performance, based on information sources including hyperlinks in web documents (Slattery and Craven, 1998; Oh et al., 2000; Yang et al., 2002), direct name-references in congressional debates (Thomas et al., 2006; Burfoot et al., 2011; Stoyanov and Eisner, 2012), citations in scientific papers (Giles et al., 1998; Lu and Getoor, 2003; McDowell et al., 2007), and user mentions or retweets in social media (Jiang et al., 2011; Tan et al., 2011). However, document collections often don’t contain explicit inter-document links, limiting the practical usefulness of such methods. In this paper, we seek to expand the reach of research which incorporates linking information, in inducing implicit linking information between documents, and demonstrating that the resultant (noisy) network structure improves document classification accuracy. The intuition underlying this work is that some types of documents have fe</context>
</contexts>
<marker>Giles, Bollacker, Lawrence, 1998</marker>
<rawString>C. Lee Giles, Kurt D. Bollacker, and Steve Lawrence. 1998. Citeseer: an automatic citation indexing system. In Proceedings of the 3rd ACM Conference on Digital libraries, pages 89–98, Pittsburgh, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew B Goldberg</author>
<author>Xiaojin Zhu</author>
<author>Stephen Wright</author>
</authors>
<title>Dissimilarity in graph-based semi-supervised classification.</title>
<date>2007</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>2--155</pages>
<contexts>
<context position="5470" citStr="Goldberg et al., 2007" startWordPosition="819" endWordPosition="822"> explicit document links, where the dual classifier approach has generally been found to perform best (Thomas et al., 2006; Burfoot et al., 2011). While the work presented here is conceptually quite simple, the findings are significant and potentially open the door to accuracy improvements on a range of document-level semantic tasks. 2 Related Work Previous work has dealt with the question of collective document classification using implicit interdocument relationships in two basic ways: 1. proximity: use a spatial or temporal dimension of the domain to relate documents (Agrawal et al., 2003; Goldberg et al., 2007; McDowell et al., 2009; Somasundaran et al., 2009). 2. similarity: relate documents via some notion of their content-based similarity (Blum and Chawla, 2001; Joachims, 2003; Takamura et al., 2007; Sindhwani and Melville, 2008; Jurgens, 2013) The work using similarity-based links is the closest to ours but is also strongly differentiated because it focuses on transductive semi-supervised classification. That task begins with the premise that only a small amount of labelled training data is available, so content-only classification is likely to be inaccurate. By contrast, the supervised techniq</context>
</contexts>
<marker>Goldberg, Zhu, Wright, 2007</marker>
<rawString>Andrew B. Goldberg, Xiaojin Zhu, and Stephen Wright. 2007. Dissimilarity in graph-based semi-supervised classification. Journal of Machine Learning Research, 2:155–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Jiang</author>
<author>Mo Yu</author>
<author>Ming Zhou</author>
<author>Xiaohua Liu</author>
<author>Tiejun Zhao</author>
</authors>
<title>Target-dependent Twitter sentiment classification.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>151--160</pages>
<location>Portland, USA.</location>
<contexts>
<context position="3020" citStr="Jiang et al., 2011" startWordPosition="448" endWordPosition="451">emantic document links can improve the results of a point-wise (content-based) classification approach. Explicit inter-document links have been variously shown to improve document classifier performance, based on information sources including hyperlinks in web documents (Slattery and Craven, 1998; Oh et al., 2000; Yang et al., 2002), direct name-references in congressional debates (Thomas et al., 2006; Burfoot et al., 2011; Stoyanov and Eisner, 2012), citations in scientific papers (Giles et al., 1998; Lu and Getoor, 2003; McDowell et al., 2007), and user mentions or retweets in social media (Jiang et al., 2011; Tan et al., 2011). However, document collections often don’t contain explicit inter-document links, limiting the practical usefulness of such methods. In this paper, we seek to expand the reach of research which incorporates linking information, in inducing implicit linking information between documents, and demonstrating that the resultant (noisy) network structure improves document classification accuracy. The intuition underlying this work is that some types of documents have features which are either absent or ambiguous in training data, but which have 106 Proceedings of the Fourth Joint</context>
</contexts>
<marker>Jiang, Yu, Zhou, Liu, Zhao, 2011</marker>
<rawString>Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun Zhao. 2011. Target-dependent Twitter sentiment classification. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 151–160, Portland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Transductive learning via spectral graph partitioning.</title>
<date>2003</date>
<booktitle>In Proceedings of the International Conference on Machine Learning,</booktitle>
<pages>290--297</pages>
<location>Washington, USA.</location>
<contexts>
<context position="5643" citStr="Joachims, 2003" startWordPosition="846" endWordPosition="847">conceptually quite simple, the findings are significant and potentially open the door to accuracy improvements on a range of document-level semantic tasks. 2 Related Work Previous work has dealt with the question of collective document classification using implicit interdocument relationships in two basic ways: 1. proximity: use a spatial or temporal dimension of the domain to relate documents (Agrawal et al., 2003; Goldberg et al., 2007; McDowell et al., 2009; Somasundaran et al., 2009). 2. similarity: relate documents via some notion of their content-based similarity (Blum and Chawla, 2001; Joachims, 2003; Takamura et al., 2007; Sindhwani and Melville, 2008; Jurgens, 2013) The work using similarity-based links is the closest to ours but is also strongly differentiated because it focuses on transductive semi-supervised classification. That task begins with the premise that only a small amount of labelled training data is available, so content-only classification is likely to be inaccurate. By contrast, the supervised techniques in this paper deal with large amounts of labelled training data and relatively high content-only performance – 76% for CONVOTE and 87% for BITTERLEMONS. It is reasonable</context>
</contexts>
<marker>Joachims, 2003</marker>
<rawString>Thorsten Joachims. 2003. Transductive learning via spectral graph partitioning. In Proceedings of the International Conference on Machine Learning, pages 290–297, Washington, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Johannsen</author>
<author>Dirk Hovy</author>
<author>H´ector Martinez Alonso</author>
<author>Barbara Plank</author>
<author>Anders Søgaard</author>
</authors>
<title>More or less supervised supersense tagging of twitter.</title>
<date>2014</date>
<booktitle>In Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014),</booktitle>
<pages>1--11</pages>
<location>Dublin, Ireland.</location>
<contexts>
<context position="2162" citStr="Johannsen et al., 2014" startWordPosition="321" endWordPosition="324">ural language processing at least, these have focused largely on conditional dependence, in the form of models such as 1In some tasks, it can also indicate heterophily, i.e. the tendency for connected instances to have contrasting properties, as we shall see for one of our two dataset. hidden Markov models (Rabiner and Juang, 1986) and conditional random fields (Lafferty et al., 2001), where independent properties of words, e.g., are combined with conditional dependencies based on their context of use to jointly predict the senses of all words in a given sentence (Ciaramita and Johnson, 2003; Johannsen et al., 2014). This paper explores the utility of homophily within joint models for document-level semantic classification, focusing specifically on tasks which are not associated with any explicit graph structure. That is, we examine whether implicit semantic document links can improve the results of a point-wise (content-based) classification approach. Explicit inter-document links have been variously shown to improve document classifier performance, based on information sources including hyperlinks in web documents (Slattery and Craven, 1998; Oh et al., 2000; Yang et al., 2002), direct name-references i</context>
</contexts>
<marker>Johannsen, Hovy, Alonso, Plank, Søgaard, 2014</marker>
<rawString>Anders Johannsen, Dirk Hovy, H´ector Martinez Alonso, Barbara Plank, and Anders Søgaard. 2014. More or less supervised supersense tagging of twitter. In Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 1–11, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Jordan</author>
<author>Zoubin Ghahramani</author>
<author>Tommi Jaakkola</author>
<author>Lawrence Saul</author>
<author>David Heckerman</author>
</authors>
<title>An introduction to variational methods for graphical models.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>37--183</pages>
<contexts>
<context position="16452" citStr="Jordan et al., 1999" startWordPosition="2543" endWordPosition="2546">til the messages stabilise. The marginal probability is then derived by calculating bi(l). Loopy belief propagation was used in early collective classification work (Taskar et al., 2002) and has remained popular since (Sen et al., 2008; McDowell et al., 2009; Stoyanov and Eisner, 2012). Mean-field Mean-field is an alternative message passing algorithm, that can be expressed as: Y bi(l) = αψi(l) jENinD and is re-computed for each document until the marginal probabilities stabilise. Loopy belief propagation and mean-field have both been justified as variational methods for Markov random fields (Jordan et al., 1999; Weiss, 2001; Yedidia et al., 2005). Minimum Cut The minimum-cut technique involves formulating a binary collective classification task as a flow graph and finding solutions using standard methods for solving minimum-cut (maximum-flow) problems. We use the method described by Blum and Chawla (2001) in an in-sample setting, which is equivalent to finding the optimal solution for the cost function for labellings: cost(Y) = X Xwi(Yi) + wr(di, dj) diED (di,dj)EE:Yi=,4Yj 5.1.4 Tuning The relative weights given to the content-only and relational classifiers can be tuned as follows (for CONVOTE, wit</context>
</contexts>
<marker>Jordan, Ghahramani, Jaakkola, Saul, Heckerman, 1999</marker>
<rawString>Michael Jordan, Zoubin Ghahramani, Tommi Jaakkola, Lawrence Saul, and David Heckerman. 1999. An introduction to variational methods for graphical models. Machine Learning, 37:183–233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Jurgens</author>
</authors>
<title>That’s what friends are for: Inferring location in online social media platforms based on social relationships.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Conference on Weblogs and Social Media (ICWSM 2013),</booktitle>
<pages>273--282</pages>
<location>Dublin, Ireland.</location>
<contexts>
<context position="5712" citStr="Jurgens, 2013" startWordPosition="856" endWordPosition="858">ly open the door to accuracy improvements on a range of document-level semantic tasks. 2 Related Work Previous work has dealt with the question of collective document classification using implicit interdocument relationships in two basic ways: 1. proximity: use a spatial or temporal dimension of the domain to relate documents (Agrawal et al., 2003; Goldberg et al., 2007; McDowell et al., 2009; Somasundaran et al., 2009). 2. similarity: relate documents via some notion of their content-based similarity (Blum and Chawla, 2001; Joachims, 2003; Takamura et al., 2007; Sindhwani and Melville, 2008; Jurgens, 2013) The work using similarity-based links is the closest to ours but is also strongly differentiated because it focuses on transductive semi-supervised classification. That task begins with the premise that only a small amount of labelled training data is available, so content-only classification is likely to be inaccurate. By contrast, the supervised techniques in this paper deal with large amounts of labelled training data and relatively high content-only performance – 76% for CONVOTE and 87% for BITTERLEMONS. It is reasonable to assume that the types of similarity-based relationships derived f</context>
</contexts>
<marker>Jurgens, 2013</marker>
<rawString>David Jurgens. 2013. That’s what friends are for: Inferring location in online social media platforms based on social relationships. In Proceedings of the 7th International Conference on Weblogs and Social Media (ICWSM 2013), pages 273–282, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sotiris Kotsiantis</author>
<author>Dimitris Kanellopoulos</author>
</authors>
<title>Discretization techniques: A recent survey.</title>
<date>2006</date>
<booktitle>In GESTS International Transactions on Computer Science and Engineering,</booktitle>
<volume>32</volume>
<pages>47--58</pages>
<contexts>
<context position="15032" citStr="Kotsiantis and Kanellopoulos, 2006" startWordPosition="2314" endWordPosition="2318">reference values Normalisation: binning Decoding: minimum-cut, mean-field or loopy belief propagation 109 0.9 s(i, j) &gt; b1; 0.8 b2 &lt; s(i, j) &lt; b1; 0.7 b3 &lt; s(i, j) &lt; b2; 0.6 b4 &lt; s(i, j) &lt; b3; 0.5 s(i, j) &lt; b4; where ψij(l, l) represents the SAME preference (i.e. the probability of i and j having the same label); the values for b1, b2, b3, and b4 are derived by sorting the relationships in the training data by similarity score, and separating them into intervals holding a proportion of SAME pairs equivalent to the nominated probability. This approach is similar to unsupervised discretisation (Kotsiantis and Kanellopoulos, 2006), except the intervals are arranged so that the output categories have a probabilistic interpretation. 5.1.3 Decoding Decoding is carried out using three techniques: (1) loopy belief propagation (McDowell et al., 2009); (2) mean-field; and (3) minimum-cut. Loopy Belief Propagation Loopy belief propagation is a message passing algorithm that can be expressed as: mi—,j(l) = Xα l&apos;EL ⎛ ⎞ ⎝ψi(l&apos;)ψij(l&apos;, l) mk—,i(l&apos;) ⎠ kENinDU\{j1 Y bi(l) = αψi(l) Y mk—,i(l) kENinDU where mi—,j is a message sent by document di to document dj, and α is a normalization constant that ensures that each message and each </context>
</contexts>
<marker>Kotsiantis, Kanellopoulos, 2006</marker>
<rawString>Sotiris Kotsiantis and Dimitris Kanellopoulos. 2006. Discretization techniques: A recent survey. In GESTS International Transactions on Computer Science and Engineering, volume 32, pages 47–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the 18th International Conference on Machine Learning,</booktitle>
<pages>282--289</pages>
<location>Williamstown, USA.</location>
<contexts>
<context position="1926" citStr="Lafferty et al., 2001" startWordPosition="283" endWordPosition="286">endence (i.e. one event is dependent on the outcome of another) or “homophily” (i.e. the tendency for connected instances to share various properties).1 Various joint models that combine the two have also been proposed, although in natural language processing at least, these have focused largely on conditional dependence, in the form of models such as 1In some tasks, it can also indicate heterophily, i.e. the tendency for connected instances to have contrasting properties, as we shall see for one of our two dataset. hidden Markov models (Rabiner and Juang, 1986) and conditional random fields (Lafferty et al., 2001), where independent properties of words, e.g., are combined with conditional dependencies based on their context of use to jointly predict the senses of all words in a given sentence (Ciaramita and Johnson, 2003; Johannsen et al., 2014). This paper explores the utility of homophily within joint models for document-level semantic classification, focusing specifically on tasks which are not associated with any explicit graph structure. That is, we examine whether implicit semantic document links can improve the results of a point-wise (content-based) classification approach. Explicit inter-docum</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the 18th International Conference on Machine Learning, pages 282–289, Williamstown, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei-Hao Lin</author>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Alexander Hauptmann</author>
</authors>
<title>Which side are you on? Identifying perspectives at the document and sentence levels.</title>
<date>2006</date>
<booktitle>In Proceedings of the 10th Conference on Computational Natural Language Learning,</booktitle>
<pages>109--116</pages>
<location>New York, USA.</location>
<contexts>
<context position="9012" citStr="Lin et al., 2006" startWordPosition="1378" endWordPosition="1381">ents from the original dataset, and instead evaluate using leave-one-out cross-validation over the 53 debates contained in the dataset, to allow for a more statistically robust evaluation; and (3) we discard the manually annotated inter-document relationships based on references to speaker names, because implicit relationships are the focus of this work. Table 1 gives statistics for our rendering of CONVOTE. The identical figures for the average number of speeches and speakers per debate reflect the fact that each speaker now contributes only one unified speech. 3.2 BITTERLEMONS BITTERLEMONS (Lin et al., 2006) is a collection of articles on the Israeli–Arab conflict harvested from the Bitterlemons website.2 In each weekly issue, the editors contribute an article giving their perspectives on some aspect of the conflict, and two guest authors contribute articles, one from an Israeli perspective and the other from a Palestinian perspective. Sometimes these guest contributions take the form of an interview, in which case we remove the questions (from the editors) and retain only the answers. The statistics in Table 2 give a picture of the size and structure of BITTERLEMONS. In accordance with Lin et al</context>
</contexts>
<marker>Lin, Wilson, Wiebe, Hauptmann, 2006</marker>
<rawString>Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, and Alexander Hauptmann. 2006. Which side are you on? Identifying perspectives at the document and sentence levels. In Proceedings of the 10th Conference on Computational Natural Language Learning, pages 109–116, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qing Lu</author>
<author>Lise Getoor</author>
</authors>
<title>Link-based classification.</title>
<date>2003</date>
<booktitle>In Proceedings of the 20th International Conference on Machine Learning,</booktitle>
<pages>496--503</pages>
<location>Washington, USA.</location>
<contexts>
<context position="2929" citStr="Lu and Getoor, 2003" startWordPosition="432" endWordPosition="435">are not associated with any explicit graph structure. That is, we examine whether implicit semantic document links can improve the results of a point-wise (content-based) classification approach. Explicit inter-document links have been variously shown to improve document classifier performance, based on information sources including hyperlinks in web documents (Slattery and Craven, 1998; Oh et al., 2000; Yang et al., 2002), direct name-references in congressional debates (Thomas et al., 2006; Burfoot et al., 2011; Stoyanov and Eisner, 2012), citations in scientific papers (Giles et al., 1998; Lu and Getoor, 2003; McDowell et al., 2007), and user mentions or retweets in social media (Jiang et al., 2011; Tan et al., 2011). However, document collections often don’t contain explicit inter-document links, limiting the practical usefulness of such methods. In this paper, we seek to expand the reach of research which incorporates linking information, in inducing implicit linking information between documents, and demonstrating that the resultant (noisy) network structure improves document classification accuracy. The intuition underlying this work is that some types of documents have features which are eith</context>
</contexts>
<marker>Lu, Getoor, 2003</marker>
<rawString>Qing Lu and Lise Getoor. 2003. Link-based classification. In Proceedings of the 20th International Conference on Machine Learning, pages 496–503, Washington, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke McDowell</author>
<author>Kalyan Moy Gupta</author>
<author>David W Aha</author>
</authors>
<title>Case-based collective classification.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th International Florida Artificial Intelligence Research Society Conference,</booktitle>
<pages>399--404</pages>
<location>Key West, USA.</location>
<contexts>
<context position="2953" citStr="McDowell et al., 2007" startWordPosition="436" endWordPosition="439">th any explicit graph structure. That is, we examine whether implicit semantic document links can improve the results of a point-wise (content-based) classification approach. Explicit inter-document links have been variously shown to improve document classifier performance, based on information sources including hyperlinks in web documents (Slattery and Craven, 1998; Oh et al., 2000; Yang et al., 2002), direct name-references in congressional debates (Thomas et al., 2006; Burfoot et al., 2011; Stoyanov and Eisner, 2012), citations in scientific papers (Giles et al., 1998; Lu and Getoor, 2003; McDowell et al., 2007), and user mentions or retweets in social media (Jiang et al., 2011; Tan et al., 2011). However, document collections often don’t contain explicit inter-document links, limiting the practical usefulness of such methods. In this paper, we seek to expand the reach of research which incorporates linking information, in inducing implicit linking information between documents, and demonstrating that the resultant (noisy) network structure improves document classification accuracy. The intuition underlying this work is that some types of documents have features which are either absent or ambiguous i</context>
</contexts>
<marker>McDowell, Gupta, Aha, 2007</marker>
<rawString>Luke McDowell, Kalyan Moy Gupta, and David W. Aha. 2007. Case-based collective classification. In Proceedings of the 20th International Florida Artificial Intelligence Research Society Conference, pages 399– 404, Key West, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke K McDowell</author>
<author>Kalyan Moy Gupta</author>
<author>David W Aha</author>
</authors>
<title>Cautious collective classification.</title>
<date>2009</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>10--2777</pages>
<contexts>
<context position="5493" citStr="McDowell et al., 2009" startWordPosition="823" endWordPosition="826">s, where the dual classifier approach has generally been found to perform best (Thomas et al., 2006; Burfoot et al., 2011). While the work presented here is conceptually quite simple, the findings are significant and potentially open the door to accuracy improvements on a range of document-level semantic tasks. 2 Related Work Previous work has dealt with the question of collective document classification using implicit interdocument relationships in two basic ways: 1. proximity: use a spatial or temporal dimension of the domain to relate documents (Agrawal et al., 2003; Goldberg et al., 2007; McDowell et al., 2009; Somasundaran et al., 2009). 2. similarity: relate documents via some notion of their content-based similarity (Blum and Chawla, 2001; Joachims, 2003; Takamura et al., 2007; Sindhwani and Melville, 2008; Jurgens, 2013) The work using similarity-based links is the closest to ours but is also strongly differentiated because it focuses on transductive semi-supervised classification. That task begins with the premise that only a small amount of labelled training data is available, so content-only classification is likely to be inaccurate. By contrast, the supervised techniques in this paper deal </context>
<context position="11959" citStr="McDowell et al. (2009)" startWordPosition="1850" endWordPosition="1853">links. before 1948 was not his land. [AHMAD HARB (GUEST); PALESTINIAN] (4) This is being neglected and Sharon is having his way in brutalizing the Palestinian people in the hope that they will succumb and abandon their rights. [HAIDAR ABDEL SHAFI (GUEST); PALESTINIAN] For other examples and more justification of this methodology, see Burford (2013). 5 Collective Classification Two standard approaches to collective classification are: (1) the dual classifier approach; and (2) the iterative classifier approach. We briefly review these approaches below, but refer the reader to Sen et al. (2008), McDowell et al. (2009) and Burford (2013) for a more detailed methodological discussion. 5.1 Dual Classifier Approach The dual classifier approach is made up of three steps, as depicted in Figure 1: 1. Base classification: Produce base classifications using (1) a content-only classifier; and (2) a relationship classifier. The contentonly classifier makes a binary prediction: FOR and AGAINST for CONVOTE, and ISRAELI or PALESTINIAN for BITTERLEMONS. The relationship classifier indicates the preference that each document pair be SAME or not (SAME). 2. Normalisation: Normalise the scores, producing values for the class</context>
<context position="15250" citStr="McDowell et al., 2009" startWordPosition="2347" endWordPosition="2350">esents the SAME preference (i.e. the probability of i and j having the same label); the values for b1, b2, b3, and b4 are derived by sorting the relationships in the training data by similarity score, and separating them into intervals holding a proportion of SAME pairs equivalent to the nominated probability. This approach is similar to unsupervised discretisation (Kotsiantis and Kanellopoulos, 2006), except the intervals are arranged so that the output categories have a probabilistic interpretation. 5.1.3 Decoding Decoding is carried out using three techniques: (1) loopy belief propagation (McDowell et al., 2009); (2) mean-field; and (3) minimum-cut. Loopy Belief Propagation Loopy belief propagation is a message passing algorithm that can be expressed as: mi—,j(l) = Xα l&apos;EL ⎛ ⎞ ⎝ψi(l&apos;)ψij(l&apos;, l) mk—,i(l&apos;) ⎠ kENinDU\{j1 Y bi(l) = αψi(l) Y mk—,i(l) kENinDU where mi—,j is a message sent by document di to document dj, and α is a normalization constant that ensures that each message and each set of marginal probabilities sum to 1. The message flow from di to dj communicates the belief of di about the label of dj. The algorithm proceeds by making each node communicate with its neighbours until the messages </context>
</contexts>
<marker>McDowell, Gupta, Aha, 2009</marker>
<rawString>Luke K McDowell, Kalyan Moy Gupta, and David W Aha. 2009. Cautious collective classification. Journal of Machine Learning Research, 10:2777–2836.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric W Nooreen</author>
</authors>
<title>Computer Intensive Methods for Testing Hypothesis.</title>
<date>1989</date>
<publisher>Wiley and Sons Inc.,</publisher>
<location>New York, USA.</location>
<contexts>
<context position="22323" citStr="Nooreen, 1989" startWordPosition="3423" endWordPosition="3424">Type Description 1 2 3 4 5 Baseline Majority 49.83 49.83 49.83 49.83 49.83 Baseline Content-only 86.53 86.53 86.53 86.53 86.53 Dual Cosine similarity, min-cut 87.88 88.55? 88.89? 89.90? 90.57? Dual Cosine similarity, loopy belief 87.54 86.87 87.88 87.88 88.55 Dual Cosine similarity, mean-field 87.54 86.87 87.88 87.88 88.55 Iterative Average similarity score 87.54 89.90? 90.91? 90.91? 89.90? Table 4: Collective classification performance on BITTERLEMONS (* signifies a statistically significant improvement over the content-only baseline, p &lt; 0.05). using approximate randomisation with p &lt; 0.05 (Nooreen, 1989). Two baseline scores are shown in the tables for collective classification results: (1) “Majority” gives the performance of the simplest possible classifier, which classifies every instance with the label that is most frequent in training data; and (2) “Contentonly” gives the performance of the bag-of-words linear-kernel SVM used to perform base classification. 6.1 Collective Classifier Performance Table 3 shows the overall collective classifier performance on CONVOTE. The best performer is the iterative classifier with 4-grams, with an accuracy of 79.05%. This is a statistically significant </context>
</contexts>
<marker>Nooreen, 1989</marker>
<rawString>Eric W. Nooreen. 1989. Computer Intensive Methods for Testing Hypothesis. Wiley and Sons Inc., New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hyo-Jung Oh</author>
<author>Sung Hyon Myaeng</author>
<author>Mann-Ho Lee</author>
</authors>
<title>A practical hypertext categorization method using links and incrementally available class information.</title>
<date>2000</date>
<booktitle>In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>264--271</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="2716" citStr="Oh et al., 2000" startWordPosition="397" endWordPosition="400">entence (Ciaramita and Johnson, 2003; Johannsen et al., 2014). This paper explores the utility of homophily within joint models for document-level semantic classification, focusing specifically on tasks which are not associated with any explicit graph structure. That is, we examine whether implicit semantic document links can improve the results of a point-wise (content-based) classification approach. Explicit inter-document links have been variously shown to improve document classifier performance, based on information sources including hyperlinks in web documents (Slattery and Craven, 1998; Oh et al., 2000; Yang et al., 2002), direct name-references in congressional debates (Thomas et al., 2006; Burfoot et al., 2011; Stoyanov and Eisner, 2012), citations in scientific papers (Giles et al., 1998; Lu and Getoor, 2003; McDowell et al., 2007), and user mentions or retweets in social media (Jiang et al., 2011; Tan et al., 2011). However, document collections often don’t contain explicit inter-document links, limiting the practical usefulness of such methods. In this paper, we seek to expand the reach of research which incorporates linking information, in inducing implicit linking information between</context>
</contexts>
<marker>Oh, Myaeng, Lee, 2000</marker>
<rawString>Hyo-Jung Oh, Sung Hyon Myaeng, and Mann-Ho Lee. 2000. A practical hypertext categorization method using links and incrementally available class information. In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 264–271, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>115--124</pages>
<location>Ann Arbor, USA.</location>
<contexts>
<context position="6586" citStr="Pang and Lee, 2005" startWordPosition="991" endWordPosition="994">ailable, so content-only classification is likely to be inaccurate. By contrast, the supervised techniques in this paper deal with large amounts of labelled training data and relatively high content-only performance – 76% for CONVOTE and 87% for BITTERLEMONS. It is reasonable to assume that the types of similarity-based relationships derived for transductive semi-supervised classification would be ineffective in a supervised context. This conclusion is supported by an experiment that shows that the vocabularies of document pairs tend to overlap to similar degrees regardless of document class (Pang and Lee, 2005). 3 Corpora We experiment with two corpora in this research: CONVOTE and BITTERLEMONS. These two are selected on the grounds that they satisfy two intuitive criteria about types of text collections that may contain features that are not useful for content-only classification, but which may indicate relationships between pairs of documents: (1) the corpora both use an unconstrained prose vocabulary, which increases the likelihood that authors will use distinctive words or sequences of words that are not frequent enough to be useful in training, but which can be used to semantically relate pairs</context>
</contexts>
<marker>Pang, Lee, 2005</marker>
<rawString>Bo Pang and Lillian Lee. 2005. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 115–124, Ann Arbor, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John C Platt</author>
</authors>
<title>Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods.</title>
<date>1999</date>
<booktitle>Advances in Large Margin Classifiers,</booktitle>
<pages>61--74</pages>
<editor>In Alexander Smola, Peter Bartlett, and Bernhard Sch¨olkopf, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, USA.</location>
<contexts>
<context position="13468" citStr="Platt, 1999" startWordPosition="2076" endWordPosition="2077">ntent-only base classifier, we use the same bag-of-words SVM with binary (existencebased) unigram features as (Thomas et al., 2006). This classifier has been shown to be the best bagof-words model for BITTERLEMONS (Beigman Klebanov et al., 2010). As our relationship base classifier, we use the cosine similarity scores described above, calculated using n-grams of several different lengths. 5.1.2 Normalisation We use probabilistic SVM normalisation to convert the signed decision-plane distance output by the content-only classifier into the probability that the instance is in the positive class (Platt, 1999). For the relationship classifier, the technique used to convert the cosine similarity score into a classification preference needs to fit complex criteria. Preliminary experiments suggested that while the very highest similarity scores are good indicators of SAME relationships, classifier precision drops quickly as recall increases. To avoid polluting the classification graph with large numbers of lowquality links, the normalisation method should incorporate a threshold that discards a significant proportion of the test set pairs. We adopt the following binning technique to convert the cosine</context>
</contexts>
<marker>Platt, 1999</marker>
<rawString>John C. Platt. 1999. Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods. In Alexander Smola, Peter Bartlett, and Bernhard Sch¨olkopf, editors, Advances in Large Margin Classifiers, pages 61–74. MIT Press, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence R Rabiner</author>
<author>Biing-Hwang Juang</author>
</authors>
<title>An introduction to hidden markov models.</title>
<date>1986</date>
<journal>ASSP Magazine, IEEE,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="1872" citStr="Rabiner and Juang, 1986" startWordPosition="275" endWordPosition="278">ose instances, based primarily on either conditional dependence (i.e. one event is dependent on the outcome of another) or “homophily” (i.e. the tendency for connected instances to share various properties).1 Various joint models that combine the two have also been proposed, although in natural language processing at least, these have focused largely on conditional dependence, in the form of models such as 1In some tasks, it can also indicate heterophily, i.e. the tendency for connected instances to have contrasting properties, as we shall see for one of our two dataset. hidden Markov models (Rabiner and Juang, 1986) and conditional random fields (Lafferty et al., 2001), where independent properties of words, e.g., are combined with conditional dependencies based on their context of use to jointly predict the senses of all words in a given sentence (Ciaramita and Johnson, 2003; Johannsen et al., 2014). This paper explores the utility of homophily within joint models for document-level semantic classification, focusing specifically on tasks which are not associated with any explicit graph structure. That is, we examine whether implicit semantic document links can improve the results of a point-wise (conten</context>
</contexts>
<marker>Rabiner, Juang, 1986</marker>
<rawString>Lawrence R. Rabiner and Biing-Hwang Juang. 1986. An introduction to hidden markov models. ASSP Magazine, IEEE, 3(1):4–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prithviraj Sen</author>
<author>Galileo Mark Namata</author>
<author>Mustafa Bilgic</author>
<author>Lise Getoor</author>
<author>Brian Gallagher</author>
<author>Tina Eliassi-Rad</author>
</authors>
<title>Collective classification in network data.</title>
<date>2008</date>
<journal>AI Magazine,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="11935" citStr="Sen et al. (2008)" startWordPosition="1846" endWordPosition="1849">h similarity-based links. before 1948 was not his land. [AHMAD HARB (GUEST); PALESTINIAN] (4) This is being neglected and Sharon is having his way in brutalizing the Palestinian people in the hope that they will succumb and abandon their rights. [HAIDAR ABDEL SHAFI (GUEST); PALESTINIAN] For other examples and more justification of this methodology, see Burford (2013). 5 Collective Classification Two standard approaches to collective classification are: (1) the dual classifier approach; and (2) the iterative classifier approach. We briefly review these approaches below, but refer the reader to Sen et al. (2008), McDowell et al. (2009) and Burford (2013) for a more detailed methodological discussion. 5.1 Dual Classifier Approach The dual classifier approach is made up of three steps, as depicted in Figure 1: 1. Base classification: Produce base classifications using (1) a content-only classifier; and (2) a relationship classifier. The contentonly classifier makes a binary prediction: FOR and AGAINST for CONVOTE, and ISRAELI or PALESTINIAN for BITTERLEMONS. The relationship classifier indicates the preference that each document pair be SAME or not (SAME). 2. Normalisation: Normalise the scores, produc</context>
<context position="16068" citStr="Sen et al., 2008" startWordPosition="2484" endWordPosition="2487">inDU\{j1 Y bi(l) = αψi(l) Y mk—,i(l) kENinDU where mi—,j is a message sent by document di to document dj, and α is a normalization constant that ensures that each message and each set of marginal probabilities sum to 1. The message flow from di to dj communicates the belief of di about the label of dj. The algorithm proceeds by making each node communicate with its neighbours until the messages stabilise. The marginal probability is then derived by calculating bi(l). Loopy belief propagation was used in early collective classification work (Taskar et al., 2002) and has remained popular since (Sen et al., 2008; McDowell et al., 2009; Stoyanov and Eisner, 2012). Mean-field Mean-field is an alternative message passing algorithm, that can be expressed as: Y bi(l) = αψi(l) jENinD and is re-computed for each document until the marginal probabilities stabilise. Loopy belief propagation and mean-field have both been justified as variational methods for Markov random fields (Jordan et al., 1999; Weiss, 2001; Yedidia et al., 2005). Minimum Cut The minimum-cut technique involves formulating a binary collective classification task as a flow graph and finding solutions using standard methods for solving minimu</context>
</contexts>
<marker>Sen, Namata, Bilgic, Getoor, Gallagher, Eliassi-Rad, 2008</marker>
<rawString>Prithviraj Sen, Galileo Mark Namata, Mustafa Bilgic, Lise Getoor, Brian Gallagher, and Tina Eliassi-Rad. 2008. Collective classification in network data. AI Magazine, 29(3):93–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vikas Sindhwani</author>
<author>Prem Melville</author>
</authors>
<title>Documentword co-regularization for semi-supervised sentiment analysis.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 IEEE International Conference on Data Mining,</booktitle>
<pages>1025--1030</pages>
<location>Washington, USA.</location>
<contexts>
<context position="5696" citStr="Sindhwani and Melville, 2008" startWordPosition="852" endWordPosition="855"> are significant and potentially open the door to accuracy improvements on a range of document-level semantic tasks. 2 Related Work Previous work has dealt with the question of collective document classification using implicit interdocument relationships in two basic ways: 1. proximity: use a spatial or temporal dimension of the domain to relate documents (Agrawal et al., 2003; Goldberg et al., 2007; McDowell et al., 2009; Somasundaran et al., 2009). 2. similarity: relate documents via some notion of their content-based similarity (Blum and Chawla, 2001; Joachims, 2003; Takamura et al., 2007; Sindhwani and Melville, 2008; Jurgens, 2013) The work using similarity-based links is the closest to ours but is also strongly differentiated because it focuses on transductive semi-supervised classification. That task begins with the premise that only a small amount of labelled training data is available, so content-only classification is likely to be inaccurate. By contrast, the supervised techniques in this paper deal with large amounts of labelled training data and relatively high content-only performance – 76% for CONVOTE and 87% for BITTERLEMONS. It is reasonable to assume that the types of similarity-based relatio</context>
</contexts>
<marker>Sindhwani, Melville, 2008</marker>
<rawString>Vikas Sindhwani and Prem Melville. 2008. Documentword co-regularization for semi-supervised sentiment analysis. In Proceedings of the 2008 IEEE International Conference on Data Mining, pages 1025–1030, Washington, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Se´an Slattery</author>
<author>Mark Craven</author>
</authors>
<title>Combining statistical and relational methods for learning in hypertext domains.</title>
<date>1998</date>
<booktitle>In Proceedings of Inductive Logic Programming, 8th International Workshop,</booktitle>
<pages>38--52</pages>
<location>Madison, USA.</location>
<contexts>
<context position="2699" citStr="Slattery and Craven, 1998" startWordPosition="393" endWordPosition="396">s of all words in a given sentence (Ciaramita and Johnson, 2003; Johannsen et al., 2014). This paper explores the utility of homophily within joint models for document-level semantic classification, focusing specifically on tasks which are not associated with any explicit graph structure. That is, we examine whether implicit semantic document links can improve the results of a point-wise (content-based) classification approach. Explicit inter-document links have been variously shown to improve document classifier performance, based on information sources including hyperlinks in web documents (Slattery and Craven, 1998; Oh et al., 2000; Yang et al., 2002), direct name-references in congressional debates (Thomas et al., 2006; Burfoot et al., 2011; Stoyanov and Eisner, 2012), citations in scientific papers (Giles et al., 1998; Lu and Getoor, 2003; McDowell et al., 2007), and user mentions or retweets in social media (Jiang et al., 2011; Tan et al., 2011). However, document collections often don’t contain explicit inter-document links, limiting the practical usefulness of such methods. In this paper, we seek to expand the reach of research which incorporates linking information, in inducing implicit linking in</context>
</contexts>
<marker>Slattery, Craven, 1998</marker>
<rawString>Se´an Slattery and Mark Craven. 1998. Combining statistical and relational methods for learning in hypertext domains. In Proceedings of Inductive Logic Programming, 8th International Workshop, pages 38–52, Madison, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swapna Somasundaran</author>
<author>Galileo Namata</author>
<author>Lise Getoor</author>
<author>Janyce Wiebe</author>
</authors>
<title>Opinion graphs for polarity and discourse classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing,</booktitle>
<pages>66--74</pages>
<contexts>
<context position="5521" citStr="Somasundaran et al., 2009" startWordPosition="827" endWordPosition="830">ifier approach has generally been found to perform best (Thomas et al., 2006; Burfoot et al., 2011). While the work presented here is conceptually quite simple, the findings are significant and potentially open the door to accuracy improvements on a range of document-level semantic tasks. 2 Related Work Previous work has dealt with the question of collective document classification using implicit interdocument relationships in two basic ways: 1. proximity: use a spatial or temporal dimension of the domain to relate documents (Agrawal et al., 2003; Goldberg et al., 2007; McDowell et al., 2009; Somasundaran et al., 2009). 2. similarity: relate documents via some notion of their content-based similarity (Blum and Chawla, 2001; Joachims, 2003; Takamura et al., 2007; Sindhwani and Melville, 2008; Jurgens, 2013) The work using similarity-based links is the closest to ours but is also strongly differentiated because it focuses on transductive semi-supervised classification. That task begins with the premise that only a small amount of labelled training data is available, so content-only classification is likely to be inaccurate. By contrast, the supervised techniques in this paper deal with large amounts of labell</context>
</contexts>
<marker>Somasundaran, Namata, Getoor, Wiebe, 2009</marker>
<rawString>Swapna Somasundaran, Galileo Namata, Lise Getoor, and Janyce Wiebe. 2009. Opinion graphs for polarity and discourse classification. In Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing, pages 66–74, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veselin Stoyanov</author>
<author>Jason Eisner</author>
</authors>
<title>Minimumrisk training of approximate CRF-based NLP systems.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>120--130</pages>
<location>Montr´eal, Canada.</location>
<contexts>
<context position="2856" citStr="Stoyanov and Eisner, 2012" startWordPosition="419" endWordPosition="422">or document-level semantic classification, focusing specifically on tasks which are not associated with any explicit graph structure. That is, we examine whether implicit semantic document links can improve the results of a point-wise (content-based) classification approach. Explicit inter-document links have been variously shown to improve document classifier performance, based on information sources including hyperlinks in web documents (Slattery and Craven, 1998; Oh et al., 2000; Yang et al., 2002), direct name-references in congressional debates (Thomas et al., 2006; Burfoot et al., 2011; Stoyanov and Eisner, 2012), citations in scientific papers (Giles et al., 1998; Lu and Getoor, 2003; McDowell et al., 2007), and user mentions or retweets in social media (Jiang et al., 2011; Tan et al., 2011). However, document collections often don’t contain explicit inter-document links, limiting the practical usefulness of such methods. In this paper, we seek to expand the reach of research which incorporates linking information, in inducing implicit linking information between documents, and demonstrating that the resultant (noisy) network structure improves document classification accuracy. The intuition underlyi</context>
<context position="16119" citStr="Stoyanov and Eisner, 2012" startWordPosition="2493" endWordPosition="2496">nDU where mi—,j is a message sent by document di to document dj, and α is a normalization constant that ensures that each message and each set of marginal probabilities sum to 1. The message flow from di to dj communicates the belief of di about the label of dj. The algorithm proceeds by making each node communicate with its neighbours until the messages stabilise. The marginal probability is then derived by calculating bi(l). Loopy belief propagation was used in early collective classification work (Taskar et al., 2002) and has remained popular since (Sen et al., 2008; McDowell et al., 2009; Stoyanov and Eisner, 2012). Mean-field Mean-field is an alternative message passing algorithm, that can be expressed as: Y bi(l) = αψi(l) jENinD and is re-computed for each document until the marginal probabilities stabilise. Loopy belief propagation and mean-field have both been justified as variational methods for Markov random fields (Jordan et al., 1999; Weiss, 2001; Yedidia et al., 2005). Minimum Cut The minimum-cut technique involves formulating a binary collective classification task as a flow graph and finding solutions using standard methods for solving minimum-cut (maximum-flow) problems. We use the method de</context>
</contexts>
<marker>Stoyanov, Eisner, 2012</marker>
<rawString>Veselin Stoyanov and Jason Eisner. 2012. Minimumrisk training of approximate CRF-based NLP systems. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 120–130, Montr´eal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Takamura</author>
<author>Takashi Inui</author>
<author>Manabu Okumura</author>
</authors>
<title>Extracting semantic orientations of phrases from dictionary.</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>292--299</pages>
<location>Rochester, USA.</location>
<contexts>
<context position="5666" citStr="Takamura et al., 2007" startWordPosition="848" endWordPosition="851">te simple, the findings are significant and potentially open the door to accuracy improvements on a range of document-level semantic tasks. 2 Related Work Previous work has dealt with the question of collective document classification using implicit interdocument relationships in two basic ways: 1. proximity: use a spatial or temporal dimension of the domain to relate documents (Agrawal et al., 2003; Goldberg et al., 2007; McDowell et al., 2009; Somasundaran et al., 2009). 2. similarity: relate documents via some notion of their content-based similarity (Blum and Chawla, 2001; Joachims, 2003; Takamura et al., 2007; Sindhwani and Melville, 2008; Jurgens, 2013) The work using similarity-based links is the closest to ours but is also strongly differentiated because it focuses on transductive semi-supervised classification. That task begins with the premise that only a small amount of labelled training data is available, so content-only classification is likely to be inaccurate. By contrast, the supervised techniques in this paper deal with large amounts of labelled training data and relatively high content-only performance – 76% for CONVOTE and 87% for BITTERLEMONS. It is reasonable to assume that the typ</context>
</contexts>
<marker>Takamura, Inui, Okumura, 2007</marker>
<rawString>Hiroya Takamura, Takashi Inui, and Manabu Okumura. 2007. Extracting semantic orientations of phrases from dictionary. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics, pages 292–299, Rochester, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenhao Tan</author>
<author>Lillian Lee</author>
<author>Jie Tang</author>
<author>Long Jiang</author>
<author>Ming Zhou</author>
<author>Ping Li</author>
</authors>
<title>User-level sentiment analysis incorporating social networks.</title>
<date>2011</date>
<booktitle>In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>1397--1405</pages>
<location>San Diego, USA.</location>
<contexts>
<context position="3039" citStr="Tan et al., 2011" startWordPosition="452" endWordPosition="455">ks can improve the results of a point-wise (content-based) classification approach. Explicit inter-document links have been variously shown to improve document classifier performance, based on information sources including hyperlinks in web documents (Slattery and Craven, 1998; Oh et al., 2000; Yang et al., 2002), direct name-references in congressional debates (Thomas et al., 2006; Burfoot et al., 2011; Stoyanov and Eisner, 2012), citations in scientific papers (Giles et al., 1998; Lu and Getoor, 2003; McDowell et al., 2007), and user mentions or retweets in social media (Jiang et al., 2011; Tan et al., 2011). However, document collections often don’t contain explicit inter-document links, limiting the practical usefulness of such methods. In this paper, we seek to expand the reach of research which incorporates linking information, in inducing implicit linking information between documents, and demonstrating that the resultant (noisy) network structure improves document classification accuracy. The intuition underlying this work is that some types of documents have features which are either absent or ambiguous in training data, but which have 106 Proceedings of the Fourth Joint Conference on Lexi</context>
</contexts>
<marker>Tan, Lee, Tang, Jiang, Zhou, Li, 2011</marker>
<rawString>Chenhao Tan, Lillian Lee, Jie Tang, Long Jiang, Ming Zhou, and Ping Li. 2011. User-level sentiment analysis incorporating social networks. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 1397– 1405, San Diego, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Taskar</author>
<author>Pieter Abbeel</author>
<author>Daphne Koller</author>
</authors>
<title>Discriminative probabilistic models for relational data.</title>
<date>2002</date>
<booktitle>In Proceedings of the 18th Conference on Uncertainty in Artificial Intelligence,</booktitle>
<pages>485--492</pages>
<location>Alberta, Canada.</location>
<contexts>
<context position="16019" citStr="Taskar et al., 2002" startWordPosition="2475" endWordPosition="2478">,j(l) = Xα l&apos;EL ⎛ ⎞ ⎝ψi(l&apos;)ψij(l&apos;, l) mk—,i(l&apos;) ⎠ kENinDU\{j1 Y bi(l) = αψi(l) Y mk—,i(l) kENinDU where mi—,j is a message sent by document di to document dj, and α is a normalization constant that ensures that each message and each set of marginal probabilities sum to 1. The message flow from di to dj communicates the belief of di about the label of dj. The algorithm proceeds by making each node communicate with its neighbours until the messages stabilise. The marginal probability is then derived by calculating bi(l). Loopy belief propagation was used in early collective classification work (Taskar et al., 2002) and has remained popular since (Sen et al., 2008; McDowell et al., 2009; Stoyanov and Eisner, 2012). Mean-field Mean-field is an alternative message passing algorithm, that can be expressed as: Y bi(l) = αψi(l) jENinD and is re-computed for each document until the marginal probabilities stabilise. Loopy belief propagation and mean-field have both been justified as variational methods for Markov random fields (Jordan et al., 1999; Weiss, 2001; Yedidia et al., 2005). Minimum Cut The minimum-cut technique involves formulating a binary collective classification task as a flow graph and finding so</context>
</contexts>
<marker>Taskar, Abbeel, Koller, 2002</marker>
<rawString>Ben Taskar, Pieter Abbeel, and Daphne Koller. 2002. Discriminative probabilistic models for relational data. In Proceedings of the 18th Conference on Uncertainty in Artificial Intelligence, pages 485–492, Alberta, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Thomas</author>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Get out the vote: Determining support or opposition from congressional floor-debate transcripts.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>327--335</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="2806" citStr="Thomas et al., 2006" startWordPosition="410" endWordPosition="413"> utility of homophily within joint models for document-level semantic classification, focusing specifically on tasks which are not associated with any explicit graph structure. That is, we examine whether implicit semantic document links can improve the results of a point-wise (content-based) classification approach. Explicit inter-document links have been variously shown to improve document classifier performance, based on information sources including hyperlinks in web documents (Slattery and Craven, 1998; Oh et al., 2000; Yang et al., 2002), direct name-references in congressional debates (Thomas et al., 2006; Burfoot et al., 2011; Stoyanov and Eisner, 2012), citations in scientific papers (Giles et al., 1998; Lu and Getoor, 2003; McDowell et al., 2007), and user mentions or retweets in social media (Jiang et al., 2011; Tan et al., 2011). However, document collections often don’t contain explicit inter-document links, limiting the practical usefulness of such methods. In this paper, we seek to expand the reach of research which incorporates linking information, in inducing implicit linking information between documents, and demonstrating that the resultant (noisy) network structure improves docume</context>
<context position="4971" citStr="Thomas et al., 2006" startWordPosition="740" endWordPosition="743">n. We are the first to achieve this using a general-purpose setup, as applied to a range of datasets. Our results are achieved using n-gram overlap features for both the CONVOTE and BITTERLEMONS corpora, without the use of annotations for explicit semantic inter-document relationships. A second contribution of this work is the finding that simple iterative classifiers outperform more complex dual classifiers when using implicit inter-document links. This finding contradicts earlier work using explicit document links, where the dual classifier approach has generally been found to perform best (Thomas et al., 2006; Burfoot et al., 2011). While the work presented here is conceptually quite simple, the findings are significant and potentially open the door to accuracy improvements on a range of document-level semantic tasks. 2 Related Work Previous work has dealt with the question of collective document classification using implicit interdocument relationships in two basic ways: 1. proximity: use a spatial or temporal dimension of the domain to relate documents (Agrawal et al., 2003; Goldberg et al., 2007; McDowell et al., 2009; Somasundaran et al., 2009). 2. similarity: relate documents via some notion </context>
<context position="7560" citStr="Thomas et al., 2006" startWordPosition="1148" endWordPosition="1151">ora both use an unconstrained prose vocabulary, which increases the likelihood that authors will use distinctive words or sequences of words that are not frequent enough to be useful in training, but which can be used to semantically relate pairs of documents (c.f. newswire articles); and (2) the majority of the text content in both corpora is clearly relevant to the dimension of classification, i.e. there is minimal use of “boilerplate” or “background” material, so the pool from which to select task-relevant content to form interdocument semantic relationships is larger. 3.1 CONVOTE CONVOTE (Thomas et al., 2006) consists of US congressional speeches relating to a specific bill or resolution, and the ultimate vote of each speaker (“for” or “against”). The document classifier uses the text of each speech to predict the vote of the speaker. Three modifications are made to the corpus: (1) speeches by the same speaker are concatenated, to more naturally represent the requirement that each speaker only has one vote; (2) we drop 107 Total Tokens 1.2M Speeches 1699 Debates 53 Average speakers/speeches per debate 32 Average tokens per speech 735 Proportion of FOR speeches 49% Table 1: Corpus statistics for CO</context>
<context position="12987" citStr="Thomas et al., 2006" startWordPosition="2001" endWordPosition="2004">IAN for BITTERLEMONS. The relationship classifier indicates the preference that each document pair be SAME or not (SAME). 2. Normalisation: Normalise the scores, producing values for the classification preference functions, ψi, which can be input into a collective classification algorithm. 3. Decoding: Produce final classifications by optimally decoding the content-only and relationship level preferences using a collective classification algorithm. 5.1.1 Base classification For our content-only base classifier, we use the same bag-of-words SVM with binary (existencebased) unigram features as (Thomas et al., 2006). This classifier has been shown to be the best bagof-words model for BITTERLEMONS (Beigman Klebanov et al., 2010). As our relationship base classifier, we use the cosine similarity scores described above, calculated using n-grams of several different lengths. 5.1.2 Normalisation We use probabilistic SVM normalisation to convert the signed decision-plane distance output by the content-only classifier into the probability that the instance is in the positive class (Platt, 1999). For the relationship classifier, the technique used to convert the cosine similarity score into a classification pref</context>
</contexts>
<marker>Thomas, Pang, Lee, 2006</marker>
<rawString>Matt Thomas, Bo Pang, and Lillian Lee. 2006. Get out the vote: Determining support or opposition from congressional floor-debate transcripts. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 327–335, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yair Weiss</author>
</authors>
<title>Comparing the mean field method and belief propagation for approximate inference in MRFs.</title>
<date>2001</date>
<booktitle>In Manfred Opper and David Saad, editors, Advanced mean field methods: theory and practice,</booktitle>
<pages>229--239</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, USA.</location>
<contexts>
<context position="16465" citStr="Weiss, 2001" startWordPosition="2547" endWordPosition="2548">ilise. The marginal probability is then derived by calculating bi(l). Loopy belief propagation was used in early collective classification work (Taskar et al., 2002) and has remained popular since (Sen et al., 2008; McDowell et al., 2009; Stoyanov and Eisner, 2012). Mean-field Mean-field is an alternative message passing algorithm, that can be expressed as: Y bi(l) = αψi(l) jENinD and is re-computed for each document until the marginal probabilities stabilise. Loopy belief propagation and mean-field have both been justified as variational methods for Markov random fields (Jordan et al., 1999; Weiss, 2001; Yedidia et al., 2005). Minimum Cut The minimum-cut technique involves formulating a binary collective classification task as a flow graph and finding solutions using standard methods for solving minimum-cut (maximum-flow) problems. We use the method described by Blum and Chawla (2001) in an in-sample setting, which is equivalent to finding the optimal solution for the cost function for labellings: cost(Y) = X Xwi(Yi) + wr(di, dj) diED (di,dj)EE:Yi=,4Yj 5.1.4 Tuning The relative weights given to the content-only and relational classifiers can be tuned as follows (for CONVOTE, without loss of </context>
</contexts>
<marker>Weiss, 2001</marker>
<rawString>Yair Weiss. 2001. Comparing the mean field method and belief propagation for approximate inference in MRFs. In Manfred Opper and David Saad, editors, Advanced mean field methods: theory and practice, pages 229– 239. MIT Press, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yiming Yang</author>
<author>Se´an Slattery</author>
<author>Rayid Ghani</author>
</authors>
<title>A study of approaches to hypertext categorization.</title>
<date>2002</date>
<journal>Journal of Intelligent Information Systems,</journal>
<pages>18--2</pages>
<contexts>
<context position="2736" citStr="Yang et al., 2002" startWordPosition="401" endWordPosition="404">a and Johnson, 2003; Johannsen et al., 2014). This paper explores the utility of homophily within joint models for document-level semantic classification, focusing specifically on tasks which are not associated with any explicit graph structure. That is, we examine whether implicit semantic document links can improve the results of a point-wise (content-based) classification approach. Explicit inter-document links have been variously shown to improve document classifier performance, based on information sources including hyperlinks in web documents (Slattery and Craven, 1998; Oh et al., 2000; Yang et al., 2002), direct name-references in congressional debates (Thomas et al., 2006; Burfoot et al., 2011; Stoyanov and Eisner, 2012), citations in scientific papers (Giles et al., 1998; Lu and Getoor, 2003; McDowell et al., 2007), and user mentions or retweets in social media (Jiang et al., 2011; Tan et al., 2011). However, document collections often don’t contain explicit inter-document links, limiting the practical usefulness of such methods. In this paper, we seek to expand the reach of research which incorporates linking information, in inducing implicit linking information between documents, and demo</context>
</contexts>
<marker>Yang, Slattery, Ghani, 2002</marker>
<rawString>Yiming Yang, Se´an Slattery, and Rayid Ghani. 2002. A study of approaches to hypertext categorization. Journal of Intelligent Information Systems, 18(2-3):219– 241.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Yedidia</author>
<author>William Freeman</author>
<author>Yair Weiss</author>
</authors>
<title>Constructing free-energy approximations and generalized belief propagation algorithms.</title>
<date>2005</date>
<journal>IEEE Transactions on Information Theory,</journal>
<pages>51--2282</pages>
<contexts>
<context position="16488" citStr="Yedidia et al., 2005" startWordPosition="2549" endWordPosition="2552">rginal probability is then derived by calculating bi(l). Loopy belief propagation was used in early collective classification work (Taskar et al., 2002) and has remained popular since (Sen et al., 2008; McDowell et al., 2009; Stoyanov and Eisner, 2012). Mean-field Mean-field is an alternative message passing algorithm, that can be expressed as: Y bi(l) = αψi(l) jENinD and is re-computed for each document until the marginal probabilities stabilise. Loopy belief propagation and mean-field have both been justified as variational methods for Markov random fields (Jordan et al., 1999; Weiss, 2001; Yedidia et al., 2005). Minimum Cut The minimum-cut technique involves formulating a binary collective classification task as a flow graph and finding solutions using standard methods for solving minimum-cut (maximum-flow) problems. We use the method described by Blum and Chawla (2001) in an in-sample setting, which is equivalent to finding the optimal solution for the cost function for labellings: cost(Y) = X Xwi(Yi) + wr(di, dj) diED (di,dj)EE:Yi=,4Yj 5.1.4 Tuning The relative weights given to the content-only and relational classifiers can be tuned as follows (for CONVOTE, without loss of generality): ψ&apos;i(FOR) =</context>
</contexts>
<marker>Yedidia, Freeman, Weiss, 2005</marker>
<rawString>Jonathan Yedidia, William Freeman, and Yair Weiss. 2005. Constructing free-energy approximations and generalized belief propagation algorithms. IEEE Transactions on Information Theory, 51:2282–2312.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>