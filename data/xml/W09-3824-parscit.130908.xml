<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.936573">
Cross Parser Evaluation and Tagset Variation : a French Treebank Study
</title>
<author confidence="0.815717">
Djamé Seddah†, Marie Candito$ and Benoît Crabbé$
</author>
<note confidence="0.5486475">
† Université Paris-Sorbonne
LALIC &amp; INRIA (ALPAGE)
28 rue Serpente
F-75006 Paris France
</note>
<sectionHeader confidence="0.97907" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999995192307692">
This paper presents preliminary investiga-
tions on the statistical parsing of French by
bringing a complete evaluation on French
data of the main probabilistic lexicalized
and unlexicalized parsers first designed
on the Penn Treebank. We adapted the
parsers on the two existing treebanks of
French (Abeillé et al., 2003; Schluter and
van Genabith, 2007). To our knowledge,
mostly all of the results reported here are
state-of-the-art for the constituent parsing
of French on every available treebank. Re-
garding the algorithms, the comparisons
show that lexicalized parsing models are
outperformed by the unlexicalized Berke-
ley parser. Regarding the treebanks, we
observe that, depending on the parsing
model, a tag set with specific features
has direct influence over evaluation re-
sults. We show that the adapted lexical-
ized parsers do not share the same sensi-
tivity towards the amount of lexical ma-
terial used for training, thus questioning
the relevance of using only one lexicalized
model to study the usefulness of lexical-
ization for the parsing of French.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999734083333333">
The development of large scale symbolic gram-
mars has long been a lively topic in the French
NLP community. Surprisingly, the acquisition of
probabilistic grammars aiming at stochastic pars-
ing, using either supervised or unsupervised meth-
ods, has not attracted much attention despite the
availability of large manually syntactic annotated
data for French. Nevertheless, the availability
of the Paris 7 French Treebank (Abeillé et al.,
2003), allowed (Dybro-Johansen, 2004) to carry
out the extraction of a Tree Adjoining Grammar
(Joshi, 1987) and led (Arun and Keller, 2005)
</bodyText>
<note confidence="0.890462">
$ Université Paris 7
INRIA (ALPAGE)
30 rue du Château des Rentiers
F-75013 Paris France
</note>
<bodyText confidence="0.999928951219512">
to induce the first effective lexicalized parser for
French. Yet, as noted by (Schluter and van Gen-
abith, 2007), the use of the treebank was “chal-
lenging”. Indeed, before carrying out successfully
any experiment, the authors had to perform a deep
restructuring of the data to remove errors and in-
consistencies. For the purpose of building a sta-
tistical LFG parser, (Schluter and van Genabith,
2007; Schluter and van Genabith, 2008) have re-
annotated a significant subset of the treebank with
two underlying goals: (1) designing an annota-
tion scheme that matches as closely as possible
the LFG theory (Kaplan and Bresnan, 1982) and
(2) ensuring a more consistent annotation. On the
other hand, (Crabbé and Candito, 2008) showed
that with a new released and corrected version of
the treebank1 it was possible to train statistical
parsers from the original set of trees. This path
has the advantage of an easier reproducibility and
eases verification of reported results.
With the problem of the usability of the data
source being solved, the question of finding one
or many accurate language models for parsing
French raises. Thus, to answer this question,
this paper reports a set of experiments where
five algorithms, first designed for the purpose of
parsing English, have been adapted to French:
a PCFG parser with latent annotation (Petrov et
al., 2006), a Stochastic Tree Adjoining Grammar
parser (Chiang, 2003), the Charniak’s lexicalized
parser (Charniak, 2000) and the Bikel’s implemen-
tation of Collins’ Model 1 and 2 (Collins, 1999)
described in (Bikel, 2002). To ease further com-
parisons, we report results on two versions of the
treebank: (1) the last version made available in
December 2007, hereafter FTB , and described
in (Abeillé and Barrier, 2004) and the (2) LFG
inspired version of (Schluter and van Genabith,
2007).
The paper is structured as follows : After a brief
presentation of the treebanks, we discuss the use-
</bodyText>
<footnote confidence="0.673298">
1This has been made available in December 2007.
</footnote>
<page confidence="0.944752">
150
</page>
<note confidence="0.8821775">
Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 150–161,
Paris, October 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999308333333333">
fulness of testing different parsing frameworks
over two parsing paradigms before introducing
our experimental protocol and presenting our re-
sults. Finally, we discuss and compare with re-
lated works on cross-language parser adaptation,
then we conclude.
</bodyText>
<sectionHeader confidence="0.996522" genericHeader="introduction">
2 Treebanks for French
</sectionHeader>
<bodyText confidence="0.99924525">
This section provides a brief overview to the cor-
pora on which we report results: the French Tree-
bank (FTB) and the Modified French Treebank
(MFT).
</bodyText>
<subsectionHeader confidence="0.959234">
2.1 The French Treebank
</subsectionHeader>
<bodyText confidence="0.999893375">
THE FRENCH TREEBANK is the first treebank
annotated and manually corrected for French. It
is the result of a supervised annotation project of
newspaper articles from Le Monde (Abeillé and
Barrier, 2004). The corpus is annotated with la-
belled constituent trees augmented with morpho-
logical annotations and functional annotations of
verbal dependents as shown below:
</bodyText>
<figure confidence="0.999105826086956">
&lt;SENT&gt;
&lt;NP fct=&amp;quot;SUJ&amp;quot;&gt;
&lt;w cat=&amp;quot;D&amp;quot; lemma=&amp;quot;le&amp;quot; mph=&amp;quot;ms&amp;quot; subcat=&amp;quot;def&amp;quot;&gt;le&lt;/w&gt;
&lt;w cat=&amp;quot;N&amp;quot; lemma=&amp;quot;bilan&amp;quot; mph=&amp;quot;ms&amp;quot; subcat=&amp;quot;C&amp;quot;&gt;bilan&lt;/w&gt;
&lt;/NP&gt;
&lt;VN&gt;
&lt;w cat=&amp;quot;ADV&amp;quot; lemma=&amp;quot;ne&amp;quot; subcat=&amp;quot;neg&amp;quot;&gt;n’&lt;/w&gt;
&lt;w cat=&amp;quot;V&amp;quot; lemma=&amp;quot;être&amp;quot; mph=&amp;quot;P3s&amp;quot; subcat=&amp;quot;&amp;quot;&gt;est&lt;/w&gt;
&lt;/VN&gt;
&lt;AdP fct=&amp;quot;MOD&amp;quot;&gt;
&lt;w compound=&amp;quot;yes&amp;quot; cat=&amp;quot;ADV&amp;quot; lemma=&amp;quot;peut-être&amp;quot;&gt;
&lt;w catint=&amp;quot;V&amp;quot;&gt;peut&lt;/w&gt;
&lt;w catint=&amp;quot;PONCT&amp;quot;&gt;-&lt;/w&gt;
&lt;w catint=&amp;quot;V&amp;quot;&gt;être&lt;/w&gt;
&lt;/w&gt;
&lt;w cat=&amp;quot;ADV&amp;quot; lemma=&amp;quot;pas&amp;quot; subcat=&amp;quot;neg&amp;quot;&gt;pas&lt;/w&gt;
&lt;/AdP&gt;
&lt;AP fct=&amp;quot;ATS&amp;quot;&gt;
&lt;w cat=&amp;quot;ADV&amp;quot; lemma=&amp;quot;aussi&amp;quot;&gt;aussi&lt;/w&gt;
&lt;w cat=&amp;quot;A&amp;quot; lemma=&amp;quot;sombre&amp;quot; mph=&amp;quot;ms&amp;quot; subcat=&amp;quot;qual&amp;quot;&gt;sombre&lt;/w&gt;
&lt;/AP&gt;
&lt;w cat=&amp;quot;PONCT&amp;quot; lemma=&amp;quot;.&amp;quot; subcat=&amp;quot;S&amp;quot;&gt;.&lt;/w&gt;
&lt;/SENT&gt;
</figure>
<figureCaption confidence="0.942884333333333">
Figure 1: Simplified example of the FTB: ”Le bi-
lan n’est peut-être pas aussi sombre.” (i.e. The
result is perhaps not as bleak)
</figureCaption>
<bodyText confidence="0.999936318181818">
Though the original release (in 2000) consists
of 20,648 sentences, the subset of 12351 function-
ally annotated sentences is known to be more con-
sistently annotated and therefore is the one used
in this work. Its key properties, compared with
the Penn Treebank (hereafter PTB, (Marcus et al.,
1994)), are the following:
Size: The FTB consists of 385,458 tokens and
12,351 sentences, that is the third of the PTB. It
also entails that the average length of a sentence
is 27.48 tokens. By contrast the average sentence
length in the PTB is 24 tokens.
Inflection: French morphology is richer than
English and leads to increased data sparseness is-
sues for the purpose of statistical parsing. There
are 24,098 types in the FTB, entailing an average
of 16 tokens occurring for each type.
A Flat Annotation Scheme: Both the FTB
and the PTB are annotated with constituent trees.
However, the annotation scheme is flatter in the
FTB. For instance, there are no VPs for finite verbs
and only one sentential level for clauses or sen-
tences whether or not introduced by a complemen-
tizer. Only verbal nucleus (VN) is annotated and
comprises the verb, its clitics, auxiliaries, adverbs
and surrounding negation.
While X-bar inspired constituents are supposed
to contain all the syntactic information, in the FTB
the shape of the constituents does not necessar-
ily express unambiguously the type of dependency
existing between a head and a dependent appear-
ing in the same constituent. Yet, this is crucial to
extract the underlying predicate-argument struc-
tures. This has led to a “flat” annotation scheme,
completed with functional annotations that inform
on the type of dependency existing between a verb
and its dependents. This was chosen for French
to reflect, for instance, the possibility to mix post-
verbal modifiers and complements (Figure 2), or
to mix post-verbal subject and post-verbal indirect
complements : a post verbal NP in the FTB can
correspond to a temporal modifier, (most often) a
direct object, or an inverted subject, and all cases,
other subcategorized complements may appear.
</bodyText>
<sectionHeader confidence="0.601384" genericHeader="method">
SENT
</sectionHeader>
<figureCaption confidence="0.6529225">
Figure 2: Two examples of post-verbal NPs : a
temporal modifier (a) and a direct object (b)
Compounds: Compounds are explicitly anno-
tated and very frequent in the treebank: 14.52% of
tokens are part of a compound (see the compound
peut-être ’perhaps’ in Figure 1 ). They include
</figureCaption>
<figure confidence="0.997564108695652">
NP-SUJ
PP-AOBJ
VN
NP-OBJ
N
banque
(b) The Council has notified his decision to the bank
D
Le
N
Conseil
V
V
a notifié
N
sa décision
D
P
à
D
la
NP
SENT
NP-SUJ
PP-AOBJ
VN
NP-MOD
D N
une lettre
V
envoyée
N
semaine
A
dernière
NP
aux N
salariés
V
avait
V
été
D
la
P
(a) A letter had been sent last week to the employees
</figure>
<page confidence="0.994318">
151
</page>
<bodyText confidence="0.9994962">
digit numbers (written with spaces in French) (e.g.
10 000), frozen compounds (eg. pomme de terre
’potato’) but also named entities or sequences
whose meaning is compositional but where inser-
tion is rare or difficult (e.g. garde d’enfant ’child
care’). As noted by (Arun and Keller, 2005), com-
pounds in French may exhibit ungrammatical se-
quences of tags as in à la va vite ’in a hurry’
: Prep+ Det+ finite verb + adverb or can in-
clude “words” which do not exist outside a com-
pound (e.g hui in aujourd’hui ’today’). Therefore,
compounds receive a two-level annotation : con-
stituent parts are described in a subordinate level
using the same POS tagset as the genuine com-
pound POS. This makes it more difficult to extract
a proper grammar from the FTB without merged
compounds2. This is why, following (Arun and
Keller, 2005) and (Schluter and van Genabith,
2007), all the treebanks used in this work contain
compounds.
</bodyText>
<figure confidence="0.4559685">
AdP
FTB initial analysis MFT modification
</figure>
<figureCaption confidence="0.9860615">
Figure 3: Increased stratification in the MFT : “en-
core pas très bien” (’still not very well’)
</figureCaption>
<figure confidence="0.94238772">
XP1
..Y.. X1 ..Z.. COORD
C XP2
XP1
AdP ADV
AdP
AdP ADV
AdP
ADV
encore
bien
ADV
pas
très
ADV
bien
ADV
encore
ADV
très
ADV
pas
COORD-XP
2.2 The Modified French Treebank
XP C XP2
</figure>
<bodyText confidence="0.995497833333333">
THE MODIFIED FRENCH TREEBANK (MFT) has
been derived from the FTB by (Schluter and van
Genabith, 2008) as a basis for a PCFG-based Lexi-
cal Functional Grammar induction process (Cahill
et al., 2004) for French. The corpus is a subset of
4739 sentences extracted from the original FTB.
The MFT further introduces formal differences of
two kinds with respect to the original FTB: struc-
tural and labeling modifications.
Regarding structural changes, the main transfor-
mations include increased rule stratification (Fig.
3), coordination raising (Fig. 5).
Moreover, the MFT’s authors introduced new
treatments of linguistic phenomena that were not
covered by their initial source treebank. Those
include, for example, analysis for ’It’-cleft con-
structions.3 Since the MFT was designed for the
purpose of improving the task of grammar induc-
tion, the MFT’s authors also refined its tag set by
propagating information (such as mood features
added to VN node labels), and added functional
paths4 to the original function labels. The modifi-
cations introduced in the MFT meet better the for-
mal requirements of the LFG architecture set up
</bodyText>
<footnote confidence="0.998195666666667">
2Consider the case of the compound peut-être ’perhaps’
whose POS is ADV, its internal structure (Fig. 1) would lead
to a CFG rule of the form ADV −→ V V.
3See pages 2-3 of (Schluter and van Genabith, 2007) for
details.
4Inspired by the LFG framework (Dalrymple, 2001).
</footnote>
<figure confidence="0.279991">
..Y.. X1 ..Z..
</figure>
<figureCaption confidence="0.8833725">
Figure 5: Coordinated structures in the general
case, for FTB (up) and MFT (down)
</figureCaption>
<bodyText confidence="0.99653925">
by (Cahill et al., 2004) and reduce the size of the
grammars extracted from the treebank. MFT has
also undergone a phase of error mining and an ex-
tensive manual correction.
</bodyText>
<subsectionHeader confidence="0.998431">
2.3 Coordination in French Treebanks
</subsectionHeader>
<bodyText confidence="0.999975823529412">
One of the key differences between the two French
treebanks is the way they treat coordinate struc-
tures. Whereas the FTB represents them with an
adjunction of a COORD phrase as a sister or a
daughter of the coordinated element, the MFT in-
troduces a treatment closer to the one used in the
PTB to describe such structures. As opposed to
(Arun and Keller, 2005) who decided to transform
the FTB’s coordinations to match the PTB’s analy-
sis, the COORD label is not removed but extended
to include the coordinated label (Fig. 5).
In Figure 5, we show the general coordination
structure in the FTB, and the corresponding mod-
ified structure in the MFT. A more complicated
modification concerns the case of VP coordina-
tions. (Abeillé et al., 2003) argue for a flat repre-
sentation with no VP-node for French, and this is
</bodyText>
<page confidence="0.972211">
152
</page>
<figure confidence="0.998505290322581">
SENT SENT
COORD-VP
VN
Ssub
C-C
VP
VP
NP
CL
Elle
NP
V
CL
Elle
et
NP
Ssub
ajoute
douze points de désaccord
VN-finite
V-finite
ajoute
VN-finite
V-finite
présente
que ...
COORD
que ... CC VN
et V
présente
douze points de désaccord
</figure>
<figureCaption confidence="0.795081">
Figure 4: Two representations of “VP coordinations” for the sentence She adds that ... and presents
twelve sticking points: in the FTB (left) and in the MFT (right)
</figureCaption>
<bodyText confidence="0.9979772">
particularly justified in some cases of subject-verb
inversion. Nevertheless, VP phrases are used in
the FTB for non-finite VPs only (nodes VPinf and
VPpart). In the MFT, finite VPs were introduced
to handle VP coordinations. In those cases, the
FTB annotation scheme keeps a flat structure (Fig-
ure 4, left), where the COORD phrase has to be in-
terpreted as a coordinate of the VN node; whereas
finite VP nodes are inserted in the MFT (Figure 4,
right).
</bodyText>
<subsectionHeader confidence="0.976963">
2.4 Summary
</subsectionHeader>
<bodyText confidence="0.999961625">
In Table 2, we describe the annotation schemes of
the treebanks and we provide in Table 1 a numeric
summary of some relevant different features be-
tween these two treebanks. The reported numbers
take into account the base syntactic category labels
without functions, part-of-speech tags without any
morpho-syntactic information (ie. no ’gender’ or
number’).
</bodyText>
<table confidence="0.902612857142857">
properties FTB MFT
# of sentences 12351 4739
Average sent. length 27.48 28.38
Average node branching 2.60 2.11
PCFG size (without term. prod.) 14874 6944
# ofNT symbols 13 39
# of POS tags 15 27
</table>
<tableCaption confidence="0.997847">
Table 1: Treebanks Properties
</tableCaption>
<sectionHeader confidence="0.957372" genericHeader="method">
3 Parsing Algorithms
</sectionHeader>
<bodyText confidence="0.999886636363636">
Although Probabilistic Context Free Grammars
(PCFG) are a baseline formalism for probabilis-
tic parsing, it is well known that they suffer from
two problems: (a) The independence assumptions
made by the model are too strong, and (b) For Nat-
ural Language Parsing, they do not take into ac-
count lexical probabilities. To date, most of the
results on statistical parsing have been reported
for English. Here we propose to investigate how
to apply these techniques to another language –
French – by testing two distinct enhancements
</bodyText>
<figure confidence="0.960457583333333">
FTB MFT
POS tags A ADV C CL D ET A A_card ADV
I N P P+D P+PRO ADV_int AD-
PONCT PREF PRO Vne A_int CC CL
V C_S D D_card
ET I N N_card
P P+D PONCT
P+PRO_rel PREF
PRO PRO_card
PRO_int PRO_rel
V_finite V_inf
V_part
</figure>
<construct confidence="0.6703933">
NT labels AP AdP COORD NP AdP AdP_int AP
PP SENT Sint Srel AP_int COORD_XP
Ssub VN VPinf VP- COORD_UC CO-
part ORD_unary NC
NP NP_int NP_rel
PP PP_int PP_rel
SENT Sint Srel Ssub
VN finite VN inf
VN:part VP VPinf
VPpart VPpart_rel
</construct>
<tableCaption confidence="0.87555">
Table 2: FTB’s and MFT’s annotation schemes
</tableCaption>
<bodyText confidence="0.9995572">
over the bare PCFG model carried out by two class
of parser models: an unlexicalized model attempt-
ing to overcome problem (a) and 3 different lex-
icalized models attempting to overcome PCFG’s
problems (a) and (b)5.
</bodyText>
<subsectionHeader confidence="0.999474">
3.1 Lexicalized algorithms
</subsectionHeader>
<bodyText confidence="0.999885166666667">
The first class of algorithms used are lexicalized
parsers of (Collins, 1999; Charniak, 2000; Chi-
ang, 2003). The insight underlying the lexical-
ized algorithms is to model lexical dependencies
between a governor and its dependants in order to
improve attachment choices.
Even though it has been proven numerous times
that lexicalization was useful for parsing the Wall
Street Journal corpus (Collins, 1999; Charniak,
2000), the question of its relevance for other lan-
guages has been raised for German (Dubey and
Keller, 2003; Kübler et al., 2006) and for French
</bodyText>
<footnote confidence="0.9659955">
5Except (Chiang, 2003) which is indeed a TREE IN-
SERTION GRAMMAR (Schabes and Waters, 1995) parser but
which must extract a lexicalized grammar from the set of con-
text free rules underlying a treebank.
</footnote>
<page confidence="0.998607">
153
</page>
<bodyText confidence="0.999942957446809">
(Arun and Keller, 2005) where the authors ar-
gue that French parsing benefits from lexicaliza-
tion but the treebank flatness reduces its impact
whereas (Schluter and van Genabith, 2007) argue
that an improved annotation scheme and an im-
proved treebank consistency should help to reach
a reasonable state of the art. As only Collins’ mod-
els 1 &amp; 2 have been used for French as instances
of lexicalised parsers, we also report results from
the history-based generative parser of (Charniak,
2000) and the Stochastic Tree Insertion Grammar
parser of (Chiang, 2003) as well as (Bikel, 2002)’s
implementation of the Collins’ models 1 &amp; 2
(Collins, 1999). Most of the lexicalized parsers
we use in this work are well known and since their
releases, almost ten years ago, their core parsing
models still provide state-of-the-art performance
on the standard test set for English.6 We insist on
the fact that one of the goals of this work was to
evaluate raw performance of well known parsing
models on French annotated data. Thus, we have
not considered using more complex parsing archi-
tectures that makes use of reranking (Charniak and
Johnson, 2005) or self-training (McClosky et al.,
2006) in order to improve the performance of a
raw parsing model. Furthermore, studying and de-
signing a set of features for a reranking parser was
beyond the scope of this work. However, we did
use some of these models in a non classical way,
leading us to explore a Collins’ model 2 variation,
named model X, and a Stochastic Tree Adjoining
Grammar (Schabes, 1992; Resnik, 1992) variant7 ,
named Spinal Stochastic Tree Insertion Grammars
(hereafter SPINAL STIG), which was first used to
validate the heuristics used by our adaptation of
the Bikel’s parser to French. The next two subsec-
tions introduce these variations.
Collins’ Model 2 variation During the ex-
ploratory phase of this work, we found out that a
specific instance of the Collins’ model 2 leads to
significantly better performance than the canoni-
cal model when applied to any of the French Tree-
banks. The difference between those two models
relies on the way probabilities associated to so-
called “modifier non terminals” nodes are handled
by the generative model.
To explain the difference, let us recall that
</bodyText>
<footnote confidence="0.9901688">
6Section 23 of the Wall Street Journal section of the PTB.
7The formalism actually used in this parser is a con-
text free variant of Tree Adjoining Grammar, Tree Insertion
Grammars (TIG), first introduced in (Schabes and Waters,
1995).
</footnote>
<bodyText confidence="0.9910905">
a lexicalized PCFG can roughly be described
as a set of stochastic rules of the form:
</bodyText>
<equation confidence="0.92265">
P → Ln Ln−1 ..L1 H R1 .. Rm−1 Rm
</equation>
<bodyText confidence="0.998798266666667">
where Li, H, Ri and P are all lexicalized non
terminals; P inherits its head from H (Bikel,
2004). The Collins’ model 2 deterministically
labels some nodes of a rule to be arguments of
a given Head and the remaining nodes are con-
sidered to be modifier non terminals (hereafter
MNT).
In this model, given a left-hand side symbol, the
head and its arguments are first generated and then
the MNT are generated from the head outward.
In Bikel’s implementation of Collins’s model 2
(Bikel, 2004), the MNT parameter class is the fol-
lowing (for clarity, we omit the verb intervening,
subcat and side features which are the same in
both classes) :
</bodyText>
<listItem confidence="0.956984">
• model 2 (canonical) :
</listItem>
<equation confidence="0.399843">
p(M(t)i|P, H, wh, th, map(Mi−1))
</equation>
<bodyText confidence="0.999144142857143">
Where M(t)i is the POS tag of the ith MNT,
P the parent node label, H the head node
label, wh the head word and th its POS
tag. map(Mi−1) is a mapped version of
the previously-generated modifier added to
the conditioning context (see below for its
definition).
</bodyText>
<equation confidence="0.970109">
+START+ if i = 0
CC if Mi = CC
+PUNC+ if Mi =,
or Mi =:
+OTHER+ otherwise
</equation>
<bodyText confidence="0.99433225">
Whereas in the model we call X 8, the mapping
version of the previously generated non terminal is
replaced by a complete list of all previously gen-
erated non terminals.
</bodyText>
<listItem confidence="0.991561">
• Model X :
</listItem>
<equation confidence="0.362473">
p(M(t)i|P, H, wh, th, (Mi−1, ..., Mi−k))
</equation>
<bodyText confidence="0.994196142857143">
The FTB being flatter than the PTB, one can con-
jecture that giving more context to generate MNT
will improve parsing accuracy, whereas clustering
MNT in a X-bar scheme must help to reduce data
sparseness. Note that the Model X, to the best of
our knowledge, is not documented but included in
Bikel’s parser.
</bodyText>
<footnote confidence="0.987771666666667">
8See file NonTerminalModelStructure1.java in Bikel’s
parser source code at http://www.cis.upenn.edu/
~dbikel/download/dbparser/1.2/install.sh.
</footnote>
<equation confidence="0.9707405">
map(Mi) = I
I
</equation>
<page confidence="0.997524">
154
</page>
<bodyText confidence="0.99998856">
The spinal STIG model In the case of the STIG
parser implementation, having no access to an
argument adjunct table leads it to extract a gram-
mar where almost all elementary trees consist of
a suite of unary productions from a lexical anchor
to its maximal projection (i.e. spine9). Therefore
extracted trees have no substitution node.
Moreover, the probability model, being split
between lexical anchors and tree templates,
allows a very coarse grammar that contains, for
example, only 83 tree templates for one treebank
instantiation, namely the FTB-CC (cf. section 5).
This behavior, although not documented10, is
close to Collins’ model 1, which does not use any
argument adjunct distinction information, and led
to results interesting enough to be integrated as
the “Chiang Spinal” model in our parser set. It
should be noted that, recently, the use of similar
models has been independently proposed in
(Carreras et al., 2008) with the purpose of getting
a richer parsing model that can use non local
features and in (Sangati and Zuidema, 2009) as a
mean of extracting a Lexicalized Tree Substitution
Grammar. In their process, the first extracted
grammar is actually a spinal STIG.
</bodyText>
<subsectionHeader confidence="0.99908">
3.2 Unlexicalized Parser
</subsectionHeader>
<bodyText confidence="0.995980947368421">
As an instance of an unlexicalized parser, the last
algorithm we use is the Berkeley unlexicalized
parser (BKY) of (Petrov et al., 2006). This algo-
rithm is an evolution of treebank transformation
principles aimed at reducing PCFG independence
assumptions (Johnson, 1998; Klein and Manning,
2003).
Treebank transformations may be of two kinds
(1) structure transformation and (2) labelling
transformations. The Berkeley parser concentrates
on (2) by recasting the problem of acquiring an
optimal set of non terminal symbols as an semi-
supervised learning problem by learning a PCFG
with Latent annotations (PCFG-LA): given an ob-
served PCFG induced from the treebank, the latent
grammar is generated by combining every non ter-
minal of the observed grammar to a predefined set
H of latent symbols. The parameters of the latent
grammar are estimated from the actual treebank
</bodyText>
<footnote confidence="0.8948138">
9Not to be confused with the “spine” in the Tree Adjunct
Grammar (Joshi, 1987) framework which is the path from a
foot node to the root node.
10We mistakenly “discovered” this obvious property dur-
ing the preliminary porting phase.
</footnote>
<bodyText confidence="0.8746305">
trees (or observed trees) using a specific instanci-
ation of EM.
</bodyText>
<sectionHeader confidence="0.996688" genericHeader="method">
4 Experimental protocol
</sectionHeader>
<bodyText confidence="0.9999775">
In this section, we specify the settings of the
parsers for French, the evaluation protocol and the
different instantiations of the treebanks we used
for conducting the experiments.
</bodyText>
<subsectionHeader confidence="0.997637">
4.1 Parsers settings
</subsectionHeader>
<bodyText confidence="0.999775">
Head Propagation table All lexicalized parsers
reported in this paper use head propagation tables.
Adapting them to the French language requires
to design French specific head propagation
rules. To this end, we used those described by
(Dybro-Johansen, 2004) for training a Stochastic
Tree Adjoining Grammar parser on French. From
this set, we built a set of meta-rules that were
automatically derived to match each treebank
annotation scheme.
As the Collins Model 2 and the STIG model need
to distinguish between argument and adjunct
nodes to acquire subcategorization frames prob-
abilities, we implemented an argument-adjunct
distinction table that takes advantage of the
function labels annotated in the treebank. This is
one of the main differences with the experiments
described in (Arun and Keller, 2005) and (Dybro-
Johansen, 2004) where the authors had to rely
only on the very flat treebank structure without
function labels, to annotate the arguments of a
head.
Morphology and typography adaptation Fol-
lowing (Arun and Keller, 2005), we adapted
the morphological treatment of unknown words
proposed for French when needed (BKY’s and
BIKEL’s parser). This process clusters unknown
words using typographical and morphological in-
formation. Since all lexicalized parsers contain
specific treatments for the PTB typographical con-
vention, we automatically converted the original
punctuation parts of speech to the PTB’s punctua-
tion tag set.
</bodyText>
<subsectionHeader confidence="0.96329">
4.2 Experimental details
</subsectionHeader>
<bodyText confidence="0.9998626">
For the BKY parser, we use the Berkeley imple-
mentation, with an initial horizontal markoviza-
tion h=0, and 5 split/merge cycles. For the
COLLINS’ MODEL, we use the standard param-
eters set for the model 2, without any argu-
</bodyText>
<page confidence="0.998175">
155
</page>
<bodyText confidence="0.998748833333333">
ment adjunct distinction table, as a rough emu-
lation of the COLLINS MODEL 1. The same set
of parameters used for COLLINS’ MODEL 2 is
used for the MODEL X except for the parameters
“Mod{Nonterminal,Word}ModelStructureNumber” set to
1 instead of 2.
</bodyText>
<subsectionHeader confidence="0.995738">
4.3 Protocol
</subsectionHeader>
<bodyText confidence="0.9999735">
For all parsers, we report parsing results with the
following experimental protocol: a treebank is di-
vided in 3 sections : test (first 10%), development
(second 10%) and training (remaining 80%). The
MFT partition set is the canonical one (3800 sen-
tences for training, 509 for the dev set and the last
430 for the test set). We systematically report the
results with compounds merged. Namely, we pre-
process the treebank in order to turn each com-
pound into a single token both for training and test.
</bodyText>
<subsectionHeader confidence="0.977036">
4.4 Evaluation metrics
</subsectionHeader>
<bodyText confidence="0.99991675">
Constituency Evaluation: we use the standard
labeled bracketed PARSEVAL metric for evalua-
tion (Black et al., 1991), along with unlabeled
dependency evaluation, which is described as a
more annotation-neutral metric in (Rehbein and
van Genabith, 2007). In the remainder of this pa-
per, we use PARSEVAL as a shortcut for Labeled
Brackets results on sentence of length 40 or less.
Dependency Evaluation: unlabeled dependencies
are computed using the (Lin, 1995) algorithm,
and the Dybro Johansens’s head propagation rules
cited above11. The unlabeled dependency accu-
racy gives the percentage of input words (exclud-
ing punctuation) that receive the correct head. All
reported evaluations in this paper are calculated on
sentences of length less than 40 words.
</bodyText>
<subsectionHeader confidence="0.774513">
4.5 Baseline: Comparison using minimal
tagsets
</subsectionHeader>
<bodyText confidence="0.999995">
We compared all parsers on three different in-
stances, but still comparable versions, of both the
FTB and the MFT. In order to establish a base-
line, the treebanks are converted to a minimal tag
set (only the major syntactic categories.) without
any other information (no mode propagation as in
the MFT) except for the BIKEL’s parser in Collins’
model 2 (resp. model X) and the STIG parser (i.e.
</bodyText>
<footnote confidence="0.6247782">
11For this evaluation, the gold constituent trees are con-
verted into pseudo-gold dependency trees (that may con-
tain errors). Then parsed constituent trees are converted
into parsed dependency trees, that are matched against the
pseudo-gold trees.
</footnote>
<bodyText confidence="0.9993561875">
STIG-pure) whose models needs function labels to
perform.
Note that by stripping all information from the
node labels in the treebanks, we do not mean
to compare the shape of the treebanks or their
parsability but rather to present an overview of
parser performance on each treebank regardless of
tagset optimizations. However, in each experiment
we observe that the BKY parser significantly out-
performs the other parsers in all metrics.
As the STIG parser presents non statistically sig-
nificant PARSEVAL results differences between its
two modes (PURE &amp; SPINAL) with a f-score p-
value of 0.32, for the remaining of the paper we
will only present results for the STIG’s parser in
“spinal” mode.
</bodyText>
<table confidence="0.9988104">
FTB-min MFT-min
COLLINS MX PARSEVAL 81.65 79.19
UNLAB. DEP 88.48 84.96
COLLINS M2 PARSEVAL 80.1 78.38
UNLAB. DEP 87.45 84.57
COLLINS M1 PARSEVAL 77.98 76.09
UNLAB. DEP 85.67 82.83
CHARNIAK PARSEVAL 82,44 81.34
UNLAB. DEP 88.42 84.90
CHIANG-SPINAL PARSEVAL 80.66 80.74
UNLAB. DEP 87.92 85,14
BKY PARSEVAL 84,93 83.16
UNLAB. DEP 90.06 87.29
CHIANG-PURE PARSEVAL 80.52 79.56
UNLAB. DEP 87,95 85.02
</table>
<tableCaption confidence="0.997472">
Table 3: Labeled Fl scores for unlexicalised
</tableCaption>
<bodyText confidence="0.718129">
and lexicalised parsers on treebanks with minimal
tagsets
</bodyText>
<sectionHeader confidence="0.9828035" genericHeader="method">
5 Cross parser evaluation of tagset
variation
</sectionHeader>
<bodyText confidence="0.999763714285714">
In (Crabbé and Candito, 2008), the authors
showed that it was possible to accurately train the
Petrov’s parser (Petrov et al., 2006) on the FTB us-
ing a more fine grained tag set. This tagset, named
CC12 annotates the basic non-terminal labels with
verbal mood information, and wh-features. Re-
sults were shown to be state of the art with a Fl
parseval score of 86.42% on less than 40 words
sentences.
To summarize, the authors tested the impact of
tagset variations over the FTB using constituency
measures as performance indicators.
Knowing that the MFT has been built with PCFG-
based LFG parsing performance in mind (Schluter
</bodyText>
<note confidence="0.412965">
12TREEBANKS+ in (Crabbé and Candito, 2008).
</note>
<page confidence="0.998553">
156
</page>
<bodyText confidence="0.999694666666667">
and van Genabith, 2008) but suffers from a small
training size and yet allows surprisingly high pars-
ing results (PARSEVAL F-score (&lt;=40) of 79.95
% on the MFT gold standard), one would have
wished to verify its
performance with more annotated data.
However, some semi-automatic modifications
brought to the global structure of this treebank
cannot be applied, in an automatic and reversible
way, to the FTB. Anyway, even if we cannot evalu-
ate the influence of a treebank structure to another,
we can evaluate the influence of one tagset to an-
other treebank using handwritten conversion tools.
In order to evaluate the relations between tagsets
and parsing accuracy on a given treebank, we ex-
tract the optimal tagsets13 from the FTB, the CC
tagset and we convert the MFT POS tags to this
tagset. We then do the same for the FTB on which
we apply the MFT’s optimal tagset (ie. SCHLU).
Before introducing the results of our experiments,
we briefly describe these tagsets.
</bodyText>
<listItem confidence="0.6678402">
1. min : Preterminals are simply the main cate-
gories, and non terminals are the plain labels
2. cc : (Crabbé and Candito, 2008) best tagset.
Preterminals are the main categories, con-
catenated with a wh- boolean for A, ADV,
PRO, and with the mood for verbs (there are 6
moods). No information is propagated to non
terminal symbols. This tagset is shown in Ta-
ble 4, and described in (Crabbé and Candito,
2008).
</listItem>
<table confidence="0.87074475">
ADJ ADJWH ADV ADVWH CC CLO CLR
CLS CS DET DETWH ET I NC NPP P P+D
P+PRO PONCT PREF PRO PROREL PROWH
V VIMP VINF VPP VPR VS
</table>
<tableCaption confidence="0.981817">
Table 4: CC tagset
</tableCaption>
<listItem confidence="0.650081">
3. schlu : N. Schluter’s tagset (Table 2.
</listItem>
<bodyText confidence="0.980132073170731">
Preterminals are the main categories, plus
an inf/finite/part verbal distinction, and
int/card/rel distinction on N, PRO, ADV, A.
These distinctions propagate to non terminal
nodes projected by the lexical head. Non ter-
minals for coordinating structures are split
according to the type of the coordinated
phrases.
Results of these experiments, presented in Table
5, show that BKY displays higher performances
13W.r.t constituent parsing accuracy
in every aspects (constituency and dependency,
except for the MFT-SCHLU). Regardless of the
parser type, we note that unlabeled dependency
scores are higher with the SCHLU tagset than with
the CC tagset. That can be explained by the finest
granularity of the SCHLU based rule set compared
to the other tagset’s rules. As these rules have all
been generated from meta description (a general
COORD label rewrites into COORD_vfinite, CO-
ORD_Sint, etc..) their coverage and global accu-
racy is higher. For example the FTB-CC contains
18 head rules whereas the FTB-SCHLU contains
43 rules.
Interestingly, the ranking of lexicalized parsers
w.r.t PARSEVAL metrics shows that CHARNIAK
has the highest performance over both treebank
tagsets variation even though the MFT’s table (ta-
ble 5) exhibits a non statistically significant vari-
ation between CHARNIAK and STIG-spinal on
PARSEVAL evaluation of the MFT-CC.14
One the other hand, unlabeled dependency evalu-
ations over lexicalized parsers are different among
treebanks. In the case of the FTB, CHARNIAK
exhibits the highest F-score ( FTB-CC: 89.7,
FTB-SCHLU: 89.67) whereas SPINAL STIG per-
forms slightly better on the MFT-SCHLU (MFT-
CC: 86,7, MFT-SCHLU: 87.16). Note that both
tested variations of the Collins’ model 2 display
very high unlabeled dependency scores with the
SCHLU tagset.
</bodyText>
<sectionHeader confidence="0.999729" genericHeader="method">
6 Related Works
</sectionHeader>
<bodyText confidence="0.999779388888889">
As we said in the introduction, the initial work
on the FTB has been carried by (Dybro-Johansen,
2004) in order to extract Tree Adjunct Grammars
from the treebank. Although parsing results were
not reported, she experienced the same argument
adjunct distinction problem than (Arun and Keller,
2005) due to the treebank flatness and the lack of
functional labels in this version. This led Arun
to modify some node annotations (VNG to distin-
guish nodes dominating subcategorized subject cl-
itics and so on) and to add bigrams probabilities to
the language model in order to enhance the over-
all COLLINS’ MODEL’ performance. Although
our treebanks cannot be compared (20.000 sen-
tences for Arun’s one vs 12351 for the FTB), we
report his best PARSEVAL results (&lt;=40): 80.65
LP, 80.25 LR, 80.45 F1.
However, our results are directly comparable with
</bodyText>
<footnote confidence="0.59302">
14Precision P-value = 0.1272 and Recall = 0.06.
</footnote>
<page confidence="0.827777">
157
</page>
<table confidence="0.999854875">
Parser Parseval Dependency Parseval Dependency
MFTCC MFTSCH. MFTCC MFTSCH. FTBCC FTBSCH. FTBCC FTBSCH.
Collins (MX) 80.2 80.96 85.97 87.98 82.52 82.65 88.96 89.12
Collins (M2) 78.56 79.91 84.84 87.43 80.8 79.56 87.94 87.87
Collins (M1) 74 78.49 81.31 85.94 79.16 78.51 86.66 86.93
Charniak 82.5 82.66 86.45 86.94 84.27 83.27 89.7 89.67
Chiang (Sp) 82.6 81.97 86.7 87.16 81.73 81.54 88.85 89.02
Bky 83.96 82.86 87.41 86.87 86.02 84.95 90.48 90.73
</table>
<tableCaption confidence="0.998485">
Table 5: Evaluation Results: MFT-CC vs MFT-SCHLU and FTB-CC vs FTB-SCHLU
</tableCaption>
<table confidence="0.883117615384615">
(Schluter and van Genabith, 2007) whose best
PARSEVAL F-score on raw text is 79.95 and our
best 82.86 on the MFT-SCHLU.
PARSER FTBARUN MFTSCHLU
Arun (acl05) 80.45 -
Arun (this paper) 81.08 -
Schluter (pacling07) - 79.95
Collins (Mx) 81.5 80,96
Collins (M2) 79.36 79,91
Collins (M1) 77.82 -
Charniak 82.35 82,66
Chiang (Sp) 80.94 81,86
Bky 84.03 82.86
</table>
<tableCaption confidence="0.796554">
Table 6: Labeled bracket scores on Arun’s FTB
version and on the MFT
</tableCaption>
<bodyText confidence="0.999914047619048">
In order to favour a “fair” comparison between
our work and (Arun and Keller, 2005), we also
ran their best adaptation of the COLLINS MODEL
2 on their treebank version using our own head
rules set15 and obtained 81.08% of Fl score (Ta-
ble 6). This shows the important influence of a
fine grained head rules set and argues in favor
of data driven induction of this kind of heuris-
tics. Even though it was established, in (Chiang
and Bikel, 2002), that unsupervised induction of
head rules did not lead to improvement over an
extremely hand crafted head rules set, we believe
that for resource poor languages, such methods
could lead toward significant improvements over
parsing accuracy. Thus, the new unsupervised
head rules induction method presented in (Sangati
and Zuidema, 2009) seems very promising for this
topic.
However, it would be of interest to see how the
Arun’s model would perform using the MODEL X
parameter variations.
</bodyText>
<sectionHeader confidence="0.998428" genericHeader="method">
7 Discussion
</sectionHeader>
<bodyText confidence="0.946949604166667">
Regarding the apparent lack of success of a gen-
uine COLLINS’ MODEL 2 (in most cases, its per-
15Due to the lack of function annotation labels in this tree-
bank, (Arun and Keller, 2005)’s argument distinction table
was used for this experiment.
formance is worse than the other parsers w.r.t to
constituent parsing accuracy) when trained on a
treebank with annotated function labels, we sus-
pect that this is caused by the increased data
sparseness added by these annotations. The same
can be said about the pure STIG model, whose re-
sults are only presented on the FTB-MIN because
the differences between the spinal model and itself
were too small and most of the time not statisti-
cally significant. In our opinion, there might be
simply not enough data to accurately train a pure
COLLINS’ MODEL 2 on the FTB with function
labels used for clues to discriminate between argu-
ment and adjuncts. Nevertheless, we do not share
the commonly accepted opinion about the poten-
tial lack of success of lexicalized parsers.
To the best of our knowledge, most adaptations of
a lexicalized model to a western language have
been made with Dan Bikel’s implementation of
COLLINS’ MODELS.16
In fact, the adaptations of the CHARNIAK and
BKY’s models exhibit similar magnitudes of per-
formances for French as for English. Evidence of
lexicalization usefulness is shown through a learn-
ing curve (Figure 6) obtained by running some of
our parsers in perfect tagging mode. This experi-
ment was done in the early stages of this work, the
goal was to see how well the parsers would behave
with the same head rules and the same set of pa-
rameters. We only compared the parsers that could
be used without argument adjunct distinction table
(ie. COLLIN’S MODEL 1, SPINAL STIG, CHAR-
NIAK and BKY).
For this earlier experiment, our implementation
of the COLLINS MODEL 1 actually corresponds to
the MODEL X without an argument adjunct dis-
tinction table. More precisely, the absence of ar-
gument nodes, used for the acquisition of subcat-
egorization frames features, makes the MODEL X
parsing model consider all the nodes of a rule, ex-
16Note that the CHARNIAK’s parser has been adapted for
Danish (Zeman and Resnik, 2008) ; the authors report a 80.20
Fl score for a specific instance of the Danish Treebank.
</bodyText>
<page confidence="0.974596">
158
</page>
<figure confidence="0.998362">
Labeled brackets F−score (&lt;=40)
2000 4000 6000 8000 10000
Number of training sentences
</figure>
<figureCaption confidence="0.9373445">
Figure 6: Learning Curve experiment results for
parsers in perfect tagging mode
</figureCaption>
<bodyText confidence="0.999253769230769">
cept the head, as Modifier Non Terminal nodes
(MNTs). Hence, because of the impossibility to
extract subcategorization frames, the generation
of a MNT depends mainly on the parent head
word and on the whole list of previously gener-
ated MNTs. One can suppose that training on
small treebanks would lead this distribution to be
sparse, therefore most of the discriminant infor-
mation would come from less specific distribu-
tions. Namely the ones conditioned on the head
pos tag and on the last previously generated MNT
as shown in this model back-off structure (Table
7).
</bodyText>
<equation confidence="0.96335625">
Back-off level p(M(t)i |· · · )
0 P, H, wh, th, (Mi−1, ..., Mi−k)
1 P, H, th, Mi−1
2 P, H, f
</equation>
<tableCaption confidence="0.6699195">
Table 7: MODEL X simplified parameter class for
MNTs
</tableCaption>
<bodyText confidence="0.999546928571429">
M(t)i is the POS tag of the ith MNT, P the parent node
label, H the head node label, wh the head word, th its POS
tag, (Mi−1, ..., Mi−k) the list of previously generated MNTs
and f a flag stating if the current node is the first MNT to be
generated.
Interestingly, in the SPINAL STIG model,
almost all the extracted trees are spinal and conse-
quently are handled by an operation called Sister
Adjunction whose probability model for a given
root node of an elementary tree, also conditions
its generation upon the label of the previously
generated tree (Chiang, 2003). Furthermore,
the second component of the Sister Adjunction’s
back-off structure (Table 8) is made coarser by the
removing of the lexical anchor of the tree where a
sister-adjunction is to occur.
Studying in depth the respective impact of these
features on the performance of both models is
outside the scope of this paper, nevertheless we
note that their back-off structures are based on
similar principles: a deletion of the main lexical
information and a context limited to the root label
of the previously generated tree (resp. MNT node
label for the MODEL X). This can explain why
these formally different parsers display almost the
same learning curves (Fig. 6) and more over why
they surprisingly exhibit few sensitivity to the
amount of lexical material used for training.
</bodyText>
<equation confidence="0.8668675">
Back-off level Psa(γ |· · · )
0 τ,,, ω,,, η,,, i, X
1 τ,,, η,,, i, X
2 τ,,, η,,, i
</equation>
<tableCaption confidence="0.7618285">
Table 8: SPINAL STIG parameter class for Sister-
adjoining tree templates (Chiang, 2003)
</tableCaption>
<bodyText confidence="0.994143538461538">
γ is the tree to be generated on the sister adjunction site
(η,,, i) of the tree template τ,,, ω,, is the lexical anchor of τ,,,
τ,, is τ,, stripped from its anchor POS tag and X is the root
label of the previous tree to sister-adjoin at the site (η,,, i).
However, the learning curve also shows that the
CHARNIAK’s17 and BKY’s parsers have almost
parallel curves whereas this specific COLLIN’S
MODEL 1 parser and the SPINAL STIG model have
very similar shape and seem to reach an upper
limit very quickly.18 The last two parsers having
also very similar back-off models (Chiang, 2003),
we wonder (1) if we are not actually comparing
them because of data sparseness issues and (2) if
the small size of commonly used treebanks does
not lead the community to consider lexicalized
models, via the lone COLLINS’ MODELS, as inap-
propriate to parse other languages than Wall Street
Journal English.
17As opposed to the other parsers, the Charniak’s parser
tagging accuracy did not reach the 100% limit, 98.32% for the
last split. So the comparison is not really fair but we believe
that the visible tendency still stands.
18We are of course aware that the curve’s values are also
function of the amount of new productions brought by the
increased treebank size. That should be of course taken into
account.
</bodyText>
<figure confidence="0.9950004">
76 78 80 82 84 86 88
Berkeley
Charniak
SpinalTig
Model 1 (emulated)
</figure>
<page confidence="0.993011">
159
</page>
<bodyText confidence="0.999908695652174">
Regarding the remarkable performance of the
BKY algorithm, it remains unclear why exactly
it systematically outperforms the other lexicalized
algorithms. We can only make a few remarks
about that. First, the algorithm is totally dis-
joint from the linguistic knowledge, that is entirely
taken from the treebank, except for the suffixes
used for handling unknown words. This is not true
of the Collins’ or Charniak’s models, that were
set up with the PTB annotation scheme in mind.
Another point concerns the amount of data nec-
essary for an accurate learning. We had the intu-
ition that lexicalized algorithms would have ben-
efited more than BKY from the training data size
increase. Yet the BKY’s learning curve displays a
somewhat faster progression than lexicalized algo-
rithms such as the SPINAL STIG and our specific
instance of the COLLINS’ MODEL 1.
In our future work, we plan to conduct
self-training experiments using discriminative
rerankers on very large French corpora to study
the exact impact of the lexicon on this unlexical-
ized algorithm.
</bodyText>
<sectionHeader confidence="0.998661" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999990866666667">
By adapting those parsers to French and carry-
ing out extensive evaluation over the main char-
acteristics of the treebank at our disposal, we
prove indeed that probabilistic parsing was effi-
cient enough to provide accurate parsing results
for French. We showed that the BKY model estab-
lishes a high performance level on parsing results.
Maybe more importantly we emphasized the im-
portance of tag set model to get distinct state of
the art evaluation metrics for FTB parsing, namely
the SCHLU tagset to get more accurate unlabeled
dependencies and the CC tagset to get better con-
stituency parses. Finally, we showed that the lexi-
calization debate could benefit from the inclusion
of more lexicalized parsing models.
</bodyText>
<sectionHeader confidence="0.996892" genericHeader="acknowledgments">
9 Acknowledgments
</sectionHeader>
<bodyText confidence="0.9819556">
This work was supported by the ANR Sequoia
(ANR-08-EMER-013). We heartily thank A.
Arun, J. van Genabith an N. Schluter for kindly
letting us use our parsers on their treebanks.
Thanks to the anonymous reviewers for their com-
ments. All remaining errors are ours. We thank J.
Wagner for his help and we would like to acknowl-
edge the Centre for Next Generation Localization
(www.cngl.ie) for providing access to one of its
high-memory nodes.
</bodyText>
<sectionHeader confidence="0.994899" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999570367346939">
Anne Abeillé and Nicolas Barrier. 2004. Enrich-
ing a french treebank. In Proceedings of Language
Ressources and Evaluation Conference (LREC), Lis-
bon.
Anne Abeillé, Lionel Clément, and François Toussenel,
2003. Building a Treebank for French. Kluwer,
Dordrecht.
Abhishek Arun and Frank Keller. 2005. Lexicalization
in crosslinguistic probabilistic parsing: The case of
french. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 306–313, Ann Arbor, MI.
Daniel M. Bikel. 2002. Design of a multi-lingual,
parallel-processing statistical parsing engine. In
Proceedings of the second international conference
on Human Language Technology Research, pages
178–182. Morgan Kaufmann Publishers Inc. San
Francisco, CA, USA.
Daniel M. Bikel. 2004. Intricacies of Collins’ Parsing
Model. Computational Linguistics, 30(4):479–511.
E. Black, S. Abney, D. Flickinger, C. Gdaniec, R. Gr-
ishman, P. Harrison, D. Hindle, R. Ingria, F. Jelinek,
J. Klavans, M. Liberman, M. Marcus, S. Roukos,
B. Santorini, and T. Strzalkowski. 1991. A proce-
dure for quantitatively comparing the syntactic cov-
erage of english grammars. In Proceedings of the
DARPA Speech and Natural Language Workshop,
pages 306–311, San Mateo (CA). Morgan Kaufman.
Aoife Cahill, Michael Burke, Ruth O’Donovan, Josef
van Genabith, and Andy Way. 2004. Long-Distance
Dependency Resolution in Automatically Acquired
Wide-Coverage PCFG-Based LFG Approximations.
In Proceedings of the 42nd Annual Meeting of the
Association for Computational Linguistics, pages
320–327, Barcelona, Spain.
Xavier Carreras, Mickael Collins, and Terry Koo.
2008. TAG, dynamic programming, and the percep-
tron for efficient, feature-rich parsing. In Proceed-
ings of the Twelfth Conference on Computational
Natural Language Learning (CoNLL), pages 9–16.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-fine n-best parsing and maxent discriminative
reranking. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL 2005), Ann Arbor (MI).
Eugene Charniak. 2000. A maximum-entropy-
inspired parser. In Proceedings of the 1st Annual
Meeting of the North American Chapter of the ACL
(NAACL), Seattle.
</reference>
<page confidence="0.968715">
160
</page>
<reference confidence="0.999798327272727">
David Chiang and Daniel M. Bikel. 2002. Recover-
ing latent information in treebanks. In Proceedings
of COLING’02, 19th International Conference on
Computational Linguistics, Taipei, Taiwan, August.
David Chiang, 2003. Statistical Parsing with an Auto-
matically Extracted Tree Adjoining Grammar, chap-
ter 16, pages 299–316. CSLI Publications.
Michael Collins. 1999. Head Driven Statistical Mod-
els for Natural Language Parsing. Ph.D. thesis,
University of Pennsylvania, Philadelphia.
Benoit Crabbé and Marie Candito. 2008. Expériences
d’analyse syntaxique statistique du français. In
Actes de la 15ème Conférence sur le Traitement Au-
tomatique des Langues Naturelles (TALN’08), pages
45–54, Avignon, France.
Mary Dalrymple. 2001. Lexical-Functional Grammar,
volume 34 of Syntax and Semantics. San Diego,
CA; London. Academic Press.
Amit Dubey and Frank Keller. 2003. Probabilis-
tic parsing for german using sister-head dependen-
cies. In In Proceedings of the 41st Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 96–103.
Ane Dybro-Johansen. 2004. Extraction automatique
de grammaires à partir d’un corpus français. Mas-
ter’s thesis, Université Paris 7.
Mark Johnson. 1998. PCFG models of linguis-
tic tree representations. Computational Linguistics,
24(4):613–632.
Aravind K. Joshi. 1987. Introduction to tree adjoining
grammar. In A. Manaster-Ramer, editor, The Math-
ematics ofLanguage. J. Benjamins.
R. Kaplan and J. Bresnan. 1982. Lexical-functional
grammar: A formal system for grammarical repre-
sentation. In J. Bresnan, editor, The Mental Repre-
sentation of Grammatical Relations, pages 173–281.
Mass.: MIT Press.
Dan Klein and Christopher D. Manning. 2003. Ac-
curate unlexicalized parsing. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics-Volume 1, pages 423–430. Asso-
ciation for Computational Linguistics Morristown,
NJ, USA.
Sandra Kübler, Erhard W. Hinrichs, and Wolfgang
Maier. 2006. Is it really that difficult to parse ger-
man? In Proceedings of the 2006 Conference on
Empirical Methods in Natural Language Process-
ing, pages 111–119, Sydney, Australia, July. Asso-
ciation for Computational Linguistics.
Dekang Lin. 1995. A dependency-based method for
evaluating broad-coverage parsers. In International
Joint Conference on Artificial Intelligence, pages
1420–1425, Montreal.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1994. Building a large annotated
corpus of english: The penn treebank. Computa-
tional Linguistics, 19(2):313–330.
David McClosky, Eugene Charniak, and Mark John-
son. 2006. Effective self-training for parsing. In
Proceedings of the Human Language Technology
Conference of the NAACL, Main Conference, pages
152–159, New York City, USA, June. Association
for Computational Linguistics.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and
interpretable tree annotation. In Proceedings of
the 21st International Conference on Computational
Linguistics and 44th Annual Meeting of the Associ-
ation for Computational Linguistics, Sydney, Aus-
tralia, July. Association for Computational Linguis-
tics.
Ines Rehbein and Josef van Genabith. 2007. Tree-
bank annotation schemes and parser evaluation for
german. In Proceedings of the 2007 Joint Confer-
ence on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning (EMNLP-CoNLL), Prague.
Philip Resnik. 1992. Probabilistic tree-adjoining
grammars as a framework for statistic natural lan-
guage processing. COLING’92, Nantes, France.
F. Sangati and W. Zuidema. 2009. Unsupervised
methods for head assignments. In Proceedings of
the 12th Conference of the European Chapter of the
ACL (EACL 2009), pages 701–709, Athens, Greece.
Association for Computational Linguistics.
Y. Schabes and R.C. Waters. 1995. Tree Insertion
Grammar: Cubic-Time, Parsable Formalism that
Lexicalizes Context-Free Grammar without Chang-
ing the Trees Produced. Computational Linguistics,
21(4):479–513.
Yves Schabes. 1992. Stochastic Lexicalized Tree Ad-
joining Grammars. In Proceedings of the 14th con-
ference on Computational linguistics, pages 425–
432, Nantes, France. Association for Computational
Linguistics.
Natalie Schluter and Josef van Genabith. 2007.
Preparing, restructuring, and augmenting a french
treebank: Lexicalised parsers or coherent treebanks?
In Proceedings of PACLING 07.
Natalie Schluter and Josef van Genabith. 2008.
Treebank-based acquisition of lfg parsing resources
for french. In European Language Resources As-
sociation (ELRA), editor, Proceedings of the Sixth
International Language Resources and Evaluation
(LREC’08), Marrakech, Morocco, may.
Daniel Zeman and Philip Resnik. 2008. Cross-
language parser adaptation between related lan-
guages. In Proceedings of IJCNLP 2008 Work-
shop on NLP for Less Privileged Languages, Haj-
darábádu, India.
</reference>
<page confidence="0.998209">
161
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.288043">
<title confidence="0.838273">Cross Parser Evaluation and Tagset Variation : a French Treebank Study</title>
<author confidence="0.994905">Marie Benoît</author>
<affiliation confidence="0.654499">amp;</affiliation>
<address confidence="0.478445">28 rue F-75006 Paris France</address>
<abstract confidence="0.994674592592593">This paper presents preliminary investigations on the statistical parsing of French by bringing a complete evaluation on French data of the main probabilistic lexicalized and unlexicalized parsers first designed on the Penn Treebank. We adapted the parsers on the two existing treebanks of French (Abeillé et al., 2003; Schluter and van Genabith, 2007). To our knowledge, mostly all of the results reported here are state-of-the-art for the constituent parsing of French on every available treebank. Regarding the algorithms, the comparisons show that lexicalized parsing models are outperformed by the unlexicalized Berkeley parser. Regarding the treebanks, we observe that, depending on the parsing model, a tag set with specific features has direct influence over evaluation results. We show that the adapted lexicalized parsers do not share the same sensitivity towards the amount of lexical material used for training, thus questioning the relevance of using only one lexicalized model to study the usefulness of lexicalization for the parsing of French.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeillé</author>
<author>Nicolas Barrier</author>
</authors>
<title>Enriching a french treebank.</title>
<date>2004</date>
<booktitle>In Proceedings of Language Ressources and Evaluation Conference (LREC),</booktitle>
<location>Lisbon.</location>
<contexts>
<context position="3716" citStr="Abeillé and Barrier, 2004" startWordPosition="584" endWordPosition="587">er this question, this paper reports a set of experiments where five algorithms, first designed for the purpose of parsing English, have been adapted to French: a PCFG parser with latent annotation (Petrov et al., 2006), a Stochastic Tree Adjoining Grammar parser (Chiang, 2003), the Charniak’s lexicalized parser (Charniak, 2000) and the Bikel’s implementation of Collins’ Model 1 and 2 (Collins, 1999) described in (Bikel, 2002). To ease further comparisons, we report results on two versions of the treebank: (1) the last version made available in December 2007, hereafter FTB , and described in (Abeillé and Barrier, 2004) and the (2) LFG inspired version of (Schluter and van Genabith, 2007). The paper is structured as follows : After a brief presentation of the treebanks, we discuss the use1This has been made available in December 2007. 150 Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 150–161, Paris, October 2009. c�2009 Association for Computational Linguistics fulness of testing different parsing frameworks over two parsing paradigms before introducing our experimental protocol and presenting our results. Finally, we discuss and compare with related works on cross-la</context>
</contexts>
<marker>Abeillé, Barrier, 2004</marker>
<rawString>Anne Abeillé and Nicolas Barrier. 2004. Enriching a french treebank. In Proceedings of Language Ressources and Evaluation Conference (LREC), Lisbon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anne Abeillé</author>
<author>Lionel Clément</author>
<author>François Toussenel</author>
</authors>
<title>Building a Treebank for French.</title>
<date>2003</date>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="1731" citStr="Abeillé et al., 2003" startWordPosition="262" endWordPosition="265">al material used for training, thus questioning the relevance of using only one lexicalized model to study the usefulness of lexicalization for the parsing of French. 1 Introduction The development of large scale symbolic grammars has long been a lively topic in the French NLP community. Surprisingly, the acquisition of probabilistic grammars aiming at stochastic parsing, using either supervised or unsupervised methods, has not attracted much attention despite the availability of large manually syntactic annotated data for French. Nevertheless, the availability of the Paris 7 French Treebank (Abeillé et al., 2003), allowed (Dybro-Johansen, 2004) to carry out the extraction of a Tree Adjoining Grammar (Joshi, 1987) and led (Arun and Keller, 2005) $ Université Paris 7 INRIA (ALPAGE) 30 rue du Château des Rentiers F-75013 Paris France to induce the first effective lexicalized parser for French. Yet, as noted by (Schluter and van Genabith, 2007), the use of the treebank was “challenging”. Indeed, before carrying out successfully any experiment, the authors had to perform a deep restructuring of the data to remove errors and inconsistencies. For the purpose of building a statistical LFG parser, (Schluter an</context>
<context position="12004" citStr="Abeillé et al., 2003" startWordPosition="1935" endWordPosition="1938">TB represents them with an adjunction of a COORD phrase as a sister or a daughter of the coordinated element, the MFT introduces a treatment closer to the one used in the PTB to describe such structures. As opposed to (Arun and Keller, 2005) who decided to transform the FTB’s coordinations to match the PTB’s analysis, the COORD label is not removed but extended to include the coordinated label (Fig. 5). In Figure 5, we show the general coordination structure in the FTB, and the corresponding modified structure in the MFT. A more complicated modification concerns the case of VP coordinations. (Abeillé et al., 2003) argue for a flat representation with no VP-node for French, and this is 152 SENT SENT COORD-VP VN Ssub C-C VP VP NP CL Elle NP V CL Elle et NP Ssub ajoute douze points de désaccord VN-finite V-finite ajoute VN-finite V-finite présente que ... COORD que ... CC VN et V présente douze points de désaccord Figure 4: Two representations of “VP coordinations” for the sentence She adds that ... and presents twelve sticking points: in the FTB (left) and in the MFT (right) particularly justified in some cases of subject-verb inversion. Nevertheless, VP phrases are used in the FTB for non-finite VPs onl</context>
</contexts>
<marker>Abeillé, Clément, Toussenel, 2003</marker>
<rawString>Anne Abeillé, Lionel Clément, and François Toussenel, 2003. Building a Treebank for French. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abhishek Arun</author>
<author>Frank Keller</author>
</authors>
<title>Lexicalization in crosslinguistic probabilistic parsing: The case of french.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>306--313</pages>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="1865" citStr="Arun and Keller, 2005" startWordPosition="283" endWordPosition="286">zation for the parsing of French. 1 Introduction The development of large scale symbolic grammars has long been a lively topic in the French NLP community. Surprisingly, the acquisition of probabilistic grammars aiming at stochastic parsing, using either supervised or unsupervised methods, has not attracted much attention despite the availability of large manually syntactic annotated data for French. Nevertheless, the availability of the Paris 7 French Treebank (Abeillé et al., 2003), allowed (Dybro-Johansen, 2004) to carry out the extraction of a Tree Adjoining Grammar (Joshi, 1987) and led (Arun and Keller, 2005) $ Université Paris 7 INRIA (ALPAGE) 30 rue du Château des Rentiers F-75013 Paris France to induce the first effective lexicalized parser for French. Yet, as noted by (Schluter and van Genabith, 2007), the use of the treebank was “challenging”. Indeed, before carrying out successfully any experiment, the authors had to perform a deep restructuring of the data to remove errors and inconsistencies. For the purpose of building a statistical LFG parser, (Schluter and van Genabith, 2007; Schluter and van Genabith, 2008) have reannotated a significant subset of the treebank with two underlying goals</context>
<context position="8622" citStr="Arun and Keller, 2005" startWordPosition="1357" endWordPosition="1360">). They include NP-SUJ PP-AOBJ VN NP-OBJ N banque (b) The Council has notified his decision to the bank D Le N Conseil V V a notifié N sa décision D P à D la NP SENT NP-SUJ PP-AOBJ VN NP-MOD D N une lettre V envoyée N semaine A dernière NP aux N salariés V avait V été D la P (a) A letter had been sent last week to the employees 151 digit numbers (written with spaces in French) (e.g. 10 000), frozen compounds (eg. pomme de terre ’potato’) but also named entities or sequences whose meaning is compositional but where insertion is rare or difficult (e.g. garde d’enfant ’child care’). As noted by (Arun and Keller, 2005), compounds in French may exhibit ungrammatical sequences of tags as in à la va vite ’in a hurry’ : Prep+ Det+ finite verb + adverb or can include “words” which do not exist outside a compound (e.g hui in aujourd’hui ’today’). Therefore, compounds receive a two-level annotation : constituent parts are described in a subordinate level using the same POS tagset as the genuine compound POS. This makes it more difficult to extract a proper grammar from the FTB without merged compounds2. This is why, following (Arun and Keller, 2005) and (Schluter and van Genabith, 2007), all the treebanks used in </context>
<context position="11624" citStr="Arun and Keller, 2005" startWordPosition="1871" endWordPosition="1874">res in the general case, for FTB (up) and MFT (down) by (Cahill et al., 2004) and reduce the size of the grammars extracted from the treebank. MFT has also undergone a phase of error mining and an extensive manual correction. 2.3 Coordination in French Treebanks One of the key differences between the two French treebanks is the way they treat coordinate structures. Whereas the FTB represents them with an adjunction of a COORD phrase as a sister or a daughter of the coordinated element, the MFT introduces a treatment closer to the one used in the PTB to describe such structures. As opposed to (Arun and Keller, 2005) who decided to transform the FTB’s coordinations to match the PTB’s analysis, the COORD label is not removed but extended to include the coordinated label (Fig. 5). In Figure 5, we show the general coordination structure in the FTB, and the corresponding modified structure in the MFT. A more complicated modification concerns the case of VP coordinations. (Abeillé et al., 2003) argue for a flat representation with no VP-node for French, and this is 152 SENT SENT COORD-VP VN Ssub C-C VP VP NP CL Elle NP V CL Elle et NP Ssub ajoute douze points de désaccord VN-finite V-finite ajoute VN-finite V-</context>
<context position="15581" citStr="Arun and Keller, 2005" startWordPosition="2548" endWordPosition="2551">del lexical dependencies between a governor and its dependants in order to improve attachment choices. Even though it has been proven numerous times that lexicalization was useful for parsing the Wall Street Journal corpus (Collins, 1999; Charniak, 2000), the question of its relevance for other languages has been raised for German (Dubey and Keller, 2003; Kübler et al., 2006) and for French 5Except (Chiang, 2003) which is indeed a TREE INSERTION GRAMMAR (Schabes and Waters, 1995) parser but which must extract a lexicalized grammar from the set of context free rules underlying a treebank. 153 (Arun and Keller, 2005) where the authors argue that French parsing benefits from lexicalization but the treebank flatness reduces its impact whereas (Schluter and van Genabith, 2007) argue that an improved annotation scheme and an improved treebank consistency should help to reach a reasonable state of the art. As only Collins’ models 1 &amp; 2 have been used for French as instances of lexicalised parsers, we also report results from the history-based generative parser of (Charniak, 2000) and the Stochastic Tree Insertion Grammar parser of (Chiang, 2003) as well as (Bikel, 2002)’s implementation of the Collins’ models </context>
<context position="23296" citStr="Arun and Keller, 2005" startWordPosition="3822" endWordPosition="3825">n rules. To this end, we used those described by (Dybro-Johansen, 2004) for training a Stochastic Tree Adjoining Grammar parser on French. From this set, we built a set of meta-rules that were automatically derived to match each treebank annotation scheme. As the Collins Model 2 and the STIG model need to distinguish between argument and adjunct nodes to acquire subcategorization frames probabilities, we implemented an argument-adjunct distinction table that takes advantage of the function labels annotated in the treebank. This is one of the main differences with the experiments described in (Arun and Keller, 2005) and (DybroJohansen, 2004) where the authors had to rely only on the very flat treebank structure without function labels, to annotate the arguments of a head. Morphology and typography adaptation Following (Arun and Keller, 2005), we adapted the morphological treatment of unknown words proposed for French when needed (BKY’s and BIKEL’s parser). This process clusters unknown words using typographical and morphological information. Since all lexicalized parsers contain specific treatments for the PTB typographical convention, we automatically converted the original punctuation parts of speech t</context>
<context position="31966" citStr="Arun and Keller, 2005" startWordPosition="5227" endWordPosition="5230">se of the FTB, CHARNIAK exhibits the highest F-score ( FTB-CC: 89.7, FTB-SCHLU: 89.67) whereas SPINAL STIG performs slightly better on the MFT-SCHLU (MFTCC: 86,7, MFT-SCHLU: 87.16). Note that both tested variations of the Collins’ model 2 display very high unlabeled dependency scores with the SCHLU tagset. 6 Related Works As we said in the introduction, the initial work on the FTB has been carried by (Dybro-Johansen, 2004) in order to extract Tree Adjunct Grammars from the treebank. Although parsing results were not reported, she experienced the same argument adjunct distinction problem than (Arun and Keller, 2005) due to the treebank flatness and the lack of functional labels in this version. This led Arun to modify some node annotations (VNG to distinguish nodes dominating subcategorized subject clitics and so on) and to add bigrams probabilities to the language model in order to enhance the overall COLLINS’ MODEL’ performance. Although our treebanks cannot be compared (20.000 sentences for Arun’s one vs 12351 for the FTB), we report his best PARSEVAL results (&lt;=40): 80.65 LP, 80.25 LR, 80.45 F1. However, our results are directly comparable with 14Precision P-value = 0.1272 and Recall = 0.06. 157 Pars</context>
<context position="33584" citStr="Arun and Keller, 2005" startWordPosition="5496" endWordPosition="5499">.96 82.86 87.41 86.87 86.02 84.95 90.48 90.73 Table 5: Evaluation Results: MFT-CC vs MFT-SCHLU and FTB-CC vs FTB-SCHLU (Schluter and van Genabith, 2007) whose best PARSEVAL F-score on raw text is 79.95 and our best 82.86 on the MFT-SCHLU. PARSER FTBARUN MFTSCHLU Arun (acl05) 80.45 - Arun (this paper) 81.08 - Schluter (pacling07) - 79.95 Collins (Mx) 81.5 80,96 Collins (M2) 79.36 79,91 Collins (M1) 77.82 - Charniak 82.35 82,66 Chiang (Sp) 80.94 81,86 Bky 84.03 82.86 Table 6: Labeled bracket scores on Arun’s FTB version and on the MFT In order to favour a “fair” comparison between our work and (Arun and Keller, 2005), we also ran their best adaptation of the COLLINS MODEL 2 on their treebank version using our own head rules set15 and obtained 81.08% of Fl score (Table 6). This shows the important influence of a fine grained head rules set and argues in favor of data driven induction of this kind of heuristics. Even though it was established, in (Chiang and Bikel, 2002), that unsupervised induction of head rules did not lead to improvement over an extremely hand crafted head rules set, we believe that for resource poor languages, such methods could lead toward significant improvements over parsing accuracy</context>
</contexts>
<marker>Arun, Keller, 2005</marker>
<rawString>Abhishek Arun and Frank Keller. 2005. Lexicalization in crosslinguistic probabilistic parsing: The case of french. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 306–313, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
</authors>
<title>Design of a multi-lingual, parallel-processing statistical parsing engine.</title>
<date>2002</date>
<booktitle>In Proceedings of the second international conference on Human Language Technology Research,</booktitle>
<pages>178--182</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="3520" citStr="Bikel, 2002" startWordPosition="553" endWordPosition="554">rted results. With the problem of the usability of the data source being solved, the question of finding one or many accurate language models for parsing French raises. Thus, to answer this question, this paper reports a set of experiments where five algorithms, first designed for the purpose of parsing English, have been adapted to French: a PCFG parser with latent annotation (Petrov et al., 2006), a Stochastic Tree Adjoining Grammar parser (Chiang, 2003), the Charniak’s lexicalized parser (Charniak, 2000) and the Bikel’s implementation of Collins’ Model 1 and 2 (Collins, 1999) described in (Bikel, 2002). To ease further comparisons, we report results on two versions of the treebank: (1) the last version made available in December 2007, hereafter FTB , and described in (Abeillé and Barrier, 2004) and the (2) LFG inspired version of (Schluter and van Genabith, 2007). The paper is structured as follows : After a brief presentation of the treebanks, we discuss the use1This has been made available in December 2007. 150 Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 150–161, Paris, October 2009. c�2009 Association for Computational Linguistics fulness of tes</context>
<context position="16140" citStr="Bikel, 2002" startWordPosition="2642" endWordPosition="2643">es underlying a treebank. 153 (Arun and Keller, 2005) where the authors argue that French parsing benefits from lexicalization but the treebank flatness reduces its impact whereas (Schluter and van Genabith, 2007) argue that an improved annotation scheme and an improved treebank consistency should help to reach a reasonable state of the art. As only Collins’ models 1 &amp; 2 have been used for French as instances of lexicalised parsers, we also report results from the history-based generative parser of (Charniak, 2000) and the Stochastic Tree Insertion Grammar parser of (Chiang, 2003) as well as (Bikel, 2002)’s implementation of the Collins’ models 1 &amp; 2 (Collins, 1999). Most of the lexicalized parsers we use in this work are well known and since their releases, almost ten years ago, their core parsing models still provide state-of-the-art performance on the standard test set for English.6 We insist on the fact that one of the goals of this work was to evaluate raw performance of well known parsing models on French annotated data. Thus, we have not considered using more complex parsing architectures that makes use of reranking (Charniak and Johnson, 2005) or self-training (McClosky et al., 2006) i</context>
<context position="33943" citStr="Bikel, 2002" startWordPosition="5564" endWordPosition="5565">s (M2) 79.36 79,91 Collins (M1) 77.82 - Charniak 82.35 82,66 Chiang (Sp) 80.94 81,86 Bky 84.03 82.86 Table 6: Labeled bracket scores on Arun’s FTB version and on the MFT In order to favour a “fair” comparison between our work and (Arun and Keller, 2005), we also ran their best adaptation of the COLLINS MODEL 2 on their treebank version using our own head rules set15 and obtained 81.08% of Fl score (Table 6). This shows the important influence of a fine grained head rules set and argues in favor of data driven induction of this kind of heuristics. Even though it was established, in (Chiang and Bikel, 2002), that unsupervised induction of head rules did not lead to improvement over an extremely hand crafted head rules set, we believe that for resource poor languages, such methods could lead toward significant improvements over parsing accuracy. Thus, the new unsupervised head rules induction method presented in (Sangati and Zuidema, 2009) seems very promising for this topic. However, it would be of interest to see how the Arun’s model would perform using the MODEL X parameter variations. 7 Discussion Regarding the apparent lack of success of a genuine COLLINS’ MODEL 2 (in most cases, its per15Du</context>
</contexts>
<marker>Bikel, 2002</marker>
<rawString>Daniel M. Bikel. 2002. Design of a multi-lingual, parallel-processing statistical parsing engine. In Proceedings of the second international conference on Human Language Technology Research, pages 178–182. Morgan Kaufmann Publishers Inc. San Francisco, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
</authors>
<date>2004</date>
<journal>Intricacies of Collins’ Parsing Model. Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="18258" citStr="Bikel, 2004" startWordPosition="3004" endWordPosition="3005">n the way probabilities associated to socalled “modifier non terminals” nodes are handled by the generative model. To explain the difference, let us recall that 6Section 23 of the Wall Street Journal section of the PTB. 7The formalism actually used in this parser is a context free variant of Tree Adjoining Grammar, Tree Insertion Grammars (TIG), first introduced in (Schabes and Waters, 1995). a lexicalized PCFG can roughly be described as a set of stochastic rules of the form: P → Ln Ln−1 ..L1 H R1 .. Rm−1 Rm where Li, H, Ri and P are all lexicalized non terminals; P inherits its head from H (Bikel, 2004). The Collins’ model 2 deterministically labels some nodes of a rule to be arguments of a given Head and the remaining nodes are considered to be modifier non terminals (hereafter MNT). In this model, given a left-hand side symbol, the head and its arguments are first generated and then the MNT are generated from the head outward. In Bikel’s implementation of Collins’s model 2 (Bikel, 2004), the MNT parameter class is the following (for clarity, we omit the verb intervening, subcat and side features which are the same in both classes) : • model 2 (canonical) : p(M(t)i|P, H, wh, th, map(Mi−1)) </context>
</contexts>
<marker>Bikel, 2004</marker>
<rawString>Daniel M. Bikel. 2004. Intricacies of Collins’ Parsing Model. Computational Linguistics, 30(4):479–511.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Black</author>
<author>S Abney</author>
<author>D Flickinger</author>
<author>C Gdaniec</author>
<author>R Grishman</author>
<author>P Harrison</author>
<author>D Hindle</author>
<author>R Ingria</author>
<author>F Jelinek</author>
<author>J Klavans</author>
<author>M Liberman</author>
<author>M Marcus</author>
<author>S Roukos</author>
<author>B Santorini</author>
<author>T Strzalkowski</author>
</authors>
<title>A procedure for quantitatively comparing the syntactic coverage of english grammars.</title>
<date>1991</date>
<booktitle>In Proceedings of the DARPA Speech and Natural Language Workshop,</booktitle>
<pages>306--311</pages>
<publisher>Morgan Kaufman.</publisher>
<location>San Mateo (CA).</location>
<contexts>
<context position="25074" citStr="Black et al., 1991" startWordPosition="4109" endWordPosition="4112">we report parsing results with the following experimental protocol: a treebank is divided in 3 sections : test (first 10%), development (second 10%) and training (remaining 80%). The MFT partition set is the canonical one (3800 sentences for training, 509 for the dev set and the last 430 for the test set). We systematically report the results with compounds merged. Namely, we preprocess the treebank in order to turn each compound into a single token both for training and test. 4.4 Evaluation metrics Constituency Evaluation: we use the standard labeled bracketed PARSEVAL metric for evaluation (Black et al., 1991), along with unlabeled dependency evaluation, which is described as a more annotation-neutral metric in (Rehbein and van Genabith, 2007). In the remainder of this paper, we use PARSEVAL as a shortcut for Labeled Brackets results on sentence of length 40 or less. Dependency Evaluation: unlabeled dependencies are computed using the (Lin, 1995) algorithm, and the Dybro Johansens’s head propagation rules cited above11. The unlabeled dependency accuracy gives the percentage of input words (excluding punctuation) that receive the correct head. All reported evaluations in this paper are calculated on</context>
</contexts>
<marker>Black, Abney, Flickinger, Gdaniec, Grishman, Harrison, Hindle, Ingria, Jelinek, Klavans, Liberman, Marcus, Roukos, Santorini, Strzalkowski, 1991</marker>
<rawString>E. Black, S. Abney, D. Flickinger, C. Gdaniec, R. Grishman, P. Harrison, D. Hindle, R. Ingria, F. Jelinek, J. Klavans, M. Liberman, M. Marcus, S. Roukos, B. Santorini, and T. Strzalkowski. 1991. A procedure for quantitatively comparing the syntactic coverage of english grammars. In Proceedings of the DARPA Speech and Natural Language Workshop, pages 306–311, San Mateo (CA). Morgan Kaufman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aoife Cahill</author>
<author>Michael Burke</author>
<author>Ruth O’Donovan</author>
<author>Josef van Genabith</author>
<author>Andy Way</author>
</authors>
<title>Long-Distance Dependency Resolution in Automatically Acquired Wide-Coverage PCFG-Based LFG Approximations.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>320--327</pages>
<location>Barcelona,</location>
<marker>Cahill, Burke, O’Donovan, van Genabith, Way, 2004</marker>
<rawString>Aoife Cahill, Michael Burke, Ruth O’Donovan, Josef van Genabith, and Andy Way. 2004. Long-Distance Dependency Resolution in Automatically Acquired Wide-Coverage PCFG-Based LFG Approximations. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 320–327, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Mickael Collins</author>
<author>Terry Koo</author>
</authors>
<title>TAG, dynamic programming, and the perceptron for efficient, feature-rich parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the Twelfth Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>9--16</pages>
<contexts>
<context position="20814" citStr="Carreras et al., 2008" startWordPosition="3433" endWordPosition="3436">have no substitution node. Moreover, the probability model, being split between lexical anchors and tree templates, allows a very coarse grammar that contains, for example, only 83 tree templates for one treebank instantiation, namely the FTB-CC (cf. section 5). This behavior, although not documented10, is close to Collins’ model 1, which does not use any argument adjunct distinction information, and led to results interesting enough to be integrated as the “Chiang Spinal” model in our parser set. It should be noted that, recently, the use of similar models has been independently proposed in (Carreras et al., 2008) with the purpose of getting a richer parsing model that can use non local features and in (Sangati and Zuidema, 2009) as a mean of extracting a Lexicalized Tree Substitution Grammar. In their process, the first extracted grammar is actually a spinal STIG. 3.2 Unlexicalized Parser As an instance of an unlexicalized parser, the last algorithm we use is the Berkeley unlexicalized parser (BKY) of (Petrov et al., 2006). This algorithm is an evolution of treebank transformation principles aimed at reducing PCFG independence assumptions (Johnson, 1998; Klein and Manning, 2003). Treebank transformati</context>
</contexts>
<marker>Carreras, Collins, Koo, 2008</marker>
<rawString>Xavier Carreras, Mickael Collins, and Terry Koo. 2008. TAG, dynamic programming, and the perceptron for efficient, feature-rich parsing. In Proceedings of the Twelfth Conference on Computational Natural Language Learning (CoNLL), pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarseto-fine n-best parsing and maxent discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL 2005),</booktitle>
<location>Ann Arbor (MI).</location>
<contexts>
<context position="16697" citStr="Charniak and Johnson, 2005" startWordPosition="2733" endWordPosition="2736">ee Insertion Grammar parser of (Chiang, 2003) as well as (Bikel, 2002)’s implementation of the Collins’ models 1 &amp; 2 (Collins, 1999). Most of the lexicalized parsers we use in this work are well known and since their releases, almost ten years ago, their core parsing models still provide state-of-the-art performance on the standard test set for English.6 We insist on the fact that one of the goals of this work was to evaluate raw performance of well known parsing models on French annotated data. Thus, we have not considered using more complex parsing architectures that makes use of reranking (Charniak and Johnson, 2005) or self-training (McClosky et al., 2006) in order to improve the performance of a raw parsing model. Furthermore, studying and designing a set of features for a reranking parser was beyond the scope of this work. However, we did use some of these models in a non classical way, leading us to explore a Collins’ model 2 variation, named model X, and a Stochastic Tree Adjoining Grammar (Schabes, 1992; Resnik, 1992) variant7 , named Spinal Stochastic Tree Insertion Grammars (hereafter SPINAL STIG), which was first used to validate the heuristics used by our adaptation of the Bikel’s parser to Fren</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarseto-fine n-best parsing and maxent discriminative reranking. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL 2005), Ann Arbor (MI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum-entropyinspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st Annual Meeting of the North American Chapter of the ACL (NAACL),</booktitle>
<location>Seattle.</location>
<contexts>
<context position="3420" citStr="Charniak, 2000" startWordPosition="536" endWordPosition="537">l set of trees. This path has the advantage of an easier reproducibility and eases verification of reported results. With the problem of the usability of the data source being solved, the question of finding one or many accurate language models for parsing French raises. Thus, to answer this question, this paper reports a set of experiments where five algorithms, first designed for the purpose of parsing English, have been adapted to French: a PCFG parser with latent annotation (Petrov et al., 2006), a Stochastic Tree Adjoining Grammar parser (Chiang, 2003), the Charniak’s lexicalized parser (Charniak, 2000) and the Bikel’s implementation of Collins’ Model 1 and 2 (Collins, 1999) described in (Bikel, 2002). To ease further comparisons, we report results on two versions of the treebank: (1) the last version made available in December 2007, hereafter FTB , and described in (Abeillé and Barrier, 2004) and the (2) LFG inspired version of (Schluter and van Genabith, 2007). The paper is structured as follows : After a brief presentation of the treebanks, we discuss the use1This has been made available in December 2007. 150 Proceedings of the 11th International Conference on Parsing Technologies (IWPT),</context>
<context position="14884" citStr="Charniak, 2000" startWordPosition="2436" endWordPosition="2437">f V_part NT labels AP AdP COORD NP AdP AdP_int AP PP SENT Sint Srel AP_int COORD_XP Ssub VN VPinf VP- COORD_UC COpart ORD_unary NC NP NP_int NP_rel PP PP_int PP_rel SENT Sint Srel Ssub VN finite VN inf VN:part VP VPinf VPpart VPpart_rel Table 2: FTB’s and MFT’s annotation schemes over the bare PCFG model carried out by two class of parser models: an unlexicalized model attempting to overcome problem (a) and 3 different lexicalized models attempting to overcome PCFG’s problems (a) and (b)5. 3.1 Lexicalized algorithms The first class of algorithms used are lexicalized parsers of (Collins, 1999; Charniak, 2000; Chiang, 2003). The insight underlying the lexicalized algorithms is to model lexical dependencies between a governor and its dependants in order to improve attachment choices. Even though it has been proven numerous times that lexicalization was useful for parsing the Wall Street Journal corpus (Collins, 1999; Charniak, 2000), the question of its relevance for other languages has been raised for German (Dubey and Keller, 2003; Kübler et al., 2006) and for French 5Except (Chiang, 2003) which is indeed a TREE INSERTION GRAMMAR (Schabes and Waters, 1995) parser but which must extract a lexicali</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A maximum-entropyinspired parser. In Proceedings of the 1st Annual Meeting of the North American Chapter of the ACL (NAACL), Seattle.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Daniel M Bikel</author>
</authors>
<title>Recovering latent information in treebanks.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING’02, 19th International Conference on Computational Linguistics,</booktitle>
<location>Taipei, Taiwan,</location>
<contexts>
<context position="33943" citStr="Chiang and Bikel, 2002" startWordPosition="5562" endWordPosition="5565">0,96 Collins (M2) 79.36 79,91 Collins (M1) 77.82 - Charniak 82.35 82,66 Chiang (Sp) 80.94 81,86 Bky 84.03 82.86 Table 6: Labeled bracket scores on Arun’s FTB version and on the MFT In order to favour a “fair” comparison between our work and (Arun and Keller, 2005), we also ran their best adaptation of the COLLINS MODEL 2 on their treebank version using our own head rules set15 and obtained 81.08% of Fl score (Table 6). This shows the important influence of a fine grained head rules set and argues in favor of data driven induction of this kind of heuristics. Even though it was established, in (Chiang and Bikel, 2002), that unsupervised induction of head rules did not lead to improvement over an extremely hand crafted head rules set, we believe that for resource poor languages, such methods could lead toward significant improvements over parsing accuracy. Thus, the new unsupervised head rules induction method presented in (Sangati and Zuidema, 2009) seems very promising for this topic. However, it would be of interest to see how the Arun’s model would perform using the MODEL X parameter variations. 7 Discussion Regarding the apparent lack of success of a genuine COLLINS’ MODEL 2 (in most cases, its per15Du</context>
</contexts>
<marker>Chiang, Bikel, 2002</marker>
<rawString>David Chiang and Daniel M. Bikel. 2002. Recovering latent information in treebanks. In Proceedings of COLING’02, 19th International Conference on Computational Linguistics, Taipei, Taiwan, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Statistical Parsing with an Automatically Extracted Tree Adjoining Grammar, chapter 16,</title>
<date>2003</date>
<pages>299--316</pages>
<publisher>CSLI Publications.</publisher>
<contexts>
<context position="3368" citStr="Chiang, 2003" startWordPosition="530" endWordPosition="531">ible to train statistical parsers from the original set of trees. This path has the advantage of an easier reproducibility and eases verification of reported results. With the problem of the usability of the data source being solved, the question of finding one or many accurate language models for parsing French raises. Thus, to answer this question, this paper reports a set of experiments where five algorithms, first designed for the purpose of parsing English, have been adapted to French: a PCFG parser with latent annotation (Petrov et al., 2006), a Stochastic Tree Adjoining Grammar parser (Chiang, 2003), the Charniak’s lexicalized parser (Charniak, 2000) and the Bikel’s implementation of Collins’ Model 1 and 2 (Collins, 1999) described in (Bikel, 2002). To ease further comparisons, we report results on two versions of the treebank: (1) the last version made available in December 2007, hereafter FTB , and described in (Abeillé and Barrier, 2004) and the (2) LFG inspired version of (Schluter and van Genabith, 2007). The paper is structured as follows : After a brief presentation of the treebanks, we discuss the use1This has been made available in December 2007. 150 Proceedings of the 11th Inte</context>
<context position="14899" citStr="Chiang, 2003" startWordPosition="2438" endWordPosition="2440">ls AP AdP COORD NP AdP AdP_int AP PP SENT Sint Srel AP_int COORD_XP Ssub VN VPinf VP- COORD_UC COpart ORD_unary NC NP NP_int NP_rel PP PP_int PP_rel SENT Sint Srel Ssub VN finite VN inf VN:part VP VPinf VPpart VPpart_rel Table 2: FTB’s and MFT’s annotation schemes over the bare PCFG model carried out by two class of parser models: an unlexicalized model attempting to overcome problem (a) and 3 different lexicalized models attempting to overcome PCFG’s problems (a) and (b)5. 3.1 Lexicalized algorithms The first class of algorithms used are lexicalized parsers of (Collins, 1999; Charniak, 2000; Chiang, 2003). The insight underlying the lexicalized algorithms is to model lexical dependencies between a governor and its dependants in order to improve attachment choices. Even though it has been proven numerous times that lexicalization was useful for parsing the Wall Street Journal corpus (Collins, 1999; Charniak, 2000), the question of its relevance for other languages has been raised for German (Dubey and Keller, 2003; Kübler et al., 2006) and for French 5Except (Chiang, 2003) which is indeed a TREE INSERTION GRAMMAR (Schabes and Waters, 1995) parser but which must extract a lexicalized grammar fro</context>
<context position="16115" citStr="Chiang, 2003" startWordPosition="2637" endWordPosition="2638">he set of context free rules underlying a treebank. 153 (Arun and Keller, 2005) where the authors argue that French parsing benefits from lexicalization but the treebank flatness reduces its impact whereas (Schluter and van Genabith, 2007) argue that an improved annotation scheme and an improved treebank consistency should help to reach a reasonable state of the art. As only Collins’ models 1 &amp; 2 have been used for French as instances of lexicalised parsers, we also report results from the history-based generative parser of (Charniak, 2000) and the Stochastic Tree Insertion Grammar parser of (Chiang, 2003) as well as (Bikel, 2002)’s implementation of the Collins’ models 1 &amp; 2 (Collins, 1999). Most of the lexicalized parsers we use in this work are well known and since their releases, almost ten years ago, their core parsing models still provide state-of-the-art performance on the standard test set for English.6 We insist on the fact that one of the goals of this work was to evaluate raw performance of well known parsing models on French annotated data. Thus, we have not considered using more complex parsing architectures that makes use of reranking (Charniak and Johnson, 2005) or self-training </context>
<context position="38162" citStr="Chiang, 2003" startWordPosition="6284" endWordPosition="6285"> 7: MODEL X simplified parameter class for MNTs M(t)i is the POS tag of the ith MNT, P the parent node label, H the head node label, wh the head word, th its POS tag, (Mi−1, ..., Mi−k) the list of previously generated MNTs and f a flag stating if the current node is the first MNT to be generated. Interestingly, in the SPINAL STIG model, almost all the extracted trees are spinal and consequently are handled by an operation called Sister Adjunction whose probability model for a given root node of an elementary tree, also conditions its generation upon the label of the previously generated tree (Chiang, 2003). Furthermore, the second component of the Sister Adjunction’s back-off structure (Table 8) is made coarser by the removing of the lexical anchor of the tree where a sister-adjunction is to occur. Studying in depth the respective impact of these features on the performance of both models is outside the scope of this paper, nevertheless we note that their back-off structures are based on similar principles: a deletion of the main lexical information and a context limited to the root label of the previously generated tree (resp. MNT node label for the MODEL X). This can explain why these formall</context>
<context position="39699" citStr="Chiang, 2003" startWordPosition="6551" endWordPosition="6552">ee templates (Chiang, 2003) γ is the tree to be generated on the sister adjunction site (η,,, i) of the tree template τ,,, ω,, is the lexical anchor of τ,,, τ,, is τ,, stripped from its anchor POS tag and X is the root label of the previous tree to sister-adjoin at the site (η,,, i). However, the learning curve also shows that the CHARNIAK’s17 and BKY’s parsers have almost parallel curves whereas this specific COLLIN’S MODEL 1 parser and the SPINAL STIG model have very similar shape and seem to reach an upper limit very quickly.18 The last two parsers having also very similar back-off models (Chiang, 2003), we wonder (1) if we are not actually comparing them because of data sparseness issues and (2) if the small size of commonly used treebanks does not lead the community to consider lexicalized models, via the lone COLLINS’ MODELS, as inappropriate to parse other languages than Wall Street Journal English. 17As opposed to the other parsers, the Charniak’s parser tagging accuracy did not reach the 100% limit, 98.32% for the last split. So the comparison is not really fair but we believe that the visible tendency still stands. 18We are of course aware that the curve’s values are also function of </context>
</contexts>
<marker>Chiang, 2003</marker>
<rawString>David Chiang, 2003. Statistical Parsing with an Automatically Extracted Tree Adjoining Grammar, chapter 16, pages 299–316. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia.</location>
<contexts>
<context position="3493" citStr="Collins, 1999" startWordPosition="549" endWordPosition="550">nd eases verification of reported results. With the problem of the usability of the data source being solved, the question of finding one or many accurate language models for parsing French raises. Thus, to answer this question, this paper reports a set of experiments where five algorithms, first designed for the purpose of parsing English, have been adapted to French: a PCFG parser with latent annotation (Petrov et al., 2006), a Stochastic Tree Adjoining Grammar parser (Chiang, 2003), the Charniak’s lexicalized parser (Charniak, 2000) and the Bikel’s implementation of Collins’ Model 1 and 2 (Collins, 1999) described in (Bikel, 2002). To ease further comparisons, we report results on two versions of the treebank: (1) the last version made available in December 2007, hereafter FTB , and described in (Abeillé and Barrier, 2004) and the (2) LFG inspired version of (Schluter and van Genabith, 2007). The paper is structured as follows : After a brief presentation of the treebanks, we discuss the use1This has been made available in December 2007. 150 Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 150–161, Paris, October 2009. c�2009 Association for Computational</context>
<context position="14868" citStr="Collins, 1999" startWordPosition="2434" endWordPosition="2435">l V_finite V_inf V_part NT labels AP AdP COORD NP AdP AdP_int AP PP SENT Sint Srel AP_int COORD_XP Ssub VN VPinf VP- COORD_UC COpart ORD_unary NC NP NP_int NP_rel PP PP_int PP_rel SENT Sint Srel Ssub VN finite VN inf VN:part VP VPinf VPpart VPpart_rel Table 2: FTB’s and MFT’s annotation schemes over the bare PCFG model carried out by two class of parser models: an unlexicalized model attempting to overcome problem (a) and 3 different lexicalized models attempting to overcome PCFG’s problems (a) and (b)5. 3.1 Lexicalized algorithms The first class of algorithms used are lexicalized parsers of (Collins, 1999; Charniak, 2000; Chiang, 2003). The insight underlying the lexicalized algorithms is to model lexical dependencies between a governor and its dependants in order to improve attachment choices. Even though it has been proven numerous times that lexicalization was useful for parsing the Wall Street Journal corpus (Collins, 1999; Charniak, 2000), the question of its relevance for other languages has been raised for German (Dubey and Keller, 2003; Kübler et al., 2006) and for French 5Except (Chiang, 2003) which is indeed a TREE INSERTION GRAMMAR (Schabes and Waters, 1995) parser but which must ex</context>
<context position="16202" citStr="Collins, 1999" startWordPosition="2652" endWordPosition="2653">the authors argue that French parsing benefits from lexicalization but the treebank flatness reduces its impact whereas (Schluter and van Genabith, 2007) argue that an improved annotation scheme and an improved treebank consistency should help to reach a reasonable state of the art. As only Collins’ models 1 &amp; 2 have been used for French as instances of lexicalised parsers, we also report results from the history-based generative parser of (Charniak, 2000) and the Stochastic Tree Insertion Grammar parser of (Chiang, 2003) as well as (Bikel, 2002)’s implementation of the Collins’ models 1 &amp; 2 (Collins, 1999). Most of the lexicalized parsers we use in this work are well known and since their releases, almost ten years ago, their core parsing models still provide state-of-the-art performance on the standard test set for English.6 We insist on the fact that one of the goals of this work was to evaluate raw performance of well known parsing models on French annotated data. Thus, we have not considered using more complex parsing architectures that makes use of reranking (Charniak and Johnson, 2005) or self-training (McClosky et al., 2006) in order to improve the performance of a raw parsing model. Fur</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benoit Crabbé</author>
<author>Marie Candito</author>
</authors>
<title>Expériences d’analyse syntaxique statistique du français.</title>
<date>2008</date>
<booktitle>In Actes de la 15ème Conférence sur le Traitement Automatique des Langues Naturelles (TALN’08),</booktitle>
<pages>45--54</pages>
<location>Avignon, France.</location>
<contexts>
<context position="2672" citStr="Crabbé and Candito, 2008" startWordPosition="416" endWordPosition="419">an Genabith, 2007), the use of the treebank was “challenging”. Indeed, before carrying out successfully any experiment, the authors had to perform a deep restructuring of the data to remove errors and inconsistencies. For the purpose of building a statistical LFG parser, (Schluter and van Genabith, 2007; Schluter and van Genabith, 2008) have reannotated a significant subset of the treebank with two underlying goals: (1) designing an annotation scheme that matches as closely as possible the LFG theory (Kaplan and Bresnan, 1982) and (2) ensuring a more consistent annotation. On the other hand, (Crabbé and Candito, 2008) showed that with a new released and corrected version of the treebank1 it was possible to train statistical parsers from the original set of trees. This path has the advantage of an easier reproducibility and eases verification of reported results. With the problem of the usability of the data source being solved, the question of finding one or many accurate language models for parsing French raises. Thus, to answer this question, this paper reports a set of experiments where five algorithms, first designed for the purpose of parsing English, have been adapted to French: a PCFG parser with la</context>
<context position="27670" citStr="Crabbé and Candito, 2008" startWordPosition="4520" endWordPosition="4523">ent results for the STIG’s parser in “spinal” mode. FTB-min MFT-min COLLINS MX PARSEVAL 81.65 79.19 UNLAB. DEP 88.48 84.96 COLLINS M2 PARSEVAL 80.1 78.38 UNLAB. DEP 87.45 84.57 COLLINS M1 PARSEVAL 77.98 76.09 UNLAB. DEP 85.67 82.83 CHARNIAK PARSEVAL 82,44 81.34 UNLAB. DEP 88.42 84.90 CHIANG-SPINAL PARSEVAL 80.66 80.74 UNLAB. DEP 87.92 85,14 BKY PARSEVAL 84,93 83.16 UNLAB. DEP 90.06 87.29 CHIANG-PURE PARSEVAL 80.52 79.56 UNLAB. DEP 87,95 85.02 Table 3: Labeled Fl scores for unlexicalised and lexicalised parsers on treebanks with minimal tagsets 5 Cross parser evaluation of tagset variation In (Crabbé and Candito, 2008), the authors showed that it was possible to accurately train the Petrov’s parser (Petrov et al., 2006) on the FTB using a more fine grained tag set. This tagset, named CC12 annotates the basic non-terminal labels with verbal mood information, and wh-features. Results were shown to be state of the art with a Fl parseval score of 86.42% on less than 40 words sentences. To summarize, the authors tested the impact of tagset variations over the FTB using constituency measures as performance indicators. Knowing that the MFT has been built with PCFGbased LFG parsing performance in mind (Schluter 12T</context>
<context position="29411" citStr="Crabbé and Candito, 2008" startWordPosition="4816" endWordPosition="4819">structure to another, we can evaluate the influence of one tagset to another treebank using handwritten conversion tools. In order to evaluate the relations between tagsets and parsing accuracy on a given treebank, we extract the optimal tagsets13 from the FTB, the CC tagset and we convert the MFT POS tags to this tagset. We then do the same for the FTB on which we apply the MFT’s optimal tagset (ie. SCHLU). Before introducing the results of our experiments, we briefly describe these tagsets. 1. min : Preterminals are simply the main categories, and non terminals are the plain labels 2. cc : (Crabbé and Candito, 2008) best tagset. Preterminals are the main categories, concatenated with a wh- boolean for A, ADV, PRO, and with the mood for verbs (there are 6 moods). No information is propagated to non terminal symbols. This tagset is shown in Table 4, and described in (Crabbé and Candito, 2008). ADJ ADJWH ADV ADVWH CC CLO CLR CLS CS DET DETWH ET I NC NPP P P+D P+PRO PONCT PREF PRO PROREL PROWH V VIMP VINF VPP VPR VS Table 4: CC tagset 3. schlu : N. Schluter’s tagset (Table 2. Preterminals are the main categories, plus an inf/finite/part verbal distinction, and int/card/rel distinction on N, PRO, ADV, A. Thes</context>
</contexts>
<marker>Crabbé, Candito, 2008</marker>
<rawString>Benoit Crabbé and Marie Candito. 2008. Expériences d’analyse syntaxique statistique du français. In Actes de la 15ème Conférence sur le Traitement Automatique des Langues Naturelles (TALN’08), pages 45–54, Avignon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Dalrymple</author>
</authors>
<title>Lexical-Functional Grammar,</title>
<date>2001</date>
<volume>34</volume>
<publisher>Academic Press.</publisher>
<location>San Diego, CA; London.</location>
<contexts>
<context position="10956" citStr="Dalrymple, 2001" startWordPosition="1755" endWordPosition="1756">d for the purpose of improving the task of grammar induction, the MFT’s authors also refined its tag set by propagating information (such as mood features added to VN node labels), and added functional paths4 to the original function labels. The modifications introduced in the MFT meet better the formal requirements of the LFG architecture set up 2Consider the case of the compound peut-être ’perhaps’ whose POS is ADV, its internal structure (Fig. 1) would lead to a CFG rule of the form ADV −→ V V. 3See pages 2-3 of (Schluter and van Genabith, 2007) for details. 4Inspired by the LFG framework (Dalrymple, 2001). ..Y.. X1 ..Z.. Figure 5: Coordinated structures in the general case, for FTB (up) and MFT (down) by (Cahill et al., 2004) and reduce the size of the grammars extracted from the treebank. MFT has also undergone a phase of error mining and an extensive manual correction. 2.3 Coordination in French Treebanks One of the key differences between the two French treebanks is the way they treat coordinate structures. Whereas the FTB represents them with an adjunction of a COORD phrase as a sister or a daughter of the coordinated element, the MFT introduces a treatment closer to the one used in the PT</context>
</contexts>
<marker>Dalrymple, 2001</marker>
<rawString>Mary Dalrymple. 2001. Lexical-Functional Grammar, volume 34 of Syntax and Semantics. San Diego, CA; London. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Dubey</author>
<author>Frank Keller</author>
</authors>
<title>Probabilistic parsing for german using sister-head dependencies. In</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>96--103</pages>
<contexts>
<context position="15315" citStr="Dubey and Keller, 2003" startWordPosition="2502" endWordPosition="2505">lexicalized models attempting to overcome PCFG’s problems (a) and (b)5. 3.1 Lexicalized algorithms The first class of algorithms used are lexicalized parsers of (Collins, 1999; Charniak, 2000; Chiang, 2003). The insight underlying the lexicalized algorithms is to model lexical dependencies between a governor and its dependants in order to improve attachment choices. Even though it has been proven numerous times that lexicalization was useful for parsing the Wall Street Journal corpus (Collins, 1999; Charniak, 2000), the question of its relevance for other languages has been raised for German (Dubey and Keller, 2003; Kübler et al., 2006) and for French 5Except (Chiang, 2003) which is indeed a TREE INSERTION GRAMMAR (Schabes and Waters, 1995) parser but which must extract a lexicalized grammar from the set of context free rules underlying a treebank. 153 (Arun and Keller, 2005) where the authors argue that French parsing benefits from lexicalization but the treebank flatness reduces its impact whereas (Schluter and van Genabith, 2007) argue that an improved annotation scheme and an improved treebank consistency should help to reach a reasonable state of the art. As only Collins’ models 1 &amp; 2 have been use</context>
</contexts>
<marker>Dubey, Keller, 2003</marker>
<rawString>Amit Dubey and Frank Keller. 2003. Probabilistic parsing for german using sister-head dependencies. In In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 96–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ane Dybro-Johansen</author>
</authors>
<title>Extraction automatique de grammaires à partir d’un corpus français.</title>
<date>2004</date>
<tech>Master’s thesis,</tech>
<institution>Université Paris</institution>
<contexts>
<context position="1763" citStr="Dybro-Johansen, 2004" startWordPosition="267" endWordPosition="268">hus questioning the relevance of using only one lexicalized model to study the usefulness of lexicalization for the parsing of French. 1 Introduction The development of large scale symbolic grammars has long been a lively topic in the French NLP community. Surprisingly, the acquisition of probabilistic grammars aiming at stochastic parsing, using either supervised or unsupervised methods, has not attracted much attention despite the availability of large manually syntactic annotated data for French. Nevertheless, the availability of the Paris 7 French Treebank (Abeillé et al., 2003), allowed (Dybro-Johansen, 2004) to carry out the extraction of a Tree Adjoining Grammar (Joshi, 1987) and led (Arun and Keller, 2005) $ Université Paris 7 INRIA (ALPAGE) 30 rue du Château des Rentiers F-75013 Paris France to induce the first effective lexicalized parser for French. Yet, as noted by (Schluter and van Genabith, 2007), the use of the treebank was “challenging”. Indeed, before carrying out successfully any experiment, the authors had to perform a deep restructuring of the data to remove errors and inconsistencies. For the purpose of building a statistical LFG parser, (Schluter and van Genabith, 2007; Schluter a</context>
<context position="22745" citStr="Dybro-Johansen, 2004" startWordPosition="3739" endWordPosition="3740">“discovered” this obvious property during the preliminary porting phase. trees (or observed trees) using a specific instanciation of EM. 4 Experimental protocol In this section, we specify the settings of the parsers for French, the evaluation protocol and the different instantiations of the treebanks we used for conducting the experiments. 4.1 Parsers settings Head Propagation table All lexicalized parsers reported in this paper use head propagation tables. Adapting them to the French language requires to design French specific head propagation rules. To this end, we used those described by (Dybro-Johansen, 2004) for training a Stochastic Tree Adjoining Grammar parser on French. From this set, we built a set of meta-rules that were automatically derived to match each treebank annotation scheme. As the Collins Model 2 and the STIG model need to distinguish between argument and adjunct nodes to acquire subcategorization frames probabilities, we implemented an argument-adjunct distinction table that takes advantage of the function labels annotated in the treebank. This is one of the main differences with the experiments described in (Arun and Keller, 2005) and (DybroJohansen, 2004) where the authors had </context>
<context position="31770" citStr="Dybro-Johansen, 2004" startWordPosition="5200" endWordPosition="5201">ion between CHARNIAK and STIG-spinal on PARSEVAL evaluation of the MFT-CC.14 One the other hand, unlabeled dependency evaluations over lexicalized parsers are different among treebanks. In the case of the FTB, CHARNIAK exhibits the highest F-score ( FTB-CC: 89.7, FTB-SCHLU: 89.67) whereas SPINAL STIG performs slightly better on the MFT-SCHLU (MFTCC: 86,7, MFT-SCHLU: 87.16). Note that both tested variations of the Collins’ model 2 display very high unlabeled dependency scores with the SCHLU tagset. 6 Related Works As we said in the introduction, the initial work on the FTB has been carried by (Dybro-Johansen, 2004) in order to extract Tree Adjunct Grammars from the treebank. Although parsing results were not reported, she experienced the same argument adjunct distinction problem than (Arun and Keller, 2005) due to the treebank flatness and the lack of functional labels in this version. This led Arun to modify some node annotations (VNG to distinguish nodes dominating subcategorized subject clitics and so on) and to add bigrams probabilities to the language model in order to enhance the overall COLLINS’ MODEL’ performance. Although our treebanks cannot be compared (20.000 sentences for Arun’s one vs 1235</context>
</contexts>
<marker>Dybro-Johansen, 2004</marker>
<rawString>Ane Dybro-Johansen. 2004. Extraction automatique de grammaires à partir d’un corpus français. Master’s thesis, Université Paris 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>PCFG models of linguistic tree representations.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="21365" citStr="Johnson, 1998" startWordPosition="3522" endWordPosition="3523">els has been independently proposed in (Carreras et al., 2008) with the purpose of getting a richer parsing model that can use non local features and in (Sangati and Zuidema, 2009) as a mean of extracting a Lexicalized Tree Substitution Grammar. In their process, the first extracted grammar is actually a spinal STIG. 3.2 Unlexicalized Parser As an instance of an unlexicalized parser, the last algorithm we use is the Berkeley unlexicalized parser (BKY) of (Petrov et al., 2006). This algorithm is an evolution of treebank transformation principles aimed at reducing PCFG independence assumptions (Johnson, 1998; Klein and Manning, 2003). Treebank transformations may be of two kinds (1) structure transformation and (2) labelling transformations. The Berkeley parser concentrates on (2) by recasting the problem of acquiring an optimal set of non terminal symbols as an semisupervised learning problem by learning a PCFG with Latent annotations (PCFG-LA): given an observed PCFG induced from the treebank, the latent grammar is generated by combining every non terminal of the observed grammar to a predefined set H of latent symbols. The parameters of the latent grammar are estimated from the actual treebank</context>
</contexts>
<marker>Johnson, 1998</marker>
<rawString>Mark Johnson. 1998. PCFG models of linguistic tree representations. Computational Linguistics, 24(4):613–632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
</authors>
<title>Introduction to tree adjoining grammar.</title>
<date>1987</date>
<journal>The Mathematics ofLanguage. J. Benjamins.</journal>
<editor>In A. Manaster-Ramer, editor,</editor>
<contexts>
<context position="1833" citStr="Joshi, 1987" startWordPosition="279" endWordPosition="280">usefulness of lexicalization for the parsing of French. 1 Introduction The development of large scale symbolic grammars has long been a lively topic in the French NLP community. Surprisingly, the acquisition of probabilistic grammars aiming at stochastic parsing, using either supervised or unsupervised methods, has not attracted much attention despite the availability of large manually syntactic annotated data for French. Nevertheless, the availability of the Paris 7 French Treebank (Abeillé et al., 2003), allowed (Dybro-Johansen, 2004) to carry out the extraction of a Tree Adjoining Grammar (Joshi, 1987) and led (Arun and Keller, 2005) $ Université Paris 7 INRIA (ALPAGE) 30 rue du Château des Rentiers F-75013 Paris France to induce the first effective lexicalized parser for French. Yet, as noted by (Schluter and van Genabith, 2007), the use of the treebank was “challenging”. Indeed, before carrying out successfully any experiment, the authors had to perform a deep restructuring of the data to remove errors and inconsistencies. For the purpose of building a statistical LFG parser, (Schluter and van Genabith, 2007; Schluter and van Genabith, 2008) have reannotated a significant subset of the tr</context>
<context position="22044" citStr="Joshi, 1987" startWordPosition="3631" endWordPosition="3632">kinds (1) structure transformation and (2) labelling transformations. The Berkeley parser concentrates on (2) by recasting the problem of acquiring an optimal set of non terminal symbols as an semisupervised learning problem by learning a PCFG with Latent annotations (PCFG-LA): given an observed PCFG induced from the treebank, the latent grammar is generated by combining every non terminal of the observed grammar to a predefined set H of latent symbols. The parameters of the latent grammar are estimated from the actual treebank 9Not to be confused with the “spine” in the Tree Adjunct Grammar (Joshi, 1987) framework which is the path from a foot node to the root node. 10We mistakenly “discovered” this obvious property during the preliminary porting phase. trees (or observed trees) using a specific instanciation of EM. 4 Experimental protocol In this section, we specify the settings of the parsers for French, the evaluation protocol and the different instantiations of the treebanks we used for conducting the experiments. 4.1 Parsers settings Head Propagation table All lexicalized parsers reported in this paper use head propagation tables. Adapting them to the French language requires to design F</context>
</contexts>
<marker>Joshi, 1987</marker>
<rawString>Aravind K. Joshi. 1987. Introduction to tree adjoining grammar. In A. Manaster-Ramer, editor, The Mathematics ofLanguage. J. Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kaplan</author>
<author>J Bresnan</author>
</authors>
<title>Lexical-functional grammar: A formal system for grammarical representation.</title>
<date>1982</date>
<booktitle>The Mental Representation of Grammatical Relations,</booktitle>
<pages>173--281</pages>
<editor>In J. Bresnan, editor,</editor>
<publisher>MIT Press.</publisher>
<location>Mass.:</location>
<contexts>
<context position="2579" citStr="Kaplan and Bresnan, 1982" startWordPosition="401" endWordPosition="404">to induce the first effective lexicalized parser for French. Yet, as noted by (Schluter and van Genabith, 2007), the use of the treebank was “challenging”. Indeed, before carrying out successfully any experiment, the authors had to perform a deep restructuring of the data to remove errors and inconsistencies. For the purpose of building a statistical LFG parser, (Schluter and van Genabith, 2007; Schluter and van Genabith, 2008) have reannotated a significant subset of the treebank with two underlying goals: (1) designing an annotation scheme that matches as closely as possible the LFG theory (Kaplan and Bresnan, 1982) and (2) ensuring a more consistent annotation. On the other hand, (Crabbé and Candito, 2008) showed that with a new released and corrected version of the treebank1 it was possible to train statistical parsers from the original set of trees. This path has the advantage of an easier reproducibility and eases verification of reported results. With the problem of the usability of the data source being solved, the question of finding one or many accurate language models for parsing French raises. Thus, to answer this question, this paper reports a set of experiments where five algorithms, first de</context>
</contexts>
<marker>Kaplan, Bresnan, 1982</marker>
<rawString>R. Kaplan and J. Bresnan. 1982. Lexical-functional grammar: A formal system for grammarical representation. In J. Bresnan, editor, The Mental Representation of Grammatical Relations, pages 173–281. Mass.: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1,</booktitle>
<pages>423--430</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="21391" citStr="Klein and Manning, 2003" startWordPosition="3524" endWordPosition="3527">dependently proposed in (Carreras et al., 2008) with the purpose of getting a richer parsing model that can use non local features and in (Sangati and Zuidema, 2009) as a mean of extracting a Lexicalized Tree Substitution Grammar. In their process, the first extracted grammar is actually a spinal STIG. 3.2 Unlexicalized Parser As an instance of an unlexicalized parser, the last algorithm we use is the Berkeley unlexicalized parser (BKY) of (Petrov et al., 2006). This algorithm is an evolution of treebank transformation principles aimed at reducing PCFG independence assumptions (Johnson, 1998; Klein and Manning, 2003). Treebank transformations may be of two kinds (1) structure transformation and (2) labelling transformations. The Berkeley parser concentrates on (2) by recasting the problem of acquiring an optimal set of non terminal symbols as an semisupervised learning problem by learning a PCFG with Latent annotations (PCFG-LA): given an observed PCFG induced from the treebank, the latent grammar is generated by combining every non terminal of the observed grammar to a predefined set H of latent symbols. The parameters of the latent grammar are estimated from the actual treebank 9Not to be confused with </context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1, pages 423–430. Association for Computational Linguistics Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra Kübler</author>
<author>Erhard W Hinrichs</author>
<author>Wolfgang Maier</author>
</authors>
<title>Is it really that difficult to parse german?</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>111--119</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="15337" citStr="Kübler et al., 2006" startWordPosition="2506" endWordPosition="2509">pting to overcome PCFG’s problems (a) and (b)5. 3.1 Lexicalized algorithms The first class of algorithms used are lexicalized parsers of (Collins, 1999; Charniak, 2000; Chiang, 2003). The insight underlying the lexicalized algorithms is to model lexical dependencies between a governor and its dependants in order to improve attachment choices. Even though it has been proven numerous times that lexicalization was useful for parsing the Wall Street Journal corpus (Collins, 1999; Charniak, 2000), the question of its relevance for other languages has been raised for German (Dubey and Keller, 2003; Kübler et al., 2006) and for French 5Except (Chiang, 2003) which is indeed a TREE INSERTION GRAMMAR (Schabes and Waters, 1995) parser but which must extract a lexicalized grammar from the set of context free rules underlying a treebank. 153 (Arun and Keller, 2005) where the authors argue that French parsing benefits from lexicalization but the treebank flatness reduces its impact whereas (Schluter and van Genabith, 2007) argue that an improved annotation scheme and an improved treebank consistency should help to reach a reasonable state of the art. As only Collins’ models 1 &amp; 2 have been used for French as instan</context>
</contexts>
<marker>Kübler, Hinrichs, Maier, 2006</marker>
<rawString>Sandra Kübler, Erhard W. Hinrichs, and Wolfgang Maier. 2006. Is it really that difficult to parse german? In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 111–119, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>A dependency-based method for evaluating broad-coverage parsers.</title>
<date>1995</date>
<booktitle>In International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1420--1425</pages>
<location>Montreal.</location>
<contexts>
<context position="25417" citStr="Lin, 1995" startWordPosition="4164" endWordPosition="4165">mpounds merged. Namely, we preprocess the treebank in order to turn each compound into a single token both for training and test. 4.4 Evaluation metrics Constituency Evaluation: we use the standard labeled bracketed PARSEVAL metric for evaluation (Black et al., 1991), along with unlabeled dependency evaluation, which is described as a more annotation-neutral metric in (Rehbein and van Genabith, 2007). In the remainder of this paper, we use PARSEVAL as a shortcut for Labeled Brackets results on sentence of length 40 or less. Dependency Evaluation: unlabeled dependencies are computed using the (Lin, 1995) algorithm, and the Dybro Johansens’s head propagation rules cited above11. The unlabeled dependency accuracy gives the percentage of input words (excluding punctuation) that receive the correct head. All reported evaluations in this paper are calculated on sentences of length less than 40 words. 4.5 Baseline: Comparison using minimal tagsets We compared all parsers on three different instances, but still comparable versions, of both the FTB and the MFT. In order to establish a baseline, the treebanks are converted to a minimal tag set (only the major syntactic categories.) without any other i</context>
</contexts>
<marker>Lin, 1995</marker>
<rawString>Dekang Lin. 1995. A dependency-based method for evaluating broad-coverage parsers. In International Joint Conference on Artificial Intelligence, pages 1420–1425, Montreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="5945" citStr="Marcus et al., 1994" startWordPosition="899" endWordPosition="902">ubcat=&amp;quot;neg&amp;quot;&gt;pas&lt;/w&gt; &lt;/AdP&gt; &lt;AP fct=&amp;quot;ATS&amp;quot;&gt; &lt;w cat=&amp;quot;ADV&amp;quot; lemma=&amp;quot;aussi&amp;quot;&gt;aussi&lt;/w&gt; &lt;w cat=&amp;quot;A&amp;quot; lemma=&amp;quot;sombre&amp;quot; mph=&amp;quot;ms&amp;quot; subcat=&amp;quot;qual&amp;quot;&gt;sombre&lt;/w&gt; &lt;/AP&gt; &lt;w cat=&amp;quot;PONCT&amp;quot; lemma=&amp;quot;.&amp;quot; subcat=&amp;quot;S&amp;quot;&gt;.&lt;/w&gt; &lt;/SENT&gt; Figure 1: Simplified example of the FTB: ”Le bilan n’est peut-être pas aussi sombre.” (i.e. The result is perhaps not as bleak) Though the original release (in 2000) consists of 20,648 sentences, the subset of 12351 functionally annotated sentences is known to be more consistently annotated and therefore is the one used in this work. Its key properties, compared with the Penn Treebank (hereafter PTB, (Marcus et al., 1994)), are the following: Size: The FTB consists of 385,458 tokens and 12,351 sentences, that is the third of the PTB. It also entails that the average length of a sentence is 27.48 tokens. By contrast the average sentence length in the PTB is 24 tokens. Inflection: French morphology is richer than English and leads to increased data sparseness issues for the purpose of statistical parsing. There are 24,098 types in the FTB, entailing an average of 16 tokens occurring for each type. A Flat Annotation Scheme: Both the FTB and the PTB are annotated with constituent trees. However, the annotation sch</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1994</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1994. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McClosky</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Effective self-training for parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,</booktitle>
<pages>152--159</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City, USA,</location>
<contexts>
<context position="16738" citStr="McClosky et al., 2006" startWordPosition="2739" endWordPosition="2742">as well as (Bikel, 2002)’s implementation of the Collins’ models 1 &amp; 2 (Collins, 1999). Most of the lexicalized parsers we use in this work are well known and since their releases, almost ten years ago, their core parsing models still provide state-of-the-art performance on the standard test set for English.6 We insist on the fact that one of the goals of this work was to evaluate raw performance of well known parsing models on French annotated data. Thus, we have not considered using more complex parsing architectures that makes use of reranking (Charniak and Johnson, 2005) or self-training (McClosky et al., 2006) in order to improve the performance of a raw parsing model. Furthermore, studying and designing a set of features for a reranking parser was beyond the scope of this work. However, we did use some of these models in a non classical way, leading us to explore a Collins’ model 2 variation, named model X, and a Stochastic Tree Adjoining Grammar (Schabes, 1992; Resnik, 1992) variant7 , named Spinal Stochastic Tree Insertion Grammars (hereafter SPINAL STIG), which was first used to validate the heuristics used by our adaptation of the Bikel’s parser to French. The next two subsections introduce th</context>
</contexts>
<marker>McClosky, Charniak, Johnson, 2006</marker>
<rawString>David McClosky, Eugene Charniak, and Mark Johnson. 2006. Effective self-training for parsing. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 152–159, New York City, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="3309" citStr="Petrov et al., 2006" startWordPosition="520" endWordPosition="523"> a new released and corrected version of the treebank1 it was possible to train statistical parsers from the original set of trees. This path has the advantage of an easier reproducibility and eases verification of reported results. With the problem of the usability of the data source being solved, the question of finding one or many accurate language models for parsing French raises. Thus, to answer this question, this paper reports a set of experiments where five algorithms, first designed for the purpose of parsing English, have been adapted to French: a PCFG parser with latent annotation (Petrov et al., 2006), a Stochastic Tree Adjoining Grammar parser (Chiang, 2003), the Charniak’s lexicalized parser (Charniak, 2000) and the Bikel’s implementation of Collins’ Model 1 and 2 (Collins, 1999) described in (Bikel, 2002). To ease further comparisons, we report results on two versions of the treebank: (1) the last version made available in December 2007, hereafter FTB , and described in (Abeillé and Barrier, 2004) and the (2) LFG inspired version of (Schluter and van Genabith, 2007). The paper is structured as follows : After a brief presentation of the treebanks, we discuss the use1This has been made a</context>
<context position="21232" citStr="Petrov et al., 2006" startWordPosition="3502" endWordPosition="3505">nteresting enough to be integrated as the “Chiang Spinal” model in our parser set. It should be noted that, recently, the use of similar models has been independently proposed in (Carreras et al., 2008) with the purpose of getting a richer parsing model that can use non local features and in (Sangati and Zuidema, 2009) as a mean of extracting a Lexicalized Tree Substitution Grammar. In their process, the first extracted grammar is actually a spinal STIG. 3.2 Unlexicalized Parser As an instance of an unlexicalized parser, the last algorithm we use is the Berkeley unlexicalized parser (BKY) of (Petrov et al., 2006). This algorithm is an evolution of treebank transformation principles aimed at reducing PCFG independence assumptions (Johnson, 1998; Klein and Manning, 2003). Treebank transformations may be of two kinds (1) structure transformation and (2) labelling transformations. The Berkeley parser concentrates on (2) by recasting the problem of acquiring an optimal set of non terminal symbols as an semisupervised learning problem by learning a PCFG with Latent annotations (PCFG-LA): given an observed PCFG induced from the treebank, the latent grammar is generated by combining every non terminal of the </context>
<context position="27773" citStr="Petrov et al., 2006" startWordPosition="4537" endWordPosition="4540">EP 88.48 84.96 COLLINS M2 PARSEVAL 80.1 78.38 UNLAB. DEP 87.45 84.57 COLLINS M1 PARSEVAL 77.98 76.09 UNLAB. DEP 85.67 82.83 CHARNIAK PARSEVAL 82,44 81.34 UNLAB. DEP 88.42 84.90 CHIANG-SPINAL PARSEVAL 80.66 80.74 UNLAB. DEP 87.92 85,14 BKY PARSEVAL 84,93 83.16 UNLAB. DEP 90.06 87.29 CHIANG-PURE PARSEVAL 80.52 79.56 UNLAB. DEP 87,95 85.02 Table 3: Labeled Fl scores for unlexicalised and lexicalised parsers on treebanks with minimal tagsets 5 Cross parser evaluation of tagset variation In (Crabbé and Candito, 2008), the authors showed that it was possible to accurately train the Petrov’s parser (Petrov et al., 2006) on the FTB using a more fine grained tag set. This tagset, named CC12 annotates the basic non-terminal labels with verbal mood information, and wh-features. Results were shown to be state of the art with a Fl parseval score of 86.42% on less than 40 words sentences. To summarize, the authors tested the impact of tagset variations over the FTB using constituency measures as performance indicators. Knowing that the MFT has been built with PCFGbased LFG parsing performance in mind (Schluter 12TREEBANKS+ in (Crabbé and Candito, 2008). 156 and van Genabith, 2008) but suffers from a small training </context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ines Rehbein</author>
<author>Josef van Genabith</author>
</authors>
<title>Treebank annotation schemes and parser evaluation for german.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<location>Prague.</location>
<marker>Rehbein, van Genabith, 2007</marker>
<rawString>Ines Rehbein and Josef van Genabith. 2007. Treebank annotation schemes and parser evaluation for german. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Probabilistic tree-adjoining grammars as a framework for statistic natural language processing. COLING’92,</title>
<date>1992</date>
<location>Nantes, France.</location>
<contexts>
<context position="17112" citStr="Resnik, 1992" startWordPosition="2807" endWordPosition="2808"> raw performance of well known parsing models on French annotated data. Thus, we have not considered using more complex parsing architectures that makes use of reranking (Charniak and Johnson, 2005) or self-training (McClosky et al., 2006) in order to improve the performance of a raw parsing model. Furthermore, studying and designing a set of features for a reranking parser was beyond the scope of this work. However, we did use some of these models in a non classical way, leading us to explore a Collins’ model 2 variation, named model X, and a Stochastic Tree Adjoining Grammar (Schabes, 1992; Resnik, 1992) variant7 , named Spinal Stochastic Tree Insertion Grammars (hereafter SPINAL STIG), which was first used to validate the heuristics used by our adaptation of the Bikel’s parser to French. The next two subsections introduce these variations. Collins’ Model 2 variation During the exploratory phase of this work, we found out that a specific instance of the Collins’ model 2 leads to significantly better performance than the canonical model when applied to any of the French Treebanks. The difference between those two models relies on the way probabilities associated to socalled “modifier non termi</context>
</contexts>
<marker>Resnik, 1992</marker>
<rawString>Philip Resnik. 1992. Probabilistic tree-adjoining grammars as a framework for statistic natural language processing. COLING’92, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sangati</author>
<author>W Zuidema</author>
</authors>
<title>Unsupervised methods for head assignments.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL</booktitle>
<pages>701--709</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Athens, Greece.</location>
<contexts>
<context position="20932" citStr="Sangati and Zuidema, 2009" startWordPosition="3454" endWordPosition="3457">, allows a very coarse grammar that contains, for example, only 83 tree templates for one treebank instantiation, namely the FTB-CC (cf. section 5). This behavior, although not documented10, is close to Collins’ model 1, which does not use any argument adjunct distinction information, and led to results interesting enough to be integrated as the “Chiang Spinal” model in our parser set. It should be noted that, recently, the use of similar models has been independently proposed in (Carreras et al., 2008) with the purpose of getting a richer parsing model that can use non local features and in (Sangati and Zuidema, 2009) as a mean of extracting a Lexicalized Tree Substitution Grammar. In their process, the first extracted grammar is actually a spinal STIG. 3.2 Unlexicalized Parser As an instance of an unlexicalized parser, the last algorithm we use is the Berkeley unlexicalized parser (BKY) of (Petrov et al., 2006). This algorithm is an evolution of treebank transformation principles aimed at reducing PCFG independence assumptions (Johnson, 1998; Klein and Manning, 2003). Treebank transformations may be of two kinds (1) structure transformation and (2) labelling transformations. The Berkeley parser concentrat</context>
<context position="34281" citStr="Sangati and Zuidema, 2009" startWordPosition="5612" endWordPosition="5615">ebank version using our own head rules set15 and obtained 81.08% of Fl score (Table 6). This shows the important influence of a fine grained head rules set and argues in favor of data driven induction of this kind of heuristics. Even though it was established, in (Chiang and Bikel, 2002), that unsupervised induction of head rules did not lead to improvement over an extremely hand crafted head rules set, we believe that for resource poor languages, such methods could lead toward significant improvements over parsing accuracy. Thus, the new unsupervised head rules induction method presented in (Sangati and Zuidema, 2009) seems very promising for this topic. However, it would be of interest to see how the Arun’s model would perform using the MODEL X parameter variations. 7 Discussion Regarding the apparent lack of success of a genuine COLLINS’ MODEL 2 (in most cases, its per15Due to the lack of function annotation labels in this treebank, (Arun and Keller, 2005)’s argument distinction table was used for this experiment. formance is worse than the other parsers w.r.t to constituent parsing accuracy) when trained on a treebank with annotated function labels, we suspect that this is caused by the increased data s</context>
</contexts>
<marker>Sangati, Zuidema, 2009</marker>
<rawString>F. Sangati and W. Zuidema. 2009. Unsupervised methods for head assignments. In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL 2009), pages 701–709, Athens, Greece. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Schabes</author>
<author>R C Waters</author>
</authors>
<title>Tree Insertion Grammar: Cubic-Time, Parsable Formalism that Lexicalizes Context-Free Grammar without Changing the Trees Produced.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="15443" citStr="Schabes and Waters, 1995" startWordPosition="2524" endWordPosition="2527">hms used are lexicalized parsers of (Collins, 1999; Charniak, 2000; Chiang, 2003). The insight underlying the lexicalized algorithms is to model lexical dependencies between a governor and its dependants in order to improve attachment choices. Even though it has been proven numerous times that lexicalization was useful for parsing the Wall Street Journal corpus (Collins, 1999; Charniak, 2000), the question of its relevance for other languages has been raised for German (Dubey and Keller, 2003; Kübler et al., 2006) and for French 5Except (Chiang, 2003) which is indeed a TREE INSERTION GRAMMAR (Schabes and Waters, 1995) parser but which must extract a lexicalized grammar from the set of context free rules underlying a treebank. 153 (Arun and Keller, 2005) where the authors argue that French parsing benefits from lexicalization but the treebank flatness reduces its impact whereas (Schluter and van Genabith, 2007) argue that an improved annotation scheme and an improved treebank consistency should help to reach a reasonable state of the art. As only Collins’ models 1 &amp; 2 have been used for French as instances of lexicalised parsers, we also report results from the history-based generative parser of (Charniak, </context>
<context position="18040" citStr="Schabes and Waters, 1995" startWordPosition="2957" endWordPosition="2960">is work, we found out that a specific instance of the Collins’ model 2 leads to significantly better performance than the canonical model when applied to any of the French Treebanks. The difference between those two models relies on the way probabilities associated to socalled “modifier non terminals” nodes are handled by the generative model. To explain the difference, let us recall that 6Section 23 of the Wall Street Journal section of the PTB. 7The formalism actually used in this parser is a context free variant of Tree Adjoining Grammar, Tree Insertion Grammars (TIG), first introduced in (Schabes and Waters, 1995). a lexicalized PCFG can roughly be described as a set of stochastic rules of the form: P → Ln Ln−1 ..L1 H R1 .. Rm−1 Rm where Li, H, Ri and P are all lexicalized non terminals; P inherits its head from H (Bikel, 2004). The Collins’ model 2 deterministically labels some nodes of a rule to be arguments of a given Head and the remaining nodes are considered to be modifier non terminals (hereafter MNT). In this model, given a left-hand side symbol, the head and its arguments are first generated and then the MNT are generated from the head outward. In Bikel’s implementation of Collins’s model 2 (B</context>
</contexts>
<marker>Schabes, Waters, 1995</marker>
<rawString>Y. Schabes and R.C. Waters. 1995. Tree Insertion Grammar: Cubic-Time, Parsable Formalism that Lexicalizes Context-Free Grammar without Changing the Trees Produced. Computational Linguistics, 21(4):479–513.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
</authors>
<title>Stochastic Lexicalized Tree Adjoining Grammars.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th conference on Computational linguistics,</booktitle>
<pages>425--432</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Nantes, France.</location>
<contexts>
<context position="17097" citStr="Schabes, 1992" startWordPosition="2805" endWordPosition="2806">was to evaluate raw performance of well known parsing models on French annotated data. Thus, we have not considered using more complex parsing architectures that makes use of reranking (Charniak and Johnson, 2005) or self-training (McClosky et al., 2006) in order to improve the performance of a raw parsing model. Furthermore, studying and designing a set of features for a reranking parser was beyond the scope of this work. However, we did use some of these models in a non classical way, leading us to explore a Collins’ model 2 variation, named model X, and a Stochastic Tree Adjoining Grammar (Schabes, 1992; Resnik, 1992) variant7 , named Spinal Stochastic Tree Insertion Grammars (hereafter SPINAL STIG), which was first used to validate the heuristics used by our adaptation of the Bikel’s parser to French. The next two subsections introduce these variations. Collins’ Model 2 variation During the exploratory phase of this work, we found out that a specific instance of the Collins’ model 2 leads to significantly better performance than the canonical model when applied to any of the French Treebanks. The difference between those two models relies on the way probabilities associated to socalled “mod</context>
</contexts>
<marker>Schabes, 1992</marker>
<rawString>Yves Schabes. 1992. Stochastic Lexicalized Tree Adjoining Grammars. In Proceedings of the 14th conference on Computational linguistics, pages 425– 432, Nantes, France. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Natalie Schluter</author>
<author>Josef van Genabith</author>
</authors>
<title>Preparing, restructuring, and augmenting a french treebank: Lexicalised parsers or coherent treebanks?</title>
<date>2007</date>
<booktitle>In Proceedings of PACLING 07.</booktitle>
<marker>Schluter, van Genabith, 2007</marker>
<rawString>Natalie Schluter and Josef van Genabith. 2007. Preparing, restructuring, and augmenting a french treebank: Lexicalised parsers or coherent treebanks? In Proceedings of PACLING 07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Natalie Schluter</author>
<author>Josef van Genabith</author>
</authors>
<title>Treebank-based acquisition of lfg parsing resources for french.</title>
<date>2008</date>
<booktitle>In European Language Resources Association (ELRA), editor, Proceedings of the Sixth International Language Resources and Evaluation (LREC’08),</booktitle>
<location>Marrakech, Morocco,</location>
<marker>Schluter, van Genabith, 2008</marker>
<rawString>Natalie Schluter and Josef van Genabith. 2008. Treebank-based acquisition of lfg parsing resources for french. In European Language Resources Association (ELRA), editor, Proceedings of the Sixth International Language Resources and Evaluation (LREC’08), Marrakech, Morocco, may.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Zeman</author>
<author>Philip Resnik</author>
</authors>
<title>Crosslanguage parser adaptation between related languages.</title>
<date>2008</date>
<booktitle>In Proceedings of IJCNLP 2008 Workshop on NLP for Less Privileged Languages, Hajdarábádu,</booktitle>
<contexts>
<context position="36625" citStr="Zeman and Resnik, 2008" startWordPosition="6011" endWordPosition="6014">e with the same head rules and the same set of parameters. We only compared the parsers that could be used without argument adjunct distinction table (ie. COLLIN’S MODEL 1, SPINAL STIG, CHARNIAK and BKY). For this earlier experiment, our implementation of the COLLINS MODEL 1 actually corresponds to the MODEL X without an argument adjunct distinction table. More precisely, the absence of argument nodes, used for the acquisition of subcategorization frames features, makes the MODEL X parsing model consider all the nodes of a rule, ex16Note that the CHARNIAK’s parser has been adapted for Danish (Zeman and Resnik, 2008) ; the authors report a 80.20 Fl score for a specific instance of the Danish Treebank. 158 Labeled brackets F−score (&lt;=40) 2000 4000 6000 8000 10000 Number of training sentences Figure 6: Learning Curve experiment results for parsers in perfect tagging mode cept the head, as Modifier Non Terminal nodes (MNTs). Hence, because of the impossibility to extract subcategorization frames, the generation of a MNT depends mainly on the parent head word and on the whole list of previously generated MNTs. One can suppose that training on small treebanks would lead this distribution to be sparse, therefor</context>
</contexts>
<marker>Zeman, Resnik, 2008</marker>
<rawString>Daniel Zeman and Philip Resnik. 2008. Crosslanguage parser adaptation between related languages. In Proceedings of IJCNLP 2008 Workshop on NLP for Less Privileged Languages, Hajdarábádu, India.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>